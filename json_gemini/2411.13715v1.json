{"title": "SimPhony: A Device-Circuit-Architecture Cross-Layer Modeling and Simulation Framework for Heterogeneous Electronic-Photonic AI System", "authors": ["Ziang Yin", "Meng Zhang", "Amir Begovic", "Rena Huang", "Jeff Zhang", "Jiaqi Gu"], "abstract": "Electronic-photonic integrated circuits (EPICs) offer transformative potential for next-generation high-performance AI but require interdisciplinary advances across devices, circuits, architecture, and design automation. The complexity of hybrid systems makes it challenging even for domain experts to understand distinct behaviors and interactions across design stack. The lack of a flexible, accurate, fast, and easy-to-use EPIC AI system simulation framework significantly limits the exploration of hardware innovations and system evaluations on common benchmarks. To address this gap, we propose SimPhony, a cross-layer modeling and simulation framework for heterogeneous electronic-photonic AI systems. SimPhony offers a platform that enables (1) generic, extensible hardware topology representation that supports heterogeneous multi-core architectures with diverse photonic tensor core designs; (2) optics-specific dataflow modeling with unique multi-dimensional parallelism and reuse beyond spatial/temporal dimensions; (3) data-aware energy modeling with realistic device responses, layout-aware area estimation, link budget analysis, and bandwidth-adaptive memory modeling; and (4) seamless integration with model training framework for hardware/software co-simulation. By providing a unified, versatile, and high-fidelity simulation platform, SimPhony enables researchers to innovate and evaluate EPIC AI hardware across multiple domains, facilitating the next leap in emerging AI hardware.", "sections": [{"title": "I. INTRODUCTION", "content": "Heterogeneous electronic-photonic integrated circuits (EPICs) are emerging as a next-generation platform for high-performance artificial intelligence (AI) computing. Demonstrated optical neural networks (ONNs) showcase breakthroughs in their performance and efficiency [1]\u2013[9]. Many research focuses on materials, devices, and circuits to overcome technological barriers in photonic AI. Some cross-layer co-design [10]\u2013[14] and architecture optimization [4], [5], [15]\u2013[19] research have scaled these systems for real-world AI tasks. Exploring the full stack of EPIC AI systems demands expertise across physics, device design, analog circuits, system architecture, electronic-photonic design automation (EPDA), and AI algorithms, as system-level evaluation is critical to understanding innovations at each individual design layer.\nHowever, the complexity of such hybrid system makes it challenging even for experts to grasp the behavior of each component and its interactions across software and hardware. Key challenges include: Lack of Unified Representation of Distinct PTC Circuit Topology: Photonic tensor cores (PTCs) employ diverse optical principles for matrix computation, e.g., magnitude/phase modulation, wavelength/mode/time-division multiplexing (WDM, MDM, TDM), interference, diffraction, etc. Such abundant design flexibility creates various PTC circuit topologies, e.g., weight bank [20], triangular mesh [1], [21], rectangular mesh [22], butterfly mesh [3], crossbar [2], [4], [17], single WDM link [23], etc. Prior simulators are modified from digital tools [24] that only support array-like computing architectures and cannot represent diverse PTC topologies. Lack of Support for Optics-Specific Dataflow and Parallelism: EPIC AI systems involve parallelism and resource sharing beyond temporal/spatial dimensions. The combination of optical broadcasting, hierarchical accumulation, and multi-dimensional reuse patterns results in a complex dataflow. The additional optical dimensions, like magnitude/phase, wavelength, polarization, and modes, further complicate the design space. Thus, a flexible framework tailored to optics-specific needs is required. Lack of Accurate Model-Circuit-Layout Co-Modeling: Unlike digital AI accelerators, analog systems integrate models tightly with devices/circuits, leading to inaccuracies in energy modeling due to unawareness of real workload data and precise device settings. Beyond simple analytical models, there is a strong need to incorporate rigorous simulations and even chip measurements into energy analysis. Additionally, existing EPIC design tools overlook the layout when estimating the chip area. Previous methods [4], [25], [26] aggregate device footprints, leading to an underestimate of area. Therefore, a fast yet accurate layout estimator is essential for more reliable area analysis.\nIn this work, we present SimPhony, an open-source cross-layer modeling and simulation framework for heterogeneous EPIC AI systems. Built with a customized EPIC device library, SimPhony enables the hierarchical construction of heterogeneous photonic architectures from arbitrary PTC circuit topologies. Integrated with the ONN training library, SimPhony enables end-to-end simulation, including workload extraction, memory construction, and dataflow generation, while accurately analyzing system latency, data-aware energy, and layout-aware area.\nOur main contributions are as follows,\n\u2022 We introduce SimPhony, a cross-layer simulation framework for EPIC AI systems, enabling end-to-end accurate performance and efficiency analysis.\n\u2022 Unified PTC Representation: Utilizing our customized device library, we design a hierarchical netlist-based circuit"}, {"title": "II. PRELIMINARY", "content": "The diverse properties of PTC designs result in variations in circuit topology, devices, and operational principles, affecting speed and power. Table I categorizes PTCs by expressivity, computing mechanism, operand range, and reconfiguration speed [8]. For expressivity, universal PTCs can perform arbitrary matrix multiplication, e.g., micro-ring (MRR) arrays [20], while subspace PTCs support only a subset of static linear transformation [3]. Based on the numerical range of input operands, full-range PTCs compute arbitrary values in one shot, whereas subspace coherent PTCs (e.g., Butterfly meshes) require two differential computations for full-range input/output. Incoherent PTCs, e.g., MRR arrays [20], also require two computations to handle full-range inputs, while non-volatile phase change material (PCM) crossbar arrays [2] need up to four cycles. Reconfiguration speed is another key factor to determine its supported dataflow and operations. Thermo-optic MZI arrays require matrix decomposition and thermal tuning to reconfigure the weights, leading to a delay of \u00b5s to ms and limiting them to weight-stationary dataflows, unsuitable for dynamic self-attention. Dynamic PTCs [4], [17] use high-speed modulators for real-time matrix switching, enabling dynamic tensor products and output-static dataflows. Developing a modeling framework that accurately models complex system performance is challenging.\nPTCs also feature varied topologies beyond conventional crossbars, such as triangular [21] and butterfly meshes [3]. Architectural features like optical broadcast, multi-dimensional sharing [4], analog-domain accumulation, and electrical-optical (E-O) interfaces further complicate system description and accurate modeling."}, {"title": "B. Photonic Accelerator Simulation Tools", "content": "Prior photonic AI hardware is evaluated based on internal closed-source analytical device modeling and behavior-level modeling [3], [15], [16], [28], [29], unaware of the numerical values in actual workloads. CimLoop is a recent analog NN simulator; its photonic version [24] has showcased one architecture Albireo [5]. However, it focuses on architectural parameters (e.g., memory and dataflow), and lacks support for flexible PTC construction with photonics-specific dataflow and parallelism. Its oversimplified device modeling and the complicated interface of the Timeloop-based framework make it challenging for device and circuit researchers to explore hardware optimization efficiently. Furthermore, previous efforts have not interfaced with ONN training tools at the application level, lacking an integrated ONN training and device/circuit-centric system modeling infrastructure, which is needed to model EPIC AI system efficiency and performance."}, {"title": "III. SIMPHONY: EPIC AI SYSTEM MODELING AND SIMULATION FRAMEWORK", "content": "Figure 1 summarizes the simulation flow and key components of our proposed SimPhony framework. It contains a customized electronic-photonic device library SimPhony-DevLib and supports flexible, hierarchical, and parametric modeling of EPIC AI system architecture SimPhony-Arch. Integrated with TorchONN model training toolkit, our simulation system SimPhony-Sim handles photonics-specific dataflow with bandwidth-adaptive memory hierarchy, data-aware power estimation, link budget analysis, and layout-aware chip area analysis."}, {"title": "A. SimPhony-DevLib: Comprehensive and Customizable Electronic-Photonic Device Library", "content": "One key novelty of our simulation framework is the support of a comprehensive and customizable device library SimPhony-DevLib, which lays the foundation for flexible architecture construction and accurate system modeling.\nModeling Granularity: SimPhony-DevLib device modeling is based on experimental data reported, ensuring an accurate representation of device characteristics. Specifically, the photonic device power models are obtained through Lumerical HEAT simulation or experimental measurements that are aware of actual device configuration, ensuring fast and accurate cost modeling.\nModeling Approach: We organize key components into electrical and optical categories, including a variety of high-performance photonic and electronic devices. Comprehensive device information is provided in detail to support accurate simulations of area, power, latency, and link budget. Devices from foundry PDKs can be plugged in. Our device library supports flexible scaling with different technology nodes, port numbers, working conditions, and more. For example, digital-to-analog converters (DACs) in our library support power scaling with customized sampling rates and bit resolutions, enabling power optimization via gating or quantization. On photonic device front, e.g., the electro-optic Mach-Zehnder modulator (MZM) is widely used for high-speed encoding. To achieve precise performance modeling, we collect various properties such as spatial size, bandwidth, insertion loss, modulation efficiency, static power, extinction ratio, testing bitwidth, and more."}, {"title": "B. SimPhony-Arch: Hierarchical, Parametric Heterogeneous EPIC AI System Architecture Builder", "content": "To enable flexible construction of heterogeneous multi-core architectures with diverse PTC designs and dataflows, we introduce SimPhony-Arch, a hierarchical, parametric architecture builder.\nExisting simulators focus on dataflow-centric architectural modeling with fixed PTC designs, often neglecting device/circuit details. This limits their suitability for fundamental device/circuit-level customization, underscoring the need for a universal representation to unify diverse PTC designs.\nTo enable flexible PTC construction, we customize a netlist representation in SimPhony-Arch to describe devices as instances and port connectivity as directed 2-pin nets. Unlike electrical circuit netlists with undirected multi-pin nets, PTCs require directed 2-pin nets to capture the directional optical signal flow.\nKey observations of PTC design patterns inspire us to use modular circuit construction, avoiding manual scripting of large netlists. This allows us to define a minimal building block, denoted as node, e.g., a dot-product unit shown in Fig. 2(a), and build the circuit according to specific scaling rules with a user-defined node connection topology. A weighted directed acyclic graph (DAG) is generated based on the node topology, as shown in Fig. 2(b). The topology and insertion loss-based edge weights are essential in link budget analysis and layout-aware area estimation. This universal, hierarchical netlist interface also enables potential SPICE simulation and physical design as a future extension.\nIn the following, we provide two case studies of how to construct representative PTC architectures in a parametric style.\nCase Study 1: Dynamic Array-style Tensor Cores TEMPO [4], [17]. The first case study demonstrates how to construct an array-style PTC architecture, TeMPO [4], [17], designed for dynamic time-multiplexed tensor products, as shown in Fig. 3(a). We first define the architecture parameters: R tiles, each containing C cores, with $H \\times W$ dot-product nodes per core performing parallel computations. Then, we define the structure of the minimum building block, i.e., the dot-product unit, denoted as a node. A node netlist is used to describe the 6-device circuit topology using directed 2-pin nets to represent the waveguide connections and signal flow, shown in Fig. 2(a). To efficiently span the multi-core architecture without manually detailing every connection, we define scaling rules applied to each node and describe inter-node connections. This approach supports parametric generation of the architecture, enabling automatic analysis of area, power, and link budget. For example, the device area/power estimation engine will trace the netlist to count the number of devices considering hardware sharing. There are RCHW total nodes for parallel dot-product. As the output of C cores in a tile are in-situ accumulated, integrators/ADCs can be shared and thus scaled by CHW. MZM group A encodes one matrix operand and can be broadcast to R tiles. Thus, the input encoders, i.e., DAC A and MZM A, are scaled by RH. These scaling"}, {"title": "C. SimPhony-Sim: EPIC AI System Simulation Flow", "content": "SimPhony-Sim is an end-to-end simulation flow, including NN model conversion and workload extraction to memory simulation and analysis of latency, area, and energy cost.\n1) ONN Model Conversion and Workload Extraction: For digital DNN accelerator simulation, model training and hardware mapping are sufficiently decoupled. In contrast, analog mixed-signal EPIC AI systems require cross-layer co-design, resulting in closely coupled model training, conversion, mapping, and architecture simulation processes. Our SimPhony-Sim system can seamlessly interface with an open-source ONN training library, TorchONN [30], that supports various customized ONN types. A digital DNN will be first converted to its analog optical version with layer-wise conversion, e.g., Conv2d to TeMPOConv2d. The converted model will be trained with device non-ideality, quantization, pruning, and various co-design methodologies to ensure accuracy, robustness, and energy efficiency. The converted ONN model will be parsed by SimPhony-Sim to extract the detailed workload configuration for each layer, including input/weight size, input/weight/output bitwidth, pruning mask, scaling factors, actual weight values, etc. Weight values can have different modes, e.g., matrix values, normalized device transmissions, phase shifts, or even control voltages, which are useful for precise value-aware power modeling. Convolution, linear, and attention layers will be converted to general matrix multiplication (GEMM) representations. Other less computation-intensive layers are offloaded to electrical processors and omitted here for simplicity. With a layer-to-arch mapping configuration, we enable the flexibility to map different layers to different types of sub-architectures based on their compatibility and efficiency considerations, enabling heterogeneous computing paradigms.\n2) Photonics-Specific Dataflow and Latency Analysis: Besides the support for standard dataflow for GEMM, e.g., weight/input/output stationary, here, we emphasize unique photonic-specific mapping and parallelism in SimPhony-Sim.\nMulti-Dimension Parallelism and Hierarchical Accumulation. Beyond the spatial and temporal dimensions of electrical hardware, optical systems have more physical dimensions for parallel computing and hardware sharing, e.g., spectral, polarization, modes, etc. Figure 4 illustrates a partitioned GEMM workload mapped to a multi-core TeMPO architecture with multi-dimensional parallelism and hierarchical accumulation. As shown in the nested loop representation, multiple wavelengths are used for spectral parallel summation, photocurrents from C cores are aggregated for analog-domain parallel summation, spatial parallelism is used for parallel outer product, temporal integration is used for analog sequential summation, and the partial sum is further sequentially accumulated digitally in the local buffer. Based on the mapping and parallelism, we will derive the system execution latency in units of cycles.\nLatency Penalty for Range-Restricted PTCs. As highlighted in Section II and Table I, PTCs are constrained in their numerical range representation due to device modulation features, leading to varying processing times to complete full-range computations. We denote the number of iterations to acquire full-range output as $I$. Especially for PTCs that can only encode positive inputs/weights, four times the execution cost is required to realize full-range output, i.e., $I=4$. SimPhony will automatically analyze the tensor core property based on input/weight/output encoding properties and generate the corresponding dataflow with $I \\times$ latency penalty.\nPTC Reconfiguration Latency Penalty. In weight-stationary PTCs, loading new weights is sometimes bottlenecked by slow device reprogramming rather than memory loading. For instance, thermo-optic (TO) devices have a thermal time constant of 10 \u00b5s, and writing to phase change material (PCM) cells incur a delay of over 100 ns. SimPhony-Sim automatically analyzes reprogramming latency and applies corresponding cycle penalty whenever weight loading causes circuit reconfiguration delays exceeding one clock cycle, e.g., 500 cycles per switch for 100 ns reconfiguration delay at 5 GHz. The total latency of mapping one layer is $T_{tot} = T_{load-input/weight} + T_{write-out} + I(T_{comp} + T_{reconfig})$.\n3) Bandwidth-Adaptive Memory Hierarchy Modeling: One of the key points to enabling photonics advantage in AI computing is sufficient data movement bandwidth and latency-hiding techniques. Note that we focus on memory bandwidth analysis and assume on-chip and cross-chiplet interconnects provide sufficient data transaction bandwidth, especially when optical interconnects are available for multi-Tbps signal fanout/broadcast bandwidth [31]. SimPhony-Arch adopts a four-level memory hierarchy consisting of off-chip High Bandwidth Memory (HBM), Global Buffer (GLB), Local Buffer (LB), and Register File (RF). Each memory level stores operands A, B, and the output in progressively smaller sizes:i.e., the entire model at the HBM level, a single layer at the GLB level, the processing matrix dimensions at the LB level, and data for a single cycle at the RF level. The bandwidth of LB ($BW_{LB}$) and RF ($BW_{RF}$) must accommodate the architecture's single-cycle processing throughput, calculated as $BW_{LB}, BW_{RF} > BytesPerCycle \\times f$, where f is the PTC operating clock frequency. GLB's bandwidth ($BW_{GLB}$) is calculated as $BW_{GLB} = MaxLayerSize \\cdot f/(N_p \\cdot D_p \\cdot M_p)$, where the partitioned matrix dimensions are $N_p, D_p$, and $M_p$. We first profile the maximum bandwidth requirement ($BW$) for all sub-architectures based on the GLB demand per cycle, considering data sharing and broadcast in a specific dataflow. To enable full utilization of the computing cores without memory bottleneck, we adopt a SoTA multi-block SRAM design to meet the bandwidth demand A multi-block GLB can boost its bandwidth proportional to the number of blocks [4], [17]. SimPhony-Sim automatically searchs for the minimum number of required GLB blocks, $# of Blocks = T_{GLB} \\cdot BW/(b_{bus} \\cdot 8)$, where $T_{GLB}$ is the fastest cycle simulated by CACTI [32], and $b_{bus}$ is the buswidth in bits.\n4) Link Budget Analysis: Link budget analysis is important for the photonic systems to profile the critical-path insertion loss and derive the laser source power requirement and optical signal-to-noise ratio (SNR). To obtain the IL on the critical path, we leverage our constructed hierarchical, weighted DAG representation of the architecture in Fig. 3(a), 3(b). From a given source node, i.e., laser, to a destination node, i.e., photodetector (PD), we will use the graph's longest path to get the critical path IL. Given the PD sensitivity $S$, to differentiate bin-bit input levels with a target bit error rate, we can derive the lowest laser power required [3], [4],\n$P_{laser} = \\frac{10^{(S+IL)/10} \\cdot 2^{b_{in}}}{\\eta_{WPE} \\cdot (1 - 10^{-0.1ER})}$,\nwhere $\\eta_{WPE}$ is the laser wall plug efficiency. Non-ideal modulation extinction ratio ER is also considered a power penalty to recover the full modulation range [20].\n5) Data-Dependent Device-Response-Aware Energy Analysis: To accurately model the energy of EPIC AI systems, SimPhony-Sim captures data access energy via CACTI-simulated memory energy and computing energy based on actual operand values and realistic device power modeling. For data access cost, we derive the memory access size ($D_{mem}$) for off-chip HBM, GLB, LB, and RF based on the dataflow analysis and accumulate the energy cost with\nCACTI-simulated access energy per bit $e_{mem}$, i.e., $E_{mem} = \\sum_{mem \\in \\{HBM, GLB, LB, RF\\}} e_{mem} D_{mem}$.\nFor computing cost, SimPhony-Sim supports data-dependent energy analysis with accurate device power modeling, shown in Fig. 5. For analog hardware, the encoded data determines the device configuration, significantly impacting its power. Hence, SimPhony accumulates the energy over cycles based on the values of the real operands. This approach enables accurate energy profiling with fine-grained power gating from ONN pruning [14]. Device power modeling is also critical. Default library power references, like $P_{PS}$ for phase shifters (PSs), often overestimate actual power, while analytical models can be overly ideal. As shown in Fig. 5, SimPhony-Sim supports customized power models using analytical, simulation, or chip testing data for power estimation with different fidelity.\n6) Layout-Aware Chip Area Analysis: The chip area is crucial for fabrication and packaging costs and guiding design optimization. SimPhony-Sim supports fast, realistic layout-aware area estimation. Unlike previous methods that simply sum all device footprints, SimPhony-Sim either takes in a user-defined bounding box or automatically generates a signal-flow-aware floorplan, as shown in Fig. 6. SimPhony sets the placement site width to fit the longest device and attempts to hide other devices beneath it. The floorplan follows the device's topological order from the netlist to adhere to the minimum bending rule in PIC placement, accounting for user-defined device/node spacing. This approach closely matches the real layout area and can be potentially extended to interface with PIC placement tools."}, {"title": "IV. EVALUATION RESULTS", "content": "We validate our simulation results by comparing them with architectural evaluation results reported in previous work. It is important to clarify that, in the absence of system-level experimental demonstrations of multi-core photonic AI chips, we compare our results with prior architecture simulation results. We re-emphasize that individual component data used are backed by experimental measurements, and area estimates are based on real chip layouts. The functionality and accuracy of the ONN model are ensured by the TorchONN training framework, which is beyond the scope of our architecture performance modeling tool.\nGEMM Workloads: To validate the simulation results of SimPhony for GEMM, we compare the simulated area and energy metrics on a (280\u00d728)\u00d7(28\u00d7280) GEMM task against the reference values reported in the original TeMPO paper [17] in Fig. 7 with the following architecture settings. We set the core width and height to 4 and the number of tiles and cores per tile to 2. The area 7(a) and energy 7(b) breakdown from SimPhony match the reference results from TeMPO paper.\nDynamic Transformer Workloads: For Transformers with self-attention operations, we validate SimPhony's area and energy results against Lightening-Transformer [4] (LT), shown in Fig. 8. we simulate BERT-Base [33] with a single (224x224) ImageNet-1K [34] image. We adopt LT's settings: 4 tiles, 2 cores per tile, each core sized 12\u00d712, with 12 wavelengths operating at 5 GHz. Since LT provides only power breakdowns, we report power instead of energy. SimPhony accurately reproduces the chip area when appropriate scaling factors are applied, matching LT's reported values. Minor deviations in photonic core and memory areas stem from differences in core area calculations, memory simulations, and device spacing. Our layout-aware estimator effectively generates realistic core areas. Device power aligns with LT's breakdown except for memory, where deviations result from different technology nodes used in memory simulation (SimPhony uses CACTI-45 nm [32]; LT uses PCACTI-14 nm [35]) and SRAM port/bus differences."}, {"title": "B. SimPhony Use Cases", "content": "To show the capability of SimPhony, we study multiple design examples by sweeping PTC architectural parameters in SimPhony to gain design insights and demonstrate their impacts on system performance and efficiency. All simulations discussed below have a 4\u00d74 core size with 2 tiles and 2 cores per tile.\n1) Multi-Wavelength Parallelism: As discussed in Section III-C2, optical systems allow parallelism beyond spatial and temporal dimensions. However, data encoding in these dimensions requires extra power. Figure 9(a) examines TeMPO [17] under varying wavelength settings on a (280\u00d728)\u00d7(28\u00d7280) GEMM task while scaling MZM and laser sources with the number of wavelengths. Increased wavelengths enhance parallelism, speeding up computation and reducing energy for components that do not scale with wavelength. However, the MZM's energy remains constant as the number of MZMs scale with # of wavelengths.\n2) Bitwidth Representation vs. Energy Consumption: To investigate how the ADC/DAC bit precision impacts the system power, in Fig. 9(b), we sweep the energy for different tensor bitwidth. The results show a clear trend of increasing energy with higher bits. Users can leverage bitwidth simulation results to find the sweet spot for optimal efficiency.\n3) Layout-Aware and Data-Dependent Modeling: The exploration of layout-aware area estimation and data-dependent modeling is shown in Fig. 10. The layout-unaware method underestimates the node area by 72%, while our floorplan estimation enables accurate area estimation compared to the real layout. In data-awareness evaluation, we focus on a weight-static PTC SCATTER [14] where weight values impact the phase shifter's power. By counting PS power based on real weight values, the PS energy decreases from 0.0537 \u00b5J to 0.0215 \u00b5J with an approximate power model. If a rigorous device power model is used, the energy is further reduced to 0.0209 \u00b5J with a substantial 60% reduction.\n4) Heterogeneous Mapping: Lastly, we show SimPhony's capability for heterogeneous architecture modeling with layer-to-sub-architecture mapping in Fig. 11. The convolutional layers of VGG-8 are mapped to SCATTER [14], while the linear layers are mapped to MZI meshes [1], while two sub-architectures share the same on-chip memory hierarchy. This hybrid architecture modeling showcases SimPhony's flexibility in integrating hybrid systems and enabling fine-grained workload-to-hardware mapping. As a future extension, SimPhony can be extended to enable automated design space exploration that combines the strengths of different photonic computing architectures in heterogeneous systems for diverse AI workloads."}, {"title": "V. CONCLUSION", "content": "This paper presents SimPhony, a cross-layer modeling and simulation framework for EPIC AI hardware, enabling photonic-specific design evaluation and fair comparisons across implementations. By emphasizing accurate device/circuit-level modeling with generic and extensible representations, SimPhony bridges hardware and software stacks to support flexible hardware construction, validation, and architecture exploration with multi-dimensional metric trade-offs. We have validated SimPhony's accuracy against prior work and will continue expanding its capabilities to help researchers uncover insights and drive innovation in high-performance, energy-efficient photonic computing systems."}]}