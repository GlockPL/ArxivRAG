{"title": "Anomalous Agreement: How to find the Ideal Number of Anomaly Classes in Correlated, Multivariate Time Series Data", "authors": ["Ferdinand Rewicki", "Joachim Denzler", "Julia Niebling"], "abstract": "Detecting and classifying abnormal system states is critical for condition monitoring, but supervised methods often fall short due to the rarity of anomalies and the lack of labeled data. Therefore, clustering is often used to group similar abnormal behavior. However, evaluating cluster quality without ground truth is challenging, as existing measures such as the Silhouette Score (SSC) only evaluate the cohesion and separation of clusters and ignore possible prior knowledge about the data. To address this challenge, we introduce the Synchronized Anomaly Agreement Index (SAAI), which exploits the synchronicity of anomalies across multivariate time series to assess cluster quality. We demonstrate the effectiveness of SAAI by showing that maximizing SAAI improves accuracy on the task of finding the true number of anomaly classes K in correlated time series by 0.23 compared to SSC and by 0.32 compared to X-Means. We also show that clusters obtained by maximizing SAAI are easier to interpret compared to SSC.", "sections": [{"title": "1 Introduction", "content": "Detecting and classifying abnormal system states is crucial for effective monitoring and control of complex systems. Unfortunately, supervised classification approaches fall short because anomalies are by definition rare, and especially for real-world applications, no or very limited labeled data is available. Therefore, clustering is used to derive groups of similar anomalous behavior from unlabeled data (Sohn et al. 2023; Rewicki et al. 2024a). Assessing the quality of a given solution obtained by applying clustering algorithms such as K-means (MacQueen et al. 1967) to the anomalous subsequences or inferred features is challenging for a number of reasons: (a) no ground truth is available to determine the quality of a solution, (b) the true number of clusters in the data is usually unknown, (c) the solution is highly dependent on the chosen embedding in a feature space (Rewicki et al. 2024a; Raihan 2023). Furthermore, classical unsupervised cluster quality measures such as the Silhouette Score (SSC) (Rousseeuw 1987) evaluate the cohesion within and the separation between clusters but do not incorporate any prior knowledge about the data. To address this challenge in the case of multivariate time series consisting of sufficiently similar signals, we investigate the following research question: How can we exploit the similarity between signals when clustering anomalies found in these variables? The SAAI is based on the principle, that anomalies found simultaneously (i.e., synchronously) in several similar variables within a multivariate time series should belong to the same class. In this work, we deliver evidence on the effectiveness of this measure and show, that maximising SAAI is superior compared to maximizing SSC and the X-Means algorithm (Pelleg, Moore et al. 2000), a variant of K-Means that determines the ideal value for K. Our contributions are:\n1. We derive the SAAI, an internal measure of the quality of anomaly clusters.\n2. We justify the effectiveness of SAAI by showing that SAAI outperforms SSC and X-Means on the task of finding the true number of classes K. We show that the results obtained by using SAAI are highly correlated with those obtained by using the Adjusted Rand Index (ARI) (Hubert and Arabie 1985) and the Fowlkes Mallows Index (FMI) (Fowlkes and Mallows 1983), two external cluster quality measures that require ground truth labels.\n3. We show that the clusterings obtained from maximizing SAAI are easier to interpret compared to SSC.\nThe rest of the paper is organized as follows: We start with discussing related work in Section 2. In Section 3 we derive the SAAI using an illustrative example and introduce the synthetic dataset. In Section 4 we present the experimental setup and results, which we discuss in Section 5. Finally, in Section 6 we conclude and give an outlook on future work."}, {"title": "2 Related Work", "content": "The Silhouette Score, introduced in (Rousseeuw 1987), is the standard measure for evaluating clustering results and quantifies both, cohesion and separation within clusters. It is calculated by averaging the silhouette coefficients $SSCC_j$ for each cluster $C_j$, defined as\n$SSCC (C_j) =\\frac{1}{|C_j|} \\sum_{SEC_j}\\frac{idist(S) \u2013 wdist(S)}{max(wdist(S), idist(S))}$ (1)\nThe measure $wdist(S)$ is the average distance of the object $S \u2208 C_j$ to all other elements within its own cluster $C_j$"}, {"title": "3 Methodology", "content": "In the following section we present the methodology of this study. We start with deriving the SAAI and give an illustrative example. Afterwards we introduce the synthetic dataset, which we use in our experiments to justify the proposed measure."}, {"title": "Synchronized Anomaly Agreement Index (SAAI)", "content": "To evaluate the quality of clustering results, we introduce the Synchronized Anomaly Agreement Index (SAAI). The rationale behind this measure is to use prior knowledge about the signals of a multivariate time series. Assuming sufficiently correlated signals, synchronized, i.e. temporally aligned, anomalies in different channels should be assigned to the same cluster, as they are likely to represent the same anomaly type.\nWe begin with the basic definitions:"}, {"title": "4 Experiments and Results", "content": "We implemented our experiments using Python (version 3.11). For Clustering we used the K-Means implementation in the TSLearn package (Tavenard et al. 2020), which is compatible with subsequences of unequal length. For the same reason, we implemented the X-Means algorithm to use K-Means with an elastic distance measure. We found that we get better results when using Merge-Split-merge (MSM) (Stefan, Athitsos, and Das 2013) compared to using Dynamic Time Warping (DTW) (Vintsyuk 1968; Sakoe and Chiba 1978; Berndt and Clifford 1994) so we compare to the X-Means version with MSM as distance measure. We also noticed a major difference in our results depending on the SSC implementation. We compared that in the TSLearn package to that in scikit-learn (Pedregosa et al. 2011) with the DTW implementation from the aeon-toolkit (Middlehurst et al. 2024) and found that the SSC in scikit-learn yields much better results, even though it is not compatible with unequal length subsequences. Therefore we padded the subsequences with zero to make them equal length. A comparison of these two SSC variants can be found in the"}, {"title": "Synthetic Greenhouse Temperature Data", "content": "To evaluate SAAI on finding the ideal number of classes K within multivariate time series containing different types of anomalies, we perform the following experiments: We generate a large number of multivariate time series of the synthetic ICS temperature measurements and vary different parameters, namely the number (K) and type of injected anomaly classes, the dimension (D) of the multivariate time series, and the ratio of synchronized to unsynchronized anomalies rsync. We then cluster the anomalous sequences using K-Means clustering with (DTW) as the distance measure. To remove high-frequent noise from the sequences, we apply moving average smoothing with a window size of 5. For each parameter we change, we generate 50 multivariate time series and cluster the anomalous subsequences of each time series with 2 \u2264 k < 20, where k is the number of clusters for K-means. We measure how often the correct value K was found by maximizing the internal metrics SAAI and SSC. In addition, we compute the external metrics SAAI and SAAI and use them to find the true number of classes, again by maximizing their respective values. It is fair to complain that with access to the ground truth labels, finding the true number of classes K by maximizing an external metric is pointless. However, we do this for the sake of analyzing the correlation of the internal metrics SSC and SAAI with the external metrics ARI and FMI. As another competitor, we use the X-Means Algorithm (Pelleg, Moore et al. 2000) to determine the ideal value for K."}, {"title": "Increasing K", "content": "In the first experiment we fix D = 2, choose rsync \u2208 [0.5,1] and increase the number of classes from K = 2 to K = 6. We run the experiment 50 times for each value of K and select a new value for rsync as well as K new classes on each run uniformly at random. Figure 4a shows the accuracy in finding the true number of classes for increase K. Except for K = 2, SAAI shows superior performance compared to SSC. For K > 3, SAAI is almost as good as using the external metrics ARI and FMI. X-Means shows the worst results among the compared methods. All methods show decreasing accuracy as K increases."}, {"title": "Increasing D", "content": "Now, we increase the dimension of the multivariate time series from D = 2 to D = 10 while fixing K = 4 and choosing rsync \u2208 [0.5, 1]. We run the experiment 50 times for each value for d and select a new value for rsync as well as new K = 4 classes on each run uniformly at random. Figure 4b shows the accuracy in finding the true number of classes K for increasing dimension D. Again, SAAI shows superior performance in finding the true value K compared to SSC and X-Means. Compared to ARI and FMI, SAAI is almost on par with the external metrics for D < 6 and even slightly better for D > 6. Despite the minor variability in accuracies within the results for one method, we also see that the accuracy of finding the true value K is almost independent from the dimension D of the multivariate time series."}, {"title": "Decreasing rsync", "content": "In the third experiment, we fix K = 4 and D = 2 and decrease rsync from rsync = 1 to rsync = 0 in steps of 0.1. We run the experiment 50 times for each value of rsync and select K new classes on each run uniformly at random. Figure 4c shows the accuracy in finding the true number of classes K. As in the previous experiments, SAAI proves to be superior to SSC and X-Means in determining the true value K. Compared to ARI and FMI, the accuracy for SAAI is on par for 1 rsync < 0.2. For 0.2 \u2264 1 - rsync \u2264 0.8, the accuracy for SAAI shows an decreasing trend as expected, but is still higher than for SSC and X-Means. For 1 rsync > 0.8 the accuracy for SAAI falls below that of SSC and X-means The correlation of SAAI and rsync is expected, since rsync determines the proportion of synchronized anomalies in the time series."}, {"title": "Lagged Variables", "content": "In the experiments described above, the time series variables were all highly correlated. In Section 3 we derived SAAI for \"temporally aligned anomalies in similar measurements\". To get an idea of \"how similar\" the signals of the multivariate time series need to be, we perform the following experiment: We fix D = 2, select rsync \u2208 [0.5,1] and K = 4 new classes uniformly at random on every run. We modify the correlation between the variables of the 2D time series by increasing the lag l between the first and second dimensions in steps of 60 minutes, from l = -720 (-0.5 day) to l = 720 (+0.5 day). Again, we measure the accuracy of finding the true value K by maximizing SAAI, SSC, ARI, and FMI and by applying X-Means. The results are shown in Figure 5. The black dashed line shows the Pearson correlation coefficient p for the two variables of the time series. The baseline, based on random guessing, for finding the correct value of K for 2 \u2264 k < 20 is p = 1 and shown as a black dotted line.\nFor -180 < l < 180, the shaded gray in Figure 5, SAAI achieves superior results than SSC and is again almost on par with ARI and FMI. For X-Means, the accuracy of 0.14 at l = 180 is slightly higher than 0.12 for SAAI. The area of -180 < l < 180 corresponds to a correlation of p > 0.43 and marks the sweet spot for applying SAAI. For l > 360 maximizing SSC shows better or equal results compared to all other methods."}, {"title": "Summary", "content": "The Multi Comparison Matrix (MCM) (Ismail-Fawaz et al. 2023) shown in Figure 6 summarizes the results presented before. It shows the Mean Accuracy for the task"}, {"title": "Real Greenhouse Temperature Data", "content": "In this experiment, we demonstrate the effectiveness of SAAI when working with real, unlabeled data. For this purpose, we use the ICS temperature measurements included in the edeniss2020 dataset (Rewicki et al. 2024b). This time series consists of 38 temperature measurements from the EDEN ISS research greenhouse. We follow the approach in (Rewicki et al. 2024a) and find anomalous sub-"}, {"title": "Ablation Study", "content": "In our ablation study, we evaluate the contribution of the penalty terms \u03bb and \u03be in Equation (8). We perform the same experiments as described in Section 4. The results are summarized in Figure 9. $SAAI$ refers to the $SAAI$ given in Definition 6, while $SAAIp1$ and $SAAIp2$ refer to the $SAAI$ with only the first and second penalty terms, respectively:\n$SAAIp1 := \u03bb\\frac{A_S}{A_{s}}+(1-\u03bb)\\frac{K-1}{K},$\n$SAAIP2 := \u03bb\\frac{A_S}{A_{s}}+(1-\u03bb)\\frac{K-n1}{K}$ (9)\nwith $\u03bb \u2208 [0, 1]$.\nWhile the effect of penalizing pseudo-clusters through the second penalty term \u03be is smaller compared to penalizing small values for K, both terms add significant improvement on the overall accuracy."}, {"title": "5 Discussion", "content": "Through our experiments in Section 4, we have shown that maximizing SAAI outperforms maximizing SSC, as proposed by (Shahapure and Nicholas 2020; Zhou and Gao 2014), as well as X-Means, proposed by (Pelleg, Moore et al. 2000) on the task of finding the true number of anomaly classes K in multivariate time series consisting of sufficiently similar measurements. Maximizing SAAI improves mean accuracy significantly over SAAI by 0.09 and over X-Means by alomst 0.17. The difference in mean accuracy of SAAI and FMI however is not statistically significant. The relatively low scores across all methods are subject to all runs from the Lagged Variables experiment being included in the evaluation. SAAI also shows a high to very high correlation with those results obtained by maximizing ARI and FMI. Our results are consistent with those of (Raihan 2023) that SSC is not suitable for finding the correct value for K by maximizing SSC when working with raw time series. Our findings contradict the proposal of (Shahapure and Nicholas 2020) and (Zhou and Gao 2014), however they did not evaluate their approaches on time series data. The Lagged Variables experiments give an idea of how the rather vague notion of similar-enough might be quantized. For correlation coefficients p > 0.43, maximizing SAAI gives an higher accuracy as maximizing SSC. However, for l 180, which"}, {"title": "6 Conclusions", "content": "In this paper, we propose SAAI, an unsupervised measure of anomaly cluster quality that incorporates prior knowledge about the multivariate time series by exploiting the similarity between individual signals. We demonstrate the effectiveness of SAAI by showing that maximizing SAAI outperforms maximizing SSC and X-Means on the task of finding the true number of anomaly classes K. Also, SAAI shows high correlation with results obtained from maximizing the external measures ARI and FMI. When applied to real, unlabeled data, the clustering result found by maximizing SAAI is easier to interpret compared to SSC. Our ablation study shows that all parts of the SAAI formula are necessary. However, SAAI has two major shortcomings: (1) it is only applicable to univariate anomalies found in multivariate time series consisting of reasonably similar signals, and (2) SAAI does not consider anomalies found in only a single variable (i.e., unaligned). Both shortcomings will be the subject of future research, as addressing (1) would allow extension to multivariate anomalies, and including unaligned anomalies by addressing (2) will expand the range of valid use cases."}, {"title": "A Appendix", "content": "SAAI Algorithm & Complexity Analysis\nThe algorithm for calculating the SAAI is shown in algorithm 1. To determine the set of synchronized anomalies As, we have to compare all anomalous subsequences in different variables S(i) , S(i) that overlap in time, i.e. ai,biaj,bj\ni < j and bj < a\u017c or bi > aj. A sweep-line algorithm for calculating the SAAI is given in Algorithm 1. For each anomalous sequence, we create two events in lines 4-8 with a complexity of O(n), where n = |A|. The sorting of the 2n events in line 9 has a complexity of O(nlogn). The events are sorted by time and in case of ties by event, so that \"END\" events are sorted before \"START\" events. Each interval is added to (line 21) and removed from (line 23) the active intervals S once, resulting in O(n) insertions and deletions from S. Before an interval is added, it is compared to all active intervals. Since all intervals can be active at the same time, the maximum number of comparisons is (2) in the worst case, which is in O(n\u00b2). However, this worst case occurs only if n is close to the dimension of the time series D and all anomalous subsequences are synchronized. Typically, we have D < n when clustering anomalous subsequences in multivariate time series. This gives a complexity of O(nlogn) for the average case where D \u226an and overlaps are sparse, and O(n\u00b2) for the worst case where D \u2248 n and many overlapping intervals."}, {"title": "Selecting \u03bb", "content": "The parameter \u03bb in Equation (8) determines the weight of the main term over the regularizing term. A value of \u03bb = 1 would evaluate only the main term and ignore the number of clusters and pseudo-clusters in the solution found. On the contrary, a value of \u03bb 0 would evaluate only the number of"}, {"title": "Silhouette Score Implementations", "content": "While running our experiments on synthetic data, we found that the results for the Silhouette Score depend strongly on the implementation used to compute it. As shown in Figure 12, the implementation in the tslearn package (Tavenard et al. 2020) gives significantly worse results than the implementation in scikit-learn. This is surprising since tslearn is a specialized package for time series analysis and supports the calculation of the Silhouette score for sequences of unequal length. However, for the sake of a fair comparison, we"}, {"title": "SAAI and SSC results for edeniss2020 (ICS) dataset", "content": "For the experiment on real ICS data from the EDEN ISS research greenhouse, we clustered the anomalous subsequences found by the MDI and DAMP algorithms with increasing number of clusters 1 < K < 20. The results of SAAI and SSC are visualized in Figure 13. Both SSC variants have their highest score at K = 3, while SAAI has its maximum at K = 11, which seems to be a more realistic value in this case."}]}