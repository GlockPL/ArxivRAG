{"title": "RADON-NIKOD\u00ddM DERIVATIVE: RE-IMAGINING ANOMALY\nDETECTION FROM A MEASURE THEORETIC PERSPECTIVE", "authors": ["Shlok Mehendale", "Aditya Challa", "Rahul Yedida", "Sravan Danda", "Santonu Sarkar", "Snehanshu Saha"], "abstract": "Which principle underpins the design of an effective anomaly detection loss function? The answer\nlies in the concept of Radon\u2013Nikod\u00fdm theorem, a fundamental concept in measure theory. The key\ninsight is \u2013 Multiplying the vanilla loss function with the Radon\u2013Nikod\u00fdm derivative improves the\nperformance across the board. We refer to this as RN-Loss.\nThis is established using PAC learnability of anomaly detection. We further show that the Radon-\nNikod\u00fdm derivative offers important insights into unsupervised clustering based anomaly detections\nas well.\nWe evaluate our algorithm on 96 datasets, including univariate and multivariate data from diverse\ndomains, including healthcare, cybersecurity, and finance. We show that RN-Derivative algorithms\noutperform state-of-the-art methods on 68% of Multivariate datasets (based on F-1 scores) and also\nachieves peak F1-scores on 72% of time series (Univariate) datasets.", "sections": [{"title": "1 Introduction", "content": "Anomaly detection, the process of identifying rare yet significant deviations from normal patterns, has become es-\nsential in various domains such as finance, healthcare, and cybersecurity, where undetected anomalies can lead to\ncatastrophic consequences. Researchers have explored supervised and unsupervised approaches for anomaly detec-\ntion. Although unsupervised approaches work well when labeled anomalies are scarce and often not found in training\ndata, shallow unsupervised anomaly detection methods like One-Class SVM Manevitz and Yousef [2002], Isolation\nForest Liu et al. [2008] are limited in their scalability to large datasets Ruff et al. [2020]. Tree-based algorithms such\nas Isolation Forest, Random Cut Forest Guha et al. [2016], d-BTAI Sarkar et al. [2021b], and MGBTAI Sarkar et al.\n[2023], report a comparatively better performance. Supervised learning needs to use labeled data and has difficulty\nidentifying unseen anomaliesKawachi et al. [2018],Chandola et al. [2009]; it also offers several advantages that make\nthem a favorable choice. For example, supervised algorithms can leverage domain knowledge to recognize complex\npatterns indicative of anomalies by training on labeled examples of both normal and anomalous instances. This results\nin improved accuracy and precision compared to unsupervised methods, which rely on more generalized patterns and\nassumptions G\u00f6rnitz et al. [2012], Ruff et al. [2020]. Supervised algorithms suffer from the class imbalance issue\nbecause loss functions used in these algorithms assume equally distributed datasets across multiple classes.\nMotivation of the present work: Anomaly detection has been a long-standing focus of research, addressing diverse\napplications such as fraud detection, network security, and medical diagnostics Chandola et al. [2009], Hilal et al."}, {"title": "Contributions/Insights", "content": "The key contribution of this paper is the rethinking of anomaly detection from first principles (PAC learnability) and the\nintroduction of a weighted loss function based on the Radon-Nikod\u00fdm derivative (termed \u201cRN-Loss\u201d in this paper),\ntailored for anomaly detection.\nTheoretical Insights: In Section 2 we introduce the problem of (PAC-)learnability of anomaly detection problem.\nIn Section 3 we show that anomaly detection is indeed learnable under some mild conditions (see informal summary)\nof (PAC-)learnability. The main insight from this derivation is \u2013 The generic loss function for learning anomaly detec-\ntion is the product of the original loss function and the Radon-Nikod\u00fdm derivative of the two respective distributions.\nAn operator (Radon-Nikod\u00fdm derivative) is able to calibrate the two different measures i.e. distributions. This en-\nables identifying anomalies in the data distribution. Further we also show that, this divergence in distributions can\nbe quantified using the anomaly contamination ratio. This interpretation and formal proof also turned out to be per-\nformant when tested on diverse datasets. Specifically, if one has samples and used the empirical estimate, then the\nideal (generic) loss function tailored for anomaly detection becomes a (appropriately) weighted loss. In other cases\n(unsupervised), it reduces to the ratio of kernel density estimates.\nEmpirical Insights: RN-Loss maintains computational efficiency by building on base loss functions like Binary\nCross-Entropy, enabling integration with architectures such as Feedforward ReLU and LSTM models. Further unsu-\npervised methods like dBTAI Sarkar et al. [2021b] can benefit from an adapted version of RN-Loss thus making it\ncapable of identifying anomalies even when the model is trained solely on normal data. This ability to detect previously\nunseen anomalies demonstrates its robustness and effectiveness in scenarios where anomalous data is not present dur-\ning training. It supports operational simplicity with automated hyperparameter tuning via AUC ROC, removing the\nneed for manual thresholding (Appendix F, Table 15).\nThe loss function demonstrates flexibility, fitting varied data distributions such as Weibull and Log-normal without\nrequiring structural changes (Appendix F, Table 13). These properties make RN-Loss a robust and adaptable ap-\nproach for anomaly detection, combining improved metrics, efficiency, and versatility, making it suitable for diverse\napplications in real-world scenarios.\nConsequences: The RN-Loss function introduces improvements in anomaly detection, achieving enhanced perfor-\nmance and broad adaptability. It outperforms prior SoTA methods, improving F-1 Scores in 68% and Recall in 46%\nof the multivariate datasets, with similar trends in time-series (Univariate) data (F-1: 72%, Recall: 83%). These results\ndemonstrate its consistent performance across diverse benchmarks.\nOur experiments demonstrate that RN-Loss significantly improves the performance of unsupervised anomaly detec-\ntion methods, specifically vanilla implementation of CBLOF and ECBLOF Sarkar et al. [2021a], when combined with\nclustering algorithms like K-Means Gao [2009] and dBTAI Sarkar et al. [2021b]. The enhanced KMeans-CBLOF\nalgorithm achieved superior performance on 93% of univariate datasets (27 out of 29) and 48% of multivariate datasets\n(32 out of 67) in comparison to the original KMeans-CBLOF algorithm. While dBTAI previously achieved state-of-\nthe-art results, its metrics\u2014particularly precision\u2014were inflated. RN-Loss helped normalize these metrics and the\nmodified dBTAI further maintained or improved its overall performance across 59 multivariate datasets and demon-\nstrated increased recall values across nearly all univariate datasets. Detailed experimental results are presented in\nTable 41, Table 42, Table 43 and Table 44 in the Appendix F. For the mathematical foundations of adapting CBLOF\nand ECBLOF to RN-Loss, please refer to Appendices Appendix C and Appendix D, respectively."}, {"title": "2 Problem Setup and Notation", "content": "Let X C Rd denote the feature space and Y \u2208 {1, . . ., K} denote the label space. The base distribution is denoted by\na joint distribution DXBYB over X \u00d7 Y, where XB \u2208 X and YB \u2208 Y. The anomaly distribution is denoted by DXAYA\nover the same X \u00d7 Y and XA \u2208 X. However, YA does not belong to Y for simplicity we assume YA = K + 1. We\nalso often use the mapping & which is a function which maps the labels {1, . . ., K} \u2192 0 and label {K + 1} \u2192 1.\nWe assume that the distribution we sample from is a mixture of the base-distribution and the anomaly distribution, i.e\n$\\mathcal{D}_{XY} = (1 \u2212 \\alpha)\\mathcal{D}_{X_B Y_B} + \\alpha \\mathcal{D}_{X_A Y_A}$ where $\\alpha \u2208 [0,1)$ is unknown. \u03b1 is referred to as anomaly contamination ratio.\nWe sometimes omit the \u03b1 when we imply that \u03b1 can be any unknown value.\nAnomaly detection can either be supervised and unsupervised. For completeness, we state both these problems below.\nSupervised Anomaly Detection: Given a sample of points S := {(x\u00b2, y\u00b2)} drawn i.i.d from Dxy, the aim is to\nobtain a classifier f such that, for any sample \u00e6 from marginal Dx : (i) if \u00e6 is sampled from DXA then identify it as\nanomaly and (ii) if \u00e6 is sampled from DXB identify it as non-anomaly. Note that we have at our disposal the labels\n$\\phi \\circ Y \\in \\{0, 1\\}$, making this a binary classification problem.\nUnsupervised Anomaly Detection: Given a sample of points S := {(x\u00b2, y\u00b2)} drawn i.i.d from DXBYB, the aim is\nto obtain a classifier f such that, for any sample \u00e6 from marginal Dx : (i) if \u00e6 is sampled from Dx then identify it\nas anomaly and (ii) if x is sampled from DXB identify it as non-anomaly.\nRemark: Supervised and unsupervised cases differ by the sampling distribution Dxy vs DXBYB and whether we\nhave \"some\" labels to identify the classifier f."}, {"title": "Radon-Nikod\u00fdm Derivative: Re-imagining Anomaly Detection from a Measure Theoretic Perspective", "content": "Space of Distributions: Clearly, if there is no restriction on the set of possible distributions Dxy, no-free-lunch\ntheorem Wolpert [1996] suggests that anomaly detection is impossible. So, we restrict the set of distributions to a set\n$\\$\\mathcal{D}_{XY}.\\$\"\nHypothesis Space, Loss function and Risks : Let H \u2282 {h : X \u2192 {0,1}} denote the set of functions from which\nwe choose our classifier f. Any specific h \u2208 H is referred to as hypothesis function or simply function if the context\nis clear. We consider 0-1 loss function \u2013 l : Y \u00d7 \u0423 \u2192 {0,1} where $l(y_1, y_2) = \\begin{cases}\n  0 & \\text{if } y_1 = y_2 \\\\\n  1 & \\text{otherwise}.\n\\end{cases}\\$\n\nRD(h) = EDXYy [l(h(x), y)]\n$\\$\\mathcal{D} = (1 \u2212 \\alpha)\\mathcal{D}_{X_B Y_B} + \\alpha\\mathcal{D}_{X_A Y_A}\\$ \nRa(h) = (1 - a) RDXBYB (h) + QRDXAYA (h)\n(i) an algorithm A : U=1 (X \u00d7 Y) \u2192 H, (ii) a decreasing sequence e(n) \u2192 0, and (iii) for all Dxy \u2208 DXY\nES~DY [RDXY (A(S)) - inf RDXy (h)] \u2264 e(n)\nhEH\nSpecifically, neural networks are PAC learnable.\nNote that we are interested in the anomaly detection. Which means, while learning may be done with specific a, the\ntest distribution is always fixed at a = 0.5. Formally, we sample from Dxy, but the risk we are interested is when\nbase-distribution and anomalies are equally possible, i.e a = 0.5. Thus, we need to show that\n0.5\n0.5\nES~D [RDXY (A(S)) inf Roxy (h)] < \u03b5(\u03b7)\nhEH\nWhere e(n) \u2192 0 as n \u2192 \u221e."}, {"title": "3 RNLoss : Derivation from first principles", "content": "The aim of this article is to obtain the algorithm A for solving the anomaly detection problem. We achieve this in 2\nstages - (i) Assume that a is known and design a loss using the Radon-Nikod\u00fdm(RN) derivative, (ii) Design the loss\nfunction which approximates a.\nWe begin by recalling the established Radon-Nikod\u00fdm theorem from measure theory.\nTheorem 3.1 (Radon\u2013Nikod\u00fdm Konstantopoulos et al. [2011]). Let (\u03a9, A) be a measurable space with A as the \u03c3\nalgebra and \u00b5, v denote two o-finite measures such that v << \u03bc (v is absolutely continuous with respect to \u03bc). Then,\nthere exists a function f such that,\n$\\nu(A) = \\int_A f d\\mu$ (or) dv = fd\u00b5\nfor some b on the support of \u00b5.\nexists a \u0394\u03bc,\u03bd such that,\n$\\frac{1}{\\Delta_{\\mu,\\nu}} < \\frac{R_{\\mathcal{D}_{XY}}(h)}{R_{\\mathcal{D}_{XY}}(h)} < \\Delta_{\\mu,\\nu}$ for all h \u2208 H, there"}, {"title": "4 Experiments - Anomaly Detection", "content": "Datasets: A total of 96 datasets (29 Univariate and 67 Multivariate) with anomalous instances in varying degrees\nwere considered for evaluation from AD-Bench, SWaT, etc., with the notable inclusion of ESA-ADB, a recently pub-\nlished time series data set (Appendix F, Table 16). Our datasets cover multiple domains such as finance, healthcare,\ne-commerce, industrial systems, telecommunications, astronautics, computer vision, forensics, botany, sociology, lin-\nguistics, etc. The data volume ranges from 80 to 61,936, and the anomaly percentages range from 0.03% to 43.51%.\nWe further split the datasets over three anomaly contamination ranges: i) less than 1% (critically imbalanced datasets),\nii) between 1% to 10%, and iii) greater than 10% (moderately imbalanced datasets).\n(i) Anomaly < 1%: In this, we primarily focus on detecting extreme outliers or rare events as they deviate\nsignificantly from the normal, also being highly indicative of critical issues such as fraud or system failures.\nThis set consists of 22 univariate and 4 multivariate datasets from different distributions such as Weibull and\nlog-normal other than Gaussian.(Appendix F, Table 13)\n(ii) Anomaly between 1 10%: This set also indicates outliers that are less frequent than the normal data\nbut occur often enough to be noticeable. It consists of 47 datasets (40 multivariate and 7 univariate) with\ndistributions such as Exponential, Weibull, Gamma, and Log-normal. Extensive research has been performed\non these datasets over the past few years and is simultaneously documented in the form of surveys compiling\nall the methodologies presented to date, Samariya and Thakkar [2023], Cao et al. [2024].\n(iii) Anomaly > 10%: These datasets comprise clusters of sample points that lie away from the general distri-\nbution and are termed outliers, such as in some cases of collective anomalies or contextual anomaly groups.\nThis set has 16 multivariate datasets, including time series, with various domains covered in the Appendix.\nA separate subsection of analysis has been done targeting Time Series anomaly detection in particular, where we use\n29 univariate time-dependent and 7 multivariate time-dependent datasets, along with the newly proposed ESA-ADB\ndataset Kotowski et al. [2024] along with six other SWaT datasets Wang et al. [2019] and a BATADAL dataset.\nNetwork Architecture: We used two architecture in our study. First, RN-Net is a ReLU feedforward network\nwith RN-Loss, comprising 64 hidden units in a binary classification setting. We train for 50 epochs using the Adam\noptimizer. Additionally, we use batch normalization Ioffe and Szegedy [2015], dropout Srivastava et al. [2014], and\nearly stopping with a threshold of 10 epochs. We reduce our learning rate by half every 5 epochs until it reaches 10-6.\nParallel to this, we integrated L2 regularisation with RN-Net and noticed a further step-up in performance across\ndatasets (Results are in Appendix F, Tables 37 and 38).\nSimilarly, to demonstrate the flexibility and adaptability of RN-Loss, we create RN-LSTM: A LSTM with 32 hidden\nunits coupled with the RN-Loss function.\nEvaluation: We adopt a modified approach to the traditional 70-30 data splitting technique. We allocate 70% of the\nnormal data for training, while only 15% of the anomalous data is used for training. The remaining data, comprising\n30% of the normal data and 85% of the anomalous data, is reserved for testing. This strategy is designed to evaluate\nthe robustness of the model, particularly given that anomalies typically constitute less than 10% of the dataset. By\nusing only 15% of these rare anomalies for training, the exposure to anomalous content is zero or minimal, encasing\nboth scenarios of the model being trained on a completely normal dataset or with some anomaly contamination. The\nresults from both setups are identical, which further eliminates the need for training on anomalous data, as in most\nsupervised learning algorithms for optimal performance, like DevNet Gan et al. [2015], DAGMM Zong et al. [2018],\netc."}, {"title": "5 Conclusion", "content": "Anomaly detection is a fundamental problem across multiple domains. Formally, an anomaly is any sample that does\nnot belong to the underlying data distribution. However, identifying anomalies is challenging, particularly when the\ndata distribution exhibits high variability. Despite its importance, the theoretical foundations of anomaly detection\nremain underexplored.\nWhat is the right principle to design loss function for anomaly detection? We show that the right principle should\ncorrect the discrepancies between the distributions. This is easily achieved by weighing the generic loss function with\nRadon-Nikod\u00fdm derivative. We prove this by establishing the PAC learnability of anomaly detection. We refer to this\napproach as RN-Loss. Notably, we show that (supervised) weight-adjusted loss functions and unsupervised Cluster-\nBased Local Outlier Factor (CBLOF) naturally emerge as performant and conceptual instances of this correction\nmechanism.\nEmpirical evaluations across 96 datasets demonstrate that weighting a standard loss function by the Radon-Nikod\u00fdm\nderivative enhances performance, making RN-Loss a robust, efficient, and adaptable solution that outperforms state-"}]}