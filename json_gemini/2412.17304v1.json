{"title": "On the Feasibility of Vision-Language Models for Time-Series Classification", "authors": ["Vinay Prithyani", "Mohsin Mohammed", "Richa Gadgil", "Ricardo Buitrago", "Vinija Jain", "Aman Chadha"], "abstract": "We build upon time-series classification by leveraging the capabilities of Vision Language Models (VLMs). We find that VLMs produce competitive results after two or less epochs of fine-tuning. We develop a novel approach that incorporates graphical data representations as images in conjunction with numerical data. This approach is rooted in the hypothesis that graphical representations can provide additional contextual information that numerical data alone may not capture. Additionally, providing a graphical representation can circumvent issues such as limited context length faced by LLMs. To further advance this work, we implemented a scalable end-to-end pipeline for training on different scenarios, allowing us to isolate the most effective strategies for transferring learning capabilities from LLMs to Time Series Classification (TSC) tasks. Our approach works with univariate and multivariate time-series data. In addition, we conduct extensive and practical experiments to show how this approach works for time-series classification and generative labels. Code and datasets used in this study are available at GitHub\u00b9.", "sections": [{"title": "1 Introduction", "content": "Time Series Classification (TSC) is an important and challenging problem in data mining, with a variety of applications. Over the years, hundreds of time-series algorithms have been proposed, with varying success.\nRecently, Large Language Models (LLMs) have gained prominence due to their abilities to capture patterns in sequential data, particularly in human language. Additionally, the modalities of vision and language have converged, resulting in the emergence of VLMs, or Vision-Language Models. One such VLM is LLAVA, which combines a vision encoder and Vicuna, an open-source LLM, for general-purpose visual and language understanding.\nAt the same time, LLMs have been used mainly for time-series forecasting tasks. Successful papers have framed time series forecasting as next token prediction in text. We seek to understand how LLMs can also be adept at classifying time-series data due to sequential pattern mining. Additionally, VLMs have shown great promise on general Visual-Question Answering (VQA) tasks. By providing a graphical representation of time-series data, we aim to make LLMs more robust.\nAdditionally, our method requires an out-of-box VLM model to be fine-tuned for one to two epochs. This simple method provides competitive results to many deep learning frameworks, which may require longer training times. We explore how:\n1. Fine-tuning a VLM on time-series images and language for two epochs or less can produce competitive results.\n2. VLMs excel on temporal time-series data (such as sensor data) over spatial time-series data.\n3. VLMs can struggle with generalization, especially for multi-class and clustered labeltime-series."}, {"title": "2 Background", "content": "Time Series Classification (TSC) TSC consist in classifying a time series into one of several possible categories. This problem arises in many areas such as medical devices, motion sensors or audio processing (Middlehurst et al., 2023). The largest public dataset for such problem is the UCR Time Series Archive (Dau et al., 2018) Deep Learning models have been developed for TSC, such as InceptionTime (Fawaz et al., 2019), which is an ensemble of Convolutional Neural Networks (CNN) based architectures, or H-Inception (Ismail-Fawaz et al., 2022), an improvement using hand-crafted filters. Other non deep learning techniques have proven to be very effective, HIVE-COTE (Middlehurst et al., 2021), which is an ensemble of TSC models.\nFoundation Models Training data is limited compared to the size of today's models (Fawaz et al., 2018), which makes overfitting a common problem. As a result, some pre-trained models have been used to tackle Time Series problems. The first layers of H-Inception has been pre-trained by using time series from different datasets and classifying the dataset to which the time series belong (Ismail-Fawaz et al., 2023), and then finetuned to each dataset individually. In the domain of Time Series Forecasting, LLMs have been shown to posses zero shot forecasting capabilities (Gruver et al., 2024). However, a natural limitation of LLMs is the limited context length and the high computational costs for large sequences, which is a problem especially in Multivariate Time Series.\nVision Language Models Several VLM have been pretrained to perform a task given a visual and text prompt, such as LLaVA (Liu et al., 2023) and (Bai et al., 2024). These models have been trained to have general Visual Question Answering capabilities, but can be finetuned to specific datasets."}, {"title": "3 Methods", "content": "Our pipeline is structured into five key stages, each addressing a critical aspect of the research process: scenario generation, experiment launcher, data generation, model training, and evaluation. The following subsections describe each stage in detail:"}, {"title": "3.1.1 Scenario Generation", "content": "We define a scenario to be a set of hyper-parameters, useful to test a specific hypothesis. This set includes settings for context length, downsampling strategy, image representation type and number of epochs for training. For example in Figure 1, Scenariol might represent a scenario with context length 2048 and an adaptive downsampling strategy. In the scenario generation phase, we generate all possible experimental scenarios to comprehensively test the hypothesis under different conditions. Our aim is to ensure a broad exploration of the experimental space by accounting for various potential influences on model performance. By systematically generating all possible scenarios, we mitigate the risk of missing critical interactions between parameters and ensure that our results are generalizable. This approach also facilitates reproducibility by documenting the full set of conditions tested."}, {"title": "3.1.2 Experiment Launcher", "content": "Primary responsibility of the experiment launcher is automating the execution of the pipeline across the set of defined datasets and different experimental scenarios. This module acts as the orchestrator, sequentially launching experiments based on the generated scenarios. Each experiment is logged, ensuring that all relevant metadata (e.g., dataset used, model configuration, hyperparameters) are captured. This automation significantly reduces human intervention, allowing for high-throughput experimentation and consistent application of the experimental protocol across different trials. It ensures that each experiment is conducted in a controlled, systematic manner, minimizing variability that could otherwise skew results."}, {"title": "3.1.3 Data Generation", "content": "During this phase, the pipeline generates the appropriate data splits-train, validation, and test-based on the chosen dataset and the scenario parameters. We employ a 80/10/10 split of the dataset, allocating 80% of the data for training, 10% of the data for validation and the remainder 10% for testing. This balanced split ensures that there is sufficient data for model optimization, while reserving an adequate portion for evaluation and generalization assessment on unseen data. The data generated can be one of two modes: BASELINE"}, {"title": "3.1.4 Training", "content": "LLaVA's groundbreaking architecture (Figure 2) combines the capabilities of pre-trained language models like Vicuna or LLaMA with visual encoders like CLIP. This fusion is achieved by converting the visual features extracted from images into a format compatible with the language model's embeddings. To facilitate this alignment, a trainable projection matrix is utilized, generating a sequence of visual token embeddings that can be seamlessly integrated into the language model. This stage performs fine-tuning of the LLaVA model (Language and Vision Assistant) using the generated training data. The model is trained based on the scenario-specific parameters, which may include adjustments to number of epochs, context length."}, {"title": "3.1.5 Evaluation", "content": "The final stage evaluates the fine-tuned model on unseen test data, specifically focusing on one-shot accuracy. One-shot accuracy measures the model's ability to generalize from minimal training examples, making it an essential metric in few-shot learning tasks. The results from the evaluation stage are recorded and analyzed, providing insights into the model's performance under different conditions. The evaluation process offers a rigorous assessment of the model's generalization capabilities. By focusing on one-shot accuracy, we aim to measure the model's effectiveness in real-world applications where access to large amounts of labeled data is often limited. The results from this stage directly inform conclusions about the model's suitability for deployment in similar environments."}, {"title": "3.2 Graphical and Text-Based Representations of Time-Series Data", "content": "For LLMs, we construct the prompt in a customizable fashion based on the following:\n1. Univariate or Multivariate signal\n2. BaseLine or With Stats\nAs can be seen in Figures 2-4, the Baseline prompt simply consists of the time series signal. The With Stats prompt further enhances the prompt with statistics calculated from the time series signal. For multi-dimensional time series data, we enumerate the signal and statistics across each dimension. The integration of graphical representations in conjunction with text-based data is a cornerstone of our approach to enhancing the capabilities of Vision-Language Models (VLMs) in interpreting time-series data. For graph data, our primary focus is on generating clean, uncluttered line plots that effectively convey the time-series data without extraneous elements. This decision is based on the understanding that additional features in a graph, such as titles, axis labels, and legends, while informative in a human-readable context, can introduce unnecessary complexity and noise when processed by a VLM. These elements could potentially distract the model from the core data trend or pattern that the line plot is intended to represent."}, {"title": "3.3 Model Context Length Variation", "content": "In our exploration of the capabilities of LLMs and VLMs, a key aspect we investigate is the impact of varying the context length on model performance. Specifically, we categorize datasets into two groups based on their alignment with our total context length, which is set at 2048 tokens. This threshold is significant as it represents a common constraint in many language models, where the capacity to process and interpret information is bounded by a maximum token limit. For datasets that exceed this 2048-token limit, we employ different downsampling strategies. Down-sampling involves reducing the size of the dataset to fit within the prescribed token limit, a process that inherently leads to a loss or corruption of some data. Aside from context windows, this approach simulates scenarios where the available data is in- complete or partially corrupted, a common challenge in real-world applications.\nWe do this by applying different downsampling strategies. The prupose of this filtering step is to smooth out the signal. We test whether the incorporation of a visual component can compensate for the loss of information due to downsampling. By introducing visual data, we aim to ascertain if the VLM can leverage this additional modality to maintain or even enhance it's performance despite the reduced textual data."}, {"title": "3.4 Downsampling Strategies", "content": "Uniform downsampling (Figure 7) is a technique used in signal processing to reduce the sampling rate of a time series by selecting data points at regular intervals. Unlike adaptive downsampling, which adjusts the sampling rate based on the variability of the signal, uniform downsampling treats"}, {"title": "3.4.1 Uniform Downsampling", "content": "all sections of the signal equally, discarding intermediate points to achieve a lower resolution. This approach is particularly useful for reducing the computational burden or storage requirements when working with large datasets, while retaining the overall structure and key features of the original signal. However, it may lead to information loss in regions where the signal exhibits rapid changes, as the uniform selection does not account for variations in the data's complexity."}, {"title": "3.4.2 Adaptive Downsampling", "content": "Adaptive downsampling (Figure 8) is a technique used to reduce the sampling rate of a time series signal in a way that preserves important information, particularly in regions of the signal that exhibit high variability. Unlike uniform downsampling, which samples data points at regular intervals, adaptive downsampling dynamically adjusts the rate based on the signal's characteristics. Areas of high complexity or rapid change are sampled more frequently, while regions of lower variability are sampled less densely. This approach helps to maintain the critical features of the signal, minimizing information loss, while reducing the amount of data that needs to be processed or stored. Adaptive downsampling is especially useful in scenarios where the data exhibits non-uniform behavior, and efficient compression is needed without compromising signal integrity."}, {"title": "Algorithm 2 Adaptive Downsampling Overview", "content": "Require: Input signal $X = \\{X_1, X_2, ..., X_n\\}$, window size $w$, downsampling factor $f$, and lambda $\\tau$\nEnsure: Downsampled signal $Y$\nInitialize empty list $Y$\ntarget_len = $\\frac{Len(X)}{f}$\nnumber_windows = $\\frac{Len(X)}{w}$\nInitialize empty list variability\nfor $i = 0$ to num_windows do\n\twindow = $X[i * w : (i + 1) * w]$\n\t\n\tend for\n$Y = adaptive\\_downsample\\_impl(variability, \\tau)$\nreturn Downsampled signal $Y$"}, {"title": "4 Evaluation Metrics", "content": "We focus on measuring model performance by following the paradigm of multiple-choice benchmarks for LLMs. We follow the method set by the original MMLU implementation by only extracting the predictions or predicted probabilities of the model that correspond to the answers. We do this in a one-shot setting in order to be mindful of the context length of the model."}, {"title": "5 Experiments", "content": "For the single-class setting, we primarily use the UCR time-series benchmark datasets that are a widely utilized benchmark in time-series analysis and deep learning research. It provides a standardized framework for evaluating the performance of time-series classification algorithms across a diverse range of domains. For the multi-class setting, we consider two datasets. The first dataset is The Free Music Archive (FMA). The dataset (Figure 9) includes 106,574 tracks categorized into a hierarchical structure of 161 genres. We leverage the hierarchical nature of the genres to construct a multi-label dataset. For this setting, we cluster the labels within each parent genre and have the model predict the parent genre, as a way of doing future extreme label classification. Additionally, it contains temporal features for each track collected by EchoNet, that we use as our uni-variate time-series.\nFinally, we consider a multi-variate, multi-class dataset in the form of sensor values from a hydraulic test rig. The system measures the condition of four hydraulic components (cooler, valve, pump and accumulator). As our label, we pass in the status of each component, and attempt to prompt the model by appending the component name to the input during evaluation.\nModels We use LLAVA for our pre-trained VLM model, with CLIP Vit Large Patch as the Vision Encoder and Vicuna-7B as the Large Language Model.\nTraining We train each LLAVA model on one A100 GPU for two epochs, using lora_r as 128 and lora_alpha as 256."}, {"title": "6 Results", "content": "In our exploration, we also aim to study the impact, different graphical representations have on Time Series Classification tasks. For this purpose, we conducted an A/B test comparing two types of graphical representations: line plots and scatter plots. The goal is to identify which representation"}, {"title": "6.1 A/B Testing Line Plots vs. Scatter Plots", "content": "better aided the model in capturing relevant temporal patterns in the data resulting in better one-shot accuracy."}, {"title": "6.1.1 Experiment Setup", "content": "We selected the following datasets from the UCR Time Series Archive.\n\u2022 ItalyPowerDemand: Time series depicting monthly power demand\n\u2022 PenDigits: Time series depicting x,y coordinates of pen traced across a digital screen"}, {"title": "Graphical Representation Types:", "content": "\u2022 Line Plot: In this representation, all data points are connected to form a continuous line, highlighting the trend, direction, and changes over time.\n\u2022 Scatter Plot: In contrast, scatter plots presented individual data points without connecting lines, treating each point as an independent entity."}, {"title": "6.1.2 Hypothesis", "content": "We hypothesized that line plots would outperform scatter plots in classification tasks due to their inherent ability to better capture the structure of time-series data due to the following reasons:\n1. Temporal Structure: Line plot continuity should make it easier for the model to detect trends and relationships between consecutive data points.\n2. Noise Reduction: Isolated points in scatter plots can appear more randomly distributed, making it difficult for the model to grasp underlying patterns.\n3. Trend Detection: Line plots would offer a clearer visual representation of trends, periodicity, and other temporal features, which are critical for accurately classifying time-series data.\n4. Visual Clarity for Long Sequences: When dealing with longer time-series sequences, scatter plots can become increasingly difficult to interpret, as the number of points grows and overlaps. Line plots, however, maintain clarity even with longer sequences, as the continuous lines provide a clear visual path through the data, aiding the model in recognizing temporal relationships."}, {"title": "6.1.3 Results", "content": "Our findings confirmed the hypothesis. In our experiments, as shown in Table 1, line plots led to significantly higher classification accuracy compared to scatter plots, when keeping all other parameters constant. For example, in the PenDigits dataset, the model's accuracy with line plots was 85.08%, while with scatter plots, it dropped to 80.64%. Similar results were observed for ItalyPowerDemand"}, {"title": "6.2 Pipeline Results", "content": "On single-label classification, as shown in Table 2, LLAVA performs quite well on most of the present data despite down-sampling. However, it should be noted that the model does best on signal data that is inherently temporal. Temporal signals, such as the ones in our power demand and ECG datasets, have inherent time-based patterns. The two datasets that display poor performance, PhalangesOutlines and Hand- Outlines (Table 3) contain extracted hand and bone outlines, as compared to temporal data. LLAVA may be less adept at handling static, spatial data or the specific feature representations derived from out-lines."}, {"title": "7 Conclusion", "content": "In this work, we explored the potential of Vision-Language Models (VLMs) for Time Series Classification (TSC) tasks by leveraging their ability to process both graphical and textual representations of time-series data using LLaVA. Our experiments demonstrated that VLMs can produce competitive results even with minimal fine-tuning, especially when incorporating visual representations that provide additional contextual information beyond what numerical data alone can capture.\nWe also introduced a scalable, end-to-end pipeline that allows for experimentation across multiple training scenarios, providing insights into the effectiveness of different configurations, such as varying context lengths, downsampling strategies, and data representations. Notably, the introduction of adaptive downsampling, which dynamically adjusts the level of downsampling based on signal variability, showed promising results by retaining more relevant information in high-variability regions.\nOur findings underscore three key observations:\n1. Higher context lengths significantly improve performance for high-dimensional signals: Longer context lengths enable the model to capture more extensive temporal dependencies and richer feature representations, which are crucial for high-dimensional data. For example, in tasks like ECG classification, where signal patterns span longer intervals, the ability to observe a broader context led to drastic improvements in accuracy.\n2. Choosing the right downsampling strategy is essential: The choice of downsampling strategy greatly influences model performance, as it determines how much information is preserved during preprocessing. Adaptive downsampling, which adjusts based on signal variability, was particularly effective in retaining critical information from high-variability regions while reducing noise in lower-variability segments.\n3. Custom features computed on the original signal can boost performance: Adding engineered features derived from the original signal, such as statistical summaries or domain-specific metrics, can provide complementary information that enhances the model's ability to discriminate between classes.\nFuture work may focus on improving model generalization, particularly in multi-class settings, and further refining the adaptive methods to better handle the complexity of real-world time-series data."}, {"title": "A Data Sample Examples", "content": ""}, {"title": "A.1 Baseline Representation", "content": "The baseline representation shows the raw time- series signal in a comma-separated format. Below is an example of a data sample and the corresponding class prediction from the model."}, {"title": "A.2 WITHL_STATS Representation", "content": "The WITHL_STATS representation shows the raw time-series signal in a comma-separated format augmented with summary statistics."}, {"title": "A.3 Other Experiments: WITH_RATIONALE", "content": "In this approach, we further augment the time- series data with some rationales. These rationales are synthesized by prompting LLMs to justify why a certain classification makes sense. Our hypothesis here, was that a rationales-based approach ensures that the model is aligned with domain-specific knowledge. This can be particularly useful, when data is complex to interpret without clear justifica- tion."}, {"title": "A.4 Issues in Rationales Based Approach", "content": "Our ability to generate Rationales did not generalize well across test-data. For a two-class classification problem, the similarity factor of the rationales turns out to be high, not really aiding in augmenting the predictive power of the model. This is obvious from the training plot of the rationales based approach. The training loss levels off to zero and stays there, characteristic of over-fitting to training data."}, {"title": "A.5 Future Work", "content": "The limitations of the rationale-based approach observed in this study highlight key areas for improvement. Future work will focus on:\n\u2022 Enhancing rationale diversity and generalization through dynamic selection techniques.\n\u2022 Introducing regularization methods to mitigate over-fitting.\n\u2022 Incorporating human feedback to refine and validate rationale generation.\n\u2022 Developing task-specific metrics for evaluating rationale relevance and informativeness.\n\u2022 Exploring integration with advanced architectures, such as attention mechanisms, to better utilize rationale information.\n\u2022 Experimenting with alternative loss functions tailored to rationale quality and predictive power."}]}