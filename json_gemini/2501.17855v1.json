{"title": "GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings", "authors": ["Ziang Liu", "Yuanchen Ju", "Yu Da", "Tom Silver", "Pranav N. Thakkar", "Jenna Li", "Justin Guo", "Katherine Dimitropoulou", "Tapomayukh Bhattacharjee"], "abstract": "Robot caregiving should be personalized to meet the diverse needs of care recipients-assisting with tasks as needed, while taking user agency in action into account. In physical tasks such as handover, bathing, dressing, and rehabilitation, a key aspect of this diversity is the functional range of motion (fROM), which can vary significantly between individuals. In this work, we learn to predict personalized fROM as a way to generalize robot decision-making in a wide range of caregiving tasks. We propose a novel data-driven method for predicting personalized fROM using functional assessment scores from occupational therapy. We develop a neural model that learns to embed functional assessment scores into a latent representation of the user's physical function. The model is trained using motion capture data collected from users with emulated mobility limitations. After training, the model predicts personalized fROM for new users without motion capture. Through simulated experiments and a real-robot user study, we show that the personalized fROM predictions from our model enable the robot to provide personalized and effective assistance while improving the user's agency in action. See our website for more visualizations: https://emprise.cs.cornell.edu/grace/.", "sections": [{"title": "I. INTRODUCTION", "content": "Participants with Spinal Muscular Atrophy gave examples that \"stressed the importance of personalized adaptations. These insights highlight the need for adaptive algorithms and interfaces that are tailored to individual needs, moving away from a one-size-fits-all model.\u201d [1]\nCare recipients and caregivers alike voice the need for personalization in assistive robotics [2\u20134]. If the goal is to empower individuals, then \"one size does not fit all.\" Recent advances in caregiving robots offer specific solutions for indi-vidual users in activities of daily living (ADLs) such as feed-ing [5-7], dressing [8,9], bathing [10, 11], transferring [12], and ambulating [13]. To create caregiving robots at the scale necessary to meet the needs of the approximately 1.3 billion people worldwide who live with significant disabilities [14], we should develop fundamental methods that span multiple activities and generalize across users.\nGeneralizing robot caregiving across users requires a rep-resentation of user functional ability. For example, consider"}, {"title": "II. RELATED WORK", "content": "A. Functional Range of Motion Modeling\nThe importance of fROM for general functional ability is well understood in occupational therapy [17]. Activities of daily living such as dressing, grooming, bathing, and feeding, as well as general independence in mobility are greatly affected by and often correlated with fROM [16,30]. Prediction of fROM from clinical functional assessment scores is therefore common in clinical practice.\nModeling fROM has also been considered in the human-robot interaction literature. For example, Bestick et al. [31] fit personalized kinematic models for human arms using motion capture data. Haering et al. [32] take a similar approach while focusing on detailed modeling of the 3 degrees of freedom in the shoulder, again using motion capture. Other work [33] considers soft-tissue modeling of the human arm as an orthogonal consideration to the personalization and generalization challenges that we address in this work.\nMost relevant are prior works that consider fROM modeling for users with mobility limitations. In particular, we take inspi-ration from Keyvanian et al. [29], who use motion capture to collect fROM data for users with emulated mobility limitations using resistance bands. This previous work does not consider learning a model that generalizes across users.\nB. Functional Assessments\nOur central insight in this work is that robot caregiving can be generalized across users by predicting fROM from func-tional assessment scores. The connection between functional assessment scores and fROM is well understood in occupa-tional therapy [34\u201336]. Functional assessments are also widely used in various fields such as psychology, rehabilitation, and geriatrics [37-40] to evaluate an individual's capabilities and limitations in performing everyday tasks and activities.\nPrevious work in rehabilitation robotics has considered leveraging functional assessments in combination with ma-chine learning [41-43]. These works typically consider ma-chine learning as a tool through which functional assessment can be improved. In contrast, we learn a model that makes predictions from functional assessment scores. To the best of"}, {"title": "III. PROBLEM FORMULATION", "content": "For a caregiving robot to provide personalized assistance while considering a user's agency, it must be able to pre-dict whether a candidate joint configuration falls within the user's fROM. In this work, we focus on four degrees of freedom (DOF) in the right arm: shoulder rotation, abduc-tion/adduction, flexion/extension, and elbow flexion. Formally, a joint configuration is a vector of joint angles \u03b8\u2208 [0,2\u03c0)4 obtained from motion capture data, and we wish to determine the fROM \u0398u for each user u, where\n\u0398u = {0 : 0 is reachable for user u}.\nWhen predicting fROM for a user, we assume the avail-ability of their functional assessment scores. In this work, we use ARAT [21] and FMA [22], which are standard in occupational therapy and can be easily collected in-situ by a licensed therapist. In contrast, directly measuring fROM typically requires a lab setting with expensive motion capture systems [18\u201320]. We combine the functional scores for user u into a vector \u03c3u \u2208 Rn. Formally, we wish to learn the mapping f : \u03c3u \u2192 \u0398u, that is, predict a user's fROM from their functional assessment scores.\nWe consider data-driven methods that can learn this map-ping for new users after training on users with known func-tional scores and fROM. We assume access to training data of the form {(\u03c3u, Cu, \u0398u) : u \u2208 training users}, where Cu is a discrete mobility condition category (see Section V-A). We evaluate performance on a dataset of unseen users with unknown and potentially unseen condition categories using normalized Matthews correlation coefficient (nMCC) [49]."}, {"title": "IV. A GENERALIZED MODEL FOR PERSONALIZED FROM", "content": "In this section, we detail GRACE, our novel data-driven method for predicting personalized fROM from functional assessment scores (Fig. 2). First, we reformulate fROM predic-tion as a binary classification problem (Section IV-A). Next, we learn a compact latent representation that captures a user's functional assessment results (Section IV-B). Finally, we train a neural network to predict the feasibility of a given joint configuration conditioned on the latent representation (Section IV-C)."}, {"title": "A. Reformulating fROM prediction as Binary Classification", "content": "To predict the personalized fROM set \u0398u for a user u, we reformulate the problem as a binary classification task. The goal is to determine whether a given joint configuration 0 is feasible for a specific user, conditioned on their functional assessment scores \u03c3u.\nWe begin by defining a bounding volume in the joint space that covers all possible joint configurations observed across participants and conditions. The minimum and maximum values for each joint dimension are computed across all users and conditions, yielding a hyper-rectangular bounding volume, denoted as \u0398bound. However, the actual feasible fROM for each user is only a subset of this volume. Naively sampling within \u0398bound would result in a disproportionate number of negative samples. To ensure a balance between feasible and infeasible configurations, we construct a mesh grid with 40 samples per joint dimension, spanning the entire \u0398bound. To reduce the high-dimensional joint space, we then refine this set by taking the union of all joint configurations that are feasible across all users and conditions, resulting in a reduced, feasible set, denoted as \u0472union. Subsequently, for each user, we use \u0472\u0438 to classify the mesh grid points in \u0472union into positive and negative examples.\nFor each \u03b8\u2208 \u0398union, we concatenate the user's functional scores \u03c3\u03b7 with the joints to create the classification input:\n\u03a7\u03c5 = [\u03c3\u03ba; \u03b8].\nThe reachability of e assigns a binary class label yu, indicating whether the joint configuration is feasible for the user u. We aggregate all (xu, Yu) pairs across users to create the classification dataset."}, {"title": "B. Learning a Latent Representation for User Functionality", "content": "We extract a compact latent representation to encapsulate a user's functional assessment results using an autoencoder model. The input is all normalized functional assessment scores \u03c3\u03b5 \u2208 Rn for user u, which are embedded into a latent vector zu \u2208 Rk by the encoder E:\nZu = \u03b5(\u03c3\u03c5).\nThe latent vector zu represents the user's capabilities and is then passed through the decoder D to reconstruct the original functional scores:\n\u00f4u = D(zu).\nThe encoder and decoder are two-layer feed-forward neural networks, each with a hidden layer size of 16 and a latent vector dimension k = 4. The training objective is to minimize reconstruction error using mean squared error (MSE) loss. Additionally, a contrastive loss Lcontrastive is applied to shape the latent space, enforcing proximity between embeddings with similar mobility and separation between distinct ones:\nLcontrastive = \n1\n\u03a1\u03a3 [{c=c;} .d(Zi, j)2\n+ I{ci\u2260c; } \u00b7 max(0, m \u2013 d(zi, zj))2]\nwhere d(,) is L2 distance, m is a margin parameter, and ci and cj represent the discrete mobility condition categories for users i and j respectively."}, {"title": "C. Predicting Joint Feasibility with a Neural Model", "content": "After training the functional score encoder, we train a neural network to predict the feasibility of a given joint configuration, conditioned on the latent representation of the user's functional assessment. The model takes as input the concatenation of the latent user embedding zu \u2208 Rk and the joint configuration \u03b8 \u2208 [0, 2\u03c0)4, providing a combined representation wu \u2208 Rk+4:\nWu = [zu; 0].\nThis combined vector wu serves as the input to a three-layer feed-forward neural network F(wu; $) with learnable param-eters 4. The output of the network is a scalar \u0177u \u2208 {0,1}, which predicts whether the joint configuration is feasible for the user u:\n\u0177u = F(wu; $).\nThe neural network is trained by minimizing a binary cross-entropy loss. The network consists of three fully connected layers with hidden size 16. We optimize the parameters using Adam [50] with a learning rate of 5 \u00d7 10-4, a batch size of 4096, and train the model for 10 epochs."}, {"title": "V. A NEW DATASET FOR FROM PREDICTION", "content": "Training GRACE requires a dataset of functional assessment scores and fROM for multiple users with diversity in their mobility. This paper contributes DataGRACE, the first open-source dataset of this kind. In this section, we describe our procedure for collecting this dataset.\nA. Emulating Mobility Limitations with Resistance Bands\nFollowing common practice in occupational therapy educa-tion [51,52] and prior HRI work [29], and with guidance from a licensed occupational therapist, we designed our emulation setup using exercise bands of variable resistance (Fig. 3) to represent clinically relevant mobility limitations. While we acknowledge that real patient data offers the most definitive validation, our occupational therapy collaborator confirmed that measurements taken in these emulated conditions closely resemble the functional limitations of care recipients, provid-ing confidence in the ecological validity of our approach.\nWe collected data from 11 participants, each emulating 4 different conditions of mobility, for a total of 43 \"users\" in the dataset (one participant-condition was removed due to technical error). The participants included 6 East Asian, 1 White, and 4 South Asian individuals; 3 females and 8 males; heights ranging from 160 cm to 185 cm; aged between 20 and 30 years; and varying in exercise routines and body shapes.\nWe secured a belt around each participant's waist (resting on the pelvic bone), serving as the anchor point for attaching resistance bands to the right arm. Specifically, 2 anchor points on the belt were secured at the pelvic level, W\u2081, located at the left iliac crest, and W2, located at the right iliac crest. Two additional armbands were anchor points on the right arm. The"}, {"title": "B. Collecting Functional Assessment Scores", "content": "Functional assessment scores were collected by an ex-perienced licensed occupational therapist following standard clinical practice. Another occupational therapist, blind to the purpose of the study, independently scored the recorded clini-cal assessment videos. Inter-rater reliability was strong across all participants and tasks (Cohen's Kappa 0.9 and above). We selected scores from two functional assessments that are most commonly used across clinical conditions to evaluate upper extremities functional motor performance [62, 63]: ARAT [21] and FMA [22].\nAction Research Arm Test (ARAT) ARAT has four sub-tests: grasp, grip, pinch, and gross movement. Given our focus on mobility limitations of the shoulder and elbow joints (inclusive of forearm pronation/supination), we carried out 3 sub-tests. In the grasp sub-test, participants were instructed to grasp six different objects of varying sizes, shapes, and weights, and move them from table height to the top of the ARAT box (Fig. 3). The grip sub-test involved tasks such as pouring water and picking up objects to place them in specific locations inside the ARAT box. In the gross movement sub-test, participants were asked to perform movements such as touching the back of their head, the top of their head, and their mouth. The ARAT items are scored based on observation of movement performance using a 4-level scale.\nFugl-Meyer Assessment (FMA) The Fugl-Meyer Assess-ment has 5 sub-tests; in this study, we utilize only the upper extremities sub-tests (FMA-UE), which involve diagonal movement patterns, complex movement patterns, and coor-dination/speed in movement patterns of the right arm. The occupational therapist evaluated mobility limitations and task completion following the FMA scoring system."}, {"title": "C. User Study: Collecting Ground-Truth fROM", "content": "We collected ground-truth fROM data using motion capture with 10 OptiTrak cameras. Each subject is fitted with 27 reflective markers on their upper body, arms, and head, as shown in Fig. 3. To minimize inaccuracies in joint angle reconstruction caused by slippage, we attached the markers directly to the participant's skin rather than using a traditional motion capture suit.\nThe data collection protocol for fROM involved two phases, designed to maximize coverage of the joint configuration space while ensuring repeatability. In phase one, participants replicated guided motions demonstrated by an occupational therapist, ensuring consistent and maximal exploration of joint limits. In phase two, participants performed self-directed movements for 30 seconds, with instructions to reach specific spatial landmarks within the scene. This combination of guided and free-motion phases enabled a comprehensive capture of both controlled and naturalistic movement patterns.\nD. Extracting Joint Angles from Motion Capture\nWe utilize the bone segment poses generated by Motive's human skeleton model to compute the right arm joint angles. Following the International Society of Biomechanics (ISB) standard [64] and prior work [29], we derive joint angles through a series of transformations defined as follows.\nRelative Rotation Matrix Let Ri and Rj be the rotation matrices for segments i and j respectively. The relative rotation matrix Ri,j representing the orientation of segment j relative to segment i, is computed as Ri,j = RRj.\nShoulder Joint Angles For the shoulder joint, the relative rotation matrix is decomposed into a sequence of Euler angles #shoulder = (@plane, \u03b8elev, Orot), corresponding to the plane of el-evation, elevation in plane, and shoulder rotation, respectively. This representation follows the ISB-recommended order of rotations for the glenohumeral joint (GHJ) [64].\nElbow Joint Angle To determine the elbow joint angle, we extract the primary direction vectors from the upper arm and forearm segments, denoted as Vupper and Vforearm. We then use their normal vector to find the plane that contains Vupper and Vforearm, then project each vector onto the plane and normalize to obtain uupper and uforearm. The relative angle @elbow between the upper arm and forearm is then computed as delbow = cos-1 (Uupper \u00b7 Uforearm).\nE. Completing fROM with One-Class SVM\nThe fROM data collected for a given user \u0472u is a finite subset of Ou, the infinite fROM for that user. Following previous work [29], we complete the fROM by fitting a one-class SVM model [28] to \u2295u. In all experiments, we use an RBF kernel (y = 0.0003,\u03bd = 0.01) for the SVM. We then use the decision boundary of the SVM to define \u0398u."}, {"title": "VI. EXPERIMENTS", "content": "We are interested in the extent to which GRACE can predict accurate, personalized, and useful fROM from functional as-sessment scores. We perform three sets of experiments: a direct"}, {"title": "A. Analysis of User Functionality Model", "content": "We first directly evaluate the ability of our model to predict fROM for new users. Throughout the three sets of experiments, we use the normalized Matthews Correlation Co-efficient (nMCC) as a measure of classification performance. nMCC is 1.0 for perfect performance and 0.5 in expectation for random predictions, even in the presence of class imbalance. We compare our method against two baselines:\n1) Ground Truth Condition: uses ground-truth condition ID instead of learned functional assessment embeddings.\n2) User Agnostic: omits the functional score encoder lead-ing to a non-personalized model.\nIn this set of experiments, we test three hypotheses by varying the training and evaluation procedure. Statistical significance is assessed using the t-test.\nHypothesis 1: Leveraging functional assessment scores im-proves fROM predictions for unseen users. We evaluate this hypothesis under two experimental scenarios. In the first sce-nario, we run leave-one-out cross-validation with the 43 users (Fig. 4). Our method significantly outperforms User Agnostic in nMCC (p < 0.001) and is not significantly different from Ground Truth Condition (p = 0.0869). These results suggest that our method is able to leverage functional scores to outperform a non-personalized model and match a model that has access to ground-truth user condition information.\nRecall that our data collection process has each of the 11 participants emulate 4 conditions. In a second analysis, we select one hold-out participant from the 11, train the model on all conditions for the remaining 10 participants, and evaluate on all 4 conditions for the hold-out user. We perform cross-validation over 5 random seeds. Results are shown in Fig. 4. Our model again significantly outperforms the User Agnostic baseline (p < 0.001), further indicating that incorporating functional assessment scores yields more accurate FROM predictions for previously unseen users. In this scenario, our model exhibits slightly lower performance relative to Ground Truth Condition (p = 0.0012).\nTakeaway 1: Our model predicts personalized fROM using functional scores for unseen users in our dataset."}, {"title": "Hypothesis 2: Leveraging functional assessment scores im-proves personalized fROM predictions for unseen conditions.", "content": "We hold out one of the four conditions during training and evaluate the model on all users in the unseen condition. We perform cross-validation for each hold-out condition with five random seeds. Results are shown in Fig. 4. Our method significantly outperforms both the Ground Truth Condition (p < 0.001) and User Agnostic baseline (p < 0.001).\nTakeaway 2: The combination of functional score assess-ments along with our learned fROM model can generalize to unseen conditions in our dataset.\nHypothesis 3: Our model captures differences in fROM for users with the same underlying condition. We train on 10 users with the same condition and evaluate on the held-out user. We cross-validate and run 5 random seeds. Statistical tests show no significant difference between our method with the Ground Truth Condition baseline (p = 0.3296) and the User Agnostic baseline (p = 0.3627). Consequently, this hypothesis is nullified: we find no evidence to suggest that our method can distinguish between users with the same condition.\nTakeaway 3: While the functional assessments we use in this work are reliable measures of motor function [65, 66], they may not capture all relevant factors affecting fROM; incorpo-rating additional assessments could improve performance [67]."}, {"title": "B. Simulated Robot Experiments", "content": "In this set of experiments, we evaluate the extent to which GRACE can be used for personalized and generalized robot caregiving. We run simulation experiments in four environ-ments inspired by common caregiving scenarios. In each environment, we define a generalization scenario, a success criteria, and an agency in action metric (higher is better). We describe the environments briefly here and refer to supplemen-tary materials on our website for details.\n1) Handover: A user sitting in a wheelchair asks the robot to hand over an object in the environment. The robot selects a 3D handover position.\n2) Rehab: A robot guides a user in a wheelchair through an arm stretching exercise where the robot selects target joint positions and the user attempts to reach them.\n3) Dressing: A robot selects a position at which to hold the arm-hole of a garment. The user attempts to reach that position and then extends their arm through the sleeve.\n4) Bathing: A robot is performing assisted bed bathing. The user's arm must be repositioned. The robot decides whether to ask the user to independently move their arm, or to move their arm for them.\nAll agency results are normalized with respect to a ground-truth method that has access to the fROM for the held-out user. We use PyBullet [68] for forward kinematics and RCare-World [69] for visualization (Fig. 5). For each environment, we sample 100 tasks and evaluate on 5 held-out users. We compare the following approaches:\n1) GRACE (Optimistic): Use the fROM predicted by our model to maximize agency subject to task success.\n2) GRACE (Conservative): Same, but predict fROM con-servatively: classify reachable if P(\u0177u \u2265 0.95).\n3) Heuristic (Optimistic): Assume a spherical fROM cen-tered at the resting position with a large radius (30 cm).\n4) Heuristic (Conservative): Same, but with a smaller radius (10 cm).\nUsing this setup, we test the following hypothesis:\nHypothesis 4: Personalized fROM prediction can improve user agency and success rates in robot caregiving tasks.\nSimulation results are presented in Fig. 5. We first find that GRACE consistently outperforms the heuristic baselines. Furthermore, we observe that optimism increases agency but reduces success. Comparing the optimistic and conservative variations of GRACE, we see the method's ability to flexibly balance task success and agency in action. These results demonstrate that by incorporating user-specific functional data, GRACE tailors assistance to individual needs, thereby empow-ering users to take a more active role in the caregiving process.\nTakeaway 4: Personalized FROM prediction enables a trade-off between success rate and agency in robot caregiving."}, {"title": "C. Real-Robot User Study", "content": "In this final set of experiments, we conduct a user study with a real robot. The setup is shown in Fig. 5. We consider a handover task involving three objects-a TV remote, a prescription bottle, and a water bottle-based on a list of household objects prioritized for robot retrieval by people with ALS [70]. The robot is a Franka Emika Panda 7-DOF arm with polymetis controllers [71] running on an Ubuntu 20.04 desktop. We recruit 5 participants from the original 11 and have each of them again emulate mobility limitations with resistance bands (Conditions 2, 3, and 4; see Section V-A).\nFor each participant and for each of the three objects, we use GRACE (Optimistic), Heuristic (Optimistic), and Heuristic (Conservative) to select handover positions. For GRACE, we choose the optimistic variant as it best represents the overall performance in simulation, and use a model trained on all participants except for the current one. Additional comparisons with GT Condition and User Agnostic baselines (see Section VI-A) are in the supplementary material on our website. In each trial, the robot picks the object and brings it to the handover position proposed by the model. The user then attempts to reach the object and answers a series of questions about the interaction. We conduct this user study in two parts, where the order of trials varies to address two different hypotheses. The first part tests the following hypothesis:\nHypothesis 5: Personalized fROM prediction improves task success rates, sense of agency, physical effort, and safety in a real robot-human handover task.\nWe first evaluate all three methods and all three objects for a participant emulating a single condition. The order of methods and objects is counterbalanced to mitigate ordering effects. We consider the following metrics:\n1) Task Success: whether the participant is able to grasp the object after handover (true or false)."}, {"title": "2) Sense of Agency:", "content": "the participant's perception of the extent to which they are actively using their physical abilities (5 point Likert scale).\n3) Physical Effort: the participant's self-reported physical exertion (5 point Likert scale).\n4) Safety: the proximity of the robot gripper to the user's hand during object handover (5 point Likert scale).\n5) Comfort the user's self-reported comfort during object handover (5 point Likert scale).\nResults are shown in Fig. 5. We see that GRACE sig-nificantly outperforms the Heuristic (Conservative) baseline in terms of sense of agency (p = 0.0054), physical effort (p = 0.0080), and safety (p < 0.001). GRACE also sig-nificantly outperforms the Heuristic (Optimistic) in terms of task success (p = 0.0018), with slightly lower but comparable safety (p = 0.0069). Other differences were not statistically significant. These findings are consistent with our simulation results and underscore the flexible trade-off between task success and other metrics that our method enables.\nTakeaway 5: GRACE improves task success, sense of agency, physical effort, and safety for real users.\nThe second part of the study tests the hypothesis:\nHypothesis 6: Users perceive GRACE's fROM prediction to be personalized.\nTo test this hypothesis, we vary emulated conditions for each user. The robot performs one handover with the water bottle for each condition to evaluate each approach. We ask participants to rank the approaches in terms of perceived personalization. We found that all five users consistently ranked GRACE the highest in terms of personalization.\nTakeaway 6: GRACE's personalization aligns with real users' perception of personalization.\nAltogether, this real-world user study demonstrates that GRACE significantly enhances the user's sense of agency and encourages more active physical participation while also"}, {"title": "improving safety during robot interactions\u2014all without com-promising task success. Additionally, users consistently rated GRACE as more adaptive and responsive to their individual abilities compared to the heuristic baseline, highlighting the method's ability to predict personalized fROM from functional assessment scores, making it more responsive and empowering for users with mobility limitations.", "content": "VII. DISCUSSION\nIn this work, we considered the challenge of scaling robot caregiving by generalizing across users. Our key insights were that fROM serves as a general-purpose representation for personalizing robot policies and can be predicted from readily available functional assessment scores. We introduced DataGRACE, the first open-source dataset with paired func-tional assessment scores and fROM data, and used it to train GRACE, a neural model that predicts fROM from functional assessment scores. In three sets of experiments, we found that GRACE consistently outperforms baselines and enables personalized assistance in multiple robot caregiving scenarios.\nThere remain many open challenges for personalizing robot caregiving. For fROM prediction, we found that GRACE was unable to significantly distinguish between users within the same mobility condition based on their functional scores. GRACE can be extended to integrate additional assessment scores that capture an even wider range of functional limi-tations. While these functional scores reliably reflect fROM over time for stable conditions, we encourage future research to consider transient or gradual changes in user functionality, where scores are frequently reassessed.\nFor personalizing robot caregiving more broadly, this work represents a small step-much remains to be done. Our efforts here demonstrate the viability of generalizing robot caregiving through learned user models and suggest a path forward to answer the call for personalization in assistive robotics [1-4]."}]}