{"title": "Enhancing Deep Learning with Optimized Gradient Descent: Bridging Numerical Methods and Neural Network Training", "authors": ["Yuhan Ma", "Dan Sun", "Erdi Gao", "Ningjing Sang", "Iris Li", "Guanming Huang"], "abstract": "Optimization theory serves as a pivotal scientific instrument for achieving optimal system performance, with its origins in economic applications to identify the best investment strategies for maximizing benefits. Over the centuries, from the geometric inquiries of ancient Greece to the calculus contributions by Newton and Leibniz, optimization theory has significantly advanced. The persistent work of scientists like Lagrange, Cauchy, and von Neumann has fortified its progress. The modern era has seen an unprecedented expansion of optimization theory applications, particularly with the growth of computer science, enabling more sophisticated computational practices and widespread utilization across engineering, decision analysis, and operations research. This paper delves into the profound relationship between optimization theory and deep learning, highlighting the omnipresence of optimization problems in the latter. We explore the gradient descent algorithm and its variants, which are the cornerstone of optimizing neural networks. The chapter introduces an enhancement to the SGD optimizer, drawing inspiration from numerical optimization methods, aiming to enhance interpretability and accuracy. Our experiments on diverse deep learning tasks substantiate the improved algorithm's efficacy. The paper concludes by emphasizing the continuous development of optimization theory and its expanding role in solving intricate problems, enhancing computational capabilities, and informing better policy decisions.", "sections": [{"title": "I. INTRODUCTION", "content": "Optimization theory has long been pivotal in advancing both mathematical and computational sciences. Deeply embedded in economic theory [1-3], it has expanded across various domains, including medical diagnostics [4-6], computer vision [7-9], and text analysis [10-13], driven by the need to solve increasingly complex problems.The evolution of this field has been marked by significant milestones-from the geometric explorations of ancient Greece to the calculus innovations by Newton and Leibniz, and further, through the contributions of Lagrange, Cauchy, and von Neumann. Optimization theory has always been an important scientific tool in the fields of mathematics and computer science research from ancient times to the present. It has been continuously developing and has made significant contributions to various other fields. Now, it is being used to solve a variety of complex problems, enhance computer performance, and help policymakers make better decisions. These historical advancements laid the groundwork for the modern applications of optimization theory, which now encompass diverse areas such as neural network[14-16], deep learning[17-20], and big data analytics.\nOptimization problems are ubiquitous in deep learning. Taking regression problems as an example, we hope that the final output of the deep learning model can be as close to the true value as possible, which is actually solving an optimization problem. In addition, we can see the shadow of optimization problems in classification and object detection problems. So, can we use optimization theory to help neural networks solve optimization problems? In fact, the gradient descent algorithm in deep learning is closely related to optimization theory, and improvements to optimizers such as SGD-M [21], Adagrad [22], and RMSprop [23] are all based on improvements to optimization theory. The focus of the aforementioned improvement methods is to accelerate the training speed of the optimizer, while this chapter aims to improve SGD from the perspective of interpretability and accuracy enhancement.\nThis paper first briefly describes the connection between SGD [24] and the forward Euler method in numerical optimization methods. Based on this, we have improved the SGD optimizer, and have verified the good performance of the improved algorithm on various types of deep learning tasks. The experimental results show that improving the optimizer with higher-order numerical differentiation is feasible."}, {"title": "II. BACKGROUND", "content": "A. Training Process of Deep Neural Networks\nThe training of deep neural networks can be viewed as a non-convex optimization problem, as shown below:\n$\\min L(W) = \\min \\frac{1}{|D|} \\sum_{x \\in D} L(x; W)$ (1)\nwhere L(W) is the loss function; W represents the model parameters; D represents the dataset; xrepresents the input to the model.\nB. Gradient Descent and Stochastic Gradient Descent\nThe goal of training neural networks is to find a set of appropriate parameters w to minimize L, which is an optimization problem. Typically, we can use the Gradient Descent (GD) method to solve such problems. The iterative process of GD can be written as\n$W_{k+1} = W_k - \\epsilon \\nabla_{W_k}L(W_k)$ (2)\nwhere $\\epsilon$ represents the training step size, and k represents the iteration number. Since the GD method calculates the gradient by using all input samples at once, training deep neural networks with the GD method can take a long time. To improve the training efficiency of deep neural networks, Stochastic Gradient Descent (SGD) is often used instead of GD. The iterative process of SGD can be derived as\n$W_{k+1} = W_k - \\epsilon \\nabla_{W_k}L_s(x; W)$ (3)\nwhere $L_s(x; W)$ can be specifically expressed as\n$\\min L_s(x; W) = \\min \\frac{1}{|S|} \\sum_{x \\in S} L(x; W)$ (4)\nwhere S is a subset of the dataset D. By observing equations, it is not difficult to find that the iterative forms of the GD algorithm and the SGD algorithm are very similar to the forward Euler method. Inspired by this discovery, this chapter re-examined the relationship between optimizers and numerical methods and attempted to improve SGD with a high-precision numerical differentiation."}, {"title": "III. METHOD", "content": "A. Gradient Descent Algorithm and Numerical Methods\nThis section first analyzes the connection between the gradient descent algorithm and the forward Euler method. Then, based on the connection between the two, the SGD algorithm's iterative method is improved using the Taylor multi-step difference method, and the TM-SGD algorithm is proposed.\nGradient Descent Algorithm and Numerical Methods We first analyze GD. Rewrite equation as\n$\\frac{W_{k+1} - W_k}{\\epsilon} = -\\nabla_{W_k}L(W_k)$ (5)\nAssuming that the training process of the deep neural network is time-related, the left side of equation can be considered as the derivative of W. Subsequently, we obtain a system of ordinary differential equations (ODE) as\n$\\dot{W} = -\\nabla_{W}L(W)$ (6)\nThus, we can view the iterative process of GD as solving the ODE using the forward Euler method. Observing equations, it can be found that in SGD, $\\nabla_{W_k}L_s(x; W)$ is used to estimate $\\nabla_{W}L(x; W)$ in GD. Next, we begin a qualitative analysis of the relationship between GD and SGD. Assume that $\\dot{W} = -\\nabla_{W}L(W) + \\xi$ follows some unknown distribution $\\xi$. Therefore, equation can be written as\n$\\dot{W} = -\\nabla_{W}L(W) + \\xi$ (7)\nObserving the above equation, it is not difficult to find that the iterative process of SGD is actually similar to that of GD, but for SGD, its iterative process is solving the ODE with unknown distribution noise using the forward Euler method.\nB. Taylor Multi-step Method\nBased on the Taylor series, we constructed a high-precision multi-step numerical method. Compared to the forward Euler method, the truncation error of the Taylor multi-step method is $O(\\tau^3)$, while the truncation error of the forward Euler method is $O(\\tau^2)$. This indicates that the Taylor multi-step method has higher computational accuracy than the forward Euler method. In Section 2.5, we conducted some numerical experiments to verify the superiority of the Taylor multi-step method.\nC. TM-SGD\nBased on the analysis above, we discovered the connection between the SGD algorithm and numerical methods. When we use the Taylor multi-step method to improve the SGD algorithm, we obtain the following iterative formula:\n$W_{k+1} = 1.5W_k \u2013 W_{k-1} + 0.5W_{k-2} \u2013 \\epsilon \\nabla_{W_k}L_s(x; W)$ (8)\nHowever, when we directly apply formula to improve SGD and propose TM-SGD, the neural network models trained by TM-SGD often perform poorly. In fact, in the numerical experiments, the constructed Taylor multi-step method exhibited significant solution fluctuations in the early stages of solving the problem. From the perspective of control theory, this is because the time lag affects the stability of the dynamic system. Note that the constructed Taylor multi-step method includes three terms (i.e., $\\theta(x_k)$, $\\theta(X_{k-1})$, $\\theta(X_{k-2})$), while the forward Euler equation only includes one term (i.e., $\\theta(x_k)$). Therefore, the constructed Taylor multi-step method relies on more previous data to predict the value of the next time step than the forward Euler method."}, {"title": "IV. EXPERIMENT", "content": "A. Experiment Settings\n1) Dataset\nThis chapter conducts experiments on various tasks to verify the excellent performance of the improved SGD algorithm. Initially, the datasets involved in the experiments will be presented in this section. Subsequently, the datasets and models involved in the TM-SGD are provided in the following text.\nThe datasets involved in the experiments of this chapter are as follows:\n\u2022 CIFAR-10/100 [25]. Benchmark datasets featuring 60,000 32x32 color images in 10/100 classes for object recognition tasks."}, {"title": "V. CONCLUSIONS", "content": "This paper begins by elucidating the connection between GD/SGD and the forward Euler method. Subsequently, the numerical experimental results demonstrate that the Taylor multi-step method has higher computational accuracy than the forward Euler method. Considering the impact of computational accuracy on solving ODE problems, this chapter improves the SGD algorithm using the Taylor multi-step difference method and proposes TM-SGD. Thereafter, we tested the performance of the TM-SGD algorithm in various different task scenarios. The experimental results show that the performance of the improved TM-SGD is superior to that of the original SGD. Additionally, taking SGD-M as an example, we improved it using the Taylor multi-step method and discussed the performance enhancement and existing shortcomings of the improved TM-SGD-M. The work in this chapter indicates that using numerical difference methods to improve optimizers is a straightforward approach to optimizer enhancement. Compared to other optimizer improvement methods, the optimizer proposed in this paper is easy to modify the code, and has certain interpretability and extensibility, which means that the method proposed in this paper does not require changing the original training method and hyperparameter settings of the optimizer to enhance the performance of the improved method. The application of these sophisticated numerical techniques in optimization algorithms opens new avenues for industries such as healthcare, where predictive modeling and diagnostic accuracy are paramount; finance, where complex risk assessments and algorithmic trading benefit from enhanced computational capabilities; and autonomous vehicle navigation, which relies on precise and efficient real-time decision-making systems. The continued exploration and adaptation of such methods promise significant strides in the field of computational intelligence, potentially revolutionizing how industries leverage Al to solve complex, real-world problems."}]}