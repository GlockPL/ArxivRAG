{"title": "Enhancing Microgrid Performance Prediction with Attention-based Deep Learning Models", "authors": ["Vinod Kumar Maddineni", "Naga Babu Koganti", "Praveen Damacharla"], "abstract": "In this research, an effort is made to address microgrid systems' operational challenges, characterized by power oscillations that eventually contribute to grid instability. An integrated strategy is proposed, leveraging the strengths of convolutional and Gated Recurrent Unit (GRU) layers. This approach is aimed at effectively extracting temporal data from energy datasets to improve the precision of microgrid behavior forecasts. Additionally, an attention layer is employed to underscore significant features within the time-series data, optimizing the forecasting process. The framework is anchored by a Multi-Layer Perceptron (MLP) model, which is tasked with comprehensive load forecasting and the identification of abnormal grid behaviors. Our methodology underwent rigorous evaluation using the Micro-grid Tariff Assessment Tool dataset, with Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and the coefficient of determination (r2-score) serving as the primary metrics. The approach demonstrated exemplary performance, evidenced by a MAE of 0.39, RMSE of 0.28, and an r2-score of 98.89% in load forecasting, along with near-perfect zero state prediction accuracy (approximately 99.9%). Significantly outperforming conventional machine learning models such as support vector regression and random forest regression, our model's streamlined architecture is particularly suitable for real-time applications, thereby facilitating more effective and reliable microgrid management.", "sections": [{"title": "I. INTRODUCTION", "content": "In the microgrid ecosystem, load forecasting and the iden-tification of anomalous generation patterns are integral to fulfilling demand requirements. The energy provision within such networks may derive from various sources, including diesel and solar energy, showcasing the system's versatility in harnessing power. [1]. However, this form of distributed energy source is susceptible to fluctuations thereby presenting chal-lenges in maintaining stable output power.Thus, conducting a thorough analysis of the patterns exhibited by the generated electricity is of paramount importance. On that note, the proliferation of diverse energy generation capabilities within microgrid configurations has markedly piqued the interest of a broader spectrum of stakeholders [2]. In this research, the study delves into predictive analysis of volatile load demand and the detection of anomalies in power generation within microgrid infrastructures, aiming to enhance the operational efficiency and reliability of these systems. The proposed solution focuses on striking a balance between the demand and energy produced by the grid; this approach could further facilitate an effective management of grid energy even dur-ing the elevated usage in a typical scenarios such as warm seasons. Another benefit of the devised strategy is accurate load forecasting within the microgrids; this plays a crucial role in preventing unexpected outages, enhancing the reliability of power supply. Furthermore, the adoption of renewable energy sources in electricity generation significantly contributes to the reduction of CO2 emissions, promoting a more sustainable and environmentally friendly energy landscape. A typical representation of the micro grid is shown in Figure 1.\nAs illustrated in the Figure 1, the microgrid integrates both renewable and non-renewable energy sources. Central to this system's efficacy is a sophisticated controller tasked with the precise apportionment of generated power. This includes a strategic division between direct residential supply and allocation to energy storage solutions, underpinning a nuanced approach to energy distribution and conservation.\nArtificial Intelligence (AI) has exhibited substantial poten-tial in the analysis of time series data. This research is aimed at leveraging the structural advantages of well-established mem-ory models, specifically the Gated Recurrent Unit (GRU) and attention mechanisms, to refine microgrid behavior predictions [3]. Additionally, the study has explored the incorporation of"}, {"title": "II. METHODOLOGY", "content": "convolution layers for extracting time-dependent features to further enhance the precision of microgrid predictions[4]. The proposed structure integrates a one-dimensional convolution function (Convld) and a Gated Recurrent Unit (GRU) to capture temporal features from the input time series. An attention layer further refines this process by highlighting the significance of specific time-dependent information extracted from the series, thereby enhancing the model's focus on relevant data for improved predictive accuracy. Finally, a Multilayer Perceptron (MLP) [5] model is used for end to end regression and classification.To expedite the performance of the final model, the minimum number of units has been selected for both the GRU and MLP components.\nThe literature review in recent studies illustrates a broad exploration of AI techniques, particularly in Deep Learning and Machine Learning, for diagnosing anomalies and forecasting behaviors in microgrid systems. Various approaches, ranging from Feed-Forward Neural Networks (FNN), Recurrent Neu-ral Networks (RNNs) including Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), to more complex architectures like sequence-to-sequence models and Temporal Convolutional Networks (TCN), have been scrutinized [6], [7]. The study is notable for its extensive comparison of these models applied to real-world data, identifying specific models that excel in short-term and long-term load forecasting. Similarly, the research demonstrates the efficacy of integrating full wavelet packet transforms with Multi-Layer Perceptrons (MLP) for detailed electricity consumption forecasting during varying conditions, significantly outperforming standard neu-ral network approaches[8].\nFurther, the application of machine learning and deep learn-ing for electrical load prediction is elaborated in studies, which reveal the superior accuracy of LSTM-based models when optimized with relevant data, including weather variables[9]. The innovative use of federated learning for energy forecast-ing showcases the potential for privacy-preserving models in residential energy consumption analysis[10]. Moreover, the advancement in fault detection methods within microgrids, as discussed in recent studies, highlights the significant role of various machine learning classifiers, like Decision Trees and AdaBoost, in enhancing microgrid reliability. The collective findings from these studies underscore the evolving landscape of AI applications in microgrid monitoring and management, steering towards more efficient and reliable energy systems. This backdrop forms the foundation for our research, where we propose a new model combining convolution, GRU, and attention layers aimed at improving load forecasting precision and speed, addressing the challenges associated with training deep learning models for real-time microgrid applications.\nThe main focus of the proposed method is to extract effective information from the original time series using a shallow deep learning architecture. This research has three main contributions:\n\u2022 Proposing a shallow network for load and abnormal behavior forecasting.\n\u2022 Comparing the performance of the proposed shallow deep learning model and traditional Machine Learning (ML) models.\n\u2022 Improving the performance of the proposed deep learning method using the fine-tuning of the learning rate and batch size.\nThis research paper continues as follows: Section II delves into the latest literature on load forecasting and the utilization trend in DL models, while section II offers a statistical review of the datasets used. Section III, on the other hand, focuses on the evaluation of model parameters and algorithm structures for load forecasting and abnormal behavior prediction. The experimental results, along with the performance ratings on these models, are presented in Section IV. Finally, Section V gives a recap of the study's findings, limitations, and potential future directions."}, {"title": "A. Dataset", "content": "The Microgrid Tariff Assessment Tool offers information on electricity consumption in rural sub-Saharan Africa, al-lowing users to examine the impact of system reliability on sizing and costs. It includes data on the levelized cost of electricity for diesel-only, solar-plus-storage, and solar-storage-diesel systems. The tool enables scenario comparison for locations in East, West, and Southern Africa, factoring in local geographical and economic parameters [11]. the tool allows comparison scenarios for three different locations in sub-Saharan Africa: East Africa (Lodwar, Kenya), West Africa (Accra, Ghana), and Southern Africa (Lusaka, Zambia). Each location has specific geographical and economic parameters tailored to the region, such as solar resource availability, diesel fuel prices, and distribution system costs. The statistical characteristics of the dataset are shown in Table I.\nIn this research, two columns are considered as the main targets of the prediction. The first considered target in this research is the generator-produced power (kW) and abnormal behavior of the generator-produced power (kW)."}, {"title": "B. Proposed Model", "content": "1) Convolution Layer: This investigation utilizes a one-dimensional convolution layer to delineate the temporal asso-ciations among elements within a time series dataset[12]. The essence of this layer lies in its employment of mathematical convolutions, which process information across designated windows. The formula for computing the output of this convolution layer is shown in Equation 1.\n\\(y_{k}^{l} = b_{k} + \\sum_{i=1}^{N-1} Convid (w_{ik}^{l} * x_{i}^{l-1})\\)  (1)\nwhere the l-1 is defined as the input of the layer l-1, b is defined as the bias of the kth neuron at layer l, w is the kernel from the ith neuron at layer l - 1 to the kth neuron at layer l, Convid is the 1-dimensional convolution layer with zero padding function, yk is kth output of layer l. Utilizing a one-dimensional convolution layer presents a dual benefit of enabling the extraction of temporal features while concurrently facilitating the optimization of the end regression or classifier model[13].\n2) Gated Recurrent Unit (GRU): The Gated Recurrent Unit (GRU) is an improved version of the LSTM network. Different from LSTM, the GRU prioritizes passing only the most critical information while omitting non-vital data. It accomplishes this by employing fewer gates in its structure [14]. The architecture of the GRU layer is shown in Figure 2. the equations for components of the GRU are shown as follows:\n\\(r_{t} = Sigmoid(X_{t} * W_{r} + W_{r} * H_{t-1} + b_{r})\\) (2)\n\\(z_{t} = Sigmoid(X_{t} * W_{z} + W_{z} * H_{t-1} + b_{z})\\) (3)\n\\(Out_{t} = (1 - z_{t}) * h_{t-1} + z_{t} *(Tanh(X_{t} * W + W * r_{t} * h_{t-1} + b))\\) (4)\nThe process of calculating the reset gate is illustrated in Equation 2, while the GRU unit's output computations are demonstrated in Equation 3. GRUs address the vanishing gradient descent issue in simple RNNs, improving training speed. They use update and reset gates to control information forwarded to the output, similar to LSTM cells but with one less gate, making them more efficient.\n3) Attention Layer: Central to each attention mechanism is the process to compute attention scores for every segment of the input sequence. These scores dictate the level of focus each part should receive during output generation. Typically, a softmax function is applied to calculate these attention scores, ensuring their sum equals one, thus facilitating a weighted importance across the sequence[15]. The architecture of the attention layer is shown in Figure 3. The attention weights are\ndetermined by assessing the likeness between the query and every key, using a measure of similarity such as dot product or cosine similarity. These weights are subsequently normalized using a softmax function to achieve a probability distribution. The importance of each occurrence of the query is then dictated by these weights [16]. The formula for calculating the emphasizing factor a is mentioned in Equation 5.\n\\(A_{t,i} = \\frac{e^{\\text{score}(X*K_{w},X*Q_{w,})}}{\\sum_{i=1}^{n} e^{\\text{score}(X*K_{w},XQ_{w,})}}\\)  (5)\n4) Multilayer Perceptron (MLP): This study uses a Multi-layer Perceptron (MLP) [17], a commonly used architecture in artificial neural networks, as a regression model to forecast the final layer [18]. Techniques such as the dropout layer and batch normalization are employed to prevent overfitting. The hidden layer within MLP modules consists of a combination of dropout and dense layers. The output layer's units depend on the grid's bus numbers [19]."}, {"title": "C. Proposed structure", "content": "In this paper, the study introduces a novel framework combining convolutional, GRU, attention, and MLP layers for forecasting load or detecting anomalies within datasets. Initially, convolution and GRU layers process the input signal for time-sensitive patterns, while the attention layer identifies key insights from the GRU output. The outputs from these layers are merged and normalized, with the architecture being iteratively applied. The culmination of this process is the ap-plication of a multi-layer perceptron for final value prediction, with the architecture detailed in the accompanying figure. 4."}, {"title": "D. Baseline Models", "content": "Similar to the reviewed research [20], this study conducts a comparative analysis of the proposed model against tradi-tional ML models using an identical dataset. The evaluation encompasses KNN, SVM, tree-based methods, and Bayesian strategies to assess the proposed model's performance. Each model applies a unique analytical perspective to the classifica-tion and regression tasks, with subsequent sections delving into the structural composition of each model for a comprehensive understanding.\n1) KNN: The K-Nearest-Neighbours (KNN) is a classifi-cation technique that uses the nearest neighbors of a data record to determine its category. Selecting the right value for 'k' in this method can be tricky [21]. The KNN Model, a more efficient approach, automatically optimizes 'k', im-proving classification speed and accuracy while reducing data dependency, making it a viable alternative to traditional KNN classification [22].\n2) SVM: Support vector machines (SVMs) are popular supervised learning techniques used for data classification and information retrieval in large, multidimensional tasks [23]. They are noted for their high accuracy in text cat-egorization and pattern identification, especially with small and unbalanced training sets. While primarily used in binary classification, SVMs can also handle multi-class problems. Their theoretical and empirical benefits make them suitable for active learning\n3) Tree base algorithms: A decision tree is a hierarchical tool used for data classification, boasting accurate, straight-forward analysis [24]. XGBoost and AdaBoost are ensemble learning algorithms that combine weak learners into one ef-fective learner. XGBoost is a quick, efficient, scalable method that reduces overfitting, whilst AdaBoost iteratively builds a strong classifier, focusing on hard-to-categorize cases. Both are widely used in machine learning applications due to their improved predicted accuracy [25].\n4) Beysian Methods: The Naive Bayes algorithm, based on Bayes' Theorem, is effective for classifying data such as tumors using gene expression profiling. Despite assuming each property is independent, it can predict classes based on assigned posterior class probabilities [26]. Highly paral-lelizable and flexible, it's suitable for large data analytics and applicable to fields like statistics and bioinformatics. A Bayesian probabilistic model must be built to use this method."}, {"title": "III. EXPERIMENTAL RESULTS AND ANALYSIS", "content": "This study conducted experiments using 80% of the dataset for training and 20% for testing, with training capped at 10,000 iterations and discontinued if no improvement was seen after 300 epochs. The initial learning rate was set at 0.001 and was reduced threefold in the absence of performance gains. Evaluations were performed using a V-100 GPU and an Intel Cori@7 processor, employing MAE and RMSE as the key metrics. The formulae for calculating the MAE and RMSE is mentioned as follows:\n\\(Mean Absolut Error (MAE) = \\frac{\\sum_{i=1}^{N} |Predicted_{i} - Real_{i}|}{N}\\)  (6)\n\\(Root Mean Squared Error (RMSE) = \\sqrt{\\frac{\\sum_{i=1}^{N} (Predicted_{i} - Real_{i})^{2}}{N}}\\) (7)\n\\(Accuracy = \\frac{TP + TN}{TP + FP + TN + FN}\\) (8)\n\\(Precision = \\frac{TP}{TP + FP}\\) (9)\nTP, TN, FP, and FN are abbreviations for true positive, true negative, false positive, and false negative predictions, respectively.\nThe evaluated results for forecasting the load by the pro-posed DL model amd ML models has shown in Table II. As shown in Table II, the performance of the proposed method is superior to ML models. The proposed model performance vs real value for the predicted instances is shown in Figure 5.\nThe analysis across various machine learning models re-veals competent accuracy in identifying instances with zero output. Nevertheless, the models' efficacy in predicting values generated by the generator falls short. Specifically, the Support Vector Regression (SVR) model from the experiment results shows suboptimal performance for predicting peak generation values around 12kW. Conversely, the Random Forest (RF) model excels at predicting zero-output instances but struggles with accurately forecasting generated energy levels of 8kW, highlighting a nuanced challenge in energy production predic-tion."}, {"title": "IV. DISCUSSION", "content": "This study employs a synergistic approach utilizing CNN, GRU, and attention mechanisms to forecast microgrid opera-tions and identify anomalies, extracting temporal patterns from various energy sources for predictive load management. It em-ploys an attention layer to highlight crucial features, validated against the Micro-grid Tariff Assessment Tool dataset, achiev-ing approximately 99.9% accuracy in zero state predictions and load forecasting accuracy with metrics of 0.39 MAE, 0.28 MSE, and an r2-score of 98.89%. The significance of features on predictions is assessed using Shapley values. The results of shapely values for each feature is shown in Figure 8.\nShapley values are a concept from cooperative game theory and are used as a method of attributing a fair reward to players based on their contribution to the game. Within the context of"}, {"title": "V. CONCLUSION", "content": "A microgrid system consists of many diverse renewable and non-renewable energy sources that feed into either a standalone system or a utility grid. The energy produced varies significantly due to the range of sources, like solar and diesel, leading to fluctuations between no power and full power generation. These fluctuations can result in abnormal behavior in the microgrid. Incorporating a mix of renewable and non-renewable sources, this study devises a predictive model for microgrid dynamics, utilizing convolution and GRU layers for time-sensitive data extraction, emphasized by an attention layer. An MLP model refines the prediction and abnormality detection. Evaluated with the Micro-grid Tariff Assessment Tool dataset, this method demonstrated accuracy with a 0.39 MAE, 0.28 RMSE, and 98.89% r2-score in load forecasting, and nearly 99.9% accuracy in zero power state prediction, showcasing its effectiveness in microgrid behavior forecasting."}]}