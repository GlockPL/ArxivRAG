{"title": "Enhancing Microgrid Performance Prediction with Attention-based Deep Learning Models", "authors": ["Vinod Kumar Maddineni", "Naga Babu Koganti", "Praveen Damacharla"], "abstract": "In this research, an effort is made to address microgrid systems' operational challenges, characterized by power oscillations that eventually contribute to grid instability. An integrated strategy is proposed, leveraging the strengths of convolutional and Gated Recurrent Unit (GRU) layers. This approach is aimed at effectively extracting temporal data from energy datasets to improve the precision of microgrid behavior forecasts. Additionally, an attention layer is employed to underscore significant features within the time-series data, optimizing the forecasting process. The framework is anchored by a Multi-Layer Perceptron (MLP) model, which is tasked with comprehensive load forecasting and the identification of abnormal grid behaviors. Our methodology underwent rigorous evaluation using the Micro-grid Tariff Assessment Tool dataset, with Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and the coefficient of determination (r2-score) serving as the primary metrics. The approach demonstrated exemplary performance, evidenced by a MAE of 0.39, RMSE of 0.28, and an r2-score of 98.89% in load forecasting, along with near-perfect zero state prediction accuracy (approximately 99.9%). Significantly outperforming conventional machine learning models such as support vector regression and random forest regression, our model's streamlined architecture is particularly suitable for real-time applications, thereby facilitating more effective and reliable microgrid management.", "sections": [{"title": "I. INTRODUCTION", "content": "In the microgrid ecosystem, load forecasting and the identification of anomalous generation patterns are integral to fulfilling demand requirements. The energy provision within such networks may derive from various sources, including diesel and solar energy, showcasing the system's versatility in harnessing power. [1]. However, this form of distributed energy source is susceptible to fluctuations thereby presenting challenges in maintaining stable output power.Thus, conducting a thorough analysis of the patterns exhibited by the generated electricity is of paramount importance. On that note, the proliferation of diverse energy generation capabilities within microgrid configurations has markedly piqued the interest of a broader spectrum of stakeholders [2]. In this research, the study delves into predictive analysis of volatile load demand and the detection of anomalies in power generation within microgrid infrastructures, aiming to enhance the operational efficiency and reliability of these systems. The proposed solution focuses on striking a balance between the demand and energy produced by the grid; this approach could further facilitate an effective management of grid energy even during the elevated usage in a typical scenarios such as warm seasons. Another benefit of the devised strategy is accurate load forecasting within the microgrids; this plays a crucial role in preventing unexpected outages, enhancing the reliability of power supply. Furthermore, the adoption of renewable energy sources in electricity generation significantly contributes to the reduction of CO2 emissions, promoting a more sustainable and environmentally friendly energy landscape. A typical representation of the micro grid is shown in Figure 1.\nAs illustrated in the Figure 1, the microgrid integrates both renewable and non-renewable energy sources. Central to this system's efficacy is a sophisticated controller tasked with the precise apportionment of generated power. This includes a strategic division between direct residential supply and allocation to energy storage solutions, underpinning a nuanced approach to energy distribution and conservation.\nArtificial Intelligence (AI) has exhibited substantial potential in the analysis of time series data. This research is aimed at leveraging the structural advantages of well-established memory models, specifically the Gated Recurrent Unit (GRU) and attention mechanisms, to refine microgrid behavior predictions [3]. Additionally, the study has explored the incorporation of"}, {"title": "II. METHODOLOGY", "content": "The Microgrid Tariff Assessment Tool offers information on electricity consumption in rural sub-Saharan Africa, allowing users to examine the impact of system reliability on sizing and costs. It includes data on the levelized cost of electricity for diesel-only, solar-plus-storage, and solar-storage-diesel systems. The tool enables scenario comparison for locations in East, West, and Southern Africa, factoring in local geographical and economic parameters [11]. the tool allows comparison scenarios for three different locations in sub-Saharan Africa: East Africa (Lodwar, Kenya), West Africa (Accra, Ghana), and Southern Africa (Lusaka, Zambia). Each location has specific geographical and economic parameters tailored to the region, such as solar resource availability, diesel fuel prices, and distribution system costs. The statistical characteristics of the dataset are shown in Table I.\nIn this research, two columns are considered as the main targets of the prediction. The first considered target in this research is the generator-produced power (kW) and abnormal behavior of the generator-produced power (kW)."}, {"title": "B. Proposed Model", "content": "This investigation utilizes a one-dimensional convolution layer to delineate the temporal associations among elements within a time series dataset[12]. The essence of this layer lies in its employment of mathematical convolutions, which process information across designated windows. The formula for computing the output of this convolution layer is shown in Equation 1.\n\n$y_k^l = b_k + \\sum_{i=1}^{N-1} Convid (w_{ik}^l * x_i^{l-1})$  (1)\n\nwhere the l-1 is defined as the input of the layer l-1, b is defined as the bias of the kth neuron at layer l, w\u00b9 is the kernel from the ith neuron at layer l - 1 to the kth neuron at layer 1, Convid is the 1-dimensional convolution layer with zero padding function, yk is kth output of layer l. Utilizing a one-dimensional convolution layer presents a dual benefit of enabling the extraction of temporal features while concurrently facilitating the optimization of the end regression or classifier model[13].\nThe Gated Recurrent Unit (GRU) is an improved version of the LSTM network. Different from LSTM, the GRU prioritizes passing only the most critical information while omitting non-vital data. It accomplishes this by employing fewer gates in its structure [14]. The architecture of the GRU layer is shown in Figure 2. the equations for components of the GRU are shown as follows:\n\n$r_t = Sigmoid(X_t * W_r + W_r * H_{t-1} + b_r)$  (2)\n\n$z_t = Sigmoid(X_t * W_z + W_z * H_{t-1} + b_z)$ (3)\n\n$Out_t = (1-z_t) * h_{t-1} + z_t *(Tanh(X_t * W + W*r_t*h_{t-1} + b))$ (4)\n\nThe process of calculating the reset gate is illustrated in Equation 2, while the GRU unit's output computations are demonstrated in Equation 3. GRUs address the vanishing gradient descent issue in simple RNNs, improving training speed. They use update and reset gates to control information forwarded to the output, similar to LSTM cells but with one less gate, making them more efficient.\nCentral to each attention mechanism is the process to compute attention scores for every segment of the input sequence. These scores dictate the level of focus each part should receive during output generation. Typically, a softmax function is applied to calculate these attention scores, ensuring their sum equals one, thus facilitating a weighted importance across the sequence[15]. The architecture of the attention layer is shown in Figure 3. The attention weights are determined by assessing the likeness between the query and every key, using a measure of similarity such as dot product or cosine similarity. These weights are subsequently normalized using a softmax function to achieve a probability distribution. The importance of each occurrence of the query is then dictated by these weights [16]. The formula for calculating the emphasizing factor a is mentioned in Equation 5.\n\n$A_{t,i} = \\frac{e^{score(X*K_w, X*Q_{w,i})}}{\\sum_{i=1}^{n} e^{score(X*K_w, XQ_{w,i})}}$  (5)\n\nThis study uses a Multi-layer Perceptron (MLP) [17], a commonly used architecture in artificial neural networks, as a regression model to forecast the final layer [18]. Techniques such as the dropout layer and batch normalization are employed to prevent overfitting. The hidden layer within MLP modules consists of a combination of dropout and dense layers. The output layer's units depend on the grid's bus numbers [19]."}, {"title": "C. Proposed structure", "content": "In this paper, the study introduces a novel framework combining convolutional, GRU, attention, and MLP layers for forecasting load or detecting anomalies within datasets. Initially, convolution and GRU layers process the input signal for time-sensitive patterns, while the attention layer identifies key insights from the GRU output. The outputs from these layers are merged and normalized, with the architecture being iteratively applied. The culmination of this process is the application of a multi-layer perceptron for final value prediction, with the architecture detailed in the accompanying figure. 4."}, {"title": "D. Baseline Models", "content": "Similar to the reviewed research [20], this study conducts a comparative analysis of the proposed model against traditional ML models using an identical dataset. The evaluation encompasses KNN, SVM, tree-based methods, and Bayesian strategies to assess the proposed model's performance. Each model applies a unique analytical perspective to the classification and regression tasks, with subsequent sections delving into the structural composition of each model for a comprehensive understanding.\nThe K-Nearest-Neighbours (KNN) is a classification technique that uses the nearest neighbors of a data record to determine its category. Selecting the right value for 'k' in this method can be tricky [21]. The KNN Model, a more efficient approach, automatically optimizes 'k', improving classification speed and accuracy while reducing data dependency, making it a viable alternative to traditional KNN classification [22].\nSupport vector machines (SVMs) are popular supervised learning techniques used for data classification and information retrieval in large, multidimensional tasks [23]. They are noted for their high accuracy in text categorization and pattern identification, especially with small and unbalanced training sets. While primarily used in binary classification, SVMs can also handle multi-class problems. Their theoretical and empirical benefits make them suitable for active learning\nA decision tree is a hierarchical tool used for data classification, boasting accurate, straightforward analysis [24]. XGBoost and AdaBoost are ensemble learning algorithms that combine weak learners into one effective learner. XGBoost is a quick, efficient, scalable method that reduces overfitting, whilst AdaBoost iteratively builds a strong classifier, focusing on hard-to-categorize cases. Both are widely used in machine learning applications due to their improved predicted accuracy [25].\nThe Naive Bayes algorithm, based on Bayes' Theorem, is effective for classifying data such as tumors using gene expression profiling. Despite assuming each property is independent, it can predict classes based on assigned posterior class probabilities [26]. Highly parallelizable and flexible, it's suitable for large data analytics and applicable to fields like statistics and bioinformatics. A Bayesian probabilistic model must be built to use this method."}, {"title": "III. EXPERIMENTAL RESULTS AND ANALYSIS", "content": "This study conducted experiments using 80% of the dataset for training and 20% for testing, with training capped at 10,000 iterations and discontinued if no improvement was seen after 300 epochs. The initial learning rate was set at 0.001 and was reduced threefold in the absence of performance gains. Evaluations were performed using a V-100 GPU and an Intel Cori@7 processor, employing MAE and RMSE as the key metrics. The formulae for calculating the MAE and RMSE is mentioned as follows:\n\n$Mean Absolut Error (MAE) = \\frac{\\sum_{i=1}^{N} |Predicted_i - Real_i|}{N}$ (6)\n\n$Root Mean Squared Error (RMSE) = \\sqrt{\\frac{\\sum_{i=1}^{N} (Predicted_i - Real_i)^2}{N}}$ (7)\n\n$Accuracy = \\frac{TP + TN}{TP + FP + TN + FN}$ (8)\n\n$Precision = \\frac{TP}{TP + FP}$ (9)\n\nTP, TN, FP, and FN are abbreviations for true positive, true negative, false positive, and false negative predictions, respectively.\nThe evaluated results for forecasting the load by the proposed DL model amd ML models has shown in Table II. As shown in Table II, the performance of the proposed method is superior to ML models. The proposed model performance vs real value for the predicted instances is shown in Figure 5.\nThe analysis across various machine learning models reveals competent accuracy in identifying instances with zero output. Nevertheless, the models' efficacy in predicting values generated by the generator falls short. Specifically, the Support Vector Regression (SVR) model from the experiment results shows suboptimal performance for predicting peak generation values around 12kW. Conversely, the Random Forest (RF) model excels at predicting zero-output instances but struggles with accurately forecasting generated energy levels of 8kW, highlighting a nuanced challenge in energy production prediction."}, {"title": "IV. DISCUSSION", "content": "This study employs a synergistic approach utilizing CNN, GRU, and attention mechanisms to forecast microgrid operations and identify anomalies, extracting temporal patterns from various energy sources for predictive load management. It employs an attention layer to highlight crucial features, validated against the Micro-grid Tariff Assessment Tool dataset, achieving approximately 99.9% accuracy in zero state predictions and load forecasting accuracy with metrics of 0.39 MAE, 0.28 MSE, and an r2-score of 98.89%. The significance of features on predictions is assessed using Shapley values. The results of shapely values for each feature is shown in Figure 8.\nShapley values are a concept from cooperative game theory and are used as a method of attributing a fair reward to players based on their contribution to the game. Within the context of predictive modeling, these values offer a quantitative metric to assess the relative importance of each feature, enabling a nuanced understanding of their impact on model outcomes. As shown in Figure 8, \"Battery O&M\" and \"Reopt LLC\" are the two most important features for forecasting the generated power. Also, the \"PV O&M\" and \"Battery O&M\" are the least important features for abnormal behavior detection and generated load forecasting.\nThe model exhibits near-optimal performance in precise load forecasting and anomaly detection, attributed to the optimized number of neurons and units within the MLP and GRU layers, respectively. This optimization renders the method relatively shallow, ensuring rapid response times that rival those of machine learning models and surpass the base algorithm in test phases. Consequently, this approach is well-suited for real-time applications in load forecasting and the detection of abnormal behaviors.\nFuture work will focus on enhancing the model's accuracy in predicting microgrid behaviors by exploring various optimization techniques to fine-tune the hyperparameters, thereby striving to achieve superior performance of the proposed approach."}, {"title": "V. CONCLUSION", "content": "A microgrid system consists of many diverse renewable and non-renewable energy sources that feed into either a standalone system or a utility grid. The energy produced varies significantly due to the range of sources, like solar and diesel, leading to fluctuations between no power and full power generation. These fluctuations can result in abnormal behavior in the microgrid. Incorporating a mix of renewable and non-renewable sources, this study devises a predictive model for microgrid dynamics, utilizing convolution and GRU layers for time-sensitive data extraction, emphasized by an attention layer. An MLP model refines the prediction and abnormality detection. Evaluated with the Micro-grid Tariff Assessment Tool dataset, this method demonstrated accuracy with a 0.39 MAE, 0.28 RMSE, and 98.89% r2-score in load forecasting, and nearly 99.9% accuracy in zero power state prediction, showcasing its effectiveness in microgrid behavior forecasting."}]}