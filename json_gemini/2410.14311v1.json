{"title": "Game Theory with Simulation in the Presence of Unpredictable Randomisation", "authors": ["Vojt\u011bch Kova\u0159\u00edk", "Lewis Hammond", "Nathaniel Sauerberg", "Vincent Conitzer"], "abstract": "AI agents will be predictable in certain ways that traditional agents are not. Where and how can we leverage this predictability in order to improve social welfare? We study this question in a game-theoretic setting where one agent can pay a fixed cost to simulate the other in order to learn its mixed strategy. As a negative result, we prove that, in contrast to prior work on pure-strategy simulation, enabling mixed-strategy simulation may no longer lead to improved outcomes for both players in all so-called \"generalised trust games\". In fact, mixed-strategy simulation does not help in any game where the simulatee's action can depend on that of the simulator. We also show that, in general, deciding whether simulation introduces Pareto-improving Nash equilibria in a given game is NP-hard. As positive results, we establish that mixed-strategy simulation can improve social welfare if the simulator has the option to scale their level of trust, if the players face challenges with both trust and coordination, or if maintaining some level of privacy is essential for enabling cooperation.", "sections": [{"title": "1 INTRODUCTION", "content": "With the current pace of progress in AI, we are likely to increasingly see important interactions take place not only between humans, but also with and between Al agents [5, 6]. To ensure that the societal impact of these interactions is positive, it is important to understand the ways in which Al agents differ from humans [4]. This in turn can help us design interventions that promote socially desirable outcomes [20].\nOne important distinction between human and AI agents is that the behaviour of AI agents is determined by their source code, and can therefore in certain cases be reliably predicted [23]. This could be achieved, for example, by inspecting the Al's source code and reasoning about it, or by creating a copy of the AI and running it in a simulated environment. As these examples suggest, we will assume that predicting the Al's actions requires non-trivial effort, and is therefore associated with some cost [9, 15]. (Readers familiar with Stackelberg games [25] can think of this setting as one where the follower has to choose to pay some cost before they are allowed to see the leader's mixed commitment. For a more detailed discussion of related work, see Section 6.) For concreteness, this paper will discuss this general topic in terms of simulating the AI agent, though our results also apply to other forms of prediction.\n1.1 Illustrative Example\nAlice, Bob, and his robots. Consider a setting in which Alice (player one) and Bob (player two) are due to interact in some particular situation, corresponding formally to some arbitrary two-player game G. Instead of interacting directly, however, Bob will deploy a robot\u00b9 that will act on his behalf. Moreover, Alice will have the option to analyse the robot, at some cost $C_{sim} > 0$. We will refer to this analysis as simulation.\nIn general, the robot can use randomness to determine which action to take. Correspondingly, we will distinguish between two types of simulation, depending on whether Alice is able to predict the robot's source of randomness or not. To capture this distinction formally, we can assume that the robot corresponds to some probability distribution $\\theta_2$ over pure strategies in G. In mixed-strategy simulation, Alice learns the robot's mixed strategy $\\theta_2$. In pure-strategy"}, {"title": "2 BACKGROUND", "content": "For a finite set X, \u2206(X) denotes the set of all probability distributions over X. For a probability distribution p, supp (p) denotes the support of p. We use $P_1$ and $P_2$ as shorthands for \"player one\" and \"player two\". When there is risk of confusion about which game a given object belongs to, we add superscript notation (e.g., $u^G$ for utility in G).\nA two-player normal-form game (NFG) G is a triplet $(S_1, S_2, u)$ where: $S := S_1 \\times S_2 \\neq \\emptyset$ is a set of pure strategy profiles (finite, unless specified otherwise) and $u = (u_1, u_2) : S \\rightarrow \\mathbb{R}^2$ is the utility function. We will typically denote the elements of $S_i$ (pure strategies) as $s_i$. A mixed strategy $\u03c3_i$ is a probability distribution over pure strategies. $\u03a3_i := \u2206(S_i)$ denotes the set of all mixed strategies. Since any pure strategy $s_i$ can be identified with the mixed strategy $\u03c3_i$ that selects $s_i$ with probability 1, we sometimes view pure strategies as a subset of mixed strategies. A subgame of G is any game of the form $G' = (S'_1, S'_2, u')$, where $S' \\subseteq S$.\nWith a light abuse of notation, we will overload the symbol u to also denote the expected utilities corresponding to mixed strategies. A strategy $\u03c3_1$ is said to be a best response to a strategy $\u03c3_2$ if $\u03c3_1 \\in \\arg \\max_{\u03c3'_1 \\in \u03a3_1} u_1 (\u03c3'_1, \u03c3_2)$. We use $br(\u03c3_2)$ to denote the (non-empty) set of all pure best responses to $\u03c3_2$. Since the utility of the best-responding player is determined by the other player's strategy, we sometimes denote it as $u_1 (br(\u03c3_2), \u03c3_2)$. (The analogous definitions apply when the roles of P1 and P2 are reversed.) A Nash equilibrium is a strategy profile $\u03c3 = (\u03c3_1, \u03c3_2)$ under which each player's strategy is a best response to the strategy of the other player. NE(G) denotes the set of all Nash equilibria in G.\nA strategy $s_1$ is said to be an (opponent-)favourable best response to $\u03c3_2$ if $s_1 \\in \\arg \\max_{t_1 \\in br(\u03c3_2)} u_2 (t_1, \u03c3_2)$. We use $f\\text{-}br(\u03c3_2)$ to denote the (non-empty) set of all (pure) favourable best responses to $\u03c3_2$. When one player uses a favourable best response, the utilities of both players are determined by the other player's strategy; this allows us to denote these utilities as $u_1 (f\\text{-}br(\u03c3_2), \u03c3_2)$ and $u_2 (f\\text{-}br(\u03c3_2), \u03c3_2)$.\nA Stackelberg game [25] is a setting where one player, the leader, commits to a mixed strategy to which the other player, the follower, best-responds. In this paper, we assume that P2 is the Stackelberg leader and P1 is the follower, which better fits the assumption that P1 is the simulator. Formally, a Stackelberg game $\\mathcal{G}$ corresponding to a base-game G works as follows. First, the leader selects a mixed strategy $\u03c3_2 \\in \u03a3_2$. Afterwards, the follower selects a favourable best response $s_1 \\in f\\text{-}br^G (\u03c3_1)$, (i.e., breaking ties in the leader's favour). The players then receive payoffs $u^{\\mathcal{G}} (s_1, \u03c3_2) := u^G (s_1, \u03c3_2)$. By Stackelberg equilibrium (SE) of $\\mathcal{G}$, we mean any NE of the Stackelberg game $\\mathcal{G}$.\nWe also also consider \"pure Stackelberg games\" where the leader"}, {"title": "3 PURE- VS. MIXED-STRATEGY SIMULATION", "content": "In this section, we formally define mixed-strategy simulation, contrast it with pure-strategy simulation, and survey the basic properties of the corresponding games.\n3.1 Definitions of Simulation Games\nIn Section 1.1, we informally described simulation games through a scenario in which Bob (P2) selects a robot that acts on his behalf and Alice (P1) has an option to pay a fixed cost to analyse the robot prior to interacting with it. If Alice takes advantage of this option, she learns the (pure or mixed) strategy that the robot is going to employ and best-responds to it, breaking ties in Bob's favour. Otherwise, the game proceeds as usual. We now give a formal counterpart to this description, the first part of which is a reformulation of that of Kova\u0159\u00edk et al. [15].\nDefinition 3.1 (Pure- and Mixed-Strategy Simulation). The mixed- and pure-strategy simulation games $\\mathcal{G}_{C_{sim}}^{m\\text{-}sim}$ and $\\mathcal{G}_{C_{sim}}^{p\\text{-}sim}$ (or simply $\\mathcal{G}^{m\\text{-}sim}$ and $\\mathcal{G}^{p\\text{-}sim}$) corresponding to a two-player NFG G and simulation cost $C_{sim} > 0$ are defined as the (infinite) NFGs given by:\n$\\mathcal{S}_1^{\\mathcal{G}^{m\\text{-}sim}} := S_1^G \\cup \\{m\\text{-}sim\\}, \\mathcal{S}_2^{\\mathcal{G}^{m\\text{-}sim}} := \u03a3_2^G$,\n$\\mathcal{S}_1^{\\mathcal{G}^{p\\text{-}sim}} := S_1^G \\cup \\{p\\text{-}sim\\}, \\mathcal{S}_2^{\\mathcal{G}^{p\\text{-}sim}} := \u03a3_2^G$,\nwhere m-sim and p-sim are new strategies of P1, called mixed- and pure-strategy simulation in G, defined by\n$u_1 (m\\text{-}sim, \u03c3_2) := u^G (br^G (\u03c3_2), \u03c3_2) - C_{sim}$,\n$u_2(m\\text{-}sim, \u03c3_2) := u^G (f\\text{-}br^G (\u03c3_2), \u03c3_2)$,\nresp.\n$u_1 (p\\text{-}sim, \u03c3_2) := \\mathbb{E}_{s_2 \\sim \u03c3_2} u_1 (br^G (s_2), s_2) - C_{sim}$,\n$u_2(p\\text{-}sim, \u03c3_2) := \\mathbb{E}_{s_2 \\sim \u03c3_2} u_2 (f\\text{-}br^G (s_2), s_2)$.\nA simulation equilibrium is an NE in which P1 simulates with non-zero probability.\nWhen the distinction between pure- and mixed-strategy simulation does not matter, we will use the colloquial term simulation.\nThis example also shows that in a pure-strategy simulation game $\\mathcal{G}^{p\\text{-}sim}$, Bob cannot gain anything by randomising over multiple mixed strategies (since all utilities only depend on the overall distribution over $S_2$). For the purposes of formal analysis of pure-strategy simulation games, this allows us to assume that Bob's space of pure strategies in $\\mathcal{G}^{p\\text{-}sim}$ is limited to $\\mathcal{S}^{\\mathcal{G}^{p\\text{-}sim}} = \u03a3_2^G$.\n3.2 Randomising over Mixed Strategies\nThroughout the paper, and in particular in some of the proofs, it will be crucial to be able to treat \u201cmixtures over mixed strategies\u201d differently from a standard mixed strategies (since the two respond differently to mixed-strategy simulation, as we saw earlier). To address this issue, we will refer to probability distributions over $\u03a3_2^G$ as meta-strategies and denote them by symbols such as $\u00b5_2$ (or $m_2$ when the meta-strategy is pure, i.e., when it puts all probability mass on a single $\u03c3_2 \\in \u03a3_2^G$). We will use the hat symbol to indicate that a given mixed strategy is being used as a (pure) meta-strategy. For example, Bob's above-mentioned mixed meta-strategy of uniformly randomising between a Rock-bot, Paper-bot, and Scissors-bot could be formally written as $\u00b5_1 := \\frac{1}{3}R + \\frac{1}{3}P + \\frac{1}{3}S$, while the pure meta-strategy of always using the Uniform-bot would correspond to $m_2 := \\widehat{\\frac{1}{3}R + \\frac{1}{3}P + \\frac{1}{3}S}$.\nFor a mixed meta-strategy $\u00b5_2 \\in \\Delta(\u03a3_2^{\\mathcal{G}^{m\\text{-}sim}})$ and pure base-game strategy $s_2 \\in S_2^G$, we will use $\u016d_2(s_2)$ to denote the total probability that $\u00b5_2$ puts on $s_2$. For example, if $\u00b5_2$ represents Bob using Uniform-bot with probability 30% and Rock-bot R with the remaining 70% probability, we have $\u016d_2(R) = 0.3 \\cdot \\frac{1}{3} + 0.7 \\cdot 1 = 0.8$.\n3.3 Basic Properties of Simulation Games\nWhile this paper focuses on the implications of mixed-strategy simulation m-sim, pure-strategy simulation p-sim will be relevant for two reasons. First, it serves as an important baseline for comparison. Second, it can be a useful source of intuitions for the properties of mixed-strategy simulation - this is because m-sim in G can be also be understood as p-sim in the infinite game $(S_1^G, \u03a3_2^G, u)$."}, {"title": "4 COMPUTATIONAL RESULTS", "content": "In this section, we investigate the difficulty of analysing mixed-strategy simulation games. From Proposition 3.4, it follows that even though $\\mathcal{G}^{m\\text{-}sim}$ is defined as an infinite game, it can be solved in finite time. By \"solving\" a game, we mean any of: (a) finding one NE; (b) finding an NE that maximises social welfare or the utility of one of the players; or (c) finding all NE payoff profiles and some NE corresponding to each.\nProposition 4.1 (Upper bound on solving $\\mathcal{G}^{m\\text{-}sim}$). For any G, solving $\\mathcal{G}^{m\\text{-}sim}$ is at most as difficult as solving a game $\\widehat{G}$ with $|S_{\\widehat{G}}| = O(|S^G|^{2.2^{|S^G|}})$.\nProof Sketch. The non-trivial part is the size of $\\mathcal{S}_{2}^{\\widehat{G}}$. Proposition 3.4 shows that a suitable $\\mathcal{S}_{2}^{\\widehat{G}}$ can be obtained by splitting the $(|S^G|-1)$-dimensional simplex $\u03a3^G$ into $O(|S^G|)$ convex polytopes and only considering the vertices of these polytopes. Estimating the number of these vertices yields the result.\nThe fact that NE(G) \u2286 $NE(\\mathcal{G}^{m\\text{-}sim})$ trivially implies that finding all NE of $\\mathcal{G}^{m\\text{-}sim}$ is at least as difficult as finding all NE of G. The difficulty of finding simulation equilibria of $\\mathcal{G}^{m\\text{-}sim}$ depends on $C_{sim}$. When $C_{sim}$ is prohibitively high, solving $\\mathcal{G}^{m\\text{-}sim}$ is equivalent to solving G (since Alice never simulates). For general $C_{sim}$, we leave determining the exact complexity of finding simulation equilibria of $\\mathcal{G}^{m\\text{-}sim}$ as an open problem.\nFrom the perspective of a designer, arguably the most important question is whether enabling simulation is likely to lead to more socially beneficial outcomes in a given game. The following result shows that this is, in general, hard to determine.\nTheorem 4.2 (Determining whether simulation helps is hard). Denote by $P_a, ..., P_e$ the problems of determining whether enabling m-sim introduces an NE which is strictly better than all NE of G in terms of (a) both players' utilities, (b) $P_1$'s utility, (c) $P_2$'s utility, (d) any strictly monotonic social welfare function (such as $u_1 + u_2$ or $u_1u_2$), or (e) the egalitarian social welfare function min{$u_1, u_2$}.\nFor general games G, each of the problems $P_a, ..., P_e$ is NP-hard.\nProof Sketch. The proof has two main ingredients. First, we create a game where the only NE payoffs are (0,0), but enabling simulation introduces a simulation equilibrium with payoffs $(1 - C_{sim}, 1)$. (This is easily achieved in a scenario where the players need to coordinate between two identical trust games; cf. Figure 4.) Second, we use a pre-existing method [19] for constructing a class C of games such that (a) any $G \\in C$ has a NE with payoffs (0,0); (b) a game $G \\in C$ may or may not have a NE with payoffs (1, 1), but definitely has no other NE; (c) determining whether $G \\in C$ does or does not have the NE with payoffs (1, 1) is NP-hard. We then show that enabling m-sim does not affect the NE of $G \\in C$.\nBy putting these two ingredients together, we obtain a class of games where enabling m-sim is guaranteed to yield a good outcome, but such outcome may or may not have been possible even without simulation - and determining whether this is the case or not is equivalent to solving a problem that is known to be NP-hard.\nFor the purpose of this paper, Theorem 4.2 suggests that we should not expect to be able to find a concise description of the effects of enabling m-sim in general games. We will, therefore, instead focus on identifying particular classes of games where simulation has predictable effects."}, {"title": "5 EFFECTS OF SIMULATION ON PLAYERS' WELFARE", "content": "In this section, we describe specific classes of games where enabling mixed-strategy simulation does, and does not, lead to socially beneficial outcomes."}, {"title": "5.1 Drawbacks of an Overly Informed Co-Player", "content": "In Section 1.1, we saw that in the simple case of a 2 \u00d7 2 trust games, enabling p-sim introduces Pareto-improving NE but enabling m-sim does not. The following theorem is a generalisation of this negative result.\nTheorem 5.1 (Simulating a perfectly informed player). Let $G_0$ be a finite two-player game. Denote by G the game where:\n(i) First, P1 selects $s_1 \\in S_1^{G_0}$ and P2 observes P1's choice.\n(ii) Next, P2 selects a pure strategy $s_2 \\in S_2^{G_0}$. We assume that P2 must select a Pareto-optimal response (but they are not required to best-respond).\n(iii) The players receive utilities $u^{G_0} (s_1, s_2)$.\nThen enabling m-sim does not introduce Pareto-improving NE in G.\nProof Sketch. When P2 can select $s_2$ as a function of P1's choice of $s_1$, they can increase the relative attractiveness of any fixed $\\widehat{s} \\in S_1$ by being maximally aggressive against any $s_1 \\neq \\widehat{s}$. Crucially, P2 can do this without lowering P1's utility of $\\widehat{s}$. Moreover, P2 can then bring P1's utility for $\\widehat{s}$ all the way to their maxmin value, and any NE of $(\\mathcal{G}_{0})^{m\\text{-}sim}$ will require P2 to do so. However, once P1 only gets their maxmin value, they have no reason to simulate, destroying any potential for simulation-based cooperation."}, {"title": "5.2 Partial Trust", "content": "The following definition captures settings where Alice can vary the degree to which she trusts Bob, with more trust enabling better outcomes for both, but also making Alice more vulnerable to exploitation (for illustration, see Figure 2). The purpose of this section is to show that settings where such modulation of trust is possible can benefit from mixed-strategy simulation.\nDefinition 5.2 (Generalised Partial-Trust Game). By a generalised partial-trust game (PTG), we mean any G = ($S_1, S_2, u$) that satisfies the conditions\n(1) P2 has two strategies: P2 only has only two pure strategies, which we label Cooperate (C) and Defect (D);\n(2) P1 has a dedicated strategy for opting out of the game: P1 has a strategy, which we label Walk Out (WO), for which u(WO, C) = u(WO, D) = (0,0);\n(3) Trust enables profits but is exploitable:\nAny P1's strategy T \u2260 WO (\u201ctrust\u201d) satisfies\n$u_1 (T, C) > u_1 (WO,\u00b7) = 0 > u_1 (T,D)$\n$u_2 (T, D) > u_2 (T, C) > u_2 (WO, \u00b7 ) = 0$;\nand the technical assumptions\n(4) There is a straightforward hierarchy of trust:\n(a) For any two strategies T \u2260 T', we have $u_1 (T, C) \\neq u_1 (T', C)$.\n(b) When $u_1 (T, C) > u_1 (T', C)$, we also have $u_2 (T, C) > u_2 (T', C)$, $u_1 (T, D) < u_1 (T', D)$, $u_2 (T, D) > u_2 (T', D)$;\n(5) P1 cannot use convex combinations for tie-breaking:\nFor any T, if a convex combination $\u03c3_1 = \u03bbs_1 + (1 - \u03bb)t_1$ satisfies $u_1 (T, \u03c3_2) = u_1 (\u03c3_1, \u03c3_2)$ for all $\u03c3_2$, it must also satisfy $u_2 (T, \u03c3_2) = u_2 (\u03c3_1, \u03c3_2)$ for all $\u03c3_2$.\nTo give an intuition for the conditions used in Definition 5.2, note that (3) ensures that non-zero payoffs can only be achieved when P1 Trusts P2, but P2 is always tempted to Defect, which makes P1 strictly worse off than if they Walk Out. The technical conditions (4a) and (5) ensure that once P1 decides on the tradeoff between potential gains from cooperation and exploitability, they have no room left for varying P2's payoffs. The technical condition (4b) ensures that higher cooperative gains for P1 go hand in hand with higher cooperative gains for P2 (but also increase P1's exploitability and P2's gains from defection).\nThe concept of a game with a gradation of trust can be extended in many ways, such as not having the default outcome be zero, not requiring that a higher degree of trust means that $u_2 (T, D)$ is higher, giving P2 a hierarchy of cooperative and defective strategies, etc. However, to simplify the exposition, this paper will only consider the basic setup described in Definition 5.2. The following lemma summarises the basic properties of generalised partial-trust games."}, {"title": "5.3 Trust and Coordination", "content": "We now investigate simulation in coordination games.\nDefinition 5.5 (Generalised Coordination Game). By a generalised coordination game, we will mean a finite two-player G game where:\n\u2022 $S_i = \\{a^1,..., a^n\\}$, for some n \u2265 2;\n\u2022 $u_i (a^k, a^l) = 0$ for k \u2260 l; and\n\u2022 $u_1 (a^k, a^k), u_2(a^k, a^k) > 0$ for any k.\nAs a standard property of coordination games, we get that:\nLemma 5.6. For any generalised coordination game, $NE(G) = \\{\u03c3_K | K \\subseteq \\{1,..., n\\}$ for some $\u03c3_K$ which satisfy: (i) supp $(\u03c3_k) = \\{a^k | k \\in K\\}$. (ii) NE that mix over fewer actions yield higher payoffs. (That is, $\u03c3_{K'}$ is a strict Pareto improvement over $\u03c3_k$ whenever $K' \\subseteq K$.)\nProposition 5.7 (Simulation in coordination games). Let G be a generalised coordination game and denote by $\u03c3^{\\{1,...,n\\}}$ its fully mixed NE. Then, for sufficiently low $C_{sim}$, we have:\n(i) $\\mathcal{G}^{m\\text{-}sim}$ has some simulation equilibrium $\u00b5^*$;\n(ii) Any simulation equilibrium $\u00b5^* \\in NE(\\mathcal{G}^{m\\text{-}sim})$ satisfies\n$u_1(\u03c3^{\\{1,...,n\\}}) < u_1(\u00b5^*) < \\max_k u_1(a_1^k, a_2^k)$\n$u_2(\u03c3^{\\{1,...,n\\}}) < u_2(\u00b5^*) \\leq \\max_k u_2(a_1^k, a_2^k)$;\n(iii) Unless G has multiple optimal pure commitments for P2, any such $\u00b5^*$ satisfies $u_2(\u00b5^*) < \\max_k u_2(a_1^k, a_2^k)$.\nProposition 5.7 shows that mixed-strategy simulation is able to prevent the worst equilibria, but does not introduce Pareto-improving NE in the stronger sense of allowing for an outcome that wouldn't be achievable through other means (i.e., by successful selection of a pure equilibrium). The following example and theorem show that the usefulness of mixed-strategy simulation increases when the players need to deal not only with coordination but also with issues of trust.\nDefinition 5.8 (Trust-And-Coordination Game). By a trust-and-coordination game, we mean a game G which works as follows (for examples, see Figure 3 and 6).\n\u2022 In the first stage, the players simultaneously select an action from the set $\\{a^1,..., a^n, OO\\}$.\n\u2022 If the players select $(a^k, a^l)$ for k \u2260 1, they receive \u201cbad\u201d miscoordination payoffs $(B_1, B_2)$.\n\u2022 Opting Out of the game via OO yields $(B_1, B_2)$, with an additional reward $\u03f5$ for the player(s) who used OO.\n\u2022 the players coordinate on some $(a^k, a^k), they enter the second stage of the game, where they play a subgame $G_k$.\n\u2022 Each $G_k$ is a 2\u00d72 trust game with actions {Trust, Walk Out}, resp. {Cooperate, Defect}."}, {"title": "5.4 Mixed-Strategy Simulation and Privacy", "content": "Kova\u0159\u00edk et al. [15] show that pure-strategy simulation can sometimes be harmful to both players. An example that illustrates this dynamic is a scenario where Bob, after successfully cooperating with Alice, has to put all his profits into a password-protected account. While Alice could always attempt to guess Bob's password, doing so would typically be futile. However, if she had access to pure-strategy simulation, she would be able to predict Bob's password and steal his profits, so Bob would chose to not cooperate with Alice in the first place. In contrast, if Alice only had access to mixed-strategy simulation, Bob could protect his profits by using a randomly-generated password, thus preserving the possibility of cooperation with Alice.\nIn Example G.2, we give a general construction which adds this \"password-guessing\" dynamic into any base-game, allowing us to derive the following result.\nTheorem 5.11. There are games where enabling m-sim introduces Pareto-improving NE, but pure-strategy simulation does not."}, {"title": "A EXTENSIVE-FORM GAMES", "content": "Definition A.1 (EFG). An extensive form game is a tuple of the form E = (N, A, H, \u03c1, \u03c0c, I, u) for which\n\u2022 N = {1, ..., N} for some N \u2208 N,\n\u2022 H is a tree 10 on A,\n\u2022 A and all sets A(h) := {a \u2208 A | ha \u2208 H}, for h \u2208 H, are compact,\n\u2022 \u03c1: H\\Z \u2192 N \u222a {c} (where Z denotes the leaves of H),\n\u2022 \u03c0c(h) \u2208 \u2206(A(h)) for \u03c1(h) = c,\n\u2022 u: Z \u2192 $\\mathbb{R}^N$, and\n\u2022 I = ($I_1,..., I_N$) is a collection of partitions of H, where each $I_i$ provides enough information to identify i's legal actions.11\nRecall that every normal-form game can be represented as an EFG (by assuming that players select actions one by one, but only observe the actions of others after taking their own action).\nA behavioural strategy for player i is a mapping\n$\\pi_i: \\{h \\in H | p(h) = i\\} \\leftrightarrow \\pi_i(h) \\in \\Delta(A(h))$.\nBy \u03a0 = $\\underset{i \\in N}{\\times}$ $\\Pi_i$, we denote the set of all behavioural strategy profiles \u03c0 = ($\u03c0_i$)$_{i \u2208 N}$. A behavioural strategy \u03c0i is said to be pure when for every h with \u03c1(h) = i and every a \u2208 $A_i(h)$, we have $\u03c0_i (a) \u2208 \\{0,1\\}$. Each \u03c0 \u2208 \u03a0 induces a probability distribution over the set Z of leaves the EFG. This allows us to define the expected utility in E as $u_i(\u03c0) := \\mathbb{E}_{z \\sim \u03c0}u_i(z)$. A behavioural strategy $\u03c0_i$ is said to be a best response to $\u03c0_{-i}$ if $\u03c0_i \\in \\arg \\max_{\u03c0'\\in\\Pi_i} u_i(\u03c0'_i, \u03c0_{-i})$.\nAll of the definitions straightforwardly generalise to the case where rewards are received during the game (i.e., we have some reward function $r_i$ that assigns $r_i(h, a) \u2208 \\mathbb{R}$ to every a \u2208 A(h) and $u_i(z) := \\sum_{h \\to z} r_i(h, a)$. Moreover, they also generalise to the case of infinite games. While this might sometimes cause the expectations to be undefined or infinite, we will only work with games where this is not an issue.\nA normal-form representation G of an extensive-form game E is defined as the normal-form game ($\\mathcal{S}^G_1,..., \\mathcal{S}^G_N, u^G$) given by\n$\\mathcal{S}^G_i := \\{\\pi_i \\in \\Pi_i | \\pi_i \\text{ is pure}\\}$,\n$u^G (\u03c0_1, ..., \u03c0_N) := u^E (\u03c0_1, ..., \u03c0_N)$."}, {"title": "B PROOFS FOR Section 3 (BASIC PROPERTIES)", "content": "In the remainder of the appendix, we present the proofs of the theoretical results described in the main text. To make some of the lengthier proofs easier to navigate, we state their main steps as separate claims and prove these claims using a separate proof environment.\nThe remainder of this section gives the proofs related to the basic properties of simulation games, and in particular the reduction of $\\mathcal{G}^{m\\text{-}sim}$ to a strategically-equivalent finite subgame.\nLemma 3.2. Identifying $\u03c3 \\in \u03a3^G$ with $(\u03c3_1,\u03c3_2) \\in \u03a3^{\\mathcal{G}^{m\\text{-}sim}}$, we have $NE(G) \u2286 NE(\\mathcal{G}^{m\\text{-}sim})$ for any G.\nPROOF. Let $\u03c3 \\in NE(G)$. To prove that $(\u03c3_1, \u03c3_2)$ is an NE of $\\mathcal{G}^{m\\text{-}sim}$, we need to show that neither player has a profitable deviation. Recall that $S_1^{\\mathcal{G}^{m\\text{-}sim}} = S_1^G \u222a \\{m\\text{-}sim\\}$ and $S_2^{\\mathcal{G}^{m\\text{-}sim}} = \u03a3_2^G$. Since \u03c3 is an NE, no $s_1 \\in S_1^G$ or $\u03c3_2 \\in \u03a3_2^G$ can constitute a profitable deviation from \u03c3 and hence from $(\u03c3_1, \u03c3_2)$ either. Moreover, for m-sim, we have\n$u_1^{m\\text{-}sim} (m\\text{-}sim, \u03c3_2) = u^G (br^G (\u03c3_2), \u03c3_2) - C_{sim}$,\n$= u_1^G (\u03c3_1, \u03c3_2) - C_{sim} \\leq u_1^G (\u03c3_1, \u03c3_2)$.\nThis shows that $(\u03c3_1, \u03c3_2)$ admits no profitable deviation."}, {"title": "B.1 Reduction of Strategy Space in NFGs", "content": "The following standard result ensures that when investigating the Nash equilibria of G", "\u03a3_{-i}": "s_i \\in br(\u03c3_{-i"}, ".", "nThen NE(G) = NE(G').\nThe proof is standard, but we provide it for completeness.\nProof. $NE(G') \\subseteq NE(G)$: Suppose that $\u03c3 \\in \u03a3^{G'}$ is not a Nash equilibrium of G. First, if \u03c3 uses strategies that do not appear in G', then \u03c3 cannot be an NE of G' and there is nothing to prove. Second, if supp $(\u03c3_i) \u2286 S'_i$ for both players, then we can use the fact that since \u03c3 is not an NE in G to get that for (at least) one of the players, there exists some pure best-response $s_i \\in br^G (\u03c3_{-i})$ for which $u_i (s_i, \u03c3_{-i}) > u_i (\u03c3_i, \u03c3_{-i})$. However, since S' contains all pure best responses, $s_i$ is also available in G'. This shows that player i can unilaterally improve their utility by deviating from $\u03c3_i$, so \u03c3 is not an NE of G'.\n$NE(G) \\subseteq NE(G')$: This part of the proof is analogous, except that we use the fact that when $\u03c3_i$ is a possibly"]}