{"title": "Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis", "authors": ["Yanzhi Wang", "Chu Wang", "Jinhong Wu", "Ziyang Yu", "Qi Zhou"], "abstract": "Fault diagnosis technology supports the healthy operation of mechanical equipment. However, the variations conditions during the operation of mechanical equipment lead to significant disparities in data distribution, posing challenges to fault diagnosis. Furthermore, when deploying applications, traditional methods often encounter issues such as latency and data security. Therefore, conducting fault diagnosis and deploying application methods under cross-operating conditions holds significant value. This paper proposes a domain adaptation-based lightweight fault diagnosis framework for edge computing scenarios. Incorporating the local maximum mean discrepancy into knowledge transfer aligns the feature distributions of different domains in a high-dimensional feature space, to discover a common feature space across domains. The acquired fault diagnosis expertise from the cloud-model is transferred to the lightweight edge-model using adaptation knowledge transfer methods. While ensuring real-time diagnostic capabilities, accurate fault diagnosis is achieved across working conditions. We conducted validation experiments on the NVIDIA Jetson Xavier NX kit. In terms of diagnostic performance, the proposed method significantly improved diagnostic accuracy, with average increases of 34.44% and 17.33% compared to the comparison method, respectively. Regarding lightweight effectiveness, proposed method achieved an average inference speed increase of 80.47%. Additionally, compared to the cloud-model, the parameter count of the edge-model decreased by 96.37%, while the Flops decreased by 83.08%.", "sections": [{"title": "1. INTRODUCTION", "content": "Rotating machinery fault diagnosis involves detecting, analyzing, and assessing the fault status of mechanical equipment to identify and pinpoint underlying issues[1]. It plays a crucial role in ensuring production continuity, enhancing equipment reliability and operational efficiency, reducing production costs, extending equipment lifespan, and ensuring workplace safety, thereby providing robust support for industrial production[2, 3].\nOver the years, deep learning techniques have emerged as powerful tools for fault diagnosis due to their ability to effectively analyze complex data patterns and make accurate predictions[4, 5]. Zhang et al. [6] utilized generative adversarial networks to learn the mapping between noise distribution and real mechanical vibration data, and then generated samples to balance and expand the dataset, addressing the problem of fault diagnosis under data imbalance. Zhao et al. [7] inserted soft thresholding as a non-linear transformation layer into the deep architecture to construct the Deep Residual Shrinkage Network. This model enhances the feature learning capability for high-noise vibration signals, achieving high fault diagnosis accuracy. Li et al. [8] proposed a two-stage transfer adversarial network, which can effectively separate multiple unlabeled new fault types from known fault types, and can be applied to detect various new faults in rotating machinery. It is worth noting that operating conditions are not constant, during the operational service of mechanical equipment. Its operation is accompanied by changes in factors such as rotation speed, load, etc., exhibiting characteristics of diversity[9]. This leads to significant differences in data distribution, indicating that the data are not from the same distribution. To address this issue, many studies have been conducted on fault diagnosis across different operating conditions [10, 11]. Lu et al. [12] employed a deep multi-scale CNN to extract multi-scale features from the measured raw vibration signals. Furthermore, they introduce a transformer block structure with a multi-head attention mechanism to establish connections between fault information and fault categories, demonstrating excellent fault feature spectrum recognition capability. Peng et al. [13] proposed a hybrid matching adversarial domain adaptation network, selecting multi-scale convolutional kernels. Simultaneously, embedding hybrid matching and confidence threshold in the adversarial network reduced conditional distribution differences. Ren et al. [14] proposed an unsupervised cross-task meta-learning strategy with a preference for distributional similarity, centered around a distribution distance weighting mechanism. The concept of maximum mean discrepancy was introduced simultaneously and used to measure the distribution distance. Chai et al. [15]extracted transferable and discriminative fault prototypes by simultaneously training a similarity-based"}, {"title": "2. PRELIMINARY", "content": "As a potentially effective fault diagnosis method under cross-conditions based on edge computing, this paper considers model lightweighting and cross-domain feature learning. Therefore, this section focuses on Depthwise SeparableConvolution (DSC) and Local Maximum Mean Discrepancy (LMMD), explaining their background and basic concepts in detail."}, {"title": "2.1. Deepwise Separable Convolution", "content": "The DSC is a convolutional operation used in neural networks to decrease the number of model parameters and computational complexity while maintaining model performance[31]. This operation is applicable for designing lightweight neural networks in resource-constrained scenarios. This operation specifically includes two steps: depth convolution and point convolution"}, {"title": "2.2. Local Maximum Mean Discrepancy", "content": "The Maximum Mean Discrepancy (MMD) is a method for quantifying the difference between two distributions. It relies on a kernel function to map the two distributions into a Hilbert space and calculates their mean difference within that space. LMMD extends the concept of MMD by incorporating locality[32].\nLMMD takes into consideration the potential local variations that may occur during changes in data distribution, rather than solely focusing on global distribution changes. This method aids in capturing differences between probability distributions more sensitively, particularly when dealing with complex data distributions. In the fields of deep learning and machine learning, LMMD is frequently employed for domain adaptation problems, where there are distinct discrepancies between the distributions of training data from the source domain and testing data from the target domain.\nThe objective of LMMD is to align the feature distributions of the same categories between the source and target domains. The specific computation process of LMMD is as follows:\nLMMD(X,Y) = \\frac{1}{C} \\sum_{c=1}^{C} \\bigg[ \\frac{1}{n_s^c} \\sum_{x_i \\in D_s} w_i^s \\phi(x_i) - \\frac{1}{n_t^c} \\sum_{x_j \\in D_t} w_j^t \\phi(x_j) \\bigg]^2 = \\frac{1}{C} \\sum_{c=1}^{C} \\bigg[ \\frac{1}{n_s^c (n_s^c-1)} \\sum_{i=1}^{n_s^c} \\sum_{j=1}^{n_s^c} w_i^s w_j^s k(z_i^s, z_j^s) + \\frac{1}{n_t^c (n_t^c-1)} \\sum_{i=1}^{n_t^c} \\sum_{j=1}^{n_t^c} w_i^t w_j^t k(z_i^t, z_j^t) - 2 \\frac{1}{n_s^c n_t^c} \\sum_{i=1}^{n_s^c} \\sum_{j=1}^{n_t^c} w_i^s w_j^t k(z_i^s, z_j^t) \\bigg] \\tag{1}\nWhere, $x_i^s$ and $x_j^t$ represent the i-th sample from the source domain and the j-th sample from the target domain, respectively. $z_i^s$ and $z_j^t$ represent the features outputted by the model for the i-th sample in the source domain and the target domain, respectively. $w_i^s$ and $w_j^t$ respectively represent the weights of the $x_i^s$ and $x_j^t$ sample belonging to class C in the source domain and the target domain, $\\sum_{j=1}^{n_s^c} w_j^s$ and $\\sum_{j=1}^{n_t^c} w_j^t$ are both equal to 1. Definition $w_i^c$ represents the weight of the C-th category label occupied by the current sample label, which can be calculated by the formula (2): \nw_i^c = \\frac{y_{ic}}{\\sum_{(x, y) \\in D_c} y_{ic}} \\tag{2}\nWhere, $y_{ic}$ represents the value of the C-th category in vector $y_i$. The labels of the source domain data are known and $w_i^s$ can be calculated using the known labels $y_{ic}$. However, the labels of the target domain are unknown, so the weights are calculated using the pseudo-labels obtained from the output $\\hat{y}_i = f(x_i)$ of the network."}, {"title": "3. PROPOSED METHOD", "content": "This study presents an intelligent fault diagnosis method based on domain adaptation to address the issue of cross-condition fault diagnosis in rotating machinery in edge computing scenarios. The proposed method comprises three stages: cloud-based model training, knowledge transfer at the edge, and real-time fault diagnosis at the edge. Fig. 2 illustrates the main workflow of this method.\nIn the cloud, firstly, numerous normal samples and samples of each fault category under a single working condition are obtained through simulation experiments. Then, the C-model is trained based on the above large number of samples. Following a process of successive training iterations, the model's optimal weight parameters are identified and deployed to the edge computing end. In the edge device, the superior feature extraction capabilities are conveyed to the lightweight E-model through the mechanism of knowledge transfer. Additionally, the diagnostic capability from the source domain (Condition 0) is generalized to the target domain (Condition N). Then, the E-model is deployed and run. The method achieves fast and accurate fault diagnosis near the device by inputting real-time operational data.\nThe key aspect of the proposed method is in the domain adaptation technique, which enables the transfer of knowledge from a complex C-model to a simple E-model and the adaptation from the single condition to the various operating conditions."}, {"title": "3.2. Model Structure", "content": "The proposed method involves two network architectures: the C-model, which is trained in the cloud and provides fault knowledge at the edge, and the E-model, which is deployed at the edge for real-time diagnosis. In the operational framework of the proposed method, the C- model is expected to have a deep network architecture to ensure its ability to effectively capture and represent data features, thereby achieving accurate prediction capabilities. Meanwhile, the"}, {"title": "3.3. Knowledge Transfer Methodology", "content": "The C-model is initially iteratively trained based the cloud computing. This enables C- model to effectively capture and represent features of the samples, acquiring accurate recognition capabilities for single operating conditions. Subsequently, there is a need to transfer the diagnostic capability from the large and complex neural network (C-model) to a smaller and simpler neural network (E-model), while also generalizing the diagnostic capability from single operating conditions to other conditions. This paper proposes a novel knowledge transfer method aimed at optimizing model size, enhancing computational efficiency, and aligning the diagnostic capability of the E-model with real-working conditions. The proposed knowledge transfer method, which consists of two stages, is illustrated in Fig. 2.\nWhen constructing both the C-model and the E-model, the same Pre-FE block was employed as the front feature extractor. During knowledge transfer, weight sharing was conducted on the Pre-FE block first. By employing a weight-sharing mechanism, the E-model can fully utilize the feature extraction capabilities of the C-model. Specifically, this implies that the E-model effectively inherits and shares the feature representations learned by the C-model. This process reduces the computational cost of training this part of the feature extraction capability on edge devices, effectively alleviating the computational burden.\nAfter completing the above weight-sharing operation, lock the weight of the Pre-FE block in the E model. Next, we train the E-Pos-FE block and classifier via Algorithm 1. Specifically, samples from Condition 0 are first input into the feature extractor of the C-model, resulting in feature representation $A_{classifier}^C$. While samples from Condition N are input into the feature extractor of the E-model, resulting in feature representation $A_{classifier}^E$. Next, based on $A_{classifier}^C$, $A_{classifier}^E$ and the corresponding labels of the samples, the differences in the distribution of related subdomains are calculated using LMMD and denoted as $LOSS_{Feature}$. It is then incorporated as one of the components in the model optimization objective.\nFurthermore, the classifier of the E-model outputs the predicted categories of samples from Condition N, which undergo label smoothing to obtain $\\tilde{A}_{classifier}^E$. Combined with the true labels Label, $LOSS_{Classify}$ is calculated using the cross-entropy loss function, serving as another component of the model optimization objective. Assign weights a and \u1e9e to $LOSS_{Feature}$"}, {"title": "3.4. The Approach of Domain Adaptive", "content": "In the knowledge transfer process mentioned above, parameters a and \u1e9e are set to adjust the weights of $LOSS_{Feature}$ and $LOSS_{Classify}$. Furthermore, adjusting the influence of the guidance role of the E-model's diagnostic effectiveness under actual operating conditions and the feature recognition capability of the C-model on the loss during the training process. However, in practical operations, it is challenging to quantify the differences between various conditions manually. Therefore, the proposed method adopts domain adaptation to adjust parameters a and \u1e9e, thereby achieving better adaptive diagnosis across operating conditions.\nThe approach of domain adaptive primarily employs two key elements: the computation of $LOSS_{Classify}$ using LMMD, and the adaptive adjustment of the weights for $LOSS_{Feature}$ and $LOSS_{Classify}$ to obtain the total optimization objective loss during the knowledge transfer process.\nThe optimization objective $LOSS_{Classify}$ aims to minimize the distribution differences between the target condition and the source domain condition. Enabling the proposed method to extract fault features with high correlation across operating conditions. The LMMD method is utilized to compute $LOSS_{Classify}$ during the training process.\nThe total optimization objective loss in the knowledge transfer process is obtained by adaptively adjusting the weights of $LOSS_{Feature}$ and $LOSS_{Classify}$ . First, calculate the gradient of $LOSS_{Feature}$ and $LOSS_{Classify}$ on the output value $A_{classifier}^E$ of the E-model respectively:\n$Grad_{Classify} = Gradient(LOSS_{Classify}, A_{classifier}^E) \\tag{3}$ \n$Grad_{Feature} = Gradient(LOSS_{Feature}, A_{classifier}^E) \\tag{4}$\nThen, the weights of $LOSS_{Feature}$ and $LOSS_{Classify}$ are calculated separately for the dynamic calculation of loss:\n$\\alpha = \\frac{w_a}{w_a + w_b} \\frac{l_a}{l_a + l_b + \\epsilon} \\tag{5}$ \n$\\beta = \\frac{w_b}{w_a + w_b} \\frac{l_b}{l_a + l_b + \\epsilon} \\tag{6}$\nwhere $l_a$ and $l_b$ are the L2 paradigms of $LOSS_{Feature}$ and $LOSS_{Classify}$, and $w_a$ and $w_b$ are the L2 paradigms of $Grad_{Feature}$ and $Grad_{Classify}$, respectively, and $\\epsilon$ is a very small value for avoiding division by zero error. Further, the total optimization objective loss during knowledge migration of the proposed method is calculated:\nloss =\\begin{cases}  \\alpha*LOSS_{Feature} + \\beta*LOSS_{Classify}, epoch \\le 0.9*num_{epoch}  \\\\LOSS_{Classify}, epoch > 0.9*num_{epoch} \\end{cases}\\tag{7}\nTherefore, the proposed method adjusts parameters a and \u1e9e, adaptively. Through the backpropagation optimization process of loss affecting the edge model, the adaptation to actual working conditions is achieved."}, {"title": "4. CASE STUDIES", "content": "The research utilized both a computer and an edge computing suite to conduct case studies. The computer served as the cloud device, equipped with an Intel Core i7-11700K@3.60GHz processor, an NVIDIA GeForce RTX 3070 GPU. Meanwhile, the edge computing suite uses the Jetson Xavier NX kit with an NVIDIA Volta GPU. Operating on the Ubuntu platform, the edge device utilized Docker for deployment purposes. The models were developed using Python 3.9 environment and PyTorch framework."}, {"title": "4.1. Experimental background", "content": null}, {"title": "4.2. CASE 01", "content": "Case 01 was performed using the customized RMFS platform developed by Huazhong University of Science and Technology, as shown in Fig. 4. The simulation platform includes an electric motor, control unit, gearbox, and friction brake[33]. It enables the introduction of various faults in the gearbox, and the operational conditions can be adjusted by modifying input power and friction brake. The ZDY80 parallel-axis gearbox was chosen as the subject of investigation in this study. The gearbox can simulate five different fault types, including: Normal, Broken, Miss, Root, and Pitting. Experiments were conducted with input powers of 1800W and 3000W, and loads set at 0, 50 n\u2022m, and 100 n\u2022m."}, {"title": "4.2.1. Experimental Method", "content": null}, {"title": "4.2.2. Results & Discussion", "content": "In the experiment, the input samples for each neural network are reconfigured into a matrix dimensions of [6, 56, 56]. Concurrently, the batch size is set as 32 for the training process. To comprehensively compare our proposed method with other classical approaches, we conducted 5 repeated experiments. The test accuracies of each model in different groups were recorded, as shown in Fig. 5, where error bars represent the standard deviation of the results. Furthermore, the average diagnostic accuracy of each model was calculated and summarized in Table 2 for quantitative analysis. It is evident that our proposed method outperforms the comparative methods, indicating its strong diagnostic capability under varying conditions. Specifically, apart from the average diagnostic accuracy of 90.08% in Group B3, the method consistently achieved accuracies above 95% in the remaining 7 groups. Moreover, the diagnostic results showed relative stability compared to the comparative methods. Regarding MobileNet, except for the result of 78.91% in Group A4, the accuracies in the other groups were above 80% but still below 90%. This phenomenon suggests the outstanding feature extraction capability of depth-wise separable convolutions. In addition, MobileNet showed less overfitting to the source domain during the experiment due to its lightweight design with fewer parameters. Consequently, it demonstrated good performance in cross-condition testing. ShuffleNetV2 yielded results ranging from 60% to 80%, with poor stability, showcasing diagnostic capabilities inferior to MobileNet. Xception, as a classic deep neural network with a larger parameter count, exhibited poor adaptability during cross-condition fault diagnosis experiments. C-model-transfer and E- model-transfer, as classic transfer learning methods, both showed test results below 50% in each group, with poor stability. This suggests that despite the availability of a small amount of labeled target domain data in the experiment, the limited sample size constrained the knowledge gained, leading to suboptimal performance."}, {"title": "4.3. CASE 02", "content": "The data for Case 02 was obtained using the Dynamic Drive System (DDS) at Southeast University, China[36]. The simulation platform illustrated in Fig. 9. enables the emulation of"}, {"title": "4.3.1. Experimental Method", "content": null}, {"title": "4.3.2. Results & Discussion", "content": "In the experiment, the input data for each model are reconfigured into a matrix with dimensions [6, 32, 32]. In training, the batch size is set to 32, considering the convergence of the model and memory usage. Cosine Annealing LR is used to adjust the LR during training. To ensure the robustness of the results, C and D groups of experiments were independently repeated 5 times and the average values were used for subsequent analysis.\nTo improve the persuasiveness of the ablation experiments, we conducted five repetitions of each experiment. We recorded the test accuracies of each model in the two groups, as shown in Fig. 10. The error bars represent the standard deviation of the results, and the table below displays the average diagnostic accuracy of the methods. The results in the figure exhibit a stair- step distribution, and our proposed method significantly outperforms the two comparison methods. Specifically, in both sets of experiments, the proposed method shows an average improvement of 19.76% and 11.02% over the W/O-Domain-adaptation and W/O-Adaptation- adjustment methods, respectively. These results indicate that the proposed method, which utilizes self-adaptive adjustment of LOSS weights and pre-adaptation methods, effectively enhances the fault diagnostic capability under variable operating conditions. Meanwhile, the stability of the two comparison methods is relatively poor. This is particularly evident in the W/O-Domain-adaptation method, where the accuracy deviation in the C group experiments exceeds 30%. This suggests that due to the limited number of target domain samples provided in the experiment, the comparison methods struggle to acquire sufficient diagnostic knowledge, leading to unstable results."}, {"title": "5. CONCLUSION", "content": "Fault diagnosis in mechanical equipment plays a pivotal role in supporting industrial production. Notably, variations in speed, load, and other factors during mechanical equipment operation lead to significant differences in data distribution, posing challenges for fault diagnosis. Moreover, conventional cloud-based fault diagnosis methods often encounter issues such as time delays and data security concerns during application deployment, while standard fault diagnosis methods for cross-operating conditions cannot be directly applied to edge computing devices. Therefore, fault diagnosis under diverse operating conditions using edge computing holds significant research value. This study proposes a lightweight fault diagnosis framework based on domain adaptation for edge computing scenarios. The objective is to achieve accurate fault diagnosis under cross-working conditions while maintaining real-time diagnosis capabilities. By incorporating domain adaptation learning into fault diagnosis, it aligns feature distributions across different domains in a high-dimensional feature space, thereby identifying common feature spaces among diverse domains. Leveraging a knowledge transfer approach, fault diagnosis expertise obtained from the cloud-based C-model is transferred to the lightweight E-model. We conducted validation experiments on two devices.\nThe proposed method significantly enhances diagnostic accuracy, with average improvements of 34.44% compared to existing methods, respectively. Additionally, our method achieves an average increase in inference speed of 80.47% compared to contrasting methods. Compared to the C model, the parameter count of the E model is reduced by 96.37%, and Flops are reduced by 83.08%. Furthermore, we conducted ablation experiments, and the diagnostic accuracy of the proposed method was improved by an average of 22.67% and 11.99% compared to the method lacking domain adaptation and the method lacking adaptation, respectively.\nIn summary, the domain adaptation method effectively improves the effectiveness of knowledge transfer, enabling the transfer of fault diagnosis knowledge learned under a single operating condition to actual operational conditions. This provides an effective approach for cross-condition fault diagnosis in edge computing scenarios, further promoting the widespread application of intelligent fault diagnosis in practical scenarios. However, although the proposed method achieves excellent lightweight effects, it still requires fine-tuning on the edge side with a small amount of operational data during knowledge transfer, which increases the overhead at the edge to some extent. Future work could explore the design of an online learning mechanism, allowing the model to be updated and adjusted based on real-time data collected on edge devices and then deployed[37]. Through online learning, the model can continuously adapt to changes in the edge environment, achieving adaptive capabilities without the need for fine-tuning."}, {"title": "Declaration of competing interest", "content": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper."}, {"title": "Funding", "content": "This research was supported in part by the National Key R&D Program of China Young Scientists Project [Grant number 2022YFC2204700]."}, {"title": "Data availability", "content": "Data will be made available on request."}]}