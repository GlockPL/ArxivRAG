{"title": "Structural features of the fly olfactory circuit mitigate the stability-plasticity dilemma in continual learning", "authors": ["Heming Zou", "Yunliang Zang", "Xiangyang Ji"], "abstract": "Artificial neural networks face the stability-plasticity dilemma in continual learning, while the brain can maintain memories and remain adaptable. However, the biological strategies for continual learning and their potential to inspire learning algorithms in neural networks are poorly understood. This study presents a minimal model of the fly olfactory circuit to investigate the biological strategies that support continual odor learning. We introduce the fly olfactory circuit as a plug-and-play component, termed the Fly Model, which can integrate with modern machine learning methods to address this dilemma. Our findings demonstrate that the Fly Model enhances both memory stability and learning plasticity, overcoming the limitations of current continual learning strategies. We validated its effectiveness across various challenging continual learning scenarios using commonly used datasets. The fly olfactory system serves as an elegant biological circuit for lifelong learning, offering a module that enhances continual learning with minimal additional computational cost for machine learning.", "sections": [{"title": "Results", "content": "CL in the fly olfactory circuit. Our first goal was to build a minimal model of the fly olfactory circuit to simulate its ability to learn distinct odors sequentially (Fig. 1c). The neuronal connections between the PN layer and the KC layer are determined by a random sparse expansion projection matrix [42]. Similar to previous work, each neuron in the KC layer is connected to r PNs (where r is referred to as synaptic degree [46]), with the synaptic weight set to 1, while the other weights in the connection matrix are set to 0,\nindicating no connection. For KCs, we apply the top-k operation to simulate the strong inhibition from APL neurons, activating only the top k percent of neurons with the strongest odor stimulation (winner-take-all).\nWe denote k as the coding level in neuroscience [47-48]. Subsequently, KCs are fully connected to MBONs\nthat represent different odor categories. Consistent with previous biological models [42], only the synaptic weights between the KC and MBON layers are updatable, while the connections between the PN and KC layers remain frozen during learning. The parameter update mechanism in the fly olfactory circuit is still an open question in neuroscience. Here, we adopted the efficient Synaptic Intelligence (SI) algorithm to update synaptic weights, an effective CL method designed to maintain memories for older tasks [9]. For comparison, we also utilized the widely used Stochastic Gradient Descent (SGD) method, which aims to minimize the loss function by updating synaptic weights without specifically considering the stability or plasticity of the network. Similar to previous work [46, 49], we simulated odors of corresponding categories by adding Gaussian-distributed noise to randomly selected class prototypes (class centroids). The dimensionality of the odor features is 50, the same as the number of glomeruli, through which signals are fed to PNs (see Methods for details). Following the setup of the CIL paradigm, we simulated 10 odor categories divided into 5 tasks for CL, with two new odors learned in each task (Fig. 2a).\nIn Fig. 2b, we defined a baseline fly olfactory circuit model, with expansion ratio of being 40; the synaptic degree r, set to 6; and the coding level k, set to 1%. under this expansion ratio, we selected r and k as the hyperparameters that yield the best accuracy in this setting. Note that except the slightly lower k value (experimentally 5%), all other parameters are identical to experimentally reported values [39-41, 50-\n51]. We used average accuracy to evaluate the performance after learning each task, backward transfer to measure forgetting, and forward transfer to measure plasticity loss (see Methods for details).\nThe simulation results indicate that the baseline fly olfactory circuit model maintains high accuracy even after learning 10 classes of odors sequentially, regardless of the synaptic update methods (SGD-fly and SI-fly in Fig. 2b left). Nonetheless, once ablating the fly olfactory circuit (SGD and SI in Fig. 2b by removing the KCs), the test accuracy significantly drops. By comparison, CL achieves a higher performance if SI is adopted as the synaptic updating method compared to SGD. From a fine-grained perspective, backward transfer and forward transfer can be considered as the components of accuracy decrease projected onto the dimensions of forgetting and plasticity loss, within the range of (-100%, 0). SI efficiently mitigates forgetting by using regularization to consolidate synaptic weights vital to previous tasks, which unavoidably leads to loss of plasticity as a side effect (Fig. 2b middle & right). In contrast, SGD exhibits almost no plasticity loss, but significant forgetting occurs during the process of CL. The fly olfactory model efficiently mitigates both forgetting and loss of plasticity when they exist. All these results support our hypothesis that the fly olfactory circuit supports CL of distinct odors.\nIn the next step, we analyzed the sensitivity of learning performance to the parameters that determine the three circuit features (Fig. 2c-e). We reported the average accuracy, accumulated accuracy (mean value of average accuracy before the current stage), as well as the last stage backward and forward transfer. The effects of the circuit parameters on learning performance are independent of the synaptic update rules. The expansion ratio facilitates CL by reducing both stability (backward transfer) and plasticity (forward transfer) loss, with the facilitation effect gradually saturating when the expansion ratio exceeds 40 (Fig. 2c). Both stability and plasticity are largely independent of the synaptic degree in the middle range but drop significantly when the number approaches either maximum or minimum values, leading to a similar trend in CL performance (Fig. 2d). The coding level in KCs is critical for CL. Memory stability decreases significantly with higher coding levels, but plasticity increases steeply in the initial range and then saturates. The net effect of these two factors is that there exists an optimal coding range for CL performance (Fig. 2e)."}, {"title": "Biological factors breaking the stability-plasticity dilemma in the fly olfactory circuit.", "content": "In this section,\nwe outlined how the fly olfactory circuit addresses the stability-plasticity dilemma during CL of distinct odors.\nFig. 3a illustrates the probability density function of the angle distributions between two random vectors. When vectors are projected from a lower dimensional space to a higher dimensional space, they are more likely to be perpendicular, with reduced correlations. In the feedforward path, odor information is transformed by the fixed PN-to-KC projection matrix (Wp\u2192K) and the adaptable KC-to-MBON\nprojection matrix (Wk\u2192\u043c). The numerous KCs help make vectors representing different odors more orthogonal after passing through Wp\u2192K, reducing task interference and minimizing forgetting. For_WK\u2192M,\nwe measured the angle between the gradients at the optima of task 1 (VL\u2081(w\u2081)) and task 5 (VL5(w)) as shown in Fig. 3b. As the expansion ratio increases, this angle approaches 90 degrees, which helps prevent forgetting. When gradients for different tasks (VLi and VLj) become more orthogonal, changes in weights for new tasks interfere less with the loss function of previous tasks [52] (see Theorem 1).\nTo our knowledge, there is no direct mathematical tool to prove that expansion enhances plasticity. We calculated the average magnitude of synaptic weights, a common metric for measuring plasticity (see\nMethods for details). Larger expansions result in decreased average magnitude of synaptic weights (Fig. 3c). Smaller network weights reduce the condition number of the Hessian matrix, accelerating the convergence speed of the SGD algorithm and aiding the network in finding a global maximum, thereby enhancing plasticity [53]. Another intuitive aspect is that more KCs increase the network's representational capacity, aiding adaptation to new tasks and consequently improving plasticity.\nThe synaptic degree is linked to the \"effective dimension\" of the KC layer. If two KCs are connected to identical PNs, their outputs are indistinguishable, leading to fewer effective KCs. Define p as the\nprobability that each KC receives a distinct subset of inputs (Fig. 3d). The maximum probability p and the largest number of effective KCs occur when the synaptic degree is n/2 (where n is the number of glomeruli and PN types) [46]. Extremely small or large synaptic degrees reduce the number of effective KCs and dimensionality, causing declines in both stability and plasticity (shifting to the left in Figs. 3b-c).\nFig. 3e shows KC activation for different tasks. After the top-k operation (winner-take-all via strong APL inhibition), KC activity becomes sparse and well-separated, minimizing overlap. This creates isolated\nsub-networks for each task, enhancing stability. However, only a subset of neurons is active, leaving many dormant, which reduces network capacity and decreases plasticity. Consequently, backward transfer\nincreases with sparser activity, while forward transfer decreases.\nIn Fig. 3f, the Pareto front illustrates the stability-plasticity dilemma, with each front representing the same representational capacity. The black dashed \"iso-accuracy line\" indicates a set of stability-plasticity\ncombinations that achieve identical learning performance. Increasing the effective dimension (via larger expansions or synaptic connections) advances the Pareto front, enhancing both stability (AS\u2081) and plasticity\n(\u0394\u03a1\u2081) simultaneously. Along this new boundary, an optimal coding level exists that balances stability (AS2) and plasticity (AP2), resulting in optimal learning performance. While increasing the expansion ratio and synaptic degree (optimal value ~25) consistently improves CL, these benefits come with higher metabolic and structural costs. Thus, the expansion ratio (~ 40) and synaptic degree (~ 6) in the fly olfactory circuit may represent a biological configuration that achieves effective performance with limited resources.\nFrom a ML perspective, this lightweight circuit provides a computationally efficient framework. For a single sample, its binary and sparse structure reduces the Floating-Point Operations (FLOPs) from\n100\u00d72000 (with half additions and half multiplications) to 6\u00d72000 (only additions) when mapping the 50-\ndimensional PNs to 2000-dimensional KCs, compared to a dense matrix. To update the synaptic weights\nbetween KCs and MBONs, only 6\u00d720\u00d710 FLOPs are needed (with a coding level of 0.01), which is about\n1% of the FLOPs required to update all parameters. In practical tests (see Fig. 3g), the SGD (SI)-Fly incurs\nminimal additional time compared to SGD (SI)."}, {"title": "The Fly Model improves stability and plasticity for stability-targeted methods.", "content": "The Fly Model enhances stability and plasticity when combined with stability-targeted strategies in ML. Based on the simulation results and analysis, we hypothesized that a model structure mimicking the fly olfactory circuit can facilitate CL in ML models. We proposed the fly olfactory circuit as a lightweight plug-and-play module, referred to as the Fly Model, and tested its effects on CL by integrating it with modern ML methods in the context of CIL.\nIn all subsequent ML tasks, CL performance was evaluated using CIFAR-100 (100 classes) [43], CUB-\n200-2011 (200 classes) [44], and VTAB (50 classes) [45], with 10, 20, and 10 classes per simulation task, respectively. Fig. 4a illustrates the pipeline of the first batch of simulations. We used the widely adopted\npre-trained Vision Transformer [54] model as the backbone, extracting 768-dimensional image feature vectors to feed into the Fly Model. In the Fly Model, there are 768 PNs (matching the feature vector size),\n30,000 KCs, and MBONs corresponding to the total class numbers: 100 for CIFAR-100, 200 for CUB-200-2011, and 50 for VTAB. The pre-trained model and PN\u2192KC connections remain frozen during\ntraining, with only the connection weights between KCs and MBONs updated. We employed the commonly used SGD, elastic weight consolidation (EWC) [6], and SI [9] strategies to update the connection weights. EWC and SI are strategies aimed at enhancing stability.\nThe Fly Model's impact on CL is evident through consistent improvements in test accuracy across all datasets, regardless of the weight update methods used (Fig. 4b-d, left). The Fly Model increases test\naccuracy by 22% for CIFAR-100, 25% for CUB-200-2011, and 7% for VTAB when using SGD to update\nsynaptic weights. The according accuracy improvements are 8%, 15%, and 5% with the SI method.\nImprovements fall within the middle range when using EWC. By analyzing test accuracy reduction into\nbackward and forward transfer, we illustrated the Fly Model's effects on stability and plasticity changes\nduring CL (Fig. 4b-d, middle & right). Across datasets, SGD causes minimal plasticity loss but experiences\nsignificant forgetting (stability loss) due to a lack of protection for previously learned synaptic weights. SI and EWC prevent forgetting by regularizing and consolidating important synaptic weights, but at the cost of reduced plasticity for new tasks. The Fly Model mitigates both stability and plasticity loss for stability-\ntargeted SI and EWC. For SGD, the facilitation effect is mainly due to reduced overwriting, as SGD causes minimal plasticity loss.\nThese results indicate that neural networks often suffer more from forgetting than plasticity loss in CIL experiments, highlighting where the Fly Model contributes most in this context. However, plasticity loss can become more severe in longer non-stationary sequence learning (see Fig. 6)."}, {"title": "The Fly Model improves stability after combining with strategies targeted at enhancing plasticity.", "content": "The Fly Model improves stability after combining with strategies targeted at enhancing plasticity. In the previous section, the facilitation effects of the Fly Model on CL have been mainly tested on strategies that mitigate forgetting. There also exist strategies aimed at alleviating plasticity loss [28-29]. In Fig. 5, we\ntested the facilitation effects of the Fly Model by combining it with two recent representative methods, L2 Init [29] and Shrink and Perturb (S&P) [28]. These methods incorporate either a regularization term on the initial parameters or parameter perturbations to enhance plasticity. The commonly used SGD method is preserved for comparison.\nFor plasticity-targeted methods, we employed a grid search to identify hyperparameters that yield the best test accuracy. Across all datasets, the CL performance of L2 Init and S&P is indistinguishable from that of the SGD method. In the current settings, forgetting is the primary issue, while plasticity loss is less significant. The test accuracy, along with backward transfer, decreases when hyperparameters aimed at\nimproving plasticity are applied (Supplementary Fig. 1), suggesting that plasticity-targeted methods tend\nto sacrifice stability for enhanced plasticity. Optimal performance is achieved when these hyperparameters\nare close to zero, effectively reverting to basic SGD. These results indicate that plasticity-targeted methods\ndo not alleviate catastrophic forgetting. However, the Fly Model significantly improves the ability of these methods to mitigate forgetting without causing plasticity loss.\nThe effectiveness and robustness of the Fly model were also tested in multilayer neural networks (where the recent continual backpropagation methods can be applied [5]) and class-imbalanced scenarios (Supplementary Figs. 2-3). While we could not exhaust all synaptic update strategies and datasets, the simulation results support our hypothesis that the fly olfactory model can, in principle, integrate with other ML strategies to enhance CL performance."}, {"title": "The Fly Model mitigates plasticity loss in long-sequence, non-stationary data streams.", "content": "In our CIL simulations, plasticity loss is less significant than stability loss, which limits the Fly Model's effectiveness in addressing plasticity loss. Therefore, we simulated streaming learning, where new information arrives in non-stationary online data streams without clearly defined task boundaries, leading to severe plasticity loss in neural networks."}, {"title": "The Fly Model enhances stability-targeted methods in streaming learning.", "content": "Fig. 6 The Fly Model enhances stability-targeted methods in streaming learning. a Streaming learning using Input Permuted MNIST. Metrics include average online accuracy, dormant units, stable rank, and\naverage weight magnitude. The effects of the Fly Model are tested against synaptic update strategies of\nSGD, EWC, and SI. b Same as a, but using Label Permuted MNIST (Layout inspired by [1]).\nFollowing previous studies [29, 36], we adopted two typical datasets: Input Permuted MNIST [55] and Label Permuted MNIST [29]. We generated 10,000 samples per task, with a total of 100 tasks in sequence. Each sample was fed into the network once, in an online learning manner. Throughout the 100 tasks, the network was trained to classify 10 classes. Unlike CIL, the number of classes does not increase over time. For Input Permuted MNIST, the input distribution shifts during CL, with the pixels of the same images randomly permuted in different orders for new tasks (Fig. 6a). For Label Permuted MNIST, concepts shift, where the same inputs are assigned randomly permuted labels for different tasks (Fig. 6b).\nTo evaluate the learning process from various perspectives, we employed four key metrics. Average online accuracy, a variant of average accuracy, measures plasticity. Dormant units indicate the ratio of neurons with nearly zero activation values; more dormant units suggest fewer active units available for adapting to new information. Stable rank, akin to effective rank in matrix theory, also measures plasticity, with a higher stable rank indicating greater plasticity [56]. Lastly, average weight magnitude is considered; according to ML theory, networks with lower weight magnitudes tend to exhibit higher plasticity [53] (see\nMethods for details).\nPlasticity-targeted methods have already shown exceptional performance in this scenario, resulting in minimal plasticity loss. Therefore, we examined the Fly Model's impact on reducing plasticity loss in stability-targeted methods, using basic SGD for comparison. Simulation results reveal that EWC and SI perform similarly to basic SGD, experiencing significant plasticity loss. However, incorporating the Fly\nModel effectively mitigates this loss. Metrics such as average online accuracy (increased), dormant units (reduced), stable rank (increased), and average weight magnitude (reduced) all demonstrate consistent\ntrends."}, {"title": "Discussion", "content": "In recent years, brain-inspired computation has shown great promise in addressing AI challenges. Many studies draw inspiration from different brain circuits, integrating features like synaptic mechanisms, neuronal properties, and coding strategies to pursue human-like intelligence. However, not all features are optimal for computational and learning performance. Each feature may represent a trade-off tailored to\nspecific functions, considering factors like metabolic costs, resilience, and learning speed. The fly olfactory\ncircuit exemplifies this idea.\nIn CL, increasing the number of KCs and forming more synaptic connections with glomeruli can improve performance, but the marginal gains are offset by higher metabolic and structural costs. Maintaining memory stability requires avoiding the overwriting of learned synaptic weights, leading to the stability-plasticity dilemma. Previous studies have tried to balance these factors by efficiently searching for unused synaptic weights for new tasks while preserving important ones. For instance, smaller synaptic weights may help find solutions for new tasks by accelerating convergence [53]. However, they can't resolve the dilemma if the capacity limit is reached. Similar to neurogenesis in biological circuits [57], one\nsimple solution in ML is to increase network capacity by adding neurons, which unavoidably increases computational costs.\nThe Fly Model elegantly overcomes this dilemma with three key features: large expansion, sparse connections, and sparse coding. It enhances CL in two ways. First, sparse coding in KCs balances stability\nand plasticity. Second, these features elevate the network's Pareto front for stability-plasticity with minimal additional computational costs (Fig. 3). Biologically, similar structures exist in the cerebellum, hippocampus, and electric fish, related to cerebellum-like circuits [39-40, 58-59].\nIn this work, we demonstrated that the three critical features of cerebellum-like circuits\u2014large\nexpansion, sparse connections, and sparse coding\u2014can function as a plug-and-play component that\nintegrates seamlessly with modern ML methods to reliably facilitate CL. Furthermore, the proposed Fly\nModel, a specific instance of cerebellum-like modules, may have broad applications in other ML tasks such\nas spatial navigation, anomaly detection, and language processing, owing to its strengths in feature\nextraction [59-60].\nTo make the Fly Model more practical for real-world applications, there is still room for improvement. The fly olfactory circuit model is minimal. More biologically efficient factors, such as branch-dependent\ncomputing [61], state-dependent learning [62-63], and multisite plasticity [64], have not been included in our model framework due to limited knowledge. These factors may be the missing pieces for CL. We have\nshown that there is an optimal coding level for any fixed scenario of CL, but this level can vary under\ndifferent setups and network architectures. Developing an automatic parameter selection algorithm would\ngreatly enhance real-world deployment. Furthermore, the sparsity property of the Fly Model has the\npotential to save significant resources, which is crucial for edge devices with limited computational\ncapacities. If a specific operator could be implemented in hardware, it would further reduce computational consumption. Finally, while we tested the Fly Model in the context of image classification tasks, more\ngeneral CL paradigms involving diverse cognitive tasks need to be explored. These represent promising\ndirections for future research."}, {"title": "Methods", "content": "Problem Statement\nIn this paper, we mainly focused on the traditional CIL scenario and the emerging streaming learning scenario. In CIL, we denote sequentially arriving tasks as_D = {D\u2081, ..., D\u2081} where each_task_Dt =\n{(x,y)}1 contains Nt samples. Each sample x within a task is drawn from the input space Xt, and its corresponding label y from the label space Yt. The training process involves sequentially learning from D\u2081 to Dr, followed by class prediction on an unseen test set within the full label space. The neural network learns mutually exclusive classes within each task where the intersection of Y\u00bf \u2229 Y; = \u00d8. For streaming learning, the notation is similar, but the task sequence is much longer, and samples within each task can only be trained once. In this work, we primarily focused on the case where Y\u2081 = Y; to study plasticity changes throughout the process.\nDataset Configuration\nIn Fig. 2, we generated simulated data to mimic odors using a configuration similar to previous work [49]. We first generated_C = 10_class prototypes, c\u00a1 \u2208 Rn, from a uniform distribution U[0,1]\". Each prototype is a n = 50 dimensional vector. Subsequently, we applied Gaussian noise to generate samples\nXjj = C\u00a1 + N(0, \u03a3), where each sample is labeled with yi corresponding to the category of ci. For simplicity, we assume different dimensions of the Gaussian noise are independent and identically\ndistributed, which means the covariance matrix \u03a3 = diag(\u03c32, ..., \u03c3\u00b2). For CL, we adopted the CIL setting\nwith task sequence T = 5, and each task has 2 classes. We set the standard deviation of the Gaussian noise to \u03c3 = 0.5. There are a total of 50,000 training samples and 10,000 testing samples, with the number of samples balanced across classes.\nIn Figs. 4-5 and Supplementary Fig. 2, we employed the same experimental setting. For CIFAR-100, the\ntask sequence T = 10, with each task comprising 10 randomly selected classes. For CUB-200-2011, the\ntask sequence T = 10, and each task has 20 classes. For VTAB, the task sequence_ T = 5, and each task\nhas 10 classes.\""}, {"title": "Mathematical Formula", "content": "We traced the process of forward propagation and backward propagation to demonstrate how the Fly Model operates from a mathematical perspective. Assume we have a feature x \u2208 R input to the Fly Model, it is\nthen transformed to a higher dimension feature h\u2208 Rm where m \u00bb n using a binary, sparse random\nmatrix WpK \u2208 Rm\u00d7n through_h = Wp\u2192KX. In each row of Wp\u2192k, k \u00abn_random columns are set to 1,\nwhile the remaining columns are set to 0. During the learning process, Wp\u2192K is not updated. The high-dimensional feature h is then inhibited by a top-k operation top-k(x) : Rm \u2192 Rm, with only m \u00d7 k <\nm dimensions with the strongest activations are retained, and the remaining dimensions are reset to 0. This can be formulated as z\u2208 Rm satisfying_z = top-k(h). After the top-k operation, z is projected to output\nneurons for classification o = WK\u2192MZ, where o\u2208 R and Wk\u2192\u043c \u2208 Rcxm. Unlike WpK, WKM is updated through backpropagation. Assume the loss function is L(0,y), y is the ground truth label, the synaptic weights in WK\u2192M are updated by:\nWij \u2190 Wij \u2013 learning_rate \u00d7$\\frac{\\partial L(o,y)}{\\partial W_{ij}}$ where\n$\\frac{\\partial (\\frac{\\partial L(o, y)}{\\partial W_{ij}},}{\\partial W_{ij}},\\quad\\quad$if the j-th dimension is activated in z,\n0, if the j-th dimension is not activated in z.\nThis means that most parameters in WK\u2192M are not updated.\nAngle Between Two Random Vectors\nIn an n-dimensional space, the probability density function of the angle between two random vectors is:\n\u03c1n(\u03b8) =$\\frac{\\Gamma(\\frac{n}{2})}{\\Gamma(\\frac{n-1}{2})\\pi^{-\\frac{1}{2}}}\\text{sinn}^{\\text{n-1}}\\text{ 0.}$\nThe variance of the angle distributions is:\nVarn(0) =$\\frac{\\Gamma(\\frac{n-1}{2})}{\\Gamma(\\frac{n}{2})\\sqrt{2pi}}$(0-$\\frac{\\pi}{2}$)$\\text{sinn}^{\\text{n-2}}\\text{ 0d0,}$\nwhich decreases as n increases. Thus, higher dimensions increase the probability that two vectors become\northogonal."}, {"title": "Probability of Each KC Connecting to Different Set of PNs", "content": "This is a variant of the well-known \"birthday problem\" [46], which can be calculated using combinatorial numbers. We assume that the PN layer has n neurons, the KC layer has m neurons and the synaptic degree\nis r. We can denote_R = C. Therefore, the probability is given by:\np = $\\frac{R!}{(R-m)!R^m}$\nMore Orthogonal Gradients Have Less Forgetting\nWe denote Lt(w) as gradient at task t. Then we can derive the following theorem:\nTheorem 1 [52]: Let w' = w \u2013 \u03b7\u2207Lt(w), Then there exists \u03be\u2208 [0,1] such that \u2207L\u2081(w) \u2013 VL\u2081(w') =\n\u2212\u03b7 < VL\u2081(w \u2013 \u03be\u03b7\u2207Lt(w)), VL\u2081(w) >.\nObviously, the left side of the equation increases, leading to forgetting. The right side of the equation\nrepresents the inner product of the two gradients. Therefore, if the two gradients are more orthogonal to\neach other, the inner product decreases, and the neural network forgets less about the previous tasks."}, {"title": "Network Architecture", "content": "For the pre-trained model Vision Transformer, we used the Vit B/16-IN21K version across all experiments. We integrated the Fly Model with several multilayer perceptrons for testing.\nIn Figs. 2, 4-5 and Supplementary Fig. 3, we used the simplest Fly Model consisting of three layers.\nIn Fig. 6a, we prepended two linear layers to the Fly Model, with a hidden dimension of 784 (matching the dimension of MNIST images) and ReLU as the activation function between these layers.\nIn Fig. 6b, we added one linear layer compared to the network in Fig. 4, with the hidden dimension set\nto 100.\nIn Supplementary Fig. 2, we used the same architecture as Fig. 6a, but the hidden dimension is 768 (the same as the output dimension of the Vision Transformer)."}, {"title": "Compared Baseline", "content": "Apart from the original SGD, we choose two forgetting-targeted methods EWC, SI and three plasticity-targeted methods Shrink and Perturb (S&P), L2 Init, and Continual Backpropagation (CBP) for comparison.\nElastic Weight Consolidation (EWC) [6] is one of the most classical CL methods. It uses the Fisher\ninformation matrix to record the weights important for old tasks and protects them through a regularization term during parameter updates. Let Ltrain(0) be the loss function for new tasks, F be the Fisher\ninformation matrix, a be the regularization coefficient, \u03b8i and 01:t-1,i be the current and previous parameters, respectively. The EWC loss is defined as:\nLEWC(0) = Ltrain(0) +$\\frac{1}{2} \\sum_i F_{1:t-1, ii} ( \\theta_i - \\theta_{1:t-1, i})^2.$\nSynaptic Intelligence (SI) [9] is similar to EWC but has lower complexity, reducing the task of maintaining an O(n\u00b2) Fisher information matrix to O(n) importance weights for each parameter. Additionally, it has\nbetter biological interpretability. The SI loss is defined as:\nLS1(0) = Ltrain(0) + c \u03a3\u03ba\u03a9(\u03b8\u03ba \u2013 0)2,"}, {"title": null, "content": "where$\\Omega_{k}=\\frac{w^*_k}{(\\Delta w_k^l)^2 + \\xi}$ denotes the importance of the parameter. c is the regularization coefficient.\nShrink and Perturb (S&P) [28] imposes perturbations by first slightly shrinking the network's weights and\nthen adding a small-scale perturbation from randomly initialized parameter at the end of each task. Here,\nshrink and perturb are small numeric numbers. The modified weight is:\nw = (1 \u2013 shrink) \u00d7 w\u2081 + perturb \u00d7 wi.\nL2 Init [29] imposes a regularization term on the network weights during the training process, constraining their distance from the randomly initialized weights. Let Ltrain(0) be the loss function of the task, o be\nthe initial parameters, and a be the regularization coefficient. The regularized loss is:\nLreg(0) = Ltrain(0) + \u03b1||\u03b8 \u2013 \u03b8\u03bf|\nContinual Backpropagation (CBP) [5] tracks the utility measure for each neuron and periodically reinitializes the subset of weights that have the smallest utility values. The utility is calculated as:\nu\u2081[i] = \u03b7 \u00d7 u\u2081[i] + (1 \u2212 \u03b7) \u00d7$\\frac{1}{2+1}\\sum_{k=1}^{K_{l+1}}$ |wli,k,t|\nwhere hi,it is the output of the i-th neuron in in layer l at time t, and Wli,k,t is the weight connecting\nthe i-th neuron of layer I and the k-th neuron of layer 1+1 at time t + 1.\nEvaluation Metric\nTo evaluate performance under CIL setting, we mainly used the following metrics: average accuracy (At),\naccumulated accuracy (At), backward transfer (BWTt) and forward transfer (FWTt)\nAt =$\\frac{1}{t}$ \u03a3i=1 ai,i,\n$\\overline{A_t}$ =$\\frac{1}{t} \\sum_{i=1}^t A_i,$\nBWTt =$\\frac{1}{t-1}\\sum_{i=1}^{t-1} (a_{t,i}-a_{i,i}),$\nFWTt =$\\frac{1}{t-1}\\sum_{i=2}^t(a_{i,i}-a_i),$\nwhere ati is the test accuracy of task i after learning taskt, and \u00e3\u00a1 is the test accuracy of task i when learned directly from a randomly initialized network.\nThroughout the process, At can be viewed as the performance of CL at each stage. \u0100t can be regarded as\nthe average accumulated performance before task t. BWTt measures how much of the previously learned tasks is forgotten after learning task t, representing the degree of catastrophic forgetting. FWTt measures the performance decrement for each newly learned class relative to learning from scratch, which indicates\nplasticity loss.\nFor the streaming learning setting, we mainly focused on plasticity loss. This can be measured by average\nonline accuracy, dormant units, stable rank, and average weight magnitude. Their specific forms are listed\nbelow.\naverage online accuracy =$\\frac{1}{N_i}$ \u03a3j=1 ai,j,\nwhere Ni is the number of data batches in task i, and aij is the average accuracy of the j-th batch.\ndormant units =$\\frac{1}{M}$$\\sum_{i=1}^M 1(a_i < \\delta),$ where ai is the activation value of each neuron in the network (with M neurons), and 8 = 0.01 is the\nthreshold. Smaller activation values can lead to gradients tending toward zero during backpropagation,\nmaking it difficult for the weights to be updated and results in plasticity loss.\nstable rank =$\\min_k [\\sum_{i=1}^k/ \\sigma_i] \rgeq 1 - \\delta,$ \n\u03ba \u03a3\u03af=1 \u03c3\u03b7\nwhere \u03c3\u2081 are singular values of the preceding linear layer of the Fly Model, sorted as \u03c3\u2081 > \u03c32 > \u2026 > \u03c3\u03b7\u00b7\nFollowing [29, 56], we use 8 = 0.01 as threshold. A low stable rank indicates that only a small number of dimensions are needed to represent most of the information in the matrix, suggesting that many units in the hidden layer do not provide effective output, which is a sign of plasticity loss.\naverage weight magnitude =$\\frac{1}{M}\\sum i w_i,$\nwhere wi is the weight value of each neuron (with M neurons). The magnitude of the network's weights\nis related to the condition number of the Hessian matrix in the second-order Taylor expansion of the loss function. An increase in network weights may lead to a pathological Hessian matrix. According to convex\noptimization theory, this can slow down the convergence speed of the SGD algorithm, requiring a longer time for the neural network to converge [53]."}, {"title": "Implementation Detail", "content": "We used grid search to find the optimal hyperparameters for each experiment. The best parameters are summarized in Supplementary Table 1. All results were averaged over 5 runs using different random seeds. Additionally, we used gradient clipping to avoid gradient explosion if necessary.\nData availability\nAll datasets analyzed in this study are freely available online resources.\nCode availability\nCode that can be used to reproduce the main results of this paper will be available on github."}]}