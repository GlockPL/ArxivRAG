{"title": "NOT-SO-OPTIMAL TRANSPORT FLOWS FOR\n3D POINT CLOUD GENERATION", "authors": ["Ka-Hei Hui", "Chao Liu", "Xiaohui Zeng", "Chi-Wing Fu", "Arash Vahdat"], "abstract": "Learning generative models of 3D point clouds is one of the fundamental prob-\nlems in 3D generative learning. One of the key properties of point clouds is their\npermutation invariance, i.e., changing the order of points in a point cloud does not\nchange the shape they represent. In this paper, we analyze the recently proposed\nequivariant OT flows that learn permutation invariant generative models for point-\nbased molecular data and we show that these models scale poorly on large point\nclouds. Also, we observe learning (equivariant) OT flows is generally challeng-\ning since straightening flow trajectories makes the learned flow model complex\nat the beginning of the trajectory. To remedy these, we propose not-so-optimal\ntransport flow models that obtain an approximate OT by an offline OT precompu-\ntation, enabling an efficient construction of OT pairs for training. During training,\nwe can additionally construct a hybrid coupling by combining our approximate\nOT and independent coupling to make the target flow models easier to learn. In\nan extensive empirical study, we show that our proposed model outperforms prior\ndiffusion- and flow-based approaches on a wide range of unconditional generation\nand shape completion on the ShapeNet benchmark.", "sections": [{"title": "1 INTRODUCTION", "content": "Generating 3D point clouds is one of the fundamental problems in 3D modeling with applications\nin shape generation, 3D reconstruction, 3D design, and perception for robotics and autonomous\nsystems. Recently, diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020) and flow match-\ning (Lipman et al., 2022) have become the de facto frameworks for learning generative models for\n3D point clouds. These frameworks often overlook 3D point cloud permutation invariance, implying\nthe rearrangement of points does not change the shape that they represent.\nIn closely related areas, equivariant optimal transport (OT) flows (Klein et al., 2024; Song et al.,\n2024) have been recently developed for 3D molecules that can be considered as sets of 3D atom\ncoordinates. These frameworks learn permutation invariant generative models, i.e., all permutations\nof the set have the same likelihood under the learned generative distribution. They are trained using\noptimal transport between data and noise samples, yielding several key advantages including low\nsampling trajectory curvatures, low-variance training objectives, and fast sample generation (Poola-\ndian et al., 2023). Albeit these theoretical advantages, our examination of these techniques for 3D\npoint cloud generation reveals that they scale poorly for point cloud generation. This is mainly due\nto the fact that point clouds in practice consist of thousands of points whereas molecules are as-\nsumed to have tens of atoms in previous studies. Solving the sample-level OT mapping between a\nbatch of training point clouds and noise samples is computationally expensive. Conversely, ignoring\npermutation invariance when solving batch-level OT (Pooladian et al., 2023; Tong et al., 2023) fails\nto produce high-quality OT due to the excessive possible permutations of point clouds.\nIn this paper, we propose a simple and scalable generative model for 3D point cloud generation\nusing flow matching, coined as not-so-optimal transport flow matching, as shown in Fig 1. We\nfirst propose an efficient way to obtain an approximate OT between point cloud and noise samples.\nInstead of searching for an optimal permutation between point cloud and noise samples online during\ntraining, which is computationally expensive, we show that we can precompute an OT between a\ndense point superset and a dense noise superset offline. Since subsampling a superset preserves the"}, {"title": "2 RELATED WORKS", "content": "Score-based Generative Models. Recently, diffusion models (Sohl-Dickstein et al., 2015; Ho et al.,\n2020; Song & Ermon, 2019) have gained popularity in generating data of various formats, especially\nimages (Rombach et al., 2022; Ramesh et al., 2022) and videos (Blattmann et al., 2023; Brooks et al.,\n2024). These generative models employ an iterative process to transform a known distribution,"}, {"title": "3 METHOD", "content": "In Section 3.1, we begin by covering preliminaries of training a continuous normalizing flow and\nrecent OT flows. Section 3.2 explores the challenges of applying existing OT approximation meth-\nods to 3D point clouds. To tackle these challenges, we introduce our approximate OT approach in\nSection 3.3 that precomputes OT maps in an offline fashion, and in Section 3.4, we explore a simple\nhybrid and less optimal coupling approach that makes target flows easier to learn.\n3.1 PRELIMINARIES\nContinuous Normalizing Flow (CNF) (Chen et al., 2018) morph a base Gaussian distribution q0\ninto a data distribution q\u2081 using a time-variant vector field ve,t : [0, 1] \u00d7 Rd \u2192 Rd, parameterized\nby a neural network \u03b8. The mapping is obtained from an ordinary differential equation (ODE):\n$\\frac{d}{dt}Xt = Vot(xt).$\nConceptually, the ODE transports an initial sample xo ~qo, where xo \u2208 Rd with pt denoting\nthe distribution of samples at step t and po(x) := qo(x). Usually, the vector field ve,t is trained to\nmaximize the likelihood p\u2081 assigned to training data samples x1 from distribution q1. This procedure\nis computationally expensive due to extensive ODE simulation for each parameter update.\nFlow Matching (Lipman et al., 2022) avoid the computationally expensive simulation process for\ntraining CNFs. In particular, we define a conditional vector field ut(\u00b7|\u00d71) and path pt(x1) that\ntransform qo into a Dirac delta at x\u2081 at t = 1. Lipman et al. (2022) show that ve,t can be learned via\na simple conditional flow matching (CFM) objective:\n$LCFM = Et,91(\u00d71),90(x0)||Vo,t(xt) - ut(xt|x1)||\u00b2.$\nA common choice for the conditional vector field is ut(x|x\u2081) := $\\frac{X1 - x0}{1}$, which can be easily\nsimulated by linearly interpolating the data and Gaussian samples via xt = (1 - t) * x0 + tx1."}, {"title": "3.2 EXISTING OT APPROXIMATION FOR POINT CLOUD GENERATION", "content": "We focus on generating 3D shapes represented as point clouds. A point cloud x1 \u2208 RN\u00d73 is a set of\npoints sampled from the surface of a shape S, where N is the number of points. Unlike 2D images,\npoint clouds have unique properties that pose challenges for existing OT methods:\n(i) Permutation Invariance. A point cloud, while arranged in a matrix form, is inherently a set.\nShuffling points in x1 should represent the same shape. Mathematically, given a permutation matrix\np(g), the sampling probability remains unchanged, i.e., q1 (p(g)\u00d71) = 91(X1).\n(ii) Dense Point Set. Point clouds are finite samples on surfaces. However, similar to low-resolution\nimages, sparse point sets may miss fine geometric structures and details. Thus, most works use dense\npoint sets (say N > 2048) to accurately capture 3D shapes.\nExisting approach to estimating OT maps face these challenges on point clouds:"}, {"title": "3.3 OUR OT APPROXIMATION", "content": "A simple approach to generate training point clouds is to re-sample the points from the object surface\nin each training iteration. However, most point cloud generation methods avoid this tedious online\nsampling by pre-sampling a dense point superset X1 \u2208 RM\u00d73 with M >> N. During training,\nrandom subsets of X\u2081 are selected as training targets. This procedure converges to the true sam-\npling distribution, following a straightforward extension of the law of large numbers (see Appendix\nproposition 1 for details). In a similar spirit, we compute an offline OT map between a dense point"}]}