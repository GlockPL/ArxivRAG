{"title": "ReFocus: Reinforcing Mid-Frequency and Key-Frequency Modeling for Multivariate Time Series Forecasting", "authors": ["Guoqi Yu", "Yaoming Li", "Juncheng Wang", "Xiaoyu Guo", "Angelica I. Aviles-Rivero", "Tong Yang", "Shujun Wang"], "abstract": "Recent advancements have progressively incorporated frequency-based techniques into deep learning models, leading to notable improvements in accuracy and efficiency for time series analysis tasks. However, the Mid-Frequency Spectrum Gap in the real-world time series, where the energy is concentrated at the low-frequency region while the middle-frequency band is negligible, hinders the ability of existing deep learning models to extract the crucial frequency information. Additionally, the shared Key-Frequency in multivariate time series, where different time series share indistinguishable frequency patterns, is rarely exploited by existing literature. This work introduces a novel module, Adaptive Mid-Frequency Energy Optimizer, based on convolution and residual learning, to emphasize the significance of mid-frequency bands. We also propose an Energy-based Key-Frequency Picking Block to capture shared Key-Frequency, which achieves superior inter-series modeling performance with fewer parameters. A novel Key-Frequency Enhanced Training strategy is employed to further enhance Key-Frequency modeling, where spectral information from other channels is randomly introduced into each channel. Our approach advanced multivariate time series forecasting on the challenging Traffic, ECL, and Solar benchmarks, reducing MSE by 4%, 6%, and 5% compared to the previous SOTA iTransformer. Code is available at this GitHub Repository:", "sections": [{"title": "1. Introduction", "content": "Accurate forecasting of time series offers reference for decision-making across various domains, including weather, economics, and energy. Especially, long-term multivariate time series forecasting (LMTSF) emerges as a prominent area of interest in academic research and industrial applications, offering the advantage of capturing complex interdependencies and trends across multiple variables.\nRecently, the powerful representation capabilities of neural networks, such as Multi-Layer perception (MLPs), Transformers, and Temporal Convolution Network (TCNs), have significantly advanced deep learning-based LMTSF. These approaches can be broadly categorized into two/three folds: time-domain-based and frequency-domain-based methods, or mixed time & frequency. Time-domain methods are intuitive, handling nonlinearity and non-periodic signals directly from the raw sequence using Transformers, TCN, or MLP. The latest study highlights that time-domain forecasters face challenges such as vulnerability to high-frequency noise, and computational inefficiencies. While frequency-domain-based methods usually transform the time-domain data to the frequency spectrum by Fast Fourier transform (FFT). Then other operations (Self-attention, Linear mapping, etc.) are employed to extract frequency information. These methods benefit from advantages such as computational efficiency, periodic patterns extracting, and energy compaction.\nHowever, existing frequency-domain-based forecasters usually face TWO significant challenges when dealing with real-world long-term time series: the Mid-Frequency Spec-"}, {"title": "2. Related work", "content": "Advancement in Recent Deep Learning-based Time Series Forecasting\nRecent advancements in deep learning-based time series forecasting can be broadly categorized into three key areas: (1) the application of sequential models to time series data, (2) the tokenization of time series, and (3) the exploration of intrinsic patterns within time series. Efforts in the first area have focused on deploying various architectures for time series forecasting, including Transformer, Mamba, MLPs, RNNs, Graph Neural Networks, TCNs, and even Large Language Models (LLMs).\nThe second direction has witnessed groundbreaking developments, particularly in Patch Embedding and Variate Embedding. The final area explores modeling complex relationships, including the inter-series dependencies, the dynamic evolution within a sequence, or both.\nTime Series Modeling with Frequency\nFrequency as a key feature of time series data, has inspired numerous works. FITS employs a simple frequency-domain linear, getting results comparable to SOTA models with 10K parameters. Autoformer introduces the auto-correlation mechanism, leveraging FFT to improve self-attention. FEDformer further calculates attention weights from the spectrum of queries and keys. FiLM applies Fourier analysis to preserve historical information while filtering out noise. FreTS incorporates frequency-domain MLP to model both channel and temporal dependencies. TimesNet utilizes FFT to extract periodic patterns. FilterNet proposes a filter-based method from the perspective of signal processing.\nHowever, they do not address the Mid-Frequency Spectrum Gap and shared Key-Frequency modeling. In contrast, our method employs 'Adaptive Mid-Frequency Energy Optimizer' to improve mid-frequency feature extraction and introduces 'Energy-based Key-Frequency Picking Block' with 'Key-Frequency Enhanced Training' strategy to capture shared Key-Frequency across channels."}, {"title": "3. Methodology", "content": "3.1. Problem Definition\nGiven a multivariate time series input \\(X \\in \\mathbb{R}^{C\\times T}\\), multivariate time series forecasting tasks are designed to predict\nits future F time steps \\(\\hat{Y} \\in \\mathbb{R}^{C\\times F}\\) using past T steps. C is the number of variates or channels.\n3.2. Preliminary Analysis\nThis section presents why RevIN, High-pass, and Low-pass filters fail to address the Mid-Frequency Spectrum Gap. Let the input univariate time series be \\(x(t)\\) with length T and target \\(y(t)\\) with length F.\nDefinition 3.1 (Frequency Spectral Energy). The Fourier transform of \\(x(t)\\), \\(X(f)\\), and its spectral energy \\(E_x(f)\\) is given by:\n\\(X(f) = \\sum_{t=0}^{T-1} x(t) e^{-i2\\pi ft/T-1}, f = 0,1,..., T - 1\\)\n\\(E_x(f) = |X(f)|^2. \\qquad (1)\\)\nImpact of RevIN on Frequency Spectrum\nDefinition 3.2 (Reversible Instance Normalization). Given a forecast model \\(f : \\mathbb{R}^{T} \\rightarrow \\mathbb{R}^{F}\\) that generates a forecast \\(\\hat{y}(t)\\) from a given input \\(x(t)\\), RevIN is defined as:\n\\(\\tilde{x}(t) = \\frac{x(t) - \\mu}{\\sigma}, t = 0, 1, ..., T - 1\\)\n\\(\\hat{y}(t) = f(\\tilde{x}(t)), \\hat{y}(t)_{rev} = \\hat{y}(t) \\cdot \\sigma + \\mu,\\)\n\\(\\mu = \\frac{1}{T}\\sum_{t=0}^{T-1}x(t), \\qquad \\sigma = \\sqrt{\\frac{1}{T}\\sum_{t=0}^{T-1}(x(t) - \\mu)^2}. \\qquad (2)\\)\nTheorem 3.3 (Frequency Spectrum after RevIN). The spectral energy of \\(\\tilde{x}(t)\\) (transformed using RevIN):\n\\(E_{\\tilde{x}}(0) = 0, f = 0,\\)\n\\(E_{\\tilde{x}}(f) = (\\frac{1}{\\sigma})^2 |X(f)|^2, f = 1, 2, ..., T - 1. \\qquad (3)\\)\nThe proof is in Appendix A.1. Theorem 3.3 suggests that RevIN scales the absolute spectral energy by \\(\\sigma^2\\) but does not affect its relative distribution except \\(E_{\\tilde{x}}(0) = 0\\). Thus, RevIN preserves the relative spectral energy distribution and leaves the Mid-Frequency Spectrum Gap unresolved. However, our experiments still employ RevIN to ensure a fair comparison with other baselines.\nImpact of High- and Low-pass filter\nWe still define \\(x(t)\\) to be the filtered (processed) signal, obtained by applying a filter \\(H(f)\\) (High/Low-pass filter). The filter \\(H(f)\\) is 1 in the passband (High/Low frequency) and 0 in the stopband (Middle frequency). So \\(E_x(f) = 0, E_x \\leq E_x(f)\\) for middle frequencies, which creates even larger gap.\n3.3. Overall Structure of The Proposed ReFocus\nIn this section, we elucidate the overall architecture of Re-Focus, depicted in Figure 2. We define frequency domain"}, {"title": "3.4. Key-Frequency Enhanced Training strategy", "content": "In real-world time series, certain channels often exhibit spectral dependencies, which may not be fully captured in the training set, and the specific channels with such dependencies are also unknown. So this work borrows insight from recent advancement of mix-up in time series, randomly introducing spectral information from other channels into each channel, to enhance the extraction of the shared Key-Frequency, as in Figure 3. Given a multivariate time series input \\(X \\in \\mathbb{R}^{C\\times T}\\) and its ground-truth \\(Y \\in \\mathbb{R}^{C\\times F}\\), we generate a pseudo sample pair:\n\\(X' = iFFT(FFT(X) + \\alpha \\cdot FFT(X[perm, :])),\\)\n\\(Y' = iFFT(FFT(Y) + \\alpha \\cdot FFT(Y[perm, :])). (6)\\)\n\\(\\alpha \\in \\mathbb{R}^{C\\times 1}\\) is a weight vector sampled from a normal distribution, perm is a reshuffled channel index. Since FFT and iFFT are linear operations, this mix-up process can be equivalently simplified in the Time Domain:\n\\(X' = X + \\alpha \\cdot X [perm, :],\\)\n\\(Y' = Y + \\alpha \\cdot Y [perm, :] (7)\\)\nWe alternate training between real and synthetic data to preserve the spectral dependencies in real samples. This combines the advantages of data augmentation, such as improved generalization, while mitigating potential drawbacks like over-smoothing and training instability."}, {"title": "4. Experiments", "content": "4.1. Experimental Settings\nThis section first introduces the whole experiment settings under a fair comparison. Secondly, we illustrate the experiment results by comparing ReFocus with the TEN well-acknowledged baselines. Further, we conducted an ablation study to comprehensively investigate the effectiveness of the 'Adaptive Mid-Frequency Energy Optimizer' (AMEO), 'Energy-based Key-Frequency Picking Block' (EKPB), and 'Key-Frequency Enhanced Training strategy' (KET).\nWe conduct extensive experiments on selected Eight widely-used real-world multivariate time series forecasting datasets, including Electricity Transformer Temperature (ETTh1, ETTh2, ETTm1, and ETTm2), Electricity, Traffic, Weather used by Autoformer, and Solar Energy datasets proposed in LSTNet.\nFor a fair comparison, we follow the same standard protocol and split all forecasting datasets into training, validation, and test sets by the ratio of 6:2:2 for the ETT dataset and 7:1:2 for the other datasets. The characteristics of these datasets are shown in Table 1 (More can be found in the Appendix).\nEvaluation protocol Following TimesNet, we use Mean Squared Error (MSE) and Mean Absolute Error (MAE) for the evaluation. We follow the same"}, {"title": "4.2. Experiment Results", "content": "Quantitative comparison\nComprehensive forecasting results are listed in Table 2. We leave full forecasting results in APPENDIX to save place. It is quite evident that ReFocus has demonstrated superior predictive performance across all datasets, significantly outperforming the second-best method. Especially, Compared to the previous SOTA iTransformer, we have reduced the MSE by 4%, 6%, and 5% on the three most challenging benchmarks: Traffic, ECL, and Solar, respectively, indicating a significant breakthrough. These significant improvements indicate that the ReFocus model possesses robust performance and broad applicability in multivariate time series forecasting tasks, especially in tasks with a large number of channels, such as the Solar Energy dataset (137 channels), ECL dataset (321 channels), and Traffic dataset (862 channels)."}, {"title": "4.3. Model Analysis", "content": "Ablation study of AMEO and KET\nTo evaluate the contributions of each module in ReFocus, we performed ablation studies on the 'Adaptive Mid-Frequency Energy Optimizer (AMEO)' and the \u2018Key-Frequency Enhanced Training (KET)' strategy. The results are summarized in Table 3. Notably, integrating both modules achieves the best performance, highlighting the effectiveness of their synergy. Additionally, each module delivers substantial improvements over baseline models in most cases.\nFurther study of KET\nWe conducted further ablation studies on the KET to demonstrate the importance of alternate training between real and synthetic data. The experimental results in Table 4 reveal that while training on pseudo samples can partially enhance the model's generalization performance on the test set, it also tends to cause over-smoothing and training instability on more complex datasets, such as Solar Energy. In contrast, training on real and synthetic data alternatively (KET) improves generalization and mitigates over-smoothing and training instability by preserving the spectral dependencies of real samples. More Analyses are in Appendix C.\nAblation study of different Key-Frequency Picking strategy\nWe conducted an ablation study on various key-frequency selection strategies. The evaluated methods include Maximum-based, Minimum-based, and Softmax-based random sampling strategies. Our experimental results in Table 5 reveal that purely relying on Maximum or Minimum-based strategies may overlook certain critical Key-Frequency. In contrast, the random sampling strategy based on a Softmax probabilistic distribution consistently achieved the best overall performance, particularly on datasets with a larger number of channels and higher complexity-key challenges in multivariate time series forecasting.\nOutstanding inter-series modeling ability of the EKPB\nWe compared 'Energy-based Key-Frequency Picking Block' (EKPB) with several well-established backbones, including iTransformer, TSMixer, and Crossformer, which have demonstrated exceptional performance in modeling inter-series dependencies. Additionally, we included FECAM, a method also designed for modeling cross-channel frequency-domain dependencies. The results presented in Table 6 demonstrate that our EKPB outperforms in modeling inter-series dependencies across multiple datasets. Additionally, when comparing the number of parameters and inference time during prediction under identical configurations on the ECL dataset, our EKPB method still outperforms other baselines by a significant margin, as in Table 7. To illustrate EKPB's functionality, we visualize the series embeddings with and without its adjustment in Figure 5. The T-SNE visualization of the series embeddings shows that without EKPB, using only the channel-independent strategy, the MSE is 0.171. After applying EKPB, channels sharing Key-Frequency (variates 2&3) are clustered, while others (variates 1&3) are separated. This adjustment improves the MSE from 0.171 to 0.145, a 15% reduction. These indicate that EKPB not only achieves better predictive performance"}, {"title": "5. Conclusion", "content": "This work addresses two critical challenges in multivariate time series forecasting: the Mid-Frequency Spectrum Gap and the efficient modeling of the shared Key-Frequency. We propose the 'Adaptive Mid-Frequency Energy Optimizer', which effectively enhances mid-frequency extraction, and the 'Energy-based Key-Frequency Picking Block' with the 'Key-Frequency Enhanced Training' strategy, which efficiently captures shared frequency patterns. Extensive experiments demonstrate the superiority of our approach, achieving up to 6% MSE reduction on challenging benchmarks, thus advancing the SOTA in frequency-domain forecasting."}, {"title": "A. Proof", "content": "This section is dedicated to proving Theorem 3.3 and Theorem 3.5.\nA.1. Impact of RevIN on Frequency Spectrum\nRevIN normalizes inputs using sample-wise mean and variance, then reverts scaling post-prediction to ensure consistent distributions, mitigating non-stationary effects in time series.\nLet the original time series be \\(x(t)\\) with length T. The series \\(\\tilde{x}(t)\\) that processed by RevIN is given by:\n\\(\\tilde{x}(t) = \\frac{x(t) - \\mu}{\\sigma}, t = 0, 1, ..., T - 1,\\)\n\\(\\mu = \\frac{1}{T}\\sum_{t=0}^{T-1}x(t), \\qquad \\sigma = \\sqrt{\\frac{1}{T}\\sum_{t=0}^{T-1}(x(t) - \\mu)^2}. (8)\\)\nThe Fourier transform of \\(x(t)\\) and \\(\\tilde{x}(t)\\) are:\n\\(X(f) = \\sum_{t=0}^{T-1} x(t) e^{-i2\\pi ft/T-1}, f = 0,1, ..., T - 1,\\)\n\\(\\tilde{X}(f) = \\sum_{t=0}^{T-1} \\frac{x(t) - \\mu}{\\sigma} e^{-i2\\pi ft/T-1}\\)\n\\(= \\frac{1}{\\sigma}\\sum_{t=0}^{T-1}x(t)e^{-i2\\pi ft/T-1} - \\frac{\\mu}{\\sigma}\\sum_{t=0}^{T-1}e^{-i2\\pi ft/T-1}. (9)\\)\nThe spectral energy is computed as the squared magnitude of the Fourier transform. For \\(x(t)\\) and \\(\\tilde{x}(t)\\), we have:\n\\(E_x(f) = |X(f)|^2, E_{\\tilde{x}}(f) = |\\tilde{X}(f)|^2. (10)\\)\nWhen f = 0, the exponential term \\(e^{-i2\\pi ft/T-1} = 1\\), so:\n\\(\\frac{\\mu}{\\sigma}\\sum_{t=0}^{T-1}e^{-i2\\pi ft/T-1} = \\frac{\\mu T}{\\sigma} = 0 \\qquad (11)\\)\nSince \\(\\frac{\\mu}{\\sigma}\\) is a constant, we have:\n\\(\\frac{\\mu}{\\sigma}\\sum_{t=0}^{T-1}e^{-i2\\pi ft/T-1} = 0, f = 1, 2 ...,T - 1,\\)\n\\(\\tilde{X}(f) = \\frac{1}{\\sigma}\\sum_{t=0}^{T-1}x(t)e^{-i2\\pi ft/T-1} - \\frac{\\mu}{\\sigma}\\sum_{t=0}^{T-1}e^{-i2\\pi ft/T-1}\\)\n\\(= \\frac{1}{\\sigma}X(f),\\)\n\\(E_{\\tilde{x}}(f) = (\\frac{1}{\\sigma})^2 |X(f)|^2. (12)\\)\nThis suggests that RevIN scales the spectral energy by \\(\\frac{1}{\\sigma^2}\\) but does not affect its relative distribution except \\(\\tilde{X}(0) = 0\\). Thus, RevIN preserves the relative spectral energy distribution and leaves the Mid-Frequency Spectrum Gap unresolved.\nA.2. Impact of AMEO on Frequency Spectrum\nReferring back to Definition 3.4, AMEO is defined as:\n\\(\\tilde{x}(t) = x(t) - \\frac{\\beta}{K} \\sum_{k=0}^{K-1}x(t + K - 1 - k),\\)\n\\(x(t) = \\begin{cases} \\tilde{x}(t-(\\frac{K}{2} + 1)), & \\text{if } \\frac{K}{2} + 1 \\leq t < T + \\frac{K}{2} + 1 \\\\ 0, & \\text{if } 0 \\leq t < \\frac{K}{2} + 1 \\text{ or } T + \\frac{K}{2} + 1 < t < T + K \\end{cases}. (13)\\)\nThe Fourier transform of \\(\\tilde{x}(t)\\) is:\n\\(\\tilde{X}(f) = \\sum_{t=0}^{T-1} x(t) e^{-i2\\pi ft/T-1} - \\frac{\\beta}{K} \\sum_{t=0}^{T-1} \\sum_{k=0}^{K-1}(t + K - 1 - k)e^{-i2\\pi ft/T-1}\\)\n\\(= X(f) - \\frac{\\beta}{K} \\sum_{k=0}^{K-1} \\sum_{t=0}^{T-1}x(t + K - 1 - k)e^{-i2\\pi ft/T-1}.\\)\\(= X(f) - \\frac{\\beta}{K} \\sum_{k=0}^{K-1} T_k(f). \\qquad (14)\\)\nFor \\(T_k(f)\\), given FFT\\({x(t - a)}\\) = \\(X(f)e^{-i2\\pi fa/T-1}\\), we have:\n\\(T_k(f) = \\sum_{t=0}^{T-1} x(t + K - 1 - k) e^{-i2\\pi ft/T-1}\\)\n\\(= \\sum_{t=0}^{T-1} x(t + \\frac{3K}{2} - k - \\frac{3K}{2}) e^{-i2\\pi ft/T-1}\\)\n\\(= FFT{x(t + \\frac{3K}{2} - k - \\frac{3K}{2})}\\)\n\\(= X(f) e^{i2f(\\frac{3K}{2} - k - \\frac{3K}{2})/T-1}. (15)\\)"}]}