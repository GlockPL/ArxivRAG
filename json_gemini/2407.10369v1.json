{"title": "A Robust Governance for the AI Act: AI Office, AI Board, Scientific Panel, and National Authorities", "authors": ["Claudio Novelli", "Philipp Hacker", "Jessica Morley", "Jarle Trondal", "Luciano Floridi"], "abstract": "Regulation is nothing without enforcement. This particularly holds for the dynamic field of emerging technologies. Hence, this article has two ambitions. First, it explains how the EU's new Artificial Intelligence Act (AIA) will be implemented and enforced by various institutional bodies, thus clarifying the governance framework of the AIA. Second, it proposes a normative model of governance, providing recommendations to ensure uniform and coordinated execution of the AIA and the fulfilment of the legislation. Taken together, the article explores how the AIA may be implemented by national and EU institutional bodies, encompassing longstanding bodies, such as the European Commission, and those newly established under the AIA, such as the AI Office. It investigates their roles across supranational and national levels, emphasizing how EU regulations influence institutional structures and operations. These regulations may not only directly dictate the structural design of institutions but also indirectly request administrative capacities needed to enforce the \u0391\u0399\u0391.", "sections": [{"title": "1. Introduction", "content": "The effective implementation of the Artificial Intelligence Act (AIA) throughout the European Union (EU) depends on a uniform, coordinated, and well-funded governance setting. This is especially important given the increasing need for harmonized regulatory application in the digital sector, as emphasized by EU policymakers due to the numerous laws already enacted (Tar 2024). For this purpose, the AIA, notably in Chapter VII (\u2018Governance'), underscores the role of different institutional bodies, supranational and national, such as the AI Office, the European AI Board, the Advisory Forum, the Scientific Panel, and (two) national competent authorities in each Member State. Close coordination between these bodies is crucial for implementing and enforcing the AIA's rules across all Member States. This interaction should also guarantee compatibility with other EU regulations to avoid redundancy and antinomies.\nThis article explores how the AIA may be implemented by the EU institutional bodies, encompassing longstanding bodies, such as the European Commission (Commission), and those newly established under the AIA, such as the AI Office. It investigates their roles across supranational and national levels, emphasizing how EU regulations influence institutional structures and operations. These regulations may not only directly dictate the structural design of institutions but also indirectly request administrative capacities needed to enforce the AIA.\nThese deliberations share an important dynamic aspect: bodies enforcing the AIA will be tasked with overseeing activities in various sectors, due to the rapidly expanding reach of AI into all products and services. Interconnections with the enforcement of other recent EU legislations and the digital sector, such as the Digital Services Act (DSA), are bound to arise. Hence, both at the EU and the national level, AIA enforcement bodies, such as the AI Office and specific national regulators, may ultimately be considered the nucleus of more encompassing \u201cdigital agencies,\u201d bundling competencies and expertise across various digital instruments. This raises the stakes of designing these entities wisely.\nDespite existing research on how EU regulatory governance influences national governance processes, we know little about how EU policy regulations of the EU shape states' enforcement infrastructures \u2013 that is, the organizational design of public administration (Benz, Broschek, and Lederer 2021; Egeberg and Trondal 2015; Muth 2019). To explore this, we will delve into the institutional design of these bodies, which includes the structure, competence, (division of) tasks, funding, and allocation of responsibilities.\nThe normative framework is becoming more established, especially after the consolidation of the AIA, but there remains scope for additional adjustments in the phase of implementing and delegated acts. This stage enables the Commission and, on"}, {"title": "2. General considerations: designing robust governance for the AIA", "content": "This section discusses the potential goals, structures, interdependencies, and challenges of establishing a multilevel governance framework for AI in the EU and Member States.\n a) EU level\nAt least three options for institutional designs are available at the EU level to establish executive capacities for regulating and enforcing AI.\nOption 1 suggests a centralized institutional design to incorporate tasks related to AI regulations within the remit of the Commission \u2013 notably within its departments, i.e., its Directorates-General (DG). This could imply the establishment of a new DG (or a new unit within it) or reforming an existing one by increasing its policy portfolio to incorporate AI (e.g., Connect A responsible for \u2018Artificial Intelligence and Digital Industry). This structure would enhance the Commission's ultimate control, oversight, and management of AI policy regulation and enforcement activities.\nOption 2 consists of a decentralized institutional design incorporating AI-related tasks in EU-level agencies. Similar to the Commission, this could involve either the establishment of a new AI agency at arm's length distance from the Commission or a reformed EU agency, incorporating AI tasks in its task portfolio. This would leave the Commission less control, oversight, and day-to-day management."}, {"title": "3. The AIA implementation and enforcement: the tasks of the Commission", "content": "Implementing the AIA and its enforcement involves several non-legislative acts primarily under the Commission's authority according to the EU's rules for"}, {"title": "3.1 Procedures", "content": "The European Commission is required to engage with Member State experts and representatives when adopting implementing and delegated acts to ensure the consistent application and detailed implementation of EU laws. Implementing acts aim to apply EU laws consistently across Member States without altering the law (Article 291 TFEU). In contrast, delegated acts are designed to supplement or modify non-essential elements of legislative acts, adding details needed for their implementation (Article 290 TFEU). Implementing acts, governed by the comitology procedure, involve collaboration with a committee of Member State representatives. Under the AIA, this engagement involves only the European AI Board. Delegated acts require consultation with Member State experts but do not involve a formal committee (Craig 2018). Delegated acts are subject to scrutiny by the European Parliament and the Council, which have two months to raise objections; otherwise, the act is adopted. The Commission's powers under the AIA, including adopting delegated acts, are granted for five years and can be silently renewed unless opposed by the European Parliament (EP) and Council (Article 73 AIA). The Commission must keep the EP and Council informed about delegated acts and report on its activities within nine months, allowing for oversight and potential revocation of its powers. Additionally, the Commission is tasked with publishing guidelines and making binding decisions to implement the AIA effectively. The AI Office will support the adoption of implementing and delegated acts, while the AI Board focuses on implementing acts (see Section 3)."}, {"title": "3.2 Guidelines operationalizing the risk-based approach", "content": "The Commission develops guidelines and updates them to assist in implementing the AIA's risk-based approach, focusing on classifying high-risk AI systems (Article 6(5) AIA). Additionally, the Commission uses delegated acts to update Annex III, either adding new high-risk AI use cases or removing ones that no longer pose significant risks, based on criteria such as likelihood of use, autonomy, human oversight, and outcome reversibility, ensuring that these adjustments do not compromise the EU's health, safety, and rights standards (Article 7 AIA).\nConsidering the risk-based classification of AI systems, which potentially offers a robust regulatory approach by building in regulatory flexibility and applies to general-purpose AI (GPAI, also known as foundation models) albeit under a distinct terminology - namely, the 'high impact capabilities' (Article 51(1) AIA) these guidelines should also detail methodologies for risk assessments (Novelli, Casolari, Rotolo, et al. 2024; Novelli et al. 2023).\nSignificantly, within this framework, the Commission must define the rules about \u201csignificant modifications\u201d that alter the risk level of a (high-risk) system once it has been introduced to the market or put into use (Articles 25(1) and 3(23)). These alterations, not anticipated or accounted for in the initial conformity assessment conducted by the provider, may require the system to be reclassified (Article 96(1),"}, {"title": "3.3 Classification of GPAI", "content": "The Commission has notable authority under the AIA to classify GPAI as exhibiting 'systemic risk' (Article 51 AIA). This distinction, establishing the famous two-tiered approach to the regulation of GPAI (Hacker, Engel, and Mauer 2023), is crucial: only systemically risky GPAIs are subject to the more far-reaching AI safety obligations concerning evaluation and red teaming, comprehensive risk assessment and mitigation, incident reporting, and cybersecurity (Art. 55 AIA). This classification authority is delineated in Article 51 AIA, which outlines the criteria according to which a GPAI is considered to exhibit systemic risk. The decision to classify a GPAI as systemically risky can be initiated by the Commission itself or in response to a qualified alert from the Scientific Panel, confirming the presence of such high-impact capabilities.\nThe Commission may dynamically adjust regulatory parameters, such as thresholds, benchmarks, and indicators, through delegated acts. This adaptive mechanism is essential for a robust governance model as it ensures that regulations remain relevant amidst the fast pace of technological advancements, including improvements in algorithms and hardware efficiency. The capacity to refine these regulatory measures is particularly vital as the trend in AI development moves towards creating more powerful, yet \u201csmaller\u201d models that require fewer floating-point operations (FLOPs) (Ma et al. 2024)."}, {"title": "3.4 Prohibited systems", "content": "The Commission is tasked with developing guidelines to address prohibited AI practices (Article 5, AIA), including setting technical standards and best practices for AI system design to prevent manipulative techniques. It must also define criteria for exceptions where AI can be used to address significant threats or terrorist activities, with specific allowances for law enforcement, such as the use of real-time remote biometric identification in public spaces. These guidelines will also outline necessary procedural safeguards to ensure such exceptions do not infringe on fundamental rights. They will be crucial to balance law enforcement needs with individual privacy and freedom protections."}, {"title": "3.5 Harmonized standards and high-risk obligations", "content": "The Commission must also set harmonized standards and define obligations for providers of high-risk AI systems under the AIA, requiring a comprehensive \"in-door\" risk management process that is continuous and iterative throughout the system's lifecycle. This includes detailing timelines, design choices, data processing methods, and strategies to mitigate biases, alongside standardizing technical documentation as per Annex IV, with updates via delegated acts to adapt to technological advances and ensure compliance with regulatory standards."}, {"title": "3.6 Information and transparency", "content": "The Commission is also responsible for setting forth information obligations along the AI value chain that reflect the current technological standards for providers of high-risk systems (Article 28 AIA) and offering guidance to ensure compliance with transparency requirements, which holds particular significance for GPAI (Article 53 AIA). To achieve this, the Commission might, for example, issue directives on properly revealing the use of GPAI across different settings, considering the medium and essence of the content implicated."}, {"title": "3.7 Overlap with other regulations and enforcement timeline", "content": "Finally, the Commission must elucidate the interplay between the AIA and other EU legislative frameworks to guarantee internal systematicity and consistent enforcement across the board. This may include providing illustrative examples of potential overlaps or conflicts and promoting the formation of joint oversight entities or working groups. Such initiatives would facilitate the exchange of information, standardize enforcement approaches, and develop unified interpretative guidelines, ensuring a harmonized regulatory landscape across the European Union.\nThe AIA's enforcement is structured in stages, with transition periods for compliance varying by the risk level of AI systems and linked to the Act's official entry into force. Specific grace periods are set for different categories of AI systems, ranging from 6 to 36 months. However, for existing GPAI systems already on the market, a grace period of 24 months is granted before they must comply fully (Article 83(3) AIA). Even more importantly, high-risk systems already on the market 24 months after the entry into force are entirely exempt from the AIA until significant changes are made in their designs (Article 83(2) AIA). Conceptually, this important change can be equated with the substantial modification discussed above. Arguably, however, this blank exemption is in deep tension with a principle of product safety law: it applies to all models on the market, irrespective of when they entered the market. Moreover, the grace period for GPAI and the exemption for existing high-risk systems favor incumbents vis-\u00e0-vis newcomers, which is questionable from a competition perspective."}, {"title": "4. Supranational authorities: the AI Office, the AI Board, and the other bodies", "content": "The AIA mandates a comprehensive governance framework, as highlighted in Recital 5 of the Commission's Decision that establishes the AI Office. This framework oversees AI advancements, liaises with the scientific community, and plays a pivotal role in investigations, testing, and enforcement, all with a global perspective.\nThe governance structure proposed by the AIA involves establishing national and supranational bodies. Two key institutions are formed at the supranational level: the AI Office and the European AI Board. While distinct in structure and task, these entities are somehow complementary. The AI Office is anticipated to focus on regulatory oversight and enforcement, especially concerning GPAI models. The European AI Board is expected to ensure coordination among Member States, enhancing the AIA's implementation through advice, consultation, and awareness initiatives. Besides these two, the AIA also introduces other significant, though partially autonomous, supranational bodies, namely the Scientific Panel and the Advisory Forum."}, {"title": "4.1. The AI Office", "content": "The first step in implementing the AIA was establishing a centralized AI Office, in January 2024. Its primary mission is to lay down harmonized rules to implement and enforce the AIA consistently across the EU. The formation of the AI Office is geared towards unifying Europe's AI expertise by leveraging insights from the scientific domain. In implementing the AI Act, much will depend on \u201cgetting the AI Office right.\"\nThe Office's broad mandate involves collaboration with scientific experts, national authorities, industry representatives, and significant institutions like the European High-Performance Computing Joint Undertaking and international organizations. An important aspect of the AI Office's role is overseeing General-Purpose AI (GPAI) technologies, exemplified by ChatGPT and Gemini (e.g., Articles 52 to 56 \u0391\u0399\u0391).\n a) Institutional identity, composition, and operational autonomy\nRegarding its institutional identity, the AI Office resembles EU interinstitutional services, marked by its focused scope \u2013 currently dedicated solely to implementing the AIA \u2013 and its role in providing cross-support to various institutions such as the EP, Council, and the Central Bank. Like interinstitutional services, it extends support to agencies and bodies like the European Data Protection Board and the European Investment Bank. It is explicitly stipulated in Articles 5 and 6 of the Commission's decision that the AI Office is entrusted with supporting the European Artificial Intelligence Board and collaborating with the Centre for Algorithmic Transparency. This places the AI Office in a position comparable to other interinstitutional services, such as the Computer Emergency Response Team (CERT-EU), illustrating its distinctive function within the EU framework.\nHowever, unlike interinstitutional services, the AI Office is integrated within the administrative framework of a single entity, specifically the DG for Communication Networks, Content, and Technology (DG-CNECT) of the Commission. The AI Office thus represents primarily a centralized institutional design (see Option 1 above). DG-CNECT operates similarly to a national ministry, overseeing the implementation of policies and programs related to the digital single market. Within DG-CNECT, there are multiple units (called Connects), each specializing in various facets of digital policy, technology, and administration. These units often have overlapping competencies, and the AI Office engages in cross-cutting issues relevant to several of them, with Connect A (\u2018Artificial Intelligence and Digital Industry') being particularly central.\nThis integration implies that the regulations and procedural framework of the Commission govern the AI Office. However, the AI Office's precise organizational structure, specific method of ensuring expertise, and operational autonomy remain ambiguous. No provisions, either in the AIA or in the Commission's decision, have been established regarding the composition of the AI Office, its collaborative dynamics with the various Connects within the DG, or the extent of its operational"}, {"title": "4.2. The AI Board, the Advisory Forum, and the Scientific Panel", "content": "The European Artificial Intelligence Board (hereafter \u201cthe Board\u201d) is distinct from the AI Office. Yet, it undertakes tasks that are parallel and intersect with those of the AI Office, particularly in supervising and directing the execution of the AIA. Currently, the governance and operational structure of the Board is primarily detailed in Articles 65 and 66 of the AIA. In addition to the Board, the AIA also establishes other bodies that, while independent in their formation, support the Board: the Advisory Forum and the Scientific Panel. This creates a complex network of bodies, making their coordination challenging.\na) Structures, roles, and composition of the three bodies\nThe Board consists of a representative from each Member State, appointed for three years, with one of them as the chair. The AI Office and the European Data Protection Supervisor participate as observers without voting powers. Unlike the generic recruitment criteria for the AI Office, the AIA explicitly requires that Member States appoint representatives to the Board who have the requisite expertise and authority in their respective countries to contribute to the Board's missions effectively. These representatives are also empowered to gather essential data and information to ensure uniformity and coordination among national competent authorities (Article 65(4)(c) AIA). This coordination is supported by two permanent sub-groups, which serve as platforms for collaboration and information sharing between market surveillance and"}, {"title": "5. National authorities: Notifying Authorities, Notified Bodies, and Market Surveillance Authorities", "content": "Supranational authorities have an essential role, but the effective implementation and enforcement of this Regulation frequently require a local presence, placing the responsibility primarily on Member States. Each is expected to set up at least one notifying authority responsible for compliance and certification processes and one market surveillance authority to verify that products meet EU harmonization legislation standards for safety, health, and environmental protection as outlined in Regulation (EU) 2019/1020. Both authorities are also encouraged to guide compliance to SMEs and start-ups, considering any relevant recommendations from the Board and the Commission (Chapter VII, Section 2 AIA).\nThe AIA mandates that national authorities must have permanently available staff with expertise in AI, data protection, cybersecurity, fundamental rights, health and safety, and relevant standards and laws. Member States must assess and report this adequacy to the Commission every two years (Article 70 AIA). This shows how policy regulations by the EU may have an organizational component that interacts with the historical prerogatives of national governments to structure the state apparatus at its own will (\u201cadministrative sovereignty\").\nIn this context, Member States have the flexibility to design their governance structures for AI regulation: they can either establish new regulatory bodies dedicated to AI or integrate these oversight responsibilities into existing entities, like national Data Protection Authorities, within their legal frameworks. This autonomy allows them to delegate tasks to the most suitable public organizations, as discussed above (Part 2.b)).\n5.1. Notifying Authority and Notified Bodies\nNotifying authorities are national entities established by each Member State to evaluate, designate, and recognize conformity assessment bodies and oversee their activities (Article 28 AIA).\nEntities seeking to perform conformity assessments under the AIA must apply to the notifying authority in their Member State or a third country, providing a detailed description of their assessment activities, used modules, AI systems competencies, and an accreditation certificate from a national body. Once an applicant is verified to meet all criteria, the notifying authority endorses it as a notified body, officially recognized to evaluate AI system conformity before market release. Notifying authorities oversee these bodies impartially, are prohibited from engaging in assessment activities to avoid conflicts of interest, and can restrict, suspend, or withdraw a body's status if it fails to meet obligations."}, {"title": "5.2. Market Surveillance Authority", "content": "Under the AIA, Member States are mandated to appoint a specific Market Surveillance Authority (MSA) to serve as a single point of contact (Art. 70 AIA) and to"}, {"title": "6. Towards a robust governance: recommendations", "content": "Building on this analysis, we envision several important updates that should be made to the governance structure of the AI Act.\n6.1. Clarifying the institutional design of the AI Office\nGiven the broad spectrum of tasks anticipated for the AI Office \u2013 from evaluating GPAIS' capabilities to assisting in creating regulatory sandboxes more detailed organizational guidance seems needed to identify its institutional design. Additionally, the mandate for the AI Office to \u201cinvolve independent experts to carry out evaluations on its behalf\u201d (Recital 164 AIA) lacks specificity concerning the criteria for selecting these experts. This requirement is akin to the UK's approach to health technology assessments, where the National Institute for Health and Care Excellence (NICE) sets definitive criteria for evidence evaluation, commissioning entities like the Cochrane Collaborative for independent reviews. This model, supported by government funding, provides a structured and standardized method that could inform the AI Office's procedures to ensure its effectiveness in fulfilling its diverse responsibilities.\nAnother critical consideration is the potential impact of integrating the AI Office within the overarching framework of the Commission, which may obscure its operational transparency. This concern stems from the obligation to adhere to the Commission's general policies on communication and confidentiality. For example, the right to public access to Commission documents, governed by Regulation (EC) No 1049/2001, includes numerous exceptions that could impede the release of documents related to the AI Office. One such exception allows EU institutions to deny access to documents if it would compromise the \u201c[...] commercial interests of a natural or legal person, including intellectual property,\u201d a broadly defined provision lacking specific, enforceable limits. To mitigate this risk, a narrower interpretation of these exceptions should be applied to the AI Office, aligning with recent trends in the case law of the EU Courts (Marcoulli and Cappelletti 2023). This approach could help circumvent the transparency issues these rules have caused for other EU agencies, such as Frontex (Salzano and Gkliati 2023).\nIn addition, further clarification regarding the AI Office's operational autonomy is required. This could, for example, come in the form of guidelines delineating its decision-making authority, financial independence, and engagement capabilities with external parties. As described previously (Recital 14), the call for involving independent experts is a step in the right direction. Still, detailed criteria for expert selection and involvement are required to ensure transparency and efficacy in its evaluation and advisory roles.\nAn alternative, potentially more effective approach would be establishing the AI Office as a decentralized agency with its legal identity, like the EFSA and the EMA. This model, designed for pivotal sectors within the single market, would endow the AI Office with enhanced autonomy, including relative freedom from political agendas at the Commission level, a defined mission, executive powers, and the authority to issue binding decisions, albeit with options for appeal and judicial scrutiny. Such an organizational shift would likely boost the AI Office's independence from the Commission and the broader EU institutional matrix, positioning it as a key player in AI governance. This might, however, risk agency drift in which operations by the AI"}, {"title": "6.2. Integrating the Forum and the Panel into a single body", "content": "The first point concerns the institutional framework of the advisory bodies and stakeholder representation in them. As anticipated, there is potential for consolidating the Panel and the Forum into a singular entity. This move would reduce duplications and bolster the deliberation process before reaching a decision. Such a combined entity would merge the diverse knowledge bases of civil society, the business sector, and the academic community, promoting inclusive and reflective discussions of the needs identified by the Commission and Member States. A unified entity combining the Advisory Forum's extensive stakeholder engagement with the Scientific Panel's specialized, independent expertise could significantly improve the quality of advice to the Board, the Office, and other EU institutions or agencies. The unified entity would ensure that the guidance reflects both the technical complexities and societal implications of AI and challenges the belief that GPAI necessitates fundamentally different knowledge from other AI systems. Subcommittees or working groups could help avoid the risk of this unified body becoming overburdened or diluting specific expertise within a larger group."}, {"title": "6.3. Coordinating overlapping EU entities: the case for an AI Coordination Hub", "content": "As AI technologies proliferate across the EU, collaboration among various regulatory entities becomes increasingly critical, especially when introducing new AI applications intersects with conflicting interests. A case in point is the independent decision by Italy's data protection authority, \u2018Garante per la privacy', to suspend ChatGPT, a move not mirrored by other data protection entities within the EU. The scope for such overlaps is not limited to national data protection authorities but extends to other entities, such as decentralized agencies, including the European Data Protection Board (EDPB), the European Union Agency for Cybersecurity (ENISA), the Fundamental Rights Agency (FRA), the European Medicines Agency (EMA), the European Banking Authority (EBA), and the European Union Intellectual Property Office (EUIPO). The likelihood of overlaps and interferences with the constellation of bodies now introduced by the AIA \u2013 e.g., the Office, the Board, the Forum, etc. \u2013 is high.\nIn light of these challenges, it becomes crucial to incorporate efficient coordination mechanisms within the EU's legislative framework. Enhancing the functionality of the existing EU Agency Network\", to foster a collaborative environment and act as a unified point of communication for all EU agencies and Joint Undertakings (JUs) on multifaceted issues, would mark a significant advancement. However, establishing a centralized platform, the European Union Artificial Intelligence Coordination Hub (EU AICH), emerges as a compelling alternative. This hub would convene all pertinent bodies involved in AI regulation and oversight, facilitating collective decision-making. Establishing such a hub promises to elevate significantly the uniformity of AIA enforcement, improve operational efficiency, and reduce inconsistencies in treating similar matters."}, {"title": "6.4. Control of AI misuse at the EU level", "content": "The absence of authority for the AI Board to revise or address national authorities' decisions, unlike the European Data Protection Board's role under GDPR, presents a"}, {"title": "6.5. Learning mechanisms", "content": "Given their capacity for more rapid development and adjustment, the agility of non-legislative acts presents an opportunity for responsive governance in AI. However, the agility of the regulatory framework must be matched by the regulatory bodies' adaptability. Inter- and intra-agency learning, and collaboration mechanisms are essential for addressing AI's multifaceted technical and social challenges (Dimitropoulos and Hacker 2016). This approach should facilitate continuous improvement and adaptation of regulatory practices to ensure they remain effective in guiding and governing AI technologies' legal and safe development and deployment. To this end, specific ex-ante and ex-post review obligations of the Office's and Board's actions and recommendations could be introduced. More importantly, a dedicated unit, for example, within the AI Office, should be tasked with identifying best and worst practices across all involved entities (from the Office to the Forum). Liaising with Member State competence centers, such a unit could become a hub for institutional and individual learning and refinement of AI, within and beyond the AIA framework."}, {"title": "7. Conclusions", "content": "While an intricate, yet solid foundation for AI governance has been introduced in the AIA, this article calls for a forward-looking perspective on AI governance, stressing the importance of anticipatory regulation and the adaptive capabilities of governance structures to keep pace with technological advancements. The article makes five key proposals. First, it suggests establishing the AI Office as a decentralized agency similar to EFSA or EMA to enhance its autonomy and reduce potential influences from political agendas at the Commission level. Second, there is potential for consolidating the AI Office's advisory bodies\u2014the Advisory Forum and the Scientific Panel\u2014into a single entity to streamline decision-making and improve the quality of advice; this body would reflect both technical and societal implications of AI. Third, the article discusses the need for more coherent decision-making and cooperation among the various EU bodies involved in AI oversight, which may have overlapped or conflicting jurisdictions. This need could be addressed by strengthening the existing EU Agency Network or creating an EU AI Coordination Hub. Fourth, the lack of authority for the AI Board to revise national decisions could lead to inconsistent application of AI regulations across Member States, similar to issues observed with GDPR enforcement. Fifth, to ensure responsive and effective governance of AI technologies, it proposes introducing mechanisms for continuous learning and adaptation within the regulatory"}]}