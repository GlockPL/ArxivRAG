{"title": "Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems", "authors": ["Minhye Jeon", "Seokho Ahn", "Young-Duk Seo"], "abstract": "The use of knowledge graphs in recommender systems has become one of the common approaches to addressing data sparsity and cold start problems. Recent advances in large language models (LLMs) offer new possibilities for processing side and context information within knowledge graphs. However, consistent integration across various systems remains challenging due to the need for domain expert intervention and differences in system characteristics. To address these issues, we propose a consistent approach that extracts both general and specific topics from both side and context information using LLMs. First, general topics are iteratively extracted and updated from side information. Then, specific topics are extracted using context information. Finally, to address synonymous topics generated during the specific topic extraction process, a refining algorithm processes and resolves these issues effectively. This approach allows general topics to capture broad knowledge across diverse item characteristics, while specific topics emphasize detailed attributes, providing a more comprehensive understanding of the semantic features of items and the preferences of users. Experimental results demonstrate significant improvements in recommendation performance across diverse knowledge graphs.", "sections": [{"title": "1 INTRODUCTION", "content": "Recommender systems mainly rely on direct interactions between users and items, which often leads to challenges such as data sparsity and cold start problems. To address these challenges, the side information of items (e.g., price, category, and brand) offers an opportunity to leverage diverse relations and information. In particular, the diverse characteristics of recommender systems and domain-specific differences make it challenging to construct and apply a knowledge graph consistently across systems. In response, previous studies [7, 8] have highlighted the importance of interoperability in knowledge graph-based recommender systems by standardizing the structure of side information or consistently modeling relations.\nRecently, large language models (LLMs) have demonstrated their ability to deeply understand and infer meaning from context information across various domains, driving research into methods for extracting keywords from context information. Semantic features within context information (e.g., item descriptions and user reviews) offer valuable insights but are often utilized without proper processing or analysis in knowledge graph-based recommender systems. However, applying these methods to recommender systems that prioritize interoperability remains challenging, particularly due to the reliance on for domain experts to manually integrate context information into knowledge graphs. Additionally, the methods used to expand these knowledge graphs are often inconsistent, making it difficult to systematically organize the diverse information embedded in both side and context information. Finally, identifying and processing synonymous words generated by LLMs requires additional steps, which need to be handled consistently.\nTo address this problem, we propose a systematic and consistent method for extracting topics inherent in the side and context information of items, leveraging LLMs. Building on the need to comprehend knowledge across multiple contextual levels [3], our approach extracts both general and specific topics to capture the semantic features of the items from various perspectives. The proposed method involves three key steps: (i) General topic extraction. Using both side and context information, we extract a general topic. This step addresses overlapping data by incorporating the previously extracted general topic into subsequent iterations, ensuring consistency across the process; (ii) Specific topic extraction. Context information is utilized to extract specific topics, capturing the unique characteristics of each item; (iii) Topic refinement. A refining algorithm is applied to address synonym overlap within the specific topics, ensuring clarity and consistency despite their inherent complexity;\nTo achieve this, the general topic offers deeper insights into broader characteristics (e.g., sub-category) compared to the original side information (e.g., category). In contrast, the specific topic captures each item's information and users' preferences, reflecting both subjective and objective aspects. Leveraging both the general and specific topics enables a more comprehensive understanding of the characteristics of an item, as well as the preferences and behaviors of its users. Additionally, our approach is based on a standardized metagraph, ensuring a consistent and interoperable approach across various domains in recommender systems. We demonstrate that the proposed approach significantly improves recommendation performance by comparing results across diverse knowledge graphs in multiple systems.\nThe main contributions are summarized as follows:\n\u2022 We propose a method that extracts general and specific topics from both side and context information within the knowledge graph using LLMs.\n\u2022 Our approach ensures interoperability by utilizing a standardized metagraph, enabling consistent topic extraction and refining processes regardless of the differences across various systems.\n\u2022 Comparative experiments demonstrate that the proposed approach improves recommendation performance in terms of four different evaluation metrics across various domains."}, {"title": "2 RELATED WORKS", "content": "This section first explains previous work on knowledge graph-based recommender systems (Section 2.1), and then introduces previous studies that enhance knowledge graphs in recommender systems using LLMs (Section 2.2)."}, {"title": "2.1 Knowledge graph-based Recommender Systems", "content": "Approaches to leveraging knowledge graphs in recommender systems are generally categorized into two types: (i) Embedding-based approach and (ii) Path-based approach. These approaches differ in how they leverage the relations within the knowledge graph. The embedding-based approach represents entities and relations by embedding them into a low-dimensional vector space, enabling recommendations based on vector similarity. In contrast, the path-based approach identifies connection paths between users and items, utilizing these paths for recommendations. This approach allows for discovering indirect connections through path exploration, enabling recommendations even when direct links are latent. We provide a detailed explanation of each approach as follows.\nEmbedding-based approach. TransE [1] and TransR [9] are among the most widely used techniques for knowledge graph embedding. CKE [30] is a hybrid model that integrates collaborative filtering with TransR to capture the latent relations between users and items. KGAT [20] and CKAN [25] extend TransR-based embeddings by incorporating an attention mechanism to assign varying importance to relations, thereby enhancing model performance. RippleNet [19] and KGIN [21] both leverage TransE for knowledge graph embeddings. RippleNet focuses on propagating user preferences, while KGIN learns the relational characteristics to enhance the latent relations between users and items. However, embedding-based approaches are constrained to utilize the detailed characteristics of items, as they primarily focus on structural information [33].\nPath-based approach. Designing meta-paths or modeling inter-entity connection patterns presents a significant challenge [5]. KPRN [23] extracts various paths connecting users and items from knowledge graphs and learns them using recurrent neural networks (RNNs). RuleRec [11] identifies path rules from knowledge graphs to capture latent relations, learning rules that users tend to follow. PGPR [26] and ReMR [22] employ reinforcement learning to discover user-item paths. However, when knowledge graphs lack sufficient paths between users and items, the amount of information available for the model to learn is limited, leading to potential performance degradation. Despite this, previous work has not consistently leveraged context information to address these limitations. Since relevant information varies across domains, some domains require expertise from domain experts [18], which leads to challenges in terms of scalability and generalizability.\nOur contributions. To address this problem, we propose a method to effectively utilize context information in a knowledge graph built from the side information of items. We also present a consistent approach to enhancing the knowledge graph. Furthermore, we demonstrate that LLMs can be applied without expert intervention, improving interoperability."}, {"title": "2.2 LLM-based Knowledge graph Construction in Recommender Systems", "content": "Recently, research on enhancing knowledge graphs using LLMs has been actively progressing. Previous studies aim to address the data sparsity and cold start problems in recommender systems by expanding entities and relations using LLMs [6, 31].\nYang et al. [27] proposes a framework that utilizes side information to discover latent relations, suggesting a method to automatically identify new types of relations using LLMs to enhance recommendation performance. Shi et al. [16] extracts qualitative information, such as style, price, and color, from user review data to build user subgraphs, improving recommendation performance through subgraph inference. Yang et al. [28] introduces a method that generates common sense-based subgraphs from item side information using LLMs and applies them to recommendations. However, previous studies often do not fully utilize context information, relying only on limited side information such as type and brand, or extracting only general characteristics of items by leveraging external knowledge from LLMs [28].\nOur contributions. In this paper, we extract more enriched general topics compared to previous studies by utilizing not only side information but also context information, which captures item-specific semantic features. Furthermore, we enhance the knowledge graph by extracting specific topics that capture the characteristics of each item and the preferences of users based on context information."}, {"title": "3 PRELIMINARIES", "content": "This section first introduces the theoretical backgrounds (Section 3.1) and formulates the task (Section 3.2) of our proposed approach."}, {"title": "3.1 Theoretical Backgrounds", "content": "This section provides theoretical explanations of three key concepts essential for understanding the proposed approach: Knowledge graph, Metagraph, and Side/Context information.\nKnowledge graph. A knowledge graph is a directed graph consisting of nodes and edges, where each edge represents a semantic relationship between two nodes [8, 13]. We formally define a knowledge graph $G$ as:\n$G = \\{(h, r, t) | h, t \\in &, r \\in R\\}$                                        (1)\nwhere $& = \\{e_1, e_2,..., e_k\\}$ is a set of $k$ entities (i.e., nodes) and $R = \\{r_1, r_2,\u2026, r_g\\}$ is a set of $g$ relation types (i.e., edges). In this context, $h$, $r$, and $t$ typically denote the head, relation, and tail, respectively. Each triplet $(h, r, t) \\in G$ indicates a semantic relationship $r$ from the entity $h$ to the entity $t$.\nIn recommender systems, the entity types can include users $U$ and items $I$ in addition to knowledge base entities &. Incorporating explicit and implicit feedback between users and items, such as $R_+ = \\{interact, also\\_bought, ... \\}$, can provide more insights into user preferences [17, 23]. Additionally, newly defined relations between other entities can be considered [8]. To capture all these interactions, we can expand the knowledge graph $G$ to an extended knowledge graph $G_{RS} = \\{(h, r, t) | h, t \\in & \\cup U, r \\in R \\cup R_+\\}$ for recommender systems.\nMetagraph. We first define a metagraph $M$ of a knowledge graph $G$, also known as a schema [12, 29], which represents the relationships between super-entities [2]:\n$M = \\{(\\eta, r, \\tau) | \\eta, \\tau \\in A, r \\in R\\}$                                     (2)\nwhere $A$ denotes a set of entity types. The metagraph provides additional abstract information about entities [10] but also enforces the triplet types of the knowledge graph [7], thereby enhancing the interoperability of different systems. Formally, we first define the subset of entities $&_a = \\{e \\in & | \\phi(e) = a\\}$ that corresponds to an entity type $a \\in A$, using an entity type mapping function $\\phi: & \\rightarrow A$. Then for a triplet $(h, r, t) \\in G$, there must exist a triplet type $(\\eta, r, \\tau) \\in M$ where $h \\in &_{\\eta}$ and $t \\in &_{\\tau}$.\nFor recommender systems, constructing knowledge graphs in a consistent manner is challenging due to their variations in domains and system characteristics. As part of this effort, RecKG [7] standardizes the metagraph $M^*$ for recommender systems by categorizing entity types $A^*$, relation types $R^*$, and their triplet types. By constructing knowledge graphs based on this standardized metagraph, multiple systems can be integrated more effectively, thus achieving interoperability. In other words, expanding a standardized metagraph provides a basis for developing improved methods that achieve interoperability.\nSide/Context information. We begin by grouping the standardized entity types $A^*$ within the standardized metagraph $M^*$ for recommender systems, aiming to develop an improved method while maintaining interoperability. Based on the metagraph proposed in RecKG [7], the entity types include a user $U \\in A^*$ and an item $I \\in A^*$, while the remaining entity types provide supplementary information for these users and items.\nWe first formally define the type of side information [5, 15] as a subset of all entity types except for the user and item, $A_{side} = A^* - \\{U, I\\}$. Examples of side information include attributes such as Performer (a standardized form for roles such as actor and singer), Type (a standardized form for classifications such as category and genre), Release date, Price, and Description. Assuming the head entity type is either a user $U$ or an item $I$, we also define the set of relation types where the tail entity type is side information, i.e., $R_{side} = \\{r \\in R | (\\eta, r, \\tau) \\epsilon M^*, \\tau \\in A_{side}\\}$.\nAmong the side information, we focus on textual data as context information [14, 15] due to its ability to capture richer contextual meanings beyond categorical or numerical attributes, such as Description and Review. Formally, let $A_{cont} \\subseteq A_{side}$ represent the set of entity types that provide context information, and $R_{cont} = \\{r \\in R | (\\eta, r, \\tau) \\epsilon M^*, \\tau \\in A_{cont}\\}$ denote the corresponding set of contextual relation types. These contextual attributes are particularly valuable in recommender systems as they enable the extraction of semantic features through LLMs [24, 32], allowing for more nuanced and personalized recommendations while maintaining interoperability."}, {"title": "3.2 Task Formulation", "content": "This section outlines the objectives of our approach. Specifically, we aim to construct a topic-aware knowledge graph $G$ (output) from an existing knowledge graph $G_{RS}$ (input) by consistently extracting and replacing topics within context information. To ensure interoperability across different recommender systems, we begin by constructing a topic-aware metagraph $M$ based on a standardized metagraph $M^*$. Formally, we first define a subset $M_{base} \\subseteq M^*$, containing all triplet types except for context information, as follows:\n$M_{base} = \\{(\\eta, r, \\tau) | \\eta, \\tau \\in A^* \u2013 A_{cont}, r \\in R^* \u2013 R_{cont}\\}$.           (3)\nNext, we extract the topic entity type $A_{topic}$ from both side and context information, along with its corresponding relation $R_{topic}$. Constructing topic-only metagraph $M_{topic}$ based on these topic entity types $A_{topic}$ and its relations $R_{topic}$ as follows:\n$M_{topic} = \\{(\\eta, \u03b3, \u03c4) | \u03b7 \\in \\{U, I\\}, r \\in R_{topic}, \u03c4 \\in A_{topic}\\}$.                              (4)\nThen the final topic-aware metagraph $M$ is constructed by combining the base metagraph $M_{base}$ and topic-only metagraph $M_{topic}$. This union integrates the fixed side information with the newly extracted topic information:\n$M = M_{base} \\cup M_{topic}$.                                                               (5)\nThis combination ensures that all contextual properties are replaced by the corresponding topics, eliminating context information from the metagraph. As the topic-aware metagraph $M$ is derived from the standardized metagraph $M^*$, interoperability is ensured without difficulty. Finally, enforcing triplet types $(\\eta, r, \\tau) \\in M$, we consistently construct the topic-aware knowledge graph $G$:\n$G = \\{(h, r, t) | (\\eta, r, t) \\in M, h \\in &_{\\eta}, t \\in &_{\\tau}\\}$                                       (6)\nwhich achieves the aim of the task.\nNote that there are several factors to consider before proceeding with this task. First, it is essential to determine which topic type to extract. Second, the process of extracting topics from the actual context information must be performed in a systematic and consistent manner. The method proposed in the next section outlines various approaches for addressing these factors."}, {"title": "4 PROPOSED APPROACH", "content": "This section first provides an overview of our approach (Section 4.1), then details the extraction of general and specific topics from both side and context information in the knowledge graph (Sections 4.2 and 4.3). Finally, we focus on synonymous topics in the extraction process and introduce a refining algorithm to resolve this issue while maintaining interoperability (Section 4.4)."}, {"title": "4.1 Approach Overview", "content": "This section provides an overview of our proposed approach, shown in Figure 2. As discussed in Section 3.2, our approach aims to construct a topic-aware knowledge graph for recommender systems by extracting topic entities from both side and context information, ensuring interoperability. Considering the importance of understanding knowledge across multiple contextual levels [3], we use distinct strategies for topic extraction using LLMs. Specifically, we update the general topics, which already exist in the side information (e.g., Type); while we replace the specific topics from the context information (e.g., Description and Review).\nTo achieve this, we first extract the general topic using both side and context information, then update more detailed type (i.e. SubType) for lowest level Type entity (in Figure 2(a) and Section 4.2). Simultaneously, specific topics are replaced using context information, including Description and Review, for each Item entity (in Figure 2(b) and Section 4.3). Due to the different extract strategies (i.e., update and replace strategies), specific topics may lead to synonymous entities across different items. To address this, we introduce a refining algorithm to handle these synonyms (in Figure 2(c) and Section 4.4). By starting with a standardized metagraph, the entire process can be consistently applied across various recommender systems. Each process is detailed in the following sections."}, {"title": "4.2 General topic extraction", "content": "This section describes the method for extracting general topics from the knowledge base, shown in Figure 2(a). Focusing solely on Type) (e.g., category and genre) is too broad to capture the detailed categorization of an item. To address this, we enhance the Type entity by extracting a general topic. Specifically, we use both side information (i.e., Type) and context information (i.e., Description) to extract the Subtype entity.\nFormally, a triplet type is first added to the topic-aware metagraph $M$ to ensure interoperability, satisfying:\n\\{(I, related\\_to, Subtype)\\} \\subseteq M.                                              (7)\nIt follows that Subtype $ \\in A$ and related\\_to $ \\in R$ hold. By fixing these triplet types, we construct entities $&_{Subtype} \\subseteq &$ by using LLMs based on both Type and Description entity types. These triplets are added to the topic-aware knowledge graph $G$:\n\\{(h, r, t) | h \\in I, r = related\\_to, t \\in &_{subtype}\\} \\subseteq G.             (8)\nDuring the construction of $&_{Subtype}$, it is iteratively updated for each leaf node in the type tree, which organizes the existing Type elements in the knowledge base into a tree structure, starting from &$Type$. This process is iterated for items within the same lowest level Type in the type tree. We provide an illustrative example in Figure 3(a) to explain this iterative process:\nThe general topic reflects the information from the \"Current Category Tree\", which contains subtypes generated from items at the same lowest level. Leveraging existing data, the subtype of the current item is added to the \"Current Category Tree\", if it is not duplicate. For instance, when \u201cHydrating Serum\u201d and \u201cPlumping Serum\" are generated, the non-duplicate subtypes are added to the \"Current Category Tree\". By repeating this process for each item, the extraction of general topics effectively captures the detailed information compared to the existing Type."}, {"title": "4.3 Specific topic extraction", "content": "This section focuses on extracting specific topics, as shown in Figure 2(b). Specific topics represent unique properties inherent in context information that cannot be derived from side information. For example, Description provides objective information about an item, whereas Review conveys subjective opinions from users who have interacted with the item.\nTo achieve this, we extract and replace inherent topics within such context information, iterating through all connected context information for each item. In this context, each item is assumed to have N reviews and a single description, as shown in the left part of Figure 2(b). Specific topics (i.e., Word) are extracted for each context information. From the Review, two triplets are added to the topic-aware metagraph M:\n\\{(U, mention, Word), (I, described\\_as, Word)\\} \\subseteq M.              (9)\nSimilarly, a triplet type related to the Description is also added:\n\\{(I, tagged, Word)\\} \\subseteq M.                                                             (10)\nAs shown in Figure 3(b), the process extracts specific topics (i.e., Word) for each context information. While Word extracted from Description contains objective information about the item, the information from Review reflects the subjective opinions of each review, thus distinguishing the relations between entities.\nNote that this process is applied uniformly to all context information associated with an item. Thus, unlike general topic extraction, the large number of candidate words leads to inherent synonyms within the entities &$Word$. To address this issue, the words are first aggregated as Candidate\\_word and then grouped under &$Candidate\\_word$, requiring an additional synonym refinement process. The following section provides a detailed explanation of this refinement process."}, {"title": "4.4 Topic Refining", "content": "This section introduces an algorithm for refining specific topics, as illustrated in Figure 2(c). As mentioned in Section 4.3, &$Candidate\\_word$ may have overlapping meanings. Specific topics capture detailed characteristics of an item, often requiring a large number of words to fully describe the item's attributes. However, using LLMs to handle synonyms for such a large number of specific topics within a single prompt, as in the method described in Section 4.2, is challenging due to token limitations. Therefore, an additional refining method is necessary to resolve this issue while maintaining interoperability.\nGiven the importance of both morphological and semantic similarity of words [4], we first partition the topics based on morphology to create manageable subsets for processing with LLMs, and subsequently group them semantically using LLMs. To achieve the first step, we partition all extracted candidate topics &$Candidate word$ as described in Algorithm 1. The detailed explanation of the algorithm is as follows:\nThis algorithm recursively partitions specific candidate words &$Candidate\\_word$, into smaller subsets based on their prefixes. Specifically, the function TopicPartition calls the recursive function  TopicPartitionRecursive, which returns partitions of &$Candidate\\_word$ (Lines 1-4). The function _TopicPartitionRecursive takes two parameters: prefix and the subset of words W. Words whose first N characters match new_prefix are added to the subset p (Lines 10-14). If the size of p does not exceed the threshold T, it is added to the partition P (Lines 15-16). Otherwise, TopicPartitionRecursive is recursively called with the new prefix and the corresponding subset to further refine the partition (Lines 17-18). The algorithm ensures that every subset in the final partition are smaller than T.\nEach subset p is individually fed into the LLMs to group &$Candidate\\_word$ with the same meaning, finally returning &$Word$. The prompt used in this process is shown in Figure 3(c). In practice, the frequency of each topic's usage was included as input to the LLMs, replacing it with the more frequently mentioned topic. Then these triplets are added to the topic-aware knowledge graph G:\n\\{(h, r, t) | h \\in U, r = mention, t \\in &_{Word}\\}\n\\cup \\{(h, r, t) | h \\in I, r = described\\_as, t \\in &_{Word}\\}\n\\cup \\{(h, r, t) | h \\in I, r = tagged, t \\in &_{Word}\\} \\subseteq G.\n(11)\nThis process is not only constructed based on standardized metagraphs, but the algorithms are also applicable regardless of system size, ensuring interoperability."}, {"title": "5 EXPERIMENTS", "content": "In this section, we present our experimental setup and discuss the results of applying our proposed approach to the knowledge graph."}, {"title": "5.1 Experimental Settings", "content": "Dataset. We evaluate our consistent methodology on two datasets to demonstrate its applicability across both general domains and recommender system scenarios.\nAmazon Beauty and Clothing\u00b9 are e-commerce datasets from Amazon, offering diverse metadata such as brand, category, price, and other relevant attributes. Additionally, they provide information on related items connected through predefined relationships like \"also\\_bought\u201d, \u201calso\\_viewed\u201d, and \u201cbought\\_together\u201d, as well as user reviews for the items."}, {"title": "5.2 Experimental Results", "content": "This section presents the experimental results of the proposed approach, as summarized in Table 2.\nWe first compare $G_{base}$ and $G_{base}$ to observe the impact of incorporating context information. The results show that the knowledge graph integrating both general and specific topics ($G_{base}$) outperformed the baseline knowledge graph ($G_{base}$), which was constructed using only side information. This demonstrates that combining context information with side information has a significant impact on improving recommendation performance.\nWe next compared the recommendation results of two extended knowledge graphs following the PGPR approach; the first ($G_{large}$) utilized only review data, while the second ($G_{large}$) incorporated item descriptions in addition to reviews. The knowledge graph enriched with item descriptions and user reviews demonstrated superior performance, as general topics represent the broader characteristics of items, while specific topics capture detailed attributes and user preferences. Both types of topics played a crucial role in enhancing performance, emphasizing the importance of analyzing diverse forms of side and context information.\nIn short, our approach can be applied across different domains, resulting in consistent performance improvements. These implications highlight its interoperability and effectiveness in enhancing knowledge graphs when integrated with existing methods."}, {"title": "6 CONCLUSION", "content": "This study proposes a method for systematically and consistently extracting general and specific knowledge embedded in an item's side information and context information using LLMs. Specifically, we extract general topics using side and context information. Specific topics are derived from the context information of each item, capturing both the objective characteristics of the items and the subjective preferences of users. This allows us to present a knowledge graph expansion method that enhances both item-entity connections and user-entity interactions. Furthermore, we refine and group synonymous words using our proposed algorithm and LLM, enhancing the organic connections between entities within the knowledge graph. Importantly, we demonstrate that this method can effectively expand the knowledge graph without requiring intervention from domain experts.\nWe further aim to enhance interoperability and improve recommendation performance in real-world systems by applying our method to integrated systems across multiple domains."}]}