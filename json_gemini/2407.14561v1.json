{"title": "NNSIGHT AND NDIF: DEMOCRATIZING ACCESS TO\nFOUNDATION MODEL INTERNALS", "authors": ["Jaden Fiotto-Kaufman", "Alexander R Loftus", "Eric Todd", "Jannik Brinkmann", "Caden Juang", "Koyena Pal", "Can Rager", "Aaron Mueller", "Samuel Marks", "Arnab Sen Sharma", "Francesca Lucchetti", "Michael Ripa", "Adam Belfki", "Nikhil Prakash", "Sumeet Multani", "Carla Brodley", "Arjun Guha", "Jonathan Bell", "Byron Wallace", "David Bau"], "abstract": "The enormous scale of state-of-the-art foundation models has limited their accessi-\nbility to scientists, because customized experiments on large models require costly\nhardware and complex engineering that is impractical for most researchers. To\nalleviate these problems, we introduce NNsight, an open-source Python package\nwith a simple, flexible API that can express interventions on any PyTorch model\nby building computation graphs. We also introduce NDIF, a collaborative research\nplatform providing researchers access to foundation-scale LLMs via the NNsight\nAPI. Code, documentation, and tutorials are available at https://nnsight.net/.", "sections": [{"title": "INTRODUCTION", "content": "Research on large-scale AI currently faces two practical challenges: lack of transparent model access,\nand lack of adequate computational resources. This paper introduces the NNsight library and the\nNational Deep Inference Fabric (NDIF), which together aim to address both of these challenges.\nModel access is limited by the secrecy of state-of-the-art commercial model parameters (OpenAI\net al., 2023; Anthropic, 2024; Gemini Team et al., 2024). Commercial application programming\ninterfaces (APIs) offer frontier models \u201cas a service,\" allowing thousands of concurrent users to share\nmodel instances and thus reducing computational costs. However, these APIs lack transparency for\nscientists studying model internals, such as intermediate activations or gradients used during neural\nnetwork inference and training.\nModels with openly downloadable parameters provide partial transparency (Scao et al., 2022; Black\net al., 2021; Touvron et al., 2023; Jiang et al., 2023). However, the adoption of these models is\noften limited to smaller sizes because models with tens of billions of parameters exceed a single\nGPU's memory capacity. When scaled to hundreds of billions of parameters, these models are too\nlarge even for the combined GPU memory of a single node. For example, inference on a 530 billion\nparameter LLM requires about 1TB of GPU memory just to load the model parameters in 16-bit\nprecision (Aminabadi et al., 2022). Even if a scientist has access to such resources, evaluating large\nmodels blocks others from using the same resources concurrently, preventing their efficient utilization.\nThe problem is worse still when we wish to perform deeper analyses of model internals, as such\nexperiments are generally even more compute- and time-intensive. Thus, despite evidence that key\ncapabilities emerge only in the largest models (Wei et al., 2022; Patel & Pavlick, 2022; Rae et al.,\n2021; Brown et al., 2020), studying them can often seem unattainable.\nAs a result, most researchers are limited to studying model internals using smaller models (Hernandez\net al., 2024; Marks et al., 2024b; Brinkmann et al., 2024; Hanna et al., 2023; Wang et al., 2022).\nResearch on large models is also typically limited to \u201cblack-box\" investigations using commercial\nAPIs. In other words, research into the internal mechanisms of the largest (and most capable) models\nhas been hindered by multiple infrastructural barriers.\nSurveys of AI research needs have documented this unsatisfactory situation (Shevlane, 2022; Bucknall\n& Trager, 2023; Casper et al., 2024): Specifically, Bucknall & Trager (2023) highlights the need for\nstructured model access APIs that offer greater transparency than existing commercial AI APIs.\""}, {"title": "TRANSPARENT AND FLEXIBLE MODEL INTERACTIONS", "content": "NNsight minimizes the learning curve for researchers by providing transparent access to PyTorch-\nbased models. Our approach combines a novel tracing context with programming idioms that will be\nfamiliar to PyTorch users.\nNNsight's core API uses a tracing context that encapsulates model interactions within a defined scope,\nbuilding and executing its intervention graph upon exiting the scope. Inside this context, users can\nemploy standard PyTorch operations to manipulate model internals, probe activations, and implement\ncustom interventions."}, {"title": "GRAPH REPRESENTATION", "content": "Once interventions are defined, they can be represented as an intervention graph (Figure 1, middle).\nThis allows for a number of flexible downstream use cases. For instance, when executing remotely,\nthe graph is sent to a remote server through an intermediate custom json format (see Figure 2,\nSerialisation). Users can share their interventions with other users by exporting the graph to json or\nto a visualization, creating an ecosystem of shareable model interventions."}, {"title": "FLEXIBILITY", "content": "NNsight directly hooks into the PyTorch nn. Module object, allowing it to work with any torch\nmodel, Module, or architecture. To support common use cases, we include infrastructure for accessing\ncustom models distributed by popular platforms like HuggingFace and Meta. However, the core\npackage is architecture-agnostic: Interventions on custom models are a core use-case. For example,\nSharma et al. (2024) used NNsight to investigate the mechanisms of factual recall in the Mamba state\nspace model Gu & Dao (2023). This flexibility, along with the shareable graph idiom, enforces a\ncommon language across codebases: Regardless of input modality or model architecture, intervention\ngraphs are saved using the same json specification."}, {"title": "TRANSPARENCY", "content": "The computation graph is fully accessible to the user during runtime. This allows users to inspect,\ndebug, and understand the sequence and nature of operations being applied to the model. Each node\nin the graph contains information about the operation it represents."}, {"title": "IMPLEMENTATION", "content": "NNsight is built on a few core components that define a compositional language for modifying\nmodels. These components include the tracing context for building computation graphs, an envoy\nsystem for wrapping PyTorch modules, and an intervention graph for representing and executing\noperations. This section details the implementation of these elements and how they interact to provide\nNNsight's functionality."}, {"title": "THE TRACING CONTEXT", "content": "The core workflow in NNsight uses tracing contexts to build computation graphs, defined by an\nNNsight class object or one of its subclasses. When an NNsight object wraps a PyTorch Module,\nthe tracing context exposes intermediate inputs and outputs. Within this context, user-specified\noperations, written in Python and PyTorch become nodes in an intervention graph. The graph's\nexecution is deferred until the context exits.\nThis deferred execution scheme allows for debugging user specified operations and compute-efficient\ntracking of model operations without immediate execution. This verifies the intervention's exe-\ncutability, raising errors if bugs are detected, all provinf the same information as scanning, but with"}, {"title": "THE ENVOY SYSTEM", "content": "When a PyTorch model is initialized with the NNsight class, each module in the model's hierarchy\nis recursively wrapped with an Envoy object. Envoy objects allow for access to model inputs and\noutputs, for deferred execution, and for additional interventions as illustrated in Figure 3.\nModules wrapped with an Envoy class define input and output properties. Accessing either\nproperty creates a Proxy object, which serves as a placeholder for the tensor data that will flow\nthrough the Module during model execution. Proxy objects allow users to define operations and\ninterventions on the model's computation graph without immediately executing them. Proxy objects\nserve as entry points into the intervention graph; they enable tracking of dependencies between\ndifferent parts of the computation, as each operation on a proxy creates a new node in the graph.\nInput and output proxies propagate into all further nodes on the graph.\nThe Envoy class also implements custom attribute handling and iteration methods to seamlessly\nintegrate with the underlying PyTorch Module structure. It can wrap any PyTorch Module, regardless\nof its internal complexity. This includes custom modules, nested structures, and even dynamic\narchitectures. This system enables NNsight to support interventions on any model architecture built\nwith PyTorch."}, {"title": "INTERVENTION GRAPH", "content": "The intervention graph is implemented through a Graph class in NNsight. The Graph class maintains\na dictionary of nodes (self. nodes), each representing an operation or intervention.\nThe graph supports a validation mode (self.validate), which can execute nodes with proxy values\nas they are added. This allows for early detection of issues like shape mismatches without running\nthe full model, and for validating each operation in the graph. The graph automatically generates\nunique names for each node so that each operation can be uniquely identified and referenced.\nUpon execution, dead nodes are removed for optimization and the computation graph is compiled.\nThe intervention graph is interleaved with the underlying Module, so that execution occurs alongside\nthe existing computation graph at the right points. Upon exiting the tracing context, the graph is\nexecuted with real values rather than FakeTensors."}, {"title": "INVOCATION", "content": "Multiple tracing contexts can be used with an invoke method, allowing for complex, multi-stage\ninterventions. Code Example 4 uses invoke to implement activation patching - an intervention tech-\nnique where neural network activations are replaced across a pair of inputs - which is a fundamental\nmethod for model interventions. Using NNsight 's invoke contexts, we can access and then replace a\nhidden state between a pair of prompts.\nPrompts passed to different invokes are combined into a single batch for forward execution, so\nthat multiple invokes only require a single forward pass. This design allows researchers to define\ninterventions that can access and modify data across different prompts within the same tracing context.\nThe intervention graph is still populated upon exiting the tracing context, with a single intervention\ngraph built across all invoke contexts."}, {"title": "THE SESSION CONTEXT", "content": "The session context in NNsight extends functionality for scenarios involving multiple traces. Unlike\nstandard trace contexts where values are destroyed after execution, session tracks and preserves\nthese values across multiple traces. The values can then be used for interventions that require\ninformation from previous executions of the intervention graph.\nThe session context enables an environment for multiple forward passes on remote infrastructure.\nSessions are particularly valuable when working with very large models, as it allows researchers to\nperform complex analyses and interventions without the need to transfer large amounts of intermediate\ndata between passes.\nBecause the session context allows multiple forward and backward passes, it can be used it for\nthings like remote training and fine-tuning, including parameter-efficient fine-tuning (Lester et al.,\n2021), Low-Rank Adapters (Hu et al., 2021), and probing methods (Belinkov, 2022)."}, {"title": "PERFORMANCE", "content": "In this section we compare the performance of NNsight with other libraries that enable interventions\non model internals. To ensure a fair comparison, we focus on libraries that use PyTorch as the\nunderlying deep learning framework. We find that NNsight achieves competitive time efficiency\nacross a range of tasks.\nOur performance comparison includes runtime measurements for activation patching and attribution\npatching across models with varying parameter counts and architectures. Specifically, we consider"}, {"title": "RELATED WORK", "content": "Research model hosting frameworks. The most similar previous works are Garcon (Elhage et al.,\n2021) and Petals (Borzunov et al., 2022). Garcon is a proprietary internal research system at Anthropic\nthat supports remote inspection and customization of large models hosted on a remote cluster. Unlike\nthe computation-graph approach of NNsight, Garcon operates by allowing researchers to hook models\nvia arbitrary-code execution. As a result, co-tenancy is unsafe, so unlike the NDIF server which shares\nmodel instances between many users, Garcon requires each user to allocate their own model instance,\nwhich is computationally expensive. The Petals system has similar goals, but instead of distributing\nexperiment code, it distributes foundation-model computation across user-contributed nodes in a\nBitTorrent-style swarm. Petals achieves co-tenancy by leaving researcher-defined computations on\nthe user's own system. Unlike Petals, NNsight can avoid costly model-internal data transfers by\nexecuting computation graphs on NDIF servers.\nSeveral other solutions for sharing hosted model resources have been developed, including VLLM\n(Kwon et al., 2023), Huggingface TGI (Dehaene et al., 2024) and Nvidia TensorRT-LLM (Nvidia,\n2024). These are systems for LLM inference acceleration that support large-scale multiuser model\nsharing. However, unlike NDIF, these systems only provide black-box API access to models, and do\nnot permit model inspection or modification, which limits their utility for interpretability research.\nFrameworks for model internals. Numerous efforts have been made to create robust tools for\nexploring and manipulating model internals. TransformerLens (Nanda & Bloom, 2022) is designed\nto facilitate the exploration of GPT-style decoder-only language models. It allows users to apply\ncustom functions to outputs of specific model modules. Unlike NNsight which operates on arbitrary\nPyTorch networks, TransformerLens is limited to autoregressive transformers. Pyvene (Wu et al.,\n2024) supports configurable intervention schemes on PyTorch modules, decorating a PyTorch\nmodule with hooks that allow activations to be collected and overwritten. Pyvene operates at a higher\nlevel of abstraction, and can be configured as a layer over NNsight. Baukit (Bau, 2022), a spiritual\npredecessor to NNsight, provides a range of utilities which simplify tracing and editing activations.\nBut unlike NNsight, it lacks an intermediate representation for user actions on models. Penzai\n(Johnson, 2024) is an open-source functional library which provides a modular system that allows for\nintrospection, visualization, and manipulation of neural network computation graphs; Penzai works\nwithin the JAX framework, in contrast to NNsight which works with PyTorch models."}, {"title": "ECOSYSTEM", "content": "The NNsight project encourages community participation. Interested researchers can join the NDIF\nDiscord for updates, feedback, and collaboration opportunities. We welcome open-source participa-\ntion via the project github page. For more information, visit our website, which contains detailed\ndocumentation, tutorials, and links to NNsight's GitHub repository and Discord server.\nMore information on NDIF can be found at https://ndif. us. Requests for early access to NDIF\nresources can be made through the Discord community. They are available to educational and\nresearch users with a U.S. affiliation after a short application. Other researchers with private GPU\nclusters may also deploy their own instance of NDIF, as the implementation is open-sourced with a\npermissive MIT license."}, {"title": "LIMITATIONS", "content": "NNsight and NDIF are limited in several areas:\nIntervention graph optimization. The intervention graph can be optimized by removing unnecessary\noperations, fusing operations, and applying other optimizations that are difficult to do in the dynamic\nPython environment. Libraries like TorchScript (DeVito, 2022) and TorchFX incorporate many\nsuch optimizations out-of-the-box.\nHigh-level abstractions. NNsight operates at a low level, using PyTorch operations within tracing\ncontexts. This is a conscious design choice, because the tensor manipulation design choices in\nPyTorch are a familiar idiom going all the way back to APL (Iverson, 1962), minimizing user\noverhead to get started. However, packages like pyvene (Wu et al., 2024) or TransformerLens\n(Nanda & Bloom, 2022) provide abstractions which build functionality on top of PyTorch, and\nprovide a common set of abstractions regardless of the underlying model's implementation details.\nClosed-source model support. NNsight cannot run closed-source, proprietary models like GPT-4 or\nClaude. However, the API is designed to be technically feasible for companies to support without\ngiving up custody of their proprietary model parameters."}, {"title": "CONCLUSION", "content": "We introduce NNsight, an open-source Python library that provides access to the internals of\nfoundation models, including those too large to analyze on most individual or academic hardware.\nBy leveraging NDIF infrastructure, NNsight enables researchers to perform complex interventions\nand explore neural networks at a scale previously limited by computational and financial constraints.\nNNsight supports a range of research activities focussed on model interpretability, including probing,\nintervention, and optimization; it is designed to be intuitive, architecture-agnostic, and capable of\nboth local and remote execution.\nNNsight and NDIF provide tooling to run interpretability analyses in a standardized way and the\nability to do so on (very) large models hosted remotely, respectively. Our hope is that this helps\nto democratize large model access and ultimately facilitate rapid progress on research into large\ngenerative models and their inner-workings."}]}