{"title": "NNSIGHT AND NDIF: DEMOCRATIZING ACCESS TO FOUNDATION MODEL INTERNALS", "authors": ["Jaden Fiotto-Kaufman", "Alexander R Loftus", "Eric Todd", "Jannik Brinkmann", "Caden Juang", "Koyena Pal", "Can Rager", "Aaron Mueller", "Samuel Marks", "Arnab Sen Sharma", "Francesca Lucchetti", "Michael Ripa", "Adam Belfki", "Nikhil Prakash", "Sumeet Multani", "Carla Brodley", "Arjun Guha", "Jonathan Bell", "Byron Wallace", "David Bau"], "abstract": "The enormous scale of state-of-the-art foundation models has limited their accessibility to scientists, because customized experiments on large models require costly hardware and complex engineering that is impractical for most researchers. To alleviate these problems, we introduce NNsight, an open-source Python package with a simple, flexible API that can express interventions on any PyTorch model by building computation graphs. We also introduce NDIF, a collaborative research platform providing researchers access to foundation-scale LLMs via the NNsight API. Code, documentation, and tutorials are available at https://nnsight.net/.", "sections": [{"title": "INTRODUCTION", "content": "Research on large-scale AI currently faces two practical challenges: lack of transparent model access, and lack of adequate computational resources. This paper introduces the NNsight library and the National Deep Inference Fabric (NDIF), which together aim to address both of these challenges.\nModel access is limited by the secrecy of state-of-the-art commercial model parameters (OpenAI et al., 2023; Anthropic, 2024; Gemini Team et al., 2024). Commercial application programming interfaces (APIs) offer frontier models \u201cas a service,\" allowing thousands of concurrent users to share model instances and thus reducing computational costs. However, these APIs lack transparency for scientists studying model internals, such as intermediate activations or gradients used during neural network inference and training.\nModels with openly downloadable parameters provide partial transparency (Scao et al., 2022; Black et al., 2021; Touvron et al., 2023; Jiang et al., 2023). However, the adoption of these models is often limited to smaller sizes because models with tens of billions of parameters exceed a single GPU's memory capacity. When scaled to hundreds of billions of parameters, these models are too large even for the combined GPU memory of a single node. For example, inference on a 530 billion parameter LLM requires about 1TB of GPU memory just to load the model parameters in 16-bit precision (Aminabadi et al., 2022). Even if a scientist has access to such resources, evaluating large models blocks others from using the same resources concurrently, preventing their efficient utilization. The problem is worse still when we wish to perform deeper analyses of model internals, as such experiments are generally even more compute- and time-intensive. Thus, despite evidence that key capabilities emerge only in the largest models (Wei et al., 2022; Patel & Pavlick, 2022; Rae et al., 2021; Brown et al., 2020), studying them can often seem unattainable.\nAs a result, most researchers are limited to studying model internals using smaller models (Hernandez et al., 2024; Marks et al., 2024b; Brinkmann et al., 2024; Hanna et al., 2023; Wang et al., 2022). Research on large models is also typically limited to \u201cblack-box\" investigations using commercial APIs. In other words, research into the internal mechanisms of the largest (and most capable) models has been hindered by multiple infrastructural barriers.\nSurveys of AI research needs have documented this unsatisfactory situation (Shevlane, 2022; Bucknall & Trager, 2023; Casper et al., 2024): Specifically, Bucknall & Trager (2023) highlights the need for structured model access APIs that offer greater transparency than existing commercial AI APIs."}, {"title": "TRANSPARENT AND FLEXIBLE MODEL INTERACTIONS", "content": "NNsight minimizes the learning curve for researchers by providing transparent access to PyTorch-based models. Our approach combines a novel tracing context with programming idioms that will be familiar to PyTorch users.\nNNsight's core API uses a tracing context that encapsulates model interactions within a defined scope, building and executing its intervention graph upon exiting the scope. Inside this context, users can employ standard PyTorch operations to manipulate model internals, probe activations, and implement custom interventions."}, {"title": "REMOTE EXECUTION ON NDIF", "content": "On its own, NNsight empowers researchers to explore the internals of models running on their own hardware. Combining with the National Deep Inference Fabric (NDIF), however, allows them to work with foundation models hosted on remote GPUs by toggling a single keyword argument."}, {"title": "DESIGN", "content": "One of the core goals of NNsight is to create a common, highly-legible notation for expressing changes to models. Previously, researchers accessing model internals have \u201cforked\" code to add customization or have used callback hooks, but these ad-hoc conventions create diverse codebases which may be hard to read and understand. NNsight addresses this problem by introducing a workflow based on Python context managers that organizes model modifications in a way that is concise and easy to understand.\nWithin a context, NNsight exposes the inputs, outputs, and gradients of PyTorch Modules. Users can leverage this to modify computation anywhere in a PyTorch Module's forward or backward pass. Upon exiting the context manager, the interventions generate a computation graph which is hooked into a PyTorch Module. Users can extract PyTorch objects like activations, model outputs, or gradients from a given forward or backward pass using a save method. If the code is executed remotely, save will download and store the value in a local variable that the user can access."}, {"title": "INTERVENTIONS ARE PYTORCH CODE", "content": "Interventions are defined using basic PyTorch operations, which are written with regular PyTorch code (Figure 1, left). This is accomplished by overloading Python and PyTorch code within the tracing context. This setup allows users already familiar with PyTorch and NumPy syntax to create sophisticated interventions quickly, with as little overhead as possible."}, {"title": "GRAPH REPRESENTATION", "content": "Once interventions are defined, they can be represented as an intervention graph (Figure 1, middle). This allows for a number of flexible downstream use cases. For instance, when executing remotely, the graph is sent to a remote server through an intermediate custom json format (see Figure 2, Serialisation). Users can share their interventions with other users by exporting the graph to json or to a visualization, creating an ecosystem of shareable model interventions."}, {"title": "FLEXIBILITY", "content": "NNsight directly hooks into the PyTorch nn.Module object, allowing it to work with any torch model, Module, or architecture. To support common use cases, we include infrastructure for accessing custom models distributed by popular platforms like HuggingFace and Meta. However, the core package is architecture-agnostic: Interventions on custom models are a core use-case. For example, Sharma et al. (2024) used NNsight to investigate the mechanisms of factual recall in the Mamba state space model Gu & Dao (2023). This flexibility, along with the shareable graph idiom, enforces a common language across codebases: Regardless of input modality or model architecture, intervention graphs are saved using the same json specification."}, {"title": "TRANSPARENCY", "content": "The computation graph is fully accessible to the user during runtime. This allows users to inspect, debug, and understand the sequence and nature of operations being applied to the model. Each node in the graph contains information about the operation it represents."}, {"title": "IMPLEMENTATION", "content": "NNsight is built on a few core components that define a compositional language for modifying models. These components include the tracing context for building computation graphs, an envoy system for wrapping PyTorch modules, and an intervention graph for representing and executing operations. This section details the implementation of these elements and how they interact to provide NNsight's functionality."}, {"title": "THE TRACING CONTEXT", "content": "The core workflow in NNsight uses tracing contexts to build computation graphs, defined by an NNsight class object or one of its subclasses. When an NNsight object wraps a PyTorch Module, the tracing context exposes intermediate inputs and outputs. Within this context, user-specified operations, written in Python and PyTorch become nodes in an intervention graph. The graph's execution is deferred until the context exits.\nThis deferred execution scheme allows for debugging user specified operations and compute-efficient tracking of model operations without immediate execution."}, {"title": "INVOCATION", "content": "Multiple tracing contexts can be used with an invoke method, allowing for complex, multi-stage interventions. Code Example 4 uses invoke to implement activation patching - an intervention technique where neural network activations are replaced across a pair of inputs - which is a fundamental method for model interventions. Using NNsight 's invoke contexts, we can access and then replace a hidden state between a pair of prompts."}, {"title": "The Session Context", "content": "The session context in NNsight extends functionality for scenarios involving multiple traces. Unlike standard trace contexts where values are destroyed after execution, session tracks and preserves these values across multiple traces. The values can then be used for interventions that require information from previous executions of the intervention graph.\nThe session context enables an environment for multiple forward passes on remote infrastructure. Sessions are particularly valuable when working with very large models, as it allows researchers to perform complex analyses and interventions without the need to transfer large amounts of intermediate data between passes.\nBecause the session context allows multiple forward and backward passes, it can be used it for things like remote training and fine-tuning, including parameter-efficient fine-tuning (Lester et al., 2021), Low-Rank Adapters (Hu et al., 2021), and probing methods (Belinkov, 2022)."}, {"title": "PERFORMANCE", "content": "In this section we compare the performance of NNsight with other libraries that enable interventions on model internals. To ensure a fair comparison, we focus on libraries that use PyTorch as the underlying deep learning framework. We find that NNsight achieves competitive time efficiency across a range of tasks.\nOur performance comparison includes runtime measurements for activation patching and attribution patching across models with varying parameter counts and architectures. Specifically, we consider"}, {"title": "RELATED WORK", "content": "Research model hosting frameworks. The most similar previous works are Garcon (Elhage et al., 2021) and Petals (Borzunov et al., 2022). Garcon is a proprietary internal research system at Anthropic that supports remote inspection and customization of large models hosted on a remote cluster. Unlike the computation-graph approach of NNsight, Garcon operates by allowing researchers to hook models via arbitrary-code execution. As a result, co-tenancy is unsafe, so unlike the NDIF server which shares model instances between many users, Garcon requires each user to allocate their own model instance, which is computationally expensive. The Petals system has similar goals, but instead of distributing experiment code, it distributes foundation-model computation across user-contributed nodes in a BitTorrent-style swarm. Petals achieves co-tenancy by leaving researcher-defined computations on the user's own system. Unlike Petals, NNsight can avoid costly model-internal data transfers by executing computation graphs on NDIF servers.\nSeveral other solutions for sharing hosted model resources have been developed, including VLLM (Kwon et al., 2023), Huggingface TGI (Dehaene et al., 2024) and Nvidia TensorRT-LLM (Nvidia, 2024). These are systems for LLM inference acceleration that support large-scale multiuser model sharing. However, unlike NDIF, these systems only provide black-box API access to models, and do not permit model inspection or modification, which limits their utility for interpretability research.\nFrameworks for model internals. Numerous efforts have been made to create robust tools for exploring and manipulating model internals. TransformerLens (Nanda & Bloom, 2022) is designed to facilitate the exploration of GPT-style decoder-only language models. It allows users to apply custom functions to outputs of specific model modules. Unlike NNsight which operates on arbitrary PyTorch networks, TransformerLens is limited to autoregressive transformers. Pyvene (Wu et al., 2024) supports configurable intervention schemes on PyTorch modules, decorating a PyTorch module with hooks that allow activations to be collected and overwritten. Pyvene operates at a higher level of abstraction, and can be configured as a layer over NNsight. Baukit (Bau, 2022), a spiritual predecessor to NNsight, provides a range of utilities which simplify tracing and editing activations. But unlike NNsight, it lacks an intermediate representation for user actions on models. Penzai (Johnson, 2024) is an open-source functional library which provides a modular system that allows for introspection, visualization, and manipulation of neural network computation graphs; Penzai works within the JAX framework, in contrast to NNsight which works with PyTorch models."}, {"title": "ECOSYSTEM", "content": "The NNsight project encourages community participation. Interested researchers can join the NDIF Discord for updates, feedback, and collaboration opportunities. We welcome open-source participation via the project github page. For more information, visit our website, which contains detailed documentation, tutorials, and links to NNsight's GitHub repository and Discord server.\nMore information on NDIF can be found at https://ndif. us. Requests for early access to NDIF resources can be made through the Discord community. They are available to educational and research users with a U.S. affiliation after a short application. Other researchers with private GPU clusters may also deploy their own instance of NDIF, as the implementation is open-sourced with a permissive MIT license."}, {"title": "LIMITATIONS", "content": "NNsight and NDIF are limited in several areas:\nIntervention graph optimization. The intervention graph can be optimized by removing unnecessary operations, fusing operations, and applying other optimizations that are difficult to do in the dynamic Python environment. Libraries like TorchScript (DeVito, 2022) and TorchFX incorporate many such optimizations out-of-the-box.\nHigh-level abstractions. NNsight operates at a low level, using PyTorch operations within tracing contexts. This is a conscious design choice, because the tensor manipulation design choices in PyTorch are a familiar idiom going all the way back to APL (Iverson, 1962), minimizing user overhead to get started. However, packages like pyvene (Wu et al., 2024) or TransformerLens (Nanda & Bloom, 2022) provide abstractions which build functionality on top of PyTorch, and provide a common set of abstractions regardless of the underlying model's implementation details.\nClosed-source model support. NNsight cannot run closed-source, proprietary models like GPT-4 or Claude. However, the API is designed to be technically feasible for companies to support without giving up custody of their proprietary model parameters."}, {"title": "CONCLUSION", "content": "We introduce NNsight, an open-source Python library that provides access to the internals of foundation models, including those too large to analyze on most individual or academic hardware. By leveraging NDIF infrastructure, NNsight enables researchers to perform complex interventions and explore neural networks at a scale previously limited by computational and financial constraints. NNsight supports a range of research activities focussed on model interpretability, including probing, intervention, and optimization; it is designed to be intuitive, architecture-agnostic, and capable of both local and remote execution.\nNNsight and NDIF provide tooling to run interpretability analyses in a standardized way and the ability to do so on (very) large models hosted remotely, respectively. Our hope is that this helps to democratize large model access and ultimately facilitate rapid progress on research into large generative models and their inner-workings."}]}