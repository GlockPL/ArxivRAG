{"title": "Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report", "authors": ["Markus Dablander"], "abstract": "Video games are a natural and synergistic application domain for artificial intelligence (AI) systems, offering both the potential to enhance player experience and immersion, as well as providing valuable benchmarks and virtual environments to advance AI technologies in general. This report presents a high-level overview of five promising research pathways for applying state-of-the-art AI methods, particularly deep learning, to digital gaming within the context of the current research landscape. The objective of this work is to outline a curated, non-exhaustive list of encouraging research directions at the intersection of AI and video games that may serve to inspire more rigorous and comprehensive research efforts in the future. We discuss (i) investigating large language models as core engines for game agent modelling, (ii) using neural cellular automata for procedural game content generation, (iii) accelerating computationally expensive in-game simulations via deep surrogate modelling, (iv) leveraging self-supervised learning to obtain useful video game state embeddings, and (v) training generative models of interactive worlds using unlabelled video data. We also briefly address current technical challenges associated with the integration of advanced deep learning systems into video game development, and indicate key areas where further progress is likely to be beneficial.", "sections": [{"title": "Introduction", "content": "In the last decade, the rise of advanced neural network architectures has led to a series of dramatic breakthroughs in the fields of machine learning and artificial intelligence (AI). The GPU-accelerated training of large, carefully designed deep learning models has enabled researchers to tackle previously intractable challenges in diverse areas such as computer vision [1, 2, 3, 4, 5], natural language processing [6, 7, 8, 9], artificial content generation [10, 11, 12, 13], and computational chemistry [14, 15, 16, 17, 18]. One exceptionally promising and natural application area for modern deep learning, which will be explored in this report, is digital gaming.\nThe focus of AI research on games already has a long and important history. In particular, the study of classical board games such as Chess, Checkers, and Go has been formative and instrumental for the AI field as a whole [19, 20]. The highly structured nature of many games allows for the emergence of great complexity and strategic depth from simple rules that can easily be expressed in a computational framework; consequently, games have long been considered ideal testing grounds for the reasoning and planning capabilities of AI agents. A significant milestone was reached in 2016, when the first AI system achieved superhuman performance in the game of Go [21], which, at that time, represented the last major, popular board game in which human experts still outperformed computers.\nParticularly since then, digital games have increasingly been recognised as one of the next great frontiers of AI research. In recent years, considerable progress has been made towards developing AI agents capable of mastering real-time strategy video games, such as StarCraft II [22], and multiplayer online battle arena video games, such as Dota 2 [23], both of which pose a far greater challenge to AI systems than classical board games. Simultaneously, the construction of general AI models that can learn to play multiple, qualitatively distinct arcade video games has emerged as an active field of research [24, 25, 26], and work in this area may serve as a stepping stone towards the development of more general AI systems in other domains.\nImportantly, it is not merely the case that video games have the potential to enrich contemporary AI research; the converse is true as well. The relationship between AI research and digital gaming is mutual and synergistic [19, 20, 27], with video games providing valuable benchmarks, test-beds and virtual environments for novel AI systems, while novel AI systems, in turn, provide a wealth of opportunities for video game developers to enhance their creative products. Partly due to the rapid progress of recent AI technologies, in particular deep learning, many of these opportunities are still underutilised and have yet to be explored.\nThis report aims to give a concise, preliminary overview of a selection of five potential research avenues for the application of state-of-the-art AI techniques to digital gaming. While our emphasis will mainly be on research directions where contemporary AI methods can enhance digital gaming, the reciprocal connection between AI and video games makes it conceivable that investigating these topics could also drive new insights and advancements in AI itself. The objective of this exploratory report is not to provide a comprehensive set of mature research proposals, or to present novel original research findings. Instead, the focus is on offering a speculative collection of high-level ideas that may serve to inspire more rigorous and focused research efforts in the future. The selected areas are not in any way exhaustive, but rather represent a curated and necessarily subjective collection of ideas deemed particularly intriguing during our examination of the current research landscape.\nThe foundational book from Yannakakis and Togelius [20], which served as one of the most valuable references for this work, outlines three core applications of AI to video gaming:\n\u2022 AI for game playing and agent modelling, which includes simulating the role of a human player [22, 23], or controlling other game agents in the broadest sense, such as non-player characters (NPC) [28, 29], or hidden agents governing aspects of the game environment [30].\n\u2022 AI for procedural content generation [31], which includes the algorithmic creation of game levels, music, textures, art, dialogues, items, characters, or any other digital content.\n\u2022 AI for player modelling [32], which includes the modelling of human player characteristics, such as player type, predicted in-game behaviour, or emotional state, based on measured gameplay and player data.\nAll of these three areas are reflected in the research avenues discussed below, with a greater emphasis on the first two."}, {"title": "Large Language Models for Game Agent Modelling", "content": "Large language models (LLMs) such as OpenAI's GPT-4 [33], Google's Llama 3 [34], and Anthropic's Claude 3 [35] have recently risen to enormous prominence due to their advanced capabilities to maintain realistic conversational arcs and generate flexible solutions to a wide range of language-related tasks. Current state-of-the-art LLMs are based almost exclusively on variants of the transformer architecture, introduced in the seminal work of Vaswani et al. [7] in 2017. Transformer networks rely on the concept of self-attention, a deep learning mechanism designed to effectively capture long-range dependencies and contextual information in sequential data. The core training process for many LLMs is self-supervised and autoregressive, meaning that the LLM is trained to generate text by probabilistically predicting the next word (or subword token) in a text based on the preceding words. LLMs regularly contain billions of trainable parameters and are frequently trained on vast corpora of unlabelled textual data collected from publicly available sources such as books and websites [36].\nAt the moment, LLMs are attracting significant attention within the video game AI research community for their potential applicability to a diverse array of gaming-related tasks [37, 38]. For example, LLMs have recently been explored for the algorithmic creation of new video game levels in Super Mario Bros [39], the autonomous playing of Minecraft through the generation of code for a suitable game API [40], the systematic extraction of player sentiment from written game reviews [41], and the automatic generation of dynamic audio commentary for League of Legends gameplay [42]. Covering all promising use cases of LLMs in digital gaming would be beyond the scope of this exploratory report. However, we briefly highlight one possible research direction we consider to be particularly interesting, namely the use of LLMs for game agent modelling.\nGame agent modelling includes the development and control of NPCs such as teammates, enemies, sidekick companions, merchants, bystanders, and other virtual characters in the broadest sense. Perhaps one of the most evident and fruitful applications of LLMs in this context would be to equip NPC agents with the ability to have natural and unscripted conversations with each other and with human players. First investigations in this area have already begun [43, 44, 45]; further advancements in integrating LLMs as NPC dialogue systems may be able to markedly enhance the realism of virtual characters, leading to substantially deeper and more immersive video game experiences.\nHowever, the overall potential of LLMs for agent modelling may exceed the already appealing area of dynamic dialogue generation. In 2024, Hu et al. [46] gave a conceptual description of an entire cognitive architecture for general game agents that embeds an LLM as the core thinking component within a network of other submodules covering perception, memory, role-playing, action, and learning. Drawing closely from the work of Hu et al., one might envision an LLM-based cognitive architecture broadly working as follows: the perception module translates current game states into textual descriptions; the thinking module, powered by an LLM, receives outputs from the perception module and relevant text-based memories retrieved from the memory module to output textual action plans; these plans are translated by the action module into executable low-level in-game actions; the LLM-based thinking process is additionally biased with character information by the role-playing module; and continuously updated with techniques such as reinforcement learning or supervised finetuning by the learning module. One may also consider introducing a separate goal module that manages the objectives of the agent in a text-based manner and interacts with the other modules.\nWhile each of the above modules could easily warrant its own extensive research programme, first successful attempts to design game agents via the integration of LLMs into broader cognitive architectures have already been made. Most notably, Park et al. [44] created an interactive artificial society consisting of a virtual 2D village with 25 distinct LLM-based game agents with different personalities and professions. Each agent maintains a text-based memory stream that contains a comprehensive list of the agent's perceptions, along with generated action plans and synthesised higher-order reflections. An LLM interacts with the agent's memory stream and current perceptions to generate new reflections and adapt action plans. This approach leads to an impressively complex and convincing set of self-organising emergent social behaviours: agents lead natural dialogues, coordinate actions, spread information, and dynamically update social relationship memories. A simple, schematic overview of an LLM-based cognitive architecture, heavily inspired by the works of Park et al. [44] and Hu et al. [46], is depicted in Figure 1.\nFurther efforts, such as those by Park et al., to integrate LLMs into a broader network of cognitive modules could not only contribute to the development of more immersive video game characters and"}, {"title": "Neural Cellular Automata for Procedural Content Generation", "content": "Cellular automata (CA) [49, 50] are a family of extensively investigated and diverse mathematical models represented by grids of cells, whose states evolve in discrete time. At each time point t, each cell has a state represented by a number (or a vector of numbers), and its state at time t + 1 is determined by its own state and the states of its neighboring cells at time t, according to a local transition function that defines how the states evolve.\nA simple and iconic example of CA that many readers may be familiar with is given by Conway's Game of Life [51], which takes place on an infinite 2D orthogonal grid of square cells, each of which can only be in one of two possible states, dead or alive. Given some initial configuration, cell states start to evolve based on a simple transition function that only takes into account how many dead or alive neighbours a cell has at a given time. In spite of its extreme simplicity, Conway's Game of Life exhibits an impressive set of complex self-organising behaviours.\nCA have already been used in video games with considerable success, for instance to grow infinite cave levels for the game Cave Crawler [52], automatically generate playable mazes for maze running games [53], model granular media like sand or soil [54], or simulate erosion in virtual environments [55]. CA are highly computationally efficient models that can be used to generate intricate virtual content. At the same time, CA are conceptually simple, intuitive to understand and easy to implement. However, the constructive, emergent nature of CA also makes them difficult to control [20]. In general, given a local transition function, it is very difficult to predict which pattern will arise over time from a specific initial grid state; even extremely similar initial states may quickly diverge in a chaotic manner, leading to entirely different outcomes [56]. Similarly, identifying a local transition function that over time maps a given initial state to a desired pattern is a nontrivial technical problem. These properties limit the utility of CA as procedural content generators for video games by making it challenging to impose essential constraints on generated content. Such constraints may"}, {"title": "Deep Surrogate Modelling to Accelerate Computationally Expensive In-Game Simulations", "content": "In their seminal study, Gilmer et al. [14] not only introduced message-passing as a unifying framework for graph neural network architectures; in addition to this salient contribution, they also showed that a graph neural network can learn to efficiently predict quantum-chemical properties of small molecules using the QM9 data set [67] for training. The QM9 data set consists of around 134k chemical compounds; each compound comes with a set of numerical labels that represent approximations of relevant quantum-chemical properties. For each compound, each numerical label is the result of a quantum-mechanical simulation based on what is known as density functional theory [68]. Density functional theory simulations, while highly useful for elucidating the electronic structure of a molecule, are associated with prohibitive computational costs; for example, generating all the labels in the QM9 data set for a single molecule with nine heavy atoms on a single core of a Xeon E5-2660 processor with 2.2 GHz and commonly used software may take around one hour [14]. In contrast, the graph neural network from Gilmer et al., which was trained on the QM9 data set in a supervised manner, can estimate the outcome of density functional theory simulations for a novel molecule in a fraction of a second. This corresponds to a speed-up of five orders of magnitude, making it computationally feasible to rapidly predict quantum-chemical properties for large molecular libraries.\nThe work of Gilmer et al. represents a prime example of what can be referred to as deep surrogate modelling [69, 70, 71, 72]. A high-level illustration of the key idea behind deep surrogate modelling is given in Figure 3. In one of its most elementary forms, deep surrogate modelling is a technique used to speed up the evaluation of a computationally expensive function\n$f: X \\rightarrow R^n$\nthat is of interest for a practical application. For instance, f could represent an expensive numerical computer simulation. In our earlier example from Gilmer et al., the domain X would be a set of molecular graphs, and f would represent a density functional theory simulation that maps molecular graphs to numerical quantum-chemical properties expressed as vectors in R\u201d. Initially, a (sometimes considerable) computational effort is made to create a data set\n$D = \\{(x_1, f(x_1)), ..., (x_m, f(x_m))\\} \\subseteq X \\times R^n,$\nwhich is then used to train the parameters @ of a suitable deep learning architecture\n$\\Phi_\\theta: X \\rightarrow R^n$"}, {"title": "Self-Supervised Video Game State Representation Learning", "content": "Being able to represent the abstract state of a video game in terms of a meaningful numerical vector is a key element in a large variety of modern AI applications for digital gaming [20]. In this context, a high-quality vectorial representation technique should be able to condense the essential features of a video game state into an informative embedding that can be effectively used for downstream AI tasks. Such tasks may, for example, include using a game state embedding as a model of perception for an autonomous game agent [26, 80], predicting the emotional state of a player from gameplay video streams [81], predicting future game states from current ones [82], dynamically adapting game music depending on the state of a game [83], or algorithmically translating game states into natural language descriptions [44].\nA powerful deep learning paradigm for vectorial data representation that has emerged in recent years is self-supervised learning [84], which offers a collection of strategies to learn rich, general-purpose embeddings solely from the internal structure of unlabelled input data. While supervised deep learning is based on the extraction of task-specific features from labelled data sets, self-supervised learning does not rely on data annotation by human subjects, and instead allows one to find flexible feature representations in a task-agnostic manner. Labelled data is frequently scarce and hard to obtain; self-supervised learning methods do not suffer from comparable limits, as they can take advantage of vast corpora of unlabelled data sets, such as curated libraries of images and text extracted from the internet. Representations learned via self-supervised training can be employed in a variety of ways, including clustering [85] and anomaly detection [86]. Importantly, they can also be fine-tuned on downstream supervised tasks [87], an approach that regularly leads to substantial boosts in performance compared to purely supervised techniques.\nWhile self-supervised learning has become a significant area of research in domains like natural language processing and computer vision [88], comparable work in digital gaming is still relatively sparse. A literature search for studies that use concepts from self-supervised learning in digital gaming revealed only 12 instances [80, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]. In a notable article, Anand et al. [80] introduced a systematic benchmark to evaluate self-supervised learning methods for video game states via the prediction of essential internal game variables in Atari 2600 games from learned representations. They employed this benchmark to demonstrate the effectiveness of a mutual-information-based representation learning strategy. In a related study, Trivedi et al. [89] showed that three popular self-supervised learning strategies applied to video game pixels alone can be used to derive game state embeddings that are predictive of key internal game variables, such as enemy positions on the screen in a first-person shooter, or game world coordinates of football players and the ball in a football simulator.\nRepresenting video game states via state-of-the-art self-supervised learning may be an impactful area for future research. One particularly interesting approach could be to further investigate joint-"}, {"title": "Learning Generative Models of Interactive Worlds from Unlabelled Videos", "content": "In early 2024, Google DeepMind introduced Genie [104], an 11-billion parameter generative world model trained in a self-supervised manner on a large-scale library of publicly available gameplay videos of 2D platformer games. Genie can automatically generate an infinite variety of novel and action-controllable 2D platformer gaming worlds. Each unique world is created using only a single image as an initial seed.\nThe neural architecture of Genie consists of three major components, all of which rely on the use of computationally efficient spatiotemporal transformer models [7, 105]: a video tokeniser, a latent action model, and a dynamics model. The video tokeniser is implemented via a VQ-VAE [106] that is trained to translate video game frames into discrete vectorial tokens, and vice versa. The latent action model is trained to infer plausible actions between consecutive pairs of frames. It too is based on a VQ-VAE architecture that naturally allows for limiting the number of possible actions to a small, fixed-size set of discrete vectorial action embeddings. Most notably, the latent action model is trained in an entirely self-supervised way, without the need for human-annotated action labels. The dynamics model [107] is trained autoregressively to predict future tokenised frames from past and current tokenised frames and inferred action embeddings. As a result, the dynamics model is encouraged to learn the consequences of actions on the temporal evolution of the video game world.\nOnce trained, the Genie system can be operated in the following way:\n1. A user first prompts Genie with an image x1 vaguely resembling a scene from a platformer game. This image serves as the initial game frame. The starting image x\u2081 could for instance be a screenshot from an actual game, an imagined sketch drawn by a human, or an artificial image created via a text-to-image generator [108] from a natural language description.\n2. The image x1 is compressed into a discrete vectorial token 21 using the video tokeniser.\n3. The player can then input an initial action which is translated into a discrete vectorial action embedding a\u2081 by a component of the latent action model.\n4. The dynamics model uses its acquired world knowledge [109] to predict the next tokenised frame 22 based on action a\u2081 and state 21.\n5. The compressed vectorial token 22 is decoded into the next video game frame x2 by the video tokeniser. The image frame x2 is displayed to the user.\n6. The last three steps are iteratively repeated to give rise to an interactive sequence of image frames\n$(x_1, x_2, x_3, ...)$\nthat constitute a playable platformer game. For example, after the initial iteration, the user specifies another action a2, the dynamics model uses (21, 22) and (a1, a2) to predict 23, and 23 is subsequently decoded into the next visible frame x3.\nThis process is visualised in Figure 5.\nOne of the limitations of Genie outlined in the original article [104] is its low frame rate, reported to be around one frame per second. Genie may also sometimes hallucinate unrealistic future scenarios, or fail to maintain the stability and consistency of a generated world over time. Despite these"}, {"title": "Current Technical Challenges for Deep Learning in Digital Gaming: A Critical View", "content": "While modern AI techniques, in particular deep learning, hold significant promise to enhance the future of video gaming experiences, serious technical challenges remain. As in other application areas of neural networks, these challenges frequently revolve around computational efficiency and speed, interpretability and predictability, the setting of model constraints, data requirements, model generalisation abilities, privacy considerations, and financial costs. Other, more game-specific issues centre around the complexities of integrating deep learning systems into traditional game development workflows, development time, managing player expectations with regards to AI, maintaining narrative control of video game stories, ensuring model consistency, and preserving debugging options.\nOne of the main concerns of game developers is the feasibility of training, running and gathering data for advanced deep learning architectures [123, 124]. The large amount of computation time and expensive hardware required to train state-of-the-art models such as LLMs or interactive-world generators represent an important bottleneck, especially for small and moderately-sized studios. Furthermore, if a model does not generalise effectively to new scenarios, it may have to be discarded or retrained. In supervised settings, it may be intractable to obtain sufficient amounts of human-annotated training data. If supervised data relates to in-game behaviour or player analytics, this may also potentially raise concerns regarding privacy ethics. In addition, running large trained models in real-time during gameplay could decelerate frame rate and responsiveness to unacceptably low levels.\nFurther hurdles for game developers arise in connection to the black-box nature of deep learning systems [125, 126], which refers to the difficulty in understanding how such models make predictions and arrive at decisions. Neural networks consist of inscrutable compositions of large matrices and"}, {"title": "Conclusions", "content": "In this work, we illuminated five promising research pathways for the application of state-of-the-art AI techniques to digital gaming: LLMs for game agent modelling, neural cellular automata for procedural content generation, deep surrogate modelling to accelerate expensive in-game simulations, self-supervised game state representation learning, and the use of unlabelled video data to train generative models of interactive worlds. The primary objective of this report is to provide a high-level overview of these areas within the current research landscape, with the aim of sparking intellectual curiosity for more targeted and in-depth research efforts in these or related fields in the future.\nVideo games are one of the most natural and important research frontiers in the search for general artificial intelligence systems, as they offer an almost limitless abundance of distinct cognitive tasks and simulated environments to challenge virtual agents. Further work in the areas discussed in this report could not only lead to novel technologies that enhance the quality and immersiveness of digital gaming experiences; it could also drive scientific developments in the search for more useful and capable AI models overall. For instance, research on LLM-based video game agents could lead to progress on the debated question to what extent purely language-based systems are in fact suitable as models for general intelligence [47, 48]; and advanced generative models of interactive worlds could supply AI agents with a potentially infinite stream of complex virtual training and testing environments [104, 111].\nWhile we regard the research directions described in this work to hold considerable potential, it is important to note current challenges that may still limit the practical utility of deep learning in digital gaming. Issues remain around topics such as interpretability, predictability, consistency, debuggability, data requirements, generalisation, reusability, the setting of model constraints, as well as financial and computational efficiency. Systematic efforts to address these technical obstacles, alongside experimentation with novel research ideas like those outlined in this report, should be a high priority to accelerate future progress in both AI and video game research."}]}