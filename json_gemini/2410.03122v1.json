{"title": "RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning", "authors": ["Zihao Zhao", "Yuchen Yang", "Yijiang Li", "Yinzhi Cao"], "abstract": "The ripple effect poses a significant challenge in knowledge editing for large language models. Namely, when a single fact is edited, the model struggles to accurately update the related facts in a sequence, which is evaluated by multi-hop questions linked to a chain of related facts. Recent strategies have moved away from traditional parameter updates to more flexible, less computation-intensive methods, proven to be more effective in the ripple effect. In-context learning (ICL) editing uses a simple demonstration Imagine that + new fact to guide LLMs, but struggles with complex multi-hop questions as the new fact alone fails to specify the chain of facts involved in such scenarios. Besides, memory-based editing maintains additional storage for all edits and related facts, requiring continuous updates to stay effective. As a result of the design limitations, the challenge remains, with the highest accuracy being only 33.8% on the MQUAKE-CF benchmarks for Vicuna-7B. To address this, we propose RIPPLECOT, a novel ICL editing approach integrating Chain-of-Thought (COT) reasoning. RIPPLECOT structures demonstrations as {new fact, question, thought, answer}, incorporating a thought component to identify and decompose the multi-hop logic within questions. This approach effectively guides the model through complex multi-hop questions with chains of related facts. Comprehensive experiments demonstrate that RIPPLECOT significantly outperforms the state-of-the-art on the ripple effect, achieving accuracy gains ranging from 7.8% to 87.1%. RIPPLECOT is open-source and available at https://github.com/zzhao71/RippleCOT", "sections": [{"title": "1 Introduction", "content": "As large language models (LLMs) become more prevalent in various sectors, their limitations, such as storing inaccurate or sensitive knowledge, pose growing concerns (Dhingra et al., 2022; Carlini et al., 2021; Wolf et al., 2019). This has led to the development of knowledge editing methods aimed at updating the facts. The ripple effect represents a significant challenge in knowledge editing for LLMs that was not explored until very recently (Cohen et al., 2023). When one fact is edited in a model, the ripple effect refers to the chain of related facts that should be updated following the edited one, which is evaluated by the multi-hop questions (Zhong et al., 2023) linked to a chain of facts. Figure 1 illustrates an example of the multi-hop question: if we modify the author of Misery to Richard Dawkins, the related multi-hop facts, such as the citizenship of the author of Misery, should also be updated.\nConventional parameter-based editing methods, such as fine-tuning (Zhu et al., 2020) or matrix computation (Meng et al., 2022b), update the model's parameters to recall specific edited facts effectively but risk catastrophic forgetting (Zheng et al., 2023) and were proven failure on the ripple effect (Cohen et al., 2023). The edits are limited to the facts within the training data and struggle with related but untrained facts. Recent parameter-free editing approaches, like memory-based editing (Mitchell et al., 2022), also face challenges when related facts fall outside the maintained memory's scope. In-context learning (ICL) editing uses the simple prompt Imagine that + new fact to help the model recall the new fact. However, it struggles with complex, multi-hop questions because the new fact alone does not specify the chain of facts within such scenarios. Due to those limitations, the best result (Zhong et al., 2023) achieves only a 33.8% accuracy on the MQUAKE-CF benchmarks with Vicuna-7B model, with other methods performing around 15%.\nTo address this, we propose to integrate COT reasoning into the ICL framework, guiding LLMs to process multi-hop questions sequentially. While we observe the direct use of a \"Think step by step\" COT prompt improving performance, it falls short in open-source models with limited reasoning capacities. To arrive at a better solution, we develop RIPPLECOT, by structuring the demonstration to (new fact, question, thought, answer). RIPPLECOT operates in two stages: demonstration generation and refinement. During generation, RIPPLECOT identifies multiple relationships and missing items within the defined fact triplets (s, r, o) (Cohen et al., 2023), i.e., subject, relation, and object. For example, in Figure 1, the question involves multiple relations: citizenship and head. RIPPLECOT decomposes the questions into (Ellie Kemper, citizenship, ?) and (?, head, ?*). Given the new fact (Ellie Kemper, citizenship, Croatia), the ? is identified as Croatia. The thought then becomes Ellie Kemper is a citizen of Croatia \u2192 Croatia's head of state is Zoran Milanovic. This effectively triggers the COT reasoning ability of the LLMs, significantly improving the ripple effect for more complex questions. In the refinement stage, RIPPLECOT selects the top-k candidates among generated (new fact, question, thought, answer) pairs whose questions have the highest cosine similarity with the task question.\nBeyond COT reasoning ability, RIPPLECOT of-fers several advantages. First, RIPPLECOT operates without altering model parameters, resulting in lower computational costs and enabling efficient adaptation to multi-hop questions for a single edit. It also supports multiple editing scenarios, which have been less explored by the literature, such as accurately updating the related facts if changing the President of the United States from Obama to Trump and then to Biden. Second, our COT demonstration generation is automatic and highly flexible, tailored to task-specific questions. We have designed and evaluated multiple methods for generating demonstrations, including human selection from benchmark datasets along with the existing approaches, few-shot generation using GPT-40 (Achiam et al., 2023) based on selected references, and zero-shot generation with GPT-40, identifying the optimal approach for enhancing ripple effects. Additionally, RIPPLECOT can be integrated with existing knowledge editing methods to further improve ripple effect performance.\nIn summary, this paper has three main contributions:\n\u2022 We propose a novel ICL knowledge editing framework with automatic COT demonstration generation and refinement, namely RIPPLECOT.\n\u2022 We explore different ways for generating COT demonstration, namely full-shot selection, few-shot generation, and zero-shot generation\n\u2022 RIPPLECOT significantly improves accuracy, ranging from 7.8% to 87.1%, in addressing ripple effects on multi-hop questions, as demonstrated on the RIPPLEEDIT (Cohen et al., 2023) and MQUAKE (Zhong et al., 2023) datasets."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Knowledge Editing", "content": "Knowledge editing methods include parameter-based methods (Mitchell et al., 2021; Meng et al., 2022a; Dong et al., 2022) and parameter-free methods (Zheng et al., 2023; Zhong et al., 2023; Wang et al., 2024; Chen et al., 2024). In parameter-based editing methods, Fintuning (Zhu et al., 2020) uses gradient descent to update model parameters based on the edit; MEND (Mitchell et al., 2021) introduces hyper-networks that convert the gradients to model parameter changes; ROME (Meng et al., 2022a) introduces causal tracing that locates and updates the parameters responsible for factual associations. However, these methods can result in catastrophic forgetting of previously learned"}, {"title": "2.2 Ripple Effect", "content": "A common under-addressed problem of all knowledge editing methods is the propagation of knowledge updates to other logically connected facts, which is referred to as the ripple effect. Cohen et al. (Cohen et al., 2023) first define and categorize the ripple effects into logical generalization, compositionality I & II, subject aliasing, preservation, and relation specificity, each denoting a different logical pattern. Compositionality I & II involves two-hop questions, in which the models perform the worst. This observation is recapitulated by Zhong et al. (Zhong et al., 2023), where the performance of the edited model is evaluated by 2,3,4-hop questions. Overall, the knowledge editing performance decreases as the intermediate logical steps increase."}, {"title": "3 Problem Formulation", "content": "Knowledge editing aims to update the fact triplet from $(s, r, o)$ to $(s, r, o^*)$, where s is the subject, r the relation, o the original object and $o^*$ the new object. These triplets are formulated (Petroni et al., 2018) as prompt templates $p(s, r, \\text{@})$,\u2014for example, with s = Stephen King, r = Citizenship and @ is a place holder for the object, the prompt is: The citizenship of Stephen King is ___. Using a language model $f : X \\rightarrow Y$, which processes input prompt $x \\in X$ to generate output $y \\in \\mathcal{Y}$, we probe the model with $p(s,r, \\text{@})$. The output $f(p(s,r,o))$ should match the original object o, such as American. After editing, the model $f^*$ should return $f^*(p(s, r, \\text{@}))$, matching the updated object $o^*$, such as British."}, {"title": "3.1 In-Context Knowledge Editing", "content": "Given a new fact triplet $(s, r, o^*)$, In-context knowledge editing injects it via an input prompt starting with the prefix \u201cImagine that\u201d (Cohen et al., 2023), following the template $p(s,r, o^*)$ We denoted this new fact injection as $e(s,r,o^*) = $\u201cImagine that\u201d + $p(s, r, o^*)$. The edited model is then defined as $f^* = f \\circ (e(s,r,o^*))$. To verify the edit, we query the edited model with $f^*(p(s, r, o))$ and check if it successfully recalls $o^*$."}, {"title": "3.2 Ripple Effect with Multi-hop Questions", "content": "The ripple effect is assessed through multi-hop questions (Zhong et al., 2023). Imagine a chain of facts $\\mathcal{Q} = \\{(s_1, r_1, o_1),..., (s_n, r_n, o_n)\\}$, where each object o serves as the subject $s_{i+1}$ in the subsequent fact. We refer to the set of relations as $\\mathcal{R} = \\{r_1,...,r_n\\}$ and the set of subjects as $\\mathcal{S} = \\{s_1,...,s_n\\}$. The multi-hop questions are formulated using $\\mathcal{Q}$ that begins with the head entity $s_1$ till the $r_n$, and the answer is the tail entity $o_n$. For instance, consider the question What is the citizenship of the author of Misery? composed of the fact chains {Misery, Author, Stephen King} and {Stephen King, Citizen, American}. If we update the first fact to {Misery,Author,Ellie Kemper}, the edited model $f^*$ is validated by checking if the response for the above question is British instead of American, reflecting the related fact {Ellie Kemper,Citizen,British}."}, {"title": "4 RIPPLECOT", "content": "As discussed above, knowledge editing faces the challenge of ripple effects where a sequence of related facts should also be updated to arrive to the correct answer to some particular question. This chain of related facts for knowledge editing resembles a chain of thoughts in reasoning which motivates us to integrate CoT reasoning into the ICL pipeline and propose RIPPLECOT as a unified solution."}, {"title": "4.1 RIPPLECOT Formulation", "content": "For each knowledge editing, we construct k demonstrations $\\mathcal{D} = \\{d_1,...,d_k\\}$, which $d_i \\in \\mathcal{D}$ consist of four main components: new fact, question, thought, and answer.\nNew facts. $(s_1,r_1,o_1)$, which are examples of information designated for edits."}, {"title": "Questions.", "content": "Multi-hop questions $p(\\mathcal{S}, \\mathcal{R}, \\text{@})$ with $s \\in \\mathcal{S}$ and $r \\in \\mathcal{R}$, which are formulated to probe the related facts following the new facts, thereby assessing the ripple effects of edits."}, {"title": "Thoughts.", "content": "Break down the questions according to each relation $r_1, ..., r_n \\in \\mathcal{R}$ as follows:\n$$\n\\{\ns_1, r_1, o_1\\}\\\\\ns_2 = o_1, r_2, o_2 \\\\\n:\\\\\n:\\\\\ns_{n-1} = o_{n-1}, r_{n-1}, o_*\\}\n$$\nAnswers. $o_n$, which provides the exact answer to the question, derived from the logical reasoning in the thoughts section.\nThe goal of the demonstration is to allow the model to generate the correct answer through its COT reasoning ability, establishing clear connections between the new facts and their related facts to the final answers."}, {"title": "4.2 Demonstration Generation", "content": "To generate k demonstrations $\\mathcal{D} = \\{d_1,...,d_k\\}$ with the COT formulation, we explore three approaches:\nFull-shot Selection. $\\forall d_i \\in \\mathcal{D}$, the {new fact, question, thought, answer} set is randomly selected from the MQUAKE benchmark. This ensures high-quality, logically coherent contexts that serve as reliable examples for the model.\nFew-shot Generation. To generalize the demonstration beyond the scope of MQUAKE, RIPPLECOT first creates a reference set $\\mathcal{D}_{refer}$ containing a few demonstrations using the human selection. This reference set is then used to guide LLMs, which have shown remarkable reasoning and instruction-following ability, in generating demonstrations with a similar format. We evaluate both GPT-40 and GPT-J generated demonstrations, the prompt is as follows:\nZero-shot Generation RIPPLECOT explore the Zero-shot Generation ability (Ramesh et al., 2021) of LLMs to directly generate examples following specific formats. Specifically, we remove the reference set $\\mathcal{D}_{refer}$, using only the COT format introduced in Section 4.1. We use both GPT-40 and GPT-J to generate the demonstrations using the above prompt, omitting the line \"Example: $\\mathcal{D}_{refer}$\"."}, {"title": "4.3 Demonstration Refinement", "content": "After demonstration generation, we refine the demonstration by ordering it by the similarity (Lu et al., 2021) between the question components in the $\\mathcal{D}$, denoted as $\\{q_{demo}\\}_{i=1}^k$, and the question that we want the model to answer, denoted by $\\{q_{target}\\}_{i=1}^k$. We follow Liu et al. (Liu et al., 2021) to use the all-MiniLM-L6-v2 (Wang et al., 2020) to get embeddings (Reimers and Gurevych, 2019) denoted as $\\{E(q_{demo})\\}_{i=1}^k$ and $\\{E(q_{target})\\}_{i=1}^k$ respectively. The similarity $\\{m\\}$ is calculated by the cosine similarity (Huang et al., 2008) with each $m_i$:\n$$\nm_i = \\frac{E(q_{demo}) \\cdot E(q_{target})_i}{\\sqrt{E(q_{demo})^2 \\cdot E(q_{target})_i^2}}\n$$\nThen, RIPPLECOT select the top-t demonstrations from $\\{q_{demo}\\}_{i=1}^k$ with with the highest $\\{m\\}$. This approach ensures that the most relevant demonstrations are selected, thereby improving the overall performance of the model."}, {"title": "5 Experiments", "content": ""}, {"title": "5.1 Experiment Setup", "content": "We primarily assess our method using the MQUAKE (Zhong et al., 2023) and RIPPLEEDIT (Cohen et al., 2023) dataset with the models GPT-J (6B) (Wang and Komatsuzaki, 2021), Vicuna-7B (Zheng et al., 2024), and GPT-3 (Brown et al., 2020; Ouyang et al., 2022). We adopt the accuracy metric from previous work (Zhong et al., 2023; Cohen et al., 2023), where an answer is deemed correct if the model's output contains the expected answer. We set our default setting as the full-shot selection with k = 5 demonstrations."}, {"title": "5.1.1 Dataset", "content": "RIPPLEEDIT. This dataset contains counterfactual knowledge editing examples (Meng et al., 2022a)."}, {"title": "5.1.2 Baseline", "content": "We conduct a comparative analysis of RIPPLECOT against several established techniques: Fine-tuning (FT) (Zhu et al., 2020), MEND (Mitchell et al., 2021), ROME (Meng et al., 2022b), DeepEdit (Wang et al., 2024), IKE (Cohen et al., 2023) and MEMIT (Meng et al., 2022a), as well as our proposed BaseCOT, which adds a \"Think step by step\" prompt (Kojima et al., 2022) after the question, as the baseline method for the RIPPLECOT approach.\nFT: FT employs gradient descent to update model parameters based on the edits, directly modifying the weights to reflect the new information.\nMEND: MEND trains a hypernetwork to transform raw fine-tuning gradients based on an edited fact, creating targeted weight updates to integrate new factual content.\nROME: ROME identifies and localizes factual knowledge within specific Transformer layers, then updates the feedforward networks in those layers to incorporate new facts.\nMeLLo: MeLLo stores edited facts externally. During runtime, related facts are retrieved, and conflict detection ensures appropriate edited outputs.\nMEMIT: MEMIT extends ROME by enabling simultaneous editing of a large set of facts. It updates feedforward networks across multiple layers, effectively encoding a broader range of factual information.\nDeepEdit: This method views knowledge editing as a constrained decoding problem, ensuring outputs meet the proposed semantic constraints. DeepEdit uses a depth-first search-based progressive decoding technique for efficient updates without retraining.\nIKE: The ICL editing approach with a demonstration as \"Imagine that\" + new fact."}, {"title": "5.2 Comparison with Baselines", "content": "To mimic the human-written chain-of-thought context, we extract new facts, questions, thoughts, and answers from multi-hop questions in the MQuAKE dataset. Each question in this dataset is a 2-hop, 3-hop, or 4-hop question. We combine each sub-question and its corresponding answer into a single sentence to form the thought process. Following the approach of Zhong et al. (Zhong et al., 2023), we post three similar questions. If one of these questions yields an accurate answer, we consider the model to have successfully edited the new facts. The default number of contexts used is five. The results are presented in Table 1.\nOur model shows much better performance compared to previously proposed models in all three datasets. Furthermore, compared to BaseCOT, our method still shows better performance, which reinforces that our method helps improve the model's reasoning ability and amplifies the ripple effects."}, {"title": "5.3 Performance on One-time Edit", "content": "The number of edited instances. Following the methodology of (Zhong et al., 2023), we split the dataset into groups of g instances, where g values are 1, 100, 1000, and 3000. For a higher number of edited facts, RIPPLECOT introduces a dynamic retrieval method based on similarity measures between the thought and the stored new facts. The evaluation prompt becomes:\n[5-shot demonstrations]\n[New facts: m facts line by line\nretrieved from the given 3000 facts]\n[Question]\nThe m new facts are selected based on their similarity to the generated thoughts.\nThe details of the dynamic retrieval process are as follows. Note that m is not fixed, because a single question may relate to multiple edited facts. For example, for the question, \"What is the capital of the country to which Lou Pearlman belonged?\", the relevant facts might be \"Lou Pearlman is a citizen of India\" and \"The capital of India is Taloga.\" To address this, RIPPLECOT retrieves up to m rounds with one fact per round and employs an early stopping criterion if no contradiction is detected during a self-check. The setting of self-check follows (Zhong et al., 2023) and (Wang et al., 2024) for identifying contradictions between the retrieved facts and the answer. For each retrieval"}, {"title": "5.4 Performance in medical applications", "content": "We conducted experiments on the MedCF dataset (Xu et al., 2024), a benchmark for medical question-answer tasks. We follow Xu et al. (Xu et al., 2024) to evaluate the Meditron-7B model. The Table 4 shows the applicability of RIPPLECOT to knowledge editing in the medical domain. Unlike BaseCOT which relies heavily on the model's reasoning ability, RIPPLECOT tailors the thought process for knowledge editing, effectively decomposing multi-hop logic in questions."}, {"title": "5.5 Performance on Multi-time Edit", "content": "Previously, to our knowledge, all methods have evaluated knowledge editing using multi-hop questions or simple question-answering (Wang, 2022) under one-time editing. However, in real life, it is common to update knowledge multiple times. For instance, in the context of presidential elections, the president of the United States changes every 4 or 8 years, necessitating repeated updates to this knowledge. Due to the lack of datasets evaluating this aspect, we decided to modify the answers twice. For example, as shown in Figure 1, we change the author of Misery from Stephen King to Richard Dawkins, and then to a new author, Ernest Hemingway. We applied similar changes to a total of randomly selected 200 datasets by altering the answers to multi-hop questions to mimic multiple edits in real life.\nTable 5 shows the number of edits significantly impacts retrieval-based methods, which struggle with these kinds of problems. When conflicting knowledge is injected into the knowledge base, retrieval accuracy decreases, leading to lower accuracy for multi-hop questions. However, our method, RIPPLECOT, is less affected by multiple edits. The performance of RIPPLECOT remains relatively stable even with multiple edits, provided the demonstrations do not change."}, {"title": "5.6 Combination with Baselines", "content": "In this study, we integrate our proposed method into existing approaches and baselines to evaluate its effectiveness in improving performance. The performance enhancements observed, as illustrated in Figure 2, demonstrate the significant impact of our method in amplifying ripple effects."}, {"title": "5.7 Ablation Study", "content": "In this section, we ablate on different components of RIPPLECOT, which are generation strategy,"}, {"title": "5.7.1 Demonstration Generation", "content": "Generation Strategy.\nTable 6 indicates that few-shot generation may significantly amplify ripple effects. The comparable performance between few-shot generation and human selection, particularly with GPT-40's few-shot performance surpassing that of human selection (human-written chain-of-thought content), suggests a viable alternative for automatic context generation. We utilize GPT-40 and GPT-J (6B) models to generate demonstrations using both few-shot and zero-shot generation (Levy et al., 2017). For zero-shot learning, we input the prompt directly, allowing the model to autonomously generate the result. For few-shot learning, we extract several contexts from the MQUAKE dataset, which includes new facts, questions, thoughts, and answers, and prompt the model to generate the context in a similar format. The generated content is then used as context for RIPPLECOT. We impose several criteria on the generated context: it must comprehensively include all four sections (facts, questions, thoughts, and answers), and the answer should be concise, ideally a term or a few words. The similarity between GPT-J and GPT-40 generation suggests that performance is optimal when provided with several high-quality examples. However, in the zero-shot scenario, GPT-40 may still outperform due to its superior capability in generating reasonable chain-of-thought prompts.\nHow many referenced demonstrations are needed for the few-shot generation? We try to"}, {"title": "5.7.2 Demonstration Refinement", "content": "As discussed in our methodology, we employ cosine similarity to select demonstrations. During the generation process, we initially generate 20 candidate contexts and then select 5 of these based on"}, {"title": "6 Conclusion", "content": "RIPPLECOT has demonstrated superior performance relative to existing approaches. Through our experiments, we have highlighted the importance of our method in amplifying the ripple effect, as well as its flexibility in integration with other existing methods. Additionally, our analysis of chain-of-thought generation provides valuable insights for automatic generation. By combining the inherent flexibility and improved efficacy of in-context editing, our method can significantly streamline the process of knowledge updating, facilitating more accurate and contextually relevant model responses across various domains."}, {"title": "Limitations", "content": "Our study, while promising, has several notable limitations that should be addressed in future work:\n\u2022 Limited Dataset Scope. There are limited benchmarks for analyzing ripple effects, especially for multiple edits. We conducted experiments on only two datasets. We hope that, in the future, a larger dataset will be developed, encompassing various scenarios such as questions related to several parallel facts, to enable a more comprehensive evaluation.\n\u2022 Assumption of LLM Capabilities. Our approach assumes that the employed LLMs possess sufficient capabilities to handle knowledge editing and chain-of-thought (CoT) reasoning. However, if sub-optimal LLMs are used, the effectiveness of the proposed methods may be compromised, leading to diminished overall performance.\n\u2022 Bias in Edits. The creation of multiple edits to simulate real-life scenarios may inadvertently introduce biases. These biases might not accurately reflect the complexity and variability of natural"}, {"title": "Potential Negative Social Impact", "content": "Our commitment to ethical research practices guided our methodology and implementation throughout the study, however, RIPPLECOT may raise the following negative impacts:\nFirstly, we acknowledge the importance of ensuring the accuracy and integrity of information in language models. The ability to edit knowledge within these models must be approached with caution to prevent the propagation of misinformation. This means that our approach may be maliciously employed to distort, manipulate, or propagate misinformation. We raise this potential negative social impact here to highlight the need for stringent safeguards and monitoring mechanisms. Researchers and practitioners utilizing RIPPLECOT must implement robust verification processes to ensure that only accurate and verified information is introduced into language models.\nSecondly, we are aware of the potential biases that may be introduced through manual edits and the limitations of the datasets used. This means that using LLMs or the limited current datasets on knowledge editing might inherit the biases in LLMs or the current datasets.\nBy addressing these potential negative social impacts, we aim to contribute to the responsible advancement of knowledge editing technologies, ensuring they are used to enhance the reliability and effectiveness of language models in various applications."}, {"title": "A Appendix", "content": ""}, {"title": "A.1 Example Prompts and Generation Results", "content": "$\\newline$\\{Demonstrations\\}$\\newline$New Fact: Lou Pearlman is a citizen of India, The capital of India is Taloga$\\newline$Question: What is the capital of the country to which Lou Pearlman belonged?\\newline$New fact: the author of Misery is Richard Dawkins. Question: What is the nationality of the author of Misery. Thought: The author of Misery is Richard Dawkins. Richard Dawkins is a citizen of United Kingdom Therefore, the nationality of the author of Misery is British. Answer: British$\\newline$New fact: The capital of United States of America is El Campu. Question: What is the capital city of the country that Michael Feinstein is a citizen of ? Thought: Michael Feinstein is a citizen of United States of America. The capital of United States of America is El Campu. Thus, the capital city of the country that Michael Feinstein is a citizen of is El Campu. Answer: El Campu$\\newline$Thought: Lou Pearlman is a citizen of India. The capital of the country of which Lou Pearlman is a citizen is Taloga. Answer: Taloga"}, {"title": "A.2 Comparison of Different CoT Methods", "content": "Our evaluation in Table 9 also shows that RIPPLECOT outperforms the standard CoT approach, Base-COT with \"think step by step,\" as well as other advanced CoT methods, i.e., Self-generated-COT (Wang et al., 2023) that prompts the model to split a complex question into several sub-questions, while Least-to-most-COT (Zhou et al., 2022) let the model generate and arrange the sub-questions from easy to hard. We also compare more advanced prompting such as Self-consistency (Wang et al., 2022) by generating several candidates and performing majority voting. RippleCOT also outperforms plain Self-consistency, demonstrating the significance of CoT in knowledge editing. Self-consistency essentially is self-ensembling which be combined with RippleCOT. We demonstrate that RippleCOT can be further boosted by self-consistency, as shown in the Table 9."}, {"title": "A.3 Safety Evaluation", "content": "We conducted a jailbreak attack (Huang et al., 2023) before and after applying RippleCOT, and found that the attack success rate is unchanged (92%) for the MaliciousInstruct dataset with the Vicuna-7B model under their setting w/o sys. prompt. This is because RippleCOT does not alter any model parameters during editing, thus it does not affect the model's safety level."}, {"title": "A.4 More baseline with large models", "content": "We added three large models, GPT-4-0125 (1.8T), GPT-40 and Claude-3.5 sonnet (while the exact parameter size isn't specified, it is the latest high-performing large model), to the table below, in addition to GPT-3 (175B), which have already been included in our paper. We observe that RippleCOT performs well on both smaller and larger models, whereas BaseCOT, which relies solely on the model's reasoning ability, is effective only for larger models with enhanced reasoning capabilities. The results is shown in Table 10."}]}