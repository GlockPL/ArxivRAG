{"title": "Cluster Model for parsimonious selection of variables\nand enhancing Students' Employability Prediction", "authors": ["Pooja Thakar", "Prof. Dr. Anil Mehta", "Dr. Manisha"], "abstract": "Educational Data Mining (EDM) is a promising\nfield, where data mining is widely used for predicting students'\nperformance. One of the most prevalent and recent challenge\nthat higher education faces today is making students skillfully\nemployable. Institutions possess large volume of data; still they\nare unable to reveal knowledge and guide their students. Data in\neducation is generally very large, multidimensional and\nunbalanced in nature. Process of extracting knowledge from such\ndata has its own set of problems and is a very complicated task.\nIn this paper, Engineering and MCA (Masters in\nComputer Applications) students data is collected from various\nuniversities and institutes pan India. The dataset is large,\nunbalanced and multidimensional in nature. A cluster based\nmodel is presented in this paper, which, when applied at pre-\nprocessing stage helps in parsimonious selection of variables and\nimproves the performance of predictive algorithms. Hence,\nfacilitate in better prediction of Students' Employability.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent times, Education to a greater extent has become\nemployment oriented. Placements of an institution build its\nreputation and market value. Employability of students' not\nonly plays a very vital role in their own growth, but is a crucial\nfactor for the growth of institute and nation by enlarge.\nEducational Data Mining is a field that develops methods\nto discover knowledge from students' data. Institutes want to\nidentify those students, who have the potential to fetch best\nplacement in the market. They also want to know the attributes\nof best achievers, so that others can be guided and trained to\nperform better. Predicting student's employability in the\nbeginning stage, as soon as they enter the institute can be used\nto take proactive and timely actions. This may improve their\nperformance and will also identify students, who are at the risk\nof unemployment.\nInstitutes manage colossal records of students. Along with\nbasic primary academic data; institutes also maintain secondary\ncognitive, psychometric and analytical records of students.\nFactors such as communication skills, personal qualities,\nteamwork, critical thinking, and problem solving skills are\nimportant employability factors [1]. Studies also reflect the\nimportance of secondary attributes along with primary\nattributes for higher prediction accuracy and analysis [23].\nFactors like location, medium of teaching, qualification of\nmother, income of family and status are highly correlated with\nacademic performance of students [25]. Such a data has high\npotential to uncover knowledge that can be utilized to guide\nstudents for better employability. But, the data collected from\neducational ecosystem suffer with two intrinsic problems. They\nare:\na) Data is Unbalanced \u2013 High Achievers records are\nvery less as compared to Non Achievers, thus\nunbalanced, which is further difficult to predict and\nextract rules. Data is unbalanced, when some classes\nhave significantly large number of instances available\nthan others. Predictive algorithms overlook minority\nclasses, and considers only majority classes. Minority\nclass hubs may lead to misclassification in many\nhigh-dimensional datasets [3]. As a result, the\npredictive algorithms are unable to classify them\ncorrectly.\nb) Data is Multidimensional: With inclusion of\nPersonal, Geographical, Family Background,\nProfessional, Academic Psycometric, Cognitive,\nNon Cognitive attributes of every student, data\nbecome multidimensional. Controlled dataset with\nhigh dimensionality may result in over-fitting and\ndecrease the generalization performance of predictive\nalgorithms[2]. This in turn requires huge set of data\nfor better prediction.\nTeaching -Learning Systems are also highly customized to\nfulfill the needs of specific Institute for which it is designed.\nThere is no unified model that can be used across institutes\nwith any type of dataset.\nIn Indian higher education system, Engineering (B.E. /\nB.Tech.) and MCA (Masters in Computer Applications) are\ntwo professional degree courses that makes students ready for\nInformation Technology (IT) based Companies. Most of the\nstudents in these courses aspire and compete to obtain the best\ncampus placements, before they pass out.\nThis paper presents a model that uses clustering at pre-\nprocessing stage and improves the performance of various\npredictive algorithms to predict employability. Data is"}, {"title": "II. REVIEW OF LITERATURE", "content": "In last decade, Data Mining has aroused the research\ninterest of researchers in the field of Education and majority of\nthem have worked to determine the techniques in predicting\nacademic performance [15] [16] [17] [18] [19] [33][34].\nIn last few years, researchers have tried to find out the\nfactors affecting employability of students. Emotional\nIntelligence, Personal Management, Life experience, Work\nExperience are considered as important factors for\nEmployability Development Profile [5]. Emerald Group\nPublishing Limited published a paper in 2014 that described\nlink between Competences, Dispositions and Employability\n[6]. Cairns, Gueni, Fhima, David and Khelifa found positive\ncorrelation in employees jobs/assignments, history etc. [7].\nPotgieter & Coetzee revealed significant relationships between\nthe personality and employability. They listed eight core\nemployability features for fetching and sustaining employment\nopportunities [8]. Employers give premier importance to soft-\nskills and the lowest weight on academic reputation as\ndescribed by David, Hamilton, Riley and Mark [9]. Denise\nJackson and Elaine Chapman indicated significant differences\nbetween academic and employer skill ratings and revealed\nmajor skill gap between academia and industry [10]. V. K.\nGokuladas necessitated specific skills in students beyond\ngeneral academics, he showcased that GPA and proficiency in\nEnglish language are vital predictors of employability [11]\n[12]. Noor Aieda, Abu Bakar, Aida Mustapha, Kamariah Md.\nNasir found that graduates by enlarge lack in interpersonal\ncommunication, creative and critical thinking, problem solving,\nanalytical, and team work [13]. Jamaludin, Nor Azliana, and\nShamsul Sahibuddin highlighted that industry requires skilled\nworker to handle the projects as compared to only CGPA\nachievement [32].\nRecently, few researchers have worked on students'\nemployability prediction. In 2016, Mishra, Kumar and Gupta\ncollected the data of 1400 MCA students to predict students'\nemployability in campus placements excluding cognitive\nfactors such as reasoning, aptitude and communication skill\n[20]. Piad, K.C., Dumlao, M., Ballera, M.A. and Ambat, S.C.\npublished a paper in 2016 to predict employability of\nInformation Technology students. Dataset of 515 students with\n9 variables was taken for prediction [21]. Awang-Hashim, R.,\nLim, H.E., Yatim, B., TENGKU ARIFFIN, T.F., Zubairi,\nA.M., Yon, H. and Osman, O. in 2015 designed a statistical\nprediction model to identify low employability graduates in\nMalaysia [22]. In a recent study of 2016, conducted by Chen,\nPei-lin, Wei Cheng, and Ting-ting Fan collected the dataset of\n2160 with 6 attributes such as gender, area, type of college,\ndegree, master and grades were used to create an employability\nmodel [24]. Jantawan, Bangsuk, and Cheng-Fa Tsai, designed\na model for employability prediction using data mining\ntechniques for a university in Thiland and emphasized on the\nneed of more variables and automated preprocessing, [14].\nattributes\nfor\nMost of the researches emphasized to include all types of\nparameters such as cognitive, psychometric, background with\nacademic\nbetter prediction\n[1][8][9][11][14][23][25]. Need for large, multidimensional\ndataset with automated pre-processing is also reflected [14].\nRecent study by Tarik A. Rashid in 2015 pointed out future\nworks to be based upon three parameters, first is to increase the\nsize and type of the dataset, finding different ways to work out\nthe problem with unbalanced data and examine other feature\nselection techniques that could enhance the performance of\nclassification techniques [35].\nThis paper is an attempt to deal with the problem of large,\nmultidimensional, unbalanced dataset of education system.\nAutomated and speedy feature selection at preprocessing is\nperformed to enhance the performance of predictive\ntechniques."}, {"title": "III. DATA MINING, CLUSTERING AND CLASSIFICATION\nTECHNIQUES", "content": "As quoted by Han and Kamber \u201cData mining refers to\nextracting or mining knowledge from large amounts of data.\u201d\n[27]. There are two methods in data mining for learning and\nextracting knowledge. They are supervised and unsupervised\nlearning. Supervised learning or commonly known as\nclassification is based on supervision i.e. the training data is\naccompanied by class and new data is classified on the basis\nof training set [26]. In unsupervised learning or commonly\nknown as clustering, the class labels of training data is\nunknown [26].\nThe Model presented in this paper uses clustering at\npreprocessing stage to enhance the performance of\nclassification. The techniques used in model are described\nbelow:\nk-Nearest Neighbor: It is better known as learning by analogy\nand is the simplest of all. It compares a given test example\nwith training examples for similarity. All of the training"}, {"title": "IV. EXPERIMENTAL SETUP", "content": "A. Data Collection\nData set used in this study is obtained from various\nUniversities and Institutes pan India. Training and Placement\nCells of various Institutes offering four year Engineering\n(Bachelor in Engineering \u2013 B.E. or Bachelor in Technology\n\u2013 B.Tech.) course or three years MCA (Master in Computer\nApplications) Degree Course were contacted. TPO (Training\nand Placement Officers) sent their institutes past records in the\nformat provided to them in spreadsheet. Many of them\nprovided data in the format they keep it at the Institute level.\nPlaced Students details were either provided by the TPO or\nsecondary data is collected from the Institutes website. Data\ncollected is then compiled in one spread sheet.\nB. Data Selection and Transformation\nData is deliberately collected for Engineering and MCA\nstudents keeping in mind that maximum of them opt for\nplacements after obtaining degree and in both courses last\nsemester is specifically dedicated to internship in Companies.\nThis is to ensure seriousness in students, while they sit for\ncampus placements. Graduate courses such as BCA (Bachelor\nin Computer Applications) are not included as students are not\nvery sincere for the placements; most of them opt for higher"}, {"title": "D. Performance Measures", "content": "Classification accuracy is the number of correct predictions\nmade, divided by the total number of predictions made,\nmultiplied by 100 to turn it into a percentage. In a problem\nwhere there is a large class imbalance, a model can predict the\nvalue of the majority class for all predictions and achieve high\nclassification accuracy. This is called the Accuracy Paradox\n[28]. The dataset used in study suffers with this; hence\naccuracy measure may not be the perfect indicator to judge the\nperformance of classifiers. Classification accuracy is typically\nnot enough information to make decision on effectiveness of\nmodel if dataset has unbalanced classes.\nF1 Score is the weighted average of Precision and Recall.\nTherefore, this score takes both false positives and false\nnegatives into account. F1 is more useful than accuracy, if you\nhave an uneven class distribution [29].\nThe formula for F1 Score is 2*(Recall * Precision)/(Recall +\nPrecision).\nKappa is also another measure, which may be used in this\ncase. Kappa Statistics is a normalized value of agreement for\nchance. It can be described as\nK= (P (A)- P(E))/(1-P (E))\nWhere,\nP (A) is percentage agreement and P (E) is chance\nagreement.\nIf K =1 than agreement is ideal between the classifier and\nground truth.\nIf K=0, it indicates there's a chance of agreement. [30]"}, {"title": "E. Cluster Model for pre-processing", "content": "A novel approach is adopted for pre-processing the raw data\n(RD). Dataset is first transposed by swapping attributes as\ninstances and instances as attributes. The new dataset now\nobtained is named as (RD1). K-means Clustering with Jaccard\nSimilarity is applied on raw dataset (RD1), which results in\nreducing dimensionality, find relevant set of attributes very\nfast and improves classification performance.\nStep wise description of model is as follows:\nStep1: Retrieve Raw Dataset (RD) in the form of matrix\n(Raw dataset after cleaning and necessary\ntransformations)\nStep2: Transpose (TP) matrix RD i.e. RD1=TP [RD]\nStep3: Apply clustering on RD1 with k = 2 or 3\n(Apply k-means-Fast clustering algorithm with\nJaccard Similariry on RD1)\nStep4: Perform Filtering of RD1 w.r.t. Clusters\nStep 5: Generate new Dataset w.r.t. Clusters named as Data\nCluster (DC1), DC2 and DC3\nStep6: Transpose all Data Clusters as\nCluster1=TP [DC1]\nCluster2=TP [DC2]\nCluster3=TP [DC3]\nStep7: Implement selected Classification Algorithm on\neach data cluster Cluster1, Cluster2 and Cluster3\nStep8: Validate Performance of classifier with X-\nValidation by applying 10 fold cross validation."}, {"title": "V. RESULTS", "content": "The performances of eleven predictive algorithms for\npredicting students' employability on the aforesaid dataset\nwere experimented upon and results were calculated. Due to\nintrinsic problems of large, unbalanced, multidimensional\ndataset the results obtained were not satisfactory, when only\npredictive algorithms were applied directly on Raw Data\n(RD).\nTo overcome the problem of multidimensional data, PCA\n(Principle Component Analysis) is considered as very\nversatile, oldest and the most popular technique in\nmultivariate analysis [36]. But when applied with the\naforementioned dataset, it could not improve the results much.\nComparative is shown in Table I and Table II below.\nCluster Model is then applied on this large, multidimensional\nunbalanced dataset; k-means Clustering with Jaccard s\nimilarity is applied on the set of 152 attributes (after\ntransposing the data) at the level of pre-processing. This\ndivided the dataset into clusters. The clusters now obtained\ncontain reduced set of attributes, which are correlated to each\nother. This method eventually reduced the attribute set at a\nvery fast pace. Now each cluster is transposed again and\nclustering algorithm is applied on them. Validated the\nperformance of classifier with 10-fold cross validation and it\nshows significant improvement in results. It is also noticed\nthat the cluster, which has Class as an attribute shows best\nresults. Comparative results are as follows:\nThis can be further proved with Statistical t-test measures.\nResults reflect that the improvement is significant.\nLet's define hypothesis:\nHypothesis 1.1\nHo 1.1: There is no significant difference in F1 score of\nvarious Predictive Algorithms\nHA 1.1: There is significant difference in F1 Score of various\nPredictive Algorithms.\nHypothesis 1.2\nHo 1.2: There is no significant difference in Kappa values of\nvarious Predictive Algorithms\nHA 1.2: There is significant difference in Kappa values of\nvarious Predictive Algorithms.\nt-Test: Paired Two Sample for Means is conducted between\nthe F1 Score obtained by Predictive Algorithms only and\nwhen the same algorithms were applied using cluster model.\nResults are as follows"}, {"title": "VI. CONCLUSION AND FUTURE SCOPE", "content": "The results prove that prediction performance for students'\nemployability can be enhanced by applying Cluster Model,\nwhen dataset is large, unbalanced and multidimensional.\nMoreover, clustering applied on attributes set at pre-\nprocessing stage helps in parsimonious selection of variables\nand improves performance of predictive algorithms.\nThis paper also statistically analyzes and compares the results\nof predictive algorithms, when applied with proposed cluster\nmodel. The results clearly depicts that Cluster Model is\nsuperior to commonly used methods to predict students'\nemployability and reducing dimensionality. Taking the base of\nproposed model more improvement can be made in future."}]}