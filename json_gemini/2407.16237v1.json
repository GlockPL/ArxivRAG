{"title": "OriGen: Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection", "authors": ["Fan Cui", "Chenyang Yin", "Kexing Zhou", "Youwei Xiao", "Guangyu Sun", "Qiang Xu", "Qipeng Guo", "Demin Song", "Dahua Lin", "Xingcheng Zhang", "Yun (Eric) Liang"], "abstract": "Recent studies have illuminated that Large Language Models (LLMs) exhibit substantial potential in the realm of RTL (Register Transfer Level) code generation, with notable advancements evidenced by commercial models such as GPT-4 and Claude3-Opus. Despite their proficiency, these commercial LLMs often raise concerns regarding privacy and security. Conversely, open-source LLMs, which offer solutions to these concerns, have inferior performance in RTL code generation tasks to commercial models due to the lack of high-quality open-source RTL datasets.\nTo address this issue, we introduce OriGen, a fully open-source framework featuring self-reflection capabilities and a dataset augmentation methodology for generating high-quality, large-scale RTL code. We propose a novel code-to-code augmentation methodology that leverages knowledge distillation to enhance the quality of the open-source RTL code datasets. Additionally, OriGen is capable of correcting syntactic errors by leveraging a self-reflection process based on feedback from the compiler. The self-reflection ability of the model is facilitated by a carefully constructed dataset, which comprises a comprehensive collection of samples. Experimental results demonstrate that OriGen remarkably outperforms other open-source alternatives in RTL code generation, surpassing the previous best-performing LLM by 9.8% on the VerilogEval-Human benchmark. Furthermore, OriGen exhibits superior capabilities in self-reflection and error rectification, surpassing GPT-4 by 18.1% on the benchmark designed to evaluate the capability of self-reflection.", "sections": [{"title": "1 INTRODUCTION", "content": "Recently, large language models (LLMs) have demonstrated out-standing performance in natural language comprehension and gen-eration [11]. Studies have shown that LLMs exhibit considerableability in code generation tasks [21]. Commercial LLMs, such asGPT-4 [1] and Claude3-Opus [2], generate high-quality softwarecode for common programming languages like C++ and Python,which enhance coding productivity significantly. Moreover, LLMshave also illustrated impressive capabilities in hardware code gener-ation, especially for the Register Transfer Level (RTL) code. Specif-ically, RTL code generation from natural language instructionspresents an innovative approach to enhance hardware develop-ment productivity, offering the potential to revolutionize existingHDL coding workflows by alleviating the burdensome task of HDLcoding for designers.\nWhile commercial LLMs have demonstrated proficiency in gen-erating RTL code, they often raise concerns regarding privacy andsecurity. These issues are especially critical in the domain of hard-ware design, as RTL code frequently contains valuable intellectualproperty. Furthermore, the closed-source nature of these LLMsrestricts researchers from conducting in-depth analyses and cus-tomizations, impeding further fine-tuning of the models in specificdomains, such as hardware design. In contrast, open-source mod-els provide better privacy and security while facilitating furtherimprovement and customization. Open-source models, such as Star-Coder2 [15], DeepSeek-Coder [9], and CodeQwen-V1.5 [3], have demonstrated promising results in code generation for prevalentprogramming languages like Python and C/C++, while their per-formance in RTL code generation still lags behind GPT-3.5. Thisunderscores the pressing need to develop a specialized open-sourceLLM tailored for RTL code generation."}, {"title": "2 BACKGROUND AND RELATED WORK", "content": "The scarcity of high-quality RTL code datasets is a significantfactor contributing to the poor quality of RTL code generation. InLLM training, both the scale and quality of the dataset are essentialfor effective code generation performance. However, compared toother popular programming languages, there is a notable short-age of high-quality, large-scale RTL code datasets, which posesa significant challenge for achieving satisfactory results in RTLgeneration tasks. To address this issue, several studies have fo-cused on collecting open-source code snippets [7, 19, 22, 23]. Nev-ertheless, these open-source datasets may include low-quality codethat can impair the model's performance [13]. Other researchershave developed methodologies for synthesizing RTL code usingLLM [5, 13, 14]. VerilogEval [13] generates datasets by adding de-scriptions to open-source Verilog code but suffers from its averagelow quality. RTLCoder [14] selects hardware-related keywords asseeds to generate natural language instructions, which are thenconverted into corresponding RTL code by GPT-3.5. Although thisdataset meets quality standards, it is limited in scale because thegenerated data is restricted to the selected keywords.\nSelf-reflection is also a critical factor to be considered in thefield of RTL code generation. In the context of RTL code generation,self-reflection refers to the model's assessment of its generated codebased on feedback from the compiler and simulator. This processinvolves identifying the causes of errors and refining the resultsaccordingly, just as in the hardware design process, where RTLcode undergoes rigorous evaluation by the compiler and simulatorto ensure its correctness and adherence to design specifications.\nHowever, existing open-source LLMs mainly focus on code gen-eration, neglecting the interactive process of compilation and sim-ulation in hardware design methodologies. In consideration of theabove limitations, several studies have integrated self-reflectionmethodologies into their frameworks [24, 25, 27]. Nonetheless, bothRTLFixer [25] and AutoChip [24] rely on commercial LLMs for self-reflection, which raises potential concerns regarding privacy andsecurity, as previously discussed. Open-source LLMs generally ex-hibit weaker self-reflection capabilities compared to commercialLLMs, primarily due to their limited training data. Consequently,there is a need to develop a methodology for constructing datasetsspecifically designed to enhance the self-reflection abilities of open-source LLMs.\nIn this paper, we introduce OriGen, a fully open-source frame-work featuring self-reflection capabilities and a dataset augmenta-tion methodology. We propose a novel code-to-code augmentationthat leverages knowledge distillation to improve the quality ofopen-source RTL code datasets, which are of a large scale but havelimited quality due to the lack of rigorous review and validationprocesses.\nOur approach involves extracting high-level code descriptionsfrom the open-source RTL code and refining the code based onthese descriptions using the Claude3-Haiku model, which acts asthe teacher model. Commercial LLMs have been trained on vastamounts of high-quality data and possess strong language under-standing and generation capabilities. By leveraging these models asteachers, we can distill their knowledge and refine the open-sourceRTL code. This method enables the generated code to potentiallyachieve even superior performance of the teacher model."}, {"title": "2.1 LLMs for Verilog Generation", "content": "Large Language Models (LLMs) have emerged as powerful tools forcode generation across various programming languages. Trained onvast amounts of code and natural language data, these models canlearn the statistical patterns and relationships within the trainingdata, enabling them to generate code that adheres to the syntax andstyle of the target programming language. Recently, researchers inthe field of hardware design have shown a growing interest in lever-aging LLMs for generating RTL code. RTL is a crucial abstractionlevel in hardware design, describing the flow of data and controlsignals between registers and combinational logic. By fine-tuningLLMs on RTL code datasets, models are capable of generating RTLcode, potentially accelerating the hardware design process.\nAmong the pioneering endeavors, DAVE [18] represents an ini-tial exploration into the generation of Verilog code from natural"}, {"title": "2.2 Reflection for Verilog Generation", "content": "Existing open-source LLMs designed for RTL code generation havemainly focused on the generative aspects, neglecting the crucialstages of verification and reflection that are integral to hardwaredesign methodologies. The effectiveness of self-reflection and recep-tivity to feedback in addressing real-world issues has been demon-strated by SWE-agent [29], which successfully resolved problemsin GitHub's repositories. This highlights the potential benefits ofincorporating self-reflection mechanisms into LLMs for RTL codegeneration, as it could enable the models to learn from feedback anditeratively improve the generated code, aligning with the rigorousverification processes inherent to hardware design methodologies.\nRecognizing the limitations of previous research on LLMs forRTL generation, AutoChip [24] and RTLFixer [25] decide to intro-duce self-reflection into the their framework. Specifically, RTLFixer"}, {"title": "2.3 Knowledge Distillation", "content": "To enable open-source models to acquire capabilities comparableto commercial closed-source models, knowledge distillation hasbecome a focus for researchers. [28]. A common approach involvesleveraging the closed-source LLM to provide reference answers,which are then used to fine-tune the open-source LLM throughSupervised Fine-Tuning (SFT), enabling the latter to learn from theknowledge embodied in the closed-source model. Specifically, SFTis a effective knowledge distillation method. In this approach, theteacher model, typically an advanced LLM, is first used to generatea large number of input-output data pairs. Subsequently, thesedata pairs generated by the teacher model are utilized as trainingdata to fine-tune the student model, typically a smaller open-sourcelanguage model. Through this process, the student model can mimicthe behavior of the teacher model, thereby acquiring the knowledgewithin the teacher model.\nThe code-to-code augmentation methodology employed in thiswork falls under the realm of knowledge distillation techniques. Byleveraging the knowledge within these advanced models, the pro-posed method can effectively distill and transfer their capabilitiesto the target model, enabling it to acquire the desired capability ofRTL code generation in a scalable and automated manner."}, {"title": "3 METHODOLOGY", "content": "In this section, we provide comprehensive details of OriGen, apowerful framework designed to enhance Verilog code generation."}, {"title": "3.1 Overview", "content": "The overview of the code-to-code augmentation methodology andOriGen's generation and self-reflection framework are illustratedin Figure 1 and Figure 2 respectively. As shown in Figure 1, in thecode-to-code augmentation process, two datasets are generated:an enhanced code dataset and an error-correction dataset. The en-hanced code dataset contains code-description paired data samples,enabling the LLM to learn the correspondence between Verilogcode and natural language. The error-correction dataset compriseserroneous code-fixed code paired data samples, allowing the LLMto enhance its self-reflection capability by learning from examplesof code errors and their corrections.\nAs shown in Figure 2, in the code generation and error correctionstage, OriGen comprises a base LLM and two trained LoRA models:"}, {"title": "3.2 Code-to-Code Augmentation", "content": "The code-to-code augmentation process aims to transfer advancedRTL code generation and correction capabilities from commercialLLMs to our model. To achieve this, a carefully filtered collectionof comprehensive open-source RTL code samples is utilized as afoundation.\nTo extract a valuable dataset from open-source RTL code sam-ples [15, 23], a rigorous filtration process is applied. Initially, dueto the constraints imposed by the model's context window and thechallenges associated with incomplete descriptions for longer codesnippets, samples exceeding 300 lines or 1536 tokens are excluded.Additionally, samples with an average of more than 30 tokens (ap-proximately 90 characters) per line are considered non-standard andare consequently eliminated, ensuring that only concise and stan-dard code samples are retained. Subsequently, to ensure the mean-ingfulness and substantive content of the code snippets, a keyword-based filtration approach is employed. Each sample must containboth the module and endmodule keywords, alongside at least oneoccurrence of keywords related to procedural blocks, always (in-clusive of variants like always_comb, always_ff, always_latch,etc.) or assign. This criterion guarantees that the selected snip-pets are representative of functional and logical hardware designs.Lastly, all comments within the code samples are removed. This"}, {"title": "3.3 Error-Correction Dataset", "content": "Although OriGen, after being trained on the enhanced code dataset,demonstrates performance comparable to that of advanced closed-source LLMs in RTL code generation, it exhibits weaker self-reflectioncapabilities compared to commercial LLMs like other open-sourceLLMs."}, {"title": "3.4 Code Generation and Fix", "content": "As shown in Figure 2, in the code generation and error correctionstage, OriGen comprises a base LLM and two trained LoRA mod-els: Gen LoRA and Fix LoRA. Following training on the enhancedcode dataset, Gen LoRA has developed robust RTL code generationcapabilities but exhibits limitations in self-reflection. To furtherenhance its capabilities of self-reflection, Gen LoRA is trained onthe error-correction dataset, resulting in Fix LoRA.\nThe reason for employing two LoRA models, Gen LoRA andFix LoRA, instead of a single LoRA is based on experimental re-sults, which indicate that Fix LoRA, trained on the error-correctiondataset, exhibits inferior performance compared to Gen LoRA in theRTL code generation task. This performance degradation may beattributed to the fact that training on a dataset containing syntacticerrors could potentially weaken the model's overall performance.Therefore, OriGen adopts a two-LoRA approach, where Gen LoRAis responsible for generating the initial code, and Fix LoRA is taskedwith rectifying syntactic errors, utilizing its specialized training onthe error-correction dataset.\nThe generative and iterative self-reflection process is illustratedin Figure 2. Initially, OriGen accepts the user's natural languagespecification and proceeds to generate the corresponding RTL codeusing Gen LoRA. The generated code is then subjected to the com-piler's verification process using Iverilog. In cases where the codefails to compile, OriGen initiates a self-reflection process to fix thecode. This process involves utilizing the erroneous code, compilererror messages, and natural language instructions to guide themodel in identifying and rectifying the issues. The self-reflectionloop continues until the generated code successfully passes compi-lation or reaches a predefined maximum number of iterations."}, {"title": "3.5 VerilogFixEval", "content": "To evaluate the capability of different models in reflecting on andimproving from Verilog compiler error messages, we constructedthe VerilogFixEval benchmark. The benchmark comprises codesamples that failed to pass the compilation verification, along withthe corresponding natural language instructions and compiler errormessages. The erroneous RTL code samples were selected fromcode generated by LLMs that performed comparable with GPT-3.5 on the VerilogEval benchmark. This selection approach wasadopted since OriGen achieves a relatively high compilation passrate. By including code samples from poorly performing LLMs, thebenchmark ensures the diversity of errors while avoiding potentialbias in the test results that may favor OriGen due to errors generatedby OriGen itself.\nDuring the evaluation process, the model will receive natural language instructions, erroneous RTL code, and compiler errormessages, and will be required to correct the RTL code. The finalevaluation metrics include two parts, syntactic correctness andfunctional correctness."}, {"title": "4 EVALUATION", "content": ""}, {"title": "4.1 Experimental Setting", "content": "For our pre-trained model, we selected the DeepSeek-Coder-7B-Instruct model, as it exhibits the best performance in Verilog codegeneration among all 7B models, to the best of our knowledge. It isto ensure that our pre-trained model possesses strong capabilities inthe domain of Verilog code generation, providing a solid foundationfor further fine-tuning and evaluation.\nTo evaluate the performance of Verilog code generation, we se-lected two representative benchmarks: VerilogEval [13] and RTLLM [16].The former, VerilogEval, originates from approximately 150 Verilogtasks on the HDLBits website, which were manually converted tocreate VerilogEval-Human and generated by GPT-3.5 to produceVerilogEval-Machine. The latter benchmark, RTLLM, consists of 29Verilog tasks with more diverse levels of difficulty, closely alignedwith real-world design tasks. Both benchmarks employ the widelyadopted $pass@k$ evaluation metric to assess the correctness of thegenerated code's functionality. In this metric, if any one of the $k$samples passes the unit test, the problem is considered solved.\n$pass@k := E 1$ Problems $\\binom{n}{c} \\frac{\\binom{c}{1}}{\\binom{n}{k}}  $                                                                           (1)\nwhere we generate $n \\geq k$ samples for each instruction in which $c \\leq n$ samples pass testing. We choose $n = 10$ in experiments.\nTo assess the models' capability for self-reflection, we utilized the VerilogFixEval benchmark, as discussed in Section 3.5. This"}, {"title": "4.2 Model Training", "content": "We employ the LoRA (Low-Rank Adaptation) [10] method to trainthe model's capability in generating RTL code. This approach allowsfor enhancing the model's specific abilities in RTL code generationwhile minimizing the impact on its other capabilities. For all thetraining processes, we employ the float16 mixed precision method,although the model is trained in bfloat16 precision. We utilize theAdam optimizer with $\\beta_{1} = 0.9$, $\\beta_{2} = 0.999$, and the cosine learningrate decay to schedule our learning rate. The warm-up ratio is setto 0.03.\nDuring the training process, we initially segment the dataset intosmaller subsets, each containing 10k samples, resulting in a total of18 groups. We then perform fine-tuning on these smaller datasets toevaluate their quality and assess the model's performance trainingon them. Throughout the experiments, it is evident that the dataset'sperformance is relatively sensitive to the learning rate.\nAs illustrated in Figure 7, we choose several subsets of the dataset,including 6 smaller 10k-samples datasets and 2 larger 30k-samplesdatasets. Employing varying learning rates during the trainingphase lead to noticeable differences in the pass@1 metric on theVerilogEval benchmark [13]. Simultaneously, the results obtainedfrom training on different datasets exhibit significant variations.These observations highlight the sensitivity of the model's perfor-mance to the choice of learning rate and the characteristics of thetraining dataset. In response, we implement a strategy of trainingeach small dataset with its optimal learning rate. Furthermore, weconduct training exclusively on those datasets where the pass@1metric surpass 42%. This approach mitigate the sensitivity of themodel's performance to the learning rate, ensuring that each datasetsubset is trained with the most suitable learning rate to achieveoptimal results. Additionally, it avoids the detrimental influence ofunderperforming datasets."}, {"title": "4.3 Functional Correctness", "content": "Table 1 presents the results on the VerilogEval benchmark. Toensure fairness, we did not utilize the self-reflection feature forthis comparison and generated code in a single attempt, like othermodels. The models compared include closed-source commercialLLMs such as GPT-3.5/GPT-4, Claude3-Haiku/Sonnet/Opus, generalopen-source code models [3, 9], and models customized for RTLcode generation [12-14, 17, 19].\nIn the VerilogEval benchmark [13], for pass@1 in Human andMachine categories, OriGen achieves 76.1% and 51.4% respectively.It outperforms remarkably all other alternatives designed for RTLcode generation, for example, compared to the best-performed fullyopen-source RTLCoder [14], OriGen surpasses it by 9.8% in Humanbenchmark. When compared with commercial closed-source mod-els, OriGen also achieves excellent performance. It significantlysurpasses GPT-4 of 2023 version, which was previously the widelycompared baseline. Even when compared with the state-of-the-artmodels, OriGen outperforms Claude3-Haiku/Sonnet, only slightlyinferior to the current best models GPT-4 Turbo and Claude3-Opusby 3% in Human benchmark. Moreover, as evident from Table 1, itachieves the best performance on the Machine benchmark, remark-ably outperforming other models including GPT-4 Turbo.\nTo prevent our model from over-fitting on the VerilogEval bench-mark, we also conduct experiments on another benchmark designedfor RTL code generation, RTLLM [16]. Similar results are observedon RTLLM as shown in Table 1, where OriGen significantly outper-forms other models, achieving performance comparable to GPT-4Turbo and Claude3-Opus.\nIn summary, OriGen outperforms all non-commercial modelsremarkably in all metrics on both benchmarks.\nMoreover, as illustrated in Figure 8, we observe that the strat-egy of training each small dataset with its optimal learning rateand excluding the datasets with relatively poor performance al-lows the model's performance to gradually improve as the datasetgrows larger. This demonstrates the effectiveness of the trainingmethodology."}, {"title": "4.4 Capability of Self-Reflection", "content": "The evaluation metrics of VerilogFixEval consist of two components:syntactic correctness and functional correctness. Syntactic correct-ness assesses whether the generated rectified RTL code successfully"}, {"title": "4.5 Ablation Studies", "content": "We perform two ablation experiments to investigate the efficacy ofthe code-to-code augmentation method and to examine the model'sself-reflection capability before and after training on the error-correction dataset.\nFor the ablation study of the code-to-code data augmentationmethod, we compared the performance of models trained on RTLcode dataset before and after code-to-code augmentation method."}, {"title": "5 CONCLUSION", "content": "This paper introduces OriGen, an open-source framework for RTLcode generation. It proposes a novel code-to-code augmentationmethodology to generate high-quality, large-scale RTL code datasets,which enhances the model's training data. The framework alsointroduces a self-reflection mechanism that allows OriGen to au-tonomously fix syntactic errors by leveraging compiler feedback,thereby improving its code generation accuracy. Furthermore, weconstruct a dataset to improve the model's capability of self-reflectionbased on compiler error messages and erroneous code and develop abenchmark to evaluate this capability. Experimental results demon-strate that OriGen remarkably outperforms other open-source al-ternatives in RTL code generation, surpassing the previous best-performing LLM by 9.8% on the VerilogEval-Human benchmark andis comparable with GPT-4. Moreover, OriGen exhibits superior ca-pabilities in self-reflection and error rectification, surpassing GPT-4by 18.1% in syntactic correctness on the VerilogFixEval benchmark."}]}