{"title": "EU-Nets: Enhanced, Explainable and Parsimonious U-Nets", "authors": ["Bohang Sun", "Pietro Li\u00f2"], "abstract": "In this study, we propose MHEX+, a framework adaptable\nto any U-Net architecture. Built upon MHEX+, we introduce novel U-\nNet variants, EU-Nets, which enhance explainability and uncertainty es-\ntimation, addressing the limitations of traditional U-Net models while\nimproving performance and stability. A key innovation is the Equiva-\nlent Convolutional Kernel, which unifies consecutive convolutional lay-\ners, boosting interpretability. For uncertainty estimation, we propose the\ncollaboration gradient approach, measuring gradient consistency across\ndecoder layers. Notably, EU-Nets achieve an average accuracy improve-\nment of 1.389% and a variance reduction of 0.83% across all networks\nand datasets in our experiments, requiring fewer than 0.1M parameters.", "sections": [{"title": "1 Introduction", "content": "In clinical practice, accurate segmentation of anatomical structures or lesions is\ncrucial for diagnosis, treatment planning, and prognosis. However, deep neural\nnetworks, despite their strong performance, often lack transparency, making their\ndecision-making process difficult to understand.[1,2]\nExisting explainability methods, particularly Grad-CAM and its variants [3,4,5],\nhave demonstrated effectiveness in classification tasks. However, their application\nto semantic segmentation is limited, as they primarily highlight the predicted\nregions without explaining the underlying decision-making process. [6,7,8].\nBeyond explainability, uncertainty estimation is also crucial in medical image\nsegmentation. Inference methods based on uncertainty modeling, such as Subjec-\ntive Logic (SL) [9] and Dempster-Shafer Theory (DST) [10], can quantify belief\nmass. However, these methods typically require training models from scratch,\nwhich may degrade accuracy, especially in cases where the loss function is sensi-\ntive. Monte Carlo Dropout (MC Dropout) [11] requires the model to incorporate\ndropout layers at inference, while Deep Ensembles [12] estimate uncertainty by\nmeasuring model disagreement but incur high computational costs due to the\nneed for training multiple identical or diverse models.\nMotivated by the above considerations, we propose a novel explainable U-\nNet variant, referred to as EU-Nets, based on the Multi-Head Explainer (MHEX)\nframework [13]. The main contributions of this work are summarized as follows:"}, {"title": "2 Related Work", "content": "U-Net and Its Variants U-Net [14] introduced skip connections to bridge low-\nlevel and high-level features, significantly improving segmentation performance.\nU-Net++ [15] further enhanced this design by incorporating dense connections\nand deep supervision to refine feature aggregation. AHF-U-Net [16] employed\nattention mechanisms similar to SE [17] and CBAM [18] to compute importance\ncoefficients for fusion connections, enhancing feature selection adaptively. U-Net\nTransformer [19] integrated self-attention in the bottleneck and cross-attention\nin skip connections.\nExplainability Methods Grad-CAM and its variants [3,4,5] generate saliency\nmaps by weighting feature maps based on gradients, second-order derivatives, or\nmodel confidence. SHAP [20] estimates feature importance by perturbing inputs\nand computing Shapley values. LIME [21] approximates local decision bound-\naries by training interpretable linear models around the input space. MHEX\n(Multi-Head Explainer) [13] enhances both performance and explainability through\nlightweight modules and fine-tuning while also providing uncertainty estimation.\nUncertainty Estimation Subjective Logic (SL) [9] and Dempster-Shafer The-\nory (DST) [10] encourage models to quantify uncertainty in predictions. Monte\nCarlo Dropout (MC Dropout) [11] estimates uncertainty by enabling dropout\nat inference time. Deep Ensembles [12] aggregate predictions from multiple in-\ndependently trained models to improve robustness. Test-Time Augmentation\n(TTA) [22] leverages augmented inputs during inference to indirectly reflect\nmodel uncertainty. MHEX [13] introduces an alternative uncertainty estimation\napproach by analyzing gradient consistency."}, {"title": "3 Method", "content": ""}, {"title": "3.1 EU-Nets", "content": "MHEX has been shown to enhance interpretability and uncertainty estimation in\nclassification tasks. However, its integration into semantic segmentation remains\nunderexplored."}, {"title": "3.2 MHEX+ Module", "content": "In EU-Nets, the MHEX+ module operates as follows:\n\\(Y = ReLU(Conv1(X) +b1)\\)\n\\(Attention Gate = \u03c3(Y), Yattended = \u03c3(Y) \u2299 Y\\)\n\\(Deep Prediction = Conv2(Y) + b2\\)\nwhere Conv\u2081 is a 1\u00d71 convolution followed by ReLU activation, and \\(\u03c3(\u00b7)\\) denotes\nthe sigmoid function applied in the attention gate. The final deep prediction is\ncomputed via Conv2. For simplicity, biases are omitted in our implementation.\nThe MHEX+ module in EU-Nets is depicted on the left side of Figure 1."}, {"title": "3.3 Equivalent Convolutional Kernel & Salience Map", "content": "We extend the \\(W_{equiv}\\) principle to convolutions. Given two consecutive layers\nConv1 and Conv2, their equivalent kernel is computed as:\n\\(W_{equiv} [C] = \\sum_{j=1}^{C_{in}}W_{Conv2} [C, j] \u00b7 W_{Conv1} [j]\\)\nwhere c represents the output channel corresponding to a specific class. Conv1\nis part of the Attention Gate, while Conv2 is responsible for deep prediction.\nIn this way, multiple convolutional operations are consolidated into a single\nequivalent transformation. The Equivalent Convolutional Kernel enables efficient\nClass Activation Map (CAM) generation:\n\\(CAM_{C} = \\sum_{j=1}^{C_{in}} W_{equiv} [C, j] \u00b7 A[j]\\)\nwhere \\(A[j]\\) represents the activation map of the j-th channel.\nIt is important to note that the time complexity of Grad-CAM is \\(O(n\u00b2 \u00b7 C')\\),\nwhereas MHEX+CAM has a time complexity of O(C), where C denotes the\nnumchannels, which is a constant usually.\nThe right side of Figure 1 illustrates the Equivalent Convolutional Kernel."}, {"title": "3.4 Integration", "content": "U-Net-like networks consist of three stages: downsampling (encoder), extracting\nlow-level features; bottleneck, capturing global context; and upsampling (de-\ncoder), reconstructing the segmentation map.\nWe construct residual connections in the double convolution module across\nall decoders in U-Nets to integrate MHEX+, following the structural design\nprinciples of ResNet [26]. For U-Net++, we use the densely connected version\nrather than the deep supervision version, as MHEX+ already incorporates deep\nsupervision. Please refer to Figure 2."}, {"title": "3.5 Uncertainty Analysis", "content": "In this section, we introduce the concept of collaboration gradient to measure\nthe consistency between adjacent MHEX+ blocks at the pixel level.\nWe compute gradients for each pixel (i, j) and measure the cosine similarity\nof gradient vectors from adjacent MHEX+ blocks at layers 1 and 1+1 in EU-Nets\ndecoders. Specifically, for each pixel, the Uncertainty (U(i,j)) is defined as:\n\\(U(i,j) = \\sum_{L-1} cos(\\nabla_{C_l}^{(i,j)}, \\nabla_{C_{l+1}}^{(i,j)})\\)\nwhere\n\\(\\nabla_{C_l}^{(i,j)} = \\frac{\\partial L_{(i,j)}}{\\partial C_l}\\), denotes the gradient of the cross-entropy loss \\(L_{(i,j)}\\) with\nrespect to the parameter \\(C_l\\) at layer l;\n\\(\\nabla_{C_{l+1}}^{(i,j)} = \\frac{\\partial L_{(i,j)}}{\\partial C_{l+1}}\\) represents the corresponding gradient from layer l + 1;\n\\(cos(\\nabla_{C_l}^{(i,j)}, \\nabla_{C_{l+1}}^{(i,j)})\\) represents the cosine similarity between the two gradient\nvectors at pixel (i, j).\nTo verify the validity of our proposed uncertainty measure, we compare it\nagainst the Deep Ensemble method [12], which constructs multiple indepen-\ndent models {M1, M2, ..., MN} and estimates uncertainty for a given pixel (i, j)\nbased on the variation in predicted probabilities across models. Two commonly\nused uncertainty metrics in Deep Ensemble are:\n\\(\\sigma^{2} (y = c|x) = \\frac{1}{N} \\sum_{m=1}^{N}(P_{m}(y = c|x) \u2013 P(y = c|x))^{2}\\)\n\\(H(y|x) = \\sum_{C}P(y = c|x) log P(y = c|x)\\)\nwhere Pm(y = c|x) is the probability assigned by model Mm, and P(y = c|x)\nis the mean probability across models. Higher entropy H(y|x) indicates greater\nuncertainty due to model disagreement."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Datasets", "content": "To evaluate the performance of EU-Nets, we tested them on four diverse datasets\nspanning multiple imaging modalities (MRI, CT, Ultrasound, and Dermoscopic\nimages). Each dataset presents unique segmentation challenges:\nMSD-Heart [27]: 30 MRI scans (320 \u00d7 320), left atrium segmentation,\nlimited sample size, high anatomical variability.\nMSD-Spleen [27]: 61 CT scans (500 \u00d7 500), spleen segmentation, varied\nfield-of-view.\nBreast Ultrasound [28]: 780 ultrasound images (600 patients, 500 \u00d7 500),\nclassification: normal, benign, malignant, multi-label cases merged manually.\nISIC 2016 [29]: 900 training, 350 test dermoscopic images (1024 \u00d7 768),\nmelanoma segmentation with expert-annotated masks."}, {"title": "4.2 Results", "content": "In this section, we analyze model performance across datasets in Section 4.1.\nTo ensure a fair comparison and reduce potential biases, we maintain consis-\ntent hyperparameters for all models, including image size, batch size, learning\nrate, and number of epochs. Each model is trained for up to 50 epochs with\nearly stopping (patience = 10) and adaptive learning rate reduction (patience =\n5). Consequently, training typically converges before the 30th epoch, with most\ntrials stopping early. We perform five-fold cross-validation for all datasets.\nEU-Nets consistently outperform their baseline counterparts, particularly in\nterms of stability, demonstrating robustness across different cross-validation folds\nand diverse data distributions. Moreover, integrating MHEX+ introduces only\na minimal increase in model parameters (<0.1M). For overall performance com-\nparison, see Table 1, and for individual sample results, refer to the Pred row in\nFigure 3."}, {"title": "4.3 Salience Map", "content": "Although both MHEX+ and Grad-CAM highlight important regions, they rely\non fundamentally different mechanisms. Grad-CAM computes pixel-wise gradi-\nents, reproducing the segmentation output rather than providing deeper insights.\nIn contrast, MHEX+ leverages class-level equivalent convolution kernels to\nanalyze how the network attends to each class. By aggregating learned weights\ninstead of focusing solely on pixel-level gradients, MHEX+ captures multi-scale\nfeature responses across decoder stages, highlighting relevant regions beyond the\nsegmented target, such as liver and kidney areas. For comparison, see Figure 4."}, {"title": "4.4 Uncertainty Evaluation", "content": "To evaluate the validity of our MHEX+ based uncertainty estimation (MU), we\ncompare MU maps with Deep Ensemble uncertainty (DEU) maps (Section 3.5).\nWe conducted experiments on the MSD-Heart dataset using 50 randomly\nselected samples and tested four proposed EU-Nets. Each model's uncertainty\nwas computed via the MU approach, and the resulting maps were aggregated\ninto a single composite visualization (Fig. 5, last column). For single uncertainty\nsamples, see Figure 3, last row. DEU maps (Fig. 5) were obtained using entropy-\nand variance-based uncertainty estimation (Section 3.5).\nTo quantify the agreement between MU and DEU, we computed the IoU,\nDice, and Pearson correlation between the uncertainty maps. The results, sum-\nmarized in Table 2, show statistically significant differences between MU and\nDEU (p value = 0.0), suggesting that MU captures uncertainty through internal\ngradient alignment within a single model."}, {"title": "5 Conclusion", "content": "We propose EU-Nets, a family of explainable U-Net variants that enhance inter-\npretability, segmentation performance, and uncertainty estimation. The MHEX+\nmodule in EU-Nets is compatible with any U-Net-based architecture. Experi-\nments on four medical imaging datasets demonstrate that EU-Nets consistently\noutperform their baselines. Compared to Grad-CAM, MHEX+ based saliency\nmaps capture multi-scale and cross-decoder features, providing deeper insight\ninto model predictions. Additionally, our gradient-based uncertainty estimation\naligns well with Deep Ensemble methods, while requiring only a single model."}]}