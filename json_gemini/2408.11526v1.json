{"title": "RConE: Rough Cone Embedding for Multi-Hop Logical Query Answering on Multi-Modal Knowledge Graphs", "authors": ["Mayank Kharbanda", "Rajiv Ratn Shah", "Raghava Mutharaju"], "abstract": "Multi-hop query answering over a Knowledge Graph (KG) involves traversing one or more hops from the start node to answer a query. Path-based and logic-based methods are state-of-the-art for multi-hop question answering. The former is used in link prediction tasks. The latter is for answering complex logical queries. The logical multi-hop querying technique embeds the KG and queries in the same embedding space. The existing work incorporates First Order Logic (FOL) operators, such as conjunction ($\\land$), disjunction ($\\lor$), and negation ($\\neg$), in queries. Though current models have most of the building blocks to execute the FOL queries, they cannot use the dense information of multi-modal entities in the case of Multi-Modal Knowledge Graphs (MMKGs). We propose RConE, an embedding method to capture the multi-modal information needed to answer a query. The model first shortlists candidate (multi-modal) entities containing the answer. It then finds the solution (sub-entities) within those entities. Several existing works tackle path-based question-answering in MMKGs. However, to our knowledge, we are the first to introduce logical constructs in querying MMKGS and to answer queries that involve sub-entities of multi-modal entities as the answer. Extensive evaluation of four publicly available MMKGs indicates that RConE outperforms the current state-of-the-art. The source code and datasets are available at https://github.com/kracr/rcone-qa-mmkg.", "sections": [{"title": "I. INTRODUCTION", "content": "Knowledge Graph (KG) [1] is a directed graph with a set of entities (nodes) and directed relations among those entities (edges). KGs are an excellent tool for representing data in graph topology. They are used in applications such as question-answering and recommendation systems in diverse fields like biomedicine, physics, and geoscience [2].\nMulti-hop logical query answering over KGs has gained attention recently [3]. Various neural methods are proposed to answer a logical query. It involves traversing one or more hops over a KG to reach the answers. The query generally consists of First Order Logic (FOL) operators, such as existential quantification ($\\exists$), conjunction ($\\land$), disjunction ($\\lor$), and negation ($\\neg$).\nCurrent State-of-the-Art (SOTA). There are two major challenges to consider while handling logical query answering over KGs [4]. First, long and complex queries on large KGs incur exponential computational costs. Second, a robust model for handling missing edges in the graphs. Several methods have been proposed to embed the KG and queries in the same space to tackle these issues [5]. These methods iteratively progressed to incorporate different FOL operators in the queries. Geometric [4], [6], and probabilistic [7] methods embed the queries as geometrical shapes and probabilistic distributions, respectively. These methods are scalable and do not keep track of the intermediate nodes.\nShortcomings of SOTA Methods. [RQ1] Multi-Modal Knowledge Graphs (MMKGs) are KGs with multiple modalities, such as images, texts, and videos, as entities [8]. Though the current approaches can handle all the FOL operators well, they cannot incorporate the rich information of multi-modal entities. The node\u2019s embedding, in these models, is based on the relations with its neighbors. They do not consider the entity\u2019s features, which may lead to the loss of critical information in the case of multi-modal entities. [RQ2] There can be multiple subjects in a single multi-modal entity, and it might be that all the subjects are not answers to a query. One of the goals of this work is to get those individual subjects as answers. [RQ3] One way to tackle [RQ1] and [RQ2] is to generate a sub-KG for each multi-modal entity before training (offline). Convert the original MMKG to a non-multi-modal KG by merging all sub-KGs with the MMKG. However, for large MMKGs, constructing the sub-KGs for each multi-modal entity will incorporate high pre-processing and space overhead.\nTo address these challenges, we propose RConE, an embedding method for answering logical queries on MMKGs. In this work, we focus on entity/relational labels and images as the modalities. We summarize our contributions as follows.\nContribution I: Logical Query Answering on MMKGs at a finer granularity. We propose a novel problem of query answering using FOL constructs on MMKGs. In this problem, the answers might not be complete entities but some part (sub-entities) of the multi-modal entities. To our knowledge, we are the first to handle such queries. Consider the MMKG in Figure 1. For the query, \u201cShirt color of the actor not wearing brown shoes in the Toy Story movie,\u201d the answer is Green. The related computational graph is in Figure 2. In the MMKG, Green (shirt), is in the Toy Story (Poster) entity (sub-entity of Toy Story (Poster) entity), but there is no entity Green in the MMKG. To cater to these kinds of queries, we propose our model RConE.\nContribution II: RConE \u2013 A novel perspective of handling the query answering on MMKGs. We extend one of"}, {"title": "II. RELATED WORK", "content": "Multi-Hop Query Answering. There are two types of multi-hop querying techniques: path-based answering [9]\u2013[14] and logical query answering. In path-based answering, rules or paths of the KG are traversed to answer a query. It is generally used to improve the link prediction task. Logical query answering [5] embeds the KG and the query in the same space to evaluate the answer set. Our proposed model is based on logical query answering.\nGQE [15] proposed the initial query engine. The model answers the query with the closest answer embedded to the query. Query2Box [4] extended the work by representing the region of interest (ROI) using d-dimensional boxes. This ROI helps incorporate multiple answers to a query. The model could handle the disjunction ($\\lor$) and conjunction ($\\land$) operators. BetaE [7] and ConE [6] extended Query2Box to integrate the negation ($\\neg$) operator, making them fully compatible with FOL operators. While BetaE uses d-beta distributions to represent a query component, ConE uses d-ary sector cones. Extensions have also been proposed for hyper-relational KGs [16], [17] and temporal KGs [18]. A detailed survey on different query-answering methods is provided in [19]. Information about the current state of the art and the prospective future of logical query answering over KGs is contemplated in [5].\nQuestion-Answering on MMKGs. There are several works on path-based question-answering over an MMKG. Single-hop models like IKRL [20] use attention to capture the visual features of images. TransAE [21] adds multi-modal features and extends the conventional single-hop embedding model TransE [22]. MMKGR [23] proposed the initial multi-hop path-based query answering method using reinforcement learning for a unified gate attention network to filter noise. A review of the application of MMKGs in different fields is presented in [8]. Though these works use MMKGs to evaluate a query, they do not support logical queries with FOL constructs."}, {"title": "III. PRELIMINARIES", "content": "MMKG. A Multi-Modal Knowledge Graph $G(V,R,U,M)$ is a directed graph where $V$ and $R$ are entity and relation sets, respectively. $U$ is the triplet set, represented as\n$U = \\{(e_s,r,e_d) | e_s,e_d \\in V, r \\in R\\}$\nThere are $|M| = k$ modalities in the graph, such that\n$\\gamma(e_i) \\in M = \\{M_1, M_2, ..., M_k\\}, e_i \\in V$\nwhere $m_1$ is the generic entity label. In Figure 1, the entities {Tom Hanks, Walt Disney} $\\in m_1$ (generic) and {Toy Story (Poster), Walt Disney (Logo)} $\\in m_2$ (images). We consider $k = 2$, in this work.\nSub-Entity Knowledge Graph (Scene Graph). For each node, $e_j$, such that $\\gamma(e_j) = m_2$, we define a sub-entity KG or a scene graph as $SG_j(V_j, R_j,U_j)$. $V_j, R_j$, and $U_j$ are sub-entity, sub-relation, and sub-triplet sets, respectively. The $SG_s$ are the KGs describing each multi-modal entity in $G$.\nFOL Queries. First Order Logic (FOL) queries $q \\in Q = \\{Q_{train}, Q_{test}\\}$ consists of logical operators such as conjunction ($\\land$), disjunction ($\\lor$), existential quantification ($\\exists$), and negation ($\\neg$). We are not including universal quantification ($\\forall$), similar to [6], [7], as its applications in real-world KGs are rare. Queries are expected to be in Disjunctive Normal Form (DNF). This enables us to handle the union operator at the end, which helps the model to be scalable for long queries. An FOL query $q \\in Q$, with respect to an MMKG, comprises a non-variable anchor entity set\n$V_a \\subseteq V_u = \\bigcup_{j=1}^{\\nu} V_j | \\bigcup_V | \\gamma(e_j) = m_2$"}, {"title": "IV. METHOD", "content": "Figure 4 presents the flow diagram of our model RConE. It comprises two modules, the RConE Engine (RCE) and the Sub-Entity Prediction module. The RCE traverses query and outputs two entity sets 1) Answer entities in the rigid region (John Lassester in Q2). 2) Multi-modal entities consisting of the answers in the fuzzy region (Toy Story (Poster) in Q1). For each candidate multi-modal entity in the fuzzy region (here, Toy Story (Poster)), the Sub-Entity Prediction module initially generates a sub-entity KG (scene graph). Following this, it embeds the scene graph. Finally, the module transforms the sub-entities to the RConE's embedding space. The transformation is such that the answer sub-entities (Green in Q1) belong in the rigid region and other sub-entities outside the RConE embedding. In the following subsections, we describe each module in detail. A brief overview of the steps is presented in Algorithm 1 in the supplementary material.\nAs shown in Figure 4, RCE takes MMKG and queries as input and embeds them in the RConE embedding space. It traverses the query computational graph to generate the embedding. During traversal, RCE handles different FOL operators in a query. We first discuss the embedding procedure for queries and entities. Following it are the details about the transformation in embeddings based on the FOL operators.\nEntity and Query Embedding. Let $A(q)$ be the entity set satisfying the query $q$. The embedding for $A(q)$ is the cartesian product of d-ary (fuzzy-rigid) sector cones in $K^d$ embedding space (Figure 3). The embedding is presented as $V_q = (\\theta_{ax}, \\theta_{ri}, \\theta_{fu})$, where $\\theta_{ax} \\in [-\\pi, \\pi)^d$ is the semantic axis. $\\theta_{ri} \\in [0, 2\\pi]^d$ is the rigid aperture enclosing the region A around it. $\\theta_{fu} \\in [0, 2\\pi - \\theta_{ri}]^d$ is the fuzzy aperture enclosing region B around the rigid cone.\nAll entities belonging to the answer set (John Lasseter in Q2) will have embeddings in the region A. The multi-modal entities in G, which have some part in the answer (Toy Story (Poster) in Q1), will have embeddings in region B.\nThe embedding of node $v \\in V_u$ is represented as $v = (\\theta_{ax}, 0, 0)$. It can be considered as an answer set consisting of a single answer v. The embedding consists of no rigid and fuzzy areas (blue vector in Figure 3).\nThe reasons we are using the rough sets (fuzzy (boundary) region) as an extension to the original ConE [6] model are\n*   The multi-modal entities should operate in the same space as the unimodal entities as we are traversing the query in that space.\n*   The multi-modal entities containing the answer would be semantically similar to other answers. So, their embedding should also be closer. Hence, they would belong to the boundary region with partial membership (Equation 7c) to the answer set.\nLogical Operators. The query computational graph consists of different logical operators (Intersection, Union, and Complement) along with the relation projection operator. The $A(q)$'s RConE embedding resembles the answer set that satisfies the processed query at any moment through this traversal. Figure 5 consists of the visual representation of how all the operations work on 1-ary RConE embedding. We present the modeling of each operator below. Each operator has been extended to accomodate the fuzzy boundary part in ConE [6].\nProjection. Projection is a relation-dependent transformation of answer distribution ($A(q)$), with the transformed embedding in the same space as the original one. We define projection mapping using the following function.\n$P_r: V \\longrightarrow V, V_r, V_p \\in K^d$"}, {"title": "V. EXPERIMENTS", "content": "Datasets and Evaluation Metrics. For evaluation, we use multi-modal datasets FB15k, FB15k-(237), YAGO15k, and DB15k [31", "22": "uni-modal dataset) to check whether the performance of our proposed model degrades compared to its non-multi-modal counterpart (ConE). Table II contains statistics of all the datasets. We use the average Mean Reciprocal Rank (MRR) and average HITS scores of all the answers to a query. We use these metrics for all three goals (1a, 1b, 2) described in Section IV-C.\nBaselines. Since RConE is the first multi-modal logical query-answering algorithm, we choose non-multi-modal models BetaE [7", "6": "as baselines. BetaE embeds the query answer distribution as d-dimensional beta distribution. The method was the first to handle the negation ($\\neg$) operator. ConE improved on BetaE and represented the answer distribution as d-ary sector-cones. We cannot compare our model with path-based MMKG algorithms; hence, we omit them.\nQuery Generation. We propose a new query generation module that extends [7", "27": ".", "28": ".", "7": "and incorporate Type I answers-based queries for all the 14 query structures (Figure 7) as well. Given a query structure, the algorithm chooses an answer randomly and backtracks to reach the source node while following the query structure. During traversal, it determines the relations randomly. It then executes the query again to get all the other entities that can be reached, given the source and the query.\nScene Graph Generation. We choose FCSGG [27", "32": "for training.\nThe sub-module is used in both RConE and query generation. To make them independent, we use HRNet-W48 [33", "34": "."}]}