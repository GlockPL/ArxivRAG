{"title": "Intuitionistic Fuzzy Cognitive Maps for Interpretable\nImage Classification", "authors": ["Georgia Sovatzidi", "Michael D. Vasilakakis", "Dimitris K. Iakovidis"], "abstract": "Abstract\u2014The interpretability of machine learning models is\ncritical, as users may be reluctant to rely on their inferences.\nIntuitionistic FCMs (iFCMs) have been proposed as an extension\nof FCMs offering a natural mechanism to assess the quality of\ntheir output through the estimation of hesitancy, a concept\nresembling to human hesitation in decision making. To address the\nchallenge of interpretable image classification, this paper\nintroduces a novel framework, named Interpretable Intuitionistic\nFCM (I2FCM), which is domain-independent, simple to\nimplement, and can be applied on Convolutional Neural Network\n(CNN) models, rendering them interpretable. To the best of our\nknowledge this is the first time iFCMs are applied for image\nclassification. Further novel contributions include: a feature\nextraction process focusing on the most informative image regions;\na learning algorithm for data-driven determination of the\nintuitionistic fuzzy interconnections of the iFCM; an inherently\ninterpretable classification approach based on image contents. In\nthe context of image classification, hesitancy is considered as a\ndegree of inconfidence with which an image is categorized to a\nclass. The constructed iFCM model distinguishes the most\nrepresentative image semantics and analyses them utilizing cause-\nand-effect relations. The effectiveness of the introduced\nframework is evaluated on publicly available datasets, and the\nexperimental results confirm that it can provide enhanced\nclassification performance, while providing interpretable\ninferences.", "sections": [{"title": "I. INTRODUCTION", "content": "MACHINE learning models are increasingly being\nadopted to make decisive and meaningful\npredictions in several critical tasks of various\nscientific fields [1]. However, the absence of interpreting the\nresults in an intelligible way results in ML approaches being\nconsidered in some cases unreliable and \"black boxes\" [2]. In\nrecent years, there have been increasing efforts to develop\nimage classification models explaining their inferences [3].\nAmong them, methods based on fuzzy logic offer the advantage\nof being robust under uncertainty and imprecision, while\nenabling human-like non-numerical knowledge representation\nand reasoning. Recently proposed fuzzy models include an\nexplainable Deep Neural Network (xDNN) proposed as a non-\niterative and non-parametric image classifier, capable of\ncombining both reasoning and data-driven learning [4]. Deep\nMachine Reasoning (DMR) was proposed as an extension of\nxDNN, which used a decision tree-based inference and\nsynthetic data to balance the classes of complex multiclass\nproblems [5]. The interpretable Deep Rule-Based (DRB)\nclassifier was proposed for image recognition problems [6]. A\nkey aspect of that method was that it combined a zero-order\nself-organizing rule-based system with a multi-layer image-\nprocessing architecture. This method was extended to\nHierarchical DRB (H-DRB), which considered a self-ordering\nhierarchical rule structure providing enhanced interpretability\n[7].\nFuzzy Cognitive Maps (FCMs) are graph-based knowledge\nmodels composed of concepts and causal relationships among\nthem [8]. Due to their simple yet efficient structure, FCMs have\nbeen increasingly used for many applications of various\nscientific fields, including engineering, medicine, and business\nfields [9], [10]. However, the potentials of FCM have not been\nyet sufficiently investigated with respect to image-based\ndecision making. A relevant study [11] proposed an FCM with\na Hebbian learning algorithm developed to predict breast cancer\nrisk using mammographic image features. In [12], FCMs were\nutilized to classify remote sensing image scenes, while a swarm\nintelligent algorithm was used for parameter tuning.\nPreliminary works of the authors exploited FCMs to develop\ninterpretable image classifiers. More specifically, the xFCM,\nproposed in [13], was a first approach of an auto-constructed\nFCM capable of classifying images. In addition, the\nInterpretable FCM-based Feature Fusion (IF\u00b3) framework\nproposed in [14] enabled the fusion of different features\nextracted using various methods and adapted for automated\nlesion risk assessment in medical images. However, the\ninterpretations derived from these approaches were considering\neach image as a whole, neglecting local information from image\nregions that encompasses details about their content.\nOver the years, various modifications have been proposed to\novercome the limitations of FCMs [9]. Considering the\nhesitation that experts may have when defining the relations\namong the graph concepts, iFCM-I and iFCM-II were\nintroduced. These models can effectively tackle uncertainty by\nincorporating intuitionistic fuzzy sets (IFSs) [15], [16]. They\nhave demonstrated a more robust decision-making performance\ncompared to the conventional FCM models, while offering a\nnatural mechanism to assess the quality of their output through\nhesitancy estimation. Despite their advantages, to date, only a\nlimited number of applications have been based on iFCMs."}, {"title": "II. PRELIMINARIES", "content": "FCMs constitute a powerful tool for complex system\nmodeling [8]. They are graph-based models, composed of\nnodes and weighted arcs. The nodes represent concepts related\nto the complex system being modeled, and the arcs represent\nrules expressing causal relationships between these concepts.\nEach of the N concepts $C_i, i = 1, ..., N$, of the FCM has a value\n$A_i \\in [0,1]$. The weight of an arc between two concepts $C_j, j =$\n$1, ..., N$, and $C_i, i \\neq j$ denoted as $W_{ji} \\in [-1,1]$, represents the\ndegree to which $C_j$ influences $C_i$. There are three types of causal\nrelationships: a) positive ($W_{ji} > 0$), which means that an\nincrease in the value of $C_j$, causes an increase of the value of $C_i$,\nb) negative ($W_{ji} < 0$), indicating that an increase in the value of\n$C_j$, causes a decrease of the value of $C_i$, and c) neutral ($W_{ji} =$\n0), meaning that there is no relationship between $C_j$ and $C_i$. To\nconstruct an FCM, a number of concepts along with the\nrespective weighted arcs connecting them, are usually defined\nmanually with the contribution of domain experts. Once the\ngraph is constructed, given a test case, the reasoning phase takes\nplace until the FCM converges to a steady state. The values of\nthe output concepts retrieved from that state represent its\ninferences. During the reasoning process the concept values\n$A_i \\in [0,1]$ are iteratively calculated as follows [8]\n$A_i^{t+1} = f(A_i^t + \\sum_{j=1,j\\neq i}^{N} A_j^t \\cdot W_{ji})$\nwhere $A_i^{t+1}$ represents the value of $C_i$ at the iteration $t + 1$, $W_{ji}$\nis the influence of $C_j$ on $C_i$, and $f$ is a sigmoid function such as\nthe log sigmoid\n$f(x) = \\frac{1}{1+\\exp(-x)}$\nwhich maps the concept values within [0,1][21]. The initial\nstate vector $A^0$ represents the initial concept values, for t = 0."}, {"title": "B. Intuitionistic Fuzzy Cognitive Maps", "content": "Intuitionistic fuzzy sets (IFSs) [22] extend fuzzy sets by\nintroducing the concept of non-membership as not necessarily\na complement to the membership. Given a universe of discourse\nG, an IFS is defined as\n$\\delta = \\{(x, \\mu_\\zeta(x), \\gamma_\\zeta(x))| x \\in G \\}$\nwhere $\\mu_s(x) \\in [0,1]$ and $\\gamma_s(x) \\in [0,1]$ define the degree of\nmembership and non-membership, respectively of $x \\in G$ to\n$S \\subset G$. The hesitancy $h_\\zeta(x)$ of an element $x \\in G$ to $S \\subset G$ is\ndefined as follows:\n$h_\\zeta(x) = 1 - \\mu_\\zeta(x) - \\gamma_\\zeta(x)$\ncharacterizing the indeterminacy (uncertainty) of the\nmembership of x in S.\nIn [16], iFCM-II was proposed as an extension of the original\nFCM model exploiting IFSs to model the uncertainty in the\ndetermination of the concept values and the weights of the"}, {"title": "III. METHODOLOGY", "content": "The proposed framework for interpretable image\nclassification involves two phases, a training, and a testing\nphase, which are detailed in the following paragraphs."}, {"title": "A. Training Phase", "content": "Let us consider a set of K training input images $I_k, k = 1, ..., K$,\nwith ground-truth class vectors $y_k = [y_1, y_2, ... y_F]$, where F\nrepresents the total number of classes in the training dataset. An\nimage belongs to class f, if $y_f = 1$, otherwise it does not belong\nto that class.\nFirstly, the SLIC superpixel segmentation algorithm [23] is\nused to segment $I_k, k = 1, ..., K$, into P superpixels $p =$\n$1, ..., P$, in line with [24]. The generated superpixels constitute"}, {"title": "Step 2: Concept Mining", "content": "The feature vectors $D_k = \\{d_1^k, ..., d_{P'}^k \\}, k = 1 ... K$ extracted\nfrom each training image $I_k$ belonging to class f, are grouped into\n$M_f$ clusters, using a conventional clustering algorithm, such as the\nk-means. The clusters facilitate a higher-level representation of the\nimage content incorporating conceptual information. The\nmedoids of the clusters are used as a more compact representation\nof this information (dashed squares in Fig.3\u2013step 2). The resulting\nmedoids are denoted as $r_m, m = 1, ..., M$, where $M =$\n$\\sum_{f=1}^{F} M_f$. For each medoid $r_m$, a respective class vector $y_m =$\n$[y^1, y^2, ... y^f]$ is used to characterize its belongingness to a\nclass, where $y^f \\in \\{0,1\\}$, and F is the total number of classes.\nConsidering that the mined clusters with medoids $r_m$ represent\nconcepts that exist in the input image, they will be considered as"}, {"title": "Step 3: Similarity Calculation", "content": "In the third step of the training phase the similarity among the\ncalculated medoids $r_m, m = 1, ..., M$ and the extracted set of\nfeature vectors $D_k = \\{d_1^k, ..., d_{P'}^k \\}, k = 1 ... K$ from a training\nimage $I_k$ is calculated as follows [26]\n$\\zeta_k(r_m) = \\sum_{p=1}^{P'} (1-\\frac{||d_p^k -r_m||}{\\sum_{k=1}^{K}||d_p^k -r_m||})$\nwhere $|| \\cdot ||$ is a distance metric, e.g., the Euclidean distance. The\nrationale of (10) is that it provides a normalized estimation of\nsimilarity, in the same way that a human recognizes and\nclassifies objects based on comparisons with previous known,"}, {"title": "Step 4: Intuitionistic Fuzzy Modelling", "content": "The fourth step includes the construction of IFSs linguistically\ncharacterizing the similarity of an input image with the images\nbelonging to the target and other classes. The IFSs are modeled\nusing a membership and a non-membership function. The\nmembership function expresses the similarity of the feature\nvectors extracted from the input image with the medoids of the\nclusters derived from the training images of the class it belongs\nto. The non-membership function expresses the similarity of the\nfeature vectors extracted from the input image with the medoids\nof the clusters derived from the images belonging to the other"}, {"title": "Step 5: iFCM Construction", "content": "This step defines the structure of the iFCM model, including\nthe determination of its concepts and relations. Unlike\nconventional FCMs, which require the participation of experts,\nthe introduced framework embeds a learning algorithm for\nautomatic determination of its structure and the weights of its\ninterconnections based on the training dataset.\nConsidering the graph nodes of the iFCM, the nodes\nrepresenting the input concepts represent the clusters with\nmedoids $r_m$ of each examined class $f = 1, ..., F$ (step 2, step\n3), and the output concepts represent the different classes $f =$\n$1,..., F$ included in the training images of the dataset used.\nThe influence between two related concepts $C_j, C_i, i \\neq$\n$j,i,j = 1, ..., N$, where $N = M + F$ is the total number of\nconcepts, is expressed by an IFS of the form $\\{(w^h,w^\\gamma)\\}_{ji}$.\nThis IFS is created following the process described in step 4.\nTwo types of relations can be distinguished: the relations\nbetween a) input-output concepts, and b) input concepts.\nRelations between input and output concepts. To define\nand linguistically characterize the influence between such\nconcepts, IFSs $S_{ji} = \\{(w^h,w^\\gamma)\\}_{ji}$, are constructed as follows:\n$S_{ji} = \\cup_{\\varphi=1}^{\\Phi}S_m^{\\varphi}$\nwhere $S_m B_m \\times Q_m, m = 1, ..., M$. The symbol \u201c$\\cup$\u201d\nrepresents the intuitionistic fuzzy union operation performed\nbetween $C_j$ and $C_i, i, j = 1, ..., N, i \\neq j$. Based on [27], the\nintuitionistic fuzzy union operation is performed by aggregating\nthe fuzzy sets $B_m$ (which are used for the definition of the IFS\nmemberships) using the fuzzy union operation, and the fuzzy\nsets $Q_m$ (which are used for the definition of the IFS non-\nmemberships) with the fuzzy intersection. The rationale behind\nusing the intuitionistic fuzzy union operation comes from the"}, {"title": "Relations between input concepts.", "content": "To linguistically\ncharacterize the influences between the input concepts,\nrespective IFSs are defined as follows:\n$S_{ji} = (\\cup_{\\varphi=1}^{\\Phi}S_m^{\\varphi}) \\cap (\\cup_{\\varphi=1}^{\\Phi}S_{m_j}^{\\varphi})$\nwhere $S_m B_m \\times Q_{m_i}$\nand $S_{m_j} B_{m_j} \\times Q_{m_j}, m =$\n$1, ..., M, i, j = 1, ..., N, i \\neq j$. The symbol \u201c$\\cap$\u201d represents the\nintuitionistic fuzzy intersection operation performed between\n$C_i$ and $C_j$. The fuzzy sets $B_{m_i}, B_{m_j}$ are aggregated, using the\nfuzzy union operation, while for the fuzzy sets $Q_{m_i}$ and $Q_{m_j}$\nthe fuzzy intersection is used, resulting in $\\cup_{\\varphi=1}^{\\Phi}S_m$ and\n$\\cup_{\\varphi=1}^{\\Phi}S_m$. Based on [27], the intuitionistic fuzzy intersection\noperation is performed by aggregating the resulting IFSs, as\nshown in (13). The rationale behind using the fuzzy intersection\nis that it represents the consensus among expert opinions that\nexist when determining the relations in the conventional FCMs."}, {"title": "B. Test Phase", "content": "Given a test input image I, feature vectors $D = \\{d^1, ..., d^{P'}\\}$\nare extracted using a CNN, as described in step 1 of the training\nphase. The similarity $\\zeta(r_m)$ between the calculated medoids $r_m,$\n$m = 1, ..., M$ and $D = \\{d^1, ..., d^{P'}\\}$ is calculated, and they are\nlinguistically characterized using IFSs (steps 3,4). In this way, the\nstate vector\n$A = \\{(w^h(\\zeta(r_1)), w^\\gamma(\\zeta(r_1))), ..., (w^h(\\zeta(r_M)),w^\\gamma(\\zeta(r_M)))\\}$\nof the image is calculated and used as input in the trained iFCM\nmodel, aiming to perform interpretable classification. The\nreasoning process is then performed by iteratively calculating\nthe pairs $(v^{\\mu}, v^{\\gamma})_i$ of each $C_i, i = 1, ..., N$ using (6)-(8)."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "To evaluate the performance of I\u00b2FCM, the following publicly\navailable benchmark datasets were used:\na) Caltech 101 [29] contains 9,144 images of 102 different\nclasses. Each class includes 33 to 800 images, and the size of\nthe images on average is 300 \u00d7 200 pixels. For the experiments,\n30 randomly selected images from each class of the dataset\nwere used as the training set while the rest images formed the\ntest set.\nb) Caltech 256 [30] consists of 30,607 images, illustrating 256\ndifferent object classes with at least 80 images in each class.\nThe images of the dataset have an average resolution of 300 \u00d7\n250 pixels. For the evaluation, 60 randomly selected images\nfrom each class composed the training set, and the rest of them\nare used for testing.\nc) 15-Scenes [31] includes 200 to 400 images of 15 classes with\nan average resolution of 300 \u00d7 250 pixels. A set of 100 images\nwas used for training and the rest of them for testing.\nThe feature extraction process (step 1) was performed using\nVGG-16 model pretrained on ImageNet [32]. The clustering\nprocess was implemented using the k-means algorithm [33]\nwith Euclidean distance, as a baseline clustering algorithm\ncommonly used in related methods [26]. The range of the\nnumber of clusters in k-means tested using grid search was [5,\n50], and the range of number of fuzzy sets tested using grid\nsearch was [5, 15]. The fuzzy sets were implemented using\nGaussian membership functions. In addition, the number of\niFCM input concepts ranged from 2 to 15, and the number of\noutput concepts were defined according to the number of\nclasses included in the dataset used. The hesitancy values of the\niFCM concepts were initially set to 0. Furthermore, the\nhyperbolic tangent (tanh) was used in as a transfer function in\n$\\{(\\beta_\\mu, \\beta_\\gamma)\\}$ of (6)-(7)."}, {"title": "B. Classification Performance", "content": "The performance of I\u00b2FCM, was compared with both state-of-\nthe-art and conventional machine learning models in terms of\nclassification accuracy. Comparisons were performed with the\nfollowing models: a) VGG-16 [34], b) VGG-19 [34], c)\nGoogleLeNet [35], d) ResNet-101 [36], e) ResNet-50 [36], f)\nDirected Acyclic Graph (DAG)-CNN [37], g) k-Nearest\nNeighbors (k-NN) algorithm [38] as well as relevant state-of-\nthe-art interpretable models: a) DMR [5], b) xDNN [4], c) H-\nDRB [7], d) DRB [6], and e) xFCM [13]. It should be noted that\nthe presented comparisons are based on results reported in the\nliterature and all experiments were performed based on settings\nand guidelines used in the respective studies.\nThe results are summarized in Tables II-III, where the\ninterpretable classification methodologies are underlined. It\ncan be noticed that I2FCM outperforms most of the compared\nmodels in terms of the classification accuracy on all datasets.\nIt is worth noting that I2FCM outperforms all non-interpretable"}, {"title": "C. Interpretability Analysis", "content": "Let us consider a test input image, which depicts a flamingo\nfrom the Caltech-101 dataset. According to step 1 of the\nproposed framework feature vectors D are extracted from K =\n9 selected superpixels. The iFCM model constructed in step 5 of\nthe training process consists of a total of M = 8 input concepts\nare used, which are the following: $C_1$: \"Rhino-head\", $C_2$:\n\"Rhino-body\", $C_3$: \u201cKangaroo-head\u201d, $C_4$: \u201cKangaroo- body\u201d,\n$C_5$: \"Flamingo-head\", $C_6$: \"Flamingo-body\", $C_7$: \"Llama-head\",\n$C_8$: \"Llama-body\". The output concepts represent the\ncorresponding F = 4 classes that are: $C_9$: \"Rhino\", $C_{10}$:\n\"Kangaroo\", $C_{11}$: \"Flamingo\", and $C_{12}$: \"Llama\u201d. The iFCM\nmodel has relations between all input concepts, as well as\nrelations between input and output concepts. To simplify its\nrepresentation in Fig. 7(a) only a subset of the relations is\ndepicted. The fuzzy sets corresponding to the linguistic values\nof the influences between its concepts are illustrated in Fig. 7\n(b).\nThe initial state vector of the input image is calculated (after\nsteps 2 and 3) and is utilized as input to the iFCM model. Then,\nthe iFCM iteratively calculates its concept values, until it\nreaches a steady state, in t = 12 iterations, using (6)-(8). The\nconvergence of the output concepts of the iFCM model, in\nterms of its membership and hesitancy values, is illustrated in\nFig. 6. Also, the results of the image classification after t = 12\niterations, are presented in Fig. 7(d). In this figure, green bars\nrepresent membership, blue bars represent non-membership,\nand yellow bars represent the respective hesitancy values. It can\nbe observed that in all cases, the non-membership values reach\nzero at the steady state. This is due to the reasoning performed\nusing (7) [16]. Thus, the initial non-membership values do not\npractically affect the final decision. The hesitancy values are\ndecreased for the iFCM nodes containing parts characterizing\nthe class to which the image belongs to. In this example nodes\n$C_5$, $C_6$\ncontain parts characterizing the class and\n$C_{11}$: \"Flamingo\" (Fig. 7(d)). In case an image belongs to a\ncertain class with high similarity with the corresponding\nconcepts, the membership function tends to 1, while the non-\nmembership and hesitancy values tend to 0. The low degree of\nhesitancy confirms the validity of the decision.\nTo summarize, the explanation about the classification\noutcome for the test input image, after t = 12 iterations, is the\nfollowing:\n\u2022\nThe input image is classified as \"Flamingo\" because it\nhas (a) Very High similarity with Very Low hesitancy\nwith $C_5 =$\u201dFlamingo-head\u201d; (b) Very High similarity\nwith Very Low hesitancy with $C_6 =$ \u201cFlamingo-\nbody\u201d.\n\u2022\nThe input image cannot be classified as \u201cRhino\u201d\nbecause it has (a) Low similarity with a Very High\nhesitancy with $C_1$: \u201cRhino-head\u201d, and (b) High\nsimilarity with Very High hesitancy with $C_2$: \u201cRhino-\nbody\u201d.\nThe high degree of similarity, i.e., membership value, in the\nlatter case can be explained by the fact that the extracted\nfeatures vectors $d_{10}$, $d_{12}$, $d_{15}$ corresponding to the background\nof the image (Fig. 7(a)), have a similar visual content with $C_2$\nthat represents the \"Rhino-body\". More specifically, as\nillustrated in the figure, in the test image there are regions of\ndark blue in the background, which are similar to the body of\nrhino.\nRegarding the relations of iFCM for the image classification\nproblem under consideration, the following conclusions can be\nderived: for the membership values there is a positive causality\n(whereas for the non-membership values there is a negative\ncausality) between:\n(a) input and output concepts that are related to the same\nclass. For example, there is a positive relation between\n$C_1$ and $C_2$, representing ", "Rhino-\nbody": "respectively. This means that as the similarity of\nthe extracted features from the test input image with the\nrepresentative features depicting", "with": "hino-body\u201d.\n(b) input and output concepts related to the same class. For\nexample, Fig. 7 (a) shows that there is a positive\ninfluence of the input concepts $C_1$ and $C_2$, with the\noutput concept $C_9$, belonging to the class \u201cRhino\u201d.\nIn addition, there is a negative causality in the membership\nvalues (whereas there is a positive causality in the non-\nmembership values), among:\n(a) the input concepts related to different classes.\n(b) the input and output concepts representing different\nclasses."}, {"title": "V. DISCUSSION AND CONCLUSIONS", "content": "In this paper, a novel framework named I\u00b2FCM is introduced.\nThe proposed framework constructs iFCM models for interpe-"}, {"title": "", "content": "Advantages of I2FCM over current relevant classification\nframeworks, include the following:\n\u2022\nIntuitionistic fuzzy logic improves the knowledge\nelicitation and, consequently, the decision-making\nprocess of FCMs.\n\u2022\nIncludes an algorithm for automatic determination of\nthe graph structure from the data used, thus limiting\nhuman intervention and participation of experts.\n\u2022\nIt provides more accurate outcomes than most other\ninterpretable state-of-the-art approaches compared,\nand this can be attributed to the improved modeling of\nthe uncertainty through IFSs.\n\u2022\nIt can encapsulate CNN classifiers, thus making them\ninterpretable.\n\u2022\nIt is simple to implement.\nFuture directions include further investigation of the proposed\nframework, including its performance on various application\ndomains."}]}