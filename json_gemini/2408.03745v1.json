{"title": "Intuitionistic Fuzzy Cognitive Maps for Interpretable Image Classification", "authors": ["Georgia Sovatzidi", "Michael D. Vasilakakis", "Dimitris K. Iakovidis"], "abstract": "The interpretability of machine learning models is critical, as users may be reluctant to rely on their inferences. Intuitionistic FCMs (iFCMs) have been proposed as an extension of FCMs offering a natural mechanism to assess the quality of their output through the estimation of hesitancy, a concept resembling to human hesitation in decision making. To address the challenge of interpretable image classification, this paper introduces a novel framework, named Interpretable Intuitionistic FCM (I2FCM), which is domain-independent, simple to implement, and can be applied on Convolutional Neural Network (CNN) models, rendering them interpretable. To the best of our knowledge this is the first time iFCMs are applied for image classification. Further novel contributions include: a feature extraction process focusing on the most informative image regions; a learning algorithm for data-driven determination of the intuitionistic fuzzy interconnections of the iFCM; an inherently interpretable classification approach based on image contents. In the context of image classification, hesitancy is considered as a degree of inconfidence with which an image is categorized to a class. The constructed iFCM model distinguishes the most representative image semantics and analyses them utilizing cause- and-effect relations. The effectiveness of the introduced framework is evaluated on publicly available datasets, and the experimental results confirm that it can provide enhanced classification performance, while providing interpretable inferences.", "sections": [{"title": "I. INTRODUCTION", "content": "MACHINE learning models are increasingly being adopted to make decisive and meaningful predictions in several critical tasks of various scientific fields [1]. However, the absence of interpreting the results in an intelligible way results in ML approaches being considered in some cases unreliable and \"black boxes\" [2]. In recent years, there have been increasing efforts to develop image classification models explaining their inferences [3]. Among them, methods based on fuzzy logic offer the advantage of being robust under uncertainty and imprecision, while enabling human-like non-numerical knowledge representation and reasoning. Recently proposed fuzzy models include an explainable Deep Neural Network (xDNN) proposed as a non- iterative and non-parametric image classifier, capable of combining both reasoning and data-driven learning [4]. Deep Machine Reasoning (DMR) was proposed as an extension of xDNN, which used a decision tree-based inference and synthetic data to balance the classes of complex multiclass problems [5]. The interpretable Deep Rule-Based (DRB) classifier was proposed for image recognition problems [6]. A key aspect of that method was that it combined a zero-order self-organizing rule-based system with a multi-layer image- processing architecture. This method was extended to Hierarchical DRB (H-DRB), which considered a self-ordering hierarchical rule structure providing enhanced interpretability [7]. Fuzzy Cognitive Maps (FCMs) are graph-based knowledge models composed of concepts and causal relationships among them [8]. Due to their simple yet efficient structure, FCMs have been increasingly used for many applications of various scientific fields, including engineering, medicine, and business fields [9], [10]. However, the potentials of FCM have not been yet sufficiently investigated with respect to image-based decision making. A relevant study [11] proposed an FCM with a Hebbian learning algorithm developed to predict breast cancer risk using mammographic image features. In [12], FCMs were utilized to classify remote sensing image scenes, while a swarm intelligent algorithm was used for parameter tuning. Preliminary works of the authors exploited FCMs to develop interpretable image classifiers. More specifically, the xFCM, proposed in [13], was a first approach of an auto-constructed FCM capable of classifying images. In addition, the Interpretable FCM-based Feature Fusion (IF\u00b3) framework proposed in [14] enabled the fusion of different features extracted using various methods and adapted for automated lesion risk assessment in medical images. However, the interpretations derived from these approaches were considering each image as a whole, neglecting local information from image regions that encompasses details about their content. Over the years, various modifications have been proposed to overcome the limitations of FCMs [9]. Considering the hesitation that experts may have when defining the relations among the graph concepts, iFCM-I and iFCM-II were introduced. These models can effectively tackle uncertainty by incorporating intuitionistic fuzzy sets (IFSs) [15], [16]. They have demonstrated a more robust decision-making performance compared to the conventional FCM models, while offering a natural mechanism to assess the quality of their output through hesitancy estimation. Despite their advantages, to date, only a limited number of applications have been based on iFCMs."}, {"title": "II. PRELIMINARIES", "content": "FCMs constitute a powerful tool for complex system modeling [8]. They are graph-based models, composed of nodes and weighted arcs. The nodes represent concepts related to the complex system being modeled, and the arcs represent rules expressing causal relationships between these concepts. Each of the N concepts $C_i$, $i = 1, ..., N$, of the FCM has a value $A_i \\in [0,1]$. The weight of an arc between two concepts $C_j$, $j = 1, ..., N$, and $C_i$, $i \\neq j$ denoted as $W_{ji} \\in [-1,1]$, represents the degree to which $C_j$ influences $C_i$. There are three types of causal relationships: a) positive ($W_{ji} > 0$), which means that an increase in the value of $C_j$, causes an increase of the value of $C_i$, b) negative ($W_{ji} < 0$), indicating that an increase in the value of $C_j$, causes a decrease of the value of $C_i$, and c) neutral ($W_{ji} = 0$), meaning that there is no relationship between $C_j$ and $C_i$. To construct an FCM, a number of concepts along with the respective weighted arcs connecting them, are usually defined manually with the contribution of domain experts. Once the graph is constructed, given a test case, the reasoning phase takes place until the FCM converges to a steady state. The values of the output concepts retrieved from that state represent its inferences. During the reasoning process the concept values $A_i \\in [0,1]$ are iteratively calculated as follows [8]\n$A_i^{t+1} = f (A_i^t + \\sum_{j=1,j\\neq i}^{N} A_j^t \\cdot W_{ji})$\nwhere $A_i^{t+1}$ represents the value of $C_i$ at the iteration t + 1, $W_{ji}$ is the influence of $C_j$ on $C_i$, and $f$ is a sigmoid function such as the log sigmoid\n$f(x) = \\frac{1}{1+exp(-x)}$\nwhich maps the concept values within [0,1][21]. The initial state vector $A^0$ represents the initial concept values, for t = 0."}, {"title": "B. Intuitionistic Fuzzy Cognitive Maps", "content": "Intuitionistic fuzzy sets (IFSs) [22] extend fuzzy sets by introducing the concept of non-membership as not necessarily a complement to the membership. Given a universe of discourse G, an IFS is defined as\n$\\delta = \\{(x, \\mu_s(x), \\gamma_s(x))| x \\in G \\}$\nwhere $\\mu_s(x) \\in [0,1]$ and $\\gamma_s(x) \\in [0,1]$ define the degree of membership and non-membership, respectively of x \u2208 G to S\u2282 G. The hesitancy $h_s(x)$ of an element x \u2208 Gto S\u2282 G is defined as follows:\n$h_s(x) = 1 - \\mu_s(x) - \\gamma_s(x)$\ncharacterizing the indeterminacy (uncertainty) of the membership of x in S.\nIn [16], iFCM-II was proposed as an extension of the original FCM model exploiting IFSs to model the uncertainty in the determination of the concept values and the weights of the"}, {"title": "III. METHODOLOGY", "content": "The proposed framework for interpretable image classification involves two phases, a training, and a testing phase, which are detailed in the following paragraphs."}, {"title": "A. Training Phase", "content": "Let us consider a set of K training input images $I_k$, $k = 1, ..., K$, with ground-truth class vectors $y_k = [y_1, y_2, ... y_F]$, where F represents the total number of classes in the training dataset. An image belongs to class f, if $y_f = 1$, otherwise it does not belong to that class.\nFirstly, the SLIC superpixel segmentation algorithm [23] is used to segment $I_k$, $k = 1, ..., K$, into P superpixels $p = 1, ..., P$, in line with [24]. The generated superpixels constitute a superpixel map of height 7, and width p (Fig. 2). The training input image $I_k$, $k = 1, ..., K$, is fed into a CNN to produce \u03b4 feature maps $\\Delta_k \\in R^{\u03b4\u00d7p}$. The extracted feature maps are rescaled to the resolution of the superpixel map of $I_k$, $k = 1, ..., K$ (Fig. 2). A feature vector of the form $d_p^k$ is extracted from each superpixel $p = 1, ..., P$ of $I_k$, using average pooling. In the example of Fig. 2, a total of P=16 feature vectors, $d_1^k, ..., d_P^k$, are obtained by following this process.\nWithin the I2FCM framework, a further selection of the most informative superpixels is introduced, considering their spatial interrelations in the superpixel map. Ideally, the most informative superpixels are those that describe the object represented in an image, and are more likely to be close to each other, while the superpixels that describe the background are arbitrarily placed at different positions [25]. To determine the superpixels that are likely informative, the following distances are calculated between all superpixels: a) their spatial distance based on their center of mass, and b) the distance among the feature vectors $d_p^k$ extracted from them. The superpixels having both of these distances smaller than the respective average distances are selected. In the example illustrated in Fig. 2, a subset of P' = 9 out of the total P = 14 superpixels, are selected (denoted a with a red outline). The set of feature vectors extracted from these superpixels is denoted as $D_k = \\{d_1^k, ..., d_{P'}^k\\}$."}, {"title": "Step 2: Concept Mining", "content": "The feature vectors $D_k = \\{d_1^k, ..., d_{P'}^k\\}$, $k = 1 ... K$ extracted from each training image $I_k$ belonging to class f, are grouped into $M_f$ clusters, using a conventional clustering algorithm, such as the k-means. The clusters facilitate a higher-level representation of the image content incorporating conceptual information. The medoids of the clusters are used as a more compact representation of this information (dashed squares in Fig.3-step 2). The resulting medoids are denoted as $r_m$, $m = 1, ..., M$, where $M = \\sum_{f=1}^{F} M_f$. For each medoid $r_m$, a respective class vector $y_m = [y^1, y^2, ... y^f]$ is used to characterize its belongingness to a class, where $y^f \\in \\{0,1\\}$, and F is the total number of classes. Considering that the mined clusters with medoids $r_m$ represent concepts that exist in the input image, they will be considered as input concept nodes of the iFCM, which is constructed at a later step of this methodology (step 5). In Fig. 3 (step 2), images from three different classes (F = 3) are provided as an example, together with the features extracted from them during step 1. In this example, the medoids $r_1$ and $r_2$ correspond to class 1, $r_3$ and $r_4$ correspond to class 2, and $r_5$ and $r_6$ correspond to class 3."}, {"title": "Step 3: Similarity Calculation", "content": "In the third step of the training phase the similarity among the calculated medoids $r_m$, $m = 1, ..., M$ and the extracted set of feature vectors $D_k = \\{d_1^k, ..., d_{P'}^k\\}$, $k = 1 ... K$ from a training image $I_k$ is calculated as follows [26]\n$z_k(r_m) = \\sum_{p=1}^{P'} (1 - \\frac{||d_p^k, r_m||}{\\sum_{p=1}^{P'} ||d_p^k, r_m||})$\nwhere ||\u00b7|| is a distance metric, e.g., the Euclidean distance. The rationale of (10) is that it provides a normalized estimation of similarity, in the same way that a human recognizes and classifies objects based on comparisons with previous known, related prototypes [26]. This process is illustrated with an example in Fig.3 (step 3). The calculated similarities are then summed up and normalized within the interval [0, 1]. The resulting similarity vectors are depicted in the form of a histogram with their components appearing as color bars. Under each bin of these histograms a visual example of the respective medoid is provided. The different colors represent the three different classes included in the dataset."}, {"title": "Step 4: Intuitionistic Fuzzy Modelling", "content": "The fourth step includes the construction of IFSs linguistically characterizing the similarity of an input image with the images belonging to the target and other classes. The IFSs are modeled using a membership and a non-membership function. The membership function expresses the similarity of the feature vectors extracted from the input image with the medoids of the clusters derived from the training images of the class it belongs to. The non-membership function expresses the similarity of the feature vectors extracted from the input image with the medoids of the clusters derived from the images belonging to the other classes. More specifically, the membership functions $w^\\mu_h(z_k(r_m))$ of the IFSs, are created by considering the similarities between $r_m$ and $D_k$, calculated for the images $I_k$ belonging to the same class ($y_k = y_m$). The non-membership functions $w^\\mu_\\gamma(z_k(r_m))$ of the IFSs, are created by considering the similarities between $r_m$ and $D_e$ calculated from images $I_k$ belonging to different classes ($y_k \\neq y_m$). These IFSs are created by combining different fuzzy sets $B_m$, $e = 1, ..., E_b$, and $Q_m$, $e = 1, ..., E_q$ representing different degrees of membership and non-membership, respectively, as follows: initially the calculated similarities for the construction of $B_m$ are clustered into $E_b$ clusters, and the calculated similarities for the construction of $Q_m$ are clustered into $E_q$ clusters, using a conventional clustering algorithm, such as the k-means. The respective medoids $b_{m,e}$, $e = 1, ..., E_b$, and $q_{m,e}$, $e = 1,..., E_q$ obtained from this clustering process are used to construct fuzzy sets with membership functions defined in the universe of similarities [0, 1], topping at these medoids. An example is illustrated in Fig. 3 (step 4). It shows the construction of fuzzy sets $B_m$ using the similarities $z_k(r_1)$, $z_k(r_2)$ of $D_k = \\{d_1^k, ..., d_{P'}^k\\}$, $k = 1 ... K$ with $r_1$ and $r_2$ respectively, from the images belonging to the same class (\\\u0423\u043a(y\u00b9) = \u0423\u0442(y\u00b9), m = 1,2). Using the calculated medoids $b_1^1$, $b_1^2$, $b_1^3$ three fuzzy sets $B_1, B_2, B_3$ are defined. In this example triangular membership functions are used for simplicity; however, membership functions of other shapes, e.g., a Gaussian, are applicable. The membership functions are designed so that they top at these medoids (framed within a blue box in Fig. 3\u2013step 4). For the construction of $Q_m$, the similarities $z_k(r_1)$, $z_k(r_2)$ of $D_k = \\{d_1^k, ..., d_{P'}^k\\}$, $k = 1 ... K$ with $r_1$ and $r_2$ respectively, are calculated from images belonging to different classes ($y_k(y^1) \\neq y_m(y^1)$, f = 2,3, m = 1,2). The respective medoids $q_1^1$, $q_1^2$, $q_1^3$ are then used to construct $Q_1, Q_2,Q_3$, also considering membership functions of triangular shape (framed within a green box in Fig. 3-step 4). When using triangular functions, the intermediate triangles are extended to the nearest calculated centroid. Considering the non-membership functions, the intervals of the leftmost triangle extend to zero, corresponding to the \u201cHigh\u201d linguistic value, while the interval of the rightmost membership function is extended to one. Specifically, the rightmost triangle is transformed into a trapezoidal function with its right side extending to the nearest centroid [26] (Fig. 3-step 4). In addition, the fuzzy sets have to be defined in such a way to overlap covering the whole range [0,1], with no gaps. The overlap between the fuzzy sets aims to maintain continuity in the output.\nIn line with [15], the subset of pairs of fuzzy sets from $B_m \u00d7 Q_m$ that satisfy the conditions imposed by the definition of an IFS (Section II.B) are considered as pairs of membership and non-membership functions, generating a set of IFSs ($S_m$), defined as follows:\n$S_m = \\{z_k(r_m), w^\\mu_h(z_k(r_m)), w^\\mu_\\gamma(z_k(r_m))| z_k \\in [0,1]\\}$\nwhere q = 1, ..., \u03a6, and \u03a6 is the number of different generated IFSs."}, {"title": "Step 5: iFCM Construction", "content": "This step defines the structure of the iFCM model, including the determination of its concepts and relations. Unlike conventional FCMs, which require the participation of experts, the introduced framework embeds a learning algorithm for automatic determination of its structure and the weights of its interconnections based on the training dataset.\nConsidering the graph nodes of the iFCM, the nodes representing the input concepts represent the clusters with medoids $r_m$ of each examined class f = 1, ..., F (step 2, step 3), and the output concepts represent the different classes f = 1,..., F included in the training images of the dataset used. Figure 4 illustrates an iFCM model defined using the proposed framework, for the example of Fig. 3. The model contains six input concepts, i.e., $C_1$ - $C_6$, corresponding to the six clusters with medoids $r_m$, $m = 1, ... 6$ of that example, and three output concepts because the classification problem involves three classes (Fig. 3).\nThe influence between two related concepts $C_j$, $C_i$, $i \\neq j$,i,j = 1, ..., N, where N = M + F is the total number of concepts, is expressed by an IFS of the form $\\{\\{w^\\mu_h,w^\\mu_\\gamma\\}\\}_{ji}$. This IFS is created following the process described in step 4. Two types of relations can be distinguished: the relations between a) input-output concepts, and b) input concepts. Figure 5 illustrates subgraphs of the FCM shown in Fig. 4, to demonstrate the calculation of the weights of the interconnections between the concepts, which is detailed in the following paragraphs.\nRelations between input and output concepts. To define and linguistically characterize the influence between such concepts, IFSs $S_{ji} = \\{\\{w^\\mu_h,w^\\mu_\\gamma\\}\\}_{ji}$, are constructed as follows:\n$S_{ji} = \\cup_{m=1}^{\\Phi} S_m$\nwhere $S_m B_m \u00d7 Q_m$, m = 1, ..., M. The symbol \"$\\cup$\" represents the intuitionistic fuzzy union operation performed between $C_j$ and $C_i$, i, j = 1, ..., N, i \u2260 j. Based on [27], the intuitionistic fuzzy union operation is performed by aggregating the fuzzy sets $B_m$ (which are used for the definition of the IFS memberships) using the fuzzy union operation, and the fuzzy sets $Q_m$ (which are used for the definition of the IFS non- memberships) with the fuzzy intersection. The rationale behind using the intuitionistic fuzzy union operation comes from the process that occurs in the construction of conventional FCMs, where all expert opinions are taken into account to model the relations that exist between various factors in a given problem. In Fig.5, examples of such relations are $\\{\\{w^\\mu_h, w^\\mu_\\gamma\\}\\}_{17}$, $\\{\\{w^\\mu_h, w^\\mu_\\gamma\\}\\}_{18}$, $\\{\\{w^\\mu_h, w^\\mu_\\gamma\\}\\}_{19}$. Regarding $\\{\\{w^\\mu_h, w^\\mu_\\gamma\\}\\}_{17}$, where $C_1$ corresponds to the cluster with medoid $r_1$ of class 1 (f = 1), and $C_7$ represents the output concept class 1 (f = 1) (Fig. 4). To determine the relation between $C_1$and $C_7$, a set of IFSs ($\\breve{S}^\u03c6$, \u03c6 = 1, ..., \u03a6) where $\\breve{S}^\u03c6 B_1 \u00d7 Q_1$. The IFS corresponding to the relation between $C_1$ and $C_7$ is $S_{17}=\\{\\{w^\\mu_h, w^\\mu_\\gamma\\}\\}_{17}$ and is used to characterize linguistically the similarities $z_1(r_1)$ to $z_k(r_1)$ (framed in a blue box in Fig. 5).\nRelations between input concepts. To linguistically characterize the influences between the input concepts, respective IFSs are defined as follows:\n$S_{ji} = (\\cup_{m_i=1}^{\\Phi} S_{m_i}) \\cap (\\cup_{m_j=1}^{\\Phi} S_{m_j})$\nwhere $S_{m_i} B_{m_i} \u00d7 Q_{m_i}$ and $S_{m_j} B_{m_j} \u00d7 Q_{m_j}$, m = 1, ..., M, i, j = 1, ..., N, i \u2260 j. The symbol \u201c\u2229\u201d represents the intuitionistic fuzzy intersection operation performed between $C_j$ and $C_i$. The fuzzy sets $B_{m_i}, B_{m_j}$ are aggregated, using the fuzzy union operation, while for the fuzzy sets $Q_{m_i}$ and $Q_{m_j}$ the fuzzy intersection is used, resulting in $U_{m_i=1}^{\\Phi} S_{m_i}$ and $U_{m_j=1}^{\\Phi} S_{m_j}$. Based on [27], the intuitionistic fuzzy intersection operation is performed by aggregating the resulting IFSs, as shown in (13). The rationale behind using the fuzzy intersection is that it represents the consensus among expert opinions that exist when determining the relations in the conventional FCMs. In Fig.5 indicative examples of such relations are $\\{\\{w^\\mu_h, w^\\mu_\\gamma\\}\\}_{21}$, $\\{\\{w^\\mu_h, w^\\mu_\\gamma\\}\\}_{23}$. Regarding $\\{\\{w^\\mu_h, w^\\mu_\\gamma\\}\\}_{23}$, $C_2$ corresponds to the cluster with medoid $r_2$ of class 1 (f = 1),"}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "To evaluate the performance of I\u00b2FCM, the following publicly available benchmark datasets were used:\na) Caltech 101 [29] contains 9,144 images of 102 different classes. Each class includes 33 to 800 images, and the size of the images on average is 300 \u00d7 200 pixels. For the experiments, 30 randomly selected images from each class of the dataset were used as the training set while the rest images formed the test set.\nb) Caltech 256 [30] consists of 30,607 images, illustrating 256 different object classes with at least 80 images in each class. The images of the dataset have an average resolution of 300 \u00d7 250 pixels. For the evaluation, 60 randomly selected images from each class composed the training set, and the rest of them are used for testing.\nc) 15-Scenes [31] includes 200 to 400 images of 15 classes with an average resolution of 300 \u00d7 250 pixels. A set of 100 images was used for training and the rest of them for testing.\nThe feature extraction process (step 1) was performed using VGG-16 model pretrained on ImageNet [32]. The clustering process was implemented using the k-means algorithm [33] with Euclidean distance, as a baseline clustering algorithm commonly used in related methods [26]. The range of the number of clusters in k-means tested using grid search was [5, 50], and the range of number of fuzzy sets tested using grid search was [5, 15]. The fuzzy sets were implemented using Gaussian membership functions. In addition, the number of iFCM input concepts ranged from 2 to 15, and the number of output concepts were defined according to the number of classes included in the dataset used. The hesitancy values of the iFCM concepts were initially set to 0. Furthermore, the hyperbolic tangent (tanh) was used in as a transfer function in $\\{\\{\u03b2_\\mu^s, \u03b2_\\gamma^s\\}\\}_{ys}$ of (6)-(7)."}, {"title": "B. Classification Performance", "content": "The performance of I\u00b2FCM, was compared with both state-of- the-art and conventional machine learning models in terms of classification accuracy. Comparisons were performed with the following models: a) VGG-16 [34], b) VGG-19 [34], c) GoogleLeNet [35], d) ResNet-101 [36], e) ResNet-50 [36], f) Directed Acyclic Graph (DAG)-CNN [37], g) k-Nearest Neighbors (k-NN) algorithm [38] as well as relevant state-of- the-art interpretable models: a) DMR [5], b) xDNN [4], c) H- DRB [7], d) DRB [6], and e) xFCM [13]. It should be noted that the presented comparisons are based on results reported in the literature and all experiments were performed based on settings and guidelines used in the respective studies.\nThe results are summarized in Tables II-III, where the interpretable classification methodologies are underlined. It can be noticed that I2FCM outperforms most of the compared models in terms of the classification accuracy on all datasets. It is worth noting that I2FCM outperforms all non-interpretable models. More importantly, comparing its classification performance with that of the original VGG-16 network, it becomes evident that its use enhances the classification of the same feature vectors (since VGG-16 is used for feature extraction in step 1 (section III). Some of the compared interpretable methods in Table II perform somewhat better than I2FCM; however, as noted in Table I, the latter has the advantage of providing interpretations that include semantically relevant details about image contents. To further highlight this aspect, the following subsection provides an analysis of the interpretability of IFCM with a specific example."}, {"title": "C. Interpretability Analysis", "content": "Let us consider a test input image, which depicts a flamingo from the Caltech-101 dataset. According to step 1 of the proposed framework feature vectors D are extracted from K = 9 selected superpixels. The iFCM model constructed in step 5 of the training process consists of a total of M = 8 input concepts are used, which are the following: C\u2081: \"Rhino-head\", C2: \"Rhino-body\", C3: \u201cKangaroo-head\u201d, C4: \u201cKangaroo- body\", C5: \"Flamingo-head\", C6: \"Flamingo-body\", C\u2087: \"Llama-head\", Cg: \"Llama-body\". The output concepts represent the corresponding F = 4 classes that are: C9: \"Rhino\", C10: \"Kangaroo\", C11: \"Flamingo\", and C12: \"Llama\u201d. The iFCM model has relations between all input concepts, as well as relations between input and output concepts. To simplify its representation in Fig. 7(a) only a subset of the relations is depicted. The fuzzy sets corresponding to the linguistic values of the influences between its concepts are illustrated in Fig. 7 (b).\nThe initial state vector of the input image is calculated (after steps 2 and 3) and is utilized as input to the iFCM model. Then, the iFCM iteratively calculates its concept values, until it reaches a steady state, in t = 12 iterations, using (6)-(8). The convergence of the output concepts of the iFCM model, in terms of its membership and hesitancy values, is illustrated in Fig. 6. Also, the results of the image classification after t = 12 iterations, are presented in Fig. 7(d). In this figure, green bars represent membership, blue bars represent non-membership, and yellow bars represent the respective hesitancy values. It can be observed that in all cases, the non-membership values reach zero at the steady state. This is due to the reasoning performed using (7) [16]. Thus, the initial non-membership values do not practically affect the final decision. The hesitancy values are decreased for the iFCM nodes containing parts characterizing the class to which the image belongs to. In this example nodes C5, C6 contain parts characterizing the class and C11: \"Flamingo\" (Fig. 7(d)). In case an image belongs to a certain class with high similarity with the corresponding concepts, the membership function tends to 1, while the non- membership and hesitancy values tend to 0. The low degree of hesitancy confirms the validity of the decision.\nTo summarize, the explanation about the classification outcome for the test input image, after t = 12 iterations, is the following:\n\u2022 The input image is classified as \"Flamingo\" because it has (a) Very High similarity with Very Low hesitancy with C5 =\"Flamingo-head\"; (b) Very High similarity with Very Low hesitancy with C\u2086 = \u201cFlamingo- body\u201d.\n\u2022 The input image cannot be classified as \u201cRhino\u201d because it has (a) Low similarity with a Very High hesitancy with C\u2081: \"Rhino-head\", and (b) High similarity with Very High hesitancy with C\u2082: \"Rhino- body\u201d.\nThe high degree of similarity, i.e., membership value, in the latter case can be explained by the fact that the extracted features vectors $d^{10}, d^{12}, d^{15}$ corresponding to the background of the image (Fig. 7(a)), have a similar visual content with C\u2082 that represents the \"Rhino-body\". More specifically, as illustrated in the figure, in the test image there are regions of dark blue in the background, which are similar to the body of rhino.\nRegarding the relations of iFCM for the image classification problem under consideration, the following conclusions can be derived: for the membership values there is a positive causality (whereas for the non-membership values there is a negative causality) between:\n(a) input and output concepts that are related to the same class. For example, there is a positive relation between C\u2081 and C\u2082, representing \"Rhino-head\u201d and \u201cRhino- body\u201d, respectively. This means that as the similarity of the extracted features from the test input image with the representative features depicting \"Rhino-head\" increases, there is also an increase to the similarity with \"Rhino-body\u201d.\n(b) input and output concepts related to the same class. For example, Fig. 7 (a) shows that there is a positive influence of the input concepts C\u2081 and C\u2082, with the output concept C\u2089, belonging to the class \u201cRhino\u201d.\nIn addition, there is a negative causality in the membership values (whereas there is a positive causality in the non- membership values), among:\n(a) the input concepts related to different classes.\n(b) the input and output concepts representing different classes."}, {"title": "V. DISCUSSION AND CONCLUSIONS", "content": "In this paper, a novel framework named I\u00b2FCM is introduced. The proposed framework constructs iFCM models for interpe- table image classification, and to the best of our knowledge it is the first iFCM-based approach applied in the context of image analysis. The main characteristic of iFCMs is their natural mechanism to assess the quality of their output through the estimation of hesitancy.\nThe application of I\u00b2FCM on well-known benchmark datasets showed that it is competitive to state-of-the-art in terms of classification performance, while providing meaningful explanations. Compared to the rest interpretable models, i.e., DMR [5], xDNN [4], HDRB [7], DRB [6], enables the user to monitor the decision-making process while at the same time explaining the result obtained at each iteration, in an understandable way, using the causality existing among the graph nodes. In this way, it strengthens the confidence of the user, and makes the framework useful and suitable to be implemented in highly sensitive areas, including healthcare [1]. Furthermore, compared to xFCM [13], the proposed I2FCM framework enables the image interpretation based on local visual content captured by selective superpixel-based spatial sampling of image regions.\nIn addition, the proposed framework defines iFCMs that are able to distinguish representative semantics among various image classes, and their cause-and-effect relations. The evaluation of the iFCM using publicly available benchmark datasets indicated its superiority over other state-of-the-art methods, including interpretable ones."}]}