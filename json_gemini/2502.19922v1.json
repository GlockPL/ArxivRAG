{"title": "Incremental Learning with Repetition via Pseudo-Feature Projection", "authors": ["Benedikt Tscheschner", "Eduardo Veas", "Marc Masana"], "abstract": "Incremental Learning scenarios do not always represent real-world inference use-cases, which tend to have less strict task boundaries, and exhibit repetition of common classes and concepts in their continual data stream. To better represent these use-cases, new scenarios with partial repetition and mixing of tasks are proposed, where the repetition patterns are innate to the scenario and unknown to the strategy. We investigate how exemplar-free incremental learning strategies are affected by data repetition, and we adapt a series of state-of-the-art approaches to analyse and fairly compare them under both settings. Further, we also propose a novel method (Horde), able to dynamically adjust an ensemble of self-reliant feature extractors, and align them by exploiting class repetition. Our proposed exemplar-free method achieves competitive results in the classic scenario without repetition, and state-of-the-art performance in the one with repetition.", "sections": [{"title": "1. Introduction", "content": "As autonomous agents and models in production systems are exposed to continuous streams of information, they are required to adapt to dynamic data distributions with potentially multiple tasks and integrate new information over time. The practice of retraining the complete system whenever new data is available becomes unfeasible as the storage, computation and privacy constraints for data streams increase. To address these constraints, incremental learning (IL) or continual learning has emerged as a promising approach.\nIL aims to learn a model sequentially through a sequence of tasks introducing disjoint sets of information at each training step. Generally, these scenarios enforce a strict no-repetition constraint allowing access to the data distribution only once in the task sequence. Unlike humans, who can learn nearly inference-free between tasks, neural networks suffer from a phenomenon called catastrophic forgetting. When models are optimized sequentially on novel tasks, a swift forgetting of previously learned tasks is observed. To mitigate this forgetting, a delicate balance between preserving learned task knowledge (stability) and the ability to adapt to new information (plasticity) has to be reached, which is known as the stability-plasticity dilemma. A popular approach to address this is to cache a representative subset of previously encountered data points in a buffer and replay them during the following training sessions.\nAlthough such rehearsal addresses catastrophic forgetting effectively, data privacy concerns have been raised, and the scalability of an exemplar buffer in long-tailed incremental sequences is questionable due to the large computational cost of complete retraining and significant storage requirements.\nNonetheless, the strict enforcement of no-class repetition becomes unrealistic for many real-world applications, as continuous streams are bound to repeat certain information or be affected by semantic or covariate shifts. For example in industrial defect detection, certain common defects and defect-free samples will repeat throughout production. The occurrence of repetition is further amplified in environments where an agent has the freedom to reexperience elements which are contained within the overall environment design. Thus the effects of catastrophic forgetting are likely exaggerated as an uncontrollable form of rehearsal occurs naturally. Previous incremental learning research has largely explored catastrophic forgetting under the assumption that new information has a single opportunity to be learned, since each class is only available within a single task throughout the sequence. The introduction of repetition into these scenarios enables the selection of more broad incremental training tasks and highlights the different dynamics within the plasticity-stability dilemma of learning new tasks while maintaining current knowledge. The focus on catastrophic forgetting without repetition may limit the development of more realistic incremental learning agents, which involve different complex objectives like forward transfer and efficiency for computational limitations in edge devices.\nAs such, we want to loosen the no-repetition constraint and explore the effects of natural repetition. To explore these new settings and effects, our contributions are:\n1. a new variation of the class-incremental learning"}, {"title": "2. Related Work", "content": "Class-incremental learning (CIL) addresses the challenge of training a model sequentially on a series of tasks, without access to previous or future data. When training without any constraints, models fail to retain knowledge from previous tasks a problem known as catastrophic forgetting. Usually, each incremental task contains a disjoint set of new classes, which increases the difficulty of discriminating between those which have not been learned together under the same task. A key challenge in incremental learning lies in keeping the balance of the stability-plasticity dilemma, critical for mitigating catastrophic forgetting while ensuring the adaptability of the model to new tasks.\nIncremental learning approaches include: weight regularization, which preserves important weights by estimating their importance; knowledge distillation, which focuses on protecting task representations rather than weights; rehearsal, which replay stored exemplars from previous tasks; mask-based approaches, which use task-specific masks to isolate parameters that can be updated; and dynamic network structures, which expand the model architecture by adding new or contracting existing modules for each task. In this work, we concentrate on weight-regularization, knowledge distillation and dynamic network structure-based methods. These are the approaches that work on task-agnostic scenarios (do not require a task-ID during inference) and promote privacy preservation (do not store samples).\nIncremental learning with repetition. In many practical applications (automated failure inspection, medical imaging, robotics), pattern repetition naturally arises, yet traditional CIL approaches assume that each class is encountered only once, imposing a strict no-repetition constraint. This constraint focuses on the prevention of catastrophic forgetting but also diverges from real-world scenarios where classes may reappear or shift over time. To address this, Hemati et. al propose an extension to the class-incremental learning scenario which models the repetition of individual classes outside of a single task. Unlike joint incremental or rehearsal-based learning, this repetition is innate to the learning scenario and cannot be adjusted. This emphasizes an experience-based scenario, which favours shorter training tasks that can sometimes only cover a part of the class distribution. Moreover, covering scenarios that lie between the classic offline incremental and the online ones.\nClass-incremental learning with repetition has received increased interest in the research community, being a central element in the challenge tracks of the last two CLVISION challenge tracks at CVPR 2023 and 2024. In the 2023 edition, we competed with a base variant of our proposed method, although without elements for controlling ensemble growth (see Sec. 3.1), self-supervision (see Sec. D) or applicability to variable network architectures.\nClass prototypes and pseudo-features. To enforce stability and alleviate class-recency biases in the classifier, Exemplar-Free Class Incremental Learning (EFCIL) methods utilize class prototypes to simulate unavailable classes. These prototypes capture statistical properties of embedding representations of each class, which are usually modeled as a multivariate Gaussian distribution. Specifically, the statistics typically include the mean and covariance of feature representations for each class, allowing to generate pseudo-features when class data is not available. To extract representations, the neural network is divided into two modules. A feature extractor (FE) that projects the input samples into their corresponding embedding representation; and a classifier head that uses these embeddings to solve the classification task. Therefore, prototype-based methods can generate embeddings even when no samples from past classes are available during subsequent tasks by sampling the stored distributions of each class. The sampled embedding representations are rehearsed alongside the current task data, thus promoting stability and mitigating class-recency bias. However, in order to maintain valid approximations of class distributions, the feature extractor needs to be either frozen or heavily regularized to prevent changes or drifts in the extracted features. Unlike rehearsal-based approaches, the use of prototypes does not violate data privacy due to the non-linearly projected representation in the embedding space.\nFeature translation. Instead of sampling the distribution approximated by class prototypes, FeTrIL proposes to translate the features of available data classes to unavailable ones directly. Given a feature extractor $f(x; \\theta)$ being trained on current data $\\{(x_i, Y_i)\\}$, its output embedding $F$ is efficiently translated from one of the current"}, {"title": "3. Method", "content": "In incremental learning scenarios with repetition, the reappearance of classes introduces uncertainty in task sequences, requiring strategies that handle dynamic class distributions. Our approach aims to: (a) capture information from the current task, (b) integrate it with knowledge from previously seen tasks, and (c) ensure the ability to discriminate between all encountered classes so far. To achieve this, we leverage zero-forgetting feature extractors (FEs), which are aggregated in an ensemble to overcome the limitation of a completely fixed feature space. Through this aggregation, we form a flexible feature representation space that can adapt (expand or contract) based on the incremental learning sequence (see Fig. 1 for an overview of the proposed method structure).\nTo effectively utilize this dynamic embedding space, we address the challenge of missing classes by constructing prototypes for all encountered classes. Class prototypes are used to train a unifying classification layer through an adjusted feature translation mechanism, termed pseudo-feature projection, ensuring continuous adaptation and robust performance across all classes. Concretely, the learning approach is divided into two steps: (1st) based on the difficulty of the current task and depending on how well new classes can fit into the ensemble embedding space, the ensemble is expanded with a new feature extractor (described in Sec. 3.1); (2nd) once the embedding space has been fixed for the current task, class prototypes are extracted and the unified classification layer is trained through the pseudo-feature projection (described in Sec. 3.2). These steps are performed for every incremental task and are summarized in Figure 2.\n#### 3.1. Feature Extractor Ensemble\nThe proposed aggregation framework consists of multiple individual feature extractors (FEs), each trained on a specific task and then frozen to preserve the learned representations. The motivation for this zero-forgetting strategy is to enforce stability, avoiding any catastrophic forgetting on the ensemble while providing some plasticity through the extension of the ensemble. Unlike FeTrIL, which freezes a single feature extractor after the initial training, the extension of the feature space through the ensemble relieves the dependence of an expressive initial feature extractor. The goal of each feature extractor is to build a diverse and expressive feature space that emphasizes high-quality representations rather than optimizing the performance of the individual incremental task. Further, we adopt the self-learning loss from PASS [47]. This self-learning loss enhances the learned feature representation by simultaneously classifying image orientation and categories (each image class now has 4 augmented labels depending on the image orientation). To further improve regularization on the feature space topology, we incorporate a metric learning head with contrastive loss and hard-negative mining. This promotes spherical-shaped clusters in the embedding space, which improves class discrimination between known and unknown distributions. Additionally, the sphere-shaped structure aligns well with the properties of a multivariate Gaussian distribution, which relates to the pseudo-feature projection we propose. An ablation study of the effects of individual components is provided in the supplementary material (see Sec. D).\nEnsemble Growth. To control the growth of the ensemble, we set a predefined budget B for the maximum number of FEs. For each incremental task, a decision is made whether the concatenated embedding space should be adjusted based on the following criteria:\n*   constant feature representation: when the current ensemble embedding representation is sufficient to handle the incremental task, no new FE is trained. New classes are learned using the existing ensemble representations without requiring additional feature extraction capacity.\n*   dynamic feature adaption: when the current ensemble of FEs cannot adequately represent the new task due to a significant change in the data distribution, task complexity or overlap with previous classes, a new FE is added.\nTo capture these criteria and guide the growth of the ensemble, we propose two heuristics to guide the modification of the ensemble (see Step 1 in Fig. 2a):\n*   Class Set Maximisation (Hordem): this heuristic aims to maximize the diversity of classes represented across the ensemble. Specifically, it ensures that each FE contributes to representing as much of a distinct set of classes as possible\n$\\max \\bigcup_i l_c \\in F_i,$\n$i\\in B$\n\nthereby increasing the overall coverage of the class space across all feature extractors. This maximization is tested at the start of each incremental task. Thus, when a larger class set is possible with the current incremental task data, a new FE is trained. The new FE either is added or replaces one in the ensemble.\n*   Task Error Rate (Horde): At the start of the incremental task, the error rate $e$ on the current incremental data is computed (before training). It is obtained from the confusion matrix (CM) by calculating the ratio of wrong predictions over all other predictions:\n$e = (\\frac{1}{C} \\sum_i( \\frac{\\sum_{j\\neq c} CM_{c,j}}{\\sum_i CM_{c,i}}))$\n\nIf $e$ is too high, the incremental data cannot be classified with the current ensemble effectively. Therefore, we introduce a threshold or budget of the ensemble $B$ which signals the need to train a new feature extractor based on $e$. After training the unified head (Step 2), an improvement score is calculated as the difference between the error rate at Step 1 (before any training is performed) and after Step 2. If the budget $B$ has been exceeded the FE with the lowest improvement score is replaced.\n#### 3.2. Unified Classification Layer\nTo unify the feature representations from the ensemble and enable task-agnostic classification, we utilize a fully-connected layer. This layer has dynamic input and output sizes depending on the growth of the ensemble and the number of incrementally learned classes. To mitigate task-recency bias, we train this unified head using both data from the current task and projected class prototype features through our proposed pseudo-feature projection.\nPseudo-feature projection. Pseudo-feature projection, inspired by FeTrIL, extends feature translation by incorporating both the mean and standard deviation of class prototypes. This enhances the sampling of dimensions, reduces the chance of overlapping classes in the embedding space and leads to more accurate feature replay. With this projection, a data point from one class may be projected to a pseudo-feature representation of any other previously learned class. Our proposed projection extends the one from FeTrIL on Eq. (1) as\n$F_c = \\mu_c + \\frac{f(x_i;\\theta) - \\mu_{y_i}}{\\sigma_{y_i}}. \\sigma_c,$\n\nwhere $F$ represents the pseudo-features of the latent representation of a data point $(x_i, y_i)$ which is projected from the original class $y_i$ to the desired class $c$. This transformation leverages the class prototypes; specifically the mean $\\mu_y$ and standard deviation $\\sigma_y$; to modify the latent representation $f(x_i; \\theta)$. Class prototypes are updated during Step 2, before training the unified classification layer and after the ensemble has been adjusted.\nWe represent a complete class prototype as the concatenation of the individual class statistics from each FE in the ensemble:\n$\\mu_c = (\\mu_{c,1}, ..., \\mu_{c,n}),$\n$\\sigma_c = (\\sigma_{c,1}, ..., \\sigma_{c,n}),$\n\nwhere $n$ determines the current size of the ensemble. Throughout the incremental sequence, the ensemble can be expanded until the feature extractor budget is exhausted $(n \\le B)$. Once this limit has been reached, individual feature extractors need to be finetuned or replaced and their corresponding class prototype $(\\mu_{c,i}, \\sigma_{c,i})$ is reset.\nClass prototypes of certain classes may be incomplete for newly added or modified FEs. When class statistics are unknown for a specific FE, estimates are required for pseudo-feature projection to calculate $\\hat{\\mu}_{c,f}$ and $\\hat{\\sigma}_{c,f}$. In the absence of statistical information, we fix the standard deviation to $\\hat{\\sigma}_{c,f} = 1$. This decision is based on the fact that the estimation of $\\hat{\\mu}_{c,f}$ already provides sufficient variance. Therefore, for the estimation of the mean component $l_{c,f}$ we propose three heuristics:\n1.  zeros: clamping all $\\hat{\\mu}_{cf}$ estimations to 0\n$\\mu_{c,i} = 0,$\n\n2.  random: randomly sample $\\hat{\\mu}_{e,f}$ from a multivariate normal distribution\n$\\mu_{c,i} \\sim N(0;\\Sigma),$\n\n3.  original features: estimate $\\hat{\\mu}_{c,f}$ with the original representation of the transforming sample and use them without modification\n$\\mu_{c,f} = f(x_i; \\theta) .$"}, {"title": "4. Experimental Setup", "content": "Most incremental learning methods expect a different set of classes with all dataset samples for each class available when learning its corresponding task. However, when class repetition is introduced, the complexity of potential scenarios increases significantly, and where sequence length and repetition frequency become additional variables. To address this, we propose an analysis into the effects of class repetition within a setting that shares many characteristics of traditional incremental learning but incorporates longer sequences with class repetition. Code for the proposed scenarios and methods is available\u00b9.\nOverall, the proposed experiments aim to analyze a) the performance of IL methods in scenarios without repetition (baseline), b) the performance of CIL with small incremental tasks and class repetition, and c) the resilience of the methods against bias deviations in repetition frequency.\nIdeally, we expect the average accuracy of our proposed method to be on par with state-of-the-art methods"}, {"title": "4.1. Compared Methods", "content": "We benchmark a total of 14 methods, which include two rehearsal-based approaches, five incremental learning methods, five state-of-the-art exemplar-free class-incremental learning (EFCIL) methods, and two variants of our proposed approach. The two rehearsal-based methods are excluded from the ranking and serve as an upper baseline (Joint ) and a reference point (Weight-Alignment (WA); n = 2000).\nThe five incremental learning methods consist of two baseline methods (Freezing (FZ) and Finetuning (FT)), and three classic IL methods Elastic Weight Consolidation (EWC), Memory Aware Synapses (MAS) and Learning without Forgetting (LWF). These three methods were not originally proposed for CIL, thus, requiring the use of a task-ID at inference time. However, they are easily and commonly adaptable to task-agnostic settings. As such, we performed a grid search for their optimal hyperparameters based on the CIL 50/10 setting and used these for the repetition settings.\nThe five state-of-the-art, rehearsal-free, protoype-based methods comprise: Prototype Augmentation and Self-Supervision (PASS), Class-Incremental Learning with Dual Supervision (IL2A), Self-Sustaining Representation Expansion (SSRE), Prototype Reminiscence and Augmented Asymmetric Knowledge Aggregation (PRAKA) and Feature Translation for Exemplar-free Class Incremental Learning (FeTrIL).\nThese methods were originally reported on the CIL CIFAR 50/10 setting. Therefore, since the proposed repetition scenarios are closely related to this setting, we use the hyperparameters proposed by the original authors.\nFinally, we evaluate our proposed method with both ensemble growth heuristics (Hordem and Hordec). A de-"}, {"title": "4.2. Model Architecture", "content": "All methods employ the same base feature extractor, a ResNet-18 model that has been adjusted to the CIFAR input dimensions. For our approach, which utilizes an ensemble of feature extractors, we employ a slimmed-down variant of ResNet-18 for incremental tasks. This variant reduces the number of channels/filters for convolutions while preserving the network's depth (see supplementary material Sec. B). With this reduced architecture, we construct an ensemble consisting of one full ResNet-18 and nine Slim-ResNet-18 models (making our budget B=10). This configuration results in a total number of parameters and computational requirements (see Table 2) that are roughly equivalent to those of knowledge distillation approaches (or importance weight estimation )."}, {"title": "4.3. Scenarios", "content": "Experiments are conducted on the CIFAR-100 dataset, employing data augmentation in line with other CIL methods. These augmentations consist of a 4-pixel zero padding of the input image and a random cropping to the original 32 \u00d7 32 size. Followed by a random horizontal flip, image brightness jitter and image normalization.\nTo evaluate the effects of repetition on CIL methods, we organize the experiments in three scenarios. First, a baseline is established by evaluating (a) all methods on an incremental learning scenario without repetition.\n(a) CIL 50/10. The classic task-agnostic class-incremental scenario consisting of an initial training session with 50 classes and followed by 10 incremental tasks, each containing five novel classes.\nSecond, we evaluate (b) performance on a modified CIL scenario where classes repeat in the task sequence. Specifically, the scenario is built by replacing the discrete incremental tasks with clear boundaries from CIL 50/10 with small (2,000 training samples per task) incremental tasks that can contain class repetition. Each class, old or new, has the same probability of being in an incremental task.\n(b) EFCIR-U 50/100. Similarly to the CIL 50/10 scenario, the initial training also covers 50 classes. An essential element of repetition is a mixture of new and already seen samples. Therefore, we only provide 50% of the available training data samples for the initial training. Following the initial task, the scenario consists of 99 small, incremental tasks, with a limit of 2,000 training samples each. Both the initial 50 and incremental 50 classes have a fixed probability of 15% of being discovered or repeated in an incremental task so that tasks do not contain too many classes on average. The number of samples per class in a task are balanced as in the CIL 50/10 scenario. In the third scenario, the aim is to assess the IL method's (c) resilience against biases in repetition frequency. To establish this bias during scenario creation we propose to draw the repetition probability of each class from a Beta Distribution. An illustration of the repetition bias is provided in the supplementary material Sec. E.\n(c) EFCIR-B 50/100. To test the resiliency against repetition frequency, we sample individual class repetition probabilities $p \\sim Beta(\\alpha, \\beta)$ with parameters $\\alpha = 3.5$ and $\\beta = 20.0$. This way, the expectation $E[Beta(3.5, 20.0)] \\approx 0.15$ is similar to the uniform EFCIR-U scenario, implying that on average the same number of classes are present in each task.\nIn scenarios with repeated classes, the optimal learning rate and number of epochs depend on various factors (e.g. method, number of training samples, length of incremental sequence) and are highly influential. To address this, we split 10% of the available training data as a validation set. For all methods, we apply early stopping using this validation data for the classes present in the task. We monitor the validation loss (including regularization and auxiliary losses of the method) and allow for a patience period of 5 epochs. If no improvement is observed, we perform a learning rate decay step. Each decay step reduces the learning rate by a factor of 0.1, the model weights are reset to the best checkpoint before patience, and we do not perform more than 2 decay steps.\nEvaluation. All scenarios are ranked by the average accuracy achieved over the complete task sequence. Average accuracy is calculated by evaluating the model on the CIFAR test set based on the classes that have been seen up to each task. Complementary to the average accuracy, average forgetting is also reported, which measures the drop in accuracy over the task sequence. Experimental results are averaged over 5 seeds."}, {"title": "5. Results", "content": "The summarized results of the experiments are listed in Table 3. Detailed plots and tables of the accuracy progression for all methods in each proposed scenario are provided in the supplementary material (Sec. G).\nScenario (a) CIL 50/10. The conducted baseline experiment confirms the reported results from other works . We observe a significant performance gain of approximately 10-15% in average accuracy over the task sequence when comparing the state-of-the-art rehearsal-free (EFCIL) methods with EWC, MAS and LwF. While our proposed method is particularly designed towards repetition scenarios, where the estimation of class prototype components is not always required, it remains competitive in disjoint, no-repetition scenarios as well, showing comparable performance to the best EFCIL methods .\nScenario (b) EFCIR-U. Introducing class repetition in small incremental tasks into the scenario leads to significant performance differences. Weight-regularization approaches and vanilla finetuning typically underperform compared to knowledge distillation or class prototype-based approaches in EFCIL . However, in this scenario with repetition, we observe greatly improved performance for FT, EWC and MAS. The results for these methods surpass even the results from the CIL 50/10 scenario by leveraging data repetition effectively (see Fig. 3). In contrast, EFCIL methods (PASS, IL2A, SSRE, PRAKA) that rely on both class prototype rehearsal and knowledge distillation show a performance degradation under repetition. This decline is not observed in methods that use either knowledge distillation (LwF) or class prototype rehearsal with frozen feature extractors (FeTrIL, Ours).\nWe hypothesize that the estimation of class prototypes with incomplete class data distribution in the former methods leads to a suboptimal feature embedding space, which is then propagated through the incremental task sequence via knowledge distillation. Frozen feature extractors, on the other hand, avoid this issue since their representations remain fixed after the initial training, preventing catastrophic drift in the embedding space during the task sequence. This raises the question whether the assumption that the complete training data distribution of an individual class as in traditional class-incremental learning - is a realistic assumption for continual learning scenarios.\nOur ensemble-based approach (Horde), with both en-"}, {"title": "6. Conclusion", "content": "In this work, we conducted an exploratory evaluation of CIL methods in exemplar-free class-incremental learning with repetition scenarios and investigated their resiliency to biases in the repetition frequency of classes.\nIn the evaluated repetition scenarios, EFCIL methods that rely on class prototypes (PASS, PRAKA, IL2A, SSRE) severely underperform and are unable to benefit from the repetition of classes. Notably, weight-regularization-based approaches perform exceptionally well in repetition scenarios provided that training with cross-entropy is restricted to the classes present in each task, thereby mitigating the risk of class-recency bias in the classification head. The results from the repetition frequency bias from a beta distribution show only minimal performance differences, with either no effect on average accuracy or a slight drop of up to 2%. Thus, a bias in repetition frequency alone without a biased sample distribution within a training task is insufficient for significant classification bias.\nFurthermore, we introduce a novel ensemble learning technique that takes advantage of class repetition. This method combines a dynamic set of independent feature extractors, which are aligned through a unified head in a process we call pseudo-feature projection. The proposed method demonstrates competitive performance in traditional no-repetition settings and establishes a new state-of-the-art for scenarios with repetition."}]}