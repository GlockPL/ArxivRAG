{"title": "Incremental Learning with Repetition via Pseudo-Feature Projection", "authors": ["Benedikt Tscheschner", "Eduardo Veas", "Marc Masana"], "abstract": "Incremental Learning scenarios do not always represent real-world inference use-cases, which tend to have less strict task boundaries, and exhibit repetition of common classes and concepts in their continual data stream. To better represent these use-cases, new scenarios with partial repetition and mixing of tasks are proposed, where the repetition patterns are innate to the scenario and unknown to the strategy. We investigate how exemplar-free incremental learning strategies are affected by data repetition, and we adapt a series of state-of-the-art approaches to analyse and fairly compare them under both settings. Further, we also propose a novel method (Horde), able to dynamically adjust an ensemble of self-reliant feature extractors, and align them by exploiting class repetition. Our proposed exemplar-free method achieves competitive results in the classic scenario without repetition, and state-of-the-art performance in the one with repetition.", "sections": [{"title": "1. Introduction", "content": "As autonomous agents and models in production systems are exposed to continuous streams of information, they are required to adapt to dynamic data distributions with potentially multiple tasks and integrate new information over time [3, 28, 43]. The practice of retraining the complete system whenever new data is available becomes unfeasible as the storage, computation and privacy constraints for data streams increase [31, 35, 39]. To address these constraints, incremental learning (IL) or continual learning has emerged as a promising approach [4].\nIL aims to learn a model sequentially through a sequence of tasks introducing disjoint sets of information at each training step [8, 27, 42]. Generally, these scenarios enforce a strict no-repetition constraint [7] allowing access to the data distribution only once in the task sequence. Unlike humans, who can learn nearly inference-free between tasks, neural networks suffer from a phenomenon called catastrophic forgetting [10, 12]. When models are optimized sequentially on novel tasks, a swift forgetting of previously learned tasks is observed. To mitigate this forgetting, a delicate balance between preserving learned task knowledge (stability) and the ability to adapt to new information (plasticity) has to be reached, which is known as the stability-plasticity dilemma [29]. A popular approach to address this is to cache a representative subset of previously encountered data points in a buffer and replay them during the following training sessions [38, 41, 42]. Although such rehearsal addresses catastrophic forgetting effectively, data privacy concerns have been raised [14], and the scalability of an exemplar buffer in long-tailed incremental sequences is questionable [42] due to the large computational cost of complete retraining and significant storage requirements.\nNonetheless, the strict enforcement of no-class repetition becomes unrealistic for many real-world applications, as continuous streams are bound to repeat certain information [7] or be affected by semantic or covariate shifts [30]. For example in industrial defect detection, certain common defects and defect-free samples will repeat throughout production. The occurrence of repetition is further amplified in environments where an agent has the freedom to reexperience elements which are contained within the overall environment design. Thus the effects of catastrophic forgetting are likely exaggerated as an uncontrollable form of rehearsal occurs naturally. Previous incremental learning research has largely explored catastrophic forgetting under the assumption that new information has a single opportunity to be learned, since each class is only available within a single task throughout the sequence. The introduction of repetition into these scenarios enables the selection of more broad incremental training tasks and highlights the different dynamics within the plasticity-stability dilemma of learning new tasks while maintaining current knowledge [7]. The focus on catastrophic forgetting without repetition may limit the development of more realistic incremental learning agents, which involve different complex objectives like forward transfer [24] and efficiency for computational limitations in edge devices [9].\nAs such, we want to loosen the no-repetition constraint and explore the effects of natural repetition. To explore these new settings and effects, our contributions are:\n1. a new variation of the class-incremental learning"}, {"title": "2. Related Work", "content": "Class-incremental learning (CIL) addresses the challenge of training a model sequentially on a series of tasks, without access to previous or future data [36]. When training without any constraints, models fail to retain knowledge from previous tasks a problem known as catastrophic forgetting [10, 12]. Usually, each incremental task contains a disjoint set of new classes, which increases the difficulty of discriminating between those which have not been learned together under the same task [8]. A key challenge in incremental learning lies in keeping the balance of the stability-plasticity dilemma [29], critical for mitigating catastrophic forgetting while ensuring the adaptability of the model to new tasks.\nIncremental learning approaches include: weight regularization [2, 20], which preserves important weights by estimating their importance; knowledge distillation [18, 22], which focuses on protecting task representations rather than weights; rehearsal [38], which replay stored exemplars from previous tasks; mask-based approaches [26], which use task-specific masks to isolate parameters that can be updated; and dynamic network structures [11, 32], which expand the model architecture by adding new or contracting existing modules for each task. In this work, we concentrate on weight-regularization, knowledge distillation and dynamic network structure-based methods. These are the approaches that work on task-agnostic scenarios (do not require a task-ID during inference) and promote privacy preservation (do not store samples).\nIncremental learning with repetition. In many practical applications (automated failure inspection, medical imaging, robotics), pattern repetition naturally arises, yet traditional CIL approaches assume that each class is encountered only once, imposing a strict no-repetition constraint [7]. This constraint focuses on the prevention of catastrophic forgetting but also diverges from real-world scenarios where classes may reappear or shift over time. To address this, Hemati et. al [15, 16] propose an extension to the class-incremental learning scenario which models the repetition of individual classes outside of a single task. Unlike joint incremental or rehearsal-based learning, this repetition is innate to the learning scenario and cannot be adjusted. This emphasizes an experience-based scenario [41], which favours shorter training tasks that can sometimes only cover a part of the class distribution. Moreover, covering scenarios that lie between the classic offline incremental and the online ones.\nClass-incremental learning with repetition has received increased interest in the research community, being a central element in the challenge tracks of the last two CLVISION challenge tracks at CVPR 2023 and 2024 [1, 16]. In the 2023 edition, we competed with a base variant of our proposed method, although without elements for controlling ensemble growth (see Sec. 3.1), self-supervision (see Sec. D) or applicability to variable network architectures.\nClass prototypes and pseudo-features. To enforce stability and alleviate class-recency biases in the classifier [27], Exemplar-Free Class Incremental Learning (EFCIL) methods [33, 40, 46\u201348] utilize class prototypes to simulate unavailable classes. These prototypes capture statistical properties of embedding representations of each class, which are usually modeled as a multivariate Gaussian distribution [40, 46, 47]. Specifically, the statistics typically include the mean and covariance of feature representations for each class, allowing to generate pseudo-features when class data is not available. To extract representations, the neural network is divided into two modules. A feature extractor (FE) that projects the input samples into their corresponding embedding representation; and a classifier head that uses these embeddings to solve the classification task. Therefore, prototype-based methods can generate embeddings even when no samples from past classes are available during subsequent tasks by sampling the stored distributions of each class. The sampled embedding representations are rehearsed alongside the current task data, thus promoting stability and mitigating class-recency bias. However, in order to maintain valid approximations of class distributions, the feature extractor needs to be either frozen or heavily regularized to prevent changes or drifts in the extracted features. Unlike rehearsal-based approaches, the use of prototypes does not violate data privacy due to the non-linearly projected representation in the embedding space [44, 47].\nFeature translation. Instead of sampling the distribution approximated by class prototypes, FeTrIL [33] proposes to translate the features of available data classes to unavailable ones directly. Given a feature extractor f(x; \u03b8) being trained on current data {(xi, yi)}, its output embedding F is efficiently translated from one of the current"}, {"title": "3. Method", "content": "In incremental learning scenarios with repetition, the reappearance of classes introduces uncertainty in task sequences, requiring strategies that handle dynamic class distributions. Our approach aims to: (a) capture information from the current task, (b) integrate it with knowledge from previously seen tasks, and (c) ensure the ability to discriminate between all encountered classes so far. To achieve this, we leverage zero-forgetting feature extractors (FEs), which are aggregated in an ensemble to overcome the limitation of a completely fixed feature space. Through this aggregation, we form a flexible feature representation space that can adapt (expand or contract) based on the incremental learning sequence (see Fig. 1 for an overview of the proposed method structure).\nTo effectively utilize this dynamic embedding space, we address the challenge of missing classes by constructing prototypes for all encountered classes. Class prototypes are used to train a unifying classification layer through an adjusted feature translation mechanism, termed pseudo-feature projection, ensuring continuous adaptation and robust performance across all classes. Concretely, the learning approach is divided into two steps: (1st) based on the difficulty of the current task and depending on how well new classes can fit into the ensemble embedding space, the ensemble is expanded with a new feature extractor (described in Sec. 3.1); (2nd) once the embedding space has been fixed for the current task, class prototypes are extracted and the unified classification layer is trained through the pseudo-feature projection (described in Sec. 3.2). These steps are performed for every incremental task and are summarized in Figure 2.\n3.1. Feature Extractor Ensemble\nThe proposed aggregation framework consists of multiple individual feature extractors (FEs), each trained on a specific task and then frozen to preserve the learned representations. The motivation for this zero-forgetting strategy is to enforce stability, avoiding any catastrophic forgetting on the ensemble while providing some plasticity through the extension of the ensemble. Unlike FeTrIL, which freezes a single feature extractor after the initial training, the extension of the feature space through the ensemble relieves the dependence of an expressive initial feature extractor. The goal of each feature extractor is to build a diverse and expressive feature space that emphasizes high-quality representations rather than optimizing the performance of the individual incremental task. Further, we adopt the self-learning loss from PASS [47]. This self-learning loss enhances the learned feature representation by simultaneously classifying image orientation and categories (each image class now has 4 augmented labels depending on the image orientation). To further improve regularization on the feature space topology, we incorporate a metric learning head with contrastive loss [34] and hard-negative mining [37]. This promotes spherical-shaped clusters in the embedding space, which improves class discrimination between known and unknown distributions [25]. Additionally, the sphere-shaped structure aligns well with the properties of a multivariate Gaussian distribution, which relates to the pseudo-feature projection we propose. An ablation study of the effects of individual components is provided in the supplementary material (see Sec. D).\nEnsemble Growth. To control the growth of the ensemble, we set a predefined budget B for the maximum num-"}, {"title": "3.2. Unified Classification Layer", "content": "To unify the feature representations from the ensemble and enable task-agnostic classification, we utilize a fully-connected layer. This layer has dynamic input and output sizes depending on the growth of the ensemble and the number of incrementally learned classes. To mitigate task-recency bias [8], we train this unified head using both data from the current task and projected class prototype features through our proposed pseudo-feature projection.\nPseudo-feature projection. Pseudo-feature projection, inspired by FeTrIL [33], extends feature translation by incorporating both the mean and standard deviation of class prototypes. This enhances the sampling of dimensions, reduces the chance of overlapping classes in the embedding space and leads to more accurate feature replay. With this projection, a data point from one class may be projected to a pseudo-feature representation of any other previously learned class. Our proposed projection extends the one from FeTrIL on Eq. (1) as\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\\begin{equation}\nF_c = \\mu_c + \\frac{f(x_i; \\theta) - \\mu_{y_i}}{\\sigma_{y_i}} \\cdot \\sigma_c,\n\\end{equation}\n\\end{document}\n\nwhere F represents the pseudo-features of the latent representation of a data point (xi, yi) which is projected from the original class yi to the desired class c. This transformation leverages the class prototypes; specifically the mean \u00b5y and standard deviation \u03c3y; to modify the latent representation f(xi; \u03b8). Class prototypes are updated during Step 2, before training the unified classification layer and after the ensemble has been adjusted.\nWe represent a complete class prototype as the concatenation of the individual class statistics from each FE in the ensemble:\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\\begin{align}\n\\mu_c &= (\\mu_{c,1}, ..., \\mu_{c,n}), \\\\\n\\sigma_c &= (\\sigma_{c,1}, ..., \\sigma_{c,n}),\n\\end{align}\n\\end{document}\n\nwhere n determines the current size of the ensemble. Throughout the incremental sequence, the ensemble can be expanded until the feature extractor budget is exhausted (n \u2264 B). Once this limit has been reached, individual feature extractors need to be finetuned or replaced and their corresponding class prototype (\u00b5c,i, \u03c3c,i) is reset.\nClass prototypes of certain classes may be incomplete for newly added or modified FEs. When class statistics are unknown for a specific FE, estimates are required for pseudo-feature projection to calculate \u00b5\u0302 c,f and \u03c3\u0302 c,f. In the absence of statistical information, we fix the standard deviation to \u03c3\u0302 c,f = 1. This decision is based on the fact that the estimation of \u00b5\u0302 c,f already provides sufficient variance. Therefore, for the estimation of the mean component \u00b5\u0302 cf we propose three heuristics:\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\\begin{equation}\n\\mu_{c,f} = 0,\n\\end{equation}\n\\end{document}\n\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\\begin{equation}\n\\mu_{c,f} \\sim \\mathcal{N}(0; \\Sigma),\n\\end{equation}\n\\end{document}\n\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\\begin{equation}\n\\mu_{c,f} = f(x_i; \\theta) .\n\\end{equation}\n\\end{document}"}, {"title": "4. Experimental Setup", "content": "Most incremental learning methods expect a different set of classes with all dataset samples for each class available when learning its corresponding task. However, when class repetition is introduced, the complexity of potential scenarios increases significantly, and where sequence length and repetition frequency become additional variables. To address this, we propose an analysis into the effects of class repetition within a setting that shares many characteristics of traditional incremental learning but incorporates longer sequences with class repetition. Code for the proposed scenarios and methods is available\u00b9.\nOverall, the proposed experiments aim to analyze a) the performance of IL methods in scenarios without repetition (baseline), b) the performance of CIL with small incremental tasks and class repetition, and c) the resilience of the methods against bias deviations in repetition frequency.\nIdeally, we expect the average accuracy of our proposed method to be on par with state-of-the-art methods on (a) and to outperform them in (b) and (c). To validate this, method performance will be ranked based on average accuracy for all scenarios (a \u2013 c).\n4.1. Compared Methods\nWe benchmark a total of 14 methods, which include two rehearsal-based approaches, five incremental learning methods, five state-of-the-art exemplar-free class-incremental learning (EFCIL) methods, and two variants of our proposed approach. The two rehearsal-based methods are excluded from the ranking and serve as an upper baseline (Joint [8]) and a reference point (Weight-Alignment (WA) [45]; n = 2000).\nThe five incremental learning methods consist of two baseline methods (Freezing (FZ) and Finetuning (FT) [27]), and three classic IL methods Elastic Weight Consolidation (EWC) [20], Memory Aware Synapses (MAS) [2] and Learning without Forgetting (LWF) [22]. These three methods were not originally proposed for CIL, thus, requiring the use of a task-ID at inference time. However, they are easily and commonly adaptable to task-agnostic settings. As such, we performed a grid search for their optimal hyperparameters based on the CIL 50/10 setting and used these for the repetition settings.\nThe five state-of-the-art, rehearsal-free, protoype-based methods comprise: Prototype Augmentation and Self-Supervision (PASS) [47], Class-Incremental Learning with Dual Supervision (IL2A) [46], Self-Sustaining Representation Expansion (SSRE) [48], Prototype Reminiscence and Augmented Asymmetric Knowledge Aggregation (PRAKA) [40] and Feature Translation for Exemplar-free Class Incremental Learning (FeTrIL) [33]. These methods were originally reported on the CIL CIFAR 50/10 setting. Therefore, since the proposed repetition scenarios are closely related to this setting, we use the hyperparameters proposed by the original authors.\nFinally, we evaluate our proposed method with both ensemble growth heuristics (Hordem and Hordec). A de-"}, {"title": "4.2. Model Architecture", "content": "All methods employ the same base feature extractor, a ResNet-18 [13] model that has been adjusted to the CIFAR input dimensions [46, 47]. For our approach, which utilizes an ensemble of feature extractors, we employ a slimmed-down variant of ResNet-18 for incremental tasks. This variant reduces the number of channels/filters for convolutions while preserving the network's depth (see supplementary material Sec. B). With this reduced architecture, we construct an ensemble consisting of one full ResNet-18 and nine Slim-ResNet-18 models (making our budget B=10). This configuration results in a total number of parameters and computational requirements (see Table 2) that are roughly equivalent to those of knowledge distillation approaches (or importance weight estimation [2, 20, 23])."}, {"title": "4.3. Scenarios", "content": "Experiments are conducted on the CIFAR-100 dataset [21], employing data augmentation in line with other CIL methods [40, 46]. These augmentations consist of a 4-pixel zero padding of the input image and a random cropping to the original 32 \u00d7 32 size. Followed by a random horizontal flip, image brightness jitter and image normalization.\nTo evaluate the effects of repetition on CIL methods, we organize the experiments in three scenarios. First, a baseline is established by evaluating (a) all methods on an incremental learning scenario without repetition.\n(a) CIL 50/10. The classic task-agnostic class-incremental scenario consisting of an initial training session with 50 classes and followed by 10 incremental tasks, each containing five novel classes.\nSecond, we evaluate (b) performance on a modified CIL scenario where classes repeat in the task sequence. Specifically, the scenario is built by replacing the discrete incremental tasks with clear boundaries from CIL 50/10 with small (2,000 training samples per task) incremental tasks that can contain class repetition. Each class, old or new, has the same probability of being in an incremental task.\n(b) EFCIR-U 50/100. Similarly to the CIL 50/10 scenario, the initial training also covers 50 classes. An essential element of repetition is a mixture of new and already seen samples. Therefore, we only provide 50% of the available training data samples for the initial training. Following the initial task, the scenario consists of 99 small, incremental tasks, with a limit of 2,000 training samples each. Both the initial 50 and incremental 50 classes have a fixed probability of 15% of being discovered or repeated in an incremental task so that tasks do not contain too many classes on average. The number of samples per class in a task are balanced as in the CIL 50/10 scenario. In the third scenario, the aim is to assess the IL method's (c) resilience against biases in repetition frequency. To establish this bias during scenario creation we propose to draw the repetition probability of each class from a Beta Distribution [19]. An illustration of the repetition bias is provided in the supplementary material Sec. E.\n(c) EFCIR-B 50/100. To test the resiliency against repetition frequency, we sample individual class repetition probabilities p ~ Beta(\u03b1, \u03b2) with parameters \u03b1 = 3.5 and \u03b2 = 20.0. This way, the expectation E[Beta(3.5, 20.0)]\u22480.15 is similar to the uniform EFCIR-U scenario, implying that on average the same number of classes are present in each task.\nIn scenarios with repeated classes, the optimal learning rate and number of epochs depend on various factors (e.g. method, number of training samples, length of incremental sequence) and are highly influential. To address this, we split 10% of the available training data as a validation set. For all methods, we apply early stopping [5, 34] using this validation data for the classes present in the task. We monitor the validation loss (including regularization and auxiliary losses of the method) and allow for a patience period of 5 epochs. If no improvement is observed, we perform a learning rate decay step. Each decay step reduces the learning rate by a factor of 0.1, the model weights are reset to the best checkpoint before patience, and we do not perform more than 2 decay steps.\nEvaluation. All scenarios are ranked by the average accuracy [8, 27, 33, 36, 47] achieved over the complete task sequence. Average accuracy is calculated by evaluating the model on the CIFAR test set based on the classes that have been seen up to each task. Complementary to the average accuracy, average forgetting [6, 8, 27] is also reported, which measures the drop in accuracy over the task sequence. Experimental results are averaged over 5 seeds."}, {"title": "5. Results", "content": "The summarized results of the experiments are listed in Table 3. Detailed plots and tables of the accuracy progression for all methods in each proposed scenario are provided in the supplementary material (Sec. G).\nScenario (a) CIL 50/10. The conducted baseline experiment confirms the reported results from other works [8, 40, 46, 47]. We observe a significant performance gain of approximately 10-15% in average accuracy over the task sequence when comparing the state-of-the-art rehearsal-free (EFCIL) methods with EWC, MAS and LwF. While our proposed method is particularly designed towards repetition scenarios, where the estimation of class prototype components is not always required, it remains competitive in disjoint, no-repetition scenarios as well, showing comparable performance to the best EFCIL methods [33, 40, 46, 47].\nScenario (b) EFCIR-U. Introducing class repetition in small incremental tasks into the scenario leads to significant performance differences. Weight-regularization approaches and vanilla finetuning typically underperform compared to knowledge distillation or class prototype-based approaches in EFCIL [40]. However, in this scenario with repetition, we observe greatly improved performance for FT, EWC and MAS. The results for these methods surpass even the results from the CIL 50/10 scenario by leveraging data repetition effectively (see Fig. 3). In contrast, EFCIL methods (PASS, IL2A, SSRE, PRAKA) that rely on both class prototype rehearsal and knowledge distillation show a performance degradation under repetition. This decline is not observed in methods that use either knowledge distillation (LwF) or class prototype rehearsal with frozen feature extractors (FeTrIL, Ours).\nWe hypothesize that the estimation of class prototypes with incomplete class data distribution in the former methods leads to a suboptimal feature embedding space, which is then propagated through the incremental task sequence via knowledge distillation. Frozen feature extractors, on the other hand, avoid this issue since their representations remain fixed after the initial training, preventing catastrophic drift in the embedding space during the task sequence. This raises the question whether the assumption that the complete training data distribution of an individual class as in traditional class-incremental learning - is a realistic assumption for continual learning scenarios.\nOur ensemble-based approach (Horde), with both en-"}, {"title": "6. Conclusion", "content": "In this work, we conducted an exploratory evaluation of CIL methods in exemplar-free class-incremental learning with repetition scenarios and investigated their resiliency to biases in the repetition frequency of classes.\nIn the evaluated repetition scenarios, EFCIL methods that rely on class prototypes (PASS, PRAKA, IL2A, SSRE) severely underperform and are unable to benefit from the repetition of classes. Notably, weight-regularization-based approaches perform exceptionally well in repetition scenarios provided that training with cross-entropy is restricted to the classes present in each task, thereby mitigating the risk of class-recency bias in the classification head. The results from the repetition frequency bias from a beta distribution show only minimal performance differences, with either no effect on average accuracy or a slight drop of up to 2%. Thus, a bias in repetition frequency alone without a biased sample distribution within a training task is insufficient for significant classification bias.\nFurthermore, we introduce a novel ensemble learning technique that takes advantage of class repetition. This method combines a dynamic set of independent feature extractors, which are aligned through a unified head in a process we call pseudo-feature projection. The proposed method demonstrates competitive performance in traditional no-repetition settings and establishes a new state-of-the-art for scenarios with repetition."}, {"title": "A. Pseudo Code", "content": "The algorithm for the proposed Horde method can be separated into two parts: (1st) the training of an individual feature extractor (FE), which is listed in Algorithm 1 and (2nd) the overall assembly of the ensemble and training of the unified head through pseudo-feature projection (see Algorithm 2). The training of a feature extractor (1st part) can be freely adjusted (loss, network architecture) as long as a frozen feature extractor that can produce an embedding is the result.\nAlgorithm 1 FE Training\n1: Initialize CE and ML Head\n2: Initialize new FE (or transfer learned weights)\n3: for training epoch do\n4:  for X; Y in Dataloader do\n5:   X; Y SelfSupervision(X; Y)\n6:   Extract X FE(X)\n7:   Predict \u0176 HeadCE(X)\n8:   Project A HeadML(X)\n9:   Calculate LCE (from Y and \u0176)\n10:   Calculate LML (with Hard Neg. Pairs on A)\n11:   Backprop LCE + LML\n12:  end for\n13: end for\n14: Remove CE and ML head\n15: Freeze FE\nAlgorithm 2 IL through pseudo-feature projection\n1: for task do\n2:  if Growth Condition (Hordem or Hordec) then\n3:   Train FE (Algorithm 1)\n4:   Add / Replace FE in ensemble\n5:  end if\n6:  Calculate \u00b5c and \u03c3c for all current classes c\n7:  for training epoch do\n8:   for Batch do\n9:    Calculate LCE Only Unified head\n10:    Generate F from current Batch\n11:    Calculate LCE;P for F\n12:    Backprop LCE + LCE;P\n13:   end for\n14:  end for\n15: end for"}, {"title": "B. Details about the Model Architecture", "content": "The individual layers of a ResNet-18 are listed in Table 4 and a structural overview is depicted in Figure 6. There is no difference in the depth of the network or the type of layers between the ResNet-18 and the Slim-ResNet-18. The only difference is the number of base filters Cb for the convolutions in the Basic Blocks. The Slim-ResNet-18 uses Cb = 20 while the full ResNet-18 uses Cb=64. This influences the number of channels for the following operations so that a compression to approximately a tenth of the original size can be achieved."}, {"title": "C. Method Hyperparameters", "content": "The hyperparameters for all compared methods are listed in Table 5. For EWC, MAS and LWF, we perform a grid-search over their main hyperparameters on the CIL 50/10 scenario, and the one achieving the highest average accuracy are fixed for the repetition tasks. The remaining hyperparameters are the ones recommended by their original authors for the corresponding scenario."}, {"title": "D. Feature Extractor Training Components", "content": "Table 6 provides an overview of the effects of each component in the Feature Extractor and its effect on the average accuracy in the CIL scenario (a). The results have been averaged over 5 seeds. Both the self-supervision from PASS [47] as well as the training with the metric learning head are beneficial based on the overall average accuracy. The metric learning head alone without a cross-"}, {"title": "E. Scenario Visualization", "content": "In the proposed experiments we differentiate between a fairly balanced repetition scenario and a biased scenario. The difference between the two repetition frequencies is visualized in Fig. 7 and Fig. 8. On average both scenarios have 15 classes in each incremental task."}, {"title": "F. Longer Task Sequence", "content": "The results from scenario (b) indicate a strong accuracy recovery/trend for weight regularization techniques. We further evaluate with even longer task sequences where the number of incremental tasks is increased from 99 to 149. The accuracy on later tasks is very strong on weight-regularization techniques as the overall accuracy trend continues. However, it is important to note that, already in the 100 task scenario, all available training data is used in the task sequence at least once, thus further tasks can only repeat samples and no longer provide any new/incremental training data. Although EWC and MAS both achieve a significant higher final accuracy in the longer task sequence, they are still slightly worse in terms of average accuracy across the whole sequence, since they are less stable in the initial tasks of the sequence. The compared average accuracies for the 100 and 150 task scenarios, as well as final test accuracy after the task sequence, are listed in Table 7. Furthermore, the accuracy progression is visualized in Figure 9."}, {"title": "G. Scenario Results", "content": "The following figures visualize the detailed Average Accuracy development over the incremental task sequence. For each method the mean and one standard deviation have been plotted. The results for the class-incremental scenario (a) are listed in Table 8 and visualized in Figure 10. The unbiased repetition results fo scenario (b) can be found in Table 9 and Figure 11. The results of the biased class-repetition scenario (c) are shown in Table 10 and Figure 12."}]}