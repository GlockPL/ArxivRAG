{"title": "LogLLM: Log-based Anomaly Detection Using Large Language Models", "authors": ["Wei Guan", "Jian Cao", "Shiyou Qian", "Jianqi Gao"], "abstract": "Software systems often record important runtime information in logs to help with troubleshooting. Log-based anomaly detection has become a key research area that aims to identify system issues through log data, ultimately enhancing the reliability of software systems. Traditional deep learning methods often struggle to capture the semantic information embedded in log data, which is typically organized in natural language. In this paper, we propose LogLLM, a log-based anomaly detection framework that leverages large language models (LLMs). LogLLM employs BERT for extracting semantic vectors from log messages, while utilizing Llama, a transformer decoder-based model, for classifying log sequences. Additionally, we introduce a projector to align the vector representation spaces of BERT and Llama, ensuring a cohesive understanding of log semantics. Unlike conventional methods that require log parsers to extract templates, LogLLM preprocesses log messages with regular expressions, streamlining the entire process. Our framework is trained through a novel three-stage procedure designed to enhance performance and adaptability. Experimental results across four public datasets demonstrate that LogLLM outperforms state-of-the-art methods. Even when handling unstable logs, it effectively captures the semantic meaning of log messages and detects anomalies accurately.", "sections": [{"title": "I. INTRODUCTION", "content": "Ensuring high availability and reliability is crucial for large- scale software-intensive systems [1], [2]. As these systems become more complex and expansive, the occurrence of anomalies becomes unavoidable [3], [4]. Even a minor issue can lead to performance degradation, data integrity problems, and substantial losses in both customers and revenue. Therefore, anomaly detection is vital for maintaining the health and stability of complex software-intensive systems [5]. Software-intensive systems typically produce console logs that record system states and critical runtime events [6]. Engineers can utilize this log data to evaluate system health, identify anomalies, and trace the root causes of issues. However, due to the potentially vast volume of logs, manually analyzing them for anomalies can be both labor-intensive and prone to mistakes [7]. Consequently, log-based anomaly detection has emerged as a key area in automated log analysis, focusing on the automatic identification of system anomalies through log data. Numerous deep learning-based methods [8]-[22] for log- based anomaly detection have been proposed. These methods typically employ sequential deep learning models such as LSTM [23] and transformers [24]. These methods can be further divided into reconstruction-based methods [8]-[15] and binary classification-based methods [16]\u2013[22]. Reconstruction- based methods involve designing and training a deep neural network to reconstruct input log sequences, with anomalies detected based on reconstruction errors. The underlying principle is that anomalous samples cannot be accurately reconstructed. Binary classification-based methods, on the other hand, involve designing a binary classifier to classify samples as either normal or anomalous. These methods often require labeled anomalies for training purposes. It is recognized that system logs are documented in natural language and contain a significant amount of semantic information. Nevertheless, traditional deep learning-based methods struggle to effectively capture this information. In recent years, significant advancements have been achieved in LLMs, such as GPT-4 [25], Llama 3 [26], and ChatGLM [27]. These models are characterized by their vast parameter sizes and are pretrained on substantially larger datasets, ranging from several gigabytes to terabytes in size. This extensive pretraining equips them with remarkable lan- guage comprehension abilities, enabling superior performance in tasks such as summarization, paraphrasing, and instruc- tion following even in zero-shot scenarios [28]. Existing methods that utilize LLMs for log-based anomaly detection can be categorized into prompt engineering-based [7], [29]- [31] and fine-tuning-based [3], [32]\u2013[40] approaches. Prompt engineering-based methods leverage the zero/few-shot capa- bilities of LLMs to detect anomalies based solely on the models' internal knowledge. However, these methods often struggle to customize solutions for specific datasets, leading to suboptimal detection performance. Fine-tuning-based methods integrate LLMs into deep neural networks and tailor them to user-specific datasets. Nevertheless, these methods encounter challenges such as limited semantic understanding, suboptimal LLM utilization (relying solely on LLMs for semantic infor- mation extraction), and insufficient consideration of input data format, which can lead to memory overflow. To tackle the aforementioned challenges, we propose LogLLM, a novel log-based anomaly detection framework that harnesses LLMs. Unlike traditional methods that rely on log parsers for template extraction, LogLLM preprocesses log messages using regular expressions, thereby streamlining the entire process. LogLLM, a fine-tuning-based method, utilizes"}, {"title": "II. RELATED WORK", "content": "In this section, we explore related work in the field of log-based anomaly detection, with a particular focus on deep learning-based methods. We give special attention to ap- proaches that utilize pretrained LLMs.\nA. Traditional Deep Learning for Log-based Anomaly Detection\nMany traditional deep learning-based methods for log-based anomaly detection have been proposed. These works can be grouped into two types based on the training paradigm: reconstruction-based methods and binary classification-based methods. Reconstruction-based methods [8]\u2013[15] involve designing and training a deep neural network to reconstruct input log sequences. Anomalies are detected based on reconstruction er- rors. Normal log sequences can be reconstructed with minimal errors, while anomalous log sequences cannot be effectively reconstructed, resulting in significantly higher reconstruction errors. These methods consistently train the deep model on normal data that is free of anomalies, which means they are semi-supervised. DeepLog [8] adopts LSTM to predict the next log template ID based on past log sequences. Similarly, LogAnomaly [9] predicts the next log template ID based on both sequen- tial and quantitative patterns. Autoencoders (AEs) [10]\u2013[13] and generative adversarial networks (GANs) [14], [15] are widely used in reconstruction-based methods. For example, LogAttn [10] adopts an AE that incorporates a temporal convolutional network (TCN) to capture temporal semantic correlations and a deep neural network (DNN) to capture statistical correlations. Duan et al. [14] use a GAN, where an encoder-decoder framework based on LSTM serves as the generator. Convolutional neural networks (CNNs) are used as the discriminator. The reconstruction error is calculated based on the difference between the input and the output from the generator. Binary classification-based methods [16]-[22] often em- ploy deep neural networks that output either one or two values. Typically, a single value represents the probability that a sample belongs to the anomalous class, and anomalies are detected by applying a threshold to convert this probability into a binary classification. When two values are output, they represent the probabilities of the sample belonging to the normal and anomalous classes, respectively. Most methods [16]\u2013[20] typically train deep models in a supervised manner. For example, Zhang et al. [16] propose LayerLog, which integrates word, log, and logseq layers to extract semantic features from log sequences. CNNs are utilized in [17], [18] to develop a binary classifier. LogRobust [19] integrates a pre-trained Word2Vec model, specifically FastText [42], and combines it with TF-IDF weights to learn representation vectors of log templates. These vectors are then fed into an attention-based Bi-LSTM model for anomaly detection. LogGD [20] transforms log sequences into graphs and utilizes a graph transformer neural network that combines graph structure and node semantics for log-based anomaly detection. Some work [21], [22] involves training binary classifiers in a semi-supervised manner. For example, Trine [21] uses a transformer encoder [24] to encode normal log sequences into vector representations and a generator to produce random fake vector representations. The discriminator, which is composed of a transformer and a multi-layer perceptron (MLP), is trained to distinguish whether the given vector representations are normal log sequences and it is subsequently used to detect anomalies. PLELog [22] tackles the challenge of insufficient labeling by employing probabilistic label estimation and de-velops an attention-based GRU neural network for anomaly detection. It is acknowledged that system logs are recorded in natural language and contain a substantial amount of semantic infor-mation. However, traditional deep learning-based methods face challenges in capturing this information."}, {"title": "B. LLMs for Log-based Anomaly Detection", "content": "Existing LLMs can be categorized into transformer encoder- based models, such as BERT [43], RoBERTa [44], and Span- BERT [45], and transformer decoder-based models, including GPT-4 [25], Llama 3 [26], and ChatGLM [27]. Two prevalent strategies for utilizing LLMs are prompt engineering and fine- tuning. Prompt engineering-based methods [7], [29]-[31] detect anomalies solely by relying on the internal knowledge of LLMs. These methods typically employ transformer decoder- based models. For instance, Qi et al. [7] employ ChatGPT for zero-shot and few-shot log-based anomaly detection, utilizing prompt templates that integrate the log sequence directly. However, this approach becomes impractical when using a large window size for grouping log messages. Egersdoerfer et al. [30] address this issue by maintaining a summary-based memory, which summarizes the previous log messages, elim- inating the need to input the entire log sequence for anomaly detection. RAGLog [31] uses a retrieval augmented generative (RAG) framework [46] to analyze log entries by querying its store of samples of normal log entries. They design prompt templates for LLMs to determine whether a queried log entry is normal or abnormal. Prompt engineering-based methods of- ten struggle to customize solutions for specific datasets, which can lead to suboptimal detection performance in particular datasets. Fine-tuning-based methods [3], [32]\u2013[40] incorporate LLMs into deep neural networks and customize them to the user's own dataset. Some methods [32]-[35], although adopt- ing transformer encoder-based LLMs for anomaly detection, do not capture the semantic information within log sequences. For example, LogBERT [32] and LAnoBERT [33] utilize BERT to reconstruct the input sequence of log template IDs (IDs of log string templates) and detect anomalies based on reconstruction errors, disregarding the semantic information. Other methods [3], [36]-[39] use transformer encoder-based LLMs solely for extracting semantic information from log messages and then employ either smaller models [3], [36]\u2013 [38] or distance-based comparison [39] for classification. For instance, NeuralLog [3] leverages BERT to extract semantic vectors from raw log messages, which are subsequently used to detect anomalies via a transformer-based classification model. Similarly, RAPID [39] utilizes transformer encoder-based models to extract semantic vectors and performs anomaly detection by comparing each query log sequence with its nearest document log sequence. Hadadi et al. [40] directly input template sequences parsed from log sequences, into an LLM and fine-tune it to accurately predict sequence labels. However, this method is impractical because each template may be processed into multiple tokens by the LLM's tokenizer, and a single template sequence can contain numerous log templates. Consequently, an excessive number of tokens can be generated for one template sequence, which LLMs often cannot process due to token (memory) limitations [41]. LogLLM is a fine-tuning-based method that utilizes BERT for extracting semantic vectors from log messages and Llama, a transformer decoder-based model, for log sequence classi- fication. This method aligns the vector representation spaces of BERT and Llama using a projector. By adopting BERT, LogLLM effectively mitigates the out-of-memory issue caused by excessive tokens when directly tokenizing the entire log sequence with Llama's tokenizer. Compared to other methods, LogLLM fully exploits the capabilities of LLMs for log-based anomaly detection."}, {"title": "III. PRELIMINARIES", "content": "To establish the groundwork for subsequent sections, we introduce the system log, which records the system's events and internal states during runtime. A system log contains a list of log messages in chronological order. Fig. 1 presents a snippet of a raw system log generated by the BGL (the BlueGene/L supercomputer system), with"}, {"title": "IV. METHODOLOGY", "content": "In this section, we present our innovative anomaly detection framework, LogLLM. As illustrated in Fig. 4, the log sequence undergoes preprocessing using regular expressions before be- ing fed into a deep neural network that integrates BERT [43], a projector, and Llama 3 [26] for log sequence classification. In the following sections, we will provide detailed insights into log sequence preprocessing, the architecture of the deep model, and the model training procedure.\nA. Preprocessing\nConsidering that the log message content includes variable parameters carrying dynamic runtime information, which is always irrelevant to the anomalies and complicates deep model training, as demonstrated in Section V-F, a technique is needed to identify these parameters and replace them with a constant token. Log parsers, such as Drain [51] and Spell [52], are widely adopted in log-based anomaly detection methods and appear to be a useful technique. However, as noted by Le et al. [3], existing log parsers do not always perform correctly on all log datasets and struggle to handle out-of-vocabulary (OOV) words in new log messages, resulting in a loss of semantic information. When logs are unstable, these parsers become increasingly ineffective over time, making it difficult to support subsequent anomaly detection. Thanks to the structured log generation process, the textual format of parameters representing specific objects can be easily identified using regular expressions [53]. Consequently, we replace each variable parameter, such as account, directory path, and IP address, with '<*>'. Despite its simplicity, this technique offers significant performance advantages. Com- pared with log parsers, this preprocessing technique is more effective and does not require training.\nB. Model Architecture\nAs shown in Fig. 4, our deep model consists of three main components: BERT, a projector, and Llama. Both BERT and Llama are pretrained LLMs. BERT is utilized to extract vector representations of log messages, while Llama is employed to classify the log sequences. The projector serves as a bridge, aligning the vector representation spaces of BERT and Llama. It is important to note that our model incorporates only one instance of BERT and one projector."}, {"title": "C. Training", "content": "1) Minority Class Oversampling: LogLLM is a supervised anomaly detection method, which means it needs labeled nor- mal and anomalous samples for training. However, supervised anomaly detection methods often face the challenge of data imbalance, which can lead to biased model training. In an anomaly detection task, there are only two classes: normal and anomalous, and the number of instances in each class is uncertain. To cope with data imbalance, we oversample the class with fewer samples, ensuring that the proportion of the minority class is no less than B. Formally, let the the proportion of the minority class is \u03b1 and \u03b1 < \u03b2, and the total number of samples is Sample_num. To achieve a proportion of \u03b2 for the minority class, it will be oversampled to the following quantity:\n$\\frac{\\beta(1 - \\alpha)}{1-\\beta} \\times Sample\\_num$    (1)\nThis adjustment will make the proportion of the minority class equal to \u03b2.\n2) Training Objective: Our objective is to train the deep model to predict whether a given log sequence is normal or anomalous. We fine-tune the model to respond appropriately: if the sequence is anomalous, it outputs 'The sequence is anomalous'; if normal, it outputs 'The sequence is normal'. We utilize cross-entropy loss [54] as our loss function.\n3) Training Procedure: To train our deep model, we follow three main stages. Stage 1. Fine-tuning Llama to capture the answer tem- plate: The first stage involves fine-tuning Llama to capture the answer template. Specifically, we train Llama to respond to the prompt 'Is this sequence normal or anomalous?' with 'The sequence is anomalous/normal'. This stage requires only a few data samples. Stage 2. Training the embedder of log messages: The second stage involves training the embedder of log messages, specifically BERT and the projector. This stage aims to project each log message to the embedding of the most suitable token in Llama, enabling Llama to discern whether the given log sequence is normal or anomalous. Stage 3. Fine-tuning the entire model: Finally, we fine-tune the entire model to ensure cohesive and accurate performance across all components. 4) Efficient Fine-Tuning on LLMs: To reduce the costs involved in fine-tuning LLMS (BERT and Llama) with a substantial number of parameters, we utilize QLoRA [55] to minimize memory usage. QLoRA accomplishes this by backpropagating gradients into a frozen 4-bit quantized model, while maintaining the performance levels achieved during the full 16-bit fine-tuning process."}, {"title": "V. EXPERIMENTS", "content": "In this section, we perform empirical assessments of LogLLM's performance on four real-life logs. LogLLM is coded in Python, and the source code is available at https://github.com/guanwei49/LogLLM.\nA. Benchmark Methods\nTo verify the superiority of the proposed method, we compare LogLLM with five state-of-the-art semi-supervised methods: DeepLog [8], LogAnomaly [9], PLELog [22], Fast- LogAD [34], and LogBERT [32]. We also compare it with three supervised methods: LogRobust [19], CNN [18] and NeuralLog [3], and one method that does not require training a deep model but needs some normal samples for retrieval: RAPID [39]. Notably, FastLogAD, LogBERT, NeuralLog, and RAPID adopt LLMs for anomaly detection."}, {"title": "B. Experimental Settings", "content": "In our experiment, the hyperparameter \u03b2, which is described in Section IV-C1, is set to 30%. We use the Adam optimizer [56] to train the model with a mini-batch size of 16. Unless otherwise specified, the training procedure is configured as follows: In the first stage, only 1,000 samples are involved with a learning rate of 5e-4. The second and third stages each consist of two epochs with a learning rate of 5e-5. For a fair comparison, we configure the hyperparameters for all compared methods according to the values provided in their original articles."}, {"title": "C. Metrics", "content": "We evaluate the performance of these methods using the widely adopted Precision, Recall and F1 score. These metrics are calculated as follows:\n$Precision = \\frac{TP}{TP + FP}$    (2)\n$Recall = \\frac{TP}{TP+FN}$    (3)\n$F_1-score = \\frac{2* Precision * Recall}{Precision + Recall}$    (4)\n, where TP, FN, FP represent true positives, false negatives and false positives respectively.\nPrecision refers to the percentage of correctly detected anomalies among all anomalies identified by the model, while recall represents the percentage of anomalies that are correctly identified from all real anomalies. The $F_1$-score combines these two metrics into a single measure, providing a balanced assessment of the model's performance in detecting anomalies."}, {"title": "D. Dataset", "content": "To evaluate our method for log-based anomaly detection, we selected four public datasets [57]: HDFS, BGL, Liberty, and Thunderbird. The details for each dataset are provided below: HDFS (Hadoop Distributed File System) dataset [49] is generated by running Hadoop-based mapreduce jobs on over 200 Amazon EC2 nodes and contains a total of 11,175,629 log messages. These log messages are grouped into different log windows based on their block_id, which reflect program executions in the HDFS. Among these, 16,838 blocks (2.93%) indicate system anomalies. BGL (Blue Gene/L) dataset [50] is a supercomputing system log dataset collected from a BlueGene/L supercom- puter system at lawrence livermore national labs (LLNL). The dataset contains 4,747,963 log messages, each of which has been manually labeled as either normal or anomalous. There are 348,460 log messages (7.34%) that are labeled as anomalous. Thunderbird dataset [50] is a publicly accessible collection of log data sourced from the Thunderbird supercomputer at sandia national laboratories (SNL). This dataset consists of both normal and anomalous messages, each of which has been manually categorized. Although the dataset contains over 200 million log messages, we focus on a subset of 10 million continuous log messages for computational efficiency. This subset includes 4,937 anomalous log messages, representing approximately 0.049% of the total. Liberty dataset [50] comprises system logs from the Liberty supercomputer at sandia national labs (SNL) in Albuquerque. This supercomputer features 512 processors and 944 GB of memory, and the dataset contains over 200 million log messages. For computational efficiency, we sample 5 million consecutive log messages, among which 1,600,525 are identi- fied as anomalous, constituting approximately 32.01% of the total sampled messages. In the context of HDFS, we adopt a session window strategy, which involves grouping log messages into sequences based on the block_id present in each log message. Each session is labeled using ground truth. For other datasets, including BGL, Thunderbird, and Liberty, we utilize a fixed window strategy to group log messages, with a window size of 100 messages and a step size of 100 messages. A log sequence is deemed anomalous if it contains at least one anomalous log message according to the ground truth. Similar to existing work [8], [9], [19], [22], [34], [39], we split each dataset into a training set and a testing set with a ratio of 8:2 to evaluate the performance of a log-based anomaly detection approach. For the HDFS dataset, we randomly split the log sequences into training and testing data. In contrast, for the BGL, Thunderbird, and Liberty datasets, we adhere to a chronological split [6]. This strategy ensures that all log sequences in the training set precede those in the testing set, reflecting real-world conditions and mitigating potential data leakage from unstable log data."}, {"title": "E. Performance Evaluation", "content": "Table II presents the experimental results of various log-based anomaly detection methods on the HDFS, BGL, Liberty, and Thunderbird datasets. The best results are highlighted in bold. We have the following observations:"}, {"title": "F. Effects of Different Preprocessing Techniques", "content": "We evaluate the effectiveness of the different preprocessing techniques. The results are shown in Table IV. In this table, 'Raw' indicates that the content of log messages is not preprocessed and is directly input into the proposed deep model. 'Template' indicates that sequences of log templates produced by Drain [51], a log parser, are used as input for the proposed deep model. 'Template ID' signifies that the IDs of log templates, obtained by Drain, are simply encoded into numeric vectors using an embedding layer instead of BERT. The preprocessing technique 'Template ID' renders"}, {"title": "G. Ablation Study of the Training Procedure", "content": "We investigate the effect of each training procedure through an ablation study. The results are presented in Table V, where 'W/O' denotes 'without'. We have the following observations: Skipping any training stage results in a decrease in the F1- score across all datasets, demonstrating the effectiveness of our three-stage training procedure. Training without stage 1 leads to the worst performance, with the $F_1$-score averaged across all datasets decreasing by as much as 29.7%. This demonstrates that fine-tuning Llama to capture the answer template (Stage 1) is essential before training the embedder of log messages (Stage 2). Without this stage, the embedder may be misdirected, resulting in incorrect semantic capture of log messages and model failure. Training without stage 3 yields relatively poor performance, with an average $F_1$-score decrease of 10.5%. This indicates that sequentially fine-tuning Llama and training the embedder alone is insufficient for the model to capture anomalous patterns; cohesive fine-tuning of the entire model is essential. Training without stages 2 and 1&2 (only adopting training stage 3: fine-tuning the entire model) results in acceptable performance, with average $F_1$-score decreases of 2.5% and 3.2%. This demonstrates that individually training the embedder (BERT and projector) before fine-tuning the entire model can also enhance performance. This stage allows the embedder to generate better semantic vectors of log messages for Llama to discern anomalies. In summary, our proposed three-stage training procedure is well-suited for our deep model in log-based anomaly detection."}, {"title": "H. Impact of Minority Class Oversampling", "content": "Note that normal and anomalous samples in the training dataset are imbalanced, as shown in Table I. For the HDFS, BGL, and Thunderbird datasets, normal samples outnumber anomalous samples. Conversely, in the Liberty dataset, anoma- lous samples exceed normal samples. The hyper-parameter \u03b2 controls the proportion of the minority class by oversampling to address data imbalance problem, as described in Section IV-C1. In this section, we investigate the impact of \u03b2 by vary- ing its value. Fig. 5 illustrates the performance of LogLLM on the four datasets under different magnitudes of \u03b2. When \u03b2 = 0, the samples are not oversampled; instead, the original datasets are utilized directly for training. As illustrated in Fig. 5b, for the HDFS, BGL, and Thunder- bird datasets, the recall always increases, while for the Liberty dataset, recall decreases as \u03b2 increases. This can be attributed to the fact that for the HDFS, BGL, and Thunderbird datasets, when \u03b2 increases, anomalies are oversampled, making the model more prone to identifying samples as anomalies. In contrast, for the Liberty dataset, when \u03b2 increases, normal samples are oversampled, making the model more prone to identifying samples as normal. As illustrated in Fig. 5c, the changing pattern of the $F_1$- score is basically the same across all datasets. The $F_1$-score increases and then decreases as \u03b2 increases. However, the LogLLM seems not to be sensitive to \u03b2; when \u03b2 is between 10% and 80%, the variation in the $F_1$-score is no more than 0.07. Thanks to the substantial semantic knowledge embedded in LLMs, a trained model can effectively learn anomalous patterns and detect anomalies, even when the minority class constitutes only 10% of the dataset. In comparison to the BGL and Thunderbird datasets, the $F_1$-score for the HDFS and Liberty datasets shows minimal variation with respect to \u03b2. This consistency can be attributed to the clear anomalous pat- terns present, allowing LogLLM to be easily trained to detect anomalies across various \u03b2 values. However, LogLLM appears unable to effectively handle extremely imbalanced scenarios. For instance, in the Thunderbird dataset, anomalies constitute only 1.05% of the samples, causing the trained model to be biased and classify all samples as normal. As a result, precision, recall, and $F_1$-score are all equal to 0. Consequently, minority class oversampling is sometimes essential. As anticipated, as \u03b2 increases, the training time also in- creases, as shown in Fig. 5d. This relationship arises because a higher \u03b2 leads to more oversampled data samples, as indicated by equation (1), thereby enlarging the training dataset. To summarize, minority class oversampling is essential; however, the value of the hyperparameter \u03b2 does not signif- icantly impact the performance of LogLLM, making careful selection unnecessary. Moreover, excessively large values of Bare undesirable, as they result in prolonged training times. Values between 30% and 50% are deemed acceptable."}, {"title": "VI. CONCLUSION", "content": "In this paper, we propose LogLLM, a novel log-based anomaly detection framework that leverages LLMs. LogLLM employs both transformer encoder-based and decoder-based LLMs, specifically BERT and Llama, for log-based anomaly detection. BERT is utilized to extract semantic vectors from log messages, while Llama is used to classify log sequences. To ensure coherence in log semantics, we introduce a projector that aligns the vector representation spaces of BERT and Llama. LogLLM is trained using an innovative three-stage procedure designed to enhance both performance and adapt- ability. Extensive experiments conducted on four public real- world datasets demonstrate that LogLLM achieves remarkable"}]}