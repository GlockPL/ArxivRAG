{"title": "PatchCTG: Patch Cardiotocography Transformer\nfor Antepartum Fetal Health Monitoring", "authors": ["M. Jaleed Khan", "Manu Vatish", "Gabriel Davis Jones"], "abstract": "Antepartum Cardiotocography (CTG) is vital for fetal health monitoring, but\ntraditional methods like the Dawes-Redman system are often limited by high\ninter-observer variability, leading to inconsistent interpretations and potential\nmisdiagnoses. This paper introduces PatchCTG, a transformer-based model\nspecifically designed for CTG analysis, employing patch-based tokenisation,\ninstance normalisation and channel-independent processing to capture essential\nlocal and global temporal dependencies within CTG signals. PatchCTG was eval-\nuated on the Oxford Maternity (OXMAT) dataset, comprising over 20,000 CTG\ntraces across diverse clinical outcomes after applying the inclusion and exclu-\nsion criteria. With extensive hyperparameter optimisation, PatchCTG achieved\nan AUC of 77%, with specificity of 88% and sensitivity of 57% at Youden's index\nthreshold, demonstrating adaptability to various clinical needs. Testing across\nvarying temporal thresholds showed robust predictive performance, particularly\nwith finetuning on data closer to delivery, achieving a sensitivity of 52% and\nspecificity of 88% for near-delivery cases. These findings suggest the potential of\nPatchCTG to enhance clinical decision-making in antepartum care by providing\na reliable, objective tool for fetal health assessment.", "sections": [{"title": "1 Introduction", "content": "Antepartum Cardiotocography (CTG) plays a pivotal role in fetal health monitor-\ning, serving as a critical assessment tool in prenatal care. Using ultrasound-based\ntechniques to record Fetal Heart Rate (FHR) and uterine activity, CTG provides clin-\nicians with data on fetal well-being through the examination of heart rate variability\nand response patterns to uterine contractions. Established methods like the Dawes-\nRedman (DR) computerised CTG system [1] offer valuable criteria for interpreting\nCTG patterns, enhancing clinical decisions that help mitigate risks of adverse out-\ncomes such as neonatal acidaemia, hypoxia and stillbirth [2]. Despite its widespread\nadoption in clinical settings, CTG analysis suffers from high intra- and inter-observer\nvariability. Studies indicate that clinical assessments can overlook 35-92% of FHR pat-\nterns [3, 4], and inter-observer agreement may be as low as 29%, with false positive\nrates reaching up to 60% [5, 6]. These limitations underscore the necessity for more\nreliable, objective methods of fetal monitoring.\nRecent advancements in artificial intelligence and machine learning, particularly\ndeep learning, have demonstrated considerable potential in automating and improving\nthe accuracy of CTG interpretation. By leveraging deep learning models, researchers\nhave advanced the detection of adverse outcomes in CTG signals through feature\nextraction, noise reduction and classification tasks, providing more consistent assess-\nments than manual interpretation [7]. Transformers excel at handling sequential data,\nincluding biomedical time series, due to their ability to capture complex temporal\ndependencies by dynamically learning correlations across input elements, which makes\nthem highly promising for CTG analysis [8]. With self-attention mechanisms, Trans-\nformers capture complex temporal dependencies in CTG data, focusing on relevant\nsegments of FHR and uterine activity patterns.\nDespite these advancements, several challenges persist in applying deep learning to\nCTG-based fetal health monitoring. Existing models fall short in capturing the physi-\nological responses in CTG, largely due to signal variability across patients, monitoring\nconditions and clinical contexts [9]. Issues like insufficient data diversity, high com-\nputational costs and a lack of generalizability across different clinical settings often\nlimit the performance of deep learning models on CTG data. Addressing these chal-\nlenges requires specialised models that can adapt to different temporal patterns while\nmaintaining robust performance.\nIn this paper, we introduce Patch Cardiotocography Transformer (PatchCTG), a\npatch-based transformer model designed to classify adverse and normal outcomes in\nantepartum CTG recordings reliably. The PatchCTG model builds on recent advance-\nments in patch-based Transformers for time series [10], which demonstrate promising\nperformance in sequence compression and feature representation by segmenting signals\ninto patches. Unlike traditional CTG analysis approaches, PatchCTG applies instance\nnormalisation and channel-independent processing to manage distribution shifts and\ncapture the distinct temporal dynamics of FHR and uterine activity. By leveraging\npatch-based tokenisation and self-attention, PatchCTG provides enhanced computa-\ntional efficiency and adaptability to longer temporal windows, making it well-suited for\nCTG data, where signal length and variability pose significant modelling challenges.\nThe main contributions of this study are as follows:"}, {"title": "2 Related Work", "content": "The Dawes-Redman (DR) system has long served as the gold standard in electronic\nfetal monitoring, providing a rule-based algorithm for interpreting CTG signals by\nanalysing FHR variability and responses to uterine contractions [1]. Despite its wide\nadoption, studies reveal that CTG interpretation using DR criteria is often marred by\nsubstantial inter-observer variability, with agreement rates between clinicians ranging\nfrom 35% to 92%, largely depending on experience levels [3, 4]. This subjectivity\nraises reliability concerns, as inconsistent interpretations can lead to misclassification\nand potentially adverse outcomes. Neppelenbroek et al. [13] further underscored this\nissue, showing that only professionals with high training consistency in controlled\nenvironments achieved satisfactory inter- and intra-observer agreement, which varied\nsignificantly from 64% to 98%. Jones et al. [14] evaluated the performance of the DR\nalgorithm in predicting adverse outcomes, using 4,196 antepartum FHR recordings and\nexcluding those with incomplete data or terminated analyses. Their findings indicated\nthat while the DR algorithm showed high sensitivity (91.7%) for detecting fetal well-\nbeing, its specificity for adverse outcomes was low (15.6%), limiting its predictive\nutility in high-risk pregnancies.\nTo mitigate the subjectivity and variability of manual CTG assessment, machine\nlearning approaches have been proposed as alternatives to improve reliability and inter-\npretative accuracy. Traditional ML methods such as the EMD-SVM model by Krupa\net al. [15] employed Empirical Mode Decomposition (EMD) for feature extraction and\nSupport Vector Machine (SVM) classification, achieving 87% accuracy with a high\nagreement (kappa value 0.923) with expert evaluations. Georgieva et al. [16] employed\nan ensemble of Artificial Neural Networks (ANNs) for adverse outcome prediction,\nachieving a sensitivity of 60.3% and specificity of 67.5%. Fei et al. [17] developed an\nAdaptive Neuro-Fuzzy Inference System (FCM-ANFIS) that achieved 96.39% accu-\nracy, outperforming conventional classifiers. Chen et al. [18] introduced a Deep Forest\nmodel that handled overlapping normal and suspicious classifications with 92.64%\naccuracy on the UCI dataset [19]. However, while these traditional approaches demon-\nstrated some promise, their limited feature extraction capabilities often restricted their\ngeneralisation across diverse datasets.\nWith advancements in deep learning, more sophisticated models like Convolutional\nNeural Networks (CNNs) and Long Short-Term Memory (LSTM) networks gained\ntraction in CTG analysis, allowing for improved temporal feature extraction and pat-\ntern recognition in FHR variability. Petrozziello et al. [20] applied Multimodal CNNs\nto predict fetal distress by processing FHR and uterine contraction data, achieving a\nTrue Positive Rate (TPR) of 53% at a 15% False Positive Rate (FPR). Ogasawara et al.\n[21] proposed CTG-net, a three-layer CNN model that achieved an AUC of 0.73\u00b10.04,\noutperforming SVM and k-means clustering. Xiao et al. [22] used a multiscale CNN-\nBiLSTM model to capture spatial and temporal features, reaching a sensitivity of\n61.97% and specificity of 73.82% on the CTU-UHB dataset [23]. Fei et al. [24] devel-\noped a Multimodal Bidirectional Gated Recurrent Unit (MBiGRU) network, achieving\nan AUC of 93.27%. Although these DL approaches showed an improved ability to\nextract intricate temporal patterns, their capacity to capture long-range dependencies\nin non-stationary CTG data and to generalise was still limited.\nIn recent years, hybrid models have emerged, integrating diverse neural architec-\ntures to harness complementary strengths. For instance, Spairani et al. [25] combined\na Multi-Layer Perceptron (MLP) and CNN for mixed quantitative and image-derived\ninputs, achieving an accuracy of 80.1% but showing limited sensitivity. Feng et al. [26]\napplied an ensemble of SVM, eXtreme Gradient Boosting (XGB) and random forest\nmodels, reaching 0.9539 accuracy on the UCI dataset. Zhang et al. [27] developed DT-\nCTNet, which combined an XGBoost ensemble and CNN-based tracking, achieving a\ndiagnostic accuracy of 96.3%. Chen et al. [28] introduced an Unsupervised Domain\nAdaptation (UDA) model, DANNMCTG, to handle cross-device discrepancies, achiev-\ning an accuracy of 71.25%. These models have demonstrated potential for enhanced\ngeneralisation and interpretability; however, their performance frequently depends on\nextensive feature engineering and high computational demands.\nThe emergence of self-attention mechanisms and transformer-based models has\nshifted the landscape in time-series classification, offering enhanced capacity to capture\ncomplex temporal dependencies. For CTG data, self-attention models have shown the\npotential to address the limitations of CNNs and RNNs by dynamically focusing on\nrelevant parts of the signal. Asfaw et al. [29] introduced a Gated Convolutional Multi-\nHead Attention (GCMHA) model, which combined CNNs with attention mechanisms\nto refine temporal dependencies, achieving a sensitivity of 49.08% at a 15% FPR.\nWu et al. [30] proposed the Ensemble Transformer-Convolutional Neural Network\n(ETCNN), designed to capture both short and long-term features by segmenting FHR\npatterns into acceleration and deceleration phases. ETCNN demonstrated improved\nsegmentation accuracy, achieving an 80.68% accuracy for accelerations and a 78.24%\naccuracy for decelerations.\nBeyond general transformer-based models, emerging research [10] suggests that\npatch-based transformers offer unique advantages for time-series analysis. By segment-\ning sequences into patches, these models reduce input dimensionality while preserving\nlocal and global temporal information, improving feature extraction and computa-\ntional efficiency. Patch-based segmentation has enhanced computational efficiency and\nimproved feature representation in complex, non-stationary data, making it a promis-\ning approach for CTG classification. The design of patch-based transformers aligns\nwell with CTG data requirements, where signal length and variability are considerable\nchallenges for conventional approaches."}, {"title": "3 Proposed Method", "content": "The Patch Cardiotocography Transformer (PatchCTG) is a transformer-based archi-\ntecture designed to classify CTG signals into binary outcomes: adverse or normal.\nIt builds upon the time series forecasting transformer architecture [31], which has\nbeen adapted for the specific task of CTG classification. PatchCTG focuses on time\nseries classification using FHR and TOCO signals, each consisting of L = 960 time\nsteps (corresponding to one hour of recording). PatchCTG efficiently extracts tem-\nporal dependencies from CTG signals through a workflow that includes instance\nnormalisation for mitigating distribution shifts, patching for sequence compression,\nchannel-independent processing, a Transformer backbone for temporal modelling and\na classification head with pooling, dense layer and sigmoid activation for prediction.\nIn time-series analysis, particularly in clinical datasets, the characteristics of input\nsignals can vary significantly due to various factors such as variations between patients\nand recording conditions. To mitigate the resulting distribution shift effects between\ntraining and testing data, PatchCTG adopts instance normalisation, which has\nproven effective in reducing such distribution issues [32, 33]. Instance normalisa-\ntion independently standardises each univariate channel (FHR or TOCO) to have\nzero mean and unit variance. It recalculates mean and variance statistics for each\nsequence during inference, which helps to reduce patient-to-patient variability and\nensures robustness across various recording conditions. Specifically, each univariate\nchannel (FHR or TOCO) is independently standardised to have zero mean and unit\nvariance. Given an input time series $x^{(i)} = (x_1^{(i)}, x_2^{(i)},...,x_L^{(i)})$, the normalised version\n$\\hat{x}^{(i)}$ is computed as:\n$$\\hat{x}^{(i)} = \\frac{x^{(i)} - \\mu^{(i)}}{\\sigma^{(i)}}$$\nwhere $\\mu^{(i)}$ and $\\sigma^{(i)}$ are the mean and standard deviation of $x^{(i)}$, respectively. This\nensures that the model is robust to scale variations and more stable during training,\nwhich is essential for effective learning from clinical data, often involving different\nbaselines for each patient and varied signal characteristics.\nThe PatchCTG method adopts a patching mechanism, which segments each uni-\nvariate signal into a sequence of patches, inspired by the success of patch-based\nstrategies in time-series forecasting [31, 34]. Patching effectively captures both local\nand global temporal trends, reduces input sequence length, and facilitates smoother\ntemporal transitions in medical time series where gradual physiological changes occur.\nGiven an input univariate signal $x^{(i)}$, the patching mechanism divides $x^{(i)}$ into non-\noverlapping or overlapping patches of fixed length $P$. Specifically, a patch $p_j^{(i)}$ of the\nsignal is defined as:\n$$p_j^{(i)} = (x_{jS+1}^{(i)}, x_{jS+2}^{(i)},..., x_{jS+P}^{(i)}), j = 0, 1, ..., N - 1,$$\nwhere $S$ is the stride (step size), $P$ is the patch length, and $N$ is the total number\nof patches given by:\n$$N = \\frac{L-P}{S} + 1.$$\nThe stride $S$ controls the overlap between consecutive patches. By adjusting the\nstride, PatchCTG can create overlapping patches ($S < P$) to capture smoother tran-\nsitions across temporal segments or non-overlapping patches ($S = P$) to focus on\ndistinct episodes. Patching reduces the input sequence length by representing each\npatch as a single token, thereby enhancing computational efficiency. Each patch also\nretains local semantic information, which is critical for understanding physiological\ntrends and events, such as identifying patterns in FHR that correlate with uterine\ncontractions.\nPatchCTG employs a channel-independent Transformer encoder for each\nunivariate signal (FHR or TOCO). By processing each channel independently, the\nmodel learns unique temporal dynamics for each physiological signal before com-\nbining them for classification. The input encoding begins by projecting each patch\nfrom its original input space into a higher-dimensional latent space using a linear\ntransformation:\n$$z_j^{(i)} = W_p p_j^{(i)} + W_{pos}^{(i)}, W_p \\in \\mathbb{R}^{P \\times d},$$\nwhere $d$ is the latent dimensionality of the patch representation. To preserve\ntemporal information, positional encodings $W_{pos} \\in \\mathbb{R}^{N \\times d}$ are added to each patch\nrepresentation, resulting in:\n$$e_j^{(i)} = z_j^{(i)} + W_{pos}^{(i)},$$\nwhere $e_j^{(i)}$ represents the encoded patch with temporal information. This positional\nencoding ensures that the model can learn to interpret the sequential changes in CTG\nsignals, which is important for understanding FHR decelerations or accelerations in\nresponse to uterine contractions.\nThe Transformer backbone consists of L encoder layers, each comprising two\nsub-layers:\n\u2022 Multi-Head Self-Attention (MHSA): The multi-head self-attention mechanism\nenables PatchCTG to learn relationships between different patches within a given\nsignal, providing a comprehensive view of temporal dependencies across the time\nseries [34]. Given query, key, and value matrices Q, K, and V, the attention output\nA is computed as:\n$$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}}) V,$$\nwhere $d_k$ is the dimensionality of the key vectors, and the scaling factor $\\frac{1}{\\sqrt{d_k}}$ ensures\nnumerical stability.\n\u2022 Feed-Forward Network (FFN): The feed-forward network is applied to each output of\nthe MHSA. It consists of two linear transformations with a non-linearity in between\n(Gaussian Error Linear Unit, GELU). Given an input vector $h_i$, the FFN output $f_i$\nis given by:\n$$f_i = GELU(W_1h_i + b_1)W_2 + b_2,$$\nwhere $W_1, W_2$ are learnable weight matrices, and $b_1, b_2$ are biases. Residual con-\nnections and layer normalization are employed to stabilize training and facilitate\ngradient flow across multiple layers.\nPatchCTG handles missing values using a masking mechanism, which prevents\nthe model from learning spurious relationships from incomplete data during attention\ncomputations. After processing the input patches through the Transformer backbone,\nPatchCTG applies global average pooling across the time dimension. Given the\noutput representations ${e_j^{(i)}}_{j=1}^N$, global average pooling computes:\n$$g^{(i)} = \\frac{1}{N} \\sum_{j=1}^{N} e_j^{(i)}$$\nwhere $g^{(i)}$ is the aggregated feature representation for each input sequence. By\nusing global pooling, PatchCTG extracts meaningful summary statistics across the\nentire time horizon of each channel, capturing short-term variations and long-term\ntrends, both of which may have clinical relevance in determining adverse outcomes.\nThe pooled representation is then passed to a classification head, consisting of a\ndense layer and a sigmoid activation function, which maps the aggregated features to\na single output value:"}, {"title": "4 Experiments and Results", "content": "The dataset used in this study was sourced from the Oxford Maternity (OXMAT)\ndataset [11], a comprehensive repository of CTG traces and maternal-neonatal health\nrecords collected from the Oxford University Hospitals maternity database at John\nRadcliffe Hospital. The OXMAT dataset contains over 211,000 CTGs, collected from\nmore than 250,000 pregnancies between January 1991 and February 2024. Alongside\nCTG signals, the dataset includes over 250 clinical variables, which cover a range of\nmaternal and neonatal outcomes such as Apgar scores, cord blood gas (CBG) values,\nbirthweights, delivery types, medications and other related health parameters. For\nthe development of PatchCTG, we adopted the dataset preprocessing methodology\ndescribed in [35] for cohort development and outcome categorisation. Raw digital\nCTG traces were extracted from singleton pregnancies between gestational weeks 37+0\nand 41+6. The preprocessing involved removing CTG traces that were missing more\nthan 30% of their signal information or had aborted Dawes-Redman analysis before\nevaluation. Only traces that had undergone successful Dawes-Redman analysis were\nincluded.\nTo establish the Adverse Pregnancy Outcome (APO) cohort, traces acquired within\n7 days prior to delivery were selected to ensure that CTG patterns used for classi-\nfication were temporally related to the outcome. The adverse pregnancy outcomes\nconsidered included acidaemia, stillbirth, asphyxia, extended Special Care Baby Unit\n(SCBU) admission, Hypoxic-Ischaemic Encephalopathy (HIE), low Apgar score and\nneonatal resuscitation at delivery. These outcomes were chosen based on their clinical\nsignificance and correlation with neonatal health risks. To develop the Normal Preg-\nnancy Outcome (NPO) cohort, inclusion and exclusion criteria were applied to identify"}, {"title": "4.2 Hyperparameter Optimisation", "content": "The performance of deep learning model heavily depends on the appropriate selection\nof hyperparameters. Therefore, a comprehensive hyperparameter optimisation pro-\ncess was conducted to determine the best configuration for the PatchCTG model to\naccurately classify CTG signals into binary outcomes (adverse or normal) in terms of\nArea Under the Curve (AUC). The hyperparameter optimisation aimed to enhance\nmodel generalizability while mitigating overfitting, with the objective of maximizing\nthe validation AUC metric. We employed the Optuna hyperparameter optimisation\nframework [12] to perform an efficient and systematic search across a wide hyperpa-\nrameter space. The optimisation process was formulated as a Bayesian optimisation\nproblem, allowing us to iteratively explore the search space and focus on promising\nhyperparameter combinations based on previous trials. The goal was to identify the\nbest hyperparameters that achieve the highest AUC score on the validation set, ensur-\ning reliable binary classification of adverse pregnancy outcomes. The hyperparameter\nsearch covered various components of the PatchCTG architecture, including:\n\u2022 Transformer Encoder Layers: The number of encoder layers was varied from 3 to 6 to\ndetermine the optimal model depth that effectively captures temporal dependencies\nwithout leading to overfitting.\n\u2022 Attention Heads: The number of attention heads was tuned from the set {4, 8, 16, 32}\nto evaluate the impact of multi-head attention mechanisms on capturing complex\ntemporal relationships.\n\u2022 Model Dimension: The embedding dimensionality was tuned from the set\n{64, 128, 192, 256, 384, 512, 640}, where higher dimensionality allowed for richer\nfeature representations, while lower dimensionality reduced computational cost.\n\u2022 Feedforward Layer Dimension: The hidden layer dimensionality within the feedfor-\nward network was adjusted from the set {128, 192, 256, 320, 384, 512, 640} to balance\nthe expressiveness and complexity of the model.\n\u2022 Dropout Rates: Dropout rates for different components (transformer layers, fully\nconnected layers, and attention heads) were tuned in the range of [0.1, 0.5] to control\noverfitting and improve model robustness.\n\u2022 Learning Rate: The learning rate was selected from the set\n{1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 5e-4, 1e-3} to identify the most suitable rate for efficient\nconvergence of the model.\n\u2022 Batch Size: The batch size was varied from {16, 32, 48, 64} to determine the optimal\ntrade-off between convergence stability and computational efficiency.\n\u2022 Patching Parameters: The patch length and stride for sequence patching were tuned\nfrom the set {4,8,16,32} and {4,8,16}, respectively, to explore different levels of\nsequence compression and overlapping temporal regions.\n\u2022 Activation Function: Activation functions {ReLU, GELU, ELU} were evaluated to\ndetermine which non-linearity yielded the most expressive feature representations\nfor the CTG data."}, {"title": "4.3 Training, Finetuning and Testing", "content": "The PatchCTG model underwent a comprehensive training, finetuning and evaluation\nprocedure to assess its effectiveness in classifying CTG signals into APO and NPO\nclasses. The process involved training on a large, balanced dataset, finetuning on\nspecific subsets and assessing generalizability and performance stability across different\nconfigurations and cohorts. The performance of PatchCTG was primarily evaluated\nusing the Area Under the Curve (AUC) metric, along with other classification metrics\nsuch as sensitivity, specificity, Positive Predictive Value (PPV), Negative Predictive\nValue (NPV), F1 score and accuracy.\nThe initial training phase involved the entire dataset, consisting of 20,589 CTGs\n(10,890 NPOs and 9,699 APOs), using the hyperparameters that were optimised\nthrough the Optuna framework. The PatchCTG model was trained for a total of 50\nepochs, with an early stopping criterion based on validation AUC, to ensure that the\nmodel generalised well without overfitting. The training-validation split was performed\nwith an 80-20 ratio, providing 16,471 samples for training and 4,118 for validation and\ntesting.\nFigure 1 presents the training and validation progress plots, showing the conver-\ngence to an AUC of approximately 77%. The ROC curve (Figure 1) demonstrates the\nability of PatchCTG to distinguish between adverse and normal outcomes, with the\nAUC well above the random guess. The performance metrics obtained for different\nclassification thresholds, including default threshold, Youden's index threshold, high\nsensitivity threshold and high specificity threshold, are presented in Figure 3. These\nresults indicate a well-balanced trade-off between sensitivity and specificity, depend-\ning on the threshold selected. At Youden's index threshold, PatchCTG achieved a\nsensitivity of 57%, specificity of 88%, PPV of 81%, and an F1 score of 67%, which\nhighlights the robustness of the model for clinical decision support.\nTo evaluate the impact of the temporal gap between CTG recording and delivery\noutcome, the PatchCTG model was assessed with varying thresholds of days to delivery\nfor the APO cohort. Specifically, the model was evaluated on subsets of the dataset\nwith APO cases recorded within 1 to 7 days before delivery (Figure 2). The AUC\nincreased from approximately 74% to 77% as the threshold increased from 1 to 7 days\nbefore delivery. The results indicated that CTG signals collected closer to delivery had\na slightly lower predictive power compared to those recorded over a longer duration\npreceding delivery. This could be due to increased variability and abrupt changes"}, {"title": "5 Discussion", "content": "PatchCTG demonstrated robust performance with an AUC of 77%, highlighting its\ncapacity to accurately classify CTG recordings as adverse or normal outcomes in the\nantepartum setting. Compared to traditional CTG analysis models, such as the Dawes-\nRedman system [1] and machine learning approaches [15, 17], PatchCTG provides a\nmore consistent, objective evaluation, addressing long-standing issues in CTG interpre-\ntation, including inter-observer variability and limited predictive capability for adverse\noutcomes. This consistency is critical given the limitations of prior models, which have\nshown lower specificity and varying sensitivities, often requiring complex feature engi-\nneering to capture nuanced temporal patterns in FHR signals [16, 18]. The integration\nof patch-based segmentation and self-attention mechanisms in PatchCTG represents\na significant advancement in CTG analysis, drawing on transformer architectures that\nhave shown promise in other medical time-series applications [8]. By segmenting CTG\nsignals into patches and applying instance normalisation and channel-independent pro-\ncessing, PatchCTG efficiently captures both local and global temporal dependencies,\nwhich are essential for interpreting the physiological dynamics in FHR and uterine con-\ntraction signals. Unlike convolutional models [20, 24] that excel in extracting spatial\nfeatures but can struggle with long-range dependencies, PatchCTG leverages the self-\nattention mechanism to dynamically adjust its focus across signal patches, enhancing\nits ability to detect subtle patterns associated with adverse outcomes.\nEvaluating PatchCTG under different temporal thresholds demonstrated its gener-\nalisability across various intervals before delivery, with some reduction in performance\nfor signals recorded closer to delivery. This degradation may reflect the increased\nvariability and subtle changes in physiological patterns as delivery approaches, high-\nlighting the need for additional clinical markers or features to improve prediction\naccuracy during these critical hours. Importantly, the ability of the model to leverage\nbroader temporal data during pretraining, with finetuning on closer-to-delivery sig-\nnals, illustrates an approach beneficial for clinical settings where data from different\ntime windows may vary in availability and relevance. The performance of PatchCTG\nacross different classification thresholds also underscores its adaptability for clinical\npriorities. By adjusting the threshold to increase sensitivity, the model can be tuned to\nminimise false negatives, which is essential in high-risk clinical scenarios where missing\nan adverse outcome could lead to severe consequences. Conversely, a high specificity\nthreshold could help reduce unnecessary interventions when the priority is to avoid\nfalse positives. This flexibility makes PatchCTG a valuable tool for aiding clinical\ndecision-making in fetal monitoring.\nBenchmark comparisons further underscore the strong performance of PatchCTG\nrelative to an optimized hybrid deep learning model and the DR algorithm. With an\nAUC of 77%, PatchCTG outperformed the CNN-LSTM-Transformer model, which\nachieved an AUC of 73.5%, and the Dawes-Redman algorithm, which had an AUC of\n67%. This comparison underscores the enhanced capability of PatchCTG to capture\ncritical temporal dependencies while maintaining high predictive accuracy, particularly\ncompared to conventional methods that exhibit lower specificity and sensitivity trade-\noffs. Overall, PatchCTG addresses gaps identified in prior deep learning methods for\nCTG analysis by efficiently capturing temporal dependencies, reducing subjectivity\nand enabling adaptable outputs. Future work should explore integrating multimodal\nbiomedical and clinical data to further enhance predictive power, particularly as deliv-\nery approaches and validation across larger, more diverse datasets to ensure model\ngeneralisability and real-world impact."}, {"title": "6 Conclusion", "content": "This study introduces PatchCTG, a transformer model explicitly designed for antepar-\ntum CTG-based fetal health monitoring. Achieving an AUC of 77%, PatchCTG\noutperformed the Dawes-Redman system (AUC of 67%) and an optimised hybrid deep\nlearning model (AUC of 73.5%). The ability of PatchCTG to capture complex local\nand global temporal dependencies, along with its adaptability across varying time-\nframes, positions it as a valuable tool for clinical application, offering greater reliability\nand objectivity than traditional methods. Its adaptable sensitivity and specificity\nthresholds further enhance its clinical utility, allowing for precision adjustments that\nprioritise sensitivity in high-risk cases or specificity to minimise unnecessary inter-\nventions. This flexibility, combined with the capacity of PatchCTG to generalise\nacross different temporal windows, supports a robust approach to CTG interpreta-\ntion that can help reduce the subjectivity common in manual assessments. While the\nperformance of PatchCTG is promising, further enhancements could be achieved by\nincorporating additional data sources and clinical markers, particularly to improve\npredictive accuracy closer to delivery. Future work will focus on expanding clinical val-\nidation across diverse datasets and exploring the integration of multimodal inputs to\nenhance fetal health assessment and support more timely, informed clinical decisions."}]}