{"title": "Characterising Simulation-Based Program Equilibria", "authors": ["Emery Cooper", "Caspar Oesterheld", "Vincent Conitzer"], "abstract": "In Tennenholtz's program equilibrium, players of a game submit programs to play on their behalf. Each program receives the other programs' source code and outputs an action. This can model interactions involving Al agents, mutually transparent institutions, or commitments. Tennenholtz (2004) proves a folk theorem for program games, but the equilibria constructed are very brittle. We therefore consider simulation-based programs \u2013 i.e., programs that work by running opponents' programs. These are relatively robust (in particular, two programs that act the same are treated the same) and are more practical than proof-based approaches. Oesterheld's (2019) eGrounded Bot is such an approach. Unfortunately, it is not generally applicable to games of three or more players, and only allows for a limited range of equilibria in two player games. In this paper, we propose a generalisation to Oesterheld's (2019) eGrounded Bot. We prove a folk theorem for our programs in a setting with access to a shared source of randomness. We then characterise their equilibria in a setting without shared randomness. Both with and without shared randomness, we achieve a much wider range of equilibria than Oesterheld's (2019) \u20acGrounded Bot. Finally, we explore the limits of simulation-based program equilibrium, showing that the Tennenholtz folk theorem cannot be attained by simulation-based programs without access to shared randomness.", "sections": [{"title": "1 Introduction", "content": "Consider a game in which, rather than choosing actions, players submit programs (McAfee 1984; Howard 1988; Rubinstein 1998, Sect. 10.4; Tennenholtz 2004). Programs receive as input the source code of the opponents' programs, and output actions. E.g., in the (one-shot) prisoner's dilemma, the programs might be CliqueBots: 'cooperate if the other program is equal to this program, else defect'. CliqueBots form a cooperative equilibrium. This illustrates how such games \u2013 program games \u2013 allow for new equilibria.\nTraditional game-theoretic concepts, such as Nash equilibrium, have been developed without mutual transparency in mind, and may therefore be less relevant to interactions involving AI agents whose source codes might be available to other agents (Conitzer and Oesterheld 2023). Program games could model interactions between principals designing AI agents, interactions between Al agents themselves, or smart contracts. This could include interactions between large language models where the programs are prompts provided by humans and interpreted by the models. Program games can also model some interactions between hu-mans, such as those involving mutually conditional commit-ments, or transparent institutions (Critch, Dennis, and Russell 2022).\nTennenholtz (2004) proves a folk theorem for program equilibria (cf. Rubinstein 1998, Sect. 10.4): any set of feasible and individually rational (i.e., better-than-minimax) payoffs of a game is achievable in a program equilibrium. How-ever, this result is proved using programs based on syntactic comparison, such as the above CliqueBot in the prisoner's dilemma. Such equilibria are extremely fragile: if someone, perhaps from a different community, writes a slightly different version of CliqueBot (CliqueBot'), then CliqueBot and CliqueBot' will defect on each other.\nPrevious authors have proposed different ways of achieving more robust program equilibria. One proposal is that of L\u00f6bian programs (Barasz et al. 2014; Critch 2019; Critch, Dennis, and Russell 2022; Oesterheld 2022). In the pris-oner's dilemma, the L\u00f6bian FairBot roughly works by coop-erating if and only if it can prove the opponent cooperates. The L\u00f6bian FairBots cooperate against each other. Unfortu-nately, there are practical difficulties with this approach. If the opponent program is not very interpretable (e.g., a large neural net), it may be difficult or impossible to prove things about its output.\nWe therefore turn our attention to simulation-based ap-proaches, such as Oesterheld's (2019) eGroundedFairBot and Grounded Bot. In the prisoner's dilemma, the GroundedFairBot cooperates with probability e and oth-erwise simulates the opponent and cooperates if and only if in the simulation the other player cooperates. If two GroundedFairBots play against each other, the simulated player may in turn simulate the other, etc., but eventually the e-probability case will be triggered, ensuring termina-tion. This program is easy to implement and can be used against programs that are not very interpretable.\nWe can view Oesterheld's (2019) eGrounded Bot as sim-ulating a repeated game. With probability e, the program is on the first 'time step', and does not observe any previous ac-tions. Otherwise, it simulates the other program. If the other program is another eGrounded Bot, that program will again"}, {"title": "2 Background and Preliminaries", "content": "We will sometimes denote the tuple $(x_1,...,x_n)$ by $x_{1:n}$, and the tuple $(x_1,..., x_{i\u22121}, x_{i+1},...,x_n)$ by $x_{-i}$. Similarly, we will use 'players -i' to refer to all players of a game but player i.\nWe assume familiarity with game theory. See, e.g., Osborne (2004) for an introduction. We introduce some definitions for normal-form games.\nAn n-player normal-form game comprises finite action sets $A_i$ and utility functions $u_i: \\prod_{i=1}^{n} A_i \u2192 \\mathbb{R}$ for each player $i \u2208 \\{1, ... n\\}$. A strategy for player i is a probability dis-tribution $s_i \u2208 \\Delta(A_i)$ over actions for player i. A strategy profile is a tuple $(s_1,... s_n)$ of strategies for all players.\nGiven a joint distribution over outcomes $(a_1,..., a_n)$, the expected utility for player i is, writing $A_i$ for the ith player's action (a random variable), $E [u_i] = E [u_i(A_{1:n})] = \\sum_{a_{1:n}} P(A_{1:n} = a_{1:n}) u_i(a_1,..., a_n)$. When players' ac-tions are independent, with player i following strategy $s_i$ for each i, write $u_i(s_1,...,s_n) := E [u_i(A_{1:n})] = \\sum_{a_{1:n}} u_i (a_{1:n}) \\prod_j P (A_j = a_j)$.\nWe call a set of expected payoffs $v_{1:n}$ individually ra-tional (without coordination) if it is at least as good for each player as that player's minimax utility, i.e., $v_i \u2265 \\min_{s_{-i} \u2208 \\prod_{j \\neq i} \\Delta(A_j)} \\max_{a_i \u2208 A_i} u_i (s_{-i}, a_i)$ for all i. Say $v_{1:n}$ is strictly individually rational if this inequality is strict for all i.\nSay that a set of payoffs $v_{1:n}$ is feasible (without corre-lation) if it is achieved by some set of (independently sam-pled) strategies, i.e., if for some $s_{1:n}$, for all i, $v_i = u_i(s_{1:n})$. Meanwhile, $v_{1:n}$ is feasible with correlation if it is achieved in expectation by some set of strategies not sampled inde-pendently: i.e., if when $A_{1:n}$ follows some joint distribution over $\\prod_{i=1} A_i$, we have $v_i = E [u_i(A_{1:n})]$.\nWe now define program equilibrium (Tennenholtz 2004). We will consider programs that are themselves deterministic, but take as input one or more ran-dom sequences. We also assume that programs always have access to their own source code. Write apply for the func-tion that takes as input a program and a tuple of input ar-guments and runs the program on the input arguments, out-putting whatever the program outputs (if anything)."}, {"title": "3 Correlated Program Games", "content": "We first consider correlated program games. We use an additional variant on apply calls for this set-ting: Define apply*$(p_i, (p_{-i}, (r_m), (x'_m)))$ to be equal to apply$(p_i, (p_{-i}, (r_m), (x'_m)))$ if the variables $(x'_m)$ are not accessed except inside further apply* calls, and $R_i$, a special symbol to indicate that the private random sequence was accessed, otherwise. For example, in the random-access machine model this would trigger whenever the simulated program runs the command for reading (with either direct or indirect addressing) one of memory addresses containing the independent random bits (e.g., loading from, comparing with the contents of, or performing an arithmetic operation using the contents of such a memory location, in the formal-ism of 'MIX' from Knuth (1997, Sec. 1.3.1, Volume 1)). We do not include simply passing the $(x'_m)$ on via apply calls as"}, {"title": "4 Epsilon-Grounded Simulation without Shared Randomness", "content": "We now consider uncorrelated program games, where no correlated random sequence is available to the programs, so that programs can only randomise independently. We present our algorithm, the uncorrelated eGrounded Bot, in Algorithm 2. It works almost identically to correlated \u00abGrounded Bots: it determines its time step based on the first element of the random sequence that is less than e, and then simulates the other programs at earlier time steps."}, {"title": "5 General Simulation-based Programs", "content": "We now turn to more general simulation-based programs, in the uncorrelated setting from the last section. Can we do better than the uncorrelated (Grounded Bots? We start by defining the class of programs we are interested in.\nSay a program $p_i$ is simulationist if it only refer-ences the input programs, $p_{-i}$, via calls of the form apply$(p_j, (p'_{-j}, (r'_m)))$ where each $p'$ is either one of the in-put programs, or is itself simulationist, $(r'_m)$ is any sequence, and we allow $i = j$.\nThis definition is inductive e.g., uncorrelated eGrounded Bots are simulationist, as are, say, Defect-Bots. Meanwhile, a program p that ran the input programs on a mix of such programs and input programs would be simulationist, as would a program q that ran the input programs on p. Note that we exclude programs that run the input programs on programs that are not simulationist. We explain this further in Appendix G.\nWe give here a simple example of a game in which it is possible to sustain a profile of equilibrium payoffs with some simulationist programs, but not with uncorrelated eGrounded Bots."}]}