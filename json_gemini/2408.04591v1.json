{"title": "HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts", "authors": ["Hongjun Wang", "Sagar Vaze", "Kai Han"], "abstract": "Generalized Category Discovery (GCD) is a challenging task in which, given a partially labelled dataset, models must categorize all unlabelled instances, regardless of whether they come from labelled categories or from new ones. In this paper, we challenge a remaining assumption in this task: that all images share the same domain. Specifically, we introduce a new task and method to handle GCD when the unlabelled data also contains images from different domains to the labelled set. Our proposed 'HiLo' networks extract High-level semantic and Low-level domain features, before minimizing the mutual information between the representations. Our intuition is that the clusterings based on domain information and semantic information should be independent. We further extend our method with a specialized domain augmentation tailored for the GCD task, as well as a curriculum learning approach. Finally, we construct a benchmark from corrupted fine-grained datasets as well as a large-scale evaluation on DomainNet with real-world domain shifts, reimplementing a number of GCD baselines in this setting. We demonstrate that HiLo outperforms SoTA category discovery models by a large margin on all evaluations.", "sections": [{"title": "Introduction", "content": "The task of category discovery [1] has recently gained substantial interest in the computer vision community [2-7]. The task is to leverage knowledge from a number of labelled images, in order to discover and cluster images from novel classes in unlabelled data. Such a task naturally occurs in many practical settings; from products in a supermarket, to animals in the wild, to street objects for an autonomous vehicle. Specifically, Generalized Category Discovery (GCD) [8] has recently emerged as a challenging variant of the problem in which the unlabelled data can contain both instances from 'seen' and 'unseen' classes. As such, the problem is succinctly phrased as: \"given a dataset, some of which is labelled, categorise all unlabelled instances (whether or not they come from labelled classes)\". This is more realistic and challenging than conventional Semi-Supervised Learning (SSL) [9], which aims to learn a strong model to recognize objects using both labelled and unlabelled data, under the assumption that the unlabelled samples belong to the same classes as the labelled data.\nIn this paper, we challenge a key, but often ignored, assumption in this setting: GCD methods still assume that all instances in the unlabelled set come from the same domain as the labelled data. In practise, unlabelled images may not only contain novel categories, but also exhibit low-level covariate shift [10, 11]. It has long been established that the performance of image classifiers degrades substantially in the presence of such shifts [12-14] and, indeed, we find that existing GCD models perform poorly in such a setting. Compared to related literature in, for instance, domain adaptation [15\u201317] or domain generalization [18, 19] the task proposed here presents a dual challenge: models must be robust to the low-level covariate shift while remaining sensitive to semantic novelty.\nConcretely, we tackle a task in which a model is given access to labelled data from a source domain. It is further given access to a pool of unlabelled data, in which images may come from either the source domain or new domains, and whose categories may come from the labelled classes or from new ones (see Figure 1). Such a setting may commonly occur if, for example, images are taken with different cameras or under different weather conditions. Moreover, such a setting is often observed on the web, in which images come from many different domains and with innumerable concepts. We suggest that the ability to cluster novel concepts while accounting for such covariate shift will be an important factor in fully leveraging web-scale data.\nTo tackle these problems, we introduce the 'HiLo' architecture and learning framework. The HiLo architecture extracts both 'low-level' (early layer) and 'high-level' (late layer) features from a vision transformer [20]. While extracting features at multiple stages of the network has been performed in domain adaptation [21-23], we further introduce an explicit loss term to minimise mutual information between the two sets of features (Section 3.2.1). The intuition is that the covariate and semantic information in the data is (by definition) independent, and that the inductive bias of deep architectures is likely to represent low-level covariate information in early layers, and abstract semantic information in later ones [24, 25]. Next, we take inspiration from a strong method from the domain adaptation field, PatchMix [17], which works by performing mixup augmentation in the embedding space of a pretrained transformer. While naive application of this method does not account for semantic novelty in unlabelled data, we extend the PatchMix objective to allow training with both a self-supervised contrastive objective (Section 3.2.2), and a semantic clustering loss (Section 3.2.2). With these changes, the PatchMix style augmentation is tailored to leverage both the labelled and unlabelled data available in the GCD setting. Our 'HiLo' feature design in our framework enables the model to disentangle domain and semantic features, while patch mixing allows the model to bridge the domain gap among images and focus more on determining the semantic shifts. Therefore, we introduce the patch mixing idea into our 'HiLo' framework, equipping it with a strong capability to discover novel categories from unlabelled images in the presence of domain shifts.\nFinally, we find that curriculum learning [26\u201328] is particularly applicable to the setting introduced in this work (Section 3.2.3). Specifically, the quality of the learning signal differs substantially across different partitions of the data: from a clean supervised signal on the labelled set; to unsupervised signals from unlabelled data which may or may not come from the same domain and categories. It is non-trivial to train a GCD model to discover novel categories in the presence of both domain shifts and semantic shifts in the unlabelled data. To address this challenge, we introduce a curriculum learning approach which gradually increases the sampling probability weight of samples predicted as from unknown domains, as training proceeds. Our sequential learning process prioritizes the discovery of semantic categories initially and progressively enhances the model's ability to handle covariate shifts, which cannot be achieved by simply adopting existing domain adaptation methods.\nTo evaluate out models, we construct the 'SSB-C' benchmark suite - based on the recent Semantic Shift Benchmark (SSB) [29] \u2013 with domain shifts introduced by synthetic corruptions following ImageNet-C [30]. On this benchmark, as well as on a large-scale DomainNet evaluation with real data [31], we also reimplement a range of performant baselines from the category discovery literature. We find that, on both benchmarks, our method substantially outperforms all existing category discovery models [8, 5, 1, 4].\nIn summary, we make the following key contributions: (i) We formalize a challenging open-world task for category discovery in the presence of domain shifts; (ii) We develop a new method, HiLo, which disentangles covariate and semantic features to tackle the problem, extending state-of-the-art methods from the domain adaptation literature; (iii) We reimplement a range of category discovery models on a benchmark suite containing both fine-grained and coarse-grained datasets, with real and synthetic corruptions. (iv) We demonstrate that, on all datasets, our method substantially outperforms current state-of-the-art category discovery methods with finetuned hyperparamters."}, {"title": "Related work", "content": "Category discovery was firstly studied as novel category discovery (NCD) [1] and recently extended to generalized category discovery (GCD) [8]. GCD extends NCD by including unlabelled images from both labelled and novel categories. Many successful NCD methods have been proposed (e.g., DTC [1], RankStats [2, 3], WTA [6], DualRank [7], OpenMix [32], NCL [33], UNO [4], Spacing loss [34]), they do not address domain shifts. Recent work [35] considers domain shifts in NCD with labelled target domain images. We focus on GCD without any labelled instances from new domains, where unlabelled images may come from multiple novel domains. For GCD, [8] fine-tunes a ViT model using DINO [36] and semi-supervised k-means clustering. ORCA [37] enhances intra-class separability with adaptive margin loss. CiPR [38] uses hierarchical clustering and positive samples for representation learning. SimGCD [5] employs entropy regularization for improved performance. Other methods include [39\u201343]. DCCL [39] dynamically updates visual conceptions. PromptCAL [40] refines affinity graphs in vision transformers. GPC [42] uses a GMM-based method for representation learning and category estimation. \u00b5-GCD [41] applies a student-teacher mechanism. The study of category discovery is attracting increasing efforts, expanding to different challenging scenarios, e.g., the presence of long-tailed data distribution [44, 45], collaborative discovery of novel classes across distributed datasets while maintaining data privacy [46, 47], continual category discovery without forgetting the previously learned categories [48\u201350], etc. The challenge of domain shifts has been considered in the NCD setting by [51] under two critical assumptions, the unlabelled samples are from a disjoint set of categories than the labelled ones, and the unlabelled samples are from a single new domain w.r.t. the labelled data, rendering this setting less practical. In contrast, in this paper, we consider the problem of GCD with domain shifts, relaxing semantic constraints to the GCD setting while taking into account the mixed domains in the unlabelled data. This more realistic and challenging problem, to our knowledge, has not been explored in the literature.\nUnsupervised domain adaptation (UDA) adapts models from a source domain to a target domain, with labelled data from the former and unlabelled data from the latter. UDA methods are categorized into moment matching [13, 52, 53, 14] and adversarial learning [12, 54, 55] methods. DANN, FGDA, DADA are popular examples using a min-max game. MCD and SWD implicitly use adversarial learning with L\u2081 distance and sliced Wasserstein discrepancy, respectively. [56] extracts foreground semantics using class activation maps and mix them with randomly cropped patches from other domains. Mixstyle [25] enhances model generalizability by probabilistically mixing instance-level feature statistics of training samples from different source domains. EFDM [57] applies the Exact Histogram Matching (EHM) algorithm, Sort-Matching, to the empirical Cumulative Distribution Functions (eCDFs) of image features for cross-domain generalization. CGDM [15] leverages cross-domain gradient discrepancy, while [16] couples NWD with a single task-specific classifier with implicit K-Lipschitz constraint. PMTrans [17] aligns the source and target domains with the intermediate domain by employing semi-supervised mixup losses in both feature and label spaces. UDA typically assumes that the source and target domains have a shared label space, while [58] introduces the task of universal domain adaptation, which aims to learn a domain-invariant representation for data from different domains with partially overlapping label spaces. UniOT [59] leverages the optimal transport for partial alignment with adaptive filling to encourage global discrimination and local consistency of samples for universal domain adaptation."}, {"title": "HiLo networks for GCD with domain shifts", "content": "In this section, we start with the problem statement of GCD with domain shifts. Subsequently, we introduce the SimGCD baseline in Section 3.1, which serves as a robust GCD baseline upon which our method is built. Finally, we introduce our HiLo networks for GCD with domain shifts in Section 3.2.\nProblem statement. We define Generalized Category Discovery with domain shifts as the task of classifying images from mixed domains \u03a9 = \u03a9\u00ba\u03b1 \u222a \u03a9 (where \u03a9 \u041f \u03a9 = \u00d8 and \u03a9 may contain multiple domains in practise), only having access to partially labelled samples from domain \u03a9\u00ba. The goal is to assign class labels to the remaining images, whose categories and domains may be seen or unseen in the labelled images. Formally, let D be an open-world dataset consisting of a labelled set D' = {(xi, Yi)}\u2081 [\u039d\u03b9 C X \u00d7 Y and an unlabelled set Du = {xi} 1[\u039d\u2081 C X\u201c. The label space for labelled samples is Y\u00b2 = C\u2081 and for unlabelled samples is Yu = C = C1 \u222a C2, where C, C1, and C2 represent the label sets for 'All', \u2018Old', and \u2018New' categories, respectively. It is important to note that yl \u2286 y|. The objective of GCD is to classify all unlabelled images in Du (from either \u03a9\u03b1 or \u03a9) using only the labels in D\u00b9. This is different from the setting of NCD with domain shift and GCD, which assumes Y' \u2229 Yu = \u00d8 for the former and N\u00ba = \u03a9' with singleton cardinalities for the latter. For notation simplicity, hereafter we omit the subscript i for each image xi."}, {"title": "Background: SimGCD", "content": "SimGCD [5] is a representative end-to-end baseline for GCD, which integrates two primary losses for representation learning and parametric classification: (1) a contrastive loss $L_{rep}$ based on InfoNCE [60] is applied for the representation learning of the feature backbone; and (2) a cross-entropy loss $L_{cls}$ for training a cosine classification head [61], utilizing different image views as pseudo-labels for one another. Following [8], SimGCD employs the ViT model as the backbone containing m Transformer layers. Let F be the feature extractor consisting of these m layers and H be a projection head. For an input image x, a l2-normalised feature can be obtained by $z = H(F(f(x)))$, where f is a standard embedding layer before the multi-head attention layers in the ViT model. The representation loss is\n$L^{rep}(x) = \\frac{1}{\\left|\\mathcal{P}(x)\\right|} \\sum_{z^{+} \\in \\mathcal{P}(x)} -\\log \\sigma(z \\cdot z^{+}; \\tau),$ (1)\nwhere $\u03c3(\u00b7; \u03c4)$ is the softmax operation with a temperature \u03c4 for scaling and P(x) denotes the positive feature set for each \u00e6. Suppose we sample a batch B, which contains labelled images and unlabelled images, denoted as B\u00b9 and Bu, respectively. For each x \u2208 B (either a labelled or unlabelled image), P(x) contains only the feature of a different view of the same image. For each x \u2208 B\u00b9, an additional P(x) including features of other images from the same class and the feature of a different view of the same image is also used for supervised constrastive learning. Likewise, the classification loss can be written as\n$L^{cls}(x) = - \\sum_{w \\in \\mathcal{W}} q \\log \\sigma(z \\cdot w; \\tau),$ (2)\nwhere W is a set of prototypes and each vector w in W represents a l2-normalised learnable class prototype. $z$ is the l2-normalised vector of F(f(x)). For each x \u2208 B, q is the pseudo-label from a sharpened prediction of a different view of the same image. For each x \u2208 B\u00b9, an additional q as the one-hot ground-truth vector is also used for supervised learning. Let $L_{r}$ be the summation of $L^{rep}$ and $L^{cls}$ for simplification, the overall loss can then be written as:\n$\\mathcal{L}_{sim} = \\lambda \\sum_{x \\in \\mathcal{B}} L^{r,c}(x) + (1 - \\lambda) \\sum_{x \\in \\mathcal{B}^l} L^{r}(x) + \\epsilon \\Delta,$ (3)\nwhere B\u00b9 denotes the subset of labelled samples in the current mini-batch, and \u2206 is an entropy maximization term to prevent pseudo-label collapse [62]. Finally, \u03bb and $ \\epsilon $ are hyperparameters, and we refer to the original work for further details [5].\nDespite achieving strong performance on the standard single-domain GCD task, SimGCD struggles in the more realistic scenario in which the unlabelled data exhibits domain shifts. However, due to the lack of consideration for domain shifts in the design of SimGCD, it struggles to achieve satisfactory GCD performance in the presence of domain shifts. Next, we present our HiLo framework, which builds upon SimGCD and introduces three key innovations to effectively handle domain shifts in GCD."}, {"title": "HiLo: High and Low-level Networks", "content": "The architecture of our HiLo framework is outlined in Figure 2. Firstly, we propose a method to disentangle domain features and semantic features using mutual information minimization. Secondly, we introduce patch-wise mixup augmentation in the image embeddings, facilitating knowledge transfer between labelled and unlabelled data across different domains. Lastly, we employ a curriculum sampling scheme that gradually increases the proportion of samples from the unseen domain during training. This curriculum-based approach aids the learning process by initially focusing on easier single-domain discrimination and gradually transitioning to more challenging cross-domain discrimination."}, {"title": "Learning domain-semantic disentangled features for GCD", "content": "As covariate shift observed by new domains $\u03a9_{\\beta}$ in $D^u$ degrades performance, we aim to learn two distinct feature sets encoding domain and semantic aspects by minimizing their mutual information. For each image x, we thus consider that its feature can be partitioned into two parts, depicting domain-specific (e.g., real, sketch) and semantic information (e.g., cat, dog), respectively. However, it is intractable to estimate the mutual information between random variables of semantic and domain in finite high-dimensional space without parametric assumptions [63, 64]. Instead of calculating the exact value, assumptions based on convex conjugate [65] and GAN [66] are utilized for estimation. [67, 68] further demonstrate that this estimation can be achieved without such assumptions. We thus adopt the approach from [68] based on Jensen-Shannon divergence to estimate the mutual information. For each image, instead of considering a single feature vector as $z = H(F(f(x)))$, here we consider two feature vectors, $z_d$ and $z_s$, for domain and semantic information respectively. Inspired by the fact that deeper layers of the model give higher-level features and the shallower layers of the model give lower-level features [69, 25], we use the feature from the very first layer of the ViT as $z_d$ and that from the very last layer as $z_s$. Specifically, we obtain $[z_d, z_s] = H(F(f(x)))$, where H consists of two projection heads, one on the first layer feature of F and the other on the last layer feature of F (see Figure 2). Therefore, the mutual information between domain and semantic features can be approximated by a Jensen-Shannon estimator:\n$L_m = I_{\\Theta}(z_d, z_s) = E_{p(z_d, z_s)} [- \\log (1 + e^{-I_{\\Theta}(z_d, z_s)})] - E_{p(z_d)p(z_s)} [\\log (1 + e^{I_{\\Theta}(z_d, z_s)})],$ (4)\nwhere I is an MLP and an output dimension of 1. I takes the concatenation of $z_s$ and $z_d$ as input and predict a single scalar value. We aim to minimize the expected log-ratio of the joint distribution concerning the product of marginals. Note that here $z_s$ and $z_d$ may come from two different images. In practice, we tile the domain and semantic features of all the images in the mini-batch, and concatenate them, before applying I on all the concatenated features. We then extract the diagonal entries (which are from the marginals) as the first term and the other entries (which are from the joint distribution) as the second term in Equation (4)."}, {"title": "PatchMix contrastive learning", "content": "Mixup [70] is a powerful data augmentation technique that involves blending pairs of samples and their corresponding labels to create new synthetic training examples. It has been shown to be very effective in semi-supervised learning [71], long-tailed recognition [72], etc. In the presence of domain shifts, Mixup has also been shown to be effective in unsupervised domain adaptation [73] and domain generalization [25]. Recently, PMTrans [17] introduced PatchMix, which is a variant of Mixup augmentation by mixing up the embeddings of images in the Transformer-based architecture for domain adaptation. Particularly, for an input image x with label y, PatchMix augments its j-th embedding patch by\n$\\psi(x)_j = \\beta_j \\psi(x)_j + (1 - \\beta_j) \\psi(x')_j,$ (5)\nwhere \u00e6' is an unlabelled image with or without domain shift, $\u03b2_j \u2208 [0, 1]$ is the random mixing proportion for the j-th patch, sampled from Beta distribution, and \u2299 denotes the multiplication operation. A one-hot vector derived from y is then smoothed based on $\u03b2_j$ to supervise the cross-entropy loss to train the classification model. However, this works under the assumption that the out-of-domain samples share the same class space with the in-domain samples, restricting its application to the more practical scenarios where the out-of-domain samples may come from new classes as we consider in the problem of GCD with domain shift. Hence, we devise a PatchMix-based contrastive learning method to address the challenge of GCD in the presence of domain shift. Our approach properly leverages all available samples, including both labelled and unlabelled data, from both in-domain and out-of-domain sources, encompassing both old and new classes. By incorporating these diverse samples, our technique aims to improve the model's ability to handle domain shifts and effectively generalize across different classes."}, {"title": "Curriculum sampling", "content": "As curriculum sampling [26] can effectively enhance the generalization capability of models by gradually increasing the difficulty of the training data, which is also a natural fit to the GCD with domain shift problem. Here, we also introduce a curriculum sampling scheme to further enhance the learning of our HiLo framework. We expect the training to start by focusing on samples from the same domain to learn semantic features and leverage more samples containing the additional challenge of domain shifts in the later training stages. To this end, we devise a difficulty measure $P_{cs}(x|t)$ for each sample \u00e6 at training time step t (i.e., epoch), by considering the portion of samples belonging to each domain. As the unlabelled samples are from multiple domains and we do not have access to the domain label, we run the semi-supervised k-means on all the domain features $z_d$ extracted using the DINO pretrained backbone. Let the resulting clusters along the domain axis be $D_a$ and $D_b$, which corresponds to domains $\u03a9_a^{D^u}$ and $\u03a9_b^{D^u}$ respectively and $D^u = D_a \u222a D_b$. With the above, we then define the sampling probability weight $p_{cs}(x|t)$ for each sample as follows:\n$p_{cs}(x|t) =\\begin{cases}1, & x \\in D^l, \\\\ \\frac{\\left|D^l\\right|}{\\left|D_a\\right|}, & x \\in D_a,\\\\ r_0 + (r' - r_0) 1(t > t'), & x \\in D_b\\end{cases}$ (10)\nwhere 1(\u00b7) is an indicator function, t' is a constant epoch number since which we would like to increase the portion of samples from unknown domains, ro and r' are constant probabilities for samples from unknown domains to be sampled in the earlier stages (i.e., < t') and latter stages (i.e., > t'), t indicates the current training time step. In our formulation, (1) if \u00e6 is a labelled sample, its $p_{cs}(x|t)$ is set to 1, without any discount; (2) if \u00e6 is an unlabelled sample and is in $D_a$ (i.e., predicted as from the seen domain), $p_{cs}(x|t)$ is set to $|D^l|/|D_a|$ (i.e., proportional to the labelled and unlabelled samples from the same domain, as per the sampling strategy used in the conventional GCD without domain shifts [8]); and (3) if \u00e6 is an unlabelled sample and is in $D_b$ (i.e., predicted as from the unseen domain), its $p_{cs}(x|t)$ will increase along with the training after epoch t'.\nIn Appendix D, we provide an approximated theoretical analysis for our method. Theorem 1 suggests (1) that learning on the original domain data first can effectively lower the error bound of category discovery on Du and (2) the domain head that can reliably discriminate original and new domain samples can further reduce this error bound. Theorem 2 suggests that minimizing the mutual information between domain and semantic features can further lower the error bound of category discovery on Du. These theorems further validate the effectiveness of our method from a theoretical perspective."}, {"title": "Experiments", "content": "To validate the effectiveness of our method, we perform various experiments on the largest public datasets with domain shifts, DomainNet [31], containing about 0.6 million images with 345 categories distributed among six domains. Moreover, based on the Semantic Shift Benchmark (SSB) [29] (including CUB [76], Stanford Cars [77], and FGVC-Aircraft [78]), we construct a new corrupted dataset called SSB-C (i.e., CUB-C, Scars-C, and FGVC-C) following [30]. We exclude unrealistic corruptions and corruptions that may lead to domain leakage to ensure that the model does not see any of the domains in SSB-C during training (see Appendix A for details). Overall, we introduce 9 types of corruption and 5 levels of corruption severity for each type, resulting in a dataset 45x larger than SSB. For the semantics axis, on both DomainNet and SSB-C, following [8], we sample a subset of all classes as the old classes and use 50% of the images from these labelled classes to construct $D_{\u03a9^a}$. The remaining images with both old classes and new classes are treated as the unlabelled data $D_{\u03a9^a}^u$. For the domain axis, on DomainNet, we select images from the 'Real' domain as $D_{\u03a9^a}$ and pick one of the remaining domains as $D_{\u03a9_{\\beta}}$ in turn (or include all the remaining domains as $D_{\u03a9_{\\beta}}$). While on SSB-C, we use each dataset in SSB as $D_{\u03a9^a}$ and its corresponding corrupted dataset in SSB-C as $D_{\u03a9_{\\beta}}$. Statistics of the datasets are shown in Table 1.\nEvaluation protocol. For DomainNet, $\u03a9^a = {\u03c9_1}$ and $\u03a9_{\\beta} = {\u03c9_2}$, where w\u2081 stands for different domains. We also experiment with the case where $\u03a9_{\\beta} = {\u03c9_2,..., \u03c9_6}$. We train the models on $D_{\u03a9^a}$ (i.e., $D_{\u03a9^a}^l$ U $D_{\u03a9^a}^u$) and $D_{\u03a9_{\\beta}}$ of all classes without annotations. For SSB-C, $\u03a9^a = {\u03c9_1}$ and $\u03a9_{\\beta} = {\u03c9_2,..., \u03c9_{10}}$ since we have nine types of corruptions. During evaluation, we compare the ground-truth labels yi with the predicted labels \u0177i and measure the clustering accuracy by $ACC = \\frac{1}{D} \\sum_{i=1}^{D} 1(y_i = \\phi(y_i))$, where \u03c6 is the optimal permutation that matches the predicted"}, {"title": "Analysis", "content": "Effectiveness of different components. We validate the effectiveness of different components and design choices for our method in Table 4. As our method is built upon SimGCD, the effectiveness of each component can be observed by comparing its performance with that of SimGCD. We combine SimGCD with the original PatchMix in [17] (row 1) as a strong baseline for our task since these are SoTA methods for GCD and UDA respectively. Rows 2-4 indicate our main conceptual methodological contributions. As can be seen, simply combining SimGCD with the original PatchMix developed for UDA leads to a relatively small influence on the results. The original PatchMix focuses mainly on bridging the domain gap of labelled classes through a semi-supervised loss, which limits its capability on the unseen classes from new domains. After sutbly adapting PatchMix into contrastive learning for GCD (row 2), the unlabelled data containing both domain shifts and semantic shifts can be properly utilized for training, leading to an obvious performance boost on \u03a9. Furthermore, when we disentangle semantic features from domain features (row 3), the model significantly improves performance on both Na and N, demonstrating dissociation of spurious correlations. Curriculum sampling further enhances performance on \u03a9 (row 4).\nImportance of domain-semantic feature disentanglement. To validate the necessity of extracting domain and semantic features from different layers, we experiment on two variants of the model, by attaching both heads in H either to the deepest layer or to the shallowest layer. As shown in rows 5-6 in Table 4, both variants are significantly inferior to our approach using features from different layers. In addition, we further carry out controlled experiments by fixing the layer for one of the two heads while varying the other. In Figure 3 (a), we fix the semantic head to the last layer and vary the 'Shallow' layer for the domain head, from layer 1 to layer 4. As can be seen, attaching the domain head to the earlier layers gives better performance, which also validates that lower-level features are more domain-oriented. Similarly, in Figure 3 (b), we fix the domain head to the first layer and vary the 'Deep' layer for the semantic head, from the last layer to the fourth last layer. We can see that the last layer is the best choice for the semantic head. These results corroborate the importance of domain-semantic feature disentanglement and our design choice of using lower-level features for domain-specific information and higher-level features for semantic semantic-specific information."}, {"title": "Qualitative results", "content": "Here, we provide qualitative results on DomainNet and CUB-C. The attention map offers valuable insights into the focus of Transformer-based models on the input. We obtain the attention maps for the CLS token from multiple attention heads in the final layer of the ViT backbone, highlighting the top 10% most attended patches in Figure 4. We observe that, compared with the baseline, HiLo is much more effective in focusing on the foreground object even in the presence of significant domain shifts (e.g., painting style, foggy weather). This demonstrates that HiLo is robust to domain shifts and remains unaffected by potential spurious correlations between semantic features and low-level statistics."}, {"title": "Conclusion", "content": "In this paper, we study the new and challenging problem of generalized category discovery under domain shifts. To tackle this challenge, we propose the HiLo learning framework, which contains three major innovations, including domain-semantic disentangled feature learning, PatchMix contrastive learning, and a curriculum learning approach. We thoroughly evaluate HiLo on the DomainNet dataset and our constructed SSB-C benchmark, and show that HiLo outperforms SoTA GCD methods for this challenging problem."}]}