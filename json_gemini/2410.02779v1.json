{"title": "Learning variant product relationship and variation attributes\nfrom e-commerce website structures", "authors": ["Pedro Herrero-Vidal", "You-Lin Chen", "Cris Liu", "Prithviraj Sen", "Lichao Wang"], "abstract": "We introduce VARM, variant relationship matcher strategy, to iden-\ntify pairs of variant products in e-commerce catalogs. Traditional\ndefinitions of entity resolution are concerned with whether product\nmentions refer to the same underlying product. However, this fails\nto capture product relationships that are critical for e-commerce\napplications, such as having similar, but not identical, products\nlisted on the same webpage or share reviews. Here, we formulate\na new type of entity resolution in variant product relationships to\ncapture these similar e-commerce product links. In contrast with\nthe traditional definition, the new definition requires both identify-\ning if two products are variant matches of each other and what are\nthe attributes that vary between them. To satisfy these two require-\nments, we developed a strategy that leverages the strengths of both\nencoding and generative Al models. First, we construct a dataset\nthat captures webpage product links, and therefore variant product\nrelationships, to train an encoding LLM to predict variant matches\nfor any given pair of products. Second, we use RAG prompted gen-\nerative LLMs to extract variation and common attributes amongst\ngroups of variant products. To validate our strategy, we evaluated\nmodel performance using real data from one of the world's leading\ne-commerce retailers. The results showed that our strategy outper-\nforms alternative solutions and paves the way to exploiting these\nnew type of product relationships.", "sections": [{"title": "1 INTRODUCTION", "content": "Entity resolution (ER) [4] is an important task in data integration\nwhose goal is to determine whether two mentions refer to the same\nreal-world entity. Industry practitioners and academic researchers\nhave, for long, devised techniques to address ER in various do-\nmains, e.g. resolving social media handles [21], resolving products\nin e-commerce [8]. While ER usually refers to exact ER wherein\ntwo mentions are deemed to match each other if and only if each\nand every attribute of said mentions agree with each other, data\nintegration in e-commerce entails addressing subtle but non-trivial\nversions of the basic ER task. Still, this traditional definition of en-\ntity resolution fails to capture product relationships that are critical\nfor e-commerce catalogs.\nAs illustrated in the e-commerce site screenshot in Figure 1A,\nhighly related products, but not identical products, are listed on the\nsame webpage to facilitate the search. These consolidated webpage\nlistings allow customers to look at the common product attributes\nwhile being able to easily choose amongst the different product\nvariations, given by the variation attributes, such as color or size.\nIdentifying these kind of product relationships not only improves\ne-commerce listings, but it can also be exploited for many other\napplications, such as review sharing or search deduplication. To"}, {"title": "2 RELATED WORK", "content": "Given that ER has been a topic of research for more than half a\ncentury, almost all major approaches of machine learning have\nbeen applied to solve it including supervised and unsupervised\napproaches [6]. More recently, the focus has shifted to deep learn-\ning including bespoke neural networks [17], pre-trained language\nmodels [16] and most recently, generative AI [18-20]. None of"}, {"title": "3 METHODS", "content": "Our variant relationship matching, VARM, strategy can be largely\ndivided into two main tasks (Fig. 2): 1) variant match prediction,\nand 2) identification of variation attributes."}, {"title": "3.1 Variant match prediction", "content": "Each product p can be defined as a structured set of key-value pairs\n p = {(ai, vi)}1<i\u2264k, where a\u00a1 is the attribute name and vi is the\nattribute's value represented as text (see A.1). Given a product pair\n(p1, p2) the encoding model aims to predict match label in a binary\nclassification task.\nDistilBERT was chosen as the encoding model given its compet-\nitive performance on product entity tasks [16, 20], but the strategy\ngeneralizes to alternative model choices. The model has 66M pa-\nrameters, distilled from a 110M parameter teacher model, with"}, {"title": "3.2 Variation attribute identification", "content": "For a set of products in a given variation group, we formulated\nthe variation attribute estimation of VARM as a \"Text-to-Text\" task\ninspired by the recent success of generative AI [7, 13, 23]. Specifi-\ncally, the input is structured as an instruction that encapsulates the\ntext attributes for all the products belonging to a given variation\ngroup. Therefore, for each given variation group, we have a set of\nproducts P1:k \u2208 P with associated attributes (a1:k,1:i, 01:k,1:i), and\ninstruction I that the generative model f takes to predict attribute\ntarget class c e\u2208 Cas:\nf: {P(a1:k,1:i 01:k,1:i), I} \u2192 C\nwhere the set of class labels C is limited to common and variation\nattributes. Note that we do not set a constraint to provide labels for\nall of the attributes nor to limit the output to structured attributes.\nAs such, the model can identify variation attributes in the product\nattribute keys a or values v. Still, we penalize the model when\nproviding contradictory labels for the same attribute.\nWe formalize the model as both a zero-shot and few-shot learner\nutilizing an off-the-shelf LLM, Claude3 Haiku [1] (see parameters\nsettings in table 4). The zero-show formulation implicitly assumes\nthat LLMs have been trained on massive amounts of language data\nand thus posses contextual understanding, given a correctly en-\ngineered prompt [12, 23]. For prompt engineering we combined\nChain-of-Thought and instruction techniques, to predict all at-\ntributes labels for a given variation group [25, 29]. To mitigate\nthe impact of this assumption, we provide product relevant infor-\nmation as part of the prompt using RAG [14]. For a given product\npair of certain product type and brand, information about variation\nattributes is retrieved online from the webpage-linked products\ndataset. For the specific product type or brand, variation groups\nwith products belonging to the same product type or brand were\nfiltered, then the associated variation attributes were collected and\nstructured into a list of unique variation attributes to be included\nin the prompt."}, {"title": "3.3 Datasets", "content": "The datasets used to develop and evaluate VARM models were\u00b9:\nWebpage-linked products: dataset containing pairs of prod-\nucts listed on the same e-commerce webpage as illustrated in Fig.\n1A. Since these pairs were presented together, we can assume them\nto belong to the same variation group and therefore are variant prod-\nucts, irrespective of the variation attribute(s). Using these positive\nrelationships, we generated synthetic samples by shuffling product\npairs. Exploiting our understanding of product relationships, we\nused an informed strategy to generate negative samples accord-\ning to the following three buckets: hard negative samples coming\nfrom shuffling product pairs for another product from the same\nbrand and product type, medium difficulty samples by shuffling\nproduct pairs for another product from the same product type but\nnot brand, and easy samples by shuffling pairs for another product\nfrom different product type and brand. Text information from 2M\nproduct pairs and 168K variation groups is structured into product\nattributes, split into 70:30 training:evaluation sets with balanced\nclass labels, while enforcing that products from the same variation\ngroups are in the same data split."}, {"title": "4 RESULTS", "content": "4.1 VARM accurately learns variation matching\nproduct relationships from website\nstructure\nTo validate our VARM strategy we evaluated the outputs of the dif-\nferent model components under different experimental conditions\nand compared its performance to state-of-the-art models perform-\ning the same tasks.\nFirstly, since the webpage linked products dataset initially con-\ntains only positive variation match samples, we generated synthetic\nsamples by shuffling product pairs. We used an informed strategy\nto generate the negative samples according to types of products\nand brands (see Datasets section in Methods). As control, we com-\npared the performance of models trained in this dataset to that\nof a dataset containing random pair shuffles for negative sample\ngeneration. For each experiment we generated 1M negative samples\nto generate a label-balanced dataset with 2M pairs partition into\n70:30 training:evaluation splits, while ensuring that products from\nthe same variation group would be in a given split."}, {"title": "4.2 VARM correctly classifies variation\nattributes", "content": "Identifying attributes that are common or vary across groups of vari-\nant products is critical for multiple applications. To assess VARM's\nability to label attributes, we sampled 500 variation groups present\nin the webpage linked products dataset where the variation at-\ntribute is known. We tested the performance of the zero-shot gen-\nerative AI model, GenAlzero_shot, prompted to solve this task and\nalso when provided additional RAG information about variation\nattributes from other products of similar type and brand, GenAIRAG.\nBoth GenAlzero_shot and GenAIRAG generate qualitative correct\nresponses, with consistent explanations that take into consideration\nproduct type and brand (examples in A.2).\nTo get a quantitative estimate of the performance, we estimated\nthe recall when predict structured variation attributes, to prevent\npenalizing for additionally found variation attributes that may not\nhave a structured key. As baseline, we define a heuristic model that\nestimates variation attributes as the structured attributes that vary\nacross more that 90% of the products in the variation group. All mod-\nels can predict variation attributes above chance, with generative\nmodels outperforming heuristic-based methods. Moreover, provid-\ning additional context about products in the prompt, GenAIRAG\nfurther boosts attribute identification performance."}, {"title": "5 DISCUSSION", "content": "The recent developments in LLM technology has popularized its\nuse with successful application to a multitude of use cases including\ne-commerce tasks [20]. Particularly, encoding LLMs are generally\npreferred for classification tasks or learning embeddings, while\ngenerative Al models are used for text generation tasks like summa-\nrizing or translation [3, 20, 28]. In this work, we capitalize on the\nrespective advantages of encoding and generative LLMs to solve a\nnew task for entity resolution aimed at identifying variant matches\nand variation attributes amongst e-commerce products.\nHere, we show how we can learn variant product relationships\nleveraging the information present in website structures. Still, it will\nbe worth exploring in future works how to adjust the granularity of\nthese relationships so it can be applied across e-commerce sectors.\nFor example, jewelry variation attributes could be material type at\na coarse level of description, but for jewelry retailers the relevant\nvariation attributes could be finer as ring size or gem type. Here, we\nshowed that the strategy used to augment the dataset and generate\nnegative examples was for model performance, suggesting that data\naugmentation methods could prove useful to define new types of\nproduct relationships [9, 26].\nThis work expands the traditional definition of ER to identify\nvariant relationships and implemented a model to successfully iden-\ntify this relationships amongst products. While it was only tested in\ne-commerce catalog applications, the new formulation and model\nstrategy can be directly extended to other areas using ER, such as\ndata curation or customer identification [2]."}, {"title": "A APPENDIX", "content": ""}, {"title": "A.1 Variation product attributes", "content": "****** Variation product attributes ******\n<product i>\nbrand = ...\ntitle = ...\npart number = ...\nmodel number = ...\nsize = ...\ncolor = ..., ...\nitem package quantity = ...\ngeneric keyword = ...\nproduct category = ...\nproduct description = ...\nproduct type = ..., ...\n<product i>"}, {"title": "A.2 Example variation product group attributes\nprediction outputs", "content": "{\"Different\": [\"item_name\", \"item_id\",\n\"item_package_weight\", \"color\", \"included_components\",\n\"model_name\", \"size\", \"grip_size\", \"head_size\"], \"Same\":\n[\"brand\", \"product_type\", \"item_type\"], \"Reason\": [\"The\ndifferent attributes across the products are mainly related\nto the specific details of each racket model, such as the\nname, ID, images, weight, color, included components,\nmodel name, size, grip size, and head size. These attributes\nreflect the unique characteristics and specifications of\nthe different YONEX racket models. The same attributes\nacross the products indicate the common properties\nshared by YONEX sport racket products, such as the\nbrand, product type and item type.\"]}\n{\"Different\": [\"color\", \"size\", \"item_name\", \"item_id\",\n\"part_number\", \"generic_keyword\"], \"Same\":\n[\"age_range_description\", \"brand_value\", \"closure_type\",\n\"material_composition\", \"item_type_keyword\", \"prod-\nuct_type\", \"care_instructions\"], \"Reason\": [\"The color,\nsize, product names, item IDs, part numbers, and generic\nkeyword values are different across the two products to\nrepresent different variations of the same product type.\nHowever, the brand, closure type, material composition,\nitem type, product type, and care instructions are the same\nacross the two products as they are common attributes of\nthe product type.\"] }"}, {"title": "A.3 Variant product classification prompt", "content": "****** Variant product classification prompt ******\nYou are an expert on products. Compare the details in the\ntwo following products and determine if they refer to the\nsame or different products. The products are considered\nthe same product if all details match except for details like\ncolor or size.\nReturn the answer strictly \"yes\" when they are the same\nproduct or \"no\" when they are different. Also say, how\nsimilar the two products are in a scale from 0 to 1? Where\n0 means that the products are completely different and 1\nthey are the exact same.\nDescription of the first product: {product 1}\nDescription of the second product: {product 2}\nFirst, respond \"yes\" or \"no\" and a similarity score between\n0 and 1."}]}