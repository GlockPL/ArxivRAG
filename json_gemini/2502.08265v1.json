{"title": "Exploring the Potential of Large Language Models to Simulate Personality", "authors": ["Maria Molchanova", "Anna Mikhailova", "Anna Korzanova", "Lidiia Ostyakova", "Alexandra Dolidze"], "abstract": "With the advancement of large language models (LLMs), the focus in Conversational AI has shifted from merely generating coherent and relevant responses to tackling more complex challenges, such as personalizing dialogue systems. In an effort to enhance user engagement, chatbots are often designed to mimic human behaviour, responding within a defined emotional spectrum and aligning to a set of values. In this paper, we aim to simulate personal traits according to the Big Five model with the use of LLMs. Our research showed that generating personality-related texts is still a challenging task for the models. As a result, we present a dataset of generated texts with the predefined Big Five characteristics and provide an analytical framework for testing LLMs on a simulation of personality skills.", "sections": [{"title": "1 Introduction", "content": "After their breakthrough in NLP, large language models (LLMs) continue to improve, becoming integral to the modern digital world. Their ability to generate coherent and contextually relevant responses finds application in various fields, including dialogue systems (Yi et al., 2024).\nLLMs, with their ability to generate human-like text, open up new possibilities for conversational agents, making interactions with users more engaging. However, to boost this emotional connection between AI assistants and humans, dialogue systems need to be more personalized taking into account individual characteristics of users. Prompting LLM-based multi-agent systems with personality can significantly enhance their capability to converse with empathy (Rashkin et al., 2018).\nImitating personality with LLMs may be a good way to develop usable AI assistants that perfectly align with users needs (Tseng et al., 2024). Incorporating the desired character in assistants for each user can personalize user experience, prolonging dialogues and making them more lively. Thus, adjusting a bot personality to suit a user's emotional state can enhance user satisfaction with dialogue systems (Prendinger et al., 2005; Polzin and Waibel, 2000). In LLM-based multi-agent systems, agents can take on different roles with description of their personality. For example, such agents can be applied to the gaming industry, portraying players with different characteristics, or in business applications, where agents can take on the roles of customer-oriented employees to provide guidance in certain fields of expertise (Guo et al., 2024).\nThe current study aims at providing evidence on how different LLMs may be prompted with Big Five personality model, and how consistent they are in the imitated personalities. We explore not only how well LLMs associate personality traits with corresponding behavior, but also their knowledge about language patterns and life goals related to the prompted personality. As a result of our study we develop an open-source analytical framework to encourage further research in personality simulation by LLMs."}, {"title": "2 Related Work", "content": "Big Five Personality Model The Big Five personality model is considered to be a valid approach to evaluate one's personality traits due to its reliability and practicality (John et al., 2008). Compared to MBTI personality measurement, the Big Five model has proven its validity across different populations (Schweiger, 1985). According to the Big Five model, an individual's personality can be represented along five dimensions, namely Extraversion, Neuroticism, Agreeableness, Conscientiousness, and Openness to Experience. Each dimension is a dichotomy with low and high trait manifestations. Recent research adds a new dimension, Honesty-Humility, to the original model (Costa and McCrae, 2008).\nInitially, the Big Five model is based on the linguistic hypothesis, claiming that the natural language descriptors of person's traits, moods, and characteristics can be generalized and represented as a personality model. Subsequently, there appear also psychological questionnaires, namely those as TDA (Goldberg, 1992), NEO (Costa and McCrae, 1992), and BFI (John, 1991), that help to determine personality traits by answering a predefined set of questions. All the questionnaires show respectable validity and reliability, but BFI questionnaire stands out for question formulation (John et al., 2008). The Big Five model is critiqued for lacking detailed personality classification, as all traits seem to be abstract (John et al., 2008); moreover, the model only includes traits linked to natural language analysis, neglecting non-social personal traits (Trofimova, 2014). Nevertheless, these characteristics can be advantageous in the context of LLMs, as they can be utilized to generate a personality in natural language modeling using the Big Five model.\nPersonality of Large Language Models The research devoted to personality in LLMs focuses on two main aspects, including internal LLM personality and LLM-prompted personality. LLM personality is usually analyzed by leveraging the Big Five questionnaire results, LLM-generated text analysis (both linguistic and psychological), or automated text classification for the Big Five traits.\nStudies on LLM personalities, e.g., (Sorokovikova et al., 2024), provide statistics on how LLMs answer the different the Big Five questionnaires (IPIP-NEO, BFI-44). This should reveal the LLM hidden personality. The findings seem to be quiet impressive, as they portray GPT-4 and Mixtral as open, agreeable, conscientious, extroverted and emotionally stable agents capable of engaging conversations. However, other studies disagree with this conclusion, as the questionnaire results do not seem to reflect real model personality and do not help to predict model actions (Ai et al., 2024).\nStudies on how we can induce personality in LLMs demonstrate different ways a personality can be prompted to an LLM. Some approaches suggest describing personality based on the personal facts (e.g., providing the LLM with a personality description from PersonaChat dataset) or based on descriptions of each the Big Five characteristic (Serapio-Garc\u00eda et al., 2023; Liu et al., 2024). The other research also tests personality simulation through text generation (Jiang et al., 2024) or sentence completion (Hilliard et al., 2024). Personality modeling is usually affected by the model size, as it is stated in all above-described studies."}, {"title": "3 Methods", "content": "Based on previous research, LLM personality prompting should be approached from two perspectives, including personality questionnaire answering and personal text generation. Therefore, the executed LLM personality analysis consists of two stages. First, the personality questionnaire is used to evaluate the LLM's understanding of the links between personality traits and the associated behaviors. Second, LLMs are prompted to generate texts regarding their induced personality. Compared to the first analysis stage, personality-related text generation requires from an LLM knowledge not only about personality behavior but also about personal language habits, life goals, and inclinations. LLM-generated texts are analyzed in different ways to build a complete picture of the LLM's personality simulation abilities that involves human evaluation of the generated texts, automatic evaluation, and linguistic feature analysis. The analysis is conducted among the proprietary LLMs, including GPT-3.5 Turbo and GPT-4 Omni \u00b9, Mixtral 8x22B \u00b2, Claude 3 Haiku \u00b3. These models were chosen because of their speed, affordability, comparative input context length, and performance."}, {"title": "4 LLMs Answering the Big Five Questionnaire", "content": "Testing prompted LLM personality through questionnaire was based on the BFI-44 questionnaire due to its size and reliability. Each item in the questionnaire corresponds to one of the Big Five traits. So, the model was given instructions to simulate high or low trait score and answer the questionnaire part related to this trait (see in AppendixC.1). Then the results were aggregated and the final trait score was revealed.\nFollowing (Serapio-Garc\u00eda et al., 2023)'s approach to questionnaire answering, we also measured the reliability and validity of the LLM's questionnaire answers. Reliability tests included measuring Cronbach's alpha and Guttman's lambda (see Appendix A). As the reliability metrics exceed 0.85, the questionnaire answers of LLMs may be considered real and plausible.\nTo observe more precisely how the model's answers differ regarding high or low trait prompting, a distribution map was built (see Figure 1). The map reveals that none of the observed models demonstrates consistent personality generation when assessing the personality-related statements. However, some models show accurate performance considering particular traits. So, the Claude model seems to have inner knowledge about such traits as Openness to experience and Conscientiousness, whereas the Mixtral model about Agreeableness and Neuroticism. The GPT models are able to differentiate between high and low levels of Extraversion; additionally, the GPT-4 Omni model excels at distinguishing high and low levels of Agreeableness."}, {"title": "5 LLMs Generating Big Five Personality Texts", "content": "5.1 Experiment Settings\nIn order to evaluate LLM simulation of a prompted personality in generated texts, a set of questions was prepared. The questions concerned the LLM preferences, perspectives, and related matters. The prompt for generation consisted of specified trait scores, a description of each trait, and the chosen question (see Appendix C.2). Two categories of data were generated:\n\u2022 Texts generated using only one trait. The purpose of this task is to evaluate the model's ability to imitate a specific characteristic.\n\u2022 Texts generated using personality settings that included every factor of the Big Five model, in order to examine the overall simulation of traits. The analysis of this second type will be addressed in future research.\nTo generate responses reflective of individual traits, we tested all possible discrete score variations from 1 to 5 to ensure the diversity of generated texts and adjusted the temperature settings to 0, 0.5, 0.7, and 0.9. To analyze the LLM responses to multiple personality traits, we used data points formed by a normal distribution. The mean and variance for the distribution of each trait were calculated by analyzing a dataset of 1,015,342 questionnaire answers (Big Five Personality Test Dataset, 2024) that contained the personality traits information of actual users. These data were also obtained using different temperature settings.\nThe Claude model exhibited p performance in deciding whether to deliver a direct answer to a question or to provide a recommendation consistent with the designated personality profile. Additionally, the model sometimes explicitly disclosed its own personality traits despite instructions in the prompt to avoid doing so. In such instances, responses were edited by masking direct references to personality characteristics or by removing content that did not align with the task objectives.\n5.2 Human Evaluation\nFrom the LLM-generated data, there were selected about 288 text samples for human annotation in total. The amount of texts is equally distributed across all the models under analysis and balanced by model temperature. The data is equally split into batches with 20 texts per batch for an annotator.\nFor human evaluation, we recruited 8 annotators to infer the personality traits in the texts generated by the LLMs. They were provided with the trait descriptions and a detailed instruction, explaining required steps to complete the annotation. Annotators scored each text on a scale from -2 to +2, depending on the intensity each personality trait is expressed, where -2 is low score, 0 is neutral, and +2 is high score. From a given list of reasons, raters also chose why they thought the trait should be scored that low or high. To extract linguistic patterns from the texts, annotators were asked to highlight words and word phrases that made them think the person had a particular personality trait. As perceptions of psychological aspects of personality can vary among individuals, each models' answer was assigned to 3 different annotators, and the agreement between them was evaluated using Fleiss' kappa. The final assessments were acquired via voting. Inner-annotation agreement metrics are displayed in Table 1. We conducted metric calculations at multiple levels, including identifying the existence or absence of a trait in the text, and calculating the score group (non-distinguishable, low, middle, high).\n5.3 Automatic Evaluation\nTo extrapolate the human evaluation of LLM-simulated personality and to enable future automated evaluation for other models and prompts, we created an LLM-based personality classifier. This classifier is based on the CARP method (Sun et al., 2023), which initially prompts the LLM to provide a list of clues (i.e., keywords, phrases, contextual information, semantic relations, semantic meanings, tones, references) that indicate a personality trait. The model subsequently analyzes the extracted data and, based on this analysis, detects the personality trait, providing an explanation for its response. The instructions for personality detection given to the model were exactly the same as those provided to the human annotator (see Appendix C.3). The GPT-4 Omni model was chosen as the base classifier due to its superior performance compared to other LLMs.\nThe analysis of the correspondence between classifier evaluations and those of human annotators includes several levels:\n\u2022 Level 1: Evaluating the presence or absence of trait markers in the text. The classifier's and annotators' responses are considered consistent if both determine that the markers are either present or absent.\n\u2022 Level 2: Categorizing the scores into four groups. The Low group includes scores of -2 and -1. A score of 0 represents a balanced demonstration of the trait and is classified into a distinct category. The High group contains scores 1 and 2. The Non-distinguishable category is for cases where the trait cannot be identified. The classifier's results and the human annotators' results are compared among these groups.\n\u2022 Level 3: Analyzing the differences between the classifier's evaluations and the average scores provided by the annotators.\nTable 2 presents the examination of the similarity between the LLM-based classifier evaluations and the human annotators' responses at Levels 1 and 2. The Level 3 metrics are displayed in Table 3.\nThe most problematic trait for the classifier is Neuroticism, which also has a low inner-annotation agreement metric within the group.\nFigure 4 presents the results of the classifier's detection of the trait included in the prompt and shows how identifiable the presence of the prompted trait is in the generated text. Figure 2 demonstrates the distribution of trait scores in generated texts when the model failed to recognize the personality. The confusion matrices in Figure 2 illustrate how accurately the prompted score groups for the traits were identified by the classifier and what types of errors were made.\nThe results of the Big Five classifier on generated text data show that among all the models analyzed, the trait of Openness to Experience was consistently simulated throughout the text generation process. The models demonstrated a robust understanding of the prompts, effectively capturing and conveying both low and high scores in the generated texts. Although the presence of Agreeableness trait was often detected in the generated texts, several models mistakenly represented high score of the trait personality, even if the prompt required low trait score.\nThe models had significant difficulty simulating Neuroticism. Nearly half of the generated texts did not consist of any detectable trait markers. The majority of models consistently presented personality with low scores of Neuroticism, even when the high scores were prompted. The results for Extraversion and Agreeableness exhibit notable variations among different models. In almost all cases, when a middle score for a trait was not correctly represented, the prompted personality was frequently identified as either a low or high score of the trait.\nAdditionally, we found that when the model exhibits an identifiable bias towards either high or low scores, the generated texts with a middle score of a trait would frequently follow this bias. As a result, using the base method of prompting a middle score of a trait does not produce the desired outcome.\nThe comparison between models reveals that:\n\u2022 Claude-3 Haiku model demonstrated a robust ability for imitating Openness to Experience: texts generated with this trait in the prompt can be easily identified for its existence, and the model successfully simulates both low and high scores. The presence of the Conscientiousness trait was detected in 75% of cases, and the scores were reproduced with high precision in the texts. The model is capable of simulating different scores of Agreeableness; however, with slightly less precision. The model demonstrated strong bias toward low scores for Extraversion and Neuroticism, regardless of the prompt settings.\n\u2022 GPT-3.5 Turbo model was capable of imitating Openness to Experience in generated texts, despite some flaws. In addition, the model demonstrated significant bias towards Conscientiousness (high score), Agreeableness (high score), and middle bias towards Neuroticism (low score). In almost half of the cases, it demonstrates a high score for Extraversion, even when low scores are requested in the prompt.\n\u2022 GPT-4 Omni model demonstrated a strong ability to imitate the Big Five traits such as Openness to Experience, Conscientiousness, and Extraversion. Regarding the trait Agreeableness, the model had a moderate bias towards high scores. The model successfully simulated various scores of Neuroticism in the texts; however, it had a slight bias towards expressing low scores and a tendency to under-demonstrate the trait in texts where a low score was specified in the prompt.\n\u2022 Mixtral 8x22B model, along with other models, is capable of imitating the trait Openness to Experience, however with a few mistakes. Although the model could not demonstrate the Conscientiousness trait in a significant number of cases (43%), successfully simulated both low and high personality scores in detected cases. The model also demonstrates a minor bias when generating low scores of Extraversion and high scores of Agreeableness, together with a strong bias towards low scores of Neuroticism.\n5.4 Linguistic Features Evaluation\nAt last the generated texts were analyzed linguistically. First, the texts prompted with different trait scores were compared to each other based on vocabulary used. This required to measure similarity between texts with different trait scores. The simplest way to assess text similarity is the use of TF-IDF vectorization\u2074 for comparing generated texts. The heatmap shown in Figure 3 displays the mean scores of the chosen Big Five traits for the five most similar texts to a given text (the scores are averaged among texts with the same trait; similar texts with other traits are not considered). The results show that Claude Haiku and GPT-4 Omni generate the most lexically consistent texts, which at the same time differ according to the level of trait manifestation.\nIn addition to that, we analyzed the extracted text samples assigned to the traits by annotators. Personality types are usually indicated by the usage of certain lexicons in the texts (Ashton et al., 2004). As LLMs are able to align with human linguistic patterns simulating personality types (Jiang et al., 2023), we examined lexical choices in the generated texts across different trait scores.\nText samples were preprocessed and then lemmatized for further analysis with the use of the spaCy library 5. The extracted lemmas were categorized by a part of speech and the trait scores specified in prompts. The most common verbs, nouns, and adjectives depicting personality features, according to annotators' opinions, are presented in Appendix D. Nouns and adjectives more effectively represent the spectrum of the five personality traits compared to verbs. Analysis revealed that 16% of the linguistic patterns in generated texts were derived from prompts. Texts with high or low scores exhibit more noticeable variations in lexicons, whereas texts with a neutral trait score (equal to 0) tend to display linguistic patterns that are common to both high and low-scored texts. With the exception of Neuroticism, the lexicons of zero-scored samples are more similar to those that have low scores, as they share up to 34% of patterns. The distribution of lemmas across trait scores demonstrates that employing binary scores for persona definition in LLM prompts is more reasonable, as most models struggle to capture subtle nuances of personality features."}, {"title": "6 Analytical Framework", "content": "In our exploration of LLM capacity to generate personality-consistent content, we developed and released an analytical framework that empowers researchers to replicate research with custom parameters. Our customizable framework allows users to integrate their own models and configurations, and to modify prompts for personality simulation. It supports the incorporation of different personality questionnaires beyond the BFI-44 used in our study. Additionally, users can add custom questions for the models to generate responses to.\nWithin this framework, the evaluated models respond to items from the chosen questionnaires, and their answers are used for graphical analysis The models also generate texts based on specified prompts, which are then automatically analyzed using the LLM-based classifier. This process assesses the accuracy and consistency with which the models adhere to the assigned personality traits during text generation. By making this framework publicly available on GitHub 6, we aim to contribute a valuable tool for advancing research in personality simulation by LLMs. The dataset of generated texts used in this research is also available at the same link."}, {"title": "7 Discussion", "content": "Leveraging both questionnaire answering and text generation for testing LLM personality simulation skills gives a complex picture how LLM can answer certain personality-related statements and formulate statements about itself. Seemingly, the text generation is more informative regarding the Big Five personality simulation, as it is originally based on the linguistic hypothesis and is associated with the use of specific vocabulary. The complexity of text analysis process may be overcome when using modern NLP tools and LLM power.\nConcerning modern LLM performance on personality simulation, Neuroticism, among all the Big Five traits, is the most challenging trait to simulate by LLMs, as it was not detected in the questionnaire answers or by human analysis. The explanation might be that high score of Neuroticism is mostly connected to direct actions and ability to demonstrate emotional response, and LLMs cannot be proactive or show their emotions. Therefore, when prompting personality to an LLM, Neuroticism is better to set neutral or to avoid mentioning. However, overall LLM performance may be estimated as good, because LLMs demonstrate knowing of Big Five trait characteristics and seem to differentiate between various levels of trait manifestation."}, {"title": "8 Conclusion and Future Work", "content": "In this paper, we explored the potential of LLMs to simulate personality traits across different types of tasks. The results of personality simulation varied significantly depending on the task type. For example, when an LLM was asked to response questionnaire aligned with its prompted personality, the model generally performed well, though occasionally exhibited minor bias. However, when generating texts, LLM behavior differed significantly. In some cases, the models were unsuccessful in effectively conveying the presence of personality traits with recognizable scores in the generated text. Particularly, for the Big Five traits such as Agreeableness and Neuroticism, some models demonstrated strong bias towards certain score groups, even when explicitly prompted to simulate opposing trait scores. Thus, the model's behavior in responding to questionnaires and in generating texts may have been inconsistent. This difference may be related to the models' inherent default role, where high Agreeableness and low Neuroticism scores are considered essential for being an effective AI assistant.\nTherefore, when generating text that encompasses the full spectrum of personality trait scores according to the Big Five model, it is crucial to assess whether the model exhibits any bias towards specific trait scores. To facilitate further research on the capabilities of LLMs in simulating personality and conducting prompt engineering experiments for personality assignment, we have released a repository containing the analytical framework developed for this study.\nFuture research should focus on detailed multiple-trait personality generation, as AI models might be capable of incorporating all five traits of the Big Five model into the agent's personality. It is appealing due to the perspective of creating complex agent characters or game characters."}, {"title": "Limitations", "content": "Limitations of the current study include using the Big Five personality model despite its assumptions (Costa and McCrae, 1999) about proactivity and variability of a research subject. Besides, the effect of LLM size and training data was not taken into account as it may affect how models are capable of answer the questionnaire and generate texts. The study is also limited by usage of only partial human dataset annotation."}]}