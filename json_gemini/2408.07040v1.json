{"title": "KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation", "authors": ["Daniele Rege Cambrin", "Eleonora Poeta", "Eliana Pastor", "Tania Cerquitelli", "Elena Baralis", "Paolo Garza"], "abstract": "Segmentation of crop fields is essential for enhancing agricultural productivity, monitoring crop health, and promoting sustainable practices. Deep learning models adopted for this task must ensure accurate and reliable predictions to avoid economic losses and environmental impact. The newly proposed Kolmogorov-Arnold networks (KANs) offer promising advancements in the performance of neural networks. This paper analyzes the integration of KAN layers into the U-Net architecture (U-KAN) to segment crop fields using Sentinel-2 and Sentinel-1 satellite images and provides an analysis of the performance and explainability of these networks. Our findings indicate a 2% improvement in IoU compared to the traditional full-convolutional U-Net model in fewer GFLOPs. Furthermore, gradient-based explanation techniques show that U-KAN predictions are highly plausible and that the network has a very high ability to focus on the boundaries of cultivated areas rather than on the areas themselves. The per-channel relevance analysis also reveals that some channels are irrelevant to this task.", "sections": [{"title": "1 Introduction", "content": "In recent years, remote sensing and deep neural networks have revolutionized how we approach agricultural management, environmental monitoring, and many earth-observation-related tasks. Their combination proved to be effective in a wide range of tasks, such as emergency management [19] and land cover [31]. One task related to land cover is the segmentation of crop fields, which is crucial for optimizing agricultural productivity, assessing crop health, and planning sustainable farming practices [7].\nThe accuracy and interpretability of the neural networks used in this process are fundamental to ensure reliable and actionable insights. Accurate segmentation of crop fields enables precise calculations of area coverage, assessment of crop types, and monitoring of agronomic factors such as plant health and soil conditions [6]. This information is critical for making informed decisions on irrigation, fertilization, and crop rotation, which are essential for enhancing yield and sustainability [10]. Furthermore, accuracy in semantic segmentation tasks directly influences economic planning and policy-making at various governmental and institutional levels. Providing accurate decisions is essential, yet model understandability and accessibility are also vital to allow practitioners to validate them and adhere to institutional regulations [45]. These factors are crucial as they significantly impact both economies and the environment. [15]. Deep learning models can achieve high accuracy, but they are often considered \"black boxes\" due to their intricate architectures composed of numerous layers and parameters that are difficult to interpret. This complexity poses significant challenges in understanding the decision-making processes underlying these models. In the context of remote sensing, the interpretability of such models is further complicated by the nature of the data, which includes various spectral bands, temporal sequences, and spatial resolutions. Additionally, factors such as noise, occlusions, and atmospheric effects can obscure the models' decision-making processes.\nConsequently, explainability in deep learning for remote sensing is crucial, as it ensures that humans can understand the decisions and outputs of these models. Developing techniques to elucidate the logic behind the model outputs is essential for validating its results and establishing confidence in its practical applications. A widely adopted approach to enable model explainability is to provide explanations for individual predictions of a model in a post-hoc fashion, allowing its interpretability while not affecting its accuracy. This solution finds application in the domain of earth observation, where explanations are presented as saliency maps (or heat maps), highlighting which parts of the satellite image influence the model prediction [15, 18] (see Figure 1 (c) and (d) as examples).\nThe recent introduction of Kolgomorov-Arnold Networks (KANs) [23] posed a new paradigm for neural networks as an alternative to Multi-Layer Perceptrons (MLPs). Inspired by the Kolmogorov-Arnold representation theorem [2,20], KANs allow learning custom activations of the edge of the network. In this way, it is possible to analyze the contribution of individual components of the input"}, {"title": "2 Related Work", "content": "In this section, we provide an overview of the advancements in remote sensing for agriculture, the explainability of neural networks, and their intersection."}, {"title": "2.1 Remote Sensing", "content": "Remote sensing technologies have been extensively applied in agriculture to enhance crop monitoring, management, and productivity. Early studies focused on utilizing satellite imagery to assess crop health and estimate yields [5]. With advancements in sensor technology and data processing techniques, the resolution and accuracy of remote sensing data have significantly improved, enabling more detailed analysis of agricultural landscapes [33]. One application of remote sensing in agriculture is crop field segmentation, which involves identifying cultivated areas. The introduction of Convolutional Neural Networks (CNNs) and the U-Net architecture has further enhanced crop field segmentation [4,48]. Although recent advancements have proposed other architectures, it still remains one of the most effective baselines in remote sensing, thanks to its design [12]. Integrating multispectral and hyperspectral imaging has also contributed to more accurate crop field segmentation. These images capture data across various wavelengths, providing richer information about crop characteristics [43]."}, {"title": "2.2 Explainable AI", "content": "Explainable artificial intelligence (XAI) is a branch of AI research dedicated to making machine learning models interpretable and understandable to humans [1,3,32]. In recent years, there has been a significant interest in applying XAI techniques to Earth observation tasks, driven by the necessity to interpret complex AI models applied in remote sensing [15,18]. Solutions in this domain follow a standard categorization of XAI approaches: interpretable by design and post-hoc explainability methods [32]. By-design approaches, such as [21, 28, 29, 40], integrate interpretability intrinsically into the design of the model algorithm or its architecture. However, they often fail to explain individual model predictions, raising doubts about their actual ability to help humans understand the process [15]. Additionally, these approaches tend to be less accurate than black-box models. To address these limitations, many works focus on post-hoc explanations [16-18,26,42], which aim to explain trained black-box models while preserving their accuracy and enhancing transparency.\nSaliency maps are one of the most adopted post-hoc methods for visualizing which parts of an input image influence the model's prediction. Saliency maps (or heat maps) are overlayed pixel-based importance scores over the input image, highlighting how much each pixel contributes to the prediction. These maps have been widely adopted for semantic segmentation in tasks such as medical diagnosis [16-18, 26]. The urgency of understanding the decision process of the models in remote sensing has led to works investigating their application to segment satellite imagery and agricultural fields [18]."}, {"title": "3 Methodology", "content": "In this section, we formalize the problem by first detailing the crop field segmentation task, followed by the explainability part, and finally, we present the models."}, {"title": "3.1 Problem statement", "content": "This work addresses the crop field segmentation problem based on radiometric or hyperspectral images. The problem can be formulated as follows:\nLet $I$ be an arbitrary satellite image of size $W \\times H \\times D$, where $W$ and $H$ are the width and height of the images in pixels, respectively, while $D$ is the depth of the images (i.e., the number of features per pixel). The objective is to automatically create a binary mask $M$ represented by a matrix of size $W \\times H$ associated with $I$, where the value 1 in a cell indicates the associated pixel contains cultivated area. In contrast, O is related to any non-cultivated area.\nExplainability Statement We aim to help users fully understand how the model achieves effective segmentation by providing them with visual explanations of model predictions. From an XAI perspective, the problem can be formulated as follows:\nGiven an image $I$ and its binary mask $M$, we want to produce a saliency map (or heat map) $S$ of size $W \\times H$ to highlight the regions of $I$ that are"}, {"title": "3.2 Models", "content": "In this study, we compare the well-known U-Net [36] with a modified version [22] which integrates KAN [23] layers into the architecture. In the following, we first outline the U-Net architecture. We then outline the KAN neural networks and, finally, its integration into the U-KAN architecture."}, {"title": "U-Net", "content": "U-Net is a convolutional neural network architecture designed primarily for biomedical image segmentation [36]. Its architecture is characterized by a U-shaped structure (as seen in Figure 2), with a contracting path to capture context and a symmetric expanding path to enable precise localization. The contracting path consists of repeated application of convolutions followed by max-pooling operations, while the expanding path involves upsampling and convolutional layers to reconstruct the image resolution. This design allows U-Net to effectively learn from relatively few training images and produce high-quality segmentations, making it a popular choice for segmentation beyond medical imaging."}, {"title": "KAN", "content": "Kolmogorov-Arnold Networks [23] (KANs) are a novel type of neural network inspired by the Kolmogorov-Arnold representation theorem [2,20], which"}, {"title": "U-KAN", "content": "states that every multivariate continuous function $f : [0,1]^n \\rightarrow \\mathbb{R}$ can be represented as a superposition of the two-argument addition of continuous functions of one variable:\n\\[f(x) = f(x_1, x_2,...,x_n) = \\sum_{q=0}^{2n} \\Phi_q(\\sum_{p=1}^n \\phi_{q,p}(x_p))\\]\nwhere $\\phi_{q,p}: [0,1] \\rightarrow \\mathbb{R}$ and $\\Phi_q : \\mathbb{R} \\rightarrow \\mathbb{R}$. Unlike traditional Multi-Layer Perceptrons (MLPs) that have fixed activation functions on nodes, KANs employ learnable activation functions on edges. This is achieved by replacing every linear weight parameter with a univariate function parameterized as a spline. The activations change step-by-step to better approximate the desired target during the training, and KANs offer the possibility of visualizing the learnable activation functions. In this way, KANs can be more transparent and efficient in learning more complex relations than MLPs, offering promising alternatives to traditional deep learning models. The learned activations can be low-cost functions (e.g., constant or linear) when there is no need for complex non-linearities. This also grants the possibility of understanding the salient parts of the input.\nU-KAN [22] proposes to implement the deepest layer of the U-Net using KANs. These layers are composed of a tokenization layer, a KAN layer, a downsampling layer, and a final normalization layer. In Figure 3, it is possible to see the key difference stands only in how the deepest representations are processed by the network. The main features of the U-Net, such as downsampling and skip-connection, remain invariant, sharing the same benefits. The modification in the encoder's last layers and the decoder's firsts allows the network to learn custom activation functions instead of fixed ones, potentially improving the representativity of the embeddings and reducing the required computational resources by learning simple activations when needed."}, {"title": "4 Experimental Setup", "content": "This section describes the adopted dataset, the experimental setting, and the adopted evaluation metrics for the crop segmentation performance and quality of the derived explanations."}, {"title": "4.1 Dataset", "content": "We employed the South Africa Crop Type dataset [46], which contains images taken from both Sentinel-2 and Sentinel-1 covering a wide region of South Africa. The dataset includes small and irregular-shaped [25] crop fields, making it more challenging, and provides higher resolution imagery (of size 256 \u00d7 256) than other datasets covering the area. The annotations contain the mask of the areas covered by a certain crop. For our analysis, we limit the scope to distinguish between cultivated and non-cultivated areas. We analyzed the results using both types of imagery from Sentinel-2 and Sentinel-1.\nSentinel-1 [44] is a satellite mission under the Copernicus program, comprising two identical satellites equipped with C-band Synthetic Aperture Radar (SAR). It provides all-weather, day-and-night radar imaging. The satellite can work in both single-polarization and double-polarization modes. On land, it mainly works collecting VV and VH polarizations\nSentinel-2 [14] is part of the Copernicus program and consists of two satellites. These satellites carry high-resolution multispectral imaging instruments with 13 spectral bands ranging from Ultra-Blue, Visible, Near Infrared (NIR), and Short Wave infrared (SWIR). It is particularly sensitive to vegetation due to the presence of instruments that work in the infrared spectrum.\nWhile Sentinel-1 images can cover different atmospheric situations due to the radiometric nature of the imagery, Sentinel-2 is affected by clouds and similar atmospheric disturbances. Since the provided cloud masks are often not accurate, we computed the masks with the s2cloudless algorithm [39]. We exclude low-quality Sentinel-2 images with a strong overlap between the cloud mask and the areas containing crops (intersection over 0.7).\nSince no splits were provided, we randomly divided the dataset into a training set containing 2019 training, 267 validation, and 364 test samples. The three splits are similar (p > 0.9) according to the chi-square test when measuring the class frequencies. In this way, we created two datasets with three splits each due to the fact the dates of Sentinel-1 and Sentinel-2 do not exactly match because of the different revisit times. Figure 4, show a sample from the test set in both Sentinel-1 VV and Sentinel-2 RGB."}, {"title": "4.2 Experimental Setting", "content": "Crop Field Segmentation The images have size 256 \u00d7 256 \u00d7 2 for Sentinel-1 data and shape 256 \u00d7 256 \u00d7 12 for Sentinel-2. We train all networks with an AdamW optimizer and a learning rate scheduler with a reduction on plateau of factor 0.2 and patience of 5. The initial learning rate was set to 1e-4, and the batch size to 16. We trained the models for 60 epochs. We apply random horizontal and vertical flipping as augmentations. The loss function is generalized dice loss [41], which takes into account the class imbalance in the images. We compared the two networks with the same encoder (and so decoder) embedding sizes to better understand how they exploit the same representation space.\nWe evaluated the networks under Intersection-Over-Union (IoU), F1-Score (F1), Precision (Prec), and Recall (Rec) for the positive class. We also evaluated GFLOPs to measure the efficiency of the network."}, {"title": "Explainability", "content": "We use Grad-CAM [38] as a visual post-hoc explanation method for this task because of its proven effectiveness in previous XAI studies in remote sensing [18]. Grad-CAM is particularly valuable because it helps answer the critical question, \"Where does the model focus when segmenting crops?\u201d.\nFor each image, we generate a single saliency map to quantify the influence of each pixel on the prediction of the positive class (i.e., cultivated area) made by a model (i.e., U-NET or U-KAN). In GradCAM, the generation process first involves computing the gradients of the positive class score with respect to feature maps of a selected convolutional layer. These gradients are then averaged globally to obtain the importance weights for each feature map. Next, a weighted sum of these feature maps is performed using the calculated weights. This yields a coarse location map that highlights the regions of the input image that are most influential in model segmentation decisions. Finally, we apply a ReLU activation to this weighted sum to ensure that only positive influences are considered, producing the final Grad-CAM heat map. In our experiments, we use Sentinel-2 data, which provides multispectral images over 12 channels, and generate the explanations for the test set images.\nWe assessed the Plausibility, Sufficiency, and Per-channel Relevance of the generated Grad-CAM heatmaps. Below, we provide a detailed description of each metric."}, {"title": "5 Experimental Results", "content": "In this section, we present the results obtained for the analyzed dataset. First, we outline crop segmentation performance, addressing our research question RQ1."}, {"title": "5.1 Task Performances", "content": "In Table 1, we report the results obtained when employing U-Net and U-KAN on Sentinel-1 and Sentinel-2 data. U-KAN provides the best performance in terms of IoU on Sentinel-2, proving its adaptability in dealing with complex relations. On Sentinel-1, U-KAN gets comparable performance in terms of IoU to U-Net. In terms of precision, the KAN variant is more performant, scoring \u2248 +3% than U-Net. Although Sentinel-1 imagery is less affected by atmospheric events, Sentinel-2 bands provide a better understanding of the area with both networks. U-KAN proves to be more computationally efficient than a standard U-Net when looking at GFLOPS: it consumes half the one of U-Net.\nThe KAN variant proves to be a preferable solution in both cases, providing better or comparable performance in fewer GFLOPs. Moreover, it proves to be more precise in any case."}, {"title": "5.2 Analysis of explanations", "content": "We analyze the explainability results of U-KAN and U-Net networks on the Sentinel-2 dataset through qualitative and quantitative assessments."}, {"title": "Qualitative Evaluation", "content": "We examine the saliency maps obtained from both networks. This analysis provides insight into the areas where each model focuses its attention, offering a deeper understanding of their segmentation behaviors.\nFigure 1 shows examples of saliency maps generated by the U-Net and U-KAN models. The red pixels indicate the points where the network's attention is most focused, highlighting the differences in the behavior of the two models. Figure 1 (c) reveals that the U-Net model focuses on a significantly larger area than the U-KAN model. This observation suggests that, regardless of the effectiveness of the segmentation task, the U-Net model tends to distribute its focus over larger regions. In contrast, the U-KAN model has an interesting feature in its approach to the segmentation task. The network focuses predominantly on"}, {"title": "5.3 Analysis of the trained models", "content": "As previously mentioned, KANs are designed with a level of interpretability through the possibility of visualizing learnable activation functions. Although our main goal is to explore the post-hoc explainability of the U-KAN network with respect to the U-Net, we also sought to analyze the behavior of learnable activation functions in a decoding layer. This is also particularly relevant when analyzing the resource consumption of the network since the learned function can be simple to compute (e.g., linear) or complex when necessary, potentially helping both GFLOPs and performance, as shown before.\nIn Figure 6, we report the learned activations for an element of the embeddings in a decoder layer. We can see substantial differences between the base function (SiLU) and ReLU, commonly employed by U-Net. U-KAN effectively represented more complex relations in the deep embeddings. The second activation is reversed along the y-axis compared to SiLU. The first and the third are similar but have a different slope (the first function is steeper).\nMoreover, each element of the embedding learns different activations with different complexity. Some of them could be constant activations for certain elements in the embeddings. The learned functions with a variance < 1 are ~26% the total, while the ones with a variance < 0.1 are \u2248 8%. This indicates the irrelevant parts of the embedding because every input is mapped to the same value every time."}, {"title": "6 Conclusions", "content": "In this work, we have shown how the new KANs can improve well-known architecture applied to the agricultural field, particularly in terms of efficiency, using only half the resources of full CNN architecture. Our study indicates that U-KAN offers superior performance by achieving higher precision and IoU scores than U-Net. The explainability analysis also reveals two significant insights. First, the U-KAN network's emphasis on boundary details makes it particularly effective for tasks such as boundary delimitation and mapping. Second, not all the channels are useful for the segmentation task. So, users can decide to rely only on the most important reducing computational costs of the models. In future work, we intend to implement the insights from our network explainability analysis to enhance performance and reduce computational costs."}]}