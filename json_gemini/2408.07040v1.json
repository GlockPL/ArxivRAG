{"title": "KAN You See It?\nKANs and Sentinel for Effective and Explainable\nCrop Field Segmentation", "authors": ["Daniele Rege Cambrin", "Eleonora Poeta", "Eliana Pastor", "Tania\nCerquitelli", "Elena Baralis", "Paolo Garza"], "abstract": "Segmentation of crop fields is essential for enhancing agricul-\ntural productivity, monitoring crop health, and promoting sustainable\npractices. Deep learning models adopted for this task must ensure accu-\nrate and reliable predictions to avoid economic losses and environmental\nimpact. The newly proposed Kolmogorov-Arnold networks (KANs) offer\npromising advancements in the performance of neural networks. This pa-\nper analyzes the integration of KAN layers into the U-Net architecture\n(U-KAN) to segment crop fields using Sentinel-2 and Sentinel-1 satel-\nlite images and provides an analysis of the performance and explain-\nability of these networks. Our findings indicate a 2% improvement in\nIoU compared to the traditional full-convolutional U-Net model in fewer\nGFLOPs. Furthermore, gradient-based explanation techniques show that\nU-KAN predictions are highly plausible and that the network has a very\nhigh ability to focus on the boundaries of cultivated areas rather than\non the areas themselves. The per-channel relevance analysis also reveals\nthat some channels are irrelevant to this task.", "sections": [{"title": "1 Introduction", "content": "In recent years, remote sensing and deep neural networks have revolutionized how\nwe approach agricultural management, environmental monitoring, and many\nearth-observation-related tasks. Their combination proved to be effective in a\nwide range of tasks, such as emergency management [19] and land cover [31].\nOne task related to land cover is the segmentation of crop fields, which is cru-\ncial for optimizing agricultural productivity, assessing crop health, and planning\nsustainable farming practices [7].\nThe accuracy and interpretability of the neural networks used in this process\nare fundamental to ensure reliable and actionable insights. Accurate segmenta-\ntion of crop fields enables precise calculations of area coverage, assessment of\ncrop types, and monitoring of agronomic factors such as plant health and soil\nconditions [6]. This information is critical for making informed decisions on ir-\nrigation, fertilization, and crop rotation, which are essential for enhancing yield\nand sustainability [10]. Furthermore, accuracy in semantic segmentation tasks\ndirectly influences economic planning and policy-making at various governmen-\ntal and institutional levels. Providing accurate decisions is essential, yet model\nunderstandability and accessibility are also vital to allow practitioners to validate\nthem and adhere to institutional regulations [45]. These factors are crucial as\nthey significantly impact both economies and the environment. [15]. Deep learn-\ning models can achieve high accuracy, but they are often considered \"black boxes\"\ndue to their intricate architectures composed of numerous layers and parame-\nters that are difficult to interpret. This complexity poses significant challenges\nin understanding the decision-making processes underlying these models. In the\ncontext of remote sensing, the interpretability of such models is further compli-\ncated by the nature of the data, which includes various spectral bands, temporal\nsequences, and spatial resolutions. Additionally, factors such as noise, occlusions,\nand atmospheric effects can obscure the models' decision-making processes.\nConsequently, explainability in deep learning for remote sensing is crucial,\nas it ensures that humans can understand the decisions and outputs of these\nmodels. Developing techniques to elucidate the logic behind the model outputs\nis essential for validating its results and establishing confidence in its practical\napplications. A widely adopted approach to enable model explainability is to\nprovide explanations for individual predictions of a model in a post-hoc fashion,\nallowing its interpretability while not affecting its accuracy. This solution finds\napplication in the domain of earth observation, where explanations are presented\nas saliency maps (or heat maps), highlighting which parts of the satellite image\ninfluence the model prediction [15, 18] (see Figure 1 (c) and (d) as examples).\nThe recent introduction of Kolgomorov-Arnold Networks (KANs) [23] posed\na new paradigm for neural networks as an alternative to Multi-Layer Percep-\ntrons (MLPs). Inspired by the Kolmogorov-Arnold representation theorem [2,20],\nKANs allow learning custom activations of the edge of the network. In this way,\nit is possible to analyze the contribution of individual components of the input"}, {"title": "2 Related Work", "content": "In this section, we provide an overview of the advancements in remote sensing\nfor agriculture, the explainability of neural networks, and their intersection."}, {"title": "2.1 Remote Sensing", "content": "Remote sensing technologies have been extensively applied in agriculture to en-\nhance crop monitoring, management, and productivity. Early studies focused on\nutilizing satellite imagery to assess crop health and estimate yields [5]. With ad-\nvancements in sensor technology and data processing techniques, the resolution\nand accuracy of remote sensing data have significantly improved, enabling more\ndetailed analysis of agricultural landscapes [33]. One application of remote sens-\ning in agriculture is crop field segmentation, which involves identifying cultivated\nareas. The introduction of Convolutional Neural Networks (CNNs) and the U-\nNet architecture has further enhanced crop field segmentation [4,48]. Although\nrecent advancements have proposed other architectures, it still remains one of the\nmost effective baselines in remote sensing, thanks to its design [12]. Integrating\nmultispectral and hyperspectral imaging has also contributed to more accurate\ncrop field segmentation. These images capture data across various wavelengths,\nproviding richer information about crop characteristics [43]."}, {"title": "2.2 Explainable AI", "content": "Explainable artificial intelligence (XAI) is a branch of AI research dedicated to\nmaking machine learning models interpretable and understandable to humans\n[1,3,32]. In recent years, there has been a significant interest in applying XAI\ntechniques to Earth observation tasks, driven by the necessity to interpret com-\nplex AI models applied in remote sensing [15,18]. Solutions in this domain follow\na standard categorization of XAI approaches: interpretable by design and post-\nhoc explainability methods [32]. By-design approaches, such as [21, 28, 29, 40],\nintegrate interpretability intrinsically into the design of the model algorithm\nor its architecture. However, they often fail to explain individual model pre-\ndictions, raising doubts about their actual ability to help humans understand\nthe process [15]. Additionally, these approaches tend to be less accurate than\nblack-box models. To address these limitations, many works focus on post-hoc\nexplanations [16-18,26,42], which aim to explain trained black-box models while\npreserving their accuracy and enhancing transparency.\nSaliency maps are one of the most adopted post-hoc methods for visualizing\nwhich parts of an input image influence the model's prediction. Saliency maps (or\nheat maps) are overlayed pixel-based importance scores over the input image,\nhighlighting how much each pixel contributes to the prediction. These maps\nhave been widely adopted for semantic segmentation in tasks such as medical\ndiagnosis [16-18, 26]. The urgency of understanding the decision process of the\nmodels in remote sensing has led to works investigating their application to\nsegment satellite imagery and agricultural fields [18]."}, {"title": "3 Methodology", "content": "In this section, we formalize the problem by first detailing the crop field seg-\nmentation task, followed by the explainability part, and finally, we present the\nmodels."}, {"title": "3.1 Problem statement", "content": "This work addresses the crop field segmentation problem based on radiometric\nor hyperspectral images. The problem can be formulated as follows:\nLet $I$ be an arbitrary satellite image of size $W \\times H \\times D$, where $W$ and $H$\nare the width and height of the images in pixels, respectively, while $D$ is the\ndepth of the images (i.e., the number of features per pixel). The objective is to\nautomatically create a binary mask $M$ represented by a matrix of size $W \\times H$\nassociated with $I$, where the value 1 in a cell indicates the associated pixel\ncontains cultivated area. In contrast, O is related to any non-cultivated area.\nExplainability Statement We aim to help users fully understand how the\nmodel achieves effective segmentation by providing them with visual explana-\ntions of model predictions. From an XAI perspective, the problem can be for-\nmulated as follows:\nGiven an image $I$ and its binary mask $M$, we want to produce a saliency\nmap (or heat map) $S$ of size $W \\times H$ to highlight the regions of $I$ that are"}, {"title": "3.2 Models", "content": "In this study, we compare the well-known U-Net [36] with a modified version [22]\nwhich integrates KAN [23] layers into the architecture. In the following, we first\noutline the U-Net architecture. We then outline the KAN neural networks and,\nfinally, its integration into the U-KAN architecture.\nU-Net U-Net is a convolutional neural network architecture designed primarily\nfor biomedical image segmentation [36]. Its architecture is characterized by a U-\nshaped structure (as seen in Figure 2), with a contracting path to capture context\nand a symmetric expanding path to enable precise localization. The contracting\npath consists of repeated application of convolutions followed by max-pooling\noperations, while the expanding path involves upsampling and convolutional lay-\ners to reconstruct the image resolution. This design allows U-Net to effectively\nlearn from relatively few training images and produce high-quality segmenta-\ntions, making it a popular choice for segmentation beyond medical imaging.\nKAN Kolmogorov-Arnold Networks [23] (KANs) are a novel type of neural net-\nwork inspired by the Kolmogorov-Arnold representation theorem [2,20], which"}, {"title": "KAN You See It?", "content": "states that every multivariate continuous function $f : [0,1]^n \\rightarrow R$ can be repre-\nsented as a superposition of the two-argument addition of continuous functions\nof one variable:\n$f(x) = f(x_1, x_2,...,x_n) = \\sum_{q=0}^{2n} \\Phi_q(\\sum_{p=1}^n \\phi_{q,p}(x_p))$\nwhere $\\phi_{q,p}: [0,1] \\rightarrow R$ and $\\Phi_q: R \\rightarrow R$. Unlike traditional Multi-Layer Per-\nceptrons (MLPs) that have fixed activation functions on nodes, KANs employ\nlearnable activation functions on edges. This is achieved by replacing every linear\nweight parameter with a univariate function parameterized as a spline. The acti-\nvations change step-by-step to better approximate the desired target during the\ntraining, and KANs offer the possibility of visualizing the learnable activation\nfunctions. In this way, KANs can be more transparent and efficient in learning\nmore complex relations than MLPs, offering promising alternatives to traditional\ndeep learning models. The learned activations can be low-cost functions (e.g.,\nconstant or linear) when there is no need for complex non-linearities. This also\ngrants the possibility of understanding the salient parts of the input.\nU-KAN U-KAN [22] proposes to implement the deepest layer of the U-Net\nusing KANs. These layers are composed of a tokenization layer, a KAN layer, a\ndownsampling layer, and a final normalization layer. In Figure 3, it is possible\nto see the key difference stands only in how the deepest representations are pro-\ncessed by the network. The main features of the U-Net, such as downsampling\nand skip-connection, remain invariant, sharing the same benefits. The modifica-\ntion in the encoder's last layers and the decoder's firsts allows the network to\nlearn custom activation functions instead of fixed ones, potentially improving\nthe representativity of the embeddings and reducing the required computational\nresources by learning simple activations when needed."}, {"title": "4 Experimental Setup", "content": "This section describes the adopted dataset, the experimental setting, and the\nadopted evaluation metrics for the crop segmentation performance and quality\nof the derived explanations."}, {"title": "4.1 Dataset", "content": "We employed the South Africa Crop Type dataset [46], which contains images\ntaken from both Sentinel-2 and Sentinel-1 covering a wide region of South Africa.\nThe dataset includes small and irregular-shaped [25] crop fields, making it more\nchallenging, and provides higher resolution imagery (of size 256 \u00d7 256) than\nother datasets covering the area. The annotations contain the mask of the areas\ncovered by a certain crop. For our analysis, we limit the scope to distinguish\nbetween cultivated and non-cultivated areas. We analyzed the results using both\ntypes of imagery from Sentinel-2 and Sentinel-1.\nSentinel-1 [44] is a satellite mission under the Copernicus program, com-\nprising two identical satellites equipped with C-band Synthetic Aperture Radar\n(SAR). It provides all-weather, day-and-night radar imaging. The satellite can\nwork in both single-polarization and double-polarization modes. On land, it\nmainly works collecting VV and VH polarizations\nSentinel-2 [14] is part of the Copernicus program and consists of two satellites.\nThese satellites carry high-resolution multispectral imaging instruments with\n13 spectral bands ranging from Ultra-Blue, Visible, Near Infrared (NIR), and\nShort Wave infrared (SWIR). It is particularly sensitive to vegetation due to the\npresence of instruments that work in the infrared spectrum.\nWhile Sentinel-1 images can cover different atmospheric situations due to the\nradiometric nature of the imagery, Sentinel-2 is affected by clouds and similar\natmospheric disturbances. Since the provided cloud masks are often not accurate,\nwe computed the masks with the s2cloudless algorithm [39]. We exclude low-\nquality Sentinel-2 images with a strong overlap between the cloud mask and the\nareas containing crops (intersection over 0.7).\nSince no splits were provided, we randomly divided the dataset into a training\nset containing 2019 training, 267 validation, and 364 test samples. The three\nsplits are similar (p > 0.9) according to the chi-square test when measuring the\nclass frequencies. In this way, we created two datasets with three splits each due\nto the fact the dates of Sentinel-1 and Sentinel-2 do not exactly match because\nof the different revisit times. Figure 4, show a sample from the test set in both\nSentinel-1 VV and Sentinel-2 RGB."}, {"title": "4.2 Experimental Setting", "content": "Crop Field Segmentation The images have size 256 \u00d7 256 \u00d7 2 for Sentinel-1\ndata and shape 256 \u00d7 256 \u00d7 12 for Sentinel-2. We train all networks with an\nAdamW optimizer and a learning rate scheduler with a reduction on plateau\nof factor 0.2 and patience of 5. The initial learning rate was set to 1e-4, and"}, {"title": "KAN You See It?", "content": "the batch size to 16. We trained the models for 60 epochs. We apply random\nhorizontal and vertical flipping as augmentations. The loss function is generalized\ndice loss [41], which takes into account the class imbalance in the images. We\ncompared the two networks with the same encoder (and so decoder) embedding\nsizes to better understand how they exploit the same representation space.\nWe evaluated the networks under Intersection-Over-Union (IoU), F1-Score\n(F1), Precision (Prec), and Recall (Rec) for the positive class. We also evaluated\nGFLOPs to measure the efficiency of the network.\nExplainability We use Grad-CAM [38] as a visual post-hoc explanation method\nfor this task because of its proven effectiveness in previous XAI studies in re-\nmote sensing [18]. Grad-CAM is particularly valuable because it helps answer\nthe critical question, \"Where does the model focus when segmenting crops?\u201d.\nFor each image, we generate a single saliency map to quantify the influ-\nence of each pixel on the prediction of the positive class (i.e., cultivated area)\nmade by a model (i.e., U-NET or U-KAN). In GradCAM, the generation process\nfirst involves computing the gradients of the positive class score with respect to\nfeature maps of a selected convolutional layer. These gradients are then aver-\naged globally to obtain the importance weights for each feature map. Next, a\nweighted sum of these feature maps is performed using the calculated weights.\nThis yields a coarse location map that highlights the regions of the input image\nthat are most influential in model segmentation decisions. Finally, we apply a\nReLU activation to this weighted sum to ensure that only positive influences are\nconsidered, producing the final Grad-CAM heat map. In our experiments, we\nuse Sentinel-2 data, which provides multispectral images over 12 channels, and\ngenerate the explanations for the test set images.\nWe assessed the Plausibility, Sufficiency, and Per-channel Relevance of the\ngenerated Grad-CAM heatmaps. Below, we provide a detailed description of\neach metric."}, {"title": "KAN You See It?", "content": "Plausibility Plausibility refers to the degree to which the explanations align with\nhuman understanding and domain-specific knowledge [13,18,37]. This is crucial\nin ensuring that the models not only perform well but are also aligned with\nhuman expectations and knowledge. In this study, we want to assess to which\nextent each obtained heat map is aligned with the relative ground truth. We\nevaluate the plausibility of saliency maps by calculating each metric (IoU, F1,\nPrec, Rec) between the generated saliency map and the corresponding ground\ntruth mask.\nSince our saliency maps provide continuous explanations where each pixel has\na value of importance, we established a threshold of importance to define which\npixels are considered important for the segmentation with Otsu method [34].\nThis method segments the saliency map into distinct regions, creating a binary\nmask directly comparable to the binary truth mask.\nSufficiency Sufficiency is an aspect of faithfulness, evaluating whether an expla-\nnation indeed captures the important factors contributing to the segmentation\nand, therefore, is sufficient. [24,35].\nTo assess the sufficiency of an explanation, we preserve only the important\npixels identified by the explanation and mask the others. We then evaluate the\nperformance metrics (IoU, F1-score, Precision, and Recall) for the positive class\non this altered image. Sufficiency is computed as the change in metrics between\nthe original and altered images. A smaller drop in performance indicates a more\nsufficient explanation. In this case, we also use the Otsu method to threshold\nthe binary saliency maps.\nPer-channel Relevance Another important aspect of standard XAI evaluation is\nthe variation in performance metrics when the input image is perturbed. Occlu-\nsion sensitivity [8] is a method that involves systematically masking parts of the\ninput image using a sliding window and measuring the change in the model's out-\nput. This technique identifies critical image regions for the model's predictions,\noffering insights into its reasoning and the faithfulness of its explanations.\nIn our specific situation, we apply the idea of occlusion not to parts of the\nimage but to entire channels. This approach aligns better with the nature of\nour data, where each pixel carries its own importance and classification. By\noccluding an entire channel, we can systematically evaluate how the absence of\nspecific channels affects the model's explanation, providing clearer insights into\nthe role each channel plays in the classification process.\nIn our tests, we occlude one channel at a time and calculate the saliency map.\nThen, we measure the IoU between the saliency map obtained by occluding one\nchannel and the saliency map obtained using all channels."}, {"title": "5 Experimental Results", "content": "In this section, we present the results obtained for the analyzed dataset. First, we\noutline crop segmentation performance, addressing our research question RQ1."}, {"title": "5.1 Task Performances", "content": "In Table 1, we report the results obtained when employing U-Net and U-KAN on\nSentinel-1 and Sentinel-2 data. U-KAN provides the best performance in terms\nof IoU on Sentinel-2, proving its adaptability in dealing with complex relations.\nOn Sentinel-1, U-KAN gets comparable performance in terms of IoU to U-Net.\nIn terms of precision, the KAN variant is more performant, scoring \u2248 +3%\nthan U-Net. Although Sentinel-1 imagery is less affected by atmospheric events,\nSentinel-2 bands provide a better understanding of the area with both networks.\nU-KAN proves to be more computationally efficient than a standard U-Net when\nlooking at GFLOPS: it consumes half the one of U-Net.\nThe KAN variant proves to be a preferable solution in both cases, providing\nbetter or comparable performance in fewer GFLOPs. Moreover, it proves to be\nmore precise in any case."}, {"title": "5.2 Analysis of explanations", "content": "We analyze the explainability results of U-KAN and U-Net networks on the\nSentinel-2 dataset through qualitative and quantitative assessments."}, {"title": "Qualitative Evaluation", "content": "We examine the saliency maps obtained from both\nnetworks. This analysis provides insight into the areas where each model focuses\nits attention, offering a deeper understanding of their segmentation behaviors.\nFigure 1 shows examples of saliency maps generated by the U-Net and U-\nKAN models. The red pixels indicate the points where the network's attention\nis most focused, highlighting the differences in the behavior of the two models.\nFigure 1 (c) reveals that the U-Net model focuses on a significantly larger area\nthan the U-KAN model. This observation suggests that, regardless of the effec-\ntiveness of the segmentation task, the U-Net model tends to distribute its focus\nover larger regions. In contrast, the U-KAN model has an interesting feature in\nits approach to the segmentation task. The network focuses predominantly on"}, {"title": "KAN You See It?", "content": "the boundaries of cultivated areas rather than within the areas themselves. This\nfocus on boundaries suggests that the U-KAN model prioritizes delineating the\nedges of areas of interest. This last feature opens up the potential use of U-KAN\nnetworks in boundary delimitation and mapping tasks, where precise edge de-\ntection and delineation are crucial [27,47]. These considerations generally apply\nto the images in the dataset. We included multiple examples of saliency maps in\nour repository."}, {"title": "Quantitative Evaluation", "content": "Table 2 presents the evaluation results of Plausi-\nbility. Regarding the plausibility of explanations, U-KAN demonstrates higher\nIoU and Precision than its competitor, U-Net. This indicates that U-KAN pro-\nvides more accurate and reliable explanations, aligning more closely with human\nunderstanding. On the other hand, U-Net has a higher Recall and F1 score of\nplausibility. This could be because U-Net is more sensitive and captures more\nfeatures in saliency maps, although it includes more false positives."}, {"title": "KAN You See It?", "content": "In Table 3, we present the results assessing the Sufficiency of explanations.\nSufficiency is quantified as the difference in metrics between masked images and\ntheir original counterparts. An interesting observation is the variation in the\nPrecision metric. While there is a decrease in other metrics, which aligns with\nremoving less critical pixels, there is an improvement in Precision for both U-\nKAN and U-Net. This increase in precision is noteworthy because by excluding\nless important pixels, both networks demonstrate an enhanced ability to delin-\neate pixels belonging to crop class."}, {"title": "KAN You See It?", "content": "Table 4 reports the Per-channel relevance results. For each model, we report\nthe IoU score between the saliency map of all channels and the one obtained by\nobscuring the specific channel related to the band. In this context, a lower IoU\nsignifies the higher importance of a channel. Specifically, if removing a channel\nyields a lower or zero IoU, it indicates that the channel plays an important role\nin the final segmentation task. For both U-KAN and U-Net models, we obtain\nthat the channels corresponding to bands B05 (705 nm Red Edge), B8A (865\nnm Narrow Near-Infrared), and B11 (1610 nm Shortwave Infrared 1) are\nidentified as the most significant for crop segmentation task due to their specific\nsensitivities. Specifically, B05 and B8A are sensitive to chlorophyll content and\nvegetation biomass and B11 to moisture content in soil and vegetation [9,11,30].\nThis quantitative evaluation across all test samples aligns with the qualitative"}, {"title": "KAN You See It?", "content": "results displayed in Figure 5, confirming the discussed insights. Analyzing the\nrelevance of each channel in Sentinel-2 images opens the possibility of reducing\nthe number of channels used by focusing on only the most important ones.\nThis optimization can enhance efficiency and reduce computational costs while\nmaintaining the quality of the analysis."}, {"title": "5.3 Analysis of the trained models", "content": "As previously mentioned, KANs are designed with a level of interpretability\nthrough the possibility of visualizing learnable activation functions. Although\nour main goal is to explore the post-hoc explainability of the U-KAN network\nwith respect to the U-Net, we also sought to analyze the behavior of learnable\nactivation functions in a decoding layer. This is also particularly relevant when\nanalyzing the resource consumption of the network since the learned function\ncan be simple to compute (e.g., linear) or complex when necessary, potentially\nhelping both GFLOPs and performance, as shown before.\nIn Figure 6, we report the learned activations for an element of the embed-\ndings in a decoder layer. We can see substantial differences between the base\nfunction (SiLU) and ReLU, commonly employed by U-Net. U-KAN effectively\nrepresented more complex relations in the deep embeddings. The second activa-\ntion is reversed along the y-axis compared to SiLU. The first and the third are\nsimilar but have a different slope (the first function is steeper).\nMoreover, each element of the embedding learns different activations with\ndifferent complexity. Some of them could be constant activations for certain\nelements in the embeddings. The learned functions with a variance < 1 are\n~26% the total, while the ones with a variance < 0.1 are \u2248 8%. This indicates\nthe irrelevant parts of the embedding because every input is mapped to the same\nvalue every time."}, {"title": "6 Conclusions", "content": "In this work, we have shown how the new KANs can improve well-known archi-\ntecture applied to the agricultural field, particularly in terms of efficiency, using"}, {"title": "KAN You See It?", "content": "only half the resources of full CNN architecture. Our study indicates that U-KAN\noffers superior performance by achieving higher precision and IoU scores than\nU-Net. The explainability analysis also reveals two significant insights. First, the\nU-KAN network's emphasis on boundary details makes it particularly effective\nfor tasks such as boundary delimitation and mapping. Second, not all the chan-\nnels are useful for the segmentation task. So, users can decide to rely only on\nthe most important reducing computational costs of the models. In future work,\nwe intend to implement the insights from our network explainability analysis to\nenhance performance and reduce computational costs."}]}