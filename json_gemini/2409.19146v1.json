{"title": "BOUND TIGHTENING NETWORK FOR ROBUST CROWD COUNTING", "authors": ["Qiming Wu"], "abstract": "Crowd Counting is a fundamental topic, aiming to estimate\nthe number of individuals in the crowded images or videos fed\nfrom surveillance cameras. Recent works focus on improving\ncounting accuracy, while ignoring the certified robustness of\ncounting models. In this paper, we propose a novel Bound\nTightening Network (BTN) for Robust Crowd Counting. It\nconsists of three parts: base model, smooth regularization\nmodule and certify bound module. The core idea is to propa-\ngate the interval bound through the base model (certify bound\nmodule) and utilize the layer weights (smooth regularization\nmodule) to guide the network learning. Experiments on dif-\nferent benchmark datasets for counting demonstrate the effec-\ntiveness and efficiency of BTN.", "sections": [{"title": "1. INTRODUCTION", "content": "Crowd counting aims to estimate the total number of pedes-\ntrians in static images or dynamic videos. This task has\ndrawn great attention because of its variety of applications\nin the real world. However, accurately counting people in\nthe crowds is challenging due to diverse crowd distributions,\nsevere occlusion and large-scale variations. With the rapid\nprogress of deep neural networks (DNNs) [1, 2, 3, 4, 5], the\nrecent data-driven models have gained excellent counting\nperformance. These methods can be roughly divided into\nthree groups: directly applying object detector on the input\nimage [6, 7], learning a mapping from patches to a number\n[8, 9] and summing over the predicted density map [10, 11].\nThe mainstream focus in the counting area has been towards\nexploiting the advances in density map based methods due to\nthe remarkable representation learning ability.\nDespite the dramatic performance improvement in count-\ning accuracy, few works [12, 13] have been devoted to the\nrobustness of the models. Current estimation-based crowd\ncounting models are highly vulnerable to adversarial exam-\nples since small perturbation may lead to wrong predictions.\nWu et al. [12] first propose a systematic and practical method\non the evaluation of the robustness in the counting area.\nThey design adversarial patches to successfully attack several\ncounting models in white-box and black-box forms. Fur-\nther, Liu et al. [13] propose a Perceptual Adversarial Patch\n(PAP) framework, which promotes the transferability of our\nadversarial patches by exploiting the model scale and posi-\ntion perceptions. But they only focus on designing attack\nalgorithms, leaving the defense pattern unresolved.\nIn this paper, we propose a novel Bound Tightening\nNetwork (BTN) for Robust Crowd Counting. Specifically,\nthe model is composed of three parts (as shown in Figure\n1): Smooth Regularization Module, Base Model and Certify\nBound Module. In the smooth regularization module, BTN\nutilizes layer weights of the base model to introduce the reg-\nularization term in certificate model training. This module\nhelps smoothen the training loop and benefits the final per-\nformances against adversarial examples. In the certify bound\nmodule, we manually introduce the adversarial perturbation e\nand construct the initial interval bound [x \u2212 \u03f5, x + \u03f5] based on\nthe input image x. Then, the module propagates the interval\nbound through model layers and provides a possible predic-\ntion area to guide the later training loop. After iterations of\ncertificate training, BTN finally becomes robust against ad-\nversarial perturbations and could provide a tight bound of the\nmodel prediction.\nIn summary, our contributions are as follows: we propose\na novel network named BTN for robust crowd counting. It not\nonly provides theoretical guarantees of the model prediction\nagainst adversarial examples, but also enhances the model ro-\nbustness on different standard datasets in crowd counting."}, {"title": "2. METHODOLOGY", "content": "Regression Based Crowd Analysis. Given a set of N labeled\nimages D = {(xi, li)}i=1N, where xi \u2208 RH1\u00b7W1\u00b7C1 and H1,\nW1, and C\u2081 are the height, width, and channel number of\nthe image, respectively. li is the ground truth density map of\nimage xi. Then, the crowd analysis task aims to learn a model\nfo, parameterized by 0, which can map from a crowd image\nto a corresponding density map by using these labeled images\nand solving the following optimization problem:\n$\\min_\\theta \\frac{1}{2N} \\sum_{i=1}^N |f_\\theta(x_i) - l_i|^2$.\nNote that researchers recently have adopted more effective\nloss functions in crowd counting [2, 1] and we consider the\nmost commonly used L2 loss function. Moreover, different\ncrowd counting models will use different architectures. For\ninstance, MCNN [3] uses Multi-column convolutional neural\nnetworks to predict the density map. The learned model fo\ncan be used to predict the crowd count in a testing image x.\nSpecifically, fe takes x as an input and outputs the predicted\ndensity map fe(xi). Then, the crowd count in x is estimated\nby summing up all values of the density map.\nThreat Model. In this paper, we focus on white-box ad-\nversarial attacks, which represent the most powerful adver-\nsary since it has access to the parameters and architecture of\nthe target model. We now define the Lp norm adversary for-\nmally as follows:\n(Lp, \u03f5)-Adversary in Crowd Counting. Given the\ndataset D = {(xi,li) \u2208 X \u00d7 Y|i = 1,..., N}, where X,\nY denotes the input space and the true label space, respec-\ntively. The Adversary will generate a well-crafted input\nx \u2208 Bp,e(xi) such that fo(x) \u2260 li (with large distances)."}, {"title": "2.1. Certify Bound Module", "content": "The certify bound module exams if the model output satisfies\na given specification. On crowd counting models, we certify\nthe pixels of the output density map, namely, every pixel value\nwill be bounded within an interval:\n$\\forall x_o \\in S(x_k, \\epsilon) = \\{ x | ||x - x_k||_\\infty \\leq \\epsilon \\},\\\\Z_{Ki} \\in [\\underline{Z}_{Ki}, \\overline{Z}_{Ki}],$\nwhere ZKi denotes the i-th pixel of the model output ZKi and\n$\\underline{Z}_{Ki}, \\overline{Z}_{Ki}$ represent the element-wise lower bound and upper\nbound for ZKi. Now consider the Groundtruth map GT for\nthe Zki, GTi is the i-th pixel value, we have:\n$\\min\\limits_{i}\\max\\limits_{i}(|GT_{i} - \\underline{Z}_{Ki}|, |\\overline{Z}_{Ki} - GT_{i}|),$ \nwhere the inner \u2211i max(|GTi \u2212 \\underline{Z}Ki|, |\\overline{Z}Ki \u2212 GTi|) denotes\nthe verification goal, namely, finding the worst-case robust-\nness bounds. Besides, the outer part minf\u03b8 means to turn the\nverification to the robustness optimization for a tighter bound\nby training the model f\u03b8 through the verification equation."}, {"title": "2.2. Smooth Regularization Module", "content": "To begin with, we first propose the Norm Duality theorem\nbased on the H\u00f6lder Inequality to theoretically guarantee the\nlegitimacy of using L1 and L2 regularization in the robustness\ntraining process.\nTheorem 1. (Norm Duality) Consider the activation func-\ntion ReLU, the model f have K affine layers, zo = x and Wi\nrepresents the i-th affine layer. Given the adversarial example\n{x: ||x - x||\u221e\u2264 \u03f51} as the input example, we have:\n$\\|| f(\\tilde{x}) - f(x) \\||_{\\infty} \\leq \\epsilon_1 \\prod_{m=1}^K \\max_j ||W_{mj}||_1.$\nBased on the Theorem 1, we now optimize the right part\nas to verifiably train the model. For total K affine layers, we\nmodify the optimization part as $\\min\\limits_\\theta \\sum_{i=1}^K ||W_i||_1$, which\nis the L1 regularization form. Further more, we derive the\nfollowing lemma:\nLemma 1. (L2 Norm Cases). Consider the L2 norm bounded\nadversarial example {x: ||x - x||2 < \u03f52} and the notations\nin Theorem.1, for any neuron j of z\u2081, we have:\n$|z_{1j} - \\tilde{z}_{1j}| \\leq \\epsilon_2 ||W_{1j}||_2.$\nProof. The detailed proof of the theorem and the lemma will\nbe shown in the code repositories.\nConsidering Theorem 1 and Lemma 1, our loss is com-\nposed of three parts: Normal training loss, Certify error loss\nand Regularization loss. The general form of the practical\nloss is:\n$L_{total} = \\kappa L_{normal} + (1 - \\kappa) L_{certify} + \\lambda L_{reg}.$\nFor regression-based crowd counting models, we use the\nMean Squared Error (MSE) loss as it is the most widely used\nloss form in the field of crowd counting. Then we rewrite the\ntotal loss function Ltotal:\n$\\begin{aligned}\nL_{total} = & \\frac{1}{2N} \\{\\sum\\limits_{j=1}^N \\|| f_\\theta(\\tilde{x_j}) - l_j \\||^2 \\\\\n&+\\n  (1 - \\kappa) [\\max(\\mid GT_i - \\underline{Z}_{Ki}\\mid, \\mid \\overline{Z}_{Ki} - GT_i \\mid)]^2 \\\\\n& +\\lambda \\sum\\limits_{m=1}^K \\||W_m\\||_1\\}.\n\\end{aligned}$"}, {"title": "2.3. Robustness Optimization.", "content": "We utilize above two modules to guide the robustness op-\ntimization (i.e., BTN certificate training). Given the base\nmodel f initialized with 00, we adopt the multi-stage training\nschedule: 50 epochs to warm up (\u03ba = 1 in Eq.7), 150 epochs\nfor the slow decrease of \u03ba (from 1 to 0.5) and 200 epochs for\nthe certificate training (\u03ba = 0.5). Besides, the weight decay\nparameter \u03bb = 1 \u00d7 10\u22123 and \u03b2 = 10 (L2 cases)."}, {"title": "3. EXPERIMENTS", "content": ""}, {"title": "3.1. Experiment Setup", "content": "Dataset. For crowd counting, we verifiably train and evaluate\nthe robustness bounds on the ShanghaiTech A and B dataset\n[3], which is the most representative dataset in the field con-\ntains 1198 images with over 330,000 people annotated. For\nablation studies on image classifiers, we select the most com-\nmonly used CIFAR10 and Tiny-ImageNet [14].\nModel Structure. In this paper, we utilize the MCNN\n[3] as the base model, which has three branches composed\nof convolutional and max-pooling layers. MCNN is popular\nfor its great transferability to various tasks. For ablation stud-\nies on image classifiers, we use the same Medium and Large\nCNN models in IBP [15] for a fair comparison. And we use\nthe same model as in \"BCP\" method [16] to train on the Tiny-\nImageNet [14].\nEvaluation Metrics. For crowd counting, we propose\ntwo metrics for the evaluation of robustness: certify-tight\nMAE & MSE and certify-pixel MAE & MSE:\n$Certify\\text{-}tight\\text{ }MAE = \\frac{1}{N} \\sum_{i=1}^{N} \\mid C^{GT} - \\tilde{C} \\mid,$\n$Certify\\text{-}tight\\text{ }MSE = \\frac{1}{N} \\sum_{i=1}^{N} (C^{GT} - \\tilde{C})^2,$\nwhere N is the number of images, CGT denotes the i-th\nground-truth counting and C\u2081 is the counting of the robustness\nbound (upper or lower bound). In fact, we select the maxi-\nmum distance between GT and the robustness bound, namely,\n$\\mid C^{GT} - \\tilde{C_i} \\mid= max(\\mid C^{GT} - C(\\underline{z}_{Ki})\\mid, \\mid C(\\overline{z}_{Ki}) - C^{GT}\\mid)$.\nTo better evaluate the worst case of every pixel on the output\ndensity map (measure the model performances on the pixel\nlevel), we introduce the Certify-pixel MAE & MSE:\n$Certify\\text{-}pixel\\text{ }MAE:\n\\frac{1}{N} \\sum\\limits_{i} \\sum\\limits_{j} \\max(\\mid \\underline{Z}_{Kij} - GT_{ij}\\mid, \\mid GT_{ij} - \\overline{Z}_{Kij}\\mid),$\n$Certify\\text{-}pixel\\text{ }MSE:\n\\frac{1}{N} \\sum\\limits_{i} \\sum\\limits_{j} [\\max(\\mid \\underline{Z}_{Kij} - GT_{ij}\\mid, \\mid GT_{ij} - \\overline{Z}_{Kij}\\mid)]^2.$"}, {"title": "4. CONCLUSION AND FUTURE WORK", "content": "We creatively propose the efficient and scalable regression-\nbased neural network certification method named BTN,\nwhich adopts the \"smooth regularization module\" and the\n\"certify bound module\" in the certificate training loops.\nMoreover, we theoretically demonstrate the feasibility and\nthe tight bound of BTN, and experiment with BTN on the\npopular crowd counting dataset along with some classifica-\ntion datasets. We find that BTN performs effectively and\nefficiently on these datasets and even better than the state-\nof-the-art method like CROWN-IBP. In addition, BTN has\nstrong practicability and can be compatible with the main-\nstream crowd counting networks as basic models. Our work\nhighlights the need for future works on the verification of\nneural networks."}]}