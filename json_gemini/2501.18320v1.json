{"title": "Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach", "authors": ["Tianpeng Pan", "Wenqiang Pu", "Licheng Zhao", "Rui Zhou"], "abstract": "Automated optimization modeling (AOM) has evoked considerable interest with the rapid evolution of large language models (LLMs). Existing approaches predominantly rely on prompt engineering, utilizing meticulously designed expert response chains or structured guidance. However, prompt-based techniques have failed to perform well in the sensor array signal processing (SASP) area due the lack of specific domain knowledge. To address this issue, we propose an automated modeling approach based on retrieval-augmented generation (RAG) technique, which consists of two principal components: a multi-agent (MA) structure and a graph-based RAG (Graph-RAG) process. The MA structure is tailored for the architectural AOM process, with each agent being designed based on principles of human modeling procedure. The Graph-RAG process serves to match user query with specific SASP modeling knowledge, thereby enhancing the modeling result. Results on ten classical signal processing problems demonstrate that the proposed approach (termed as MAG-RAG) outperforms several AOM benchmarks.", "sections": [{"title": "I. INTRODUCTION", "content": "Sensor Array Signal Processing (SASP) has experienced remarkable advancements over the past few decades [1], which finds utility in a spectrum of applications, including telecommunications, radar, sonar, etc. Research within this field has encompassed areas such as beamforming, direction-of-arrival (DOA) estimation, primal user detection, source localization, etc. Over time, SASP has witnessed a paradigm shift from a predominantly parametric approach [2] to optimization methodologies [1], [3], leading to substantial advances in various application domains. Typically, SASP problems can be formulated as optimization problems, where mathematical formulations (objective functions and constraints) are established from the prior knowledge of the sensor system models and the final processing goal.\nTraditionally, solving SASP problems necessitates the manual formulation and development of algorithms by human experts. However, the recent invention of Large Language Models (LLMs) demonstrates the potential to revolutionize SASP problem-solving. In particular, LLMs are capable of comprehending natural language inputs and generating logical sequences as responses, allowing users to describe the SASP problem and requirement in an intuitive way. Moreover, LLM has shown talent towards comprehension on mathematical equations [4]\u2013[6]. This enables the automation of optimization model and algorithm suggestions, streamlining the process of finding effective solutions for diverse SASP problems. This approach is termed automated optimization modeling (AOM), which has great potential for immediate but reasonable solutions for a wide range of SASP applications.\nCurrently, AOM methods [4], [6] predominantly utilize prompt engineering, including guiding LLMs to perform step-by-step reasoning [6]\u2013[12] and deploying multi-agent systems to generate manually crafted response chains [13]\u2013[16]. This approach engages LLMs in constructing logical sequences for problem solving, emulating human cognitive processes [7]. However, the inherent knowledge deficiencies present within LLMs has not yet been resolved. To clarify the knowledge referenced, the retrieval-augmented generation (RAG) [17], [18] method has recently been proposed. Notable performance improvements have been realized through the optimization of dataset structure [19] and the enhanced training of the retriever model [20]\u2013[22]. However, despite these efforts, the SASP domain involves substantial domain-specific knowledge, limiting the success achieved by current AOM strategies.\nTo realize the potential of LLM-assisted AOM for SASP problem-solving, we introduce an automated modeling approach, which combines a multi-agent (MA) structure with a specific graph-based RAG (Graph-RAG) process. The MA structure is specifically tailored for the architectural complexities of AOM processes, following on principles of human expert's problem-solving logic. Each agent in the system is designed to tackle a segment of the problem, thereby decomposing a challenging mission into manageable sub-tasks [13]. The Graph-RAG component enhances this setup by matching user inputs with detailed domain modeling knowledge. This process mitigates the complexity of the AOM task, and further improves the performance by ensuring that only pertinent information is retrieved and utilized in modeling generation. Unlike traditional RAG, Graph-RAG organizes prior knowledge using a graph structure, making the retrieval process precise, crucial for fields like SASP where specific knowledge is needed [18]. The proposed approach is termed as MAG-RAG. To evaluate it, we build a testing dataset, which includes 10 classical SASP problems along with recommended solutions. The experimental results indicate that MAG-RAG"}, {"title": "II. THE PROPOSED AOM APPROACH", "content": "The pipeline of the developed approach consists of two workflows as illustrated in Fig. 1. The blue workflow illustrates the utilization of the Graph-RAG technique for constructing a knowledge database from domain-specific documents. This knowledge database can provide professional optimization modeling examples tailored to the user's query input (see example in Fig. 2). The other workflow in brown is the automated optimization modeling procedure, requiring the involvement of several agents. Before we formally introduce the pipeline structure\u00b9, we specify three agents for AOM in the SASP domain, namely, Extraction Agent $A_{ET}$, Terminology Agent $A_{TG}$, and Optimization Modeling Agent $A_{OM}$. The role of each agent is explained as follows:\nExtraction Agent $A_{ET}$. This agent receives raw documents {$I_1, I_2,..., I_N$} in the SASP field as input, and strictly follows instructions from prompt $P_{ET}$ to extract knowledge {$O_1, O_2,..., O_N$} critical for optimization modeling. Take $I_i$, $i \\in [1,..., N]$ as an example, the key knowledge extraction process can be formulated as follows:\n$O_i = A_{ET} (P_{ET}, I_i)$.\nTerminology Agent $A_{TG}$. This agent transforms original user input $Q$ into terminological description $P$. Given a specially designed prompt instruction $P_{TG}$, the extraction process is as follows:\n$P = A_{TG} (P_{TG}, Q)$.\nOptimization Modeling Agent $A_{OM}$. This agent provides a complete modeling result $M$ for $P$ with reference to the extracted prior knowledge $K$. Prior knowledge $K$ is obtained from a Graph-RAG searching process (to be explained in Sec. II-C) with the query embedding of $P$. The generation process of $A_{OM}$ can be formulated as follows:\n$\u041c = \u0410_{OM} (\u0420_{OM}, \u041a, \u0420) .\nThe pipeline of AOM is summarized as follows. Firstly, with the user-input query $Q$ including the scene description, a Terminology Agent $A_{TG}$ converts unspecified user input query into a terminological problem description $P$. Secondly, we retrieve top-k most relevant documents as reference knowledge $K$ based on description $P$. Finally, combining the terminology description $P$ with reference knowledge $K$, Agent $A_{OM}$ provides an answer $M$ as the output. The retrieval technique in the second step is Graph-RAG which will be explained in the subsequent section."}, {"title": "B. Graph-RAG Dataset Construction", "content": "To assist LLMs with sophisticated SASP modeling, we construct a graph-based data base, where domain knowledge is extracted and represented as nodes, then weighted edges are formed among correlated nodes before knowledge searching.\nModeling Information Requirements: Initially, N domain knowledge documents {$I_1, I_2,..., I_N$} are collected as raw property to construct the database. Though we anticipate the original documents to possess more information, they may also introduce information redundancy. Since not all the provided information contributes positively to the AOM task, excessive information imposes an additional burden on the modeling agent, which must first extract the essential information from the documents before proceeding with the subsequent modeling process. Besides, context limitation of LLMs [13], [23] should also be seriously treated.\nThus, an Extraction Agent $A_{ET}$ is developed to distill the original documents into content pertinent to optimization modeling {$0_1,0_2,...,0_N$}. In order to conquer the uncontrollability of the LLM responses, we make it strictly follow the modeling mindset of human expert (as illustrated in Fig.2) with a target-definite prompt, where LLM response is instructed to consist of five parts: terminological description, example information, system model, optimization formulation and optimization algorithm. An example of the results is illustrated in Fig. 3.\nDataset Construction of Graph-RAG: The extracted content is formulated as a graph structure [19], [24]:\n$G = (V, E)$,\nwhere $G$ denotes the graph dataset, $V$ and $E$ represent nodes and edges, respectively. Such a structure is chosen due to the fact that the graph structure is inherently endowed with a hierarchical process, allowing for a natural division of graphs into sub-graphs to capture the optimization modeling procedure. Additionally, graphs present superior flexibility for community"}, {"title": "C. Knowledge Searching Using Graph-RAG", "content": "$v_i$, the embedding of each node's key words is generated as: $v_i = f_e (f_k (n_i))$, $v_j = f_e (f_k (n_j))$, where $f_e$ denotes the transformation from natural language to feature space using text-embedding-3-small [26], and $f_k$ is the value extraction process from the node attribute \u201ckeyword\". Then, cosine similarity $s_{ij}$ is applied to calculate the relevance:\n$s_{ij} = \\frac{v_i \\cdot v_j}{||v_i||\\times||v_i||}$\nIf $s_{ij}$ is greater than $\\delta$, a relationship between $n_i$ and $n_j$ is established, with $s_{ij}$ assigned as the value of \u201csimilarity\u201d attribute.\nKnowledge searching process plays a vital role in Graph-RAG process. Due to the tendency of LLMs to utilize few-shot learning [27], they prefer to draw on the given examples for responses. Furthermore, $A_{TG}$ produces content consistent with SASP terminologies, thus we employ \"PT\" layer for knowledge searching. For instance, considering a node $n_p$, $p \\in [1,..., N]$, the relevance of it to $P$ can be determined as:\n$S_{ep} = \\frac{f_e (P) \\cdot f_e (f_k (n_p))}{||f_e (P)||\\times||f_e (f_k (n_p))||}$.\nThen we manually produce a set $L$ that preserves the similarity of $n_p$ to $P$:\n$L\\leftarrow L\\cup\\{n_p: S_{ep}\\}$.\nFinally, the nodes corresponding to the top-k similarities in L are selected. We build the knowledge K for AOM by concatenating the node content connected by \u201cSD\u201d edges from these selected nodes. In this paper, we set k = 3, by taking into account the context limitation and knowledge richness."}, {"title": "III. EXPERIMENTS", "content": "Dataset: We select ten classical SASP problems to evaluate the AOM performance, including transmitted beam pattern matching (Q1), cooperative sensing under ideal communication conditions (Q2), sensor placement (Q3), MIMO radar waveform design (Q4), direct positioning determination (Q5), DOA estimation (Q6), interference signal suppression (Q7), bearing-based localization (Q8), TOA-based localization (Q9) and TDOA-FDOA-based localization (Q10). For each issue, we finely select a number of documents containing standard modeling approaches to construct dataset SPAMR. The selected documents contain heuristic modeling strategies and optimization algorithms that can help researchers and LLMs improve the modeling process.\nComparison Methods: To fully evaluate MAG-RAG, we employ two external benchmarks. Pure MA refers to a pure agent logic chain for AOM, that the knowledge retrieval process of Graph-RAG is replaced by Knowledge Generation"}, {"title": "IV. CONCLUSION", "content": "In this paper, we propose MAG-RAG approach for AOM, targeting SASP problems. We transform the AOM process into consecutive but separate parts, and based on this, a MA architecture is utilized to assign different sub-tasks into different LLMs. To enhance the efficiency, a graph-based RAG is adopted, where prior knowledge can be structurally stored and searched with more performance improvement.\nFinally, we note that the proposed MAG-RAG mainly explores AOM for different SASP problems, while implicit relation between similar optimization algorithms is not sufficiently explored. Moreover, the inherent clustering strategy towards correlative SASP issues that may potentially enhance the knowledge searching efficiency is still unexplored."}]}