{"title": "Bridging Today and the Future of Humanity: AI Safety in 2024 and Beyond", "authors": ["Shanshan Han"], "abstract": "Significant progress has been made in AI safety. However, as this field thrives, a critical question emerges: Are our current efforts aligned with the broader perspective of history and human civilization? This paper presents a blueprint for an advanced human society and leverages this vision to guide contemporary AI safety efforts. We outline a future where the Internet of Everything becomes reality, and create a roadmap that represents significant technological advancements towards this envisioned future. For each stage of advancement, we forecast potential AI safety issues that humanity may face. By projecting current efforts against this blueprint, we examine the alignment between the present motivations and long-term needs. We identify gaps in current approaches and highlight unique challenges and missions that demand increasing attention from AI safety practitioners in the 2020s, addressing critical areas that must not be overlooked in shaping a safe and responsible future for AI development. This vision paper aims to offer a broader perspective on AI safety, emphasizing that our efforts should not only address immediate concerns but also anticipate potential risks in the expanding AI landscape, thereby fostering Al's role in promoting a more secure and sustainable future for human civilization.", "sections": [{"title": "Introduction", "content": "The rapid development of AI and Large Language Models (LLMs) has fostered extensive progress in AI safety, specifically, LLM safety. Researchers have been dedicated to addressing potential security and privacy risks in LLM lifecycle, aiming to align AI behaviors with human values and prevent misuse of LLMs, inappropriate outputs, information leakage, etc. However, despite the intense focus on LLM safety, a critical question emerges: Are these efforts on AI safety truly on the right track, aligned with the evolution of human civilization, or are they merely addressing concerns of the present stage?\nOne fundamental reason for this uncertainty lies in the probabilistic nature of current AI. Despite their impressive capabilities in natural language processing and problem-solving, today's AI, including advanced LLMs, falls short of what could be considered genuine intelligence. These systems heavily rely on vast training datasets to function effectively, and lack true understanding, consciousness, self-awareness, and the ability to reason in ways comparable to human cognition. They are, in essence, highly sophisticated pattern recognition and prediction machines, rather than entities capable of abstract thought and genuine reasoning. Moreover, recent studies have raised concerns about the reasoning abilities of LLMs, which may actually be a form of approximate retrieval from their training data and the deductive closure of the training data [28, 61]. While this process can simulate deductive reasoning in simpler cases through external validation, optimization, and repeated searching of the problem space, it fundamentally differs from human reasoning that involves abstract thinking, causal understanding, and the ability to generalize from limited examples.\nThe unresolved issue of sustainable energy is another critical factor that challenges our current efforts to AI safety. Current AI fails to fully represent a third industrial revolution from the perspective of human history, as the fundamental energy issue remains unsolved. Historically, the two industrial revolutions that have profoundly shaped human civilization were driven by revolutionary energy innovations, with the First Industrial Revolution fueled by steam and coal, and the Second Industrial Revolution characterized by a new wave of technological innovations powered by electricity and petroleum. However, current AI, rather than solving energy issues, consumes a significant amount of energy. Training GPT-4 consumed over 50,000 MWh, 10,353.5 tons of CO2 equivalent and approximately 0.02% of California's annual electricity generation [44, 10, 2]. Also, inference with LLMs is also computationally intense, e.g., a single query to GPT-4 consumes 0.001 to 0.01 kWh, approximately 15x energy than a Google query [40, 18]. Given that ChatGPT alone has over 200 million weekly active users and receives over 1.54 billion page visits monthly [55], when scaled to billions of queries, the energy consumption becomes substantial. The significant energy requirements of current AI systems raise serious sustainability concerns and limiting their deployment throughout the human society. Thus, until we overcome the energy constraints, AI's ability to reshape society remains restricted.\nThese concerns suggest that our efforts on AI safety today may fail to capture deeper insights that could emerge as AI evolves, potentially neglecting technological challenges that ultimately shape the impact of AI on human civilization. This raises several critical questions:\n\u2022 Are we focusing on the right problems that align with the long-term AI development?\n\u2022 Are we potentially overlooking significant challenges that will emerge as AI evolves?\n\u2022 Are we on the right track for addressing real challenges in AI safety?\n\u201cThe Moon and Sixpence.\u201d This paper envisions an ultimate advanced society in a distant future of human civilization for forecasting technological advancements to guide today's AI safety research. In this future, energy issues have been resolved, and intelligent chips and brain-computer interfaces have been fully developed, which enables advanced intelligent robots to integrate into everyday life. Breakthroughs in foundational theories, such as Einstein's relativity and quantum computing, have catalyzed revolutionary progress in AI, and humans and robots are connected in an interconnected network, i.e., the Internet of Everything, as illustrated in Fig. 1. While this vision may be beyond the horizon of several decades, by reviewing the present landscape of AI safety against the far future, we gain insights into the potential and limitations of our current approaches, as well as specific missions for AI safety researchers in the 2020s that might otherwise be overlooked. It reminds us that while addressing today's immediate concerns is crucial, we should avoid being constrained by these short-term solutions and look toward the future to guide our present efforts better.\nTakeaways: i) The term \u201cAI safety\" can be extended to \"AI quality assurance\" to encompasses more comprehensive concepts and possibilities in the fast evolving AI landscape. ii) Deeper collaboration with experts from diverse fields is essential to ensure the standards to align with human values. iii) AI workflow customization and user-AI interactions are important, especially in dynamic contexts and across different user groups. iv) Customized AI safety workflows are in need. Humanity's pursuit of higher technology will never stop. While searching for the sixpence on the ground, do not forget to look up at the night sky and chase the moon."}, {"title": "From the New World", "content": "In this future, humanity has entered an unprecedented era. Scientists have achieved breakthroughs in energy production with technological innovations. The resulting flood of abundant, clean energy has revolutionized human civilization beyond the our ancestors' wildest dreams, reshaping the world and initiating a new chapter of human civilization."}, {"title": "Imagining the Future: Blueprint Picture", "content": "The transformative energy revolution has catalyzed human civilization from every aspect. Foundational theories of science have undergone revolutionary breakthroughs, with major advancements in nanotechnology, quantum mechanics, and Einstein's relativity theories. The world has been reshaped by innovative technologies such as intelligent chips, brain-computer interfaces, holographic technology, and advanced 3D printing, bringing about changes in daily life of miraculous.\nTransportation has evolved dramatically. While simple mechanical vehicles, such as fixed-track trains and high-speed rail, still exist due to their efficient and straightforward design, they operate at astonishing speeds with high stability, powered by efficient and limitless energy. Advanced autonomous vehicles and aircraft are widespread and are controlled by intelligent chips, eliminating the need for any human intervention. Also, due to breakthroughs in Einstein's relativity theories [13, 14] and Quantum Mechanics [15, 75], humanity has unlocked the potential of instant spatial-temporal transportation that allow for long-distance travel in short time that transcends the imagination of the 21st century.\nAdvanced brain-computer interfaces and intelligent microchips has revolutionized the way people perceive, which expands the boundaries of human cognition. No longer are people operating devices and asking questions in search engines or LLMs; the embedded intelligence chips help them to gather more comprehensive information and interact with the surrounding environment. Meanwhile, communication over long distances has transcended the limitations of cables and the outdated internet; information, thoughts, emotions, and sensations flow through a new medium due to the advancement in quantum computing.\nIntelligent robots have been integrated into every aspect of modern society and play important roles of daily life. Different from their \"data-hungry machine intelligent ancestors\" that relies on huge amount of training data and statistical patterns in the early 21st century, these intelligent robots perceive and learn through intelligent chips, which are real artificial intelligence and possess genuine understanding and adaptability, much like a human child discovering the world for the first time. Also, their functionalities are customizable through specialized chips based on user needs. Robots can engage in complex interactions with people and adapt their capabilities and expertise to suit their human counterparts' requirements.\nIn this brave new world, humans and robots exist within a vast, interconnected perceptual network, where the boundaries between the digital and physical worlds have been blurred, i.e., the Internet of Everything. Such a network integrates objects with embedded intelligent chips, such as smart devices, autonomous systems, intelligent robots, and humans cognition, which allows for unprecedented levels of efficiency, personalization, and adaptability and fundamentally reshapes the way people interact with the world."}, {"title": "Retrospective on AI Safety in the New World", "content": "In a world where the Internet of Everything has become a reality, intelligent robots are customized to meet diverse user needs and seamlessly integrate into daily life; see Figure 1. Consequently, the concept of AI safety has been redefined to focus more on the quality of services they provide, i.e., emphasizing comprehensive quality assurance. Unlike today's command-and-response interactions between humans and LLMs, future robots can engage in sophisticated reasoning, emotional cognition, and possess appropriate levels of autonomy. They will also interact dynamically with other entities, including humans and fellow robots, within the interconnected system.\nThe Internet of Everything scenarios necessitate the robots to handle complex interactions, demanding a sophisticated understanding of the environment for decision-making. Care robots, for instance, should not only assist physically but also recognize emotions and offer emotional support or suggestions, while cleaning robots need to assess whether a room requires more work based on its cleanliness level. Such advanced interactions require deep understanding of the environments, demanding real-time information retrieval and processing, which is far beyond what can be achieved with simple code logic. Robots must continuously collect and analyze data from their environment, and integrate external inputs with contextual knowledge to facilitate real-time decision-making, such that they can deliver high-quality services that align precisely with human needs and expectations.\nCustomization is a key aspect of future robots for providing personalized services to meet individuals' requirements. Even robots of the same type should be capable of adapting their services to different individuals. Teaching robots should adjust educational materials and teaching methods to capitalize on each student's unique talents and strengths, while cleaning robots should intelligently schedule their works to minimize disruption to other humans in the household, e.g., avoiding occupied workspace. Such customization aligns the robots' capabilities with specific user preferences, and ensures that the robots serve as effective assistants across a wide range of daily tasks and environments.\nFinally, the effectiveness of intelligent robots in the Internet of Everything requires a balance between robot autonomy with human oversights. Too little autonomy would burden users with continuous supervision, while too much autonomy could raise safety concerns or result in unintended behaviors. For instance, a care robot may operate with high autonomy when monitoring vital signs or providing routine care, but would require human intervention for critical decisions. Conversely, while the tasks of cleaning robots are generally routine, they must still adapt to specific circumstances, such as recognizing when an area is occupied by people and postponing cleaning activities. An appropriate level of robot autonomy optimizes the division of labor between humans and robots, ensuring that robots function effectively and safely while enhancing our daily lives without compromising human control over these intelligent robots."}, {"title": "Bridging Today and the Future", "content": "This section presents an ambitious roadmap towards the aspirations for the advanced future, exploring key milestones in the evolution of AI and human civilization. By considering potential paradigm shifts in fundamental theories and breakthroughs in technology, we feature this fascinating journey into three eras, i.e., i) the data-driven era where AI learns knowledge from vast training datasets, ii) the neural augmentation era where Human-machine interface and intelligent chips extend the boundary of human cognition, and iii) the revolutionary era with a breakthrough in energy production that catalyzes transformative changes across every aspect of human society; see \u00a73.1, \u00a73.2, and \u00a73.3, respectively. We then examine the evolving paradigms of AI safety throughout this journey, analyzing the potential focuses and challenges of each era and exploring the impacts of technological advancement on AI safety in \u00a73.4."}, {"title": "Rookie Level: Data-Driven Era", "content": "The Data-Driven Era represents the early phase of AI development, where AI models heavily rely on the quality, availability, and quantity of training data. In this era, AI makes probabilistic inferences based on patterns found in massive training datasets, thus failing to achieve genuine understanding of data. While AI in this era cannot be regarded as real intelligence, it assists people to solve problems and enhances productivity in the society.\nStage 1: Past, Current, and the Near Future. This stage is characterized by diverse AI models for processing various forms of data across different scenarios. Researchers have been engaging in refining model structures and developing advanced algorithms, enabling more sophisticated analysis of data in different formats. The thrive of LLMs exemplifies this progress, showcasing unprecedented capabilities of AI models in language processing and generation. Concurrently, we observe significant advancements in other fields such as computer vision, with progress in image processing and video analysis, as well as advancements in audio recognition. This stage is driven by exploring vast datasets and the refining algorithms continuously, which consistently pushes the boundaries of AI capabilities within specific domains.\nStage 2: Interdisciplinary AI. This stage is characterized by leveraging AI to transform traditional fields, such as healthcare [57, 1], finance [69, 78], and education [49, 38], through cross-disciplinary applications in human society. Mature multi-agent systems [31, 66, 70, 21] that leverage AI entities with different specializations will be widely utilized to assist people and solve sophisticated problems. Such agents participate in decision-making processes, or represent users to finish some tasks, providing more sophisticated solutions of a given problem. In healthcare, for example, a multi-agent system may involve collaboration between various medical agent specialties and integrate data from diverse sources to formulate comprehensive treatment plans. The rise of interdisciplinary AI integration will amplify the utility of AI in more complex scenarios. Although AI at this stage is still not real intelligence, it becomes deeply embedded in different domains in human society, and may catalyze the emergence of new fields at the intersection of traditional disciplines and AI."}, {"title": "Champion Level: Neural Augmentation Era", "content": "In this era, AI models have been widely applied in human society, and humans may witness breakthroughs in advanced technologies and fundamental theories, which may extend the boundary of human cognition and life experience.\nStage 3: Breakthroughs in Advanced Technologies. In this stage, breakthroughs in advanced technologies emerge, such as brain-computer interfaces, Nanotechnology, and holographic technologies. These innovations enable unprecedented levels of interaction between humans and machines by augmenting human senses and cognition. For instance, intelligent chips may be developed that integrate directly with the human body, creating a seamless interface between biological and digital systems. Such advances also change the nature of the data. Unlike traditional static formats such as text, images, or videos, the data in this stage becomes more comprehensive, encompassing dynamic, real-time, and sensory-rich formats, such as neural activity patterns or real-time environmental data from augmented reality systems. In addition to the advancements in AI seen during the Data-Driven Era, this stage further expands the boundaries of human perception and cognition, revolutionizing how people experience and interact with the world. However, widespread application of these techniques is limited by energy constraints and the significant resources required for implementation.\nStage 4: Breakthroughs in Fundamental Theories. In this stage, humanity experiences a new wave of breakthroughs in fundamental theories, such as Einstein's Relativity Theories and Quantum Mechanics. These theoretical advances redefine our understanding of the universe and offer new possibilities for innovations in technologies. Such breakthroughs may also unlock solutions to longstanding challenges in human history, i.e., the energy issues, offering clean, abundant, and sustainable energy sources."}, {"title": "Ultimate Level: Revolutionary Era", "content": "Stage 5: Energy Revolution. A new era arrives as humanity finally achieves energy revolution, unraveling the mysteries of sustainable power generation. This may be achieved through mature technologies that are currently on the horizon, such as breakthroughs in large-scale controlled nuclear fusion, or revolutionary solar technologies, together with advancement in nanotechnologies that produce new materials for collecting and storing solar energy efficiently. The energy issue may also be solved through innovations that are beyond the scope of today's technologies, such as deploying satellites for gathering and storing solar energy in space. These satellites might then transmit the abundant energy to the receivers on Earth. Regardless of the specific technology, the flood of clean, abundant energy can eliminate the dependence on fossil fuels, and fundamentally revolutionize the global economic landscapes as well as human civilization.\nStage 6: The Internet of Everything. The final stage is the realization of Internet of Everything. Every object, living being, and system becomes part of a vast, intelligent network. This hyper-connected world is characterized by unprecedented levels of perception, communication, and interactions between humans and intelligent robots in an area. Language barriers may disappear, as human can perceive with chips for understanding, which enables ubiquitous real-time context-aware translations between people of different languages and cultures. Due to everyone is connected to a huge network, the boundary of human sense has been extended, which may also catalyze breakthroughs in holographic technology. Remote experiences become true; working, entertainment, and communication are revolutionized, and human has entered the ultimate advanced era."}, {"title": "Evolving AI Safety Paradigms", "content": "The landscape of AI safety shifts as humanity processes through stages of technology revolutions, and the focus of AI safety is different at each stage. The core AI safety challenges in different historical eras are summarized in Fig. 3.\nData-Driven Era. Current AI safety efforts primarily focus on data safety and model safety. A critical aspect of these efforts involves adversarial attacks to training data or AI models [3, 64, 54, 8, 71, 34], as well as malicious inputs designed to manipulate AI systems or induce producing unsafe content, e.g., jailbreaking or prompt injection attacks [19]. Correspondingly, red-teaming ML models [17, 63, 51, 4, 45] is widely used to identify potential vulnerabilities in ML models with attacks to further enhance the robustness of AI models. Meanwhile, significant work is being done to enhance AI system security and robustness [7, 62, 84]. Data security and privacy are also key concerns, particularly given the vast amounts of sensitive information used in AI training [33, 35, 23, 32]. Additionally, researchers have been engaging in AI governance to enhance AI accountability [6], such as promoting transparency and explainability [85] in AI systems to ensure the decision-making processes are understandable and accountable. Other significant areas of focus include improving the quality of AI outputs, specifically, aligning AI outputs with human values by addressing issues such as bias, fairness, ethics, etc [67, 46, 58, 53, 65].\nNeural Augmentation Era. Advancements in cognitive chips and brain-computer interfaces have extended the boundaries of human cognition and have changed the way of human perceiving the world. With the integration of intelligent chips and their direct neural connections to AI systems, users can interact with AI with high flexibility, and the customization of AI services towards different user groups or domain knowledge might be a critical focus. Individuals might rely on AI in different ways based on their background and cognitive needs, thus, personalized experiences of AI services should be explored for different user needs and preferences.\nRevolutionary Era. In the revolutionary era, AI safety challenges may focus on the complex interactions between interconnected entities, such as humans and intelligent robots, within the network. As users may have diverse needs and robots will provide customized services, ensuring the safety and reliability of these interactions becomes challenging. Robots may need to request and integrate data from multiple external sources in real-time to fulfill user requests. Managing the quality and security of these interactions is crucial, as any breakdown or interference could lead to incorrect or even harmful outcomes. Ensuring seamless communication, data integrity, and decision-making in such a sophisticated network may require smarter, more efficient methods, such as advanced cache management systems, to support the dynamic and complex interactions. This requires addressing issues of latency, data accuracy, and the security of transmitted information to maintain a safe and reliable network to ensure high-quality interactions between humans and robots in the network. By aligning AI with the progress of human civilization, we can see the path of AI safety evolves in different stages, which reflects the growing complexity of the roles of Al in human society. Initially, the focus is on addressing safety issues related to data and models. As AI and novel technologies become more developed, the focus of AI safety shifts to customization, which ensures the services provided by AI systems to meet individual needs. Finally, when entering the era of Internet of Everything, challenges in AI safety further evolve, focusing on complex interactions between humans and robots in the same network.\nThese insights offer guidelines for what we can do for AI safety at the current stage. In the following sections, we will overview today's AI safety landscape, then reflect on the progress in this area so far, and finally, explore the challenges and responsibilities of current AI safety practitioners, highlighting areas where further improvements and efforts are needed in the present stage."}, {"title": "Back to the 2020s: Today's AI Safety Landscape", "content": "This section retrospects the practices in AI safety so far, and project them against the blueprint future to guide our current efforts in AI safety."}, {"title": "Jailbreaking and Red Teaming", "content": "LLM jailbreak [68, 86] refers to the practice of bypassing the built-in safety and ethical guardrails of LLMs. These models are designed with restrictions to prevent them from generating harmful, inappropriate, or unethical content. However, through various techniques, users can manipulate the model into providing responses it normally wouldn't, such as giving instructions for illegal activities, bypassing censorship, or generating offensive content.\nRed-teaming is a common practice for mitigating unsafe behaviors in LLMs, where teams of experts simulate attacks or misuse scenarios to identify potential vulnerabilities in LLMs [17, 63, 51, 4, 45, 36, 74]. By actively challenging AI models and probing for weaknesses through adversarial inputs, bias exploitation, or system manipulation, it helps uncover potential risks that may not be evident in normal usage, such as biases, or failure modes that might lead to undesirable behaviors in AI models. The outputs from red-teaming can be used to train the model to be less likely to cause harm or steer it away from undesirable outputs. This proactive approach has proven effective in stress-testing A\u0399 models and has been widely used in industry practices [5, 45, 17].\nAs AI systems grow more sophisticated, red teaming must continually adapt to keep pace with increasingly complex attacks, which calls for more advanced tools and interdisciplinary expertise [42]. Regular and diverse red teaming exercises are crucial for maintaining robust AI systems, allowing developers to anticipate and mitigate risks in an ever-changing landscape. Also, current red-teaming practices are often static, typically conducted after model pretraining and consisting of one-time attacks. While this approach provides useful insights, it does not fully account for the evolving user needs, especially when faced of the growing demand for customized LLM services. To address this, red teaming should simulate diverse user groups and scenarios, such as simulating a diverse range of user groups and their unique needs, to address the customization of AI services and enable a comprehensive evaluation of potential vulnerabilities across different contexts."}, {"title": "Moderation and Guardrails", "content": "Content moderation ensure the outputs generated by LLMs are safe, appropriate, and free from harmful content [37, 30, 22, 26]. Moderation approaches leverage rule-based methods, machine learning classifiers, and human interfaces to monitor, evaluate, and manage the outputs produced by LLMs. Inappropriate user inputs or LLM outputs, e.g., contents that contain toxicity, bias, hallucinations, jailbreaks, etc, will be detected and handled properly.\nGuardrails [41, 50] employ customizable LLM inference workflows for ensuring the quality of LLM outputs while enhancing the control of the whole LLM workflows. It functions as an intermediary layer between users and LLMs, and enables users to add corresponding components at any stage of inference based on their needs, such as implementing code-based rules, desired output structure, and quality guarantees, to LLMs outputs.\nAs we reflect on practices for AI moderation and guardrails, several key challenges and considerations have emerged. The balance between utility and safety is crucial and may require dynamic solutions according to the changing contexts. Overly strict moderation can cause an AI system to be helpless, e.g., an LLM that always responds \"sorry, I cannot answer this question.\" is completely safe but useless. Thus, defining appropriate thresholds for acceptable responses is challenging and requires careful consideration of the changing context and potential risks. Also, customization for moderation should be applied for different use cases and user groups, as certain information may be safe for one user group but inappropriate or dangerous for another. An expert in chemistry may need specific and technical information on dangerous substances like explosives for professional purposes, while this same information should be restricted for the general public."}, {"title": "Privacy", "content": "Privacy leakage is a critical concern in machine learning models and AI services, as these models are often trained on diverse datasets collected from public and private sources. This raises significant concerns about data misuse, breaches, and the inadvertent exposure of confidential information and personal data [72, 47, 52, 12, 33, 39]. Adversaries may exploit model weights or gradients to infer sensitive information in the training data [82, 25, 77], or conduct adversarial attacks by querying the model to extract sensitive information [32, 9]. As AI models, particularly LLMs, become more integrated into everyday applications [59, 16], ensuring data privacy is crucial.\nTechniques such as differential privacy [24, 60, 81, 80] and federated learning [83, 78, 20, 76, 43] are being applied to protect sensitive data during training, ensuring that individual data points cannot be extracted from model weights or outputs. Additionally, privacy-preserving cryptographic protocols, such as homomorphic encryption [29, 48, 27], are explored to minimize data exposure, enabling LLMs to process and generate information without compromising data confidentiality. Furthermore, researchers also leverage differential privacy in finetuning or in-context learning [73, 79, 56], and design privacy-preserving prompts for querying LLMs [23, 11], to ensure data privacy during interactions between users and ML models.\nAs we retrospect the practices of data privacy, an important aspect is the balance between privacy and utility. While ensuring privacy is essential to protect personal information, they often come at the cost of reduced functionality and utility. In practice, these privacy measures may not always prevent determined attackers, while inadvertently hindering legitimate users. This paradox reflects a deeper issue: those who truly wish to exploit vulnerabilities will often find ways around existing defenses, while overly cautious measures tend to affect regular users more than malicious actors."}, {"title": "AI Safety Practitioners in 2020s: Challenges and Missions", "content": "This section utilizes the blueprint picture to guide our efforts today and navigate the challenges and opportunities of the current stage. As AI safety practitioners in the 2020s, we stand at a pivotal moment in history, as society moves toward a new era where AI will be widely integrated into everyday life. Our mission is not only to address current safety concerns but also to anticipate and mitigate the risks in the expanding AI landscape.\nA shift from AI safety to AI quality assurance. First of all, the rapid changing AI landscape requires a shift in focus from narrowly defined safety concerns to a more comprehensive concept, i.e., AI quality assurance. Instead of focusing solely on detecting and preventing negative outcomes, practitioners should work on proactive measures to enhance the overall quality of AI interactions. Viewing safety as part of a quality-driven approach helps to create AI that is not only safe but also more accurate, dependable, and capable of meeting the complex demands of real-world applications. Also, the terminology \"quality assurance\" also guide us to think more about what we can do as practitioners in this field to align with the overall blueprint picture.\nAlignment with more interdisciplinary collaborations. A key area that demands increased focus is the alignment of AI systems with deeper insights between different fields, people, and cultures. Current AI systems, while advanced, often lack a deep understanding of the ethical, social, and cultural contexts, and the alignment research tend to be conducted mostly by people in the computer science field, aiming at improving benchmarking scores. However, more advanced AI systems necessitate interdisciplinary collaboration between AI researchers and experts from diverse fields such as psychology, sociology, history, art, and anthropology, etc, especially for AI applications for specific fields such as finance [69, 78], healthcare [57, 1], education [49, 38], etc. AI safety practitioners must work towards bridging this gap by fostering interdisciplinary collaboration between fields such as philosophy, psychology, and sociology, etc, alongside computer science. By expanding the focus beyond technical constraints, practitioners can develop AI systems that are better aligned with human well-being as well as our diverse society.\nCustomization. Customization in AI is essential for ensuring that AI systems can meet the diverse needs of users and operate effectively in a variety of contexts. Current AI systems such as ChatGPT tend to provide same services across all user groups regardless of individual differences. However, as AI becomes more integrated into everyday life, one-size-fits-all solutions are no longer adequate. People have different backgrounds, preferences, and requirements, and AI systems must be able to adapt to individual differences to provide safe, effective, and relevant services. As an example, an AI interacting with a child should respond differently than one interacting with an adult, taking into account age, learning objectives, cognitive abilities, emotional maturity, etc. Customization of AI services can enhance safety by adjusting content and interactions to align with specific cultural norms, legal regulations, and ethical considerations. In fields such as finance [69, 78], healthcare [57, 1], and education [49, 38], customizing AI services based on user profiles is crucial for enhancing user satisfaction as well as preventing potential harmful outputs.\nInteraction. From our long-term goal towards the blueprint future, advanced human-AI interaction will involve complex interactions between intelligent robots and human users. This necessitates a shift in focus from static, one-shot analyses to dynamic, context-aware interactions between users and models to enhance alignment at the current stage. Besides prompt-based LLM systems or services, we can develop more sophisticated, context-aware interfaces for human-AI interaction to maintain coherent, multi-round interactions and adapt to evolving conversational contexts. Correspondingly, new safety protocols for such systems are in need to adjust in real-time to evolving contexts and user needs. It's also necessary to develop new methodologies for risk assessment and mitigation that can operate effectively in complex, rapidly changing environments involving multiple AI agents and human users."}, {"title": "Conclusion", "content": "This paper presents a blueprint for an advanced human society and leverages this forward-looking vision to guide today's AI safety efforts. Through the blueprint, it becomes clear that Artificial General Intelligence (AGI) is not the ultimate goal of AI development. Instead, the true vision lies in the Internet of Everything, a deeply interconnected world where intelligent systems seamlessly integrate into all aspects of life. While AGI is a popular topic discussed among people in the computer science field today, a more advanced world demands interdisciplinary collaborations across various fields. Regarding AGI as the ultimate goal might limit our creativity in the 2020s, confining us to \"local optima\" and potentially missing the real challenges.\nWhat will this future world be like? Will it bring more happiness to human-beings? The answer is uncertain. Advanced technologies may take on more duties, leaving humans with fewer tasks and more predictability in everyday life. However, with many everyday problems solved by advanced technologies, people may have more time for self-reflection and personal growth, which may lead to a new form of \"happiness\".\nAs we stand at a pivotal moment in human history, our efforts become not only a technological endeavor but also a profound exploration of human potential and the boundaries of human capability. In any case, the journey toward this advanced future is fascinating, and every human being will look forward to it."}]}