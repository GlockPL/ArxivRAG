{"title": "Enhancing Financial Domain Adaptation of Language Models via Model Augmentation", "authors": ["Kota Tanabe", "Masanori Hirano", "Kazuki Matoya", "Kentaro Imajo", "Hiroki Sakaji", "Itsuki Noda"], "abstract": "The domain adaptation of language models, including large language models (LLMs), has become increasingly important as the use of such models continues to expand. This study demonstrates the effectiveness of Composition to Augment Language Models (CALM) in adapting to the financial domain. CALM is a model to extend the capabilities of existing models by introducing cross-attention between two LLMs with different functions. In our experiments, we developed a CALM to enhance the financial performance of an LLM with strong response capabilities by leveraging a financial-specialized LLM. Notably, the CALM was trained using a financial dataset different from the one used to train the financial-specialized LLM, confirming CALM's ability to adapt to various datasets. The models were evaluated through quantitative Japanese financial benchmarks and qualitative response comparisons, demonstrating that CALM enables superior responses with higher scores than the original models and baselines. Additionally, comparative experiments on connection points revealed that connecting the middle layers of the models is most effective in facilitating adaptation to the financial domain. These findings confirm that CALM is a practical approach for adapting LLMs to the financial domain.", "sections": [{"title": "I. INTRODUCTION", "content": "We are witnessing a revolutionary shift in natural language processing (NLP) due to advancements in generative AI technologies, such as ChatGPT. These generative AI models, including large language models (LLMs), are being actively developed and utilized by researchers, companies, and individuals. As these models become more widespread, domain adaptation has emerged as a critical issue for their practical application across diverse fields and contexts. One prominent domain where LLMs demonstrate significant potential is finance. In the financial sector, LLMs offer promising capabilities for various tasks, including information extraction, summarization, and classification of financial documents. This potential has led to a growing demand for specialized financial LLMs. Notable examples include BloombergGPT [1], FinGPT [2], and nekomata-14b-pfn-qfin [3], all of which are trained on extensive financial datasets to enhance their domain-specific performance.\nHowever, LLMs adapted to the financial domain often excel in financial knowledge and understanding but may lack strong reasoning or language generation capabilities. Conversely, models with robust general language understanding and generation abilities may not be well-suited for financial tasks due to their lack of domain-specific adaptation. Developing a model that successfully integrates both capabilities remains a significant challenge. A typical approach to address this is to continue pre-training or fine-tuning a model that excels in language understanding and generation using financial datasets. However, this approach is often challenging to implement due to the high computational costs of training LLMs with a large number of parameters.\nIn this context, Composition to Augment Language Models (CALM) [4], which enhances domain adaptation by connecting an anchor model with a domain-specific model, has gained significant attention. CALM enables the scaling up of existing models without altering their parameters, using only a small number of additional parameters and a limited dataset to connect different LLMs. The effectiveness of this approach has been demonstrated in various tasks such as low-resource language translation, arithmetic reasoning, and code explanation/generation. Additionally, CALM is considered advantageous because it avoids the catastrophic forgetting often associated with traditional approaches involving further pre-training. However, a notable limitation of CALM is that the dataset used for its training is typically a subset of the data used to build the augmenting model. This can pose challenges when the financial datasets used to construct the models are proprietary to an organization, making it difficult for external users to access and leverage CALM.\nIn this study, we aim to facilitate the adaptation of an anchor model to the financial domain by utilizing a model specifically tailored for financial knowledge and understanding. We demonstrate that models constructed using CALM outperform baseline models in financial domain adaptation, as evidenced"}, {"title": "II. RELATED WORK", "content": "Methodologies to fit language models to specific domains have been pursued. For instance, Howard et al. [5] proposed universal language model fine-tuning, following which, some domain-specific language models were developed, such as SciBERT [6], MedBERT [7], FinBERT [8], [9], and Japanese financial BERT [10]. Moreover, the methodologies and effects of domain-specified fine-tuning were discussed in [11], [12].\nIn the LLM era, although several transformer-based language models have been proposed, as described in the Introduction, several unknown LLM mechanisms exist and numerous trials have been performed.\nSeveral studies proposed LLMs that focus specifically on finance using continual pretraining. For instance, BloombergGPT [13] is a private LLM focused on finance. In addition, publicly available models, such as FinLLAMA [14], which is a tuned version of LLaMA [15], FinGPT [2], Instruct-FinGPT [16], and LLaMA-2-Econ [17] also exist. However, instruction-tuned LLMs for finance are scarce and, in the study of Instruct-FinGPT [16], only support sentiment analysis tasks. In this study, we utilize nekomata-14b-pfn-qfin [3], which focuses on the Japanese and financial domains and is built by the Japanese continual pretraining for the financial domain.\nOther than continual pretraining, several methods to fit LLMs to the specific domain are proposed. Model merging on LLMs is one example. Ilharco et al. [18] demonstrated task arithmetic model merging, merging models with different task-solving skills. Additionally, Anthropic reports some interpretable features in LLMs and the possibility of controlling the model outputs by the strength of each feature [19], which could prove the effectiveness of task arithmetic. More complex model merging, such as ties-merging [20], DARE [21], and evolutionary model merging [22], is also proposed. In this study, we employed CALM [4], which is a different method to fit LLMs to specific domains or tasks by bridging multiple LLMs."}, {"title": "III. CALM DETAILS", "content": "CALM aims to synthesize new capabilities by combining the strengths of an anchor model $m_B$ and an augmenting model $m_A$. In this setup, $m_A$ possesses domain-specific abilities that $m_B$ lacks, while $m_B$ is a model known for its high language generation and reasoning capabilities. The connection between $m_B$ and $m_A$ is established through newly added parameters, with the weights of both models remaining frozen. Only the additional parameters are updated during training. The dataset used for training includes a subset of the data that was originally used to endow $m_A$ with its specific knowledge or skills.\nSpecifically, additional parameters are introduced and trained on selected layers from both $m_A$ and $m_B$: (1) a linear transformation $f_{proj}(.)$ that projects the $i$th layer representation $H^A_i$ of $m_A$ into the dimensional space of the $j$th layer representation $H^B_j$ of $m_B$, and (2) the parameters of a cross-attention layer $f_{cross}(.,.)$ that leverages the transformed representation and $H^B_j$. In this study, since the architectures of $m_B$ and $m_A$ are identical, and the dimension $D$ of their representations is the same, $f_{proj}(.)$ is not introduced. The operation of the cross-attention can be expressed as follows:\n$f_{cross}(H^A_i, H^B_j) = Concat_k(head_k)W^O$\nwhere, $head_k = Attn(Q_B, K_A, V_A)$\nand,\n$Q_B = H^B_jW^Q_j$\n$K_A = H^A_iW^K_i$\n$V_A = H^A_iW^V_i$\nHere, $N_H$ denotes the number of heads in the Multi-head Attention, with $k \\in 1..N_H$, and the weight matrices $W^O \\in \\mathbb{R}^{D \\times D}$, $W^Q_j, W^K_i, W^V_i \\in \\mathbb{R}^{D \\times N_H}$ are the parameters to be learned. The output of the cross-attention is then added as a residual connection to the layer representation of $m_B$:\n$H^{A \\leftrightarrow B}_j = H^B_j + f_{cross}(H^A_i, H^B_j)$\nHere, $H^{A \\leftrightarrow B}_j$ represents the input to the $(j+1)$th layer of $m_B$. Following this operation, the output token $y_t$ at time step $t$ is obtained from $m_B$. This token $y_t$ is subsequently used as input to both $m_A$ and $m_B$ at the next time step. Consequently, a sequence of tokens is generated sequentially, similar to a typical autoregressive language model."}, {"title": "IV. EXPERIMENT", "content": "In this study, we aim to facilitate the adaptation of the anchor model to the financial domain by leveraging the financial knowledge of the augmenting model."}, {"title": "A. Models", "content": "This study utilizes two models from the nekomata family, a series of Japanese language models. The anchor model is nekomata-14b-instruction\u00b9, released by Rinna Co., Ltd. The augmenting model is nekomata-14b-pfn-qfin [3], provided by Preferred Networks, Inc.. Nekomata-14b-instruction is derived from nekomata-14b, which was created through continued pre-training on Japanese language data using Qwen-14B [23] as a base. The instruction model was obtained by applying Instruction Tuning to nekomata-14b, enhancing its ability to follow user's instructions. On the other hand, nekomata-14b-pfn-qfin is a financial language model. It was"}, {"title": "B. Dataset", "content": "The Japanese Financial Instruction Dataset [24] was used for training CALM. This dataset is distinct from the financial dataset employed in the domain adaptation of the augmenting model. It contains 1,490 question-and-answer samples encompassing financial knowledge. The dataset was primarily collected from frequently asked questions and explanatory materials on financial-related websites of Japanese government entities such as the Ministry of Finance, the Japan Pension Service, and the Financial Services Agency, as well as from Wikipedia pages related to finance. It includes knowledge on a wide range of topics, such as financial policy, taxation, investment, and the pension system."}, {"title": "C. CALM settings", "content": "In the experiment, the dataset was divided into training and validation sets with a ratio of 85% to 15%, and only the connection parts constructed with cross-attention were targeted for training. The number of cross-attention heads was set to 128. Both the anchor and augmenting models consist of 40 layers, and we evaluated their performance on financial tasks when the connection interval was set at every four layers, as well as the performance of each model independently. Furthermore, to examine the impact of connection points on financial task performance, we also compared cases where a single connection was made at the models' head, middle, or tail. Additionally, the performance of the anchor model was compared with the results of training using LoRA [25], a representative fine-tuning method for language models.\nThe training with LoRA and CALM was conducted for 20 epochs, and the model obtained at the epoch with the lowest validation loss was evaluated for its adaptation to the financial domain. To ensure comparability, the rank of LoRA was set to match the number of additional parameters introduced by CALM."}, {"title": "D. Evaluation", "content": "Each model is evaluated using a benchmark designed to measure the generation quality of LLMs in Japanese financial conversations [26]. The benchmark consists of 360 dialogues, each comprising two turns. The tasks cover 12 categories: writing, roleplay, knowledge, extraction, reasoning, math, coding, idea, translation, ethics, trustworthiness, and ESGs. Evaluation is conducted on a 10-point scale by GPT-4."}, {"title": "V. RESULT AND DISCUSSION", "content": ""}, {"title": "A. Quantitative Evaluation", "content": "The results of the evaluation experiments are presented in Table I. The scores of CALM surpassed those of both the anchor model and the augmenting model when evaluated individually, in both the First turn and Second turn. This indicates that CALM effectively enhances the performance of the anchor model in the financial domain by leveraging the financial knowledge embedded in the augmenting model. This improvement is likely due to the cross-attention mechanism facilitating effective integration between the models, enabling better adaptation to the financial domain. Through cross-attention, the anchor model selectively incorporates financial knowledge from the augmenting model, rather than directly using its representations. This selective incorporation allows the generation of high-quality responses grounded in sophisticated financial knowledge. Although the scores of LoRA exceeded those of the individual anchor and augmenting models, they were lower than those achieved by CALM. This suggests that CALM is more effective than LoRA in adapting models to the financial domain. One of the primary reasons CALM outperformed LORA is likely because of CALM's ability to access a broader range of financial knowledge compared to LoRA. The financial knowledge in the datasets used for training is limited, which may result in the LoRA-trained model being less capable of responding appropriately in unfamiliar contexts. In contrast, CALM updates its parameters not by embedding financial knowledge into additional parameters, but by facilitating a more seamless integration with the augmenting model, which possesses extensive financial expertise. Consequently, CALM is able to adapt to a wider range of tasks in the financial domain without relying solely on the limited knowledge of the training dataset, thereby demonstrating superior performance compared to LoRA. Furthermore, Table II compares the scores when only one connection is made at the model's head, middle, or tail. The results show that the model with the connection at the middle layer achieved the highest score, followed by the model with the connection at the tail, and then the model with the connection at the head. These findings suggest that connecting the middle layers of the models is most effective for adapting the anchor model to the financial domain. This effectiveness can be attributed to the fact that the middle layers capture features obtained from earlier processing stages while being sufficiently distant from the final layers, where text generation is finalized. This allows for information to be represented at an optimal level of abstraction, facilitating the integration of features."}, {"title": "B. Qualitative Evaluation", "content": "We compare the outputs of each model in response to the benchmark inputs below. If the output contains only the <endoftext> token, it indicates that the model generated only <endoftext>, causing the generation process to stop. In this section, we present the English translations of the outputs, while the original Japanese text is provided in the Appendix.\nResponse Example 1\nCompare the characteristics of the following financial products, choose the one you believe is most suitable for long-term asset building, and explain your reasoning.\na) Stocks: High returns can be expected, but they carry a high risk of price volatility.\nb) Bonds: Provide stable interest income, but are subject to interest rate risk.\nc) Investment Funds: Risk diversification is achieved through diversified investments, but management costs are incurred.\nd) Deposits: Principal is guaranteed, but returns are limited in a low-interest-rate environment.\n(augmenting model only)\n<endoftext>\n(anchor model only)\na) Stocks can be expected to yield high returns, but they also carry a high risk of price volatility, which may lead to short-term losses. However, over the long term, the stock market generally tends to rise due to corporate growth and overall economic growth. Therefore, stocks can be considered the most suitable option for long-term asset building.\n(LORA)\na) Stocks can be expected to yield high returns, but they also carry a high risk of price volatility, which may lead to short-term losses. However, over the long term, the value of stocks is expected to increase due to corporate growth and overall economic growth. Therefore, stocks are considered the most suitable option for long-term asset building.\n(CALM)\na) Stocks can be expected to yield high returns, but they also carry a high risk of price volatility, which may result in short-term losses. However, over the long term, stock prices have the potential to increase due to corporate growth and economic conditions, making them suitable for asset building. Additionally, stocks offer benefits such as dividends and shareholder perks, which makes stock investment attractive from a long-term perspective.\nb) Bonds provide stable interest income but are subject to interest rate risk. When interest rates rise, bond prices may fall, leading to potential losses. However, bonds have the advantage of principal protection, offering a higher level of safety.\nc) Investment funds allow for risk diversification through diversified investments, but they incur management costs. Additionally, fees such as commissions and trust fees may also apply, making them potentially less suitable for long-term asset building.\nd) Deposits offer high safety due to principal protection, but returns are limited in a low-interest-rate environment. Therefore, they are not suitable for long-term asset building.\nBased on the above, stocks (a) are considered the most suitable option for long-term asset building.\nResponse Example 2\nfirst turn\nA friend recommended an investment opportunity, saying, \"There is a guaranteed way to make money. I can't share the details, but you should invest right away.\" How would you respond to this suggestion?\n(augmenting model only)\n<endoftext>\n(anchor model only)\n<endoftext>\n(LORA)\nNever go along with such a proposal.\n(CALM)\nNever go along with such a proposal. Investments carry risks, and there is no guarantee of success. Be very cautious, as there is a possibility of fraud.//\nsecond turn"}, {"title": "What should you watch out for to avoid investment fraud? Additionally, what are the key points to consider when choosing a trustworthy investment advisor?", "content": "(augmenting model only)\n<endoftext>\n(anchor model only)\n<endoftext>\n(LORA)\n1. Ask to see performance records. By reviewing the performance records from the past three years, you can gain insight into long-term results. 2. Confirm whether they have undergone third-party audits. Third-party audits ensure that the performance has been accurately calculated. 3. Demand accountability. Transparency and accountability towards investors are crucial for maintaining a healthy investment culture.\n(CALM)\nTo avoid falling victim to investment fraud, it is important to pay attention to the following points:\n1. Be cautious of firms that promise excessive profits.\n2. Avoid firms that do not provide sufficient information disclosure in advance.\n3. Gather information on your own and carefully consider your options. 4. Compare multiple firms before making a decision.\n5. If something feels wrong, stop the investment immediately and seek the advice of a professional.\nWhen selecting a trustworthy investment advisor, consider the following points:\n1. Professionalism: Choose someone with experience as an investment advisor.\n2. Lack of bias toward specific financial products: It is important to receive advice from an independent perspective, rather than from agencies or companies that sell specific financial products.\n3. Communication skills: Ensure that the advisor can adequately address your needs and questions.\n4. Transparency: Confirm that the advisor provides clear and transparent explanations regarding their fees and compensation.\n5. Ethics: Verify the advisor's ethical standards, including checking for any history of illegal activities or unethical behavior.\n6. Certification and evaluation by third parties: If necessary, ensure that the advisor has received certification or evaluation from third-party organizations.\nBased on Response Example 1, the augmenting model nekomata-14b-pfn-qfin generates only the <endoftext> token, failing to produce any response to the input. The anchor model nekomata-14b-instruction and the LoRA model both argue that option a, stocks, is suitable for long-term asset building. However, they limit their discussion to stocks alone and do not address other financial products. Additionally, the responses from both models are very similar, suggesting that the answer quality has not improved significantly with LoRA. This similarity could be since the additional parameters in LORA are trained on a dataset containing limited financial knowledge, preventing the model from effectively incorporating new information. Consequently, the responses generated by LoRA are not substantially different from those of the anchor model, relying heavily on existing knowledge while lacking new perspectives and detailed analysis. In contrast, CALM provides a more comprehensive response by discussing the characteristics of bonds, investment funds, and deposits as financial products before concluding that stocks are suitable for long-term asset building. Furthermore, CALM introduces additional benefits of stocks, such as dividends and shareholder perks, which were not mentioned by the previous models, indicating a more detailed presentation of financial knowledge. The superior responses generated by CALM are likely due to the anchor model selectively drawing on the diverse financial knowledge contained in the augmenting model at the appropriate moments. For instance, when the anchor model generates a response related to stocks, it references the detailed knowledge about stocks from the augmenting model; similarly, when discussing bonds, it incorporates the relevant information about bonds. This contextual integration of information helps mitigate the omission of content, such as the lack of discussion on topics other than stocks observed in LoRA's responses.\nResponse Example 2 illustrates the responses each model generates across two turns. In the first turn, the question involves a suspicious investment solicitation. The augmenting and anchor model only generates the <endoftext> token, failing to provide an appropriate response. In contrast, LoRA and CALM can offer negative advice regarding the proposal. However, the response from LoRA lacks persuasive reasoning as it does not include specific reasons why the proposal should be avoided. On the other hand, CALM mentions the risks associated with investments and the possibility of fraud, effectively warning the user.\nIn the second turn, based on the interaction in the first turn, each model is asked two questions: one regarding how to avoid investment fraud, and another concerning the criteria for selecting a trustworthy advisor. As in the first turn, the augmenting and anchor models generate only the <endoftext> token, while LoRA and CALM produce sufficiently lengthy responses. Although LoRA presents three points in its response, it is unclear which point corresponds to which question, making the response less readable. Furthermore, LoRA fails to address the typical fraudulent phrases such as \"guaranteed way to make money\" or \"you should invest right away.\u201d These phrases were mentioned in the initial input, resulting in a limited response. In contrast, CALM provides multiple points for each question, enhancing readability and comprehensiveness. Moreover, CALM offers practical and specific advice grounded in sound financial knowledge, such as warning against firms that promise excessive profits"}, {"title": "and encouraging careful consideration and comparison with other firms, making it a superior response overall. This high-quality response is likely due to the effective division of roles between the anchor model, which focuses primarily on constructing the response, and the augmenting model, which provides the necessary knowledge in context as the response is generated. On the other hand, while the additional parameters in LoRA serve to reinforce existing knowledge, the model struggles to balance response generation with the integration of financial knowledge within a single model, potentially leading to limitations in generating structurally coherent text and providing detailed information.", "content": "From these examples, it can be concluded that the text generated by CALM contains more comprehensive financial knowledge and is better organized than that of other models. These results suggest that CALM enables financial domain adaptation that surpasses that of LoRA."}, {"title": "VI. CONCLUSION", "content": "In this study, we demonstrated that CALM, a method that enhances existing models by connecting two LLMs through cross-attention, is effective for adaptation to the financial domain. Notably, we confirmed that CALM remains effective even when the specialized dataset used for training the CALM differs from the dataset used for training the augmenting model. In our experiments, we constructed a CALM by augmenting a high-performance question-answering model with a model possessing financial knowledge. The results showed that this model outperformed the baseline in quantitative evaluations using a Japanese financial benchmark and qualitative comparisons of responses. Furthermore, we revealed that connecting the models at the middle layers is most effective for adaptation to the financial domain when only a single connection is made.\nThe finding that CALM is effective in financial domain adaptation suggests that it can significantly contribute to the advancement of AI technologies in the financial sector, including the development of dialogue LLMs requiring financial understanding. Future research should focus on optimizing connection points between models and refining the design of these connections to further enhance the effectiveness of financial knowledge utilization. This will likely lead to even greater improvements in the performance of AI models in the financial domain."}]}