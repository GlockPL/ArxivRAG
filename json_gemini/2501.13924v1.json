{"title": "TOWARDS ROBUST MULTIMODAL OPEN-SET TEST-TIME ADAPTATION VIA ADAPTIVE ENTROPY-AWARE OPTIMIZATION", "authors": ["Hao Dong", "Eleni Chatzi", "Olga Fink"], "abstract": "Test-time adaptation (TTA) has demonstrated significant potential in addressing distribution shifts between training and testing data. Open-set test-time adaptation (OSTTA) aims to adapt a source pre-trained model online to an unlabeled target domain that contains unknown classes. This task becomes more challenging when multiple modalities are involved. Existing methods have primarily focused on uni-modal OSTTA, often filtering out low-confidence samples without addressing the complexities of multimodal data. In this work, we present Adaptive Entropy-aware Optimization (AEO), a novel framework specifically designed to tackle Multimodal Open-set Test-time Adaptation (MM-OSTTA) for the first time. Our analysis shows that the entropy difference between known and unknown samples in the target domain strongly correlates with MM-OSTTA performance. To leverage this, we propose two key components: Unknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality Prediction Discrepancy Optimization (AMP). These components enhance the model's ability to distinguish unknown class samples during online adaptation by amplifying the entropy difference between known and unknown samples. To thoroughly evaluate our proposed methods in the MM-OSTTA setting, we establish a new benchmark derived from existing datasets. This benchmark includes two downstream tasks \u2013 action recognition and 3D semantic segmentation \u2013 and incorporates five modalities: video, audio, and optical flow for action recognition, as well as LiDAR and camera for 3D semantic segmentation. Extensive experiments across various domain shift scenarios demonstrate the efficacy and versatility of the AEO framework. Additionally, we highlight the strong performance of AEO in long-term and continual MM-OSTTA settings, both of which are challenging and highly relevant to real-world applications. This underscores AEO's robustness and adaptability in dynamic environments.", "sections": [{"title": "INTRODUCTION", "content": "Test-time adaptation (TTA) significantly enhances the robustness and adaptability of machine learning models by enabling a source pre-trained model to adapt to target domains experiencing distribution shifts (Wang et al., 2021). This adaptability is crucial for ensuring the applicability of models in real-world scenarios, such as autonomous driving and action recognition. To address the challenges posed by distribution shifts, a variety of TTA algorithms have been developed (Niu et al., 2022; Yuan et al., 2023; Gong et al., 2024). These algorithms adapt specific model parameters using incoming test samples through unsupervised objectives such as entropy minimization and pseudo-labeling. However, most of these algorithms are designed for unimodal data, particularly images (Li et al., 2023). As real-world applications increasingly demand the processing of multimodal data, extending these approaches to support multimodal TTA across various modalities, including audio-video (Kazakos et al., 2019) and LiDAR-camera (Dong et al., 2022), has become essential. In response to this, several methods, such as READ (Yang et al., 2024) and MM-TTA (Shin et al., 2022), have been proposed to address the complexities inherent in multimodal TTA."}, {"title": "MULTIMODAL OPEN-SET TEST-TIME ADAPTATION", "content": "Multimodal Open-set Test-Time Adaptation (MM-OSTTA) aims to adapt a pre-trained source model to a target domain that experiences both distribution shifts and label shifts across multiple modalities. Let $D_s = \\{(x_i, y_i)\\}_{i=1}^{N_s}$ represent the source domain dataset with label space $C_s$, which follows the distribution $P_{xy}$, where each sample $x_i$ consists of $M$ modalities, denoted as $x_i = \\{x_i^k | k = 1,..., M\\}$. Similarly, let $D_T = \\{(x_i, y_i)\\}_{i=1}^{N_T}$ represent the target domain dataset with label space $C_T$ and distribution $P_{xy'}$. Let $f : X \\rightarrow \\mathbb{R}^C$ denote a neural network trained on the source distribution $P_{xy}$, where C is the number of classes in $C_s$. In MM-OSTTA, f consists of M feature extractors $g_k(\\cdot)$ and a classifier $h(\\cdot)$. Each feature extractor $g_k(\\cdot)$ processes modality k to produce an embedding $Z^k$, and the classifier h(\u00b7) combines these embeddings to generate a prediction probability p:\n$p = \\delta(f(x)) = \\delta(h([g_1(x_1), ..., g_M(x_M)])) = \\delta(h([Z^1, ..., Z^M]))$,\nwhere $\\delta(\\cdot)$ denotes the softmax function. Additionally, we include separate classifiers $h_k(\\cdot)$ for each modality k, yielding modality-specific prediction probabilities $p^k = \\delta(h_k(g_k(x_k)))$.\nGiven a well-trained multimodal source model $f(x)$ on $D_s$, MM-OSTTA aims to adapt this model to the target domain $D_T$, where $P_{xy} \\neq P_{xy'}$. Unlike traditional closed-set TTA, which assumes $C_s = C_T$, MM-OSTTA operates under the condition $C_s \\subset C_T$, meaning the target domain may contain samples from unknown classes not present in the source domain. In addition to adapting the model and making predictions, MM-OSTTA involves generating a prediction score $S(x)$ for each sample and employing an unknown class detector $G_{\\eta}(x)$, defined as:\n$G_{\\eta}(x) = \\begin{cases} \\text{known} & S(x) \\geq \\eta \\\\ \\text{unknown} & S(x) < \\eta \\end{cases}$,\nwhere $\\eta$ is a predefined threshold. Samples with $S(x) < \\eta$ are classified as unknown. We use the Maximum Softmax Probability (MSP) (Hendrycks & Gimpel, 2017) as $S(x)$ by default."}, {"title": "METHODOLOGY", "content": null}, {"title": "CORRELATION BETWEEN ENTROPY AND MM-OSTTA PERFORMANCE", "content": "We begin by exploring the relationship between prediction entropy, defined as $H(p) = -\\sum_{c=1}^{C} p_c\\text{log }p_c$, and the performance of MM-OSTTA. Using a pre-trained model on the source domain, we generate predictions on the target domain without performing any adaptation. The target domain consists of both known and unknown samples. To quantify this relationship, we calculate the average prediction entropy for known ($H_{known}$) and unknown samples ($H_{unknown}$) separately, and then compute the difference ($H_{unknown} - H_{known}$). We evaluate this entropy difference across various domain-shift scenarios using the EPIC-Kitchens (Damen et al., 2018) dataset and analyze its correlation with an MM-OSTTA performance metric (FPR95), which measures the unknown class detection ability. A lower FPR95 indicates better performance. As shown in Fig. 2, there is a strong correlation between the entropy difference and MM-OSTTA performance, with a larger entropy difference corresponding to a lower FPR95. This observation is intuitive, as a higher entropy difference suggests that unknown samples exhibit significantly greater entropy than known samples, making them easier to differentiate.\nTent (Wang et al., 2021) minimizes the entropy for all samples, regardless of whether they belong to known or unknown classes, which inadvertently decreases the entropy difference between these"}, {"title": "UNKNOWN-AWARE ADAPTIVE ENTROPY OPTIMIZATION", "content": "As discussed in Sec. 3.1, improving MM-OSTTA performance requires increasing the entropy difference between known and unknown class samples, i.e., maximizing the entropy of unknown samples while minimizing that of known samples. Tent (Wang et al., 2021) minimizes the entropy of all samples, failing to enhance this difference. Some approaches (Niu et al., 2023; Yang et al., 2024) apply entropy minimization selectively to high-confident samples, but still struggle to increase the entropy difference. The first step in effectively optimizing entropy for both known and unknown samples is to reliably identify potential unknown samples. To address this, we introduce the Unknown-aware Adaptive Entropy Optimization (UAE) loss, which adaptively weights and optimizes each sample based on its prediction uncertainty. The UAE loss is defined as:\n$W_{Ada} = \\text{Tanh}(\\beta \\cdot (H(\\hat{p}) - \\alpha))$,\n$\\mathcal{L}_{AdaEnt} = -H(\\hat{p}) \\cdot W_{Ada}$,\nwhere Tanh is the hyperbolic tangent function, $W_{Ada}$ is the adaptive weight assigned to each sample, $H(\\hat{p})$ is the normalized entropy of prediction $\\hat{p}$, computed as $H(\\hat{p}) = -(\\sum_{c=1}^{C} p_c\\text{log }p_c)/\\text{log}(C)$, with C being the number of classes. The parameters $\\alpha$ and $\\beta$ are hyperparameters that control the entropy threshold and scaling, respectively.\nThe function Tanh(x) is positive when x > 0 and negative when x < 0. Therefore, the UAE loss $\\mathcal{L}_{AdaEnt}$ maximizes $H(\\hat{p})$ when $H(\\hat{p}) > \\alpha$ (i.e. when prediction confidence is low, indicating the sample is likely unknown) and minimizes $H(\\hat{p})$ when $H(\\hat{p}) < \\alpha$ (i.e. when prediction confidence is high, indicating the sample is likely known). Moreover, Tanh(x) asymptotically approaches 1 as x increases and converges to -1 as x decreases, resulting in higher weights for samples with very high or very low $H(\\hat{p})$ (i.e. those that most likely to be known or unknown). When $H(\\hat{p})$ is close to $\\alpha$, the model is uncertain about whether the sample is known or unknown, and there is a higher risk of wrong predictions. In such cases, the assigned weight approaches 0, effectively neutralizing the potential negative impact of uncertain samples. In this manner, our UAE loss adaptively optimizes the entropy for each sample, enhancing the separation between known and unknown samples to ensure more reliable predictions."}, {"title": "ADAPTIVE MODALITY PREDICTION DISCREPANCY OPTIMIZATION", "content": "To further enhance the entropy difference between known and unknown samples, we introduce Adaptive Modality Prediction Discrepancy Optimization (AMP), which optimizes the predictions across different modalities. To achieve this, AMP first employs an adaptive entropy loss, similar to the UAE, that increase the entropy of predictions from each modality when confidence is low, and decrease it when confidence is high. The loss is defined as:\n$\\mathcal{L}_{AdaEnt^*} = -\\frac{1}{2}(H(p^1) + H(p^2)) \\cdot W_{Ada}$,\nwhere $W_{Ada}$ is the adaptive weight calculated in Eq. (3). Additionally, we propose maximiz-"}, {"title": "EXPERIMENTS", "content": "We evaluate our proposed method across four benchmark datasets: EPIC-Kitchens and Human-Animal-Cartoon (HAC) for multimodal action recognition with domain shifts, Kinetics-100-C for multimodal action recognition under corruptions, and the nuScenes dataset for multimodal 3D semantic segmentation in Day-to-Night and USA-Singapore adaptation scenarios."}, {"title": "EXPERIMENT SETTINGS", "content": "Datasets. For domain adaptation experiments, we utilize the widely adopted EPIC-Kitchens (Damen et al., 2018) and HAC (Dong et al., 2023) datasets. Both datasets offer three modalities: video, audio, and optical flow. The EPIC-Kitchens dataset comprises eight actions ('put', 'take', 'open', 'close', 'wash', 'cut', 'mix', and 'pour') recorded in three distinct kitchens, forming three domains D1, D2, and D3. The HAC dataset includes seven actions ('sleeping', 'watching TV', \u2018eating', \u2018drinking', \u2018swimming', 'running', and \u2018opening door') performed by humans (H), animals (A), and cartoon (C) figures, resulting in three distinct domains: H, A, and C. In our experiments, models are pre-trained on a source domain and adapted to a target domain online. For the open-set setting, we treat HAC samples as unknown classes for EPIC-Kitchens and vice versa. To prevent class overlap, we exclude the 'open' class samples from EPIC-Kitchens dataset and the 'opening door' class from the HAC dataset when used as unknowns.\nFor the corruption robustness experiments, models are trained on clean datasets and adapted to corrupted test sets. We create the Kinetics-100-C dataset, which includes video and audio modalities, following the approaches outlined in Hendrycks & Dietterich (2019) and Yang et al. (2024). Kinetics-100-C consists of 100 classes selected from Kinetics-600 dataset (Carreira et al., 2018), with 21181 videos for training and validation, and 3800 videos for testing. We apply six types of corruptions on videos (Gaussian, Defocus, Frost, Brightness, Pixelate, and JPEG) and audios (Gaussian, Wind, Traffic, Thunder, Rain, and Crowd), generating six distinct corruption shifts. For example, Defocus (v) + Wind (a) indicates defocus corruption on video and wind corruption on audio. All experiments are conducted under the most severe corruption level 5 (Hendrycks & Dietterich, 2019). For the open-set setting, we utilize HAC as the unknown classes, applying the same corruption types as in\nKinetics-100-C, resulting in the HAC-C dataset. By applying identical corruption types, we create open-set samples from a matching domain shift but with unknown classes.\nFor multimodal 3D semantic segmentation, we utilize the nuScenes dataset (Caesar et al., 2020), which includes LiDAR and camera modalities. We examine two realistic adaptation scenarios following Jaritz et al. (2020): (1) Day-to-Night adaptation: LiDAR exhibits minimal domain shift due to its active sensing capabilities (emitting laser beams that remain largely unaffected by lighting conditions). In contrast, the camera, functioning as a passive sensor, experiences a significant domain gap due to poor light at night, leading to substantial changes in object appearance. (2) USA-Singapore country-to-country adaptation: The domain gap may vary for both LiDAR and camera modalities. For certain classes, the 3D shape may shift more significantly than the visual appearance, while for others, the reverse may hold true. In the open-set setting, we designate all vehicle classes as unknown. During training, unknown classes are labeled as void and ignored. During inference, the objective is to segment the known classes while simultaneously detecting unknown classes.\nEvaluation Metrics. To evaluate the model's adaptation performance on known data, we use accuracy (Acc) for classification tasks and mean Intersection over Union (IoU) for segmentation tasks. To assess the model's ability to robustly detect unknown classes, we measure the area under the receiver operating characteristic curve (AUROC) and the false positive rate of unknown samples when the true positive rate at 95% (FPR95) for unknown samples. As our objective is to achieve a good balance between the classification accuracy of known classes and the detection accuracy of unknown classes, we reformulate a novel version of H-score, defined as the harmonic mean of Acc, AUROC, and FPR95:\n$\\text{H-score} = \\frac{3}{\\frac{1}{\\text{Acc}} + \\frac{1}{\\text{AUROC}} + \\frac{1}{1-\\text{FPR95}}}$\nSince a lower FPR95 indicates better performance, we use 1 - FPR95 for the H-score calculation in Eq. (9). AUROC provides a global measure of how well the model distinguishes between known and unknown classes across all possible thresholds, making it suitable for tasks requiring balanced performance across thresholds. FPR95 evaluates the model's performance at a specific recall level (95% TPR), which is particularly important in applications requiring high recall, such as fraud detection or outlier detection. To comprehensively evaluate the model under the open-set setting, both FPR95 and AUROC are included in our H-score calculation. For the segmentation task, we replace Acc with IoU to calculate H-score.\nBaseline models. We compare our method against two unimodal TTA methods, Tent (Wang et al., 2021) and SAR (Niu et al., 2023), as well as two unimodal open-set TTA methods, OSTTA (Lee et al., 2023) and UniEnt (Gao et al., 2024), along with one multimodal TTA method, READ (Yang et al., 2024)."}, {"title": "COMPARISONS WITH STATE-OF-THE-ART", "content": "Robustness under domain shifts. We first conduct comprehensive experiments on domain adaptation benchmarks, where a model is trained on a single source domain and then adapted online to a target domain with significant distribution shifts. Unimodal TTA methods, such as Tent (Wang et al., 2021) and SAR (Niu et al., 2023), underperform in the multimodal open-set TTA setup, revealing their limited adaptability in complex scenarios involving multiple modalities and unknown classes. Similarly, OSTTA (Lee et al., 2023), a unimodal open-set TTA method, struggles to achieve robust performance, highlighting the inherent challenges of multimodal open-set TTA. In contrast, UniEnt (Gao et al., 2024), another unimodal open-set TTA method, performs well in this setup. The SOTA multimodal TTA method READ (Yang et al., 2024) demonstrates competitive performance. Our proposed AEO framework demonstrates strong robustness in the challenging open-set setup"}, {"title": "ABLATION STUDIES AND ANALYSIS", "content": "Ablation on each proposed module. We conducted comprehensive ablation studies to evaluate the contribution of each proposed module. The results indicate that incorporating UAE effectively increases the entropy difference between known and unknown samples, thereby enhancing detection performance for unknown classes. Additionally, integrating AMP maximizes the prediction discrepancy between different modalities for unknown classes, fostering uncertainty in predictions and further improving unknown class detection. These two modules are complementary, and their combined implementation achieves the highest performance across all datasets."}, {"title": "CONCLUSION", "content": "In this work, we tackle the challenging task of Multimodal Open-set Test-time Adaptation (MM-OSTTA) for the first time. Motivated by the observation that the entropy difference between known and unknown class samples positively correlates with MM-OSTTA performance, we propose Adaptive Entropy-aware Optimization (AEO). AEO consists of two key components: Unknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality Prediction Discrepancy Optimization (AMP). Together, these components increase the entropy difference between known and unknown class samples during online adaptation in a complementary manner. We conduct extensive experiments on the newly introduced benchmark, encompassing two downstream tasks and five different modalities, to demonstrate the efficacy and versatility of our proposed AEO. Furthermore, AEO achieves promising results in both long-term and continual MM-OSTTA settings, where the adaptation process is repeated over multiple rounds and the target domain distribution evolves over time. These results underscore the robustness and adaptability of AEO in dynamic, real-world environments."}]}