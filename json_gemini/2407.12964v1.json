{"title": "Learning Long-Horizon Predictions for Quadrotor Dynamics", "authors": ["Pratyaksh Prabhav Rao", "Alessandro Saviolo", "Tommaso Castiglione Ferrari", "Giuseppe Loianno"], "abstract": "Accurate modeling of system dynamics is crucial for achieving high-performance planning and control of robotic systems. Although existing data-driven approaches represent a promising approach for modeling dynamics, their accuracy is limited to a short prediction horizon, overlooking the impact of compounding prediction errors over longer prediction horizons. Strategies to mitigate these cumulative errors remain underex- plored. To bridge this gap, in this paper, we study the key design choices for efficiently learning long-horizon prediction dynamics for quadrotors. Specifically, we analyze the impact of multiple architectures, historical data, and multi-step loss formulation. We show that sequential modeling techniques showcase their advantage in minimizing compounding errors compared to other types of solutions. Furthermore, we propose a novel decoupled dynamics learning approach, which further simplifies the learning process while also enhancing the approach modu- larity. Extensive experiments and ablation studies on real-world quadrotor data demonstrate the versatility and precision of the proposed approach. Our outcomes offer several insights and methodologies for enhancing long-term predictive accuracy of learned quadrotor dynamics for planning and control.", "sections": [{"title": "I. INTRODUCTION", "content": "Unmanned Aerial Vehicles (UAVs), including quadrotors, are becoming integral to a variety of applications, includ- ing logistics, reconnaissance missions, search and rescue, and inspections scenarios [1]. These tasks require UAVs to precisely navigate through unknown cluttered environments, which demands planning collision-free paths and controlling the UAV to closely follow these paths [2]. The effectiveness of both planning and control critically relies on the accurate prediction of action sequence outcomes, necessitating precise system dynamics modeling [3]. Yet, modeling these dynam- ics is often challenging due to complex aerodynamic forces, interactions between propellers, and other nonlinear phe- nomena experienced during different operating conditions, which traditional physics-based models often fail to capture accurately [4], [5]. These limitations can result in suboptimal flight performance and, eventually, catastrophic failures."}, {"title": "II. RELATED WORKS", "content": ""}, {"title": "A. Dynamics Learning for One-step Forecasts", "content": "One-step dynamics learning models have proven to be highly effective in addressing a diverse array of robotics tasks. For instance, Gaussian Processes (GPs) have suc- cessfully tackled various lower-dimensional robotic learning challenges, demonstrating their proficiency in managing un- certainty in a structured manner [18], [19]. However, GPs face scalability limitations, especially with tasks involving high dimensions and large datasets. On the contrary, deep neural networks have exhibited remarkable scalability to higher dimensions and the ability to handle large amounts of data effectively. For instance, [20] adopted a Multi- Layer Perceptron (MLP) to capture helicopter dynamics. [21] employed a shallow MLP to learn the full system dynamics of a quadrotor. Moreover, a diverse array of archi- tecture types, incorporating sequence modeling techniques, has found practical utility in the realm of learning robot dynamics. Examples include the application of Recurrent Neural Networks (RNNs) [22] and Temporal Convolutional Networks (TCNs) [4], [23], [24]. Furthermore, other data- driven methods such as structured mechanical models [25] and Lagrangian networks [26] leverage deep learning to satisfy smooth constraints. Despite the versatility offered by all these models, a common challenge arises, particularly in tasks requiring long-horizon planning and control, where they often encounter compounding errors."}, {"title": "B. Compounding Errors in Multi-step Forecasts", "content": "The compounding error problem has been previously studied under the context of model-based reinforcement learning [10], [11], where a dynamic model of the system is iteratively learned and recursively applied to derive a control policy. For instance, [12] addresses compounding error in model prediction using real observations, aiming to avoid distribution drift. [13] tackles the problem with short horizons, at the expense of long-term capabilities. Other approaches involve tweaking model optimization, including imitation-learning-inspired models [14], multi-step estima- tors [15], and flexible prediction horizons [16].\nThe model proposed by [9] introduces a new training paradigm to mitigate compounding error by embedding time dependence in predictions. However, it is currently limited by its requirement for closed-form controllers. Recently, [17] investigated various factors that influence the magni- tude of long-term prediction error. Yet, this work primarily aims at understanding the properties and conditions causing compounding errors. The challenge of compounding error remains not fully understood in terms of design choices, techniques, and model architectures for enhancing long- horizon predictions of learning dynamic models. To address this gap, we present a specific set of network design and training choices to mitigate this challenging problem."}, {"title": "III. BACKGROUND", "content": ""}, {"title": "A. Modeling the System Dynamics", "content": "Consider the system's state $x_t \\in \\mathbb{R}^n$ at time $t$, influenced by the action $u_t \\in \\mathbb{R}^m$. Modeling the system dynamics requires finding a function $f: \\mathbb{R}^n \\times \\mathbb{R}^m \\rightarrow \\mathbb{R}^n$ such that\n\n$X_{t+1} = f(x_t, u_t)$.\n\n(1)\nThe quadrotor's state at_a given time index is given by $x_t = [p_t^T\\;v_t^T\\;q_t^T\\;w_t^T]^T$, where $p_t \\in \\mathbb{R}^3$ and $v_t \\in \\mathbb{R}^3$ are the robot's position and velocity expressed in the inertial frame, $q_t \\in \\mathbb{R}^4$ is the robot's attitude using the unit quaternion representation with respect to the inertial frame, and $w_t \\in \\mathbb{R}^3$ is the robot's angular velocity in the body frame. Furthermore, the control action is represented by $u_t \\in \\mathbb{R}^4$ and corresponds to the motor speeds."}, {"title": "B. Learning One-step System Dynamics", "content": "The common practice for learning the system dynamics in- volves training a one-step predictive model $h_\\theta$, parametrized by $\\theta$, on a dataset of $N$ collected state-action trajectories $\\mathcal{D} = \\{(X_i, U_i, X_{i+1})\\}_{i=1}^N$. The input to the neural network consists of linear velocity $v$, angular velocity $w$, attitude $q$, and control inputs $u$. Position information is omitted, as- suming position-independent system dynamics, as the robot's positional changes can be recovered via Euler integration. The training process optimizes $\\theta$ to minimize the prediction error of $h_\\theta$ over $\\mathcal{D}$ as follows\n\n$\\min_\\theta \\frac{1}{N}\\sum_{i=1}^N ||x_{t+1} - \\hat{x}_{t+1}||^2$,\n\n(2)\n\nwhere $\\hat{x}_{t+1} = h_\\theta(x_t, u_t)$. Rather than solely predicting the true state observation as $x_{t+1} = h_\\theta(x_t,u_t)$, an alternative approach involves predicting the change in the current state, expressed as $x_{t+1} = x_t + h_\\theta(x_t, u_t)$. This technique, widely adopted [13], [27], is popular in regularizing the prediction distribution. Therefore, we employ it in this work."}, {"title": "C. Compounding Errors in Multi-step Forecasts", "content": "When forecasting the outcome for a given sequence of control actions T steps in the future, the one-step dynamics model is recursively applied as\n\n$X_{t+T} = h_\\theta(... h_\\theta (h_\\theta (x_t, u_t), u_{t+1})..., u_{t+T})$.\n\n(3)\n\nHowever, any prediction error caused by inaccurately model- ing the system dynamics, namely $\\epsilon_t = ||x_t|\\hat{x}_t||^2$, undergoes multiplicative growth due to each subsequent prediction's input being influenced by past errors. Formally, the com- pounding error problem in multi-step forecasts over a $T$ time horizon can be formulated as\n\n$X_{t+1} = h_\\theta(x_t, u_t) + \\epsilon_t$,\n$X_{t+2} = h_\\theta(X_{t+1}, U_{t+1}) + \\epsilon_{t+1}$,\n: \n(4)\n$X_{t+T} = h_\\theta(X_{t+T-1}, U_{t+T-1}) + \\epsilon_{t+T}$.\n\nThis compounding effect of errors is a consequence of each subsequent prediction incorporating all past errors, leading to a cumulative effect on the overall prediction accuracy."}, {"title": "IV. METHODOLOGY", "content": ""}, {"title": "A. Model Architectures", "content": "The inherent challenge in data-driven dynamics learning lies in the degradation of state and action information by sensor noise. Consequently, the Markovian assumptions on the robot dynamics and full observability are constrained. Recognizing this, previous studies explored the integration of historical information to address these limitations. Lever- aging recently observed states and actions, which retain redundant patterns, provides a mechanism for data-driven models to mitigate the effects of noise [4]. Formally, this integration involves histories of states $X_t = [x_{t-H}...x_t]$, and control inputs, denoted as $U_t = [u_{t-H}...u_t]$, both with a length of $H$, enabling the prediction of the state at time t + 1 as $X_{t+1} = x_t + h_\\theta(X_t, U_t)$.\n\nWhile historical information has demonstrated effective- ness in learning accurate dynamics, its potential with dif- ferent model architectures tailored to capturing long-range time dependencies remains largely unexplored, particularly in addressing the compounding error problem. Traditional MLPs, commonly employed for such tasks, struggle to leverage temporal context effectively due to inherent ar- chitectural limitations. This leads to inaccuracies and high variance in predictive capability. To bridge this gap, our study focuses on benchmarking several state-of-the-art recurrent architectures, including Long Short-Term Memory (LSTM) [28], Gated Recurrent Unit (GRU) [29], and TCN [30]. LSTM and GRU, being variants of RNNs, are specifically de- signed to capture long-range dependencies in sequential data. Specifically, LSTMs incorporate memory cells and multiple gating mechanisms, while GRUs simplify this architecture by combining gates. While LSTMs are computationally ex- pensive, GRUs offer performance with lower computational complexity. TCNs, leveraging causal convolutions, provide efficient training and scalability. However, they may require more data for optimal performance."}, {"title": "B. Multi-Step Loss", "content": "Recent works on learning dynamics models [4], [5] utilize a single step loss, where the model is trained to predict the immediate next state. The loss function is computed as shown in eq. (2). This formulation focuses on short-term prediction accuracy and often fails in applications involving long-horizon planning and control. To tackle this problem, recent approaches [9]\u2013[11] have adopted a multi-step loss formulation which improves the long-term predictive capa- bility. The multi-step loss formulation involves predicting multiple future states beyond just the immediate next step. The model is trained to forecast the system's behavior over a longer horizon by recursively predicting $U$ future steps. The loss function is computed based on the cumulative error over all predicted future steps compared to their corresponding actual future states as\n\n$\\min_\\theta \\frac{1}{UN}\\sum_\\mathcal{D}\\sum_{i=1}^U ||x_{t+i} - \\hat{x}_{t+i}||^2$.\n\n(5)\n\nThis approach provides a more comprehensive evaluation of the model predictive performance over longer time horizons and is beneficial for tasks requiring foresight and planning."}, {"title": "C. Dynamics Decoupling", "content": "The formulation of learning dynamics models involves various strategies, among which the full-state predictor and the multi-head predictor are prominent (Figure 2). The full- state predictor aims to directly forecast the complete state vector, encompassing linear velocity v, angular velocity w, and attitude q, offering a comprehensive view of system dynamics. However, its holistic approach may encounter challenges in capturing long-term dependencies due to the complexity of underlying dynamics and the high-dimensional output space, potentially increasing sensitivity to data noise. Conversely, the multi-head predictor divides the prediction task into separate heads, typically focusing on velocity and attitude independently. While this specialization allows tailored modeling of different state aspects, it introduces co- ordination challenges. Dividing the prediction task can hinder effective prediction coordination, leading to inconsistencies and limited information sharing between the decoders, reduc- ing predictive accuracy. In contrast, our proposed modular approach decouples system dynamics into manageable sub- problems. By focusing on distinct components, such as ve- locity and attitude, decoupled predictors promote modularity, simplify learning and enable independent optimization. This strategy enhances the model's capability to capture complex dynamics and facilitates more accurate long-term predictions, addressing the limitations of traditional predictors. Specifi- cally, we introduce two key modules: the Velocity Predictor and the Attitude Predictor. The Velocity Predictor is designed to forecast the change in velocity at the next time step. Formally, it is expressed as\n\n$\\hat{z}_{t+1} = z_t + h_\\theta^{vel} (X_t, U_t)$,\n\n(6)\n\nwhere $\\hat{z}_{t+1}$ and $z_t$ denote the predicted velocity and current velocity, encompassing both linear and angular changes $z = [v \\; w]$. On the other hand, the Attitude Predictor forecasts the change in attitude quaternion at the next time step and is formulated as\n\n$\\hat{q}_{t+1} = h_\\theta^{att} (X_t, U_t) \\otimes q_t$,\n\n(7)"}, {"title": "V. EXPERIMENTAL SETUP", "content": ""}, {"title": "A. Datasets", "content": "We extensively perform experiments on two well-known open-source real-world quadrotor datasets to analyze the long-term predictive performances of the neural models.\nPI-TCN. This dataset [4] includes 68 trajectories with a total flight time of 58 min 3 sec. These cover a diverse range of motions, including straight-line accelerations, circular movements, parabolic maneuvers, and lemniscate trajecto- ries. The dataset is designed to capture complex effects, pushing the quadrotor to its physical limits with speeds of 6 ms-1, linear accelerations of 18 ms-2, angular accelerations of 54 rads-2, and motor speeds of 16628 rpm. Data is sampled at 100 Hz. We use 54 trajectories for training, 10 for validation, and 4 for testing, ensuring a comprehensive evaluation across various challenging scenarios.\nNeuroBEM. This dataset [5] comprises 96 flights with a total flight time of 1 hr 15 min, encapsulating the entire performance envelope of the platform up to observed speeds"}, {"title": "B. Training", "content": "We carefully chose the model architecture parameters to ensure real-time performance on an embedded platform. By analyzing the inference speed of baseline models relative to their parameter count (see Figure 3), we establish a parameter bound by identifying the model with the lowest parameter count capable of real-time performance. LSTM demonstrates real-time predictions with up to 5.2 million parameters. To ensure fair comparisons, we select this parameter bound across all models. All models adopt an encoder-decoder structure. For consistency, all encoders feature three layers. The MLP encoder consists of layers with 1024, 512, and 512 neurons, respectively. Similarly, the LSTM and GRU encoders consist of three layers with 512 neurons each in the hidden state. The TCN encoder integrates three hidden layers with sizes of 512, 256, and 256 neurons, leveraging temporal convolutional layers with a LeakyReLU activation function, batch normalization, kernel size of 3, and a dilation factor of 2. All architectures incorporate an MLP decoder composed of three layers with 512, 256, and 256 neurons. In our training process, we chose not to normalize the input state and actions (motor speed), as we notice no significant performance improvement. However, we scale the motor speed data by multiplying them by 10-3 to ensure equal distribution of data component scales, allowing the neural network to assign equal importance to all components. We employ the AdamW optimizer for training over 50 K iterations, $B_1$ and $B_2$ set to 0.9 and 0.999, respectively, and a weight decay of 10-4. We train models with a batch size of 512, constant learning rate warm up, lasting for 5K iterations, followed by a cosine annealing learning rate scheduler."}, {"title": "C. Evaluation Metric", "content": "We employ a sliding window approach with size H along the unseen testing trajectory. At each state-control slice of H, the velocity predictor forecasts linear and angular velocities T steps ahead, and we compute the velocity error between predicted and ground truth velocity values\n\n$\\delta_v = \\frac{1}{T} \\sum_{i=0}^{T-1} ||(\\hat{z}_i - z_i)||_2$,\n\n(8)\n\nwhere $z_i$ represents the ground truth velocities at time index i, and $\\hat{z}_i$ denotes the predicted velocities at time index i. Similarly, the attitude predictor forecasts unit quaternion states T steps ahead, and we compute the quaternion error with respect to the ground truth unit quaternion. We consider that the orientation is not an element of the Euclidean space [31]. Therefore, to compute the quaternion error we take the logarithm of the rotation difference between the predicted and ground truth quaternion. The error is\n\n$\\delta_q = \\frac{1}{T} \\sum_{i=0}^{T-1} \\theta_i$,\n\n(9)\n\nwhere, for a given time index i, $\\theta_i$ is calculated as\n\n$\\theta_i = arctan(\\frac{||Aq_{error}||}{Aq_{error}})$.\n\n(10)\n\nThe terms $Aq_{error}$ and $Aq_{error}$ denote the vector and scalar components of the quaternion respectively, and $Aq_{error}$ is\n\n$Aq_{error} = q_{truth} \\otimes (q_{pred})^{-1}$,\n\n(11)\n\nwhere $q_{truth}$ and $q_{pred}$ represent the ground truth and pre- dicted quaternions, respectively. Finally, log $Aq_{error} = u\\theta_i$, where $u = \\frac{Aq_{error}}{||Aq_{error}||}$. Both $\\delta_v$ and $\\delta_q$ are averaged across all slices of different testing trajectories to evaluate the model's predictive accuracy. We evaluate the ability to predict horizons of 60 steps across the unseen testing trajectories of both datasets for all experiments. The reported experimental results are obtained by averaging the models trained with 3 different random seeds, ensuring robustness and reliability, unless explicitly stated otherwise."}, {"title": "VI. RESULTS", "content": ""}, {"title": "A. Impact of History Length and Multi-step Loss", "content": "In this section, we investigate the impact of incorporating historical information and utilizing multi-step loss formula- tion on model performance, with all models in this experi- ment employing the decoupled predictor type. Subsequently, we conduct an ablation study to showcase the superior performance of the decoupled predictor type compared to the previously mentioned predictor types, thereby further validat- ing our proposed approach. We begin by comparing MLP models with and without history information, highlighting the importance of temporal context in predictive modeling. By leveraging historical data, the model improves its ability to capture system dynamics, as evidenced by quantitative results (Table I). Additionally, we investigate multi-step loss formulation's effectiveness in enhancing long-term predictive accuracy, presenting comparative analysis between single- step and multi-step loss functions. Our study reveals that optimizing error over multiple future time steps U reduces prediction errors and improves model robustness for mit- igating compounding errors over long-horizon predictions. Unroll length of 1 serves as the baseline, representing single-step loss with no unrolling. Our findings suggest an optimal configuration of a history length of 20 paired with an unroll length of 10, and is selected for all subsequent experiments. Exceeding an unroll length of 10 leads to training instabilities due to large gradient values. We also notice that if we go beyond a history length of 20, the error increases. Beyond a certain history length, the relevance of past observations may diminish, and including excessively distant past information may introduce noise or irrelevant patterns, hindering the model's ability to generalize effectively to unseen data. Furthermore, we observe MLP's limitations in effectively"}, {"title": "B. Sequential Models Performance", "content": "In this section, we assess the performance of sequential models, including LSTM, GRU, and TCN, in comparison to MLP, highlighting their effectiveness in capturing temporal dependencies and reducing compounding errors. Figure 4 illustrates the mean and variance of composed predictions to evaluate the long-term predictive capability of these models on various unseen test trajectories. Notably, the mean and variance of MLP predictions are observed to be higher than those of the sequential models, indicating the ability of the latter to leverage temporal dependencies for more accurate predictions. This discrepancy arises primarily due to the inherent limitations of MLP architectures in capturing tem- poral dependencies effectively. As a result, MLPs struggle to leverage temporal context from historical information, lead- ing to less accurate predictions over longer time horizons. Additionally, another factor contributing to the higher mean and variance in MLP predictions is the loss of causality in time-dependent signals. Unlike sequential models, which inherently preserve the temporal order of data through re- current connections or 1-D convolutional operations, MLPS process input data in a feedforward manner, disregarding the sequential nature of the information. This lack of causality can lead to discrepancies in predictions, especially over longer time horizons, where the relationships between data points play a critical role in accurate forecasting.\n\nFurthermore, we observe that TCN outperforms all base- line models across various experiments, exhibiting superior performance in terms of predictive accuracy and stability. Moreover, our experiments reveal that TCN achieves a 21\u00d7 reduction in velocity error and a significant 23\u00d7 reduction in attitude error compared to MLP with no history on the PI-TCN dataset. Similarly, on the NeuroBEM dataset, TCN demonstrates a remarkable 31\u00d7 reduction in velocity error and an impressive 56\u00d7 reduction in attitude error compared to MLP with no history. These findings further underscore the superiority of sequential models, particularly TCN, in dynamics learning tasks, emphasizing their ability to capture"}, {"title": "C. Comparison of Predictor Types", "content": "This section analyzes the predictive performance and stability of various predictor types across trajectories charac- terized by diverse levels of aggressiveness. These trajectories exhibit average velocities ranging from 1.12 ms-1 to 3.27 ms-1 for the PI-TCN dataset and 1.67 ms 1 to 15.02 ms-1 for the NeuroBEM dataset. Both velocity and attitude errors are assessed for each predictor type. Results indicate a consistent superiority of the decoupled dynamics predictor over both the full-state and multi-head predictors across all aggression levels, underlining its adeptness in handling chal- lenging dynamic scenarios (refer Table II). Furthermore, an in-depth analysis of the mean and standard deviation of the best-performing predictors across 10 different random seeds underscores the decoupled predictors' enhanced stability and robustness compared to their counterparts (refer Figure 5). Notably, the instability and inaccuracy arises due to the complexity of the underlying problem."}, {"title": "D. Ablation of State Input Representation", "content": "In this experiment, we aim to assess the impact of different input combinations on the performance of our framework for learning dynamics. We consider as inputs the history of velocity, angular velocity, attitude, and control action. Given the crucial role of control action in influencing system dynamics, it is included in all input combinations. We de- compose the framework into three separate predictors: linear velocity, angular velocity, and attitude predictors to better understand the effects of different inputs on each solution. Our observations reveal notable trends across the predic- tors (Table III). Firstly, for the linear velocity predictor, we observe that incorporating the full state information as input, comprising the history of linear velocity, angular velocity, attitude, and control action, result in the best performance. Furthermore, there is a gradual increase in performance as we augment the input with additional state quantities, indicating the importance of considering the complete state information for accurate prediction. Similar trends are observed for the angular velocity and attitude predictors, with optimal perfor- mance achieved when full state observations are included as input. This ablation study highlights the significance of full state information in capturing the intricate dynamics of the system and achieving superior predictive accuracy."}, {"title": "VII. DISCUSSION", "content": "The proposed approach offers several new valuable in- sights and guidelines for designing data-driven solutions for quadrotor learning dynamics. First, leveraging histor- ical information and employing multi-step loss formula- tion significantly enhances the model's ability to predict longer horizons. Second, the modular approach decouples system dynamics into manageable subproblems, facilitating independent optimization of each module. Finally, a TCN architecture integrated with the two aforementioned designs, demonstrates superior performance across diverse levels of aggressiveness in real-world scenarios. The top-performing model produces feasible and stable open-loop predictions for up to 60 steps, showcasing its robustness and efficacy."}, {"title": "VIII. CONCLUSIONS", "content": "In summary, our work tackles the critical challenge of achieving accurate modeling of system dynamics to en- able effective control of quadrotors. Despite the promises of existing data-driven approaches, their limitations in ad- dressing compounding errors over long prediction horizons highlight the necessity for comprehensive strategies. Through meticulous evaluation of design choices and exploration of sequential modeling techniques, we demonstrate strategies in minimizing these errors. Our novel decoupled dynamics learning framework stands out for its ability to simplify the learning process while enhancing modularity, hence improving long-term forecasts. Extensive experiments on real-world datasets validate the efficacy and precision of our approach. Future work includes integrating the proposed framework with a controller to analyze flight performance under challenging operating conditions."}]}