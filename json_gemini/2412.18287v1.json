{"title": "Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation", "authors": ["Sheng Xiang", "Mingzhi Zhu", "Dawei Cheng", "Enxia Li", "Ruihui Zhao", "Yi Ouyang", "Ling Chen", "Yefeng Zheng"], "abstract": "Credit card fraud incurs a considerable cost for both cardholders and issuing banks. Contemporary methods apply machine learning-based classifiers to detect fraudulent behavior from labeled transaction records. But labeled data are usually a small proportion of billions of real transactions due to expensive labeling costs, which implies that they do not well exploit many natural features from unlabeled data. Therefore, we propose a semi-supervised graph neural network for fraud detection. Specifically, we leverage transaction records to construct a temporal transaction graph, which is composed of temporal transactions (nodes) and interactions (edges) among them. Then we pass messages among the nodes through a Gated Temporal Attention Network (GTAN) to learn the transaction representation. We further model the fraud patterns through risk propagation among transactions. The extensive experiments are conducted on a real-world transaction dataset and two publicly available fraud detection datasets. The result shows that our proposed method, namely GTAN, outperforms other state-of-the-art baselines on three fraud detection datasets. Semi-supervised experiments demonstrate the excellent fraud detection performance of our model with only a tiny proportion of labeled data.", "sections": [{"title": "Introduction", "content": "The great losses caused by financial fraud have attracted continuous attention from academia, industry, and regulatory agencies. For instance, as reported in (AlFalahi and Nobanee 2019; M\u00e1t\u00e9 et al. 2019), financial fraud detection plays a critical role to support the sustainable economic growth. However, fraudulent behaviors against online payments, such as illegal card swiping, have caused property losses to online payment users (Bhattacharyya et al. 2011b). An important line of research in financial fraud detection is credit card fraud detection, where credit card fraud is a general term for the unauthorized use of funds in a transaction, typically by means of a credit or debit card (Bhattacharyya et al. 2011a). Figure 1 shows a typical fraud detection framework deployed in the commercial system (Cheng et al. 2020a). A direct way to detect fraud is to match each transaction according to specific rules such as card blacklists and budget checking. However, criminals will also obtain the knowledge of vulnerabilities from the response of the pre-designed rule system, thus invalidating the original system. To solve the invalidation problem, the predictive model is designed to automatically detect fraud patterns and produces a fraud risk score. Domain experts then can thereby focus on the high-risk transactions.\nState-of-the-art. In the literature, many existing predictive models have been extensively studied to deal with fraud transactions (e.g., (Patidar, Sharma et al. 2011; Fu et al. 2016)), which can be classified into two categories: (1) Rule-based methods directly generate sophisticated rules by domain experts to identify the suspicious transactions. For instance, authors in (Seeja and Zareapoor 2014) proposed an association rule method for mining frequent fraud rules; (2) Machine learning-based methods learn static models by exploring large amounts of historical data. For example, authors in (Fiore et al. 2017) extracted features based on neural networks and built supervised classifiers for detecting fraudulent transactions. Recently, graph machine learning-based methods have been proposed (Wang et al. 2019a) where the transactions are modeled as a graph, and the advanced graph embedding techniques are deployed."}, {"title": "Motivation", "content": "The state-of-the-art fraud detection techniques (Dou et al. 2020; Liu et al. 2020, 2021) can well capture the temporal or graph-based patterns of the transactions and significantly advance the performance of credit card fraud detection. However, they have at least one of the following three main limitations: (1) ignoring unlabeled data containing rich fraud pattern information; (2) ignoring categorical attributes, which are ubiquitous in the real production environment; and (3) requiring too much time on feature engineering, especially for categorical features.\nThese motivate us to design a semi-supervised graph neural network for credit card fraud detection. In particular, to capture the relationships among the credit card transactions associated with temporal information, we leverage a temporal transaction graph to model the time-relevant patterns. Besides, labeling the transactions is time-consuming and cost expensive. Only a tiny proportion (much less than 10%) of transactions are labeled in billions of real-life transactions, which contains many fraud patterns that have not been detected. Therefore, it is crucial to exploit the natural features from unlabeled data. In this paper, we design a Gated Temporal Attention Network (GTAN) for the temporal transaction graph, which can extract temporal fraud patterns and exploit both labeled and unlabeled data. In addition, categorical attributes are ubiquitous and useful in real applications. Therefore, it is necessary to leverage useful information through an attribute-driven model. In this paper, we introduce an attribute learning layer for preprocessing the transaction attributes and add risk embedding as new categorical attributes, which can better model fraud patterns (e.g., attribute embedding learning and risk propagation).\nContributions of our work are summarized as follows:\n\u2022 We model credit card behaviors as a temporal transaction graph and formulate a credit card fraud detection problem as a semi-supervised node classification task.\n\u2022 We present a novel attribute-driven temporal graph neural network for credit card fraud detection. Specifically, we propose a gated temporal attention network to extract temporal and attribute information. And we pass attributes and risk information on the temporal transaction graph to exploit both labeled and unlabeled data.\n\u2022 Extensive experiments on three datasets show the superiority of our proposed GTAN on fraud detection. Semi-supervised experiment results show that, when leveraging rich information from the unlabeled data and a bit of labeled data, our proposed method detects more fraud transactions than baselines."}, {"title": "Related Works", "content": "Credit Card Fraud Detection\nSeveral machine learning techniques have been proposed in the literature to address the credit card fraud detection problem. For instance, in (Maes et al. 2002), Bayesian Belief Networks (BBN) and Artificial Neural Networks (ANN) were applied on a real dataset obtained from Europay International. In (\u015eahin and Duman 2011) decision trees and support vector machines (SVMs) are applied on a real-world national bank dataset. The authors in (Fu et al. 2016) showed that using convolution to extract patterns can achieve higher accuracy than non-convolution neural networks. Recently, graph-based fraud detection techniques were proposed. For instance, CARE-GNN (Dou et al. 2020) was proposed to tackle fraud detection on relational graphs. PC-GNN (Liu et al. 2021) was proposed for imbalanced supervised learning on graphs. (Fiore et al. 2017) also proposed a generative adversarial network to improve the classification performance. In (Cheng et al. 2020a,b), authors proposed joint feature learning based on spatial and temporal patterns. However, they modeled the fraud patterns by using only one transaction/cardholder, thereby not being able to exploit the unlabeled data in real-life credit card transactions. The approach we present in this paper is radically different, as we employ a semi-supervised architecture, where the fraud patterns on both unlabeled and labeled data are jointly learned within an attribute-driven graph neural network framework.\nGraph-Based Semi-supervised Learning\nMany recent works have shown the benefit of using unlabeled node attributes in graph neural networks for a wide range of prediction tasks (Vaswani et al. 2017; Song et al. 2022), such as text classification (Xu et al. 2018), molecule property prediction (Guan et al. 2018) or language understanding (Shen et al. 2018). For instance, graph convolutional networks (GCN) were employed on partially labeled citation networks for node property prediction (Kipf and Welling 2016). GraphSAGE (Hamilton, Ying, and Leskovec 2017) was proposed to generate low-dimensional embeddings for previously unseen data. Graph attentive network model and random walks (Wang et al. 2019a) were deployed on social graphs to link the unlabeled and labeled data and pass messages among them. However, they still face at least one of the following two limitations: (1) cannot scale up to real-world graphs over millions of nodes (e.g., vanilla graph attention networks (Velickovic et al. 2018) have a space complexity $O(N^2)$, where N denotes the number of nodes, which is unaffordable for tasks with millions of nodes); (2) cannot propagate and learn the categorical attribute embeddings, especially for risk embeddings. Differently, our approach addresses the fraud detection problem via a message-passing model using categorical attributes, including risk information from node neighbors. Our work exploits attribute-driven model and semi-supervised graph neural networks to find more fraud patterns, which significantly improve the accuracy of credit card fraud detection."}, {"title": "Proposed Method", "content": "In this section, we first introduce the framework of our proposed GTAN. Then, we present the process of feature engineering, the gated temporal attention networks, risk embedding and propagation, and the fraud detection classifier. Lastly, we introduce the optimization strategy.\nModel Architecture\nThe general model architecture of our proposed method is illustrated in Figure 2. Raw attributes of transaction records are first learned by the attribute embedding look-up and feature learning layer, which includes feature aggregation with a multi-layer perception (MLP). In our implementation, the attributes of the card include the card type, cardholder type, card limit, remaining limit, etc. The transaction attributes include the channel ID, currency ID, transaction amount, etc. The merchant attributes contain merchant type, terminal type, merchant location, sector, charge ratio, etc. Then, we devise a gated temporal attention network to aggregate and learn the importance of historical transaction embeddings. Afterward, we leverage a two-layer MLP to learn the fraud probability from these representations. The whole model can be optimized in an end-to-end mechanism jointly with the existing stochastic gradient descent algorithm."}, {"title": "Attribute Embedding and Feature Learning", "content": "Given transaction records $r \\(r_1, r_2,\\dots,r_n\\)$, each record $r_i$ contains card attributes $f_c$, transaction attributes $f_t$, and merchant attributes $f_m$ as $r_i = \\{f_c, f_t, f_m\\}$. In preprocessing, different from (Cheng et al. 2020b), we do not filter out any cards or merchants with few authorized transaction records. As the number of cards and merchants which have never been checked manually is much larger than checked, we adopt full transaction records of users to maintain all potential frauds. Afterward, we construct the numerical attribute representation of each record into tensor format $X_{num} \\in R^{N \\times d}$, where N denotes the number of transactions, and d denotes the dimensions of features. Besides, we extract the card, transaction, and merchant category attributes $X_{cat} \\in R^{N \\times d}$ separately through attribute embedding layers, which can be formulated as follows:\n$e_{attr} = onehot(f_{attr}) \\cdot E_{attr},$\n$X_{cat,i}=MLP(\\sum_{j\\in table} e_{j}), i \\in \\{card, trans, mchnt\\},$   (1)\nwhere $j \\in table$, denotes the column j in our input table data i, $e_{attr} \\in R^{1 \\times d}$ denotes the embedding of attribute attr, onehot(.) denotes the one-hot encoding, $f_{attr}$ denotes the single attribute of one transaction, and $E_{attr} \\in R^{m \\times d}$ denotes the embedding matrix of attribute attr, where m denotes the maximum number of attribute attr. After obtaining the embedding vector of each attribute in the card, transaction, and merchant tables, we aggregate these embeddings to obtain each transaction's categorical embedding through add-pooling with $X^{cat}_u=\\sum_{e\\in \\{card, trans, mchnt\\}} e$, where $X^{cat}_u \\in R^{1 \\times d}$ denotes the category embedding vector of the u-th transaction record. To address the heterogeneity of categorical attributes, our proposed feature learning layer can model all categorical attributes and project them to a unified spatial dimension, which benefits our attribute-driven graph learning model."}, {"title": "Gated Temporal Attention Networks", "content": "To learn the temporal fraud patterns, we generate the temporal transaction graph (Xiang et al. 2021, 2022b) and aggregate messages on this graph to update the embedding of each transaction. Particularly, the directed temporal edges are generated with the previous transactions as the source and the current ones as the target, as illustrated in Figure 2(c). Then we aggregate messages through Temporal Graph Attention (TGAT) mechanism (Xiang et al. 2022a). The number of generated temporal edges per node is a hyper-parameter, which will be studied in the experiment section.\nTemporal Graph Attention. After the feature engineering and attribute embedding, we leverage a series of transaction embeddings $X = \\{x_{to}, x_{t_1},...x_{t_n}\\}$ to learn the temporal embedding of each transaction record. First, we combine categorical attributes and numerical attributes as the input of GTAN network with $X^{(t_i)}= X^{num} + X^{cat}$. At the first TGAT layer, we set $H^0 = X$ as the input embedding matrix. Afterward, we leverage multi-head attention to separately calculate the importance of each neighbor and update embeddings, which can be formulated as follows:\n$H =Concat(Head_1, ..., Head_{hat{t}}) W_o, $  (2)"}, {"title": null, "content": "where $\\hat{t}$ denotes the number of heads, $W_o \\in R^{d \\times d}$ denotes learnable parameters, H denotes the aggregated embeddings with $H = \\{h_{to}, h_{t_1}, ..., h_{t_n}\\}$, and each attention head is formulated as follows:\n$Head = \\sum_{x_i \\in N(x_t)} \\sigma(\\sum_{x_i \\in X} A_{x_t, x_i} x_t),$ \n$A_{x_t, x_i} = \\frac{exp(LeakyReLU(a^T[x_t||x_i]))}{\\sum_{x_j \\in N(x_t)} exp(LeakyReLU(a^T[x_t||x_j]))},$  (3)\nwhere N(xi) denotes the temporal neighbors of the i-th transaction, $a_{xt,xi}$ denotes the importance of temporal edge $(x_t, x_i)$ in each attention head, and $a \\in R^{2d}$ denotes the weight vector of each head. In practice, to avoid extra space consumption in extreme cases (such as high-frequency transactions in a short period), we use a neighbor sampling and truncation strategy to control the number of neighbor nodes |N(xt)| (i.e., the number of associated temporal edges per node) through which the temporal graph attention layer propagates messages. Besides, to avoid borrowing future information, the neighbor transactions sampled for each transaction must be the past transactions from the same cardholder so that we can model the temporal fraud pattern through message passing on the temporal transaction graph.\nAttribute-driven Gated Residual. To further improve the effectiveness and interpretability of our method, after obtaining aggregated embeddings, we leverage the embeddings and raw attributes to infer the importances of the aggregated embeddings and raw attributes after each layer of TGAT, which can be formulated as follows:\n$gate_{t_i} = \\sigma([x_{cat, t_i} || X_{num, t_i} || h_{t_i}]\\beta_{t_i}),$\n$z_{t_i} =gate_{t_i} h_{t_i} + (1 - gate_{t_i}) \\cdot X_{t_i},$   (4)\nwhere $gate_{t_i} \\in [0,1]$ denotes the gate variable of the i-th transaction, $\\sigma$ denotes the sigmoid activation function, $\\beta_{t_i} \\in R^{3d \\times 1}$ denotes the gate vector, and $z_{t_i}$ denotes the output vector of each TGAT layer, which is fed into the next layer as input. According to our framework, if we stack a new TGAT layer with the attribute-driven gated residual mechanism, we use the output of the k-th gating mechanism as the input of the k + 1-th TGAT."}, {"title": "Risk Embedding and Propagation", "content": "Inspired by unifying label propagation with feature propagation (Shi et al. 2021), we propose to take the manually annotated label as one of the categorical attributes of the transaction, and get the embedding of this categorical attribute, which we call risk embedding. Specifically, we take the manually annotated label as the risk feature of each transaction, where the category of unlabeled data is 'unlabeled', and the category of the rest of the data is 'fraud' or 'legitimate'. Then, we add this feature to the transaction data as one of our input categorical attributes. Due to concerns about label leakage, this attribute has not been used in previous fraud detection solutions. We will discuss the techniques for avoiding label leakage later. Then, we propose to embed the partially observed risk attributes (i.e., labels) into the same space as the other node features, which consist of the risk embedding vectors for labeled nodes and zero embedding vectors for the unlabeled ones. Then, we add the node features and risk embeddings together as input node features with $X_{t_i}= x^{(t_i)}_{num} + x^{(t_i)}_{cat} + \\tilde{Y} W_r$, where $W_r$ denotes the learnable parameters of risk embedding. (Shi et al. 2021) have proved that by mapping partially-labeled $\\tilde{Y}$ and node features X into the same space and adding them up, we can use one graph neural network to achieve both attribute propagation and label propagation. Therefore, our fraud detection model can jointly model the temporal fraud patterns and risk propagation by adding the transaction label as one of the transaction categorical attributes."}, {"title": "Fraud Risk Prediction", "content": "After obtaining the aggregated embeddings of transactions, we leverage a two-layer MLP to predict the fraud risk, which is formulated as follows:\n$\\hat{y} = \\sigma(PReLU(HW_0 + b_0)W_1 + b_1),$ (5)\nwhere $\\hat{y} \\in R^{N \\times 1}$ denotes the risk prediction results of all transactions, and W and b denote the learnable parameters of MLP. Afterward, we calculate the objective function L via binary cross-entropy, which is formulated as follows:\n$\\mathcal{L} = - \\frac{1}{N} \\sum_{i=0}^{V} [y_i\\cdot log(p(\\hat{y}_i|X, A))+$ \n$(1-y_i) \\cdot log(1 - p(\\hat{y}_i|X, A))],$  (6)\nwhere y denotes the ground-truth label of transactions. The proposed GTAN can be optimized through the standard SGD-based algorithms.\nMasking to Avoid Label Leakage\nPrevious works only took risk information as optimization objectives to supervise their fraud detection model training. Unlike previous credit card fraud detection solutions, we semi-supervise our model by propagating transaction attributes and risk embeddings among labeled and unlabeled transactions. Using an unmasked objective for our fraud detection model will result in label leakage in the training process. In this case, our model will directly take observed labels and neglect the complicated hidden fraud patterns, which cannot be generalized in predicting future fraud transactions. Therefore, we propose to learn from the risk information of each transaction's neighbor transactions instead of learning from the label of itself. Specifically, a masked fraud detection training strategy is leveraged. During each training step, we randomly sample a batch of nodes, namely center nodes, along with the neighbor nodes corresponding to each center node. Then, we convert the partially observed labels $\\hat{Y}$ into $\\hat{Y}$ by masking all the center nodes' risk embeddings to zero embeddings and keeping the others unchanged. Then, our objective function is to predict $\\hat{Y}$ with given X, Y and A:\n$\\mathcal{L} = - \\frac{1}{V} \\sum_{i=0}^{V} [y_i\\cdot log(p(\\hat{y}_i|X, \\tilde{Y}, A))+$ \n$(1-y_i) \\cdot log(1 - p(\\hat{y}_i|X, \\tilde{Y}, A))],$ (7)"}, {"title": "Experiments", "content": "In this section, we first describe the datasets used in the experiments, then compare our fraud detection performance with other state-of-the-art baselines on two supervised graph-based fraud detection datasets and one semi-supervised dataset. Then, we perform ablation studies by evaluating two variants of the proposed GTAN, which demonstrates the effectiveness of our proposed method and attribute-driven mechanism.\nExperiment Settings\nDatasets To the best of our knowledge, we did not find any public semi-supervised credit card fraud detection dataset. Therefore, we collect the partially labeled records from our collaborated partners, namely Finacial Fraud Semi-supervised Dataset (FFSD). The ground truth labels are obtained on cases reported by consumers and confirmed by financial domain experts. If a transaction is reported by a cardholder or identified by financial experts as fraudulent, we label it as 1; otherwise, it is labeled as 0. Besides, we also experimented on two public supervised fraud detection datasets. The YelpChi graph dataset (Rayana and Akoglu 2015) contains a selection of hotel and restaurant reviews on Yelp. Nodes in the graph of the YelpChi dataset are reviews with 32-dimensional features, and the edges are the relationships among reviews. The Amazon graph dataset (McAuley and Leskovec 2013) includes product reviews of musical instruments. The nodes in the graph are users with 25-dimensional features, and the edges are the relationships among reviews. Some basic statistics of the three datasets are shown in Table 1.\nCompared Methods. The following methods are compared to highlight the effectiveness of the proposed GTAN.\n\u2022 GEM. Heterogeneous GNN-based model proposed in (Liu et al. 2018). We set the learning rate to 0.1 and the number of hops of neighbors to 5.\n\u2022 FdGars. Fraudster detection via the graph convolutional networks proposed in (Wang et al. 2019b). We set the learning rate to 0.01 and the hidden dimension to 256.\n\u2022 Player2Vec. Attributed heterogeneous information network proposed in (Zhang et al. 2019). We set the same parameters as the FdGars model.\n\u2022 Semi-GNN. A semi-supervised graph attentive network for financial fraud detection proposed in (Wang et al. 2019a). We set the learning rate to 0.001.\n\u2022 GraphSAGE. The inductive graph learning model proposed in (Hamilton, Ying, and Leskovec 2017). We set the embedding dimension to 128.\n\u2022 GraphConsis. The GNN-based model tackling the inconsistency problem, proposed in (Liu et al. 2020). We used the default parameters suggested by the original paper.\n\u2022 CARE-GNN The GNN-based model tackling fraud detection on a relational graph (Dou et al. 2020). We used default parameters from the original paper.\n\u2022 PC-GNN. A GNN-based model remedying the class imbalance problem, proposed in (Liu et al. 2021). We used the default parameters from the original paper.\n\u2022 GTAN. The proposed gated temporal attention network model.\u00b9 We also evaluate two variants of our model, GTAN-A and GTAN-R, in which the temporal graph attention component and risk embedding component are not considered, respectively. We set the batch size to 256, the learning rate to 0.0003, the input dropout ratio to 0.2, the number of heads to 4, the hidden dimension d to 256, and train the model with the Adam optimizer for 100 epochs with early stopping."}, {"title": "Evaluation Metrics", "content": "We evaluate the experimental results on credit card fraud detection and opinion fraud datasets by the area under the ROC curve (AUC), macro average of F1 score (F1-macro), and averaged precision (AP), which are calculated as follows:\nWe count the number of True Positive $N_{TP}$ (i.e. correct identification of positive labels), False Positive $N_{FP}$ (i.e., incorrect identification of positive labels), and False Negatives $N_{FN}$ (i.e., incorrect identification of negative labels). Then, F1 score and AP as formulated with $F1_{macro} = \\frac{1}{\\left|C\\right|}\\sum_{i=1}^{\\left|C\\right|}\\frac{P_i+R_i}{2}$ and $AP = \\sum_{i=1}^{n}(R_i - R_{i-1})P_i$, where $P_i = \\frac{N_{TP}}{(N_{TP}+N_{FP})}$ and $R_i = \\frac{N_{TP}}{(N_{TP}+N_{FN})}$.\nWe also report the AUC in our experiments."}, {"title": "Fraud Detection Performance", "content": "In YelpChi and Amazon datasets, we set the ratio of training to testing as 2:3. In the FFSD dataset, transactions of the first 7 months are used as training data, and then we detect fraud transactions in the following 3 months (August, September, and October of 2021). We repeat the experiments ten times"}, {"title": "Semi-supervised Experiment", "content": "To compare the capability of semi-supervised learning, we further set the ratio of the training set to the whole dataset to different values. For brevity of the diagrams, we select the two most competitive baselines (i.e., PC-GNN and CARE-GNN) for the following semi-supervised experiments. We vary the percentages of nodes used for training from 10% to 80% with an incremental of 10% for eight sets of experiments, with the remaining nodes as the test set in each set of experiments. We perform experiments on the YelpChi and Amazon datasets since they are fully annotated, which allows us to vary the ratio of labeled data in a wide range. The experimental results are shown in Figure 3.\nOn the YelpChi dataset, we can observe that GTAN always has the best performance under different training ratios. At the same time, in scenarios with little labeled data (10% training ratio), GTAN still performs well. As the number of labeled data increases, there is a steady improvement in the performance of GTAN. On the Amazon dataset, we can also observe that GTAN always has the best performance under different training ratios. Compared with the YelpChi dataset, the GTAN model on the Amazon dataset is less sensitive when changing the training ratio with no more than 2% variations in the AUC. This fully demonstrates that GTAN can achieve good performance even when there is a small portion of labeled data available (i.e., as low as 10%). Therefore, we conclude that the GTAN model is robust to training ratio changes and consistently outperforms PC-GNN and CARE-GNN, which shows the superiority of GTAN model in semi-supervised learning."}, {"title": "Ablation Study", "content": "The proposed model contains some key components, and we verify their effectiveness by ablating each component, respectively. Specifically, we evaluate two variants, namely GTAN-A and GTAN-R. In the GTAN-A model, we remove the TGAT component, and the central node aggregates messages directly collected from neighboring nodes. In this case, we obtain the transaction embeddings from all the neighbor embeddings with the same weight instead of adaptively adjusting the weights of neighbor nodes. In the GTAN-R model, we remove the risk embedding component and only use the original node attributes X.\nThe grey bars in Figure 4 show the removal of the attention mechanism has the greatest impact on the accuracy metrics of the model. This proves that the reweighting of temporal transaction neighbors from the temporal graph attention mechanism is effective in our graph-based method. Besides, the green bars in Figure 4 gets the second-highest scores compared with GTAN, which proves that the risk embedding is effective in modeling credit card fraud patterns from transaction risk propagation. In summary, removing either component deteriorates the performance of GTAN, which proves that the temporal graph attention mechanism and risk embedding are both effective in graph-based fraud detection."}, {"title": "Parameter Sensitivity", "content": "In this section, we study the model parameter sensitivity by varying the depth of temporal graph attention layers, the number of temporal edges per node, the hidden dimension, and the batch size. The experimental results in the fraud detection dataset are reported in Figure 5.\nWe vary the depth of temporal graph attention layers from 1 to 10. As shown in Figure 5(a), our model's performance remains stable with up to 8 GNN layers. With deeper layers, our model tends to aggregate the temporal information from larger neighborhoods. Our model performs the best with two GNN layers when the AUC and AP reach the peak; therefore, we set the default depth to 2. The performance is degraded if we keep on increasing the depth of TGAT layers. The reason might be that deeper GNNs result in over-smoothing (Zhao and Akoglu 2020) in transaction embeddings. Figure 5(b) shows that when we increase the number of temporal edges per node from 1 to 10, our proposed model could consider neighbors in a wider range. Besides, our model requires at least 2 neighbors to learn graph-based transaction embeddings, and it reaches peak performance when the number of edges is 6. Beyond that, an excessive increase in the number of edges in the graph is not beneficial to the model's accuracy. Figure 5(c) shows that when we increase the hidden dimensions from 4 to 2048, our model maintains stable model performance and reaches a relative performance peak at 256. Figure 5(d) shows that our model performs best when the batch size is set as 64 or 256. Considering the training efficiency of the model, we set the batch size as 256. Generally, for values ranging from 16 to 512, the model is not sensitive to the hidden dimension and batch size, with less than 3% variations in the AUC."}, {"title": "Conclusion", "content": "In this paper, we studied an important real-world problem of credit card fraud detection. Considering that the labeling of fraud transactions is time-consuming and cost-expensive, we proposed an effective semi-supervised credit card fraud detection method by modeling data with temporal transaction graphs and developing attribute-driven gated temporal attention networks. Considering the ubiquitous categorical attributes and human-annotated labels, we proposed an attribute representation and risk propagation mechanism to model the fraud patterns accurately. The comprehensive experiments demonstrated the superiority of our proposed methods in three fraud detection datasets compared with other baselines. Semi-supervised experiments demonstrate the excellent fraud detection performance of our model with only a tiny proportion of manually annotated data. Our approach has been deployed in a transaction fraud analysis system. In the future, we will explore to study the temporal fraud patterns and risk-propagation fraud patterns in an effective and efficient way."}]}