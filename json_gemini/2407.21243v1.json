{"title": "Informed Correctors for Discrete Diffusion Models", "authors": ["Yixiu Zhao", "Jiaxin Shi", "Lester Mackey", "Scott Linderman"], "abstract": "Discrete diffusion modeling is a promising framework for modeling and generating data in discrete spaces. To sample from these models, different strategies present trade-offs between computation and sample quality. A predominant sampling strategy is predictor-corrector T-leaping, which simulates the continuous time generative process with discretized predictor steps and counteracts the accumulation of discretization error via corrector steps. However, for absorbing state diffusion, an important class of discrete diffusion models, the standard forward-backward corrector can be ineffective in fixing such errors, resulting in subpar sample quality. To remedy this problem, we propose a family of informed correctors that more reliably counteracts discretization error by leveraging information learned by the model. For further efficiency gains, we also propose k-Gillespie's, a sampling algorithm that better utilizes each model evaluation, while still enjoying the speed and flexibility of T-leaping. Across several real and synthetic datasets, we show that k-Gillespie's with informed correctors reliably produces higher quality samples at lower computational cost.", "sections": [{"title": "1 Introduction", "content": "Denoising diffusion models are powerful generative models for high-dimensional data [1-3]. The central idea of diffusion models is to gradually corrupt data into noise using a \"noising\" or \"forward\" process and then to train a parameterized model (usually a deep neural network) to learn its time reversal, commonly known as the \u201cdenoising\" or simply the \"backward\" process. In continuous domains such as image generation, the forward process is usually defined by gradual injection of Gaussian noise and scaling, transforming the data distribution close to a standard normal. The backward process is then approximated by learning the gradient of the log density (also known as the \"score function\") of the marginal distribution. Samples can be drawn from a trained model by first generating Gaussian noise and then simulating the backward process using the score information. Diffusion generative models are currently the dominant framework for image generation and can generate high-resolution images with stunning details and style given prompts by the users [4, 5].\nGiven the success of diffusion models in continuous domains, recent work has explored diffusion modeling in discrete domains [6-13], with applications to language [13], protein sequences [14, 15], graphs [16], and more. Notably, Campbell et al. [9] developed TauLDR, a general framework for discrete denoising diffusion in continuous time. They formulated the forward and backward processes as continuous time Markov chains (CTMCs), and their model learns to predict the distribution over denoised data via an evidence lower bound (ELBO) objective. Lou et al. [13] adopted a very similar strategy but instead directly parameterize the concrete score function an analog of the continuous score function in discrete spaces."}, {"title": "2 Background", "content": "Consider a data point x \u2208 S which is assumed to be sampled from the data distribution Pdata (xo). Denoising diffusion models [1-3] seek to model this unknown data distribution by progressively adding noise to data samples until their distribution converges to a simple target, such as a uniform distribution. Then, a deep neural network is trained to invert this process and remove the noise. This reverse process forms a generative model from which new samples can be drawn. The noising and generative processes are also called the forward and backward processes, respectively. We will adopt this convention for the rest of the paper.\nContinuous-time diffusion models define a forward process with noising distribution qt(xt|x0) and marginals qt(xt) = \u222b qt(xt|xo)qo(x0)dxo, with qo = Pdata and qt \u2248 \u03c0 where \u03c0 is the limiting distribution of the forward process, which is assumed to be a simple distribution. Then, a parameterized process with marginals pt is learned to match the true backward process.\nWhen the data of interest is discrete in nature (e.g., text, protein sequences, neural spike counts), the forward-process can be described with a continuous-time Markov chain (CTMC), which is captured by the initial distribution qo and a transition rate matrix Rt \u2208 RS\u00d7S, where S = |S| denotes the cardinality of the data space. The off-diagonal terms Rt(x, y), x \u2260 y of the matrix represent the rate of state x transitioning to state y, and the diagonals Rt(x, x) are defined as the negative sum of all other elements in the same row: Rt(x,x) = \u2212 \u03a3y\u2260x Rt(x, y). Under the assumption that Rt and Rs commute for all s and t, the finite-time transition probabilities satisfy"}, {"title": "2.1 Continuous-Time Discrete Diffusion Models", "content": null}, {"title": "2.2 Sequence Modeling with the Absorbing Forward Process", "content": "For real-world applications, the data is often a vector or sequence x1:D of length D, where each dimension of the data xd belongs to a vocabulary, and the full state space is the product of the vocabularies and thus exponentially large. With a shift in notation, we now use S = {1, ..., S} to denote the \u201cvocabulary\u201d set instead, whereas the full space is represented as SD.\nGiven the factorization of this space, it is natural to model the forward process as a composition of identical independent processes on each dimension, where the rate over the entire state Rt can be written as"}, {"title": "2.3 Sampling From the Backward Process", "content": "Given learned rates R for the backward process, one can approximately sample from the backward Markov jump process using Gillespie's algorithm [22] which computes"}, {"title": "2.4 Corrector Steps for \u03c4-leaping", "content": "Because of the approximate nature of the \u03c4-leaping steps, this approach accumulates simulation errors over the course of the backward process. To combat this problem, additional corrector steps can be used to make sure that the marginal distribution of samples xt at time t matches qt. Campbell et al. [9] show that a corrector process with rates:"}, {"title": "3 Methods", "content": "This section presents our main contributions. Focusing on discrete diffusion models with an absorbing forward process, we propose a modification of Gillespie's algorithm, a classic algorithm for simulating CTMCs, to approximate the backward process with fewer model evaluations. Then, motivated by the discussion above, we develop novel corrector steps for the reverse process. Taking inspiration from the Stein operator literature, we present informed correctors, a family of Markov transition operators that leverage score information learned by the model to more efficiently address mistakes in the reverse process and improve sample quality."}, {"title": "3.1 k-Gillespie's Algorithm", "content": "In the absorbing state reverse process, a change in the state happens if and only if a new token is generated from the absorbing state. This means that the number of state changes is exactly equal to the number of positions D, which, in Gillespie's algorithm, also corresponds to D model evaluations.\nUnlike Gillespie's, \u03c4-leaping can freely choose the number of model evaluations by changing the step size \u03c4. This enables a trade-off between sample quality and computation. Unfortunately, a Poisson-distributed number of updates in the \u03c4-leaping algorithm means that on some steps, no"}, {"title": "3.2 Informed Correctors", "content": "We propose the following family of correctors for discrete diffusion sampling by combining the symmetrized forward process and with an additional \u201ccorrector operator,\u201d At,"}, {"title": "4 Learning Informed Correctors for Absorbing State Diffusion", "content": "We develop an approach for learning informed correctors for discrete diffusion models with absorbing forward processes. Specifically, we modify the parameterization and architecture such that when trained with the same ELBO objective, the model learns the necessary score information efficiently. Note that this change in architecture is only required for the absorbing state diffusion, and for uniform process diffusion informed correctors can be applied directly without changing the learning scheme."}, {"title": "4.1 Alternative Parameterization for Efficient Score Evaluation", "content": "The corrector rates in (8) and (9) provide a nonzero rate of converting the token at the d-th dimension of x back into a mask. These rates depend on the score function"}, {"title": "4.2 Learning the Full Score Information Using Hollow Transformers", "content": "Despite the conceptual simplicity, for this parameterization to work in practice, one must make sure that for d \u2208 M(x) information about xd does not leak to the output fo (x,t)d,i. To achieve this, we use a hollow transformer [28], a two-stream self-attention architecture where each stream runs causal attention in a different direction. The embeddings are then offset by one position so that the embedding at position d does not attend to the corresponding input position. By combining these two directional streams, the hollow transformer satisfies the property that, for continuous x,\n\nIn other words, the network output at dimension d is agnostic to the input at the same dimension d. We provide more details of the model architecture in Section 6.\nLearning the Hollow Transformer with the ELBO Objective The parameterization in (10) can be learned with the hollow transformer without changing the ELBO objective (4). To see why, consider a pair of observations x and x' = Md(x) such that xd \u2260 MASK. By the property of the hollow transformer, fHT(x,t)d,i = fHT(x',t)d,i. However, since the forward rate Rt(\u00b7, x) is 0 under the absorbing forward process, the backward rate R\u2021 (x, \u00b7) is also 0. This means that during training, gradients only flow through R\u2081(Md, \u00b7), which encourages the network output fhr(x,t)d,i to approach the true denoising distribution qo\u2081t(x8 = i | Md(x)) which is conditioned on the masked state Md(x) = x'. In other words, since the model does not see xd when producing the output at dimension d, it always tries to produce outputs as if xd = MASK to minimize the loss."}, {"title": "5 Related Work", "content": "Discrete diffusion models and predictor-corrector sampling. Sohl-Dickstein et al. [1] derived a discrete diffusion model but only for binomial variables. Hoogeboom et al. [6], Song et al. [7] extended the formulation to categorical variables using a uniform noising distribution, which was further generalized by Austin et al. [8] to enable any corruption processes specified with a transition matrix. Austin et al. [8] also discussed the continuous-time limit of the proposed discrete diffusion model. A continuous-time objective amenable to training was first proposed by Campbell et al. [9] and further developed by Benton et al. [12], Lou et al. [13], Shi et al. [19]. In addition to this line of"}, {"title": "6 Experiments", "content": "We evaluate k-Gillespie's algorithm and informed correctors on synthetic and real datasets for both unconditional and conditional sampling tasks. We train a hollow transformer architecture augmented for denoising diffusion using standard implementation techniques [17]. The inputs to the transformer are treated as one-hot variables, destroying all ordinal structure of the data. Our networks use 5M to 8M parameters depending on the task. Training is done using a single A100 GPU with 80GB of memory on an academic cluster.\nTo study efficiency-quality trade-offs, we measure different dataset-dependent metrics and also record the number of function evaluations (NFE) needed to produce each sample under different sampling schemes. For \u03c4-leaping, we control NFE via tuning the \u03c4 parameter, which is the inverse of the number of predictor steps. For our k-Gillespie's, we change k from 1 to 3, with higher values of k resulting in fewer NFEs. Keep in mind that each corrector step also requires one function evaluation."}, {"title": "6.1 The Countdown Dataset", "content": "To check our intuition that standard forward-backward correctors would perform poorly for absorbing diffusion processes (see Section 2.4), we create a synthetic sequence dataset with strong position-wise correlation structure and test generation quality for different corrector steps. Given a state size S and sequence length D, a data sequence x1:D is drawn according to the following rule:\n\nWe evaluate sample quality for this dataset using the error rate measured by the proportion of generated tokens that fail to count downward from the previous token:"}, {"title": "6.2 Gene Expression Data", "content": "To test if these sampling schemes also capture correlations on real data,\nwe use a gene expression time series dataset [36] and the evaluation metrics from Kerrigan et al. [37]. We quan-tize the values by binning them into S = 64 discrete bins and train our model on the discretized data. Kerrigan et al. [37] evaluates the quality of the generated sequences by computing point-wise statistics for each position along the sequence lengths and computes the mean squared error (MSE) of these statistics between the samples and true data.\nUnfortunately, these point-wise met-rics are ineffective at testing the corre-lation structure of individual sampled sequences, since they only measure marginal distributions on each sequence dimension. However, as we have demonstrated previously, correctors are needed to compensate for the predictor's failures to capture dependencies in the data. In order to better test this, we calculate the point-wise metrics on the discrete cosine transform (DCT) of the sequences.\nThe results are shown in Figure 3. Each method uses 56 model evaluations and 2 corrector steps per predictor step. We find that k-Gillespie's still reliably outperforms \u03c4-leaping, while the MPF informed corrector yields the best performance on many metrics."}, {"title": "6.3 Conditional Generation on Monophonic Music", "content": "Following Campbell et al. [9], we test conditional generation by modeling songs from the Lakh pianoroll dataset. In this dataset, monophonic sequences of length 256 are extracted, with each coordinate representing one of 128 notes or a rest. Campbell et al. [9] trained a discrete denoising diffusion model with the uniform forward process. The training objective was altered to target the last 224 time steps of the input sequence given the first 32. We construct our hollow transformer model with approximately the same number of parameters and train it for over 1M iterations."}, {"title": "7 Discussion", "content": "We proposed informed correctors and modified algorithms for discrete diffusion models with absorbing forward processes. We showed that common scheme of \u03c4-leaping with the forward-backward corrector is not well-suited to this setting. To address this problem, we develop novel, informed correctors and provided a modified training strategy to learn them. We showed that this approach produces superior sample quality with fewer model evaluations than previous methods. Overall, our work serves to further enhance the capabilities of diffusion models in discrete regimes.\nLimitations Using the informed correctors for absorbing diffusion requires architecture modifica-tions such as using the hollow transformer. In practice, we cannot apply the correctors directly for pretrained models and have to retrain them from scratch. This limits the direct applicability of our methods.\nFuture work In developing the informed corrector, we observed that design decisions in the training and sampling phases can be strongly coupled. To leverage better sampling methods, the need for modifying the training setup naturally arises. Future work could explore this coupling in more depth, for example, by studying how the architecture and training objective can be further adapted to efficient sampling strategies."}, {"title": "A Unifying the TauLDR and score entropy objectives", "content": "We first reproduce the TauLDR objective:"}, {"title": "B Pseudocode for k-Gillespie's Algorithm", "content": "We give pseudocode for the k-Gillespie's algorithm presented in Section 3.1 in Algorithm 1. Note that here we use the generation operator x = Gd (y) to represent the sequence obtained by changing the dth component of y to the token n."}], "equations": ["q_{t+\\Delta t|t}(y | x) = \\left[\\exp \\left{\\int_{t}^{t+\\Delta t} R_s ds\\right}\\right](x, y) = I(x,y) + R_t(x, y)\\Delta t + o(\\Delta t), \\tag{1}", "R_t(y, x) = R_t(x, y) \\frac{q_t(x)}{q_t(y)} = R_t(x, y) \\frac{\\sum_{x_0} q_{t|0}(x | x_0) q_0|t(x_0 | y)}{\\sum_{x_0} q_{t|0}(y | x_0) q_0|t(x_0 | y)}.\\tag{2}", "\\hat{s}_t^{\\theta}(y) = \\sum_{x_0} \\frac{q_{t|0}(x | x_0)}{q_{t|0}(y | x_0)} P_{t}^{\\theta}(x_0 | y). \\tag{3}", "-\\log p(x_0) \\leq L(0) = \\mathbb{E}_{q_{t|0}(y|x_0)} \\left[ \\int_0^1 \\sum_{x \\neq y} q_{t|0}(y | x_0) \\left[ R_t(y,x) - R_t(y, x) \\log(R_t^{\\theta}(y, x))\\right] dt + C,\\tag{4}", "R(x, y) = \\beta(t) \\sum_d R(x_d, y_d)1\\{x_{\\backslash d}=y_{\\backslash d}\\}\\tag{5}", "R^{\\text{absorb}}(x, y) = \\begin{cases} 1 & y = \\text{MASK}, x \\neq \\text{MASK} \\\\ -1 & y = x, x \\neq \\text{MASK} \\\\ 0 & \\text{otherwise}, \\end{cases}\\tag{6}", "R(x,y) = R_t(x,y) + \\mathring{R}_t(x,y)\\tag{7}", "R^{\\text{J}}(x,y) = \\begin{cases} J(R_t(x, y) + R_t(y,x)) \\cdot A_t(x, y) & x \\neq y \\\\ -\\sum_{z} R(x, z) & x = y \\end{cases}\\tag{8}", "A_t(x, y) = \\begin{cases} \\kappa(t) \\frac{q_t(y)}{q_t(x)} & y \\neq x \\\\ -\\sum_z A_t(x,z) & y = x \\end{cases}\\tag{9}", "s_t(x) M_d(x) = \\frac{q_t(x)}{q_t(M_d(x))} \\approx \\frac{\\sum_i^S q_{t|0}(x | x_0 = i) f_t^\\theta(x,t)_{d,i}}{\\sum_i^S q_{t|0}(M_d(x) | x_0 = i) f_t^\\theta(M_d(x),t)_{d,i}}.\\tag{10}", "\\frac{\\partial}{\\partial x_d} HT(x,t)_{d,i} = 0 \\quad \\forall i \\in \\{1, ..., S\\}.\\tag{11}", "x^1 \\sim \\text{Uniform}\\{1, ..., S\\}, \\quad x^{d+1} | x^d \\sim \\begin{cases} \\delta_{x^d} & x^d \\neq 0 \\\\ \\text{Uniform}\\{1, ..., S\\} & x^d = 0\\end{cases}\\tag{12}", "r_{\\text{err}}(\\{x_n\\}_{1...N}) = \\frac{1}{ND} \\sum_{n=1}^N \\sum_{d=1}^D 1\\{(x_n)^d - (x_n)^{d-1} \\neq 0\\}.\\tag{13}", "L(0) = \\mathbb{E}_{q_t(y)r_t(z|y)} \\left[ R_t(y) - \\sum_{z^{\\prime} \\neq y} R_t(y, z^{\\prime}) \\log(R_t^{\\theta}(y, z))\\right] dt \\tag{14}", "L(0) = \\int \\mathbb{E}_{q_t(y)r_t(z|y)} \\left[ R_t(y) - R_t(y) \\log(R_t^{\\theta}(y, z))\\right] dt,\\tag{15}", "r_t(z|y) = \\begin{cases} \\frac{R_t(y,z)}{R_t(y)} & y \\neq z \\\\ 0 & y = z \\end{cases}\\tag{16}", "q_t(y)r_t(z | y) = \\sum_{x_0} q_0(x_0)\\psi_t(z | x_0)\\phi_t(y | z, x_0),\\tag{17}", "L(0) = \\int \\mathbb{E}_{q_0(x_0)q_t(y|x_0)r_t(z|y)} \\left[ R_t(y) - \\sum_{z \\neq y} R_t(y, z) \\log(R_t^{\\theta}(z, y))\\right] dt\\tag{18}", "= \\int \\mathbb{E}_{q_0(x_0)q_t(y|x_0)} \\left[ R(y) - \\sum_{z \\neq y} R_t(y, z) \\log(R_t^{\\theta}(z, y)) \\right] dt\\tag{19}", "= \\int \\mathbb{E}_{q_0(x_0)q_t(y|x_0)} \\left[ \\sum_{z \\neq y} R_t(y, z) - \\sum_{z \\neq y} R_t(y, z) \\log(R_t^{\\theta}(z, y)) \\right] dt\\tag{20}", "= \\int \\mathbb{E}_{q_0(x_0)} \\sum_{y} \\sum_{z \\neq y} \\left\\{q_t(y|x_0)R_t(y, z) - q_t(y | x_0) R_t(y, z) \\log(R_t^{\\theta}(z,y))\\right\\} dt\\tag{21}", "= \\int \\mathbb{E}_{q_0(x_0)} \\sum_{y} \\sum_{z \\neq y} \\left\\{q_t(y | x_0)R_t(y, z) - q_t(z | x_0) R_t(z, y) \\log(R_t^{\\theta}(y, z))\\right\\} dt\\tag{22}", "= \\int \\mathbb{E}_{q_0(x_0)} \\sum_{y} \\sum_{z \\neq y} \\left\\{q_t(y | x_0)R_t(y, z) - q_t(z | x_0) R_t(z, y) \\log(\\frac{R_t(y, z)}{q_t(y | x_0)})\\right\\} dt\\tag{23}", "= \\int \\mathbb{E}_{q_0(x_0)q_t(y|x_0)} \\sum_{x \\neq y} \\left\\{\\frac{R_t^{\\theta}(y, x)}{q_t(y|x_0)} - R_t^{\\theta}(y, x) \\log(R_t^{\\theta}(y, x))\\right\\} dt,\\tag{24}"]}