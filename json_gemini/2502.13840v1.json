{"title": "Mitigating Popularity Bias in Collaborative Filtering through Fair Sampling", "authors": ["Jiahao Liu", "Dongsheng Li", "Hansu Gu", "Peng Zhang", "Tun Lu", "Li Shang", "Ning Gu"], "abstract": "Recommender systems often suffer from popularity bias, where frequently interacted items are overrepresented in recommendations. This bias stems from propensity factors influencing training data, leading to imbalanced exposure. In this paper, we introduce a Fair Sampling (FS) approach to address this issue by ensuring that both users and items are selected with equal probability as positive and negative instances. Unlike traditional inverse propensity score (IPS) methods, FS does not require propensity estimation, eliminating errors associated with inaccurate calculations. Our theoretical analysis demonstrates that FS effectively neutralizes the influence of propensity factors, achieving unbiased learning. Experimental results validate that FS outperforms state-of-the-art methods in both point-wise and pair-wise recommendation tasks, enhancing recommendation fairness without sacrificing accuracy. The implementation is available at https://anonymous.4open.science/r/Fair-Sampling", "sections": [{"title": "Introduction", "content": "Recommender systems gather vast amounts of data on user behavior, especially implicit feedback from user-item interactions, to model user preferences [15-20, 29]. However, user interactions are shaped not only by intrinsic user preferences but also by external factors, such as item popularity [30]. Directly modeling observed user interactions may lead to predictions that are overly skewed toward popular items [26]. The Matthew effect exacerbates this by making long-tail items less likely to be recommended, thus diminishing the novelty, diversity, and fairness of recommendations [8].\nSeveral methods based on inverse propensity scores (IPS) [24] have been proposed to mitigate popularity bias by weighting samples during model training. However, estimating propensity scores in practical applications can be highly challenging. These methods often rely on overly simplified assumptions-for instance, assuming that the propensity score depends solely on item popularity-which can lead to high variance [22]. Although variance reduction techniques, such as clipping the scores, can be applied, these adjustments compromise unbiasedness. Furthermore, the difficulty in accurately estimating propensity scores prevents IPS-based methods from effectively eliminating popularity bias.\nIn this paper, we first analyze the optimization objectives of ideal and classical loss functions, identifying that the bias in classical loss functions stems from the inclusion of propensity factors in the model output. Meanwhile, popular items are more likely to be treated as positive samples during training, which leads to higher propensity factor scores and subsequently higher interaction scores, with popularity being mistakenly interpreted as user preference. Building on this insight, we propose a fair sampling (FS) method that ensures each user and each item has an equal likelihood of being selected as both positive and negative instances during training, thus preventing popular items from being overly selected as positive samples. Theoretical analysis demonstrates that the proposed FS can effectively eliminate the influence of propensity factors without the need to estimate the propensity score, thereby mitigating popularity bias and overcoming the limitations of IPS-based methods.\nFS is a sampling-level optimization method that can be applied to both point-wise and pair-wise loss functions. Depending on the type of loss function, we implement FS-Point for point-wise loss and FS-Pair for pair-wise loss. We compare FS-Point and FS-Pair against their respective point-wise and pair-wise baselines. Experimental results show that FS achieves state-of-the-art performance."}, {"title": "Related Work", "content": "IPS-based methods mitigate popularity bias in recommender systems through sample weighting. We categorize related work by the type of loss function: point-wise or pair-wise.\nPoint-wise. Rel-MF [25] formulates interaction occurrence as a two-step process-exposure and interaction-and introduces an unbiased point-wise loss function. DU [10] refines this method by enhancing propensity score estimation. CJMF [34] introduces a joint learning framework to simultaneously model unbiased user-item relevance and propensity. BISER [11] addresses item bias via self-inverse propensity weighting and employs bilateral unbiased learning to unify two complementary models. More recently, ReCRec [14] improves bias correction by distinguishing unexposed from disliked items, enabling better reasoning over unclicked data.\nPair-wise. UBPR [24] builds on the two-step interaction assumption to introduce an unbiased pair-wise loss function. UPL [22] extends this approach with a variance-reduced learning method. CPR [26] redefines unbiasedness in ranking and leverages cross pairs to improve unbiased learning. UpliftRec [4] applies uplift modeling to dynamically optimize top-N recommendations, revealing latent user preferences while maximizing click-through rates. Additionally, PU [3] models feedback labels as a noisy proxy for exposure outcomes and integrates a theoretically noise-resistant loss function into propensity estimation."}, {"title": "Methods", "content": "We first introduce the notations in Section 3.1 and formalize the ideal and classic loss functions in Sections 3.2 and 3.3, respectively. Then, in Section 3.4, we analyze the bias in the classic loss function by comparing its optimization objective with that of the ideal loss function. Finally, in Section 3.5, we present the proposed fair sampling (FS) method and analyze how it mitigates popularity bias."}, {"title": "Notations", "content": "For a user $u \\in U$ and an item $i \\in I$, we refer to a user-item pair as a positive pair if an interaction occurs between them; otherwise, we call it a negative pair. A interaction occurs through a two-step process [24, 25]: first, a user observes an item; then, based on how relevant the item is to the user's preferences, the user decide whether to interact with it. Next, we define three binary indicator matrices: (1) Observation matrix $O\\in \\{0,1\\}^{|U|\\times|I|}$, where $O_{u,i}$ indicates whether $u$ has observed $i$ (or, equivalently, whether $i$ has been exposed to $u$); (2) Relevance matrix $R \\in \\{0,1\\}^{|U|\\times|I|}$, where $R_{u, i}$ indicates whether $u$ would interact with $i$ given $O_{u,i} = 1$ (or, equivalently, whether $u$ likes $i$); (3) Interaction matrix $Y \\in \\{0,1\\}^{|U|\\times|I|}$, where $Y_{u,i}$ indicates whether $u$-$i$ is a positive pair. Note that only $Y$ is observable, while both $O$ and $R$ are latent variables.\nClearly, $u$-$i$ is a positive pair ($Y_{u,i} = 1$) if and only if $u$ has observed $i$ ($O_{u,i} = 1$) and the two have high relevance ($R_{u,i} = 1$). This can be expressed as $Y_{u,i} = O_{u,i} R_{u,i}$, or in matrix form, $Y = O \\cdot R$. Consequently,\n$P(Y_{u,i} = 1) = P(O_{u,i} = 1, R_{u,i} = 1)$  (1)\n$= P(O_{u,i} = 1|R_{u,i} = 1) P(R_{u,i} = 1)$,\nwhere $P(R_{u,i} = 1)$ denotes the relevance probability between $u$ and $i$, and $P(O_{u,i} = 1|R_{u,i} = 1)$ represents the exposure probability-the probability that $i$ is observed by $u$ given their relevance. Assuming the exposure probability can be decomposed into user propensity, item propensity, and user-item relevance, it can be expressed as:\n$P(O_{u,i} = 1|R_{u,i} = 1) = \\theta_u \\cdot \\theta_i \\cdot P(R_{u,i} = 1)^{\\alpha}$. (2)\nHere, $\\theta_u$ and $\\theta_i$ are user-specific and item-specific propensity factors, respectively, which tend to have higher values for active users and popular items. The term $P(R_{u,i} = 1)^{\\alpha}$ indicates that a higher relevance score increases the exposure probability, where $\\alpha$ is a positive constant used to moderate its influence."}, {"title": "Ideal Point-wise Loss and Pair-wise Loss", "content": "Ideally, a recommendation model should reflect users' intrinsic preferences $R$ rather than simply imitating observed user behaviors $Y$. For this to hold, users must observe all items and decide whether to interact with them based on relevance. In this scenario, all elements of $O$ are assigned a value of 1, making $Y$ identical to $R$.\nOne commonly used point-wise loss is the cross-entropy loss. Let $s_{u,i}$ denote the predicted score of $u$-$i$ produced by the model, then $\\delta^{+}(u, i) = - \\log(s_{u,i})$ and $\\delta^{-}(u, i) = - \\log(1-s_{u,i})$, where $\\delta^{+}(u, i)$ and $\\delta^{-}(u, i)$ denote the loss contributions for $u$-$i$ being a positive and a negative pair, respectively. The ideal point-wise loss is defined as follows:\n$\\mathcal{L}_{ideal}^{point} = \\sum_{(u,i; R_{u,i}) \\in U \\times I} [R_{u,i} \\cdot \\delta^{+}(u, i) + (1 - R_{u,i}) \\cdot \\delta^{-}(u, i)]$. (3)\nOne commonly used pair-wise loss is the BPR loss, which is defined as $\\zeta (u, i, j) = - \\ln \\sigma (s_{u,i} - s_{u,j})$, where $\\sigma(\\cdot)$ is the sigmoid function. The ideal pair-wise loss is defined as follows:\n$\\mathcal{L}_{ideal}^{pair} = \\sum_{(u,i,j; R_{u,i}, R_{u,j}) \\in U \\times I \\times I} [R_{u,i} \\cdot (1 - R_{u,j}) \\cdot \\zeta (u, i, j)]$. (4)\nThe ideal loss functions can guide the model to learn users' inherent preferences. However, since $R$ is unobservable, the ideal loss functions cannot be computed directly."}, {"title": "Classic Point-wise Loss and Pair-wise Loss", "content": "WMF [6] introduced a point-wise loss for modeling implicit feedback data:\n$\\mathcal{L}_{bias}^{point} = \\sum_{(u,i; Y_{u,i}) \\in U \\times I} [Y_{u,i} \\cdot \\delta^{+}(u, i) + (1 - Y_{u,i}) \\cdot \\delta^{-}(u, i)]$. (5)\nBPR [23] introduced a pair-wise loss for modeling implicit feedback data:\n$\\mathcal{L}_{bias}^{pair} = \\sum_{(u,i,j; Y_{u,i}, Y_{u,j}) \\in U \\times I \\times I} [Y_{u,i} \\cdot (1 - Y_{u,j}) \\cdot \\zeta (u, i, j)]$. (6)\nClassic loss functions are designed to directly model the interaction matrix $Y$. Since $Y$ depends not only on $R$ but also on $O$, classic loss functions provide biased approximations of the ideal loss functions."}, {"title": "Analysis", "content": "Let $s_{u,i}^{ideal}$ and $s_{u,i}^{bias}$ denote the predicted results obtained by optimizing the model with the ideal loss ($\\mathcal{L}_{ideal}^{point}$ or $\\mathcal{L}_{ideal}^{pair}$) and the classic loss ($\\mathcal{L}_{bias}^{point}$ or $\\mathcal{L}_{bias}^{pair}$), respectively. $s_{u,i}^{ideal}$ captures users' intrinsic preferences $R$, while $s_{u,i}^{bias}$ reflects users' interaction behaviors $Y$. Therefore,\n$s_{u,i}^{ideal} = P(R_{u,i} = 1) > 0$,\n$s_{u,i}^{bias} = P(Y_{u,i} = 1) = \\theta_u\\theta_iP(R_{u,i} = 1)^{\\alpha + 1} > 0$. (7)\nIntuitively, classic loss functions introduce biases as they inherently incorporate propensity factors into the model's output. As a result, even if user $u$ exhibits the same level of preference for both items $i$ and $j$ ($P(R_{u,i} = 1) = P(R_{u,j} = 1)$), the optimization outcome of classic loss functions tends to favor the item with a higher propensity factor ($\\theta_u\\theta_iP(R_{u,i} = 1)^{\\alpha}$ or $\\theta_u\\theta_jP(R_{u,j} = 1)^{\\alpha}$).\nThe optimization objective of $\\mathcal{L}_{ideal}^{point}$ is to increase $s_{u,i}^{ideal}$ when $R_{u,i} = 1$ and decrease $s_{u,i}^{ideal}$ when $R_{u,i} = 0$. We use $\\Delta x$ to denote the change in $x$ after one optimization step (e.g., gradient descent). Therefore,\n$\\Delta s_{u,i}^{ideal} = \\Delta P(R_{u,i} = 1) > 0 \\quad \\text{ if } R_{u,i} = 1, \\\\$ (8)\n$- \\Delta s_{u,i}^{ideal} = - \\Delta P(R_{u,i} = 1) > 0 \\quad \\text{ if } R_{u,i} = 0,$ \nwhich can also be written as:\n$\\Delta \\ln P(R_{u,i} = 1) > 0 \\quad \\text{ if } R_{u,i} = 1, \\\\$ (9)\n$- \\Delta \\ln P(R_{u,i} = 1) > 0 \\quad \\text{ if } R_{u,i} = 0.$\nWhile for $\\mathcal{L}_{bias}^{point}$, its optimization objective is to increase $s_{u,i}^{bias}$ when $Y_{u,i} = 1$ and decrease $s_{u,i}^{bias}$ when $Y_{u,i} = 0$. Therefore,\n$\\Delta s_{u,i}^{bias} = \\Delta P(Y_{u,i} = 1) > 0 \\quad \\text{ if } Y_{u,i} = 1, \\\\$ (10)\n$- \\Delta s_{u,i}^{bias} = - \\Delta P(Y_{u,i} = 1) > 0 \\quad \\text{ if } Y_{u,i} = 0,$ \nwhich can also be written as:\n$\\Delta \\ln P(Y_{u,i} = 1) = \\Delta \\ln \\theta_u + \\Delta \\ln \\theta_i + (\\alpha + 1)\\Delta \\ln P(R_{u,i} = 1) > 0 \\quad \\text{ if } Y_{u,i} = 1, \\\\$ (11)\n$- \\Delta \\ln P(Y_{u,i} = 1) = -\\Delta \\ln \\theta_u - \\Delta \\ln \\theta_i - (\\alpha + 1)\\Delta \\ln P(R_{u,i} = 1) > 0 \\quad \\text{ if } Y_{u,i} = 0.$\nThe optimization objective of $\\mathcal{L}_{ideal}^{pair}$ is to increase the margin between $s_{u,i}^{ideal}$ and $s_{u,j}^{ideal}$. Therefore,\n$\\Delta (\\ln P(R_{u,i} = 1) - \\ln P(R_{u,j} = 1)) = \\Delta \\ln \\frac{P(R_{u,i} = 1)}{P(R_{u,j} = 1)} > 0$. (12)\nWhile for $\\mathcal{L}_{bias}^{pair}$, its optimization objective is to increase the margin between $s_{u,i}^{bias}$ and $s_{u,j}^{bias}$. Therefore,\n$\\Delta (\\ln P(Y_{u,i} = 1) - \\ln P(Y_{u,j} = 1)) = \\Delta \\ln \\frac{P(Y_{u,i} = 1)}{P(Y_{u,j} = 1)} > 0$.\n$\\\\= \\Delta \\ln \\frac{P(R_{u,i} = 1)}{P(R_{u,j} = 1)} + (\\alpha + 1) \\Delta \\ln \\frac{\\theta_i}{\\theta_j} > 0$. (13)\nBy comparing Equation (9) with (11), and Equation (12) with (13), it can be observed that $\\mathcal{L}_{bias}^{point}$ and $\\mathcal{L}_{bias}^{pair}$ improperly optimize the propensity factors ($\\theta_u$ and $\\theta_i$ for $\\mathcal{L}_{bias}^{point}$, and $\\theta_i$ and $\\theta_j$ for $\\mathcal{L}_{bias}^{pair}$). Since popular items and active users are more frequently selected to form positive pairs during training, their propensity factors tend to be higher. Ultimately, propensity factors related to exposure probability $P(O_{u,i} = 1|R_{u,i} = 1)$, rather than relevance probability $P(R_{u,i} = 1)$, lead to higher interaction scores $P(Y_{u,i} = 1)$, which is not the intended outcome."}, {"title": "Fair Sampling", "content": "Fair sampling (FS) constructs supplementary sample(s) for each original sample in the classic loss during model training, helping to prevent the improper optimization of propensity factors and thereby mitigating popularity bias. Depending on the type of loss function, FS has two variants: FS-Point, designed for point-wise loss, and FS-Pair, designed for pair-wise loss.\nThe sample set utilized by the classic point-wise loss function $\\mathcal{L}_{bias}^{point}$ is:\n$D^{point} = \\{(u, i; Y_{u,i}) | u \\in U, i \\in I\\}$. (14)\nFor each $(u, i; Y_{u,i}) \\in D^{point}$, we can find a corresponding $(\\tilde{u}, \\tilde{i})$ that satisfies the conditions $Y_{\\tilde{u}, \\tilde{i}} = Y_{u,i}$, $Y_{\\tilde{u}, i} = 1 - Y_{u,i}$, and $Y_{u, \\tilde{i}} = 1 - Y_{u,i}$. Then, we can obtain the sample set for FS-Point loss by combining them together:\n$D^{point}_{FS} = D^{point} \\cup \\{(\\tilde{u}, i; Y_{\\tilde{u}, i}), (u, \\tilde{i}; Y_{u, \\tilde{i}}), (\\tilde{u}, \\tilde{i}; Y_{\\tilde{u}, \\tilde{i}})| (u, i; Y_{u,i}) \\in D^{point}\\}$. (15)\nFinally, FS-Point loss is defined as:\n$\\mathcal{L}_{FS}^{point} = \\sum_{(u,i; Y_{u,i}) \\in D^{point}_{FS}} [Y_{u,i} \\cdot \\delta^{+}(u, i) + (1 - Y_{u,i}) \\cdot \\delta^{-}(u, i)]$. (16)\nWe assume $Y_{u,i} = 1$ (a similar conclusion can be drawn when $Y_{u,i} = 0$). Based on Equation (11), when $(u, i; Y_{u,i} = 1)$ is input into $\\mathcal{L}_{FS}^{point}$ for optimization, $\\ln \\theta_u$ and $\\ln \\theta_i$ are amplified. However, when the corresponding supplementary samples-(\\tilde{u}, i; Y_{\\tilde{u}, i} = 1), (u, \\tilde{i}; Y_{u, \\tilde{i}} = 0), and (\\tilde{u}, \\tilde{i}; Y_{\\tilde{u}, \\tilde{i}} = 0)-are input into $\\mathcal{L}_{FS}^{point}$ for optimization, the optimization effect on the propensity factors is offset:\n$(\\Delta \\ln \\theta_u + \\Delta \\ln \\theta_i) + (\\Delta \\ln \\theta_{\\tilde{u}} + \\Delta \\ln \\theta_{\\tilde{i}})+\n\\\\(-\\Delta \\ln \\theta_{\\tilde{u}} - \\Delta \\ln \\theta_i) + (-\\Delta \\ln \\theta_u - \\Delta \\ln \\theta_{\\tilde{i}}) = 0$. (17)\nThe sample set utilized by the classic pair-wise loss function $\\mathcal{L}_{bias}^{pair}$ is:\n$D^{pair}_{bias} = \\{(u, i, j; Y_{u,i}, Y_{u,j}) | u \\in U, i, j \\in I\\}$. (18)\nFor each $(u, i, j; Y_{u,i}, Y_{u,j}) \\in D^{pair}_{bias}$, we can find a corresponding (\\tilde{u}, j, i) that satisfies the conditions $Y_{\\tilde{u}, j} = Y_{u,i}$ and $Y_{\\tilde{u}, i} = Y_{u,j}$. Then, we can obtain the sample set for FS-Pair loss by combining them together:\n$D^{pair}_{FS} = D^{pair}_{bias} \\cup \\{(\\tilde{u}, j, i; Y_{\\tilde{u}, j}, Y_{\\tilde{u}, i}) | (u, i, j) \\in D^{pair}_{bias}\\}$ (19)\nFinally, FS-Pair loss is defined as:\n$\\mathcal{L}^{pair}_{FS} = \\sum_{(u,i,j; Y_{u,i}, Y_{u,j}) \\in D^{pair}_{FS}} [Y_{u,i} \\cdot (1 - Y_{u,j}) \\cdot \\zeta (u, i, j)]$. (20)\nSince a sample contributes to the loss only when $Y_{u,i} = 1$ and $Y_{u,j} = 0$, we focus on this case. Based on Equation (13), when $(u, i, j; Y_{u,i} = 1, Y_{u,j} = 0)$ is input into $\\mathcal{L}^{pair}_{FS}$ for optimization, $\\ln \\frac{\\theta_i}{\\theta_j}$ is amplified. However, when the corresponding supplementary sample (\\tilde{u}, j, i; Y_{\\tilde{u}, j} = 1, Y_{\\tilde{u}, i} = 0) is input into $\\mathcal{L}^{pair}_{FS}$ for optimization, $\\ln \\frac{\\theta_j}{\\theta_i}$ is amplified, which offsets the optimization effect on the propensity factors:\n$\\Delta (\\ln \\frac{\\theta_i}{\\theta_j}) + \\Delta (\\ln \\frac{\\theta_{\\tilde{j}}}{\\theta_{\\tilde{i}}}) = \\Delta (\\ln \\frac{\\theta_i}{\\theta_j} + \\ln \\frac{\\theta_j}{\\theta_i}) = 0$. (21)\nThe idea of FS is simple-whenever a user or item is chosen to form a positive/negative pair, the user or item is simultaneously selected to form a corresponding negative/positive pair. Equations (17) and (21) indicate that FS-Point loss and FS-Pair loss no longer optimize propensity factors. Consequently, only the preference-related factor $P(R_{u,i} = 1)$ is optimized, effectively mitigating the popularity bias. Note that FS does not require estimating the propensity score, which avoids the incomplete removal of popularity bias in IPS-based methods, which stems from their inability to estimate the propensity score accurately."}, {"title": "Experiments", "content": "We experiment with three widely used datasets: Amazon Review (Kindle) [21], Gowalla [5], and Yelp. These datasets contain log data capturing observed user behavior. Under the two-step interaction assumption, these datasets exhibit popularity bias. We retain only interactions with ratings \u2265 4 and ensure that both users and items have at least 10 interactions. \nFollowing prior offline evaluation protocols [2, 12, 28], we construct unbiased validation and test sets by sampling from the full dataset with equal selection probability for each item. The remaining data serves as the training set. The dataset is split into training, validation, and test sets in a 7:1:2 ratio.\nWe evaluate performance using three metrics: Recall@K, NDCG@K, and ARP@K, with K set to 20 by default. Recall@K and NDCG@K are widely used to assess recommendation accuracy. Average Recommendation Popularity at K (ARP@K) serves as a complementary metric for measuring recommendation bias [1, 31]. It calculates the average popularity of the top-K recommended items per user, where lower ARP@K values indicate reduced bias. To ensure result reliability, we report the average outcomes over five independent runs.\nAll methods introduced in Section 2 serve as baselines. Additionally, we incorporate several causal inference methods that quantify popularity bias during training and mitigate it during inference. Specifically, these methods consist of three point-wise approaches-ExpoMF [13], CauseE [2], and MACR [27]-and three pair-wise approaches-PD [32], DICE [33], and CGCL [7]. To ensure fairness, all methods use MF [9] as the backbone model and share the same hyperparameter search space. All point-wise methods use cross-entropy loss, while all pair-wise methods use BPR loss."}, {"title": "Results", "content": "As shown in Table 2, FS-Point achieves the highest Recall and NDCG, and the lowest APR among point-wise learning methods. Similarly, FS-Pair achieves the best performance in these metrics among pair-wise methods. This suggests that, compared to other baselines, FS more effectively mitigates the influence of popularity bias, increasing the likelihood of recommending unpopular items without sacrificing recommendation accuracy. Notably, despite its simplicity, theoretical analysis confirms that FS completely eliminates popularity bias, enabling optimal performance under the current evaluation strategy, where the test set is designed to be unaffected by item popularity."}, {"title": "Conclusions", "content": "We propose a fair sampling (FS) method, which mitigates popularity bias in collaborative filtering by ensuring that each item appears equally as both a positive and negative sample during training. Both theoretical analysis and experimental results demonstrate the effectiveness of the proposed FS method. A potential limitation of FS is that it completely overlooks the influence of popularity, even though popularity is often correlated with higher quality. Strategically adjusting the sampling ratio between popular and non-popular items may help balance recommendation diversity and quality. Applying the concept of fair sampling at the attribute level is a promising avenue for future research."}]}