{"title": "Dynamic Adaptive Optimization for Effective Sentiment Analysis Fine-Tuning on Large Language Models", "authors": ["Hongcheng Ding", "Xuanze Zhao", "Shamsul Nahar Abdullah", "Deshinta Arrova Dewi", "Zixiao Jiang"], "abstract": "Sentiment analysis plays a crucial role in various domains, such as business intelligence and financial forecasting. Large language models (LLMs) have become a popular paradigm for sentiment analysis, leveraging multi-task learning to address specific tasks concurrently. However, LLMs with fine-tuning for sentiment analysis often underperforms due to the inherent challenges in managing diverse task complexities. Moreover, constant-weight approaches in multi-task learning struggle to adapt to variations in data characteristics, further complicating model effectiveness. To address these issues, we propose a novel multi-task learning framework with a dynamic adaptive optimization (DAO) module. This module is designed as a plug-and-play component that can be seamlessly integrated into existing models, providing an effective and flexible solution for multi-task learning. The key component of the DAO module is dynamic adaptive loss, which dynamically adjusts the weights assigned to different tasks based on their relative importance and data characteristics during training. Sentiment analyses on a standard and customized financial text dataset demonstrate that the proposed framework achieves superior performance. Specifically, this work improves the Mean Squared Error (MSE) and Accuracy (ACC) by 15.58% and 1.24% respectively, compared with previous work.", "sections": [{"title": "Introduction", "content": "Sentiment analysis has become an essential tool for businesses to understand and analyze customer opinions and feedback, gauging public perception of their products, services, and brand reputation (Liu 2020; Alaei, Becken, and Stantic 2019). It is also used in demand forecasting by analyzing online product reviews (Kharfan, Chan, and Firdolas Efendigil 2021; Li, Lin, and Xiao 2022) and in supply chain management to monitor supplier performance and identify potential risks (Sharma, Adhikary, and Borah 2020). In the financial sector, sentiment analysis is crucial for forecasting stock market trends (Bai et al. 2023), predicting cryptocurrency prices (Chowdhury et al. 2020), and forecasting exchange rates (Ding et al. 2024a).\nTraditionally, sentiment analysis employs various approaches, primarily including machine learning algorithms (e.g., SVM and Naive Bayes (Dang, Moreno-Garc\u00eda, and De la Prieta 2020)) and deep learning methods (e.g., CNN"}, {"title": "Method", "content": "In this section, we will introduce traditional sentiment analysis, our framework incorporating the DAO module with LORA."}, {"title": "Traditional Sentiment Analysis", "content": "Backbone: RoBERTa-Large. In sentiment analysis, LLMs serve as text data embedding generators, concatenating various task-specific heads for various sentiment analysis tasks. This work employs RoBERTa-Large as the embedding generator for text data, as illustrated in Figure 3 (A). The training set is defined as $\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^{N}$, where $N$ denotes the total number of texts, $x_i$ represents each text in the dataset, and $y_i \\in [-1,1]$ corresponds to the annotated sentiment polarity score.\nThe pre-trained RoBERTa tokenizer Tokenizer(.) processes each text $x_i$ in the dataset, and then the tokenized text passes through 24 Transformer encoder blocks Encoder(.) to generate the final hidden state $H_i$:\n$H_i = Encoder(Tokenizer(x_i))$, (1)\nwhere $H_i \\in \\mathbb{R}^{1\\times1024}$. This hidden state serves as input to task-specific heads. For sentiment polarity analysis, we implement a regression head (Figure 3 (B)) comprising two linear layers and a sigmoid activation function:\n$S_i = LL_2(\\sigma(LL_1(H_i)))$, (2)\nwhere $LL_1: \\mathbb{R}^{1024} \\rightarrow \\mathbb{R}^{128}$ is the first linear layer, $\\sigma(\\cdot)$ denotes the sigmoid function, and $LL_2: \\mathbb{R}^{128} \\rightarrow \\mathbb{R}$ produces the final sentiment polarity score $S_i \\in [-1,1]$.\nFor the regression task, we use Mean Squared Error (MSE) as the loss function, denoted as $L_r$:\n$L_r = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$, (3)\nwhere $n$ denotes the number of texts texts in the training set, $\\hat{y}_r$ represents the predicted polarity score, and $y_i$ is the ground truth sentiment polarity score.\nStandard Learning. In sentiment analysis, particularly in data-limited scenarios, enhancing model performance is crucial. We introduce a multi-task learning approach. Specifically, we incorporate a classification task alongside the regression task to better capture the sentiment tendencies embedded in the text. This approach mitigates the impact of"}, {"title": "Dynamic Adaptive Optimization", "content": "In the context of multi-task learning with LLMs, two primary challenges arise: Task-level challenge: inter-task difficulty discrepancy. The loss functions associated with regression and classification tasks may exhibit significant disparities in their magnitudes. Consequently, this discrepancy can lead to the dominance of one task over others during the training process, potentially hindering the model's ability to effectively learn and generalize across all tasks. Data-level challenge: imbalanced data distribution. Within each training batch, the sample distribution can exhibit considerable variability, and the class distribution may be inherently imbalanced. As a result, the model may be susceptible to overfitting or underfitting for certain classes, compromising its overall performance and generalization capability.\nTo address these challenges, we propose a DAO module as shown in Figure 4 (A), which is a learnable neural network integrated into the multi-task learning framework.\nSolution #1: Inter-task Difficulty Discrepancy. Due to the different magnitudes of the loss functions for regression and classification tasks, directly summing them may cause one task to dominate the entire training process. To balance the contributions of different tasks, we introduce a gradient-based weighting method. Specifically, we define the total multi-task loss function $L_{mtl}$ as follows:\n$L_{mtl} = \\lambda_r^t \\hat{w}_r L_r^t +  \\lambda_c^t \\hat{w}_c L_c^t $, (9)\nwhere $L_r^t$ and $L_c^t$ represent the losses of the regression and classification tasks at step $t$, respectively, $\\hat{w}_r^t$ and $\\hat{w}_c^t$ are the task-specific weights, and $\\lambda_r^t$ and $\\lambda_c^t$ are the gradient-based weighting coefficients.\nAt each training step, we compute the gradients of the regression and classification task losses:\n$g_r^t = \\nabla L_r^t , g_c^t = \\nabla L_c^t$. (10)\nThen, we use the $L_2$ norms of these gradients to compute the gradient-based weighting coefficients:\n$\\lambda_r^t = \\frac{||g_r^t||}{||g_r^t|| + ||g_c^t||}, \\lambda_c^t = \\frac{||g_c^t||}{||g_r^t|| + ||g_c^t||}$. (11)\nThese gradient-based weighting coefficients are used to balance the learning progress of different tasks and scale them to similar magnitudes in the total multi-task loss function $L_{mtl}$.\nSolution #2: Imbalanced Data Distribution. We introduce a regularization term and class-specific weights into the classification loss function. The regularization term $-\\alpha \\log p_{c,k}^t$ encourages the model to pay more attention to minority classes with smaller sample proportions, while the class-specific weights $\\upsilon_{c,k}^t$ are inversely proportional to the sample proportions $p_k^t$:\n$\\upsilon_{c,k}^t = \\frac{1}{(p_k^t)^{\\beta}}$, (12)\nwhere $\\beta$ is a parameter that controls the degree of class balancing.\nWe use $\\mathcal{D}$ to denote the entire dataset and $\\mathcal{D}^t$ to represent the batch of data sampled at time step $t$. For each batch $\\mathcal{D}^t$, we calculate the proportion of samples $p_k^t$ belonging to class $k$ as:\n$p_k^t = \\frac{|\\mathcal{D}_k^t|}{|\\mathcal{D}^t|}$, (13)\nwhere $|\\mathcal{D}_k^t|$ and $|\\mathcal{D}^t|$ denote the number of samples in batch $\\mathcal{D}^t$ belonging to class $k$ and the total number of samples in batch $\\mathcal{D}^t$, respectively.\nTo incorporate the regularization term $-\\alpha \\log p_{c,k}^t$ and the class-specific weights $\\upsilon_{c,k}^t$ into the classification loss function, we define the imbalanced data distribution loss $L_{imb}^t$ conditioned on $\\mathcal{D}^t$ as:\n$L_{imb}^t(\\mathcal{D}^t) = \\sum_{k=1}^{B} \\upsilon_{c,k}^t (p_{Lk}^t - \\alpha \\log p_{c,k}^t)$. (14)\nThis loss captures the sample distribution and class proportions specific to the current batch, allowing the model to dynamically adapt to the characteristics of each batch during training. We then incorporate the imbalanced data distribution loss $L_{imb}^t(\\mathcal{D}^t)$ into the total multi-task loss function $L_{mtl}$ from Challenge 1, along with the task-specific weights $\\hat{w}_r^t$ and $\\hat{w}_c^t$:\n$L_{mtl}(\\mathcal{D}^t) = \\lambda_r^t \\hat{w}_r^t L_r^t + \\lambda_c^t \\hat{w}_c^t L_c^t +  \\lambda_c^t \\hat{w}_c^t L_{imb}^t(\\mathcal{D}^t)$\n$= \\lambda_r^t \\hat{w}_r^t L_r^t + \\lambda_c^t \\hat{w}_c^t L_c^t +  \\sum_{k=1}^{B} \\upsilon_{c,k}^t (p_{Lk}^t - \\alpha \\log p_{c,k}^t)$, (15)\nwhere $\\lambda_r^t$ and $\\lambda_c^t$ are the gradient-based weighting coefficients, $\\upsilon_{c,k}^t$ are the class-specific weights, and $L_k$ is the classification loss for class $k$ at time step $t$. The total multi-task loss $L_{mtl}$ is now conditioned on the current batch $\\mathcal{D}^t$, allowing the model to adapt to the specific characteristics of each batch during training.\nTo learn the hyperparameters $\\alpha$ and $\\beta$, we treat them as learnable parameters of the DAO Module and update them using gradient descent along with the other parameters of the module. During the backward pass, the gradients of the DAO Module loss $L_{mtl}(\\mathcal{D}^t)$ with respect to $\\alpha$ and $\\beta$ are computed as follows:\n$\\frac{\\partial L_{mtl}^t(\\mathcal{D}^t)}{\\partial \\alpha} = -\\sum_{k=1}^{B} \\upsilon_{c,k}^t \\log p_{c,k}^t$. (16)\nTo compute the gradient with respect to $\\beta$, we apply the chain rule and substitute the expression for $\\frac{\\partial \\upsilon_{c,k}^t}{\\partial \\beta}$:\n$\\frac{\\partial L_{mtl}(\\mathcal{D}^t)}{\\partial \\beta} = \\sum_{k=1}^{B} \\frac{\\partial \\upsilon_{c,k}^t}{\\partial \\beta} (p_{Lk}^t - \\alpha \\log p_{c,k}^t)$\n$= - \\sum_{k=1}^{B} \\upsilon_{c,k}^t \\log p_{c,k}^t (p_{Lk}^t - \\alpha \\log p_{c,k}^t)$. (17)\nThe hyperparameters $\\alpha$ and $\\beta$ are then updated using an optimizer such as Adam or AdamW.\nTo obtain the task-specific weights $\\hat{w}_r^t$ and $\\hat{w}_c^t$, we pass the gradient-weighted regression loss $\\lambda_r^t L_r^t$, the gradient-weighted imbalanced data distribution loss $L_{imb}^t(\\mathcal{D}^t)$, and the current batch $\\mathcal{D}^t$ through the DAO Module:\n$\\hat{w}_r^t, \\hat{w}_c^t = DAO(\\lambda_r^t L_r^t, L_{imb}^t(\\mathcal{D}^t), \\mathcal{D}^t)$ (18)"}, {"title": "LORA", "content": "We implement LoRA (Hu et al. 2021) for parameter-efficient fine-tuning (PEFT) of the pre-trained ROBERTa-large model. LoRA injects trainable low-rank decomposition matrices into each layer, reducing parameters while maintaining performance.\nLORA introduces rank-r matrices $U \\in \\mathbb{R}^{d\\times r}$ and $V \\in \\mathbb{R}^{r\\times d}$ into each attention block and feed-forward network, as shown in Figure 4 (B). The figure illustrates how LORA is integrated into the Transformer encoder, with pretrained weights $W$ remaining frozen while low-rank matrices are trained. The adjusted weight matrix $W'$ during forward propagation is:\n$f(x) = (W + UV) \\cdot X + b$, (22)\nwhere $b$ is the bias, and $X$ is the input as illustrated in Figure 4 (B). Only $U$ and $V$ are updated during training, significantly reducing trainable parameters and potentially accelerating training.\nIn traditional multi-task learning with constant weight, this approach can lead to suboptimal performance. Our proposed framework incorporates the DAO module that dynamically adjusts task weights based on their relative importance, gradients, and data characteristics during training. This batch-level dynamic adaptive loss addresses the limitations of constant-weight approaches by considering the"}, {"title": "Evaluation", "content": "Software and Hardware\nWe use Ubuntu 22.04, Python 3.9.19, PyTorch 2.3.1, PEFT 0.12.0, and CUDA 12.4, running on a system with 32GB RAM and an NVIDIA RTX 3090 Ti GPU with 24GB VRAM.\nSetup and Dataset\nBenchmark. We use diffrent benchmarks to verify our framework. We establish three benchmark: ROBERTa-Large (Liu et al. 2019) for regression, Twitter-RoBERTa-Large (Loureiro et al. 2023) for regression, and Twitter-RoBERTa-Large with constant-weight multi-task learning for regression and classification. Additionally, we propose two methods: Twitter-RoBERTa-Large with DAO for multi-task learning, and the multi-task learning framework using Twitter-ROBERTa-Large with DAO and LoRA.\nEvaluation Metrics. For the regression task, we utilize MSE, Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and the Coefficient of Determination (R2). For the classification task, we use ACC, weighted Precision, and weighted F1 score.\nDataset. We use a standard and customized financial text dataset that comprises 23,242 preprocessed news and analysis texts on EUR/USD exchange rates (Ding et al. 2024a). This dataset is randomly split into training and validation sets with a 9:1 ratio, and all experiments utilize these two identical datasets. Further information and supplementary details can be found in the Appendix."}, {"title": "Main Results", "content": "In this section, we will first introduce the hyperparameters and then analyze the experimental results.\nModel Hyperparameters. The training texts exceeding 512 tokens are truncated to the first 512 tokens. The model is trained with a batch size of 10 for 100 epochs, using the AdamW optimizer with a learning rate of 1e-5 and an epsilon value of 1e-8. The training process incorporates 1e2 warmup steps and implements cosine decay for learning rate scheduling. To ensure the reproducibility of the experiments, we set constant random seeds for Python (42), NumPy (42), and PyTorch (42) across all runs.\nDAO Module Hyperparameters. The optimizer is Adam with a learning rate of 0.001.\nLORA Parameters. Different LoRA configurations are applied in the experiments, with the rank values set to 8, 16, 32, 64, 128, 256, 384, and 512. Correspondingly, the scaling factor (alpha) for the LoRA matrices is set to one times the rank. The dropout rate for all LoRA configurations is constant at 0.05 to prevent overfitting."}, {"title": "Related Work", "content": "LLMS NLP advancements lead to the widespread application of LLMs in sentiment analysis tasks. ChatGPT shows significant potential in automating student feedback analysis, outperforming traditional deep learning models (Shaikh et al. 2023). Pre-trained models like BERT achieve state-of-the-arts results by learning contextual word representations (Liao et al. 2021). In Arabic sentiment analysis, transformer-based models like RoBERTa and XLNet push boundaries despite language complexities (Alduailej and Alothaim 2022). Krugmann and Hartmann (2024) reveals that GPT-3.5, GPT-4, and Llama 2 can compete with and sometimes surpass traditional transfer learning methods in sentiment analysis. Carneros-Prado et al. (2023) highlights the versatility of pre-trained LLMs like GPT-3.5 in diverse NLP applications, including emotion recognition. However, fully fine-tuning these LLMs for specific tasks remains computationally expensive and time-consuming, posing challenges for both academia and industry.\nPEFT To address computational challenges, researchers introduce PEFT methods for LLMs. Hu et al. (2023) presents LLM-Adapters, integrating adapters into LLMs and achieving comparable performance to powerful 175B parameter models using only 7B parameters in zero-shot tasks. Lei et al. (2023) introduces Conditional Adapters (CODA), which adds sparse activation and new parameters to pre-trained models for efficient knowledge transfer, significantly speeding up inference. Hu et al. (2021) proposes LoRA, which injects trainable low-rank decomposition matrices into each Transformer layer, reducing parameters while maintaining performance on par with full fine-tuning."}, {"title": "Conclusion", "content": "In this work, we propose a multi-task learning framework with a DAO module for LLM-based sentiment analysis. The DAO module dynamically adjusts task weights based on their relative importance and data characteristics, addressing inter-task difficulty and data imbalance issues. This plug-and-play module can be seamlessly integrated into existing models, enhancing their adaptability to diverse tasks and datasets. Combined with LoRA for efficient fine-tuning, our approach achieves state-of-the-art performance in financial sentiment analysis, significantly improving MSE and accuracy over previous methods.\nIn the future work, we will explore the use of data-aware classification tasks to enhance the performance of multi-task learning with DAO module under data-limited scenarios."}, {"title": "Appendix", "content": "Dataset\nIn this work, the text dataset comes from another study (Ding et al. 2024a). Specifically, the dataset is collected from investing.com and forexempire.com, focusing on the EUR/USD exchange rate. The dataset spans from February 6, 2016, to January 19, 2024, encompassing all accessible data on these platforms, resulting in a total of 35,427 records. To address the presence of noise and information irrelevant to the target exchange rate, we use ChatGPT-4.0 and prompt engineering techniques to filter the raw dataset. Further analysis reveals that typically only individual paragraphs or multiple sentences within articles directly relate to the EUR/USD exchange rate, likely catering to readers' diverse interests. To extract the most relevant parts and refine the dataset, we process the text data using ChatGPT-4.0, yielding a final text dataset comprising 23,242 records.\nSentiment polarity annotation in exchange rate texts is particularly complex because such texts are often filled with professional terminology, implied emotions related to market conditions, and subtle variations across industries. Moreover, as exchange rate issues involve two countries, significant positive or negative news about one country can have"}, {"title": "Evaluation Metrics", "content": "For the sentiment score regression task, where the model predicts a continuous sentiment polarity score, we employ the following metrics:\n\u2022 Mean Squared Error (MSE) calculates the average squared differences between the predicted sentiment polarity scores (yi) and the annotated sentiment polarity scores (yi) in the test set. MSE provides a measure of the model's accuracy in predicting the exact sentiment scores. It is defined as:\n$MSE = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\nwhere n is the number of texts in the test set.\n\u2022 Mean Absolute Error (MAE) measures the average magnitude of the absolute errors between the predicted and annotated sentiment polarity scores, ignoring their direction. MAE helps in understanding the average error magnitude and is less sensitive to outliers compared to MSE. It is formulated as:\n$MAE = \\frac{1}{n}\\sum_{i=1}^{n} |y_i - \\hat{y}_i|$\n\u2022 Root Mean Squared Error (RMSE) is the square root of MSE and provides the error magnitude in the same units as the sentiment polarity scores. RMSE is more interpretable than MSE and is calculated as:\n$RMSE = \\sqrt{MSE}$\n\u2022 R-squared ($R^2$) indicates the proportion of variance in the sentiment polarity scores that can be explained by the model's predictions. It provides a measure of how well"}, {"title": "Accuracy", "content": "For the sentiment classification task, where texts are categorized into five sentiment classes (e.g., strong positive, positive, neutral, negative, strong negative), we calculate the following metrics:\n\u2022 Accuracy (ACC): the ratio of correctly predicted sentiment classes to the total number of predictions. It measures the overall correctness of the model's classifications and is defined as:\n$ACC = \\frac{\\sum_{i=1}^{5}TP_i}{\\sum_{i=1}^{5}(TP_i + FN_i)}$\nwhere $TP_i$ is the number of instances correctly predicted as class i, and $FN_i$ is the number of instances that actually belong to class i but are wrongly predicted as other classes.\n\u2022 Precision: the ratio of correctly predicted positive instances to all instances predicted as positive. It measures the model's ability to avoid false positives and is calculated as:\n$Precision = \\frac{TP_{pos}}{TP_{pos} + FP_{pos}}$\nwhere $TP_{pos}$ is the number of positive instances correctly predicted as positive, and $FP_{pos}$ is the number of non-positive instances wrongly predicted as positive.\n\u2022 Recall (or Sensitivity): the ratio of correctly predicted positive instances to all actual positive instances. It measures the model's ability to identify all positive instances and is calculated as:\n$Recall = \\frac{TP_{pos}}{TP_{pos} + FN_{pos}}$\nwhere $FN_{pos}$ is the number of positive instances wrongly predicted as non-positive.\n\u2022 F1 Score: the harmonic mean of Precision and Recall, providing a balanced measure of the model's performance, especially when the sentiment classes are imbalanced. It is calculated as:\n$F1 = 2 \u00d7 \\frac{Precision \u00d7 Recall}{Precision + Recall}$\nProof of Equivalence Between Weighted Recall and Accuracy in Multi-Class Classification\nIn a multi-class classification problem with n classes, let $TP_i$, $FN_i$, and $Support_i$ denote the true positives, false negatives, and total instances (support) for class i, respectively. The recall for class i is given by:\n$Recall_i = \\frac{TP_i}{TP_i + FN_i} = \\frac{TP_i}{Support_i}$"}, {"title": "The weighted recall", "content": "The weighted recall is then calculated as:\n$Weighted\\ Recall = \\frac{\\sum_{i=1}^{n} Recall_i \u00d7 Support_i}{\\sum_{i=1}^{n} Support_i}$\nSubstituting the expression for Recall:\n$Weighted\\ Recall = \\frac{\\sum_{i=1}^{n} \\frac{TP_i}{Support_i} \u00d7 Support_i}{\\sum_{i=1}^{n} Support_i}$\nThe Support; terms in the numerator and denominator cancel out, leaving:\n$Weighted\\ Recall = \\frac{\\sum_{i=1}^{n} TP_i}{\\sum_{i=1}^{n} Support_i}$\nThis is exactly the formula for overall accuracy:\n$Accuracy = \\frac{TP_1+TP_2+...+TP_n}{Support_1 + Support_2 + ... + Support_n}$\nTherefore, in a multi-class classification setting, weighted recall is mathematically equivalent to accuracy."}]}