{"title": "EverAdapt: Continuous Adaptation for Dynamic Machine Fault Diagnosis Environments", "authors": ["Edward", "Mohamed Ragab", "Min Wu", "Yuecong Xu", "Zhenghua Chen", "Abdulla Alseiari", "Xiaoli Li"], "abstract": "Unsupervised Domain Adaptation (UDA) has emerged as a key solution in data-driven fault diagnosis, addressing domain shift where models underperform in changing environments. However, under the realm of continually changing environments, UDA tends to underperform on previously seen domains when adapting to new ones a problem known as catastrophic forgetting. To address this limitation, we introduce the EverAdapt framework, specifically designed for continuous model adaptation in dynamic environments. Central to EverAdapt is a novel Continual Batch Normalization (CBN), which leverages source domain statistics as a reference point to standardize feature representations across domains. EverAdapt not only retains statistical information from previous domains but also adapts effectively to new scenarios. Complementing CBN, we design a class-conditional domain alignment module for effective integration of target domains, and a Sample-efficient Replay strategy to reinforce memory retention. Experiments on real-world datasets demonstrate EverAdapt superiority in maintaining robust fault diagnosis in dynamic environments. Our code is available here: EverAdapt-Code.", "sections": [{"title": "I. INTRODUCTION", "content": "In machine fault diagnosis, a critical challenge is the distribution shift problem, where the models' performances decline due to differences in training (source domain) and testing (target domain) data distributions [1], [2]. Unsupervised domain adaptation (UDA) emerges as a promising solution for addressing distribution shift challenges in fault diagnosis. It leverages labeled data from a source domain, such as publicly available or simulated data, and unlabeled data from a target domain with a related but different distribution [3]-[5].\nUDA's primary challenge in dynamic environments is its traditional focus on adapting to a single target domain. This limitation becomes especially apparent in scenarios where a model sequentially encounters multiple domains. In predictive maintenance, it is crucial for a fault diagnosis model, initially trained under specific pressure and temperature conditions of a particular machine, to be adaptable to varying working environments over time. While UDA enables the model to adjust to the most recent domain, this often results in the loss of proficiency in previously learned domains, a phenomenon known as catastrophic forgetting [6]. A naive solution to this problem would be to train a new model for each set of conditions, but this approach is impractical and resource-intensive for continuous operation, as illustrated in Figure 1. Therefore, there is a need for a model must continually adapt to new domains without losing its ability to perform in earlier ones [6].\nRecently, continual unsupervised domain adaptation methods have gained traction by allowing models to adapt to new domains without forgetting previous ones [7]\u2013[9]. However, the majority of existing methods are designed for computer vision applications, which may fail to perform well on time series data in machine fault diagnosis applications. Further, we argue that batch normalization (BN) can be detrimental to knowledge retention when adapting to new domains in fault diagnosis applications. Specifically, BN adjusts the model to the current domain's statistics, overlooking those from previous domains. This causes the model to specialize in the latest domain, impairing its performance on previously seen domains. To address this issue, the \u201cEverAdapt framework is designed for continual model adaptation across diverse domains while addressing the catastrophic forgetting problem. The framework features a class-conditional domain alignment (CCA) module for integrating new domains, aligning them with the source domain at the class-wise level. This ensures effective domain adaptation by addressing class misalignment, crucial for consistent performance across different conditions. To address the catastrophic forgetting problem, we develop a novel Continual Batch Normalization (CBN), which standard-izes the batch statistics across different domains using fixed statistics from the source domain. This process ensures consistent feature representation, significantly reducing the risk of forgetting when adapting to new domains. However, resetting target domains to source statistics in CBN can lead to training instability due to domain distribution shifts. To counter this, we reduce the uncertainty of the learned features by minimizing their conditional entropy. This approach helps mitigate the instability caused by the adaptation of batch statistics from various domains to the source statistics. Beyond adapting batch statistics across domains, our approach augments CBN with simple self-training using replay samples to align fine-grained classes between domains. Notably, integrating CBN significantly cuts down the number of replay samples required for effective self-training.\nIn summary, EverAdapt presents a scalable and efficient framework adept at navigating the dynamic complexities of machine fault diagnosis. The primary contributions of this approach are summarized as follows:\n\u2022 Forgetting Prevention Module: Introducing a novel CBN technique via standardizing batch statistics across do-mains using fixed statistics from the source domain. This approach preserves consistent feature representation and substantially mitigates the risk of forgetting.\n\u2022 Flexible Everadapt Framework: Versatile adaptability of the Everadapt framework, accommodating a range of techniques for adaptation and replay, making it apt for various fault diagnosis scenarios.\n\u2022 Empirical Validation: Demonstrated superiority of the proposed approach through experiments on real-world datasets, showcasing significant improvements over state-of-the-art methods and substantial mitigation of the for-getting issue."}, {"title": "II. RELATED WORKS", "content": "In the field of machine fault diagnosis, domain adaptation has emerged as a vital solution for adapting models to diverse industrial environments. Early studies focused on aligning feature distributions using techniques like Maximum Mean Discrepancy (MMD) [10]. Adversarial networks were later introduced for improved distribution alignment [11]. Recent advancements include class-conditional alignment methods [12], which align not only feature distributions but also class-related information between domains. Some techniques leverage multiple source domains through weighting schemes [13]. While these approaches are effective in static environments with a single target domain, they encounter limitations when dealing with dynamic environments where models encounter multiple domains sequentially. Notably, as models adapt to new domains, they often suffer from the drawback of forgetting knowledge about previously encountered domains. This limitation underscores the need for novel methods to facilitate adaptation to sequential, dynamic domains while preserving knowledge from previous domains.\nContinual adaptation to new domains while retaining knowledge of previous domains is a crucial challenge in computer vision applications. Existing methods have primarily focused on mitigating catastrophic forgetting when adapting to new domains. Feature replay has proven instrumental in addressing this problem, either through subsamples from previous domains [7], [14] or synthetic data generated by generative models [8], [15]. Another approach involves parameter and weight regularization, achieved by either regularizing domain-specific features [16], domain-specific neurons [17], or domain-specific weights [18]. While these methods have been effective in vision applications, they may not be directly applicable to signal data in machine fault diagnosis. Moreover, these approaches often overlook the contribution of Batch Normalization (BN) to the forgetting problem in previously seen domains. In contrast, we introduce a novel approach tailored to machine fault diagnosis. We present a simple yet effective Continual Batch Normalization (CBN) technique that addresses BN limitations and significantly reduces forgetting on previously seen domains"}, {"title": "III. METHODOLOGY", "content": "In the context of continual domain adaptation, we consider a source dataset Ds = {x,y}1 consisting of labeled samples, where each sample includes a signal x's and a corresponding label y. Moreover, we are presented with a sequence of target domains, denoted as Dr = {D+,D},...,D}, each comprising unlabeled samples {x}771. The goal is to train a model fe capable of accurately predicting labels across multiple target domains {D,\u2026\u2026\u2026, D}, each characterized by a unique marginal distribution P(x), distinct from the source domain's distribution Ps(x). The conditional distributions P(yx) are assumed to be invariant across the source and target domains. The crux of the problem lies in training the model fe not only to adapt to the distinct characteristics of each target domain but also to maintain and leverage the knowledge acquired from previous domains without the benefit of labeled data."}, {"title": "D. Class-conditional Alignment (CCA)", "content": "One of the key tasks in continual domain adaptation is the alignment of data distributions across different domains. However, conventional alignment methods primarily focus on aligning feature distributions between the source and target domains. While effective to some extent, they often overlook the fine-grained class distribution within each domain. This oversight can lead to a misalignment of similar classes across domains, negatively impacting the model's adaptation performance. To address this challenge, we introduce our CCA module, which focuses on aligning class distributions between domains more granularly. Given the challenge of unlabeled target samples, our approach utilizes robust pseudo-labeling to classify target domain samples. Pseudo-labels are generated based on the highest probability class indicated by the model's predictions. The pseudo-label for a target sample xf is given by:\n$\\hat{y_r} = \\arg \\max \\sigma(h_\\theta(f_\\theta (z_i^T)))$,\nwhere \u0177r is the pseudo-label for the i-th target sample, and for represents the encoder model applied to current target domain time Dr. Once pseudo-labels are assigned, we align the class distributions by minimizing a class-level loss. This loss aims to reduce the discrepancy between the source and target distributions for each class. The class-level alignment loss Lloc can be expressed as:\n$L_{loc} = \\min_\\theta \\sum_{c=1}^C d(Z_s^c, Z_t^c)$,\nwhere C denotes the number of classes, Z& and Zf are the latent features for class c in the source and target domains, respectively. d(\u00b7, \u00b7) is a distance metric measuring the discrepancy between the two domains. Here, the Maximum Mean Discrepancy (MMD) is employed as the distance between similar classes across domains, which defined as:\n$d(Z_s^c, Z_t^c) = ||E_{Z_s}[\\zeta(Z_s)] - E_{Z_t}[\\zeta(Z_t)]||$.\nIn the above equation, ( is a feature map transforming the samples into a Reproducing Kernel Hilbert Space (RKHS) with a characteristic kernel k, and ||\u00b7|| denotes the norm in this space. The kernel function k is defined by the inner product in the RKHS: k(\u00b7, \u00b7) = ($(\u00b7), 5(\u00b7))."}, {"title": "E. Preventing Catastrophic Forgetting", "content": "A major challenge in continual adaptation is mitigating performance degradation on previously learned domains after adapting to new domains, a phenomenon known as catastrophic forgetting. In this work, we posit that batch normalization (BN) contributes significantly to this forgetting. To address this, we introduce a simple yet effective approach that adapts BN for sequentially arriving domains. We first discuss conventional BN to identify the underlying causes of forgetting. Subsequently, we present our CBN technique, designed specifically to overcome the issue of catastrophic forgetting in dynamic learning environments.\n1) Batch Normalization: Batch Normalization (BN) is an essential technique in neural networks, aimed at addressing internal covariate shift. It normalizes the inputs of each layer to have zero mean and unit variance, contributing to the stabilization of the training process. For a mini-batch B, BN normalizes each input xi as:\n$\\hat{x_i} = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$\nHere, \u03bc\u03b2 and \u03c3\u03b5 are the mean and variance of the mini-batch, respectively, calculated by:\n$\\mu_B = \\frac{1}{m} \\sum_{i=1}^m x_i, \\sigma_B^2 = \\frac{1}{m} \\sum_{i=1}^m (x_i - \\mu_B)^2$.\nThe normalized input \u00eei is then linearly transformed using learnable parameters y and \u03b2:\n$y_i = \\gamma \\hat{x_i} + \\beta$.\nA fundamental limitation of conventional BN in continual learning arises from its domain-specific normalization approach. BN normalizes inputs based on the current domain's statistics as:\n$BN(x; \\mu^{domain}, \\sigma^{domain}) = \\gamma \\frac{X - \\mu^{domain}}{\\sqrt{(\\sigma^{domain})^2 + \\epsilon}} + \\beta$\nIn this context, domain and \u03c3\u03c4\u03bf domain are the mean and variance computed from the current domain's data. While this approach is effective for static data distributions, it can be problematic for continual learning. Rapid adaptation to the new domain's statistics (domain, domain) may lead to a loss of information about previous domains' statistical properties, posing a challenge for models that need to perform well across diverse and evolving data streams.\n2) Continual Batch Normalization (CBN): To overcome the limitations of conventional BN in continual learning scenarios, we introduce CBN. This technique aims to preserve knowledge from previously learned domains while effectively adapting to new data, mitigating catastrophic forgetting. Unlike conventional BN, which recalculates mean and variance for each target domain, CBN standardizes the normalization process using statistics from the source domain.\nDuring the source pretraining stage, we obtain running source statistics, including mean pema and variance \u03c3\u03ad\u03bc\u03b1, from each batch using Exponential Moving Average (EMA):\n$\\mu^{EMA} = (1 - \\alpha) \\cdot \\mu^{EMA} + \\alpha \\cdot \\mu_B, \\sigma^{EMA^2} = (1 - \\alpha) \\cdot \\sigma^{EMA^2} + \\alpha \\cdot \\sigma_B^2$.\nUsing these estimated source statistics, we standardize the batches of the all the incoming target domain:\n$x_T = \\frac{X_T - \\mu^{EMA}}{\\sqrt{\\sigma^{EMA^2} + \\epsilon}}$\nBy normalizing target domain data relative to the fixed statis-tics from the source domain, CBN maintains a consistent fea-ture distribution across domains. This consistency ensures that knowledge from the source domain is preserved as the model adapts to new target domains, enhancing its generalization capabilities in continual domain adaptation tasks.\n3) Minimizing Features Entropy: Resetting different target domains to the source statistics can cause instability in the training performance of CBN due to the distribution shift between domains. To address this, we aim to reduce the uncer-tainty of the learned features by minimizing their conditional entropy. This approach helps mitigate the instability caused by the differing adaptation of batch statistics from various domains to the source statistics. We formulate this process as follows: Given the target domain features zr = fo\u2081(xT), we normalize these features to obtain \u0175r = Norm(zr). Finally, our objective is to minimize the conditional entropy of the normalized features, which can be expressed as:\n$L_e = \\min_\\theta H(\\hat{z_T}|x_T)$,\nwhere H(2T|XT) represents the conditional entropy, which quantify the average uncertainty in the normalized feature set 2T given the observed target data xr. By minimizing Le, we aim to reduce this uncertainty, thereby enhancing the features sharpness and, consequently, stabilizing the training process amidst varying domain-specific data distributions."}, {"title": "F. Overall Objective", "content": "EverAdapt optimizes multiple objectives to facilitate adapta-tion to new domains while retaining knowledge from previous ones. These objectives include minimizing the conditional entropy of target features (Le), aligning source and target features with consideration for class information (Lloc), self-training using memory samples (Lm), and maintaining source classification performance (L5). However, balancing the min-imization of entropy and class-conditional alignment (CCA) poses challenges, as excessive entropy reduction can result in prediction collapse into a single class, counteracting CCA's goal of precise class alignment across domains. To navigate this, we employ an adaptive weighting strategy. Initially, we prioritize entropy minimization (Le) with lesser emphasis on CCA loss (Lloc). As training progresses, we gradually shift the focus, reducing entropy weight and enhancing the emphasis on CCA\nThe overall objective of EverAdapt is formalized as:\n$L_{overall} = \\alpha(t)L_e(z_T) + (1 - \\alpha(t))L_{loc}(z_s, Z_T) + \\beta L_m(X_M) + L_s(x_s, y_s)$"}, {"title": "IV. EXPERIMENTAL SETTINGS", "content": "We validated our method using the Paderborn University (PU) bearing dataset and the University of Ottawa (UO) bear-ing dataset, which are ideal for testing a CDA setting due to its various working conditions. Details regarding each dataset will be discussed in the next section. Following the approach suggested by Zhao et al. [26], we used data segmentation to increase the size of both dataset and simplify the model's input requirements. Specifically, we applied a moving window technique with a window size and stride length of 1024 to segment the data, ensuring that the resulting data segments are distinct and non-overlapping for model training.\n1) Paderborn University Dataset: The Paderborn Univer-sity dataset [27] contains vibration signals from an electric motor, with a total of 32 sets of signals, each representing a different bearing. Out of these, 6 bearings are healthy, 12 have artificial damage, and 14 have real damage from actual working conditions. Each bearing was tested under four different working conditions. Two dataset, named PU Artificial and PU Real, were created using combining signals from healthy bearings and artificially damaged bearings or bearings with real damage. Both subsets include a combination of healthy and faulty signals, as detailed in a table referred to as Table I. In these datasets, the type of bearing is used as the class label and the different working conditions under which the bearings were tested are considered as different domains.\n2) University of Ottowa Dataset: The University of Ottowa (UO) dataset [28] comprises vibration signals from bear-ings operating under varying health conditions and rotational speeds. A total of 36 set of signals are included, each corresponding to one of 12 experimental conditions derived from combinations of three bearing health states (healthy, inner race defect, outer race defect) and four rotational speed patterns (increasing speed, decreasing speed, increasing then decreasing speed, and decreasing then increasing speed). For each condition, three trials were conducted to ensure data reliability. In the UO dataset, the state of the bearing's health is used as a class label, and the different rotational speed patterns are considered as separate domains."}, {"title": "V. RESULTS AND DISCUSSIONS", "content": "To evaluate the performance of our model, we compare it We assessed the efficacy of our EverAdapt technique by comparing it with recent domain adaptation methods proposed for fault diagnosis. We re-implement all the baselines in our framework, while ensuring the same backbone network and training schemes. Overall, the compared methods are as follows:\n\u2022 Conditional adversarial DA with discrimination embed-ding (CADA-DE) [19]: utilized a conditional adversarial alignment by integrating task-specific knowledge with the features during the alignment step for the different domains.\n\u2022 Hierarchical deep domain adaptation (HDDA) [21]: aligns the second-order statistics of the source and target distributions in order to effectively minimize the shift between the two domains.\n\u2022 Improved Domain Adversarial Neural Network (IDANN) [20]: leverages gradient reversal layer to adversarially train a domain discriminator network against an encoder network.\n\u2022 Minimum Discrepancy Estimation for Deep Domain Adaptation (MMDA) [22]: combines the MMD and cor-relation alignment with entropy minimization to effec-tively address the domain shift issue.\nThese results indicate that EverAdapt is highly effective in retaining previously learned knowledge while adapting to new tasks which contrasts the baseline CDA methods such as CUA and DCTLN-DWA which demonstrated remarkable BWT scores at the expense of Adapt performance.\nThis superiority is further illustrated in Figure 3a, which plots the initial target accuracy as the model adapts to various target domains. The plot reveals that our method not only achieves significantly higher initial accuracy, indicating superior adaptation performance but also excels in knowledge retention, as demonstrated by the minimal performance drop compared to other baseline methods."}, {"title": "C. Model Analysis", "content": "We conducted an extensive analysis to better understand how our model achieves its state-of-the-art performance.\n1) Ablation Study: An ablation study was conducted across three distinct scenarios to assess the efficacy of each component in the EverAdapt model, with results indicating consistent performance improvements in all scenarios. For each scenario, detailed findings are presented in Table V. Initially, the class-conditional alignment exhibited adaptation capabilities but was inadequate in countering catastrophic forgetting. The addition of replay samples improved knowledge retention, enhancing overall BWT by 7.29% but slightly reduced adaptation performance by 1.57%. The integration of CBN significantly boosted both memory retention, with a 7.73% improvement in BWT, and adaptation performance, improving by 3.16%. This advancement not only mitigated the initial dip in adaptation performance but also surpassed the performance of the model with only class-conditional alignment by 1.59%.\n2) Replay Samples Efficiency: This study investigates Con-tinual Batch Normalization (CBN)'s role in addressing catas-trophic forgetting, focusing on the use of minimal replay sample sizes. In scenario 3 of the PU Artificial dataset, we assessed the effectiveness of preserving merely 1% of data from each target domain. As illustrated in Figure 3b, our find-ings demonstrate CBN's substantial contribution to reinforcing replay sample utility. With just a 1% replay sample size, CBN notably enhances Backward Transfer (BWT) by nearly 7%, markedly reducing forgetting to 0.73%. Furthermore, augmenting the replay size to 10% while incorporating CBN yields only a slight BWT increment of 0.1%. This suggests that small replay samples, in conjunction with CBN, effectively combat the catastrophic forgetting challenge.\n3) Stability study: This section presents a stability study of the Continual Batch Normalization (CBN) module within the EverAdapt framework. Focusing on the PU Artificial dataset's scenario 3, we evaluated the significance of individual CBN components in stabilizing the model. Figure 3c illustrates the performance comparisons between the full implementation of EverAdapt, a variant employing only source statistics normal-ization without entropy, and another variant excluding CBN entirely. The results affirm the full CBN model's superior performance, indicating the drawbacks of omitting certain components. Specifically, while normalizing target samples with source statistics improved median accuracy by 6.83%, it also introduced greater variability, evidenced by a fourfold increase in the range of performance outcomes. Integrating entropy, alongside source statistics normalization, significantly counteracted this variability. This emphasizes the critical roles of both entropy incorporation and source normalization in CBN, enhancing not only the model's performance but also its stability under dynamic environmnets."}, {"title": "VI. CONCLUSION", "content": "In this study, we introduce EverAdapt, a streamlined ap-proach for continual unsupervised domain adaptation in ma-chine fault diagnosis. Central to EverAdapt is the novel Continual Batch Normalization (CBN) technique, which ef-fectively preserves model performance across varying domains and mitigates catastrophic forgetting. By standardizing batch statistics and reducing reliance on extensive replay samples, CBN emerges as the pivotal contribution of this work, ensuring robust and efficient adaptation in dynamic environments. Em-pirically, EverAdapt has demonstrated superior performance, setting new benchmarks on two real-world datasets, and foster-ing more robust and practical solutions in the face of dynamic real-world scenarios."}]}