{"title": "AI, Climate, and Transparency:\nOperationalizing and Improving the AI Act", "authors": ["Nicolas Aldert", "Kai Ebert", "Ralf Herbrich", "Philipp Hacker"], "abstract": "This paper critically examines the AI Act's provisions on climate-related trans-\nparency, highlighting significant gaps and challenges in its implementation. We\nidentify key shortcomings, including the exclusion of energy consumption during\nAI inference, the lack of coverage for indirect greenhouse gas emissions from AI\napplications, and the lack of standard reporting methodology. The paper proposes\na novel interpretation to bring inference-related energy use back within the Act's\nscope and advocates for public access to climate-related disclosures to foster mar-\nket accountability and public scrutiny. Cumulative server level energy reporting\nis recommended as the most suitable method. We also suggests broader policy\nchanges, including sustainability risk assessments and renewable energy targets,\nto better address AI's environmental impact.", "sections": [{"title": "Introduction", "content": "The climate implications of artificial intelligence (AI), including energy and water consumption, are\nincreasingly subjected to public scrutiny and academic research [5, 4, 1, 3, 7, 2]. While energy effi-\nciency targets for data centers are under discussion,\u00b9 there is concern that their energy consumption\ncould surpass the available supply of renewable energy. Major companies like Google have reported\nthat increased energy demand related to AI endangers their carbon zero strategies2.\nAs in many collective action problems, regulation may play a major part in mitigating the negative\nimpact of AI on climate while fostering socially beneficial use cases. Globally, several initiatives\nare underway to establish legal frameworks for AI. The most prominent example is probably the EU\nAI Act, which has just entered into force at the beginning of August 2024. The Act also includes sig-\nnificant sections concerning climate impacts, primarily reporting obligations. Thus, one might hope,\nthe climate effects of AI could become a relevant market parameter; have reputational repercussions;\nand enable public scrutiny, by analysts and NGOs.\nAgainst this background, this paper analyzes the Act's transparency provisions from both a legal and\na technical perspective, and makes three core contributions. First, it shows that the Act falls short in"}, {"title": "Climate Transparency and the AI Act: Gaps and Interpretation\nChallenges", "content": "Any change for the better starts with information about what is wrong. However, at the moment, it is\noften unclear what the exact impact of the development and usage of an AI model is concerning en-\nergy and water consumption. The AI Act seeks provide a remedy by forcing certain AI providers to\nmake climate-related disclosures. However, the patchwork of provisions includes seven significant\nambiguities and loopholes.\nFirst, for high-risk AI systems, providers are required under Art. 11(1) to document the computa-\ntional resources used in development, training, testing, and validation, as per Annex IV(2). However,\nthere is no explicit requirement to disclose energy consumption, limiting the comparability of, and\ntransparency on, the environmental impact of these high-risk systems to estimates based on the\ndocumented computational resources.\nSecond, the AI Act imposes transparency obligations on providers of general-purpose AI (GPAI)\nmodels, particularly concerning energy consumption. Under Art. 53(1)(a), providers must maintain\nup-to-date technical documentation that includes information specified in Annex XI, which requires\nknown or estimated energy consumption of the model, with estimates potentially based on compu-\ntational resources. However, this requirement focuses on the model's development phase, excluding\nthe inference phase, which is a significant oversight given the potentially much greater cumulative\nenergy consumption during inference [6, 8]. To address this gap, a novel interpretation can be con-\nsidered. Art. 53(1)(a) and (b), in conjunction with Annex XI and Annex XII, require providers to\ninclude in the documentation for downstream AI system providers and authorities information on the\ntechnical means needed to integrate the GPAI model into AI systems. Although energy consumption\nis not explicitly mentioned, these provisions should, arguably, be interpreted to include information\non hardware requirements, allowing downstream providers to estimate the energy consumption for\ninference. This novel interpretation would indirectly ensure transparency regarding inference energy\nuse.\nA third issue arises with open-source (OS) GPAI models, which are generally exempt from trans-\nparency obligations unless they pose a systemic risk (Art. 53(2)). Recital 102 emphasizes trans-\nparency for OS models but does not include energy consumption in the information that must be\ndisclosed. Rather, the focus is on parameters, model architecture, and usage information, leaving a\ngap in transparency regarding the energy impact of these models.\nRegarding, fourth, fine-tuning, Recital 97 seems to imply that an entity engaging in any, even mi-\nnuscule, fine-tuning of a GPAI model automatically becomes the provider of a new model, with all\ncorresponding duties. For minor changes, this seems excessive, even though Recital 109 suggests\nthat reporting obligations are limited to that fine-tuning. However, Art. 25(1)(b) holds that, for high-\nrisk AI systems (e.g., in recruitment), only a substantial modification bestows provider status upon\nthe modifying entity. This rule could be analogized for fine-tuning, such that only substantial model\nmodifications via fine-tuning lead to provider status, protecting smaller entities.\nFifth, the AI Act overlooks the greenhouse gas (GHG) effects of AI applications, such as those\nused in oil and gas exploration [3]. This omission leaves a significant gap, as these applications can\nsubstantially contribute to climate change, yet their environmental impact remains unreported.\nSixth, while the Act requires energy consumption to be documented, this information is only avail-\nable to authorities, not downstream providers (unless our suggested interpretation is adopted), and\nnot to the general public. Without broader access to this data, transparency and accountability are\nsignificantly curtailed, hindering market effects based on climate reporting, independent research\nand verification, and public scrutiny by analysts and NGOs.\nFinally, the Act also fails to address the use of toxic materials and water consumption, a critical\nfactor in data center operations. While most data centers in the EU must report their water usage\nunder the Energy Efficiency Directive, the AI Act lacks a specific attribution to AI, as stipulated"}, {"title": "Operationalizing the Requirements: Implementation Challenges", "content": "As the previous section showed, under the current version of the AI Act, GPAI providers must\nlog the energy consumption used for training GPAI models. To operationalize this provision, it\nis crucial to clarify how energy consumption should be measured or estimated. We discuss three\nmethods: measurement at the data center level; at the cumulative server level; and at the individual\ngraphic-processing unit (GPU) level.\nEnergy efficiency in data centers is measured by the Power Usage Efficiency (PUE) metric. It\ndenotes the ratio of total energy used by the data center to the energy consumed by its computational\nhardware. A lower PUE indicates higher energy efficiency, with a global average PUE of 1.58\nrecorded in 20233. When measuring energy consumption at the data center level, the advantage lies\nin capturing the total power usage, including both direct computing energy and overhead like cooling.\nThis provides a comprehensive overview and encourages efficient data center selection. However, it\ncan obscure the energy impacts of specific model architecture or software inefficiencies, as these are\ninfluenced by the data center's overall efficiency. Estimating with the PUE ratio is practical but may\nlack precision for specific model-level insights.\nAt the cumulative server level, i.e., for all utilized servers within one data center, energy measure-\nment with power distribution units is highly accurate, closely reflecting model size, data volume, and\nsoftware efficiency. This method is recognized in the industry and can provide detailed insights into\nenergy consumption. However, not all data centers currently track power demand at this level, and\nimplementing such systems can be time-consuming4. While cloud providers like AWS and Azure\nmay have these capabilities, widespread reporting standards are lacking, potentially disadvantaging\nsmaller companies.\nFinally, measuring energy usage at the GPU level within a server is straightforward with on-chip\nsensors for components like NVIDIA GPUs, which offer user-friendly monitoring. However, this\napproach significantly underestimates total energy consumption as it only accounts for a single com-\nponent, missing the broader picture of server-wide energy use. Therefore, it is not recommended for\ncomprehensive energy tracking."}, {"title": "Discussion and Policy Proposals", "content": "The AI Act is a first step toward mandatory AI related climate reporting, but is riddled with loopholes\nand vague formulations. To remedy this, we make six key policy proposals. Such mechanisms\nshould not only be included in the evaluation report due in August 2028 (Art. 111(6)), but in any\ninterpretive guidelines by the AI Office and other agencies, reviews and potential textual revisions\nbeforehand.\nThe primary weakness of the AI Act is the exclusion of inferences from explicit and mandatory\nenergy consumption reporting. While we offer a solution for interpretation, it is unclear whether\ncourts, agencies and companies will follow this route. This significantly hampers the assessment of\nfuture AI energy usage, related carbon emissions, and effects on (renewable) energy infrastructure.\nHence, future guidance from the AI Office, and delegated acts by the Commission (Art. 53(5) and\n(6)), should explicitly include inference as a reporting category, both in Annex XI (for the AI office)\nand XII (for downstream actors).\nAnother major challenge is the failure to include indirect emissions by AI applications (e.g., for\noil and gas exploration) and water consumption within the reporting obligations. This should be\nremedied at the provider (water) and the deployer level (applications).\nThird, the consequences of minor fine-tuning operations on GPAI remain unclear. It would be ben-\neficial to tie the energy reporting requirement to the mechanism of training (fitting model weights)"}, {"title": "Conclusion", "content": "This paper tackles some of the complexities at the intersection of AI, climate and regulation. The\nAI Act does contain significant climate reporting obligations. By drawing on technical and legal\nresearch, we show that they contain too many loopholes, and are difficult to operationalize. Perhaps\nmost importantly, even though recent research has shown inference to be a major driver of AI-\nrelated GHG emissions, this key area is omitted from the AI Act. A novel interpretation of the\nAct's reporting obligations might bring inference back within its scope. Furthermore, none of the\nclimate disclosures are initially open to the public. We suggest changing this urgently to kickstart\nmarket pressure, induce reputational effects, and enable crucial public scrutiny, e.g. by academics\nand NGOs.\nHowever, climate reporting can only be a first step in addressing the massive and fast-rising envi-\nronmental impact of AI models and systems. It must be complemented by substantive obligations,\nincluding sustainability risk assessment and management, renewable energy targets for data centers,"}]}