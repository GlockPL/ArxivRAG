{"title": "TOWARD LLM-AGENT-BASED MODELING OF TRANSPORTATION SYSTEMS: A CONCEPTUAL FRAMEWORK", "authors": ["Tianming Liu", "Jirong Yang", "Yafeng Yin"], "abstract": "In transportation system demand modeling and simulation, agent-based models and microsimulations are current state-of-the-art approaches. However, existing agent-based models still have some limitations on behavioral realism and resource demand that limit their applicability. In this study, leveraging the emerging technology of large language models (LLMs) and LLM-based agents, we propose a general LLM-agent-based modeling framework for transportation systems. We argue that LLM agents not only possess the essential capabilities to function as agents but also offer promising solutions to overcome some limitations of existing agent-based models. Our conceptual framework design closely replicates the decision-making and interaction processes and traits of human travelers within transportation networks, and we demonstrate that the proposed systems can meet critical behavioral criteria for decision-making and learning behaviors using related studies and a demonstrative example of LLM agents' learning and adjustment in the bottleneck setting. Although further refinement of the LLM-agent-based modeling framework is necessary, we believe that this approach has the potential to improve transportation system modeling and simulation.", "sections": [{"title": "Introduction", "content": "In transportation planning, modeling the transportation system and evaluating its performance is a critical task. The system evaluation model in transportation planning aims to model complex and dynamic interactions between travelers and infrastructure and predict future travel patterns and behaviors based on various social and economic factors, such as demographics of the population, the built environment, the local economy, the transportation network, and the transportation policies. Currently, the state-of-the-art models in planning are the agent-based models and the corresponding agent-based system micro-simulation tools. These models avoid the aggregation issues of conventional aggregated approaches such as the four-step model by modeling travelers as representative agents who can interact with the environment and make informed, autonomous decisions. By simulating agents' detailed travel behaviors and incorporating these behaviors into a dynamic representation of both demand and supply in transportation systems, agent-based models provide detailed, granular insights that improve forecast accuracy. In transportation engineering practice, agent-based models have also slowly begun to replace the classical four-step models in the planning process of some planning agencies [1].\nHowever, the established agent-based modeling methods still have some limitations on their behavioral realism and applicability in practice. First, the decision-making mechanisms within agent-based models generally rely on mathematical models that require a priori behavioral assumptions, which may not fully capture the bounded rationality and nuanced decision-making processes of travelers [2, 3]. Second, these models often demand extensive, high-"}, {"title": "Literature Review", "content": null}, {"title": "Agent-based models of transportation system", "content": "In travel demand modeling and transportation system analysis, agent-based modeling, first developed in the 1990s, has been established as an important paradigm. Compared to previous approaches which rely on aggregations of populations, trips, and behaviors of travelers, agent-based models offer a more detailed and behaviorally realistic representation of travelers' travel behavior by simulating the micro-level travel behavior and dynamics of representative agents. As pointed out by Kagho et al. [4], agent-based transportation models consist of three key components: the physical environment, which is the transportation infrastructure and services; the agents, which are the travelers; and strategies of agents, which guide and regulate agents' behavior. By setting up the agents, establishing their decision-making processes, and modeling their interaction with the transportation physical infrastructure, agent-based models can comprehensively simulate the dynamics of a transportation system and help decision-making in system performance"}, {"title": "LLM and LLM agents", "content": "LLMs are generative AI models crafted to understand and generate human language. These models are built upon sequence-to-sequence deep learning techniques, particularly transformers, and trained on extensive and diverse text datasets, including books, articles, websites, online forums, social media, and research papers. While early forms of these models, such as text-davinci [14], are designed only to process the ability to complete texts based on given information, state-of-the-art models such as ChatGPT [15], Gemini [16], and LLama [17] have evolved into sophisticated chatbots that can engage in conversations and respond to user queries and instructions. The language comprehension and autonomous generation ability of LLMs make them highly versatile tools that can perceive and complete tasks autonomously as agents.\nReflecting on the key requirements for traveler agents in agent-based transportation models, it becomes clear that LLMs have the essential capabilities to function as agents in the simulation process. First, LLMs possess advanced natural language processing abilities, enabling them to effectively receive and interpret a wide range of inputs from the environment. Their flexibility is enhanced by prompting mechanisms that allow for easy adaptation by simply modifying the natural language input for different information, facilitating frequent and efficient interactions. Unlike traditional machine learning models that require structured inputs, LLMs can process and understand unstructured information directly in human language, offering a significant advantage in versatility. Furthermore, LLMs are capable of autonomously planning and adjusting actions based on the information they process. For example, when prompted with specific instructions or questions, they can efficiently handle tasks like drafting essays, generating code, or solving complex problems with minimal human intervention. In travel itinerary planning applications, LLM also demonstrates good abilities to draft travel plans [18, 19]. Additionally, LLM agents show impressive adaptability through continuous learning from interactions, mostly as service assistants. For instance, LLM-based chatbots refine their conversational strategies based on user feedback, improving both the relevance and accuracy of their responses. This dynamic adjustment allows LLM agents to perform increasingly complex tasks over time, enhancing their value in decision-making, task automation, and problem-solving across various domains. Overall, LLMs' capabilities make them highly suitable for use as agents in agent-based simulations of transportation systems."}, {"title": "Advantages of LLM-agent-based models", "content": "While LLMs possess the capability to become suitable traveler agents in a transportation system, we argue that LLM-based agents can not only be suitable for the modeling framework but also have the potential to address some existing limitations of the agent-based modeling frameworks."}, {"title": "Relaxing behavioral assumptions", "content": "First, LLM agents have the potential to relax assumptions in the behavioral modeling of human travelers. Existing agent-based models rely on mathematical frameworks such as discrete choice models and decision trees that usually assume behavioral rules for travelers. Following the economics tradition, travelers are usually assumed to be rational. However, behavioral science suggests that humans often exhibit irrationality and bounded rationality in their daily actions [32]. LLMs have the potential to relax the behavioral assumption in the modeling process. In essence, LLMs are sequence-to-sequence models that can predict the distribution of next word $w^{(u)}$ in a sequence u given the previous words $w^{(u)}_{i-1}, w^{(u)}_{i-2}, ..., w^{(u)}_1$:\n$w^{(u)} \\sim P(w^{(u)} | w^{(u)}_1, w^{(u)}_2, ..., w^{(u)}_{i-1})$\nLeveraging vast corpora of human-generated text \u2014 including encyclopedias, academic papers, government reports, online forums, social media, blogs, and diverse web content \u2013 LLMs are exposed to an extensive dataset that reflects human patterns and behavior. This training data equips LLMs with insights into the varied reasoning, attitudes, and identities that shape human communication and decision-making. Along with their generative ability, LLMs have the potential to replicate realistic behavioral patterns, enabling them to simulate decision-making processes that reflect human diversity and tendencies. This characteristic makes them well-suited to capturing the complex, often non-linear and non-rational behavior exhibited by human decision-makers. This is supported by some established evidence showing that LLMs can exhibit similar economic behavior [33, 34] and social behavior [35, 25] as humans."}, {"title": "Reducing data requirement", "content": "Second, LLM agents offer the potential for more efficient and data-sparing calibration of the agent behavioral models. Traditional models of agent behavior, such as discrete choice models, have to be calibrated from scratch from a corresponding dataset with sufficient quality. The challenge of gathering large-scale, high-quality datasets suitable for calibration has historically been a barrier, particularly for agencies or communities with constrained resources. However, LLM agents benefit from having been pre-trained on extensive and diverse datasets on human knowledge and behavioral contexts. This pre-training allows LLMs to start with a rich baseline of generalizable knowledge about human behavior. Furthermore, beyond traditional training, LLM agents can also be customized with targeted natural language prompts. By defining the identity, motivations, or constraints of an agent through prompting, the model can adapt its responses to simulate context-sensitive behaviors. This method of customization enables LLM agents to generalize behavior across varying scenarios based on prior knowledge, making them capable of replicating nuanced behavior with minimal additional data. The ability of LLMs to be fine-tuned through simple, accessible prompts reduces"}, {"title": "Better supporting alternative evaluation", "content": "Finally, the LLM-agent-based framework may allow for easier evaluation of alternative situations and policies. Forecasting travel demand and evaluating system performance under new plans and situations such as building new roads, developing zones, or introducing technologies like CAVs and on-demand public transit poses significant challenges in transportation modeling. Currently, both the agent settings and datasets need extensive modifications to accommodate new scenarios, particularly for emerging technologies. In contrast, LLM agents offer greater flexibility by allowing agent behaviors to be customized through natural language prompts, eliminating the need for custom code or logic for each scenario. This reduces the time and expertise required to set up complex simulations. Moreover, LLMs' prompting mechanism enables behavioral generalization with minimal data; instead of retraining the model on large datasets, small changes in the prompt can guide LLM agents to perform in new situations. LLM agents can also reason about unfamiliar scenarios using their extensive pre-trained knowledge. This flexibility removes the need for hard-coding detailed behavior rules and processes for every scenario, a common requirement in conventional agent-based models. In other domains, some established research has already demonstrated the flexibility of LLM-agent-based modeling in evaluating alternative scenarios and policies. For example, Han et al. [28] uses LLM agents to evaluate the impact of different communication policies on firm collusion and market outcome; Hua et. al. [36] simulates the outcome of historical international events using LLM agents; Li et al. [29] evaluates the macro-economic impact of the COVID-19 pandemic on US unemployment rates; Chopra et al. [31] uses a large LLM-agent-based simulation framework to evaluate the public health impact of COVID-19 containment policies including stimulus payments, pandemic fatigue and targeted interventions of vaccines in New York City."}, {"title": "System design", "content": "In this section, we present the system design, information flow, and agent structure of our LLM-agent-based modeling framework. Our system is composed of two main parts: the LLM agents and the environment. The agents represent individual units in the transportation system such as a traveler or a family as a whole, and the environment is a dynamic transportation network simulator that can simulate the infrastructure and service performance in response to the travel demand. In the simulation, multiple representative LLM agents interact with the environment and simulate the system dynamics. The agents run in parallel and have different identities to represent different population groups. Through the interaction between the representative agents and the dynamic network simulator, our LLM-agent-based modeling framework can simulate the transportation system's dynamics and evaluate the performance of the system.\nThe LLM agents in our framework need to possess the ability to identify tasks, process information, learn from past interactions, and make autonomous decisions. To achieve these requirements, we design the LLM agents with a series of components and functions to allow for information storage, processing, and adaptive actions. The design of our LLM agents and their interaction workflow with the dynamic transportation network simulator are presented in Figure 2.\nOur agent design features an LLM core; a memory system that stores information; an identity core that defines the social demographics, tasks, and restrictions of the agents; and autonomous planning abilities to devise plans, extract travel-related information at any level, and execute actions. The agent has three long-lasting core components: identity, memory, and LLM core. Their corresponding designs and tasks are:\n\u2022 Identity: The identity describes the information related to the present that may impact the agent's decision-making. The identity contains social-demographic information about the agent, such as age, income, occupation, and number of cars owned, the agent's persona, such as level of environmental awareness, and the agent's travel-related tasks, such as going to school or grocery shopping that the traveler needs to do, along with the associated restrictions, such as school starting at 9 am. All identity information is stored in natural language and exists in the agents' long-term memory throughout the simulation.\n\u2022 Memory: The memory describes the past travel-related experiences and reflections of the agents that may help to adjust their decision-making in the future. In designing the memory system, we emulate the human decision-making process and memory formulation by implementing both a short-term memory system and a long-term memory system. The short-term memory system stores detailed travel experiences that have happened recently, while the long-term memory system stores high-level information that tends to stay longer in the memory of humans. The memory items that describe the past experience of agents are all stored in natural language.\n\u2022 LLM core: The core of the agent is a LLM. The LLM handles a diverse set of functions and tasks that includes natural language processing, autonomous summarization, and autonomous planning in the overall workflow. The agents will frequently query the LLM with the corresponding prompt dependent on the task.\nIn the overall information flow, when interacting with the environment, the agents first perceive their past travel experience and store it in their memory. Then, combining memory and identity, the agent leverages its LLM core to derive and process multiple levels of activity and travel plans. Finally, the agents execute their travel actions. The environment will simulate the system outcome based on the agent's actions, and with the agent receiving the outcomes, a new iteration in the simulation begins. In this iterative process, the agents process multiple functionalities such as perception, reflection, planning, plan processing, and acting. These functionalities are described below:\n\u2022 Perception: The perception function translates the outcomes such as travel times from the simulator to the agents. In this process, the agents can perceive their past travel experiences in their interactions with the system by using its LLM core and natural language processing to translate the numeric outputs of the system to natural language. These travel experiences are then stored in the memory system of agents.\n\u2022 Reflection: In reflection, we aim to take insights from the human memory system and information processing process [37]. For humans, details of recent experiences are stored in short-term memories while more macroscopic takeaways are processed by the human brain and stored in long-term memories. Thus, in the LLM-agent information flow, we also ask the agents to regularly conduct reflections based on their short-term memory and extract relevant top-level information from past travel to their long-term memories.\n\u2022 Planning: Given available information in their memory system and their identity, the agents leverage the strong reasoning ability of their LLM core to plan and decide their actions on diverse tasks. When doing planning, the agents will retrieve their identity and past experiences from both short-term and long-term memories. This information is processed into prompts and fed into the LLM core of the agent, and the LLM core will autonomously make plans and travel-related decisions based on the information.\n\u2022 Plan processing: As travel demand is largely a derived demand, in the simulation, the agents often need to devise general plans before determining the travel-related details. In the agent design, we also leverage the language processing ability to let the LLM core extract relevant information from a more general plan for a more detailed plan. For example, the LLM core can extract travel-related information from the general activity plan of the agents to form the outline of the agent's travel plan, and the agent can use this information to make further decisions.\n\u2022 Action: Based on the agents' travel plans, the LLM core leverages its language processing capabilities to convert natural language actions into structured mathematical inputs for the dynamic transportation network simulator."}, {"title": "Behavioral Tuning of LLM Agents with Human Travelers", "content": "In designing LLM-based agents, we aim to mirror human decision-making processes and traits. Given that transportation system simulations are inherently interactive and iterative, agents must not only make travel decisions but also incorporate feedback from the system to refine their behavior. Consequently, agent behavior must align with that of human travelers along two critical dimensions: first, agents should exhibit travel choices consistent with those of human users under similar contextual conditions; second, agents must demonstrate the capacity to learn from past experiences and adjust their future decisions accordingly. This section highlights the feasibility of fine-tuning LLM agents to fulfill these two criteria within an LLM-agent-based modeling framework, supported by illustrative examples and references to established studies."}, {"title": "Tuning LLM agents on travel choices", "content": "In the LLM-agent-based framework, the LLM agents need to make a series of choices when making their travel decisions, notwithstanding activity scheduling, mode choices, and route choices. While LLMs process autonomous decision-making abilities and also process training from vast amounts of human-generated training data, there is no guarantee that in terms of behavior, LLM agents would be similar to humans. Even with the popular role prompting [38] method, in which social-demographic information of the decision maker is provided to LLM to enhance its impersonation of humans, Evidence from social science and psychology [39, 40, 41, 42, 43, 44, 45] suggests that prompting LLMs with the task, demographics, and context information alone may not sufficiently generate behaviors that are similar to those of humans. Consequently, additional tuning of LLM agents is required to better align their travel choices with those of human travelers.\nEncouragingly, recent research in the transportation domain suggests that with targeted prompting and conditioning, LLM agents can indeed exhibit travel behaviors that closely resemble human actions across various decision contexts:\n\u2022 Activity scheduling: Established studies have demonstrated that incorporating additional context from historical data can better align LLM agents' activity scheduling behavior with that of human travelers. For instance, Wang et al. [45] emphasize the significance of travel motivation and habitual patterns in the activity scheduling context, proposing a pipeline that mines and summarizes these behavioral contexts from travelers' historical travel diaries. This information is then used in the LLM prompt to generate activity trajectories. Their evaluation on a large-scale mobility trajectory dataset shows that tuning LLM agents with this approach produces activity patterns more aligned with human behavior than existing frameworks. Similarly, Liu et al. [46] proposes a few-shot learning framework, leveraging LLMs' pattern recognition and reasoning capabilities. By providing social-demographic data, summary statistics, and exemplar travel diaries, they enable in-context\nlearning for LLMs. Their experiments with the National Household Travel Survey data reveal that few-shot LLMs can generate activity patterns closely matching those of human travelers.\n\u2022 Destination choice: LLMs have also demonstrated the ability to make destination choices similar to those of human travelers. Using a few-shot learning approach, Wang et al. [47] investigate whether LLMs can predict a traveler's next destination based on current location and past activities. Their framework incorporates historical trajectory data alongside contextual information, allowing the LLM to extract patterns from historical data and infer the traveler's next destination. Tests on a real-world mobility dataset reveal that LLMs can generate destination choices comparable to those of human travelers.\n\u2022 Mode choice: Recent literature has also demonstrated that LLMs may be tuned to exhibit similar mode choice behavior as human travelers. In our previous study on mode choice [48], we find that role prompting based on social-demographic information alone and few-shot learning is insufficient in aligning LLMs with human travelers on mode choice behavior. We then propose a persona discovery and loading framework (as shown in Figure 3) to further tune LLMs on mode choice behavior. The framework first leverages LLM's reasoning ability to discover latent persona characteristics in mode choice behavior and then matches new observations with the proper latent persona similar to a latent class discrete choice model. Using a real-world dataset, we find that the proposed framework can significantly improve the behavioral alignment of LLMs and human travelers in the mode choice context.\n\u2022 Other travel choice contexts: Additional evidence of LLMs' behavioral alignment with human travelers has been observed in other travel choice contexts. For example, Chen et al. [49] investigate how LLMs can simulate traveler decision-making during train delays. To enable the LLM to better model travelers' waiting decisions, the authors introduce a few-shot learning framework that incorporates delay logs and contextual features. These delay-specific features allow the LLM to identify key patterns and better predict traveler behavior during delays. Their validation using real-world delay data shows that delay-log-tuned LLMs can accurately simulate travelers' waiting decisions."}, {"title": "Tuning LLM agents on learning and adjustment", "content": "To design LLM agents that exhibit human-like learning and adjustment behavior, we align the agents with four critical traits observed in human cognitive processes:\n\u2022 Intelligence: Human intelligence is characterized by the capacity to solve complex, multi-level problems by breaking them down into smaller, manageable sub-problems. To emulate this capacity, we implement chain-of-thought prompting [50] within the agents' planning process. This approach facilitates stepwise reasoning, enabling agents to generate more accurate and interpretable solutions for complex planning tasks. Additionally, to mitigate small logical errors inherent to LLMs, we incorporate self-correction mechanisms [51]. This method enables LLM agents to iteratively review, identify, and revise their own responses, thereby reducing reasoning errors and enhancing overall decision accuracy.\n\u2022 Bounded rationality: Human decision-making is shaped by bounded rationality, a concept rooted in the presence of cognitive biases, risk aversion, loss aversion, and behavioral inertia (reluctance to deviate from the status quo) [32]. To simulate this trait in LLM agents, we integrate bounded rationality into the agents' reasoning process through prompt engineering. Specifically, the prompts encourage agents to consider behavioral inertia by highlighting the potential costs, effort, or inconvenience associated with changing a previous decision. This modification enables the agents to more realistically emulate human-like, suboptimal decision-making.\n\u2022 Limited memory Human memory is limited, with people typically retaining only key summaries or notable (extreme) events over time, while routine details are more easily forgotten. To mimic this aspect of human cognition, we develop a memory architecture for LLM agents comprising both short-term and long-term memory systems. The agents' reflection process prioritizes the consolidation of key summaries and extreme events into long-term memory. This memory design allows LLM agents to demonstrate human-like recall patterns and enables decision-making that reflects the kinds of experiences that most strongly influence human judgments.\n\u2022 Theory-of-mind Theory of Mind [52] is the ability to understand and infer the mental states, thoughts, beliefs, intentions, and emotions of others. In the transportation system setting, agents are also aware of other travelers' existence and notice that collective changes of other agents may impact their own decision's outcome. Thus, we also incorporate this into the planning prompt of the agents by making the LLM agents aware that the system involves multiple participants. This mechanism enables agents to recognize that their decisions are interdependent with those of other agents, allowing them to account for the potential impacts of collective behavior on system outcomes and adjust their choices accordingly.\nBy incorporating intelligence, bounded rationality, and limited memory into the design of LLM agents, we enable the agents to exhibit more realistic learning and adjustment behavior. To demonstrate that our agent design can trigger agents' learning and adjustment behavior during its iterative interaction with the environment, we use the setting of a classic example in transportation system analysis: the bottleneck model. In this model, a bottleneck that has a limited capacity lies in the way of the traveler on their way of commute and this bottleneck may cause congestion. The travelers would adjust their departure time every day by learning from past experiences and making today's departure time decision, aiming to minimize a weighted sum of the total travel time and the cost of early/late arrival at the destination. In this setup, agents are placed in a game-theoretical environment where they need to continuously learn from their past choices to optimize their departure times through repeated interactions.\nThe agent's perception is embodied in its memory system, where LLM agents store past travel experiences, including details such as departure time, arrival time, and travel time, in natural language descriptions. However, not all of it is utilized during decision-making. Similar to human behavior, LLM agents rely on overall trends and significant, extreme events to guide their next actions. To replicate this human-like trait, we designed a reflection module that enables agents to summarize their travel experiences and behavioral patterns over a specific time frame. These summaries, along with key extreme events (e.g., instances of high travel costs due to early arrival, late arrival, or traffic congestion), are stored in the agents' long-term memory. When agents retrieve information from the memory system, the decision-making process is guided by these summarized trends and extreme events, rather than by every individual data point. The memory system's three key components storage, reflection, and retrieval are designed to mimic the way human travelers prioritize patterns and extreme experiences over detailed recollection. Results from ablation experiments reveal that agents with the reflection module demonstrate more consistent and stable decision-making patterns, further supporting the importance of this design approach."}, {"title": "Technical Challenges", "content": "Our previous discussion and demonstration illustrated the potential, advantages, and feasibility of the LLM-agent-based modeling framework. However, there are still some challenges in the development and implementation of such a framework of transportation systems. We outline some remaining challenges in this section."}, {"title": "Enhancing behavioral alignment", "content": "While LLMs have shown great potential in replicating diverse behavior among different groups of travelers, a distinctive aspect of human behavior is its inherent randomness. For example, even when faced with the same choice problem, humans may sometimes make decisions that deviate from their usual preferences. In traditional modeling frameworks, stochastic models based on random utility theory are used to capture both the diversity and randomness of human behavior. However, LLMs may struggle to replicate this randomness. Since LLMs are trained on large datasets and designed to predict the most probable next word or sequence, their responses tend to be repetitive and conform to general norms. This limits the diversity and unpredictability of their outputs compared to human responses, which are more variable and less predictable. Additionally, LLMs are designed to avoid generating harmful, offensive, or inappropriate content, which encourages the production of conservative, neutral, or \"safe\" responses. This built-in safety mechanism further narrows the range of possible outputs. Empirical evidence from Park et al. [43] highlights this issue, showing that LLMs exhibit a \u201ccorrect answer\" effect, where responses to survey questions are highly uniform, unlike human respondents who demonstrate significantly more diverse answers. While adjusting the \"temperature\" hyperparameter which controls the randomness of the text generation process can increase response diversity, both Wang et al. [55] and Liu et al. [48] find that temperature adjustments alone are insufficient to achieve the same level of randomness as observed in human behavior. Therefore, new methodologies are required to better align LLM behavior with the behavioral randomness exhibited by human travelers."}, {"title": "Scalability of the simulation", "content": "Another major challenge of LLM-agent-based modeling in transportation systems is scalability. Transportation systems are inherently large and require a substantial number of agents, making it difficult to operationalize an LLM-agent-based framework at scale. The two primary bottlenecks are computational resource requirements and processing latency.\nLLMs demand significant computational power, and as the number of agents increases, the system's memory and processing needs grow proportionally. Running large-scale agent-based simulations quickly becomes resource-intensive. While cloud computing can help alleviate some of the computational burden, it does not fully address the issue of processing time. LLMs generally take longer to process inputs and generate responses than traditional models, making this a key bottleneck in large-scale simulations involving numerous agents. Transportation system simulations not only require large numbers of agents but also multiple repetitions to achieve convergence and assess system performance. As a result, the extended response times of LLM agents can significantly increase the total simulation runtime. Existing research has explored LLM-agent-based simulations with different agent counts, ranging from a few agents in game-like environments [20, 36], to around 10 agents in social sandboxes [27], and up to 50-100 agents in larger domains like"}, {"title": "Verification of the model", "content": "The final main challenge for the LLM-agent-based modeling framework is verification. Although our initial efforts suggest that LLMs can replicate human traveler behavior in certain scenarios and generate behaviorally sound adjust-ments, further verification is essential to assess their behavioral accuracy across diverse tasks. For instance, it remains unclear how closely LLM agents mimic human information processing and learning from past experiences, requiring additional experimental validation. Moreover, verifying individual behaviors is difficult when ground-truth data on human actions is limited. Additionally, behavioral accuracy at the individual decision level does not automatically ensure that system-wide simulation outcomes align with real-world data, making verification at both individual and system levels crucial for the verification of our proposed framework."}, {"title": "Conclusion", "content": "In this paper, we introduce a conceptual framework of an LLM-agent-based modeling framework for transportation systems. Our approach leverages the natural language understanding and autonomous decision-making capabilities of LLM agents, which positions them as effective agents within an agent-based modeling framework. We postulate that LLM agents have the potential to address some challenges in the agent-based modeling of transportation systems, particularly regarding behavioral assumptions, data efficiency, and flexibility.\nBy closely simulating human travelers' characteristics and interactions, we propose a general framework using LLM agents as proxies for human travelers and dynamic transportation network simulators as environments. Our framework incorporates a human-aligned agent design, featuring a memory system that mimics human memory, alongside an information retrieval and decision-making mechanism that enables LLM agents to learn from prior experiences and generate sound travel plans and actions. Furthermore, we demonstrated that the proposed framework has desirable properties on behavior emulation and learning abilities. We tested our framework on the morning commute bottleneck case and verified that the designed agents can generate sound behavior and adjust their decisions by learning from their interactions with the framework. Overall, our proposal is novel in the travel demand modeling and transportation system modeling domain, and our demonstration indicates the LLM-agent-based modeling framework has the potential to enhance the design and application of agent-based models in both academia and practice.\nNonetheless, some challenges remain. Tuning the behavioral alignment of LLM agents with human decision-making, especially in capturing randomness, is a key area for improvement. The scalability of the framework also poses limitations that must be addressed, and rigorous verification of both agent behavior and system-wide outcomes will be essential for broader applicability. Future research should focus on refining these aspects to enhance the accuracy and applicability of the LLM-agent-based framework for transportation modeling and related fields."}]}