{"title": "MaskMol: Knowledge-guided Molecular Image Pre-Training Framework for Activity Cliffs with Pixel Masking", "authors": ["Zhixiang Cheng", "Hongxin Xiang", "Pengsen Ma", "Li Zeng", "Xin Jin", "Xixi Yang", "Jianxin Lin", "Yang Deng", "Bosheng Song", "Xinxin Feng", "Changhui Deng", "Xiangxiang Zeng"], "abstract": "Activity cliffs, which refer to pairs of molecules that are structurally similar but show significant differences in their potency, can lead to model representation collapse and make the model challenging to distinguish them. Our research indicates that as molecular similarity increases, graph-based methods struggle to capture these nuances, whereas image-based approaches effectively retain the distinctions. Thus, we developed MaskMol, a knowledge-guided molecular image self-supervised learning framework. MaskMol accurately learns the representation of molecular images by considering multiple levels of molecular knowledge, such as atoms, bonds, and substructures. By utilizing pixel masking tasks, MaskMol extracts fine-grained information from molecular images, overcoming the limitations of existing deep learning models in identifying subtle structural changes. Experimental results demonstrate MaskMol's high accuracy and transferability in activity cliff estimation and compound potency prediction across 20 different macromolecular targets, outperforming 25 state-of-the-art deep learning and machine learning approaches. Visualization analyses reveal MaskMol's high biological interpretability in identifying activity cliff-relevant molecular substructures. Notably, through MaskMol, we identified candidate EP4 inhibitors that could be used to treat tumors. This study not only raises awareness about activity cliffs but also introduces a novel method for molecular image representation learning and virtual screening, advancing drug discovery and providing new insights into structure-activity relationships (SAR).", "sections": [{"title": "1 Introduction", "content": "Drug discovery has always posed a significant challenge in life sciences, and its outcome could tremendously impact medical research. Recently, the advancements in machine learning and artificial intelligence are now opening up new possibilities and leading to breakthroughs in the field of drug discovery 1-3. Over the past few years, machine learning has made remarkable advancements in various aspects of early drug discovery, such as molecular generation4-6, molecular optimization7-9, and molecular property prediction10-16. These technologies are offering more efficient and accurate methods for developing new drugs.\nMolecular property prediction plays a vital role in the drug discovery and design process, as it directly impacts the safety, effectiveness, and efficiency of drug development17. The fundamental concept behind molecular property prediction is that molecules with similar structures tend to have similar properties18. As shown in Figure 1a Left, molecules with distinct scaffolds exhibit different activities, and they can be well separated. However, there are cases called activity cliffs19, where two molecules with similar structures have significantly different biological activities (Figure 1b Right).\nPredicting activity cliffs holds substantial importance in rational drug design and the efficient discovery of new therapeutic agents20. Anticipating cliffs provides crucial insights into SAR and optimizes lead compounds more effectively, leading to more reliable biological activity prediction.\nActivity cliff task is a very important yet understudied task in the field of drug discovery. Previous studies21-23 have observed that graph-based models have poor performance on"}, {"title": "2 Results and Discussion", "content": "activity cliffs. We conjecture that the graph-based representation learning methods cannot separate two similar molecules in the feature space called representation collapse, resulting in poor performance on the activity cliffs. As shown in Figure b, we evaluate the performance of various GNN architectures on the activity cliffs, such as GCN24, GAT25, and MPNN26. The figure clearly shows that as the similarity between pairs of molecules becomes higher and higher, the distance in the feature space of graph-based methods decreases faster, which proves our conjecture. We defined this phenomenon as representation collapse. Therefore, we turn to discover other representations of molecules and find that various graph-based representation learning methods are inferior to image-based representation learning methods in identifying differences between similar molecules. Although molecular graphs and images describe the same molecular information, they are essentially different due to modal differences (graph versus image) and feature extraction differences (GNN versus CNN). In the activity cliff task, pairs of molecules have very similar structures and significant differences in activity. For example, a difference of just one atom can lead to a completely different activity. Increasing the discrimination between two similar molecules is the key to the success of predicting activity cliffs for deep learning models. For the GNN model, the small structural difference will be over-smoothed 27 out during information aggregation, resulting in little difference in the extracted features. This is also why GNN methods perform poorly on activity cliff tasks. For images, the convolution operation in CNN has the characteristics of local connectivity and parameter sharing, which makes the model pay more attention to local features to preserve these differences 28. These observations indicate that image-based methods can amplify the differences between two similar molecules and motivate us to develop an image-based method for more accurate activity cliff prediction.\nBesides, obtaining labels for activity cliffs requires expensive and time-consuming wet experiments. The inadequacy of labeled data significantly impacts model performance. Thus, we turn our attention to the pretrain-finetune paradigm30-35, because the pre-training process doesn't need labels, and few labels can be used in the fine-tuning phase to enhance performance. However, unlike natural images, molecular images are not as information-dense and have many blank areas. If we simply apply the pre-trained framework in computer vision such as MAE31 directly to molecular images, it would be challenging for the model to utilize meaningful molecular knowledge to identify subtle changes in cliff molecules. Therefore, it is necessary to use molecular domain knowledge to guide the model to learn molecule structures.\nMoreover, activity cliffs often arise due to subtle changes at various molecular levels 36-37, such as specific atom substitutions, bond modifications, or functional group replacements. At the atomic level, substituting a hydrogen atom on a benzene ring with a chlorine atom can lead to significant changes in the molecule's binding interactions with receptors, thereby affecting its biological activity. Changing a single bond in a molecule to a double bond may alter the molecule's shape and electronic distribution, thereby affecting its interactions with targets and its biological activity. Replacing a hydroxyl group on a benzene ring with a methyl group. While the structural difference is insignificant, the hydroxyl group can form hydrogen bonds, significantly affecting the molecule's solubility and interactions with biological targets. As a result, our objective is to incorporate prior"}, {"title": "2.1 Overview of MaskMol", "content": "chemical knowledge into the model and utilize this activity cliff-related knowledge to instruct the model in learning molecules. Here, we present a novel self-supervised pre-training framework called MaskMol, which focuses on learning fine-grained representations from molecular images with knowledge-guided pixel masking. We design three pixel masking-based pre-training tasks with three different levels of knowledge, involving atomic knowledge, bond knowledge, and motif knowledge. These tasks enable MaskMol to comprehensively learn the local regions of molecules by pixel-level knowledge prompts.\nIn summary, our main contributions are:\nWe first pinpoint the bottleneck in the molecular activity cliff task that the cliff molecules give rise to deep learning model representation collapse. Image-based model is superior to graph-based model due to alleviating representation collapse.\nWe design a novel and multi-level knowledge-guided molecular image self-supervised learning framework (called MaskMol) using a pixel masking strategy. After pre-training on a large-scale dataset consisting of approximately two million molecules, MaskMol demonstrated a significant performance enhancement on activity cliff estimation datasets and compound potency prediction datasets.\n\u2022 Explainable case study and visualization demonstrate that MaskMol strongly enables cliff awareness for bioactivity estimation and extracting meaningful SAR information for intuitive interpretation.\n\u2022 Through MaskMol, we identified candidate EP4 inhibitors that could be used to treat tumors, demonstrating that MaskMol can be used as a promising method under activity cliff virtual screening scenario."}, {"title": "2.2 Model Performance on Downstream Tasks", "content": "This section gives an overview of our MaskMol, highlighted in Figure 1c and Figure 1d. To accurately estimate molecular activity cliffs, we developed a knowledge-guided molecular image pre-training framework by fine-grained pixel masking, MaskMol. It consists of two parts: (1) three knowledge-guided pixel masking strategies, and (2) three knowledge-guided masked pixel prediction tasks for pre-training. See the Experimental Section for more descriptions on MaskMol.\nFirstly, the conversion from molecular SMILES to molecular images is performed using RDKit. To eliminate any extraneous color effects, we proceed by removing all non-essential hues from the molecular images. Next, again leveraging RDKit, we apply green hues to atoms, bonds, and motifs separately. In the following, HSV detection isolates regions with green pixels within the highlighted image. To introduce an element of randomness, we select a subset of atom/bond masking images by randomly choosing a fraction (determined by the masking ratio y) from the available masking atom/bond image sets.\nConsequently, we generate a set of masking images, totaling y. Natom and y. Nbond in number. It is important to note that to ensure that motifs do not cross each other, we only randomly select one masking image from the set of masking motif images. Moving forward, the masked image is combined with the original molecular image. Precisely, we adjust the white region of the masking image to correspondingly modify the region of the molecular image. In this synthesis process, we end up with three masked molecular images: the masked atom/bond/motif image. The three images are input through ViT to obtain latent"}, {"title": "2.2.1 Activity Cliff Estimation", "content": "features and classified through different fully connected layers. The pre-trained molecular encoder is fine-tuned on downstream tasks to further improve model performance.\nTo evaluate the effectiveness of the image-based representations learned by MaskMol, we choose wide-ranging popular or state-of-the-art baselines for comparison on activity cliff estimation benchmark (ACE) called MoleculeACE21, including 12 pre-training baselines and 11 traditional machine learning methods.\nWe refer to the original paper21 and follow its strategy to split the dataset. To assess the generalization of MaskMol, we employed a widely used splitting strategy known as scaffold split on ACE task and compound potency prediction (CPP) task. This is a more challenging but practical setting since the test molecules can be structurally different from the training set.\nAs shown in Figure 2a, we compared the performance of MaskMol with three types of state-of-the-art self-supervised molecular representation models: (1) sequence-based, (2) graph-based, and (3) image-based models. MaskMol has a better performance compared with sequence-based (for example, ChemBERTa38), graph-based (for example, GROVER39, MoICLR40, GEM41, EdgePred42, Mole-BERT10, 3DInformax43, GraphMVP44, and InstructBio45), and image-based models (for example, ImgaeMol17) using MoleculeACE experimental set-up. Compared with the second-best model (InstructBio), the elevated RMSE of MaskMol ranges from 2.3% to 22.4% with an overall relative improvement of 11.4% across 10 ACE datasets, in particular for HRH3 dataset (19.4%"}, {"title": "2.2.2 Compound Potency Prediction", "content": "RMSE improvement) and ABL11 dataset (22.4% RMSE improvement). In addition, MaskMol achieved lower RMSE values (Figure 2b) on D4R (RMSE = 0.73), DAT (RMSE = 0.59), FX (RMSE = 0.73), GSK3 (RMSE = 0.69), HRH3 (RMSE = 0.58), SOR (RMSE = 0.76), ABL11 (RMSE = 0.66), GR (RMSE = 0.68), CLK4 (RMSE = 0.85), and OX2R (RMSE = 0.67) compared with traditional ECFP-based methods across multiple machine learning algorithms, including support vector machine46, random forest47, k-nearest neighbors48, multilayer perception49, and gradient boosting machine50. In summary, Our method MaskMol, surpasses other state-of-the-art methods, achieving the lowest RMSE in these comparisons. To further substantiate MaskMol's efficacy in identifying activity cliff pairs, we showcase results using $RMSE_{cliff}$ as an additional performance metric. On the DAT and OX2R datasets, MaskMol achieves a 6.7% improvement in $RMSE_{cliff}$ compared to the second-best method (SVMECFP). Taking into account the two metrics of RMSE and $RMSE_{cliff}$, MaskMol also has a lower value than any other state-of-the-art molecular representation models (Figure 2c). Furthermore, to evaluate the disparity between the prediction and label, we employ Kullback-Leibler Divergence (KLD51) for measuring distribution differences (Figure 2d). The KLD values of all ACE datasets are significantly lower and the distributions of label and prediction values are close, except CLK4. We hypothesize that the relatively pronounced discrepancies observed in the CLK4 dataset could be attributed to its limited molecule number (731), which may have resulted in an under-fitted model.\nTo test the generalization of MaskMol, we split the datasets using a scaffold split (Figure 3a). We found that MaskMol significantly outperforms SVMECFP models across all"}, {"title": "2.3 Ablation Studies on MaskMol", "content": "10 ACE datasets. For instance, the RMSE values of MaskMol (RMSE = 0.69) compared with SVMECFP model (RMSE = 0.97) in the prediction of ABL11 are elevated by over 28.9%. We further evaluated the $RMSE_{cliff}$, compared with SVMECFP models, MaskMol achieves better performance with a performance advantage of 6.4% on average, in particular for SOR (20.9% $RMSE_{cliff}$ improvement). Compared with the molecule image pre-training model (ImageMol), the elevated RMSE of MaskMol ranges from 6% to 28.8% with a performance advantage of 17% on average, the elevated $RMSE_{cliff}$ ranges from 9.4% to 40% with a performance advantage of 19.4% on average.\nThese results validate MaskMol's ability to precisely predict molecules exhibiting activity cliffs. Notably, ECFP-based methods demonstrate robust performance, whereas graph-based methods tend to underperform in activity cliff estimation. Graph-based models are vulnerable to representation collapse when faced with activity cliffs, and they face challenges in learning from non-smooth objective functions23. Furthermore, we found that image-based methods such as ImageMol have lower RMSE and $RMSE_{cliff}$ than graph-based algorithms (EdgePred, GraphMVP, 3DInfomax, Mole-BERT). This further demonstrates that the CNN-based model can use local inductive biases to identify subtle cliff changes. Although InstructBio attempts to mitigate representation collapse by leveraging a substantial amount of unlabeled data as pseudo-labels, it still does not match the performance of ECFP-based methods. The addition of pseudo-labels helps to clarify class boundaries52, suggesting that semi-supervised learning could emerge as a novel solution for addressing activity cliffs.\nAlthough MaskMol is primarily designed for solving fine-grained tasks such as ACE, it also performs well on the coarse-grained task of CPP. Compound potency prediction is crucial to the drug discovery and design process53-54. Researchers aim to forecast the biological activity of chemical compounds, explicitly measuring their potency in terms of the amount needed to produce a desired effect. As shown in Figure 3b, MaskMol has a better performance compared with sequence-based (ChemBERTa), graph-based (MolCLR, MGSSL, MPG55, and GraphMVP), and image-based models (ImageMol) using a scaffold split. Notably, on the BACE1 dataset, MaskMol achieves a small MAE of 0.56, while the best-performing baseline model (ImageMol), achieves 0.63. It is worth mentioning that MaskMol achieves this performance using only 2M pre-training data, compared to the 10M pre-training data used by ChemBERTa and ImageMol. This demonstrates that MaskMol can achieve superior performance with significantly less pre-training data.\nWe perform comprehensive experiments to investigate the impact of each component in MaskMol on the activity cliff estimation. As illustrated in Figure 3c, seven out of ten datasets have a pre-training gain of more than 30% and the gain reaches its peak at 45.87% on the DAT dataset. Furthermore, the average gain across all ACE datasets surpasses 34.43%, underscoring the substantial enhancement in MaskMol's performance attributable to knowledge-guided masked pixel prediction tasks. Unlike graphs, graph treats molecules as nodes and bonds, which encode a large amount of chemical information such as atom"}, {"title": "2.4 Interpretation of MaskMol", "content": "types and bond types. For an initialized image model, molecules are input into the model in the form of RGB pixels, which do not contain any chemical information. The model's understanding of molecular images is limited to the fact that the image is composed of some \u201cline.\u201d Therefore, it is necessary to help the model understand the chemical information in the image, which allows the model to understand the specific meaning of the \"lines.\u201d in the image. This is why we can see that MaskMol has greater improvement gains than graph-based GROVER before and after pre-training (34.43% versus 8.53%). The observed decline in performance for \"w/o AMPP\u201d (RMSE 4.5% decline), \"w/o BMPP\" (RMSE 16.4% decline), and \u201cw/o MMPP\u201d (RMSE 21% decline) indicates that the removal of any level knowledge-guide task adversely affects MaskMol's performance, with MMPP being the most influential. We also explored the impact of pre-training with different data scales. The size of pre-training dataset for MaskMolbase and MaskMolsmall are 20K and 2M respectively. We found that the average RMSE performance increased from 0.76 to 0.70 as the pre-trained data scale increased. This suggests that MaskMol will be further improved as more molecules are added to the pre-training dataset.\nAdditionally, we delve into analyzing the implications of the masking ratio, examining how its value affects MaskMol's overall performance (Figure 3d). It is worth noting that the optimal masking ratio in our study significantly deviates from the typical ratios used in BERT and MAE. BERT typically employs a masking ratio of 15%, whereas MAE utilizes a masking ratio as high as 75%. However, we found that a 50% masking ratio yields optimal results in our experiments. Molecular images are rather sparse with most pixels being empty and the resolution of the images is important in such settings. Thus, we research the impact of image size and the ratio of empty spaces to useful pixels on the learned representations (Figure 3e). The results show that the image size and useful pixel ratio achieved similar performance on ACE dataset (p>0.05, Mann-Whitney U test56)."}, {"title": "2.4.1 Investigation of MaskMol Representation", "content": "We use t-SNE to compare the representation learned by MaskMol with the ECFP fingerprints feature (Figure 4a,b). The t-SNE algorithm maps similar molecular representations to adjacent points in two dimensions. We observe that ECFP can only be mapped based on structure, resulting in active and inactive molecules being mixed in the feature space. Through multi-level knowledge-guided masked pixel prediction tasks, MaskMol can be aware of changes in atom/bond/motif when any atom/bond/motif in the image changes. Thus, the representations learned by MaskMol can effectively distinguish between active and inactive molecules, with a clear boundary between them.\nAdditionally, we have included some randomly selected pairs of activity cliffs in the figure to illustrate the similar and dissimilar molecules learned by MaskMol based on their biological activity. MaskMol can learn similar representations from molecules with similar structures and properties and map molecules with significant differences in structures and properties to distinct feature spaces. This demonstrates that MaskMol learns the topological structure information between molecules and uses properties to differentiate between molecules.\nTo measure the distance between active cliff pairs in feature space, we introduce a"}, {"title": "2.4.2 Explaining MaskMol via Attention Visualization", "content": "distance metric $d = \\frac{1}{N} \\sum_{i=1}^{N} p_i$, $p_i = \\sum_1^{2} \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$, where M1 = (X1,Y1), M2 =(x2, y2) are active cliff pair coordinates in the unified feature space. Figure 4c illustrates that in all ACE datasets, the distance between active cliff pairs in the feature space generated by MaskMol is considerable, significantly greater than that of ECFP. This observation highlights the effectiveness of MaskMol in accurately estimating activity cliffs, as it can capture subtle structural variations and utilize them to describe and represent molecules.\nWe applied three levels of knowledge-guided pixel masking to the molecular images and used Grad-CAM57 to visualize the areas of attention (Figure 4d). The results show that MaskMol accurately classifies the knowledge and focuses on the appropriate masked areas. This indicates that our three knowledge-guided masked pixel prediction tasks allow the model to identify different molecular chemical structures.\nIn Figure 4e, we provide a comparative analysis of key substructures associated with activity cliffs, as extracted by various deep learning (DL) methods. We select the top-3 most crucial edges detected by PGExplainer58. GNNs tend to allocate attention to insignificant regions of the cliff molecule and emphasize the identical structure. This observation supports our hypothesis that GNNs are susceptible to representation collapse when dealing with active cliffs, thereby hindering their ability to correctly identify cliff molecules. We can see that ImageMol focuses on large areas of the molecules, while MaskMol, without pre-training, only focuses on the entire molecule and ignores irrelevant blank areas. However, neither of them pays attention to the important substructure that"}, {"title": "2.4.3 Explaining MaskMol via Attention Visualization", "content": "affects the activity. MaskMol successfully identifies the most informative substructure and judges compound activity based on these substructures. These plots convincingly prove that MaskMol recognizes subtle differences in activity cliff pairs' substructures and can provide reliable and informative insights for medicinal chemists in identifying key substructures.\nWe use Substructure-Mask Interpretation (SME59) to further quantify the contribution of substructure to MaskMol predictions. We define the impact of the masking substructure on the overall prediction as the attribution. We make two predictions with MaskMol, one before and one after applying the substructure masking to the molecular image, and consider the difference between the predicted values as the attribution $Attribution_{sub} = f(x) - f(x_{sub})$, among them, x represents the molecular image, $x_{sub}$ represents the molecular image of masking substructure, and f represents MaskMol. By calculating the contribution of substructure to model predictions, we can gain insight into the impact of substructure on molecule activity. As depicted in Figure 5a, adding substructures such as benzene ring (Attribution = -1.93, K\u2081 = 5,370 nM) and ethyl alcohol (Attribution = -0.95, K\u2081 = 758 nM), the attributions are lower than zero, and the influence of the benzene ring is greater than that of ethyl alcohol, which is highly consistent with the molecular activity value. It can also be found that the position of the propyl group affects the activity, and the attribution value also makes the same judgment. Figure 5b also shows the same conclusion in the DAT dataset.\nIn addition to biological activity, we also present the chemically intuitive explanation of MaskMol on Mutagenicity. Figure 5c and Figure 5d display the analysis of different"}, {"title": "2.5 Virtual screening using MaskMol", "content": "substructures based on their Mutagenicity. A positive attribution indicates that the substructure contributes to toxicity, while a negative attribution suggests that the substructure has a detoxifying effect. Figure 5c reveals that nitro, amino, and quinone groups enhance the model's ability to predict toxicity, while carboxyl groups improve the model's prediction of non-toxicity. This observation aligns with previous studies, which have identified aromatic nitro, aromatic amino, and quinone groups as toxic and carboxyl groups as detoxifying60-62.\nIn summary, this visualization provides evidence that MaskMol is subtle structure-aware and exploits structural differences to make accurate predictions. Thus, MaskMol can provide meaningful and fresh SAR insights to help medicinal chemists in structural optimization and de novo design.\nEP4 receptor has been widely investigated and recognized as a promising drug target for cancer immunotherapy63. We manually collected data from multiple sources, including the BindingDB64, ChEMBL database, and patent libraries targeting EP4. Canonicalization of the molecules was achieved utilizing RDKit, and duplication of SMILES was deleted, resulting in a finalized dataset comprising 1633 molecules. We evaluated the performance of MaskMol on EP4 targets with a random split of 8:1:1. We found that MaskMol has a low RMSE on the test set (RMSE = 0.577), and the prediction values are linearly correlated with the label values in Figure 5f Left (R2 = 0.789). The t-SNE visualization in the latent space showed a clear boundary between inhibitors and non-inhibitors (Figure 5e grey"}, {"title": "3 Discussion", "content": "dots). To test the generalization ability of MaskMol, we constructed an additional patent set (131 molecules) from the extended patents and literature as an external validation set (R2 = 0.755). We found that inhibitors and non-inhibitors in the patent test were also perfectly separated. MaskMol identified 9 known EP4 inhibitors and visualized these 9 molecules to embedding space (Figure 5e), suggesting structural identification ability of MaskMol to learn discriminative information. These nine molecules (Grapiprant65, L00166, CJ-04279467, MK-289468, CR608669, ONO-457870, E704671, HL-4372, and AMX1200673) have been validated (including cell assay, clinical trial, or other evidence) as potential EP4 inhibitors.\nThese findings demonstrate the ability of MaskMol to provide robust and generalizable molecular representation and prediction of inhibitors of targets, making it an efficient and effective virtual screening method.\nIn the field of early-stage drug discovery, machine learning is gaining prominence, yet the concept of activity cliffs remains underexplored. Activity cliffs, which refer to structurally similar molecules with significant differences in potency, are critical for virtual screening and developing models that understand complex structure-activity relationships. Traditional graph-based methods often struggle with representation collapse due to high similarity between activity cliffs. To address this, we developed MaskMol, a knowledge-guided self-supervised learning framework utilizing molecular images. MaskMol employs three pre-training tasks with pixel masking, incorporating atomic, bond, and motif knowledge. This approach enables MaskMol to effectively learn local molecular regions"}, {"title": "4 Methods", "content": "and detect subtle changes in activity cliffs. Experimental results confirm MaskMol's superior accuracy in predicting activity cliffs and its performance compared to other state-of-the-art algorithms. Extensive experiments and ablation studies validate the effectiveness of each MaskMol component and determine the optimal ratio for knowledge-guided pixel masking. Furthermore, MaskMol identifies critical substructures responsible for activity cliffs through visualization, enhancing researchers' understanding of compounds and facilitating the drug discovery process. This study not only raises awareness about activity cliffs but also introduces a novel method for molecular image representation learning and virtual screening, advancing drug discovery and providing new insights into structure-activity relationships.\nFuture potential directions may improve MaskMol further: (1) Incorporating more chemical knowledge (such as fingerprints knowledge, 3D space structure knowledge, and chemical reaction knowledge) into image model is a promising future direction. Fingerprint-based methods have demonstrated excellent performance in predicting activity cliffs. Therefore, incorporating information from multiple fingerprints, such as MACCS74, ECFP, PharmPrint75, and USRCAT76, into the image model can enhance its accuracy. Currently, the consideration of activity cliffs does not include chiral cliffs. Learning 3D spatial structure information may be beneficial for predicting chiral cliffs. Despite the structural similarity of cliff molecules, their reaction synthesis processes differ, providing a unique perspective that can be used to identify these molecules. (2) Fine-grained alignment of images and other representations (for example SMILES and graph). By applying our proposed knowledge-guided pixel masks, we can perform fine-grained masking on images. This"}, {"title": "4.1 Data and code availability", "content": "approach allows us to align images and graphs (or SMILES) more precisely, guiding the model to learn from multiple views and improving its ability to capture subtle differences. (3) Multi-task learning of multiple activity cliff prediction datasets. This approach will not only predict activity cliffs but also address related tasks such as toxicity prediction and pharmacokinetic parameter prediction. By tackling multiple tasks simultaneously, we expect to improve the model's overall generalization and performance.\nAll of the codes are freely available at GitHub: https://github.com/ZhixiangCheng/MaskMol.\nThe datasets for activity cliff estimation can be downloaded from MoleculeACE at the following URL:https://github.com/molML/MoleculeACE/tree/main/MoleculeACE/Data/benchmark\\data.\nThe datasets for compound potency prediction can be obtained at the following URL:https://github.com/TiagoJanela/ML-for-compound-potency-prediction/tree/main/dataset.\nThe Mutagenicity datasets used in this study are available at https://doi.org/10.5281/zenodo.7707093."}, {"title": "4.2 Knowledge-guided Masked Pixel Prediction", "content": "Definition. A molecule's 2D information can usually be represented as a graph G = (V, \u03b5) with atoms V as nodes and the edges & given by covalent bonds. But in our experiments, the molecule is expressed as the image x \u2208 RH\u00d7W\u00d7C, where (H, W) is the resolution of the"}, {"title": "4.2.1 Atom-level Masked Pixel Prediction", "content": "molecular image, C is the number of channels.\nWe counted the atom types of molecules in the pre-training data and selected the ten most frequent atom types (e.g., C, N, O, CI). Correspondingly, the ten atom types serve as pseudo-labels for the atom-level masked pixel prediction (AMPP). Formally, the molecular image set and the pseudo-labels are {x \u2208 R224\u00d7224\u00d73}N=1 and yatom \u2208 {0,1,\u2026 ,9}10 respectively. For each x\u2081, we will get the mask atom image sets M = {Mj}Natomj=1 by Masking. Random sampling M with a masking ratio \u03b3 to get the subset of Mas M* = {Mj}mj=1, where m = \u03b3. Natom denotes the masking image number of subset. Then, we can obtain the masking atom image, denoted as x\u2081 = x\u00a1\u00a9M*, where indicates modifying the pixel value in x\u2081 corresponding to the white pixel area in M to white. Following ViT32, we divide a masking atom image \u017e\u2081 into regular non-overlapping patches. To save calculation time and make our model pay more attention to the masked patches, we only calculate the loss of the masked patches (\u017e\u2081). Finally, the cost function of the AMPP task is as follows:\n$L_{AMPP} = arg \\underset{\\theta,W}{min} \\frac{1}{N} \\sum_{i=1}^{N} l(w(f_{\\theta}((x_i))), y^{atom})$\nwhere f\u03b8 and \u03b8 refer to the mapping function and corresponding parameters of the molecular encoder, w represents the parameters of the fully connected classification layers, l is the cross-entropy (CE) loss function."}, {"title": "4.2.2 Bond-level Masked Pixel Prediction", "content": "The workflow of the bond-level masked pixel prediction (BMPP) is similar to that of AMPP, and the difference is that there are only four bond types, i. e., single, double, triple, and aromatic, and the pseudo-labels are ybond \u2208 {0,1,2,3}4. The BMPP loss function is defined as follows:"}, {"title": "4.2.3 Motif-level Masked Pixel Prediction", "content": "$L_{BMPP} = arg \\underset{\\theta,w}{min} \\frac{1}{N} \\sum_{i=1}^{N} l(w(f_{\\theta}((x_i))), y^{bond})$\nBreaking of Retrosynthetically Interesting Chemical Substructures (BRICS77) based on chemical reaction templates was utilized to partition functional groups. However, the functional group vocabulary obtained through the BRICS division is somewhat redundant. To address this issue, two rules defined in MGSSL12 were applied to eliminate redundant functional groups. As a result, we obtained a motif vocabulary consisting of 9854 motifs. We opted for the top 200 motifs with the highest occurrence and eliminated molecules lacking these particular motifs to reduce time and space burdens on the MMPP task. The motif-level masked pixel prediction (MMPP) process is also consistent with AMPP. The difference is that the pseudo-labels are ymotif \u2208 0,1,\u2026,199200 and we only randomly sample a motif in Mas M* so that there is no intersection between motifs and the model can extract accurate motif information. It is worth noting that when calculating loss, we use the classification token feature x\u2081cls to classify and perform loss calculation. The MMPP loss function is defined as follows:\n$L_{MMPP} = arg \\underset{\\theta,W}{min} \\frac{1}{N} \\sum_{i=1}^{N} l(w(f_{\\theta}((x_i^{cls}))), y^{motif})$"}, {"title": "4.3 Pre-training and Fine-tuning", "content": "Here, we used ViT as our molecular encoder. After using data augmentations and masking to obtain masking molecular images \u2081, we forward these images x\u2081 to the ViT model to"}, {"title": "4.4 Training Details", "content": "extract latent features f\u03b8(xi). Then, these latent features are used by three pretext tasks to calculate the total cost function L, which is defined as\n$L = L_{AMPP} + L_{BMPP} + L_{MMPP}$\nIn order to pretrain our MaskMol, we first gathered 2 million unlabeled molecules with drug-like properties from the PubChem database78. We divided the 2M pre-training data into a training set (95%) and a validation set (5%), and judged the pre-training performance through the accuracy of each task. Finally, the AMPP, BMPP, and MMPP accuracy can reach 99.3%, 98.0%, and 89.6%, respectively. After the initial pre-training phase, we proceed to fine-tune the pre-trained encoder for the specific downstream tasks. In particular, we incorporate an extra fully connected layer after the encoder. The output dimension of this layer is set to match the number of categories associated with the downstream tasks."}, {"title": "4.4.1 Baselines", "content": "The performance regarding methods (MLP49, GBM50, RF47, SVM46, KNN48, AFP79, MPNN26, GAT25, GCN24, CNN80, LSTM81 is derived from MoleculeACE21. The performance regarding methods (MolCLR40, GROVER39, GEM41, InstructBio45) is derived from InstructBio. We additionally execute experiments on the activity cliff estimation datasets following the same experimental setting used in Mole-BERT10, EdgePred42, GraphMVP44, 3DInfomax43, and ImageMol17."}]}