{"title": "An Expectation-Maximization Algorithm-based Autoregressive Model for the Fuzzy Job Shop Scheduling Problem", "authors": ["Yijian Wang", "Tongxian Guo", "Zhaoqiang Liu"], "abstract": "The fuzzy job shop scheduling problem (FJSSP) emerges as an innovative extension to the job shop scheduling problem (JSSP), incorporating a layer of uncertainty that aligns the problem more closely with the complexities of real-world manufacturing environments. This improvement increases the computational complexity of deriving the solution while improving its applicability. In the domain of deterministic scheduling, neural combinatorial optimization (NCO) has recently demonstrated remarkable efficacy. However, its application to the realm of fuzzy scheduling has been relatively unexplored. This paper aims to bridge this gap by investigating the feasibility of employing neural networks to assimilate and process fuzzy information for the resolution of FJSSP, thereby leveraging the advancements in NCO to enhance fuzzy scheduling methodologies. To achieve this, we approach the FJSSP as a generative task and introduce an expectation-maximization algorithm-based autoregressive model (EMARM) to address it. During training, our model alternates between generating scheduling schemes from given instances (E-step) and adjusting the autoregressive model weights based on these generated schemes (M-step). This novel methodology effectively navigates around the substantial hurdle of obtaining ground-truth labels, which is a prevalent issue in NCO frameworks. In testing, the experimental results demonstrate the superior capability of EMARM in addressing the FJSSP, showcasing its effectiveness and potential for practical applications in fuzzy scheduling.", "sections": [{"title": "I. INTRODUCTION", "content": "The job shop scheduling problem (JSSP) is a well- established combinatorial optimization problem (COP) that holds both theoretical significance and practical relevance [1]-[3]. The JSSP describes the processing time in the form of crisp numbers. However, in real-world manufacturing sce- narios, numerous uncertain factors, such as human variability [4] and machine flexibility [5], often preclude the accurate specification of processing times. To overcome this limitation, the fuzzy JSSP (FJSSP) that represents processing times with fuzzy numbers has emerged and drawn extensive attention [6]. Current algorithms for the FJSSP predominantly employ heuristic algorithms. Li et al. [7] contributed to the field by developing a bi-population balancing multiobjective evolu- tionary algorithm tailored for the distributed flexible FJSSP. They introduced an innovative crossover operator and two cooperative population environmental selection mechanisms, which effectively balanced the convergence and diversity \u0441\u0430- pabilities of the algorithm. Zhang et al. [8] proposed a multi- objective evolutionary algorithm that integrated clustering and hierarchical estimation techniques, addressing the challenge of maintaining a balance between the diversity and convergence of nondominated solutions while ensuring overall convergence. Gao et al. [9] crafted a differential evolution algorithm with a novel selection mechanism, enhancing the solution of FJSSP. Li et al. [10] enhanced an artificial immune system algorithm for the flexible FJSSP by incorporating simulated annealing, thereby boosting its exploration capabilities. Sun et al. [11] created an effective hybrid cooperative coevolution algorithm aimed at minimizing the fuzzy makespan of the flexible FJSSP, with a combination of particle swarm optimization and genetic algorithms significantly improving the convergence ability. Wang et al. [12] utilized fuzzy relative entropy to convert a multiobjective FJSSP into a single-objective problem and designed a hybrid adaptive differential evolution algorithm to address it. Pan et al. [13] focused on the energy-efficient flexible FJSSP and developed a bi-population evolutionary"}, {"title": "II. PRELIMINARIES", "content": "Fuzzy numbers are used to represent the processing time for the fuzzy scheduling, which is described in this section.\nIn manufacturing environments, precise processing times are often elusive due to variables such as the diverse skill levels of workers [39]. While exact durations may not be predictable, experts can often draw on historical data to provide estimated durations [40]. To address this unpredictability, a prevalent strategy involves estimating within confidence intervals. When certain values are more likely, opting for a fuzzy interval or number becomes an appropriate choice [41].\nAssume S is a fuzzy set defined on R, with a membership function $\u03bc_s : R \u2192 [0,1]$. The a-cut of S is defined as $S_\u03b1 = \\{x \u2208 R: \u03bc_\u03c2(x) \u2265 \u03b1\\}$, \u03b1 \u2208 [0, 1], and the support is $S_0$. A fuzzy interval is delineated by its a-cuts being confined, and a fuzzy number \u00d1, with a compact support and a pronounced modal value, is depicted by closed intervals $\u00d1_\u03b1 = [n_\u03b1, \\tilde{n}_\u03b1]$.\nThe triangular fuzzy number (TFN) [16] is frequently uti- lized in fuzzy scheduling problems. Let \u00c4 be a TFN denoted as $A = (a_1,a_2, a_3)$, where $a_1$ and $a_3$ outline the range of potential values and $a_2$ signifies the modal value within this range. The membership function of \u0100 is defined as follows:\n$\u03bc_A(x) = \\begin{cases} \\frac{x-a_1}{a_2-a_1}, & \\text{if } a_1 < x < a_2, \\\\  \\frac{a_3-x}{a_3-a_2}, & \\text{if } a_2 < x < a_3, \\\\  0, & \\text{otherwise.} \\end{cases}$"}, {"title": "A. Fuzzy number"}, {"title": "1. Addition Operation.", "content": "According to [42], the sum of A and B is calculated as follows:\n$A + B = (a_1+b_1, a_2 + b_2, a_3 + b_3)$."}, {"title": "2. Max operation.", "content": "According to [43], the max operation between A and B is defined as:\n$max(A, B) = \\begin{cases} A, & \\text{if } A \u2265 B, \\\\ B, & \\text{otherwise.} \\end{cases}$\nIt is evident that the max operation is determined by a ranking operation. In fuzzy scheduling, a commonly used ranking method is as follows [44]: Let $c_1(A) = \\frac{a_1+2a_2+a_3}{4}, c_2(A) = a_2$, and $c_3(A) = a_3 - a_1$. \u0100 > B if and only if one of the following three conditions is met:\n1) $c_1(\u00c3) > c_1(B)$;\n2) $c_1(A) = c_1(B) \\land c_2(A) > c_2(B)$;\n3) $c_1(A) = c_1(B) \\land c_2(A) = c_2(B) \\land c_3(\u00c3) > c_3(B)$.\nHowever, this method can only compare the magnitude of two TFNs at a time, and comparing multiple TFNs in this way would be very time-consuming, which is not conducive to the learning process of neural networks. Another commonly used ranking method [45] involves defuzzifying fuzzy numbers into crisp numbers, allowing the comparison of these values to determine the relationship between the TFNs, as shown in the following formula:\n$Defuzz(A) = \\frac{a_1 + 2a_2 + a_3}{4}$"}, {"title": "B. FJSSP", "content": "The FJSSP involves a collection of jobs, machines, and operations. Specifically, there are n jobs denoted by set I, m machines represented by set M, and N operations within set O. Each operation $i \u2208 O$ is associated with a unique job $J_i \u2208 I$, processed by a specific machine $M_i \u2208 M$, and has an uncertain processing time denoted by a TFN $t_i$. The operations are linked by a binary relationship \"\u2192\" that forms chains for each job. If operation i precedes j (i \u2192 j), they share the same job $J_i = J_j$, and no other operation x can exist such that $i \u2192 x$ or $x \u2192 j$. Let S be the set of scheduling schemes. The objective of FJSSP is to minimize the fuzzy makespan, i.e., to find the fuzzy start time $s_i$ for each operation $i \u2208 O$ to minimize the following objective over all possible schemes:\n$\\underset{\\pi \\in S}{min} \\underset{i\\in O}{max} s_i + t_i$\ns.t. $s_i \u2265 0$, \u2200i \u2208 O,\n$s_j \u2265 s_i + t_i$, if $i \u2192 j, i, j \u2208 O$,\n$s_j \u2265 s_i + t_i \\lor s_i \u2265 s_j + t_j$, if $M_i = M_j, i, j \u2208 O$.\nTo enable the neural network to assimilate the intricate con- straint information inherent in the FJSSP, this paper devi- ates from the conventional mixed-integer linear programming models [47] typically utilized in heuristic algorithms. Instead, we adopt the disjunctive graph [48] to effectively model the FJSSP. This methodological choice facilitates a more nuanced representation of the scheduling constraints, enhancing the"}, {"title": "III. EMARM", "content": "In this section, we begin by formulating the FJSSP as a generative task and outlining its optimization objectives. Subsequently, we detail the computational methods for each specific component of the objective. Finally, we introduce a strategy to address the challenge posed by the absence of ground-truth solutions in NCO using the EM algorithm."}, {"title": "A. Autoregressive model for FJSSP"}, {"title": "", "content": "Given an training set $\\{I_l\\}_{l=1}^{L}$ and its scheduling scheme $\\{\\pi_l\\}_{l=1}^{L}$, where $\\pi_l = (\\pi_{l,1},..., \\pi_{l,mn})$, our objective is to model the joint probability distribution $p(I_l, \\pi_l)$ to derive the conditional probability $p(\\pi_l | I_l)$. By leveraging the chain rule, we can express this as:\n$p(\\pi_l | I_l) = p (\\pi_{l,1} | I_l) \\prod_{i=2}^{mn} P (\\pi_{l,i} | \\pi_{l,1},..., \\pi_{l,i-1}, I_l)$"}, {"title": ""}, {"title": "", "content": "where m denotes the number of machines, n represents the number of jobs, and mn is the length of $\u03c0_l$. It is evident that modeling $p(\u03c0_l | I_l)$ in this way would require exponential complexity, which is not feasible. Assuming $\u03c0_{l,i}$ to be i.i.d. or Markovian would make it possible to model $p(\u03c0_l | I_l)$, but this assumption does not align with the actual situation of the FJSSP as discussed in Section II.B. To address this, we posit the existence of a neural network $p_\u03b8$ (parameterized by \u03b8) that approximates the conditional probability table in Eq. (11):\n$P_\u03b8(\\pi_l | I_l) = \\prod_{i=1}^{mn} P_\u03b8 (\\pi_{l,i} | \\pi_{l,1},..., \\pi_{l,i-1}, I_l)$."}, {"title": ""}, {"title": "", "content": "Consequently, an autoregressive model is established, and the $\u03c0_l$ is constructed by iteratively generating $\u03c0_{l,i}$ from i = 1 to mn.\nOur objective is to identify the parameter \u03b8 that maximize the log-likelihood of the optimal scheduling scheme $\\{\u03c0^*_l\\}_{l=1}^{L}$ for training set $\\{I_l\\}_{l=1}^{L}$:\n$\\theta = arg \\underset{\\theta}{max} \\sum_{l=1}^{L} log p_\u03b8 (\\pi^*_l | I_l)$."}, {"title": ""}, {"title": "", "content": "The remainder of this section offers a comprehensive expla- nation of the methods for representing and calculating each element within Eqs. (12) and (13). In Sections III.B-D, we focus on a specific instance to illustrate the principles, for brevity, we omit the subscript l."}, {"title": ""}, {"title": "B. Hand-crafted fuzzy prior", "content": "In the disjunctive graph model, the data information, specif- ically the fuzzy processing times, is stored at the vertices representing the operations, while constraints are defined by the edges. However, the raw data for these vertices includes only a single fuzzy processing time, which is insufficient to make accurate decisions. To achieve this, we require more comprehensive information. This is because, in addition to its own numerical magnitude, its role (relative numerical magnitude) in the job and machine to which it belongs is also important. We manually design significant information as priors to be integrated into the network. For each operation i, the composition of its information vector $x_i \u2208 R^{18}$ is as follows:\n$\\tilde{t}_i = (t_1, t_2,t_3) \u2208 R\u00b3$,\n$t_2 = Defuzz (\\tilde{t}_i) \u2208 R$,\n$\\frac{\\sum_{j=S_{t_i}}^{i} Defuzz (\\tilde{t}_j)}{\\sum_{j=S_{t_i}}^{End_i} Defuzz (\\tilde{t}_j)} \u2208 R$,\n$\\frac{\\sum_{j=i+1}^{End_i} Defuzz (\\tilde{t}_j)}{\\sum_{j=S_{t_i}}^{End_i} Defuzz (\\tilde{t}_j)} \u2208 R$,\n$\\frac{\\sum_{j=S_{t_i}}^{End_i} Defuzz (\\tilde{t}_j)}{Min_{j=S_{t_i}}^{End_i} Defuzz (\\tilde{t}_j)}$,\n$Defuzz (Quartile (J_i)) \u2208 R\u00b3$,\n$Defuzz (Quartile (M_i)) \u2208 R\u00b3$,\n$Defuzz (\\tilde{t}_i) - Defuzz (Quartile (J_i)) \u2208 R\u00b3$,\n$Defuzz (\\tilde{t}_i) - Defuzz (Quartile (M_i)) \u2208 R\u00b3$."}, {"title": "", "content": "where Quartile (Ji) and Quartile (Mi) represent the quartile of the fuzzy processing time for operations belonging to Ji and Mi, respectively. Eqs. (14) and (15) describe local information and represent the fuzzy processing time and the defuzzified processing time of Oi, respectively. Other equations describe global information. Eqs. (16) and (17) describe how much of the job to which it belongs has been completed and how much is left after processing Oi, respectively. Eqs. (18) and (19) describe the quartiles of fuzzy processing time for the job and machine to which O\u00bf belongs, respectively. Eqs. (20) and (21) describe the difference of the defuzzified fuzzy processing time of O and Eqs. (18) and (19), respectively."}, {"title": "C. Encoder", "content": "A two-layer graph attention network (GAT) [49] is em- ployed to extract and learn valuable information from the disjunctive graph. This network transforms 18-dimensional $x_i$ into a h-dimensional $e_i$. The primary advantage of $e_i$ over $x_i$ lies in its ability to complement the relationship between edges. To preserve the vertex information without dilution, the output at each layer of the GAT is concatenated with the original feature vector $x_i$. The formulation of encoder is detailed as follows:\n$e_i = [x_i||\u03c3 (GAT_2 ([x_i||\u03c3 (GAT_1 (x_i, D))], D))]$,\nwhere \"||\" is the concatenation operation, \u03c3is the ReLU activation function, D = AUE is the set of edges for instance I, and $e_i$ describes the instance I in Eq. (12)."}, {"title": "D. Decoder", "content": "The decoder is composed of two parts: A state network and a decision network. The former is responsible for updating state, and the latter is responsible for making decisions based on the information provided by the encoder and the state network. The two networks are described below."}, {"title": "1. The state network."}, {"title": "", "content": "EMARM makes decisions step by step, and each decision impacts the future. Therefore, after each decision, it is necessary to update the state and convey it to the EMARM to enhance the accuracy of subsequent decisions.\nFirst, we generate an 11-dimensional context vector $c_i$ (i = 1,2,..., n) for each job to describe its information. Assuming that Ot,i denote the ready operation of job Ji at step t and its predecessor is Ot,i - 1. The context vector $c_i \u2208 R^{11}$ contains the following entries:\n$Defuzz (FC(o_{t,i} - 1)) \u2013 Defuzz (FC(M_{o_{t,i}})) \u2208 R$ (23)\n$\\frac{Defuzz (FC(o_{t,i} - 1))}{Defuzz (max_{i=1,...,n} FC(I_i))} \u2208 R$ (24)\n$\\frac{Defuzz (FC(o_{t,i} - 1))}{\\frac{Defuzz (\\sum_{i=1}^{n} FC(I_i))}{n}} \u2208 R$ (25)\n$Defuzz (FC(o_{t,i} - 1)) \u2013 Defuzz (Quartile(J_i)) \u2208 R\u00b3$ (26)\n$Defuzz (FC(M_{o_{t,i}})) \u2208 R$ (27)\n$\\frac{Defuzz (max_{i=1,...,m} FC(M_i))}{\\frac{Defuzz (\\sum_{i=1}^{m} FC(M_i))}{m}} \u2208 R$ (28)\n$Defuzz (FC(M_{o_{t,i}})) \u2013 Defuzz (Quartile(M_i)) \u2208 R\u00b3$ (29)\nwhere FC() calculates the fuzzy completion time. Eq. (23) describes the relationship between two factors that affect Ot,i processing: Whether the predecessor operation is complete and whether the required machine is idle. Eq. (24) measures how close the current fuzzy completion time of $J_{o_{t,i}}$ is to the current fuzzy makespan. Eq. (25) measures how early or late the fuzzy completion time of $J_{o_{t,i}}$ is compared to the average fuzzy completion time of all jobs in current state. Eq. (26) describes the relative fuzzy completion time of $J_{o_{t,t}}$ with respect to other jobs in current state. Eq. (27) measures how close the current fuzzy completion time of $M_{o_{t,i}}$ is to the current fuzzy makespan. Eq. (28) measures how early or late the fuzzy completion time of $M_{o_{t,i}}$ is compared to the average completion time of all jobs in current state. Eq. (29) describes the relative fuzzy completion time of $M_{o_{t,i}}$ with respect to other machines in current state.\nSecond, these context vectors are further integrated by Eq. (30) to derive the state vectors $s_i \u2208 R^d$ (i = 1, 2, . . ., n). These state vectors assist the decision network in making informed decisions, where d is a hyper-parameter.\n$s_i = \u03c3 (\\sum_{j=1,...,n} c_jW_1+ MHA (c_jW_1) W_2)$."}, {"title": ""}, {"title": "", "content": "2. Decision network. This network combines the $e_{o_{t,i}}$ gen- erated by the encoder, which contain global information about the FJSSP, with the si generated by the state network, which contain local state information, to generate the probability of choosing a job for the step t. The details are as follows:\n$z_i = FNN ([e_{o_{t,i}}||S_i])$,\nwhere FNN denotes the feedforward neural network [51]. Sub- sequently, these zi \u2208 R are transformed into probabilities with a Softmax function: $p_i = \\frac{e^{z_i}}{\\sum_{i=1}^{n} e^{z_i}}$, where $p_i$ corresponds to $p_\u03b8 (\\pi_{l,i} | \\pi_{l,1},..., \\pi_{l,i-1}, I_l)$ in Eq. (12). Finally, the job to be processed at step t is determined through the sample method described below.\nOn the one hand, we randomly select a job i with a probability proportional to pi, which is produced at step t by the decoder. On the other hand, to avoid selecting jobs that have already been completed, we employ a masking operation to set the probability of selecting them in subsequent steps to zero."}, {"title": "E. Training strategy based on EM algorithm", "content": "To address the challenge of determining the parameter \u03b8 of EMARM according to Eq. (13), we encounter a chicken-and- egg dilemma: Knowing the optimal scheduling scheme \u03c0* is essential for identifying \u03b8, yet discovering \u03c0* itself relies on having a well-tuned \u03b8.\nThe EM algorithm [52] provides a solution to this dilemma. It is an iterative method designed for estimating parameters in statistical models that include latent variables. When the true values of these latent variables remain unknown, traditional maximum likelihood estimation is not feasible, and thus, the EM algorithm maximizes a lower bound of the log-likelihood function. This bound is established using Jensen's inequality, as illustrated in Eq. (32), where x, y, and e denote the latent variables, observations, and model parameters, respectively.\nThe algorithm proceeds through two main steps:\n\u2022 Expectation step (E-step): Sample latent variables from the current conditional distribution estimate x ~ p\u03c6(xy), and compute the expected log-likelihood lower bound L(0).\n\u2022 Maximization step (M-step): Maximize Ex~pe(xy) [log pe(x)] to update parameter \u03b8.\nThis iterative process enables the EM algorithm to converge towards a local maximum of the log-likelihood of the observed data, rendering it a robust technique for estimation problems with latent variables. Given the NP-hard nature of the FJSSP [9], the optimal scheduling scheme * shares the same un- observable characteristic as the latent variable. This similarity motivates us to tackle the problem using the EM algorithm, the pseudo-code for which is presented in Algorithm 1, where \u03c0l is a scheduling scheme of instance Il, FMS(\u00b7) calculates the fuzzy makespan. Furthermore, in the specific implementation, the expected solution for each instance may be obtained by sampling multiple candidate scheduling schemes and selecting the best, thereby improving the performance of EMARM in the early stages.\n$\\int log p_\u03b8(y) = \\int log \\frac{p_\u03b8(y, x)}{p_\u03b8(x|y)}dx \u2265 \\int p_\u03b8(x|y) log \\frac{p_\u03c6(y, x)}{p_\u03c6(x|y)} dx = \\int p_\u03b8(x|y) log p_\u03c6(y, x) dx - \\int p_\u03b8(x|y) log p_\u03c6(x|y) dx = E_{p_\u03b8(x|y)}[log p_\u03c6(y | x) + log p_\u03c6(x) - log p_\u03c6(x | y)] \u2261 C(0).$"}, {"title": "IV. NUMERICAL RESULT AND COMPARISONS", "content": "In this section, numerous experiments are performed to validate the effectiveness of the EMARM. The EMARM is developed using Python 3.9 and PyTorch 1.3.1, and is executed on an Ubuntu 22.04 PC. The hardware setup includes an Intel Platinum 8358P processor and an NVIDIA GeForce RTX 4090 with 24GB of memory."}, {"title": "A. Dataset and test instances"}, {"title": "", "content": "We randomly generate 30000 instances as the training set by following [53]. The size (m\u00d7n) of the training set includes 10 x 10, 15 \u00d7 10, 15 \u00d7 15, 20 x 10, 20 \u00d7 15, and 20 \u00d7 20 with each size represented by 5000 instances. The validation set is generated in the same way as the training set, except that the number of instances for each size is 100. In order to test the performance of EMARM comprehensively, we select 9 benchmarks from [54], and generate 2 benchmarks (20 x 20, 30 \u00d7 20) following the method in [54], with each benchmark consisting of 4 instances. It is worth noting that the benchmarks are not exactly the same size as those in the training set, which helps to demonstrate the generalization ability of EMARM."}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "In this paper, we investigate the FJSSP. This problem extends the JSSP by employing fuzzy numbers to characterize uncertainties in the production process. While this approach is more closely aligned with real-world manufacturing scenarios, it also increases the complexity of finding solutions. NCO is experiencing rapid development and is achieving many remarkable results. However, no researchers have attempted to address the FJSSP using learning-based methods. We model the FJSSP as a generative task and propose the EMARM to solve it. Firstly, to enable neural networks to capture fuzzy information, we design hand-crafted fuzzy priors. Secondly, we employ the EM algorithm to overcome the challenge of obtaining ground-truth labels in NCO. Lastly, a large number of experiments prove the effectiveness of the method we propose in this paper. In the future, on one hand, we intend to investigate the po- tential of alternative generative models in tackling the FJSSP."}]}