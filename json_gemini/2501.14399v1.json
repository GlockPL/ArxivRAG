{"title": "Handling Heterophily in Recommender Systems with Wavelet Hypergraph Diffusion", "authors": ["Darnbi Sakong", "Thanh Tam Nguyen", "et al."], "abstract": "Recommender systems are pivotal in delivering personalised user experiences across various domains. However, capturing the heterophily patterns and the multi-dimensional nature of user-item interactions poses significant challenges. To address this, we introduce FWHDNN (Fusion-based Wavelet Hypergraph Diffusion Neural Networks), an innovative framework aimed at advancing representation learning in hypergraph-based recommendation tasks. The model incorporates three key components: (1) a cross-difference relation encoder leveraging heterophily-aware hypergraph diffusion to adapt message-passing for diverse class labels, (2) a multi-level cluster-wise encoder employing wavelet transform-based hypergraph neural network layers to capture multi-scale topological relationships, and (3) an integrated multi-modal fusion mechanism that combines structural and textual information through intermediate and late-fusion strategies. Extensive experiments on real-world datasets demonstrate that FWHDNN surpasses state-of-the-art methods in accuracy, robustness, and scalability in capturing high-order interconnections between users and items.", "sections": [{"title": "1. Introduction", "content": "Recommender systems often rely on Collaborative Filtering (CF) to predict items that users might prefer by analyzing their past interactions and finding similarities with others who share comparable behaviors. This approach has become essential in improving user experiences across diverse applications, such as social networking platforms [1], streaming services [2], and online shopping sites [3], by filtering through large volumes of content.\nThe advent of graph neural networks (GNNs) has inspired recent advancements in representation learning by leveraging the structural properties of user-item interaction data to capture collaborative signals inherent in graph topologies. GNN-based CF models offer significant advantages for recommendation systems by effectively capturing and representing the intricate relationships between users and items through nodes and edges. This structural representation allows the models to uncover hidden patterns, similarities, and community structures, enhancing the accuracy and relevance of recommendations. For example, models like LightGCN [4] and UltraGCN [5] simplify traditional graph convolutional networks (GCNs) to better align with the needs of recommendation systems. Such GNN-based CF models are limited in their ability to capture complex, multi-way relationships, as they primarily focus on pairwise interactions. Furthermore, these models often struggle to represent and leverage higher-order connections, which can result in less nuanced and comprehensive recommendations.\nTo further enhance embedding expressiveness with intricate user-item relationships, hypergraphs have been integrated into the CF framework due to their ability to represent complex group-level interactions between users and items. Unlike traditional binary interaction graphs, hypergraphs connect multiple users to a specific item via hyperedges, encapsulating their multi-way interactions. A notable example is SHT [6], which employs a integration of hypergraph transformers to capture global collaborative relationships for recommendation task.\nWhile hypergraph-based methods have achieved notable advancements, they often neglect the presence of heterophilic patterns in user-item interaction data. Figure 1 illustrates a scenario where users and items exhibit diverse characteristics - often referred to as a heterophilic pattern. On the top oval, a single user ui interacts with multiple items(e.g., itema, item, item, itema), each belonging to different genres (e.g., Leadership, Technology, Self-help). Meanwhile, on the bottom oval, a single item itemj is consumed by various users usera, users, userc), each from different age groups (e.g., 45-54, 18-24, 35-44). By highlighting these cross-cutting relationships - one user engaging with diverse item genres, and one item appealing to diverse user demographics - the example emphasizes the multifaceted and heterogeneous nature of user-item interactions. Such patterns make it challenging to capture all relevant and irrelevant signals (e.g., shared preferences, demographic overlaps, cross-genre interests), which is a key motivation for developing models that can effectively handle complex recommendation settings.\nIn practical applications, users typically interact with items from a wide range of categories. To effectively learn representations, items within similar or related categories should have embeddings that are closely aligned, while embeddings for items in different categories should be more distinct. Furthermore, accurately modeling multi-hop neighborhood relationships is essential for capturing complex interactions. However, many existing models rely on deeply stacked Hypergraph Convolutional Networks (HGCN) layers, which often result in over-smoothing, making the embeddings less distinguishable. Overcoming this limitation requires a more sophisticated strategy that naturally integrates local and global connections without deep stacking, while accounting for the diversity and heterogeneity in user-item interaction graphs."}, {"title": "2. Model and Problem Formulation", "content": "In this section, we begin by presenting the structural data, which includes user-item interactions and user-item hypergaph, followed by a formal definition of heterophilic pattern and our task.\nInteraction Graph. The interaction graph represents the explicit relationships between users and items. Formally, it is a bipartite graph G = (U, I, E), where U and I are the sets of users and items, respectively, and E is the set of edges indicating interactions (e.g., clicks, purchases, or ratings) between users and items. Each edge (u, i) \u2208 E may be associated with additional attributes, such as timestamps or interaction strengths, which can enhance the representation of the graph.\nUser-Item Hypergraph. Hypergraphs can be divided into user hypergraph and item hypergraph. The user hypergraph Hu = (U,Eu) focuses on relationships among users. Here, U is the set of user nodes, and Eu is the set of hyperedges. Each hyperedge e \u2208 Eu connects a group of users sharing a common interaction pattern, such as engaging with the same item, or exhibiting similar preferences.\nThe item hypergraph H\u2081 = (I, E\u00bf) focuses on relationships among items. Here, I represents the set of item nodes, and E\u00bf is the set of hyperedges. Each hyperedge e \u2208 Ei connects a subset of items that are co-interacted with by the same user or group of users. This structure enables the modeling of item co-occurrences, such as items frequently bought together or shared in playlists, and captures their interdependencies in a higher-order manner.\nBy combining the user hypergraph and the item hypergraph into a unified framework, the user-item hypergraph H = (UUI, E) captures the complex and interrelated higher-order interactions between users and items.\nHeterophilic Pattern in Hypergraph. Heterophily refers to the tendency of nodes with different attributes or types to form connections. In the context of a user-item hypergraph, this means that users or items with contrasting characteristics may still be connected through the same hyperedge. Unlike a binary interaction graph, a hypergraph often exhibits heterophilic patterns due to its ability to model higher-order relationships, where diverse users or items with contrasting characteristics are grouped"}, {"title": "Definition 1 (Heterophilic-aware Recommendation)", "content": "A heterophilic-aware recommendation task aims to leverage heterophilic patterns in the user and item hypergraphs to improve the quality of recommendations. Formally, given a user u \u2208 U and a set of candidate items Ic\u2286 I, the objective is to predict a ranking over Ic that maximizes the likelihood of matching user u's diverse preferences, as inferred from heterophilic relationships in the hypergraph H."}, {"title": "3. Methodology", "content": "In this section, we first present the detailed architecture of our proposed FWHDNN model, as illustrated in Figure 2. First, we introduce the heterophily-aware hypergraph diffusion module that ensures varying message-passing for nodes in different class and labels. Second, we exploit wavelet transform-based hypergraph neural network layers to capture various scales of topological information of group-wise relationships among users and items. Third, we fuse features that capture different facets through intermediate and late fusion mechanisms to seamlessly combine structural and textual information for expressive representations. We further adopt contrastive learning to enforce the representations of equivalent entity to be close in proximity than the others in the vector space. Finally, the final user and item embeddings are harnessed to predict user interest scores on the candidate items."}, {"title": "3.1. Cross-Difference Relation Encoding", "content": "Inspired by the principles outlined in ED-HNN [7], our methodology first constructing user and item representations through the exploration of heterophilic relationships in user-item hypergraphs. In such hypergraphs, it is common to observe users grouping items into distinct categories, reflecting specific preference behaviors. To distinguish items across categories while retaining the shared characteristics within a category, we introduce a novel mechanism leveraging Heterophily-aware Hypergraph Diffusion Network (HDNN) layers.\nOur approach first applies a multi-layer perceptron (MLP) to transform the embeddings of users and items. This transformation allows the model to dynamically adapt to intricate data patterns, providing flexibility, and predefined parameter structures that may falter in scenarios where heterophilic patterns are widely spread. Afterward, the transformed embeddings are passed through HGCN, which aggregates node information within hyperedges based on topological relationships. To enhance the diversity of messages exchanged among nodes in a hyperedge and ensure equivariance, we integrate the aggregated node features with their original embeddings. This combined structure ensures that the model captures both local and global heterophilic patterns effectively. The HDNN framework can be formulated as:\nX(1) = LN(HConv(MLP\u2081(X(1)), H)) + X(1), \nX = LN(HConv(MLP2(X()), H)) + X (2)\nHere, X represents the embeddings of users and items, Xv denotes the node embeddings, and Xe refers to the hyperedge embeddings. The incidence matrix is represented by H, while MLP1(\u00b7) and MLP2(.) indicate the multi-layer perceptrons. The hypergraph convolution layer is denoted as HConv(.), and LN(\u00b7) corresponds to Layer Normalization [9]. The resulting node embeddings are subsequently combined with their initial embeddings to preserve essential features captured at different layers."}, {"title": "3.2. Multi-level Cluster-wise Encoding", "content": "Building upon the localized hypergraph neural network framework introduced in [8], we present a wavelet-based multi-scale group-wise relationship-aware encoder designed to capture neighborhood structures across various scales while maintaining the heterogeneity inherent in hypergraphs.\nThe use of wavelet bases facilitates localized convolution in the vertex domain, allowing the convolution operation to focus on specific scope of regions of the hypergraph rather than treating the entire structure as a whole. This localization is especially advantageous in hypergraphs with diverse hyperedge types, as it enables the model to effectively capture the heterogeneity of the data while embedding topological information. The formulation of the wavelet-based hypergraph convolution layer is as follows:\nX(1+1) = \u0398\u039b\u0398'\u03a7(1) W + X(2)"}, {"title": "3.3. Integrated Multi-modal Fusion Mechanism", "content": "To enhance the expressiveness and robustness of embeddings, we propose an Integrated Multi-modal Fusion Mechanism that synthesizes multi-faceted features (e.g., structural and textual features) through intermediate and late-fusion strategies. This approach leverages complementary information across modalities, enabling the construction of holistic representations that capture both shared and unique characteristics inherent to each data source.\nWe begin by initializing the structural embeddings Es to capture the intrinsic relationships among entities based on their underlying graph structure. Simultaneously, we leverage the textual embeddings Et derived from user and item profiles[10], which encode semantic information present in their descriptive attributes.\nIn the intermediate-fusion stage, the two-faceted attributes are subsequently processed through the two aforementioned modules. Within each module, structural and textual embeddings are pass-forwarded independently, ensuring that two different modals are handled in a manner that preserves their unique characteristics. The features are refined and transformed to enhance their representational quality, capturing the salient aspects of their respective modalities. The separated outputs are then averaged, yielding a unified representation that balances the contributions of both structural and textual features. Finally, decisions of modality-specific outputs from two modules are aggregated at a higher level in the late-fusion stage to preserve modality-specific nuances."}, {"title": "3.4. Multi-Encoder Collaborative Supervision", "content": "To ensure a unified representation of user preferences, it is essential to align the embeddings of the same users and items produced by the two separate modules, which capture distinct aspects of user behavior. This alignment helps the model integrate multiple perspectives into a consistent understanding. On the other hand, significant differences between the embeddings from the two modules might indicate redundancy or conflicting information in the captured features. To preserve the unique contributions of each encoder, the embeddings should be close to one another within the vector space.\nTo achieve this goal, we implement a cross-view contrastive learning approach. This method treats embeddings of the same users (or items) from different encoders as positive pairs and unrelated embeddings as negative pairs. The contrastive loss, inspired by InfoNCE [11], is formulated:\nIL = -log \u03a3 exp sz(u,))/T)\ni=0 l=0\nHere, 7 represents a temperature parameter, s(.) denotes the cosine similarity function, zi, l corresponds to the collaborative latent vector of a user (or item) at layer 1, and Ti, l signifies the latent vector of the same user (or item) from different encoders at the same layer.\nAdditionally, we incorporate the commonly used BPR loss [12], which is based on the assumption that if a user u interacts with an item i, the user is more likely to prefer i over items that they have not interacted with. To optimize the model parameters, we minimize the BPR loss function:\nLBPR = \u03a3\u03a3\u03a3 \u2013 logo (Yu,i \u2013 Yu,i')\nUEU i\u2208Zu i' Iu\nHere, U represents the set of users, i \u2208 Zu refers to the items that a user has interacted with, and i' & Iu corresponds to items with which the user has no observed interactions. The term \u0177 indicates the likelihood of user u engaging with item i, calculated as the dot product of the user's embedding and the item's embedding."}, {"title": "4. Evaluation", "content": "In this section, we assess the performance of Wave-HDNN by comparing it with several state-of-the-art baseline methods. We begin by outlining the experimental setup and proceed to provide a detailed performance analysis across multiple datasets."}, {"title": "4.1. Experimental Setting", "content": "To ensure a fair comparison, we conducted evaluations on three real-world datasets: Amazon-Books for book recommendations, Steam for game recommendations, and Yelp for business recommendations. The detailed statistics for these datasets are summarized in Table 1. These datasets were chosen to reflect varying interaction densities, showcasing the model's ability to perform robustly under diverse real-world conditions. For the initial textual embeddings, we leverage the semantic representation encoding approach proposed in [13] which generates textual embeddings from their profiles. Each dataset was divided into training, validation, and test sets using a 7:1:2 ratio. The final performance of each model was determined by averaging the results over five independent runs.\nMetrics. To assess the performance of the models, we employ two widely-recognized ranking metrics: Recall@k"}, {"title": "and Normalized Discounted Cumulative Gain (NDCG@k)", "content": "These metrics enable us to evaluate how effectively the models predict user interests and prioritize relevant items within the top recommendations.\n\u2022 Recall@k(Recall at k): Recall@k measures the proportion of relevant items that are successfully retrieved within the top-k recommended items. For each user, it is calculated as the number of relevant items present in the top-k list divided by the total number of relevant items available for that user. This metric provides insight into the model's ability to capture a comprehensive set of items that align with the user's interests, emphasizing the completeness of the recommendations.\nRecall@k = Number_of_relevant_items_in_topk / Total_number_of_relavant_items\n\u2022 NDCG@k: NDCG@k evaluates the quality of the ranking of the recommended items by considering both their relevance and their positions within the top-k list. This metric assigns higher scores to relevant items that appear earlier in the ranking, reflecting the assumption that users are more likely to engage with items presented at the top of the list. The Discounted Cumulative Gain (DCG@k) is first calculated by summing the relevance scores of the recommended items, discounted logarithmically based on their position:\nDCG@k = \u03a3 reli/ log2(i + 1)\ni=1\nwhere rel, is the relevance score of the item at position i. NDCG@k is then obtained by normalizing DCG@k with the ideal DCG@k (IDCG@k), which is the maximum possible DCG@k for the given set of relevant items:\nNDCG@K = DCG@K / IDCG@K\nIn the experimental settings, we specifically set the k value to 10, 20, and 40."}, {"title": "4.2. Baseline Models", "content": "We evaluate the performance of our proposed model FWHDNN against five cutting-edge baseline models, including both GNN-based and hypergraph-based approaches for recommendation tasks.\n\u2022 LightGCN[4] streamlines the NGCF framework by retaining only the neighborhood aggregation component, focusing on CF representation learning while removing unnecessary complexities.\n\u2022 SGL[14] builds on the LightGCN framework by incorporating an augmentation strategy alongside self-supervised contrastive learning to enhance representation quality.\n\u2022 DHCF[15] employs a dual-channel hypergraph neural network to facilitate a divide-and-conquer approach, allowing separate yet simultaneous learning of user and item embeddings.\n\u2022 HCCF[16] leverages contrastive learning to encode both local and global perspectives of user-item hypergraphs, enabling the model to learn distinct user and item representations effectively.\n\u2022 SHT[6] utilizes a transformer-based architecture paired with a hypergraph attention mechanism. Additionally, it introduces a data augmentation technique that captures diverse CF signals from various perspectives.\n\u2022 AutoCF[17] incorporates generative self-supervised learning to perform automated data augmentation, extracting meaningful self-supervised features without manual intervention.\n\u2022 WaveHDNN[18] incorporates two separate perspectives of structural information to account for heterophilic patterns and multi-scale relationships."}, {"title": "4.3. Performance Comparison", "content": "This section presents a detailed analysis of the performance results for all baseline models across the three datasets and provides a summary of their comparative performance.\nOverall Comparison. As illustrated in Table 2 and Table 3, the FWHDNN model we propose consistently achieves superior performance compared to all baseline methods across various evaluation metrics, highlighting its robustness in diverse scenarios. Particularly, on the Steam dataset, which contains collection of user interaction data sourced from the Steam online gaming platform, our model exceeds the second-best model by a notable 2.95% in NDCG@40, a critical metric for assessing the relevance of the top 40 recommendations. In addition, for sparse datasets, which feature limited user-item interactions, FWHDNN demonstrates marked improvements of 2.81% and 5.45%, respectively, for Amazon-books and Yelp dataset over the next-best models. These gains are particularly noteworthy because sparse datasets typically pose greater challenges for recommendation models, as the lack of interactions makes it more difficult to learn accurate representations. Despite this, FWHDNN's ability to generalize and perform well even in sparse environments underscores its adaptability and robustness.\nThe superior performance of FWHDNN stems from several key innovations: 1) The ability to learn distinctive representations using hypergraph convolution networks with"}, {"title": "Superiority over Hypergraph-based baselines", "content": "The experimental findings demonstrate that hypergraph-based approaches consistently surpass traditional graph-based models like LightGCN and SGL across all test scenarios. This performance difference underscores the benefits of leveraging hypergraphs to represent more intricate user-item relationships compared to standard binary interaction graphs. By capturing high-order group interactions that conventional graph methods often overlook, hypergraphs enable the generation of more precise recommendations.\nNotably, SHT, a representative hypergraph-based approach, outperforms SGL by 34.7% and 21.2% w.r.t. NDCG@4@traints in Amazon-books and Steam datasets, respectively. This significant improvement highlights the strength of hypergraphs in modeling complex group interactions and higher-order dependencies, leading to more accurate recommendations. By considering these high-order group interactions, hypergraph-based models can better represent the underlying topological structure of the user-item interaction space.\nAmong hypergraph-based models, FWHDNN excels with an 2.81% gain in Recall@40 on the Amazon-books dataset, showcasing its exceptional capability in identifying relevant items for users. Recall@40, which measures a model's ability to recommend items users are likely to interact with, reflects the effectiveness of FWHDNN's sophisticated fusion of equivariant message passing and wavelet-based structural learning techniques. Such a substantial improvement in recall signifies that FWHDNN is highly effective at recommending items that closely match user preferences.\nIn summary, the experimental results show the superiority of hypergraph-based methods over traditional graph-based approaches, especially when it comes to modeling complex, high-order relationships. Furthermore, among hypergraph-based models, our proposed WaveHDNN consistently achieves state-of-the-art performance, thanks to its advanced integration strategy of structural and textual information, multi-scale feature learning, and robust message-passing mechanisms."}, {"title": "5. Related Works", "content": "Traditional Collaborative Filtering. CF is a fundamental technique in recommender systems, aiming to predict user preferences based on historical user-item interactions. CF methods can be broadly categorized into memory-based and model-based approaches. Memory-based techniques, such as User-Based CF and Item-Based CF, leverage similarity measures like cosine similarity or Pearson correlation to estimate the likeness between users or items [19, 20]. While these methods are straightforward and intuitive, they often struggle with scalability and data sparsity, particularly in large and complex real-world datasets [21, 22, 23, 24, 25, 26].\nModel-based approaches, on the other hand, address these challenges by learning latent representations of users and items. For instance, Matrix Factorization (MF) projects users and items into a shared latent space for scalable predictions. BiasMF [27] extends MF by incorporating user and item bias terms, improving its ability to capture individual characteristics. Singular Value Decomposition (SVD) [27] decomposes the user-item interaction matrix into latent factors, enabling predictions of future interactions. An advanced variant, SVD++ [28], integrates implicit feedback, such as clicks or views, to capture finer user preferences. Non-Negative Matrix Factorization (NMF) [29] enhances MF by enforcing non-negativity constraints, ensuring that the latent factors are interpretable and positive.\nTo account for non-linear relationships between users and items, Neural Collaborative Filtering (NCF) [30] replaces the traditional inner product in MF with a neural network, allowing the model to learn complex user-item interactions through multi-layer feature transformations. While MF and NCF are effective, they assume static user preferences, which may not align with real-world scenarios where preferences evolve. To address this, sequence-aware models, such as Recurrent Neural Networks (RNNs) [31] and Transformer-based models [32], have been developed to model the sequential patterns of user interactions, capturing dynamic preferences over time. Despite the emergence of more sophisticated models, foundational techniques like BiasMF and NCF remain essential in the CF community. These models strike a balance between performance and interpretability and often serve as a basis for building advanced hybrid models.\nTraditional CF methods are beyond the scope of this paper's experimental comparisons. Instead, we concentrate on graph-based CF models due to their superior ability to capture complex, higher-order user-item interactions and leverage relational information effectively [4, 16]. This focus allows for a more comprehensive analysis aligned with our proposed hypergraph-based approach [33, 34, 35, 36, 37, 38, 39].\nGraph-based Collaborative Filtering. To effectively model user preference behaviors, graph structures have become a popular approach, where users and the items they interact with are represented as nodes connected by edges [34, 35, 40, 38]. Traditional methods, such as Item-Rank [41], assign weights to items based on relationships observed through random walks, while SimRank [42] calculates user and item similarity by analyzing shared neighbors in the graph structure.\nIn recent years, GNNs have emerged as a powerful tool for CF, leveraging graph-based representations to capture user-item interaction patterns. For instance, NGCF [43] enhances the propagation process within user-item graphs by extending GCNs. AGCN [44] incorporates attention mechanisms to assign varying weights, emphasizing the relevance of nodes during propagation. LightGCN [4] streamlines the GCN framework by removing non-linear activation functions and feature transformations, focusing solely"}, {"title": "Superiority over Hypergraph-based baselines", "content": "Traditional Collaborative Filtering. By incorporating self-supervised learning, MHCN also restores lost connections through hierarchical mutual information maximization.\nAlthough hypergraph-based collaborative filtering methods have achieved considerable success, many room for improvement still exists. With this motivation, our proposed model focuses on propagating permutation equivariant messages through HGCN layers, thus making embeddings more distinguishable. Furthermore, by introducing wavelet-transform-inspired mechanisms, we leverage wavelets at multiple scales to comprehensively capture diverse structural features. Through these advancements, we aim to enhance both the representational power and generalization capability of hypergraph-based CF models [59, 60, 61, 62, 63, 64]."}, {"title": "6. Conclusion", "content": "We introduce FWHDNN, a novel CF framework that simultaneously captures heterophilic patterns and multi-scale structural information via a wavelet transform-based hypergraph diffusion algorithm. Heterophilic user-item interaction patterns are addressed through a cross-difference relation encoder, which applies distinct message passing strategies based on node types. Additionally, multi-scale group-wise structures are incorporated via a multi-level cluster-wise encoder, leveraging wavelet-aware hypergraph convolutional networks (HGCNs). Each encoder combines textual and structural perspectives through intermediate fusion, and the final embedding is derived using a late-fusion mechanism. Empirical results on real-world datasets demonstrate the superiority of FWHDNN over state-of-the-art baseline models. Future directions include extending FWHDNN to handle dynamic user preferences and more complex interaction types for broader applicability in recommendation systems [65, 66, 67, 68, 69]."}]}