{"title": "EVOLUTION OF COLLECTIVE AI\nBEYOND INDIVIDUAL OPTIMIZATION", "authors": ["Ryosuke Takata", "Norihiro Maruyama", "Yujin Tang", "Hiroki Kojima", "Yingtao Tian", "Takashi Ikegami"], "abstract": "This study investigates collective behaviors that emerge from a group of homogeneous individuals\noptimized for a specific capability. We created a group of simple, identical neural network based\nagents modeled after chemotaxis-driven vehicles that follow pheromone trails and examined multi-\nagent simulations using clones of these evolved individuals. Our results show that the evolution\nof individuals led to population differentiation. Surprisingly, we observed that collective fitness\nsignificantly changed during later evolutionary stages, despite maintained high individual performance\nand simplified neural architectures. This decline occurred when agents developed reduced sensor-\nmotor coupling, suggesting that over-optimization of individual agents almost always lead to less\neffective group behavior. Our research investigates how individual differentiation can evolve through\nwhat evolutionary pathways.", "sections": [{"title": "Introduction", "content": "Artificial Intelligence (AI) has witnessed significant advances with the emergence of powerful neural network (NN)\nmodels. Examples include large language models [1] and image generation models such as DALL-E [2], Imagen\n[3], and Parti [4]. Each has achieved previously unseen capabilities as powerful individuals through recent technical\nbreakthroughs.\nOn the other hand, the biological evolutionary strategy focuses more on the direction of collective intelligence compared\nto individual ability, especially for species living in populations [5]. Unlike individual intelligence, which deals\nwith challenges independently, collective intelligence necessitates the ability to process information, operate in a\ndecentralized manner, and adaptively integrate information based on context. This distinction is evident in social insects,\nsuch as ants and bees, where collective behavior with role differentiation emerges not from highly complex individuals\nbut through simple interactions among members.\nRecent studies have demonstrated various approaches to understanding collective behavior. Neural controllers evolved\nto climb environmental gradients can develop exploration-exploitation strategies [6], while effective gradient climbing\ncan emerge from local sensing and interactions without global planning [7]. The exploration processes themselves show\nremarkable parallels between environmental and internal memory search, suggesting common evolutionary origins [8].\nSocial interactions shape exploration strategies that may not necessarily optimize group-level efficiency [9]. Physical\napproaches to collective behavior in insects have revealed how individual properties and their interactions lead to various\nscales of collective patterns [10]. These findings suggest that collective intelligence emerges through the complex\nrelationship between individual and group-level behaviors [11], where local interactions and environmental feedback\nplay crucial roles.\nWe seek to bridge the biological collective intelligence with artificial intelligence, which we denote as \"Collective\nAI\" [12] and [13], focusing on the use of a population of neural networks. Here the intelligence of Collective AI is\nembodied not in the capacity of individual neural network, but instead in how each member (or agent) of the population\ninteracts with each other, as well as the dynamics of the resulting population. This interaction can be quantified through\ninformation-theoretic measures, particularly focusing on how environmental information is processed and integrated\nwith internal states to generate collective behaviors.\nIn this study, we focus on how individual optimization of a specific behavior-chemotaxis-can lead to emergent\ncollective behavior when agents interact in a shared environment. Specifically, we investigate the evolution of collective\nintelligence in populations of neural network-controlled agents inspired by clonal insects. These agents, evolved\nindividually to perform chemotaxis, interact in multi-agent simulations where communication occurs via pheromone\nsignals. In our simulation, we observe that collective intelligence is realized, which accompanies role differentiation.\nIndividuals that specialize in collecting chemicals in the environment can effectively use the same chemicals for\ncommunication when they are in a group. While individual evolution prioritizes optimization for specific tasks, we seek\nto understand how group-level dynamics emerge and diverge from individual optimization."}, {"title": "Models", "content": "In the model, we first induce chemotaxis in a single agent: in the framing of chemotaxis, this agent then senses the\nchemicals produced by other individuals, using this chemotactic response to gather with them. The resulting collective\nbehavior is subsequently analyzed."}, {"title": "Agents Controlled by Neural Networks", "content": "An agent's behavior is controlled by a neural network (Figure 1), the parameters of which changes through an\nneuroevolution process. The neural network has an input layer of 9 neurons (1 bias, 6 input neurons, 2 context neurons),\na hidden layer of 7 neurons (1 bias, 6 hidden neurons), and an output layer of 4 neurons (2 output neurons, 2 context\nneurons). Neuroevolution was performed on all 82 weights of the neural network. We used CMA-ES [14] in EvoJAX\n[15] as our evolutionary algorithm. CMA-ES generates multiple candidate solutions using a multivariate normal\ndistribution and calculates their goodness of fit. The advantage here is that it is easy to parallelize the evaluation of the\nobjective function with the number of candidate solutions.\nThe agent moves by having its velocity and angular velocity determined by a neural network. The range of values for\nthe angular velocity w(t) is [\u22120.05, 0.05], and the following formula is used to update the agent's angle 0(t).\n$\\theta(t) = \\theta(t - 1) + w(t)$                                                                                    (1)"}, {"title": "Experimental Setup", "content": "The experiment consists of two phases: (1) an evolution phase where a single agent's neural network is trained to\nacquire chemotaxis behavior, and (2) a test phase where the evolved neural network is replicated across 1024 agents for\nevaluation. In the test phase, evaluation is conducted on a homogeneous population where all agents share identical\nneural network parameters.\nWe evaluate our evolved neural network periodically. Concretely, for every 10 generations, we pick the best individual\nfrom the population and replicate its parameters (i.e. the synaptic weights) 1024 times to create identical agents, and\nuse these agents to conduct a multi-agent simulation.\nThe parameter values used in the simulations are detailed in Table 1. The environmental parameters, such as spatial\ndimensions and pheromone evaporation rate, remain identical between the single-agent evolution phase and the\nmulti-agent test phase."}, {"title": "Pheromone Environment", "content": "The evolution phase which agents are subjected to chemotaxis, the environment is populated with a single agent and\npheromones (Figure 2). The pheromones evaporate and decay over time. In this phase, Agents can evolve to gain the\nfitness. The fitness function is expressed by the following function:\n$F(t) = \\int \\phi(r(t), t)dt$                                                                                               (4)\nwhere \\phi is the amount of pheromone released into the environment other than its own release, and r(t) is the position\nof the agent at time t.\nIn the evolution phase, the placement of the pheromones changes randomly with every trial. Five initial pheromones are\ngenerated at random locations. The shape of the initial pheromone is a mixed bell-shaped distribution with randomly\nassigned parameters. One bell-shaped distribution has the parameters maximum amount of pheromone a, standard\ndeviation \u03c3, and center coordinates xc, yc, and is expressed by the following probability density function. Here, Table 2\nsummarizes the details of each parameter that is randomly set.\n$f(x, y) = a \\exp \\{ \\frac{(x - x_c)^2 + (y - y_c)^2}{2\\sigma^2}\\}$                                                                  (5)"}, {"title": "Results", "content": ""}, {"title": "Local vs. Global Movement Patterns", "content": "The evolution of agents' movement patterns was compared between the single agent and multi-agent simulations (Figure\n3). In the first generation, both in the single agent and in multi-agent, they do not respond to pheromones and move\nonly linearly. This is because the neural network has not yet evolved to properly respond to sensor inputs and change\nmotor outputs.\nAs the generations progressed, the single agent acquired chemotaxis, which also changed the overall behavior of the\nmulti-agent. At generation 100, the single agent does not optimize its behavior to stop at the position of maximum\npheromone concentration, and multi-agent simulations differentiate agent movement patterns. Within the population,\nof agents sharing the same neural network, some exhibit local movement patterns while others roam more globally.\nEven when agents settle into localized patterns, disrupting these local structures can transition them into more global\nmovements.\nThen at generation 500, the single agent shows an optimized movement pattern, and in multi-agent simulations, agents\ncluster locally at multiple positions. In these clusters, most agents achieve the optimal strategy of continuously gaining\npheromones by remaining stationary, similar to the single agent case. After this point, while the single agent's movement\npattern remains largely unchanged, the multi-agent simulation shows further evolution: after generation 1000, the spatial\nsize of local clusters slightly increases, forming dynamic clusters that continue to move. This results in a decrease in\nthe collective fitness measured by pheromone gain, which will be discussed later.\nWe also analyzed the time series of pheromone gain in this environment (see Figures 7 and 8 in the Appendix). The\nanalysis showed that single agents evolved chemotaxis behavior that enables them to reach areas of highest pheromone\nconcentration via optimal paths."}, {"title": "Phase Transition of Collective Behavior", "content": "We analyzed the evolution of collective behavior (Figure 4). The collective fitness (average of individual fitness across\nagents) showed significant variation even after individual fitness (ability to collect pheromones) converged (Figure\n4 (A)). This analysis reveals that behaviors which maximize individual benefits may not necessarily optimize the\ncollective performance, yet group-level fitness remains quantifiable and meaningful. The multi-agent environment\ncreates situations not present in single-agent scenarios, leading to differences in fitness diversity.\nChanges in collective fitness can be explained by the differentiation of pheromone gain within the population (Figure 4\n(B)). Groups with high collective fitness show clear separation between agents that collect few pheromones and those\nthat collect many.\nHowever, groups with high collective fitness show similar movement patterns across agents (Figure 4 (C)). This indicates\nthat despite similar movement patterns, there is variation in pheromone gain. In the localized cluster patterns seen at\ngeneration 500 (Figure 3 (B)), while agents exhibit nearly identical stationary behavior patterns, their pheromone gain\ndiffers due to differentiation between large and small clusters.\nTo analyze the contributions of different information sources to agent behavior, we examined both external information\nfrom sensor inputs and internal state information including context neurons in the neural network. We calculated\nthe mutual information $MI(I; O)$ between sensor inputs and motor outputs, and the conditional entropy $H(O|I)$ of\noutputs conditioned on sensor inputs (Figure 4 (D)). The mutual information and conditional entropy are given by the\nfollowing equations:\n$MI(I; O) = H(I) + H(O) \u2013 H(I,O)$                                                                               (6)\n$H(O|I) = H(I,O) \u2013 H(I)$                                                                                       (7)\nwhere I represents the time series data from 6 sensor inputs and O represents 2 motor outputs. These calculations used\nsensor and motor values (min=0 and max=1) discretized with a bin width of 0.01. And the entropy of agent behavior\n(motor outputs) H (O) is expressed as the sum of MI(I; O) and H(O|I):\n$H(O) = MI(I; O) + H(O|I).$                                                                                                (8)\nOverall, the mutual information is higher than the internal information content, suggesting that information from the\nenvironment significantly contributes to agent behavior. The mutual information initially increases before sharply\ndecreasing (Figure 4 (D)). At generation 500, when collective fitness reaches its peak, mutual information is at its lowest."}, {"title": "Evolution of Energy Distribution", "content": "We still need to quantify the population dynamics. The activity of agents can be measured as kinetic energy. We\nmeasured the kinetic energy of individual i at time step t by tracking the agent's behavior, defined by the following\nequation:\n$E_i(t) = \\Delta x_i^2 + \\Delta y_i^2$.                                                                                                      (9)"}, {"title": "Diversity in Collective Behavior", "content": "We examined the relationship between individual and collective fitness across 10 different evolutionary seeds (Figure 6\n(A)). The results show that once individual fitness exceeds a certain level, collective fitness diversifies. This suggests\nthat collective fitness is not uniquely determined by individual fitness.\nParticularly in the later generations where collective fitness shows diversification, we investigated the relationship\nbetween mutual information $MI(I; O)$ with both collective fitness and differentiation in movement patterns. We see\nnegative correlations in both cases (Figure 6 (B) and (C)). Across the 10 seeds, the correlation coefficients between\nmutual information $MI(I; O)$ and collective fitness ranged from -0.91 to 0.03 (\u03bc = \u22120.41, s = 0.26), while those\nbetween mutual information $MI(I; O)$ and the standard deviation of movement patterns ranged from -0.64 to 0.21\n(\u03bc = \u22120.21, s = 0.29) (Figure 11). These results indicate that lower mutual information $MI(I; O)$ tends to correlate\nwith higher collective fitness and more uniform but rather spatially localized movement patterns."}, {"title": "Discussions", "content": "We demonstrated the emergence of ant-like swarms (Figure 3) simply by grouping multiple individual agents that\nhad evolved to acquire chemotaxis. Despite having no information about other agents during the training phase, the\nresults suggest that primitive behavioral principles like chemotaxis alone can enable swarm formation. This aligns with\nfindings in biological systems where self-organization emerges from simple individual behaviors [16].\nOur results suggest that individual evolution does not necessarily lead to collective novel behaviors. Collective\nfitness does not directly correspond to individual fitness, and even when individual evolution stabilizes, collective\ndiversity continues to change. We attribute the diversity of behavior emerged when individuals grouped together to\ndue pheromones, a means of communication. This is in line with [17] that argues signal communication allows for\ndiversity in collective behaviors. During periods of stable individual fitness, we observed a decrease in sensor-motor\ncoupling $MI(I; O)$. This reduction in sensory sensitivity appears to lead to uniform movement patterns across the\nagent population. This phenomenon resembles the concept of collective intelligence as observed in natural systems,\nwhere group performance can diverge from individual capabilities [5]. We observed that mutual information $MI(I; O)$\nis higher than the internal information content $H(O|I)$. It demonstrates their behaviors emerge through interactions\nbetween the external environment and their internal states. We hypothesis that it is due to adaptability for individual"}, {"title": "Results of Different Evolution Seed", "content": "Analysis across 10 different evolutionary seeds shows negative correlations in later generations between mutual\ninformation MI(I; O) and both collective fitness and movement area standard deviation (Figure 11). Collective fitness\nshows stronger negative correlation, suggesting that, despite seed variation, higher collective fitness corresponds to\nweaker input-output relationships."}, {"title": "Rule-based Agent Without Internal States as a Criterion", "content": "To verify that the agent has acquired chemotaxis, we created a rule-based agent. The body, sensors, and motors of the\nagent are the same as those of the neural network agent. The agent proceeds in the direction of the sensor position to\nwhich it responded most strongly among the sensors around its body. Specifically, for each sensor input, the motor\noutput is as shown in Table 3.\nThe rule-based agent here has no internal states, only responses to inputs are implemented. With reference to such direct\nchemotaxis coupled to the environment, we examine the dynamics due to chemotaxis via internal states implemented\nby a neural network.\nThe chemotaxis acquired by the agent through the evolution of the neural network was compared to the rule-based\nchemotaxis. The trajectory of the agent, without internal states and with rule-based chemotaxis, is shown in Figure 12.\nThe trajectories of the agents are represented for 1000 steps in the single-agent environment. The behavior of the agent\nclimbing the pheromone gradient shown here is similar to the behavior acquired through evolution in Figure 3 (A).\nHere, to measure the similarity of the behaviors, we measured the cross-correlation of the time series of behavioral\noutputs through 1000 steps (Figure 13). This cross-correlation represents the degree to which the evolved chemotaxis is\nsimilar to the rule-based chemotaxis. In this Figure, the horizontal axis represents the number of steps, the vertical axis\nrepresents the time delay, and the colors represent the strength of the correlation. It can be seen that after approximately\ngeneration 100, the behaviors are synchronized with almost no time delay. This means that the rule-based level of\nchemotaxis was acquired in around 100 generations.\nIndividual behavior was not differentiated in the population in the rule-based agent (Figure 14). These agents have no\ninternal state and act only in response to inputs. This suggests that for individual behavior to be differentiated, it is\nnecessary to have an internal state, such as a neural network."}]}