{"title": "Fast-staged CNN Model for Accurate pulmonary\ndiseases and Lung cancer detection", "authors": ["Abdelbaki Souid", "Mohamed Hamroun", "Soufiene Ben Othman", "Hedi Sakli", "Mohamed Naceur ABDELKARIM"], "abstract": "Pulmonary pathologies are a global health\nconcern, often leading to fatal outcomes when not promptly\ndiagnosed and treated. Chest radiography is a primary\ndiagnostic tool, but the availability of experienced radiologists is\nlimited. Artificial Intelligence (AI) and machine learning,\nparticularly in computer vision, offer a solution. This research\nevaluates a deep learning model for detecting lung cancer,\nspecifically pulmonary nodules, and eight other lung pathologies\nusing chest radiographs. The study combines diverse datasets,\ncomprising over 135,120 frontal chest radiographs, to train a\nConvolutional Neural Network (CNN). A two-stage\nclassification system, incorporating ensemble methods and\ntransfer learning, triages images into Normal or Abnormal\ncategories and identifies specific pathologies, including lung\nnodules among eight conditions. The deep learning model\nachieves impressive results in nodule classification, with a top-\nperforming accuracy of 77%, sensitivity of 0.713, specificity of\n0.776 during external validation, and an AUC score of 0.888.\nWhile successful, some misclassifications, primarily false\nnegatives, were observed. In conclusion, this model\ndemonstrates the potential for generalization across diverse\npatient populations due to the geographic distribution of the\ntraining dataset. Future improvements may involve integrating\nETL data distribution and adding more nodule-type samples to\nenhance diagnostic accuracy.", "sections": [{"title": "I. INTRODUCTION", "content": "Chest radiography is widely recommended and routinely\nutilized as the primary imaging modality to detect suspected\nrespiratory illnesses, particularly lung cancer. The popularity\nof this investigation can be attributed to its procedural\nsimplicity, widespread availability, easy accessibility, and\nminimal radiation exposure when compared to chest CT\n(Computed Tomography) scans. The simplicity of the\nprocedure enables early detection of lesions, thereby\nfacilitating prompt disease assessment and management[1].\nBased on numerous studies, the implementation of chest\nradiography in lung cancer screening has been shown to\nimprove survival rates. For instance, Strauss et al[2]\nconducted randomized controlled trials that presented\ncompelling evidence indicating that CXR screening can\nenhance lung cancer survival by detecting tumors at an earlier\nstage[3]. Moreover, a large population-based cohort study\ndemonstrated that CXR screening decreased lung cancer\nmortality by 18% in high-risk individuals. Additionally, a\ncase-control study revealed that CXR screening reduced lung\ncancer mortality by over 20% [4]. hese studies highlight the\nsignificant potential of CXRs in lung cancer screening."}, {"title": null, "content": "However, identifying nodules in chest imaging is considered\na challenging image classification task. Lung nodules are low-\ncontrast tissues that are difficult to distinguish, and early\nstudies have utilized pre-defined features extracted from\nimage processing or manually hand-crafted to extract\nmeaningful features such as shapes, textures, densities, and\nintensities, which are then classified using machine learning\ntechniques [5]. Nevertheless, such feature engineering tasks\nhave limited generalization capabilities. Until recently,\ncomputing power and the availability of large data sets\nallowed this approach to flourish, these advances in deep\nlearning and large data sets allow the algorithm to match the\nperformance of medical professionals in various fields such as\nbiomedical fields [6, 7], medical imaging tasks, including the\ndetection of diabetic retinopathy [8], skin cancer classification\n[9], and lymph node metastases detection [10]. Consequently,\nthe automatic diagnosis of chest imaging has garnered\nincreasing attention [11], Artificial intelligence and machine\nlearning applications in the medical field have expanded\nsignificantly and now include sensitive medical tasks such as\nskin melanoma[12], brain tumor[13] and other pathology\ndetection models [14-16]."}, {"title": null, "content": "This work presents a two-stage deep learning pipeline that\nis designed to identify the presence of abnormalities in patient\nexams, predict potential pulmonary pathologies from a set of\neight possibilities, and localize the identified pathology in the\nexam image for better explainability. The pipeline utilizes\nadvanced machine learning techniques to achieve these goals,\noffering a powerful tool for clinicians and researchers in the\nfield of pulmonary pathology identification and diagnosis."}, {"title": null, "content": "The main objective of this study is to investigate the\nchallenge of recognizing eight types of malignant lung\nconditions such as Mass and Nodule. The model consists of\ntwo blocks: the first is a feature extractor, which includes a\npre-trained Convolutional Neural Network (CNN) that uses\nstate-of-the-art techniques, while the second block applies\ntransfer learning to refine the model's predictions. The study\nis divided into several sections, beginning with an\nintroduction, followed by a review of previous work on the\nclassification of medical data in section 2. Section 3 presents\nthe suggested approach, while section 4 discusses the outcome\nof the experiment that was carried out. This work is concluded\nin the final part of the study."}, {"title": "II. RELATED WORK", "content": "The ability of machine learning algorithms, especially\ndeep learning, to identify abnormalities in X-ray images has\ngrown in popularity in recent years. Artificial intelligence is\nused in medical research to aid in diagnosis, and some studies"}, {"title": null, "content": "have shown positive and accurate results. Strategies used by\nprevious researchers to manage lung diseases using artificial\nintelligence and deep neural networks are discussed here."}, {"title": null, "content": "The majority of patients that are diagnosed with lung\ncancer are in the mature stage with a lack of a good prognosis.\nAside from the late staging of diagnosis, the variability of\nimaging features and histology in lung cancer makes it\ndifficult for doctors to select the optimal treatment approach\n[17] The imaging features of lung cancer vary from a single\ntiny nodule to ground-glass opacity, multiple nodules, pleural\neffusion, lung collapse, and multiple opacities [18]; simple\nand small lesions are extremely difficult to detect [19], table 1\nillustrates some of these works."}, {"title": null, "content": "DL-based models have also shown potential for detecting\nnodules/masses on chest radiographs [20-23], with\nsensitivities ranging from 0.51-0.84 and a mean number of FP\nindications per image (mFPI) of 0.02-0.34. Furthermore,\nradiologist performance at identifying nodules was improved\nwith these CAD models than without them [20]."}, {"title": null, "content": "The topic of Triage to Normal/Abnormal is a commonly\nstudied subject in medical imaging. Studies in this area aim to\ndistinguish normal chest x-rays (CXRs) or prioritize\nurgent/critical cases to reduce the radiologist's workload or\nimprove the reporting time. To develop a triaging workflow,\nTang et al [24] compared the performance of various deep\nlearning models applied to several datasets to distinguish\nabnormal cases."}, {"title": null, "content": "A large proportion of the studies use pre-trained standard\narchitectures that can easily be found in deep learning\nlibraries. These architectures are commonly Resnet [25],\nDenseNet [26], MobileNet [27]. The choice of model depth\n(such as ResNet-18, ResNet-50, DenseNet-121, DenseNet-\n161) also varies between studies as there is no standard in this\ndesign choice. Most of those studies do not introduce\nmethodological novelty but report or compare the\nperformances of multiple architectures on a given task.). Some\nstudies bring methodological novelty by making use of\nmethods that are known to work well to improve model\nperformance elsewhere. For example, it is known that an\nensemble of many models improves performance compared to\na single model, some studies that make use of this method are\nSouid et al [23], Sakli et al [6], those models aim to improve\nperformance and add localization capabilities to an image\nlevel prediction model. The work of Bharti et al [28] propose\na combination of Conv NN and Spacial Transformer network,\nthe method achieves 73% of accuracy. The research presented\nby Boyang and Wenyu [29] illustrates the efficiency of multi-\nscale adaptive residual network to identify four pulmonary\npathologies. The model achieves 0,97 AUC."}, {"title": null, "content": "The work presented in this paper proposes a robust method\nfor detecting anomalies in chest X-rays and identifying\nmultiple lung nodules and masses associated with pulmonary\ndiseases. This is achieved through the use of a convolutional\nneural network on multiple stages. Additionally, data\nimbalances are addressed through transfer learning and\nweighted loss to optimize models for anomaly detection,\nmulticlass classification, and specifically lung cancer\nprediction. The proposed method offers promising results in\nthe accurate detection of abnormalities in chest X-rays and\nholds great potential for improving the diagnosis and\ntreatment of pulmonary diseases, particularly lung cancer."}, {"title": "III. METHODOLGY", "content": "The presented work employs a modular two-stage\ndetection system that leverages IoT and edge computing\ntechnologies for the analysis of chest X-rays. The initial stage\nfocuses on anomaly detection, while the subsequent stage\ninvolves detecting eight distinct lung pathology classes using\nmultiple weights. A crucial aspect that enables the success of\nthis work is the utilization of a large dataset, as deep learning\nmodels tend to excel when trained on extensive data. figure 1\nprovides an overview of the IoT and edge computing\narchitecture used in this application. The architecture\nencompasses interconnected devices, sensors, and edge\nnodes that facilitate real-time data processing and analysis at\nthe edge of the network, minimizing latency and optimizing\nresource utilization. This architecture enhances the efficiency\nand effectiveness of analyzing chest X-rays by enabling rapid\nand localized data processing"}, {"title": "A. Overview", "content": "EfficientNet is a family of efficient Convolutional Neural\nNetworks (CNNs) designed to improve accuracy while\nreducing the number of parameters, computation, and memory\nusage required to perform image classification tasks. The\nmain concept behind Efficient-Net is to balance the scaling of\nnetwork dimensions which leads to improved accuracy and\nlow computational complexity. These models have been\nproven to achieve state-of-the-art performance on various\nbenchmark datasets for image classification tasks, as well as\nbeing capable of adapting to other vision-related tasks [30].\nThe presented work uses EfficientNetB0 [30] for the\nabnormality triage, also the transfer learning strategy is been\nused in this work, figure 2 illustrates the architecture including\nthe training procedure which will be further explained in next\nsection."}, {"title": null, "content": "The model pipeline, as depicted in figure 1, is capable of\nprocessing both PACS data streams and individual samples.\nThe first model within the pipeline examines the presence of\nabnormalities in the provided CXRs. In case abnormalities\nare identified, the second model is triggered for further\nanalysis. Upon completion of the pipeline cycle presented in\nthe figure 2, the model generates predictions related to\nabnormality and various pathologies, with a particular focus\non lung cancer, including masses, nodules, and seven other\npathologies. This approach exhibits promising outcomes in\naccurately identifying abnormalities and pathologies related\nto the lungs, thereby showcasing significant potential for\nenhancing the diagnosis and treatment of pulmonary\ndiseases."}, {"title": "B. Dataset presentation", "content": "Training abnormality detection models or any deep\nlearning models require a proper architecture and an important\nnumber of samples as a set of data. For this task, chosing to\nwork with the VinDr-CXR by Ha Q. Nguyen et al. [31], This\ndataset is open source and consists of 18,000 chest\nradiographs in total, subdivided into the training set and test\nset, and text mined with fourteen disease image labels. This\ndataset is extremely useful for calibrating the number of\ndistributions of certain classes. For the second model, eight\nclasses of lung diseases are considered in this paper. Wang et\nal. [32] proposed Chest-x-ray 8 one of the largest open-source\ndata sets by comprise 108,948 frontal view chest radiographs\ncollected from 32,717 unique patients with eight disease\nimage labels. Furthermore, Wang et al. [32] expanded the\nChest-x-ray 8 to include 112,120 scans, and 14 pathologies\nlabels that were text mined. They included \"No Finding\" for\nsamples that did not have an illness. \"Infiltration, Mass,\nNodule, Pleural Thickening, Atelectasis, Cardiomegaly,\nConsolidation, Edema, Effusion, Emphysema, Fibrosis,\nHernia, Pneumonia, and Pneumothorax\" are the diseases.\nHowever, this dataset is weighted with several faults,\nbeginning with a large class unbalance caused by an\nunmatched number of normal samples. A second issue is a\nlarge number of uncommon classes, such as Hernia and\nPneumonia, which include fewer than a thousand examples.\ncombing two other datasets to address these problems, the first\ndataset is the OTC and Chest-X-ray dataset by KS. Daniel et\nal. [33], comprises two sets one for the OCT and the other\nchest-x-ray, our interest is focused on the chest-x-ray set,\nwhich comprises 5,863 chest radiograph text mined in 2\ncategories \"Normal and Pneumonia\", as it is clear by now our\naim is from using this dataset is to boosting the distribution\nfrequency of Pneumonia class. Then used the VinDr-CXR by\nHa Q. Nguyen et al. [31], which is implemented for training\nthe first model. There is still some drawback for this method\nas it is not possible to leverage the metadata contained in both:\nVin-Dr-CXR and Chest-x-ray 14 and OTC and Chest-x-ray\ndataset due to big differences in the metadata starting the data\ntype: Vin-Dr-CXR and Chest-x-ray 14 and OTC and Chest-x-\nray dataset owing to significant changes in metadata\nbeginning with the data type: The Vin-Dr-CXR comes in\nDICOM format, but the other two datasets come in JPEG\nformat, which is a significant difference that can't be rely on.\nSecond, as previously stated, the Vin-Dr-CXR and chest-x-ray\n14 share some of the listed pathologies but not all of them, so\nchoosing between using the full dataset and having 17 classes\nor reducing the number of pathologies. For this work,\nacquiring the following eight lung diseases: \"Atelectasis,\nCardiomegaly, Consolidation, Nodule/Mass, Pleural\nthickening, Pneumothorax, Pulmonary fibrosis, and\nPneumonia."}, {"title": "C. Dataset processing and augmentation", "content": "Each model required a specific data processing\nmethodology, even the datasets have a relatively common\npathologies category. Starting with the general abnormality\nmodel, originally the dataset comprises 15 classes with a\nrelativity small data distribution compared to the NIH dataset,\nwhich is convenient in our case for the model to be familiar\nwith the maximum number of cases. The dataset was provided\nin the DCIOM format which added some additional time to\nprocess the data and explore any utility of the meta-data stored\nwithin the DCIOM files. To reduce the classes dimension, a\nPCA was applied. One other important side was the clarity of\nthe scans which was absent in some samples, addressing this\nissue by implementing the Contrast limited adaptive\nhistogram equalization (CLAHE) [34], Hence using transfer\nlearning-based architecture to enhance model performance,\nthe training data were converted into channels instead of one\nchannel, also training deep learning requires heavy computer\ncomputation and time consumption, hence reducing the size\nof the images from (512, 512) to (224, 224)."}, {"title": null, "content": "For the second model, applying the required data cleaning\nsuch as detecting the existence of outliers, preventing data\nleakage, and sanity check for each class. Then, the\nreformulated dataset is split into three subsets the biggest one\nfor training, the second one the validation, and the last small\nsubset used to test the model performance."}, {"title": null, "content": "Data augmentation is a valuable technique for reducing\nmodel overfitting by increasing the amount of data training\nand introducing various distortions and noise to the training\ndata. On photos, using four types of data augmentation\ntechniques: horizontal flip, brightness, and contrast, random-\nsized crops, and, normalizing the pixel values of images so the\nrange of pixel intensity values is between 0 and 255.To\naddress the data unbalanced, we had modified the across-\nentropy loss present in equation 1 by adding a positive wight\nand a negative eight."}, {"title": null, "content": "$Lcross-entropy - (Wp log(1 \u2212 f(x)))$"}, {"title": null, "content": "Where the positive weight wp multiplied by the positive\nfrequency of each class freqp to be equal to the negative weight\nwn, multiplied by the negative frequency freqn of each class\npresented in the formula"}, {"title": null, "content": "$Wp \u00d7 freqp = Wn \u00d7 freqn$"}, {"title": null, "content": "And N is the total number of patients."}, {"title": "D. Pipeline models architectures", "content": "Both models chares some similar specification, the two\nproposed model uses the EfficientNet, however each model\nhave his own role in the all-in pipeline."}, {"title": "\u2022 Efficient Net Architecture", "content": "The EfficientNet [30] is a collection of models based on\nthe baseline network described in table 1. Its main component\nis the Mobile Inverted Bottleneck Conv (MB-Conv) Block,\nintroduced in [27] and shown in Fig 1. The EfficientNet\nConvolutional Network family is based on the idea of starting\nwith a high-quality yet compact baseline model and uniformly\nscaling each of its dimensions systematically with a fixed set\nof scaling coefficients, both of the presented model uses\nEfficientNet CNN as a base. the time complexity of the\nConvolutional layer is O (k.n.d\u00b2), However, as mentioned\nprior, EfficientNet use NAS architecture (Neural Architecture"}, {"title": "Search)", "content": "and also added classification layers, so time\ncomplexity becomes not easy to calculate."}, {"title": null, "content": "was gradually reduced to 0.01e-3 using the ReduceL-\nROnPlateau scheduler."}, {"title": null, "content": "The model was initially trained by fixing all the layers of the\npre-trained model and training it for 15 epochs, where each\nepoch had half the number of steps. This was followed by a\nsecond training phase, where the model was fine-tuned for\nanoth-er 15 epochs. An examination was conducted on the 0.5\nthreshold to improve accu-racy and enable the model to\ngeneralize better."}, {"title": "E. Modules Evalution", "content": "Both experiments were evaluated using receiver operating\ncharacteristic. To measure the quality of predictions of the\npresented models, it is highly relevant to calculate the\nevaluation metrics namely the sensitivity, specificity,\naccuracy, and AUC of ROC (Area Under the Curve Receiver\noperating characteristic). All the training and testing are made\non Google Colab [35] instance with 1 V-GPU with 15 GB of\nRAM and 1 CPU for 16 GB of RAM:"}, {"title": null, "content": "$precision = \\frac{TP}{TP + FP}$"}, {"title": null, "content": "$Sensitivity = \\frac{TP}{TP + FN}$"}, {"title": null, "content": "The TP, FP, and FN refers to True Positive, False Positive,\nand False Negative. The Fl1-score is calculated using the\nfollowing formula:"}, {"title": null, "content": "$F1-score = 2 \\times \\frac{precision \\times recall}{precision + recall}$"}, {"title": "IV. EXPERIMENTAL RESULT AND DISCUSSION", "content": "A. Results Evaluation\nReviewing the model's performance revealed some\nnotable results. The first model was trained on 20 epochs with\nAdam optimizer and categorical cross entropy loss, viewing\nthe model accuracy curve presented in the figure 5 we notice\nsome sign of plausible overfitting, in general the model\naccuracy got 94% during training/validation and 93% on 3000\nexternal test set."}, {"title": null, "content": "To further investigate the model performance, we calculate the\nconfusion matric illustrated in the figure 6. The results of the\nclassification were very acceptable, 246 images over 3000\nimages were miss classified. Also, calculating the precision,\nrecall and F1-score based on the test data, the model achieves\n93% of precision for normal and abnormal cases, the model\nalso achieved the highest F1-score for the abnormal cases with\n95%, table 2 illustrate the described results. Other metrics\nresults were presented in the table."}, {"title": null, "content": "In our assessment, we discovered a large dispersion of\nfindings compared to AUC values. In addition to the loss\nfunction, this might result from the random initialization of the\nmodels and the stochastic nature of the optimizer."}, {"title": null, "content": "The EfficientNet B1 indicates that having more features\nimproves total model performance based on the loss value.\nThe performance metric on EfficientNet B1 during training\nshows 0.265 in training and 0.245 invalidations for Loss,\nAccuracy with between 76% and 95% class-wise, 81,5% for\nsensitivity, 80,8% for Specificity, and 0,888 for AUC, table 1\nshows the individual results, and Fig 7 shows the Receiver\nOperating Characteristic for the AUC."}, {"title": "B. Discussion", "content": "Overall, Overall, the combination is very promising for\nreal-world accurate prediction, meaning that if the second\nmodel did not detect the correct abnormality, the pipeline is at\nleast capable to recognize whether abnormality exists or not\nwhich is the role of the first model. For the second model,\naccording to the obtained results from the evaluation process,\nwe would like to say that the model gets good performance\ntoward the detection specific classes that are presenting Lung\ncancer: the mass and Nodule, the had proven its efficiency to\ndetect lung nodule/mass w To begin, we compared the\nobtained results to those by Wang et al [32]. While DenseNet\n121 have a superior individual AUC in 8 out of 8 disease\nclasses, EfficientNet B1 has a 30% improvement in more than\nthree of them. Baltruschat et al [36] are among those who have\ncontributed to this study. While our model was trained with\nfewer epochs, it nevertheless produced good results for\n\"Atelectasis, Cardiomegaly, Pleural thickening, Pulmonary\nfibrosis, and Pneumonia\" as well, a slightly higher average\nAUC of 0.888. The EfficientNet B1 is more generic; three\nclasses surpass the 0.9 AUC score, and the GradCam [37]\nVisualization is quite precise even for picture resolutions of\n224,224, the figure 9 illustrate some of the test examples. The\nEfficientNet B1 also achieves extremely acceptable results\nwhen compared to other state-of-the-art studies, such as Wang\net al [32] with an AUC value of 0.745 and Baltruschat et al\n36] with an AUC of 0.806, as well as table 3 present\nindividual AUC diseases comparison."}, {"title": null, "content": "When applying the Gradient class activation map, the model\ndoes a decent job by highlighting the region of interest\ncorrelated with the prediction label, the model is capable of\nlocalizing the predicted pathology even with low prediction\nprobability, this indicates how far the presented model can\nexplain the prediction also the fairness of the model."}, {"title": "CONCLUSION", "content": "Based on the findings, we believe that our deep learning-\nbased CAD might help radiologists improve the accuracy of\ntheir diagnosis of a wide range of pulmonary lesions. In an\nemergency situation where, expert radiologists are either\noverworked or unavailable, a deep learning system, for\nexample, can speed up image interpretation. Although it can\nimprove interpretation accuracy, our method should only be\nused to supplement diagnoses of pulmonary problems."}, {"title": null, "content": "We found also that implementing 2 stage detection the\nradiologist has less chance to skip pulmonary abnormalities,\nalso the model not only can detect the listed pathologies but\nalso can discover rare classes due to these combinations."}, {"title": null, "content": "Concerning evaluation, the proposed approach brought\nimprovements compared to others' work, with an overall\nAUC of 0.888 and AUC of lung Mass/Nodule of 0.835,\nSpecificity of 77. 6%, and sensitivity of 71.3%, and with less\nthan 16 epochs."}, {"title": null, "content": "Our research has significant limitations. To begin with, it\ndid not use the complete dataset, which had over fifteen\ndiseases. Second, no expert comparisons were included in our\nanalysis because it was a feasibility study. Third, the\ndiscrepancy between the AUC and the accuracy needs more\nstudy, which necessitates the usage of other measures. There\nwere many approaches to handle the imbalanced dataset, and\nit was necessary to investigate the efficiency differences\nbetween the strategies."}]}