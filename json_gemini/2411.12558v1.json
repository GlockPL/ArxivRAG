{"title": "Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework", "authors": ["Ismail Nejjar", "Hao Dong", "Olga Fink"], "abstract": "Open-set Domain Adaptation (OSDA) aims to adapt a model from a labeled source domain to an unlabeled target domain, where novel classes also referred to as target-private unknown classes - are present. Source-free Open-set Domain Adaptation (SF-OSDA) methods address OSDA without accessing labeled source data, making them particularly relevant under privacy constraints. However, SF-OSDA presents significant challenges due to distribution shifts and the introduction of novel classes. Existing SF-OSDA methods typically rely on thresholding the prediction entropy of a sample to identify it as either a known or unknown class but fail to explicitly learn discriminative features for the target-private unknown classes. We propose Recall and Refine (RRDA), a novel SF-OSDA framework designed to address these limitations by explicitly learning features for target-private unknown classes. RRDA employs a two-step process. First, we enhance the model's capacity to recognize unknown classes by training a target classifier with an additional decision boundary, guided by synthetic samples generated from target domain features. This enables the classifier to effectively separate known and unknown classes. In the second step, we adapt the entire model to the target domain, addressing both domain shifts and improving generalization to unknown classes. Any off-the-shelf source-free domain adaptation method (e.g., SHOT, AaD) can be seamlessly integrated into our framework at this stage. Extensive experiments on three benchmark datasets demonstrate that RRDA significantly outperforms existing SF-OSDA and OSDA methods. The source code is publicly available\u00b9.", "sections": [{"title": "Introduction", "content": "Unsupervised Domain Adaptation (UDA) (Ben-David et al. 2010; Ganin and Lempitsky 2015; Long et al. 2015) adapts a model from a labeled source domain to an unlabeled target domain (Oza et al. 2023), effectively addressing the issue of domain shift where the source and target distributions differ. UDA strategies typically align feature distributions between domains using metric learning techniques (Long et al. 2015; Kang et al. 2019) or adversarial training (Ganin and Lempitsky 2015; Tzeng et al. 2017; Luo et al. 2019), and more recently, self-training approaches (Sun et al. 2022; Hoyer et al. 2023; Zhu, Bai, and Wang 2023). Despite their success, most current domain adaptation approaches operate under the assumption of a shared label set between the source and target domains (i.e., Cs = Ct), referred to as Closed-set Domain Adaptation (Saenko et al. 2010). However, this assumption is often impractical in real-world scenarios.\nIn contrast, Open-set Domain Adaptation (OSDA) extends the target label space beyond that of the source domain (i.e., C's \u2288 Ct) (Saito et al. 2018; Liu et al. 2019), thereby adding complexity to the DA task. OSDA aims to align target samples from known classes with those from the source domain while effectively identifying target samples belonging to categories not observed in the source domain, referred to as unknown classes (Panareda Busto and Gall 2017; Bucci, Loghmani, and Tommasi 2020; Jang et al. 2022). Various criteria based on instance-level predictions have been proposed, including entropy-based (Feng, Xu, and Tao 2021; Saito et al. 2020) and confidence-based (Saito and Saenko 2021; Fu et al. 2020) methods.\nAdditionally, privacy and legal considerations increasingly limit access to labeled source data for adaptation purposes. To address this, source-free adaptation methods (Fang et al. 2024) have emerged, enabling adaptation without reliance on labeled source data (Kim et al. 2021; Kundu et al. 2020a; Li et al. 2020). In this paper, we focus on Source-free Open-set Domain Adaptation (SF-OSDA), where only a pre-trained source model is available for knowledge transfer, without access to labeled source data. While some Source-free Domain Adaptation (SF-DA) methods have demonstrated effectiveness in addressing SF-OSDA for classification tasks (Liang, Hu, and Feng 2020; Yang et al. 2022; Wan et al. 2024), semantic segmentation (Choe et al. 2024), and graph applications (Wang et al. 2024), they primarily focus on the semantics of known classes in the source domain, often overlooking the crucial aspect of novel-class semantics. These methods focus on segregating target samples with low entropy, categorizing them as known classes, and subsequently optimizing specific objectives such as entropy minimization or clustering. In this process, data points associated with known classes are prioritized, while those with high entropy are typically excluded from training, leading to a semantic disparity between the known and unknown classes.\nTo effectively adapt a pre-trained source model to a target domain facing both category and distribution shifts, we propose Recall and Refine for Domain Adaptation (RRDA) for"}, {"title": "Methodology", "content": "robust SF-OSDA. RRDA employs a two-step strategy. First, we propose to leverage the semantics of the unknown classes by introducing a novel target classifier with K+ K' decision boundaries. These boundaries extend the K classes from the source domain with K' additional classes for the unknown categories. To achieve this, synthetic samples are generated in the feature space from target domain features. These synthetic points are optimized to exhibit low entropy for known classes and high entropy for unknown classes, which are then clustered into K' categories. The synthetic data are used to refine the decision boundaries of the source classifier, enabling the target classifier to accommodate the unknown classes. In the second step, any off-the-shelf source-free domain adaptation method (e.g., SHOT (Liang, Hu, and Feng 2020), AaD (Yang et al. 2022)) can be integrated into our framework to adapt the entire model to the target domain. RRDA directly learns to classify target unknown classes. The framework introduces K' as a hyper-parameter, which we set to K' = K for simplicity. Sensitivity analysis shows that performance improves with higher values of K', though results remain robust across a range of settings. Extensive experiments on three SF-OSDA benchmark datasets demonstrate the effectiveness of our approach, significantly outperforming existing methods.\nFor SF-OSDA, we are given a source pre-trained model $f_s$ and an unlabeled target domain with $n_t$ samples, denoted as $D_t = \\{(x_i)\\}_{i=1}^{n_t}$, where $x_i \\in \\mathcal{X} \\subset \\mathbb{R}^X$. The target domain follows a distinct data distribution ($P_t \\neq P_s$) from the source domain, reflecting both distribution and label shifts. Let $C_s$ and $C_t \\subset \\mathcal{Y}$ represent the label sets for the source and target domains, respectively, where $C_s \\subset C_t$. Both domains share $K$ common classes referred to as known classes ($C_s = C_k$). Additionally, the target domain includes target-private novel classes, jointly considered as a single unknown class ($C_{unk} = C_t \\backslash C_s$).\nThe primary objective of SF-OSDA is to classify both unknown and known classes, relying exclusively on the target domain data and a pre-trained source model. The pre-trained model can be decomposed as $f_s = h_s \\circ g_s$, where $h_s : \\mathbb{R}^X \\rightarrow \\mathbb{R}^D$ is a feature extractor and $g_s : \\mathbb{R}^D \\rightarrow \\mathbb{R}^K$ is the source classifier. Unlike previous works, which freeze the source classifier (e.g., SHOT) during adaptation, we propose training a new target classifier $g_t$ to explicitly account for target-private unknown classes.\nOne of the challenges in open-set scenarios is the ability to distinguish known from unknown classes in the target domain. Different approaches have been proposed for distinguishing between known and unknown classes, including hand-crafted thresholding criteria and clustering strategies. However, paradigms such as vendor-to-client (Kundu et al. 2020c) are more effective, as they incorporate an auxiliary out-of-distribution classifier during source training, enabling better handling of unknown classes in the target domain.\nIn this paper, we propose a novel approach to address this limitation by adapting the source classifier post hoc to include new decision boundaries for unknown classes. Our method enables the seamless adaptation of any off-the-shelf source pre-trained model to a target domain, even in the presence of novel classes. Motivated by the idea that learning from unknown class samples can improve performance in open-set scenarios, our objective is to simplify adaptation and eliminate the dependency on threshold-based methods during inference."}, {"title": "RRDA", "content": "Our proposed Recall and Refine framework for SF-OSDA consists of three main steps:\nSynthetic Data Generation: Referring to step (b) in Figure 1, synthetic feature points are generated for both known and unknown classes. This involves optimizing target feature representations using entropy objectives.\nTarget Classifier Training: Referring to step (c) in Figure 1, the synthetic feature points are used to train a new target classifier $g_t$ with extended decision boundaries to accommodate unknown classes.\nTarget Domain Adaptation: The entire model is adapted using any off-the-shelf source-free domain adaptation methods (e.g., SHOT, AaD) on target domain data.\nThis allows the model to (1) learn the semantics of both known and unknown classes in the target domain, (2) treat OSDA as a simple closed-set scenario, and (3) directly output predictions for unknown classes.\nThe first step of our proposed approach involves generating synthetic features for both known and unknown classes using the source classifier $g_s$. Specifically, we optimize the target feature representation $z_t = h(x_t)$ to generate synthetic samples that exhibit low entropy for known classes and high entropy for the unknown class. We denote these optimized synthetic features as $z_k^*$ and $z_{unk}^*$. The unknown features are then clustered in K' classes, and a new target classifier $g_t$ is introduced"}, {"title": "Synthetic Data Generation", "content": "with K+ K' classes. In this section, we describe the process for obtaining feature representations for both known and unknown classes. We use standard gradient descent optimization to generate the desired feature representations.\nSynthetic Unknown Classes Generation: To effectively identify points near the source classifier's decision boundary, we aim to find $z^*_{t_{unk}}$ that maximizes entropy while ensuring diverse feature representations, thereby reducing the risk of collapsing to a single-point representation. To prevent feature collapse, we introduce a variance regularization term in the form of a hinge function applied to the standard deviation of features across the batch dimension. Specifically, we initialize the optimization with a noisy version of the original features $z_t$. This process is formulated as follows:\n$\\min\\limits_{z_t} -H(\\sigma(g_s(z_t))) + \\lambda \\cdot \\max(0,1 - \\sqrt{Var(z_t)}),$ (1)\nwhere $H(p) = - \\sum\\limits_{k=1}^{K} p_k \\log(p_k)$ represents the entropy, and $\\sigma$ is the softmax activation function, and $\\lambda$ was set to 1 for all the experiments. After optimization, only the points satisfying $H(g(z_t)) > 0.75 \\cdot \\log(K)$ (see Ablation section for threshold discussion) are considered as $z^*_{t_{unk}}$. The selected features $z^*_{t_{unk}}$ are then clustered into K' unknown classes using K-means. Each cluster is assigned a pseudo-label corresponding to a new class index, $Y_{unk} \\in \\{K + 1, ..., K + K'\\}$, representing the specific unknown class assigned to the synthetic features. These synthetic features and their associated pseudo-labels $(z^*_{t_{unk}}, Y_{unk})$ will be used in the subsequent training of the target classifier.\nThis approach is motivated by the observation in the literature (Lampert, Nickisch, and Harmeling 2009) that it is possible to generate meaningful semantics for novel classes using known classes.\nSynthetic Known Classes Generation: A similar optimization approach is employed to generate synthetic data points for the known classes. The optimization is performed iteratively K times, once for each known class k (where k\u2208 [1, ..., K]). The objective is to minimize the cross-entropy for each class directly from $z_t$. The optimization problem for generating a sample for class k is defined as:\n$\\min\\limits_{z_t} L_{CE}(g(z^*_t), I_k) + \\lambda \\cdot \\max(0,1 - \\sqrt{Var(z_t)}),$ (2)\nwhere $I_k$ is the identity function for the k-th class (i.e., a one-hot vector), and $\\lambda$ controls the regularization term, set to 1 in all experiments. After optimization, only the points satisfying $L_{CE}(g(z_t), I_k) < 0.25 \\cdot \\log(K)$ (see Ablation section for threshold discussion) are considered as $z_k^*$. Each selected synthetic feature $z_k^*$ is assigned the pseudo-label $y_k = k$, forming the pairs $(z_k^*, y_k)$. These synthetic data points and their corresponding pseudo-labels are then used to train the target classifier. By iteratively generating feature points for each known class, our method enhances the decision boundaries without requiring access to the original source data or labels."}, {"title": "Target Classifier Training", "content": "In the second step, we introduce a new target classifier $g_t$ with K + K' classes, where K is the number of known classes and K' is the number of unknown classes. The weights for the known classes $g_t[1:K]$ are initialized using the source classifier's weights $g_s$, while the weights for the unknown classes $g_t[K+1:K+K']$ are randomly initialized. The target classifier $g_t$ is trained using the synthetic feature-label pairs for the known classes $(z_k^*, t_k)$ for $k \\in \\{1, ..., K\\}$, and the unknown classes $(z^*_{t_{unk}}, Y_{unk})$. The supervised training objective is defined as:\n$\\min L_{CE}(g_t(z^*_t), \\hat{y}^*_t),$ (3)\nwhere $z^*_t$ represents the combined synthetic features for both known and unknown classes, and $\\hat{y}^*_t$ represents their corresponding labels. The results of the previous steps, including the refined decision boundaries achieved by RRDA, are illustrated in Figure 2."}, {"title": "Target Domain Adaptation", "content": "Any source-free unsupervised domain adaptation method (originally designed for closed-set scenarios) can be integrated into our approach to address open-set scenarios, provided it incorporates a diversity loss or a similar mechanism to facilitate self-learning of unknown classes. To empirically validate this hypothesis, we consider SHOT (Liang, Hu, and Feng 2020) and AaD (Yang et al. 2022), using their respective training objectives for adaptation. SHOT (Liang, Hu, and Feng 2020) employs information maximization and self-supervised pseudo-labeling to adapt the source model to the target domain. Its objective function can be expressed as:\n$\\mathcal{L}_{shot} = \\frac{\\lambda_{Ent}}{n_t} \\sum_{i=1}^{n_t} \\sum_{k=1}^{K+K'} p_{k,i} \\log p_{k,i} + \\lambda_{Div} \\cdot \\sum_{k=1}^{K+K'} \\hat{p}_k \\log \\hat{p}_k + \\lambda_{ps} \\cdot \\mathcal{L}_{pseudo},$\nwhere $p_k = \\frac{1}{n_t} \\sum_{i=1}^{n_t} p_k(x_i; \\theta)$, and $\\mathcal{L}_{pseudo}$ is the pseudo-labeling loss function from (Liang, Hu, and Feng 2020). During adaptation, only the feature encoder is updated while the classifier remains frozen. AaD (Yang et al. 2022) leverages local consistency and global dispersion. The objective function for feature i is formulated as:\n$\\mathcal{L}_{AaD,i} = - \\sum_{j \\in C_i} p_j + \\frac{1}{\\vert B_i \\vert} \\sum_{m \\in B_i} p_m,$\nwhere $C_i$ represents the local neighborhood of feature i and $B_i$ is the mini-batch feature not in $C_i$. Unlike SHOT, AaD updates the entire model weights during adaptation."}, {"title": "Experimental Setup", "content": "Datasets. Office-Home (Venkateswara et al. 2017) comprises 65 labeled image categories from four distinct domains: Art (Ar), Clipart (Cl), Product (Pr), and Real World (Rw). We designate the first 25 alphabetically ordered categories as known classes, with the remaining 40 as unknown. Office-31 (Saenko et al. 2010) consists of 31 classes across three domains: Amazon (A), Dslr (D), and Webcam (W). We assign the first 10 as known and the last 10 classes as unknown. VisDA (Peng et al. 2017) have 12 categories across"}, {"title": "Ablation Study and Sensitivity Analysis", "content": "Optimization Process. We conducted ablation studies on Office-31 with three different settings to train the new classifier. The results are shown in Table 4. We compare the following scenarios: (1) selecting target features based on entropy threshold without optimization, (2) optimizing entropy without hinge loss for diversity, and (3) the full proposed method optimizing feature points based on entropy and diversity. Our findings are as follows: (1) Using target features based on entropy directly to train the target classifier leads to the worst results in terms of HOS. SHOT-O achieves an HOS of 88.2 %, while using features directly without optimization achieves an HOS of 86.5%. (2) Optimizing the points significantly improves performance. There is a slight additional improvement when using hinge loss during optimization to promote diversity. (3) The full proposed method, which optimizes feature points based on both entropy and diversity, yields the best performance. We used SHOT for adaptation in the experiment as it keeps the classifier frozen, allowing for a direct performance comparison with the new classifier.\nThreshold Sensitivity Analysis. To further analyze the hyperparameter sensitivity and its impact on performance, we examined the effect of varying the entropy threshold used for feature selection during the optimization process. The thresholds were evaluated on the A2D task (ref Table 5).\nWe observe that the best-performing threshold on this task is T = 0.1. However, the HOS score remains consistent across different thresholds. For larger datasets, such as VisDA, where the domain shifts are more significant, lower thresholds (e.g., T = 0.1) can result in highly imbalanced datasets, with some classes being excluded entirely. For example, under such thresholds, a subset of classes may not meet the selection criteria. To ensure consistency across all datasets while maintaining a balanced feature distribution,"}, {"title": "Conclusion", "content": "we report results using T = 0.25 throughout the experiments. This threshold provides a balance between maintaining sufficient class representation and achieving competitive performance, particularly in scenarios with significant domain shifts.\nVarying Unknown Classes. We investigated the robustness of our framework against an increased number of unknown private classes, which complicates the distinction between known and unknown classes. We compared our method to LEAD, SHOT-O, and AaD-O on the Office-31 dataset. As shown in Figure 3a, our RRDA method in combination with SHOT and AaD achieves stable results and consistently outperforms existing approaches. For consistency with our main results, we kept K\u2032 fixed at 10.\n. Figure 3b shows adaptation performance for different K\u2032 values of the target classifier on Office-31 dataset. The performance improves as K\u2032 increases, validating the benefit of inheriting class separability knowledge, before eventually reaching a plateau. In fact, K\u2032 = 15 yields the best results. For the main experiments, we reported Office-31 results using K\u2032 = K = 10.\nillustrates the training curves for the A2W task on the Office-31 dataset. Our method shows consistent HOS improvement on the test set, with steadily increasing before plateauing. In contrast, AaD-O exhibits unstable training, with noticeable performance fluctuations throughout the training process.\nSpace Visualization. Figure 4 shows t-SNE embeddings of pre-classifier features for the source-only model, AaD-O, and our method on the A2W task on the Office-31 dataset. The source-only model (Figure 4a) exhibits well-separated known class clusters but mixes unknown samples with known classes. AaD-O (Figure 4b) slightly improves known-unknown separation, but class overlap remains. Our method (Figure 4c) achieves superior separation of known and unknown classes, maintaining tight, well-defined known class clusters while isolating unknown samples. This demonstrates our method\u2019s effectiveness in inheriting class separability during adaptation.\nIn this work, we introduce Recall and Refine for Domain Adaptation (RRDA), a simple but effective framework for SF-OSDA. RRDA enables the successful adaptation of offthe-shelf source pre-trained models to target domains, effectively addressing both distribution and category shift problems. RRDA achieves this by introducing a new target classifier that aids in classifying and learning the semantics of both known and unknown classes. This approach enables the direct use of source-free adaptation methods designed for closed-set scenarios in open-set contexts. Extensive experiments on three challenging benchmarks demonstrate that RRDA significantly outperforms existing SF-OSDA methods and even surpasses OSDA methods that have access to the source domain. Future work could explore its potential for continuous adaptation in the setup where new classes appear over time."}]}