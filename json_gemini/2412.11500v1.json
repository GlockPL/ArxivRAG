{"title": "Intention Knowledge Graph Construction for User Intention Relation Modeling", "authors": ["Jiaxin Bai", "Zhaobo Wang", "Junfei Cheng", "Dan Yu", "Zerui Huang", "Weiqi Wang", "Xin Liu", "Chen Luo", "Qi He", "Yanming Zhu", "Bo Li", "Yangqiu Song"], "abstract": "Understanding user intentions is challenging for online platforms. Recent work on intention knowledge graphs addresses this but often lacks focus on connecting intentions, which is crucial for modeling user behavior and predicting future actions. This paper introduces a framework to automatically generate an intention knowledge graph, capturing connections between user intentions. Using the Amazon m2 dataset, we construct an intention graph with 351 million edges, demonstrating high plausibility and acceptance. Our model effectively predicts new session intentions and enhances product recommendations, outperforming previous state-of-the-art methods and showcasing the approach's practical utility.", "sections": [{"title": "Introduction", "content": "Understanding user intentions behind behaviors poses a significant challenge for online platforms. Recent research has introduced the concept of intention knowledge graphs (Yu et al., 2023, 2024) to address this issue. These graphs connect various user behaviors, such as co-purchasing (Yu et al., 2023) and queries (Yu et al., 2024), to their corresponding intentions expressed in natural language. intention knowledge graphs have proven valuable in applications like product recommendation (Yu et al., 2023) and search relevance (Yu et al., 2024). Users often have specific intentions, such as preparing for a Halloween party. They may want to dress up as a vampire or werewolf and create a spooky atmosphere with decorations. However, these intentions are often only implicitly suggested by actions, such as the items shown in Figure 1 (A). Previous attempts at constructing intention knowledge graphs have focused on using large language models to generate explanations for behaviors (Yu et al., 2023), utilizing sources like session history and query keywords (Yu et al., 2024). For instance, analyzing the browsing history of items can reveal the intention to dress up for Halloween.\nHowever, previous methods have not explored how intentions interrelate. Explicitly modeling these connections aligns with the shift towards System II 2 reasoning, emphasizing logical and sequential reasoning. Research has shown the importance of this reasoning in online behaviors (Kleinberg et al., 2022), where users focus on long-term rewards rather than unconscious browsing. Therefore, we aim to model explicit intention relations.\nOur goal extends beyond understanding initial intentions to predict subsequent ones. For example, intending to buy a desk might lead to buying an office chair. This inference can improve user behavior modeling and recommendations. However, building these connections is unexplored.\nCommonsense knowledge is crucial for modeling intention relationships. For example, planning a Halloween party requires understanding that costumes and decorations are likely intentions. We propose using commonsense relations to describe temporal and causal intention connections. After identifying intentions from user sessions, we use a classifier to determine inferential connections, enhancing our understanding of intention relationships. For instance, Figure 1 (B) demonstrates the plausible co-occurrence relationship between dressing up and decorating intentions.\nUsing inferential commonsense relations can be challenging to generalize to unseen situations. Concepts like conceptualization and instantiation help generalize commonsense reasoning (Wang et al., 2023b,a,c, 2024). We incorporate this into our knowledge graph, using models to conceptualize in-"}, {"title": "Related Work", "content": "Knowledge graphs (KGs) are crucial for enhancing recommendation systems on e-commerce platforms due to their structured and extensible nature. The Amazon Product Graph (Zalmout et al., 2021) exemplifies this by aligning Amazon's catalog with external KGs like Freebase (Bollacker et al., 2008), extracting numerous attributes across product types. This interconnected web of product data enables Amazon to offer personalized shopping experiences. Similarly, Alibaba's developments, such as AliCG (Zhang et al., 2021), AliCoCo (Luo et al., 2020), and AliMeKG (Li et al., 2020), leverage extensive e-commerce data for improved product recommendations and search capabilities. These KGs focus on item properties and categories without directly addressing the user motivations and intentions behind decisions. FolkScope (Yu et al., 2023) and COSMO (Yu et al., 2024) introduce intention knowledge graphs, incorporating user intentions from large language models and query-buy relations. However, they lack direct relations between"}, {"title": "IGC-RC Framework", "content": "We utilize the Amazon M2 dataset (Jin et al., 2023), focusing on the English subset with 1.2 million sessions, to generate user intentions. The session history, comprised of sequences of user-browsed products, is processed to extract attributes such as titles, descriptions, models, sizes, and colors. These details are compiled into a JSON file, serving as the input for our intention generation module.\nUsing GPT-3.5, we generate concise, informative, and diverse user intentions, totaling 4.3 million from the dataset. Our approach surpasses FolkScope by using an advanced language model and eliminating ConceptNet relation constraints, fostering a more diverse output. See Figure 3 in the appendix for our prompt designs."}, {"title": "Intention Relation Classification", "content": "A significant challenge is linking user intentions meaningfully. These intentions, often event-based, rely on commonsense knowledge to establish connections, such as understanding that purchasing a gift usually precedes celebrating Christmas (Speer et al., 2017; Sap et al., 2019; Hwang et al., 2021; Fang et al., 2021; Tandon et al., 2017).\nAs shown in Table 11, we first convert candidate edges into assertions using a template-based approach to achieve this. Then, the plausibility estimation model Vera (Liu et al., 2023a) evaluates these assertions. Finally, we set a plausibility threshold to add high-plausibility edges to the knowledge graph. We conducted binary classifica-"}, {"title": "Intention Conceptualization", "content": "A conceptualization provides an abstract, simplified view of a selected part of the world, encompassing objects, concepts, and relationships (Gruber, 1993; Himanen et al., 2019). Intention conceptualization extracts abstract concepts from user intentions to represent them in a knowledge graph, aiding e-commerce recommendation systems by modeling user intention dynamics.\nRecent studies (Wang et al., 2023b,a,c, 2024) primarily address entity and event conceptualization, leaving user intention conceptualization as an open challenge. Two main approaches exist: crowdsourced and large language model (LLM) annotations (Wang et al., 2024). While crowd-sourcing offers high-quality results, it is costly and limited in"}, {"title": "Intrinsic Evaluation", "content": "In this section, we evaluate the quality of the generated knowledge graph using both crowdsourced human annotations and automatic evaluations."}, {"title": "Human Evaluation", "content": "Annotators evaluate two aspects of the generated intentions: plausibility and typicality. Plausibility refers to the likelihood that an assertion is valid based on its properties, usages, and functions. Typicality measures how well an assertion reflects specific features influencing user behavior, such as informativeness and causality. For example, \"they are used for Halloween parties\" is more informative than \"they are used for the same purpose.\" We collected annotations for 3,000 session-intention pairs, each evaluated by three annotators. The inter-annotator agreement scores were 0.91 for plausibility and 0.74 for typicality. We use the same annotation guidelines and criteria from the FolkScope paper, and this can"}, {"title": "Automatic Evaluation", "content": "In this section, we systematically evaluate three key aspects: (1) Intention Prediction; (2) Conceptualization of New Intentions; and (3) Item Recovery."}, {"title": "Extrinsic Evaluation", "content": "Since our datasets are from the real-world Amazon M2 recommendation datasets, it is natural and necessary to validate the effectiveness of our work on the corresponding downstream tasks to show its usefulness. With this section, we demonstrate that our KG can provide extra information gain for session recommendation, which is also one of the major goals of the current KG."}, {"title": "Data Preparation", "content": "The whole English subset of the M2 dataset with our generated knowledge graph is utilized in this step for the session recommendation task. We split all sessions into train, validation, and test sets at a ratio of 8:1:1. Since the original dataset is preprocessed before release, we do not employ additional filtering operations to avoid the risk of session loss or false connections among items.\nSince all of the current session recommendation paradigms are difficult to integrate a million-level commonsense knowledge graph as we constructed in an end-to-end manner, we build upon an item relation graph based on it with meta-path methods to describe product relations. Specifically, we first gather all 1-hop session pairs where concepts or temporal relations directly connect their intentions. To alleviate redundant connection and noise, we only keep session pairs if (1) they have no less than six distinct meta paths passed through commonsense relation nodes or (2) one can reach the other from all of its 1-hop concept nodes. Then, we"}, {"title": "Graph Representations for Session Recommendation", "content": "Given the relation G, one can obtain item representations with various graph representation methods. We adopt the simple yet effective graph convolution operation to learn informative item representations, which is formulated as\n$E^{l+1} = AE$,\nwhere A is the adjacency matrix of G, $E \\in R^{N \\times d}$ is the d-dimensional embedding dictionary of all items. Canonical methods are utilized during graph representation learning, including light-weight convolution and sum pooling. After L-th convolution, the knowledge graph-based representations EL can be directly utilized in the recommendation tasks for enhancing performance.\nTo achieve end-to-end recommendation, we designed a Relational Intention Knowledge Graph-based recommender named RIGRec, which seamlessly integrates the graph representations learning module into the session recommendation framework. Concretely, the widely used attention-based method SASRec is adopted as our session encoder, which aggregates the learned knowledge graph-based item representations within each session for user preference estimation."}, {"title": "Baselines and Evaluation Metrics", "content": "We compare our model with following ten representative and state-of-the-art methods, covering (1) the classical method FPMC (Rendle et al., 2010), (2) the RNN-based method GRU4Rec (Hidasi et al., 2016), (3) the predominant attention-based methods including BERT4Rec (Sun et al., 2019), SASRec (Kang and McAuley, 2018), CORE (Hou et al., 2022) and FEARec (Du et al., 2023), (4) graph-based methods including SR-GNN (Wu et al., 2019b) and GCE-GNN (Wang et al., 2020), (5) side information fusion methods including SASRecF (Kang and McAuley, 2018) and DIF-SR (Xie et al., 2022). We exclude some state-of-the-art methods like FAPAT (Liu et al., 2023b) due to the need for massive support resources or exponential computation complexity.\nWe employ two standard evaluation metrics in the field of recommender systems, including Recall at a cutoff top k (Recall@k) and Normalized Discounted Cumulative Gain at a cutoff top k (NDCG@k). We rank the ground-truth item alongside all candidates to ensure an unbiased evaluation rather than adopting the negative sampling strategy. We report the averaged metrics over 5 runs with the commonly utilized $k \\in \\{5, 10, 20, 50, 100\\}$. The implementation details are in the Appendix A.5."}, {"title": "Performance Comparison", "content": "presents the recommendation performance of all models on the M2 dataset. An unpaired T-test with a p-value of 0.05 is conducted to prove the improvement is statistically significant. From these results, We have the following observations.\nOur method consistently surpasses all baselines by a considerable margin regarding most metrics. Performance improvement should be attributed to"}, {"title": "Ablation Study", "content": "To research the effectiveness of information provided by conceptualization and concepts relation of intentions, we conduct ablation studies by comparing our RIGRec with three variants generated by removing different types of edges as follows: (1) w/o all: This variant removes the whole item graph, equal to SASRec. (2) w/o concept: This variant removes edges acquired by the meta path through concepts. (3) w/o commonsense relation: This variant removes edges acquired by meta path through commonsense relation nodes.\nFigure 2 presents the results of the ablation studies; we interpret the results with the following discoveries. First, our constructed intention knowledge graph is of vital use to produce helpful item representations for downstream recommendation tasks. As we can see, the performance of our model exceeds that of SASRec by a large margin. Second, both types of information contained in intention conceptualization and concepts relation prove efficient. It can be confirmed that the two variants solely with corresponding edges can outperform w/o all variants. Third, distinct relations provide dissimilar contributions to each metric, w/o commonsense relation presenting high Recall metrics. At the same time, w/o conceptualization performs better in NDCG metrics, which reaffirms the significance of constructing multi-type nodes and relations in our intention knowledge graph."}, {"title": "Conclusion", "content": "We present IGC-RC, a framework for automatically constructing intentional commonsense knowledge graphs from user behaviors. Using this framework, we built the Relational Intention Knowledge Graph (RIG) and validated its quality through extensive evaluations. Results show that RIG significantly enhances the performance of state-of-the-art session"}, {"title": "Limitations", "content": "The intention generation process relies on GPT-3.5, which may introduce additional computational overhead. Future work could explore more efficient language models to streamline this component. Our framework is evaluated using the Amazon M2 dataset, which is specific to e-commerce. The applicability of the proposed method to other domains remains to be tested. The current implementation focuses on the English subset of the dataset. Extending the framework to support multiple languages could enhance its versatility. While we incorporate commonsense relations such as temporality and causality, the scope of relation types is limited. Incorporating a broader range of relational categories may improve the knowledge graph's comprehensiveness. We would like to provide more validation if more suitable datasets are available. However, most public datasets are desensitized and anonymized, making generating intention based on the anonymized ID features hard. Besides, our utilized M2 dataset is a mixed-type dataset, which already contains multi-typed items (sports, beauty, baby, etc.). The item and session sizes also exceed general research works."}, {"title": "Ethics Statement", "content": "This study ensures the responsible use of data and technology by utilizing the anonymized Amazon M2 dataset, which safeguards user privacy and complies with data protection regulations. We have implemented measures to prevent the inclusion of any personally identifiable information (PII). Additionally, we acknowledge potential biases in the dataset and have taken steps to mitigate them through standard preprocessing techniques. Our use of large language models focuses on enhancing user experience without manipulating behavior, and we advocate for transparency in deploying intention knowledge graphs within e-commerce platforms."}, {"title": "Human Annotation", "content": "We collected annotations for 3,000 session-intention pairs, each evaluated by three annotators. The inter-annotator agreement scores were 0.91 for plausibility and 0.74 for typicality. Three annotators independently evaluated each of the 1,000 intention-intention discourse pairs for intention relation classification, achieving an overall inter-annotator agreement of 0.69. All raw annotation data will be made publicly available to support future research in this area. We use exactly the same standard of annotations on plausibility and typicality."}, {"title": "Concept Prediction", "content": "We conducted experiments to compare different methods for predicting conceptualized intentions, where the goal is to predict corresponding concepts for a given purpose.\nThe first method employed a generative approach using LLMs, specifically Mistral-7B-Instruct-v0.3, Meta-Llama-3-8B-Instruct, and flan-t5-xl. This approach generated concepts in the same way as our RIG construction process. During testing, we created a candidate pool containing both true and false concepts for each intention. The LLMs generated ten concepts per intention, and matching concepts were ranked first while maintaining their generation order. We used negative sampling to create a candidate pool of 500 concepts. Importantly, we did not fine-tune the LLMs to maintain consistency with the approach used in RIG's construction.\nOur proposed approach's second method utilized an embedding-based model (bge-base-en-v1.5) to transform intentions and concepts into embeddings and compute their cosine similarities. We fine-tuned the embedding model using contrastive learning, incorporating cross-entropy loss to improve matching performance. During testing, we created a candidate pool of 500 concepts and ranked them based on their cosine similarities with the given intention.\nWe constructed a dataset of intention-concept pairs from RIG for our experimental setup. We split it into training, validation, and testing sets with an 8:1:1 ratio, resulting in 147,801 intention-concept pairs in the test set. We conducted our"}, {"title": "Intention Prediction", "content": "The input of this task is a session, and the output of this task is the ranking of the ground-truth intention over a pool of negative intentions. The goal of this task is to rank the correct intention higher than the incorrect intentions. Because the input of this task is a session, so we use the SASRec as the backbone model. We used the all-MiniLM-L6-v2 model to generate embeddings for session items and intentions. These item embeddings initialized the item embedding matrix in SASRec. During training, the parameters of session encoders and item embeddings are tuned. TripletMarginLoss minimized the distance between session and positive intention embeddings while maximizing the distance to negative intentions. Random sampling of positive and negative samples, followed by backpropagation and early stopping, was used to optimize the model."}, {"title": "Product Recovery Benchmark", "content": "We use the same evaluation method to ensure the fairness of the evaluation. shows the evaluation based on 1,203 overlapping products between the two graphs. For these identical products, we compared the intentions generated by Folkscope and RIG, respectively. The rankings and evaluations were conducted using this same set of overlapping products, allowing for a direct comparison of intention quality between the two systems. This methodology ensures a fair and balanced assessment of each method's ability to generate relevant intentions.\nUsing the same sentence embedding model (BGE), we acquired pre-computed intention and product embeddings. Then, we used the intention embeddings as input and the product embeddings as output to train a Multi-Layer Perceptron (MLP) scoring model using Noise Contrastive Estimation (NCE) loss. In the evaluation phase, for each intention, we analyzed one positive sample against 10 negative samples by calculating the cosine similarity scores of their embeddings to the target embedding and subsequent rankings, where the rank"}, {"title": "Implementation Details of Session Recommendation", "content": "For a fair comparison, the dimension of item embedding is set to 64 for all methods. Grid search strategy is applied to determine the optimal configuration of standard parameters, involving the learning rate in ${1e-2,1e-3,1e-4}$, the dropout rate in ${0,0.1,0.2, 0.3, 0.4}$, the loss function in {BPR loss, Binary Cross Entropy loss, Cross Entropy loss} and the coefficient of L2 regularization in {0, ${1-2}$, 1e-3,1e-4}."}, {"title": "Large Language model Generation Prompts", "content": "The following Figure 3 and Figure 4 denote the prompts that we used to generate the intentions and concepts."}, {"title": "Annotation Questions", "content": "Here, we give three examples of annotation questions from our questionnaire for the Amazon Mechanical Turk. They are for the session intentions quality annotation, the intention relation classification annotation, and the intention conceptualization classification."}]}