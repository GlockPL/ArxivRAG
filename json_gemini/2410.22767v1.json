{"title": "Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot", "authors": ["Sejin Lee", "Dongha Kim", "Min Song"], "abstract": "Goal-oriented chatbots are essential for automating user tasks, such as booking flights or making restaurant reservations. A key component of these systems is Dialogue State Tracking (DST), which interprets user intent and maintains the dialogue state. However, existing DST methods often rely on fixed ontologies and manually compiled slot values, limiting their adaptability to open-domain dialogues. We propose a novel approach that leverages instruction tuning and advanced prompt strategies to enhance DST performance, without relying on any predefined ontologies. Our method enables Large Language Model (LLM) to infer dialogue states through carefully designed prompts and includes an anti-hallucination mechanism to ensure accurate tracking in diverse conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder (VGAE) to model and predict subsequent user intent. Our approach achieved state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST models, and performed well in open-domain real-world conversations. This work presents a significant advancement in creating more adaptive and accurate goal-oriented chatbots.", "sections": [{"title": "I. INTRODUCTION", "content": "Text-based conversational systems, or chatbots, have gained significant attention for their ability to automate user tasks. Goal-oriented chatbots, in particular, specialize in assisting users with tasks such as booking flights or making restaurant reservations [1], [2]. A key element of these systems is Dialogue State Tracking (DST), which enables the chatbot to maintain an accurate understanding of user goals and dialogue state throughout the conversation [3].\nTraditional DST approaches rely on predefined ontologies\u2014structured, domain-specific vocabularies that define possible intents and slot values. While ontologies provide a framework for organizing dialogue states as triples of <domain, slot, value> (see Figure 1), they are rigid and resource-intensive, requiring manual updates for each new domain or variation in user input. This makes them unsuitable for open-domain scenarios, where the topics are unpredictable and diverse [4], [5]. The process of maintaining an ontology is not only costly but also prone to annotation errors, further complicating its use in real-world applications.\nTo address these limitations, we propose a novel, ontology-free DST approach that leverages the pre-trained knowledge of Large Language Model (LLM) to dynamically track user goals. LLM-based approaches offer a more flexible solution by leveraging vast pre-trained knowledge, allowing them to handle diverse and dynamic dialogue contexts without relying on predefined schemas. Instead of relying on fixed templates, our method fine-tunes LLM through instruction tuning and prompt design, allowing them to accurately capture dialogue states from the conversation context without predefined slot values. By removing the constraints of manually curated ontologies, our approach provides a more adaptable and scalable solution for real-world conversations. By using techniques such as Chain-of-Thought [6], Persona [7], SELF-DISCOVER [8], and Tree of Thought [9], we create prompts that guide the LLM to extract meaningful dialogue states at each turn. Additionally, we incorporate an anti-hallucination mechanism to prevent the model from producing inappropriate slot values in cases where no valid ontology-free options exist.\nTo further enhance dialogue state prediction, we employ a Variational Graph Auto-Encoder (VGAE) to represent dialogue states as graphs. This allows us to reason over subgraphs corresponding to user intents and predict the next dialogue state based on the user's utterance.\nOur approach achieves state-of-the-art performance with a JGA of 42.57%, surpassing existing ontology-less DST models and demonstrating strong performance on open-domain real-world dialogue data(\u00a7VI). Our contributions are as follows:\n\u2022 We introduce the first ontology-free DST model that accurately tracks dialogue states using advanced prompting techniques, eliminating the need for predefined templates.\n\u2022 Our model uses a novel combination of LLM-based prompting and VGAE to predict the next dialogue state in goal-oriented conversations, even in open-domain settings.\n\u2022 The proposed method is applicable to unlabeled, real-world conversations, providing a scalable and adaptable solution for DST across diverse domains, thereby contributing to the advancement of goal-oriented chatbots."}, {"title": "II. BACKGROUND", "content": "In this section, we first introduce the formalism of DST that will be used throughout this paper. We then describe the background of Graph Neural Network (GNN) involved in the process of predicting the next dialogue state, specifically how we use VGAE."}, {"title": "A. Dialogue State Tracking", "content": "DST provides crucial information by tracking the responses exchanged between the user and the system to achieve a specific goal. DST represents the dialogue state as a set of slot-value pairs that reflect the context of the conversation. User utterances are denoted by $U$, and system responses are denoted by $R$. Each turn of the conversation is marked by $t$, and the context up to turn $t$ can be defined as:\n$C_t = {U_1, R_1, ..., R_{t\u22121}, U_t}$\nIn multi-domain DST scenarios, the user's intent is represented as domain-slot-value triples, such as <restaurant-food-asian>. The domain $M$ is represented as $D = {d_1,d_2,...,d_m}$, where each domain contains $N$ slots $S = {$s_1,s_2,...,s_n}$. The key objective of DST is to accurately identify the slot values $v_{mn}$ corresponding to the dialogue context $C_{on}$ for each domain $m$ and slot $n$. Results from DST can be used as inputs to a GNN to analyze relationships between slot-value pairs within a dialogue state network. Instead of directly enhancing DST, GNN is applied post-DST to model and learn from the structured dialogue data represented in graph form. For instance, domain and slot values extracted by DST are represented as nodes in a graph $G = (V, E)$, where $V$ represents the domains and slots, and $E$ represents the relationships between them. GNNs utilize this graph structure to predict new relationships (e.g., potential slot-value pairs) or analyze existing ones, allowing for deeper insights into the dialogue state. A VGAE is well-suited for this context, as it is an unsupervised learning framework capable of capturing hidden patterns in the non-Euclidean space of graph structures derived from DST. It uses latent variables $z$ to encode relationships between nodes (i.e., slot-value pairs), with the goal of predicting new slot-value relationships based on the existing dialogue state graph. The loss function is defined as:\n$L_{BCE} = \\sum_{i \\in V, j \\in V} -A_{i,j} log(\\hat{A_{ij}}) \u2013 (1 \u2013 A_{ij}) log(1 \u2013 \\hat{A_{ij}})$\nAdditionally, the evidence lower bound (ELBO) loss, incorporating Kullback-Leibler (KL) divergence, is given by:\n$L_{ELBO} = L_{BCE} \u2013 KL[q(Z|X, A)$\nThrough this process, DST results serve as the foundation for GNN-based models, which can predict new slot-value pairs or infer the user's unspoken intent. By applying GNN, we can analyze the complex structure of dialogue data and gain deeper insights into the results generated by DST."}, {"title": "III. METHODOLOGY", "content": "Our overall process is provided in Figure 2. Taking unstructured current dialogue as input, the LLM infer the optimal DST prompt through instruction and prompt strategy. At this stage, prompt design becomes an excellent strategy to replace ontology. The extracted dialogue state is structured into a graph through the VGAE stage, ultimately predicting the dialogue state to be extracted from the user's next utterance."}, {"title": "A. Instruction Tuning", "content": "To improve LLM's DST reasoning without relying on an ontology, we performed instruction tuning. Our approach provides the model with explicit and precise instructions, enabling it to accurately extract domains, slots, and values across various contexts. The model is trained to follow the given instructions, allowing it to consistently track the dialogue state in a conversation scenario without the need for an ontology. For more details, see Appendix A.\nWe also utilized one of the parameter-efficient fine-tuning methods, the Low-Rank Adaptation (LoRA) technique [10]. This allowed us to improve the model's learning speed and achieve high performance with fewer resources. It enables the model to properly extract dialogue states in different conversational situations and accurately understand user intent in multi-domain dialogues."}, {"title": "B. Prompt Strategy", "content": "Previous work has incorporated ontology to constrain output, but our approach eliminates the need for ontology entirely. Our objective is to fully replace the role of ontology, which has traditionally enhanced DST performance. To achieve this, we integrate a thought-based method aimed at discerning latent user intentions during dialogue. We construct our prompting templates using Chain-of-Thought (CoT) reasoning, which guides the LLM through a series of intermediate reasoning steps, improving its ability to handle complex tasks and better understand user intentions [6].\nSeveral prompting methods have evolved from CoT, including Tree of Thoughts (ToT) [9] and SELF-DISCOVER [8]. ToT generalizes CoT by enabling the exploration of coherent text units, while SELF-DISCOVER allows the LLM to autonomously uncover intrinsic reasoning structures within tasks, improving performance in domain-specific applications. Additionally, [7] demonstrated that assigning a persona to an LLM enhances its task performance. We incorporate a persona into our prompts, improving the model's ability to track the dialogue state accurately.\nOur focus is on optimizing prompt formats for the DST task without relying on ontology. Previous research [11] has shown that zero-shot learning can outperform few-shot learning in fine-tuned language models. Thus, we adopt zero-shot DST, using a fine-tuned language model applicable to open-domain dialogue systems and real-world chatbots without the need for a predefined dictionary. By consolidating these techniques, we design prompts that effectively substitute for ontology-based conceptualization and relationships between concepts."}, {"title": "Anti-Hallucination", "content": "Because the ontology-free approach does not require labeled data and allows LLM to track unstated values, it can significantly increase the risk of hallucinations. The anti-hallucination step enhances performance by incorporating the possibility of a correct answer in the prompt, rather than relying on fine-tuning [12]. We adopted this step to prevent the tracking of non-existent values and to ensure that inferences are appropriate for the DST task. Hallucinations can be reduced by including a brief, explicit instruction: \"If the value does not exist, return the value as NONE.\"\nThis anti-hallucination technique not only enhances the LLM's performance in DST by reducing its reliance on ontology but also ensures that our ontology-free approach remains effective across unseen domains, such as open-domain dialogue and real-world data."}, {"title": "C. VGAE Stage", "content": "We propose a VGAE stage that constructs a graph structure from the set of dialogue states extracted in the previous stage to predict the goal of the next utterance. Domains and slot-value pairs are represented as nodes in the graph, with edges indicating their relationships. The slot-value nodes represent the user's semantic intent. By utilizing VGAE, we can generate candidates for the next utterance's goal based on the previously extracted dialogue states. These candidate links predict multiple potential purposes in the user's subsequent utterances.\nTo predict the user's next dialogue goal, a subgraph is constructed by extracting dialogue states from the given dialogue. The encoder generates a latent representation, 2, from the subgraph. The decoder then predicts links between nodes using the inner product of E and 2. The resulting probabilities, derived via a sigmoid function, identify the most likely candidate dialogue states for the user's subsequent utterances."}, {"title": "IV. EXPERIMENTS SETUP", "content": ""}, {"title": "A. Datasets", "content": "We designed our experiments using three goal-oriented dialogue benchmark datasets: Schema-Guided Dialogue (SGD) [1], MultiWOZ2.0 [13], and MultiWOZ2.4 [14]. The MultiWOZ dataset consists of human-to-human conversations and has been revised to correct annotation errors and reduce noise. The SGD dataset comprises approximately 16,000 conversations between humans and a chat assistant, encompassing previously unseen domains and services."}, {"title": "B. Metrics", "content": "We adopt slot F1 score and slot accuracy metrics due to the absence of a predefined template, which makes it challenging to evaluate our model comparably to previous studies that relied on Joint Goal Accuracy (JGA) based on ontology. Nevertheless, we include JGA for consistency with previous DST models. JGA requires all predicted values to exactly match the actual values for accuracy. Slot F1 score measures precision and recall in slot extraction, while slot accuracy assesses the correctness of slot value predictions across conversations. These metrics are suitable for both open-domain and real-world data scenarios."}, {"title": "C. Model", "content": "We used the open-source LLaMA3 model with 8 billion parameters, employing LoRA and instruction tuning. To compare performance differences, we also used GPT-3.5 and GPT-4o with the same instructions and prompts. Training was conducted without the use of ontology, focusing on identifying the best prompt combinations."}, {"title": "D. Graph Construction", "content": "We constructed a graph from the domains and slot-value pairs extracted via DST, linking each domain to its corresponding slot-value pairs. The data was split into 5% validation, 10% test, and 85% training. During training, we masked some graph links to evaluate the model's predictive performance and enhance generalization. Data partitioning was random, and we used 10-fold cross-validation for validation."}, {"title": "V. RESULT", "content": "We evaluated two separate stages: finding the optimal DST prompts and predicting the next state of the dialogue based on them. We evaluated three models and three datasets with three metrics to find the optimal combination of DST prompts, and the results are shown in Table I. The results of each step are discussed in each section below."}, {"title": "Anti-Hallucination Step", "content": "Our prompt strategy consisted of a combination of prompt methods, user input, and anti-hallucination steps to improve performance in the absence of an ontology. To evaluate this, we tested our approach using the anti-hallucination step on the MultiWOZ2.4 dataset. The results showed that this technique was effective, with 47.06% of performances improving the slot F1 score by more than 20% over the 27.57% of the prompts without the step. A detailed description of these steps and the results of our experiments can be found in Appendix B-A"}, {"title": "Effective Prompt Strategy", "content": "We hypothesized that our zero-shot inference approach could replace the need for an ontology in an instruction-tuned model, as demonstrated in Table I. Based on the anti-hallucination step, there were four versions of each prompt: CoT, CoT with persona pattern, SELF-DISCOVER, and ToT. Among these, the strategy combining CoT with the persona pattern had the highest JGA value across all conditions. It also achieved the highest slot F1 score, averaging 50.36% across all experiments. Thus, we found that the CoT with persona pattern was the most effective prompt strategy for the DST task. Variations of the persona pattern can be found in Appendix A."}, {"title": "Dialogue State Prediction", "content": "After performing DST with the selected prompts and graphing the tracked dialogue states, we compared different GNNs using AUC and AP metrics to evaluate their performance in predicting the next dialogue state. As a comparison, we selected models that predict links in a graph structure: GAT [25], GraphSAGE [26], GIN [27], CGN-JK [28], GTN [29], and VGAE, the model we used. As shown in Table II, VGAE performed the best on all datasets, achieving an AUC of 98.6% and an AP of 98.99% on average, significantly outperforming other models.\nMost GNNs recorded AUC and AP values above 90%, indicating that the conversation tracking network effectively captured useful link prediction information. These results suggest that our approach is highly effective in graphically organizing dialogue states and using them for advanced link prediction. The exceptional performance of VGAE underscores the importance of graph-based methodologies in tracking and predicting dialogue states."}, {"title": "Comparison to the traditional DST model", "content": "We compared our approach with the JGA of existing zero-shot DST models evaluated on unseen domains, independent of ontology, as shown in Table III. The methods compared include TRADE [3], SUMBT [15], SimpleTOD [16], T5DST [17], DiSTRICT [18], SynthDST [19], S3DST [20], IC-DST [21], ParsingDST [22], UNO [23], TransferQA [24], and the ontology-free model of [4]. Our model achieved a JGA of 42.57% on MultiWOZ 2.0, 50.0% on MultiWOZ 2.4, and 75.8% on SGD, outperforming ontology-based zero-shot models and reaching performance comparable to few-shot models.\nThe ontology-less model of [4] achieved 39.41% with a single method and 42.12% with an ensemble method on MultiWOZ2.0. Our ontology-free approach achieved a state-of-the-art JGA of 42.57% on the same dataset, demonstrating improved performance over Gao's method. This confirms the validity of our approach in achieving DST goals without relying on ontology.\nWe maintained strong performance on the MultiWOZ2.4 and SGD datasets, with JGA scores of 56.64% and 70.99%, respectively, showing that our model can effectively learn complex conversational patterns. These results suggest that our model can perform well across various real-world conversations, providing important insights into the feasibility of ontology-independent models for DST."}, {"title": "Few-Shot Evaluation", "content": "Goal-oriented dialogues, like all dialogues, are diverse and broad. To evaluate the generalizability of our ontology-free DST approach, we tested it using a few-shot evaluation: 2-shot, 3-shot, and 4-shot methods compared to the original zero-shot setting.\nAs shown in Table IV, the ontology-free approach achieved a superior JGA of 56.64% in the zero-shot setting. Adding more examples improved slot accuracy, but also increased the likelihood of incorrect answers according to the other two metrics. For example, in the zero-shot setting, we achieved 68% slot accuracy, which improved to 88% in the few-shot setting, though the difference in slot F1 score was less than 2%. This suggests that while additional examples help the model recognize complex patterns, they can also increase the frequency of uncertain answers. Nonetheless, the ontology-free approach appears well-suited for various real-world conversational scenarios."}, {"title": "Error analysis", "content": "Our LLM-based approach generates more diverse responses than traditional language models but encounters two primary error types: tracking non-existent values and synonym tracking. In the MultiWOZ2.4 dataset, tracking non-existent values accounted for 25.5% of errors, such as tracking \u201c...', \u2018XXXXX', and 'general'. This highlights challenges in tracking exact values in specific contexts. Synonym tracking errors accounted for 5.3% of errors, such as tracking '5 nights' instead of '5'. These results illustrate limitations stemming from the absence of ontology and suggest that such errors are inherent to ontology-free models."}, {"title": "VI. OPEN DOMAIN DIALOGUE", "content": "Unlike traditional task-oriented bots, open-domain dialogue systems aim to build long-term relationships with users by fulfilling human needs for communication, affection, and social belonging [30]. In the previous section, we showed that our approach is completely independent of ontology and does not require labels on the data, and thus can extract dialogue states from open domain dialogue systems and real-world data. To demonstrate this, we used Persona-Chat [31], which consists of crowd-sourced conversations in which each participant plays the role of an assigned persona.\nWe implemented the experiment in the same way as in Section IV: we performed the evaluation with completely new data and could only measure slot accuracy, as the slot for the next utterance did not exist. As it turned out, the domain comprising the dialogue was \u201cGeneral\u201d, and predicting the slot for the next utterance based on this yielded an AUC of 0.9589 and an AP of 0.9791. In the absence of metrics, an example of our own human evaluation on a randomized dialogue can be found in Appendix C. These results imply that our approach is applicable to all common conversations."}, {"title": "VII. RELATED WORK", "content": "Evolution of Text-Based Conversational Systems Text-based conversational systems, or chatbots, have become increasingly popular due to their ability to automate user tasks and provide accurate answers. These systems process and understand natural language, track conversation context through a conversation manager, and generate appropriate responses [32].\nTo understand natural language and predict dialogue states, DST uses deep neural Network. [3] proposed a dialogue state generator using a copying mechanism to address dependency on domain ontology and lack of cross-domain knowledge sharing. [15] introduced the Slot-utterance Matching Belief Tracker (SUMBT) with an Attention mechanism, and [33] used attention mechanisms to efficiently estimate conversational context.\nAdvances in Generation-Based Chatbots and DST Generation-based chatbots operate across various domains, with research focused on reducing dependence on ontology. [34] introduced a Neural Belief Tracking (NBT) framework using CNNs, and [35] applied a BERT-style model for non-categorical methods. However, some open-domain chatbots still rely on complex rule-based systems [36]. Zero-shot methodology has been applied to track multi-domain utterances in DST. [37] proposed parameter-efficient transfer learning for zero-shot domain adaptation, and [20] introduced S3-DST for long context tracking.\nWith LLM capable of analyzing natural language semantics, studies have applied LLM to DST tasks [38], [39]. Prompting methods include few-shot learning examples [21], [40], schema-based prompts [41], [42], instructional prompts [43], and function calling [44].\nLink Prediction and GNN Link prediction is essential in network structure data and can be approached with heuristic methods and latent feature extraction [45]. GNN are deep learning models that handle graph-related tasks by aggregating information from graph structures and encoding node features [25]. GNN are effective for link prediction and have been applied to various problems, including DST.\nFor instance, [46] used Graph Attention Network (GAT) to augment GPT-2 for information extraction from user utterances, and [47] proposed a dynamic schema graph fusion network. [48] developed a multi-domain dialogue state tracker using GAT-based schema graphs, and [49] proposed Dialogue State Tracking with Question Answering using bidirectional attention flow."}, {"title": "VIII. CONCLUSION", "content": "We propose a novel approach to extracting dialogue states and predicting the next dialogue state using prompts that replace ontology for goal-oriented conversation agents. We performed well on DST without ontology by tailoring prompts for DST through instruction tuning, prompt strategy. Dialogue state is represented as a relation graph to predict the dialogue state in the user's next utterance to capture the conversation context and user intent. Our experimental results on MultiWOZ and SGD show that our approach performs well without ontology, and the predicted candidate dialogue states allow us to identify the context and user intent in the next conversation. We also verified that our approach performs well on a open domain dialogue dataset called Persona-Chat. We conclude that our approach can be effectively applied to complex dialogue situations in the real world to advance purposeful goal-oriented chatbots."}, {"title": "IX. LIMITATION", "content": "This study has two key limitations: (1) Our approach relies on zero-shot prompt engineering for DST without using an ontology, combining existing prompting techniques rather than introducing a new algorithm. While the results demonstrate that robust prompts can replace ontologies, future research should focus on developing novel prompting algorithms specifically for DST. (2) We applied our method to open-domain dialogue (\u00a7VI), but the absence of a standardized evaluation scale required us to rely on provisional self-validation. To address this, future work will include large-scale human evaluations or the creation of a comprehensive evaluation framework using LLM. These limitations provide important directions for future research and lay the groundwork for developing more advanced and practical DST systems."}, {"title": "APPENDIX A", "content": "DESCRIPTION OF PROMPT TEMPLATES"}, {"title": "A. Instruction Tuning", "content": "We used a fixed instruction template to fine-tune an open-source model to create a model for DST. It is important to note that this fixed instruction template does not contain an ontology. This fixed prompt is used in fine tuning, along with the prompts in prompt strategy, and also utilized in the reasoning step. See the example prompt in appendix A-C for an instruction."}, {"title": "B. Prompt Strategy", "content": "Given that traditional DST performs well based on ontology, we aimed to perform DST without using ontology at all. We adopted LLM for its high performance and prompt engineering for its task-specific performance. In the prompt strategy stage, we tried to find the best combination of prompts for the DST task. We used several prompt engineering methods. The tables below show the combinations using the methods we used. First, we performed the DST with a single prompt to see if each prompt method could work well in the DST. We then performed experiments with multiple variations of each method, including an anti-hallucination step. We provide some examples of prompts alone and in combination in these prompting strategies below."}, {"title": "Prompt Type 1: \"CoT\"", "content": "{\"prompt\": Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. Ensure that the response is clear, concise, and directly addresses the task described in the instruction. Avoid asking for personal information or making assumptions beyond the provided context. Let's step by step. Instruction: instruction Input: input Response:}"}, {"title": "Prompt Type 2: \"CoT\" + \"Persona 1\"", "content": "{\"prompt\": You are an advanced dialogue state tracker with expertise in understanding and managing complex conversations to maintain context and provide accurate responses. Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. Ensure that the response is clear, concise, and directly addresses the task described in the instruction. Avoid asking for personal information or making assumptions beyond the provided context. Let's step by step. Instruction: instruction Input: input Response:}"}, {"title": "Prompt Type 3: \"CoT\" + \"Persona 2\"", "content": "{\"prompt\": You are a context-aware dialogue specialist, skilled in recognizing user intents and maintaining seamless conversation flow by accurately tracking dialogue states. Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. Ensure that the response is clear, concise, and directly addresses the task described in the instruction. Avoid asking for personal information or making assumptions beyond the provided context. Let's step by step. Instruction: instruction Input: input Response:}"}, {"title": "Prompt Type 4: \"CoT\" + \"Persona 3\"", "content": "{\"prompt\": You are an expert conversational analyst, proficient in monitoring and updating dialogue states to ensure coherent and contextually appropriate interactions. Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. Ensure that the response is clear, concise, and directly addresses the task described in the instruction. Avoid asking for personal information or making assumptions beyond the provided context. Let's step by step. Instruction: instruction Input: input Response:}"}, {"title": "C. Prompt Strategy", "content": "While traditional DST typically performs well based on predefined ontology, our objective was to explore DST without relying on any ontology. To achieve this, we utilized LLM due to its high performance and incorporated prompt engineering techniques to optimize task-specific outcomes. During the prompt strategy phase, we sought to identify the most effective combination of prompts for the DST task.\nWe employed various prompt engineering approaches and conducted experiments with different combinations. Initially, we performed DST using a single prompt to assess the feasibility of each method. We then tested multiple variations, including the implementation of an anti-hallucination step. For detailed examples and the full list of prompts used in this study, please refer to our GitHub repository: https://github.com/Eastha0526/Beyond-Ontology-in-DST.git."}, {"title": "APPENDIX B", "content": "ADDITIONAL RESULT"}, {"title": "A. Anti-Hallucination", "content": "To mitigate hallucinations in LLM, which often generate overly descriptive responses without a defined ontology, we implemented a specific anti-hallucination prompt. For instance, when asked about a \"nearby attraction,\" the LLM might respond with unnecessary details such as \"a restaurant called Zizi Cambridge, and a nearby attraction is Cambridge\" rather than the concise \"Cambridge.\"\nTo address this, we introduced a prompt instructing the LLM to return \"None\" if a precise answer is unavailable. This reduced unnecessary elaboration, yielding more direct responses. The specific prompt was: \"If the value does not exist, return the value as NONE.\" This method significantly enhanced model performance, improving the F1 score by up to 20%.\nTable V show that the Anti-Hallucination step improved slot F1 scores and slot accuracy for different prompt types. The CoT approach, which included the Anti-Hallucination step, was particularly effective. Among the various personas tested, the \"Context-Aware Dialogue Specialist\" achieved the highest F1 score (47.06%), making it the best-performing prompt type."}, {"title": "APPENDIX C", "content": "OPEN DOMAIN DIALOGUE"}, {"title": "VIII. ACKNOWLEDGMENT", "content": "This work was supported by the National Research Foun- dation of Korea(NRF) grant funded by the Korea govern- ment(MSIT) (No. 2022R1A2B5B02002359). This work was partly supported by an IITP grant funded by the Korean Government (MSIT) (No. RS-2020-II201361, Artificial Intel- ligence Graduate School Program (Yonsei University))"}]}