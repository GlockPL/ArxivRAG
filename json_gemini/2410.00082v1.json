{"title": "Graph Residual Noise Learner Network for Brain Connectivity Graph Prediction", "authors": ["Oytun Demirbilek", "Tingying Peng", "Alaa Bessadok"], "abstract": "A morphological brain graph depicting a connectional fingerprint is of paramount importance for charting brain dysconnectivity patterns. Such data often has missing observations due to various reasons such as time-consuming and incomplete neuroimage processing pipelines. Thus, predicting a target brain graph from a source graph is crucial for better diagnosing neurological disorders with minimal data acquisition resources. Many brain graph generative models were proposed for promising results, yet they are mostly based on generative adversarial networks (GAN), which could suffer from mode collapse and require large training datasets. Recent developments in diffusion models address these problems by offering essential properties such as a stable training objective and easy scalability. However, applying a diffusion process to graph edges fails to maintain the topological symmetry of the brain connectivity matrices. To meet these challenges, we propose the Graph Residual Noise Learner Network (Grenol-Net), the first graph diffusion model for predicting a target graph from a source graph. Its two core contributions lie in (i) introducing a graph diffusion model that learns node-level noise for accurate denoising (ii) introducing a node-based diffusion function to better maintain the topological structure of brain graphs. Our Grenol-Net is composed of graph convolutional blocks, which first learn the source embeddings and second, a set of fully connected layers assisted with a positional encoding block that predicts the nodes with noise level t-1 in the target domain. We further design a batch normalization block that learns the target distribution at diffusion timestep t and operates an element-wise subtraction from the predicted nodes with noise level t-1. Our Grenol-Net outperformed existing methods on the morphological brain graph extracted from cortical measurements of the left and right hemispheres separately and on three distinct datasets from multiple cohorts.", "sections": [{"title": "1 Introduction", "content": "A morphological brain graph represents cortical similarities between pairwise Regions of Interest (ROIs) using structural T1-weighted MRI [18], providing insights into how different brain regions' morphology may influence each other. Studies have shown that morphological connectivities are crucial for exploring brain abnormalities in neurological diseases [22,18]. However, acquiring complete connectomic datasets often faces challenges in reality due to the high costs of medical scans and time-consuming neuroimage processing pipelines [8]. To tackle this challenge, graph convolution frameworks based on generative adversarial network (GAN) have been proposed to predict missing brain graphs or to infer structural from functional brain graphs[2,11,23,3]. However, these approaches may suffer from generator hallucination due to the GAN mode collapse problem, leading to a lack of diversity in the predicted graphs despite the large training set. Alternatively, [11] proposed a brain graph generative framework based on edge graph convolutional network (NNConv) [10] to generate a representative brain graph template of a population of brain multigraphs with a shared neurological state, such as autism. While this method avoids GAN's problems as it relies solely on graph convolutional learning blocks, it is not specifically designed for predicting a morphological target brain graph from a source graph. Consequently, there is a need in the field of network neuroscience for more accurate and dedicated generative models for predicting a missing morphological brain graph from an existing one.\nRecently, diffusion models [20,12] have emerged as promising solutions to the data generation problem, demonstrating remarkable progress in generating different types of medical modalities [14]. The key success of diffusion models largely comes from the noise diffusion process that introduces diversity in the generated data, making it less prone to mode collapse issues [6]. Despite recent progress in these methods for medical image generation, existing graph diffusion models are mostly designed for predicting proteins or molecular structures, which have different topologies from brain graphs [17]. Thus, these graph diffusion frameworks cannot be used for brain graph generation tasks. So far, we have identified only one brain graph synthesis work using a diffusion model [19]. This work combines a graph U-net with a diffusion model in a single framework to predict high-resolution brain graphs from low-resolution ones, where resolution refers to the number of ROIs considered in the brain graph. Although promising, this model faces one significant challenge: the diffusion process proposed in the work does not preserve the node-wise topological properties as it operates on the graph edges directly. However, the edges represent the similarity in morphology between ROIs (nodes), which are crucial for understanding the function of each brain region in both healthy and neurological disorder cases [1]. Therefore, neglecting the diffusion process on nodes fails to maintain the symmetry of the connectivity patterns in the brain."}, {"title": "2 Methodology", "content": "We propose Grenol-Net, the first graph diffusion framework tailored to predict a target brain graph from source one, effectively learns the topological brain structure given the node features, thus maintaining the connectivity diversity in isomorphic brain graphs (i.e., derived from the same parcellation brain template). Our framework comprises two intricately designed learning blocks, each playing a pivotal role in achieving our objectives. The first block comprises a series of graph convolutional blocks that unravel the complex interplay of connections within the source brain graph. By leveraging a cross-node message passing function, Grenol-Net learns a unique embedding of each ROI, laying a solid foundation for precise prediction. This process is further enhanced by a set of fully connected layers, complemented by a positional encoding block, which orchestrates the prediction of nodes with noise level t 1 in the target domain. This integration of graph convolution and positional encoding enables Grenol-Net to capture the intricate nuances of brain graph connectivity with unparalleled accuracy. The second block of Grenol-Net introduces a batch normalization mechanism that not only learns the distribution of the target brain graph at diffusion timestep t but also establishes a residual connection to isolate and recover the noise applied to the target. We offer open access to pre-trained Grenol-Net and its source code, fostering collaborative research efforts within the network neuroscience community to expand upon our work."}, {"title": "A) Brain graph representation.", "content": "Let G(V, E) be a fully connected undirected graph where V is the set of vertices (i.e., nodes) and E is the set of edges. In the context of brain graph prediction, our objective is to learn a mapping from source Gsrc (Vsrc, Esrc) to target Gtgt (Vtgt, Etgt). Particularly, we construct edges ei,j each represents a morphological (i.e., specific structural features that represent shape) dissimilarity between two cortical regions of interest (ROI) (i.e., respective node features ni and n; of node i and node j), and calculated using our pairing function (Fig. 1-A) as following:\n$e_{i,j} = \\frac{n_i - n_j}{Ni + n_j}$                                                                                                                                                                     (1)\nwhich yields a symmetric adjacency matrix. Different from [18] where edges are calculated as the absolute difference, here we propose our formula to obtain normalized features strictly between 0 and 1 for a better representation of morphological similarities in brain graphs."}, {"title": "B) Forward diffusion process to add noise to brain graphs.", "content": "Diffusion models are generative models defined as latent variable models [20]. Let q(xt) be the forward diffusion process for the target data distribution where t is the diffusion timestep. Sampling from this distribution to get the nodes of a target graph is defined as a Markov chain xt ~ q(xt) to gradually add Gaussian noise according to a variance schedule \u03b2\u2081...\u1e9e\u0442 [12]:\nq(x1:Txo) = \\prod_{t=1}^{T} q(x_t|x_{t-1}), q(x_t|x_{t-1}) = N(x_t; \\sqrt{1 - \\beta_{t-1}}x_{t-1}, \\beta_tI_k)                                                                                                                            (2)\nwhere I is an identity matrix, T is the maximum number of diffusion timesteps, and here we introduce k as the standard deviation coefficient for the normal distribution (N). By proposing the k parameter to scale the standard deviation of the noise, we aim to avoid significant data losses between two diffusion timesteps. Authors in [4] also highlighted this problem such that the high variance of independent noise destroys an important amount of information in small-sized images due to less redundancy in neighboring values. Next, we denote at 1- \u03b2t and \u0101t = \u03a0-1 as and we diffuse the node features of target graph Gtgt as:\n$n^{tgt}_t = \\sqrt{\\bar{a}_t}n^{tgt} + \\sqrt{(1 - \\bar{a}_t)} \\epsilon$                                                                                                                                                                                                                   (3)\nwhere e is the generated noise, and nigt is the nodes of the target graph (Fig. 1-B). We visualize the output noisy graphs in Fig.1-E by reconstructing their edges with our pairing function in Eq.1. Authors in [19] applied a diffusion process that directly operates on the graph edges that fails to maintain the symmetry of the adjacency matrices. Instead, we unprecedentedly propose our novel diffusion methodology for brain connectivity graphs to address this problem."}, {"title": "C) Graph residual noise learner network.", "content": "We aim to predict the added diffusion noise on a target graph with a given diffusion timestep t and guided with the source graph Gsrc. To employ the diffusion guidance, authors in [13] investigate the necessity to train a separate classifier. However, we define a simpler network Grenol-Net as \u00ea = ee(n+gt, t, Gsrc) where \u00ea is the predicted noise and \u03b8 is the learnable parameters (weights and biases). First, graph convolutional layers introduced in [10] (NNConv) of our model learn an embedding vector to represent the source graph Gsrc, each graph convolutional layer can be formulated as follows:\nn'\u2081 = Oni + \u2211nj.fo(ei,j)                                                                                                                                                                                                                                       (4)\njEN(i)\nwhere, n' is the embedding value for node i, N is the neighboring function, and fe is a linear layer with learnable parameters (weights and biases). Then, we introduce a group of fully connected layers that map the source embeddings to target embeddings. We condition these target embeddings by adding a sinusoidal position embedding layer inspired by the Transformer [21] as it was also proposed to represent the diffusion timestep in [12] since the target embeddings ideally represent the noisy target and are dependent on the diffusion timestep t. Next, we introduce a batch normalization layer to the noisy node features from a batch of target graphs ntgt to learn the distribution of the target domain. After we obtain the target embedding vector, we subtract it from the batch-normalized noisy node features vector as the target embeddings should be close to the noisy node features of the previous diffusion timepoint. We refer to this set of operations as residual, since it works as a by-pass connection as shown in Fig. 1-C. Finally, we define our objective function as the standard mean square error Lmse between the generated noise e and predicted noise \u00ea as follows in closed form:\n$L_{mse} = E_{t~[1,T],n^{tgt}~q(n^{tgt}),\\epsilon~N(0,1_k)} ||\\epsilon - \\hat{\\epsilon}_\\theta (n^{tgt}, t, G_{src})||^2                                                                                                                                                                                                                                                          (5)"}, {"title": "D) Guided denoising from source to target domain.", "content": "The reverse process of the diffusion (i.e., denoising) is defined as a Markov chain p(x) = N(x+; 0, Ik) that gradually removes Gaussian noise, and formulated as [12]:\n\u0440\u04e9(xo:T) = p(x\u0442) \\prod_{t=1}^{T}Po(Xt\u22121|Xt), Po(Xt\u22121|Xt) = N(xt\u22121; \u00b5\u00f8(xt, t), Eo(xt, t))                                                                                                                                   (6)\nwhere De is a reverse process covariance function approximator and he is a reverse process mean function approximator, the result of the analysis in [12]. They also set Do(xt,t) = \u03c3\u2021I and ot\n Bt Bt1-at-1 as untrained time dependent constants. Specifically, to approximate the forward process posterior variance and mean, we follow a similar procedure by defining \u03bc\u03b5 and \u03c3\u03c4. We picked the same ot in [12], but we define our reverse process mean function approximator \u03bc\u03b8 guided by the source graph (Gsrc) which is learned by the graph convolutional layers of our Grenol-Net (69):\n$\\mu_\\theta (n^{tgt}_t, t, G_{src}) = \\frac{1}{\\sqrt{a_t}} (\\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha_t}}} \\epsilon_\\theta (n^{tgt}_t, t, G_{src}))$                                                                                                    (7)"}, {"title": "", "content": "Finally, we can define our complete sampling procedure Xt-1 ~ Po(Xt-1|Xt) to approximate the noisy target nodes at the previous diffusion timestep as follows:\n$n^{tgt}_{t-1} = \\mu_\\theta (n^{tgt}_t, t,G_{src}) + \\sigma_\\theta \\epsilon$                                                                                                                                                                                                                                                                 (8)\nWith our sampling methodology, we first generate a random Gaussian noise and denoise with source guidance and then gradually remove the noise as illustrated in Fig.1-D. By introducing a guidance procedure for the sampling methodology of the diffusion model, we aim to generate target graphs from source brain graphs using a diffusion model."}, {"title": "3 Experiments and Results", "content": "We evaluated our architecture on 3 different datasets: Human Connectome Project (HCP) Young Adult [7], Child and Adolescent NeuroDevelopment Initiative (Candishare) Schizophrenia Bulletin 2008 [9,15], and Openneuro Cannabis Use Disorders Identification Test (Openneuro) [16]. The parcellation statistics were already calculated with the HCP pipeline and verified by further quality checks for the HCP dataset. For Openneuro and Candishare, we executed the Freesurfer [8] pipeline (v7.2.0) on Ubuntu 22.04. We picked datasets to validate our model and benchmarks on various dataset groups. Specifically, all our datasets are collected for different studies, age groups, parcellation software, and MRI machines stated in Table 1. A node ni yields one of the node features, each derived from regional statistics from cortical parcellations (e.g., mean curvature, cortical thickness, surface area). To parcellate the brain into cortical regions, we used Desikan-Killiany Cortical Atlas [5], where each subject is parcellated into 34 ROI and left and right hemispheres from their T1-w MRI scan. We constructed Gsrc based on mean curvature, while Gtgt were derived from cortical thickness. These morphological metrics were chosen for their significance in network neuroscience studies, as evidenced by prior research [11,2]."}, {"title": "3.2 Hyperparameter tuning", "content": "We evaluated Grenol-Net against benchmark methods using 5-fold cross-validation. Each cortical hemisphere data was independently trained and tested. Our model architecture consists of a graph convolutional block with 3 layers of NNConv with convolution size 48 followed by 3 fully connected layers with size: 128. Training employed Adam optimization with weight decay regularization (AdamW), a learning rate of 0.001, weight decay of 0.001, and 500 epochs. We applied cosine beta scheduling for the noise schedule with hyperparameters set to k = 0.01 and T = 100."}, {"title": "3.3 Benchmarks", "content": "In our experiment, we compared our model against three benchmarks tailored for isomorphic brain graph prediction: First, hierarchical adversarial domain alignment (HADA) [2], a GAN-based method for brain graph prediction using leave-one-out (LOO) splitting. Second, multi-GCN-based generative adversarial network (MGCN-GAN) [23], employing complex loss functions including MSE, Pearson correlation coefficient (PCC), and GAN loss. Third, a graph convolutional architecture [11] predicts a single graph from multi-graphs. We adapt the same architecture to predict a target graph from a source graph."}, {"title": "3.4 Evaluation", "content": "Then, we illustrated the results in Fig. 2 for each subject and compared our model with the benchmarks where each model is trained and tested on three datasets separately. Our Grenol-Net significantly outperforms the benchmarks in terms of prediction accuracy across all datasets with p-value < 0.001 except for HADA on Candishare's left hemisphere dataset. We showcase our model's superiority over HADA which is a rigid model utilizing the LOO strategy for graph prediction. Likewise, despite the ambiguous inference mode of MGCN-GAN, our model consistently outperforms it across the left and right hemispheres of three datasets. Moreover, MGCN-GAN is trained by optimizing a combination of loss functions: MSE loss, PCC loss, and GAN loss. We illustrate in Fig. 2 that our Grenol-Net trained with simple loss function Eq. 5 outperforms MGCN-GAN trained with its complex loss function. We further showcase the superiority of our model over DGN, a fully GNN-based generative model. Hence we affirm that our graph diffusion-based model stands out as the superior choice for predicting brain graphs. We further reported results in Fig. 3 of Grenol-Net being trained and validated with solely 21 subjects and tested on 21 others from Openneuro (internal test set) and 47 test subjects from Candishare and 557 test subjects from hep (cross-cohort test sets). Remarkably, our model still performs well on other cohorts. This demonstrates the breadth of our residual noise learner in accurately training on a very limited dataset. Thus, we can affirm the robustness of Grenol-Net in training and generalizing to diverse cohorts, showcasing its capability to effectively learn from a limited dataset while maintaining high performance across different subject groups. We ran our experiments using a single NVIDIA GeForce RTX 3060 with 6GB memory and measured the inference time of our model on one subject as 0.1816 seconds on average. To conclude, Grenol-Net's remarkable performance not only highlights its ability to surpass the limitations of benchmark models through its diffusion-based property but also underscores its efficiency in inference, as evidenced by its ability to process individual predictions in mere seconds. This versatility positions Grenol-Net as an ideal solution for a wide range of isomorphic graph prediction tasks."}, {"title": "4 Conclusion", "content": "Our graph diffusion model effectively addresses the morphological brain network prediction challenge. Future research could focus on enhancing the model's explainability and interpretability to deepen insights into brain connectivity dynamics. Additionally, while applicable to one-target prediction tasks, the computational cost remains a challenge for multi-target predictions. Nevertheless, our simple yet efficient framework holds the potential for transforming brain graph prediction, with future endeavors aiming to develop more efficient diffusion models for multi-target prediction while emphasizing interpretability to advance neuroscience understanding."}]}