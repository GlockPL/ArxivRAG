{"title": "Deep Autoencoders for Unsupervised Anomaly Detection in Wildfire Prediction", "authors": ["\u0130rem \u00dcstek", "Miguel Arana-Catania", "Alexander Farr", "Ivan Petrunin"], "abstract": "Wildfires pose a significantly increasing hazard to global ecosystems due to the climate crisis. Due to its complex nature, there is an urgent need for innovative approaches to wildfire prediction, such as machine learning. This research took a unique approach, differentiating from classical supervised learning, and addressed the gap in unsupervised wildfire prediction using autoencoders and clustering techniques for anomaly detection. Historical weather and normalised difference vegetation index datasets of Australia for 2005-2021 were utilised. Two main unsupervised approaches were analysed. The first used a deep autoencoder to obtain latent features, which were then fed into clustering models, isolation forest, local outlier factor and one-class SVM for anomaly detection. The second approach used a deep autoencoder to reconstruct the input data and use reconstruction errors to identify anomalies. Long Short-Term Memory (LSTM) autoencoders and fully connected (FC) autoencoders were employed in this part, both in an unsupervised way learning only from nominal data. The FC autoencoder outperformed its counterparts, achieving an accuracy of 0.71, an F1-score of 0.74, and an MCC of 0.42. These findings highlight the practicality of this method, as it effectively predicts wildfires in the absence of ground truth, utilising an unsupervised learning technique.", "sections": [{"title": "1 Introduction", "content": "Forests are essential to maintaining the planet's ecological equilibrium, but they face threats from fires caused by both natural phenomena and human activities (Qiang et al., 2011). These wildfires are catastrophic events that negatively impact the environment, the economy, and the natural resources (Meddour-Sahar, 2015; Sayad et al., 2019). On the human front, they can lead to loss of life, respiratory ailments, and other health challenges. At the same time, economically, they can devastate communities, affecting livelihoods and leading to billions in damages. The impact on wildlife is also severe, threatening a diverse range of species with effects such as respiratory distress, altered behaviour, and even the threat of extinction. Simultaneously, the natural environment suffers degradation through soil erosion, loss of biodiversity, and the destruction of essential ecosystems such as forests (Sanderfoot et al., 2022).\nIn recent years, the frequency of wildfires has surged, becoming a global concern that has drawn attention from various fields of study (Abid, 2021). A very recent example would be the wildfire episodes encompassing 25 million acres in Canada in 2023 (Canada, n.d.). The growing threat of wildfire disasters is primarily attributed to climate change. These changes, characterised by higher temperatures and extended dry periods, have led to unprecedented bushfire activities, particularly within Australia (Vardoulakis et al., 2020).\nIn 2019, Australia, the focus area of this research, encountered its hottest year on record, with the annual national mean temperature surpassing the average by 1.52\u00b0C. It also experienced its driest year on record, with notable heatwaves occurring in January and December (Yu et al., 2020). Between 2019 and 2020, Australia witnessed one of the largest wildfires in modern record. A minimum area of 46 million acres of land was burnt (Sulova & Jokar Arsanjani, 2020). The 2019-20 wildfire is noted for having the strongest measures on record in terms of both magnitude and intensity (Zhang et al., 2021). Regarding their impacts on climate change and the environment, these fires directly claimed 33 human lives and over one billion indigenous animals (Norman et al., 2021). Furthermore, 417 individuals succumbed to smoke inhalation, and it is believed that 80% of Australia's population was directly or indirectly affected by the fires (Borchers Arriagada et al., 2020; Norman et al., 2021; Ogie et al., 2022). Moreover, projections indicate that such wildfires will continue to occur due to multiple factors. Based on scientific estimates by the United Nations, extreme wildfires could increase by as much as"}, {"title": "2 Related Work", "content": "In this section we review relevant research to our project, beginning with a general study on wildfire prediction using machine learning, followed by specific reviews of the techniques employed in our work: anomaly detection, autoencoders, and the combination of both."}, {"title": "2.1 Wildfire Prediction Using ML Models", "content": "Various ML techniques and features have been applied and researched regarding forest fire prediction and detection. The most common and popular ML models used are the artificial neural networks (ANN), support vector machines (SVM), random forests (RF), XGBoost, and decision trees (DT), as highlighted by Jain et al. (2020) in their review of 300 different papers.\nA common focus in the works exploring ML techniques has been the joint use or comparison between SVM and ANN models. For instance, Sayad et al. (2019) combined in a single pipeline SVM and ANN to forecast wildfires using a dataset based on the NDVI, land surface temperature (LST), and thermal anomalies from the Moderate Resolution Imaging Spectroradiometer (MODIS), and three characteristics relevant to the status of crops. The findings demonstrated high fire occurrence prediction accuracy (ANNs: 98.32%; SVM: 97.48%), defining it as the ratio of correctly predicted instances to the total instances. The study integrated NDVI, LST, and thermal anomalies with ground truth labelled data. However, the researchers recommended integrating weather data due to its strong relationship with wildfire incidence, development, spread, and extinction. They especially highlighted utilising certain variables which drastically affect wildfire incidences and likelihood: air temperature, wind, and soil moisture Sayad et al. (2019).\nAnother study included weather data, as suggested by Sayad et al. (2019). Sakr et al. (2011) compared SVM and ANN for predicting the likelihood of a fire using cumulative precipitation and relative humidity for several months of the year. SVM performed better in binary fire/no fire classification with the highest accuracy of 94.21%, while ANN obtained a maximum of 91.2%.\nGholamnia et al. (2020) took a distinct approach and explored ML models for mapping wildfire susceptibility instead of predicting them. Using wildfire inventory data from global positioning systems (GPS) and MODIS fire occurrences, they considered sixteen conditioning factors, including meteorological parameters and a vegetation index. Among the eleven ML techniques compared, RF showed the highest accuracy of 88%, followed by SVM at 79%. The study is noteworthy for implementing the unsupervised self-organising maps (SOM) technique, which was however applied to a two-class data and has been adapted for use for classification purposes. The least accurate models were RBF, logistic regression, and SOM. Although not directly comparable to the subject of this paper, it serves as a valuable example of ML's potential in the wildfire susceptibility mapping domain.\nTurning attention to different geographical contexts, Sulova and Jokar Arsanjani (2020) conducted research similar to this study in terms of the study area, focusing on predicting wildfire risk in Australia over six months. They used topography, vegetation, infrastructure, meteorology, and socioeconomic data. The study employed Na\u00efve Bayes (NB), Classification and Regression Tree (CART), and RF models, with RF achieving the highest accuracy of 96% and NB having the lowest accuracy of 64%.\nKondylatos et al. (2022) aimed to accurately forecast wildfire danger using deep learning (DL) models such as LSTM and ConvLSTM and traditional models like RF and XGBoost. The research covered Greece, parts of the Balkan peninsula, and western Turkey. They utilised various datasets, which were including daily weather data from ERA-5 Land and satellite variables from MODIS, such as NDVI and Land Surface Temperature."}, {"title": "2.2 Anomaly Detection in Wildfire Prediction", "content": "Anomaly detection aims to identify anomalous patterns, often known as outliers or anomalies, that significantly deviate from the rest of the data (Thudumu et al., 2020). Such a task can be performed using supervised or unsupervised learning techniques. In this study, an unsupervised learning version will be implemented. In extreme event scenarios, it is difficult to find appropriately labelled datasets because detecting anomalous observations requires effort and expertise. Therefore, supervised learning based on labelled data may not be a viable and suitable solution in all anomaly detection circumstances (Esmaeili et al., 2023). This underscores the value and contribution of unsupervised anomaly detection.\nTo the best of our knowledge, there is no study implementing anomaly detection directly in wildfire prediction using unsupervised learning techniques. However, there exists a closely related study working in wildfire risk prediction using anomaly detection method, even though it is not an exact match with this research's topic. In their research, Salehi et al. (2016) set out to use weather data to better predict the risk of wildfires. They devised a new model named Context-Based Fire Risk (CBFR) that considers the changing patterns of weather over time using a context-based anomaly detection method. They used ECMWF ERA-5 weather data from the Blue Mountains in Australia. To assess the performance of their model, the authors compare it to the commonly used McArthur FFDI method. They looked at AUC and the straight-up accuracy rate. Their CBFR model performed better on both counts. Specifically, CBFR had an AUC of 0.96 and an accuracy of 0.94, while the FFDI method scored 0.89 for AUC and 0.87 for accuracy."}, {"title": "2.3 Autoencoders and Dimensionality Reduction", "content": "The first autoencoder neural network was developed to reduce dimensionality (Masci et al., 2011), showing specific advantages over other types of traditional dimensionality reduction methods. For instance, since they are non-linear, autoencoders can generally outperform linear traditional methods in the context of dimensionality reduction (Bank et al., 2020).\nAlthough there have been no previous examples of such use of autoencoders in the wildfire prediction domain, there is one study focusing on post-fire assessment (Coca & Datcu, 2021). The authors introduced a framework for burned area estimation using mul-"}, {"title": "2.4 Autoencoders and Anomaly Detection", "content": ""}, {"title": "2.4.1 \u0410\u043f\u043emaly Detection Based on Reconstruction Error", "content": "Using autoencoders to detect anomalies using the reconstruction error is a technique well applied in several areas. The idea is as follows: a trained autoencoder would learn the latent subspace based on only normal (non-anomalous) instances. Once trained, the input data is reconstructed, and reconstruction errors, i.e., the difference between the original and reconstructed data, are calculated. As a result, while normal instances have low reconstruction errors, anomalies have high reconstruction errors (Bank et al., 2020).\nTo the best of our knowledge, no existing literature has explored anomaly detection using only deep autoencoders and reconstruction error in the context of wildfire prediction. The forthcoming referenced studies, while they are from varying domains, share a methodology closely aligned with this research.\nD. Cheng et al. (2022) utilised a ResNet autoencoder to identify anomalies in radar data. Their model incorporated both convolutional and LSTM layers. Convolutional layers captured features, while LSTM layers assessed temporal dependencies in radar data. The model achieved an accuracy potential of up to 85%. Esmaeili et al. (2023) trained deep autoencoders on normal data to spot anomalies in a similar domain. Using autoencoder-based prediction models on electrochemical aptasensor recordings with various signal lengths, they used reconstruction errors to set up a threshold for assigning anomalies and used kernel density estimation. They implemented vanilla, ULSTM, and Bi-LSTM autoencoder. The integrated ULSTM-vanilla model achieved about 80% accuracy for longer signal datasets, 65% and 40% for shorter ones.\nZhao et al. (2017) introduced a unique model called Spatio-Temporal Autoencoder (STAE) in a different domain that learns video representation and detects anomalies in the video by extracting features from spatial and temporal dimensions using deep autoencoders. The utilisation of reconstruction error shares common points with the approach employed by Hasan et al. (2016). Once their model was trained, both studies produced a \"regularity score\" based on the reconstruction error, highlighting that video sequences with regular events had low errors. In contrast, anomalous sequences had high errors, allowing them to spot anomalies."}, {"title": "2.4.2 \u0410\u043f\u043emaly Detection Based on Clustering through Latent Features", "content": "Clustering is organising unlabelled data into similar groupings known as clusters. A cluster is a group of data items that are similar to one another but differ from other clusters (Serra & Tagliaferri, 2019). When labelled data is not available, clustering offers a valuable alternative to supervised learning techniques.\nNevertheless, most traditional clustering algorithms are sensitive to the dimension of the input data, making them suffer from \u201cthe curse of dimensionality\u201d (Saxena et al., 2017), which makes them less effective in high-dimensional spaces than in low-dimensional data (Aggarwal & Reddy, 2013). In order to solve this problem, dimensionality reduction-based clustering algorithms have been developed. These techniques translate data to lower"}, {"title": "3 Methodology", "content": "The code within this research has been developed using Python 3.10.10. The procedures related to autoencoder modelling, including training, compilation, fine-tuning, and adaptation, were developed using TensorFlow 2.10.0 (Abadi et al., 2016). In the context of clustering, the Scikit-learn 1.2.2 library was employed (Pedregosa et al., 2018)."}, {"title": "3.1 Data", "content": "This paper focuses on the region of Australia. It includes seven states: New South Wales (NSW), Northern Territory (NT), Queensland (QL), South Australia (SA), Victoria (VI), Western Australia (WA), and Tasmania (TA). The dataset used is a combination of 2 datasets. The first dataset, released by IBM, is the historical weather and vegetation index. It was released for the Call for Code Spot Challenge for Wildfires competition, and is publicly available (IBM, 2020). It includes historical weather and vegetation index information from 2005 to 2021 as daily aggregated values. The second dataset, the Wildfires dataset is a component of the main dataset (IBM, 2020) and it is only used to evaluate the performances of the obtained model. Since we are following an unsupervised approach, the \"wildfire\" ground truth information obtained from the Wildfires dataset is not used during any training phase. Necessary information regarding the datasets is summarised in Table 1."}, {"title": "3.1.1 Feature Importance", "content": "Given that certain variables might be interrelated, and some may not provide significant value, RF models inherently select a subset of significant variables for classification, instead of using all variables, and thus enhancing the classification performance of high-dimensional data. This feature selection can be visualized through \"Gini importance\", also known as mean decrease in impurity (MDI), which ranks the relevance of features (Sutera, 2021). RF was employed to get a feature importance plot with MDI values, as seen in Figure 2. Parameters used for the RF fit can be found in Table 3."}, {"title": "3.1.2 Data Split", "content": "The data is split into three parts: training, validation, and testing. For training, data with only normal (non-wildfire) cases are used. A mix of data from both classes is needed for the validation and test parts. The original dataset has 14,299 non-wildfire (NW) cases (35%) and 26,677 wildfire (W) cases (65%). This imbalance within the classes arises due to the daily aggregation of data. If even a single minor wildfire is reported on a given day, that day is labelled as a \"wildfire\", increasing the wildfire count.\nThe autoencoder is trained solely on non-wildfire data. Therefore, a substantial portion of NW from the original dataset (12,869 cases) is allocated to the train data, ensuring maximum use of the non-wildfire information present. The remaining NW cases are evenly divided between the test and validation datasets, with each receiving 715 NW cases. For test and validation datasets, wildfire cases are initially split into 13,338 and 13,339, respectively. However, given that the train data consisted of a total of 12,869 instances, these numbers seemed disproportionate. To address this, 1,000 wildfire cases are randomly dropped for both the test and validation datasets. Thus, each test and validation set consists of 1,000 wildfire cases with 715 non-wildfire cases, resulting in datasets with (W=1,000, NW=715).\nThis process ensures that the test and validation dataset sizes are not excessively larger than the train data due to the class imbalance. Consequently, the distribution for training, testing, and validation sets is roughly 80%, 10%, and 10%. Still, it is worth noting that, since some instances had to be dropped due to the imbalance in the original dataset, some information in the original data was not fully utilized during modelling, which could be listed as a limitation. This whole procedure is applied separately for both Dataset 1 and Dataset 2. Min-max scaling was employed to ensure that all features in the dataset have a uniform scale, allowing them to contribute equally to the model's per-"}, {"title": "3.2 Methods", "content": "In this study, we focus on two main unsupervised approaches: using a deep autoencoder to obtain latent features for clustering models and using a deep autoencoder to reconstruct input data and identify anomalies through reconstruction errors. These strategies have been discussed extensively in the Related Work section, where their applications and effectiveness in different contexts were reviewed in detail. The main aim here is to fill the research gap in unsupervised learning for wildfire prediction using unlabelled data. Deep autoencoders are utilised to detect anomalies in data, classifying them as \"wildfire\" or \"non-wildfire.\" The model is trained on non-anomaly instances. Two strategies are explored:\n1. Using the deep autoencoder for training, then reconstructing input data in lower dimensions and applying clustering methods to these latent features to differentiate wildfires.\n2. Using the deep autoencoder to reconstruct input data, where high reconstruction errors signify anomalies. Here, both Fully Convolutional (FC) and Long-Short-Term-Memory (LSTM) autoencoders are employed, with the latter being adept at capturing temporal patterns in time-series data, a feature that FC architectures lack."}, {"title": "3.2.1 Deep Autoencoders", "content": "An autoencoder is a unique variant of feed-forward neural networks aiming to have the output closely mirror the input. Figure 3 shows that both the input and output layers have matching dimensions. An autoencoder consists of two main parts: an encoder and a decoder as provided in Figure 3."}, {"title": "3.2.1.1 LSTM Autoencoder", "content": "As mentioned, a deep autoencoder can include hidden LSTM layers in its encoder and decoder components. Using LSTM layers provides the advantage of capturing temporal information, if any, in the time-series data. To utilise the LSTM autoencoder, the dataset must be reshaped into a format compatible with what the LSTM requires. Thus, for the training, testing, and validation datasets, sequences of a 10-day length were prepared. Table 5 showcases the precise shape details of the inputs prior to feeding them into the LSTM autoencoder. Table 6 provides detailed information on the final model's hyperparameter tuning details and the library used for this."}, {"title": "3.2.1.2 Fully Connected (FC) Autoencoder", "content": "Like the LSTM autoencoder, the FC autoencoder incorporates hidden, fully connected layers in both its encoder and decoder parts. The hyperparameter tuning details for the FC autoencoder are detailed in Table 7, which shows the final model setup and the parameters explored. Like the LSTM autoencoder, the FC autoencoder also establishes mirrored architectures, formed with FC layers. Figure 5 represents the FC autoencoder architecture."}, {"title": "3.2.2 Anomaly Detection with Deep Autoencoders", "content": "This section delves into the anomaly detection methodology utilising the deep autoencoder models discussed in the preceding sections.\nThe choice of the two detection strategies is informed by their proven efficacy in the domain of anomaly detection, as highlighted in Section 2. The first approach, using latent features obtained from a deep autoencoder for clustering models, leverages the ability of autoencoders to reduce dimensionality and extract significant features from the data. This method has shown promise in various applications, including environmental monitoring and anomaly detection, as discussed by authors such as Tian et al. (2014) and Ma (2022). The clustering models used\u2014isolation forest, local outlier factor (LOF), and one-class SVM are well-established techniques for identifying outliers in high-dimensional data (Liu et al., 2012; Breunig et al., 2000; Sch\u00f6lkopf et al., 1999).\nThe second approach, using reconstruction errors from a deep autoencoder to identify anomalies, exploits the inherent capability of autoencoders to learn the normal pat-"}, {"title": "3.2.2.1 \u0410\u043f\u043emaly Detection Based on Clustering through Latent Features", "content": "In this case, the encoder segment of the FC autoencoder is employed to extract the latent features from the train and test datasets. These features are compressed from a 28-dimensional space down to an 8-dimensional one. An FC autoencoder is used, pre-trained on the train data (which consists of only non-wildfire cases). Specifically, to obtain latent features, the encoder component of the FC autoencoder is employed. The data dimension for both is reduced from 28 to 8. Then, latent train data is used to fit the cluster model. Three"}, {"title": "3.2.2.2 \u0410\u043f\u043emaly Detection Based on Reconstruction Error", "content": "In this approach, both FC and LSTM autoencoders are employed independently, though the procedure for each remains the same. The hyperparameter tuning details for both FC and LSTM autoencoders are detailed in Table 9. The selected LSTM model is presented in table 10. This model uses a batch size of 32, Tanh activation functions for both the encoder, decoder, and Adam optimizer with LSTM layers [256, 128, 64, 32,16].\nHyperparameter tuning was exclusively conducted for Dataset 1. Consequently, the same architecture of the chosen final model was also used when training Dataset 2. For the FC case, two models emerge as strong candidates for the final selection. These top-tier models will be referred to as Model A and Model B and are presented in table 11. Having the highest F1 scores, they indicate a balance between precision and recall and a decent overall classifier performance. It is decided to assess both and compare their"}, {"title": "3.2.2.3 Performance Metrics", "content": "For both approaches, after getting the anomaly detection/classification results based on test data, the performance of the model on unseen data needs to be evaluated. For this, the model's performance is evaluated against five metrics: Accuracy, precision, recall, F1-score, and Matthew's coefficient (MCC). The following equations present formulas for calculating these metrics, where TP = True Positive, TN = True Negative, FP= False Positive, and FN = False Negative:\nAccuracy = $\\frac{TP + TN}{P+N}$ (4)\nPrecision = $\\frac{TP}{TP + FP}$ (5)\nRecall = $\\frac{TP}{TP + FN}$ (6)\nF1 = 2 $\\frac{(Precision \u00d7 Recall)}{(Precision + Recall)}$ (7)\nMatthew's coefficient (MCC) = $\\frac{TP \u00d7 TN - FP \u00d7 FN}{\\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}$ (8)\nA confusion matrix for each model (Demir, 2022), based on test data, was also produced. Lastly, a ROC curve plot and AUC are plotted and calculated. A ROC curve plots the TP rate in comparison to the FP rate. These values shift relative to one another. Essentially, when the TP rate peaks, the FP rate is at its minimum, and vice versa (Maxion & Roberts, 2004). AUC is a key metric for assessing a binary classifier's performance. It ranges from 0.5 (equivalent to random guessing) to 1.0 (a flawless classifier). AUC evaluates the effectiveness of score classifiers by considering all potential classification thresholds. (Melo, 2013)."}, {"title": "4 Results", "content": ""}, {"title": "4.1 Anomaly Detection Based on Clustering through Latent Features", "content": "In this section, two different models and their results will be presented for each cluster model type (Isolation Forest, LOF, and one-class SVM). While the first one is the best model according to the hyperparameter tuning, the other one will have different parameters for the sake of the comparison of the parameters and performance."}, {"title": "4.1.1 Isolation Forest", "content": "Based on Table 12, Model (A) assumes half of the data is anomalous (0.5), while Model (B) only assumes 0.2 of the data is anomalous due to the contamination parameter. This discrepancy leads to a significant difference in their performance."}, {"title": "4.1.2 LOF", "content": "In 13 and Figure 7, it is seen that Model (C) outperformed in recall (76.6% vs 60%) and F1-score (71.9% vs 65.5%), indicating its superiority in detecting real anomalies. In contrast, while Model (D) has a higher precision of 72%, it struggles to identify all real anomalies, as revealed by its low recall of 60%.\nWhile drawing definitive conclusions on the influence of the number of neighbours from just two models is challenging, there is a trend: models with better accuracies consistently have a higher number of neighbours in LOF. Similarly with isolation forest, the contamination parameter significantly drops LOF's performance. It typically reflects the"}, {"title": "4.1.3 One-Class SVM", "content": "Both models, (E) and (F), employ the RDF kernel, allowing us to compare the performance metrics due to the variations in the Nu parameter Table 14. The difference in the Nu values significantly impacts the models' performances. Model (E), with a Nu value of 0.6, exhibits better overall performance across all metrics than Model (F), which has a Nu value of 0.3. Specifically, Model (F)'s performance lags, especially in terms of recall (32.2%), which is considerably lower than Model (E)'s recall (66.2%) as in Figure 8."}, {"title": "4.1.4 Visualization of the Results", "content": "Figure 9 represents the anomaly detection results of all three techniques on 3D maps with PCA features. PCA features are created here just for visualisation purposes. The actual clustering, fitting, and prediction processes utilise the original latent data generated through an autoencoder, detailed in Section 3.2.2.1. Latent test data, which is 8-dimensional, is reduced into 3-dimensional data using PCA so that it is possible to vi-"}, {"title": "4.2 Anomaly Detection Based on Reconstruction Error", "content": ""}, {"title": "4.2.1 LSTM autoencoder", "content": "The model definition used for the training was presented in Table 10. Both datasets training underwent training for 200 epochs, incorporating an early stopping mechanism to mitigate overfitting. Figure 10 displays the training and validation loss plots of the LSTM autoencoder for both Dataset 1 and Dataset 2.\nFor Dataset 1, although the initial epochs show fluctuations, the model seems to stabilize and converge without any evident signs of overfitting or underfitting. Both the training and validation losses exhibit a consistent declining trend across the 200 epochs in Figure 10. Early stopping is not triggered, suggesting that extending the training might further reduce validation loss. For Dataset 2, the loss plots appear less consistent. Around the 125th epoch, there is a sudden spike in loss followed by a rapid decline. Even as training continues to the 175th epoch, the model does not attain much additional learning. Table 15 presents the obtained performance metrics of models on the test data for Dataset 1 and Dataset 2.\nFrom Table 15 and Figure 11, it is observed that the model trained on Dataset 1 demonstrates better performance in Accuracy, Precision, Recall, and F1-score compared to the model trained on Dataset 2, which retains only 17 variables. However, an important point for both models is that MCC is very low. While the first model's MCC is closer"}, {"title": "4.2.2 FC Autoencoder", "content": "The models A and B trained in this scenario were presented in Table 11. Each model's training process spanned 400 epochs, with an early stopping (patience criteria as 20) integrated to avoid potential overfitting.\nBased on Figure 13, the FC Autoencoder Model A demonstrates steady convergence in its training and validation loss plots for both Dataset 1 and Dataset 2. This smooth progression suggests effective learning without erratic fluctuations, which is favourable.\nHowever, the early stopping could have been triggered earlier. This might indicate that the early stopping criteria, the patience parameter, which is 20, in this case, were set too early, which allowed the model to train longer than necessary without significant performance gains.\nIn Figure 14, the FC Autoencoder Model B shows a less consistent convergence than Model A across both datasets. Notable fluctuations in loss are observed, with early stopping triggered around the 120th epoch for Dataset 1 and the 100th epoch for Dataset 2. Additionally, a significant gap between training and validation losses in Dataset 1 suggests potential overfitting, contrasting with the performance observed in Model B.\nTable 16 represents the obtained performance metrics of Models A and B on the test data of Dataset 1 and Dataset 2. Upon analysing the performance metrics from Table 16 and confusion matrices in Figures 15 and 16, several insights emerge regarding the efficacy of Models A and B across Datasets 1 and 2. For Dataset 1, both models show relatively similar performance metrics. However, a key distinction arises in the recall, where Model B has a noticeable advantage with 71.4% while Model A's recall is 68%. On the contrary, the MCC value of Model A is slightly higher than Model B, which may be due to its use of the Cyclical Learning Rate scheduler, enabling more refined learning rate adjustments. For Dataset 2, although both models showcase very close precision, Model B compensates again with a better recall, offering 60.7% against Model A's 55.5%. Model B also marginally outperforms Model A in accuracy and MCC."}, {"title": "5 Discussion", "content": "In this research, two different unsupervised learning approaches to detect wildfires in Australia with deep autoencoders have been implemented successfully.\nThe first approach was anomaly detection based on clustering through latent features using deep autoencoders. Here, firstly an FC autoencoder is trained and applied to reduce the data dimension from 28 to 8. Then, this latent data is fed into three different clustering methods (isolation forest, LOF, and one-class SVM) to spot outliers. This approach presented several challenges. First, the performance metrics of all three methods were closely dependent on specific parameters, especially the contamination and Nu values. For instance, the recall value for the isolation forest model dropped sharply from 67.5% to 33.7% when contamination was decreased from 0.5 tom 0.2. Adjusting contamination and Nu values, while helpful, may only serve as a specific short-term solution. In addition, considering that these techniques are implemented in an \"unsupervised learning\" way, it is important to remember that a real-life scenario will not have ground truth labelled (wildfire or non-wildfire) data available for parameter adjustment. Another challenge related to how the anomaly data spread out. Thanks to 3D map visualisations done using PCA components, it was observed that anomaly data outliers did not cluster separately from the usual normal data points. Consequently, due to these challenges and results, clustering techniques alone were not sufficient, robust, or efficient in distinguishing anomalies in this wildfire dataset. This realisation triggered the exploration of alternative strategies, guiding us to the second approach: anomaly detection using deep autoencoders, primarily based on reconstruction error.\nThe second approach involved using deep autoencoders to detect anomalies by using the reconstruction error. The approach involved training the deep autoencoder on normal data points and then using this trained model on the reconstruction of test data. Anomalies have higher reconstruction errors while normal data points have low errors. Two different deep autoencoder type were implemented: LSTM and FC.\nIn the LSTM autoencoder case, a final model architecture was determined after hyperparameter tuning and was applied to both Dataset 1 and Dataset 2. The model trained on Dataset 1 showcased better performance metrics with an accuracy of 56.3%, whereas the model trained on Dataset 2 managed only 45.7%. A consistent issue with both models was their tendency to misclassify non-wildfire cases, often labelling them as wildfires. Ultimately, the performance of both models is not sufficient, as their AUC values close to 0.5 suggest nearly random predictions. Our initial assumption was that utilizing LSTM layers would be advantageous given the time series nature of the data, hoping to capture temporal information. However, this assumption did not hold true in practice. Potential reasons include the short sequence span of 10 days, which might not provide enough temporal context. Additionally, the daily aggregation of the data could have lost valuable temporal patterns that LSTM layers might have captured. Lastly, one can note that low values of accuracy are expected given the challenging nature of the data and the lack of historical ground truth. Eventually, the goal of this study is not to filter out methods with poorer performance but to provide a comprehensive comparison.\nThe final modelling phase employed an FC autoencoder. Two promising models obtained from hyperparameter tuning were utilized on both Dataset 1 and Dataset 2. The first model leveraged the Adam optimizer with a learning rate scheduler, while the second relied on RMSProp without any scheduler. Despite the compact 17-feature dimension of Dataset 2, the models maintained strong metrics on this dataset as well. However, Dataset 1's models did perform better eventually. Most impressively, the top model - using RMSProp without any scheduler - recorded an accuracy of 71.1%, an F1-score of 74.2%, and an MCC of 0.417. These figures are significantly higher than what is achieved with earlier methods, highlighting the effectiveness of this approach and the use of FC layers in deep autoencoders."}, {"title": "6 Conclusion", "content": "In environmental science and disaster prevention, detection, and prediction of wildfires in time, especially in vulnerable regions such as Australia, remains a crucial concern. This research successfully employed several unsupervised learning techniques, in the context of anomaly detection with deep autoencoders, to predict wildfires in Australia. This approach fills a gap in the field of wildfire prediction.\nOur research explored two primary methods. The first method focused on anomaly detection using latent features extracted from a deep autoencoder and demonstrated initial promising results. Utilizing the FC autoencoder enabled significant dimensionality reduction, and when paired with clustering techniques like isolation forest, LOF, and one-class SVM, yielded some encouraging results. However, while these methods showed potential, they were somewhat sensitive to specific parameters, which could affect their reliability in real-life scenarios without labels. Furthermore, the fact that anomaly data is"}]}