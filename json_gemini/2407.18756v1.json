{"title": "Evaluating Human Trajectory Prediction with Metamorphic Testing", "authors": ["Helge Spieker", "Nassim Belmecheri", "Arnaud Gotlieb", "Nadjib Lazaar"], "abstract": "The prediction of human trajectories is important for planning in autonomous systems that act in the real world, e.g. automated driving or mobile robots. Human trajectory prediction is a noisy process, and no prediction does precisely match any future trajectory. It is therefore approached as a stochastic problem, where the goal is to minimise the error between the true and the predicted trajectory. In this work, we explore the application of metamorphic testing for human trajectory prediction. Metamorphic testing is designed to handle unclear or missing test oracles. It is well-designed for human trajectory prediction, where there is no clear criterion of correct or incorrect human behaviour. Metamorphic relations rely on transformations over source test cases and exploit invariants. A setting well-designed for human trajectory prediction where there are many symmetries of expected human behaviour under variations of the input, e.g. mirroring and rescaling of the input data. We discuss how metamorphic testing can be applied to stochastic human trajectory prediction and introduce the Wasserstein Violation Criterion to statistically assess whether a follow-up test case violates a label-preserving metamorphic relation.", "sections": [{"title": "1 Introduction", "content": "Human trajectory prediction (HTP) is the task of predicting the future paths that individual humans may take based on the trajectories of their past movements and environment. It is a key component in many autonomous systems that must be aware of its environment, one being automated driving [17]. Here, a specific focus is on predicting future trajectories of other traffic participants, like pedestrians or cyclists. This group is commonly referred to as Vulnerable Road Users (VRUs) and due to their difference in movement patterns to vehicles, predicting their trajectories is a separate task.\nHuman trajectory prediction is an active research area, and current methods have achieved strong results [2, 7, 10, 18, 23, 25, 33, 40]. Despite these recent advancements, ensuring the robustness, accuracy, and reliability of these prediction models is still a challenge. It is crucial to rigorously test these models to identify potential flaws, enhance their performance, and ensure their safe practical application [37]. Some work exists in the domains of adversarial testing [3, 4, 15, 36, 45, 47] and verification [44] with a focus on creating specific failure cases.\nGiven that HTP models are machine learning systems and operate stochastically, testing does not only serve the detection of bugs, but also to measure the model performance. While the HTP test data contains a ground-truth future trajectory, many alternative trajectories would have been similarly realistic and a broader evaluation scheme besides the distance to one ground-truth trajectory would give more information about robustness of the method [24].\nApplying metamorphic testing to human trajectory prediction addresses the complexities and non-determinism of these models, where traditional testing is hindered by the lack of precise ground-truth data and the challenge of obtaining accurate datasets. Metamorphic testing enhances robustness by identifying edge cases and subtle errors by validating metamorphic relations, which are properties the output should maintain under input transformations. We envision the application of MT for human trajectory prediction in the sense of traditional testing, but also to expand the evaluation setting by providing a more diverse view of the robustness of the models under input transformations without requiring additional involvement in data collection and labelling."}, {"title": "2 Background", "content": ""}, {"title": "2.1 Metamorphic Testing", "content": "Some programs are considered as being non-testable because it is not possible to define complete and correct oracles for them [38]. Such non-testable programs include supervised machine learning models which generalise their prediction after being trained on a set of labelled instances [43]. The exact behaviour of these models largely depends on the datasets used to train them, and their predictions are usually marred by uncertainties. Metamorphic Testing (MT) is a software test input generation method which copes with non-testable programs by leveraging user-defined properties of the system, called metamorphic relations and generating follow-up test cases by using these relations [5, 6].\nDefinition 2.1 (Metamorphic Relation (MR)). Let P be a program under test, x and y two test inputs for P, then a MR for P is expressed as a relation $\u2200x, \u2200y, r_i(x, y) \u21d2 r_o(P(x), P(y))$ where P(x) (resp. P(y)) denotes the execution of P on x (resp. y).\nIt's worth noting that MRs are necessary (but not sufficient) properties to ensure the correctness of P w.r.t. its specification. Formally speaking, $r_i(x, y) \u2227 \u00acr_o(P(x), P(y)) \u21d2 \u00accorrect(P)$. MRs are convenient properties for generating follow-up test cases.\nDefinition 2.2 (Follow-up test cases). Let $r_i(x, y) \u21d2 r_o(P(x), P(y))$ be an MR for P, then if there exists a transformation f (possibly non-deterministic) such that $y = f(x)$, then it becomes possible to generate a sequence of follow-up test cases from x, namely $<x, t(x), t(t(x)), ... >$ which all have to fulfil the MR for P. Thus, the transformation t is convenient to generate follow-up test cases.\nAs noted in Segura's survey [31], many MRs can be identified for testing a program. A key difficulty in MT is thus to find MRs and determine which ones have the greatest fault-revealing capabilities. MT has been extensively used to test trained ML models including simple classifiers [26, 39], deep learning models [9], machine translation [35], object detection and classification [34]. MT has received considerable attention in the automated driving field [8], but to the best of our knowledge, it has not yet been applied to test human trajectory prediction models."}, {"title": "2.2 Human Trajectory Prediction", "content": "Recent research explores the prediction of human trajectories in different contexts. Multiple methods can be categorised based on the multimodality in predicting, the input signals fed to the prediction model, and the type of the output provided by the model.\nHuman trajectory prediction models have multiple modalities. Unimodal models assume that there is a single probable outcome or future path, multiple methods have been proposed such as Social Forces [14], Social LSTM [1]. On the other hand, multimodal models consider multiple possible outcomes or future paths. This type of prediction acknowledges the inherent uncertainty in forecasting and provides several potential trajectories or trends based on the given data or input signals. Some multimodal models are based on generative aspects such as DESIRE [16], Trajectron++ [30] and Introvert [32] where the idea is to generate the stochastic outcome in future predictions through a learned latent variable with a defined prior distribution. Others, e.g. [19, 21, 46], are based on spatial probability estimates, where the multimodality is obtained through estimated probability maps.\nDepending on the prediction model, multiple input signals can be expected, such as the human pose and gaze of other pedestrians in the scene. These signals can reveal the immediate intentions of the individual and the potential interactions, that can influence the trajectory of the individual. RGB scene images can offer a comprehensive view of the environment. Scene semantic representations and location data can provide context, thus enhancing the accuracy of the prediction.\nCurrent trajectory prediction models are multimodal, meaning they take into account more than just the past motion of objects. They incorporate additional information, such as environmental maps. Furthermore, these models generate a stochastic output, representing multiple potential human trajectories, projecting the inherent uncertainty and variability in human behaviour and movement [42].\nDefinition 2.3. Multimodal Human Trajectory Prediction Given the historical information, the objective of the model is to predict the distribution of a human's trajectory for T future timesteps. The model learns the parameters & of the probability $P_\u0398(Y|X, M)$, where X represents trajectory history, M represents the map or environment information, and Y represents the predicted trajectory. For a given agent i, the model predicts the future positions in the next T timesteps from the current time t, defined as $Y_i = (Y_{t+1}, Y_{t+2}, ..., Y_{t+T})$. The model's input is the historical information in the past n timesteps, denoted as $X_i = (X_{t-n+1}, X_{t-n+2}, ..., X_t)$."}, {"title": "3 Related Work", "content": "Forecasting the trajectory of pedestrians based on their past movements is important to design safe automated driving systems. Previous work has addressed the challenge of verifying the robustness of HTP models by considering adversarial attacks [3, 4, 15, 36, 45, 47]. However, many of these works have just translated adversarial attacks proposed in the context of image classification and object detection tasks without taking into account the peculiarities of HTP model robustness verification. Recently, by using probably approximately correct (PAC) learning and formalising the notion of HTP robustness, Zhang et al. have proposed in [44] a rich framework to verify the robustness of pedestrian trajectory prediction models. Using ablation studies, Uhlemann et al. have proposed to evaluate HTP model safety in the context of automated driving [37]. These approaches are interesting, but they do not rely on systematic testing methodologies, which can detect faults consistently.\nTo the best of our knowledge, MT has not yet been used for testing HTP models, but approaching the verification of stochastic systems with MT is not new [6]. Introduced by Guderlei and Mayer, statistical MT replaces traditional violation criteria, i.e., the"}, {"title": "4 Metamorphic Testing of Human Trajectory Prediction", "content": "We present an MT method for human trajectory prediction (HTP), designed for handling stochastic prediction outputs. Current HTP models expect as input the previous trajectory of the human plus additional information. We consider HTP models where the additional information is a visualisation of the environment from birds-eye view, e.g. from a drone recording. This is a common setup in the HTP literature [20, 22, 23, 28]. To be useful for HTP, the image input is segmented to identify the different regions in the scene, which give an indication of which areas are walkable and which are more likely to be used.\nBoth the historical trajectory and the environment can be modified by the metamorphic relations. The historical trajectory can be manipulated directly, as it is a sequence of (x, y) tuples. Manipulating the image input directly is more difficult to do automatically and runs the risk of introducing unrealistic artefacts that hinder the testing process, even with modern generative ML models. For this reason, we manipulate the input on the level of the segmented image, i.e. after the first input processing step. Figure 1 visualises the inputs and outputs of a HTP model. The left side shows the original RGB image, the input trajectory (blue) and a set of sampled output trajectories (red). The right side shows the corresponding segmentation map of the RGB image with colour-coded areas. In this example, five different area types plus a background class are distinguished, which is common in the literature [20, 22], but other class structures are possible.\nIn the following, we will first introduce the metamorphic relations and the violation criterion for follow-up test cases before we bring everything together into the overall metamorphic testing process for H\u03a4\u03a1."}, {"title": "4.1 Metamorphic Relations", "content": "We introduce a set of metamorphic relations (MRs) to transform source test cases into follow-up test cases. A test case in HTP is the combination of segmentation map and input trajectory of past motion history. The MRs considered in this study are mirroring the input in the horizontal or vertical axis and changing the rescaling factor of the segmentation map, i.e. resizing the map and trajectory. All of these MRs are revertible, i.e. the source test case can be reconstructed from the follow-up test case, and label-preserving, i.e. if available ground-truth labels were transformed similarly they could be evaluated. For our violation criterion, ground-truth labels are not required.\nDefinition 4.1 (MR1: Mirroring). The input is mirrored along the horizontal or vertical axis of the segmentation map.\nMirroring is a basic transformation, and the HTP model should be robust against these transformations. Mirroring might lead to corruption when applied to the original image, for example, in Figure 1a the label \"Slow\" on the street would be unreadable. The segmentation map (Figure 1b) does not carry this level of detail and is not corrupted by the mirroring operation.\nDefinition 4.2 (MR2: Rescale). The rescaling factor of the original image is modified.\nThe intuition for this MR is that the original input images are resized before they are processed. However, the exact input size is not fixed and can be varied. The distribution of trajectories should be consistent, independent of the size of the input image.\nThe MRs presented here are not exhaustive, but they were selected for being intuitive and label-preserving, allowing us the evaluation of the Violation Criterion, that we will introduce next."}, {"title": "4.2\nWasserstein Violation Criterion", "content": "As part of the testing process, we must validate whether the result for the follow-up test case violates the MR. This validation is performed through a violation criterion. In many MRs, the violation criterion is a basic comparison, e.g. a violation occurs if the result of the follow-up test case is {=, =, <, >, <, >} than the source test case result. However, the HTP model is a stochastic system and returns a distribution of future trajectories. Here, a basic comparison itself is not suitable, and we need a different violation criterion. This violation criterion must compare two distributions of trajectories and decide whether they are reasonably similar or whether there is a substantial difference, such that the underlying MR is violated.\nWe propose the Wasserstein Violation Criterion (WVC) for the detection of faults in label-preserving MRs in HTP. The WVC approaches the comparison of the two distributions as an optimal transport problem [27], i.e. it determines the minimal cost to transform one distribution into the other. Specifically, we compare the trajectory distribution using the Wasserstein distance. The Wasserstein distance is based on a matching between the sampled trajectories in each set, where the overall distance between the matches is minimal. Intuitively, it is described as the minimal cost to transform one probability distribution into the other, and also referred to as earth mover's distance [29], which visualises the optimal transport concept for two piles of earth that represent two distributions and should be compared by moving as little earth as possible. For HTP,"}, {"title": "4.3 Test Process", "content": "Algorithm 1 outlines the metamorphic testing process for a single source and follow-up test case. The process follows the general structure of metamorphic testing and its three phases: First, the source test case is sampled and the system-under-test is executed with it. In our case, to handle the non-determinism in the HTP model, we execute the SUT multiple times - parametrized by the parameter N - and calculate the pairwise Wasserstein distances between the predictions and calculate statistics. Afterwards, the test case is transformed according to the selected MR and executed once. In the evaluation phase, the result of the follow-up test case is compared against each source test case execution and the z-test is calculated to detect potential violations."}, {"title": "5 Experiments", "content": ""}, {"title": "5.1 Experimental Setup", "content": "We use the Stanford Drone Dataset (SDD) [28], which is widely used in the trajectory prediction literature [20, 22]. The dataset consists of 11,000 unique pedestrians in 8 top-down scenes around the Stanford University campus. To avoid data leakage, we take the scenes from the test split of the dataset as in [22].\nSince we utilise the existing test set of SDD, we have ground-truth information available for our experiments. We use this ground-truth information to calculate the standard trajectory prediction metrics ADE and FDE for the source and follow-up predictions. These metrics form a reference to interpret the effectiveness of the stochastic violation criterion and the general effect of the metamorphic transformations on prediction performance.\nThe system-under-test (SUT) is the YNet trajectory prediction model [22] using the publicly available, trained model weights\u00b9 and the experimental parameters. We test two forecasting settings, following the experimental conditions from Mangalam et al. [22]. Short-term forecasting has a $t_p$ = 3.2 second past motion history, sampled at 2.5 FPS, and a prediction horizon of $t_f$ = 4.8 seconds. Long-term forecasting has a $t_p$ = 5 second past motion history,"}, {"title": "5.2 Results", "content": "Table 1 and Table 2 summarise the results for each forecasting setting, separated per metamorphic relation. We observe a close similarity in detected violations of the metamorphic relation for the proposed Wasserstein violation criterion, which does not need any ground-truth labels, and the ground-truth dependent Mean-ADE and Mean-FDE. This similarity occurs in both forecasting settings.\nThere is further a strong difference in ADE/FDE values between BoN and Mean, especially in the short-term forecasting setting. Here, the forecasting horizon is smaller and the variation that the sampled trajectories can have is more limited than in the long-term forecasting setting.\nWe perform an additional experiment to investigate the agreement between the violations detected by WVC and the ADE/FDE-based criteria. The experiment is approached as a binary classification problem, where the ADE/FDE-detected violations are considered the class labels and the WVC-detected violations are the predictions. We report accuracy, precision, and recall over multiple p-value thresholds to understand the sensitivity of the results, too.\nThe results are shown in Figures 2 and 3. They confirm for both settings that there is a substantial agreement between detected violations of WVC and Mean-ADE/FDE. At the same time, they show that the p-value threshold is relevant to be adjusted per setting. In short-term forecasting, increasing the p-value threshold improves all metrics, whereas it has the opposite effect in long-term forecasting and decreases the overall classification quality."}, {"title": "6 Conclusion and Future Work", "content": "In this work, we have presented a metamorphic testing approach for human trajectory prediction (HTP). Human trajectory prediction is a stochastic process, and we have adopted the MT methodology accordingly by introducing the statistical Wasserstein Violation Criterion, which identifies violations of label-preserving metamorphic relations through measuring the Wasserstein distances between predicted trajectory distributions and identifying statistically significant outliers. Our experiments with a popular HTP model show that the proposed criterion is similarly effective as an alternative criterion that requires the annotated ground-truth data of the dataset to detect violations.\nIn future work, we will expand our evaluation over more metamorphic relations, trajectory prediction models, involving multiple pedestrians, and other base datasets in an attempt to enhance the existing evaluation setups by transformed and modified test scenarios. Additionally, we will further consider the modelling of dedicated scenarios via custom segmentation maps and input trajectories for broader diversity in the scenarios. This should support the further automation of the metamorphic testing process [12]."}]}