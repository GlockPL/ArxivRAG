{"title": "Knowledge Models for Cancer Clinical Practice Guidelines : Construction,Management and Usage in Question Answering", "authors": ["Pralaypati Ta", "Bhumika Gupta", "Arihant Jain", "Sneha Sree C", "Keerthi Ram", "Mohanasankar Sivaprakasam"], "abstract": "An automated knowledge modeling algorithm for Cancer Clinical Practice Guidelines (CPGs) extracts the knowledge contained in the CPG documents and transforms it into a programmatically interactable, easy-to-update structured model with minimal human intervention. The existing automated algorithms have minimal scope and cannot handle the varying complexity of the knowledge content in the CPGs for different cancer types. This work proposes an improved automated knowledge modeling algorithm to create knowledge models from the National Comprehensive Cancer Network (NCCN) CPGs in Oncology for different cancer types. The proposed algorithm has been evaluated with NCCN CPGs for four different cancer types. We also proposed an algorithm to compare the knowledge models for different versions of a guideline to discover the specific changes introduced in the treatment protocol of a new version. We created a question-answering (Q&A) framework with the guideline knowledge models as the augmented knowledge base to study our ability to query the knowledge models. We compiled a set of 32 question-answer pairs derived from two reliable data sources for the treatment of Non-Small Cell Lung Cancer (NSCLC) to evaluate the Q&A framework. The framework was evaluated against the question-answer pairs from one data source, and it can generate the answers with 54.5% accuracy from the treatment algorithm and 81.8% accuracy from the discussion part of the NCCN NSCLC guideline knowledge model.", "sections": [{"title": "I. INTRODUCTION", "content": "The clinical practice guidelines (CPGs) for cancer diseases provide care pathway guidelines for treating cancer patients. The National Comprehensive Cancer Network's (NCCN) Clinical Practice Guidelines in Oncology [1] are widely used by oncologists to manage cancer patients. The knowledge contained in the NCCN CPGs is frequently updated due to ongoing research in cancer therapy. It is desirable to have a machine-readable knowledge model to manage this knowledge [2] so that the model can be updated quickly and queried accurately. To capture the knowledge contained in the CPGs, several computer-interpretable guidelines (CIGs) models have been proposed in the literature [3], [4]. However, the suggested CIG models have not been widely used in reality; this could be because of the difficulty in transforming CPGs into CIGs and the scarcity of related tools [2], [5]. In our previous work [6], we proposed an automated process for extracting the knowledge components from the NCCN CPGs and creating a knowledge model using the open standard JSON-LD format. The method was validated using the NCCN treatment guidelines for NonSmall Cell Lung Cancer (NSCLC). NCCN publishes treatment guidelines for more than 60 different cancer types. The complexity of the knowledge content of the guideline documents varies depending on the type of cancer. The automated algorithm to create knowledge models should be able to faithfully extract the knowledge components from the NCCN CPG documents for all possible cancer types, irrespective of the complexity of the document content.\n\nThe NCCN oncology guidelines are updated regularly as information regarding cancer treatment advances. As the complexity of the NCCN guidelines increases significantly over time [7], it's necessary to have an automated method to identify the updates in a new version. A page-by-page overview of the modifications incorporated is included in a new version of an NCCN guideline document. However, it would be more convenient if the precise location of the modification on the page could be detected. A before-and-after comparison is also quite helpful in understanding the differences.\n\nOne of the primary purposes of knowledge modeling CPGs is to query the guideline knowledge programmatically to find the relevant information instead of manually finding it. It's desirable to have a question-answering (QA) system that can answer natural language questions from the guideline knowledge models. With the recent advances in the pre-trained large language models (LLM), the performance of the QA systems, including the medical QA systems, has improved significantly [8] [9]. As argued in [10] and [11], an evidencebased QA framework enhances the trustworthiness of a medical QA system. For the rapidly changing guideline knowledge, a retrieval augmented generation (RAG) [12] based LLM application can produce evidence-based responses using the guideline knowledge models as the augmented knowledge base.\n\nThe following are the primary contributions of this work:"}, {"title": "II. METHODOLOGY", "content": "NCCN guideline documents contain an algorithm section that depicts the treatment pathways graphically. The text blocks of treatment paths, called nodes, are joined by directed edges to show the sequential ordering. For different cancer types, the guideline documents use various forms of directed edges to illustrate the complex treatment algorithm, e.g., fan-out edges, multi-segment directed edges, and the edges connected to one after another. A faithful extraction of the edges is required to establish the relation between the nodes correctly.\n\nThe discussion section of the NCCN guidelines includes a detailed explanation of the recommendations given in the algorithm section, supported by clinical data and scientific reasoning. It primarily consists of textual information structured into sections, sub-sections, and paragraphs. The textual data was extracted paragraph by paragraph by recognizing the structure of the guideline documents using heuristics-based algorithms."}, {"title": "B. Knowledge Model Comparison", "content": "The knowledge model for the algorithm section of the NCCN guideline contains various types of nodes and the relations between them. A page-by-page comparison of the node contents is carried out to compare two different versions of such models. The hash of the node contents is matched to find the unchanged nodes. For nodes with varying hash values, a pairwise edit distance-based similarity score between the node contents is calculated. If the score is above an upper threshold, the nodes are considered similar; if the score is below a lower threshold, categorize the node as an added or removed node; otherwise, consider it a modified node."}, {"title": "C. Question Answering Framework", "content": "The question-answering framework utilizes the algorithm section and the discussion section content as two distinct augmented knowledge bases. As a result, two RAG-based question-answering frameworks were created. After combining using RRF, two top-scoring paragraphs were passed along with the question to an LLM. The LLM generates the final answer conditioned on the input paragraphs."}, {"title": "D. Fine-tuning of Embedding Model", "content": "We extracted 398 paragraphs from the treatment part of the discussion section of the NCCN guideline for NSCLC version 3.2022. A set of 1908 synthetic questions was generated from these paragraphs by using an LLM with the appropriate prompt. The retrieval model was fine-tuned using the generated questions and the matching paragraphs to adapt the model for the domain-specific content."}, {"title": "E. QA Dataset Creation", "content": "We gathered the treatment-related information from the data sources, and the potential question-answer pairs were identified manually. Except for the alterations required to convert it to Q&A format, we attempted to keep as much of the original text as possible. The question-answer pairs were saved in XML format, adapted from the MedQuAD [23] dataset."}, {"title": "III. SYSTEM IMPLEMENTATION", "content": "We used the Apache PDFBox [14] library, version 2.0.25, to extract the graphical and textual content from the guideline documents. The textual content was extracted in HTML format by using the PDFBox library. The HTML data was then processed for paragraph-wise extraction of the text."}, {"title": "B. Question Answering Framework", "content": "We used a fine-tuned version of the BAAI General Embedding (BGE) large model [15] to generate the dense vectors. The Faiss library [17] was used to create an index of the dense vectors, and the semantically similar vectors were retrieved using the L2 distance-based similarity search functionality offered by Faiss. The sparse vectors were generated using the BM25 [18] model. We used the Okapi BM25 implementation of the Rank_bm25 [20] library."}, {"title": "V. CONCLUSION", "content": "To make cancer CPGs queryable, we proposed an enhanced version of the automated knowledge modeling algorithm to convert the NCCN guidelines for multiple cancer types. We also proposed an algorithm for comparing the knowledge models for different versions of NCCN guidelines. We created a set of question-answer pairs and a QA framework to explore the possibility of querying the model. Using the algorithm part and discussion section of the NCCN guideline, respectively, the framework can produce the answers with 54.5% and 81.8% accuracy, suggesting a significant scope of improvement for future works. This work focused on retrieving treatment options from the knowledge model for Non-Small Cell Lung Cancer; however, retrieving cancer evaluation recommendations also need to be studied. Also, the study should be broadened to encompass additional types of cancer."}]}