{"title": "LCFed: An Efficient Clustered Federated Learning Framework for Heterogeneous Data", "authors": ["Yuxin Zhang", "Haoyu Chen", "Zheng Lin", "Zhe Chen", "Jin Zhao"], "abstract": "Clustered federated learning (CFL) addresses the performance challenges posed by data heterogeneity in federated learning (FL) by organizing edge devices with similar data distributions into clusters, enabling collaborative model training tailored to each group. However, existing CFL approaches strictly limit knowledge sharing to within clusters, lacking the integration of global knowledge with intra-cluster training, which leads to suboptimal performance. Moreover, traditional clustering methods incur significant computational overhead, especially as the number of edge devices increases. In this paper, we propose LCFed, an efficient CFL framework to combat these challenges. By leveraging model partitioning and adopting distinct aggregation strategies for each sub-model, LCFed effectively incorporates global knowledge into intra-cluster co-training, achieving optimal training performance. Additionally, LCFed customizes a computationally efficient model similarity measurement method based on low-rank models, enabling real-time cluster updates with minimal computational overhead. Extensive experiments show that LCFed outperforms state-of-the-art benchmarks in both test accuracy and clustering computational efficiency.", "sections": [{"title": "I. INTRODUCTION", "content": "Deep learning (DL) is rapidly advancing, fueled by unprecedented amounts of data and achieving significant successes in areas such as signal processing [1]\u2013[6], anomaly detection [7], smart healthcare [8]\u2013[10], and autonomous driving [11]\u2013[13]. However, this data is typically distributed across large-scale mobile devices and the Internet of Things (IoT) [14], [15], with privacy restrictions [16], [17] and network bandwidth limitations [18], [19] preventing its transfer to a central server for training. To address these challenges, federated learning (FL) [12], [20]\u2013[26] has emerged as a privacy-preserving distributed DL paradigm. FL training involves exchanging only model parameters, not raw data, between edge devices and a central server, thereby ensuring privacy and significantly reducing communication overhead [27].\nHowever, data heterogeneity severely impedes the efficiency of democratizing FL across edge devices [28]\u2013[32]. The non-independent and identically distributed (non-IID) nature of device raw data often results in disparate local risks, complicating the task of optimizing a single global model for all devices [33]. To overcome this limitation, clustered federated learning (CFL) [34], [35] groups edge devices into multiple clusters based on similarities in local data distribution. This approach enables intra-cluster collaborative training of a central model tailored to the specific data characteristics of each cluster, thereby improving overall training performance.\nDespite extensive research [36]\u2013[38], current CFL methods still face significant limitations. Firstly, despite differences in data distribution between clusters, some knowledge remains beneficial for sharing. Existing CFL methods isolate clusters, limiting valuable inter-cluster knowledge exchange and resulting in suboptimal test accuracy. Secondly, clustering in CFL necessitates computing the similarity between device models and cluster centers. However, with the rapid expansion of the number of edge devices participating in FL [14], the computational cost of these similarity measurements has increased substantially, thus hindering training convergence.\nTo address these challenges, we propose LCFed, a novel and efficient CFL framework. LCFed splits the model and employs specialized training and aggregation strategies for distinct sub-models, thereby effectively integrating global knowledge within each cluster to optimize training performance. Furthermore, LCFed customizes a computationally efficient measure for model similarity. By offline sampling devices to compute a model rank decomposition matrice, LCFed enables the server to update similarities using low-rank models, significantly reducing server-side computational overhead. Our key contributions are summarized as follows.\n\u2022 In this paper, we propose LCFed, an efficient CFL framework for heterogeneous data. To the best of our knowledge, LCFed is the first CFL framework to achieve optimal training performance by employing model splitting to facilitate simultaneous knowledge sharing at both the intra-cluster and global levels.\n\u2022 We investigate the computational overhead of clustering in CFL and customize a low-rank model-based similarity measurement method for LCFed. This approach significantly reduces the server\u2019s computational burden for cluster assignments, particularly in large-scale scenarios.\n\u2022 We conduct experiments on diverse real datasets in heterogeneous settings to demonstrate the superior overall performance, robustness, and computational efficiency of LCFed, surpassing state-of-the-art methods."}, {"title": "II. PROBLEM FORMULATION", "content": "We consider a typical FL scenario where each device $i \\in [m]$ possesses its private dataset $D_i$ from distribution $P_i(x, y)$, where $m$ is the number of devices, $x$ and $y$ represent the input features and corresponding labels. In LCFed, each device $i$ trains a personalized model $f_i(w_i; \\cdot)$ with weights $w_i$. The server groups devices into $K$ clusters and trains the cluster center models ${\\Omega_k}_{k\\in[K]}$ to guide the personalized model training within each cluster. Thus, the objective function is:\n$\\min_{\\{w_i\\}_{i=1}^m} \\sum_{i=1}^m \\{\\mathcal{L}_i(w_i) + \\frac{\\mu}{2} ||w_i - \\Omega_{k^*(i, R^*)}||_2^2\\}$ \ns.t. $\nR^* = \\arg \\max_{R \\in R^{m \\times K}} \\sum_{k=1}^K \\sum_{i=1}^m R_{i,k}Sim_i(w_i, \\Omega_k(\\{w_i\\}_{i \\in [m]}, R)), \\qquad (1)$\nwhere $\\mu$ is a regularization factor, $Sim_i(\\cdot, \\cdot)$ measures model similarity, and $R$ is the assignment matrix where $R_{i,k} = 1$ if device $i$ belongs to cluster $k$ else $R_{i,k} = 0$.\n$\\Omega_k(\\{w_i\\}_{i \\in [m]}, R) = \\frac{\\sum_{i=1}^m R_{i,k} w_i}{\\sum_{i=1}^m R_{i,k}}$ is the central model of cluster $k$, and $k^*(i, R)$ represents the cluster to which device $i$ belongs, corresponding to the sole 1 in the $i$-th row of $R$. Note that $k^*$ is well-defined per $R$'s definition."}, {"title": "III. METHODOLOGY", "content": "The core design of the LCFed framework centers on two key innovations: (1) integrating global knowledge into intra-cluster co-training by employing model partitioning, and (2) minimizing the server-side computational costs of similarity updates through the use of low-rank models. An overview of the LCFed framework is illustrated in Fig 1."}, {"title": "A. Global and Intra-Cluster Knowledge Integration", "content": "An inherent limitation of existing CFL methods is their confinement of all knowledge sharing within each cluster. This constraint prevents devices from accessing valuable global-scale knowledge beyond their cluster boundaries, thereby leading to suboptimal performance. To overcome this limitation, we draw inspiration from insights into latent space features of DL models [39], [40], and split the model $w$ into a shallow embedding sub-model $\\phi$ and a deep decision sub-model $h$. The embedding $\\phi$ processes low-dimensional features of input data, providing a foundational representation for subsequent tasks [40]. This representation is less affected by data heterogeneity, making it well-suited for collaborative learning across the global scope [41]. Meanwhile, the decision $h$ captures device-specific data distributions and is ideally shared within the intra-cluster context [42].\nSpecifically, in each training round, the server aggregates device local models $\\{w_i = (\\phi_i, h_i)\\}_{i\\in[m]}$ into a global embedding $\\Phi = \\frac{1}{m} \\sum_{i=1}^m \\phi_i$ and $K$ cluster center models $\\{\\Omega_k = \\frac{\\sum_{i=1}^m R_{ik} w_i}{\\sum_{i=1}^m R_{i,k}}\\}_{k\\in[K]}$. During local updates, device $i$ learns global knowledge from $\\Phi$ and intra-cluster knowledge from its cluster center model $\\Omega_{k^*}$. The optimization objective for local updates is as follows:\n$\\min_{\\{w_i\\}_m} \\{\\underbrace{\\mathcal{L}_{sup}}_{L_{local}} + \\frac{\\mu}{2} \\underbrace{||w_i - \\Omega_{k^*}||_2^2}_{L_{cluster}} + \\frac{\\lambda}{2} \\underbrace{||\\phi_i - \\Phi||_2^2}_{L_{global}}\\}, \\qquad (2)$\nwhere $\\mu$ and $\\lambda$ are regularization factors."}, {"title": "B. Low-Rank Model Similarity", "content": "Another challenge for CFL lies in achieving effective and computationally efficient cluster assignment. Some methods perform clustering only once at the start of training (offline) [43], [44], making the clustering results highly susceptible to early-stage randomness, which compromises robustness and ultimately degrades collaborative training performance.\nIn contrast, online clustering methods continuously update model similarities and cluster assignments at each global round [35], [36]. While this approach yields more effective and robust clustering outcomes, it also imposes a substantially higher computational burden [45], [46]. Current CFL methods typically compute model similarity $Sim_i(\\cdot, \\cdot)$ using cosine similarity or negative L2 distance between device and cluster center parameters for updating assignment matrix $R$:\n$R_{i,k} = \\begin{cases} 1, & k = \\arg \\max_j Sim_i(w_i, \\Omega_j) \\\\ 0, & \\text{else} \\end{cases} \\qquad (3)$\nConsequently, each training round requires $m \\times K$ server-side model similarity measures. As the number of devices $m$ involved in FL training continue to surge [14], [17], the clustering computational cost becomes increasingly substantial.\nTo tackle this challenge, LCFed customizes a low-rank model-based similarity measure. Specifically, at the beginning of LCFed training, we offline sample a subset of devices $S_d$, flattening and concatenating their local updated models into $W_a \\in R^{|S_d| \\times dim(w)}$. We then apply dimensionality reduction techniques (e.g., PCA [47]) to $W_a$, yielding a model rank decomposition matrice $M \\in R^{dim(w) \\times D}$ with low-rank model space dimensionality $D$. Each device $i$ stores $M$ locally and sends the low rank model $M w_i$, along with its updated model $w_i$, to the server in each round. Consequently, the server updates $Sim_i(w_i, \\Omega_k)$ based on these low-rank models:\n$Sim_i(w_i, \\Omega_k) = \\frac{M w_i \\cdot M \\Omega_k}{||M \\cdot w_i||_2 ||M \\cdot \\Omega_k||_2} \\qquad (4)$\nBy using low-rank models, LCFed reduces the similarity computation cost by a factor of around $\\frac{dim(w)}{D}$, and we will discuss the clustering overhead in detail in subsequent experiments. The complete pseudocode of the LCFed framework is presented in Algorithm 1."}, {"title": "IV. EVALUTAION", "content": "We implement LCFed framework using Python 3.7 and PyTorch 1.12.1., and train it with NVIDIA GeForce RTX 3090 GPUs. We adopt the well-known LeNet-5 [48] model, trained with the MNIST [48], CIFAR-10 and CIFAR-100 [49] datasets. We split LeNet-5 into the final fully connected layer as decision $h$ and other shallow layers as embedding $\\phi$. Consistent with previous research [37], [50], we employ the Dirichlet distribution with $\\alpha = 0.1$ and the pathological distribution (where $n$ denotes the number of labels per device) for non-IID data settings. A total of $m = 100$ devices are simulated, with the number of clusters $K$ set to 10. The SGD optimizer is employed with a learning rate set to 0.01. Other hyperparameters include a batch size of 32 and the number of local iterations set to 5. To investigate the advantages of LCFed, we compare it with six other state-of-the-art benchmarks: (1) FedAvg [20]: all devices share a global model; (2) FedPer [51]: devices share a global embedding $\\phi$ while"}, {"title": "V. CONCLUSION", "content": "This paper proposes LCFed, a novel and efficient CFL framework with two key innovations. First, LCFed partitions the model, utilizing specialized training and aggregation strategies for different sub-models, thereby effectively integrating global and intra-cluster knowledge to improve local training performance. Second, by leveraging a low-rank model-based similarity measure, LCFed significantly reduces computational overhead while maintaining robust clustering effectiveness. Extensive experiments demonstrate that LCFed surpasses state-of-the-art benchmarks in both test accuracy and computational efficiency."}]}