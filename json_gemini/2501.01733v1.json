{"title": "Augmentation Matters: A Mix-Paste Method for X-Ray Prohibited Item Detection under Noisy Annotations", "authors": ["Ruikang Chen", "Yan Yan", "Jing-Hao Xue", "Yang Lu", "Hanzi Wang"], "abstract": "Automatic X-ray prohibited item detection is vital for public safety. Existing deep learning-based methods all assume that the annotations of training X-ray images are correct. However, obtaining correct annotations is extremely hard if not impossible for large-scale X-ray images, where item overlapping is ubiquitous. As a result, X-ray images are easily contaminated with noisy annotations, leading to performance deterioration of existing methods. In this paper, we address the challenging problem of training a robust prohibited item detector under noisy annotations (including both category noise and bounding box noise) from a novel perspective of data augmentation, and propose an effective label-aware mixed patch paste augmentation method (Mix-Paste). Specifically, for each item patch, we mix several item patches with the same category label from different images and replace the original patch in the image with the mixed patch. In this way, the probability of containing the correct prohibited item within the generated image is increased. Meanwhile, the mixing process mimics item overlapping, enabling the model to learn the characteristics of X-ray images. Moreover, we design an item-based large-loss suppression (LLS) strategy to suppress the large losses corresponding to potentially positive predictions of additional items due to the mixing operation. We show the superiority of our method on X-ray datasets under noisy annotations. In addition, we evaluate our method on the noisy MS-COCO dataset to showcase its generalization ability. These results clearly indicate the great potential of data augmentation to handle noise annotations. The source code is released at https://github.com/wscds/Mix-Paste.", "sections": [{"title": "I. INTRODUCTION", "content": "VER the past few years, automatic X-ray prohibited item detection, which can assist security inspectors to quickly identify the locations and categories of prohibited items, has attracted much attention. A large number of prohibited item detection methods [1]\u2013[7] have been developed.\nGenerally, existing X-ray prohibited item detection methods depend heavily on a large-scale dataset for model training. Unfortunately, obtaining correct annotations with clean cat- egory labels as well as accurate bounding boxes is labor- expensive and requires the expertise of professionals. Notably,"}, {"title": "II. RELATED WORKS", "content": "In this section, we briefly review several related works. We first introduce X-ray prohibited item detection methods in Section II-A. Then, we review data augmentation methods in Section II-B. Finally, we review the methods of learning with label noise and learning with noisy annotations for object detection in Section II-C and Section II-D, respectively."}, {"title": "A. X-Ray Prohibited Item Detection", "content": "With the development of deep learning technology, auto- matic X-ray prohibited item detection has been widely applied in security inspection. A variety of methods [1], [3], [4], [6], [19]\u2013[25] have been developed to address the severe occlusion and item overlapping problems in X-ray images by introducing attention mechanisms or specifically-designed modules. Wei et al. [1] propose an attention mechanism to enhance the edge and material information of prohibited items. Zhang et al. [3] apply spatial- and channel-wise attention mechanisms to extract discriminative features and incorporate a dependency refinement module to explore long-range dependencies within the feature map. Tao et al. [4] identify the object regions for prohibited item detection by removing the noisy infor- mation from neighboring regions and activating the boundary information. Ma et al. [6] leverage dual-view X-ray images"}, {"title": "B. Data Augmentation", "content": "Data augmentation aims to improve the generalization ca- pability of models by artificially increasing the diversity of the training data. Cutout [26] randomly applies masking to square patches in the image, effectively enforcing the model to learn from incomplete information. Mix-Up [27] generates new training examples by linearly interpolating between two images and their corresponding labels. This encourages the model to generalize beyond the training data and reduce sensitivity to adversarial examples. AlignMix [28] improves representation learning by geometrically aligning and interpo- lating features from multiple images. Such a way enhances the model's generalization and robustness. Mosaic [29] combines four images into one, enabling the model to observe multiple contexts in a single training step. This method increases the diversity of the dataset and exposes the model to more com- plex, multi-object scenes, enhancing robustness to variations in object scale and occlusions. Channel augmentation [30] explores the relationship between visible and infrared images to obtain modality-invariant features.\nRecently, some methods leverage CLIP [31] or the diffusion model [32] to generate new data by using prompt words. Fang et al. [33] propose a data augmentation pipeline based on controllable diffusion models and CLIP for object detection. Gannamaneni et al. [34] generate safety critical scenes by inpainting with diffusion models conditioned on text and pose, offering fine-grained control over pedestrian attributes.\nSome of the above methods perform well in clean X-ray datasets [35]. However, when applied to the X-ray datasets in- volving noisy annotations, the generated X-ray images contain significant disturbances, potentially degrading model perfor- mance. Different from the above data augmentation methods, we design a data augmentation method to effectively alleviate noisy annotations in the X-ray dataset and improve the training performance of the model in the noisy dataset."}, {"title": "C. Learning with Label Noise", "content": "A number of methods [8]\u2013[10], [16], [36], [37] have been developed for learning with label noise. Some methods [38]\u2013 [41] address the label noise problem by employing a noise transition matrix to refine predictions. Goldberger et al. [38] adopt both an s-model and a c-model to effectively obtain a noise transition matrix. Patrini et al. [39] explicitly model the noise transition matrix to correct the loss. Several works [10], [36], [42], [43] reveal that a loss function involving symmetric properties exhibits enhanced robustness against label noise. However, these methods may only be capable of handling certain noisy rates. Recent methods focus on new learning paradigms [9], [44]\u2013[50]. For example, MentorNet [44] leverages a teacher-student framework to learn a robust student model by exploiting the knowledge of a teacher model. Co-teaching [9] trains the two models simultaneously, where each model selects the samples with the small-loss criterion to update the other model. Co-teaching+ [45] improves the performance of Co-teaching by training on disagreement data. JoCoR [46] allows the two models to reach an agreement by minimizing the distance loss predicted by the two models. PurifyNet [48] introduces a hard-aware instance re-weighting strategy to focus on hard samples in the noisy dataset. Ye et al. [49] propose an online label co-refinement framework, which progressively refines noisy labels during model optimization.\nThe above methods mainly handle label noise and focus on the image classification task. In this paper, our method addresses noisy annotations involving both category noise and bounding box noise for training a robust prohibited item detec- tor. Moreover, unlike the above methods that select clean data by designing different strategies, our method addresses noisy annotations from the perspective of data augmentation. In this way, our method does not require estimating/predefining the noise rates or selecting a clean subset as did in conventional label noise learning methods."}, {"title": "D. Learning with Noisy Annotations for Object Detection", "content": "Recently, some methods [11]\u2013[14] have been developed to address robust training on noisy annotations for object detection. Chadwick et al. [11] extend the Co-teaching strategy to the field of object detection. Li et al. [12] decouple bounding box noise from category noise and then leverage the predicted output for category noise correction and bounding box refinement. Yang et al. [13] reduce the influence of noisy labels by employing diverse loss functions. Liu et al. [14] treat each object as a bag of instances and select accurate instances from the object bags for training. Wang et al. [15] develop a novel Bayesian filter-based prediction ensemble method to address noisy bounding box annotations within a teacher- student learning framework.\nThe aforementioned methods are designed for common object detection. In contrast, our method mixes multiple item patches to mimic the characteristics of X-ray images (i.e., the ubiquitous overlapping between items) for prohibited item de-tection. Surprisingly, experiments show that our method is also beneficial in improving the performance of common object detection (which exists a certain level of object overlapping)."}, {"title": "III. METHDOLOGY", "content": "In this section, we first give the problem formulation in Section III-A. Then, we provide an overview of our method in Section III-B. Next, we describe our Mix-Paste method in detail in Section III-C. Finally, we introduce an LLS strategy, which can be effectively combined with Mix-Paste to alleviate the influence of noisy annotations during model training, in Section III-D."}, {"title": "A. Problem Formulation", "content": "Some X-ray datasets involve noisy annotations due to the difficulty of obtaining high-quality human annotations in X- ray images, where item overlapping is prevalent. In this paper, we address the problem of training a robust prohibited item detector on the noisy X-ray dataset, where the noise contains a mixture of category noise and bounding box noise. In addition, we do not assume that a subset with clean annotations is available.\nGiven a noisy dataset $D = \\{(x_i, y_i)\\}_{i=1}^N$, where $x_i$ is the i-the training image and $y_i = \\{c_j, b_j\\}_{j=1}^{J_i}$ denotes the annotation of $x_i$. Here, $c_j$ denotes the label of the j-th prohibited item, $b_j = (\\tilde{x}, \\tilde{y}, \\tilde{w}, \\tilde{h})$ represents the ground-truth bounding box coordinates ($\\tilde{x}$ and $\\tilde{y}$ represent the coordinates of the top-left corner, and $\\tilde{w}$ and $\\tilde{h}$ represent the width and height, respectively) of the j-th prohibited item, and $J_i$ is the number of prohibited items for $x_i$. Unlike the image classification task, the prohibited item detection task often involves two types of noise: category noise and bounding box noise. In this way, the dataset contains class-corrupted instances where the category labels are noisy, and position-corrupted instances where the ground-truth bounding boxes are inaccurate. Hence, we aim to train a noise-robust model based on D and evaluate its performance on the test set."}, {"title": "B. Overview", "content": "In this paper, we develop a simple yet effective data aug- mentation method called Mix-Paste for training on the noisy X-ray dataset. Mix-Paste is a plug-and-play data augmentation method that can be directly applied to the training of different prohibited item detectors. The overview of our method is shown in Fig. 2.\nSpecifically, for each item patch corresponding to a ground- truth bounding box in the training image, we first randomly select several item patches (specified by the ground-truth bounding boxes with the same category label) from different images. Then, we resize these item patches to the same size and mix them. Finally, we can paste the mixed patch back into the original item location in the image. In this way, the mixture of item patches can generate a new training image with reduced noise interference. Note that instead of applying Mix-Paste to all the images, we apply our proposed Mix-Paste to the randomly selected subset of the training set (with a probability), maintaining consistency between the training and test samples. In this way, some X-ray images are generated by Mix-Paste while the other images are unchanged.\nTo obtain a robust detector on the augmented data, we further design an item-based large-loss suppression (LLS) strategy, which suppresses the large losses corresponding to potentially positive predictions of additional items during loss calculation. Technically, we first select the predicted bounding boxes, for which the Intersection over Unions (IoUs) between them and the ground-truth bounding boxes are larger than a threshold. Then, we identify those predicted bounding"}, {"title": "C. Mix-Paste", "content": "We generate a new patch by mixing multiple item patches that share the same category label. To mix these item patches, we crop the item patches from the selected images according to the ground-truth bounding boxes and resize them to the same size. Finally, the mixed patch is used to replace the original patch. Note that we only randomly select patches with the same category label from the whole dataset without assuming that the labels of the selected patches are clean.\nMathematically, the process of generating the mixed patch B is formulated as\n$\\begin{equation}\\label{eq:1}  \\mathrm{B}=\\alpha \\mathrm{B}_{\\alpha}+\\sum_{n=2}^{\\mathrm{K}} \\frac{1-\\alpha}{\\mathrm{K}-1} \\odot resize(\\mathrm{B}_n), \\end{equation}$\nwhere K is the total number of patches for mixing (including the original item patch); $B_\\alpha$ is the original item patch in x; $B_n$ is the n-th item patch randomly selected from the whole dataset; '$\\odot$' is the element-wise multiplication; resize(\u00b7) denotes the function that resizes the item patch to the same size as $B_\\alpha$; $\\alpha$ is an edge smoothing mask to make the mixed patch more natural.\nThe edge smoothing mask is defined as\n$\\begin{equation}\\label{eq:2} \\alpha(i, j)=\\begin{cases} 1-\\left(1-\\lambda\\right) \\cdot\\left(d_{i, j} /(\\beta \\cdot w)\\right), & d_{i, j} \\leq \\beta \\cdot w, \\\\  \\lambda, & d_{i, j}>\\beta \\cdot w, \\end{cases} \\end{equation}$\nwhere $d_{i,j}$ is the distance between the pixel (with the spatial location of (i,j) in the patch) to the nearest boundary of the patch; $\\beta$ denotes a threshold to control the smoothing area (we empirically set $\\beta$ to 10%); w is the width of the bounding box; $\\lambda\\in [0,1]$ is a random number generated from a Beta distribution. Although the edge smoothing mask can allow for the natural appearance of the mixed patch, we also observe that simply merging the patches with linear combinations can also achieve similar performance.\nNote that some methods apply threat image projection for image fusion. However, it is difficult to apply threat image projection in our method due to the following several reasons. First, some threat image projection methods [51], [52] require X-ray images with plain backgrounds to segment prohibited items and superimpose isolated prohibited items onto normal images. As most X-ray datasets do not have X-ray images with plain backgrounds, it is not trivial to obtain isolated prohibited items. Second, traditional threat image projection methods [53], [54] only work on the fusion of gray images. However, most current X-ray datasets are color images (notice that the color information of each prohibited item plays an important role in detection due to the penetration characteristics of X- rays). Therefore, these methods cannot be directly used in our method. Subsequently, the mixed patch is pasted back into the original image, which can be formulated as\n$\\begin{equation} x[\\tilde{x} : \\tilde{x} + \\tilde{w}, \\tilde{y} : \\tilde{y} + \\tilde{h}] = B, \\end{equation}$\nwhere x denotes the original image corresponding to the item patch; $[\\tilde{x} : \\tilde{x} + \\tilde{w}, \\tilde{y} : \\tilde{y} + \\tilde{h}]$ denote the bounding box region of the original item patch $B_\\alpha$.\nWhy does Mix-Paste work? We analyze the reasons why our Mix-Paste can work on the training of X-ray prohibited item detection under noisy annotations. First, Mix-Paste can reduce category noise and bounding box noise explicitly. For an annotated bounding box with the prohibited item label $\\tilde{j}$ in the dataset involving the category noise rate of $P_c$, the probability of the prohibited item within the bounding box region is estimated as 1 \u2212 $P_c$. When K item patches with the same category label $\\tilde{c_j}$ are mixed, the probability of the existence of the item with the label $\\tilde{c_j}$ (which is computed as 1 \u2212 $P_c^K$) is increased. Analogously, suppose that the bounding box noise rate is $P_b$, the probability of the K mixed patch that can accurately bound a correct prohibited item (which is computed as 1 \u2212 $P_b^K$) is also increased. Second, Mix-Paste can effectively mimic item overlapping in X-ray images, thereby enabling the detector to enhance its awareness of overlapping. Third, Mix-Paste can generate more diverse training samples, thereby enhancing the generalization ability of the model.\nCan the mixing operation perfectly mimic item overlap- ping in X-ray images? Some existing data augmentation methods (such as Mix-Up [27]/CutMix [55]) fail to generate data perfectly as the original dataset. However, these data augmentation methods can significantly enhance the model performance in various tasks by substantially increasing the diversity of the dataset. In the same spirit, although the mixing operation in Mix-Paste cannot perfectly mimic item overlapping in X-ray images, it still can encourage the model to learn some characteristics of X-ray images under item overlapping conditions. More importantly, our Mix-Paste is shown to be effective in alleviating the influence of noisy annotations during model training.\nCan Mix-Paste be applied to the segmentation task? Unfortunately, our method is difficult to be applied to the segmentation task. The core idea behind our method is to increase the probability of the target prohibited item appearing within a bounding box by mixing different item patches. It is straightforward to adjust the different sizes of bounding boxes for patch mixing since these boxes are rectangular. However, it is not easy to align the object with different shapes at the"}, {"title": "D. Item-Based Large-Loss Suppression (LLS) Strategy", "content": "After the mixing operation, the probability of the mixed patch containing the correct target prohibited item is increased (the detailed analysis about why our Mix-Paste can work on the training of X-ray prohibited item detection under noisy annotations is given in Section III-C). However, the mixing operation is likely to introduce additional noisy-labeled prohibited items (caused by category noise in some selected patches) during training. In fact, the probability that the selected patches consist of all correct prohibited items is only $(1 - P_c)^K$, where $P_c$ denotes the category noise rate and K is the number of patches. Consequently, the mixing operation may introduce additional noisy-labeled prohibited items during training. In such a case, the model tends to predict these items for the newly generated image during training. However, these predicted bounding boxes will be mistakenly considered as false predictions since their corresponding correct labels are not available. Hence, these potentially positive predictions give large losses in the conventional classification loss calculation, resulting in a negative influence on model training.\nTo alleviate this problem, we propose an item-based large- loss suppression (LLS) strategy. As illustrated in Fig. 2, we categorize the prediction results into four parts, including (1) $P_{B_{neg}}$: the predicted bounding boxes whose IoUs between them and the ground-truth bounding boxes are less than a threshold (e.g., there is no matching between the ground-truth bounding box and the predicted bounding box in Fig. 2(b)); (2) $P_{B_{fb}}$: the predicted bounding boxes whose IoUs are greater than a threshold and the predicted label is the background (e.g., the predicted bounding box position is correct but the category label is predicted to the background in Fig. 2(b)); (3) $P_{B_{pos}}$: the predicted bounding boxes whose IoUs are greater than a threshold and the predicted label is the same as the ground-truth category label (e.g., both the predicted bounding box position and category label are correct in Fig. 2(b)); (4) $P_{B_{pp}}$: the predicted bounding boxes whose IoUs are greater than a threshold and the predicted label (not the background) is different from the ground-truth category label (e.g., the predicted bounding box position is correct but the predicted category label is incorrect in Fig. 2(b)).\nWhen calculating the classification loss, we suppress $P_{B_{pp}}$ from the prediction results and focus on the remaining three parts. Hence, the final loss is calculated as\n$\\begin{equation} L = L_{bbox} + L_{cls_{neg}} + L_{cls_{pos}} + L_{cls_{fb}}, \\end{equation}$\nwhere $L_{bbox}$ denotes the bounding box regression loss; $L_{cls_{neg}}$, $L_{cls_{fb}}$, and $L_{cls_{pos}}$ denote the classification losses for $P_{B_{neg}}$, $P_{B_{fb}}$, and $P_{B_{pos}}$, respectively.\nFor learning with label noise on image classification, the popular small-loss criterion [16], [17] treats samples with small losses as clean samples and considers samples with large losses as noisy samples. However, for prohibited item detection, the loss calculation contains both foreground and background predictions, where the background predictions account for the majority of the total loss. As a result, the small-loss criterion mainly focuses on background predictions and may ignore foreground predictions in this task. In contrast, our LLS strategy is highly effective in handling category noise by removing only the potentially positive predictions.\nWhy does the LLS strategy work? In the LLS strategy, we ignore the predicted bounding boxes whose predicted labels are different from the ground-truth category labels (except for those whose predicted label is the background) when calculating the classification loss. In noisy scenarios, the mixed patches may contain multiple prohibited items because of category noise. Consequently, when these newly generated images are used for training, the model tends to give correct predictions for additional items. However, since these items are not associated with correct labels, they are considered as false predictions and consequently give large losses during model training. This will lead to incorrect model optimization, reducing the overall performance of the model. To mitigate this and enhance the model performance, we suppress the large losses corresponding to potentially positive predictions of additional items for loss calculation. Note that we still compute the loss for those predicted bounding boxes whose predicted labels are the background since the predicted bounding box region contains a prohibited item."}, {"title": "IV. EXPERIMENTS", "content": "In this section, we first introduce the datasets and evaluation metrics in Section IV-A. Then, we present the noise rate estimation and implementation details of our method in Sec- tion IV-B and Section IV-C, respectively. Next, we compare our method with state-of-the-art methods on the noisy X-ray datasets in Section IV-D and the noisy MS-COCO dataset in Section IV-E. After that, we conduct ablation studies in Section IV-F. Finally, we give some visualization results in Section IV-G."}, {"title": "A. Datasets", "content": "In this paper, we conduct experiments on two popular X-ray datasets, i.e., OPIXray [1] and PIDray [3]. OPIXray contains 8,885 images with 5 categories of prohibited items (i.e., different types of cutters). Following [1], we use 7,109 images for training and 1,776 images for testing. We report mAP@.5 and mAP@[.5, .95] as the evaluation metrics. PIDray contains 29,457 images for training and 18,220 images for testing, covering 12 different categories. The images in the test set are further divided into 3 subsets (i.e., easy, hard, and hidden) according to their detection difficulty. Following [3], we use 29,457 images for training and 18,220 images for testing. We report mAP@[.5, .95] as the evaluation metric.\nTo validate the generalization ability of our method to com- mon object detection, we also conduct experiments on MS- COCO [18]. MS-COCO is a public common object detection dataset, which contains more than 135k images for training and 5k images for testing, covering 80 different categories. Following [12], we use train2017 as training data, and report mAP@.5 and mAP@[.5, .95] on val2017."}, {"title": "B. Noise Rate Estimation", "content": "Our research has shown variability in noise rates across dif- ferent X-ray datasets. Specifically, while some X-ray datasets (such as the PIDray dataset) exhibit minimal noisy annotations, we identify that some X-ray datasets (such as the OPIXray dataset) contain a number of noisy annotations (including both category noise and bounding box noise). In these datasets, many bounding box annotations are larger than the actual position of prohibited items while the category labels of some prohibited items are mislabeled due to the great similarity between some prohibited items.\nWe conduct a quantitative analysis of the noise rate on the OPIXray dataset. Specifically, for bounding box noise, we first train a model on the original dataset by treating all the categories as one category. In this way, the influence of category noise is removed. Then, we compare the detection results with the ground-truth labels and filter out samples"}, {"title": "C. Implementation Details", "content": "To effectively evaluate the performance of our method under noisy annotations, we introduce different types of noise to the original dataset. For category noise, we randomly replace the original category label with another category label, with a replacement probability of $P_c$. For bounding box noise, we randomly perturb the original bounding box with a probability of $P_b$. Specifically, for a bounding box with coordinates $(\\tilde{x}, \\tilde{y}, \\tilde{w}, \\tilde{h})$, we randomly perturb the coordinates with a probability of $P_b$ by shifting and scaling the box as follow:\n$\\begin{aligned} &\\tilde{x}=\\tilde{x}+\\Delta_{\\tilde{x}} \\times \\tilde{w}, \\\\ &\\tilde{y}=\\tilde{y}+\\Delta_{\\tilde{y}} \\times \\tilde{h}, \\\\ &\\tilde{w}=\\tilde{w} \\times (1+\\Delta_{\\tilde{w}}), \\\\ &\\tilde{h}=\\tilde{h} \\times (1+\\Delta_{\\tilde{h}}), \\end{aligned}$\nwhere $\\Delta_{\\tilde{x}}$, $\\Delta_{\\tilde{y}}$, $\\Delta_{\\tilde{w}}$, and $\\Delta_{\\tilde{h}}$ are randomly sampled from a uniform distribution U(\u2212\u03b4, \u03b4) (\u03b4 is the perturbation level). We set \u03b4 to 0.3 in all experiments.\nFor all the datasets, we adopt Faster R-CNN (FRCNN) [58] with ResNet-50 as the backbone network. The backbone is initialized with the weights pretrained on ImageNet [59]. The whole network is optimized by the stochastic gradient descent (SGD) algorithm with a momentum of 0.9 and a weight decay of 0.0001. The batch size is set to 2. The initial learning rate is set to 0.005 and decreased by a factor of 10 at the 17th and 21st epochs. The total number of training epochs is 24. The number of item patches K for mixing is set to 2. We apply Mix-Paste to the training set with a probability of 0.6. We only employ the random flip to all the comparison methods. All the competing methods are trained on a machine with an NVIDIA RTX 3090 GPU."}, {"title": "D. Experiments on the X-Ray Datasets", "content": "To verify the effectiveness of our method, we perform experiments on two X-ray datasets with different levels of noise rates for both category noise and bounding box noise. We compare our method with several state-of-the-art methods, including the baseline method (FRCNN [58]), prohibited item detection methods (LIM [4], SDANet [3], and GADet [25]), and learning with noisy annotations methods (SCE [10], LNCIS [13], and OA-MIL [14]). The results are shown in Table I and Table II.\nFor the OPIXray dataset, we can observe that the noise- robust loss function-based method SCE does not perform well. Compared with the baseline, SCE only gives marginal performance improvements at low noise rates. Moreover, when the noise rates are large, the performance obtained by SCE is even lower than that obtained by the baseline method. The performance degradation of SCE can be attributed to its limited ability to handle the bounding box noise. In other words, when both the bounding box noise rate and the category noise rate are high, the performance of SCE is severely affected. The X-ray prohibited item detector LIM shows relatively good anti-noise ability. At some noise rates, it even performs better than LNCIS, a method specifically designed to deal with object detection noise. This is because LIM can filter out irrelevant noisy information in features, making it less prone to overfit the noise. The X-ray prohibited item detector GADet also demonstrates good performance in terms of mAP@[.5,.95]. This can be attributed to its IoU- aware label assignment strategy, which selects high-quality and precise positive samples while ignoring potentially noisy low-quality predictions. Among all the competing methods, our Mix-Paste method achieves the best results at all noise rates. Specifically, our method achieves 81.8% mAP@.5 and 33.7% mAP@[.5, .95] (at the noise rates of $P_c$ = 60% and $P_b$ = 60%), which is 25.1% and 15.3% higher than the baseline, respectively.\nFor the PIDray dataset, the X-ray prohibited item detector LIM and GADet shows good performance. LNCIS can also alleviate the negative influence of noisy annotations to a certain extent. However, it exhibits only marginal performance improvements at high noise rates. At some high noise rates, the performance obtained by OA-MIL is inferior to the baseline, indicating its instability. Compared with the other competing methods, our method consistently gives the best results across all noise rates. Specifically, at the noise rates of $P_c$ = 60% and $P_b$ = 60%, our method achieves a mAP@[.5, .95] of 51.3%, 47.9%, and 21.9% in the easy, hard, and hidden test sets, which is 21.9%, 20.5%, and 8.6% higher than the baseline, respectively.\nThe above results show that our method can greatly improve the performance of the model at both low and high noise rates and enhance the robustness of the model."}, {"title": "E. Experiments on the MS-COCO Dataset", "content": "Our method is mainly designed for prohibited item detection under noisy annotations by considering the characteristics of X-ray images, where item overlapping is ubiquitous. Interest- ingly, object overlapping also exists in some natural images for the common object detection task. Hence, the idea of increasing the probability of target objects in the generated images by fusing the same category label can be also applied to common object detection.\nTo evaluate the generalizability of our proposed method, we conduct experiments on the widely used common object detection dataset, the MS-COCO dataset. The evaluation re- sults are shown in Table IV. From Table IV, we observe that SCE performs poorly. LNCIS shows moderate performance improvements over the baseline method (the vanilla FRCNN). The performance of OA-MIL is unstable, and its performance is even worse than the baseline at some noise rates (e.g., $P_c$ = 40% and $P_b$ = 40%). Compared with the other competing methods, our method gives better performance at different noise rates. Specifically, at the noise rates of $P_c$ = 60% and $P_b$ = 60%, our method achieves 45.3% mAP@.5 and 26.2% mAP@[.5, .95], which is 2.1% and 2.9% higher than the baseline, respectively. These results demonstrate the effectiveness of our method on the noisy MS-COCO dataset, indicating the robustness and broad applicability of our method to data beyond X-ray images."}, {"title": "F. Ablation Studies", "content": "We conduct ablation studies to study the effectiveness of each component in our method. Unless otherwise specified, the noise rates are set to $P_c$ = 60% and $P_b$ = 60% and the LLS strategy is not used (we focus on the evaluation of Mix- Paste). The OPIXray dataset is used.\nEffectiveness of Mix-Paste and LLS. The ablation study results on the key components of our method are shown in Table V. We can see that the performance of our method with only Mix-Paste is better than the baseline by 13.1% mAP@[.5, .95]. This demonstrates the effectiveness of Mix-Paste, which mixes multiple item patches with the same category label to alleviate the influence of noisy annotations. After further applying the LLS strategy, the performance of our method is further improved by 2.2%, verifying the importance of the LLS strategy, which ignores the potentially positive predictions during the mixing process.\nInfluence of the Number of Patches K. We investigate the influence of the number of patches K used in Mix-Paste, as shown in Fig. 3(a). Our method gives a good performance when the values of K are set to 2 and 3. However, when the value of K becomes large (e.g., 4 or 5), the performance obtained by our method decreases. When more patches are mixed, the likelihood of capturing the correct prohibited item is increased. However, such a way also raises the probability of introducing additional prohibited items. As a result, excessive patch mixing can negatively influence the extraction of rele- vant information in the original patch, hindering the learning of correct prohibited items.\nTraining Curve. To verify whether our Mix-Paste can help alleviate the overfitting of noise during model training, we plot the training curve in Fig. 3(b). We can see that the performance obtained by the baseline model increases at the early training stage but gradually decreases at the later training stage. In contrast, the performance obtained by our method is relatively stable at the later training stage. This demonstrates that our method can effectively alleviate the overfitting of the model to noise during training.\nEffectiveness of the Patch Mixing Strategy. In Mix-Paste, we mix multiple item patches with the same category label to generate a mixed patch and paste it back into the original image for data augmentation. To show the effectiveness of our patch mixing strategy, we compare the performance between"}, {"title": "Effectiveness on Different Category Noise Rates and Bounding Box Noise Rates", "content": "We conduct experiments to in- vestigate the effectiveness of our method on different category noise rates and bounding box noise rates on the OPIXray dataset. The results are shown in Table IX. From the results, we can see that OA-MIL is good at addressing category noise, and LNCIS works well on handling bounding box noise. Among all the competing methods, our method can effectively deal with both category noise and bounding box noise, and achieve the best results in all the cases. This proves that our method has a strong anti-noise ability.\nInfluence of the Probability of Applying Mix-Paste. We investigate the influence of the probability p of applying Mix- Paste for augmentation during training. The results are shown in Table X. We can see that when the value of p is 0.6, our method can achieve the best performance. When the value of p approaches 1, the performance obtained by our method decreases or even the training fails. This is because when p is close to 1, all samples are artificially generated. Such a manner can lead to significant inconsistency between the training samples and the test samples, making the distribution of"}]}