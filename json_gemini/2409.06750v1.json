{"title": "Can Agents Spontaneously Form a Society?", "authors": ["Hanzhong Zhang", "Jibin Yin", "Mulin Jiang", "Cong Su"], "abstract": "Generative agents have demonstrated impressive capabilities in specific tasks, but most of these frameworks focus on independent tasks and lack attention to social interactions. We introduce a generative agent architecture called ITCMA-S, which includes a basic framework for individual agents and a framework called LTRHA that supports social interactions among multi-agents. This architecture enables agents to identify and filter out behaviors that are detrimental to social interactions, guiding them to choose more favorable actions. We designed a sandbox environment to simulate the natural evolution of social relationships among multiple identity-less agents for experimental evaluation. The results showed that ITCMA-S performed well on multiple evaluation indicators, demonstrating its ability to actively explore the environment, recognize new agents, and acquire new information through continuous actions and dialogue. Observations show that as agents establish connections with each other, they spontaneously form cliques with internal hierarchies around a selected leader and organize collective activities.", "sections": [{"title": "1 INTRODUCTION", "content": "Large language models (LLMs) have contributed to significant progress in the field of natural language processing and are widely used in various domains, such as machine translation [45], dialogue generation [9], and content creation [47]. These models are capable of correctly parsing and generating complex sentence structures and have demonstrated unprecedented capabilities in understanding language. However, LLMs often lack true comprehension and rely more on pattern matching and probabilistic predictions [10]. It has also been difficult to create systems to achieve human-like systematic generalization [23]. To overcome these problems, researchers have introduced LLM-based agents. This has allowed the incorporation of external knowledge bases to supplement a model's knowledge gaps in specific domains [44]. They can also be used to decompose a complex task into multiple simpler tasks to achieve hierarchical processing [42].\nOn this basis, Park et al. [32] introduced a novel LLM-based agent, namely, a generative agent. This agent simulates trustworthy human behavior. Generative agents have the ability to make multifaceted inferences about an environment, themselves, and other individuals in the environment. They can design daily activity plans based on their own characteristics and experiences and adjust their plans to changes as they occur. When a situation changes, they can flexibly update plans to ensure adaptation to it.\nThe importance of this progress cannot be ignored. In human computer interaction, especially in virtual assistants, customer service robots, and even more complex systems, such as self-driving cars and smart homes, the ability of agents to generate believable human behavior is crucial. Generative agents can support more adaptive and flexible interaction processes. This ability not only enhances the system's responsiveness to dynamic situations but also brings human-computer interaction closer to natural behavioral patterns in interpersonal communication. In addition, by simulating human behavior, generative agents can demonstrate autonomy and sociality in various complex situations, making the interaction process smoother and more intuitive. This feature plays an important role in improving the user experience and increasing the trustworthiness of a system [16].\nHowever, existing generative agent architectures still face many challenges. While traditional agent structures are good at processing and generating behaviors, they are primarily designed for isolated tasks and, thus, mostly lack a focus on sociality. This often makes it difficult for them to model and apply the nuances of social interactions, leading them to focus only on completing tasks and overlook behaviors that promote social connections. This is clearly not conducive to cooperation among multiple agents and may lead to behaviors that are detrimental to the group [35]. In scenarios involving multiple agents, a lack of structured social behavior may lead to disjointed or even chaotic interactions. To truly harness the potential of these agents in domains requiring interaction, there is an urgent need to explore their ability to participate in social interactions, establish relationships, and exhibit emerging social behaviors.\nIn this paper, we improve upon an existing LLM-based agent architecture (the internal time-consciousness machine based agent [ITCMA] introduced by [51]) and propose ITCMA-S (the \"S\" signifies our contribution of social interaction) architecture to enable agents to adapt to multi-agent interaction scenarios. It contains a"}, {"title": "2 RELATED WORK", "content": "2.1 LLM-based agent\nPark et al. [32] introduced a generative agent based on an LLM and demonstrated that it can generate trustworthy individual behavior and sudden group behavior in simulations. For example, a generative agent will turn off a stove when it sees its breakfast burning and will stop to chat when it encounters other agents with whom it wants to talk. Based on this research, numerous LLM-based agents have emerged. Zhang et al. [46] proposed AppAgent, which constructs an agent to operate any smartphone application. Hong et al. [21] proposed an 18-billion-parameter visual language model (VLM) named CogAgent, which specializes in GUI understanding and navigation. Vezhnevets et al. [40] provided the Concordia library to simulate agent interactions in physical, social, and digital spaces. Among these, a special agent called the game master (GM) is responsible for simulating the environment of agent interactions. Agents take action by describing what they want to do in natural language, and the GM then translates their actions into appropriate implementations.\n2.2 Research on the Structure of Generative\nAgents\nThe original structure of generative agents, as described by Park et al. [32], mainly consisted of three parts: memory flow, reflection, and planning. The concept of a chain of thought (CoT) was particularly important for improvements to the planning module [42]. CoT refers to the ability of an LLM to think and reason gradually through a series of steps or iterations, reflecting human cognitive processes. Traditional language models generate responses without clear intermediate steps, which can lead to suboptimal answers, especially in complex inference scenarios. CoT overcomes these limitations by introducing intermediate steps to enable language models to reason, thereby enhancing the model's ability to solve problems. Mondal et al. [29] suggested using knowledge graphs to enhance multiple patterns to help models solve complex problems, thereby triggering CoT functionality. Their proposed method, knowledge augmented multimodal (KAM)-CoT, decouples the inference process into two consecutive stages. In the first stage, practical reasons are provided, and in the second stage, the generated reasons are used as additional input to provide answers.\nAs an improvement to the memory module, Liu et al. [26] proposed the reasoning and acting through scratchpad and examples (RAISE) architecture, which was specifically designed to enhance the functionality of conversational agents. It combines a dual-component memory system, similar to the short-term and long-term memory functions of the human brain. Toy et al. [38] proposed a metacognitive module by improving the reflection module in generative agents, allowing agents to broadly consider their situations to create alternative strategies and improve their performance."}, {"title": "3 GENERATIVE AGENT FRAMEWORK", "content": "3.1 The Internal Time-Consciousness Machine\nBased Agent\nZhang, Yin, et al. [51] introduced the internal time-consciousness machine (ITCM), which is a computational consciousness structure. The ITCM supports agents in taking action and making inferences in an open world. It can help generative agents become more flexible and intelligent when handling complex tasks; this improves their interpretability and makes their actions easier to understand and predict. On this basis, they proposed ITCM-based agent (ITCMA). As a generative model, ITCMA considers both the reasoning ability"}, {"title": "3.2 Memory and Imagination", "content": "3.2.1 Memories Blended into the Present. In ITCMA, after a memory is awakened to the present moment, it is juxtaposed with the retention and primal impression in the consciousness channel. However, the theory of creature consciousness suggests that phenomenal consciousness requires the blending of a \"phenomenal field\" mechanism that may originate in the thalamus and neural inputs from different cortical areas responsible for processing memory-related information [3]. It is obvious that, for humans, the awakening of memory is not simply juxtaposition but blending with present consciousness. Conceptual blending is a cognitive activity that combines information from different contexts [15]. Its main process is composition, which is the process of projecting input spaces (two different fields) into the blended space. Blending can combine elements from the input spaces to provide relationships that do not exist within a single input space.\nTherefore, based on conceptual blending theory, we hypothesize that when a memory of ITCMA-S enters the current consciousness channel, its phenomenal fields of observation and recollection are blended to obtain the imagination of this moment, and thus the material of the consciousness channel is obtained. As shown in Figure 2, this process satisfies the following steps: In the first step, Figure 2(a), there is local matching between the phenomenal fields; that is, the equivalent component connections are generated by the matching. Once the match between the two fields is created, it is said that there is cross-space mapping between them. In the second step, Figure 2(b), which is the blending process, the matching structure of the two phenomenal fields is utilized to establish the generic space (which can be roughly understood as the common \u201cbelonging\u201d class containing the instances of the elements of the phenomenal fields). In the third step, Figure 2(c), via the generic space, the two phenomenal fields are projected into a new space: the blended space. After this, components and structures in the phenomenal field selectively enter the blended space, forming structures that are, to some extent, distinct from the original phenomenal field.\nWe stipulate that for completely identical objects, they are placed in the blended space after blending takes place (i.e., taking the average); objects that match in the generic space (with similarity exceeding a threshold) are each placed in the blended space; and objects that do not match have a certain probability of being placed in the blended space. Therefore, for the two phenomenal fields $f_x$ and $f_y$, the blending process $Blend(f_*, f')$ follows Algorithm 1:"}, {"title": "3.2.2 Memory Storage and Compression", "content": "One of the reasons for the slow processing speed of ITCMA is the memory activation algorithm it uses. Its improved Levenshtein distance method provides better memory query results. However, it consumes more time than the simple cosine similarity algorithm. For this reason, it was necessary to improve it.\nOne way to improve the speed of memory activation is to reduce the number of memories that the agent needs to query. Due to the learning of new memories, the retention and association of existing memories will be affected [1]. One way to address this is to modify, split, and recombine memories over time, that is, to compress memories [11]. This compression can affect the accuracy of memory, but its impact on recall is not as severe. In fact, people do not use precise memories when making decisions [8]. The compression process of memory constantly generates new meanings [15], and making decisions based on such memories is sometimes seen as intelligent inference, which may be a source of the generalization of human intelligence [34]."}, {"title": "3.3 Emotion and Motivation", "content": "Emotions can help with decision-making, not just interfere with it, as most people believe [12]. For example, in decision-making, emotions can highlight the importance of a certain premise, thereby making a decision tend toward that premise. This idea coincides with the practice in ITCMA of allowing LLMs to choose which action to perform by deducing the protention $Prot$ of each action in the action space. However, although ITCMA provides LLMs with an internal driving force $d'$ that includes emotions for decision-making, it only adds the weighted sum of the three-dimensional PAD emotions at this moment to the internal driving force $d_{t-1}$ at the previous moment. Indeed, agents tend to push pleasure and dominance to have the highest values possible [13, 37], but they also generally tend to keep emotional arousal at a stable value [20]. In ITCMA-S, the arousal $A_t$-based mechanism of passive attention is quantified as the degree of change between the elements in retention and the elements in the current primary impression. The dominance $D_t$ is quantified as the difference between the protention $Prot^{-1}$ at the previous moment and the primal impression $PIt$ at this moment. The pleasure $P_t$ is quantified as the degree of satisfaction with the agent's desire and the degree of avoidance of pain. The expression $w_p + w_A + w_D = 1$ contains the dynamic weights of the emotions. Therefore, for the emotional dimensions $P_t, A_t, D_t \\in (-1, 1)$ at time $t$, the emotional values should be considered as follows:\n$P_t = tanh(desire) - tanh(pain)$ (10)\n$At = tanh(\\frac{2n}{\\pi}(\\sum_{n=1}^{t-1}(diff (PI^i, re^i))))$\n(11)\n$D = tanh(diff (PIt, Prot^{-1}))$ (12)"}, {"title": "3.4 Reduction of Action Space", "content": "The PET framework created an elimination module for Alf World using pre-trained Q&A models to filter out containers and objects unrelated to the current task based on common sense about the task [43]. Through this step, the time required for an untrained agent to enter the task context can be effectively reduced. Similarly, ITCMA-S also uses an LLM Elim to reduce the number of action spaces in a zero-shot manner. Specifically, for the target G of the agent, we create a prompt in $Desc = $ \"Your task is to: G. The actions you can take are: AS. The ai will be relevant?\" format for the executable action $a_i \\in AS$ in the action space AS. Elim will output the confidence score for the action a\u2081:\n$\\mu_{a_1} = Elim(Desc, G, AS, a_1)$ (16)\nAmong them, $\\mu_{a_1} \\in [1,5]$. When $\\mu_{a_1}$ is less than the threshold, $a_i$ will be removed from the action space. The elimination process is shown in Figure 3."}, {"title": "4 SOCIAL INTERACTION FRAMEWORK", "content": "Zhang, Duan, et al. [49] proposed a social regulation model for the dynamic adaptation of users in virtual interactive environments, namely the tribal theater model (TTM), to address the core issue of \"enhancing user interaction freedom.\" This model emphasizes the subjectivity of interactive users. In this section, based on the TTM and field theory [5], we present a multi-agent social interaction architecture, the LTRHA, for ITCMA-S, which consists of four modules: locale & topic, resources, habitus, and action. We aimed to design an interaction architecture for generative agents to promote the emergence of spontaneous social interactions within their societies. Specifically, there is no preset identity in the LTRHA environment. Every agent has certain resources. The environment will provide basic action options, such as using objects and communicating with other agents. The probability of successfully executing"}, {"title": "4.1 Locale and Topic", "content": "In the TTM, the field is decomposed into two parts: the tribe and the atmosphere [49]. To distinguish the field in ITCMA-S from the field in ITCMA, we refer to the parts as the locale and topic. The locale and topic modules can be understood together as an interactive space. In human society, such interactive spaces typically include locales as physical spaces and topics as mental factors [27, 31]. For example, in a speech setting, the stage and audience seats are part of the locale, and the passion aroused by the speaker in the audience is a topic.\nWe define a sub-environment env of the overall environment, which includes a space and n agents occupying that space. We make the spatial area and its contained objects $loc_{env}$ as the locale, and the emotion synthesis function $tpc_{env}$ of these agents is a topic. Among them, we define agent $gai \\in GA$ with emotional dimensions $P_i, A_i, D_i \\in (-1, 1)$. The emotion synthesis function is described by the following equation:\n$tpc_{env}=\\frac{\\Sigma P_iA_iDi}{n}^2$ (17)"}, {"title": "4.2 Resources", "content": "The execution of actions by agents requires a certain amount of resources, just as implementing decisions in human society requires a certain cost. Resources are allocated to the agents in the sub-environments based on the actions of the agents by a model called the \"matrix.\"\n4.2.1 Competition for Limited Resources by Agents. The key to interactive regulation is the resources possessed by an agent [5, 19]. Virtual resources, such as the cultural level and social status, are considered interactive resources. We believe that the agents' environment is a space for competing resources. Changing the distribution and relative weights of resources is equivalent to changing the structure of the environment. A resource is both a weapon and an object of contention, enabling its owner to exert influence on the environment. Therefore, the number of resources possessed by an agent determines the actions it can perform in one time step. Specifically, in the environment, a total of n agents $gai \\in GA$ each hold a number of resources $Si$. $Si$ is initially 1. Agents take turns executing actions. A specific gai takes action with a probability $rate_i$ as follows:\n$rate_i = 0.5 + \\frac{Sigmoid(Si)}{2}$ (18)"}, {"title": "4.3 Habitus and Action", "content": "\"Habitus\" is a technical term that describes a series of ways of perception, cognition, and action. It shares similarities with the meaning of the common English word \"habit\" (which comes from the Latin word \"habitus,\" which means condition or appearance in that language). In human society, it can be understood as a decision tree for action. When we are in an environment, a corresponding decision tree is activated, and we decide on our final actions based on our behavioral habits. This is similar to the logic of mutual influence between an environment and an agent in reinforcement learning. In addition to an agent shaping the environment, the environment shapes habitus, and the habitus is thus a product of an inherent and necessary attribute of the environment reflected in the agent [6].\nThus, habitus is clearly an attribute of an agent itself, but it is also included in our framework because of its close relationship to environmental content. The actions ultimately taken in the LTRHA framework can be summarized as follows [7]: action $a_i$ of agent $gai$ is driven by the combination of habitus $H_i$, resource $S_i$ and environment $env\\leftarrow [loc_{env}, tpc_{env}]$, that is, $a_i \\leftarrow f(gai (H_i, S_i), env)$."}, {"title": "5 EVALUATION", "content": "5.1 Environment Settings\nThe environments that support the evaluation of individual agent capabilities include the agent behavior evaluation framework Magenta [2], the network task environment WebArena [52], the life task environment ALFWorld [36], and the Chinese character role-playing conversation benchmark CharacterEval [39]. These environments can effectively evaluate the ability of individual agents to complete tasks, but they are not very helpful for the social evaluation of multi-agent systems.\nTo evaluate the sociality of multi-agent systems, it was necessary to consider constructing a virtual artificial society. Xue et al. [45] suggested that a comprehensive method of computational experiment design can be used to infer social systems through multi-agent systems. Artificial societies are used for descriptive modeling in computational experiments. After constructing an artificial society, researchers can directly create computational experiments to simulate and interpret the results of trials conducted using different conditions, locations, and participants. The most classic example of such an environment is the Smallville environment provided by Park et al. [32]. This is a 2D open-world role-playing game (RPG). Agents interact with the world and with each other through their behavior and through natural language. At each time step in Smallville, the agent outputs a natural language statement describing its current operation, such as, \u201cIsabella is writing a diary.\" This statement is then translated into specific actions that affect the sandbox world. With the ALFWorld environment used by ITCMA as a reference, we designed a 2D sandbox RPG similar to Smallville, called Irollan Valley, as shown in Figure 5. It includes six agents with the following arbitrary two-letter designations: AY, SG, MD, WL, LL, and WM. It also uses environment text descriptions and operational primitives consistent with ALFWorld. Because we wanted to observe the spontaneous emergence of individual character traits and role divisions by agents without presets or interventions, we did not preconceptualize any personality or identity for the agents in IrollanValley, as Smallville did.\nIrollan Valley accepts control requests via a server. This server enables the generative agents to use the sandbox information and allows them to move and influence the sandbox environments. At each time step, the server provides a natural language description of the agents' current environment and executable action space, moves the generative agents to new locations by accepting actions from them, and updates the state of any sandbox objects with which agents interact. The server returns a JSON (JavaScript object notation) object containing a natural language description of the new environment, allowing the agents to update their parameters.\nIrollanValley has eight main areas: the six agents' corresponding houses, a public canteen, and a public reading room. Each area has its own furniture and other items. Agents can hold any number of items and use the furniture to place and store them, or to change the state of these items. For example, the sinkbasin can make items clean and damp, while the stoveburner can remove the damp state of the items and make them hot. Agents can exchange items freely to achieve their respective goals."}, {"title": "5.2 Human Evaluation", "content": "To evaluate the effectiveness of ITCMA-S, we conducted an ablation study. There were five ablation architectures: the original ITCMA architecture without improvements, the LTRHA-only architecture, the compressed memory-only architecture, the driver-only architecture, and the full ITCMA-S architecture.\nWe recruited 48 human evaluators to assess the output from the agents in the study. We hoped that the agents could generate sociality in multiple ways. This would mean that they would take the initiative to explore the environment and meet new agents. They would acquire new information through their own continuous actions, past memories, and conversations with other agents, and"}, {"title": "5.3 Formation of Cliques and Groups in Social Interaction", "content": "To further investigate the utility and mechanics of ITCMA-S, we conducted a more detailed analysis of its logs. Figure 6 shows the state changes of the six agents in ITCMA-S over 75 time steps. Figure 6(a) shows the change in driver values for the agents. As described previously, the driver value reflects the willingness to encourage the agent to take action. More specifically, Figure 6(b) shows the changes in the three dimensions of emotions that make up the driver. Each agent maintained its pleasure value at a high level and kept its arousal value as stable as possible over the 75 time steps (although the mean was relatively high overall, as agents tended to move among different scenes rather than stay in a specific scene), while the dominance value, although not showing a high level, rarely dropped below zero. As can be seen, the action choices of the agents in ITCMA-S exhibited a virtuous cycle. Agents actively explored the environment and engaged in social activities that changed the environment. The environment, in turn, provided positive feedback to the agent, improving their emotions (increasing their pleasure and dominance) and leading to a higher willingness (that is, driver) to take action.\nIn addition, we investigated the changes in scene information reflected in the LHRHA framework, as shown in Figure 7. Figure 7(a) shows the changes in the resource structure of the scene. For most agents, their total amount of resources was rising. However, due to the limited total amount of resources, the resources of individual agents (e.g., WL and MD) were continuously flowing to other agents. We found that agents with resource loss were often alone and did not interact with other agents, even when they shared a room with them. Most of their actions involved resting (such as using beds or chairs), and most of their thoughts were about wanting to rest or read. Other agents liked to engage in social activities, discuss what they wanted to do together, and follow this up with planned group actions. These agents spontaneously selected a leader (LL)"}, {"title": "6 CONCLUSION", "content": "In this paper, we described how generative agents spontaneously formed social relationships and explored how they modeled complex human social behavior through mutual interaction, information exchange, and relationship building. We introduced ITCMA-S, an improved generative agent architecture designed to enhance agent socialization in multi-agent interaction contexts. ITCMA-S combines the basic framework of individual agents with the LTRHA framework, which supports multiple agents in social interactions. This enables agents to identify and filter actions that are not conducive to social interactions in dynamic environments, thus promoting more socially beneficial action choices. An evaluation conducted in an open sandbox world environment showed that agents were able to actively explore the environment, meet other agents, acquire new information through continuous actions and conversations, and spontaneously form cliques and leadership structures in complex social environments. Observations of agent behavior showed that the agents were able to demonstrate positive emotional changes in social interactions, which enhanced their willingness to act and their social competence. This finding provides a new perspective for understanding the sociality of generative agents and lays the groundwork for future agent design and applications. Our future research will further explore how to optimize agents' social behavior to improve their adaptability in multicultural environments and investigate the effects on agents' behavior of introducing social structures with humans as interaction partners."}]}