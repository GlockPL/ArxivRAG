{"title": "STOCHSYNC: STOCHASTIC DIFFUSION SYNCHRONIZATION FOR IMAGE GENERATION IN ARBITRARY SPACES", "authors": ["Kyeongmin Yeo", "Jaihoon Kim", "Minhyuk Sung"], "abstract": "We propose a zero-shot method for generating images in arbitrary spaces (e.g., a sphere for 360\u00b0 panoramas and a mesh surface for texture) using a pretrained image diffusion model. The zero-shot generation of various visual content using a pretrained image diffusion model has been explored mainly in two directions. First, Diffusion Synchronization-performing reverse diffusion processes jointly across different projected spaces while synchronizing them in the target space-generates high-quality outputs when enough conditioning is provided, but it struggles in its absence. Second, Score Distillation Sampling-gradually updating the target space data through gradient descent-results in better coherence but often lacks detail. In this paper, we reveal for the first time the interconnection between these two methods while highlighting their differences. To this end, we propose StochSync, a novel approach that combines the strengths of both, enabling effective performance with weak conditioning. Our experiments demonstrate that StochSync provides the best performance in 360\u00b0 panorama generation (where image conditioning is not given), outperforming previous finetuning-based methods, and also delivers comparable results in 3D mesh texturing (where depth conditioning is provided) with previous methods.", "sections": [{"title": "1 INTRODUCTION", "content": "Diffusion models pretrained on billions of images have demon-strated remarkable capabilities in various zero-shot applications. A notable example is the zero-shot generation of diverse visual data, including arbitrary-sized images, 3D mesh textures , ambiguous images , and zoomed-in"}, {"title": "2 RELATED WORK", "content": "In this section, we first review two approaches that generate samples in canonical space by leveraging pretrained diffusion models trained in instance space: Diffusion Synchronization and Score Distillation Sampling. We then discuss these approaches, along with other related works, in the context of two applications: panorama generation and 3D mesh texturing.\nDiffusion Synchronization (DS). Liu et al. (2022) was among the first works to utilize DS, focusing on compositional image generation. Subsequent works, such as (Bar-Tal et al., 2023; Lee et al., 2023), extended DS to support image generation at arbitrary resolutions. Beyond images, DS has been"}, {"title": "3 PROBLEM DEFINITION AND OVERVIEW", "content": "We propose a method for generating data points in one space (referred to as the canonical space Z) using a pretrained diffusion model that has been trained on another space (referred to as the"}, {"title": "4 DIFFUSION REVERSE PROCESS", "content": "The forward process of a diffusion model sequentially corrupts sample data using a predefined variance schedule \u03b11,...,\u03b1T, where one can sample xt at arbitrary timestep t from a clean sample x0:\n$x_t = \\sqrt{\u03b1_t}x_0 + \\sqrt{1-\u03b1_t}\u03f5$, where $\u03f5 \\sim N(0,I)$.  (1)\nSong et al. (2021a) propose DDIM, a diffusion reverse process generalizing DDPM Ho et al. (2020), by defining the posterior distribution $q_{\u03c3_t}(x_{t\u22121}|x_t, x_0)$ with a parameter \u03c3t determining the level of stochasticity as follows:\n$q_{\u03c3_t} (x_{t-1}|x_t, x_0) = N (\u03bc_{\u03c3_t} (x_0, x_t), \u03c3_t^2I)$,  (2)\nwhere $\u03bc_{\u03c3_t} (x_0, x_t) = \\sqrt{\u03b1_{t-1}}x_0 + \\sqrt{1 - \u03b1_{t-1}} (\\frac{x_t - \\sqrt{1 - \u03b1_t}\u03f5_\u03b8(x_t, y)}{\\sqrt{\u03b1_t}})$, (3)\nIn the reverse process, the transitional likelihood distribution pe(xt\u22121|xt) becomes the same with the posterior distribution in Eq. 2 while the clean sample x0 is approximated using the noise predictor \u03f5\u03b8(xt, y), where y is the input condition (e.g., a text prompt); note that the time input is omitted for simplicity. When \u03f5t = \u03f5\u03b8(xt, y), the prediction of clean sample x0 at timestep t, denoted as x0|t, is derived as follows based on Tweedie's formula (Robbins (1956)):\n$x_{0|t} = \u03a6(x_t, \u03f5_t) = \\frac{x_t - \\sqrt{1 - \u03b1_t}\u03f5_t}{\\sqrt{\u03b1_t}}$   (4)\nA clean data sample x0 is then generated by first sampling standard Gaussian noise xT ~ N(0, I) and gradually denoising it over time by iteratively sampling a noisy data point xt\u22121 from pe(xt\u22121|xt). The mapping from a noisy data point xt to x0 becomes deterministic when \u03c3t = 0 for all t and is equivalent to solving an ODE (Song et al., 2021b; Chen et al., 2018) with a specific discretization.\nReverse Process from the Perspective of x0jt. Here, to connect the reverse process of DDIM to the algorithms to be introduced in the next section, we reinterpret the reverse denoising process as an iterative refinement process of the prediction of clean sample x0jt. See Alg. 1, where x0|t and et are computed at each timestep. Note that the mean of the likelihood distribution pe(xt\u22121|xt) in Eq. 3 can be rewritten in terms of x0 and et:\n$\u03bc_{\u03c3_t} (x_0, \u03f5_t) = \\sqrt{\u03b1_{t-1}}x_0 + \\sqrt{1 - \u03b1_{t-1}} \u03f5_t^2$  (5)\nApart from setting ot = 0, one can consider a special case when ot = $ \\sqrt{1 \u2212 \u03b1_{t\u22121}}$, which maximizes the level of stochasticity during the sampling process. This cancels out the noise prediction term et in Eq. 5. We denote this case by overriding \u03bc\u03c3t(\u00b7,\u00b7) with \u03bc\u2217(\u00b7), which now takes a single parameter x0:\n$\u03bc^{*}(X_0) = \\sqrt{\u03b1_{t-1}}X_0$. (6)"}, {"title": "5 DIFFUSION SYNCHRONIZATION AND SCORE DISTILLATION SAMPLING", "content": "As methods leveraging pretrained diffusion models to generate data in other spaces, there have been mainly two approaches: Diffusion Synchronization (DS)  and Score Distillation Sampling (SDS) . In this section, we briefly review these methods, analyze the connections between them as well as their differences, and discuss the limitations of each method.\n5.1 DIFFUSION SYNCHRONIZATION\nThe idea of Diffusion Synchronization (DS) is to perform the reverse process jointly across multiple instance spaces while synchronizing the processes through mapping to the canonical space. Among the various options for synchronization, Kim et al. (2024a) have demonstrated that averaging the predictions of the clean samples x0lt in the canonical space and then projecting it back to each instance space provides the best performance across a broad range of applications. Alg. 2 shows the pseudocode, which, at each step, performs one-step denoising of DDIM for each view (lines 10-11), updates the data point in the canonical space z while averaging xot by solving a 12-minimization (line 13), and then projects z back to each space (line 9). The differences from the reverse process of DDIM (Alg. 1) are highlighted in blue.\nFor the stochasticity of the denoising process, typically deterministic DDIM reverse process (\u03c3\u03c4 = 0) (Bar-Tal et al., 2023; Zhang et al., 2024b) or DDPM reverse process (\u03c3\u03c4 = $\\sqrt{(1 \u2212 \u03b1_{t\u22121})/(1 \u2212 \u03b1_t)}\\sqrt{1 \u2212 \u03b1_t/\u03b1_{t\u22121}}$) (Liu et al., 2023) have been used."}, {"title": "5.2 SCORE DISTILLATION SAMPLING", "content": "Score Distillation Sampling (SDS) and its variants are alternatives for generating samples in different spaces. Unlike DS, SDS does not use the reverse diffusion process but instead employs gradient-descent-based updates. The motivation behind SDS is to leverage the loss function from noise predictor training to discriminate real data points while projecting the canonical data point fc(z), corrupting it through the forward process, and then predicting the added noise from it.\nTo clarify the similarities and differences between SDS and DS, we provide a different perspective on understanding SDS, as shown in Alg. 3, aligning each computation with those in DS (Alg. 2). There are several key differences, highlighted as green in Alg. 3. First, the timestep t is not decreased from T to 1 but is randomly sampled until convergence (line 3). Second, while synchronization approaches typically make the reverse process deterministic or identical to DDPM (Liu et al., 2023), SDS uses maximum stochasticity (\u03c3\u03c4 = $\\sqrt{1 \u2212 \u03b1_{t\u22121}}$), thus eliminating the need to maintain the noise et. Third, the prediction of the clean sample is updated to the canonical space not by solving the 12 minimization but by performing a single gradient descent step (line 7).SDS was originally introduced to perform gradient descent for the loss $||\u03f5 \u2212 \u03f5_\u03b8(x_{t\u22121},y)||^2$ (while omitting the gradient of the U-Net), where \u0454 is the standard normal sample used in xt\u22121 sampling, i.e.,xt\u22121 = \u03bc\u2217(xo\t) + \u03c3\u03c4\u03b5 (line 5), while it is equivalent to the loss used in DS, $|| f_c(z) \u2212 X_{o|t\u22121}||^2$,up to a scale as explained in Appendix (Sec. A).\nAs observed in previous works , when input conditions are provided, the quality of SDS-generated outputs is inferior to that of DS-based methods. However, SDS performs better than DS when no conditions are given (except for the text prompt), effectively integrating images from the instance spaces without producing seams, although it struggles to generate fine details (Fig. 2(b)). In the following section, we introduce our novel method that combines the strengths of both approaches to achieve superior quality in unconditional canonical data point generation while maintaining performance in conditional generation."}, {"title": "6 STOCHSYNC: STOCHASTIC DIFFUSION SYNCHRONIZATION", "content": "Based on our analysis comparing Diffusion Synchronization (DS) and Score Distillation Sampling (SDS) in Sec. 5, we propose our novel method, Stochastic Diffusion Synchronization, or StochSync for short, which combines the best features of each method to achieve superior performance in unconditional canonical sample generation. From the perspective of DS, we introduce three key changes in the algorithm.\nMaximum Stochasticity in Synchronization. One of the key differences between SDS and previous DS methods is that SDS can be interpreted as utilizing maximum stochasticity in the DDIM denoising step (setting ot = $ \\sqrt{T} A_{t-1}$ in Eq. 5 and thus removing the et term), while earlier DS methods have not explored this aspect. We investigated whether maximum stochasticity helps DS achieve better coherence of samples across instance spaces, similar to what is observed in SDS. As the results shown in Fig. 2(c), it indeed helps remove seams, resulting in much smoother transitions across views. However, we also observe a trade-off between coherence and realism: increased stochasticity leads to greater deviation from the data distribution, producing less realistic images. We present a more detailed analysis of maximum stochasticity on global consistency and realism in Appendix (Sec. D), along with experimental results.\nMulti-Step xolt Computation. To resolve the trade-off between coherence and realism, we propose replacing the computation of x0|t from Tweedie's formula (Eq. 4), the one-step prediction of the clean sample x0 from xt, with a multi-step deterministic denoising process of DDIM, denoted as G(xt). We observe that a more accurate prediction of the clean samples xolt at each step along with maximum stochasticity level allows us to achieve both high coherence and realism as shown in Fig. 2(d). Notably, when replacing the computation of x0|t with multi-step denoising, StochSync"}, {"title": "7 EXPERIMENT RESULTS", "content": "In this section, we present the experimental results of StochSync for two applications: 360\u00b0 panorama generation and 3D mesh texturing. 360\u00b0 panorama generation is an example of unconditional canonical data point generation (except for text conditioning), while 3D mesh texturing is an example of using depth maps as conditioning. We provide comparisons with baseline methods, user study results, as well as ablation study results. In Appendix, we include implementation details (Sec. B), details of the user study (Sec. C), and additional qualitative and quantitative results (Sec. G). Extensions of StochSync to additional applications, such as 8K panorama generation and 3D Gaussians texturing, are provided in Appendix (Sec. F).\n7.1 360\u00b0 PANORAMA GENERATION\nIn the 360\u00b0 panorama generation, the projection operation f is equirectangular projection, which maps a 360\u00b0 panoramic image to perspective view images. We specifically use \u2018Stable Diffusion 2.1 Base' as the pretrained diffusion model for all methods, except for the baselines that require"}, {"title": "ETHICS STATEMENT", "content": "StochSync leverages a diffusion model trained on the LAION-5B dataset (Schuhmann et al., 2022), which has been preprocessed to remove unethical content. However, despite these efforts, the pretrained diffusion model may still generate undesirable content when presented with misleading or harmful prompts, a limitation that our method also inherits. It is important to acknowledge this risk, as models like StochSync could inadvertently produce biased or inappropriate outputs and should be used with caution. Additionally, StochSync may impact the creative industry by automating parts of the generative process. However, it also offers opportunities to enhance productivity and accessibility to generative tools."}, {"title": "REPRODUCIBILITY STATEMENT", "content": "StochSync uses the 'Stable Diffusion 2.1 Base' (Rombach et al., 2022) and the depth-conditioned ControlNet (Zhang et al., 2023), both of which are publicly available. We also provide the pseudocode of StochSync in Alg. 4 and the implementation details including hyperparameters in Sec. B. We will also release our code publicly."}, {"title": "APPENDIX", "content": "A REFORMULATION OF SDS Loss\nHere, we show that the SDS loss introduced in Sec. 5.2 of the main paper is equivalent to the original loss presented in DreamFusion (Poole et al., 2023) up to a scale. In Sec. 5.2, the SDS loss is presented from the perspective of clean samples:\n$||f_c(z) - X_{ot-1}||^2 \\frac{2\\sqrt{\u03b1_{t-1}}}{\u03b1_{t-1}} = 2|| \\sqrt{\u03b1_{t-1}} Xt\u22121 - \\sqrt{1 - \u03b1_{t\u22121}}\u03f5_\u03b8(Xt\u22121,Y) || ^2$  (7)\n$ \\frac{1 - \u03b1_{t-1}}{\u03b1_{t-1}} || \u03f5 \u2013 \u03f5_\u03b8(X_{t\u22121}, y) ||\u00b2, $  (8)\nwhere the equality in the first line holds from Eq. 4 and e is sampled from a standard Gaussian, N(0,1). Previous works have also made a similar observation.\nB IMPLEMENTATION DETAILS\nPanorama Generation. We set the resolution of the perspective view images to 512 \u00d7 512, and the panorama to 2,048 \u00d7 4,096. A linearly decreasing timestep schedule is employed, starting from T = 900 and decreasing to Tstop = 270, with a total of 25 denoising steps. For multi-step xo|t computation, the total number of steps is initially set to 50, decreasing linearly as the denoising process progresses. For view sampling, we alternate between two sets containing five views each, with azimuth angles of [0\u00b0, 72\u00b0, 144\u00b0, 216\u00b0, 288\u00b0] and [36\u00b0, 108\u00b0, 180\u00b0, 252\u00b0, 324\u00b0]. The elevation angle is set to 0\u00b0, and the field of view (FoV) is set to 72\u00b0.\nFor methods utilizing multi-step xot predictions, computing Xot-1 = G(xt-1) as in line 11 of Alg. 4, only for the last two steps in the loop of line 7, we leverage the previous x0|t to better preserve the boundary regions. We perform the denoising process while blending the noisy data point as foreground and the previous x0|t as background, as done in RePaint. For the background mask, we start from the entire region and gradually decrease the regions over time to be close to the boundaries.\n3D Mesh Texturing. For 3D mesh texturing, we follow the approach in SyncTweedies and use the same image and texture resolutions. We use the same number of steps as in the 360\u00b0 panorama generation task with a linearly decreasing time schedule from T = 1,000 to Tstop = 270. We use 4 views to minimize overlaps between the views. For multi-step x0|t predictions, we use the same refinement mentioned above.\nC USER STUDY DETAILS\nIn this section, we provide details of the user study described in Sec. 7.1.1 of the main paper. We evaluated user preferences across two prompt sets: PanFusion (Zhang et al., 2024a) prompts and horizon-specific prompts. The study was conducted via Amazon Mechanical Turk (AMT).\nScreenshots of the user study are shown in Fig. 6. Participants were presented with two panoramic images (in random order) generated using the same text prompt: one by L-MAGIC and the other by StochSync. They were asked to answer the following question: \"Which image has better quality, fewer seams, fewer distortions, and better alignment with the given text prompt across the panoramic view?\" In each user study, 25 panoramic images were shown in a shuffled order, including five vigilance tests. For the vigilance tests, participants were shown a wide image composed of concatenated 2D square images alongside a ground truth 360\u00b0 panorama, with the same resolution and question format. For the final results, we collected responses from 50 out of 96 participants from the PanFusion set and 59 out of 100 participants from the horizon set, passing at least three vigilance tests. We required participants to be AMT Masters and have an approval rate of over 95%."}, {"title": "D ANALYSIS OF MAXIMUM STOCHASTICITY", "content": "D.1 ANALYSIS\nHere, we provide an analysis of maximum stochasticity \u03c3T = $ \\sqrt{1 \u2212 \u03b1_{t\u22121}}$ in achieving view consistency at the cost of quality degradation. To provide clarity in the analysis, we consider a simplified setup where: (1) the instance space consists of a single image (N = 1, line 8, Alg. 4), (2) the projection operation is replaced with an identity function (line 9, Alg. 4), and (3) the objective function is modified to a composition of masked 12 losses (lines 6 and 13 of Alg. 4).\nImpact of Stochasticity on Consistency. An example of the simplified setup is image inpainting task, where the objective is to generate a realistic image xo that aligns with the partial observation y = MX0, where M \u2208 {0, 1} represents a binary mask. To guide the sampling process, the generation is conditioned by replacing M\u2299 xo|t with y.\nUnder these simplifications, the update rule for z becomes:\nz = arg $min_z$ [||(1 \u2013 M) \u2299 (z - Xo|t\u22121)||^2 + ||M\u2299 (z\u2212y)||^2] . (9)\nTo analyze the effectiveness of the level of stochasticity on synchronization, we examine the convergence rate of measurement error, L(xo|t) = ||M\u2299 xo|t - y||2, for two cases: \u03c3\u03c4 0 and \u03c3\u03c4 = $ \\sqrt{1- A_{t\u22121}}$ (Max. \u03c3\u03c4), respectively. As discussed in Sec. 4, when ot = 0, the sampling process becomes fully deterministic. To better illustrate our intuitions, we make two reasonable and straightforward assumptions:\n\u2022 The initial sample x\u012b ~ N(0,I) satisfies L(x0|7) \u226b 0 and L(G(x\u012b)) > 0.\n\u2022 The pretrained noise prediction network e\u0473(\u00b7,\u00b7) is K-Lipschitz, satisfying $|\u03f5_\u03b8(x_t,t) \u2212 \u03f5_\u03b8(x_{t-\u2206t}, t \u2212 \u2206t)| < K|xt \u2212 xt\u2212\u2206t|$ for some constant K.\nUnder these assumptions, the reformulation of a one-step denoising process from the perspective of xo|t yields the following.\nXot-At = Xolt +  $\\frac{1-\u03b1_{t-At}}{\u03b1_{t-At}}  (Et - Et-At)$. (10)\n... Xot-At - Xo|t| =  $ \\frac{1-\u03b1_{t-At}}{\u03b1_{t-At}} |Et - Et-At| < \\frac{1-\u03b1_{t-At}}{\u03b1_{t-At}}  K|xt - Xt->t| \u2248 0$, (11)"}]}