{"title": "Demystifying the Potential of ChatGPT-4 Vision for Construction\nProgress Monitoring", "authors": ["A. B. Ersoz"], "abstract": "The integration of Large Vision-Language Models (LVLMs) such as OpenAI's GPT-4 Vision\ninto various sectors has marked a significant evolution in the field of artificial intelligence,\nparticularly in the analysis and interpretation of visual data. This paper explores the practical\napplication of GPT-4 Vision in the construction industry, focusing on its capabilities in\nmonitoring and tracking the progress of construction projects. Utilizing high-resolution aerial\nimagery of construction sites, the study examines how GPT-4 Vision performs detailed scene\nanalysis and tracks developmental changes over time. The findings demonstrate that while\nGPT-4 Vision is proficient in identifying construction stages, materials, and machinery, it faces\nchallenges with precise object localization and segmentation. Despite these limitations, the\npotential for future advancements in this technology is considerable. This research not only\nhighlights the current state and opportunities of using LVLMs in construction but also discusses\nfuture directions for enhancing the model's utility through domain-specific training and\nintegration with other computer vision techniques and digital twins.", "sections": [{"title": "Introduction", "content": "The rapid advancement of Large Language Models (LLMs) has significantly shaped the field\nof natural language processing, placing these models at the center of text analysis and\ngeneration efforts. LLMs, known for their training on large datasets, have developed the\nremarkable capability to understand and produce text in a way that closely mimics human\nlanguage. The widespread availability of platforms like ChatGPT (OpenAI, 2022) and Gemini\n(Google, 2023) has made these technologies accessible to more people, expanding their use\nacross different fields. Alongside the advancements in language processing, the emergence of\nLarge Vision-Language Models (LVLMs), also sometimes referred to as Large Vision Models,\nsignifies a similar revolution within the realm of image processing and interpretation. These\nsophisticated artificial intelligence systems are engineered to analyze and interpret visual\ninformation like their linguistic counterparts interpret text. Drawing on extensive visual\ndatasets, LVLMs are adept at identifying and understanding visual elements and structures,\nthereby enabling a wide array of applications, including image-based dialogue, image\nrecognition, visual question answering, document analysis, and image captioning."}, {"title": "Related Work", "content": "The integration of artificial intelligence in various sectors has reached new heights with the\nadvent of GPT-4V, OpenAI's most advanced generative model. This section delves into the\ndiverse applications of GPT-4V across different domains, demonstrating its capability to\ninterpret and respond to visual data alongside text. From transforming medical diagnostics to\nadvancing remote sensing technologies, the applications of this AI tool exemplify a significant\nleap in bridging the gap between visual perception and language understanding.\nIn a 2024 study by Sievert et al., the researchers explored how OpenAI's ChatGPT 4 with\nVision capabilities could be used to analyze medical images, specifically confocal laser\nendomicroscopy (CLE) images, for diagnosing a type of cancer that occurs in the throat. A\ncollection of 12,809 CLE images from five patients was gathered and anonymized. The images\nwere used to train and validate OpenAI's GPT-4.0 API. A training dataset of 16 images and a\nvalidation dataset of 139 images were classified. Despite the limited training, GPT-4.0 achieved\nan accuracy of 71.2% in identifying cancer, which was still below the 88.5% accuracy rate of\nhuman medical experts. This discrepancy highlights the challenges and limitations of AI in\nmedical diagnostics, mainly when dealing with small datasets (Sievert et al., 2024). In a\ncorrespondence to the editor of the International Journal of Surgery (London, England), the\npotential of GPT-4 in altering breast cancer treatment is highlighted. The authors discuss how\nthis advanced Al technology can aid in interpreting complex medical concepts, providing\nemotional support, and assisting in patient self-management, making it a critical component of\nbreast cancer care. While GPT-4 enhances decision-making and medical education for\nhealthcare providers, it is emphasized that it cannot replace the crucial role of human doctors\nor the empathy inherent in patient care. Breast cancer treatment still demands expert judgment\nand a personalized approach from a physician, and ethical considerations are vital to ensure\nfairness and transparency in Al's application. Despite potential challenges, there is significant\noptimism about the role of GPT-4 in advancing breast cancer treatment, promising a future\nwhere human expertise and artificial intelligence synergize to enhance patient support and care.\nThe correspondence calls for further research to explore the benefits of GPT-4, underscoring\nits potential to transform healthcare practices (Deng et al., 2023).\nRecent advancements in AI technology have led to exploring its potential applications in\nmedical education, particularly in examining how models like ChatGPT perform in medical\nexaminations. In a 2024 study by Nakao et al., researchers assessed GPT-4V using the 117th\nJapanese National Medical Licensing Examination, which included visual elements. The study\nrevealed that the inclusion of images did not improve performance; accuracy rates were 68%\nwith images and 72% without, suggesting that the current version of GPT-4V may struggle with\ninterpreting medical images, potentially limiting its applicability in medical training and\ndecision-making (Nakao et al., 2024). Building on these findings, another study by Hyungjin\nKim et al. in 2024 explicitly focused on ChatGPT's ability to interpret radiological images from\nmedical school exam questions. While ChatGPT demonstrated proficiency in handling text-\nbased radiology questions, it weakened with image-based queries, showing significantly lower\naccuracy than third-year medical students. This indicates that although AI models like ChatGPT\nare progressing, they still require significant enhancements and specialized training in medical\nimaging to be considered reliable in the clinical radiology setting (Kim et al., 2024).\nDespite this technology's challenges and early development stage, the authors are optimistic\nabout its application prospects, suggesting that Visual ChatGPT could significantly advance\nremote sensing methodologies by making them more accessible and efficient. Balado and\nNguyen (2023) evaluated the functionality of MATLAB codes generated by ChatGPT for point\ncloud processing tasks such as surface normal calculation, curvature, eigenvalues, and\neigenfeatures. The study demonstrated that while ChatGPT could generate simple and short\nfunctional codes, it struggled with more complex code that required the correct use of loops,\nindexes, or equations. This research highlights the potential of LLMs in generating code for"}, {"title": "An Illustrative Example", "content": "This section demonstrates the application of GPT-4 Vision to monitor and track construction\nprogress for two buildings on a university campus at the Middle East Technical University. The\nfirst site features a combination of reinforced and steel structures , while the second\nsite consists of fully reinforced concrete structures . ChatGPT had been used via\nchat.openai.com as of April 28th, 2024. We used high-resolution aerial photographs with\ndimensions of 4000x3000 pixels. No custom instructions of ChatGPT or memorization features\nwere enabled, allowing results based purely on the input provided during each session. The\nresponse time for each result generation was less than 30 seconds."}, {"title": null, "content": "For the initial analysis, High-resolution aerial images measuring 4000x3000 pixels were\nutilized. The AI was prompted to \u201cList the properties in this construction site. \u201d for each\nimage, ChatGPT responded to for reinforced and steel structure  as:\nIn the construction site depicted in the image, the following properties and features can be identified:\n1. Building Under Construction: A partially constructed multistory building with exposed floors.\n2. Red Steel Framework: A red steel structural framework is visible on top of the building, indicating\nongoing construction or expansion.\n3. Heavy Machinery:\n\u2022 Excavator: Positioned on the ground to the right of the building, possibly used for\nearthmoving or site preparation tasks.\n\u2022 Wheel Loader or similar machinery: Located at the bottom left corner, typically used for moving\nmaterials.\n4. Construction Materials:\n\u2022 Sand piles: Likely used for making concrete or for grading purposes.\n\u2022 Gravel or aggregate piles: Also a component of concrete or used for drainage systems.\n\u2022 Pipes and construction supplies: Stored around the site, indicating the various stages of construction\nactivity.\n5. Perimeter Fencing: Enclosing the site for security and safety, indicating a controlled access area.\n6. Storage and Workspace:\n\u2022 Covered areas that could serve as on-site storage for tools and materials or as workspaces for the\nconstruction crew.\n\u2022 Open areas with stacked materials and supplies necessary for the ongoing construction work.\n7. Geographic Location: The presence of a forest or treed area around the construction site, suggesting\na location that is not densely urban.\n8. Site Terrain: Modified ground surrounding the building, with visible tire tracks and dug-out areas\nindicating heavy machinery movement and site preparation work.\n9. Safety Features: Visible safety barriers around potential hazards and possibly safety signage (not\nclearly visible but commonly present in such settings).\nChatGPT response for fully reinforced concrete structure :\nThe image shows a construction site with various features:\n1. Partially Constructed Multi-Story Building: There's a structure that appears to be a multi-story\nconcrete building in the midst of construction. Some floors are partially done with visible columns and\nsupport beams.\n2. Construction Materials: Various construction materials are scattered throughout the site, including\nstacks of bricks, piles of construction bars (rebar), and other building materials.\n3. Heavy Machinery: There is construction machinery present, which includes at least one telehandler\nand what appears to be a mobile crane.\n4. Scaffolding: There are sections of scaffolding around the building, used by workers to access higher\nlevels of the construction.\n5. Debris: There's a significant amount of debris and rubble on the upper floors of the building, possibly\nfrom demolition work or the aftermath of a structural collapse.\n6. Surrounding Structures: Adjacent to the construction site, there are other buildings that look like\ncompleted structures, possibly office or industrial buildings.\n7. Safety Barriers: There are red and white safety barriers around the perimeter of the site, which are\nlikely there to prevent unauthorized access and to mark the construction zone.\n8. Construction Site Accessories: There are also various items like portable toilets, storage containers,\nand makeshift sheds, probably used for storage or as temporary site offices.\n9. Fenced Areas: Part of the construction site is fenced, likely for security purposes and to delineate the\nconstruction area from the surrounding environment.\n10. Topography: The site is surrounded by some greenery and trees, indicating it may be on the outskirts\nof an urban area or in a more suburban or rural setting.\n11. Vehicle Tracks: There are visible tracks on the ground, indicating the movement of vehicles around\nthe site.\nThese observations provide a general understanding of the construction site's characteristics and status."}, {"title": null, "content": "These results showcase GPT-4 Vision's adeptness at comprehensive scene analysis, providing\na foundational understanding of the construction site's current state and context. Following the\nscene understanding, the study progressed to examine GPT-4 Vision's capability in tracking\nconstruction development and assessing task completion. Two sets of aerial images of the fully\nreinforced concrete structure, taken one month apart, were uploaded to the ChatGPT . The system was instructed to \"Two images will be uploaded, after upload, categorize and\ncreate a list of construction progress.\u201d"}, {"title": null, "content": "ChatGPT responded to this prompt as given below:\nThank you for uploading both images. Based on the visual information, I will categorize the construction\nprogress as follows:\nFirst Image:\n1. Excavation and foundation work appears to be complete.\n2. Formwork for columns and walls is erected, indicating that the construction is prepared for concrete\npouring.\n3. Scaffolding is in place for work on the above-ground structure.\n4. Construction materials and equipment are organized around the site, showing active work. 5. The\nground floor slab seems to be complete, with work progressing on upper floor slabs.\nSecond Image:\n1. The progress is similar to the first image with the continuation of concrete work.\n2. Formwork is present on additional floors, suggesting vertical construction progression. 3. More\nscaffolding is visible, indicating ongoing work on higher levels.\n4. Construction materials appear to be more spread out, likely due to work taking place on various parts\nof the building simultaneously.\n5. The perimeter of the building seems to be more defined, with potential work on internal partitions or\nwalls.\nBoth images show the construction site at an advanced stage of the structural phase, with work focused\non erecting the concrete skeleton of the building. The precise sequence of construction steps can only be\ndetermined if the images are taken at different times; however, the visible elements suggest the project is\nmoving from completing the ground floor toward constructing the upper floors. There doesn't appear to\nbe any significant exterior work yet, such as cladding or facade installation, which typically follows the\ncompletion of the main structure.\nThen, the AI tool was provided with a list of expected tasks at the construction site and asked\nto, \u201cFrom this list which tasks are completed? Categorize, completed, ongoing and not started\ntasks only. Prepare a table.\n1 Site - Earth\n2 Foundations\n3 Structural Columns - B1 Basement"}, {"title": null, "content": "GPT-4 Vision identified the progress and tabulated the tasks into categories as below:\nBased on the images provided and the construction list, the categorization of tasks is as follows:\n1 Site - Earth - Completed\n2 Foundations - Completed\n3 Structural Columns - B1 Basement - Completed\n4 Structural framing - B1 Basement - Completed\n5 Floor Slabs - B1 Basement - Completed\n6 Structural Framing - Ground Floor - Completed\n7 Floor Slabs - Ground Floor - Completed\n8 Structural Columns - Ground Floor - Completed\n9 Columns - Ground Floor - Completed\n10 Structural Framing - 1st Floor \u2013 Ongoing\n11 Floor Slabs - 1st Floor \u2013 Ongoing\n12 Structural Columns - 1st Floor \u2013 Ongoing\n13 Columns - 1st Floor \u2013 Ongoing\n14 Structural Framing - 2nd Floor \u2013 Not Started\n15 Floor Slabs - 2nd Floor \u2013 Not Started\n16 Structural Columns - 2nd Floor - Not Started\n17 Columns - 2nd Floor \u2013 Not Started\n18 Structural Framing - Roof \u2013 Not Started\n19 Floor Slabs - Roof \u2013 Not Started\n20 Roofs - Not Started\nThe above categorization is inferred from the images with the understanding that the first floor is above\nthe ground floor. The tasks that are 'Ongoing' are assumed because there is visible work in progress\nrelated to those tasks in the images, whereas 'Not Started' tasks are those for which there is no visible\nwork or structure present."}, {"title": "Discussion and Conclusions", "content": "The deployment of GPT-4 Vision in construction progress monitoring offers promising insights\ninto the initial capabilities of AI for scene understanding and progress monitoring. As far as the\nauthors' knowledge, this is the first study to explore the use of GPT-4 Vision for construction\nprogress monitoring, offering new insights into its capabilities and limitations. This section\ndelves into the findings of this evaluation in detail while explaining the current state, limitations,\nopportunities, and future works."}, {"title": "Current State and Limitations", "content": "\u2610\nThe review of ChatGPT-4 Vision capabilities in identifying and analyzing construction\nsites reveals both its strengths and limitations. Initially, ChatGPT effectively recognizes\nthe type of building and construction materials, correctly identifying type of steel and\nreinforced concrete structures.\n\u2610\nRegarding construction machinery, ChatGPT demonstrates an understanding of\ndifferent equipment types, such as excavators and wheel loaders, although it struggles\nwith precise location identification due to its inability to detect objects at the pixel level.\nThe inability to accurately detect objects in images hinders the performance of detection\nand segmentation tasks in computer vision applications. The machinery was identified\nas a telehandler and a mobile crane in Figure 2b. Although the mobile crane was\ncorrectly identified, a backhoe loader was actually present on the site instead of a\ntelehandler. However, the equipment mounted on the front of the backhoe loader is\nsimilar to that of a telehandler, which performs similar functions. Therefore, this\nmisclassification is not entirely incorrect.\n\u2610\nMoreover, ChatGPT can identify various construction site materials like sand piles,\npipes, and other supplies, providing relevant information about their uses. This\nknowledge aids in assessing the progress of construction accurately. However, there are\ninstances of misclassification, such as wrongly identifying debris on upper floors as\nunused materials, leading to incorrect assumptions about potential demolition work.\nThis points to limitations in object classification that could affect the model's reliability\nin specific scenarios.\n\u2610\nRegarding safety measures, ChatGPT identifies general precautions like perimeter\nfencing and safety barriers but lacks specificity about their locations. This general\ninformation might not be sufficient for detailed safety analysis or planning.\n\u2610\nChatGPT demonstrates proficiency in contextualizing the construction environment,\nsuccessfully identifying non-urban settings by noting surrounding forests and tree areas.\nIt recognizes site accessories such as portable toilets and storage containers, which are\ncrucial for managing and organizing construction sites. The model also comments on\nsite accessibility by noting roads and visible tracks, although these observations are not\ndetailed.\n\u2610\nFor the comparison of consecutive time images, ChatGPT analyzes each construction\nstage sequentially, providing general information about the stage, materials, and\nmachinery involved as it conducts scene understanding (Figure 3). The first image was\nidentified with the foundation work completed. ChatGPT noted the preparation for\nconcrete pouring, inferred from the erection of formwork for columns and walls. It\ncorrectly identified the completion of the ground floor slab. The addition of floors and\nthe progression of vertical construction was recognized in the second image. It was also\nobserved that more construction materials were distributed across the site, indicating\nthat various parts of the structure were being built simultaneously.\n\u2610\nTo establish a baseline for ChatGPT, items from the construction plan were provided,\nand it was prompted to categorize these items as completed, ongoing, or not started. It\ndemonstrated the ability to create a categorized table. ChatGPT accurately understood\nthat the earthworks and foundations were completed. The platform identified the floor\nlevels, noting that the tasks on the ground floor were completed and that construction"}, {"title": null, "content": "on the first floor was ongoing. The tasks for the second floor had not yet started. A more\ndetailed construction plan could be input to enhance the categorization of each task."}, {"title": "Opportunities and Future Works", "content": "\u2610\nLooking forward, the development of GPT-4V in progress monitoring tasks represents\nan early step with significant potential for expansion and improvement. Current research\nshould include more diverse structures, such as transportation and hydraulic facilities,\nto test the model's capability to identify different material types. This would provide a\nbroader understanding of its applicability across various construction domains.\n\u2610\nIntegrating aerial and ground images when uploading to the ChatGPT process could\nenhance the model's effectiveness by providing a more comprehensive view of\nconstruction sites. This approach could lead to more detailed and accurate monitoring,\nencompassing a wider range of perspectives and details.\n\u2610\nWhile current GPT models do not have the capability to segment objects within images,\nutilizing pre-segmented images could facilitate better object differentiation, as\nsuggested by Yang et al. (2023), indicating that segmented images improve object\nlocalization. Hence, incorporating segmented images could be a valuable next step in\nrefining GPT's visual recognition functions.\n\u2610\nIt is also crucial to evaluate other language vision models like Gemini (Google, 2023)\nand LLaVa (Liu et al., 2023) to compare their performance with GPT-4V. Such\ncomparative studies could highlight strengths and weaknesses specific to each model,\nguiding further development and optimization.\n\u2610\nIntegrating GPT models with as-planned models could significantly enhance\nconstruction monitoring, such as exporting screenshots of the same viewpoints from 4D\nBIM as both as-planned and as-built images for GPT analysis. This integration could\nassist in creating accurate digital twins and enable precise tracking of construction\nprogress.\n\u2610\nLastly, there is immense potential in training or fine-tuning these models with\nconstruction-specific images. Domain-specific large vision models could revolutionize\nthe industry by improving efficiency and expanding capabilities (LandingAI, 2023).\nTheir ability to understand complex patterns from large datasets could be pivotal in\naddressing various challenges within the construction sector and beyond."}]}