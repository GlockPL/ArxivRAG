{"title": "EXAONE 3.0 7.8B Instruction Tuned Language Model", "authors": ["LG AI Research"], "abstract": "We introduce EXAONE 3.0 instruction-tuned language model, the first open model in the family\nof Large Language Models (LLMs) developed by LG AI Research. Among different model sizes,\nwe publicly release the 7.8B instruction-tuned model to promote open research and innovations.\nThrough extensive evaluations across a wide range of public and in-house benchmarks, EXAONE 3.0\ndemonstrates highly competitive real-world performance with instruction-following capability against\nother state-of-the-art open models of similar size. Our comparative analysis shows that EXAONE\n3.0 excels particularly in Korean, while achieving compelling performance across general tasks and\ncomplex reasoning. With its strong real-world effectiveness and bilingual proficiency, we hope that\nEXAONE keeps contributing to advancements in Expert AI. Our EXAONE 3.0 instruction-tuned\nmodel is available at https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct.", "sections": [{"title": "Introduction", "content": "EXAONE stands for Expert AI for EveryONE, a vision that LG is committed to realizing in order to democratize\naccess to expert-level artificial intelligence capabilities. Our objective of Expert AI is twofold: to help the general public\nachieve expert-level competency in various fields and to assist experts in attaining even higher levels of proficiency.\nThis aligns with LG AI Research's mission to integrate advanced AI into everyday life, making expert knowledge and\ncapabilities accessible to a broader audience.\nIn August 2024, LG has announced the release of EXAONE 3.0 models with enhanced performance and equipped\nwith the Enterprise AI Agent service enabled by the models. EXAONE 3.0 models will be supplied for commercial\npurposes, mainly to LG affiliates and partners as before, but among them, the 7.8B instruction-tuned model is made\npublicly available for non-commercial, research purposes. This release aims to support the broader AI community by\nproviding access to a high-performance language model, thereby fostering innovation and collaboration. This technical\nreport covers the performance of EXAONE 3.0's 7.8B instruction-tuned model which is competitive in English and\nexcellent in Korean compared to other similar-sized recently-released large language models (LLMs)."}, {"title": "Model Training", "content": "In this section, we provide an overview of the model training process for EXAONE 3.0, which encompasses several\ncritical stages, including the detailed architecture design, efficient tokenization for bilingual support, extensive pre-\ntraining on a diverse dataset, and advanced post-training techniques to enhance instruction-following capabilities. These\nsteps ensure the model's robust performance in real-world scenarios and adherence to strict data compliance standards."}, {"title": "Model Architecture", "content": "In line with recent trends, EXAONE language model is based on the decoder-only transformer architecture [39]. Its\nmaximum context length is 4,096 tokens, and it uses Rotary Position Embeddings (RoPE) [36] and Grouped Query\nAttention (GQA) [2]."}, {"title": "Tokenizer", "content": "The design choices for a tokenizer has a significant impact on the efficiency of training and generation. It is essential to\ntake into account the supporting languages in order to ensure optimal performance. EXAONE 3.0 7.8B is a bilingual\nmodel to support two languages: English and Korean. Due to the heterogeneous linguistic features of the two, we\nespecially considered the agglutinative feature in Korean to pre-tokenize Korean corpora using MeCab [21]. Then,\nwe trained on BBPE (byte-level byte-pair encoding) tokenizer [40] from scratch with a vocabulary size of 102,400.\nIt results in a similar compression ratio in English but a lower compression ratio in Korean over existing tokenizers\nas in Table 2. A lower compression ratio indicates that the tokenizer generates fewer tokens per word, which can be\nbeneficial as it reduces the likelihood of over-tokenization. This is particularly important for Korean language due to its\nagglutinative structure, where words can be formed by combining multiple morphemes, thus leading to improved model\nperformance and generation."}, {"title": "Pre-training", "content": "There has been a trend in pre-training to utilize trillions of tokens (Table 3) far beyond the data-optimal scaling laws\n[18]. Furthermore, the importance of data quality becomes more significant in cost-effective training [13, 43]. Following\nthe trend, several researchers put efforts to make the large amount of web-crawled data accessible at hands and study\nthe behavior of the model by controlling the quality and diversity of the data [29, 30].\nIn order to create the best-fit data and training regime to train EXAONE language models from scratch, we made sure\nto enhance the overall quality of the data, acknowledged the potential legal issues, and set an adequate curation strategy\nto boost expert knowledge."}, {"title": "Data Processing", "content": "To construct the data pool at first, we collected a comprehensive combination of large-scale\nweb-crawled, publicly-available, and internally-constructed corpora. Then, we applied the de facto standard which\nincludes rule-based filtering, machine learning based filtering, URL-based filtering, fuzzy deduplication, and removal\nof personally identifiable information (PII) to our pool. We not only adhered to the established methods but also\nimplemented data-specific processing strategies to increase the depth of knowledge. In addition to handling the data\nquality, we excluded the data sources that posed potential legal risks. The detailed information is described in Section 2.6."}, {"title": "Post-training", "content": "To improve the instruction-following ability of EXAONE language models, we performed a two-stage post-training:\nsupervised fine-tuning (SFT) [41] and direct preference optimization (DPO) [31].\nAs a first stage, creating high-quality instruction tuning data is crucial for performance as it helps the model generalize\nto new tasks. However, challenges arise from the difficulty in gathering sufficiently good-quality data. To address\nthis, we developed a broad spectrum of instruction types to enhance diversity and coverage. To cover a broad range\nof service-oriented instructions, we defined various topics and instructional functionalities. Using the definitions, we\ncreated multi-turn datasets that are diverse and closely mimic authentic user interactions, providing a realistic reflection\nof genuine user experiences as in Table 4.\nThe second stage is to align the model with human preferences using human feedback, which is known as Direct\nPreference Optimization (DPO). Language models were trained to maximize differences in reward between chosen\nand rejected responses in preference datasets. There are two methods in DPO: offline DPO and online DPO, and we\napplied them in sequence. The offline DPO is a technique for training models using pre-built preference data, as shown\nin Table 5. On the other hand, the online DPO configures prompts to have data distributions similar to those learned\nthrough the offline DPO, enables the model to generate responses, evaluates them against preferences using reward\nmodels, labels responses to chosen or rejected, and uses the results for training again."}, {"title": "Training Costs", "content": "EXAONE language models were trained using Google Cloud Platform and a cluster powered by NVIDIA H100\nGPUs and NVIDIA NeMo Framework. Then, they were optimized by NVIDIA TensorRT-LLM. The total amount of\ncomputation used for model training was about 4 \u00d7 1023 FLOPS."}, {"title": "Data Compliance", "content": "AI model development requires a large amount of data, and the acquisition and utilization of this data can lead to various\nlegal issues, such as copyright infringement, intellectual property infringement, and personal information protection\nviolations. If these issues are ignored or addressed inadequately, it can have a significant impact on the company, as\nwell as the general users and businesses that use the AI model.\nTo minimize these risks, LG AI Research conducts AI Compliance reviews throughout the entire process of data\ncollection, AI model training, and information provision. The team responsible for data collection uses a checklist to\nidentify potential problems before they occur. If a problem arises, the relevant department is consulted. When acquiring\ndata through ownership or licensing agreements, the relevant team negotiates with the data owner and, if necessary,\nconsults with legal professionals to ensure proper data acquisition or licensing.\nEach training dataset is subjected to a licensing review process. After this review, the AI model is trained using the\napproved data. Subsequently, a data risk assessment is conducted to establish the criteria for the AI model's distribution.\nThe language model, developed pursuant to this robust compliance system, distinctly omits legally precarious data such\nas news articles and books."}, {"title": "Evaluation", "content": "EXAONE 3.0 7.8B is a bilingual model trained mainly on English and Korean. To evaluate performance in English and\nKorean, well-known public benchmark datasets and in-house benchmark datasets were used. See Table 18 in Appendix\nfor more details on the benchmark datasets and the methods used to evaluate the models with them.\nThe results of model's English and Korean performance against the benchmarks summarized in Table 6. The models\nused for performance comparison are the latest models of similar size that support both English and Korean, for which\nwe obtained all the performance data by measuring performance ourselves. There are some differences between the\nperformance results that we measured and the reported numbers, but most of them did not show significant differences."}, {"title": "English Capability", "content": "The results of this performance comparison show that our model has a competitive overall performance in English\nagainst the comparison models."}, {"title": "Real-world Use Cases", "content": "EXAONE aims to be an Expert AI, so achieving comprehensive performance in real-world use cases is crucial. However,\nevaluating comprehensive performance through benchmarks that only measure single tasks has its limitations. Often,\nthere's a discrepancy between responses perceived as satisfactory by users and the actual benchmark scores. Therefore,\nLMSYS Chatbot Arena [26], which reflects actual human evaluations, has gained attention. To verify performance\nin real-world use cases, we measured four benchmarks that have a high correlation with LMSYS Chatbot Arena as\nin Table 7. Like well-known stylistic preference for longer responses (a.k.a. verbosity bias) in MT-bench [45], each\nbenchmark inherently exhibits certain biases by design. Therefore, we advocate using multiple benchmarks to ensure\ncomprehensive and accurate real-world evaluations.\nBased on Table 7, EXAONE 3.0 7.8B instruction-tuned model demonstrates significantly better performance compared\nto other models on MT-Bench, one of the benchmarks prominently featured in LMSYS Chatbot Arena. Specifically,\nthe MT-Bench score of 9.01 is remarkably high. In the Arena-hard-auto full leaderboard [4], only models with at least\n70B parameters have achieved a score of 46.8 or higher as of today. The WildBench score of 48.2 is also the highest\namong models with less than 10B parameters. Lastly, the AlpacaEval 2.0 LC benchmark score of 45.0 surpasses the\nGPT-4-0314 model's score of 35.3, as listed on the leaderboard [3]. Overall, as evidenced by the average scores, our\nmodel outperforms other similar-sized open models in real-world use cases."}, {"title": "Math", "content": "To assess performance in math capabilities, we measured two benchmarks: GSM8K and MATH. GSM8K is used\nto measure grade school math word problems, and MATH is used to measure challenging competition mathematics\nproblems. As shown in Table 8, EXAONE 3.0 7.8B instruction-tuned model performed well on both benchmarks, and\nas evidenced by the average scores, it demonstrates superior math capability compared to other models."}, {"title": "Coding", "content": "To evaluate coding capabilities, we measured the performance on popular benchmarks for Python code generation,\nfocusing on relatively simple, self-contained functions. HumanEval measures functional correctness for synthesizing\nPython programs from docstrings, and MBPP (The Mostly Basic Programming Problems) measures models' ability to\nsynthesize short Python programs. As shown in Table 9, EXAONE 3.0 7.8B instruction-tuned model's performance in\nHumanEval stands out compared to other models, and it also shows competitive performance in MBPP. Consequently,\nthe average scores indicate that our model demonstrated superior coding capability compared to other models."}, {"title": "Reasoning", "content": "To evaluate the reasoning capability, we measured two benchmarks: ARC-C (AI2 Reasoning Challenge - Challenge\nSet) and GPQA (General-Purpose Question Answering) as in Table 10. ARC-C focuses on the model's higher-order\nreasoning capabilities, particularly in solving challenging science exam questions that require the application of scientific\nknowledge and logical thinking. GPQA assesses the model's ability to answer a wide range of questions across various\ndomains, testing the breadth and accuracy of its knowledge. Together, these benchmarks provide a comprehensive\nassessment of the models' performance in both complex reasoning tasks and general knowledge.\nBased on Table 10, EXAONE 3.0 7.8B instruction-tuned model ranks third in performance on both benchmarks."}, {"title": "General", "content": "Due to recent issues with benchmark contamination, the reliability of evaluation scores from traditional benchmarks\nhas decreased. To address this problem, Open LLM Leaderboard 2 [14] was released. It includes IFEval (Instruction\nFollowing Evaluation), BBH (Big-Bench Hard), MATH Level 5, GPQA (Google-Proof QA), MuSR (Multistep Soft\nReasoning), and MMLU-Pro. These benchmarks are designed to test models on complex reasoning, long-range context\nparsing, and instruction-following abilities, providing a more rigorous evaluation than traditional benchmarks."}, {"title": "Korean Capability", "content": "To measure the model's general capability, we adopted the Open LLM Leaderboard 2 for comparative evaluation. As\nshown in Table 11, EXAONE 3.0 7.8B instruction-tuned model demonstrated competitive general capability compared\nto other models."}, {"title": "Real-world Use Cases", "content": "To evaluate the comprehensive performance of models, similar to real-world use cases in Section 3.1.1, we selected\ntwo Korean benchmarks: KoMT-Bench and LogicKor. KoMT-Bench is an in-house dataset created by translating\nthe MT-Bench dataset into Korean and modifying the content to reflect the characteristics and cultural nuances of the\nKorean language. Examples are shown in Table 19 in Appendix. The categories and number of questions are identical\nto those of the original MT-Bench dataset. LogicKor is a similar benchmark to MT-Bench, consisting of 42 multi-turn\nprompts across six categories (reasoning, mathematics, writing, coding, comprehension, and Korean language).\nAs shown in Table 12, EXAONE 3.0 7.8B instruction-tuned model surpassed the comparison models in both benchmarks.\nIn this experiment, we found that, even when responses in the KoMT-Bench were generated in a language other than\nKorean, GPT-4-0613, acting as the judge, continued to award high scores. To handle such cases, we adopt a square root\npenalty which applies the square root to the score of non-Korean responses in order to adjust for this discrepancy5."}, {"title": "General", "content": "To conduct a comprehensive evaluation, we utilized public Korean benchmarks as given in Table 13. In accordance with\nthe English general benchmarks in Section 3.1.5, we adopted similar benchmarks KMMLU [34] and KoBEST [20].\nFurthermore, we included Korean subset of Belebele [6] benchmark which is a multiple-choice multilingual machine\nreading comprehension benchmark. The overall results demonstrate that our model outperformed other models on most\nbenchmarks."}, {"title": "Responsible AI", "content": "We follow the LG AI Ethics Principles [23] to ensure the responsible development and deployment of the\nEXAONE 3.0 7.8B. Considering the model's capabilities, we assessed potential social and ethical issues and identified\nsolutions to address them. We focus on improving the model's safety and maintaining high ethical standards throughout\nthe development process."}, {"title": "Benefits", "content": "EXAONE 3.0 7.8B is the open model designed to offer robust performance in bilingual environments, with particular\nstrength in Korean. We believe this broad access to our model can open new avenues for researchers and developers\nwithin the AI community. This accessibility encourages innovation and collaboration, enabling users to explore a wide\nrange of application possibilities.\nOne of the key benefits of EXAONE 3.0 7.8B is its advanced capabilities allow for comprehensive instruction fine-tuning,\nwhich supports a wide range of developer needs. This flexibility enhances the model's utility in creating specialized\napplications. These applications can be tailored to suit various industries and domains, making EXAONE 3.0 7.8B\na valuable tool in diverse professional settings.\nHowever, with the release of this model, we emphasize the importance of responsible use to prevent malicious activities.\nBy doing so, we aim to foster a safe and innovative AI research environment, thereby making a positive contribution to\nthe global AI community."}, {"title": "Risks and Mitigations", "content": "Open model brings significant benefits to the AI community. However, we are aware that they also come with significant\nchallenges for responsible deployment such as malicious misuse, unintended outcomes like discriminatory bias, and\nharmful content. Through AI Ethical Impact Assessment, we identified several risks and improved the model's safety.\nA primary concern is malicious misuse from by bad actors. Open access to model weights allows anyone to fine-tune\nand deploy the model without substantial oversight. This accessibility increases the risk of misuse, such as generating\nmisinformation and disinformation, influencing public opinion, and enabling scams or phishing attempts, similar to risks"}, {"title": "Red Teaming", "content": "We have conducted comprehensive evaluations of EXAONE 3.0 7.8B to assess the ethics and security using both\nin-house and third-party datasets. Ethical evaluations focus on detecting hate, bias, and illegal content, while security\nassessments address potential information hazards, such as the use of private data in training.\nThe internal evaluation is executed by an in-house team and tested using carefully crafted question-answer datasets,\ndesigned to cover a wide range of unethical and insecure scenarios. Team members labeled the system's responses\nas either \"Pass\u201d or \u201cFail\u201d, providing reasons for their assessments, and labeled as \"Skipped\" if the language model\nprovided off-topic responses. The results are presented in Table 14."}, {"title": "Limitations", "content": "EXAONE 3.0 7.8B, like all existing language models, has certain limitations and may occasionally generate inap-\npropriate responses. The language model generates responses based on the output probability of tokens, and it is\ndetermined during learning from training data. While we have made every effort to exclude personal, harmful, and\nbiased information from the training data, some problematic content may still be included, potentially leading to\nundesirable responses. Please note that the text generated by EXAONE language model does not reflect the views of\nLG AI Research.\n\u2022 Inappropriate answers may be generated, which contain personal, harmful or other inappropriate information.\n\u2022 Biased responses may be generated, which are associated with age, gender, race, and so on.\n\u2022 The generated responses rely heavily on statistics from the training data, which can result in the generation of\nsemantically or syntactically incorrect sentences.\n\u2022 Since the model does not reflect the latest information, the responses may be false or contradictory.\nLG AI Research strives to reduce potential risks that may arise from EXAONE language model. Users are not allowed\nto engage in any malicious activities (e.g., keying in illegal information) that may induce the creation of inappropriate\noutputs violating LG AI's ethical principles when using EXAONE language model."}, {"title": "Deployment", "content": "Section 8.3 in Appendix provides license information for using the EXAONE 3.0 7.8B. Understanding the license\ninformation is essential for the legal utilization of the language model."}, {"title": "Conclusion", "content": "In this technical report, we premiered EXAONE 3.0 7.8B instruction-tuned language model, our first open LLM\nin EXAONE model family. Demonstrating its excellence in Korean and competency in English among models of\ncomparable size, we expect that stellar performance across real-world scenarios facilitates diverse open innovations. For\nnotable instance, this model serves foundations for our enterprise AI agent that optimizes business workflow, boosting\nboth efficiency and productivity.\nWhile we are currently releasing the cost-effective EXAONE 3.0 7.8B instruction-tuned model exclusively for non-\ncommercial and research purposes, we are optimistic that witnessing diverse applications of the 7.8B will further open\naccess to additional models in the future."}]}