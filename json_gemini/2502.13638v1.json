{"title": "Integrating Inverse and Forward Modeling for Sparse Temporal Data from Sensor Networks", "authors": ["Julian Vexler", "Bj\u00f6rn Vieten", "Martin Nelke", "Stefan Kramer"], "abstract": "We present CavePerception, a framework for the analysis of sparse data from sensor networks that incorporates elements of inverse modeling and forward modeling. By integrating machine learning with physical modeling in a hypotheses space, we aim to improve the interpretability of sparse, noisy, and potentially incomplete sensor data. The framework assumes data from a two-dimensional sensor network laid out in a graph structure that detects certain objects, with certain motion patterns. Examples of such sensors are magnetometers. Given knowledge about the objects and the way they act on the sensors, one can develop a data generator that produces data from simulated motions of the objects across the sensor field. The framework uses the simulated data to infer object behaviors across the sensor network. The approach is experimentally tested on real-world data, where magnetometers are used on an airport to detect and identify aircraft motions. Experiments demonstrate the value of integrating inverse and forward modeling, enabling intelligent systems to better understand and predict complex, sensor-driven events.", "sections": [{"title": "1 Introduction", "content": "Sensor networks can collect an almost arbitrary amount of multivariate data in a fraction of a second. However, sensors only measure the effect or outcome of physical phenomena. The true parameters that cause these outcomes are usually unknown. Inverse modeling is the approach to estimate the unknown causal parameters from the available observations. In other words, models are trained with the obtained data, in order to estimate the unknown parameters. Machine Learning (ML) approaches are the state of the art for making inferences from data. However, they frequently achieve their peak performance when the true labels are known and they can be trained in a supervised fashion. In contrast to inverse modeling, forward modeling uses well-defined parameters to generate synthetic data from simulations in, usually, controlled environments. In this work,"}, {"title": "2 Related Work", "content": "Inverse modeling is currently the predominant paradigm in ML and Data Mining (DM). Work on the integration of forward and inverse modeling, however, is currently found mainly outside ML and DM. A paper from applied physics [8] presents a deep learning approach to the forward and inverse designs of plasmonic metasurface structural color. Another applied physics paper describes a deep learning framework for forward and inverse problems in time-domain electromagnetics [4]. Closer in spirit are robotics approaches for tracking and prediction based on deep forward and inverse perceptual models [7]. Deriving data from simulations of theoretical models and then training classification, regression, and ranking models is quite common in ML applied to particle physics [6]. One has to note that the integration of forward and inverse modeling is similar to abduction [5], a currently underrepresented topic in DM [13].\nIn case of traffic surveillance on airport grounds, there is no actual standard for sensor systems for the tasks of object detection, speed estimation, tracking, and classification. Consequently, different technological systems are explored in the literature, where most of them focus on trajectory optimization during flight [9], mid-air classification of aircraft using radar [14] or aircraft classification based on top-view images [3,1]. However, in case of surface traffic surveillance on airports, aircraft need to be classified on the ground. Hence, visual-based technologies may struggle with obstacles and visually bad weather conditions like heavy rain, snow or fog [15]. On the other hand, magnetometers are not affected as they measure the Earth's magnetic field. They may also be installed directly below the surface of the holding point positions that need to be monitored, functioning as on-site sensors. Consequently, magnetometers have a high potential to be a part of traffic surveillance systems on airport grounds."}, {"title": "3 Simulation-Assisted Forward Modeling for Sparse Temporal Sensor Data", "content": "Our solution to the challenge of object detection, motion estimation, and classification of a moving object based on multivariate time-series data, is mirrored in our framework, named CavePerception. Inspired by Plato's allegory of the cave, where humans only see shadows of objects, which are inaccurate representations of ideal objects, we interpret our problem as follows: The sensors measurements are reflections of object motions, yet, they are not able to accurately represent the objects themselves. Consequently, the goal of CavePerception is to perceive real-world observations as imperfect representations of forwardly modeled synthetic patterns that are generated from known objects. Despite the imprecision"}, {"title": "Algorithm 1: CavePerception", "content": "// Inverse Modeling\n$\\\\$ estimate motion vector\n$\\\\$ classify object category\n$\\\\$ inversely modeled hypotheses\n// Forward Modeling\n$\\\\$ simulation hypotheses generated by a synthetic data generator\n// Inverse and Forward Modeling Matching\n$\\\\$ retrieve the most likely hypotheses (see Algorithm 2)\nin the data, the matching between observed and well-defined patterns shall reveal the true object.\nA top-level view of the processing pipeline of CavePerception is shown in Algorithm 1 and explained in detail below. The inverse modeling aims to classify an object and estimate its motion vector based on the information retrieved from the sensory data and geometric domain knowledge. This part of the framework is based on previous work [12,11], briefly summarized below. The forward modeling and hypotheses matching parts are the novel aspects of CavePerception. Overall, the aim is to improve the results from inverse modeling, by assisting the data analysis with well-defined, knowledge-infused simulations.\nInverse Modeling In the context of signal processing, it is often required to first employ a signal detection algorithm, before applying subsequent algorithms. Let $F = {s_1, ..., s_k}$ denote a sensor field, where each sensor $s_i \\in F$ delivers a multivariate vector reading. In case of 3-axis magnetometers, it is a three-dimensional vector of the Earth's magnetic field at each time point t: $s = {X,Y,Z}$.\nWe are only interested in sensor signals, when an object p is present. Hence, an event detection algorithm based on a Z-score approach is applied, to calculate a moving threshold $T(s_t)$ for each sensor $s_i \\in F$ at time t. A sensor s is activated if its measurements exceed the threshold: $|s_t| \\geq T(s_t)$. Furthermore, we define an event $E(t_0, t_k)$ as a sequence of activated sensors over time, from $t_0$ to $t_k$, as:\n$E(t_0,t_k) := {s_{tm}|\\forall s \\in F, m \\in [0, k] : |s_{tm} | \\geq T(s_{tm})},\\quad$(1)\nwhere at least one sensor is activated at each time point $t_m$. For simplification, event $E(t_0, t_k)$ is abbreviated as E. In real-world scenarios, an event E captures a temporal frame of a moving object p, where the object activates one or multiple sensors at each time point in E. Ideally, the complete object motion is observed in one event E. However, depending on the sensor field set-up, the sensor type, and"}, {"title": "Algorithm 2: Inverse and Forward Model Matching", "content": "// Hypotheses matching\n$\\\\$\n// Time-invariant hypotheses reduction\n$\\\\$ binary activation matrices of matched synthetic datasets\n$\\\\$ binary activation matrix of event E\n$\\\\$ initialize empty set for scalar distances\nfor each $\\\\$ do\n$\\\\$ // see Eq. 5\n$\\\\$ // see Eq. 6\nend\n$\\\\$ // see Eq. 7\n(iii) a motion was detected, but the object could not be classified, and (iv) there is not enough information to detect a motion or to perform a classification.\nOur forward modeling approach aims to fill the gaps of missing information in $\\\\$, including the identification of the specific object type p, by employing a time-invariant hypotheses matching algorithm within CavePerception. The pseudocode is shown in Algorithm 2 and explained below.\nHypotheses Matching The first step of the algorithm is the matching of the inversely derived hypotheses $\\\\$ of event E with the simulated hypotheses $\\\\$. In contrast to $\\\\$, the parameters of all hypotheses $h = (p, \\vartheta) \\in \\\\$ are known. Therefore, only those simulations are considered where the simulation parameters correspond to the estimated parameters $\\\\$ and $\\\\$:\n$\\\\$ \\quad$(2)\nThe hypotheses reduction to $\\\\$ results in hypotheses $h_i \\in \\\\$, where each parameter is known, as the missing information from the inverse modeling in $\\\\$ is filled with the available information in $\\\\$. For example, if the category $\\\\$ of object p is successfully predicted during inverse modeling, then all simulations of object types ${p_1,..., p_n}$ of category $\\\\$ are extracted from $\\\\$. This way, not only the categories of the objects are known, but also the specific object types $p_i$, which were unknown in $\\\\$. Here, we use the notation $p_i$ for the predictions of the true type p based on the predicted category $\\\\$. With the hypotheses matching, the set of simulation datasets $D_s$ is reduced to:\n$\\\\$,\nwhere $\\\\$ only contains those simulated datasets where the simulations were performed according to the estimated parameter combinations in $\\\\$."}, {"title": "Time-Invariant Hypotheses Reduction", "content": "After the hypotheses matching, it remains to retrieve the most likely hypotheses from $\\\\$ to describe the observed event E. Therefore, binary activation matrices of the simulated datasets $\\\\$ are compared with the binary activation matrix of event E. This way, we aim to find an optimal geometry-based match. Hence, each synthetic dataset $\\\\$ is converted from a continuous data representation to a binary activation matrix $\\\\$, where each column represents a sensor and the rows represent the time:\n$B_{i,j} = \\begin{cases} 1, & \\text{if } z_{i,j} \\geq T(z_{i,j})\\\\ 0, & \\text{otherwise.} \\end{cases}$    (4)\nSubsequently, each binary activation matrix $\\\\$ needs to be matched with $\\\\$. The matches are then used to derive dissimilarity scores that describe to which extent a simulation coincides with the observation. The most similar simulation hypotheses are then returned as the most likely explanations for the observed event. The matching of the binary activation matrices can be performed with any pair-wise distance measure pdist. The matrices themselves, $\\\\$ and $\\\\$, need to have the same number of columns $n_c$ (the number of sensors), but can vary in the number of rows $n_k$ and $n_l$, i.e. $|\\\\$ = (n_k, n_c) and $|\\$\\\\$ = (n_l, n_c), as the lengths of different events may vary. The pair-wise distance between the two matrices results in a distance matrix:\n$\\\\$   (5)\nwhere $v_i$ and $v_j$ are the i-th and j-th row vectors of matrices $\\\\$ and $\\\\$, respectively. In this work, we apply the Hamming distance, which counts at how many positions the entries in two vectors differ. Applied to the sensor activation matrices, it counts how many sensors differ in their activation in event E and simulation $S_i$. However, we are interested in a scalar score to describe the dissimilarity between both matrices. Therefore, the diagonals within matrix M are considered. Each diagonal is a full-match of observation E"}, {"title": "Time-Invariant Hypotheses Reduction", "content": "within the simulation $S_i$. We restrict the diagonals to mirror the full path of the smaller matrix. Hence, each diagonal needs to have min($n_k$, $n_l$) values. If a full match is not required, i.e. both crossings can also match partially, then the length of the diagonals could be set to be less restrictive. We can assure $n_k$ to be smaller than $n_l$ by transposing the resulting matrix, if $n_k > n_l$. To obtain a scalar distance sdist($M_{E,S_i}$), we search for the minimal dissimilarity in the diagonal sums of all diagonals diag(M) = {diag\u2081(M), ..., diagk(M)}:\n$\\$\nEquation 6 returns the optimal time-invariant match of event E with simulation $S_i$. Applying Equation 6 to every simulation $S_i \\in \\\\$, a set of optimal time-invariant matches is obtained and collected in $\\\\$. Finally, Algorithm 2 concludes the search for the optimal match in the simulations by choosing the simulations with the lowest scalar dissimilarity:\n$\\$\nNotice that synthetic data generation for sensors may be a challenging task. However, data normalization techniques may simplify the task, as the data generator then only has to mimic the normalized data. To further reduce the dependence on an exact data representation, our solution matches the hypotheses parameters h during the hypothesis matching, and afterwards, only the binary activation matrices B are compared to each other. Hence, it does not harm the solution, if the synthetic data does not perfectly match the real-world sensor data."}, {"title": "4 Experimental Results", "content": "The real-world data are multivariate time-series data covering a period of two years. The objects to be identified are aircraft, of which only the gears and engines are detectable by magnetometers. The real-world data has a high level of noise and latent factors that may reduce the data quality. Further, the data is sparse as many aircraft types occur rarely compared to a few types, which are often observed. On the other hand, the synthetic data (generated by forward modeling) has a larger aircraft type variety due to simulations of more aircraft types. The simulations were performed according to the background knowledge available. That is, for each aircraft type that passed the considered sensor field during the two-year observation period and whose aircraft dimension is known, motions were simulated with different motion vector assignments: The sensor field was passed in two directions at varying speeds and with small variations in the motion angles, such that aircraft do not always exactly follow the guiding line. All experiments were performed on a computer with OS Ubuntu 22 with 32GB memory, an Intel Core i7-4770K CPU and a GeForce GTX 1080 TI GPU. The GPU was used for the ML algorithms in the model comparison section, which are also a part of the inverse modeling of CavePerception."}, {"title": "Group Rank Evaluation", "content": "The predicted classes of CavePerception are contained in H. Based on the dissimilarities, one can obtain a ranking of dissimilarity groups $\\\\$, where each group $\\\\$ contains those simulations $\\\\$ where the dissimilarities are equal to i. This approach allows us to measure the degree of deviation from the true result based on the dissimilarity values. shows the histograms of the dissimilarity group ranks that contain the true class. That means, group one is the group with the highest match with event E,"}, {"title": "Model Comparison", "content": "We also compare CavePerception to commonly used ML algorithms to validate the benefit of combining forward with inverse modeling procedures. Therefore, we consider Transformers, which are frequently considered one of the best performing learning algorithms, XGBoost, random forest, and a random guessing baseline, which predicts the majority class. The disadvantage of many standard implementations of tree-based learners is the requirement of having all data preloaded, such that the models can be trained on the whole training data at once. Due to the size of our training data and the memory size required to train these models, random forests and XGBoost were trained on 75% of the training data. Incremental learning or similar techniques may be used to train the models on the whole dataset by iteratively updating from subsamples, however, this may introduce other challenges like representation bias"}, {"title": "5 Conclusion", "content": "In real-world applications, temporal data from sensor networks are frequently sparse and noisy. In this paper, we have shown that the combination of forward and inverse modeling can improve the overall results in such settings. Experiments have shown that our framework, CavePerception, does not only outperform other methods on complex data, but also that its group ranking approach based on hypothesis matching is able to capture most of the correct classes within the first two to three ranked groups. The model comparison also shows that classification results may be improved by including forwardly modeled hypotheses, compared to models that are solely inversely trained. Another advantage of our solution is that missing information from inverse modeling is filled with assignments from synthetic simulations based on the event matching with the real-world observation.\nCavePerception should work, as far as possible, without homogeneity assumptions in real-world sensor network deployments. It is able to handle any two-dimensional sensor layout structure and also works independent of the sensor sampling frequency, as the temporal differences between consecutive points are considered instead of fixed frequency-based time points. However, it requires at least two sensor lines perpendicular to each other, of which one is necessary to estimate the motion vector, while the other one is important for classification. Another limitation of CavePerception is the necessity of object type geometries. If the geometry of an object type is unknown, a simulation for this type cannot be performed, resulting in a non-detection of the correct type, in case it occurs in an observation. Further, the performance of CavePerception depends on the inverse modeling results. If the inverse process yields a false classification, then it will affect the final outcome of the hypotheses matching. Therefore, it is crucial to optimize the inverse modeling procedure. In future work, this dependence on inverse modeling may be loosened by providing probabilistic results, such that the matching between inverse and forward modeling may take the probabilities into account. On our roadmap, CavePerception shall be further developed and integrated into a prototype for real-time traffic surveillance on airport aprons."}]}