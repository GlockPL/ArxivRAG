{"title": "Dynamics of Toxicity in Political Podcasts", "authors": ["Naquee Rizwan", "Vishwajeet Singh Solanki", "Nayandeep Deb", "Kiran Garimella", "Sarthak Roy", "Animesh Mukherjee"], "abstract": "Toxicity in digital media poses significant challenges, yet little attention has been given to its dynamics within the rapidly growing medium of podcasts. This paper addresses this gap by analyzing political podcast data to study the emergence and propagation of toxicity, focusing on conversation chains-structured reply patterns within podcast transcripts. Leveraging state-of-the-art transcription models and advanced conversational analysis techniques, we systematically examine toxic discourse in over 30 popular political podcasts in the United States.\nOur key contributions include: (1) creating a comprehensive dataset of transcribed and diarized political podcasts, identifying thousands of toxic instances using Google's Perspective API, (2) uncovering concerning trends where a majority of episodes contain at least one toxic instance, (3) introducing toxic conversation chains and analyzing their structural and linguistic properties, revealing characteristics such as longer durations, repetitive patterns, figurative language, and emotional cues tied to anger and annoyance, (4) identifying demand-related words like 'want,' 'like,' and 'know' as precursors to toxicity, and (5) developing predictive models to anticipate toxicity shifts based on annotated change points.\nOur findings provide critical insights into podcast toxicity and establish a foundation for future research on real-time monitoring and intervention mechanisms to foster healthier discourse in this influential medium.", "sections": [{"title": "1 Introduction", "content": "Understanding and addressing toxicity in digital media is an ongoing challenge for researchers and practitioners alike. While much attention has been paid to platforms such as social media and online forums, comparatively less is known about the nature and dynamics of toxicity within the rapidly growing medium of podcasts. In this study, we aim to bridge this gap by collecting and analyzing political podcast data, focusing specifically on conversation chains structured reply patterns within podcast transcripts - to study the emergence and propagation of toxicity in this medium.\nPodcasting has seen remarkable growth in recent years, emerging as a mainstream medium for information and entertainment. As of 2024, there are over 500 million podcast listeners worldwide, representing 23.5% of all internet users. In the United States alone, 47% of adults have listened to a podcast within the last month, a figure that has more than tripled over the past decade. Politics and government rank as the third most popular podcast topic, with 41% of listeners regularly tuning in to content in this category [8, 25]. This growth underscores the importance of podcasts as a platform for political discourse, but it also highlights their potential as vehicles for misinformation, conspiracies, and hate speech [30]. Unlike traditional forms of media, podcasts remain largely unmoderated, further exacerbating the risks of unchecked toxicity. Understanding toxicity in podcasts is therefore not only academically significant but also crucial for ensuring healthy democratic discourse.\nStudying toxicity in podcasts presents unique challenges. Unlike text-based content, the audio format of podcasts makes them inherently difficult to monitor and analyze using traditional strategies. Transcribing large volumes of audio content incurs significant computational and financial costs, making large-scale studies impractical without significant resources. Further, audience interaction in podcasts is limited compared to social media platforms, where users can directly respond to or fact-check content. This lack of interactivity complicates efforts to understand how toxic narratives resonate with audiences. Moreover, analyzing toxicity within podcast transcripts requires not only identifying toxic language but also tracking how it ebbs and flows over time \u2013 examining what triggers toxic conversations and how they evolve within conversational structures. These complexities highlight why na\u00efve approaches to studying podcast toxicity often fail to capture its multifaceted nature.\nExisting research provides valuable starting points, but fails to address the problem in a comprehensive way. Advances in automatic transcription tools, such as Whisper, now allow for large-scale analysis of audio data. However, as previous work on datasets like RadioTalk [3] demonstrates, transcription errors and content ambiguity remain significant barriers, particularly for conversational and emotive formats such as podcasts. In addition, though the study of toxicity online is an active research area [21], there is little work on understanding conversational structures of toxicity and how it evolves [32].\nIn this paper, we introduce the concept of toxic conversation chains in podcasts. Using state-of-the-art transcription models and conversational analysis techniques, we explore how toxicity emerges and spreads in political podcasts. Our approach combines scalable transcription workflows with innovative analysis of conversational dynamics, providing novel insights into the structure and flow of toxic discourse in this medium."}, {"title": "2 Related works", "content": "Toxicity on social media: Toxicity, broadly characterized as disrespectful, harmful, or unreasonable communication, has been a significant focus in social media research [28]. It manifests itself through harassment, hate speech, and polarized discourse, often perpetuated by bots and trolls that amplify its spread. Studies highlight that toxicity often combines with misinformation and polarization, forming a \"cycle of online extremism\" that exacerbates its societal impact [27].\nDetection of toxicity: Defining and detecting toxicity requires nuanced approaches due to its context-sensitive nature. Techniques like BERT-based sentiment analysis have proven effective in detecting toxic content on platforms such as Twitter, leveraging large labeled datasets to improve classification accuracy [19]. Further, context-aware models are necessary to differentiate between benign negativity and harmful toxicity, particularly in multi-dimensional interactions [9]. Perspective API [16] is a valuable tool for researchers to analyze toxicity of online content, allowing them to study the spread of hate speech, cyberbullying, and other harmful online behaviors in different languages and cultures.\nToxicity in podcasts: Unlike traditional social media, podcasts present unique challenges due to their audio form. Transcription is often necessary for textual analysis, but introduces errors and challenges such as speaker identification and role prediction [6]"}, {"title": "3 Dataset", "content": "In this section, we discuss the details of curating, transcribing and diarizing the dataset being used for this work.\nWe construct the dataset based on channels list curated and shared by [30]. They identify popular political podcasts by analyzing Apple Podcasts' top hundred lists from two specific time periods and selecting talk shows that discuss politics, policy, current events, or news. The process is expanded by including related political punditry podcasts from the 'you might also like' recommendations, creating a comprehensive sample for analysis. RSS feeds are used to download the wav files and the podcasts span around the years 2022-2023. The full list of 31 podcast shows we used in this paper are shown in Table 3 in the Appendix. We acknowledge that these channels might have a bias with over representation from right leaning sources since the original objective of the dataset curated by [30] was to study conspiracies and misinformation. Having said that, care should be taken in interpreting the results particularly in the context of prevalence of toxicity, since our dataset only represents a small, biased subset of political podcasts.\nThat said, even though the set of podcasts we consider is small, these shows might have disproportionate impacts and people who are in power might disproportionately listen to these. For e.g., a lot of January 6, 2021 US Capitol attack \u00b9 coordination and top down messages iterate through the podcasts of personalities like Steve Bannon. Hence, the claims made on these podcasts may have particularly consequential implications for broader public opinion and political discourse. So, as a part of this work, we try to understand the toxicity being driven through conversational chains so that such content can be auto-moderated and avoided. A detailed summary of the dataset over thirty-one podcast channels, and some metadata associated with them is shown in Appendix 3.\nWe use WHISPER [22] to transcribe and PYANNOTE2 to diarize and identify individual speakers [4]. We filter out overlapping speech"}, {"title": "4 Toxic conversation chains", "content": "In this section, we discuss the process employed to accurately calculate the toxicity scores and the subsequent formulation of toxic conversation chains using these toxicity scores."}, {"title": "4.1 Toxic score calculation", "content": "To compute the toxicity of a speaker's speech we pass the diarized text corresponding to the speech to Perspective API.3 We use the benchmark TOXICITY attribute, available with the API to obtain the toxicity scores. Since the Perspective API can handle a limited number of tokens we split the diarized conversation text corresponding to a speaker turn into chunks of 17 seconds since this is the median conversation time of a turn in our dataset (see Figure 1). We club 1-4 chunks (approximately one minute) into a segment. Each segment corresponds to a specific speaker identified by a speaker ID, a set of (at most) four chunks, the start and end timestamps and the diarized text corresponding to the chunks in the segment. The toxicity score of a segment is set to the maximum of the toxicity score across these chunks within the segment. If a speaker turn exceeds the duration limit of a segment, it is broken into the required number of contiguous segments. We perform all our analysis at the level of these one minute segments so that the observations are statistically meaningful and not over dominated by a speaker speaking over a long stretch."}, {"title": "4.2 Toxic chain formulation", "content": "A toxic chain constitutes an anchor segment, the preceding ten and the following ten segments of the anchor segment (see Figure 1). A segment is identified as an anchor segment if its toxicity score is 0.7 or higher. This threshold is set as per the guidelines noted in documentation of the Perspective API.4 We take the previous and the next ten segments to understand what leads to the rise in toxicity and what happens after a peak toxic threshold has been reached. Anchoring on this threshold, we perform our analysis on a total of 8,634 chains. A set of representative examples of toxic conversation chains are provided in Figure 8 & Appendix 11."}, {"title": "4.3 Distribution of the toxic chains across\npodcasts", "content": "We compute the distribution of the toxic chains across the different podcast channels. Figure 3 shows the distribution of top ten channels. The top five contributing podcast channels are Louder with Crowder, Mark Levin Podcast, The New Abnormal, The Dan Bongino Show and Get Off My Lawn Podcast w/ Gavin McInnes in decreasing order of contribution aggregating to a total of 63.6%. Together, these podcasts potentially reach tens of millions of listeners every week.5 Many of these channels have been reported to be hosted and attended by people making homophobic, and racist remarks. 6,7,8"}, {"title": "5 Analysis of the toxic conversation chains", "content": "In this section we present an in-depth analysis of the segments constructed in the previous section."}, {"title": "5.1 Time coverage", "content": "The duration of each segment in a conversation chain is the difference between the start and the end time obtained during diarization process. We calculate the mean of the segment's duration across all the chains and plot them in Figure 4. Error bars indicate 95% confidence intervals. Interestingly, the anchor segment has the highest mean implying that speakers tend to speak for longer duration when their speech is most toxic.\nFurther, the rise in the mean duration is not sudden and neither is the fall. While the ascend starts from Segment -1 itself, the decay is more gradual and flattens after Segment 3."}, {"title": "5.2 Basic textual properties", "content": "We now study the basic textual properties of the diarized text corresponding to the anchor segments and compare them with the other segments in a chain. For all our textual analysis, we use the PyNLP19 library.\n(i) Token count: We calculate the total number of tokens in the diarized text for each segment in a conversation chain. To break the words into tokens, we use the word_tokenize from NLTK library.\n(ii) Type token ratio (TTR): This metric is used to evaluate the diversity of vocabulary in a text. It is given by the formula: #types/#tokens, where types are unique tokens. Higher values indicate greater lexical diversity which means that the text has less redundancy. Lower values suggest repetitive textual content. Figure 5 shows that the mean TTR for anchor segment is lower than all other segments in the chain indicating that there is more repetition (possibly of the same hateful remark) in the anchor segment.\n(iii) Token entropy: Using the unigram probability values of the tokens we compute the entropy of the diarized text. Figure 5 shows that the anchor segment has a higher average entropy compared to the other segments indicating that the text in the anchor segment is more random and less well-formed.\n(iv) Perplexity: Perplexity measures the prediction ability of a language model. Formally, if a language model has a perplexity P, then it means that the model is as uncertain as if it is select-ing P equally likely choices which is mathematically represented as: $P = Pr(w_1, w_2, ..., w_n)^{-1}$ where $w_1, w_2, ..., w_n$ are a sequence of tokens and $Pr$ is the language model. For our use case, $Pr$ is the unigram model where the unigram probabilites are obtained from the diarized text. Figure 5 shows that the mean perplexity is the highest for the anchor segment indicating that the conversation is least organized/coherent in this segment."}, {"title": "5.3 Figurative language", "content": "Human conversation, especially in a public discourse like podcasts are often strewn with figurative language like hyperboles and metaphors [5]. Hyperboles incorporate exaggeration for emphasis and metaphor is used to make implied comparison. In this section, we report the extent of such figurative language present in the conversation chains. We use the bert-large-uncased model finetuned on the STL task [1] to infer the hyperboles and metaphors from the diarized text. From Figure 6, we observe that, as expected, the usage of metaphors in podcasts is generally high ranging between 69.58% - 73.53% for the non-anchor segments. Remarkably, it reaches to an all high of 81.91% for the anchor segment. Further, we observe that the anchor segment has nearly double the percentage of hyperboles (18.03%) compared to the highest among non-anchor segments (9.19%). Thus, in summary, the toxic segment has the highest exaggeration level and more frequently invokes implied comparison. Both of these work as possible means to emphasize on the embedded toxic remark making it intense as well as subtle at the same time."}, {"title": "5.4 Empath features", "content": "Empath is a metric which is frequently used in text analytics to assess the emotional content of the text. We also use empath as a metric to understand the underlying emotions and behaviourial patterns latent in the conversation chains. Since our inputs are conversation chains and not flat text, we finetune the DistilBERT [24] model over the dataset presented in [23] to infer the 32 empath features from these chains. In Figure 7 we show the top eight most frequent emotions that have occurred at least 5% of times within a segment. We observe considerably high intensity for the following empath features - 'angry', 'furious', 'annoyed', 'disguted' in the anchor segment. On the other hand, there is a reduced intensity of the following empath features - 'surprised', 'hopeful', 'afraid', 'anticipating' in the anchor segment. Thus toxic conversations are laden with aggression resulting in the loss of decorum in the conversation."}, {"title": "5.5 Keywords", "content": "In order to identify and compare the keywords present in the segments we extract the top ten toxic key-phrases from each segment in every conversation chain using KEYBERT [10]. Each phrase is limited to a maximum of five-grams. The word embeddings for KEYBERT algorithm are obtained from the DETOXIFY [12] library. 10\nTo ensure diversity in our extracted key-phrases, we use the maximal margin relevance utility of the KEYBERT algorithm enforcing a diversity score of 0.75. In addition, we eliminate stop words & punctuations and only retain strings containing characters from the English alphabet. We combine all the keywords obtained from the preceding ten segments and represent them as a word cloud;"}, {"title": "5.6 Topical shifts", "content": "The keyword analysis in the previous section indicates that there is a significant change in the conversation content during the transition from the previous to the anchor segment. This hints to the fact that there is a possible topical/thematic shift during such a transition. In order to establish this we perform topic modeling using the BERTopic [11] model. We extract the topics considering the previous ten aggregated segments a one document, the next ten aggregated segments as a second document and the anchor segment as the third document. We set the number of topics to three and report the top ten most representative words for that topic which has the highest probability of association with a document. The results are noted in Table 1, which reveal significant shifts in thematic focus and toxicity level during the transition from the previous to the anchor segment and the anchor segment to the next segment. Precisely the anchor topic is highly toxic while the preceding and the following topics are more related to demands thus offering insights into the progression and contextual drivers of toxic conversations."}, {"title": "6 Change points in toxic chains", "content": "While linguistic properties studied in the previous section enables us to characterize the conversation chains, it is not possible to formulate actionable insights for designing effective interventions. In order to achieve this goal one has to acknowledge that toxic conversation chains are inherently dynamic, with evolving interactions that may involve multiple participants. Understanding the trajectory of these conversations requires identifying key points where significant shifts occur. Automatic change point detection can enable researchers to: (i) Isolate key moments: Automatically identify segments of conversations where toxicity sharply increases/decreases or new topics are introduced; and, (ii) Understand contextual triggers: Track down the patterns latent in events or statements that precede toxicity spikes or topic changes and thus reveal actionable insights for designing intervention strategies."}, {"title": "6.1 Automatic change point detection", "content": "We utilize standard change point detection (CPD) algorithms to automatically identify change points within conversation chains. Specifically, we consider various search methods - PELT, KERNELCPD, WINDOW, BOTTOMUP & BINSEG alongside different cost functions including rbf, cosine, 12 & linear. All implementations are done through ruptures [26] library. 11 According to the documentation, twelve combinations over these search methods and cost functions are possible; however only rbf as the cost function coupled with PELT, KERNELCPD, BOTTOMUP & BINSEG search methods successfully identifies at least one change point. As a result, we conduct our experiments and identify change points using these four algorithms."}, {"title": "6.2 Manual annotation of change points", "content": "To evaluate the predictive performance of the baseline CPD algo-rithms we conduct a manual annotation exercise of the change points. We consider as many as top 100 toxic conversation chains based on the toxicity scores of the anchor segments. We then get all the change points in each of these chains annotated by three annotators. All the three annotators are experts in hate speech analysis research. To ensure consistency and reliability in the annotation process, we ask the annotators to base their judgments on the following factors - (a) tone: shifts in sentiment or intensity, such as transitions from neutral or mildly toxic statements to overt hostility, (b) topical shift: the emergence of new discussion themes or the cessation of previously dominant topics and (c) change in toxicity: escalations or reductions in the degree of harmful language or expressions. Further since this is a sensitive task we instruct the annotators to (a) maintain confidentiality and handle the conversational data responsibly, (b) focus on objective evaluation without imposing personal biases and (c) annotate at most 15 data points per day to ensure annotation quality and mental well being of annotators. We appropriately remunerate the annotators with Amazon gift vouchers.\nOverall, the annotators marked a median of 3 change points for most of the chains with the minimum and maximum being 1 and 7 respectively. The total number of change points marked by them across all the 100 chains is 984. We believe that this is a unique and a first-of-its-kind dataset that can be used in future to train/evaluate other predictive algorithms."}, {"title": "6.3 Performance evaluation", "content": "Evaluation metrics: In order to measure the correspondence between the manually annotated change points and those generated by the CPD algorithms we use four standard metrics \u2013 Hausdorff distance, 12 rand index, precision, and recall. While calculating the metrics, if a particular change point is marked by a majority of the annotators it is considered as a valid change point. While the total number of unique points annotated by all 3 annotators is 615, after the majority voting we arrive at 257 points. The predictions of the algorithms are evaluated against these majority voted change points for evaluation.\nKey results: The main results are noted in Table 2. We find that the KERNELCPD method stands out as the best-performing algorithm across multiple metrics, particularly in terms of Hausdorff distance, rand index, and precision, where it consistently outperforms the other methods. It achieves the highest precision and a high recall value with the margin of two, making it very reliable in detecting change points with both high accuracy and minimal error. PELT performs decently in most metrics, but lags behind KERNELCPD in terms of Hausdorff distance, rand index and precision, indicating that it may miss some important change points. BOTTOMUP provides moderate performance but is generally less reliable than KERNELCPD, particularly in terms of precision. Finally, BINSEG shows poor results across all metrics, suggesting that it is the least effective algorithm for detecting change points in toxic conversation chains. We present two representative examples of the change points across two different chains in Figure 10."}, {"title": "7 Discussion", "content": "Social media has been extensively studied with respect to intervention and demarcation strategies [13, 14, 31]. Rigorous research projects have lead to the development of various strategies like counter speech [18], text detoxification [7], and meme intervention [13], among many others, including some controversial strategies [15]. Podcasts are comparatively different, since the interaction of the audience with guests/hosts is nearly negligible. Also, unlike social media content, they are generally characterized by long conversations and figuring out exact toxic segments in real time is difficult. Thus, for current scenarios, intervention is limited to only beeping or stripping away such contents which is not real time and is also often ignored by the podcast owners and streaming platforms due to the lack of automation strategies. Further, unlike the access of social media contents, podcasts can easily be made available in offline mode and can create a much bigger indirect impact. In addition, the toxic clips can be spread on social media without any further context thus spicing up the whole thing and leading to even worse polarization.\nIn this paper we introduced a dataset of transcribed political podcasts and formulated toxic conversation chains from the transcribed text. Firstly, we make the surprising observation on the high prevalence of toxicity (detected with high confidence) in podcasts which reach tens of millions of users. Next, we made various interesting observations regarding the linguistic characteristics of these chains. We noted that the anchor segment corresponding to the most toxic part of the chain has a lot of repetition, is less well-formed and has emotions and sentiments related to anger and fury. Expressions of demand in conversations can quickly lead the discourse to higher levels of toxicity. Subsequently, we manually annotate 100 toxic chains with change points for training and evaluation of automatic methods. We plan to release this dataset upon acceptance. Based on this ground-truth dataset we established that CPD algorithms can be effectively used to monitor the toxicity levels of conversation chains in real time.\nThe CPD algorithm as demonstrated here can be used to automatically monitor the toxicity levels in real time. Such real time monitoring can be very useful in controlling toxicity by making the participating hosts/guests aware of the rising toxicity in their conversation through a recommendation/alert system. Based on adherence to such recommendations, points, badges and other incentives may be awarded to the participants to promote healthy interaction and deescalate toxicity. In cases of extreme violation automatic termination of the recording of the conversation can also be implemented.\nAs future work, we plan to extend our study to incorporate audio signals as well accompanied by complete and thorough analysis over different audio features. We also plan to develop intervention strategies for this complex scenario. We also plan to expand our dataset and scalable tooling to other political podcasts to get clear estimates on the prevalence of toxicity in podcasts. Finally, an important aspect that our paper does not answer is the impact of such toxicity on the listeners. Our findings lead us to the question on whether toxicity might become normalized if coming from popular podcast hosts who reach tens of millions of people and the consequences it might have on our political discourse. Some of the tools we developed could be used by social scientists to study and answer such questions.\nEthics statement. Our dataset comprises popular podcasts curated from publicly available RSS feeds, which are widely accessible and listened to by tens of millions of people. These podcasts are analyzed using automated transcription and diarization techniques, and while individual speakers are segmented to enable conversational analysis, their identities are neither inferred nor used in the analysis to ensure privacy. We recognize the potential for biases in various stages of our pipeline, including transcription, diarization, toxicity detection, and change point detection. To mitigate these biases, we employed a rigorous evaluation process, comparing multiple algorithms at each stage and selecting the best-performing ones based on empirical results. While our analysis yielded promising findings, we emphasize the importance of conducting a comprehensive audit of the pipeline to further evaluate its reliability and fairness, particularly in production or high-stakes contexts. Our study adheres to ethical guidelines for research on publicly available data and prioritizes transparency, privacy, and the minimization of harm. We aim to contribute constructively to the discourse on toxicity in podcasts while acknowledging the limitations of our methods and the need for ongoing scrutiny and improvement."}]}