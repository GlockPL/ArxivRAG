{"title": "Neural Continuous-Time Supermartingale Certificates", "authors": ["Grigory Neustroev", "Mirco Giacobbe", "Anna Lukina"], "abstract": "We introduce for the first time a neural-certificate frame-work for continuous-time stochastic dynamical systems. Autonomous learning systems in the physical world demand continuous-time reasoning, yet existing learnable certificates for probabilistic verification assume discretization of the time continuum. Inspired by the success of training neural Lyapunov certificates for deterministic continuous-time systems and neural supermartingale certificates for stochastic discrete-time systems, we propose a framework that bridges the gap between continuous-time and probabilistic neural certification for dynamical systems under complex requirements. Our method combines machine learning and symbolic reasoning to produce formally certified bounds on the probabilities that a nonlinear system satisfies specifications of reachability, avoidance, and persistence. We present both the theoretical justification and the algorithmic implementation of our framework and showcase its efficacy on popular benchmarks.", "sections": [{"title": "Introduction", "content": "Ensuring safety is paramount to the alignment and gover-nance of autonomous learning systems. Providing verifiable guarantees of compliance with safety requirements is essential for building trust between a system, its users, and the regulators. This is especially critical when the system is deployed in the physical world, where it can cause harm. A central challenge in designing autonomous learning systems is developing control policies that ensure the desired spatial and temporal behavior. These objectives include reaching a specific target region (reachability), consistently avoiding unsafe regions (avoidance), reaching and remaining within a safe region (persistence), and combinations thereof.\nAutonomous systems often face multiple probabilistic un-certainties, leading to noisy model parameters or stochas-tic system evolution. Safe control design for the most gen-eral models-nonlinear continuous-time stochastic dynam-ical systems-provides formal guarantees for systems op-erating in uncertain physical environments. Powerful tech-niques for achieving this are based on Lyapunov functions,"}, {"title": "Problem Statement", "content": "Consider a probability space (\u03a9, F, P) with filtration F = (Ft)t\u22650. Let (R\u00b9, B(R\u00b9)) and (U, B(U)) be Polish spaces of states and actions (here B(\u00b7) denotes the Borel o-algebra, i.e., the smallest o-algebra that contains the open intervals). In other words, we assume that the states are real-valued vectors of length l < \u221e, but controls can be anything Borel-measurable.\nConsider a continuous-time dynamical system described by the following stochastic differential equation (SDE):\ndXt = f (t, Xt, u) dt + g(t, Xt, u) dWt\nwhere f : R+ \u00d7 R\u2032 \u00d7 U \u2192 R\u00b9 and g : R+ \u00d7 R\u2032 \u00d7 U \u2192 R\u00b9\u00d7 Rk are vector- and matrix-valued drift and diffusion functions, R+ \u2261 [0,\u221e); they represent the determinis-tic and stochastic parts of the dynamics. (Wt)t>o is a k-dimensional Wiener process with independent coordinates.\nWe assume that the state space R\u00b9 contains a subset X of interest that we restrict our attention to. For example, the system can be known to remain in X almost surely (a.s.), that is, with probability one."}, {"title": "A Primer on Stochastic Calculus", "content": "Under our assumptions, the problem (1) has a solution that is a so-called Feller-Dynkin process\u00b9. The dynamics of a Feller-Dynkin process can be described by a linear opera-tor G called its infinitesimal generator, which in our case admits the following form (Khasminskii 2011):\nG = \\frac{\\partial}{\\partial t} + \\sum_{i=1}^{l} f_i \\frac{\\partial}{\\partial x_i}+\\frac{1}{2}\\sum_{i=1}^{l}\\sum_{r=1}^{k} [g_r g_r^T]_{ii} \\frac{\\partial^2}{\\partial x_i^2}.\nInfinitesimal generator is the stochastic counterpart of gra-dient, describing the direction of fastest expected increase.\nNext, let us recall the definition of a natural filtration and stopping time. The natural filtration of F with respect to a stochastic process (nt)t>0 is the smallest o-algebra (Nt)t>0 on \u03a9 that contains all pre-images of B(X)-measurable sub-sets of X for times s up to t,\n\u039d\u2081\u03c2\u03c3\u03b7\u03c2\u00b9(A) | s\u2208R+\u2227 s\u2264 t > A\u2208 B(X)}.\nThe natural filtration represents the information flow gener-ated by a stochastic process: at any moment of time t, the \u03c3-algebra Nt includes all of the information generated by the process up to that point of time.\nA random variable \u03c4 : \u03a9 \u2192 R+ is called an F-stopping time if {T < t} \u2208 Ft for all t \u2208 R+. Intuitively, \u03c4 is a stopping time if it is possible to determine whether it hap-pened without looking into the future. We can \"freeze\" a stochastic process at a stopping time (hence the name). For-mally, this results in a new version of a stochastic process called a stopped process that is defined for all w\u2208 \u03a9as\nNt^r(w) = nt(w){t\u2264r(w)} + N(w) (w)I{t>r(w)}.\nThe stopped process follows the original process up to a ran-dom time \u03c4, and after that point it stays the same. Stopped processes are of special interest to us because they are used to construct supermartingales.\nAn F-adapted (i.e., such that nt is always Ft-measurable) stochastic process (nt)t>o is called an F-supermartingale if E[nt | Fs] \u2264 ns for every pair of times t > s \u2265 0."}, {"title": "Comparison to Alternative Models", "content": "Continuous-time deterministic certificates do not consider the quadratic term in (6) and therefore fail to fully capture the stochastics of a system defined by (1). For example, the solutions to x\u02d9 = x and dXt = Xtdt+Xt dWt are xt = xoet and Xt = xoet/2+Wt; the growth rates (1 and 1/2) are different. Similarly, discrete-time stochastic systems repre-sent the dynamics of a continuous-time system only approx-imately. The solutions to xt+1 - Xt = -xt + Nt where nt ~ N(0,1) (i.i.d.) and dXt = -Xtdt + dWt are xt = 2-txo + \\sum_{i=1}^{t}2^{i-t}\\tilde{n}_{i-1} = e^{-t\\ln 2}x0 + \\frac{2}{\\sqrt{3}}\\sqrt{1 - 4^{-t}}\\tilde{\\eta}_{t}, \\tilde{\\eta}_{t} ~ N(0, 1) and Xt = e^{-t/2}xo + W_{1-e^{-2t}}; again, the de-cay rates (ln 2 and 0.5) differ, leading to different dynamics. These examples show that existing certificates cannot be directly applied to the continuous-time stochastic setting. To satisfy a RAS specification, we need to find a new type of certificate and prove its validity for our problem."}, {"title": "Reach-Avoid-Stay Certificates", "content": "Definition 2. A function V (t, x) : R+ \u00d7 R\u00b9 \u2192 R is called a reach-avoid-stay certificate (RAS-C) if in the domain R++ \u00d7 X it is bounded and twice continuously differentiable with respect to x and continuously differentiable with respect to t, and, moreover, the following conditions hold, given the sets X and Xo, the families of sets X, and X*, as well as some positive constants as <BS < ORA < BRA:\n1. nonnegativity: V(t, x) \u2265 0 for all t > 0 and x \u2208 X;\n2. initial condition: V(0, xo) \u2264 ara for all xo \u2208 \u03a7\u03bf;\n3. safety condition: V(t, x) \u2265 Bra for all (t, x) \u2208 X;\n4. decrease condition: there exists ((t) satisfying\n\\lim_{t\\to\\infty} \\int_{0}^{t} \\zeta(s) ds = \\infty and \\zeta(t) > 0,\nand G\u201eV(t, x) \u2264 \u2212\u03da(t) for all (t, x) \u2208 LBRA (V)\\int Xx.\n5. goal condition: in the target set X there exists a sub-\u1e9es set, Lps(V);\n6. stay condition: there exists \u00a7(t) satisfying\n\\lim_{t\\to\\infty} \\int_{0}^{t} \\xi(s) ds = \\infty and \\xi(t) > 0,\nand GV (t, x) \u2264 \u2212(t) for all (t, x) \u2208 (XNL BRA (V))\\ int La (V).\nRemark 2. Conditions (7) and (8) are satisfied by any posi-tive constants \u03da and \u00a7. We use a more general definition, be-cause sometimes it is possible to derive better bounds based on the domain knowledge of the problem at hand.\nAt the core of the definition is the following idea: every process issuing within the sub-ara set Lara (V) is unlikely to leave the sub-Bra Set LBRA(V), and similarly for \u1e9es and as. Based on this property, we can show that the function V decreases in expectation along the sample paths of the state process until it reaches the target. If the value of V is initially at most ARA, we have not left the sub-BRA set with some high probability (to be defined later) and thus have avoided the unsafe states. Similarly, if within the target there exists a subset where the values of V are sufficiently low, and they are expected to decrease outside of this set, the process will be \"trapped\" within this smaller subset with high probability (again, to be defined later). These properties motivate the conditions of Definition 2, and are outlined in Figure 2. This intuitive explanation of reach-stay-avoid certification can be stated rigorously as the following theorem.\nTheorem 1 (RAS-C certifies an RAS specification). A pol-icy a satisfies an RAS specification (X, X, \u03a7\u03bf, \u03b5, \u03b4) if there exists a reach-avoid-stay certificate such that\n\\epsilon = 1 - \\frac{\\alpha_{RA}}{\\beta_{RA}} and \\delta = 1 - \\frac{\\alpha_s}{\\beta_s}.\nRemark 3. Note that there are two probabilities \u025b and 8 in the definition of the RAS specification, but four numbers in the definition of RAS-C. Since the probabilities of an RAS specification are defined by the ratios, we can fix either QRA or BRA beforehand, and similarly for as or \u1e9es."}, {"title": "Neural Certificate Training & Verification", "content": "Finding certificates analytically is a challenging task. Therefore, drawing on advancements in the new field of neural certificates, we employ a deep neural network to find the certificate Ve as a function of an input state x and trainable"}, {"title": "Algorithm 1: RAS Certificate Training", "content": "Data: a drift f and diffusion g of (1), a policy \u3160, an RAS specification (\u03a7, \u03a7\u03bf, \u03a7\u03bf, \u03b5, \u03b4), batch size n, regularization multiplier \u03bb, number of cells per dimension m, maximum cell splitting depth k, frequency of verification q.\nResult: satisfaction of the specification (Yes/No).\n1 Initialize the levels BRA > CRA > \u03b2\u03c2 > \u03b1\u03c2 > 0;\n2 create AABB cells C for the verifier;\n3 for N epochs do\n4  sample a batch B of n points from X;\n5  find the loss L using (10)\u2013(15);\n6  train the parameters 0 using the gradient \u2207\u03b8L;\n7  if every q steps then\n8  using IBP, compute lower Vlow (C) and upper\n9  Vup(C) bounds on V(x) for all cells C;\n10  compute \u0109 via (16) and continue if \u0109 < \u03b5;\n11  compute 8 via (17) and continue if \u2642 < \u03b4;\n12  using IBP, compute the upper bounds\n13  [GV]up (C) for cells in C2 defined by (18);\n14  set the verification depth d \u2190 0;\n15  find unverified cells\n16  U\u2190 {C | [GV]up (C) \u2265 0};\n17  while |U| > 0 and d < k do\n18  split each cell in U into 2\u00aa smaller cells;\n19  increase the depth d \u2190 d + 1;\n20  compute the upper bounds [GV]up (C');\n21  remove cells where the bound is negative;\n22  if \u0109 > \u025b and \u03b4 > 8 and |U| = 0 then\n23  return Yes;\n24 return No.\nnetwork parameters 0. Our method is summarized in Algo-rithm 1 and Figure 3, and explained in this section.\nWhile the theoretical contributions separate the time t \u2208 R+ and the state x \u2208 X variables due to different require-ments on differentiability of the certificate with respect to them. When this distinction is of no concern, we can em-bed the time variable t into the space vector (for example, as x = (e-t,x1, ..., x\u2081) to map it into a compact interval). Moreover, if the system is time-homogeneous, we can drop the dependence of the certificate on time entirely. Techni-cally, this makes the initial condition of Definition 2 more restrictive, as it will require that V(0,x) \u2264 ORA for all (t,x) \u2208 R+ \u00d7 X0 instead of just for t = 0, but the re-sulting dimensionality reduction simplifies the verification process. For these reasons, we opt to make the presentation more succinct by dropping the time variable from now on."}, {"title": "Training", "content": "This approach raises a few issues to be addressed.\nFirst, we need to set the threshold levels. We elect:\n\\alpha_{RA} = \\frac{\\kappa}{\\kappa - 1}, \\beta_{RA} = \\frac{\\alpha_{RA}}{1 - \\epsilon}, \\beta_s = 0.9, \\alpha_s = \\frac{\\beta_s (1 - \\delta)}{\\kappa}"}, {"title": "Verification", "content": "To verify that all of the properties of Definition 2 hold, we employ interval bound propagation (IBP) (Xu et al. 2020). IBP, as well as other abstract interpretation methods (Gehr et al. 2018; Kouvaros and Lomuscio 2021; Zhang et al. 2018), have proven effective in verifying correctness of neu-ral networks' output. To this end, we construct bounded cer-tificate and generator networks that take intervals rather than point values as their inputs. By propagating the input inter-vals through these networks, we obtain upper and/or lower bounds on the certificate and its generator.\nTo construct the interval inputs for IBP, we divide the set X into cells C which are axis-aligned bounding boxes (AABBs) covering the whole space X, that is, X \u2286 UCEC C. We do this by discretizing each dimension [xmin, xmax], i = 1,..., l of the state space X into collections Xi of m equal intervals, X\u2081 \u2261 {[xmin, xmin + Ai], ..., [xmax \u2212 Ai, xmax]}, Ai = (xmax-xmin)/l, and using all of the possible Cartesian products thereof as m\u00b9 cells, C \u2261 X\u2081 \u00d7\u2025\u2025\u2025 \u00d7 X\u2081.\nFor each cell, we compute the lower Vlow (C) and upper Vup(C) bounds on V(x) within that cell, x \u2208 C. Given the bounds, we find the empirical reach-avoid probability \u00ea\n\\hat{\\epsilon} \\triangleq (1-\\frac{V^{max}_{C:C\\cap \\mathcal{X}_0\\neq \\emptyset}(C)}{\\beta_{RA}})^+, where\n\\alpha_{RA} = \\frac{\\alpha_s - min_{C:C\\cap \\mathcal{X}_0\\neq \\emptyset}}{V^{min}_{C:C\\cap \\mathcal{X}_0\\neq \\emptyset}(C)}.\nThis verifies that the initial set values are at most ARA, and the unsafe set values are at least BRA. Therefore, if the de-crease condition is satisfied, the reach-avoid event (3) occurs with probability at least \u00ea.\nSimilarly, for the goal condition, we compute a provable stay probability \u2642 as\n\\hat{\\delta} \\triangleq (1 - \\frac{\\hat{\\alpha}_s}{\\beta_s})^+, where\n\\hat{\\alpha}_s \\triangleq min{\\frac{\\alpha_s}{V_{up}(C)}, min_{C:C\\cap \\mathcal{X}_0\\neq \\emptyset}{V_{low}(C)}.}\nThis guarantees that at least in one of the cells within the tar-get the certificate values go below \u00e2s, and on the boundary the values are at least \u1e9es.\nFinally, we verify the decrease condition by computing upper bounds on the generator values [G\u201eV]up(C) in the set\nC2 = {C | Vlow (C) > \\hat{\\alpha}_s > V_{up}(C) \\leq \\beta_{RA}}.\nWe then check if any of the cells have non-negative upper bounds. If they do (and we observed this happening often, as the generator bounds involve quadratic terms and as a result they are much looser than the value bounds) the de-crease condition in those cells cannot be verified. We split such cells in two along each of the dimensions. We then re-compute the cell bounds for each of the 2 sub-cells. We repeat this until either no counterexample is found, meaning that the decrease condition is verified (as it holds over a col-lection of cells fully covering the desired subspace), or the maximum iteration depth is achieved.\nFinally, if the estimated probabilities \u00ea and \u2642 exceed the specified ones \u025b and \u03b4, and no cells with Gup (C) \u2265 0 are found, we obtained a provably correct RAS-C."}, {"title": "Experiments", "content": "To illustrate the practical efficacy of our framework, we syn-thesize neural certificates for two continuous-time control benchmarks. To the extent of our knowledge, this is the first work on formal verification of neural certificates for continuous-time stochastic control using neural networks. Thus, we do not include comparisons to any other methods.\nThe computing infrastructure and values of the hyperpa-rameters for all of the experiments and the neural network architectures are given in the technical appendix.\nWe employ auto_LiRPA (Xu et al. 2020) for IBP, which is a library for automatic bound computation with linear relaxation based perturbation analysis. We integrate (1) numerically with stochastic Runge-Kutta method using torchsde (Li et al. 2020). Note that this approximation scheme is not employed in Algorithm 1, but only to simu-late the sample paths shown in the figures.\nWe successfully train RAS certificates for two controlled SDEs. The times and numbers of verification phases re-quired for training are summarized in Table 1. More details on each of the problems are given in the technical appendix."}, {"title": "Stochastic Inverted Pendulum", "content": "Inverted pendulum (Chang, Roohi, and Gao 2019; Wu et al. 2023) is a classical nonlinear control problem. We disturb the angle by a Wiener process with scale \u03c3, resulting in the following SDEs:\n\\frac{mL^2}{I}\\ddot{\\theta} dt = (sin \\theta_t + M\\pi(\\theta_t)) dt + \\sigma dW_t, \\dot{\\theta}_t = \\varphi_t dt,\nwhere is the angular velocity. The drift and diffusion are\nf_{\\pi}(\\varphi, \\theta) = \\frac{I}{mL^2}sin \\theta + \\frac{M}{mL^2}\\pi(\\varphi, \\theta),\ng_{\\pi}(\\varphi, \\theta) = \\frac{\\sigma}{mL^2}.\nThe policy \u03c0(\u03c6, \u03b8) is represented by a neural network. An example of a trained certificate is presented in Figure 1."}, {"title": "Bivariate Geometric Brownian Motion", "content": "Geometric Brownian motion (GBM) is one of the most stud-ied stochastic processes and is frequently utilized in finan-cial mathematics. We consider the following controlled ver-sion of bivariate GBM:\ndXt = (\\mu Xt \u2013 ut(Xt)) dt + \\sigma(Xt) dWt, where\n\\mu = \\begin{bmatrix} -0.5\\\\ -0.5 \\end{bmatrix} and \\sigma = 0.2 \\text{diag}(X_t)."}, {"title": "Related Work", "content": "The concept of representing Lyapunov functions as neural networks was theoretically discussed in seminal work (Long and Bayoumi 1993; Prokhorov 1994). This idea led to the development of numerical machine learning algorithms for neural Lyapunov functions (Serpen 2005; Petridis and Petridis 2006; Noroozi et al. 2008). Building on this, learn-ing algorithms have been extended to encompass barrier functions for avoidance control (Richards, Berkenkamp, and Krause 2018; Dawson et al. 2021), contraction metrics (Sun, Jha, and Fan 2020), and the compositional certification of multi-agent systems (Qin et al. 2021; Zhang et al. 2023b), and the simultaneous training of control policies and neural certificates (Kolter and Manek 2019; Wu et al. 2023), al-beit initially without formal soundness guarantees. Our re-sult provides formal soundness guarantees, drawing upon and extending the following related work.\nNeural Continuous-Time Lyapunov Certificates. Cou-pling machine learning with symbolic reasoning techniques like satisfiability modulo theory (SMT) solving and bound propagation made a significant step forward for neural cer-tification with formal guarantees (Chang, Roohi, and Gao 2019; Abate et al. 2021). Initially focused on Lagrangian and asymptotic stability, neural certificates with provable guarantees for continuous-time deterministic systems have since been extended to cover avoidance, reachability, in-variance, persistence, and combinations of these proper-ties (Zhao et al. 2020; Takeishi and Kawahara 2021; Zhang et al. 2023a; Edwards, Peruffo, and Abate 2023).\nNeural Discrete-Time Lyapunov Certificates. Advances in neural certificates for differential equations have inspired"}, {"title": "Neural Discrete-Time Supermartingale Certificates", "content": "Neural Discrete-Time Supermartingale Certificates. In the presence of stochastic uncertainty, traditional Lyapunov-like certificates are overly conservative and unrealistic; re-lying on worst-case reasoning, they do not quantify the probability of events to occur. Probabilistic neural certifi-cates, which build on supermartingale-like conditions, were initially developed for almost-sure termination and, anal-ogously, discrete-time reachability (Abate, Giacobbe, and Roy 2021; Ansaripour et al. 2023). These neural super-martingale certificates were later generalized to quanti-tative reachability, avoidance and reach-avoidance (Math-iesen, Calvert, and Laurenti 2023; \u017dikeli\u0107 et al. 2023a; Chat-terjee et al. 2023; Badings et al. 2024). Further advance-ments have studied the optimization of probability bounds and compositional certification (Abate et al. 2023; \u017dikeli\u0107 et al. 2023b).\nNeural Continuous-Time Supermartingale Certificates. Neural supermartingale-based techniques have been studied primarily in the context of discrete-time systems. Their ex-tension to continuous-time systems has been solely explored in the context of stability control, and even then, without provable guarantees (Zhang, Zhu, and Lin 2022)."}, {"title": "Conclusion & Future Work", "content": "We have introduced the first neural supermartingale for continuous-time reasoning with provable guarantees, appli-cable to combinations of reachability, avoidance, and per-sistence properties. We have formulated a proof rule (Theo-rem 1) for a supermartingale certificate for continuous-time systems and, by integrating machine learning with symbolic reasoning, we have fully automated their construction. We have built a prototype and demonstrated that our method is practically effective on continuous-time systems with neural policies, extending the state of the art in algorithmic verifi-cation for provably safe stochastic nonlinear control.\nOur framework is open to extension towards the auto-mated synthesis of neural controllers alongside their cer-tificates, without the need to pre-initialize a control policy or guide it with other methods. We foresee integration with advanced symbolic reasoning techniques based on adaptive discretization (\u017dikeli\u0107 et al. 2023a; Badings et al. 2024), adversarial attack algorithms (Yang et al. 2024; Wu et al. 2023), and generalization to more expressive temporal logic requirements (Abate, Giacobbe, and Roy 2024; Nadali et al. 2024; Giacobbe et al. 2024)."}, {"title": "Technical Appendix", "content": "This appendix contains a simple example of the problem at hand, the proofs of the lemmas presented in the paper, and implementation details for the experimental section."}, {"title": "An Illustrative Example", "content": "Consider the following stochastic differential equation:\ndXt = aXt dt + \u03c0(Xt) dWt.\nWhen u = 0 there is no stochasticity to the problem, and the resulting deterministic system is unstable for any starting point 20, since the analytical solution x(t) = xoeat to i = ax with the initial condition x(0) = xo tends to infinity.\nNow consider the following control policy:\n\u03c0\u03c3(x) = \u03c3\u03c7.\nIn other words, the controller adds a white noise propor-tional to the state. The resulting system's dynamics are\ndXt = aXt dt + oXt dWt\nwhich is a geometric Brownian motion with drift a and volatility \u03c3. It is a well-studied stochastic process and the solution for the initial condition Xo = xo is\nXt = xoe^{(a-\\frac{\\sigma^2}{2})t+\\sigma W_t}.\nIf \u03c3 > \u221a2a, surprisingly (and even somewhat counterintu-itively), the system becomes stabilized by pure noise injec-tion. This highlights the fundamentally different nature of continuous-time stochastic problems compared to their de-terministic counterparts. This phenomenon is illustrated by Figure 5."}, {"title": "Analytical Derivatives of a Neural Network", "content": "We computer \\frac{\\partial V}{\\partial x} and \\frac{\\partial^2 V}{\\partial x^2} using the following statement.\nProposition 1 (Singla and Feizi (2020), Lemma 1). Con-sider an N-layer neural network defined recursively for i = 0, 1, ..., N \u2013 1 as\na(-1) = x, z(i) = W(i)a(i-1) + b(i), a(i) = oi(z(i)).\nThe j-th row of the Hessian of its output z(N-1) with respect to the input x can be computed via\nH_{x_z^{(N-1)}} = \\sum_{i=0}^{N-2}(B^{(i)})^T diag(F^{(N-1,2)}((\\alpha^{(i)})))B^{(i)};\nB(i) = \\begin{cases} \\begin{bmatrix} W^{(0)}\\\\ \\end{bmatrix}, i = 0, \\\\ \\begin{bmatrix} W^{(i)} diag (\\sigma_{i-1}'(z^{(i-1)})))B^{(i-1)}, i\\geq 1;\\end{cases}\nF(k,i) = \\begin{cases} W^{(k)}, i = k \\\\ W^{(k)} diag(\\sigma_{k-1}'(z^{(k-1)}))\\\\ \\end{cases} F^{(k-1,i)}, i=k-1\\\\  i<k-2\nand its Jacobian is equal to B(N-1).\nRemark 4. Our neural network architecture is slightly dif-ferent, with the final output a(N) = \u03c3\u03b7(z(N)) instead of z(N). We obtain the formulae for our case by extending the network of Proposition 1 with a final linear layer with W(N+1) = [1] an b(N+1) = 0 in the calculations.\nGiven this proposition, we find the first derivative vector as the transpose of the Jacobian, and the second derivative vector as the diagonal of the Hessian."}, {"title": "Proof of Theorem 1", "content": "First, we need to ensure that & is indeed a stopping time.\nLemma 2. Let N = (Nt)t>o be the natural filtration with respect to a state process (X0,0)t>o issuing in some state xo \u2208 Xo. Consider a continuous function V(t,x) : R+ \u00d7 X \u2192 R. For any constants as, BRA \u2208 R such that \u1e9e < p, the random variable & given by (9) is an N-stopping time. Moreover, if the decrease and stay conditions of Definition 2 hold, then < \u221e (a.s.).\nIn proving Lemma 2, we will employ the following result.\nProposition 2 (recurency citerion, cf. Khasminskii (2011), Theorem 3.9). A Feller-Dynkin process (Nt)t>0 with in-finitesimal generator G leaves a domain U in finite time (a.s.)"}, {"title": "Hyperparameter Values", "content": "For the inverted pendulum, we use a policy pre-trained with torchRL for the deterministic version of the problem. The script used for training and the saved policy are both in-cluded in the code appendix. The policy network consists of two linear layers with hyperbolic tangent activations, fol-lowed by a final linear layer. The hidden layers consist of 64 neurons.\nFor the certificate network, the architecture is the same, but with the addition of a softplus activation at the end to make the values nonnegative. The hidden layers contain 32 neurons.\nThe values of the remaining hyperparameters are summa-rized in Table 2 and can be found in the code appendix."}]}