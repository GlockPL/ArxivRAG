{"title": "They Look Like Each Other: Case-based Reasoning for Explainable\nDepression Detection on Twitter using Large Language Models", "authors": ["Mohammad Saeid Mahdavinejad", "Amirhassan Monadjemi", "Peyman Adibi", "Pascal Hitzler"], "abstract": "Depression is a common mental health issue\nthat requires prompt diagnosis and treatment.\nDespite the promise of social media data for\ndepression detection, the opacity of employed\ndeep learning models hinders interpretability\nand raises bias concerns. We address this chal-\nlenge by introducing ProtoDep, a novel, ex-\nplainable framework for Twitter-based depres-\nsion detection. ProtoDep leverages prototype\nlearning and the generative power of Large Lan-\nguage Models to provide transparent explana-\ntions at three levels: (i) symptom-level expla-\nnations for each tweet and user, (ii) case-based\nexplanations comparing the user to similar indi-\nviduals, and (iii) transparent decision-making\nthrough classification weights. Evaluated on\nfive benchmark datasets, ProtoDep achieves\nnear state-of-the-art performance while learn-\ning meaningful prototypes. This multi-faceted\napproach offers significant potential to enhance\nthe reliability and transparency of depression\ndetection on social media, ultimately aiding\nmental health professionals in delivering more\ninformed care.", "sections": [{"title": "1 Introduction", "content": "Depression is a common mental health disorder\nthat affects a significant number of people world-\nwide. According to the National Institute of Mental\nHealth, roughly 22.8% of adults in the U.S. experi-\nence a diagnosable mental illness annually (of Men-\ntal Health, 2023). Timely diagnosis and interven-\ntion are crucial, as untreated or inadequately man-\naged depression can lead to severe consequences,\nincluding suicide and chronic, risky behaviors like\nsubstance abuse (Goodwin et al., 2022).\nTraditional methods for depression detection,\nheavily reliant on self-reported information through\nonline questionnaires, are often hampered by low\nparticipation rates and potential selection bias.\nThis has spurred the exploration of alternative ap-\nproaches, with social media platforms emerging as\na promising avenue (Chancellor and De Choudhury,\n2020; Culotta, 2014; De Choudhury and De, 2014;\nGuntuku et al., 2017; Paul and Dredze, 2011).\nWhile deep learning models exhibit significant\npotential in detecting depression on social media,\ntheir inherent \"black box\" nature presents a sig-\nnificant challenge (Ji et al., 2021; Nguyen et al.,\n2022). This opacity hinders practitioners' ability to\nassess the validity of model predictions and raises\nconcerns about potential biases or errors within the\nmodels themselves.\nRecent efforts toward more explainable models\nfor mental health assessment have primarily fo-\ncused on two key approaches: post-hoc methods\nand interpretable models. Post-hoc methods aim\nto explain the predictions of pre-trained models\nretrospectively. However, they rely on approxima-\ntions of a model's internal decision-making process,\nfailing to explain why specific input features are\ncrucial (Nguyen et al., 2021).\nIn contrast, interpretable models are inherently\ndesigned to be transparent by restricting their com-\nplexity. However, current state-of-the-art models\nprimarily rely on attention weights for explanation\n(Han et al., 2022). The validity of these weights as\nreliable explanations remains under debate (Bibal\net al., 2022). Furthermore, these explanations of-\nten focus on low-level input features, like individ-\nual posts or tweets, which may not align with the\nhigher-level concepts, such as symptoms, used by\nprofessionals.\nThis paper introduces ProtoDep, a novel explain-\nable framework for depression detection on Twit-\nter. It leverages prototype learning, utilizing repre-\nsentative data points (prototypes) to classify new\ninstances. This framework facilitates the identifi-\ncation of key factors contributing to users' depres-\nsive behavior on social media through three dis-\ntinct levels of explanations. Firstly, by harnessing\nthe generative power of Large Language Models\n(LLMs), ProtoDep generates symptom-level expla-"}, {"title": "2 Related Work", "content": "The rise of social media has created exciting oppor-\ntunities for mental health research. Its real-time na-\nture and extensive archives offer unique advantages\nover traditional, retrospective studies. Researchers\ncan track and potentially predict risk factors over\ntime, enabling timely interventions for vulnerable\ncommunities (Kruzan et al., 2022; Livingston et al.,\n2014; Ridout and Campbell, 2018).\nThis potential has driven exploration into using\nsocial media data to identify and predict mental\nhealth challenges like anxiety (Ahmed et al., 2022;\nSaifullah et al., 2021; Shen and Rudzicz, 2017) and\ndepression (De Choudhury et al., 2013a,b; Park\net al., 2013; Tsugawa et al., 2015; Xu et al., 2021).\nInitial research employed basic methods for ana-\nlyzing social media data to glean mental health\ninsights (Coppersmith et al., 2014; De Choud-\nhury et al., 2013a; Coppersmith et al., 2014).\nSubsequently, the focus shifted towards develop-\ning feature engineering techniques and machine\nlearning models for prediction (Birnbaum et al.,\n2017; Moreno et al., 2011; Nguyen et al., 2014;\nRumshisky et al., 2016; Tsugawa et al., 2015). For\ninstance, (De Choudhury et al., 2013b) extracted\nlinguistic features to build an SVM model for de-\npression prediction.\nThe advent of deep learning further revolution-\nized the field, eliminating the need for hand-crafted\nfeatures (Ji et al., 2018; Sawhney et al., 2018).\n(Tadesse et al., 2019) leveraged an LSTM-CNN\nmodel with word embeddings to identify suicide\nideation on Reddit, showcasing the power of deep\nlearning approaches.\nPre-trained language models (PLMs) have\ngained significant traction in natural language pro-\ncessing (NLP) tasks, including mental health pre-\ndiction (Han et al., 2022; Ji et al., 2021; Nguyen\net al., 2022). (Jiang et al., 2020) utilized BERT's\ncontextual representations for mental health issue\ndetection, while (Otsuka et al., 2023) evaluated\nBERT-based models in clinical settings. Addition-\nally, multi-task learning approaches have been ex-\nplored to predict multiple mental health conditions\nsimultaneously (Benton et al., 2017). (Sarkar et al.,\n2022) trained a multi-task model for predicting\nboth depression and anxiety, demonstrating the po-\ntential for joint prediction. However, these multi-\ntask models often lack the flexibility to adapt to\nnew tasks.\nDespite these advancements, explainability re-\nmains a critical challenge in computational mental\nhealth prediction. While feature importance meth-\nods like SHAP (Shapley et al., 1953; Datta et al.,\n2016; Lundberg and Lee, 2017) and LIME (Ribeiro\net al., 2016) provide insights into feature contri-\nbutions, they lack explanations for why specific\nfeatures are crucial. Recent studies suggest that\nexample-based explanations, often utilizing Case-\nBased Reasoning (CBR) techniques, resonate more\nwith human users (Nguyen et al., 2021). However,\nthis approach is limited by the underlying model\narchitecture.\nBuilding upon these developments, our work in-\ntroduces a novel framework to depression detection\non Twitter using prototype learning. Our key focus\nis to provide interpretable explanations at multiple\nlevels, addressing the critical gap in explainability\nfor mental health prediction on social media."}, {"title": "3 Method", "content": "This section presents ProtoDep, a novel framework\nfor transparent reasoning about mental health in so-\ncial media. ProtoDep uses prototypes to represent\nsymptoms and users, enabling more interpretable\nexplanations. Given a labeled user with its tweets,\nProtoDep performs classification in five steps illus-\ntrated in Figure 1. Step 1: Embedding user tweets.\nStep 2: Learning symptom prototypes. Step 3: En-\ncoding the user. Step 4: Learning user prototypes.\nStep 5: Performing classification.\n3.1 Preliminaries\nOur objective is to determine if a specific user u\nis depressed. Each user has a collection of tweets\nT where T = {t1, t2, ..., tn} and n is number of\ntweets. Once the model is trained, the aim is to\npredict a binary label \u0177 for the user u, where \u0177 \u2208\n{0, 1}. If y = 1, the user is identified as depressed.\nSubsequently, \u0177 is matched against y, which is the\nground truth.\n3.2 Step 1: Embedding User's Tweets\nGiven a set of tweets T for a user u, first, we obtain\nan embedding of T using a pre-trained sentence\nencoder. E will be an embedding matrix of T.\nFormally,\n\\(E = TweetEncoder(T)\\) (1)\n3.3 Step 2: Learning Symptom Prototypes\nThis step focuses on training symptom prototypes\nthat faithfully capture the essence of each depres-\nsion symptom while maintaining close alignment\nwith actual tweets from the dataset. In simpler\nterms, we aim to develop representations of symp-\ntoms that are both accurate and grounded in the\nlanguage used by individuals describing their ex-\nperiences. However, due to the absence of infor-\nmation about individual user symptoms or specific\ntweets (limited to user-level labels), we propose\na supervised initialization strategy for prototypes,\ncoupled with a specific loss function, to achieve this\nobjective. This step encompasses two sub-steps:\nA. Symptom Space Creation and B. Symptom\nSpace Optimization. Figure 2 (a) illustrates a\ngeneral schema for this layer.\nA. Symptom Space Creation: The first step\nin creating an embedding space for symptom pro-\ntotypes is identifying the underlying concepts or\nsymptoms within the space. We use the Patient\nHealth Questionnaire - 9 (PHQ-91), one of the most\nwidely used questionnaires to assess depression\n(Kroenke et al., 2010), as a reference for defining\nthe concepts. The PHQ-9 is a self-administered\nquestionnaire that measures the presence and sever-\nity of nine depressive symptoms over two weeks.\nIt has been validated by multiple studies and is\nregarded as a reliable and accurate measure of de-\npression (Levis et al., 2019). The nine symptoms\nare Depressed Mood (S1), Loss of Interest or Plea-\nsure (S2), Sleep Disturbance (S3), Fatigue or Low\nEnergy (S4), Changes in Appetite (S5), Feelings\nof Guilt or Worthlessness (S6), Difficulty Concen-\ntrating (S7), Psychomotor Agitation or Retardation\n(S8), and Suicidal Thoughts (S9). We consider\nthese symptoms as the base concepts in our embed-\nding space to simulate human reasoning processes\nand enhance ProtoDep interpretability.\nThe second step is to initialize a set of prototypes\nfor each concept. Manually creating exemplary sets\nfor each prototype proves resource-intensive and\nneeds iterative refinement. To address this chal-\nlenge, we leverage the generative capabilities of\nLLMs. Specifically, we employ GPT-4 to automat-\nically generate relevant examples, focusing on dif-\nferent aspects of a given symptom. These examples\nserve as our initial set of prototypes for subsequent\ntraining. We note that the number of prototypes is\nan important hyperparameter, and generating dif-\nferent numbers of examples from GPT-4 for each\nexperiment is inconsistent and impractical. There-\nfore, we generate a maximum number of examples\nonce and use the mean of the embedded examples\nas a base prototype for each symptom. Then, for\neach experiment, we sample around each base pro-\ntotype with a normal distribution. We define Pbase\nas the base prototype and \\(P^{j}\\) to be set of m proto-\ntypes for the symptom j by:\n\\(P^{j} \\sim N(P^{base}, \\sigma^{2})\\). (2)\nwhere \u03c3\u00b2 is variance. Therefore, P will be set for\nall symptom prototypes.\nB. Symptom Space Optimization: Given the\nlack of tweet-level labels, we propose a novel ap-\nproach that leverages supervised-initialized proto-\ntypes. Specifically, we formulate the optimization\nprocess as a multi-label classification task, where\neach tweet is labeled with the nearest symptom\nwithin the embedding space. By adopting this strat-\negy, we effectively use prior knowledge from the"}, {"title": "3.4 Step 3: Encoding the User", "content": "Following the approach of (Han et al., 2022), we\nuse a multi-layer attention mechanism and a feed-\nforward neural network to encode the sequential"}, {"title": "3.5 Step 4: Learning User Prototypes", "content": "This step provides transparent, case-based reason-\ning to evaluate the user's depressive behavior. It\nfollows the same principle as the learning symp-\ntom prototype step and consists of two sub-steps:\nA. User Space Creation and B. User Space Opti-\nmization. Figure 2 (b) illustrates this step.\nA. User Space Creation: Social media datasets\nfor depression detection often exhibit an imbalance\nbetween the number of users or tweets in each class.\nThis may negatively impact the reasoning of deep\nlearning models as they may prioritize the majority\nclass during training. Inspired by (Das et al., 2022),\nwe encourage the model to find the best examples\nfor both classes to find a more effective decision\nboundary between them. Unlike the symptom pro-\ntotype space, which relies on predefined prototypes,\nthe user prototype space allows the model to learn\nthe prototypes from the data. Consequently, we\nrandomly initialize k different vectors per class as\ninitial prototypes.\nB. User Space Optimization: In this step, we\nadopt the same optimization strategy as in step 2,\nbut with a crucial difference. We leverage the user-\nlevel labels to learn the prototypes in a supervised\nfashion-this way, we do not require the computa-\ntion of si. We denote the total loss for this step as\nLuser."}, {"title": "3.6 Step 5: Classification", "content": "The final step of our model is to classify the users\nbased on their similarity to symptoms and user\nprototypes. First, we calculate the average of all\ntweet-symptom similarities, providing an overall\nmeasure of the similarity between a user's tweets\nand the symptom prototypes. Then, we concatenate\nthese scores with the user prototype similarities and\nfeed this into a linear layer followed by a Softmax\nfunction to obtain the final classification. We use\nbinary cross-entropy (BCE) loss for this step, and\nthe total loss function for our model will be:\n\\(L = L_{symp} + L_{user} + L_{BCE}\\) (13)"}, {"title": "4 Experiment Results", "content": "Dataset. We employ an openly available Twitter\ndataset, MDL, specifically designed for depression\ndetection. For comparison purposes, we use the\nspecific version of the MDL dataset provided by\n(Han et al., 2022). In this dataset, individuals who\nposted tweets containing predefined phrases indica-\ntive of depression, such as \"I'm,\" \"I was,\" \"I am,\"\nor \"I've been diagnosed with depression,\" were la-\nbeled as depressive. Conversely, those who never\nposted any tweet containing the term \"depress\"\nwere labeled as non-depressive. (Han et al., 2022)\nemployed a random selection of users to create five\ndistinct datasets. The train, validation, and test sets\nutilize 60%, 20%, and 20% of the entire dataset.\nThis resulted in 2,524 users in the train set and 842\nusers in each validation and test set. More details\nregarding the dataset can be found in (Han et al.,\n2022).\nBaselines. To evaluate the ProtoDep framework,\nwe compare its performance to four established de-\npression detection baselines. Given its similarity in\napproach, we consider (Han et al., 2022) the most\nrelevant and significant baseline for our model. Ad-\nditionally, we compare our results to (Gui et al.,\n2019; Lin et al., 2020; Zhang et al., 2021b), as\nthese studies appeared to be most pertinent to our\nwork.\nSetup. We trained all models using a GeForce\nRTX 3090 with 64GB of RAM and Pytorch 2.0.1.\nWe tuned the hyperparameters on the validation\ndata and optimized all neural models with the\nAdamW algorithm. The learning rate and the batch\nsize were le-3 and 64, respectively. We applied\nearly stopping based on the F1 score on the vali-\ndation data. The maximum number of tweets per\ninput was 200. For symptom and user prototypes,\nwe set the number of prototypes per class to m = 7\nand k = 3, respectively. We sampled normally\naround the base prototypes with \u03c3 = 0.025. We\nalso used two-layer attention for Step 3. We chose\n\"all-mpnet-base-v2\" (Reimers and Gurevych, 2019)\nas our Tweet Encoder Model. We discuss more on\nthese in section 5.\nResult (1): Classification Performance. We\nassess ProtoDep using five benchmark datasets\nand compare it against state-of-the-art methods, as\ndemonstrated in Table 1. ProtoDep achieves a com-\npetitive 94.4% average F1 score, providing more\nintuitive and interpretable prototypes for classifi-\ncation decisions and maintaining consistent perfor-\nmance across different randomly sampled datasets\n(D1-D5). We also explore another variant of Pro-\ntoDep, ProtoDep-Acc, to demonstrate its power\nto achieve state-of-the-art performance. ProtoDep-\nAcc leverages a different loss function for learning\nprototypes. We discuss more about ProtoDep-Acc\nin section 5.\nResult (2): Explainable Prototypes. We evalu-\nate the quality of ProtoDep's learned prototypes us-\ning two distinct methods. First, we compare these\nprototypes with manually labeled ground truth pro-\ntotypes created by domain experts. To achieve this,\nwe leverage a specialized dictionary developed by\n(Yazdavar et al., 2017). This lexicon contains an\nextensive collection of depression-related terms\nspecifically associated with the nine symptom cate-\ngories of the PHQ-9. These terms have undergone\nmeticulous curation to capture the subtle nuances\ninherent in depression symptoms.\nBy aligning our learned prototypes with this es-\ntablished lexicon, we can assess their relevance and\nmeaningfulness within the context of depression.\nTo quantify this alignment, we compute the mean\nrepresentation for each symptom prototype and\nsubsequently measure its cosine similarity with the"}, {"title": "Result (3): Transparent Reasoning", "content": "Beyond\naccurate depression detection, ProtoDep offers\nvaluable insights into its decision-making process\nthrough several avenues. Examining the weights as-\nsigned to various symptoms within its final layer un-\nveils their relative importance in user classification.\nAs illustrated in Figure 5, ProtoDep across diverse\ndatasets prioritizes symptoms like \"Fatigue or low\nenergy\" and \"Lack of Interest,\" mirroring human\nexpert judgment reported in (Yazdavar et al., 2017).\nInterestingly, it assigns less weight to \"Sleep Dis-\norder\" and \"Concentration problems,\" potentially\ndue to the ambiguity of these symptoms in textual\ndata. For example, the tweet \"lost in my own mind\"\nmight not explicitly mention keywords indicating\n\"Concentration problems,\" making accurate clas-\nsification challenging. This finding highlights the\ninherent difficulty in capturing nuanced depressive\nsymptoms, even for human experts.\nFurthermore, ProtoDep's user embedding layer\nwith stacked attention layers holds promise for in-\nterpreting user classifications, similar to Han et al.\n(2022). We analyzed attention scores to identify\ntweets that significantly influence user classifica-\ntion. However, echoing prior research (Bibal et al.,\n2022; Wen et al., 2022; Pruthi et al., 2020), our\nextensive evaluation across both methods revealed\nno statistically significant association between at-\ntended tweets and those crucial for accurate classi-\nfication. This suggests that while attention weights\noffer glimpses into model behavior, they might not\ndirectly explain specific classification outcomes in\nthis context."}, {"title": "5 Ablation Study", "content": "We consider four different settings to validate the\nimpact of different hyperparameters.\nSymptom Prototype Initialization. In this\nstudy, we explore alternative methods for initializ-\ning symptom prototypes. We compare two novel\ninitialization approaches with the baseline method\nthat utilizes a pre-trained language model (LLM)\nfor symptom initialization. In the first setting, we\nleverage the ground truth lexicon as the founda-\ntion for symptom prototypes. We extract ground\ntruth embeddings from this lexicon and then sample\nadditional prototypes around them for each symp-\ntom class. A well-constructed lexicon captures\ndomain-specific nuances and expert knowledge,\nwhich can enhance the quality of symptom proto-\ntypes. In the second setting, we depart from direct\nlexicon embeddings. Instead, we identify the near-\nest tweet in our dataset to each lexicon symptom\nand use its embedding as the basis for symptom\nprototypes. We then continue sampling around\nthese tweet-grounded prototypes. By anchoring the\ninitial prototypes to actual tweets, we aim to im-\nprove their relevance and alignment with real-world\nsymptom expressions. Our experimental results in\nTable 2 demonstrate that both the lexicon-based and\ntweet-grounded initialization outperform the LLM\nbaseline. Notably, the curated lexicon's consider-\nation of various combinations of the depression-\nindicative keywords contributes to its effectiveness.\nHowever, the marginal performance difference be-\ntween these two settings and the baseline suggests\nthat LLMs can achieve competitive results even\nin scenarios lacking human annotation or domain-\nspecific knowledge.\nPrototype Loss Function. To assess the influ-\nence of different loss functions within the ProtoDep\nframework, we implemented two evaluation set-"}, {"title": "6 Conclusion", "content": "In this paper, we proposed ProtoDep, a novel frame-\nwork that combines prototype learning and Large\nLanguage Models (LLMs) to provide explainable\ndepression detection on Twitter. Unlike conven-\ntional \"black-box\" models, ProtoDep can generate\ntransparent and interpretable explanations at three\nlevels: symptom-level, case-based, and transparent\ndecision-making weights. We evaluated ProtoDep\non five benchmark datasets and showed it achieves\ncompetitive performance while learning meaning-\nful and representative prototypes. We argue that\nProtoDep has the potential to improve the trustwor-\nthiness and accountability of depression detection\non social media, as well as to facilitate the under-\nstanding and intervention of mental health profes-\nsionals. As a future work, we plan to investigate the\napplicability of ProtoDep to other social media plat-\nforms and mental health domains and enhance the\nexplanation generation process with more clinical\nand contextual information. To sum up, ProtoDep\nis a novel and promising framework for explain-\nable depression detection on social media, which\ncan contribute to the well-being of individuals and\nsociety."}, {"title": "7 Ethical Consideration", "content": "We used a publicly available dataset introduced by\nHan et al. (2022). Our investigation focuses ex-"}, {"title": "8 Limitations", "content": "While ProtoDep offers a promising approach to\nexplainable depression detection on Twitter, it is\nessential to acknowledge potential limitations asso-\nciated with this framework:\nData Representativeness: The performance\nand generalizability of ProtoDep heavily rely on the\nquality and representativeness of the training data.\nBiases or limitations within the training data can\nbe reflected in the learned prototypes, potentially\nleading to biased predictions for demographics or\ngroups underrepresented in the data.\nTweet Encoder Model: The effectiveness of the\nlearned prototypes largely relies on the selection\nof the tweet encoder model. If the encoder model\ncannot accurately differentiate between various ini-\ntial symptom prototypes, it will fail to converge\nto a meaningful prototype space at the end of the\ntraining process.\nPrivacy Concerns: Utilizing social media data\nfor depression detection raises inherent privacy con-\ncerns. It is crucial to ensure user privacy through-\nout the data collection, processing, and explanation\ngeneration stages, adhering to relevant ethical and\nlegal guidelines.\nLimited Scope: While ProtoDep focuses on\nTwitter data, it might not generalize to other social\nmedia platforms with different content characteris-\ntics and user behaviors. Further research is needed\nto explore the framework's applicability across di-\nverse platforms.\nClinical Validation: Although ProtoDep aims\nto aid mental health professionals by providing\ntransparent case-based reasoning for each predic-\ntion, its effectiveness in real-world clinical settings\nrequires rigorous validation through controlled\nstudies with healthcare providers.\nHyperparameter Tuning: During our experi-\nments with ProtoDep, we observed that model per-\nformance and prototype quality significantly varied\nfor different hyperparameters. Careful hyperpa-\nrameter optimization is necessary for adaptation to\ndifferent domains.\nBy acknowledging these limitations and actively\nworking towards addressing them, future research\ncan refine ProtoDep to ensure its responsible, eth-\nical, and effective implementation in supporting\nmental health diagnosis and intervention."}]}