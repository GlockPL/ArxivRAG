{"title": "Full-Stack Optimized Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation", "authors": ["RONG SHAN", "JIACHEN ZHU", "JIANGHAO LIN", "CHENXU ZHU", "BO CHEN", "RUIMING TANG", "YONG YU", "WEINAN ZHANG"], "abstract": "As large language models (LLMs) achieves remarkable success in natural language processing (NLP) domains, LLM-enhanced recommender systems have received much attention and are being actively explored currently. In this paper, we focus on adapting and enhancing large language models for recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation realms, i.e., LLMs fail to effectively extract useful information from a pure textual context of long user behavior sequence, even if the length of context is well below the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely Retrieval-enhanced Large Language models Plus (ReLLaX), which provides full-stack optimization from three perspectives, i.e., data, prompt and parameter. For data-level enhancement, we design semantic user behavior retrieval (SUBR) to reduce the heterogeneity of the behavior sequence, thus lowering the difficulty for LLMs to extract the essential information from user behavior sequences. Although SUBR can improve the data quality, further increase of the sequence length will still raise its heterogeneity to a level where LLMs can no longer comprehend it. Hence, we further propose to perform prompt-level and parameter-level enhancement, with the integration of conventional recommendation models (CRMs). As for prompt-level enhancement, we apply soft prompt augmentation (SPA) to explicitly inject collaborative knowledge from CRMs into the prompt. The item representations of LLMs are thus more aligned with recommendation, helping LLMs better explore the item relationships in the sequence and facilitating comprehension. Finally for parameter-level enhancement, we propose component fully-interactive LoRA (CFLORA). By enabling sufficient interaction between the LoRA atom components, the expressive ability of LoRA is extended, making the parameters effectively capture more sequence information. Moreover, we present new perspectives to compare current LoRA-based LLM4Rec methods, i.e. from both a composite and a decomposed view. We theoretically demonstrate that the ways they employ LoRA for recommendation are degraded versions of our CFLORA,", "sections": [{"title": "1 INTRODUCTION", "content": "Recommender systems play an important role in various online applications to address the challenge of information overload and fulfill users' information needs [22, 84, 85]. Meanwhile, large language models (LLMs) have achieved significant advancements in the natural language processing (NLP) field, demonstrating remarkable abilities to generate human-like text across diverse tasks [4, 74, 82, 92]. As a result, recent studies have begun to investigate the integration of LLMs into recommender systems [2, 27, 42, 43]. These works directly leverage LLMs for various recommendation tasks, such as listwise ranking and pointwise scoring, revealing their promising performance in enhancing recommendation systems [2, 91].\nIn this paper, we focus on adapting and enhancing large language models (LLMs) for recommen- dation tasks. Specifically, we identify and address the challenge of lifelong sequential behavior incomprehension, which refers to the inability of LLMs to effectively extract useful information from long user behavior sequences, even when the length of context is well below their context window limitations.\nTo address the lifelong sequential behavior incomprehension problem, we propose a novel frame- work to develop Retrieval-enhanced Large Language models Plus (ReLLaX) for recommendation tasks, which provides full-stack optimization for the LLM4Rec paradigm. Specifically, we offer solutions from three perspectives: data, prompt, and parameter.\nFrom the data perspective, to address the performance issues associated with long sequences, we propose Semantic User Behavior Retrieval (SUBR). Instead of simply truncating the top-K most recent behaviors, SUBR selects the top-K semantically relevant behaviors to the target item. This approach enhances the quality of data samples and lowers the heterogeneity of the user behavior"}, {"title": "2 PRELIMINARIES", "content": "In this paper, we focus on click-through rate (CTR) prediction, a critical component of recommender systems that estimates the probability of a user clicking on a target item within a given context. The training dataset for CTR prediction can be represented as D = {(xi, yi)}^N_{i=1}, where N denotes the number of data samples. In next parts, we give the formulation of CTR prediction tasks for"}, {"title": "2.1 CTR Problem Formulation", "content": "Click-through rate (CTR) prediction is a fundamental task in recommendation systems, aimed at estimating the probability of a user clicking on a specific item. Formally, let U denote the set of users with their profiles (e.g. age or gender) and I denote the set of items with their attributes (e.g. category or brand). Each user u \u2208 U has a has a chronological interaction sequence Hu = [il]^L_{l=1}, where il \u2208 I is the l-th item interacted by the user u and L is the length of the interaction sequence. Given a target item ic, the objective of is to predict the probability \u0177 of the user u clicking on ic, which can be represented as:\n\u0177 = P(y = 1 | u, Hu, ic),\nwhere y = 1 indicates a click. Let x = (u, Hu, ic) denote the current input, and it can be expressed in two modalities: (1) ID modality xID, generated using a one-hot encoder, which would be taken as input for conventional recommendation models, and (2) text modality xtext, which will be directly fed into the LLMs."}, {"title": "2.2 Conventional Recommendation Models", "content": "Typically, conventional recommendation models take xID as inputs, and then encode xID into dense representations with the embedding layers. Let ru, eic \u2208 Rd_e denote the representation for the user u and target item ic respectively, and de is the embedding size. EID = [ei]^L_{i=1} \u2208 RLxde denotes the representations of items in the interaction sequence. Next, different functions f(\u00b7) can be leveraged to aggregate the dense representations for feature interaction or user sequence modeling, the process can be written as:\nh = f(ru, Eu, lic) \u2208 Rd_h,\nwhere h is the final representation, and dh is the hidden dimension. Finally, a classification head g, which is often a linear layer with sigmoid function, maps the final representation into the predicted click-through rate (CTR) \u0177:\n\u0177 = g(h) \u2208 [0, 1]."}, {"title": "2.3 Pointwise Scoring with Large Language Models (LLMs)", "content": "Let Me denote a large language model with parameters \u0398. The LLM takes the discrete tokens of xtext as input, and generates the next token \u0177text as the output, the process of which can be formulated as follows:\ns = M_\u0398(x^{text}) \u2208 R^V,\np = Softmax(s) \u2208 R^V,\n\u0177^{text} ~ p,\nwhere V is the vocabulary size, and \u0177text is the next predicted token sampled from the probability distribution p.\nNevertheless, CTR prediction demands the model to conduct pointwise scoring, in which case the output should be a floating-point number \u0177 \u2208 [0, 1] instead of a discrete token \u0177text. Therefore, we follow previous works [2, 97] and intercept the estimated scores s \u2208 RV of the binary key answer words \u201cYes\u201d and \u201cNo\u201d. Then we conduct a bidimensional softmax over them to predict the CTR. Specifically, suppose the token indices for \u201cYes\u201d and \u201cNo\u201d in the LLM vocabulary are m and n respectively, the pointwise scoring of LLMs for CTR prediction can be written as:\n\u0177 = \\frac{exp(s_m)}{exp(s_m) + exp(s_n)} \u2208 [0, 1].\nIt is noteworthy that such an estimated click-through rate \u0177 is only used on the testing set for evaluation, which also enables zero-shot inference. For training, the common paradigm of instruction tuning is preserved, which leverages the following causal language modeling objective:\nmax_\u0398  \\sum_{(x^{text}, y^{text})\u2208D}  \\sum_{j=1}^{\\|y^{text}\\|} log P_\u0398 (y_j^{text} | x^{text}, y_{<j}^{text}),\nwhere yj is the j-th token of the textual output y, and y<j denotes the tokens before yj."}, {"title": "2.4 LORA for Efficient Adaptation", "content": "Full finetuning of LLMs is time-consuming and resource-intensive, and low-rank adaptation (LoRA) serves as an efficient alternative. It introduces trainable low-rank matrices to approximate the updates of pretrained weights, while the pretrained weights are frozen. Specifically, LoRA employs a low-rank decomposition on the update of the weights \u0394\u0398. The process can be represented as:\n\u0394\u0398 = BA,\nwhere A \u2208 R^{rxd_{down}}, B \u2208 R^{d_{up}xr} are down-projection and up-projection matrices respectively. A can be randomly initialized, while B is often initialized as zero matrix to ensure the output equal to the original value. The rank r is much smaller than both ddown and dup, improving the efficiency of model adaptation. By applying LoRA on the LLM transformer layers, the causal language modeling objective in Equation 9 can be rewritten as:\nmax_{\u0394\u0398} \\sum_{(x^{text}, y^{text}) \u2208 D} \\sum_{j=1}^{\\|y^{text}\\|} log P_{\u0398+\u0394\u0398} (y_j^{text} | x^{text}, y_{<j}^{text}),\nwhere \u0398 is fixed and only \u0394\u0398 is trainable during the instruction tuning process. Correspondingly, the next token logits s in Equation 5 when evaluation on the testing set can be reformulated as:\ns = M_{\u0398+\u0394\u0398}(x^{text})."}, {"title": "3 METHODOLOGY", "content": "In this section, we introduce our proposed ReLLaX framework in details. First, we will provide an overview of the whole framework. Then we elaborate on our key techniques in three aspects, e.g. data, prompt and parameter."}, {"title": "3.1 Overview of ReLLaX", "content": "As illustrated in Figure 3, ReLLaX proposes a full-stack optimization framework for LLMs to tackle the problem of lifelong sequence incomprehension in recommendation, where our devel- oped techniques provide (1) data-level, (2) prompt-level and (3) parameter-level enhancement, respectively.\nData-level Enhancement. To improve the data quality, we propose to perform semantic user behavior retrieval (SUBR) over the textual data samples. We first obtain the semantic vectors for each item utilizing the large language model, based on which we can retrieve the top-K semantically relevant behaviors for each textual data sample xtext. Then these retrieved behaviors can substitute the original top-K recent behaviors, resulting in the retrieval-enhanced data sample xtext. The heterogeneity of items in the sequence is lowered, reducing the difficulty for LLMs to extract useful information from the sequence. Note that SUBR serves for data augmentation purpose, and xtext will be the input for LLMs to reason over, rather than xtext.\nPrompt-level Enhancement. We propose to conduct soft prompt augmentation (SPA) to make the vanilla item representations of LLMs more aligned with recommendation. Firstly, we pretrain a conventional recommendation model (CRM), whose item ID embeddings lie in recommendation space and encode collaborative knowledge well. Secondly, to adapt these ID embeddings into the language space of LLM, we leverage a lightweight projector to convert them into soft prompt tokens, which are then concatenated with the original textual tokens of the items. This comprehensive prompting design helps LLMs model the item relationships in the sequence better, thus improving LLMs' ability to handle inputs with long behavior sequences.\nParameter-level Enhancement. We develop component fully-interactive LoRA (CFLoRA) to construct personalized parameters more effectively for efficient finetuning. We first harness the pretrained CRM to obtain the final representation for each data sample, which encodes all collaborative information for recommendation. Based on the these representations, component interaction matrices can be generated using a lightweight projector, which would be inserted between the vanilla LoRA decomposition matrices. The process operates in a composite view which focuses on LoRA matrices. Notably, in the corresponding decomposed view where we investigate"}, {"title": "3.2 Semantic User Behavior Retrieval", "content": "The user behavior sequences often consist of diverse, heterogeneous, and sometimes random or noisy item clicks [46, 81, 83], making it difficult for LLMs to extract useful information from the sequences. Hence, we propose semantic user behavior retrieval (SUBR) to improve the data quality and homogenize the sequence. SUBR operates by substituting the simply truncated most recent K behaviors with the most semantically relevant K behaviors towards the target item. The retrieved user behaviors serve to denoise the user behavior sequence and convey clearer and more essential user interests for the target item, while the original length of user behavior sequence is preserved.\nFirstly, we perform semantic item encoding to generate a semantic vector for each item. For the t-th item in the pool, we construct a descriptive text through a hard prompt template (an example is shown in Figure 4), and feed the text into the LLM. The hidden states from the last layer of the LLM are then averaged to produce a vector z_t \u2208 Rdz, where dz is the hidden size of LLM (e.g., 4096 for Vicuna-7B and 5120 for Vicuna-13B). We further apply principal component analysis (PCA) [70] for both dimension reduction and denoising purposes, obtaining the final semantic vector qt \u2208 Rda, where we set the dimension dq to 512. Now we can assess the semantic relevance between each pair of items by calculating the cosine similarity between their respective semantic vectors.\nNext, we can employ semantic user behavior retrieval on each sample xtext to obtain the retrieval- enhanced counterpart xtext, which will be the new textual input for the LLM. Specifically, the original truncated top-K recent behaviors are replaced with the top-K semantically relevant be- haviors of the target item, while maintaining a similar length of textual input. In this way, SUBR improves the data quality, reducing the difficulty for LLMs to comprehend the long user behavior sequences."}, {"title": "3.3 Soft Prompt Augmentation", "content": "Collaborative knowledge from conventional recommendation models (CRMs) can help LLMs capture user behavior patterns easier and improve recommendation performance, which has been revealed by previous works [41, 96]. Therefore, rather than relying solely on hard prompts composed of textual tokens, we employ soft prompt augmentation (SPA) to construct a more comprehensive prompt. Integrated with collaborative knowledge from CRMs, the comprehensive prompt can make the item representations in the language space more aligned with recommendation, and helps LLMs model the item relationships in the sequence better, which facilitates LLMs' understanding of the behavior sequences. Next, we dive into the details of the SPA module.\nAs described in Section 2, each data sample x can be expressed in two modalities, e.g. ID modality xID and text modality xtext (now we use xtext after SUBR). We first pretrain a conventional recommendation model with the full training set. Then for each data sample in ID modality xID, we can get the historical and target item embeddings EID = [li1, li2, \u2026\u2026\u2026, liL, eic] via looking up the pretrained CRM embedding tables. For each data sample in text modality xtext, we utilize the LLM tokenizer to tokenize it into T = [tl]^P_{l=1}, where tl denotes l-th text token and P denotes the number of tokens. These text tokens are further encoded into embeddings Etext = [vl]^P_{l=1}, where vl \u2208 Rdo is the token embedding of tl in the LLM embedding table, and do is the LLM token embedding size. \nSince the item ID embeddings EID are pretrained in the recommendation space, not the language space where the LLM operates, we need to bridge the modality gap and adapt EID into the language space. Specifically, we leverage a lightweight soft prompt generation projector, e.g. a two-layer multilayer perceptron (MLP), to map the ID embeddings into soft prompt tokens \u00cau,ic = [vi1, vi2,\u00b7\u00b7\u00b7, viL, vic]. These soft prompt tokens are then appended behind their corresponding text token embeddings and result in the enhanced token embeddings \u1ebc, which will be the final input fed to the LLM in our ReLLaX framework:\n\u1ebc = [v1,\u00b7\u00b7\u00b7, un1, vi1, ***, vn2, viz,\u00b7\u00b7\u00b7, unL, viL, unL+1, vic],\nwhere {n_j}_{j=1}^{L+1} are the last text token positions for the historical items and the target item. Our comprehensive prompting approach provides a more informative representation of items, combining the LLM's semantic information with the pretrained CRM model's collaborative filtering features. This facilitates the LLM's understanding of user history and improves its ability to perform CTR tasks."}, {"title": "3.4 Component Fully-Interactive LoRA", "content": "Current LLM4rec methods [2, 34, 46, 96, 100] mainly leverage LoRA [28] for parameter-efficient finetuning. However, due to the incomprehension problem, the vanilla LoRA parameters may not be expressive enough to effectively capture the long-sequence information. In this part, we first conduct a theoretical analysis of these methods by revisiting LoRA parameters, in both a decomposed and a composite view. Building on the analysis, we observe that the interaction between LoRA"}, {"title": "3.4.1 Decomposed View", "content": "First, we examine the LoRA matrices from a decomposed view, where we focus on the vectors composing the matrices. As stated in Section 2.4, the vanilla LoRA approximates the update of weights by the multiplication of the up-projection matrix B \u2208 R^{d_{up}xr} and the down- projection matrix A \u2208 R^{rxd_{down}}. If we partition A and B along the r-dimension into vectors, we can get:\nB = [B_1, B_2,\uff65\uff65\uff65, B_r],\nAT A\u02dc = [A_1, A_1, \u2026, A_r],\nwhere Bj \u2208 R^{d_{down}x1} is the j-th column vector for B, and Aj \u2208 R^{1xd_{up}} is the j-th row vector for A. We regard these vectors as atom components of the LoRA matrices, as they cannot be decomposed further. With these atom components, the vanilla LoRA matrices can be expressed as:\n\u0394\u0398_1 = BA = \\sum_{j=1}^r B_jA_j.\nHence, the vanilla LoRA matrices can be viewed as the aggregation of one-to-one interaction between Bj and Aj, where the aggregation weight is fixed to 1.\nAlthough vanilla LoRA has demonstrated promising performance in many LLM4Rec works [2, 41, 46, 96], some recent works [34, 100] further propose to construct personalized LoRA parameters. They generally prepare mutiple sets of LoRA parameters, and use conventional recommendation models to generate the scaling aggregation weights for different sets of LoRA. Therefore, following the original papers [34, 100], the update can be formulated as:\n\u0394\u0398_2 = \\sum_{j=1}^N \u03b1_jB_jA_j,\nwhere N denotes the number of LoRA sets. Bj \u2208 R^{d_{up}xr_1}, Aj \u2208 R^{r_1xd_{down}} are j-th set of LoRA matrices, and \u03b1j is the scaling weight generated by CRM for them. r1 is their rank. In our decomposed view, we can rewrite Equation 14 into:\n\u0394\u0398_2 = \\sum_{j=1}^N \\sum_{k=1}^1 \u03b1_jB_k^jA_k^j\nwhere B_k^j and A_k^j are k-th atom components of j-th LoRA matrices. Furthermore, to make Equa- tion 15 more concise, we can absorb the first summation into \u03b1 by setting r = r1N, which can be viewed as splitting one r-rank LoRA into N sets (e.g., r = 4, N = 2 in Figure 2). In this way, we can get:\n\u0394\u0398_2 = \\sum_{j=1}^r \u03b1_{j//N} B_jA_j\nand Bj, Aj are atom components of the r-rank LoRA. Therefore, in a decomposed view, we can see that the interaction between atom components remain partial and not sufficient (i.e., only Bj and Aj with the same j have interactions), while the aggregation weight is customized by conventional recommendation model.\nBuilt on these observations, we aim to enable more sufficient interaction between the atom com- ponents and extend the expressive power of LoRA parameters, with the integration of collaborative knowledge from CRM. To this end, we propose the component fully-interactive LoRA (CFLORA)"}, {"title": "3.4.2 Composite View", "content": "In the composite view, we return to analyze the LoRA matrices, instead of atom components. Revisiting Equation 17, we can observe that it is mathematically consistent with the multiplication of several matrices:\n\u0394\u0398_{CFLORA} = \\sum_{i=1}^r \\sum_{j=1}^r w_{ij} B_iA_j = BWA,\nwhere W \u2208 R^{r*r}, and wij fills the corresponding value in W. Correspondingly, we can rewritten Equation 13 and Equation 16 in a similar form:\n\u0394\u0398_1 = \\sum_{j=1}^r B_jA_j = BIA,\n\u0394\u0398_2 = \\sum_{j=1}^r \u03b1_{j//N} B_jA_j = BW_2A,\nwhere I \u2208 R^{r*r} is the identity matrix. W2 \u2208 R^{r*r} is a diagonal matrix where the diagonal elements can be divided into different N blocks of different \u03b1.\nComparing Equation 18 and Equation 19, we can observe that the way existing LLM4Rec methods employ LoRA are special cases of CFLoRA in the composite view. CFLoRA can degrade into them with different constraints on W. By analyzing LoRA parameters in both a composite view and a decomposed view, we provide a novel perspective to evaluate and compare these methods."}, {"title": "3.4.3 CFLoRA Implementation", "content": "We have discussed that CFLORA enables full interaction between atom components under the decomposed view, while preserving a concise matrix form under the composite view. Based on the matrix form, we can easily and elegantly implement the CFLoRA module. Specifically, for each data sample x, using the pretrained CRM, we can get the final representation h according to Equation 2. With a lightweight projector (e.g., a two-layer MLP) and reshaping transformation, we can get the final W. The process can be formulated as:\nh = f(ru, Eu, lic) \u2208 Rdh,\nh1 = Projector(h) \u2208 Rr^2,\nW = Reshape(h1) \u2208 Rr*r.\nIn this way, CFLORA extends the expressive capability of LoRA by enabling more comprehensive interaction, which makes the parameters effectively capture more useful information from the"}, {"title": "3.5 Training and Inference Procedure", "content": "We optimize the overall ReLLaX framework in an end-to-end manner, where the training objective is an extended version of causal language modeling in Equation 9 with the integration of ID modality inputs:\nmax_{\u0394\u0398} \\sum_{I(x^{ID},x^{text}, y^{text})\u2208D} \\sum_{j=1}^{\\|y^{text}\\|} log P_{\u0398+\u0394\u0398} (y_j^{ext} | x^{ID}, x^{text}, y_{<j}^{text}).\nThe trainable parameters \u0394\u0398 now include the prompt generation projector in SPA, the component interaction projector in CFLoRA, as well as the vanilla LoRA A, B matrices. The main weights of LLMs and the pretrained conventional recommendation model are frozen.\nCorresponding, the inference process of ReLLaX also needs to incorporate the ID modality inputs, changing Equation 10 into:\ns = M_{\u0398+\u0394\u0398}(x^{ID}, x^{text})."}, {"title": "4 EXPERIMENT", "content": "In this section, we conduct extensive experiments to answer the following research questions:\nRQ1 How does ReLLaX perform compared to existing baselines?\nRQ2 What are the influences of different modules for ReLLaX?\nRQ3 Does ReLLaX promote the lifelong sequential behavior comprehension ability of LLMs for recommendation tasks?\nRQ4 How does ReLLaX help LLMs to better comprehend the user behavior sequence?"}, {"title": "4.1 Experiment Setup", "content": "We conduct experiments on three real-world datasets (i.e., BookCrossing, MovieLens- 1M and MovieLens-25M) and show the dataset statistics in Table 2. MovieLens-1M and MovieLens- 25M datasets are split into training and testing sets with ratio of 8:1 according to the global times- tamp [61]. Since BookCrossing dataset has no timestamps, we follow previous work [2] and divide it into training and testing sets with ratio of 9:1 by random split of users. Data samples with user behavior sequence length less than 5 are filtered on all three datasets. We describe more preprocessing details as follows:\n\u2022 BookCrossing possesses user-book integer ratings ranging from 0 to 10. We consider samples with rating above 5 as positive, and the rest as negative.\n\u2022 MovieLens-1M contains user-movie integer ratings ranging from 0 to 5. Samples with ratings of 4 and 5 are labeled as positive and the rest as negative. [85, 99]\n\u2022 MovieLens-25M has a scoring range from 0 to 5, with increments of 0.5. We label samples with ratings above 3.0 as positive, and the rest as negative."}, {"title": "4.1.2 Evaluation Metrics", "content": "To evaluate the recommendation performance of different models, we utilize AUC (area under the ROC curve), Log Loss (binary cross-entropy loss) and ACC (accuracy score) as the evaluation metrics. In the CTR prediction task, slightly higher AUC or lower Log Loss (e.g., 0.001) can be regarded as significant improvement [40, 79]."}, {"title": "4.2 Overall Performance (RQ1)", "content": "We evaluate the performance of ReLLaX in comparison to existing baseline models, and report the results in Table 3. Note that as the training of LLM-based models (i.e., TALLRec, CoLLM, iLoRA, ReLLa and ReLLaX) is both time-consuming and resource-intensive, we follow previous works [2,"}, {"title": "4.3 Ablation Study (RQ2)", "content": "To analyze the efficacy of each module in our proposed ReLLaX framework, we design several model variants of ReLLaX. The number of training samples are fixed to 1024/8192/8192, and the length of textual user behavior sequnce is set to 60/30/30 for BookCrossing/MovieLens-1M/MovieLens-25M datasets, respectively. The length of user behavior sequences for the pretrained traditional CTR model is set to 60. The designed model variants of ReLLaX are as follows:\n\u2022 ReLLaX (Ours) is the complete version of our proposed method, with SUBR, SPA and CFLORA providing data-level, prompt-level and parameter-level enhancement respectively.\n\u2022 ReLLaX (w/o SUBR). We remove the semantic user behavior retrieval for both training and testing samples. That is, training and testing data uses prompts without retrieval enhancement. This variant aims to ablate on the efficacy of data augmentation brought by retrieval.\n\u2022 ReLLaX (w/o SPA). We remove the soft prompt augmentation for both training and testing samples. That is, the prompts are the same as vanilla ReLLa, without explicitly injecting collaborative knowledge into the prompt.\n\u2022 ReLLaX (w/o CFLoRA). We remove CFLORA modules. Therefore, the instruction tuning utilizes vanilla LoRA, with SUBR to improve the data quality and SPA to generate soft prompt.\n\u2022 ReLLa. This variant corresponds to removing all the new proposed techniques in this paper, i.e. SPA and CFLORA.\n\u2022 ReLLa (w/o IT). We remove the instruction tuning from ReLLa, while still leveraging SUBR. This variant indicates the zero-shot setting of ReLLa, which aims to ablate on the efficacy of data augmentation of SUBR under the zero-shot setting.\n\u2022 ReLLa (w/o IT & Retrieval). We remove both the instruction tuning and retrieval operation. Therefore, the testing data only contains original data samples. This variant indicates the zero-shot version of vanilla Vicuna-13B."}, {"title": "4.4 Sequential Behavior Comprehension (RQ3)", "content": "We vary the length of user behavior sequence to analyze its impact on CTR prediction performance, which can reflect the comprehension ability of a model towards user behavior sequences. It is noteworthy that ReLLaX utilizes user behavior sequences of two modalities, e.g. text modality in the hard prompt, and ID modality for CRM in the SPA and CFLoRA module. As the length of user behavior sequences increases, the number of tokens in the textual sequence grows, leading to more VRAM consumption. In comparison, as shown in Equation 21, sequences in ID modality can be encoded into dense representations, and will incur no additional resource overhead as the sequence length increases. Therefore, in this section, we first vary the length of textual behavior sequence K with vanilla ReLLa, which removes the ID behavior sequences from ReLLaX. Finding the best and largest K that computation resource allows, we bring back the ID modality, fix the largest K and evaluate ReLLaX with ID behavior sequences with different length L."}, {"title": "4.4.1 Different textual sequence length for ReLLa", "content": "We evaluate ReLLa (few-shot), which uses the pure textual behavior sequences, against SIM (full-shot) and Vicuna-13B (zero-shot) using the same sequence length. The number of training examples (i.e., shots) for ReLLa is 256/8192/8192 for BookCrossing, MovieLens-1M and MovieLens-25M respectively, while SIM (full-shot) is trained with the entire training set and Vicuna-13B (zero-shot) is not tuned. In our experiment setting, the maximum tokens allowed by the resource is about 700 tokens. Hence, we choose the largest textual sequence length K to 60/30/30 for the three datasets respectively, and evaluate the performance within the largest K. The results are illustrated in Figure 6, from which we can have the following observations:\n\u2022 As a conventional recommendation model, SIM (full-shot) enjoys steady performance im- provement when the ID sequence length K increases. This is consistent with our common"}, {"title": "4.4.2 Further longer ID sequence length for ReLLaX", "content": "In section 4.4.1, we have found that under the computation resource limitation and a mediate K (i.e., K<=30), ReLLa can enjoy better CTR prediction performance as K increases, thus mitigating the behavior sequence incomprehension problem. Here, we fix textual sequence length K to the maximum (i.e., 30 on the MovieLens-1M dataset). By further introducing SPA and CFLoRA to ReLLa, we evaluate ReLLaX with different ID sequence length L, to see if further longer ID sequence can improve the understanding of the long textual sequence (i.e., L >= K). The number of training samples for the models is 8192. The results are reported in Figure 7, and we can observe that:\n\u2022 Injecting collaborative knowledge into the LLM by SPA and CFLoRA can improve the recom- mendation performance. Even when the ID sequence length K is equal to the text sequence length (i.e., L = 30, K = 30), ReLLaX can still outperform ReLLa, while the exact items composing the sequences are the same in the text and ID sequence. This indicates that the soft prompt injected using the SPA module can improve the understanding of the pure textual behavior sequences, and CFLoRA is more effective to capture long-sequence information than vanilla LoRA in ReLLa.\n\u2022 ReLLa and ReLLaX are more sample-efficient than SIM. With the same number of training samples, ReLLa and ReLLaX can achieve better recommendation performance.\n\u2022 The performance of ReLLaX improves as L increases. This can be attributed to that more useful information is encoded and utilized by the LLM as L grows, thus further enhancing the comprehension ability over the behavior sequences."}, {"title": "4.5 Case Study (RQ4)", "content": "In this section, we perform a case study to explore how ReLLaX enhances the ability of LLMs to understand long user behavior sequences. As depicted in Figure 8, we choose a testing sample from the MovieLens-25M dataset, and visualize the attention scores of the target item across the user behavior sequence for three models, i.e. Vicuna-13B (zero-shot), ReLLa (few-shot), and ReLLaX (few-shot). The attention score for each historical item is calculated by summing up the attention scores of each word token for the corresponding item at the last hidden layer of the LLM. In Figure 8, each historical item is represented by a rectangle, with colors ranging from blue to purple. The deeper the color, the higher the attention score of the corresponding item, indicating a greater contribution to the final CTR estimation.\nOn the long sequence, for Vicuna-13B (zero-shot), the movie Warrior is given high attention, which have little relevance to the target movie Thor: Ragnarok. Consequently, the model fails to accurately predict the user's preference for the target item. By incorporating semantic user behavior retrieval (SUBR), we can homogenize the sequence and introduce more relevant items. As shown in Figure 8, ReLLa (few-shot) focuses more on superhero movies like Iron Man 3, which are semantically similar to the target item.\nHowever, although SUBR can lower the heterogeneity score, as the length of sequence increases further, the heterogeneity of the longer sequence can still raise to a high level where LLMs fail to comprehend it, which is also illustrated in Table 1. Hence, in Figure 8, with further longer sequences, there are still some irrelevant items, such as Kick-Ass 2, which is not closely related to Thor: Ragnarok produced by Marvel. By further implementing soft prompt augmentation (SPA) and instruction tuning with component fully-interactive LoRA (CFLoRA), ReLLaX (few-shot) demonstrates a more refined attention mechanism. The significant attention weights are now concentrated on relevant superhero movies produced by Marvel. This indicates that the techniques we propose can help"}, {"title": "5 RELATED WORK", "content": "LLMs accurately identify the correlation between the target item and historical items, thereby improving their understanding of user behavior sequences."}, {"title": "5.1 Traditional CTR Prediction", "content": "Click-through rate (CTR) prediction is a critical component in a variety of online applications, such as recommender systems [84", "56": "and web search [15, 18, 44"}]}