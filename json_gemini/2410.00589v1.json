{"title": "GERA: Geometric Embedding for Efficient Point Registration Analysis", "authors": ["Geng Li", "Haozhi Cao", "Mingyang Liu", "Shenghai Yuan", "Jianfei Yang"], "abstract": "Point cloud registration aims to provide estimated transformations to align point clouds, which plays a crucial role in pose estimation of various navigation systems, such as surgical guidance systems and autonomous vehicles. Despite the impressive performance of recent models on benchmark datasets, many rely on complex modules like KPConv and Transformers, which impose significant computational and memory demands. These requirements hinder their practical application, particularly in resource-constrained environments such as mobile robotics. In this paper, we propose a novel point cloud registration network that leverages a pure MLP architecture, constructing geometric information offline. This approach eliminates the computational and memory burdens associated with traditional complex feature extractors and significantly reduces inference time and resource consumption. Our method is the first to replace 3D coordinate inputs with offline-constructed geometric encoding, improving generalization and stability, as demonstrated by Maximum Mean Discrepancy (MMD) comparisons. This efficient and accurate geometric representation marks a significant advancement in point cloud analysis, particularly for applications requiring fast and reliability.", "sections": [{"title": "I. INTRODUCTION", "content": "Point cloud registration is a fundamental problem in 3D scene understanding and robotics. The goal is to acquire the point-wise transformation matrix that aligns two point clouds, which plays a vital role in various downstream tasks (e.g., motion estimation [1], [2], 3D scene reconstruction [3], SLAM [4], [5], and surgical navigation [6]).\nRecent non-learning-based methods for non-rigid registration perform well but are hindered by high inference time, limiting real-time use. Learning-based methods, which eliminate complex optimization at test time, improve efficiency but still fall short of real-time performance, necessitating further enhancements for practical deployment [7], [8]. A typical example is the point cloud registration of organs in surgical robots [9], [10] as shown in Fig. 1. On the one hand, the registration algorithm, in this case, needs to be robust and highly accurate to guarantee the success of the surgery. On the other hand, it must satisfy the real-time inference requirement even with rather limited computational resources (e.g., embedded devices). Therefore, developing accurate and efficient learning-based point cloud registration methods is significant, bridging the gap between benchmarking and real-life deployment.\nExisting learning-based solutions [7], [8] rely on complex local geometric feature extractors that extract usable registration features from raw 3D points [11], [12]. Despite their effectiveness, these powerful extractors (e.g., KPConv [11] and Transformer [12]) usually contain masses of trainable parameters, bringing significant computational expenses during both the training and inference stages. As the model becomes increasingly complex, its performance improvements fall short of meeting the demands for real-time processing.\nWe revisited recent learning-based registration methods and found that their primary efficiency bottleneck stems from feature extraction and online local construction modules [7], [8], [13]. Drawing inspiration from non-learning methods [14], we propose replacing traditional positional information with geometric features, to optimize registration performance. Our approach constructs information-rich geometric-encoded inputs, which offer two key advantages. First, by using efficient encoding algorithms, geometric 3D representations can be extracted without learnable modules, reducing the computational load during both offline training and online inference. Second, these geometric representations are more informative than raw 3D points, leading to better performance even with simpler learnable modules.\nBased on the above analysis, in this paper, we propose GERA, a method for GEometric embedding for learning- based efficient point registration with a lightweight trainable network, improving both the effectiveness and efficiency of registration. Given raw point clouds as input, we first construct a 3D descriptor for each point by forming a fully connected graph using this point and its neighboring points. The edges of the graph represent the distances between every pair of points. We conducted a kernel-based statistical analysis using Maximum Mean Discrepancy(MMD) [15] to demonstrate the stability and robustness of our geometric embedding encoding. which is a kernel-based statistical measure employed to analyze the similarity of encoded embeddings between different input samples. By leveraging the MMD, we demonstrated that the stability of geometric information encoding features is superior to previous state-of-the-art learning-based solutions. Additionally, our descriptors can be constructed offline, significantly reducing training and inference time. Following prior work that employs MLP architectures for point cloud analysis and registration, we utilize this simple network architecture to effectively leverage the informative descriptors, thereby significantly surpassing previous complex learning-based solutions. Our experiment results show that the inference speed was increased by 22x, resulting in a 115% improvement in prediction accuracy compared to the existing state-of-the-art solution.\nOur contributions can be summarized as follows:\n\u2022 We propose an offline method that efficiently and accurately constructs geometric information from point clouds.\n\u2022 We are the first to replace 3D coordinate input with geometric encoding information in point cloud processing.\n\u2022 We surpassed the SOTA by 12.5% while using only 3% of the computation time required by existing methods."}, {"title": "II. RELATED WORK", "content": "Feature encoding for point cloud data began with PointNet [16], which utilized rotation-invariance and an MLP architecture but lacked the ability to capture local geometric information. This was improved by PointNet++ [13], which introduced hierarchical feature extraction from local to global levels, and DGCNN [17], which considered the relative distances between neighboring points. KPConv [11] further advanced this by extracting features within a spherical range, similar to convolution. In point cloud registration, methods like GeoTransformer [8] and Lepard [7] adopted transformer architectures to effectively model local geometric information, though with increased computational overhead."}, {"title": "B. Non-learning-based Methods", "content": "The Iterative Closest Point (ICP) [18] algorithm based on the least squares method relies heavily on initialization and converges slowly. Coherent Point Drift [19] (CPD) formulates the registration task as a probability density estimation problem, iteratively updating point correspondences and non-rigid transformation parameters using the expectation-maximization technique. However, CPD requires multiple iterations and is sensitive to occlusions and outliers. Methods employing Graph-Laplacian regularization [20] and context-aware Gaussian fields (SCGF) [21] improve correspondence and transformation estimation but depend on high-quality assignment initialization. Bayesian Coherent Point Drift (BCPD) [22] enhances CPD's convergence through variational Bayesian inference but remains prone to local minima. The MR-RPM [23] method based on manifold regularization captures the intrinsic geometry of point sets using manifold regularization priors. PointSetReg [24] utilizes unsupervised clustering analysis, avoiding explicit point correspondences to improve robustness and efficiency. However, the heavy reliance of PointSetReg on cluster-level information may reduce precision when handling complex point clouds."}, {"title": "C. Learning-based Methods", "content": "FPT [6] utilizes a decoder composed of PointNet and fully connected layers to perform non-rigid registration on prostate point clouds, offering high efficiency but limited robustness due to the lack of a geometric construction module. Lepard [7] employs a transformer architecture to form attention heads between point clouds, extracting the point correspondence matrix, which is then input into algorithms such as N-ICP [14] for non-rigid registration. While Lepard provides comprehensive encoding of point cloud information, its slower processing speed limits practical applications. Similar to non-rigid registration, the problem of scene flow estimation has garnered increasing attention in recent years. PointPWC-Net [25] refines the flow iteratively at multiple scales, enhancing its ability to capture fine-grained motion details, but its computational complexity remains relatively high. BI-PointFlowNet [26] incorporates bidirectional learning for point clouds, enhancing accuracy and robustness, but it encounters difficulties when handling scenes with large displacements. DiffFlowNet [27] utilizes a powerful and complex diffusion model, achieving millimeter-level error in scene flow estimation, but it also introduces the challenge of prolonged inference time."}, {"title": "III. METHODOLOGY", "content": "Probelm Definition: In non-rigid registration, we are given a source point set $P_s = {x_1,..., x_i, ..., x_M }$ and a target point set $P_T = {y_1,...,Y_j,..., Y_N}$, where $x_i, Y_j \\in R^3$ represent the 3D coordinates of the points, and M, N are their respective counts. The goal is to estimate displacement vectors $D_{pred} = [d_{pred_1},..., d_{pred_i},..., d_{pred_M}]$, which deform each point $x_i \\in P_s$ to align with $P_T$.\nThe deformed point set $P'_s = {x'_1,...,x'_i,...,x'_M }$ is computed as:\n$x'_i = x_i + f(x_i, D_{pred}) = x_i + d_{pred_i} + \\epsilon(x_i)$, (1)\nwhere $x'_i$ is the deformed point in $P'_s$, and $\\epsilon(x_i)$ represents a small adjustment term to enhance registration smoothness."}, {"title": "A. Efficient Offline Geometric Representations", "content": "Using only two neighboring points for geometric construction forms the simplest fully connected graph, yielding limited information. To further enrich the embedded information, we consider each point's n neighbors as vertices of a fully connected graph, resulting in $C_n^2$ pairwise distances. This comprehensive modeling retains only the edge lengths, which, according to distance geometry and rigidity theory, uniquely determine a 3D structure [28]. This approach is widely used in structural chemistry and drug design [29], [30], which could be formulated as:\n$sc^i \\in R^d = concat({G(i,j,k) | 1 \\leq j \\leq k \\leq n})$, (3)\nwhere $sc^i$ denotes the fully connected graph constructed from n neighboring points. d represents the total number of edges in the fully connected graph, $C_n^2$.\nPrevious studies on local geometric information used 3D spatial coordinates of point clouds with online extraction, resulting in a computational complexity of O(n), where n is the number of training epochs, demanding significant computational and memory resources. This paper instead proposes an offline geometric information construction method with O(1) complexity, significantly alleviating the overhead during the training process. Based on our quantitative analysis with MMD, we further demonstrate that our proposed geometric representations possess superior generalizability and stability compared to others."}, {"title": "1) Construction of Geometric Representations", "content": "Our method improves upon previous local geometric information construction by using a simple geometric prior. Traditional methods [8] compute distances and angles between points and neighbors, which are not directly comparable to MLP input because angles and distances represent different dimensions of information. By forming a triangle with the original point and its two neighbors, and defining it by side lengths, we reduce the geometric relationships to a consistent and usable format for the network, which can be formulated as:\n$\\alpha = ||P_i - P_j ||, \\qquad \\beta = ||P_i - P_k ||, \\qquad \\gamma = ||P_j - P_k ||, \\qquad G_{(i,j,k)} = concat(\\alpha, \\beta, \\gamma),$(2)\nwhere $P_i$, $P_j$, $P_k$ are the coordinates of points, and $G_{(i,j,k)}$ donates the geometric information constructed for points i, j, k. concat(\u00b7) indicates the concatenation operation."}, {"title": "2) Analysis of Stability and Generalization", "content": "Non-rigid point cloud registration entails more complex transformations than rigid registration, resulting in flexible data distribution variations. Thus, a robust feature representation with strong generalization is essential. To assess the stability and generalization of geometric encoding, we performed a quantitative analysis based on MMD, a criterion widely used to measure discrepancy in domain adaptation [31]\u2013[33].\nSpecifically, MMD measures the distance between samples in a high-dimensional feature space, with smaller distances indicating greater similarity and thus stronger generalization and stability. In this context, MMD can provide a quantitative assessment about the similarity of the encoded features between samples, expressed as:\n$MMD^2(P_s, P_T) = ||E_{x\\sim P_s}[\\phi(x)] \u2013 E_{y\\sim P_T}[\\phi(y)]||^4,$(4)\nwhere $k(x, y) = exp(\\frac{-||x - y||^2}{2\\sigma^2})$\nwhere $\\phi(x)$ is the mapping function that projects the x into a high-dimensional Reproducing Kernel Hilbert Space H. By expanding and simplifying equation (3), we can derive the computation formula for MMD:\n$MMD^2(P_s, P_T) = E_{x,x'\\sim P_s}[k(x, x')] + E_{y,y'\\sim P_T}[k(y, y')] - 2E_{x\\sim P_s, y\\sim Q}[k(x, y)],$(5)\nwhere $k(x, y) = exp(-\\frac{||x - y||^2}{2\\sigma^2})$(6)\nwhere x and x' represent two independent samples drawn from the distribution Ps, and k(\u00b7, \u00b7) is the kernel function. Equation (5) specifies the Gaussian kernel function.\nIn this study, we employed identical encoder architectures for both 3D coordinate encoding and geometric encoding as inputs to MMD. As shown in Fig. 2, the MMD values produced by geometric encoding were significantly lower than those from position encoding, indicating that GERA's geometric encoding method is more stable and has stronger generalization capabilities. Moreover, the minimum, mean, and maximum MMD values for geometric encoding were 0.2736, 0.3178, and 0.3668, respectively, which are notably"}, {"title": "1) Geometric Encoder and Decoder", "content": "As we discussed, offline geometric encoding extrated rich features from the raw point clouds. By leveraging these features, we can effectively and efficiently address the non-rigid registration task with a simple MLP architecture. Given the raw point cloud inputs Ps and PT, the geometric extraction process Geo(\u00b7) first constructs the geometric information. The resulting geometric embeddings from Ps and PT can be expressed as:\n$P_s^e = Geo(P_s) = {sc_p^i \\in R^d | 1 \\leq i \\leq m}$,(7)\n, where sc denotes the edge length in the encoded fully connected graph, i, k are the point indices, and m represents the number of points in the point cloud.\nThe feature extraction of Ps and PT is performed through an MLP, resulting in geometric features $F_{Ps}^{geo}$ and $F_{PT}^{geo}$, respectively. These two features are then concatenated to generate a new representation $concat(F_{Ps}^{geo}, F_{PT}^{geo})$. This process can be formulated as:\n$F_{geo}^{full} = concat{\\lambda{P_s, (concat(F_{Ps}^{geo}, F_{PT}^{geo}), n), P_T}},$(8)\nwhere $\\lambda(p, n)$ represents the replication of pn times.\nThe concatenated feature vector $F^{geo} \\in R^d$ is replicated n times, where n is the number of points in the point cloud, producing a fully populated feature map $F^{geo}_{full} \\in R^{d \\times n}$. This feature map concatenates in the packing stage with the point cloud coordinates. The decoder, an MLP, then processes this combined data to output the predicted displacement matrix for point cloud registration."}, {"title": "2) Loss function", "content": "Previous methods used 3D coordinates as a metric to quantify the differences between two point clouds. However, we found that the geometric information constructed by GERA can capture detailed geometric differences in the point clouds. Therefore, we introduced Lgeo, an unsupervised loss function that can be combined with existing registration methods, leading to significant improvements.\nOur Lgeo is formed by extracting geometric information from the target and output point clouds using the geometric extraction process Geo(\u00b7), with the error calculated via an adapted Chamfer distance loss.\n$L_{geo} = \\sum_{p \\in P_s} min_{q \\in P_T} || Geo(p) \u2013 Geo(q)||^2 + \\sum_{q \\in P_T} min_{p \\in P_s} || Geo(q) \u2013 Geo(p)||^2,$(9)\nwhere p and q denote points in the source point cloud and the target point cloud.\nAdditionally, we employed the commonly used root mean square error (RMSE) to calculate the error between the source and target point clouds, defining it as Lxyz. During training, Lgeo and Lxyz form a semi-supervised combination learning framework, and the total loss can be expressed as:\n$L_{total} = \\alpha L_{geo} + (1 \u2013 \\alpha) L_{xyz},(10)\nwhere $\\alpha \\in R$, a=0 corresponds to our proposed GERA-xyz, while $\\alpha \\neq 0$ corresponds to GERA-geo."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "To simulate realistic surgical scenarios, we selected the point cloud subsets of the liver, brain, stomach, and small bowel from the MedShapeNet dataset [34]. The original point clouds, consisting of 10,000 points, were downsampled to 1,024 points to mimic the sparse point clouds commonly encountered in real-world scenarios. Two benchmarks are"}, {"title": "D. Experiment Results", "content": "1) Comparisons with Other Methods on The Combined Dataset: Fig. 4 compares our method with other approaches. While FPT [6], PointPwc [25], Difflow3D [27], and Bi-pointflownet [26] have faster inference times, their registration errors of 12.80 mm, 10.01 mm, 13.51 mm, and 8.07 mm do not meet accuracy or real-time requirements. PointSetReg [24] achieves a lower error but processes only one frame per second, limiting its efficiency. In contrast, our method achieves the best result among learning-based methods with an error of 7.01 mm and real-time performance at 156 frames per second."}, {"title": "2) Results on Small Bowel Dataset", "content": "In robotic surgery, registration tests on multiple organs are often required. Additionally, point clouds collected from medical organs frequently contain substantial noise and are often incomplete in shape. To evaluate the robustness and capability of GERA, we conducted experiments on a more realistic and challenging small intestine dataset. These challenges arise from two main factors: first, the structure and distribution of the small intestine are more complex and diverse; second, the dataset is limited, containing only 131 samples, which accounts for 13% of the entire dataset. Fig. 5 qualitatively presents four small bowel samples with significant distribution differences, with noise and breakpoints highlighted in yellow boxes. Fig. 5 compares the performance of our"}, {"title": "V. CONCLUSION", "content": "In this paper, we introduced GERA, a method for real-time point cloud processing utilizing an offline geometric information constructor. We conducted experiments using MMD and a challenging small bowel dataset to validate the robustness and superiority of our approach. However, our experiments were primarily focused on the registration of individual organ data and did not consider the registration of composite objects in scenarios like scene flow. Our future research direction is to apply GERA's offline geometric encoder to the scene flow problem, aiming to achieve high-precision scene flow estimation with no time delay."}]}