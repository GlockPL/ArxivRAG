{"title": "Time-series attribution maps with regularized contrastive learning", "authors": ["Steffen Schneider", "Rodrigo Gonz\u00e1lez Laiz", "Anastasiia Filippova", "Markus Frey", "Mackenzie Weygandt Mathis"], "abstract": "Gradient-based attribution methods aim to\nexplain decisions of deep learning models but\nso far lack identifiability guarantees. Here,\nwe propose a method to generate attribu-\ntion maps with identifiability guarantees by\ndeveloping a regularized contrastive learning\nalgorithm trained on time-series data plus a\nnew attribution method called Inverted Neu-\nron Gradient (collectively named xCEBRA).\nWe show theoretically that CEBRA has\nfavorable properties for identifying the Ja-\ncobian matrix of the data generating pro-\ncess. Empirically, we demonstrate robust\napproximation of zero vs. non-zero entries\nin the ground-truth attribution map on syn-\nthetic datasets, and significant improvements\nacross previous attribution methods based on\nfeature ablation, Shapley values, and other\ngradient-based methods. Our work consti-\ntutes a first example of identifiable inference\nof time-series attribution maps and opens\navenues to a better understanding of time-\nseries data, such as for neural dynamics and\ndecision-processes within neural networks.", "sections": [{"title": "1 Introduction", "content": "The distillation of knowledge from data is a core tenet\nof science. In neuroscience, where high-dimensional\nand large-scale data are becoming increasingly avail-\nable, a better understanding of how the input data\nis shaping the distilled knowledge is a key challenge.\nModern approaches for extracting information for neu-\nral time-series data are leveraging deep learning mod-\nels to extract latent dynamics. Yet, the nature of how\nindividual neurons can be mapped to these population-\nlevel latents is unknown. Similarly to computer vision,\nwhere pixels are attributed to classification decisions,\nour aim is to understand how individual neurons con-\ntribute to the neural code over time.\nIn machine learning, especially in computer vision,\nmany algorithms exist for explaining the decisions of\ntrained (non-linear) neural networks, often on static-\nimage classification tasks (Samek et al., 2019; An-\ncona et al., 2017; Shrikumar et al., 2016; Sundarara-\njan et al., 2017; Montavon et al., 2015; Simonyan\net al., 2013; Lundberg and Lee, 2017). In particu-\nlar, gradient-based attribution methods have shown\nempirical success, but can be computationally costly\nand/or lack theoretical grounding (Simonyan et al.,\n2013; Lundberg and Lee, 2017), which ultimately lim-\nits their utility and scope in scientific applications that\nbenefit from theoretical guarantees.\nWe consider the problem of estimating time-series at-\ntribution maps for the purpose of scientific, neural\ndata analysis. Concretely, in neuroscience, various\npopulations of neurons are recorded over time, and\none aims to understand how these neurons relate to\nobservable behaviors or internal states (Figure 1). For\ninterpretability, linear methods (such as PCA or lin-\near regression) are often used, even though the un-\nderlying data did not necessarily arise from linear pro-\ncesses. However, non-linear methods are difficult to in-\nterpret (Breen et al., 2018; Samek et al., 2019). Emerg-\ning approaches leverage latent variable models, which\nare particularly well suited to extract the underlying\ndynamics, but how these abstract latent factors map\nonto neurons remains an open challenge.\nHere, we build on recent advances using time con-\ntrastive learning with auxiliary variables, as it showed\nconsiderable promise in its performance for recover-\ning latent spaces with identifiability guarantees, both\ntheoretically and empirically (Hyvarinen and Morioka,\n2016; Hyvarinen et al., 2019; Schneider et al., 2023;\nZimmermann et al., 2021)."}, {"title": "2 Identifiable attribution maps", "content": "A critical application of attribution methods is to in-\nvestigate properties of a trained neural network, e.g.,\na computer vision model classifying images. In many\nscientific domains, data comes in the form of time-\nseries (videos, neural recordings, etc.). Therefore, in\nthis setting, we are interested in a notion of attribution\ngrounded in the ground truth connectivity - \u201cground\ntruth map\u201d - between the recorded time-series data\nand the underlying data-generating process, i.e., latent\nfactors, at each time step. Such a view on attribution\nmethods allows us to connect the attribution map to\nthe causal structure of the data generating process,\nwhich we outline in the following:\nDefinition 1 (Data generating process). We assume\nthat data is generated from a set of latent factors\n$Z_1 \\in \\mathbb{R}^{d_1},...,Z_G \\in \\mathbb{R}^{d_G}$. For brevity, the vector\n$z\\in \\mathbb{R}^d$ denotes the concatenation of all factors, and\n$d = \\sum_i d_i$. Their distribution for the timestept fac-\ntorizes to\n$p(z^{(t)}|z^{(t-1)}) = \\prod_{i=1}^G p(z_i^{(t)} | z^{(t-1)})$, (1)\ni.e., factors are conditionally independent given their\nvalue at the previous time step $z^{(t-1)}$. The support of\nthe resulting marginal distributions $p(z_i)$ is assumed\nto be a convex body or the hypersphere embedded in\n$\\mathbb{R}^{d_i}$. The conditional distribution is assumed to\ntake the form\n$\\forall i \\in [G]: p(z_i^{(t)} | z^{(t-1)}) \\propto exp(-\\delta(z_i^{(t)}, z^{(t-1)}))$, (2)\nfor each latent factor, based on the negative dot-\nproduct or a semi-metric $\\delta: Z \\times Z \\to \\mathbb{R}$. An injective\nmixing function $g : Z \\to X$ with $X \\subset \\mathbb{R}^D$ maps latent\nfactors to observations,\n$\\forall i \\in [D] : x_i = g_i([Z_j]_{j\\in P_i})$. (3)\n$P_i$ is an index set, and $j\\in P_i$ implies that factor $z_j \\in$\n$\\mathbb{R}^{d_j}$ is used to generate the output $x_i$.\nSome factors are connected to auxiliary variables $c_i$\nthrough bijective maps $\\Upsilon_i : \\mathbb{R}^{d_i} \\to \\mathbb{R}^{d_i}$ s.t. $z_i = \\Upsilon_i(c_i)$,\nas exemplified in Figures 1 & 2.\nWe proceed with a rigorous definition of identifiability\nfor time-series attribution maps. Identifiability in the\ncontext of deep learning models is commonly studied\nin terms of indeterminacies in the inferred latent space\n(Khemakhem et al., 2020; Roeder et al., 2021). Under\nthe data-generating framework defined above, consider\na feature encoder $f : X \\mapsto Z$ which maps observable\ndata to an embedding space. The feature encoder is"}, {"title": "3 Regularized Contrastive Learning", "content": "We now propose a new estimation algorithm for time-\nseries attribution maps under the data generating pro-\ncess in Def. 1, and later show that it satisfies the\nnotion of identifiability in Def. 3. We introduce a\nnew variant of contrastive learning for estimation of\ntime-series attribution maps, which we call CEBRA\n(explainable). Specifically, we build on our previous\nwork CEBRA Schneider et al. (2023). As we show in\nour theoretical results, this extended algorithm iden-\ntifies latent factors underlying the dataset, and then\nattributes them to the input data conditioned on ob-\nservable, auxiliary variables.\nIn the following, we call $p(..)$ the positive and $q(..)$\nthe negative sample distribution. We call $(x,x^+)$ a\npositive pair, and all $(x, x_i)$ for $i \\in [N]$ negative pairs.\nThe auxiliary variables shape the positive distribution,\nand hence the positive pairs. x is the input time-series\ndata, for example neural activity recorded from the\nbrain (Figure 1).\nWe define a feature encoder $f := [f_1;...; f_G]$, with\n$f_i: X \\to \\mathbb{R}^{d_i}$ that maps samples into an embedding\nspace partitioned into G groups. In practice, we pa-\nrameterize f as a single neural network and only split\nthe last layer into G different parts. For training, we\napply similarity metrics $d_i: \\mathbb{R}^{d_i} \\times \\mathbb{R}^{d_i} \\to \\mathbb{R}$ to the\ndifferent parts of this feature encoder, abbreviated as\n$\\psi_i(x, y) := \\phi_i(f_i(x), f_i(y))$. We then leverage the gen-\neralized InfoNCE loss (Schneider et al., 2023),\n$\\mathcal{L}_N[\\Psi] = \\mathbb{E}_{\\substack{x\\sim p(x), \\\\ x^+ \\sim p_i(x^+|x), \\\\ x_1,...,x_N \\sim q(x_i|x)}}[l(x, x^+, \\{x_i\\}_{i=1}^N)]$, (8)\nusing the loss function\n$l(x, x^+, S) = -\\psi(x, x^+) + log \\sum_{x^-\\in S} e^{\\psi(x,x^-)}$, (9)\nwhere S denotes a set of negative examples. In addi-\ntion, we regularize the Jacobian matrix of the feature\nencoder by minimizing its Frobenius norm (Hoffman\net al., 2019). With these constraints, we propose our\nmodified objective function, which we call Regularized\nContrastive Learning, for all parts of the representa-\ntion:\n$\\mathcal{L}_N [\\Psi; \\lambda] = \\mathbb{E}_{\\substack{x\\sim p(x), \\\\ x^+ \\sim p_i(x^+|x) \\\\ \\forall i \\in [G] \\\\ x_1,...,x_N \\sim q(x_i|x)}}[\\sum_{i=1}^G l(x, x_i^+, \\{x_i\\}_{i=1}^N) + \\lambda ||J_f(x)||_F]$,\n(10)\nwhere $J_f(x)$ is the Jacobian of the feature encoder f\noptimized as part of $\\Psi$, $||\\cdot||_F$ denotes the Frobenius\nnorm and $\\lambda$ is a hyperparameter tuned based on the\nlearning dynamics. $\\lambda$ is set to the highest value pos-\nsible that still allows the InfoNCE component of the\nloss to stay at its minimum.\nIn this work, we use this method in two ways: \u201csuper-\nvised contrastive\u201d and \u201chybrid contrastive\u201d both with\n($\\lambda > 0$) or without regularization ($\\lambda = 0$). Supervised\nmeans the auxiliary information is used for all latent\ndimensions. Hybrid means some latent dimensions are\nspecifically reserved for unaccounted for latent factors\n(i.e., unsupervised \u201ctime-only'; factors that we do not\nexplicitly test with auxiliary data but want to account\nfor) and others tied to auxiliary variables (Schneider\net al., 2023).\nModel fitting. To optimize Eq. 10, we need to sam-\nple from suitable positive distributions $p_1,...,p_G$ for\neach group and a negative distribution q. If a la-\ntent factor z is connected to an observable c, we use\na variant of supervised contrastive learning with con-\ntinuous labels (Schneider et al., 2023): We uniformly\nsample a timestep t (and hence, a sample x(t)) from\nthe dataset. This timestep is associated to the la-\nbel c(t). We consider the changes of c across the\ndataset, $\\Delta_t = c(t+1) - c(t)$. We sample a timestep\n$\\tau$ uniformly, and then find the timestep t' for which\n$||c(t') - c(t) - \\Delta_\\tau||$ is minimized. This yields a positive\npair (x(t), x(t')) to feed to the model.\nIf a latent factor is not connected to an observable,\nwe leverage the time structure only (Hyvarinen and\nMorioka, 2017; Hyvarinen et al., 2019) and use adja-\ncent timesteps as positive pairs: (x(t), x(t+1)). More\ndetails about sampling are provided in the Appendix.\nObtaining attribution maps. Our attribution\nmap A is a D \u00d7 d-dimensional matrix and its entry\n$A_{ij}$ denotes if the latent at dimension j is related to\ninput dimension i. We can compute such a map for\nevery timepoint in the dataset or aggregate multiple\ntimepoints into a global map.\nAfter training f using our regularized contrastive\nlearning method, we obtain attribution maps by com-\nputing the Jacobian matrix $J_f(x)$. We then consider\nits pseudo-inverse $J_f^+(x)$ at every timestep, which we\nname the \u201cinverted neuron gradient\u201d. The estima-\ntion coincides with the \u201cneuron gradient\u201d attribution\nmethod (Simonyan et al., 2013), however this has not\nbeen paired with identifiable regularized contrastive\nlearning as proposed here.\nSimilar to Afchar et al. (2021), our work focuses on the\nproblem of clearly delineating the binary relationship\nbetween latents and input data. For this, we threshold\nthe attribution map with a variable decision threshold\n$\\epsilon$, $\\hat{A}(x) := 1\\{|J_f^+(x)| > \\epsilon\\}$ for inverted neuron gradi-"}, {"title": "4 Identifiability of \u201eCEBRA", "content": "We now derive two new results relevant for the appli-\ncation to the generation of attribution maps. Firstly,\nwe want to ensure a goodness of fit criterion for distin-\nguishing meaningful fits of the model, both in the time\ncontrastive and supervised contrastive case (Theorem\n1). Secondly, we extend identifiability of the latent\nspace to identifiability of the Jacobian (Theorem 2).\nTheorem 1. Assume $\\Psi^*$ is a minimizer of the gener-\nalized InfoNCE loss (Eq. 8) under the non-linear ICA\nproblem in Def. 1 for $N \\to \\infty$. Assume that the model\nis trained on auxiliary variables c which are indepen-\ndent of z. Then, $\\Psi^* = const.$ is the trivial solution\nwith $\\lim_{N \\to \\infty} L_N[\\Psi^*] = log N$ and the embedding col-\nlapses.\nThis result ensures that if an auxiliary variable c is not\nrelated to the data but still used during training, the\nloss remains at change level log N. Hence, we can rule\nout auxiliary variables not useful for subspace identi-\nfication, and sort them out for model fitting.\nWe proceed with studying the attribution map. The\nloss in Eq. 10 intuitively solves G non-linear demixing\nproblems using the single feature encoder f. By apply-\ning time contrastive and supervised contrastive learn-\ning to structure the embedding space, we can show:\nTheorem 2. Assume\n\u2022 A mixing function g with ground truth map $A_g$\nmaps latent factors z to a signal space such that\n$x = g(z)$ according to Def. 1.\n\u2022 The differentiable feature encoder f minimizes the\nregularized contrastive loss (Eq. 10) on the support\nof $p(z)$.\nThen, in the limit of infinite samples $N \\to \\infty$,\n\u2022 the model identifies the latent subspaces of the\nground truth process, i.e., $g(f(x)) = Bx$ with a\nblock diagonal matrix B.\n\u2022 we identify zero-entries of the ground truth at-\ntribution map $A_g$ (Def. 4) through the pseudo-\ninverse $J_f^+(x)$,\n$J_f^+(x) \\approx A_g$. (12)"}, {"title": "5 Experimental Methods", "content": "Synthetic finite time-series data design. To ver-\nify our theory, we generated a synthetic dataset fol-\nlowing Def. 1. An essential aspect of our synthetic\ndesign lies in the definition of the mixing function g\nwhich, consequently, defines the ground truth attribu-\ntion map. We split z into the factors z\u2081 and z2 (Ap-\npendix Figure 5). Figure 2 illustrates the two exper-\nimental synthetic data-generation configurations em-\nployed in this work, and Appendix Figure 8 shows the\nlearned embedding."}, {"title": "6 Simulations", "content": "Regularized, hybrid contrastive learning iden-\ntifies the ground truth attribution map. We\nbegin by experimentally testing our theory that reg-\nularized hybrid contrastive learning allows for causal\ndiscovery of time-series attribution maps. To quantify\nthis, we first consider an average auROC score across\ntime for recovering the ground truth graph structure\n(as shown in Figure 2(a)).\nConcretely, Table 1 shows the auROC for recovering\nA using combinations of training schemes. We investi-\ngate the effect of the different model properties with an\nordinary least squares (OLS) ANOVA (F = 17.0, p <\n10-5) followed by a Tukey HSD posthoc test, see Ap-\npendix D for statistical methods and full results. Both\nthe combination of regularized training followed by es-\ntimating the pseudo-inverse (p < 0.01), and combin-\ning regularized training with hybrid contrastive learn-\ning (p < 0.001) significantly outperform all considered\nbaselines, validating the claims made in Theorem 2\nempirically.\nContrastive learning is critical for large num-\nbers of latent factors. The importance of using\nhybrid contrastive learning (which can identify the la-\ntent factors) becomes most apparent with an increas-\ning number of latent factors, as we would expect in\na realistic dataset. Figure 3 shows the variation in\nperformance as we keep the dimension of observable\nfactors fixed at 2 and vary the latent dimension from\n4 to 9. Performance scales with the number of avail-\nable training samples, and we observed that increasing\ndataset size beyond 100,000 samples allows the use of"}, {"title": "7 Application to neural data analysis", "content": "We next tested the combinations of supervised (base-\nline), supervised-contrastive, and hybrid contrasting\nlearning with or without regularization using the at-\ntribution method we propose (and compare to the de-\nscribed baselines) on synthetic neural data for bench-\nmarking using RatInABox (Figure 4a; see Experimen-\ntal Methods). On this data, multiple combinations\nof methods reach the maximum possible performance\n(100% auROC), but importantly this means that our\nCEBRA method still performs very well under more\nrealistic (time and neuron number) settings (Appendix\nTable 3, Figure 4b).\nWe then examined the position attribution scores for\neach cell type. Specifically, we measured whether place\nand grid cells had a higher attribution to speed or head\ndirection (as would be desired from the ground truth\ngraph (see Appendix Figure 9). CEBRA could in-\ndeed nicely segment neurons into different types (Fig-\nure 4c-e). We also carried out experiments where we\nincreased the noise within the input data and show\nexcellent results with CEBRA (Appendix Figure 10).\nNotably, our attribution method is computationally\nfaster than integrated gradients and non-gradient\nbased approaches like feature ablation, and of com-\nparable speed as Shapley values (see Appendix Ta-\nble 4). Contrastive model training adds a 2x compu-\ntational overhead for behavior contrastive learning and\na 3x computational overhead for the hybrid mode (Ap-\npendix Table 5). This overhead comes with the ability\nto attribute inputs to latent factors and clearly defined\nbehavior of the goodness-of-fit if no connection exists\nbetween input data and auxiliary variables (Theorem\n1), i.e., visible as an embedding collapse.\nLastly, we show that our method is applicable to real-\nworld neural data recorded in rats (Gardner et al.,\n2022). We trained CEBRA (and baselines) with 2D\nposition as the auxiliary variable. We compute the\nattribution score over time and show that our method\ncan be used to attribute cells to known cell types (e.g.,\na grid cell); see Appendix C for full results."}, {"title": "8 Discussion", "content": "Our presented approach differs from other time-series\nattribution methods by considering the attribution\nmap of the data-generating process, which is partic-\nularly relevant for applications in scientific data anal-\nsis. In contrast to previous work, our attribution map\nis not with respect to a particular model, but rather\nthe data generating process itself.\nTime-series attribution. Ismail et al., 2021 dis-\ncuss multiple attribution methods in the context of\ntime-series attribution and point to their potential lim-\nitations. An early work trying to address these limita-\ntions is Dynamax Crabb\u00e9 and van der Schaar (2021).\nDynamax is a perturbation-based approach: Given\na trained time-series model, it learns a binary mask\nwhich, when applied to the input, does not meaning-\nfully change the prediction of that model. While the\ncontext is slightly different, the authors similarly to\nus define the correct masking values through non-zero\ngradients (see their Def. 2). However, unlike our no-\ntion, the definition here is with respect to the model\ntrained on the data, without a defined connection to\nthe ground truth process underlying the dataset.\nLiu et al., 2024 recently combined Dynamax-like train-\ning of an attribution mask with contrastive learning\nand the proposed ContraLSP. ContraLSP uses both\na learned mask (like in Dynamax) and the inverted\nmask to provide a stronger regularization signal to the\nmask, resulting in substantially improved performance\non several downstream tasks. Leung et al., 2023 pro-\npose WinIT which uses perturbation-based time se-\nries attribution across temporal dependencies. This\nextended the capabilities of Dynamax across multiple\ntime steps, which is relevant in a range of real-world\ntasks. However, these developments are orthogonal to\nour approach discussed here, as their main focus is on\nthe computation of the mask value, rather than its the-\noretical connection to the ground truth process. We\nanticipate that incorporating advanced mask learning\nmethods into the parameterization of our attribution\nmap might yield further improvements over our naive\naveraging method to obtain a stable attribution map.\nContrastive surrogates. Another interesting de-\nvelopment is CoRTX Chuang et al. (2023) train\nCORTX which can be considered a \u201csurrogate\u201d model\nfor generating explanations: Given an existing model\nto investigate, CoRTX trains a second model which\nmimics the sensitivity to perturbations using con-\ntrastive learning. This is an interesting connection\nto our supervised contrastive mode, as this sensitiv-\nity is an auxiliary variable influencing the selection\nof positive pairs. However, while Chuang et al., 2023\nprovide error bounds between the surrogate and inves-\ntigate model, no connection to the ground-truth gen-\nerating process is given, as in our work. It would be\ninteresting to discuss whether this method gets con-\nceptually similar to ours as we consider the inverted\ndata generating process $g^{-1}$ as the \u201cmodel\u201d under in-"}, {"title": "9 Conclusions", "content": "We proposed a theoretically grounded approach for es-\ntimating attribution maps in time-series data based\non a newly formalized method: regularized contrastive\nlearning with inverted neuron gradients. We theoret-\nically and empirically showed that this approach can\noutperform supervised baselines. Our theoretical re-\nsults hold for fully converged contrastive learning mod-\nels with infinite data, yet our finite data experiments\nshow the effectiveness of our approach in limited data\nsettings. Although theoretically connecting the attri-\nbution score to model fit in limited data is complex,\nour work shows that the measured $R^2$ of recovering\nobservable factors aligns with theory. In neural record-\nings, many behaviors and sensory inputs - such as an-\nimal motion, stimuli, and rewards - are measurable,\nleading the field to focus on mapping neural dynam-\nics to these behaviors. Our work considers a single\ntruly latent (but potentially multi-dimensional) factor\nfor attribution, while also supporting multiple latents\nthat can be mapped to observable auxiliary variables.\nNotably, our method outperforms supervised baselines\nin this task (Figure 3).\nAdopting the contrastive learning algorithm from Hy-\nvarinen et al. (2019) could theoretically improve re-\nsults by achieving identifiability up to permutations\nand point-wise bijective transforms, yet it requires\nstricter conditions and more complex training with a\nnon-linear projection head.\nLastly, for practical applications, our chosen setup is\nquite versatile. During analysis it is always possible to\nbreak up the linear ambiguity between different latent\nfactors by specifying the dimensions (or more broadly,\nthe basis vectors of a latent subspace) to attribute to.\nThis possibility exists with our inference framework,\nand allows attribution to multiple latent factors with\nthis form of weak supervision, i.e., user input.\nOverall, our new method, xCEBRA, demonstrates a\nsignificant advancement in time-series attribution, and\nwe hope future work can leverage it to find biological\ninsights - how inputs concretely map to hidden under-\nlying factors in neural dynamics."}, {"title": "Appendix", "content": "A Proofs\nWe will now derive identifiability guarantees for the global attribution map under the model described in the\nmain paper. Given a data generating process and a ground truth global attribution map of the data generating\nprocess, we aim for a guarantee of the form\n$\\hat{J_g} \\approx J_g L$ (13)\nfor a suitable estimator $\\hat{J_g}$ up to a matrix L that scales the ground truth derivatives in $J_g$ point-wise and will\nhence not affect the \u201creal zeros\u201d in the Jacobians relevant for Def. 4.\nWe use contrastive learning to obtain a feature encoder f which identifies the ground-truth latents up to a linear\nindeterminacy. We structure this feature encoder to reconstruct different parts of the latent representation in\ndifferent dimensions of the reconstructed latent space.\nThen, we estimate the attribution map by computing the pseudo-inverse of the feature encoder\u2019s Jacobian, which\nis directly related to the Jacobian of the mixing function. To obtain the correct pseudo-inverse, we need to obtain\na minimum-Jacobian solution of the feature encoding network. We hence introduce a new regularized contrastive\nlearning objective.\nThe underlying constrained optimization problem is:\n$\\min_f ||J_f(x)||_F  s.t. \\phi_i(f_i(x), f_i(y)) = log \\frac{p_i(y|x)}{q_i(y|x)} + C(x) \\forall i \\in [G]$, (14)\nwith the positive sample distribution $p_i$ and the negative sample distribution q. We call (x, y+) the positive\npair, and all (x, y) negative pairs. In the following we define $\\phi_i(x, y) := \\phi_i(f_i(x), f_i(y))$ where $f := [f_1; ... ; f_G]$\nis the feature encoder and $\\phi_i$ are similarity metrics. We re-state the regularized contrastive learning objective\nfunction which is a relaxation of Eq. 14:\n$\\mathcal{L}_N[\\Psi; \\lambda] = \\mathbb{E}_{\\substack{x\\sim p(x), \\\\ y^+ \\sim p_i(y|x) \\forall i \\in[G] \\\\ y_1,...,y_N \\sim q(y|x)}}[\\sum_{i=1}^G(- \\phi_i(x, y_i^+) + log \\sum_{j=1}^N e^{\\phi_i(x,y_j^-)}) + \\lambda ||J_f(x)||_F^2]$,\n(15)\nIn principle, this objective is able to identify an arbitrary amount of separate factor groups (G), given sufficient\ncapacity of the model. The choice of $\\phi_i$ for the individual parts of the feature representation depends on the\nexact distribution underlying data generation, and is discussed below.\nA.1 Preliminaries\nBefore proving our results on identifiable attribution maps, it is useful to restate a few known results from the\nliterature, concerning properties of the InfoNCE loss. Hyvarinen et al. (2019) showed that contrastive learning\nwith auxiliary variables is identifiable up to permutations or linear transformations for conditionally exponential\ndistributions. Zimmermann et al. (2021) related this to identifiability for models trained with the InfoNCE\nloss, and showed that assumptions about the data-generating process can be incorporated into the choice of loss\nfunction. Schneider et al. (2023) then formulated a supervised contrastive learning objective based on selecting\nthe positive and negative distributions in the generalized InfoNCE objective.\nWe will first re-state the minimizer of the InfoNCE loss (Def. 8) used in our algorithm:\nProposition 1 (restated from Schneider et al. (2023)). Let p(\u00b7|\u00b7) be the conditional distribution of the positive\nsamples, q(\u00b7|\u00b7) the conditional distribution of the negative samples and p(\u00b7) the marginal distribution of the\nreference samples. The generalized InfoNCE objective (Def. 8) is convex in \u03c8 with the unique minimizer\n$\\psi^*(x, y) = log \\frac{p(y|x)}{q(y|x)} +C(x)$, with Lv[\u03c8\u2217] = log N \u2212 DKL(p(\u00b7|\u00b7)||q(\u00b7|\u00b7))\n(16)\nfor N \u2192 \u221e on the support of p(x), where C : Rd \u2192 R is an arbitrary mapping."}, {"title": "B.1 Synthetic finite time-series data design", "content": "We sample 10 different datasets with 100,000 samples, each with a different mixing function g. All latents of\nthe dataset are chosen to lie within the box [-1,1]D. We sample the dataset by selecting z\u2081 from a uniform\ndistribution over [-1,1]D. The following time steps are generated by Brownian motion, zt = N[-1,1](zt\u22121,\u03c32I)\nwhere N[-1,1] is a truncated normal distribution clipped to the bounds of the box. All other latent factors are\nsampled accordingly. The process is outlined in Figure 5.\nSimilar to Schneider et al. (2023), the feature encoder f is an MLP with three layers followed by GELU activations\n(Hendrycks and Gimpel, 2016), and one layer followed by a scaled tanh to decode the latents. We train on batches\nwith 5,000 samples each. The first 2,500 training steps minimize the InfoNCE or supervised loss with \u03bb = 0; we\nthen ramp up \u03bb to its maximum value over the following 2,500 steps, and continue to train until 20,000 total\nsteps. We compute the $R^2$ for predicting the auxiliary variable c from the feature space after a linear regression,\nand ensure that this metric is close to 100% for both our baseline and contrastive learning models to remove\nperformance as a potential confounder."}, {"title": "B.2 Simulated (RatInABox) neural data.", "content": "As an application to a neuroscientific use case, we generate synthetic neural data during navigation using RatIn-\nABox (George et al., 2024), a toolbox that simulates spatial trajectories and neural firing patterns of an agent in\nan enclosed environment. We generate a trajectory with a duration of 2000 seconds and sample every dt = 0.1s,\nresulting in 20000 time steps. We use the default environment and simulate place, two modules of grid, head\ndirection, and speed cells (n=100 neurons each, 400 neurons in total). Place cells are modeled as a difference\nof Gaussians with width=0.2m; grid cells are modeled as three rectified cosines with two grid modules with\nmodule scales set to 0.3 and 0.4; for all other cells, we use the RatInABox default values. As all neurons within\nRatInABox are rate-based we use the firing rate of the cells for all subsequent analysis. For all cells we then\ncalculate the spatial information criteria $SI = \\sum_i P_i log_2(\\frac{r_i}{\\bar{r}})$ where $P_i$ is the probability of the stimulus being\nin the ith spatial bin, $r_i$ is the estimated firing rate in the ith spatial bin and $\\bar{r}$ is the overall average estimated\nfiring rate (Skaggs et al., 1996).\nTo calculate the grid scores we used the method described by Sargolini et al. (2006). Briefly, we first calculate\nratemaps for each cell, which we use to calculate Spatial Auto-Correlograms (SAC). We then rotate the SAC at\nmultiple angles and determine the correlation coefficients in comparison with the unaltered SAC. The highest\ncorrelation score obtained at rotations of 30, 90, and 150 degrees is deducted from the lowest score observed at\n60, 90, and 120 degrees rotation. This value is denoted as the grid score."}, {"title": "C Additional Experimental Results", "content": "Uncovering the Correct Dimensionality in regularized contrastive learning. We conducted experi-\nments aimed at identifying the correct dimensionality in our regularized contrastive learning algorithm, xCEBRA.\nThe experimental setup follows the procedure detailed in Appendix B.1, where the true dimensionality is 6D\n(3D+3D). Instead of also fixing the dimensionality of our model to 6D, we vary the model dimensionality from 2D\\"}]}