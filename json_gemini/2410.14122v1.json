{"title": "TOWARDS ROBUST TRANSCRIPTION: EXPLORING NOISE INJECTION STRATEGIES FOR TRAINING DATA AUGMENTATION", "authors": ["Yonghyun Kim", "Alexander Lerch"], "abstract": "Recent advancements in Automatic Piano Transcription (APT) have significantly improved system performance, but the impact of noisy environments on the system performance remains largely unexplored. This study investigates the impact of white noise at various Signal-to-Noise Ratio (SNR) levels on state-of-the-art APT models and evaluates the performance of the Onsets and Frames model when trained on noise-augmented data. We hope this research provides valuable insights as preliminary work toward developing transcription models that maintain consistent performance across a range of acoustic conditions.", "sections": [{"title": "1. INTRODUCTION", "content": "Automatic Music Transcription (AMT) is a fundamental task in Music Information Retrieval (MIR), aiming to convert audio recordings into symbolic representations, such as the Musical Instrument Digital Interface (MIDI) format. As a foundational task in Music Information Retrieval (MIR), AMT has broad applications in music education, search, creation, and musicology [1]. While AMT in general targets all musical instruments and efforts have been made for a variety of instruments [2-4], the majority of research has focused on transcribing solo piano performances [5-12]. Recent advancements in piano transcription have led to significant improvements, particularly in onset detection; models trained on the MAESTRO dataset [7] have achieved onset F1 scores exceeding 95% [4,8-12]. However, these results are typically based on evaluations using very clean data. Thus, the robustness of these piano transcription systems in real-world scenarios remains largely unexplored. Some previous work shows how performance degrades in altered acoustic environments [13] and how robustness can be improved through data augmentation [7, 13].\nDespite the proven benefits of data augmentation in improving model robustness, there are no established guidelines for prioritizing specific techniques in AMT. While various studies have explored different data augmentation methods [7, 13, 14], there is limited clarity on how to apply these techniques effectively. For instance, when employing noise injection, several key factors must be considered, such as the type of noise (e.g., white, pink, environmental), the Signal-to-Noise-Ratio (SNR), and the ratio of clean to augmented data. However, to the best of our knowledge, these parameters are often chosen arbitrarily, highlighting the need for further investigation in this area.\nIn this study, we investigate the impact of white noise injection, a widely adopted technique in audio research [15-17], on piano transcription. Our analysis has two primary goals, (i) to assess the performance degradation of AMT systems across various SNR levels, and (ii) to demonstrate the effectiveness of white noise injection in enhancing the robustness of the transcription."}, {"title": "2. EXPERIMENTS", "content": "This section outlines the experimental methods and summarizes the results. Due to the page limit constraints, detailed numerical results are not included in the main text but can be accessed, along with the experimental code, on GitHub.\n2.1 Exp. 1: Impact of Noise on Pre-Trained Systems\nRecording piano performances in uncontrolled environments often results in widely varying SNRs due to lack of high quality equipment, background noise, reverberation, and other environmental factors. In such settings, the SNR tends to be lower than in controlled professional environments such as studios. To rigorously assess the robustness of the models under these conditions, we evaluated their performance across a broad range of SNR values, ranging from -6 dB to 45 dB, in 3 dB intervals, covering a total of 18 different SNR levels.\nFor this experiment, we utilized two state-of-the-art models: Onsets and Frames [5] and the model proposed by Kong et al. [8]. The Kong et al. model was tested using a publicly available pre-trained checkpoint, while the Onsets and Frames [5] model was re-implemented using the PyTorch framework, following the original training procedures and specifications outlined in the respective papers.\nWe generated white noise-augmented versions of the MAESTRO v3 [7] dataset for inference. The test split, consisting of 177 recordings, was used for evaluation as defined in the dataset's metadata. To create the augmented"}, {"title": "2.2 Exp. 2: Effect of Noise Injection during Training", "content": "To investigate whether performance degradation in noisy environments can be mitigated through data augmentation, we employed the Onsets and Frames model [5], training it with white noise-injected audio. We introduce the term Clean-to-Noise Ratio (CNR) to represent the proportion of clean to noise-injected audio sampled during training. Based on the hypothesis that the level of perturbation impacts performance, we trained the model using CNR levels of 0 (fully perturbed), 1/3, 1, 3, and \u221e (clean audio only). For each CNR, the model probabilistically samples from the clean or noisy audio. In case of noisy audio, the SNR dB value is randomly sampled from [0, 24], followed by RMS normalization and clipping prevention. This SNR range was chosen based on prior research [7,13] and results from Sect. 2.1, where significant performance degradation was observed.\nWe followed the original Onsets and Frames [5] configuration throughout the training process, standardizing the number of iterations to 100k for all experiments. This decision was based on preliminary experiments with noise-injected audio, which showed that increasing the number of iterations beyond 100k did not result in lower losses.\nThe performance evaluation of the trained models is presented in Figure 2.\nWe observe that the the systems trained with noisy data all considerably outperform the system trained with clean data for low SNRs. As the SNR increases, the gap de-"}, {"title": "3. CONCLUSION", "content": "This study highlights the importance of white noise injection in improving the robustness of APT models for diverse acoustic conditions. By introducing CNR, we show that under the right conditions, noise-injected training enhances performance at lower SNR levels and is on par at high SNRs. The findings emphasize the need for carefully selecting the data augmentation parameters and imply that increased robustness to different noise environments does not need to come at a cost for clean environments. In fact, there might be ways to gain significant improvements across all SNR levels. Future work will investigate the impact on training data augmentation on other AMT systems, as well as extend data augmentation settings to be investigated."}]}