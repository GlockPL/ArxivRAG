{"title": "Enhancing Financial VQA in Vision Language Models using Intermediate Structured Representations", "authors": ["Archita Srivastava", "Abhas Kumar", "Rajesh Kumar", "Prabhakar Srinivasan"], "abstract": "Chart interpretation is crucial for visual data analysis, but accurately extracting information from charts poses significant challenges for automated models. This study investigates the fine-tuning of DEPLOT, a modality conversion module that translates the image of a plot or chart to a linearized table, on a custom dataset of 50,000 bar charts. The dataset comprises simple, stacked, and grouped bar charts, targeting the unique structural features of these visualizations. The fine-tuned DEPLOT model is evaluated against its base version using a test set of 1,000 images and two metrics: Relative Mapping Similarity (RMS), which measures categorical mapping accuracy, and Relative Number Set Similarity (RNSS), which evaluates numerical interpretation accuracy. To further explore the reasoning capabilities of large language models (LLMs), we curate an additional set of 100 bar chart images paired with question-answer sets. Our findings demonstrate that providing a structured intermediate table alongside the image significantly enhances LLM reasoning performance compared to direct image queries.", "sections": [{"title": "1. INTRODUCTION", "content": "In today's data-driven world, data visualization plays a crucial role in conveying complex information clearly and effectively. Charts, such as bar charts, line charts, and pie charts, are fundamental tools for this purpose, widely applied across domains like finance, healthcare, business intelligence, and scientific research to support decision-making. However, accurately extracting and interpreting information from charts remains a significant challenge for automated models due to the wide variation in chart structures, configurations, and complexities. This difficulty is especially pronounced in domain-specific applications, where visualizations often possess unique characteristics tailored to specialized data needs.\nDEPLOT [1] introduces a modality conversion module that maps visual chart data into structured data tables, effectively translating visual features into data representations. Although DEPLOT is trained on diverse chart types, it can achieve enhanced accuracy through fine-tuning on domain-specific datasets. This targeted approach enables the model to learn the distinctive features and attributes of specific chart types, improving both categorical mapping and numerical interpretation. Once accurate intermediate tables are generated, large language models (LLMs) [2] can leverage their few-shot learning capabilities for advanced reasoning and querying tasks.\nTo evaluate the effectiveness of the fine-tuned model, we employ two key metrics: Relative Number Set Similarity (RNSS) [3], [4] and Relative Mapping Similarity (RMS). RNSS measures the relative accuracy of predicted numerical values compared to ground-truth data, tolerating minor transpositions and small errors. RMS assesses the accuracy of categorical label mappings, accounting for textual and numerical distances between predicted and actual entries. By calculating RMS precision, recall, and F1 scores, we comprehensively evaluate the model's ability to interpret table structures while remaining invariant to row and column permutations.\nOur results demonstrate that fine-tuning DEPLOT on a custom dataset significantly improves its ability to accurately interpret both categorical and numerical aspects of bar chart data. This approach establishes a framework for adapting DE-PLOT to various domains by tailoring datasets to specific chart types or configurations, paving the way for the development of highly accurate, domain-specific models for data visualization analysis. By highlighting the benefits of targeted fine-tuning, this research advances the field of visual-language models for automated chart interpretation, enabling more reliable and adaptable data extraction from visualizations."}, {"title": "2. PROBLEM STATEMENT", "content": "Charts are a cornerstone of data visualization, widely used to represent categorical data and facilitate comparisons across groups. However, their structural diversity and domain-specific configurations pose significant challenges for automated interpretation. Current systems struggle to extract and interpret in-"}, {"title": "3. PRIOR METHODOLOGIES", "content": "The field of automated chart interpretation has seen two primary methodological approaches: hybrid systems and end-to-end models. Hybrid systems combine optical character recognition (OCR), keypoint detection, and object segmentation with hand-engineered rules to extract chart data [5], [4], [3]. While effective for simple scenarios, these systems face scalability challenges due to their reliance on domain-specific rules and manual configuration.\nEnd-to-end models, on the other hand, bypass intermediate steps by directly interpreting visual chart data [6] [7]. Although promising, these methods demand extensive fine-tuning on specialized datasets, limiting their adaptability and performance in handling complex or novel chart configurations.\nDEPLOT [1], a modality conversion module, bridges the gap by translating visual chart data into structured tables. This intermediate representation enables downstream models, such as large language models (LLMs), to perform reasoning tasks with enhanced accuracy. Despite its versatility, the base DEPLOT model struggles with domain-specific charts, necessitating fine-tuning to improve its performance for specific applications."}, {"title": "4. OUR PROPOSED SOLUTION", "content": "To address the limitations of existing methods, we propose fine-tuning the DEPLOT model on a custom dataset of 50,000 bar charts, including simple, stacked, and grouped configurations. This targeted fine-tuning allows the model to better capture the unique structural features of bar charts, enhancing its ability to generate accurate categorical mappings and numerical interpretations. By leveraging intermediate structured table representations generated by the fine-tuned DEPLOT model, large language models (LLMs) can more effectively reason and answer questions about chart data.\nOur approach includes evaluating the fine-tuned model using two metrics: Relative Number Set Similarity (RNSS) and Relative Mapping Similarity (RMS). RNSS assesses numerical accuracy by comparing predicted values to ground-truth data, while RMS measures the precision, recall, and F1 scores of categorical label mappings. These metrics ensure a comprehensive evaluation of the model's interpretative capabilities.\nIn addition to enhancing DEPLOT's performance, we analyze the reasoning abilities of LLMs when provided with intermediate structured tables. Three experimental scenarios are considered:\n1) Query and image only,\n2) Query, image, and a table generated by the fine-tuned DEPLOT model (Ft), and\n3) Query, image, and a table generated by the base DE-PLOT model (Bt).\nOur findings demonstrate that accurate table representations significantly enhance LLM reasoning capabilities, with smaller models like Qwen2-VL-7B [8] outperforming larger counterparts such as GPT-40 when provided with high-quality structured data. This research highlights the transformative potential of integrating modality conversion and fine-tuning to advance automated chart interpretation and reasoning."}, {"title": "5. DATASET CREATION", "content": "The performance of machine learning models, particularly those designed for chart interpretation like DEPLOT, relies heavily on the quality, diversity, and relevance of the training and evaluation datasets [9] [10]. In this study, we introduce a dataset of 50,000 bar charts, meticulously designed to represent financial applications. This dataset encompasses a wide range of financial metrics and concepts, providing the contextual depth needed to fine-tune DEPLOT for financial chart analysis. While tailored for financial applications, the methodology and techniques used in creating this dataset are highly adaptable and can be extended to other domains or chart attributes with minimal modification."}, {"title": "5.1 Dataset Characteristics", "content": "To capture a wide range of potential scenarios, key elements of the bar charts were randomized using a curated list of domain-specific labels and values tailored to financial applications. The randomized elements include:\nTitles: A diverse array of financial chart titles was generated, such as \u201cQuarterly Revenue Growth,\u201d \u201cMarket Share by Region,\u201d and \u201cProfitability Comparison.\u201d These titles were carefully curated to reflect common themes in financial reporting and analysis, ensuring realistic context during chart generation.\nX-Axis Labels: The x-axis labels, typically representing time or categories, included options like \"Fiscal Quarter,\" \"Region,\" and \"Product Category.\" These were selected from a predefined list of terms relevant to financial analysis, ensuring contextual alignment with the domain.\nY-Axis Labels: The y-axis reflected financial metrics such as \"Revenue ($),\u201d \u201cProfit Margin (%),\" and \"Market"}, {"title": "Capitalization ($B).", "content": "Randomized selection from a comprehensive list ensured clarity and relevance to financial data representation."}, {"title": "Categories:", "content": "Categories, representing data groupings such as financial years, regions, or product lines, were randomly assigned. This diversity helps the model generalize across various financial contexts."}, {"title": "Bar Ranges:", "content": "Value ranges for the bars were randomly generated to reflect realistic financial variations, including both positive and negative values. This aspect accurately represents the dynamic nature of financial data."}, {"title": "Bar Types:", "content": "The dataset incorporated multiple chart types, including simple, stacked, and grouped bar charts. Each type offers unique visual representations, enriching the dataset's diversity."}, {"title": "Bar Orientation:", "content": "Both horizontal and vertical bar orientations were included to ensure the model could interpret financial data regardless of layout."}, {"title": "Annotations:", "content": "Some charts featured numerical annotations directly on the bars, while others omitted them. This variability introduces an additional layer of complexity, enabling the model to learn from both annotated and non-annotated visual cues.\nBy randomizing these elements from a well-structured list, we ensure that the dataset is not only diverse and comprehensive but also specifically tailored to reflect the nuances of financial data representation. This careful design enhances the model's ability to understand and interpret a wide range of financial charts accurately."}, {"title": "5.2 Generalizability to Other Domains", "content": "While the current dataset is tailored for financial applications, the methodology developed in this study is highly adaptable and can be extended to create datasets for a wide range of industries and domains.\nThe core approach involves customizing chart elements such as titles, axis labels, categories, and annotations to align with domain-specific terminology and concepts. This ensures that the model interprets charts within their appropriate context, whether they pertain to financial data, healthcare metrics, or marketing performance.\nFor example, in the healthcare domain, chart titles could include \"Patient Survival Rates by Treatment\u201d or \u201cHospital Admissions by Disease Type,\" with corresponding y-axis labels such as \"Survival Rate %\" or \"Number of Admissions.\" The bars could represent data points like diseases, treatment types, or patient demographics, randomized to create a diverse and robust dataset. Similarly, in the marketing sector, potential titles might be \"Ad Performance Over Time\u201d or \u201cRevenue Growth by Region,\" with y-axis labels such as \u201cConversion Rate %\" or \"Sales Revenue $.\"\nThis versatile methodology allows for the development of specialized datasets across domains, enabling the fine-tuning of DEPLOT or similar models for various real-world applications. This approach transforms DEPLOT into a specialized tool that enhances its chart interpretation capabilities, enabling it to address sector-specific tasks effectively."}, {"title": "5.3 Synthetic Training Data Generation", "content": "The bar charts for this dataset were generated using Python's Matplotlib [11] and Seaborn [12] libraries, offering a wide range of customization options for creating diverse, visually complex charts. Each chart was saved as an image file (e.g., .png) with an accompanying structured JSON file that contains the textual description necessary for model training. This textual description serves as the ground truth that aligns with the visual content of the chart.\nTo maintain consistency with the output format of the base DEPLOT model, we structured the textual descriptions carefully. Below are examples of the textual descriptions for various chart types, reflecting different layouts and their corresponding labels.\nGeneral Structure of the Textual Descriptions\nTITLE: The title of the chart, which varies according to the chart's context and the domain.\nX-Axis Label: Denotes the category or dimension of the data, such as financial metrics, time periods, or regions. This label will change depending on the layout and type of data being represented (e.g., fiscal year, product category, or market region).\nY-Axis Label: Represents the metric or value being measured, such as revenue, costs, or growth percentages. This label is adjusted according to the specific chart layout.\nCategories and Values: For each category on the x-axis, the corresponding value(s) for the y-axis are listed. Depending on the chart layout (simple, stacked, or grouped), the values are presented differently:\nFor simple bar charts, each category will have a single value associated with it.\nFor stacked bar charts, multiple values are stacked for each category to represent different sub-metrics.\nFor grouped bar charts, multiple bars are grouped together for each category, each representing a different group or series.\nThe \"|\" delimiter separates columns (i.e., labels and values), while \"<0x0A>\" marks the end of each row, ensuring proper parsing and structure for the model to interpret the data accurately.\nExample Textual Descriptions for Different Chart Types\n1. Simple Vertical Bar Chart: An example chart, Fig. 1, is provided to illustrate the syntax of a simple vertical bar chart along with its corresponding ground truth representation.\n\u201cTITLE |{Chart Title} <0x0A> {X-Axis Label} |{Y-Axis Label} <0x0A> {Category_1} |{Value_1} <0x0A> {Category_2} |{Value_2} ...\u201d"}, {"title": "Example:", "content": "\u201cTITLE Strategic Human Capital Management <0x0A> Content Engagement Metric Asset Turnover Ratio <0x0A> Billing 62 <0x0A> Equity |84 <0x0A> Sales 65 <0x0A> Income |-68 <0x0A> Depreciation |33 <0x0A> Valuation |-25 <0x0A> Loans |-25\u201d"}, {"title": "2. Stacked Horizontal Bar Chart:", "content": "An example chart, Fig. 2, is provided to illustrate the syntax of a stacked horizontal bar chart along with its corresponding ground truth representation.\n\u201cTITLE |{Chart Title} <0x0A> {Y-Axis Label} |{Stack_A} |{Stack_B} <0x0A> {Category_1} |{Value_1_A} |{Value_1_B} <0x0A> {Category_2} |{Value_2_A} |{Value_2_B} ...\u201d"}, {"title": "Example:", "content": "\"TITLE Financial Metrics <0x0A> Operating Profit Soci\u00e9t\u00e9 G\u00e9n\u00e9rale Bank of China <0x0A> Expenditures 366 352 <0x0A> Accounts 482 421 <0x0A> Audit |167 386 <0x0A> Subsidies 358 253 <0x0A> Profit 421 147 <0x0A> Revenues |314 |228\""}, {"title": "3. Grouped Vertical Bar Chart:", "content": "An example chart, Fig. 3, is provided to illustrate the syntax of a grouped vertical bar chart along with its corresponding ground truth representation.\n\u201cTITLE |{Chart Title} <0x0A> {X-Axis Label} |{Group_A} |{Group_B} |{Group_C} <0x0A> {Category_1} |{Value_1_A} |{Value_1_B} |{Value_1_C} <0x0A> {Category_2} |{Value_2_A} |{Value_2_B} |{Value_2_C} ...\u201d\nEach description ensures that all chart types\u2014whether simple, stacked, or grouped\u2014are consistently formatted, with labels and categories adjusted according to the layout. The data is structured to support effective training of the DEPLOT model by providing a rich, diverse dataset that reflects various financial scenarios and chart configurations."}, {"title": "6. EVALUATION OF BASE DEPLOT MODEL ON CUSTOM DATASET", "content": "In this section, we evaluate the performance of the base DEPLOT model on 1,000 generated test images across three bar chart types simple, stacked, and grouped. The model's accuracy is assessed using two metrics: Relative Number Set Similarity (RNSS) and Relative Mapping Similarity (RMS), both of which offer different insights into the alignment between the predicted output and the target data. The RNSS metric focuses on numeric accuracy, while RMS provides a comprehensive evaluation by incorporating structural information and alignment between the row-column mappings."}, {"title": "6.1 Metrics Overview", "content": ""}, {"title": "A. Relative Number Set Similarity (RNSS):", "content": "The RNSS metric [3] is used to evaluate the similarity between the sets of numeric entries predicted by the model and those in the target table. This metric assesses how closely the set of predicted numbers aligns with the ground-truth values in the target table without considering the position of these values.\nTo compute RNSS, let $P = {p_i}_{1<=i<=N}$ represent the set of model-predicted numbers in the table and $T = {t_j}_{1<=j<=M}$ represent the numbers in the target table. A threshold of 10% is applied to account for minor deviations, allowing predicted values $p_i$ to be considered correct if they lie within \u00b110% of the corresponding ground-truth values $t_j$.\nThe relative distance $D(p, t)$ between each predicted and target number is calculated as:\n$D(p, t) = min (1, \\frac{|p - t|}{|t|})$\nThe final RNSS score is then computed by finding the minimal cost matching between elements in $P$ and $T$ using a binary matrix $X \u2208 R^{N\u00d7M}$. The score is defined as:\n$RNSS = 1 - \\frac{\\sum_{i=1}^{N} \\sum_{j=1}^{M} X_{ij} D(p_i, t_j)}{max(N, M)}$\nHowever, RNSS has limitations for evaluating complex tables:\nIt overlooks the positional information of numbers within the table.\nNon-numeric content is ignored, which may lead to inaccurate assessments when tables include text.\nIt fails to distinguish between high and low relative errors, which can result in imprecise evaluations.\nRNSS does not account for precision versus recall losses in table reconstruction, limiting its utility for detailed accuracy assessments."}, {"title": "B. Relative Mapping Similarity (RMS) :", "content": "The RMS metric was developed to address the limitations of RNSS by evaluating both numeric and textual content while accounting for the structural layout of the table. RMS interprets tables as a collection of mappings from row and column headers to values, enabling a comparison that respects both value accuracy and positional consistency.\nLet, Each entry in the predicted table $P$ be represented as $p_i = (p_{ri}, p_{ci}, p_{vi})$, where $p_{ri}$ and $p_{ci}$ are row and column headers, and $p_{vi}$ is the value. Similarly, each entry in the target table $T$ be represented as $t_j = (t_{rj}, t_{cj}, t_{vj})$.\nThe RMS metric computes both precision and recall scores based on pairwise distances between corresponding entries in P and T. The distance for textual entries is calculated with Normalized Levenshtein Distance (NL) [13], and for numeric entries, with the relative distance $D_0(p,t)$, defined as:\n$D_0(p, t) = min (1, \\frac{|p - t|}{|t|})$\nFor each entry pair $(p_i,t_j)$, the similarity $D_{r,e}(p,t)$ is calculated as:\n$D_{r,e}(p, t) = (1 \u2013 NL_\u03c4(p_r||p_c, t_r||t_c)) \\cdot (1 \u2013 D_0(p_v, t_v))$\nwhere $||$ denotes string concatenation, and the parameter \u03c4 limits partial credit for highly dissimilar texts.\nThe RMS Precision and RMS Recall scores are computed by summing similarities over matched entries:\n$RMS Precision = 1 - \\frac{\\sum_{i=1}^{N} \\sum_{j=1}^{M} X_{ij} D_{\u03c4,0}(p_i, t_j)}{N}$\n$RMS Recall = 1 - \\frac{\\sum_{i=1}^{N} \\sum_{j=1}^{M} X_{ij} D_{\u03c4,0}(p_i, t_j)}{M}$\nThe RMS F1 Score, representing overall performance, is computed as the harmonic mean of RMS Precision and RMS Recall:\n$RMS F1 Score = 2 \\cdot \\frac{RMS Precision \\cdot RMS Recall}{RMS Precision + RMS Recall}$\nThis score is invariant to row and column transpositions, making it well-suited for evaluating structured table data."}, {"title": "6.2 Evaluation of Base DEPLOT Model on Custom Dataset", "content": "Our dataset for testing the base DEPLOT model includes 1,000 bar charts distributed as follows:\n500 Simple Bar Charts\n300 Stacked Bar Charts\n200 Grouped Bar Charts\nThe RNSS and RMS scores for each chart type are recorded to analyze the model's performance on both numeric accuracy and structural mapping and the averages were reported as follows for the Base DEPLOT Model:\nAverage RNSS: 89.67%\nAverage RMS F1 Score: 50.93%"}, {"title": "7. FINE-TUNING DEPLOT ON THE CUSTOM BAR CHART DATASET", "content": "Accurate representation of charts as structured tables is crucial for facilitating efficient querying and reasoning, especially when leveraging the zero/few-shot inference capabilities of large language models (LLMs). In particular, a well-defined table structure enhances the model's ability to perform complex reasoning tasks without the need for extensive retraining. The accurate mapping of chart elements (e.g., axis labels, categories, and values) into tables provides a structured format that is more easily parsed by the LLM, facilitating tasks such as data extraction, trend analysis, and question answering. In turn, this structure empowers users to query the model effectively.\nIn this section, we describe the process of fine-tuning the DEPLOT model on a specialized dataset of 50,000 financial bar chart images. The dataset is divided as follows: 50% simple bar charts, 30% stacked bar charts, and 20% grouped bar charts. This distribution ensures that the model is exposed to a wide range of chart structures, improving its ability to handle diverse visualization types. This fine-tuning is intended to enhance the model's accuracy and specificity in interpreting bar charts that include financial data. The fine-tuning is conducted using structured data on financial metrics, making the model more proficient in financial terminology, numerical patterns, and chart layouts common in finance."}, {"title": "7.1 Dataset Preparation", "content": "The dataset used for fine-tuning comprises 50,000 image-text pairs, where each image represents a bar chart and the corresponding ground truth table (Gt) provides a structured syntax representation of the underlying data for the chart. Each data point includes (As shown in Fig 4, 5, and 6) :\nImage Data: Each bar chart is saved as an image file, representing a visualization of financial data in various formats.\nText Data (Gt): Each chart has a corresponding text-based data table with proper syntax. The table text includes information like the chart title, labels, and values for each category, mirroring the layout of the bar chart."}, {"title": "7.2 Model Configuration and Dataset Processing", "content": "To effectively train DEPLOT, the model configuration and data processing are tailored for bar chart interpretation.\nModel Initialization: The fine-tuning uses the DEPLOT model pre-trained on general chart data. This model serves as a foundation, and it is then further trained to specialize in financial bar charts through the custom dataset.\nText Processing: The textual data from each table is processed with tokenization and padding, which are essential for consistent input format across different chart types. These steps ensure that the textual ground truth for each image is aligned with the structure that the DEPLOT model expects."}, {"title": "7.3 Training Procedure", "content": "The fine-tuning process is conducted over multiple epochs with the goal of improving DEPLOT's performance on financial bar charts.\nTraining Configuration: The fine-tuning is set to run for 10 epochs, with the model leveraging an AdamW optimizer to update weights effectively and maintain stability in the learning process. The training is conducted on a NVIDIA H100 GPU to speed up the process.\nTraining Loop: For each epoch, the model processes batches of images and text data from the dataset. In each batch, the model is prompted to generate the data table that corresponds to the input image, effectively \"learning\" the relationships between the visual representation and the underlying numerical data. The model computes loss values during this process, which measure the difference between the predicted and actual tables, and then adjusts its weights to minimize these errors.\nCheckpointing: To monitor progress and safeguard against any potential interruptions, model weights are saved at the end of each epoch. These checkpoints serve as backup models that represent the state of the model at specific stages of training, allowing for flexibility in further analysis or adjustments.\nThis fine-tuning process aims to adjust the DEPLOT model to recognize the nuanced details of financial bar charts, refining its ability to interpret both numeric values and structural layouts within these charts. By training the model on a diverse set of bar chart examples, we ensure that it becomes proficient in decoding a variety of financial chart types, preparing it for the final evaluation phase of the study.\nThe fine-tuning process is expected to yield a model with improved capability to interpret and convert complex bar charts into structured tables, which is critical for applications in finance where precise data extraction from charts is essential."}, {"title": "8. EVALUATION OF FINE-TUNED DEPLOT MODEL", "content": "This section analyzes the improvements observed in the DE-PLOT model's performance after fine-tuning it for 10 epochs on a custom dataset of financial bar charts. We compare the fine-tuned model's scores with those of the base model to demonstrate how the specialized training data enhanced the model's interpretative accuracy."}, {"title": "8.1 Performance Metrics", "content": "To assess the improvements rigorously, we employed two primary metrics:\nRelative Number Set Similarity (RNSS): This metric measures the degree of similarity between the numeric values in the predicted and target tables. It focuses solely on numerical accuracy by comparing the sets of numbers in both tables, irrespective of order or structure.\nRelative Mapping Similarity (RMS): This metric evaluates both structural and positional similarity between the predicted"}, {"title": "7. CONCLUSION AND FUTURE DIRECTIONS", "content": "Our two-step approach-extracting tabular data from charts followed by querying LLMs with these tables-demonstrates significant improvements in numeric question-answering (QA) performance. The fine-tuning of the DEPLOT model played a pivotal role, yielding tabular data that substantially reduced MAPE and RMSE across all tested models. Notably, smaller vision-language models, when provided with refined tabular representations, outperformed larger models (such as GPT-40) operating directly on raw images. This highlights the potential of carefully designed intermediate structured representations to enhance both performance and resource efficiency in complex reasoning tasks.\nFuture research could explore several avenues to further advance this approach:\nAdaptive Data Augmentation: Leveraging synthetic charts to expand fine-tuning datasets, improving DE-PLOT's generalization to unseen data.\nModel Ensembles: Combining multiple table extraction models or integrating error-correction mechanisms to refine extracted tables further.\nMultimodal Fusion Architectures: Developing architectures that incorporate refined tabular data alongside selective visual cues for enhanced numeric reasoning.\nDespite its promising results, the proposed approach has certain limitations. It relies heavily on high-quality, annotated training datasets, making it susceptible to biases or inaccuracies in the data. The model has shown strong performance on simple, stacked, and grouped bar charts but has not been thoroughly evaluated on more complex visualizations (e.g., multi-axis plots or charts with intricate legends). Furthermore, the approach assumes clean input images and consistent visual encodings; any noise or OCR errors may degrade performance. Lastly, domain-specific fine-tuning may limit generalization to unfamiliar chart types or unconventional encodings. Addressing these challenges in future work will enhance the robustness and scalability of the approach."}, {"title": "B. PROMPTS", "content": "This section contains the detailed prompts that were used to generate queries for 100 images, by prompting GPT-40. Additionally, the prompts used to query the language model (LLM) are included, offering insight into the specific descriptions and instructions given to the model in order to generate Question-answer pairs."}]}