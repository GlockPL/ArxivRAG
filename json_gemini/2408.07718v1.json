{"title": "Impact of Inaccurate Contamination Ratio on Robust Unsupervised Anomaly Detection", "authors": ["Jordan F. Masakuna", "DJeff Kanda Nkashama", "Marc Frappier", "Arian Soltani", "Pierre-Martin Tardif", "Froduald Kabanza"], "abstract": "Training data sets intended for unsupervised anomaly detection, typically presumed to be anomaly-free, often contain anomalies (or contamination), a challenge that significantly undermines model performance. Most robust unsupervised anomaly detection models rely on contamination ratio information to tackle contamination. However, in reality, contamination ratio may be inaccurate. We investigate on the impact of inaccurate contamination ratio information in robust unsupervised anomaly detection. We verify whether they are resilient to misinformed contamination ratios. Our investigation on 6 benchmark data sets reveals that such models are not adversely affected by exposure to misinformation. In fact, they can exhibit improved performance when provided with such inaccurate contamination ratios.", "sections": [{"title": "Introduction and related work", "content": "Unsupervised anomaly detection relies heavily on the assumption that training data sets are devoid of anomalies. However, in practice, this assumption often falls short, as data sets frequently harbor anomalous instances [Jha et al., 2023, Perini et al., 2023, Qiu et al., 2022], referred to as contamination [Hayes and Ohrimenko, 2018, Perini et al., 2023]. The presence of contamination poses a significant\nchallenge to unsupervised anomaly detection models, potentially compromising their effectiveness and reliability. To address this challenge, robust anomaly detection models have been developed (e.g., isolation forest (IF) [Liu et al., 2008], local outlier factor (LOF) [Alghushairy et al., 2020], one-class support vector machine (OCSVM) [Alam et al., 2020], neural transformation learning for deep anomaly detection beyond images (NeutrALAD) [Qiu et al., 2022] and deep unsupervised anomaly detection (DUAD) [Li et al., 2021]), aiming to mitigate the impact of contamination on model performance. Crucial to such models is the accurate estimation of contamination ratio, which informs the model about the proportion of anomalies within the data set.\nContamination ratio is susceptible to inaccuracies, which can arise due to various factors such as data collection processes [Whang et al., 2023, Cowie et al., 2011] and labeling errors [Rottmann and Reese, 2023, Northcutt et al., 2021]. The reliance of robust models on accurate contamination ratio information raises a critical question: How do these models perform when confronted with misinformed contamination ratios?\nOur primary objective is to ascertain the resilience of contamination-robust models to misinformed contamination ratios. Through a meticulous investigation encompassing six benchmark data sets, we aim to shed light on the extent to which contamination-robust models are affected by inaccuracies in contamination ratio estimation. We expect model's performance to decline when received inaccurately specified contamination ratios (see Figure 1).\nThis preliminary work focuses on shallow anomaly detection models only, i.e., IF, LOF and OCSVM."}, {"title": "Discussion and conclusion", "content": "We use six data sets for experiments, whose the distributions are visualized in Figure 2: (1) CICIOT is a real-time data set containing 33 attacks that are executed in an IoT network [Neto et al., 2023]. (2) CREDIT is credit fraud data set comprising financial transaction records annotated with binary labels indicating fraudulent or legitimate transactions [Warghade et al., 2020]. (3) ECG consists of recordings of electrical activity of the heart, capturing expected waveform patterns and anomalies [Khan et al., 2021]. (4) IDS contains simulated network traffics and several types of attacks [Sharafaldin et al., 2018]. (5) KDD contains simulated military traffics and several types of attacks [Tavallaee et al., 2009]. (6) KITSUNE is a network attack data set captured from either an IP-based commercial surveillance system or an IoT network [Mirsky et al., 2018]. For performance evaluation, we focus solely on accuracy since the test data subsets are well-balanced (in this binary classification task).\nFigure 3 shows the accuracy of models against misinformed contamination ratios. These findings challenge the conventional assumption regarding the impact of misinformed contamination ratios on contamination-robust unsupervised anomaly detection models. Contrary to expectations, the tested models demonstrated resilience and even outperformed anticipated outcomes under such conditions. These results suggest that the robust unsupervised anomaly detection models under consideration may not necessitate precise contamination ratios to address data contamination. This unexpected robustness suggests a need for deeper investigation into the underlying mechanisms of these models and highlights the importance of reassessing our assumptions in unsupervised anomaly detection research. Notably, while the expected behavior was observed on some instances (e.g., all 3 models on CREDIT and IF on IDS), the consistent trend across multiple data sets underscores the significance of these findings and their potential implications for advancing anomaly detection methodologies.\nThe implications of these unexpected findings are multifaceted and significant. They challenge the prevailing assumptions in anomaly detection research, prompting a reevaluation of the factors that influence model performance. This could lead to the refinement of existing methodologies and the development of more accurate anomaly detection systems. The implications of this study extend beyond anomaly detection alone, offering insights into broader issues of model robustness, reliability, and adaptability in the face of uncertainty in domains such as cybersecurity and fraud detection. Further investigation is needed to grasp the true meaning of these results, including deep models."}]}