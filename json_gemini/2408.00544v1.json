{"title": "Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Model", "authors": ["Felipe Mahlow", "Andr\u00e9 Felipe Zanella", "William Alberto Cruz Casta\u00f1eda", "Regilene Aparecida Sarzi-Ribeiro"], "abstract": "In recent years, Generative Artificial Intelligence (GenAI) has undergone a profound transformation in addressing intricate tasks involving diverse modalities such as textual, auditory, visual, and pictorial generation. Within this spectrum, text-to-image (TTI) models have emerged as a formidable approach to generating varied and aesthetically appealing compositions, spanning applications from artistic creation to realistic facial synthesis, and demonstrating significant advancements in computer vision, image processing, and multimodal tasks. The advent of Latent Diffusion Models (LDMs) signifies a paradigm shift in the domain of AI capabilities. This article delves into the feasibility of employing the Stable Diffusion LDM to illustrate literary works. For this exploration, seven classic Brazilian books have been selected as case studies. The objective is to ascertain the practicality of this endeavor and to evaluate the potential of Stable Diffusion in producing illustrations that augment and enrich the reader's experience. We will outline the beneficial aspects, such as the capacity to generate distinctive and contextually pertinent images, as well as the drawbacks, including any shortcomings in faithfully capturing the essence of intricate literary depictions. Through this study, we aim to provide a comprehensive assessment of the viability and efficacy of utilizing AI-generated illustrations in literary contexts, elucidating both the prospects and challenges encountered in this pioneering application of technology.", "sections": [{"title": "I. INTRODUCTION", "content": "Generative Artificial Intelligence (GenAI) has revolution-ized various tasks by integrating capabilities in text, audio,video, and image generation. GenAI excels in creating syn-thetic data that closely mimics real-world phenomena. Forinstance, text generation models such as OpenAI's GPT [1]have transformed the field of writing by demonstrating anexceptional understanding of context and coherence [2]. Thesemodels enhance natural language processing, content creation,and automated writing tasks [3]. In the realm of audio, modelslike Tacotron [4] and WaveNet [5] leverage deep neuralnetworks to generate realistic speech and music, pushing theboundaries of audio synthesis [6]. Similarly, image generationhas seen significant advancements with models such as DALL-E [7], [8], MidJourney [9], and Stable Diffusion [10], whichcan create intricate images from textual descriptions. Addition-ally, Generative Adversarial Networks (GANs) [11] have beenpivotal in producing high-quality images for artistic endeavorsand realistic face generation, significantly impacting computervision and multi-modal tasks [12]\u2013[14]. The ability of gener-ative models to create human-like content has opened up newavenues for creative, automated, and innovative applications.However, these advancements also bring about concerns andchallenges that need to be addressed in the future [15].Text-to-image (TTI) models focus on developing methodsand algorithms to create visual images from written text. Asignificant breakthrough in this field has been the rise of LatentDiffusion Models (LDMs) [10], which build upon the foun-dational principles of Diffusion Probabilistic Models (DPMs)[16]. Diffusion models apply a series of random transforma-tions progressively to an image's probability distribution [17].This iterative process generates detailed and realistic imageswhile providing greater control over the creation process.The integration of GenAI into the creative process hasshown a profound and multifaceted impact. For instance,research on the use of TTI models in craft education in-dicates that artificial intelligence (AI) can aid ideation andvisualization but also raised concerns about skill gaps, lack ofmateriality, and ethical implications, including biases and theimpact on creativity and copyright [18]. Similarly, GenAI canincrease creativity in writing tasks, showing improved qualityof text outputs with AI support, despite a greater uniformityin generated creations [19]. Additionally, the application ofAI in independent publishing, reveals both the AI's capabilityto enhance ideation and production, and the need for criticalapproaches to its role in preserving human craftsmanship [20].AI use also has environmental implications, with researchshowing that text and illustration production with AI cangenerate significantly fewer carbon emissions compared tohuman methods [21]. However, the adoption of AI in creativefields is not without challenges, including ethical issues andthe need for a careful balance between automation and humanauthorship. Analyzing these dynamics is crucial to understand-ing how AI can be a powerful tool in enhancing the creativeprocess while addressing the challenges associated with itsintegration.The extant literature offers a scant examination of theintersection between AI and book illustration. Traditionally,the illustration of literary works necessitated the interventionof human artists, a process often characterized by its time-consuming nature and subjectivity. However, recent advance-ments in AI present opportunities for automation, potentiallyenhancing this process by generating illustrations that encap-sulate the essence and historical context of literary workswith significantly reduced resources and time compared to"}, {"title": "II. METHODOLOGY", "content": "This section describes the systematic procedure adoptedfor generating and refining illustrations for seven classicalBrazilian books using the Stable Diffusion model."}, {"title": "A. The Books", "content": "The selection of these texts was guided by the goal ofrespecting copyright constraints while providing a rich sourcefor creative exercises. Therefore, only texts from Brazilianliterature available in the public domain were chosen.The selected books for this study are:\n\u2022 Senhora (1875) by Jos\u00e9 de Alencar\n\u2022 O Corti\u00e7o (1890) by Alu\u00edsio Azevedo\n\u2022 A Vi\u00fava Sim\u00f5es (1897) by J\u00falia Lopes de Almeida\n\u2022 Dom Casmurro (1899) by Machado de Assis\n\u2022 Horto (1900) by Auta de Souza\n\u2022 Os Sert\u00f5es (1902) by Euclides da Cunha\n\u2022 O Triste Fim de Policarpo Quaresma (1915) by LimaBarreto\nThese works were chosen for their literary significance andtheir rich descriptive passages, which provide ample materialfor visualization through GenAI. Each text offers uniquenaratives and vivid descriptions that facilitate the generationof diverse and engaging illustrations. Senhora and O Corti\u00e7o,for example, are notable for their detailed portrayal of 19th-century Brazilian society, while Dom Casmurro and Os Sert\u00f5esare renowned for their deep psychological and socio-politicalinsights. A Vi\u00fava Sim\u00f5es and Horto contribute with theirunique thematic and stylistic elements, and O Triste Fim dePolicarpo Quaresma is recognized for its satirical and culturalcritique. The choice of these works not only ensures a diverserange of illustrative challenges but also honors the literaryheritage of Brazilian authors through modern technologicalmeans."}, {"title": "B. Hardware Configuration", "content": "All computations were performed on a system equippedwith an NVIDIA GeForce RTX 3090 GPU. This setup pro-vided enough computational power and memory capacity,essential for handling the process involved in generating andrefining the images."}, {"title": "C. Image Generation", "content": "In the first stage, the Stable Diffusion XL Base 1.0 model was employed to generate the initial images. The model"}, {"title": "D. Image Refinement", "content": "In the second stage, the Stable Diffusion XL Refiner 1.0model was used to enhance the images generated in theprevious step. This refinement model received the latent im-ages (partially processed images) and continued the denoisingprocess from 0.8, completing the remaining steps to 1.0.This additional 40-step inference phase ensured that the finalimages reached a higher level of quality and detail. The refinermodel utilized additional components, such as a second textencoder and the variational autoencoder (VAE) from the basemodel, to improve the accuracy and aesthetics of the images.The refiner corrected imperfections and added fine details,making the illustrations more vivid and true to the originaldescriptions."}, {"title": "E. Large-Scale Generation and Selection", "content": "For each book, five prompts were generated, and for eachprompt, 300 images, resulting in 1500 images per book. Thislarge-scale generation ensured a wide variety of illustrations,allowing for a rigorous selection of the best representationsfor the project. These large quantities are important so thatthe calculation of quantitative metrics can be done moreaccurately."}, {"title": "F. Quantitative Evaluation Metrics", "content": "To evaluate the quality of the images generated we em-ployed two evaluation metrics, the CLIP [25] and IS scores[26].\n1) CLIP Score: The CLIP Score is a metric that evaluates the semantic quality and relevance of the generated images concerning the input prompts. We utilize the \"clipq_score\" function from the \"torchmetrics.functional.multimodal\"3 library, which calculates the CLIP score of an image concerninga text prompt. The CLIP model was trained on a large numberof text-image pairs to learn a joint representation of text andimage. It is capable of assessing the semantic quality of thegenerated images concerning the provided prompts.\n2) Inception Score (IS): IS is a metric that evaluates both the quality and diversity of the generated images. A higher IS indicates that the generated images are both diverse (capturing multiple classes) and of high quality (clearly recognizable by"}, {"title": "III. RESULTS", "content": "In this section, we present and analyze examples of thegenerated images, focusing on specific examples that highlightthe process and outcomes of our methodology. Figures 1and 2 showcase selected images, which facilitate a discussionon the creation process and the critical role of the promptin generating visually captivating and contextually relevantillustrations.\nWhile the AI system autonomously manages the imagegeneration process, the formulation of the prompt remains acritical task for the user. Mere transcription of text from thebook typically results in suboptimal outcomes. It is imperativeto conceptualize the scene based on the textual descriptionsprovided in the book and devise a prompt that facilitates thecreation of an image that is both visually compelling andfaithful to the scene's intrinsic characteristics."}, {"title": "A. Qualitative Approach", "content": "Figure 1a) exemplifies the representation of Capitu's eyes,often described as \"olhos de ressaca\" (sea surge eyes) inMachado de Assis's Dom Casmurro. These eyes are character-ized as \"gypsy eyes, oblique and dissimulated,\" as mentionedin chapters 13 and 32 of the book. The prompts used forthis image were inspired by the physical and symbolic traitsdetailed in these chapters. Capitu is described as havingbrunette hair and light eyes, considering that the true colorof her eyes is not explicitly revealed in the book. The promptused was:\"Painting of oblique and concealed eyes. Just eyes.Mysterious and energetic fluid, like the wave thatretreats from the beach, on hangover days. Brunette,clear and large eyes, straight and long nose, had athin mouth and wide chin.\"\nFigure 1b) clearly illustrates the importance of imagining away to represent a scene. This image was created to depictBentinho's suspicion that his son was fathered by Escobar, asdescribed in chapters 131 and 132 of Dom Casmurro, portray-ing Bentinho's obsession with Escobar's photograph, which hekept in his office. Bentinho frequently noted the resemblancebetween his son and Escobar, fueling his suspicions. Theimage positions the child in front of Escobar's photograph,highlighting the similarities between them and symbolizingBentinho's growing distrust. The prompt used was:\"A painting of a young kid (4yo) in the center. In the background, there is a photograph of his fatheron the wall. The kid looks like the father, who was40yo. 1800s.\""}, {"title": "IV. CONCLUSIONS", "content": "In this study, we explored the application of LDMs for thetask of book illustration, utilizing the Stable Diffusion modelto generate images based on prompts derived from sevenclassical Brazilian literary works. Our results indicate that theeffectiveness of image generation is significantly influenced bythe quality and specificity of the prompts provided. Promptsthat were carefully crafted to encapsulate the essence of thescenes described in the books yielded more compelling andrelevant visual results. Conversely, generic or poorly articu-lated prompts often led to suboptimal outcomes, highlightingthe importance of prompt design in the generative process.Through the illustrative examples provided, including figures representing characters and scenes from Dom Casmurro,A Vi\u00fava Sim\u00f5es, Senhora, O Corti\u00e7o, O Triste Fim de Poli-carpo Quaresma, and Os Sert\u00f5es, we observed that the StableDiffusion model could effectively capture and convey thethematic and visual elements of the source material. How-ever, certain limitations were noted. For instance, the model'stendency to produce predominantly white individuals, despitethe diversity described in the books, points to inherent biasesin the training data that affect the generated results. Thisis exemplified by the generated images of characters fromSenhora and O Triste Fim de Policarpo Quaresma.Quantitative evaluations using CLIP and IS scores revealedvariations in the quality of the generated images across different concepts. The analysis demonstrated that images alignedwith literary descriptions from Horto and O Triste Fim dePolicarpo Quaresma scored high in both metrics, indicatingsuccessful visualizations of these concepts.In conclusion, while the Stable Diffusion model is apowerful tool for generating illustrative content from textualprompts, its efficacy relies on precise prompt formulation andawareness of model biases. Future models should address theseissues by incorporating more diverse datasets. AI research inillustration should also focus on advanced prompt engineeringto enhance the quality and inclusivity of generated images.This study adds to the growing body of research on usinggenerative models in creative contexts, offering insights intotheir potential and limitations in literary illustration."}, {"title": "B. Quantitative Approach", "content": "In this section, we present a quantitative analysis of thegenerated images using two evaluation metrics: CLIP andIS scores. These metrics provide insights into the semanticrelevance and overall quality of the images produced forvarious literary concepts. \nIt should be observed that, despite the limited presentationof images restricted to no more than two distinct promptsper book in Figures 1 and 2 each book is characterizedby five distinct prompts with 300 images each. The afore-mentioned metrics are thus computed based on an aggregateof 1500 generated images. The results indicate varying levels"}]}