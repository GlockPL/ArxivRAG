{"title": "Revisiting In-Context Learning with Long Context Language Models", "authors": ["Jinheon Baek", "Sun Jae Lee", "Prakhar Gupta", "Geunseob (GS) Oh", "Siddharth Dalmia", "Prateek Kolhar"], "abstract": "In-Context Learning (ICL) is a technique by\nwhich language models make predictions based\non examples provided in their input context.\nPreviously, their context window size imposed\na limit on the number of examples that can be\nshown, making example selection techniques\ncrucial for identifying the maximally effective\nset of examples. However, the recent advent of\nLong Context Language Models (LCLMs) has\nsignificantly increased the number of examples\nthat can be included in context, raising an im-\nportant question of whether ICL performance\nin a many-shot regime is still sensitive to the\nmethod of sample selection. To answer this,\nwe revisit these approaches in the context of\nLCLMs through extensive experiments on 18\ndatasets spanning 4 tasks. Surprisingly, we ob-\nserve that sophisticated example selection tech-\nniques do not yield significant improvements\nover a simple random sample selection method.\nInstead, we find that the advent of LCLMS\nhas fundamentally shifted the challenge of ICL\nfrom that of selecting the most effective exam-\nples to that of collecting sufficient examples\nto fill the context window. Specifically, in cer-\ntain datasets, including all available examples\ndoes not fully utilize the context window; how-\never, by augmenting the examples in context\nwith a simple data augmentation approach, we\nsubstantially improve ICL performance by 5%.", "sections": [{"title": "1 Introduction", "content": "In-Context Learning (ICL) has emerged as a pow-\nerful paradigm in natural language processing that\nenables Language Models (LMs) to learn, adapt,\nand generalize from examples provided within their\ninput context, eliminating the need for extensive\ntraining and parameter updates (Brown et al., 2020;\nMin et al., 2022; von Oswald et al., 2023). How-\never, due to the limited context lengths of earlier\nLMs (which accommodate only a few thousand to-\nkens), much of previous ICL work has focused on\noptimizing sample selection strategies (Liu et al.,\n2021; Rubin et al., 2022; Sorensen et al., 2022; An\net al., 2023; Mavromatis et al., 2023; Liu et al.,\n2024). With the advent of Long Context Language\nModels (LCLMs), which are capable of processing\nover a million tokens in a single context window,\nthese constraints are significantly relaxed as it en-\nables including a large number of examples to be\nused in ICL, known as many-shot ICL (Agarwal\net al., 2024; Bertsch et al., 2024).\nThis expansion of context length raises an impor-\ntant question: do previous sample selection strate-\ngies, designed for shorter context windows in ear-\nlier LMs, generalize to the many-shot ICL regime?\nTo answer this, we systematically revisit existing\nsample selection strategies by conducting extensive\nexperiments across 18 datasets spanning diverse\ntasks (namely, classification, translation, summa-\nrization, and reasoning) with multiple LCLMs. Our\nexperiments include three types of sample selec-\ntion methods: relevance, diversity, and difficulty-\nbased sample selection, as outlined in Dong et al.\n(2023). From these experiments, we uncover novel\nand surprising findings: contrary to prevailing ex-\npectations that carefully selected ICL demonstra-\ntions would yield performance improvements, they\nare similarly effective with a simple random selec-\ntion approach, offering no statistically meaningful\nimprovements in almost all cases (Figure 1). An\nadditional reason to prefer the naive sample selec-\ntion approach is that it enables greater efficiency\nthrough key-value caching of in-context examples\n(as the same examples can be reused across multi-\nple queries), unlike sophisticated sample selection\nmethods where the examples vary for each sample.\nWhile the expanded context length in LCLMs\nallows us to focus less on selecting optimal sub-\nsets of examples, it introduces a new challenge:\neffectively utilizing this expanded capacity when"}, {"title": "2 Examining Sample Selection Methods\nfor In-Context Learning with LCLMs", "content": null}, {"title": "2.1 Background", "content": "We begin with formally introducing LCLMs, fol-\nlowed by describing the setup of ICL with LCLMs.\nLong-Context Language Models A language\nmodel (LM), which takes an input sequence of to-\nkens x = [x1, x2,..., xn] and generates an output\nsequence of tokens y = [Y1, Y2,..., Ym], can be\nrepresented as follows: y = LM(x), where @ is\nthe set of model parameters that are typically fixed\nafter training due to the high computational costs\nof fine-tuning. A long-context LM (LCLM) is an\nadvanced LM (Reid et al., 2024) that is designed\nto accommodate sequences with a large number of\ntokens (e.g., n can exceed 1 million), typically far\nsurpassing the context sizes of earlier LMs.\nIn-Context Learning with LCLMs Given a set\nof k input-output pairs {(xi, Yi)}=1 as well as an\ninput query x', the goal of ICL is to produce an out-\nk\nput y = LCLM(x'|{(xi, Yi)}=1), where the model\n(LCLM) uses the contextual examples {(xi, Yi)}=1\nto make predictions for \u00e6'. In prior research before\nthe advent of LCLMs, the value of k was often\nlimited by the relatively short context lengths of\nearlier models, which constrained the number of ex-\namples that could be utilized for ICL. Subsequently,\nsignificant work has focused on developing sam-\nple selection techniques to optimize performance"}, {"title": "2.2 Experimental Setup", "content": "We now discuss the detailed experimental design.\nTasks and Datasets We experiment with 18 dif-\nferent datasets across four tasks to evaluate the ef-\nfectiveness and robustness of various approaches.\n\u2022 Translation: This task evaluates the ability of\nmodels to translate text from one language to an-\nother. We include translations from English to\nlow-resource languages (namely, Bemba, North-\nern Kurdish, and Ewe) and high-resource lan-\nguages (Spanish, French, and German) from the\nFLORES-200 benchmark (NLLB et al., 2022),\nwith chrF scores (Popovic, 2015) as the metric.\n\u2022 Summarization: This task assesses the capabil-\nity of models to generate concise and coherent\nsummaries from articles. We include one widely-\nused XSum dataset (Narayan et al., 2018) and\ntwo long-context summarization datasets: ArXiv\nand GovReport (Cohan et al., 2018; Huang et al.,\n2021). ROUGE-L score is used for evaluation.\n\u2022 Reasoning: This task evaluates the capability\nof models to perform complex reasoning. We\nuse three challenging datasets from Big Bench\nHard (BBH) (Suzgun et al., 2022) following the\nexperimental setting of Long-Context Frontiers\n(LOFT) benchmark (Lee et al., 2024a).\n\u2022 Classification: This task includes challenging\nbenchmark datasets for ICL from Li et al. (2024),\nparticularly designed for classification problems\nwith diverse classes and long inputs.\nICL Sample Selection Strategies To ensure\ncomprehensive coverage of previously explored\nsample selection strategies, we follow the category\nof three core dimensions from Dong et al. (2023)\n(that extensively summarizes around ICL 200 pa-\npers). This includes selecting samples based on\ntheir diversity, difficulty, and relevance to the query,\nwith the baseline of random sample selection.\n\u2022 Naive: This method randomly selects examples\nfrom a dataset and uses this initial set of selected\nexamples as ICL demonstrations for all queries.\n\u2022 Relevance: This method selects examples that\nare most similar to the input query to maximize"}, {"title": "3", "content": "the alignment of ICL demonstrations with the\nquery. To compute semantic similarity between\nthe query and each example, we use an embed-\nding model (Lee et al., 2024b).\n\u2022 Diversity: This method selects examples that are\nmaximally distinct from each other to capture\na broad coverage of features and characteristics\nwithin the task space. We first embed each exam-\nple in a shared embedding space with Lee et al.\n(2024b) and utilize k-means clustering (where k\ncorresponds to the number of desired ICL exam-\nples) to group the examples into subcategories.\nWe then select the example closest to each cluster\ncenter as the representative to capture a diverse\nsubset of the task features.\n\u2022 Difficulty: This method selects examples based\non their difficulty. We examine two approaches:\nthe first method (called Curriculum) follows a\ncurriculum learning paradigm where examples\nare ordered from easiest to hardest; the second\none (called Hard) includes only difficult exam-\nples, as simpler examples may already be well-\nunderstood by models. To assess example diffi-\nculty, we use model-based evaluation (Liu et al.,\n2023), which prompts LCLMs 30 times and aver-\nages difficulty scores weighted by probabilities.\nLCLM Configurations for ICL We consider\nLCLMs that support extensive token capacities to\nevaluate ICL performance in long-context, many-\nshot ICL scenarios. We focus on models that have\ncontext window lengths on the order of millions:\nGemini 1.5 Flash, which can process up to 1 mil-\nlion tokens; Gemini 1.5 Pro, which can process up\nto 2 million tokens (Reid et al., 2024). In addition,\nwe also consider the Llama 3.1 70B model (Dubey\net al., 2024), which, while supporting the com-\nparatively smaller context size of 128K tokens, is\nstill considered an LCLM. For all experiments, we\nutilize the default hyperparameters for both Gem-\nini and Llama. To provide a comprehensive view\nof performance under different shots, we vary the\nnumber of ICL examples, starting from one and se-\nquentially doubling to 2, 4, 8, 16, 32, and so forth,\nuntil reaching either the context size limit or the\nmaximum number of dataset samples, whichever\nis exhausted first. Furthermore, to ensure the re-\nliability of our results, we conduct multiple runs\nfor each experimental setup: 3 runs for translation\nand summarization tasks; 10 runs for reasoning\nand classification tasks. The prompts used to elicit\nresponses from ICL are provided in Appendix A."}, {"title": "2.3 Experimental Results", "content": "Results on Sample Selection Strategies We re port the detailed results of various sample selection\napproaches in many-shot ICL scenarios in Figure 2.\nTo rigorously evaluate each sample selection ap proach and their statistically significant gains, we\nconduct a t-test with a 95% confidence threshold\nand report the results in Table 1. From these results,\nwe observe that previously effective sample selec tion methods, designed for shorter context LMs,\nyield little to no performance gains over the ran dom selection approach when applied to LCLMs.\nAggregated results across three different LCLMs\nindicate statistical significance in fewer than 15%\nof instances, indicating that they are not reliable.\nAnalysis on Number of ICL Examples To see\nthe performance of ICL with respect to the number\nof examples, we visualize results in Figure 3. Over all, for any sampling method, we observe that per formance increases as the number of examples in creases. Also, when the number of examples is rel atively small, the relevance-based sample selection\napproach performs particularly well, as focusing on\nhighly relevant examples maximizes learning effec tiveness when using a small number on examples.\nHowever, as the number of examples increases, the\nperformance gap between various sample selection\nmethods diminishes, indicating that performance is\nless dependent on selection strategies in many-shot\nscenarios. Lastly, in the summarization task (where\nsamples tend to be longer than those in other tasks),\nwe observe an initial increase in performance as\nmore examples are added, followed by a decline"}, {"title": "4", "content": "once the context becomes heavily populated with a\nlarge number of examples. We argue this decline\nlikely reflects the challenges LCLMs face in pro-\ncessing extremely long contexts, and we offer more\nanalysis and discussion in Section 4.2.\nAnalysis on Example Order Previous work has\nshown that earlier LMs are sensitive to the order of\nexamples when doing few-shot ICL. For example,\nLMs tend to follow the answer in the last exam-\nple (Zhao et al., 2021; Lu et al., 2022). To investi-\n5\ngate whether similar issues arise in many-shot ICL\nwith LCLMs, we experiment by comparing per-\nformance when ordering ICL examples randomly,\nby increasing similarity, and by decreasing similar-\nity. The results in Table 2 suggest that the order of\nexamples does not affect performance of LCLMs.\nAnalysis on Computational Complexity In ad-\ndition to performance, computational complexity\nis a critical factor to consider when assessing the\npracticality of many-shot ICL with LCLMs, as they\noften handle million-token contexts. We note that\nfor approaches that adjust ICL examples based on\nthe given query (such as relevance-based selection),\nthe complexity scales quadratically, O(n\u00b2), where\nn represents the number of tokens used for ICL\ndemonstrations. In contrast, the simpler naive selec-\ntion approach, which uses the same set of randomly\nselected examples for all queries, offers a signifi-\ncantly more efficient complexity of O(kn), where\nk is the number of tokens only within the target\nquery (n > k). This is because the selected exam-\nples do not change based on the query; thus, the\nsame set of examples can be key-value cached. As\na result, random selection is a practical choice due\nto its equivalent performance with other selection\nmethods and the added advantage of efficiency."}, {"title": "3 Augmenting ICL Demonstrations to\nIncrease Context Capacity of LCLMs", "content": null}, {"title": "3.1 ICL Example Augmentation Approach", "content": "Recall that recent advances in LCLMs offer un-\nprecedented context capacity, potentially amplify-\ning ICL performance by including more examples.\nHowever, the available examples sometimes fall\nshort of filling this expanded capacity, and this\nunder-utilization of the context may result in sub-\noptimal performance. To address this, we introduce\na simple yet effective ICL sample augmentation ap-\nproach designed to increase the context capacity of\nLCLMs, while being scalable for many-shot sce-\nnarios. This method consists of synthetic example\ngeneration and low-quality example filtering.\nGeneration of Synthetic Examples Formally,\nlet D = {(xi, Yi)}=1 be a dataset of available ICL\nexamples for a given target task, where each exam-\nple (xi, yi) represents an input-output pair. The\nobjective is to generate a set of synthetic examples\nD' = {(x, y)}=1 (to supplement the original\ndataset D), such that the augmented set of exam-\nples DAUG = D \u222a D' can increase the utilization\nof the available context capacity of LCLMs. To\noperationalize this, we generate each synthetic ex-\nample (x, y) by prompting an LM with randomly\nselected real examples from D as context, to ensure\nthat the generated data retains meaningful patterns\nand characteristics relevant to the task.\nFiltering Out Low-Quality Examples Once the\nsynthetic examples are generated, we filter out low-\nquality instances that may introduce noise or irrele-\nvant information. To do this, we design a function\nf that assigns a quality score to each synthetic ex-\nample (x, y) based on its contextual relevance\nand alignment with real examples as well as over-\nall quality. Specifically, each synthetic example is\nrated on a 5-point Likert scale by prompting the\nLM 30 times with the synthetic and 30 real exam-\nples. We then compute an aggregate score using a\nweighted average of scores with their correspond-\ning probabilities from the LM. Only the synthetic\nexamples that exceed a quality threshold, \u03c4, are"}, {"title": "6", "content": "retained in the augmented example set, as follows:\nDAUG = D \u222a {(x\n\u2032\nj\n, y\n\u2032\nj\n) | f(x\n\u2032\nj\n, y\n\u2032\nj\n, D) \u2265 \u03c4}\nm\nj=1,\nwhere f(x\n\u2032\nj\n, y\n\u2032\nj\n, D) is the quality assessment func tion, and \u03c4 is the threshold value for filtering.\n3.2 Experimental Setup\nFor synthetic data generation and filtering, we use\nGemini Pro, one of the state-of-the-art LMs. We\nfocus on tasks that underutilize the context capac ity of LCLMs even when all available samples are\nprovided, such as translation, reasoning, and classi fication. For each task, we generate 3,000 examples\nand retain only those with a quality score above the\nmedian among the generated samples. As a result,\nwe use the original examples and 1,500 synthetic\nexamples. The prompts used to elicit data genera tion and filtering are provided in Appendix A.\n3.3 Experimental Results\nMain Results As shown in Table 3, which com pares the example augmentation approach (with\nrandom selection) to other sample selection strate gies, the augmentation approach demonstrates sub stantial performance gains across various datasets,\nwhich can be attributed to the greater diversity and\nvolume of ICL examples achieved through syn thetic data generation, leading to the effective uti lization of the context capacity of LCLMs. Also,\nlike the random selection approach, our augmenta tion method allows the reuse of the same examples\nacross all queries. Thus, due to key-value caching,\nthe augmentation approach is as efficient as random\nselection while achieving superior performance."}, {"title": "Ablation Study on Augmentation", "content": "To see how\neach component in the augmentation approach con tributes to performance gains, we conduct an ab lation study. As shown in 4, we observe that the\nfull augmentation method (called Augmentation),\nwhich uses both original examples and filtered syn thetic examples in combination, achieves the best\nperformance. In contrast, when the filtering step\nis omitted, performance decreases, indicating that\nfiltering contributes positively by removing lower quality synthetic examples. Also, a large perfor mance drop occurs when original samples are ex cluded from the augmented set. This suggests that\nalthough filtering helps maintain quality, the syn thetic samples generated still do not match the qual ity of the original examples. Thus, while our aug mentation approach is effective, further research\ncould improve data generation techniques to im prove the quality of the synthetic examples."}, {"title": "4 Behaviors of LCLM-Enabled ICL", "content": null}, {"title": "4.1 LCLM-Based ICL with Noisy Examples", "content": "LCLMs can accommodate a large number of di verse ICL examples, which raises the question of\nthe impact and risk of including noisy examples in\nthe context. We investigate how the performance of"}, {"title": "7", "content": "LCLM-enabled ICL is impacted when some or all\nof the ICL examples are noisy. To simulate noisy\nexamples, we modify the outputs of a subset of in-context demonstrations by replacing their outputs\nwith outputs from other randomly selected demon-strations. As shown in Figure 4, LCLM-enabled\nICL is largely robust to noise when the propor-tion of noisy examples is relatively low (i.e., below\n25%). This observation highlights why augmented\nexamples, even if slightly lower quality, can still\nenhance performance as it increases the utilization\nof the context window. Also, when the amount\nof noise exceeds this threshold, LCLMs become\nvulnerable to the negative effects of noise and the\nperformance notably declines. This adverse effect\nis more pronounced for challenging tasks, such as\nthe GovReport dataset in summarization and low-resource translation tasks (e.g., English to Bemba\nor Ewe). This is likely because LCLMs are less\nfamiliar with those tasks, and therefore rely more\non learning from in-content examples.\n4.2 LCLM-Based ICL with Long Context\nAs the context length capacity of LCLMs contin-ues to grow, it becomes increasingly important to\nassess whether LCLMs can reliably utilize a large\nnumber of ICL examples. To investigate this, we\nconduct an experiment analyzing the performance\nas a function of the context utilization. Specifically,\nwe gradually increase the number of examples by\npowers of two, and if the entire set of examples\nwithin the dataset is used, we further extend the con-text utilization by repeating these examples. The\nhypothesis being tested is that if LCLMs can effec-tively understand and utilize extremely long con-"}, {"title": "7", "content": "text, performance should remain consistent even\nwith repeated examples, as the presence of dupli-cates should not impact contextual understanding.\nHowever, as shown in Figure 5, a substantial perfor-mance decline occurs when LCLMs are pushed to\nuse extremely large contexts. Specifically, this de-cline generally begins when more than 25% of the\navailable context capacity is utilized. Also, the per-formance drop is pronounced in tasks such as xsum,\nwhich requires generating abstractive summaries\n(unlike other summarization datasets like arXiv\nor GovReport) and in tasks demanding complex\nreasoning such as date understanding (Date) and\nobject tracking (Tracking7). These findings sug-gest that while LCLMs can handle moderately long\ncontexts, they encounter limitations with exceed-ingly large contexts, particularly in tasks requiring\nfine-grained reasoning or abstractive generation.\nThis may be due to challenges in distinguishing\nand integrating relevant information across numer-ous examples, especially when tasks require high\nlevels of nuanced abstraction and precise reasoning."}, {"title": "5 Related Work", "content": "Long Context Language Models The field of\nlanguage modeling has witnessed remarkable ad-vancements, particularly with the development of\nLarge Language Models (LLMs) (Brown et al.,\n2020; OpenAI, 2023; Reid et al., 2024; Dubey et al.,\n2024). However, early LLMs were oftentimes con-strained by relatively short context windows, typi-cally handling only a few thousand tokens at a time,\nwhich limits their applicability in advanced tasks\nrequiring broader context comprehension, such as\ndocument-level summarization or complex reason-"}, {"title": "8", "content": "ing (Koh et al., 2023; Suzgun et al., 2022). \u03a4\u03bf\naddress this, recent efforts have led to the develop-ment of Long Context Language Models (LCLMs),\ndesigned specifically to process much larger con-texts, sometimes accommodating over a million\ntokens within a single prompt (Reid et al., 2024).\nTo mention a few, models like Longformer and\nBigBird (Beltagy et al., 2020; Zaheer et al., 2020)\nincorporate sparse attention mechanisms to effi-ciently handle extended contexts without compro-mising on computational feasibility. Recent work\nhas pushed these limits even further \u2013 for exam-ple, LongRoPE extends the the context window of\nLLMs to 2M tokens by interpolating their specific positional embeddings (Ding et al., 2024).\nIn-Context Learning In-Context Learning (ICL)\nis a recent paradigm that enables language models\nto learn from examples provided within their input\ncontext and then perform given tasks (Brown et al.,\n2020; Min et al., 2022; von Oswald et al., 2023).\nSince its introduction, previous studies have con-centrated on developing the strategies to optimize\nthe quality and arrangement of in-context examples\nto maximize performance, especially given the lim-itations of early LMs on context length. For exam-ple, these approaches include selecting examples\nthat maximize relevance to the target query (Liu\net al., 2021; Rubin et al., 2022), ensuring diver-sity among examples to cover a range of possible\ncases (Sorensen et al., 2022; An et al., 2023), strate-gically ordering examples to improve model adap-tation (Zhao et al., 2021; Lu et al., 2022), and pri-oritizing examples by their ease of learning based\non their difficultly (Mavromatis et al., 2023; Liu et al., 2024). Yet, as the context capacity expands\nwith LCLMs, these conventional selection strate-gies warrant re-evaluation, particularly in many-shot settings; thus, we focus on revisiting them.\nMany-Shot ICL Early approaches in many-shot\nICL have primarily focused on the paradigm shift\nbrought by the ability to incorporate a larger num-ber of examples within the input context (Agar-wal et al., 2024; Bertsch et al., 2024), without giving much consideration to example selection\nstrategies other than the random selection. De-spite their simplicity, such many-shot ICL methods have sometimes demonstrated performance com-parable to fine-tuning. Also, there is a very recent\nwork that explores retrieval strategies in many-shot\nICL (Bertsch et al., 2024); however, they use mod-els with relatively limited context capacities (e.g.,"}, {"title": "8", "content": "under 100k tokens with Llama 2), resulting in re-strictions on the number of examples included and, consequently, making retrieval-based methods ap-pear more advantageous. However, contrary to this\nfinding, we uncover that this advantage diminishes as the context capacity increases, allowing random\nsampling to perform on par with more sophisticated selection methods when a large number of exam-ples is used. Lastly, other recent efforts include\nestablishing benchmarks for long-context ICL (Lee\net al., 2024a; Li et al., 2024). Unlike prior studies,\nour work offers a novel perspective by systemati-cally re-evaluating traditional selection strategies\nin the expanded context regime and highlighting\nthe shift from selection optimization to effectively\nleveraging the extensive context space in many-shot ICL, with the proposal of data augmentation\nfor cases where the number of examples is not suf-ficient to populate the context capacity of LCLMs."}, {"title": "6 Conclusion", "content": "We explored ICL in the context of LCLMs, which\nthe enable inclusion of significantly more exam-ples in-context than previously possible, and inves-tigated whether traditional sample selection strate-gies remain effective in these many-shot scenar-ios. Through extensive experiments across diverse\ntasks and datasets, we observed that previously fa-vored, sophisticated sample selection techniques offer minimal to zero performance gains over sim-ple random selection in most cases. We believe this\nunexpected finding suggests a potential paradigm shift in ICL research: as LCLMs allow the process-ing of extensive contexts, sample selection may no\nlonger be a priority, with simpler methods proving\nsimilarly effective and more computationally effi-cient due to key-value caching. We also highlighted\nthe emerging challenge of underutilized context in\nlow-resource tasks due to limited example availabil-ity, and, to address this, proposed a data augmenta-tion strategy, which substantially boosts ICL perfor-mance by increasing context utilization of LCLMs.\nLastly, we analyzed the behavior of LCLM-enabled\nICL when operating with extremely long context\nand in the presence of noisy examples, and found that while performance improves with added exam-ples, it plateaus and even declines when the context\nbecomes too long, with increased vulnerability to\nnoise in complex tasks. This suggests promising future directions in making LCLMs more robust to lengthy context and noise examples alongside the\ndirection of extending their context length."}, {"title": "Limitations", "content": "While this work explores the new opportunity of\nICL with LCLMs, a couple of limitations can be\nconsidered. First, the computational cost associated\nwith LCLMs remains a significant challenge, partic-ularly for researchers and practitioners in resource-constrained settings. Second, while the proposed\ndata augmentation method enhances context utiliza-tion of LCLMs and improves ICL performance, the\nquality of synthetic examples often falls short of the\nquality of original data. Addressing them through\ncost-efficient strategies for leveraging LCLMs and\ndeveloping improved data augmentation techniques\nwould be an exciting area for future work."}, {"title": "Ethics Statement", "content": "We believe this work does not raise any direct ethi-cal concerns, as it primarily focuses on advancing\nthe understanding of ICL with LCLMs. However,\nas with any other application of LCLM-based ICL, careful consideration must be given to the quality\nof the examples used in the context. Specifically, the inclusion of biased, harmful, or otherwise prob-lematic examples in the input context can propagate\nor amplify these issues in the model's outputs, and\nwe advise practitioners to carefully evaluate and\nselect ICL examples to avoid potential issues."}]}