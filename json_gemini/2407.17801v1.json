{"title": "EEG-SSM: Leveraging State-Space Model for Dementia Detection", "authors": ["Xuan-The Tran", "Linh Le", "Quoc Toan Nguyen", "Thomas Do", "Chin-Teng Lin"], "abstract": "State-space models (SSMs) have garnered attention\nfor effectively processing long data sequences, re-\nducing the need to segment time series into shorter\nintervals for model training and inference. Tradi-\ntionally, SSMs capture only the temporal dynam-\nics of time series data, omitting the equally critical\nspectral features. This study introduces EEG-SSM,\na novel state-space model-based approach for de-\nmentia classification using EEG data. Our model\nfeatures two primary innovations: EEG-SSM tem-\nporal and EEG-SSM spectral components. The\ntemporal component is designed to efficiently pro-\ncess EEG sequences of varying lengths, while the\nspectral component enhances the model by inte-\ngrating frequency-domain information from EEG\nsignals. The synergy of these components allows\nEEG-SSM to adeptly manage the complexities of\nmultivariate EEG data, significantly improving ac-\ncuracy and stability across different temporal res-\nolutions. Demonstrating a remarkable 91.0% ac-\ncuracy in classifying Healthy Control (HC), Fron-\ntotemporal Dementia (FTD), and Alzheimer's Dis-\nease (AD) groups, EEG-SSM outperforms existing\nmodels on the same dataset. The development of\nEEG-SSM represents an improvement in the use of\nstate-space models for screening dementia, offer-\ning more precise and cost-effective tools for clini-\ncal neuroscience.", "sections": [{"title": "1 Introduction", "content": "Dementia, a cognitive decline that impairs memory and func-\ntional abilities, affects approximately 45 million people glob-\nally [Nichols et al., 2019], with numbers expected to increase\ndue to longer lifespans and an aging population. Alzheimer's\ndisease (AD), the most common form of dementia, accounts\nfor 60-80% of cases [Association and others, 2018], affecting\n1 in 9 individuals over 65 [Rajan et al., 2021]. It is a pro-\ngressive neurological disorder characterized by beta-amyloid\naccumulation and tau tangles, leading to neuronal death, brain\natrophy, and symptoms like memory loss, confusion, and be-\nhavioural changes. Frontotemporal degeneration (FTD), an-\nother form of dementia, leads to social, behavioural, and mo-\ntor deficits due to the deterioration of frontal and temporal\nlobes. FTD typically affects individuals aged 45-60 and rep-\nresents a significant portion of dementia cases, especially in\nthose under 65 [Hogan et al., 2016]. These dementia present\nsignificant healthcare challenges with substantial impacts on\npeople with dementia (PwD) [Beerens et al., 2014] and so-\nciety, underscoring the need for advancements in accurate\nscreening methods.\nThe standard screening approach for dementia typically in-\nvolves cognitive tests like the Mini-Mental State Examination\n(MMSE) [Folstein, 1975], the Montreal Cognitive Assess-\nment (MOCA) [Julayanont and Nasreddine, 2017], the Mini-\nCog test [Borson et al., 2000], and the Addenbrooke's Cog-\nnitive Examination III (ACE-III) [Bruno and Schurmann Vi-\ngnaga, 2019]. These tests are advantageous due to their sim-\nplicity and quick administration. However, their effectiveness\ncan be compromised by factors such as the patient's educa-\ntional background, emotional state, and test reiteration. Neu-\nroimaging techniques like MRI and PET scans offer greater\ndetecting accuracy but are hampered by high costs and the ne-\ncessity for extensive expert analysis [Sun et al., 2024]. Elec-\ntroencephalography (EEG) serves as a practical alternative,\nbeing cost-effective, non-invasive, and highly portable while\nproviding direct, high-resolution monitoring of brain activity.\nThe development of AI-based detecting models using EEG\ndata can potentially yield more accurate detection and reduce\nthe burden on healthcare professionals.\nThe quest for effective AI-based detection models for brain\ndisorders has led to the exploration of various machine-\nlearning techniques using EEG data. Traditional machine\nlearning models typically utilize temporal, spectral, and spa-\ntial features extracted from EEG signals for classification\ntasks. A notable study by McBride et al. [McBride et al.,\n2014] employed a support vector machine (SVM) to dis-\ntinguish between healthy controls (HC), mild cognitive im-\npairment (MCI), and PwD, achieving an accuracy rate of\n85.4%. Deep learning approaches have also been investi-\ngated for this purpose. Ieracitano et al. [Ieracitano et al.,\n2019] used a multilayer perceptron (MLP) model incorporat-\ning wavelet EEG features to classify the same groups, achiev-\ning an 89.2% accuracy. Another innovative study applied"}, {"title": "2 Method", "content": "Our EEG-SSM model aims to harness the strengths of SSM\nin conjunction with multivariate EEG segmentation, as de-\ntailed in Figure 1. This section begins with an introduction\nto the key principles underpinning SSMs. It then delves into\nthe technique used to divide EEG data into multivariate seg-\nments, each defined by specific feature categories: temporal\nand spectral features (frequency). The section concluded by\npresenting a novel optimization strategy (Opt-W) designed to\nefficiently encode EEG wavelet bands, showcasing the inno-\nvative integration of SSM with EEG data analysis."}, {"title": "2.1\nPreliminaries - SSM", "content": "The SSM functions by mapping the input vector x \u2208 R1\u00d7D\nto a higher-dimensional latent space h \u2208 R1\u00d7N (where N >\nD), subsequently computing a mapping from h to the output\ny\u2208 R1\u00d7\u010e. The following set of equations formalizes the\nSSM:\nh'(t) = Ah(t) + Bx(t)   (1)\ny(t) = Ch(t) + Dx(t) (2)\nwhere A \u2208 RN\u00d7N, B\u2208 RN\u00d71, C\u2208 R1\u00d7N, and D\u2208 R1\u00d71\nrepresent the learned parameter matrices of the model. Equa-\ntions 1 and 2, initially in continuous form, are not directly ap-\nplicable for deep learning tasks. To adapt these for use, they\nwere converted to a discrete form using the Zero-Order Hold\n(ZOH) method [Pohlmann, 2000]. Following this transfor-\nmation, a global convolution operation was applied to the dis-\ncretized form, rendering it suitable for input into the Mamba\nEncoder.\nK = (CB CAB ... CAM-1B), (3)\ny = x * K, (4)\nwhere M signifies the length of the input sequence x, and K\nis an RM - dimensional structured convolutional kernel."}, {"title": "2.2 EEG Preprocess", "content": "Segmentation\nThe Mamba architecture, originally tailored for 1-D se-\nquences, has been adapted in this work for multivariate EEG\ndata to encapsulate all EEG feature dimensions, as depicted\nin Figure 1. The upper module of the architecture processes\nsegmented multivariate EEG data, preparing it for the EEG-\nSSM encoder block. A key attribute of the Mamba model is\nits proficiency in managing long sequence data, rendering it\nparticularly apt for resting-state EEG analysis. This attribute\nallows for EEG data segmentation into various lengths with\nminimal data information loss.\nTemporal EEG: To process the multivariate EEG data\ninto blocks suitable for encoder networks, we initiate by\nconverting the 3-dimensional EEG data, denoted as t \u2208\nIRNseg XNcXNseq, into flattened 2-dimensional patches repre-\nsented by Xp \u2208 RNc\u00d7Nseq. Here, Nseg signifies the number\nof segments, Ne stands for the number of channels, and Nseq\ndenotes the segment length corresponding to the number of\ntime points within a single EEG segment. For instance, a\nsegment with a length of 2 seconds could encompass a se-\nquence ranging from time frame = 0 to time frame = 2s. Sub-\nsequently, these 2-D patches xp are linearly projected onto a\nvector of size M, which facilitates the extraction of temporal\nfeatures from the EEG data follows: To = [thS; t2S; ...; tS]\nwhere to is the j-th patch of the original EEG sequence,\nSERNcXNseq. The EEG-SSM encoder is used in individ-\nual segments, extracting representative EEG features for each\nsegment. Given that Mamba operates on 1D sequences, the\ntemporal domain data, Xtemporal, retaining the original shape\nof the EEG segment input, transforms a Forward Conv1D\nlayer into a 1D array as follows:\nx(t) = [Conv1d(tS); ...; Conv1a(tS)] (5)\nSpectral EEG\n\u2022 Wavelet Filter: We employ a Wavelet Filter [Xu et al.,\n1994], denoted as \u03a9, to process EEG data for feature\nextraction. Specifically, we focus on segmenting the\nEEG signals into distinct frequency bands, each associ-\nated with different cognitive states and activities. These\nbands include the Delta band (0.5\u20134Hz), Theta band (4-\n8Hz), Alpha band (8-12 Hz), Beta band (12\u201320 Hz), and\nGamma band (20\u201340 Hz), which are utilized to feature\nthe EEG data for subsequent analysis [Sun et al., 2024].\n\u2022 In the spectral domain, Power Spectral Density (PSD)\nfeatures are computed using Welch's method [Welch,\n1967] to obtain Xspectral before its transformation to a 1D\narray by an additional Forward Conv1D layer follows:\nx(t) = [Conv1d((X)); ...; Conv1a(N(X))] (6)\nMamba Input In our methodology, the Mamba system is\ndesigned with three distinct inputs x(t) (see Equation 1) :\none for purely temporal features (Equation 5), another for ex-\nclusively spectral features Equation 6), and a third that con-\ncatenates both temporal and spectral features, allowing for a\ncomprehensive analysis through separate yet complementary\ndata feature types (see Figure 1)."}, {"title": "2.3 EEG wavelet optimization for spectral features\n(Opt-W)", "content": "Previous research [Swarnalatha and others, 2023; Al-\nSharabi et al., 2022; Sedghizadeh et al., 2022] in the field of\ncognitive impairment and dementia detection has been lim-\nited by an inability to automatically optimize the weights\namong wavelet bands (Delta, Theta, Alpha, Beta, Gamma).\nThe ratio between these bands plays a critical role in identi-\nfying various cognitive conditions [Chikhi et al., 2022], un-\nderscoring the need for a solution capable of dynamically of\neach wavelet's importance band according to the specific type\nof dementia and the patient's condition. Implementing such\na system would significantly enhance the accuracy and effi-\ncacy of classifying cognitive problems. In this segment, we\ndelineate the ensemble layer, an innovative network layer en-\ngineered for the efficacious training of deep neural networks\nby leveraging features from separate wavelet-specific models\nto automatically update the weights featuring the combina-\ntion of different wavelet bands (Delta, Theta, Alpha, Beta,\nGamma) for spectral features. The foundational idea is intu-\nitive: the ensemble layer assimilates inputs typically desig-\nnated for the ultimate layer of a deep neural network (such as\na softmax layer for classification) and orchestrates a wavelet-\nspecific linkage from this terminal layer to the labels of var-\nious wavelet-centric models. This linkage adeptly encapsu-\nlates the distinct reliabilities and the biases introduced by\nspecific wavelet bands, transforming the conventional output\nlayer into a pivotal bottleneck layer that is communally uti-\nlized by different wavelet-centric models. For illustrative pur-\nposes, Figure 2 portrays this bottleneck configuration within\na neural network framework tailored for EEG classification\nchallenges, featuring three classes and encompassing R mod-\nels, inclusive of 5 wavelet-specific models.\nThe methodology entails employing the labels from a des-\nignated wavelet band to disseminate errors throughout the\nneural network. The ensemble layer meticulously adjusts the\ngradients emanating from the labels of that particular wavelet\nband, aligning them with its accuracy through scaling and\nbias modulation. Consequently, the bottleneck layer of the\nnetwork aggregates these tailored gradients from the labels of\nvarious wavelet-centric models and propels them backward\nthrough the network's remaining structure. This orchestra-\ntion, facilitated by the so-called \u201censemble layer\", empowers\nthe network to mitigate the influence of unreliable labelers\nand rectify persistent biases in their labels, all within the tra-\nditional backpropagation paradigm.\nFormally, let & symbolize the output of a deep neural net-\nwork with an arbitrary architecture. For the sake of simplic-\nity, we postulate that & emerges from a softmax layer, with \u03be\u03b5\ndenoting the probability of classifying the input instance into\ncategory c. The activation for each wavelet-specific model r\nwithin the ensemble layer is defined as m\" = fr(\u00a7), where fr\nsignifies a wavelet-specific function, and the output of the en-\nsemble layer is rendered as the softmax of these activations:\n\u03c8 =\nem\n\u03a3R\nr=1\nemr\nThe conundrum then lies in formulating the function fr(\u03be).\nIn the experimental section, we explore various alternatives.\nFor classification endeavors, it is plausible to envisage a\nmatrix transformation such that fr(g) = Wrg, where Wr\nrepresents a wavelet-specific matrix. Given a cost function\nE(\u03c8\", y\") that juxtaposes the expected output of the rth\nwavelet-specific model with its actual label y\", we can ascer-\ntain the gradients at the activation m\u201d for each model\nand backpropagate them to the bottleneck layer, culminating\nin the equation:\n\u0394\u0395\n\u0394\u03b5 =\n\u03a3R\nr=1\n\u0394\u0395\nAmr\n\u0394\u0395\n(7)\nHence, the gradient vector at the bottleneck layer amalga-\nmates into a composite of gradients, each weighted according\nto the labels from the disparate wavelet-specific models. Fur-\nthermore, if a wavelet model is predisposed to misclassify\nclass c as class 1 (indicative of a bias specific to the wavelet\nmodel), the matrix Wr can adeptly recalibrate the gradients to\naccommodate this bias. The weights of the wavelet-specific\nmodels, WrR1, delineating the transition from the bottle-\nneck layer's output & to the wavelet labels vrh can be de-\""}, {"title": "3 Experiments", "content": "3.1 Dataset\nIn this study, we utilized a recently published EEG resting\nstate dataset from May 2023, comprising data from 88 sub-\njects across three categories: AD, FTD, and HC [Miltiadous\net al., 2023b]. This dataset was selected for its comprehen-\nsive data length for each subject and the novelty of its ap-\nplication in research. It features a balanced representation\nof conditions with 36 AD participants, 23 FTD subjects, and\n29 healthy HC. Data were collected using 19 EEG channels\n(Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3,\nPz, P4, T6, O1, and O2) and 2 reference electrodes, adhering\nto the international 10\u201320 system. The recordings offer a res-\nolution of 10 uV/mm at a sampling rate of 500 Hz. Duration\nvaried among groups: AD recordings averaged 13.5 minutes\n(ranging from 5.1 to 21.3 minutes), FTD recordings 12 min-\nutes (ranging from 7.9 to 16.9 minutes), and HC recordings\n13.8 minutes (ranging from 12.5 to 16.5 minutes), totalling\n485.5 minutes for AD, 276.5 minutes for FTD, and 402 min-\nutes for HC. Despite the resting state condition with closed\neyes, some recordings exhibited eye movement artifacts. To\naddress this, the dataset employed the Independent Compo-\nnent Analysis (ICA) method (specifically, the RunICA algo-\nrithm) to transform the 19 EEG signals into 19 ICA com-\nponents. Artifacts identified as eye or jaw movements were\nsubsequently removed using the \"ICLabel\" algorithm within\nthe EEGLAB platform [Delorme et al., 2007], ensuring the\nintegrity of the EEG data for analysis."}, {"title": "3.2 Settings", "content": "We trained our EEG-SSM model on the dataset previously\nreferenced, setting the model dimension (d-model) to match\nthe number of EEG channels, which is 19. The model dis-\ntinguishes between HC, FTD, and AD; thus, the number of\nclasses was set to 3. For the optimization process, we em-\nployed cross-entropy loss and the Adam optimizer [Kingma\nand Ba, 2014] with a learning rate of 0.001, iterating the train-\ning process over 500 epochs to ensure adequate learning and\nconvergence of the model.\nIn this study, we trained the EEG-SSM model using a\ndataset that includes a balanced division into training, test-\ning, and validation sets, each constituting 60%, 20%, and\n20% of the data, respectively. The model's efficacy was as-\nsessed against established benchmarks, such as a basic Recur-\nrent Neural Network (RNN) and an EEG-transformer model.\nConsistent across all models, we adhered to a training regi-\nmen of 500 epochs to ensure thorough learning and fair com-\nparison."}, {"title": "3.3 Dementia detection results", "content": "Benchmark models performance In assessing the perfor-\nmance of various models for classifying resting state neural\ndisorders, Table 1 presents a comparison across different seg-\nment lengths ranging from 2s to 256s. The RNN model,\nwith the least number of parameters at 8.6K, shows mod-\nerate performance, peaking at 42.7% accuracy for the 32s\nsegment. EEG-Net, with a slightly higher parameter count\nof 12K, demonstrates improved accuracy, particularly at 4s\nwith 55.6%. The EEG-Transformer, despite a significant in-\ncrease in parameters to 120K, attains its best performance at\na shorter 2s segment with 70.1% accuracy but shows a down-\nward trend as the segment length increases.\nEEG-SSM performance The EEG-SSM model exhibits\nsuperior performance across all variants when compared to\nthe RNN and EEG-Net, with the EEG-SSM variant, boast-\ning 4.4K parameters, outperforming other models in longer\nsegments. This variant achieves an impressive 91.0% accu-\nracy at 2s and maintains robust performance as the segment\nlength increases, highlighting its efficacy in handling various\ntemporal resolutions of EEG data. The EEG-SSM temporal and\nEEG-SSM spectral variants also show strong results, particu-\nlarly favoring the mid-range segment lengths of 16s to 64s.\nHowever, a common trend across all models is a decline in\nperformance at the longest segment length of 256s, with the\nEEG-SSM temporal variant experiencing the most significant\ndrop to 46.8% accuracy, suggesting a potential trade-off be-\ntween segment length and model efficacy. The provided con-\nfusion matrix, depicted in Figure 3, corresponds to the perfor-\nmance of the EEG-SSM model, which attained an impressive\naccuracy rate of 91.0% on a test set derived from 2-second\nEEG data segments. The total number of 2-second segments\nfor all subjects amounted to 35,254, with a data split ratio of\n60% for training, 20% for validation, and 20% for testing.\nThe matrix showcases the model's considerable accuracy in\ncorrectly identifying 2,751 instances of AD, 2,219 instances\nof HC, and 1,434 instances of FTD. Misclassifications were\nrecorded with AD misidentified as HC and FTD in 146 and\n75 instances, respectively; HC mistaken for AD and FTD in\n139 and 74 instances, respectively; and FTD confounded with\nAD and HC in 124 and 89 instances, respectively. These fig-\nures highlight the model's robust performance in distinguish-\ning AD and HC, indicating a need for further refinement in\naccurately classifying FTD to enhance its discernment from\nAD and HC conditions.\nThe role of EEG sampling rate in EEG-SSM model per-\nformance Table 2 delineates the performance of the EEG-\nSSM model variants to the number of EEG channels at two\ndistinct sampling rates, 250 Hz and 125 Hz. When analyzing\nthe results at the higher sampling rate of 250 Hz, the EEG-\nSSM model stands out with consistently high accuracy across\nall segment lengths, achieving its peak accuracy of 83.1% at\nthe 2s segment length. The EEG-SSM spectral variant, while\nslightly lagging behind its counterparts, still maintains a com-\nmendable performance, especially at 256s, where it nearly\nmatches the EEG-SSM model with an accuracy of 72.8%.\nThe performance trend alters slightly at the lower sampling\nrate of 125 Hz. Here, all EEG-SSM model variants generally\nshow a modest reduction in accuracy across the board. Never-\ntheless, the EEG-SSM combined model demonstrates resilience,\nmaintaining a strong performance with the highest accuracy\nof 73.6% at 4s. Interestingly, the performance gap between\nthe temporal and spectral variants narrows in the longer seg-\nment lengths, indicating a potential dependency of model per-\nformance on the interplay between sampling rate and EEG\ndata resolution.\nAcross both sampling rates, there is a notable trend where\naccuracy tends to decrease with increasing segment length,\naffirming the complexity of capturing informative features\nfrom extended data sequences. The EEG-SSM temporal vari-\nant, in particular, shows a significant decline in performance"}, {"title": "4 Discussion", "content": "In our exploration, we delve into the capabilities of the\nMamba model, tailoring it to effectively process multivariate\nEEG data across a spectrum of temporal resolutions. This en-\ndeavor led to creating the EEG-SSM temporal variant, high-\nlighting the model's adaptability to diverse EEG segment\nlengths. Additionally, we introduced the EEG-SSM spectral\nvariant, an innovative methodology that facilitates incorpo-\nrating spectral data from EEG signals into the Mamba frame-\nwork. The fusion of these two approaches culminates in the\nEEG-SSM combined model, which highlights the advantages\nof both temporal and spectral analyses to deliver superior\naccuracy and robustness against variations in EEG segment\nlengths.\nEEG Sequence Length Impact The Mamba model has\ndemonstrated exceptional performance in natural language\nprocessing (NLP) tasks, effectively handling sequence\nlengths up to 220 tokens [Gu and Dao, 2023]. However,\nour findings, as presented in Table 1, reveal a notable per-\nformance dip for the EEG-SSM temporal variant as the EEG\nsequence length increases. This decrease in accuracy can be\nattributed to the model treating each EEG timepoint as an in-\ndividual token, where the timepoint token dimension (19, 1)\nis significantly smaller compared to typical word token em-\nbeddings such as Word2Vec [Church, 2017].\nEEG Channel Effectiveness In our experiments with re-\nduced subsets of EEG channels (specifically, using 6 and 12\nchannels), we observed a decline in accuracy across all EEG-\nSSM model variants as the number of channels was reduced.\nThis trend likely arises from the unique brain signal infor-\nmation conveyed by each channel in multivariate EEG data,\nemphasizing the importance of spatial features representing\nbrain connectivity between EEG channels. Despite its suc-\ncess in extracting temporal and spectral features, the current\niteration of the EEG-SSM model does not incorporate spa-\ntial features, marking a limitation and an avenue for future\nresearch. The challenge in integrating spatial features lies in\ntheir differing data shape compared to temporal and spectral\nfeatures. Moving forward, we aim to develop methodologies\nto incorporate spatial features into the EEG-SSM model, en-\nhancing its screening capabilities by leveraging the compre-\nhensive neural information in EEG data.\nSpectral Feature Effectiveness A pivotal aspect of the\nEEG-SSM spectral variant is its capacity to account for in-\ndividual differences in EEG signal characteristics, thereby\noptimizing the contribution of distinct EEG frequency bands\nto each subject's data analysis. This nuanced approach not\nonly underscores the flexibility and computational efficiency\nof the EEG-SSM models but also improves the performance\nof screening methodologies within clinical neuroscience. The\nsequence length issue of Mamba prompted us to explore the\nincorporation of spectral EEG features as a means to main-\ntain consistent EEG-SSM performance across different seg-\nment lengths. The PSD extraction from EEG segments offers\na promising solution, as variations less influence PSD values\nin segment length, providing a stable feature set for the EEG-\nSSM model. As evidenced in Table 1, integrating PSD fea-\ntures has resulted in more stable model performance across\nvarious EEG segment lengths, underscoring the effectiveness\nof spectral information in enhancing the EEG-SSM frame-\nwork. Upon evaluating the EEG-SSM models across varying\nsampling rates (Table 2), we observed a uniform decline in\nperformance with the reduction of sampling rates. This out-\ncome is intuitively expected, as lower sampling rates yield\nfewer temporal data points for model training, resulting in di-\nminished EEG data information. Notably, the performance\nof the EEG-SSM temporal model is particularly sensitive to re-\nductions in sampling rate, a vulnerability that becomes more\npronounced with longer segment lengths. This sensitivity un-\nderscores the critical role of sampling rate in preserving the\nintegrity of temporal information within the EEG data, with\nlower rates leading to more significant information loss in the\ntemporal domain.\nTemporal and Spectral Combination Effectiveness It is\ncrucial to highlight that integrating temporal and spectral\nfeatures for training with the EEG-SSM model results in\nhigher and more consistent accuracy than training the model\nwith unimodal features. We achieved the peak accuracy of\n91.0% when training EEG-SSM with 2-second segments.\nThis performance surpasses that of existing studies utilizing\nthe same dataset. For instance, Miltiadous' approach, uti-\nlizing a Convolution-Transformer Architecture named DICE-\nNet [Miltiadous et al., 2023a], reported accuracies of 83.28%\nand 74.96% for AD-CN and FTD-CN models, respectively.\nAdditionally, a method combining CNNs and ViTs detailed in\n[Chen et al., 2023a] achieved an accuracy of 76.37%. These\ncomparisons underscore the efficacy of the EEG-SSM model\nin dementia detection, highlighting its potential for advancing\nscreening tools in clinical neuroscience."}, {"title": "5 Conclusion", "content": "Our study presents a novel method for analysing multivari-\nate EEG data through the novel application of the Mamba\nmodel, tailored for varying temporal resolutions. The devel-\nopment of EEG-SSM temporal and EEG-SSM spectral mod-\nels marks a pivotal step towards leveraging the full spectrum\nof EEG data, encompassing both temporal and spectral in-\nformation. This dual approach has demonstrated exceptional\nperformance, notably achieving an accuracy of 91.0% in dis-\ntinguishing between HC, FTD, and AD subjects, thereby\noutperforming existing methodologies on the same dataset.\nIncluding EEG-SSM spectral is particularly noteworthy for\nits ability to account for individual variability in EEG sig-\nnals, ensuring the model's broad applicability and enhanced\nscreening precision. Our findings underscore the potential of\nEEG-SSM models to improve clinical screening, offering a\nmore accurate, efficient, and cost-effective tool for screening\nto detect dementia early. This research showcases the versa-\ntility and effectiveness of the EEG-SSM framework. It lays a\nsolid foundation for future research in clinical neuroscience,\npromising improved screening solutions for a spectrum of\nneurological disorders."}]}