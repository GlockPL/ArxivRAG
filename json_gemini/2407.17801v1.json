{"title": "EEG-SSM: Leveraging State-Space Model for Dementia Detection", "authors": ["Xuan-The Tran", "Linh Le", "Quoc Toan Nguyen", "Thomas Do", "Chin-Teng Lin"], "abstract": "State-space models (SSMs) have garnered attention\nfor effectively processing long data sequences, re-\nducing the need to segment time series into shorter\nintervals for model training and inference. Tradi-\ntionally, SSMs capture only the temporal dynam-\nics of time series data, omitting the equally critical\nspectral features. This study introduces EEG-SSM,\na novel state-space model-based approach for de-\nmentia classification using EEG data. Our model\nfeatures two primary innovations: EEG-SSM tem-\nporal and EEG-SSM spectral components. The\ntemporal component is designed to efficiently pro-\ncess EEG sequences of varying lengths, while the\nspectral component enhances the model by inte-\ngrating frequency-domain information from EEG\nsignals. The synergy of these components allows\nEEG-SSM to adeptly manage the complexities of\nmultivariate EEG data, significantly improving ac-\ncuracy and stability across different temporal res-\nolutions. Demonstrating a remarkable 91.0% ac-\ncuracy in classifying Healthy Control (HC), Fron-\ntotemporal Dementia (FTD), and Alzheimer's Dis-\nease (AD) groups, EEG-SSM outperforms existing\nmodels on the same dataset. The development of\nEEG-SSM represents an improvement in the use of\nstate-space models for screening dementia, offer-\ning more precise and cost-effective tools for clini-\ncal neuroscience.", "sections": [{"title": "1 Introduction", "content": "Dementia, a cognitive decline that impairs memory and func-\ntional abilities, affects approximately 45 million people glob-\nally [Nichols et al., 2019], with numbers expected to increase\ndue to longer lifespans and an aging population. Alzheimer's\ndisease (AD), the most common form of dementia, accounts\nfor 60-80% of cases [Association and others, 2018], affecting\n1 in 9 individuals over 65 [Rajan et al., 2021]. It is a pro-\ngressive neurological disorder characterized by beta-amyloid\naccumulation and tau tangles, leading to neuronal death, brain\natrophy, and symptoms like memory loss, confusion, and be-\nhavioural changes. Frontotemporal degeneration (FTD), an-\nother form of dementia, leads to social, behavioural, and mo-\ntor deficits due to the deterioration of frontal and temporal\\lobes. FTD typically affects individuals aged 45-60 and rep-\nresents a significant portion of dementia cases, especially in\nthose under 65 [Hogan et al., 2016]. These dementia present\nsignificant healthcare challenges with substantial impacts on\npeople with dementia (PwD) [Beerens et al., 2014] and so-\nciety, underscoring the need for advancements in accurate\nscreening methods.\nThe standard screening approach for dementia typically in-\nvolves cognitive tests like the Mini-Mental State Examination\n(MMSE) [Folstein, 1975], the Montreal Cognitive Assess-\nment (MOCA) [Julayanont and Nasreddine, 2017], the Mini-\nCog test [Borson et al., 2000], and the Addenbrooke's Cog-\nnitive Examination III (ACE-III) [Bruno and Schurmann Vi-\ngnaga, 2019]. These tests are advantageous due to their sim-\nplicity and quick administration. However, their effectiveness\ncan be compromised by factors such as the patient's educa-\ntional background, emotional state, and test reiteration. Neu-\nroimaging techniques like MRI and PET scans offer greater\ndetecting accuracy but are hampered by high costs and the ne-\ncessity for extensive expert analysis [Sun et al., 2024]. Elec-\ntroencephalography (EEG) serves as a practical alternative,\nbeing cost-effective, non-invasive, and highly portable while\nproviding direct, high-resolution monitoring of brain activity.\nThe development of AI-based detecting models using EEG\ndata can potentially yield more accurate detection and reduce\nthe burden on healthcare professionals.\nThe quest for effective AI-based detection models for brain\ndisorders has led to the exploration of various machine-\nlearning techniques using EEG data. Traditional machine\nlearning models typically utilize temporal, spectral, and spa-\ntial features extracted from EEG signals for classification\ntasks. A notable study by McBride et al. [McBride et al.,\n2014] employed a support vector machine (SVM) to dis-\ntinguish between healthy controls (HC), mild cognitive im-\npairment (MCI), and PwD, achieving an accuracy rate of\n85.4%. Deep learning approaches have also been investi-\ngated for this purpose. Ieracitano et al. [Ieracitano et al.,\n2019] used a multilayer perceptron (MLP) model incorporat-\ning wavelet EEG features to classify the same groups, achiev-\ning an 89.2% accuracy. Another innovative study applied\na Boltzmann machine to spectral images from EEG chan-\nnels, achieving an impressive accuracy of 95%. Ensemble\nlearning methods, which combine multiple machine learning\nmodels, have shown promising results. For instance, Sun et\nal. [Sun et al., 2024] leveraged an ensemble approach using\nAdaboost to differentiate between HC, mild cognitive impair-\nment (MCI), and dementia groups with an accuracy of 93.3%\nacross a dataset including 75 HC, 99 with MCI, and 78 with\ndementia. Kim et al. [Kim et al., 2023] extended this ap-\nproach with an ensemble deep learning model validated on a\nsubstantial dataset of 1379 EEG recordings from 1155 PwD.\nIn the dataset leveraged for our research, Miltiadous et\nal. reported an accuracy of 83.28% for Alzheimer's dis-\nease versus Control (AD-CN) and 74.96% for Frontotempo-\nral Dementia versus Control (FTD-CN) using a Convolution-\nTransformer Architecture known as DICE-Net [Miltiadous et\nal., 2023a]. A separate method by Chen et al., which inte-\ngrated Convolutional Neural Networks (CNNs) with Visual\nTransformers (ViTs), attained an accuracy of 76.37% [Chen\net al., 2023a]. Our results will be juxtaposed with these find-\nings for a comprehensive comparison.\nThe burgeoning computational power and the advent of\ntransformer-based deep learning methods have ushered in\nnew opportunities for EEG data analysis. With their parallel\ncomputation abilities and self-attention mechanisms, trans-\nformers are well-suited for capturing the intricate temporal\npatterns within EEG signals that extend over long durations\n[Vaswani et al., 2017]. However, despite their advantages,\ntransformers are not without their challenges. They often ne-\ncessitate substantial computational resources, and their per-\nformance tends to wane as sequence lengths grow [Gu and\nDao, 2023]. This is a significant concern for EEG data\ncharacterized by complex and prolonged temporal dynam-\nics. To surmount the inherent limitations of transformers, a\nnovel approach known as the State Space Models with Se-\nlective Scan, or Mamba models, has been introduced [Gu\nand Dao, 2023]. These models strive to synergize the se-\nquential processing strength inherent in traditional state space\nmodels (SSM) [Hamilton, 1994] with the parallel processing\nand long-term memory retention proficiencies of transform-\ners. Mamba models are thus poised to capitalize on the best\nof both worlds, offering a promising new direction for en-\nhancing EEG data analysis and expanding the potential for\nAI-based screening in neurology. Several variations of the\nMamba model have been successfully applied in both the vi-\nsion [Zhu et al., 2024; Liu et al., 2024b; Ma et al., 2024;\nLiu et al., 2024a] and medical fields [Guo et al., 2024], yield-\ning promising results.\nIn this study, we propose an improved Mamba model by\nadapting it to varying temporal resolutions of multivariate\nEEG data. Our adaptation, termed EEG-SSM temporal, demon-\nstrates the model's versatility in handling different EEG seg-\nment sequence lengths. Furthermore, we have developed\nEEG-SSM spectral, a novel approach that enables the Mamba\nmodel to integrate spectral information from EEG signals.\nBy merging EEG-SSM temporal and EEG-SSM spectral, we for-\nmulate EEG-SSM combined, a hybrid model that leverages the\nstrengths of both temporal and spectral domains to achieve\nenhanced accuracy and stability, even as EEG segment length\nincreases. Crucially, EEG-SSM spectral addresses individ-\nual variability in EEG signals by determining the optimally\nweighted contributions of various EEG frequency bands for\neach subject's segment data. Our integrated approach not\nonly showcases the adaptability and efficiency of EEG-SSM\nmodels but also lays the groundwork for developing more\nprecise and computationally economical detection tools in\nclinical neuroscience."}, {"title": "2 Method", "content": "Our EEG-SSM model aims to harness the strengths of SSM\nin conjunction with multivariate EEG segmentation, as de-\ntailed in Figure 1. This section begins with an introduction\nto the key principles underpinning SSMs. It then delves into\nthe technique used to divide EEG data into multivariate seg-\nments, each defined by specific feature categories: temporal\nand spectral features (frequency). The section concluded by\npresenting a novel optimization strategy (Opt-W) designed to\nefficiently encode EEG wavelet bands, showcasing the inno-\nvative integration of SSM with EEG data analysis."}, {"title": "2.1 Preliminaries - SSM", "content": "The SSM functions by mapping the input vector $x \\in \\mathbb{R}^{1\\times D}$\nto a higher-dimensional latent space $h \\in \\mathbb{R}^{1\\times N}$ (where $N >\nD$), subsequently computing a mapping from $h$ to the output\n$y\\in \\mathbb{R}^{1\\times \\tilde{D}}$. The following set of equations formalizes the\nSSM:\n$$h'(t) = Ah(t) + Bx(t)$$\n$$y(t) = Ch(t) + Dx(t)$$\nwhere $A \\in \\mathbb{R}^{N\\times N}, B\\in \\mathbb{R}^{N\\times 1}, C\\in \\mathbb{R}^{1\\times N}$, and $D\\in \\mathbb{R}^{1\\times 1}$\nrepresent the learned parameter matrices of the model. Equa-\ntions 1 and 2, initially in continuous form, are not directly ap-\nplicable for deep learning tasks. To adapt these for use, they\nwere converted to a discrete form using the Zero-Order Hold\n(ZOH) method [Pohlmann, 2000]. Following this transfor-\nmation, a global convolution operation was applied to the dis-\ncretized form, rendering it suitable for input into the Mamba\nEncoder.\n$$K = (CB \\quad CAB \\quad \\dots \\quad CA^{M-1}B),$$\n$$y = x * K,$$\nwhere $M$ signifies the length of the input sequence $x$, and $K$\nis an $\\mathbb{R}^M$ - dimensional structured convolutional kernel."}, {"title": "2.2 EEG Preprocess", "content": "Segmentation\nThe Mamba architecture, originally tailored for 1-D se-\nquences, has been adapted in this work for multivariate EEG\ndata to encapsulate all EEG feature dimensions, as depicted\nin Figure 1. The upper module of the architecture processes\nsegmented multivariate EEG data, preparing it for the EEG-\nSSM encoder block. A key attribute of the Mamba model is\nits proficiency in managing long sequence data, rendering it\nparticularly apt for resting-state EEG analysis. This attribute\nallows for EEG data segmentation into various lengths with\nminimal data information loss.\nTemporal EEG: To process the multivariate EEG data\ninto blocks suitable for encoder networks, we initiate by\nconverting the 3-dimensional EEG data, denoted as $t \\in\n\\mathbb{R}^{N_{seg} \\times N_c\\times N_{seq}}$, into flattened 2-dimensional patches repre-\nsented by $x_p \\in \\mathbb{R}^{N_c\\times N_{seq}}$. Here, $N_{seg}$ signifies the number\nof segments, $N_c$ stands for the number of channels, and $N_{seq}$\ndenotes the segment length corresponding to the number of\ntime points within a single EEG segment. For instance, a\nsegment with a length of 2 seconds could encompass a se-\nquence ranging from time frame = 0 to time frame = 2s. Sub-\nsequently, these 2-D patches $x_p$ are linearly projected onto a\nvector of size $M$, which facilitates the extraction of temporal\nfeatures from the EEG data follows: $T_0=[t^S_1; t^S_2; ...; t^S_J]$\nwhere $t^S_0$ is the $j$-th patch of the original EEG sequence,\n$s \\in \\mathbb{R}^{N_c\\times N_{seq}}$. The EEG-SSM encoder is used in individ-\nual segments, extracting representative EEG features for each\nsegment. Given that Mamba operates on 1D sequences, the\ntemporal domain data, $X_{temporal}$, retaining the original shape\nof the EEG segment input, transforms a Forward Conv1D\nlayer into a 1D array as follows:\n$$x(t) = [Conv1d(t^S_1); ...; Conv1d(t^S_J)]$$\nSpectral EEG\n\u2022 Wavelet Filter: We employ a Wavelet Filter [Xu et al.,\n1994], denoted as \u03a9, to process EEG data for feature\nextraction. Specifically, we focus on segmenting the\nEEG signals into distinct frequency bands, each associ-\nated with different cognitive states and activities. These\nbands include the Delta band (0.5\u20134Hz), Theta band (4-\n8Hz), Alpha band (8-12 Hz), Beta band (12\u201320 Hz), and\nGamma band (20\u201340 Hz), which are utilized to feature\nthe EEG data for subsequent analysis [Sun et al., 2024].\n\u2022 In the spectral domain, Power Spectral Density (PSD)\nfeatures are computed using Welch's method [Welch,\n1967] to obtain $X_{spectral}$ before its transformation to a 1D\narray by an additional Forward Conv1D layer follows:\n$$x(t) = [Conv1d(\\Omega(X_1)); ...; Conv1d(\\Omega(X_J))]$$\nMamba Input In our methodology, the Mamba system is\ndesigned with three distinct inputs $x(t)$ (see Equation 1) :\none for purely temporal features (Equation 5), another for ex-\nclusively spectral features Equation 6), and a third that con-\ncatenates both temporal and spectral features, allowing for a\ncomprehensive analysis through separate yet complementary\ndata feature types (see Figure 1)."}, {"title": "2.3 EEG wavelet optimization for spectral features\n(Opt-W)", "content": "Previous research [Swarnalatha and others, 2023; Al-\nSharabi et al., 2022; Sedghizadeh et al., 2022] in the field of\ncognitive impairment and dementia detection has been lim-\nited by an inability to automatically optimize the weights\namong wavelet bands (Delta, Theta, Alpha, Beta, Gamma).\nThe ratio between these bands plays a critical role in identi-\nfying various cognitive conditions [Chikhi et al., 2022], un-\nderscoring the need for a solution capable of dynamically of\neach wavelet's importance band according to the specific type\nof dementia and the patient's condition. Implementing such\na system would significantly enhance the accuracy and effi-\ncacy of classifying cognitive problems. In this segment, we\ndelineate the ensemble layer, an innovative network layer en-\ngineered for the efficacious training of deep neural networks\nby leveraging features from separate wavelet-specific models\nto automatically update the weights featuring the combina-\ntion of different wavelet bands (Delta, Theta, Alpha, Beta,\nGamma) for spectral features. The foundational idea is intu-\nitive: the ensemble layer assimilates inputs typically desig-\nnated for the ultimate layer of a deep neural network (such as\na softmax layer for classification) and orchestrates a wavelet-\nspecific linkage from this terminal layer to the labels of var-\nious wavelet-centric models. This linkage adeptly encapsu-\nlates the distinct reliabilities and the biases introduced by\nspecific wavelet bands, transforming the conventional output\nlayer into a pivotal bottleneck layer that is communally uti-\nlized by different wavelet-centric models. For illustrative pur-\nposes, Figure 2 portrays this bottleneck configuration within\na neural network framework tailored for EEG classification\nchallenges, featuring three classes and encompassing R mod-\nels, inclusive of 5 wavelet-specific models.\nThe methodology entails employing the labels from a des-\nignated wavelet band to disseminate errors throughout the\nneural network. The ensemble layer meticulously adjusts the\ngradients emanating from the labels of that particular wavelet\nband, aligning them with its accuracy through scaling and\nbias modulation. Consequently, the bottleneck layer of the\nnetwork aggregates these tailored gradients from the labels of\nvarious wavelet-centric models and propels them backward\nthrough the network's remaining structure. This orchestra-\ntion, facilitated by the so-called \u201censemble layer\", empowers\nthe network to mitigate the influence of unreliable labelers\nand rectify persistent biases in their labels, all within the tra-\nditional backpropagation paradigm.\nFormally, let $s$ symbolize the output of a deep neural net-\nwork with an arbitrary architecture. For the sake of simplic-\nity, we postulate that $s$ emerges from a softmax layer, with $\\xi_c$\ndenoting the probability of classifying the input instance into\ncategory $c$. The activation for each wavelet-specific model $r$\nwithin the ensemble layer is defined as $m^r = f_r(\\xi)$, where $f_r$\nsignifies a wavelet-specific function, and the output of the en-\nsemble layer is rendered as the softmax of these activations:\n$$\\psi = \\frac{e^{m^r}}{\\sum^R_{r=1}}$$\nThe conundrum then lies in formulating the function $f_r(\\xi)$.\nIn the experimental section, we explore various alternatives.\nFor classification endeavors, it is plausible to envisage a\nmatrix transformation such that $f_r(\\xi) = W_r\\xi$, where $W_r$\nrepresents a wavelet-specific matrix. Given a cost function\n$\\mathcal{E}(\\psi^r, y^r)$ that juxtaposes the expected output of the $r^{th}$\nwavelet-specific model with its actual label $y^r$, we can ascer-\ntain the gradients at the activation $m^r$ for each model\nand backpropagate them to the bottleneck layer, culminating\nin the equation:\n$$\\frac{\\Delta \\mathcal{E}}{\\Delta \\xi} = \\sum^R_{r=1} \\frac{\\Delta \\mathcal{E}}{\\Delta m^r} \\frac{\\Delta m^r}{\\Delta \\xi}$$\nHence, the gradient vector at the bottleneck layer amalga-\nmates into a composite of gradients, each weighted according\nto the labels from the disparate wavelet-specific models. Fur-\nthermore, if a wavelet model is predisposed to misclassify\nclass c as class 1 (indicative of a bias specific to the wavelet\nmodel), the matrix $W_r$ can adeptly recalibrate the gradients to\naccommodate this bias. The weights of the wavelet-specific\nmodels, $W_r \\in \\mathbb{R}^{1\\times R}$, delineating the transition from the bottle-\nneck layer's output $\\xi$ to the wavelet labels $\\psi_{rh}$ can be de-\""}, {"title": "3 Experiments", "content": "3.1 Dataset\nIn this study, we utilized a recently published EEG resting\nstate dataset from May 2023, comprising data from 88 sub-\njects across three categories: AD, FTD, and HC [Miltiadous\net al., 2023b]. This dataset was selected for its comprehen-\nsive data length for each subject and the novelty of its ap-\nplication in research. It features a balanced representation\nof conditions with 36 AD participants, 23 FTD subjects, and\n29 healthy HC. Data were collected using 19 EEG channels\n(Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3,\nPz, P4, T6, O1, and O2) and 2 reference electrodes, adhering\nto the international 10\u201320 system. The recordings offer a res-\nolution of 10 uV/mm at a sampling rate of 500 Hz. Duration\nvaried among groups: AD recordings averaged 13.5 minutes\n(ranging from 5.1 to 21.3 minutes), FTD recordings 12 min-\nutes (ranging from 7.9 to 16.9 minutes), and HC recordings\n13.8 minutes (ranging from 12.5 to 16.5 minutes), totalling\n485.5 minutes for AD, 276.5 minutes for FTD, and 402 min-\nutes for HC. Despite the resting state condition with closed\neyes, some recordings exhibited eye movement artifacts. To\naddress this, the dataset employed the Independent Compo-\nnent Analysis (ICA) method (specifically, the RunICA algo-\nrithm) to transform the 19 EEG signals into 19 ICA com-\nponents. Artifacts identified as eye or jaw movements were\nsubsequently removed using the \"ICLabel\" algorithm within\nthe EEGLAB platform [Delorme et al., 2007], ensuring the\nintegrity of the EEG data for analysis.\n3.2 Settings\nWe trained our EEG-SSM model on the dataset previously\nreferenced, setting the model dimension (d-model) to match\nthe number of EEG channels, which is 19. The model dis-\ntinguishes between HC, FTD, and AD; thus, the number of\nclasses was set to 3. For the optimization process, we em-\nployed cross-entropy loss and the Adam optimizer [Kingma\nand Ba, 2014] with a learning rate of 0.001, iterating the train-\ning process over 500 epochs to ensure adequate learning and\nconvergence of the model.\nIn this study, we trained the EEG-SSM model using a\ndataset that includes a balanced division into training, test-\ning, and validation sets, each constituting 60%, 20%, and\n20% of the data, respectively. The model's efficacy was as-\nsessed against established benchmarks, such as a basic Recur-\nrent Neural Network (RNN) and an EEG-transformer model.\nConsistent across all models, we adhered to a training regi-\nmen of 500 epochs to ensure thorough learning and fair com-\nparison."}, {"title": "3.3 Dementia detection results", "content": "Benchmark models performance In assessing the perfor-\nmance of various models for classifying resting state neural\ndisorders, Table 1 presents a comparison across different seg-\nment lengths ranging from 2s to 256s. The RNN model,\nwith the least number of parameters at 8.6K, shows mod-\nerate performance, peaking at 42.7% accuracy for the 32s\nsegment. EEG-Net, with a slightly higher parameter count\nof 12K, demonstrates improved accuracy, particularly at 4s\nwith 55.6%. The EEG-Transformer, despite a significant in-\ncrease in parameters to 120K, attains its best performance at\na shorter 2s segment with 70.1% accuracy but shows a down-\nward trend as the segment length increases.\nEEG-SSM performance The EEG-SSM model exhibits\nsuperior performance across all variants when compared to\nthe RNN and EEG-Net, with the EEG-SSM variant, boast-\ning 4.4K parameters, outperforming other models in longer\nsegments. This variant achieves an impressive 91.0% accu-\nracy at 2s and maintains robust performance as the segment\nlength increases, highlighting its efficacy in handling various\ntemporal resolutions of EEG data. The EEG-SSM temporal and\nEEG-SSM spectral variants also show strong results, particu-\nlarly favoring the mid-range segment lengths of 16s to 64s.\nHowever, a common trend across all models is a decline in\nperformance at the longest segment length of 256s, with the\nEEG-SSM temporal variant experiencing the most significant\ndrop to 46.8% accuracy, suggesting a potential trade-off be-\ntween segment length and model efficacy. The provided con-\nfusion matrix, depicted in Figure 3, corresponds to the perfor-\nmance of the EEG-SSM model, which attained an impressive\naccuracy rate of 91.0% on a test set derived from 2-second\nEEG data segments. The total number of 2-second segments\nfor all subjects amounted to 35,254, with a data split ratio of\n60% for training, 20% for validation, and 20% for testing.\nThe matrix showcases the model's considerable accuracy in\ncorrectly identifying 2,751 instances of AD, 2,219 instances\nof HC, and 1,434 instances of FTD. Misclassifications were\nrecorded with AD misidentified as HC and FTD in 146 and\n75 instances, respectively; HC mistaken for AD and FTD in\n139 and 74 instances, respectively; and FTD confounded with\nAD and HC in 124 and 89 instances, respectively. These fig-\nures highlight the model's robust performance in distinguish-\ning AD and HC, indicating a need for further refinement in\naccurately classifying FTD to enhance its discernment from\nAD and HC conditions.\nThe role of EEG sampling rate in EEG-SSM model per-\nformance Table 2 delineates the performance of the EEG-\nSSM model variants to the number of EEG channels at two\ndistinct sampling rates, 250 Hz and 125 Hz. When analyzing\nthe results at the higher sampling rate of 250 Hz, the EEG-\nSSM model stands out with consistently high accuracy across\nall segment lengths, achieving its peak accuracy of 83.1% at\nthe 2s segment length. The EEG-SSM spectral variant, while\nslightly lagging behind its counterparts, still maintains a com-\nmendable performance, especially at 256s, where it nearly\nmatches the EEG-SSM model with an accuracy of 72.8%.\nat the longest segment of 256s across both sampling rates,\nwhich may suggest limitations in the model's ability to pro-\ncess temporal features over extended periods. Conversely, the\nrobustness of the EEG-SSM combined model across varied seg-\nment lengths underscores its effectiveness in integrating mul-\ntiple feature domains for neural disorder classification, even\nas the sampling rate varies.\nThe role of EEG channels in EEG-SSM model perfor-\nmance In Table 3, we assess the EEG-SSM model's per-\nformance across different numbers of EEG channels, specif-\nically examining various combinations of 6 and 12-channel\nconfigurations across various segment lengths ranging from\n2 seconds to 256 seconds, the highest accuracy of 6 and 12-\nchannels combination is selected to report. The EEG-SSM\ntemporal model, which focuses on temporal features, shows a\nperformance boost when the number of channels is increased\nfrom 6 to 12, with accuracy improving from 68.4% to 76.7%\nfor the 2s segment length. This trend of improved perfor-\nmance with more channels is consistent across all segment\nlenghts for the temporal model, although the accuracy decre-\nment with longer segments remains evident.\nThe EEG-SSM spectral model, which relies on spectral fea-\ntures, also benefits from increased channels. With 6 channels,\nthe spectral model peaks at 60.6% accuracy at the 2s seg-\nment, while the 12-channel configuration sees a notable jump\nto 77.1% accuracy for the same segment length. The spectral\nmodel retains higher accuracy rates with increasing segment\nlenghts when more channels are utilized, suggesting that ad-\nditional channels provide a richer spectral representation that\nthe model can leverage for classification.\nThe EEG-SSM combined model, which integrates both tem-\nporal and spectral features, achieves the highest accuracy\nacross both channel configurations. For the 6-channel setup,\nthe combined model's best performance is at 4s segment\nlength with 67.5% accuracy, while the 12-channel configu-\nration sees its peak performance of 78.4% at the 2s segment\nlength. This model's accuracy is superior at shorter segments\nand remains relatively stable across longer segments, high-\nlighting the combined model's robustness and ability to uti-\nlize a more comprehensive feature set effectively.\nThe overall trend observed in Table 3 suggests that the per-\nformance of all EEG-SSM model variants is influenced by\nthe number of EEG channels and the segment length. There\nis a clear pattern where the combined model consistently out-\nperforms the individual temporal and spectral models, indi-\ncating that a multifaceted approach to feature integration can\nyield more accurate neural disorder classification across vari-\nous EEG data resolutions."}, {"title": "4 Discussion", "content": "In our exploration, we delve into the capabilities of the\nMamba model, tailoring it to effectively process multivariate\nEEG data across a spectrum of temporal resolutions. This en-\ndeavor led to creating the EEG-SSM temporal variant, high-\nlighting the model's adaptability to diverse EEG segment\nlenghts. Additionally, we introduced the EEG-SSM spectral\nvariant, an innovative methodology that facilitates incorpo-\nrating spectral data from EEG signals into the Mamba frame-\nwork. The fusion of these two approaches culminates in the\nEEG-SSM combined model, which highlights the advantages\nof both temporal and spectral analyses to deliver superior\naccuracy and robustness against variations in EEG segment\nlengths.\nEEG Sequence Length Impact The Mamba model has\ndemonstrated exceptional performance in natural language\nprocessing (NLP) tasks, effectively handling sequence\nlengths up to $2^{20}$ tokens [Gu and Dao, 2023]. However,\nour findings, as presented in Table 1, reveal a notable per-\nformance dip for the EEG-SSM temporal variant as the EEG\nsequence length increases. This decrease in accuracy can be\nattributed to the model treating each EEG timepoint as an in-\ndividual token, where the timepoint token dimension (19, 1)\nis significantly smaller compared to typical word token em-\nbeddings such as Word2Vec [Church, 2017].\nEEG Channel Effectiveness In our experiments with re-\nduced subsets of EEG channels (specifically, using 6 and 12\nchannels), we observed a decline in accuracy across all EEG-\nSSM model variants as the number of channels was reduced.\nThis trend likely arises from the unique brain signal infor-\nmation conveyed by each channel in multivariate EEG data,\nemphasizing the importance of spatial features representing\nbrain connectivity between EEG channels. Despite its suc-\ncess in extracting temporal and spectral features, the current\niteration of the EEG-SSM model does not incorporate spa-\ntial features, marking a limitation and an avenue for future\nresearch. The challenge in integrating spatial features lies in\ntheir differing data shape compared to temporal and spectral\nfeatures. Moving forward, we aim to develop methodologies\nto incorporate spatial features into the EEG-SSM model, en-\nhancing its screening capabilities by leveraging the compre-\nhensive neural information in EEG data.\nSpectral Feature Effectiveness A pivotal aspect of the\nEEG-SSM spectral variant is its capacity to account for in-\ndividual differences in EEG signal characteristics, thereby\noptimizing the contribution of distinct EEG frequency bands\nto each subject's data analysis. This nuanced approach not\nonly underscores the flexibility and computational efficiency\nof the EEG-SSM models but also improves the performance\nof screening methodologies within clinical neuroscience. The\nsequence length issue of Mamba prompted us to explore the\nincorporation of spectral EEG features as a means to main-\ntain consistent EEG-SSM performance across different seg-\nment lengths. The PSD extraction from EEG segments offers\na promising solution, as variations less influence PSD values\nin segment length, providing a stable feature set for the EEG-\nSSM model. As evidenced in Table 1, integrating PSD fea-\ntures has resulted in more stable model performance across\nvarious EEG segment lengths, underscoring the effectiveness\nof spectral information in enhancing the EEG-SSM frame-\nwork. Upon evaluating the EEG-SSM models across varying\nsampling rates (Table 2), we observed a uniform decline in\nperformance with the reduction of sampling rates. This out-\ncome is intuitively expected, as lower sampling rates yield\nfewer temporal data points for model training, resulting in di-\nminished EEG data information. Notably, the performance\nof the EEG-SSM temporal model is particularly sensitive to re-\nductions in sampling rate, a vulnerability that becomes more\npronounced with longer segment lengths. This sensitivity un-\nderscores the critical role of sampling rate in preserving the\nintegrity of temporal information within the EEG data, with\nlower rates leading to more significant information loss in the\ntemporal domain.\nTemporal and Spectral Combination Effectiveness It is\ncrucial to highlight that integrating temporal and spectral\nfeatures for training with the EEG-SSM model results in\nhigher and more consistent accuracy than training the model\nwith unimodal features. We achieved the peak accuracy of\n91.0% when training EEG-SSM with 2-second segments.\nThis performance surpasses that of existing studies utilizing\nthe same dataset. For instance, Miltiadous' approach, uti-\nlizing a Convolution-Transformer Architecture named DICE-\nNet [Miltiadous et al., 2023a], reported accuracies of 83.28%\nand 74.96% for AD-CN and FTD-CN models, respectively.\nAdditionally, a method combining CNNs and ViTs detailed in\n[Chen et al., 2023a] achieved an accuracy of 76.37%. These\ncomparisons underscore the efficacy of the EEG-SSM model\nin dementia detection, highlighting its potential for advancing\nscreening tools in clinical neuroscience."}, {"title": "5 Conclusion", "content": "Our study presents a novel method for analysing multivari-\nate EEG data through the novel application ofthe Mamba\nmodel, tailored for varying temporal resolutions. The devel-\nopment of EEG-SSM temporal and EEG-SSM spectral mod-\nels marks a pivotal step towards leveraging the full spectrum\nof EEG data, encompassing both temporal and spectral in-\nformation. This dual approach has demonstrated exceptional\nperformance, notably achieving an accuracy of 91.0% in dis-\ntinguishing between HC, FTD, and AD subjects, thereby\noutperforming existing methodologies on the same dataset.\nIncluding EEG-SSM spectral is particularly noteworthy for\nits ability to account for individual variability in EEG sig-\nnals, ensuring the model's broad applicability and enhanced\nscreening precision. Our findings underscore the potential of\nEEG-SSM models to improve clinical screening, offering a\nmore accurate, efficient, and cost-effective tool for screening\nto detect dementia early. This research showcases the versa-\ntility and effectiveness of the EEG-SSM framework. It lays a\nsolid foundation for future research in clinical neuroscience,\npromising improved screening solutions for a spectrum of\nneurological disorders."}]}