{"title": "MLDGG: META-LEARNING FOR DOMAIN GENERALIZATION ON GRAPHS", "authors": ["Qin Tian", "Chen Zhao", "Minglai Shao", "Wenjun Wang", "Yujie Lin", "Dong Li"], "abstract": "Domain generalization on graphs aims to develop models with robust generalization capabilities, ensuring effective performance on the testing set despite disparities between testing and training distributions. However, existing methods often rely on static encoders directly applied to the target domain, constraining its flexible adaptability. In contrast to conventional methodologies, which concentrate on developing specific generalized models, our framework, MLDGG, endeavors to achieve adaptable generalization across diverse domains by integrating cross-multi-domain meta-learning with structure learning and semantic identification. Initially, it introduces a generalized structure learner to mitigate the adverse effects of task-unrelated edges, enhancing the comprehensiveness of representations learned by Graph Neural Networks (GNNs) while capturing shared structural information across domains. Subsequently, a representation learner is designed to disentangle domain-invariant semantic and domain-specific variation information in node embedding by leveraging causal reasoning for semantic identification, further enhancing generalization. In the context of meta-learning, meta-parameters for both learners are optimized to facilitate knowledge transfer and enable effective adaptation to graphs through fine-tuning within the target domains, where target graphs are inaccessible during training. Our empirical results demonstrate that MLDGG surpasses baseline methods, showcasing the effectiveness in three different distribution shift settings.", "sections": [{"title": "1 Introduction", "content": "Domain generalization is a fundamental research area in machine learning that aims to enhance the ability of models learned from source domains to generalize well to different target domains [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]. While handling distribution shifts across domains on Euclidean data has achieved significant success [13, 14], there has been limited focus on graph-structured data due to specific challenges where domains are characterized by variations of node features and graph topological structures simultaneously. Consequently, a model trained on one graph domain (e.g., gamer networks, TWITCH) may exhibit poor generalization performance when deployed in a different domain (e.g., social networks, FB-100).\nTo address the problem of domain generalization on graphs, several efforts have been made. Existing approaches on invariant learning with Graph Neural Networks (GNNs) [15, 16] focus on encoding invariant information of graphs by minimizing the risk across various environments under the assumption that the information determining labels remain constant. They usually assume access to abundant and diverse training domains, prompting researchers to propose data augmentation [17, 18, 19] to alleviate the problem, which strives to diversify the training domains as much as possible to improve the generalization ability of the model. However, an overly flexible domain augmentation strategy can create implausible augmented domains [20]. Additionally, the complexity of real-world graph structures and the often unknown underlying data generation mechanisms make it challenging to acquire the knowledge necessary for generating new graphs.\nMoreover, to alleviate the above obstacles and enhance the interpretability of generalized models, causal reasoning is often combined with invariant learning [21, 22]. The invariance principle from causality elucidates and models the underlying generative processes of graphs, targeting the identification of stable causal relationships across different domains. Nevertheless, studies show that trained GNNs are heavily biased towards specific graph structures and cannot effectively address the domain variations on graph topology structures [23].\nAdditionally, some studies integrate structure learning to improve the robustness of generalized GNNs, such as capturing the domain-independent and domain-invariant clusters to learn invariant representations [23] by training static encoders shared by all source graphs [28]. However, capturing invariant topology structure learners across domains reduces the adaptability of the structural encoder and limits its ability to accommodate various distributions. Hence, it is urgent to train models who possess transferable knowledge across domains with various distribution shifts.\nIn this paper, we propose a novel cross-multi-domain meta-learning framework, MLDGG, designed to acquire transferable knowledge from graphs sampled in the source domain and generalize to those in the target domain, where target graphs are inaccessible during training. Specifically, to address the problem of node-level domain generalization on graphs, where domain variations are characterized by graph topological structures and node features, MLDGG comprises two key components: a structure learner and a representation learner. The structure learner aims to mitigate the adverse effects of task-unrelated edges and capture structure knowledge shared across different domains, enhancing the comprehensiveness of representations learned by GNNs. The representation learner disentangles semantic and variation factors to capture the invariant patterns of the truly predicting properties in different domains. In the context of meta-learning, the goal of MLDGG aims to learn optimal meta-parameters (initialization) for both learners so that they can facilitate knowledge transfer and enable effective adaptation to graphs through fine-tuning within the target domains. Our contributions are summarized as follows:\n\u2022 We propose a novel cross-multi-domain meta-learning framework on graphs. It is designed to acquire transferable knowledge from graphs sampled in the source domain and generalize to those in the target domain, where target graphs are inaccessible during training.\n\u2022 The framework consists of two key learners: a structure learner, which captures shared topology patterns across different graph domains to enhance the robustness of GNNs, and a representation learner, which disentangles domain-invariant semantics from domain-specific variations. In the context of meta-learning, the parameter initializations for both learners are optimized to facilitate knowledge transfer and enable effective adaptation to graphs through fine-tuning within the target domains.\n\u2022 Empirically, we conduct three distinct cross-domain settings to assess the generalization ability of MLDGG for node-level prediction tasks under different degrees of distribution shifts using real-world graph datasets. Our method consistently outperforms state-of-the-art baseline approaches."}, {"title": "2 Related Work", "content": "Domain Generalization on Graphs. Domain generalization aims to generalize a model trained on multiple seen domains with diverse distributions to perform well on an unseen target domain [29]. The study of domain generalization on graphs presents significant challenges due to the irregular nature of graph data and the complex dependencies between nodes [30, 31]. Methodologically, various strategies such as robust optimization [32, 33], invariant learning [34, 16, 15], causal approaches [21, 22] and meta-learning domain generalization [35, 36, 37, 38] have been employed to tackle this problem. Robust optimization improves the generalization ability by improving the model's performance in the worst-case data distribution. Invariant learning minimizes prediction variance across domains to capture invariant features across domains. Causal approaches are dedicated to separating inclusive information factors (semantic information) and irrelevant factors, utilizing the principles of causal graphs in an unsupervised or semi-supervised manner. In addition, GraphGlow [28] improves GNN generalization by learning generic graph structures. It trains a static structure encoder to capture invariant structure information across domains and apply it in the target domain, which reduces the adaptability of the structural encoder and limits its ability to accommodate various distributions. Despite GNNs' ability to extract abstract representations, they mix the domain-invariant semantic factor with the domain-specific variation factor. Meta-learning learns prior experiences during meta-training and transforms learned knowledge to the target domain by simple fine-tuning. Following similar spirits, we use a combination of learning domain-invariant semantic information and learning-to-learn strategies to achieve domain generalization across domains.\nMeta-Learning on Graphs. Meta-learning, also known as \"learning to learn\", focuses on the ability of a model to learn and adapt to new tasks or domains quickly and efficiently [39, 40]. It has been widely used in generalization problems [41, 42, 43, 20]. Consequently, meta-learning for graphs generally combines the advantages of GNNS and meta-learning to implement generalization on irregular graph data [44, 45]. From the learning tasks of view, these methods generally fall into three categories, node-level [46, 47], edge-level [44, 38] and graph-level [48, 49]. Methodologically, these approaches incorporate metric-based [50, 51], which are aimed at learning metrics to quantify the similarity between task-specific support and query sets, and optimization-based methods [52, 53] that concentrate on effectively training a well-initialized learner capable of rapidly adapting to new few-shot tasks via simple fine-tuning. However, they only consider the scene where all tasks originate from the same domain, the challenge of generalizing prior experiences from cross-multi-domain graphs during meta-training and transferring knowledge to unseen domains is unexplored in the existing literature."}, {"title": "3 Preliminaries", "content": "We list all notations used in this paper in Table 7 in Appendix A.\nNode-level Domain Generalization on Graphs. Given a set of graphs \\(G = \\{G^{e_i}\\}_{i=1}^K\\), where each graph \\(G^{e_i} = (A^{e_i}, X^{e_i})\\) is sampled from a unique domain \\(e_i \\in E\\) and a domain \\(e_i\\) is defined as a joint distribution \\(P(A^{e_i}, X^{e_i})\\). In each graph \\(G^{e_i}\\), we denote \\(A^{e_i} \\in \\{0,1\\}^{|V^{e_i}|\\times|V^{e_i}|}\\) the adjacency matrix, where \\(V^{e_i}\\) is a collection of nodes. \\(X^{e_i} = R^{|V^{e_i}|\\times D_{e_i}}\\) represents the node feature matrix of D-dimensional vectors. \\(y^{e_i} = \\{y^{e_i}_j\\}_{j=1}^{|V^{e_i}|}\\) denotes node labels in \\(G^{e_i}\\).\nFor node-level domain generalization, each graph \\(G^{e_i} \\in G\\) is associated with a specific variation in graphic topology \\(A^{e_i}\\) and node features \\(X^{e_i}\\). The graph set G is partitioned into multiple source graphs \\(G_s = \\{G^{e_i}\\}_{i=1}^{K}\\) where \\(K = |E_s|\\) and \\(E_s \\subset E\\), and target graphs \\(G_t\\) with \\(E_t = E\\setminus E_s\\). The objective is to maintain satisfactory generalization performance in node-level prediction accuracy transitioning from given source graphs \\(G_s\\) to target graphs \\(G_t\\), with the condition that \\(G_t\\) remains inaccessible during training.\nMeta-Learning is an approach aimed at training a model over a range of tasks to be able to adapt to new tasks rapidly [54, 55, 20], where each task \\(T^i \\sim P(T)\\) associated with a data batch is partitioned into a support set \\(T_{sup}\\) for the learning phase and a query set \\(T_{qry}\\) for evaluation purposes. Meta-learning can be described as \"learning to learn\" because it involves finding a meta-parameter \\(\\theta\\) from which one can quickly derive multiple optimized parameters \\(\\theta_i\\}_{i=1}^M\\) specific to individual tasks \\(\\{T^i\\}_{i=1}^M\\).\nModel-agnostic meta-learning (MAML) [39] is a notable gradient-based meta-learning approach that has demonstrated remarkable success in generalization. The core assumption of MAML is that some internal representations are better suited to transfer learning.\nDuring training, the model first learns from \\(T_{sup}^i\\) for each task \\(T^i\\) and accordingly optimizes the task-specific parameter to \\(\\theta'_i\\) with one or few gradient steps. The meta-parameter \\(\\theta\\) is updated through query losses evaluated from \\(\\{T_{qry}^i\\}_{i=1}^M\\)"}, {"title": "4 Methodology", "content": "The primary challenges of MLDGG involve modeling and capturing generalizable structure patterns across multiple domains, as well as disentangling domain-invariant semantic factors and domain-specific variation factors. To this end, the structure learner \\(f_t\\) is devoted to capturing shared structural information across domains while enhancing the comprehensiveness of representations learned by GNN through mitigating the adverse effects of task-unrelated edges (Sec. 4.1). Additionally, the representation learner \\(f_r\\) captures the invariant patterns of the truly predictive properties through the semantic encoder \\(E_s\\) by disentangling semantic and variation factors in node representations based on the causal invariance principle (Sec. 4.2). Finally, in Sec. 4.3, we integrate two learners within the meta-learning framework to capture transferable knowledge across various domains. For simplicity, in this section, domain \\(e_i\\) is simplified to i.\n4.1 Structure Learner\nFor graph data with both attributes and topologies, how to learn as comprehensive and rich node representation as possible is a problem that has been explored. One prevalent method is GNNs, which learns node representations through recursive aggregation of information from neighboring nodes. However, based on the model of the message-passing mechanism, small noise propagation to neighboring areas may cause deterioration of the representation quality.\nTherefore, we optimize GNN by learning high-quality graph structures. Further, we also explore the common structural pattern between cross-domain graphs to improve generalization ability. Here, we define a refined graph structure matrix as \\(A'\\) learned by a graph structure learner \\(f_t\\). The \\(f_t\\) is expected to produce optimal graph structures that can give rise to satisfactory downstream classification performance.\nFirst, we learn an intermediate similarity graph matrix F, where \\(F_{jk}\\) denotes the edge weights of node j and k. To fuse attributes and topological information, we use the representation of nodes \\(r \\in R^d\\) to calculate the weight of edges between nodes:\n\\[F_{jk} = \\delta(r_j\\hat{w}, r_k\\hat{w}),\\]\nwhere \\(\\hat{w} \\in R^m\\) is a weight vector and is trainable, \\(\\delta(\\cdot, \\cdot)\\) is a similarity function that includes simple dot-product and so on. After obtaining F, we generate a novel graph structure A' by sampling from \\(A'_{jk} \\sim Bernoulli(F_{jk})\\). Further, we regularize the learned graph structure using sparsity and smoothness constraints:\n\\[B = -\\alpha\\sum_{j,k} A'_{jk}||r_j - r_j|| - \\beta||A'||\\_0,\\]\nwhere the \\(\\alpha\\) and \\(\\beta\\) are hyperparameters controlling different modules' importance. We adopt the policy gradient optimization method for the non-differentiable problem of sampling A'. We define the probability for sampling as follows:\n\\[\\Phi(A') = \\Pi_{j,k} (A'_{jk}F_{jk} + (1 - A'_{jk})(1 - F_{jk})).\\]\nThen we independently sample H times to obtain \\(\\{A'\\}_{h=1}^H\\) and \\(\\{(A')^H\\}_{h=1}^H\\). We define the regularization B in Eq. (4) as the reward function, then we optimize the \\(\\theta_t\\) using REINFORCE [58] algorithm with the gradient:\n\\[\\nabla_{\\theta_t} C_{reg} = \\frac{1}{H}\\sum_{h=1}^H \\log \\Phi(A'_h) (B(A'_h) - \\bar{B}),\\]\nwhere \\(\\bar{B}\\) is the mean value, serving as a baseline function. It operates by averaging the regularization rewards \\(B(A')\\) across a single feed-forward computation, thereby aiding in the reduction of variance throughout the training of the policy gradient.\nAfter obtaining A' by structure learner \\(f_t\\), we recursively propagate features along the latent graph A' and original adjacent matrix A to update node representations by the GNN network parameterized by \\(\\theta_g\\). This process can be formulated as:\n\\[R = \\lambda GNN(R, A) + (1 - \\lambda) GNN(R, A'),\\]\nwhere \\(\\lambda\\) denotes the weight coefficient, \\(R = \\{r_i\\}_{i=1}^{|V|} \\in R^{|V|\\times d}\\) where \\(r \\in R^d\\) is the node representation.\n4.2 Representation Learner\nDespite GNNs having the capability to extract abstract representations for predictions, the representation may unconsciously mix up semantic factors s and variation factors v due to a correlation between them. So the model still relies on the domain-specific variation factors v for prediction via this correlation. However, this correlation may change drastically in a new domain, making the effect from v misleading. So we assume the representation of each node is disentangled into two factors: a domain-invariant semantic factor s determining the label and a domain-specific variation factor v independent of labels. \\(p(r|s, v)\\) and \\(p(y|s)\\) are invariant across domains, and the change of prior \\(p(s, v)\\) is the only source of domain change. Based on the above causal generative principle, we develop the representation learner based on variational Bayes [59, 60]. Here, the representation of the node learned by GNN r and the label y are accessible variables and we have supervised data from the underlying representation \\(p^*(r, y)\\) in the source domain. The log marginal likelihood of the r and y is as follows:\n\\[\\log p(r, y) = \\log \\int\\int p(s,v,r,y)dsdv,\\]\nwhere \\(p(s, v, r, y) := p(s, v)p(r|s, v)p(y|s)\\). By maximizing the likelihood in Eq. (8), \\(p(r, y)\\) will match the \\(p^*(r, y)\\). However, the direct optimization of Eq. (8) is intractable, so we utilize the variational inference [60] to approximate the marginal likelihood. We introduce a tractable distribution \\(q(s, v|r, y)\\) and construct the variational objective as follows:\n\\[\\log p(r, y) \\geq E_{q(s,v|r,y)} \\log \\frac{p(s, v, r, y)}{q(s, v|r, y)} =: L_{q(s,v|r,y)} (r, y),\\]\nwhere \\(L_{p,q_{s,v|r,y}} (r, y)\\) is called Evidence Lower BOund (ELBO). Unfortunately, the introduced model \\(q(s, v|r, y)\\) fails to facilitate the estimation of \\(p(y|r)\\). To alleviate this problem, we introduce an auxiliary model \\(q(s, v, y|r)\\) to target \\(p(s, v, y|r)\\), which enables the straightforward sampling of y given r for prediction. Meanwhile, \\(q(s, v, y|r) = q(s, v|r, y)q(y|r)\\) means it can help learning inference model \\(q(s, v|r, y)\\), where \\(q(y|r) := \\int q(s, v, y|r)dsdv\\). Due to \\(p(s, v, y|r)\\) can be factorized as \\(p(s, v|r)p(y|s)\\). Thus, we can instead introduce a lighter inference \\(q(s, v|r)\\) for the minimally intractable component \\(p(s, v|r)\\) and use \\(q(s, v|r)p(y|s)\\) as an approximation to \\(q(s, v, y|r)\\). This turns the objective Eq. (9) to:\n\\[\\log p(r, y) \\geq \\frac{1}{q(y|r)} [E_{q(s,v|r)} [p(y|s) \\log q(y|r)]] + \\frac{1}{q(y|r)} [E_{q(s,v|r)} [p(y|s) \\log p(r|s, v)]] + \\frac{1}{q(y|r)} E_{q(s,v|r)} [p(y|s) \\log \\frac{p(s, v)}{q(s, v|r)}]] =: L_{ELBO},\\]\nwhere \\(q(y|r) = E_{q(s,v|r)} [p(y|s)]\\). The \\(L_{ELBO}\\) in Eq. (10) consists of three components. The first term is the negative of the standard cross entropy (CE) loss and \\(p(y|s)\\) gives the ability to model to predict the target label. The second term encourages the latent representation s and v to preserve the salient information of r by reconstruction. The third and fourth term drives the variational posteriors \\(q(s, v|r)\\) towards its priors. By maximizing the \\(L_{ELBO}\\) in Eq. (10), it becomes feasible to deduce the parameters of distribution over the joint latent variables s and v. The Monte Carlo method can be used to estimate expectations [59]. The derivation of Eq. (10) is provided in Appendix B.\nMLDGG-ind. To improve the generalization of the model, we consider another case where s and v are independent, i.e., \\(p^+(s, v) = p(s)p(v)\\). Formally, the distribution \\(p^+(s, v)\\) exhibits a higher entropy compared to \\(p(s, v)\\), which diminishes specific information of the source domain and promotes dependence on causal mechanisms for enhanced generalization. Under the conditional independence assumption, the \\(p(s, v))\\) can be turned to \\(p(s)p(v)\\) and \\(q(s, v|r)\\) can be turned to \\(q(s|r)q(v|r)\\) in Eq. (10), which is denoted as \\(L_{ELBO}^+\\)"}, {"title": "5 Theoretical Analysis", "content": "This section presents a theoretical analysis of the boundary guarantee for domain generalization errors in the meta-learning framework that integrates the structural and representation learner.\nTheorem 1 (Upper bound: accuracy). Define the expected error of f in representation space as \\(\\epsilon_{Acc}(f) = E[L(f \\circ g(A, X), Y)]\\). For any \\(f : R^3 \\rightarrow R\\), any representation mapping \\(g : A\\times X \\rightarrow R^3\\), and any loss function \\(L : R\\times R \\rightarrow R\\) that is upper bounded by \\(\\pi_u\\), the expected error of \\(f \\circ g : A \\times X \\rightarrow R\\) at any target domain \\(e_T \\in E_t\\) is upper bounded:\n\\[E_{e_T} \\epsilon_{Acc}^{e_T} (f \\circ g) \\leq \\frac{1}{K} \\sum_{i=1}^K \\epsilon_{Acc}^{e_i} (f \\circ g) + \\sqrt{2\\pi_u} \\max_{i \\in [K]} d_{JS} (P_{S,Y}^{e_T}, P_{S,Y}^{e_i}) + \\sqrt{2\\pi_u} \\frac{1}{K} \\sum_{i=1}^K d_{JS} (P_{A,X}^{e_i}, P_{A,X}^{e_i}) + \\sqrt{2\\pi_u} \\max_{i,j \\in [K]} d_{JS} (P^{e_i}, P^{e_j}).\\]\nFor simplicity, we omit parameters \\(\\theta\\) and its domain \\(\\Theta\\). In this paper, the g function is \\(g = f_t \\circ GNN \\circ E_s\\). We adopt Jensen-Shannon (JS) distance [62] denoted as \\(d_{JS}\\) to quantify the dissimilarity between two distributions.\nTheorem 2 (Lower bound: accuracy). Suppose \\(L(f \\circ g(A, X), Y)\\) is lower bounded by \\(\\pi_{\\varepsilon}\\) when \\(f \\circ g(A, X) \\neq Y\\), and is 0 when \\(f \\circ g(A, X) = Y\\). Let \\(\\xi\\) denote the number of labels, if \\(d_{JS}(P_Y^{e_i}, P_Y^{e_T}) \\geq d_{JS}(P^{e_i}, P^{e_T})\\), the expected error of f at source and target domains is lower bounded:\n\\[\\frac{1}{K} \\sum_{i=1}^K \\epsilon_{Acc}^{e_i} (f \\circ g) + \\epsilon_{Acc}^{e_T} (f \\circ g) \\geq \\frac{\\pi_{\\varepsilon}}{4 \\xi K} \\sum_{i=1}^K (d_{JS}(P_Y^{e_i}, P_Y^{e_T}) - d_{JS}(P_{A,X}^{e_i}, P_{A,X}^{e_T}))^4.\\]"}, {"title": "6 Experiments", "content": "We apply MLDGG to real-world datasets to investigate the effectiveness of domain generalization on graphs, which focuses on the following research questions.\n\u2022 RQ1: Dose MLDGG surpass the the state-of-the-art methods in the field of domain generalization on graphs?\n\u2022 RQ2: To what extent does each critical component contribute to the overall performance of the MLDGG?\n\u2022 RQ3: How does the representation learner improve the generalization of GNN?\n6.1 Experiment Setup\n6.1.1 Datasets\nWe utilize three real network datasets that come with ground truth to verify the effectiveness of MLDGG. Experiments are conducted on the multiple graphs contained within each dataset. The statistical characteristics of these networks are shown in Table 1 and due to space constraints, we present the details of the dataset in the Appendix C.1.\n6.1.2 Baselines\nWe compare MLDGG with graph domain generation methods (EERM [16], SRGNN [63], FLOOD [15]), data augmentation methods for graphs (Mixup [64]), meta-learning methods for graphs (GMeta [44], GraphGlow[28], MD-Gram [57]) and a base method ERM. Readers can refer to Appendix C.2 for more details of baseline methods.\n6.1.3 Implementation Details\nWe establish 3 different scenarios determined by whether the source and target graphs are derived from the same dataset.\n\u2022 S1T1. Both source and target graphs originate from the same dataset. We sequentially test each graph for each dataset while training on the remaining ones.\n\u2022 S1T2. The source graphs and target graphs are from different datasets. In particular, all graphs in the source are from the same dataset. For instance, we use 5 graphs from FACEBOOK-100 for training and testing on the graphs of TWITCH-EXPLICIT and WEBKB, separately. This approach can be similarly applied to other datasets.\n\u2022 S12T3. The source graphs and target graphs are from different datasets. In particular, the source graphs for training are selected from different datasets. Here, we choose eight graphs from two distinct datasets for training (e.g., FACEBOOK-100 and TWITCH-EXPLICIT), and testing on the other dataset (WEBKB).\nWe use GCN architectures as the GNN model in MLDGG. For all baseline models, we implemented them using the authors' provided source code and also set GCN as the backbone. To reduce the time and space cost of the structure learner, following the simplification of [28], we convert the sampling of A' in the structure learner to the product of the (NP)-dimensional matrix and its transpose. Due to the baseline methods' inability to adapt to varying feature and label dimensions, we employ zero-padding for feature dimensions and label expansion to standardize them after comparing different padding methods. We report the experimental results for all scenarios, with the final result for each dataset derived from the mean of all graphs within that dataset. The results represent the average values obtained from 10 runs for all the methods compared.\n6.1.4 Hyper-parameter Settings\nThe parameters of the structure learner include \\(\\lambda\\) (the weight on original graphs), \\(\\alpha\\) (the weight on smoothness constraints), and \\(\\beta\\) (the weight on sparsity constraints). We adjust all values to fall within the range of [0, 1]. In meta-training, we set the update step as 5. In meta-testing, we set the update step in \\(\\{1, 5, 10, 20, 30, 40\\}\\). The learning rates for the inner and outer loops are set to \\(l_{in} = 1e-3\\) and \\(l_{out} = 1e-1\\), respectively.\n6.2 Results\nPerformance Comparison. In response to RQ1, we evaluate MLDGG's performance on three scenarios in 6.1.3. The results are reported in Table 3-6, where numbers in bold represent the best results and underlined means second best. Based on these, we identified the following observations:\nFirst, MLDGG exhibits superior performance compared with other competitive baselines on all datasets within three experimental settings, highlighting its robust generalization capabilities. The structure learner guides the model to learn more meaningful node representations and capture shared structure information across domains, and the representation learner guides the model to disentangle semantic and domain-specific information in node representation. Furthermore, we have observed superior classification performance when s and v are independent. This observation suggests that domain-specific and label-independent variation factors disturb the model's classification, consequently influencing its generalization capability. Disentangling s and v offers greater advantages for generalization.\nSecond, the results of S1T1, S1T2, and S12T3 demonstrate that the best generalization performance is achieved when the training domain originates from diverse datasets. Among all comparative methods, the performance of GraphGlow is second only to our framework, which suggests that integrating structure learning with GNN facilitates the capture of richer knowledge within graphs. All comparative methods exhibit varying performances under different distribution shift settings. Traditional invariant learning methods exhibit superior performance in scenarios where the source domain originates from the same dataset, as opposed to situations involving diverse datasets. It suggests that invariant learning methods demonstrate limited generalization ability in situations with substantial distribution shifts. Other cross-domain meta-learning methods do show better generalization ability for cross-domain scenarios. In contrast, cross-domain meta-learning methods demonstrate superior performance, attributable to meta-learning's advanced ability to capture shared knowledge across domains.\nAblation Studies. To answer RQ2, we conduct five ablation studies to evaluate the robustness of key modules, namely structure learner, representation learner, and MAML. The results of MLDGG and MLDGG-ind are shown in Fig. 3 and Fig. 4, where we follow the setting of Table 6. In-depth descriptions and the algorithms for these studies and more results can be found in Appendix D. (1) In MLDGG w/o SL, we input the graph directly into the GNN to learn node representations and compare its accuracy with MLDGG. We observe declines of 2% to 3% in accuracy across all settings compared to the full model. Given that GNNs often aggregate task-irrelevant information, which can result in overfitting and diminish generalization performance, the introduction of the structure learner becomes crucial. By mitigating the adverse effects of task-unrelated edges, the structure learner facilitates the acquisition of comprehensive node representations, thereby improving the overall performance. (2) In MLDGG w/o RL, we only keep the structure learner and just finetune the GNN encoder during the test phase. We observe a more substantial loss in performance degradation to 3% to 6% across all settings. This indicates that the disentanglement of semantic and variation factors can enhance the model's generalization capability. Class labels are dependent on semantic factors, while variation factors representing domain-specific elements are not associated with these labels. When the representation learner is absent, performance degradation occurs, particularly in the presence of OOD samples stemming from distributional shifts in target domains. Therefore, mitigating the influence of variation factors becomes crucial for improving the model's robustness across diverse domains. (3) In MLDGG w/o MAML, it does not share the semantic and variation encoders across different domains, which significantly decreases model performance by 8% to 10%. This observation indicates the critical role played by the meta-learner modules in facilitating knowledge transfer from source and target graphs. The MAML framework serves as an integration for both the structure learner and representation learner, thereby enabling efficient knowledge transfer and facilitating effective adaptation to unseen target domains. (4) In MLDGG W/O INNER-SL, we remove each task-specific structure learner so that all tasks share a structure learner. We observe declines of 1% to 2% in accuracy across all settings compared to the full model. This indicates that learning initialization parameters for the structure learner based on the meta-learning framework are conducive to capturing the structure information shared by different domains and improving the generalization ability. (5) In MLDGG w/o INNER-RL, we remove each task-specific representation learner so that all tasks share a representation learner, which decreases model performance by 2% to 3%. This indicates that learning initialization parameters for the representation learner based on the meta-learning framework can guide the model to learn semantic factors and variation factors, to better disentangle to improve generalization ability.\nThe demonstration of the effectiveness of the representation learner. To answer RQ3, we visualize the output r of each node of the GNN, domain-invariant semantic factors s and domain-specific variation factors v respectively in Fig. 5 (different colors represent different labels). The domain-invariant semantic factors s and domain-specific variation factors v are disentangled from the node representations r learned from GNNs. We can see that the samples, represented by s are more distinguished than those represented by r. The samples represented by v are independent of classes. These phenomena indicate that by disentangling the node representation learned from GNN to capture the domain-invariant semantic information that determines the label, the influence of the variation factors on the label prediction can be reduced and better generalization performance can be achieved.\nSensitivity Analysis. The results of sensitivity analysis of MLDGG to varying numbers of gradient steps during meta-testing and the weight of the original graph \\(\\lambda\\) are provided in Appendix F.1."}, {"title": "7 Conclusion", "content": "In this paper, we introduce a novel cross-multi-domain meta-learning framework, MLDGG, for node-level graph domain generalization. The framework integrates a structure and a representation learner within the meta-learning paradigm to facilitate knowledge transfer and enable rapid adaptation to target domains previously. The structure learner mitigates the adverse effects of task-unrelated edges to facilitate the acquisition of comprehensive node representations of GNN while capturing the shared structure information. The representation learner by disentangling the semantic and variation factors enhances the model's generalization. We conduct extensive experiments and the results demonstrate that our model outperforms baseline methods."}]}