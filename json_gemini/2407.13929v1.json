{"title": "Unmasking Social Bots: How Confident Are We?", "authors": ["James, Giroux", "Gangani, Ariyarathne", "Alexander C., Nwala", "Cristiano, Fanelli"], "abstract": "Social bots remain a major vector for spreading disinformation on social media and a menace to the public. Despite the progress\nmade in developing multiple sophisticated social bot detection algorithms and tools, bot detection remains a challenging,\nunsolved problem that is fraught with uncertainty due to the heterogeneity of bot behaviors, training data, and detection\nalgorithms. Detection models often disagree on whether to label the same account as bot or human-controlled. However, they\ndo not provide any measure of uncertainty to indicate how much we should trust their results. We propose to address both bot\ndetection and the quantification of uncertainty at the account level a novel feature of this research. This dual focus is crucial\nas it allows us to leverage additional information related to the quantified uncertainty of each prediction, thereby enhancing\ndecision-making and improving the reliability of bot classifications. Specifically, our approach facilitates targeted interventions\nfor bots when predictions are made with high confidence and suggests caution (e.g., gathering more data) when predictions\nare uncertain.", "sections": [{"title": "Introduction", "content": "Social media platforms have fundamentally transformed global communication, enabling the near-instant dissemination of\ninformation. Platforms like Facebook, YouTube, and Twitter/X, have over two billion monthly active users\u00b9 and empower\nindividuals to broadcast their thoughts easily. However, the popularity that social media enjoys has incentivized malicious\nactors such as tech-savvy individuals or governments\u00b2, to deploy social bots to influence organic discourse and manipulate\nsocial media users for economic or political profit. Social bots\u00b3,\u2074 accounts controlled partly or fully by software have\nbeen used to artificially boost the popularity of political candidates\u2075, spread conspiracy theories\u2076,\u2077 during health crises\u2078, and to\nmanipulate the stock market\u2079,\u00b9\u2070.\nA 2023 study that analyzed 1 million tweets during a Republican debate and a Donald Trump interview identified over\n1,200 bot accounts spreading false narratives, highlighting the significant impact of bots during major events\u00b9\u00b9. Anecdotal\nreports further underscore the prevalence of bot accounts, with some users suggesting that a substantial fraction of interactions\non the platform are bot-generated. Despite enhanced verification processes, verified accounts continue to promote fraudulent\nschemes, illustrating the ongoing challenge in curbing bot activity.\nThe issue of bot prevalence has also featured prominently in high-profile disputes, such as Elon Musk's acquisition of\nTwitter. Musk's legal team, using Botometer\u00b9\u00b2, an online tool for identifying spam and fake accounts, claimed that 33%\nof \"visible accounts\u201d were \u201cfalse or spam\". However, Botometer's creator, Kaicheng Yang, criticized this claim and their\nmethodology, stating that the figure was misleading and disclosed that Musk's team had not consulted him before using the\ntool\u00b9\u00b3. Perhaps even more concerning is the adaptation of AI to bypass security systems deemed \u201cprove you're not a robot\ntests.\" This concern has been echoed by Musk, Fig. 1 (left), as these tests are commonly used as initial filters for the prevention\nof inauthentic and/or malicious bot accounts. Moreover, accounts that successfully bypass such tests are increasingly becoming\nmore \"human-like,\" as indicated by the dimensionality reduced representations of accounts in Fig. 1 (right). Musk has also\nimplicated that the only reasonable method to solve the bot crisis is to force Twitter users into a paid subscription. Unfortunately,\npaid subscription has only worsened the bot-problem, since fake accounts can now pay to receive verification status (blue\ncheck mark), and thus appear authentic, as highlighted by the European Commission claim that Twitter is in violation the\nDigital Services Act\u00b9\u2074. Similarly, Elon Musk's imposition of a prohibitively costly paywall to access Twitter's research API has\nhampered the ability of researchers to study and mitigate bot activities.\nGiven the serious harm that social bots wielded by bad actors, pose to democracy\u00b9\u2076,\u00b9\u2077, public health\u00b9\u2078\u207b\u00b2\u2070, or the the\neconomy\u00b2\u00b9, researchers have responded by developing a broad range of bot detection tools. Various Machine-Learning\nmethods have been trained to detect social bots with a combination of features extracted from the social network structure,\ncontent/profile attributes, and temporal patterns\u00b3. Alternatively, all of these feature types are combined into a single model\u00b2\u00b2\u207b\u00b2\u2077.\nBot-detection algorithms often start by modeling the characteristics of accounts as the first step to distinguish bot from\nhuman-like behaviors\u2074. Accounts may be represented using user profile information\u00b2\u2078, content\u00b2\u2079\u207b\u00b3\u00b9, actions\u00b3\u00b2, social network\u00b3\u00b3,"}, {"title": "Results", "content": "In this section, we discuss the results of predicting the labels (bot or human) of accounts with our network, a Bayesian Neural\nNetwork (BNN) inspired by the Event-Level-Uncertainty Quantification (ELUQuant)\u00b3\u2078 work originally developed for nuclear\nphysics. This approach allows for the calculation of aleatoric and epistemic uncertainty in the predictions of whether Twitter/X\naccounts are bots or humans.\nIt is also important to compare the performance of the BNN with its deterministic counterpart, the Deep Neural Network\n(DNN). A BNN should perform at least as well as its deterministic counterpart. This has been demonstrated in the following\nway. We evaluate our model using standard methods, namely the Receiver Operating Characteristic (ROC) Curve and the\nassociated Area Under the Curve (AUC). These metrics allow us to avoid making hard threshold cuts in the probability space\nand reflect a model's performance across various thresholds. Thus, AUC is an ideal metric for such use cases. We then compare\nthe results to the deterministic counterpart of our BNN, a DNN, along with the Random Forest (RF) from Nwala et al.\u00b3\u2075. We\nextract both BLOC and Botometer features for the same set of users. Figure 2 shows a comparison between three methods,\nwith the AUC indicated in the legend. The left plot contains the ROC curves for the algorithms trained on BLOC features,\nwhere the error is calculated through bootstrapping over the posterior on the probability. This approach allows us to produce 5\u03c3\nbands over both the True Positive Rate (TPR) and False Positive Rate (FPR). The right plot provides the same ROC Curves for\nalgorithms trained on Botometer features. We note an AUC for the BNN of 0.966\u00b10.001, which agrees with the deterministic\nDNN that achieves an AUC of 0.969 on BLOC features. The same agreement between the BNN and DNN is also seen in\nBotometer features with the BNN obtaining an AUC of 0.973\u00b10.001 and the DNN obtaining an AUC of 0.975. In both cases,\nthe RF outperforms the DNN and BNN due to its ability to operate more efficiently with smaller training sample sizes.\nWe also aimed to validate the epistemic uncertainty produced by the network, where we expect maximum uncertainty for\nprobability values P(bot) ~ 0.5. Figure 3 reports the aleatoric uncertainty, epistemic uncertainty, and the sum in quadrature for\nthe total uncertainty.\nOne can notice that, in general, the uncertainty is larger when the prediction is more ambiguous, that is, around a probability\nof 0.5, and it is smaller when it is close to 0 (account identified as human) or 1 (account identified as a bot). The reader should\nbe reminded that the uncertainties are provided at the Twitter/X account level, meaning that our BNN provides an output\nprobability of being a bot account along with the associated uncertainties, both aleatoric and epistemic. Another observation is"}, {"title": "", "content": "that the aleatoric uncertainty, which captures the randomness in our data and its propagation in the network's predictions, is\ngenerally more spread than the epistemic uncertainty and can reach higher values.\nWe consolidated the uncertainty quantification by running a closure test, consisting of training the network (i) without\nincluding the aleatoric term, thereby predicting only the epistemic uncertainty, and (ii) including both aleatoric and epistemic\nterms. Details on how these two scenarios can be implemented are discussed in the Methods section and are also described\nin\u00b3\u2078. We demonstrated through a Z-score test that the epistemic uncertainties obtained on the accounts (considering the results\nfrom methods (i) and (ii) at the account level) produce consistent epistemic uncertainties (all values are within |Z| \u2264 0.5). This\nclosure test supports the fact that the quantified aleatoric uncertainty is decoupled from the epistemic uncertainty, with the latter\nappearing, on average, different from the former.\nAfter consolidating our results, as discussed, we compare the performance of our network with respect to state-of-the-art\nworks utilizing BLOC features\u00b3\u2075 and Botometer\u00b9\u00b2 with random forest (RF) as a classifier, as done in those papers. We evaluate\nthe performance using precision, recall, and F1 metrics. Our method outperforms other methods in terms of recall and F1, and\nis nearly on par in terms of precision, as shown in Table 1.\nWe note that the BNN is more generalizable to the excess human accounts contained within the dataset. Since we sample a\n50/50% class split at training, validation, and testing, we retain the excess accounts as an additional measure of performance.\nThe BNN is more able to capture a generalized weight distribution in the form of a posterior in comparison to the DNN. Note\nthat both models have been regularized in the same manner apart from the inherent KL term appearing for the BNN, which\ncontrols the distribution of the learned weights under the Gaussian prior. After verifying that our performance is on par with or\neven surpasses other state-of-the-art approaches, we finally utilize the additional information from uncertainty quantification.\nThis is the novel contribution of our work compared to other works in the field of bot detection. In the following Table 2, we\nshow the results obtained by applying a 3\u03c3 cut based on the quantified uncertainty at the account level. Specifically, we ensure\nthat the predicted outcome is not consistent with a probability of 0.5 (indicating the largest uncertainty in classification) by\nusing the predicted value of the probability and a 3\u03c3 interval. In other words, we classify only those events that satisfy:\n$|P_{pred} - 0.5| > 3\\sigma(P_{pred}).$ (1)\nEquation (1) is used for both $\\sigma(P_{pred}) = \\sigma_{epi}.(P_{pred})$ and $\\sigma_{tot}.(P_{pred})$, representing the cases of epistemic only or the total\nuncertainty in quadrature between aleatoric and epistemic. The results show an improvement in performance, across all metrics,\nover the baseline as uncertainty is introduced into the decision making process. We also report the \"rejection\" fraction, which\ncorresponds to the number of account that are held for further information to be acquired before classification. This additional\ninformation from uncertainty allows for more informed decisions, thereby impacting the decision-making process for Twitter/X"}, {"title": "Discussion", "content": "Our study details a fully Bayesian framework inspired by ELUQuant\u00b3\u2078 to classify Twitter/X accounts as bots or humans,\nassessing its performance against DNNs and RF models. The BNN demonstrates comparable performance to both the DNN and\nRF models in terms of AUC, while providing additional information in the form of uncertainty. Crucial for decision-making at\nthe account level. Closure tests affirm the robustness of our uncertainty quantification, in which we are able to decouple the\naleatoric and epistemic components. By applying a 3\u03c3 uncertainty threshold, we observe improved accuracy and F1 scores,\nunderscoring the utility of uncertainty-aware models in bot detection. This approach not only enhances predictive reliability but\nalso provides deeper insights into model behavior, advancing the field's understanding and application of probabilistic neural\nnetworks.\nOur contribution should be framed in the context of end-to-end analysis pipelines using uncertainty at the account level.\nAs we have shown, our design philosophy is agnostic to input, obtaining similar performance on both BLOC and Botometer\nfeatures. The network itself can easily be adapted to more complex problems and deploy the same uncertainty aware procedures\ndeveloped within. Specifically, using uncertainty to isolate subsets of accounts where the network has shown to be unreliable.\nThese accounts can be further monitored over a period of time and reevaluated once more information has been obtained.\nReducing the potential of false account suspension."}, {"title": "Methods", "content": "Bayesian Neural Networks\nBayesian Neural Networks (BNNs) are extensions of traditional Deep Neural Networks (DNNs), aiming to optimize distributions\nof weights at each layer.\u00b9 The aim of BNNs is to approximate a posterior distribution over the weights, given a dataset q(W|D).\nThis allows predictions of quantities through a posterior distribution q(y|x, D), integrated over the weights. The formulation of\nsuch a posterior is intractable and therefore one must turn to Bayesian inference techniques during optimization. Traditional\napproaches define the posterior distribution to be a fully factorized Gaussian (diagonal covariance) q(W), such that the\nevidence-lower bound (ELBO) can be maximized between the approximated posterior and the prior. Note that maximizing\nthe ELBO is equivalent to minimizing the Kullback-Leibler (KL) Divergence. This assumption, although more advantageous,\ntends to be limiting in terms of learned network complexity. Another approach provided in Louizos and Welling\u2074\u2070, is to instead\napproximate the posterior as a product of fully factorized Gaussian and a mixing density, Eq. 2, where q(z) is a vector of\nrandom variables. The random variables act multiplicatively on the means of the mixing density to reduce computational\ncomplexity.\n$9(W) = \\int q(W|z)q(z)dz$ (2)\nThe result is a more flexible posterior distribution over the weights, capable of learning multi-modal dependencies between\nweights. However, this too becomes intractable, and therefore, an approximate lower bound of entropy must be constructed.\nThis can be done through an auxiliary distribution r(z|W), equivalent to performing variational inference on an augmented\nprobability space\u2074\u2070. Moreover, the approximated posterior remains true given the fact that the auxiliary distribution can be\nmarginalized out. As stated in Louizos and Welling\u2074\u2070, the tightness of the bound on q(W) (and therefore the quality of it)\ndirectly depends on the ability of r(z|W) to approximate the posterior of q(z|W), and is therefore chosen to be represented with\ninverse normalizing flows. The choice of normalizing flows allows analytic computation of the marginals through bijective\ntransformations. The approximate posterior is then constrained through Eq. 3 during training, acting as a regularization term in\nconjunction with traditional loss functions.\n$\\mathcal{L}_{KL.} = -KL(q(W)||p(W))$ \n$= E_{q(W,zr)}[-KL(q(W|ztf)||p(W))$\\$\n$+logr(zt|W) - logq(ZT)]$ (3)\nWe also extend our network to capture the aleatoric uncertainty component using the methodology described in Kendal et\nal.\u2074\u00b9. For each input the network produces a latent variable f, along with with the aleatoric uncertainty component s = log \u03c3.\nWe choose to interpret the network output (s) as the logarithm of the uncertainty, allowing \u03c3 to be positive definite through an\nexponential transformation \u03c3 = es. We then define a Gaussian distribution over the latent variate such that:\n$f_W ~ N(f_w, o_w)$\n$p = Sigmoid(f)$ (4)\nwhere W are the weights of the network. The expected log-likelihood, and therefore loss function is given by Eq. 5, where the\nsubscript c denotes the associated class.\n$log E_{n(f,o)} [P_c]$ (5)\nAs mentioned in Kendal et al.\u2074\u00b9, it is not possible to integrate out the Gaussian distribution, and as such Monte Carlo\nintegration must be deployed. At training time this amounts to and extra sampling step to draw samples following Eq. 6 in\nwhich we take the expected value of the latent variable to produce our probability.\n$\\hat{f}=f_w+6_w\\cdot\\epsilon, \\epsilon~N(0,1)$ (6)\nWe inherit the design philosophy from Fanelli and Giroux\u00b3\u2078, in which we first design a minimal complexity DNN as the\nbasis for our BNN. Bayesian blocks characterized by Multiplicative Normalizing Flows (MNF) layers\u2074\u2070 are utilized at each\nlayer. The analysis pipeline is shown in Fig. 4."}, {"title": "", "content": "As stated in Fanelli and Giroux\u00b3\u2078, SELU activation functions, as presented by Klambauer et al.\u2074\u00b2, possess inherent self-\nnormalizing properties, which ensure non-vanishing gradients. Their self-normalization nature could provide cases in which\nbatch normalization is not needed, although this is data-dependent. We utilize SELU along with batch normalization to improve\nnetwork convergence\u2074\u00b2. The output of the network provides a probability of the account being a bot given a BLOC input; a\nrepresentation of both the accounts actions and content. The task is treated as a binary classification loss where we deploy\nBinary Cross-Entropy, Eq. 7, coupled to the KL term in Eq. 3.\n$\\mathcal{L}_{BCE.} = \\frac{1}{N} \\sum_{i=1}^{N} y_i log(p(y_i)) + (1 - y_i) \\cdot log(1 - p(y_i))$ (7)\nThe resulting loss function is the given by Eq. 8, where \u03b1 is a scaling parameter to allow the contribution of the BCE term.\nTrivial optimization techniques showed values on the order of \u03b1 ~ 10\u22124 to be suitable given the relative scales.\n$\\mathcal{L} = \\mathcal{L}_{BCE.} + \\alpha \\mathcal{L}_{KL.}$ (8)\nThe network is trained using a traditional 70/15/15% split, in which we make the distribution of humans and bots equal\nprior to splitting. This removes any bias the network may incur due to class imbalance. This sampling results in an excess\nof human accounts which we use as additional performance measures. The Adam optimizer is used, along with a Cosine\nAnnealing learning rate scheduler with an initial learning rate of 5 \u00d7 10\u22124. We deploy early stopping, defining the convergence\nwhen the validation loss is no longer decreasing after five epochs. The number of epochs for early stopping is chosen to reflect\nthe stability of the training and account for fluctuations. Information regarding training is summarized in Table. 3.\nAt inference, we sample a set of ten thousand weights from the network posterior for each account. This, in turn, provides a\nposterior distribution of the predicted probability of being a bot account. We then take the expected value (the mean) as the\nfinal probability and compute the standard deviation on this distribution to provide the epistemic (model) uncertainty. The\naleatoric uncertainty is taken to be the average. In this case, we are assuming a Gaussian uncertainty profile on the output,\nwhich is a good approximation given the choice of Gaussian prior. Inference statistics can be found in Table. 4."}, {"title": "BLOC", "content": "The Behavioral Languages for Online Characterization (BLOC\u00b3\u2075) provides formal languages that represent the behaviors of\nsocial media accounts irrespective of social media platform, user-agent (human or bot), or intent (malicious or benign). The\nBLOC formal languages are defined by a set of alphabets (action and content) and rules for generating BLOC strings which are\ntokenized to produce BLOC words. BLOC words which represent the behaviors of social media accounts, consist of symbols\ndrawn from distinct alphabets representing an account's actions and content. Fig. 5a illustrates a possible representation of a\nsequence of tweets by three different Twitter accounts, @NASA,@Alice, and @Bob. The @NASA account replied to a tweet,\nposted a tweet, and then re-shared (retweet) a tweet, resulting in the BLOC action sequence: p.T.r. Here, each action (e.g.,\nreply to) is represented by a single symbol (e.g., p), and the dots represent long pauses (e.g., > 1 minute) between actions.\nOnce generated, BLOC strings are be tokenized (Fig. 5b) into bi-grams (two-letter words), then we can represent any social\nmedia account as a vector of BLOC words. A collection of point vectors corresponding to multiple accounts make up the\nBLOC matrix in Fig. 5c. In this vector space model, each account is represented as a point (W1,W2, ..., wk) in k-dimensional\nvector space where each dimension i corresponds to a BLOC word. The weight wi represents how well an account is described\nby word i. For each account a, we instantiated wi with the TF-IDF weight\u2074\u00b3, the product of the term frequency (TF) and the\ninverse document frequency (IDF):\n$w_i(a) = f_i(a) (1+log(\\frac{D}{d_i}))$ (9)\nwhere di is the number of accounts with word i and D is the total number of accounts."}, {"title": "Botometer", "content": "Botometer,\u00b2 is a publicly available supervised machine learning system that classifies a given Twitter account as bot or\nhuman-controlled. Botometer-V4 (the current version of Botometer at the time of writing)\u00b2\u2077 utilizes over 1,000 features\nthat can be grouped into six categories that focus on different account characteristics including, metadata from the accounts\n(e.g., numbers of friends and followers), retweet and mention networks, temporal features (e.g., frequency of posts), content\ninformation, and sentiment. In the deployed system, different classifiers in an ensemble are trained on different accounts\ntypes, and then these classifiers vote to obtain the final bot score\u00b2\u2077. Here however, we only utilize the representation power of\nBotometer by extracting its features which serve as input to BNN and DNN."}, {"title": "Conclusion", "content": "Social bots remain a potent instrument malicious agents utilize to spread disinformation and manipulate the public on social\nmedia. To tackle the bot problem and mitigate their serious social, political, or economic harms, researchers have developed\nmultiple bot detection algorithms and tools. However, bot detection continues to be a challenging unsolved problem, because\nbot behaviors are dynamic and heterogeneous (e.g., spam, fake followers, amplifiers), and different training data and detection\nmodels capture a subset of these behaviors. This means that different detection models could disagree on whether to label the\nsame account as bot or human-controlled, yet they do not produce any uncertainty to indicate how much we should trust their\nresults.\nWe propose the first uncertainty-aware bot detection algorithm that combines bot detection with uncertainty quantification.\nOur method is agnostic to bot detection features, demonstrated by deploying it with two existing Twitter/X bot detection feature\nsets: BLOC and Botometer. Our algorithm captures uncertainty arising from randomness in the account feature space (aleatoric\nuncertainty) and the uncertainty introduced by the bot detection model (epistemic uncertainty). Notably, while every method\ncan introduce epistemic uncertainty, our proposed architecture actively estimates and accounts for this uncertainty, unlike other\nmethods that may ignore it, leading to potentially erroneous decisions. Furthermore, our method demonstrated exceptional\nperformance, matching or surpassing traditional detection techniques.\nCrucially, the uncertainty information of our method has multiple applications. First, it could inform more effective\ndecision making by allowing social media platforms to carry out targeted interventions (e.g., account suspension) for bots\nwhen predictions are made with high confidence and caution (e.g., gathering more data) when predictions are uncertain. This\ncould reduce errors associated with mislabeling accounts as bots. Additionally, uncertainty information can indicate anomalous\nbehavior, raising additional flags for accounts exhibiting such patterns."}, {"title": "Code Availability", "content": "The code used for this work is available at https://github.com/wmdataphys/UncertaintyAwareBotDetection"}]}