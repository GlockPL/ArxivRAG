{"title": "Unmasking Social Bots: How Confident Are We?", "authors": ["James, Giroux", "Gangani, Ariyarathne", "Alexander C., Nwala", "Cristiano, Fanelli"], "abstract": "Social bots remain a major vector for spreading disinformation on social media and a menace to the public. Despite the progress made in developing multiple sophisticated social bot detection algorithms and tools, bot detection remains a challenging, unsolved problem that is fraught with uncertainty due to the heterogeneity of bot behaviors, training data, and detection algorithms. Detection models often disagree on whether to label the same account as bot or human-controlled. However, they do not provide any measure of uncertainty to indicate how much we should trust their results. We propose to address both bot detection and the quantification of uncertainty at the account level a novel feature of this research. This dual focus is crucial as it allows us to leverage additional information related to the quantified uncertainty of each prediction, thereby enhancing decision-making and improving the reliability of bot classifications. Specifically, our approach facilitates targeted interventions for bots when predictions are made with high confidence and suggests caution (e.g., gathering more data) when predictions are uncertain.", "sections": [{"title": "Introduction", "content": "Social media platforms have fundamentally transformed global communication, enabling the near-instant dissemination of information. Platforms like Facebook, YouTube, and Twitter/X, have over two billion monthly active users\u00b9 and empower individuals to broadcast their thoughts easily. However, the popularity that social media enjoys has incentivized malicious actors such as tech-savvy individuals or governments\u00b2, to deploy social bots to influence organic discourse and manipulate social media users for economic or political profit. Social bots\u00b3,\u2074 accounts controlled partly or fully by software have been used to artificially boost the popularity of political candidates\u2075, spread conspiracy theories\u2076,\u2077 during health crises\u2078, and to manipulate the stock market\u2079,\u00b9\u2070.\nA 2023 study that analyzed 1 million tweets during a Republican debate and a Donald Trump interview identified over 1,200 bot accounts spreading false narratives, highlighting the significant impact of bots during major events\u00b9\u00b9. Anecdotal reports further underscore the prevalence of bot accounts, with some users suggesting that a substantial fraction of interactions on the platform are bot-generated. Despite enhanced verification processes, verified accounts continue to promote fraudulent schemes, illustrating the ongoing challenge in curbing bot activity.\nThe issue of bot prevalence has also featured prominently in high-profile disputes, such as Elon Musk's acquisition of Twitter. Musk's legal team, using Botometer\u00b9\u00b2, an online tool for identifying spam and fake accounts, claimed that 33% of \"visible accounts\u201d were \u201cfalse or spam\". However, Botometer's creator, Kaicheng Yang, criticized this claim and their methodology, stating that the figure was misleading and disclosed that Musk's team had not consulted him before using the tool\u00b9\u00b3. Perhaps even more concerning is the adaptation of AI to bypass security systems deemed \u201cprove you're not a robot tests.\" This concern has been echoed by Musk, Fig. 1 (left), as these tests are commonly used as initial filters for the prevention of inauthentic and/or malicious bot accounts. Moreover, accounts that successfully bypass such tests are increasingly becoming more \"human-like,\" as indicated by the dimensionality reduced representations of accounts in Fig. 1 (right). Musk has also implicated that the only reasonable method to solve the bot crisis is to force Twitter users into a paid subscription. Unfortunately, paid subscription has only worsened the bot-problem, since fake accounts can now pay to receive verification status (blue check mark), and thus appear authentic, as highlighted by the European Commission claim that Twitter is in violation the Digital Services Act\u00b9\u2074. Similarly, Elon Musk's imposition of a prohibitively costly paywall to access Twitter's research API has hampered the ability of researchers to study and mitigate bot activities.\nGiven the serious harm that social bots wielded by bad actors, pose to democracy\u00b9\u2076,\u00b9\u2077, public health\u00b9\u2078\u2013\u00b2\u2070, or the the economy\u00b2\u00b9, researchers have responded by developing a broad range of bot detection tools. Various Machine-Learning methods have been trained to detect social bots with a combination of features extracted from the social network structure, content/profile attributes, and temporal patterns\u00b3. Alternatively, all of these feature types are combined into a single model\u00b2\u00b2\u2013\u00b2\u2077. Bot-detection algorithms often start by modeling the characteristics of accounts as the first step to distinguish bot from human-like behaviors\u2074. Accounts may be represented using user profile information\u00b2\u2078, content\u00b2\u2079\u2013\u00b3\u00b9, actions\u00b3\u00b2, social network\u00b3\u00b3,"}, {"title": "Results", "content": "In this section, we discuss the results of predicting the labels (bot or human) of accounts with our network, a Bayesian Neural Network (BNN) inspired by the Event-Level-Uncertainty Quantification (ELUQuant)\u00b3\u2078 work originally developed for nuclear physics. This approach allows for the calculation of aleatoric and epistemic uncertainty in the predictions of whether Twitter/X accounts are bots or humans.\nIt is also important to compare the performance of the BNN with its deterministic counterpart, the Deep Neural Network (DNN). A BNN should perform at least as well as its deterministic counterpart. This has been demonstrated in the following way. We evaluate our model using standard methods, namely the Receiver Operating Characteristic (ROC) Curve and the associated Area Under the Curve (AUC). These metrics allow us to avoid making hard threshold cuts in the probability space and reflect a model's performance across various thresholds. Thus, AUC is an ideal metric for such use cases. We then compare the results to the deterministic counterpart of our BNN, a DNN, along with the Random Forest (RF) from Nwala et al.\u00b3\u2075. We extract both BLOC and Botometer features for the same set of users. Figure 2 shows a comparison between three methods, with the AUC indicated in the legend. The left plot contains the ROC curves for the algorithms trained on BLOC features, where the error is calculated through bootstrapping over the posterior on the probability. This approach allows us to produce 5\u03c3 bands over both the True Positive Rate (TPR) and False Positive Rate (FPR). The right plot provides the same ROC Curves for algorithms trained on Botometer features. We note an AUC for the BNN of 0.966\u00b10.001, which agrees with the deterministic DNN that achieves an AUC of 0.969 on BLOC features. The same agreement between the BNN and DNN is also seen in Botometer features with the BNN obtaining an AUC of 0.973\u00b10.001 and the DNN obtaining an AUC of 0.975. In both cases, the RF outperforms the DNN and BNN due to its ability to operate more efficiently with smaller training sample sizes.\nWe also aimed to validate the epistemic uncertainty produced by the network, where we expect maximum uncertainty for probability values P(bot) ~ 0.5. Figure 3 reports the aleatoric uncertainty, epistemic uncertainty, and the sum in quadrature for the total uncertainty.\nOne can notice that, in general, the uncertainty is larger when the prediction is more ambiguous, that is, around a probability of 0.5, and it is smaller when it is close to 0 (account identified as human) or 1 (account identified as a bot). The reader should be reminded that the uncertainties are provided at the Twitter/X account level, meaning that our BNN provides an output probability of being a bot account along with the associated uncertainties, both aleatoric and epistemic. Another observation is"}, {"title": "Methods", "content": "Bayesian Neural Networks (BNNs) are extensions of traditional Deep Neural Networks (DNNs), aiming to optimize distributions of weights at each layer.\u00b9 The aim of BNNs is to approximate a posterior distribution over the weights, given a dataset q(W|D). This allows predictions of quantities through a posterior distribution q(y|x, D), integrated over the weights. The formulation of such a posterior is intractable and therefore one must turn to Bayesian inference techniques during optimization. Traditional approaches define the posterior distribution to be a fully factorized Gaussian (diagonal covariance) q(W), such that the evidence-lower bound (ELBO) can be maximized between the approximated posterior and the prior. Note that maximizing the ELBO is equivalent to minimizing the Kullback-Leibler (KL) Divergence. This assumption, although more advantageous, tends to be limiting in terms of learned network complexity. Another approach provided in Louizos and Welling\u2074\u2070, is to instead approximate the posterior as a product of fully factorized Gaussian and a mixing density, Eq. 2, where q(z) is a vector of random variables. The random variables act multiplicatively on the means of the mixing density to reduce computational complexity.\n$q(W) = \\int q(W/z)q(z)dz$\n(2)\nThe result is a more flexible posterior distribution over the weights, capable of learning multi-modal dependencies between weights. However, this too becomes intractable, and therefore, an approximate lower bound of entropy must be constructed. This can be done through an auxiliary distribution r(z|W), equivalent to performing variational inference on an augmented probability space\u2074\u2070. Moreover, the approximated posterior remains true given the fact that the auxiliary distribution can be marginalized out. As stated in Louizos and Welling\u2074\u2070, the tightness of the bound on q(W) (and therefore the quality of it) directly depends on the ability of r(z|W) to approximate the posterior of q(z|W), and is therefore chosen to be represented with inverse normalizing flows. The choice of normalizing flows allows analytic computation of the marginals through bijective transformations. The approximate posterior is then constrained through Eq. 3 during training, acting as a regularization term in conjunction with traditional loss functions.\n$\\mathcal{L}_{KL.} = -KL(q(W)||p(W))$\n$= E_{q(W,z|r)}[-KL(q(W|z_{tf})||p(W))$\n$+log r(z_{t}|W) - log q(z_{T})]$\n(3)\nWe also extend our network to capture the aleatoric uncertainty component using the methodology described in Kendal et al.\u2074\u00b9. For each input the network produces a latent variable f, along with with the aleatoric uncertainty component s = log \u03c3. We choose to interpret the network output (s) as the logarithm of the uncertainty, allowing \u03c3 to be positive definite through an exponential transformation \u03c3 = es. We then define a Gaussian distribution over the latent variate such that:\n$fW \\sim N(fw, ow)$\n$p = Sigmoid(f)$\n(4)\nwhere W are the weights of the network. The expected log-likelihood, and therefore loss function is given by Eq. 5, where the subscript c denotes the associated class.\n$\\log E_{n(f,o)}[P_c]$\n(5)\nAs mentioned in Kendal et al.\u2074\u00b9, it is not possible to integrate out the Gaussian distribution, and as such Monte Carlo integration must be deployed. At training time this amounts to and extra sampling step to draw samples following Eq. 6 in which we take the expected value of the latent variable to produce our probability.\n$\\hat{f} = fw + \\sigma_w \\cdot \\epsilon,  \\epsilon \\sim N(0,1)$\n(6)\nWe inherit the design philosophy from Fanelli and Giroux\u00b3\u2078, in which we first design a minimal complexity DNN as the basis for our BNN. Bayesian blocks characterized by Multiplicative Normalizing Flows (MNF) layers\u2074\u2070 are utilized at each layer. The analysis pipeline is shown in Fig. 4."}, {"title": "BLOC", "content": "The Behavioral Languages for Online Characterization (BLOC\u00b3\u2075) provides formal languages that represent the behaviors of social media accounts irrespective of social media platform, user-agent (human or bot), or intent (malicious or benign). The BLOC formal languages are defined by a set of alphabets (action and content) and rules for generating BLOC strings which are tokenized to produce BLOC words. BLOC words which represent the behaviors of social media accounts, consist of symbols drawn from distinct alphabets representing an account's actions and content. Fig. 5a illustrates a possible representation of a sequence of tweets by three different Twitter accounts, @NASA,@Alice, and @Bob. The @NASA account replied to a tweet, posted a tweet, and then re-shared (retweet) a tweet, resulting in the BLOC action sequence: p.T.r. Here, each action (e.g., reply to) is represented by a single symbol (e.g., p), and the dots represent long pauses (e.g., > 1 minute) between actions.\nOnce generated, BLOC strings are be tokenized (Fig. 5b) into bi-grams (two-letter words), then we can represent any social media account as a vector of BLOC words. A collection of point vectors corresponding to multiple accounts make up the BLOC matrix in Fig. 5c. In this vector space model, each account is represented as a point (W\u2081,W\u2082,...,Wk) in k-dimensional vector space where each dimension i corresponds to a BLOC word. The weight wi represents how well an account is described by word i. For each account a, we instantiated wi with the TF-IDF weight\u2074\u00b3, the product of the term frequency (TF) and the inverse document frequency (IDF):\n$w_i(a) = f_i(a) \\left(1 + log\\frac{D}{d_i}\\right)$\n(9)\nwhere di is the number of accounts with word i and D is the total number of accounts."}, {"title": "Botometer", "content": "Botometer,\u00b2 is a publicly available supervised machine learning system that classifies a given Twitter account as bot or human-controlled. Botometer-V4 (the current version of Botometer at the time of writing)\u00b2\u2077 utilizes over 1,000 features that can be grouped into six categories that focus on different account characteristics including, metadata from the accounts (e.g., numbers of friends and followers), retweet and mention networks, temporal features (e.g., frequency of posts), content information, and sentiment. In the deployed system, different classifiers in an ensemble are trained on different accounts types, and then these classifiers vote to obtain the final bot score\u00b2\u2077. Here however, we only utilize the representation power of Botometer by extracting its features which serve as input to BNN and DNN."}, {"title": "Acknowledgements", "content": "We thank William & Mary for supporting the work of CF and JG through CF's start-up funding. The authors acknowledge William & Mary Research Computing for providing computational resources and technical support that have contributed to the results reported within this article."}, {"title": "Code Availability", "content": "The code used for this work is available at https://github.com/wmdataphys/UncertaintyAwareBotDetection"}]}