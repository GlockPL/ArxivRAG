{"title": "Implicit Sentiment Analysis Based on Chain-of-Thought Prompting", "authors": ["Zhihua Duan", "Jialin Wang"], "abstract": "Implicit Sentiment Analysis (ISA) is a crucial research area in natural language processing. Inspired by the idea of large language model Chain of Thought(CoT), this paper introduces a Sentiment Analysis of Thinking (SAoT) framework. The framework first analyzes the implicit aspects and opinions in the text using common sense and thinking chain capabilities. Then, it reflects on the process of implicit sentiment analysis, and finally, it deduces the polarity of sentiment. The model is evaluated on the SemEval 2014 dataset, consisting of 1120 restaurant reviews and 638 laptop reviews. The experimental results demonstrate that the utilization of the ERNIE-Bot-4+SAoT model yields a notable performance improvement. Specifically, on the restaurant dataset, the F1 score reaches 75.27, accompanied by an ISA score of 66.29. Similarly, on the computer dataset, the F1 score achieves 76.50, while the ISA score amounts to 73.46. Comparatively, the ERNIE-Bot-4+SAoT model surpasses the BERTAsp+SCAPT baseline by an average margin of 47.99%.", "sections": [{"title": "I. INTRODUCTION", "content": "The sentiment analysis of text can be performed through natural language processing (NLP), including positive, negative, or neutral. It enables the understanding of customers language, expression, and underlying emotional meaning.There are many subtasks and topics in sentiment analysis.Implicit sentiment analysis, As part of sentiment analysis, aims to identify implicitly expressed sentiment viewpoints and polarities.\nBased on the presence or absence of explicit sentiment words, it can be categorized into Explicit Sentiment Analysis (ESA) and Implicit Sentiment Analysis (ISA). ESA is the mainstream research scenario, where explicit sentiment expressions exist in the text. Compared to ESA, ISA faces the following complex challenges:1. Lack of explicit sentiment words: ISA lacks explicit sentiment words or expressions, making it difficult to identify and extract potential sentiments from the text. Implicit sentiments are often conveyed through subtle cues, nuanced language, metaphors, or context, requiring a deeper understanding of the text. 2. Context and subjective expressions: Implicit sentiments are heavily influenced by the context in which they occur. Understanding the context and its impact on sentiment requires analyzing a broader range of language and situational factors surrounding the text. Subjective expressions further increase the complexity of analysis as they involve personal viewpoints, opinions, and individual experiences.3. Ambiguity and polysemy: Implicit sentiments can be ambiguous, with multiple possible interpretations. Words or phrases may have different meanings and can be associated with various sentiments depending on the context.\nFortunately, in recent years, A Transformer-based approach to large language models [1],such as ChatGPT, LLaMA [2], [3], and GPT4 have made significant advancements, providing us with a promising solution to our problem. On one hand, LLMs through extensive pre-training, have acquired vast amounts of world knowledge and demonstrated outstanding capabilities in common-sense understanding, effortlessly tackling common-sense reasoning tasks. On the other hand, The latest insights in Chain of Thought (CoT) theory underscore the extensive capabilities of LLMs in analytical thinking.In CoT reasoning, by appropriately guiding the LLM, it can engage in chain-based reasoning [4].\nTo address the challenges of implicit sentiment analysis, This investigation was stimulated by the CoT principle in large language models(LLMS) and introduces a new sentiment analysis framework called Sentiment Analysis of Thought (SAoT)."}, {"title": "II. RELATED WORK", "content": "Sentiment analysis techniques vary in levels and methods, and they possess different levels of task complexity. Rule-based and lexicon-based methods require pre-defined sentiment lexicons and manual annotation of texts, incurring significant labor and time costs. Rule-based approaches tend to exhibit limited effectiveness when dealing with intricate or heterogeneous textual data, as they are restricted to recognizing only elementary sentiments or topics.Machine learning-based methods rely on manually designed sentiment features, which often yield suboptimal results. Using deep learning methods requires a lot of training data and a lot of computing power, and they have limitations in sentiment recognition in texts, particularly in handling complex emotions and topics [5].\nPrompt-based sentiment analysis methods: Recent research has highlighted the potential of prompt engineering to enhance language models' reasoning abilities.By generating prompt templates, language models can improve their performance on reasoning and commonsense reasoning tasks [4].they have"}, {"title": "III. SAOT FRAMEWORK", "content": "As illustrated in Figure 1, the framework leverages common-sense knowledge and the ability to form chains of thought to conduct in-depth analysis of implicit aspects and viewpoints in the text. By reflecting on the process of implicit sentiment analysis, the framework infers the polarity of sentiments.\nIn Figure 1, A: SAOT Chain is depicted, which utilizes split prompts. One prompt is used for conducting in-depth analysis of implicit aspects and viewpoints in the text, while the other prompt is used for reflecting on the process of implicit sentiment analysis. Their respective outputs are obtained by applying a language model. Subsequently, The outcomes are concatenated and forwarded together to the language model to attain the final result.B: No-Chain, on the other hand, utilizes direct input of prompts into a language model to acquire the ultimate outcome.\nThe key findings of this paper are as follows: We propose a sentiment analysis inference framework based on the CoT concept and design a set of effective prompt words to analyze implicit sentiment viewpoints in the text.\n\u2022 Firstly, we utilize common-sense knowledge and the ability to form chains of thought to analyze implicit aspects and viewpoints in the text. Through analyzing the context and relevant information, we can capture the implicit sentiment viewpoints that are not explicitly expressed, enriching the content of sentiment analysis.\n\u2022 Secondly, we reflect on the process of implicit sentiment analysis. Traditional methods often focus only on the surface-level sentiment information in the text, overlooking the underlying sentiment intentions. We believe that implicit sentiment analysis requires further thinking and reasoning to uncover the deeper meanings behind the sentiments. By introducing the process of inference, we can more accurately infer the sentiment polarity in the text, providing more comprehensive and accurate results for sentiment analysis.\n\u2022 Furthermore, we deduce the sentiment polarity results. By combining the semantic information of the text with the sentiment targets, we can better understand the meaning of the sentiment expressions and deduce the corresponding sentiment polarity.\nIn the experimental phase, we combine the SAoT framework with the ERNIE-Bot-4 model and conduct a detailed evaluation and comparison in a zero-shot setting. The experimental results demonstrate that the SAoT+ERNIE-Bot-4 framework achieves significant performance improvements in sentiment analysis tasks."}, {"title": "IV. EXPERIMENTS", "content": "This study aims to conduct experiments on zero-shot sentiment analysis, where we can predict sentiment even without fine-tuning or pre-training by using large-scale models and prompt words. Two widely used datasets, the Laptop and Restaurant datasets, were selected for our experimental analysis. These datasets are sourced from SemEval2014 and are among the most commonly used sentiment analysis datasets. For this research, we exclusively utilized the test data from these datasets, which include user review texts, targets, indications of implicit sentiment, and corresponding sentiment polarity labels (positive, negative, neutral). More detailed information about the datasets can be found in Table 1. By conducting experiments on these datasets, Our objective is to investigate the efficiency of the SAoT approach in the zero-shot sentiment analysis task and analyze its performance."}, {"title": "B. Setup", "content": "In this research, we performed experiments on two publicly available datasets, specifically the Laptop and Restaurant datasets from SemEval14. These datasets consist of explicit and implicit sentiment records. We utilized Flan-T5 as the underlying network for the Large Language Model (LLM) and tested it using Flan-T5 models: 76M, 250M, and 783M, which are available at https://huggingface.co/google. Additionally, we also tested with larger models such as Llama2 and ERNIE-Bot-4. Llama2 encompasses versions: Llama2 7b, and Llama2 70b. Our approach was compared with state-of-the-art zero-shot baseline models, using F1 score as the evaluation metric for zero-shot testing.The Flan-T5 model was executed on a V100 GPU during the experiments, while the Llama2 models were tested on the Baidu Intelligent Cloud Qianfan platform. This platform is an all-in-one enterprise-level platform for large models, providing advanced generative AI production and application development toolchains. The latest version of the Wenxin large model 4.0 has been officially released, offering users powerful functionality and a convenient development environment. In the implementation process, we fully utilized the advantages of the LangChain large model application development tool. By customizing the LLM language model class, we seamlessly integrated different large-scale language models. By leveraging the LangChain tool, we were able to efficiently develop and integrate various LLM models, thus ensuring the functionality of the system. This customizable approach provides more options and effectively addresses various language processing tasks, providing a reliable and efficient foundation for this research."}, {"title": "C. Inference Results", "content": "Table 2 presents a comprehensive comparison of various models employed for zero-shot reasoning. When applied to the restaurant dataset, the ERNIE-Bot-4+SAoT approach achieves an F1 score of 75.27, accompanied by an ISA score of 66.29. On the computer dataset, it attains an F1 score of 76.50, and an ISA score of 73.46.\nIn comparison to the BERTAsp+SCAPT model, the ERNIE-Bot-4+SAoT model demonstrates notable advancements. It exhibits a substantial increase of 45.25% ( = 75.27 - 30.02) in the F1 score on the Restaurant dataset and an impressive improvement of 50.73% ( = 76.50 - 25.77) on the Laptop dataset. On average, there is an overall improvement of 47.99% ( = (45.25 + 50.73) / 2) .\nAdditionally, we performed sentiment analysis on the Llama2+SAoT (7B) and Llama2+SAoT (70B) model series. we observed a direct correlation between the model parameter size of Llama2 and the enhancement in the F1 score. As the model parameter size increased, the F1 score improved accordingly."}, {"title": "D. Enhancing Performance with SAoT Applications", "content": "As shown in Figure 2, we compared the performance differences between the prompt method and the SAoT method based on the ERNIE-Bot-4 model. The outcomes of the analysis on the Laptop and restaurant datasets are illustrated in Figure 2. It can be observed that both the prompt and SAoT methods exhibit relatively high performance levels in ESA, although the improvement achieved by SAoT is limited. However, the prompt-based method shows a higher failure rate in ISA, while ERNIE-Bot-4+SAoT has achieved significant improvements in ISA."}, {"title": "V. CONCLUSION", "content": "This paper presents a sentiment analysis approach that leverages the SAoT framework, aiming to achieve the inference process of implicit sentiment analysis reasoning chains. Building upon existing large-scale language models, we design corresponding prompts for the inference steps of SAoT. By leveraging commonsense and the ability to reason through thinking chains, the large-scale language model performs inferential analysis on implicit aspects and opinions in the text, reflecting on the process of implicit sentiment analysis. Ultimately, we are able to infer the polarity of sentiment. On the Laptop dataset, Our SAoT approach demonstrates superior performance in the zero-shot setting of the ERNIE-Bot-4 model."}]}