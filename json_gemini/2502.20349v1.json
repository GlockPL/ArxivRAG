{"title": "Naturalistic Computational Cognitive Science", "authors": ["Wilka Carvalho", "Andrew Lampinen"], "abstract": "Artificial Intelligence increasingly pursues large, complex models that perform many\ntasks within increasingly realistic domains. How, if at all, should these developments in\nAl influence cognitive science? We argue that progress in Al offers timely opportunities\nfor cognitive science to embrace experiments with increasingly naturalistic stimuli, tasks,\nand behaviors; and computational models that can accommodate these changes. We first\nreview a growing body of research spanning neuroscience, cognitive science, and Al that\nsuggests that incorporating a broader range of naturalistic experimental paradigms (and\nmodels that accommodate them) may be necessary to resolve some aspects of natural\nintelligence and ensure that our theories generalize. We then suggest that integrating\nrecent progress in Al and cognitive science will enable us to engage with more natural-\nistic phenomena without giving up experimental control or the pursuit of theoretically\ngrounded understanding. We offer practical guidance on how methodological practices\ncan contribute to cumulative progress in naturalistic computational cognitive science, and\nillustrate a path towards building computational models that solve the real problems of\nnatural cognition\u2014together with a reductive understanding of the processes and principles\nby which they do so.", "sections": [{"title": "Introduction", "content": "Cognitive scientists build models to make our theories concrete \u2014 which offers testable\npredictions, eliminates ambiguities (Guest and Martin, 2021), and can reveal unexpected\nproperties of cognition and behavior (McClelland, 2009). Cognitive models can range from\nsimplified models of a high-level process (e.g. Frank and Goodman, 2012; Cohen et al.,"}, {"title": "What is \u201cnaturalistic\u201d computational cognitive science?", "content": "Naturalistic computational cognitive science is a research strategy for theory-driven cognitive\nscience that aims to predict human behavior across increasingly naturalistic stimuli and tasks.\nThis approach gradually increases the ecological validity of experimental designs while ensuring\nmodels can accommodate both simplified and more natural conditions. As demonstrated in\nmachine learning (\u00a75), this strategy has enabled models that can work with real-world data,\nalbeit imperfectly."}, {"title": "The benefits of naturalistic experimental settings", "content": "In this section, we outline the benefits of naturalistic experimental settings for cognitive\nscience. Specifically, we argue that naturalistic experimental settings can engage mechanisms\nthat are qualitatively different than those engaged in simpler settings \u2014 and thereby change\nthe scientific inferences we draw. We review examples where naturalistic experimental settings\nhave changed our understanding of a system, and have helped to disentangle competing\nmodels that simpler settings could not.\nAs an orienting conceptual example, imagine that we are doctors studying heart function,\nand we chose to only study it while the participants are lying down and resting. We could\ncertainly learn interesting things thereby; the resting setting offers high test-retest reliability,\nand a highly-controlled environment to study the processes like how respiratory cycles affect\nheart rate. However, it offers this control and reliability precisely by removing the many\nfactors of natural variation that interact with heart rate, and indeed for which heart function\nevolved \u2014 such as rapid adaptation to movement, stress, etc. Studying heart function across\na broader range of naturalistic settings would be necessary to understand why the system is\nthe way it is, and how all the physiological (and psychological) processes involved interact.\nFor example, if we experimentally manipulated breathing, but did so across a range of different\nnaturalistic activities (sitting, speaking, running, etc.) we would more effectively determine\nhow breathing affects heart function, and how that effect depends on the state of the overall\nsystem. That is, by studying phenomena across a range of naturalistic settings we elaborate\nour understanding of the system, and can build more complete theories of its function."}, {"title": "Behavior can be different in naturalistic experiments", "content": "The starting point for many cognitive analyses is behaviors on a task designed to isolate\nsome cognitive capability. However, there are many cases in which task-relevant behavior\ncan be altered by seemingly-orthogonal features of the task\u2014thus raising the risk that our\ntheories will be overfit to a restricted task setting unless we also consider a broading range\nof variation. In this section, we review some examples illustrating changes in behavior or\ncapabilities in naturalistic settings.\nExample 1: moral behavior can change when moving from textual vignettes to virtual\nreality. Recent research has shown that behavioral choices can change when moving from\ntext to virtual reality as it can mark a shift from moral judgment (i.e. deciding whether\nthings are moral) to moral action (Francis et al., 2017). When presented with the classic\ntrolley dilemma in text form, only 40% of participants say they would pull a switch to divert\na trolley that would kill one person to save five others. However, when the same scenario\nis presented in virtual reality where participants must simulate the action, 55% choose to\npull the switch. This difference becomes even more pronounced in the \u201cfootbridge\u201d variant\nof the dilemma. In the text version, only 10% of participants say they would push someone\noff a bridge to save five others. Yet when able to simulate this action in virtual reality, 65%\nof participants choose to push the person. These findings demonstrate that people's stated\nmoral preferences in hypothetical scenarios can differ substantially from their actions in more\nnaturalistic settings.\nExample 2: memory performance differs between naturalistic search and explicit mem-\norization. When participants are explicitly instructed to memorize objects in a 3D home\nenvironment, their subsequent recall accuracy was significantly lower than when they inciden-\ntally encounter the same objects during visual search tasks (Helbing et al., 2020). This effect\nextends to spatial memory as well. Not only do participants better remember the identity of\nobjects encountered during search, they also show more accurate memory for object loca-\ntions-placing objects closer to their original positions when they were initially seen during\nsearch versus explicit memorization. These findings demonstrate that tasks focused explicitly\non memory may not capture all aspects of how memory naturally operates during everyday\nbehavior. Additionally, it suggests that computational models of memory may need to be\nrevised to account for these differences in naturalistic settings. This is supported by research\nshowing that people display detailed memory of object and spatial information in real-world\nscenes (Bainbridge et al., 2019).\nExample 3: mice can learn 1000\u00d7 faster during natural behavior, compared to two-\nalternative forced choice tasks. Recent research has shown that learning rates can dra-\nmatically differ between simplified laboratory tasks and more naturalistic settings (Rosenberg\net al., 2021). When mice are tested in traditional two-alternative forced choice (2AFC)\ntasks, they typically require 10,000 trials over 3-6 weeks of training to reach asymptotic per-\nformance of only about 67% accuracy. However, when allowed to freely explore a labyrinth"}, {"title": "Neural systems can operate differently under naturalistic conditions", "content": "In addition to behavioral differences like those reviewed above, naturalistic conditions can\nresult in changes to neural coding and computation. Thus, in order to arrive at a complete\nunderstanding of neural function, we need to consider the responses of the system across\na range of simpler and more naturalistic settings. In this section, we highlight some exam-\nples of different computations or computational roles that arise when moving from standard\nparadigms to more naturalistic ones.\nExample 1: the model of superior colliculus shifted from a model of eye movement to\none of integrating sensory inputs for body control. Cisek (1999) suggests that the focus\non computational behavior as an input-output mapping neglects the fundamental fact that\nnatural intelligence evolved not to produce single responses, but for closed-loop control in an\nenvironment. This setting yields a rather different interpretation of the system's representa-\ntions and processes. More generally, many researchers have argued that cognition cannot be\nunderstood completely outside its embodiment and the environment in which cognitive pro-\ncesses are instantiated (e.g., Newen et al., 2018). For example, Cisek and Green (2024) ar-\ngues that as we increased naturalism from head-fixed to head-free to body-free settings when\nstudying monkeys, we expanded our theory of superior colliculus from controlling saccadic eye\nmovement to generally integrating multimodal cues to guide bodily action-selection (Cisek\nand Green, 2024). That is, as we increased the naturalism of the experimental conditions\nthat we used to study monkeys, we arrived at a more complete model of superior colliculus.\nExample 2: visual processing systems operate differently during natural viewing com-\npared to passive viewing paradigms. Traditional research has shown that one of the earliest\nvisual responses in the brain (known as P100/M100) occurs about 100ms after a person's\neyes land and fixate on a new location (Vinje and Gallant, 2000). However, this finding comes\nprimarily from experiments where participants passively view images while keeping their eyes\nstill. In contrast, natural vision involves actively moving our eyes multiple times per second\nto sample information from different parts of a scene. When the researchers examined brain\nresponses during this more natural active viewing, they found that the P100/M100 response\nactually begins when the eye movement (saccade) starts, not when it ends at the new fixation"}, {"title": "Naturalistic experimental paradigms can expose computational chal-lenges that engage mechanisms differently", "content": "Finally, naturalistic paradigms can likewise introduce challenges that are important to un-\nderstanding functioning of the system as a whole. In this section, we highlight examples\nwhere the challenges posed by increasing naturalism can engage computational mechanisms\ndifferently\u2014which can be useful for disentangling underlying mechanisms, and is important\nfor achieving generalizable understanding.\nExample 1: Different learning mechanisms only yield distinct predictions under work-\ning memory load. Overly-simplified tasks can yield aliasing of different solutions, where\nmany different computational approaches yield the same behavior. Collins (2024) presents\nan example, by showing that what seems superficially to be implemented as a standard rein-\nforcement learning algorithm, on closer examination may instead be implemented through a\ncombination of working memory and simpler value-free associative learning. However, the\ndifference between these two implementations cannot be identified in standard task settings,\nas Collins notes: \u201cEven simple tasks designed to elicit a target process (such as bandit tasks\nfor RL) recruit multiple other processes, but those processes may be unidentifiable in such\ntasks. Disentangling multiple processes requires considering more complex tasks to elicit dif-\nferentiable behavior.\u201d The more complex tasks in question simply increase the stimulus set\nsize within learning blocks to a handful of objects, rather than restricting to two or three\u2014i.e.,"}, {"title": "The (surprising) benefits of learning with naturalistic data", "content": "The standard lesson in science is that we must simplify an experimental setting so that we can\nbetter arrive at a causal conclusion. However, we have already seen examples illustrating that\nmore is different (Anderson, 1972) \u2014certain properties of intelligence may only emerge in more\n\"complicated\u201d naturalistic settings. In this section, we detail examples where naturalistic data\nitself seems to play an importance role in producing the empirical phenomena of intelligence\nthat we wish to study.\nMany of the findings we will discuss here will be modern results from Al. One common trend\nis that there is a positive interaction between learning-based systems and naturalistic data\u2014\nlearning-based systems can accommodate naturalistic data, and reciprocally, learning from\nnaturalistic data results in qualitatively better results than learning in simpler settings. While"}, {"title": "Learning enables models that can operate on natural data", "content": "Perhaps the first surprising benefit of (deep) learning is that it enables a system to operate\nover natural data. Until AlexNet (Krizhevsky et al., 2012), the prevailing wisdom was that\none had to design useful representations of natural data for models. However, AlexNet and\nsubsequent work showed that a model could learn useful representations for naturalistic data\nsimply by being trained to make predictions about this data. Surprisingly, these models learn\nrepresentations that have notable correspondence to the internal representations in visual\ncortex (Yamins et al., 2014; Khaligh-Razavi and Kriegeskorte, 2014). Here, we review some\nof this work and how learning-based methods can enable more flexible cognitive models that\noperate on natural data.\nLearning-based vision models can operate on natural data and predict neural data (sur-\nprisingly) well. There is a rich history of learning-based methods revealing how neural net-\nworks can develop internal representations from pixel-based images that strongly correspond\nto neural data. A seminal example comes from Olshausen and Field (1996), who showed that\nV1-like Gabor filters could emerge from a convolutional neural network optimized to transmit\ninput while minimizing overall activation (essentially, a sparse autoencoder). Prior to this, V1\nactivations were modeled using analytically defined Gabor filters. This breakthrough demon-\nstrated that V1-like receptive fields could arise naturally from optimization to environmental\nstatistics of edges at varying frequencies and orientations. Building on this foundation, Lee\net al. (2007) demonstrated that V2-like convolutional filters could emerge from unsupervised\noptimization of sparse deep belief networks. A significant advance came when Yamins and\nDiCarlo (2016) showed that task-optimized deep convolutional neural networks trained for\nobject classification developed intermediate layers that matched neural representations in V4\nand IT better than any previous models. Recent research has revealed an even more striking\nfinding: these task-optimized networks represent images in a latent space whose geometry\nhas remarkable correspondence to brain topography (Doshi and Konkle, 2023). When fitting\na 2D sheet to image representations such that neighboring points correspond to nearby points\nin the original high-dimensional space, the resulting sheet shows striking similarities to actual\nbrain topography. Thus, learning-based approaches, particularly neural networks, not only\nenable effective visual processing but also provide surprisingly accurate predictions of brain\norganization and function."}, {"title": "Learning from naturalistic data can improve generalization", "content": "Studying how systems generalize is a key method in cognitive science and Al. Conceptual\narguments often rely on empirical studies of generalization; however, these generalization\nproperties are often studied in simple settings, with minimal models learning from minimal\nfeatures (e.g. Marcus, 1998). A fundamental assumption underlying this approach is that\nthe simplifications do not alter the generalization problem. However, here we review studies\nfrom Al and neuroscience showing that the variability of experience according to seemingly-\northogonal variables can alter how systems learn and generalize\u2014thus implying that studying\nmodels within more restricted settings may be misleading about the naturalistic computational\nproblem.\nExample 1: Compositional generalization of image classifiers vs. agents. Naturalistic\ntasks can fundamentally change what models learn and how they generalize. Hill et al. (2020)\ntrained two models to do a vision-language grounding task, and tested their compositional\ngeneralization to held-out language instructions. Both models were trained on the same\nlanguage examples, and tested on the same held-out examples. However, one model was\ntrained as an agent that interacts with a simulated environment, while the other was a simple\nimage-language classifier trained on screenshots from that environment. The authors found\nthat the interacting agent exhibited perfect compositional generalization to the novel language\nutterances, while the image classifier was substantially worse in novel settings. The authors\nalso explored a range of other settings, including generalization benefits of more naturalistic\n3D (rather than 2D) environments, or egocentric embodiments. Their results illustrate how\nricher, more naturalistic settings can enhance the generalizability of the solutions a system\nlearns. Thus, if we are interested in understanding how a system generalizes, we may need"}, {"title": "Learning with naturalistic data can yield good performance acrossa range of seemingly disparate tasks", "content": "One interesting finding from the deep learning literature is that when deep learning archi-\ntectures with many parameters are trained with a lot of naturalistic data and an appropriate\n\"basic\u201d learning objective, these architectures can develop mechanisms that go beyond the\nlearning objective they were trained on. Crucially, these learning paradigms can allow models\nto transfer well (through initial performance or accelerated learning) on novel tasks beyond\nthe training distribution.\nHuman learning may likewise benefit from transfer among the disparate tasks we learn. We ar-\ngue that these Al findings motivate computational cognitive science research studying whether\n\"down-stream human behavior\u201d on a set of tasks can be recapitulated by a model which is\ntrained on a large set of naturalistic tasks or stimuli representative of some of aspect of\nhuman experience\u2014as in meta-learning approaches (cf. Wang, 2021). Below, we provide ex-\namples of this kind of transfer spanning computer vision, reinforcement learning, and natural\nlanguage processing.\nExample 1: Computer Vision. One of the earliest successes from deep learning came in\ncomputer vision. Soon after AlexNet (Krizhevsky et al., 2012) achieved strong results on\nthe ImageNet dataset (Deng et al., 2009), researchers showed that the features discovered\nby AlexNet could be repurposed to novel tasks ranging from scene recognition to medical"}, {"title": "Learning from naturalistic data allows us to ask new questionsabout the origins of knowledge", "content": "The points outlined above have an important consequences; using models that learn from\nnaturalistic data can change our theoretical conclusions in cognitive science. For example,\nif a model fails to generalize when trained on simple data, we cannot be sure if the model"}, {"title": "Building generalizable models", "content": "ML research has excelled in developing generalizable models. While we focus on their utility for\nworking on naturalistic stimuli and tasks, we believe cognitive science would broadly benefit\nfrom improved practices for developing generalizable models. In this section, we highlight\nthree key practices of empirical ML research that we believe computational cognitive science\ncan adopt. The first is frictionless reproducibility: the practice of developing research artifacts\nwhich can be reused, and repurposed with minimal effort (\u00a75.1). The second is a focus on\ndeveloping generalizable models that can learn successfully across many datasets (\u00a75.2). We\nargue that these two offer the foundation for having groups of research collectively work on\nimportant research problems through the utilization of benchmarks (\u00a75.3).\nBefore we continue, we acknowledge that modern empirical ML is a young field which, like\nother fields, has faced challenges in rigor and reproducibility (Melis et al., 2017; Lucic et al.,\n2018; Riquelme et al., 2018; Henderson et al., 2018; Recht et al., 2019; Agarwal et al.,\n2021). Despite these challenges, we are optimistic that some of the practical knowledge ML\nhas developed is valuable for improving rigor and reproducibility, as we highlight below."}, {"title": "Frictionless reproducibility: a superpower", "content": "Within cognitive science and psychology, there is currently substantial friction when using data\nor code of prior work (Nosek et al., 2015; Hardwicke et al., 2018). Researchers may not share\ndata in a standard or easy to use format, often don't fully report their analysis methods, or\nprovide code that contains errors (Poldrack et al., 2017). In a large-scale replication analysis\nof open code and data, researchers found that 38% of code was not usable and only 31%\nof workflows had reproducible results (Hardwicke et al., 2018). These factors may have\ncontributed to the replication crisis (Lilienfeld, 2017; Shrout and Rodgers, 2018).\nIn recent years, data-centric sciences are experiencing a profound transition to what David\nDonoho calls \u201cfrictionless reproducibility\" (Donoho, 2024; cf. Recht, 2024). Donoho identi-\nfies three key pillars to frictionless reproducibility: data sharing, code sharing, and competitive\nchallenges. We will focus on the first two in this section, and competitive challenges in \u00a75.3.\nCritically, with frictionless reproducibility, the research artifacts that are produced allow fu-\nture researchers to exactly re-execute the same complete workflow with minimal effort. With\nthis, good ideas are spread, adopted, and improved with little friction. Donoho argues that\nML is ostensibly the most successful at frictionless reproducibility. Below we review some\nsupporting strategies that may aid cognitive science."}, {"title": "Developing models with an eye towards generalizability", "content": "Task-performing computational models have been a goal of cognitive science since Newell\n(1973). This sentiment still exists today (Kriegeskorte and Douglas, 2018; Almaatouq et al.,\n2024) and is exemplified in conferences that explicitly seek to integrate cognitive science and\nneuroscience with Al (Naselaris et al., 2018). Cognitive scientists are well aware that they\ncan't rely on a single paradigm for the studying an effect if they want to achieve generaliz-\nable conclusions (Holzmeister et al., 2024; Yarkoni, 2022). Ideally, the models we develop\ngeneralize beyond the setting (e.g. stimulus set or task-specification) they were designed\nfor. This requires two things. First, that the model can operate over new stimulus sets and\ngeneralize its behavior to new tasks. Second, that the behavioral (and potentially neural)\npredictions made by our models capture human behavior on new tasks and new stimulus sets.\nClearly, the first is a requirement for the second. Here, we argue that machine learning, with\nits emphasis on frictionless reproducibility, has made significant strides in developing models\nthat can generalize. We detail recommendations for cognitive science below."}, {"title": "Benchmarks: catalysts for progress and innovation", "content": "Another challenge that cognitive science faces is fragmentation. This has been true since\nNewell's seminal critique (Newell, 1973), where his observation that piece-wise investigation\nof brain components would not yield a cohesive understanding remains relevant forty years\nlater (Schrimpf et al., 2020; DiCarlo et al., 2023). Current experimental paradigms often\nproduce disconnected, incommensurate findings that resist integration across studies, even\nwithin the same domain (Almaatouq et al., 2024). This fragmentation manifests not only in\nmethodology but also in how researchers distribute their attention across different problems,"}, {"title": "Building from naturalistic experiments to cognitive the-ories", "content": "A primary goal of cognitive science is understanding. Experiments and computational mod-\neling are key constraints on theory building. By instantiating our theories in a model, we\nare forced to make our theories more precise by concretizing the ambiguous details of the\nmapping from a verbal hypothesis to its implementation (Guest and Martin, 2021).\nFrom this perspective, building computational models that perform the task in as naturalistic\na way as possible, across as wide a variety of settings as possible, imposes much stronger\nconstraints on our theories than an abstracted model at a higher-level (cf. Cao and Yamins,"}, {"title": "Performing controlled experiments by parametrically manipulatingnaturalistic data (in unnatural ways)", "content": "Developing and testing models on truly naturalistic data introduces new issues that are not\npresent in simple artificial settings. Naturalistic data distributions may be too \u201ceasy\u201d \u2014for\nexample, they may only rarely include edge-cases that test key capabilities (Zhang et al.,\n2023); thus, testing average performance over a naturalistic distribution may not identify\nimportant failures. Relatedly, in naturalistic data, features may be confounded, which can\nprevent readily disentangling how a model is solving a task (Rust and Movshon, 2005). For\nexample, models trained on ImageNet (Deng et al., 2009) rely on features like texture more\nthan humans do (Geirhos et al., 2018), but still perform similarly to humans on ImageNet.\nThese issues limit our ability to achieve deep understanding from experimenting with only the\ndistribution of naturalistic data (Rust and Movshon, 2005).\nHowever, we believe that these challenges are surmountable by parametrically manipulating\nrich, naturalistic data (Fig. 8)-preserving or enhancing its richness, while more carefully\naccounting for theoretically motivated constructs. For example, to effectively test processing\nof challenging syntactic structures, Futrell et al. (2021) edited natural stories to increase the\ndensity of these rare constructions, while preserving the richness and naturalism of the original\ncontent. Similarly, the work of Geirhos et al. (2018) engineered datasets that combine natural\nshapes and textures in unnatural ways. To do so, the authors exploited the contemporary ML\ntechnique of iterative style transfer Gatys et al. (2016)-combining the features of different\nimages at different spatial scales\u2014thus illustrating how progress in Al models unlocks new\nexperimental approaches. These conflicting shape-texture datasets helped to inspire similar\nexperiments on humans (Jagadeesh and Gardner, 2022b,a); surprisingly, those studies found\nthat human visual cortex likewise appears to use textural rather than shape-focused represen-\ntations, and shape-driven behavior is thus mediated by downstream readout processes. Thus,\nmanipulating features to test models can lead to new insights into brain function."}, {"title": "Incorporating naturalistic variation to enhance generalizability", "content": "By testing hypotheses in settings where other aspects of the task and data generating process\nare sampled broadly from the naturalistic distribution, we address some of the challenges of\ngeneralizability that arise from testing on a much narrower distribution than the written hy-\npothesis implies (cf. Yarkoni, 2022). For example, if the hypothesis is about visual processing\nin general, but the task paradigm relies solely on abstract shape stimuli, the conclusions may\nnot generalize in the way the written results would suggest. Thus, testing our hypotheses\nacross varied settings\u2014\u201cdesign[ing] with variability in mind\" (Yarkoni, 2022)-increases the\nlikelihood of identifying robust effects that will generalize (cf. Baribault et al., 2018). In the\nlanguage of regression, varying as many other data generating factors as possible brings us\ncloser to estimating the \u201cmain effect\u201d of an experimentally-manipulated construct, rather\nthan estimating the \u201csimple effect\" of the manipulation in the single setting we have tested.\nFor example, it is a long-standing principle of experimental design to test a hypothesis with\nmultiple stimuli, and statistically quantify the stimulus effect to estimate the generalizability\n(e.g. Clark, 1973). However, many other experiment features\u2014even exact task formulations\nsuch as multi-arm bandit tasks\u2014are often preserved within a paper, or even across an entire\nliterature. Just like testing a hypothesis with a single stimulus, this lack of variation poses\nchallenges for generalizability (cf. Eckstein et al., 2022)\u2014especially because the way that\nresearchers operationalize a theory can substantially affect their conclusions (e.g. Holzmeister\net al., 2024; Schweinsberg et al., 2021; Strickland and Suben, 2012). While naturalistic\nvariation cannot resolve this issue in full, we believe that incorporating a broader range of\nthe natural variation of settings, stimuli, and tasks within which we expect those theories to\nhold, will help us to develop more generalizable theories.\nIncorporating variation into our experiments can also help us to revise the constructs un-\nderlying our theories. For example, Eisenberg et al. (2019) study the putative construct of\nself-regulation by simultaneously testing a large variety of existing self-regulation measures.\nThe authors find that these measures do not form a unitary construct. Rather, task- and\nsurvey-based measures each tap into distinct, multi-factorial constructs, with individual tasks\nloading primarily onto a subset of the factors in their domain. That is, two different studies\nthat each use only a single measure for self-regulation may be tapping into entirely different\nconstructs. By contrast, by substantially varying the tasks we use to measure a theoretical\ncomponent like self-regulation, we can more fully disentangle the underlying constructs\u2014and\nthereby improve the extent to which our theories generalize."}, {"title": "Interpreting complex models to yield explanations", "content": "If we perform experiments in naturalistic settings, and develop complex models that can pre-\ndict human behavior across them, how does this support explaining the cognitive phenomena\nof interest? In this section we will review some paths to deriving explanations of phenomena"}, {"title": "Theories that combine task-performing models with reductive explanation.", "content": "Above, we have argued for the value of embracing the richness of naturalistic tasks, even if\nit leads us to build more complex task-performing models that are hard to interpret, but that\nperhaps make more accurate predictions of behavior. In the previous section, we have outlined\nsome of the possibilities (and challenges) of deriving understanding from these models. So\nwhat, ultimately, should we seek?\nWe argue that naturalistic computational cognitive science should seek theories of cognitive\nphenomena that consist of two components:\n1. Task-performing (predictive) models that reproduce the phenomena across the same\nrange of naturalistic stimuli and paradigms as the human/animal subjects.\n2. Reductions of these task-performing models to simpler mechanisms, properties, and\ntheories of why these models reproduce the phenomena.\nThese two components serve different purposes. The first helps to demonstrate that the\nmodels are real candidate models of the phenomena in question, rather than models that\nsimply could not scale to the real problem or that are overfit to a particular instantiation of\nthe task. We believe this component is necessary because otherwise the problem space is\nunder-constrained, as we have argued above. Moreover, it provides a test-bed for perform-\ning experimentation that would be impossible in reality (e.g. beyond what would be feasible\nor ethical in the lab), which is useful for both scientific and practical reasons. The second\ncomponent-where feasible\u2014allows linking these predictions to the explanatory understand-\ning that cognitive scientists have usually sought, and that may help us to generalize our\ninsights beyond the current paradigms. This perspective aligns with past arguments on how\ndeep learning can contribute to understanding in cognitive neuroscience (Saxe et al., 2021;\nKanwisher et al., 2023; Cao and Yamins, 2024b; Doerig et al., 2023). However, we emphasize\nthat combining these two components makes explicit links between the actual problem the"}, {"title": "Discussion", "content": "In this paper, we have tried to outline a direction of research that we call \u201cnaturalistic com-\nputational cognitive science\u201d that aims to build generalizable models of cognition that scale\nto naturalistic tasks, while still offering routes to explanatory and theoretical understanding.\nThis perspective synthesizes a growing literature on the importance of naturalistic experi-\nments and generalizable models, and grows out of a long-standing focus in cognitive science\non explaining a broad range of phenomena. We outline these connections here.\nThe quest for building general models of natural intelligence. A long history of cognitive\nscience research has sought to develop frameworks with the generality to explain a wide scope\nof cognitive phenomena. Researchers in connectionist (e.g. McClelland et al., 1986, 2003),\nBayesian (e.g. Tenenbaum and Griffiths, 2001), and cognitive architectures (e.g. Ritter et al.,\n2019; Laird, 2019) paradigms have tried to identify underlying principles or mechanisms that\nexplain many phenomena. However, while the modeling frameworks themselves are general,\ntypical instantiations of these frameworks have built specialized models focused on individual\ntasks.\nOther recent studies have built upon foundation models from Al that can perform many\ntasks. Some works have applied cognitive paradigms to study the behaviors of these models\n(e.g. Binz and Schulz, 2023; Lampinen et al., 2024; Buschoff et al., 2025). Other recent\nworks have finetuned these models using cognitive data, to create generalizable cognitive\nmodels that can predict behavior on new experimental paradigms in areas like vision (e.g.\nMuttenthaler et al., 2024b,a; Fu et al., 2024), or the broader space of cognitive tasks that\ncan be presented in language (Binz and Schulz, 2024; Binz et al., 2024).\nWe see the arguments that we have laid out in this paper as being broadly compatible with\nmany of these approaches and frameworks, but offering a stronger emphasis on the virtuous\ncycle of expanding the scope and naturalism of our experimental designs, and expanding\nthe generalizability of our models and theories\u2014and anchoring these in the practicalities of\nachieving frictionless reproducibility.\nTowards experiments that involve naturalistic behavior In emphasizing more naturalistic\nexperiments, our perspective aligns with a variety of works that have likewise highlighted\nthe importance of considering the scope of complex naturalistic behaviors. This perspective\nhas been advocated frequently in neuroscience (e.g. Mobbs et al., 2021; Cisek and Green,\n2024), where even prominent visual processing signals can be fundamentally different in active,\nnaturalistic paradigms than in simpler classic ones (e.g. Amme et al., 2024). Likewise, Wise\net al. (2023) advocate for the need to explore more naturalistic environments and behaviors in\nreinforcement learning, to grapple with the complexity of behavior in environments closer to"}]}