{"title": "Humanity in AI: Detecting the Personality of Large Language Models", "authors": ["Baohua Zhang", "Yongyi Huang", "Wenyao Cui", "Huaping Zhang", "Jianyun Shang"], "abstract": "Questionnaires are a common method for detecting the personality of Large Language Models (LLMs). However, their reliability is often compromised by two main issues: hallucinations (where LLMs produce inaccurate or irrelevant responses) and the sensitivity of responses to the order of the presented options. To address these issues, we propose combining text mining with questionnaires method. Text mining can extract psychological features from the LLMs' responses without being affected by the order of options. Furthermore, because this method does not rely on specific answers, it reduces the influence of hallucinations. By normalizing the scores from both methods and calculating the root mean square error, our experiment results confirm the effectiveness of this approach. To further investigate the origins of personality traits in LLMs, we conduct experiments on both pre-trained language models (PLMs), such as BERT and GPT, as well as conversational models (ChatLLMs), such as ChatGPT. The results show that LLMs do contain certain personalities, for example, ChatGPT and ChatGLM exhibit the personality traits of 'Conscientiousness'. Additionally, we find that the personalities of LLMs are derived from their pre-trained data. The instruction data used to train ChatLLMs can enhance the generation of data containing personalities and expose their hidden personality. We compare the results with the human average personality score, and we find that the personality of FLAN-T5 in PLMs and ChatGPT in ChatLLMs is more similar to that of a human, with score differences of 0.34 and 0.22, respectively.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) serve as human assistants that can understand and respond to human language more naturally, help customer service agents respond to client queries promptly and accurately, and offer more personalized experiences (Jeon and Lee, 2023; Liu et al., 2023; Dillion et al., 2023). Unlike traditional deep learning models, LLMs achieve remarkable performance in semantic understanding and instructions following (Lund et al., 2023; Liu et al., 2023), which makes LLMs behave more like humans.\nSome research suggests that LLMs are similar to humans in terms of their thinking. For example, Kosinski (2023) shows that ChatGPT has reached the level of a human 9-year-old child. Additionally, Bubeck et al. (2023) demonstrates that GPT-4 possesses fundamental human-like capabilities. These capabilities include reasoning, planning, problem-solving, abstract thinking, understanding complex ideas, rapid learning, and experiential learning. Experts from Johns Hopkins University have found that the theory of mind of GPT-4 has surpassed human abilities. It achieves 100% accuracy in some tests through a process of mental chain reasoning and step-by-step thinking (Moghaddam and Honey, 2023). Based on these works, we believe it is reasonable to detect the personality of LLMs using methods commonly used to evaluate the personality of humans.\nOne of the most commonly used psychological model in human personality detecting systems is Big Five (Costa and McCrae, 1992), which sorts personalities into openness, conscientiousness, extraversion, agreeableness, and neuroticism. Other commonly utilized psychological frameworks include MBTI (Jessup, 2002), 16PF (Cattell and Mead, 2008), and EPQ (Birley et al., 2006). Early psychology research established conventional assessment approaches, such as questionnaires and text mining.\nQuestionnaire is the most commonly used method for human personality detection. It mainly works by providing a series of statements and asking participants to indicate the extent to which each statement applies to themselves (Boyd and Pen-"}, {"title": "2 Related Work", "content": "In this paper, we explore the personality of LLMs guided by the Big Five psychological model. We will introduce research work on psychological and some key research from PLMs to ChatLLMs."}, {"title": "2.1 Personality Traits", "content": "The most widely and frequently used personality models are the Big Five model (Costa and McCrae, 1992) and the MBTI model (Jessup, 2002). In the early stages of psychological research, questionnaires (Vanwoerden et al., 2023) and self-report (Lin et al., 2023) methods are the main tools used to determine and examine an individual's personality. These methods focus on providing the participant with a number of descriptive states to answer according to his or her personality, with one of the more well-know ones being IPIP 2 (International Personality Item Pool) (Goldberg et al., 2006). Then personalities of the participants can be scored according to their answers (Hayes and Joseph, 2003). But, these methods are gradually abandoned by computer science scholars due to their low efficiency and ecological validity. Scholars then try to use lexicon-based methods, machine learning-based methods, and neural network-based methods to mine personality traits from text, which increases efficiency by eliminating the need to collect questionnaires.\nLexicon-based methods include LIWC (Pennebaker et al., 2001), NRC (Mohammad and Turney, 2013), Mairesse (Mairesse et al., 2007) and others. Those lexicons can be used to extract the psychological information from text. However, the different systems and classification criteria used by various researchers means that the mixing of multiple dictionaries may introduce errors. Additionally, this method may not effectively extract features in long texts. Machine learning-based methods include SVM, Na\u00efve Bayes and XGBoost (Nisha et al., 2022). Neural network-based methods include the use of CNN (Majumder et al., 2017), RNN (Sun et al., 2018), RCNN (Xue"}, {"title": "2.2 Large Language Models", "content": "LLMs have a significant impact on the AI community with the emergence of ChatGPT3 and GPT-44, leading to a rethinking of the possibilities of Artificial General Intelligence (AGI). The base model of ChatGPT is GPT3 (Brown et al., 2020), a pre-trained model that has 175B parameters. GPT-3 can generate human-like text and complete tasks such as language translation, question answering, and text summarization with impressive accuracy and fluency. Models similar to GPT3 include LLaMA (Touvron et al., 2023), BLOOM (Scao et al., 2022) and T5 (Raffel et al., 2020). Although the OpenAI team has not release the technical details of ChatGPT, we can infer from the content of InstructGPT (Ouyang et al., 2022) that the process of training with instruction data is very important. Then, more models such as Alpaces obtained by train LLaMA with the instruct dataset generated by ChatGPT, ChatGLM based on GLM (Zeng et al., 2022; Du et al., 2022), BLOOMZ and Vicuna have been released. Although these models have slightly weaker capabilities than ChatGPT, they have fewer parameters and consume fewer resources.\nFollowing the release of these models, it has become well-established that individual researchers can train a ChatLLM from a base PLM. This also opens up the possibility of exploring the knowledge contained within LLMs. Given that current LLMs are so human-like in their performance, we believe that psychological measures used for humans can be employed to detect the personality of LLMs."}, {"title": "2.3 Personality in LLMs", "content": "There have been several a lot of works focusing on the personality of LLMs (Safdari et al., 2023; Jiang et al., 2024; Pan and Zeng, 2023). Wen et al. (2024) propose that there are two categories of detection, Likert scale questionnaires (Song et al., 2023b; Frisch and Giulianelli, 2024) and assessment results analysis (Dorner et al., 2023; Huang et al., 2023).\nIn the questionnaire approach, the direct use of questionnaires usually requires additional work to extract the LLMs' answers from their re-sponses (Serapio-Garc\u00eda et al., 2023). For example, Ganesan et al. (2023) investigate the zero-shot ability of GPT-3 in estimating the Big Five personality traits from users' social media posts. Jiang et al. (2022) detect personality in LLMs using the questionnaire method and propose an induced prompt to shape LLMs with a specific personality in a controllable manner.\nTo facilitate the statistical analysis of results, some studies have defined the current task in a prompt format and specified the structure of the LLMs' responses (La Cava et al., 2024; St\u00f6ckli et al., 2024). Meanwhile, to reduce the likelihood of the model rejecting responses, some studies have changed the questionnaire to be completed by a third person or used role-playing tasks to prompt LLMs to generate responses (Miotto et al., 2022; ?). However, Song et al. (2023b) argue that self-assessment tests are not suitable for measuring personality in LLMs and advocate for the development of dedicated tools for machine personality measurement.\nIn the assessment results analysis method, the current approach focuses on classifying responses from LLMs (Karra et al., 2022; Pellert et al., 2023). In addition to neural network-based models, linguistic-based text analysis tools have also been used for personality classification of LLMs (Frisch and Giulianelli, 2024; Jiang et al., 2023).\nHowever, all current methods have limitations. Questionnaire methods are constrained by LLM hallucinations, and models that categorize re-sponses for LLMs often lack psychological features. To address this issue, we combine both questionnaire and text mining methods, which, in our opinion, can yield more objective results. We adapt Psy Atten (Zhang et al., 2023) as the classifier, which can combine text features with psychological features."}, {"title": "3 Method", "content": "As we mentioned above, we use questionnaire and text mining to detect the personality of LLMs. The example of the two methods is shown in Figure 1, and the process of the two methods is shown in Figure 2.\nIn questionnaire method, we use the MPI120 questions to replace [Statement] and then ask each LLM to provide an answer from (A) to (E). The model's score on each question is calculated based"}, {"title": "4 Experiments", "content": "We employ personality questionnaire (MIP120) datasets (Casipit et al., 2017) in questionnaire method and personality classification (Essay) datasets (Pennebaker and King, 1999) in text mining method. The MIP120 dataset comprises 120 individual state descriptions, covering all five traits of the Big Five. During testing, participants are required to select one answer from five given options. The Essay dataset includes 2468 articles written by students, and each article is labeled with Big Five traits. It is worth noting that for LLMs, both datasets were used for testing."}, {"title": "4.2 LLMs", "content": "To investigate the sources of personality knowledge embedded in LLMs, we select two sets of baseline models. One set consists of PLMs for text generation, such as BERT-base (Devlin et al., 2019), GPT-neo2.7B, flan-T5-base (Raffel et al., 2020), GLM-10b (Du et al., 2022), LLaMA-7b (Touvron et al., 2023), BLOOM-7b (Scao et al., 2022), GLM4-9b, LLaMA3-8b, and so on. The other set consists of ChatLLMs trained on the instruct dataset, which can better follow human instructions and includes Alpaca-7b, LLaMA3-Chat-8b, ChatGLM-6b, GLM4-Chat-9B, BLOOMZ-7b, ChatGPT (gpt-3.5-turbo) and GPT40 (gpt-4o-2024-08-06).\nAll LLMs checkpoints are obtained from the Hugging Face Transformers library, and inferences are accelerated by four NVIDIA A100 80GB GPUs and four RTX 3090 GPUs. For ChatGPT and GPT40, we call their API to obtain experimental results. To obtain the original results, we do not change the initialization temperatures."}, {"title": "4.3 Experiment Design", "content": "As mentioned above, we employ both questionnaire and text mining methods to conduct the experiments.\nQuestionnaire: We conduct experiment based on Figure 1(a). Since the PLMs are unable to follow the instructions shown above, we used a few-shot learning approach letting the model generate further answers, the example prompts are shown in Appendix 6.1. We provide three examples with different answers for one statement, then present the actual statement for the PLMs to answer. Detailed statistical results are shown in Table 7. For ChatLLMs, we use the provided instruction template in Figure 1(a). After all the LLMs have responded to the statement, we manually identify the responses of each model and assign answers from (A) through (E). The results are displayed in Table 1.\nText Mining: We randomly select 50 examples for each of the five personality traits, and extract the first sentences to make LLMs to continue the writing. Then, we use PsyAtten as classifier to detect the personality from the text. We retrain PsyAtten model based on their paper, all parameters setting and the train-test splits are same as those in their paper. The results are shown in Table 8 and Table 2. We also try using ChatGPT and Llama3, but the performances are not better than that of PsyAtten; we report those findings in the Appendix.\nFinally, we transformed the results of text mining based on the scores of the questionnaire to"}, {"title": "4.4 Results and Analysis", "content": "Questionnaire: Table 1 shows the results of LLMs' personality analysis on MPI120 dataset. All results are obtained using English questionnaires, except for GLM and ChatGLM6b, which use Chinese. The \"human\" score and are calculated based on the analysis of 619,150 responses on the IPIP-NEO-120 inventory (The sample is the same internet sample studied in Johnson (2005), which contains 23,994 individuals (8764male, 15,229 female, 1 unknown, ages ranged from 10 to 99, with a mean age of 26.2 and SD of 10.8 years )). It is worth noting that, similar to human personality assessments, the scores here only partially indicate whether the model possesses a certain trait (equivalent to 3 in human testing when a certain threshold is exceeded). Additionally, a high or low score does not necessarily reflect the model's strength or weakness in that trait. The results of GLM and LLaMA are not presented due to their failure to generate appropriate answers, regardless of the prompt design. These models simply repeat the prompt, even when few-shot methods are employed. The scores with a value of more than 3 (thresholds for human questionnaire scores) are underlined.\nIn the results of PLMs, Flan-T5 exhibits the smallest mean absolute error, while GLM4 scores closest to the average human scores and achieves scores above 3 on all four \"OCEA\" traits, similar to those of humans. LLaMA3 closely follows these models. These results suggest that the psychological performance of these models is comparable to the human average, likely due to the broad distribution of pre-training data used by both models. In contrast, ERNIE exhibits the largest mean absolute error among the models, which we believe is due to ERNIE's reliance on a large amount of Chinese datasets, potentially introducing biases in psychological cognition.\nIn the results of ChatLLMs, LLaMA3-Chat exhibits the smallest mean absolute error, while GPT40 scores closest to the average human scores and achieves scores above 3 on all four OCEA traits, similar to those of humans. Additionally, the \u03c3 of GPT40 is also small, suggesting that GPT40 is the closest to the average human score. The performance of LLaMA3-Chat, GLM4-Chat, and ChatGPT is also similar to that of humans, except in the 'N' trait. We can also find that, GPT40 and BLOOMZ achieve the same traits with human, while GLM4-Chat, LLaMA3-Chat and ChatGPT achieve all five traits.\nComparing the results of PLMs and ChatLLMs, we can find that all the scores of PLMs are lower than the corresponding ChatLLMs. The ChatLLMs do not change the personality traits that the PLMs already exhibited, they only extend the traits. And, we can find that, even the same trait, the score of ChatLLMs is also higher than that of PLMs. In terms of the mean absolute error \"d\", almost every ChatLLM are lower than the corresponding PLM, which suggests that human preference alignment can indeed bring LLMs closer to average human scores.\nText Mining: Table 2 shows the results of text mining after formula 2. The original results are shown in Table 8. The Slef-alpaca model in Table 2 is the model we trained based on Stanford University's Alpaca without any personality knowledge. We follow the research process of Stanford University's Alpaca and perform full-parameter fine-tuning on LLaMA-7b using the instruction-based data provided by Alpaca. To avoid the influence of personality knowledge in the instruction training data, we manually filter the data related to emotions, mood, and self-awareness, resulting in a final set of 31k instructions. We train a new model using the same parameter settings as those of Aplaca, details are described in the Appendix 6.3.\nWe can find that LLaMA3 in PLMs and LLaMA3-chat in ChatLLMs obtain the closest score to the average of human scores, while GPT-4o achieves the closest standard deviation to that of humans.\nIn the results of PLMs, only LLaMA3 exhibits a personality tendency towards 'CEAN,' while LLaMA, GPT-NEO, and GLM4 only achieve 'C E.' It is worth noting that LLaMA3 does not share the same personality traits as LLaMA; LLaMA3 has two additional traits, 'A N,' that LLaMA lacks. However, LLaMA3 retains the characteristics that LLaMA already exhibits. Additionally, it can be observed that LLaMA3 scores higher on each trait than LLaMA, which suggests that more training data can enhance the model's ability to express personality. Since the model structure of LLaMA is very similar, this would seem to support the importance of data in shaping model personality.\nIn the results of ChatLLMs, the personality of GPT-40 differs from that of ChatGPT; GPT-40 does not exhibit the 'E A' traits, which we believe may be due to differences in human preference alignment. The personality of Self-alpaca also differs from that of Alpaca; Self-alpaca does not exhibit the 'E A' traits because we filtered the training data related to emotions, mood, and self-awareness. Additionally, we observe that the scores of Self-Alpaca are lower than those of Alpaca.\nComparing the results of PLMs and ChatLLMs, we find that the scores of PLMs are consistently lower than those of the corresponding ChatLLMs. Additionally, all the ChatLLMs do not alter the personality traits exhibited by the PLMs; instead, they extend these traits, as observed in the results of the questionnaires. The results of LLaMA and LLaMA3 demonstrate that training data can influence the personality of a model. From the results of LLaMA, Alpaca, and Self-Alpaca, we observe that instruction data fine-tuning tends to make the"}, {"title": "4.5 The Reliability of Text Mining", "content": "To demonstrate that our method can reduce the impact of hallucinations, we performed an error analysis on the results of ten experiments. The dataset was randomly re-sampled for each experiment, and the results were averaged over ten experiments. Some of the experimental results are shown in Table 4. As we can see, the variance of every model is very little, this indicates that the scores obtained by our method are stable no matter how they are sampled. And the results demonstrate at least 80% consistency, which proven that our text mining method can avoid the influence of hallucinations."}, {"title": "5 Conclusion", "content": "In this paper, we investigate the presence of personality traits in LLMs. We apply the Big Five model as a psychological framework and analyze LLMs using both questionnaires and text mining methods. Our experimental results confirm that LLMs do exhibit specific personality traits, and that the personality knowledge in ChatLLMs originates from their base models. Unless modified through explicit instruction, such data encourages the model to generate text reflecting these personality traits more vividly. Furthermore, we identify the inherent personality traits in LLMs such as ChatGPT and BLOOMZ, without any induced prompt. Our experiments demonstrate that the personality of ChatGPT mose closely aligns with the average human profile, followed by ChatGLM. To the best of"}, {"title": "Limitations", "content": "Due to computational resource constraints, this paper does not experimentally validate the model for other large number of parameters. In addition, the selection of scores of 1, 3, and 5 in the Text mining method is relatively subjective."}, {"title": "Ethics Statement", "content": "All work in this paper adheres to the ACL Code of Ethics. The human statistics we obtained are anonymised data that do not contain any personal information."}, {"title": "6 Appendix", "content": "The process of the two methods is shown in Figure 1. As we can see, for questionnaire, we design special prompts, for ChatLLMs, the prompt is Question: Given a statement of you:\"You {STATEMENT}. Please choose from the following options to identify how accurately this statement describes you. Options: (A).Very Accurate (B).Moderately Accurate (C).Neither Accurate Nor Inaccurate (D).Moderately Inaccurate (E). Very Inaccurate Answer: \"\nFor PLMs, we use few-shot prompt, \" Question: Given a statement of you: You feel happy. Please choose from the following options to identify how accurately this statement describes you. Options: (A).Very Accurate (B).Moderately Accurate (C).Neither Accurate Nor Inaccurate (D).Moderately Inaccurate (E).Very Inaccurate. your answer is (A). Question: Given a statement of you: You feel happy. Please choose from the following options to identify how accurately this statement describes you. Options: (A).Very Accurate (B).Moderately Accurate (C).Neither Accurate Nor Inaccurate (D).Moderately Inaccurate (E).Very Inaccurate. your answer is (E). Question: Given a statement of you: You feel happy. Please choose from the following options to identify how accurately this statement describes you. Options: (A).Very Accurate (B).Moderately Accurate (C).Neither Accurate Nor Inaccurate (D).Moderately Inaccurate (E). Very Inaccurate. your answer is (C). Question: Given a statement of you: You Please choose from the following options to identify how accurately this statement describes you. Options: (A).Very Accurate (B).Moderately Accurate (C).Neither Accurate Nor"}, {"title": "6.2 Reasons for Choosing PsyAtten", "content": "We test the accuracy of ChatGPT, LLaMA3 and PsyAtten on the Big Five personality classification dataset (Pennebaker and King, 1999). The results are showed in Table 5.\nWe randomly select 20% of the data from the dataset as test data, and use the remaining data as training data for PsyAtten and LLaMA3. For ChatGPT, we simply call the API. In the case of ChatGPT, the seed is set to 42, the temperature to 0.2, and the model used is 'gpt-3.5-turbo-16k'. The prompt used to test is as follows: \"Determine from your knowledge what the Big Five personality trait is in the following sentence by answering in the format \\\"O:1, C:0, E:1, A:1, N:1\\\", where 1 means that thoes sentences have this personality trait and 0 means that thoes sentences don't, and if you're not sure please answer 2, being careful not to include other outputs If you are not sure whether you have this personality trait or not, please answer 2, taking care not to include other outputs. Here are the sentences you need to judge: [Sentences]\\\". The \"[Sentences]\" is been replaced by the content generated by tested models. For LLaMA3, we use LLaMA3-8B and fine-tune all the parameters with 10 A100 80G GPUs, based on the transformers package. The random seed is 42, the learning rate is 2e-5, the number of epochs is 10, the batch size is 16, and the maximum length is to 2048. For PsyAtten, we use the same settings as proposed by the author in their paper.\nSince PsyAtten obtain the best results compared with ChatGPT and LLaMA3, we choose it as the predictor for text mining method."}, {"title": "6.3 Training of Self-alpaca", "content": "Following the work of the Stanford team, we obtained Self-alpaca by fine-tuning the full parameters of LLaMA-7b using the instruction-based data provided by Alpaca. We manually filtered out data related to emotions, mood, and self-awareness. The batch size is set at 128, the learning rate at 3e-4, the maximum length at 2048, and we fine-tuned the model for 10 epochs."}, {"title": "6.4 Analysis of Different LLMs", "content": "Figure 3 shows the scores of five models with an average absolute error of less than 0.5 on the Big Five personality traits. It can be observed that most models score high on \"Openness\" and \"Extraversion\", which is consistent with human expectations. The score distribution of ChatLLMs is nearly identical, while the scores of the PLMs, T5, differ significantly from those of other models. These findings demonstrate that training models using directive data leads to a convergence towards similar personalities."}, {"title": "6.5 Statistics of Questionnaire and Text Mining", "content": "Questionnaire: In order to prevent large models from evading questions by frequently responding with \"C: Neither Accurate and Nor Inaccurate,\" we conducte a statistical analysis on the distribution of their answers. Table 7 presents the statistical results for the \"O, C, E\" features. To validate the reasonableness of the answer distribution, we utilized responses from ten million individuals in the Big Five personality Test dataset 6 as the benchmark. The \"Human\" indicates the percentage of each option derived from the aforementioned dataset.\nFrom the Table 7, it's evident that the proportion of option C in the responses from the LLMs is relatively low. With the exception of \"BLOOM\", \"ChatGPT\", and \"Alpaca7b-en\", all other models have proportions of option C that are lower than those in human responses. This suggests that the models' responses to the questionnaire are effective.\nText Mining: In the text mining section, we utilize classifiers to determine the personality of content generated by models. Therefore, if the generated content is relatively short, it will impact the classifier's ability to make accurate judgments. Hence, we conduct a statistical analysis on the length of generated content. Table 6 shows the reuslt. As you can see, apart from FLAN-T5, the lengths of content generated by other models all exceed 100 words, with the majority surpassing 300 words. Consequently, we consider this content to be effective as well."}, {"title": "6.6 Original Results of Text Mining", "content": "We can find that the text generated by BLOOM and FLAN-T5 contains fewer personality traits, which can be attributed to the brevity of the generated texts. The predictor cannot determine their personality from such short texts. From Table 8, we can find that the number of texts containing personality features generated by ChatLLMs is higher than that of PLMs. But the P value is almost identical, with a mean difference of 0.04 between LLaMA and Alpaca, 0.02 between LLaMA and Self-alpaca, and 0.04 between ChatGPT and GPT-NEO. We believe this strongly indicates that the personalities of ChatLLMs are consistent with their base PLMs, and that instruction data fine-tuning enables the model to express personality traits more readily."}, {"title": "6.7 Detailed Results of Section 4.5", "content": "We will report all the results of the reliability of text mining in Table 9. As we can see, in all 65 instances of single personality trait detection, only 25% (16 instances) do not fully coincide with the expected results. However, even in the least coinciding cases, the method still achieves 80% accuracy. We believe the results can prove that our method can avoid the influence of hallucination."}, {"title": "6.8 Results of ChatGPT in Text Mining", "content": "Although ChatGPT shows poor performance on the Big Five personality classification dataset, we also use it as a predictor to detect the personality of texts generated in text mining method. Additionally, we compared the results with that of questionnaire. The results are shown in Table 10, Table 11, and Table 12."}, {"title": "6.9 Potential Applications", "content": "In this paper, we find that the personality knowledge in ChatLLMs originates from their base models, and instruction data fine-tuning tends to make the models show more personality. We think this conclusion can help us learn about LLMs and determine the personality of LLMs by controlling their pre-trained data. Additionally, we can design special instruction data to expose the hidden personality traits of LLMs. All of this can help humans train more suitable LLMs."}]}