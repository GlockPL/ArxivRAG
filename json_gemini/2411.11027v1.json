{"title": "BianCang: A Traditional Chinese Medicine Large Language Model", "authors": ["Sibo Wei", "Xueping Peng", "Yi-fei Wang", "JiaSheng Si", "Weiyu Zhang", "Wenpeng Lu", "Xiaoming Wu", "Yinglong Wang"], "abstract": "The rise of large language models (LLMs) has driven significant progress in medical applications, including traditional Chinese medicine (TCM). However, current medical LLMs struggle with TCM diagnosis and syndrome differentiation due to substantial differences between TCM and modern medical theory, and the scarcity of specialized, high-quality corpora. This paper addresses these challenges by proposing BianCang (\u6241\u4ed3), a TCM-specific LLM, using a two-stage training process that first injects domain-specific knowledge and then aligns it through targeted stimulation. To enhance diagnostic and differentiation capabilities, we constructed pre-training corpora, instruction-aligned datasets based on real hospital records, and the ChP-TCM dataset derived from the Pharmacopoeia of the People's Republic of China. We compiled extensive TCM and medical corpora for continuous pre-training and supervised fine-tuning, building a comprehensive dataset to refine the model's understanding of TCM. Evaluations across 11 test sets involving 29 models and 4 tasks demonstrate the effectiveness of BianCang, offering valuable insights for future research. Code, datasets, and models are available at https://github.com/QLU-NLP/BianCang.", "sections": [{"title": "1 Introduction", "content": "Recently, LLMs have achieved remarkable success in natural language processing (Zhao et al., 2023). General-purpose models such as GPT-4 (Achiam et al., 2023), Qwen2 (Yang et al., 2024a), and Baichuan2 (Yang et al., 2023) have demonstrated impressive capabilities across diverse tasks. Building on these models, researchers have effectively applied LLMs to specialized domains such as healthcare (He et al., 2023), law (Yue et al., 2023), and finance (Chen et al., 2023b), often at relatively low cost. Among these fields, healthcare, stands out due to its critical role in safeguarding human health and extending life, making it a focal point of extensive research and practical applications.\nThe complexity and specialization of knowledge in the biomedical field place higher demands on the domain expertise of LLMs (He et al., 2023). To address this challenge, secondary training on general-purpose LLMs is often required. Researchers typically focus on optimizing the training methods and improving the quality of training data to enhance the effectiveness of this process. From the perspective of optimizing training methods, Zhang et al. introduced reinforcement learning from mixed feedback (RLMF) to integrate data from various sources, resulting in the development of HuatuoGPT1 (Zhang et al., 2023a). Chen et al. proposed a training method combining pre-training and supervised fine-tuning into a single stage, simplifying the process and leading to HuatuoGPT2 (Chen et al., 2023a). To improve the quality of training data, Bao et al. employed diverse strategies to construct the DISC-Med-SFT dataset, which enhanced the responsiveness of medical LLMs in both single-round and multi-round consultation scenarios, resulting in DISC-MedLLM (Bao et al., 2023). Luo et al. developed a multi-task bilingual Chinese-English dataset to train the Taiyi model (Luo et al., 2024a).\nThese medical LLMs perform well in modern medicine, but their performance in TCM is relatively unsatisfactory. The primary reason for this is the significant difference between TCM theory and modern medicine. TCM has a unique and complete theoretical foundation. Unlike modern medicine, which treats diseases based on their types, TCM determines the patient's syndrome type by analyzing the evidence collected through the \"four diagnostic methods\u201d (\u671b\u95fb\u95ee\u5207: inspection, listening and smelling, inquiry, and palpation). Treatment is then administered based on the syndrome type. As a result, patients with the same disease and different syndrome types may receive different treatments, while patients with different diseases and the same syndrome type may receive the same treatment. This approach, known as \"treating the same disease with different therapies\u201d (\u540c\u75c5\u5f02\u6cbb) and \u201ctreating different diseases with the same therapy\u201d (\u5f02\u75c5\u540c\u6cbb), is central to TCM (Mucheng et al., 2022).\nAs shown in Fig. 1, for the same patient, modern medicine uses medical instruments to measure the T-wave (related to changes in the electrocardiogram) and diagnoses the patient based on the specific value changes and trends of the T-wave. In contrast, TCM maps the patient's described symptoms and the evidence gathered from the four diagnostic methods into a unique Yin-Yang (\u9634-\u9633) coordinate system, analyzes the underlying causes, and synthesizes these findings to determine the patient's syndrome type. Compared to modern medicine, which relies on measurable data from instruments, TCM is more abstract, experience-based, and harder to explain (Mucheng et al., 2022). Facing the complexity of TCM tasks and the limitations of LLMs, Zhang et al. trained Qibo using a specialized TCM corpus and explored applying Qibo to TCM consultations (Zhang et al., 2024). Yang et al. trained Zhongjing using a self-built dataset of authentic doctor-patient dialogues, aiming to improve the LLM's ability to conduct proactive inquiries and understand multi-round consultations in TCM (Yang et al., 2024b). Hua et al. focused on enhancing the model's grasp of TCM and pharmacology, training Lingdan (Hua et al., 2024). While these TCM-specific LLMs have made some progress, their ability to differentiate and diagnose syndromes in TCM remains limited, particularly in real diagnostic scenarios where practical syndrome differentiation and diagnostic analysis skills are required.\nTo address the aforementioned challenges and further enhance the comprehensive capabilities of TCM-focused LLMs, we propose BianCang (\u6241\u4ed3), a large TCM language model based on Qwen-2/2.5, designed to improve syndrome differentiation and diagnostic capabilities in TCM. BianCang adopts a two-stage training process: in the first stage, extensive traditional Chinese medicine and medical knowledge is injected through continuous pre-training of the foundational model; in the second stage, supervised fine-tuning is applied to activate and align the model's internal knowledge. We evaluated BianCang on 11 test sets across 4 tasks, and the results show that it consistently outperforms existing open-source TCM-specific and Chinese medical language models in all dimensions of capability.\nOur main contributions are summarized as follows:\n\u2022 We developed BianCang, a novel TCM LLM, through a two-stage training process tailored to TCM characteristics. The model has acquired extensive TCM knowledge and real clinical case expertise, demonstrating genuine syndrome differentiation and diagnostic capabilities.\n\u2022 We constructed and open-sourced the ChP-TCM dataset, based on the Pharmacopoeia of the People's Republic of China, designed for pre-training and supervised fine-tuning of TCM models."}, {"title": "2 Related Work", "content": "2.1 LLMs in Chinese Medical Domain\nAmong the existing Chinese medical LLMs, some works are based on open-source foundation models, which are then fine-tuned on self-constructed medical datasets. Examples include DoctorGLM (Xiong et al., 2023) and BenTsao (Wang et al., 2023). To further enhance the capabilities of medical LLMs, researchers have explored optimizing training methods from various perspectives. For instance, Zhang et al. introduced RLMF (Reinforcement Learning from Mixed Feedback) in their training process to coordinate both ChatGPT-extracted data and real-world data from doctors, resulting in HuatuoGPT1 (Zhang et al., 2023a). Chen et al., aiming to reduce the complexity of multi-stage training strategies, proposed a one-stage domain adaptation protocol where heterogeneous data from both traditional pre-training and supervised stages are unified into a simple instruction-output pair format, which they used to train HuatuoGPT2 (Chen et al., 2023a). Tian et al. developed ChiMedGPT, following a process that included pre-training, supervised fine-tuning (SFT), and reinforcement learning from human feedback (RLHF) (Tian et al., 2024). Other researchers have attempted to improve the quality of training data. For example, Bao et al. constructed a high-quality SFT dataset using three strategies: utilizing medical knowledge graphs, reconstructing real-world dialogues, and incorporating human-guided preference rephrasing, significantly enhancing the model's response capabilities in both single-turn and multi-turn consultation scenarios (Bao et al., 2023). Luo et al. built a rich, multi-task bilingual dataset in both Chinese and English and trained the Taiyi model (Luo et al., 2024a). Although these medical LLMs have achieved considerable success in modern medicine, their performance in the TCM domain is significantly lacking.\n2.2 LLMs in TCM Domain\nPrevious Chinese medical LLMs have mostly focused on modern medical systems. Unlike modern medicine, TCM emphasizes a holistic view and individualized treatment, focusing on balancing Yin-Yang, harmonizing Qi (\u6c14) and blood (\u8840), and coordinating the internal organs. TCM diagnoses are conducted through the four diagnostic methods (inspection, listening/smelling, inquiry, and palpation) to understand the patient's overall conditions (Mucheng et al., 2022). The theoretical foundation of syndrome differentiation and disease diagnosis in TCM is unique and fundamentally different from modern medicine. Existing medical LLMs are unable to grasp the principles of TCM, resulting in unsatisfied performance.\nSome studies have specifically aimed at improving the capabilities of LLMs in TCM. For example, Zhang et al. built a TCM-specific corpus and trained the Qibo model, which was applied to the pipeline of TCM consultations (Zhang et al., 2024). Yang et al. constructed a real-world, multi-turn Chinese medical dialogue dataset, CMtMedQA, and trained the Zhongjing model using continuous pre-training, SFT, and RLHF, which enhanced the model's ability in active inquiry and multi-turn understanding within the context of TCM (Yang et al., 2024b). Hua et al. focused on traditional Chinese medicine, constructing datasets for TCM pre-training, traditional Chinese patent medicine (TCPM) Q&A, and the spleen and stomach herbal prescription recommendation, and used these datasets to train the Lingdan model (Hua et al., 2024). Although these efforts have made significant progress in TCM LLMs, these models still lack real-world diagnostic experience in TCM and perform poorly on real-world syndrome differentiation and disease diagnosis tasks.\nTo address the aforementioned challenges, we propose BianCang, a novel TCM LLM based on Qwen2/2.5. BianCang first undergoes continuous pre-training to inject large amounts of TCM and medical knowledge, as well as real medical records, into the model. It is then fine-tuned using a carefully curated set of TCM-specific instructions to activate the model's internal knowledge and align these instructions with the model's internal knowledge. This training strategy ensures consistency in the model's knowledge before and after SFT, significantly improving its performance"}, {"title": "3 Methods", "content": "This section introduces the construction of BianCang, which consists of two stages: continuous pre-training and supervised fine-tuning. The overall process is shown in Fig. 2.\n3.1 Continuous Pre-training\nSFT is a key stage in building large language models. Recent research has found that SFT is not a process of learning world knowledge specific to a domain, but rather a process of aligning instructions with the knowledge already embedded in the parameters of LLMs (Ren et al., 2024). In order to maintain consistency in the model's knowledge before and after SFT as much as possible, we first perform continuous pre-training on the base model to inject extensive knowledge of traditional Chinese medicine and healthcare (Zhou et al., 2023). Books are the crystallization of human wisdom and serve as high-quality data for training large language models (Gunasekar et al., 2023). We collected a vast amount of TCM and medical books and processed them through OCR, cleaning, and segmentation. Similarly, we also collected open-source medical encyclopedias and literature (Chen et al., 2023a). To further enhance the model's knowledge of TCM, we incorporated more specialized TCM corpora into the pre-training data, including the Pharmacopoeia of the People's Republic of China (Part I: Traditional Chinese Medicine) and common TCM syndrome knowledge bases, which we scraped and cleaned using web crawlers, as well as the ChatMed-TCM dataset (Wei et al., 2023). For TCM, relying solely on theoretical knowledge is insufficient; practical diagnostic experience is also required. Therefore, we included 12,259 real patient case records and 56,928 real TCM syndrome differentiation and diagnosis records in the pre-training stage. Additionally, to improve the model's performance in TCM and medical-related exams, we introduced the training set from the Chinese Medical Benchmark (CMB) (Wang et al., 2024).\nBesides TCM and medical corpora, we also incorporated general domain corpora into the pre-training data to prevent the model from overfocusing on special domains, which could lead to catastrophic forgetting in general domains. Among them, COIG-CQIA is a high-quality, multi-domain instruction fine-tuning dataset aligned with human interaction behaviors (Bai et al., 2024). APE-210K is a diverse collection of mathematical word problems (Zhao et al., 2020). Evol-Instruction-66K is a filtered and curated dataset for code generation (Luo et al., 2024b). We concatenated the instructions and responses from these three datasets as the pre-training data. Notably, all three general-domain datasets exhibit a certain level of logical reasoning, which we speculate could benefit tasks such as TCM syndrome differentiation, as it also requires logical reasoning skills.\n3.2 Supervised Fine-Tuning (SFT)\nSFT is the core stage for applying the large language model of TCM to real-world scenarios, and the key phase in enabling the model's conversational abilities. The quality and diversity of the instruction data are crucial to the SFT process (Touvron et al., 2023). To maximize the activation of the knowledge embedded in the pre-trained model and align it with downstream real-world TCM tasks, we constructed a high-quality and diverse instruction dataset, which contains the following five types of data:\nTCM Pharmacopoeia Data: Based on the Pharmacopoeia of the People's Republic of China (Part I: Traditional Chinese Medicine), we constructed the ChP-KnowledgeQA and ChP-PrescriptionWriting instruction sets to enhance the model's TCM knowledge and question-answering abilities. The ChP-KnowledgeQA set consists of question-answer pairs covering topics such as the properties, identification, processing, taste, meridian tropism, functions, indications, dosage, and storage methods of TCM herbs and medicinal materials. The ChP-PrescriptionWriting set consists of question-answer pairs focused on composing and formulating TCM prescriptions. When constructing these two instruction sets, we manually created several query templates to ensure the diversity of the instructions. These two datasets are referred to as the ChP-TCM dataset.\nMedical Record Data: Based on real hospital records, we constructed the TCMSD-DD-SFT, TCM-WM-Diff-SFT, and TCM-Plan-SFT instruction sets to improve the model's performance on real-world tasks such as syndrome differentiation and disease diagnosis in TCM. The TCMSD-DD-SFT set is designed for TCM syndrome and disease differentiation, aiming to analyze a patient's condition and syndrome type based on their chief complaint, admission details, medical history, and information gathered through TCM's \"Four Diagnoses\" (inspection, listening and smelling, inquiry, and palpation). The TCM-WM-DiffDiag-SFT set includes differential diagnoses in both TCM and western medicine (WM) based on real hospital records. The TCM-Plan-SFT set focuses on providing detailed treatment plans based on a patient's basic condition and diagnosis results. To construct these instruction sets, we manually created a variety of inquiry and response templates, and then employed a weighted random selection approach to generate instruction data from these templates, enhancing the quality and diversity of the instruction sets.\nMulti-turn Dialogue Data: To equip the model with conversational capabilities in the medical field, we utilized the DISC-Med-SFT dataset (Bao et al., 2023). DISC-Med-SFT is a high-quality SFT dataset containing a large number of samples that were reconstructed from existing medical datasets. These data help the model learn medical knowledge, align its behavior with human preferences, and adapt to the distribution of real-world online medical dialogues.\nExam Data: The MLEC-QA dataset is a large-scale Chinese biomedical multiple-choice question-answering dataset (Li et al., 2021), sourced from the Chinese Medical Licensing Examination. It covers five subfields: TCM, integrative medicine (combining TCM and Western medicine), clinical medicine, public health, and basic clinical medicine. Based on this dataset, we constructed the MLEC-SFT instruction set to enhance the model's comprehensive question-answering abilities in TCM and healthcare.\nGeneral Domain Data: To prevent the loss of the model's general capabilities, we mixed in some general domain data during the SFT process. MS-Agent-Bench\u00b9 is a general-purpose multi-domain SFT dataset, from which we randomly selected 65,000 samples. Self-Cognition is a custom instruction set we manually constructed to help the model develop self-awareness capabilities.\n3.3 Model Training\nWe train BianCang at two scales, with parameter sizes of 7 billion and 14 billion, based on Qwen2/2.5-7B and Qwen2.5-14B (Yang et al., 2024a), respectively. We employ full-parameter fine-tuning during both the continuous pre-training and supervised fine-tuning stages. We use Scalable lightWeight Infrastructure for Fine-Tuning (SWIFT) (Zhao et al., 2024) as the training framework.\nTo ensure training stability, we set the weight decay to 0.1 for 14B model and 0.01 for 7B model to prevent overfitting, the max gradient norm to 0.5 to prevent gradient explosion, and the warmup ratio to 0.05 for 14B model and 0.03 for 7B model to maintain smooth training. To balance training costs, we utilize parallel training, gradient checkpointing, fp16 precision, and gradient accumulation strategy, and limit the model's maximum response length to 4096 tokens. We reserve 5% of the training set for validation and use token-level accuracy to validate the model, saving the best checkpoint as the final model. Experiments are conducted on 8 A100 40G GPUs, with both continuous pre-training and supervised fine-tuning performed over two epochs. The loss across all training stages successfully converges to a valid range."}, {"title": "4 Experiments and Evaluation", "content": "4.1 Baselines\nTo comprehensively evaluate the performance of our model alongside existing models, we selected a series of LLMs with varying parameters as comparison baselines, including general, medical, and TCM-specific LLMs.\nGPT-4 (Achiam et al., 2023): GPT-4 is a large-scale, multimodal model developed by OpenAI. It has demonstrated human-level performance across various professional and academic benchmarks. We conduct tests using the API service provided by OpenAI, invoking the GPT-40 model.\nBianQue2-6B (Chen et al., 2023c): BianQue-6B is a ChatGLM-based (Du et al., 2022) LLM finetuned with the self-constructed health conversation dataset BianQueCorpus that is consist of multiple turns of questioning and health suggestions polished by ChatGPT. BianQue2-6B expands upon the previous version by incorporating data from pharmaceutical instruction guides, medical encyclopedia knowledge, and ChatGPT distillation instructions, enhancing the model's capabilities in providing recommendations and knowledge retrieval.\nDoctorGLM-6B (Xiong et al., 2023): A large-scale Chinese medical model based on ChatGLM-6B (Du et al., 2022), fine-tuning on a large amount of medical instruction dataset.\nBenTsao-Llama-7B (Wang et al., 2023): A Chinese medical LLM based on Chinese-LLaMA-7B (Cui et al., 2023), and fine-tuned on an 8K medical dialogue dataset.\nShenNong-TCM-LLM-7B (Wei et al., 2023): A large traditional Chinese medicine model based on Chinese-LLaMA-7B (Cui et al., 2023), fine-tuned on the self-constructed ChatMed-TCM dataset.\nTaiyi-7B (Luo et al., 2024a): A bilingual medical large language model designed for various biomedical tasks, trained on 140 Chinese and English biomedical datasets across 15 BioNLP tasks.\nWiNGPT22: A large language model developed by Weining Health for the medical domain, aimed at providing intelligent medical Q&A, diagnostic support, and medical knowledge services to improve the efficiency of diagnosis and the quality of healthcare services. WiNGPT2-7B-Base is based on Qwen-7B (Bai et al., 2023), while WiNGPT2-Llama3-8B-Base is based on LLaMA3-8B (Dubey et al., 2024).\nHuatuoGPT2 (Chen et al., 2023a): HuatuoGPT2 employs an innovative domain adaptation method to significantly boost its medical knowledge and dialogue proficiency. We utilized two models, HuatuoGPT2-7B and HuatuoGPT2-13B, which are based on Baichuan2-7B-Base and Baichuan2-13B-Base (Yang et al., 2023), respectively.\nSunsimiao-7B (Xin and Dong, 2023): A Chinese medical large language model based on Qwen2-7B (Yang et al., 2024a), fine-tuned on high-quality medical data. It has achieved excellent results in Chinese medical exams.\nQiZhen-CaMA-13B3: A Chinese medical large language model based on CaMA-13B (Zhang et al., 2023b), trained on the QiZhen medical knowledge base with a Chinese medical instruction set. It performs exceptionally well in Chinese medical scenarios.\nZhongjing-13B (Yang et al., 2024b): A Chinese medical large language model that has undergone end-to-end training, from pre-training to reinforcement learning. In certain dialogue scenarios, it approaches the professional level of expert doctors. Zhongjing-13B is based on Ziya-LLaMA-13B-v1 (Zhang et al., 2022), a general Chinese LLM with 13 billion parameters, trained based on LLaMA.\nChiMedGPT-13B (Tian et al., 2024): ChiMed-GPT is a Chinese medical large language model based on Ziya-LLaMA-13B-v2 (Zhang et al., 2022). It has undergone comprehensive pre-training, SFT, and RLHF.\nDISC-MedLLM-13B (Bao et al., 2023): A large language model specifically designed for medical and healthcare conversational scenarios. DISC-MedLLM-13B is based on Baichuan-13B-Base4 and trained on the DISC-Med-SFT multi-turn dialogue dataset.\nLingdan-13B (Hua et al., 2024): A traditional Chinese medicine (TCM) large language model based on Baichuan2-13B-Base (Yang et al., 2023), trained on a rich dataset including TCM ancient books, textbooks, and the Chinese Pharmacopoeia.\nGLM4 (GLM et al., 2024): GLM-4-9B is the open-source version of the latest generation of pre-trained models in the GLM-4 series launched by Zhipu AI.\nQwen2/2.5 (Yang et al., 2024a): Qwen2 is a series of open-source multilingual pre-trained and instruction-tuned models based on the Transformer architecture, developed by the Qwen Team. These models have achieved outstanding results across various benchmark evaluations. Qwen2.5 represents a significant upgrade over Qwen2, optimized to meet specific requirements.\n4.2 Evaluation\nWe conducted model evaluation from both objective and subjective perspectives. The objective evaluation includes three tasks: TCM syndrome differentiation, TCM disease diagnosis, and exams, covering ten datasets. The subjective evaluation task involves medical record analysis using BC-Analytical test set. The prompt templates used in the experiments can be found in the appendix.\n4.2.1 Objective Evaluation\nThe objective evaluation primarily tests the model's capabilities in three areas: TCM syndrome differentiation, TCM disease diagnosis, and mastery of TCM and medical knowledge.\nFor the TCM syndrome differentiation task, we used the TCMSD and TCMSD-BC test sets. The TCMSD test set was adapted from the test set of the TCM-SD dataset (Mucheng et al., 2022), where we constructed queries and responses using fields from the TCM-SD test set. The TCMSD-BC dataset was built based on proprietary medical records. The TCM syndrome differentiation task is divided into two test modes: direct inference (DI) and chain of thought (CoT), with accuracy serving as the evaluation metric.\nFor the TCM disease diagnosis task, we used the TCMDD and TCMDD-BC test sets. Similarly, the TCMDD test set was adapted from the test set of the TCM-SD dataset (Mucheng et al., 2022), while the TCMDD-BC dataset was constructed based on proprietary medical records. Like the syndrome differentiation task, the disease diagnosis task is evaluated using two test modes: DI and CoT, with accuracy as the evaluation metric.\nTo assess the model's mastery of TCM and medical knowledge, we applied the MLEC-QA (Li et al., 2021) and Chinese Medical Benchmark (CMB) (Wang et al., 2024) test sets. The MLEC-QA test set is divided into five subsets: traditional Chinese medicine, traditional Chinese medicine combined with western medicine, clinic, public health, and stomatology. The CMB dataset is a comprehensive medical benchmark that includes six categories: physician exam, nursing exam, pharmacist exam, medical technician exam, professional knowledge exam, and medical postgraduate entrance exam. The average score across these six categories is used as the final result. The examination tasks are evaluated in two test modes: zero-shot and few-shot, with accuracy as the evaluation metric.\n4.2.2 Subjective Evaluation\nWe used the BC-Analytical test set for the subjective evaluation of the model. The BC-Analytical dataset, which we constructed using proprietary medical records, includes 50 complex TCM cases. Each case is accompanied by three questions: disease diagnosis and syndrome differentiation analysis, differential diagnosis, and treatment plan formulation. We evaluate the model from three dimensions: professionalism, fluency, and safety, using win rate, tie rate, and loss rate as the evaluation metrics. All evaluations are conducted by hospital physicians. Following prior research (Yang et al., 2024b), we redefined the evaluation criteria for professionalism, fluency and safety. The specific evaluation standards are as follows:\nProfessionalism: (1) Must have an accurate understanding of the problems and needs from doctors or patients in order to provide relevant responses and advice; (2) must correctly predict the patient's disease or syndrome and provide supporting rationale when providing diagnostic support; (3) must correctly interpret the medical knowledge involved.\nFluency: (1) Answers must be semantically coherent and free of logical errors or irrelevant information; (2) the style and content of answers must be consistent and free of conflicting information; (3) responses must remain friendly and welcoming; cold or overly brief language is unacceptable.\nSafety: (1) Must provide scientifically accurate medical knowledge, especially in cases of disease diagnosis, medication recommendations, etc.; (2) must admit ignorance of unknown knowledge; (3) must ensure patient safety; (4) must refuse to answer information or advice that could cause harm; (5) must comply with medical ethics while respecting patient choice and refuse to answer if violated.\n4.3 Results\n4.3.1 Objective Evaluation Results\nThe objective evaluation results in the field of traditional Chinese medicine (TCM) are shown in Table 3. According to the table, BianCang achieved outstanding performance across three TCM tasks: syndrome differentiation, disease diagnosis, and TCM exam. In all cases, it outperformed the baseline models. Below, we summarize our main observations and conclusions from these experimental results:\nMost previous large TCM and medical models lacked the analytic capabilities for syndrome differentiation and disease diagnosis in TCM. We identify three main reasons for this limitation: (1) The foundational models of some early models were relatively weak, resulting in insufficient fundamental capabilities; (2) The TCM tasks require systematic knowledge reserves and extensive diagnostic experience, which most previous models lacked due to limited guidance from real-world TCM syndrome differentiation and disease diagnosis experience; (3) Although prior models utilized continuous pre-training and supervised fine-tuning, they did not fully leverage the characteristics of each stage, resulting in an inconsistency between the fine-tuning instructions and the model's internal knowledge.\nOur model possesses strong analytical capabilities for both syndrome differentiation and disease diagnosis. For instance, BianCang-Qwen2.5-7B-Instruct achieved an accuracy of 78.90% on the TCMSD test set in direct inference (DI) mode, reflecting an improvement of approximately 48 percentage points over the foundational model Qwen2.5-7B, and about 47 percentage points over the previously best-performing TCM model, Lingdan-13B. In the chain-of-thought (CoT) reasoning mode, BianCang-Qwen2.5-7B-Instruct achieved further improvement, reaching an accuracy of 82.10% on the TCMSD test set, about 61 percentage points higher than the foundational model Qwen2.5-7B and around 48 percentage points above the previously best-performing TCM model, Huatuo2-7B. Similarly, BianCang-Qwen2.5-7B-Instruct also achieved significant improvements on the TCMSD-BC, TCMDD, and TCMDD-BC test sets.\nMoreover, our model achieved optimal results in both TCM and TCM combined with western medicine exams, indicating that it has mastered a more comprehensive and systematic TCM knowledge base. These experimental results verify the effectiveness of our selected foundational model, data formulation, and training strategy within the TCM domain.\nThe objective evaluation results for the Chinese medical exams are shown in Table 4. As indicated in Table 4, BianCang not only performed exceptionally well in the field of TCM but also demonstrated remarkable performance in modern medicine, surpassing all baseline models. This indicates that our data formulation and training strategy have enhanced the model's capabilities in both TCM and modern medicine.\n4.3.2 Subjective Evaluation Results\nFor the subjective evaluation, we selected four models with strong overall performance in objective evaluation as baselines to reduce human evaluation costs. The subjective evaluation results of TCM case analysis are shown in Figure 3. The results indicate that our model demonstrates a higher level of professionalism in analyzing real TCM cases, which is largely due to its well-developed TCM knowledge system and authentic diagnostic experience. In terms of fluency, our model can generate more authentic, TCM-styled outputs, surpassing most baseline models. In terms of safety, such as in diagnostic or medication recommendation scenarios, our model consistently outperformed the baseline models. Overall, our model's responses received greater approval from TCM experts.\n4.4 Effectiveness of Two-stage Training Strategy\nWe conducted a set of comparative experiments to illustrate the necessity and effectiveness of the two-stage training strategy. The experimental results are shown in Table 5. \"Vanilla\" refers to the foundational model. \u201cOne Stage\" represents directly applying supervised fine-tuning (SFT) to the model using an instruction set tailored for TCM downstream tasks. \u201cTwo Stage\" represents first injecting knowledge through continuous pre-training and then applying supervised fine-tuning on downstream tasks to maximize consistency between the instructions and the model's internal knowledge during fine-tuning. The SFT data and training parameter settings used in both One Stage and Two Stage are entirely consistent.\nThe experimental results indicate that our two-stage training strategy is highly effective when the foundational model itself lacks sufficient knowledge. Taking the TCM syndrome differentiation task as an example, we observe that the foundational model performs poorly on this task, highlighting its lack of TCM-specific knowledge in syndrome differentiation. In such cases, directly applying SFT to the base model may result in limited performance gains due to inconsistencies between the instructions and the model's internal parameter knowledge. In contrast, with the two-stage training strategy, the consistency between the instructions and the model's internal parameter knowledge is enhanced, leading to a substantial improvement in the model's performance on the TCM syndrome differentiation task. This improvement is especially significant in chain-of-thought scenarios, where effective reasoning depends on the model's foundational knowledge."}, {"title": "5 Conclusion and Limitations", "content": "In this work, we introduce BianCang, a large language model specifically designed for traditional Chinese medicine (TCM), to address challenges unique to TCM large language models. We constructed a comprehensive pre-training corpus and a diverse set of supervised fine-tuning instructions, employing a two-stage training strategy to train BianCang that first injects domain-specific knowledge and then aligns it through targeted stimulation. Experimental results robustly demonstrate the effectiveness and superiority of BianCang. Despite these achievements, it is important to emphasize that BianCang is primarily an auxiliary research tool, not a substitute for professional TCM consultation. We recognize the limitations of the model. BianCang cannot guarantee accuracy in all its responses. Due to the serious consequences that can arise from inaccurate data in medical domain, we strongly suggest that users exercise caution when dealing with generated information and seek advice from experts."}]}