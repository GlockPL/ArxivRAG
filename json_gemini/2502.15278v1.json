{"title": "CopyJudge: Automated Copyright Infringement Identification and Mitigation in Text-to-Image Diffusion Models", "authors": ["Shunchang Liu", "Zhuan Shi", "Lingjuan Lyu", "Yaochu Jin", "Boi Faltings"], "abstract": "Assessing whether AI-generated images are substantially similar to copyrighted works is a crucial step in resolving copyright disputes. In this paper, we propose CopyJudge, an automated copyright infringement identification framework that leverages large vision-language models (LVLMs) to simulate practical court processes for determining substantial similarity between copyrighted images and those generated by text-to-image diffusion models. Specifically, we employ an abstraction-filtration-comparison test framework with multi-LVLM debate to assess the likelihood of infringement and provide detailed judgment rationales. Based on the judgments, we further introduce a general LVLM-based mitigation strategy that automatically optimizes infringing prompts by avoiding sensitive expressions while preserving the non-infringing content. Besides, our approach can be enhanced by exploring non-infringing noise vectors within the diffusion latent space via reinforcement learning, even without modifying the original prompts. Experimental results show that our identification method achieves comparable state-of-the-art performance, while offering superior generalization and interpretability across various forms of infringement, and that our mitigation method could more effectively mitigate memorization and IP infringement without losing non-infringing expressions.", "sections": [{"title": "1. Introduction", "content": "Text-to-image generative models (Rombach et al., 2022; Betker et al., 2023; Team et al., 2023; Esser et al., 2024; Hurst et al., 2024; Zhang et al., 2023b;a; Hintersdorf et al., 2024) have transformed creative industries by producing detailed visuals from text prompts. However, these models have been found to sometimes memorize and reproduce content from their training data (Carlini et al., 2023; Somepalli et al., 2023a; Ren et al., 2024; Wang et al., 2024c; Shi et al., 2024b;a; Zhang et al., 2024). This raises significant concerns about copyright infringement, especially when the generated images closely resemble existing copyrighted works. According to U.S. law (rot, 1970), also referenced by most countries, a work can be considered infringing if it constitutes substantial similarity to another work. Therefore, determining whether AI-generated images infringe on copyright requires a clear and reliable method to compare them with copyrighted materials to identify substantial similarity.\nHowever, identifying substantial similarity is not a trivial task. There are already some methods to assess image similarity through distance-based metrics, e.g., L2 norm (Carlini et al., 2023). However, we found that these manually designed metrics do not always align with the human judgment for infringement determination. Additionally, it often suffer from insufficient generalization ability and lack interpretable results. This motivates the need for an approach that better measures substantial similarity, one that is more human-centered, interpretable, and generalized to handle copyright infringement identification in AI-generated images.\nRecently, large-scale models have already been successfully applied as judges in fields such as finance, education, and healthcare (Gu et al., 2024; Li et al., 2024; Zhuge et al., 2024). In this paper, we attempt to leverage large vision-language models (LVLMs) to model the practical court decisions on substantial similarity. However, directly applying large models for infringement identification may face unreliable outputs due to their limited comprehension or potential misinterpretation. To address this, we propose CopyJudge, an automated abstraction-filtration-comparison framework with multi-LVLM debate to reliably follow the court decision process on identifying substantial similarity.\nSpecifically, referring to the software abstraction test (Abramson, 2002), we decompose the image into different"}, {"title": "3. LVLM for Infringement Identification", "content": "Our goal is to determine whether an image infringes the copyright of a known copyrighted image. Based on U.S. law (rot, 1970) and similar laws in other countries, given an image x created with access to the copyrighted image xcr, if x and xcr exhibit substantial similarity, then x is deemed to infringe the copyright of xcr."}, {"title": "3.1. Problem Formulation", "content": "Motivated by this, we aim to establish a substantial similarity identification model f, which takes x and Xcr as inputs and outputs a similarity score s. When s exceeds a threshold \u03b3, we determine that x infringes on Xcr. This can be defined as:\nIsInfringement(x) = I(f(x, xcr) > \u03b3), (1)\nwhere x represents the AI-generated image, and xcr is the corresponding copyrighted image."}, {"title": "3.2. Abstraction-Filtering-Comparison Framework", "content": "For the process of identifying substantial similarity, we refer to the abstraction-filtering-comparison test method (Abramson, 2002), which has been widely adopted in practical court rulings on infringement cases, and propose an automated infringement identification framework using large vision-language models, as seen in Figure 1. In the copyright expression extraction stage, we break down images into different elements (such as composition and color patterns), and filter out non-copyrightable parts, leaving copyrighted portions to assess substantial similarity. In the next copyright infringement determination stage, multiple LVLMs debate and score the similarity of images given the copyrighted elements, with a final decision made by a meta-judge LVLM based on their consensus. Human priors are injected into the models through few-shot demonstrations to better align with human preferences.\nCopyright expression extraction via image-to-text abstraction and filtration. The process of distinguishing between the fundamental ideas and the specific expressions of an image is a crucial step in determining copyright protection. The core idea of our method is to break down the image into different layers or components, in order to examine the true copyright elements.\nFirst, during the abstraction phase, the image is analyzed and decomposed into its fundamental building blocks. This involves identifying the core elements that contribute to the overall meaning or aesthetic of the image, such as composition, themes, color palette, or other unique visual elements. We can implement this using an LVLM \\( \\pi_{abs} \\), defined as:\n\\( \\pi_{abs}(x, x_{cr}, p_{abs}) \\rightarrow (z, z_{cr}), \\)\nwhere z and zer represent the expressions of x and xcr in text after decoupling, respectively. The goal is to abstract away the superficial features of the image that do not hold significant creative value and instead focus on the underlying concepts that convey the essence of the work.\nThe next step is filtering. At this stage, elements of the image that are not eligible for copyright protection are removed from consideration. These can include generic concepts, common patterns, functional aspects, or elements derived from public domain sources. For example, standard design patterns or commonly used motifs in artwork may not be deemed original enough to warrant protection under copyright law. This process could be defined as:\n\\( \\pi_{fil}(z, z_{cr}, p_{fil}) \\rightarrow (z^c, z_{cr}^c), \\)\nwhere z\u00ba and zer are the filtered copyright expressions, and fil is another independent LVLM. Filtering helps ensure"}, {"title": "Copyright infringement determination via multi-LVLM comparison", "content": "Many studies (Du et al., 2023; Chan et al., 2023; Lakara et al., 2024; Liu et al., 2024) have shown that multi-agent debate can effectively improve the reliability of responses generated by large models. At this stage, we utilize N LVLMs \u03c0i(i = 1, 2, ..., N) to communicate with each other and evaluate overall similarity. In addition, to align with human judgment preferences, we employ few-shot in-context learning (Dong et al., 2022; Agarwal et al., 2024) by presenting multiple pairs of images scored by humans as references. Specifically, for a single agent \u03c0\u2081, given inputs including x, xer, the filtered copyright expressions ze, zer, an instruction pi, and the set of human reference images Dh and their corresponding score set Sh, the agent is required to output a score si \u2208 [0, 1], confidence ci \u2208 [0, 1], and supporting rationale ri. Specifically, the process can be represented as:\n\\( \\pi_i (x, x_{cr}, z^c, z_{cr}^c, p_i, D_h, S_h) \\rightarrow (s_i, c_i, r_i). \\)\nFollowing (Du et al., 2023), we adopt a fully connected synchronous communication debate approach, where each LVLM receives the responses (s, c, r) from the other N \u2013 1 LVLMs before making the next judgment. This creates a dynamic feedback loop that strengthens the reliability and depth of the analysis, as models adapt their evaluations based on new insights presented by their peers. Each LVLM can adjust its score based on the responses from the other LVLMs or keep it unchanged. We use the following consistency judgment criterion:\nSi - Sj \u2264 a \u2200i, j\u2208 {1,2,..., N}. (5)\nIf the difference in scores between all LVLMs is less than a, we consider that all models have reached a consensus. Additionally, to avoid the models getting stuck in a meaningless loop, we set the maximum number of debate rounds to M.\nAfter the debate, the agreed-upon results will be input into an independent meta-judge LVLM \u03c0f, which synthesizes the results to give the final score on whether substantial similarity has occurred, defined as:\n\\( \\pi_f(x, x_{cr}, z^c, z_{cr}^c, p_f, D_h, S_h, S_m, C_m, R_m) \\rightarrow (s_f, c_f, r_f), \\)\nwhere Sm, Cm, and Rm represent the set of scores, confidence levels, and rationales from N LVLMs after reaching consensus in the m-th (m < M) debate. By combining the strengths of individual agents and iterative debating, the approach could achieve a reliable assessment of visual similarity. Furthermore, we can determine whether the generated image constitutes infringement based on whether the final similarity score exceeds a specific threshold \u03b3:\nIsInfringement(x) = I(sf) > \u03b3. (7)\nThe whole two-stage process ensures a comprehensive and reliable evaluation by integrating multiple perspectives and rigorous analysis. The complete algorithm and instruction prompts can be found in appendix A.1 and A.2."}, {"title": "4. LVLM for Infringement Mitigation", "content": "Based on the identification results, we attempt to control the generation model to ensure its outputs do not infringe on copyright. As shown in Figure 2, we will discuss two methods separately depending on the control target: prompt control and latent control."}, {"title": "4.1. Mitigation via LVLM-based Prompt Control", "content": "Wen et al. have proved that slightly modifying the overfitted prompts can effectively avoid generating memorized images. To achieve automated prompt modification aimed at eliminating infringement expressions, we use an LVLM as a prompt optimizer to iteratively adjust the infringing prompt until the final score falls below a threshold \u03b3. Formally, given the source image xer, the generated image xt and the corresponding prompt pt at round t, control condition pc, historical judgment score sf, confidence c, and rationale rf, the prompt modifier \u03c0p is tasked with providing the prompt for the next round, that is:\n\\( \\pi_p (x_t, x_{cr}, p_t^c, p_c, s_f, c_f, r_f) \\rightarrow p_{t+1}. \\)\nHere, pe requires the modifier to alter the infringing expression while preserving the original expression as much as possible to avoid generating meaningless images. This mitigation strategy does not require any knowledge of text-to-image models, making it suitable for general black-box scenarios. The algorithm and instruction prompts can be found in appendix B.1 and B.2."}, {"title": "4.2. Mitigation via RL-based Latent Control", "content": "For diffusion models, the output is influenced not only by the prompt but also by the latent noise. Latent noise represents encoded representations of the input that capture essential features in a lower-dimensional space. These latent variables guide the generation process, affecting the finer details of the resulting image. In this section, we propose a reinforcement learning (RL)-based latent control method to mitigate copyright infringement in diffusion-based generative models. Our method involves training an agent to search the input latent variables that yield lower infringement scores, ensuring that the generated outputs do not violate copyright.\nSpecifically, for latent variable z, we define a policy \u03c0\u03c9 parameterized by w, allowing us to sample latent noise \u03b5 ~ \u03c0\u03c9(z), which follows a Gaussian distribution. The sampled noise e is then passed through the pre-trained diffusion decoder f to produce the image x = f(z, e).\nTo assess the copyright infringement potential of the generated image, we employ our CopyJudge to obtain the infringement score sf. Based on this score, we define a reward function:\nR(z) = log(sf). (9)\nThis reward is designed to penalize outputs with higher infringement scores, thus encouraging the generation of non-infringing content. We optimize the parameters w by maximizing the expected reward, L(w), defined as:\nL(w) = \u0395\u03c0\u03c0\u03c9 [R(2)]. (10)\nThe gradient of this objective is computed using the REIN-FORCE rule (Williams, 1992), which is given by:\n\u25bd\u03c9L(\u03c9) = \u0395\u03c0\u03c0\u03c9 [\u2207w log(\u03c0\u03c9)R(z)]. (11)\nDuring the training process, the latent variable z is updated according to the following rule:\nz' = z + \u03b2\u03b5, \u03b5\u03b9 \u03c0\u03c9(2), (12)\nwhere \u1e9e is the step size. We further conduct normalization for the latent variables to maintain stability and prevent extreme deviations. This RL-based approach allows the agent to explore variations in the latent space, thereby improving its ability to generate non-infringing content. The detailed algorithm can be found in appendix B.1."}, {"title": "5. Experiments", "content": "Firstly, we use D-Rep dataset (Wang et al., 2024b), which contains realistic and generated image pairs scored by human from 0 to 5 according to their similarity. Following its setting, we consider samples with scores of 4 or above as infringement samples, while the rest were non-infringement samples. We use the 4,000 official test images. In addition, we also consider the specific IP infringement. Referring to (Ma et al., 2024), we select 10 well-known cartoon characters and 10 artworks from Wikipedia (all can be found in B.2). 3 different text-to-image models-Stable Diffusion v2, Kandinsky2-2 (Razzhigaev et al., 2023), and Stable Diffusion XL (Podell et al., 2023)\u2014are used to generate images. For each item, we manually select one infringing image and one non-infringing image from each model, resulting in a total of 60 positive samples and 60 negative samples.\nWe select 4 commonly used distance-based image copy detection metrics: L2 norm (Carlini et al., 2023), which directly measures pixel-wise differences; LPIPS (Zhang et al., 2018), which captures perceptual similarity based on deep network features; SSCD (Pizzi et al.,"}, {"title": "5.1. Infringement Identification Experiments", "content": "Metric. Accuracy and F1 score are calculated as the criteria for infringement classification. We perform grid search to select the threshold that achieves the highest F1 score for each method.\nImplementation detail. Although our approach does not rely on a specific LVLM, we choose GPT-40 (Hurst et al., 2024) as our agent by default. As for multi-agent debate, we use 3 agents with a maximum of 5 iterations. We use random 3 images from each level (0-5) in the D-Rep training set as human priors to present to the agent.\nFrom the results in Table 1, it is evident that traditional image copy detection methods exhibit limitations in the copyright infringement identification task. Our approach significantly outperforms most methods. For the state-of-the-art method, PDF-Emb, which was trained on 36,000 samples from the D-Rep, our performance on D-Rep is slightly inferior. However, its poor performance on the Cartoon IP and Artwork dataset highlights its lack of generalization capability, whereas our method demonstrates equally excellent results across datasets. Figure 3 illustrates the prediction score distributions for all methods, showing that our approach achieves a relatively more distinct boundary between infringing and non-infringing cases. More results and details on time cost can be found in appendix A.3 and A.4."}, {"title": "5.2. Infringement Mitigation Experiments", "content": "To thoroughly test the effectiveness of our infringement mitigation, we consider both memorization and specific IP infringement mitigation."}, {"title": "5.2.1. \u039c\u0395MORIZATION MITIGATION", "content": "Wen et al. have found that text-to-image model memorization can be mitigated through simple prompt modifications without additional model training. They iteratively adjust prompt embeddings through gradients based on text-conditional noise prediction to reduce memorization. To compare with it, we conduct our memorization mitigation test using the overfitted Stable Diffusion v1 model trained by them. We use the same 200 memorized images provided by them and record the average Infringement Score identified by CopyJudge before and after the mitigation. At the same time, we use the CLIP Score (Radford et al., 2021) to measure the alignment between the modified images and the"}, {"title": "5.2.2. IP INFRINGEMENT MITIGATION", "content": "Compared to cases of exact replication (memorization), here we consider specific IP infringement, such as imitation of cartoon IPs and artistic elements. Based on whether the input prompt contains direct copyright information, we consider two types of infringement scenarios: explicit infringement and implicit infringement.\nExplicit infringement. This refers to prompts that directly contain copyright information, such as \u201cGenerate an image of Mickey Mouse.\u201d We use the 20 cartoon and artwork samples collected in section 5.1 to generate infringing images using Stable Diffusion v2, where the prompt explicitly includes the names or author names of the work.\nImplicit infringement. This occurs when the prompt does"}, {"title": "5.3. Ablation Studies", "content": "We separately explore the contributions of the abstraction-filtration-comparison test (AFC), multi-agent debate (MAD), and prior demonstration (DEM) to infringement identification. We randomly select 200 samples from the D-Rep dataset for ablation experiments, with each group undergoing five independent runs. As shown in Table 5, each module has a positive impact. Specifically, abstraction-filtration-comparison significantly improves accuracy, the demonstration of human priors effectively enhances the F1 score, and the multi-agent debate further boosts both metrics, ensuring reliable identification results."}, {"title": "6. Limitations and Future Work", "content": "While our method shows promise, its performance is currently constrained by the availability of labeled data, making it challenging to fully evaluate its alignment with human judgment. To address this, we believe that developing a more comprehensive dataset containing detailed human judgment criteria is crucial. In addition, we are looking forward to stronger attacks to test the robustness of our mitigation strategies. Improving the retrieval of infringing images will also provide valuable insights into the relationship between generative models and copyrighted content. Lastly, although our approach does not require a specific LVLM, we plan to explore other models beyond GPT in advancing copyright protection in the future."}, {"title": "7. Conclusion", "content": "We present CopyJudge, an innovative framework for automating the identification of copyright infringement in text-to-image diffusion models. By leveraging abstraction-filtration-comparison test and multi-LVLM debates, our approach could effectively evaluate the substantial similarity between generated and copyrighted images, providing clear and interpretable judgments. Additionally, our LVLM-based mitigation strategy helps avoid infringement by automatically optimizing prompts and exploring non-infringing latent noise vectors, while ensuring that generated images align with the user's requirements."}, {"title": "A. Supplementary Information on Infringement Identification", "content": "In Algorithm 1, we present the detailed procedure for automated infringement identification based on the abstraction-filtering-comparison framework. The algorithm systematically extracts copyrightable expressions from images, filters out non-protectable elements, and employs a multi-agent debate among LVLMs to assess substantial similarity."}, {"title": "A.1. Algorithm", "content": "Require: Image pair (x, xcr), LVLMS {\u03c0abs, \u03c0fil, \u03c01,..., \u03c0\u039d, \u03c0f}, thresholds \u03b1, \u03b3, maximum debate rounds M, human reference dataset Dh, score set Sh\n1: Stage 1: Copyright Expression Extraction\n2: Extract abstracted expressions:\n(z, zcr) \u2190 abs(X, Xcr, Pabs)\n3: Filter non-copyrightable elements:\n(ze, zer) \u2190 \u03c0\u03b9(z, Zer, Pil)\n4: Stage 2: Copyright Infringement Determination\n5: for each LVLM \u03c0i, where i \u2208 {1, 2, . . ., N} do\n6:\nCompute similarity score, confidence, and rationale:\n(Si, Ci, ri) \u2190 \u03c0i (X, Xcr, Z, Zer, Pi, Dh, Sh)\n7: end for\n8: Initialize debate round counter m\u21901\n9: while m \u2264 M do\n10:\nfor each LVLM \u03c0i do\n11:\nReceive responses {(sj, Cj,rj)|j \u2260 i}\n12:\nUpdate score based on peer evaluations\n13:\nend for\n14:\nCheck consensus: |si - sj| \u2264 a, Vi, j\n15:\nif consensus achieved then\n16:\nBreak loop\n17:\nend if\n18:\nmm+1\n19: end while\n20: Meta-judge LVLM final decision:\n21:\n(Sf, Cf,rf) \u2190 \u3160 f(x, Xcr, Z\u00ba, Zcr,Pf, Dh, Sh, Sm, Cm, Rm)\n22: Determine infringement:\n23: IsInfringement(x) \u2190 I(sf > Y)"}, {"title": "A.2. Instructive Prompts Used", "content": "The effectiveness of the infringement identification process relies on well-designed prompts. Below are examples of instructive prompts used in our framework:\n\u2022 Abstraction Prompt: \u201cPlease help decompose the given two images into their abstract concepts. Identify key components such as composition, themes, color palette, textures, and any unique visual elements. Describe each component in detail. Ensure the output follows the template format: 'Image1: XXX, Image2: XXX'."}, {"title": "A. Supplementary Information on Infringement Mitigation", "content": "For infringement mitigation, we use two strategies: prompt control and latent control, corresponding to Algorithm 2 and Algorithm 3, respectively."}]}