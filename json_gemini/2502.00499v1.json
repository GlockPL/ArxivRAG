{"title": "Discovering Directly-Follows Graph Model for Acyclic Processes", "authors": ["Nikita Shaimov", "Irina Lomazova", "Alexey Mitsyuk"], "abstract": "Process mining is the common name for a range of methods and approaches aimed at analysing and improving processes. Specifically, methods that aim to derive process models from event logs fall under the category of process discovery. Within the range of processes, acyclic processes form a distinct category. In such processes, previously performed actions are not repeated, forming chains of unique actions. However, due to differences in the order of actions, existing process discovery methods can provide models containing cycles even if a process is acyclic. This paper presents a new process discovery algorithm that allows to discover acyclic DFG models for acyclic processes. A model is discovered by partitioning an event log into parts that provide acyclic DFG models and merging them while avoiding the formation of cycles. The resulting algorithm was tested both on real-life and artificial event logs. Absence of cycles improves model visual clarity and precision, also allowing to apply cycle-sensitive methods or visualisations to the model.", "sections": [{"title": "1 Introduction", "content": "For the purpose of process data analysis, process mining (van der Aalst 2016) methods have been successfully applied in many areas, such as business, medicine, logistics, and many others. Process mining allows us to explore, analyse and improve processes through event data stored in the event logs. The event log is the collection of event records that reflect process behaviour for a certain period of time. Process mining methods can be divided into three categories: process discovery, conformance checking, and process enhancement. Process discovery methods are very important (Milani et al. 2022) as they allow for the automatic synthesis of models of real processes based on event logs. Discovered process models can be analysed in order to search for anomalies, correlations, deviations and inefficiencies, taking into account the flow of the process. Depending on the algorithm, models can be synthesised in various notations, such as Petri nets, UML, BPMN or Directly Follows Graphs (DFGs). Despite its"}, {"title": "2 Motivating example", "content": "Let us begin with a real-life example to demonstrate the realistic nature of the problem we are studying. In this paper, we consider data from the Learning Management System (LMS) of our university. The data contains information about students' academic performance. Based on these data, we create an event log. In this paper, the event log contains data on events related to three groups of students attending classes, lectures, and seminars in two academic courses: \u201cBusiness and management in a global context\" (\u201cbmgc\u201d, for short) and \u201cCalculus\u201d (\u201ccalc\u201d, for short). The log consists of traces, which are sequences of actions ordered by time. Each trace is related to a single case, which in our context corresponds to a student. Thus, the collection of traces represents individual learning trajectories of students.\nWe would like to motivate our research using the small simplified sample from the event log. Our sample includes records for five students and only parts of events (see Tab. 1). Each row represents an event record. The record contains the case ID, timestamp, and the name of the activity performed.\nIn our example, the records have the following form: <the_name_of_the_educational_course><the_type_of_the_performed_class>_<the_serial_number_of_the_class>. The timestamp shows when the class took place, and the case_ID is the unique identification number of the student.\nThe process model can be constructed with the help of a process discovery algorithm. We will use an algorithm that provides a process model in the form of a DFG (van der Aalst 2022). DFG represents a process as a graph. Nodes of this graph correspond to activities. If an arc connects two nodes, then the related activities follow each other directly, at least in some instances of the process. Thus, such a directed graph reflects all possible orders of process activities observed in reality.\""}, {"title": "3 Basic definitions", "content": "In this section, we provide some basic definitions that will be used in the following.\nLet X be a set. A multiset m over a set X is a mapping: $m : X \\rightarrow N$, where $N$ is the set of natural numbers (including zero), i.e., a multiset may contain several copies of the same element. For an element $x \\in X$, we write $x \\in m$, if $m(x) > 0$. For two multisets $m,m'$ over X we write $m \\subseteq m'$ iff $\\forall x \\in X : m(x) \\leq m'(x)$ (the inclusion relation). The sum, the union, and the subtraction of two multisets m and m' are defined as usual: $\\forall x \\in X : (m+m')(x)=m(x)+m'(x)$, $(m \\cup m')(x)=max(m(x),m'(x))$, $(m-m')(x) = m(x) \u2013 m'(x)$, if $m(x) \u2013 m'(x) \\geq 0$, otherwise $(m \u2013 m')(x) = 0$. By $M(X)$ we denote the set of all multisets over X.\nFor a set X, by X* with elements of the form $(x_1,...,x_k)$ we denote the set of all finite sequences (words) over X.\nIn practice, an event log is represented as a collection of records, where each record contains information about an event, including at least the event name, the event identifier, and a timestamp. A collection of records can be divided into traces based on case identifiers, and the order of event names in traces is determined according to the timestamps.\nDefinition 1. Let E be a finite set of event names (events for short). A trace over E is a finite sequence $\\sigma = (e_1,\u2026\u2026,e_n)$ of events from E, i.e. $\\sigma\\in E^*$. An event log over E is a finite multiset of traces $L\\in M(E^*)$.\nGiven an event log L over E, we define two binary relations on E (w.r.t. L).\nDefinition 2. We say that an event b directly follows an event a in L (written a < b), if there is a trace $\\sigma = (e_1,\u2026,e_n) \\in L$, such that for some $i = 1,\u2026, n \u2212 1$, $e_i = a$ and $e_{i+1} = b$, i. e. b goes directly after a in $\\sigma$.\nAn event b follows an event a in L, if there is a trace $\\sigma = (e_1,\u2026,e_n) \\in L$, such that for some $i, j = 1,\u2026,n$, $e_i = a$, $e_j = b$, and i < j, i. e. b goes after a in $\\sigma$.\nDefinition 3. A directly-follows graph (DFG) over E is a labelled directed graph $G = (V,A,\\lambda,V_{start},V_{end})$, where:\n\u2022 V is a finite set of vertices;\n\u2022 A C V \u00d7 V is a finite set of arcs;\n\u2022 $\\lambda : V - \\{V_{start}, V_{end}\\} \\rightarrow E$ is a labelling function that maps each vertex to an event name;\n\u2022 $V_{start} \\in V$ is the only vertex that does not have incoming arcs;\n\u2022 $V_{end} \\in V$ is the only vertex that does not have outgoing arcs.\nDFG is used to model the behaviour of the system.\nDefinition 4. Let $G = (V,A,\\lambda,v_{start},V_{end})$ be a DFG over E. A finite sequence of event names $r = (e_1,\u2026\u2026,e_n) \\in E^*$ is called a run in G if exists a path $(V_{start},V_1,\u2026\u2026,V_n,V_{end}) \\in G$ with $\\lambda(v_1) = e_1, \\lambda(v_2) = e_2,\u2026, \\lambda(v_n) = e_n$."}, {"title": "4 Acyclic DFG model discovery", "content": "In this section, we present a new algorithm for discovering an acyclic DFG from an event log of the acyclic process. The main idea of the algorithm is as follows. Given an acyclic event log, the first step is to split the log into DFG-acyclic sublogs. This is always possible because each trace in the acyclic event log can itself be considered as a DFG-acyclic event log. The classical DFG discovery algorithm is then applied to each of these sublogs, resulting in a set of acyclic DFG (sub)models. We then used a special merging of these submodels to construct the acyclic DFG model for the entire original event log. Note that to avoid cycles in the resulting DFG model, we allow more than one node to be labelled with the same event name.\nWe illustrate the approach with the commutative diagram in Fig. 3. Here L is an acyclic event log, partitioned into DFG-acyclic sublogs $l_1, l_2, ... , l_n$, i.e. $L = l_1 + ... + l_n$. Acyclic DFG models $M_1 =DFG(l_1), M_2 = DFG(l_2), . . ., M_n = DFG(l_n)$ are discovered from these sublogs using the classical algorithm. By $\\bigoplus$ we denote here special merging operation on submodels $M_1,..., M_n$, resulting in a DFG model M, corresponding to the entire log L. This operation is defined in Sec. 4.2 as a model merging algorithm.\nWe show further that M perfectly fits L, provided that $M_i$ perfectly fits $l_i$ for all i = 1, . . ., n.\nThe following subsections describe the three steps of our discovery algorithm in more detail.\n1. event log partitioning;\n2. merging of (two) acyclic DFGs;\n3. merging of (two) acyclic DFGs with repeated event names."}, {"title": "4.1 Acyclic event log partitioning", "content": "Here we describe how to partition an acyclic event log into DFG-acyclic sublogs.\nIn an acyclic event log, each event occurs at most once in each trace. For events A and B in an acyclic event log L, we write $A \\ll_L B$, or just A < B, if there is a trace in L with A occurring earlier than B.\nA DFG model discovered from an acyclic log L contains cycles, if for some two events A and B, $A \\ll B$ and $B \\ll A$ in L, i.e., there are two traces in L where two events occur in different orders. Thus, a single trace is a DFG-acyclic event log. Then, a DFG-acyclic sublog should not contain two traces with two events occurring in different orders. We call such traces compatible. Checking whether two traces are compatible is straightforward.\nTo partition an acyclic event log into DFG-acyclic sublogs, we represent the log as a graph where nodes are traces, and edges connect compatible traces. A set of pairwise compatible traces (a DFG-acyclic sublog) forms a clique in this graph. Partitioning the log into the minimal number of sublogs is equivalent to finding the minimum clique cover for the graph. Since the minimum clique cover problem is NP-hard (Karp 1972), we solve the problem using a heuristic algorithm that produces a nearly optimal solution in a reasonable amount of time.\nFor each of the obtained DFG-acyclic event logs, an acyclic DFG model can be constructed using a known discovery algorithm. The next subsection describes how these models can be combined into one overall acyclic DFG model."}, {"title": "4.2 Merging algorithm for two acyclic DFG models", "content": "After partitioning an acyclic event log and constructing multiple acyclic DFG models, the next task is to combine these models into a new acyclic DFG that perfectly fits the original acyclic event log. We first describe the merging of two acyclic DFG models with unique event labels. We present two algorithms to solve this problem, a naive one and a more accurate one. However, such a merger may result in a DFG in which multiple nodes are labelled with the same event. Therefore, to merge more than two DFG models, we next present an algorithm to merge acyclic DFG models with duplicate event names."}, {"title": "4.2.1 Naive Approach", "content": "Now we describe a naive merging algorithm that produces results quickly but at the expense of the size and complexity of the resulting model.\nGiven two acyclic DFG models with unique event labels, the merging algorithm is performed in four steps:\n1. searching for maximum common subgraphs;\n2. constructing the connectivity graph for common subgraphs;\n3. finding and eliminating cycles in the connectivity graph;\n4. merging subgraphs based on fusion of some vertices labelled with the same event names."}, {"title": "4.2.2 More Accurate Merging", "content": "In the naive approach, we duplicate the entire common subgraph if the corresponding vertex in the connectivity graph is excluded to break cycles (see Fig. 5). However, in many cases, it is possible to remove only some event nodes in common subgraphs and still break all cycles.\nFor a more accurate approach, we include entire subgraphs in the connectivity graph. Now in the connectivity graph, an arc connects two vertices in two different common subgraphs iff there is a path from one of them to the other in at least one of the two initial acyclic DFGs.\nWe continue to use the example in Fig. 4, and Fig. 8 shows the corresponding connectivity graph for accurate merging, where nodes of different subgraphs are coloured in different shades.\nTo eliminate cycles in the accurate approach, we use the same Bounded Search Tree algorithm as in the naive approach. In our example, we only need to remove one node F to make the connectivity graph acyclic (see Fig. 9).\nCompared with the naive approach, the accurate approach uses a connectivity graph with a larger"}, {"title": "4.3 Merging two acyclic DFG models with duplicate event names", "content": "The algorithms described above allow us to merge two models without duplicate event names, producing a DFG with duplicate names. So, when we merge more than two models, to do it pairwise, we need an algorithm to merge acyclic models with duplicate event names.\nTo illustrate the new algorithm, we use an example in Fig. 11. Here, two models have only one common subgraph with vertices A, B, C, D, E, and F. In the first model, event names K, L, N, and P appear twice, but are renamed to distinguish them: K into K1 and K2, etc. In the second"}, {"title": "5 Evaluation", "content": "In this section, we evaluate our discovery approach using real-life data sets. The example provided in Section 2 (see Tab. 1) is a simplified sample extracted from the real-life event log that will be described in the following section."}, {"title": "5.1 Real-life case description", "content": "In this case study, we analyse educational trajectories of students who attend several university-level educational courses. From the university LMS, we collected data on three groups of students who studied two educational courses over the course of half an academic year. In Tab. 2 shows an example of a sample of the data set. The grades in the data, depending on the class and course, may reflect either the student's grades, their attendance in classes, or whether they were active in class or not. To apply process discovery algorithms, the data must first be aggregated and converted into an event log in a suitable format.\nBased on the data obtained, a single unified event log was created (see Tab. 3 for an excerpt from this log). An event in this log is a class or an exam. Activities, which are also event names, are enhanced with additional data, to distinguish courses and grades. First, the name of the corresponding subject is added at the beginning of the event name. Next, at the end of the event name, we add the presence, activity, or level of the performance of the student: low, med[ium], high, or none. Some classes do not track student attendance and will only be marked as 'none' or 'active'.\nNow, having the event log, we apply the process discovery algorithms and assess the discovered pro-cess models. To test our algorithm, we implemented the described approaches (anonymous.4open.science 2024) using the Python programming environment and the NetworkX library."}, {"title": "5.2 Models examples", "content": "As it was shown in the motivational example, the standard DFG discovery algorithm constructs the model with numerous cycles when dealing with the event log in which event names are ordered differently in different traces (see Fig. 13). The resulting model looks quite confusing. Such models are even called \"spaghetti models\" in informal conversations. This type of model does not allow researchers to perform visual analysis due to its complexity.\nThe main reason for the complexity of the model is the presence of cycles. Cycles occur because of differences in the order of event names. In our case, different groups of students have different dates for classes, as well as their numbers. This happens due to schedule mismatches between groups and various other circumstances. Thus, there are differences in the order and number of event names in the traces for different groups of students. The differences between groups grow with the number of educational courses involved as the number of possible mismatches increases. However, the nature of the process represented in this case is acyclic. In the real-life setting, students do not repeat exactly the same previous"}, {"title": "5.3 Models assessment", "content": "To assess discovered models and, thus, our algorithms, we calculate and compare various metrics for the process models, such as precision, fitness (recall) and time taken by the algorithms.\nWe constructed several models using the acquired event logs for three student groups in two academic courses. As a standard DFG algorithm, we use the algorithm provided in the PM4Py library (Berti et al. 2023), with the results converted into a directed graph data structure from the NetworkX library, for a"}, {"title": "5.4 Artificial data", "content": "To show a case where the accurate approach is preferable, let us provide an artificial one. In this case, we have two departments of an imaginable company that work on the same process. Each department"}, {"title": "6 Related work", "content": "Process mining methods are covered by a vast number of works. Most aspects of process mining are covered in the books (van der Aalst 2016; Burattin 2015; Mans et al. 2015) and in the subsequent hand-book (van der Aalst and Carmona 2022). These works provide a solid foundation for the area with all the necessary definitions, methods, and algorithms.\nThe standard DFG discovery method is known to be problematic in some cases (van der Aalst 2019). The work describes the problem with cycles that appear in process models containing parallel events or due to event names happening in different orders, even if in observable behaviour all event names appear at most once per trace. That implies that users should be aware of the features of the DFG discovery algorithm to avoid misleading interpretations.\nBPMN models with repeated event nodes were considered in Lieben (2018), where the authors de-scribe a discovery algorithm for exploratory data analysis. By allowing vertices to repeat in the models, the resulting models can be simplified. Repeating event nodes is also an alternative way to visualize"}, {"title": "7 Conclusion and future work", "content": "In this paper, we propose a new approach to process discovery. This allows us to build acyclic DFG models for acyclic processes. Given an acyclic process, the acyclic event log can be partitioned into parts that produce acyclic DFG models, which can then be merged into a single acyclic DFG model representing the initial event log. The occurrence of cycles during merging is avoided by allowing the repetition of event nodes. The DFGs synthesised using the provided algorithm, compared with those constructed using the standard DFG discovery algorithm, retain the same level of fitness and provide a higher level of precision due to the absence of cycles. However, the number of nodes in the discovered model is higher because of repeating nodes. The two merging approaches shown in this research provide a choice between speed and quality. The accurate approach requires more time to provide better merging in more complex cases. In contrast, the naive approach often returns the same result while taking less time to merge the models. We demonstrate how algorithms work using a real-life example based on educational data from universities. Of course, the use cases of our approach are not limited to educational data or any other particular applied area.\nThe absence of cycles in the model opens up the possibility of using process model visualisations that would be useless and difficult to implement in the presence of cycles. One particular example of a cycle-dependent visualisation is the approach based on Sankey diagrams Derezovskiy et al. (2024). Sankey diagrams allow us to show cycles, but cycles greatly reduce the clarity of the model. Another example where acyclic models are also required is Bayesian belief networks. In Vasilecas et al. (2014), authors"}]}