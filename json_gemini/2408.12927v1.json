{"title": "Abductive and Contrastive Explanations\nfor Scoring Rules in Voting", "authors": ["Cl\u00e9ment Contet", "Umberto Grandi", "J\u00e9r\u00f4me Mengin"], "abstract": "We view voting rules as classifiers that assign a winner (a\nclass) to a profile of voters' preferences (an instance). We propose to\napply techniques from formal explainability, most notably abductive\nand contrastive explanations, to identify minimal subsets of a pref-\nerence profile that either imply the current winner or explain why a\ndifferent candidate was not elected. Formal explanations turn out to\nhave strong connections with classical problems studied in compu-\ntational social choice such as bribery, possible and necessary win-\nner identification, and preference learning. We design algorithms for\ncomputing abductive and contrastive explanations for scoring rules.\nFor the Borda rule, we find a lower bound on the size of the small-\nest abductive explanations, and we conduct simulations to identify\ncorrelations between properties of preference profiles and the size of\ntheir smallest abductive explanations.", "sections": [{"title": "1 Introduction", "content": "Explaining the outcomes of artificial intelligence algorithms is one of\nthe main challenges of present research in this field, with a plethora\nof competing approaches and venues to discuss them (see, e.g., the\nrecent special issue edited by Miller et al. [30]). This problem is tradi-\ntionally less of an issue for voting rules, where social choice theorists\nhave used the axiomatic approach to justify the use of a specific vot-\ning rule. More recently, a stream of papers have used such axiomatic\nproperties to obtain justifications for the outcome of a voting rule on\na given preference profile [8, 33, 31]. Moreover, voting rules are no\nblack boxes. They are usually given in the form of an explicit func-\ntion or procedure that computes the winner of a given election. As\nalready observed by Ebadian et al. [16], classical voting rules typi-\ncally admit straightforward procedural explanations.\nHowever, the realm of digital democracy can be led to implement\narguably complex rules that require lengthy explanations to justify or\nexplain how the outcome is computed from voters' preferences. To\ngive two examples, the deliberation platform LiquidFeedback' uses\nthe Schultze voting rule [2], and many participatory budgeting bod-\nies are experimenting with the recently proposed method of equal\nshares\u00b2 [34]. Moreover, recent work is starting to consider social\nchoice on large number of alternatives, be them a list of government\nproposals or sentences produced by LLMs in response to prompts\n(see, e.g., [32, 11, 19]). In this setting, even voting rules whose func-\ntioning is easy to explain-such as scoring rules-may profit from\nthe development of magnifying lenses, in the form of well-studied\nand scientifically grounded algorithms for explanations, that are able\nto point at which subsets of the preference profile determines the top\npositions in the collective ranking, arguably augmenting the voters'\ntrust in the outcome of the vote while at the same time providing\nthe analyst with important information on the structure of the voters'\npreferences.\nThis paper argues that such tools can be obtained by suitably\nadapting notions from the growing body of research on formal ex-\nplanations in machine learning, most notably abductive explanations\nalso called prime implicant explanations [35, 14, 29] and their dual\ncontrastive explanations [22]. The underlying idea behind this en-\ndeavour is to explain the decision of supervised machine learning\nalgorithms known as classifiers by identifying subsets of the feature\nspace for which all possible completions do not change the classi-\nfier's decision (abductive explanations) or such that there exists a\ncompletion changing the decision (contrastive explanations, a spe-\ncial case of counterfactual explanations [37, 27]).\nWe will focus on a specific class of voting rules known as scor-\ning rules, which includes the plurality rule, k-approval rules, and\nthe Borda rule. Our choice is motivated by their computational\nproperties-most notably the fact that computing a necessary winner\ncan be done in polynomial time-as well as due to its wide applica-\ntion in recent digital democracy applications (see, e.g., [25, 32]).\nOur contribution. We first adapt the definitions of abductive and\ncontrastive explanations to the realm of voting rules in Section 2. We\ndesign an appropriate feature space on which explanations can be\ncomputed. Given our focus on scoring rules, we chose to represent\nprofiles of preferences as rank matrices, in which n\u00d7 m non-binary\nfeatures represent (in a non-anonymous way) which among m can-\ndidates is placed in k-th entry by voter i in its voting ballot. We also\nshow a useful connection between formal explanations and the clas-\nsical concepts of possible and necessary winner which will form the\nbasis of our algorithms for computing explanations.\nComputing formal explanations for binary classifiers is a search\nproblem in an exponential space, but efficient algorithms have been\nproposed in the literature, often using SAT solvers. Computing for-\nmal explanations in voting requires tackling the additional problem\nof interconnected features, implied by the assumptions that prefer-\nences are complete, transitive, and irreflexive binary relations. We\ndefine and analyse our algorithms for the computation of formal ex-\nplanations in voting in Section 3.\nTypically, the winner of a scoring rule on a preference profile can\nbe explained by a large number of formal explanations. We are there-\nfore interested in providing bounds on the size of the smallest ones."}, {"title": "2 Preliminaries", "content": "In this section we introduce the notions of abductive and contrastive\nexplanations and apply them to the realm of voting theory.\n2.1 Formal explanations\nFormal explanations are tools recently developed for explainable ar-\ntificial intelligence [35, 14, 22, 29, 27]. Given a classification prob-\nlem, the aim is to find inclusion-minimal subsets of features that are\nable to explain the classifier decision on a given instance. For ab-\nductive explanations we look for minimal subsets of features such\nthat any extension does not change the classifier decision, and for\ncontrastive explanations we look for minimal subsets such that there\nexists an extension that reverts the classifier's decision. Both types of\nexplanations are based on the computation of minimal conjunctions\nof literals representing whether the value of a feature can vary.\nAs an explanatory example, assume that the decision of whether to\nallow a bank client to open a mortgage is done by a classifier on the\nbasis of age and revenue. A negative decision by the classifier on an\ninstance can be explained by an abductive explanation pointing out\nthat the revenue is too low, so that the answer is negative irrespec-\ntive of the age of the client. A contrastive explanation, on the other\nhand, would point out that by keeping the same age and changing the\nrevenue it would be possible to obtain the mortgage.\nFormally, following the notations used by Marques-Silva [29], we\nare given a set of N features F, with each i-th feature having values\nin finite domain Di, and a set of classes K. A feature space is defined\nby F = D1 \u00d7 D2 \u00d7 \u00d7 DN and a classifier is any non-constant\nfunction that maps the feature space IF into the set of classes K, i.e.\n\u03ba: F \u2192 \u041a.\nDefinition 1. Given v \u2208 F, an abductive explanation (AXp) for the\nclassification of v by k is any minimal subset X C F such that\n\u2200(x \u2208 F).\n((\u2227xi = vi) \u21d2 (k(x) = k(v))\n(1)\ni\u2208X\nGiven v \u2208 F, a contrastive explanation (CXp) for the classification\nof v by k is any minimal subset Y F such that\n\u2203(x \u2208 F).\n((\u2227xi = vi) \u2227 (k(x) \u2260 k(v)))\n(2)\ni\u2208F\\Y\nIntuitively, given a specific instance, an AXp is a minimal subset of\nissue values to keep in order to ensure that the outcome of K remains\nunchanged, while a CXp is a minimal subset of issue values to erase\nin order to be able to change the outcome of \u043a.\n2.2 Elections and scoring rules\nAn election consists of a set A of n agents, a set C of m candidates,\nand a preference profile P = (P1, ..., Pn), where each P\u2081 is a linear\norder over C, called a preference relation or ballot. We denote IP the\nset of all possible profiles. A non-resolute voting rule F is a function\nthat maps IP into a subset of candidates, i.e., F: P \u2192 P(C) with\nP(C) the power set of the set of candidates.\nThere exists a particular class of voting rules known as scoring\nrules. Given a vector of weights (W1,W2,..., wm), for each ballot\nthe ith candidate scores wi points. The winners are then the candi-\ndates with the highest total score over all the ballots. Formally, given\na preference profile P, let pos(c, Pi) be the position of candidate\nc in the linear order Pi submitted by voter i, with the top-ranked\ncandidate being in position 1. A scoring rule assigns to each candi-\ndate c a score equals to \u2211i\u2208A Wpos(c,P\u2081), and the candidates with\nthe highest score are declared the winners. Notable examples in-\nclude the Borda rule defined by scoring vector (W1,W2,..., Wm) =\n(m \u2013 1,m \u2013 2,..., 0), and k-approval rules defined by vectors\n(1, ..., 1,0 ...,0), with k being the number of 1s in the scoring\nvector (with 1-approval being the plurality rule). For an introduction\non voting rules we refer to Brams and Fishburn [6] and Zwicker [39].\nExample 1. Consider four candidates A, B, C, D and four voters.\nWe represent the preferences of the voters with the rows of the fol-\nlowing matrix, with the most preferred candidate on the left and the\nleast preferred on the right:\nR =\nvoter 1\nvoter 2\nvoter 3\nvoter 4"}, {"title": "2.3 Formal explanations for elections", "content": "Voting rules can be seen as special cases of classifiers that take pro-\nfiles of linear orders as input and output a set of winning candidates.\nHowever, this representation depends on how input profiles are en-\ncoded into a feature space. This choice is crucial to formal expla-\nnations, as the encoding into a feature space determines the space\nof possible explanations (see Definition 1), with important conse-\nquences on their expressiveness and computational complexity.\nIn the literature on (computational) social choice, incomplete pref-\nerences are usually represented as partial orders (see, e.g., [24, 38]).\nHowever, for the specific case of scoring rules we propose the use of\npartial rank matrices in view of their more compact representation.\nDefinition 2. A rank matrix R = (R1, ..., Rn) is an n\u00d7m matrix,\nwhere each row Ri is a permutation of the set of candidates C.\nProfiles can naturally be represented with rank matrices (see Ex-\nample 1). In this context, each row represents a voter's ballot as a\nlinear order over candidates. Given a candidate c\u2208 C and k \u2264 m,\nRi,k = c means that c is in the kth position in the ballot of voter i.\nThroughout this paper, we will use interchangeably the terms vote\nprofile and rank matrix.\nDefinition 3. A partial rank matrix R = (R1, ..., Rn) is an n \u00d7 m\nmatrix with values in C\u222a {null}, such that on every row Ri each\nelement of C appears at most once.\nIf Ri,k = null, we say that k is a free entry in Ri. Conversely,\nk is a locked entry in Ri if Ri,k \u2260 null. When displayed in our\nexamples, free entries will be represented by middots (.). We define\nthe size of a partial rank matrix R (respectively ballot Ri), noted |R|\n(respectively Ri), as the number of its non-null entries.\nDefinition 4. Given two partial rank matrices R and R', we say that\nR' is an extension of R, denoted R \u2286 R', if for all (i, k) such that\nRi,k \u2260 null we have that Ri,k = R'i,k. We denote with Ext(R)\nthe set of all complete extensions of a partial rank matrix R, i.e.,\nextensions of R with no null value.\nGiven two rank matrices R' and R\" such that R' CR\", we\ndefine R = R\" \\ R' to be the partial rank matrix such that Ri,k =\nnull for all (i, k) such that Rik \u2260 null, and Ri,k = Rik for all\nother entries. We can now adapt Definition 1 for scoring rules.\nDefinition 5. Given a complete rank matrix R, a voting rule F and a\nwinning candidate w \u2208 F(R), an AXp of w \u2208 F(R) is a C-minimal\npartial rank matrix X such that X  R and\n\u2200(R' \u2208 P), X\u2286 R'\n\u21d2 w \u2208 F(R').\n(3)\nA CXp of w \u2208 F(R) is a \u2286-minimal partial rank matrix Y such that\nYC R and\n\u2203(R' \u2208 P), (R \\ Y) \u2286 R' and w \u2209 F(R').\n(4)\nExample 2. Consider the following partial rank matrix:\nIn any complete extension of X\u00b9, candidate A scores 3 points under\nthe Borda rule with the ballot of voter 1, 3 points with voter 3, and at\nleast 1 point with voter 4 (since for that voter, B is already in the last\nposition); so the overall score of A cannot be less than 7. Conversely,\nB may score 3 with voter 2, but cannot score more than 1 with voter\n3 (in the second-to-last position), so the overall Borda score for B\ncannot be more than 6. Thus A beats B with the Borda rule in any\ncomplete extension of X\u00b9, and it is not difficult to check that neither\nC nor D can beat A; although there can be ties, A is assured to be\none of the Borda winners. Moreover, if any of the non-null entries in\nX\u00b9 is freed (i.e., replaced with \u00b7), then it can be shown that there is a\ncomplete extension in which A is not a Borda winner anymore. Since\nX\u00b9 CR, this shows that X\u00b9 is an AXp for A \u2208 Borda(R).\nExample 3. Consider y\u00b9 below and its complement wrt. R:\nIf R\u00b2 is the completion of R \\ Y\u00b9 with C in the first position for\nvoter 1, and A in the third position, then the Borda score of A in R2\nis 1+0+3+1 = 5, the score of C is 3+2+1+2= 8, thus\nA \u2209 Borda(R2). This shows that Y\u00b9 is a CXp for A \u2208 Borda(R).\nAs observed previously, the feature space we just defined is not\ncomposed of independent features (the cells of a rank matrix). The\nfollowing example calls for a refinement of the notion of AXp.\nExample 4. Consider the two partial rank matrices X\u00b2 and X\u00b3 be-\nlow, of which the rank matrix R of Example 1 is a complete extension.\nObserve that X\u00b9 and X2 only differ in the first row:\nBoth X\u00b2 and X\u00b3 are AXps for A \u2208 Borda(R). However, it can be\nargued that they represent the same explanation, because the first row\nof X2 and X\u00b3 have a single possible extension, namely [A B C D].\nIn other words: X\u00b2 and X\u00b3 represent the same explanation, which is\nbetter represented with the full ballot [ABCD] on the first row.\nAs the example above shows, we can have multiple AXps (up to\nm) which differ only by one null entry in a row, and this is due to the\nconstraints defining a linear order of candidates. To avoid the redun-\ndancy caused by multiple equivalent AXps we propose the following:\nDefinition 6. Given a complete rank matrix R, a voting rule F and\na winning candidate w \u2208 F(R), an irredundant abductive expla-\nnation, or iAXp, of w \u2208 F(R) is a \u2286-minimal partial rank matrix\nX such that X CR, it verifies equation (3), and such that every row\nhas either none or at least 2 null entries.\nFormal explanations under constraints have been studied by\nCooper and Amgoud [13]. Our iAXps correspond to their no-\ntion of subset-minimal, coverage-based prime-implicant explanation\n(mCPI-Xp). Note that an AXp typically is also an iAXp, except when\nit has one or more rows with one null entry only. Given their close-\nness, in the remainder of the paper we will talk about AXps in gen-\neral, except when discussing algorithms for their computation.\""}, {"title": "2.4 Necessary winner and explanations", "content": "The well-studied concept of necessary and possible winner of voting\nrules [24] can be used to obtain a useful equivalent formulation for\nDefinition 5. Recall that given a candidate c \u2208 C, a voting rule F, and\na partial rank matrix R, c is a necessary winner if for every extension\nR' of R we have that c\u2208 F(R'), and we write c \u2208 NWF (R). Sim-\nilarly, c is a possible winner for R and F if there exists an extension\nR' of R such that c\u2208 F(R'), and we write c \u2208 PWF (R). It is now\nstraightforward to show the following:\nProposition 1. Given a complete rank matrix R, a voting rule F\nand a winning candidate w \u2208 F(R), X is an AXp of R iff X is\na-minimal partial rank matrix s.t. X \u2208 R and w \u2208 NWF(X).\nMoreover, Y is a CXp of R iff Y is a C-minimal partial rank matrix\ns.t. YC R and w \u2209 NWF(R \\ Y).\nFor scoring rules, the problem of deciding whether or not a can-\ndidate is a necessary winner can efficiently be solved thanks to a\ncharacterization based on candidates' minimal and maximal achiev-\nable scores [24]. Given its importance for the rest of the paper, we\nreframe the original result here with our notation.\nGiven a (possibly partial) rank matrix R = (R1,..., Rn), let us\ndenote the score obtained by c in Ras \u03c3r(c) and the score in a single\nballot Ri as \u03c3r\u2081(c). Clearly, \u03c3r(c) = \u2211r;er\u03c3r;(c). For any\npartial rank matrix R and any candidate c, we introduce omin (c) =\nminR'\u2208Ext(R)\u03c3R' (c) (resp. omax(c) = maxR'\u2208Ext(R)\u03c3R' (c))\nto be the minimal (resp. maximal) score that candidate c can obtain\nin any complete extension of R. Konczak and Lang [24] proved the\nfollowing characterization of necessary winners:\nProposition 2. Let F be a scoring rule, R a (possibly partial) rank\nmatrix, and c a candidate. c \u2208 NWF(R) if and only if for all c'\u2208\nC\\ {c},\n\u03c3min(c) \u2265 \u03c3max (c')\n(5)\nA more detailed analysis and proof of this proposition can be found\nin the extended version of this paper [12].\nExample 5. Consider the partial rank matrix X\u00b9 from Exam-\nple 2. The table below gives the minimal and maximal Borda scores\nomin (A) and o (B) as well as o (C) and oma (D):\nUsing Proposition 2 we can infer that A \u2208 NWBorda (R\u00b9). This, com-\nbined with the fact that freeing any other non-null entry in X\u00b9 would\ndecrease omin (A), or increase or for some of the other candi-\ndates, shows that X\u00b9 is an AXp of A \u2208 Borda(R) by Proposition 1.\nSimilarly, consider the partial rank matrix Y\u00b9 of Example 3. The\ntable below gives minimal and maximal Borda scores for A, B, C\nand D in any complete extension of R \\ Y\u00b9:\nObserve that om 1 (A) < (C), thus A \u2209 NWBorda(R\\Y\u00b9).\nMoreover \u00b9 is a minimal partial rank matrix with this property,\nmaking y\u00b9 a CXp for A \u2208 Borda(R) by Proposition 1."}, {"title": "3 Computing explanations for voting rules", "content": "Existing algorithms to compute formal explanations range from find-\ning one AXp or CXp, obtaining one (cardinal-wise) smallest AXp or\nCXp, and enumerating all AXps and CXps (we refer to [29] for a re-\ncent survey). All these algorithms are specializations of algorithms\nused to compute Minimal Unsatisfiable Sets (MUS) and Minimal\nCorrection Sets (MCS) [22]. In this section we adapt these algorithms\nto the computation of formal explanations for scoring rules.\nAs previously observed, in our settings the features are not inde-\npendent, since they are entries of a rank matrix. Hence, our algo-\nrithms have to include additional guardrails to ignore redundant ex-\nplanations generated by the non-independence of our features.\n3.1 Computing one explanation\nAlgorithm 1 finds one CXp for a given rank matrix and one of the\nwinning candidates. Because the non-independence of features does\nnot play a role in the computation of CXps, it is a straightforward\nadaptation of the classical algorithm for finding contrastive expla-\nnations for arbitrary classifiers. Indeed, when computing CXps we\nlook for the minimal amount of matrix entries to remove to be able\nto change the winner, and removing a single entry in a row of a rank\nmatrix does not change the set of possible extensions. Algorithm 1\ngoes across each entry of the rank matrix and locks as many as possi-\nble while keeping the constraint w \u2208 NWF(R\\Y). If this condition\nis broken, the algorithm rolls back by one step and frees the entry that\nhas just been locked. Since it is easier to verify that w \u2208 NWF(Y)\nwhere Y = R \\ Y, the algorithm works on the complement of the\nCXp, namely Y. Due to the monotonicity of explanations (i.e., if we\nhave enough information to declare the winner, having even more\ninformation will also be enough to declare the winner), the entry re-\nmoved and then added back will not have to be tested again later.\nAlgorithm 1 and, later, Algorithm 2, take a seed in input parame-\nters. This seed will be used for computations in Algorithms 4 and 5\nto have some control on the explanation returned. The seed plays\nthe role of a shortcut: one can view it as if all the entries it con-\ntains were the first iterations of the for loop on line 2. Since we have\nw \u2209 NWF(R\\S), we know that no rollback would have occurred.\nAlgorithms 1 and 2 can be run with the whole rank matrix as the seed\nto output a minimal explanation.\nAlgorithm 2 finds one irredundant AXp for a given rank matrix\nand one of the winning candidates. Because of the duality between\nthe definitions of AXp and CXp (see, e.g., [22]), its structure is very\nsimilar to Algorithm 1 with additional steps to take into account the\nnon-independence of features. This takes the form of both an addi-\ntional constraint on the seed (namely that \u2200i, Si \u2260 m 1) and a"}, {"title": "3.2 Enumeration and smallest explanations", "content": "Algorithm 4 enumerates all iAXps and CXps by exploring the whole\nsearch space. It iteratively generates a seed which will lead to a new\nCXp or iAXp with a call to an NP oracle. In this case, the problem\nof finding new instances to explore is encoded in a SAT formula. Ev-\nery entry of the rank matrix is associated to a literal where a True\nassignment means that the entry is fixed. A SAT solver is then used\nto efficiently find new instances thanks to the monotonicity of expla-\nnations. An upper bound on the total number of AXps and CXps is\n2([mm]), which can be derived via Sperner's Theorem (for a deeper\nanalysis of this mechanism see [26]). Finally, to prevent issues with\nthe non-independence of our features in Algorithm 4 and later Al-\ngorithm 5, instances containing a row with only one free entry are\nremoved (lines 2 to 3). The added clauses can be read as: for each\nentry i, jo, if xi,jo is false (the entry is free), then \u2200j\u2260jo \u00acXi,j_is\ntrue (at least another entry in the row is free).\nWhen selecting one of the many possible formal explanations we\nwill be interested in selecting the smallest one. Recall that the size\nof a partial rank matrix is the number of its non-null entries. We can\ntherefore define the set of smallest iAXps, denoted as SiAXp, as the\nargmin{x|x is iAXp of w\u2208F(R)} |X|. Finding a smallest CXp is rela-\ntively easy and can be done by computing a smallest cost solution to\na SAT problem. However, finding a SiAXp is generally harder. Algo-\nrithm 5 is based on a previous solution which uses the hitting set du-\nality of MUS and MCS and iteratively computes minimum (cardinal-\nwise) solutions to a hitting set problem [21]."}, {"title": "4 Smallest abductive explanations for Borda", "content": "One of the main challenges of dealing with formal explanations is\nthe existence of a large number of possible explanations. Indeed, the"}, {"title": "4.1 The size of abductive explanations for Borda", "content": "We first give a lower bound on the size of abductive explanations for\nthe Borda rule. The proof is non-trivial, and uses a suitably defined\nnotion of normal form for ballots of rank matrices, hinging on the\ncharacterisation of necessary winners proved in Proposition 2. We\ngive a sketch of the proof here, a detailed proof can be found in the\nextended version of this paper [12].\nTheorem 4. Let R be a rank matrix with n voters and m candidates\ns.t. w \u2208 C is a Borda winner of R. For all AXp X of R, we have:\n|X| \u2265 n\n(6)\nProof sketch. First, we observe that to bound the size of AXps of\nan arbitrary rank matrix, we can construct a different rank matrix\nwhich admits an AXp of size smaller or equal to the original ma-\ntrix. This observation is at the basis of our normal form construction\nbelow. Second, let a weak AXp be any partial rank matrix verifying\nconstraint (1) but that is not necessarily minimal. Because of subset-\nminimality, smallest weak AXps are AXps, and since AXps are also\nweak AXps, then proving (6) restricted to weak AXps is equivalent\nto proving the bound in Theorem 4.\nOur proof then uses the characterisation proved in Proposition 2:\nif X is an AXp for w \u2208 Borda(R), w is a necessary winner of X if\nand only if omin (w) > omax (c') for every other candidate c'. We\nnow define (c') = omin(w) \u2013 omax (c'), and we call \u2206 =\n\u03a3'\u2260c\u2206x(c') the total margin of victory. Since w is a necessary\nwinner for X, then \u2265 0. We also show that the computation of\nthe total margin of victory can be decomposed as the sum of total"}, {"title": "4.2 A map of elections for SiAXps for Borda", "content": "To get a clearer picture of the sizes of SiAXps of the Borda rule\nwe set up a map of elections using the tools by Szufa et al. [36].\nA map of elections starts from a set of profiles, generated using\nknown preference distributions, and generates a 2D embedding of\nthe space obtained by calculating the isomorphic swap-distance be-\ntween the profiles. Following their approach, to improve the inter-\npretability of the map we introduce specific extreme profiles to act\nas a compass [3, 18]. Our data set is composed of 146 profiles with\n4 candidates and 12 voters generated from 17 different cultures. The\ndetails of our dataset can be found in the extended version of this pa-\nper [12]. Preliminary experiments with higher number of voters and\ncandidates led to excessive execution time for Algorithm 5.\nThe first map in Figure 1 plots the map of elections for our dataset\non the left, which is coherent with those obtained by Szufa et al.\n[36] in past research. The compass profiles in red are the identical\nculture (ID) where all ballots are identical, the antagonism culture\n(AN) where half of the ballots are identical and the other half is their\nopposite, and the uniform culture (UN) where ballots are drawn uni-\nformally at random among all the possible ones (there are four of\nthem to account for randomness). Ten instances were generated for"}, {"title": "5 Conclusions and future work", "content": "A primary direction for future research is to test formal explana-\ntions on voting rules defined on the majority graph, devising a feature\nencoding that result in compact formal explanations. While the ax-\niomatic calculus devised by Nardi et al. [31] leads to human-readable\nexplanations supporting the choice of the winner in an election, our\nproposal of adapting formal explanations for scoring rules does not\nseem fit for this application, due to the large number of possible ex-\nplanations and the size of smallest explanations, which is high as\nsoon as the preference profile shows some complexity.\nA surprising connection can be shown between formal explana-\ntions and bribery in voting, with CXps identifying the positions in\nthe rankings that allow for a minimal destructive bribery attack, and\nAXps defining optimal protection against such attacks [28]. Formal\nexplanations in voting can also be used to study optimal preference\nelicitation strategies to compute the winner of a given election. This\nproblem has been well-studied in the literature as the communica-\ntion complexity [10] and the sample complexity [15] of voting rules,\nwith the size of smallest abductive explanations having a natural cor-\nrespondence with the former concept."}, {"title": "Appendix", "content": "A Proofs for Section 2 (Preliminaries)\nProof of proposition 2. In the original paper presenting the concept\nof necessary winner [24], the authors use a different representation of\npartial profiles. Where we use partial rank matrices, they use partial\norders on candidates.\nThis does not impact the characterisation of necessary winner\nwhich is independent of the representation. Indeed, for a profile P, a\nvoting rule F and a winning candidate c\u2208 F(P), if for all candidate\nc' different from c and all P' a such that P is an extension of P', we\nhave that omin (c) \u2265 omax (c'), then \u03c3\u03c1\u03b9(c) \u2265 \u03c3\u03c1\u03b9(c') because by\ndefinition we have \u03c3\u03c1\u03b9 (c) \u2265 omin (c) and omax (c') \u2265 \u03c3\u03c1\u03b9 (c').\nKonczak and Lang [24] present this result as an equivalence. How-\never as pointed out by Xia and Conitzer [38] this is a mistake as the\nfollowing counterexample shows. Consider four candidates A, B, C,\nD, three voters with the Borda rule. The first vote is the partial order\nA > B, A > C, A > D, B > C, B D. The second vote is\nAC, A D, B > A, B > C, B > D. The third is A > B. A\nis in first position in vote 1, in second in vote 2 and cannot be lower\nthan third in vote 3. Hence, omin (A) = 6. Similarly, \u03c3max (B) = 7,\nomax (C) = 5 and omax (D) = 5. A ties with B in the first two\nvotes but beats B in the third vote so A is ranked above B. Since\nomin (A) > omax (C) and omin (A) > omax (D), A is ranked\nabove C and D. Thus, we know that A will always be first and hence\nis a necessary winner. However, we have omin (A) < omax (B).\nEven if the equivalence does not hold in the original setting of\npartial orders, we now show that it holds when preference profiles\nare represented as rank matrices. Indeed, in our context, minimizing\nthe score of a necessary winner w and maximizing the score of any\nother candidate c are two independent goals. Hence, given a partial\nranks matrix R, for every candidate c, there exist a complete rank\nmatrix Re such that R \u2286 Re, or\u300f(w) = omin (w) and or\u300f(c) =\nomax (c). Since w is a necessary winner of partial rank matrix R, for\nany extension R' of R, we have o\u03c0\u03b9 (w) \u2265 \u03c3\u03c0\u03b9 (c). Applying this to\neach Re, we have \u2200c \u2208 C, omin (w) > \u03c3max (c). To construct such\nextension of R, we work ballot by ballot. If at least w or c is locked\nachieving both goals simultaneously then, is trivial. If both w and c\nare free, there are at least two free entries in the ballot. Hence, we\ncan put c in the most preferred free entry and w in the least preferred\nfree one without any problem."}]}