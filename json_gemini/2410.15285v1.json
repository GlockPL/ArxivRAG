{"title": "Contextual Augmented Multi-Model Programming (CAMP): A Hybrid Local-Cloud Copilot Framework", "authors": ["Yuchen Wang", "Shangxin Guo", "Chee Wei Tan"], "abstract": "The advancements in cloud-based Large Languages Models (LLMs) have revolutionized AI-assisted programming. However, their integration into certain local development environments like ones within the Apple software ecosystem (e.g., iOS apps, macOS) remains challenging due to computational demands and sandboxed constraints. This paper presents CAMP, a multi-model AI-assisted programming framework that consists of a local model that employes Retrieval-Augmented Generation (RAG) to retrieve contextual information from the codebase to facilitate context-aware prompt construction thus optimizing the performance of the cloud model, empowering LLMs' capabilities in local Integrated Development Environments (IDEs). The methodology is actualized in Copilot for Xcode, an AI-assisted programming tool crafted for Xcode that employs the RAG module to addresses software constraints and enables diverse generative programming tasks, including automatic code completion, documentation, error detection, and intelligent user-agent interaction. The results from objective experiments on generated code quality and subjective experiments on user adoption collectively demonstrate the pilot success of the proposed system and mark its significant contributions to the realm of AI-assisted programming.", "sections": [{"title": "I. INTRODUCTION", "content": "The field of natural language processing (NLP) has seen remarkable advancements through the use of large language models (LLMs). These models, capable of understanding and generating natural languages, have been fine-tuned to improve their performance using feedback mechanisms [1], [2]. The application of LLMs to AI-assisted programming has recently garnered significant attention [3], [4], as they offer the potential to embed advanced conversational agents into software development [5], [6]. This aligns with the visionary ideas presented in Edsger W. Dijkstra's seminal paper [7], illustrating the transformative potential of computers in facilitating a streamlined integration of code and human creativity.\nThe MIT programmer's apprentice was one of the earliest AI-assisted programming tools, aiming to simulate a knowledgeable junior programmer and utilizing NLP to understand programming patterns and interactions [8], [9]. This tool introduced revolutionary concepts such as code generation [10] and an early form of \u201cprompt engineering\u201d [11], driven by the recognition of computer programming as a systematic process of abstraction and simplification [7], [12].\nAI-assisted programming improves software productivity by automating tasks, detecting errors, enhancing code quality, promoting usability, improving reliability, and accelerating the overall software development cycles [4]. Rather than replacing human programmers, these tools empower them to unleash their creative potential. By automating repetitive and mundane tasks, AI-assisted programming frees up valuable time and mental energy for human programmers to focus on innovative problem-solving and designing elegant solutions with the help of predictive analysis. Furthermore, by incorporating natural language processing capabilities (i.e., via prompt engineering), these tools enable human programmers to interact with software systems in a more intuitive and human-like manner, thus streamlining the software development process [13].\nCloud-based tools that leverage LLMs, such as Codeium [14], GitHub Copilot [15], OpenAI ChatGPT [16], and Amazon CodeWhisperer [17], enable users to access their cloudbased LLM services and online resources through dedicated application programming interfaces (APIs) in an on-demand manner. These tools can be incorporated into existing systems like a local integrated development environment (IDE) or implemented via a Software-as-a-Service (SaaS) web interface, acting as a virtual service entity to meet objectives and save costs for the human programmer [18]. The expanding reach and high demand usage of these LLM-based tools reflect the growing demand for advanced NLP capabilities in software development, resonating with Dijkstra's anticipation of a paradigm shift, where the major challenge lies not merely in the execution of programs but in the very process of their creation and maintenance [7], [13]. Dijkstra argued for the integration of documentation as an essential part of a program rather than just a guide for humans and envisioned the goal as treating documentation as an integral part of a program to address challenges related to malfunctioning, partial fault recovery, and modifying programs while in action [7].\nThe advent of Retrieval-Augmented Generation (RAG) has further revolutionized AI-assisted programming [19]. By com-"}, {"title": "II. RELATED WORKS", "content": "A. Retrieval Augmented Generation (RAG)\nRAG is a recent development in the field of NLP that combines the strengths of pre-trained language models with information retrieval techniques. The RAG approach retrieves relevant documents from a large corpus and uses them to condition the generation process of the language model [19], [20], proposed initially as a method to leverage the vast amount of knowledge available in large text corpora to improve the performance in NLP tasks like question answering and fact verification. In the context of programming, RAG could potentially be used to improve the performance of code generation tasks by allowing the model to retrieve relevant code snippets from a large corpus of source code, which provides insights for our proposed work.\nB. Software Naturalness Hypothesis\nThe software naturalness hypothesis, articulated by [21], contends that programming languages should emulate the understanding and manipulation patterns inherent in natural language processing techniques applied to human languages. This hypothesis finds early substantiation in an n-gram model for code completion tasks, demonstrating the conception of software as possessing natural, repetitive, and predictable characteristics. The conceptualization of modeling codes through statistical language models with fine-tunable parameters inspires our proposed RAG module, detailed in Section IV-A, where we fine-tune hyperparameters, such as content search heuristics, to optimize the prompt engineering via maximumlikelihood estimation.\nC. Language Models for Big Code Analysis\nLLMs have emerged as a promising approach to address challenges in computer programming, providing user-friendly means for constructing and modifying code with a natural language-like ease, thus vividly exemplifying the software naturalness hypothesis [21]. Since the introduction of the transformer architecture in 2017 [22], LLMs trained on large-scale datasets of programs have shown significant benefits in code-related tasks by effectively learning programming language patterns and structures, which are collectively part of Big Code analysis [23]. Recent LLMs such as T5 [24], BERT [25], GPT-4 [16] and Palm 2 [26] have demonstrated impressive capabilities in understanding and generating human-like text, opening up new possibilities for enhancing software engineers' development experiences.\nD. AI-assisted Programming\nDijkstra in [7] foresaw the growing complexity of highlevel programming languages, anticipating the use of computer to assist human software engineers. His insight highlighted the importance of code translation, not just as a tool for human understanding, but as a crucial element in the code creation and modification process [7]. This foresight sets the stage for AI-assisted programming, which is the incorporation of machine learning techniques and tools into the software development process [27] to improve computer programming tasks. This concept shares similarities with pair programming [28], [29], whereby two human programmers collaborate to develop software by alternating between writing code (driver) and reviewing (observer) in a continuous switch. AI-assisted programming essentially replaces one of the two human programmers with an AI assistant, akin to the aforementioned MIT programmer's apprentice [8], [9]. The AI assistant automates tasks that can be broadly classified into two categories: generation and understanding. Generation tasks encompass activities such as code generation [30], [31], code completion [32], [33], code translation [34], [35], code refinement [36], and code summarization [37]. On the other hand, understanding tasks encompass activities like defect detection [38] and clone detection [39]. Improving the quality of large language models for these tasks focus on enhancing pre-training schemes [5], expanding training corpora [40], and employing improved evaluation metrics [6]. Many AI products have shown outstanding performances in coding assistance. AI-based predictive analysis [41] can anticipate"}, {"title": "III. PROBLEM FORMULATION", "content": "In this section, we mathematically formulate the language model that we require for AI-assisted programming, to explicitly define the problem metrics and show its feasibility.\nNaturally, a \"programming copilot\" can be formulated as a language model with input (e.g. user commands, existing codes, past tokens, etc.) and output (e.g. automated completed content, suggested options, answers to user queries, etc.). If we zoom in on the context-based content generation that enhances AI-assisted programming with LLMs, the retrieval augmented generator we propose is formulated as a language model with input of \"retrieved context\u201d and output of \"retrieved content\u201d.\nWe then construct the correlation between the context and content and solve for its solutions on the optimal parameters of the language model.\nLet us start with the standard maximum entropy language model with the form [48]:\n$p(w/h) = \\frac{exp (a^T f (w, h))}{\\Sigma_{w'} exp (a^T f(w', h))}$\nwhere w is the generated word given history h and vector $a \\in R^d$ represents the model's parameters that are attached to the extracted features $f(w, h) \\in R^d$.\nThe model is easily extended to support separate \"learning\" of w and h, with individual embeddings and a parameter matrix instead of the parameter vector\n$p(w/h) = \\frac{exp (\\psi(w)^T A \\phi(h))}{\\Sigma_{w'} exp (\\psi(w')^T A \\phi(h))}$                                                                                                                               (1)\nwhere $\\psi(\\cdot) \\in R^{d_\\psi}$ and $\\phi(\\cdot) \\in R^{d_\\phi}$ are individual embeddings of the word and history and A represents the extended parameter matrix.\nA typical RAG model uses the input sequence to retrieve relevant content (also called \"document\") and then uses both the input and the document to generate the output sequence [19]. The retriever $p_\\eta(z|x)$ computes the probability distribution of the top documents over the database, given input x; the generator $p_\\theta (y|x, z, y_{1:i-1})$ then generates token $y_i$ based on the original input x and the retrieved document z. The model is end-to-end formulated as\n$P_{RAG} = \\Sigma_{z \\in top-K(p(x))} P_\\eta(z|x) P_\\theta(y|x, z)$\n$ = \\Sigma_{z \\in top-K(p(x))} P_\\eta(z|x) [\\Pi_i P_\\theta (y_i|x, z, y_{1:i-1}),$                                                     (2)\nand if each step of token generation can draw the distribution probability from all documents (which aligns with our case):\n$P_{RAGT} = \\Pi_i \\Sigma_{z \\in top-K(p(x))} P_\\eta(z|x) P_\\theta(y_i|x, z, y_{1:i-1})$                                                    (3)"}, {"title": "IV. METHODOLOGY", "content": "In the next Section IV-A, we present our solution to the problem with M consisting of three sub-models: a contextual retriever, a content retriever, and a prompt constructor, and \u03b3 consisting of the parameters corresponding to the models: {\u03b7', \u03b7, \u03b8}.\nA. Context-Based RAG\nAs mathematically defined in Section III, our proposed RAG module consists of three major components: (I) a context retriever $R_{\\eta'}(c|x)$ that captures contextual information from the input of local development environment, (II) a content retriever $R_\u03b7(z|x, c)$ that generates top relevant content given the current context and the original input, and (III) a prompt constructor $G_\u03b8 (y_i|x, c, z, y_{1:i-1})$ that creates prompts to assist LLMs from the retrieved information and user queries. The RAG module is expected to support local context-aware AIassisted programming, especially in mainstream tasks like code auto-completion and question handling.\nFigure 2 presents a detailed illustration of the system workflow. Given the local development environment at a certain timestamp t, the contextual information c is first obtained. Here we generally refer to input like code base and user queries as part of the local environment. The context c is then utilized for the retrieval of the top-ranked relevant content information z, such as code snippets, interface, file path with programming structures, etc. Both the context and content are finally utilized in prompt construction for LLMs requests. Note that the local development environment is dynamically changing as t changes, so the workflow is synchronous with"}, {"title": "V. IMPLEMENTATION DETAILS", "content": "With the proposed RAG module which contains the trained retrievers and constructor, we are then ready to implement it in IDEs. The methodology can be generalized and applied to a broad range of local environments, but we specifically target ones with strict restrictions like sandbox constraints where the retrieved contextual information and content are necessary \"single source of truth\" about the development environment and play critical roles in enhancing AI-assisted programming.\nThis section presents the implementation details of our methodology in Xcode where we bridge the RAG module to both the local code base and the user to achieve real-time sync. As mentioned in Section II-E, extra efforts are required for IDEs like Copilot with sandboxed environments. For less restricted IDEs, the implementation becomes trivial.\nA. The Copilot for Xcode Framework\nThe structural framework of the Copilot for Xcode is illustrated in the sequence diagram presented in Figure 3. Upon users updating the code, the underlying model is promptly notified to retrieve information about the local context and user queries. Subsequently, it constructs prompts enriched with this contextual information, facilitating AI-assisted programming with LLMs. The response obtained is processed by the model and converted into suggestions for subsequent interactions between the user and the system, with Copilot for Xcode acting as the intermediary between the user and Xcode for code updates based on user feedback.\nThroughout this operational sequence, Copilot for Xcode fulfills the following key functions: 1) local context retrieval, 2) prompt construction, 3) bridging to IDEs, and 4) user interactions. The first two functionalities address RQ 1, while the latter two are pertinent to RQ 2. This framework dynamically establishes a connection between local IDEs and users, integrating them with cloud-based LLMs.\nB. Bridging to IDEs\nEnabling LLM functionality within Xcode is mainly constrained by two major obstacles: the IDE's sandboxing mechanism that delays synchronous user interactions and the limited information revealed by Xcode to software developers that hinders thorough code understanding. We correspondingly propose two key techniques to overcome these challenges and extract essential contextual information that is highly relevant to LLMs' prompt construction.\n1) XPC Service Level Communication: Firstly, the Xcode's sandboxing mechanism restricts plugin access to specific resources and prevents the launching of other programs. Take the real-time code suggestion feature for instance: to utilize language servers like Github Copilot requires an additional program provided by Github to be executed alongside the plugin, posing a necessity for our system to bypass the sandbox of Xcode. To achieve this, we propose to establish communication between the Xcode source editor extension and a non-sandboxed XPC Service, which acts as a cross-process call service that facilitates the communication between the extension and the language server. This further allows the presentation of code suggestions in the user interface (UI) that is not constrained by Xcode.\n2) Accessibility API: The second challenge is the limited permission allowed by Xcode to access local information, modify the code base, and interact with users. To assemble a request for language servers, sufficient information must be gathered from the development environment, but Xcode by default only provides the source code and file types. To obtain additional contextual information without relying on Xcode, we leverage the Accessibility API from the software development kit. This API captures and exposes information such as all text, cursor position, current editing file location, project location, etc, along with changes in the code base, enabling accurate local context retrieval. Besides the code base, the API also captures information about Xcode UI and supports interactions with the UI elements like the menu bar items. This empowers the proposed system to determine the appropriate location for content display and execute in-place code editing. We will present more details about user interactions in Section V-C.\n3) Local Context Retrieval: The above techniques allow us to proceed with the local context retrieval and eventually achieve context-aware prompt construction. We retrieve local context c from the development environment, including current cursor location, file path, and code snippets that users are paying attention to, from Xcode's data directory, as presented by (9). The directory is created by the Xcode development environment to store intermediate build and index information. It is separate from the project directory and is primarily used to cache build artifacts, compiled code, and index information generated during the development process."}, {"title": "VI. EVALUATION", "content": "We evaluate the performance of Copilot for Xcode assisted programming with objective and subjective experiments, as a proof of concept of our proposed methodology. In the objective experiment, we run automatic code completion tests on a LeetCode database to measure the code quality; in the subjective experiment, we employ user studies to observe user adoption. Note that because of a lack of competitive tools on the same surface, our experiments mainly aim to ascertain the proposed tool's practical efficacy and gain insights into its applications in problem-solving and potential growth points for the future.\nA. Objective Evaluation\nThe objective evaluation assesses the performance of Copilot for Xcode through code completion tasks. Given a seed program, we divide it into two segments: the first part serves as a prompt, and the second part represents the \"ground truth\". During the evaluation, we conceal the second part and let the model complete the code based on the prompt. The generated code is then compared with the \"ground truth\u201d for performance analysis. As Copilot for Xcode represents the pioneering tool for Xcode, it lacks direct comparison models. The objective metrics employed in this study primarily serve as a Proof of Concept to glean valuable insights into the quality of the generated code.\n1) Experiment Setup: In alignment with prevalent research practices in this domain [51] [52], we construct our evaluation dataset using a well-established repository of LeetCode solution programs in Swift 1. LeetCode is a widely used online platform for honing coding skills, particularly for technical interviews. As reported by Table II, we took 358 algorithmic coding questions from the LeetCode repository as seed programs. Typically, each seed program includes a problem description and a main function that solves the problem. To form the prompt and \"ground truth\", we truncate the seed program at the first line following the problem description (excluding comments or blank lines). The model then generates code starting from the first token after this truncation point.\nTo achieve automated evaluation and mitigate potential biases introduced by manual testing, we create the simulation progress Pat the XPC service level to communicate with CopilotForXcodeExtensionService, a child process of Copilot for Xcode that manages code updates within Xcode.\n2) Results Analysis: We utilize multiple metrics to evaluate Copilot for Xcode's capabilities of code generation. The Levenshtein edit similarity [53] and BLEU score [54] are commonly adopted in related work for syntactic analysis of LLMs; the Abstract Syntax Tree (AST) Similarity quantifies the resemblance between ASTs of code snippets and is widely employed in evaluating code structural similarity. Additionally, we measure the similarity in contextual meaning with ROBERta [55], by obtaining the semantic embeddings and computing the cosine similarity. This multifaceted approach aims to offer a comprehensive insight into Copilot for Xcode in generating code that aligns syntactically and structurally and semantically with the expected output.\nB. Subjective Evaluation\nWe conducted user studies involving four participants to evaluate the practical usability of Copilot for Xcode, as inspired by the study that evaluates the usability of code generation tools at [56]. The participants were asked to solve different types of programming tasks with Xcode, both with and without the assistance of Copilot for Xcode. We closely observed their problem-solving processes and recorded key metrics, including time spent, bottleneck steps, and tool utilization.\n1) Experiment Setup: The user study participants we found are university students and software engineers with at least one year of coding experience in Swift. Among the four participants (2 Female, 2 Male), 1 is an undergraduate, 1 is a master, and 2 are software engineers. For each participant, we organized an on-site user study session that lasted around one hour. During the session, participants were first briefed about how to use Copilot for Xcode and were given a short period (10 minutes) to freely explore the software. Then they were given two programming tasks to solve and asked a few questions afterward.\nThe two programming tasks we chose are one algorithmic and one UI-related problem:\n\u2022\nT1. Given an unsorted array, sort it with merge sort (without calling any APIs).\n\u2022\nT2. Create a \"HomeView\" and \"DetailsView\" with SwiftUI that navigates to each other."}, {"title": "VII. LIMITATIONS AND FUTURE DIRECTIONS", "content": "In this section, we critically analyze the limitations in our work and propose directions for future research works, in algorithm optimization, model refinement, and software features extensions.\n1) End to End Training: The work we presented trains different components of the RAG module individually and sequentially, based on our assumptions of the data distributions (e.g. We potentially assume that the distribution \u03b7' of importance of various context sources is independent of the rankings @ of different prompt components.). In future research, we propose to train all parameters end-to-end in one data pipeline, which might bring new insights to our understanding of the model parameters. However, this may also add to the computational burden and cause delays in user interactions.\n2) Trust AI: The integration of data accessibility tools and generative AI services within the software introduces potential concerns and ethical considerations regarding data privacy.\nTo address this limitation and foster a user-centric approach, our next step involves the implementation of a robust user consent mechanism that empowers users with the ability to control the access of our tool to their development data and make informed decisions about the extent of information shared. We aim to closely align with emerging privacy regulations and frameworks such as the General Data Protection Regulation (GDPR) [57], to not only comply with legal requirements but also promote ethical data handling practices.\n3) Software Feature Extensions: We also propose several extended features for Copilot for Xcode to prepare for its utilization in the production environment. As a software prototype, Copilot for Xcode overcomes considerable challenges during practical usage. For example, to bypass the sandboxing restrictions, it employs unconventional methods to retrieve local context information. As such, one future direction for us is to develop a portable functionality kit to maximize the tool's compatibility with future versions of Xcode. Secondly, as the current code suggestions are presented as C-style comments in comment mode, which can inadvertently disrupt a user's code if they are working on incompatible formats, we will work on extending to multiple programming languages for suggested code presentation. Furthermore, we will explore user coding preferences by exploiting user feedback during the interactions to improve customized services."}, {"title": "VIII. CONCLUSION", "content": "This paper introduced a context-based RAG method that enhances AI-assisted programming with retrieved contextaware content from the development environment. It then proposed Copilot for Xcode that actualizes the methodology in Xcode, as a pilot success of AI-assisted programming in Apple's sandbox-constrained IDEs.\nIn this work, we explored the effectiveness of retrievalaugmented prompt engineering in AI-assisted programming and demonstrated its practical application in influencing code generation and guiding language models toward user-centric outcomes. We started with mathematically modeling the core problem as convex optimization problems and providing algorithms that arrive at globally optimal solutions with computational efficiency. We proceeded to implement the methodology in Xcode, with specific techniques to deal with the data constraint and bridge the tool with the local development environments. We then conduct preliminary objective measurements and subjective use studies as proof of concept which demonstrates the satisfactory performance of the proposed framework.\nBy combining the capabilities of context-based RAG and integrated tools for prompt engineering, Copilot for Xcode enhances and streamlines the software development process within Apple's Xcode. The integration of Copilot for Xcode with other cloud-based services like Xcode Cloud can also improve the overall productivity and efficiency in software development, which is especially important to continuous integration (CI) and continuous delivery (CD) in the software development pipeline. As AI-assisted programming tools like Copilot get incorporated into more IDEs, it brings us closer to the realization of Dijkstra's vision, fostering a symbiotic relationship between human programmers and AI-powered tools to achieve more efficient and reliable software development. The proposed methodology is also largely generalizable"}]}