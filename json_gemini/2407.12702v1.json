{"title": "TransCAD: A Hierarchical Transformer for CAD Sequence Inference from Point Clouds", "authors": ["Elona Dupont", "Kseniya Cherenkova", "Dimitrios Mallis", "Gleb Gusev", "Anis Kacem", "Djamila Aouada"], "abstract": "3D reverse engineering, in which a CAD model is inferred given a 3D scan of a physical object, is a research direction that offers many promising practical applications. This paper proposes TransCAD, an end-to-end transformer-based architecture that predicts the CAD sequence from a point cloud. TransCAD leverages the structure of CAD sequences by using a hierarchical learning strategy. A loop refiner is also introduced to regress sketch primitive parameters. Rigorous experimentation on the DeepCAD [43] and Fusion360 [41] datasets show that TransCAD achieves state-of-the-art results. The result analysis is supported with a proposed metric for CAD sequence, the mean Average Precision of CAD Sequence, that addresses the limitations of existing metrics.", "sections": [{"title": "1 Introduction", "content": "Practically every object encountered in daily life originates from a Computer-Aided Design (CAD), highlighting the fundamental role of CAD in industrial manufacturing processes. Currently, the dominant paradigm for CAD design is feature-based modelling [48]. It allows the creation and manipulation of 3D models through a series of features, individual elements or operations (holes, slots, fillets, etc.), that modify the geometry of a CAD model. The process is typically initiated with the design of planar sketches, i.e. collection of loops composed of 2D curves, followed by a CAD operation (extrusion, revolution, etc.) that expands sketches into a 3D solid model. The final model is represented by the sequence of these CAD sketches and operations. Feature-based modelling has been widely adopted, as it enables intuitive design alterations and seamless CAD software integration, making it essential for an iterative development of complex designs. The recent availability of large CAD model datasets, such as ABC [18] and Fusion360 [41], has sparked significant interest in developing learning-based approaches for feature-based modelling. Recent efforts have been focused on deep generative modelling [33, 43, 45,47], where large transformer-based networks are trained to create new CAD models or to automatically complete partial designs"}, {"title": "2 Related Works", "content": "Generative Models for CAD: The advent of large-scale 3D shape datasets [4, 18, 24, 41], combined with the significant progress for generative models in vision [5, 10, 12, 16], has sparked interest in the generation of 3D shapes. Existing methods have been proposed for various 3D representations, including point clouds [1,2,49], 3D meshes [29,38], voxel grids [21,42], and signed distance functions [6,44]. This work focuses on CAD model generation, which compared to the above is parametric and directly editable in CAD software. A line of work explores the generation of the Boundary-Representation (B-Rep), a collection of parametric surfaces connected via a structured topological graph. Solid-Gen [13] considers B-Rep synthesis based on transformers and two-level pointer networks. BrepGen [46] represents a B-Rep via a fixed tree of latent geometry representations that can be generated by a diffusion model. Feature-based CAD generation has also been recently explored. Most relevant to our work is Deep-CAD [43], a non-autoregressive generative model capable of synthesizing novel CAD sequences based on a transformer auto-encoder architecture. In [45, 47] the authors also follow autoregressive strategies. HNC [45] uses a hierarchical model based on high-level concepts and a code tree for CAD model generation and auto-completion. Similarly, in SkexGen [47] a transformer architecture is used to generate CAD models in the sketch-extrude format by encoding the topology and geometry using different codebooks. All the aforementioned works are oriented around 3D shape generation and either do not address the reverse-engineering task or address it via adaptation of generative modelling leading to suboptimal performance."}, {"title": "3 Problem Statement", "content": "A CAD model $C\\in C$ is constructed in a sequence of construction steps. Each step can be seen as a 2D parametric sketch $s \\in S$ (e.g. set of lines, arcs, etc.) followed by a CAD operation $o \\in O$ (e.g. extrusion, revolution, etc.) [43, 47]. Here, C is the set of all possible CAD models, S and O represent the sets of possible CAD sketches and operations, respectively. CAD models constructed exclusively from the extrusion operation type are considered in this work. Extrusion $e \\in E$, where E denotes the set of possible extrusions, is the most common operation and enables the description of a wide range of CAD models [43,45,47]. TransCAD aims at learning how to predict the sequence of CAD construction steps from an input point cloud. Formally, given a point cloud $P = [P_1,...,P_n] \\in R^{n\\times 3}$, where"}, {"title": "4 Hierarchical CAD Sequence Learning from Point Clouds", "content": "TransCAD non-autoregessively learns to predict a CAD sequence from an input point cloud in the format described in Section 3. First, the point cloud is encoded into point features using a standard point cloud encoder. In order to facilitate the learning of CAD sequences, a hierarchical CAD sequence decoding is proposed. In particular, a high-level sequence of embedding corresponding to the loop and extrusion steps is learned. Those embedding are then fed to either a loop or extrusion decoder based on predicted type to learn the loop and extrusion parameters. Finally, the predicted loop parameters are further refined using the actual unquantized loop parameters (ground truth). The overall model architecture is depicted in Fig. 2 and the different components are described below."}, {"title": "4.1 Point Cloud Encoder", "content": "The point cloud encoder $\\Phi_p$ consists of 4 layers of PointNet++ [32] and operates on an input point cloud P. It outputs per-point features encoding local neighborhood information, $F = [f_1...f_n] \\in R^{n\\times d_p}$, that encode local neighborhood information, $d_p$ denotes the dimension of the features. Note that point normals of P are estimated using [35] and are provided as input to $\\Phi_p$ along with its 3D coordinates."}, {"title": "4.2 Loop-Extrusion Decoder", "content": "The main objective of the loop-extrusion decoder $\\Phi_{p,e}$ is to learn a high-level sequence of embedding $F_{p,e} = [f_{p,e}^1,...,f_{p,e}^{L_{p,e}}] \\in R^{d_z\\times L_{p,e}}$ corresponding to loops and extrusions from the point cloud features $F_p$. Here, $d_z$ and $L_{p,e}$ denote the embedding dimension and the length of the sequence, respectively."}, {"title": "4.3 Loop and Extrusion Parametrization", "content": "After obtaining the representation and the type of loop and extrusion steps, the parameters of both loops and extrusions are decoded from these representations using separate decoders.\nExtrusion Decoder: As mentioned in Section 3, the extrusion sequence is described by a sequence of 11 quantized parameters $e^* \\in [0..d_q]^{11\\times L_e}$. In order to obtain these parameters from the extrusion sequence embedding $F_e$, an extrusion decoder $\\Phi_e$ consisting of 3 MLP layers followed by softmax is used. The predicted probabilities of the extrusion sequence parameters $\\check{e}^* \\in [0,1]^{11\\times d_q \\times L_e}$ are compared to the ground truth one-hot-encoded parameters in $e^*$ using a cross-entropy loss, $L_e$.\nLoop Decoder: Similarly to the extrusion decoder, the loop decoder $\\Phi_{\\rho}$ predicts the quantized parameters of the loop sequence $p^* \\in [0..d_q]^{6 \\times n_p \\times L_p}$ as explained in Section 3. Nevertheless, 4 layers of multi-head transformer blocks are employed instead of simple MLP layers. This is due to the sequential nature of loop decoding in contrast to extrusions. Note that a similar strategy"}, {"title": "5 Proposed Evaluation", "content": "In this section, we first outline the limitations of existing evaluation methods in CAD sequence. Then, our new proposed evaluation metric framework for assessing the performance of CAD sequence inference from point clouds is described.\nDeepCAD [43] Evaluation for Feature-based Reverse Engineering: An evaluation framework for CAD sequence was originally introduced in [43] and later used in [27]. This framework includes both accuracy for assessing the fidelity of the predicted sequence and Chamfer Distance (CD) to measure the quality of the recovered 3D geometry. Accuracy is assessed using two metrics, specifically Command Type Accuracy ($\\text{ACC}_{cmd}$) and Parameter Accuracy ($\\text{ACC}_{param}$) defined by\n$\\text{ACC}_{cmd} = \\frac{1}{N_c} \\sum_{i=1}^{N_c} I[t_i = \\hat{t_i}]$,\n$\\text{ACC}_{param} = \\frac{1}{N_c} \\sum_{i=1}^{N_c} \\frac{1}{K} \\sum_{j=1}^{|p_i|} I[|p_{i,j} - \\hat{p_{i,j}}| < \\eta] I[t_i = \\hat{t_i}]$,\nwhere $t_i$ and $\\hat{t_i}$ are the ground truth and predicted command types (for commands representing primitives and extrusions), $p_{i,j}$ and $\\hat{p_{i,j}}$ are ground truth and predicted command parameters, $N_c$ denotes the total number of CAD commands and $I[.]$ is the indicator function. $K = \\frac{1}{\\sum_{i=1}^{N_c} I[t_i = \\hat{t_i}]|p_i|}$ is the total number of parameters of the correctly recovered commands and $\\eta$ is a tolerance threshold. The 3D geometry is evaluated with Chamfer Distance (CD) computed by sampling 2000 points on the ground truth and predicted shapes.\nLimitations: We identify the following limitations of the aforementioned evaluation. (1) The proposed $\\text{ACC}_{cmd}$ overlooks the possibility of over-prediction in the CAD sequence. As indicated in Eq.(4), the computation of this metric sums across the set of ground truth CAD commands $N_c$. A predicted sequence could erroneously include extra loop-extrusion operations and still achieve a full score, as exemplified on the left panel of Fig. 3. (2) The evaluation of $\\text{ACC}_{param}$ is conducted solely on the subset of K accurately identified commands, thus introducing a trade-off between $\\text{ACC}_{param}$ and $\\text{ACC}_{cmd}$. This interdependence complicates the interpretation of results. (3) Assessment of parameter quality via $\\text{ACC}_{param}$ solely in terms of accuracy is failing to distinguish between the magnitudes of errors. A parameter inaccurately placed in an adjacent quantization bucket incurs the same penalty as one with a larger deviation, despite potentially minor implications on the CAD model's final geometry. These limitations cannot be entirely mitigated by complementing CAD command accuracies with the chamfer distance (CD) metric. While CD is a valuable assessment of shape similarity, it does not address the core objective of reverse engineering: to accurately recover the designer's original CAD sequence. Two CAD models might be close in terms of CD yet possess vastly different CAD construction steps (see right panel of Fig. 3).\nProposed Evaluation Framework: To overcome the identified challenges, we introduce the mean Average Precision of CAD Sequence (APCS), a novel evaluation metric tailored for feature-based reverse engineering. APCS adopts the concept of Average Precision (AP) commonly used in other tasks, to quantify the similarity between predicted and ground truth CAD sequences. We introduce the CAD Sequence Similarity Score (CSSS) that can be computed between predicted and ground truth CAD sequences as follows\n$\\text{CSSS}(C, \\hat{C}) = \\frac{1}{2 N_P} \\sum_{j=1}^{N_P} \\sum_{i=1}^{N_p} [S(\\hat{s_{j,i}}, s_{j,i}) \\cdot I[typ (\\hat{s_{j,i}}) = typ(s_{j,i})]] + \\frac{1}{2 N_e} \\sum_{j=1}^{N_e}S(\\hat{e_j}, e_j)$,\nwhere $typ(.)$ is a function that determines the type of each primitive d (arc, line, etc.), and $S(p,\\hat{p}) = e^{-k||P-\\hat{P}||}$ is a scoring function with $S(p, \\hat{p}) \\in [0,1]$ with 1 assigned when predicted parameterization is identical to the ground truth. We define $N_P^f = max(|p_j|,|\\hat{p_j}|)$ where $|.|$ denotes set cardinality, $N^o = max (L_p, \\hat{L_p})$ where $L_p$ is the number of predicted primitives and $\\hat{L_p}$ is the number of ground truth primitives for loop $p_j$ and $N_e = max (L_e, \\hat{L_e})$ where $L_e$ is the number of predicted extrusions and"}, {"title": "6 Experiments", "content": "In this section, the experimental setup is first presented. Then, qualitative and quantitative results are analyzed. Afterwards, the components of TransCAD are ablated. Finally, the limitations of our model are outlined."}, {"title": "6.1 Experimental Setup", "content": "Dataset: For training and evaluation, the DeepCAD dataset [43] is used. The sketch extrusion sequences of the CAD models are processed in quantized (8 bits)"}, {"title": "7 Conclusion", "content": "In conclusion, we propose TransCAD an end-to-end transformer-based neural network that learns to recover the CAD sequence from a given point cloud. Two of the main features of TransCAD are a hierarchical structure that enables the learning of a high-level loop-extrusion sequence and a loop refiner that aims at correcting errors in loop parameter predictions. We also propose a primitive representation in which each primitive is described by the same number of parameters. We identify the limitations of current metrics in the emerging domain of 3D reverse engineering and propose a new metric, the APCS that leads to a fair comparison of parametric CAD sequences. Thorough experiments show that TransCAD achieves state-of-the-art results in different realistic scenarios."}]}