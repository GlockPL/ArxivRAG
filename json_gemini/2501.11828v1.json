{"title": "Fact-Preserved Personalized News Headline\nGeneration", "authors": ["Zhao Yang", "Junhong Lian", "Xiang Ao"], "abstract": "Personalized news headline generation, aiming at\ngenerating user-specific headlines based on readers' preferences,\nburgeons a recent flourishing research direction. Existing studies\ngenerally inject a user interest embedding into an encoder-\ndecoder headline generator to make the output personalized,\nwhile the factual consistency of headlines is inadequate to be\nverified. In this paper, we propose a framework Fact-Preserved\nPersonalized News Headline Generation (short for FPG), to\nprompt a tradeoff between personalization and consistency. In\nFPG, the similarity between the candidate news to be exposed\nand the historical clicked news is used to give different levels of\nattention to key facts in the candidate news, and the similarity\nscores help to learn a fact-aware global user embedding. Besides,\nan additional training procedure based on contrastive learning is\ndevised to further enhance the factual consistency of generated\nheadlines. Extensive experiments conducted on a real-world\nbenchmark PENS\u00b9 validate the superiority of FPG, especially\non the tradeoff between personalization and factual consistency.", "sections": [{"title": "I. INTRODUCTION", "content": "News headline generation, intended to build a brief, in-\nformative, coherent headline for the given news article, has\nbeen perceived as a headline-specialized summarization task\nfor decades [1]\u2013[10]. Recently, personalized headline genera-\ntion [11], i.e., generating a user-specific headline based on the\nuser's reading interest, was proposed to produce eye-attracting\nheadlines rather than potential clickbait. Its underlying idea\nis that readers with different preferences can find their focal\ncharacters even in the same news, as illustrated in Fig.1.\nHowever, excessive personalization may threaten the factual\nconsistency of news headlines, which is an imperative matter\nof principle in precision journalism [12].\nTo this end, we desire to reconcile the personalization\nand factual consistency of generated headlines. The following\nchallenges remain unsolved. First, these two goals seem to run\ncounter to each other. More personalization encourages more\nfacts related to historical clicks in the headline, while high\nconsistency requires preserving more facts from the candidate\nnews in the title. Hence, jointly optimizing both goals in\na unified framework might be challenging. Second, neither\npersonalization nor factual consistency can be simply judged\nwith existing metrics, a reasonable comprehensive evaluation\nmethod is in urgent demand.\nTo remedy these challenges, we propose a model\nnamed FPG (Fact-Preserved Personalized News Headline\nGeneration), which utilizes an encoder-decoder framework that\nadapts Transformer [13] with a history encoder, a personalized\nnews encoder, and a user-guided decoder. The history encoder\nis analogous to existing work modeling users' interests based\non their historical behaviors [14]\u2013[17]. The personalized news\nencoder leverages the similarity between the candidate news\nand historical clicks to attach various importance to clicked\nnews. The user-guided decoder learns a fact-aware user em-\nbedding to perturb headline generation based on personalized\ncandidate news representations. Furthermore, an enhanced\ntraining phase based on contrastive learning [18], [19] is\nleveraged for buoying the factual consistency of generated\nresults. Similar techniques were recently observed effectively\nin abstractive summarization [20]. For evaluation, we examine\ngenerated headlines based on personalization, factual consis-\ntency, and coverage, which will be detailed in Section V-C.\nIn a nutshell, our contributions are: (1) We are the very first\nattempt to make a tradeoff between personalization and factual\nconsistency for news headline generation. (2) We propose an\nend-to-end model FPG, equipped with a personalized news\nencoder that selectively concentrates on fact-consistent user\ninterests via attention between the candidate news and histori-\ncal clicks. Meanwhile, a training method based on contrastive\nlearning takes factual consistency of the generation as a posi-"}, {"title": "II. RELATED WORK", "content": "Previous studies related to our task can be divided into two\nmajor categories: content-based headline generation and user-\noriented headline generation.\nContent-based headline generation aims to yield a con-\ncise, coherent, informative headline for the given article based\non its content\u00b2, which is similar to the text summarization\ntask. The extractive approaches [1], [2] select a subset of\nactual sentences from the original article to compose a news\nsummary, resulting in incoherent headlines with inadequate\ninformation. The abstractive models [4], [5], [7], [21], [22]\nusually instantiate an encoder-decoder framework to build\ncompact and coherent titles through learning the representa-\ntions of the content. In recent years, Transformer-based pre-\ntrained models [23]\u2013[25] have reached SOTA for content-\nbased headline generation [9], [10], [26], [27]. However,\nthese approaches have mediocre performance in personalized\nsituation due to rare consideration for user preference.\nUser-oriented headline generation desires to build a head-\nline that not only contains critical news facts but also grabs\nusers' curiosity, promoting reading interests. This may require\nauxiliary user information, e.g., users' profile, landing page,\nhistorical clicks, etc. Some researchers propose to revamp\nheadline styles [28] to attract readers' attention. Implicit\napproaches [28]\u2013[30] differentiate the sentence into content\nand style representations to implicitly perform style trans-\nfer. The explicit approaches [31]\u2013[34] directly identify style-\noriented examples or keywords for decorating titles. However,\nlimited styles may not satisfy various users, and over-decorated\nheadlines may also derive clickbait.\nRecent studies on personalized text generation emphasize\navoiding clickbait in engaging headlines [11], [35]\u2013[37], but\nincorporating users' historical information may disrupt head-\nline consistency due to global user embedding interference."}, {"title": "III. PROBLEM FORMULATION", "content": "The problem of personalized headline generation can be\nformulated as follows. Given a user u, we denote u's historical\nclicked news as $C_u = [c_1, c_2,\u2026\u2026\u2026, c_N]$ where $c_u$ (j =\n1,..., N) is the j-th clicked news headline and N is the length\nof the clicked sequence. Each news headline c is composed\nof a word sequence, i.e., \u0441 = $[w_1^c, w_2^c,...,w_T^c]$, where T\nis the maximum length of the headline, $w \\in V$ for all\n$1 \\le j \\le T$ and V is the word vocabulary. Then, given\na candidate news v to be exposed to the user u where its\nnews body X = $[w_1, w_2, ..., w_M]$ contains a maximum of\nM words, our target is to build a specific-customed headline\n$Y_u = [y_1, y_2,...,y_T]$ for the user u based on his/her"}, {"title": "IV. METHODOLOGY", "content": "This section details our proposed FPG model, which is\nillustrated in Figure 2, and we adopt Transformer [13] as the\nbackbone of FPG.\nA. History Encoder\nAs demonstrated in Fig.2(a), the history encoder aims to\nlearn users' interest representations based on their historical\nbehaviors. For each headline c in the clicked sequence $C_u =$\n$[c_1, c_2,..., c_N]$ of the user u, the encoder first converts c from\na sequence of words into a sequence of embedding vectors,\ni.e., c = $[w_1, w_2, ..., w_T]$, $w_j \\in R^{1\\times d_e}$. Then, the embeddings\nare fed into a GRU [38] to learn the semantic hidden state\nof each word, i.e., h = $[h_1, h_2,..., h_T]$, $h_j \\in R^{1\\times d_e}$.\nThe weighted sum of h by Eq.(2) is considered the news\nrepresentation of c.\n$a_j = Softmax(h^Ttanh(V_a h + b_a))$    (1)\n$e_c = \\sum_{j=1}^{T} a_j h_j$  (2)\nWhere $V_a \\in R^{d_e\\times d_e}$, $b_a \\in R^{d_e\\times 1}$. We denote $E_u =\n[e_1, e_2,..., e_N]$ as the news-level user interests of u, where\neach $e_j$ is obtained from the j-th news headline in u's clicked\nsequence, i.e., $C_u$\nB. Personalized News Encoder\nAs shown in Fig.2(b), the personalized news encoder intends\nto encode a candidate news body based on the similarity\nbetween the candidate news and news-level interests of the\ncorresponding user. We expect the news body to exploit some\nvaluable information from news-level user interests, which\nshould share semantical similarity with partial content, to learn\npersonalized representations. Therefore, another history-cross"}, {"title": "attention sub-layer", "content": "attention sub-layer is used to capture the interaction between\nnews body and historical behaviors: the query $Q_h$ is the linear\nprojection of the news body representations X while the key\n$K_h$ and value $V_h$ are projections of news-level user interest\nembeddings $E_u$.\n$Q_h = XH^Q, K_h = EH^K, V_h = EH^V$   (3)\n$X_p = Softmax(\\frac{Q_hK_h^T}{\\sqrt{d_e}}) V_h$    (4)\nWhere $H^Q, H^K, H^V \\in R^{d_e\\times d_e}$ are learnable parameter ma-\ntrices. Through such interaction, information from historical\nclicks, which is semantically similar to the candidate news,\nis attached to the representations of the news body implicitly,\nenhancing attention to the user's fine-grained interests. For\nexample, analogous entities that appear both in clicked news\nand the candidate news directly reflect the user's potential\ninterests should be spotlighted. After utilizing N encoder\nblocks, we obtain the history-aware representations of the\ncandidate news, i.e., $X_{enc}$\nC. User-guided Decoder\nAs illustrated in Fig. 2(c), the user-guided decoder generates\na personalized headline under the guidance of a global user\ninterest embedding.\nInstead of learning a fixed embedding for each user [11],\nwhich may contain inconsistent information with the candidate\nnews, our approach desires to learn a fact-aware global user\nrepresentation based on the relevance of news-level interests\nto the candidate news. The user embedding is the weighted\nsummation of news-level user interests:\n$u = \\sum_{j=1}^{N} \\alpha_j e_j$   (5)\nWhere ${\\alpha_1,..., \\alpha_N}$ are attention scores of history-cross attention\nsub-layer in the first news encoder block.\nTo avoid additional edits to the decoder input format or\nextra training parameters, we simply replace the [BOS]\u00b3 token\nwith the user embedding u so that the model again considers\nthe user's preference at every decoding step, enhancing the\npersonalization of the generated headline. At each decoding\nstep t, the input embeddings of the partially generated headline\nis $Y_u = [u; y_1, ..., y_{t-1}]$,where $u, y_j \\in R^{1\\times d_e}$, for all $1 <\nj \\le (t \u2212 1)$. $Y_u$ is then fed into the masked self-attention\nlayer and aligned with personalized encoder representations\n$X_{enc}$. After N blocks, the output of the decoder at time step t\nis $S \\in R^{1\\times d_e}$. The probability distribution P over the whole\nvocabulary can be calculated as:\n$P(\\hat{y_t}) = Softmax(SW + b)$    (6)\nWhere $W_o \\in R^{d_e\\times ||V||}$ and $b_o \\in R^{1\\times ||V||}$ are learnable\nparameter matrices. We use the negative log-likelihood as the\nloss function to train the headline generation model:\n$\\mathcal{L}_{NLL} = -\\sum_{i=1}^{T} log P(y_i|y_1,..., y_{i-1}; X, C)$    (7)"}, {"title": "D. Fact-enhanced Training", "content": "The modules mentioned above allow news-level and global\nuser representations to be involved in personalized headline\ngeneration, while auxiliary user information may also bring\ninconsistency in headline generation. Especially when none\nof historical clicks are relevant to the candidate news, the user\nembedding may induce misinformation at the decoding step.\nTherefore, an additional mechanism is required to enhance the\nfactual consistency of generated personalized headlines.\nPrevious studies have shown that simply removing un-\nfaithful instances from the supervision data [39] or utilizing\nmethods such as reinforcement learning [40] and contrastive\nlearning [20], [41] can enhance the consistency in text genera-\ntion. Motivated by [20], we apply a multi-stage fact-enhanced\ntraining phase, as demonstrated in Algorithm 1, to improve\nthe factual consistency of generated headlines by minimizing\na contrastive learning loss:\n$\\mathcal{L}_{CLL} = -\\mathbb{E}_{X,C,Y^+} \\mathbb{E}_{D^*} log P(y^+; x, c)$   (8)\n$- \\mathbb{E}_{X,C,Y^-} \\mathbb{E}_{D^*} log(1 \u2013 P(y^\u2212; x, c))$"}, {"title": "V. EXPERIMENT SETTINGS", "content": "We validate our proposed method on the PENS benchmark,\nwhich comprises a news corpus, 500,000 anonymized user\nclick behavior data from Microsoft News involving 445, 765\nusers, and manually annotated personalized headlines. The test\nset includes 50 news of interest chosen by 103 annotators to\nbuild their clickstream, along with 200 news articles for which\nthey provided preferred headlines, serving as personalized\nheadlines. More details on PENS can be found in [11].\nDue to the lack of reliable personalized headlines during\nthe training phase, distant supervision is conducted to train our\nmodel. We take advantage of historical clicks to model a user's\ninterests and approximate original headlines of newly clicked\nnews within this impression as imperfect labels for training.\nIt's notable that considering some news that have appeared in\nthe clickstreams of too many users as personalized headlines\nis unreasonable. To mitigate this problem, we have limited the\nnumber of users associated with each news during the training\nprocess. This limitation ensures that our model doesn't overly\nfocus on news articles that have a broad appeal and have been\nclicked on by a vast number of users. The training data with the\nlimitation number l is noted as $D_l$. We use $D_5$ for our major\nexperiments, where the same news article in the training set\nis clicked by a maximum of five users.\nIn addition, we only pre-train the headline generator with\nthe corpus that excludes candidate news used in the training\nand test set, indicated as C. This decision stemmed from our\nobservation that, despite achieving higher coverage scores, the\nmodel cannot acquire the capability to decorate user-specific\nheadlines, which contradicts our goal of personalized headline\ngeneration. The statistics of datasets are shown in Table I.\nB. Baselines\nBaselines consist of non-personalized and personalized ap-\nproaches. We include some SOTA headline generation models:\n(1) PGN [22] is a seq2seq model with a copy mechanism. (2)\nPG+Transformer [42] combines a transformer-based encoder\nwith the pointer-generator network. (3) Transformer [13] is\nan encoder-decoder model based only on the attention mech-\nanism. (4) BART [25] is a highly effective large pre-trained\ntransformer-based model for text generation. Besides, we also\ncompare with some baselines mentioned in [11], including\nNPA [16], EBNR [43], NRMS [15], and NAML [14].\nOur proposed model is denoted as FPG-GRU. By replacing\nthe GRU layer in our history encoder with other structures like"}, {"title": "C. Evaluation Metrics", "content": "Traditional metrics like ROUGE [44] mainly assess text-\nreference overlap and fail to capture headline personalization\nand consistency with content. Thus, we adopt a three-pronged\napproach to comprehensively evaluate headline quality.\n1) Personalization: While lacking a valid metric for per-\nsonalization, we can gauge it by comparing generated head-\nlines to users' historically clicked titles, which reflect their\nfine-grained reading preferences as the personalization score.\n$P_{sim} (max/avg) = Max/Mean_{c \\in C_u} sim(c, y)$     (9)\nWhere $C_u$ is the click sequence of user u, y is the generated\nheadline, sim indicates similarity functions. We report the\nmean and maximum value of all cosine similarity scores\nto evaluate fine-grained personalization, noted as $P_c(max)$\nand $P_c(avg)$. A high maximum score indicates similarity\nto at least one reader's historically clicked title related to\ntheir interest, while the mean score reflects overall similarity\nbetween historical titles and the generated headline.\n2) Factual Consistency: The factual consistency scores\nreflect the news headline's faithfulness to the source article.\nWe utilize FactCC [45], a weakly-supervised, model-based\napproach, to evaluate the factual consistency score.\n3) Coverage: We assess the informativeness and coverage\nof generated headlines by reporting the average F1 of ROUGE\nscores [44]. The coverage scores also partially reflect general\npersonalization, given that manually-written headlines in test\nset mirror annotators' personalized reading preferences [11].\nD. Implementation Details\nThe head number in multi-head attention layer is 12. The\nnumber of encoder and decoder block N is 6. The dimension\n$d_e$ is set to 768. All components of Transformer are initialized\nwith BART-base parameters\u2074. The optimizer is AdamW [46]\nwith $\u03b2_1 = 0.9$ and $\u03b2_2 = 0.99$. The epoch number for the\npre-trained phrase is 5, and 5, 9, 1 for each training stage\nafterward. The learning rates for each training stage are set\nto 3e - 5, le - 4, 3e - 5, and le - 7, respectively. During\ndecoding, we use beam search with beamsize = 3. We trained\nand evaluated the model on a single NVIDIA V100 GPU."}, {"title": "VI. EXPERIMENT RESULTS", "content": "The main results are shown in Table II. We evaluate gen-\nerated personalized headlines through three aspects, namely\ncoverage, factual consistency, and personalization.\nCoverage indicates that our method FPG-GRU achieves the\nhighest scores at ROUGE-1, -2, and -L with 27.33, 10.51,\nand 23.30, significantly outperforming other baselines. This\nindicates that our model generates more informative, fluent\nheadlines, and matches the users' general interests well.\nB. Case Study\nFinally, we exhibit an interesting case in our experiment, as\nshown in Table III. We compare our generated personalized\nheadlines with outputs from the base headline generator,\ni.e., BART, and with personalized titles built by SOTA of\npersonalized headlines generation, i.e., PENS-NAML.\nNotably, previous models trained from scratch exhibited\nfactual and syntactic errors. For instance, when the source\nnews article reported \"Justin Rose\" as the golfer's score,\nthe generated headline mistakenly mentioned \u201cTiger Woods\".\nAnalyzing the user's click history, it's evident he/she is a\ngolf tournament enthusiast, possibly favoring \u201cTiger Woods\".\nWhile personalized headlines should emphasize such interests,\nthey must maintain factual consistency. In contrast, BART\nfaithfully reflected the news content, generating a more co-\nherent and factual headline despite lacking personalization.\nMeanwhile, our FPG-GRU strikes a balance between user\nappeal and factual consistency, offering a more personalized,\ninformative, and consistent headline. It highlights relevant\nphrases like \"Tiger Woods\" and \"U.S. Open\" and provides\nadditional details such as \"65\" and \"Pebble Beach\", aligning\nbetter with the user's interests.\nVII. CONCLUSION AND DISCUSSION\nIn this paper, we proposed a framework FPG to make\na trade-off between personalization and factual consistency\nin personalized news headline generation. This framework is\nunderpinned by the principle of user appeal, leveraging the\nsemantic similarity between the candidate news and the user's\nhistorical click patterns to selectively emphasize key facts\nthat align with the user's nuanced interests. Meanwhile, the\nglobal user embedding subtly influences the decoder's ultimate\nprediction, thereby infusing a degree of personalization into\nthe generated headlines. In the pursuit of consistency, we\nhave engineered a fact-aware user embedding that serves to\nmitigate the propagation of inconsistent information. Addi-\ntionally, we have implemented a contrastive learning-based\nfactual enhancement training regimen, which bolsters the\nmodel's proficiency in preserving factual consistency between\nthe generated headlines and the source news. Extensive exper-"}]}