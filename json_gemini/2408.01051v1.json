{"title": "From Stem to Stern: Contestability Along Al Value Chains", "authors": ["Agathe Balayn", "Yulu Pi", "David Gray Widder", "Kars Alfrink", "Mireia Yurrita", "Sohini Upadhyay", "Naveena Karusala", "Henrietta Lyons", "Cagatay Turkay", "Christelle Tessono", "Blair Attard-Frost", "Ujwal Gadiraju"], "abstract": "This workshop will grow and consolidate a community of interdisciplinary CSCW researchers focusing on the topic of contestable AI. As an outcome of the workshop, we will synthesize the most pressing opportunities and challenges for contestability along AI value chains in the form of a research roadmap. This roadmap will help shape and inspire imminent work in this field. Considering the length and depth of AI value chains, it will especially spur discussions around the contestability of AI systems along various sites of such chains. The workshop will serve as a platform for dialogue and demonstrations of concrete, successful, and unsuccessful examples of AI systems that (could or should) have been contested, to identify requirements, obstacles, and opportunities for designing and deploying contestable AI in various contexts. This will be held primarily as an in-person workshop, with some hybrid accommodation. The day will consist of individual presentations and group activities to stimulate ideation and inspire broad reflections on the field of contestable AI. Our aim is to facilitate interdisciplinary dialogue by bringing together researchers, practitioners, and stakeholders to foster the design and deployment of contestable AI.", "sections": [{"title": "1 BACKGROUND", "content": "In recent years, the Computer-Supported Cooperative Work (CSCW), Human-Computer Interaction (HCI), and Artificial Intelligence (AI) communities have become interested in contestable AI as a means to confront, acknowledge, and rectify the negative impacts caused by AI systems. Contestable AI refers to AI systems that are open and responsive to human dispute and intervention throughout their lifecycle [2]. This interest is evident in theoretical and empirical research and practice [3, 11, 14, 17], as well as Al governance initiatives that aim to explore contestability as a means to enhance human agency [8] and address ethical and societal implications of AI. For example, consider the 2020 United Kingdom school exam grading controversy [12]: students protested the use of an AI algorithm to determine their grades, holding signs that read \"Your algorithm does not know me.\" This highlighted the urgent need for Al systems and processes that are open to human intervention and responsive to disputes.\nContestable Al is a growing interdisciplinary field. Legal scholars have proposed the right to contest [5], which ensures a level of protection for individuals affected by algorithmic decisions [9]. Meanwhile, HCI and CSCW researchers view contestability from a design perspective, focusing on making AI systems contestable to developers and end users by design [1, 2, 10, 21]. While these efforts have made significant progress in directing the conversation towards making AI more responsive and accountable through ongoing learning based on feedback and contestation [16], their main focus remains on contesting AI design or outputs [4] within specific domains such as content moderation [19].\nA broader perspective on contestability can be gained by considering Al systems as dynamic sociotechnical systems with temporal and spatial dimensions. This approach expands our horizons to consider contestable AI as a value chain problem\u00b9 [6, 7, 20]). This encompasses the entirety of the AI lifecycle, including various actions taken by different actors: the extraction of materials, the construction of physical infrastructures, the decision-making process in data collection, model development, modes of human oversight and the impact on individuals, society and the environment. CSCW methodologies and prior insights around collaborative work are of particular relevance to investigating the AI value chain through the lens of contestability.\nExploring contestable AI along the AI value chain broadens the scope of potential sites and angles for contestation. For instance, harms arising further up the Al value chain, such as poor labor conditions, negative environmental impacts, and the inappropriate collection and use of personal data, remain relatively absent from the academic discourse around contestable AI. In recent years, activist efforts have emerged in response to the growing concerns surrounding AI systems and their impact on society. Should those activities fall into our discussion of contestable AI, and if so, how? One notable example is the Data Centre Activism in Chile, Ireland, and the Netherlands [13]. Activists in these countries have protested against the construction and expansion of data centers, citing concerns about their environmental impact, energy consumption, and the potential for Al systems to exacerbate social inequalities. These real-life examples show that contestability could entail public discourse and policy debates, involving individuals utilizing social media platforms to raise their concerns or actively engaging in decisions around AI. However, there is a lack of discussion regarding how these practices fit within the scope of contestable AI and the unique challenges and opportunities faced.\nMoreover, adopting the value-chain perspective in contestable Al exposes and prompts discussion of the inherent challenges of attributing responsibility. Contesting AI may face the \"many hands problem,\" as the design or output being contested may result from a chain of different actors contributing in different ways and capacities to the production, deployment, and use [7]. This raises crucial questions: what and who exactly are we contesting, and who precisely bears the responsibility to address the contestation? It also opens the door to moving beyond individualistic approaches, and exploring how communities or society can contest AI collectively.\nTo address these issues and support this emerging research area, the goal of this workshop is to explore the impacts, challenges, opportunities, and limitations of contestable Al along the AI value chain around the world. We are particularly interested in empirical studies, including real-world case studies and user studies with both positive and negative outcomes, along with reflections on lessons learned. Additionally, we seek descriptions of unique contexts for contestable AI and their varied and specific challenges, and visionary discussions, and proposals about the implications of"}, {"title": "2 WORKSHOP GOAL", "content": "Through a series of talks, keynotes, and group work, we expect the workshop to achieve the following outcomes:\n\u2022 Developing a holistic understanding of the requirements, challenges, existing support, and forthcoming opportunities to inform future research and practice on contestable AI.\n\u2022 Identifying and synthesizing unique contributions of the CSCW community in contestable AI.\n\u2022 Fostering an interdisciplinary community of researchers and practitioners spanning relevant disciplines (e.g., HCI, AI, law, economics, political science, among others).\n\u2022 Developing shared vocabulary and priorities across disciplines and communities to design for contestability along AI chains.\n\u2022 Publishing an article in the Communications of the ACM (CACM) sketching out a roadmap for contestable Al research that can inspire and shape research in this nexus over the next 10 years."}, {"title": "3 WORKSHOP STRUCTURE", "content": ""}, {"title": "3.1 Workshop schedule", "content": "We schedule the workshop for one day, as outlined in Table 1. After the workshop, the organizers and interested participants will gather (virtually), generate a summary of the key insights gleaned from the workshop discussions, and craft a roadmap for future research."}, {"title": "3.2 Activity Description", "content": "The workshop will consist of the following activities.\nParticipant presentation: We will ask each participant to present an overview of their submission. Depending on the number of submissions, we will accommodate the length of the presentations to create room for every submission to be presented."}, {"title": "4 PRACTICALITIES", "content": "We envision the workshop to be held primarily in-person, with a limited capacity for virtual participation, using an online goup chat. Plenary sessions will be streamed via videoconferencing. To accommodate participants who may not be able to attend in person, we will allow them to present their work remotely via asynchronous video recordings or through live remote presentation. If more than six participants are online, we will group them and accommodate their participation in the group activities. Five workshop organizers will potentially be online and involved via Zoom.\nTo support the various activities, we will need access to a standard conference room that can accommodate up to 40 people (we envision a maximum of 30 participants in the workshop, and 10 in-person workshop organizers). Standard audiovisual equipment for the presentations and group sessions will also be required.\nIdeally, the seating will be flexible, to cater for the presentation and group activities. Several tables to conduct the group activities will be needed. Other resources such as whiteboards, large blank papers, pens, and sticky notes can facilitate group sessions."}, {"title": "5 WORKSHOP ATTENDANCE", "content": ""}, {"title": "5.1 Workshop participants", "content": "We will recruit workshop participants via a call for submissions. Each author of accepted submissions will be granted a seat at the workshop. The call for submissions will be circulated on various HCI mailing lists and social media. Submission authors will be asked to send their submissions to the email address for the workshop before September 15th, 2024. At least two workshop organizers will review each submission.\nIf we do not reach the maximum number of participants via this process, we will open participation to people who do not have any submissions. For that, we will invite interested people to send a brief statement describing one's motivation to the workshop organizers who will then confirm the participant's spot. We will also directly reach out to our contacts, e.g., from civil society, and invite them to ensure participants' diversity.\nWe will invite submissions that can contribute to raising discussions for setting an agenda around contestable AI along the AI value chain. These submissions can focus on various sites of the Al value chain, and discuss who might want to contest what and towards which end-goal, when and how to contest, the challenges, needs, supports, and opportunities for contestation, and the limitations of current contestability works. The submissions should not exceed 4000 words with unlimited references and supplementary material.\nWe encourage submissions from various disciplines. Not only can these submissions deal with HCI/CSCW or algorithmic work, but also policy perspectives and the views of advocacy organizations."}, {"title": "5.2 Workshop organizers", "content": "The diverse backgrounds of the workshop organizers allow us to cover computer science and human-computer interaction, across various continents, with expertise primarily stemming from academia but also industry and policy making.\n\u2022 Agathe Balayn is a postdoctoral researcher at Deft University of Technology. Her work lies at the intersection between the technical underpinnings of AI, their operationalization in practice, and AI policy. She has conducted extensive qualitative work in organizations producing and consuming Al systems, to understand the concerns of stakeholders along the Al supply chain, the factors impacting their practices, and the harms that might arise.\n\u2022 Yulu Pi is a PhD student at the Centre for Interdisciplinary Methodologies, University of Warwick. She also works on the IN-DEPTH EU AI TOOLKIT project for the Leverhulme Centre for the Future of Intelligence. Her research focuses on empowering those affected by AI through explainability and contestability. Her work extends beyond technical and design issues to consider how these concepts can be incorporated into Al governance.\n\u2022 David Gray Widder studies how people creating Al systems think about the downstream harms their systems make possible, and the wider cultural, political, and economic logics which shape"}]}