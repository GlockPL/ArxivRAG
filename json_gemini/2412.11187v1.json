{"title": "Analyzing the Attention Heads for Pronoun Disambiguation in Context-aware Machine Translation Models", "authors": ["Pawe\u0142 M\u0105ka", "Yusuf Can Semerci", "Jan Scholtes", "Gerasimos Spanakis"], "abstract": "In this paper, we investigate the role of attention heads in Context-aware Machine Translation models for pronoun disambiguation in the English-to-German and English-to-French language directions. We analyze their influence by both observing and modifying the attention scores corresponding to the plausible relations that could impact a pronoun prediction. Our findings reveal that while some heads do attend the relations of interest, not all of them influence the models' ability to disambiguate pronouns. We show that certain heads are underutilized by the models, suggesting that model performance could be improved if only the heads would attend one of the relations more strongly. Furthermore, we fine-tune the most promising heads and observe the increase in pronoun disambiguation accuracy of up to 5 percentage points which demonstrates that the improvements in performance can be solidified into the models' parameters.", "sections": [{"title": "1 Introduction", "content": "In Context-Aware Machine Translation (MT), the context sentences are available to the system and can be used to maintain coherence of the translation and to resolve ambiguities (Agrawal et al., 2018; Bawden et al., 2018; M\u00fcller et al., 2018; Voita et al., 2019b). Both the source-side (sentences in the source language) and target-side context (the previously translated sentences) can be used as context. Although many novel architectures have been proposed to tackle the task of Context-aware MT (Tu et al., 2017; Bawden et al., 2018; Miculicich et al., 2018; Maruf et al., 2019; Huo et al., 2020; Zheng et al., 2021), we limit our investigation to the standard Transformer (Vaswani et al., 2017) architecture (often referred to as the single-encoder architecture), because of its simplicity and demonstrated high performance (Sun et al., 2022; Majumde et al., 2022; Gete et al., 2023; Post and Junczys-Dowmunt, 2023; Mohammed and Niculae, 2024). For the Transformer model to be successful in the task of Context-aware MT, it has to integrate the contextual information and utilize it to produce the translation autoregressively. During inference, the contextual information has to come through the mechanism of multi-head attention. Motivated by the findings that attention heads can learn to perform seemingly specific functions (Clark et al., 2019; Voita et al., 2019c; Jo and Myaeng, 2020; Olsson et al., 2022), we hypothesize that certain heads in a model can be crucial for the context utilization. We study the case of pronoun disambiguation, where the selection of the correct pronoun is dependent on the antecedent (contextual cue), which can be present in the previous (context) sentences. Therefore, we analyze the translation models through the lens of the attention given by the attention heads to the plausible relations that could influence the prediction of a pronoun:"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Context-aware Machine Translation", "content": "A direct approach to include previous sentences as context in MT is to concatenate them with the current sentence. This method is often called the single-encoder architecture, as the basic encoder-decoder architecture is used (Tiedemann and Scherrer, 2017; Ma et al., 2020; Zhang et al., 2020). The multi-encoder approach is to encode the context sentences by a separate encoder (Jean et al., 2017; Miculicich et al., 2018; Maruf et al., 2019; Huo et al., 2020; Zheng et al., 2021). Existing studies also investigated more exotic architectures (Miculicich et al., 2018; Bao et al., 2021; Chen et al., 2022; Maka et al., 2024), post-processing translation (Voita et al., 2019b,a), and employing a memory mechanism (Feng et al., 2022; Bulatov et al., 2022). Yin et al. (2021) applies attention regularization that concentrates on the context phrases marked as important by human translators which is similar to Head Tuning method in our work. In recent years, the single-encoder architecture has seen increased prominence in the literature because of its simplicity and robust performance (Majumde et al., 2022; Gete et al., 2023; Post and Junczys-Dowmunt, 2023; Mohammed and Niculae, 2024), even on long context sizes (of up to 2000 tokens) when data augmentation was used (Sun et al., 2022). For this reason, this paper focuses on this architecture."}, {"title": "2.2 Explaining Models", "content": "Explaining models' decisions or behaviors is an important issue from the safety and ethical considerations (Madsen et al., 2022). Additionally, we argue that they can also be valuable from the engineering perspective, where the shortcomings of the models can potentially be addressed when they are brought to light. Numerous methods explaining Natural Language Processing models have been proposed (Bau et al., 2018; Toneva and Wehbe, 2019; Ferrando et al., 2022; Langedijk et al., 2024; Meng et al., 2024). Even though some works have argued against using raw attention scores as explanations themselves (Jain and Wallace, 2019) the attention mechanism is an important part of the Transformer and many researchers concentrated their efforts to understand its influence on the model's behavior (Wiegreffe and Pinter, 2019; Abnar and Zuidema, 2020; Kobayashi et al., 2020, 2021; Bogoychev, 2021; Gheini et al., 2021; Mohebbi et al., 2023). Our work is motivated by the findings suggesting that some heads have specific roles or functions (Clark et al., 2019; Voita et al., 2019c; Olsson et al., 2022) that can be linked to linguistic relations (Vig and Belinkov, 2019; Tenney et al., 2019; Jo and Myaeng, 2020). Several works have investigated the models in MT (Goindani and Shrivastava, 2021; Voita et al., 2021; Sarti et al., 2023; Mohammed and Niculae, 2024). In contrast, our work focuses on identifying where in the model's architecture the contextual information is integrated. We also investigate the influence of the alterations to the model (i.e., modifying the attention scores corresponding to the plausible relations) on the context usage."}, {"title": "3 Methods", "content": "We denote the tokenized source and target sentences of example d in the dataset as $S_d$ and $T_d$ respectively. We define the sets containing the indices of contextually important tokens (context cues) on the source $S_c$ and target side $T_c$, and the sets containing the indices of contextually dependent tokens on the source $S_p$ and target side $T_p$. On the target side, the token indices denote the predicted tokens, rather than the input tokens, which are shifted right during training and contrastive evaluation. This way we analyze the model during the inference step when the context-dependent tokens $T_p$ are being predicted. Consequently, the context cue tokens on the target side Ye also mark the steps where those tokens are being generated by the model. Because the input tokens have been found to retain their identity throughout the layers of the Transformer (Brunner et al., 2020), we add the set $T_{C+1}$ referring to the contextually important tokens on the input. In the case of ambiguous pronouns, the context cues tokens are the antecedents and the contextually dependent tokens are the pronouns, both on the source and target side. We investigate the relations between the following token sets (see Figure 1 for an example):\n\u2022 from source dependent to source important tokens ($S_P \\rightarrow S_c$) - in the encoder's self-attention;\n\u2022 from target dependent to source important tokens ($T_P \\rightarrow S_c$) - in the decoder's cross-attention;\n\u2022 from target dependent to source dependent tokens ($T_p \\rightarrow S_p$) - in the decoder's cross-attention;\n\u2022 from target dependent to target important tokens ($T_p \\rightarrow T_c$) - in the decoder's self-attention;\n\u2022 from target dependent to target important tokens on the input ($T_p \\rightarrow T_{C+1}$) - in the decoder's self-attention.\nWe examine the models through three methods. Attention Scores (Section 3.1) and Score-Accuracy Correlation (Section 3.2) are based on observing the model's behavior during the task of contrastive disambiguation. The method Modifying Heads (Section 3.3) introduce a form of disturbance into the functioning of an attention head."}, {"title": "3.1 Attention Scores", "content": "To find the heads that learned to pay high attention to the relations of interest we measure and average the attention scores $Z^{l,h}$ of each head h in every layer l for all relations of interest. For the contextually important and dependent phrases that span over multiple tokens, we take the maximum score."}, {"title": "3.2 Score-Accuracy Correlation", "content": "The fact that a particular attention head - on average pays attention to the relation of interest does not necessarily mean that the head is crucial or helpful for disambiguation. Therefore, we want to measure how the head's attention scores of a relation correspond to the model correctly disambiguating a particular example. We define a variable I as follows:\n$I^d =\\begin{cases}1, \\text{ if correctly scored},\\\\0, \\text{ otherwise,}\\end{cases}$\nwhere d is an example from the contrastive dataset D. We calculate the point-biserial correlation coefficient between attention scores given by each head $Z^{l,h}$ and the variable I. The accuracy on the whole dataset can be calculated as $\\sum_{d \\in D} I^d/|D|$."}, {"title": "3.3 Modifying Heads", "content": "The goal of Modifying Heads is to adjust the behavior of the head in a controlled manner. It modifies attention scores from a particular token ensuring that the total attention score given to a target subset of tokens equals a desired value C while preserving the pre-softmax attention scores H for all other target tokens. Modifying Heads allows us to experimentally test the behavior of the model if one (or more) of its heads were better or worse at the function of attending to the context-informative tokens. For simplicity, we jointly label the attending tokens (left-hand-side of the arrow $\\rightarrow$) as y and attended tokens (right-hand-side of the arrow $\\rightarrow$) as X. Consequently, $Y \\rightarrow X$ can represent all investigated relations inside the corresponding attention module. Modifying Heads can be formulated as follows:\n$H_{i,j}^{l,h,d} = \\log(\\frac{C}{|X^d|(1-C)} \\sum_{k \\in X^d \\setminus X^d} \\exp(H_{i,k}^{l,h,d}))$\n$\\forall i \\in Y^d, j \\in X^d,$\nwhere H represent the updated pre-softmax attention scores, H are the original pre-softmax scores, $k \\in X^d \\setminus X^d$ are the attended tokens not present in the subset of interest $X^d$. The derivation of the formula can be found in Appendix A."}, {"title": "4 Experiments", "content": "All our experiments are implemented\u00b9 in Hugging-face transformers framework (Wolf et al., 2020)."}, {"title": "4.1 Models", "content": "In this study, we use pre-trained single-encoder models for two reasons: to assess how models' abilities learned on intra-sentential phenomena will translate into the inter-sentential regime, and to analyze the robustly trained and widely tested models instead of training models from random initialization. The first model we experiment with is OPUS-MT en-de\u00b2 (Tiedemann and Thottingal, 2020; Tiedemann et al., 2023). It is a relatively small (6 layers, 8 heads) encoder-decoder Transformer model trained on English-to-German translation. The second model is No Language Left Behind (NLLB-200) (NLLB Team et al., 2022), which is a multilingual MT model. We use the small distilled version with approximately 600 million parameters \u00b3, which consists of 12 encoder and decoder layers and 16 heads."}, {"title": "4.2 Context-aware Fine-tuning", "content": "We fine-tuned both models for Context-aware MT by concatenating the previous sentences with the current sentence on both the source and target side. Each sentence is separated by the [SEP] token (before fine-tuning, we expanded the vocabulary of the OpusMT en-de model with this token). We trained two versions of the OpusMT en-de model with maximum context sizes - the number of context sentences of one and three (refered to as context-aware-1 and context-aware-3 models), and one version of NLLB-600M with the maximum context size of one. We train the models with all the context sizes from zero to the maximum context size while keeping the context size the same on the source and target side for each example. During inference, we provide the models with the number of sentences equal to the maximum context size it was trained with. For Opus-MT en-de, we used the train subset of the IWSLT 2017 (Cettolo et al., 2017) English-to-German dataset, and interleaved English-to-"}, {"title": "4.3 Contrastive Datasets", "content": "We used two contrastive datasets: ContraPro (M\u00fcller et al., 2018) for the English-to-German direction, and the Large Contrastive Pronoun Test-set (LCPT; Lopes et al. (2020)) for the English-to-French direction. Both are based on the OpenSubtitles 2018 dataset (Lison et al., 2018), and consist of the source sentence, the source- and target-side context with several translations differing only in a pronoun that requires context to be correctly translated. The details of the contrastive datasets are presented in Appendix C. For each model, we first calculated the average attention scores assigned by each of the model's heads to the relations of interest (as described in Section 3.1) for the examples from the contrastive datasets and calculated the point-biserial correlation between the measured attention scores given by each head to the relations of interest and the model correctly disambiguating a particular example (see Section 3.2). Next, we applied Modifying Heads method (see Section 3.3) to each head of the models. We used the following values of C (eq.2) [0.01, 0.25, 0.5, 0.75, 0.99] (uniformly probing the available range) for OpusMT en-de models, and [0.01, 0.99] for other models after observing that the relation between model's ContraPro accuracy and modified value was mostly monotonic for all heads (see Appendix G for the detailed results). Additionally, we disabled each head by assigning the same probability to all tokens (see Appendix B for the detailed formulation) but we found that the results match the results for modifying the head to 0.01 without distinguishing the relation of interest."}, {"title": "5 Results", "content": "The base results in terms of accuracy and BLEU (Papineni et al., 2002) on contrastive datasets and BLEU on test subset of the IWSLT 2017 dataset are presented in Table 1. Since sentence-level models receive only the current sentence as input, we evaluate them by extracting examples from contrastive datasets where the antecedent is in the same sentence as the pronoun. This way we ensure that the"}, {"title": "5.1 OpusMT en-de", "content": "We performed the analysis of the models based on OpusMT en-de (sentence-level, context-aware-1, and context-aware-3) on the ContraPro dataset. The sentence-level model was evaluated only on the examples where the antecedent was located in the current sentence. For the context-aware models, we employed the full dataset. We present the results for all three models in Figure 2, where for each head we show the metrics introduced in Section 3 (correlations, accuracy when modified to 0.01, and modified to 0.99) in relation to the averaged attention scores. The expanded results can be found in Appendix G. Additionally, to give a sense of the distribution of the results, we show histograms of the observed values of the metrics with annotated values corresponding to prominent heads in Appendix I. Most heads do not pay - on average a large at-"}, {"title": "5.2 NLLB-200", "content": "The results of the analysis of the NLLB-200 context-aware models are presented in Figure 3. The expanded results, including the sentence-level model, can be found in Appendix H. The histograms of the results are presented in Appendix I."}, {"title": "5.2.1 English-to-German", "content": "For the English-to-German direction, only a single encoder head - e-12-4 - was found to attend the"}, {"title": "5.2.2 English-to-French", "content": "For the English-to-French direction, the accuracy of the unmodified models on LCPT reaches 95% for the sentence-level model and almost 92% for the context-aware model, which is considerably higher than on ContraPro. This could explain the lower ranges of responses to modifying heads and correlation coefficients observed in the results. In contrast to the English-to-German direction, we observed a higher number encoder heads attending the Sp \u2192 Sc relation (e.g., e-12-4, e-8-4, e-6-13, and e-12-8). Nevertheless, none of them responded to modifying. Similarly, several heads (c-6-16, \u0441-8-3, c-5-3, c-7-11) were attending but non-responsive to the Tp \u2192 Sp relation. For the TP \u2192 Sc relation, head c-8-6 was non-attending and positively responsive. This behavior was exhibited by two decoder heads - d-10-3 and d-10-6 - for the Tp \u2192 Tc relation. The Tp \u2192 TC+1 relation was attended by three heads - d-8-5 and d-9-12"}, {"title": "5.3 Discussion", "content": "Taking into account the results for all models we make the following observations.\n\u2022 Some heads appear to have a function identifiable through analysis. This is confirmed by previous research (Clark et al., 2019; Voita et al., 2019c; Tenney et al., 2019; Jo and Myaeng, 2020; Olsson et al., 2022), however we additionally demonstrate that adjustments to the functioning of heads (whether improved or diminished) leads to noticeable changes in models' performance (in terms of the accuracy of pronoun disambiguation).\n\u2022 The decoder-attention (corresponding to the target-side context) has the highest impact on the pronoun disambiguation accuracy. Note that we used the gold context (provided with the examples). In a real-world system, the context would come from the model's predictions. It is interesting to note that the most relevant heads are located in higher layers. Our intuition is that in the decoder the output token is presumably decided in the layers closer to the output and only with this information can heads attempt to find the corresponding antecedent.\n\u2022 In the decoder-attention, the important context tokens are the tokens corresponding to both the antecedent being predicted (the $T_p \\rightarrow T_c$ relation) and being passed to the model as input (the $T_p \\rightarrow T_{C+1}$ relation) with most heads spe-"}, {"title": "6 Tuning Heads", "content": "After identifying the most responsive heads, we fine-tuned them to assess to what extent the augmented behavior of the heads can be solidified into the models' parameters without compromising overall translation quality. To obtain the dataset containing the pronoun-antecedent pairs we applied the CTXPRO toolset (Wicks and Post, 2023) to the IWSLT 2017 en-de dataset (unrelated to the ContraPro dataset). The details can be found in Appendix F. We tuned selected heads of the OpusMT en-de models. The results are shown in Figure 4. The models exhibit higher accuracy for each tuned head without reducing the translation quality (see Appendix F for the extended results). The improvement is the highest for the sentence-level model and reduces with increased context size. The low number of examples with antecedent distance of two or more in the training dataset could explain the reduction in improvement for the context-aware-3 model. Alternatively, the representations of the"}, {"title": "7 Conclusions", "content": "In this paper, we researched the influence of the attention heads in the Context-aware MT models on the task of pronoun disambiguation in English-to-German and English-to-French language directions. We measured and modified the attention scores corresponding to the relations that could influence the prediction of a pronoun: pronoun-antecedent on the source and target sides, pronoun-pronoun, and pronoun-antecedent between the target and source sides. We found that some heads do attend the relations of interest but not all of them influence the pronoun disambiguation capabilities of the models. We showed that some heads are underutilized by the models - the models' performance could improve if they attended the relations. We confirmed that the target-side context is more impactful than the source-side context. Additionally, we note that the target-side context cue tokens can be useful to the model both when passed to the model (as the input of the decoder) as well as when they are predicted (as the output of the decoder). Lastly, we showed that the heads can be fine-tuned to attend the relations improving the models."}, {"title": "8 Limitations", "content": "We only investigated the pre-trained models that we fine-tune for the Context-aware MT. The attention heads could behave differently if the models were trained from the random initialization. Additionally, we employed the contrastive datasets to analyze the models. The behavior of the models can differ from the generative setting. We also used the gold target context. In the real-world scenario, the models would base its predictions on the previously generated target context. Lastly, we only considered the pronoun disambiguation task and only two language directions: English-to-German and English-to-French."}, {"title": "9 Acknowledgments", "content": "The research presented in this paper was conducted as part of VOXReality project, which was funded"}, {"title": "A Derivation of Modifying Heads Formula", "content": "In this section, we will provide a short derivation of the Modifying Heads equation (eq. 2) (see Section 3.3). Let us consider the i-th token in the left-hand side set Y of the relation of interest Y \u2192 X for the example d from the dataset. For a selected layer l and head h, the goal is to find the values of pre-softmax attention scores $H^{l,h,d}$ for all tokens j from the right-hand side set X of the relation of interest such that the sum of the resulting attention scores (post-softmax) $Z^{l,h,d}$ would be equal to a desired value C. We also assume that the attention scores would be spread equally among the tokens from the right-hand side set X. This can be formulated as:\n$C = \\sum_{j' \\in X^d} Z_{ij'}^{l,h,d} = |X^d|Z_{ij}^{l,h,d}$\n$\\forall i \\in Y^d, j \\in X^d,$\nThe attention scores are calculated using the following equation:\n$Z_{i,k}^{l,h,d} = \\frac{\\exp(H_{i,k}^{l,h,d})}{\\sum_{k' \\in X^d} \\exp(H_{i,k'}^{l,h,d})}$\n$\\forall i \\in Y^d, k \\in X^d,$\nwhere $X^d$ are the tokens from which the the right-hand side set X are selected. We expand eq.3 using eq.4 and split the sum in the denominator into two"}, {"title": "B Disabling Heads Method", "content": "In addition to the methods described in Section 3 we disabled heads of the models. Disabling heads means that we assign equal attention score to all key K tokens, thus they cannot function as before. It can be done for all query Q tokens or only for the selected ones. To minimize the disturbance to the model, we only disable heads for the Q tokens in they set. This allows the head to function normally for all other tokens but prevents it from attending to the contextually informative tokens from the contextually dependent tokens. Regardless, it still does not distinguish between relations of interest. For example, disabling a head in the cross-attention prevents it from attending both $T_p \\rightarrow S_p$ and $T_P \\rightarrow S_c$ relations reducing the granularity of the analysis. For an example d from the dataset, disabling heads is defined as:\n$\\overline{Z}_{i,k}^{l,h,d} = \\frac{1}{|X^d|}$\n$\\forall i \\in Y^d, k \\in X^d,$\nwhere Z are the updated attention scores (after softmax is applied), Xd is the whole set of attended tokens, including the attended tokens-of-interest $X^d$. Implementation-wise, we set pre-softmax attention scores H to zero and rely on the softmax"}, {"title": "C Details of the Datasets", "content": "In this section, we present the details of the datasets used in our investigation. The number of documents, sentences, and tokens in the subsets of the IWSLT 2017 (Cettolo et al., 2017) dataset for English-to-German and English-to-French directions can be seen in Table 2."}, {"title": "D Details of Context-aware Fine-tuning", "content": "We trained the models with Adafactor optimizer (Shazeer and Stern, 2018) on a single GPU (NVIDIA GeForce RTX 3090 24GB) for 10 epochs and select the checkpoint with the highest BLEU (Papineni et al., 2002) on the ContraPro dataset (M\u00fcller et al., 2018) (translating the sentences with the provided target context). The models acquired the highest BLEU score after two epochs for OpusMT en-de with a context window of one, and only after one epoch for OpusMT en-de with a context window of three and NLLB-200 (with a context window of one)."}, {"title": "E Modifying Multiple Heads", "content": "For all investigated models, we found that several heads are improving the accuracy of the model when modified to attend the relations of interest. To asses to what extent the improvement of different heads is overlapping we selected several heads with highest improvement in accuracy when modified to 0.99 and modified each pair of heads together to 0.99 for the relations they responded. We experimented with two models: OpusMT en-de with context size of three (we selected 8 heads), and context-aware NLLB-200 model on English-to-German and English-to-French directions (we selected 7 and 5 heads respectively). We report the percentage overlap of the accuracy improvement of modifying both heads against the sum of improvements of modifying each head separately,"}, {"title": "F Details of Head Tuning", "content": "We trained the selected heads of a model to generate the attention scores matching the scores resulting from modifying to 0.99. We froze all parameters of the model apart from the parameters responsible for the Q and K transformation in a targeted layer and updated only the parameters corresponding to the targeted head. Although we experimented with the calculation of the loss based on post-softmax attention scores Z, we observed a slight decrease in BLEU on the IWSLT 2017 test-set. Therefore, we decided to use the pre-softmax attention scores H to calculate the loss. We formulate the target pre-softmax attention scores for a token $i \\in Y$ as:\n$H_{i,j}^{l,h,d} =\\begin{cases}\\overline{H}_{i,j}^{l,h,d}, & \\text{ if } j \\in X,\\\\H_{i,j}^{l,h,d}, & \\text{ if } j \\notin X,\\end{cases}$\nwhere H is calculated according to eq. 2 (see Section 3.3, and H is the attention score obtained from"}, {"title": "G Expanded Results of the OpusMT en-de Models", "content": "In this section, we present the expanded results for the models based on OpusMT en-de (sentence-level, context-aware-1, and context-aware-3). The accuracy of the context-aware model with the context size of one on the ContraPro contrastive dataset when modifying heads to different values (from the set [0.01, 0.25, 0.5, 0.75, 0.99]) for five relations of interest can be seen in Figure 8. The results show that the changes in accuracy are monotonic. The raw results for all measured quantities (av-"}, {"title": "H Expanded Results of the NLLB-200 Models", "content": "Here, we show the expanded results for the two multi-lingual models (sentence-level and context-aware) based on NLLB-200. In Section 5.2 we presented the measured metrics introduced in Section 3 (correlations, accuracy when modified to 0.01, and modified to 0.99) in relation to the averaged attention scores only for the context-aware model. The results for both models and both language directions can be seen in Figure 12. We show the raw results for all relations of interest in: Figure 13 for the sentence-level model on ContraPro (English-to-German) dataset, Figure 14 for the context-aware model on ContraPro dataset, Figure 15 for the sentence-level model on LCPT (English-to-French) dataset, and Figure 16 for the context-aware model on LCPT dataset."}, {"title": "I Histograms of the Results", "content": "For each model, we generated histograms of the measured metrics and annotate with arrows the values for the most notable heads. Figures 17, 18, and 19 show the histograms for OpusMT en-de models (sentence-level, context-aware-1, and context-aware-3 respectively). The histograms for sentence-level NLLB-200 can be found in Figures 20 and 22 for the English-to-German and English-to-French directions respectively. The corresponding histograms of the context-aware NLLB-200 model are presented in Figures 21 and 23 for English-to-German and English-to-French respectively."}]}