{"title": "1-800-SHARED-TASKS @ NLU of Devanagari Script Languages:\nDetection of Language, Hate Speech, and Targets using LLMs", "authors": ["Jebish Purbey", "Siddartha Pullakhandam", "Kanwal Mehreen", "Muhammad Arham", "Drishti Sharma", "Ashay Srivastava", "Ram Mohan Rao Kadiyala"], "abstract": "This paper presents a detailed system description of our entry for the CHiPSAL 2025 shared task, focusing on language detection, hate speech identification, and target detection in Devanagari script languages. We experimented with a combination of large language models and their ensembles, including MuRIL, IndicBERT, and Gemma-2, and leveraged unique techniques like focal loss to address challenges in the natural understanding of Devanagari languages, such as multilingual processing and class imbalance. Our approach achieved competitive results across all tasks: F1 of 0.9980, 0.7652, and 0.6804 for Sub-tasks A, B, and C respectively. This work provides insights into the effectiveness of transformer models in tasks with domain-specific and linguistic challenges, as well as areas for potential improvement in future iterations.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) have revolutionized natural language processing (NLP) yet South Asian languages remain largely underrepresented within these advancements despite being home to over 700 languages, 25 major scripts, and approximately 1.97 billion people. Addressing these gaps, this paper focuses on three critical NLP tasks of CHIPSAL 2025 (Sarveswaran et al., 2025) in Devanagari-scripted languages: 5-way classification of the text based on the language of the text (Sub-task A), Binary classification for detecting hate speech in the text (Sub-task B), and 3-way classification for detecting target of hate speech in a text (Sub-task C) (Thapa et al., 2025). Our system leverages the multilingual capabilities of open-source LLMs namely IndicBERT V2 (Doddapaneni et al., 2023), MuRIL (Khanuja et al., 2021), and Gemma-2 (GemmaTeam, 2024) and their ensembles for natural language understanding of Devanagari script languages. Our work contributes to advancing language technology in South Asia, aiming for inclusivity and deeper understanding across diverse linguistic landscapes."}, {"title": "Dataset & Task", "content": "The goal of Sub-task A is to determine the language of the given Devanagari script among the 5 languages to address the critical need for accurate multilingual identification. The dataset consists of text in Nepali (Thapa et al., 2023; Rauniyar et al., 2023), Marathi (Kulkarni et al., 2021), Sanskrit (Aralikatte et al., 2021), Bhojpuri (Ojha, 2019), and Hindi (Jafri et al., 2024, 2023). For Sub-task B, the goal is to determine if the text contains hate speech or not. The dataset consists of social media text (tweets) in Hindi and Nepali languages. Sub-task C follows Sub-task B, where the goal is to identify the targets of hate speech among \"individual\", \"organization\", or \"community\". Similar to Sub-task B, the dataset for Sub-task C is in Hindi and Nepali languages."}, {"title": "Methodology", "content": "The common approach to all three Sub-tasks was to fine-tune a multitude of multilingual models in the train set and use the dev set to select the best few models during the Evaluation phase. The selected best models were then fine-tuned again on both the train and dev sets and their ensemble, by majority voting, was used for the final prediction of the test set during the Testing phase as shown in Figure 1. The models fine-tuned under this approach include decoder-only models such as Gemma-2 9B, Llama 3.1 8B (LlamaTeam, 2024), and Mistral Nemo Base 12B (MistralAI, 2024), and BERT (Devlin et al., 2019) based models such as IndicBERT V2, MuRIL, XLM Roberta (Conneau et al., 2019), mDistilBERT (Sanh et al., 2019) and mBERT (Devlin et al., 2018). For decoder-only models, each Sub-task was formulated as a text-generation task where each model was asked to generate only one option among the given choices. For BERT-based models, each Sub-task was formulated as a multi-label classification task by adding a classification head to the model.\nFor Sub-task A, each decoder-only models were trained for 1 epoch with a learning rate of 2e-4. The BERT-based models were trained for 5 epochs with a learning rate of 4e-5 with weighted cross-entropy loss. For Sub-task B, decoder-only models were trained for 2-4 epochs with a learning rate of 2e-4. The BERT-based models were trained for 5 epochs with a learning rate of 4e-5.\nTo handle the class imbalance in sub-task B, focal loss (Lin et al., 2018) was used for BERT-based models. Focal loss modifies cross-entropy by reducing the relative loss for well-classified examples, focusing more on hard, misclassified examples. The focal loss is given by formula 1:\n\n$L_{focal} = -\\alpha_t (1 - p_t)^{\\gamma} log(p_t)$\n\nWhere, $\\alpha_t$ is the balancing factor for class t, $p_t$ is the model's estimated probability for the correct class, and $\\gamma$ is the focusing parameter that adjusts the rate at which easy examples are down-weighted. The hyperparameters $\\alpha_t$ and $\\gamma$ were determined using grid search as 0.35 and 4.0 respectively.\nFor Sub-task C, only decoder models were used during the Testing phase as BERT-based models massively underperformed in limited tests. An additional Gemma-2 27B model was fine-tuned for Sub-task B and C using Odds Ratio Preference Optimization (ORPO) (Hong et al., 2024) for better alignment. All the fine-tuning of decoder-only models was carried out using Unsloth with Low-Rank Adaptation of Large Language Models (LORA) (Hu et al., 2021). The rank (r) and alpha ($\\alpha$) values used were 16 for both."}, {"title": "Results and Discussion", "content": "During the Evaluation phase, various models were assessed across Sub-tasks A, B, and C using the dev set to identify the top-performing models for each task. For Sub-task A (Table 4), the BERT-based models and decoder-only models, both delivered strong performances, with IndicBERT V2 and MuRIL emerging as the best models, each achieving an F1 score of 0.9978. They also had high recall and precision, indicating their robustness in effectively balancing sensitivity and specificity in task A classification. mBERT, XLM-Roberta, and larger generative models like Gemma-2 and Mistral Nemo also scored close to the top contenders, demonstrating that BERT-based and recent LLMs both possess considerable ability in text classification. For Sub-task B (Table 6), models' performance varied more significantly, reflecting the increased complexity compared to Sub-task A. Among the evaluated models, fine-tuned Gemma-2 9B with few-shot prompting yielded an F1 score of 0.7412. This shows Gemma-2's effective adaptation in low-resource scenarios even with limited examples. IndicBERT V2 and XLM-Roberta also provided competitive results, with IndicBERT V2 achieving an F1 score of 0.7298, reinforcing its efficacy across both tasks. This marked Gemma-2 9B and IndicBERT V2 as the top choices to be further evaluated for Sub-task B during the Testing phase. In Sub-task C (Table 8), Gemma-2 9B demonstrated superior results with an F1 score of 0.6937. This outcome was significantly better than all other models, indicating Gemma-2's robust performance for tasks with limited examples. XLM Roberta achieved the second-highest F1 score of 0.5455. The performance of other models shows the complexity of the task as except for Gemma-2, other models couldn't cross the F1 score of 0.6."}, {"title": "Testing Phase", "content": "For the testing phase, we retrained the top-selected models from the Evaluation phase by incorporating both the train and dev sets to create a more generalized model for final testing. For Sub-task A (Table 5), ensemble techniques were applied to enhance accuracy further, leading to notable improvements in performance. Three ensembles were constructed, each with a different fallback model for cases without a majority prediction. Among these, Ensemble-2, which defaulted to IndicBERT V2's predictions when no majority was reached, yielded the highest F1 score of 0.9980. This ensemble strategy was instrumental in refining classification outcomes by leveraging the strengths of multiple models while relying on IndicBERT V2's consistency as a fallback. As a result, Sub-task A saw an optimal performance boost, indicating the success of ensembling techniques in improving classification tasks with high base accuracy. For Sub-task B (Table 7), we employed a similar ensemble approach to maximize prediction performance. Ensemble results demonstrated improved robustness and balance across the metrics, culminating in an F1 score of 0.7652, with strong recall (0.7441) and precision (0.7925). For the ensemble, we employed an additional Gemma-2 27B trained using ORPO with the two models selected during the Evaluation phase. The overall gains from the ensemble approach for this task underscore its potential to improve tasks with more nuanced, challenging data patterns. In Sub-task C (Table 9), instead of using ensembling, we selected Gemma-2 27B ORPO as the optimal model for its strong performance during testing. This model achieved an F1 score of 0.6804, with balanced recall (0.6669) and precision (0.7183), showcasing its capability to handle more granular classification without the need for ensemble interventions. The decision to forego ensembling was based on the observation that Gemma-2 27B's setup offered robust, reliable performance on its own, suggesting that, for some tasks, a single, finely-tuned model can sometimes match or exceed ensemble outcomes."}, {"title": "Conclusion", "content": "Our results demonstrate the importance of leveraging tailored approaches to tackle complex natural language understanding tasks across multiple languages in Devanagari script. By combining the multilingual strengths of the BERT-based models, focal loss for class sensitivity, and the generative power of Gemma-2, we achieved notable performance improvements across the subtasks. These findings highlight the value of adapting model architectures and training strategies to the nuances of each task, especially in handling multilingual contexts and imbalanced classes. This work lays a foundation for more refined, scalable hate speech detection systems for South Asian languages that can respond effectively to diverse and complex online discourse."}, {"title": "Limitations", "content": "The datasets used for training and evaluation in hate speech and target detection are relatively small, which may impact the generalizability of the models in real-world applications. The challenges such as unbalanced datasets, difficulties in data collection, and issues with code-mixed languages, as noted in prior research (Parihar et al., 2021), remain significant hurdles in the accurate detection of hate speech. Although techniques like focal loss and Odds Ratio Preference Optimization (ORPO) were applied to improve performance, the models still struggle with fine-grained distinctions in ambiguous hate speech contexts. Additionally, the decoder-only models were trained in 4-bit precision due to computational limitations, and they may perform better in full-precision mode. While these models performed well in most tasks, they are computationally intensive, requiring substantial resources for both fine-tuning and inference. On the other hand, BERT-based models performed well in Sub-tasks A and B, and with larger datasets, they may offer better performance for Sub-task C at a lower computational cost than decoder-only models."}, {"title": "Ethical Considerations", "content": "When developing models for detecting hate speech and its targets, it's important to address several ethical concerns. A major issue is the potential for bias in both the data and the model's outputs. Since the datasets used in the development are limited and might not fully represent all social contexts, there's a risk that the models could unintentionally reinforce biases or target specific groups unfairly. These models might also be used in ways that could cause harm, such as censoring or flagging content incorrectly without human oversight. Given the complex nuances of hate speech, it's crucial to avoid over-censorship, which may otherwise lead to the unjust targeting of certain communities or the stifling of legitimate free speech."}, {"title": "Appendix", "content": "We provide the confusion matrix for all the models we tested below:"}, {"title": "Task A: Language Detection", "content": "Task: You are an expert linguist specializing\nin Devanagari script languages. Your task\nis to identify the language of the given\ntext.\n### Instruction:\nAnalyze the following Devanagari script text\nand determine its language. Choose the\ncorrect language code from these options:\n0: Nepali\n1: Marathi\n2: Sanskrit\n3: Bhojpuri\n4: Hindi\n### Input:\nText: {text}\n### Response:\nThe language code for the given text is: {label}"}, {"title": "Task B: Hate Speech Detection", "content": "Task: You are fluent in Nepali and Hindi\nlanguages. Your task is to classify if the\ngiven input text contains hate speech or\nnot.\n### Instruction:\nThe goal of this subtask is to identify the\ntargets of hate speech in a given text.\nChoose the correct category from these\noptions:\n1: Hate\n0: Non-Hate\n### Examples:\nInput: {example_text1}\nResponse: {example_text1_label}\nInput: {example_text2}\nResponse: {example_text2_label}\nInput: {example_text3}\nResponse: {example_text3_label}\nInput: {example_text4}\nResponse: {example_text4_label}\nInput: {example_text5}\nResponse: {example_text5_label}\n### Input:\n{text}\n### Response:\n{label}"}, {"title": "Task C: Hate Speech Target Detection", "content": "You are an expert linguist specializing in\ndetecting hate speech targets in\nDevanagari-script tweets. Your task is to\nclassify the target of hate speech.\n### Instruction:\nAnalyze the given tweet in Devanagari script\nand determine who the hate speech is\ntargeting.\nStep 1: First, decide if the target is an\nindividual or a group.\nStep 2 (if group): If it's a group, further\nclassify it as either an organization or a\ncommunity.\nClassify the final label according to these\ncategories:\n0. Individual: A specific person or a small set\nof identifiable individuals\n1. Organization: A formal entity, institution,\nor company\n2. Community: A broader group based on\nethnicity, religion, gender, or other\nshared characteristics\n### Input:\n{}\n### Response:\n{}"}]}