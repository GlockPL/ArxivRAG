{"title": "Multi-Slice Spatial Transcriptomics Data Integration Analysis with STG3Net", "authors": ["Donghai Fang", "Fangfang Zhu", "Wenwen Min"], "abstract": "With the rapid development of the latest Spatially Resolved Transcriptomics (SRT) technology, which allows for the mapping of gene expression within tissue sections, the integrative analysis of multiple SRT data has become increasingly important. However, batch effects between multiple slices pose significant challenges in analyzing SRT data. To address these challenges, we have developed a plug-and-play batch correction method called Global Nearest Neighbor (G2N) anchor pairs selection. G2N effectively mitigates batch effects by selecting representative anchor pairs across slices. Building upon G2N, we propose STG3Net, which cleverly combines masked graph convolutional autoencoders as backbone modules. These autoencoders, integrated with generative adversarial learning, enable STG3Net to achieve robust multi-slice spatial domain identification and batch correction. We comprehensively evaluate the feasibility of STG3Net on three multiple SRT datasets from different platforms, considering accuracy, consistency, and the FILISI metric (a measure of batch effect correction efficiency). Compared to existing methods, STG3Net achieves the best overall performance while preserving the biological variability and connectivity between slices. Source code and all public datasets used in this paper are available at Github (https://github.com/wenwenmin/STG3Net) and Zenodo (https://zenodo.org/records/12737170).", "sections": [{"title": "I. INTRODUCTION", "content": "In complex organisms, cells are organized into specialized clusters with distinct functions through dynamic interactions and intricate arrangements among them [1]. These clusters exhibit mutual influence and close connections to collectively carry out the coordinated operation of the organism. The latest spatially resolved transcriptomics (SRT) techniques [2, 3], such as ST with a spatial resolution of 100 \u00b5m, 10x Visium with a spatial resolution of 55 \u00b5m, and Stereo-seq with a spatial resolution of 220 nm, enable genome-wide analysis at the multicellular or even single-cell level, capturing the transcriptional expression corresponding to specific spatial locations (referred to as spots) [4-6]. The insights into genomic transcriptional expression based on spatial information provide a solid foundation for researchers to understand many biological processes that affect diseases and facilitate advancements in the diagnosis and treatment of related conditions [7, 8]. An important computational task in recent SRT data analysis is the identification of shared and specific clusters, referred to as spatial domains, which are defined as regions with similar spatial expression patterns. Several methods have been proposed to address the spatial domain identification problem in single-slice SRT datasets [7-12] and data denoising [13, 14]. For example, SpaGCN [9] utilizes unsupervised clustering algorithms to detect different spatial expression patterns in single-slice SRT datasets. DeepST [10] further extracts information from histological images using convolutional networks and then employs a deep generative network to identify spatial domains. STAGATE [8] utilizes a deep autoencoder model and employs graph attention mechanism to learn spatial heterogeneity. STMask [7] employs a dual-channel autoencoder with masks to learn the latent representation of a single slice. However, these methods face challenges in the comprehensive analysis of multiple SRT datasets since batch effects among multi-slices generated under different conditions, techniques, or developmental stages may obscure actual biological signals [15, 16]. This limitation poses a significant challenge to existing methods developed based on single-slice approaches and restricts our ability to understand the biological processes occurring between slices.\nTo address these challenges, several methods and tools have been developed for the integrated analysis of multiple SRT datasets. PASTE [17] assumes the maximum possible overlap between multiple slices and improves clustering performance by aligning neighboring slices to the central slice using alignment algorithms. However, its applicability is limited to cases in which slices only partially overlap or do not overlap spatially at all. Splane [18] utilizes the Spoint model for deconvolution analysis of SRT data. The obtained cell type composition replaces the original transcriptional expression as the input to the model. By integrating adversarial learning strategies, it demonstrates the elimination of batch effects across slices. However, it is a multi-stage model, and the performance of spatial domain identification across slices is highly dependent on the deconvolution performance. STAligner [15] combines STAGATE with a method based on mutual nearest neighbors (MNNs) [19] into a unified model, enabling the spatial awareness of multiple SRT datasets. However, the MNN-based method forces the search for MNN-pairs between arbitrary slices. In reality, slices may not necessarily contain the same specialized clusters, such as at different time points, leading to the incorrect construction of MNN-pairs in different spatial domains. Additionally, computing MNN-"}, {"title": "II. PROPOSED METHODS", "content": "To overcome the \"identity transformation\" issue, we use the augmented representation  X \u2208 \\mathbb{R}^{N \\times N_t} as the input for training the model. Specifically, from the set of spot vertices, a masked vertex set Vm is randomly sampled with a masking rate p. For the i-th spot (vi), if vi \u2208 Vm,  Xi = X[mask], where X[mask] represents the mask token vector; otherwise, Xi = xi.\nFor any given slice (indexed as s), the Euclidean distance between spots is calculated based on their spatial coordinates. The K-nearest neighbor (KNN) algorithm is then applied to select the top K nearest neighboring spots, resulting in the construction of an adjacency matrix As. If j-spot is a neighbor of i-spot, then As,ij = As,ji = 1. Subsequently, the adjacency matrices of each slice are combined to form a block diagonal adjacency matrix A, which serves as the input."}, {"title": "C. Latent representation learning with masked reconstruction", "content": "The latent representation of gene expression is obtained from the encoder. The encoder first takes the masked matrix X and passes it through two stacked fully connected layers to generate a low-dimensional representation Hf \u2208 \\mathbb{R}^{N \\times d_f}. Additionally, leveraging the advantages of the SRT dataset, a graph convolutional network (GCN) is utilized to process and aggregate information from neighboring nodes, facilitating the integration of gene expression and spatial coordinates. This results in a meaningful and useful latent representation H \u2208 \\mathbb{R}^{N \\times d}. Here, df and d are the dimensions of the low-dimensional expression representation, and the final latent representation of STG3Net, respectively. The calculation of H involves a two-layer GCN, which is defined as follows:\nH = GCN\u0127(A, Hf) = \u00c3ReLU(\u00c3HfWo)W1 \\tag{1}\nwith weight matrices Wo, W1, and symmetrically normalized adjacency matrix \u00c3 = D\u2212\u00bdAD\u2212\u00bd.\nOnce the training phase is completed, we utilize X as the input to the encoder and obtain the latent representation H. This representation is then used for downstream tasks such as spatial domain identification and visualization in multiple SRT dataset analysis.\nThe decoder consists of one fully connected layer and one GCN, which is used to reconstruct the gene expression Z \u2208 \\mathbb{R}^{N \\times N_t} from the latent representation. The calculation of Z is as follows:\nZ = GCN\u2082(A, H) = \u00c3LeakyReLU(HW)W \\tag{2}\nwith weight matrices W and W1.\nTherefore, one of the main objectives of STG3Net is to reconstruct the masked gene expression of spots in Vm given a partially observed spot set and adjacency relationships. By utilizing the Scaled Cosine Loss (SCE) as the objective function, it is defined under a predetermined scaling factor \u03b3 as follows:\n\\mathcal{L}_{sce} = \\frac{1}{|V_m|} \\sum_{v_i \\in V_m} (1 - \\frac{X_i^T Z_i}{\\|X_i\\| \\|Z_i\\|})^\\gamma, \\gamma \\geq 1 \\tag{3}\nwhere \u03b3 is fixed to 2 to reduce the contribution from simple samples during the training process, and |Vm| represents the number of spots in the masked set."}, {"title": "D. Adversarial learning for multiple slices", "content": "To improve the clustering performance across multiple slices, we have designed a discriminator consisting of three stacked fully connected layers. It takes the latent representation outputted by the encoder as input and produces the probability Pi,s of i-spot belonging to s-slice. Therefore, under the supervision of the slice label yi,s of i-spot, we have the discriminator loss as follows:\n\\mathcal{L}_{dis} = \\frac{1}{|V_m|} \\sum_{V_i \\in V_m} Y_{i,s} \\log(p_{i,s}) \\tag{4}\nThe Ldis is minimized when there is a need to discover distinguishing features between slices from the latent representation, allowing the discriminator to accurately predict the slice labels. Conversely, Ldis is maximized when there is a need to deceive the discriminator to mitigate batch effects across multiple slices, ensuring that spots from different slices would have the highest similarity."}, {"title": "E. Triplet learning with global nearest neighbors", "content": "We have developed a novel Global Nearest Neighbor (G2N) anchor pairs selection method specifically for analyzing the multiple SRT dataset. This method utilizes the obtained G2N-pairs to overcome batch effects across multiple slices. Firstly, we define the anchor Asi as the i-th spot on the current s-th slice, while the positive anchor is defined as the spot on all other t-th slices except the s-th slice. Based on this, we further calculate the similarity between the latent representations of the anchor and positive anchors and retain the top Kg nearest positive anchors for each anchor, denoted as Bs.i. To further obtain a global set of positive anchors, we employ clustering to discover and acquire nodes that share global semantic information with the anchors. By utilizing a clustering algorithm, we cluster the spots into Ke clusters and select nodes belonging to the same domain as the anchor as similar points that share semantic information globally. This set is denoted as Cs,i. Therefore, we obtain the set Rs,i = Bs,i \u2229 Cs,i of globally nearest anchor nodes in the latent space. To prevent excessive reliance on cluster distribution and avoid mode collapse, we randomly select n/2 nodes from the set Rs,i as the final positive anchor set Ps,i. The negative anchors are defined on the s-th slice, selecting Ps,i nodes from different domains than the current anchor as the negative anchor set Ns.i.\nThe triplet loss is employed to minimize the distance between anchor-positive pairs and maximize the distance between anchor-negative pairs in the latent space. The calculation is as follows:\n\\mathcal{L}_{tri} = \\frac{1}{N_{tri}} \\sum_{\\tau \\in T} (max(\\|h_a - h_p\\|_2 - \\|h_a - h_n\\|_2 + \\gamma, 0)) \\tag{5}\nwhere T is the set of all anchor points As,i along with their corresponding positive anchor set Ps,i and negative anchor set Ns,i, forming the G2N-pairs. Ntri represents the total number of G2N-pairs and \u03b3 is the margin (default 1.0).\nFinally, the entire learning objective is written as:\n\\mathcal{L} = \\mathcal{L}_{sce} - \\lambda \\mathcal{L}_{dis} + (1 - \\lambda)\\mathcal{L}_{tri} \\tag{6}\nwhere \u03bb is a hyperparameter that control the contribution in the loss function."}, {"title": "F. Evaluation criteria", "content": "We utilize accuracy metrics to describe the clustering precision of the method, consistency metrics to measure the dispersion of clustering results [1], and the local inverse Simpson index to evaluate the batch correction effect across multiple slices [21]. Specifically, in accuracy description, we have the following metrics: Adjusted Rand Index (ARI), used to compare the similarity between clustering results and manually annotated labels. Normalized Mutual Information (NMI), based on information theory, it measures the normalized mutual information between clustering results and true labels. Homogeneity (HOM) score, a metric that assesses if all clusters contain only data points belonging to a single class, indicating homogeneous clustering. Completeness (COM) score, a metric that measures if all data points belonging to a particular class are grouped together in the same cluster, indicating complete clustering [1]. Therefore, the overall accuracy score is calculated as follows:\nAccuracy = \\frac{1}{3} \u00d7 (NMI + HOM + COM) \\tag{7}\nThe closer the ARI and Accuracy scores are to 1, the better the clustering precision.\nWe assess spatial continuity using the Spatial Chaos Score (CHAOS), where a lower chaos value indicates better identified spatial domain continuity. The Percentage of Anomalous Points (PAS) represents the randomness of points located outside the clustered spatial domains, with a lower PAS score indicating better detected spatial domain continuity [1]. Therefore, a lower overall score for consistency corresponds to better continuity. The calculation is as follows:\nConsistency = \\frac{1}{2} \u00d7 (CHAOS + PAS) \\tag{8}\nWe evaluate the degree of separation between the same domain and different domains by using the Local Inverse Simpson Index (LISI) for each batch within a domain (LISI_batch) and the LISI across all data for the domain (LISI_domain). The F1 score of the LISI [21] is calculated as follows:\nF1LISI = \\frac{2(1 - LISI_{domain_{norm}})(LISI_{batch_{norm}})}{1 - LISI_{domain_{norm}} + LISI_{batch_{norm}}} \\tag{9}\nA higher F1 score indicates superior batch correction."}, {"title": "III. EXPERIMENTS", "content": "In this study, we analyze multiple SRT datasets from three different platforms. Lastly, we investigate mouse embryo (ME) slices at different developmental stages from the Stereo-seq platform. We select slices from the E9.5, E10.5, and E11.5 time periods."}, {"title": "IV. CONCLUSIONS AND DISCUSSION", "content": "In this paper, we propose STG3Net, a novel method designed to integrate multiple SRT datasets and correct batch effects. We enhance the robustness of the self-supervised encoder by reconstructing masked spot expressions, which helps in reducing the occurrence of discrete spots. We employ adversarial learning to improve the model's ability to identify spatial domains in complex, multi-slice SRT data. Additionally, we introduce a plug-and-play batch correction method called Global Nearest Neighbor (G2N) anchor pair selection, specifically designed for SRT datasets. G2N facilitates faster acquisition of anchor pairs by considering global semantic information and minimizing the selection of erroneous pairs.\nWe validate STG3Net on three diverse datasets using multiple evaluation metrics, including continuity, accuracy, and effectiveness of batch correction. For the DLPFC donor3 data, the latent representation generated by STG3Net enables UMAP visualization, effectively capturing cortical layers and blending multiple slices. The performance on AMB and ME datasets demonstrates STG3Net's ability to preserve variability and connectivity during biological development. Furthermore, an ablation study is conducted to explore the model's performance by examining the impact of different components, objective functions, and other factors from various perspectives."}]}