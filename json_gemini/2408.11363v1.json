{"title": "ProteinGPT: Multimodal LLM for Protein Property Prediction\nand Structure Understanding", "authors": ["Yijia Xiao", "Edward Sun", "Yiqiao Jin", "Qifan Wang", "Wei Wang"], "abstract": "Understanding biological processes, drug development, and biotechnological advancements\nrequires detailed analysis of protein structures and sequences, a task in protein research that is\ninherently complex and time-consuming when performed manually. To streamline this process, we\nintroduce ProteinGPT, a state-of-the-art multi-modal protein chat system, that allows users to upload\nprotein sequences and/or structures for comprehensive protein analysis and responsive inquiries.\nProteinGPT seamlessly integrates protein sequence and structure encoders with linear projection\nlayers for precise representation adaptation, coupled with a large language model (LLM) to generate\naccurate and contextually relevant responses. To train ProteinGPT, we construct a large-scale dataset\nof 132,092 proteins with annotations, and optimize the instruction-tuning process using GPT-40.\nThis innovative system ensures accurate alignment between the user-uploaded data and prompts,\nsimplifying protein analysis. Experiments show that ProteinGPT can produce promising responses to\nproteins and their corresponding questions.", "sections": [{"title": "1 Introduction", "content": "Proteins are fundamental molecular building blocks of life, playing critical roles in biological processes [1].\nUnderstanding their structure, functions, and interactions is vital for advancements in drug discovery [2],\nhealthcare [3], and biological/medical engineering [4]. Recent breakthroughs in machine-learning-based\nprotein structure and function prediction [5] have significantly accelerated biological research by reducing\nthe reliance on traditional labor-intensive laboratory experiments and literature searches.\nChallenges. As proteins can be represented by strings of characters, each corresponding to an amino acid\nfrom an alphabet of 20 letters, recent advancements in Large Language Models (LLMs) have naturally\nextended to protein research.\nStudies like ProtST [6], ProteinChat [7], and ProtChatGPT [8] align protein sequence or structure\ndata with textual descriptions to create LLMs for proteins.\nHowever, most of these studies rely on a single modality, potentially overlooking insights from\nthe fusion of multiple modalities. For instance, protein sequences can reveal evolutionary information,\nfunctional sites, and sequence-structure relationships, while protein structures provide critical insights\ninto spatial arrangement, structural dynamics, binding sites, and stability.\nApplying multimodal LLMs to protein modeling is non-trivial due to the challenge in aligning diverse\nmodalities, such as textual descriptions, protein sequences, and protein structures. Meanwhile, direct\nend-to-end retraining for protein LLMs is usually impractical due to extensive requirements for annotated\ndata."}, {"title": "This Work", "content": "We propose ProteinGPT, a chat system that allows researchers to upload protein sequences\nand/or structures (via fasta or PDB files) and ask natural language questions. ProteinGPT consists of four\nmajor blocks: a protein sequence encoder, a protein structure encoder, a projection layer, and an LLM.\nThe protein sequence encoder is based on the esm2_t36_3B_UR50D model from ESM-2 (Evolutionary\nScale Modeling 2) [5], which features 36 transformer layers and 3 billion parameters. The model is\npretrained on UniRef50/D, a comprehensive protein database that strategically samples UniRef100\nsequences from UniRef50 clusters to maximize sequence diversity, thereby enriching the informativeness\nof the encoding. The protein structure encoder, esm_if1_gvp4_t16_142M_UR50, is an inverse folding\nmodel that incorporates a geometric input processing layer paired with a seq2seq transformer. Trained\non 12 million structures predicted by AlphaFold2 [9], the model is highly effectively at capturing the\nstructural information of proteins.\nThis design enables information extraction from not only the protein structural and sequential\ninformation but also prior knowledge within ESM. The projection layer aligns both embeddings with\nLLM embeddings.\nTo effectively train the system for modality alignment, we introduce ProteinQA, a large-scale dataset\nof over 132,092 protein sequences, structures, and annotations.\nUnlike previous works that use entire protein annotations as the prediction target for instruction\ntuning, we propose a GPT-4 [10] guided approach that decomposes proteins' abstract summary into\nquestion-answer (QA) pairs, effectively enhancing the model's ability to understand user queries and\ngenerate concise, relevant answers.\nContributions. Our contributions are as follows:\n\u2022 Novel Framework. We introduce ProteinGPT, an innovative chat system that fuses protein sequence\nand structural information to enable interactive protein-focused conversations, significantly enhancing\nthe understanding and design of proteins;\n\u2022 Large-scale Dataset. We propose ProteinQA, a large-scale dataset based on the RCSB-PDB Protein\nDescription Dataset [7]. ProteinQA encompasses 132,092 protein samples, each annotated with a\ndetailed descriptive abstract, 20-30 property tags, and 5-10 QA pairs. The depth and variety of these\nannotations position ProteinQA as a high-quality instruction tuning corpus;\n\u2022 Comprehensive Experiments. We conducted extensive experiments on mainstream open-source and\nproprietary LLM backbones under different scenarios. Our empirical analysis provides guidance for\nthe future design of protein LLMs."}, {"title": "2 Methodology", "content": ""}, {"title": "2.1 Model Architecture", "content": "ProteinGPT consists of two frozen pre-trained encoders : an inverse folding model\n(esm_if1_gvp4_t16_142M_UR50) for structure encoding and a protein language model for sequence\nencoding (esm2_t36_3B_UR50D). The embeddings generated by these models are fed into a linear\nprojection layer to produce soft prompts for the LLM. The model training comprises two stages: 1)\nSequential and Structural Alignment and 2) Instruction Tuning."}, {"title": "2.1.1 Sequence and Structure Alignment", "content": "In the alignment stage, protein structures are first fed into the pre-trained structure encoder, which\nexplicitly captures the detailed 3D structures and models spatial interactions between amino acid residues.\nWe take esm_if1_gvp4_t16_142M_UR50 as the structure encoder. Then, sequences are encoded using the\nsequence encoder esm2_t36_3B_UR50D featuring 36 transformer layers and 3 billion parameters, trained\non the Protein UniRef50/D database to enhance sequence diversity. This module integrates structural\ninformation with implicit structural contact, evolutionary, and biochemical information that the structure\nalone does not capture. For efficient training, both of these modules are frozen. We utilize a specialized\ntoken prompt for protein-text modality alignment:\nQ: < Protein >< Struct >< Seq >\n</Protein >< QuestionPrompts >\nA: < Description >\nThe structural and sequential information is encoded into the soft prompts and prepended to the\nquestion prompt. In stage 1 training, the question prompt Q is left empty to prioritize learning the abstract\ndescription from the protein representation. The description tag is then replaced with the full annotation\nfrom RCSB-PDB [7] to train the projection layer in aligning a protein with its annotation description."}, {"title": "2.1.2 Instruction Tuning", "content": "In stage 2, the model undergoes instruction tuning using our curated QA dataset. Unlike previous works\nthat utilize full annotations, we focus on specific QA examples to facilitate instruction tuning. We augment\nthe abstract dataset from stage 1 using GPT-40 to generate explicit QA pairs for this stage. The prompts\nfrom stage 1 are adapted to the LLaMA style (\u201c###Human : . . .\u201d and \u201c###Assistant : . . .\u201d), with\nQ replaced by explicit questions from the QA dataset, such as \u201chow many assemblies does this protein\nhave.\" The model then generates descriptive yet concise answers from the given protein as A."}, {"title": "2.2 Datasets", "content": "For modality alignment, we construct a large-scale dataset from the RCSB-PDB database [11] consisting\nof 132,092 protein structures, sequences, and abstract descriptions. The raw dataset of 204,826 proteins\nis filtered to retain only those with an abstract description, chain A, and sequences without non-encodable\ncharacters. Each entry in the final dataset includes the 3D protein structure represented by backbone\natomic coordinates, the sequence string, and a rich protein annotation, as shown in Figure 2. The detailed\nstatistics of our dataset are presented in Table 1, highlighting the extensive annotations and comprehensive\ncontent available for each protein."}, {"title": "2.3 Data Augmentation", "content": "Previous works often use the entire protein annotation for instruction tuning [6\u20138], which may result in the\nmodel producing overly detailed responses with extraneous information not directly relevant to the user\nprompt. Therefore, our ProteinGPT decomposes the rich protein annotations into more specific QA-pairs\nfor instruction tuning so that user instructions can be concisely answered. We do this by generating short\nconcise answers along with long-form responses to include our dataset. Concretely, we prompt GPT-40\nto generate both open-ended and close-ended QA pairs with the context of the abstract to decompose the\nabstract into atom-level QA pairs. As seen in Table 1, on average, each protein has around 40 total QA\npairs generated from this process."}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Training", "content": "Our training process is divided into two phases: modality alignment (MA) and instruction tuning (IT).\nThis approach allows the model to preserve previously acquired knowledge while effectively handling\nspecific instructions, such as protein-related queries.\nStage 1: Modality Fusion/Alignment (MA). In this stage, we focus exclusively on training the projection\nadapter by freezing both sequence and structure encoders. We set the maximum text length of abstracts to\n384 characters to accommodate the annotation lengths within the RCSB-PDB dataset. The projection\nlayer is trained over 10 epochs with a batch size of 1, weight decay of 0.05, and 2048 warm-up steps.\nThe dataset is divided into a training set (70%) of 105,673 proteins and a testing set (30%) of 26,419\nproteins. We utilize the AdamW optimizer with \\(\\beta_1 = 0.9\\), \\(\\beta_2 = 0.98\\) [12], and employ a learning rate\nscheduler with a linear warm-up followed by cosine annealing. We set the initial learning rate to \\(1 \\times 10^{-4}\\),\nthe minimum learning rate to \\(8 \\times 10^{-5}\\), and the warm-up learning rate to \\(1 \\times 10^{-6}\\). Automatic mixed\nprecision (AMP) [13] was used to improve training efficiency.\nStage 2: Instruction Tuning (IT). In this stage, the model is fine-tuned on a protein question-answering\ntask. Training is conducted for 10 epochs with a batch size of 1, weight decay of 0.05, and 200 warm-up\nsteps. The QA dataset used in this phase comprises approximately 3.7 million samples, with around 35\nquestions per protein. We apply similar settings for the AdamW optimizer and AMP, but with a lower\ninitial learning rate of \\(1 \\times 10^{-5}\\), a minimum rate of \\(1 \\times 10^{-6}\\), and a warm-up rate of 1 \u00d7 10-6."}, {"title": "3.2 Computational Cost", "content": "We conduct our training using two NVIDIA H100 PCIe GPUs (80GB) and two NVIDIA A100 PCIe\nGPUs (40GB). Stage 1 requires approximately one week, while stage 2 demands around 60 hours."}, {"title": "4 Results", "content": "We trained ProteinGPT on 4 base LLM architectures: Vicuna [14], LLaMA-2 [15], LLaMA-3 [16],\nand Mistral [17]. We conducted a series of experiments to assess ProteinGPT's effectiveness both\nquantitatively and qualitatively. Additionally, we carried out ablation studies to ascertain the importance"}, {"title": "4.1 Qualitative Evaluation", "content": "Figure. 6-8 shows example conversations between human users and ProteinGPT. To ensure unbiased\nevaluation and avoid data leakage, all testing was performed on a separate set of proteins isolated from\ntraining. ProteinGPT effectively interpret the semantics of queries and produces accurate, logically\nconsistent responses. These responses include details about protein functions, such as catalyzing the\nreduction of dinitrogen to ammonia, and structures, such as the structural dependencies on the substrate\nazide and the product ammonia. This demonstrates ProteinGPT's capabilities on protein sequence,\nstructure, and function understanding tasks and its potential for enabling rapid exploration of proteins."}, {"title": "4.2 Quantitative Evaluation", "content": ""}, {"title": "4.2.1 Instruction Tuning Observations", "content": "We randomly select 3,508 question-answer-protein pairs from our curated dataset, covering 160 proteins\nfrom the test split. Each protein is associated with 28~30 questions that ProteinGPT has not seen\nduring training. Similarly, for baseline comparison with vanilla LLM (without modality alignment or\ninstruction tuning) and GPT, we sample 1,025 questions (35 proteins with 28~30 questions per protein),\nconsidering the computational costs. For fairness of comparison, all evaluations are performed on this\nsame set of question-answer-protein pairs. We employ standard metrics for semantic similarity, including\nBERTScore [18], PubMedBERT-Score [19], and GPT Score [20], as well as lexical metrics (ROUGE-\n1/2/L [21]), to compare model predictions with the ground truth. Note: for the GPT Score, we simply\nreplaced the encoder used in the BERTScore with OpenAI's text-embedding-3-large embedding\nmodel.\nTable 2 and Table 4 highlight the performance of the full modality aligned and instruction tuned\nProteinGPT. As seen, it has very high overall semantic scores, however has very low lexical scores. This\ncan be explained by looking closer at the output of ProteinGPT. While our annotations often contained"}, {"title": "4.2.2 Foundational LLMs Comparision", "content": "From the 4 models that we selected, the versions of ProteinGPT that are based on Mistral and LLaMA-3\nappear to perform the best. This can be observed in Figure. 7. This is likely due to the already stellar\nperformance of these foundational LLMs, especially with LLaMA-3 being Meta's newest and most\npowerful model and Mistral similarly being the SOTA released by Mistral AI."}, {"title": "4.2.3 Baseline Comparisions to ProteinGPT", "content": "We also compare ProteinGPT to two baselines to demonstrate our contributions in creating multimodal\nLLMs that are more capable than general-purpose LLMs in communicating about proteins. The first\nbaseline is the vanilla LLMs that we trained our models on, such as Vicuna, Mistral, LLaMA-3, and\nLLaMA-2. The second baseline is GPT-4 and GPT-3.5. For evaluation, we simply pretended the FASTA\nsequence of the protein in front of the prompt to give the LLM context of the protein.\nVanilla LLM: The semantic and lexical scores for prompting a vanilla LLM with a prompt prepended\nwith a protein sequence are included in Tables 2 and 4. Note: These are the same results as the stage in\nthe ablation study in which no training is done.\nOpenAI GPT-4/GPT-3.5: Similarly, the scores for using GPT-4 and GPT-3.5 as the LLM are presented\nin Table 3 and Table 5. We utilized GPT-3.5-turbo, GPT-40, and GPT-4-turbo in our evaluation.\nThe overall comparison can be seen in Figure 3, which shows that ProteinGPT outperforms both\nbaselines consistently. This demonstrates that our model outperforms knowledge embedded within LLMs\nand effectively utilizes sequence and structure information to answer questions."}, {"title": "4.2.4 Baseline Comparisons to ProteinGPT", "content": "We also compare ProteinGPT to two baselines to demonstrate our contributions in creating multimodal\nLLMs that are more capable than general-purpose LLMs in communicating about proteins. The first\nbaseline is the vanilla LLMs that we trained our models on, such as Vicuna, Mistral, LLaMA-3, and\nLLaMA-2. The second baseline is GPT-4 and GPT-3.5. For evaluation, we simply pretended the FASTA\nsequence of the protein in front of the prompt to give the LLM context of the protein."}, {"title": "4.2.5 Close-Ended Accuracy Experiment", "content": "Although semantic-based evaluations may be use-\nful in gauging the feasibility of our outputs, to\nensure our model is outputting factually correct\ninformation regarding a given protein, we also\nconduct a close-ended answer format evaluation\non ProteinGPT with samples from our test subset\nof proteins. We selected 160 proteins for evalu-\nation but only used QA-pairs that had a factual\nsingle-word ground truth and excluded questions\nthat had open-ended answers (e.g. \"describe this\nprotein\"). Examples of such closed-ended ques-\ntions are \"yes\"/\"no\" questions or information on\nthe number of assemblies or polymers in a protein.\nWe then use GPT-40 to directly judge the outputs\nof ProteinGPT to the ground truth in our dataset.\nThe results can be seen in Figure 4. Llama-3 and\nMistral are the best-performing backbone models,"}, {"title": "4.3 Ablation Study", "content": "Lastly, to better understand our contributions and ensure the model is learning at each step in the\narchitecture, we perform an ablation study to demonstrate that the module after each stage is indeed\nimproving the performance of ProteinGPT. ProteinGPT is broken down into three modules: vanilla LLM,\nmodality-aligned LLM, and instruction-tuned LLM.\nVanilla LLM: Table 4 (a) and Table 2 (a) display the semantic and lexical scoring using similar metrics\nfor the vanilla LLM of choice (Vicuna, LLaMA, etc.). This is evaluated on the same set of 160 proteins\nand 3508 questions that we used to evaluate the final model. Also note that at this stage, no training has\nbeen done, the model is the same as the out-of-the-box LLM.\nModality Aligned (MA) LLM: Following this, Table 4 (b) and Table 2 (b) show that of the LLM after\nmodality alignment. Evaluated on the same set of proteins, at this stage, the linear layer has been trained\nto learn to align and fuse the structure and sequence modalities to the LLM.\nInstruction Tuned (IT) LLM: Lastly, as mentioned previously, Tables 4 (c) and 2 (c) are for the fully\naligned and instruction-tuned model. At this stage, the model is complete and has been tuned on our\nGPT-40 curated dataset to follow instructions concisely.\nFigure 5 highlights the performance differences between each of these stages. We can observe that,\nthe instruction-tuned and modality-aligned final model consistently outperforms the modality-only model\nand vanilla LLMs. This falls in line with our hypothesis and demonstrates that our 3 stages of training are\nindeed improving the model's multi-modal understanding of proteins. More specifically, the observation\nthat modality alignment always performs better than a vanilla LLM demonstrates that through this stage,\nthe MLLM understands how to digest multi-modal information. Similarly, the observation that the\ninstruction-tuned and modality-aligned ProteinGPT performs better than all other stages demonstrates\nthat this stage indeed teaches the model how to properly answer questions related to these structures and\nsequences it learned from the previous stage."}, {"title": "5 Related Works", "content": "Protein Representation Learning. Studies in protein representation mainly focus on the four hierarchical\nstructural levels of proteins, which are critical for their biological roles. Some research [24, 25] treat\nprotein sequences as a biological language and utilize the Transformer architecture [26] to model amino\nacid interactions and predict sequences using large sequence databases. Other approaches [5, 27\u201333]\nemploy Masked Language Modeling (MLM) to develop attention mechanisms reflecting protein spatial\ninteraction maps. Structure-oriented methods [34\u201336] encapsulate the functional attributes and spatial\ndata of proteins for tasks like molecule binding [37, 38], protein interface studies [39, 40], and property\npredictions [41]. However, most works rely on single-modal data, which overlooks the cross-modality\ninteractions among text and protein sequence & structure information.\nLarge Language Models. Recent advancements in Large Language Models (LLMs) such as GPT-\n4 [20], LLaMA [42], Mistral Large 2 [17], and Gemini [43] have established new benchmarks in\nnatural language processing (NLP), offering enhanced language comprehension and reasoning [44\u201348].\nMultimodal LLMs (MLLMs) have further extended these capabilities beyond text, enabling the processing\nof natural language task performance on multimodal data [49\u201351].\nFusing Protein with LLMs. The integration of large language models (LLMs) into protein research\nhas yielded innovative methods for understanding protein structures and functions. Given that proteins can\nbe represented as character strings, models like ProteinChat [7] and ProtChatGPT [8] have been developed\nto facilitate the analysis of protein sequences. ProteinChat focuses on providing ChatGPT-like capabilities\nfor interpreting 3D protein structures, while ProtChatGPT leverages a Protein-Language Pertaining\nTransformer (PLP-former) to align protein embeddings with natural language queries, enhancing the\naccessibility of protein data. ProteinCLIP [52] introduces a contrastive learning approach to refine\nprotein sequence embeddings by aligning them with functional text descriptions, improving tasks like\nprotein-protein interaction prediction. InstructProtein [53] further bridges human and protein languages\nby enabling bidirectional generation, facilitating text-based protein function prediction and sequence\ndesign. ProtST [6] presents a framework that strengthens protein language models by integrating protein\nsequences with textual descriptions of their properties, utilizing tasks such as unimodal mask prediction,\nmultimodal representation alignment, and multimodal mask prediction to enhance the understanding\nof protein functions at various levels of detail. ProtLLM [54] introduces a dynamic protein mounting\nmechanism and a protein-as-word language modeling approach, enabling the model to handle interleaved\nprotein and text inputs, and to predict both natural language and protein sequences, with pre-training on\nthe InterPT dataset that combines structured and unstructured biological data. Collectively, these models\ndemonstrate the potential of LLMs to advance protein research."}, {"title": "6 Conclusions", "content": "We introduce ProteinGPT, a protein LLM designed to enhance question-answering capabilities and\nsignificantly expedite the process of protein understanding by providing concise responses to queries.\nProteinGPT fuses structure and sequence modalities to align them to any base LLM, allowing protein\nresearchers to harvest any off-the-shelf model to build a protein model off of. By integrating sequence\nand structural data, ProteinGPT also builds upon existing methodologies in protein-centric large language\nmodels and expands upon them by introducing GPT-40 to enrich protein data with detailed annotations,\nthereby optimizing instruction tuning. Our experimental results indicate that ProteinGPT not only shows\npromise for practical applications in protein understanding and design but also highlights the potential of\ninteractive protein models as a dynamic research tool. This research serves as an incremental step towards\nmore sophisticated interactive protein models, and we anticipate that ProteinGPT will contribute to and\ninspire further innovations in protein research, fostering more rapid advancements in this critical field."}, {"title": "Limitations", "content": "Our work has the following limitations. 1) Hallucination ProteinGPT leverages the capabilities of LLMs\nfor protein conversations, thus inheriting their potential for hallucination. This may imply safety concerns\nin the field of biology as it can provide faulty information with significant consequences. 2) Verifiability,\nProteinGPT provides all answers without citations, making it hard to verify and trace the information back\nto the sources. 3) Dependency on Training Data Quality. The effectiveness of the model heavily relies on\nthe quality of the training data. As demonstrated with alignment using GPT-4, different strategies may\nyield vastly different results.\nTo address these issues, future research can focus on more rigorous data processing and selection\nstrategies to ensure model validity and reliability. Additionally, researchers can explore various strategies\nsuch as retrieval augmented generation (RAG) to incorporate cited sources into responses for better\ntrustworthiness and reliability of Protein LLMs. Continuous refinements with expert inputs and feedback\nfrom the biology community could make ProteinGPT integral to protein researchers in the near future."}, {"title": "A Case Studies", "content": "To avoid data leakage, we reserved 30% of our QA and abstract dataset for testing, which is around\n26,419 proteins. This ensures that the tests reflect real-world scenarios as ProteinGPT has never seen\nthese proteins before during training. We provide ProteinGPT's Q and A on Protein 7RUV in Figure 8."}, {"title": "B Comparative Plots", "content": "Figures 7 and 9 highlight the performance comparison across different models, including various versions\nof ProteinGPT, OpenAI's GPT models, and Mistral models, using multiple evaluation metrics.\nFigure 9 shows the performance of ProteinGPT variants alongside OpenAI's GPT and MA models.\nThe key observations from this figure are:\n\u2022 ROUGE-1 and ROUGE-L: The ProteinGPT_Mistral model significantly outperforms the other\nmodels with scores of 0.451 and 0.460, respectively. ProteinGPT_LLaMA-3 and the other GPT\nvariants (GPT-3.5-turbo, GPT-4-turbo, GPT-40) have much lower scores, indicating that the Mistral-\nbased variant is superior in these metrics.\n\u2022 ROUGE-LSum: Similar to ROUGE-1 and ROUGE-L, the ProteinGPT_Mistral variant leads\nwith a score of 0.457, followed closely by ProteinGPT_LLaMA-3 at 0.387. Other models show\nsignificantly lower scores, emphasizing the effectiveness of the Mistral variant.\n\u2022 BERT Score: The ProteinGPT_Mistral model also performs best with a score of 0.821, with\nProteinGPT_LLaMA-3 following at 0.779. The GPT models lag behind, demonstrating that the\nProteinGPT variants are more aligned with human evaluations.\n\u2022 PubMedBert Score: Again, ProteinGPT_Mistral achieves the highest score of 0.758, outper\nforming ProteinGPT_LLaMA-3 slightly. The GPT models perform lower in this biomedical\ndomain-specific metric.\n\u2022 GPT-40 Score: The trend continues with ProteinGPT_Mistral leading at 0.717, while ProteinGPT_LLaMA-3 scores 0.706, suggesting a close performance in this category.\nIn Figure 7, the performance of ProteinGPT with different base large language models (LLMs) is\nevaluated. The following findings are noteworthy:\n\u2022 ROUGE-1 and ROUGE-L: The Mistral variant of ProteinGPT outperforms other base models\n(Vicuna, LLaMA-2, and LLaMA-3) in both ROUGE-1 (0.461) and ROUGE-L (0.460) scores.\nLLaMA-3 follows, but with slightly lower performance, while Vicuna and LLaMA-2 have the\nlowest scores.\n\u2022 ROUGE-LSum: The Mistral base again outperforms others with a score of 0.457, while the\nLLaMA-3 variant is close behind at 0.367.\n\u2022 BERT Score: Mistral shows the best performance (0.821), with other bases following in descending\norder: LLaMA-3 (0.779), LLaMA-2 (0.730), and Vicuna (0.739).\n\u2022 PubMedBert Score: Mistral continues to outperform other base models with a score of 0.758,\nwhile LLaMA-3 follows at 0.706.\n\u2022 GPT-40 Score: The Mistral base model scores highest at 0.717, followed by LLaMA-3 at 0.698.\nOverall, the findings suggest that the ProteinGPT_Mistral variant consistently outperforms other\nmodels across all metrics. The Mistral base model proves to be the most effective for ProteinGPT,\nindicating that the combination of Mistral with ProteinGPT architecture is particularly powerful. In\ncontrast, other base models such as LLaMA-2 and Vicuna, and the GPT variants, show comparatively\nlower performance, especially in metrics like ROUGE-1, ROUGE-L, and the PubMedBert Score, which\nare crucial for natural language processing tasks in specialized domains such as biomedical text analysis."}]}