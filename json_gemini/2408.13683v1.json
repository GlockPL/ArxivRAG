{"title": "Submodular Maximization Approaches for Equitable Client Selection in Federated Learning", "authors": ["Andr\u00e9s C. Castillo J.", "Ege C. Kaya", "Lintao Ye", "Abolfazl Hashemi"], "abstract": "In a conventional Federated Learning framework, client selection for training typically involves the random sampling of a subset of clients in each iteration. However, this random selection often leads to disparate performance among clients, raising concerns regarding fairness, particularly in applications where equitable outcomes are crucial, such as in medical or financial machine learning tasks. This disparity typically becomes more pronounced with the advent of performance-centric client sampling techniques. This paper introduces two novel methods, namely SUBTRUNC and UNIONFL, designed to address the limitations of random client selection. Both approaches utilize submodular function maximization to achieve more balanced models. By modifying the facility location problem, they aim to mitigate the fairness concerns associated with random selection. SUBTRUNC leverages client loss information to diversify solutions, while UNIONFL relies on historical client selection data to ensure a more equitable performance of the final model. Moreover, these algorithms are accompanied by robust theoretical guarantees regarding convergence under reasonable assumptions. The efficacy of these methods is demonstrated through extensive evaluations across heterogeneous scenarios, revealing significant improvements in fairness as measured by a client dissimilarity metric.", "sections": [{"title": "I. INTRODUCTION", "content": "THE Federated Learning (FL) paradigm involves the col-laborative training of a centralized machine learning model using edge devices, commonly referred to as clients. This setting allows for models to be trained using localized data from these devices without the need to transmit the data to a centralized location. Updates to the model are accumulated from these clients via periodic communication rounds and aggregated at the central location resulting in an improved machine learning model.\nTraditionally, randomly selecting a subset of clients has been the de facto approach for this setting [2]. However, pre-vious work has found that, oftentimes, this random selection approach does not perform well in terms of convergence and fairness properties, especially in heterogeneous settings where the data being held by each client may not necessarily come from the same distribution [3]. This is especially evident in applications characterized by a high degree of data heterogene-ity, where the need for a balanced and fair machine learning model is highly prioritized, such as in the use of computer vision models in medical imaging, where, for example, the data may be MRI images that have been produced by machines from different manufacturers. Because of this, client selection remains an open challenge within the field [4], [5]. Another motivating scenario is the case of networked sensing [6], [7]. In networks comprising units, there is a common goal to devise an inference method that reduces the total estimation error. Nevertheless, in numerous scenarios, each unit must produce a dependable estimate to avoid impeding decision-making among other units in the network [8]. For instance, in autonomous vehicle settings, a unit with substantial estimation error might necessitate slowing down, thus influencing the behavior of other units [9]. Hence, there is an urgent need to minimize the collective mean-square estimation error across the entire network while ensuring consistent performance among individual units. Such considerations have further re-ceived attention in shared communication systems [10].\nTo address this, differing from previous client selection strategies, the idea of incorporating submodular set functions as a viable strategy for solving the client selection problem has been proposed [11]\u2013[14]. A typical problem studied in submodular optimization literature is the maximization of a submodular function under a cardinality constraint [15]\u2013[17]. In this problem, the task is to maximize the utility of the selection made from a ground set N, while making sure that the number of elements in the selection stays under a given integer cardinality constraint value \u03ba. This can be formalized as\n$\\max_{S\\subset N} f(S) \\text{ s.t. } |S| \\leq \\kappa,$\nwhere f is a submodular function, N is the ground set, and \u03ba is a positive integer."}, {"title": "A. Contributions", "content": "This paper presents two novel algorithms, SUBTRUNC and UNIONFL, specifically designed to enhance the fairness of client selection criteria within the context of Federated Learning. These algorithms employ a tailored submodular function approach derived from the facility location problem to optimize client selection.\nBuilding upon the framework of DIVFL [11], SUBTRUNC modifies the gradient similarity approach by integrating a truncated submodular function term. This addition serves as a regularization term aimed at encouraging balance by incorporating both the gradient similarity metrics and the individual loss values of clients. Consequently, the resulting model achieves a more equitable performance distribution across all clients.\nSimilarly, UNIONFL introduces a regularization term that promotes client diversification. By maintaining a record of selected clients within a window of preceding time steps in each round, UNIONFL promotes diverse solutions by encour-aging the involvement of clients that have not been previously selected in a similar manner. Notably, this regularization term seamlessly integrates into conventional submodular maximiza-tion frameworks, offering a streamlined approach to promoting fairness in client selection.\nBoth of these proposed methods not only ensure the se-lection of the most representative clients but also facilitate their participation in a fair manner, leading to a model that exhibits uniform performance across all clients, both in terms of training and test outcomes.\nAdditionally, we show that these algorithms enjoy strong theoretical guarantees on their convergence under mild as-sumptions such as nonconvexity. In particular, under smooth-ness, and without assuming the well-known Bounded Client Dissimilarity (BCD) assumption where one assumes that for some $G^2 \\in \\mathbb{R}$,\n$||\\nabla f_i(w) - \\nabla f(w)||^2 \\leq G^2 \\forall w \\in \\mathbb{R}^d, i \\in N.$\nOur work shows that by relaxing: (2), which, in practice, is a hard-to-verify assumption [18]; the assumptions of a uniformly bounded gradient; strong convexity required by prior works; our proposed algorithm then enjoys strong the-oretical guarantees that hold on the expected performance in nonconvex optimization problems. That is, our method needs $K = O(1/\\epsilon^2)$ rounds of communication in order to achieve $\\mathbb{E}[||\\nabla f(w_k)||^2] < \\epsilon$ while doing away with the Bounded Client Dissimilarity Assumption under a smooth nonconvex scenario."}, {"title": "B. Related Works", "content": "Recently, by being able to model client selection through a submodular maximization problem, [11] was able to obtain improved performance when compared with traditional client selection strategies such as random sampling. This work does so by attempting to select a subset of clients whose gradient most closely resembles that of the full client set, by modeling the problem as a submodular maximization problem, which can be solved with greedy methods. Although our work, sim-ilar to [11], utilizes the concept of submodular maximization for client selection, it differs from it in that we employ a facility location submodular function modified by a truncated submodular function, making use of the loss value of each client for the truncation. This modification acts as a fairness-aware term that promotes a balanced model performance across all clients regardless of the distribution of the data these clients may hold, resulting in models whose performance does not drastically differ from client to client throughout the training process. Additionally, our theoretical analysis of the convergence of our method is significantly different from [11] and utilizes considerably milder assumptions.\nBoth [12], [13] have also explored the use of submodular maximization and its greedy solution as a means to solve the client selection problem. In particular, these works seek to create an optimal client schedule under computational and time constraints. This approach differs from ours in that instead of approximating the full client gradient by a subset and greedily selecting them, the problem is modeled as a Submodular-Cost Submodular-Knapsack problem where the selection is constrained by computational and timing metrics, whereas we look at our constraint through a truncated approach, which can be likened to the notion of the presence of a budget. Additionally, neither [12], [13] establish any convergence rate for the resultant FL method.\nIn tackling data heterogeneity and client selection schemes within FL, [14] also approaches the client selection problem as a submodular maximization problem that can be greed-ily solved under a knapsack constraint. This work seeks to maximize statistical performance under system performance constraints, like upload and communication time. This differs from our work in that we leverage the heterogeneity of the data in each client to create more diverse solutions by exploiting the loss at each client's dataset while approximating the solution set via the client's gradient. Additionally, we do not further constrain the problem under system heterogeneity metrics as [14]."}, {"title": "II. PRELIMINARIES AND BACKGROUND", "content": "This paper considers the standard FL setting comprised of a central server that acts as a model aggregator, $\\left|N\\right|$ clients that can participate in training, and a model parameterized by $w \\in \\mathbb{R}^d$. Each client $i$ in this setting has data coming from a distribution $D_i$ and an objective function $f_i(w)$ which is the expected loss of the client concerning some loss function $l$ over drawn data from $D_i$. The main objective is for the central server to optimize the average loss $f(w)$ over the $\\left|N\\right|$ clients:\n$f(w) := \\frac{1}{\\left|N\\right|} \\sum_{i \\in N} f_i(w),$\n$f_i(w) := \\mathbb{E}_{x \\sim D_i}[l(x, w)].$\nWhen the data distributions across all clients are equal, the setting is considered independent and identically distributed (iid). If they differ across clients, then it is considered hetero-geneous (non-iid).\nAt any given round of a typical FL setting, a random subset of clients is chosen to perform training. By carrying out a series of local gradient descent updates in the client's data and communicating these to the central server, the final model is constructed. This method of averaging out the client's updates is known as the FEDAVG algorithm [2].\nHowever, client selection still remains an open challenge within FL [4], [5]. Recently, utilizing submodular functions for client selection by modeling the problem as a facility location problem was introduced [11]. This strategy aims to find a representative subset of clients whose aggregated update models what the overall aggregated update would look like if all clients participated in the training.\nOur proposed methods build up on the idea of leveraging submodular functions to create more representative client sets. It does so by finding a representative subset of clients while"}, {"title": "III. SUBTRUNC AND UNIONFL: FAIRNESS-AWARE CLIENT SELECTION APPROACHES", "content": "In this section, we develop our proposed fairness-aware client selection approaches.\n**A. SubTrunc**\nTo motivate our formulation of a modified facility location objective via a truncated submodular function, we first follow the outline of DivFL [11], which follows the logic found in [31]. Suppose there is a mapping $\u03c3 : N \u2192 S$, in which N is the ground set of elements and S is the constructed set and where the gradient information $\u2207f_i(w)$ from client i is approximated by the gradient information from a selected client $\u03c3(j) \u2208 S$. For $j \u2208 S$, $C_j := {i \u2208 N|\u03c3(i) = j}$ is the set approximated by client j and $\u03b3_j := |C_j|$ results in the following formulation:\n$\\min_{S \\subset N} \\sum_{i \\in N} ||\\nabla f_i(w) - \\sum_{j \\in S} \\gamma_j \\nabla f_j(w)|| \\leq \\sum_{j \\in S} \\min_{j \\in S} ||\\nabla f_i(w) - \\nabla f_j(w)|| := \\hat{G}(S).$\nThat is, $\\sum_{j \\in S} \\gamma_j \\nabla f_j(w)$ can be viewed as the approximation of the global gradient $\\sum_{i \\in N} \\nabla f_i(w)$. Therefore, the left-hand side of (9) can be interpreted as the approximation error, and the right-hand side of (9) provides an upper bound on the approximation error. Thus, to minimize the approximation error, DIVFL aims to select a set of clients S that minimizes $\\hat{G}(S)$ subject to a cardinality constraint on S. Upon defining $\\tilde{G}(S) := \\hat{G}(\u2205) - \\hat{G}(S)$ this task can be written as\n$\\max_{S \\subset N} \\tilde{G}(S) \\text{ s.t. } |S| \\leq \\kappa,$\nwhere \u03ba is a target bound on the number of participating clients in each communication round. Minimizing $\\hat{G}(S)$ or equiva-lently maximizing $\\tilde{G}(S)$ is the equivalent of maximizing the well-known facility location monotone submodular function [16]. However, this problem, under a cardinality constraint, is NP-hard in general which requires efficient approximation algorithms to provide a near-optimal solution. The greedy algorithm and its randomized variants are among the canonical methods for such optimization problems [32]\u2013[35].\nFinding the most representative set at any given round may not always provide a model that performs in a balanced and similar fashion across all clients thereby leading to potential unfair behaviours in FL-based model training. As a result of this observation, we propose a fairness regularization term utilizing the truncation of a judicious submodular function:\n$H(S) := \\min(b, F(S)),$\nwith\n$F(S) := \\sum_{i \\in S} \u03c6(f_i(w)),$\nwhere $f_i(w)$ is the expected loss of client $i$ with respect to some loss function $l$ as defined in (4), $\u03bb > 0$ and $b \u2208 \u211d_+$ are input parameters aiming to explore the inherent trade-off between performance and fairness; $\u03c6$ can be any monotone nondecreasing function with a bounded Lipschitz constant L. Tying client loss to this regularization term enhances a diver-sified client selection process. Changes in b allow for further client participation, especially for those clients with minimal participation, thus ensuring a more fair total client participa-tion, where each client can have an opportunity to contribute to the final model. When a function with $L < 1$ is used, $F(S)$ effectively becomes an attenuation term, suppressing the difference between the client losses. Whereas, when $L > 1$, $F(S)$ enhances this difference. However, the choice of \u03c6 could be a potential avenue of further research as finding a \u03c6 that judiciously tunes this attenuation or enhancement effect could be of interest. Here, we assume without loss of generality that the clients' loss functions are nonnegative. The combination of this fairness-aware term with the original objective results in the following optimization for client selection:\n$\\max_{S \\subset N} W(S) := \\tilde{G}(S) + \u03bbH(S) \\text{ s.t. } |S| \\leq \\kappa.$\nA desirable property of the proposed formulation is the preservation of monotonicity and submodularity, which is indeed the case, as demonstrated next.\n**Proposition 3.** *The set function W(S) in (13) is monotone and submodular.*\nProof. Note that F(S) is a modular function and hence monotone and submodular [16]. By Proposition 1, H(S) is therefore a monotone submodular function. Finally, from Proposition 2, it can be seen that any linear combination of submodular functions with the same ground set remains submodular. Since both $\\tilde{G}(S)$ and H(S) in (11) are monotone submodular, their nonnegative linear combination in (13) is also monotone submodular.\n**B. UnionFL**\nWe further propose the following novel formulation, which incorporates a regularization term involving the history of previously constructed solutions to the objective function, to promote diversification of the sequence of subsequent solu-tions. Additionally, this method can also be employed with any objective function so long as this objective function is submodular. Suppose $f_t : N_t \u2192 \u211d_+$ is a submodular objective function that we wish to maximize at time step t, making a selection out of ground set $N_t$, selecting no more elements than $\u03ba_t$. We propose the regularization of this objective as follows:\n$\\max_{S_t \\subset N_t} f_t(S_t) - \u03bcg_t(S_t) \\text{ s.t. } |S_t| \\leq \\kappa_t.$\nwhere $g_t(S_t) := |(\\bigcup_{i \\in u_t} S_i) \u2229 S_t|$; $f_t(S_t)$, is the submodular function as defined by (10), however it is worth pointing out that any submodular function fits into this framework; $u_t$ is a 'look-back' window hyperparameter for previously constructed sets; $\u03bc \u2265 0$ is a regularization hyperparameter and $t$, represents the concept of global rounds within the FL framework.\nIn this formulation the original objective function, $f_t(S_t)$, is penalized by, $\u03bcg_t(S_t)$, based on how many elements the solution set that is currently being constructed has in common with the previous solution sets constructed through time steps within a window $u_t$. For instance, at time step t, a typical value for $u_t$ might be $u_t = {t \u2013 5, ..., t - 1}$ in which case, the penalization at each time step t would depend on the common elements of not only the current solution but also the common elements with the latest 5 solutions.\nWe can easily see that as $u_t$ increases, the original objective suffers a heavier penalty given that we will be looking into more previously constructed solution sets, which means that our common client pool will be larger. On the contrary, as"}, {"title": "Algorithm 1 FAIRNESS-AWARE FL ALGORITHMS", "content": "Input: Truncation, regularization parameters $b, \u03bb, \u03bc \u2208 \u211d$, and window schedule $u_t$, communication rounds $K$, local steps $E$, participating clients $\u03ba$, initial weight vector $w_0$, learning rate $\u03b7$\nOutput: $w_K$, weights for trained model\n1: Server initializes $w_0$\n2: for $k$ = 1, ..., $K$ do\n3: Subset $S_k$ of size \u03ba is selected by the server via the stochastic variant of the na\u00efve greedy algorithm,\n4: following the formulation of (13) or alternatively the formulation of (14).\n5: for client $i \u2208 S_k$ do\n6: $w_{k,0}^{(i)} \u2190 w_k$\n7: for $r$ = 1, ..., $E$ do\n8: Select random batch from client $i$:\n9: $B_{k,r}^{(i)}$\n10: compute stochastic gradient $f_i$ at $w_{k,r}^{(i)}$ over $B_{k,r}^{(i)}$\n11: $\u2207f_i(w_{k,r}^{(i)}; B_{k,r}^{(i)})$ :\n12: $w_{k,r+1}^{(i)} \u2190 w_{k,r}^{(i)} - \u03b7\u2207f_i(w_{k,r}^{(i)}; B_{k,r}^{(i)})$ :\n13: end for\n14: $w_k^{(i)} \u2190 w_{k,E}^{(i)}$\n15: end for\n16: $w_{k+1} \u2190 \\frac{1}{\u03ba} \\sum_{i \\in S_k} w_k^{(i)}$\n17: end for\n18: return $w_K$ \u25b7 Final model weights\nA na\u00efve greedy approach starts at round k with an empty set, $S_k \u2205$, and adds the element $e \u2208 N \\ S_k$ which provides the highest marginal gain, $\u0394(e|S_k)$.\n$S_{k+1} S_k\u222a {argmax_{e \u2208 N\\S_k} (\u0394(e|S_k))}.$\nNonetheless, if the cardinality of the ground set N is too large, searching through this space for the desired elements may prove to be too expensive. Because of this, stochastic variants of the na\u00efve greedy algorithm can be employed [33]\u2013[37] to effectively reduce this search cost while still maintaining high-confidence in the solution provided. This is done by randomly sampling a smaller subset $R$ of size r and searching through this reduced space. That is:\n$S_{k+1} S_k\u222a {argmax_{e \u2208 R\\S_k} (\u0394(e|S_k))}.$\nApplying the selection strategy utilizing (13) or alternatively (14), and using the FEDAVG algorithm as the core method for aggregating client model updates results in our proposed algo-rithms SUBTRUNC and UNIONFL, summarized as Algorithm 1."}, {"title": "IV. THEORETICAL CONVERGENCE ANALYSIS", "content": "In this section, we analyze the convergence properties of the proposed algorithms under standard assumptions in nonconvex FL. Our analysis utilizes more relaxed assumptions compared to [11], complementing our proposed fairness-promoting for-mulation."}, {"title": "APPENDIX", "content": "**A. Convergence Analysis for SUBTRUNC and UNIONFL**\nWe will provide convergence results for SUBTRUNC, with-out the Bounded Client Dissimilarity Assumption. Following a similar outline to [18], we use Lemma 1 and exploit the L-smoothness of f to obtain a bound on the per-round progress of the algorithm. Additionally both Lemmas 2, 3 are used to help bound terms deriving from the analysis of Lemma 1, mainly dealing with bounding the gradient error at any given round as well as providing a bound on the expected value of the gradient for each client at any given communication round k and local step 7. Different from [18], we carefully account for the bias terms that arise from utilizing the submodular client selection method by leveraging Assumption 3.\nNow, we present the proof of Theorem 1 which states the convergence properties of SUBTRUNC.\n*Proof.* Using the results from Lemma 1, for $\u03b7_kLE \\le \\frac{3}{4}$, the per-round progress can be bounded as follows:\n$\\mathbb{E}[f(w_{k+1})] \\leq \\mathbb{E}[f(w_k)] - \\frac{\u03b7_kE}{4} \\mathbb{E}[||\u2207f(w_k)||^2] + \\frac{\u03b7_kLE^2}{2}(\\frac{9\u03b7_kLE}{4} + 1) \\sum_{i\u2208[n]} \\mathbb{E}[||\u2207f_i(w_k)||^2] + \\frac{\u03b7_kLE^2}{2} ((\\frac{9\u03b7_kLE}{4}) + \\frac{3E}{4} + 1)\\frac{\u03c3^2}{n} + \u03b7_k(1+\u03b7_kLE)E\u03b3$.\nNow, by utilizing $f_i$'s attributes of L-smoothness and non-negativity, we obtain the following:\n$\\sum_{i \\in [n]} \\mathbb{E}[||\u2207f_i(w_k)||^2] \\leq \\sum_{i \\in [n]} 2L (f_i(w_k) - f_*) \\leq 2nLf(w_k) - 2nLf* \\leq 2nLf(w_k) - 2Lf* \\leq 2nLf(w_k).$\nPlugging the above to the result of Lemma 1 and setting a constant learning rate $\u03b7_k = \u03b7$, we get:\n$\\mathbb{E}[f(w_{k+1})] \\leq (1 + \u03b7^2L^2E^2 (\\frac{9\u03b7LF}{4} + 1)) \\mathbb{E}[f(w_k)] - \\frac{\u03b7E}{4} \\mathbb{E}[||\u2207f(w_k)||^2] + \\frac{\u03b7^2LE^2}{2} ((\\frac{9\u03b7LE}{4}) + \\frac{3E}{4} + 1) \\frac{\u03c3^2}{n} + \u03b7 (1 + \u03b7LE) E\u03b3.$\nLet us define the following $\u03b6_1 := \u03b7^2L^2E^2(\\frac{9\u03b7LE}{4} + 1)$, $\u03b6_2 := \\frac{\u03b7^2LE^2}{2} ((\\frac{9\u03b7LE}{4}) + \\frac{3E}{4} + 1) \\frac{\u03c3^2}{n}$, and finally $\u03b6_3 := \u03b7 (1 + \u03b7LE) E\u03b3$. Then substituting the above, and unfolding the recursion of (21), we obtain:\n$\\mathbb{E}[f(w_K)] \\leq (1 + \u03b6_1)^K f(w_0) - \\frac{\u03b7E}{4} \\sum_{k=0}^{K-1} (1 + \u03b6_1)^{(K-1-k)} \\mathbb{E}[||\u2207f(w_k)||^2] + \\frac{\u03b6_2}{\u03b7} \\sum_{k=0}^{K-1} (1 + \u03b6_1)^{(K-1-k)} + \\frac{\u03b6_3}{\u03b7} \\sum_{k=0}^{K-1} (1 + \u03b6_1)^{(K-1-k)}."}]}