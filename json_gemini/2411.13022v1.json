{"title": "Training Physics-Driven Deep Learning Reconstruction without Raw Data Access for Equitable Fast MRI", "authors": ["Ya\u015far Utku Al\u00e7alar", "Merve G\u00fclle", "Mehmet Ak\u00e7akaya"], "abstract": "Physics-driven deep learning (PD-DL) approaches have become popular for improved reconstruction of fast magnetic resonance imaging (MRI) scans. Even though PD-DL offers higher acceleration rates compared to existing clinical fast MRI techniques, their use has been limited outside specialized MRI centers. One impediment for their deployment is the difficulties with generalization to pathologies or population groups that are not well-represented in training sets. This has been noted in several studies, and fine-tuning on target populations to improve reconstruction has been suggested. However, current approaches for PD-DL training require access to raw k-space measurements, which is typically only available at specialized MRI centers that have research agreements for such data access. This is especially an issue for rural and underserved areas, where commercial MRI scanners only provide access to a final reconstructed image. To tackle these challenges, we propose Compressibility-inspired Unsupervised Learning via Parallel Imaging Fidelity (CUPID) for high-quality PD-DL training, using only routine clinical reconstructed images exported from an MRI scanner. CUPID evaluates the goodness of the output with a compressibility-based approach, while ensuring that the output stays consistent with the clinical parallel imaging reconstruction through well-designed perturbations. Our results show that CUPID achieves similar quality compared to well-established PD-DL training strategies that require raw k-space data access, while outperforming conventional compressed sensing (CS) and state-of-the-art generative methods. We also demonstrate its effectiveness in a zero-shot training setup for retrospectively and prospectively sub-sampled acquisitions, attesting to its minimal training burden. As an approach that radically deviates from existing strategies, CUPID presents an opportunity to provide equitable access to fast MRI for underserved populations in an attempt to reduce the inequalities associated with this expensive imaging modality.", "sections": [{"title": "1 Introduction", "content": "Magnetic resonance imaging (MRI) is a central tool in modern medicine, offering multiple soft tissue contrasts and high diagnostic sensitivity for numerous diseases. However, MRI is among the most expensive medical imaging modalities, in part due to its long scan times. Demand for MRI scans has shown an annual growth rate of 2.5%, while the number of MRI units per capita has increased by 1.8% in a similar time frame (Martella et al., 2023). This mismatch has further increased the wait times for MRI exams (Bartsch et al., 2024; Hofmann et al., 2023), particularly in rural areas and underserved communities (Burdorf, 2022), as depicted in Fig. 1. Thus, techniques for fast MRI scanning that can reduce overall scan times without compromising diagnostic quality (Ak\u00e7akaya et al., 2022) are critical for improving the throughput of MRI.\nComputational MRI approaches, including partial Fourier imaging (McGibney et al., 1993), parallel imaging (Pruessmann et al., 1999; Griswold et al., 2002), compressed sensing (Lustig et al., 2007), and more recently deep learning (DL) (Hammernik et al., 2018; Schlemper et al., 2018) have been developed for accelerating MRI. In most MRI centers, parallel imaging remains the most widely used approach for the reconstruction of routine clinical images. The acceleration rates afforded by these methods, however, are limited due to noise amplification and aliasing artifacts. DL-based methods, especially physics-driven DL (PD-DL) approaches, offer state-of-the-art improvements over parallel imaging (Knoll et al., 2020a). However, the translation of PD-DL to clinic has been hindered by generalizability and artifact issues related to details not well represented in training databases, in other words when faced with out-of-distribution samples at test"}, {"title": "2 Background and Related Work", "content": ""}, {"title": "2.1 MRI Forward Model and Conventional Methods for MRI Reconstruction", "content": "MRI raw data is acquired in the frequency domain of the image, referred to as k-space. For fast MRI, data is acquired in the sub-Nyquist regime by undersampling the acquisition in k-space. In this case, the forward acquisition model relating the image x \u2208 Cn to these raw MRI data (or k-space) measurements is given as:\n$\\Upsilon_{\\Omega} = E x + n,$\nwhere yo denotes the acquired k-space data corresponding to the undersampling pattern \u03a9 with |\u03a9| = m < n. En denotes the multi-coil encoding operator that includes information from ne receiver coils, each of which are sensitive to a different part of the image (Hamilton et al., 2017). When the acceleration rate R = n/m is less than ne, this system of equations is over-determined due to the redundancies among the receiver coils. Parallel imaging uses these redundancies to solve the maximum likelihood estimation problem under i.i.d. Gaussian noise (Pruessmann et al., 1999):\n$x_{PI} = arg min ||y_{\\Omega} - E x||_2^2 = (E^H E_{\\Omega})^{-1} E_{\\Omega}^H y_{\\Omega}$\nNumerically, this can be solved directly for certain undersampling patterns (Pruessmann et al., 1999) or more broadly iteratively using conjugate gradient (CG) (Pruessmann et al., 2001). Using the equivalence of multiplication in image domain and convolutions in k-space (Uecker et al., 2014), it can also be solved as an interpolation problem in k-space (Griswold et al., 2002). Parallel imaging remains the most clinically used acceleration method for MRI, with some MR systems using the image-based reconstruction, while others utilizing the equivalent k-space interpolation.\nIn modern computational MRI, additional regularization is often incorporated into the objective function (Hammernik et al., 2023):\n$arg min ||y_{\\Omega} - E x||_2^2 + \\tau R(x),$\nwhere R(.) denotes a regularizer. For instance, compressed sensing (CS) uses the idea that images should be compressible in an appropriate transform domain (Lustig et al., 2007), and uses R(x) = T||WX||1, where is the regularization weight, W is a linear sparsifying transform such as a discrete wavelet transform (DWT) and ||\u00b7 ||1 is the l\u2081 norm."}, {"title": "2.2 PD-DL Reconstruction via Algorithm Unrolling", "content": "Among different PD-DL methods (Ahmad et al., 2020; Gilton et al., 2021; Knoll et al., 2020a), unrolled networks (Monga et al., 2021) remain the highest performer in reconstruction challenges, as reported a year ago (Hammernik et al., 2023; Muckley et al., 2021). These methods unroll iterative algorithms for solving the regularized least squares objective in (3) (Fessler, 2020), such as proximal gradient descent (Schlemper et al., 2018) or variable splitting with quadratic penalty (VS-QP) (Aggarwal et al., 2019), over a fixed number of steps. VS-QP transforms (3) into 2 sub-problems:\n$z^{(i)} = arg min \\frac{1}{2} ||x^{(i-1)} - z||_2^2 + R(z),$\n$x^{(i)} = arg min \\frac{1}{2} ||y_{\\Omega} - E x||_2^2 + \\frac{\\mu}{2} ||x - z^{(i)}||_2^2,$\nwhere (4a) is the proximal operator for the regularization, implicitly solved using neural networks, while (4b) accounts for data fidelity and has a closed form solution:\n$x^{(i)} = (E^H E_{\\Omega} + \\mu I)^{-1} (E_{\\Omega}^H y_{\\Omega} + \\mu z^{(i)}),$\nwhich can be solved by CG (Aggarwal et al., 2019). Unrolled networks are conventionally trained using supervised learning over a database, where the reference raw k-space measurements are first retrospectively undersampled to form yo. Subsequently, the network is trained to map to"}, {"title": "2.3 Self-Supervised and Unsupervised Methods", "content": "Obtaining fully-sampled reference data in MRI can be infeasible due to prolonged scan durations, organ movement in acquisitions such as real-time cardiac imaging or myocardial perfusion (Rajiah et al., 2023), or signal decay in acquisitions like diffusion MRI with EPI (U\u011furbil et al., 2013). To enable training of PD-DL networks without fully sampled raw MRI data, a variety of unsupervised learning methodologies have emerged (Ak\u00e7akaya et al., 2022), including self-supervised learning techniques (Yaman et al., 2020; Chen et al., 2021) and generative modeling approaches (Jalal et al., 2021; Chung & Ye, 2022; Chung et al., 2023).\nSelf-supervised methods use a masking approach to generate supervisory labels from the under-sampled data (Yaman et al., 2020; Millard & Chiew, 2023; Hu et al., 2024). A pioneering method in this field, self-supervision via data undersampling (SSDU) (Yaman et al., 2020, 2022a), involves partitioning the acquired measurement \u03a9 into two disjoint subsets (\u03a9 = \u039b\u03c5\u0398) to train the network in a self-supervised manner:\n$min E [L (y_{\\Lambda}, E_{\\Lambda} (f(y_{\\Theta}, E_{\\Theta}; \\Theta)))]$\nEven though these self-supervision based approaches demonstrate exceptional performance across various tasks, they lack the ability to train the model without access to undersampled raw data, as they cannot operate solely using images that are exported from the scanner.\nConversely, generative methods learn the prior distribution of the given dataset, which is then leveraged in conjunction with a log-likelihood data term during the testing phase. Although recent methods based on diffusion/score-based models have shown substantial promise, these methods require large amounts of high-quality images either reconstructed from raw data (Jalal et al., 2021; Luo et al., 2023) or as DICOMs (Chung & Ye, 2022), as well as computational resources to perform the training, both of which may not be feasible in the setups we are focused on."}, {"title": "3 Unsupervised Training for PD-DL without Raw k-space Data", "content": "In this study, we introduce a novel framework to train PD-DL models, utilizing only routinely available clinical images exported directly from MRI scanners. Recently, inspired by the connections between PD-DL and compressibility-based processing (Gu et al., 2022), a compressibility-inspired loss was proposed to evaluate the goodness of unsupervised PD-DL training (Al\u00e7alar et al., 2024). However, this approach still requires access to raw k-space data to stabilize training, making it unsuitable for our goals. Here, we adapt the compressibility idea and augment it with a parallel imaging fidelity to successfully reconstruct clinical images in DICOM format without needing any raw k-space data.\nCompressibility Aspect of the Loss Formulation. Compressibility/sparsity in the output of the PD-DL network can be enforced by utilizing a weighted l\u2081 norm (Al\u00e7alar et al., 2024), which has been demonstrated to provide a closer approximation to the lo norm compared to the standard l1 norm (Candes et al., 2008). Thus, this compressibility of the output image in CUPID is achieved by the loss term\n$L_{comp}(x_{PI}, x^{(m)}) = \\frac{1}{N} \\sum_{n=1}^N (\\frac{|(Wf(x_{PI}, E_{\\Omega}))_n|}{|(Wx^{(m)})_n| + \\epsilon}),$\nwhere XPI denotes the DICOM input acquired using parallel imaging, W represents the wavelet transform, N is the total number of wavelet coefficients and x(m) signifies the signal estimate following the training during the mth reweighting step. Similar to Al\u00e7alar et al. (2024); Candes et al. (2008), we chose the initial weights from a CS reconstruction that has a large regularization and e is added for numerical stability. Note, here we redefined f(,) without the network parameters, 0, and used XPI as the network input instead of yn, to simplify notation."}, {"title": "Parallel Imaging Fidelity", "content": "Relying solely on (8) will result in inaccurate training as the neural network learns to produce an all-zeros image in an effort to drive the wavelet coefficients in the numerator to zero, which minimizes the loss function in (8). In Al\u00e7alar et al. (2024), fidelity with raw k-space data was used to avoid this training issue. In our setting without raw k-space access, we introduce a novel fidelity operator that stabilizes the training of the reconstruction algorithm, building on ideas from parallel imaging.\nSpecifically, we ensure that our network outputs are consistent with any clinical parallel imag-ing reconstruction through carefully crafted perturbations, {pk}. These perturbations for R-fold acceleration are designed in such a way that R-fold aliasing do not create overlaps in the field-of-view, indicating that they could be resolved by parallel imaging reconstruction. The idea behind this design choice is to ensure that the network, when applied to the unperturbed XPI, yields an accurate estimate of x, and when applied to XP1 + p, similarly recovers x + p, as the perturbation p must be resolvable within the framework of any parallel imaging approach. Both processes are visualized in Fig. 2. By doing so, the consistency term ensures a non-zero output when the sparsity is minimized. Thus, our second loss term that enforces parallel imaging fidelity is given as:\n$L_{pif}(x_{PI}) = E_{\\rho} [\\frac{||f(x_{PI} + \\rho, E_{\\Omega}) - \\rho - f(x_{PI}, E_{\\Omega})||_2^2}{||\\rho||_2^2}]$\nFrom an implementation perspective, the expectation over p is calculated over K such perturba-tions {pk}. The fold-over constraint for each {pk} is achieved by picking the perturbations as randomly rotated and positioned letters, numbers, card suits or other shapes that have different intensity values. These choices also ensure that high-frequency information, such as edges, are accurately reconstructed by the regularization process. Our final loss function for CUPID is:\n$L_{CUPID} = L_{comp} + \\lambda. L_{pif},$\nwhere \u03bb is a trade-off parameter between two terms."}, {"title": "Subject-Specific / Zero-Shot Application", "content": "In resource-limited or underserved settings, it may be more practical to fine-tune the method using only a few subjects, or even a single"}, {"title": "4 Evaluation", "content": "We conducted a thorough evaluation of our method, assessing its performance through both qual-itative and quantitative analyses, and focused on uniform/equidistant patterns which produces coherent artifacts that are more difficult to remove compared to the incoherent artifacts from random undersampling (Knoll et al., 2019). We further note that CUPID demonstrates robust performance across a wide range of A values, provided that A is chosen within a reasonable range. An ablation study on the choice of A is included in Sec. 4.5."}, {"title": "4.1 Experimental Setup and Implementation Details", "content": "Retrospective Undersampling Setup. In our retrospective studies, we used fully-sampled multi-coil knee and brain MRI data from the fastMRI database (Knoll et al., 2020b). Knee dataset included fully-sampled coronal proton density-weighted (coronal PD) and PD with fat suppression (coronal PD-FS) data. For brain MRI, axial FLAIR (ax-FLAIR) dataset with matrix size of 320\u00d7320 is used. The knee and brain MRI datasets comprised data collected from 15 and 20 receiver coils, respectively. Both datasets were retrospectively undersampled using a uniform/equidistant pattern at R = 4. 24 lines of auto-calibration signal (ACS) from center of the raw k-space data were kept. DICOM images to train our proposed model were reconstructed using parallel imaging (CG-SENSE), solving XP1 = (EHE)-1. For each dataset, models were trained using 300 slices, and testing was performed using 380 slices for knee MRI and 100 slices for brain MRI, from distinct subjects.\nProspective Undersampling Setup. A multi-echo 3D GRE sequence on a 7T Siemens Magne-tom MRI scanner was acquired. In this experiment, we replicate the practical pipeline for CUPID, where data is acquired at the desired high acceleration rate, and reconstructed to XPI with noise and aliasing artifacts, using parallel imaging. The corresponding DICOM images are exported and used for fine-tuning the PD-DL model with CUPID. To this end, the brain dataset, with matrix size = 288 \u00d7 288 and in-plane resolution 0.7 \u00d7 0.7mm\u00b2, was acquired with prospective undersam-pling R = 9 (in ky only), which is the desired target acceleration, much higher than the clinical protocol at R = 3. Low-resolution images were acquired in the same orientation for sensitivity estimation (Krueger et al., 2023). Training and reconstruction with CUPID was done in a zero-shot subject-specific manner.\nMore details about the implementation of the PD-DL models are provided in Appendix A."}, {"title": "4.2 Comparison Methods", "content": "We compared our method against several database training methods that have access to raw k-space data, including supervised PD-DL (Hammernik et al., 2018; Aggarwal et al., 2019; Knoll et al., 2020a), self-supervision via data undersampling (SSDU) (Yaman et al., 2020), and equivariant imaging (EI) (Chen et al., 2021). All PD-DL methods utilized the same unrolled network and components (Appendix A) to ensure that only the training process differed for fair comparisons.\nIn addition, we compared our approach with methods that can operate without raw data access as long as En is known at test time. These include compressed sensing (CS) (Lustig et al., 2007), and ScoreMRI (Chung & Ye, 2022). The latter trains a time-dependent score function using denoising score matching on a large dataset of reference fully-sampled images, and uses this score function during inference to sample from the conditional distribution given the measurements. Note both CS and ScoreMRI use \u0395n for data fidelity during inference. This can be accessed by multiplying XP1 with \u0395\u0395\u03a9. Note that En includes information about the undersampling pattern \u03a9, which is completely known from the acquisition parameters, and coil sensitivities, which can be estimated from separate calibration scans in DICOM format (Krueger et al., 2023). A similar observation applies to the data fidelity in (5) for unrolled networks, thus they can be used for inference using only XPI and En. We emphasize that what sets CUPID apart from other PD-DL strategies is that it is the only one that can train the unrolled network without using yo. Thus, without loss"}, {"title": "4.3 Experiments with Retrospectively Undersampled Data", "content": "Database Results. Representative results in Fig. 3 show that baseline CG-SENSE, CS, EI and ScoreMRI reconstructions exhibit residual artifacts. In contrast, CUPID successfully eliminates these artifacts from the CG-SENSE image using a well-trained PD-DL network, achieving state-of-the-art reconstruction quality comparable to supervised PD-DL and SSDU, despite only having access to XPI for training, and not to raw k-space data unlike these other methods. We observe that parallel imaging reconstruction is not clinically usable at higher acceleration rates, but it is improved using a PD-DL reconstruction trained with CUPID. We further note that mild blurring was observed in some slices for database-training only. This is expected since we are no longer benefiting from redundancies from across multiple coils due to having no access to multi-coil raw k-space data, unlike the comparison methods. Quantitative results presented in Tab. 1 validate the visual observations, demonstrating that CUPID consistently outperforms CG-SENSE, CS, EI, and ScoreMRI across multiple datasets. Moreover, CUPID maintains performance comparable to"}, {"title": "4.4 Practical Setting: Prospectively Undersampled Study", "content": "As discussed in Sec. 4.1, brain data is acquired at the target acceleration rate, reconstructed via parallel imaging and exported in DICOM format to perform zero-shot fine-tuning. Fig. 5 shows reconstruction results for the vendor parallel imaging reconstruction, as well as CS, ScoreMRI and CUPID. CS reduces the noise in the parallel imaging reconstruction, but leads to blurring due to over-regularization. In contrast, ScoreMRI struggles to reconstruct accurately at this high accel-eration rate, suggesting generalizability issues for the pre-trained score function to high-resolution imaging at a different field strength, not represented in the training database, and potential dif-ficulties with uniform undersampling. Furthermore, the public implementation of ScoreMRI uses hard constraints for data fidelity, which leads to more pronounced artifacts due to potential phase mismatch with the coils generated from separate calibration data. Our proposed CUPID method effectively mitigates both artifacts and noise in the DICOM image (shown in zoomed insets) with-out requiring any raw k-space data, attesting to the effectiveness of CUPID in real-world scenarios. Note minor residual artifacts remain since the target acceleration R = 9 in 1-dimension is very high. We note that ZS-SSDU cannot be applied here due to the unavailability of raw data. We further note that the vendor-provided DICOM was generated using k-space interpolation (Griswold et al., 2002) instead of the image domain formulation in (2). Due to their equivalence, this did not cause any issues for CUPID, as expected."}, {"title": "4.5 Ablation Studies", "content": "We carried out two ablation studies to explore key factors influencing the performance of our algorithm. The first study explored the effect of A parameter to the final reconstruction, by training 5 distinct PD-DL networks using \u03bb\u2208 {0, 50, 100, 200, \u221e}. We note that using \u03bb = 0 corresponds to using only the compressibility term (Lcomp in (8)), whereas using \u5165 \u2192 \u221e translates to using solely the parallel imaging fidelity term (Lpif in (9). Fig. 6 shows the corresponding reconstruction results for each case. As outlined in Sec. 3, only using Lcomp leads to overly-smooth reconstructions due to network forcing the wavelet coefficients towards zero without maintaining consistency with the data. On the other hand, solely using Lpif results in DIP-like reconstructions (Ulyanov et al., 2018), where the network overfits the data without any regularization, resulting in noise amplification. CUPID with \u03bb\u2208 {50, 100, 200} integrates both loss terms to attain high-fidelity reconstructions. Thus, we conclude that CUPID demonstrates robust performance across a wide range of A values. Our second ablation study focuses on the effect of the number of perturbation patterns used in the training, and is provided in Appendix B.1."}, {"title": "4.6 Discussion and Future Work", "content": "Filtering on Routine Clinical Images. MR scans may include filtering operations applied by some vendors that affect the assumption XP1 = (E)-1. This was discussed extensively in Shimron et al. (2022), in the context of using retrospective undersampling of DICOM images to train DL reconstruction, especially highlighting the use of zero-padding, which improves the display resolution compared to the acquisition resolution. It was shown that training of models from retrospective undersampling of databases of DICOM images for PD-DL training using zero-padding may lead to biases and inaccuracies. Conversely, our approach is physics-driven in nature, and the sampling pattern \u03a9 naturally accounts for the zero-padding operation. However, our method is not immune to other types of filtering/processing, such as implicit intensity correction (Han et al., 2001) or deidentification methods (Van Essen et al., 2013), in which case the filtered XPI would need to be treated as the parallel imaging solution corresponding to a filtered version of y.\nResources for Fine-Tuning of PD-DL Reconstruction. While our method is aimed to improve equitable access to fast MRI in low-resource settings, we do acknowledge that such low-"}, {"title": "5 Conclusion", "content": "In this study, we presented a novel training strategy, Compressibility-inspired Unsupervised Learn-ing via Parallel Imaging Fidelity (CUPID), for PD-DL MRI reconstruction without access to raw k-space data. This approach leverages the compressibility of output images along with strategically designed perturbations that remain intact post-parallel imaging, thereby enhancing image quality in clinically accessible images in a physics-driven manner without the need for any raw k-space data. To the best of our knowledge, this is the first attempt that does not rely on raw data and uses these clinical images to train PD-DL networks, which is known for their high-fidelity reconstruc-tions. CUPID also alleviates the training burden of generative methods, which requires a large number of data during training to capture the prior well. Quantitative and qualitative assessments of our method, conducted on both retrospectively and prospectively accelerated acquisitions, show its effectiveness in delivering high-quality performance across a diverse range of MRI scans and learning settings."}, {"title": "A Implementation Details for Each Method", "content": ""}, {"title": "Compressed Sensing", "content": "We solved the regularized l\u2081 minimization problem given below:\n$arg min ||\\Upsilon_{\\Omega} \u2013 E_{\\Omega}X||_2^2 + \\tau||WX||_1,$\nusing VS-QP (Fessler, 2020). Similar to the unrolled network, data fidelity was solved using CG, and soft thresholding was implemented on the DTCWT coefficients."}, {"title": "ScoreMRI", "content": "For ScoreMRI implementation, we followed the original code and pre-trained network provided by Chung & Ye (2022) in their corresponding public repository."}, {"title": "PD-DL Based Approaches", "content": "For each method, the unrolled network comprised 10 unrolls, while the regularizer was implemented as a CNN-based ResNet architecture (Timofte et al., 2017) that had 10 residual blocks. Data fidelity was achieved using a conjugate-gradient (CG) method (Aggarwal et al., 2019) with 10 iterations. The unrolled network was trained in an end-to-end fashion for 100 epochs. For supervised PD-DL (Hammernik et al., 2018; Aggarwal et al., 2019), the normalized l1-12 loss function was used between the reconstructed and ground truth raw k-space data (Knoll et al., 2020a). For SSDU, \u03c1 = |\u0394|/|\u03a9| = 0.4 was used as proposed in Yaman et al. (2020). For EI (Chen et al., 2021), we modified the loss function in PD-DL networks to:\n$min E [L (y_{\\Theta}, f(y_{\\Lambda}, E_{\\Lambda}; \\Theta))] + \\beta \\sum_{g \\in G} L (T_gf (y_{\\Lambda}, E_{\\Lambda}; \\Theta), f (E_{\\Lambda}T_g f (y_{\\Lambda}, E_{\\Lambda}; \\Theta), E_{\\Lambda}; \\Theta))$\nin which the first term enforces consistency while the second term imposes equivariance relative to a group of transformations, {Tg}g\u2208G. Here, |G| defined as the cardinality of {Tg}g\u2208G and B is the equivariance weight. We followed the authors' publicly available CT reconstruction code for EI (Chen et al., 2021), and employed 3 rotations along with 2 flips. For CUPID, dual-tree complex wavelet transform (DTCWT) which provides an over-complete representation (Selesnick"}, {"title": "B Perturbation Strategies", "content": ""}, {"title": "B.1 Choice for Number of Perturbation Patterns", "content": "The empirical expectation that approximates the one in (9) is expected to converge to the true expectation as we introduce more perturbation patterns and randomness over the choice of p. Fig. 7 shows the zero-shot fine-tuning results of CUPID with K\u2208 {1,3,6,10}, while Fig. 8(a) and Fig. 8(b) illustrates the corresponding PSNR and SSIM curves throughout the training epochs, respectively. As expected, using a single pattern could not capture the true mean and exhibits artifacts. As we introduce more perturbations, we reduce the artifacts and noise amplification. At a certain point, increasing the number of perturbations becomes counterproductive, yielding only marginal gains while significantly increasing the computation time. Thus, we opted to use 6 distinct pk patterns throughout our study as it offers the optimal trade-off."}, {"title": "B.2 Design Alternatives for Perturbations", "content": "As stated in Sec. 3, added perturbations may consist of several different structures. Fig. 9 provides some of these perturbation examples, an illustration of how the perturbation looks with undersam-pling, and how they are recovered perfectly through conventional parallel imaging methods. We note that there was no task-specific perturbation that we used, meaning that the perturbations selected from the same set were applied to all datasets given that the created perturbations do not create fold-overs at R-fold which result in artifacts. Note the latter condition means they should be recoverable through parallel imaging reconstruction. Finally, we note that when calculating the sample mean estimate for (9), intensity of the perturbations was empirically found to be more im-portant than their shapes/orientations. Specifically, we observed that varying it randomly within the perturbation, as in Fig. 9b-d, leads to improved reconstruction outcomes."}, {"title": "C More Results from the Retrospective Study", "content": "We further include the representative reconstructions from the Ax-FLAIR dataset in Fig. 10."}, {"title": "D Further Quantitative Results", "content": "A more detailed version of Tab. 1, incorporating the standard error of the mean, is provided in Tab. 2."}, {"title": "E Compatibility with Various Parallel Imaging Reconstructions", "content": "Vendor reconstructions typically use different parallel imaging techniques. For our retrospective studies, we used CG-SENSE (or equivalently SENSE) (Pruessmann et al., 1999) because it natu-rally fits with the DF units in the unrolled network, and it is commonly used in clinical settings, alongside GRAPPA (Griswold et al., 2002). However, we emphasize that our method does not make assumptions about the specific reconstruction method used by the vendor; instead, it as-sumes that parallel imaging can resolve the perturbations, which is ensured by designing them in a manner that prevents fold-over aliasing artifacts from overlapping.\nTo further validate this, we include representative CUPID reconstruction results in Fig. 11 where XPI is generated via GRAPPA (Griswold et al., 2002), demonstrating that CUPID is compatible with different types of parallel imaging reconstructions as input. We further note that the prospec-tive study also used GRAPPA reconstruction as input, as this is the reconstruction provided by the vendor used in our institution."}]}