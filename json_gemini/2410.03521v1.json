{"title": "LCMDC: Large-scale Chinese Medical Dialogue Corpora for Automatic\nTriage and Medical Consultation", "authors": ["Xinyuan Wang", "Haozhou Li", "Dingfang Zheng", "Qinke Peng"], "abstract": "The global COVID-19 pandemic underscored\nmajor deficiencies in traditional healthcare sys-\ntems, hastening the advancement of online med-\nical services, especially in medical triage and\nconsultation. However, existing studies face\ntwo main challenges. First, the scarcity of large-\nscale, publicly available, domain-specific med-\nical datasets due to privacy concerns, with cur-\nrent datasets being small and limited to a few\ndiseases, limiting the effectiveness of triage\nmethods based on Pre-trained Language Mod-\nels (PLMs). Second, existing methods lack\nmedical knowledge and struggle to accurately\nunderstand professional terms and expressions\nin patient-doctor consultations. To overcome\nthese obstacles, we construct the Large-scale\nChinese Medical Dialogue Corpora (LCMDC),\ncomprising a Coarse-grained Triage dataset\nwith 439,630 samples, a Fine-grained Diagno-\nsis dataset with 199,600 samples, and a Medi-\ncal Consultation dataset with 472,418 items,\nthereby addressing the data shortage in this\nfield. Moreover, we further propose a novel\ntriage system that combines BERT-based super-\nvised learning with prompt learning, as well as\na GPT-based medical consultation model using\nreinforcement learning. To enhance domain\nknowledge acquisition, we pre-trained PLMs\nusing our self-constructed background corpus.\nExperimental results on the LCMDC demon-\nstrate the efficacy of our proposed systems. Our\ncorpora and codes are available at: Corpora and\nCodes", "sections": [{"title": "1 Introduction", "content": "The outbreak and spread of COVID-19 have placed\nimmense pressure on global healthcare systems,\nexposing numerous shortcomings in traditional\nhealthcare services (Sun et al., 2021). In response\nto the urgent need for pandemic control, online\nmedical consultations and tele-medicine have be-\ncome crucial for maintaining healthcare services\n(Jnr, 2020). Between July and December 2022,\n58.5% of U.S. adults used the Internet to seek\nhealth or medical information, 41.5% communi-\ncated with a doctor or doctor's office, and 46.1%\nchecked medical test results(Wang and Cohen,\n2023). According to the China Internet Network In-\nformation Center (CNNIC), as of December 2023,\nthe number of Internet medical users in China\nreached 414 million. This trend reflects the grow-\ning reliance on digital platforms for healthcare.\nThe rise of online healthcare platforms has made\nmedical triage and intelligent Q&A key research\nareas, helping reduce the burden on healthcare sys-\ntems by providing remote medical advice and re-\nducing unnecessary hospital visits. These technolo-\ngies enhance resource efficiency, minimize cross-\ninfection risks, and improve access to healthcare\nservices, especially in remote areas.\nHowever, most existing studies face two main\nchallenges. Firstly, due to data privacy concerns,\nobtaining large-scale public medical triage and con-\nsultation datasets is difficult. Although some stud-\nies have collected corpora for automatic diagnosis\n(Wei et al., 2018; Lin et al., 2019; Xu et al., 2019)\nand dialogue generation (Liu et al., 2022), these\ndatasets are limited to a few specific diseases and\nare small in size (Zeng et al., 2020), making them\ninadequate for training intelligent medical diagno-\nsis models based on pre-trained language models.\nSecondly, patient-doctor consultations usually uti-\nlize distinct expressions and professional terms,\nmaking it difficult for existing methods that lack\ndomain-specific knowledge to comprehend medi-\ncally pertinent information (Li et al., 2024).\nTo address the limitations of existing datasets,\nwe have constructed the Large-scale Chinese\nMedical Dialogue Corpora (LCMDC) by extract-\ning patient-doctor conversations from the \"Quick\nDoctor\" website 1. Our work addresses two key\nneeds in online healthcare: task-oriented medical"}, {"title": "2 Chinese Medical Corpus", "content": "To address the scarcity of large-scale corpora and\nthe constraints of current datasets, we collected\nmillions of doctor-patient conversations to con-\nstruct the Large-scale Chinese Medical Dialogue\nCorpora (LCMDC). This collection is designed\nto enhance medical triage and dialogue genera-\ntion and includes three components: 1) a Coarse-\ngrained Triage dataset, 2) a Fine-grained Diagnosis\ndataset, and 3) a Medical Consultation dataset."}, {"title": "2.1 Data Collection", "content": "To make the model more adaptable to conversa-\ntional and ambiguous medical descriptions, we\nclaw the original data from the online medical con-\nsultation platform named \"Quick Doctor\". Reasons\nare shown in Appendix B.1.\nWe collect millions of entries containing doc-\ntor responses and conduct statistical analysis and\nvisualization based on different labels to better un-\nderstand the original data. Our analysis, illustrated\nin Figure 1, explores the gender and age of users.\nThe results show that female users significantly"}, {"title": "2.2 Intelligent Triage Dataset", "content": "For automatic medical triage and diagnosis, we\nconstruct two datasets of different granularities for\nexperimental analysis. The triage process is con-\nceptualized as a text classification task, where pa-\ntient consultations serve as input, and department\nclassifications function as labels.\nWe organize the original corpus into two datasets\nafter data preprocessing: 1) a Coarse-grained\nTriage dataset with primary department labels for\nhigher accuracy in quickly identifying potential\nconditions and directing patients to the appropri-\nate department, and 2) a Fine-grained Diagnosis\ndataset with tertiary department labels for more\nprecise guidance, thereby helping users access de-\ntailed medical knowledge and improving query\nefficiency. The Coarse-grained dataset has over\n430,000 entries with 14 categories, while the Fine-\ngrained dataset has over 190,000 entries with 120\ncategories, as shown in Table 1. Based on these\ndatasets, we further propose an intelligent triage\nalgorithm based on supervised learning and prompt-\nbased learning and then evaluated its effectiveness."}, {"title": "2.3 Medical Consultation Dataset", "content": "For the medical dialogue generation, we extract the\nQuestion-Answer sample from the original corpus\nto create the Medical Consultation Dataset, which\ncan offer several advantages: 1) Major medical\nQ&A portals have a large user base with compre-"}, {"title": "3 Intelligent Triage System", "content": "We propose two text classification-based methods\nto evaluate intelligent triage datasets, using coarse-\ngrained and fine-grained data to provide varying\nlevels of consultation suggestions. We re-train\nlanguage models on medical text data to improve\ntheir performance on Chinese medical texts and de-\nvelop a supervised text classification model based\non these domain-adapted models. For categories\nwith limited data, a prompt-based text classifica-\ntion method leverages pre-trained language mod-\nels' knowledge, enhancing performance on small\ndatasets."}, {"title": "3.1 Problem Definition", "content": "The intelligent medical triage task is modeled as a\ntext classification problem, processing user queries"}, {"title": "3.2 Supervised Learning Triage System", "content": "First, we propose a traditional supervised learning-\nbased text classification method. The proposed net-\nwork framework is shown in Figure 2. The input\nis the user query text, and the output is the clas-\nsification distribution of the text. First, we use a\npre-trained language model (e.g., BERT) to obtain\nthe CLS vector of the text, which is the classifica-\ntion vector inherent in BERT. Simultaneously, we\nextract the token representation vectors encoded by\nBERT and use a bidirectional LSTM network to\ncapture temporal information. The CLS vector and\nthe output vectors from the LSTM layer are then\nfused and processed using a Dendritic Network for\ninformation integration. Finally, a Single-Layer\nPerceptron and a Softmax function are used to ob-\ntain the classification distribution.\nThe model consists of four steps: The first step\nis domain-specific knowledge learning based on\npre-training. To make the pre-trained language\nmodel used in this model more suitable for the\nmedical domain, we further pre-trained the gen-\neral pre-trained language model using the collected\nmedical encyclopedia data and medical consulting\ndata. Self-supervised learning was performed us-\ning the MLM pre-training task, enabling the model\nto better learn medical knowledge and colloquial\nexpressions. The pre-training process employed\nthe same parameters as BERT, selecting 15% of the\ntotal words as masked tokens. The training objec-\ntive of the MLM task is to minimize the following\nnegative log-likelihood loss function:\n$L = - \\sum log P (X\\_\\{m(x)}\\Em(x)$\nBased on the pre-trained language model with\nmedical text supplementation, we represent the text\nby obtaining the classification vector inherent to\nthe pre-trained language model and the text token\nrepresentation vector encoded by the pre-trained\nlanguage model.\n$X^{mb} = BERTemb (T_i)$\nThe embedding vectors are then computed by the\nmulti-head self-attention mechanism in BERT to\nget the representation vectors and the CLS vector.\n$S\\_{i,j} = softmax (\\frac{(Q^\\intercal K)\\_i\\_\\{j\\}}{\\sqrt{k\\_h}})*V,$\nwhere $S^i_j \\in \\mathbb{R}^{k\\_m\\times k\\_h}$ are representations with\nattention.\n$O\\_{(1)} = Layer Norm (x^{i-1}+S^{i}\\_{(2)})S^{i}\\_{(2)})$, \nwhere $O\\_{(i)} \\in \\mathbb{R}^{k\\_m\\times k\\_h}$ are updated representa-\ntions.\nNext, the temporal information is extracted using\na bidirectional LSTM network\n$\\overrightarrow{H\\_i} = LSTM (P\\_i)$\n$\\overleftarrow{H\\_i} = LSTM (P\\_i)$\n$H = [\\overrightarrow{H\\_i}, \\overleftarrow{H\\_i}], H\\in \\mathbb{R}^{2\\cdot k\\_h}$\nAfter obtaining the representation $H_i$ summa-\nrized by the LSTM network, we fuse it with the\nBERT output classification vector $[Cls]_i$ to form a\nnew representation vector $M_i$:\n$M_i = [H_i; Cls_i]$\nThis vector is then input into the DD layer for\nprocessing, which reduces the probability of over-\nfitting and improves the model's robustness.\n$D_i = W_d * (M_i \\cdot M_i), W_d\\in\\mathbb{R}^{(3\\cdot k\\_h)\\times k\\_h}$\nFinally, the decision is made through a dense\nlayer:"}, {"title": "3.3 Prompt Learning Triage System", "content": "Both granularity-level classification datasets suffer\nfrom data imbalance issues. For categories with\nless data, the performance of conventional text clas-\nsification methods encounters certain bottlenecks.\nTo address this, we propose a prompt-based classifi-\ncation method that leverages the knowledge embed-\nded in pre-trained language models tailored to the\nmedical domain to improve classification accuracy.\nIn this prompt-based classification method, the la-\nbel is a list of text, and the classification process\ninvolves predicting the content of this text, thus\nachieving classification. This approach establishes\na relationship between the input sentence and the\nlabel name. It effectively utilizes the knowledge\nwithin pre-trained language models and performs\nwell on datasets with few samples, making it suit-\nable for classifying rare diseases with limited sam-\nples. Specifically, for each user input text, we add\na prompt sentence with a masked word, shown in\nFigure 3."}, {"title": "4 Medical Consultation System", "content": "For the medical consultation dataset, we developed\na Chinese medical dialogue system using a genera-\ntive language model to simulate interactions with"}, {"title": "4.1 Problem Definition", "content": "We mathematically model building a consultation\nsystem as a text-generation task. Specifically,\nbased on the input question $Q = (q_1, q_2, ..., q_M)$,\nwe use a knowledge graph for supplementary in-\nput, denoted as $I = Graph(Q) = (i_1, i_2, . . ., i_L)$.\nThe text generation model produces the response\nsequence $A = (a_1, a_2,..., a_V)$ as follows:\n$A = TextGen (Q, I)$\n$= TextGen (q_1, q_2, ..., q_M, i_1, i_2, ..., i_L)$"}, {"title": "4.2 Overview", "content": "Based on the GPT-2 model, we re-train the model\nusing the collected medical encyclopedia text data\nto internalize knowledge, making it more suitable\nfor tasks in the medical domain. Next, we construct\na medical knowledge graph and use a search-and-match approach to find relevant knowledge to each\nquestion, providing external information as sup-\nplementary input text. Then, we train the model\nusing dialogue data and finally fine-tune it using\nreinforcement learning.\nAccording to the above process, we construct\nthe domain-specific medical consultation system,\nas shown in Figure 4."}, {"title": "4.3 Knowledge Injection Answer Generation", "content": "Knowledge injection allows the model to have rich\nprior knowledge, which involves re-training the\nlarge language model using the collected basic"}, {"title": "5 Experiments", "content": "We build the intelligent triage system and medical\nconsultation system and test them on the collected\ndatasets."}, {"title": "5.1 Experiment Setup", "content": "The experiments for the triage and consultation\nsystems, including datasets, baselines, evaluation\nmetrics, hyper-parameters, and environment set-\ntings, are outlined in detail in the Appendix C."}, {"title": "5.2 Supervised Triage System Experiment", "content": "For the supervised learning classification method,\nwe employ different baselines including machine"}, {"title": "5.2.1 Overall Performance", "content": "For the supervised learning classification method,\nwe employ different baselines including machine"}, {"title": "5.2.2 Results of Domain Information Injection", "content": "To investigate the differences before and after\ndomain-specific re-training of different pre-trained\nmodels, we designed comparative experiments to\nevaluate model performance under different condi-\ntions. We used the original BERT and MacBERT\nmodels, as well as the proposed models utilizing\nthese pre-trained models, comparing their perfor-\nmance before and after re-training. The results are\nshown in Figure 5\nWith the same pre-trained models and classifi-\ncation network structures, re-training the language\nmodel can improve the accuracy of the classifica-"}, {"title": "5.2.3 Parameters Study", "content": "We also investigated the impact of different num-\nbers of dendritic neural network layers and LSTM\nlayers on classification results to select the optimal\nalgorithm model structure.\nAccording to the results in Figure 6, the dendritic\nneural network achieves the best classification per-\nformance with 3 layers, and the LSTM network\nachieves optimal performance with 2 layers."}, {"title": "5.3 Prompting Triage System Experiment", "content": "Prompt learning quickly completes tasks using pre-\ntrained knowledge, even with limited data. To\nleverage this advantage, we created small sample\ndatasets by removing high-data categories from the\ncoarse-grained and fine-grained datasets, resulting\nin 73,604 entries across nine categories and 24,940\nentries across 83 categories, respectively."}, {"title": "5.4 Question Answer System Experiment", "content": "First, we compared the proposed framework's\ntext generation model with a deep learning-based\nsequence-to-sequence (seq2seq) model. The\nseq2seq model is constructed with LSTM networks\nfor both the Encoder and Decoder and includes in-\nformation interaction methods such as attention\nmechanisms and information fusion representa-\ntions. This model serves as a representative of\ndeep learning methods that do not incorporate back-\nground information.\nAdditionally, we compared the proposed text\ngeneration model with the BART model. BART\ncombines features of both autoencoding and au-\ntoregressive language models and is widely used in\nthe field of text generation, especially for text sum-\nmarization. In this study, we utilized the general\nChinese BART model to build a dialogue system\nand trained it using medical dialogue data."}, {"title": "5.4.1 Overall Performance", "content": "First, we compared the proposed framework's\ntext generation model with a deep learning-based\nsequence-to-sequence (seq2seq) model. The\nseq2seq model is constructed with LSTM networks\nfor both the Encoder and Decoder and includes in-\nformation interaction methods such as attention\nmechanisms and information fusion representa-\ntions. This model serves as a representative of\ndeep learning methods that do not incorporate back-\nground information.\nAdditionally, we compared the proposed text\ngeneration model with the BART model. BART\ncombines features of both autoencoding and au-\ntoregressive language models and is widely used in\nthe field of text generation, especially for text sum-\nmarization. In this study, we utilized the general\nChinese BART model to build a dialogue system\nand trained it using medical dialogue data."}, {"title": "6 Discussion and Future Work", "content": "We discuss the biases in online medical data, AI\nadoption in healthcare, and the development of\nlarge language models in different sectors. For\ndetails, please refer to Appendix E.\nLooking ahead, future work focuses on expand-\ning datasets to reduce bias, enhancing intelligent\ntriage systems with background knowledge and\nmulti-modal methods, and refining medical consul-\ntation systems through alignment between LLM\noutputs and human preferences. The potential for\nfurther applications of LLMs is vast, enabling more\nflexible and realistic solutions in various fields. For\ndetails, please refer to the Appendix F."}, {"title": "7 Conclusion", "content": "We collected and organized Chinese medical data,\nincluding datasets for automated medical triage and\nconsultation, forming the foundation of our work.\nBased on these datasets, we developed two systems:\nan intelligent triage system using text classification\nand a medical consultation system using a gener-\native language model. Experimental results and\nablation studies validated the effectiveness of both\nsystems, demonstrating improved performance in\nmedical diagnosis and consultation tasks."}, {"title": "8 Limitation", "content": "Dataset Biases:\n\u2022 Lack of Emergency Data: The dataset lacks\nemergency and severe cases, limiting the\nmodel's ability to generalize to critical or ur-\ngent medical situations.\n\u2022 Imbalanced Age Distribution: The dataset\nis biased towards younger users, with insuf-\nficient data on elderly populations, reducing\nthe model's applicability to older age groups.\n\u2022 Issues Due to Anonymity: The anonymity\nof online consultations often leads to more\nprivate or informal questions, which may not\naccurately reflect typical clinical scenarios,\naffecting the model's real-world performance.\nIntelligent Triage System:\n\u2022 Lack of Comparison with Human Perfor-\nmance: Current classification methods lack\nsufficient comparison with professional doc-\ntors' diagnostic results, making assessing their\nreliability in practical medical applications dif-\nficult.\n\u2022 Lack of Multi-modal Research: Exist-\ning classification methods are primarily text-\nbased and do not incorporate multi-modal data\nsuch as images or audio, limiting the under-\nstanding of comprehensive patient informa-\ntion.\nMedical Consultation System:\n\u2022 No Multi-turn Dialogues: Generation meth-\nods are often limited to single-turn dialogues,\nlacking the ability to handle contextual infor-\nmation across multiple rounds of interaction,\nwhich is crucial in real consultations.\n\u2022 No Role-playing or Simulation: There is\na lack of role-playing or simulation of real\nmedical scenarios in the generated dialogues,\nresulting in responses that lack authenticity\nand practical relevance to clinical settings."}, {"title": "9 Ethical Issues", "content": "Our study does not present any ethical issues that\nwould require formal ethics approval, as it does not\ninvolve human subjects, sensitive personal data, or\nany other ethical considerations that would necessi-\ntate formal ethics oversight. First, the anonymized"}, {"title": "A Related Work", "content": ""}, {"title": "A.1 Dataset", "content": "CBLUE (Zhang et al., 2022) is a comprehensive\nChinese biomedical language understanding bench-\nmark designed to advance research in biomedical\nNLP for the Chinese language. MedDG (Liu et al.,\n2020) is a large-scale dataset aimed at develop-\ning conversational agents for primary clinical ad-\nvice, especially valuable during the COVID-19 pan-\ndemic. MedDialog (Zeng et al., 2020) is a compre-\nhensive dataset for training and evaluating medi-\ncal dialogue systems, enhancing remote healthcare\nservices. MedQuAD (Ben Abacha and Demner-\nFushman, 2019) is a significant resource for devel-\noping AI models in medical question answering,\nproviding a robust foundation for understanding\nand responding to medical inquiries. There are\nsome other datasets like event recognition (Deng\net al., 2022)."}, {"title": "A.2 Triage System", "content": "IntelTriage (Billis et al., 2019) is an intelligent\ntriage system for Emergency Departments in\nGreece, dynamically prioritizing patients and mon-\nitoring their vital signs using wearable biosensors.\nThe Babylon AI-powered Triage and Diagnostic\nSystem (Razzaki et al., 2018) demonstrated diag-\nnostic accuracy comparable to human doctors and\nprovided generally safer triage recommendations.\nMESTRIMAN (Sierra et al., 1993) is an expert sys-\ntem designed to support medical assistance during\ncatastrophes by coordinating resources and enhanc-\ning disaster management. The SADE model (Li"}, {"title": "A.3 Question Answer System", "content": "This research (Abdallah et al., 2020) automates\nthe generation of qualified medical answers using\nan end-to-end RNN and encoder-decoder model\ntrained on data from online health services. An-\nother system (Jiang et al., 2021) integrates med-\nical knowledge, knowledge graphs, and QA sys-\ntems, using crawler technology and rule-based al-\ngorithms for classification and querying. An end-\nto-end character-level multi-scale CNN framework\n(Zhang et al., 2017) is introduced for Chinese medi-\ncal question-answer matching. Med-PaLM 2 (Sing-\nhal et al., 2023) leverages large language model\nimprovements and medical domain finetuning to\nenhance performance on medical QA datasets."}, {"title": "B Dataset Details", "content": ""}, {"title": "B.1 Reasons for Data Source", "content": "Here are several reasons for choosing \"Quick Doc-\ntor\" website:\n\u2022 Apart from sensitive information, the patient\nconsultations and doctor responses are public,\nreducing the difficulty of data collection.\n\u2022 The portal boasts an extensive dataset, contain-\ning over 100 million entries, which adequately\nmeets our requirements.\n\u2022 The portal provides comprehensive informa-\ntion, including user characteristics like gender\nand age, and detailed classifications of medi-\ncal departments across four levels, facilitating\nrobust data statistics and medical department\nrecommendations."}, {"title": "C Experiment Setup Details", "content": ""}, {"title": "C.1 Datasets", "content": "In Section 2, we collect medical corpus and formu-\nlate 2 datasets for the triage system and consulta-\ntion system respectively. In the intelligent triage\ndataset, the inputs are the users' questions, and the\noutputs are two different grained labels, indicating\nhigh-level and detailed triage."}, {"title": "C.2 Baselines", "content": "For the triage system, we employ SVM (Cortes\nand Vapnik, 1995) and decision tree (Quinlan,"}, {"title": "C.3 Evaluation Metrics", "content": "For the triage system, we utilize classification met-\nrics, including accuracy, precision, recall, and F-1\nscore. For the consultation system, we employ\nvarious evaluations, including n-gram overlap mea-\nsures such as BLEU (Papineni et al., 2002), NIST\n(Doddington, 2002), RIBES (Isozaki et al., 2010),\nCHRF (Popovi\u0107, 2015), and GLEU (Mutton et al.,\n2007); distance-based measures like TER (Snover\net al., 2006); vector similarity measures including\nWMD (Kusner et al., 2015); n-gram diversity mea-\nsures such as Self BLEU; sentence semantic simi-\nlarity measures including BERT score (Zhang et al.,\n2019) and Web Bert Similarity; and other metrics\nsuch as Lexical Diversity, and KL Divergence."}, {"title": "C.4 Hyper Parameters", "content": "For continuous pre-training of BERT and\nMacBERT, we set the max input length as 128\nand mask 15% of tokens in the MLM task. For the\nsupervised training of the triage system, we set\nthe embedding dimension to 768, and the LSTM\nhidden size to 1024. We train 50 epochs. The learn-\ning rate for the pre-trained language model is 5e-5,\nwhile that for other parts of the whole framework\nis 2e-4. For the prompt learning method, we train\n20 epochs with a learning rate of 2e-5. For the con-\nsultation system, we use GPT-2 as the base model.\nWe set the token embedding dimension to 768, and\nthe vocabulary length of natural language tokens\nto 50257. In the pre-training stage, we trained 10\nepochs using background knowledge. In the fine-\ntuning stage, we trained 20 epochs using a learning\nrate of 2.6e-5."}, {"title": "C.5 Experimental Environment", "content": "All experiments were conducted on Ubuntu 22.04.3\nLTS OS, with the framework of Python 3.11.5 and\nPyTorch 2.0.1. All data are computed on 4 NVIDIA\nGeForce RTX 2080 Ti GPUs, each featuring 12 GB\nof memory with CUDA version 12.2."}, {"title": "D Ablation Study Details", "content": ""}, {"title": "D.1 Supervised Triage System Experiment", "content": "To verify the necessity of each component in the\nsupervised triage system, we conducted ablation\nexperiments by removing each component."}, {"title": "D.2 Medical Consultation System Experiment", "content": "Next, we conducted ablation experiments to de-\ntermine the importance of each component of the\nmedical consultation system. Three comparative\nmodels were set up: a model without knowledge\ninternalization, a model without input supplemen-\ntation, and a model without both components."}, {"title": "E Discussion", "content": ""}, {"title": "E.1 Data Issues", "content": "During data collection, we found certain biases in\nthe data gathered from online platforms. Firstly,\nacute and severe cases are not typically presented\nonline, as patients in these situations usually go\ndirectly to the hospital. Secondly, the internet acts\nas a filter, with the online population differing from\nthe general population. This results in a majority of\nyounger users seeking online consultations, leading\nto a lack of data on elderly conditions. Lastly,\ndue to the anonymity of the internet, the nature of\nquestions asked online can differ from those asked\noffline, often including more private issues.\nMedical issues require maximum caution, and\nlicensed doctors undergo extensive training to earn\ntheir qualifications due to the severe consequences\nof medical errors, which can endanger lives. There-\nfore, using current AI, which often functions as\na black-box system, for diagnosis and treatment\nremains an ethical and legal grey area. At present,\nAI can only serve as a supplementary tool. Simi-\nlar to autonomous driving, where accidents pose\nchallenges in accountability, AI in healthcare must\ndevelop gradually. Automation systems must ad-\nvance in a phased manner."}, {"title": "E.2 Discussion on Current Large Models", "content": "With the rise of ChatGPT, pre-trained language\nmodels seem to have deviated from their origi-\nnal purpose but have unified various tasks. Pre-\nviously proposed task classifications are now out-\ndated. Since the introduction of the T5 model, all-\nnatural language processing tasks can be modeled\nas text generation tasks, differing only in prompts.\nCurrently, the boundaries between various big data\ntasks are unclear, and many tasks can be converted\ninto generative tasks. The popularity of ChatGPT\nhas even given rise to a new role, \"prompt engi-\nneer,\" who specializes in crafting effective prompts\nto leverage ChatGPT for task completion. In the fu-\nture, large models can liberate and enhance produc-\ntivity, handling repetitive tasks and freeing humans\nfor creative work, thus advancing technological\nprogress."}, {"title": "E.3 Comparison Between Industrial and\nResearch Institutions in Large Model\nDevelopment", "content": "Industries aim to generate profits, driving them to\ndevelop market-appropriate large models with high\nenthusiasm. They also have vast user bases that\nprovide data and accelerate training. However, in-\ndustries face ethical and legal constraints, such as\npatents and privacy issues. Research institutions,\nlacking immediate application needs or access to\nfirst-hand data, face disadvantages in a data-driven\nera. Nonetheless, they pursue innovation without\nprofit motives, experimenting in numerous direc-\ntions, where even a one-in-a-million success marks\na significant breakthrough. Furthermore, research\ninstitutions frequently refresh their teams, main-\ntaining high efficiency in research."}, {"title": "F Potential Future Work", "content": ""}, {"title": "F.1 Dataset Extension", "content": "Collecting data from multiple sources can help mit-\nigate the bias faced in the dataset."}, {"title": "F.2 Intelligent Triage", "content": "The All-in-one LLMs can solve the triage in a more\ngeneral way. Researchers may pay more attention\nto adding more background information, such as\nmulti-modality methods. Double checking will\nground truth after the decision is also important\ndue to the high risk of medical problems."}, {"title": "F.3 Medical Consultant", "content": "Medical consultation systems have a promising\nfuture as AI technology advances, with human re-\nsources and potentially unlimited computing re-\nsources that can scale with demand. With the de-\nvelopment of current LLMs, constructing a consul-\ntation system become easier. Researchers can shift\ntheir focus to the alignment between LLM output\nand human preference (legal issues, correct knowl-\nedge, cost trade-off). The RLHF may contribute to\nthe alignment."}, {"title": "F.4 Further Application", "content": "The power of LLMs may empower more compli-\ncated tasks. As a result, researchers may not need to\nformulate real tasks into fixed mathematical tasks,\nwhich will enable more flexible and realistic so-\nlutions. Researchers may extend the usage of our\ndatasets based on their own need."}]}