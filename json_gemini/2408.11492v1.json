{"title": "Estimating Peer Direct and Indirect Effects in Observational Network Data", "authors": ["Xiaojing Du", "Jiuyong Li", "Debo Cheng", "Lin Liu", "Wentao Gao", "Xiongren Chen"], "abstract": "Estimating causal effects is crucial for decision-makers in many applications, but it is particularly challenging with observational network data due to peer interactions. Many algorithms have been proposed to estimate causal effects involving network data, particularly peer effects, but they often overlook the variety of peer effects. To address this issue, we propose a general setting which considers both peer direct effects and peer indirect effects, and the effect of an individual's own treatment, and provide identification conditions of these causal effects and proofs. To estimate these causal effects, we utilize attention mechanisms to distinguish the influences of different neighbors and explore high-order neighbor effects through multi-layer graph neural networks (GNNs). Additionally, to control the dependency between node features and representations, we incorporate the Hilbert-Schmidt Independence Criterion (HSIC) into the GNN, fully utilizing the structural information of the graph, to enhance the robustness and accuracy of the model. Extensive experiments on two semi-synthetic datasets confirm the effectiveness of our approach. Our theoretical findings have the potential to improve intervention strategies in networked systems, with applications in areas such as social networks and epidemiology.", "sections": [{"title": "Introduction", "content": "Causal effect estimation is an important area of study, with the focus on determining cause-and-effect relationships between variables (Imbens and Rubin 2010; Pearl 2009). It is challenging to achieve accurate causal effect estimation using observational data due to the presence of confounders that affect both the treatment and the outcome. When the data is collected from sources such as social networks, communication networks, or biological networks, causal effect estimation becomes even more challenging since the data is inherently networked, meaning that units (e.g., individuals, nodes) are interconnected, and their outcomes potentially being influenced by both the treatments and outcomes of their neighbors (Sinclair, McConnell, and Green 2012). This implies that traditional causal inference methods are not applicable any more since they may not adequately account for peer effects or network dependencies (Yao et al. 2021). Therefore, estimating causal effects on network data necessitates specialized techniques that can handle these interdependencies, ensuring that the estimated effects are not biased by the network structure itself.\nEffects in network data can be classified into peer effects (PE, an individual's treatment affects another's outcome) and self-treatment effects (STE, an individual's treatment affects their own outcome). As illustrated in Fig. 1(a), in the context of an infectious disease, an individual's infection status depends on both their own and their neighbors' vaccination statuses. Peer effects can be direct, where the vaccination of an individual's neighbour reduces the risk of the individual's infection (peer direct effect, PDE, as indicated by the edge marked with \u2460 in Fig. 1(b)), or indirect, where the vaccination of an individual's neighbour affects the neighbor's own infection status, which in turn (indirectly) affects the individual's infection status (peer indirect effect, PIE, as indicated by the path marked with \u2461 in Fig. 1(b)). Understanding these mechanisms is crucial for optimizing vaccination strategies. Peer direct effect denotes the effectiveness of a vaccine on an individual by vaccinating their neighbours regardless of their neighbours' infectious conditions. Peer indirect effect indicates the effectiveness of a vaccine on an individual by improving their neighbours infectious conditions through vaccination.\nCausal mediation analysis (MacKinnon, Fairchild, and Fritz 2007) is usually used to distinguish between direct and indirect effects in independent and identically distributed (IID) data. VanderWeele et al. (VanderWeele, Tchetgen, and Halloran 2012) combined causal mediation analysis with"}, {"title": "Preliminary", "content": "This section provides the notations and problem setting used throughout the paper."}, {"title": "Notations and Problem Setting", "content": "Throughout the paper, uppercase letters (e.g., \\(T_i\\), \\(W_{t_i}\\)) denote variables, while lowercase letters (e.g., \\(t_i\\), \\(w_{t_i}\\)) represent their values. Bold uppercase letters (e.g., \\(\\textbf{W}\\), \\(\\textbf{X}\\), \\(\\textbf{W}_y\\), \\(\\textbf{W}_x\\)) indicate sets of variables, vectors or matrices, and bold lowercase letters (e.g., \\(w_x\\), \\(x\\), \\(w_y\\), \\(w_{x_i}\\)) represent their corresponding values.\nA network can be represented as a pair (\\(V\\), \\(E\\)), where \\(V = \\{V_1,..., V_m\\}\\) is the set of nodes, and \\(E \\subset V \\times V\\) is the set of edges between the nodes. A node \\(V_i \\in V\\) has a set of features \\(X_i = \\{X_{i1}, ..., X_{ik}\\}\\), a treatment \\(T_i\\), and an outcome \\(Y_i\\) associated with it. We assume \\(T_i \\in \\{0,1\\}\\) is a binary treatment, representing, e.g., whether node \\(V_i\\) receives a vaccination or not, and \\(Y_i\\) is a continuous variable, indicating, e.g., the level of immunity of \\(V_i\\). For simplicity of presentation, we will use the index of a node, e.g., \\(i\\), to represent the corresponding node \\(V_i\\) when there is no ambiguity in the rest of the paper."}, {"title": "Considering an individual or node i, its outcome \\(Y_i\\) is affected by several factors: its own features \\(X_i\\), its treatment \\(T_i\\), the features of its neighbors \\(\\textbf{X}_j\\}_{j\\in N_i}\\), the treatments administered to those neighbors \\(\\textbf{T}_j\\}_{j\\in N_i}\\), and the outcomes observed in those neighbors \\(\\textbf{Y}_j\\}_{j\\in N_i}\\). Here, \\(N_i\\) represents the set of neighbors of unit \\(i\\), as illustrated in Fig. 2(a).\nWe use Kullback-Leibler (KL) divergence (Belov and Armstrong 2011) to compute the difference between the probability distributions \\(P_i\\) and \\(P_j\\) of node \\(i\\) and its neighboring node \\(j\\), as given by Eq 1 below:", "content": "Considering an individual or node i, its outcome \\(Y_i\\) is affected by several factors: its own features \\(X_i\\), its treatment \\(T_i\\), the features of its neighbors \\(\\textbf{X}_j\\}_{j\\in N_i}\\), the treatments administered to those neighbors \\(\\textbf{T}_j\\}_{j\\in N_i}\\), and the outcomes observed in those neighbors \\(\\textbf{Y}_j\\}_{j\\in N_i}\\). Here, \\(N_i\\) represents the set of neighbors of unit \\(i\\), as illustrated in Fig. 2(a).\nWe use Kullback-Leibler (KL) divergence (Belov and Armstrong 2011) to compute the difference between the probability distributions \\(P_i\\) and \\(P_j\\) of node \\(i\\) and its neighboring node \\(j\\), as given by Eq 1 below:\n\\(D_{KL} (P_i || P_j) = \\sum_k P_i(k) log(\\frac{P_i(k)}{P_j (k)})\\)\nwhere \\(k\\) is the dimension of the feature vector of a node. Based on the KL divergence, we calculate the influence weight of neighbor \\(j\\) on individual \\(i\\), \\(w_{ij}\\) as follows:\nw_{ij} = \\frac{1}{1+ D_{KL}(P_i || P_j)}\nThe higher the weight \\(w_{ij}\\), the greater the influence of neighbor \\(j\\) on individual \\(i\\).\nNeighbor treatment exposure \\(W_{t_i}\\), neighbor contagion exposure \\(W_{y_i}\\), and neighbor feature \\(W_{a_i}\\) = \\(\\textbf{W}_{x_i}\\) are calculated as: \\(W_{t_i} = \\sum_{j\\in N_i} w_{ij}T_j\\), \\(W_{y_i} = \\sum_{j\\in N_i} w_{ij}Y_j\\), \\(W_{a_i} = \\sum_{j\\in N_i} w_{ij}X_j\\), respectively.\nOur problem definition is provided as follows:\nProblem Definition. Given the observational networked data of a network (\\(V\\), \\(E\\)), including the data of the features, treatments and outcomes associated with the nodes of the network, our goal is for each node or individual \\(i\\) to distinguish and obtain unbiased estimation of the peer direct effects (PDE) (i.e., the causal effect of \\(W_t\\) on \\(Y_i\\) via \\(W_{t_i}\\rightarrow Y_i\\)), peer indirect effects (PIE) (i.e., the causal effect of \\(W_t\\) on \\(Y_i\\) via \\(W_{t_i} \\rightarrow W_{y_i} \\rightarrow Y_i\\)), and self-treatment effects (STE) (i.e., the causal effect of \\(T_i\\) on \\(Y_i\\) via \\(T_i \\rightarrow Y_i\\)) as shown in Fig. 2.\nThe formal definitions of group level PDE and PIE, and STE are based on the potential outcome framework (Imbens"}, {"title": "and Rubin 2010). In the following, we first present the basic concepts of the framework, then give the definitions of PDE, PIE and STE.\nFor each unit i under two treatment conditions T. (where \\(T_i = 0\\) represents no treated unit and \\(T_i = 1\\) represents treated unit), we define two potential outcomes: \\(Y_i(1)\\), the outcome if the unit receives treatment, and \\(Y_i(0)\\), the outcome if untreated.\nThe individual treatment effect (ITE) is defined as the difference between these potential outcomes:", "content": "and Rubin 2010). In the following, we first present the basic concepts of the framework, then give the definitions of PDE, PIE and STE.\nFor each unit i under two treatment conditions T. (where \\(T_i = 0\\) represents no treated unit and \\(T_i = 1\\) represents treated unit), we define two potential outcomes: \\(Y_i(1)\\), the outcome if the unit receives treatment, and \\(Y_i(0)\\), the outcome if untreated.\nThe individual treatment effect (ITE) is defined as the difference between these potential outcomes:\nITE_i = Y_i(1) \u2013 Y_i(0)\nThe average treatment effect (ATE) across the population is defined as the expected value of the ITE for all units:\nATE = E[Y_i(1) \u2013 Y_i(0)]\nUnder the potential outcome framework and following the definitions of PDE and PIE in (VanderWeele, Tchetgen, and Halloran 2012), in our problem setting, we have:\nPDE = E [Y (w, W_y (w_{t_i})) \u2013 Y (w_{t_i}, W_y (w_{t_i})]\nPIE = E [Y_i(w_{t_i}, W_y (w_{t_i}) \u2013 Y_i(w_{t_i}, W_y (w_{t_i})]\nThe PDE defined in Eq. 5 indicates the average of the difference between the potential outcomes of an individual when the aggregated treatment of its neighbours, i.e., its neighbor treatment exposure \\(W_{t_i}\\), is changed from one level (\\(w'_{t_i}\\)) to another (\\(w_{t_i}\\)), while the aggregated neighbor potential outcome, i.e., its neighbor contagion exposure \\(W_{y_i}\\), remains at the level as it would have been if the neighbours' aggregated treatment had been \\(w_{t_i}\\), denoted as \\(w_y(w_{t_i})\\). In the vaccination example, PDE indicates the average effect of changing the vaccination status of an individual's neighbors on the infectious status of the individual, assuming the neighbors' infectious status is kept at the level as after their vaccination status is changed.\nThe PIE defined in Eq. 6 indicates the average of the difference between the potential outcomes of an individual when the aggregated treatment of its neighbours, i.e., its neighbor treatment exposure \\(W_{t_i}\\), remains unchanged at (\\(w_{t_i}\\)), while the aggregated neighbor potential outcome, i.e., its neighbor contagion exposure \\(W_{y_i}\\), is changed from what it would have been if the neighbours' aggregated treatment had been \\(w'_{t_i}\\), denoted as \\(w_y(w'_{t_i})\\), to what it would have been if the neighbours' aggregated treatment had been \\(w_{t_i}\\), i.e., \\(w_y(w_{t_i})\\). In the vaccination example, PIE indicates that assuming the vaccination status of the neighbors of an individual remains unchanged, how the change of the infectious status of an individual's neighbors as a result of changing their vaccination status would affect the infectious status of the individual.\nThe definition of STE in our problem setting is similar to the definition of ATE, i.e., STE = E [\\(Y_i(1) \u2013 Y_i(0)\\)]. In the vaccination example, STE indicates the average difference of potential outcomes of an individual if the individual had been vaccinated versus if they had not been vaccinated.\nEstimating these effects deepens our understanding of interactions within complex networks and provides critical insights for informed policy decisions."}, {"title": "Assumptions", "content": "In observational data, we only have the observed outcome, i.e., the factual outcome, but estimating causal effects requires the potential outcomes, i.e., both the factual and counterfactual outcomes. Therefore, the following assumptions are needed for estimating causal effects from observational network data (Jiang and Sun 2022).\nIn the following assumptions, \\(Z_i = (W_{t_i}, W_{y_i})\\), where \\(W_{t_i}\\) and \\(W_{y_i}\\) represent the aggregated treatment and contagion exposures of node i's neighbors, respectively. We define \\(z_i\\) as the corresponding value of \\(Z_i\\).\nAssumption 1 (Network Unconfoundedness): The potential outcome is independent of both individual treatment and neighborhood exposure, given the individual and neighbor features. i.e., \\(Y_i(t_i, z_i) \\amalg t_i, Z_i | X_i, W_{x_i}\\)\nAssumption 2 (Network Interference): If the potential outcome \\(Y_i(t_i, z_i)\\) for individual i depends on both i's treatment \\(T_i\\) and \\(Z_i\\), network interference exists.\nAssumption 3 (Network Consistency): The potential outcome equals the observed outcome when a unit is exposed to the same treatment and neighborhood exposure. i.e., \\(Y_i = Y_i(t_i, z_i)\\) if unit i is subjected to \\(t_i\\) and \\(z_i\\).\nAssumption 4 (Network Overlap): Every treatment and neighborhood exposure pair (\\(T_i\\), \\(Z_i\\)) must have a positive probability of occurring. i.e., \\(0<p(t_i, Z_i | X_i, W_{x_i}) < 1\\)."}, {"title": "The Proposed gDIS Method", "content": "Identifiability of PDE, PIE and STE\nEstablishing the identifiability of a causal effects is the prerequisite for estimating the causal effects from data. To study the identifiability of the causal effects (PDE, PIE and STE) with network data, we propose a novel causal graph, as shown in Fig. 2(b), to illustrate these causal effects. In this section, we provide the assumptions and conditions for identifying these causal effects from network data, along with the theoretical analysis and corresponding proofs.\nTo present our main theoretical results (Theorems 1 and 2 below), we make the following assumptions, which are commonly found in the causal inference literature and adapted to our problem setting, with causal relationships between variables illustrated in Fig. 2(b). For simplicity, we omit the subscript i from the names of the variables shown in Fig. 2(b) in the following discussion.\nAssumption 5 (Sequential Ignorability (Imai, Keele, and Yamamoto 2010)) There exists a set of observed covariates W such that:\n1G-1. W and \\(W_t\\) block all backdoor paths from \\(W_y\\) to Y that do not pass through \\(W_t\\);\n1G-2. The set W blocks all backdoor paths from \\(W_t\\) to \\(W_y\\) or Y, and no element in W is a descendant of \\(W_t\\).\nA set W that satisfies both conditions in Assumption 5 serves as an adjustment set for obtaining unbiased estimates of PDE and PIE from network data. We present our first theoretical finding below.\nTheorem 1. In the causal DAG represented in Fig 2(b), the set of neighbor features \\(W_x\\) satisfies both conditions 1G-1 and 1G-2 of Assumption 5."}, {"title": "Proof: First, we prove that \\(\\textbf{W}_x\\) satisfies condition 1G-1 of Assumption 5. In the causal DAG shown in Fig. 2(b), all \\(W_t\\)-avoiding backdoor paths from \\(W_y\\) to Y (\\(W_y \\leftarrow W_x \\rightarrow Y\\), \\(W_y \\leftarrow W_x \\rightarrow T \\leftarrow X \\rightarrow Y\\), and \\(W_y \\leftarrow W_x \\rightarrow T \\leftarrow Y\\)) are blocked by the set \\(\\textbf{W}_x, W_t\\), thus \\(\\textbf{W}_x\\) satisfies 1g-1. Next, we prove that \\(\\textbf{W}_x\\) satisfies condition 1G-2. The set \\(\\textbf{W}_x\\) blocks all backdoor paths from \\(W_t\\) to \\(W_y\\) (\\(W_t \\leftarrow W_x \\rightarrow W_y\\), \\(W_t \\leftarrow W_x \\rightarrow Y \\leftarrow W_y\\), \\(W_t \\leftarrow W_x \\rightarrow T\\leftarrow Y\\leftarrow W_y\\), and \\(W_t \\leftarrow W_x \\rightarrow T \\leftarrow X \\rightarrow Y \\leftarrow W_y\\)) and from \\(W_t\\) to Y (\\(W_t \\leftarrow W_x \\rightarrow Y\\), \\(W_t \\leftarrow W_x \\rightarrow W_y \\rightarrow Y\\), \\(W_t \\leftarrow W_x \\rightarrow T \\rightarrow Y\\), and \\(W_t \\leftarrow W_x \\rightarrow T \\leftarrow X \\rightarrow Y\\)). \\(\\textbf{W}_x\\) is not a descendant of \\(W_t\\) in Fig. 2(b) and satisfies 1G-2. Therefore, \\(\\textbf{W}_x\\) satisfies Assumption 5 and is an adjustment set for unbiasedly estimating the PDE and PIE.\nBased on Theorem 1, the counterfactual expressions for PDE (Eq. 5), PIE (Eq. 6), and STE can be simplified into the do-expressions. This leads to our second theoretical finding presented below.", "content": "Proof: First, we prove that \\(\\textbf{W}_x\\) satisfies condition 1G-1 of Assumption 5. In the causal DAG shown in Fig. 2(b), all \\(W_t\\)-avoiding backdoor paths from \\(W_y\\) to Y (\\(W_y \\leftarrow W_x \\rightarrow Y\\), \\(W_y \\leftarrow W_x \\rightarrow T \\leftarrow X \\rightarrow Y\\), and \\(W_y \\leftarrow W_x \\rightarrow T \\leftarrow Y\\)) are blocked by the set \\(\\textbf{W}_x, W_t\\), thus \\(\\textbf{W}_x\\) satisfies 1g-1. Next, we prove that \\(\\textbf{W}_x\\) satisfies condition 1G-2. The set \\(\\textbf{W}_x\\) blocks all backdoor paths from \\(W_t\\) to \\(W_y\\) (\\(W_t \\leftarrow W_x \\rightarrow W_y\\), \\(W_t \\leftarrow W_x \\rightarrow Y \\leftarrow W_y\\), \\(W_t \\leftarrow W_x \\rightarrow T\\leftarrow Y\\leftarrow W_y\\), and \\(W_t \\leftarrow W_x \\rightarrow T \\leftarrow X \\rightarrow Y \\leftarrow W_y\\)) and from \\(W_t\\) to Y (\\(W_t \\leftarrow W_x \\rightarrow Y\\), \\(W_t \\leftarrow W_x \\rightarrow W_y \\rightarrow Y\\), \\(W_t \\leftarrow W_x \\rightarrow T \\rightarrow Y\\), and \\(W_t \\leftarrow W_x \\rightarrow T \\leftarrow X \\rightarrow Y\\)). \\(\\textbf{W}_x\\) is not a descendant of \\(W_t\\) in Fig. 2(b) and satisfies 1G-2. Therefore, \\(\\textbf{W}_x\\) satisfies Assumption 5 and is an adjustment set for unbiasedly estimating the PDE and PIE.\nBased on Theorem 1, the counterfactual expressions for PDE (Eq. 5), PIE (Eq. 6), and STE can be simplified into the do-expressions. This leads to our second theoretical finding presented below.\n\nPDE = E [Y | do(W_t = w', W_y = w_y), W_x = w_x)]\n- E [Y | do(W_t = w_t, W_y = w_y), W_x = w_x)]\n\\times P(W_y = w_y | do(W_t = w'),W_x = w_x)\n\\times P(W_x = w_x)\nPIE = E (Y | do(W_t = w_t, W_y = w_y), W_x = w_x)\n\\times [P(W_y = w_y | do(W_t = w_t),W_x = w_x)\n-P(W_y = w_y | do(W_t = w_t), W_x = w_x)]\nSTE = E(Y | do(T = t')) \u2013 E(Y | do(T = t))\nBased on Pearl's back-door adjustment formula and rules of do-calculus (Pearl 2009), we have the theorem 1 to simplify do-expressions into probability expressions.\nTheorem 2. If we can derive p(T, Y, X, W, W_y, W_t from the causal DAG in Fig 2(b), then the PDF, PIE and STE can be identified from the data as follow:\nPDE = [E(Y | Wt = w', Wy = wy, Wx = Wx)\n-E(Y | Wt = wt, Wy = wy, Wx = Wx)]\n\\times P(Wy = wy | Wt = w',Wx = wx)\n\\times P(Wx = wx)\nPIE = E(Y | Wt = wt, Wy = wy, Wx = Wx)\n\\times [P(Wy = Wy | Wt = w',Wx = Wx)\n-P(Wy = Wy | Wt = wt, Wx = Wx)]\nSTE = P(X = x)P(Wx = wx)\n\\times [E(Y | T = t', X = x,Wx = wx)\n-E(Y | T = t, X = x,Wx = wx)]\nProof: We prove that Eq 7 to Eq 9 are identifiable, i.e., the do-operator can be converted to a do-free expression in Eq 10 to Eq 12, respectively. Our proposed causal DAG is shown in Fig 2(b). Based on rule 2 of do-calculus, we have"}, {"title": "P(Y = y | do(W_t = w',W_y = w_y),W_x = w_x)) = P(Y = y | do(W_t = w'),W_y = w_y, W_x = w_x)) since (Y \\ud Y | W_y | W_t,W_x)GW+wy, where \\(W_t\\) represents the removal of all arrows pointing to \\(W_t\\), and \\(W_y\\) represents the removal of all arrows emanating from \\(W_y\\). P(Y = y | do(W_t = w'), W_y = w_y,W_x = w_x)) = P(Y = y | W_t = w',W_y = w_y,W_x = w_x)) because (Y \\ud Y W_t | W_y,W_x)Gw\u2081, where \\(W_t\\) represents the removal of all arrows emanating from \\(W_t\\). P(W_y = w_y | do(W_t = w'),W_x = w_x)) = P(W_y = w_y | W_t = w',W_x = w_x)) because (\\(W_yWtWxGw\\)\nBased on the back-door adjustment formula, P(Y = y | do(T = t')) is identifiable because all backdoor paths from T to Y are blocked by adjusting for X and W. Specifically, T\u2190 X \u2192 Y is blocked by X, T\u2190 Wx \u2192 Wt \u2192 Y is blocked by Wt, T \u2190 Wx \u2192 Wt \u2192 Wy \u2192 Y is blocked by Wt, T \u2190 Wx \u2192 Wy \u2192 Y is blocked by Wx, and T \u2190 Wx \u2192 Wy \u2190 Wt \u2192 Y is blocked by Wx. Hence, P(Y = y | do(T = t')) = P(Y = y | T = t')P(X = x)P(Wx = wx). For details on the processes for calculating the PDE, PIE, and STE, please refer to the Appendix due to page limit.", "content": "P(Y = y | do(W_t = w',W_y = w_y),W_x = w_x)) = P(Y = y | do(W_t = w'),W_y = w_y, W_x = w_x)) since (Y \\ud Y | W_y | W_t,W_x)GW+wy, where \\(W_t\\) represents the removal of all arrows pointing to \\(W_t\\), and \\(W_y\\) represents the removal of all arrows emanating from \\(W_y\\). P(Y = y | do(W_t = w'), W_y = w_y,W_x = w_x)) = P(Y = y | W_t = w',W_y = w_y,W_x = w_x)) because (Y \\ud Y W_t | W_y,W_x)Gw\u2081, where \\(W_t\\) represents the removal of all arrows emanating from \\(W_t\\). P(W_y = w_y | do(W_t = w'),W_x = w_x)) = P(W_y = w_y | W_t = w',W_x = w_x)) because (\\(W_yWtWxGw\\)\nBased on the back-door adjustment formula, P(Y = y | do(T = t')) is identifiable because all backdoor paths from T to Y are blocked by adjusting for X and W. Specifically, T\u2190 X \u2192 Y is blocked by X, T\u2190 Wx \u2192 Wt \u2192 Y is blocked by Wt, T \u2190 Wx \u2192 Wt \u2192 Wy \u2192 Y is blocked by Wt, T \u2190 Wx \u2192 Wy \u2192 Y is blocked by Wx, and T \u2190 Wx \u2192 Wy \u2190 Wt \u2192 Y is blocked by Wx. Hence, P(Y = y | do(T = t')) = P(Y = y | T = t')P(X = x)P(Wx = wx). For details on the processes for calculating the PDE, PIE, and STE, please refer to the Appendix due to page limit."}, {"title": "Implementation", "content": "To accurately estimate PDE, PIE, and STE within networks, it is first necessary to establish Theorem 2, proving that these effects can be effectively identified, and then derive Eq 10 to Eq 12. The implementation process involves three key steps: (1-1) Causal Mediation Analysis: This step decomposes network peer effects into direct and indirect effects using causal mediation analysis (Pearl 2014); (1-2) Back-Door Criterion Adjustment: This step effectively identifies the STE using the back-door criterion, as introduced in the preliminaries. (2) GNNs: Multi-layer GNNs with attention mechanisms are employed to capture the different influence of high-order neighbors. (3) HSIC Regularization: HSIC regularization (Ahmad, Mazzara, and Distefano 2021) is integrated to ensure independence between features and embeddings, maximizing the utilization of graph structures and enhancing model robustness. The workflow of our gDIS model is shown in Fig. 3, and it provides a robust framework for estimating group-level PDE, PIE, and STE.\nUsing attention weights to capture the varying influences of nodes. A two-layer GNN with attention mechanisms dynamically weights the importance o neighboring nodes when updating each node's representation. By considering both direct and second-order neighbors, we calculate the attention coefficients aij to indicate the relative importance of each neighbor as follows:\n\n\\alpha_{ij} = \\frac{exp(\\phi(A^T [WH_i || WH_j]))}{\\sum_{k\\in N(i)\\cup\\{i\\}} exp(\\phi(A^T[WH_i || WH_k]))}\nwhere aij indicates the importance of neighfbor j to node i, and \\(\\phi(\\cdot)\\) is the LeakyReLU activation function (Xu et al. 2020). A is a learnable weight vector used to calculate the unnormalized attention score between nodes, while W is a"}, {"title": "learnable weight matrix that linearly transforms the feature vector H. \\(H_i\\) and \\(H_j\\) are the feature vectors of nodes i and j, respectively, and || denotes vector concatenation. \\(N(i)\\) represents the neighbor set of node i.\nThe new feature representation of node i incorporates both its own information and that of its neighbors, resulting in a more comprehensive and accurate update.\n\\(H' = \\sigma(\\sum_{j\\in N(i)\\cup\\{i\\}} A_{ij} WH_j)\\)\nwhere \\(\\sigma(\\cdot)\\) represents the ELU activation function (Ide and Kurita 2017).\nHSIC Regularization. HSIC (Ahmad, Mazzara, and Distefano 2021) measures the dependence between two variables in a Reproducing Kernel Hilbert Space (RKHS) (Berlinet and Thomas-Agnan 2011). Adding an HSIC regularization term to the loss function promotes independence between the original features and node embeddings, encouraging the embeddings to rely more on graph structure rather than node features, thereby reducing overfitting and improving robustness.\nThe feature matrix H and the kernel matrix H' using the Gaussian kernel (Keerthi and Lin 2003) function are defined as follows:", "content": "learnable weight matrix that linearly transforms the feature vector H. \\(H_i\\) and \\(H_j\\) are the feature vectors of nodes i and j, respectively, and || denotes vector concatenation. \\(N(i)\\) represents the neighbor set of node i.\nThe new feature representation of node i incorporates both its own information and that of its neighbors, resulting in a more comprehensive and accurate update.\n\\(H' = \\sigma(\\sum_{j\\in N(i)\\cup\\{i\\}} A_{ij} WH_j)\\)\nwhere \\(\\sigma(\\cdot)\\) represents the ELU activation function (Ide and Kurita 2017).\nHSIC Regularization. HSIC (Ahmad, Mazzara, and Distefano 2021) measures the dependence between two variables in a Reproducing Kernel Hilbert Space (RKHS) (Berlinet and Thomas-Agnan 2011). Adding an HSIC regularization term to the loss function promotes independence between the original features and node embeddings, encouraging the embeddings to rely more on graph structure rather than node features, thereby reducing overfitting and improving robustness.\nThe feature matrix H and the kernel matrix H' using the Gaussian kernel (Keerthi and Lin 2003) function are defined as follows:\n\\left(K_H\\right)_{il} = exp\\left(-\\frac{||H_i - H_l||^2}{2\\gamma^2}\\right)\n\\left(K_{H'}\\right)_{il} = exp\\left(-\\frac{||H'_i - H'_l||^2}{2\\gamma^2}\\right)\nwhere || \\(H_i - H_l\\)||2 is the squared euclidean distance (Danielsson 1980) between feature vectors \\(H_i\\) and \\(H_l\\). \\(\\gamma\\) is the Gaussian kernel bandwidth (Kakde et al. 2017), set to the median of input feature distances. I is the \\(m \\times m\\) identity matrix, 1 is an \\(m \\times 1\\) vector of ones, and m is the total number of samples. The centering matrix C is calculated as:\nC = I - \\frac{11^T}{n}"}, {"title": "Objective Function. We use mean squared error (MSE) loss (Chicco, Warrens, and Jurman 2021) to measure the difference between actual and predicted values. Our final objective function is:", "content": "Objective Function. We use mean squared error (MSE) loss (Chicco, Warrens, and Jurman 2021) to measure the difference between actual and predicted values. Our final objective function is:\nL_{total} = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{Y_i} - Y_i)^2 + \\lambda \\cdot \\frac{1}{(n - 1)^2} trace\\left(K_H C K_{H'} C\\right)\nwhere \\(\\lambda\\) is a hyperparameter set to 0.1. The trace term measures the dependence between the feature matrix H and the embedding matrix H'."}, {"title": "Experiments", "content": "In this section, we evaluate the causal effect estimation capabilities of gDIS. We use standard evaluation metrics to compare the performance of gDIS against baseline models, validating its effectiveness."}, {"title": "Experiments Setup", "content": "Datasets. Each unit i has only one observed treatment \\(T_i\\)", "networks": "BlogCatalog and Flickr (Li et al. 2015), with detailed descriptions provided in the Appendix.\nGiven the high-dimensional and sparse nature of the original features, we follow the approach in (Jiang and Sun 2022; Chen et al. 2024) and apply Latent Dirichlet Allocation (LDA) (Blei, Ng, and Jordan 2003) to reduce the dimension to 10. The network is then divided into training, validation, and test sets using the METIS algorithm (Karypis and Kumar 1998)."}]}