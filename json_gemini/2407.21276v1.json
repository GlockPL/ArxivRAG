{"title": "Multi-Level Querying using A Knowledge Pyramid", "authors": ["Rubing Chen", "Xulu Zhang", "Jiaxin Wu", "Wenqi Fan", "Xiao-Yong Wei", "Qing Li"], "abstract": "This paper addresses the need for improved pre-cision in existing Retrieval-Augmented Generation (RAG) methods that primarily focus on enhancing recall. We propose a multi-layer knowledge pyramid approach within the RAG framework to achieve a better balance between precision and recall. The knowledge pyramid consists of three layers: Ontologies, Knowledge Graphs (KGs), and chunk-based raw text. We employ cross-layer augmentation techniques for comprehensive knowledge coverage and dynamic updates of the Ontology schema and instances. To ensure compact-ness, we utilize cross-layer filtering methods for knowledge condensation in KGs. Our approach, named PolyRAG, follows a waterfall model for retrieval, starting from the top of the pyramid and progressing down until a con-fident answer is obtained. We introduce two benchmarks for domain-specific knowledge re-trieval, one in the academic domain and the other in the financial domain. The effectiveness of the methods has been validated through com-prehensive experiments by outperforming 19 SOTA methods. An encouraging observation is that the proposed method has augmented the GPT-4, providing 395% F1 gain by improving its performance from 0.1636 to 0.8109.", "sections": [{"title": "1 Introduction", "content": "Significant advancements have been made in Large Language Models (LLMs), including proprietary models like ChatGPT and GPT-4, as well as open-source variants like FLAN (Wei et al., 2021) and LLaMA (Touvron et al., 2023a). These mod-els have demonstrated remarkable achievements across a wide range of general knowledge tasks in areas such as language comprehension (Radford et al., 2018; Hadi et al., 2023), logical reasoning (Kojima et al., 2022; Chang et al., 2024), and com-plex question-answering (Wu et al., 2023b). How-ever, the one-size-fits-all nature of general LLMs fails to meet the specific demands for professional or personalized knowledge, such as law (Huang et al., 2023b; Cui et al., 2023) and finance domains (Wang et al., 2023; Xie et al., 2023). A straight-forward solution is to utilize Supervised Fine-Tuning (SFT) to tailor LLMs to domain-specific tasks (Ouyang et al., 2022). Examples include AlpaCare (Zhang et al., 2023), Mental LLaMA (Yang et al., 2024a) and Zhongjing (Yang et al., 2024b) in medical domain, BloombergGPT (Wu et al., 2023a), Pixiu (Xie et al., 2023), and DISC-FinLLM (Chen et al., 2023) in financial domain, and DISC-LawLLM (Yue et al., 2023) in law do-main. Nonetheless, this risks catastrophic forget-ting (Luo et al., 2023) of the general knowledge when tuning the original model, and is prone to model hallucination (Huang et al., 2023a).\nTo address this challenge, the prevalent alter-native of Retrieval Augmented Generation (RAG) is introduced as a means to enhance the domain knowledge comprehension of LLMs (Lewis et al., 2020a). Rather than solely relying on the genera-tion capabilities of LLMs to produce answers, RAG takes a different approach by incorporating infor-mation retrieval techniques. It retrieves relevant information from existing resources and utilizes this information to enrich the context of the prompt (Gao et al., 2023). This enables in-context learn-ing (Dong et al., 2023) or few-shot learning (Wang et al., 2020b) to be initiated based on the enhanced context. It makes the LLMs' output more stable, accurate, traceable, and interpretable. However, early implementations of RAG have relied on un-structured textual data chunks, which are often ob-tained by partitioning each document in the corpora database into segments with a predefined chunk size and thus not organized in a specific way (Ma et al., 2023; Lewis et al., 2020b). To address this limitation, Knowledge Graphs (KGs) have been incorporated into RAG (Baek et al., 2023a; Wu et al., 2023d; Abu-Rasheed et al., 2024). The in-"}, {"title": "2 Related Works", "content": "LLMs have become integral in various applica-tions, such as chatbots, writing assistants, cus-tomer service automation (Sallam, 2023; Rebedea et al., 2023). Domain-specific LLMs are a sub-set of LLMs that have been tailored to understand and generate text within a particular area of exper-tise, such as law (Huang et al., 2023b; Cui et al., 2023; Yue et al., 2023), medicine (Zhang et al., 2023; Yang et al., 2024b,a), or finance (Ge et al., 2024; Wang et al., 2023; Xie et al., 2023; Chen et al., 2023). These models aim to provide higher accuracy and more relevant outputs than general-purpose LLMs when dealing with specialized con-tent (Ouyang et al., 2022). A common approach is to adapt instruction fine-tuning based on the general LLMs (Ouyang et al., 2022) using domain-specific copra. However, research has shown that the gen-erality of the fine-tuned model will diminish, re-sulting in catastrophic forgetting (Luo et al., 2023; Zhai et al., 2023). In order to tackle the limita-tions, the approach of prompting LLMs with extra domain knowledge as contexts is widely adopted."}, {"title": "2.2 Retrieval-Augmented Generation", "content": "Retrieval-Augmented Generation (RAG) enhances the generative capabilities of language models by incorporating retrieved knowledge for in-context learning (Lewis et al., 2020b; Gao et al., 2023). NaiveRAG represents the most basic architecture within this framework, in which the system re-trieves the top-k documents that are most relevant to the query and integrate them into the prompt, thereby grounding the responses in more relevant information (Ma et al., 2023).\nExpanding on NaiveRAG, advanced RAG incor-porates additional modules or structures to improve retrieval precision. Reranking is a notable example,"}, {"title": "2.3 Knowledge-Augmented Language Models", "content": "The Knowledge-Augmented Language Model (LM) approach involves integrating LMs with ad-ditional knowledge bases to facilitate in-context learning (Liu et al., 2019). In addition to incor-porating knowledge in the form of raw texts (Ma et al., 2023), knowledge graphs (KGs) (Baek et al., 2023b; Pan et al., 2024; Wu et al., 2023d) have gained popularity, and Ontologies (Vamsi et al., 2024) have also been utilized, albeit less frequently. In most KG augmentation methods (Pan et al., 2024), the RAG framework is followed, wherein the context is expanded by incorporating retrieved KG triples instead of raw text chunks. KAPING (Baek et al., 2023a) serves as an early example of this approach, which has been later refined in RRA (Wu et al., 2023c). Regarding Ontologies, instead of being used as an individual knowledge base, they are often employed as assistants for generating KG triplets (Pan et al., 2024) (e.g., Text2KGBench (Mi-hindukulasooriya et al., 2023)) or for augmenting textual corpora (e.g., EKGs (Baldazzi et al., 2023), OntoChatGPT (Palagin et al., 2023)). The integra-tion of various forms of knowledge bases poses a significant challenge and remains an area that has received limited exploration."}, {"title": "3 Knowledge Pyramid Construction", "content": "Let us establish the knowledge pyramid as the foun-dational base for PolyRAG. The construction pro-cess begins by creating three distinct knowledge banks, each guided or supported by an Ontology, a knowledge graph, and the raw texts, following com-mon practices. These banks (denoted as O, K, and T, respectively) form the initial layers of the pyra-mid. The essence of our proposed methodology lies in fostering interactions between these layers,"}, {"title": "3.1 Construction of Initial Layers", "content": "Ontology Layer: The Ontology layer O = {0s, 0;} consists of a schema Os and correspond-ing instances O\u00bf. Defining an Ontology schema typically requires significant time and effort from human experts, and achieving a comprehensive schema can be challenging. To simplify the process, one approach is to initially extract a sub-domain schema from general Ontologies like WordNet (Miller, 1995) or ConceptNet (Speer et al., 2017).\nWith the schema Os that we extracted, we can guide LLMs to extract instances from the raw text layer T for each of the concept-attribute pair (c,a) \u2208 Os, where c is a concept (e.g., pro-fessor) and a is one of its attributes (e.g., re-search_interest). This can be written as a prompt function"}, {"title": null, "content": "fins(c, a; p): Given a paragraph {p} from the {domain} domain, please identify in-stances of the Ontology relationship where a class {c} has the attribute of {a}. Note that the attribute may consist of multiple entities."}, {"title": null, "content": "Executing this function results in instances that fulfill the specified relationship. By repeatedly ap-plying this function to each paragraph, the set Oi is constructed as\nOi = {fins(c, a; p) |\u2200(c, a) \u2208 Os, \u2200p \u2208 T}.\nIt is important to note that the specific implemen-tation of the prompt may vary among LLMs. Ad-ditionally, in certain cases, it may be beneficial to provide examples to initiate few-shot learning for extracting high-quality information, depending on the capabilities of the LLMs. Our implementations are available in the Github repository.\nKnowledge Graph Layer: We adopt Open Infor-mation Extraction (OpenIE) (Etzioni et al., 2008) to extract KG triples from raw texts. However, direct extraction often results in noisy output, including irrelevant or duplicate entities. To address this, we draw inspiration from the multi-round prompting approach of LLM2KG (Carta et al., 2023) and reim-plement it by introducing four functions: fpar(p)"}, {"title": null, "content": "for paraphrasing, fent() for entity extraction, frel()\nfor relation completion, and fdis() for disambigua-\ntion. These functions form a cascade for KG triplet\nextraction and refinement as\nfkg(p) = fdis(fent(fpar(P)), frel(fpar(p))).\nIt constructs the initial knowledge graph layer as\nK = {fkg(p)|\u2200p \u2208 T}."}, {"title": "3.2 Knowledge Completion", "content": "As shown in the pyramid of Figure 1, the higher layers are more structured but not easy to define or extract, resulting in limited coverage. One com-mon issue is the absence of important classes or at-tributes from the expert-defined Ontology schema, which has historically hindered the ease of defining Ontologies. By utilizing the pyramid framework, we can address this issue in a data-driven man-ner. The idea is to identify noteworthy concepts and relations that exist in the lower layers but are absent from the higher layers. These identified ele-ments are then incorporated into the higher layers to enhance knowledge completion. For instance, our research reveals that the relationship publica-tions_in_important_journals appears frequently in both the knowledge graph and raw texts but is ab-sent from the Ontology. This is due to the tendency of human-defined schema to overlook this specific relationship, as the presence of the publications attribute may make it seem redundant. However, users often query this specific relation, and it is explicitly mentioned in professors' profiles. It is thus worth including it in the Ontology.\nOur approach involves modeling the seman-tic distributions of the Ontology and knowledge graph to identify concepts and relations that ex-hibit significant divergence between the two layers. To achieve this, we begin by transforming class-attribute pairs in the Ontology layer O into sub-ject+relation phrases that align with the format in the knowledge graph layer K. Instructor embed-ding (Su et al., 2022) of phrases at both layers are then encoded so as to project them into a common semantic space. We then learn for each layer a multivariate Gaussian using"}, {"title": null, "content": "F(X) = 1/(2\u03c0)^(n/2)|\u03a3|^(1/2) e^(-1/2 (X-\u03bc)^\u03a4 \u03a3^(-1)(X-\u03bc)),"}, {"title": "3.3 Knowledge Condensation", "content": "The process of Knowledge Completion aims to enhance the richness of information in a bottom-up manner. In addition, we perform Knowledge Condensation to improve the compactness of the pyramid in a top-down approach. The principle is to leverage the well-structured knowledge in the higher layers to eliminate redundant information present in the lower layers. This is implemented by using each class-attribute in the Ontology layer as an anchor and explore its neighborhood to identify a set of k nearest knowledge graph triplets {Xk}. A prompt function is then applied to instruct the LLM to summarize them into compact ones as\nfcon({Xk}): Please condense the set of knowledge graph triplets {Xk} obtained from the {domain} domain by eliminating redundant triplets and summarizing the re-maining ones in a more concise manner. Here are some examples for your refer-ence: {examples}. The condensation pro-cess should follow the logic of {CoT}."}, {"title": "4 Multi-Level Querying", "content": "The pyramid enables PolyRAG in a straightfor-ward top-down querying manner, following the flow Ontology\u2192Knowledge Graph\u2192Raw Texts, in which the results are returned if answers are found at higher layers; otherwise, the querying continues to the next layer. The querying flow is"}, {"title": "4.1 Search at Ontology Layer", "content": "At the Ontology Layer, we can utilize SparQL as the query language. SparQL is a well-defined lan-guage that provides precise results when queries are properly structured. To achieve this, we can guide the LLM to generate the SparQL query by using the following prompt function\nQueryonto(Q, schema): Given a input question {Q} within the domain {do-main}, please formulate a SPARQL query to retrieve the answer based on the pro-vided Ontology schema. The namespace is {schema.base}, and the classes are {schema.class}. The object properties be-tween classes are {schema.op}, and the classes may also have data properties such as {schema.dp}."}, {"title": null, "content": "For the example of a query question like \u201cWho is currently working in CS Department and was graduated from Cambridge University?\u201d, the LLM extracts the related attributes of \u201cworks_in\" and \"graduated_from\" with the given schema, and gen-erate a SPARQL query to search a staff who sat-isfies the relevant condition in O. The execut-ing results may include a list of names, or simply\""}, {"title": "4.2 Search at Knowledge Graph Layer", "content": "At the knowledge graph layer, we employ a re-trieval approach similar to the embedding-based retrieval utilized in NaiveRAG. However, instead of using chunks, we work with triplets. Once the matching triplets are retrieved, we utilize a prompt function to assess the Language Model's agree-ment on whether the question has been answered adequately as\nQuerykg(Q, triples): Given a question {Q} and the context information provided by the matched triples from the knowledge graph {triples}, please justify whether the pro-vided information is sufficient to accurately answer the question. Respond with either \"Yes\" or \"No\" to provide your justification."}, {"title": null, "content": "For example, given a query of \"which CS staff has interest in cloud computing?\u201d, the LLM may justify a set of triples as \u201cagree\u201d if they include information like \u201cProf. A works in CS Department, Prof. A published on cloud computing journal, etc.\"; inversely, the justification might be \u201cdisagree\u201d if the triples do not provide the key knowledge related to this query, thus the searching will process to the next layer for a more relevant context in order to answer the query.\""}, {"title": "5 Experiments", "content": "Our experimentation involves two distinct domain-specific benchmarks. The first benchmark is Academia Challenge (AcadChall), which has been built by ourselves and focuses on the academic domain. It encompasses a comprehensive collec-tion of data obtained from XXX university, in-cluding information about 31 departments, 1,319 faculty members, and 2,061 courses. Specifically, AcadChall consists of 512 MCQ and MAQ ques-tions that cover topics related to teaching and re-search. These questions are intentionally designed to be more challenging compared to existing bench-marks, as each question presents eight answer choices. This design aims to provide a more rig-orous assessment of the models' precision. The second benchmark is FiQA, which is widely rec-"}, {"title": "5.3 Comparison to SOTA Methods", "content": "We compare PolyRAG with five groups of state-of-the-art (SOTA) methods, including 1) Frozen-LLMs that are pretrained LLMs of frozen parame-ters and no external knowledge has been used for querying. 2) SFT (Supervised Fine-Tuning) that are LLMs that undergo supervised fine-tuning on domain-specific datasets. We include two latest im-plementation of Finance-LLM and Finance-Chat (Cheng et al., 2024), both of which are trained on fi-nancial corpora. Additionally, we explore variants of SFT that employ LoRA (Hu et al., 2022) instead of the entire models. 3) NaiveRAG proposed in (Lewis et al., 2020a). 4) Advanced RAG that in-clude two recent models, namely ColBERTv2 (San-thanam et al., 2022) and Bge-reranker (Xiao et al., 2023). 5) KG-Augmented LLMs that consists of models proposed in (Baek et al., 2023b) that in-tegrate knowledge graphs (KGs) into the LLMs. Various LLMs have been explored as the back-"}, {"title": "5.4 Knowledge Completion and Condensation", "content": "We have conducted experiments to evaluate the ef-fectiveness of knowledge completion (CPL) and condensation (CND) by integrating them with a baseline model (PolyRAG without these two mod-ules). The results are presented in Table 2. Please note that due to space limitations, we only list re-sults for four specific backbones. For a comprehen-sive performance analysis with Vicuna-13B and LLaMA2-70B backbones, please refer to the Ap-pendix C. The results clearly demonstrate the ef-fectiveness of both completion and condensation in enhancing performance, whether used individ-ually (CPL: 3.8% \u00b1 6.1 performance gain, CND: 2.2% \u00b1 3.3 performance gain) or in combination (6.5% \u00b1 6.4 performance gain over the baseline). Our statistics indicate that with completion, queries resolved at the Ontology layer is increased by 5%."}, {"title": null, "content": "With condensation, more than 27% of queries are resolved at the KG layer."}, {"title": "5.5 Influence of Knowledge Layers", "content": "We have examined the influence of different knowl-edge layers on various backbones. The results are presented in Table 3. It is obvious that the Ontology layer plays a prominent role as a knowledge base in enhancing precision, as evidenced by a precision gain of 25.8% \u00b1 7.4 when combined with the raw text layer and 13.7% \u00b1 10.3 when combined with the KG layer. On the other hand, the KG layer demonstrates a balanced impact on improving ei-ther precision or recall. These observations align with our early discussions."}, {"title": "6 Conclusion", "content": "This research has described a preliminary investi-gation that provides a multi-level query approach to domain-specific question answering. In this con-text, we addressed two significant challenges: the problem of prioritizing knowledge in a certain area and the presence of noise in retrieval situations. In order to overcome the limitations, we introduce Knowledge Pyramid multi-level retrieval frame-work as PolyRAG. PolyRAG utilizes a sequential retrieval approach and prioritizes knowledge ex-traction. This approach is designed to tackle the challenges posed by the high demand for dense knowledge in domain-specific scenarios and the distractions caused by noisy contexts. The accu-racy of PolyRAG has been validated through exten-sive tests done in AcadChall and R-FLUE-FiQA, surpassing earlier approaches and generating state-of-the-art results."}, {"title": "Limitations", "content": "One limitation to consider is that Language Mod-els (LLMs) do not strictly adhere to the SparQL syntax, which can result in typographical errors in the queries. Further investigation into this aspect is warranted."}, {"title": "Ethics Statement", "content": "This research paper adheres to ethical consider-ations throughout its methodology and findings. The study primarily focuses on the development and evaluation of a retrieval-augmented generation framework, PolyRAG, for domain-specific knowl-edge retrieval. The research involves the use of existing datasets and benchmarks, as well as the creation of two new benchmarks in the academic and financial domains.\nThe authors ensure proper citation and acknowl-edgment of the data sources to maintain trans-parency and intellectual property rights. In terms of human subjects, this research does not involve any direct human participation, personal data col-lection, or sensitive information. Therefore, ethical concerns related to informed consent, privacy, and confidentiality are not applicable in this context."}, {"title": "A Knowledge Graph Layer Construction", "content": "This section provides the detailed implantations of the four functions for constructing the knowledge graph layer in Section 3.1.\nfpar (p): Determine the factual claims from a given paragraph {p}. Put these facts into short phrases with basic grammar. Re-member that every statement should have a distinct meaning, and pronouns should be avoided."}, {"title": null, "content": "fent(fpar(p)): Extract the noun entities in phrases from the given sentences fpar(p). The entities should not contain any comma, and each entity should be unique during ex-traction."}, {"title": null, "content": "frel(fpar(p)): Given the reference context fpar (p) and relevant entities, complete the relations between two entities. Notice that a triple should only contain one entity as head, one verb or verb phrase as relation, and one entity as tail. Separate the head, relation, and tail with a comma."}, {"title": null, "content": "fdis(fent(), frel()): You are given several triples frel() with their entities fent(). These triples consist of subject-predicate-object el-ements, separated with a comma, but may contain ambiguities or inaccuracies. Your task is to refine and disambiguate these triples to ensure that they accurately reflect the entities and relationships described in their source texts without duplication or omissions. If the relationships have the same semantic meaning, rewrite the triples with the same relation. If the triple has already been mentioned with the same meaning as previous triples, delete it."}, {"title": "B AcadChall and R-FLUE-FIQA\nBenchmarks", "content": "Table 4 lists the data statistics of two benchmarks. We use Vicuna-13B (Chiang et al., 2023) to build the knowledge pyramid for two datasets according to the methods illustrated in Section 3.1. Specif-ically, the AcadChall dataset is created by crawl-"}, {"title": "C Discussion on Knowledge Completion\nand Condensation", "content": "Table 5 verifies the effectiveness of our proposed knowledge completion and condensation tech-niques over multiple LLM backends. Specifically, the multi-level querying on the knowledge pyramid without completion and condensation techniques is used as the baseline. In the baseline, around 30% of questions are answered by more structured data (i.e., Ontology or KG). After applying the completion and condensation techniques, the per-centage increases to 64%. For example, the relation \u201chas published in\u201d, which frequently appears in the KG layer, has been used to complete the Ontol-ogy layer. It has resulted in those questions related to \"publications\u201d being answered by the Ontology"}]}