{"title": "Streamflow Prediction with Uncertainty Quantification for Water Management: A Constrained Reasoning and Learning Approach", "authors": ["Mohammed Amine Gharsallaoui", "Bhupinderjeet Singh", "Supriya Savalkar", "Aryan Deshwal", "Yan Yan", "Ananth Kalyanaraman", "Kirti Rajagopalan", "Janardhan Rao Doppa"], "abstract": "Predicting the spatiotemporal variation in stream- flow along with uncertainty quantification enables decision-making for sustainable management of scarce water resources. Process-based hydrologi- cal models (aka physics-based models) are based on physical laws, but using simplifying assump- tions which can lead to poor accuracy. Data-driven approaches offer a powerful alternative, but they re- quire large amount of training data and tend to pro- duce predictions that are inconsistent with physical laws. This paper studies a constrained reasoning and learning (CRL) approach where physical laws represented as logical constraints are integrated as a layer in the deep neural network. To address small data setting, we develop a theoretically-grounded training approach to improve the generalization ac- curacy of deep models. For uncertainty quantifica- tion, we combine the synergistic strengths of Gaus- sian processes (GPs) and deep temporal models (i.e., deep models for time-series forecasting) by passing the learned latent representation as input to a standard distance-based kernel. Experiments on multiple real-world datasets demonstrate the ef- fectiveness of both CRL and GP with deep kernel approaches over strong baseline methods.", "sections": [{"title": "1 Introduction", "content": "Streamflow is fundamental to meeting societal needs includ- ing food and energy security, and environmental health. In \"fully appropriated\u201d Western US watersheds\u2014where every drop of water is associated with a beneficial use under a legal water rights system-an accurate representation of the spatio- temporal variation in streamflow is essential for sustainable management of scarce water resources. A typical decision context in the snow-dominant Western US is reservoir opera- tions leading into the spring and summer months when most of the streamflow is generated (high streamflow months from March through July which is the focus of our study). The reservoirs need to be operated to manage competing objectives based on expectations of upcoming streamflow. Typical objectives include meeting flood control, irrigation demands for the season, and hydro power generation needs (see Fig. 1). One concrete example of the conflicting ob- jectives is as follows. The reservoirs need to be evacuated enough to capture upcoming streamflow and avoid flood risk. However, this cannot be at the expense of not being able to fill the reservoir before the irrigation season starts. Having a good forecast of expected flows in high flow months, and reliable uncertainty bounds around it can help optimize stor- age and release decisions to meet all objectives. Moreover, different decisions will involve utilizing uncertainty bounds in different ways. When flood risk needs to be minimized, the reservoir manager will likely utilize flows at the upper bound of the uncertainty interval in water release decisions. In contrast, while focusing on meeting irrigators' needs, the reservoir manager will likely make storage decisions based on the lower bound of expected streamflow. Under the aus- pices of a federal grant, this project team has been interacting with United States Bureau of Reclamation (USBR)\u2014the fed- eral agency tasked with managing reservoir operations for all reservoirs in the Western United States where water for ir- rigation is a key operational priority along with a multitude of other uses (see Fig. 1). Therefore, this work has a real potential for impact at the U.S. national scale. Process-based hydrological models (aka physics-based models) that take weather, soil, and other inputs to translate precipitation to streamflow using biophysical representations of the hydrological process are commonly used to estimate streamflow. These models have been known to yield best re- sults when calibrated to individual watersheds but they con- tinue to struggle in regional-scale modeling across multiple watersheds because hydrological response is heterogeneous and watershed-specific [Kratzert et al., 2019]. Data-driven (aka deep learning) models can capture this heterogeneity and push the frontiers in learning universal, re- gional, and local hydrological behavior [Kratzert et al., 2019; Peters-Lidard et al., 2017; Karpatne et al., 2016] while in- creasing streamflow prediction accuracy. However, this learn- ing methodology has to maintain the basic laws governing hydrological processes (e.g., conservation of mass for water balance) and capture the essence of important intermediary processes (e.g., evapotranspiration) that translate precipita- tion to streamflow. Since regional-scale water management decisions are made on \"seasonal\u201d time scales, we seek to make streamflow prediction for high-flow months to allow a targeted impact. As a result, we lack large amounts of train-"}, {"title": "2 Background and Problem Setup", "content": "In streamflow prediction, utilizing graph representations is an efficient method for illustrating watersheds. Within a defined geographical expanse, a watershed represents the entirety of land that contributes water to a shared outlet, which might be a river, lake, or ocean. Within the watershed, a river network showcases the flow paths and connections of water in that re- gion. A watershed is subdivided into grids, representing dis- crete small sections that facilitate the analysis and modeling of factors such as water movement. In the graph representa- tion, the nodes represent the grids within the watershed, and the edges represent the flows between them. Each node has a set of environmental features (including variables related to precipitation and temperature). Given this rich graph rep- resentation, our objective is to predict the streamflow at the watershed outlet at fixed time intervals. Since water manage- ment decisions are made seasonally, we aim to make stream- flow predictions for high-flow months (March to July). Domain Knowledge. The water balance equation (WBE) is a fundamental concept in hydrology: the amount of wa- ter in a system should be balanced between the inputs (e.g., precipitation), outputs (e.g., evapotranspiration, streamflow), and changes in storage (e.g., soil moisture or snowpack). It is given by $P > ET + S$, where $P$ is precipitation, $ET$ is evapotranspiration, and $S$ is streamflow. WBE is not an equality because all components of the water balance are not present here and holds only at an annual aggregated level. Problem Setup. For a given watershed, we consider a sequence of graphs over discrete time steps denoted as $G_1, G_2,\u2026\u2026,G_T$, where each graph $G_t$ represents a directed graph with a set of nodes $V$ and a set of edges $E \\subset V \\times V$. At each time step, the corresponding features matrix $X_t \\in \\mathbb{R}^{n \\times m}$, where $n = |V|$ and $m$ is the number of features. The graph $G_t$ is also characterized by an adjacency matrix $A \\in \\mathbb{R}^{n \\times n}$, with the property that $A_t$ remains invariant since grid connections are static. At each (monthly) time step $t$, we also have the target variable $y_t$ which is the streamflow at the watershed outlet node. Given a training data of time-series $D = \\{(X_t, Y_t)\\}_{t=1}^{T}$ and domain knowledge $K$ in the form of water balance equation, we have two goals: a) To learn a predictor $F$ that can make accurate predictions consistent with the knowledge $K$ for unseen inputs $X_{t'}$ where $t' > T$ (high-flow months only). b) To get uncertainty estimates in the form of a prediction interval $[lb, ub]$ for $X_{t'}$, where the true output $y_{t'} \\in [lb, ub]$ with a high probability."}, {"title": "3 Technical Approach", "content": "In this section, we outline our overall methodology shown in Algorithm 1 to address the three technical challenges, namely, predictions consistent with domain knowledge, small training data, and uncertainty quantification."}, {"title": "3.1 Constrained Reasoning and Learning", "content": "Recurrent Convolutional Graph Neural Network. We employ a recurrent convolutional graph convolutional neu- ral network (RCGNN) [Seo et al., 2016; Sit et al., 2021; Xiang and Demir, 2022] to solve the streamflow prediction task. RCGNN is a generalization of classical graph convolu- tional network that incorporates the recurrent nature of RNN to capture temporal dependencies in graph-structured data. Notably, in graph embedding learning, for a given node, we integrate information from both preceding time steps and ad- jacent river segments (i.e., edges). The RCGNN model establishes transition connections for the derived latent representation using a recurrent cell con- figuration. In the scope of this study, we employ the Gated Recurrent Unit (GRU) cell, known for its prowess in captur- ing sequential patterns and dependencies in graph-structured data. For time step $t$, given a graph represented by its adja- cency matrix $A$ and its input feature matrix $X$, a graph con- volutional GRU layer is parameterized with multiple weight matrices $W$'s, $U$'s and bias terms $b$'s, and starts by computing the reset gate $r_t$ and updates gate $z_t$ from time step $t - 1$:\n$r_t = \\sigma(W_r \\cdot X + U_r \\cdot (A \\cdot H^{(t-1)}) + b_r)$\n$z_t = \\sigma(W_z \\cdot X + U_z \\cdot (A \\cdot H^{(t-1)}) + b_z)$,\nwhere $H^{(t-1)}$ is the hidden state of the previous time step $t$, while $\\sigma$ denotes the sigmoid activation function. Next, it computes candidate hidden state ($\\tilde{h}$):\n$\\tilde{h} = tanh(W_h X + U_h \\cdot (r_t \\odot (A \\cdot H^{(t-1)})) + b_h)$.\nHere, $\\odot$ represents element-wise multiplication. Using $z_t$ and $\\tilde{h}$, we update the current hidden state $H^{(t)}$ as follows:\n$H^{(t)} = z_t \\odot H^{(t-1)} + (1 - z_t) \\odot \\tilde{h}_t$.\nTherefore, the learnable weight matrices of the model are specifically denoted above by $W_r$, $U_r$, $W_z$, $U_z$, $W_h$ and $U_h$, and trainable bias terms are $b_r$, $b_z$ and $b_h$. For the subse- quent output layers, two distinct activation functions are em- ployed alongside two linear layers. For the activation func- tion, we use LeakyRelu to introduce non-linearity. We build our RCGNN model to learn the graph embedding according to the above architecture, denoted by $f(X)$. Semantic Probabilistic Layer. To address the challenge of maintaining domain knowledge consistency, the constrained reasoning and learning (CRL) approach instantiates the con- cept of semantic probabilistic layer (SPL) [Ahmed et al., 2022b]. SPL can be replaced with the predictive layer of any deep neural network. It allows to model domain knowledge as logical constraints over multiple inter-related output vari- ables and guarantees consistency of predicted outputs. Given a structured input $X$, the computation of the prob- ability of a candidate structured output $Y$ is decomposed as $p(Y|f(X)) = q_{\\Theta}(Y|f(X)) \\cdot c_K(X,Y)/Z(X)$, where $f(X)$ represents the feature embedding or latent representation of input $X$; $q_{\\Theta}(Y|f(X))$ parameterized by $\\Theta$ allows us to per- form probabilistic reasoning over candidate structured out- puts $Y$; $c_K(X, Y)$ is a constraint reasoner to ensure that pre- dicted structured outputs $Y$ are consistent with the domain knowledge $K$ and produces evaluation 1 (i.e., $c_K(X, Y)=1$) only when $Y$ satisfies the declarative knowledge $K$; and $Z(x)$ is a normalization constant. SPL leverages the benefi- cial properties of probabilistic circuits [Vergari et al., 2020; Choi et al., 2020] for tractable learning and reasoning. It encodes $q_{\\Theta}(Y|f(X))$ and $c_K(X, Y)$ as circuits, and consid- ers constrained computational graphs to achieve tractability. Therefore, SPL allows us to produce consistent and correct"}, {"title": "3.2 Importance Weighted Training", "content": "Given the learned latent representations $\\{z_i = f(X_i)\\}_{i=1}^T$ from the recurrent GNN model, we describe a novel impor- tance weighted training approach to improve the generaliza- tion accuracy of the predictive model $F$. Notations. Our goal is to train regression models over the training data $D_{tr} = \\{z_i, Y_i\\}_{i=1}^T$ with $T$ examples. Suppose each data sample $(z_i, Y_i)$ is drawn from a target distribution $P$ over the space $Z \\times Y$ such that $z_i$ is an input from the in- put space $Z$ and $y_i \\in Y$ is the corresponding ground-truth output. Let $F : Z \\rightarrow Y$ denote a predictive model trained on the training set $D_{tr}$. A loss function $l : Y \\times Y \\rightarrow \\mathbb{R}$ is used to measure the accuracy of predictions made by $F$. In this paper, we consider the residual $l(F(z), y) = |F(z) \u2013 y|$ as loss and assume that there exists an upper bound of loss as $L = \\max_{(z,y)\\in Z\\times Y}l(F(x),y) < \\infty$. Typically, $F$ is expected to reach a small true risk, defined as $R(F) = E_{(z,y)~P}[l(F(z),y)]$ in the sense of population. Unfortu- nately, we cannot measure $R(F)$ due to the availability of only finite training samples drawn from $P$. Hence, the empirical risk $R(F) = \\frac{1}{T} \\sum_{i=1}^T l(F(z_i), Y_i)$ on $D_{tr}$ is employed to estimate it, leaving a standard esti- mation error bound in $O(\\frac{1}{\\sqrt{T}})$ (see Lemma 1). The rate of convergence of generalization error bound is particularly important when the number of training samples $T$ is small. For example, to ensure the same $O(10^{-2})$ generalization er- ror bound, $O(\\frac{1}{\\sqrt{T}})$ requires $T = O(10^{4})$, while the faster rate $O(\\frac{1}{T})$ only needs $T = 10^{2}$, significantly reducing the requirement of large training sets from modern ML methods. High-level Algorithm. Importance-weighted (IW) training is an iterative gradient-based approach. It assigns importance weight $w(z, y)$ to each sample $(z, y) \\in D_{tr}$ such that $w(z, y)$ is directly proportional to the loss $l(F(z), y)$ based on the current model $F$ and employs the weighted gradient to update the model parameters of $F$ in each iteration. Analogous to the empirical risk $R(F)$, we define the IW empirical risk with weights $w(z, y)$ for $F$ as\n$R_w(F) = \\frac{1}{T}\\sum_{i=1}^T w(z_i, Y_i) l(F(z_i), Y_i)$.\n$R_w(F)$ is general enough to include the empirical risk $R(F)$ as a special case: setting $w(z_i, Y_i) = 1$ for all data samples reduces $R_w(F)$ to $R(F)$. In what follows, we show that un- der some configurations of importance weighting function $w$, $R_w(F)$ gives a tighter estimation of the true risk $R(F)$. Theoretical Analysis. The following lemma shows the gen- eralization error bound for IW empirical risk $R_w(F)$. Lemma 1. (Error bound of IW risk, Theorem 1 in [Cortes et al., 2010]) Let $M = \\sup_{z,y}w(z,y)$ denote the infinity norm of $w$ on the domain. For given $F$ and $\\delta > 0$, with probability at least $1 - \\delta$, the following bound holds:\n$R(F) - R(F) < \\sqrt{\\frac{2M \\log(1/\\delta)}{3T}} + \\sqrt{\\frac{2 d_2(P||Q) \\log(1/\\delta)}{T}}$\nwhere $d_2(P || Q) = \\int \\frac{P(x) \\cdot P(x)}{Q(x)} dx$ is the base-2 exponen- tial for R\u00e9nyi divergence of order 2 between two distributions $P$ and $Q$ and $T$ is the number of training samples. In the above prior result, the last term on the right side $(O(\\frac{d_2}{T}))$ typically dominates the first term $(O(\\frac{M}{T}))$, i.e., $O(\\frac{M}{T}) << O(\\sqrt{\\frac{d_2}{T}})$. Consequently, the choice of $w$ mainly changes the quantity of R\u00e9nyi divergence $d_2$ and thus the dominating term $O(\\sqrt{\\frac{d_2}{T}})$. In what fol- lows, we theoretically show that a simple principle to choose group-wise weights $w$ can easily shrink $d_2$ in the dominating term compared with the conventional empirical risk. Specif- ically, the grouping principle is based on the prediction loss $l(F(z), y)$ of $F$ overall data samples. Given a total number of groups $K$, denote the group $D_k$ such that any data from $D_k$ suffers smaller loss than that from the next group $D_{k+1}$, i.e., $l(F(z),y) \\leq l(F(z'), y')$ for all $(z, y) \\in D_k$ and $(z', y') \\in D_{k+1}$ with $k \\in \\{1, ..., K - 1\\}$ (see discussion in \u201cPractical Algorithm\"). Accordingly, the probability of drawing data from $D_k$ is denoted by $P_k = P\\{(z,y) \\in D_k\\}$. Specifically, for the fixed $F$ and the same analysis framework under Lemma 1, let $B$ and $B_w$ be the generalization error bounds of empirical risk and IW empirical risk, respectively, i.e., $R(F) \u2013 R(F) < B$ and $R(F) \u2013 R_w(F) \\leq B_w$. Below we prove that $B_w < B$ under a certain group-wise setting for $w$. Before proceeding to the main theorem, we define group- wise weights as $\\{w_k\\}_{k=1}^K$, where $w_k$ is assigned to data from group $D_k$ as the weight shown by $R(F)$ in (1). Theorem 1. (IW Improves generalization bound) Assume $\\frac{2M \\log(1/\\delta)}{3T} < \\sqrt{\\frac{2d_2(P||Q) \\log(1/\\delta)}{T}}$ in (2) of Lemma 1. Set $w(z,y) = w_k$ for $(z,y) \\in D_k$ such that $P_k \\cdot w_k = \\frac{k^{\\alpha}}{K^{\\beta+1}}$ for any $k \\in \\{1, ..., K\\}$. Under the conditions $0 < \\alpha < min\\{K - 1,\\beta - \\frac{1}{ln(K)}\\}$, and $K > 2$, the IW empirical risk $R_w(F)$ gives a tighter generalization bound than empir- ical risk $R(F)$ with $B = \\sqrt{\\frac{2 \\log(1/\\delta)}{T}}$ and $B = \\sqrt{\\frac{2 d_2(P||Q) \\log(1/\\delta)}{(a+1)T}}$\""}, {"title": "3.3 Gaussian Process with Deep Kernels for UQ", "content": "Gaussian processes (GPs) [Williams and Rasmussen, 2006] are considered as gold standard for uncertainty quantification (UQ). GPs are non-parametric models and allows the practi- tioner to incorporate domain knowledge in the form of ker- nels $\\kappa(x, x')$ to measure similarity between pairs of inputs $x$ and $x'$ (e.g., RBF kernel). GPs are Bayesian models whose posterior mean and stan- dard deviation provide prediction and uncertainty for each input. A major drawback of GPs is that they have dif- ficulty scaling to high-dimensional structured inputs (e.g., time-series of graphs) as in our problem setting. On the other hand, deep kernel learning (DKL) [Wilson et al., 2016] is a recent technique that has shown to be a promising solu- tion towards handling this drawback. To synergistically com- bine the strengths of GPs and DKL, we parameterize the ker- nel function of the GP model with a neural network feature extractor that is passed to a canonical distance-aware kernel such as RBF kernel. Specifically, we add a GP layer on top of the latent representations learned by the recurrent GNN model. Given the learned latent representations $z_i = f(X_i)$ for all i=1 to T, we create a GP using $D_{tr} = \\{z_i, Y_i\\}_{i=1}^T$ with T training examples. We employ the latent representations $z_i = f(X_i)$ to define a RBF kernel as shown below.\n$\\kappa(z, z') = \\sigma_f e^{-\\frac{||z - z'||^2}{2 \\gamma^2}} \\\\ \\$\nTraining GPs refers to estimating the hyper-parameters of the GP kernel. For example, the RBF kernel in equation (3) has the length-scale $\\gamma$ and the signal variance $\\sigma_f$ hyperparam- eters. To learn the hyperparameters of the kernel, we maxi- mize the marginal likelihood of the observed data using the training data $D_{tr}$. Another advantage of GPs for UQ is that we can update the model online based on new training examples to improve the uncertainty estimates for future predictions. The predictive uncertainty estimate for an input with la- tent representation $z$ can be computed in closed form (for the noiseless observations setting) as given below:\n$\\sigma^2(z) = k(z, z) \u2013 k_*^T K^{-1}k_*$,\nwhere $k_* = [k(z, z_1), k(z, z_2) \u00b7\u00b7\u00b7k(z, z_T)]$ and $K$ is the ker- nel matrix computed over the latent representation of training inputs. We can compute a GP driven confidence interval for input $z$ as $[\\mu(z) \u2013 2\\sigma(z), \\mu(z) + 2\\sigma(z)]$, where $\\mu(z)$ is the posterior mean prediction of the GP."}, {"title": "4 Experiments and Results", "content": "In this section, we describe our empirical results and analysis."}, {"title": "4.1 Experimental Setup", "content": "Watershed Datasets. We collected US Geological Sur- vey's observed monthly streamflow at the outlet of six water- sheds in the Columbia River basin of the Pacific Northwest US: Boise River (BR), Clearwater (C), Clearwater Canyon Ranger (CCR), Flathead (F), South Fork Clearwater (SFC), and Yakima (Y). Our intent was to primarily focus on \"natu- ral\" watersheds with minimal human influence, and this crite- rion along with a constraint on the watershed size (minimum of 1800 sq. km) resulted in the first five watersheds. Addi- tionally, we included the Yakima River basin as an example of human-influenced watershed knowing that the model per- formance will likely be poor. Each watershed has different number of grids (no. of nodes in graph) and river network corresponds to the ad- jacency matrix of the graph. Each graph node has multiple time-varying (monthly) environmental features. The watersheds encompass a span of water years, com- monly used in hydrology to capture the hydrological cycles, starting in October and ending in September next year. We employed the following training/validation/testing splits. The"}, {"title": "4.2 Results and Discussion", "content": "Performance of Streamflow Predictive Models. We make the following observations. 1) All data-driven models perform better than physics-based model VIC- CropSyst across all watersheds. 2) All methods that combine data and knowledge perform better than the pure data-driven model RCGNN for all cases. This demonstrates the value of domain knowledge in the form of the water balance equation 3) Importance-weighted training improves the predictive ac- curacy of RCGNN-CRL-IW over the standard training. This result demonstrates the practical value of our theoretically- justified IW training approach. 4) Accuracy enhancement, relative to the physics-based model, varies by watershed, and time of the year (Fig 2, Fig 5 and Fig 6 in Appendix).\n$NSE = 1 - \\frac{\\sum_{i=1}^n (Y_i \u2013 \\hat{Y}_i)^2}{\\sum_{i=1}^n (Y_i \u2013 \\bar{y})^2}$"}, {"title": "5 Roadmap to Deployment", "content": "The intended application base for our streamflow predic- tion methodology are federal and state/regional agencies that manage reservoirs or engage in other forms of water resources management and planning. However, to enable such partner- ships in the near term, several improvements and extensions have been planned. First, the problem formulation needs to be extended to a forecast setting where expectations of me- teorological and other input variables inform the streamflow predictions. Datasets for expectations of weather are avail- able in the same format as our current inputs and can be di- rectly integrated. Our current prediction accuracies provide an upper bound which will diminish when errors associated with expectations of input variables are added in. To this end, the provision of uncertainty bounds supported by our frame- work will be crucial for the end-user. User interfaces that display the uncertainty metrics in a way that is most useful for decision-making are needed for deployment. We have been exploring the current decision-making interfaces used by the agency to seamlessly integrate. Finally, our stake- holder agency identified explainability of the model as a key feature of interest in transitioning to deployment and we can adapt existing work on explainable AI for this purpose."}, {"title": "6 Summary and Future Work", "content": "This paper studied a constrained reasoning and learning approach for streamflow prediction by combining domain knowledge with deep temporal models, and Gaussian process with deep kernel learning approach for uncertainty quantifi- cation. Our experimental results demonstrated the effective- ness of our overall methodology on diverse real-world water- shed datasets and in guaranteeing that constraints are satisfied for every test-time prediction. One unexplored but important challenge is to model and reason about the human influence on water availability to further improve accuracy."}, {"title": "A Appendix: Recurrent Convolutional Graph Neural Network", "content": ""}, {"title": "B Appendix: Proof for theorem 1", "content": "Proof for Theorem 1\nTheorem 2. (Theorem 1 restated: IW Improves generalization bound) Assume $\\frac{2M \\log(1/\\delta)}{3T} < \\sqrt{\\frac{2d_2(P||Q) \\log(1/\\delta)}{T}}$ in (2) of\nLemma 1. Set $w(z,y) = w_k$ for $(z,y) \\in D_k$ such that $P_k \\cdot w_k = \\frac{k^{\\alpha}}{K^{\\beta+1}}$ for any $k \\in \\{1, ..., K\\}$. Under the conditions\n$0 < \\alpha < min\\{K - 1,\\beta - \\frac{1}{ln(K)}\\}$, and $K > 2$, the IW empirical risk $R_w(F)$ gives a tighter generalization bound than\nempirical risk $R(F)$ with $B = \\sqrt{\\frac{2 \\log(1/\\delta)}{T}}$ and $B = \\sqrt{\\frac{2 d_2(P||Q) \\log(1/\\delta)}{(a+1)T}}$\nProof. (of Theorem 1) Recall the base-2 exponential of R\u00e9nyi divergence of order 2 between $P$ and $\\frac{P}{W}$:\n$d_2(P|| \\frac{P}{W}) = \\int \\frac{P(z,y) \\cdot P(z,y)}{\\frac{P(z,y)}{w(z,y)}}d(z,y) =  \\int \\frac{P(z,y)}{w(z,y)} w(z,y)d(z,y)$.\nIt it worth noting a special case of $w(z, y) = 1$ reduces IW empirical risk $R_w(F)$ back to empirical risk $R(F)$:\n$d_2(P|| \\frac{P}{W}) = d_2(P|| \\frac{P}{1}) =  \\int \\frac{P(z,y)}{1} \\cdot 1 d(z,y) = 1$.\nThen, to prove the main result regarding generalization bounds, under the assumption that$\\frac{2M \\log(1/\\delta)}{3T} \\leq \\sqrt{\\frac{2d_2(P||Q) \\log(1/\\delta)}{T}}$\nin the same analysis result (2) of Lemma 1, we have the following inequalities:\n$R(F) - R(F) \\leq \\sqrt{\\frac{2M \\log(1/\\delta)}{3T}} \\leq \\sqrt{\\frac{2d_2(P||P) \\log(1/\\delta)}{T}} =  \\sqrt{\\frac{2 \\log(1/\\delta)}{T}} = B$,\n$R(F)\nR_w (F) \\leq \\sqrt{\\frac{2d_2(P||\\frac{P}{W}) \\log(1/\\delta)}{T}} < \\sqrt{\\frac{2\\log(1/\\delta)}{(a+1)T}} = B_w.$\nTo show that IW empirical risk $R_w(F)$ gives a tighter generalization bound than empirical risk, it suffixes to prove that\n$d_2(P||\\frac{P}{W}) \\leq d_2(P||P) = 1$. Now we divide $d_2(P||\\frac{P}{W})$ that involves all possible data into K groups as follows\n$d_2(P|| \\frac{P}{W}) =  \\int \\frac{P(z,y)}{\\frac{P}{W}} d(z,y) = \\int \\frac{P(z,y)}{\\frac{P}{W}} \\sum_{k=1}^K I[(z, y) \\in D_k]  w(z,y)d(z,y)$\n$ = \\sum_{k=1}^K \\int \\frac{P(z, y)}{(\\frac{P}{W}) }\\cdot I[(z, y) \\in D_k] \\cdot w(z, y)d(z, y) =  \\sum_{k=1}^K \\int \\frac{P(z, y)}{(\\frac{P}{W})} \\cdot I[(z, y) \\in D_k] \\cdot w_k d(z,y) = \\sum_{k=1}^K P_k \\cdot w_k,$"}, {"title": "C Appendix: Additional Experimental Results", "content": ""}, {"title": "D Hyper-parameter Tuning", "content": "We employed the validation data to select the hyper-parameters for all deep neural network approaches (RCGNN, PG-RCGNN, RCGNN-CRL, RCGNN-CRL-IW). We selected a learning rate of 0.001, a weight decay of 0.0005, a hidden dimension of 256 for the predictive layers, and a dropout rate of 0.2."}]}