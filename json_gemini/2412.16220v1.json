{"title": "Cross-Attention Graph Neural Networks for Inferring Gene Regulatory Networks with Skewed Degree Distribution", "authors": ["Jiaqi Xiong", "Nan Yin", "Yifan Sun", "Haoyang Li", "Yingxu Wang", "Duo Ai", "Fang Pan", "Shiyang Liang"], "abstract": "Inferencing Gene Regulatory Networks (GRNs) from gene expression data is a pivotal challenge in systems biology, and several innovative computational methods have been introduced. However, most of these studies have not considered the skewed degree distribution of genes.Specifically, some genes may regulate multiple target genes while some genes may be regulated by multiple regulator genes. Such a skewed degree distribution issue significantly complicates the application of directed graph embedding methods. To tackle this issue, we propose the Cross-Attention Complex Dual Graph Embedding Model (XATGRN). Our XATGRN employs a cross-attention mechanism to effectively capture intricate gene interactions from gene expression profiles. Additionally, it uses a Dual Complex Graph Embedding approach to manage the skewed degree distribution, thereby ensuring precise prediction of regulatory relationships and their directionality. Our model consistently outperforms existing state-of-the-art methods across various datasets, underscoring its efficacy in elucidating complex gene regulatory mechanisms.", "sections": [{"title": "Introduction", "content": "Cells execute diverse functions by expressing various genes and through the interplay of regulatory relationships among these genes. Bulk sequencing [1] enables the profiling of gene expression within specific tissues. From such gene expression matrices, researchers can extract a Gene Regulator Network (GRN). GRNs are crucial in different biological processes; they can aid in studying developmental biology, unraveling the mechanisms behind various diseases, and identifying new therapeutic targets [2, 3, 4, 5].\nAlthough numerous databases have accumulated extensive regulatory relationships, each tissue's GRN reveals its unique regulatory characteristics [6, 7, 8]. Hence, it is impractical to validate the specific GRN regulatory network in each tissue solely through wet experiments. Many researchers have proposed computational methods for bulk sequencing GRN inference. Prior to the prevalent of deep learning models, researchers proposed various GRN inference methods based on conventional machine learning and statistical approaches, including correlation-based methods [9], Bayesian network- based methods [10, 11], and hybrid methods [12, 13]. In recent years, with the accumulation of sequencing data [14, 15] and the development of deep learning technology, numerous deep learning-based bulk GRN inference methods have emerged. For instance, the CNNGRN [16] model utilizes a convolutional neural network to reconstruct gene regulatory networks from large-scale gene expression data. This CNNGRN model leverages known gene regulatory networks as prior knowledge to capture gene neighborhood information, and incorporates it as network structural features to enhance the predictive power over gene-gene relations. This improvement is particularly effective in inferring gene regulatory networks in real species.\nAlthough effective, CNN-based approaches are not naturally designed for tackling data in non-euclidean space. Hence, more recent models aim to incorporate graph-based methods. GRGNN [17] was the first to introduce Graph Neural Networks (GNNs) [18, 19, 20, 21] into GRN research. It"}, {"title": "Methods", "content": ""}, {"title": "Problem Definition", "content": "In Gene Regulatory Networks (GRNs), regulator genes R interact with target genes T to control cellular processes. These interactions can be activating, when the regulator enhances the target's expression, or repressing, when it decreases the expression. The regulatory relationships are directional, flowing from the regulator gene R to the target gene T. We represent these relationships as directed edges $e_{RT}$. The goal is to predict the type of regulation $F_{RT}$ between regulator gene R and target gene T, which can be activation, repression, or non-regulated."}, {"title": "Overview of the XATGRN", "content": "Our Cross-Attention Complex Dual Graph Embedding Model (XATGRN) is designed to infer the regulation types for Gene Regulatory Networks (GRNs). In particular, our XATGRN can distinguish between the activation type and repression type. Our model operates by treating the GRN inference problem as the link prediction task between regulator genes R and target genes T. As shown in Figure 1, our model extracts key features from both bulk gene expression data and existing databases that detail prior regulatory associations with regulation types, refining this features through a softmax classifier to predict the regulatory relationships as either activation, repression, or non-regulated interactions.\nInitially, the gene expression profiles of regulator-target gene pairs (R, T) are used by the fusion module (Figure 1a), yielding the fusion embedding vector. This vector encapsulates the gene expression features and the correlation information between the regulator and target genes. Subsequently, our Relation Graph Embedding Module The complex embeddings capture both the connectivity and directionality within the network.\nUltimately, the fusion embedding, along with the complex embeddings of regulator gene R and target gene T, are"}, {"title": "Fusion Module", "content": "Our Fusion Module extracts gene expression features from both the regulator gene R and the target gene T. This module captures the interactions between the gene pair (R, T), which are essential for predicting regulatory mechanisms within gene regulatory networks (GRNs), as shown in Figure 1a.\nTo address the shortcomings of conventional one-dimensional CNNs used by DeepFGRN [25], we introduce the Fusion Module. This module is based on the Cross-Attention Network (CAN), inspired by FusionDTI [28]. In particular, CAN enables our model to focus on the most relevant aspects of the gene expressions, which significantly improves its capacity to extract meaningful representations.\nThe gene expression data for the regulator gene R and the target gene T are processed to generate queries, keys, and values for the cross-attention mechanism, denoted as $Y_R$ and $Y_T$, respectively. The queries, keys, and values for gene R are represented as $Q_R$, $K_R$, $V_R$ and for gene T as $Q_T$, $K_T$, $V_T$. The projection matrices $W_R^Q$, $W_R^K$, $W_R^V$ and $W_T^Q$, $W_T^K$,$W_T^V$ map the gene data into the corresponding representations. Specifically, those matrices are defined as follows:\n$Q_R=Y_RW_R^Q$, $K_R = Y_RW_R^K$, $V_R = Y_RW_R^V$, (1)\n$Q_T = Y_TW_T^Q$, $K_T = Y_TW_T^K$, $V_T = Y_TW_T^V$. (2)\nMulti-head self-attention and cross-attention mechanisms are subsequently applied. Notably, each gene retains half of its original self-attention embedding and half of its cross- attention embedding, which allows the model to better handle the intrinsic features of each gene while capturing the complex interactions between them. These embeddings encapsulate the intricate regulatory interactions, thereby enhancing our model's capacity to discern the relationship between the genes.\nThe embeddings from both the regulator and target genes are then concatenated to form a combined embedding. Such a combined embedding is processed to produce the correlation embedding, which represents the regulatory relationship between the gene pair (R, T).\nThe fusion module and the subsequent steps are defined by the following equations:\n$R^* = \\frac{1}{2}[MHA(Q_R, K_R, V_R) + MHA (Q_T, K_R, V_R)]$,(3)\n$T^* = \\frac{1}{2}[MHA (Q_T, K_T, V_T) + MHA (Q_R, K_T, V_T)]$, (4)\n$F_{fusion} = Concat ((MeanPool(R^*), MeanPool(T^*)),1)$, (5)\nwhere the embeddings $R^*$ and $T^*$ represent the enhanced representations of the regulator and target genes, respectively. Specifically, $R^*$ integrates information from both the regulator's self-attention and the cross-attention with the target, while $T^*$ integrates information from both the target's self-attention and the cross-attention with the regulator. The mean pooling operation is denoted by MeanPool, and the concatenation operation is denoted by Concat. The final fusion embedding $F_{(R,T)}^{fusion}$ represents the regulatory relationship between the regulator and target genes."}, {"title": "Relation Graph Embedding Module", "content": "The Relation Graph Embedding Module addresses the complexity of representing nodes within Gene Regulatory Networks (GRNs). It handles the challenges posed by high- dimensional, sparse, and directed interactions. Specifically, it leverages the skewed degree of genes, which is crucial for differentiating between regulator and target nodes in GRNs.\nTo effectively embed the nodes in a GRN, we adopt the Complex Dual Graph Embedding approach from the DUPLEX framework [26]. As shown in Figure 1b, this approach generates amplitude and phase embeddings for both regulator and target genes, which encode both the connectivity and directionality of the regulatory interactions.\nWe model a directed graph (digraph) G = (V, E), where V represents the nodes and E represents the directed edges. Each edge (R,T) \u2208 E symbolizes a regulatory link from the regulator gene R to the target gene T. Here, R and T are specific instances of genes u in the graph, where R acts as a regulator and T as a target in the regulatory relationship. Our objective is to map each gene u to a d-dimensional vector $x_u \\in C^{d\\times 1}$.\nTo represent the directionality and connectivity of edges in GRN, our XATGRN leverage the the Hermitian Adjacency Matrix (HAM). This approach is particularly effective to address the challenge of asymmetric digraphs in GRNs. We use H to denote the HAM, which is defined in polar form as:\n$H = A_s \\exp(i\u0398)$, (6)\nwhere i is the imaginary unit and $\\odot$ represents the Hadamard product. The symmetric binary matrix $A_s$ is defined as:\n$A_s (u, v) =\n\\begin{cases}\n1 \\text{ if } (u, v) \\in E \\text{ or } (v, u) \\in E, \\\\\n0 \\text{ otherwise}.\n\\end{cases}$ (7)\nThe antisymmetric matrix $\\Theta$ contains elements from the set {-1,0,1} defined as:\n$\\Theta (u, v) =\n\\begin{cases}\n1 \\text{ if } (u, v) \\in E, \\\\\n-1 \\text{ if } (v, u) \\in E, \\\\\n0 \\text{ otherwise}.\n\\end{cases}$ (8)\nHence, the HAM's entries H(u,v), taking values in the set {i, -i, 1, 0}, effectively capture the relationships in GRNs, representing four different types of status between u and v including forward, reverse, bidirectional interactions and non-existing. This representation is particularly suited to GRNs, where regulatory interactions can be both directional and varied in nature. In contrast, the traditional asymmetric adjacency matrix A necessitates separate entries for A(u, v) and A(v, u), each restricted to {0, 1}, to encode the same diversity of relationships. The HAM's ability to integrate directionality and connectivity in a single, symmetric matrix offers a more comprehensive and efficient representation, aligning perfectly with the intricate patterns observed in GRNs.\nFurthermore, the matrix decomposition $H = X^T\\overline{X}$, where X is the node embedding matrix, represents the inner product between X and its complex conjugate $\\overline{X}$. This decomposition facilitates the expression of the node embedding $x_u$ in polar"}, {"title": "", "content": "form. Specifically, the embedding is written as follows:\n$x_u = a_u \\exp(i\\frac{\\pi}{2}\u03b8_u)$, (9)\n$\\overline{x_u} = a_u \\exp(-i\\frac{\\pi}{2}\u03b8_u)$. (10)\nwhere $a_u$ represents the amplitude and $\u03b8_u$ the phase of the embedding $x_u$. These complex conjugate embeddings $x_u$ and $\\overline{x_u}$ are interpreted as the representations of the regulator and target roles of gene node u, respectively. This joint embedding strategy, in contrast to using separate embeddings for the regulator and target, enables co-optimized learning from both the incoming and outgoing edges of the node u. Such an approach effectively addresses the challenge of the imbalance between in-degrees and out-degrees, which can significantly affect the embedding quality of nodes within Gene Regulatory Networks (GRNs).\nDual GAT Encoder\nBased on HAM, we will introduce a dual encoder architecture that comprises an amplitude encoder, a phase encoder, and a fusion layer. The encoders refine node embeddings by aggregating information from both incoming and outgoing edges of nodeu, effectively addressing the issue of skewed degree distribution.\nThe amplitude encoder employs GAT to aggregate information from both incoming and outgoing edges for each node. This process captures the node's overall connectivity, ensuring that even nodes with varying in-degrees and out- degrees are embedded with high quality in the context of the network's topology:\n$a_u^{'} = ReLU(\\sum_{v \\in N(u)} \u03b1_{uv}^{(am)} \\cdot a_v)$. (11)\nwhere N(u) denotes the set of neighboring nodes connected to node u via either incoming or outgoing edges, $\u03b1_{uv}^{(am)}$ is the attention coefficient for amplitude embedding, and $a_u^{'}$ represents the updated amplitude embedding for node u.\nThe phase encoder captures the directionality of regulatory relationships by distinguishing between nodes acting as regulators and targets. The phase embedding is updated similarly using a direction-sensitive attention mechanism:\n$\u03b8_u^{'} = ReLU(\\sum_{v \\in N_{in}(u)} \u03b1_{uv}^{(ph)} \\cdot \u03b8_v + \\sum_{v \\in N_{out}(u)} \u03b1_{uv}^{(ph)} \\cdot \u03b8_v)$. (12)\nwhere $N_{in}(u)$ and $N_{out}(u)$ denote the sets of in-neighbors and out-neighbors of node u, respectively, and $\u03b1_{uv}^{(ph)}$ is the attention coefficient for phase embeddings.\nThe fusion layer is a critical component that combines the amplitude and phase embeddings, which carry distinct yet complementary information. This layer ensures that the embeddings from both encoders are effectively integrated to capture the comprehensive regulatory interactions within the GRN. The fusion process is designed to balance the contributions from both the amplitude and phase embeddings, thereby enhancing the model's ability to represent complex gene interactions accurately.\nThe fusion layer operates by combining the information from the amplitude and phase embeddings at each layer of the encoder. This is achieved through a weighted aggregation"}, {"title": "", "content": "mechanism, where the attention coefficients dictate the strength of the information exchange between the two types of embeddings. Mathematically, the fusion process for the amplitude embeddings can be formulated as:\n$F_u^{am} = ReLU(\\sum_{v \\in N(u)} \u03b1_{uv}^{(am)} \\cdot a_v^{'} + \\sum_{v \\in N(u)} \u03b1_{uv}^{(ph)} \\cdot \u03b8_v)$. (13)\nwhere $F_u^{am}$ represents the updated amplitude embedding for node u, $\u03b1_{uv}^{(am)}$ and $\u03b1_{uv}^{(ph)}$ are the attention coefficients for amplitude and phase embeddings, respectively.\nSimilarly, for the phase embeddings, the fusion process is:\n$F_u^{ph} = ReLU(\\sum_{v \\in N(u)} \u03b1_{uv}^{(ph)} \\cdot \u03b8_v^{'} + \\sum_{v \\in N(u)} \u03b1_{uv}^{(am)} \\cdot a_v)$. (14)\nwhere $F_u^{ph}$ represents the updated phase embedding for node u.\nDual Decoders and Loss Functions\nAfter obtaining the embedding features for each gene node, we introduce 2 parameter-free decoders to reconstruct the Hermitian Adjacency Matrix (HAM) These decoders are designed to ensure that the embeddings capture both the connectivity and directionality of the regulatory interactions within the GRN.\nThe direction-aware decoder aims to reconstruct the directionality of regulatory interactions. This task is formulated as a classification problem in GRN, where each edge (u, v) is assigned probabilities that correspond to its edge type (forward, reverse, bidirectional, or no edge). The predicted edge type is determined by the minimum distance between the estimated matrix element $\u0124(u, v)$ and the possible edge types r:\npred. type = argmin (Dist($\u0124(u, v), r$)), $\\forall r \\in R$, (15)\nwhere Dist($\u0124(u, v), r$) is the distance between $\u0124(u, v)$ and r. and R = {i, -i, 1,0} represents the four possible status of edge types.\nThe probabilities P($\u0124(u, v) = r$) are calculated as follows:\nP($\u0124(u, v) = r$) = $\\frac{exp(-||\u0124(u, v) - r||)}{\\sum_{r' \\in R} exp(-||\u0124(u, v) - r'||)}$, $\\forall r \\in R$. (16)\nThe self-supervised direction-aware loss is then defined as:\n$L_d = - \\sum_{r \\in R} \\sum_{\u0124(u,v)=r} log P(\u0124(u, v) = r)$. (17)\nThe connection-aware decoder is designed to reconstruct the binary presence of connections between genes, which are encoded in the amplitude embeddings. It models the connection probability for an edge (u, v) as:\nP($\u00c2_s (u, v) = 1$) = $\u03c3(\u03b1_u a_v)$, (18)\nwhere o is the sigmoid function and \u00c2s is the estimated connection matrix, and As represent the probability that a connection exists between genes u and v, allowing the model to capture uncertainty in the network structure. The"}, {"title": "", "content": "connection-aware loss function $L_c$ adheres to the same negative log-likelihood minimization principle as the direction-aware loss:\n$L_c = - \\sum_{\u03ba,\u03c5}log P(A_s (u, v) = A_s(u, v))$. (19)\nThe total loss function combines the direction-aware and connection-aware losses to ensure that the model learns both the connectivity and directionality of the regulatory interactions. The total loss is given by:\n$L_{total} = L_d + \u03bb L_c$, (20)\nwhere \u03bb is a hyperparameter that controls the weight of the connection-aware loss.\nBy leveraging the fusion module and the Relation Graph Embedding Module, our XATGRN can effectively capture the connectivity and directionality of regulatory interactions within the network and alleviate the issue due to skewed degree distribution in GRNs.\nPrediction Module\nThe prediction module in our model is designed to leverage the embeddings generated by the Fusion Module and the Relation Graph Embedding Module to make accurate predictions about the regulatory relationships within the Gene Regulatory Network (GRN). As shown in Figure 1c, This module integrates the complex embeddings of genes and employs a series of neural network layers to classify the interactions between gene pairs (R, T).\nFor each sample, the module processes the feature and label data for a gene pair (R, T), where R is the regulator gene and T is the target gene. The features from the Fusion Module are denoted as $F_{fusion}$, while the features from the Relation Graph Embedding Module include the amplitude and phase embeddings for both genes: $F_R^{am}$, $F_T^{am}$, $F_R^{ph}$, and $F_T^{ph}$.\nThese embeddings are concatenated to form a comprehensive feature vector:\n$F = concat(F_{fusion}, F_R^{am}, F_T^{am}, F_R^{ph}, F_T^{ph})$. (21)\nThe concatenated feature vector F is first processed through a 1-dimensional convolutional layer with batch normalization (BN) and max pooling, followed by ReLU activation to extract and refine spatial features:\n$x1 = ReLU(MaxPool(BN(Conv1D(F))))$, (22)\nwhere the output is x1, and the vector x1 is pass to the global average pooling layer:\n$x2= GlobalAvgPool(x1)$, (23)\nwhere the resulting vector is denoted as x2. This step condenses the feature map into a fixed-size vector that captures the essential information for classification.\nSubsequently, the flattened vector x2 is passed through two fully connected layers (FC1 and FC2) with dropout for regularization, where a dropout rate of p = 0.3 is applied:"}, {"title": "", "content": "$X3 = FC2 (Dropout (ReLU (FC1 (x2)), p = 0.3))$, (24)\nwhere x3 represents the output of the second fully connected layer, and 23 is then passed through a softmax function to produce the final classification probabilities over C classes:\noutput = softmax(x3) (25)\nTo address class imbalance, we employ a weighted cross- entropy loss function L. The weights wc for each class care inversely proportional to their frequency in the dataset:\n$Wc = \\frac{N_{total}}{N_c}$ (26)\nwhere Ntotal is the total number of samples in the dataset, and Ne is the number of samples in class c.\nThe loss function L is then defined as:\n$L= - \\sum_{c=1}^{C} w_c Y_c.log(\u0177_c)$, (27)\nwhere yc is the true label for class c, and \u0177e is the predicted probability for class c.\nOur model optimizes this loss function using the Adam optimizer, with an exponential learning rate scheduler to ensure stable and efficient convergence."}, {"title": "Dataset and Experiment", "content": ""}, {"title": "Datasets", "content": "To examine the performance of our XATGRN model, we use the FGRN benchmark, which is introduced in the DeepFGRN [25]. The benchmark collects bulk gene expression data and prior regulatory gene pairs with regulation types across 9 distinct datasets. These datasets include the DREAM5 challenge network1, E.coli under 4 different stress conditions (cold, heat, lactose, and oxidative stress), and 4 types of human diseases (Covid-19, breast cancer, lung cancer, and liver cancer). These datasets are particularly relevant for studying disease mechanisms from a gene regulatory perspective due to their significant implications in understanding disease pathology.\nTo illustrate the skewed degree distribution in these datasets, we provide a visualization of the in-degree and out- degree distributions for the DREAM5, Human, and E.coli datasets (Figure 2). This visualization highlights the significant variation in the number of incoming and outgoing edges for different genes, a characteristic that poses a challenge for traditional graph embedding methods."}, {"title": "Experiment Setting", "content": "To better evaluate the performance of the model, we adapt the 10 times of the 5-fold cross-validation. For each fold, we calculate the mean of Area Under the Receiver Operating Characteristic curve (AUC), precision, recall, and Fl-score. These metrics provide a comprehensive assessment of the model's ability to accurately predict both the presence and type of regulatory interactions within gene networks. For Fusion module, we use pytorch for implement. we employed the Adam optimizer with a learning rate of 0.001 to update the model parameters during training. For Relation Graph Embedding Module, we use DGL library and Pytorch for implementation. with a learning rate of 1e-3. We set the hidden dim to 128 and the dropout rate to 0.5. We select the optimal hyperparaneter for initial loss weight A in 0.1,0.3 and the decay rate q in 0,1e-4,1e-2. To demonstrate the effectiveness of our model, we compare XATGRN with state-of-the-art GRN inference models, including CNNGRN [29], DGCGRN [30], and DeepFGRN [3]."}, {"title": "Experiment Result", "content": "As shown in Table 1 and Figure 3, our XATGRN model consistently outperforms state-of-the-art models across all datasets. In particular, CNNGRN focuses on extracting and reconstructing features from bulk gene expression data but disregards the original structure of the gene regulatory network (GRN). While DGCGRN and DeepFGRN construct directed graph embeddings for GRN inference, they fail to address the challenge posed by skewed degree distributions, which can lead to suboptimal performance, particularly for genes with significant disparities between in-degree and out-degree variances. Our XATGRN achieves the highest AUC, recall, F1-score, and precision across the DREAM5 network1 and all four E.coli datasets. These results demonstrate that XATGRN effectively captures the complex regulatory interactions within gene networks and accurately predicts both the presence and types of regulatory relationships. Notably, XATGRN's robust performance highlights its ability to handle the skewed degree challenge more effectively compared to DeepFGRN and DGCGRN. However, it is worth noting that in certain cases, such as the human COVID-19, breast cancer, and lung cancer datasets, the recall of XATGRN is slightly lower than that of DeepFGRN. This observation indicates that it may be necessary for such complex datasets to strike a better balance between addressing the skewed degree problem and optimizing source-target embeddings. In conclusion, our XATGRN model constantly and consistently outperform competitive baselines for inferencing GRNs from different types of gene expression data."}, {"title": "Ablation Study", "content": "To evaluate the contribution of each module in the XATGRN model, we conducted an ablation study by systematically varying the inclusion of key components. The study was performed on three datasets: DREAM5 Network1, E.coli cold stress, and the Human COVID-19 dataset. We compared three different setups to assess the impact of the Fusion Module and the Relation Graph Embedding Module on the model's performance. Specifically, these setups included a full XATGRN model with both modules, a model with only the Relation Graph Embedding Module, and a model with only the Fusion Module.\nThe full XATGRN model, which includes both the Fusion Module and the Relation Graph Embedding Module, achieved the highest performance across all metrics. This configuration effectively captures the complex interactions within the Gene Regulatory Network (GRN), handling the skewed degree distribution of genes while preserving accuracy and robustness.\nWhen only the Relation Graph Embedding Module was included, the model's performance dropped slightly. These reductions highlight the importance of the Fusion Module in enhancing the model's discriminative power. By focusing on the most relevant gene expression features and the"}, {"title": "Case study", "content": "To validate the biological significance of XATGRN, we reconstructed GRN using brest cancer data and employed in-depth analysis including prediction of biomarkers and enrichment analysis of potential therapeutic drugs. The constructed breast cancer GRN contains 2,478 genes and 8,772 relationships. After reconstructing GRN, we selected ten hub genes with the highest degree (Figure 5).\nThe hub genes in Figure 5 have been fully validated through literature review. Both RELA and NFKB1 are important members of the nuclear factor kappa-B family. In breast cancer, the abnormal activation of the kappa-B signaling pathway is closely associated with the occurrence, development, invasion, and metastasis of tumors [31, 32]. SP1 is closely related to the staging, invasive potential, and survival rates of breast cancer, and high levels of SP1 often indicate poor prognosis for patients [33]. MYC is a key regulator of cell growth, proliferation, metabolism, differentiation, and apoptosis, and its deregulation contributes to breast cancer development and progression, associated with poor outcomes [34]. The transcription factor Jun is closely associated with metastasis and prognosis in breast cancer, acting as both a suppressor and oncogene [35]. TP53 mutation, frequently occurring in triple-negative breast cancer (TNBC), enhances the correlation between the high-MYC and low-TXNIP gene signature and death from breast cancer [36]. STAT3 plays a crucial role in the regulation of cancer hallmarks in breast cancer, including angiogenesis, metabolism, and invasion, and is involved in tamoxifen resistance [37]. The cytoplasmic localization of CDKN1A/p21 is predominantly associated with cancer, where it serves to promote tumorigenesis and inhibit apoptosis in breast cancer cell lines [38]. Hypoxia inducible factor-1a (HIF- 1a) is crucial in the regulation of cancer hallmarks in breast cancer, including angiogenesis, metabolism, and invasion [37]. Lastly, FOS is downregulated in breast cancer tissues and cells, and its overexpression restrains the malignant phenotypes of breast cancer cells [39]."}, {"title": "", "content": "Furthermore, we performed drug enrichment analysis on top ten hub genes of breast cancer predicted by XATGRN. Figure 6 shows the top 10 enriched potential drugs based on DsigDB obtained through hub genes. It has been confirmed that seven out of the 10 drugs in figure 6 may be used for the treatment of breast cancer. Capsaicin, known for its activation of the TRPV1 receptor, has shown potential in inhibiting breast cancer cell growth by inducing apoptosis [40]. Ritonavir, typically used"}, {"title": "Conclusion and Discussion", "content": "In this paper, we have introduced the Cross-Attention Complex Dual Graph Attention Network Embedding Model (XATGRN) for Gene Regulatory Network (GRN) inference. This model addresses several critical challenges in GRN prediction, including the accurate representation of gene regulatory interactions, the handling of skewed degree distributions, and the effective capture of complex gene-gene relationships. By incorporating a cross-attention mechanism, XATGRN enhances the model's ability to predict not only the presence of regulatory relationships but also their directionality and specific types such as activation or repression.\nOur results show that XATGRN consistently outperforms state-of-the-art models across multiple datasets. The cross- attention mechanism allows XATGRN to focus on the most relevant features from bulk gene expression data, while our relation graph embedding module effectively captures both connectivity and directionality within the GRN, even in the presence of imbalanced node degrees. This combination of strategies enables XATGRN to overcome the limitations of existing models, making it more robust and applicable in real-world biological contexts. The strong performance of XATGRN across diverse datasets emphasizes its robustness and generalizability, positioning it as a promising tool for exploring GRNs in a variety of biological contexts.\nExtensive experiments on benchmark datasets underscore the model's effectiveness in uncovering previously unknown regulatory mechanisms and its potential to identify novel therapeutic targets for complex diseases. Our XATGRN model provides a comprehensive and powerful framework for advancing our understanding of gene regulatory networks,"}, {"title": "", "content": "offering a valuable approach for both basic and applied biological research.\nIn conclusion, our XATGRN represents a significant step forward in GRN inference, providing a robust and accurate framework for studying gene regulatory mechanisms. By effectively managing skewed degree distributions and leveraging advanced attention mechanisms, XATGRN serves as a powerful tool for uncovering regulatory interactions and identifying potential therapeutic targets."}, {"title": "Key Points", "content": "We introduce Cross-Attention Complex Dual Graph Attention Network Embedding Model (XATGRN), an advanced computational model for inferencing Gene Regulatory Networks (GRNs).\nWe implement and evaluate XATGRN across 9 benchmark GRN datasets, with experimental results demonstrating its high effectiveness in capturing the complexity of gene regulation.\nWe design a unique Fusion Module and Relation Graph Embedding Module within XATGRN, which significantly mitigates the issue of skewed degree distribution and improves the model's performance in understanding gene interactions.\nWe conduct a case study on breast cancer using XATGRN, validating its practical application in predicting biomarkers and potential therapeutic drugs, and uncovering novel insights into disease mechanisms."}]}