{"title": "Self-Reasoning Assistant Learning for non-Abelian Gauge Fields Design", "authors": ["Jinyang Sun", "Xi Chen", "Xiumei Wang", "Dandan Zhu", "Xingping Zhou"], "abstract": "Non-Abelian braiding has attracted substantial attention because of its pivotal role in describing the exchange behaviour of anyons, in which the input and outcome of non-Abelian braiding are connected by a unitary matrix. Implementing braiding in a classical system can assist the experimental investigation of non-Abelian physics. However, the design of non-Abelian gauge fields faces numerous challenges stemmed from the intricate interplay of group structures, Lie algebra properties, representation theory, topology, and symmetry breaking. The extreme diversity makes it a powerful tool for the study of condensed matter physics. Whereas the widely used artificial intelligence with data-driven approaches has greatly promoted the development of physics, most works are limited on the data-to-data design. Here we propose a self-reasoning assistant learning framework capable of directly generating non-Abelian gauge fields. This framework utilizes the forward diffusion process to capture and reproduce the complex patterns and details inherent in the target distribution through continuous transformation. Then the reverse diffusion process is used to make the generated data closer to the distribution of the original situation. Thus, it owns strong self-reasoning capabilities, allowing to automatically discover the feature representation and capture more subtle relationships from the dataset. Moreover, the self-reasoning eliminates the need for manual feature engineering and simplifies the process of model building. Our framework offers a disruptive paradigm shift to parse complex physical processes, automatically uncovering patterns from massive datasets.", "sections": [{"title": "Result", "content": "Design of Non-Abelian Gauge Field Circuit Structure\nIn contrast to the commutative properties inherent in Abelian theories, non-Abelian theories exhibit captivating behaviors due to their non-commutative nature of operations. Specifically, we start with supposing there are two identical particles in a"}, {"title": null, "content": "two-dimensional space. Then the wave function can undergo arbitrary phase changes when one particle exchanges with the other particle in a counterclockwise manner:\n$\\psi(r_1,r_2) \\rightarrow e^{i\\theta}\\psi(r_1,r_2),$\nwhere $\\psi(r_1,r_2)$ is the original wave function, and $\\theta$ is the phase shift. As the second counterclockwise exchange may not necessarily return to the initial state, it will result in a non-trivial variation phase, as shown below:\n$\\psi(r_1,r_2) \\rightarrow e^{2i\\theta}\\psi(r_1,r_2),$\nwhere $\\theta = 0, \\pi$ correspond to bosons and fermions, respectively. Particles possessing alternative 'statistical angles' are referred to as anyons [34]. We refer to such particles as anyons with statistics $\\Theta$.\nWhen turning our attention to the general case of N particles, a more intricate braid-like structure emerges. The trajectories that transition these particles from their original positions $R_1, R_2, ..., R_N$ at time $t_i$ to their designated positions $R'_1, R'_2, ..., R'_N$ at time $t_f$ are intricately linked to the components of the braid group $B_N$. An element of the braid group can be visualized by imagining particle trajectories as world lines (or strings) in 2+1 dimensional spacetime, where these trajectories initiate from specific starting points and culminate at defined endpoints. The time direction is represented vertically, with the initial time at the bottom and the final time at the top, as depicted in Fig. 1(a-c). Through smooth deformations, an element of the N-particle braid group is defined as an equivalence class comprising such trajectories, where each trajectory represents a distinct path in the spacetime framework. To represent an element of the class, it is necessary to order the initial and final points along the lines of initial and final times. In drawing the trajectories, care must be taken to distinguish between one line crossing over another, which corresponds to clockwise or counterclockwise exchanges. At any intermediate time slice, there must be intersections with N lines, and these lines cannot 'turn back' to prevent the implied creation or annihilation of particles at intermediate stages. The multiplication of two elements in the braid group is simply the successive execution, and it is evident from the diagram that the order of multiplication matters, as the group is non-abelian, implying that multiplication is non-commutative.\nBraiding statistics are linked with high-dimensional representations, which will emerge in the set of degenerate states g when particles are fixed at positions. An"}, {"title": null, "content": "orthogonal basis $\\Psi_{\\alpha}$ with $\\alpha = 1, 2, ..., g$ is defined for these degenerate states. The elements of the braid group include $\\sigma_1$ and $\\sigma_2$. The $\\sigma_1$ exchanges particles 1 and 2, while the $\\sigma_2$ exchanges particles 2 and 3. The actions are represented by $g \\times g$ unitary matrices $\\rho(\\sigma_1)$ and $\\rho(\\sigma_2)$:\n$\\Psi_{\\alpha}\\rightarrow[\\rho(\\sigma_1)]_{\\alpha\\beta}\\Psi_{\\beta}, \\Psi_{\\alpha}\\rightarrow[\\rho(\\sigma_2)]_{\\alpha\\beta}\\Psi_{\\beta},$\nwhere both $[\\rho(\\sigma_1)]_{\\alpha\\beta}$ and $[\\rho(\\sigma_2)]_{\\alpha\\beta}$ are $g \\times g$ unitary matrices, defining unitary transformations within the subspace of degenerate ground states. If $\\rho(\\sigma_1)$ and $\\rho(\\sigma_2)$ do not commute, i.e., $[\\rho(\\sigma_1)]_{\\alpha\\beta}[\\rho(\\sigma_2)]_{\\beta\\gamma} \\neq [\\rho(\\sigma_2)]_{\\alpha\\beta}[\\rho(\\sigma_1)]_{\\beta\\gamma}$, the particles obey non-Abelian braid statistics. The braid statistics of particles remain Abelian state unless they commute for every particle exchange. Braided quasi-particles induce non-trivial rotations within the degenerate multi-quasi-particle Hilbert space, when they do not commute.\nIn systems possessing arbitrary sub particles, it is often necessary to consider multiple types of anyons. Fusion refers to the process of combining two anyons into a single particle entity. In the Abelian scenario, the fusion rules are straightforward [35]. For instance, $2\\pi n/m \\times 2\\pi k/m = 2\\pi(n+k)/m$, where the operation $a \\times b$ denotes the fusion of $a$ and $b$. However, there may not be a unique method to combine topological quantum numbers for non-Abelian anyons. For example, two particles each with a spin of 1/2 could be combined to form a particle with either spin 0 or spin 1. These different possibilities are known as distinct fusion channels, which is typically represented by [34]:\n$\\Phi_a \\times \\Phi_b = \\sum_c N^c_{ab}\\Phi_c,$\nwhere both $\\Phi_a$ and $\\Phi_b$ denote the fusion channels, and $N^c_{ab}$ represents the multiplicity of fusion. Such terminology clarifies that in non-Abelian anyon scenarios, fusion between particles of type a and type b might result in a particle of type c ($N^c_{ab} \\neq 0$).\nIn our work, we focus on exploring innovative approaches for developing complex and efficient circuit, guided by non-Abelian theoretical principles. This exploration occurs within the realm of circuit design, where understanding non-commutative theories is paramount. As in the field of circuit design, the principles of non-"}, {"title": null, "content": "commutative theory are crucial. The methods of coupling and the employed sequences play a pivotal role in shaping the behavior and functionality of non-Abelian circuits. And the choice of couplings, along with the sequence in which these couplings are applied, determines the emergent properties of the circuits as well.\nOur approach involves utilizing a circuit coupling module that implements non-Abelian tunneling in the form of Pauli matrices. We have explored a strategy that constructs a doubly degenerate space using basic electronic components and vector potentials of the Pauli matrix form. As shown in Fig. 1(e), we consider a configuration where three identical components (either capacitors or inductors) are connected at the heads in cell-m and cell-n to form a triangle, which exhibits $C_3$ rotational symmetry [11, 36]. For the $C_3$ unit, it possesses a two-dimensional irreducible representation, whose basis functions are complex conjugates of each other. Consequently, the circuit's doubly degenerate eigenstates can be selected as the basis for the pseudospin space. Our design commences with a chain circuit comprising four $C_3$ units, with detailed derivations provided in Appendix A."}, {"title": "Self-Reasoning Assistant Learning Framework", "content": "To facilitate the construction of non-Abelian circuits and the computation of their transfer functions, we have developed a series of non-Abelian circuit models that include four $C_3$ structures and three coupling modules. During data collection, it is stipulated that all coupling connections must be selected from Appendix C. Theoretically, the total number of circuit combinations is approximately 104 (calculated as the product of 48\u00d747\u00d746), with each coupling method occurring only once. To reduce computational complexity, we select 4,096 sets of circuit diagrams and structure information for dataset construction and model training. Our training dataset consists of circuits along with their transfer function data, including both the images and the structure information. The images show schematic diagrams of circuits with varying component values and coupling modes, while the accompanying structure information provide details on the transfer functions, input currents, and output voltages of these circuits."}, {"title": null, "content": "Subsequently, an appropriate network model is proposed for the circuit data. To address the complexity of the training dataset and meet on-demand design requirements, we introduce a text-to-image diffusion model that capitalizes on the large Transformer language model's text comprehension abilities [37]. Distinguishing itself from other language models, it allocates the training focus on the text encoder rather than on the image generation aspect, which equips itself with the ability for self-reasoning assistant learning. This feature is particularly beneficial for non-Abelian gauge fields design, facilitating the direct derivation of circuit design diagrams from input structure information. due to the extensive parameterization of T5, the framework can yield satisfactory outcomes even without fine-tuning."}, {"title": null, "content": "of 11 billion) [38], enabling the model to achieve a higher level of comprehension of the text we provide. The Cascaded Diffusion Model is further divided into two parts: the Base model and the Super-resolution model. The essence of the Base model is a typical 64 \u00d7 64 U-Net structure, which can iteratively convert Gaussian noise into samples from the learned data distribution through a denoising process. Since Diffusion Models are latent variable models, their latent variable $z = {z_t | t \\in [0,1]}$ adheres to a forward process $q(z|x)$ that starts from the data $x \\sim p(x)$. Consequently, the forward process is a Gaussian process that satisfies Markovian structure [37]:\n$q(z_t|x) = N(z_t;\\alpha_tx,\\sigma_t^2I), q(z_t|z_s) = N(z_t;(\\alpha_t/\\alpha_s)z_s,\\sigma_{ts}^2I),$\nwhere $0\\leq s0, where N(0, I) denotes the Gaussian distribution with a mean of 0 and a variance of I. Another prominent feature of the Base model is the Classifier-Free Guidance, which is the substitution of an explicit classifier with an implicit one, thereby obviating the need for direct computation of the explicit classifier and its gradients. The classifier operates by randomly dropping the condition during the training process, allowing for both conditional and unconditional sampling inputs. Both types of inputs are fed into the same diffusion model, thus enabling it to possess the capability to generate both conditionally and unconditionally. And the final sampling process can be articulated as follows [37]:\n$\\varepsilon_{\\theta}(z_t, c) = \\omega\\varepsilon_{\\theta}(z_t, c)+(1-\\omega)\\varepsilon_{\\theta}(z_t),$\nwhere $\\varepsilon_{\\theta}(z_t, c)$ and $\\varepsilon_{\\theta}(z_t)$ respectively represent the conditional and unconditional predictions, $\\theta$ is the guidance weight. For the Super-resolution model, we initially process the 64 \u00d7 64 images generated by the Base model through an efficient U-Net to upscale them to a size of 256 \u00d7 256, as detailed in Fig. 2. Subsequently, another efficient U-Net receives the complete 256 \u00d7 256 image as low-resolution input and returns an up sampled 1024 \u00d7 1024 image as the final output. This approach directly enhances efficiency while, through the augmentation of noise, it improves the model's robustness in controlling distortions. After ample training, our network ultimately acquires the capability to stably generate circuit diagrams based on input structure information,"}, {"title": null, "content": "showcasing its proficiency in self-reasoning capabilities.\nTo verify the reliability and accuracy of the model, we input 500 datasets and have the model generate circuit diagrams that meet the requirements. Subsequent theoretical calculations and statistical validation show that 387 of the generated circuit diagrams are entirely correct, 79 diagrams have minor errors with fewer than five incorrect connections, and only 34 diagrams exhibit more significant errors. We opt for this direct evaluation approach because circuit design diagrams are either correct or incorrect, with no gray area. Therefore, comparing predicted diagrams directly with theoretical ones is the most suitable method to assess accuracy. The absolute correctness rate has reached 77.4%, which indicates the favorable training outcomes and the effectiveness of our network model. Partial prediction results are illustrated in Fig. 3(a)."}, {"title": "Experimental Validation", "content": "Initially, we randomly supply circuit features to the model, including the transfer function coefficient vector, node connection components, and circuit configuration. Based on these characteristics, the model generates predicted circuit diagrams, as exemplified in Fig. 3(a). We select two representative examples from the structure information inputs used to generate circuit-m and circuit-n. For circuit-m, the inputs are: (1) transfer function coefficient vector [8.57e-18 + 7.06e-17i, 0.05 - 0.13i, 0.10 - 0.01i], and (2) node connection components 5C + 1.5R. For circuit-n, the inputs are: (1) transfer function coefficient vector [-3.44e-18 - 1.82e-17i, 0.06 + 0.02i, 0.06 + 0.02i], and (2) node connection components 5C + 2.5R. We construct circuit- m and -n on PCB boards for experimental verification, as depicted in Fig. 3(b). Besides, a constant input current $\\langle i^n_m \\rangle = (0.005\\angle 147^{\\circ},0.012\\angle -149^{\\circ},0.015\\angle 13^{\\circ})$ is maintained at cell-1, and the output voltages of cell-4 are measured. As illustrated in Fig. 3(c), the dots represent experimental data and lines indicate simulation results, which prove that the network-predicted circuits match the theoretical circuits, effectively meeting the design requirements.\nSubsequently, we examine three circuits comprised of cells-1, -2, -3, -4 and two connecting modules per unit, to explicitly characterize the non-reciprocal nature of non-Abelian gauge fields, shown in Fig. 4(a). It demonstrates the phase tuning of signals in real space in a non-Abelian manner. As the signal passes through the circuit, its pseudospin components are confined within this degenerate pseudospin space and acquire phase modulation in the form of a non-Abelian gauge field. For the same initial state $\\vec{i_0}$, passing through circuit-1, -2, and -3, different final states $\\vec{V_1}, \\vec{V_2}$ and $\\vec{V_3}$ can be obtained, as shown in Fig. 4(b). The detailed calculation processes of the transfer functions for circuits 1, 2, and 3 are presented in Appendix D.\nWe input the descriptive structure information corresponding to circuits 1, 2, and 3 into the model to predict the circuit models, with the predictions displayed in Fig. 4(c). To validate the predictions, we construct the predicted circuits 1, 2, and 3 on a PCB, as illustrated in Fig. 4(d). Alternating current is applied at three nodes of cell-1, and the output voltage is measured at the node of cell-4. We compare the predicted circuit diagrams with simulated theoretical ones, as depicted in Fig. 4(b). The result indicates a good match between the experimental and theoretical curves, with the DC component removed from the experimental results. The capacitor $C_0$ is 2.7 nF with a tolerance of \u00b120%. The resistor $R_0$ is 1 k\u03a9 with a tolerance of \u00b11%. The current"}, {"title": null, "content": "frequency is set at 15 kHz, generated by an OPA549 module. The output voltage is measured with a SIGLENT SDS2202X Plus oscilloscope. A detailed list of the experimental instruments is provided in Appendix E.\nTo compare with theoretical results, we exclude the DC components from the experimental data. The generation of DC errors mainly stems from that we provide current to three input ports in steps using a single current source. Due to the linear nature of the circuit, the total output voltage is the sum of the voltages measured in these three steps. However, this measurement method comes at the cost of relatively large cumulative errors. The DC component measurement will decrease when three current sources input simultaneously. Since the critical information in the experimental data involves the amplitude and phase of the AC components, the presence of DC components does not affect our conclusions. The experimental results indicate the successful training of our network model tailored for non-Abelian circuits, with its effectiveness and accuracy verified through simulation and experimentation."}, {"title": "Discussion", "content": "The presented framework constructs a low-dimensional latent space of non-Abelian gauge circuits, by self-reasoning assistant learning technologies. It is powered by an advanced Text Encoding using Transformer models to interpret and operationalize text-based inputs, which can iteratively convert Gaussian noise into samples from the learned data distribution through a denoising process. This process enables the framework to autonomously generate detailed circuit designs from descriptions, adapting to diverse and complex scenarios. Our framework can be adopted in the data-dependent scenarios which are difficult to describe with formulas and extended to other physical fields such as optics, acoustics, mechanics. With the advancement in the interpretability of deep learning methods in relation to physics, we can leverage the tool to uncover deeper laws of the physical world."}]}