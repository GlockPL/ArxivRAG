{"title": "ICEDIFF: HIGH RESOLUTION AND HIGH-QUALITY SEA ICE\nFORECASTING WITH GENERATIVE DIFFUSION PRIOR", "authors": ["Jingyi Xu", "Siwei Tu", "Weidong Yang", "Shuhao Li", "Keyi Liu", "Yeqi Luo", "Lipeng Ma", "Ben Fei", "Lei Bai"], "abstract": "Variation of Arctic sea ice has significant impacts on polar ecosystems, transporting routes, coastal\ncommunities, and global climate. Tracing the change of sea ice at a finer scale is paramount for\nboth operational applications and scientific studies. Recent pan-Arctic sea ice forecasting methods\nthat leverage advances in artificial intelligence has made promising progress over numerical models.\nHowever, forecasting sea ice at higher resolutions is still under-explored. To bridge the gap, we\npropose a two-staged deep learning framework, IceDiff, to forecast sea ice concentration at finer\nscales. IceDiff first leverages an independently trained vision transformer to generate coarse yet\nsuperior forecasting over previous methods at a regular 25km x 25km grid. This high-quality sea ice\nforecasting can be utilized as reliable guidance for the next stage. Subsequently, an unconditional\ndiffusion model pre-trained on sea ice concentration maps is utilized for sampling down-scaled sea\nice forecasting via a zero-shot guided sampling strategy and a patch-based method. For the first\ntime, IceDiff demonstrates sea ice forecasting with the 6.25km x 6.25km resolution. IceDiff extends\nthe boundary of existing sea ice forecasting models and more importantly, its capability to generate\nhigh-resolution sea ice concentration data is vital for pragmatic usages and research.", "sections": [{"title": "1 Introduction", "content": "Arctic sea ice is essential for global climate change and local communities. Although the exact teleconnections between\nmid-latitude weather and the variation of Arctic sea ice are yet to be revealed, the reduction of sea ice during the last\nfew decades clearly has impacts that transcend the Arctic region [Wang et al., 2019, Andersson et al., 2021]. Hence,\nestablishing skillful forecasting models is paramount for both transportation in polar regions and scientific research in\ngeoscience.\nExisting physics-based numerical models have demonstrated the ability to accurately forecast sea ice concentration\n(SIC, value ranges from 0% to 100%) for short lead times of a few weeks. However, when forecasting at longer scales,\ntheir performance significantly decreases, and their forecasting skills are even worse than those of simple statistical\nmodels [Andersson et al., 2021]. With the advent of deep learning methods and their showcased capability of handling\ncomplex visual and natural language data at large scale, a series of works based on deep learning approaches have\nbeen committed to SIC forecasting with promising results. Notable studies cover forecasting leads range from daily to\nseasonal scale, e.g., IceNet [Andersson et al., 2021] provides accurate sea ice extent (SIE, areas where the SIC value is\ngreater than 15% and could be covered with sea ice) forecasts for 6 months lead time. SICNet [Ren et al., 2022] and\nSICNet90 [Ren and Li, 2023] are skillful for forecasting SIC in subsequent 7 and 90 days, respectively. Despite the\nimproved forecasting skills of deep learning models over previous approaches, forecasting sea ice at finer scales, which\nis crucial, especially for operational applications, is still under-explored. SwinRDM [Chen et al., 2023] with similar\nintention has been proposed for weather forecasting. It combines an improved SwinRNN [Hu et al., 2023] model with\na denoising diffusion probabilistic model (DDPM) [Ho et al., 2020] to achieve super-resolution (SR) in forecasting\nclimate variables."}, {"title": "2 Related Works", "content": null}, {"title": "2.1 Deep Learning-based Sea Ice Forecasting", "content": "Deep learning models have drawn the attention of sea ice research communities and been widely investigated for Arctic\nsea ice forecasting [Petrou and Tian, 2019, Kim et al., 2020, Ali et al., 2021, Ali and Wang, 2022]. As a pioneering\nwork, ConvLSTM [Liu et al., 2021a] predicts SIC within the region of Barents Sea and has showcased comparable\nresults to the state-of-the-art numerical climate models. IceNet [Andersson et al., 2021] employs the U-Net architecture\nfor merging pre-selected ERA5 variables and SIC data to improve the accuracy of seasonal SIE prediction up to six\nmonths. The experimental results have shown that the forecasting skill of IceNet in pan-Arctic region is superior to the\nnumerical sea ice simulation model SEAS5. MT-IceNet [Ali and Wang, 2022] adopts similar approach of IceNet and\nadds bi-monthly data to further improve forecasting SIC at seasonal scale. Mu et al. [Mu et al., 2023] propose to merge\natmospheric and oceanographic in a weighted manner through a variable selection network and provide nine months of\nforecasting leads. Since SIC can be derived from SIC, SICNet [Ren et al., 2022] is proposed to solely rely on SIC data\nto predict concentration in the next seven days. Similar to IceNet, SICNet is built upon U-Net architecture and added\nwith channel-wise dependency via temporal-spatial attention module (TSAM), which is essentially a revised version of\nthe convolutional block attention module. By fusing the output of two SICNet, i.e. one for modeling SIC and the other\nfor extracting climate information, and adjusting the number of output channels, Ren et al. [Ren and Li, 2023] extends\nthe lead time to 90 days.\nBesides CNN and LSTM-based models, recent works leverage the latest advances in artificial intelligence to further\nimprove forecasting performance. For instance, IceFormer [Zheng et al., 2024] jointly models SIC and sea ice thickness\n(SIT) based on Transformer backbone. It first decomposes high dimensional spatio-temporal data into sequences via\nmultivariate empirical orthogonal functions [Sparnocchia et al., 2003, Shao et al., 2021]. Then an encoder-decoder\nTransformer is utilized to predict SIC and SIT for up to 45 days.\nDespite the performance gain of aforementioned deep learning models, non of them have addressed forecasting sea ice\nat scales lower than 25km."}, {"title": "2.2 Super Resolution", "content": "Super-resolution aims to reconstruct high-resolution (HR) images from low-resolution (LR) counterparts. For this\npurpose, several works [Liu et al., 2020a,b] explore the use of Variational Autoencoders for perceptual image super-\nresolution. These methods usually improve the restoration quality of image super-resolution by learning the conditional\ndistribution of high-resolution images induced by low-resolution images. Although these methods are able to achieve\nrealistic perceptual quality, VAE-based methods are often not as satisfactory due to their limited generation capabilities.\nTo this end, other deep learning methods, such as deep convolutional neural networks, have been widely used for\nsuper-resolution tasks in various domains. Convolutional neural networks (CNNs) based methods typically use HR\nimages corresponding to LR images to supervise training, which utilizes reconstruction loss to train CNNs. Zhou and\nSusstrunk [2019], Anwar et al. [2020] propose and optimize their CNN-based methods to tackle various super-resolution\ntasks, improving their generalization ability and robustness on real photos. However, the network trained solely on\nreconstruction loss makes it difficult to capture detailed information in images and generate diverse image results.\nTherefore, Generative Adversarial Networks (GANs) are proposed to solve these challenges. Leinonen et al [Leinonen\net al., 2020] introduced a recurrent, stochastic super-resolution GAN for down-scaling time-evolving atmospheric\nfields, demonstrating the potential of GANs in improving the spatial resolution of LR images in atmospheric sciences\napplications. These models encourage the generator to generate high-quality images that the discriminator cannot\ndistinguish from real images. Although GAN-based methods can attain satisfactory down-scaled results, the diversity\nof these methods could be enhanced.\nCurrently, diffusion model-based methods have been more widely used due to their diversity in generating images and\nthe ability to generate high-quality images comparable to GANs [Tu et al., 2024, Fei et al., 2023]. For instance, Chen et\nal. [Chen et al., 2023] utilize super-resolution based on the conditional model to recover the high spatial resolution and\nfiner-scale atmospheric details, unfolding the ability of diffusion models to generate high-quality and detailed images in\nsuper-resolution tasks.\nThe objective of this study is to forecast SIC maps at a high resolution of 6.25 km. To achieve this, we have improved\nthe SwinTransformer for predicting SIC at the standard resolution comparable to current methods. Additionally, we\nemploy a diffusion-based super-resolution model to generate high-resolution and high-quality results via zero-shot\nsampling."}, {"title": "3 Methodology", "content": "Our IceDiff framework comprises two components, i.e. the forecasting model (FM) and the guided diffusion module\n(GDM), as depicted in Figure 1. We elaborate on design details in the following sections."}, {"title": "3.1 Forecasting Model", "content": "Swin Transformer [Liu et al., 2021b] as a vision transformer backbone has been successfully adopted by various\ndata-driven weather forecasting methods [Chen et al., 2023, Zhang et al., 2014, Bi et al., 2023]. Inspired by their\nefforts and the verified effectiveness of TSAM [Ren et al., 2022], we propose to construct FM by utilizing the U-Net\narchitecture [Cao et al., 2022] and building on top of the Swin Transformer V2 backbone [Liu et al., 2022] with\nResNetTSAM block [Ren et al., 2022] for better capturing both spatial and temporal features of SIC. As illustrated in\nFigure. 1, the FM consists of encoder, bottleneck and decoder. For the patch embedding layer, it first applies a 2 x 2\nwindows size to partition the original SIC input into patches and maps them into tokens via 2D convolution. Then, the\ntemporal and spatial dependencies are modeled through the ResNetTSAM block. Both the encoder and the decoder has\n3 layers of Swin Transformers that comprises of pre-configured even number of Swin Transformer Blocks for feature\nextraction and restoration. The calculation of two consecutive blocks can be described as follows:\nzb' = LN(WMSA(zb\u22121)) + zb\u22121, \nzb = LN(MLP(zb')) + zb', \nzb+1' = LN(SWMSA(z6')) + z6', \nz6+1 = LN(MLP(z6+1')) + z6',\n(1)"}, {"title": "3.2 Exploiting Generative Diffusion Prior for High-resolution SIC Maps via Zero-shot Sampling", "content": "In this section, we exploit a down-scaling component based on an unconditional diffusion model pre-trained on\nSIC maps to generate realistic high-resolution SIC maps with rich details. Off-the-shelf methods are limited to the\nforecasting of SIC maps at a scale of 25km. However, small-scale SIC maps remain unexplored which is of significant\nvalue to ecosystems, transporting routes, coastal communities and global climate. Our IceDiff-GDM down-scales the\nSIC forecasts by IceDiff-FM to a scale of 6.25km, further expanding the accuracy and practicality of sea ice prediction.\nSpecifically, the reverse process of the diffusion model is conditioned on the low-resolution sea ice map y, which\ntransforms distribution $p_\\theta(x_{t-1}|x_t)$ into conditional distribution $p_\\theta(x_{t-1}|x_t, y)$. Previous work [Dhariwal and Nichol,\n2021] have derived the conditional transformation formula in the reverse process:\n$\\log p_\\theta(x_t|x_{t+1}, y) = \\log (p_\\theta(x_t|x_{t+1})p(y|x_t)) + N_1$,\n$ \\approx \\log p_\\theta (z) + N_2 \\ \\ z \\sim \\mathcal{N}(z; \\mu_\\theta(x_t, t) + \\Sigma g, \\Sigma_I)$, \n(3)\nwhere g refers to $ \\nabla_{x_t} \\log p(y|x_t)$. $N_1 = \\log p_\\theta(y|x_{t+1})$, $N_2$ is a constant related to g (proof in Appendix). The variance\nof the reverse process $\\Sigma = \\Sigma_\\theta(x_t)$ is constant.\nTherefore, sampling process of $p_\\theta(x_{t-1}|x_t, y)$ integrates the gradient term g with the diffusion model $(\\mu, \\Sigma) = (\\mu_\\theta(x_t), \\Sigma_\\theta(x_t))$, which plays a role in controlling the direction of map generation. We use a heuristic algorithm to\napproximate the value of g:\n$\\log p(y | x_t) = - \\log N - sL(D(x_0), y)$\n$g = \\nabla_{x_t} \\log p(y|x_t) = -s \\nabla_{x_t} L(D(x_t),y)$.\nAmong them, s is the scaling factor used to control the degree of guidance, and K is the normalization factor, which\nis the constant $p_\\theta(y|x_{t+1})$. And L is a distance function used to measure the distance deviation between two maps.\nD is an up-scale convolution function with optimizable parameters, where the parameters dynamically optimized\nwith the gradient of distance function at every reverse step. D connects two different resolution SIC maps, allowing\nlow-resolution SIC maps to provide more effective guidance.\nAs shown in Algorithm 1, GDM undergoes T reverse steps to gradually restore pure Gaussian noise $x_T \\sim \\mathcal{N}(0, I)$\nto high-resolution SIC maps. In each reverse step t, the diffusion model calculates the instantaneous estimated value"}, {"title": "4 Experiments", "content": null}, {"title": "4.1 Dataset and Baseline Setup", "content": "We evaluate our proposed IceDiff framework on the G02202 Version 4 dataset from the National Snow and Ice Data\nCenter (NSIDC). It records daily SIC data starting from October 25th 1978 and provides the coverage of the pan-Arctic\nregion (N:-39.36\u00b0, S:-89.84\u00b0, E:180\u00b0, W:-180\u00b0). The SIC map is formed of 448 x 304 pixels and each of which\nrepresents an area of 25km x 25km grid and has a value ranging from 0% to 100%. We choose data from October 25th\n1978 to 2013 as the training dataset, the years 2014 and 2015 are selected as validation set, and data from 2016 to 2023\nare used for testing. IceDiff-FM is trained on three different temporal scales, i.e. the input of SIC maps are 7 days, 8\nweeks average and 6 months average, covering forecasting leads from subseasonal to seasonal scale. Corresponding"}, {"title": "4.2 Implementation Details", "content": "We independently trained IceDiff-FM on SIC dataset of three aforementioned temporal scales for 60 epochs. For each\ntemporal scale, IceDiff-FM outputs the same length of input data as forecasting leads, i.e. 7 days, 8 weeks average, and\n6 months averages. The dimensions of embedding features of encoder, decoder, and bottleneck are all set to 32. We"}, {"title": "4.3 Evaluation Metrics", "content": "To evaluate IceDiff-FM, we select commonly used root mean square error (RMSE) and mean absolute error (MAE) for\ncomparison of forecasting accuracy. We also leverage $R^2$ score to evaluate the performance:\n$R^2 = 1- \\frac{RSS}{TSS}$\nwhere RSS represents the sum of squares of residuals and TSS denotes the total sum of squares. The Integrated\nIce-Edge Error score [Goessling et al., 2016] is introduced to evaluate the SIE (where the SIC value is greater than\n15%) prediction:\nIIEE = O + U,\nO = SUM(Max(SIEp \u2013 SIEt, 0)),\nU = SUM(Max(SIEt \u2013 SIEp, 0)),\nS I E P , S I E t = \\{\n1, SIC > 15\n0, SIC < 15\nwhere O and U represent the overestimated and underestimated SIE between the prediction (SIEp) and the ground\ntruth (SIEt), respectively. The difference between the forecasted and ground truth sea ice area (in millions of km\u00b2) is\ncalculated as follows:\n$SIEdif= \\frac{SUM(|SIEp - SIEt|) \\times 25 \\times 25}{1000000}$\nWe also adopt the Nash-Sutcliffe Efficiency [Nash and Sutcliffe, 1970] to further evaluate the predicted quality:\n$NSE = 1 \u2013 \\frac{SUM((SICt \u2013 SICp)^2)}{SUM((SICt - Mean(SICt))^2)}$\nAs to the evaluation of down-scaling quality, we utilize the Fr\u00e9chet Inception Distance (FID) [Heusel et al., 2017] and\nConsistency for comparison. In addition, we adopt Consistency to quantify the faithfulness between the generated map\nand the low-resolution map."}, {"title": "4.4 Main Results", "content": "In this subsection, we evaluate the proposed IceDiff with baseline methods for validation of the effectiveness.\nFM sets up new baselines for SIC prediction IceDiff-FM is trained independently to predict SIC at 7 days, 8 weeks\naverage, and 6 months average. As shown in Table 1, the performance of our proposed FM is superior to SICNet in all\nevaluation metrics. Although performance figures reported by other subseasonal and seasonal baseline methods may\nvary when using identical SIC datasets and training-validation-test split, our FM could provide competitive forecasts\nand sufficiently support down-scaling process."}, {"title": "4.5 Ablation Studies on Design of FM", "content": "As shown in Table 3, by adopting TSAM to FM, the performance has improved for all metrics at 7 days and 6 months\naverage lead times while the effects for 8 weeks average lead time are not all positive. Overall, incorporating TSAM to\nestablish channel-wise dependency is favorable for SIC forecast models. To examine the impacts of input SIC data\nlength, we trained FM for input lengths of half, double, and equal to the forecasting leads. The results in Table 4 show\nthe peak of the performance at the ratio where the input length equals the forecasting leads."}, {"title": "5 Conclusion", "content": "We propose a novel pan-Arctic SIC forecasting framework, IceDiff, which comprises IceDiff-FM and IceDiff-GDM,\nthe former is capable of producing accurate forecasts at three different temporal scales and the latter leverages reliable\nforecasts as guidance to generate high-quality down-scaled SIC maps. The forecasting skills of IceDiff-FM at 7 days\nlead are superior to SOTA deep learning-based models. IceDiff-FM also sets up a new baseline for weekly average\nforecasting of 8 weeks and provides competitive results in seasonal SIC forecasts. To the best of our knowledge,\nIceDiff is the first attempt to forecast SIC at 6.25km spatial scale which is a quarter of the grid size (25km) that current\nmethods performs on. The experimental results show that our framework can generate down-scaled SIC superior to\noff-the-shelf methods and it is vital for pushing forecasting models towards operational usage and further promotes sea\nice researches."}]}