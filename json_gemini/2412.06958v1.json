{"title": "Enhancing operational wind downscaling capabilities over Canada: Application of a Conditional Wasserstein GAN methodology", "authors": ["Jorge Guevara", "Victor Nascimento", "Johannes Schmude", "Daniel Salles", "Simon Corbeil-L\u00e9tourneau", "Madalina Surcel", "Dominique Brunet"], "abstract": "Wind downscaling is essential for improving the spatial resolution of weather forecasts, particularly in operational Numerical Weather Prediction (NWP). This study advances wind downscaling by extending the DownGAN framework introduced by Annau et al. to operational datasets from the Global Deterministic Prediction System (GDPS) and High-Resolution Deterministic Prediction System (HRDPS), covering the entire Canadian domain. We enhance the model by incorporating high-resolution static covariates, such as HRDPS-derived topography, into a Conditional Wasserstein Generative Adversarial Network with Gradient Penalty, implemented using a UNET-based generator. Following the DownGAN framework, our methodology integrates low-resolution GDPS forecasts (15 km, 10-day horizon) and high-resolution HRDPS forecasts (2.5 km, 48-hour horizon) with Frequency Separation techniques adapted from computer vision. Through robust training and inference over the Canadian region, we demonstrate the operational scalability of our approach, achieving significant improvements in wind downscaling accuracy. Statistical validation highlights reductions in root mean square error (RMSE) and log spectral distance (LSD) metrics compared to the original DownGAN. High-resolution conditioning covariates and Frequency Separation strategies prove instrumental in enhancing model performance. This work underscores the potential for extending high-resolution wind forecasts beyond the 48-hour horizon, bridging the gap to the 10-day low resolution global forecast window.", "sections": [{"title": "Introduction", "content": "Accurate high-resolution wind forecasts are crucial for several application sectors such as aviation [1], wind energy [2], power infrastructure [3], public safety [4], wildfire management [5], avalanche warnings [6], winter sports [7], air quality [8] and water quality management [9]. Typically, wind forecasts are obtained from numerical weather predictions (NWPs), starting with a global forecast model followed by a limited-area forecast model which takes the lower-resolution model as boundary conditions in a procedure called dynamical downscaling. In Canada, high-resolution numerical prediction models have a limited forecast horizon of 48 hours due to computational constraints. An applied perspective of the work presented in this paper is to extend high-resolution wind forecast services from 48 hours to the same 10 days forecast horizon as the Canadian global forecast model.\nIn meteorology, downscaling is the operation of passing from a coarse (or low-resolution) field to a fine (or high-resolution) field. Besides dynamical downscaling, statistical downscaling is another well established approach for correcting wind at station locations. Several variations of Model Output Statistics (MOS) [10, 11] have been proposed in the literature, with the Updateable Model Output Statistics (UMOS) [12] approach the one implemented operationally at Environment and climate Change Canada (ECCC). All the MOS techniques are essentially based on the concept of Multiple Linear Regression (MLR), where several predictors from the lower-resolution NWP output are combined linearly to minimize the mean square error against an observed weather field, with one specific model used at each station location. MOS techniques can be expanded to gridded fields as long as a high-resolution gridded target is available, or specific corrections applied at each station can be interpolated to the grid [13], but they cannot capture complex non-linear spatial interactions between variables.\nMore recently, several contributions have demonstrated the potential of Artificial Intelligence (AI) based downscaling [14-25], applying successfully techniques originally developed for image processing and computer vision to weather data. In the field of image processing, the image super-resolution (or zooming) problem consists of taking a coarser image as input and producing a finer image at higher resolution.\nEarlier methods were achieving an enhancement factor of 2 to 4 times, but with the advent of deep learning, an enhancement factor of 8 and more is now possible. Generative AI in particular has proven to be a powerful tool not only to artificially produce realistic-looking images and videos from a random seed, but also to condition the generative AI on coarser or partially missing data (called inpainting).\nAI-based techniques for downscaling weather and climate fields can be classified in an increasing order of complexity and recency. At the end of spectrum, ensemble decision trees techniques such random forests and extreme gradient"}, {"title": "Dataset", "content": ""}, {"title": "Global Deterministic Prediction System", "content": "The Global Deterministic Prediction System (GDPS) [26] is ECCC's operational long-range forecast model. It represents the global configuration of the Global Environmental Multiscale (GEM) model [27] and it is run twice a day (at 00 UTC and 12 UTC), producing 10-day forecasts at a 15-km nominal resolution."}, {"title": "High-Resolution Deterministic Prediction System", "content": "The High-Resolution Deterministic Prediction System (HRDPS) [28] is a limited-area model (LAM) configuration of GEM for Canada and Northern United States. The prediction is run operationally at ECCC every 6 hours (00 UTC, 06 UTC, 12 UTC and 18 UTC runs) for a 48 hours forecast at 2.5-km nominal resolution. The HRDPS is the main source of NWP guidance for the Meteorological Service of Canada for day 1 and day 2 forecasts."}, {"title": "Predictors and Predictands", "content": "High-resolution zonal (East-West) and meridional (North-South) surface (10 m) wind components from HRDPS are used as the target variables. By predicting both components of the wind vector, we can derive both wind speed and direction at the resolution of HRDPS. Low-resolution zonal and meridional surface wind from GDPS are taken as predictors along with surface temperature, as well as wind, temperature and vertical motion at 546 hPa. In contrast with [15], high-resolution geophysical fields are added as predictors. These static high-resolution covariates can be used as predictors since these variables are constant at the time-scale of weather prediction. The topography field is particularly important in mountainous regions where wind channeling is predominant. The land-water mask not only provides an indication of changing surface roughness between the smoother water and other land, but can also be a driver of local winds such as sea breezes and lake breezes. Finally, the surface roughness variable modulates the speed of the wind and changing surface roughness can drive turbulence in the planet boundary layer. Table 1 describes the meteorological variables used for training the AI downscaling model."}, {"title": "Data Pre-processing", "content": "The map projection of the GDPS outputs is a Yin-Yang grid with a different rotated latitude-longitude map projection than the one of the HRDPS grid. We regrid the GDPS grid to the HRDPS grid using nearest neighbor interpolation. The interpolated data is then reduced by a factor of 8 (20-km nominal resolution) as the input of the AI downscaling method."}, {"title": "Methods", "content": "In this study, we adopt the deep learning framework for downscaling wind components proposed by [15]. This framework is based on Wasserstein Generative Adversarial Networks with Gradient Penalty (WGAN-GP) [29] and incorporates elements from Generative Adversarial Networks for image super-resolution (SRGAN) [30] as a baseline for the downscaling task. In the following sections, we elaborate on the application of WGANs for the downscaling problem, describe the model architecture, and introduce our approach to integrating high-resolution static covariates into the training process using UNETs [31]."}, {"title": "Conditional WGAN-GP for Downscaling", "content": "Given a training set consisting of dynamic low-resolution (GDPS) and high-resolution (HRDPS) forecast hours, denoted as x and y, respectively. A conditional WGAN-GP, conditioned on the covariates ycov in the HRDPS domain, aims to minimize the following losses for the critic $L_c$ and generator $L_G$ [15,29,32]:\n$L_C = E_{G(x)~P_g}[C(G(x | y_{cov}))] - E_{y~P_r}[C(y)] + \\lambda E_{\\hat{y}~P_{\\hat{y}}}[(\\lVert \\nabla_{\\hat{y}} C(\\hat{y}) \\rVert_2 - 1)^2]$ (1)\n$L_G = -\\gamma E_{G(x)~P_g}[C(G(x | y_{cov}))] + \\alpha E_{y~P_r}l_c(y, G(x | y_{cov}))$ (2)\nIn this formulation, C denotes a real-valued function known as the Critic, which is defined on the HRDPS domain. The function G represents the Generator, which maps low-resolution GDPS to the HRDPS domain. The symbol $P_g$ denotes the conditional distribution of the generated downscaled GDPS data given the covariates $y_{cov}$, while $P_r$ represents the distribution of the HRDPS points. The expression $E_{\\hat{y}~P_{\\hat{y}}}[(\\lVert \\nabla_{\\hat{y}} C(\\hat{y}) \\rVert_2 - 1)^2]$ represents the gradient penalty, which is incorporated into the formulation to ensure valid Wasserstein distances by enforcing 1-Lipschitz continuity for the Critic. Here, $\\hat{y} ~ P_{\\hat{y}}$ denotes a linearly interpolated generated value defined by $\\hat{y} = \\epsilon y + (1 - \\epsilon)G(x | y_{cov})$, where $\\epsilon ~ U[0, 1]$. The scalars $\\lambda$, $\\gamma$, and $\\alpha$ are regularization hyperparameters: $\\lambda$ controls the gradient penalty term, $\\gamma$ the adversarial loss term, $E_{G(x)~P_g}[C(G(x | y_{cov}))]$, and $\\alpha$ the content loss term, $E_{y~P_r}l_c(y, G(x | y_{cov}))$. All expectations in the equations above are computed across all dimensions of x and y. Specifically, x is a tensor of size $B \\times C_l \\times W \\times H_l$, and y is a tensor of size $B \\times C_h \\times W_h \\times H_h$. Here, B represents the batch size, W and H denote the spatial width and height, respectively, while C indicates the number of input channels (variates). The subscripts l and h refer to the GDPS and HRDPS datasets, respectively. Additionally, $Y_{cov}$ is a tensor with dimensions $C_{cov} \\times W \\times H_l$, where values are replicated across the batch size B. This replication is due to the covariates being static and independent of time. It is important to note that if $y_{cov}$ is not provided, the WGAN-GP model reduces to the formulation presented in [15].\nUtilizing WGAN-GP for downscaling is preferred over traditional GANs due to the advantages offered by WGANs. These advantages include a more stable training process and the provision of meaningful loss metrics, which contribute to achieving better generative outputs. Additionally, WGAN-GP effectively mitigates common challenges encountered in GAN training, such as mode collapse and vanishing gradients. For a more comprehensive understanding of these concepts, please refer to the relevant literature [15, 29, 33]."}, {"title": "Frequency Separation", "content": "The core idea of the frequency separation approach is to decompose the low- and high-frequency components and treat them differently during WGAN-GP training [15,34], with the aim of enhancing the quality of downscaled wind components. This allows the adversarial training to focus specifically on generating the high-frequency components, which are crucial for capturing fine details. In this approach, the high-frequency components are derived as $y_h = y - H(y)$ for the HRDPS data, and $G(x | y_{cov})_h = G(x | y_{cov}) - H(G(x | y_{cov}))$ for the generated downscaled data, where H represents a low-pass filter. In this case, during WGAN-GP training, the Critic will focus on optimizing the loss based only in the high frequency components $y_h$ and $(G(x | y_{cov})_h$ instead of y and $(G(x | y_{cov}))$. On the other side the Generator delegates the generation of high frequency components to the adversarial component $-E_{G(x)_h~P_g}[C(G(x | y_{cov}))_h]$ and the low frequency components to the content loss $E_{y~P_r}l_c(H(y), H(G(x | y_{cov})))$. In [15] is proposed the partial frequency separation, this approach is similar than before but the adversarial loss is used in its original formulation, i.e., $-E_{G(x)~P_g}[C(G(x | y_{cov}))]$"}, {"title": "Architectures", "content": ""}, {"title": "Critic Network", "content": "To implement the proposed conditional WGAN-GP, we employed the same Critic network described by [15], as illustrated in Figure 2. The figure provides a schematic of the Critic network, with the numbers above each block indicating the dimensions of the data representations at various stages. The labels below the blocks denote the kernel size k, the number of filters n, and the stride s used in each layer. The Critic utilizes a VGG-style architecture that progressively reduces the spatial dimensions of the input, which may include HRDPS wind components or the downscaled version of GDPS wind components provided by the Generator network, through a sequence of convolutional layers. The network processes the input data using 3x3 convolutions with LeakyReLU activations, where each layer increases the number of feature maps while downsampling the spatial dimensions using a stride of 2. This approach allows the network to expand the number of channels up to eight times the input dimension. The extracted features are then passed through a final processing block, a regression-style scoring mechanism that reduces the feature vector to a single scalar output. This scalar score, used as an approximation of the Wasserstein distance, indicates the Critic's assessment of how real the input data appears."}, {"title": "Generator Network", "content": "The generator network implemented in the proposed model draws upon concepts from [15, 30] and is structured according to a U-Net architecture. The architecture is depicted in Figure 3 We employ this design because it facilitates the integration of HRDPS covariates and GDPS variates as inputs. The Generator embeds the HRDPS covariates through a sequence of downsampling layers reducing the spatial dimensions by a factor of eight. The resulting output tensor is then concatenated with the feature map tensor derived from the GDPS variates. This combined tensor passes through a series of residual-in-residual dense blocks, for a deep feature extraction. Following this stage, the network employs a sequence of upsampling layers that utilize pixel shuffle operations, enabling the progressive restoration of spatial resolution. Throughout the upsampling process, skip connections from the downsampling layers are leveraged to facilitate the merging of local and global features while preserving high-frequency details. The final output layer incorporates a convolutional operation to generate the GDPS downscaled version of wind componets. This U-Net architecture serves as the mechanism for implementing the conditional Wasserstein GAN, effectively utilizing HRDPS covariates to guide the generative process GDPS wind components."}, {"title": "Experiments", "content": ""}, {"title": "Dataset Split", "content": "This section outlines the experimental setup, using a dataset of matched GDPS and HRDPS forecast hours. For each prediction system, 24 hours of forecasts are used for each day consisting of forecast lead-times 6-17 hours for each of the 00 and 12 UTC runs. In this way, we avoid both the model spin-up time, and later forecast times where the two systems might have diverged because of error growth. For training, we selected all GDPS and HRDPS files with predictions starting between July 2022 to June 2023. The dataset was randomly split into 7,150 files for training, 1,178 for validation, and 1,162 for testing."}, {"title": "Metrics", "content": "To evaluate the performance of the proposed conditional WGAN-GP, we used the Root Mean Squared Error (RMSE) between the HRDPS reference and the downscaled GDPS wind components. Additionally, we employed the Radially Averaged Log-Spectrum Distance (LSD) [19]:\n$LSD(P_{true}, P_{pred}) = \\frac{1}{N_r} \\sum_r (10 log_{10} \\frac{P_{true}(r)}{P_{pred}(r)})^2$, (3)\nwhere P(r) is the Radially Averaged Power Spectrum Density [19] Observe that LSD quantifies the difference between predicted and true power spectra on a logarithmic scale. Subscripts pred and true are the P(r) of predicted and true wind fields, respectively."}, {"title": "Training Procedures", "content": "The GDPS and HRDPS datasets cover the entire Canadian region. We applied a nearest-neighbor regridding approach to align the GDPS data with the HRDPS grid of (2540, 1280) spatial values, because each data set was provided in different rotated coordinate systems. We use this regridding because preserves original pixel values avoiding interpolation artifacts. In this sense, each GDPS and HRDPS file is represented by tensors of sizes(7, 2540, 1280) and (2, 2540, 1280), where 7 and 2 represent the variable counts in GDPS and HRDPS, respectively, as detailed in Table 1. To train the WGAN-GP, we based our implementation in the open-source implementation from [36]. We used the following hyperparameters: critic Iterations: 5 (indicating one generator update per five critic updates), batch size: 32, learning Rate: 0.00025, regularization hyperparameters: $\\lambda$ = 10 (gradient penalty), $\\gamma$ = 0.01 (adversarial loss), and $\\alpha$ = 5 (content loss). We used spatial random cropping for training with a (128 \u00d7 128) crop size and a downsampling factor of 8 for the regridded GDPS, resulting in GDPS tensors of (7, 16, 16) for each corresponding HRDPS tensor of (2, 128, 128). We"}, {"title": "Effect of using HRDPS Static Covariates", "content": "In this experiment, we investigate the impact of incorporating HRDPS static covariates on downscaling accuracy. To this end, we compare the DownGAN model [15] using the open-source implementation from [36], against a the proposed conditional WGAN-GP that utilizes HRDPS covariates. Both models are trained with identical hyperparameters and configurations to ensure a fair comparison. The primary difference lies in their generator architectures: DownGAN employs a generator based on the SRGAN network introduced by [30], while the WGAN-GP model adapts the DownGAN generator to a UNET structure, allowing it to effectively incorporate the additional HRDPS covariates."}, {"title": "Effect of Frequency Separation", "content": "This section shows the experimental results to investigate the impact of Frequency Separation (FS) and Partial Frequency Separation (PFS) on the performance of the conditional WGAN-GP model. We tested multiple configurations for both FS and PFS, varying the low-pass average filter kernel sizes. Specifically, we used kernel sizes of (5, 5), (9, 9) and (13, 13) for each WGAN-GP model with FS and PFS. Additionally, we included a conditional WGAN-GP model without FS or PFS as a baseline (i.e., same MSE validation curve from Figure 4). For the experiments, we applied transfer learning starting from epoch 21,750, and continuing training up to epoch 50,750."}, {"title": "Metrics on the Test Set", "content": "This section presents the metrics computed on a test set comprising 1,162 GDPS forecast hours. Figure 7 displays the results, contrasting the 1,162 downscaled GDPS forecast hours against HRDPS references in terms of RMSE and LSD metrics. We used Bilinear interpolation and nearest neighbor (NN) interpolation as baseline methods. Additionally, we evaluated several models, including the DownGAN model at checkpoint 29000, the Conditional WGAN-GP model at checkpoints 21,750 and 43,500 (no frequency separation scenario: NFS - 21,750 and NFS - 43,500, respectively), and the Conditional WGAN-GP model with frequency separation with kernels (13, 13), (9, 9) and (5,5) at checkpoints 50,750 denoted by FS13 - 50,750, FS9 - 50,750, and FS5 - 50,750 respectively. The decision to select a specific model checkpoint was based on the lowest validation MSE metric (See experiments from Section 4.5). As shown by Figure 7, based on the test error in both metrics for the two wind components, the interpolation methods performed the worst. Additionally, the DownGAN model exhibited worse performance than the Conditional WGAN-GP variations. Among the Conditional WGAN-GP models, the method with frequency separation and a kernel size of 5, 5 provided the best performance in terms of the RMSE metric, and the one with kernel size of 9,9 in terms of the LSD metric"}, {"title": "Inference over the whole Canadian Region", "content": "Downscaling is crucial for analyzing large geographical regions; however, memory constraints can arise due to factors such as spatial resolution, data quantity, and model size. To address this issue, downscaling is often performed on smaller regions or patches, which are then stitched together to create a larger image. To downscale wind components on the entire Canadian domain we used the conditional WGAN-GP to generate overlapping 128 \u00d7 128 images across the domain and then blend these overlapping areas using a weight matrix W, which is pre-defined 128 \u00d7 128 matrix with weights in the interval [0, 1], increasing radially toward the center. Specifically, to generate a larger downscaling image I from smaller 128 \u00d7 128 images (patches), the algorithm starts by generating consecutive non-overlapping patches with a stride of 128 and copying the result directly into the corresponding region of I. Then, the entire region is again parsed, but this time the new patches overlap the artefacts. The final image is created by using linear interpolation between the patches generated in the last step and the correspondent pixels that were already in I by using the weight matrix W. Each value for pixel ij in image I' is given by $I_{ij} = I_{ij} * (1 \u2013 W_{ij}) + patch_{ij} * W_{ij}$\nThe top part of the figure highlights the region I, which contains artifacts and is constructed using consecutive non-overlapping patches. The bottom section illustrates how the inference overlapping algorithm generates and blends the new patches, constructing I'. It's important to note that the image of the entire Canada region is 2540 \u00d7 1280, where both dimensions are not divisible by 128. As a result, the far right and bottom edges of the image contain regions that weren't filled. For these smaller regions, we generate additional patches and apply the Inference Overlapping Algorithm to fill in the remaining pixels."}, {"title": "Conclusions", "content": "In this study, we presented a downscaling methodology based on a conditional Wasserstein GAN (WGAN-GP), leveraging low-resolution data from the GDPS and high-resolution data from the HRDPS, conditioned on high-resolution static covariates. We also conducted experiments incorporating the Frequency Separation approach to enhance the performance of the model. To implement the conditional WGAN-GP, we employed a UNET model as the generator. This UNET was designed to process two types of inputs: high-resolution static covariates and low-resolution GDPS data. Due to memory constraints, the training protocol relied on extracting random crops from single pairs of GDPS and HRDPS data. We carried out experiments to analyze the impact of including high-resolution static covariates in the model. Our findings indicate that these covariates significantly improved model convergence. Furthermore, experimental results demonstrated that the use of Frequency Separation contributed to further performance gains. We evaluated the generalization capability of the proposed model using a held-out test set. The results revealed that the best model configuration incorporated Frequency Separation, achieving favorable performance in terms of RMSE and Log Spectral Distance (LSD) metrics.\nTo operationalize the model, we proposed a downscaling procedure for the entire Canadian domain. This procedure generates overlapping downscaled patches of size 128 x 128 and blends them into the larger Canadian region using a linear interpolation approach. As future work, we aim to operationalize the model as a product capable of extending high-resolution wind forecast services from the current 48-hour horizon to the 10-day forecast horizon of the Canadian global forecast model. Additionally, we plan to investigate the application of recent state-of-the-art weather foundation models [37] for wind downscaling."}]}