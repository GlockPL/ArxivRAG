{"title": "A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?", "authors": ["Xinyu Liu", "Shuyu Shen", "Boyan Li", "Peixian Ma", "Runzhi Jiang", "Yuyu Luo*", "Yuxin Zhang", "Ju Fan", "Guoliang Li", "Nan Tang"], "abstract": "Translating users' natural language queries (NL) into SQL queries (i.e., NL2SQL) can significantly reduce barriers to accessing relational databases and support various commercial applications. The performance of NL2SQL has been greatly enhanced with the emergence of Large Language Models (LLMs). In this survey, we provide a comprehensive review of NL2SQL techniques powered by LLMs, covering its entire lifecycle from the following four aspects: (1) Model: NL2SQL translation techniques that tackle not only NL ambiguity and under-specification, but also properly map NL with database schema and instances; (2) Data: From the collection of training data, data synthesis due to training data scarcity, to NL2SQL benchmarks; (3) Evaluation: Evaluating NL2SQL methods from multiple angles using different metrics and granularities; and (4) Error Analysis: analyzing NL2SQL errors to find the root cause and guiding NL2SQL models to evolve. Moreover, we provide a rule of thumb for developing NL2SQL solutions. Finally, we discuss the research challenges and open problems of NL2SQL in the LLMs era.", "sections": [{"title": "I. INTRODUCTION", "content": "NATURAL Language to SQL (i.e., NL2SQL), which converts a natural language query (NL) into an SQL query, is a key technique toward lowering the barrier to accessing relational databases [1]\u2013[7]. This technique supports various important applications such as business intelligence, customer support, and more, making it a key step toward democratizing data science [8]\u2013[19]. Recent advancements in language models have significantly extended the frontiers of research and application in NL2SQL. Concurrently, the trend among database vendors to offer NL2SQL solutions has evolved from a mere notion to a necessary strategy [20], [21]. Therefore, it's important for us to understand the fundamentals, techniques, and challenges regarding NL2SQL.\nIn this survey, we will systematically review recent NL2SQL techniques through a new framework, as shown in Figure 1.\n\u2022 NL2SQL with Language Models. We will first review existing NL2SQL solutions from the perspective of language models, categorizing them into four major categories (see Figure 1(a)). We will then focus on the recent advances in Pre-trained Language Models (PLMs) and Large Language Models (LLMs) for NL2SQL.\n\u2022 Benchmarks and Training Data Synthesis. Undoubtedly, the performance of PLM- and LLM-based NL2SQL models is highly dependent on the amount and quality of the training data. Therefore, we will first summarize the characteristics of existing benchmarks and analyze their statistical information (e.g., database and query complexity) in detail. We will then discuss methods for collecting and synthesizing high-quality training data, highlighting this as a research opportunity (see Figure 1(b)).\n\u2022 Evaluation. Comprehensively evaluating NL2SQL models is crucial for optimizing and selecting models for different usage scenarios. We will discuss the multi-angle evaluation and scenario-based evaluation for the NL2SQL task (see Figure 1(c)). For example, performance can be assessed in specific contexts by filtering datasets based on SQL characteristics, NL variants, and database domains.\n\u2022 NL2SQL Error Analysis. Error analysis is essential in NL2SQL research for identifying model limitations. We review existing error taxonomies, analyze their limitations, and propose principles for designing taxonomies for NL2SQL output errors. Using these principles, we create a two-level error taxonomy and utilize it to summarize and analyze NL2SQL output errors (see Figure 1(d)).\nNext, we will introduce practical guidance for developing NL2SQL solutions, including a roadmap we designed for optimizing LLMs to NL2SQL task, along with a decision flow we created for selecting NL2SQL modules tailored to different NL2SQL scenarios. Finally, we will introduce some interesting and important open problems in the field of NL2SQL, including open-world NL2SQL tasks, cost-effective NL2SQL with LLMs, and trustworthy NL2SQL solutions.\nDifferences from Existing Surveys. Our survey distinguishes itself from existing NL2SQL surveys [22]\u2013[26] and tutorials [27]\u2013[29] in five aspects.\n\u2022 We systematically review the entire lifecycle of NL2SQL problem, as shown in Figure 1. This lifecycle includes training data collection and synthesis methods (Figure 1(b)), various NL2SQL translation methodologies (Figure 1(a)), multi-angle and scenarios-based evaluations (Figure 1(c)), and NL2SQL output error analysis techniques (Figure 1(d)).\n\u2022 We provide a more detailed and comprehensive summary of the inherent challenges in NL2SQL. Additionally, we analyze the technical challenges when developing a robust NL2SQL solution for real-world scenarios, which are often overlooked in other surveys.\n\u2022 We particularly focus on recent advances in LLM-based NL2SQL methods, summarizing key modules and comparing different strategies within this scope. We are the first survey to provide a modular summary of methods and provide detailed analyses for each key module (e.g., database content retrieval).\n\u2022 We highlight the importance of evaluating NL2SQL methods in a multi-angle way, analyze the key NL2SQL error patterns, and provide a two-level error taxonomy.\n\u2022 We provide practitioners with a roadmap for optimizing LLMs to NL2SQL task and a decision flow for selecting the suitable NL2SQL modules for various usage scenarios.\nContributions. We make the following contributions.\n\u2022 NL2SQL with Language Models. We comprehensively review existing NL2SQL techniques from a lifecycle perspective (Figure 1). We introduce the NL2SQL task definition, discuss challenges (Figure 2), provide a taxonomy of NL2SQL solutions based on language models (Figure 3), and summarize the key modules of language model-powered NL2SQL solutions (Figure 5 and Table I). Next, we elaborate on each module of language model-powered NL2SQL methods, including the pre-processing strategies (Section IV), NL2SQL translation methods (Section V), and post-processing techniques (Section VI).\n\u2022 NL2SQL Benchmarks. We review NL2SQL benchmarks based on their characteristics (Figure 10). We analyze each benchmark in-depth and present their statistical information (Table II). (Section VII)\n\u2022 NL2SQL Evaluation and Errors Analysis. We highlight the importance of evaluation in developing practical NL2SQL solutions. We review widely used evaluation metrics and toolkits for assessing NL2SQL solutions. We provide a taxonomy to summarize typical errors produced by NL2SQL methods. (Section VIII)\n\u2022 Practical Guidance for Developing NL2SQL Solutions. We provide a roadmap for optimizing existing LLMs to NL2SQL tasks. (Figure 13(a)). In addition, we design a decision flow to guide the selection of appropriate NL2SQL modules for different scenarios (Figure 13(b)).\n\u2022 Open Problems in NL2SQL. Finally, we discuss new research opportunities, including the open-world NL2SQL problem and cost-effective NL2SQL solutions (Section X).\n\u2022 NL2SQL Handbook. We maintain a continuously updated handbook\u00b9 for readers to easily track the latest NL2SQL techniques in the literature and provide practical guidance for researchers and practitioners."}, {"title": "II. NL2SQL PROBLEM AND BACKGROUND", "content": "In this section, we first formalize the definition of the NL2SQL task (Section II-A). We then introduce the workflow\nDefinition 1 (Natural Language to SQL (NL2SQL)). Natural Language to SQL (NL2SQL), also known as Text-to-SQL, is the task of converting natural language queries (NL) into corresponding SQL queries (SQL) that can be executed on a relational database (DB). Specifically, given an NL and a DB, the goal of NL2SQL is to generate an SQL that accurately reflects the user's intent and returns the appropriate results when executed on the database.\nDiscussion. In some cases, the corresponding SQL to an NL query may be multiple due to the ambiguity or underspecification of the NL, or the ambiguity of the database schema. In addition, even when the NL, database schema, and database content are clear and specific, there may still be multiple equivalent SQLs that can satisfy the given NL query.\nB. NL2SQL Human Workflow\nWhen humans, such as Database Administrator (DBA), perform the NL2SQL task, they first attempt to understand NL, then examine the database schema and contents, and finally write the corresponding SQL based on their SQL knowledge. Next, we will provide a detailed description of this process, as shown in Figure 2(a).\nStep-1: Natural Language Query Understanding: Given the NL query \"Find the names of all customers who checked out books on exactly 3 different genres on Labor Day in 2023\", the first task is to comprehend the user's intent and identify the key components of the NL. To this end, the DBA may first identify some key terms and phrases in the given NL. For example, in this query, the key terms are: 1) Entities or Attributes: \u201cnames\u201d, \u201ccustomers\u201d, \u201cbooks\u201d, and \"genres\"; 2) Temporal Context: \u201cLabor Day in 2023\"; and 3) Specific Conditions: \"exactly 3 different genres\".\nThen, the DBA may further understand the overall purpose of the NL query. In this case, the query intends to retrieve a list of customer names based on specific borrowing behavior on a particular date.\nStep-2: Schema Linking and DB Content Retrieval: Next, the DBA examines the database schema and values to identify the relevant tables, columns, and cell values needed to produce the SQL. For example, the DBA may determine that the \"Customer\" and \"Book\" tables are relevant based on their understanding of the NL (see Figure 2(a)-1). The DBA then decides which columns should be mentioned. For example, the keyword \"genres\" can refer to either \"LiteraryGenre\" or \"SubjectGenre\" (see Figure 2(a)-2).\nFurthermore, the DBA should interpret \u201cLabor Day in 2023\" based on the context. In the US, \"Labor Day in 2023\" refers to \"September 4th, 2023\", while in China, it refers to \u201cMay 1st, 2023\". This judgment involves domain knowledge or available additional information (see Figure 2(a)-5).\nStep-3: Translating the NL Intent into the SQL: Finally, the DBA writes the corresponding SQL based on their understanding of the NL and the results of schema linking and database content retrieval. This process, known as \u201cNL2SQL Translation\", requires the DBA to leverage their SQL knowledge and understanding of database concepts. However, this process can be very challenging due to the ambiguity of the NL or the complexity of the database. For example, as illustrated in Figure 2(a), despite understanding the need to link the Customer and Book tables, one must be familiar with the usage and norms of employing either a natural join or a subquery. Additionally, there may be multiple corresponding SQL queries because \"genres\" can refer to either \"LiteraryGenre\" or \"SubjectGenre\".\nC. NL2SQL Task Challenges\nAs mentioned in Section II-B, there are three key steps in the NL2SQL task. From these steps, we can identify three inherent challenges: the uncertainty of the natural language, the complexity of the database, and the translation from the \"free-form\" natural language queries to the \"constrained and formal\" SQL queries.\nIn this section, we will discuss these fundamental challenges of the NL2SQL task. We will then analyze the technical challenges, i.e., the challenges we face when developing a strong NL2SQL solution in real-world scenarios.\nC1: The Uncertain Natural Language Query. Natural language often contains uncertainties due to ambiguity and underspecification [30]. In NL2SQL tasks, the challenges related to NL can be summarized as follows:\n\u2022 Lexical Ambiguity: This occurs when a single word has multiple meanings. For example, the word \u201cbat\" can refer to an animal or a baseball bat (noun) or the action of swinging (verb).\n\u2022 Syntactic Ambiguity: This occurs when a sentence can be parsed in multiple ways. For example, in the sentence \"Mary saw the man with the telescope\", the phrase \"with the telescope\" can mean either that Mary used a telescope to see the man or that the man had a telescope.\n\u2022 Underspecification: This occurs when linguistic expressions lack sufficient detail to convey specific intentions or meanings clearly. For example, \"Labor Day in 2023\" refers to September 4th in the US but May 1st in China.\n\u2022 User Mistakes: Spelling mistakes and grammatical errors significantly increase the complexity of natural language understanding.\nC2: The Complex Database and Dirty Content. The NL2SQL task requires an in-depth understanding of the database schema, including table names, column names, and the interrelations between tables, as well as the database context involving the attributes and values of data. The complexity of modern database schema and the vast volume of data present substantial challenges to the effective operation of NL2SQL tasks. These complexities include:\n\u2022 Complex Relationships Among Numerous Tables: A database can include hundreds of tables interconnected through complex relationships. NL2SQL systems must be able to understand and utilize these relationships accurately when generating SQL queries.\n\u2022 Similarity in Column Names: Managing columns with similar names across different tables is a common challenge in the NL2SQL task. For example, a database might contain multiple tables each with a column named \u201cdate\u201d, where one might represent the \"creation date\" while another might represent the \"expiration date\u201d.\n\u2022 Domain-Specific Schema Variations: Different fields may have unique database designs, which means an NL2SQL system must adapt to each specific schema's difference, making generic solutions challenging. For example, table and column names are often expressed using abbreviations or vague expressions in the finance domain.\n\u2022 Large and Dirty Values: In the context of large databases, handling the immense volume of data efficiently is essential, as it is impractical to use all data as input. The system must focus on effectively extracting and formatting relevant data from queries to meet database requirements. In addition, it's crucial for the system to have fault tolerance capabilities to manage and mitigate errors or inconsistencies present in real-world databases, ensuring the reliability and accuracy of the query outputs.\nC3: NL2SQL Translation. The NL2SQL task differs from the compilation of a high-level programming language to a low-level machine language, as it usually has a one-to-many mapping between the input NL and output SQL queries. Specifically, the NL2SQL task faces several unique challenges:\n\u2022 Free-form NL vs. Constrained and Formal SQL: the SQL queries follow a strict syntax, whereas natural language is more flexible and varied. Translating NL queries into corresponding SQL queries requires adherence to SQL syntax rules to ensure they are executable.\n\u2022 Multiple Possible SQL Queries: a single NL query can correspond to multiple SQL queries that satisfy the requirements, leading to ambiguity in determining appropriate SQL translation (see the example in Figure 2(a)).\n\u2022 Database Schema Dependency: the NL2SQL translation process is significantly dependent on the database schema it interacts with. As shown in Figure 2 (a) and (b), for the same NL query (intent), a change in the database schema will correspond to different SQL queries. This requires NL2SQL solutions to dynamically adapt their translations to different databases.\nBeyond the above intrinsic challenges of translating natural language queries to SQL, developers must also navigate several technical obstacles to build reliable and efficient NL2SQL systems. Next, we will discuss several technical challenges that need to be addressed to develop strong NL2SQL solutions.\nTechnical Challenges in Developing NL2SQL Solutions. Developing robust NL2SQL solutions involves addressing several technical challenges. These include:\n\u2022 Efficiency of the Model: Ensuring the model can process natural language queries and convert them to SQL efficiently, minimizing latency. This consideration is crucial as efficiency directly impacts user experience and operational costs, especially in scenarios requiring low latency.\n\u2022 Efficiency of SQL: The SQL generated by NL2SQL models need to be not only correct but also optimized for performance. This involves optimization in the selection of joins, indexes, and query structures. Efficient queries reduce the load on databases, enhancing the system's responsiveness and throughput.\n\u2022 Cost-effective Solution: Deploying NL2SQL models, especially those using large language models, requires significant resources, including hardware and API costs. These models are expensive to run and can consume a lot of cost (such as energy and monetary cost). Efficient resource management is crucial to keep operational costs down and reduce environmental impact.\n\u2022 Insufficient and Noisy Training Data: Acquiring high-quality NL2SQL training data is extremely challenging. The limited amount of publicly available training data is often insufficient for training robust models. Additionally, the quality of this data is frequently compromised by noisy annotations. Annotators need database knowledge, which increases costs, and the complexity of the NL2SQL task often leads to errors, for example, in the Spider dataset [31], which required around 1100 hours of human labor to annotate about 11K (NL, SQL) pairs. However, it was subsequently identified that about 4% of the pairs had annotation errors, requiring additional annotation efforts to correct them.\n\u2022 Data Privacy: Data privacy is crucial for NL2SQL systems, especially when the databases contain sensitive data. Using cloud-based APIs like GPT-4 increases privacy risks, as it involves sending data to external servers.\n\u2022 Trustworthiness and Reliability: For NL2SQL models to be widely used, they need to be trustworthy and reliable. This means they must consistently produce accurate results across different datasets and use cases. Trustworthiness also requires that the model's decisions are transparent. This allows users to understand and check the SQL it generates. For example, using explainable AI to show how decisions are made and developing strong evaluation metrics to assess accuracy."}, {"title": "D. Challenges Solving with Large Language Models", "content": "The evolution of NL2SQL technology has been marked by substantial advancements over the years, driven primarily by progress in Natural Language Processing (NLP).\nIn Figure 3(a), we categorize the challenges of NL2SQL into five levels and define each level's specific challenges. The first three levels focus on challenges that have been addressed or are still being tackled, affirming the progressive development of NL2SQL. The fourth level symbolizes the challenges we aim to resolve in the LLMs stage. Finally, the fifth level represents our aspirations for the ultimate NL2SQL system.\nIn Figure 3(b), we describe the evolution of NL2SQL solutions from the perspective of language models, categorizing it into four stages: the rule-based stage, the neural network-based stage, the PLM-based stage, and the LLM-based stage. For each stage of NL2SQL, we analyze the changes in target users and the extent to which challenges are addressed.\nRemark: PLM vs. LLM. Figure 4 illustrates the differences between LLMs and PLMs. The LLMs are a type of PLMs characterized by superior language understanding and emergent capabilities [32], [33]. These emergent capabilities enable it to perform NL2SQL tasks using prompts. However, employing PLMS for NL2SQL tasks typically requires pre-training or fine-tuning to achieve similar performance.\n1) Rule-based Stage: In the early stages of NL2SQL technology development, research primarily focused on rule-based methods. These methods [30], [34]\u2013[36] utilized predefined rules or semantic parsers to understand natural language queries and convert them into SQL queries. For example, NaLIR [35] utilizes a syntactic parser to understand the NL query and link it to database elements. Next, it relies on manually crafted rules to generate the corresponding SQL query. However, rule-based methods have limitations in terms of adaptability, scalability, and generalization capabilities. At this stage, natural language understanding is limited to the token level, and research focuses on single-table databases. (see Figure 3(b)-1)\n2) Neural Network-based Stage: To alleviate these limitations, researchers turned to leveraging neural networks to solve the NL2SQL task. Methods based on sequence-to-sequence models or graph neural networks (GNNs) are developed [37]\u2013[39]. For example, given the various expressions possible in the WHERE clause of SQL queries, Seq2SQL [40] employs a reinforcement learning approach for partial training of this clause. This method trains the aggregation functions and SELECT clause using cross-entropy loss while employing a reward function to train the WHERE clause. Addressing the potential challenges of reinforcement learning, SQLNET [41] proposes a query skeleton technique using fixed slots, transforming the problem into a classification task. However, the generalization ability of these methods is limited by the model size and the amount of training data. At this stage, natural language understanding has advanced with the development of neural networks, not only handling synonyms and synonymous phrases but even beginning to comprehend simple text. Consequently, the research focus shifted from single-table databases like WikiSQL [40] to more complex databases like Spider [31] that involve multiple tables. (see Figure 3(b)-2)\n3) PLM-based Stage: With the introduction of PLMs such as BERT [42] and T5 [43] in 2018, NL2SQL methods based on PLMs [7], [44], [45] have achieved competitive performance on various benchmark datasets. These models brought significant advancements in natural language understanding and generation, enabling more accurate and efficient NL2SQL translation. In this stage, fine-tuning the PLMs is often required to adapt to NL2SQL tasks. For example, Graphix-T5 [44] is a hybrid model that combines a conventional pre-trained transformer architecture with custom graph-aware layers designed to enhance its performance on tasks involving graph-structured data. However, these models still face challenges in handling complex database schema and often require specific training for NL2SQL tasks. At this stage, PLMs trained on extensive corpora have further enhanced natural language understanding capabilities, successfully resolving approximately 80% of the cases in the Spider database. However, when addressing external hard-level cases, the accuracy is only around 50% [46] (see Figure 3(b)-3).\n4) LLM-based Stage: LLMs demonstrate unique emergent capabilities, which enable LLMs to surpass traditional PLMs in NLP tasks. This development has also triggered a new wave of solutions for the NL2SQL task. These LLM-based NL2SQL methods have become the most representative solutions in the current NL2SQL landscape [5], [6], [47], [48]. Current optimizations primarily focus on prompt design [6] and training LLMs [47]. DAIL-SQL [6] utilizes the GPT-4 model through effective prompt engineering techniques and has achieved competitive results on the Spider dataset. CodeS [47] is making attempts to create language models specifically for the NL2SQL task. By incrementally pretraining on StarCoder [49] with a large corpus related to NL2SQL tasks, CodeS has shown exceptional performance across numerous challenging NL2SQL benchmarks. At this stage, the emergence of emergent capabilities has significantly enhanced natural language understanding. Consequently, the focus of challenges has shifted more towards the database layer. The introduction of benchmarks like Bird [50] and Bull [48] reflects a heightened interest in addressing NL2SQL solutions under conditions of massive tables and values, as well as designing NL2SQL solutions for specific domains (see Figure 3(b)-\u2463).\nAlthough the LLM-based NL2SQL methods are still in their early phases, they have already demonstrated impressive performance. This not only validates the effectiveness of these models but also highlights the immense potential of this approach. With continuous advancements and optimization of the LLM-based methods, we believe these methods will be able to address more complex issues in practical applications.\nNL2SQL Solution in the Era of LLMs. Broadly speaking, there are two major approaches to leverage the capabilities of LLMs for NL2SQL: 1) in-context learning, and 2) pre-train/fine-tune LLMs specialized for NL2SQL.\nIn-Context Learning for NL2SQL. For in-context learning NL2SQL methods, the goal is to optimize the prompt function $P$ to guide the LLMs, which can be formulated as follows:\n$F_{LLM}(P \\vert NL, DB, K) \\rightarrow SQL$,\nwhere $K$ denotes additional information or domain-specific knowledge related to NL or DB. $P$ is a prompt function that transforms the input $(NL, DB, K)$ into a suitable textual prompt for the LLMs. An appropriately designed $P$ can effectively guide the LLMs to perform the NL2SQL task more accurately.\nEmploying in-context learning strategies for NL2SQL does not involve optimizing the parameters of the LLMs, thereby treating the LLMs as off-the-shelf tools. If the user has sufficient training data or hardware resources to calibrate the parameters of the LLMs, model performance and accuracy can be enhanced by tailoring it more closely to the specific NL2SQL task.\nPre-train and Fine-tune LLMs for NL2SQL. Fully optimizing the parameters of LLMs for NL2SQL tasks involves two critical stages: pre-train and fine-tune, which can be formulated as follows:\n$LLM^* = F_{fine-tune}(F_{pre-train}(LLM, D_p), D_f)$\nDuring pre-train, the LLM is trained on a large-scale and diverse dataset $D_p$ that includes a broad range of linguistic patterns and domain-general knowledge, enabling the model to develop robust understanding capabilities.\nIn the subsequent fine-tuning stage, the pre-trained model is further adjusted on a more specialized dataset $D_f$, which is closely aligned with the NL2SQL task. This targeted training refines the model's capabilities, enabling it to more effectively interpret and generate SQL based on natural language queries."}, {"title": "III. LANGUAGE MODEL-POWERED NL2SQL OVERVIEW", "content": "We summarize the key modules of NL2SQL solutions utilizing language models, especially PLMs and LLMs, as illustrated in Figure 5. Additionally, we compare the key module differences of existing NL2SQL solutions in Table I."}, {"title": "IV. PRE-PROCESSING STRATEGIES FOR NL2SQL", "content": "The pre-processing step is crucial for the NL2SQL translation process because it identifies the most relevant tables and columns (i.e., Schema Linking) and retrieves suitable database contents/cell values (i.e., DB Content Retrieval) used for generating SQL queries in advance. What's more, it enriches context by adding domain-specific knowledge (i.e., Additional Information Acquisition), enhances efficiency by focusing on relevant data, improves the understanding of the query context, and corrects errors to prevent their propagation.\nA. Schema Linking\nThe purpose of the schema linking is to identify the tables and columns related to the given NL query. It ensures the accurate mapping and processing of key information within the limited input, thereby improving the performance of the NL2SQL task. In the LLMs era, schema linking has become increasingly crucial due to the input length limit of LLMs.\nWe categorize existing schema-linking strategies into three groups based on their characteristics: 1) string matching-based methods, 2) neural network-based methods, and 3) in-context learning-based for schema linking.\n1) String Matching-based Schema Linking: Early research [38], [78], [79] primarily concentrated on string matching. String matching-based schema linking utilizes similarity measures between the text in the NL and the schema elements (e.g., table and column names) to identify relevant mappings. These methods rely on exact or approximate matching techniques to align the NL with the database schema, ensuring that the query components are correctly associated with the corresponding database elements. Exact matching, as employed by IRNet [78], is the simplest approach for identifying matches. An exact match requires candidates to be identical, while a partial match occurs when one candidate is a substring of the other. This method can uncover obvious links but may result in false positives when candidates share common words. Approximate string matching, such as the Damerau-Levenshtein distance [80] used by ValueNet [81], is another useful technique. It helps identify matches with different spellings or spelling mistakes. However, this methods lack the ability to handle synonyms and is not robust to variations in vocabulary.\n2) Neural Network-based Schema Linking: To alleviate the limitations of traditional string matching-based methods, some researchers employ deep neural networks to match database schema with natural language queries [7], [51], [74], [82]. These approaches effectively parse complex semantic relationships between language and database structures.\nDAE [82] formulates schema linking as a sequential tagging problem and proposes a two-stage anonymization model to learn the semantic relationship between schema and NL. However, DAE does not demonstrate how schema linking impacts the performance of NL2SQL tasks, as the lack of an annotated corpus. To address this, SLSQL [51] annotates the schema linking information for each instance in the training and development sets of Spider [31] to support a data-driven and systematic study. With the advent of the transformer, researchers start to explore the use of attention mechanisms and PLMs for schema linking. RAT-SQL [74] employs a relation-aware self-attention mechanism to integrate global reasoning across schema entities and question terms with structured reasoning based on predefined schema relationships. RESDSQL [7] proposes a ranking-enhanced encoding framework for schema linking. An additional cross-encoder is trained to classify tables and columns based on the input query. This framework ranks and filters them according to classification probabilities, resulting in a ranked sequence of schema items.\nHowever, neural network-based schema linking methods often struggle to generalize effectively across databases with significantly different schema or domains, especially when training data are limited.\n3) In-Context Learning for Schema Linking: With the advancement of LLMs such as GPT-4, existing research aims to harness the strong reasoning capabilities of LLMs for schema linking, i.e., directly identifying and linking relevant database schema components from the NL query. One important technique is to utilize the In-Context Learning (ICL) technique [83].\nThis approach leverages the capability of LLMs to understand and process complex language patterns and relationships within the data schema, facilitating a more dynamic and flexible schema linking process [5], [52], [60], [64], [84]. DIN-SQL [5] designs a prompt-based module for schema linking. The prompt comprises ten randomly chosen samples from the training set of the Spider and follows the Chain-of-Thought [85] strategy. For each column mentioned in the NL, the corresponding columns and their tables are selected from the database schema. C3 [60] designs different zero-shot prompts to instruct GPT-3.5 for table and column linking, employing the self-consistency method. For the table linking, the prompt guides the process in three steps: ranking tables by relevance, ensuring all relevant tables are included, and outputting in list format. For the column linking, another prompt guides the ranking of columns within candidate tables and outputting in dictionary format, prioritizing those matching question terms or foreign keys. Similarly, MCS-SQL [84] also performs schema linking in two steps involving table linking and column linking. However, MCS-SQL distinguishes itself by utilizing multiple prompts in both steps to maximize recall. MAC-SQL [64] propose a multi-agent collaborative framework for NL2SQL. The Selector agent performs the schema linking task. The Selector is activated only when the length of the database schema prompt exceeds a specified threshold. CHESS [52] utilizes GPT-4 to extract keywords from both NL and Evidence (additional information provided by BIRD [50]). By designing different prompts, it implements an efficient three-stage schema pruning protocol.\nEmploying ICL for schema linking has demonstrated commendable performance. However, it is important to note that LLMs face inherent limitations in the length of context they can process. Complex schema with many tables and columns may exceed this limitation. In addition, the effectiveness of ICL is heavily dependent on the quality of the prompts."}, {"title": "B. Database Content Retrieval", "content": "The purpose of database content retrieval is to efficiently retrieve cell values through textual searching algorithms and database indexing. Unlike schema linking, which focuses on finding relevant tables and columns based on the NL query, database content retrieval emphasizes efficiently retrieving cell values. Given the large scale of databases, retrieving cell values from them is resource-intensive and poses potential risks of exposing sensitive data [77]. Therefore, it is crucial to implement appropriate strategies for the scenario requirement.\nWe categorize existing database content retrieval strategies into three groups based on their characteristics: 1) String Matching-based Methods, 2) Neural Network-based Methods, and 3) Index Strategy for Database Content Retrieval.\n1) String Matching-based Methods: String matching-based methods are used to find and compare sequences of cell values related to the given NL query through string matching.\nIRNet [78] uses the n-grams method and regards those begin and end with quotes as cell values. Besides n-grams, ValueNet [81] implements two other methods for generating candidate cell values based on string similarity and heuristic selection. RESDSQL [7], Graphix-T5 [44], and PICARD [71] use the Longest Common Substring algorithm [86], which determines the maximum length sequence of characters that appear in each given string.\nFurther advancing this approach, BRIDGE [77] designs an anchor text matching to extract cell values mentioned in the NL automatically. It uses a heuristic method to calculate the maximum sequence match between the problem and the cell values to determine the matching boundary. When the cell values are substrings of words in the query, the heuristic can exclude those string matches. The matching threshold is then adjusted by making coarse accuracy measurements.\nBuilding on the concepts introduced by BRIDGE, various frameworks such as RESDSQL [7], RASAT [70], SuperSQL [46], and SmBoP [75] follow the same database content module as BRIDGE [77]. While string matching-based methods are direct and effective, they face challenges such as dealing with synonyms. In addition, when there is a large amount of database content, the high computational cost cannot be ignored.\n2) Neural Network-based Methods: Neural networks can learn complex data formats and semantic representations through multiple layers of nonlinear transformations to capture semantic features, thus alleviating the synonym issues.\nTABERT [87] utilizes a method called database content snapshots to encode the relevant subset of database content corresponding to the NL query. It uses an attention mechanism to manage information between cell value representations across different rows. Another common approach is leveraging the relationships in graphs to represent database content. For example, IRNet [78] employs the knowledge graph ConceptNet [88] to recognize cell value links and search cell value candidates in the knowledge graph. When a result exactly or partially matches a cell value, the column is assigned a type of value exact match or partial match, respectively.\nRAT-SQL [74] further improves structural reasoning capabilities by modeling the relationship between cell values and the NL query. Specifically, it identifies the column-value relationship, meaning that the value in the question is part of the candidate cell value of the column. Graphix-T5 [44] and LGESQL [89] use a value-match relation, which defines the relationship between cell values and questions similarly to RAT-SQL.\nDespite their ability to capture semantic features, these methods might still struggle with ambiguous or context-dependent NL, potentially leading to inaccurate cell value retrieval. In addition, the complexity of neural network architectures would demand substantial computational resources.\n3) Index Strategy for Database Content Retrieval: Efficiently retrieving relevant cell values from a database is crucial for the performance of NL2SQL systems, especially when dealing with large datasets. Therefore, existing research has employed indexing as a crucial method for improving the efficiency of database content retrieval, as it allows faster access to relevant cell values [47], [52].\nCHESS [52] utilizes a Locality-sensitive Hashing algorithm [90] for approximate nearest neighbor searches. It indexes unique cell values to quickly identify the top similar values related to the NL query. This approach significantly speeds up the process of computing the edit distance and semantic embedding between the NL query and cell values.\nCodeS [47] introduces a coarse-to-fine cell value matching approach. It leverages indexes for a coarse-grained initial search, followed by a fine-grained matching process. First, it builds the index for all values using BM25 [91]. The index identifies candidate values relevant to NL. The Longest Common Substring algorithm [86] is then used to calculate the matching degree between NL and the candidate values to find the most relevant cell values.\nWhile indexing strategies can significantly enhance the efficiency of searching for relevant cell values, they also have limitations. Index building requires an investment of time, and if the cell values in the database change frequently, the index must be continuously updated, introducing additional inference overhead."}, {"title": "C. Additional Information Acquisition", "content": "Additional information (e.g., domain knowledge) plays an essential role in improving the comprehension capabilities of NL2SQL models for understanding the NL query, performing the schema linking, and benefiting the NL2SQL translation. This information can provide demonstration examples, domain knowledge, formulaic evidence, and format information for the NL2SQL backbone model or specific modules, thereby enhancing the quality of the generated results.\nWith the advancement of LLMs and in-context"}]}