{"title": "Label Drop for Multi-Aspect Relation Modeling in Universal Information Extraction", "authors": ["Lu Yang", "Jiajia Li", "En Ci", "Lefei Zhang", "Zuchao Li", "Ping Wang"], "abstract": "Universal Information Extraction (UIE) has garnered significant attention due to its ability to address model explosion problems effectively. Extractive UIE can achieve strong performance using a relatively small model, making it widely adopted. Extractive UIES generally rely on task instructions for different tasks, including single-target instructions and multiple-target instructions. Single-target instruction UIE enables the extraction of only one type of relation at a time, limiting its ability to model correlations between relations and thus restricting its capability to extract complex relations. While multiple-target instruction UIE allows for the extraction of multiple relations simultaneously, the inclusion of irrelevant relations introduces decision complexity and impacts extraction accuracy. Therefore, for multi-relation extraction, we propose LD-Net, which incorporates multi-aspect relation modeling and a label drop mechanism. By assigning different relations to different levels for understanding and decision-making, we reduce decision confusion. Additionally, the label drop mechanism effectively mitigates the impact of irrelevant relations. Experiments show that LD-Net outperforms or achieves competitive performance with state-of-the-art systems on 9 tasks, 33 datasets, in both single-modal and multi-modal, few-shot and zero-shot settings.", "sections": [{"title": "Introduction", "content": "Information Extraction (IE) (Andersen et al., 1992; Grishman, 2019) tasks, both single-modal and multi-modal, encompass a wide variety of domains and relations between entities, leading to a highly diversified landscape. However, this diversification poses a significant challenge known as model explosion, which refers to the proliferation of models required to handle the diverse structures and relations present in different IE tasks. Traditionally, task-specific models (Zhang et al., 2018a; Wang and Lu, 2020; Zhong and Chen, 2021; Zhang et al., 2022; Peng et al., 2023a; Tian et al., 2023; Li et al., 2024a) have been developed to address the unique requirements of individual tasks. However, this approach is not scalable and becomes increasingly impractical as the number of tasks and their complexity grow.\nTo tackle the issue of model explosion, Universal Information Extraction (UIE) (Lu et al., 2022; Li et al., 2024b) has emerged as a promising paradigm. UIE aims to develop models that can extract information across different domains and relations, in both single-modal (Fei et al., 2022) and multi-modal (Zheng et al., 2023) setting, without relying on task-specific models for each individual task. By leveraging shared knowledge, UIE models can generalize well to various IE tasks, reducing the need for a multitude of specialized models.\nGenerative UIE (Wang et al., 2022a; Sainz et al., 2024) approaches have been explored, but their reliance on large generative models as the foundation limits their efficiency. These models suffer from computational complexity and resource requirements, hindering their practical applicability. In contrast, extractive UIE (Ping et al., 2023) approaches have gained popularity due to their ability to achieve strong performance using relatively small models.\nSingle-target instruction UIE (Wadden et al., 2019) allows for the extraction of one type of relation at a time. While it excels in accuracy for simple relations, its limited efficiency and inability to model correlations between relations restrict its applicability to more complex IE tasks. To address these limitations, multiple-target instruction UIE (Zhu et al., 2023) has been proposed, enabling the extraction of multiple relations simultaneously. This approach aims to model correlations between relations and improve extraction efficiency. However, the incorporation of irrelevant relations introduces decision complexity and can have ramifications on extraction accuracy.\nHence, to address the challenges in multi-relation extraction, we propose LDNet, a novel approach that leverages multi-aspect relation modeling and a label drop mechanism. In LDNet, we assign different relations to different levels for understanding and decision-making. This approach allows the model to capture the unique characteristics and nuances of each relation separately. By organizing relations into distinct levels, LDNet reduces decision confusion, enabling more accurate and reliable extraction results. Additionally, LD-Net incorporates a label drop mechanism to address the impact of irrelevant relations. During the extraction process, LDNet selectively drops irrelevant labels, focusing on the most relevant relations for extraction. This mechanism helps mitigate the interference caused by irrelevant relations, ensuring that the model can concentrate its attention and resources on extracting the necessary and meaningful information. By filtering out noise and irrelevant signals, LDNet enhances the overall extraction performance and reduces the potential for false positives.\nTo assess the effectiveness of LDNet, we conduct extensive experiments on a diverse range of IE tasks and benchmark datasets, both single-modal and multi-modal. The evaluation covers few-shot and zero-shot settings to examine the generalization capability of LDNet. The results demonstrate that LDNet outperforms or achieves competitive performance compared to previous state-of-the-art systems across 9 tasks and 33 datasets.\nOur Contribution 1) We propose LDNet, a novel approach that leverages multi-aspect relation modeling and a label drop mechanism. 2) We employ model transfer learning, a valuable strategy for further enhancing model performance across various datasets. 3) We conduct experiments on 33 datasets across 9 tasks, in both single-modal and multi-modal, few-shot and zero-shot settings, and the results demonstrate the superiority of LDNet."}, {"title": "Related Work", "content": "Generative UIE TANL (Paolini et al., 2021) sees IE tasks as a sequence-to-sequence problem and utilizes T5 as the generative model. UIE (Lu et al., 2022) also uses T5 as the backbone. In addition, UIE designs Structured Extraction Language (SEL) that can represent diversified IE tasks, thereby enabling it to perform on a wider range of IE tasks. InstructUIE (Wang et al., 2023) further incorporates the idea of instruction-tuning and utilizes FlanT5-11B (Chung et al., 2022) for IE tasks. DeepStruct (Wang et al., 2022a) and GenIE (Josifoski et al., 2022) both formulate the generated sequence as subject-relation-object triplets, with DeepStruct having a larger model size (10B). LasUIE (Fei et al., 2022) proposes a novel structure-aware generative language model to unleash the power of syntactic knowledge. FSUIE (Peng et al., 2023b) introduces fuzzy span loss and fuzzy span attention to reduce over-reliance on span boundaries. GOLLIE (Sainz et al., 2024) improves zero-shot results on unseen IE tasks by virtue of being fine-tuned to comply with annotation guidelines. TMR (Zheng et al., 2023) addresses text-image misalignment by introducing a back-translation method using diffusion-based generative models. KnowCoder (Li et al., 2024b) introduces a code-style schema representation method. While the above generative UIE approaches offer a powerful solution for diversified IE tasks, they do not possess any notable advantages when it comes to efficiency.\nExtractive UIE DyGIE++ (Wadden et al., 2019) utilizes a dynamic span graph to model long-range relations, and with graph propagation, the model can disambiguate challenging entity mentions. UniEX (Ping et al., 2023) converts IE tasks into a token-pair problem, develops a traffine attention mechanism to integrate heterogeneous factors, and obtains the extraction target via a scoring matrix. These single-target extractive UIE approaches can achieve strong performance using a relatively small model; however, they lack the ability to model correlations between relations, thus limiting their capability to extract complex relations.\nOneIE (Lin et al., 2020) also uses a span graph, but unlike DyGIE++, it incorporates global features and adopts a CRF-based tagger to remove the constraint on the length of extracted mentions. UMGF (Zhang et al., 2021) adopts a unified intra-modal and inter-modal graph fusion method to represent visual and textual features within the same embedding space. HVPNeT (Chen et al., 2022) designs pyramidal features for images, employing"}, {"title": "Methodology", "content": "LDNet's overall framework is built upon a pretrained language model and an image backbone, consisting of a multi-aspect relation modeling component and a label drop mechanism, as shown in Figure 1.\nWe formulate IE tasks as a multi-aspect span-based relation extraction problem. Specifically, we consider three kinds of relations among IE tasks: TA relation (trigger-to-argument relation), A2A relation (argument-to-argument relation), and AS relation (argument-span relation). The TA relation signifies the association of the trigger word with the identified span. The A2A relation describes the connection between two related spans, representing the semantic or contextual relation between the identified spans. The AS relation describes the connection within a span, enabling LDNet to analyze the internal structure and coherence within the span itself. As shown in Figure 1, the AS relation is formed between \u201cthe\u201d and \u201ccat\", the trigger word \"chased\" connects to \u201cthe\u201d in the span \"the cat\" and \u201cmouse\u201d in the span \"the mouse\u201d through the TA relation, and \"cat\" is linked to \u201cthe\u201d in the span \"the mouse\" through the A2A relation."}, {"title": "Multi-aspect Relation Modeling", "content": "LDNet regularizes text input format into three components: instruction, schema labels, and text. Given an input sequence x = $[x_1, x_2,..., x_{|x|}]$, LDNet computes the text representation H = $[h_1,h_2,..., h_{|x|}] \\in R^{|x| \\times d_h}$ as follows:\nH = PLM([x_1, x_2,..., x_{|x|}]) \\\\\n= [h_1,h_2,..., h_{|x|}](1)\n(2)\nwhere PLM(\u00b7) is a pretrained language model.\nTo inject image information, given an image I, LDNet initially resizes it to 224 \u00d7 224, then divides it into $n_p$ patches according to the patch size specified by the image backbone, and subsequently derives image feature representation V \u2208 $R^{n_p \\times d_v}$ using the image backbone:\nV = VisionTransformer($I$) (3)\nLDNet then employs cross-attention, where the image feature representation functions as the query and the text representation serves as both the key and value. The output of the attention mechanism is then subjected to the hyperbolic tangent activation function, followed by a summation operation. Finally, LDNet changes the sequence length of the resulting image feature representation, yielding the final image representation V \u2208 $R^{|x| \\times d_h}$:\nQ = FFNN(MLP(V)), Q\u2208 $R^{n_p \\times d_h}$ (4)\nK = FFNN(H), V = FFNN(H) (5)\n$\\hat{V} = \\sum_{i=1}^{T} Tanh \\left(Softmax \\left(\\frac{QK^T}{\\sqrt{d_h}}\\right) V\\right)$ (6)\nV = Tanh(FFNN\u2081($\\hat{V}$)) (7)\nwhere MLP (\u00b7) represents a three-layer multilayer perceptron, FFNN$_{q/k/v}$ \u2208 $R^{d_h \\times d_h}$ represents feed-forward network for generating query/key/value, and FFNN\u2081 \u2208 $R^{1 \\times |x|}$ represents the feed-forward network changing the sequence length of the resulting image feature representation.\nLDNet modulates the fusion of image representation and text representation via a hyperparameter \u03b1 \u2208 [0, 1], and the fused image-text representation M is expressed as:\nM = H+ \u03b1 \u00b7 V (8)\na is set to 0 when only doing single-modal IE tasks. After obtaining the multi-modal representation M = $[M_1, M_2,..., M_{|x|}]$, LDNet utilizes Rotary Position Embedding (RoPE) (Su et al., 2022) to achieve relative position encoding via combining the attention computation with absolute position encoding. The queries and keys for different relations are calculated as follows:\nq_i^r = FFNN_q^r(m_i), k_j^r = FFNN_k^r(m_j) (9)\nwhere r \u2208 {TA, A2A, AS}, FFNN$_{q/k}^r \u2208 R^{d_h \\times d_i}$ are feed-forward layers for different relations, and $q_i^r$ and $k_j^r$ are the i-th query and the j-th key for different relations.\nAfterwards, $q_i^r$ and $k_j^r$ are each left-multiplied by the transformation matrices $R_i$ and $R_j$ used in RoPE respectively. The dot product of $R_i$ and $R_j$ satisfies $R_i^T R_j = R_{j-i}$, thus incorporating relative position information. The probability $s_{ij}^r$ of the relation r existing between the span from i to j is the scaled dot product of the transformed $q_i^r$ and $k_j^r$:\ns_{ij}^r = \\frac{(R_i q_i^r)^T (R_j k_j^r)}{\\sqrt{d_i}} = \\frac{q_i^T R_{j-i} k_j^r}{\\sqrt{d_i}} (10)\nBy parallelly computing the scaled dot product over all token pairs of different relations separately, we can obtain three probability matrices:\nS^r = \\begin{bmatrix} s_{11}^r & s_{12}^r & \\cdots & s_{1|x|}^r \\\\ s_{21}^r & s_{22}^r & \\cdots & s_{2|x|}^r \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ s_{|x|1}^r & s_{|x|2}^r & \\cdots & s_{|x||x|}^r \\end{bmatrix} (11)\nwhere $s_{ij}^r$ is the probability of the specific relation r \u2208 {TA, A2A, AS} existing between the token pair $(x_i, x_j)$.\nDuring training, LDNet utilizes multi-label categorical cross-entropy loss as the loss function for multi-aspect relation modeling:\n\\mathcal{L}_{MR,neg} = log \\bigg(1 + \\sum_{(i,j) \\in \\Theta_{MR,neg}} e^{G_{ij}} \\bigg) (12)\n\\mathcal{L}_{MR,pos} = log \\bigg(1 + \\sum_{(i,j) \\in \\Theta_{MR,pos}} e^{-G_{ij}} \\bigg) (13)\n\\mathcal{L}_{MR} = \\sum_{r \\in \\{TA,A2A,AS\\}} (\\mathcal{L}_{MR,neg} + \\mathcal{L}_{MR,pos}) (14)\nwhere $\\Theta_{neg}$ and $\\Theta_{pos}$ are the sets of negative and positive samples, respectively. Graph labels $G_r \\in R^{|x| \\times |x|}$ are used to distinguish between negative and positive samples. Negative samples consist of position pairs where $G_{ij}^r = 0$, while positive samples are pairs where $G_{ij}^r = 1$. $G_{ij}^r$ represents the label of the token pair $(x_i, x_j)$ for relation r."}, {"title": "Label Drop", "content": "To prioritize the relational token pairs, we employ label drop to filter out token pairs that are unlikely to have relations.\nSpecifically, we first design a label vector l$^r$ = [$l^r_1, l^r_2,..., l^r_{|x|}$] \u2208 $R^{1 \\times |x|}$ for each relation as the standard. We set the values of the elements in l$^r$ whose indices fall within the gold spans and their corresponding schema labels to 1, and the rest to 0.\nLDNet transforms the representation M into the predicted matrix $\\hat{l^r} \u2208 R^{1 \\times |x| \\times 1}$ via linear activation and Sigmoid function:\n$\\hat{l^r} = Sigmoid (FFNN^r (M)) (15)\nwhere FFNN$^r \u2208 R^{d_h \\times 1}$ is the feed-forward network for different relations.\nLater, LDNet squeezes the matrix $\\hat{l^r}$ into $\\hat{l} \u2208 R^{1 \\times |x|}$ and multiplies $\\hat{l^r}$ with every row vector in the corresponding probability matrix $S^r$ computed in Section 3.1, respectively, to obtain the final probability matrix $P^r$, which is later used for decoding:\n$\\hat{P^r_i} = \\hat{l^r_i} \\odot S_i^r (16)\nwhere $P_i^r$. represents the i-th row vector of $P^r$, $S_i^r$ represents the i-th row vector of $S^r$, and $\\odot$ represents dot product. The detailed logic of label drop mechanism can be seen in Appendix A.4.\nLDNet calculates the binary cross-entropy loss between $\\hat{l^r}$ and $l^r$ to make the predicted vector $\\hat{l^r}$ approach the label vector $l^r$ of the same relation during training:\n$\\frac{1}{|x|} \\sum_{i=1}^{|x|}(\\hat{l^r} log(l^r_i) + (1 - l^r_i) log(1 - \\hat{l^r})) (17)\n$\\mathcal{L}_{LD} = \\sum_{r \\in \\{TA,A2A,AS\\}} \\mathcal{L}_{ULD} (18)\nAfter label drop, LDNet utilizes the three final probability matrices for relation decoding. During the process of relation decoding, LDNet extracts relation between token pair whose final probability is larger than the threshold of 0.5 and identifies potential relation structures. If LDNet detects a closed relation loop as shown in Figure 1, it adds the extracted span to the predicted answer."}, {"title": "Model Transfer Learning", "content": "To further boost LDNet's performance, we propose a model transfer learning approach. We select the best-performance models fine-tuned on each dataset as the teacher models, and the generated probability distributions, namely Pr of all data entries, from these teacher models are used as soft labels when fine-tuning the corresponding pre-trained student models. Mean Squared Error (MSE) loss is employed to guide LDNet in reducing the discrepancy between the distributions of the student model and the teacher model:\n\\mathcal{L}_{MT} = \\frac{1}{|x|^2} \\sum_{i=1}^{|x|} \\sum_{j=1}^{|x|} (p_{ij}^r - \\hat{p_{ij}}^r)^2(19)\nwhere $p_{ij}$ represents the ij-th element of the $P_r$ generated by the teacher model, and $\\hat{p_{ij}}$ represents the ij-th element of the $P_r$ generated by the student model. The detailed algorithm is in Algorithm 1. Thus, the complete objective for LDNet model training can be represented as follows:\n\\mathcal{L} = \\mathcal{L}_{MR} + \\mathcal{L}_{LD} + \\mathcal{L}_{MT} (20)"}, {"title": "Experiments", "content": "We use DeBERTa-v3-large (He et al., 2021) as the PLM, ViT (Dosovitskiy et al., 2021) as the image backbone, and AdamW (Loshchilov and Hutter, 2019) as the optimizer. We conduct experiments on ACE04 (Mitchell et al., 2005), ACE05 (Walker et al., 2006), CoNLL03 (Tjong Kim Sang and De Meulder, 2003), CoNLL04 (Roth and Yih, 2004), NYT (Riedel et al., 2010), SciERC (Luan et al., 2018), CASIE (Satyapanich et al., 2020), 14-res and 14-lap (Pontiki et al., 2014), 15-res (Pontiki et al., 2015), 16-res (Pontiki et al., 2016), Twitter2015 (Lu et al., 2018), Twitter2017 (Zhang et al.,"}, {"title": "Analysis on Label Drop", "content": "To investigate the effectiveness of our label drop mechanism, we conduct ablation studies under two settings: with and without label drop. We fine-tune for 100 epochs on the IE datasets in both of the settings to fully exploit the potential of the label drop mechanism. And in order to better demonstrate the effectiveness of the label drop mechanism, we do not perform model transfer learning in the ablation study. The results are shown in Figure 2. Compared to the results of LDNet with only the multi-aspect relation modeling component, the model with the label drop mechanism shows improved performance on most datasets. It achieves an improvement of 1.93% on average for the ABSA task and a substantial increase of 11.88% on the ACE05 dataset for the EE task.\nTo further analyze the capability of the label drop mechanism, we conduct experiments on 4 text datasets involving different tasks. We randomly drop different portions of the probability matrix and test the performance. We test drop rates of 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, and 100%. We also fine-tune 100 epochs for the analysis. The results are shown in Figure 2. More detailed results can be found in the Appendix C.5.\nWe can see that LDNet exhibits stable and strong performance on the NER, RE, and ABSA tasks, under different drop rates, demonstrating the robustness of the label drop mechanism. For the EE task, the performance is more volatile, with the best performance occurring under the full drop setting, which is as expected. The fluctuations in performance on the ACE05 dataset in Figure 2 are due to the large variety of label texts in the schema labels. The label texts following [LM] include 33 types, such as 'transport', 'elect', 'start position', 'nominate', 'end position', 'attack', \u2018meet', \u2018marry\u2019,\n$\\mathcal{L}_{ULD} =$"}, {"title": "Ablation Results of Multi-aspect Relation Modeling", "content": "We further conduct experiments on the Multi-aspect Relation Modeling mechanism. In these experiments, we utilize only the Multi-aspect Relation Modeling mechanism of the LDNet model, without incorporating Label Drop or Model Transfer Learning. We report the performance of LDNet under the 'w/o PT w/ Inst.' setting, with the selected comparison baseline being the performance of Mirror under the same setting. The results are shown in the Table 7. As can be seen, LDNet MR still outperforms Mirror under the same setting, demonstrating the effectiveness of the Multi-aspect Relation Modeling mechanism. The presence of Multi-aspect Relation Modeling reduces decision confusion while also creating a more suitable environment for the label drop mechanism. So it can be shown in the table that LDNet MT- achieves the best performance among the three: LDNetMR, LDNetLD, and LDNet MT-."}, {"title": "Conclusion and Discussion", "content": "In this paper, we propose LDNet, a novel network that combines multi-aspect relation modeling and a label drop mechanism. LDNet assigns different relations to different levels for understanding and decision-making, thereby reducing decision confusion. By introducing the label drop mechanism, LDNet alleviates the influence of irrevelant relations. Experimental results show that LDNet achieves highly competitive performance across 9 tasks, in both single-modal and multi-modal, few-shot and zero-shot settings, which verifies its effectiveness and universality."}, {"title": "Limitations", "content": "1) The total quantity and variety of MIE datasets are not enough, so LDNet cannot be pre-trained on a relatively large-scale dataset for MIE as it can be for IE, and since LDNet is a universal IE and UIE solution, its performance on certain multi-modal datasets may not be as good as models specifically designed for multi-modal tasks. 2) Due to the maximum input length constraint, LDNet may experience a performance decline in document-level information extraction."}, {"title": "Ethical Considerations", "content": "If the model is able to extract information of high quality, it may be able to extract personal privacy information such as names, addresses, and phone numbers from large text datasets. This information could potentially be used for illegal monitoring, harassment, and other malicious purposes. Establishing appropriate privacy protection mechanisms and usage restrictions can be applied to ensure that the extracted information is only used for legitimate purposes and not abused."}, {"title": "A Methodology", "content": "When it comes to the specific implementation, the schema labels are divided into two parts: a set of special tokens [LM], [LR], [LC], [TL], [TP], and [B] and their corresponding label text.\n[LM], [LR], and [LC] are the special tokens that represent labels of entity mention, relation, and text classification respectively. Only one of the three special tokens [TL], [TP], and [B] will appear in a single data instance. [TP] is used for the MRC task, [B] is used for the classification task, and [TL] is used for all other tasks.\nThe special tokens [LM], [LR], [LC] will be followed by their corresponding label text, which are the tokenized strings for the entity mention, relation, and text classification labels. All the labels that appear in the dataset will be included in the schema labels, such as [LC], \"_correct\", [LC], \"_wrong\" for the classification task with \u201ccorrect\u201d and \"wrong\" as the two labels.\nWe use the special tokens in the schema labels as the trigger words and utilize them to guide the relation extraction process. A relation will only be extracted when the trigger word is activated. The label drop operation sets the elements in the label vector corresponding to the special tokens that in gold spans to 1, while the other schema label elements remain 0. For example, in the classification task, if a data instance is classified as \"correct\", the element corresponding to the [LC] token before \"_correct\" token will be set to 1, while the element corresponding to the \u201c_correct\u201d token will remain 0."}, {"title": "Handling of Unknown Schemas", "content": "If the schema is unknown, LDNet removes the schema from the original NER input format, transforming it from the format of instruction + schema + text:\n[I] Please identify possible entities from the given text and determine their types [LM] person [LM] location [LM] organization [TL] Jerry Smith is a friend of Tom\nto:\n[I] Please identify possible entities from the given text and determine their types [TP] Jerry Smith is a friend of Tom\nHere, [I] Please identify possible entities from the given text and determine their types is the instruction part, with [I] being a special token indicating the start of the instruction; [LM] person [LM] location [LM] organization represents the schema, with [LM] being a special token representing an entity type, such as [LM] person, indicating the person type; [TL] Jerry Smith is a friend of Tom is the text part, with [TL] being a special token indicating that the text following it requires not only span extraction but also the extraction of types within the schema. For instance, to extract the entity Jerry Smith, it's necessary to extract both its span and its corresponding type, person, which is associated with the span of the [LM] token in [LM] person in the schema. In the input without a schema, [TP] indicates that only entity spans need to be extracted from the text, without requiring the extraction of additional information such as types in schemas.\nThus, LDNet handles unknown schemas by processing the input as follows:\n[I] Please identify possible entities from the given text and determine their types\n[TP] Jerry Smith is a friend of Tom\nFrom the text \"Jerry Smith is a friend of Tom\", LDNet directly extracts the spans of entities such as Jerry Smith and Tom as the output."}, {"title": "Handling of Discontinuous NER and Nested NER", "content": "Discontinuous NER LDNet handles discontinuous NER in a manner similar to how it handles regular NER. Suppose the input is:"}, {"title": "Underlying Logic of Label Drop Mechanism", "content": "The underlying logic of label drop mechanism is that if the i-th token does not exist in the gold answer, after training, the value of $\\hat{l^r}$ at position i in $\\hat{l^r}$ will close to 0, it suppresses the value of $s_{ij}^r$ in the i-th column of the $S^r$ matrix. During subsequent decoding, if the value of $s_{ij}^r$ is suppressed below a threshold, LDNet will not consider extracting the relation between position i and other positions, therefore filtering out token pairs that is impossible to have relations. As shown in Figure 1, for the convenience of observation, we only depict the prediction of the A2A relation. And to better illustrate the concept of label drop, we hypothesize an extreme scenario where $\\hat{l^r}$ is the same as $l^r$. For instance, the probability of a relation existing between \"playwright\u201d and \u201cborn\" is set to 0."}, {"title": "LDNet's Contributions Relative to Prior Multi-modal Approaches", "content": "Multi-modal representation is a conventional approach. LDNet utilizes multi-modal representation to enable its application to multi-modal data. LD-Net is a universal information extraction method, its capability is general and not differentiated by whether the data is multi-modal or unimodal. Compared to prior multi-modal approaches, the contribution of LDNet lies not in combining multi-modal"}]}