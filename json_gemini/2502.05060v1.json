{"title": "Preference-aware compensation policies for crowdsourced on-demand services", "authors": ["Georgina Nouli", "Axel Parmentier", "Maximilian Schiffer"], "abstract": "Crowdsourced on-demand services offer benefits such as reduced costs, faster service fulfillment times, greater adaptability, and contributions to sustainable urban transportation in on-demand delivery contexts. However, the success of an on-demand platform that utilizes crowdsourcing relies on finding a compensation policy that strikes a balance between creating attractive offers for gig workers and ensuring profitability. In this work, we examine a dynamic pricing problem for an on-demand platform that sets request-specific compensation of gig workers in a discrete-time framework, where requests and workers arrive stochastically. The operator's goal is to determine a compensation policy that maximizes the total expected reward over the time horizon. Our approach introduces compensation strategies that explicitly account for gig worker request preferences. To achieve this, we employ the Multinomial Logit model to represent the acceptance probabilities of gig workers, and, as a result, derive an analytical solution that utilizes post-decision states. Subsequently, we integrate this solution into an approximate dynamic programming algorithm. We compare our algorithm against benchmark algorithms, including formula-based policies and an upper bound provided by the full information linear programming solution. Our algorithm demonstrates consistent performance across diverse settings, achieving improvements of at least 2.5-7.5% in homogeneous gig worker populations and 9% in heterogeneous populations over benchmarks, based on fully synthetic data. For real-world data, it surpasses benchmarks by 8% in weak and 20% in strong location preference scenarios.", "sections": [{"title": "1. Introduction", "content": "In today's fast-paced world, consumers are increasingly time-sensitive when utilizing services, leading to substantial growth in on-demand service platforms. These platforms face the significant challenge of managing rapid fluctuations in demand and meeting the urgency of customer requests, while simultaneously keeping operational costs low. Within this context, platforms increasingly rely on using gig workers via crowdsourcing, i.e., independent workers that service on-demand tasks in exchange for a compensation, instead of employing traditional contracted personnel. Crowdsourcing has gained traction across various sectors, including last-mile delivery services such as grocery delivery (e.g., Instacart) and food delivery (e.g., DoorDash, UberEats), parcel delivery (e.g., Amazon Flex, UberFreight, UberRUSH, Roadie), and ride-hailing services (e.g., Uber, Lyft, Didi). Besides offering benefits in managing demand fluctuations (Luy et al. 2024), the utilization of gig workers is also appealing due to its potential to reduce costs (Fatehi & Wagner 2022) and, in the case of crowdsourced delivery, it can contribute to sustainable urban logistics by minimizing emissions and road congestion (Yuen et al. 2023). However, integrating gig workers into on-demand service models introduces complexity to the platform's decision-making process, primarily due to the uncertainty in gig workers' availability and willingness to accept requests. In this context, the compensation offered by platforms plays a crucial role in influencing the likelihood of request acceptance (Barbosa et al. 2023, Bathke & M\u00fcnch 2023). Therefore, the success of a crowdsourcing platform relies on finding a compensation policy that balances two key objectives: creating offers attractive enough to engage gig workers, while also maintaining profitability for the platform. Achieving this balance is challenging as gig workers tend to show strong preferences based on specific request characteristics, such as the type of service, and the request's deadline. Additionally, gig workers with different characteristics, such as age and employment status can show different request preferences. Accordingly, it is essential for platforms to account for these preferences when designing compensation policies to ensure optimal outcomes. The goal of this study is to introduce compensation strategies for crowdsourced on-demand service platforms, which directly consider gig worker preferences in shaping offers for on-demand requests."}, {"title": "1.1. Related work", "content": "Our work relates to two streams of research: studies on gig worker preferences and behavior as well as work on dynamic pricing strategies for crowdsourced on-demand service platforms. In the following, we review both works concisely.\nGig worker preferences: Multiple studies investigate gig worker preferences and behavior across various on-demand service platforms. In the context of crowd-shipping, where workers bid for delivery requests, Ermagun & Stathopoulos (2018) apply logistic regression to analyze how request characteristics influence attractiveness. They find that characteristics such as the size of the package, the type of service, the delivery deadline, and the distance of delivery are significantly correlated with a request's probability of receiving a bid. In a similar context, Hou (2023) study the crowd-shipper's acceptance behavior by utilizing discrete choice models and machine learning models applied to survey data. Their findings suggest that factors such as gig workers' age, income, and the compensation offered per request are key predictors of acceptance"}, {"title": "1.2. Contributions", "content": "In this paper, we propose a general algorithmic paradigm for computing preference-aware compensation policies to incentivize gig workers on on-demand service platforms to accept request offers. Our contributions are as follows: (1) We formalize the underlying compensation problem as a Markov Decision Process (MDP) and prove that the inner optimization problem of the Bellman equation can be solved optimally under the assumption that gig worker behavior follows a Multinomial Logit model (MNL). This allows us to derive a profit maximizing policy for the operator. (2) Based on the closed-form expression of this policy, we derive a practical algorithm for making compensation decisions, utilizing an approximate value iteration method that incorporates an MNL approximation learned in a predict-then-optimize fashion. (3) We present new benchmark datasets to evaluate the effectiveness of our algorithm and, through extensive numerical experiments, compare its performance against formula-based benchmark policies, a full-information upper bound, and our approach using a perfect MNL approximation.\nOur experimental results underscore the critical role of incorporating gig worker preferences in achieving near-optimal results. In synthetic scenarios with a homogeneous gig worker population, our algorithm achieved performance ratios between 88.5% and 94.7% outperforming two benchmark policies by 2.5-7.5%. In scenarios with a heterogeneous gig worker population, our approach achieved an average performance"}, {"title": "1.3. Organization", "content": "The remainder of this paper is structured as follows. Section 2 presents our problem setting and formulates it as an MDP, while Section 3 outlines our methodology for solving the MDP. Section 4 describes our experimental design while Section 5 presents the results of our experiments, including a comparative analysis of our algorithm against benchmark policies, sensitivity analysis over the gig worker utility estimation, and managerial insights. Finally, Section 6 concludes our paper by summarizing its key findings and suggesting avenues for future work."}, {"title": "2. Problem formulation", "content": "We consider an on-demand service platform which operates on a discrete time horizon consisting of T decision time steps {1, 2, ..., T}. Within this time horizon, on-demand requests and gig workers arrive in the system stochastically. Each gig worker is willing to serve requests in exchange for a fee. The decision to accept a request is based on the gig worker's individual utility function, which is unknown to the platform operator. Generally, a higher compensation increases the likelihood of a gig worker accepting a request. Gig workers have the flexibility to choose any of the offered requests or reject all offers. The operator's task is to set a compensation for each offered request, with the objective of maximizing net profit over the complete time horizon."}, {"title": "2.1. Problem formulation as an MDP", "content": "The problem setting outlined above unfolds as an MDP as follows:\nSystem State: At any decision time step $t \\in \\{1, ..., T\\}$ the system state $S_t = (R_t, G_t)$ is a pair where $R_t$ is the set of active on-demand requests and $G_t$ is the set of available gig workers. For simplicity, we will refer to $R_t$ and $G_t$ as the request and gig worker states, correspondingly. We assume that the gig worker state $G_t$ can accommodate at most one gig worker and that they remain in the system for only one time step.\nOn-demand requests: We describe each on-demand request $i \\in R_t$ by a set of characteristics $x_i = (x_{i1}, ..., x_{ik})$, a reward $r_i > 0$ which the operator will receive for servicing the request, an expiration step $t^{exp}_i$ after which the request will leave the system without being serviced and a penalty $\\beta_i < 0$ which the operator has to pay if the request is not serviced.\nGig workers: Gig workers are willing to serve a single on-demand request in return for some compensation $c_i$. The willingness of gig worker $j \\in G_t$ to service an on-demand request $i \\in R_t$ is stochastic and can be described by a stochastic function:\n$$f_{ij} = h_j(x_i, c_i) + \\epsilon_{ij}$$\nwhere $x_i = (x_{i1}, ..., x_{ik})$ is a feature vector that describes the characteristics of request $i \\in R_t$, $c_i$ is the compensation for servicing request $i$, and $\\epsilon_{ij}$ is a noise variable. This function is unknown to the system operator.\nFeasible Decisions: At every decision time step $t \\in \\{1,..., T\\}$ the central operator must offer a compensation $c_i$ to a gig worker for servicing each request $i \\in R_t$. A feasible compensation for servicing a request $i \\in R_t$ must be non-negative ($c_i \\geq 0$). We define the set of feasible compensations for a state $S_t$ as:\n$$C(S_t) = \\{c_t = (c_i)_{i \\in R_t} : c_i \\geq 0 \\ \\forall i \\in R_t\\}$$\nEvolution of the system: At each decision time step $t \\in \\{1, ..., T\\}$, the operator observes the system state $S_t = (R_t, G_t)$. If a gig worker is in the system, the central operator decides on a compensation $c_i$ for each request $i \\in R_t$, which will be offered to the gig worker as a compensation for fulfilling the request. Subsequently, the gig worker receives these offers and either selects to service the offer which maximizes their utility or, in case all offers have low utility, rejects all offers. We denote by $P^i_j(c_t)$ the probability of a gig worker accepting request i for compensation decision $c_t = (c_i)_{i \\in R_t}$ in system state $R_t$. We denote by $P^0_j(c_t)$ the alternative where the gig worker does not select any request. In case the gig worker selects a request, the gig worker receives a compensation $c_i$, the operator receives a reward of $r_i - c_i$, and both the gig worker and the request leave the system. If the gig worker did not select any offer, the gig worker leaves the system without compensation. On-demand requests that expire in $t$, i.e., such that $t^{exp}_i = t$, also leave the system and the operator receives the corresponding penalties $\\beta_i$. So far, the system has evolved due to the realization of the operator's compensation decision and the gig worker's acceptance decision reaching a post decision state. We refer to the post-decision state at time step t as the intermediate state after a gig worker has decided which request offer to accept and after removing expired requests, but before new requests and gig workers arrive. We define the post-decision state $R^\\prime_t$ as a subset of the request state $R_t$. To this end, we note that, the probabilities $P^i_j(c_t)$ and $P^0_j(c_t)$ establish a probability distribution for the transition into post-decision states. The system then evolves between decision states t and t + 1 as new requests $R^{new}$ and new gig workers $G^{new}$ arrive, and transitions into the next state $S_{t+1}$. Lastly, we assume that all requests expire by the last decision time step T."}, {"title": "2.2. Discussion", "content": "Three comments on our problem are in order. First, our model processes offers by considering one gig worker at a time. The assumption that $G_t$ can accommodate at most one gig worker can be justified in two ways. First, by adjusting the frequency of decision time steps so that at most one gig worker arrives per step, or second, by allowing multiple gig workers to arrive simultaneously and queuing them for sequential consideration in subsequent steps. Formally, let Q represent the queue of arriving gig workers. At each time step t, all newly arrived gig workers are added to Q for processing. The operator then observes the first gig worker in the queue (FIFO) and includes them in $G_t$. If Q is not empty, the operator will observe the next gig worker in the queue in the next time step. This sequential processing ensures that $G_t$ contains at most one gig worker at any time step. Second, we assume gig workers accept one request at a time in exchange for a fee, which aligns with many real-world applications. However, an alternative approach could involve offering bundles of requests to gig workers. Extending the problem to include bundles instead of individual offers would introduce additional complexity due to the combinatorial nature of the decision-making process, making the corresponding MDP more challenging to solve. Nonetheless, we believe that with proper algorithm implementation and an efficient MNL model estimator, handling bundles of requests could be a feasible extension. Lastly, our methodology focuses on a deterministic compensation policy, however, the platform operator could alternatively opt for a stochastic compensation policy. We opted for a deterministic policy to ensure consistency and predictability for gig workers. This consistency is particularly valuable in a practical context, as it fosters trust and transparency, reducing uncertainty for workers and enabling more reliable income expectations."}, {"title": "3. Methodology", "content": "Solving the MDP as defined in Section 2 presents several key challenges from a dynamic decision-making perspective. A primary challenge is the need for a model that describes the environment's transition dynamics, which is often complex and challenging to characterize. Another significant challenge is the intractable state space arising from the stochastic arrival of requests and gig workers, which renders exhaustive computation of optimal policies infeasible. Therefore, effective generalization across states is essential, as explicitly enumerating all possible states is unrealistic in many real-world scenarios.\nOur proposed method offers several solutions to address these challenges. First, we utilize the MNL model to describe gig workers' decision-making process, capturing essential transition dynamics without requiring a fully known environment model. To manage the complexity of large state spaces, we leverage a post-decision state formulation, which eases computing optimal policies from a tractability perspective. This formulation also facilitates solving the inner optimization problem and deriving an exact form for optimal prices based on the post-decision state values. Our method is designed to ensure scalability, making it suitable for real-world applications where exhaustive enumeration of all possible states is infeasible. To this end, we incorporate value function approximators to generalize effectively across states, which enables us to estimate value functions without exhaustive state enumeration.\nThis section details our approach. Section 3.1 introduces the Bellman equation for the MDP as defined in Section 2. Section 3.2 discusses the MNL model for capturing essential transition dynamics, addresses the state space intractability by deriving the post-decision state formulation and presents an analytical solution to the optimization problem with optimal prices based on post-decision state values. Section 3.3 presents value function approximators and an algorithm for learning appropriate parameterizations. Section 3.4 details the statistical model used for gig worker utility estimation and presents the training procedure for the full algorithm. Finally, Section 3.5 discusses methodological assumptions."}, {"title": "3.1. Bellman equation", "content": "In the following, we derive the Bellman equation for the MDP as defined in Section 2. To do so, we first elaborate on optimal value functions in general to elucidate the connection between pre- and post-decision states, which then allows us to derive the pre- and post-decision state value function accordingly."}, {"title": "3.2. Representing gig worker's utility using the MNL model and deriving an analytical solution", "content": "To effectively utilize the tractability offered by the post-decision state formulation of the Bellman equation, it is essential to model the probability distribution for transitioning to each post-decision state. This necessitates a model that accurately describes gig worker behavior, and the MNL model is one of the most commonly used approaches in the literature on discrete choice behavior for both research and practical applications. Its popularity stems from the fact that it offers a closed-form expression for acceptance probabilities and its balance of simplicity and performance, which renders it both versatile and effective. Accordingly, we adopt the MNL model as the foundation for our analysis.\nMultinomial Logit models: In the MNL model, the random variables $\\{\\epsilon_{ij}\\}_{i \\in R_t}$, of the utility function (see Equation 2.1) are independent and identically distributed (i.i.d), following a Gumbel distribution. We utilize a special case of the MNL model which assumes a linear relationship between the offered compensation and Gumbel-distributed random variables with zero mean. Formally, this variation considers that the utility function of a gig worker j for a request i is:\n$$U_{ij} = u_{ij} + c_i + \\epsilon_i$$\nwhere $u_{ij}$ is a value indicating the attractiveness of request i to gig worker j, and whose value is determined by observable characteristics of the request, $c_i$ is the offered compensation to the gig worker for accepting the request, and $\\epsilon_i$ are i.i.d. zero mean Gumbel variables with variance equal to $(\\mu_j \\pi)^2/6$ for some $\\mu_j > 0$. Under this MNL model, when the request state is $R_t$, the probability of a gig worker j in time step t accepting request i for offered compensations $c_t = (c_i)_{i \\in R_t}$, equals:\n$$P^i_j(c_t) = \\frac{exp((u_{ij} + c_i)/\\mu_j)}{\\sum_{l \\in R_t}(exp((u_{lj} + c_l)/\\mu_j) + exp(u_0/\\mu_j)}$$\nwhile the probability of gig worker j not accepting any requests reads:\n$$P^0_j(c_t) = \\frac{exp(u_0/\\mu_j)}{\\sum_{l \\in R_t}(exp((u_{lj} + c_l)/\\mu_j) + exp(u_0/\\mu_j)}$$"}, {"title": "3.3. Value function approximation", "content": "Although our optimization problem has an analytical solution, derived in Section 3.2, its dependence on the post-decision value function makes precise computation infeasible due to the vast and intractable state space. To overcome this, we employ statistical models to approximate the post-decision value function.\nStatistical models for the post-decision value function: A statistical model for the post-decision value function is defined as a function $V^\\theta$ parameterized by $\\theta$ which receives as input a post-decision state $R^{post}$ and predicts a value $v$ for that state: $V^\\theta : R^{post} \\mapsto v \\in \\mathbb{R}$. The primary challenge in designing an effective statistical model to approximate the post-decision state value lies in the fact that the request state is represented as a set, containing a variable number of requests. Consequently, an effective statistical model for the post-decision value function approximation must be able to handle this dynamic structure. To account for such a variability, we utilize a neural network architecture that incorporates an attention mechanism."}, {"title": "3.4. Training procedure", "content": "Statistical model of the gig worker's utility: In practice, the true MNL model parameters for the utilities $u_{ij}$ and the Gumbel parameter $\\mu$ are not known. To estimate the parameters of the MNL model for each gig worker group, we use observed accept/reject gig worker decisions based on the characteristics of the on-demand request $x_i$ and offered compensation $c_i$. This data comes either from interactions with the environment under any reasonable policy or from pre-existing historical data. For each gig worker group $d \\in [1,...,D]$ we train a logistic regression model using the log-odds function: $(\\hat{w}_dx_i + c_i)/\\beta_d$ where $\\hat{w}_d$ and $\\beta_d$ are trainable parameters. Finally, we estimate the utility $u_{ij}$ of a gig worker j for request i using the mapping $\\hat{u}_j : x_i \\mapsto \\hat{w}x_i$, so that $\\hat{u}_{ij} = \\hat{u}_j(x_i)$, and $\\beta_d$ by letting $\\hat{\\mu}_d = \\beta_d$.\nTraining pipeline: Our training procedure for each scenario involves the following steps: Initially, we gather experiences by interacting with training scenarios. The compensation policy employed sets the compensation for each request i by randomly selecting a value between 40%-85% of the request's reward. From these experiences, we train the MNL estimator as previously defined, using stochastic gradient descent for optimization. Since the gig worker always chooses the offer that maximizes their utility, the data skews toward higher-compensation offers, especially when the sampling policy is non-optimal and tends to over-offer. Therefore, we use $L2$ regularization on the weight $\\beta_d$ to prevent the weight $\\beta_d$ from increasing excessively. We then proceed to train the post-decision value function approximation as outlined in Algorithm 1. In order to mitigate the effect of the network weight initialization, we repeat this process with 5 different random seeds, resulting in 5 distinct models. We select the final model based on the one that demonstrates the best performance on the validation scenarios."}, {"title": "3.5. Discussion", "content": "Our proposed algorithmic paradigm adopts a model-free approach in many aspects, while it relies on the MNL model to capture gig worker behavior. As a result, it requires some knowledge of gig worker groups or at least observable characteristics of gig workers. Below, we discuss key considerations and limitations of our algorithm.\nModeling gig worker utility: Modeling all stochastic aspects of the environment is impractical due to the complexity of real-world scenarios. Instead, selectively modeling key elements provides a practical balance between model-free and model-based approaches. For example, while the variability in gig worker arrivals and requests (e.g., weekday vs. weekend patterns) is too complex to be modeled precisely, focusing on gig worker decision-making is reasonable. In our approach, we use the MNL model to represent gig worker decisions. This model is widely used in research and practice, offering flexibility to capture diverse preferences across gig worker groups. However, it assumes a specific mathematical structure (e.g., independence of irrelevant alternatives), which may not fully reflect real-world decision-making. Despite this, its practicality and generalizability justify its use in our algorithm.\nKnowledge of gig worker groups: When the gig worker population displays heterogeneous preferences, i.e., when more that one gig worker group exists, the performance of our algorithm relies on having knowledge of the different groups. However, the availability of such information varies across platforms, influencing their ability to identify groups with similar preferences. Platforms seeking to identify potential groups can refer to existing studies, such as Marcucci et al. (2017), Bathke & M\u00fcnch (2023), and Miller et al. (2017), which offer valuable insights into gig worker decision-making and subgroup behavior."}, {"title": "4. Experimental Design", "content": "In the following section, we outline our numerical experiments used to evaluate the performance of our algorithm. To this end, we focus on environments that simulate delivery and ride-hailing platforms, which are two of the fastest growing sectors in the gig economy. Section 4.1 introduces our experiments for fully synthetic datasets, which model dynamic environments with stochastic on-demand request and gig worker arrivals, applicable to both delivery and ride-hailing contexts. These synthetic datasets allow us to evaluate the algorithm's performance across diverse scenarios, including variations in request arrival rates and different compositions of the gig worker population. We consider two scenarios in terms of gig worker population: one with a homogeneous gig worker population and another with a heterogeneous gig worker population composed of three distinct groups of gig workers. Section 4.2 introduces our experiments using real-world data from the NYC Taxi and Limousine Commission (2018) dataset, allowing us to assess the algorithm's performance in a more heterogeneous and realistic setting that simulates a ride-hailing platform. This dataset captures differences between instances; for example, even within instances from the same day and hour, events like national holidays or weather conditions can introduce significant variability. We simulate gig worker behavior, considering both weak and strong location preferences across four regions of Manhattan. Section 4.3 presents benchmark policies, including the full information solution policy and formula-based policies, and introduces the performance measure used for comparative analyses."}, {"title": "4.1. Synthetic scenarios", "content": "We simulate a dynamic environment over a horizon of $T = 50$ time steps and model request arrivals using a Poisson Point Process with an arrival rate $\\lambda_r$. The maximum duration for which a request stays in the system follows an exponential distribution with parameter $\\beta_\\epsilon$. There are k types of requests, each defined by m features, a pickup, and a destination location. Requests originate from n possible locations and have $n_d$ possible destinations, both being uniformly distributed. We calculate the rewards for requests as a"}, {"title": "4.2. New York Taxi (NYT) data", "content": "The NYC Taxi and Limousine Commission (2018) dataset includes detailed trip records for yellow taxis operating in New York City in the year 2018. The dataset includes features such as pick-up and drop-off dates/times, pick-up and drop-off taxi zone locations and trip distances. Due to the substantial volume of trip requests in New York City, we constrained the dataset to requests originating in the Manhattan region on Mondays from 11 a.m. to 12 p.m., and further reduced the dataset size by selecting 30% of the total on-demand requests. Each episode represents a 30-minute interval, either from 11 a.m. to 11:30 a.m. or from 11:30 a.m. to 12 p.m. Considering the 53 Mondays in 2018, this selection resulted in a total of 106 instances. We select a horizon length T of 120 time steps, corresponding to one decision every 15 seconds, a time frame deemed realistic for gig worker decision-making processes. In this scenario, we assume that the gig worker population exhibits homogeneous preferences. Due to the unavailability of real-world data on gig worker decisions, we simulate gig worker utility synthetically. To this end, we divide Manhattan into four distinct regions, following a similar approach as Yahia et al. (2021). These regions roughly correspond to: (1) Lower Manhattan, (2) Midtown Manhattan, (3) Upper West Side, and (4) Upper East Side as shown"}, {"title": "4.3. Benchmark policies & performance measure", "content": "To assess the performance of our algorithm, we compare it against several benchmark policies. These benchmarks include policies that calculate compensation based on factors like reward, travel distance, and urgency, reflecting common practices in crowdsourced delivery platforms (Alnaggar et al. 2021), as well as theoretical upper bounds to help identify the strengths and limitations of our approach. Additionally, to understand the effect of the MNL model on performance, we create benchmarks using our algorithm with both the true MNL parameters and perturbed versions of them. We now provide details on the benchmark policies used to evaluate our algorithm's performance.\nReward percentage compensation (PP): The reward percentage compensation policy sets a compensation for a request i based on a percentage of its total reward. We perform hyperparameter tuning via gridsearch to select the best percentage ranging from 40 \u2013 100%.\nFormula-based compensation (FP): The formula-based compensation policy sets a compensation for a request i based on the following formula:\n$$FP(i) = v_1 \\cdot r_i + v_2 \\cdot td_i + v_3 \\cdot \\beta_i + (v_4 \\cdot r_i) \\cdot \\mathbb{I}_{i \\in R^{exp}_t}$$\nwhere $r_i$ is the reward, $td_i$ is the travel distance and $\\beta_i$ is the penalty. The value $v_4$ can be considered as an extra boost on the compensation in cases where the request is expiring in the current time step. We conduct hyperparameter optimization via grid search over a selection of weights for each attribute and refer to Table 3 in Appendix B.2 for details.\nFull information: The full information policy is an offline policy that assumes complete information about all requests and gig workers, including all stochastic elements, i.e., request and gig worker arrival times and the realization of the random element of the gig worker's utility. This policy solves the full-information problem optimally and yields an upper bound. We refer to Appendix B.3 for details on the upper bound"}, {"title": "5. Results", "content": "We organize our results discussion in three parts: In Section 5.1, we compare the performance of our algorithm to that of the benchmark policies on the synthetic dataset with a homogeneous gig worker population. In Section 5.2, we examine the performance of our algorithm on the synthetic dataset where the gig worker population is heterogeneous, analyzing the impact of correctly modeling multiple gig worker groups versus incorrectly assuming a homogeneous population. Lastly, Section 5.3 focuses on the performance of our algorithm using the NYT datasets, for gig workers with weak and strong location preferences."}, {"title": "5.1. Homogeneous gig worker population", "content": "We first focus on a simplified case where the gig worker population is homogeneous", "conditions.\nPerformance": "The boxplots in Figure 5 show the performance ratios across all test set realizations for each of the three sub-scenarios. In Scenario I.1", "1": "In a homogeneous gig worker population", "analysis": "Figure 6 presents the results from a sensitivity analysis with respect to the estimates of the MNL model. Specifically", "expectations": "if the utility model overestimates the utilities, it incorrectly assumes that requests are more attractive to gig workers than they actually are, resulting in insufficient compensation to incentivize acceptance. Conversely, underestimation provides enough compensation to ensure acceptance but reduces revenue, as a lower offer could have sufficed for gig worker incentivization. As expected, increasing the perturbation bound deteriorates performance in all cases, with a more pronounced effect when utilities are overestimated rather than underestimated.\nWe argue that in practical applications of our algorithm, where MNL parameters are estimated using real data, it is more likely for the estimation errors to result in underestimations rather than overestimations. This argument is based on the premise that for a model to systematically overestimate utilities, gig workers must consistently accept requests for compensations lower than their baseline utility for each request. Such occurrences are only observable due to the natural variability in gig workers' utility functions, stemming from the stochastic elements of their decision-making. In contrast, underestimating utility functions is more probable, as this can occur when data is collected under an improper policy, specifically, one that systematically over-offers compensation, prompting gig workers to select the most profitable options. In these scenarios"}]}