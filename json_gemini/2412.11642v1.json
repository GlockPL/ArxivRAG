{"title": "Introduction to AI Planning", "authors": ["Marco Aiello", "Ilche Georgievski"], "abstract": "These are notes for lectures presented at the University of Stuttgart that provide an introduction to key concepts and techniques in AI Planning. Artificial Intelligence Planning, also known as Automated Planning, emerged somewhere in 1966 from the need to give autonomy to a wheeled robot. Since then, it has evolved into a flourishing research and development discipline, often associated with scheduling. Over the decades, various approaches to planning have been developed with characteristics that make them appropriate for specific tasks and applications. Most approaches represent the world as a state within a state transition system; then the planning problem becomes that of searching a path in the state space from the current state to one which satisfies the goals of the user.\n\nThe notes begin by introducing the state model and move on to exploring classical planning, the foundational form of planning, and present fundamental algorithms for solving such problems. Subsequently, we examine planning as a constraint satisfaction problem, outlining the mapping process and describing an approach to solve such problems. The most extensive section is dedicated to Hierarchical Task Network (HTN) planning, one of the most widely used and powerful planning techniques in the field. The lecture notes end with a bonus chapter on the Planning Domain Definition (PDDL) Language, the de facto standard syntax for representing non-hierarchical planning problems.", "sections": [{"title": "1 State Model", "content": "To achieve goal-oriented behaviour, AI Planning systems choose available actions to change the state of the environment in order to satisfy the goal of their user. In this sense, the state model is a fitting representation. It is a standard model in Al defined over a state space, that is, a set of states and a set of actions that deterministically map each state to another one, extended with a single initial state and a non-empty set of goal states [1]. If systems employing the state model have complete knowledge about the states, then the state model is fully observable. The concept of a state model is also the one that most planning approaches rely on.\n\nA state model M consists of five components:\n\n\u2022 S is a finite set of states,\n\n\u2022 $s_0 \u2208 S$ is the initial state,\n\n\u2022 $S_G \u2286 S$ is the set of goal states,\n\n\u2022 A is a finite set of actions,\n\n\u2022 $\u03b4 : S \u00d7 A \u2192 S$ is a deterministic transition function.\n\nM may be represented by a labelled directed graph whose vertices are the states in S. The graph contains an edge from s to s' if and only if $s' \u2208 \u03b4(s, a)$, with a \u2208 A. Each arc is called a state transition."}, {"title": "2 Classical Planning", "content": "The state model M introduced in Section 1 implies complete knowledge, that is, the model is fully observable. The application of an action in a given state always leads to one state only \u2013 the model is deterministic. Finally, a state cannot be changed by any dynamics other than the actions given in the state model - the model is static. Planning for a state model that is fully observable, deterministic, and static is called classical planning. The term classical planning refers to planning approaches that restrict the view of the world over which planning is performed. As a result, classical planning relies on several assumptions that simplify the state model [2]. These are:\n\n\u2022 environments have a finite set of states,\n\n\u2022 the initial state is complete and fully observable,\n\n\u2022 actions are deterministic,\n\n\u2022 environment states change only by executing actions,\n\n\u2022 goals are either satisfied or not by plans,\n\n\u2022 plans are ordered sequences of actions, and\n\n\u2022 there is no explicit representation of time.\n\nIn contrast, non-classic planning approaches relax these assumptions and incorporate a wider range of properties describing actual environments. For example, modern planning approaches are able to deal with states that are not fully observable or with actions whose application can non-deterministically bring a system to several possible states. Therefore, much work has focused on developing planning approaches that relax one or more of these assumptions by allowing incomplete knowledge about the initial state, partially observable states, non-deterministic actions, actions with conditional effects, preferences, and extended goals, partially ordered plans, durative actions, and so on.\n\nA common way of defining state models underlying classical planning problems is by using the STRIPS language. We use the version of STRIPS representation as assumed in the definition of the STRIPS subset of PDDL rather than the original version to define a classical planning problem."}, {"title": "Definition 1 (Classical planning problem)", "content": "A classical planning problem P is a tuple (F, O, I, G), where\n\n\u2022 F is a set of atoms,\n\n\u2022 O is a set of operators each of which is of the form (pre(o), add(o), del(o)), where pre(o) are preconditions, add(o) and del(o) are add and delete lists, respectively, and pre(o), add(o), del(o) \u2286 F,\n\n\u2022 I \u2286 F is the initial state,\n\n\u2022 G \u2286 F is the goal state.\n\nNotice that now the initial state is a set of atoms defining a unique state in the domain, while the goal state is the one for which the set of atoms in G are true.\n\nThe state model underlying the classical planning problem is implicitly described by the STRIPS representation. More formally, a classical planning problem P = (F, O, I, G) implicitly describes a state model $M_P$ = (S, $s_0$, $S_G$, A, \u03b4), where\n\n\u2022 the states s \u2208 S are collections of atoms from F,\n\n\u2022 the initial state $s_0$ is I,\n\n\u2022 the goal states s \u2208 $S_G$ are such that G \u2286 s,\n\n\u2022 the actions a \u2208 A are the operators o \u2208 O such that pre(o) \u2286 s for \u03b4(s, a),\n\n\u2022 the transition function \u03b4 maps states s into states $s' = (s \u222a add(a)) \\ del(a)$ for a \u2208 A.\n\nBefore we provide a definition of the solution to a classical planning problem, we define the application of a sequence of operators $o_1, ..., o_n$ to a state s as\n\n$s[] = s$\n\n$s[o_1, ..., o_n] = (s[o_1, ..., o_{n-1}])[o_n]$"}, {"title": "Definition 2 (Plan)", "content": "Let P = (F, O, I, G) be a classical planning problem. The sequence of operators \u03c0 = $a_1, ..., a_n$ is a plan for P if each operator $o_i$ is applicable in $s_i$, that is, pre($o_i$) \u2286 $s_i$, and the state resulting from the application of \u03c0 from the initial state I contains the goal state G, that is, G \u2286 s[\u03c0].\n\nThe plans for the problem P correspond to the solving trajectories of the state model $M_P$.\n\nIn practical applications, the domains can be quite large and complex. An example of application is from the logistics domain, particularly multi-modal transportation, where at least two means for transport are combined in order to move goods [5]. Consider that there is a truck used to move a container from one location to another. Before the move happens, the truck should be loaded, for which a load action is defined that specifies the truck to be used, the container to be loaded on that truck, and the location where the loading happens. If we assume that there are 250 trucks, 250 containers, and 720 locations, then there are 250 \u00d7 250 \u00d7 720 = 45 million possible action instances only for the load action. Similar situations can be encountered in other applications, such as the Deep Space Mission of NASA, the game of bridge, video games, and so on. Searching for solutions to planning problems in such domains can be very expensive, if not unfeasible. It is important to know, at least from a theoretical point of view, the complexity of tasks related to planning in their various forms."}, {"title": "2.1 Complexity of Classical Planning", "content": "The worst-case complexity is a common way to get a general understanding of the feasibility and difficulty of solving a computational problem [6]. In our case, a representative problem to consider is that of finding a plan, if it exists. More formally, given a planning problem P, the plan existence problem or PlanEx(P) consists in finding whether there exists a plan that solves P. Given a planning problem P and an integer k, the bounded plan existence problem or PlanLen(P) consists of finding whether there is a plan of length at most k. PlanEx (P) and PlanLen(P) help in understanding the plan generation problem for P and its optimality in terms of number of actions in the plan, respectively.\n\nFor classical planning, both plan existence problems are decidable. This means that we can construct an algorithm that checks whether a solution exists for any possible planning problem in the category of classical planning problems. This is guaranteed by the fact that the number of states is finite. However, if we add function symbols to the representation of planning problems, then the number of states can be infinite, and PlanEx (P) may become semidecidable. This means that we can construct an algorithm that terminates when a solution exists, but it may not terminate on planning problems that do not have a plan.\n\nIn addition to knowing whether and in which cases the plan existence problems are solvable, one typically wants insight into how difficult it is to solve them or what resources are needed. In computational complexity, PSPACE defines a class of complex problems that can be solved by a deterministic Turing machine using a polynomial amount of space. The space here refers to the computer memory used by the computation. Problems with both plans' existence fall into this category. Even more strongly, they are, in fact, PSPACE-complete [7]. A decision problem is PSPACE-complete if (i) it is using a polynomial amount of space (that is, it is in PSPACE) and (ii) every other decision problem in PSPACE can be transformed to it in polynomial time. In other words, PSPACE-complete problems can be solved in constant space and time. Note that PSPACE-complete problems are the most difficult problems in PSPACE. Even if we reduce the complexity of planning problems by making restrictions on the operators, the decision problems remain difficult to solve in the worst case. For example, if we restrict operators to be without delete lists in effects, both problems become NP-hard. If we though remove negative preconditions, then PlanEx(P) can be solved in polynomial time.\n\nSuch strong complexity results should, however, not discourage us. These are worst-case complexity and might say very little of the average case or the one most likely to occur for problems in a specific domain. The planning community typically also evaluates approaches in terms of their practical performance, often on a set of benchmark domains, regardless of the theoretical worst-case results."}, {"title": "2.2 Planning Algorithms", "content": "Planning is the general process of going from the planning problem to its solution. The planner operates on a search space, with a search strategy, going through a potentially very large space or even the whole space in the worst case looking for solutions. The search space can be of several forms and structures, where the difficulty of the search increases with the intricacy and size of the space.\n\nThere are many ways to find solutions to planning problems. The simplest way of solving planning problems is by using search algorithms whose search space is a subset of the state space. These are called state-based search algorithms. We briefly look at two state-based search algorithms, namely forward search and backward search.\n\nForward search\n\nForward search starts from the initial state and searches forward through the space of states in an attempt to find the goal state. Fig. 2 shows a forward search algorithm that can be used to solve a planning problem P. The algorithm is both sound, which means a plan returned by it is a solution to P, and complete, which means that if there is a solution to P, the algorithm will find it.\n\nForward search is regarded as too inefficient in practice. There are two reasons for this, the first of which is that forward search also explores irrelevant actions. Consider the get-keys action and the goal (holds k1). Now suppose that there are 10 keys in total the user owns, all given in the initial state. So, we can bind 10 different values for the parameter ?k in get-keys, leading to 10 possible instances of actions. The forward-search algorithm would need to try all these actions to find the one that leads to the goal.\n\nAs second, planning problems often have large search spaces. Even for small planning problems, the state space may consist of an exponential number of states (see [8] for an example).\n\nForward search becomes feasible in practice by employing heuristics that can lead the search faster to the goal state. Today, heuristics are derived automatically from the representation of planning problems."}, {"title": "3 Planning as CSP", "content": "The original planning state model M consists of states that are units with no particular internal structure, see Section 1. In the following section, we explored how to use variables as building blocks of predicates which are in turn used to represent states and classical planning problems. It is then natural to turn to the case in which variables are direct constituents of states. A state is represented by a set of variables, each of which takes some value. The problem then becomes the identification of appropriate values to assign to variables given some constraints over allowable values. This constitutes the constraint satisfaction problem, or CSP. A solution to a CSP is a set of assignments to variables such that all constraints are satisfied.\n\nThe idea is to solve planning problems by constraint satisfaction. To that end, a planning problem needs to be mapped to a CSP in such a way that there is a guarantee that the solution to the CSP is also a solution to the original planning problem."}, {"title": "3.1 CSP", "content": "A constraint satisfaction problem $P_{csp}$ is made of three components:"}, {"title": "3.2 From Planning Problems to CSPs", "content": "We are now ready to encode a classical planning problem into a CSP. A common practice is to translate a planning problem whose plans have a length of at most k, a number given a priori. Such a problem is called a bounded planning problem. For the sake of clarity, we assume that classical planning problems are represented by variables with binary values instead of predicates. We refer to such variables as state variables. This means that for every ground atom, there is a state variable with a domain D of two values: true or false. Similarly, a state variable is ground if there is a value assigned to it. The representation based on state variables enables us to explain the encoding into a CSP compactly.\n\nOur final aim is to characterise sequences of states {$s_0, ..., s_k$} that correspond to plans of a length at most k steps. In the following, we refer to a state $s_i$ by its index i, for $0 \u2264 i \u2264 k$. We begin the encoding of a classical bounded planning problem P based on state-variable representation into a constraint satisfaction problem $P_{CSP}$ by defining the variables of $P_{CSP}$. The CSP variables are all ground state variables of P augmented with one variable whose value corresponds to the action applied in state i.\n\n\u2022 For each ground state variable f with a domain D and for each $0 \u2264 i \u2264 k$, there is a CSP variable x[i], whose domain is D.\n\n\u2022 For each $0 \u2264 i \u2264 k \u2212 1$, there is a single CSP variable a[i], whose domain is the set of possible actions.\n\nOnce the CSP variables are derived, the next step is to encode the initial state, the goal state and action into constraints.\n\n\u2022 Constraints encoding $s_0$: Every ground state variable f whose value is true in $s_0$ is encoded into a constraint of the corresponding CSP variable for i = 0 of the form (x[0] = true). Every ground state variable f not mentioned in $s_0$ is encoded into the constraint (x[0] = false).\n\n\u2022 Constraints encoding g: Every ground state variable f whose value is v in g is encoded into a constraint of the corresponding CSP variable for i = k: (x[k] = v).\n\n\u2022 Constraints encoding actions: For each ground action (an action instance of some operator o \u2208 O) a and for each $0 \u2264 i \u2264 k \u2212 1$:"}, {"title": "3.3 Complexity", "content": "Solving constraint satisfaction problems is in general NP-complete, as the size of $P_{CSP}$ can be exponential, that is, $\\Pi = |D|$. Several restricted forms of CSP have been investigated to find tractable classes of problems. There are two main and well-studied types of restrictions, namely the constraint language restriction and the structural restriction. The former restricts the constraint language in terms of the available types of constraints: the set of relations on a domain in a given $P_{CSP}$ must be fixed and finite. Thus, the constraint language restricts the domain and the set of relations of each constraint. If, for each fixed constraint language, there exists a polynomial algorithm that solves all inconsistencies, then the corresponding of $P_{CSP}$ is tractable (in P). Otherwise, $P_{CSP}$ is NP-complete.\n\nThe structural restriction limits the way constraints are placed over variables: the immediate interaction between variables in a $P_{csp}$ is bounded. Thus, the structural restriction focuses on the scopes of the constraints rather than their relations. The problems based on structural restrictions are tractable.\n\nEncoding a bounded classical planning problem into a constraint satisfaction one, the number of CSP variables m is, in fact, linear in the size of the planning problem, k(n + 1), where k is the bound of the plan length and n is the number of state variables. From Section 2.1, we know that the bounded decision problem PLANLENGTH for a classical planning problem is PSPACE-complete."}, {"title": "3.4 Algorithms", "content": "A CSP is usually solved by searching a variable assignment from several possibilities. The search is performed systematically by a backtracking algorithm that checks all possible assignments of values to variables. A basic backtracking algorithm works as follows. It incrementally expands a partial"}, {"title": "4 HTN Planning", "content": "We saw that the classical form of planning requires an initial state, a goal state, and some actions to realise a sequence of actions that, when executed in the initial state, lead to the goal state. While actions represent simple transitions from one world state to another one, a very common structure we use to understand the world better is of a hierarchical nature. The ability of planning to represent and deal with hierarchies is at the heart of hierarchical planning, or more specifically Hierarchical Task Network (HTN) planning [11]. Hierarchies encompass rich domain knowledge characterising the world, which makes HTN planning very useful, and also to perform well in real-world domains.\n\nHTN planning breaks with the tradition of classical planning due to the type of domain knowledge and the type of goal it requires. The basic idea includes an initial state, an initial task network as an objective to be accomplished, and domain knowledge consisting of networks of primitive and compound tasks. A task network represents a hierarchy of tasks each of which can be executed, if the task is primitive, or decomposed into refined subtasks. The planning process starts by decomposing the initial task network and continues until all compound tasks are decomposed, that is, a solution is found. The solution is a plan which equates to a sequence of primitive tasks applicable to the initial state."}, {"title": "Definition 3 (HTN planning problem)", "content": "An HTN planning problem $P_{HTN}$ is a tuple (Q, T, O, M, $t_{n_0}$, $s_0$), where\n\n\u2022 Q is the finite set of predicates,\n\n\u2022 T is the finite set of tasks,\n\n\u2022 O is a finite set of operators,\n\n\u2022 M is a finite set of methods,\n\n\u2022 $t_{n_0}$ is an initial task network,\n\n\u2022 $s_0$ is the initial state.\n\nFrom this definition, we should understand that planning is no longer searching for a sequence of actions that maps an initial state into some goal state, but instead searching for a sequence of actions that accomplishes the initial task network when applied to the initial state.\n\nRecall that an operator sequence $o_1, ..., o_n$ is applicable in state s if there is a sequence of states $s_0, ..., s_n$ (that is, a solving trajectory) such that $s_0 = s$ and $o_i$ is applicable in $s_{i\u22121}$ and $s_{i\u22121}[o_i] = s_i$ for all $0 \u2264 i \u2264 n$. Then, given an HTN planning problem $P_{HTN}$, a plan is a solution to $P_{HTN}$ if there exists an operator sequence applicable in $s_0$ by decomposing $t_{n_0}$. What exactly means to decompose a task network depends on various factors described in the following."}, {"title": "4.1 Concepts", "content": "To go beyond the basic hierarchical model and understand the workings of HTN planning, one has to look into the concepts characterising and influencing the planning process and decisions made along. Figure 5 shows a diagram of the conceptual model of HTN planning. A key concept of the model is the search space to which other concepts are related and interconnected in various ways. Let us shed some light into each of them."}, {"title": "4.1.1 Task decomposition", "content": "Simply put, a task decomposition is a strategy that transforms task networks. To be more specific, given a task network tn, a task decomposition chooses a task t from tn and, if t is primitive and applicable to the current state s, the task decomposition applies t to s. Otherwise, the decomposition"}, {"title": "4.1.2 Search space", "content": "There are two structures of the search space in hierarchical planing. The first one consists of task networks and task decompositions as evolutions from one task network to another. At the beginning of the search, a task decomposition is imposed on the initial task network of a given HTN planning problem. The planning process continues by repeatedly decomposing tasks from the updated task network until a primitive task network is produced. In other words, the initial task network is reduced to a primitive task network. Interestingly, the task network can be seen as a partially specified plan up until the point in search where the task network is primitive and fully specified. A linearisation of such a primitive task network, which is also applicable in the initial state, represents a solution to the given planning problem.\n\nIt should be evident that the search space is a directed graph in which task networks (or partial plans) are vertices, and a decomposition of one task network into another task network by some method is an outgoing edge, under the condition that the initial task network belongs to the graph. An excerpt of such a graph is shown in Figure 6. Due to vertices being partial plans, we use the term plan space to refer to this structure of search space, and to the model of HTN planning that employs a plan space as plan-based HTN planning. Formal definition of plan space follows."}, {"title": "Definition 4 (Plan space)", "content": "Given an HTN planning problem $P_{HTN}$, a plan space $P_G$ is a directed graph (V, E) such that $t_{n_0}$ \u2208 V, and for each $t_n \u2192_D t_{n'}: t_n, t_{n'} \u2208 V$ and $(t_n, t_{n'}) \u2208 E$."}, {"title": "4.1.3 Constraints", "content": "As we have seen in Section 3, constraints express relationships between two or more variables. In the context of HTN planning, task networks rely upon such constraints as per definition, and also upon constraints that can be added dynamically during planning to resolve inconsistencies, for example. For the purpose of hierarchical planning, there are three types of constraints\u00b9. The first type of constraints implies commitments about partial descriptions of state objects. It answers the ques-"}, {"title": "4.1.4 Commitment", "content": "Hierarchical planning is similar to other planning techniques in the sense that it needs to make two decisions on constraints. The first one is the common decision on constraints for binding variables, while the second one is on ordering constraints, in this case, ordering tasks in task networks.\n\nThere are two main approaches for when and how to make decisions on constraints. The first approach manages constraints in compliance with the least-commitment strategy by which task order-ing and variable bindings are deferred until a decision is forced [19]. The least-commitment strategy allows for partially described state objects as some variables of a given object may be bound, while other may not.\n\nThe second approach handles constraints according to the early-commitment strategy by which all object variables are bound and operators in the plan are totally ordered at each step of the planning process. Planners employing this strategy greatly benefit from the possibility of adopting forward chaining in which chaining of operators is achieved by imposing a total order over the plan. The total ordering ensures that neither the current operator to be added to the plan can interfere with some earlier operator's preconditions or effects, nor a later operator can interfere with current task's preconditions or effects."}, {"title": "4.1.5 Constraint posting", "content": "The concept of manipulating constraints in task networks is known as constraint posting. It is based on well-known operations on constraints, being the main ones: constraint satisfaction, constraint propagation, and constraint formulation. Constraint satisfaction ensures that a variable binding sat-isfies some given constraints, as in CSP described in Section 3, or guarantees the consistency of a"}, {"title": "4.1.6 Task interactions", "content": "A task interaction is a connection between two tasks (or parts) of a task network in which these tasks (or parts) have a certain effect on each other. The character of this effect yields two categories, namely harmful interactions and helpful interactions. Harmful interactions, also knowns as threats or flaws, are defined as relationships that introduce conflicts among different parts of a task network that threaten network's correctness. The most common harmful interactions are the following:\n\n\u2022 Deleted-condition interaction happens when a primitive task in one part of a task network deletes an expression that is a precondition of a primitive task in another part of that task network.\n\n\u2022 Double-cross interaction appears when an effect of each of two conjunctive primitive tasks deletes a precondition for the other. That is, an effect of the first task deletes a precondition of the second primitive task, and an effect of the second task deletes a precondition of the first task.\n\n\u2022 Resource interaction occurs in two situations, and it is subdivided accordingly. A resource-resource interaction is similar to the deleted-condition interaction, while a resource-argument interaction occurs when a resource in one part of a task network is used as an argument in another part of that task network.\n\nHelpful interactions are relationships that can be found in situations when one part of a task network makes use of information associated with another part in the same task network. The detection of these interactions implies a possibility for planners to generate task networks and solutions of better quality. That is, some tasks can be merged together, eliminating task redundancy and potentially optimising the cost of the solution [25]. The most common helpful interactions are the following:\n\n\u2022 Placeholder replacement appears when an actual value already exists for a particular formal object. We already know that HTN planning allows tasks with variables to be inserted into a task network. If there is no specific value to be chosen for a particular variable, a so-called formal object is created and bound to that variable [26]. The formal object is simply a placeholder for something unspecified at that point.\n\n\u2022 Phantomisation emerges when some fact, which is supposed to be achieved, is already true at the point in the task network where it occurs. In other words, a phantomisation of a task t with an effect q is considered accomplished by treating q as achieved and finding an existing task t' in the task network that already achieved the same effect q.\n\n\u2022 Disjunct optimisation happens in disjunctive goals when one disjunctive goal is \"superior to the others by the nature of its interaction\" with the other tasks in a task network [26]."}, {"title": "4.1.7 Explicit conditions", "content": "Hierarchical planners essentially depend on the quality of domain knowledge so as to restrict and guide the search for a solution. Domain authors are undoubtedly the ones who have the responsibility of giving guidance information. Domain authors explicitly encode such information as conditions within tasks. For example, explicit conditions may restrict the task decomposition, filter applicable methods, expect phantomisation, or require information from an external resource. The following is a list of types of explicit conditions that can be encountered in the existing HTN planners.\n\n\u2022 Supervised condition is accomplished within a compound task. The condition may be satisfied either by an intentional insertion of a relevant effect earlier in the processing of a task network, or by an explicit introduction of a primitive task that will achieve the required effect. Only this condition should allow further decompositions to be made.\n\n\u2022 External condition must be accomplished at the required task, but under the assumption that it is satisfied by some other task from the same task network.\n\n\u2022 Filter condition decides on task relevance to a particular situation. In the case of method relevance to a certain task decomposition, this condition reduces the branching factor by eliminating inappropriate methods.\n\n\u2022 Query condition accomplishes queries about variable bindings or restrictions at some required point in a task network.\n\n\u2022 Compute condition requires satisfaction by information coming only from external systems, such as a database.\n\n\u2022 Achieve condition allows expressing goals that can be achieved by any means available to a planner."}, {"title": "4.2 Complexity", "content": "Here too, we are interested in deciding whether a plan exists. For the purpose of analysing the com-plexity of solving an HTN planning problem, we provide a few more clarifications and assumptions. The words and phrases in italics are used as categories in the analysis.\n\n\u2022 The sets O and M can be provided in two ways. The sets can be a part of the input, or they can be fixed in advance, meaning the tasks are allowed to contain methods corresponding only to predicates in the initial state.\n\n\u2022 A compound task can be defined in several ways: (1) a compound task is without any restric-tion (yes); (2) a regular task in task networks - at most one compound task followed by all primitive tasks; (3) an acyclic task \u2013 a task can be decomposed to only a finite depth; and (4) compound tasks are not allowed at all (no).\n\n\u2022 A task network containing primitive and compound tasks as defined in the previous point can be totally ordered or partially ordered.\n\n\u2022 Variables can be allowed or not in PHTN.\n\nThe complexity results of HTN planning are summarised in Table 1. When no restrictions on compound tasks are imposed and task networks are partially ordered, then giving O and M in the in-put or fixing them in advance, or allowing variables or not, does not affect the outcome and PLANEX is undecidable. However, given O and M in the input, and being every task acyclic and every task network partially ordered, PLANEX becomes decidable. PLANEX is decidable when task networks are totally ordered. In particular, when unrestricted compound tasks and variables are allowed, PLANEX is EXPSPACE-hard in double exponential time (2-EXPTIME), or, if no variable is al-lowed, PLANEX is PSPACE-hard in exponential time. When only primitive tasks and variables are allowed, PLANEX is NP-complete, irrespective of the ordering of task networks. Furthermore, forbidding the use of variables in the same case makes PLANEX to be in P. However, disallowing"}, {"title": "5 Bonus: PDDL", "content": "A standard representation for describing problems in planning is the Planning Domain Definition Language (PDDL). PDDL, as a first-order representation, is built around objects and relations. Looking at the example in Figure 1, 'agent', 'door', and 'key' are objects, and the verb phrases 'is inside', 'is locked' and 'owns' refer to relations. The PDDL representation consists of predicates which are statements describing objects with certain relations among them and can be either true or false. Predicates can be also referred to as atoms or facts. An atom is composed of a predicate symbol, which refers to a relation, followed by a list of arguments, which are used to refer to objects. For part of the aforementioned example, we get the atom Inside(agent). Arguments can be constant symbols or variables. In order to determine whether a predicate is true or false, an interpretation is needed of exactly which objects and relations are referred to by arguments and predicate symbols. In our example, Inside(agent) states that the agent is inside the smart home. Note that there may be many possible interpretations for a single predicate. We say that a predicate is true when the relation denoted by the predicate symbol holds among the objects denoted by the arguments. A predicate that cannot be shown to be true is considered to be false. Such conclusion is known as the closed-world assumption, that is, everything that is not explicitly stated to have a certain value, remains the same. A predicate whose arguments contain no variables, that is, all variables are bound to objects, is called a atom. We say that a parametrised predicate unifies with a ground atom when the parameters of the predicate can be substituted with the argument values of the atom. For example, Inside(?a) unifies with Inside (agent) with ?a bound to agent.\n\nAs in other first-order languages, complex statements can be formulated from predicates by using logical connectives, including negation (denoted by not), conjunction (denoted by and), disjunction (denoted by or), implication (denoted by imply), universal quantification (denoted by forall), and existential quantification (denoted by exists). For the semantics of the logical connectives, see for instance [8].\n\nBy using predicates, PDDL enables describing actions, initial states, and goals. PDDL separates the descriptions of predicates and actions from the description of an initial state and a goal. The former is referred to as a domain description (or domain definition), while the latter as problem description (or problem definition). A planning problem is then created by combining a domain description with a problem description. A consequence of this separation is the possibility to create different planning problems in one domain by using the same domain description combined with"}, {"title": "5.1 Domain Description", "content": "A domain description is expressed by keywords and special fields that start with a colon. Each domain description begins with the declaration\n\n(define (domain <name>))", "The": "predicates contains a list of declarations of the predicates. A predicate is of the form\n\n(NAME ?A1 ... ?An)", "declaration": "action"}]}