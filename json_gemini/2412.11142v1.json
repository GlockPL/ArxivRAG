{"title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection", "authors": ["Tiankai Yang", "Yi Nian", "Shawn Li", "Ruiyao Xu", "Yuangang Li", "Jiaqi Li", "Zhuo Xiao", "Xiyang Hu", "Ryan Rossi", "Kaize Ding", "Xia Hu", "Yue Zhao"], "abstract": "Anomaly detection (AD) is an important machine learning task with many real-world uses, including fraud detection, medical diagnosis, and industrial monitoring. Within natural language processing (NLP), AD helps detect issues like spam, misinformation, and unusual user activity. Although large language models (LLMs) have had a strong impact on tasks such as text generation and summarization, their potential in AD has not been studied enough. This paper introduces AD-LLM, the first benchmark that evaluates how LLMs can help with NLP anomaly detection. We examine three key tasks: (i) zero-shot detection, using LLMs' pre-trained knowledge to perform AD without task-specific training; (ii) data augmentation, generating synthetic data and category descriptions to improve AD models; and (iii) model selection, using LLMs to suggest unsupervised AD models. Through experiments with different datasets, we find that LLMs can work well in zero-shot AD, that carefully designed augmentation methods are useful, and that explaining model selection for specific datasets remains challenging. Based on these results, we outline six future research directions on LLMs for AD.", "sections": [{"title": "1 Introduction", "content": "Anomaly detection (AD) is an important topic in machine learning (ML) that identifies samples differing from the general distribution (Zhao et al., 2019; Liu et al., 2024b). This ability is critical for many practical applications, such as fraud detection (Abdallah et al., 2016), medical diagnosis (Fernando et al., 2021), software engineering (Sun et al., 2022), and industrial system monitoring (Sun et al., 2023). Within natural language processing (NLP), AD is also important for finding unusual text instances, which is needed for detecting spam (Rao et al., 2021), misinformation (Islam et al., 2020), or unusual user behavior (Xue et al., 2023).\nIn the current era of large language models (LLMs), we ask how AD can make use of their capabilities and what the current level of integration looks like. While LLMs have brought large improvements to areas such as text generation, summarization, and translation, their possible benefits for AD, especially in NLP, have received some attention (Li et al., 2024a; Xu and Ding, 2024) but have not been studied in detail.\nThis work presents the first comprehensive benchmark, called AD-LLM, to study the roles and potential of LLMs in NLP anomaly detection. Our analysis focuses on three key tasks that are central in AD research and in practice (Figure 1):\n\u2022 (i) LLM for Anomaly Detection (\u00a73): Many AD tasks lack enough labeled data, making it hard to train models from scratch (Han et al., 2022). LLMs, with their pre-trained knowledge, can perform zero-shot AD (Xu and Ding, 2024).\n\u2022 (ii) LLM for Data Augmentation (\u00a74): AD tasks often suffer from unbalanced or limited data (Yoo et al., 2024; Li et al., 2023). For example, only a few insurance fraud samples may be available (Bauder and Khoshgoftaar, 2018). Generative LLMs may produce synthetic data to strengthen AD cost-effectively.\n\u2022 (iii) LLM for Model Selection (\u00a75): Picking a good AD model usually needs many trials and domain insights (Jiang et al., 2024a), and current choices in practice are often random (Zhao et al., 2021). LLMs, with the prior knowledge and ability to reason, may be able to suggest suitable AD models and save human effort.\nCollectively, these three tasks tackle fundamental AD challenges from multiple angles: rapidly detecting anomalies with minimal supervision, enriching limited datasets for more robust learning, and guiding model selection without extensive domain expertise. As a result, AD-LLM not only improves individual AD components but also demonstrates how LLMs can streamline the entire process-from raw data to reliable, actionable insights."}, {"title": "2 Preliminaries on AD-LLM", "content": "Recent studies have explored the role of LLMs in AD, highlighting both opportunities and challenges. (Xu and Ding, 2024) proposes a taxonomy categorizing LLMs as either detection or generative tools, but their work lacks experimental benchmarks. Similarly, (Jiang et al., 2024b) presents MMAD, a benchmark designed for industrial AD, focusing on image datasets yet limiting its applicability to other modalities. (Liu et al., 2024a) evaluates LLMs like Llama for out-of-distribution (OOD) detection, demonstrating the effectiveness of cosine distance detectors with isotropic embeddings. However, their work primarily focuses on traditional metrics and lacks insights into advanced LLM capabilities such as data augmentation and zero-shot detection.\nOur work, AD-LLM, bridges these gaps by introducing a comprehensive benchmark for evaluating LLMs in anomaly detection across diverse tasks. This makes AD-LLM a significant step toward advancing LLM-driven anomaly detection."}, {"title": "2.2 Datasets and Traditional Baselines", "content": "Our experiments encompass five NLP AD datasets sourced from (Li et al., 2024c), derived from classification datasets. Each dataset contains text samples from multiple categories, with one designated as the anomaly category. The training data includes only normal samples. See the detailed information on datasets in Appx. A.1"}, {"title": "2.3 Common Experimental Settings", "content": "Evaluation Metrics. We evaluate the AD performance using two commonly used metrics (Han et al., 2022): (1) the Area Under the Receiver Operating Characteristic Curve (i.e., AUROC) and (2) the Area Under the Precision-Recall Curve (i.e., AUPRC). Both are the higher, the better.\nLLMs and Hardware. We select two LLMs as main backbones: (1) Llama 3.1 8B Instruct (Dubey et al., 2024) and (2) GPT-4o (OpenAI, 2024a). For brevity, we refer to the \u201cLlama 3.1 8B Instruct\" as \"Llama 3.1\". Llama 3.1 runs on NVIDIA RTX 6000 Ada, 48 GB RAM workstations. GPT-4o is accessed through Azure OpenAI API with the \"2024-08-01-preview\u201d version and OpenAI official API. Seed is set = 42 for reproducibility. Specific experimental settings will be highlighted separately in each subsequent task."}, {"title": "3 Task 1: LLM for Zero-shot Detection", "content": "Classical AD methods often require extensive training data\u2014either labeled for supervised methods or unlabeled for unsupervised ones\u2014which is time-consuming and costly (Han et al., 2022). In addition, setting up and tuning these models for real-world scenarios can be challenging and slow.\nLLMs offer a practical alternative (Xu and Ding, 2024). With their broad pre-trained knowledge, they can perform zero-shot detection without additional training data. Their ability to understand language context and semantics makes them suitable for recognizing anomalies by logical reasoning. They can also explain their predictions, improving interpretability and trustworthiness (Huang et al., 2024b), which is important in sensitive domains such as healthcare, finance, and cybersecurity."}, {"title": "3.2 Problem Statement and Designs", "content": "Problem 1 (Zero-shot AD via LLMs) Given a test set $D_{test} = {x_1, x_2, ..., x_n}$ of text samples,"}, {"title": "Evaluation Protocol.", "content": "We focus on the ability of LLMs to detect anomalies without additional training data. We consider two settings, each reflecting different levels of prior knowledge:\n\u2022 Normal Only: We provide only the normal category name(s) $C_{normal}$. This matches scenarios where normal behavior is known but anomalies are uncertain or emerging.\n\u2022 Normal + Anomaly: We provide both normal and anomaly category names, $C_{normal}$ and $C_{anomaly}$. This setting reflects situations where some information on anomalies is available, helping the LLM reason about what is anomalous.\nThe detection process is defined as:\n$P = T(x_i, C_{normal}, C_{anomaly})$\n$(r, s) = f_{LLM}(P)$    (1)\nHere, $T(\\cdot)$ constructs the prompt $P$ for a test sample $x_i$, including known category information. The anomaly category $C_{anomaly}$ is included only in the \u201cNormal + Anomaly\u201d setting, denoted as $C_{anomaly}$. The LLM $f_{LLM}$ processes the prompt to produce an anomaly score $s$ and an explanation $r$ that describes the reasoning. This setup allows a systematic evaluation of LLMs in zero-shot AD, using prompt-based inference to handle different levels of prior knowledge. See details in Appx. B."}, {"title": "3.3 Results, Insights, and Future Directions", "content": "We select Llama 3.1 and GPT-4o as zero-shot detectors with temperature = 0 for stable outputs.\nLLMs are effective in zero-shot AD, surpassing existing training-based AD algorithms. We compare Llama 3.1-based and GPT-4o-based zero-shot detectors with baseline methods across five datasets in Table 1. GPT-4o consistently outperforms all baselines, and Llama 3.1 often ranks near the top. Despite operating with limited prior information, LLMs exhibit significant potential for anomaly detection tasks. These results highlight the strength of LLMs in zero-shot AD scenarios.\nAdditional context helps. Table 1 shows improved AUROC and AUPRC when using both normal and anomaly categories (\u201cNormal + Anomaly\u201d) compared to using only normal categories (\u201cNormal Only\u201d). By providing more contextual information, LLMs better distinguish anomalous samples, increasing detection effectiveness. These results suggest that augmenting LLMs with richer information enhances their ability to detect anomalies.\nTrade-offs in detection focus. Figure 2 presents precision-recall comparisons for the two settings. Including anomaly information generally improves recall and sometimes precision. However, for \u201cAG News\u201d and \"BBC News,\u201d we observe a recall gain at the cost of precision. This indicates that adding anomaly details may shift the LLM's detection balance, emphasizing one metric over another. Thus, one must carefully select the information provided to LLMs, as it significantly impacts their detection priorities and the balance among metrics.\nFuture Direction 1: Improve Context Integration. Providing additional context improves detection, as seen in \"Normal + Anomaly.\u201d Future work may involve more systematic ways to integrate domain-specific details based on the detection priority (e.g., precision vs. recall), such as prompt design or retrieval-augmented methods (Gao et al., 2023).\nFuture Direction 2: Optimize for Real-world Deployment. Despite their effectiveness, LLM-based zero-shot AD is inherently time-consuming and costly (Sinha et al., 2024). Reducing computational overhead is important for deploying LLMs in real settings, especially for AD applications, which are often time-critical. Methods like quantization (Dettmers et al., 2023; Xiao et al., 2023), pruning (Sun et al., 2024; Fu et al., 2024), and knowledge distillation (Wang et al., 2024b; Fu et al., 2023) can help reduce the model size and inference time while maintaining good performance."}, {"title": "4 Task 2: LLM for Data Augmentation", "content": "Data augmentation (DA) in AD aims to produce additional samples to improve model training under data scarcity (Yoo et al., 2023). However, traditional methods often struggle to capture the complexity of natural language, potentially causing a shift in domain characteristics (Feng et al., 2021). LLMs offer a solution, using their broad pre-trained knowledge and autoregressive learning objectives to generate contextually relevant data with better semantic understanding (Xu and Ding, 2024)."}, {"title": "4.2 Generating Synthetic Samples for Training-based AD Models", "content": "Problem 2 (Synthetic DA via LLMs) Given a small training set $D_{small\\_train} = {x_1, x_2, ..., x_m}$ of normal samples, the goal is to produce a synthetic dataset $D_{synth} = {\\tilde{x}_1, \\tilde{x}_2, ..., \\tilde{x}_n}$ using a pre-trained LLM $f_{LLM}$. The combined dataset $D_{DA} = D_{small\\_train} \\cup D_{synth}$ is used to train an unsupervised AD method $M$, improving performance compared to using $D_{small\\_train}$ alone."}, {"title": "Evaluation Protocol.", "content": "To evaluate the impact of LLM-generated synthetic data, we set unsupervised AD baselines listed in \u00a7A.2 in a scenario with limited training data. LLMs are then utilized to generate a synthetic training dataset. However, direct prompting often leads to highly repetitive outputs, even with high decoding temperatures (Long et al., 2024). Additionally, LLMs face constraints such as token limits (e.g., GPT-4's maximum output of 4,096 tokens) and challenges in processing long contexts (Gao et al., 2024). To address these issues, we adopt a multi-step strategy:\n\u2022 Step1: Keyword Generation: Generate groups of keywords in one inquiry. Each group consists of three keywords w/ different levels of granularity: broad/general, intermediate, and fine-grained.\n\u2022 Step2: Sample Generation: For each keyword group, generate one synthetic sample $z_i$.\nBy separating keyword generation from sample creation and enforcing different granularity levels, this approach introduces controlled variability and thematic breadth without causing the model to produce overly lengthy or repetitive data. The resulting synthetic samples are more likely to be contextually rich and semantically diverse. Further details are provided in Appx. \u0421.1"}, {"title": "Results, Insights, and Future Directions.", "content": "We apply the augmentation strategy to improve two unsupervised AD methods identified as strong baselines from Task 1 results: \"OpenAI + LUNAR\u201d (Goodge et al., 2022) and \u201cOpenAI + LOF\" (Breunig et al., 2000). We use GPT-4o with a temperature of 1.0 to introduce sufficient variability in synthetic samples.\nLLM-generated synthetic data consistently improves AD performance. As shown in Figure 3, LLM-generated synthetic data provides overall performance improvements across anomaly detection methods. Notably, \u201cOpenAI + LUNAR\u201d demonstrates consistent gains across all five datasets, emphasizing the robustness of this approach. Significant improvements are observed in datasets like \"SMS Spam\" and \"N24 News,\u201d where limited original training data posed significant challenges for traditional approaches. These results suggest that LLM-generated data is particularly effective in addressing data scarcity, complementing models like \"LUNAR\u201d that benefit from robust feature representations and semantic reasoning.\nImprovement depends on model complexity and data characteristics. While \u201cOpenAI + LUNAR\u201d sees steady improvements, \u201cOpenAI + LOF\u201d\u2014a simpler density-based model\u2014exhibits variable outcomes. In data-scarce scenarios such as \"SMS Spam\" and \"N24 News,\u201d synthetic data assists LOF. However, for datasets like \"AG News\" and \"BBC News,\u201d performance declines, possibly due to the synthetic samples shifting the underlying data distribution in ways that do not align with LOF's density assumptions. These results suggest that the effectiveness of LLM-based augmentation can depend on both the algorithm's complexity and the dataset's intrinsic structure.\nFuture Direction 3: Balance Diversity and Alignment in Synthetic Data. Future work should investigate techniques to balance the diversity of synthetic samples with their semantic alignment to real-world distributions. Excessive diversity risks producing samples that deviate too far from the target domain, while insufficient diversity may fail to address data scarcity and limit generalization (Guo and Chen, 2024). Potential strategies include adjusting the prompt engineering process, using retrieval-augmented LLMs, embedding-based filters to steer generation (O'Neill et al., 2023), and incorporating human-in-the-loop interventions (Chung et al., 2023) to refine synthetic data quality and improve downstream AD performance."}, {"title": "4.3 Generating Category Descriptions for LLM-based Detectors", "content": "Problem 3 (Description DA via LLMs) Given category names $C_{normal}$ and, optionally, $C_{anomaly}$, the objective is to generate comprehensive textual descriptions $d_{normal}$ and $d_{anomaly}$ using a pre-trained LLM $f_{LLM}$. These descriptions are then incorporated into the prompts of LLM-based detectors, aiming to improve their performance compared to using category names alone.\nEvaluation Protocol. Extending the zero-shot detection from \u00a73, we employ LLMs to produce category descriptions that offer richer semantic signals beyond simple category names. Specifically, for each normal and anomaly category, we generate $d_{normal}$ and $d_{anomaly}$ based on the category names and the dataset's context. These descriptions can highlight distinctive features, typical lexical patterns, or behavioral characteristics that define normal or anomalous classes. By incorporating these descriptions into the prompt, we update Eq. (1) as:\n$P = T(x_i, (C_{normal}, d_{normal}), (C_{anomaly}, d_{anomaly})^*)$    (2)\nwhere $(C_{anomaly}, d_{anomaly})^*$ applies only in the \u201cNormal + Anomaly\" setting (see \u00a73.2). By enriching category names with category descriptions (highlighted with blue boxes), we enhance the LLM's ability to reason about subtle category distinctions and domain-relevant cues. More details are provided in Appx. \u0421.2."}, {"title": "Results, Insights, and Future Directions.", "content": "We utilize Llama 3.1 and GPT-4o to generate category descriptions. To balance the diversity and precision of the generation, we set the temperature to 0.5.\nAugmented descriptions improve LLM-based AD. As shown in Table 2, incorporating category descriptions increases AUROC scores in most datasets. This suggests that the added semantic information helps LLM-based detectors discriminate anomalous samples more effectively, especially when the dataset's inherent structure aligns well with the contextual signals embedded in the descriptions. For example, in datasets like \u201cIMDB Reviews\" and \"BBC News,\u201d providing richer textual representations of normal and anomalous classes translates to noticeable gains in both metrics.\nTrade-offs arise between different metrics. While AUROC improvements are widespread, some datasets exhibit declines in AUPRC, indicating that enhanced semantic cues may not uniformly boost all aspects of detection. This trade-off could occur if broad, high-level descriptions cause certain anomalies to appear more similar to normal samples, reducing precision. For instance, in \u201cN24 News\u201d and \"SMS Spam,\u201d the provided descriptions might introduce overlapping attributes between categories, making it more challenging to maintain high precision. These results underscore the importance of calibrating the level and type of detail included in category descriptions to suit the specific dataset characteristics.\nFuture Direction 4: Select Representative Samples. An effective way to refine category descriptions is to ground them in representative samples from the dataset. Sampling strategies based on clustering (Axiotis et al., 2024) or diversity maximization (Moumoulidou et al., 2020) can identify prototype examples that guide LLMs toward producing more tailored and context-aware descriptions. By referencing these representative samples, future approaches may generate descriptions that better reflect subtle category distinctions, ultimately improving both ranking quality and the balance between precision and recall."}, {"title": "5 Task 3: LLM for AD Model Selection", "content": "Unsupervised model selection (UMS) is critical for identifying the most suitable AD model by aligning its features with the attributes of a given dataset and the task's requirements. Given the diverse range of AD models available and the absence of a universal solution, effective UMS is essential to ensure optimal performance. Traditional UMS methods often rely on historical performance data or domain-specific expertise; however, such data may be unavailable or irrelevant for novel or evolving datasets (Zhao et al., 2021; Zhao, 2024).\nLLMs offer a promising zero-shot alternative by utilizing their extensive pre-trained knowledge to analyze datasets and recommend suitable models without relying on past performance metrics (Qin et al., 2024). They can streamline the model selection process, reducing manual overhead and domain knowledge requirements while also improving adaptability to novel data scenarios."}, {"title": "5.2 Problem Statement and Designs", "content": "Problem 4 (Zero-shot UMS via LLMs) Given a dataset $D = {x_1, x_2, ..., x_n}$ and a set of AD"}, {"title": "Evaluation Protocol.", "content": "To enable LLM-based zero-shot UMS, we provide structured, detailed information of both the dataset and the candidate models:\n\u2022 Dataset Description: dataset name, size, background, normal and anomaly categories, text-length statistics (average, maximum, minimum, and standard deviation), and representative samples of both normal and anomalous data. These attributes help the LLM understand the dataset's structure, complexity, and potential challenges, and are generally easy to obtain for new datasets.\n\u2022 Model Description: abstracts from published AD papers describing each candidate model. These abstracts highlight key model features, underlying assumptions, and targeted use cases. By examining these summaries, the LLM can align dataset attributes with model strengths, improving the relevance of its recommendations.\nWe then construct prompts that combine these datasets and model descriptions, asking the LLM to select and justify a recommended model. Further details about the prompt format and implementation can be found in Appx. D."}, {"title": "5.3 Results, Insights, and Future Directions", "content": "For the UMS scenario, which requires sophisticated reasoning, we use GPT-01-preview (OpenAI, 2024c) with enhanced reasoning abilities.\nLLM recommendations demonstrate strong potential. Figure 4 compares the detection performance across five datasets using three references: (i) the best achievable result from any model, representing the performance upper bound; (ii) the average performance of all baseline models, simulating a scenario where a user selects models at random; and (iii) the results from the LLM-recommended models (ours). The LLM-recommended models surpass the baseline average in most cases, and sometimes approach the best-performing model (e.g., on \"IMDB Reviews\u201d and \u201cSMS Spam", "AG News\u201d dataset, the LLM alternated between recommending \u201cOpenAI + LUNAR\u201d and \u201cOpenAI + ECOD,": "ustifying choices with broad statements like \u201ceffective for high-dimensional data\" or \u201cparameter-free scalability.\u201d Such non-specific rationales diminish interpretability and user trust, especially when understanding the rationale behind model choice is important.\nFuture Direction 5: Refine Input Specificity and Addressing Biases. Future work should explore how to provide more dataset-specific details and mitigate potential LLM biases. Ambiguous or incomplete input information may cause the LLM to favor well-known models or those frequently encountered during training. Ensuring detailed and balanced inputs, and exploring how inherent biases in LLMs affect recommendations, will be important steps to improve the fairness and reliability of LLM-based UMS (Dai et al., 2024).\nFuture Direction 6: Enhancing Interpretability. Improving LLMs' capacity to produce transparent, dataset-tailored justifications for model selection decisions is key (Huang et al., 2024a). Techniques such as fine-tuning with richly annotated explanations or using prompt engineering to explicitly request structured reasoning can encourage the LLM to articulate clear, context-sensitive arguments."}, {"title": "6 Conclusion and Future Directions", "content": "In this work, we presented AD-LLM, the first comprehensive benchmark that integrates LLMs into three core aspects of anomaly detection in NLP: detection, data augmentation, and model selection. Our results show that LLMs hold strong potential across these tasks. For detection, LLMs demonstrate effective zero-shot and few-shot capabilities, often performing competitively against traditional methods without task-specific training. For data augmentation, both synthetic data generation and category description augmentation lead to improved performance for unsupervised and LLM-based AD methods. For model selection, LLMs can recommend suitable AD models using only general dataset and model descriptions. These findings highlight the emerging role of LLMs in making AD more flexible, data-efficient, and adaptable.\nFuture Directions. Investigating methods to systematically integrate external context into prompts can reduce variability and enhance precision. Techniques like quantization or hardware optimizations can lower the computational burden for real-world applications. Specialized augmentation approaches, designed to optimize user-prioritized metrics, may further improve AD performance. Finally, improving the specificity and clarity of LLM justifications can enhance interpretability and user trust, and expanding the AD-LLM benchmark to include additional tasks and applications in different fields (Huang et al., 2024b; Li et al., 2024b).\nBroader Impact Statement\nAD-LLM explores the application of LLMs in enhancing AD through zero-shot detection, data augmentation, and model selection. These contributions have the potential to significantly improve real-world AD systems in critical areas such as healthcare, finance, and cybersecurity. By enabling robust, adaptable, and efficient solutions for AD tasks, this research empowers practitioners to deploy systems that are responsive to novel challenges while reducing reliance on labeled data and extensive domain expertise.\nEthics Statement\nThis study adheres to ethical guidelines, emphasizing considerations around fairness, transparency, and privacy in developing and applying LLM-based AD systems. We emphasize the importance of evaluating and mitigating biases in LLM recommendations, ensuring that outputs are equitable and unbiased. Moreover, privacy is preserved by relying on public data and avoiding the collection of sensitive information."}, {"title": "Limitations", "content": "Despite promising results, several limitations remain. First, our evaluation is constrained to a narrow set of datasets with clear normal-anomaly distinctions, and our settings in AD and category descriptions in DA follow the structure of these datasets, limiting applicability to various domains with ambiguous anomaly definitions. Second, the synthetic data generation in DA is limited in scale, producing few samples per category, and challenges in scaling up remain unresolved. Third, UMS depends on simplistic input data and matching mechanisms. Furthermore, biases in LLM recommendations, such as favoring well-documented or familiar models, need further investigation. Finally, our study evaluates only a subset of popular LLMs, lacking a comprehensive assessment. Additionally, we do not explore few-shot learning or fine-tuning, which are widely adopted techniques for enhancing LLM performance and could offer valuable complementary insights for AD tasks."}]}