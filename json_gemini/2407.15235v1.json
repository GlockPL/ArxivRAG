{"title": "TAGCOS: TASK-AGNOSTIC GRADIENT CLUSTERED CORESET SELECTION FOR INSTRUCTION TUNING DATA", "authors": ["Jipeng Zhang", "Yaxuan Qin", "Renjie Pi", "Weizhong Zhang", "Rui Pan", "Tong Zhang"], "abstract": "Instruction tuning has achieved unprecedented success in NLP, turning large language models into versatile chatbots. However, the increasing variety and volume of instruction datasets demand significant computational resources. To address this, it is essential to extract a small and highly informative subset (i.e., Coreset) that achieves comparable performance to the full dataset. Achieving this goal poses non-trivial challenges: 1) data selection requires accurate data representations that reflect the training samples' quality, 2) considering the diverse nature of instruction datasets, and 3) ensuring the efficiency of the coreset selection algorithm for large models. To address these challenges, we propose Task-Agnostic Gradient Clustered COreset Selection (TAGCOS). Specifically, we leverage sample gradients as the data representations, perform clustering to group similar data, and apply an efficient greedy algorithm for coreset selection. Experimental results show that our algorithm, selecting only 5% of the data, surpasses other unsupervised methods and achieves performance close to that of the full dataset.", "sections": [{"title": "1 Introduction", "content": "Instruction tuning is the most important strategy for customizing Large Language Models (LLMs) for downstream tasks, which allows them to precisely understand human intentions and accurately generate responses in natural languages. Recently, many existing works expand the amount and diversity of instructions for instruction tuning to further enhance the LLM's capability. However, the increased quantity of the dataset also leads to significantly higher computational costs for instruction tuning. Meanwhile, Zhou et al. revealed that only 1,000 high-quality, human-created data samples could substantially improve the ability of LLMs to follow instructions, which suggest that there exists severe redundancy in current instruction datasets, and only a high-quality subset may suffice for achieving promising performance.\nTo address the above issue, selecting a small, highly informative subset (i.e., coreset) of training samples from the original dataset is a promising solution. This approach ensures that training on the coreset achieves performance comparable to the full dataset while significantly reducing costs. However, coreset selection is challenging as it must not only consider the quality of individual samples, but also their importance within the entire subset. For example, if two high-quality samples are very similar, selecting only one may be sufficient. This global perspective on sample importance is crucial for the quality of the selected subset.\nCurrent methods for coreset selection can be categorized into two main types: 1) Heuristic-based approaches  and 2) Optimization-based approaches. Heuristic-based methods use various heuristic scores"}, {"title": "2 Related Work", "content": "Instruction tuning has achieved unprecedented success in NLP, turning large language models into versatile chatbots. Successful instruction tuning requires a powerful pre-trained base model as well as high-quality instruction datasets. For the powerful pre-trained base model, one usually selects a pre-trained LLM with more data and having more parameters, like Mistral, Llama family models. For high-quality instruction datasets part, it is expected that high-quality datasets are diverse and representative enough to adapt the LLM to potential downstream usage. With the development of instruction tuning, there are more and more instruction datasets. Usually, these datasets are either annotated by human or proprietary LLMs. Currently, instruction data generally contains these types: (1) datasets are created by researchers from existing NLP dataset and incorporate an instruction for existing input-output pairs, like Flan, SuperNI, CoT and Orca. (2) open-end text generation, e.g., multi-turn dialogue and instruction following. Several open-end text generation datasets are created by human, like Dolly and Oasst1. Others are generated by proprietary models or human interaction with these models, like Self-instruct, Alpaca, Sharegpt, Baize, GPT4-Alpaca and Unnatural Instructions. (3) instructions build for domain-specific skills, like Code-Alpaca for code completion. Given such a diverse collection of instruction dataset, the challenge for instruction tuning lies in ensuring the quality of these instructional data samples. Zhou et al. [2023]\nLLM Data Selection. Since training LLM still request a lot of resources, data selection is often used for implementing efficient training. Also, several works stress the importance of high-quality data and thus triggered more research works focus on data selection. One popular way to select data samples this is to use an extra LLM to evaluate data samples. Chen et al. [2023a], Lu et al. calls ChatGPT API to tag or evaluate the quality of the instruction data. Also, several works make use of a reward model to assess the data quality. Wettig et al. [2024], Liu et al. intends to distill the preference of proprietary LLMs to small models for implementing efficient scalable data selection. This line of data selection methods is very expensive and suffers from interpretability. Another line of works focuses on using signals from the model itself to facilitate data evaluation and selection. Marion et al. , Li et al. make use of perplexity or its variants to determine if a data sample is good or not. Xia et al., Pan et al. use the gradients and influence function to find the data sample that best matches the validation set for downstream tasks evaluation. Li et al. , Cao et al. [2023] develops their own evaluation metric for assessing data samples. Compared to existing data selection works, our work focuses on selecting influential instruction data in a task-agnostic manner, which utilizes LLM gradients as data representation and perform data selection in each cluster of data separately."}, {"title": "3 Method", "content": "To tackle the challenging coreset selection problem for LLM's instruction tuning dataset, we propose Task-Agnostic Gradient Clustered Coreset Selection (TAGCOS), a task-agnostic coreset selection approach that effectively and efficiently discovers the informative subset from a large instruction tuning dataset. In this section, we first introduce the our formulation of coreset selection, which casts the task into a gradient matching problem. Then, we elaborate the detailed steps for coreset construction.\nNotation. Assume we have a pretrained LLM @ and a giant and diverse instruction dataset D := {(s, c)(i)}=1, where each data sample z = (s, c) comprises an instruction s and a completion c. For each data sample, the loss l(z; 0) is defined as the cross entropy between the prediction distribution p(\u00b7 | s) and the ground truth text response c. Since c often contains multiple tokens, l(z; 0) is calculated as the average of the token-wise cross entropy loss across the completion c. The notation et refers to the model checkpoint at step t.\nProblem Formulation. We first formulate the task into a gradient matching problem, i.e., the average gradient of the selected subset should approximate the gradient of the entire dataset. Intuitively, if the gradient is similar throughout all the training steps, the resulting model parameter should be closed to the model trained with the entire dataset.\nFormally, given a giant and diverse dataset D, our goal is to select a subset Dsub \u2286 D (|Dsub| < |D|) containing the most informative training samples. We expect that the gradients produced by the full training dataset \\sum_{z\\in D} \\nabla_{\\theta} l(z; \\theta) can be replaced by the gradients produced by a subset \\sum_{z\\in D_{sub}} \\nabla_{\\theta} l(z; \\theta) with the minimal difference:\n\n\nmin Err (\\nabla_{\\theta}L(D;\\theta),\\frac{1}{|D_{sub}|}\\sum_{z\\in D_{sub}}w_{z}\\nabla_{\\theta}l(z;\\theta))\ns.t.D_{sub} \\subseteq D,w_{z}\\geq0,|D_{sub}|\\leq M\n\nwhere L(D; 0) = , w is the subset weight vector, ||w||1 is the sum of the absolute values and Err(\u00b7, \u00b7) measures the distance between two gradients. Note that w could be either continuous, which leads to weighted training on the selected subset, or with discrete values, which reduces to regular training on the coreset.\nHowever, due to the high diversity of the large-scale instruction tuning dataset, simply conducting selection over the entire dataset potentially causes over-sampling in certain domains and under-sampling in others. To address this, we introduce clustering to ensure balanced sampling. By splitting the dataset into clusters and selecting samples from each cluster, we ensure a more even distribution across different domains.\nOverall, as illustrated in algorithm 1, the process for coreset construction could be summarized as follows: (1) compute the gradient features G = {gi |gi = Vol(z; 0)}. Inspired by Xia et al. [2024], we compute the low-dimensional approximations of gradient features for each data samples z over the whole dataset D; (2) perform gradient-based clustering, we perform k-means clustering [Hartigan and Wong, 1979] given the gradients features and get k clusters and corresponding centroids ce for each cluster, which effectively gathers the samples with similar characteristics into one cluster; (3) coreset selection via Optimal Matching Pursuit, we compute the data samples matches best with the centroids in each cluster with an orthogonal matching pursuit algorithm [Killamsetty et al., 2021]."}, {"title": "3.1 Gradient Features Computation", "content": "We perform an efficient gradient feature approximation computation over the entire dataset. To speed up gradient computation, we follow Xia et al. [2024] to use LoRA [Hu et al., 2022] and random projections [Park et al., 2023] to reduce the number of dimensions in gradient features. Meanwhile, we propose using checkpoints sampled before convergence to compute gradient features. This is inspired by the fact that the gradient norm calcuated during the warmup phase is significantly larger than checkpoints at convergence. Therefore, these gradient features encapsulate more essential information that reflects how each sample affect the model's updates. The effectiveness of this strategy is verified by results in table 5.\nAdam Gradient Computation Function. The gradients based on Adam optimizer [Kingma and Ba, 2015] can be computed with these steps:"}, {"title": "Gradient-based Clustering", "content": "Due to the diversity of instruction tuning dataset, direct sampling over the entire dataset may not cover all the regions, since the training samples from each domain are not evenly distributed. To further improve the effectiveness and robustness of data selection, we divide the entire dataset into several clusters and then perform gradient matching algorithm on each cluster itself. With the gradient features gi from the above step, we conduct K-means clustering on them to assign each data sample into a cluster {Ck}=1. Also, we can obtain cluster centroids {\u03bc\u03ba}=1 of these clusters during the clustering process, where each centroid shares the dimension with gradient features."}, {"title": "Coreset Selection via Optimal Matching Pursuit", "content": "In each cluster, we hope to get the subset that minimizes the difference between the selected subset and the whole cluster. Instead of doing heuristic selection like selecting all the instances with shortest distance with cluster centroids, we formalize this as an optimization problem and introduce an orthogonal matching pursuit (OMP) algorithm [Killamsetty et al., 2021, Elenberg et al., 2016] to solve it. Similar with equation 1, our objective is to minimize the difference between selected in k-th cluster and the whole cluster ,\n\n\nErr(w^{k},D_{sub}^{k};D^{k}) \\triangleq \\sum_{z \\in D_{sub}^{k}} w_{z}l(z;\\theta) -\\frac{1}{|D^{k}|}\\sum_{z \\in D^{k}} \\nabla_{\\theta}l(z;\\theta)\n\n\nConsidering the regularization coefficient \u03bb, we can have as:\n\nErr_{\\lambda}(w,D_{sub}^{k};D^{k}) \\triangleq Err(w,D_{sub}^{k},D^{k}) + \\lambda ||w||_{2}^{2}\n\nHere, we approximately regard the centroids of each cluster as the average gradients of the whole cluster,\n\n\\frac{1}{|D^{k}|}\\sum_{z \\in D^{k}} \\nabla_{\\theta}l(z;\\theta) = ce_{k}"}, {"title": "4 Theoretical Analysis", "content": "In this section, we analyse the benefits of our gradient clustering in coreset selection. The general conclusion is that coreset selection problem formulated in Problem (P) is essentially a Submodular Function Maximization (SFM) problem, which is NP-hard [Bach et al., 2013]. Solving large-scaled submodular function maximization problems is extremely challenging, potentially leads to inferior solution. Our gradient clustering strategy naturally decomposes the original problem into several small scaled problems, significantly reduces the difficulty in optimization, making finding solutions with high-precision possible. The detailed results are presented in the following theorems. These theorems are adapted from the classical analysis on OMP, which can be found in the studies [Elenberg et al., 2018, Wolsey, 1982]. We adopt them to understand the superiority of our coreset selection approach.\nTo unify the problems of coreset selection with and without clustering, we extend the problem (P-k) as follows:\n\n\nmax F_{\\lambda}(D_{sub}; D),\ns.t.,|D_{sub}|\\leq M and D_{sub} \\subseteq D\n\nwhere Dsub and D are the coreset and the full dataset, respectively. c is the constant to control the coreset size.\nLemma 1. If the coreset size |Dsub| \u2264 cand maxz\u2208D ||\u2207ol(z; 0) ||2 \u2264 G, then F\u03bb(Dsub; D) is \u03b3D-weakly submodular with YD = X+MG2.\nTheorem 1. If maxz\u2208D ||\u2207ol(z; 0)||2 < G and maxzeDk ||\u2207ol(z;0)||2 < Gk for cluster k. Let D*ub and De be the optima of Problems P and P \u2013 k, with k = 1, . . ., K. Then, the followings hold:\n(i) For problem (P), OPM runs with stopping criteria Fx(Dsub; D) \u2264 \u0454 achieves set with |Dsub| <.\n(ii) For problem (P-k), OPM runs with stopping critia Fx(Dub; Dk) \u2264 \u0454k achieves set withDub<.\nSince YD = and YD =dkG, it can be expected that \u03b3D \u226a\u03b3D. Noting that a proper clustering method would make = and it is reasnonable to set to ensure comparable precisions. Thus the above theorem demonstrates that\n\nlog() << log().\nThat is, to achieve comparable accuracy, the union of the coreset selected from each cluster can be much smaller than that from the whole datasets, which verifies the benefits of gradient clustering. This is also consistent with our experimental observation. i.e., the running time of OMP without gradient clustering is significantly longer than that with gradient clustering."}, {"title": "5 Experiment", "content": "In this section, we conduct experiments to answer the following research questions:\nDoes TAGCOS achieve superior performance over other unsupervised selection methods? (Table 1)\nHow effective is the generalization of TAGCOS, and can it be transferred to different models? (Table 2)\nWhat is the best configuration for TAGCOS, including the selection proportion, the number of clusters, and the selection of gradient checkpoints? (Table 3, Table 4, Table 5)"}, {"title": "5.1 Setup", "content": "Datasets. To illustrate that TAGCOS is task agnostic, we chose diverse tasks for both training and evaluation. For the training set, we combined 17 popular instruction datasets totaling 1,068,549 examples, following Wang et al. [2023a], Ivison et al. [2023]. These datasets vary in format and reasoning tasks, with annotations by humans or the OpenAI API. For details, please refer to Appendix.\nFor evaluation, we selected TydiQA, MMLU , and BBH. TydiQA is a multilingual QA benchmark covering 11 languages, requiring models to extract answers from passages given a question. F1 is used to as the evaluation metric here. MMLU features multiple-choice questions across 57 subjects, from elementary to professional levels. It asks LLM to select a single correct answer given several options. Accuracy is used as the metric here. BBH includes 23 challenging tasks from Big-Bench, testing general reasoning skills.\nImplementation Details. Following Xia et al. [2024], we performed warmup training on a randomly selected 5% of the dataset for 4 epochs and computed 8192-dimensional gradient features on the full dataset D. The learning rate for warmup training was set to 2e-5, with a batch size of 32. Using these gradient features, we selected 5% of the original dataset using our selection methods, totaling approximately 53,427 samples. We used 100 clusters for K-means clustering and set the OMP algorithm tolerance at 0.01. After obtaining the subset, we fine-tuned the Llama-2-7B [Touvron et al., 2023] and Mistral-7B models using LoRA to reduce memory usage. For LoRA training, we used the AdamW optimizer with a learning rate of 2e-5 and 4 epochs. The context length was set to 1,024, with a batch size of 32."}, {"title": "5.2 Experimental Results", "content": "Baseline. The main experiment results are presented in Table 1. Several baselines were considered for comparison: (1) Uniform: randomly selecting the data samples from the original dataset. (2) Hardest Sampling: select the data samples with the highest perplexity. (3) Perplexity Sampling select the data samples with the lowest perplexity. (4) K-Center-Greedy with different representations: converting instruction data into embedding vectors, performing K-means clustering, and selecting samples by iteratively choosing the one closest to the cluster center among the remaining instances. Here, we consider 3 different embedding spaces, BERT , Llama and Gradient. We denote them as K-CenterBERT , K-CenterLlama and K-CenterGrad. (5) OMP: using the OMP algorithm over the entire dataset, with the mean gradient feature across the dataset as the matching target."}, {"title": "5.3 Ablation Study and Analysis", "content": "Performance of TAGCOS on Different Models. Table 2 demonstrates that the dataset generated by the Llama-2-7B model can be effectively utilized to train a superior Mistral-7B instruction model. By leveraging the datasets selected by TAGCOS on the Llama-2-7B model, the trained Mistral-7B model shows significant improvements over uniform selection methods, consistently outperforming its counterparts. This highlights TAGCOS's ability to identify transferrable and valuable data samples, indicating its potential for future proxy data selection tasks.\n5% data can achieve comparable results with full dataset. Table 3 reveals that training with only 5% of the data selected by TAGCOS results in performance comparable to that of the entire dataset. This can be attributed to the presence of noisy samples in the full dataset, which are less effective for fine-tuning.\nHow to determine the cluster numbers. Table 4 shows that the ideal cluster number for our setup is 100. Fewer clusters, especially less than the original dataset size of 18, fail to achieve good results. Additionally, merely increasing the number of clusters does not ensure improved performance. TAGCOS tends to degrade to plain OMP as the number of clusters increases. When the cluster count matches the number of samples, the performance is identical to plain OMP."}, {"title": "6 Conclusion", "content": "This paper focuses on the effective selection of coresets for LLMs in instruction tuning. To address the challenge of accurate data representation, we utilize gradient features, which indicate the influence of each data sample on the training process. Additionally, to handle diverse collections of instruction data and ensure selection efficiency, we propose clustering similar data and applying an efficient greedy algorithm for selection. Our experimental results demonstrate the effectiveness of the entire pipeline."}, {"title": "7 Limitation", "content": "Despite its impressive performance, TAGCOS is bottlenecked by the efficiency of gradient feature estimation. The gradient feature computation stage limits its scalability to larger datasets. To effectively run TAGCOS on extensive datasets, improvements in the efficiency of gradient computation are needed."}, {"title": "A Training Dataset Details", "content": "In this section, we provide the detailed sources, statistics and licenses of each training dataset used in our experiment, which is shown in table 6. We conduct coreset selection from a mixture of 17 instruction tuning datasets with various scales and properties, which demonstrates superior effectiveness compared with baseline approaches."}]}