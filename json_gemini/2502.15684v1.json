{"title": "An Agent Framework for Real-Time Financial Information Searching with Large Language Models", "authors": ["Jinzheng Li", "Jingshu Zhang", "Hongguang Li", "Yiqing Shen"], "abstract": "Financial decision-making requires processing vast amounts of real-time information while understanding their complex temporal relationships. While traditional search engines excel at providing real-time information access, they often struggle to comprehend sophisticated user intentions and contextual nuances. Conversely, Large Language Models (LLMs) demonstrate reasoning and interaction capabilities but may generate unreliable outputs without access to current data. While recent attempts have been made to combine LLMs with search capabilities, they suffer from (1) restricted access to specialized financial data, (2) static query structures that cannot adapt to dynamic market conditions, and (3) insufficient temporal awareness in result generation. To address these challenges, we present FinSearch, a novel agent-based search framework specifically designed for financial applications that interface with diverse financial data sources including market, stock, and news data. Innovatively, FinSearch comprises four components: (1) an LLM-based multi-step search pre-planner that decomposes user queries into structured sub-queries mapped to specific data sources through a graph representation; (2) a search executor with an LLM-based adaptive query rewriter that executes the searching of each sub-query while dynamically refining the sub-queries in its subsequent node based on intermediate search results; (3) a temporal weighting mechanism that prioritizes information relevance based on the deduced time context from the user's query; (4) an LLM-based response generator that synthesizes results into coherent, contextually appropriate outputs. To evaluate FinSearch, we construct FinSearchBench-24, a benchmark of 1,500 four-choice questions across the stock market, rate changes, monetary policy, and industry developments spanning from June to October 2024. Experiments demonstrate that FinSearch can outperform Perplexity Pro by 15.93% with GPT40, 14.06% with LLama3.1-405B, and 21.6% with Claude3.5-Sonnet. The code is available at https://github.com/eeeshushusang/FinSearch.", "sections": [{"title": "I. INTRODUCTION", "content": "Accessing accurate and timely information is important for making informed decisions in finance [1], [2]. The dynamic nature of financial data, with stock prices updating by the minute and complex interdependencies between market factors, requires search methods that can efficiently integrate and analyze real-time information from diverse sources [3]. Traditional search engines, while providing access to real-time information, often fail to capture the nuanced relationships and temporal dependencies inherent in financial analysis [4], [5]. Moreover, users struggle to express complex analytical needs through simple keywords, necessitating multiple iterations of query refinement, which can introduce delays in information access and potentially missing critical market signals. Furthermore, the need to initiate new search sessions for exploring related concepts creates a fragmented analytical process, hampering the comprehensive understanding of market dynamics and increasing the risk of overlooking important financial relationships [6].\nLarge Language Models (LLMs) have enabled natural language understanding and generation, offering capabilities that complement traditional search functionalities [7]. Their ability to comprehend implicit context, extract key elements from natural language descriptions, and engage in multi-turn dialogues addresses many limitations of keyword-based search. Additionally, LLMs excel at understanding user intent, automatically expanding queries, and refining responses based on user feedback. However, LLMs operate on static training data and therefore lack access to real-time information, leading to outdated analysis and potential hallucinations when addressing queries about current market conditions in finance [8].\nTherefore, recent advances have highlighted the potential value of integrating search capabilities with LLMs to create Al agents capable of processing and responding to queries using real-time information [9]. MindSearch [10] represents an initial step in this direction, introducing an AI agent framework for general search that systematically decomposes complex queries into detailed sub-queries. However, its application to financial queries reveals three limitations. First, while MindSearch effectively utilizes general web search APIs such as Google and Microsoft Bing, it lacks integration with specialized financial data sources such as market data feeds, stock APIs, and financial news databases, which are essential for comprehensive financial analysis. Second, its query structure remains static throughout the search process. In other words, once decomposed, sub-queries do not adapt based on intermediate search results, limiting their ability to respond to the dynamic nature of financial markets where new information can alter the relevance of previous queries. Third, although MindSearch can process temporal information, it does not incorporate sophisticated temporal weighting mechanisms needed for financial applications where the importance of information varies based on its recency and relationship to market events. While subsequent work MMsearch [11] has extended MindSearch's capabilities to handle multi-modal scenarios, these fundamental limitations in handling financial data remain unaddressed. Even commercial AI search products"}, {"title": "II. METHODS", "content": "FinSearch is a search agent framework specifically designed for finance, that generates both textual analysis and visual outputs, such as k-line charts, in response to complex search queries. FinSearch centers on a directed acyclic graph (DAG) structure, which we term a search graph, constructed by an LLM-based search pre-planner to represent the multi-step search process and store intermediate results. Within the search graph, each node encapsulates a sub-query, which is a focused, atomic search component targeting specific aspects of the original complex query. These sub-queries are precisely mapped to designated financial data sources through selected APIs. The directed edges between nodes represent both logical dependencies and temporal relationships between search components, creating a structured analytical pathway. Following the initial graph construction, the search executor processes the sub-queries sequentially across nodes while dynamically optimizing subsequent queries for child nodes based on accumulated results to ensure that each successive search step builds upon and refines the insights gained from previous queries. After completing the graph traversal, the temporal weighting mechanism applies time-aware weights to each node, ensuring that information is prioritized according to its chronological relevance to the user query. This temporal context is important for financial analysis, where the value of information often varies significantly with time. The final component, the response generator, synthesizes the temporally weighted information collected across the search graph into comprehensive analytical responses with LLM. The overall framework of FinSearch is depicted in Fig. 1."}, {"title": "B. Search Pre-Planner", "content": "The search pre-planner decomposes complex financial search queries into structured, executable sub-queries. The process begins with semantic parsing, where an LLM analyzes the user query to extract key elements including temporal indicators t, corporate entities, and financial events. The pre-planner gives particular attention to temporal expressions, automatically converting relative time references (e.g., \u201cyester-day\u201d, \"last Friday\") into precise dates to ensure temporal consistency throughout the subsequent search process. Following semantic extraction, the pre-planner employs a human-inspired reasoning process to break down complex financial queries into sub-queries. For instance, when analyzing a company's performance, the pre-planner might generate sequential sub-queries examining historical stock prices, recent earnings reports, market sentiment from news sources, and broader industry trends. Correspondingly, each generated sub-query is precisely mapped to one of three specialized APIs: a news API for real-time information access, a search API for general market context, and a finance API for specialized financial data retrieval.\nTo orchestrate this multi-step search process, the pre-planner constructs a search graph, represented as a DAG G(Vi, Eij)."}, {"title": "C. Search Executor with Dynamic Query Rewriter", "content": "The search executor processes the search graph generated from the pre-planner while continuously optimizing the search trajectory via the dynamic query rewriter. For search execution, the executor traverses each node in the search graph sequentially. For each node, the executor generates API call codes based on the node's sub-query $x_{query,i}$ and designated API $x_{API,i}$. The API execution process can be formalized as:\n$x_{response,i}, x_{t,i} = execute(x_{query,i}, x_{API,i})$ (1)\nwhere execute represents the API calling function that returns both the search results $x_{response, i}$ and their associated temporal information $x_{ti}$ directly from the API response.\nThe dynamic query rewriter enables adaptive search behavior that mirrors human analytical processes. After each node execution, an LLM-based rewriter evaluates both the retrieved results and the current state of the planning graph to optimize subsequent sub-queries. This adjustment process can be formally represented as:\n$P(x_{query, i}|x_{query,i}) = rewriter(x_{query, i}, x_{response, i}, G)$ (2)\nwhere $x_{query, i}$ denotes the current sub-query, $x_{query,}$ for the revised sub-query, $x_{response, i}$ represents the obtained result, and rewriter is the rewriter LLM that optimizes queries for subsequent iterations. This Markov chain-inspired approach allows FinSearch to adapt its search strategy based on accumulated insights continuously."}, {"title": "D. Temporal Weighting Mechanism", "content": "The temporal weighting mechanism ensures that recent information receives appropriate emphasis while historical context remains accessible when relevant [12]. The mechanism operates by assigning temporal weights $x_{weight,i}$ to each node based on its proximity to the query timestamp. For each node $V$ in the search graph, the temporal weight weight, i is computed using a time-decay function that considers the temporal distance between the information timestamp t and the query timestamp $x_{t,i}$:\n$x_{weight, i} = \\begin{cases}\n  \\frac{24}{|t - x_{t,i}|}, & \\text{if } |t - x_{t,i}| < 72 \\\\\n  0, & \\text{if } |t - x_{t,i}| \\geq 72\n\\end{cases}$ (3)"}, {"title": "E. Response Generator", "content": "The response generator synthesizes information from the temporally weighted search graph to produce comprehensive analytical outputs that combine textual analysis with visual representations by LLM. The generation process begins with information aggregation across all graph nodes, with each node's content being weighted according to its temporal relevance as determined by the temporal weighting mechanism. The generator performs reduplication to eliminate redundant information while preserving the unique temporal and analytical context of each data point. The textual component of the response adheres to strict citation protocols, ensuring that all insights are properly attributed to their respective sources. The generator maintains precise temporal context throughout the narrative, organizing information chronologically while emphasizing recent, highly weighted developments that are most relevant to the user's query. For quantitative financial data, the generator incorporates interactive visualizations, particularly k-line charts obtained through the finance API, which display comprehensive trading information including daily opening, closing, high, and low prices represented through candlestick patterns. The final output integrates these textual and visual elements into a structured analytical report, with visualizations positioned strategically to support the narrative flow. Each component of the response is temporally contextualized, ensuring that users understand both the chronological sequence of events and their relative importance to the current analysis."}, {"title": "III. EXPERIMENTS", "content": "Following the previous design such as GTA [13] and CF-BenchMark [14], we developed FinSearchBench-24, a benchmark comprising 1,500 multiple-choice questions spanning diverse financial topics spanning across June to October 2024. Specifically, we implemented a four-phase construction process to ensure question quality, temporal relevance, and real-world applicability. In the first phase, we collected current financial data from authoritative sources including government policy announcements, central bank communications, corporate earnings reports, and major financial news outlets,"}, {"title": "B. Implementation Details", "content": "We implemented FinSearch using Python 3.10.4 with multiple LLM backbones to evaluate performance across different model architectures. For our experiments, we tested five LLMs: GPT-40, Llama3.1-405B, Claude3.5-Sonnet, Deepseek, and Gemini-1.5-Flash. Each model was accessed through its API using standard configurations without additional fine-tuning. The search pre-planner and dynamic query rewriter components were implemented using identical prompting templates across all LLM backends to ensure a fair comparison. For financial data retrieval, we integrated three categories of APIs: Yahoo Finance API for market data and stock information, NewsAPI for real-time financial news, and GoogleSearch API for general web search capabilities. The Yahoo Finance API was specifically configured to retrieve historical price data, company fundamentals, and market indicators with a sampling rate of one minute for real-time data. The graph nodes were designed as Python objects."}, {"title": "C. Results", "content": "The experimental results in Table II demonstrate that our proposed FinSearch outperforms existing search agent methods across multiple LLM architectures. FinSearch achieves superior accuracy compared to baseline approaches and state-of-the-art search agents while maintaining reasonable computational efficiency. When examining accuracy metrics, FinSearch consistently delivers the strongest performance across all tested LLM backends. With GPT-40, FinSearch achieves 76.20% accuracy, representing a 15.93% improvement over Perplexity Pro (60.27%) and a substantial 23.80% gain over MindSearch (52.40%). Similar patterns emerge with other LLM architectures, e.g. using Llama3.1-405B, FinSearch attains 75.53% accuracy compared to Perplexity Pro's 61.47%, while with Claude3.5-Sonnet, FinSearch reaches 78.27% accuracy versus 56.67% for Perplexity Pro. The framework also demonstrates robust performance with newer LLM architectures, achieving 72.33% and 74.87% accuracy with Deepseek and Gemini-1.5-Flash respectively, though comparative data for Perplexity Pro is not available for these models. Regarding computational efficiency, FinSearch maintains reasonable processing times despite its more sophisticated search and analysis capabilities. While SearchAgent shows the fastest"}, {"title": "D. Ablation Study", "content": "To evaluate the individual contributions of FinSearch's core components, we conducted an ablation study examining the impact of the temporal-weighting mechanism and dynamic query rewriter. Table III presents the results across different LLM architectures, demonstrating that both components contribute to the framework's overall performance. The temporal-weighting mechanism emerges as the more impactful component, yielding substantial accuracy improvements when implemented alone. For instance, with GPT-40, incorporating only the temporal-weighting mechanism increases accuracy from 58.67% to 72.87%, representing a 14.20% improvement. Similar gains are observed across other LLM architectures, with improvements ranging from 12.80 to 14.87 % points. This confirms our hypothesis that temporal context plays an important role in financial information processing. While showing a more modest individual impact, the dynamic query rewriter still provides meaningful performance improvements. When implemented in isolation, it improves accuracy by 3.66 % with GPT-40 (from 58.67% to 62.33%) and demonstrates consistent gains across all LLMs. This suggests adaptive query refinement helps capture more relevant information during the search process. Most notably, combining both components produces synergistic effects, achieving the highest accuracy across all LLM configurations. With both components active, FinSearch reaches a peak performance of 78.27% accuracy using Claude3.5-Sonnet, representing a 17.47% improvement over the baseline configuration without either component. This synergy indicates that temporal awareness and dynamic query adaptation work complementarily to enhance search effectiveness. We provide a case study in Fig. 2. Regarding computational efficiency, the full configuration with both components demonstrates improved processing times compared to partial implementations in most cases. For example, with Claude3.5-Sonnet, the complete system processes queries in 18.15 seconds on average, compared to 26.64 seconds for the baseline configuration. This suggests that the additional components help focus the search process more effectively, potentially reducing unnecessary computational overhead."}, {"title": "IV. CONCLUSION", "content": "This paper introduces FinSearch, a novel search agent framework specifically designed to address the unique challenges of financial information retrieval and analysis. FinSearhc's innovations include an LLM-based multi-step search pre-planner that decomposes complex financial queries through graph representation, a dynamic query rewriter that adaptively refines searches based on intermediate results and a temporal weighting mechanism that ensures appropriate prioritization of time-sensitive financial information. Our extensive experimental evaluation on the newly developed FinSearchBench-24 dataset demonstrates FinSearch's superior performance across multiple LLM architectures. Looking forward, this work opens several promising directions for future research. FinSearch could be extended to support additional financial data sources and analysis types, while the temporal weighting mechanism could be refined to better handle different time horizons and market conditions. We believe FinSearch represents a step forward in developing specialized search agents for financial applications, demonstrating how careful integration of LLM capabilities with domain-specific requirements can yield substantial improvements in search accuracy and relevance."}]}