{"title": "A Learnable Multi-views Contrastive Framework with Reconstruction Discrepancy for Medical Time-Series", "authors": ["Yifan Wang", "Hongfeng Ai", "Ruiqi Li", "Maowei Jiang", "Cheng Jiang", "Chenzhong Li"], "abstract": "In medical time series disease diagnosis, two key challenges are identified. First, the high annotation cost of medical data leads to overfitting in models trained on label-limited, single-center datasets. To address this, we propose incorporating external data from related tasks and leveraging AE-GAN to extract prior knowledge, providing valuable references for downstream tasks. Second, many existing studies employ contrastive learning to derive more generalized medical sequence representations for diagnostic tasks, usually relying on manually designed diverse positive and negative sample pairs. However, these approaches are complex, lack generalizability, and fail to adaptively capture disease-specific features across different conditions. To overcome this, we introduce LMCF (Learnable Multi-views Contrastive Framework), a framework that integrates a multi-head attention mechanism and adaptively learns representations from different views through inter-view and intra-view contrastive learning strategies. Additionally, the pre-trained AE-GAN is used to reconstruct discrepancies in the target data as disease probabilities, which are then integrated into the contrastive learning process. Experiments on three target datasets demonstrate that our method consistently outperforms other seven baselines, highlighting its significant impact on healthcare applications such as the diagnosis of myocardial infarction, Alzheimer's disease, and Parkinson's disease. We release the source code at xxxxx.", "sections": [{"title": "1 Introduction", "content": "Medical time series data plays a critical role in various healthcare applications, ranging from disease diagnosis to patient monitoring, including electroencephalography (EEG), electrocardiography (ECG), blood pressure monitoring, respiratory rate tracking, oxygen saturation (SpO2) measurements, and more.However, the inherent complexity and variety of these signals make the process of labeling not only time-consuming but also requiring expert knowledge, typically from clinicians, to manually annotate the data. This limitation makes it particularly difficult to apply deep learning techniques, which generally rely on large amounts of labeled data to achieve optimal performance.To overcome the challenge of limited labeled data in time series, self-supervised contrastive learning has emerged as a compelling and effective approach. Recent works [16, 6, 14] have demonstrated the effectiveness of contrastive learning in medical time series across various applications. Different from computer vision where each image is a sample and the positive or negative sample is certainly at the image-level, the data in medical time series is organized hierarchically [3]. For instance, TS2Vec [28] hierarchically distinguishes positive and negative samples across both instance-wise and temporal dimensions. CLOCS [12] divides the entire patient's data into two levels: Temporal Invariance and Spatial Invariance. COMET [26] divides medical data into four levels: Patient, Trial, Sample, and Observation, to capture information at different granularities. However, in the context of using medical time series data for disease diagnosis, two key issues have emerged based on prior work. The first issue is the reliance on single-center datasets, which introduce regional biases and limit model generalizability.These datasets often have small sample sizes and lack diversity, making it difficult to apply models to other healthcare environments[4].The sequence patterns of normal patients in external data encompass rich knowledge that enhances the diversity and representativeness of the dataset, mitigating the biases inherent in single-center data. The second issue is that the primary challenge of contrastive learning lies in constructing positive and negative samples [17]. Many existing studies attempt to address this by manually designing diverse contrastive dimensions to capture temporal information at varying granularities, leveraging self-supervised learning to derive representations that improve the generalization performance of downstream label-limited tasks. However, unlike images or texts, medical time series data exhibit more subtle and complex variations, making it inherently difficult to manually define comprehensive and accurate positive and negative sample pairs [18]. This process is not only labor-intensive but also constrained in its ability to fully capture the intricate characteristics of medical time series, ultimately limiting its effectiveness in real-world applications.In this paper, we propose a novel approach LMCRD to address the aforementioned challenges. The key contributions of this work can be summarized as follows:"}, {"title": "2 Related work", "content": "In recent years, research on optimizing models using multi-center medical datasets has garnered increasing attention [25, 15, 2]. These researches are motivated by the fact that deep learning models often overfit when trained solely on data from a single medical center. Especially for the medical time series datasets, such as those involving EEG and ECG, often lack sufficient scale and comprehensive annotations. While domain adaptation [10, 2] is proposed for mapping features from the external domain to a similar feature space of the target domain and then using the classifier from the data-rich source domain to classify data in the data-scarce target domain. This method has limitations in the context of medical time series. Specifically, the difference in the scale of data between the external and target domains is not always significant. As a result, leveraging external data to enhance the performance of models trained on the target domain has become a preferred strategy. Therefore, transferring knowledge across centers to improve model performance on the target center's data distribution is an important direction for our current work."}, {"title": "2.2 Contrastive learning for time series", "content": "Self-supervised learning leverages unlabeled data to pretrain models, enabling them to capture temporal dependencies and meaningful features without relying on costly annotations. Kexin Zhang et al. [29] classify time series self-supervised learning (SSL) methods into three main categories: generative-based methods, contrastive-based methods, and adversarial-based methods. For contrastive-based methods, existing works [5, 7, 8, 28, 16] focus on how positive and negative samples are generated based on data characteristics as Appendix A.1.Most methods employ data augmentation techniques to generate different views of an input sample, learning representations by maximizing the similarity between views of the same sample while minimizing the similarity between views of different samples. However, the aforementioned methods rely on manually constructing positive and negative sample pairs. In contrast, adaptive contrastive learning has emerged as a promising direction in contrastive learning, exemplified by methods like LNT[22], which introduces Dynamic Deterministic Contrastive Loss to enable models to adaptively learn diverse positive and negative sample representations. This approach is particularly beneficial for capturing the multi-scale nonlinear dynamics and individual variability inherent in medical time series data."}, {"title": "3 Preliminaries and Problem Formulation", "content": "Let the dataset of medical time series be denoted as D, where each series of data originates from a corresponding subject s and trial r. Each subject s participates in multiple trials r. Due to the lengthy nature of medical sequence data, they are segmented into several shorter sequence fragments. The segmented sequence samples \tildexi\u2208 RTF are input to the model, with T denoting the sequence duration and F the feature dimension. To facilitate a deeper understanding, Appendix A.1 provides a detailed explanation of the hierarchical structuring of medical time series, illustrated using EEG signals from Alzheimer's disease as a case study. The external dataset D' is collected for the same medical task as the target dataset D, but they originate from different centers. Nonetheless, they share similar feature characteristics, which ensures the applicability of D' in the knowledge transfer to our target domain.\nAs shown in Figure 1, our training process consists of three stages. First, we pretrain an AE-GAN model using data from normal patients in D', whose samples are expressed as x. Next, we use the pretrained AE-GAN model to perform inference on all samples in D, whose samples are expressed as xi, obtaining reconstruction error as additional feature. The feature is then merged with the raw data, resulting in a feature-augmented dataset with the number of features increased from F to F + 1. This augmented dataset proceeds to the second stage of self-supervised learning. During this stage, through contrastive learning, we obtain an encoder ELMCRD with a multi-head attention block and its embedding space is shown in Figure B3. This encoder generates representations hi \u2208 RTC with C dimensions, and view-level representations gi\u2208 RTV\u00d7d with V views and d dimensions for each view. These representations are then used in the third stage of supervised learning to fine-tune specific scenarios."}, {"title": "4 Method", "content": "To overcome the limitations in medical time-series analysis, such as data scarcity, heterogeneity, and class imbalance, we introduce a two-stage framework that combines anomaly detection with a learnable multi-view contrastive learning strategy. The first stage leverages an AE-GAN model to perform knowledge transfer by capturing the normal data distribution from external datasets and generating enriched feature representations, which mitigate heterogeneity and data limitations in the target dataset. Building on these augmented features, the second stage employs a Learnable Multi-Views Contrastive Framework (LMCF) to extract diverse and robust temporal representations through multi-level contrastive learning. This includes subject-wise, trial-wise, epoch-wise, and temporal-wise views, complemented by inter-view and intra-view contrastive mechanisms. The overall workflow of the framework is depicted in Appendix B2 and detailed in the subsequent sections."}, {"title": "4.1 AE-GAN", "content": "To address the challenges of data scarcity and data heterogeneity in medical time series (A.2), we propose a knowledge transfer framework based on anomaly detection. This framework leverages knowledge from external datasets to enhance the feature representation of the target dataset, thereby improving the model's classification performance. Specifically, we introduce a hybrid model, AE-GAN [13, 27], which combines a Generative Adversarial Network (GAN) and an Autoencoder (AE). The AE-GAN model learns the distribution of normal samples from the external dataset and generates high-quality feature representations for normal data. These representations are then used to perform feature augmentation on the target dataset, transferring prior knowledge about normal samples from the external dataset to the model. This approach effectively mitigates challenges such as limited data size, class imbalance, and multi-center distribution differences. In this way, our framework provides a more robust and generalizable model for medical diagnosis. The AE-GAN model consists of two key components: a generator with an encoder-decoder architecture and a discriminator. The generator learns to reconstruct normal data by training on normal samples from the external dataset, while the discriminator distinguishes between real and generated samples. Through training on the external dataset, the model captures the underlying distribution of normal data and uses this knowledge to enhance the feature representation of the target dataset. This process not only enriches the feature space but also effectively addresses the issues of data scarcity and heterogeneity. In the following sections, we will use the external dataset as an example to detail the structure of the AE-GAN model, its training process, and how it achieves knowledge transfer (or feature augmentation) for the target dataset."}, {"title": "4.1.1 Generator", "content": "The generator Ggen is composed of an encoder Egen and a decoder Dgen, which work together to learn the distribution of healthy samples x from the external dataset D'. In details, The encoder maps the healthy samples x to a latent space representation and the decoder reconstructs the data from the representation to the generated data x:\n\n\nx = Ggen(x) = Dgen(Egen(x)) \tildex=\\G_{gen}(x)=D_{gen}(E_{gen}(x))x = Ggen(x) = Dgen(Egen(x))(1)\n\nThe generator is trained to minimize the reconstruction loss, ensuring that the generated data x closely approximates the original healthy samples x. This enables the generator to capture the underlying distribution of healthy data, which is critical for subsequent feature augmentation and knowledge transfer."}, {"title": "4.1.2 Discriminator", "content": "The discriminator Ddis is responsible for distinguishing between real healthy samples x from the external dataset D' and generated data x. The output of Ddis represents the probability that the sample is from healthy subject. The details about the loss function can be seen in D."}, {"title": "4.1.3 Inference on Internal Data", "content": "After pretraining, we use the AE-GAN model to perform inference on all samples xi on our target dataset. The specific steps are as follows:\ni. Input Internal Data \u0161\u012f: The samples xi from the target dataset are fed into the pretrained generator Ggen \u00b7\nii. Compute Reconstruction Error E: The generator G reconstructs the samples xi, and the reconstruction error E is computed as:"}, {"title": null, "content": "E = MSE(Ggen (xi), xi) E=MSE(G_{gen}(x_i),x_i) E = MSE(Ggen (xi), xi)(2)\n\nSince the generator is pretrained on healthy samples \u2717 from D', the reconstruction error & is smaller for healthy samples x, in the target dataset and larger for abnormal samples xi. Thus, the magnitude of E indirectly reflects the abnormality of the sample xi, i.e., the probability of disease.\niii. Feature Augmentation: The reconstruction error E is concatenated with the original features xi of the target dataset to form an augmented feature set:\n\n\nxi = concat(xi, E) x_i=\\text{concat}(x_i,E) xi = concat(xi, E)(3)\n\nThe augmented dataset xi is used for subsequent model development."}, {"title": "4.2 Learnable Multi-views Contrastive Framework", "content": "In the subsequent phase of our research, we harness the power of contrastive learning, a self-supervised learning technique, to generate series representations. The encoder ELMCRD of our approach is designed with two components.\nThe first component is a dilated convolutional network h(x), which broadens the receptive field of the sequence. This network is crucial for capturing a broader range of information and enhancing the generalizability of the temporal representations. On the other hand, inspired from the local transformations to craft diverse data views in the latent space for contrastive learning [22], we recognized that MHA can significantly reduce the manual cost of designing positive and negative sample pairs from different perspectives of data. Consequently, we incorporated a second component into our encoder, which is our innovative learnable multi-views network g(x). It introduces MHA to contrastive learning for extracting varying view representations adaptively. By leveraging both inter-wise and intra-wise contrastive losses, we ensure that the representations not only encompass diverse views but also exhibit distinct separability among different subjects within each view as Figure 2 shown.\nFurthermore, to capture the intrinsic hierarchical information embedded in medical data, we adopt the concept from COMET [26]. Our contrastive learning considers subject, trial, epoch, and timestamp, and optimizes the model using multiple InfoNCE losses [21]. Ultimately, we obtain representations that are beneficial for downstream medical time-series tasks."}, {"title": "Subject-wise Contrastive Loss Ls:", "content": "Subject may exhibit unique physiological characteristics and pathological variations. Consequently, the subject-wise contrastive learning is designed to enhance the discriminative representation of subject-specific features by increasing the similarity among samples from the same subject and the separability among samples from different subjects.Specifically, let xi,s denote the i-th anchor sample in the given batch, which is from subject s. The positive sample set St for xi,s consists of all other samples xj,s+ with the same subject s+. Correspondingly, the negative sample set S\u0129 includes all samples xj,s- from different subjects s\u00af. Based on this delineation of positive and negative samples, we define the subject-level contrastive loss function as follows:"}, {"title": "Subject-wise Contrastive Loss Ls:", "content": "Subject may exhibit unique physiological characteristics and pathological variations. Consequently, the subject-wise contrastive learning is designed to enhance the discriminative representation of subject-specific features by increasing the similarity among samples from the same subject and the separability among samples from different subjects.Specifically, let xi,s denote the i-th anchor sample in the given batch, which is from subject s. The positive sample set St for xi,s consists of all other samples xj,s+ with the same subject s+. Correspondingly, the negative sample set S\u0129 includes all samples xj,s- from different subjects s\u00af. Based on this delineation of positive and negative samples, we define the subject-level contrastive loss function as follows:"}, {"title": "Trial-wise Contrastive LoSS LR:", "content": "Trials may demonstrate distinctive experimental conditions and variations in outcomes. To address this, trial-wise contrastive learning enhances trial-specific feature representation by promoting similarity within trials and separability between trials.\nConcretely, assume xir represent the i-th anchor sample in the batch, sourced from trial r. The set of positive samples R\u2021 associated with xi,r encompasses all other samples xj,r+ that are from the same trial r+. Conversely, the set of negative samples R\u012b consists of all samples xj,r- originating from different trials r\u00af. Therefore, we establish the trial-wise contrastive loss function as below:"}, {"title": null, "content": "LR = \u03a3\u03a3 log exp (s(hi,r, hj,r+)/T)i=1 xj,r+ER+Exjr-er exp (s(hir, hj,r-)/T)L_R = \\sum_i \\sum_{x_{j,r^+} \\in R^+} \\log \\frac{\\exp (s(h_{i,r}, h_{j,r^+})/\\tau)}{\\sum_{x_{j,r^-} \\in R^-} \\exp (s(h_{i,r}, h_{j,r^-})/\\tau)}LR\u200b=i\u2211\u200bxj,r+\u200b\u2208R+\u2211\u200blogExj,r\u2212\u200b\u2208R\u2212\u2211\u200bexp(s(hir\u200b,hj,r\u2212\u200b)/\u03c4)exp(s(hi,r\u200b,hj,r+\u200b)/\u03c4)\u200b(4)\n\nwhere, hi,r denotes the representation obtained by applying the network h(x) to the sample xi,r, formally expressed as hi,r = h(xi,r). Consistent with this notation, hj,r+ and hj,r- represent the feature representations resulting from the application of h(x) to the corresponding positive and negative samples xj,r+ and xj,r-."}, {"title": "Epoch-wise Contrastive LOSS LE:", "content": "For epoch-wise contrastive learning, our hypothesis is that a sample which undergoes minor modifications, like temporal masking, should maintain a similar pattern compared to other sample. Hence, for each sample xi in batch, we employ a data augmentation strategy that is random continuous masking. This strategy involves applying two independent augmentations to xi, resulting in augmented samples and . Since these augmented samples originate from the same anchor sample xi, they are encouraged to have high similarity between their feature representations and are considered as positive pair (,). In contrast, negative sample pairs are formed from augmented samples derived from different anchor samples, such as (x,x) and (x,x). Finally, the epoch-level loss function is formulated as:"}, {"title": null, "content": "LE = log exp (h)i=1,j\u2260i (exp (h) + exp()))L_E = \\frac{1}{2}\\sum_{i=1}^M \\log \\frac{\\exp(\\tilde{h}_i \\cdot \\hat{h}_i)}{\\sum_{j=1, j \\neq i}^M (\\exp(\\tilde{h}_i \\cdot \\tilde{h}_j) + \\exp(\\hat{h}_i \\cdot \\hat{h}_j))}LE\u200b=21\u200bi=1\u2211M\u200blog\u2211j=1,j\ue020=iM\u200b(exp(h~i\u200b\u22c5h~j\u200b)+exp(h^i\u200b\u22c5h^j\u200b))exp(h~i\u200b\u22c5h^i\u200b)\u200b(5)\n\nwhere h = h(x) and h\u00b2 = h(x)."}, {"title": "Temporal-wise Contrastive Loss LT:", "content": "The objective of this loss function is to ensure that two augmented samples originating from the same sample exhibit similar representations when observed at the same timestamp, while their representations differ when observed at other timestamps. Temporal-wise contrastive learning leverages the temporal consistency within the data. In this context, let us consider the anchor sample xi,t of the i-th data point at time t within a batch. By applying temporal masking, we generate two augmented samples ast and \u2611t. The pair (x,t) is classified as a positive sample pair because they are derived from the same anchor sample at timestamp t."}, {"title": null, "content": "2Conversely, negative sample pairs are defined as (x,t) and (x,t), where t\u2260 t\u00af. These negative pairs are constructed from augmented samples originating from different temporal points, thereby encouraging the model to learn distinct representations for different time observations. The Temporal-wise contrastive loss is shown as:\n\n\nLT = TM log Qi,tt=1 i=1L_T = -\\frac{1}{T \\cdot M} \\sum_{t=1}^{T} \\sum_{i=1}^{M} \\log Q_{i,t}LT\u200b=\u2212T\u22c5M1\u200bt=1\u2211T\u200bi=1\u2211M\u200blogQi,t\u200b(6)\n\nQi,t =  (exp(htt))t=1,t\u2260t\u2212( exp(-) + exp(-))Q_{i,t} = \\frac{\\exp(\\tilde{h}_{i,t} \\cdot \\hat{h}_{i,t})}{\\sum_{t'=1, t' \\neq t^-}^{T} (\\exp(\\tilde{h}_{i,t} \\cdot \\tilde{h}_{i,t^-}) + \\exp(\\hat{h}_{i,t} \\cdot \\hat{h}_{i,t^-}))}Qi,t\u200b=\u2211t\u2032=1,t\u2032\ue020=t\u2212T\u200b(exp(h~i,t\u200b\u22c5h~i,t\u2212\u200b)+exp(h^i,t\u200b\u22c5h^i,t\u2212\u200b))exp(h~i,t\u200b\u22c5h^i,t\u200b)\u200b(7)\n\nwhere hit = h(x,t). Similarly, analogous notations with h are derived from the network h(x)."}, {"title": "Inter-view Contrastive Loss: LIRV:", "content": "The inter-view contrastive loss we propose aims to encourage the model to capture informative features across different augmented views adaptively. Essentially, inter-view loss drives the representations from different views to be distinguishable from each other, thereby promoting the diversity of views.\nLet us consider a batch of samples as xi, where i = 1,..., M. For each sample xi, we apply data augmentation to generate two augmented samples, and . These augmented samples are subsequently fed into the \u041c\u041d\u0410 module, denoted as g(x). This module generates representations \u011f for each augmented branch k \u2208 {1,2} and different views v, where g(x) = \u011di,v). The view representations from the given batch are then aggregated into \u00a7 = {\u00a7\u00a6, v, \u0160 \u0eb5\u0ec9, \u0e9a\u203a \u00b7 \u00b7 \u00b7, \u0160M,v } \u00b7\nAssume we have two views for each branch that is V = 2, To facilitate inter-view contrastive learning, we define positive sample pairs as those from the same view, such as (g1,\u011fi) and (g2, 2). Conversely, negative sample pairs are those from different views, such as (g1, \u011f2) and (g, gi). Hence, the inter-view contrastive loss is formulated as:"}, {"title": null, "content": "LIRV =  log exp(s(g, g?))i=1 j=1,ji exp(s(g, g}))L_{IRV} = \\sum_{i=1}^V \\frac{1}{\\sum_{j=1, j\\neq i}^V} \\log \\frac{\\exp(s(g^i, g^i))}{\\exp(s(g^i, g^j))}LIRV\u200b=i=1\u2211V\u200b\u2211j=1,j\ue020=iV\u200b1\u200blogexp(s(gi,gj))exp(s(gi,gi))\u200b(8)\n\nIntra-View Contrastive Loss LIAV: In addition to inter-view loss, we also introduce the intra-view loss to further refine the representations within the same view. This loss is designed to enhance the discriminative power of representations by contrasting samples from the same view but different subjects, thus encouraging the model to capture subject-specific view features more effectively.\nSimilarly, assume we have subject-specific samples xi,s, where i ranges from 1 to M. For each of them, we apply data augmentation, resulting in augmented samples and . These augmented samples are then processed through a MHA network g(x), which produces subject-specific view representations for each augmented branch k \u2208 {1,2} and various views v, i.e., \u011di,v,s = g(x).\nSuppose we have V views and S subjects. To enable intra-view contrastive learning, we identify positive sample pairs as those from the same view and subject. Therefore, we have positive pairs that are (1,2,3) +,3+). On the other hand, The negative sample pairs are defined as the samples that differ in subject at the given view, which are (\u0eae\u0ebb\u0e9a,\u0ead\u0eb2\u0e9a+,-)"}, {"title": null, "content": "LIAVVM log Ki,vs,v=1 i=1 xj,v+,+St exp(s(i,v,s,v+,3+)/T)Ki,vs  exp(s(i,v,s+,8-)/T) xj,va+,s-ESi\u200bL_{IAV}=\\frac{1}{VM}\\sum_{v=1}^V \\sum_{i=1}^M \\sum_{x_{j,v^+, s^+} \\in S_t} \\log K_{i,v,s} \\quad K_{i,v,s} = \\frac{\\exp(s(\\hat{x}_{i,v,s}, \\hat{x}_{j,v^+, s^+})/\\tau)}{\\sum_{x_{j,v^+, s^-} \\in \\mathcal{S}_i} \\exp(s(\\hat{x}_{i,v,s}, \\hat{x}_{j,v^+, s^-})/\\tau)}LIAV\u200b=VM1\u200bv=1\u2211V\u200bi=1\u2211M\u200bxj,v+ ,s+\u200b\u2208St\u200b\u2211\u200blogKi,v,sKi,v,s\u200b=\u2211xj,v+ ,s\u2212\u200b\u2208Si\u200b\u200bexp(s(x^i,v,s\u200b,x^j,v+ ,s\u2212\u200b)/\u03c4)exp(s(x^i,v,s\u200b,x^j,v+ ,s+\u200b)/\u03c4)\u200b(9)\n\nwhere St includes the augmented sample set of xv+s+ that belong to the same subject as the given augmented sample vs under the same view v. Conversely, S. consists of the augmented samples that come from the same view but different subjects.\nThus, our view loss comprises both inter-view and intra-view contrastive losses:\n\n\nLv = LIRV + LIAV L_v = L_{IRV} + L_{IAV} Lv\u200b=LIRV\u200b+LIAV\u200b(10)\n\nFinally, the overall contrastive loss function L is defined as:\n\n\nL = \u03bbs Ls + \u03bbR LR + \u03bbE LE + \u03bbT LT + \u03bbv Lv L = \\lambda_s L_s + \\lambda_R L_R + \\lambda_E L_E + \\lambda_T L_T + \\lambda_v L_v L=\u03bbs\u200bLs\u200b+\u03bbR\u200bLR\u200b+\u03bbE\u200bLE\u200b+\u03bbT\u200bLT\u200b+\u03bbv\u200bLv\u200b(11)\n\nwhere AS: AR:AE:XT:Av = 1:1:1:1:2 in our practice."}, {"title": "4.3 Fine Tuninig", "content": "In order to use the Encoder ELMCRD Of LMCRD for downstream tasks, we utilize fine-tuning as follows:\n\n\n\u0177i = C(ELMCRD (Xi)) = C(h(xi), g(xi)) \\hat{y}_i = C(E_{LMCRD} (X_i)) = C(h(x_i), g(x_i))y^\u200bi\u200b=C(ELMCRD\u200b(Xi\u200b))=C(h(xi\u200b),g(xi\u200b))(12)\n\nwhere \u0177 is the classification result for downstream medical disease diagnosis, and the training optimization objective is binary cross-entropy."}, {"title": "5 Experiments", "content": "For Alzheimer's disease, myocardial infarction, and Parkinson's disease, we introduce three target datasets corresponding to each medical disease and three additional external datasets from other centers. By incorporating these external datasets, we aim to learn medical expertise from other centers to enhance the performance of downstream tasks on the target datasets. The detailed descriptions of these six datasets and the data preprocessing steps are presented in Appendix B. During the data splitting, we use the subject identifier as the criterion for division."}, {"title": "5.2 Results", "content": ""}, {"title": "5.2.1 Results on Partial Fine-tuning", "content": "To evaluate the representation quality of our proposed LMCRD quickly, we adopt the Partial Fine-Tuning (PFT). PFT refers to combining the Encoder with frozen parameters and a trainable logistic regression linear classifier C. In this setup, we utilizes 100% of the labeled data for training the supervised classification. The PFT results on the AD dataset are shown in Table 1. Our proposed LMCRD model excels in all metrics, including Accuracy, Precision, Recall, F1 score, AUROC, and AUPRC, demonstrating the power of our representation learning."}, {"title": "5.2.2 Results on Full Fine-tuning", "content": "Unlike PFT, Full Fine-tuning (FFT) adapts all model parameters to the given target medical task, which means the Encoder and the classifier are trained together with supervision. FFT further enhances the representation in the downstream task. The results of FFT on the target dataset are exemplified using the AD dataset in Table 3, with the remaining results provided in Appendix Table B2."}, {"title": "5.3 Visualization of Views", "content": "To verify the learnable multi-view learning capability of LMCF, we employed the UMAP [19] to reduce the dimensionality of view representations to two dimensions and visualize them as shown in Figure 3. The visualizations provide strong validation from the following two aspects:"}, {"title": "6 Conclusion", "content": "In medical time-series tasks, models often overfit due to the lack of labeled data. To address this issue, we introduce external normal subject data and use AE-GAN to obtain the reconstruction discrepancy of the input sequence. This discrepancy is recognized as prior knowledge for measuring the probability of illness and is incorporated into the self-supervised contrastive learning phase. In this stage, we propose a Learnable Multi-views Contrastive Framework. By introducing multi-head attention mechanisms and view contrast learning modules, this contrastive model can adaptively learn representations of different views based on medical data characteristics, reducing the need for manual organization of positive and negative samples. Moreover, the design of inter-view and intra-view losses ensures diversity among view representations while preserving the differences between subjects within each view. Through fine-tuning downstream tasks, our experiments show that the model generates informative representations and achieves state-of-the-art performance on the AD, PTB, and TDBrain medical datasets."}, {"title": "A Preliminary Knowledge on Medical Time Series", "content": "To better understand the structure of medical time series data, this section provides a comprehensive explanation of its hierarchical organization, using EEG signals from Alzheimer's disease as an example. The dataset is categorized into four hierarchical levels: Subject, Trial, Epoch, and Temporal, with each level representing a unique granularity of the data (Appendix figure B1). Unlike conventional time series, which typically consist of sample and observation levels, medical time series incorporate two additional layers: patient and trial. These extra layers enhance the dataset's structure, enabling the development of methods tailored to the specific characteristics and analytical requirements of medical time series. As illustrated in Appendix Table B1, many existing approaches utilize only a subset of these levels, underscoring the importance of leveraging the complete hierarchy for more effective analysis."}, {"title": "Definition 1:Subject", "content": "A subject pj \u2208 RG in medical time series data represents the collection of multiple trials corresponding to a single individual. The subscript j denotes the subject ID. Trials associated with the same subject may differ due to variations in data collection timeframes, sensor placement, or patient conditions. A subject's data is generally represented as an aggregate of trials. Each trial within a subject p; is typically segmented into smaller samples to facilitate representation learning. To denote all the samples belonging to a specific subject pj, we use the notation Pj."}, {"title": "Definition 2: Trial", "content": "A trial rk refers to a continuous set of observations collected over an extended time period (e.g., 30 minutes). This can also be referred to as a record. The subscript k denotes the trial ID. Trials are generally too lengthy (e.g., consisting of hundreds of thousands of observations) to be directly processed by deep learning models. Therefore, they are usually divided into smaller subsequences, referred to as samples or segments. The collection of all samples derived from a trial rk is denoted by Rk."}, {"title": "Definition 3: Epoch", "content": "An epoch em is a sequence of consecutive observations derived from a trial, typically spanning a shorter time period (e.g., several seconds). In EEG (electroencephalography), an epoch refers to a specific time window extracted from the continuous EEG signal. These time windows are used to isolate signal segments for further analysis, often aligned with specific events or experimental conditions. Each epoch is composed of multiple observations measured at regular intervals over a time range defined by M timestamps. To denote a specific epoch within a trial, we use em, where m represents the epoch index. The set of observations forming an epoch is"}, {"title": null, "content": "em = {em,t | t = 1,..., M}.e_m = \\{ e_{m,t} | t = 1,..., M \\}em\u200b={em,t\u200b\u2223t=1,...,M}."}, {"title": "Definition 4: Temporal", "content": "A temporal observation xn,t \u2208 RH refers to a single data point or vector recorded at a specific timestamp t. The subscript n denotes the sample index, while t represents the timestamp. For univariate time series, the temporal observation is a single real value, whereas, for multivariate time series, it is a vector with H dimensions. Temporal observations may represent physiological signals, laboratory measurements, or other health-related indicators."}, {"title": "A.2 Data Scarcity and Heterogeneity for Medical Time Series", "content": "Data Scarcity Medical data, especially high-quality neurodegenerative disease data, is often expensive, with high costs associated with data collection and annotation. Additionally, individual datasets typically have limited sample sizes and suffer from class imbalance issues (e.g., an unequal ratio of healthy individuals to patients). These problems lead to overfitting during model training, poor generalization, and suboptimal classification performance.\nData Heterogeneity Medical data often exhibits a multi-center characteristic, meaning datasets from different institutions show significant distributional differences. This heterogeneity makes it difficult to directly transfer models trained on one dataset to others, severely hindering the development and application of robust deep learning models."}, {"title": "E Ablation Study", "content": "To validate the effectiveness of the AE-GAN knowledge transfer module and the Learnable Multi-Views Contrastive Framework (LMCF) in the LMCRD"}]}