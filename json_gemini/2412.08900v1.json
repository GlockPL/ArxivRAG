{"title": "Artificial Intelligence-assisted Biomedical Literature Knowledge Synthesis to Support Decision-making in Precision Oncology", "authors": ["Ting He, MS", "Kory Kreimeyer, MS", "Mimi Najjar, MD", "Jonathan Spiker, BS", "Maria Fatteh, MD", "Valsamo Anagnostou, MD, PhD", "Taxiarchis Botsis, MS, MPS, PhD"], "abstract": "The delivery of effective targeted therapies requires comprehensive analyses of the molecular profiling of tumors and matching with clinical phenotypes in the context of existing knowledge described in biomedical literature, registries, and knowledge bases. We evaluated the performance of natural language processing (NLP) approaches in supporting knowledge retrieval and synthesis from the biomedical literature. We tested PubTator 3.0, Bidirectional Encoder Representations from Transformers (BERT), and Large Language Models (LLMs) and evaluated their ability to support named entity recognition (NER) and relation extraction (RE) from biomedical texts. PubTator 3.0 and the BioBERT model performed best in the NER task (best Fl-score 0.93 and 0.89, respectively), while BioBERT outperformed all other solutions in the RE task (best Fl-score 0.79) and a specific use case it was applied to by recognizing nearly all entity mentions and most of the relations. Our findings support the use of Al-assisted approaches in facilitating precision oncology decision-making.", "sections": [{"title": "Introduction", "content": "Precision oncology aims at delivering patient-tailored cancer therapies by targeting specific molecular alterations after in-depth characterization of the molecular profiling of tumors\u00b9. This task requires thoroughly reviewing several sources, including electronic health records and next-generation sequencing outputs, to accurately define the patient's clinical-genomic phenotype and information from biomedical literature, several knowledge bases, clinical guidelines, clinical trials, FDA-approved and off-label treatments, and more. In practice, medical experts often collaborate in Molecular Tumor Boards (MTB) to interpret patients' clinical and molecular profiles and suggest genotype-targeted therapies based on levels of evidence retrieved and ranked from biomedical resources. This process typically demands manual and labor-intensive steps as existing automated approaches are limited and often do not meet the expected level of performance required to assist human experts. Considering the increasing volume of knowledge generated in all the above sources and the evolving landscape of precision oncology, significant automation is necessary to streamline information extraction from various sources, such as biomedical literature, and combine it with existing and new knowledge to support expert review in the MTB and other use cases.\nAutomated information retrieval from biomedical texts is generally supported by NLP techniques, and numerous studies have been conducted on this end over the last decades. The exciting capabilities of LLMs in language understanding and generation open new opportunities for research in the domain, and they have already been applied to clinical text for NER purposes\u00b2. Published literature is a major knowledge source in biomedicine, and several researchers have used NLP and advanced methods to process large corpora of published material and extract information of interest. Recent efforts have shown promise in efficiently retrieving cancer-specific genomic alteration and treatment mentions from PubMed and may allow us to successfully incorporate scientific findings in precision oncology. For example, PubTator 3.0 is a tool the National Library of Medicine built to identify several entities and their relations in the literature using state-of-the-art Artificial Intelligence (AI) techniques\u00b3. PubTator addresses a major limitation in previous efforts that focused on processing the titles and abstracts rather than the full text of biomedical articles. The importance of this richer text is highlighted in recent efforts that have released annotated full- text corpora and/or conducted relevant Challenges4-6.\nThese emerging needs inspired our exploration of automated information retrieval from biomedical literature assisted by modern NLP models and technologies. Our main focus was identifying entities essential in supporting decision- making in precision oncology, including mutations, cancer types, targeted therapies, and the relations between these entities. We evaluated the performance of the selected approaches using an existing reference standard widely used in the community, demonstrated their readiness to automate certain manual and labor-intensive processes, and discussed the remaining challenges that must be addressed to support several use cases in precision oncology more efficiently."}, {"title": "Methods", "content": "BioRED Corpus\nWe used the Biomedical Relation Extraction Dataset (BioRED), a unique resource of 600 biomedical PubMed abstracts that contain several entity types (Gene, Variant, Disease, Chemical, Species, and Cell Line) with their relations at the document level7. Most other annotated datasets are limited as they focus on one entity, such as tmVar8, they do not include any relation annotations among the annotated entities, such as the BC5CDR corpus, or annotate relations at the sentence level, such as the DDI corpus10. In most real use cases in precision oncology, it is essential to evaluate the entity relations at the document level, making BioRED the ideal choice for our exploration.\nWe focused on four entities (Gene, Variant, Disease, and Chemical) that represent a patient's clinical-genomic phenotype and relevant drugs as well as the relations between these entities to train models that would process biomedical publications and identify genotype-driven therapies for specific cancer types. Table 1 shows the distribution of the selected entities and relations in the BioRED corpus and the training, development, and testing sets; we retained the same split in our study. Per the BioRED annotation guidelines, curators were asked to annotate each relation using one of the following nine labels: Association, Bind, Cause, Comparison, Cotreatment, Drug Interaction, Negative Correlation, and Positive Correlation. The detailed statistics for these relation types are shown in Table 2. Some curators also annotated relations between Genes and Variants as well as Variants and Variants; these relations were not described in the guidelines. Considering the sparse distribution in most relation types, we treated them all as belonging to the \"Association\u201d type, such that we have association, negative correlation and positive correlation in the end.\nNatural Language Processing Solutions\nWe initially evaluated several BERT models for the NER and the RE tasks. The BioBERT and BioLinkBERT were two top-performing BERT models evaluated over the Biomedical Language Understanding and Reasoning Benchmark11, 12, and we selected them for both tasks. We also employed two LLMs, the open-source Mixtral-8x7b Instruct and the openAI's ChatGPT 4, which have already been investigated in several studies in biomedicine13-17 and explored their performance in the NER task only. Lastly, we used PubTator 3.0, a tool built by the National Library of Medicine that, as mentioned above, identifies several entities and their relations in biomedical literature\u00b3, including those analyzed in our study.\nIn the BERT exploration, we treated the NER task as a sequence labeling problem, annotating each token using the Beginning-Inside-Outside (BIO) tagging scheme. According to this scheme, the first token in an entity mention is labeled with the B-entity_type tag, subsequent tokens within the same entity are labeled with the I-entity_type tag,"}, {"title": "Results", "content": "Model Performance\nAs shown in Figure 2, PubTator 3.0 achieved the highest performance in the NER task with an F1-score of 0.9 or higher across all entity types, followed by BioBERT, which efficiently retrieved Genes and Drugs with balanced recall and precision between 0.86 and 0.89. When comparing the results between BioBERT and PubTator, we found that many of BioBERT's incorrect predictions stem from its tendency to rely heavily on the surrounding context of a mention to determine its label. This often results in inconsistencies, where the same mention is assigned different entity types, which is generally not the case in medical texts. For example, in the sentence \"Congenital long QT syndrome (LQTS) with in utero onset of the rhythm disturbances...,\" BioBERT correctly identified LQTS as a disease. However, in another sentence, \"A novel spontaneous LQTS-3 mutation was identified in the...,\" LQTS was incorrectly predicted as a gene. We hypothesize that this behavior arises because the BERT model, trained for masked language prediction tasks, tends to prioritize context words over medical accuracy. BioLinkBERT was less efficient than BioBERT and PubTator 3.0 in supporting the NER task, with the highest recall for the Gene entity at 0.71 and other metrics between 0.55 and 0.66 for the remaining entities. Both LLMs performed poorly overall, although ChatGPT 4"}, {"title": "Discussion", "content": "We explored the ability of selected NLP solutions to efficiently retrieve specific entities (Gene, Variant, Disease, and Chemical) and their relationships from biomedical literature. Additionally, we assessed how these solutions might contribute to decision-making in precision oncology through a particular use case. In the NER task, PubTator 3.0 was the best-performing solution (F1-score close to or above 0.9), followed by BioBERT (F1-score between 0.82 and 0.89), while BioLinkBERT and the two LLMs demonstrated average and poor performance, respectively. In the RE task, BioBERT outperformed BioLinkBERT and PubTator 3.0, but did not reach the required level of performance for routine use, missing several relations in the evaluation with the BioRED testing set and the OncoKB use case. However, it captured all individual entities included in retrieved or missed relations and reported in the OncoKB-cited papers.\nOur study has three main limitations. First, the selected BioRED corpus was not originally created with a focus on precision oncology, e.g., the Disease entity did not solely represent cancer types, and the annotated relations did not fully capture all potential associations between the Chemical and the other entities, which is a critical factor in the selection of targeted therapies. Dedicated resources might better support information retrieval and knowledge synthesis from biomedical literature. Second, none of the explored solutions could make inferences from other sections within the same full-text papers or other sources in general, as depicted in the OncoKB use case. This limitation applies to detecting relations at the document level and not simply at the section level, which partly occurred in our approach. It also refers to linking several documents and recognizing entity relations across them. Generative Al may likely bridge this gap, which may represent an additional challenge, as we elected to use LLMs for annotation rather than knowledge generation purposes.\nThe presented level of performance in the RE task cannot lead to operationalizing any of the solutions evaluated in our work. We would argue, though, that the domain has not solved this problem yet, especially in precision medicine and oncology. A representative example is the recently developed BioREX model, the core RE engine in PubTator 3.0, that considerably improved RE in several relation types (average F1-score 0.79) by applying deep learning to heterogeneous datasets (BioRED was one of these datasets) 23. However, none of these relations contained the Variant entity, although annotated in several datasets 24, 25, which is significant for characterizing a patient's genomic profile and selecting targeted therapies in precision oncology. BioREX's inability to efficiently capture this relation type was demonstrated in PubTator's evaluation in the OncoKB use case. In that sense, although PubTator performed best in the NER task, our BioBERT model offered a more efficient approach by nearing PubTator in the NER and outperforming it in the RE task. It should be clarified, though, that none of these approaches is mature enough to solve the RE problem.\nAcknowledging the limitations of existing approaches in accurately detecting certain relations in biomedical literature and clinical texts, we suggest pursuing other strategies in the precision oncology context. Traditional NLP approaches would require annotating new corpora or combining and refining existing labeled datasets and (re)training some of the best-performing state-of-the-art models to improve performance. One might also argue that the strengths of the BERT models have not been fully explored in precision oncology, and we would probably agree with this statement. For example, our BioBERT model, as part of an NLP ensemble pipeline, could accept PubTator's NER output and efficiently detect the relations in biomedical literature. This approach was not examined in our work but could be investigated in one of our next steps. On the other hand, the research community is trying to move from training models to \u201czero-shot\" learning frameworks26 that promise less labor-intensive processes and efficient implementations in end-to-end systems utilizing LLMs. The current work demonstrated that the selected LLMs could not accurately support the NER task traditional NLP approaches have (nearly) solved, further suggesting potential major challenges for these models in the more complex RE task, which we investigated in a separate analysis and found them performing very poorly (data not shown).\nThe application of generative AI to several tasks in biomedicine and precision oncology is inevitable, and we will be seeing numerous studies in this area over the next several years. Our limited analysis of the two LLMs represents a pilot study and, as such, precludes firm conclusions on the use of these methodologies in clinical decision-making. It is paramount to accurately collect the requirements and expectations from the end users before determining the next steps and calibrating these approaches. In precision oncology specifically, several sources are evaluated to make a\""}, {"title": "Conclusion", "content": "We explored several NLP solutions to automatically extract, synthesize and characterize scientific knowledge from biomedical literature that might support clinical decision-making in the context of identifying genotype-driven therapies for cancer patients. Identifying the relations between key entities was the most challenging task in our analysis, as shown in the comparisons with the reference standard and knowledge included in the OncoKB resource. The latter evaluation was very informative and demonstrated that one of the models (BioBERT) successfully identified all entity mentions found in the OncoKB-cited publications and 55% of the relations listed by the human curators. Future research must deliver efficient systems that will accurately process the compendium of information and process knowledge to support decision-making in precision oncology."}]}