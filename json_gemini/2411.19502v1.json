{"title": "Knowledge-Data Fusion Based Source-Free Semi-Supervised Domain Adaptation for Seizure Subtype Classification", "authors": ["Ruimin Peng", "Jiayu An", "Dongrui Wu"], "abstract": "Abstract\u2014Electroencephalogram (EEG)-based seizure subtype classification enhances clinical diagnosis efficiency. Source-free semi-supervised domain adaptation (SF-SSDA), which transfers a pre-trained model to a new dataset with no source data and limited labeled target data, can be used for privacy-preserving seizure subtype classification. This paper considers two challenges in SF-SSDA for EEG-based seizure subtype classification: 1) How to effectively fuse both raw EEG data and expert knowledge in classifier design? 2) How to align the source and target domain distributions for SF-SSDA? We propose a Knowledge-Data Fusion based SF-SSDA approach, KDF-MutualSHOT, for EEG-based seizure subtype classification. In source model training, KDF uses Jensen-Shannon Divergence to facilitate mutual learning between a feature-driven Decision Tree-based model and a data-driven Transformer-based model. To adapt KDF to a new target dataset, an SF-SSDA algorithm, MutualSHOT, is developed, which features a consistency-based pseudo-label selection strategy. Experiments on the public TUSZ and CHSZ datasets demonstrated that KDF-MutualSHOT outperformed other supervised and source-free domain adaptation approaches in cross-subject seizure subtype classification.\nIndex Terms\u2014EEG, seizure subtype classification, source-free domain adaptation, semi-supervised learning, knowledge-data fusion", "sections": [{"title": "I. INTRODUCTION", "content": "Epilepsy is one of the most common neurological disorders, affecting millions of patients and their families worldwide [1], [2]. Clinically, electroencephalogram (EEG) is the golden criterion for seizure diagnosis, with ictal EEG typically presenting a spike-and-wave pattern. Automated seizure diagnosis can greatly reduce the clinicians' workload in analyzing long-term EEG records [3].\nThis paper focuses on EEG-based seizure subtype classification, which determines seizure subtypes for further optimization of surgery and medical treatments [4]. According to the 2017 International League Against Epilepsy guideline [5], we categorize epileptic seizure into four subtypes: Absence Seizure (ABSZ), Focal Seizure (FSZ), Tonic Seizure (TNSZ), and Tonic-Clonic Seizure (TCSZ).\nGenerally, both traditional machine learning and deep learning approaches are viable for seizure subtype classification. Fig. 1 shows their training processes.\nFor traditional machine learning approaches, an effective handcrafted feature extractor is vital. Lots of valuable human expert knowledge has been accumulated for feature extraction. [6] reviewed the research that employed machine learning classifiers with temporal, spectral, and nonlinear handcrafted features. [7] compared the performance of different feature extraction approaches.\nFor deep learning approaches, the feature extractor and classifier are integrated into one neural network. Both model structures and training algorithms impact the classification performance. [8] grouped deep models for seizure detection into Convolutional Neural Networks, Recurrent Neural Networks, and AutoEncoders. Recently, [9] and [10] proposed Transformer [11] based models for seizure subtype classification. These deep models are usually data hungry; however, labeled data are scarce and expensive in seizure subtype classification.\nSource-free domain adaptation (SFDA) [12], [13] can be used for patient privacy protection in cross-dataset transfer learning. As illustrated in Fig. 2, SFDA aims to reduce the distribution discrepancy between the source and target domains, and the alignment process does not use the source data [12]. Source Hypothesis Transfer (SHOT) [14] is a popular SFDA approach, which includes a self-supervised pseudo-labeling strategy and an information maximization loss in training. BAIT [15] inserts an extra classifier (bait classifier) in the source model to recognize and push the unaligned target features to the correct side of the source decision boundary.\nThis study investigates few-shot source-free semi-supervised domain adaptation (SF-SSDA) for EEG-based seizure subtype classification, where very limited data of each class in the target domain are labeled. Our main contributions are:\n1) We propose a Knowledge-Data Fusion (KDF) based SF-SSDA algorithm, KDF-MutualSHOT, for seizure subtype classification. To the best of our knowledge, this"}, {"title": "II. METHODOLOGY", "content": "This section introduces our proposed KDF-MutualSHOT, which fuse expert knowledge and raw EEG data in classifier training. We first pre-train a KDF model in the source domain, then adapt it to the target dataset with MutualSHOT.\nA. The Overall Training Process\nInspired by deep mutual learning [16] for image classification, which introduces a mutual distillation mechanism with the Kullback-Leibler divergence loss $L_{KL}$ to encourage two networks with different parameters to learn from each other, we propose KDF to enhance the collaboration between a knowledge-driven SDT and a data-driven ViT. To adapt a pre-trained model to a new dataset, we design an SF-SSDA approach, MutualSHOT, to align the source and target domain distributions without the source data.\nFig. 3 illustrates the training process of KDF-MutualSHOT, which contains two stages: 1) Pre-train the KDF model in the source domain; and, 2) fine-tune it by MutualSHOT in the target domain. In the testing phase, the SDT and ViT models are used independently.\nB. Expert knowledge-Raw data Combined Training\nTo learn from knowledge-based features, following [12], we extract 41 handcrafted features\u00b9 per EEG channel, as listed in Table I. More specifically, they include 10 temporal features, 4 spectral features, 24 time-frequency features, and 3 nonlinear features. An SDT [17] classifier is then optimized by gradient descent.\nTo learn from raw EEG data, a ViT [22] is selected as the base model, whose superior performance has been demonstrated in [10]. It includes four Transformer encoder layers. First, EEG signals with dimensionality $[C \\times 1 \\times N]$, where $C$ is the number of channels and $N$ the number of time domain samples, are patchfied and mapped into embeddings with position information. Then, the Transformer encoders process these embeddings with a self-attention mechanism [11]. Finally, a feed-forward layer outputs the classification probability from the averaged representation of all patches' features.\nThe training of both SDT and ViT involves a cross-entropy loss $L_{CE}$:\n$L_{CE}^{ViT} = -\\frac{1}{K}\\sum_{k=1}^{K} \\log (p(y = k|s, \\theta_v))$\n$L_{CE}^{SDT} = -\\frac{1}{K}\\sum_{k=1}^{K} \\log (p(y = k|f, \\theta_s))$,\nwhere $K$ is the number of classes, $s$ is the data input of ViT, $f$ is the feature input of SDT, and $\\theta_v$ and $\\theta_s$ are respectively ViT and SDT model parameters.\nTo further enhance the learning efficiency, we additionally incorporate a mutual distillation mechanism to utilize complementary information from knowledge and data. As $L_{KL}$ is asymmetric, we adopt the JSD loss $L_{JSD}$ as the consistency constraint for mutual learning. The overall loss functions for ViT and SDT in KDF are hence:\n$L^{ViT} = L_{CE}^{ViT} + \\alpha L_{JSD}$\n$L^{SDT} = L_{CE}^{SDT} + \\alpha L_{JSD}$\nwhere\n$L_{JSD} = \\frac{1}{2}(L_{KL}(p_s || p_f) + L_{KL}(p_f || p_s))$\n$= \\frac{1}{2K} ( \\sum_{k=1}^{K} p_s(y = k|s, \\theta_v) \\log \\frac{p_s(y = k|s, \\theta_v)}{p_f(y = k|f, \\theta_s)} + \\sum_{k=1}^{K} p_f(y = k|f, \\theta_s) \\log \\frac{p_f(y = k|f, \\theta_s)}{p_s(y = k|s, \\theta_v)} )$.\nC. Mutual-SHOT for SF-SSDA\nIn the fine-tuning stage, SDT and ViT in the target domain model are first initialized by the pre-trained KDF model in the source domain. Then, their classifiers are fixed while the feature encoding layers are updated to align the feature distributions between the source and target domains by minimizing an information maximization loss $L_{IM}$ [14], [23]:\n$L_{IM} = -E_{x \\epsilon X} \\sum_{k=1}^{K} \\delta_k (f(x)) \\log \\delta_k (f(x)) + \\sum_{k=1}^{K} p_k \\log p_k$,\nwhere $X$ is either the features $f$ or EEG data $s$ in the target domain, depending on the type of model $f$. $\\delta_k = $"}, {"title": "III. EXPERIMENTS", "content": "This section evaluates the performance of our proposed KDF-MutualSHOT on two seizure datasets with subtype annotations. The Python code is available at https://github.com/rmpeng/MutualSHOT.\nA. Datasets and Experimental Setup\n1) Datasets: CHSZ [24] and TUSZ [25] datasets were used in our experiments. Table II summarizes their characteristics.\nWe followed the preprocessing steps and training/validation/test set partition in [24], and performed cross-patient experiments, i.e., the training and testing sets came from different patients. All reported results were the average of three-fold cross-validation with 10 repeats.\n2) Baselines: For all experiments, SDT used seven layers, and learning rate 0.01. ViT's parameters followed [10]. Both models were optimized by AdamW3."}, {"title": "IV. CONCLUSIONS", "content": "This paper has introduced a novel SF-SSDA approach, KDF-MutualSHOT, for EEG-based seizure subtype classification. An SDT and a ViT are adopted as the base models to learn from expert features and raw EEG data, respectively. In the pre-training stage, KDF enhances the learning efficiency by utilizing a JSD loss to encourage mutual learning between SDT and ViT models. The subsequent fine-tuning stage with MutualSHOT effectively adapts the model to a new target domain while preserving the source data privacy. Mutual-SHOT improves SHOT with a consistency-based pseudo-label selection strategy, which selects only the confident samples with consistent pseudo-labels from expert features and raw data. Experiments on two public seizure subtype classification datasets demonstrated the superior performance of KDF-MutualSHOT in both pre-training and fine-tuning stages."}]}