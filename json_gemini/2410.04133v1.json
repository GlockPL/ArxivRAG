{"title": "From Hospital to Portables: A Universal ECG Foundation Model Built on 10+ Million Diverse Recordings", "authors": ["Jun Li", "Aaron Aguirre", "Junior Moura", "Che Liu", "Lanhai Zhong", "Chenxi Sun", "Gari Clifford", "Brandon Westover", "Shenda Hong"], "abstract": "Artificial Intelligence (AI) has shown great promise in electrocardiogram (ECG) analysis and cardiovascular disease detection. However, developing a general AI-ECG model has been challenging due to inter-individual variability and the diversity of ECG diagnoses, limiting existing models to specific diagnostic tasks and datasets. Moreover, current AI-ECG models struggle to achieve comparable performance between single-lead and 12-lead ECGs, limiting the application of AI-ECG to portable and wearable ECG devices. To address these limitations, we introduce an ECG Foundation Model (ECGFounder), a general-purpose model that leverages real-world ECG annotations from cardiology experts to broaden the diagnostic capabilities of ECG analysis. ECGFounder is trained on over 10 million ECGs with 150 label categories from the Harvard-Emory ECG Database, enabling comprehensive cardiovascular disease diagnosis through ECG analysis. The model is designed to be both effective out-of-the-box and fine-tunable for downstream tasks, maximizing usability. More importantly, we extend its application to single-lead ECGs, enabling complex condition diagnoses and supporting various downstream tasks in mobile and remote monitoring scenarios. Experimental results demonstrate that ECGFounder achieves expert-level performance on internal validation sets for both 12-lead and single-lead ECGs, while also exhibiting strong classification performance and generalization across various diagnoses on external validation sets. When fine-tuned, ECGFounder outperforms baseline models in demographics detection, clinical event detection, and cross-modality cardiac rhythm diagnosis. ECGFounder not only enhances existing cardiovascular diagnostics capabilities but also facilitates integration into mobile and remote monitoring devices, enabling continuous, real-time cardiac health monitoring crucial for early detection and management of chronic heart conditions. The trained model and data will be publicly released upon publication through the Brain Data Science Platform (bdsp.io), promoting further research and development in this field. Our code is available at https://github.com/bdsp-core/ECGFounder.", "sections": [{"title": "1. Introduction", "content": "Electrocardiogram (ECG) is a crucial diagnostic tool that measures and records the electrical activity of the heart using electrodes placed on the skin.[2] ECG recordings are vital diagnosis and monitoring of cardiac health conditions.[14] In addition to common arrhythmias, ECGs can be used to diagnose conditions such as myocardial ischemia, myocardial hypertrophy, and myocardial infarction.[18] However, fully interpreting an ECG is complex and difficult. A typical ECG expert undergoes nearly 10 years of training, including medical school, internal medicine residency, and specialized ECG training.[2] Despite this, comprehensive and accurate interpretation of ECGs remains a challenge even for qualified experts. In real clinical scenarios an ECG may present multiple diagnoses simultaneously. For instance, a patient with coronary heart disease might also exhibit bundle branch block, ST-segment depression, and T-wave inversion. Even ECG experts may occasionally overlook or mislabel findings due to human error. There is an urgent need for an AI-powered automated model capable of identifying all ECG abnormalities.\nTraditional ECG analysis focuses on extracting waveform and rhythm features from ECG signals for arrhythmia classification and ECG anomaly detection.[9, 28] These methods are simple and effective, but limited, as they rely on expert knowledge and prior experience, which may fail to capture complex patterns in the data. Manual feature selection can lead to missing important information or overfitting. To address this limitation, some studies have introduced signal analysis techniques, such as Fourier transform and wavelet transform, which allow for automatic feature extraction and classification of ECG signals.[32, 6] Compared to traditional ECG analysis, signal analysis methods offer higher accuracy. However, these models face challenges in handling and analyzing large-scale ECG data, and they can be computationally intensive.\nRecent work has integrated deep learning models into ECG analysis, significantly improving diagnostic accuracy and efficiency.[42] Current deep learning approaches in ECG interpretation primarily employ Convolutional Neural Networks (CNNs) [16, 43, 25], Recurrent Neural Networks (RNNs)[34], Transformers [24] and their variants, which have proven effective in identifying common arrhythmias and conduction blocks.[10, 1, 30]\nHowever, due to limitations of existing ECG databases in terms of sample size, patient numbers, and the variety of diagnoses, these models have not yet addressed the challenges of inter-individual variability and the diversity of diagnoses [23]. This restricts the models to performing only a limited set of diagnostic tasks and datasets. Additionally, current ECG models do not achieve the same level of performance for single-lead ECGs as they do for 12-lead ECGs.[17, 29] These challenges highlight the practical limitations of training an ECG model from scratch on small-scale datasets, making it difficult to extend the model to real-world ECG analysis. A promising approach is to leverage transfer learning and the strong generalization capabilities of foundation models to enhance the performance of ECG models.\nFoundation models have recently made significant strides in medical AI. In retinal disease diagnosis, the RETFound model, through pre-training on a large number of retinal images, has achieved excellent performance across various clinical diagnostic tasks.[41] In computational pathology, the UNI model was trained on a vast amount of whole-slide images, reaching expert-level performance in multiple cancer diagnostic tasks.[4] In these studies, foundation models are defined as large-scale AI models trained on extensive datasets, capable of adapting to a wide range of downstream tasks. Specifically, they meet the following criteria: 1) the pre-training dataset is large in scale, 2) the model has an enormous number of parameters, and 3) it can perform a wide range of downstream tasks. Although recent work has made substantial progress in many medical fields, there is currently no foundation model for ECGs.[36, 3]\nTo fully leverage the advantages of foundation models, we develop an ECG Foundation Model\u2014a groundbreaking approach aimed at revolutionizing ECG analysis. This foundation model, the first of its kind, is capable of diagnosing 150 types of cardiac abnormalities covered by existing ECG classifications by utilizing over ten million clinically annotated real-world ECG datasets. To address the inherent challenges of incomplete annotations in real-world data, we introduce a novel method for pre-processing and training on these annotations, ensuring robust performance even under sub-optimal conditions. Moreover, by training the single-lead ECG model based on lead augmentation, we are able to maintain high diagnostic performance on single-lead ECGs as well. We validate the model's performance on both internal and external test sets, where it consistently matches expert-level diagnoses. In downstream task fine-tuning, we demonstrate ECGFounder's versatility in addressing various tasks, including demographics detection, clinical event detection, and cross-modality diagnosis (Figure 1b). Specifically, we evaluate ECGFounder on 12 clinical tasks, such as ECG age regression and classification, sex detection, chronic kidney disease (CKD) detection, chronic heart disease (CHD) detection, regression and abnormal classification of left ventricular ejection fraction (LVEF), regression and abnormal classification of NT-proBNP, and atrial fibrillation detection based on photoplethysmography(PPG)."}, {"title": "2. Methods", "content": "2.1. Datasets and pre-processing\nOur dataset, the Harvard-Emory ECG Database (HEEDB), is currently the largest open-access ECG dataset, containing 10,771,552 expert-annotated ECGs from 1,818,247 unique subjects.[19] These ECGs are predominantly 10-second, 12-lead clinical ECGs. The dataset includes annotations from cardiologists and ECG technicians paired with the ECGs. These annotations consist of discrete text reports that primarily describe the morphology, rhythm, and diagnostic information of the ECGs. Experts used the Marquette 12SL ECG Analysis Program (GE Healthcare) version 4 to assist with annotations, [12] which provides waveform parameters for doctors' reference. The program offers many diagnostic categories, allowing doctors to simply click on corresponding category labels on the computer, avoiding manual entry of diagnostic statements. To extract descriptive information about ECGs from these discrete labels, we utilized regular expressions to parse the annotations, tallying each independent label. In total, there were 287 independent phrases. After reviewing with doctors, we removed phrases that were irrelevant to ECG descriptions while retaining meaningful phrases. Ultimately, we defined 150 meaningful labels, including rich diagnostic information as well as specific rhythm and morphological descriptions (See Supplement for more details about labels).\nOur external validation data comprised three large ECG databases (DB): The CODE-test DB [31], the PTB-XL DB[38], and PhysioNet Challenge-2017 DB [5]. The CODE-test DB is composed of ECG records from 827 patients across 811 municipalities in Brazil, collected by the Telehealth Network of Minas Gerais (TNMG). There are six common arrhythmia labels in this ECG DB, annotated by several experienced ECG experts.\nThe PTB-XL dataset contains 21,837 clinical ECGs from 18,885 patients in Germany. Each ECG is a 10-second, 12-lead recording. The labels were reviewed and verified by two physicians. This dataset is currently one of the best publicly accessible ECG collections, both in terms of the number of samples and the quality of the labels.[38]\nThe PhysioNet Challenge-2017 is a large single-lead ECG dataset. The ECG recordings were collected using the AliveCor device.[5] The training set includes 8,528 single-lead ECG recordings, with durations ranging from 9 to 60 seconds, while the test set contains 3,658 ECG recordings of similar lengths. The dataset requires classification of ECG recordings into normal rhythm, atrial fibrillation rhythm, other rhythms, and noise.\nAdditionally, we utilized the MIMIC-IV-ECG DB to fine-tune our model for various downstream tasks. The MIMIC-IV-ECG dataset is part of the MIMIC series, focusing on the collection and analysis of ECG data.[7] MIMIC-IV-ECG originates from real clinical settings at Beth Israel Deaconess Medical Center (BIDMC) in Boston, USA, and contains a large number of clinical ECG recordings from patients treated in the intensive care unit (ICU). Moreover, ECG recordings in the dataset can be matched with the electronic health records of patients in the MIMIC-ED, allowing ECG data to be associated with specific conditions. Here, we linked several clinical downstream tasks, such as age, sex, chronic kidney disease (CKD), chronic heart disease (CHD), left ventricular ejection fraction (LVEF) and NT-proBNP with ECG data to explore the performance improvement of the fine-tuned ECGFounder model in detecting other diseases and clinical events. More details about the split and labels of MIMIC-IV-ECG DB can be found in Supplement.\nTo explore ECGFounder's generalization capabilities on other similar physiological signals, we fine-tuned and evaluated it using the DeepBeat dataset, a PPG-based atrial fibrillation (AF) detection dataset.[37] The dataset includes over 500,000 labeled signals from more than 100 individuals.\nFor ECG preprocessing, we applied linear interpolation to resample ECG frequencies to 500Hz. We used a high-pass filter with a cutoff frequency of 1 Hz to suppress residual baseline drift and a second-order 30 Hz Butterworth low-pass filter to reduce high-frequency noise. A 50/60 Hz notch filter was utilized to eliminate electrical interference. From ECG records longer than 10 seconds, we extracted 10-second windows in sequence. If a sequence was less than 10 seconds, we applied zero padding. We normalized all signals using the mean and standard deviation of each individual signal segment before inputting them into the model. If a signal was missing, we assigned it a value of 0."}, {"title": "2.2. Model architecture", "content": "To establish an ECG foundation model, we require an architecture that is tailored for ECG, capable of learning generalizable representations from large-scale ECG datasets. The growth in the size of ECG data and the increase in the number of leads mean that the model must not only consider temporal information of the data but also spatial relationships, i.e., interactions between different leads and the overall pattern of cardiac electrical activity. This is crucial for the ECG foundation model to be applicable in real clinical ECG scenarios, to mitigate the impact of non-uniform ECG durations and missing leads in the training dataset.\nConsidering these factors, we built our model architecture on top of the RegNet architecture. [15, 27] This structure begins with a stage-wise network design where each stage consists of a set number of blocks and channels that scale with network depth. This is beneficial for us to expand and design the blocks and channels of the ECG foundation model. Unlike traditional uniform scaling across layers, RegNet employs a quantized linear model to predict optimal widths and depths, ensuring efficient performance across a range of model sizes. The initial layers focus on capturing low-level features with fewer channels, which gradually increase as the network deepens, thus optimizing computational efficiency and model capacity. Following this, the model utilizes a series of bottleneck blocks that combine group convolutions and channel-wise attention mechanisms, enhancing the richness of representation in both temporal and spatial dimensions while controlling model complexity. This tailored configuration makes the model suitable for ECG data. More details about the model architecture can be found in the Supplement."}, {"title": "2.3. Training with real-world annotations: noisy, imbalanced, positive unlabeled", "content": "Unlike conventional ECG diagnostic models that typically use single-label classification methods, we employed multi-label classification during the training phase of the ECG foundation model. This approach aligns more closely with clinical practice, where an ECG diagnosis often consists of multiple diagnostic labels. For example, an abnormal ECG diagnosis might be something like normal sinus rhythm | premature ventricular complexes | premature ectopic complexes. Additionally, multi-label diagnostics better meet the application needs of clinicians. During training, utilizing a multi-label classification approach provides our model with rich semantic value and facilitates generalization to different annotation systems. However, the nature of multi-label annotations means that it is almost impossible to achieve perfect multi-label data, especially in cases like ECG where there are many diagnostic categories. Generally speaking, if a cardiology expert can annotate three classes simultaneously, it is considered excellent. However, the actual number of ECG diagnostic labels far exceeds three classes. [18] To address the challenge brought by incomplete ECG annotations, we introduce positive unlabeled (PU) learning method.\nPU learning is defined as when positive samples are present in the data but unlabeled, but the labeled positive samples are correct, meaning that the unlabeled samples are not necessarily negative examples.[40] Typically, PU learning leads to a severe imbalance in the predicted probability distribution: an ECG usually contains a few positive diagnostic labels, with the remaining labels being treated as negative, leading to a severe positive-negative imbalance where the negative samples far outnumber the positive samples for each label. The inherent scarcity of positive examples, combined with the missing labels, exacerbates the imbalance, making it more challenging to learn from the positive examples. When using conventional loss functions, such as the Binary Cross-Entropy (BCE) loss function, the model tends to learn from simpler samples, namely the true negative (TN) samples, while the more challenging samples, namely the false negative (FN) samples, are harder to fit. When the model is biased towards learning TN samples, its predicted probabilities tend to skew towards 0 rather than 1, which diminishes its ability to predict positive samples and weakens its potential to detect clinically important abnormalities.\nTo enhance the model's ability to fit representations of positive samples, we improved the multi-label classification loss function, enabling the model to correct missing labels by adjusting the weights of positive and negative samples.[39] Typically, for missing labels, a well-trained multi-label model's predicted probability should be close to 1 rather than 0. Therefore, by applying a smaller weight to the loss of negative labels with predicted probabilities close to 1, we can mitigate the impact of missing labels. The loss function is given by:\n$L = -(y - p)p^2$. \nHere, y is a hyperparameter of the model and p is the predicted probability of model. In this case, it is set to y = 1.5, which we find optimally balances the weights, allowing the model to learn good representations of both positive and negative samples.\nOur model training used AdamW to minimize the loss function, with an initial learning rate set to 0.001.[21] The learning rate decayed by a factor of 10 every 5 epochs. The trainable temperature parameter was initialized to 0. Training spanned a maximum of 20 epochs, with early stopping based on validation loss. We used a batch size of 1024."}, {"title": "2.4. Training a single-lead ECG model based on leads augmentation", "content": "The development of portable and wearable ECG devices in recent years has revolutionized continuous cardiac monitoring, offering a non-invasive method for real-time health assessment. Beyond the conventional diagnosis of cardiac arrhythmias, another critical challenge in this field is accurately detecting and interpreting ECG axis deviation on single-lead ECGs from portable devices (typically lead I), which can significantly impact the diagnosis of various cardiac abnormalities. For instance, left axis deviation can provide additional insights into diagnoses like left ventricular hypertrophy, left bundle branch block, left anterior fascicular block, pre-excitation syndromes, and inferior myocardial infarction. [17, 8] To address this issue, we developed a novel training method utilizing lead-augmented portable ECG models. By systematically enhancing standard 12-lead ECG data, we simulate various clinical scenarios of axis inversion, thereby enhancing the model's robustness and versatility. Understanding the relationship between ECG vectors and leads is crucial for this method. The cardiac electrical activity generates a vector representation of cardiac signals, captured by different ECG leads placed on the body. Each lead provides a unique perspective of the cardiac electrical axis, offering a comprehensive view when combined. The standard 12-lead ECG system includes limb leads (I, II, III, aVR, aVL, aVF) and precordial leads (V1-V6), with each lead representing a specific projection of the cardiac electrical vector.[22] Specifically, we primarily utilize the ECG signals from limb leads. Based on the angular position of each limb lead's axis relative to the heart, we consider lead I as the center of the semicircle (i.e., 0\u00b0) and calculate the signals from all leads around the semicircle (i.e., from -90\u00b0 to 90\u00b0), thereby obtaining six additional leads (aVL, -aVR, II, -III, aVF, -aVF). We then trained a model for portable ECG devices, extracting the lead I ECG from the HEEDB 12-lead data and randomly incorporating one of the remaining six augmented leads into the model for training with a 50% probability. This ensures that the model can learn arrhythmia features from lead I data and axis deviation from the additional six leads. Additionally, we have scaled down the model's parameter size to optimize for portable devices with limited computational resources."}, {"title": "2.5. Fine-tuning on ECG foundation model", "content": "When adapting to specific ECG downstream tasks, we need to retain the parameters of the base model and discard the initial classification linear layer. The number of classes in the downstream task determines the number of neurons needed in the final layer of the new linear layer. The training objective is to generate classification outputs that match the labels. To fully leverage the potential of the foundation model, we experimented with two fine-tuning strategies. The first fine-tuning strategy involved loading the pre-trained model parameters and fine-tuning the entire model. The second fine-tuning strategy involved loading the model parameters, freezing the encoder's parameters (i.e., not altering the encoder parameters), and only fine-tuning the final linear layer of the model.\nThe batch size is 256. The total training period is 30 epochs, with a learning rate adjustment strategy that utilizes the scheduler. After every epoch, the scheduler monitors the specified metric, and if the performance does not improve for 10 consecutive epochs, the learning rate is reduced by a factor of 0.1. The learning rate reduction is triggered based on the maximization of the monitored metric. This approach ensures a dynamic adjustment of the learning rate depending on the training progress. After training in each epoch, the model is evaluated on the validation set. [4] The model weights with the highest AUC on the validation set are saved as a checkpoint for future evaluation."}, {"title": "2.6. Clinical validation", "content": "To validate and compare the performance of our model, we established a committee consisting of three experienced ECG physicians to annotate the internal test set. We developed an ECG annotation system for physicians to use, and set up 20 types of labels including cardiac rate abnormalities, conduction blocks, myocardial dilation, myocardial infarction, and ECG morphologies, with several sub-labels under each category. The Supplement displays the complete list of label types. After independent annotation by the committee, a consensus determination was made; ECGs that did not reach consensus were removed, providing an expert standard for model evaluation. ECGs that the committee could not interpret or agree upon were eliminated from our test dataset.\nAdditionally, to compare the diagnostic accuracy between the model and experts, five additional ECG physicians were involved in this study. They were given specific instructions on how to use the system. The Supplement shows the doctors' ages, levels of experience, and education. Each doctor was required to independently annotate each ECG from the internal test set. The annotations from these physicians were then compared to the model's results."}, {"title": "2.7. Statistical analysis", "content": "The evaluation of the model was conducted by calculating accuracy, the area under the Receiver Operating Characteristic (ROC) curve (AUC), sensitivity, specificity, and the F1 score, each with bilateral 95% confidence intervals (CI)."}, {"title": "3. Results", "content": "Our dataset comprises 10,771,552 expert-annotated ECGs recorded from 1,818,247 unique subjects using 12-lead ECG machines, covering the period from the 1990s to present, with a recording duration of 10 seconds. The average age of patients is 60.6 years, with 48.7% being female.[19] After annotation cleaning, the training dataset became a multi-label dataset, with over 10,558,162 (98%) of ECGs being multi-labeled. The development dataset includes 7,519,035 ECGs from 1,725,643 patients, and the test dataset includes 834,926 ECGs from 265,818 patients. The committee internal test set includes 523 ECGs recorded between January 10, 2023, and January 20, 2023, corresponding to 523 unique patients. We obtained a total of 150 labels describing the ECGs, including heart rate abnormalities, conduction abnormalities, cardiac hypertrophy, myocardial infarction, myocardial ischemia, pacemaker devices, and ECG waveform morphology. Using these labels, we trained two deep learning ECG models separately: one for standard 12-lead ECGs and the other designed for single-lead portable device ECGs (lead I). We evaluated the performance of both models on internal and external test sets."}, {"title": "4. Discussion", "content": "In this study, we have developed and demonstrated the generalizability and robust diagnostic capabilities of ECGFounder, a universal foundation model for electrocardiogram analysis. Trained on the largest ECG dataset to date, HEEDB, which encompasses over ten million ECGs from more than one million unique patients across 150 primary diagnostic categories including normal ECGs, arrhythmias, conduction blocks, myocardial infarctions, and cardiac hypertrophy. We developed and validated a deep learning model that consistently outperforms other ECG models. Our findings on both internal and external test sets highlight the substantial clinical diagnostic value and generalizability of our model. Furthermore, we enhanced the model's performance on single-lead ECGs through a novel data augmentation method based on the cardiac axis. The internal validation results for arrhythmia diagnosis using single-lead ECGs demonstrated exceptional performance, broadening the prospects for the model's application in mobile health. Moreover, by leveraging a fine-tuned pre-trained model, ECGFounder effectively adapts to a wide range of downstream tasks, significantly enhancing the diagnosis of other diseases such as chronic kidney disease and coronary heart disease.\nECGFounder enhances diagnostic performance by learning to identify ECG features associated with cardiovascular diseases, which are typically diagnosed based on specific waveform patterns and rhythm characteristics like the elevated ST segments of myocardial infarction and the irregular fluctuations of atrial fibrillation. These features involve anomalies in cardiac electrical activity, appearing significantly different from normal ECG waveforms. Upon training, ECGFounder can recognize these disease-related waveform patterns and rhythms, accurately diagnosing corresponding cardiovascular conditions. Furthermore, ECGFounder's sensitivity exceeds that of the average cardiology expert, indicating its ability to more accurately capture subtle signs of cardiovascular diseases that may be overlooked by human experts.\nPrevious research has demonstrated that deep learning models can support clinical ECG analysis and achieve good performance.[11] However, existing models lack a universal clinical diagnostic capability for ECGs. Firstly, the training datasets used by existing models are not large or diverse enough, which can lead to overfitting and poor performance on new data, thus limiting their generalizability.[33] Additionally, the lack of demographic diversity in the training datasets means these models may perform poorly for certain demographic groups. This could lead to biases when the models are applied to data from different demographic backgrounds, affecting the fairness and accuracy of the models. Secondly, the labels for most model training datasets are derived from manual annotations by cardiology experts, which is time-consuming and labor-intensive. This limits the number of ECGs available for training. Also, because cardiology experts typically use a unified annotation system, the richness of the dataset labels is not very high, often only including common ECG abnormalities and omitting many important but rare diagnostic labels.[35] Thirdly, due to the training methods used, these models do not support both 12-lead and single-lead ECGs. To address these issues, we propose a foundation model for ECGs that supports both 12-lead and single-lead ECGs."}, {"title": "5. Conclusion", "content": "In this work, we proposed and validated the efficacy of ECGFounder in adapting to a wide range of cardiovascular diagnostic applications, demonstrating its high performance and versatility across various downstream tasks as a foundational ECG model. By overcoming the limitations related to ECG data and labeling diversity, as well as training methods, the ECG foundation model confirms its potential to transform the standard of care in cardiology and to provide real-time, accurate cardiac assessments in diverse clinical settings."}]}