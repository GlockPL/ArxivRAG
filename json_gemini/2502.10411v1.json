{"title": "TrueReason: An Exemplar Personalised Learning System Integrating Reasoning with Foundational Models", "authors": ["Sahan Bulathwela", "Daniel Van Niekerk", "Jarrod Shipton", "Maria Perez-Ortiz", "Benjamin Rosman", "John Shawe-Taylor"], "abstract": "Personalised education is one of the domains that can greatly benefit from the most recent advances in Artificial Intelligence (AI) and Large Language Models (LLM). However, it is also one of the most challenging applications due to the cognitive complexity teaching effectively while personalising the learning experience to suite independent learners. We hypothesise that one promising approach to excelling such demanding use-cases is using a society of minds. In this chapter, we present TrueReason, an exemplar personalised learning system that integrates a multitude of specialised AI models that can mimic micro skills that are composed together by a LLM to operationalise planning and reasoning. The architecture of the initial prototype is presented while describing two micro skills that have been incorporated in the prototype. The proposed system demonstrates the first step in building sophisticated AI systems that can take up very complex cognitive tasks that are demanded by domains such as education.", "sections": [{"title": "1 Introduction", "content": "The use of Artificial Intelligence (AI) in education has caught the attention of many computer scientists and educators in the last few years. In AI-supported education, sub-topics range from personalised learning to Feedback Generation to Retention and Learner Success modelling. In personalised learning systems, Educational Recommendation Systems (EdRecSys) cover a wide variety of systems that support informal learners to acquire knowledge from suitable learning resources. With the"}, {"title": "1.1 Chapter Overview", "content": "This chapter describes the TrueReason system. Section 2 informs the prior work setting the context to the proposal by describing the different components of a personalised learning system and linking it to the current advances in LLMs that motivate the design choices utilised. Section 3 describes the proposed exemplar personalised learning system with its subcomponents. This is followed by section 4 where two of the integrated micro skills, namely reinforcement learning-based multi-step recommender (section 4.1) and topic-controlled question generation (section 4.2) are described in detail with specific results. The broader discussion that links the proposed method and its ability to create sophisticated learning companions while breaking sustainability and accessibility barriers to the system is done in section 5 and the chapter is concluded in section 6."}, {"title": "2 Personalised Learning Systems", "content": "A wealth of research has been conducted on improving personalised learning systems. Among the applications that utilise personalised learning, intelligent tutoring systems and educational recommenders dominate the literature. In this section, we review and discuss in detail the different components of a personalised learning system."}, {"title": "2.1 Components of a Personalised Learning System", "content": "A personalised learning system incorporates different components that interact with each other to recommend suitable learning trajectories to learners. These core com-ponents of a conventional personalised learning system can be seen in Figure 1."}, {"title": "2.2 Domain Model", "content": "For any knowledge area, it is possible to define a scope of specific topics and subtopics that are relevant when learning. Such a structure also allows for identifying prerequisites that need to be covered earlier in the lesson sequence to provide the foundational knowledge complementary to understanding more advanced topics. Such a structure that can be exploited in creating effective lesson plans is identified as a domain model."}, {"title": "2.3 Learning Resources", "content": "While the domain model defines the structure of knowledge, learning materi-als/resources are required to carry out the actual learning. Therefore, a core compo-nent of any educational system is the collection of educational resources. Learning materials can come in different modalities (e.g. video/audio/text etc.), and different languages entailing many types of activities (e.g. questions, instructional videos, les-son summaries, interactive games etc.). The early definition of interactive educational resources was limited to dynamic modalities such as simulations and educational games. With the advent of AI, the scope of this definition has expanded significantly where AI-enabled innovations such as intelligent textbooks have also joined. The diversity of learning materials is important to provide novel learning experiences while increasing learner engagement.\nWhile in-person instructional lecturing has been a main form of knowledge trans-fer from the inception of education, adapting this teaching method to the digital realm has led to educational videos. With the mass availability of Internet connec-tivity and the popularisation of platforms such as YouTube, we find 100,000s of educational videos being created and being made available via the Internet. The mass availability of video-based educational resources was further expanded with the introduction of Massive Open Online Courses (MOOCs). Due to their heavy presence and effect, educational videos are extensively researched in the literature. A wealth of research attempts to build educational recommendation systems around video collections. Many work studies learner engagement with videos while others propose good practices to create engaging educational videos. Our prior work also has studied building educational recommendation systems for educational videos including releasing public datasets based on learner engagement with educational videos such as PEEKC and VLE datasets. This work builds the final recommender using a collection of educational videos from the PEEKC dataset [9]."}, {"title": "2.4 Learner Model", "content": "A learner model is a representation of the learner's state. This can be based on a multitude of verticals. A few frequently used verticals are learner knowledge/skill mastery [19, 70, 65] and interests/goals [71, 14]. We can hypothesise the relationship between learner engagement and the learner state using the probability distributions presented via equations 1 and 2 where learner l interacts with learning materials $r_x$ that consists of knowledge components $K_{rx}$. The latent knowledge and interest states of the learner l at time t are $\\theta^k_t$ and $\\theta^i_t$ respectively.\n$P(\\theta^k_{l,t}|r_x, K_{rx}) \\propto P(e_{l,t}^{rx}| \\theta^k_{l,t}, K_{rx}).P(\\theta^k_{l,t})$\n$P(\\theta^i_{l,t}|r_x, K_{rx}) \\propto P(e_{l,t}^{rx}| \\theta^i_{l,t}, K_{rx}).P(\\theta^i_{l,t})$"}, {"title": "2.5 Pedagogical Model", "content": "Even with the presence of key components such as a learner model, a domain model, and a comprehensive database of learning materials, a well-designed teaching strategy remains crucial for sequencing the most appropriate learning materials for each individual learner. This strategy serves as the guiding framework to ensure that educational content is not only relevant but also delivered in a manner that maximises the learner's engagement and understanding.\nA teaching strategy can draw from various pedagogical models and adapt to differ-ent learning preferences. For example, approaches like Vygotsky's zone of proximal development can help guide learners through tasks that are just beyond their current ability but can be mastered with appropriate support. Previous personalised models have e.g. integrated pedagogical theories of development [6]. Similarly, strategies can account for different cognitive or sensory learning styles, such as visual, audi-tory, kinesthetic, or reading/writing preferences, tailoring the instructional methods to better align with how each learner absorbs information.\nThese preferences and pedagogical models can also be refined dynamically, based on the learner's ongoing interactions with the system. For instance, as learners engage with the platform, it can track their progress, analyse their responses, and adjust the instructional sequence or methods to optimise their learning journey. This adaptability ensures that the teaching strategy evolves in real-time, providing increasingly personalised learning pathways.\nMoreover, learners often have distinct preferences regarding the modalities through which they consume educational content. Some may prefer watching in-structional videos, others might benefit from reading detailed texts or engaging with interactive simulations. By integrating a variety of content formats\u2014such as videos, infographics, text, quizzes, or hands-on activities-the teaching strategy can cater to diverse learner needs and ensure a richer, more inclusive learning experience.\nIncorporating these factors-pedagogical models, learning preferences, and con-tent modalities\u2014not only makes the learning process more personalised but could also enhance learner motivation and retention. A well-constructed teaching strat-egy has the potential to make education more inclusive by recognising the unique strengths, challenges, and preferences of each learner, ensuring that no one is left behind and that all learners are supported in achieving their full potential."}, {"title": "2.6 User Interface", "content": "The final component, the user interface, is essential for bridging the intelligence of the personalization system with the human learner. It serves as the primary point of interaction, allowing users to engage with a highly complex personalized learning environment in a simple and intuitive manner. While the system itself may consist of numerous sub-components\u2014such as recommendation engines, content delivery systems, and real-time data analysers\u2014the user interface is responsible for presenting this complexity in a way that feels seamless and accessible to the learner. By obfuscating the underlying technological intricacies, it allows learners to focus solely on their educational goals without being overwhelmed by the system's internal workings.\nAn effective user interface is not just a functional necessity; it is an integral part of the overall learning experience. It determines how learners navigate through ma-terials, how they receive feedback, and how they interact with adaptive features that cater to their unique needs. A well-designed interface can significantly enhance en-gagement, motivation, and learning outcomes by making the system feel responsive, personalized, and user-friendly.\nInnovative approaches have emerged to refine this critical aspect of personalized learning systems. Designers and developers now prioritize creating interfaces that are not only functional but also intuitive, adaptive, and visually appealing. Key strategies include minimizing cognitive load by reducing unnecessary complexity, providing clear navigation and guidance, and offering real-time support or hints as learners progress through tasks. The goal is to make the system feel as natural and effortless to use as possible, encouraging learners to explore and engage deeply with the content.\nOne particularly promising recent innovation in this area is the use of large language models (LLMs) to enable conversational interaction and intelligent search. LLMs allow for a more human-like interaction between the learner and the system. Rather than navigating through rigid menus or predefined pathways, learners can simply ask questions, request specific content, or seek clarification using natural language.\nIn summary, the user interface is far more than a superficial design layer; it is the conduit through which learners experience the full capabilities of a personalized learning system. By making the interface seamless and incorporating cutting-edge technologies like large language models, developers can create an environment that not only adapts to individual learning needs but also feels intuitive and engaging, empowering learners to achieve their educational objectives with greater ease."}, {"title": "2.7 Large Language Models and Knowledge Intense Tasks", "content": "With the recent advancement of deep learning, the SOTA of many applications fronts have shifted to deep neural models. Among these advances, LLMs have made"}, {"title": "3 TrueReason System", "content": "Many educational recommendation systems and personalised learning platforms to-day operate within a low bandwidth of learning activities. This means the variety of skills an educational recommender uses is limited to a single activity like rec-ommending videos, web pages or exercises and seldom utilises a multitude of skills such as recommending a video \u2192 presenting a quiz \u2192 giving feedback. However, a good human teacher would break beyond such a narrow band and incorporate a diverse set of learning activities in variable combinations to make a rich and en-gaging learning experience. Where self-regulated learning is critical (e.g. informal learning), contextualising teaching strategy can lead to success. TrueReason Assistant is a personalised learning system that attempts to build a revolutionary learning"}, {"title": "3.1 Problem Background", "content": "TrueReason serves as demonstration of how key limitations found in many educa-tional recommenders can be addressed within the same system. Some of the issues TrueReason addresses are:\n1. Learner On-boarding: When a new learner begins to use the personal recom-mender, a new model must be initialised to represent the learner's knowledge state as accurately as possible to provide relevant recommendations early on. In this case it is useful to elicit learners' background knowledge in a more direct way than observing engagement and use an alternative recommendation strategy until TrueLearn has a robust estimate from engagement events [10].\n2. Learning Goals: To assist the learner beyond recommending novel and engaging educational content, it is useful to base interactions on a basic situation model which firstly keeps track of learning goals but also allows the learner to monitor and steer their own progress by providing relevant information and feedback about knowledge components and their own knowledge state. This augments learners' agency and allows them to take control of their learning trajectory instead of being passive receivers of recommendations [57].\n3. Content Ontology: In contrast to traditional courses for more short-lived educa-tional scenarios, lifelong learning supported by open educational resources has to contend with a more diverse and rapidly changing set of resources which are likely not designed to compose as do lectures in a more formal setting. However, being able to inform learners according to the structure and relations between materials could assist them on their learning path [30].\n4. Knowledge Review: While using implicit feedback (dwell time and consumption behaviour) is data efficient, having explicit self-testing opportunities helps 1) inculcate self-awareness within the learner and 2) help the learner model to verify the precision of its knowledge state estimates. Appropriate question generation models [8] could be used to allow learners to test their knowledge or serve as a source of information to initialise or verify the learner knowledge state estimated by TrueLearn. In this direction, personalised question generation can help the AI assistant to create ad-hoc tests to individuals.\n5. Knowledge Gaps: Because the available set of educational resources are not necessarily designed to be comprehensive combined with the absence of a formal educator, learners may find that knowledge gaps persist after engaging with mate-rials or that they need clarity on unfamiliar concepts. These gaps or explanations could be addressed by world knowledge contained in a large language model or methods for generating analogical explanations [63] which rely on learners' background knowledge."}, {"title": "3.2 System Architecture", "content": "The overall architecture of the TrueReason system is presented in Figure 2. The system uses a chat interface to interact with the learner. Behind the user interface, the chat component (Chat server) handles the conversation with the learner while it has access to different skills (micro-skills to be more precise) that it can utilise to make the conversation more systematic, structured and dynamic. Access to micro-skills (such as query learner state, generate personalised questions, create a learning pathway etc.) is provided through the TrueReason API Server. In this iteration, the TrueLearn model [54] is used and we use a set of educational videos as a collection of learning resources.\nContrary to conventional AI-enabled educational systems, TrueReason can in-corporate a diverse set of activities within the learning pathway. Figure 3 outlines the logical structure of the TrueReason assistant. As per the figure, the system uses different forms of two-way interaction such as recommendation, retrieval, extracting interest and experience, questioning and evaluation etc. leading to a rich interaction between the learner and the system."}, {"title": "3.3 Domain Model", "content": "As is the practice in TrueLearn, the content model relies on Wikification to extract knowledge components (KCs) from online educational resources and represent them as sets of Wikipedia topics [5]. Each entry or page in Wikipedia could be considered a valid KC and any resource can be described as a sequence of such sets of topics along with a measure of overlap between the coverage in the resource and the entry in Wikipedia. Segmentation of the resource can be done along defined sections in a document or by taking fixed length slices of videos and audio see the PEEKC Dataset [9] for an example and a description of the conventions also followed here. To construct the content model given an arbitrary collection of educational materials we segment each resource individually and apply Wikification as described above."}, {"title": "3.3.1 Modelling Relatedness Between KCS", "content": "A weighted directed graph for each resource is then constructed where a link is created between each KC and all those following it in subsequent segments in the same learning resource. The weight of the link is determined by the frequency of one KC being followed by another. All individual resource graphs are then merged by aggregating the link weights to form a single KC graph which contains information"}, {"title": "3.4 Situation Model", "content": "The situation model is responsible for all interactions with new and ongoing learn-ers including dialogue, recommendation, engagement, and knowledge review. To implement these four broad aspects, the state about each need has to be tracked continuously. As per figure 2, this is implemented by a large language model (LLM) assistant (ChatGPT at present) combined with:\n1. Tools external to the core system that implement specific functionality (micro skills) such as multi-step recommendation or question generation \u2013 e.g. see section 4.2 about contextualised education question generation."}, {"title": "3.4.1 Dialogue States", "content": "Dialogue with the learner can be thought of as cycles between three 3 states broadly associated with (1) clarification of learner background and goals, (2) engagement with a recommended resource, and (3) knowledge review and explanation. However, these states are only implicit in the instructions provided to the LLM assistant and so learners' are afforded considerable latitude in their interactions and requests - the state is essentially captured by the dialogue message history."}, {"title": "3.4.2 Revision of Learner Background and Goals", "content": "Initial interaction is aimed at eliciting learners' background knowledge and topics of interest in a two-way dialogue which makes use of the content model to inform the learner of related topics and prerequisites they may need to be aware of. This is facilitated by the LLM assistant prompting the learner and extracting (Wikipedia) topics of relevance from their responses to call functions that add, remove, or retrieve KCs that represent learner interest and goals in the application database. In order to present related topics, the assistant has to call a function which queries the domain model as described in Section 3.3 and translates the result into natural language.\nTaking the example in Figure 3, the dialogue may proceed as follows:\nLearner: I'm interested in knowing more about computational linguistics\nAssistant calls get_related_topics(Computational Linguistics)\nAssistant: Understanding Computational Linguistics depends on having a grasp of Probability Theory and Stochastic Processes and is often applied in Document Classification. Do you need to review any of the fundamentals or are you more interested in focussing on practical applications?\nThis dialogue typically continues until the user asks for a video recommendation or the assistant suggests the same and the learner agrees."}, {"title": "3.4.3 Knowledge Review and Explanation", "content": "Once a learner has engaged with a resource, it is possible to request explanations and clarifications to address knowledge gaps or initiate a knowledge review quiz covering the recommended resource. The former currently relies on the LLM as-sistant's internal world knowledge but in future could be based on functions that provide well-motivated explanations, for example, using analogies that are identified as appropriate using learners' known background knowledge [29, 63]. Also, the be-haviour here can extend from explanations to summarisation of previously consumed learning materials.\nIf a quiz is requested or agreed to, the assistant calls a function which generates a number of questions and returns them along with answers one at a time whereupon the LLM presents them to the user and scores the answers. Section 4.2 explains how a micro-skill is developed to generate educational questions contextualised to specific Knowledge Components from a previously consumed learning resource. The ability to control the topical relevance of the questions allows the assistant to use the learner model to personalise the testing opportunity. In the initial version of the assistant, the results are simply captured for later use, but future versions should be able to use the results to update learners' models appropriately. Also, the behaviour can be extended to the assistant using personalised quizzes to improve its confidence in learner skill estimates voluntarily, without the learner explicitly requesting a quiz."}, {"title": "3.5 Engagement with Recommended Resources", "content": "To recommend a resource, the assistant calls a function which recommends a resource from the content index by considering learners' background knowledge, interests, their TrueLearn engagement model (see Section 3.6), and immediate engagement history. This introduces the title of the video and sets the current recommendation link to view the video as well as making it possible for the LLM to call functions that retrieve additional information for the resource when relevant. This currently includes access to the raw transcript and KCs covered (from Wikification). The learner thus has a number of options for engagement, including simply viewing the video or asking the assistant for a summary or key points covered after which they may, for example, choose to request a different recommendation without viewing the content. If the learner chooses to view the video, an engagement event is registered by the interface similar in convention to the events described in the PEEK Dataset [9] which is used to update a TrueLearn engagement model for the learner."}, {"title": "3.6 Learner Model", "content": "As per figure 3, interests and experience are the two main factors considered by the TrueReason system concerning user state. Resources are recommended based on learners' interests and background knowledge. We use the TrueLearn model [14], one of our prior works, capable of capturing both learner interests/goals and knowledge as the learner model. Another key advantage of TrueLearn is its ability to capture learner knowledge/interest state in a humanly intuitive format [54], which is beneficial in building a human-centric AI system. A limitation of TrueLearn is the inability to recommend materials for a new user. In the proposed TrueReason system, the conversation interface initially converses with the learner to identity their current knowledge, interests and goals. The recommendations in the inception of the learner journey are based on resources that overlap with the set of topics of interest. At the same time, engagement signals are collected with the recommended learning resources to estimate the TrueLearn model in the \"cold start recommendation regime\".\nOnce enough engagement events have been observed the TrueLearn model is used to make recommendations by means of calculating the engagement probability of re-sources in the content index with the TrueLearn novelty classifier \u2013 the \u201cengagement model recommendation regime\u201d. This method is similar to the switching-based hy-brid recommendation we have used with TrueLearn in prior work [14]. In the prior work, we used a popularity-based prior [13] rather than a prior extracted by an LLM using conversation. This approach is designed to be a baseline approach which begins to address the cold start problem for new learners while a more advanced recommendation is developed. For more information about the development of a more advanced recommendation model that can serve as a drop-in replacement for this baseline, readers can refer to the the reinforcement learning educational recommender described in section 4.1."}, {"title": "4 Micro Skills", "content": "In Sect. 3.6 the TrueLearn novelty classifier is recommended as the baseline approach to address the cold start problem. This approach serves to establish an estimation of the knowledge components which form the learner's interest as well as their knowledge state. Once the learner's interests and knowledge state is established it is possible to create a trajectory of resources to recommend to the learner in order to improve their knowledge state over their interests. This is a non-trivial task given that the trajectory over the resources from one knowledge state to a desired knowledge state cannot always be achieved by simply recommending resources that directly involve the learner's interests. Many knowledge components in the the"}, {"title": "4.1 Reinforcement Learning Multi-step Educational Recommender", "content": "learners identified interests may require prerequisite knowledge components before a learner would be willing to engage with a recommended educational resource. This implies that there is a delayed reward for engaging with resources that don't necessarily directly involve the interest of the learner, but rather indirectly aid the learner to further engage with their interests. This creates a sequential decision-making problem as to which resource should be recommended. Having an expert to identify the prerequisites of any knowledge component will not always be possible. It is thus required that these trajectories be learned. However, it is seldom the case that we have enough data from learners to learn these trajectories, and thus we need a strategy to learn these trajectories. In this section a method for a learning such a viable trajectory through available educational resources is established using reinforcement learning."}, {"title": "4.1.1 Markov Decision Process", "content": "A general RL environment is setup as a Markov Decision Process (MDP), which consists of an agent interacting with an environment. The agent will receive an observation $o_t \\in O(s_t)$ which is derived from the true state of the environment $s_t \\in S$ at each time step t. The agent will perform an action, $a_t$ obtained from its policy $\\pi(s_t)$. The probability of the transition of the $s_t$ to $s_{t'}$ and $o_t$ to $o_{t'}$ is given by $T(s_t, o_{t'} s_{t'}, a_t)$. A reward $r_t$ is given at each time step and is given by the environments reward function R(st, at). The goal of the agent is to maximise the total expected reward, $E[R_t] = \\Sigma_{t'=t} \\gamma^{t'-t} r_{t'}$, where $\\gamma$ is the discount factor."}, {"title": "4.1.2 Training Environment", "content": "In order to adapt the problem of learning a trajectory through a set of given resources we will need to establish an environment in which the recommender system (the agent) can learn which are appropriate resources to recommend. An approach of simply learning trajectories from known successful learner's activity could be used, however, data of that nature is not freely available in all cases and thus the need for a suitable proxy to generate such data arises. TrueLearn has the capability to predict engagement of a learner given enough interactions to estimate that learner's knowledge state. Thus, under the assumption that enough interactions have occurred to estimate the correct learner knowledge state, TrueLearn can be used proxy for learner engagement in the absence of learner engagement data. This gives TrueLearn the dual purpose of both estimating the learner's knowledge state and interests as well as the ability to be used as the proxy for learner engagement.\nTaking the assumption that the ground truth knowledge state (GTKS) is known for a given learner then an instance of TrueLearn can be instantiated to act as an artificial learner and give a suitable indication of engagement as well as give a simulated update to the GTKS based on engagement of the resource. This allows the construction of an environment capable of simulating any number of artificial"}, {"title": "4.1.3 Deep Deterministic Policy Gradient", "content": "Given the continuous nature of the state and actions in this environment an appropri-ate RL algorithm is that of Deep Deterministic Policy Gradient (DDPG) [36]. This is a off-policy algorithm, making it perfect for training from both simulated data and data collected from actual learners. This actor-critic model based off of the Deep Q-Leaning Networks (DQN). That is, it uses the concept from the Bellman equation:\n$Q*(s, a_t) = E[r(s_t, a_t) + \\gamma max_a Q* (s_{t'}, a_{t'})]$.\nAs seen in Figure 6, this is a model designed to have an actor which interacts with the simulated training environment described in Sect. 4.1.2, using its policy $\\pi(o_t)$ to provide an action $a_t$, note, the policy uses the observation derived from the state, as the true state of the environment is not available to the actor. These these actions are then mapped to available learning resources, with the KC-vec related to the learning resource being stored as the action in the experience replay buffer (the experience pool). The critic, using the action created by the policy of the actor, as well as the replays from the experience replay buffer, is then used to obtain the value function Q(st, at). The target networks in both the actor and the critic are used to aid in the stabilisation of learning the value function as well as help approximate future expected values of the value function based on the state at the next time step. These are updated to match the current online versions after a fixed number of time steps.\nUsing this framework we set up an actor with three linear fully connected layers, each followed be a ReLU function, with the last layer using a tanh to produce the recommended KC-vec. The critic uses three linear fully connected layers, each followed by a ReLU function, and the output of the last layer is used as the value function."}, {"title": "4.1.4 Results", "content": "To test the RL educational recommender, three experiments were run with the training environment. For each experiment we initialised a user with the same GTKS and the same set of interest topics, these were run 5 times for each model. The GTKS is used strictly for engagement prediction using the TrueLearn model and the reward function is calculated based on the change in the GTKS after updating the GTKS as"}, {"title": "4.1.5 RL Recommender Conclusion", "content": "The RL Recommender informed by TrueLearn as a proxy human has been shown to be capable of recommending a sequence of resources to increase a learners knowledge state in specific interests based on the engagement and updates done by the TrueLearn model. Future work entails checking the qualitative flow of the recommended resources and end ensure that there is a logical flow of topics, and not just arbitrary jumps between the learners interest topics."}, {"title": "4.2 Automatic Topic-Controlled Educational Question Generation", "content": "Creating lesson materials and generating topic-specific, relevant, and age-appropriate questions for teaching have long been identified as time-intensive tasks for teachers, and an area where increased consistency is also expected to improve educational out-comes for students [?]. Although learning analytics and AI in Education researchers have long explored ways to support teachers' question generation capabilities through data-driven insights and models, attempts on Topic-Controlled Question Genera-tion (T-CQG) have been less successful, primarily due to the lack of quality in the generated content. The use of language models, however, has the potential to address these quality concerns by leveraging recent advancements in natural language pro-cessing (NLP) for automatic educational question generation (EdQG). EdQG (and T-CQG) models can be integrated into personalised learning systems, to advance the system's capability to perform precise diagnostics on learner's knowledge gaps (pro-viding contextualised formative/summative assessment). From the learners' points of view, prior research also suggests a strong correlation between the personalisa-tion of testing and knowledge retention [?], which further supports the importance of topic-controlled question generation. T-CQG can serve as a small yet important micro skill that enhances TrueReason.\nEducational Question Generation (QG) involves automatically generating ques-tions from a specific text passage or a document. The main goal of QG is to produce"}, {"title": "4.2.1 Problem Definition", "content": "Topic-controlled question generation takes a target topic in addition to the descriptive text as context into account while generating the models' outputs. To define topic-controlled question generation (T-CQG) precisely, let us suppose a learner l has consumed study resources that containing knowledge c linked to various topics Tc. TrueReason's goal is to generate questions $\\hat{q_t}$, where $\\hat{q_t}$ is an educational question about the target topic t, where t \u2208 Tc, and $q_t$ consists of a sequence of tokens $q_t \\in \\{W_1,..., W_{|q_t|}\\}$, of arbitrary length $|q_t|$. The generated question not only requires to be contextually relevant to c, but align with the topic t. This task can be represented to identify the optimal question $q_t$ that maximises the conditional probability as per equation 5.\n$ \\hat{q_t}= \\arg \\max_q p(q_t|c,t) = \\arg \\max_q \\log p(w_i |c,t, w_1... w_{i-1})$\nwhere, $p(q_t|c,t)$ denotes the conditional probability that also depends on the tokens $w \\in q_t$."}, {"title": "4.2.2 Research Questions", "content": "This work revolves around one main research question:\n\u2022 Is it feasible to fine-tune a pre-trained language model (PLM) to perform T-CQG?"}, {"title": "4.2.3 Datasets Utilised", "content": "We used the SQUAD 1.1, the Stanford Question Answering Dataset, comprising over 100,000 questions crafted by crowd workers based on a selection of 536 Wikipedia articles [56] as the source for creating new datasets (SQuAD+ and MixSQUAD as described in section 4.2.4 below) for fine-tuning the models.\nFor evaluation, we used the KhanQ dataset [27] as it presents a more relevant chal-lenge for educational question generation. It includes 1,034 high-quality questions in the STEM fields generated by learners, which aim to probe deep understanding of subjects taught in Khan Academy's online courses 3. Despite its smaller size relative to SQUAD, KhanQ aligns more closely with our objective to generate topic-based and relevant educational questions (as per prior work [24]). To adapt the dataset for topic-based evaluation, we use the same approach as MixSQUAD (section ??) to create a dataset with contrasting topic-based questions. We refer to the transformed version of the KhanQ dataset as MixKhanQ dataset."}, {"title": "4.2.4 Creating Novel Datasets for T-CQG", "content": "A core contribution of this work is to introduce a novel data enrichment method that leads to the creation of new datasets that are derived from conventional question generation datasets. As described in 4.2.3, we derive the new datasets from SQUAD and KhanQ. These datasets already contain the context c and the label question qt from a human (contrast to $\\hat{q_t}$ in equation 5 which denotes the generated question). We append an additional field to the dataset, Topic t, and create three novel datasets, 1) SQUAD+ and 2) MixSQUAD for the T-CQG task. The process of generating the three datasets is presented in figure 8.\nLinking the Target Topic to Data Points, SQUAD+ Dataset\nTo identify semantic annotations for every context and question, we employ wikifi-cation [5], which annotates text inputs with relevant concepts from Wikipedia (Tc). We retain the top 5 concepts for each text (context and question) based on their PageRank scores, which reflect the authority of the concept over the annotated text. To make sure that we can link the topical alignment between the question and the context, we only retain examples where at least one common Wikipedia concept is"}, {"title": "4.2.5 Models", "content": "With the relevant datasets created", "55": "model", "24": ".", "38": "for controlling complexity in simplifying texts although our dataset creation method is very different.\nBaseline Model: We used the proposed SQUAD+ dataset (described in section 4.2.4) to finetune the T5 PLM.\nTopicQG Model: The key difference between the baseline model and the pro-posed TopicQG model lies in the data used for fine-tuning the T5-small model. We introduced the TopicQG model to contrastive examples using the novel dataset created, MixSQUAD ("}]}