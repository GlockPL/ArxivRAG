{"title": "Plan-over-Graph: Towards Parallelable LLM Agent Schedule", "authors": ["Shiqi Zhang", "Xinbei Ma", "Zouying Cao", "Zhuosheng Zhang", "Hai Zhao"], "abstract": "Large Language Models (LLMs) have demonstrated exceptional abilities in reasoning for task planning. However, challenges remain under-explored for parallel schedules. This paper introduces a novel paradigm, plan-over-graph, in which the model first decomposes a real-life textual task into executable subtasks and constructs an abstract task graph. The model then understands this task graph as input and generates a plan for parallel execution. To enhance the planning capability of complex, scalable graphs, we design an automated and controllable pipeline to generate synthetic graphs and propose a two-stage training scheme. Experimental results show that our plan-over-graph method significantly improves task performance on both API-based LLMs and trainable open-sourced LLMs. By normalizing complex tasks as graphs, our method naturally supports parallel execution, demonstrating global efficiency.", "sections": [{"title": "Introduction", "content": "The commendable progress in large language models has facilitated the impressive capability of agents for complicated, interactive tasks. Recently studies have demonstrated that generating a plan before execution enhances agents' performance, referred to as the plan-then-execute framework. Planning integrates global knowledge, enabling overall coherence rather than just local optimality. Planning breaks down complex tasks into subtasks as single-step operations, which is especially crucial for tasks requiring intricate workflows and precise action interfaces, such as UI control and software engineering. Despite the inspiring progress, the parallelism of the plan remains under-explored. Multi-step agentic frameworks generally default to blocking pipelines, where each step waits until the previous ones to complete, regardless of whether it depends on their outcome. The reasoning capabilities of agents are significantly stimulated by Chain-of-Thoughts (CoT), enabling them to divide and conquer a complex task. Although the reasoning structure is expanded to trees and graphs, the actions for sub-tasks are taken sequentially. However, these sub-tasks can run in parallel if independent of each other. While recent studies have explored the time efficiency of asynchronous execution, gaps remain when applied to real-world scenarios."}, {"title": "Related Work", "content": "This section introduces the background of agent planning and graph understanding of LLMs."}, {"title": "Planning for LLM-based Agents", "content": "Autonomous agents that interact with an environment to solve complex tasks. Planning involves developing an action sequence before execution, leveraging global knowledge of the task and environment to suggest a logically consistent trajectory. Planning decomposes a complex task and selects a feasible trajectory based on global knowledge. Searching strategies are applied to explore the optimal plan, such as depth-/breadth-first search and Monte Carlo tree search. When environmental feedback supplements perception heavily and updates the task knowledge, planning involves reflection to refine the trajectory incrementally. A world model or a reward model integrates global knowledge and predicts the environment states or estimates rewards."}, {"title": "LLM on Graphs", "content": "As realistic intricate challenges can be formed as graphs, recent studies explore the LLMs' capabilities for reasoning with graphs. Graph-of-Thought first proposes to transform the problem thinking into an arbitrary graph to enable the generation, aggregation, and refining of sub-tasks. Also extract deductive triplets from contexts and build graphs. Knowledge graphs support faithfulness and inference transparency for knowledge-intensive tasks. combines graphs with natural language prompts for reasoning about asynchronous plans in real-life tasks, instructing model to either reason based on a given graph or to generate a graph themselves and then reason about it.\nHowever, it is demonstrated that the capabilities of graph reasoning and understanding decrease as the scale and complexity of graphs increase. Empirical studies have observed a \u201ccomprehension collapse\u201d phenomenon as the graph size increases. DARG evaluates LLMs' reasoning capability on graphs and also reports a performance decrease with increasing complexity of graphs.\nDifferent from existing work, our paper further provides a more formal and scalable definition of the planning task's graph structure, which captures the inherent complexities and dependencies of the task. Our planning-over-graph offers a general framework, independent of the specific nature of the task. Additionally, we demonstrate the effectiveness of this approach by training models on these graphs, achieving significant improvements in performance."}, {"title": "Preliminary: Problem Statement", "content": "This section formalizes the problem of planning on task graphs and presents a preliminary analysis to identify the key challenges."}, {"title": "Formulation of Planning", "content": "Planning requires an agent to decompose a high-level task description into executable subtasks, schedule their execution under dependencies, optimize for time, cost, or multi-objective criteria, and finally achieve the goal. Formally, given a task description, the model generates a plan P by solving the tuple (G, \u03a9), where G denotes the complex task and \u03a9 denotes the global criteria.\nAny high-level task description can be represented as a Directed Acyclic Graph (DAG),\n$G = (T, E), T = \\{t_1,t_2,...,t_n\\},$ (1)\nwhose vertices are constrained by the precedence relationship formed by edges. e,g., $t_i < t_j$ means $t_i$ must precede $t_j$. One feasible plan P is a subgraph of G that satisfies $G, P \\subset G$.\nIn realistic scenarios, there are criteria for constraints like execution time. We formally define a global function \u03a9, where the optimal plan minimizes \u03a9 while achieving the task,\n$P_{opt} = \\arg \\min \\Omega.$ (2)\nThe measurements examine whether the predicted plan is optimal or at least feasible, and also compute the metrics of global criteria. Specifically, given each predicted plan P on a test dataset D, three kinds of metrics to evaluate its helpfulness:\n(i) Optimal Rate: The proportion of optimal plans,\n$OR = |P = P_{opt}|/|D|.$ (3)\n(ii) Success Rate: The proportion of plans that successfully achieve the goal.\n$SR = |P \\in \\{P\\}|/|D|.$ (4)\n(iii) The values of considered global criteria \u03a9."}, {"title": "Challenges of Planning", "content": "Existing explorations leave two critical limitations. (i) Understanding graphs is currently a bottleneck in complex task planning for LLMs. has shown that even with explicit graph representations, there is still a huge gap in handling complex graph topologies, suggesting unresolved challenges in structural reasoning. (ii) The scale of the currently considered graph is still very limited. considered graphs with majority nodes in the range of 2 to 10 steps. most of the graph complexity $|V| + |E|$ are also between 10 and 20.\nConsidering these limitations, we design an experiment for a pilot study. We construct 100 random graphs with 10, 30, 50 nodes and ask LLM to find the shortest path as the solution. This empirical evidence demonstrates that the core bottleneck lies in planning competence on graph topology under complex constraints. These findings inspire us to prioritize understanding capabilities on complex graphs with constraints to enhance the planning task."}, {"title": "Methodology: Plan-over-Graph", "content": "We propose the plan-over-graph paradigm. Given a textual query, the LLM is prompted to gather information and build the task graph. Then, the task graph is input, on which we have the model perform planning. Then, we focus on enhancing the graph understanding for the plan stage.\nIn the following Section 4.1 and 4.2, we propose a data construction method to acquire a large amount of controllable graph data automatically. Then, we design a training pipeline with these graph data (Section 4.3). Finally, we combine these two steps to form the plan-over-graph paradigm for inference.\nFirst, we redefine the planning task on graph structure. Without the loss of generality, we consider time and cost limits for \u03a9, the plan needs to minimize makespan or total cost.\nTask Graph. We define rules, $R = \\{r_i\\}$, that allow parallel execution on a graph. For each node\n$r = (S,t,\\tau,c).$ (5)\nA rule states that after S is satisfied, t can be executed with the required time \u03c4 and cost c.\nQuery. A query including prior knowledge and ultimate goal can be denoted as the initial node set and the target node as\n$q = (I,t_{target}),$ (6)\nPlan. The overall plan P is a set of several sub plans, each denoted as\n$p = (S,t, D), p_j \\in D_i \\rightarrow t_j \\in S_i$ (7)\nwhere S and t are the preceding vertices and the subtask, determining a ruler \u2208 R. D captures the dependencies between sub-plans.\nCriteria Here, we define the two considered global criteria, time consumption and cost. Sub-tasks that are independent of each other can be executed in parallel. In other words, $p_i$ only needs to wait for its dependency to end before starting execution. The end time of the execution of $p_i$ can be expressed as:\n$End\\_time(p_i) = \\max (End\\_time(p_j)) + \\tau_{pi},$ (8)\nThe global cost is defined as the sum of the cost values of all subtasks:\n$\\Omega_{cost}(P) = \\sum_{p \\in P} C_p.$ (9)\nWe consider the time consumption as the main criterion. Hence, $P_{opt}$ is the value that minimizes\n$\\Omega(P) = \\Omega_{time}(P) + \\epsilon \\cdot \\Omega_{cost}(P)$ (10)\nwhere $\\epsilon \\ll 1$.\nAccording to our graph definition, the \u03a9 is measured by Time Efficiency (TE) and Cost Efficiency (CE) as follows:\n$TE = \\frac{1}{n} \\sum_{i=1}^n \\frac{\\Omega_{time}(P_i)}{\\Omega_{time}(P_{opt})},$ (11)\n$CE = \\frac{1}{n} \\sum_{i=1}^n \\frac{\\Omega_{cost}(P_i)}{\\Omega_{cost}(P_{opt})}.$\nThe time and cost ratios of failed plans are assigned 4 as a penalty."}, {"title": "Data Simulation", "content": "Following our definition above, we design an automated, controllable, and scalable pipeline to generate synthetic data, which consists of the following steps:\n\u2022 Generate a connected DAG. Two distinct graph structures are employed: (i) Random DAGs. (ii) To better conform to the hierarchical structure in reality and avoid a large number of shortcuts in random graph, we also construct a tree-based structure. We first construct a tree with a depth constraint of no more than 4, and then, a small number of ancestral and cross edges are added to introduce additional dependencies and enrich the graph structure. The edges are all directed to the root. The structural trade-offs between these two graph representations are analyzed in Section 6.1. The graph is ensured to be connected, meaning there exists at least one path from the initial vertices to the target.\n\u2022 Define rules. For each non-head subtask t in the DAG, its predecessor vertices are randomly partitioned into groups as uniformly as possible. Then each predecessor group and t forms the source and target of one rule. Each rule is assigned a random time value, which is sampled from a uniform distribution ranging from 1 to 50. The cost for all rules"}, {"title": "Training Scheme", "content": "In this section, we focus on optimizing the model's ability on abstract graphs and improve its parallel planning capabilities. Our training has two stages: supervised fine-tuning and direct preference optimization.\nSupervised Fine-Tuning. We fine-tune an LLM on our abstract task datasets. This enables the model to solve planning tasks using graph representations of the problem space. We use the Low-Rank Adaptation (LoRA) method, which allows efficient adaptation of large pre-trained models by learning a small-size adapter. Two setups are considered for SFT: (i) fine-tuning with optimal data instances. (ii) to enable the model to learn both optimal and feasible solutions, we select the second-best solutions and mix them with the optimal solutions as the training data.\nDirect Preference Optimization. Following fine-tuning, direct preference optimization (DPO) is applied to distinguish the optimal solution from feasible ones. For each sample, the second-best solution works as the rejected output, while optimal solutions are the chosen output. This step further refines the model's ability to prioritize optimal solutions over feasible ones.\nAfter training, we aggregate the extracting and planning steps during the inference. Given a query with a goal description, we first extract the task graph from the description, then we generate the plan on the graph with the trained adapter loaded."}, {"title": "Experiment", "content": "Task Graph. The theoretical edge of a connected graph with node count n range spans from n \u2212 1 to n(n \u2212 1)/2. Massive edges lead to excessively long input when n is large. And tree-based graph structure also cannot have too many edges. Therefore, we adopt two practical strategies to avoid this: (i) linear scaling with edges \u2208 [2n, 3n] for random graphs and \u2208 [n, 1.5n] for tree-based graphs; (ii) uniform distribution across the full edge range, which is only used on random graphs.\nThe statistics of our synthetic data are shown in Table 2. The training set contains 12,000 training instances, divided equally across three node scales (10, 30, 50 nodes) and random and tree-based DAG structures. It employs uniform distribution edge configuration for 10/30-nodes graphs but restricts 50-nodes graphs to linear scaling. We generate 1000 input instances for each node scale and graph structure. Each input corresponds to an optimal solution and a chosen feasible solution. The testing set comprises two components: (i) baseline tests with linear edge scaling across node counts (10, 20, 30, 40, 50 nodes), each node count and graph structure containing 100 instances; (ii) edge-variation tests specifically for 10/30-nodes random graphs with uniformly distributed edges, to evaluate the model's ability to understand graphs as the number of edges changes. Due to the wide range of changes in the number of edges, we generate 1,000 instances each.\nTextual Query. To systematically evaluate the parallel planning capacity of the model in real-world task scenarios and validate our plan-over-graph paradigm, we construct an evaluation dataset utilizing the DeepSeek-R1 model. This dataset synthesizes 200 tasks derived from some real-world problem domains, where each task specification is transformed from graphs into executable workflow descriptions. The query data statistics are outlined in Appendix B."}, {"title": "Baseline", "content": "We evaluate our method against several baseline models, including API-based LLMs GPT-40 and Claude 3.5 Sonnet, and open-source LLMs, Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct. These models are selected for their strong performance and wide use. The evaluation metrics are detailed in Section 4.1. Detailed setups can be found in Appendix C."}, {"title": "Main Results", "content": "Table 3 presents experimental results. Our results answer the following three key questions.\nQ1: Can our training method teach the LLMs plan on the graph? Which method derives the best performance? The overall results for each model are shown in the upper part of Table 3. Overall, it can be observed that training largely improves the planning performance and the two-stage training achieves even better scores. Without training, Claude demonstrates high success rates (90.0%) but relatively lower optimal rates (39.2%). GPT-40 and Llama have similar success rates (51.3% and 52.3%), but GPT-4o achieves a higher Optimal Rate (14.1%) than 1.8% of Llama. Qwen shows weaker performance in both success and optimal rates (13.2% and 0.5%).\nOnly training on optimal solutions significantly improves graph understanding and planning ability, leading to a 75.7% success rate and a 61.4% optimal rate for Llama. Mixing feasible solutions further improves the performance to 86.1% and 67.5%. The best results of optimal rates (71.6%) are derived from the two-stage training, combining SFT on mixed data and DPO, maintaining high success rates (83.6%). This is because the model further tends to choose the optimal solution through DPO. We also observed consistent performance improvements on Qwen, which is inferior to Llama.\nQ2: What phenomena does the expansion of the graph scale lead to? As shown in the upprt part of Figure 3, when the number of nodes increases, which leads to a larger graph structure, the overall performance of all models decreases. For time and cost ratio, these models have shown similar sensitivity to the node count. However, the cost ratio of Llama is quite obviously increased, which shows its tendency to select more subtasks on larger graphs. For success rate, GPT-4o and Llama drop sensitively. When the number of nodes reaches 30, GPT-4o even falls below Llama. However, Claude and our trained model continue to demonstrate strong capabilities with less sensitive drops. Claude still suffers between 10 and 20 points on the optimal rate, indicating a gap in the understanding of larger-scale graphs. Across all node counts, our trained Llama significantly outperforms all other models on the optimal rate.\nThe lower part of Figure 3 shows the results of Claude and our trained Llama on the full range of edge counts for 1000 cases with 10/30-nodes, respectively. For 10 nodes, due to the number of nodes being small, both models have demonstrated robustness to changes in the number of edges across the metrics. For 30 nodes, as the number of edges increases, the difficulty for the model to find the optimal solution increases more significantly. Therefore, the average time ratio for both is on the rise. The average cost ratio increases less significantly, because as the graph becomes denser, the number of feasible solutions also increases, allowing the model to complete tasks by selecting fewer sub-tasks, though not in the most optimal time.\nQ3: Can our plan-over-graph method improve the planning performance on textual queries? The lower part of Table 3 presents the results of real-life queries, showing that our plan-over-graph method consistently improves different models' performance. When planning without extraction, Claude achieves a 89.5% success rate but struggles with the 14.5% optimal rate and a high 1.904 time ratio. Llama achieves a success rate of 19%, with no optimal plan available, causing a 3.433 time ratio. With our plan-over-graph framework, the optimal rate of Claude improves to 41.5%, and the success rate of Llama also improves to 38%, with both time ratios decreased. The model trained for planning shows greatly improved performance, surpassing even Claude in 72.5% optimal rate with a 83% success rate."}, {"title": "Analysis", "content": "In this section, we discuss our dataset and the detailed results of the experiment."}, {"title": "Graph Features", "content": "This section discusses (i) our considerations regarding the graph structure; (ii) the impact of changes in the number of nodes and edges in the graph on the planning capability of the model.\nGraph Structures. The tree-based structure is designed to better reflect real-world parallel scenarios, offering a stronger hierarchical organization that facilitates the generation of more reasonable specific scenarios. To ensure a clear distinction between parallel and non-parallel execution, we implement the following strategies: (i) controlling the depth of the tree to manage the number of branches, and (ii) grouping nodes such that the number of nodes in each group does not exceed two-thirds of the total number of predecessor nodes. In addition, we also used an undefined random graph structure to verify the robustness of the model.\nImpact of Node and Edge Counts We calculated the absolute value of correlation coefficients and slopes of normalized four metrics with changes in the number of points and edges. Overall, the impact of the edge count is smaller than the node count. For node counts, almost all metrics of the models showed strong correlation coefficients between 0.8 and 1.0. For edge variations on 10 nodes, both model shows low correlation coefficients which are less than 0.5, indicating robustness to changes in the number of edges on graphs with fewer points. However, on 30 nodes, Claude has higher correlation coefficients on all four metrics than our trained Llama, which are more than 0.7 correlation coefficients, demonstrating lower stability."}, {"title": "Time Efficiency", "content": "Our tasks inherently support parallel execution of subtasks, yet most existing methods do not consider parallelism during planning, leading to unnecessary waiting times.\nWe calculate the time ratio of parallel execution to sequential execution (that is, the sum of all sub-task durations) in the plans. The results demonstrate that the capability of planning parallel solutions can significantly reduce time compared to blocking sequential execution. Such efficiency is more significant as the graph scales. Specifically, plans from Llama and Qwen show high cost ratios, indicating that there are many redundant subtasks. When executing these plans sequentially, the inefficiency will be further amplified, leading to a low ratio of the parallel execution time to the sequential."}, {"title": "Wrong Case Study", "content": "Task Graph. The wrong cases on abstract graphs fall into two types. (i) Invalid subtask, where the plan includes subtasks without corresponding transformation rules, and (ii) Unavailable source, where the required source for a subtask is not achieved during execution. The latter indicates either a failure to consider the source availability during planning or an incorrect handling of dependencies. Shows the proportion of two error types. After training, the source dependency has almost been resolved, but the hallucination of invalid subtasks is currently the performance bottleneck.\nTextual Query. Failure to extract essential rules for subtasks will compromise the model's overall performance. However, interestingly, even with extraction errors, the model can still complete the task correctly if the subsequent planning does not encounter incorrect rules. Results of Llama show that the extraction step significantly improves the baseline success rate, and while the trained model's success rate is slightly lower than that of Claude, its optimal rate is superior. After taking a closer look, finding that only 15% matched the original graph exactly. However, the average similarity for mismatched cases was 82%, indicating minimal impact. This supports our focus on improving the model's planning capabilities on abstract graphs."}, {"title": "Conclusion", "content": "We present plan-over-graph, a novel paradigm to enhance parallelism in LLM-based agentic planning. Our approach extracts task dependencies as structured graphs, then optimizes parallel planning through graph-aware reasoning. We develop a synthetic dataset annotated with directed acyclic graphs and propose a two-stage training scheme. Experimental results demonstrate significant improvements. Our analysis further reveals that the graph structure inversely affects model performance and the time reduction brought by parallelism. This work establishes a framework for parallel agentic systems, bridging the gap between abstract graphs and real-world applications."}, {"title": "Limitations", "content": "We acknowledge the limitations of this work. (i) Although we believe and verify that the ability to plan on the graph is more important than extraction, open source models have also shown certain flaws in extraction. (ii) In reality, the model's plan can be a dynamic process that interacts with the environment, where the model can refine the previously given plan through perception. Our future work will focus on these two directions."}, {"title": "Prompt template for graph planning", "content": "You are given a set of transformation rules, where each rule consists of source nodes (materials or subtasks), target nodes (resulting materials or tasks), the time required to complete the transformation, and a cost associated with the transformation. Your goal is to plan a path from the initial nodes to the target node, supporting parallel transformations, to obtain the target node in the shortest time possible, while minimizing the total cost.\nInput format:\nTransformation rules: A list of dictionaries, where each dictionary represents a transformation rule and contains:\nsource: A list of source nodes (the prerequisites for the transformation).\ntarget: A list of target nodes (the result of the transformation).\ntime: The time required to complete the transformation (an integer).\ncost: The cost associated with the transformation (an integer).\nInitial nodes: A list of strings representing the available nodes at the start.\nTarget node: A string representing the node that needs to be obtained.\nOutput format:\nPlan: A list of subtasks, where each subtask is a JSON object with the following fields:\nname: The name of the subtask or node being completed. The default name format is \"Subtask\" followed by a sequence number.\nsource: A list of source nodes involved in this subtask. The sources must be products you already have or can obtain through previous steps.\ntarget: The target node resulting from this subtask. Both the source and target must conform to a given rule and cannot be assumed or self-created.\ndependencies: A list of dependencies (other subtask names) that need to be completed before this subtask can be executed. This ensures the execution order between subtasks, and the dependencies must provide the required sources for this subtask.\nImportant:\nThe generated JSON must strictly follow the JSON format.\nThe following rules must be strictly adhered to:\nAll keys and values must be enclosed in double quotes.\nAll elements in arrays must be separated by commas.\nAll fields in the JSON must be complete and correctly formatted, with no missing or incorrect elements.\nAll planned steps must comply with a given rule.\nAll substances involved must conform to the given rules.\nYour task is to generate the final plan in the specified JSON format, minimizing both the completion time and total cost.\nDo not provide any implementation code.\nHere is an example to better understand the task:\nNow, based on the following transformation rules, initial nodes, and target node, please provide an optimal plan that allows the target node to be obtained in the shortest time with the minimal total cost, supporting parallel transformations.\nOnly include necessary steps that are required for the fastest completion with the least cost. Do not add any extra or redundant transformation steps.\nTask:\nYour task is to generate the final plan in the specified JSON format. Do not provide any implementation code."}, {"title": "Prompt template for query planning", "content": "For the input task, please provide an optimal plan that allows the target to be obtained. Minimize the cost under the premise of the shortest time.\nProjects without dependencies can be completed in parallel to improve overall efficiency.\nPlease provide the final solution in JSON format:\nPlan: A list of subtasks, where each subtask is a JSON object with the following fields:\nname: The name of the subtask or node being completed. The default name format is \"Subtask\" followed by a sequence number.\nsource: A list of source nodes involved in this subtask. The sources must be products you already have or can obtain through previous steps.\ntarget: The target node resulting from this subtask. Both the source and target must conform to a given rule and cannot be assumed or self-created.\ndependencies: A list of dependencies (other subtask names) that need to be completed before this subtask can be executed. This ensures the execution order between subtasks, and the dependencies must provide the required sources for this subtask.\nInput:\nOutput:\nInput:\nOutput:"}, {"title": "Prompt template for extracting graph from query", "content": "Task: Extract structured transition rules from unstructured workflow narratives. Objective: Identify all transitions between nodes in the text. For each transition, extract:\nSource nodes (prerequisites)\nTarget nodes (outcomes)\nTime (duration)\nCost (numeric resource units)\nAdditionally, determine the initial_source (starting node) and target (final node).\nInput: A story describing a workflow process. Example phrases may include:\n\"From [NodeA], proceed to [NodeB] in X days at a cost of Y units\"\n\"When both [NodeA] and [NodeB] are ready, [NodeC] can be completed in X days at a cost of Y units\"\nShortcuts like \"directly from [NodeA] to [NodeC] in X days at a cost of Y units\"\nOutput:\nA JSON object with:\n1. \"rules\": A list of transition rules, each containing:\n\"id\" (sequential integer starting from 0)\n\"source\" (list of node IDs, e.g., [\"N1\"])\n\"target\" (list of node IDs, e.g., [\"N2\"])\n\"time\" (numeric value)\n\"cost\" (numeric value)\n2. \"initial_source\": List of starting node IDs (e.g., [\"N1\"])\n3. \"target\": Final node ID (e.g., \"N8\")\nYour Task: Convert the following story into the JSON format above. Ensure:\n1. All transitions are captured, including multi-source dependencies and shortcuts\n2. Node IDs (e.g., N1, N2) are preserved exactly as written\n3. Time and cost values are strictly numeric\n4. Follow the JSON schema precisely\nExample Input Story:\nExample Output:\nInput Story:\nOutput:"}, {"title": "Prompt template for generating query from graph", "content": "Transform this abstract task into a specific task in a real-world scenario, noting the following:\n1. Tasks without dependencies can be executed in parallel.\n2. Please express the instructions in complete natural language without explicitly listing the rules.\n3. As long as there is one path that reaches the final goal, it is considered successful.\n4. The source of a rule must be fully achieved before proceeding with the rule and obtaining its target.\n5. You must strictly follow the rules I have given, make sure the rules in your story correspond one-to-one with the rules I have provided, and the sum of rules in your story must be equal to the sum of rules in the task.\n6. You must explicitly mention both the time and cost associated with each rule in the story.\n7. You only need to write the rules as a story, without offering any additional evaluation comments or introductory remarks.\nHere is an example from another task for reference:\nInput:\nOutPut:\nInput:\nOutput:"}, {"title": "Textual Query Statistics", "content": "Figure 4 shows the statistics on our synthetic query data."}]}