{"title": "Generalizing Few Data to Unseen Domains Flexibly Based on Label Smoothing Integrated with Distributionally Robust Optimization", "authors": ["Yangdi Wang", "Zhi-Hai Zhang", "Su Xiu Xu", "Wenming Guo"], "abstract": "Overfitting commonly occurs when applying deep neural networks (DNNs) on small-scale datasets, where DNNs do not generalize well from existing data to unseen data. The main reason resulting in overfitting is that small-scale datasets cannot reflect the situations of the real world. Label smoothing (LS) is an effective regularization method to prevent overfitting, avoiding it by mixing one-hot labels with uniform label vectors. However, LS only focuses on labels while ignoring the distribution of existing data. In this paper, we introduce the distributionally robust optimization (DRO) to LS, achieving shift the existing data distribution flexibly to unseen domains when training DNNs. Specifically, we prove that the regularization of LS can be extended to a regularization term for the DNNs parameters when integrating DRO. The regularization term can be utilized to shift existing data to unseen domains and generate new data. Furthermore, we propose an approximate gradient-iteration label smoothing algorithm (GI-LS) to achieve the findings and train DNNs. We prove that the shift for the existing data does not influence the convergence of GI-LS. Since GI-LS incorporates a series of hyperparameters, we further consider using Bayesian optimization (BO) to find the relatively optimal combinations of these hyperparameters. Taking small-scale anomaly classification tasks as a case, we evaluate GI-LS, and the results clearly demonstrate its superior performance.", "sections": [{"title": "1. Introduction", "content": "In supervised deep learning, overfitting is a common issue when training machine learning deep neural networks (DNNs), where DNNs perform well on training data but struggle to generalize to unseen data. This issue is especially frequent when the dataset is small, as a small-scale dataset cannot accurately reflect real-world conditions (Zhou et al., 2022). Due to real-world constraints (e.g., technical difficulty, inclusion of private information, etc.), it is unrealistic to collect large-scale data in some industries. For instance, the anomaly data collection in the process of producing various industrial products is always extremely time-consuming and expensive. Thus, there is a scarcity of anomaly data when maintaining and controlling the quality of products (Bergmann et al., 2019; Tabernik et al., 2020). This dilemma is also present in other domains such as medical image analysis, financial development trend prediction and so on. A suitable approach to preventing overfitting while improving the generalization of DNNs using existing data could lead to advancements in a wide range of fields.\nIn supervised deep learning, the generalization of DNNs can be improved from both the model itself and the dataset information perspectives. Recently, a variety of regularization strategies have emerged to prevent overfitting and improve model's generalization. One branch of regularization strategies, such as $l_1$ or $1_2$ penalization, weight decay, and dropout, constrains the range of variation for model parameters or acts on hidden activation functions during model training. However, these methods intricately involve the specific parameterization or loss criterion of the model (Li et al., 2020), complicating the training process. In contrast, regularization strategies that prevent overfitting from the viewpoint of the dataset do not influence the structure of the model, making the training process simpler. The most direct method is data augmentation expanding the scale of dataset. However, collecting and annotating data in some industries always incur extremely high costs, are time-consuming, and laborious in many industries (Aghasi et al., 2024). It is natural to use the existing data to generate new ones. Unfortunately, the generated data might change the existing data characteristics significantly, potentially leading to poor performance of model on unseen data (Peck et al., 2023). Beyond merely considering existing data, since each data point in supervised deep learning contains labels with annotation information (e.g., category information) that are used to fit the output distribution"}, {"title": "1.1. Short Introduction to Label Smoothing", "content": "In this section, we briefly introduce LS using the k-class supervised classification task.\nTaking arbitrary sample $(X,Y)$ belonging to a certain category $i$ from dataset, we consider the hard one-hot vector to represent its corresponding label $Y$ when training DNNs.\n$Y = [y_1, y_2, ..., y_k]$,  (1)\nwhere $y_i \\in Y$ is:\n$y_i = \\begin{cases} 1, & \\text{if sample X belongs to class i,} \\\\ 0 & \\text{otherwise.} \\end{cases}$ (2)\nIn general, the output of model may closely mirror the hard one-hot label $Y$, where the prediction for the $i^{th}$ position approaches 1, while the predictions for other positions are nearly 0. This issue tends to result in the overconfidence of model's output and leads to overfitting. Furthermore, the situation is particularly evident when the scale of dataset is small. To address this issue, LS considers changing the hard one-hot label $Y$ in the following.\n$Y_i = \\begin{cases} 1-\\alpha, & \\text{if sample X belongs to class i,} \\\\ \\frac{\\alpha}{k-1} & \\text{otherwise.} \\end{cases}$ (3)\nwhere $\\alpha$ is a hyperparameter adjusted manually.\nLS only introduces a hyperparameter $\\alpha$ to adjust each position of the hard one-hot label $Y$. When $\\alpha = 0$, LS degenerates to hard one-hot label in equation (1). As $\\alpha$ increases, the $i^{th}$ position changes from 1 to $1-\\alpha$ and the other $k - 1$ positions change from 0 to $\\frac{\\alpha}{k-1}$. In this process, the true label value progressively decreases while the values of other categories gradually increase, penalizing the overconfidence in the outputs for the true categories while giving some attention to other categories. This makes the output distribution relatively"}, {"title": "1.2. Our Contributions", "content": "In this paper, based on the powerful regularization effect of LS for labels and its hyperparameter when training DNNs, we integrate LS into the regularization term built by DRO, introducing multiple worst-case scenarios and enabling the exploration of appropriate data shifts, adding flexibility to DRO. These data shifts are equivalent to generating multiple new samples for the same label without extra annotations. Furthermore, we overcome the limitations imposed by labels on LS by incorporating DRO.\nOur main contribution are summarized as follows.\n\u2022 We propose a novel two-stage problem, named DRO-LS, integrated LS within the DRO framework for generalizing few data to unseen domains flexibly. Specifically, the first stage perturbs existing data by LS and generate new samples, while the second stage involves using the original data and generated data to train DNNs.\n\u2022 To the best of our knowledge, it is the first time that the regularization effect of LS overcomes the limitations imposed by labels and has been applied to generate data. In addition, it is the first time that the worst-case scenario of DRO can be adjusted flexibly. Specifically, the regularization term built by DRO roughly corresponds to an $L_2$ penalization that integrates the regularization effect of LS and DNNS parameters. Moreover, we prove that there exists a bound between the existing data and the generated data, showing that the generated data maintains the characteristics of the existing data even if the hyperparameter of LS varies.\n\u2022 We develop a two-stage gradient-based algorithm, called gradient-iteration label smoothing (GI-LS), to approximately solve DRO-LS model. The algorithm can be regarded as a new data augmentation algorithm. Furthermore, we prove the convergence of the proposed algorithm, illustrating that perturbations on existing data with LS do not affect its convergence rate.\n\u2022 Since the proposed algorithm involves a series of hyperparameters for adjustment, we take in specific small-scale anomaly cases to conduct extensive simulations using Bayesian optimization (BO) provide suggestions for selecting the hyperparameter ranges of GI-LS. Furthermore, as a perturbation algorithm for existing data, we validate the effectiveness of GI-LS in defending against some general adversarial attack methods in the context of magnetic surface defects."}, {"title": "2. Related work", "content": "Our work is closely related to two streams of research in the literature. The first stream concerns data augmentation. It is common that the distribution of training data does not reflect the real-world situation, directly resulting in the overfitting of models. Data augmentation deals with the overfitting from the root of problem, which expands the scale of training data (Wang et al., 2021). However, constrained by real-world conditions, collecting and annotating samples in some industries always incurs extremely high costs. Thus,"}, {"title": "3. Method", "content": null}, {"title": "3.1. Problem formulation", "content": "In supervised learning, the optimization objective of training DNNs is as follows.\n$\\min_\\{\\theta \\in \\Theta\\} E_\\{(X,Y) \\sim P_0\\}[l(\\theta; (X,Y))]$, (4)\nwhere $(X, Y) \\in (\\mathcal{X}, \\mathcal{Y})$ are drawn from the training distribution $P_0$. $X$ denotes the training sample and $Y$ is the corresponding label. $\\theta \\in \\Theta$ represents the parameters of DNNs. $l : \\mathcal{X} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$ is the loss function.\nWe introduce the cross-entropy loss as the loss function $l$.\n$l(\\theta; (X,Y)) = - \\sum_{i=1}^{k} \\sum_{j=1}^{k} y_i \\log p_j(\\theta, x)$. (5)"}, {"title": "3.2. Theoretical Analysis", "content": "To solve the penalty problem (13), based on the definition of robust surrogate loss, we perform stochastic gradient descent on the robust surrogate loss $\\Phi_\\gamma (\\theta; (z', y))$, and have:\n$\\nabla_\\theta \\Phi_\\gamma (\\theta; (z', y)) = \\nabla_\\theta l (\\theta; (z'^*, y))$, (14)\nwhere $z'^* = \\arg \\max_{z\\in \\mathcal{Z}} \\{l (\\theta; (z, y_0)) - \\gamma c_\\theta ((z, y_0), (z', y_0))\\}$ is a perturbation of the feature map $z'$ in the current parameters $\\theta$. In fact, we aim to obtain the $z'^*$ in the supremum stage. Supposing that $||z - z'||$ is sufficiently smooth. The following theorem illustrates that the relationship between $z' = f(\\theta;x)$ and $z'^* = f(\\theta_r;x^*)$, where $x$ denotes the existing training data and $x^*$ is the optimal generated data. Specifically, we represent the non-identity Hessian matrix as $H$.\nTheorem 2 (Relationship between Existing Data and Optimal Generated Data). For $z' = f(\\theta_r;x)$ and $z'^* = f(\\theta_r;x^*)$, we have\n$||z'^* - z'|| = ||(H - \\gamma I)^{-1} \\nabla_{z'}l(\\theta; (z', y))||$, (15)\nwhere\n$\\nabla_{z'}l(\\theta; (z', y)) = (1 - \\alpha)\\theta_{f,i} + \\frac{\\alpha}{k-1}\\sum_{j \\neq i}^k \\theta_{f,j} - \\frac{\\alpha}{k-1}\\sum_{j=1}^k p_j(\\theta; z') \\cdot \\theta_{f,j}$. (16)\nTheorem 2 reveals that the feature map of the optimal generated data $z'^*$ can be obtained by perturbing the feature map of the existing data $z'$. The mass transported from $z'$ to $z'^*$ in the semantic space is equal to the product of the deviation of $l(\\theta; (z', y))$ and the Hessian matrix. Theorem 2 further provides the detailed expression for $\\nabla_{z'}l(\\theta; (z', y))$, as shown in equation (16), which consists of the feature map $z'$, the classification layer parameters $\\theta_f$. Note that the hyperparameter in equation (3) applied to labels now applies to $\\theta_f$. For the parameters $\\theta_{f,i}$ corresponding to the true category $i$, the weight is $1-\\alpha$ while the weights correspond to other positions are $\\frac{\\alpha}{k-1}$. Instead of perturbations $L_p$ for the training samples, this term aims to penalize the distance between $(1 - \\alpha)\\theta_{f,i} + \\frac{\\alpha}{k-1}\\sum_{j \\neq i}^k \\theta_{f,j}$ with the weight characterized by the hyperparameter $\\alpha$, and $\\sum_{j=1}^k p_j(\\theta; z') \\cdot \\theta_{f,j}$, which is the estimated mean of the $\\theta_f$ across all categories with"}, {"title": "4. Case Study", "content": "In this section, we apply GI-LS to a real-world case study on the classification task for small-scale anomaly images with DNNs, which includes two magnetic tile surface defect datasets (Huang et al., 2020) and two"}, {"title": "4.1. Small-scale Anomaly Dataset", "content": "We use magnetic tile surface defect (Huang et al., 2020), following the structure of CUB-200-2011 (Wah et al., 2011), to establish two magnetic tile surface datasets, as shown in Table 1. MT-Defect includes five types of defects. In contrast, MT introduces images without surface defects, which are far more numerous than the defect categories. In general, the number of products with surface defects is usually less than the number of qualified products in a real-world industrial line, and the number of each type of surface defect product is rare. The distribution of MT is consistent with the real-world situation to some extent."}, {"title": "4.2. Bayesian Optimization", "content": "As seen from the above review, the proposed GI-LS includes a series of hyperparameters. When applying stochastic gradient ascent to generate new data for the inner maximization stage of GI-LS, in addition to the $\\alpha$ of LS, the number of perturbation iterations $T$ and the step size of gradient ascent $\\eta$ are also crucial to the data generation process. Furthermore, the iterations of the outer minimization stage of GI-LS determine the efficiency. Thus, selecting appropriate ranges for these parameters is essential for the performance of GI-LS.\nBayesian Optimization (BO) has been widely used when the process of training DNNs involves multiple hyperparameters, especially in the context of manufacturing (AlBahar et al., 2021). It is known for its efficacy in globally optimizing expensive black-box functions (Semelhago et al., 2021; Xu et al., 2023). Therefore, we employ BO to explore the optimal combination of the hyperparameters. Specifically, we use Adaptive Experimentation (Ax) platform of Meta to execute BO for GI-LS (Baird et al.,2022). To address the covariance of uncertainty, the Matern 5/2 kernel is employed. We mainly focus on the parameters of the classification layer and treat the other hidden layers as the feature extraction layer. In our settings, we"}, {"title": "4.2.1. Classification Results", "content": null}, {"title": "4.2.2. Analysis of Hyperparameter Combination in GI-LS", "content": "As seen from the above review, the performance of DNNs on Wood and Carpet is relatively stable, indicating that the search space of the hyperparameters is flattened. In contrast, the performance of DNNs on MT-Defect and MT fluctuates to some extent. In this section, we analyze how the combination of hyperparameters in GI-LS clusters in the optimal region during the BO iteration for the four datasets."}, {"title": "4.3. Comparison to Existing Data Augmentation Method", "content": "In this section, using MT-Defect and MT as examples, we conduct seven data augmentation methods to compare with the proposed GI-LS method. We regard the DNNs trained with cross-entropy loss without LS and existing images from MT-Defect and MT as the benchmark. Table 5 shows the top-1 accuracy results of Cutmix (Yun et al., 2019), Cutout (DeVries and Taylor, 2017), and Mixup (Zhang et al., 2018), while Table 6 records the top-1 accuracy results of PGD (Madry et al., 2018), FGSM (Goodfellow et al., 2014), and CW attacking (Carlini and Wagner, 2017). We set the maximum perturbation $\\epsilon = \\frac{8}{225}$ for PGD and FGSM. Specifically, we use torchattacks package to achieve adversarial perturbation methods (Kim, 2020)."}, {"title": "4.4. Experiment for y Perturbation", "content": "Theorem 4 provides the bounds of the robust surrogate loss $\\Phi_\\gamma(\\theta; (z', y))$, which provide perturbations denoted as L(0) on $\\gamma$. The top-1 accuracy metrics of DNNs can serve as indicators for the bounds, measuring the distribution of generating samples consistent with $\\Phi_\\gamma(\\theta; (z', y))$. In our experiments, we perturb the value of $\\gamma$ by simulating diverse magnitudes of L(0) in Algorithm 1. The other hyperparameters are the same as those used in Table 3. Starting with $\\gamma = 10^{-3}$, we perturbed its denominator by $\\pm 0.1, \\pm 1, \\pm 10$, and $\\pm 100$. Detailed findings can be found in Table 8."}, {"title": "5. Conclusion", "content": "In this paper, we propose a two-stage DRO-LS model as a new data augmentation, which considers the regularization effect of LS integrated with DRO to address the issue of overfitting when applying DNNs in few data scenarios. Specifically, we utilize the Wasserstein distance within the DRO framework to construct the ambiguity set and ensure computational feasibility via Lagrangian relaxation. We propose a surrogate loss and prove that it is equivalent to the LS loss and a regularization term. We find that the LS regularization"}]}