{"title": "Enhancing Biomedical Knowledge Discovery for Diseases: An End-To-End Open-Source Framework", "authors": ["Christos Theodoropoulos", "James Henderson", "Andrei Catalin Coman", "Marie-Francine Moens"], "abstract": "The ever-growing volume of biomedical publications creates a critical need for efficient knowledge discovery. In this context, we introduce an open-source end-to-end framework designed to construct knowledge around specific diseases directly from raw text. To facilitate research in disease-related knowledge discovery, we create two annotated datasets focused on Rett syndrome and Alzheimer's disease, enabling the identification of semantic relations between biomedical entities. Extensive benchmarking explores various ways to represent relations and entity representations, offering insights into optimal modeling strategies for semantic relation detection and highlighting language models' competence in knowledge discovery. We also conduct probing experiments using different layer representations and attention scores to explore transformers' ability to capture semantic relations.", "sections": [{"title": "1 Introduction", "content": "Knowledge discovery (Wang et al., 2023; Shu and Ye, 2023) is a pivotal research domain due to the surge in publications, which makes keeping up with new findings challenging, necessitating automated knowledge extraction and processing. Of particular concern is the biomedical literature, where updates occur with ever-accelerating frequency (Fig. 1). Despite advances in healthcare, many diseases, such as Alzheimer's disease (AD) (Trejo-Lopez et al., 2023; Scheltens et al., 2021) and multiple sclerosis (McGinley et al., 2021; Attfield et al., 2022), lack effective cures. Additionally, over 1,200 rare disorders have limited or no cures according to the National Organization for Rare Disorders. Discovering new scientific insights from research papers can expedite disease understanding and accelerate cure development.\nThis paper presents an end-to-end framework for detecting medical entities in unstructured text and annotating semantic relations, enabling automated knowledge discovery for diseases. We employ a multi-stage methodology for data acquisition, annotation, and model evaluation. The process starts with gathering relevant PubMed abstracts from PubMed to form the corpus. Entities are identified and extracted, followed by the co-occurrence graph generation that models the intra-sentence co-occurrence of the entities across the corpus. Leveraging the processed text and co-occurrence graph, an algorithm samples sentences to create gold-standard datasets. Medical experts label the semantic relations between entities within these sentences via an annotation portal. The framework's versatility allows application across various diseases and enables expansion to encompass knowledge about symptoms, genes, and more. This study focuses on two diseases of particular research interest: Rett syndrome (RS) (Petriti et al., 2023) and AD. These diseases are selected due to their significant impact and the absence of a cure, highlighting the urgency for advancements in understanding and treatment. We introduce two curated datasets tailored for detecting semantic relations between entities in biomedical text related to RS and AD. The datasets are used for benchmarking, testing techniques for representing relations and entities and assessing language models' capabilities in knowledge discovery. This work probes the layer outputs of transformer models (Vaswani et al., 2017) and their attention patterns to reveal their ability to implicitly capture semantic relations in biomedical text.\nRS (Sandweiss et al., 2020) poses challenges due to its sporadic nature and rare expression across diverse racial groups. The disorder's elusive nature undermines its comprehension and stresses the pressing need for a cure. Rare diseases collectively affect a substantial portion of the population, with over 30 million affected people in Europe alone (Pakter, 2024). AD is characterized by its prevalence among older populations, with millions of patients worldwide as it is the most common type of dementia (60-70% cases) (Alzheimer's-Association, 2024). With life expectancy on the rise, the projected increase in Alzheimer's cases accentuates the urgency of finding a cure.\nIn summary, the key paper's contributions are:\n\u2022 Development of an open-source end-to-end framework to build disease knowledge directly from raw text.\n\u2022 Two annotated datasets for RS and AD provide gold labels for semantic relations, aiding disease knowledge discovery research.\n\u2022 Benchmarking on the datasets examines methods for relation and entity representation, offering insights into optimal approaches for semantic relation detection and emphasizing language models' knowledge discovery capabilities.\n\u2022 Probing experiments with different layer representations and attention scores assess transformers' inherent ability to capture semantic relations."}, {"title": "2 Data Pipeline", "content": "We focus on developing a robust data pipeline (Fig. 2) to annotate sentences with entities associated with the Unified Medical Language System (UMLS) (Bodenreider, 2004; Elkin and Brown, 2023). The first step involves the retrieval of the textual abstracts, followed by the mention extraction that includes entity detection and linking to UMLS. We construct a co-occurrence graph to highlight interconnections between entities in the text. The processed text and co-occurrence graph are then used to develop two curated datasets with precise entity annotations and semantic relations between detected entity pairs.\nAbstract retrieval. We retrieve PubMed articles ids based on a query (e.g., Rett syndrome) and extract their open-access abstracts. To accomplish this, we leverage the official Entrez Programming Utilities (Kans, 2024) and the Biopython API (Cock et al., 2009) (BSD 3-Clause License), ensuring access to the vast repository of biomedical literature. After obtaining the PubMed IDs (PMIDs), we retrieve the abstracts from the specified articles and tokenize the text into sentences using NLTK (Bird et al., 2009) (Apache License 2.0).\nMention extraction. MetaMapLite (Aronson, 2001) (open-source BSD License) is provided by the National Library of Medicine (NLM) for extracting biomedical entities and mapping them to Concept Unique Identifiers (CUIs) within UMLS. The tool is updated every two years to incorporate the latest medical terminology and to ensure its accuracy in extraction and mapping. MetaMapLite simultaneously extracts mentions and links them to UMLS in one step, efficiently associating mentions with their corresponding CUIs. We detect a diverse range of entities, spanning 82 unique semantic types and covering a broad spectrum of biomedical concepts, including diseases, biologically active substances, anatomical structures, genes, and more. Detailed entity detection often leads to overlapping or successive entities in the text. To address this, our pipeline incorporates a merging strategy that consolidates overlapping or subsequent entities into cohesive units. For example, in the sentence: \"To test norepinephrine augmentation as a potential disease-modifying therapy, we performed a biomarker-driven phase II trial of atomoxetine, a clinically-approved norepinephrine transporter inhibitor, in subjects with mild cognitive impairment due to AD.\", the subsequent relevant mentions norepinephrine transporter and inhibitor are merged to one entity.\nCo-occurrence graph generation. We model the intra-sentence co-occurrence between the entities. Each node in the graph corresponds to a unique CUI and contains metadata including the semantic type and the list of sentence IDs where the corresponding entity is detected. An edge between two nodes signifies that the corresponding entities co-occur within the same sentence. The edge weight represents the number of times two entities co-occur in a sentence throughout the text corpus."}, {"title": "2.1 Dataset Creation", "content": "Leveraging the extracted co-occurrence graph, we define two distinct probability distributions to select sentences for manual annotation. The first distribution P focuses on common pairs of co-occurred entities, with higher frequency in the co-occurrence graph resulting in a higher likelihood of sampling. The second distribution IP prioritizes novel/rare pairs of co-occurred entities, selecting sentences where the entities have a lower frequency in the co-occurrence graph. We sample 50% of sentences using P and 50% using IP to ensure a balance of common and potentially novel pairs of co-occurring entities in the datasets.\nThen, we develop an annotation portal using the streamlit library, providing a user-friendly interface for annotators. Annotators are presented with a sentence containing two highlighted entities and are prompted to categorize the semantic relation between them. Options include positive (direct semantic connection), negative (negative semantic connection where negative words like \"no\" and \"absence\" are present), complex (semantic connection with complex reasoning), and no relation. The annotation portal offers additional functions such as sentence removal (for non-informative sentences), entity removal (for incorrect entity types or spans), and context addition (for providing additional text to aid in relation type determination). We enlist the expertise of three medical experts to ensure the accuracy and reliability of the annotation process.\nThe result of the expert annotation yields two curated datasets. The Relation Detection dataset for Rett Syndrome (ReDReS) contains 601 sentences with 5,259 instances and 1,148 unique CUIs (Tab. 1). The inter-annotator agreement is measured using the Fleiss kappa score (McHugh, 2012), resulting in 0.6143 in the multi-class setup (4 classes) and indicating substantial agreement among annotators (Landis and Koch, 1977). In the binary setup (relation or no relation), the Fleiss kappa score is 0.7139. The Relation Detection dataset for Alzheimer's Disease (ReDAD) comprises 641 sentences with 8,565 instances and 1,480 unique CUIs (Tab. 1). The Fleiss kappa score is 0.6403 in the multi-class setup and 0.7064 in the binary setup, showing substantial consensus among annotators. The final labels are determined through majority voting, leveraging the labels provided by each expert. While the label distribution across classes is relatively balanced, the negative class is under-represented with 97 and 125 instances in ReDRES and ReDAD respectively (Tab. 1). Each dataset is randomly split into train, development, and test sets."}, {"title": "3 Models", "content": "In this section, we introduce two main models, the Language-Model Embedding Learning (LaMEL) model and the Language-Model Relation Detection (LaMReD) model (Fig. 3), to benchmark datasets and establish robust baselines.\nTask formulation. Given a sentence containing two identified entities $e_1$ and $e_2$, we predict the semantic relation $sem$, between them. In the multi-class setup, the labels are: positive, negative, complex, and no relation. In the binary setup, the goal is to determine if any relation exists. Special tokens [ent] and [/ent] mark the start and end of each entity within the sentence, ensuring consistent identification and processing of entity boundaries."}, {"title": "3.1 LaMEL model", "content": "LaMEL learns an embedding space optimized for relation detection (Fig. 3). As the backbone language model (LM), we opt for PubMedBERT (Gu et al., 2021; Tinn et al., 2023) (MIT License), available in both uncased base and uncased large versions. PubMedBERT is pretrained on the PubMed corpus, making it well-suited for our task as the curated datasets consist of sentences of abstracts from PubMed papers. Leveraging PubMedBERT ensures that the model can capture the language patterns prevalent in biomedical text. Following the LM encoding, we construct the representation of each entity by extracting its contextualized embedding $E_i$ corresponding to each entity $e_i$ from the encoded sequence. Subsequently, the entity representations are projected to the embedding space using a linear layer without changing the embedding dimension. The final prediction is based on cosine similarity between the two projected entity representations. If the cosine similarity exceeds a predefined threshold, the model predicts that there is a semantic relation between the two entities. We experiment with diverse strategies for learning entity representations (Fig. 3), aiming to optimize the effectiveness of the embedding space for the relation detection task. The explored types of entity representation $E$ are:\n\u2022 A, B, C - Special Tokens:\n$E_A = t_{[ent]}$,\n$E_B = t_{[/ent]}$,\n$E_C = t_{[ent]} ; t_{[/ent]}$,\n\u2022 D - Entity Pool:\n$E_D = [t_E]$,\n\u2022 E - Entity & Middle Pool:\n$E_E = [t_E] * [t_{Inter}]$,\n\u2022 F, G, H - Special Tokens & Middle Pool:\n$E_F = t_{[ent]} * [t_{Inter}]$,\n$E_G = t_{[/ent]} * [t_{Inter}]$,\n$E_H = t_{[ent]} *t_{[/ent]} * [t_{Inter}]$,\nwhere ${E_A, E_B, E_D, E_E, E_F, E_G,E_H} \u2208 R^d$ and $E_C \u2208 R^{2d}$, d is the embedding size of PubMedBERT base (768) and PubMedBERT large (1024), $;$ defines the concatenation, $*$ holds for the element-wise multiplication, $t_{[ent]}$, $t_{[/ent]}$ are the embeddings of the start and end special tokens of the entities, $[t_E]$ and $[t_{Inter}]$ are the averaged pooled representation of the entities and the intermediate tokens between the entities respectively."}, {"title": "3.2 LaMRED model", "content": "LaMReD provides two variations that differ in information synthesis (Fig. 3), aiming to explore the potential effect of different aggregations (Theodoropoulos and Moens, 2023). LaMReDA utilizes element-wise addition to aggregate the entities' representations, while LaMReDM employs element-wise multiplication. The input text is encoded using PubMedBERT (base or large). Following LM encoding, we construct the relation representation by sampling and aggregating tokens from the input sequence. This step enables the model to capture essential features and contextual information relevant to semantic relation classification. To mitigate the risk of overfitting and enhance model generalization, we incorporate a dropout layer (Srivastava et al., 2014) with a probability of 0.3. The linear classification layer takes the aggregated representation and outputs the predicted label.\nFollowing the paradigm proposed by Baldini Soares et al. (2019) and Hogan et al. (2021), we experiment with various approaches for learning relation representations tailored to the relation detection task to empirically ascertain the effectiveness of each strategy (Fig. 3). The explored types of relation representation R are the following:\n\u2022 A, B, C - Special Tokens:\n$R_A = f(l(t_{[ent]1}), l(t_{[ent]2}))$,\n$R_B = f(l(t_{[/ent]1}), l(t_{[/ent]2}))$,\n$R_C = f(l(t_{[ent]1}), l(t_{[/ent]1}),l(t_{[ent]2}), l(t_{[/ent]2}))$,\n\u2022 D - Entity Pool:\n$R_D = f(l([t_{E1}]),l([t_{E2}]))$,\n\u2022 E- Middle Pool:\n$R_E = l([t_{Inter}])$,\n\u2022 F - [CLS] token & Entity Pool:\n$R_F = f(l(t_{[CLS]}), l([t_{E1}]),l([t_{E2}]))$,\n\u2022 G, H, I - [CLS] token & Special Tokens:\n$R_G = f(l(t_{[CLS]}), l(t_{[ent]1}), l(t_{[ent]2}))$,\n$R_H = f(l(t_{[CLS]}), l(t_{[/ent]1}), l(t_{[/ent]2}))$,\n$R_I = f(l(t_{[CLS]}), l(t_{[ent]1}), l(t_{[/ent]1}), l(t_{[ent]2}), l(t_{[/ent]2}))$,\n\u2022 J - [CLS] token & Middle Pool:\n$R_J = f(l(t_{[CLS]}), l([t_{Inter}]))$,\n\u2022 K, L, M - Special tokens & Middle Pool:\n$R_K = f(l(t_{[ent]1}), l([t_{Inter}]), l(t_{[ent]2}))$,\n$R_L = f(l(t_{[/ent]1}), l([t_{Inter}]), l(t_{[ent]2}))$,\n$R_M = f(l(t_{[ent]1}), l(t_{[/ent]1}), l([t_{Inter}]), l(t_{[ent]2}), l(t_{[/ent]2}))$,\n\u2022 N - Entity & Middle Pool:\n$R_N = f(l([t_{E1}]), l([t_{Inter}]), l([t_{E2}]))$,\n\u2022 O, P - Context Vector & Entity Pool:\n$R_O = l(cv)$,\n$R_P = f(l([t_{E1}]),l([t_{E2}]), I(cv))$,\nwhere ${R_A, R_B, R_C, R_D, R_E, R_F, R_G, R_H, R_I,R_J, R_K, R_L, R_M, R_N, R_O, R_P} \u2208 R^d$, d is the embedding size of PubMedBERT base (768) and PubMedBERT large (1024), f() is the aggregation function, element-wise addition for LaMREDA and element-wise multiplication for LaMREDM, 1() is a linear projection layer with dimension equal to the embedding size, $t_{[ent]1}$, $t_{[/ent]1}$, $t_{[ent]2}$, and $t_{[/ent]2}$ are the embeddings of the start and end special tokens of the first and second entity and $t_{[CLS]}$ is the representation of the special token [CLS]. We define the averaged pooled representation of the entities and the intermediate tokens between the entities as $[t_{E1}]$, $[t_{E2}]$, and $[t_{Inter}]$ correspondingly. In equations 23 and 24, we utilize the localized context vector $cv$ that utilizes the attention heads to locate relevant context for the entity pair and was introduced in ATLOP (Zhou et al., 2021), a state-of-the-art model in document-level relation extraction."}, {"title": "3.3 Experimental setup", "content": "The models are trained for 50 epochs and the best checkpoints are retained based on the performance on the development set, measured using the F1-score. We utilize the Adam (Kingma and Ba, 2014) optimizer with a learning rate of $10^{-5}$. The batch size is set to 16. We conduct experiments in two distinct setups. In the multi-class setup, we evaluate performance using micro and macro F1-score, considering four relation types: positive, negative, complex, and no relation. In the binary setup, the objective is the prediction of the presence of relation. LaMEL is specifically designed for the binary setup. We utilize the official splits of ReDReS and ReDAD (Tab. 1) and repeat the experiments 10 times with different seeds. To ensure robustness of results, we also employ a 5-fold cross-validation approach. To explore the cross-disease capabilities of our approach, we train the models using one dataset (e.g., ReDReS) and evaluate on the other (e.g., ReDAD), and vice versa. We utilize the relation representation RA (Eq. 9) for LaMReDA and LaMReDM and the entity representation EA (Eq. 1) for LaMEL. These experiments are repeated 10 times with different seeds, and 15% of the training data is excluded to define the development set.\nThe cross-entropy loss function is used to train LaMREDA and LaMReDM. For LaMEL, the following cosine embedding loss function is used:\n$l(x_1, x_2, Y) = \\begin{cases}\n(1 - cos(x_1, x_2), & \\text{if } y = 1 \\\\\nmax(0, cos(x_1, x_2) - m), & \\text{if } y = -1\n\\end{cases}$"}, {"title": "4 Results", "content": "Tables 2 and 3 report the F1-scores for LaMEL LaMREDA, and LaMReDM, models on the ReDRES and ReDAD datasets. Each cell (except for cross-disease experiments) displays two values: the average F1-score from 10 runs on the original test set (Tab. 1) and the average F1-score from a 5-fold cross-validation. The models perform well across all relation (A-P) and entity (A-H) representations, showing their ability to learn meaningful representations for the semantic relation task regardless of initial token selection. However, we observe patterns regarding the relation representations. In the binary setup, relation representation RG (Eq. 15) yields strong results for both datasets, suggesting that including the [CLS] token representation might be beneficial. In the multi-class setup, relation representations RL (Eq. 20), RJ (Eq. 18), and Ro (Eq. 23) are effective for both datasets, indicating that the surrounding context is crucial for the more complex task, as R\u2081 and Rj include the averaged pooled representation of intermediate tokens between entities, and Ro leverages the context vector (Zhou et al., 2021). The intra-model comparison reveals that over-parameterization tends to be useful. Using PubMedBERT large generally results in better performance than the base alternative. The PubMedBERT base shows superior performance mainly only in experiments using the original splits of ReDRES (Tab. 1). LaMEL is highly competitive with LaMREDA and LaMReDM, indicating that learning entity embedding spaces optimized for relation detection is promising. LaMEL achieves the highest performance in the 5-fold setup of ReDAD and the original setup of ReDReS, with F1-scores of 91.03% and 91.25% respectively.\nThe inter-model comparison across the same relation representations indicates that the aggregation function does not significantly impact relation detection tasks. Neither LaMReDA (element-wise addition) nor LaMReDM (element-wise multiplication) show a clear advantage over the other. This suggests that the transformer layers of PubMed-BERT and the projection layer l() preceding the aggregation are effectively trained in both models to encode the essential information for relation detection, regardless of the aggregation function used. The cross-disease experiments underscore the robustness of the models in both binary and multi-class setups. This robustness supports transfer learning (Zhuang et al., 2020) in semantic relation detection, extending to other diseases, highlighting the potential for broader applications and research endeavors in knowledge discovery.\nHuman Performance. To assess and compare to human performance, two additional experts identify the relation type in a random sample of 300 instances from the test set of each dataset (Tab. 1). The evaluation ground truth is based on the original test set labels. In the binary setup, the average F1-score ranges from 92.14 for ReDReS to 91.87 for ReDAD. The LaMReDA, LaMReDM, and LMEL models achieve performance comparable to human experts, indicating a high ability to detect semantic relations. Multi-class macro F1-scores range from 85.23 (micro: 85.45) to 85.76 (micro: 85.87) for ReDRES and ReDAD, respectively. Compared to human experts, all models show a performance gap, highlighting that identifying more complex aspects of semantic relation is a challenging task.\nBaseline performance - lower bound. We randomly assign labels based on the training data's class distribution (Tab 1). In the binary setup, the baseline achieves F1-scores of 54% (ReDRES) and 53.16% (ReDAD). For the multi-class setup, the macro F1-scores range from 32.05% to 32.43%, stressing the task's difficulty, particularly for distinguishing various semantic relations (multi-class)."}, {"title": "5 Probing", "content": "This study probes PubMedBERT's ability to capture semantic relations between entities. We explore different transformer layer representations and attention scores per layer and attention head. Averaged pooled entity representations are extracted from each layer, followed by training a linear classification layer. We test relation representations RD, RO, and Rp (Eq. 12, 23, 24) of LaMREDA and LaMReDM to assess the impact of the context vector. Out-of-the-box representations are evaluated without the projection linear layer l(). We also extract average attention scores of tokens for each entity towards the other across each layer and head, concatenating these into a feature vector for training a linear classification layer. Following Chizhikova et al. (2022), we also train the classification layer using average attention scores between the two entities across all layers. \nFigure 4 shows the results of probing experiments in the binary setup using ReDReS and PubMedBERT base. The 10th and 11th layers provide the most informative representations for relation types (RD, RO, and Rp). The RD representation, using element-wise multiplication, outperforms other representations in intra-layer comparisons, suggesting its effectiveness without end-to-end training. However, as highlighted in section 4, inter-model comparisons indicate that the transformer layers and projection layer l() capture crucial information for relation detection, regardless of the aggregation function. Using context vectors with Ro and Rp generally offers no advantage, though Ro from the 10th and 11th layers performs well, indicating possibly meaningful localized context. Attention scores between entities in the 12th layer yield the best performance, surpassing the baseline of using scores from all layers, indicating strong attention between the entities in the last layer. Figure 4 reveals that the 6th and 9th attention heads are most informative for relation detection."}, {"title": "6 Related Work", "content": "Information Extraction Datasets. Several biomedical datasets aim to enhance Information Extraction (IE) system development (Huang et al., 2024; Detroja et al., 2023; Nasar et al., 2021; Theodoropoulos et al., 2021), typically focusing on one or a few entity types and their interactions. AIMed (Bunescu et al., 2005), BioInfer (Pyysalo et al., 2007), and BioCreative II PPI IPS (Krallinger et al., 2008) formulate protein-protein interactions. The chemical-protein and chemical-disease interactions are modeled by DrugProt (Miranda et al., 2021) and BC5CDR (Li et al., 2016), respectively. ADE (Gurulingappa et al., 2012), DDI13 (Herrero-Zazo et al., 2013), and n2c2 2018 ADE (Henry et al., 2020) include drug-ADE (adverse drug effect) and drug-drug interactions. EMU (Doughty et al., 2011), GAD (Bravo et al., 2015) and RENET2 (Su et al., 2021) contain relations between genes and diseases. N-ary (Peng et al., 2017) incorporates drug-gene mutation interactions. The task of event extraction is illustrated by GE09 (Kim et al., 2009), GE11 (Kim et al., 2011), and CG (Pyysalo et al., 2013). DDAE (Lai et al., 2019) includes disease-disease associations. BioRED (Luo et al., 2022) focuses on document-level relations for various entities. Unlike these datasets, ReDRES and ReDAD focus on RS and AD, include entities of up to 82 different semantic types, and model the semantic relation between them.\nKnowledge Discovery. Gottlieb et al. (2011) present PREDICT, a method for ranking potential drug-disease associations to predict drug indications. Romano et al. (2024) release AlzKB, a heterogeneous graph knowledge base for AD, constructed using external data sources and describing various medical entities (e.g., chemicals, genes). Other graph-based efforts model knowledge around AD for tasks such as drug repurposing (Hsieh et al., 2023; Daluwatumulle et al., 2022; Nian et al., 2022), gene identification (Binder et al., 2022), or as general knowledge repositories (S\u00fcgis et al., 2019). Another paradigm for knowledge discovery is the open information extraction (OIE) setup (Mausam et al., 2012; Etzioni et al., 2008), which faces challenges such as data consistency, performance evaluation, and semantic drift (Zhou et al., 2022). Research efforts (Wang et al., 2018; de Silva et al., 2017; Nebot and Berlanga, 2014; Movshovitz-Attias and Cohen, 2012; Nebot and Berlanga, 2011) aim to address these issues and extract knowledge with little or no supervision. Advances in literature-based discovery (Gopalakrishnan et al., 2019; Thilakaratne et al., 2019) try to identify novel medical entity relations using graph-based (Kilicoglu et al., 2020; Nicholson and Greene, 2020), machine learning (Zhao et al., 2021; Lardos et al., 2022), and co-occurrence methods (Kuusisto et al., 2020; Millikin et al., 2023). Tian et al. (2024) stress the potential of large language models (LLMs) to summarize, simplify, and synthesize medical evidence (Peng et al., 2023; Tang et al., 2023; Shaib et al., 2023), suggesting that LLMs may have encoded biomedical knowledge (Singhal et al., 2023). To exploit this potential, we explore constructing LM representations for knowledge discovery. To the best of our knowledge, no systematic approach assembles knowledge about RS. Unlike previous work, we introduce a, in principle, disease-agnostic framework, to acquire knowledge about RS and AD starting from raw text."}, {"title": "7 Conclusion", "content": "This work presents an open-source framework for disease knowledge discovery from raw text. We contribute two new annotated datasets for RS (ReDReS) and AD (ReDAD), facilitating further research. Extensive evaluation explores various methods for representing relations and entities, yielding insights into optimal modeling approaches for semantic relation detection, and emphasizing language models' potential in knowledge discovery."}, {"title": "Limitations", "content": "One limitation of the paper is that the data pipeline relies on an external mention extractor/linker. However, this aspect introduces flexibility, allowing researchers and practitioners to integrate custom models suited to their specific applications. The creation of gold-standard datasets requires the manual work of medical experts. This process is time-consuming and resource-intensive, potentially limiting the scalability of the approach. Nevertheless, the experiments demonstrate that the supervised models of the study achieve strong performance in semantic relation detection without needing a large training set. Additionally, the cross-disease experiments highlight the robustness of the models in both binary and multi-class setups. This finding enables transfer learning scenarios in semantic relation detection, which can be applied to other diseases or medical aspects, indicating a potential for broader applications and research opportunities."}, {"title": "Ethics Statement", "content": "All recruited medical experts provided informed consent before participating in the annotation process. The compensation provided to the annotators was adequate and considered their demographic, particularly their country of residence."}, {"title": "A Data Pipeline: Additional Information", "content": "To facilitate effective abstract retrieval, we implement an iterative approach to circumvent the API's limitation of retrieving only 10,000 article IDs per query. This iterative process enables us to access a comprehensive set of PubMed IDs (PMIDs) related to the query. The detailed list of the 82 semantic types of the MetaMapLite-based pipeline is presented in Table 4. In addition to the MetaMapLite-based pipeline, we propose a second pipeline that is based on ScispaCy (Apache License 2.0) (Fig. 5). The difference lies in the selection of entity extractors and linkers that map the extracted entities to knowledge schemes. Unlike MetaMapLite, which adopts an integrated approach where mention extraction and linking are performed simultaneously in a single step and focuses on UMLS mapping, allowing for more precise and targeted extraction of entities, ScispaCy serves a broader range of Natural Language Processing (NLP) tasks. After the retrieval of the abstracts that is described in subsection 2.1, the following steps are executed: Knowledge schema and linker generation, Mention extraction, Entity linking. and Sampling of linked identifiers.\nKnowledge schema and linker generation. ScispaCy (Neumann et al., 2019) harnesses an older version of UMLS (2020AA). This version serves as the foundation upon which ScispaCy trains and constructs its linkers that operate on a char-3grams string overlap-based search mechanism, facilitating efficient and accurate entity recognition and linking processes. Following the paradigm of ScispaCy, we provide scripts for generating updated linkers tailored to a range of knowledge schemes. These include UMLS (Bodenreider, 2004), Gene Ontology (GO) (Consortium, 2004), National Center for Biotechnology Information (NCBI) taxonomy (Schoch et al., 2020), RxNorm (Nelson et al., 2011), SNOMED Clinical Terms (SNOMEDCT_US) (Stearns et al., 2001), Human Phenotype Ontology (HPO) (K\u00f6hler et al., 2021), Medical Subject Headings (MeSH) (Lipscomb, 2000) DrugBank (Knox et al., 2024) and Gold Standard Drug Database. Of particular note is the inclusion of UMLS, a unified system encompassing various knowledge bases, vocabularies, taxonomies, and ontologies pertinent to the biomedical domain. Any supported linker maps the con-"}, {"title": "B Annotation Portal", "content": "Figure 7 presents the annotation portal with an example from the ReDRES dataset. The annotator's task is to identify the semantic relation between the two highlighted entities, classifying it as either a Positive Relation, Negative Relation, Complex Relation, or No Relation. If the sentence is considered uninformative or if there are errors in entity detection, type, or span, the annotator can remove the sentence or the entities. Furthermore, the annotator is encouraged to provide feedback, including any additional text that can clarify or elaborate on the relationship between the entities. By providing this supplementary information, annotators can contribute to a richer and more nuanced understanding of the relations within the data."}, {"title": "C Dataset Instances", "content": "In this section", "Relation": "n\u2022 Amyloid fibrils are found in many fatal neurodegenerative diseases such as Alzheimer's disease"}, {"Relation": "n\u2022 When the brain's antioxidant defenses are overwhelmed by IR"}, {"Relation": "n\u2022 It was not observed in synaptopodin-deficient mice", "title": "Enhancing Biomedical Knowledge Discovery for Diseases: An End-To-End Open-Source Framework", "authors": ["Christos Theodoropoulos", "James Henderson", "Andrei Catalin Coman", "Marie-Francine Moens"], "abstract": "The ever-growing volume of biomedical publications creates a critical need for efficient knowledge discovery. In this context, we introduce an open-source end-to-end framework designed to construct knowledge around specific diseases directly from raw text. To facilitate research in disease-related knowledge discovery, we create two annotated datasets focused on Rett syndrome and Alzheimer's disease, enabling the identification of semantic relations between biomedical entities. Extensive benchmarking explores various ways to represent relations and entity representations, offering insights into optimal modeling strategies for semantic relation detection and highlighting language models' competence in knowledge discovery. We also conduct probing experiments using different layer representations and attention scores to explore transformers' ability to capture semantic relations.", "sections": [{"title": "1 Introduction", "content": "Knowledge discovery (Wang et al., 2023; Shu and Ye, 2023) is a pivotal research domain due to the surge in publications, which makes keeping up with new findings challenging, necessitating automated knowledge extraction and processing. Of particular concern is the biomedical literature, where updates occur with ever-accelerating frequency (Fig. 1). Despite advances in healthcare, many diseases, such as Alzheimer's disease (AD) (Trejo-Lopez et al., 2023; Scheltens et al., 2021) and multiple sclerosis (McGinley et al., 2021; Attfield et al., 2022), lack effective cures. Additionally, over 1,200 rare disorders have limited or no cures according to the National Organization for Rare Disorders. Discovering new scientific insights from research papers can expedite disease understanding and accelerate cure development.\nThis paper presents an end-to-end framework for detecting medical entities in unstructured text and annotating semantic relations, enabling automated knowledge discovery for diseases. We employ a multi-stage methodology for data acquisition, annotation, and model evaluation. The process starts with gathering relevant PubMed abstracts from PubMed to form the corpus. Entities are identified and extracted, followed by the co-occurrence graph generation that models the intra-sentence co-occurrence of the entities across the corpus. Leveraging the processed text and co-occurrence graph, an algorithm samples sentences to create gold-standard datasets. Medical experts label the semantic relations between entities within these sentences via an annotation portal. The framework's versatility allows application across various diseases and enables expansion to encompass knowledge about symptoms, genes, and more. This study focuses on two diseases of particular research interest: Rett syndrome (RS) (Petriti et al., 2023) and AD. These diseases are selected due to their significant impact and the absence of a cure, highlighting the urgency for advancements in understanding and treatment. We introduce two curated datasets tailored for detecting semantic relations between entities in biomedical text related to RS and AD. The datasets are used for benchmarking, testing techniques for representing relations and entities and assessing language models' capabilities in knowledge discovery. This work probes the layer outputs of transformer models (Vaswani et al., 2017) and their attention patterns to reveal their ability to implicitly capture semantic relations in biomedical text.\nRS (Sandweiss et al., 2020) poses challenges due to its sporadic nature and rare expression across diverse racial groups. The disorder's elusive nature undermines its comprehension and stresses the pressing need for a cure. Rare diseases collectively affect a substantial portion of the population, with over 30 million affected people in Europe alone (Pakter, 2024). AD is characterized by its prevalence among older populations, with millions of patients worldwide as it is the most common type of dementia (60-70% cases) (Alzheimer's-Association, 2024). With life expectancy on the rise, the projected increase in Alzheimer's cases accentuates the urgency of finding a cure.\nIn summary, the key paper's contributions are:\n\u2022 Development of an open-source end-to-end framework to build disease knowledge directly from raw text.\n\u2022 Two annotated datasets for RS and AD provide gold labels for semantic relations, aiding disease knowledge discovery research.\n\u2022 Benchmarking on the datasets examines methods for relation and entity representation, offering insights into optimal approaches for semantic relation detection and emphasizing language models' knowledge discovery capabilities.\n\u2022 Probing experiments with different layer representations and attention scores assess transformers' inherent ability to capture semantic relations."}, {"title": "2 Data Pipeline", "content": "We focus on developing a robust data pipeline (Fig. 2) to annotate sentences with entities associated with the Unified Medical Language System (UMLS) (Bodenreider, 2004; Elkin and Brown, 2023). The first step involves the retrieval of the textual abstracts, followed by the mention extraction that includes entity detection and linking to UMLS. We construct a co-occurrence graph to highlight interconnections between entities in the text. The processed text and co-occurrence graph are then used to develop two curated datasets with precise entity annotations and semantic relations between detected entity pairs.\nAbstract retrieval. We retrieve PubMed articles ids based on a query (e.g., Rett syndrome) and extract their open-access abstracts. To accomplish this, we leverage the official Entrez Programming Utilities (Kans, 2024) and the Biopython API (Cock et al., 2009) (BSD 3-Clause License), ensuring access to the vast repository of biomedical literature. After obtaining the PubMed IDs (PMIDs), we retrieve the abstracts from the specified articles and tokenize the text into sentences using NLTK (Bird et al., 2009) (Apache License 2.0).\nMention extraction. MetaMapLite (Aronson, 2001) (open-source BSD License) is provided by the National Library of Medicine (NLM) for extracting biomedical entities and mapping them to Concept Unique Identifiers (CUIs) within UMLS. The tool is updated every two years to incorporate the latest medical terminology and to ensure its accuracy in extraction and mapping. MetaMapLite simultaneously extracts mentions and links them to UMLS in one step, efficiently associating mentions with their corresponding CUIs. We detect a diverse range of entities, spanning 82 unique semantic types and covering a broad spectrum of biomedical concepts, including diseases, biologically active substances, anatomical structures, genes, and more. Detailed entity detection often leads to overlapping or successive entities in the text. To address this, our pipeline incorporates a merging strategy that consolidates overlapping or subsequent entities into cohesive units. For example, in the sentence: \"To test norepinephrine augmentation as a potential disease-modifying therapy, we performed a biomarker-driven phase II trial of atomoxetine, a clinically-approved norepinephrine transporter inhibitor, in subjects with mild cognitive impairment due to AD.\", the subsequent relevant mentions norepinephrine transporter and inhibitor are merged to one entity.\nCo-occurrence graph generation. We model the intra-sentence co-occurrence between the entities. Each node in the graph corresponds to a unique CUI and contains metadata including the semantic type and the list of sentence IDs where the corresponding entity is detected. An edge between two nodes signifies that the corresponding entities co-occur within the same sentence. The edge weight represents the number of times two entities co-occur in a sentence throughout the text corpus."}, {"title": "2.1 Dataset Creation", "content": "Leveraging the extracted co-occurrence graph, we define two distinct probability distributions to select sentences for manual annotation. The first distribution P focuses on common pairs of co-occurred entities, with higher frequency in the co-occurrence graph resulting in a higher likelihood of sampling. The second distribution IP prioritizes novel/rare pairs of co-occurred entities, selecting sentences where the entities have a lower frequency in the co-occurrence graph. We sample 50% of sentences using P and 50% using IP to ensure a balance of common and potentially novel pairs of co-occurring entities in the datasets.\nThen, we develop an annotation portal using the streamlit library, providing a user-friendly interface for annotators. Annotators are presented with a sentence containing two highlighted entities and are prompted to categorize the semantic relation between them. Options include positive (direct semantic connection), negative (negative semantic connection where negative words like \"no\" and \"absence\" are present), complex (semantic connection with complex reasoning), and no relation. The annotation portal offers additional functions such as sentence removal (for non-informative sentences), entity removal (for incorrect entity types or spans), and context addition (for providing additional text to aid in relation type determination). We enlist the expertise of three medical experts to ensure the accuracy and reliability of the annotation process.\nThe result of the expert annotation yields two curated datasets. The Relation Detection dataset for Rett Syndrome (ReDReS) contains 601 sentences with 5,259 instances and 1,148 unique CUIs (Tab. 1). The inter-annotator agreement is measured using the Fleiss kappa score (McHugh, 2012), resulting in 0.6143 in the multi-class setup (4 classes) and indicating substantial agreement among annotators (Landis and Koch, 1977). In the binary setup (relation or no relation), the Fleiss kappa score is 0.7139. The Relation Detection dataset for Alzheimer's Disease (ReDAD) comprises 641 sentences with 8,565 instances and 1,480 unique CUIs (Tab. 1). The Fleiss kappa score is 0.6403 in the multi-class setup and 0.7064 in the binary setup, showing substantial consensus among annotators. The final labels are determined through majority voting, leveraging the labels provided by each expert. While the label distribution across classes is relatively balanced, the negative class is under-represented with 97 and 125 instances in ReDRES and ReDAD respectively (Tab. 1). Each dataset is randomly split into train, development, and test sets."}, {"title": "3 Models", "content": "In this section, we introduce two main models, the Language-Model Embedding Learning (LaMEL) model and the Language-Model Relation Detection (LaMReD) model (Fig. 3), to benchmark datasets and establish robust baselines.\nTask formulation. Given a sentence containing two identified entities $e_1$ and $e_2$, we predict the semantic relation $sem$, between them. In the multi-class setup, the labels are: positive, negative, complex, and no relation. In the binary setup, the goal is to determine if any relation exists. Special tokens [ent] and [/ent] mark the start and end of each entity within the sentence, ensuring consistent identification and processing of entity boundaries."}, {"title": "3.1 LaMEL model", "content": "LaMEL learns an embedding space optimized for relation detection (Fig. 3). As the backbone language model (LM), we opt for PubMedBERT (Gu et al., 2021; Tinn et al., 2023) (MIT License), available in both uncased base and uncased large versions. PubMedBERT is pretrained on the PubMed corpus, making it well-suited for our task as the curated datasets consist of sentences of abstracts from PubMed papers. Leveraging PubMedBERT ensures that the model can capture the language patterns prevalent in biomedical text. Following the LM encoding, we construct the representation of each entity by extracting its contextualized embedding $E_i$ corresponding to each entity $e_i$ from the encoded sequence. Subsequently, the entity representations are projected to the embedding space using a linear layer without changing the embedding dimension. The final prediction is based on cosine similarity between the two projected entity representations. If the cosine similarity exceeds a predefined threshold, the model predicts that there is a semantic relation between the two entities. We experiment with diverse strategies for learning entity representations (Fig. 3), aiming to optimize the effectiveness of the embedding space for the relation detection task. The explored types of entity representation $E$ are:\n\u2022 A, B, C - Special Tokens:\n$E_A = t_{[ent]}$,\n$E_B = t_{[/ent]}$,\n$E_C = t_{[ent]} ; t_{[/ent]}$,\n\u2022 D - Entity Pool:\n$E_D = [t_E]$,\n\u2022 E - Entity & Middle Pool:\n$E_E = [t_E] * [t_{Inter}]$,\n\u2022 F, G, H - Special Tokens & Middle Pool:\n$E_F = t_{[ent]} * [t_{Inter}]$,\n$E_G = t_{[/ent]} * [t_{Inter}]$,\n$E_H = t_{[ent]} *t_{[/ent]} * [t_{Inter}]$,\nwhere ${E_A, E_B, E_D, E_E, E_F, E_G,E_H} \u2208 R^d$ and $E_C \u2208 R^{2d}$, d is the embedding size of PubMedBERT base (768) and PubMedBERT large (1024), $;$ defines the concatenation, $*$ holds for the element-wise multiplication, $t_{[ent]}$, $t_{[/ent]}$ are the embeddings of the start and end special tokens of the entities, $[t_E]$ and $[t_{Inter}]$ are the averaged pooled representation of the entities and the intermediate tokens between the entities respectively."}, {"title": "3.2 LaMRED model", "content": "LaMReD provides two variations that differ in information synthesis (Fig. 3), aiming to explore the potential effect of different aggregations (Theodoropoulos and Moens, 2023). LaMReDA utilizes element-wise addition to aggregate the entities' representations, while LaMReDM employs element-wise multiplication. The input text is encoded using PubMedBERT (base or large). Following LM encoding, we construct the relation representation by sampling and aggregating tokens from the input sequence. This step enables the model to capture essential features and contextual information relevant to semantic relation classification. To mitigate the risk of overfitting and enhance model generalization, we incorporate a dropout layer (Srivastava et al., 2014) with a probability of 0.3. The linear classification layer takes the aggregated representation and outputs the predicted label.\nFollowing the paradigm proposed by Baldini Soares et al. (2019) and Hogan et al. (2021), we experiment with various approaches for learning relation representations tailored to the relation detection task to empirically ascertain the effectiveness of each strategy (Fig. 3). The explored types of relation representation R are the following:\n\u2022 A, B, C - Special Tokens:\n$R_A = f(l(t_{[ent]1}), l(t_{[ent]2}))$,\n$R_B = f(l(t_{[/ent]1}), l(t_{[/ent]2}))$,\n$R_C = f(l(t_{[ent]1}), l(t_{[/ent]1}),l(t_{[ent]2}), l(t_{[/ent]2}))$,\n\u2022 D - Entity Pool:\n$R_D = f(l([t_{E1}]),l([t_{E2}]))$,\n\u2022 E- Middle Pool:\n$R_E = l([t_{Inter}])$,\n\u2022 F - [CLS] token & Entity Pool:\n$R_F = f(l(t_{[CLS]}), l([t_{E1}]),l([t_{E2}]))$,\n\u2022 G, H, I - [CLS] token & Special Tokens:\n$R_G = f(l(t_{[CLS]}), l(t_{[ent]1}), l(t_{[ent]2}))$,\n$R_H = f(l(t_{[CLS]}), l(t_{[/ent]1}), l(t_{[/ent]2}))$,\n$R_I = f(l(t_{[CLS]}), l(t_{[ent]1}), l(t_{[/ent]1}), l(t_{[ent]2}), l(t_{[/ent]2}))$,\n\u2022 J - [CLS] token & Middle Pool:\n$R_J = f(l(t_{[CLS]}), l([t_{Inter}]))$,\n\u2022 K, L, M - Special tokens & Middle Pool:\n$R_K = f(l(t_{[ent]1}), l([t_{Inter}]), l(t_{[ent]2}))$,\n$R_L = f(l(t_{[/ent]1}), l([t_{Inter}]), l(t_{[ent]2}))$,\n$R_M = f(l(t_{[ent]1}), l(t_{[/ent]1}), l([t_{Inter}]), l(t_{[ent]2}), l(t_{[/ent]2}))$,\n\u2022 N - Entity & Middle Pool:\n$R_N = f(l([t_{E1}]), l([t_{Inter}]), l([t_{E2}]))$,\n\u2022 O, P - Context Vector & Entity Pool:\n$R_O = l(cv)$,\n$R_P = f(l([t_{E1}]),l([t_{E2}]), I(cv))$,\nwhere ${R_A, R_B, R_C, R_D, R_E, R_F, R_G, R_H, R_I,R_J, R_K, R_L, R_M, R_N, R_O, R_P} \u2208 R^d$, d is the embedding size of PubMedBERT base (768) and PubMedBERT large (1024), f() is the aggregation function, element-wise addition for LaMREDA and element-wise multiplication for LaMREDM, 1() is a linear projection layer with dimension equal to the embedding size, $t_{[ent]1}$, $t_{[/ent]1}$, $t_{[ent]2}$, and $t_{[/ent]2}$ are the embeddings of the start and end special tokens of the first and second entity and $t_{[CLS]}$ is the representation of the special token [CLS]. We define the averaged pooled representation of the entities and the intermediate tokens between the entities as $[t_{E1}]$, $[t_{E2}]$, and $[t_{Inter}]$ correspondingly. In equations 23 and 24, we utilize the localized context vector $cv$ that utilizes the attention heads to locate relevant context for the entity pair and was introduced in ATLOP (Zhou et al., 2021), a state-of-the-art model in document-level relation extraction."}, {"title": "3.3 Experimental setup", "content": "The models are trained for 50 epochs and the best checkpoints are retained based on the performance on the development set, measured using the F1-score. We utilize the Adam (Kingma and Ba, 2014) optimizer with a learning rate of $10^{-5}$. The batch size is set to 16. We conduct experiments in two distinct setups. In the multi-class setup, we evaluate performance using micro and macro F1-score, considering four relation types: positive, negative, complex, and no relation. In the binary setup, the objective is the prediction of the presence of relation. LaMEL is specifically designed for the binary setup. We utilize the official splits of ReDReS and ReDAD (Tab. 1) and repeat the experiments 10 times with different seeds. To ensure robustness of results, we also employ a 5-fold cross-validation approach. To explore the cross-disease capabilities of our approach, we train the models using one dataset (e.g., ReDReS) and evaluate on the other (e.g., ReDAD), and vice versa. We utilize the relation representation RA (Eq. 9) for LaMReDA and LaMReDM and the entity representation EA (Eq. 1) for LaMEL. These experiments are repeated 10 times with different seeds, and 15% of the training data is excluded to define the development set.\nThe cross-entropy loss function is used to train LaMREDA and LaMReDM. For LaMEL, the following cosine embedding loss function is used:\n$l(x_1, x_2, Y) = \\begin{cases}\n(1 - cos(x_1, x_2), & \\text{if } y = 1 \\\\\nmax(0, cos(x_1, x_2) - m), & \\text{if } y = -1\n\\end{cases}$"}, {"title": "4 Results", "content": "Tables 2 and 3 report the F1-scores for LaMEL LaMREDA, and LaMReDM, models on the ReDRES and ReDAD datasets. Each cell (except for cross-disease experiments) displays two values: the average F1-score from 10 runs on the original test set (Tab. 1) and the average F1-score from a 5-fold cross-validation. The models perform well across all relation (A-P) and entity (A-H) representations, showing their ability to learn meaningful representations for the semantic relation task regardless of initial token selection. However, we observe patterns regarding the relation representations. In the binary setup, relation representation RG (Eq. 15) yields strong results for both datasets, suggesting that including the [CLS] token representation might be beneficial. In the multi-class setup, relation representations RL (Eq. 20), RJ (Eq. 18), and Ro (Eq. 23) are effective for both datasets, indicating that the surrounding context is crucial for the more complex task, as R\u2081 and Rj include the averaged pooled representation of intermediate tokens between entities, and Ro leverages the context vector (Zhou et al., 2021). The intra-model comparison reveals that over-parameterization tends to be useful. Using PubMedBERT large generally results in better performance than the base alternative. The PubMedBERT base shows superior performance mainly only in experiments using the original splits of ReDRES (Tab. 1). LaMEL is highly competitive with LaMREDA and LaMReDM, indicating that learning entity embedding spaces optimized for relation detection is promising. LaMEL achieves the highest performance in the 5-fold setup of ReDAD and the original setup of ReDReS, with F1-scores of 91.03% and 91.25% respectively.\nThe inter-model comparison across the same relation representations indicates that the aggregation function does not significantly impact relation detection tasks. Neither LaMReDA (element-wise addition) nor LaMReDM (element-wise multiplication) show a clear advantage over the other. This suggests that the transformer layers of PubMed-BERT and the projection layer l() preceding the aggregation are effectively trained in both models to encode the essential information for relation detection, regardless of the aggregation function used. The cross-disease experiments underscore the robustness of the models in both binary and multi-class setups. This robustness supports transfer learning (Zhuang et al., 2020) in semantic relation detection, extending to other diseases, highlighting the potential for broader applications and research endeavors in knowledge discovery.\nHuman Performance. To assess and compare to human performance, two additional experts identify the relation type in a random sample of 300 instances from the test set of each dataset (Tab. 1). The evaluation ground truth is based on the original test set labels. In the binary setup, the average F1-score ranges from 92.14 for ReDReS to 91.87 for ReDAD. The LaMReDA, LaMReDM, and LMEL models achieve performance comparable to human experts, indicating a high ability to detect semantic relations. Multi-class macro F1-scores range from 85.23 (micro: 85.45) to 85.76 (micro: 85.87) for ReDRES and ReDAD, respectively. Compared to human experts, all models show a performance gap, highlighting that identifying more complex aspects of semantic relation is a challenging task.\nBaseline performance - lower bound. We randomly assign labels based on the training data's class distribution (Tab 1). In the binary setup, the baseline achieves F1-scores of 54% (ReDRES) and 53.16% (ReDAD). For the multi-class setup, the macro F1-scores range from 32.05% to 32.43%, stressing the task's difficulty, particularly for distinguishing various semantic relations (multi-class)."}, {"title": "5 Probing", "content": "This study probes PubMedBERT's ability to capture semantic relations between entities. We explore different transformer layer representations and attention scores per layer and attention head. Averaged pooled entity representations are extracted from each layer, followed by training a linear classification layer. We test relation representations RD, RO, and Rp (Eq. 12, 23, 24) of LaMREDA and LaMReDM to assess the impact of the context vector. Out-of-the-box representations are evaluated without the projection linear layer l(). We also extract average attention scores of tokens for each entity towards the other across each layer and head, concatenating these into a feature vector for training a linear classification layer. Following Chizhikova et al. (2022), we also train the classification layer using average attention scores between the two entities across all layers. \nFigure 4 shows the results of probing experiments in the binary setup using ReDReS and PubMedBERT base. The 10th and 11th layers provide the most informative representations for relation types (RD, RO, and Rp). The RD representation, using element-wise multiplication, outperforms other representations in intra-layer comparisons, suggesting its effectiveness without end-to-end training. However, as highlighted in section 4, inter-model comparisons indicate that the transformer layers and projection layer l() capture crucial information for relation detection, regardless of the aggregation function. Using context vectors with Ro and Rp generally offers no advantage, though Ro from the 10th and 11th layers performs well, indicating possibly meaningful localized context. Attention scores between entities in the 12th layer yield the best performance, surpassing the baseline of using scores from all layers, indicating strong attention between the entities in the last layer. Figure 4 reveals that the 6th and 9th attention heads are most informative for relation detection."}, {"title": "6 Related Work", "content": "Information Extraction Datasets. Several biomedical datasets aim to enhance Information Extraction (IE) system development (Huang et al., 2024; Detroja et al., 2023; Nasar et al., 2021; Theodoropoulos et al., 2021), typically focusing on one or a few entity types and their interactions. AIMed (Bunescu et al., 2005), BioInfer (Pyysalo et al., 2007), and BioCreative II PPI IPS (Krallinger et al., 2008) formulate protein-protein interactions. The chemical-protein and chemical-disease interactions are modeled by DrugProt (Miranda et al., 2021) and BC5CDR (Li et al., 2016), respectively. ADE (Gurulingappa et al., 2012), DDI13 (Herrero-Zazo et al., 2013), and n2c2 2018 ADE (Henry et al., 2020) include drug-ADE (adverse drug effect) and drug-drug interactions. EMU (Doughty et al., 2011), GAD (Bravo et al., 2015) and RENET2 (Su et al., 2021) contain relations between genes and diseases. N-ary (Peng et al., 2017) incorporates drug-gene mutation interactions. The task of event extraction is illustrated by GE09 (Kim et al., 2009), GE11 (Kim et al., 2011), and CG (Pyysalo et al., 2013). DDAE (Lai et al., 2019) includes disease-disease associations. BioRED (Luo et al., 2022) focuses on document-level relations for various entities. Unlike these datasets, ReDRES and ReDAD focus on RS and AD, include entities of up to 82 different semantic types, and model the semantic relation between them.\nKnowledge Discovery. Gottlieb et al. (2011) present PREDICT, a method for ranking potential drug-disease associations to predict drug indications. Romano et al. (2024) release AlzKB, a heterogeneous graph knowledge base for AD, constructed using external data sources and describing various medical entities (e.g., chemicals, genes). Other graph-based efforts model knowledge around AD for tasks such as drug repurposing (Hsieh et al., 2023; Daluwatumulle et al., 2022; Nian et al., 2022), gene identification (Binder et al., 2022), or as general knowledge repositories (S\u00fcgis et al., 2019). Another paradigm for knowledge discovery is the open information extraction (OIE) setup (Mausam et al., 2012; Etzioni et al., 2008), which faces challenges such as data consistency, performance evaluation, and semantic drift (Zhou et al., 2022). Research efforts (Wang et al., 2018; de Silva et al., 2017; Nebot and Berlanga, 2014; Movshovitz-Attias and Cohen, 2012; Nebot and Berlanga, 2011) aim to address these issues and extract knowledge with little or no supervision. Advances in literature-based discovery (Gopalakrishnan et al., 2019; Thilakaratne et al., 2019) try to identify novel medical entity relations using graph-based (Kilicoglu et al., 2020; Nicholson and Greene, 2020), machine learning (Zhao et al., 2021; Lardos et al., 2022), and co-occurrence methods (Kuusisto et al., 2020; Millikin et al., 2023). Tian et al. (2024) stress the potential of large language models (LLMs) to summarize, simplify, and synthesize medical evidence (Peng et al., 2023; Tang et al., 2023; Shaib et al., 2023), suggesting that LLMs may have encoded biomedical knowledge (Singhal et al., 2023). To exploit this potential, we explore constructing LM representations for knowledge discovery. To the best of our knowledge, no systematic approach assembles knowledge about RS. Unlike previous work, we introduce a, in principle, disease-agnostic framework, to acquire knowledge about RS and AD starting from raw text."}, {"title": "7 Conclusion", "content": "This work presents an open-source framework for disease knowledge discovery from raw text. We contribute two new annotated datasets for RS (ReDReS) and AD (ReDAD), facilitating further research. Extensive evaluation explores various methods for representing relations and entities, yielding insights into optimal modeling approaches for semantic relation detection, and emphasizing language models' potential in knowledge discovery."}, {"title": "Limitations", "content": "One limitation of the paper is that the data pipeline relies on an external mention extractor/linker. However, this aspect introduces flexibility, allowing researchers and practitioners to integrate custom models suited to their specific applications. The creation of gold-standard datasets requires the manual work of medical experts. This process is time-consuming and resource-intensive, potentially limiting the scalability of the approach. Nevertheless, the experiments demonstrate that the supervised models of the study achieve strong performance in semantic relation detection without needing a large training set. Additionally, the cross-disease experiments highlight the robustness of the models in both binary and multi-class setups. This finding enables transfer learning scenarios in semantic relation detection, which can be applied to other diseases or medical aspects, indicating a potential for broader applications and research opportunities."}, {"title": "Ethics Statement", "content": "All recruited medical experts provided informed consent before participating in the annotation process. The compensation provided to the annotators was adequate and considered their demographic, particularly their country of residence."}, {"title": "A Data Pipeline: Additional Information", "content": "To facilitate effective abstract retrieval, we implement an iterative approach to circumvent the API's limitation of retrieving only 10,000 article IDs per query. This iterative process enables us to access a comprehensive set of PubMed IDs (PMIDs) related to the query. The detailed list of the 82 semantic types of the MetaMapLite-based pipeline is presented in Table 4. In addition to the MetaMapLite-based pipeline, we propose a second pipeline that is based on ScispaCy (Apache License 2.0) (Fig. 5). The difference lies in the selection of entity extractors and linkers that map the extracted entities to knowledge schemes. Unlike MetaMapLite, which adopts an integrated approach where mention extraction and linking are performed simultaneously in a single step and focuses on UMLS mapping, allowing for more precise and targeted extraction of entities, ScispaCy serves a broader range of Natural Language Processing (NLP) tasks. After the retrieval of the abstracts that is described in subsection 2.1, the following steps are executed: Knowledge schema and linker generation, Mention extraction, Entity linking. and Sampling of linked identifiers.\nKnowledge schema and linker generation. ScispaCy (Neumann et al., 2019) harnesses an older version of UMLS (2020AA). This version serves as the foundation upon which ScispaCy trains and constructs its linkers that operate on a char-3grams string overlap-based search mechanism, facilitating efficient and accurate entity recognition and linking processes. Following the paradigm of ScispaCy, we provide scripts for generating updated linkers tailored to a range of knowledge schemes. These include UMLS (Bodenreider, 2004), Gene Ontology (GO) (Consortium, 2004), National Center for Biotechnology Information (NCBI) taxonomy (Schoch et al., 2020), RxNorm (Nelson et al., 2011), SNOMED Clinical Terms (SNOMEDCT_US) (Stearns et al., 2001), Human Phenotype Ontology (HPO) (K\u00f6hler et al., 2021), Medical Subject Headings (MeSH) (Lipscomb, 2000) DrugBank (Knox et al., 2024) and Gold Standard Drug Database. Of particular note is the inclusion of UMLS, a unified system encompassing various knowledge bases, vocabularies, taxonomies, and ontologies pertinent to the biomedical domain. Any supported linker maps the con-"}, {"title": "B Annotation Portal", "content": "Figure 7 presents the annotation portal with an example from the ReDRES dataset. The annotator's task is to identify the semantic relation between the two highlighted entities, classifying it as either a Positive Relation, Negative Relation, Complex Relation, or No Relation. If the sentence is considered uninformative or if there are errors in entity detection, type, or span, the annotator can remove the sentence or the entities. Furthermore, the annotator is encouraged to provide feedback, including any additional text that can clarify or elaborate on the relationship between the entities. By providing this supplementary information, annotators can contribute to a richer and more nuanced understanding of the relations within the data."}, {"title": "C Dataset Instances", "content": "In this section", "Relation": "n\u2022 Amyloid fibrils are found in many fatal neurodegenerative diseases such as Alzheimer's disease"}, {"Relation": "n\u2022 When the brain's antioxidant defenses are overwhelmed by IR"}, {"Relation": "n\u2022 It was not observed in synaptopodin-deficient mice, which lack spine apparatus organelles.\n\u2022"}]}]}