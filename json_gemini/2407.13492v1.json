{"title": "Enhancing Biomedical Knowledge Discovery for Diseases: An End-To-End Open-Source Framework", "authors": ["Christos Theodoropoulos", "James Henderson", "Andrei Catalin Coman", "Marie-Francine Moens"], "abstract": "The ever-growing volume of biomedical publications creates a critical need for efficient knowledge discovery. In this context, we introduce an open-source end-to-end framework designed to construct knowledge around specific diseases directly from raw text. To facilitate research in disease-related knowledge discovery, we create two annotated datasets focused on Rett syndrome and Alzheimer's disease, enabling the identification of semantic relations between biomedical entities. Extensive benchmarking explores various ways to represent relations and entity representations, offering insights into optimal modeling strategies for semantic relation detection and highlighting language models' competence in knowledge discovery. We also conduct probing experiments using different layer representations and attention scores to explore transformers' ability to capture semantic relations.", "sections": [{"title": "1 Introduction", "content": "Knowledge discovery (Wang et al., 2023; Shu and Ye, 2023) is a pivotal research domain due to the surge in publications, which makes keeping up with new findings challenging, necessitating automated knowledge extraction and processing. Of particular concern is the biomedical literature, where updates occur with ever-accelerating frequency (Fig. 1). Despite advances in healthcare, many diseases, such as Alzheimer's disease (AD) (Trejo-Lopez et al., 2023; Scheltens et al., 2021) and multiple sclerosis (McGinley et al., 2021; Attfield et al., 2022), lack effective cures. Additionally, over 1,200 rare disorders have limited or no cures according to the National Organization for Rare Disorders. Discovering new scientific insights from research papers can expedite disease understanding and accelerate cure development.\nThis paper presents an end-to-end framework for detecting medical entities in unstructured text and"}, {"title": "2 Data Pipeline", "content": "We focus on developing a robust data pipeline (Fig. 2) to annotate sentences with entities associated with the Unified Medical Language System (UMLS) (Bodenreider, 2004; Elkin and Brown, 2023). The first step involves the retrieval of the textual abstracts, followed by the mention extraction that includes entity detection and linking to UMLS. We construct a co-occurrence graph to highlight interconnections between entities in the text. The processed text and co-occurrence graph are then used to develop two curated datasets with precise entity annotations and semantic relations between detected entity pairs.\nAbstract retrieval. We retrieve PubMed articles ids based on a query (e.g., Rett syndrome) and extract their open-access abstracts. To accomplish this, we leverage the official Entrez Programming Utilities (Kans, 2024) and the Biopython API (Cock et al., 2009) (BSD 3-Clause License), ensuring access to the vast repository of biomedical literature. After obtaining the PubMed IDs (PMIDs), we retrieve the abstracts from the specified articles and tokenize the text into sentences using NLTK (Bird et al., 2009) (Apache License 2.0).\nMention extraction. MetaMapLite (Aronson, 2001) (open-source BSD License) is provided by the National Library of Medicine (NLM) for extracting biomedical entities and mapping them to Concept Unique Identifiers (CUIs) within UMLS. The tool is updated every two years to incorporate the latest medical terminology and to ensure its accuracy in extraction and mapping. MetaMapLite simultaneously extracts mentions and links them to UMLS in one step, efficiently associating mentions with their corresponding CUIs. We detect a diverse range of entities, spanning 82 unique semantic types and covering a broad spectrum of biomedical concepts, including diseases, biologically active substances, anatomical structures, genes, and more. Detailed entity detection often leads to overlapping or successive entities in the text. To address this, our pipeline incorporates a merging strategy that consolidates overlapping or subsequent entities into cohesive units. For example, in the sentence: \"To test norepinephrine augmentation as a potential disease-modifying therapy, we performed a biomarker-driven phase II trial of atomoxetine, a clinically-approved norepinephrine transporter inhibitor, in subjects with mild cognitive impairment due to AD.\", the subsequent relevant mentions norepinephrine transporter and inhibitor are merged to one entity.\nCo-occurrence graph generation. We model the intra-sentence co-occurrence between the entities. Each node in the graph corresponds to a unique CUI and contains metadata including the semantic type and the list of sentence IDs where the corresponding entity is detected. An edge between two nodes signifies that the corresponding entities co-occur within the same sentence. The edge weight represents the number of times two entities co-occur in a sentence throughout the text corpus."}, {"title": "2.1 Dataset Creation", "content": "Leveraging the extracted co-occurrence graph, we define two distinct probability distributions to select sentences for manual annotation. The first distribution $P$ focuses on common pairs of co-occurred entities, with higher frequency in the co-occurrence graph resulting in a higher likelihood of sampling. The second distribution $IP$ prioritizes novel/rare pairs of co-occurred entities, selecting sentences where the entities have a lower frequency in the co-occurrence graph. We sample 50% of sentences using $P$ and 50% using $IP$ to ensure a balance of common and potentially novel pairs of co-occurring entities in the datasets.\nThen, we develop an annotation portal using the streamlit library, providing a user-friendly interface for annotators. Annotators are presented with a sentence containing two highlighted entities and are prompted to categorize the semantic relation between them. Options include positive (direct semantic connection), negative (negative semantic connection where negative words like \"no\" and \"absence\" are present), complex (semantic connection with complex reasoning), and no relation. The annotation portal offers additional functions such as sentence removal (for non-informative sentences), entity removal (for incorrect entity types or spans), and context addition (for providing additional text to aid in relation type determination). We enlist the expertise of three medical experts to ensure the accuracy and reliability of the annotation process.\nThe result of the expert annotation yields two curated datasets. The Relation Detection dataset for Rett Syndrome (ReDReS) contains 601 sentences with 5,259 instances and 1,148 unique CUIs (Tab. 1). The inter-annotator agreement is measured using the Fleiss kappa score (McHugh, 2012), resulting in 0.6143 in the multi-class setup (4 classes) and indicating substantial agreement among annotators (Landis and Koch, 1977). In the binary setup (relation or no relation), the Fleiss kappa score is 0.7139. The Relation Detection dataset for Alzheimer's Disease (ReDAD) comprises 641 sentences with 8,565 instances and 1,480 unique CUIs (Tab. 1). The Fleiss kappa score is 0.6403"}, {"title": "3 Models", "content": "In this section, we introduce two main models, the Language-Model Embedding Learning (LaMEL) model and the Language-Model Relation Detection (LaMReD) model (Fig. 3), to benchmark datasets and establish robust baselines.\nTask formulation. Given a sentence containing two identified entities $e1$ and $e2$, we predict the semantic relation $sem$, between them. In the multi-class setup, the labels are: positive, negative, complex, and no relation. In the binary setup, the goal is to determine if any relation exists. Special tokens [ent] and [/ent] mark the start and end of each entity within the sentence, ensuring consistent identification and processing of entity boundaries.\n3.1 LaMEL model\nLaMEL learns an embedding space optimized for relation detection (Fig. 3). As the backbone language model (LM), we opt for PubMedBERT (Gu et al., 2021; Tinn et al., 2023) (MIT License), available in both uncased base and uncased large versions. PubMedBERT is pretrained on the PubMed corpus, making it well-suited for our task as the curated datasets consist of sentences of abstracts from PubMed papers. Leveraging PubMedBERT ensures that the model can capture the language patterns prevalent in biomedical text. Following the LM encoding, we construct the representation of each entity by extracting its contextualized embedding $E_i$ corresponding to each entity $e_i$ from the encoded sequence. Subsequently, the entity representations are projected to the embedding space using a linear layer without changing the embedding dimension. The final prediction is based on cosine similarity between the two projected entity representations. If the cosine similarity exceeds a predefined threshold, the model predicts that there is a semantic relation between the two entities. We experiment with diverse strategies for learning entity representations (Fig. 3), aiming to optimize the effectiveness of the embedding space for the relation detection task. The explored types of entity representation $E$ are:\n\u2022 A, B, C - Special Tokens:\n$E_A = t_{[ent]}$,\n$E_B = t_{[/ent]}$,\n$E_C = t_{[ent]}; t_{[/ent]}$,\n\u2022 D - Entity Pool:\n$E_D = [t_E]$,\n\u2022 E - Entity & Middle Pool:\n$E_E = [t_E] * [t_{Inter}]$,\n\u2022 F, G, H - Special Tokens & Middle Pool:\n$E_F = t_{[ent]} * [t_{Inter}]$,\n$E_G = t_{[/ent]} * [t_{Inter}]$,\n$E_H = t_{[ent]} * t_{[/ent]} * [t_{Inter}]$,\nwhere {$E_A, E_B, E_D, E_E, E_F, E_G, E_H$} \u2208 $R^d$ and $E_C$ \u2208 $R^{2d}$, d is the embedding size of PubMedBERT base (768) and PubMedBERT large (1024), defines the concatenation, * holds for the element-wise multiplication, $t_{[ent]}$, $t_{[/ent]}$ are the embeddings of the start and end special tokens of the entities, $[t_E]$ and $[t_{Inter}]$ are the averaged pooled representation of the entities and the intermediate tokens between the entities respectively."}, {"title": "3.2 LaMReD model", "content": "LaMReD provides two variations that differ in information synthesis (Fig. 3), aiming to explore the potential effect of different aggregations (Theodoropoulos and Moens, 2023). LaMReDA utilizes element-wise addition to aggregate the entities' representations, while LaMReDM employs element-wise multiplication. The input text is encoded using PubMedBERT (base or large). Following LM encoding, we construct the relation representation by sampling and aggregating tokens from the input sequence. This step enables the model to capture essential features and contextual information relevant to semantic relation classification. To mitigate the risk of overfitting and enhance model generalization, we incorporate a dropout layer (Srivastava et al., 2014) with a probability of 0.3. The linear classification layer takes the aggregated representation and outputs the predicted label.\nFollowing the paradigm proposed by Baldini Soares et al. (2019) and Hogan et al. (2021), we experiment with various approaches for learning relation representations tailored to the relation detection task to empirically ascertain the effectiveness of each strategy (Fig. 3). The explored types of relation representation $R$ are the following:\n\u2022 A, B, C - Special Tokens:\n$R_A = f(l(t_{[ent]1}), l(t_{[ent]2}))$,\n$R_B = f(l(t_{[/ent]1}), l(t_{[/ent]2}))$,\n$R_C = f(l(t_{[ent]1}), l(t_{[/ent]1}),\nl(t_{[ent]2}), l(t_{[/ent]2}))$,\n\u2022 D - Entity Pool:\n$R_D = f(l([t_{E1}]),l([t_{E2}]))$,\n\u2022 E- Middle Pool:\n$R_E = l([t_{Inter}])$,\n\u2022 F - [CLS] token & Entity Pool:\n$R_F = f(l(t_{[CLS]}), l([t_{E1}]),l([t_{E2}]))$,\n\u2022 G, H, I - [CLS] token & Special Tokens:\n$R_G = f(l(t_{[CLS]}), l(t_{[ent]1}), l(t_{[ent]2}))$,\n$R_H = f(l(t_{[CLS]}), l(t_{[/ent]1}), l(t_{[/ent]2}))$,\n$R_I = f(l(t_{[CLS]}), l(t_{[ent]1}), l(t_{[/ent]1}),\nl(t_{[ent]2}), l(t_{[/ent]2}))$,\n\u2022 J - [CLS] token & Middle Pool:\n$R_J = f(l(t_{[CLS]}), l([t_{Inter}]))$,\n\u2022 K, L, M - Special tokens & Middle Pool:\n$R_K = f(l(t_{[ent]1}), l([t_{Inter}]), l(t_{[ent]2}))$,\n$R_L = f(l(t_{[/ent]1}), l([t_{Inter}]), l(t_{[ent]2}))$,\n$R_M = f(l(t_{[ent]1}), l(t_{[/ent]1}), l([t_{Inter}]),\nl(t_{[ent]2}), l(t_{[/ent]2}))$,\n\u2022 N - Entity & Middle Pool:\n$R_N = f(l([t_{E1}]), l([t_{Inter}]), l([t_{E2}]))$,\n\u2022 O, P - Context Vector & Entity Pool:\n$R_O = l(cv)$,\n$R_P = f(l([t_{E1}]),l([t_{E2}]), l(cv))$, where {$R_A, R_B, R_C, R_D, R_E, R_F, R_G, R_H, R_I, R_J, R_K, R_L, R_M, R_N, R_O, R_P$} \u2208 $R^d$, d is the embedding size of PubMedBERT base (768) and PubMedBERT large (1024), $f()$ is the aggregation function, element-wise addition for LaMReDA and element-wise multiplication for LaMReDM, $l()$ is a linear projection layer with dimension equal to the embedding size, $t_{[ent]1}, t_{[/ent]1}, t_{[ent]2}$, and $t_{[/ent]2}$ are the embeddings of the start and end special tokens of the first and second entity and $t_{[CLS]}$ is the representation of the special token [CLS]. We define the averaged pooled representation of the entities and the intermediate tokens between the entities as $[t_{E1}]$, $[t_{E2}]$, and $[t_{Inter}]$ correspondingly. In equations 23 and 24, we utilize the localized context vector $cv$ that utilizes the attention heads to locate relevant context for the entity pair and was introduced in ATLOP (Zhou et al., 2021), a state-of-the-art model in document-level relation extraction."}, {"title": "3.3 Experimental setup", "content": "The models are trained for 50 epochs and the best checkpoints are retained based on the performance on the development set, measured using the F1-score. We utilize the Adam (Kingma and Ba, 2014) optimizer with a learning rate of 10-5. The batch size is set to 16. We conduct experiments in two distinct setups. In the multi-class setup, we evaluate performance using micro and macro F1-score, considering four relation types: positive, negative, complex, and no relation. In the binary setup, the objective is the prediction of the presence of relation. LaMEL is specifically designed for the binary setup. We utilize the official splits of ReDReS and ReDAD (Tab. 1) and repeat the experiments 10 times with different seeds. To ensure robustness of results, we also employ a 5-fold cross-validation approach. To explore the cross-disease capabilities of our approach, we train the models using one dataset (e.g., ReDReS) and evaluate on the other (e.g., ReDAD), and vice versa. We utilize the relation representation $R_A$ (Eq. 9) for LaMReDA and LaMReDM and the entity representation $E_A$ (Eq. 1) for LaMEL. These experiments are repeated 10 times with different seeds, and 15% of the training data is excluded to define the development set.\nThe cross-entropy loss function is used to train LaMReDA and LaMReDM. For LaMEL, the following cosine embedding loss function is used:\n$l(x_1, x_2, Y) = \\begin{cases}  1 - cos(x_1, x_2), & \\text{if } y = 1 \\\\  max(0, cos(x_1, x_2) - m), & \\text{if } y = -1  \\end{cases}$"}, {"title": "4 Results", "content": "Tables 2 and 3 report the F1-scores for LaMEL LaMReDA, and LaMReDM, models on the ReDRES and ReDAD datasets. Each cell (except for cross-disease experiments) displays two values: the average F1-score from 10 runs on the original test set (Tab. 1) and the average F1-score from a 5-fold cross-validation. The models perform well across all relation (A-P) and entity (A-H) representations, showing their ability to learn meaningful representations for the semantic relation task regardless of initial token selection. However, we observe patterns regarding the relation representations. In the binary setup, relation representation $R_G$ (Eq. 15) yields strong results for both datasets, suggesting that including the [CLS] token representation might be beneficial. In the multi-class setup, relation representations $R_L$ (Eq. 20), $R_J$ (Eq. 18), and $R_O$ (Eq. 23) are effective for both datasets, indicating that the surrounding context is crucial for the more complex task, as $R_L$ and $R_J$ include the averaged pooled representation of intermediate tokens between entities, and $R_O$ leverages the context vector (Zhou et al., 2021). The intra-model comparison reveals that over-parameterization tends to be useful. Using PubMedBERT large generally results in better performance than the base alternative. The PubMedBERT base shows superior performance mainly only in experiments using the original splits of ReDRES (Tab. 1). LaMEL is highly competitive with LaMReDA and LaMReDM, indicating that learning entity embedding spaces optimized for relation detection is promising. LaMEL achieves the highest performance in the 5-fold setup of ReDAD and the original setup of ReDReS, with F1-scores of 91.03% and 91.25% respectively.\nThe inter-model comparison across the same relation representations indicates that the aggregation function does not significantly impact relation detection tasks. Neither LaMReDA (element-wise addition) nor LaMReDM (element-wise multiplication) show a clear advantage over the other. This suggests that the transformer layers of PubMed-"}, {"title": "5 Probing", "content": "This study probes PubMedBERT's ability to capture semantic relations between entities. We explore different transformer layer representations and attention scores per layer and attention head. Averaged pooled entity representations are extracted from each layer, followed by training a linear classification layer. We test relation representations $R_D$, $R_O$, and $R_P$ (Eq. 12, 23, 24) of LaMReDA and LaMReDM to assess the impact of the context vector. Out-of-the-box representations are evaluated without the projection linear layer l(). We also extract average attention scores of tokens for each entity towards the other across each layer and head, concatenating these into a feature vector for training a linear classification layer. Following Chizhikova et al. (2022), we also train the classification layer using average attention scores between the two entities across all layers."}, {"title": "6 Related Work", "content": "Information Extraction Datasets. Several biomedical datasets aim to enhance Information Extraction (IE) system development (Huang et al., 2024; Detroja et al., 2023; Nasar et al., 2021; Theodoropoulos et al., 2021), typically focusing on one or a few entity types and their interactions. AIMed (Bunescu et al., 2005), BioInfer (Pyysalo et al., 2007), and BioCreative II PPI IPS (Krallinger et al., 2008) formulate protein-protein interactions. The chemical-protein and chemical-disease interactions are modeled by DrugProt (Miranda et al., 2021) and BC5CDR (Li et al., 2016), respectively. ADE (Gurulingappa et al., 2012), DDI13 (Herrero-Zazo et al., 2013), and n2c2 2018 ADE (Henry et al., 2020) include drug-ADE (adverse drug effect) and drug-drug interactions. EMU (Doughty et al., 2011), GAD (Bravo et al., 2015) and RENET2 (Su et al., 2021) contain relations between genes and diseases. N-ary (Peng et al., 2017) incorporates drug-gene mutation interactions. The task of event extraction is illustrated by GE09 (Kim et al., 2009), GE11 (Kim et al., 2011), and CG (Pyysalo et al., 2013). DDAE (Lai et al., 2019) includes disease-disease associations. BioRED (Luo et al., 2022) focuses on document-level relations for various entities. Unlike these datasets, ReDRES and ReDAD focus on RS and AD, include entities of up to 82 different semantic types, and model the semantic relation between them.\nKnowledge Discovery. Gottlieb et al. (2011) present PREDICT, a method for ranking potential drug-disease associations to predict drug indications. Romano et al. (2024) release AlzKB, a heterogeneous graph knowledge base for AD, constructed using external data sources and describing various medical entities (e.g., chemicals, genes). Other graph-based efforts model knowledge around AD for tasks such as drug repurposing (Hsieh et al., 2023; Daluwatumulle et al., 2022; Nian et al., 2022), gene identification (Binder et al., 2022), or as general knowledge repositories (S\u00fcgis et al., 2019). Another paradigm for knowledge discovery is the open information extraction (OIE) setup (Mausam et al., 2012; Etzioni et al., 2008), which faces challenges such as data consistency, performance evaluation, and semantic drift (Zhou et al., 2022). Research efforts (Wang et al., 2018; de Silva et al., 2017; Nebot and Berlanga, 2014; Movshovitz-Attias and Cohen, 2012; Nebot and Berlanga, 2011) aim to address these issues and extract knowledge with little or no supervision. Advances in literature-based discovery (Gopalakrishnan et al., 2019; Thilakaratne et al., 2019) try to identify novel medical entity relations using graph-based (Kilicoglu et al., 2020; Nicholson and Greene, 2020), machine learning (Zhao et al., 2021; Lardos et al., 2022), and co-occurrence methods (Kuusisto et al., 2020; Millikin et al., 2023). Tian et al. (2024) stress the potential of large language models (LLMs) to summarize, simplify, and synthesize medical evidence (Peng et al., 2023; Tang et al., 2023; Shaib et al., 2023), suggesting that LLMs may have encoded biomedical knowledge (Singhal et al., 2023). To exploit this potential, we explore constructing LM representations for knowledge discovery. To the best of our knowledge, no systematic approach assembles knowledge about RS. Unlike previous work, we introduce a, in principle, disease-agnostic framework, to acquire knowledge about RS and AD starting from raw text."}, {"title": "7 Conclusion", "content": "This work presents an open-source framework for disease knowledge discovery from raw text. We contribute two new annotated datasets for RS (Re-DReS) and AD (ReDAD), facilitating further research. Extensive evaluation explores various methods for representing relations and entities, yielding insights into optimal modeling approaches for semantic relation detection, and emphasizing language models' potential in knowledge discovery."}, {"title": "Limitations", "content": "One limitation of the paper is that the data pipeline relies on an external mention extractor/linker. However, this aspect introduces flexibility, allowing researchers and practitioners to integrate custom models suited to their specific applications. The creation of gold-standard datasets requires the manual work of medical experts. This process is time-consuming and resource-intensive, potentially limiting the scalability of the approach. Nevertheless, the experiments demonstrate that the supervised models of the study achieve strong performance in semantic relation detection without needing a large training set. Additionally, the cross-disease experiments highlight the robustness of the models in both binary and multi-class setups. This finding enables transfer learning scenarios in semantic relation detection, which can be applied to other diseases or medical aspects, indicating a potential for broader applications and research opportunities."}, {"title": "Ethics Statement", "content": "All recruited medical experts provided informed consent before participating in the annotation process. The compensation provided to the annotators was adequate and considered their demographic, particularly their country of residence."}, {"title": "A Data Pipeline: Additional Information", "content": "To facilitate effective abstract retrieval, we implement an iterative approach to circumvent the API's limitation of retrieving only 10,000 article IDs per query. This iterative process enables us to access a comprehensive set of PubMed IDs (PMIDs) related to the query. The detailed list of the 82 semantic types of the MetaMapLite-based pipeline is presented in Table 4. In addition to the MetaMapLite-based pipeline, we propose a second pipeline that is based on ScispaCy (Apache License 2.0) (Fig. 5). The difference lies in the selection of entity extractors and linkers that map the extracted entities to knowledge schemes. Unlike MetaMapLite, which adopts an integrated approach where mention extraction and linking are performed simultaneously in a single step and focuses on UMLS mapping, allowing for more precise and targeted extraction of entities, ScispaCy serves a broader range of Natural Language Processing (NLP) tasks. After the retrieval of the abstracts that is described in subsection 2.1, the following steps are executed: Knowledge schema and linker generation, Mention extraction, Entity linking. and Sampling of linked identifiers.\nKnowledge schema and linker generation. ScispaCy (Neumann et al., 2019) harnesses an older version of UMLS (2020AA). This version serves as the foundation upon which ScispaCy trains and constructs its linkers that operate on a char-3grams string overlap-based search mechanism, facilitating efficient and accurate entity recognition and linking processes. Following the paradigm of ScispaCy, we provide scripts for generating updated linkers tailored to a range of knowledge schemes. These include UMLS (Bodenreider, 2004), Gene Ontology (GO) (Consortium, 2004), National Center for Biotechnology Information (NCBI) taxonomy (Schoch et al., 2020), RxNorm (Nelson et al., 2011), SNOMED Clinical Terms (SNOMEDCT_US) (Stearns et al., 2001), Human Phenotype Ontology (HPO) (K\u00f6hler et al., 2021), Medical Subject Headings (MeSH) (Lipscomb, 2000) DrugBank (Knox et al., 2024) and Gold Standard Drug Database. Of particular note is the inclusion of UMLS, a unified system encompassing various knowledge bases, vocabularies, taxonomies, and ontologies pertinent to the biomedical domain. Any supported linker maps the concepts to UMLS CUIs enhancing the standardization of medical terminology. Notably, the flexibility of ScispaCy's implementation allows for seamless expansion to incorporate additional knowledge bases, thereby enhancing its versatility and applicability across diverse research needs.\nMention extraction. ScispaCy boasts four distinct entity extractors, each trained on different corpora, collectively encompassing a range of entity types. These extractors include named entity recognition (NER) models trained on the CRAFT corpus (with 6 entity types) (Bada et al., 2012), JNLPBA corpus (with 5 entity types) (Collier et al., 2004), BC5CDR corpus (with 2 entity types) (Li et al., 2016), and BIONLP13CG corpus (with 16 entity types) (Kim et al., 2013). To maximize the range of the entity extraction, we leverage these diverse extractors in tandem, allowing us to capture mentions of 18 unique entity types (gene or protein, cell, chemical, organism, disease, organ, DNA, RNA, tissue, cancer, cellular component, anatomical system, multi-tissue structure, organism subdivision, developing anatomical structure, pathological formation, organism substance, and immaterial anatomical entity).\nEntity linking. This process enhances the semantic understanding of the extracted entities, facilitates standardization, which is a key issue in the biomedical field (Bettencourt-Silva et al., 2012; Theodoropoulos et al., 2023), and promotes interoperability with external resources by associating the entities with specific concepts in supported knowledge schemes. Each entity is subjected to a linking process where we attempt to map it to concepts within supported knowledge bases or vocabularies. If a match is found, the entity is assigned a unique identifier, referred to as a CUI, corresponding to the specific concept in the knowledge schema. As entities may be linked to multiple knowledge sources, we merge the extracted CUIs obtained from the different linkers. This consolidation process ensures that each entity is associated with a comprehensive set of identifiers, encompassing diverse perspectives and representations across various knowledge schemes.\nSampling of linked identifiers. We address the scenario where multiple CUIs can be extracted for each entity due to the utilization of multiple linkers. We propose a prioritized sampling strategy to manage this situation and select the most relevant CUIs effectively. This strategy is designed to sample CUIs based on the predicted type of the entity (e.g., disease, gene, or chemical/drug) by prioritizing mapped CUIs from specific knowledge schemes focused on the entity being processed. For example, if an entity is predicted to be a chemical/drug, the sampling strategy first checks if any linked CUIs exist in RxNorm linker, a specific knowledge schema tailored for chemicals. If linked CUIs are found, they are sampled for inclusion in the final set of linked concepts associated with the entity, otherwise, the search is continued in a prioritized way. We stress that the sampling strategy can be easily modified by the user based on the requirements of the research or the application.\nThe co-occurrence graph generation step is described in subsection 2.1."}, {"title": "Sentence Sampling Algorithm", "content": "Given a set of sentences with defined CUIs $sent\\_c$ and the co-occurrence frequency graph $co\\_g$, sample n number of sentences (Alg. 1). Initialize a dictionary $f\\_d$ and for each sentence save the extracted CUIs pairs $c\\_p$ ($extract\\_conc(sent)$), the frequencies $f\\_p$ of each pair extracted from the $co\\_g$ ($extract\\_freq(c\\_p, co\\_g)$) and the summation of the frequencies $t\\_f$. Retrieve the sentence ids, summed frequencies, and the inverted summed frequencies from the dictionary and append them in $ids$, $f\\_l$, and $inv\\_f\\_l$ lists respectively. Calculate the total sums of the frequencies $t\\_f\\_sum$, $inv\\_t\\_f\\_sum$ and then utilize them to define the probability distributions $P$ and $IP$. Sample 50% of the sentences from $P$ ($sample(P,n/2)$) and 50% from $IP$ ($sample(IP,n/2)$) to ensure a balance of common and potentially novel pairs of co-occurred entities in the dataset."}, {"title": "B Annotation Portal", "content": "Figure 7 presents the annotation portal with an example from the ReDRES dataset. The annotator's task is to identify the semantic relation between the two highlighted entities, classifying it as either a Positive Relation, Negative Relation, Complex Relation, or No Relation. If the sentence is considered uninformative or if there are errors in entity detection, type, or span, the annotator can remove the sentence or the entities. Furthermore, the annotator is encouraged to provide feedback, including any additional text that can clarify or elaborate on the relationship between the entities. By providing this supplementary information, annotators can contribute to a richer and more nuanced understanding of the relations within the data."}, {"title": "C Dataset Instances", "content": "In this section, we present some instances of different relation types in the datasets. In each example, we highlight the two detected entities.\nPositive Relation:\n\u2022 Amyloid fibrils are found in many fatal neurodegenerative diseases such as Alzheimer's disease, Parkinson's disease, type II diabetes, and prion disease.\n\u2022 AChE has become an important drug target because partial inhibition of AChE results in modest increase in ACh levels that can have therapeutic benefits, thus AChE inhibitors have proved useful in the symptomatic treatment of Alzheimer's disease.\nComplex Relation:\n\u2022 When the brain's antioxidant defenses are overwhelmed by IR, it produces an abundance of reactive oxygen species (ROS) that can lead to oxidative stress, mitochondrial dysfunction, loss of synaptic plasticity, altered neuronal structure and microvascular impairment that have been identified as early signs of neurodegeneration in Alzheimer's disease, Parkinson's, amyotrophic lateral sclerosis, vascular dementia and other diseases that progressively damage the brain and central nervous system.\n\u2022 Autophagy inhibitor 3-methyladenine (3-MA) attenuated the neuroprotective effect of CA, suggesting that autophagy was involved in the neuroprotection of CA.\nNegative Relation:\n\u2022 It was not observed in synaptopodin-deficient mice, which lack spine apparatus organelles.\n\u2022 Furthermore, the use of some kinds of anti-hypertensive medication has been suggested to reduce the incidence of dementia including Alzheimer's disease.\nNo Relation:\n\u2022 Peripheral immune cells can cross the intact BBB, CNS neurons and glia actively regulate macrophage and lymphocyte responses, and microglia are immunocompetent but differ from other macrophage/dendritic cells in their ability to direct neuroprotective lymphocyte responses.\n\u2022 These techniques have thus provided morphological and functional brain alterations mapping of Alzheimer's disease: on one hand grey matter atrophy first concerns the medial temporal lobe before extending to the temporal neocortex and then other neocortical areas; on the other hand, metabolic alterations are first located within the posterior cingulate cortex and then reach the temporo-parietal area as well as the prefrontal cortex, especially in its medial part."}, {"title": "D Localized Context Vector", "content": "The localized context vector is computed as follows:\n\u2022 Extract the attention scores of the two entities in the last encoding layer of the language model.\n\u2022 Calculate the Hadamard product of the attention vectors.\n\u2022 Calculate the average of the Hadamard product over the attention heads.\n\u2022 Normalize to extract the distribution over the sequence.\n\u2022 Extract the localized context vector by multiplying the token representations of the last encoding layer with the distribution vector."}]}