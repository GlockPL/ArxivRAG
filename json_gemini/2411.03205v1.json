{"title": "GIS Copilot: Towards an Autonomous GIS Agent for Spatial Analysis", "authors": ["Temitope Akinboyewa", "Zhenlong Li", "Huan Ning", "M. Naser Lessani"], "abstract": "Recent advancements in Generative Artificial Intelligence (Generative AI) and particularly Large Language Models (LLMs) like GPT-4, offer promising capabilities for spatial analysis. Despite their potential, the integration of generative AI with established GIS platforms remains underexplored. In this study, we propose a framework for integrating LLMs directly into existing GIS platforms, using the well-developed GIS software QGIS as an example. Our approach leverages the reasoning and programming capabilities of LLMs to autonomously generate spatial analysis workflows and code through an informed agent that has comprehensive documentation of key GIS tools and parameters. The framework also incorporates external tools such as GeoPandas to enhance the system's geoprocessing capabilities. The implementation of this framework resulted in the development of a \"GIS Copilot\" that allows GIS users to interact with QGIS using natural language commands for spatial analysis. The GIS Copilot was evaluated based on three complexity levels: basic tasks that require one GIS tool and typically involve one data layer to perform simple operations; intermediate tasks involving multi-step processes with multiple tools, guided by user instructions; and advanced tasks which involve multi-step processes that require multiple tools but not guided by user instructions, necessitating the agent to independently decide on and executes the necessary steps. The evaluation reveals that the GIS Copilot demonstrates strong potential in automating foundational GIS operations, with a high success rate in tool selection and code generation for basic and intermediate tasks, while challenges remain in achieving full autonomy for more complex tasks. This study contributes to the emerging vision of Autonomous GIS, providing a pathway for non-experts to engage with geospatial analysis with minimal prior expertise. While full autonomy is yet to be achieved, the GIS Copilot demonstrates significant potential for simplifying GIS workflows and enhancing decision-making processes.", "sections": [{"title": "1 Introduction", "content": "In recent years, Generative Artificial Intelligence (GenAI) has gained significant attention in Geographic Information Science (GIScience). Among these advancements, Large Language Models (LLMs) have emerged as powerful tools, demonstrating potential in GIScience through their abilities in reasoning, natural language understanding, and computer programming. LLMs offer a wide range of applications within Geographic Information Systems (GIS), including spatial data analysis, process automation, and geospatial knowledge extraction. A number of studies have explored the capabilities of LLMs, with researchers investigating their potential in various GIS applications such as cartography (Tao and Xu, 2023), disaster management (Akinboyewa et al., 2024; Hao et al., 2024), GIS-based question answering (Mooney et al., 2023), location descriptions extraction (Hu et al., 2023), and geospatial data retrieval (Ning et al., 2024). These efforts demonstrate that LLMs hold promise in enhancing traditional GIS workflows.\nSpatial analysis, an essential tool in making well-informed decisions in various domains such as urban planning, environmental management, and public health, has adopted a new trend with the advent of generative AI. Several studies have explored the potential of generative AI in addressing geospatial tasks. A pioneering study by Li and Ning (2023) introduced a prototype of autonomous GIS, which demonstrates the possibility of conducting spatial analysis autonomously powered by AI. This system processes spatial problems presented by users, generates a geoprocessing workflow, and produces the corresponding executable codes, thereby producing the final result. Similarly, projects like GeoGPT (Zhang et al., 2024a), and MapGPT (Zhang et al., 2024b) have advanced the integration of generative AI into spatial data analysis.\nWhile the integration of generative AI in spatial analysis has shown significant promise, one key limitation is that these existing approaches have not fully embedded LLM capabilities within established GIS platforms like QGIS (2024), ArcGIS Pro (ESRI, 2024), and GRASS GIS (2024). Li and Ning (2023) suggest that implementing autonomous GIS based on existing GIS platforms as a \"co-pilot\" may be the most practical and efficient approach. Established GIS platforms offer a wide array of advanced specialized tools for spatial analysis, data management, and visualization. Therefore, the absence of LLM-based solutions within these established GIS platforms has not only restricted the accessibility, scalability, and effectiveness of LLMs in geospatial analysis but also missed the opportunity to leverage advanced AI reasoning in combination with GIS-specific tools.\nHowever, the integration of LLMs into GIS platforms like QGIS presents several challenges. First, GIS platforms are inherently complex, supporting a wide range of tools, libraries, and workflows for functions such as data visualization, spatial analysis, geoprocessing, and cartographic rendering. These tools often rely on diverse frameworks, data standards, and programming languages, complicating the creation of a single, cohesive workflow that integrates AI smoothly. Secondly, effective communication between the AI and existing GIS functions requires robust and error-free interaction. This involves translating natural language queries into GIS commands and ensuring that those commands align with GIS native tools and standards. Such a process demands extensive fine-tuning and specialized approaches to understand the full breadth of GIS tools and operations. Additionally, GIS workflows are often highly customized and problem specific. Developing an AI integration that can seamlessly adapt to these custom workflows, while being flexible enough to handle various user-defined parameters, is challenging."}, {"title": "2 Related Work", "content": null}, {"title": "2.1 Autonomous GIS and the integration of generative AI into geospatial tasks", "content": "The recent advancement of generative AI, particularly LLMs such as GPT-4 (OpenAI, 2023), Llama (Meta, 2024), and Gemini (Gemini Team and Google, 2023), have opened the avenue for researchers to explore autonomous GIS (Wang et al., 2024). Researchers have leveraged LLMs to conceptualize and develop various autonomous GIS agents from spatial data retrieval (Ning et al., 2024) to geospatial information extraction (Crooks and Chen, 2024) to spatial analysis and mapping (Mansourian and Oucheikh, 2024; Zhang et al., 2024b). Among the pioneering studies in autonomous GIS is the work by Li and Ning (2023), who developed a prototype named LLM-Geo to demonstrate the potential of AI-powered GIS to perform various geospatial operations such as numerical aggregation, chart generation, and map presentations in an autonomous manner using GPT-4 API. In another study, Zhang, et al. (2024a) proposed a framework named GeoGPT, which integrates the capabilities of LLMs with GIS tools to enhance the efficiency of geospatial operations, including data collection, processing, and analysis. By utilizing the LangChain framework, the LLM interprets user requests, plans the necessary steps, and sequentially executes relevant GIS tools from a predefined tool pool, encompassing tools for data collection, spatial analysis, and cartographic visualization. Additionally, Lin et al. (2024)"}, {"title": "2.2 Integrating LLMs into existing GIS platforms", "content": "Recently, efforts have been made to integrate LLMs with established GIS platforms, particularly the open source QGIS. Ning et al. (2024) introduced an autonomous GIS agent framework and a QGIS plugin to facilitate the automated downloading of geospatial data. While this study represents significant progress, it focuses primarily on data retrieval rather than the full field of spatial analysis tasks. QChatGPT (2023) is another LLM-based QGIS plugin, but its functionality is currently limited to offering guidance on performing tasks rather than automating the tasks themselves. This highlights the need for further research into methods that can seamlessly integrate LLMs into GIS tools for autonomous spatial analysis. IntelliGeo (2024) is a QGIS plugin that leverages LLMs to automate geospatial workflows. It is designed to assist GIS professionals by automatically performing GIS operations through two primary methods: generating PyQGIS scripts or creating graphical models. Although promising, it is limited to generating only general code, requiring users to manually enter some parameters in the code, reducing the automation level. Furthermore, ESRI has also taken advances toward integrating generative Al into ArcGIS, introducing AI-enhanced tools aimed at improving geoprocessing workflows (Crawford et al., 2024). This includes functionality that recommends suitable tools for specific operations, providing guidance but not automating tasks. Additionally, ESRI's Mapping Assistant leverages GenAI to allow users to initiate GIS tasks through natural language inputs, streamlining workflows significantly (ESRI, 2024). However, this development is still in progress and is not yet available to users.\nMore recently, Mansourian and Oucheikh (2024) introduced ChatGeoAI that utilizes fine-tuned Llama2 model to generate PyQGIS code that can be used to perform spatial tasks. While this approach shares the goal of creating a platform that integrates LLM with GIS for geospatial analysis tasks, our study is significantly different in several ways. First, our study proposes a framework that deeply integrates LLMs within a well-established platform like QGIS, leveraging the full range of GIS tools. This allows the LLM to be more informed and produce more accurate and context-specific code. Second, our framework is implemented through the development of a GIS Copilot that is fully integrated into the GIS software itself to make the system more accessible to a broader range of users. This integration enables the Copilot to support a wide range of operations across various data types, including vector, raster datasets, and attribute data in tabular files, which offers greater flexibility in geospatial analysis. Additionally, our framework is not limited to QGIS tools alone; it is designed to be expandable, allowing the integration of external libraries and tools that simplify specific processes. For example, the widely used Python package, seaborn, can be utilized for advanced charting, making certain tasks more efficient. Lastly, we incorporate a self-correcting mechanism aimed at minimizing errors to enhance the system's autonomy and adaptability during task execution."}, {"title": "3 Methodology", "content": null}, {"title": "3.1 The framework of GIS Copilot", "content": "The main goal of this study is to facilitate autonomous spatial analysis by leveraging established GIS platforms. To achieve that, the GIS Copilot is designed to interact with existing GIS (e.g., QGIS) via graphic user interface, GIS toolbox, and documents for the toolbox, to assist GIS users in conducting geospatial data processing and analysis tasks. Four core modules, i.e., data understanding, GIS interface interaction, code debugging, and tool documentation support GIS Copilot in accomplishing tasks. Acting as a central decision-maker, the Copilot is informed by the data insights from the data understanding module and leverages documentation of the geoprocessing tools contained in the spatial analysis toolbox, to conduct analyses. It automatically determines the most suitable geospatial processing tools for various tasks, manages data processing workflows, and executes spatial analysis operations. It generates the necessary code for the selected tools and uses the code debugging module to automatically correct errors that may arise during execution."}, {"title": "3.1.1 Spatial analysis toolbox", "content": "QGIS is a popular and powerful open-source GIS that allows users to manage, analyze, and visualize geospatial data. It includes numerous algorithm providers, offering tools for spatial analysis, raster processing, and other geoprocessing tasks. Key providers include QGIS native algorithms, GDAL/OGR, GRASS GIS, SAGA GIS, and Orfeo Toolbox. These providers give users access to a vast array of geospatial tools for diverse workflows. Additionally, QGIS can be extended using PyQGIS, a Python API that enables automation and customization. With PyQGIS, users can script tasks, develop custom plugins, and access the full QGIS functions, making it a highly flexible platform for advanced spatial analysis and tool development (QGIS, 2024b).\nThe spatial analysis toolbox in this framework comprises both built-in and customized geoprocessing tools. Built-in tools include QGIS algorithms, such as native geoprocessing algorithms (e.g., 'native:buffer' for buffering and 'qgis:selectbyattribute' for attribute selection) and external providers like GDAL (e.g., 'gdal:slope' for slope analysis). Beyond these built-in tools, the framework incorporates customized tools developed using external libraries like GeoPandas, PySAL, and Matplotlib. These tools allow for customized visualizations (e.g., barplot, scatterplot), and thematic map generation, providing additional flexibility to the spatial analysis workflows."}, {"title": "3.1.2 Toolbox documentation", "content": "The GIS Copilot is equipped with documentation of QGIS tools, enabling it to generate PyQGIS code for performing specific geoprocessing tasks. The QGIS help documents are reorganized into text-based tool descriptions, which can easily be embedded in LLM prompts. Toolbox documentation primarily consists of tool descriptions, parameters, and code examples, serving as a guide for the agent in generating code for selected tools. For instance, the QGIS native \"Clip\" tool requires parameters such as the Input Layer (the dataset to be clipped), Overlay (the boundary layer for clipping), and Output File (the path where the clipped data will be saved) (Appendix 1). By specifying these parameters and providing a code example, the system is able to generate more accurate and reliable code for the task. In our current implementation, 390 native QGIS tools and GDAL tools which have been systematically compiled with reference to the resources available on the official QGIS documentation website (QGIS, 2024b). This framework is not limited to QGIS tools and is designed to be extensible in a plug-and-play style to allow users to add new customized tools to meet specific tasks. For example, a tool used for performing kernel density estimation can be customized using geopandas, scipy, and rasterio Python libraries and registered to the Copilot (Appendix 2)."}, {"title": "3.1.3 Data understanding module", "content": "The data understanding module enables the agent to interpret the structure and attributes of spatial data before being used for any analysis. It collects a wide range of critical information for spatial analysis, such as file format, field names and samples of attribute table, coordinate reference system, data extent, and raster resolution. This module is similar to the initial step a human analyst would take when approaching a spatial analysis task \u2013understanding the data to be used. In this framework, the data understanding module enhances the agent's autonomy by generating comprehensive metadata for input datasets using LLM. This metadata provides the Copilot with a thorough overview and understanding of the data inputs, which guides the system in selecting appropriate tools for the task and selecting the right attributes for performing geospatial operations. As a result, users are not required to specify data details such as field names in their task requests, making the Copilot more user-friendly."}, {"title": "3.1.4 Code review/debugging module", "content": "The code review/debugging module is an essential component designed to enhance the reliability and accuracy of code generated during geospatial analysis. This module enables the Copilot to monitor the execution of the generated code in real-time to capture any errors that may arise. Upon detecting an error, it attempts to correct the error automatically and rewrite the code for execution. This self-debugging functionality is iterative, allowing for continuous refinement and improvement of the code, thereby increasing the chances of successful execution."}, {"title": "3.1.5 GIS interface interaction", "content": "The GIS interface interaction module in our framework enables the GIS Copilot to engage directly with the GIS environment's graphic user interface. It allows the Copilot to perform actions such as dynamic loading and handling of data within the GIS software. For example, data layers that users load into GIS software can be automatically accessed by the Copilot. Additionally, results generated from Copilot are directly reloaded into the GIS interface, which allows immediate visualization and further processing or manipulation by the user."}, {"title": "3.2 Workflow of the GIS Copilot", "content": "The GIS Copilot is implemented as a plugin within QGIS. It interprets user requests in natural language and translates them into appropriate geoprocessing commands. As shown in Figure 2, the overall workflow begins by breaking down the user's task into detailed components. Once the task is well understood, the system identifies the appropriate geoprocessing tool(s) from a wide selection, including QGIS native tools, GDAL, or other customized tools such as GeoPandas and SciPy. The tools are selected based on the steps analyzed during the task breakdown to ensure each step of the process is addressed by the most suitable tool. Based on the selected tool (s), the system generates executable Python code that is specifically designed to solve the spatial task. Throughout these steps, the system is guided by a set of predefined instructions, automatically generated metadata and a comprehensive tool list to ensure reliable task analysis, tool selection, and code generation. Finally, the code is executed,"}, {"title": "3.2.1 Task analysis and tool selection", "content": "The first stage is that the agent gives a breakdown of the task. When a user submits a spatial query in natural language, the agent processes the request to understand the underlying spatial problem. After the initial interpretation, the agent performs a task breakdown to determine what is needed to achieve the intended outcome. For instance, a user may request, \"Identify all residential areas within a 5-minute driving distance from hospitals.\" The agent first identifies the spatial entities involved - residential areas, hospitals, and the concept of a 5-minute drive. Based on these insights, it matches the request to a set of geoprocessing tools available within the spatial analysis toolbox. The decision-making process for selecting the appropriate tool involves considering several factors, such as the nature of the data (e.g., vector or raster), the geographic projection, and the data structure (e.g., polygons, lines). Additionally, any user preferences specified during the query, such as the choice of tools or specific processing techniques, are taken into account."}, {"title": "3.2.2 Code generation and parameter setting", "content": "Once the appropriate tools are selected, the next step in the workflow is the code generation phase. The agent generates python code to execute the operation based on the selected tools. The generation process is driven by predefined documentation for each tool, which includes usage guides, parameter requirements, and sample code templates so that the generated python code is well-formed and ready for execution. To personalize the generated code to fit the user's requirements, the agent adjusts the parameters to align with the task's specific details. For instance, suppose a user request is to \u201cselect counties with a population greater than 50,000\u201d. The Copilot customizes the code based on the user's specific requirement by setting the filter condition to \"Population\" > 50,000, where \u201cpopulation\" is assumed to be the relevant attribute name."}, {"title": "3.2.3 Execution and visualization of results", "content": "After generating the code, the next step involves executing it to perform the spatial analysis. This stage is facilitated by an execution and self-debugging module, which oversees the entire process. The generated code is executed directly within the QGIS Python environment, allowing the spatial analysis to be performed without leaving the QGIS interface. Depending on the nature of the task, results can take various forms: the outputs of geoprocessing tasks, such as buffer zones, intersected layers, or reclassified raster layers, are loaded and displayed directly into the QGIS environment as map layers, where they can be further analyzed, visualized, or exported. Analytical results that involve summaries, charts, attribute statistics, or calculated metrics are displayed within the plugin interface as tables, images, or textual reports. When appropriate or requested in the tasks, the plugin may also generate visualizations, such as bar charts, histograms, or other graphical representations to help users interpret the results. If an error is encountered during execution, a self-debugging module is activated. This module reviews the code, identifies the errors, makes necessary corrections, and re-executes the revised code."}, {"title": "3.3 User interface design", "content": "The GIS Copilot graphic user interface comprises five main tabs: Request box, Reports, Geoprocessing Workflow, Settings, and Help, as shown in Figure 3. The Request Page is the main interface where users can enter their requests. It includes key features like an AI-generated code displayed in real-time, an information panel showing the agent's status, a message box for user requests, and paths for datasets loaded into QGIS. Users can select datasets for analysis directly from the QGIS layer panel by checking the layers they want to include and unchecking those to exclude, enabling seamless integration with QGIS. The Reports tab allows users to view outputs like charts, plots, and statistical summaries. The geoprocessing workflow tab illustrates the steps involved in completing the user's request in a visual flow. The Settings tab lets users configure the plugin, such as setting API keys, selecting the AI model, and defining the default workspace where results are saved."}, {"title": "4 Case Studies", "content": "To demonstrate the proposed framework and capabilities of the GIS Copilot, cases are categorized into three levels of complexity: basic, intermediate, and advanced. Descriptions of each level are given in the following sections."}, {"title": "4.1 Basic level tasks", "content": "At this level, the tasks are straightforward and involve using a single tool along with one (or occasionally two) data layers. The agent is expected to perform a straightforward operation that usually requires a single step, such as calculating the area of polygons or selecting features based on attributes. These tasks are foundational, typically performed using one tool, and require minimal decision-making from the agent."}, {"title": "4.1.1 Health facilities coverage zone in Washington D.C., USA", "content": "This case involves creating service zones around health facilities in Washington D.C, United States. The input data was a vector layer of health facilities (hospitals, clinics, and pharmacies) obtained from OpenStreetMap. In this task, the agent was prompted to create 2,000-foot zones around each health facility to identify areas of service coverage (Figure 4). The agent successfully selected the appropriate spatial analysis tool (the buffer tool) and generated executable code, which includes setting the required parameters (e.g., distance) based on the user query and executing the operation."}, {"title": "4.1.2 Generating contour lines from the Digital Elevation Model (DEM)", "content": "In this case, the Spatial Analysis Agent is tasked with generating contour lines from a Digital Elevation Model (DEM) dataset, a raster data layer that represents terrain elevation. This is a foundational spatial analysis task that is frequently used in geographic studies, such as topographical mapping, environmental modeling, and landscape visualization. The agent selected the tool gdal:contour from the available geoprocessing tools within the system. This tool is specifically designed to convert elevation data (raster) into contour lines (vector), based on user-defined intervals. In our case study, the output in vector format is shown in Figure 5."}, {"title": "4.1.3 Selection of high population counties in the US.", "content": "This case demonstrates the selection of the US counties with a population exceeding 50,000. The input dataset is a single vector layer that contains the population of all counties in the contiguous U.S. states. In response to the task, the agent effectively identified the correct tool (extract by attribute) to filter the data. The agent then generated the necessary executable code, which included setting the population threshold and applying the filtering operation based on the specified condition. The result is presented in Figure 6."}, {"title": "4.1.4 Extracting land cover data of Pennsylvania", "content": "This case focuses on extracting land cover data for Pennsylvania from a larger dataset covering the contiguous US. The input data includes land cover raster data from the National Land Cover Database (NLCD) and a shapefile containing the boundary of Pennsylvania. The agent accurately selected the appropriate tool (the GDAL Clip Raster by Mask Layer tool) and generated the executable code, configuring parameters such as the input layer, output path, and clipping settings. The agent was able to produce the clipped raster layer showing the land cover specific to Pennsylvania (Figure 7). The result provides a detailed view of various land cover categories within the state's boundary."}, {"title": "4.2 Intermediate level tasks", "content": "At this level, tasks become more complex and involve multiple steps and tools. The agent is guided with specific instructions or a list of steps to perform the task. Although the steps are outlined, the agent still needs to generate the correct code for each step and link them together to perform the analysis. The focus here is to test the agent's ability to follow a given general workflow while managing more than one process."}, {"title": "4.2.1 Zonal Statistics of Average Elevation for Counties in South Carolina", "content": "In this case, the agent is tasked with analyzing the average elevation for each county in South Carolina (SC) based on the DEM. This involved a series of geoprocessing steps: clipping the DEM to the boundary of SC, generating a histogram of the clipped DEM's pixel values, calculating zonal statistics, and creating a choropleth map. The input data consists of three layers: a DEM covering a region larger than SC and two vector layers containing SC's boundary and all SC counties.\nThe results of the request are shown in Figure 8. The choropleth map generated by the agent clearly displays the average elevation values, with darker shades representing higher elevations. Also, the histogram generated by the agent illustrates the distribution of pixel values from the clipped DEM. Additionally, the geoprocessing workflow diagram illustrates the steps of the analysis."}, {"title": "4.2.2 Richland County terrain analysis", "content": "In this case, the agent was tasked with performing a detailed terrain analysis for Richland County, SC, by merging four DEM tiles obtained from the US Geological Survey (USGS) and Shuttle Radar Topography Mission (SRTM) dataset (USGS, 2024). The agent generated the geoprocessing workflow, showing the sequence of steps to complete the terrain analysis. The geoprocessing workflow began by merging the four individual DEMs to create an elevation model covering the area of interest. Once merged, the agent calculated multiple terrain characteristics, including slope, aspect, hillshade, Terrain Ruggedness Index (TRI), and Topographic Position Index (TPI). The outputs of each analysis step were visualized, with each terrain attribute displayed as a separate map (Figure 9)."}, {"title": "4.2.3 County-level obesity risk behavior index analysis", "content": "This task involves obesity risk behavior index analysis across all counties in the contiguous US. Two data layers \u2013 a shapefile containing the boundaries of all counties and a CSV file containing the rate of visits to different places such as convenience stores, limited-service restaurants, sport centers, fitness centers, and parks. The agent was able to join the attributes to the shapefile and was also able to select the fields needed for the analysis without any instruction from the user using the data understanding module. The resulting thematic map and the geoprocessing workflow generated by the agent is presented in Figure 10."}, {"title": "4.3 Advanced level tasks", "content": "In the advanced level, tasks are multistep, and the agent is expected to determine the appropriate steps independently, without explicit instructions, to devise the best approach for achieving the desired outcome. In other words, tasks are more natural in nature presenting the agent of \u201cwhat\u201d the users want with limited guidance on \u201chow\u201d to do it. The agent must select the right tools, generate the necessary code, and execute the entire process independently."}, {"title": "4.3.1 Fast-food accessibility and obesity correlation analysis for Pennsylvania Counties", "content": "This operation involves analyzing and visualizing the fast-food accessibility score for each county in Pennsylvania and performing a correlation analysis between the fast-food accessibility score and the prevalence of obesity. The agent's workflow began by calculating the fast-food accessibility score for each county based on the number of fast-food restaurants per capita. This was followed by generating a thematic map that displays counties with higher accessibility scores in darker shades of blue. Next, the agent analyzed the correlation between county-level obesity rates and fast-food accessibility scores. The results of this analysis are shown in Figure 11, where a scatter plot with a regression line highlights the relationship between fast-food accessibility and obesity rates across the state. The agent successfully managed the multistep process, calculating accessibility scores to perform correlation analysis, and visualizing the results in both a thematic map and a scatter plot. It should be noted that all the specific fields used in the analysis were automatically selected by the agent, demonstrating its ability to choose the appropriate fields needed for particular operation without explicit user guidance. Figure 11 shows the geoprocessing workflow diagram, illustrating each step of the analysis."}, {"title": "4.3.2 Spatial Distribution of COVID-19 Cases Across US Counties", "content": "This task asks, \"Could you show the spatial distribution of the COVID-19 cases across US counties? \". This request involves visualizing the spatial distribution of COVID-19 cases across US counties. The agent was provided with two datasets: shapefile of US county boundaries obtained from the United States Census Bureau (2024) and a CSV file containing COVID-19 data as of December 2020, obtained from the New York Times (2023). The analysis involved joining the attribute contained in the CSV data with the shapefile to create a thematic map that shows the COVID-19 cases across all the counties in the US. The agent successfully completed the task, automatically identifying the common fields, \"GEOID\" and \"FIPS\", for the spatial join operation. It also selected the \"cases\" field from the COVID-19 dataset to generate the thematic map. The geoprocessing workflow diagram generated by the agent and the resulting thematic map is shown in Figure 12. Counties with higher numbers of COVID-19 cases are represented by darker shades of blue on the map."}, {"title": "4.3.3 Generating the Normalized Difference Vegetation Index (NDVI) from satellite imageries", "content": "In this case, the agent was tasked with generating the Normalized Difference Vegetation Index (NDVI) for the city of Akure, Nigeria using multispectral satellite imagery. The request is \"Generate the Normalized Difference Vegetation Index (NDVI) of Akure from these satellite imageries\". The input data comprises a shapefile of the Akure boundary and Landsat 8 satellite products from the USGS, which includes multiple image bands. The agent demonstrated its capability by automatically identifying and selecting the correct bands, specifically the NIR and red bands, from the multispectral imagery. It then used these bands and applied the correct formula to generate the NDVI layer. The output was visualized as a raster map. The agent successfully managed the entire process, from band selection to calculation to ensure the correct bands were used and that the NDVI was calculated accurately (Figure 13). Note that the initial raster map generated by the agent used a black-and-white color ramp for symbology. The symbology was manually adjusted to enhance visualization in order to provide a clearer representation of the vegetation distribution in Akure, where areas of dense vegetation are represented by higher NDVI values, as shown in green, while shades of blue represent lower NDVI values. This example shows the agent's ability to handle satellite imagery data and perform key calculations with minimal user input."}, {"title": "4.4 Performance evaluation of the GIS Copilot", "content": "The performance of the GIS Copilot was assessed systematically across three levels of task complexity: basic, intermediate, and complex. Each level consisted of a set number of tasks, selected according to predefined criteria for task complexity (in Sections 4.1, 4.2 and 4.3). This structured approach ensured that the chosen tasks represented each complexity level to provide a balanced and meaningful evaluation framework. While definitions of complexity may vary, the selected tasks align closely with the GIS Copilot's intended functionality and scope.\nSuccess rates were recorded at each stage, tracking tasks completed on the first attempt as well as those required multiple attempts. Tasks that remained unsuccessful after three attempts were categorized as failures. The overall accuracy is determined by calculating the percentage of successful cases. As shown in Table 1, with 60 cases at the basic level (Appendix 3), the success rate recorded was 95%; among 30 intermediate-level tasks (Appendix 4), a success rate of 80% was observed, and for the advanced level, which included 20 cases (Appendix 5), the success rate was 75%."}, {"title": "5 Discussion", "content": "This study proposes a novel framework for integrating generative AI (LLMs) into established GIS platforms, using QGIS as a case study. Based on this framework, we implemented a Copilot which serves as an interface through which GIS users interact with the software with natural language commands. A key feature of this GIS Copilot is the extensive range of tools included, covering a broad spectrum of GIS analysis functions such as vector and raster analyses. This extensive toolkit enables the agent to efficiently handle various spatial analysis tasks within the QGIS environment. Additionally, the framework is designed to be extensible, enabling GIS users to further expand the toolbox by adding custom tool documentation that follows a predefined template. This extensibility ensures that the Copilot remains adaptable to user needs and the continuous development of new GIS tools and analyses. This work aligns with the increasing recognition of the potential for Al-driven systems to automate and streamline geoprocessing workflows. By automating these processes, the framework simplifies spatial analysis, making GIS functionalities more accessible to both expert and non-expert users.\nThis GIS Copilot responds to the previous work of Li and Ning (2023), who envisioned the need for a Copilot-style system in GIS environments to enhance automation and interaction with geospatial data. They demonstrated the potential for LLMs to autonomously generate geoprocessing workflows and emphasized the importance of integrating these capabilities directly into existing GIS software to unlock their full potential. By implementing a Copilot system within QGIS, this study addresses this challenge, illustrating how LLMs can be used to generate executable spatial analysis algorithms using existing well-developed GIS tools. A significant benefit of Copilot style integration with GIS platform is its role as a critical step toward realizing a fully autonomous GIS. Users have direct interaction with the agent directly within the GIS environment, allowing them to load and select datasets, visualize results and select between manual operations and agent-driven workflows based on their preferences. This flexibility enables users to combine traditional manual GIS processes with the efficiency of AI-driven analysis, resulting in a hybrid approach. For instance, users can load datasets into QGIS and perform analyses, generate results by the agent and further perform analyses using either the Copilot or manual methods.\nIn evaluating the performance of the GIS Copilot, we analyzed its performance across three levels of task complexity: basic, intermediate, and advanced level. At the basic level, tasks involved straightforward operations on one or two data layers, such as spatial buffering, calculating areas or filtering features based on attributes. The agent demonstrated high accuracy in selecting the appropriate tools and generating the necessary code. The reliability of the GIS Copilot at this level highlights its competence in automating foundational tasks with minimal intervention, offering an important utility for speeding up routine geospatial operations. At the intermediate level, the tasks require multistep which are described for the agent. Here, the GIS Copilot not only needed to correctly select tools but also generate and execute the code in sequence. In these scenarios, the agent showed strong performance in generating geoprocessing workflows based on the multistep task description and managing the dependencies between different steps. The success in these tasks suggests that the agent can effectively operate as an assistant to handle more involved geospatial workflows, thereby reducing the need for users to do step-by-step manual coding. The advanced level tasks involve the highest complexity, where the tasks are more natural in nature, presenting the agent of \u201cwhat\u201d the users want with limited guidance on \u201chow\u201d to do it. Here, the agent needs to understand and reason the question and determine the geoprocessing workflow autonomously. This required the GIS Copilot to interpret the natural language instructions, decide on an appropriate series of actions, select the correct tools, and execute the entire process without explicit guidance. While the agent showed promise at this level, especially in the tool selection and code generation, the success rate for these complex tasks was lower than simpler ones."}, {"title": "6 Limitations and Future Work", "content": "The GIS Copilot shows promising performance across the three levels of task complexities; however, certain issues were observed. These challenges point to potential areas for improvement and future research directions."}, {"title": "6.1 The need for a data validation module to reduce tool and parameter mismatch", "content": "The GIS Copilot shows potential in handling tasks of varying complexity, but issues like incorrect parameter assignment were observed, hindering its performance. For instance, the agent occasionally assigns vector data to parameters that require raster input. A good example"}]}