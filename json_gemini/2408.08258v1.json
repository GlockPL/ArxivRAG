{"title": "Snuffy: Efficient Whole Slide Image Classifier", "authors": ["Hossein Jafarinia", "Alireza Alipanah", "Danial Hamdi", "Saeed Razavi", "Nahal Mirzaie", "Mohammad Hossein Rohban"], "abstract": "Whole Slide Image (WSI) classification with multiple instance learning (MIL) in digital pathology faces significant computational challenges. Current methods mostly rely on extensive self-supervised learning (SSL) for satisfactory performance, requiring long training periods and considerable computational resources. At the same time, no pre-training affects performance due to domain shifts from natural images to WSIs. We introduce Snuffy architecture, a novel MIL-pooling method based on sparse transformers that mitigates performance loss with limited pre-training and enables continual few-shot pre-training as a competitive option. Our sparsity pattern is tailored for pathology and is theoretically proven to be a universal approximator with the tightest probabilistic sharp bound on the number of layers for sparse transformers, to date. We demonstrate Snuffy's effectiveness on CAMELYON16 and TCGA Lung cancer datasets, achieving superior WSI and patch-level accuracies. The code is available on https://github.com/jafarinia/snuffy.", "sections": [{"title": "1 Introduction", "content": "The emergence of whole slide images (WSIs) has presented significant opportunities to leverage machine learning techniques for essential tasks of cancer diagnosis and prognosis [27,29,34]. Nevertheless, integrating contemporary deep learning advancements into these areas faces notable challenges. Primarily, the sheer size of WSIs, with usual dimensions of approximately 150,000 \u00d7 150,000 pixels, renders them unmanageable for processing and training with existing deep learning frameworks on current hardware [30].\nA common strategy to address this challenge is to divide WSIs into smaller patches followed by the application of Multiple Instance Learning (MIL) [11,30, 35, 43, 46, 49]. MIL, a variant of weakly supervised learning, considers instances as elements of sets involving an embedding phase and a pooling operation (MIL-pooling). The embedding phase often employs a pre-trained vision backbone, frequently with a self-supervised learning technique applied on the patches, transforming these patches into embeddings. Subsequently, MIL-pooling aggregates these embeddings, deriving scores at both the patch and WSI levels [26].\nRecent advancements in WSI classification have achieved significant outcomes but face challenges like data-hungriness, high computational and memory requirements. These issues hinder the deployment and development of deep learning technologies in clinical and research settings. For example, RNN-MIL [6] and HIPT [8] require tens of terabytes of data, while DSMIL [31] and DGMIL [42] require several months for pre-training phases. DTFD-MIL [54] uses an efficient MIL-pooling strategy but demands over 100 gigabytes of system memory for training, which is only feasible in some settings. Conversely, the absence of pre-training or insufficient pre-training degrades performance because of the domain shift from natural image datasets such as ImageNet-1K to WSIS (CLAM [33] and KAT's [56] low AUC as shown in Fig. 1).\nThis work presents an approach that significantly reduces the computational demands required for training the embeddings by orders of magnitude. Then, empower its expressivity in a novel MIL-pooling to compensate for performance loss due to limited pre-training. Snuffy makes continual few-shot pre-training possible and a competitive option in this field by balancing efficiency and performance.\nOur framework comprises two key components. First, we propose using self-supervised continual pre-training with Parameter Efficient Fine Tuning (PEFT) in the pathology domain, specifically utilizing Adaptformer [9] due to its effective and straightforward design. While PEFT has been applied in various fields, its use in pathology imaging is novel. Our results indicate that transitioning from natural images to histopathology is feasible, allowing us to leverage PEFT methods effectively.\nSecond, inspired by the complex biology of cancer and the importance of the tissue microenvironment in cancer detection, we introduce the Snuffy MIL-pooling architecture, which features a new sparsity pattern for sparse transformers. We demonstrate that the Snuffy sparsity pattern acts as a universal approximator, with the number of layers constrained to a linear relationship"}, {"title": "2 Related Work", "content": "Parameter-Efficient Fine-Tuning for Vision Parameter-Efficient Fine-Tuning (PEFT), initially successful in NLP [24, 25], especially with Transformers [22, 24, 25, 40], has recently been applied to Vision Transformers (ViTs) for supervised tasks [9, 19, 47]. Techniques like Adapters [24] and LoRA [25] help mitigate overfitting during fine-tuning. The high computational demands for self-supervised pre-training, along with SSL pre-training benefits on domain-specific datasets [31], highlight PEFT's potential in SSL contexts. Recent studies [14,55] have proposed continual pre-training from general datasets like ImageNet-1K to domain-specific ones. Our study is the first to apply this approach specifically from ImageNet-1K to pathology datasets, advancing the field.\nMIL for WSI Classification The MIL-pooling operator must be permutation-invariant [26]. Traditional methods like Mean-pooling and Max-pooling have had some success, but parameterized strategies are more effective [26, 31]. Recent"}, {"title": "3 Background", "content": "For any positive integer a, we represent the set as [a] = {1,2, ..., a}. If we have a matrix A \u2208 Rdxn, we refer to its j-th column as Aj, and As denotes the submatrix comprising columns of A indexed by \u2286 [n]. The softmax operator \u03c3\u03b5[.] processes each column of a matrix, resulting in a column stochastic matrix. In terms of asymptotic behavior, f = O(g) implies that there exists a constant C > 0 such that f(n) < Cg(n) for all but finitely many n. Conversely, f = \u03a9(g) signifies that g = O(f). We use X to conceal poly-logarithmic factors of X, like 2(n).\nIn a binary classification problem, the dataset D = {(X1,Y1), ..., (Xn, Yn)} consists of bags X, where each bag X = {X1,...,Xk} contains instances x, and Y \u2208 {0, 1} represents the bag's label. The individual instance labels (y1,..., Yk} with with y \u2208 {0,1}, are unknown during training. This is modeled as:"}, {"title": "3.2 MIL Formulation", "content": "0,\n\\text{ iff } \\Sigma_i Y_i = 0\n1,\\text{ otherwise}.\n or equivalently: \nY = max{y_i}.\nTo address the complexities in learning, to navigate this, it is proposed to train the MIL model by optimizing the log-likelihood function: \nP(Y|X) = \\theta(X)^Y (1 \u2013 \\theta(X))^{1\u2212Y},\nwhere \u03b8(X) \u2208 [0, 1] is the probability of Y = 1 given X.\nGiven that MIL assumes no ordering or dependency of instances, \u03b8(X) must be a permutation-invariant (symmetric) function. This is achieved through the Fundamental Theorem of Symmetric Functions, with monomials [53] and a similar Theorem by [41] leading to: \n\\theta(X) = g(\\pi(f(x_1), ..., f(x_k))),\nwhere f and g are continuous transformations, and \u03c0 is a permutation-invariant function (MIL-pooling). There are two approaches, the instance-level approach where f is an instance classifier and g is identity function, and the embedding-level approach, where f is a feature extractor and g maps its input to a bag classification score. The embedding-based approach is preferred due to its superior performance [26].\nIn Deep MIL, f typically uses pre-trained vision backbones to extract features from bag instances [31,33, 42, 45,54,56]. The aggregation function ranges from non-parametric methods like max-pooling to parametric ones using attention mechanisms, as detailed in Section 2. Finally, g is often implemented as a linear layer with \u03c3 to project aggregated instance representations into a bag score.\nFor multiclass classification, g's output dimension is adjusted to the number of classes, and the softmax function is used instead of \u03c3 to distribute probabilities across classes."}, {"title": "3.3 Sparse Transformers", "content": "In the full-attention mechanism, each attention head considers interactions between every patch in an image. This requires significant memory and computational resources, with complexity scaling quadratically with the number of patches. However, in a sparse attention mechanism, each attention head only attends to a particular subset of patches instead of the entire set of patches. Drawing upon the formalism presented in [50], the ith sparse attention head output for a patch k in the layer l is articulated as follows: \nSHead^{i,l}(X)_k = W_A (\\sigma(\\frac{(W_Q X_k)^T W_K A_l}{\\sqrt{d}}) ) W_V A_l."}, {"title": "4 Method", "content": "To avoid extensive training on large domain-specific datasets, we propose using continual few-shot self-supervised pre-training with AdaptFormer [9] on ViTs pre-trained on ImageNet-1K [55]."}, {"title": "4.1 Continual Few-shot Efficient Self-Supervised Pre-training", "content": "Informed by the prerequisites outlined for sparse transformers, pathologists' behavior, and drawing inspiration from DSMIL [31], our Sparse Transformer architecture in MIL-pooling constitutes two main components: Max-pooling component and Attention-pooling (see Fig 2a). Further, we provide detailed descriptions of each component."}, {"title": "5 Universal Approximation of Snuffy", "content": "In this section, we demonstrate that our sparse transformer serves as a universal approximator for sequence-to-sequence functions. By applying Theorem 1 and validating the Snuffy sparsity patterns defined in Definition 1, we confirm that our transformer, utilizing softmax as the probability map, satisfies all conditions given in the theorem. Furthermore, we illustrate that our transformer does not necessitate \u0398(n2) layers, as previously suggested in studies [52]. Instead, it requires only O(nlog2) layers to ensure universal approximation with high probability, achieving the most stringent probabilistic limit of the layer count to our knowledge.\nSnuffy sparsity patterns unquestionably satisfy the criteria 1 and 3 outlined in Theorem 1. The first condition is fulfilled through the inclusion of k \u2208 A, as defined in Definition 1. Moreover, the presence of at least one global attention patch within the patterns ensures connectivity among all patches, with a maximum path length of 2, thus meeting condition 3.\nTo satisfy the criterion 2, we must demonstrate the existence of a Hamiltonian path in the graph corresponding to the union of patterns in the Snuffy sparsity patterns. Initially, we introduce Proposition 1 from graph theory to facilitate the proof. We employ the proposition and demonstrate that covering half of the patches in all layers, overall satisfies its properties. This leads to the formation of a Hamiltonian path, thus fulfilling the desired proof.\nProposition 1. Every graph G(E,V) with E and V as the set of edges and nodes, with |V|\u2265 3 and \u03b1(G) \u2264 \u03c7(G) has a Hamiltonian cycle. Where \u03b1(G) is the maximum independent set, and \u03c7(G) is the chromatic number of G.\nLemma 1. For Gs, the graph representing Snuffy sparsity patterns, we guarantee that there exists a Hamiltonian path if\n|U A^l| > \\frac{n-1}{2}.\nl\u2208[L]"}, {"title": "8 Conclusion and Discussion", "content": "We introduced a novel WSI classification framework using PEFT for data efficiency in SSL and a sparse transformer inspired by pathologists. This approach ensures global approximation with high probability and provides a tighter bound for the number of layers in sparse transformers for MIL-pooling, achieving excellent results. However, achieving SOTA results still requires long and exhaustive SSL training. Our Theoretical guarantees need a high number of layers, increas-"}]}