{"title": "CharacterBox: Evaluating the Role-Playing Capabilities of LLMs in Text-Based Virtual Worlds", "authors": ["Lei Wang", "Jianxun Lian", "Yi Huang", "Yanqi Dai", "Haoxuan Li", "Xu Chen", "Xing Xie", "Ji-Rong Wen"], "abstract": "Role-playing is a crucial capability of Large Language Models (LLMs), enabling a wide range of practical applications, including intelligent non-player characters, digital twins, and emotional companions. Evaluating this capability in LLMs is challenging due to the complex dynamics involved in role-playing, such as maintaining character fidelity throughout a storyline and navigating open-ended narratives without a definitive ground truth. Current evaluation methods, which primarily focus on question-answering or conversational snapshots, fall short of adequately capturing the nuanced character traits and behaviors essential for authentic role-playing. In this paper, we propose CharacterBox, which is a simulation sandbox designed to generate situational fine-grained character behavior trajectories. These behavior trajectories enable a more comprehensive and in-depth evaluation of role-playing capabilities. CharacterBox consists of two main components: the character agent and the narrator agent. The character agent, grounded in psychological and behavioral science, exhibits human-like behaviors, while the narrator agent coordinates interactions between character agents and environmental changes. Additionally, we introduce two trajectory-based methods that leverage CharacterBox to enhance LLM performance. To reduce costs and facilitate the adoption of CharacterBox by public communities, we fine-tune two smaller models, CharacterNR and CharacterRM, as substitutes for GPT API calls, and demonstrate their competitive performance compared to advanced GPT APIs.", "sections": [{"title": "Introduction", "content": "Role-playing is an advanced capability of large language models (LLMs) that allows them to mimic human-like behavior within the context of specific roles. This functionality underpins various practical applications, such as intelligent non-player characters (NPCs) in video games, digital replicas for personal assistants, and emotional support in mental healthcare. While there are comprehensive benchmarks for evaluating the general-purpose abilities of LLMs, including language understanding, conversation, and reasoning, the assessment of role-playing capabilities remains an area that is not as thoroughly explored. Current evaluation methods, such as static self-reporting questionnaires and simple dialogue tasks, fail to capture the full complexity of role-specific behaviors in real-life scenarios. These methods are limited by their static nature and inability to reflect continuous role-playing interactions. In reality, a character's actions, attitudes, and emotions are dynamic and evolve in response to the surrounding environment and other individuals. The proverb \"A man is judged by his deeds, not by his words\" applies here: an LLM's true role-playing ability cannot be fully understood from static dialogues or self-reports alone, but rather is demonstrated during interaction with its environment.\nIn this paper, we present CharacterBox, a dynamic, multi-agent virtual world tailor-made for eliciting nuanced human-like behaviors from LLMs in the context of role-playing evaluations. CharacterBox crafts immersive scenarios tailored to specific roles, incorporating detailed role specifications, contextual backgrounds, and interactions that mirror real-world complexity. LLMs are assigned roles and interact with both the environment and other characters through dialogue and actions that reflect their role-specific traits. A comparison between previous methods and CharacterBox is presented in Fig 1.\nTo track the evolving states of both characters"}, {"title": "Related Work", "content": "Evaluating the role-playing capabilities of LLMs is essential yet challenging, leading researchers to propose various benchmarks . RoleBench offers a role-granular dataset with extensive role dialogues for evaluation. CharacterEval uses dialogues from 77 characters in Chinese scripts, with 14 evaluation metrics and a reward model. InCharacter tests role fidelity by converting psychological scales into interview formats. RoleInteract evaluates RPAs in individual and group interactions, assessing social behaviors based on the roles. However, these benchmarks focus on static dialogues or QA interactions, while CharacterBox expands the evaluation to dynamic scenarios, including specific actions."}, {"title": "LLM-based virtual environment", "content": "Based on extensive training data, LLMs possess logical reasoning abilities and vast knowledge, making it possible to construct virtual environments based on LLMs. GenerativeAgent manually designs a virtual town, allowing LLM-based agents to play different roles to simulate human life in the town and interact with other agents. RecAgent built a virtual recommendation platform, where agents as users can browse recommended movies and chat and post on social platforms. UGI constructed a city simulation platform based on the real world, where agents can engage in social interactions, street navigation, and other urban behaviors. However, these LLM-based virtual environments are time-consuming to meticulously design and pre-define, cannot be dynamically updated, and are difficult to create in large quantities. Our framework, CharacterBox, can dynamically update the environment according to the agents' behaviors within it and can extract or create new scenes based on a given context."}, {"title": "Evaluation Framework based on Text-based Interactive Virtual World", "content": "In this section, we present an in-depth exploration of the interactive evaluation framework, CharacterBox. The CharacterBox workflow is structured around three pivotal phases: scene crafting, autonomous story play, and evaluation."}, {"title": "Scene Crafting", "content": "Scenes form the foundation of our evaluation framework. A scene, represented as $S$, includes environmental and character elements. Environmental aspects cover time, location, and descriptions that influence character behavior. Character information includes profiles like names, roles, physical and psychological states. Formally, a scene with n characters is: $S = \\{E, C\\}$, where $E$ is the environment and $C = \\{C_1, C_2, ..., C_n\\}$ are the characters.\nWhen LLMs engage in role-playing using scenes drawn from novels or scripts, there is a risk of replicating content already present in their training data. To address this, the generation of original scenes becomes necessary, but also more challenging. To ensure high-quality scene creation, we divided the development process into three stages, assigning LLMs the roles of screenwriter, director, and evaluator . As screenwriters, LLMs extract or generate scenes that align with the story's logic. As directors, they refine these scenes by focusing on key elements like events, character details, and interactions to maintain coherence and engagement. Finally, as evaluators, LLMs assess the scenes based on creativity, coherence, conformity, and detail, accepting only those that meet quality standards. These curated scenes initiate CharacterBox, providing a dynamic stage for interactive role play."}, {"title": "Autonomous Story Play", "content": "Following the scene crafting phase, the environment $E$ serves as the stage and the characters $C$ as the actors in the autonomous story play. Moreover, we design the narrator NR as a world model to analyze the characters' actions and update both the environment and character states in real time. In this way, the scene transforms from a static setting into a dynamic virtual world that evolves as the story progresses.\nEnvironment. The environment includes time, location, and descriptions, which are dynamically influenced by character actions. The narrator updates these elements in real-time.\nCharacter. Characters, controlled by LLMs, use a memory module inspired by , where each agent utilizes a vector database to record past actions and observations, retrieving relevant information to guide future behavior. Each character maintains self-beliefs and environment-beliefs following the Belief-Desire-Intention (BDI) model. Self-beliefs include identity, self-awareness, and goals, while environment-beliefs represent the character's understanding of the surroundings and other agents.\nDuring story play, characters take turns planning and executing their actions at the start of each round, drawing on memory and the BDI model, as inspired by prior work. Actions are expressed in detailed descriptions, and characters can respond immediately to others. After each round, both self-beliefs and environment-beliefs are updated accordingly.\nNarrator. The narrator serves as an objective world model, responsible for accurately analyzing the development of characters and the environment within CharacterBox. As the core of the framework, the narrator performs the following functions:\n* Analyze Action Influence: When a character $C_i$ takes an action, the narrator assesses its impact on other characters by considering their current states. The narrator identifies the character $c_r$ most affected and likely to respond to $c_i$. The action $a_i$ and resulting influence $f_r$ are conveyed to $c_r$.\n* Analyze Interaction Result: The narrator determines the outcome of the interaction between $c_i$ and $c_r$, represented by R. This outcome is used to update both characters' memories, physical positions, and psychological states.\n* Update Character: The narrator updates each character's state based on their own action or the result of interactions. If no other character responds to $c_i$, $C_i$'s state is updated based on its own action.\n* Update Environment: After each round, the narrator updates the environment E based on the characters' actions and their outcomes. If no actions affect the environment, it remains unchanged."}, {"title": "Evaluation", "content": "Through autonomous story play, we obtain a series of actions from each character in different contexts, forming a trajectory formally represented as $\\mathcal{T} = \\{E, C, a_1, o_1, a_2, o_2, ..., a_n, o_n\\}$, where each character's actions and observations are captured in relation to the environment and character information. To comprehensively evaluate the role-playing capabilities of LLMs in long-term dynamic environments, we design metrics across three main dimensions, drawing inspiration from key aspects of effective role-playing :\nCharacter Fidelity assesses how accurately the model represents the character's knowledge and behaviors. This is crucial for maintaining consistency with the character's identity:\n* Knowledge Accuracy (KA): Ensures information provided by character is factually correct and aligned with their background knowledge.\n* Behavioral Accuracy (BA): Measures the consistency of character's behaviors and linguistic patterns, ensuring alignment with their traits.\nHuman-Likeness evaluates the realism and believability of the character's portrayal, focusing on dynamic, emotionally engaging interactions:"}, {"title": "Emotional Expression (EE)", "content": "Evaluates the ability of the character to express emotions vividly, key to enhancing user immersion."}, {"title": "Personality Traits (PT)", "content": "Determines whether the model consistently maintains the character's core personality traits throughout interactions."}, {"title": "Consistency", "content": "focuses on maintaining logical continuity in the character's behavior across interactions, which is essential for immersive role-playing:"}, {"title": "Immersion (IM)", "content": "Measures the character's ability to stay in role, ensuring a continuous and believable experience for the user."}, {"title": "Adaptability (AD)", "content": "Assesses how the character adjusts to evolving situations while maintaining their integrity."}, {"title": "Behavioral Coherence (BC)", "content": "Evaluates the logical consistency of character's actions in relation to previous behaviors and current context.\nEach metric is scored from 1 to 5, with higher scores indicating stronger performance. To enhance evaluation accuracy, we leverage GPT-4 to first generate a critique of the character's trajectory, integrating this critique into the prompt before assessing each criterion. These metrics collectively ensure that the role-playing agents are not only accurate and engaging but also capable of sustaining character fidelity over extended interactions, which is crucial for immersive narrative experiences."}, {"title": "Enhancing Role-playing Ability with Trajectories", "content": "CharacterBox facilitates the efficient generation of character trajectories across diverse scenes, providing valuable insights into character reactions and behaviors within varied contexts. These trajectories offer a unique opportunity to enhance the role-playing capabilities of language models. To leverage this data, we propose two distinct methods for fine-tuning LLMs using generated trajectories:\nGuided Trajectory Fine-tuning. We first assess the role-playing capabilities of LLMs using CharacterBox, selecting high-performing models as teachers. The trajectories generated by these models are then used to fine-tune student models, resulting in significant improvements in the latter's ability to simulate complex character interactions.\nReflective Trajectory Fine-tuning. In this approach, we explore the self-reflective capabilities of LLMs. Models analyze their own generated trajectories, identifying inconsistencies and areas for improvement in character portrayal. The models then rewrite these trajectories to enhance character consistency and depth. These revised trajectories are subsequently used for fine-tuning, further strengthening the model's capacity to simulate realistic and nuanced interactions."}, {"title": "Building for a Self-contained Evaluation Workflow", "content": "In CharacterBox, the narrator agent and evaluation agent can be powered by advanced language models like GPT-4 or individuals familiar with the characters. However, these methods are costly and lack scalability. To address this, we develop CharacterNR and CharacterRM to reduce costs and enhance scalability.\nCharacterNR. CharacterNR acts as the narrator within CharacterBox. Initially, GPT-3.5 is used to generate narrator trajectory data due to its strong instruction-following abilities. To handle both Chinese and English scenes, we select Qwen2.5-7B as the base model and fine-tune it using LoRA with data generated by GPT-3.5.\nCharacter RM. We collect evaluation scores from GPT-4 across 100 scenes, incorporating outputs from nine different LLMs to ensure diversity. To maintain fairness in scoring, we select ChatGLM3-6B as the base model, since it is not among the evaluated models. We then fine-tune it using LoRA on the collected data, resulting in CharacterRM."}, {"title": "Experiment", "content": "* Scene. We select 10 well-known novels and scripts as scene sources, covering a range of settings and themes (see Appendix A.1 for details). Five works are in Chinese and five in English, with evaluations conducted in both language settings. Each scene includes specific environment and character information, with 2 to 4 characters per scene (see Appendix A.2 for further details).\n* LLM. We evaluate the role-playing ability of nine LLMs varying in model size. For closed-source models, we use GPT-4-Turbo-1106-preview as GPT-4  and GPT-3.5-Turbo-1106 as GPT-3.5 . For open-source models, we evaluate Baichuan2-7B/13B, Qwen2.5-7B/14B , Mistral-7B-v0.2, Llama3-8B"}, {"title": "Overall Performance", "content": "We select five existing and five new scenes for each novel or script, resulting in 50 English and 50 Chinese scenes. Each LLM's performance is assessed by evaluating the behavior trajectories of characters in each scene, with the average score representing the LLM's performance for that scene. The overall score for each LLM is then calculated by averaging scores across all 50 scenes.\nTable 1 presents the results across seven metrics for both English and Chinese scenes. GPT-4 performs the best across both English and Chinese scenes. GPT-3.5 shows strong performance in English scenes but falls behind Qwen2.5 models, especially Qwen2.5-14B, in Chinese scenes. The latter surpasses GPT-3.5 in multiple metrics and approaches GPT-4's competitiveness. Qwen2.5 and Baichuan2 models, due to their large-scale training on Chinese corpora, demonstrate a clear advantage in Chinese scenarios. In contrast, models like Mistral-7B-v0.2 and Llama3-8B perform better in English scenes but are relatively weaker in Chinese. Overall, bilingual models, especially Qwen2.5 and Baichuan2, show stronger role-playing capabilities in Chinese scenes, highlighting the impact of language-specific training on role-playing abilities."}, {"title": "Reliability and Validity of CharacterBox", "content": "Reliability. We measure reliability of CharacterBox using Cronbach's alpha to assess internal consistency , following prior works . As shown in Table 2, CharacterBox achieves high Cronbach's alpha values across three evaluation dimensions in both English and Chinese scenes. The consistently high scores, with most above 0.9, indicate that CharacterBox provides a reliable evaluation of LLMs' role-playing capabilities across different scenarios."}, {"title": "Role-playing Ability of Trajectory Enhanced LLM", "content": "We fine-tune Qwen2.5-7B and Qwen2.5-14B models using LoRA, applying two strategies: Guided and Reflective Trajectory fine-tuning. The performance of the fine-tuned models is evaluated on five newly generated English scenes and five Chinese scenes, which were not part of the training data.\nGuided Trajectory Fine-tuning. In this method, Qwen2.5-7B is fine-tuned with high-quality trajectories from CharacterBox. These trajectories are selected from the top-performing models across both languages in Table 1. As shown in Fig 2(a), Guided-Qwen improves by 14.3% overall in English scenes and 10.7% in Chinese scenes. In some categories such as EE and AD, the Guided-LLM outperforms GPT-3.5, demonstrating the effectiveness of using high-quality trajectories to enhance LLM's role-playing capability.\nReflective Trajectory Fine-tuning. For the reflective approach, we utilize Qwen2.5-14B, leveraging its capacity to handle the complexity of iterative improvements. The model is fine-tuned with rewritten trajectories, allowing it to reflect on its initial outputs and generate refined responses. As illustrated in Fig 2(b), Reflective-Qwen improves by 19.9% in English scenes and 12.8% in Chinese scenes, outperforming the base model across all metrics. Notably, Reflective-Qwen also achieves greater gains than Guided-Qwen, suggesting that the reflective process enables the model to generate more contextually nuanced and refined responses, leading to more believable role-playing performance."}, {"title": "Analysis of Evaluation Stages", "content": "* Three-Stage Scene Crafting.\nWhile powerful models like GPT-3.5 and GPT-4 excel at scene crafting, their high cost limits large-scale use. To address this, we implement a three-stage scene crafting approach using smaller open-source models. Our method had the LLM extract and generate scenes from 10 scripts, evaluating the results from four aspects. As shown in Table 4, GPT-4 excels at extracting scenes but has no advantage in generating new ones. In contrast, our three-stage method based on ChatGLM3-6B improves upon its baseline and outperforms GPT-3.5 and GPT-4 in both tasks. This demonstrates that small open-source LLMs can replace closed-source models in scene crafting, reducing costs significantly.\n* CharacterNR. To evaluate the effectiveness and generalization of our local CharacterNR, we generate five new Chinese and five new English scenes not included in the fine-tuning data. We assess the narrator's performance based on the Gricean Maxims : Quality, which reflects the accuracy and reasonableness of the results; Quantity, ensuring the information is substantial but not redundant; Relevance, which measures how pertinent the results are to the task;"}, {"title": "CharacterRM", "content": "CharacterRM serves as the reward model for evaluating and scoring character trajectories. We select ChatGLM3-6B as the base model, fine-tuning it with GPT-4-generated evaluation results as labels. Similar to Section 6.3, we validate CharacterRM by scoring new Chinese and English scenes outside the fine-tuning data and comparing the results with human expert evaluations. As shown in Table 3, CharacterRM outperforms ChatGLM3-6B in all metrics and achieves an overall correlation of 0.610, close to GPT-4's 0.688, demonstrating its reliability and strong alignment with human evaluations."}, {"title": "Conclusion", "content": "In this paper, we introduce CharacterBox, a dynamic, text-based virtual environment specifically designed to evaluate the role-playing capabilities of LLMs. By creating immersive scenarios that reflect the complexities of real-world interactions, CharacterBox captures nuanced human-like behaviors in LLMs, going beyond static evaluation methods. We demonstrate that fine-tuning smaller models with high-quality behavior trajectories significantly enhances their role-playing abilities. Additionally, we develope two fine-tuned components, CharacterNR and CharacterRM, allowing for a cost-efficient and self-sustained evaluation process without relying on expensive API calls. These contributions establish CharacterBox as a powerful and self-contained tool for assessing and improving LLM role-playing performance across diverse scenarios."}, {"title": "Limitation", "content": "While the CharacterBox framework offers an innovative and comprehensive approach to evaluating the role-playing capabilities of LLMs, several limitations remain: First, the runtime efficiency needs to be improved to accommodate large-scale evaluation scenarios. Second, additional human-annotated data is required to better train the reward model, ensuring more accurate evaluations. Finally, the limited context window of LLMs presents a challenge in interactive role-playing, as prompts cannot encompass all necessary information. Addressing this issue will require the development or adoption of long-context LLMs to effectively support comprehensive evaluations."}, {"title": "Applicability to Average Character in Diverse Scene", "content": "The DISC model is a psychological theory that categorizes human behavior into four types: dominance, influence, steadiness, and compliance. Dominance involves leadership and risk-taking. Influence is characterized by optimism and persuasiveness. Steadiness involves patience and supportiveness. Compliance is marked by analytical skills and precision.\nTo test our framework's applicability to diverse scenes, we created a challenging environment with characters of the four DISC types and observed their reactions. As shown in Fig 5, each character maintained their behavioral patterns in response to a sudden weather change. The dominance character led the team. The influence character boosted team confidence. The steadiness character focused on safety. The compliance character assessed risks and assisted in decision-making. This demonstrates that CharacterBox can evaluate role-playing fidelity for both famous and average characters, highlighting its potential for psychological experiments."}, {"title": "Detailed Prompt", "content": ""}, {"title": "Narrator Prompts", "content": "Action Influence: Analyzing and describe a character's specific physical action and its tangible impact on another character."}]}