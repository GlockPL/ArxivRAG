{"title": "H-FLTN: A Privacy-Preserving Hierarchical Framework for Electric Vehicle Spatio-Temporal Charge Prediction", "authors": ["Robert Marlin", "Raja Jurdak", "Alsharif Abuadbbat"], "abstract": "The widespread adoption of Electric Vehicles (EVs) poses critical challenges for energy providers, particularly in predicting charging time (temporal prediction), ensuring user privacy, and managing resources efficiently in mobility-driven networks. This paper introduces the Hierarchical Federated Learning Transformer Network (H-FLTN) framework to address these challenges. H-FLTN employs a three-tier hierarchical architecture comprising EVs, community Distributed Energy Resource Management Systems (DERMS), and the Energy Provider Data Centre (EPDC) to enable accurate spatio-temporal predictions of EV charging needs while preserving privacy. Temporal prediction is enhanced using Transformer-based learning, capturing complex dependencies in charging behavior. Privacy is ensured through Secure Aggregation, Additive Secret Sharing, and Peer-to-Peer (P2P) Sharing with Augmentation, which allow only secret shares of model weights to be exchanged while securing all transmissions. To improve training efficiency and resource management, H-FLTN integrates Dynamic Client Capping Mechanism (DCCM) and Client Rotation Management (CRM), ensuring that training remains both computationally and temporally efficient as the number of participating EVs increases. DCCM optimises client participation by limiting excessive computational loads, while CRM balances training contributions across epochs, preventing imbalanced participation. Our simulation results based on large-scale empirical vehicle mobility data reveal that DCCM and CRM reduce the training time complexity with increasing EVs from linear to constant. By mitigating key FL challenges including data heterogeneity, computational overhead, and bias H-FLTN provides a secure, resource-efficient solution for predicting EV charging behavior. Its integration into real-world smart city infrastructure enhances energy demand forecasting, resource allocation, and grid stability, ensuring reliability and sustainability in future mobility ecosystems.", "sections": [{"title": "1 INTRODUCTION", "content": "Global adoption of electric vehicles (EVs) has brought about significant changes in transportation systems and energy infrastructure, including demands and generation, with the promise of reduced greenhouse gas emissions and enhanced sustainability. However, this shift also poses significant challenges for energy providers, particularly in predicting and managing the spatial and temporal demand for EV charging. Addressing these challenges requires efficient re-source management, and privacy-preserving solutions that can handle the dynamic and heterogeneous nature of EV mobility data, particularly the non-IID distributions of data generated by diverse EV usage patterns in smart city en-vironments. One promising approach to addressing these complexities is Machine Learning (ML) using Federated Learning (FL), which enables distributed learning across decentralised systems while preserving data privacy.\nOur earlier work in FL for EV charging concentrated on location prediction [1], leaving the question of whether our model could be modified to predict an EV's next charging time alongside location. This study explores a Transformer-based approach for dual-task predictions of both the location and time of the next EV charging event. The Transformer model is particularly well-suited for time prediction due to its ability to capture long-range depen-dencies through self-attention mechanisms. Unlike Convo-lutional Neural Networks (CNNs), which focus on spatial feature extraction, and Long Short-Term Memory (LSTM) networks, which process data sequentially with recurrent dependencies, Transformers capture entire sequences in parallel, enabling more efficient modeling of temporal pat-terns. This parallelism enables the model to learn complex temporal relationships more effectively, reducing the risk of vanishing gradients and preserving information over extended time horizons. By leveraging self-attention, the Transformer model dynamically weighs the importance of past time steps, making it highly effective for predicting fu-ture EV charging times in dynamic mobility environments. This solution evaluates continuous temporal predictions, addressing limitations in prior frameworks that primarily focused on categorical spatial outputs, such as discrete location classifications.\nWhile FL enables privacy-preserving learning in decen-tralised EV networks, it faces scalability and bias chal-lenges [2]. Another study highlights that as client num-bers grow, FL systems experience increased computational overhead, training latency, and resource consumption [3]. The proposed Hierarchical Federated Learning Transformer"}, {"title": "2 RELATED WORK", "content": "FL enables distributed model training while maintaining data privacy by avoiding direct data sharing. H-FL ex-tends this concept by introducing multi-level aggregation, improving scalability and adaptability in dynamic environ-ments like EV networks [5], and [6]. Despite these advance-ments, challenges persist in scaleable resource manage-ment, ensuring privacy, and mitigating adversarial attacks in large-scale, real-world systems.\nSeveral studies have proposed techniques to address these challenges. Lalitha et al. [7] introduced P2P sharing as a decentralised collaboration mechanism, and Shamir et al. [8] proposed Additive Secret Sharing to enhance privacy during model updates. Bonawitz et al. [9] demon-strated the use of Secure Aggregation to protect individual contributions during weight aggregation, while McMahan et al. [10] explored strategies to balance client participa-tion and ensure fairness in decentralised systems. While effective, these methods often address specific challenges in isolation. The proposed H-FLTN framework builds on and integrates approaches to create a unified architecture for privacy-preserving, accurate spatio-temporal prediction, and optimally managed resource allocation in mobility-driven environments."}, {"title": "2.1 Modeling Approaches for Spatio-Temporal Predictions", "content": "Various machine learning models have been explored for spatio-temporal prediction tasks. Yan et al. [11] highlighted BiLSTM's strengths in capturing sequential dependencies but noted its limitations in computational efficiency and scalability. Marlin et al. [12] showed that CNNs effectively capture spatial dependencies but struggle with variable input dimensions and computational overhead.\nTransformer models, with their multi-head attention mechanisms, have emerged as a superior choice for spatio-temporal prediction [13]. By attending to both spatial and temporal dependencies, Transformers capture complex rela-tionships in EV mobility data, such as location and charging time interactions. Marlin et al. [1] demonstrated that Trans-formers outperformed BiLSTM and CNN architectures in predicting EV charging locations across datasets of varying sizes.\nThis study extends prior work by introducing a dual-task framework for predicting both the time and location of the next EV charging event. Unlike approaches focused solely on categorical outputs (EV next charge location) [1], this method leverages Mean Squared Error (MSE) for con-tinuous temporal predictions, improving precision. By ad-dressing key challenges in modeling dynamic mobility pat-terns, this study provides energy providers with actionable insights into both spatial and temporal energy demands."}, {"title": "2.2 Hierarchical Federated Learning (H-FL)", "content": "H-FL extends traditional FL by introducing hierarchical layers for multi-level aggregation, enabling scalability and adaptability in heterogeneous data environments. Li et al. [3] demonstrated H-FL's potential for managing data het-erogeneity, while Yang et al. [5] and Liu et al. [6] showcased its effectiveness in dynamic real-world scenarios. To address challenges in privacy researchers have proposed techniques such as P2P Sharing and Augmentation and Secure Ag-gregation. The H-FLTN framework builds on these foun-dations, integrating privacy-preserving mechanisms and ef-ficient resource allocation strategies to enhance utility for spatio-temporal prediction tasks in EV networks.\nDespite H-FL's scalability, ensuring efficient client par-ticipation while managing resource and time constraints remains an open challenge. Existing works [2], [14] explore FL optimisation but largely overlook computational load balancing in hierarchical settings. While H-FL distributes computation and communication load, optimising client selection for balanced compute expenditure and training efficiency remains critical for scalability.\nTo address this, H-FLTN introduces Dynamic Client Capping Mechanism (DCCM) and Client Rotation Man-agement (CRM), extending prior work on client selection [15]. DCCM dynamically regulates participation, reducing compute usage and training delays 5, while CRM ensures systematic client rotation, mitigating selection bias and en-abling diverse client participation. By splitting training into smaller, more efficient allocations, these mechanisms accel-erate convergence, improving accuracy in fewer iterations while lowering compute expense."}, {"title": "2.3 Integration of Privacy and Efficient Resource Management Techniques", "content": "The H-FLTN framework integrates multiple privacy-preserving techniques within a hierarchical structure to en-sure data confidentiality. P2P Sharing, proposed by Lalitha et al. [7], enables decentralised collaboration among EVs while maintaining privacy. Additive Secret Sharing [8] en-sures model updates remain confidential, while Secure Ag-gregation [9] prevents adversaries from reconstructing indi-vidual EV contributions. TLS 1.3 and MeLSeC further secure communication channels, mitigating risks of interception or unauthorised access.\nThe combination of DCCM (client capping) and CRM (client rotation) enhances resource management and ad-dresses participation bias. Unlike the single-level sampling strategies of McMahan et al. [10], DCCM improves training efficiency in hierarchical systems by selectively engaging a subset of clients per round, reducing training overhead, shortening epoch durations 5, and accelerating convergence. Wang et al. [16] explored adaptive client selection to optimise resource utilisation in FL, highlighting the need to balance computational constraints with model accuracy. Ex-panding on this, DCCM dynamically adjusts participation for efficient training without compromising performance. When combined with CRM, it maintains balanced participa-tion across training rounds, preventing selection bias while preserving learning quality."}, {"title": "3 PROBLEM DEFINITION", "content": "Predicting the next charging location and time for EVs is a critical challenge for managing energy demand in dynamic EV networks. This paper focuses on time prediction, which is novel in our work, while also addressing location pre-diction, which remains crucial for efficient energy manage-ment. Additionally, safeguarding user privacy is an integral aspect of this problem, as sensitive EV data is vulnerable to various types of attacks in decentralised networks as discussed in studies by Chen et al. [17] and Khowaja et al. [18]. Accurate spatio-temporal predictions, combined with robust privacy mechanisms, enable energy providers to optimise charging infrastructure, manage peak demand periods, and balance energy loads across regions.\nTraditional centralised approaches to predictive mod-elling struggle with the complexity of EV networks due to the following limitations:\nScalability Challenges: Large-scale EV network solu-tions must address issues such as high communication costs, varying client availability, and computational load imbalances. DCCM and CRM mitigate these by dynamically managing client participation, reducing unnecessary computation, and ensuring balanced train-ing across rounds.\nPrivacy Risks: Transferring sensitive EV data to cen-tral servers increases the risk of data breaches, raising significant privacy concerns.\nDynamic and Heterogeneous Data: EV mobility pat-terns exhibit high variability due to differences in user behaviour, and regional charging infrastructure. This heterogeneity extends beyond spatiotemporal mobility data to include variations in charging frequency, energy consumption patterns, and EV types, all of which com-plicate predictive modelling.\nThreat Model and Security Considerations: FL in decentralised EV networks introduces privacy and se-curity risks due to the distributed nature of data and model updates. Our threat model assumes an honest-but-curious adversary attempting to extract informa-tion from shared updates. The primary security concern in this study is ensuring that model updates remain confidential and are not linkable to specific EV clients.\nPrivacy-Preserving Mechanisms: To protect client con-fidentiality, the H-FLTN framework employs the fol-lowing mitigation strategies:\na) Non-transitory EVs: P2P Sharing and Augmentation for Secret Shares disperses each update among 2-10 peers when available. If fewer than two peers are available, the EV sends its encrypted secret shares directly to the DERMS instead. This decentralised approach ensures that no single EV's raw model update can be reconstructed, maintaining data con-fidentiality.\nb) Transitory EVs: These EVs submit their secret shares directly to the community DERMS. Secure Aggre-gation ensures that individual contributions remain private and cannot be traced back to a specific EV, reinforcing confidentiality.\nOutlier Mitigation: The community DERMS applies normalisation to aggregated weights, reducing the in-fluence of extreme values. While this helps smooth anomalies, it does not fully eliminate adversarial in-fluence. However, in combination with secure aggre-gation, normalisation reduces the impact of outlier up-dates before they contribute to the final model update.\nWhile privacy threats such as inference and data link-age attacks are the primary focus of this study, securing model integrity against other known attacks is left for future work.\nBy focusing on these core threats, our H-FLTN enhances privacy and security while maintaining the efficiency of model training in EV networks.\nThese vulnerabilities highlight the need for robust privacy-preserving methods, particularly in the context of distributed prediction tasks. Addressing these risks is essen-tial to ensuring user trust while maintaining accurate and efficiently managed predictions of both location and time."}, {"title": "4 MATHEMATICAL FRAMEWORK", "content": "This section presents the formalisation of our H-FLTN, de-tailing the mathematical constructs governing local model training, P2P Sharing and Augmentation with Additive Secret Sharing, Secure Aggregation, DCCM & CRM, and Prediction Transmission to EPDC. The formulation ensures privacy-preserving, resource-scalable, and efficient model updates in decentralised EV networks. Unix timestamp fea-tures are used as inputs to predict the next EV charging time, enabling the model to process time as a continuous variable rather than classifying it into categories. This enables the model to capture fine-grained temporal patterns, allowing the model to achieve accurate charge-time predictions."}, {"title": "4.1 Local Model Training and P2P Sharing with Additive Secret Sharing", "content": "Let \\(D_i\\) represent the local dataset for EV i, where \\(i \\in \\{1,2,..., N\\}\\) and N is the total number of EVs. Each EV i trains a local model \\(f_i(W)\\) on its dataset \\(D_i\\), where W represents the model parameters (weights) for EV i at time t.\nThe goal of local training is to find the optimal model parameters \\(W^*\\) by minimising the local loss function \\(L_i\\):\n\\[W^* = \\arg \\min_W L_i (f_i (W), D_i)\\]\nwhere:\n\\(W^*\\) represents the optimised local model weights for EV i at time t.\n\\(W\\) is the set of all possible model parameters being optimised.\n\\(L_i\\) is the local loss function for EV i.\nAfter local training:\nAssumption 1. Given the rapid increase in EV adoption, we assume that a minimum of two non-transitory EVs per com-munity will be available for P2P sharing. This assumption is supported by projections indicating that by 2050, over 70% of global vehicle sales will be EVs, ensuring sufficient density for this approach [19].\nNon-transitory EVs engage in P2P sharing to en-hance privacy and robustness. Once the locally trained weights \\(W^*\\) are partitioned into secret shares \\(S_{i,k}\\), these secret shares are shared within a limited peer group of 2-10 EVs. Each EV receives secret shares from its peers and aggregates them to compute augmented secret shares \\(S_{i,k}^{t}\\), where augmentation introduces con-trolled modifications to prevent direct inference of local weights while preserving the integrity of the global model.\nPeer selection is dynamic and proximity-based, considering:\nProximity-based selection (favoring EVs operating in similar regions to reflect shared energy demand characteristics).\nAvailability in the current training round.\nRotation prevents biased weight sharing. If at least 2 EVs are available, the system proceeds with P2P Sharing. If fewer than 2 EVs are available, the EV submits encrypted shares directly to the community DERMS, ensuring uninterrupted training.\nEVs communicate via secure channels using MeLSeC to negotiate and exchange secret shares.\n\\[W^t = W^* + \\alpha \\sum_{j \\in peers} S_{j,k}^{t}\\]\nWhere \\(\\alpha\\) is a scaling factor controlling the contribution of peer updates.\nTransitory EVs, by contrast, directly partition their lo-cally trained weights into secret shares:\n\\[S_{i,k}^{t} = Partition(W^*) = \\sum_{k=1}^{K} S_{i,k}\\]\nThese secret shares are transmitted to the community DERMS, ensuring that local model weights remain undis-closed.\nAssumption 2. While community DERMS receives all secret shares from transitory EVs, community DERMS is consid-ered honest-but-curious, following protocols without attempting weight reconstruction. Secure Aggregation ensures that only the final aggregated model is revealed, preventing DERMS from isolating individual EV contributions."}, {"title": "4.2 Additive Secret Sharing and Secure Aggregation", "content": "Each EV i partitions its weights into secret shares:\n\\[S_{i,k}^{t} = Partition(W^*), W^* = \\sum_{k=1}^{K} S_{i,k}\\]\nFor non-transitory EVs, secret shares are distributed among 2-10 peers and augmented with their own shares before being sent to the community DERMS for secure aggregation. In contrast, transitory EVs transmit their secret shares di-rectly to the community DERMS without peer distribution. At the community DERMS, shares are aggregated with-out reconstruction of local weights:\n\\[\\Theta = \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{k=1}^{K} S_{i,k}^{t} = \\sum_{k=1}^{K} \\Theta_k\\]\nTo mitigate privacy risks at DERMS:\nMeLSeC encryption: Secures secret shares during transmission.\nNormalisation: Reduces outlier influence:\n\\[\\tilde{\\Theta} = Normalise(\\Theta)\\]\nPeer-based Distribution: Further obfuscates updates before DERMS aggregation."}, {"title": "4.3 Dynamic Client Capping and Rotation", "content": "To optimise computational efficiency, DCCM limits the number of active EV clients to C, where \\(C < N\\). The CRM mechanism ensures clients are rotated across training rounds:\n\\[C_t = Rotate(\\{1, 2, ..., N\\}, t, C)\\]\nBy capping active clients at C, aggregation complexity is reduced from:\n\\[O(N) \\text{ to } O(C), C \\ll N\\]"}, {"title": "4.4 Prediction Transmission to EPDC", "content": "After aggregation, DERMS generate spatio-temporal predictions:\n\\[\\hat{l_t}, \\hat{T_t} = DERMS(\\tilde{\\Theta})\\]\nWhere:\n\\(\\hat{l_t}\\) is the predicted next charging location.\n\\(\\hat{T_t}\\) is the predicted charging time.\nPredictions are securely transmitted to EPDC using TLS 1.3 for energy distribution analysis."}, {"title": "4.5 Federated Learning Process", "content": "The FL process integrates P2P Sharing and Augmenta-tion, Additive Secret Sharing, Secure Aggregation, DCCM, CRM, and Normalisation:\nAlgorithm 1 FL Process for H-FLTN with DERMS and EPDC in EV Charging Networks"}, {"title": "5 PROPOSED SOLUTION", "content": "This section presents the: 1) the solution architecture, 2) the EV mobility dataset, and 3) the proposed H-FLTN system. First, we outline the H-FLTN pipeline, detailing the sequence of processes from data input to the EPDC's logistics output. Second, we describe the construction and characteristics of the EV mobility dataset, focusing on the methodologies used for data collection, feature engineering, and the assumptions embedded in the dataset. Finally, we discuss the implementation of our H-FLTN system, elaborating on its structure, training process, and specific application in predicting the EV's next charging location and time while preserving user privacy."}, {"title": "5.1 Proposed Pipeline", "content": "The pipeline illustrated in Figure 1 consists of the fol-lowing key stages:\n1) Preprocessing: Each EV processes its historical spatio-temporal mobility data independently, ensuring pri-vacy. The data is split into training, validation, and test sets, normalised, and converted into PyTorch tensors for efficient model training.\n2) Local Model Training and Prediction:\nEV clients initialise their models with community global model weights.\nModels are trained locally using EV-specific charging behaviour data.\nOnce trained, the local model outputs its prediction for the EV's next charge time and location.\nLocal model weights are then partitioned into secret shares for secure transmission.\n3) Peer-to-Peer (P2P) Sharing and Augmentation:\nNon-transitory EVs securely exchange and augment secret shares with 2-10 community peers before transmitting them to the DERMS via MeLSeC. If fewer than 2 peers are available, the EV transmits its encrypted secret shares directly to the DERMS instead.\nTransitory EVs bypass P2P sharing and send their secret shares directly to the community DERMS.\n4) Community Model Aggregation at DERMS:\nThe DERMS module receives encrypted secret shares from participating EVs.\nClient participation is regulated through the Dy-namic Client Capping Mechanism (DCCM) and Client Rotation Management (CRM), ensuring a bal-anced and efficient training process.\nSecure aggregation using additive secret sharing is applied to compute the global model weights with-out exposing individual client contributions.\nNormalisation is performed to mitigate outliers be-fore updating the community global model.\n5) Testing and Global Model Update:\nThe updated global model is evaluated on a test set to assess prediction accuracy for location and charge time.\nIf validated, the finalised weights are securely dis-tributed back to local EV models via TLS 1.3 for the next training round.\n6) Prediction Output and EPDC Analysis:"}, {"title": "5.2 EV Mobility Dataset", "content": "To develop and validate H-FLTN, we required a dataset containing detailed EV mobility and charging patterns. For this study, we utilised a modified version of the Chicago taxi mobility dataset [20], enriched with synthetic data to incorporate EV specific metrics. While originally based on non-EV taxi mobility, these enhancements reflect future adoption trends, assuming that:\nAssumption 3. The majority of taxi fleets will transition to EVs by 2050.\nAssumption 4. Uniform charging infrastructure will be in place, providing consistent charging speeds and compatibility.\nTo simulate realistic EV behaviour, the dataset includes nine EV models with battery capacities ranging from 143 km to 416 km, randomly assigned to reflect fleet diversity. Trips span one year across 77 distinct community areas, representing potential pick-up, drop-off, or charge locations, forming the study's spatial framework. Battery charge levels range from 20% to 100%, aligning with industry standards for preserving battery health [21], ensuring diverse charging scenarios from immediate to long-term needs.\nEach EV serves as a client in the H-FLTN system, contributing to decentralised learning. The framework is designed to optimise resource handling, ensuring scalability and adaptability across different urban settings, provided sufficient spatio-temporal data is available. This flexibility highlights H-FLTN's applicability in efficiently managing EV energy demands across diverse smart city environments."}, {"title": "5.3 Training", "content": "The proposed H-FLTN framework employed ML on spatio-temporal datasets representing EV trips, with each EV treated as an independent client within the system's hier-archical structure. The datasets preserved the chronological order of sequences to maintain the temporal dependencies essential for accurate location and time predictions. Each EV client trained model weights locally, which were then partitioned into secret shares and securely aggregated at the community-level DERMS. The DERMS predictions were subsequently transmitted to the EPDC for city-wide spatio-temporal EV energy demand analysis.\nExperiments utilised dataset groups organised by EV numbers: 150, 300, 500, 750, and 1000. Each group was further divided into three subgroups (A, B, and C), rep-resenting diverse community-level compositions of EVs. These subgroups were randomly selected but designed to reflect real-world variability in EV distributions across dif-ferent regions, where factors such as battery capacity, energy demand, and mobility patterns differ across communities. This structure allows for evaluating the robustness of the model across heterogeneous EV populations, ensuring that results are generalisable beyond a single distribution of EVs. Data within each group was split into training, validation, and test sets, with 85% allocated for training and validation and the remaining 15% for testing. Within the training and validation subset, an additional 85-15% split was applied to maintain representative validation sets. This stratified ap-proach ensured balanced representation of mobility patterns across training phases while preserving chronological order to maintain spatio-temporal dependencies.\nThe random assignment of EVs to subgroups inher-ently created non-IID (non-independent and identically dis-tributed) data distributions, as each subgroup captured a diversified combination of EV models, battery capacities, mobility patterns, and charging behaviours. While tradi-tional methods often simulate non-IID data using a Dirichlet distribution controlled by an \\(\\alpha\\) parameter where smaller \\(\\alpha\\) values increase data heterogeneity our approach achieves a similar outcome by leveraging random distributions. This method ensures the model learns from a broad range of real-world scenarios and generalises effectively to dynamic environments.\nTo ensure the framework aligned with real-world use cases, datasets represented a wide range of battery charge levels, from 20% to 100%. This diversity allowed the frame-work to capture varying charging behaviours, enabling short-term predictions for low battery levels (e.g., 20%) and long-term predictions for higher charge levels (e.g., 100%). This alignment with real-world charging patterns enhanced the model's utility for energy providers, supporting both short-term and long-term resource planning."}, {"title": "6 PERFORMANCE EVALUATION", "content": "This section evaluates the effectiveness of the proposed H-FLTN framework in predicting both the location and time of EVs' next charging event. We compare centralised and decentralised ML modelling approaches and analyse the results of the decentralised H-FLTN framework. Particular focus is given to the framework's ability to maintain high time and location prediction accuracy."}, {"title": "6.1 Baseline Modelling", "content": "The following section includes baseline experiments, where we evaluated three centralised ML models: BiLSTM, CNN, and a Transformer. These models were tested on spatio-temporal datasets to determine their ability to inter-pret EV sequences that include both mobility and charge transaction features. The results, presented in Table: 1, con-firmed that the Transformer model demonstrated superior performance in capturing spatio-temporal dependencies, making it the optimal choice for further decentralised ex-periments."}, {"title": "6.2 Results and Analysis", "content": "This section discusses and analyses predictive results for EV next charge prediction including both location and time metrics. The performance of the H-FLTN framework was systematically evaluated across multiple EV group sizes, with the results for the location prediction presented in Table 3 and the results for the time prediction in Table 4.\nThe evaluation of the H-FLTN framework involved datasets representing different sizes of EV groups, specifi-cally 150, 300, 500, 750, and 1000 EVs. To ensure a compre-hensive and unbiased evaluation, each group was further divided into three subgroups A, B, and C. This stratification prevents evaluation bias by mitigating potential data imbal-ances that could arise from a single large, undivided dataset. The EVs in each group and subgroup were selected in a completely random fashion, ensuring a natural distribution of variability in battery capacities, mobility patterns, and charging behaviors. This setup mirrors real-world condi-tions, where EV behaviors are inherently heterogeneous. By evaluating across multiple diverse subgroups, the frame-work's robustness, bias mitigation, and ability to generalise across varying mobility and charging conditions can be effectively assessed."}, {"title": "6.2.1 Location and Time Prediction Results", "content": "This section presents the location prediction results, analysing the effectiveness of the H-FLTN framework in capturing spatial dependencies across diverse EV groups. Table 3 provides a performance breakdown across different group sizes, highlighting trends in accuracy. This analysis examines how factors like battery charge capacity distributions and mobility patterns affect the model's ability to generalise. By examining these factors, we evaluate how well the framework maintains accurate predictions across diverse datasets and dynamic charging behaviors.\nThe 'Overall' metrics in Table 3 summarise the results across all subgroups. The overall maximum accuracy (Max (%)) reflects the highest accuracy observed among all sub-groups. The overall median accuracy (Med (%)) is the median value of the subgroup medians, providing a central tendency metric. The overall standard deviation (SD) is calculated using the pooled standard deviation formula, accounting for variability across all subgroups while con-sidering their respective sample sizes.\nThe location prediction results in Table 3 demonstrate the effectiveness of the H-FLTN framework in capturing spatial dependencies across diverse EV groups. The model achieved a median accuracy of 95.91% for the smallest EV group (150 EVs) and 96.89% for the largest group (1000 EVs), with similarly strong performance across intermediate sizes. Notably, the highest accuracy observed was 98.10%, achieved in Group B of the 1000 EV set. The relatively low standard deviation of 1.23 for the largest EV group further reinforces the framework's stability and reliability, even in scenarios with significant data heterogeneity."}, {"title": "6.3 Ablation Study", "content": "The Ablation Study provides an in-depth analysis of individual contributions and interplay of key components in the H-FLTN framework. By isolating specific mechanisms and evaluating their impact, this section underscores the significance of features such as Capping and Rotation, P2P Sharing with Augmentation, Additive Secret Sharing, and Secure Aggregation. This section is segmented into three key areas: Compute and Time Resource Optimisation, an analysis of client capping and rotating (DCCM +RCM), Lo-cation Modelling, which assesses the framework's ability to predict EV charging locations; and Time Modelling, which evaluates temporal predictions for EV charging. Together, these experiments demonstrate how each feature affects the H-FLTN framework across diverse use cases."}, {"title": "6.3.1 Compute and Time Resource Optimisation (DCCM + RCM)", "content": "To manage computational and time overheads, we imple-ment client capping and rotating mechanisms DCCM + CRM, dynamically selecting an optimal number of clients based on extensive experimentation. We calculate the com-putational cost of modelling with H-FLTN using FLOPs (Floating Point Operations), considering both the forward and backward passes through the model architecture, as outlined by Tang et al. [22]. The total FLOPs per global epoch is computed as the sum of FLOPs across all partici-pating clients, making it directly proportional to the number of clients involved in each epoch.\nFindings from these experiments highlight the effec-tiveness of the DCCM + CRM mechanisms in managing resource demands. When client participation is capped at 150 EVs, computational cost remains consistent across vary-ing dataset sizes, reflecting that the cap, rather than the total number of available clients, dictates resource usage. FLOPs for both the 500 EV and 1000 EV groups yield identical values of 74,880,000 per epoch under DCCM + CRM. Without capping, the FLOPs scale directly with client count, doubling from 249,600,000 for 500 EVs to 499,200,000 for 1000 EVs. These findings reinforce the role of DCCM + CRM in optimising compute resources to maintain efficiency as network scale grows."}, {"title": "6.3.2 Location Prediction Ablation Study", "content": "The ablation study evaluates the contribution of key features Capping & Rotating, Secret Sharing, Secure Aggregation,"}, {"title": "6.3.3 Feature Analysis", "content": "Removing individual features revealed their distinct contri-butions to model performance:\nCapping & Rotating: Removing this feature caused the overall test accuracy to drop to 94.26% (SD: 1.32). Sub-group accuracies also decreased to 94.26% (A), 93.50% (B), and 93.21% (C). This demonstrates that while Cap-ping & Rotating enhances efficiency and fairness, its removal has a moderate impact on accuracy.\nSecret Sharing: The exclusion of Secret Sharing reduced overall accuracy to 94.18% (SD: 1.16), with subgroup accuracies of 94.18% (A), 92.91% (B), and 93.83% (C). The feature's minimal impact on accuracy underscores its utility in enhancing privacy without compromising performance.\nSecure Aggregation: Removing Secure Aggregation caused a more significant decline in overall accuracy to 92.41% (SD: 1.30), with subgroup accuracies of 92.36% (A), 92.41% (B), and 91.88% (C). This feature is crucial for robust weight integration, as its absence reduces performance.\nNormalisation: The removal of Normalisation resulted in the most significant drop in overall accuracy to 83.97% (SD: 1.10). Subgroup accuracies fell to 83.84% (A), 83.17% (B), and 83.97% (C). Normalisation's ab-sence severely disrupts gradient flow and convergence, directly impacting stability and accuracy."}, {"title": "6.3.4 Time Prediction Ablation Study", "content": "The results in Table 7 highlight the critical role of specific features in achieving optimal performance and efficiency for the time model.\nThe removal of Capping and Rotating resulted in a mi-nor increase in MSE values, with the best MSE shifting from 0.0311 to 0.0335 and the median MSE slightly increasing across all subgroups. This outcome aligns with expecta-tions, as capping and rotating mechanisms regulate client participation to optimise resource allocation and mitigate bias, rather than directly influencing the model's temporal learning capability.\nSecret sharing and Secure Aggregation, which are imple-mented for privacy preservation, exhibited similar trends. The best MSE increased marginally to 0.0324 and 0.0341, re-spectively, while median values showed minor fluctuations. Since these techniques operate during the secure exchange and aggregation process rather than modifying the learning process itself, their removal had little effect on the model's ability to capture temporal dependencies.\nThe removal of Normalisation also led to negligible changes in predictive performance. The best MSE increased slightly to 0.0328, while the median MSE remained within a close range of prior results. This aligns with theoretical expectations, as the model utilises Unix timestamps, which inherently encode temporal sequences in a way that does not require Normalisation for stability.\nOverall, the ablation study confirms that while these features are essential for real-world deployment in FL sys-tems ensuring privacy, bias mitigation, and efficiency their removal does not significantly impact the model's predictive accuracy. This is expected, as the transformer-based archi-tecture leverage self-attention mechanisms to capture long-range dependencies across the entire temporal sequence simultaneously. This design allows the model to effectively encode time-based relationships without requiring explicit feature scaling, sequential processing constraints, or hand-crafted temporal smoothing. As a result, the predictive performance remains stable, even when auxiliary mecha-nisms such as Normalisation, Secure Aggregation, or client participation strategies are removed."}, {"title": "6.4 Privacy Threat Model", "content": "In the H-FLTN framework", "DERMS": "As aggregation centres, community DERMS receive secret shares from both tran-sitory and non-transitory EVs. Without appropriate privacy measures, DERMS could attempt to link shared weights to specific EVs, potentially revealing sensitive mobility pat-terns or charging"}]}