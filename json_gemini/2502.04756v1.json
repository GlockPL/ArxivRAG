{"title": "Concept Navigation and Classification via Open Source Large Language Model Processing", "authors": ["Ma\u00ebl D. Kubli"], "abstract": "This paper presents a novel methodological framework for detecting and classifying latent constructs, including frames, narratives, and topics, from textual data using Open-Source Large Language Models (LLMs). The proposed hybrid approach combines automated summarization with human-in-the-loop validation to enhance the accuracy and interpretability of construct identification. By employing iterative sampling coupled with expert refinement, the framework guarantees methodological robustness and ensures conceptual precision. Applied to diverse data sets, including AI policy debates, newspaper articles on encryption, and the 20 Newsgroups data set, this approach demonstrates its versatility in systematically analyzing complex political discourses, media framing, and topic classification tasks.", "sections": [{"title": "Introduction", "content": "The advent of Large Language Models (LLMs) has significantly altered the landscape of natural language processing (NLP) and computational linguistics. These models, trained on extensive data sets, exhibit remarkable capabilities in understanding and generating human-like text. LLMs such as GPT-4, Gemini, and LLaMA have demonstrated proficiency in various tasks such as summarization, translation, and text classification, fundamentally changing the way textual data are processed and analyzed (T\u00f6rnberg, 2023; Gilardi et al., 2023; Alizadeh et al., 2023; Lam et al., 2024). This transformative potential is particularly relevant for extracting and classifying latent constructs, which are abstract, unobservable concepts inferred from textual data. Examples include frames, which shape how issues are understood; narratives, which structure events or arguments into coherent meaning; and topics, which group semantically related words to reflect recurring themes in a text. These constructs are essential for understanding political and social discourses. They reveal patterns in framing strategies, ideological bias, and issue salience, thus clarifying how information is structured to influence audiences or shape policy debates. They also uncover patterns in extensive textual corpora-for example, by showing how news outlets frame political debates, identifying recurring narratives in social media discussions, or spotlighting emerging topics in legislative proceedings. However, extracting such information remains a traditionally difficult task laden with difficulties in interpretability, adaptability, and scalability.\nIdentifying and analyzing latent constructs in the social sciences and humanities is critical to understanding complex discourses and narratives. Focusing on frames, narratives, and topics specifically enables researchers to address key questions in communication and political science, such as how different groups define problems, justify solutions, and influence public opinion. However, the framework could potentially be extended to study other constructs (e.g., rhetorical strategies) that require similarly nuanced interpretive approaches. Although widely used, traditional quantitative methods such as Latent Dirichlet Allocation (LDA), Structural Topic Models (STM), and Bertopic often fail to capture the nuanced and dynamic nature of textual data. While earlier transformer models can address challenges like semantic ambiguity (e.g., bank referring to a financial institution versus a riverbank) and contextual nuances (e.g., liberal signifying either a political ideology or an open-minded attitude), Large Language Models (LLMs) excel in applying these capabilities at scale, integrating larger segments of text to discern underlying meanings, storylines, sentiments, rationales, arguments, and perspectives. This broader interpretive capacity makes LLMs a promising avenue for more robust and scalable text analysis, reducing the need for extensive manual refinement (Huang et al., 2023; Xu et al., 2024).\nThis study aims to harness the capabilities of LLMs to propose a hybrid approach. This iterative process merges automated text analysis with human-in-the-loop validation to balance efficiency and conceptual soundness. Although LLMs demonstrate capability in analyzing extensive textual segments, especially by identifying nuanced narratives or sentiments within entire paragraphs, the expertise of domain specialists is crucial for refining and validating the constructs that arise. By integrating LLM-driven generation of frames, topics, or narratives with expert review, this hybrid methodology ensures both scalability and theoretical robustness. For illustration, the model might generate an initial set of frames from a large news corpus, grouping articles by themes such as economic impact or political blame. Human experts would then refine or merge these themes based on domain-specific knowledge before feeding them back into the model for final classification.\nThis hybrid framework integrates LLM-driven text summarization and concept generation with a human-in-the-loop validation process to improve interpretability compared to purely automated approaches in quantitative text analysis. The approach proceeds in an iterative cycle. First, the LLM generates concise summaries and tentative conceptual categories (e.g. potential frames, topics, or narratives). The researchers then refined and validated these results, ensuring alignment with domain expertise and theoretical constructs. By merging computational efficiency with expert oversight, the framework addresses one of the most significant challenges in computational social science: achieving both conceptual precision and scalability in text analysis (Gilardi et al., 2023).\nTogether, this paper introduces one of the first frameworks that systematically integrates LLM-based analysis with structured human input at each stage of concept identification. This synergy improves adaptability and robustness, enabling a more comprehensive identification of frames, topics, and narratives. Researchers can thus move beyond the limitations of classical models and capture the complexities present in large and evolving corpora of textual data (T\u00f6rnberg, 2023; Alizadeh et al., 2023).\nThe following sections detail the theoretical foundations of the approach and review the current state of NLP techniques for concept classification. The hybrid framework is then presented\u2014including data sources, the specifics of LLM implementation, and the staged classification process with human-in-the-loop refinement. Subsequent sections report empirical applications in multiple data sets and discuss implications for research in digital democracy, political communication, and computational social sciences (Gilardi et al., 2023; Lam et al., 2024). The conclusion reflects on the benefits and limitations of the framework, as well as potential avenues for further refinement, including domain-specific fine-tuning and more sophisticated active learning strategies to enhance validity, interpretability, and robustness."}, {"title": "Theoretical Framework", "content": "Applying natural language processing (NLP) techniques to measure classification constructs such as topics, frames, and narratives has seen significant advancements. Traditional methods like Latent Dirichlet Allocation (LDA), Structural Topic Models (STM), and Bertopic have been extensively used. These methods utilize statistical approaches to identify latent structures in text data, enabling the extraction of themes and topics.\nLDA, introduced by Blei et al. (2003), is a generative probabilistic model that assumes documents are mixtures of topics and topics are mixtures of words. It has been widely applied in various domains but has crucial limitations, including difficulty interpreting topics and sensitivity to the number of topics specified a priori.\nStructural Topic Models (STM), proposed by Roberts et al. (2014), extend LDA by incorporating document-level covariates to improve the model's interpretability and flexibility. STM allows researchers to analyze how topics correlate with metadata, providing a more nuanced understanding of the text. However, STMs still face challenges in terms of scalability, computational complexity, and topic stability. Bertopic, a recent development by Grootendorst (2022), leverages BERT embeddings and clustering algorithms to generate topic models. While it improves topic coherence and interpretability, Bertopic's reliance on pre-trained embeddings limits its adaptability to domain-specific language nuances. For instance, recent studies have highlighted the potential of prompt engineering techniques in LLMs to address some of these limitations, allowing for more flexible and domain-specific adaptations (Vatsal & Dubey, 2024).\nDespite these advancements, traditional topic-modeling techniques face several problems. They often produce results that require substantial manual refinement to ensure interpretability. Moreover, these models struggle with semantic ambiguity and contextual nuances, leading to topics that may not align well with the intended constructs of interest. Furthermore, these methods typically do not account for the temporal dynamics of topics, frames, or narratives, which are crucial to understanding the evolution of discourse over time.\nIn addition to LDA, STM, and Bertopic, other methods, such as cluster analysis and network analysis, are increasingly used to improve the classification and interpretation of textual data. Cluster analysis groups similar data points according to their attributes, uncovering hidden patterns within large data sets (Jain, 2010; Jain et al., 1999). This method helps identify distinct groups or segments within text corpora, providing insight into varying themes or opinions. For example, clustering algorithms such as K-means or hierarchical clustering can be applied to text data to reveal subgroups of documents with similar thematic content (Aggarwal & Zhai, 2012).\nNetwork analysis examines relationships between entities within a data set, visualizing these connections as networks or graphs. This approach is instrumental in understanding the dynamics and structures of social interactions, information flow, and influence patterns (Borgatti & Li, 2009). Researchers can explore connections between different topics, actors, or concepts by applying network analysis to text data. This offers a deeper understanding of the complex interrelations in political discourse and digital communication (Milojevi\u0107, 2014). However, these methods also have limitations, such as the need for high-quality data and significant computational resources. Furthermore, classifying complex constructs like frames and narratives often requires nuanced interpretation and a deep understanding of the context, which can be challenging to achieve purely through automated methods without significant human oversight."}, {"title": "Capabilities of Large Language Models", "content": "Large Language Models (LLMs) such as chatGPT and its successors and counterparts have revolutionized the field of natural language processing (NLP). These models, trained in vast amounts of text data, demonstrate remarkable abilities in understanding and generating human-like text (Brown et al., 2020; Zhu et al., 2023). One of the critical capabilities of LLMs is their proficiency in summarization and information extraction. As noted in McCoy et al. (2024), this proficiency is shaped by the autoregressive nature of LLMs, which focus mainly on the prediction of the next word. LLMs can distill lengthy documents into concise summaries, effectively capturing the core information. This is achieved through techniques such as few-shot learning, where the model is provided with examples to guide its output (Zhu et al., 2023; Tai et al., 2024).\nIn addition to few-shot learning, LLMs can also perform zero-shot learning, handling entirely new tasks without any explicit training examples by relying on general textual prompts or instructions (Brown et al., 2020; Chew et al., 2023). These approaches enable LLMs to perform complex tasks with greater accuracy and adaptability, making them powerful tools in various applications, from customer service to academic research (Yang et al., 2024). Specifically, McCoy et al. (2024) contend that although the training of LLMs is structured around high-probability next-word prediction, this characteristic facilitates their efficient adaptation to tasks characterized by identifiable probabilistic structures. In cases where the task can be framed as a sequence of high-probability linguistic or conceptual steps, the autoregressive model excels, supporting the rationale behind leveraging LLMs for complex and nuanced tasks like frame and narrative extraction. However, the approach proposed by McCoy et al. (2024) also suggests that LLM success in zero-shot and few-shot tasks might be limited when faced with low-probability scenarios, which do not align with their training data distributions. In these instances, the model's internal heuristics may fail to generate coherent or accurate outputs, leading to \u201csurprising failure modes\". Such failures are especially prone to occur in out-of-distribution tasks where the required reasoning or domain knowledge goes beyond the patterns captured during training. In addition, prompt engineering methods have been explored to enhance the adaptability and specificity of LLMs for various NLP tasks, demonstrating improved performance in extracting and classifying complex constructs such as frames and narratives (Vatsal & Dubey, 2024).\nThe summarization by LLMs takes advantage of several advanced mechanisms. First, they utilize attention mechanisms that allow the model to focus on the relevant parts of the text while ignoring the less essential details (Vaswani et al., 2017). These mechanisms are deeply influenced by the LLM's internal structure, where the autoregressive model's reliance on next-token prediction can bias outputs towards high-probability continuations, as evidenced by McCoy et al. (2024). This selective attention ensures that the generated summary encapsulates the most significant points of the source material (Zhang et al., 2024). Second, the models are pre-trained in vast and diverse corpora, providing them with extensive background knowledge and contextual understanding, which enhances their ability to generate accurate and coherent summaries (Dagdelen et al., 2024). Third, fine-tuning specific summarization tasks further enhances their ability to create precise and contextually appropriate summaries (Pilault et al., 2020).\nLLMs excel at zero-shot, few-shot, and chain-of-thought tasks, performing new tasks with little to no task-specific training. This is particularly beneficial in extracting relevant information from text, as demonstrated in clinical meta-analyses studies. For instance, Kartchner et al. (2023) explored the use of ChatGPT for zero-shot information extraction from clinical trials, finding that it could accurately identify and extract pertinent data with minimal manual intervention. This ability to generalize across tasks makes LLMs handy tools in text analysis (Chew et al., 2023).\nThe effectiveness of LLMs in summarization tasks can be understood through several methodological lenses. First, from a machine learning perspective, LLMs employ a transformer architecture that excels at handling sequential data and capturing long-range dependencies. Incorporating prompt engineering techniques within this architecture can further enhance the ability of the model to generate more precise and relevant summaries (Vatsal & Dubey, 2024; Vaswani et al., 2017). The transformer architecture, combined with an autoregressive model's probabilistic approach, provides a framework that inherently favors high-probability coherent outputs, with this alignment between architecture and training objective underpinning LLM success in summarization and information extraction tasks (McCoy et al., 2024). Moreover, the self-attention mechanism allows the model to weigh the importance of different words in the input text, ensuring that the summary captures essential information while omitting irrelevant details (Vaswani et al., 2017). Recent advances in transformer models, which are also used by LLMs in general, such as the introduction of sparse attention and memory-augmented transformers, have further enhanced their capability to manage large-scale and complex data sets efficiently (Zaheer et al., 2020; Lewis et al., 2020).\nSecond, from a natural language processing standpoint, LLMs' ability to understand and generate human-like text is rooted in their extensive pre-training on large text corpora. This pre-training phase equips the models with a deep understanding of language syntax, semantics, and pragmatics, enabling them to generate summaries that are not only concise but also coherent and contextually appropriate (Dagdelen et al., 2024). Using masked language modeling and next-sentence prediction during pre-training significantly improves the models' contextual prediction and coherence generation capabilities (Devlin et al., 2018; Radford et al., 2019). This is particularly important in domains such as clinical meta-analysis, where the precision and clarity of the extracted information are paramount (Kartchner et al., 2023).\nThird, LLMs' generative nature allows them to produce flexible and adaptable summaries to various contexts. Unlike rule-based or template-based summarization methods, which can be rigid and limited in scope, LLMs can generate summaries tailored to the specific needs of the task at hand. This adaptability is crucial in dynamic fields, where the ability to quickly and accurately summarize new findings can significantly impact decision making and policy formulation (Pilault et al., 2020)."}, {"title": "Identifying Frames, Topics, Narratives and more with LLMS", "content": "LLMs' advanced language understanding capabilities make them well suited for identifying latent constructs such as frames, topics, and narratives. As defined by Entman (1993, 2007), frames involve selecting certain aspects of reality to make them more salient in communication, thereby promoting specific interpretations and evaluations. Topics represent the thematic content of discourse, while narratives encompass structured coherent sequences of events or arguments within the text.\nLLMs can efficiently detect these constructs due to their deep contextual understanding (Lam et al., 2024). By leveraging the extensive pre-training on diverse text corpora, LLMs can discern subtle linguistic cues that indicate the presence of frames, topics, or narratives. For example, an LLM can identify framing effects by recognizing patterns in how problems are defined, causes are attributed, and solutions are proposed. Similarly, the model can extract topics by clustering semantically related content and detect narratives by following the logical flow of events or arguments.\nBeyond frames, topics, and narratives, LLMs can also identify other constructs such as sentiment, stance, and rhetorical strategies. Sentiment analysis involves determining the emotional tone of the text, while stance detection assesses the author's position on a given issue. Rhetorical strategies encompass the use of language to persuade or influence the audience, including techniques such as metaphors, analogies, and appeals to emotion. The flexibility of LLMs in capturing these diverse constructs enhances their utility in comprehensive text analysis.\nThese mechanisms collectively enable LLMs to perform advanced summarization tasks, capturing the essence of the text while maintaining coherence and relevance. LLMS' efficiency in summarization significantly reduces the manual effort required in processing large data sets, making them invaluable in various domains such as healthcare, finance, and legal research."}, {"title": "Generative Framework for Construct Identification and Classification", "content": "Given LLMs' capabilities, I propose a generative framework to identify latent constructs from textual data. The process begins with the extraction and summarization of relevant information from the text using LLMs. This involves generating concise summaries that capture the core arguments, perspectives, or thematic elements present in the data. These summaries serve as the basis for further analysis, facilitating the identification of frames, topics, and narratives.\nThe generative approach involves creating potential target classes for the constructs of interest from the generated summaries. For example, in analyzing European Parliamentary Debates on AI, the LLM first produces concise summaries of each sentence, then generates potential frame classes such as AI Benefits, AI Impact, AI Impact on Society, or AI Impact on Work. The researchers subsequently refine these automatically proposed classes through an iterative process that combines automated model evaluations and human-in-the-loop validation. By reviewing the generated classes, experts ensure alignment with theoretical constructs and empirical relevance, merging or discarding categories as necessary. This iterative refinement improves accuracy and interpretability, yielding a distilled set of frames that better capture the nuances of the underlying data.\nThis framework leverages LLMs' strengths in understanding and generating text while incorporating human expertise to fine-tune the final output. Integrating LLMs with human oversight ensures that the constructs identified are theoretically sound and practically meaningful. Moreover, this approach allows for dynamic adaptation of construct identification to evolving textual data, making it particularly useful in longitudinal studies or real-time text analysis.\nTo conclude, traditional NLP techniques for measuring classification constructs have advanced significantly but face many limitations regarding interpretability, adaptability, and scalability. Large Language Models offer a promising alternative due to their superior contextual understanding and generative capabilities. Using LLMs in a generative framework, researchers can efficiently extract and identify frames, topics, narratives, and other constructs from textual data. This approach combines the strengths of machine learning and human expertise, ensuring robust and nuanced text analysis."}, {"title": "Methods", "content": "This paper aims to extract and classify latent constructs, including frames, narratives, and topics, from large textual corpora. By leveraging the capabilities of an Open-Source LLM, this approach integrates automated NLP techniques with humans in the loop validation, ensuring a comprehensive and reliable extraction process. The general framework is depicted in Figure 1.\nThe proposed methodological framework leverages Open Source LLMs, such as the LLaMA 3 model, to extract and classify latent constructs such as frames, narratives, and topics from large textual corpora. The methodology is designed to address the limitations of traditional topic modeling methods, such as Latent Dirichlet Allocation (LDA) and Structural Topic Models (STM), which often struggle with interpretability, adaptability, and scalability (Blei et al., 2003; Roberts et al., 2014; Grootendorst, 2022)."}, {"title": "Construct Identification and Summarization", "content": "The process begins with extracting relevant information from textual data using the generative capabilities of LLMs. This involves generating concise summaries that encapsulate the core arguments, perspectives, or thematic elements present in the data. Summarization is crucial, as it distills complex texts into manageable and interpretable units, facilitating the subsequent identification of latent constructs (Zhu et al., 2023). The LLM employs a transformer architecture that utilizes self-attention mechanisms to focus on the most relevant parts of the text, enabling it to distill critical information from lengthy texts while preserving essential context and meaning (Vaswani et al., 2017). At this stage, researchers iteratively refine the prompts used for summarization by testing them on representative portions of the data, ensuring that the outputs align with both theoretical and empirical objectives. This process, guided by human intervention, directs the LLM to prioritize salient constructs while reducing unnecessary details during subsequent analyses. This process is particularly suitable for identifying latent constructs because it reduces the cognitive load on subsequent analytical processes and improves the interpretability of complex data (Nenkova & McKeown, 2012). Several vital computational mechanisms underpin the effectiveness of summarization in this context.\nFirst, the Transformer Architecture and Attention Mechanisms introduced by Vaswani et al. (2017) form the backbone of modern LLMs like LLaMA 3. This architecture employs self-attention mechanisms that allow the model to weigh the importance of different words and phrases within a text. By focusing on the most relevant parts of the text, the model can generate summaries that capture the core arguments and thematic elements efficiently. The self-attention mechanism is mathematically represented as:\nAttention(Q, K, V) = softmax(QK^T / sqrt(d_k))V  (1)\nWhere Q, K, and V are the query, key, and value matrices, respectively, and dk is the dimensionality of the keys. This mechanism ensures that the model considers contextual dependencies throughout the text, leading to more coherent and contextually appropriate summaries (Vaswani et al., 2017).\nSecond, LLMs excel in few-shot and zero-shot learning scenarios, where they can perform new tasks with minimal task-specific training. This capability is particularly beneficial for summarization, as it allows the model to adapt to different textual domains and styles without requiring extensive retraining, as shown by various researchers (Kojima et al., 2022; Gilardi et al., 2023; T\u00f6rnberg, 2023; Alizadeh et al., 2023). For example, in clinical meta-analyses, LLMs can accurately identify and extract pertinent information with minimal manual intervention, demonstrating their versatility and adaptability (Kartchner et al., 2023). Moreover, prompt engineering methods can be utilized to refine LLM outputs, ensuring that the summaries are more aligned with specific research objectives and theoretical frameworks (Vatsal & Dubey, 2024).\nThirdly, LLMs are pre-trained on vast and diverse corpora, providing extensive background knowledge and contextual understanding. This pre-training equips the models with a good sense of language syntax, semantics, and pragmatics, enabling them to generate summaries that are not only concise but also coherent and contextually relevant (Devlin et al., 2018). Further fine-tuning of specific summarization tasks can further enhance their ability to produce accurate summaries tailored to the needs of particular domains or data sets, with relatively small amounts of labeled training data (Alizadeh et al., 2023)\nThe methodological implementation of summarization for construct identification involves several steps, each leveraging LLMs' computational strengths. It starts with text segmentation into manageable units, typically sentences or paragraphs. Thus, it facilitates detailed analysis and ensures that the summarization process can focus on discrete text elements. Each segment of the text undergoes a summarization using the LLM. The model generates concise summaries that encapsulate the core arguments or perspectives present in the text. The summary thus serves as the basis for identifying the latent constructs. By distilling the text, the identification of constructs is guided by pre-defined theoretical frameworks, ensuring that the extracted constructs are aligned with the research objectives and empirical relevance."}, {"title": "Frame Generation and Concept Class Creation", "content": "Once the summaries are generated, the next phase involves the iterative generation of potential target classes for the constructs of interest. For example, based on the summarized content, the model might propose frames centered on ethical debates, economic concerns, or regulatory perspectives. This generative approach leverages the LLM's ability to understand and synthesize text, producing various candidate frames that are relevant to the research objectives. The iterative process ensures comprehensive exploration of the corpus's conceptual space, meaning that all salient constructs are progressively identified. After this stage, the researchers systematically evaluate the list of suggested classes produced by the LLM, drawing on relevant theoretical frameworks and the specific scope of the study. Guided by domain expertise and empirical knowledge, they refine and finalize which classes to include, ensuring that each category reflects a conceptually sound and meaningful construct class, as explained in the following section.\nMathematically, the frame generation process can be represented as follows:\nF_i = g(\\sum_{j=1}^n S_j)\nwhere Fi denotes the generated frame class, S_j represents individual summaries, and g is the generative function of the LLM. The iterative nature of this process involves generating multiple sets of the construct of interest (e.g., frames or topics), examining them against domain-specific criteria, and refining them repeatedly, thereby exhaustively mapping the relevant conceptual space in the corpus."}, {"title": "Human-in-the-Loop Validation and Refinement", "content": "The generated concept classes then undergo a critical human-in-the-loop validation to ensure conceptual soundness and empirical relevance. The researchers review the generated classes, refining them to align with theoretical constructs and research questions. This validation step is critical to maintain the precision and interpretability of the identified constructs, addressing one of the primary limitations of fully automated methods (Kartchner et al., 2023; Gilardi et al., 2023; Alizadeh et al., 2023). The iterative refinement process enhances the model output by integrating domain expertise, thereby improving the reliability of the classification. Prompt engineering can play an expanded role in this process by providing structured prompts that not only guide the LLM toward generating outputs aligned with the theoretical constructs but also incorporate domain-specific details, key definitional elements, or examples. Through such tailored instructions, the model can be nudged to focus on the most relevant aspects of the text and generate more conceptually precise frames, topics, or narratives (Vatsal & Dubey, 2024)."}, {"title": "Construct Classification", "content": "Following the generation and validation of concept classes, the methodology employs a staged chain-of-thought approach for classification. This involves multiple stages in which the model evaluates the fit of each concept class for a given sentence or paragraph depending on the unit of analysis. Initially, the model generates a summary to encapsulate the core argument or perspective of the concept. This is followed by evaluating how well the summary aligns with the humanly validated concept classes. The model rates the fit on a scale from 1 (strongly disagree) to 7 (strongly agree) based on the coherence and relevance of the concept class to the text at hand.\nThe fit evaluation can be formally expressed as:\nFit(S, F) = 1/m \\sum_{k=1}^m Rating(S, F_k)\nwhere Fit(S, F) denotes the fit score, m is the number of frames evaluated, and Rating(S, Fk) is the rating given to the frame Fk based on its fit to the summary S. The final selection of frames for each sentence involves choosing the frame(s) with the highest fit scores, ensuring a nuanced and accurate classification.\nThe iterative and staged nature of the method ensures more robustness and reliability in identifying and classifying latent constructs. Furthermore, the inclusion of steps where the LLM is allowed to freely give reasoning should overall increase the performance of the frameworks, as shown by Tam et al. (2024). By combining automated summarization and frame generation with human validation, the approach mitigates misclassification risks and enhances the interpretability of the results. Integrating human expertise at multiple stages of the process ensures that the final result is both theoretically sound and empirically relevant, addressing the challenges faced by traditional NLP methods (Chew et al., 2023). It is also critical to ensure the interpretability and transparency of the summarization process, particularly in domains where the accuracy and clarity of extracted information are paramount (Pilault et al., 2020)."}, {"title": "Data", "content": "To illustrate and assess the effectiveness of the proposed methodology, this study uses a comprehensive data set of EU Parliamentary debates that mention \u201cAI\u201d or \u201cArtificial intelligence\" in the title or within the content of the debate. The data set comprises 133 debates that took place between 2000 and 2023. The debates were collected using a web scraper that extracted relevant data from official parliamentary records. The EU Parliamentary data set was selected because it provides detailed and highly structured debates, making it well suited for testing frame and narrative identification. The data set allows for fine-grained analysis at the sentence level, capturing subtle differences in framing within the same debate. However, the data set focuses on a specific institutional and political context, which can limit the generalizability of the findings to other types of political discourse, such as informal or less structured discussions on social networks. The analysis is performed at the sentence level. This level of granularity ensures that each statement can be classified independently, allowing the detection of subtle differences in framing that might otherwise be overlooked when analyzing entire paragraphs or full speeches.\nFor linguistic processing, I translated speeches in Polish, Czech, Greek, Dutch, Romanian, Hungarian, Danish, Swedish, Slovakian, Finnish, Croatian, Lithuanian, Bulgarian, Estonian and Slovenian into English using the Google Translation API. Google Translate is a statistical translation tool that calculates the probabilities of various correct phrase translations rather than focusing on word-for-word translation (Johnson et al., 2017). Speeches originally in English, Spanish, French, Italian, German, and Portuguese were analyzed in their native languages. Languages with less than 0.5% representation in the data set and those presenting translation challenges with the Google Translation API - Bosnian, Irish, Latvian, Maltese, Slovenian, Estonian, Bulgarian, Lithuanian, Finnish and Croatian - were excluded from the analysis.\nThe final data set contains 133 debates and 5,019 speeches with 19,538 sentences. This comprehensive data set enables an in-depth analysis of parliamentary debates on artificial intelligence in multiple languages and years within the European Parliament. The primary data set serves exclusively for the frame classification and generation process. To evaluate the validity of the frame detection methods, I conducted a validation process using a random sample of 1,250 texts stratified by frame classes. Two coders independently coded this validation subset, ensuring high reliability by only including cases where both coders agreed on the label. This rigorous approach ensures that our methods are robust and reliable for detecting and classifying frames within the data set. After coding, the validation data set contains 996 sentences, and the intercoder agreement between the two research assistants is 0.83. This shows that human coders can sufficiently classify the different frames."}, {"title": "Frame Analysis on Newspaper Articles on Encryption", "content": "To demonstrate the generalizability of the proposed methodological framework, I also applied it to a data set of US newspaper articles that are relevant to the discussion concerning encryption. This data set, drawn from multiple major outlets over 23 years (2000-2023), comprises 10,954 articles that collectively capture the discourse on encryption in US news media. The encryption data set was chosen for its rich and diverse coverage of a contested policy issue over a long period of time, enabling exploration of evolving narratives and frames. However, as a media-based data set, it can be biased by editorial perspectives and news selection processes, potentially limiting its representativeness of public opinion. Moreover, its focus on US media limits cross-national comparisons, which could be an area for future work. The entire corpus was used to generate frames and narratives, while a sample of 1,000 paragraphs spanning different articles and outlets was selected for manual validation. Two research assistants independently coded these paragraphs, following the same human-in-the-loop refinement process used in the EU Parliamentary Debates case: first identifying potential frames and then iteratively refining them with domain expertise.\nAfter coding, the validation data set contains 600 paragraphs, and the two research assistants achieve an intercoder agreement of 0.56. Although this indicates moderate reliability among human coders, it also serves as a benchmark to evaluate how well machine-based classification aligns with human judgments. Since the proposed approach is iterative and combines human expertise with automated methods, the goal is not to outperform human coders outright, but rather to harness the best of both approaches for more reliable frame classification."}, {"title": "Topic Modeling with 20 Newsgroup data set", "content": "For the topic modeling aspect of this study, the widely recognized 20 Newsgroup data set is used as a benchmark to evaluate the quality of the topic modeling algorithms. This data set contains 18,846 news articles, evenly distributed across 20 different categories, providing balanced coverage ideal for validating topic models at scale.\nWhile inspecting the corpus, I discovered 115 articles exceeding 4,096 tokens, partly due to extensive code, HTML fragments, XML headers, or other non-standard text elements. Since LLaMA 3 has a maximum context window of 4,096 tokens, summarization could not be guaranteed for texts that surpass this limit. Moreover, 53 of these long articles originate from the category \"comp\" (computer), featuring large sections of raw hex code or HTML artifacts that contribute little to meaningful textual content. As a result, these 115 articles were excluded from the analysis.\nUnlike the frame analysis data set, the 20 Newsgroup data set allows for validation using the entire data set due to its comprehensive labeling and established use as a benchmark for topic modeling. This enables a thorough evaluation of the topic modeling methods without the constraints of sample-based validation, thus enhancing the robustness and credibility of my findings."}, {"title": "Results", "content": "The proposed methodology was applied to European Parliamentary Debates on artificial intelligence (AI), which included 133 debates, 5,019 speeches, and 19,538 sentences. The Open Source Large Language Model (LLM) generated concise summaries for each sentence to capture critical themes.\nInitially, LLM identified 83 potential frames related to AI, such as AI Benefits, AI Risks, and AI Ethics. Recognizing overlaps and less relevant frames, a refinement process was conducted through human review, focusing on theoretical relevance and clarity. This led to a distilled list of 11 distinct frames: AI Benefits, AI Risks, AI Ethics, AI Regulation, AI Impact, AI Innovation, AI Development, AI Potential, AI Limitations, AI Concerns, and No Frame.\nTo assess the reliability and validity of the classification approach, I performed a validation using a random sample of 1200 sentences from the data set. Two research assistants coded the sentences independently, achieving an intercoder agreement (Krippendorff's Alpha) of 0.73 for detecting the presence of any frame and 0.6 for classifying specific frames. These metrics indicate acceptable reliability, providing a benchmark for evaluating the LLM's performance. This results in 996 usable sample sentences to validate the LLM on 1."}, {"title": "Frame Analysis on News Articles covering Encryption", "content": "The second data set focuses on how encryption is framed within the US, providing a second opportunity to test the effectiveness of the proposed method in a different setting. The initial output of the model includes an extensive list of frames, some of which overlap or are not directly relevant to the focus on encryption as a single issue topic. This underscores the need for careful human oversight to ensure that the selected frames are conceptually distinct and relevant to the debate on encryption. Through iterative refinement, one can distill the list down to a set of mostly mutually exclusive frames, avoiding redundancy while capturing the diverse ways encryption is discussed in the media. The main advantage of this frame-generation process is that it provides a researcher with an exhaustive list of possible frames measured in the data. This allows for a more manageable selection of a set of frame classes without missing important frames that could be left out.\nThis refinement process leads to the selection of frame classes that are both theoretically grounded and empirically relevant. Enabling a nuanced analysis of how encryption is framed in the news landscape of the USA. The final set of frame classes provides a coherent structure for examining encryption's competing narratives and priorities, including security, privacy, ethics, public safety, and moral evaluations. The generation of generative frames suggests all of these frames to a great degree, as they are found over many sampling iterations.\nBuilding on the model's suggestions and refining them further, I identified eleven keyframe classes to analyze how encryption is portrayed in the news media. Governmental Control, Corporate Power, Accountability Issues, Privacy vs. Security, Privacy, Security, Surveillance Concerns, National Security, Encryption Risks, Encryption Threats, and Other Frames. These categories capture the range of perspectives and narratives surrounding encryption, allowing a systematic examination of media frames that reflects the complexities and nuances of public discourse on"}]}