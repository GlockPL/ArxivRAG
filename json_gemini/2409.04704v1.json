{"title": "A Multi-scenario Attention-based Generative Model for Personalized Blood Pressure Time Series Forecasting", "authors": ["Cheng Wan", "Chenjie Xie", "Longfei Liu", "Dan Wu", "Ye Li"], "abstract": "Continuous blood pressure (BP) monitoring is essential for timely diagnosis and intervention in critical care settings. However, BP varies significantly across individuals, this inter-patient variability motivates the development of personalized models tailored to each patient's physiology. In this work, we propose a personalized BP forecasting model mainly using electrocardiogram (ECG) and photoplethysmogram (PPG) signals. This time-series model incorporates 2D representation learning to capture complex physiological relationships. Experiments are conducted on datasets collected from three diverse scenarios with BP measurements from 60 subjects total. Results demonstrate that the model achieves accurate and robust BP forecasts across scenarios within the Association for the Advancement of Medical Instrumentation (AAMI) standard criteria. This reliable early detection of abnormal fluctuations in BP is crucial for at-risk patients undergoing surgery or intensive care. The proposed model provides a valuable addition for continuous BP tracking to reduce mortality and improve prognosis.", "sections": [{"title": "I. INTRODUCTION", "content": "Continuous monitoring of blood pressure (BP) is crucial in critical care settings such as operating rooms and intensive care units [1]. Sudden BP changes can signal patient deterioration or adverse treatment responses [2]. However, intermittent cuff-based measurements may miss acute changes, driving research into cuffless BP estimation using physiological signals [3]. Generalized models have been developed but often fail to consider individual variations in BP regulation [4], making it difficult to achieve consistent performance in real-world applications. For instance, Slapni\u010dar et al. [5] proposed a PPG-based method with a mean absolute error (MAE) of 9.43 mmHg for systolic blood pressure (SBP), and Sun et al. [6] reported a standard deviation (SD) of 7.97 mmHg for SBP, highlighting the limitations in accuracy of generalized BP models. To address this, personalized BP estimation has gained increasing attention [7], [8]. Leitner et al. [7] developed a BP-CRNN-Transfer model using pre-training and fine-tuning, which improved prediction accuracy but involved complex steps unsuitable for clinical practice. Wang et al. [9] designed a lightweight personalized model for long-term BP tracking, though it was limited to a single scenario. Pediaditis et al. [10] demonstrated that individualized models significantly reduced errors compared to group-level models.\nIn this work, we propose a personalized BP forecasting model with high accuracy across diverse scenarios, utilizing electrocardiogram (ECG) and photoplethysmogram (PPG) signals. ECG provides cardiac activity data, while PPG captures peripheral vascular dynamics [5]. Combining these signals improves BP estimation accuracy [11], [12]. We frame BP forecasting as a time series modeling problem, aiming to predict future BP values based on past measurements. Accurate short-term forecasting enables early detection of critical changes in at-risk patients [13], allowing timely clinical intervention.\nThe main contributions of this work are:\n\u2022\nWe propose a BP prediction generative model effective in multiple medical scenarios, enabling non-invasive assessment and flexible prediction timing for earlier clinical intervention.\n\u2022\nWe introduce multi-domain feature fusion, incorporating time-domain and nonlinear features, providing richer information for improved BP forecasting accuracy.\n\u2022\nWe develop a personalized BP prediction model with an attention mechanism, allowing the model to focus on distinctive individual features for accurate short-term predictions."}, {"title": "II. METHOD", "content": "Datasets: We use three datasets with simultaneous ECG, PPG, and continuous BP recordings. The first is the Multi-states dataset collected in a laboratory, the second is the Intraoperative dataset from a local hospital, and the third is a subset of MIMIC-III waveforms [14]. Each dataset includes 20 subjects.\n1) Multi-states dataset: Five distinct interventions were utilized to enhance BP variations, including lying, sitting, deepbreathing, playing games, and hanggrip. Throughout the session, ECG, PPG, and BP signals were simultaneously captured at a sampling rate of 1000 Hz.\n2) Intraoperative dataset: Intraoperative clinical data, including ECG, PPG, and invasive BP signals, were collected from the hospital at a sampling rate of 250 Hz.\n3) MIMIC-III dataset: Subset of MIMIC-III includes ECG, PPG and BP signals recorded from ICU patients at a sampling rate of 125Hz.\nPreprocessing: ECG and PPG signals are preprocessed to remove noise and artifacts using techniques such as trend removal and outlier exclusion. Band-pass filtering removes baseline drift and high-frequency noises from ECG signals, with 5 Hz and 40 Hz as low and high cutoff frequencies respectively. PPG signals are low-pass filtered at 10 Hz cutoff to reduce noise.\nFeature extraction: A total of 38 features are extracted from the ECG and PPG signals. Time-domain features include pulse arrival time, its variation, heart rate, and morphological aspects like peaks, valleys, and peak-valley differences of PPG. ECG and PPG waveform features include mean, absolute sum, variance, square, and cross-correlation. Nonlinear features include fuzzy entropy. This multi-domain feature set comprehensively captures BP dynamics from the ECG and PPG data."}, {"title": "B. Time-series Forecasting Model for BP", "content": "To efficiently and accurately predict BP dynamics, we review state-of-the-art (SOTA) time series forecasting models, including Transformer [15], Informer [16], Autoformer [17], Pyraformer [18], Crossformer [19], and TimesNet [20]. Times-Net leverages 2D-variations of 1D time series data using convolutional neural networks for better representation learning.\nTo further enhance BP forecasting, we propose an improved architecture based on Inception, which efficiently captures data periodicity, making it ideal for physiological signals like ECG, PPG, and BP that follow cardiac cycles.\nWe propose the Time-series Attention-based Blood Pres-sure Forecast Network (TABNet), specifically designed for BP forecasting. TABNet integrates the Time-series Attention-based Block (TABBlock) module in Section II-C, reducing parameters and enhancing performance compared to the standard TimesNet. As shown in Figure 1, TABNet embeds preprocessed multi-domain ECG and PPG features into the TABBlock, followed by decoding and de-normalization to generate personalized BP predictions."}, {"title": "C. TABBlock", "content": "The physiological mechanism of blood pressure regulation varies among individuals. To predict BP in time series, the proposed TABBlock incorporates a parameter-free attention mechanism into the Inception module [21], [22], allowing the model to focus on distinct features like arterial stiffness, peripheral resistance, and cardiac output. This enables efficient individualized modeling while improving performance. Given the extracted ECG, PPG features, and BP time series $X_{FTS} \\in \\mathbb{R}^{L \\times M}$, where L is the number of heartbeat cycles and M is the number of extracted features, we first obtain feature rep-resentations via an embedding layer: $X_{FTS} = Embed(X_{FTS})$. For the l-th layer, the input is $X_{FTS}^{l-1} \\in \\mathbb{R}^{L \\times d}$, and the overall process is:\n\\begin{equation}\nX_{BP}^{1D} = \\bigoplus_{i=1}^{k} (X_{FTS}^{l-1} + TABBlock(X_{FTS}^{li}))\n\\end{equation}\nThe residual connection can make the signal transmitted in the deep network without attenuation or distortion, which is conducive to training the network. TABBlock contains two successive parts: capturing 2D variations of BP time series and adaptively aggregating representations.\nFirstly, we analyze the periodicity introduced by TimesNet [20], by applying Fast Fourier Transform (FFT) to this 1D input, we can get $A^{l-1}$, $r_i$, and $c_i$, which represents the amplitudes of all frequencies calculated, the top-k important frequencies, and length of each period, while $c_1 = 1$, as well as rows and columns of the following 2D tensor:\n\\begin{equation}\nA^{l-1} = Amp_{avg} (FFT(X_{FTS}^{l-1}))\n\\end{equation}\n\\begin{equation}\nr_k = arg Topk (A^{l-1})\nr \\in 1,\\dots,k\n\\end{equation}\nThe above process can be simplified as:\n\\begin{equation}\nA^{l-1,r_k,c_k} = FFT_{cal} (X_{FTS}^{l-1})\n\\end{equation}\nThis approach effectively extracts critical periodic character-istics from time-series data, crucial for the following analysis and forecasting temporal patterns.\nBased on the significant frequencies $r_i$ and length we get $c_i$ from $FFT_{cal}()$, we reshape the 1D time series into 2D tensors by this $Reshape()$ operation, the shift from 1D to 2D enables the use of convolutional layers for extracting spatial features and identifying periodic trends in time-series data, enhancing the model's predictive accuracy:\n\\begin{equation}\nX_{FTS2D}^{li} = Reshape_{c_i r_i} (X_{FTS}^{l-1}), i \\in 1,\\dots,k\n\\end{equation}\nThen, we apply the improved Inception module incorpo-rated with an attention mechanism in TABBlock to enhance feature learning. Unlike TimesNet which processes all fea-tures uniformly, the added attention layer enables focusing on informative components for more effective representation learning. Meanwhile, reducing model dimensionality improves efficiency. The attention-based lightweight TABBlock archi-tecture improves prediction performance while maintaining high computational efficiency.\n\\begin{equation}\nZ_{att}^{li} = Conv2D(ReLU(Conv2D(X_{FTS2D}^{li})))\n\\end{equation}\n\\begin{equation}\nX_{FTS2D}^{li} = AttInception(X_{FTS2D}^{li}), i \\in 1,\\dots, k\n\\end{equation}\nWhere the $AttInception(.)$ module contains a lightweight attention layer to focus on informative features as shown in Figure 2. Finally, we transform the 2D features back to 1D.\n\\begin{equation}\nX_{FTS}^{li} = Reshape_{1, (c_i x r_i)}(X_{FTS2D}^{li}), i \\in 1,\\dots,k\n\\end{equation}\nFinally, we also use $Aggregation(.)$ module, which is the adaptive aggregation method used in TimesNet to first truncate $X_{FTS}^{li}$, and then fuse k truncated 1D output features $X_{FTS}^{li}$ based on the previously calculated frequency amplitude $A^{l-1}$ corresponding to different periods, and then pass them to the next layer.\n\\begin{equation}\nX_{BP}^{1D} = Aggregation(A^{l-1} \\times X_{FTS}^{li})\n\\end{equation}\nBy modeling the time series of BP in both time and non-linear domains, TABBlock can effectively learn multi-scale temporal patterns, thereby improving prediction performance."}, {"title": "III. EXPERIMENT", "content": "As for implementation details, the train, validation and test splits are set to 7:1:2 to enable testing with more data. The encoder input dimension is set to 39 (containing input signal features and BP values). All personalized models are trained for 10 epochs with a batch size of 4 and employ mean square error as loss function. The encoder input size is 39 to match the number of input features and BP. Adam optimizer is used for optimization with a learning rate of 1e-4. The topk hyperparameter is set to 5 to select the most dominant periodicities based on the FFT frequency distributions."}, {"title": "B. Metrics and Results", "content": "To analyze the generalization capability of TABNet across environments, we calculate the average MAE and SD for 20 subjects (60 in total) from each of the three distinct datasets. This allows us to examine whether the model meets AAMI standard consistently in diverse clinical scenarios.\nFor personalized models, we investigate the amount of in-dividual patient data needed for effective modeling by varying the training sequence length from 60 to 420 heartbeat cycles. The input length is fixed at 30 cycles, and the forecasting sequence lengths are set to 5, 10, and 20 cycles to assess both short- and long-term capabilities. As shown in Table I, longer training sequences reduce prediction errors, with MAE decreasing by up to 2.5 mmHg when using 420 cycles. This indicates that more data helps capture richer features, avoiding overfitting and improving BP forecasting. Additionally, longer prediction sequences show higher errors, consistent with time series forecasting principles. The best performance occurs when forecasting 5 heartbeat cycles with 420 training cycles, reaching 2.87 mmHg MAE and 2.55 mmHg SD on the MIMIC-III dataset. For the generalized model, the input length is fixed at 30 cycles. The experiments used data from 15 subjects for training and 5 for testing, with no overlap between sets.\nFor the intraoperative dataset, while the model meets AAMI standards, its performance is lower compared to the other datasets due to significant BP fluctuations, making it chal-lenging for TABNet to capture stable feature representations for accurate short-term BP predictions.\nOverall, these results validate that using individualized models with relatively less training data can achieve accurate real-time BP monitoring to meet clinical needs."}, {"title": "C. Ablation Study", "content": "In our comprehensive ablation study, we evaluate the per-formance of our TABNet model against a suite of SOTA time-series models including TimesNet [20], Transformer [23], Autoformer [17], Pyraformer [18], and Crossformer [19], these models are adapted and assessed for this specific task of per-sonalized blood pressure forecasting. Each model, including our TABNet, is tested using their respective standard configu-rations across three datasets. The training data comprises 420 cycles with an output length of 20 cycles, ensuring a consistent and fair basis for comparison.\nIn the comparative analysis, as detailed in Table II, we use grid search method [24] to find the best hyperparameters and corresponding best performance for each model, our TABNet notably excells, surpassing all the SOTA models adapted for the BP task, both in terms of MAE and SD. This perfor-mance reinforces the effectiveness of TABNet's architecture, especially its attention-based mechanism, in this specialized predictive context. The results not only demonstrate TABNet's superior capabilities but also establish its significant position in advanced time series modeling for personalized BP prediction."}, {"title": "IV. CONCLUSION", "content": "In this paper, we propose the personalized TABNet model for continuous BP forecasting in critical care. TABNet em-ploys attention-based time series modeling to capture physio-logical relationships within and across cardiac cycles. The 2D representation learning enhances periodic pattern modeling. TABNet demonstrates accurate short-term forecasting on di-verse clinical datasets, enabled by the tailored architecture and lightweight design allowing efficient training with limited indi-vidual data. TABNet meets AAMI standards consistently, ex-cept on two tasks using highly fluctuating intraoperative data. The proposed personalized framework provides a practical tool for early abnormal BP detection and timely intervention for at-risk patients. This can facilitate continuous non-invasive BP monitoring to reduce mortality and improve prognosis in clinical care."}]}