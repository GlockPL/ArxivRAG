{"title": "SPOCKMIP: Segmentation of Vessels in MRAs with Enhanced Continuity using Maximum Intensity Projection as Loss", "authors": ["Chethan Radhakrishnaa", "Karthikesh Varma Chintalapatia", "Sri Chandana Hudukula Ram Kumara", "Raviteja Sutrave", "Hendrik Matternb", "Oliver Speckb,d,e", "Andreas N\u00fcrnbergera,c,e", "Soumick Chatterjeea,c,f,*"], "abstract": "Identification of vessel structures of different sizes in biomedical images is crucial in the diagnosis of many neurodegenerative diseases. However, the sparsity of good-quality annotations of such images makes the task of vessel segmentation challenging. Deep learning offers an efficient way to segment vessels of different sizes by learning their high-level feature representations and the spatial continuity of such features across dimensions. Semi-supervised patch-based approaches have been effective in identifying small vessels of one to two voxels in diameter. This study focuses on improving the segmentation quality by considering the spatial correlation of the features using the Maximum Intensity Projection (MIP) as an additional loss criterion. Two methods are proposed with the incorporation of MIPs of label segmentation on the single (z-axis) and multiple perceivable axes of the 3D volume. The proposed MIP-based methods produce segmentations with improved vessel continuity, which is evident in visual examinations of ROIs. In this study, a UNet MSS with ReLU activation replaced by LeakyReLU is trained on the Study Forrest dataset. Patch-based training is improved by introducing an additional loss term, MIP loss, to penalise the predicted discontinuity of vessels. A training set of 14 volumes is selected from the StudyForrest dataset comprising of 18 7-Tesla 3D Time-of-Flight (ToF) Magnetic Resonance Angiography (MRA) images. Then it is used to perform a five-fold cross-validation. The generalisation performance of the method is evaluated using the other unseen volumes in the dataset. It is observed that the proposed method with multi-axes MIP loss produces better quality segmentations with a median Dice of 80.245 \u00b1 0.129. Also, the method with single-axis MIP loss produces segmentations with a median Dice of 79.749 \u00b1 0.109. Furthermore, a visual comparison of the ROIs in the predicted segmentation reveals a significant improvement in the continuity of the vessels when MIP loss is incorporated into training.", "sections": [{"title": "1. Introduction", "content": "Segmentation of vessels on 7T magnetic resonance angiography (MRA) is one of the most important tasks in the analysis of biomedical images, as it provides essential information for the diagnosis and treatment of cerebrovascular diseases. An enhanced signal-to-noise ratio offered by 7T MRA allows for superior visualisation of cerebral vessels, revealing a higher proportion of small vessels compared to 1.5T or 3T MRAs [1]. The intricacies of small vessel structures complicate the segmentation process. Manual segmentation is labour-intensive and often leads to errors due to the challenging nature of the task. Machine learning (ML), specifically deep learning (DL), has shown promise in automating and improving the accuracy of vessel segmentation [1]. Despite its potential, deep learning in 7T MRA vessel segmentation is hindered by the need for extensive and expert-driven annotations. The manual segmentation process, necessary for training these models, is time-consuming and labour-intensive, especially given the intricacy of vessel structures in 7T MRAs. DS6 [2], a semi-supervised deep learning approach, attempts to mitigate this issue by learning from a small dataset with noisy annotations. Although this method successfully segments vessels as small as one to two voxels in diameter, it does not always produce segmentations that preserve the continuity of the vessels. Current research focuses on improving the continuity of vessels by considering the spatial correlation of pixels across dimensions.\nFor high-resolution 3D 7T MRA, creating ground truth annotations without imperfections is challenging. Usually, manual, semi-automatic, or classic vesselness segmentations are used to create training labels. However, these imperfections in training labels can reduce the performance of the trained deep learning network. In particular, if single voxels or small clusters are missed in the training labels, discontinuities in the deep learning-based vessel segmentation can occur. To overcome"}, {"title": "1.1. Related Work", "content": ""}, {"title": "1.1.1. Vessel segmentation using manual and non-DL based methods", "content": "To distinguish between vessels and non-vessels, experts assign each voxel a value of 0 for non-vessels and 1 for vessels. The detection of the lenticulostriate arteries (LSA) is one of the key tasks in this study, which includes the annotation of large and small vessels. Unlike detecting large vessels, perceiving the gaps between these vessels consisting of extremely small vessels (LSA) is difficult for the human eye. Therefore, manual segmentation procedures are biased towards the perspectives and expertise of the individual performing the annotations. The need to annotate a large number of voxels precisely to render segmentations of the 3D volume makes the task time-consuming.\nThe Frangi [3] filter is designed to enhance blood vessels and other tubular structures with the eventual goal of vessel segmentation by improving contrast and reducing noise. The approach is based on Hessian eigenvalues, which are instrumental in the vessel contrast enhancement and suppression of non-vascular structures. However, this method requires significant parameter tuning to identify small vessels of interest. Occasionally, these parameters need to be manually fine-tuned according to each dataset and volume.\nThe 'Openly available sMall vEsseL sEgmenTaTion pipelinE' (OMELETTE)\u00b9 [4] method focuses on segmenting images based on thresholds. The voxels above a certain threshold are considered vessels, and the rest are considered as background. Hysteresis thresholding is employed as it helps maintain vessel continuity by considering voxels above the lower threshold if they are connected to the vessels with higher thresholds. Additionally, Jerman's filter is used to apply Jerman's vessel response function, which is based on the volume ratio of the Hessian matrix eigenvalues."}, {"title": "1.1.2. Vessel segmentation using deep learning techniques", "content": "Convolutional Neural Networks (CNN) have been extensively used for computer vision and image processing tasks. The high-level feature representations learnt using such networks can be efficiently used as segmentation boundaries. However, the biomedical image segmentation task presents"}, {"title": "1.1.3. Maximum intensity projection", "content": "Maximum intensity projection (MIP) is used to visualise hyperintense structures in a 3D volume as a 2D projection, where, for each projection trace, only the voxel with the highest intensity is shown in the final 2D MIP. [8] hypothesises that a higher proportion of vessel structure is apparent in the MIPs as opposed to the 3D volumes and this can be exploited in cerebrovascular segmentation. MIPs have also been instrumental in the detection of pathologies. [9] and [10] demonstrated the use of MIPs of dynamic contrast-enhanced MRIs in detecting and classifying breast lesions. Furthermore, studies by [11] and [12] have shown that MIPs can be instrumental in detecting pulmonary nodules and qualitative analysis of intracranial vascularity. In the current study, the authors hypothesise that the MIP of the 3D MRA annotations can be used to improve the UNet-MSS [7, 2] network's perception of vessel continuity."}, {"title": "1.2. Contributions", "content": "This attempts to tackle the problem of vessel continuity in deep learning-based segmentation models by introducing a novel approach by incorporating maximum intensity projection (MIP) as an additional loss criterion. Two versions of the proposed loss term have been explored here and have been employed on two different deep learning models and evaluated for overall segmentation quality, underlying vasculature, and vessel continuity. This advancement has significant potential to improve the precision and reliability of vessel segmentation in neuroimaging, thereby contributing to the better diagnosis and treatment of cerebrovascular diseases, especially small vessel disorders."}, {"title": "2. Methodology", "content": ""}, {"title": "2.1. Proposed Approach: SPOOCKMIP", "content": "This paper proposes SPOCKMIP\u00b2 method, that uses the same architecture of UNet-MSS model from the DS6 research [2] with a replacement of the activation function from ReLU to LeakyReLU, and enhances the patch-based training pipeline by introducing the MIP comparisons as an additional loss term, as shown in the Fig. 1. The MIPs of the predictions for each patch at each level of UNet-MSS are computed. The predicted patch MIPs are then compared with their corresponding patches in the respective label MIPs to evaluate the MIP loss, $L_{MIP}(\\theta)$ as shown in Eq (4) and the Fig. 2a."}, {"title": "2.1.1. Maximum intensity projection loss along the slice-dimension", "content": "In addition to the Multi-Scale Supervision (MSS) Loss, the spatial continuity of the vessels along the z-axis (i.e. the slice dimension) is incorporated into the learning in the form of the MIP loss. Eq. 1 represents the total loss, which is a weighted sum of the MSS loss $L_{MSS}(\\theta)$ and the MIP loss $L_{MIP}(\\theta)$ with weight parameter $\u00b5$ and network parameter $\u03b8$. Eq. 2 represents the MSS loss where $m$ refers to the total up-sampling scales, and $\u03b1_i$ is the weight assigned to the loss at a specific up-sampling"}, {"title": "2.1.2. Cumulative maximum intensity projection loss across multiple axes", "content": "The authors propose an additional hypothesis that the continuity of vessel structures can be better perceived by analysing MIPs of the volume across multiple axes. This is achieved by comparing the MIP of the network's 3D patch predictions against the corresponding patches of MIPs of 3D labels across three different views, as shown in Fig. 2b. Therefore, the overall MIP loss is calculated as an equally weighted sum of the MIP loss along each axis, as shown in Eq. 5, where $\u03b2$ represents the"}, {"title": "2.1.3. Hypothesis", "content": "The authors hypothesise that the proposed modifications, which take into account the MIP of the volume, enhance the segmentation of small vessels and improve vessel continuity. This hypothesis is evaluated and the performance of the proposed methods is compared against the baseline approaches including UNet [5] and UNet-MSS [6] both in terms of segmentation quality using ROI comparisons and a quantitative evaluation with a set of standard vessel segmentation metrics."}, {"title": "2.2. Datasets and Labels", "content": "The proposed methodology was evaluated using the Study-Forrest\u00b3 dataset [?], comprising 7T MRA volumes of the brain acquired using 3D multi-slab Time-Of-Flight (TOF) Magnetic Resonance Angiography (MRA) with a resolution of 300\u00b5m of 20 participants. These volumes were divided into three subsets: the training set included 12 volumes, the validation set included four volumes, and the testing set included four volumes. The StudyForrest dataset includes two volumes with phase wrap-around artefacts (Fig. 3), which are regularly observed MR artefacts that occur when the dimensions of the body part being imaged exceed the defined Field of View (FOV). Those two volumes with these artefacts were discarded from the training as they hindered learning by increasing noise, and they were used for additional evaluations."}, {"title": "2.2.1. Label preparation", "content": "The labels for the test volumes were manually annotated and verified by a neurologist, while the labels for the training and validation sets were created in a semi-automated fashion using Ilastik [14] and the 3D slicer [15]. After annotating the volumes using Ilastik, the MIP of the original volume along the slice dimension was used to validate the accuracy. The resulting segmentation had thicker labels along with abundant noise in the skull region. The label thickness was reduced by annotating the outlining pixels of the vessel labels by non-vessel labels. To minimise skull noise, the noisy skull region was removed by retaining the prominent vessels using 3D slicer. Skull vessels were annotated separately in Ilastik and combined with the prominent vessels mentioned earlier. These methods resulted in accurate segmented volumes with minimal noise. The area opening and area closing morphological methods provided by the scikit-image library were then applied to reduce noise and improve vessel continuity, respectively. The area opening operation was fine-tuned with an area threshold of seven and a connectivity value of two, followed by an area closing operation with an area threshold of sixty and a connectivity value of four."}, {"title": "2.3. Experimental Setup", "content": "A 5-fold cross-validation is performed on 14 volumes, where each fold comprises three volumes for validation, while the rest are used for training. The generalisation performance of the thus trained models is evaluated using the held-out test set comprising the remaining four unseen volumes (three volumes were free of wrap-around artefacts, while one volume had such artefact). 3D MRA volumes with dimensions of 480x640x163 were converted to 3D patches of 64\u00b3. 8000 such patches from the 11 training volumes are randomly selected on each epoch for training. All experiments were performed with a 32GB Nvidia Tesla V100-SXM2 GPU with 10 CPUs and 60 GB RAM.\nSRDataset is used to prepare the dataset of patches for training and validation. The dataset was adapted to identify, for each patch, the corresponding location of the patch on the MIP of the segmentation label using the patch coordinates. Thus, it returns the patch, the corresponding label patch, and the corresponding label MIP patch on each load. All experiments were performed with a learning rate of 0.0001 over 50 epochs. Focal Tversky Loss [13] was used as a loss function for the calculation of both supervised loss (MSS loss) and MIP loss. These were optimised during training using the Adam optimiser [16]. Additionally, Automatic Mixed Precision (AMP) and gradient clipping techniques were employed to reduce memory requirements and to prevent exploding gradients."}, {"title": "2.3.1. Hyperparameters", "content": "Table 1 shows the set of different hyperparameters and their optimal values selected based on initial experiments, memory constraints, and the previous study [2]. The large 3D MRA volumes were divided into 3D patches of equal dimensions to facilitate memory-efficient learning while also increasing the number of samples per epoch. In each training iteration, a set of patches was chosen from different training volumes at random and supplied to the network. Taking into account the underlying limitation of the GPU and the size of the dataset used for the experiments, the batch size was set to 15, and the patch dimensionality was set to 64\u00b3.\n3D patches were created using SRDataset, where the coordinates of the patches are determined by traversing the 3D volume with an arbitrary stride. The dimensions of this stride were set"}, {"title": "2.3.2. Loss coefficients", "content": "The complexity of learning the optimal objective function using deep learning models increases with the number of optimisation criteria. Here, the network is essentially optimising two objectives: voxel similarity loss (MSS loss) and maximum intensity projection loss (MIP loss). The proposed approach for this multi-objective optimisation is to optimise the weighted sum of the two losses. The hyperparameter u in Eq. (1) is added as an additional network parameter with an initial value of 0.7,"}, {"title": "2.4. Evaluation", "content": "The segmentation results are quantitatively evaluated against the manually segmented ground truth in terms of the overall segmentation score using Dice Coefficient (Dice), Area under ROC Curve (AUC), and Sensitivity. In addition, the underlying structure of the vessels and the parts of the vessels identified are evaluated using Volumetric Similarity Coefficient (VS),"}, {"title": "3. Results", "content": ""}, {"title": "3.1. Quantitative Evaluation", "content": "A test set, comprising four 7T MRA volumes, is used to evaluate the 5-fold cross-validated models of each approach. One of the volumes in this set contains wrap-around artefacts, which affect the objective quantitative evaluation of the segmentation. Therefore, the resulting comparisons are presented in two categories: with and without the volume containing the aforementioned artefacts."}, {"title": "3.1.1. On test set without wrap-around artefacts", "content": "The median and variance over 15 segmentation results obtained from a 5-fold cross-validation (three volumes of the test set without wrap-around artefacts, evaluated over five folds, resulting in 15 segmentation results in total) are used to compare the performance of the methods. These results are reported in Table 2 and presented using violin plots in Fig. 5.\nThe overall segmentation scores, presented in Table 2a, show improvements with the incorporation of MIP loss compared to their baseline counterparts. It is evident from the Dice score comparisons that the UNet mMIP method clearly outperforms the baselines, with a median Dice score of 80.245 \u00b1 0.129. The AUC and sensitivity comparisons also show that the proposed MIP loss improves segmentation performance. The improvements are considerably greater in the case of the baseline UNet compared to the UNet MSS. The multi-axes UNet mMIP method outperforms its baseline, with a median AUC of 0.867 \u00b1 0.001.\nFurthermore, the volumetric comparisons of the identified vasculature are presented in Table 2b, and they also demonstrate improvements over the baselines with the addition of MIP loss. The UNet model with multi-axes MIP loss, UNet mMIP, outperforms the baselines and other proposed MIP-based methods, with a median score of 0.898 \u00b1 0.003. The comparison of the MHD metric shows that the UNet MSS mMIP method exploits voxel correlations better than the baselines and other proposed methods."}, {"title": "3.1.2. On test volume with wrap-around artefacts", "content": "The presence of wrap-around artefacts observed in one volume, as shown in Fig. 3, results in over-segmentation of the vessels on the skull and disrupts vessel boundaries, thus disregarding the continuity of the vessels in the vicinity of the artefacts. The authors evaluated the models separately only on this volume across five folds to assess the robustness of these models against such artefacts.\nComparison of the overall segmentation scores tabulated in Table 3a shows that the proposed UNet MSS mMIP method"}, {"title": "3.2. Qualitative Evaluation", "content": "The qualitative evaluation was performed by selecting five regions of interest (ROI) exhibiting notable presence of lenticulostriate arteries, as depicted in Fig. 6. The ROIs are marked with five different colours on the MIP of one of the test volumes, and their respective segmentations resulting from baselines and proposed approaches are also tabulated. Vessels in red and blue denote false negatives and false positives, respectively, while white denotes correctly segmented vessels. Yellow circles mark the notable differences among the different methods. The annotations on the ROIs of the segmentation results of the baselines (UNet and UNet MSS) show the discontinuity of the vessels. Visual comparison of these ROIs against their single-axis MIP counterparts reveals improved vessel continuity. It is also evident that the models with multi-axes MIP loss prevail over the baselines. The ROI comparisons between single-axis and multi-axes MIP-based models show a reduction in false positives. This is also evident in Fig. 7, especially in the skull. ROIs show that the multi-axes MIP-based models appear to over-segment the vessels. However, a closer look at the MIP of the input volume reveals that these overextensions are still part of the vessel, which is absent in the ground truth."}, {"title": "4. Conclusion", "content": "This paper proposed a MIP-based loss term to improve vessel continuity and overall segmentation performance of deep learning models, and evaluated this loss term on two different deep learning models. It was demonstrated that the proposed MIP-based methods outperform the baselines, both quantitatively and qualitatively. The generated segmentations not only show improvement in the continuity of the vessels, but also identify structures of small vessels that were missed in the resulting segmentations from the baselines. It was observed from experiments that the voxel similarity loss (MSS loss) retains a higher importance compared to the MIP loss, as learning suffers if voxel intensity comparisons inherent in MSS loss are insufficient. Between the two types of MIP losses explored here - single- and multi-axes - the single-axis is more stable and widely applicable to different models, while the multi-axes might be advantageous for some and over-regularise other models. Overall, the UNet model with multi-axes MIP outperformed all other models (including the baselines), resulting in a Dice score of 80.245\u00b10.129 compared.\nIn future work, the authors propose the exploration of volumetric MIP loss replacing the patch-based MIP loss proposed here for training the model. The hypothesis is that this would allow the network to perceive complex vessel structures that are missing in the partial information available in a patch. Furthermore, the merits of incorporating MIP information in semi-supervised learning approaches, such as deformation-aware learning [2], can also be a future direction for exploration."}], "equations": ["Loss(0) = \u00b5Lmss (0) + (1 \u2212 \u03bc)LMIP(0)", "m\\nLMSS (0) =  \u03a3\u03b1\u03bb(0)\\ni=1", "Lmipi(0) = almipi(0)", "lmip(0) = loss(MIP(\u0177), y \u2286 MIP(Y))", "LMIP(0) = \u03b2 \u03a3 \u03b1;(Imipx,i(0) + Imipy,i(0) + Imipzi(0))", "Dice(A, B) = 2|A \u2229 B |/|A| + |B|", "AUC = \u222b TPR(t) dFPR(t)", "Sensitivity = TP/TP + FN", "VS = 1- VA - VB/VA + VB", "MI(A, B) = \u03a3\u03a3 p(a, b) log p(a, b)p(a)p(b)", "MHD(A, B) = \u221a(A \u2013 \u0392)\u03a4\u03a3\u22121(A \u2013 B)"]}