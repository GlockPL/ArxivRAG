{"title": "SPOCKMIP: Segmentation of Vessels in MRAs with Enhanced Continuity using Maximum Intensity Projection as Loss", "authors": ["Chethan Radhakrishnaa", "Karthikesh Varma Chintalapatia", "Sri Chandana Hudukula Ram Kumara", "Raviteja Sutrave", "Hendrik Mattern", "Oliver Speck", "Andreas N\u00fcrnberger", "Soumick Chatterjee"], "abstract": "Identification of vessel structures of different sizes in biomedical images is crucial in the diagnosis of many neurodegenerative diseases. However, the sparsity of good-quality annotations of such images makes the task of vessel segmentation challenging. Deep learning offers an efficient way to segment vessels of different sizes by learning their high-level feature representations and the spatial continuity of such features across dimensions. Semi-supervised patch-based approaches have been effective in identifying small vessels of one to two voxels in diameter. This study focuses on improving the segmentation quality by considering the spatial correlation of the features using the Maximum Intensity Projection (MIP) as an additional loss criterion. Two methods are proposed with the incorporation of MIPs of label segmentation on the single (z-axis) and multiple perceivable axes of the 3D volume. The proposed MIP-based methods produce segmentations with improved vessel continuity, which is evident in visual examinations of ROIs. In this study, a UNet MSS with ReLU activation replaced by LeakyReLU is trained on the Study Forrest dataset. Patch-based training is improved by introducing an additional loss term, MIP loss, to penalise the predicted discontinuity of vessels. A training set of 14 volumes is selected from the StudyForrest dataset comprising of 18 7-Tesla 3D Time-of-Flight (ToF) Magnetic Resonance Angiography (MRA) images. Then it is used to perform a five-fold cross-validation. The generalisation performance of the method is evaluated using the other unseen volumes in the dataset. It is observed that the proposed method with multi-axes MIP loss produces better quality segmentations with a median Dice of 80.245 \u00b1 0.129. Also, the method with single-axis MIP loss produces segmentations with a median Dice of 79.749 \u00b1 0.109. Furthermore, a visual comparison of the ROIs in the predicted segmentation reveals a significant improvement in the continuity of the vessels when MIP loss is incorporated into training.", "sections": [{"title": "1. Introduction", "content": "Segmentation of vessels on 7T magnetic resonance angiography (MRA) is one of the most important tasks in the analysis of biomedical images, as it provides essential information for the diagnosis and treatment of cerebrovascular diseases. An enhanced signal-to-noise ratio offered by 7T MRA allows for superior visualisation of cerebral vessels, revealing a higher proportion of small vessels compared to 1.5T or 3T MRAs [1]. The intricacies of small vessel structures complicate the segmentation process. Manual segmentation is labour-intensive and often leads to errors due to the challenging nature of the task. Machine learning (ML), specifically deep learning (DL), has shown promise in automating and improving the accuracy of vessel segmentation [1]. Despite its potential, deep learning in 7T MRA vessel segmentation is hindered by the need for extensive and expert-driven annotations. The manual segmentation process, necessary for training these models, is time-consuming and labour-intensive, especially given the intricacy of vessel structures in 7T MRAs. DS6 [2], a semi-supervised deep learning approach, attempts to mitigate this issue by learning from a small dataset with noisy annotations. Although this method successfully segments vessels as small as one to two voxels in diameter, it does not always produce segmentations that preserve the continuity of the vessels. Current research focuses on improving the continuity of vessels by considering the spatial correlation of pixels across dimensions.\nFor high-resolution 3D 7T MRA, creating ground truth annotations without imperfections is challenging. Usually, manual, semi-automatic, or classic vesselness segmentations are used to create training labels. However, these imperfections in training labels can reduce the performance of the trained deep learning network. In particular, if single voxels or small clusters are missed in the training labels, discontinuities in the deep learning-based vessel segmentation can occur. To overcome"}, {"title": "1.1. Related Work", "content": ""}, {"title": "1.1.1. Vessel segmentation using manual and non-DL based methods", "content": "To distinguish between vessels and non-vessels, experts assign each voxel a value of 0 for non-vessels and 1 for vessels. The detection of the lenticulostriate arteries (LSA) is one of the key tasks in this study, which includes the annotation of large and small vessels. Unlike detecting large vessels, perceiving the gaps between these vessels consisting of extremely small vessels (LSA) is difficult for the human eye. Therefore, manual segmentation procedures are biased towards the perspectives and expertise of the individual performing the annotations. The need to annotate a large number of voxels precisely to render segmentations of the 3D volume makes the task time-consuming.\nThe Frangi [3] filter is designed to enhance blood vessels and other tubular structures with the eventual goal of vessel segmentation by improving contrast and reducing noise. The approach is based on Hessian eigenvalues, which are instrumental in the vessel contrast enhancement and suppression of non-vascular structures. However, this method requires significant parameter tuning to identify small vessels of interest. Occasionally, these parameters need to be manually fine-tuned according to each dataset and volume.\nThe 'Openly available sMall vEsseL sEgmenTaTion pipelinE' (OMELETTE) [4] method focuses on segmenting images based on thresholds. The voxels above a certain threshold are considered vessels, and the rest are considered as background. Hysteresis thresholding is employed as it helps maintain vessel continuity by considering voxels above the lower threshold if they are connected to the vessels with higher thresholds. Additionally, Jerman's filter is used to apply Jerman's vessel response function, which is based on the volume ratio of the Hessian matrix eigenvalues."}, {"title": "1.1.2. Vessel segmentation using deep learning techniques", "content": "Convolutional Neural Networks (CNN) have been extensively used for computer vision and image processing tasks. The high-level feature representations learnt using such networks can be efficiently used as segmentation boundaries. However, the biomedical image segmentation task presents the challenge of learning such representations using limited weak annotations. UNet [5] architecture proposes an end-to-end trainable network with a contracting path to learn high-resolution context information, followed by a symmetric expanding path that produces more precisely localised segmentation.\nUNet-based architectures have been proven to be efficient in the task of segmenting vessels. One such network is the UNet with Multi-Scale Deep Supervision (UNet MSS) [6, 7]. Zeng et.al. proposed a multi-scale loss to learn discriminative features at every level and computed the overall loss as the sum of losses at each up-sampling scale of the expansion path of the UNet. Using this architecture as the backbone, Chatterjee et.al. [2] proposed a semi-supervised deformation-aware learning approach for vessel segmentation with noisy labels. The limited annotated samples were augmented by subjecting them to random elastic deformations. The deformed samples were trained using a Siamese architecture based on UNet [5] and UNet-MSS [6, 7] models. The approach was based on the hypothesis that learning features at different scales help segment vessels of different sizes and that deformation awareness improves consistency given a small set of noisy samples."}, {"title": "1.1.3. Maximum intensity projection", "content": "Maximum intensity projection (MIP) is used to visualise hyperintense structures in a 3D volume as a 2D projection, where, for each projection trace, only the voxel with the highest intensity is shown in the final 2D MIP. [8] hypothesises that a higher proportion of vessel structure is apparent in the MIPs as opposed to the 3D volumes and this can be exploited in cerebrovascular segmentation. MIPs have also been instrumental in the detection of pathologies. [9] and [10] demonstrated the use of MIPs of dynamic contrast-enhanced MRIs in detecting and classifying breast lesions. Furthermore, studies by [11] and [12] have shown that MIPs can be instrumental in detecting pulmonary nodules and qualitative analysis of intracranial vascu-larity. In the current study, the authors hypothesise that the MIP of the 3D MRA annotations can be used to improve the UNet-MSS [7, 2] network's perception of vessel continuity."}, {"title": "1.2. Contributions", "content": "This attempts to tackle the problem of vessel continuity in deep learning-based segmentation models by introducing a novel approach by incorporating maximum intensity projection (MIP) as an additional loss criterion. Two versions of the proposed loss term have been explored here and have been employed on two different deep learning models and evaluated for overall segmentation quality, underlying vasculature, and vessel continuity. This advancement has significant potential to improve the precision and reliability of vessel segmentation in neuroimaging, thereby contributing to the better diagnosis and treatment of cerebrovascular diseases, especially small vessel disorders."}, {"title": "2. Methodology", "content": ""}, {"title": "2.1. Proposed Approach: SPO\u041e\u0421\u041a\u041c\u0406\u0420", "content": "This paper proposes SPOCKMIP2 method, that uses the same architecture of UNet-MSS model from the DS6 research [2] with a replacement of the activation function from ReLU to LeakyReLU, and enhances the patch-based training pipeline by introducing the MIP comparisons as an additional loss term, as shown in the Fig. 1. The MIPs of the predictions for each patch at each level of UNet-MSS are computed. The predicted patch MIPs are then compared with their corresponding patches in the respective label MIPs to evaluate the MIP loss, $L_{MIP}(\\theta)$ as shown in Eq (4) and the Fig. 2a."}, {"title": "2.1.1. Maximum intensity projection loss along the slice-dimension", "content": "In addition to the Multi-Scale Supervision (MSS) Loss, the spatial continuity of the vessels along the z-axis (i.e. the slice dimension) is incorporated into the learning in the form of the MIP loss. Eq. 1 represents the total loss, which is a weighted sum of the MSS loss $L_{MSS}(\\theta)$ and the MIP loss $L_{MIP}(\\theta)$ with weight parameter $\\mu$ and network parameter $\\theta$. Eq. 2 represents the MSS loss where m refers to the total up-sampling scales, and $\\alpha_i$ is the weight assigned to the loss at a specific up-sampling level. Eq. 3 represents the MIP loss that is calculated by comparing the MIP of the predicted segmentation of the patch $\\hat{y}$ against the subset of the MIP of the label segmentation Y encompassing the patch. The Focal Tversky loss [13] is used as the loss function for calculating all losses.\n\n$Loss(\\theta) = \\mu L_{MSS}(\\theta) + (1 - \\mu)L_{MIP}(\\theta)$\n\n$L_{MSS}(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\alpha_i l_{mss}(\\theta)$\n\n$L_{MIP}(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\alpha l_{mipi}(\\theta)$\n\n$l_{mip}(\\theta) = loss(MIP(\\hat{y}), y \\subseteq MIP(Y))$"}, {"title": "2.1.2. Cumulative maximum intensity projection loss across multiple axes", "content": "The authors propose an additional hypothesis that the continuity of vessel structures can be better perceived by analysing MIPs of the volume across multiple axes. This is achieved by comparing the MIP of the network's 3D patch predictions against the corresponding patches of MIPs of 3D labels across three different views, as shown in Fig. 2b. Therefore, the overall MIP loss is calculated as an equally weighted sum of the MIP loss along each axis, as shown in Eq. 5, where $\\beta$ represents the weight coefficient of the MIP loss across the x, y and z axes.\n\n$L_{MIP}(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\beta \\alpha_i (l_{mipx,i}(\\theta) + l_{mipy,i}(\\theta) + l_{mipz,i}(\\theta)) $"}, {"title": "2.1.3. Hypothesis", "content": "The authors hypothesise that the proposed modifications, which take into account the MIP of the volume, enhance the segmentation of small vessels and improve vessel continuity. This hypothesis is evaluated and the performance of the proposed methods is compared against the baseline approaches including UNet [5] and UNet-MSS [6] both in terms of segmentation quality using ROI comparisons and a quantitative evaluation with a set of standard vessel segmentation metrics."}, {"title": "2.2. Datasets and Labels", "content": "The proposed methodology was evaluated using the Study-Forrest\u00b3 dataset [?], comprising 7T MRA volumes of the brain acquired using 3D multi-slab Time-Of-Flight (TOF) Magnetic Resonance Angiography (MRA) with a resolution of 300\u00b5m of 20 participants. These volumes were divided into three subsets: the training set included 12 volumes, the validation set included four volumes, and the testing set included four volumes. The StudyForrest dataset includes two volumes with phase wrap-around artefacts (Fig. 3), which are regularly observed MR artefacts that occur when the dimensions of the body part being imaged exceed the defined Field of View (FOV). Those two volumes with these artefacts were discarded from the training as they hindered learning by increasing noise, and they were used for additional evaluations."}, {"title": "2.2.1. Label preparation", "content": "The labels for the test volumes were manually annotated and verified by a neurologist, while the labels for the training and validation sets were created in a semi-automated fashion using Ilastik [14] and the 3D slicer [15]. After annotating the volumes using Ilastik, the MIP of the original volume along the slice dimension was used to validate the accuracy. The resulting segmentation had thicker labels along with abundant noise in the skull region. The label thickness was reduced by annotating the outlining pixels of the vessel labels by non-vessel labels. To minimise skull noise, the noisy skull region was removed by retaining the prominent vessels using 3D slicer. Skull vessels were annotated separately in Ilastik and combined with the prominent vessels mentioned earlier. These methods resulted in accurate segmented volumes with minimal noise. The area opening and area closing morphological methods provided by the scikit-image library were then applied to reduce noise and improve vessel continuity, respectively. The area opening operation was fine-tuned with an area threshold of seven and a connectivity value of two, followed by an area closing operation with an area threshold of sixty and a connectivity value of four."}, {"title": "2.3. Experimental Setup", "content": "A 5-fold cross-validation is performed on 14 volumes, where each fold comprises three volumes for validation, while the rest are used for training. The generalisation performance of the thus trained models is evaluated using the held-out test set comprising the remaining four unseen volumes (three volumes were free of wrap-around artefacts, while one volume had such artefact). 3D MRA volumes with dimensions of 480x640x163 were converted to 3D patches of 643. 8000 such patches from the 11 training volumes are randomly selected on each epoch for training. All experiments were performed with a 32GB Nvidia Tesla V100-SXM2 GPU with 10 CPUs and 60 GB RAM.\nSRDataset is used to prepare the dataset of patches for training and validation. The dataset was adapted to identify, for each patch, the corresponding location of the patch on the MIP of the segmentation label using the patch coordinates. Thus, it returns the patch, the corresponding label patch, and the corresponding label MIP patch on each load. All experiments were performed with a learning rate of 0.0001 over 50 epochs. Focal Tversky Loss [13] was used as a loss function for the calculation of both supervised loss (MSS loss) and MIP loss. These were optimised during training using the Adam optimiser [16]. Additionally, Automatic Mixed Precision (AMP) and gradient clipping techniques were employed to reduce memory requirements and to prevent exploding gradients."}, {"title": "2.3.1. Hyperparameters", "content": "Table 1 shows the set of different hyperparameters and their optimal values selected based on initial experiments, memory constraints, and the previous study [2]. The large 3D MRA volumes were divided into 3D patches of equal dimensions to facilitate memory-efficient learning while also increasing the number of samples per epoch. In each training iteration, a set of patches was chosen from different training volumes at random and supplied to the network. Taking into account the underlying limitation of the GPU and the size of the dataset used for the experiments, the batch size was set to 15, and the patch dimensionality was set to 643.\n3D patches were created using SRDataset, where the coordinates of the patches are determined by traversing the 3D volume with an arbitrary stride. The dimensions of this stride were set"}, {"title": "2.3.2. Loss coefficients", "content": "The complexity of learning the optimal objective function using deep learning models increases with the number of optimisation criteria. Here, the network is essentially optimising two objectives: voxel similarity loss (MSS loss) and maximum intensity projection loss (MIP loss). The proposed approach for this multi-objective optimisation is to optimise the weighted sum of the two losses. The hyperparameter $\\mu$ in Eq. (1) is added as an additional network parameter with an initial value of 0.7, which is selected based on experimental results. It was found that the optimal value of the parameter learnt by the network was found to be 0.68. Further experiments showed that the learning suffered from under-fitting with reduced importance on MSS loss i.e., with $\\mu < 0.7$. On the other hand, a substantial increase in over-segmentation was observed with increasing weight on MIP loss, i.e., $\\mu > 0.7$. The weight coefficient $\\alpha$ associated with the MIP loss of each axis i in Eq. (5) was set to 0.33, implying equal importance for each axis. Several experiments were performed by assigning different importance to MIP loss at each axis, including a random assignment. These resulted in over-segmentation, ranging from overlapping vessel boundaries to identifying everything as vessels. The loss coefficient $\\beta$ in Eq. 5 was set to 0.3, similar to 1 \u2013 $\\mu$ in Eq. 1.\nSingle-axis MIP experiments. The coefficient $\\mu$ was set to 0.7 after a set of initial experiments. In addition, the hyperparameter was added as a parameter to the network, and the optimal value was found to be 0.68. ReLU activation was replaced by LeakyReLU to improve the optimisation of the combined losses. A higher weight was assigned to the MSS loss to learn the underlying vessel features.\nMulti-axis MIP Experiments. The SRDataset\u00b2 was adapted to compute the MIP of the labels across three dimensions of perception. The corresponding patches were identified and returned on each data load, along with the patch and its corresponding label patch. The MIP loss was computed as the sum of MIP loss along each axis, as shown in Eq. (5). Equal weights were assigned to the individual axis losses, and the coefficient $\\beta$ was set to 0.33 after initial experiments. The weight coefficient $\\mu$ was set to 0.7 for the overall sum of losses, as in Eq. (1)."}, {"title": "2.4. Evaluation", "content": "The segmentation results are quantitatively evaluated against the manually segmented ground truth in terms of the overall segmentation score using Dice Coefficient (Dice), Area under ROC Curve (AUC), and Sensitivity. In addition, the underlying structure of the vessels and the parts of the vessels identified are evaluated using Volumetric Similarity Coefficient (VS), Mutual Information (MI), and Mahalanobis Distance (MHD). The Dice Coefficient and Volumetric Similarity are instrumental in evaluating the overlap and volumetric precision of segmentations, while the AUC and Sensitivity provide critical insights into the model's discriminative power and its efficacy in accurately identifying true positives. Furthermore, the employment of Mutual Information and Mahalanobis Distance metrics captures both structural similarity and geometric accuracy. This judicious selection of diverse metrics ensures a robust and comprehensive assessment of segmentation quality, thereby significantly enhancing the model's reliability and applicability in the field.\nThe Dice Coefficient is a measure of overlap between two sets, A and B. For segmentation tasks, it can be defined as:\n\n$Dice(A, B) = \\frac{2|A \\cap B}{|A| + |B|}$\n\nwhere A and B are the sets of predicted and ground-truth segments, and | * | is the number of elements in that particular set. The Area Under the ROC Curve is a performance measurement for classification tasks (segmentation tasks can be considered as a pixel-wise classification task) at various threshold settings. The ROC is a probability curve and the AUC represents the degree or measure of separability. It is computed as:\n\n$AUC = \\int_{0}^{1} TPR(t) dFPR(t)$\n\nwhere TPR(t) and FPR(t) are the true positive and false positive rates at threshold t. Sensitivity, or recall, is the proportion of true positives correctly identified by the model and is computed as:\n\n$Sensitivity = \\frac{TP}{TP + FN}$\n\nwhere TP and FN are the number of true and false positives. The Volumetric Similarity Coefficient measures the similarity in volume between the predicted segmentation and the ground truth using:\n\n$VS = 1- \\frac{|V_A - V_B|}{|V_A + V_B|}$\n\nwhere $V_A$ and $V_B$ are the volumes of the predicted and ground-truth segments. Mutual Information (MI) measures the amount of information obtained about one random variable through the other random variable. For segmentation, it can be expressed as:\n\n$MI(A, B) = \\sum_{a\\in A} \\sum_{b\\in B} p(a, b) log \\frac{p(a, b)}{p(a)p(b)}$\n\nwhere $p(a, b)$ is the joint probability distribution of A and B, while $p(a)$ and $p(b)$ are the marginal probability distributions. The Mahalanobis Distance is a measure of the distance between a point and a distribution. For segmentation, it is used to measure the distance between the predicted segmentation and the ground truth:\n\n$MHD(A, B) = \\sqrt{(A \u2013 B)^T\\Sigma^{-1}(A \u2013 B)}$\n\nwhere A and B are the vectors of predicted and ground-truth segment coordinates, and $\\Sigma$ is the covariance matrix of the distribution.\nTo facilitate the calculation of the above-mentioned metrics, EvaluateSegmentation [17] tool was employed."}, {"title": "3. Results", "content": ""}, {"title": "3.1. Quantitative Evaluation", "content": "A test set, comprising four 7T MRA volumes, is used to evaluate the 5-fold cross-validated models of each approach. One of the volumes in this set contains wrap-around artefacts, which affect the objective quantitative evaluation of the segmentation. Therefore, the resulting comparisons are presented in two categories: with and without the volume containing the aforementioned artefacts."}, {"title": "3.1.1. On test set without wrap-around artefacts", "content": "The median and variance over 15 segmentation results obtained from a 5-fold cross-validation (three volumes of the test set without wrap-around artefacts, evaluated over five folds, resulting in 15 segmentation results in total) are used to compare the performance of the methods. These results are reported in Table 2 and presented using violin plots in Fig. 5.\nThe overall segmentation scores, presented in Table 2a, show improvements with the incorporation of MIP loss compared to their baseline counterparts. It is evident from the Dice score comparisons that the UNet mMIP method clearly outperforms the baselines, with a median Dice score of 80.245 \u00b1 0.129. The AUC and sensitivity comparisons also show that the proposed MIP loss improves segmentation performance. The improvements are considerably greater in the case of the baseline UNet compared to the UNet MSS. The multi-axes UNet mMIP method outperforms its baseline, with a median AUC of 0.867 \u00b1 0.001.\nFurthermore, the volumetric comparisons of the identified vasculature are presented in Table 2b, and they also demonstrate improvements over the baselines with the addition of MIP loss. The UNet model with multi-axes MIP loss, UNet mMIP, outperforms the baselines and other proposed MIP-based methods, with a median score of 0.898 \u00b1 0.003. The comparison of the MHD metric shows that the UNet MSS mMIP method exploits voxel correlations better than the baselines and other proposed methods."}, {"title": "3.1.2. On test volume with wrap-around artefacts", "content": "The presence of wrap-around artefacts observed in one volume, as shown in Fig. 3, results in over-segmentation of the vessels on the skull and disrupts vessel boundaries, thus disregarding the continuity of the vessels in the vicinity of the artefacts. The authors evaluated the models separately only on this volume across five folds to assess the robustness of these models against such artefacts.\nComparison of the overall segmentation scores tabulated in Table 3a shows that the proposed UNet MSS mMIP method outperforms the other baselines and the proposed methods in the presence of these artefacts, with a median Dice of 65.946 \u00b1 0.084 across five cross-validation folds. A similar trend is observed in the quantitative comparison of the vasculature, as shown in Table 3b.\nIncorporation of MIP loss is seen to improve overall segmentation scores with UNet and UNet MSS baselines. Table 3b shows a considerable improvement in the identification of the underlying vasculature when these baselines are trained with the proposed single- and multi-axes MIP loss. It is also observable that the multi-axes MIP loss outperforms the single-axis MIP loss counterparts in the presence of the artefacts.\nThe proposed UNet MSS mMIP is found to be the method with the best performance when evaluated on the volume with wrap-around artefacts. The multi-axes method also appears to outperform its single-axis counterpart both in terms of overall segmentation and the underlying vasculature."}, {"title": "3.2. Qualitative Evaluation", "content": "The qualitative evaluation was performed by selecting five regions of interest (ROI) exhibiting notable presence of lenticulostriate arteries, as depicted in Fig. 6. The ROIs are marked with five different colours on the MIP of one of the test volumes, and their respective segmentations resulting from baselines and proposed approaches are also tabulated. Vessels in red and blue denote false negatives and false positives, respectively, while white denotes correctly segmented vessels. Yellow circles mark the notable differences among the different methods. The annotations on the ROIs of the segmentation results of the baselines (UNet and UNet MSS) show the discontinuity of the vessels. Visual comparison of these ROIs against their single-axis MIP counterparts reveals improved vessel continuity. It is also evident that the models with multi-axes MIP loss prevail over the baselines. The ROI comparisons between single-axis and multi-axes MIP-based models show a reduction in false positives. This is also evident in Fig. 7, especially in the skull. ROIs show that the multi-axes MIP-based models appear to over-segment the vessels. However, a closer look at the MIP of the input volume reveals that these overextensions are still part of the vessel, which is absent in the ground truth."}, {"title": "4. Conclusion", "content": "This paper proposed a MIP-based loss term to improve vessel continuity and overall segmentation performance of deep learning models, and evaluated this loss term on two different deep learning models. It was demonstrated that the proposed MIP-based methods outperform the baselines, both quantitatively and qualitatively. The generated segmentations not only show improvement in the continuity of the vessels, but also identify structures of small vessels that were missed in the resulting segmentations from the baselines. It was observed from experiments that the voxel similarity loss (MSS loss) retains a higher importance compared to the MIP loss, as learning suffers if voxel intensity comparisons inherent in MSS loss are insufficient. Between the two types of MIP losses explored here - single- and multi-axes - the single-axis is more stable and widely applicable to different models, while the multi-axes might be advantageous for some and over-regularise other models. Overall, the UNet model with multi-axes MIP outperformed all other models (including the baselines), resulting in a Dice score of 80.245\u00b10.129 compared.\nIn future work, the authors propose the exploration of volumetric MIP loss replacing the patch-based MIP loss proposed here for training the model. The hypothesis is that this would allow the network to perceive complex vessel structures that are missing in the partial information available in a patch. Furthermore, the merits of incorporating MIP information in semi-supervised learning approaches, such as deformation-aware learning [2], can also be a future direction for exploration."}]}