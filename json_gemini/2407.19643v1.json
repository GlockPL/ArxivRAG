{"title": "Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for\nComputer Components Recommendation", "authors": ["Yunsheng Wang", "Songhao Chen", "Kevin Jin"], "abstract": "Knowledge graphs (KGs) are essential in applications such as network alignment,\nquestion-answering, and recommender systems (RSs) since they offer structured relational data that\nfacilitate the inference of indirect relationships. However, the development of KG-based RSs capable\nof processing user inputs in natural language faces significant challenges. Firstly, natural language\nprocessing units must effectively handle the ambiguity and variability in human language to interpret\nuser intents accurately. Secondly, the system must precisely identify and link entities, like product\nnames, to their corresponding nodes in KGs. To overcome these challenges, supported by Lenovo, we\ndeveloped a novel chatbot \"Prometheus\" integrating KG with a large language model (LLM),\nspecifically used for recommending computer components. This chatbot can accurately decode user\nrequests and deliver personalized recommendations derived from KGs, ensuring precise\ncomprehension and response to their computer setup needs.", "sections": [{"title": "1. Introduction", "content": "Knowledge Graph (KG) is a graph structure that contains a collection of facts, where nodes\nrepresent real-world entities, events and objects, and edges denote the relationship between two nodes\n(Fensel et al., 2020). Since its debut in 2012, various KGs have been generated, including Freebase,\nYago, Wikidata and so on (F\u00e4rber et al., 2018). The applications of KGs are numerous, ranging from\nnetwork alignment, and question-answering to recommender systems (RSs). Among these applications,\nKG-based RSs aim to process user inputs and provide related recommendations.\nThe core of any RS is its personalized recommendation algorithm. Traditional algorithms have\nachieved notable success and are generally divided into content-based filtering (Van Meteren et al.,\n2000), collaborative filtering (Herlocker et al., 2000), and hybrid filtering techniques (Basilico et al.,\n2004). Despite their successes, these traditional methods still face unresolved issues, such as sparse\nrelationships between users and items and the cold-start problem (Lika et al., 2014) encountered when\nrecommending to new users. Additionally, scaling these algorithms to meet the demands of real-world\nrecommendation scenarios presents a significant challenge. To address these limitations, researchers\nand engineers have incorporated auxiliary information into the RSs, including attribute characteristics\nof users and items (Wang et al., 2018, Wang et al., 2018, Wang et al., 2018), user social network\ninformation (Jamali & Ester, 2010), and multimedia information (e.g., texts (Wang et al., 2015), images\n(Zhang et al., 2016)). Notably, KGs offer a wealth of background information on items, revealing\nhidden relationships between them, which significantly enhances recommendation quality (Ji et al.,\n2021).\nRecently, RSs based on KGs have gained attention from both academia and industry, leading to\nthe development in numerous domains (Chicaiza et al., 2021). In the education domain, RSs are now a\ncritical area of research (Manouselis et al., 2011), with a particular focus on aiding learners by"}, {"title": "2. Proposed Method", "content": "The Prometheus chatbot integrates Knowledge Graph Construction, Natural Language Processing,\nand Chatbot design to create a completed recommender system for computer components. This system\nis built upon three main pillars: the Neo4j database for constructing the knowledge graphs, the Azure\nOpenAI service for processing natural language, and the Streamlit for building the Chatbot interface."}, {"title": "2.2 Knowledge Graph (KG) Construction", "content": "KG construction is an iterative engineering process that involves various methods and tools.\nThese approaches can be categorized into two main clusters: top-down and bottom-up.\nThe top-down approach is rooted in the modeling processes used in database construction. It\nbegins with identifying a subject domain and a list of research needs, followed by designing a\nconceptual model to collect the entities of interest, their inter-relationships, and the categories. Tools\nlike CmapTools are valuable for conceptual modeling. This is followed by creating logical and physical\nmodels that add logical representation and assertions to the collected entities and relationships. During\nthe technical development and implementation phase, important considerations include the coding\nlanguage (e.g., RDF and OWL), serialization formats (e.g., RDF/XML, Turtle, and JSON-LD), and KG\ndevelopment platforms such as Prot\u00e9g\u00e9 and DOGMA. The final step is deploying the KG as a service\nto allow community reuse and feedback, transforming domain knowledge into a machine-readable\nrepresentation.\nIn contrast, the bottom-up approach to KG construction relies on crowd-sourced data, such as\nsocial media and legacy literature. The expansion of social media and open access to published\nliterature has significantly increased data sources, leading to a rise in publications using this approach"}, {"title": "2.3 Prometheus Chatbot Design", "content": "The Streamlit application serves as a user-friendly front end for interacting with the KGs of\ncomputer components (Khorasani et al., 2022). This interface leverages the Azure OpenAI service to\nunderstand and process natural language queries, making the system highly intuitive and accessible\neven for users with limited technical knowledge.\nFeatures of the Prometheus Chatbot:"}, {"title": "2.3.1 Natural Language Processing with Azure OpenAI service:", "content": "Large language models (LLMs) demonstrate impressive capabilities in natural language\nprocessing, which are constructed using the transformer architecture. These models combine\nlarge-scale architectures with huge amounts of textual training data. This scaling up has allowed LLMs\nto understand and generate text at a level comparable to that of humans. Among them, ChatGPT\nemerged as the hottest topic on the Internet at the end of 2022 and established itself as a \"cultural\nsensation\". In this paper, we use Microsoft Azure OpenAI service to access the ChatGPT API for\nprocessing user-natural languages into Cypher queries. For example, users can input questions or\nqueries such as \"Please recommend me the power supply about GFX 3050.\" or \"What components are\nrecommended if I buy an intel i7 CPU?\" The LLM then interprets these queries and generates\nappropriate responses by referencing the KG we constructed. This integration enables the system to\nhandle various question formats and complexities, providing users with precise recommendations."}, {"title": "2.3.2 Search Functionality:", "content": "The search process begins with the user inputting a query, such as \"Tell me the GFX3050 T3 rule\nabout M70t Gen5.\" The LLM then extracts relevant keywords from the query, identified here as\n`['3050', 'M70t Gen5']`. These keywords are injected into the KG. The query seeks nodes whose `name`\nattribute contains '3050' and whose `project name` attribute contains 'M70t Gen5', returning the `T3\nrules attribute of the matching nodes. Finally, the system retrieves this information from the KG and\nprovides the answer to the user."}, {"title": "2.4 Workflow of the Prometheus Chatbot:", "content": "The user inputs a query in natural language via the Streamlit interface.\nThe LLM processes the input, interprets the user's intent, and formulates a query for the KG.\nThe system queries the Neo4j database to retrieve relevant nodes based on the processed query.\nThe LLM generates a user-friendly response to present the information.\nThe Prometheus Chatbot interface displays the results in tabular and graphical formats,\nallowing users to explore the data interactively.\nGenerally, we develop a novel tool that improves the precision of recommendations for computer\ncomponents. This system simplifies the process of finding compatible components and uses an LLM to\noffer recommendations that are context-aware and personalized."}, {"title": "3 Related Work", "content": "This step involves querying an SQLite database named T3.db, a proprietary database owned by\nLenovo, to retrieve rules for computer components. We focus on three specific types of rules: Text-rule,\nDerive, and Select. SQL queries are designed to fetch these rules with their associated metadata,\nensuring selection based on relevancy, rule type, and content. This stage is crucial for gathering the raw\ndata to populate our KG."}, {"title": "3.2 Knowledge Graph Construction", "content": "The cleaned data is then used to construct a KG using Neo4j. Nodes and relationships are created\nto represent components and their associated rules respectively. Each node consists of its name,\noriginal rule, rule index, type, project name, date, and owner. Relationships between nodes are defined\nbased on the rules, indicating compatibility (should/should not). The Neo4j database is populated with\nnodes and relationships. Take the \u201cDerive\u201d Type, for example, 32,776 nodes and 24,971 relationships\nare created."}, {"title": "3.3 Prometheus Chatbot Building", "content": "The chatbot is essential in connecting users with the RS and understandably presenting complex\ndata. In this section, we use Streamlit to construct the Prometheus chatbot for tabular data\nrepresentation (Khorasani et al., 2022). This design ensures that users can quickly comprehend and\ncompare different components, making it easier to determine what additional components are necessary\nfor their specific computer setup needs."}, {"title": "5 Discussion", "content": "Our work shows that integrating knowledge graphs (KGs) with large language models (LLMs)\ncan enhance recommender systems (RSs) efficiency. By combining database and graph-based\nvisualizations with natural language processing, our methodology deals with the complexities\nassociated with recommending computer components. The results show an improvement in the\nsystem's capability to offer precise and contextual suggestions. KGs enable structured and\ninterconnected data representation, which supports more refined reasoning and inference. Meanwhile,\nthe LLM allows users to formulate queries in natural language with high interpretative accuracy. This\ncombination is an advancement in KG-based RSs. We call this RS \u201cPrometheus\", a chatbot mainly\ndesigned for Lenovo internal use.\nHowever, challenges remain. Building an extensive KG demands great efforts to refresh and\nensure the accuracy of original data. In the future, we plan to broaden the reach of our KGs to contain\nmore components and complex rules. This expansion will further refine the capability of the\nPrometheus chatbot. Furthermore, the potential to apply our methodology to other sectors offers\npromising research opportunities. Industries with complex inventories, such as automotive, electronics,\nor healthcare, could also potentially benefit from our approach. The broader application of integrating\nKGs and LLMs underscores the future possibilities for AI-driven RSs.\""}, {"title": "6 Conclusion", "content": "In conclusion, our work shows the benefits of KG collaborative LLM in improving RSs.\nPrometheus has proved useful in the industry for better computer components recommendations."}, {"title": "7 Acknowledgments", "content": "This project was supported by the Lenovo Desktop Computing Development Lab.\nThe codes are available on GitHub:\nhttps://github.com/iamryanshengwang/Prometheus-Chatbot\nThe Lenovo database is not open access."}, {"title": "Competing Interests", "content": "The authors declare that they have no competing interests."}, {"title": "Authors Contribution Statement", "content": "Yunsheng Wang and Songhao Chen contributed equally to the conception and design of the study, data\ncollection, analysis, and interpretation. Yunsheng Wang drafted the manuscript. Kevin Jin provided the\ngrant and resources for the study. All authors reviewed and approved the final version."}, {"title": "Ethical and Informed Consent for Data Used", "content": "The data used in this study were sourced from Lenovo's proprietary databases. All necessary\npermissions were obtained from Lenovo to access and use this data for research purposes. As the data\ndoes not involve personal data, ethical approval and informed consent were not required."}, {"title": "Data Availability and Access", "content": "The codes used in this study are available on GitHub:\nhttps://github.com/iamryanshengwang/Prometheus-Chatbot.\nThe Lenovo database used for constructing the knowledge graphs is not open access due to proprietary\nrestrictions. Researchers interested in accessing the data can contact Desktop Computing Team Lead\nSonghao Chen: chensh8@lenovo.com for potential data sharing agreements."}]}