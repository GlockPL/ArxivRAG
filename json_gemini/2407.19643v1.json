{"title": "Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation", "authors": ["Yunsheng Wang", "Songhao Chen", "Kevin Jin"], "abstract": "Knowledge graphs (KGs) are essential in applications such as network alignment, question-answering, and recommender systems (RSs) since they offer structured relational data that facilitate the inference of indirect relationships. However, the development of KG-based RSs capable of processing user inputs in natural language faces significant challenges. Firstly, natural language processing units must effectively handle the ambiguity and variability in human language to interpret user intents accurately. Secondly, the system must precisely identify and link entities, like product names, to their corresponding nodes in KGs. To overcome these challenges, supported by Lenovo, we developed a novel chatbot \"Prometheus\" integrating KG with a large language model (LLM), specifically used for recommending computer components. This chatbot can accurately decode user requests and deliver personalized recommendations derived from KGs, ensuring precise comprehension and response to their computer setup needs.", "sections": [{"title": "1. Introduction", "content": "Knowledge Graph (KG) is a graph structure that contains a collection of facts, where nodes represent real-world entities, events and objects, and edges denote the relationship between two nodes (Fensel et al., 2020). Since its debut in 2012, various KGs have been generated, including Freebase, Yago, Wikidata and so on (F\u00e4rber et al., 2018). The applications of KGs are numerous, ranging from network alignment, and question-answering to recommender systems (RSs). Among these applications, KG-based RSs aim to process user inputs and provide related recommendations.\nThe core of any RS is its personalized recommendation algorithm. Traditional algorithms have achieved notable success and are generally divided into content-based filtering (Van Meteren et al., 2000), collaborative filtering (Herlocker et al., 2000), and hybrid filtering techniques (Basilico et al., 2004). Despite their successes, these traditional methods still face unresolved issues, such as sparse relationships between users and items and the cold-start problem (Lika et al., 2014) encountered when recommending to new users. Additionally, scaling these algorithms to meet the demands of real-world recommendation scenarios presents a significant challenge. To address these limitations, researchers and engineers have incorporated auxiliary information into the RSs, including attribute characteristics of users and items (Wang et al., 2018, Wang et al., 2018, Wang et al., 2018), user social network information (Jamali & Ester, 2010), and multimedia information (e.g., texts (Wang et al., 2015), images (Zhang et al., 2016)). Notably, KGs offer a wealth of background information on items, revealing hidden relationships between them, which significantly enhances recommendation quality (Ji et al., 2021).\nRecently, RSs based on KGs have gained attention from both academia and industry, leading to the development in numerous domains (Chicaiza et al., 2021). In the education domain, RSs are now a critical area of research (Manouselis et al., 2011), with a particular focus on aiding learners by"}, {"title": "2. Proposed Method", "content": ""}, {"title": "2.1 Model Overview", "content": "The Prometheus chatbot integrates Knowledge Graph Construction, Natural Language Processing, and Chatbot design to create a completed recommender system for computer components. This system is built upon three main pillars: the Neo4j database for constructing the knowledge graphs, the Azure OpenAI service for processing natural language, and the Streamlit for building the Chatbot interface."}, {"title": "2.2 Knowledge Graph (KG) Construction", "content": "KG construction is an iterative engineering process that involves various methods and tools. These approaches can be categorized into two main clusters: top-down and bottom-up.\nThe top-down approach is rooted in the modeling processes used in database construction. It begins with identifying a subject domain and a list of research needs, followed by designing a conceptual model to collect the entities of interest, their inter-relationships, and the categories. Tools like CmapTools are valuable for conceptual modeling. This is followed by creating logical and physical models that add logical representation and assertions to the collected entities and relationships. During the technical development and implementation phase, important considerations include the coding language (e.g., RDF and OWL), serialization formats (e.g., RDF/XML, Turtle, and JSON-LD), and KG development platforms such as Prot\u00e9g\u00e9 and DOGMA. The final step is deploying the KG as a service to allow community reuse and feedback, transforming domain knowledge into a machine-readable representation.\nIn contrast, the bottom-up approach to KG construction relies on crowd-sourced data, such as social media and legacy literature. The expansion of social media and open access to published literature has significantly increased data sources, leading to a rise in publications using this approach"}, {"title": "2.3 Prometheus Chatbot Design", "content": "The Streamlit application serves as a user-friendly front end for interacting with the KGs of computer components (Khorasani et al., 2022). This interface leverages the Azure OpenAI service to understand and process natural language queries, making the system highly intuitive and accessible even for users with limited technical knowledge.\nFeatures of the Prometheus Chatbot:"}, {"title": "2.3.1 Natural Language Processing with Azure OpenAI service:", "content": "Large language models (LLMs) demonstrate impressive capabilities in natural language processing, which are constructed using the transformer architecture. These models combine large-scale architectures with huge amounts of textual training data. This scaling up has allowed LLMs to understand and generate text at a level comparable to that of humans. Among them, ChatGPT emerged as the hottest topic on the Internet at the end of 2022 and established itself as a \"cultural sensation\". In this paper, we use Microsoft Azure OpenAI service to access the ChatGPT API for processing user-natural languages into Cypher queries. For example, users can input questions or queries such as \"Please recommend me the power supply about GFX 3050.\" or \"What components are recommended if I buy an intel i7 CPU?\" The LLM then interprets these queries and generates appropriate responses by referencing the KG we constructed. This integration enables the system to handle various question formats and complexities, providing users with precise recommendations."}, {"title": "2.3.2 Search Functionality:", "content": "The search process begins with the user inputting a query, such as \"Tell me the GFX3050 T3 rule about M70t Gen5.\" The LLM then extracts relevant keywords from the query, identified here as `['3050', 'M70t Gen5']`. These keywords are injected into the KG. The query seeks nodes whose `name` attribute contains '3050' and whose `project name` attribute contains 'M70t Gen5', returning the `T3 rules attribute of the matching nodes. Finally, the system retrieves this information from the KG and provides the answer to the user."}, {"title": "2.4 Workflow of the Prometheus Chatbot:", "content": "1. The user inputs a query in natural language via the Streamlit interface.\n2. The LLM processes the input, interprets the user's intent, and formulates a query for the KG.\n3. The system queries the Neo4j database to retrieve relevant nodes based on the processed query.\n4. The LLM generates a user-friendly response to present the information.\n5. The Prometheus Chatbot interface displays the results in tabular and graphical formats, allowing users to explore the data interactively.\nGenerally, we develop a novel tool that improves the precision of recommendations for computer components. This system simplifies the process of finding compatible components and uses an LLM to offer recommendations that are context-aware and personalized."}, {"title": "3 Related Work", "content": ""}, {"title": "3.1 Data Preprocessing", "content": "This step involves querying an SQLite database named T3.db, a proprietary database owned by Lenovo, to retrieve rules for computer components. We focus on three specific types of rules: Text-rule, Derive, and Select. SQL queries are designed to fetch these rules with their associated metadata, ensuring selection based on relevancy, rule type, and content. This stage is crucial for gathering the raw data to populate our KG."}, {"title": "3.2 Knowledge Graph Construction", "content": "The cleaned data is then used to construct a KG using Neo4j. Nodes and relationships are created to represent components and their associated rules respectively. Each node consists of its name, original rule, rule index, type, project name, date, and owner. Relationships between nodes are defined based on the rules, indicating compatibility (should/should not). The Neo4j database is populated with nodes and relationships. Take the \u201cDerive\u201d Type, for example, 32,776 nodes and 24,971 relationships are created."}, {"title": "3.3 Prometheus Chatbot Building", "content": "The chatbot is essential in connecting users with the RS and understandably presenting complex data. In this section, we use Streamlit to construct the Prometheus chatbot for tabular data representation (Khorasani et al., 2022). This design ensures that users can quickly comprehend and compare different components, making it easier to determine what additional components are necessary for their specific computer setup needs."}, {"title": "5 Discussion", "content": "Our work shows that integrating knowledge graphs (KGs) with large language models (LLMs) can enhance recommender systems (RSs) efficiency. By combining database and graph-based visualizations with natural language processing, our methodology deals with the complexities associated with recommending computer components. The results show an improvement in the system's capability to offer precise and contextual suggestions. KGs enable structured and interconnected data representation, which supports more refined reasoning and inference. Meanwhile, the LLM allows users to formulate queries in natural language with high interpretative accuracy. This combination is an advancement in KG-based RSs. We call this RS \u201cPrometheus\", a chatbot mainly designed for Lenovo internal use.\nHowever, challenges remain. Building an extensive KG demands great efforts to refresh and ensure the accuracy of original data. In the future, we plan to broaden the reach of our KGs to contain more components and complex rules. This expansion will further refine the capability of the Prometheus chatbot. Furthermore, the potential to apply our methodology to other sectors offers promising research opportunities. Industries with complex inventories, such as automotive, electronics, or healthcare, could also potentially benefit from our approach. The broader application of integrating KGs and LLMs underscores the future possibilities for AI-driven RSs."}, {"title": "6 Conclusion", "content": "In conclusion, our work shows the benefits of KG collaborative LLM in improving RSs. Prometheus has proved useful in the industry for better computer components recommendations."}]}