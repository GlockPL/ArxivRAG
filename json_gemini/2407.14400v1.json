{"title": "On the Impact of PRB Load Uncertainty Forecasting for Sustainable Open RAN", "authors": ["Vaishnavi Kasuluru", "Luis Blanco", "Cristian J. Vaca-Rubio", "Engin Zeydan"], "abstract": "The transition to sustainable Open Radio Access Network (O-RAN) architectures brings new challenges for resource management, especially in predicting the utilization of Physical Resource Block (PRB)s. In this paper, we propose a novel approach to characterize the PRB load using probabilistic forecasting techniques. First, we provide background information on the O-RAN architecture and components and emphasize the importance of energy/power consumption models for sustainable implementations. The problem statement highlights the need for accurate PRB load prediction to optimize resource allocation and power efficiency. We then investigate probabilistic forecasting techniques, including Simple-Feed-Forward (SFF), DeepAR, and Transformers, and discuss their likelihood model assumptions. The simulation results show that DeepAR estimators predict the PRBs with less uncertainty and effectively capture the temporal dependencies in the dataset compared to SFF- and Transformer-based models, leading to power savings. Different percentile selections can also increase power savings, but at the cost of over-/under provisioning. At the same time, the performance of the Long-Short Term Memory (LSTM) is shown to be inferior to the probabilistic estimators with respect to all error metrics. Finally, we outline the importance of probabilistic, prediction-based characterization for sustainable O-RAN implementations and highlight avenues for future research.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent forecasts suggest that by 2030, Information and Communication Technology (ICT) networks could consume up to 21% of the world's electricity supply [1]. In addition, the entire ICT sector contributes over 2% to global greenhouse gas emissions [2]. To put this into perspective, this level of emissions corresponds to that of the aviation industry as a whole. This projection raises concerns about the environmental, economic and social sustainability of these networks. Consequently, the integration of sustainability principles and power efficiency becomes essential in the development and deployment of 6G networks. Having a closer look at the recent history of cellular networks, although the deployed 5G networks are roughly four times more energy-efficient compared to their 4G networks, their energy consumption is approximately three times greater [3]. This is primarily due to the need for a greater number of cells to maintain equivalent coverage at higher frequencies, as well as the higher processing requirements resulting from wider bandwidths and a greater number of antennas. In this context, the use of energy is crucial in terms of sustainable operation. In mobile networks, energy consumption is a major concern for operators, as it significantly increases electricity bills and thus affects their Operational Expenditure (OPEX). To minimize energy consumption in mobile networks, it is important to understand where energy is consumed within the network. The Radio Access Network (RAN) is responsible for a significant part of the energy consumption in mobile networks, with the O-RU component accounting for the largest share ( around 60% of the total energy of a base station). An examination of the breakdown of energy consumption within the mobile network shows that the RAN accounts for 73% of the total energy consumption, followed by the core network with 13%, the data centers with 9%, and other operational aspects with 5% [4] [5]. Pioneer studies, such as the paper in reference [6], represent one of the most widely used Base Station (BS) power consumption models in the literature and show the linear relationship between total BS power consumption and the transmit power. A recent work in [7] provided a realistic characterization of 5G multi-carrier BSs, giving an analytical energy consumption model based on large data collection campaigns. The works in [3] and [7] showed that in modern BSs, the power consumption increases linearly with the PRB load. Furthermore, as has been recently shown in [8], DL PRB load, i.e., the ratio between the used PRBs in a BS and the maximum number of PRBs available at the remote unit, holds the highest significance in modeling radio unit energy consumption. In general, BSs are dimensioned to serve a large amount of traffic during busy hours and in practice this leads to high underutilized bandwidth usage during the major part of the day. Monitoring and managing DL PRB load is of paramount importance for optimizing network performance and ensuring quality of service for"}, {"title": "II. BACKGROUND INFORMATION", "content": "users. It involves dynamically allocating resources and optimizing network configurations to accommodate varying traffic demands and maintain energy efficient operation.\nO-RAN is a new communication paradigm designed to enable the next generation of communication systems. It provides a transformative architectural approach to mobile networks that emphasizes openness, interoperability, and innovation within the radio access network ecosystem. O-RAN promotes the separation of network elements and the introduction of open interfaces, leading to greater choice of providers and greater flexibility in deployment. In the open RAN domain, the concept of radio applications (rApps) is fundamental as it extends the capabilities of the RAN Intelligent Controller (RIC) and enables advanced features such as AI-enhanced proactive allocation of radio resources. In the O-RAN architecture, this paper proposes the integration of AI-enhanced probabilistic forecasting models as an rApp tool to predict the PRB requests. Compared to conventional single-point time series forecasting techniques (e.g. LSTMs [9] or Gated Recurrent Unit (GRU)s [10]), state-of-the-art (SotA) probabilistic forecasting techniques (e.g. DeepAR [11], Transformers [12]) are able to quantify the uncertainty in the prediction, which allows for more informative and reliable decisions. This paper investigates the power saving and error performance of the forecasting models SFF, DeepAR, and Transformer and compares them with the deterministic single-point estimator LSTM. Our results show that DeepAR estimators can predict the PRBs with lower uncertainty and effectively capture the temporal dependencies in the dataset compared to SFF- and Transformer-based models, leading to power savings. Different percentile selections in decision engine for probabilistic methods can also increase power savings, but at the cost of over-/under provisioning. At the same time, the performance of the LSTM is shown to be inferior to the probabilistic estimators with respect to all error metrics.\nThe rest of the paper is organized as follows. Section II provides background information on the O-RAN architecture, its components and gives a power consumption analytical model. Section III provides the problem statement. Section III-A gives an overview the probabilistic forecasting methods, namely SFF, DeepAR, and Transformer. Section IV presents the simulation results and finally Section V provides the conclusions and future direction of the paper."}, {"title": "A. O-RAN Architecture and Components", "content": "Traditional RAN components, up to the 4th generation, are mostly hardware-dependent. They were highly vendor-dependent, which made the integration of a cooperative intelligent network very complicated. Updating hardware components or proprietary systems significantly increases CAPEX and OPEX costs. Further development of RAN solutions for the next generation is proposed as a solution to these problems. Virtualization and disaggregation are the basis of O-RAN technology. O-RAN aims to enable open and intelligent resource management with universally compatible software solutions and minimalist hardware to avoid vendor lock-in. The most important aspects of O-RAN include open interfaces, centralised orchestration and interoperability. The most important key elements are the Open-Radio Unit (O-RU), the Open-Distributed Unit (O-DU), the Open-Central Unit (O-CU), the Near-Real-Time RIC, and the Non-Real-Time RIC.\nThe functions of the Open-Radio Unit (O-RU), the Open-Distributed Unit (O-DU) and the Open-Central Unit (O-CU) are similar to those of the disaggregated 5G-RAN, but with additional support for O-RAN specifications and interfaces. The near-real-time RIC helps to optimize resources and control RAN elements based on fine-grained data sets with AI/ML-based applications. It is suitable for tasks with a low latency overhead of 10ms to 1s. Non-real-time RIC controls and optimizes the resource based on coarse-grained broad datasets for applications with latency requirements of more than 1s. It also helps to provide policy-based guidance to near-real-time RIC. The sustainable radio resource allocation strategy presented in this paper is considered as rApp in non-real-time RIC. This rApp consists of 4 main components, namely:\n\u2022\n\u2022 Monitoring System gathers the historical data from the O-DU about assigned DL PRBs and forwards it to the analytic engine and other elements that request the data.\n\u2022 Analytic Engine pre-processes the data and splits it into a training and a test set. During training and prediction phases, the data is passed as an input feature to the various probabilistic forecasting estimators for analysis and prediction of the future PRB demands. Probabilistic forecasting techniques predict a range of possible values as well as their associated probabilities, enabling a more realistic representation of future events.\n\u2022 Decision Engine receives as an input the estimation of PRBs with their uncertainty from the analytic engine. As introduced in the next section, there is trade-off between fulfilling the PRB demands and power consumption. The decision engine must choose the PRBs to be provisioning based on the sensitivity to over-/under-estimation, taking into account their impact on sustainability.\n\u2022 Actuator is the entity responsible for executing the actual PRB allocation in the dis-aggregated RAN."}, {"title": "B. Power Consumption Model", "content": "Let us consider the power consumption model for 5G BS introduced in [7] and [13]. The total power consumption, denoted by P, can be mathematically formulated as\n$P = P_o + P_{BB} + P_{Tran} + P_{PA} + P_{out}$, (1)\nwhere $P_o$ denotes the baseline power consumption in sleep mode, $P_{BB}$ is the baseband processing power consumption. $P_{Tran}$ denotes the power consumption by the RF chains, the Power Amplifier consumption is $P_{PA}$, and $P_{out}$ is the power required for data transmission.\n$P_{out} = \\frac{1}{\\eta} \\frac{R_{BS}}{C_{BS}} P_{Tx}$ (2)\nThe first terms, i.e., $P_o$, $P_{BB}$, $P_{Tran}$, and $P_{PA}$, depend on the number of available and active RF chains. Following the approach in [13], for the sake of simplicity, the first four terms in (1) are assumed as known and the fifth term is proportional to the traffic volume.\nwhere $\\eta$ denotes the efficiency of the power amplifiers and $P_{Tx}$ is the maximum transmit power. $R_{BS}$ and $C_{BS}$ denote the actual rate and the capacity of the BS. The total capacity of the BS can be computed using the classical Shannon-Harley theorem and is given by\n$C = B \\log_2 (1 + SINR)$ . (3)\nConsidering the capacity formula is clear that $P_{out}$ in (2) is inversely proportional to the total bandwidth in the O-RU. A natural surrogate of $R_{BS}$ in (2) is to consider the DL PRB load, expressed as $\\frac{R_{BS}}{C_{BS}}$, the ratio between the average number of DL PRBs and the maximum number of DL PRBs available. It has been recently shown in [8] and [3] that DL PRB load holds the highest significance in modeling radio unit power consumption. Furthermore, note that the transmit power increases linearly with the number of used PRBs [7]. Therefore, there is a trade-off between satisfying the DL PRB demands and the energy consumption."}, {"title": "III. PROBLEM STATEMENT", "content": "We formulate the PRB allocation forecasting problem as a time series at time t by yt, then our goal is to model the conditional distribution\n$P(y_{t0:T} | y_{1:t0-1})$ (4)\nof the future of each PRB allocation value in the time series $[Y_{t0}, Y_{t0+1}, \u2026, Y_T] := y_{t0:T}$ given its past $[Y_1, ..., Y_{t0-2}, Y_{t0-1}] := y_{1:t0-1}$, where to denotes the time point from which we assume yt to be unknown at prediction time. To avoid confusion, we refer to time ranges [1, to \u2013 1] and [to, T] as the conditioning and prediction ranges, respectively. Once we learn to forecast and quantify the uncertainty in the prediction range, we provide a sustainability analysis using eq (2)."}, {"title": "A. Probabilistic Forecasting Techniques", "content": "In the field of time series forecasting, accurate predictions are mandatory for effective decision-making across various domains. While traditional forecasting methods offer deterministic point estimates, the characterization of the uncertainty in predictions provides valuable information for a proper assessment of decisions in open RAN networks. Due to recent advancements, deep learning algorithms are being integrated with traditional methods. Deterministic classical Artificial Intelligence (AI) forecast models like LSTM, GRUs, etc., fail to provide certainty about future forecasts. Their overconfidence in forecasts emerges from ignorance of data uncertainty.\nAmong the different techniques available in the literature, three architectures have gained considerable attention: the SFF, and DeepAR [11], and Transformer [12]. They will deliver more accurate and representative predictions in the form of probability distributions. We here provide a comprehensive explanation of the models evaluated in this work.\n1) Simple FeedForward (SFF): SFF is based on a simple feed-forward Neural Network (NN) that estimates the probabilistic distribution of the allocated PRBs along the time series. Instead of doing single point predictions, the NN will output the parameters of a desired distribution for every time step t. The network is composed of an input layer with neurons equal to the number of time steps in the conditioning range [1, to - 1], a hidden layer h, and an output layer with the number of neurons equal to the number of time steps in the prediction range [to, T] \u00d7 p, where p denote the amount of parameters of the assumed likelihood model. The output layers estimate the parameters of a probability distribution for each t representing the forecast uncertainty. In our work, we assume this likelihood to be the t-student location-scale distribution given by:\n$l(y_t | \\nu, \\mu, \\sigma^2) = \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\sqrt{\\nu \\pi} \\Gamma(\\frac{\\nu}{2}) \\sigma} (1 + \\frac{(y_t - \\mu)^2}{\\nu \\sigma^2})^{-(\\frac{\\nu + 1}{2})}$ , (5)\nwhere $\\mu(h_t) = W_{\\mu} h_t + b_{\\mu}$, $\\sigma(h_t) = \\log(1 + \\exp(W_{\\sigma} h_t + b_{\\sigma}))$ and $\\nu(h_t) = \\log(1 + \\exp(W_{\\nu} h_t + b_{\\nu}))$, and $h_t$ denotes the output of the last layer at prediction time t. In this way, the \u00b5 is characterized directly by the network output, and \u03c3and \u03bdare obtained by applying an affine transformation followed by a softplus activation to ensure \u03c3 > 0 and \u03bd > 0.\n2) DeepAR: DeepAR is a probabilistic forecasting algorithm based on Recurrent Neural Network (RNN) equipped with LSTM units. Unlike traditional forecasting methods, deepAR generates probabilistic forecasts providing probability distributions over future PRB allocation along the time series for every t in the prediction range. In this case, to approximate eq (4) we assume that the model distribution:\n$Q_{\\Theta} (y_{t0:T} | y_{1:t0-1})$, (6)\nconsist of a product of likelihood factors:\n$Q_{\\Theta} (y_{t0:T} | y_{1:t0-1})$\n$ = \\prod_{t=t0}^{T} l(y_t | \\Theta_\\delta (h_t))  = \\prod_{t=t0}^{T} l(y_t | \\Theta_\\delta (h(h_t, y_{t-1}, \\Theta)))$ (7)\nwhich is parametrized by the output ht of an autoregressive reccurent network $h_t = h(h_t, y_{t\u22121}, \u0398)$. In this case, h denotes a function implemented by a multilayer RNN with LSTM cells.\n$l(y_t | \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{- \\frac{(y_t - \\mu)^2}{2 \\sigma^2}}$ (8)\nSimilarly to SFF the model outputs the parameters of a probability distribution for each t. For DeepAR we assume a gaussian likelihood given by equation 8, where $\\mu(h_t) = W_{\\mu} h_t + b_{\\mu}$ and $\\sigma(h_t) = \\log(1 + \\exp(W_{\\sigma} h_t + b_{\\sigma}))$. Similarly to SFF, \u03c3 is obtained by applying an affine transformation followed by a softplus activation to ensure \u03c3 > 0.\n3) Transformer: Transformers have emerged as a powerful architecture due to their ability to capture long-range dependencies in sequences. The transformer architecture comprises two main components: the encoder and the decoder. The encoder consists of a series of N blocks, each comprising a Multi-Head Self-Attention layer followed by a position-wise fully connected layer with ReLU activations. These blocks process the input PRB allocation time series in parallel, obtaining an encoded representation of this PRBs. Next, the decoder has three layers. The first and the last one are similar to the encoder and the second one is an encoder-decoder attention mechanism. Similarly to SFF, we assume t-student location-scale distribution, eq(5).\n4) Training loss: Given the PRB allocation time series y1:T, all our presented methods use the same loss for learning the parameters of the networks, summarized for simplicity as $\u0398 = {\u0398_s, \u0398_a, \u0398_t}$. This is done by maximizing the log-likelihood:\n$L = \\sum_{t=t0}^{T} log l(y_t | \u0398(h_t))$.\nFurthermore, the models learn to estimate the distribution parameters for every time step t in the prediction range."}, {"title": "IV. SIMULATION RESULTS", "content": "This section shows the analysis of the performance of different probabilistic estimators together with the deterministic LSTM model. Python programming was used together with the Gluonts library to develop and analyze the estimators in the form of rApp. Herein, the 3 main estimators used are SFF, DeepAR, and Transformer, which predict the DL PRBs needed for the next 24-hour period based on 10 weeks of historical data. For SFF estimator the hyperparameters considered are: epochs=5, batch size=1, hidden layer dimension=[40,40], and number of evaluation samples=100. For DeepAR, the setup hyperparameters are the following: epochs=5, batch size=1, RNN Layers=2, number"}, {"title": "V. CONCLUSIONS AND FUTURE DIRECTIONS", "content": "In this paper, we have proposed a novel approach to characterize the PRB load in sustainable O-RAN using probabilistic forecasting techniques. We first provided background information on the O-RAN architecture and components, emphasizing the importance of power consumption models for sustainable implementations. We then discussed probabilistic forecasting techniques, including SFF and DeepAR, and evaluated their effectiveness in characterizing PRB load dynamics based on simulation results. The results show the potential of probabilistic forecasting to improve resource management and energy efficiency in O-RAN deployments. In particular, DeepAR estimators are shown to predict PRBs with lower uncertainty and effectively capture the temporal dependencies in the dataset compared to SFF- and Transformer-based models. Different percentile selections for probabilistic methods can also increase power savings, but at the cost of over/under-provisioning. At the same time, the performance of the LSTM is shown to be inferior to the probabilistic estimators in terms of all error metrics. For the future, there are several opportunities for further research, such as integration with energy optimization techniques (including dynamic power management strategies or renewable energy integration), validation in the real world with field trials and pilot studies, and exploration of new architectures together with additional data sources to improve accuracy."}]}