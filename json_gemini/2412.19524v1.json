{"title": "PLN and NARS\nOften Yield Similar strength \u00d7 confidence\nGiven Highly Uncertain\nTerm Probabilities", "authors": ["Ben Goertzel"], "abstract": "We provide a comparative analysis of the deduction, induction, and\nabduction formulas used in Probabilistic Logic Networks (PLN) and the\nNon-Axiomatic Reasoning System (NARS), two uncertain reasoning frame-\nworks aimed at AGI.\nOne difference between the two systems is that, at the level of indi-\nvidual inference rules, PLN directly leverages both term and relationship\nprobabilities, whereas NARS only leverages relationship frequencies and\nhas no simple analogue of term probabilities. Thus we focus here on\nscenarios where there is high uncertainty about term probabilities, and\nexplore how this uncertainty influences the comparative inferential con-\nclusions of the two systems. We compare the product of strength and\nconfidence ($s\\times c$) in PLN against the product of frequency and confi-\ndence ($f\\times c$) in NARS (quantities we refer to as measuring the \"power\"\nof an uncertain statement) in cases of high term probability uncertainty,\nusing heuristic analyses and elementary numerical computations.\nWe find that in many practical situations with high term probability\nuncertainty, PLN and NARS formulas give very similar results for the\npower of an inference conclusion, even though they sometimes come to\nthese similar numbers in quite different ways.", "sections": [{"title": "Introduction", "content": "Reasoning under uncertainty is a central challenge in artificial intelligence, and\narguably critical to achieving AGI. However, standard methodologies from the\nAI literature meet this challenge only partially. Classical probabilistic and sta-\ntistical reasoning frameworks like Bayes Nets and Markov Logic Networks don't\neffectively encompass advanced logical knowledge representation features like\nquantifiers or higher order expressions. Statistical approaches like LLMs fail at"}, {"title": "Background", "content": "Two prominent frameworks aiming to address these shortcomings are:\n1. Probabilistic Logic Networks (PLN), developed by Ben Goertzel and col-\nleagues, which combines probabilistic reasoning with a mix of higher-order\npredicate logic and term logic, driven by an observation-grounded seman-\ntics (Goertzel, 2009)\n2. Non-Axiomatic Reasoning System (NARS), developed by Pei Wang, which\nprovides an uncertain term logic for evidence-based reasoning without\nrelying on probabilistic assumptions. (Wang, 1994)\nBoth of these systems provide inference rules for deduction, induction, and\nabduction, and then contain systems for extrapolating these basic rules to han-\ndle more advanced inference scenarios involving quantifiers, causal and temporal\nreasoning, and so forth. Further, the two systems have in common that they\nassign both strength and confidence values to logical statements and relation-\nships.\nHowever, the two systems differ fundamentally in their semantics of uncer-\ntainty and their use of term probabilities. As one important aspect of this\nfoundational semantic difference, PLN assigns probabilities to both terms and\nrelationships, whereas NARS assigns uncertainties only to relationships but not\nterms.\nThis paper compares the basic truth value formulas of PLN and NARS\n(across the deduction, induction and abduction inference rules), focusing in par-\nticular on the scenario where there is high uncertainty about term probabilities\nin PLN. Our main result is if one compares the product strength \u00d7 confidence\n(which we call the \"power\") across PLN and NARS, then in situations of high\nterm probability uncertainty, we find the two systems often give very nearly the\nsame evaluation of the power to be associated to the result of an inference.\nWhat is interesting is that the two systems often come to almost the same\nnumber but by different routes: i.e. the strong alignment we observe in the\nhigh-term-probability-uncertainty case does not occur if one looks at strength\nalong or confidence alone, only if one looks at the product.\nNo similar, inference-rule-level alignment between the two systems occurs in\nthe case of higher term probability confidence, as in these cases PLN's inductive\nand abductive conclusions become strongly Bayesian, which is a quite different\ndirection from NARS."}, {"title": "Non-Axiomatic Reasoning System (NARS)", "content": "The cognitive and philosophical theory underlying NARS is quite deep and in-\nvolved and we will not attempt to summarize it here, referring the reader to"}, {"title": "Probabilistic Logic Networks (PLN)", "content": "PLN, Probabilistic Logic Networks (Goertzel et al, 2008), was originally in-\nspired by a desire to capture key aspects of NARS but within a framework\ncompatible with probability theory. The idea was, roughly, to be somewhat\nNARS-like in cases where evidence was scant, and then to resemble Bayesian\nstatistical reasoning more closely in cases where evidence was more abundant.\nOver time the theory and practice of PLN diverged further from NARS, and\nnow PLN combines aspects of term logic with aspects of higher-order predi-\ncate logic, and embraces a variety of truth value representations going beyond\nthe NARS-like ($s, c$) = (strength, confidence) pairs with which it began. In\nOpenCog Hyperon (Goertzel et al, 2023), PLN semantics is being formalized\nusing categorial and type-theoretic methods, and connected with paraconsistent\nlogic (Goertzel, 2020).\nHere, as with NARS, we will stick to a simple subset of PLN, and focus\nonly on the uncertain truth value formulas associated with the three first-order\nterm logic reasoning rules for deduction, induction and abduction. Setting aside\nuncertain truth value formulas, the structure of these rules looks the same for\nPLN as for NARS.\nWe will deal here only with what in PLN are called \"simple truth values\",\nwhich consist of strength (s) and confidence (c) defined via"}, {"title": "Basic PLN Truth Value Formulas", "content": "We now review the PLN truth value formulas comparable to the NARS formulas\ngiven above.\nDeduction Rather than providing single all-purpose truth value formulas cor-\nresponding to inference rules, PLN gives a methodology for deriving truth value\nformulas corresponding to rules. Depending on how one wants to represent un-\ncertainty (e.g. with first or higher order probabilities or various parametrizations\nor approximations thereof), and what heuristic or data-driven assumptions one\nwants to make, one may obtain different formulas. For the simple (transitive\ninference) deduction rule, we will look here at two truth value formulas working\nwith (s, c) truth values, but founded on different assumptions otherwise.\nThe most standard PLN deduction truth value formula is the \"independence-based\" formula, which is derived using an assumption that A and C are proba-\nbilistically independent within B. In this case, given"}, {"title": "Heuristic Analysis for Deduction, Induction and Ab-\nduction", "content": "For each of the three core varieties of first-order PLN and NARS inference, we\nwant to compare $s\\times c$ in PLN and $f\\times c$ in NARS."}, {"title": "Deduction", "content": "In PLN (Independence-Based), under high uncertainty of term probabilities:\n$s_{AC} \\approx s_{AB}s_{BC}$\nThis simplification occurs because the terms involving term probabilities become\nless significant.\nWe then find:\n\u2022 Confidence $c_{AC} \\approx c_{ABC_{BC}}$ (making a simple independence assumption on\nconfidences).\n\u2022 Product:\n$s_{AC} \\times c_{AC} \\approx s_{ABSBC} \\times c_{ABCBC}$\nIn PLN (Concept Geometry-Based), we have\n$s_{AC} = \\frac{s_{AB}s_{BC}}{min (1, s_{AB} + s_{BC})}$\nUnder high uncertainty of term probabilities, and when $s_{AB} + s_{BC} < 1$, this\nsimplifies to:\n$s_{AC} = \\frac{s_{AB}s_{BC}}{s_{AB} + s_{BC}}$\nWe have\n\u2022 Confidence $c_{AC} \\approx c_{ABCBC}$.\n\u2022 Power:\n$s_{AC} \\times c_{AC} = \\frac{s_{AB}s_{BC}}{s_{AB} + s_{BC}}\\times c_{ABCBC}$\nIn NARS, comparatively, we have for strength:\n$f = \\frac{f_{1}f_{2}}{f_{1}+ f_{2} - f_{1}f_{2}} \\approx \\frac{f_{1}f_{2}}{f_{1}+f_{2}}$ (for low $f_{1}$, $f_{2}$)\nand confidence:\n$c = c_{1}c_{2} (f_{1}+ f_{2} - f_{1}f_{2}) \\approx c_{1}c_{2} (f_{1}+ f_{2})$"}, {"title": "Induction", "content": "In the case of high uncertainty of term probabilities, the independence-based\nPLN induction formula\n$s_{AC} = \\frac{s_{BA}s_{BC}}{s_{B}} + \\frac{s_{B} (1-s_{BA}) (s_{C} - s_{BC})}{s_{A}(1-s_{B})}$\ncan be simplified considerably. Bayes' rule is less useful and the best approxi-\nmation one can form is generally the simple form\n$s_{AC} \\approx s_{BA}s_{BC}$\nBasically, what we are saying here is: if the term probabilities are all wildly\nuncertain, then heuristically speaking\n\u2022 the best we can do as regards the first term is assume that on average the\nratio of two unknown things is 1\n\u2022 since the second term has a product of two ratios of term probabilities,\nif term probabilities are highly uncertain then it's going to be even more\nwildly uncertain than the first term, and its contribution will end up\nnegligible once confidence is incorporated\nIn this case PLN's default confidence formulas also reduce to a simple form\n$c_{AC} \\approx c_{BA}c_{BC}$\nso the powers $\\times c$ comes out to:\n$s_{AC} \\times c_{AC} \\approx s_{BA}s_{BC} \\times c_{BA}c_{BC}$"}, {"title": "Abduction", "content": "In PLN, similarly to the induction case, under high uncertainty of term proba-\nbilities we find:\n$s_{AC} \\approx s_{AB}s_{CB}$\nyielding"}, {"title": "Concrete Numerical Examples", "content": "Following on the qualitative analysis from the previous section, to illustrate the\nsimilarities and differences between PLN and NARS under high uncertainty of\nterm probabilities, we present three numerical examples: one for deduction, one\nfor induction, and one for abduction. These examples demonstrate how the\nproducts $s\\times c$ in PLN and $f\\times c$ in NARS compare under specific conditions."}, {"title": "Example 1: Deduction", "content": "Given:"}, {"title": "Analysis:", "content": "We see that under the given simplifying assumptions, the independence-based PLN system and the NARS system yield actually identical products,\nindicating a strong alignment under high uncertainty of term probabilities.\nOn the other hand, the normalization factor in PLN's concept geometry-\nbased deduction results in a lower product compared to NARS."}, {"title": "Example 2: Induction", "content": "Given:"}, {"title": "Analysis:", "content": "Similarity: Both systems yield nearly identical products, indicating align-\nment under high uncertainty of term probabilities.\nThe heuristic simplification in PLN's induction aligns closely with NARS's\ninduction output, showcasing similar reliance on premise strengths and confi-\ndences when term probabilities are highly uncertain."}, {"title": "Example 3: Abduction", "content": "Given:"}, {"title": "Analysis:", "content": "Here we see PLN yields a lower product compared to NARS, highlighting\ndifferences in how confidence is handled.\nWhile both systems rely on the multiplicative combination of strengths/frequencies\nand confidences, the absence of normalization and the differing treatment of\nconfidence in PLN lead to discrepancies in the inferred products."}, {"title": "Summary of Results from Exploratory Examples", "content": "Specifically, what we have seen here results-wise in our handful of illustrative\nexamples is:"}, {"title": "Implications and Observations", "content": "We have shown here, through fairly simplified heuristic analyses and correspond-\ning elementary computations, that under conditions of high uncertainty about\nterm probabilities, the inference outputs of PLN and NARS exhibit certain con-\nverging tendencies, particularly when considering the products $s\\times c$ in PLN and\n$f\\times c$ in NARS.\nThe conceptual reason for this convergence is clear: High uncertainty in\nterm probabilities leads PLN to rely more on the strengths and confidences of\nrelationships. The core aim here has been to do a little specific analysis to see\nhow this notion pans out in practice.\nThe primary insight underlying the analysis here has simply been to focus\non the power $s\\times c$, because if one focuses on s alone or c alone the two systems\ndo not look so similar sometimes what one system puts into the strength,\nthe other system puts into the confidence, but when one takes the product it\nevens out."}, {"title": "Similar Though Not Identical", "content": "Overall, despite the striking parallels, we cannot say that PLN quite \"reduces to\"\nNARS when term probabilities are highly uncertain. While strong similarities\nbetween the two sets of uncertain inference rules exist under high uncertainty of\nterm probabilities, fundamental distinctions between the frameworks \u2013 such as\nnormalization factors in PLN and the experience parameter in NARS - do lead\nto nontrivial differences in their reasoning outputs even in these circumstances,\nespecially regarding non-deductive reasoning. These differences seem generally\nnot huge (we have looked at more examples than the 3 given here), but modest-\nsized systematic differences could still have a meaningful impact on AI system\nbehavior.\nHowever, it is still quite interesting how, when term probabilities are uncer-\ntain, these two inference approaches with very different conceptual and formal\nunderpinnings come quite close to saying the same thing about practical situ-\nations at least if one focuses on the \"power\" obtained by multiplying $s \\times c$.\nThis may be taken as a bit of evidence that $s\\times c$ is an interesting thing to look\nat, as well."}, {"title": "The Case of Confident Term Probabilities", "content": "When term probabilities are confidently known, the situation is generally quite\ndifferent, and the role of term probabilities in PLN often leads it to very di-\nvergent conclusions from NARS. This is very much the case for induction and\nabduction, where PLN's approach leans heavily on Bayes rule, which normalizes\nby term probabilities in a foundational and impactful way.\nIn the case of reasonably confidently known term probabilities, the outputs\nof NARS and PLN are generally extremely different on the level of individual\ninference rules, and if one were to interestingly compare the two systems, it\nwould need to be done at the level of the holistic conclusions drawn by inference\nnetworks based on a large amount of data and the combination of a large number\nof inferences (because in these cases, the two systems draw different conclusions\non the individual-rule level, but also combine the outcomes of these individual\ninferences in different ways).\nA more in-depth analysis could explore how rapidly and with what speci-\nficities PLN's conclusions become decreasingly NARS-ian as the confidence of\nterm probabilities increases."}, {"title": "Future Work", "content": "To further pursue the research direction indicated here, natural avenues would\nbe:\n\u2022 Numerical Simulations: Performing intensive numerical simulations to\nprovide more detailed quantitative comparisons, particularly in scenarios\nwith varying levels of uncertainty.\n\u2022 Practical Results Comparison: Model practical examples in several\ndomains with both systems, and assess the impact of the differences that\ndo exist between the output values of the system, in cases of highly un-\ncertain term probabilities and otherwise\n\u2022 Confidence Metrics: Explore alternative methods for calculating and\ninterpreting PLN confidence in the presence of high uncertainty about\nterm probabilities."}]}