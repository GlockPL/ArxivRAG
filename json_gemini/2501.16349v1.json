{"title": "Risk-Informed Diffusion Transformer for Long-Tail Trajectory Prediction in the Crash Scenario", "authors": ["Junlan Chen", "Pei Liu", "Zihao Zhang", "Hongyi Zhao", "Yufei Ji", "Ziyuan Pu"], "abstract": "Trajectory prediction methods have been widely applied in autonomous driving technologies. Although the overall performance accuracy of trajectory prediction is relatively high, the lack of trajectory data in critical scenarios in the training data leads to the long-tail phenomenon. Normally, the trajectories of the tail data are more critical and more difficult to predict and may include rare scenarios such as crashes. To solve this problem, we extracted the trajectory data from real-world crash scenarios, which contain more long-tail data. Meanwhile, based on the trajectory data in this scenario, we integrated graph-based risk information and diffusion with transformer and proposed the Risk-Informed Diffusion Transformer (RI-DiT) trajectory prediction method. Extensive experiments were conducted on trajectory data in the real-world crash scenario, and the results show that the algorithm we proposed has good performance. When predicting the data of the tail 10\\% (Top 10\\%), the minADE and minFDE indicators are 0.016/2.667 m. At the same time, we showed the trajectory conditions of different long-tail distributions. The distribution of trajectory data is closer to the tail, the less smooth the trajectory is. Through the trajectory data in real-world crash scenarios, Our work expands the methods to overcome the long-tail challenges in trajectory prediction. Our method, RI-DiT, integrates inverse time to collision (ITTC) and the feature of traffic flow, which can predict long-tail trajectories more accurately and improve the safety of autonomous driving systems.", "sections": [{"title": "INTRODUCTION", "content": "The emergence of autonomous driving is a revolutionary technical progress set to transform transport fundamentally. Within this context, trajectory prediction plays a pivotal role, focusing on forecasting the future paths of road agents based on their historical movements. Accurate predictions of surrounding agents' trajectories enable autonomous vehicles to strategically plan their routes and avert potential collisions. Contemporary research has introduced a multitude of trajectory prediction methodologies, encompassing both unimodal and multimodal approaches. These models usually face two challenges to achieve high prediction accuracy.\nFirst is the long-tailed phenomenon in the datasets used to train the models. Long-tailed phenomenon refers to the lack of certain types of data while rich in other types of data (1). In real traffic scenarios, most of the drivers make smooth maneuvers, which can be easily predicted. This makes the average error of the model seem small but actually ignores many key scenarios, such as crashes. Crash scenarios contain abundant long-tail data, in which agents make more lane changes, sharp turns, and dodges. However, crashes are sporadic and low-probability events, and the existing datasets lack trajectory data of agents in crash scenarios. Therefore, models trained based on these datasets usually have poor performance in critical scenarios, which can cause severe traffic crashes (2, 3).\nAnother challenge is the lack of authenticity in generating trajectories. Recently, there was a trend for generating trajectories by generative adversarial networks (GANs) (4) and Variational Auto-Encoders (VAEs) (5). However, although the behaviors generated by these models seem reasonable, they only mirror the distribution of the training data and do not learn any mechanism of traffic flow. In the meantime, these methods ignored vehicle motion uncertainty caused by different driving styles. Moreover, the interrelationship between the vehicle and the environment was rarely considered (6). The limitations of these methods lead to less practical trajectory prediction in the real world (7).\nIn order to address the problem of long-tail phenomenon, typical methods are class rebalancing, information augmentation, and module improvement (3, 8, 9). Most model improvement methods are based on class-rebalancing. However, class-rebalancing methods have the drawback of improving tail-class performance at the cost of lower head-class performance (8). This will reduce the overall accuracy of the model. Then, existing information augmentation methods cannot utilize information of multiple dimensions well. However, many types of research have demonstrated the important role of risk-information and traffic flow characteristics (flow, flow rate, and flow velocity) in trajectory prediction, especially in complicated crash scenarios (3, 9). So, we introduced graph-based risk information and traffic flow information into our prediction model to improve its performance.\nMore recently, diffusion probabilistic models, also known as diffusion models, have shown more authentic results in trajectory generation and are considered to be a model with great potential (10). Diffusion probabilistic models, which introduce noise in the forward diffusion process and then denoise to reconstruct the original trajectory distribution, have become a highly adaptable model for trajectory generation (11, 12). To further enhance the performance of diffusion probabilistic models, recent studies have improved this approach by replacing the traditional convolutional U-Net with Transformers, which have shown a more effective perception of multi-dimensional information in trajectory modeling (13). Therefore, we adopt the diffusion with transformers (DiT) as a trajectory generator to produce more realistic trajectories.\nIn this paper, we utilized the trajectory data of a crash scenario to enhance the model's prediction ability in the long-tail datasets. To enhance the accuracy of trajectory prediction in crash scenarios, we introduced risk information into the prediction, including inversed time to collision (ITTC), velocity, and traffic flow features. A diffusion model with Transformer is utilized to generate the feature of predicted trajectories. Our contribution can be summarized as follows:\n\u2022 RI-DiT: We proposed a new method to enhance the accuracy of trajectory prediction in crash scenarios, which is called Risk-informed Diffusion with Transformers (RI-DiT). By utilizing the DiT module to generate multi-modal trajectories, the diversity of the predicted trajectories is enriched, making the predictions more realistic.\n\u2022 Graph-based risk information: We extracted the trajectories in the crash scenarios to enrich the long-tail data and improved the model's prediction performance for long-tail data by integrating risk-info and traffic flow in DiT. Through diversified input data, the prediction performance of the model in crash scenarios is improved.\n\u2022 Outperformance: We conducted extensive experiments on our algorithm using the realworld vehicle trajectory in a crash scenario. The results demonstrate that our proposed algorithm performs exceptionally well, achieving notably values for the minimum average displacement error (minADE) and minimum final displacement error (minFDE) metrics, with results of 0.009/1.519 m, respectively."}, {"title": "RELATED WORKS", "content": "Trajectory Prediction\nMany methods have been proposed to predict future trajectories, including early physics-based models, such as Kalman filter (14) and Monte Carlo Methods (15). With the development of neural networks, deep learning methods are proposed to predict future trajectories, such as Recurrent Neural Network (RNN) (16), which stores information of the previous timesteps and determines outputs with the information of the contemporary inputs and history information. However, it has a drawback of gradient explode or decay when the timesteps are large. Intergrades of RNN, LSTM, and gated recurrent unit (GRU) were proposed to solve the problem of gradient explosion or decay. In practice, they are used as sequence models to predict vehicle maneuvers. In (17), fully connected\nLong Tail Learning\nTo address the problem caused by the long-tail phenomenon, resampling has been an intuitive choice (26-28). The random under-sampling (RUS) method, which involves the random exclusion of data from the head classes, has the inherent disadvantage of impairing the performance of the model on head classes (29). Progressively-balanced sampling (30) combined random sampling with class-balanced sampling. However, the dataset is not necessarily classified, making it hard to"}, {"title": "METHOD", "content": "Figure 1 shows our method framework. By inputting traffic flow characteristics, trajectory characteristics, and graph-based risk information into the risk conditional diffusion module and fusing the risk information by adding random noise to generate trajectory features. The trajectory features are passed into the scene encoder for encoding, and then the multimodal trajectories are generated through the trajectory decoder. The part of the method details the methods in the framework.\nA Graph-based Risk Calculation\nWe established a graph theory-based method (37, 38) to explicitly calculate the risk information of a certain vehicle. The risk network is defined as an undirected graph $G = (V,E, W)$, in which $V=$\n$V_1, V_2,..., v_n$ is a set of vertices, each representing a vehicle at the current scene. $E \\in {<v_a,v_b>: V_a,V_b$\n$\\in V, a=b}$ is a set of edges that each connects two vertices. At the same time, we used ITTC (39) as the weight between two vertices. ITTC avoids the issue of TTC being infinite when two vehicles are moving away from each other. Figure 2 shows the positional relationship between the two cars, each vehicle has a specific position, $O_j : (x_j,y_j)$ and velocity, $V_j : (v_x,v_y)$.\nITTC assumes the two vehicles keep their speed and direction before a potential crash, and\n\\begin{equation}\nITTC_{ij} = \\begin{cases}\n    \\frac{v_i^y - v_j^y}{x_i - x_j - (L_i + L_j) / 2}  & (v_i^y - v_j^y)[x_i - x_j - (L_i + L_j) / 2] > 0 \\\\\n    0                                          & (v_i^y - v_j^y)[x_i - x_j - (L_i + L_j) / 2] < 0\n\\end{cases}\n\\end{equation}\nWhere $L_i$ and $L_j$ respectively represent the length of the vehicle. $y_i$ and $y_j$ respectively represent the positions of vehicle i and vehicle j in the Y-axis direction, and $v_i^y$ and $v_j^y$ respectively represent the velocities of vehicle i and vehicle j in the Y direction.\nIf two vehicles are approaching in the lateral direction, replace longitudinal speed, longitudinal distance, and length with lateral speed, lateral distance, and width.\n\\begin{equation}\nITTC_{ij} = \\begin{cases}\n    \\frac{v_i^x - v_j^x}{y_i - y_j - (L_i + L_j) / 2}  & (v_i^x - v_j^x)[y_i - y_j - (L_i + L_j) / 2] > 0 \\\\\n    0                                          & (v_i^x - v_j^x)[y_i - y_j - (L_i + L_j) / 2] < 0\n\\end{cases}\n\\end{equation}\nIn this paper, 6 vehicles are taken into consideration, such as Figure 3, which are the nearest vehicles in the front and rear on the nearest three lanes. We used weighted degree centrality to estimate the risk of certain vertices, as shown in the following equation:\n\\begin{equation}\nC_d(v) = \\sum_{j=1, j\\neq i}^6 w_{ij}\n\\end{equation}\nTrajectory Diffusion\nIn crash scenarios, agents make more lane changes, sharp turns, and dodges, making the trajectories less smooth than ordinary ones. Moreover, more indicators such as risk, flow, and mean velocity are needed to be taken into consideration. By introducing more uncertainty into the trajectory generation process, we used the DiT module to encode trajectories into latent space to generate more diverse multimodal trajectories in crash scenarios (12). Traditionally, a denoising diffusion probabilistic model (DDPM) inherits convolutional U-Net from CNN++, the DiT module means that U-Net replaced by Transformer (13), which outperforms conventional U-Net. Transformer (40) is a deep learning model initially designed for natural language processing that uses selfattention mechanisms and parallel processing to efficiently handle long sequences of data, widely used in tasks like translation and text generation. DDPM consists of two phases: forward process and reverse process (denoising process). Given a set of trajectory data $x_0 \\sim q(x_0), X_1,X_2,...X_T$ are latent of the same dimension, $x_{os}$ is the synthetic trajectory in the forward process, according to a variance schedule $\\beta_1,\\beta_2,...,\\beta_T$ in each timestep, Gaussian noise $N(\\cdot)$ is added into the data.\n\\begin{equation}\nq(x_{1:T}|X_0) := \\prod_{t=1}^{T} q(x_t | x_{t-1}); q(x_t | x_{t-1}) := N(x_t; \\sqrt{1-\\beta_t}x_{t-1}; \\beta_tI)\n\\end{equation}\nWhere $\\beta_t$ is a learnable parameter, $x_t$ can be expressed as $x_t= \\sqrt{\\bar{a}_t} x_0+ \\sqrt{1-\\bar{a}_t}\\epsilon$, and $\\epsilon \\sim N(0,1)$,\n$\\bar{a}_t = \\prod_{i=1}^{t}(1 \u2013 \\beta_i)$. The reverse process can be defined as a Markov chain starting at $p(x_T)$\n$= N(x_T;0,I)$, which aims to learn the joint distribution $p_\\theta(x_{0:T})$ and recover the trajectory from noises.\n\\begin{equation}\np_\\theta (x_{0:T}) := p(x_T) \\prod_{t=1}^{T}p_\\theta(x_{t-1}|x_{t}), p_\\theta(x_{t-1}|x_{t}) := N (x_{t-1};\\mu_\\theta (x_t,t), \\Sigma_\\theta (x_t,t))\n\\end{equation}\nwhere $\\mu_\\theta(x_t,t) = \\frac{1}{\\sqrt{\\alpha_t}} (x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha_t}}}\\epsilon_\\theta (x,t))$, $\\beta_t = \\frac{\\beta_t}{1-\\bar{\\alpha_t}}$ and $\\Sigma_\\theta(x,t) = \\beta_t I$\nThe core of training the diffusion model is to minimize the mean squared error between the Gaussian noise $\\epsilon$ and predicted noise level, as shown in:\n\\begin{equation}\nL(\\theta) := E_{x_0, \\epsilon, t} [|\\epsilon - \\epsilon_\\theta(\\sqrt{\\bar{\\alpha_t}} x_t + \\sqrt{1-\\bar{\\alpha_t}}\\epsilon, t)||^2]\n\\end{equation}\nWhere $\\alpha_t$ is a hyperparameter, $\\epsilon_\\theta$ is a function that takes $x_t$ to predict $\\epsilon$, and $\\theta$ is a learnable parameter.\nFigure 4 shows the architecture of the conditional denoising diffusion probabilistic model (DDPM), which takes random noise, history trajectory, and condition as input. The output is predicted noise, and the action is latent. In our model, risk information is included as the condition. This enables the model to acquire more information about crash scenarios and enhance the model's predictive ability in critical scenarios.\nScene Encoder\nIn crash scenes, there is more information needed to be taken into consideration. We encode trajectory, risk information, and traffic flow information into tokens by using different embedding blocks. We encode trajectory, risk information, and traffic flow information into tokens by using different embedding blocks. In the process of encoding history trajectory $traj_i$ into a unified onedimensional token. So that the trajectory doesn't have to be converted to a Frenet coordinate\n\\begin{equation}\nE_{traj} = \\Phi_{traj} [x_i, V_i]\n\\end{equation}\nWhere $\\Phi_{traj}$ represents a linear layer that transforms trajectory information into a token, and $E_{traj}$ represents the result of trajectory embedding.\nThe risk embedding outcome $E_{risk}$ is defined as:\n\\begin{equation}\nE_{risk} = \\Phi_{risk} [w_1,w_2,..., w_i]\n\\end{equation}\nWhere $w_i$ are the weights of the 6 vehicles taken into consideration. $\\Phi_{risk}$ is a linear layer that transforms risk information into a token.\nThe traffic flow characteristics are also turned into tokens:\n\\begin{equation}\nE_{env} = \\Phi_{env}[K_{env}, Q_{env}, V_{env}]\n\\end{equation}\nWhere $K_{env}, Q_{env}, V_{env}$ are the flow, flow rate, and mean velocity of the traffic flow.\nThe driver's driving characteristics are also processed:\n\\begin{equation}\nE_v = [a_v, m_v, std_v, k_v, skew_v, cv]\n\\end{equation}\nWhere $a_v, m_v, std_v, skew_v$ are the acceleration, average value, standard deviation, kurtosis, skewness, and coefficient of variation of the velocity.\nTo synthesize these tokens into one token $E_a$, we concatenate $E_{traj}$ and $E_{risk}$ into one final token:\n\\begin{equation}\nE_a = ReLU(LayerNorm(Concat(E_{traj}, E_{risk}, E_{env}, E_v)))\n\\end{equation}\nWhere $ReLU(\\cdot)$ is the activation function (41).\nIn this process, we have a comprehensive token that contains information on both history, trajectory, and risk. The token is then fed to DiT blocks, which utilize a transformer to provide precise information. The transformer is built with layers including multi-head self-attention mechanisms and feed-forward neural networks, enhanced by positional encoding and residual connections. This architecture enables efficient parallel processing of sequences, making it powerful for tasks like translation and text generation.\nTrajectory Decoder\nThe trajectory decoder decodes the risk-informed token and trajectory token into predicted future trajectory. In this model, GRU layers (42) and MLP layers are applied to predict future trajectories. The GRU blocks uses a reset gate and an up-date gate, which help control the flow of information and mitigate the vanishing gradient problem to predict the future risk-informed token. The predicted information is then fed to MLPs to decode into displacements of multimodal future timesteps. The trajectory in predicted timestep m is then formed as:\n\\begin{equation}\nTraj_m = Pos_i + \\sum_{i=t}^{T_f} [\\Delta x_m, \\Delta y_m, \\Delta \\theta_m]\n\\end{equation}\nWhere $Pos_i$ is the last history position of the vehicle, and $[\\Delta x_m, \\Delta y_m, \\Delta \\theta_m]$ are the displacements of x,y position and angle of trajectory m.\nThe velocity can be calculated by following equation:\n\\begin{equation}\nV_m = \\frac{\\Delta y}{\\Delta t}\n\\end{equation}\nWhere dt is the time difference between the two consecutive points."}, {"title": "EXPERIMENTS", "content": "Dataset\nThe dataset we adopted is the public dataset released by the I-24MOTION project located near Nashville, Tennessee, USA (43). This project consists of 276 high-resolution traffic cameras, and these cameras are distributed along approximately 4.2 miles of Interstate-24 in the USA. To collect sufficient data under key scenarios, we selected the vehicle trajectories near section MM59.7 on November 21, 2022. On that day, a rear-end collision occurred among nearby vehicles, causing traffic congestion from 6:14 to 7:43 AM. The trajectory data in this crash scenario may generate more abnormal trajectories due to the traffic congestion caused by the crash. To better explore the relationship between vehicle trajectories and surrounding vehicles, we only selected the scenarios of the six closest vehicles.\nThe main data information we used is shown in Table 1. To measure the risk information and the traffic flow data in crash scenarios, we calculated the ITTC value in each frame scenario and the traffic flow density, speed, and flow rate in the road section at that time. Then, the features such as the historical trajectories, speeds, distances to surrounding vehicles, and traffic flow of the vehicles were taken as input features to predict the vehicle trajectories in the next 50 frames. Meanwhile, We calculated the FDE of each trajectory using a simple model in order to distinguish the long-tail data. To ensure there are sufficient long-tail data in the test set, we first divided the non-long-tail data in a ratio of 2:8 and then added the long-tail data to the training set and the test set in a ratio of 5:5 respectively. This made the amount of long-tail data in the training set and the test set each account for 10\\% of the total data. Therefore, the actual ratio of the training set to the test set is 74:26.\nMetrics and Loss Function\nMetrics.The performance metrics we adopted are minADE and minFDE, and these two trajectory prediction evaluation metrics have been widely used in multi-trajectory modality research (1, 44, 45). Among them, average displacement error (ADE) calculates the average L2 distance between all predicted trajectories and the actual trajectories and reports the error value that is closest to the actual trajectory. The final displacement error calculates the L2 distance between the final position of the predicted trajectory and the final position of the actual trajectory and reports the minimum value. To measure the algorithm's performance, we take the average of the minADE and minFDE, which are calculated for all trajectories.\nLong-Tail Sample Selecting. To better verify the prediction performance of the algorithm for the long-tail trajectory data in crash scenarios, we first predicted the trajectories through the relatively simple LSTM model (46), calculated the FDE value of each trajectory, and used this to evaluate the difficulty of trajectory prediction. Next, all FDEs were divided into 100 parts with the interval of [0.0002, 41.3775] through the frequency histogram shown in Figure 5. It shows that when the trajectories belong to the regular trajectories (head data), the prediction accuracy is relatively high. However, when the data are distributed in the tail (long-tail data), the prediction accuracy is low. To compare the performance ability of the model in the long-tail data, we divided these 100 data into six grades: Top 10\\%, Top 20\\%, Top 30\\%, Top 40\\%, Top 50\\%, and Rest."}, {"title": "DISCUSSION", "content": "The long-tail trajectories in crash scenarios contain many driving behaviors taken for emergency avoidance, but current studies pay less attention to the prediction of this type of trajectory, which\nleads to autonomous vehicles predicting incorrect trajectories in some critical scenarios, thereby causing serious traffic crashes (49). To address this problem, we selected the vehicle trajectory data in the rear-end crash scenario from the I-24MOTION public dataset (43). This scenario contains some trajectory data of the approximately one-and-a-half hours of traffic congestion caused by the crash. Based on the trajectory data, the risk information in the scene is obtained through graph-based risk calculation. Incorporating such data containing risk information can improve the trajectory prediction ability of intelligent driving vehicles in emergency avoidance scenarios, thereby reducing the occurrence of crashes.\nFor the trajectory data in the crash scenarios we extracted, we designed an algorithm framework including the diffusion with transformer module, the Risk & scene encoder module, and the multimodal trajectory decoder module to predict the trajectories. In this framework, risk information and traffic flow characteristics are innovatively integrated, improving the algorithm's applicability in crash scenarios. Based on the dataset, we conducted extensive experiments. The minADE and minFDE calculated by our method are 0.009/1.159 m, which greatly improves the performance of trajectory prediction in crash scenarios. At the same time, we conducted algorithm performance tests from three aspects: the role of different modules, the complexity of the MLP linear layer in the decoder, and the influence of different modalities on the trajectory prediction results. The experimental results prove the effectiveness of the DiT module and multimodal trajectory prediction for long-tail data trajectory prediction. At the same time, it is proved that for our dataset, only a decoder with fewer linear layers is suitable. In addition, the experimental results clearly show that different long-tail data distributions will affect the prediction ability of the model. The data at the tail is often more difficult to predict because the shape of the tail data trajectory is more tortuous. Our work expands the research on long-tail trajectory prediction from both the data and the trajectory prediction framework, which can help subsequent researchers better understand the long-tail trajectories in crash scenarios.\nAlthough the work of this paper has made good progress, the following shortcomings still exist: Firstly, since we predicted the long-tail trajectories in crash scenarios and do not use the currently popular trajectory prediction datasets such as nuScenes (50), Waymo (51), etc., it cannot be compared with the existing research results. Subsequent studies will improve the relevant models and conduct comparative experiments according to the characteristics of our dataset. Lastly, due to the limited crash data, we only used the trajectory data in the rear-end crash on the highway. Subsequent studies will continue to collect the trajectory data in crash scenarios to improve the generalization ability of the trajectory prediction model."}, {"title": "CONCLUSION", "content": "Aiming at the problem of low prediction accuracy of autonomous vehicles in long-tail trajectory prediction, we extracted the trajectory data in crash scenarios containing a large number of long- tail trajectories and fused risk information such as ITTC and traffic flow characteristics as input data. At the same time, the RI-DiT trajectory prediction framework was proposed, and the diffusion"}, {"title": "DECLARATION OF COMPETING INTEREST", "content": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper."}]}