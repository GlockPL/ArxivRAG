{"title": "\"It depends\": Configuring Al to Improve Clinical Usefulness Across Contexts", "authors": ["Hubert D. Zaj\u0105c", "Jorge M. N. Ribeiro", "Silvia Ingala", "Simona Gentile", "Ruth Wanjohi", "Samuel N. Gitau", "Jonathan F. Carlsen", "Michael B. Nielsen", "Tariq O. Andersen"], "abstract": "Artificial Intelligence (AI) repeatedly match or outperform radiologists in lab experiments. However, real-world implementations of radiological AI-based systems are found to provide little to no clinical value. This paper explores how to design Al for clinical usefulness in different contexts. We conducted 19 design sessions and design interventions with 13 radiologists from 7 clinical sites in Denmark and Kenya, based on three iterations of a functional AI- based prototype. Ten sociotechnical dependencies were identified as crucial for the design of AI in radiology. We conceptualised four technical dimensions that must be configured to the intended clinical context of use: Al functionality, AI medical focus, AI decision threshold, and AI Explainability. We present four design recommendations on how to address dependencies pertaining to the medical knowledge, clinic type, user expertise level, patient context, and user situation that condition the configuration of these technical dimensions.", "sections": [{"title": "1 INTRODUCTION", "content": "Artificial Intelligence (AI) models repeatedly match or outright out- perform radiologists in narrowly defined detection tasks [4, 53, 60, 63]. There are multiple studies claiming that AI-based systems en- hance radiologists' work, either by increasing accuracy or reducing time spent on each examination [48]. These claims, however, are based on retrospective evaluations conducted in laboratory settings. When looking closer into the state of the art of clinician-facing AI, the claims of utility weaken [93]. For example, Roberts et al. [61] found that out of the 62 AI models detecting and predicting COVID- 19 on chest X-rays and CT scans that were described in the literature, none were deemed to be useful for clinical purposes. Furthermore, evaluations of the handful of systems approved by the authorities in the United States and European Union [1] revealed that their clinical impact when integrated into practice remains mostly un- clear [79, 84]. A similar study by Lehman et al. [47] showed no improvement in patient outcomes after the successful integration of an AI-based support tool for mammography screenings. Strohm et al. claimed that one of the primary causes of Al's lack of success in radiology until now is due to \"uncertain added value for clinical practice of AI applications\" [73]. What these studies show is that the clinical usefulness of hitherto AI-based support systems is limited. Researchers with diverse backgrounds (AI, Health, and Human- Computer Interaction (HCI)) investigated what makes AI-based support systems clinically useful. Based on the previous work, we define clinical usefulness as the overarching quality of AI-based support systems emerging from the interplay of their real-world performance, clinical efficacy, local applicability, and end-user ac- ceptance in a situated clinical context for concrete end-users. First, robust performance in real-world settings is essential, as subpar per- formance has been found to increase workload and disrupt clinical routines [80, 82, 93]. Second, the evaluations, primarily assessing technical performance metrics through randomised clinical trials (RCTs), must encompass tangible clinical outcomes and patient benefits. Health researchers have been advocating for more flexible assessment methodologies aligned with the iterative nature of AI deployment [11, 42, 49]. Third, end-user acceptance, supported by qualities like trust and usability, emerges as pivotal for successful use in clinical practice [18, 19, 39]. Altogether, for an AI-based sys- tem to be clinically useful, it must perform well, benefit patients, and be accepted by clinical end-users working in different clinical contexts. In this paper, we investigate how to design Al for clinical use- fulness in different clinical contexts. This study was conducted as a part of a larger research and development project focused on in- novating an AI-based system to assist examinations of chest X-rays in Denmark and Kenya. Here, we define innovation as the entirety of work conducted to create an AI-based system, from creating the datasets the Al is trained on through design and development to its integration and use in practice. We conducted 19 design sessions and design interventions (online and collocated) with 13 radiolo- gists from 7 clinical sites in Denmark and Kenya. Throughout the design study, we explored a range of user interface mock-ups and three versions of a web-based prototype of an AI-based support system with prioritisation and decision-support functionalities."}, {"title": "2 RELATED WORK", "content": "2.1 Clinical Usefulness of AI Systems in Healthcare The hitherto evidence of Al's positive influence on clinical practice is limited [51, 75, 80]. Research on the real-world effect of AI in healthcare tends to be discrete and focusing on confined goals [93]. However, to provide clinical value AI-based systems have to dovetail contributions from Human-Computer Interaction, AI, and Health into a cohesive vision [30, 82, 93]. First, clinical usefulness necessitates robust performance [93]. This primarily has to be true in real-world settings, retrospective evaluations in lab environments do not speak to the final perfor- mance of a system. For example, in a real-world evaluation of an acclaimed ML model for detecting diabetic retinopathy, 21% of all cases were deemed ungradable [8]. Poor performance also leads to increased workload [57, 64, 82], additional time spent on dis- cerning false positive predictions [67, 68], or breakages to work routines [31]. Van Leeuwen et al. [80] reported that out of 100 CE-approved radiological AI-based systems, 64 showed no peer- reviewed evidence of clinical efficacy. Most evidence for the re- maining 36 systems focused on diagnostic accuracy, not real-world clinical outcomes. Second, clinical usefulness necessitates clinical efficacy [42]. However, randomised clinical trial (RCT) - a focused, systematic, rig- orous, and insulated method commonly used to evaluate the validity of clinical interventions independent of external confounders - is often following the traditional sequential paradigm of work charac- teristic for drug development [13]. In this tradition, the intervention is evaluated only when deemed complete [21]. When translating this mentality to AI-based systems, not only does it hinder innova- tion, but it also results in the evaluation of AI through the measure of technical performance [49]. While technical performance is the backbone of useful AI, clinical efficacy is not its immediate con- sequence [11, 69]. For example, Lehman et al. [47] conducted a prospective evaluation of a computer-aided detection system sup- porting mammography reporting. Researchers concluded that the"}, {"title": "\"It depends\": Configuring Al to Improve Clinical Usefulness Across Contexts", "content": "use of AI had no \"established benefit to women.\" Instead, health- care researchers are opening up towards more flexible evaluation approaches that align with the iterative and situated nature of AI innovation and \"go beyond measures of technical accuracy to in- clude quality of care and patient outcomes\" [23, 42]. Achieving high performance but in metrics that are clinically relevant is the next step towards clinically useful AI-based systems. Third, clinical usefulness necessitates clinical organisational ac- ceptance. HCI community's claim to fame is understanding that regardless of a system's performance, it will not have any impact if no one wants to use it. Thus, many facets of making clinical AI an appealing solution were explored. Trust has been hallmarked as a critical quality of clinical AI. HCI researchers investigated its origin [5, 18] and dependencies [59], as well as issued recommendations for design [39]. Explainable AI (XAI) has been the most promising answer to enhance trust, support oversight, and increase the per- ceived usefulness of clinical AI [19, 34, 46, 86]. AI as a new source of information and agency prompted the exploration of new ways of reasoning and human-AI collaboration [10, 16, 20, 25]. Researchers also investigated Al's position in a clinical decision-making process [41] and the rationale behind integration opportunities into clinical practice [39, 66, 68, 90]. They argued that the workflows, current work practices, and the broader sociotechnical context should also be taken into account when implementing clinical AI-based sys- tems [22, 39, 56, 62, 76, 93]. Addressing these concerns is crucial for AI to have a chance at benefiting patients and being accepted by healthcare professionals. Altogether, for an AI-based system to be clinically useful it must perform well, benefit patients, and be accepted by clinical end-users. However, oftentimes the innovation of clinical AI is conducted in silos and the work is not guided by the ultimate goal of clinical usefulness [13, 93]. We need to investigate how AI-based systems can be configured to support these three goals and ultimately result in clinically useful AI."}, {"title": "2.2 System Configurability", "content": "Configurability has been long considered crucial to the appropria- tion of IT systems [26, 27, 45]. There are two types of configurability that should be explored in the context of this study: before-use and in-use [36]. Before-use configurability typically involves the active participa- tion of end-users in the design processes, aiming to tailor systems to their specific needs and preferences [36]. Various methods and approaches have emerged to facilitate meaningful engagement with end-users, such as participatory design techniques [45]. Acquiring an understanding of work practices and work environment, but also technology aspects of a future system and changes it may introduce, is critical for developing systems that effectively respond to user needs [43]. This understanding enables developers and designers to implement systems that are not only technically sound but also contextually appropriate. However, according to Stewart and Williams [72], the paradigm of user-centred design does not properly answer the challenges of implementing useful systems. Rather, the final usefulness of a system is created iteratively through the acts of in-use configuration."}, {"title": "\"It depends\": Configuring Al to Improve Clinical Usefulness Across Contexts", "content": "This stance echoes Suchman who recognised the need for design activities to continue after a system's deployment [74]. The in-use configuration may cover functionalities, user inter- face, or other settings that let the end-users adjust the system to their preference and work environment [85]. However, the system is not the only configurable arena. The environment also under- goes a process of configuration to the new system. The in-use configuration processes encompass changes to the \"technical envi- ronment, organisational relations, space technology relations, as well as people's connections to other people, to other places, and work materials\" [6]. Dourish highlights how the appropriation of IT systems in practice is an act of both adapting the technology and adapting the practices to fit into the new reality [27]. As usual with AI, the matter of configuration is burdened by the immutability of certain aspects of the system in-use and the dependency of early design decisions on the use context [93]. HCI researchers investigating the design of AI-based systems learned that it is impossible to envision all aspects of clinical AI-based sys- tems before deployment. As a result, the final capabilities of such systems only take shape after they have been deployed. [33, 88]. On the opposite end of AI innovation, i.e., prior to data labelling, Zaj\u0105c & Avlona [93] established that very concrete choices and assump- tions about the final context of AI use form the data used for AI training and, by extension, shape the space of capabilities of future AI-based systems. This vicious cycle of dependencies prompted researchers into new ways of thinking about AI innovation. Ed- wards et al. [28] proposed the concept of \"growing\" to foreground the need for almost organic adoption and adaptation of new IT systems in an existing environment. Elish and Watkins presented a similar argument [29] who emphasise that early realisation of clinical AI and acknowledgement and support of the necessary \"repair work\" are crucial to counter the risk of a system remaining \"a potential solution\", i.e., a solution that is not viable when actually implemented. We see the problem of configuration of clinical AI, as a problem of obtaining reliable information related to design decisions made during the innovation process. The emergence and propagation of dependencies (or \"sociotechnical interdependencies\", see [93]) at the point of deployment hamper the ability to configure clinical AI-based systems in-use. At this point, the assumptions about the context of use are already ingrained in the AI model. We want to support the configuration of radiological AI-based systems for clini- cal usefulness by uncovering the dependencies anchored in clinical contexts and linking them with specific design decisions. This ex- tended understanding of contextual factors will allow developers and designers to implement radiological AI support configurable and useful across clinical contexts."}, {"title": "3 METHODOLOGY", "content": "In this paper, we explored how to design radiological AI-based sys- tems for clinical usefulness across contexts. This study was part of a larger project set to design and develop an AI-based support tool for radiologists examining chest X-rays, funded by the Innovation Fund Denmark (0176-00013B). The project is a multidisciplinary collaboration between the Department of Computer Science at the"}, {"title": "3.1 Research Through Design: Design Interventions with Working Prototypes", "content": "To explore the clinical usefulness of AI in different radiology con- texts, we undertook a research through design approach [96]. We conducted three iterations based on a series of design sessions and design interventions using mock-ups of user interfaces (Prototype I) and working prototypes (II and III) (Fig. 1, Fig. 2, and Fig. 3). The three iterations were determined by decisions to deploy major changes in the web-based prototypes, i.e. version 1-3, followed by gathering feedback from the participants. The design sessions were carried out both online and collocated with radiologists in hospital offices. During these sessions, we obtained medical domain knowl- edge, typically by clarifying questions about radiology work and X-rays, but we also collectively explored the design space through a range of mock-ups and prototypes. The design interventions were carried in-situ with the performative purpose of exploring how"}, {"title": "3.1.1 Prototypes.", "content": "As part of the greater project, a deep learning- based model was developed by machine learning engineers at Unumed ApS to detect selected radiological findings [92]. The AI model was developed using a convolutional neural network. The first prototype was merely a proof of concept, not designed to col- lect feedback from external domain experts. It was developed to guide future work in terms of model development and data labelling. However, inspired by earlier research [92, 93], we considered it an opportunity to engage in more concrete discussions on the merit of clinical usefulness with medical professionals at an early stage of the innovation work. The second and third iteration of the prototype consisted of an interactive web application designed to emulate a DICOM viewer. The web application integrated with the AI model developed within the bigger project. This connection enabled us to work with real data and, thus, explore with fidelity the interactions of the radiol- ogists with the system. For the design interventions, radiologists were given access to the prototype, either in-person or remotely. They were requested to choose the next examination to report, fol- lowing their usual practice and using information displayed in the prototype. Then, they were asked to interpret the selected examina- tion without the use of AI and with Al decision support. Moreover, they were asked to configure the AI tool using available options to fit their practice. Finally, they were encouraged to explore the prototype independently and interact with any element of the user interface."}, {"title": "3.2 Analysis Positionality", "content": "The data analysis was conducted by the first and last authors (HDZ and TOA) with backgrounds in Health Informatics, HCI, and AI (5+ & 15+ years of experience). Moreover, before the analysis of the data from the design sessions and design interventions, the two co-authors concluded extensive ethnographic investigations into the work practices of radiologists from the visited sites with a particular outlook on opportunities for AI support (described in a manuscript prepared for publication). First-hand experience with the work practices and similarities and differences across clinical settings informed the initial analysis of this data."}, {"title": "3.3 Data Analysis", "content": "We used reflective thematic analysis [17] to analyse collected data (transcriptions of the design interventions). The analysis took place in Dovetail - a web application for qualitative data analysis. Except for the transcription software, no AI-based analysis support was used in this study. The two authors familiarised themselves with the collected data after every iteration of the design sessions and design interventions when deciding on the next focus. Moreover, the two authors, prior to coding, based on their fieldwork experi- ence (60+ hours) and a literature review [93], devised three bucket themes to support the later organisation of codes: type of clinical site, domain expertise of medical professionals, and patient and situational context. Additionally, a fourth residual category was added not to limit coding. Next, to test the bucket themes, the two authors coded one transcript each for any references to challenges, preferences, dependencies, and configurations in relation to AI and their clinical practice. After this test, the fourth bucket theme was renamed to technical dependencies. The first author coded the re- maining transcripts following the same directions. The two authors met weekly to discuss the coverage of the coding and future con- ceptualisation of themes. The themes were created within their respective bucket themes based on their grounding in the clini- cal context. Importantly, the division of codes between the bucket themes was never final and was used only to support analysis of the significant amount of codes (n=260). Through discussion, reflection on data across the interventions, and fieldwork experience, the authors iteratively clarified themes and reorganised data, moving away from the original bucket themes (while maintaining their initial assignment known). This interpretative work was conducted twice, creating ten reflective themes. The ten themes were framed as dependencies conditioning four specific design decisions that formed an AI-based support design space."}, {"title": "4 CONFIGURING FOUR TECHNICAL DIMENSIONS OF CLINICALLY USEFUL RADIOLOGICAL AI", "content": "We identified ten dependencies that emerge from the social di- mensions of clinical AI and condition the configuration of four technical dimensions of clinical AI for radiology (see Fig. 4). Each of"}, {"title": "4.1 Social Dimensions of Clinical AI", "content": "Medical knowledge. This dimension includes concepts and defi- nitions relevant to the medical domain addressed by the innovated AI-based system, for example, the meaning of radiological findings detected by our Al-based system. Familiarity with them supports meaningful collaboration between designers, developers, and med- ical professionals and reduces the risk of incorrect assumptions throughout the innovation process. Clinic type. This social dimension addresses types of clinical sites. Imaging clinics, general hospitals, and specialised hospitals provide unique healthcare services and, thus, cater to the needs of patients with different conditions. Moreover, the type of clinical site determines the available resources, the speciality of medical professionals working there, their workflows, and their goals. User expertise level. All medical professionals have different do- main expertise. This is evident when comparing junior to senior medical professionals. However, it was also observed between board-certified radiologists. The level of expertise also determines the workload and clinical responsibilities. Patient context. This context encompasses the current location of a patient (in or out of a hospital) and their medical history. Patients are the centre of medical work. Their health and well-being are the priority. Thus, by extension, any system supporting healthcare professionals should support patients and depend on their context. User situation. This dimension pertains to the workload, avail- able time, and resources of medical professionals. While the other four dependencies describe relatively stable medical practice, situa- tional context introduces a temporal factor to the work done and may affect the priorities of medical professionals."}, {"title": "4.2 AI Functionality", "content": "Which Al functionality should the system provide? Answering this question defines this technical dimension. The functionalities explored during design interventions (prioritisation and decision support, see, Fig. 5) were linked to the AI model developed for the project this study was a part of. We explored the conditions for these functionalities to provide clinical value and propose a third functionality: quality assurance, which originated during the design interventions. Dependency 1: AI functionality depends on clinic type. Each clin- ical site has different (1) positions within the healthcare system, (2) amounts of resources available, and (3) workloads related to the size of a clinic. This is why it is important to ensure that AI functionality is implemented in a way that makes sense for the clinical site in which it will be deployed. First, while every radiologist puts the well-being of their patients first, the healthcare systems that they are a part of operate under different incentives. Public and private clinics face different chal- lenges and may require adjusted AI functionalities, for example, The number of cases in court, medical and legal cases, is way more than what you would get in the public sector. So from the medical director's office [point of view], they would want .... any small thing to be flagged so that we don't get into problems later... it would be different in K5, compared to the public sector, where even if you missed this, people are rarely taken to court but in a private setting... if they"}, {"title": "\"It depends\": Configuring Al to Improve Clinical Usefulness Across Contexts", "content": "[K5 administration] were to purchase this software, they would in- sist that it's set... to catch it all but you know of course this would irritate some radiologists [S18, Senior, Big general hospital, Kenya]. The difference in the prevalence of legal litigation against medical professionals in public and private healthcare centres highlighted by P05 may run along different axes in other countries. However, it is imperative for the creators of AI-based support systems to envision alternative motivations for the use of their systems and allow appropriate configuration. Second, different clinical sites have different financial resources available. This factor, which has rarely been considered during the design of clinical AI-based systems, is a very real limitation for which functionalities will be considered worth the investment. What is the harm in having a second opinion for each and every case? What is the cost? Is it a cost implication that we have to choose which images to prioritise or what? [S18, Senior, Big general hospital, Kenya]. The different business models implemented may be detri- mental to the usefulness of a system in practice. Providing decision support on all the examinations and detecting all the radiological findings may be too costly for clinics that could use such support the most, e.g., rural hospitals suffering from the lack of qualified radiologists. Third, the clinical usefulness of AI functionalities may vary de- pending on the size of a clinical site, as recounted by a senior radiologist from a busy specialised hospital, For me, the most rele- vant aspect of it is triage [prioritisation], but if I have five X-rays to report, then I'm not too worried because I'll get to the 5th X-ray in 20 minutes. But if I have 100 X-rays to go through, I don't want to get to the 100th X-ray and see that it was the one with critical findings. So in a setup where you're not very busy, I don't think it would be very useful [S19, Senior, Specialised hospital, Kenya]. Conversely, in smaller clinics that serve mostly outpatients, implementing AI that provides quality assurance functionality would provide more value to both the radiologists and the patients. For example, If I look at it [an examination] and [my colleague] looks at it, no one looks at it until the patient comes back four weeks later, two years later... and then \"Oh, look! That's the damn thing.\" [e.g., a missed tumour] It could be very nice to have this second opinion [I15, Senior, Imaging clinic, Denmark]. In this imaging clinic, radiologists, rather than being afraid of not reaching a critical patient in time, are worried about missing a critical but subtle finding, e.g., a small nodule, which may signify cancer. This means that the same AI functionality may provide useful support depending on the size of a clinic."}, {"title": "Dependency 2: AI functionality depends on user expertise level.", "content": "The value of support in detecting findings on a medical examina- tion decreases with increasing experience. Instead, the assigned workload increases with seniority. Thus, prioritisation and quality assurance functionalities gain importance. Radiological AI-based decision support typically presents a list of findings detected on an examination accompanied by an X\u0391\u0399 visualisation, as also explored in our prototypes. While this mode of support seems straightforward, it misses the reality of clinical practice. Senior radiologists spend a very short time interpreting chest X-rays. To ask them to revisit every examination to discern the validity of AI predictions is wishful. However, when discussing the potential value of AI-based decision support, they focused on quality assurance. Thus, AI should be treated not as an all-knowing peer who is going to point out every finding on an examination but as a safety net that activates only in time of need. For example, It could read the text we write and say: \"Oh, you missed that.\" That could be good [I11, Senior, Imaging clinic, Denmark]. This way, the envisioned system would not require the mental effort and time to discern Al output but would inform a radiologist about potentially missed findings based on the report they were writing. On the other hand, junior radiologists in clinical settings usually take significantly more time to report every examination. Moreover, all of their reports have to be confirmed by a senior colleague. For them, reporting serves as a primary learning exercise. In this con- text, they envisioned using AI support not as a quality assurance but as a new source of information used to draw their own conclu- sions. I would take a look at a chest X-ray, formulate my opinion, and then see what the AI says... If it agrees... good, if it disagrees or finds something that I hadn't, I'll examine it critically... I like getting almost overwhelmed by data, and I sort it out afterwards... [S14, Junior, Spe- cialised hospital, Denmark]. These two perspectives highlight how workflow, workload, and the act of detecting findings on a medical examination changes with expertise. The educational value created for junior radiologists by verbose explanations of Al's predictions may become a burden for senior radiologists who expect minimal disruption to their existing workflows."}, {"title": "#1 Recommendation:", "content": "Enable users to select preferred AI functionality."}, {"title": "4.3 AI Medical Focus", "content": "Which radiological findings should the AI detect? This is where our participants, for the first time, responded, starting with \"It depends...\" (see Fig. 6). Let's explore how to ensure the detected findings are clinically useful in the real world. Dependency 3: AI medical focus depends on clinic type. Different clinics take care of different types of patients suffering from differ- ent conditions. Types of patients seen in different clinical settings result in a local prevalence of observed radiological findings. As a result, a single fit-them-all system that detects an arbitrarily se- lected set of findings is not going to provide a similar quality of support across the different clinical contexts."}, {"title": "\"It depends\": Configuring Al to Improve Clinical Usefulness Across Contexts", "content": "Imaging clinics and general hospitals usually examine patients referred by general practitioners. Of such patients the majority of the examinations are deemed \"normal\" or with findings related to infections. Hospitals with emergency departments may observe an increased prevalence of trauma-related findings, whereas spe- cialised hospitals of post-operative, oncological, and chronic nature, as exemplified in these quotes: That depends on the setting. If you're in a private clinic, most of the X-rays are normal... [111] If there's something wrong, that could be pneumonia or a tumour, but usually, it's pneumonia when you go out to a private clinic [115, Senior, Spe- cialised Hospital / Imaging Clinic, Denmark]. However, detecting pneumonia would not bring value in other types of settings as high- lighted by P05: If you're working in a trauma centre, the number of critical findings [e.g. pneumothorax or hemothorax] would definitely be more than in [K5], where most of the time it's just coughs and fever [S18, Senior, Big General Hospital, Kenya]. We argue that to deliver a clinically useful AI-based system for radiologists, it is imperative to understand the local population served by the clinical site where the system is implemented. Otherwise, the developers may risk deploying a system detecting findings that may be objectively rele- vant to patient management yet not prevalent at the deployment site. Dependency 4: AI medical focus depends on user expertise level. Junior radiologists may interpret a single X-ray for up to tens of minutes. Whereas, according to our senior participants, interpret- ing a chest X-ray takes around 1 to 2 minutes. This means that with experience, many findings become \"obvious\" and are no feat to detect. When discussing the decision support functionality of our prototypes and previous systems that our participants had pi- loted, the common complaint related to the detection of \"obvious\" radiological findings, which took additional time to discern. If it's an obvious finding, we'll see that one quickly, and we all agree on it. The problem comes when it's something more subtle [106, Senior, Big General Hospital, Kenya]. Detecting the difficult or \"subtle\" radiological findings is where the value lies for senior radiologists. However, the less experienced, the more support a radiologist may accept. This was captured by P01: Maybe it'll help the resident radiologist in the first or second year, but I don't think"}, {"title": "\"It depends\": Configuring Al to Improve Clinical Usefulness Across Contexts", "content": "it will help a specialised radiologist with experience because once we can have a look, we can't miss something like this [101, Senior, Small General Hospital, Kenya). This means that in order to support different radiologists in practice, AI-based systems may need to allow users to select findings to receive support with. Without such configuration, discerning AI predictions regarding \"obvious\" findings, even when true, would result in more time spent and annoyance. Dependency 5: AI medical focus depends on patient context. Radi- ologists are not interpreting medical imaging to find every possible finding. Rather, they are interpreting them to help the ordering clinicians take action in patient management. Such actions usually occur when a new condition is being diagnosed, or a patient's health may be at risk. However, the clinical meaning of certain radiological findings depends on the location of a patient. This means that a finding may be expected when observed in an examination of a patient who is admitted to a hospital. Whereas the same finding observed in an examination of a patient who is not admitted to a hospital may warrant immediate action. Our participants stressed that useful prioritisation should con- sider patients' medical history to filter out already-known findings, which our prototype could not do. But how urgent is it? We know that pneumothorax has decreased. It's a big heart, but it's much smaller than it was a week ago. It has [pleural] effusion, but much, much less than it was a week ago. That's the thing we miss with this [111, Senior, Specialised Hospital / Imaging Clinic, Denmark]. In this quote, P11 explains that the examination they looked at may not be urgent at all despite the fact that the AI correctly detected three findings, one of them (pneumothorax) being life-threatening. These findings would not be urgent if they were already known to the ordering clinician. In such a case, the patient would have already been undergoing treatment, and this examination's sole purpose was to control its progress. In specialised hospitals and bigger general hospitals, patients often have taken several X-rays to monitor the progress of treatment. This means that the same findings, but of different severity, will be visible on their exami- nations. The ability to assess the detected findings in the light of patient history is crucial to correctly prioritise findings that warrant clinical action. When looking at radiologists' work from the perspective of con- tributing to the broader clinical work, it is counterproductive to prioritise findings that clinicians taking care of a patient are already aware of. In other words, a radiological finding may be relevant to detect on examinations from patients who are not admitted to a hospital, but not so much for patients currently admitted. A senior radiologist explained, It depends on the findings, and it depends on the patient... some findings in the out-patients would be more important to be prioritised than if they're in-house. Because if they're in-house, then I would suspect that someone not from the radiology department would have looked at them. If it's out-patient, then nobody has looked at them... [I10, Senior, Specialised Hospital, Denmark]. Whereas, as explained by P10, patients referred from outside of a hospital are more likely to have conditions that their doctors are unaware of. Thus, the location of the patient is crucial to selecting which findings are relevant to receiving support from an AI-based system."}, {"title": "#2 Recommendation:", "content": "Enable users to select radiological findings."}, {"title": "4.4 AI Decision Threshold", "content": "At what certainty level should the AI inform a user about detected findings? Specifying when a radiological AI-based system should inform a user about a finding is usually done by specifying a de- cision threshold (see Fig. 7). Selecting a specific threshold value determines the measured performance of an Al model captured by evaluation metrics like specificity, sensitivity, or positive and negative predictive values. Arguably, in practice, a decontextualised performance value is less important than the practical consequences of selecting a specific threshold level. Every time an AI model de- tects a finding (based on a selected threshold), a radiologist may have to take action to assess it. The balance between clinical value and additional burden is thus closely tied to how well the threshold is configured to match the local clinical context. We conceptualised four dependencies that influence the configuration of the AI deci- sion threshold. Dependency 6: AI decision threshold depends on medical knowl- edge. While some of the radiological findings are well understood across the contexts, some definitions are more subjective and their meanings change across countries. Infiltration or consolidation are two examples of radiological findings which have been found to be used differently in clinical practice in Denmark and Kenya. More- over, some of the findings were too vague for the radiologists to decide how to assess them, for example, I think vascular changes can mean one of two things if it's the big vessels - I think it's important to have it, e.g., if the computer can say the aorta is big... It could also be about... the small vessels, and then it's more like stasis. Then it's quite different [117, Junior, Specialised hospital, Denmark]. The underly- ing definition of a finding, in this described case, affected how P13 understood the condition and what threshold level they deemed"}, {"title": "\"It depends\": Configuring Al to Improve Clinical Usefulness Across Contexts", "content": "appropriate. Within radiology", "7": "AI decision threshold depends on user expertise level. Often, junior and senior radiologists are juxtaposed as two groups of AI support end-users with different needs. This is also visible in the strategy for selecting thresholds. When used by junior radiologists, both junior and senior radi- ologists (who supervised them) leaned towards accepting AI pre- dictions only with a high degree of certainty. As explained before, the interpretation of chest X-rays is uniquely subjective. It takes experience to report them with a high degree of certainty. In this context, an uncertain AI prediction would jeopardise the learning process and introduce more confusion, resulting in more work for the junior students and their supervisors. On the other hand, allowing senior radiologists to set the thresh- old for different findings according to their personal preferences could entice them to utilise the system in their own way. P05, who also had senior administrative experience, explained that senior radiologists do not always have the same level of expertise and"}]}