{"title": "Multi-modal Data Fusion and Deep Ensemble Learning for Accurate Crop Yield Prediction", "authors": ["Akshay Dagadu Yewlea", "Laman Mirzayeva", "Oktay Karaku\u015f"], "abstract": "This study introduces RicEns-Net, a novel Deep Ensemble model designed to predict crop yields by integrating diverse data sources through multimodal data fusion techniques. The research focuses specifically on the use of synthetic aperture radar (SAR), optical remote sensing data from Sentinel 1, 2, and 3 satellites, and meteorological measurements such as surface temperature and rainfall. The initial field data for the study were acquired through Ernst & Young's (EY) Open Science Challenge 2023. The primary objective is to enhance the precision of crop yield prediction by developing a machine-learning framework capable of handling complex environmental data. A comprehensive data engineering process was employed to select the most informative features from over 100 potential predictors, reducing the set to 15 features from 5 distinct modalities. This step mitigates the \u201ccurse of dimensionality\" and enhances model performance. The RicEns-Net architecture combines multiple machine learning algorithms in a deep ensemble framework, integrating the strengths of each technique to improve predictive accuracy. Experimental results demonstrate that RicEns-Net achieves a mean absolute error (MAE) of 341 kg/Ha (roughly corresponds to 5-6% of the lowest average yield in the region), significantly exceeding the performance of previous state-of-the-art models, including those developed during the EY challenge.", "sections": [{"title": "1. Introduction", "content": "This paper is grounded in the purpose and drive behind one of the Sustainable Development Goals (SDG) outlined by the United Nations\u2014a comprehensive set of 17 objectives to be achieved by 2030 [1]. These goals collectively embody humanity's pursuit of a sustainable future for both the planet and its inhabitants. Serving as a global framework, the 17 SDGs guide international endeavours to address the challenges posed by climate change while harmonising human ambitions for prosperity and improved quality of life. Central to this vision is the assurance of food security [2], particularly for a significant portion of the global population residing in environmentally vulnerable areas susceptible to the impacts of climate and weather fluctuations.\nRice is one of the most important staple foods globally, feeding more than half of the world's population. It is cultivated on over 160 million hectares, producing around 500 million metric tons annually, with the majority of production concentrated in Asia. The region accounts for nearly 90% of global rice output, with countries such as China, India, and Indonesia leading in production. Besides being a dietary staple, rice also supports the livelihoods of millions of farmers, playing a vital role in rural economies. However, rice cultivation is highly resource-intensive, requiring significant amounts of water and labour, and is particularly vulnerable to climate change. Rising temperatures, changing precipitation patterns, and the increasing frequency of extreme weather events threaten rice yields globally, posing challenges to food security in many regions.\nThis study underscores the critical importance of rice crops and Vietnam, focusing on their global and regional significance. Rice, often referred to as a \u201cGift of God\" for its nutritional value, is a cornerstone of food security and public health worldwide. Despite its critical role, less than 8% of global rice production enters international trade [3], emphasizing its largely localized consumption patterns, as noted by the Food and Agriculture Organisation Corporate Statistical Database (FAOSTAT). However, Vietnam stands as an exception, being one of the world's leading rice exporters. The Mekong Delta, in particular, is central to the nation's status as a global rice powerhouse, with its fertile paddy fields supporting diverse rice varieties.\nIn Vietnam, rice holds unparalleled cultural, economic, and ecological importance. It serves as a dietary staple, forming the foundation of traditional cuisine, while also being integral to the liveli-hoods of millions of rural farmers. The sector is a driver of economic development, supported by government initiatives aimed at boosting productivity and sustainability. However, the ecological and climatic demands of rice cultivation present significant challenges. As a water-intensive crop, rice is highly sensitive to temperature fluctuations, requiring an optimal range of 25-35\u00b0C. Brief exposure to extreme heat or untimely rainfall during the reproductive stage can result in sterility or yield loss. This vulnerability, coupled with the long growing periods, makes rice cultivation particularly susceptible to climate change, underscoring the urgency of sustainable practices in Vietnam and globally.\nThis paper introduces RicEns-Net, a novel ensemble learning model designed for accurate crop yield prediction. By integrating five diverse remote sensing data sources\u2014Sentinel-1, Sentinel-2, Sentinel-3, NASA's Goddard Earth Sciences (GES) Data and Information Services Center (DISC), and field measurements the proposed framework leverages sophisticated data engineering techniques to enhance predictive performance. The model effectively combines synthetic aperture radar (SAR), multispectral imaging (MSI), meteorological parameters, and ground-truth observations, ensuring a robust and comprehensive approach to crop yield estimation. The inclusion of multi-modal data sources helps mitigate uncertainties associated with individual datasets, improving both spatial and temporal resolution in predictions.\nThe remainder of this paper is organized as follows: Section 2 reviews related work, analysing previous findings and establishing the foundation for the study's objectives and contributions. Section 3 details the materials and methods, including descriptions of data sources, preprocessing techniques, and feature engineering approaches. Section 4 presents the experimental results derived from the proposed model, followed by Section 5, which interprets these findings and discusses their implications. Finally, Section 6 summarizes the study, outlines its limitations, and highlights potential directions for future research."}, {"title": "2. Related Works", "content": "Advancements have influenced the evolution of crop yield monitoring in sensor technology and data analysis methodologies. While early studies highlighted rainfall as the primary determinant of crop yield, a key shift occurred in 1968 with the recognition of soil moisture as a more reliable predictor by Baier and Robertson [4]. Their work leverages spectral data to estimate crop yield based on vegetation health indicators. Over time, numerous vegetation indices (VIs) have been developed to assess vegetative conditions and physiological characteristics of crops. These VIs, including the Normalized Difference Vegetation Index (NDVI), Leaf Area Index (LAI) [5], and Transformed Soil Adjusted Vegetation Index (TSAVI) [6], play a crucial role in crop prediction models. Advancements in hyperspectral imaging have enabled the capture of fine-grained spectral data, facilitating the development of biochemical indices for quantifying plant constituents.\nRice crop yield estimation relies on understanding the crop's growth stages and environmental factors. Water level in paddy fields, rather than direct precipitation, is crucial for irrigated rice fields. Accumulating temperature is more important than temperature at certain times, as it affects the crop's development stages. These factors are integrated into crop models to predict yield accurately.\nIn the early 2000s, research surged leveraging imaging and machine learning technologies for crop yield prediction. Studies introduced novel methodologies, such as artificial neural networks (ANN) and SVR, to analyse remote sensing data and historical yield records. These approaches demonstrated more precise results compared to traditional models and prepared for more precise and scalable methods for estimating crop yields. Uno et al. [7] analyse hyperspectral images of corn plots in Canada using statistical and ANN approaches, demonstrating the potential of ANNs in predicting yield with higher accuracy compared to conventional models. Li et al. [8] introduce a methodology employing ANN models to predict corn and soybean yields in the United States \u201ccorn belt\" region, achieving high prediction accuracy through historical yield data and NDVI time series. Bala and Islam [9] estimate potato yields in Bangladesh using TERRA MODIS reflectance data and Vegetation Indices (VIs), demonstrating the effectiveness of VIs derived from remote sensing for early yield estimation. Li et al. [10] employ SVR and multi-temporal Landsat TM NDVIs to predict winter wheat yield in China, showcasing the precision and effectiveness of SVR models in yield estimation. Stojanova et al. [11] integrate LiDAR and Landsat satellite data using machine learning techniques to model vegetation characteristics in Slovenia. Their approach combines the precision of LiDAR data with the broad coverage of satellite data, facilitating effective forest management and monitoring processes.\nFurthermore, Mosleh et al. [12] evaluated the efficacy of remote sensing imagery in mapping rice areas and forecasting production, highlighting challenges such as spatial resolution limitations and issues with radar imagery. Johnson et al. [13] developed crop yield forecasting models for the Canadian Prairies, revealing the effectiveness of satellite-derived vegetation indices, particularly NDVI, in predicting yield potential. Pantazi et al. [14] proposed a model for winter wheat yield prediction, integrating soil spectroscopy and remote sensing data to visually depict yield-influencing factors. Ramos et al. [15] introduced an optimised Random Forest algorithm for maize-crop yield prediction, emphasising the importance of vegetation indices like NDVI, NDRE, and GNDVI. Li et al. [16] utilised extreme gradient boosting machine learning to accurately predict vegetation growth in China, achieving high predictive accuracy and demonstrating effectiveness under diverse conditions. Zhang et al. [17] employed field-surveyed data to predict smallholder maize yield, with novel insights into the performance of various vegetation indices and machine learning techniques.\nRecent studies have demonstrated the efficacy of utilising Sentinel-2 satellite imagery and ma-chine learning techniques for predicting crop yields and mapping crop types in various agricultural settings. Son et al. [18] employed Sentinel-2 image composites and machine learning algorithms to forecast rice crop yields in Taiwan, finding that Support Vector Machines (SVM) outperformed RF and ANN at the field level, indicating their potential for accurate yield predictions approximately one month before harvesting. Perich et al. [19] utilised Sentinel-2 imagery to map crop yields at the pixel level in small-scale agriculture, with machine learning models utilising spectral index and raw reflectance data proving effective, even in the presence of cloudy satellite time series. Khan et al. [20] combined ground-based surveys with Sentinel-2 satellite images and deep learning tech-niques to map crop types, achieving high accuracy in identifying staple crops like rice, wheat, and sugarcane within the first four weeks of sowing.\nAlong with Sentinel 2, UAV and other sensor spectral information have also been used in the literature in the last couple of years. Shafi et al. [21] propose XGBoost, LASSO and RF regression models to be utilised via Drone-based multispectral imagery whilst Islam et al. [22] combine remote sensing and meteorological data in stacking multiple regression models for rice crop yield prediction. Zhou et al. [23] compare CNN and LSTM-based models for predicting annual rice yield in Hubei Province, China, utilising ERA5 temperature data, and MODIS vegetation indices, demonstrating that the CNN-LSTM model with spatial heterogeneity outperforms models using only remote sensing data. Arshad et al. [24] evaluate the performance of RF and SVR, in predicting wheat yield in southern Pakistan using a combination of remote sensing indices and climatic variables where RF outperforms other methods. Asadollah et al. [25] assess the effectiveness of using a novel Randomized Search cross-validation (RScv) optimization algorithm with four machine learning models to predict annual yields of four crops (Barley, Oats, Rye, and Wheat) across 20 European countries, demonstrating improved prediction accuracy through satellite-based climate and soil data.\nFurthermore, Lu et al. [26] present a state-of-the-art CNN-BiGRU model enhanced by GOA and a novel attention mechanism (GCBA) for accurate county-level soybean yield estimation in the U.S., leveraging multi-source remote sensing data and outperforming existing models in yield prediction accuracy. Killeen et al. [27] investigate UAV-based corn yield prediction using RF and linear regression models and find that spatial cross-validation reduces over-optimism in yield prediction compared to standard 10-fold cross-validation, with LR showing better spatial generalizability than RF. Dhaliwal and Williams II [28] use a 26-year dataset on US sweet corn production to evaluate machine learning models for yield prediction, finding that RF performs best, with year, location, and seed source identified as the most influential variables.\nRecently, Gadupudi et al. [29] demonstrated integrating ML strategies like RF and Decision Trees alongside DL models such as LSTM and RNN to enhance crop prediction accuracy, incor-porating soil attributes, climate data, and cost analyses to optimize outcomes. Similarly, Rao et al. [30] employed attention-based CNNs and bidirectional LSTMs with hyperparameter tuning to predict crop yields, showcasing significant improvements in detection performance through meth-ods like the shuffling shepherd optimization algorithm. Sharma et al. [31] explored the fusion of AI algorithms, including logistic regression and IoT-enabled analytics, to tailor recommendations based on regional agricultural parameters, advancing productivity and diversification.\nThe diverse literature outcomes examined previously, along with numerous others, have high-lighted the multidimensional potential of AI in transforming traditional agricultural practices into more data-driven, adaptive systems. They have employed a variety of data types from different sources and machine learning models. This diversity presents challenges in generalising techniques across different datasets, yet it also enhances performance for specific datasets. The adoption of multi-modal data usage, multi-modal AI techniques, and Ensemble methods has emerged as the current practice in this research field. Shahhosseini et al. [32] explore the predictive performance of two novel CNN-DNN machine learning ensemble models for forecasting county-level corn yields across the US Corn Belt. By combining management, environmental, and historical yield data from 1980 to 2019, the study compares the effectiveness of homogeneous and heterogeneous ensemble cre-ation methods, finding that homogeneous ensembles provide the most accurate yield predictions, offering the potential for the development of a reliable tool to aid agronomic decision-making.\nGavahi et al. [33] introduce DeepYield, a novel approach for crop yield forecasting that combines Convolutional Long Short-Term Memory (ConvLSTM) and 3-Dimensional CNN (3DCNN). By integrating spatiotemporal features extracted from remote sensing data, including MODIS Land Surface Temperature (LST), Surface Reflectance (SR), and Land Cover (LC), DeepYield outper-forms traditional methods and demonstrates more precise forecasting accuracy for soybean yields across the Contiguous United States (CONUS). Zare et al. [34] investigate the impact of data assimilation techniques on improving crop yield predictions by assimilating LAI data into three single crop models and their multimode ensemble using a particle filtering algorithm. Results from a case study in southwestern Germany reveal that data assimilation significantly enhances LAI simulation accuracy and grain yield prediction, particularly for certain crop models, highlighting the potential for further improvements in data assimilation applications through regional model calibration and input uncertainty analysis.\nMoreover, Gopi and Karthikeyan [35] introduce the Red Fox Optimization with Ensemble Recurrent Neural Network for Crop Recommendation and Yield Prediction (RFOERNN-CRYP) model, which leverages deep learning methods to provide automated crop recommendations and yield predictions. By employing ensemble learning with three different deep learning models (LSTM, bidirectional LSTM (BiLSTM), and gated recurrent unit (GRU)) and optimising hy-perparameters using the RFO algorithm, the proposed model demonstrates improved performance compared to individual classifiers, offering valuable support for farmers in decision-making pro-cesses related to crop cultivation. From a similar perspective, Boppudi et al. [36] propose a deep ensemble model for accurately predicting crop yields in India, addressing the challenge posed by variations in weather and environmental factors. The model (Deep Max Out, Bi-GRU and CNN) incorporates improved preprocessing techniques, feature selection using the IBS-BOA algorithm, and prediction through a combination of Deep Ensemble Model and Ensemble classifiers, resulting in significantly reduced error rates compared to existing methods.\nRecently, Umamaheswari and Madhumathi [37] applied a stacking ensemble approach using regressors like SVR, KNN, and RF as base learners, with LASSO regression as the meta-learner, achieving enhanced prediction precision. Osibo et al. [38] demonstrated the integration of weighted ensemble methods with remote sensing data, achieving better results compared to state-of-the-art models while simplifying data integration. Zhang et al. [39] constructed the StackReg framework, combining UAV-acquired multispectral data with ridge regression, SVM, Cubist, and XGBoost, which consistently outperformed base models, particularly in multi-stage settings. These studies highlight the critical role of ensemble learning in improving prediction reliability, offering versatile solutions adaptable to diverse agricultural contexts.\nIn the sequel, we introduce a novel framework for predicting crop yields, named \u201cRicEns-Net.\" This framework incorporates advanced data engineering processes involving five unique data sources, namely Sentinel 1/2/3, NASA's Goddard Earth Sciences (GES) Data and Information Services Centre (DISC), and field measurements. The novelty of RicEns-Net lies in its integration of these diverse and rich sources of multi-modal data, comprising 15 features selected from a pool of over 100, within an advanced Deep Ensemble model. This model encompasses widely-used CNN and MLP architectures, as well as less explored DenseNet and Autoencoder architectures, which have been infrequently utilised or entirely unexplored in existing literature."}, {"title": "2.1. Objectives & Contributions", "content": "The key objectives and related contributions of this research are as follows:\n\u2022 Integrate diverse remote sensing and meteorological data to enhance the accuracy and relia-bility of crop yield forecasting.\nContribution: We successfully unified radar, optical imagery, and meteorological data into a coherent multimodal dataset. This integration demonstrated the practical benefits of combin-ing diverse data sources, providing a foundation for robust and accurate crop yield forecasting models.\n\u2022 Address feature complexity and dimensionality challenges through advanced feature engi-neering and selection.\nContribution: We developed and implemented novel feature engineering and selection tech-niques, effectively reducing feature dimensionality while preserving essential predictive at-tributes. This contribution advanced the methodology for handling multimodal datasets in agricultural forecasting.\n\u2022 Develop a novel deep ensemble learning model to improve the precision of crop yield prediction using multimodal data sources.\nContribution: We designed a deep ensemble learning framework that leverages data from SAR, MSI, and meteorological sources. The model achieved state-of-the-art performance, significantly enhancing precision and reliability in crop yield prediction tasks.\n\u2022 Demonstrate the effectiveness of multimodal data fusion through performance comparisons with state-of-the-art machine learning techniques.\nContribution: We performed extensive benchmarking of the proposed model against leading machine learning techniques, validating the effectiveness of multimodal data fusion. The results highlighted the higher performance of the model and provided insights into the role of data integration in improving predictive accuracy."}, {"title": "3. Materials and Methods", "content": ""}, {"title": "3.1. Study Area & Rice Crop Details", "content": "As stated earlier, this study begins by employing the dataset offered by EY for the 2023 iteration of their Open Science Data Challenge [40]. The dataset encompasses information from 557 farm sites situated in Chau Thanh, Thoai Son, and Chau Phu districts within the province of An Giang in Vietnam (see Figure 1). The study province of An Giang relies significantly on agriculture as a cornerstone of its economy. Notably, An Giang province is situated in the Mekong River delta region, crucial for providing irrigation to support rice cultivation. The dataset, supplied by E\u03a5, contains fundamental details for each crop, including District Name, Latitude, Longitude, Crop Season, Crop Frequency, Harvest Date, Crop Area, and Yield as given in Table 1.\nEvery entry in the primary dataset represents an individual crop and is characterised by eight features, including three categorical variables (District name, Crop Season [WS=Winter Spring; SA = Summer Autumn], and Crop Frequency of the specified farm [D = Twice; T = Thrice]) and five numerical variables (Latitude, Longitude, Harvest Date, Area [Hectares], and Yield Rate"}, {"title": "3.2. Data/Feature Extraction", "content": ""}, {"title": "3.2.1. Sentinel-1", "content": "Sentinel-1 operates with four distinct acquisition modes: Stripmap (SM), Interferometric Wide Swath (IW), Extra Wide Swath (EW), and Wave (WV). During Synthetic Aperture Radar (SAR) acquisition, known as the \"datatake\u201d process, data from SM, IW, and EW modes is divided into smaller, manageable slices. These slices undergo processing to generate different product levels. Level-0 products contain raw sensor data, while Level-1 products provide calibrated imaging data such as Single Look Complex (SLC) and Ground Range Detected (GRD) formats, essential for in-terferometry and georeferenced analysis. Finally, Level-2 products include higher-level geophysical measurements, such as Ocean (OCN) products, which support oceanographic and environmental applications.\nSentinel 1 delivers SAR images featuring two polarisations, vertical (VV) and horizontal (VH), characterised by the difference in the polarisation of their transmitted and received signals. The polarisation of radar signals plays a crucial role in deciphering the structure and orientation of surface elements on the land. The radar signal experiences scattering and depolarisation due to the randomly oriented structure of plant leaves as it undergoes multiple bounces. By comparing the vertical (VV) and horizontal (VH) components, the degree of scattering by the land surface can be discerned. In our model, we incorporate this technique through the VV/VHratio feature. The data was collected by defining a geographical bounding box with a size of 0.001 degree, resulting in an output array size of 3x3. However, some location data did not conform to this shape and required trimming to achieve a 3x3 box size. Given Sentinel 1's spatial resolution of 10 meters, each box corresponds to an area of 30 meters by 30 meters. The subsequent features were derived from Sentinel 1 SAR data\n\u2022 Set 1 (4 variables) \u2192 VVmean, VHmean,VV/V Hratio,mean, RV Imean\nwhere the radar vegetation index (RVI) is given as\n$RVI = \\frac{VV}{\\sqrt{VV + VH}}$\n(1)"}, {"title": "3.2.2. Sentinel-2", "content": "Sentinel-2 imagery is collected through a continuous acquisition process known as 'datatake,' covering up to 15,000 km in length. The acquired data is structured into products at different processing levels. Sentinel-2 products are organized into tiles or granules, following a Universal Transverse Mercator (UTM) projection system to ensure global coverage.\nAt Level-1B, the data is provided in granules of 23 km \u00d7 25 km, containing radiometrically cali-brated and geometrically refined imagery. The Level-1C and Level-2A products are structured into 110 km \u00d7 110 km tiles, ensuring seamless coverage across designated UTM zones. Each tile over-laps with neighboring ones to maintain spatial continuity and facilitate multi-temporal analysis. Level-1C includes top-of-atmosphere (TOA) reflectance, while Level-2A applies atmospheric cor-rections to generate bottom-of-atmosphere (BOA) reflectance, making it suitable for land surface monitoring and vegetation analysis.\nSentinel 2 data furnishes spectral intensities across 13 bands, encompassing Visual-NIR (VNIR) to Short-Wave Infra-Red (SWIR) regions. Notably, there are four spectral bands, namely Red, Green, Blue, and NIR (B04, B03, B02, and B08), offering a ground resolution of 10 meters. Additionally, six bands exhibit a 20-meter ground resolution, comprising four Red Edge bands (B05, B06, B07, and B08A) and two SWIR bands with distinct wavelengths (B11 and B12). The remaining three bands, with a 60-meter ground resolution, serve specific purposes: B01 for aerosol detection (0.443 \u00b5m), B09 for water vapour observation (0.945 \u00b5m), and B10 for cirrus detection (1.374 \u00b5m). Notably, the Sentinel 2 mission boasts a revisit frequency of 5 days.\nWhen acquiring MSI data, it is crucial to account for the potential impact of cloud cover in the targeted area. With a revisit frequency of 5 days, there are only 6-8 chances to capture images during the period when crops reach full growth before maturation. Given Vietnam's tropical monsoon climate, these image opportunities are prone to cloudiness. The dataset at hand reveals median cloud coverage values of 16% and 21% during the Winter-Spring and Summer-Autumn seasons, respectively.\nIn order to prevent the occurrence of unclear or cloudy images, it is necessary to eliminate those with a high level of cloud coverage. Simultaneously, we aim to capture comprehensive crop data when the plants are at their full growth and exhibit maximum greenness. To achieve optimal outcomes, we conducted experiments with various values for maximum cloud coverage and time windows. Based on the findings detailed in Table 2, we concluded that setting the maximum cloud coverage to 60% and collecting Sentinel-2 MSI data during the 50 days preceding the crop maturation provides favourable results. The objective is to secure a minimum of 4-5 images for each specific location.\nTo ensure that the spectral intensity trends are captured, we identify the minimum, maximum, mean and variance of 9 MSI bands based on all the MSI images available for each location.\n\u2022 Set 2 (36 variables) \u2192 is in a format of \u201cBandstats\u201d where Band = {B02, B03, B04, B05, B06, B07, B08, B11, B12} and stats = {min, max, mean, var}.\nMSI data has been used to create transformational features known as Vegetation Indices given in Table A.5 like NDVI, SR, EVI, EVI2, SAVI, RGVI, DVI, MSR, NIRv, kNDVI, NDVIre, NDRE1, NDRE2 to indicate the volume of vegetation on the land surface.\n\u2022 Set 3 (26 variables) \u2192 is in a format of \"VIstats2\" where VI = {NDVI, SR, EVI, EVI2, SAVI, RGVI, DVI, MSR, NIRv, kNDVI, NDVIre, NDRE1, NDRE2} and stats2 =\n{mean, var}.\nUtilising MSI data, various features, such as NDWI, BSI, and LSWI, as outlined in Table A.5, have been generated to depict soil and water content. This application is particularly advantageous in the context of rice cultivation, where the crop is submerged in water.\n\u2022 Set 4 (6 variables) \u2192 is in a format of \"VI2stats2\" where VI2 = {NDWI, BSI, LSWI} and stats2 = {mean, var}."}, {"title": "3.2.3. Sentinel-3", "content": "Sentinel-3 ensures the continuous availability of high-quality data for monitoring land, ocean, and atmospheric conditions, particularly in coastal areas where accuracy is critical. The mission provides comprehensive environmental observations globally, supporting a range of applications. Sentinel-3 plays a key role in fire detection, inland water surface height measurements, and land ice/snow surface temperature assessments. Its multi-instrument payload enables precise monitor-ing of ocean colour, sea surface temperature, and land surface dynamics, contributing to climate research, water resource management, and disaster response.\nSentinel 3 data was acquired to obtain meteorological information related to environmental variables such as ambient air temperature (METtemp), land surface temperature (LST), solar radi-ation (METsolrad), and specific humidity (METsh). These data sets have been integrated into the model as the following features:\n\u2022 Set 6 (8 variables) \u2192 is in a format of \u201cS3stats2\" where S3 = {METtemp, LST, METsolrad, METsh} and stats2 = {mean, var}."}, {"title": "3.2.4. NASA GES DISC", "content": "Rainfall information was acquired from NASA's Goddard Earth Sciences (GES) Data and Information Services Centre (DISC) through the utilisation of the Google Earth Engine API. The data retrieval involved the utilisation of the precipitation Cal parameter, which denotes rainfall in mm per hour. We organise this data into two distinct features: Rainfall-Totalgrowth and Rainfall-Totalmaturity, encompassing three statistical measures-mean, maximum, and sum as\n\u2022 Set 7 (6 variables) \u2192 is in a format of \u201cNASAGESstats3\" where NASAGES = {Rainfallgrowth,\nRain fallmaturity} and stats3 = {mean, max, sum}."}, {"title": "3.3. Correlation Analysis", "content": "After meticulously gathering all potentially valuable engineered features from multi-modal re-mote sensing data, we proceed to examine their statistical and predictive capabilities for subsequent feature selection. This phase, delineated in this sub-section, initiates with a correlation analysis.\nConcerning the relationship between SAR features and Yieldrate, all four data features exhibit a strong correlation with Yieldrate. As anticipated, the VHmean feature effectively captures the backscattering of the SAR signal by the rice plant leaves, resulting in a higher correlation (0.32) with Yieldrate compared to VVmean (0.25). The VV/VHratio serves as a transformative feature, demonstrating an enhanced correlation (0.45) in comparison to both VVmean and VHmean individ-ually. Notably, the Radar Vegetation Index (RVI) shows a similar positive correlation (0.41) with the Yield Rate.\nAs previously indicated regarding Sentinel-2 data, we derive spectral statistics from 9 bands: B02 Blue, B03 Green, B04 Red, B05-B07 Red Edge, B08 NIR, and B11-B12 SWIR. These statis-tics, namely min, max, mean, and variance, are incorporated into the model. Upon analysing observations across all bands, it is noteworthy that variance features exhibit a relatively low corre-lation (< 0.1) with the target variable, whereas other statistical measures demonstrate correlation coefficient values surpassing 0.3.\nSpectral data is employed to generate transformative characteristics known as Vegetative In-dices (VI). These indices serve as a more efficient measure for discerning and monitoring variations in plant phenology. In our approach, we utilise VIs such as NDVI, NDVIre, NDRE1, NDRE2, SR, DVI, MSR, EVI, EVI2, SAVI and RGVI, NIRv, and kNDVI. These features are integrated into the model in the form of their respective mean and variance features. However, the variance feature is omitted from the model due to its limited correlation with the target variable. Notably, kNDVI exhibits one of the highest correlations with Yield, while features like DVI, EVI, and NIRV demonstrate some of the lowest correlations.\nSimilar to the vegetation indices, we can employ optical data to compute additional indices that precisely quantify the environmental conditions of the crop's cultivation. NDWI, LSWI16, and LSWI20 specifically indicate the water or moisture content in the soil, which is crucial for rice cultivation, requiring flooded fields. Conversely, BSI reflects the soil condition. We incorporate these attributes into the model as their respective Mean and Variance features. Similar to the approach with vegetation indices, we have excluded the variance feature from the models due to its limited correlation with Yield. Notably, all water indices exhibit high correlations with each other and share a similar correlation with Yield.\nLastly, concerning meteorological characteristics, the average ambient air temperature (refers to variable \u201cMETtemp,mean\u201d) and specific humidity (METsh,mean) exhibit the strongest correlation with crop yield, and they also demonstrate a high degree of correlation between themselves. Solar radiation (METsolrad,mean) emerges as a significant predictor due to its notable correlation with yield and comparatively lower correlation with other meteorological features."}, {"title": "3.4. Feature Selection", "content": "Up to this point, all the engineered features, totalling 94 in number, have undergone various stages of processing. These stages include (i) grouping, involving the arrangement of data types and condensation into categorical, numerical, and object types; (ii) scaling, which entails MinMax scaling; and (iii) splitting through a train-test split with a ratio of 3:1.\nAs outlined in the preceding sections, the subset of the 94 features exhibits significant corre-lation, and incorporating all these features in the models would lead to computationally intensive experiments. To mitigate this, during the final processing stage, we execute multiple rounds of feature selection, including Pairwise Feature Independence Check using the x\u00b2 test, statistical sig-nificance tests based on p-values, outlier removal, and thresholding for correlation and variance. Following these stages, the outcome is a refined set of 15 predictive (11 numerical & 4 categorical) features and 1 target feature all of which are shown in Table 3."}, {"title": "3.5. The Proposed Model - RicEns-Net", "content": "After the extensive stages of data engineering, pre-processing, and preparation mentioned ear-lier, the 15 most informative and significant data features from 5 different data modalities will be employed to predict rice yield for the specified locations. This section provides a comprehensive introduction to the proposed deep ensemble model, RicEns-Net. As mentioned in the earlier stages, deep learning models have currently been dominating yield prediction studies. This paper stands parallel with these advances in the literature but tries to explore complementary advantages of dif-ferent deep learning regression techniques under a deep ensemble architecture named RicEns-Net. The details of RicEns-Net model architectures are presented in Figure 5.\nRicEns-Net utilises two traditional deep learning architectures, CNN and MLP. Despite the various designed versions of these models in the literature, no single architecture has emerged as a general solution. This motivated us to create our architecture tailored to achieve optimal performance for the rice yield prediction dataset. In addition to CNN and MLP, RicEns-Net incorporates two significant deep learning architectures: DenseNet and AutoEncoder (AE). While these architectures are scarcely used in yield prediction literature, they are prevalent in crucial remote sensing applications, such as semantic segmentation and classification.\nOur motivation for incorporating DenseNet and AE architectures into our ensemble model stems from their respective advantages in handling complex data. AE architectures are valuable for rice yield prediction as they efficiently reduce dimensionality, extracting essential features while minimizing noise. Conversely, DenseNet architectures enhance deep learning by ensuring robust gradient flow through dense connections, thereby improving feature propagation and enabling the model to learn intricate patterns within agricultural data. These combined capabilities make the ensemble model more effective in predicting rice yield.\nIn developing the RicEns-Net ensemble model, extensive testing was conducted to determine the optimal architectures for each individual deep learning model. This rigorous process involved systematically evaluating various configurations, including the number of layers, types of activation functions, and loss functions. For each model, we experimented with different depths ranging from shallow to deep architectures to find the optimal balance between complexity and performance. We also tested various activation functions, such as ReLU, sigmoid, SiLU, and tanh, to identify the most effective function for each model. Additionally, we compared multiple loss functions, including mean squared error, mean absolute error, and Huber loss, to select the one that minimized prediction errors most effectively. Furthermore, each model's architecture was refined through a series of experiments, incorporating cross-validation and hyperparameter tuning, to ensure the best performance for predicting rice yield. This exhaustive testing process ensured that each model within the ensemble was optimally configured to contribute to the overall predictive power of RicEns-Net. The details of these architectures, including the final selected configurations, are illustrated in Figure 5. These configurations were chosen based on comprehensive performance evaluations, ensuring that each component model enhances the proposed deep ensemble's accuracy and robustness.\nIn order to create the RicEns-Net's ensemble output, we use a weighted average approach. Let yi be the output of the i-th model, and let wi be the weight assigned to the i-th model. The ensemble output YRicEns-Net is then given by:\n$Y_{RicEns-Net} = \\sum_{i=1}^{N}W_iY_i$\n(2)\nwhere N is 4 the total number of models in the ensemble and i refers to each model with keywords {Dense, AE, MLP,CNN}.\nThe weights wi are determined based on the validation errors of each model. Let ei be the vali-dation error of the i-th model. We assign the weights such that a lower validation error corresponds to a higher weight. Specifically, we can define the weight wi as:\n$W_i = \\frac{\\frac{1}{e_i}}{\\sum_{j=1}^{N}\\frac{1}{e_j}}$\n(3)\nThis choice ensures that the weights are normalised to sum to 1:\n$\\sum_{i=1}^{N}W_i = 1$\n(4)\nThus, the final ensemble output is a weighted average of the individual model outputs, where the weights are inversely proportional to the validation errors, normalised to sum to 1. This approach prioritises models with lower validation errors, giving them a higher influence on the ensemble output."}, {"title": "3.6. On Deciding State-of-the-Art", "content": "Despite significant advancements in computer vision research through the development of novel deep learning architectures, yield prediction research predominantly relies on traditional deep learn-ing methods like CNN [33, 36, 42", "43\u201345": "as well as state"}]}