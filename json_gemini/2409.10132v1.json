{"title": "STRUEDIT: Structured Outputs Enable the Fast and Accurate Knowledge Editing for Large Language Models", "authors": ["Baolong Bi", "Shenghua Liu", "Yiwei Wang", "Lingrui Mei", "Hongcheng Gao", "Junfeng Fang", "Xueqi Cheng"], "abstract": "As the modern tool of choice for question answering, large language models (LLMs) are expected to deliver answers with up-to-date knowledge. To achieve such ideal question-answering systems, locating and then editing outdated knowledge in the natural language outputs is a general target of popular knowledge editing methods. However, this target is challenging, as both identifying which tokens to edit in the reasoning steps and ensuring the coherence of the revised reasoning chain are difficult tasks. We argue that these challenges stem from the unstructured nature of natural language outputs. To address the above challenges, we propose Structural Editing (STRUEDIT), an improved baseline for knowledge editing. We first prompt LLMs to produce structured outputs consisting of reasoning triplets. Then, STRUEDIT removes any potentially outdated knowledge and efficiently refills the structured outputs with up-to-date information in a single step. Experimental results show that STRUEDIT consistently delivers the highest accuracy with lowest latency compared with other knowledge editing methods.", "sections": [{"title": "1 Introduction", "content": "With the widespread deployment of large language models (LLMs; OpenAI, 2022, 2023; Touvron et al., 2023a,b; Song et al., 2024), their reliability in answering questions is crucial, which entails accurately responding to queries with up-to-date knowledge. However, the knowledge used for pre-training LLMs cannot guarantee ongoing timeliness because the world is constantly changing. Knowledge editing (KE; Sinitsin et al., 2020; Zhu et al., 2020; De Cao et al., 2021) has been proposed to update the knowledge for LLMs.\nThe main process of existing KE methods can be summarized as Locate-Then-Edit, which requires accurately reflecting specific edited facts within the natural language reasoning steps. In a chain-of-thought (CoT) (Zhang et al., 2022) process, this means adjusting certain natural language reasoning steps based on new knowledge and accurately inferring the final result using that updated information. Model editing (ME; Meng et al., 2022a,b; Mitchell et al., 2022; Yao et al., 2023b; Xu et al., 2024) locates the position of knowledge to be edited, such as neurons in the FFN or matrix regions, and modifies them. In-context editing (ICE; Madaan et al., 2022; Zhong et al., 2023; Zheng et al., 2023; Wang et al., 2024; Bi et al., 2024a,d) locates relevant passages in the edit memory, prompting LLMs to utilize new knowledge to answer questions.\nHowever, it is difficult to identify the tokens that need editing within the natural language reasoning steps, and incorrectly modifying parameters or providing inaccurate knowledge can directly result in editing failure. Additionally, editing the tokens while ensuring the coherence of the output reasoning chain is challenging, as conflicts between new knowledge and parametric knowledge (Petroni et al., 2020; Si et al., 2023; Xie et al., 2024) can lead to hallucinations during the reasoning process (Zhang et al., 2023; Huang et al., 2023a; Wang et al., 2023a) or make stubborn knowledge difficult to edit (Bi et al., 2024a).\nIn this paper, we argue that existing KE methods pose risks due to the Locate-Then-Edit approach based on natural language reasoning. We propose a new paradigm, structural editing, which structures the natural language outputs. Instead of relying on the two-step process of locating and editing, we directly remove all information potentially affected by new knowledge and refill the output based on the updated information. This approach eliminates the challenges caused by the coupling of different reasoning steps, enabling multi-step edits to be completed in a one-shot manner. Building on these insights, we propose an effective improved baseline for knowledge editing, called STRUEDIT. STRUEDIT edits LLM outputs through knowledge structures without the need to locate outdated knowledge and also the corresponding model parameters or input context. We use LLMs to refill new knowledge into the triplet reasoning structure based on specific logical rules, which accelerates reasoning speed and eliminates issues like hallucinations. Specifically, we extract the source entity and sequential relations from the reasoning chain, perform entity matching, and select relations in the knowledge structure to infer the reasoning path and obtain the final answer.\nExperimental results demonstrate that our STRUEDIT consistently achieves the highest editing accuracy and the fastest speed compared to existing KE methods. STRUEDIT maintains robust editing capabilities as the number of reasoning hops and edited instances increases. Our work provides an improved KE baseline for LLMs with higher accuracy, faster performance, and greater robustness, paving the way for further advancements in KE."}, {"title": "2 Knowledge Editing on Multi-Hop Editing Tasks", "content": "In this paper, we focus on multi-hop editing tasks. Single-hop fact editing, such as modifying a fact triplet (s, r, t) to (s, r, t'), has been effectively addressed (Wang et al., 2023b). However, in real-world knowledge question answering (QA), changing one fact can trigger a \"ripple effect\" requiring updates to additional related facts (Cohen et al., 2024). Therefore, in multi-hop editing tasks, it is"}, {"title": "2.1 Multi-Hop Editing", "content": "Multi-hop editing is a more challenging task in KE, where LLMs need to consistently account for both the edited facts and related fact updates during multi-hop reasoning to ensure thorough knowledge revision. The main challenge lies in the potential conflict between new knowledge and the parametric knowledge in LLMs, which can result in factual hallucinations during reasoning (Bi et al., 2024b). For instance, regarding a two-hop fact chain (WWE Velocity, created by, Vince McMahon), (Vince McMahon, spouse, Linda McMahon). With a fact edit (WWE Velocity, created by, Stan Lee) and an additional fact chain (Stan Lee, spouse, Joan Lee), the correct updated answer should be Joan Lee."}, {"title": "2.2 Evaluation and Analysis", "content": "To thoroughly explore the editing capabilities of the main KE methods, including ME, ICE, and the new structural editing paradigm proposed in this paper, we conduct multi-hop editing experiments on the MQUAKE dataset with both open-source (LLAMA2-7B-CHAT) and closed-source (GPT-3.5-TURBO-INSTRUCT) models. Specifically, we construct multi-hop fact chains from the dataset and edit them with new knowledge based on each method. We set the batch size of the edit memory to 1 and full batch for KE evaluation.\nThe batch size refers to the number of instances providing the edited facts for knowledge retrieval. A batch size of 1 means only the new knowledge relevant to the reasoning is provided, while a full batch simulates a real-world editing scenario where all new knowledge is provided, even if it is not directly related to the current reasoning task.\nFrom our observations, we found that structural editing consistently achieves the best performance. Notably, in the full batch size knowledge memory setting, ME and ICE methods perform poorly, while structural editing shows a significant lead on both open-source and closed-source models.\nFurthermore, structural editing shows robust performance across varying batch sizes and reasoning hops compared to other methods. First, all methods show a noticeable drop in average accuracy when moving from batch_size = 1 to batch_size = full. In the ICE methods, IKE experiences the largest drop due to its struggle in retrieving effective new knowledge for complex reasoning chains, while MeLLo is less affected as it breaks down multi-hop queries into sequential single-hop queries. In the ME methods, additional parameter edits can lead to hallucinations. Our proposed structural editing method shows the smallest drop because, unlike other methods, it does not require locating specific knowledge, making it less affected by the number of editing instances.\nAs the number of reasoning hops increases, the accuracy of both ME and ICE methods decreases"}, {"title": "3 STRUEDIT: An Improved Baseline of Knowledge Editing", "content": "Section 2 demonstrates the exceptional accuracy and robustness of structural editing in multi-hop editing tasks. To address more generalized multi-hop QA problems with new knowledge, we propose a more comprehensive method, STRUEDIT, an improved baseline for knowledge editing. The main idea behind ME and ICE methods is to combine edited facts with parametric knowledge, relying on the strong reasoning capabilities of LLMs to answer questions. However, this approach is implicit, as it's unclear whether the model's parameters were correctly updated or if the new knowledge is trusted by the LLMs. To reduce the burden on LLMs and the uncertainty of editing, STRUEDIT does not retain parametric knowledge and no longer targets specific knowledge for editing. Instead, all related knowledge is updated, allowing LLMs to reason over up-to-date knowledge structures based on the extracted logic of the question. We introduce the details of STRUEDIT from the following aspects."}, {"title": "3.1 Structrual Editing on Parametric Output", "content": "STRUEDIT uses up-to-date knowledge from the knowledge structure to edit LLMs' parametric output for multi-hop QA, leveraging the logic rules to reason over the structure. To enable reasoning over the knowledge structure for multi-hop questions, it is essential to provide the necessary conditions, including the source entity and sequential relations. First, we input the initial multi-hop question into the LLMs and use in-context demonstrations to guide them in generating a multi-hop reasoning chain. Then, we extract the source entity and sequential relations from this chain using LLMs, providing logic for subsequent reasoning.\nIn this process, we discard all other entities in the chain reflecting parametric knowledge without checking for conflicts with the new knowledge. We only utilize LLMs to obtain invariant relations, which are invariant over time in the reasoning chain, and entities are very unstable as connections therein. This reflects the core of our STRUEDIT, where we directly remove all information potentially affected by new knowledge and then refill it based on the updated knowledge. This ensures efficient and explicit editing."}, {"title": "3.2 Multi-hop Reasoning with LLMs", "content": "Multi-hop reasoning over a knowledge structure is key to our STRUEDIT approach. Formally, given a source entity ef and a sequential relation R = {r1, ..., r} extracted according to ?? for an h-hop question, we ideally aim to find a reasoning path Pt = {(e0, r1, e1), ..., (eh\u22121, rh, eh)} that leads to the final answer eh.\nHowever, although the source entity and sequential relations provide the reasoning logic, the accuracy of reasoning can be significantly impacted by discrepancies between the entities and relations extracted from the reasoning chain and those in the knowledge structure. For instance, as shown in Figure 3, \"spouse of\" in the sequential relation does not align with \"married to\" in the knowledge structure, which could lead to the selection of an alternate path during reasoning, ultimately resulting in an incorrect outcome. To address this issue, and inspired by Bi et al. (2024c), we adopt the following strategies when entities and relations cannot be precisely matched.\nEntity Matching We construct a candidate set containing all entities, then query the LLMs with e to identify the most closely matching entity.\nRelation Selection Similarly, during the i-hop reasoning, we construct a candidate set based on all relations {r1, ..., rm} associated with the entity ei\u22121 to select the relation most similar to r.\nThe query template for entity matching and relation selection is shown in Figure 4. Entities and relations are aligned through LLM queries to optimally infer a reasoning path P = {(e0, r1, e1), ..., (eh\u22121, rh, eh)} within the knowledge structure, leading to the final answer eh, where e0 best matches the extracted e0 and {r1,...,rh} most closely correspond to the extracted {r1, ..., r}."}, {"title": "4 Experiments", "content": "Unlike the evaluation editing tasks in Section 2.2, we assess KE performance in the form of more generalized question answering tasks. We focus exclusively on the more realistic and challenging multi-hop tasks to assess whether the knowledge has been thoroughly edited. We conduct experiments using MQUAKE-3K (Zhong et al., 2023) along with its challenging derivatives, MQUAKE-2002 and MQUAKE-HARD, introduced by Wang et al. (2024). MQUAKE is a multi-hop QA benchmark for knowledge editing that provides multi-hop knowledge questions to evaluate KE on counterfactual edits. We construct KGs from the knowledge triples provided in MQUAKE to serve as the knowledge structure for our STRUEDIT."}, {"title": "4.2 Models and Baselines", "content": "We examine both closed-source models, including LLAMA2-7B-CHAT and LLAMA2-13B-CHAT, as well as open-source models, including GPT-3.5-TURBO-INSTRUCT and GPT-40-MINI. We use state-of-the-art ME and ICE methods as our baselines for comparison with our STRUEDIT, which include the following approaches:\nROME (Meng et al., 2022a) applies causal mediation analysis to locate the editing area, framing model editing as a least-squares problem under linear equality constraints and solving it using lagrange multipliers.\nMEND (Mitchell et al., 2021) adopt a meta-learning approach that trains a hypernetwork to infer weight updates from the gradient of the inserted fact.\nMEMIT (Meng et al., 2022b) insert new memories into language models by targeting key transformer weights identified as causal mediators of factual knowledge recall.\nIKE (Zheng et al., 2023) uses demonstration contexts without parameter updates, prompting LLMs to perform edits by leveraging newly retrieved knowledge.\nMeLLo (Zhong et al., 2023) guides LLMs in multi-hop knowledge editing by decomposing subproblems and detecting conflicts between parametric knowledge and edited facts.\nDEEPEDIT (Wang et al., 2024) enhances generating coherent reasoning chains with new knowledge through depth-first search."}, {"title": "4.3 Overall Performance", "content": "We set the edit memory to full batch size to reflect real-world scenarios in our experiments. Overall, both ME and ICE methods perform poorly, while our STRUEDIT consistently shows a significant lead. ME methods rely on modifying model structures or parameters to update knowledge, which becomes inefficient when dealing with a large number of new knowledge instances, as in our full batch size experiment. This can negatively impact the model's inherent parametric knowledge and reasoning abilities. In the ICE methods, IKE struggles to retrieve relevant information from the vast amount of new knowledge, resulting in poor editing performance. Although MeLLo and DEEPEDIT attempt to address this limitation through conflict detection and deep search, they are still constrained by the reasoning capabilities of open-source LLMs. Our STRUEDIT demonstrates significant improvement, highlighting its great potential in real-world scenarios.\nThe experimental results on the closed-source models are presented Due to the closed-source nature of the models, we are only able to test the ICE methods and our STRUEDIT. The ICE methods exhibit overall improvement compared to their KE performance on open-source models, as shown with DEEPEDIT showing the most significant gains. This improvement is attributed to the strong in-context learning (ICL) capabilities of the advanced closed-source models. However, our STRUEDIT also benefits from the enhanced ICL abilities of these LLMs, consistently achieving the best performance with an average accuracy that is 58.8% higher than DEEPEDIT.\nCompared to more powerful closed-source models, STRUEDIT shows an even greater lead on smaller open-source models. This indicates that previous KE methods heavily relied on the inherent capabilities of LLMs, while STRUEDIT reduces the burden on LLMs during the KE process."}, {"title": "4.4 Robustness of Knowledge Editing", "content": "The robustness of KE is crucial for assessing whether knowledge has been thoroughly and effectively edited. We evaluate the robustness of knowledge editing by assessing it across both the number of hops in multi-hop QA and the number of edited instances.\nFigure 5 shows the changes in KE performance for ME, ICE methods, and our STRUEDIT as the number of hops in multi-hop QA increases. We observed that, regardless of whether on open-source or closed-source models, all methods experience a noticeable decline in editing performance as the number of hops increases. This decline is primarily due to the hallucinations introduced by multi-hop reasoning and knowledge conflicts. Specifically, ME shows an average decrease of 57% and ICE an average decrease of 56% with each additional hop, whereas STRUEDIT only declines by 38% on average, demonstrating the strong robustness of our STRUEDIT with increasing reasoning hops.\nEdited instances refer to the number of new knowledge updates required in the edit memory. In real-world deployments, where the number of edited instances is often high, the robustness of KE in this aspect becomes especially critical. We conduct experiments based on randomly grouped edited instances of varying quantities, with the results shown Consistent with the observations of Zhong et al. (2023), all methods show further decline when more edits are injected. As the number of edited instances increases, both ME and ICE methods experience a significant decline, particularly in the comparison between 1-instance and 100-instance settings. This decline is primarily due to the challenges of imprecise knowledge localization, which fails to provide effective editing information, and hallucinations caused by knowledge conflicts. In contrast, our STRUEDIT consistently demonstrates the best performance across different instance scenarios, with the smallest average decline."}, {"title": "4.5 Editing Latency", "content": "ME methods are generally slower, as it requires locating and modifying the model based on the edited facts before reasoning. ICE methods are faster, but latency increases when longer text reasoning is needed to improve editing performance, as seen in methods like MeLLo and DEEPEDIT. STRUEDIT demonstrates the best efficiency, even compared to the simplest IKE method, because it achieves strong reasoning performance without relying on LLMs generating lengthy CoT, thanks to the support of knowledge structures."}, {"title": "5 Related Work", "content": "Pre-training on large-scale corpora equips LLMs with extensive parametric memory, including commonsense and factual knowledge. However, this parametric knowledge may be inaccurate due to errors or outdated information in the pre-training data, leading to hallucinations where the content generated by LLMs deviates from established world knowledge.\nKnowledge Conflict To mitigate the hallucinations, tools or retrieval-augmented methods such as ChatGPT Plugins and New Bing, have been proposed as effective solutions to provide external knowledge evidence. However, external knowledge may inevitably conflict with parametric knowledge, leading to unreliable support, especially when LLMs are overly confident in their own parametric knowledge.\nKE has been proposed to update outdated information, enabling models to answer current questions accurately. In general, existed KE can be divided into two main categories. ME involves modifying model parameters or structure to prevent undesired outputs. ICE edit knowledge by prompting LLMs with the newly updated facts. However, both approaches are affected by localization or knowledge conflicts, leading to hallucinations."}, {"title": "6 Conclusion", "content": "In this paper, we proposed a new improved baseline for knowledge editing, called STRUEDIT. Unlike the locate-and-edit KE approaches such as ME and ICE, STRUEDIT removes all parametric knowledge, regardless of whether it conflicts with new knowledge. By leveraging LLMs to extract entities and relations from the original question, STRUEDIT performs multi-hop reasoning over up-to-date knowledge structures to derive accurate answers. This new paradigm offers higher editing accuracy, faster performance, and greater robustness. Our work paves the way for further advancements in knowledge editing."}, {"title": "Limitations", "content": "This work presents an improved baseline for KE. Unlike ME and ICE, which rely on text-based editing information, STRUEDIT requires a more structured knowledge format to support LLM reasoning. The decline from the editing tasks in Table 1 to the QA tasks in Tables 2 and 3 reflects the loss in entity and relation extraction for STRUEDIT. While STRUEDIT demonstrates strong robustness, there is still a noticeable decline as reasoning hops and the number of edited instances increase, indicating potential errors in LLM reasoning."}, {"title": "Ethical Considerations", "content": "In this study, we adhere to ethical guidelines by using only open-source datasets and employing models that are either open-source or well-established in the scientific community. We utilize counterfactual public datasets for knowledge editing to evaluate knowledge updates. Our proposed STRUEDIT method focuses on updating knowledge to enable LLMs to accurately answer real-world questions. We are committed to maintaining high ethical standards throughout our research, emphasizing transparency and promoting the responsible use of technology for the betterment of society."}]}