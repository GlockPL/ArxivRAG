{"title": "From PowerPoint UI Sketches to Web-Based Applications: Pattern-Driven Code Generation for GIS Dashboard Development Using Knowledge-Augmented LLMs, Context-Aware Visual Prompting, and the React Framework", "authors": ["Haowen Xu", "Xiao-Ying Yu"], "abstract": "Developing web-based GIS applications, commonly known as CyberGIS dashboards, for querying and visualizing GIS data in environmental research often demands repetitive and resource-intensive efforts. While Generative AI offers automation potential for code generation, it struggles with complex scientific applications due to challenges in integrating domain knowledge, software engineering principles, and UI design best practices. This paper introduces a knowledge-augmented code generation framework that retrieves software engineering best practices, domain expertise, and advanced technology stacks from a specialized knowledge base to enhance Generative Pre-trained Transformers (GPT) for front-end development. The framework automates the creation of GIS-based web applications (e.g., dashboards, interfaces) from user-defined UI wireframes sketched in tools like PowerPoint or Adobe Illustrator. A novel Context-Aware Visual Prompting method, implemented in Python, extracts layouts and interface features from these wireframes to guide code generation. Our approach leverages Large Language Models (LLMs) to generate front-end code by integrating structured reasoning, software engineering principles, and domain knowledge, drawing inspiration from Chain-of-Thought (CoT) prompting and Retrieval-Augmented Generation (RAG). A case study demonstrates the framework's capability to generate a modular, maintainable web platform hosting multiple dashboards for visualizing environmental and energy data (e.g., time-series, shapefiles, rasters) from user-sketched wireframes. By employing a knowledge-driven approach, the framework produces scalable, industry-standard front-end code using design patterns such as Model-View-ViewModel (MVVM) and frameworks like React. This significantly reduces manual effort in design and coding, pioneering an automated and efficient method for developing smart city software.", "sections": [{"title": "1. Introduction", "content": "Over the past decades, scientific web applications (Web Apps), such as CyberGIS systems, visual analytics dashboards, digital twin platforms, and online decision support systems, have become indispensable tools for both the scientific community and the public to discover, query, visualize, and download vast urban and environmental data sets for smart city research (Ferr\u00e9-Bigorra et al., 2022; Dembski et al., 2020). Aligned with the NSF's cyberinfrastructure (CI) initiative, academia and government agencies have increasingly adopted these applications as part of interdisciplinary informatics projects, providing effective, user-friendly tools for data dissemination (Yu et al., 2021). With advances in internet and communication technologies, computing hardware, and artificial intelligence, these tools are transforming urban and environmental research by enabling data- and simulation-driven insights for decision support (Kadupitige, 2022), fostering collaborative research through data and simulation integration (Parashar et al., 2019) and enhancing education and public engagement in citizen science and voluntary data collection (Skarlatidou et al., 2019). Key application areas include water resource management (Souffront Alcantara et al., 2018; Xu et al., 2022a), hazard mitigation (Mandal et al., 2024; Xu et al., 2020; Garg et al., 2018), intelligent transportation systems (Xu et al., 2023b, 2022c; Ghosh et al., 2017), connected and automated vehicles (Xu et al., 2023c; Kampmann et al., 2019), built-environment and building energy management (Jia et al., 2019; Kim et al., 2022; Xu et al., 2022b), pandemic management (Xu et al., 2021b; Li et al., 2021; Thakur et al., 2020), and urban planning and design (Alatalo et al., 2017). Numerous interdisciplinary studies highlight the transformative potential of these web applications in advancing environmental and urban research, as well as smart city management. Their ongoing evolution is driven by the integration of emerging technologies like artificial intelligence, the Internet of Things (IoT), edge computing, and cyber-physical systems.\nDespite advancements in scientific web applications, developing customized tools like cyberGIS and digital twin platforms for integrating and visualizing diverse environmental or urban data (e.g., hydrological, traffic flow, meteorological data, or simulations) remains highly demanding and resource-intensive (Shanjun et al., 2024; Siddiqui and Mead, 2024; Lei et al., 2023). These efforts require expertise in software and data engineering, as well as time-consuming tasks like client-server development, database management, real-time analytics, machine learning, and simulations (Ikegwu et al., 2022). Consequently, researchers often shift from their core scientific work to learn complex web programming, UI/UX design, and database technologies (Li et al., 2022). Although modern software practices like design patterns aim to streamline development, their effective use demands specialized software engineering knowledge (Fayad et al., 2015). Researchers with data analytics expertise often lack formal software development experience, facing challenges even when skilled engineers are involved (Kim et al., 2017). Designing, deploying,"}, {"title": "2. Literature Review", "content": "LLMs like GPT-3 (Brown et al., 2020), GPT-4 (Sun et al., 2023), and DeepSeek (Guo et al., 2024) have revolutionized software development through autonomous code generation. Their ability to understand and generate human language enables tasks like reasoning, code generation, and problem-solving (Li and Ning, 2023; Tupayachi et al., 2024). Integrating LLMs with RAG techniques enhances domain-specific knowledge retrieval, improving code accuracy and reliability. This synergy automates key development processes, including requirement definition, bug fixing, and program repair, reducing manual effort. Ultimately, LLMs and RAG offer scalable solutions for automating repetitive and complex coding tasks (Meyer et al., 2023; Baldazzi et al., 2023).\n2.1. A Review of LLM-Based Approaches in Software Development\nLLMs are increasingly applied in diverse software engineering tasks, particularly in code generation. This paper focuses on evaluating their capabilities in web application development. The following subsections review their applications in software engineering.\n2.1.1. Automating Software Engineering Tasks\nSeveral studies have reviewed the opportunities and challenges of using LLMs in software engineering. Hou et al. (2023) provides a comprehensive analysis, categorizing LLMs into encoder-only, encoder-decoder, and decoder-only architectures. The increasing use of decoder-only models (e.g., GPT) for automating code generation and completion has significantly reduced manual effort. However, challenges persist, including handling domain-specific knowledge, improving dataset quality, and addressing the complexity of software engineering tasks beyond simple text generation. Key areas for improvement include better data preprocessing, fine-tuning for specific SE tasks, and incorporating diverse datasets, particularly from industrial contexts. Enhancing LLM robustness and refining evaluation metrics remain critical for real-world applications. While LLMs show promise in assisting SE, they are not yet capable of fully replacing human developers in complex processes. Phan et al. (2024) presents HyperAgent, a multi-agent system designed for software engineering (SE) tasks using specialized agents like Planner, Navigator, Code Editor, and Executor. Evaluated on SWE-Bench and Defects4J, HyperAgent excels in GitHub issue resolution, repository-level code generation, and fault localization, outperforming specialized systems in complex multi-step tasks. It automates large-scale coding tasks (e.g., bug fixing, feature addition) using LLMs, reducing manual intervention. However, challenges include scalability across diverse environments and high computational costs. Future work aims to integrate version"}, {"title": "2.1.2. Evaluating LLM for Software Development", "content": "With the rise of generative AI, several studies have reviewed LLMs' feasibility in code generation and complex software development tasks. Liang et al. (2024) examines GPT-4's ability to replicate empirical SE research by generating analysis pipelines. While GPT-4 structured high-level plans well, it lacked domain-specific expertise, with only 30% of its generated code executing without modification. Human oversight remains essential for ensuring accuracy. Sandberg and Zhang (2024) evaluates GPT-4 in full-stack web development, highlighting its efficiency in generating functional applications for simple projects. However, as complexity increases, GPT-4 struggles with debugging and integration, requiring significant human intervention. Gu et al. (2023) assesses ChatGPT, CodeLlama, and PolyCoder in domain-specific coding, revealing struggles with API misuse. To address this, DomCoder integrates API recommendations and chain-of-thought prompting, improving domain-specific automation. However, challenges remain in sourcing domain-specific data and ensuring API consistency. Fan et al. (2023) reviews LLMs like GPT, BERT, and Codex in software engineering tasks, identifying strengths in code completion, bug detection, and automation. Challenges include hallucinations, non-deterministic outputs, and verification issues. Future directions involve improving prompt engineering, integrating LLMs with traditional SE methods, and enhancing automated testing to mitigate hallucinations and improve reliability."}, {"title": "2.1.3. Code Generation", "content": "Ongoing research continues to refine LLM-based code generation. Guo et al. (2024) introduces DeepSeek-Coder, an open-source alternative to proprietary models, with sizes ranging from 1.3B to 33B parameters trained on 2 trillion tokens across 87 programming languages. It enhances cross-file understanding using repository-level data construction and a Fill-in-the-Middle (FIM) approach, supporting a 16K context window for handling complex tasks. Benchmarks show it outperforms CodeLlama and StarCoder, even surpassing GPT-3.5 Turbo in some cases. With a permissive license, DeepSeek-Coder advances autonomous code generation and software development. Zhang et al. (2023) proposes Planning-Guided Transformer Decoding (PG-TD), which integrates a planning algorithm with Transformers to improve code generation by leveraging test case results. PG-TD surpasses traditional sampling and beam search, boosting pass rates on competitive programming benchmarks. However, it is computationally intensive and depends on existing test cases, limiting broader applications. Future work seeks to enhance efficiency through parallel tree search and automated test case generation for real-world software development."}, {"title": "2.1.4. Front-end App Development from UI Prototypes", "content": "Xiao et al. (2024) introduces Prototype2Code, an end-to-end framework for automating front-end code generation from UI design prototypes. Traditional UI-to-code methods often produce fragmented, unstructured code, impacting maintainability. Prototype2Code addresses this by integrating design linting, graph-based UI structuring, and LLMs to enhance code generation. It first detects and corrects UI inconsistencies through linting, constructs a hierarchical layout tree for structured components, and refines UI elements using a Graph Neural Network (GNN)-based classifier before generating modular HTML and CSS with LLMs. Benchmarks against CodeFun and GPT-4V-based Screenshot-to-Code show superior visual fidelity, readability, and maintainability, validated by SSIM, PSNR, and MSE metrics. A user study confirms reduced manual modifications and improved usability. Future work aims to support dynamic components, interactivity, and cross-platform adaptability. Manuardi (2024) explores AI-driven front-end automation by converting UI mockups into structured code. Unlike text-based coding tools like GitHub Copilot, UI-driven development requires visual processing. The study proposes a multi-modal AI system that integrates computer vision and LLMs, using edge detection, contour analysis, and OCR to generate an intermediate representation, which a multi-modal LLM translates into front-end code for Angular and Bootstrap. Implemented at Blue Reply as a web-based tool, the system improves development efficiency by reducing manual coding while ensuring maintainability, advancing automated and intuitive front-end development."}, {"title": "2.2. Limitation and Knowledge Gaps", "content": "Despite advancements in LLM-powered code generation, challenges remain, particularly in scientific and GIS-based web applications. These limitations hinder seamless automation of front-end and back-end development, necessitating further research. The key challenges are outlined below as C1-C4."}, {"title": "C1. Limited Graphical and Visual Prompting:", "content": "LLMs rely on text-based prompting, limiting their ability to interpret GUI designs and wireframe sketches. While image-to-code models show promise, they struggle with complex layouts, interactive elements, and contextual relationships. The lack of robust graph-based UI understanding restricts structured, modular front-end code generation."}, {"title": "C2. Absence of Software Engineering Best Practices:", "content": "AI-generated code often lacks integration with industry design patterns (e.g., MVC, MVVM) (Xiao et al., 2024), leading to poor maintainability (Ghosh and Team, 2024; Nguyen-Duc et al., 2023). LLM-driven workflows rarely incorporate CI/CD pipelines, software testing, or version control, limiting their practical usability in large-scale development (Corona-Fraga et al., 2025; Mendoza Juan, 2024)."}, {"title": "C3. Lack of Domain Knowledge in GIS and Scientific Applications:", "content": "General-purpose LLMs struggle with GIS and scientific computing due to insufficient training on geospatial standards (GeoJSON, WMS, WFS), web mapping engines, and 3D data visualization (Zhang et al., 2024; Mansourian and Oucheikh, 2024; Hou et al., 2024a). While some fine-tuned models improve geospatial analysis (Hadid et al., 2024; Hou et al., 2024b; Akinboyewa et al., 2024), web-based GIS dashboard generation remains largely unexplored."}, {"title": "C4. Package Management Issues:", "content": "Al-generated code frequently suffers from dependency conflicts, outdated libraries, and compatibility issues, particularly in GIS and scientific computing (Hou et al., 2024a; Mahmoudi et al., 2023). Web-based GIS applications require compatibility across Python, JavaScript, and C++ libraries (e.g., Django, Flask, OpenLayers, Leaflet), which LLMs often fail to handle effectively.\nTo bridge these gaps, a robust framework is needed to automate GIS web application development. This framework should allow users to input GUI sketches from non-technical tools (e.g., PowerPoint) for seamless, code-free development."}, {"title": "3. Methodology", "content": "The following subsections outline our research motivation, the challenges we address, and our conceptual knowledge-driven approach. We then define the software design requirements, focusing on target users and key features. With these in place, we present the overall framework, detailing its major steps. This includes visual contextual prompting techniques, a software engineering and GIS knowledge base leveraging the RAG paradigm and vector databases, and Knowledge-Augmented Generation (KAG) for iterative code generation.\nRather than fine-tuning or training specific models, our approach emphasizes knowledge augmentation for LLM-driven coding. We propose a system-based, adaptable method that integrates software engineering principles into user-selected LLMs. Additionally, we introduce a generalizable approach that allows end-users to use custom UI wireframes as inputs, enabling LLMs to generate front-end web applications."}, {"title": "3.1. Motivation and Contributions", "content": "Our research develops a knowledge-driven approach to instruct LLMs, particularly GPTs, for automated code generation aligned with software engineering best practices. This supports the creation of robust, maintainable web-based GIS applications for scientific data sharing and visualization. By integrating industrial-grade practices and modern software stacks, our method lowers technical barriers for domain scientists with coding experience but limited software engineering expertise, enabling them to generate front-end CyberGIS applications efficiently.\nTo address the challenges in geospatial code generation identified in recent studies (Hou et al., 2024a,b), particularly the limitations of general-purpose GPT models in handling built-in GIS and visualization libraries and managing complex package dependencies, we propose a novel knowledge-driven approach. Existing models frequently exhibit hallucinations, runtime errors, and an inability to generate complex CyberGIS applications with advanced data querying and visualization capabilities (Hou et al., 2024a). Our approach seeks to overcome these limitations by integrating structured domain knowledge with intelligent prompt engineering and package management solutions, ensuring that LLM-generated code is accurate, executable, and aligned with industry standards. The key novelties of our contributions are as follows:\nKnowledge-Augmented Code Generation: Instead of fine-tuning LLMs, we employ Knowledge-Augmented Generation (KAG) to construct code-base and knowledge representations in a knowledge graph, integrating software engineering principles and real-world examples. This systematic approach improves the accuracy, maintainability, and scalability of LLM-generated GIS code.\nVisual Contextual Prompting: Our Python-based system translates SVG-based wireframes into structured prompts, allowing non-programmers to design UI layouts in PowerPoint or Adobe Illustrator. The system extracts GUI components, spatial relationships, and functional annotations, querying a visual contextual knowledge base for implementation details compatible with React, Angular, Bootstrap, Tailwind CSS, Leaflet, and D3.js. This structured prompting method improves code accuracy, maintainability, and best-practice adherence, making LLM-assisted GIS development more accessible and reliable.\nSoftware Engineering Practices Integration: We introduce a chain-of-steps guidance framework that ensures LLMs generate robust web-based GIS applications aligned with industry standards. Unlike conventional approaches, our framework enforces software design patterns such as MVVM in React-based SPAs, improving modularity and maintainability for GIS data visualization in web applications.\nMulti-tool Package Management: LLM-generated code often suffers from package incompatibility and outdated dependencies. Instead of generating package management files directly, our method employs a structured knowledge-driven approach to guide industry-standard tools like NPM for JavaScript and TypeScript. This ensures efficient dependency resolution, reducing deployment failures and improving workflow reliability in GIS application development."}, {"title": "3.2. Design Requirements", "content": "The target users of our proposed framework are domain scientists with strong scientific computing and programming skills in geospatial analysis, simulations, and data modeling. However, they have limited or no exposure to software engineering principles and best practices for developing modular, maintainable front-end web applications using widely adopted software stacks and technologies in the IT industry.\nThe detailed technical design requirements of our proposed framework are as follows:\nR1. Support for UI Sketches and Wireframes as Inputs: The framework should accept UI sketches and wireframes as input, allowing users to visually define the structure and layout of their web applications without requiring extensive front-end development or cyberGIS expertise.\nR2. Minimal UI/UX Expertise Required for Wireframing: Users should be able to create wireframes with minimal UI/UX design experience, ensuring accessibility for domain scientists without specialized front-end design skills. The framework should accept wireframes casually sketched using commonly available software, such as vector graphics created in Microsoft PowerPoint or Word, rather than requiring professional UI/UX prototyping tools like Adobe XD, Figma, or the discontinued Adobe Muse.\nR3. Modular and Extensible Knowledge Base: The framework should provide a structured and expandable knowledge base that allows developers and open-source communities to incrementally refine and customize sample code. By integrating domain-specific and software engineering knowledge, the framework can enhance its ability to generate front-end code with advanced features while leveraging the latest code libraries-all while adhering to best practices.\nR4. Integration of Software Engineering Practices: The system should incorporate established software design and architectural patterns to enhance code maintainability, scalability, and compliance with industry standards. For instance, modern web applications are rarely built using plain HTML, JavaScript, and a basic Python web server. As applications grow in complexity-integrating more features, data, and user workflows it becomes essential to adopt software engineering best practices, such as Separation of Concerns (SoC) and the Singleton design pattern. These principles help modularize components, optimize performance, and promote code reusability, ultimately leading to the development of robust web frameworks that abstract these practices into MVC (Model-View-Controller) and MVVM (Model-View-ViewModel) architectures. We aim to develop a systematic approach to guide existing LLMs specialized in code generation for specific domain areas, ensuring"}, {"title": "3.3. Framework Design", "content": "The overall framework design is illustrated in Figure 2, where we define 12 tasks (T1-T12) categorized into three major steps that form the core of the code generation workflow. These steps include: (1) Visual Contextual Prompting, (2) Knowledge Base and Code Base, and (3) Knowledge-Augmented Code Generation. The framework takes as input one or more user-defined wireframes that specify the layout and features of the GUI across different pages. As output, it generates the complete code base for a React project.\n3.3.1. Visual Contextual Prompting\nWe introduce a novel visual contextual prompting technique, implemented using Python scripts, to translate GUI wireframes into structured prompts for guiding LLMs in generating high-quality JavaScript and TypeScript code. Unlike conventional text-based prompting, our approach enables non-technical users, such as domain scientists, to design web applications visually using PowerPoint and Adobe Illustrator.\nExisting graphical prompting methods often rely on computer vision (CV)-based techniques to interpret bitmap images (e.g., PNG, JPEG). In contrast, our method processes SVG-based wireframes, which offer greater editability and flexibility during prototyping. This structured approach allows users to define UI components without programming expertise.\nThis step consists of two tasks, T1 and T2, aligned with the design requirements R1 and R2 in Subsection 3.2."}, {"title": "T1. Vectorization & Content Interpretation", "content": "A Python program processes wireframe files exported from PowerPoint or Adobe Illustrator in EPS/SVG formats, extracting spatial and contextual information to construct HTML layouts and components. Each GUI element\u2014such as dropdown menus, charts, and web maps-is represented as a vector graphical entity with embedded annotations specifying its function (e.g., data visualization, mapping interface, UI control). These annotations also capture interactions and dependencies, guiding LLMs in event binding for dynamic UI behaviors."}, {"title": "T2. Visual Contextual Info Calculation", "content": "Another Python script calculates visual contextual information for each SVG element, mapping it to an HTML component. This includes position, size, and style, which are then combined with wireframe annotations to generate engineered prompts. These prompts define not only individual components but also layout structures, interdependencies, and event handling logic, ensuring that LLM-generated code aligns with industry standards and preserves the user's design intent.\nBy integrating visual design with structured knowledge-based prompting, our technique lowers the barrier for non-programmers, enabling them to develop web-based GIS and data visualization applications without direct coding expertise."}, {"title": "3.3.2. Knowledge Base and Code Base", "content": "The input information, including graphical components, visual context, and annotations from user, defined wireframes-captures GUI design and software requirements in plain, non-technical language. This enables users without coding expertise to define application requirements effortlessly. However, a combined knowledge base and code base is essential to interpret these context-aware visual prompts, transforming them into structured software development strategies. These strategies generate enriched prompts with sample code, guiding LLMs for code generation within a RAG framework.\nOur knowledge base is built using knowledge graphs that encapsulate software development experiences, system requirements, and architectural designs from previous projects on digital twins, cyber infrastructure, and web-based visual analytics dashboards, as shown in Table 1. These knowledge graphs document and classify software stacks, componentization methods, and system designs based on domain-specific use cases and data types, ensuring structured and informed LLM-assisted code generation.\nAn example of the knowledge graph structure is depicted in Figure 3. The sample code stored within these graphs is either excerpted and refined from previous projects or augmented using the ChatGPT API under expert review and supervision.\nThe process of knowledge-driven prompting follows a procedural approach, structured through tasks T3 to T8, ensuring a systematic and context-driven software development workflow. These tasks are detailed in the following list, with their rationale depicted in Figure 3."}, {"title": "T3. Framework & Library Selection", "content": "This task defines criteria for selecting web frameworks and libraries based"}, {"title": "T4. HTML/TypeScript Component Tree Generation", "content": "Using extracted GUI components and annotations, this task constructs a structured HTML/TypeScript component tree, preserving semantic correctness, hierarchical relationships, and CSS styles. The wireframe context guides nested structures and component interactions to ensure logical front-end design."}, {"title": "T5. Front-End Library Selection", "content": "Based on T3's criteria, this task selects appropriate front-end software stacks, including CSS frameworks, UI libraries, mapping tools, and data visualization frameworks. It determines whether to use standard HTML elements or third-party solutions (e.g., Material-UI, Tailwind CSS, D3.js, Leaflet) by performing a vector index search on a Neo4j-backed knowledge graph (Xu et al., 2024b), ensuring optimal usability, performance, and maintainability."}, {"title": "T6. OS Commands for Package Management", "content": "After selecting libraries in T5, a Python script retrieves the corresponding OS commands for installing, updating, and managing dependencies using appropriate package management tools. JavaScript/TypeScript dependencies use NPM/NVM, Python libraries use Pip/Conda, and system-level packages use APT (Debian) or Yum (RHEL). The script consolidates commands into .sh or .bash scripts, enabling one-click execution for package management across Windows and Linux DevOps environments, handling installation, version control, and conflict resolution."}, {"title": "T7. Software Design & Architecture Patterns", "content": "This task ensures adherence to scalable and modular software design principles by integrating Separation of Concerns (SoC), MVC, and MVVM patterns. It leverages industry-standard frameworks (React, Angular) and structured prompt templates to guide LLMs in generating componentized code with proper event binding and state management."}, {"title": "T8. Software Development Prompt Generation", "content": "Expanding on T6, this task refines structured prompts for LLM-driven code generation, incorporating component-based development, lazy loading, and dynamic rendering."}, {"title": "3.3.3. Knowledge Augmented Code Generation", "content": "The structured prompts generated from T8 are then fed into the LLM agent to enable knowledge-augmented code generation. Given the token limit constraints of LLMs, we adopt a procedure-based, iterative approach that combines rule-based Python scripting with the customized generation capabilities of LLMs. This method ensures efficient front-end code generation using the React framework, which follows the Model-View-ViewModel (MVVM) architecture, along with established software engineering conventions and React's standard file structure. Our KAG approach entails the following tasks from T9 to T11, which are illustrated in Figure 4."}, {"title": "T9. Install & Update Packages using Operating System (OS) Scripts", "content": "This task automates the installation and updating of required dependencies using OS-level scripts. It ensures that all necessary packages, including Node.js, npm, and front-end libraries (e.g., React, Material-UI, Leaflet), are properly installed and version-controlled. The scripts also handle package updates to maintain compatibility with evolving software frameworks and dependencies."}, {"title": "T10. Iteration-based Code Generation using LLMs", "content": "Given the token limitations of LLMs, this task adopts a procedure-based, iterative approach for code generation. Rule-based Python scripts and structured prompts guide the LLMs to generate React components in a stepwise manner, ensuring compliance with best practices in componentization, event handling, and state management. The iterative process allows refinement and optimization of the generated code, minimizing redundancy and improving maintainability."}, {"title": "T11. Separation of Concerns (SoC) using React Convention", "content": "This task enforces Separation of Concerns (SoC) by structuring the generated code according to React's MVVM architecture. The React components, logic, styles, and API handlers are modularized into separate files, ensuring that UI elements, business logic, and data handling remain distinct. This improves scalability, maintainability, and code readability while aligning with industry standards."}, {"title": "T12. Script Connection & Organization in React File Structure", "content": "This task organizes and connects the generated scripts following the **React file structure convention**. The components are structured within a modular directory system (e.g., 'components/\u201c, \u2018hooks/\u2018, \u2018services/\u2018, \u2018contexts/'). The script integration ensures that React Router, Redux (if applicable), and event-driven logic** are properly linked, allowing seamless front-end development with maintainable and reusable components."}, {"title": "4. Result Demonstration", "content": "Using our prototyping framework, we automated the generation of front-end code for two web-based GIS dashboards addressing distinct use cases involving environmental and energy infrastructure data. To showcase the advantages of the proposed framework, which leverages knowledge-augmented code generation guided by software engineering best practices and industry standards, we developed both dashboards as single-page applications using the React framework, integrating them within the same React project."}, {"title": "4.1. Case Study I - Meteorological Data Dashboard", "content": "Access to continuous and high-quality meteorological data is essential for understanding regional climatology and atmospheric processes. Such data plays a crucial role in research efforts focused on assessing local climate patterns, modeling atmospheric dispersion, evaluating emissions, and ensuring environmental and operational safety. Research institutions like Oak Ridge National Laboratory (ORNL) require reliable meteorological measurements to support site operation, emergency preparedness, and environmental monitoring. However, meteorological data collection is often subject to various challenges, including sensor degradation, power fluctuations, lightning strikes, and instrument failures, all of which can introduce uncertainties and affect data reliability (Steckler et al., 2025).\nTo address these challenges, this study aims to leverage the prototyping framework's ability to generate the code base for a robust visual dashboard to enhances the quality and usability of meteorological data collected at ORNL by placing domain experts in the loop to supervise the data collocation and quality control processes. Specifically, a comprehensive quality assessment was conducted using a statistical framework to process of five years of meteorological data, ensuring data integrity and continuity. The visual dashboard is developed to assist the visual exploration and supervision of the data outputs from the statistical framework The primary objective is to produce a high-quality,"}, {"title": "4.2. Case Study II - Wind Turbine and Landuse Data", "content": "The expansion of renewable energy infrastructure, such as wind farms, has raised concerns about its potential ecological impacts on bird habitats. Previous studies have assessed bird habitats using bird-watching surveys and remote sensing data on natural vegetation cover, offering valuable insights into avian ecology. Building on these methods, this case study investigates the hypothesis that noise and land cover changes resulting from wind turbine operations may displace grassland- and forest-dwelling birds. To explore this, we conducted a preliminary study using data from the United States Geological Survey (USGS)'s Wind Turbine Database (USWTDB) and correlated it with a 20-year time series of land cover changes from the Multi-Resolution Land Characteristics (MRLC)'s National Land Cover Database (NLCD).\nThis case study focuses on wind farm sites across multiple states in the United States. The USWTDB provides detailed GIS data on wind turbine locations, construction years, and operational specifications, which are linked to land cover changes documented by the NLCD. The NLCD dataset includes high-resolution raster-based land cover data, capturing variations in vegetation and natural land cover over two decades. By comparing land cover data before and after the establishment of wind farms, the study identifies patterns of vegetation loss and fragmentation caused by infrastructure development, including roads, facilities, and pavements.\nTo validate these findings, this case study aims to develop a web-based GIS dashboard that integrates the time series of land cover changes from the NLCD dataset with wind turbine locations retrieved from the USWTDB. The dashboard visually overlays land cover rasters with wind turbine locations, enabling users to assess potential land cover changes caused by wind farm operations. This tool highlights areas where wildlife conservation strategies may be needed. By providing insights into the ecological impacts of wind farms, this approach establishes a practical framework for mitigating habitat loss and protecting avian species affected by renewable energy development."}, {"title": "4.3. Context-aware Visual Prompting", "content": "We present the UIs of the web-based application, which are generated from user-defined wireframes for the homepage (as depicted in Figure 5) and the visual dashboard for Use Case I (as illustrated in Figure 6). These UIs are integrated as distinct routes within a single React project, enhancing scalability and extensibility to accommodate additional GIS dashboards under the same project while maintaining a consistent UI style through code reuse. This"}, {"title": "4.4. Al-generated Dashboard Demonstration", "content": "For the meteorological data dashboard, the AI-generated interface provides an interactive platform for exploring time-series meteorological data collected from the ORR. The dashboard enables real-time visualization of meteorological variables captured by tower sensors, including temperature, wind speed, humidity, and atmospheric pressure (as shown in Figure 7). The AI-driven dashboard generation process ensures that data integrity is preserved by integrating statistical quality assessments to identify missing or inconsistent measurements.\nUsers can interact with the dashboard to:\n1. Query sensor measurements at different sites, with their locations visualized on the map.\n2. Visualize time-series meteorological trends for a large number of parameters over different time periods.\n3. Display statistical summaries of the selected time-series data.\nThe AI-generated dashboard effectively places domain experts in the loop, allowing them to supervise data quality and validate automated statistical assessments, thereby improving the usability of long-term meteorological data sets for atmospheric modeling and environmental monitoring.\nFor Use Case II, the AI-generated dashboard integrates GIS-based land cover data with wind turbine locations, providing a comprehensive platform for analyzing the ecological impacts of wind energy infrastructure (as depicted in Figure 8). By utilizing AI-assisted dashboard generation, the system automatically organizes spatial raster data sets and overlays them with wind turbine distributions to reveal patterns of land cover transformation. The dashboard enables users to perform the following functionalities:\n1. Examine land cover changes before and after wind farm construction using a 20-year historical data set. Compare the extent of vegetation loss and landscape fragmentation near wind turbine sites.\n2. Assess potential ecological risks associated with wind farm expansion by correlating turbine operations with habitat shifts.\nThis AI-enhanced approach to dashboard generation significantly reduces development time while improving the consistency and maintainability of GIS visualization tools. By combining AI-assisted UI design with data-driven analysis, this study demonstrates the potential of AI in advancing interactive environmental monitoring systems."}, {"title": "4.5. Limitation and Future Work", "content": "As our study primarily focuses on prototyping a knowledge-driven framework to demonstrate the feasibility of guiding LLMs for adaptive", "below": "nLack of Comparative Analysis across Different LLMs The framework's performance and effectiveness were evaluated using a single large language model (LLM) to demonstrate feasibility. Future work should include comparative studies across various LLMs to assess their suitability for different domains and coding scenarios.\nRequires Human Expert Review of AI-Generated Code While the framework automates front-end code generation, the resulting code still requires human experts to review for correctness, optimization, and adherence to specific project requirements. Future advancements could integrate automatic validation tools or explainable AI mechanisms to reduce dependency on manual reviews.\nCustomized Functions Require Manual Programming Efforts Although the framework automates standard functionalities, developing highly customized features still requires manual programming, which limits full automation. Future iterations of the framework could incorporate a mechanism to better support user-defined customizations through enhanced prompt engineering or plug-and"}]}