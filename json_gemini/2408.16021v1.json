{"title": "XG-NID: Dual-Modality Network Intrusion Detection using a Heterogeneous Graph Neural Network and Large Language Model", "authors": ["Yasir Ali Farrukh", "Syed Wali", "Irfan Khan", "Nathaniel D. Bastian"], "abstract": "In the rapidly evolving field of cybersecurity, the integration of flow-level and packet-level information for real-time intrusion detection remains a largely untapped area of research. This paper introduces \"XG-NID,\" a novel framework that, to the best of our knowledge, is the first to fuse flow-level and packet-level data within a heterogeneous graph structure, offering a comprehensive analysis of network traffic. Leveraging a heterogeneous graph neural network (GNN) with graph-level classification, XG-NID uniquely enables real-time inference while effectively capturing the intricate relationships between flow and packet payload data. Unlike traditional GNN-based methodologies that predominantly analyze historical data, XG-NID is designed to accommodate the heterogeneous nature of network traffic, providing a robust and real-time defense mechanism. Our framework extends beyond mere classification; it integrates Large Language Models (LLMs) to generate detailed, human-readable explanations and suggest potential remedial actions, ensuring that the insights produced are both actionable and comprehensible. Additionally, we introduce a new set of flow features based on temporal information, further enhancing the contextual and explainable inferences provided by our model. To facilitate practical application and accessibility, we developed \"GNN4ID,\" an open-source tool that enables the extraction and transformation of raw network traffic into the proposed heterogeneous graph structure, seamlessly integrating flow and packet-level data. Our comprehensive quantitative comparative analysis demonstrates that XG-NID achieves an F1 score of 97% in multi-class classification, outperforming existing baseline and state-of-the-art methods. This sets a new standard in Network Intrusion Detection Systems (NIDS) by combining innovative data fusion with enhanced interpretability and real-time capabilities.", "sections": [{"title": "1. Introduction", "content": "In the dynamic and increasingly complex landscape of cybersecurity, Network Intrusion Detection Systems (NIDS) play a crucial role in protecting systems and networks from a wide range of cyber threats (Mallick and Nath, 2024). The growing significance of cybersecurity is underscored by the rise in cyber-attacks driven by rapid digital expansion (Mwangi, 2024). In an era marked by unprecedented interconnectedness and technological advancement, the cybersecurity landscape faces an escalating challenge: the relentless wave of cyber threats targeting critical infrastructures, sensitive information, and the core functions of society (Farrukh et al., 2024a). As the digital landscape expands, so does the complexity and sophistication of cyber-attacks, necessitating a paradigm shift in defensive strategies (Cunningham, 2020). According to Gartner, by 2025, 30% of businesses in critical infrastructure will face a security breach, potentially leading to the shutdown of mission-critical cyber-physical systems (Gartner, Inc., 2021), highlighting the critical need for improved defensive measures.\nTraditional machine learning-based NIDS methodologies can be broadly categorized into two types: those that analyze flow information and those that scrutinize packet-level information (Farrukh et al., 2023). Flow-based NIDS analyze aggregated data about network traffic, such as the volume of data transferred between endpoints, the duration of connections, and the frequency of interactions. This approach is efficient for identifying patterns and anomalies at a higher level, such as Distributed Denial of Service (DDoS) attacks, which are characterized by unusually high volumes of traffic (Specht and Lee, 2004). However, flow-based systems can miss more nuanced attacks that are embedded within the payload of individual packets (Umer et al., 2017).\nConversely, packet-based NIDS focus on the contents of individual packets, examining payloads for signatures of known exploits, malware, and other malicious content. This method excels at detecting attacks that rely on specific payload characteristics, such as SQL injection or buffer overflow attacks (Farrukh et al., 2022). Despite their detailed inspection capabilities, packet-based systems can be overwhelmed by high volumes of traffic and may fail to identify broader traffic patterns indicative of certain attacks.\nThe inherent limitations of relying solely on either flow or packet-level information highlight the need for an integrated approach. Certain sophisticated attacks can exploit these limitations to bypass detection. For instance, an SQL injection attack, which embeds malicious SQL commands within a packet's payload, might evade a flow-based NIDS because it does not generate significant anomalies in traffic patterns (Umer et al., 2017). Conversely, flow-based attacks can slip through packet-level NIDS because they do not involve malicious payloads but rather manipulate the volume and frequency of packets (Tan et al., 2014). This dichotomy underscores a critical gap in current machine learning-based NIDS technologies. By failing to leverage the complementary strengths of both flow and packet-level information, existing systems leave networks vulnerable to a range of attack vectors. Addressing this gap requires a novel approach that combines these two types of information into a unified framework, enabling more comprehensive threat detection.\nIn response to these challenges, our paper proposes a novel method of multi-modal data fusion that integrates both flow and packet-level information, represented in a unique heterogeneous graph format. This approach leverages Graph Neural Networks (GNNs) to process and analyze the heterogeneous data, capturing the intricate relationships and patterns within network traffic. By representing network traffic as graphs, where nodes and edges encapsulate both flow and packet attributes, we can harness the strengths of both modalities of data. This fusion allows our system to detect a broader spectrum of cyber-attacks, improving overall detection accuracy. The graph-based representation also facilitates the learning of complex network patterns, which are essential for identifying sophisticated threats.\nFurthermore, we emphasize the importance of contextual explainability in cybersecurity. Traditional NIDS outputs are often cryptic, making it difficult for cyber analysts to understand and respond to threats effectively (Abou El Houda et al., 2022). By integrating explainability using contexual information from large language models (LLMs), our approach provides clear, actionable insights into detected threats, detailing the nature of the attack, affected components, and recommended mitigation strategies.\nIn short, this paper emphasizes the importance of data fusion in network security and proposes a novel framework that integrates flow and packet-level information using GNNs, along with contextual and explainable inferences. By bridging the gap between these two data modalities and leveraging their combined information, our approach offers a robust and comprehensive solution to network intrusion detection. This framework not only enhances the detection of threats but also provides actionable insights that can lead to the development of intelligent systems capable of making autonomous decisions on appropriate responses, thereby paving the way for improved cybersecurity measures. The main contributions of this work are as follows:\n1) We present a novel framework \"XG-NID\" that fuses flow-level and packet-level data modalities in network traffic, providing contextual, explainable, and actionable insights to enhance model interpretability and support informed decision-making.\n2) We introduce an innovative method for fusing dual modalities of network traffic-flow and packet-level information using heterogeneous graph structures for comprehensive analysis.\n3) We develop a heterogeneous graph neural network (HGNN) based on graph-level classification for NIDS, enabling real-time inference by utilizing dual-modality data and incorporating the heterogeneous nature of network traffic.\n4) We develop \"GNN4ID,\" (Farrukh et al., 2024b) an open-source tool for extracting and transforming raw network traffic into our proposed heterogeneous graph structure, integrating flow and packet-level data.\n5) We propose a new set of flow features based on temporal information to aid in producing better contextual and explainable inferences.\n6) We present a methodology for providing detailed and human-readable explanations of the proposed HGNN model results by combining contextual information from LLMs.\n7) We provide a quantitative comparative analysis of our proposed methodology with other baseline and comparable approaches to highlight its effectiveness.\nThe remainder of this paper is structured as follows: Section 2 reviews related works, covering the application of GNNs in NIDS and the role of explainable artificial intelligence (XAI) in NIDS. Section 3 details the adopted"}, {"title": "2. Related Works", "content": "In this section, we review the existing literature in two parts: the application of GNNs in NIDS and the role of XAI in the NIDS domain. Notably, there is a significant gap in the research concerning the integration of packet-level and flow-level information for both inference and explainability. Our work aims to address this gap by leveraging data fusion through heterogeneous graph structures, extracting contextual information from both packet and flow levels, and performing graph-level classification to enable real-time inference with explainability. This comprehensive approach not only enhances the detection capabilities but also provides actionable insights, advancing the field of network security."}, {"title": "2.1. Graph Neural Network", "content": "The majority of the existing literature on GNN-based NIDS focuses on node-level and edge-level classification. These studies are primarily aimed at analyzing historical network traffic to understand past attacks or to visualize network activity in a more user-friendly manner, often lacking real-time inference capabilities (Messai and Seba, 2023). Further, most of these works employ homogeneous graph representations of network traffic, which do not fully exploit the heterogeneous nature of network data. This leaves a gap in leveraging the heterogeneity of network traffic and providing real-time inference. We discuss several notable works herein, highlighting their contributions and limitations.\nLo et al. (2022) presented \"E-GraphSAGE\" to classify network flows using edge-level classification. The model captures edge and topological information in IoT networks for classification. The authors enhanced the GraphSAGE (Hamilton et al., 2017) algorithm to directly exploit the structural information of the network flow and encode it in a graph. Despite these advancements, the scalability and real-time inference capabilities remain questionable due to the computational complexity of analyzing complete flow information. Chang and Branco (2024) further enhanced E-GraphSAGE by integrating residual learning and an attention mechanism to increase efficiency. They utilized E-GraphSAGE with residual learning to target minority class imbalance and introduced an edge-based residual graph attention network (E-ResGAT) to improve efficiency. However, the reliance on fixed neighborhood edge sampling and attention mechanisms might still face challenges in highly dynamic network environments.\nZhou et al. (2020) proposed a supervised approach based on a Graph Convolutional Network (GCN) and network traces. They considered only the topological structure of the graph, omitting edge features and initializing node features as a vector of ones. This method can efficiently handle large graphs but may miss critical edge information that could enhance detection accuracy. Similarly, Zhang et al. (2022) suggested using a GCN for botnet detection. They used 12 GCN layers to capture long-term dependencies in large botnet architectures. However, very deep GCN models are prone to over-smoothing, which can diminish the model's ability to distinguish between classes.\nAltaf et al. (2023) presented a comprehensive GNN-based NIDS model capable of capturing relations in the network graph and combining both node and edge features to identify abnormal traffic behavior. This approach uses IP addresses and port numbers to represent Internet of Things (IoT) sessions as nodes and network flows as edges, which helps mitigate multiple attack vectors at the application and network layers. However, attacks dependent on payload content can still evade detection. A more general approach to detecting intrusions with a heterogeneous graph is proposed in (Pujol-Perich et al., 2022). The graph is built based on network flows, creating separate nodes for the source host, destination host, and the flow itself. This structure, combined with a nonstandard message-passing neural network (MPNN), improves the model's ability to learn embeddings from flows. Despite its promising accuracy, the model was tested on a heavily pre-processed dataset, raising questions about its performance on more balanced and varied data.\nCao et al. (2021) proposed representing packet traffic using a spatio-temporal graph to model features that vary with time. Their method aims to detect DDoS attacks in software-defined networking (SDN) environments using a Spatio-Temporal Graph Convolutional Network (ST-GCN) (Yu et al., 2017). While this approach effectively captures temporal dynamics, its applicability to a wider range of attacks remains to be seen. Premkumar et al. (2023) is the only paper we found that effectively integrates both flow and packet information utilizing Graph Representation Learning (GRL). Their approach first generates packet-level embeddings from graph representations, then combines these with flow-level"}, {"title": "2.2. Explainable Artificial Intelligence", "content": "Recent research in XAI has been actively applied to cybersecurity, particularly in specialized use cases like network intrusion detection and malware identification. Han et al. (2021) developed the DeepAID framework to interpret unsupervised deep learning-based anomaly detection systems for cybersecurity. This approach helps security analysts understand why a certain sample is considered anomalous by comparing the anomaly to a normal reference data point.\nXAI holds promise in enhancing the adoption of machine learning (ML) models within existing cybersecurity frameworks. However, several challenges still need to be addressed (Nadeem et al., 2023), particularly in making explanations more understandable for users and reducing the opacity of ML models within NIDS frameworks. To address these issues, Alwahedi et al. (2024) explored the integration of LLMs with XAI techniques. Consequently, recent research papers have focused on adding an LLM layer to the existing frameworks.\nZiems et al. (2023) introduced LLM-DTE (Large Language Model Decision Tree Explanations), a method that utilizes LLM to generate natural language explanations for decision tree-based NIDS. Khediri et al. (2024) proposed an approach that integrates SHAP (SHapley Additive exPlanations) values with LLMs to generate human-understandable explanations for detected anomalies. These SHAP values provide a detailed explanation of individual predictions by measuring the impact of each feature on the final outcome (Moustafa et al., 2023). Their methodology, applied to the CICIDS2017 dataset, demonstrated how this combination of SHAP values and LLM can offer coherent responses regarding influential predictors of model outcomes. Similarly, Ali and Kostakos (2023) developed HuntGPT, a specialized intrusion detection dashboard that incorporates XAI frameworks like SHAP with a Random Forest classifier trained on the KDD99 dataset to enhance model interpretability.\nDespite these advancements, significant issues remain regarding the scalability, efficiency, and human-centric aspects of XAI-driven cybersecurity solutions. Current explanations based on SHAP values often lack the necessary contextual and temporal information, which is crucial for accurately identifying and explaining time-based attacks. Time-based attacks, such as DDoS attacks, unfold over specific periods, where the timing and sequence of network events are quite important. A more effective explanation would incorporate temporal information, with features highlighting a rapid influx of requests to the targeted server from specific IPs within a brief timeframe, providing a clearer understanding of why the attack was detected.\nExplaining payload-specific attacks based on network flow remains a challenge. The actual signature of payload-specific attacks, such as SQL injection, lies within the payload itself. These attacks can demonstrate benign behavior in network flow, with their malicious intent residing in the packet content. Thus, explanations must consider the payload to clearly convey why a prediction was made. Current methods that explain such attacks solely based on flow data fail to capture the critical details within the payload, leading to incomplete or inaccurate explanations. These shortcomings are addressed in this paper by enhancing the feature extraction process to include both contextual and temporal information for time-based attacks, and by ensuring payload-specific attacks are explained based on their content."}, {"title": "3. Methodology", "content": "In this section, we present the methodology employed to develop and evaluate our proposed framework for network intrusion detection. The framework leverages the fusion of flow and packet-level information through a HGNN to provide real-time, explainable, and actionable insights. We begin by providing details of the proposed framework, including the feature extraction and development, graph construction, and the integration of explainability through contextual inference. This is followed by details of the dataset used for training and testing. The methodology outlines the key components that contribute to the effectiveness of our approach, ensuring comprehensive analysis and robust intrusion detection capabilities."}, {"title": "3.1. Proposed Framework", "content": "The proposed framework \"XG-NID\" presents a novel approach to network intrusion detection by integrating flow and packet-level information into a heterogeneous graph structure, enabling a more comprehensive analysis of network behavior. This fusion of multiple data modalities enhances the model's ability to capture complex interactions within the network, leading to more accurate and effective intrusion detection. Moreover, the framework not only provides performant detection capabilities but also delivers detailed, human-readable explanations and potential remedial actions, ensuring that the insights generated are both actionable and understandable. The framework is composed of six key components, as illustrated in Fig. 1.\nThe system initiates by capturing raw network traffic data (network packets), which are then processed by the first component, the Flow and Feature Generator. This component is responsible for generating network flows and extracting relevant features from both the flow and packet levels. These generated flows are subsequently passed to the Explainable Feature Extractor, which derives new features based on the temporal information from previous flows.\nOnce the features have been generated and enhanced, the data is transferred to the Graph Generator. This component transforms the flow and packet-level features into a heterogeneous graph structure, which serves as the foundation for the subsequent inference process. The transformed graph is then analyzed by the GNN Model, the fourth component, which performs the core task of intrusion detection by classifying the network traffic as either benign or respective attack class.\nThe output of the GNN Model is forwarded to both the Integrated Gradient Explainer and the Generative Explainer, components five and six, respectively. The Integrated Gradient Explainer identifies the most significant attributes of the graph structure that contributed to the model's prediction, providing a localized explanation of the model's output.\nLeveraging these local explanations, the Generative Explainer generates specific prompts and formulates detailed, human-readable explanations of the results. Also, it offers potential remedial actions, ensuring that the system's outputs are not only accurate but also actionable and understandable.\nThe following sub-sections provide the technical details of each component, offering a comprehensive understanding of how our framework is utilized for effective cyber threat detection and explanation."}, {"title": "3.1.1. Flow and Feature Generator", "content": "The Flow and Feature Generator is the first component of our proposed framework, responsible for processing raw network traffic and aggregating it into flows. The primary goal of this component is to extract features from raw network traffic for real-time inference. For our approach, we set a maximum limit of 20 packets per flow, following the work of the CIC-IoT2023 dataset (Neto et al., 2023). The decision to limit the flow to 20 packets is driven by our objective to enable real-time inference; allowing flows to accumulate based on default parameters could result in flow\ndurations of up to 30 minutes (Aouini and Pekar, 2022). Additionally, we set an idle timeout of 120 seconds, meaning that if a flow remains inactive for this duration, it is concluded.\nThe Flow and Feature Generator also segregates packet-level information with respect to its corresponding flow, ensuring that each flow includes payload information derived from its associated packets. This segregation is crucial for generating graph structures, as our objective is to unify flow and packet-level information into a cohesive representation.\nBuilt upon NFStream (Aouini and Pekar, 2022), the Flow and Feature Generator computes 76 flow-level features and 14 packet-level features. The primary focus of the packet features is to capture the payload information, which is crucial for detecting payload-specific attacks.\nOnce the flows and their respective features are generated, the Flow and Feature Generator transforms the payload of each packet within a flow into a uniform feature space of 1500 features. This transformation is based on the method outlined in Farrukh et al. (2022), where the payload of each packet is represented by 1500 features derived from the bytes of the payload. The hexadecimal representation of each byte is converted into an integer ranging from 0 to 255, with each resulting integer forming one feature. In cases where the payload is shorter than 1500 bytes, zero padding is applied to maintain a consistent feature vector structure. For packets with no payload, the entire feature vector is padded with zeros.\nMathematically, the feature space for a flow can be represented as follows:\nFeatures = [F_1, F_2, ..., F_{76}, P_{payload}, P_{flag},..., P_{layersize}]\n(1)\nwhere:\nP_{payload} = [P_1^{1500}, P_2^{1500},..., P_n^{1500}]\nP_{flag} = [P_1^{x}, P_2^{x}, ..., P_n^{x}]\nP_{layersize} = [P_1^{x}, P_2^{x}, ..., P_n^{x}]\nIn this context:\n\u2022 F_1, F_2, ..., F_{76} denote the 76 flow-level features, encapsulating various attributes related to the overall network flow.\n\u2022 P_{payload} = [P_1^{1500}, P_2^{1500},..., P_n^{1500}] represents the payload features of the packets within the flow, where each packet P_i is expressed as a 1500-dimensional vector. The superscript 1500 denotes the dimensionality of each payload vector.\n\u2022 P_{flag} = [P_1^{x}, P_2^{x}, ..., P_n^{x}] represents another set of packet-level features, such as flags, with dimensionality x for each packet.\n\u2022 P_{layersize} = [P_1^{x}, P_2^{x}, ..., P_n^{x}] represents additional packet-level features, such as IP layer size, also with dimensionality x for each packet."}, {"title": "3.1.2. Explainable Feature Extractor", "content": "Conventional features, developed by the first component, are typically effective for identifying volume-based attacks characterized by significant spikes in SYN requests or packet rates within a single flow but are less effective in detecting attacks that require understanding patterns across multiple flows. To address this limitation, the explainable feature extractor also extracts temporal features that capture statistics from previous flows. This approach involves analyzing the evolution of network flow statistics over time and identifying patterns across multiple flows. Techniques such as sliding window features, which aggregate statistics within specific time frames (e.g., connection attempts or packet rates over the last minute), provide a more comprehensive view of network activity and help identify deviations from normal behavior. Temporal correlation, which tracks the relationship between successive flows such as repeated scanning attempts from the same source, aids in identifying reconnaissance activities. By integrating these additional features, the detection system can better understand and explain the broader context of network traffic patterns, leading to a more performant approach for identifying and mitigating threats.\nOur proposed approach for extracting additional features is illustrated in Algorithm 1. This approach leverages sliding window and temporal techniques to enhance the detection and explanation of cyber-attacks. As detailed in Table 1, the algorithm tracks and calculates various rolling window-based temporal features for each destination machine. These temporal features are systematically updated over time and are then integrated with conventional flow features. The resulting set of metrics offers a comprehensive framework for network intrusion detection, improving both the accuracy and interpretability of the system's predictions. This integration of temporal and flow-based features allows for a more dynamic and context-aware understanding of network behavior, which is crucial for identifying and explaining complex, time-based attacks."}, {"title": "3.1.3. Graph Generator", "content": "To effectively utilize network traffic data for network intrusion detection, we transformed the extracted flow and packet features into a heterogeneous graph structure. This transformation leverages both flow-level and packet-level information, facilitating a comprehensive analysis of the network traffic. Our graph structure includes two types of nodes and two types of edges, enabling detailed and nuanced modeling of network activities.\nLet G = (V, E) represent our heterogeneous graph, where V is the set of nodes and E is the set of edges. The nodes in our graph are categorized into two types: flow nodes and packet nodes. Each flow node v_f \\in V_f corresponds to a unique network flow F, and each packet node v_p \\in V_p represents an individual packet P_i within a flow F having n packets. Thus, the set of nodes V is given by:\nV = V_f \\cup V_p\n(2)\nEach flow node v_f is associated with a feature vector \\mathbf{h}_f \\in \\mathbb{R}^d, derived from flow-level attributes. Similarly, each packet node v_p has a feature vector \\mathbf{h}_p \\in \\mathbb{R}^{1500}, where the attributes are primarily based on packet payload data.\nEdges in the graph E also fall into two categories: \"contain\" edges E_c and \"link\" edges E_l. A \"contain\" edge e \\in E_c connects a flow node v_f to its corresponding packet nodes v_p. The feature vector for a \"contain\" edge, \\mathbf{a}_e \\in \\mathbb{R}^b, includes the layer sizes and direction of the packet. The E_c are represented as:\nE_c = \\{(v_f, v_{p_i}) \\mid 1 \\leq i \\leq n\\}\n(3)\nA \"link\" edge e \\in E_l connects sequential packet nodes within a flow, thereby forming a directed acyclic graph (DAG). The feature vector for a \"link\" edge, \\mathbf{a}_e, includes the time difference (t_\\delta) between two consecutive packets. E_l are represented as:\nE_l = \\{(v_{p_i}, v_{p_{i+1}}) \\mid 1 \\leq i < n\\}\n(4)\nThe process of generating the graph structure is concisely presented in Algorithm 2. Additionally, we developed an open-source tool, GNN4ID (Farrukh et al., 2024b), which facilitates the transformation of raw network traffic into the proposed heterogeneous graph structure. GNN4ID effectively integrates the functionalities of our first three components, enabling users to seamlessly convert any raw network traffic data into the desired graph format. This tool comprehensively demonstrates the entire process, from extracting information from raw packet capture files to generating flow and packet-level features, and ultimately constructing the specified graph structure. A visual depiction of our graph structure is provided in Fig. 2, highlighting the detailed connections and attributes of both nodes and edges."}, {"title": "3.1.4. Graph Neural Network Model", "content": "The proposed HGNN model is designed to effectively process the dual modalities of network traffic packet-level and flow-level information-by leveraging a heterogeneous graph structure. The model is built upon the Graph Attention Convolution (GATConv) (Velickovic et al., 2017) approach to capture the intricate relationships between different types of nodes and edges in the network traffic graph.\nThe layered architecture of the proposed HGNN model is as follows:\n\\mathbf{h}_i^{(l)} = ReLU \\Big(GATConv \\big(\\mathbf{h}_i^{(l-1)}, \\mathbf{A}, \\mathbf{E}\\big)\\Big)\n(5)\nwhere \\mathbf{h}_i^{(0)} denotes the initial node features for each node type V_i, \\mathbf{A} represents the adjacency matrix, and \\mathbf{E} denotes the edge features. The GATConv layers learn attention scores for each edge, enabling the model to focus on the most relevant connections in the graph.\nIn the HGNN model, both node and edge features are crucial for accurately capturing the characteristics of network traffic. The GATConv layers compute attention coefficients \\alpha_{ij} for each edge (i, j), which are then used to aggregate the features of neighboring nodes and edges. The aggregation function for the node embeddings at layer l is defined as:\n\\mathbf{h}_i^{(l)} = \\sigma \\Big( \\sum_{j \\in \\mathcal{N}(i)} \\alpha_{ij} \\mathbf{W}^{(l)} \\mathbf{h}_j^{(l-1)} + \\sum_{e_{ij} \\in \\mathcal{E}} \\alpha_{ij} \\mathbf{W}_e^{(l)} \\mathbf{h}_{e_{ij}}^{(l-1)} \\Big)\n(6)\nwhere \\mathcal{N}(i) represents the neighbors of node i, \\mathbf{W}^{(l)} and \\mathbf{W}_e^{(l)} are the learnable weight matrices for nodes and edges, respectively, and \\sigma is a non-linear activation function (ReLU or LeakyReLU). The edge features \\mathbf{h}_{e_{ij}}^{(l-1)} are combined with the node features from the previous layer to provide a richer representation at each layer. This combination allows the model to capture both local (node-level) and global (edge-level) interactions within the graph.\nThe HGNN model consists of two GATConv layers, each followed by a batch normalization step and a LeakyReLU activation function to introduce non-linearity:\n\\mathbf{h}_i^{(2)} = ReLU \\Big(BN \\big(GATConv \\big(\\mathbf{h}_i^{(l)}, \\mathbf{A}, \\mathbf{E}\\big)\\big)\\Big)\n(7)\nHere, the batch normalization function BN(\\cdot) is applied to the output of the GATConv layer to stabilize the learning process, particularly in deep networks, by normalizing the output features. The LeakyReLU activation function ensures that the model can learn from both positive and negative feature values, thereby enhancing its ability to capture complex patterns in the data.\nFollowing the two convolutional layers, the node embeddings are aggregated into a single graph-level embedding using a global mean pooling operation:\n\\mathbf{h}_{graph} = GlobalMeanPool \\Big(\\mathbf{h}_i^{(2)}\\Big)\n(8)\nThis pooling step generates a unified representation of the entire graph by averaging the embeddings of all nodes, ensuring that both packet-level and flow-level information are comprehensively captured.\nThe graph-level embedding is then passed through a series of fully connected layers to produce the final classification output. These layers progressively reduce the dimensionality of the embedding while refining the learned features:\nOut = LogSoftmax \\Big(\\mathbf{W}_2 \\cdot ReLU \\big(\\mathbf{W}_1 \\cdot ReLU \\big(\\mathbf{W}_0 \\mathbf{h}_{graph}\\big)\\big)\\Big)\n(9)\nwhere \\mathbf{W}_0, \\mathbf{W}_1, and \\mathbf{W}_2 are weight matrices for the fully connected layers, and LogSoftmax(\\cdot) converts the final output into class probabilities.\nThe proposed HGNN model effectively integrates packet-level and flow-level information within a heterogeneous graph framework, combining node and edge features to capture the full spectrum of interactions in network traffic data. By utilizing GATConv layers with attention mechanisms, the model prioritizes critical connections within the graph, enhancing the overall accuracy of the classification."}, {"title": "3.1.5. Integrated Gradient Explainer", "content": "The fourth component in our system is the Integrated Gradient Explainer, which provides feature-based local explanations for each predicted outcome from the HGNN model. This explainer uses the Integrated Gradient approach to determine the contribution of each input feature to the network's prediction (Sundararajan et al., 2017). One of the primary advantages of Integrated Gradients is that it does not require any modification to the original network architecture. It is implemented with a few calls to the standard gradient operator, making it simple and efficient to use. Moreover, this method ensures that the attributions are accurate and meaningful, as it satisfies key theoretical principles that make the explanations reliable.\nIntegrated Gradients work by considering the path integral of the gradients of the prediction function F along a straight line from a baseline input to the actual input. If a baseline input is not provided, zero is used as the default value. The method computes the integral of the gradients at all points along this path, resulting in attributions that explain the importance of each feature in the input. Mathematically, this is represented as follows:\nIntegratedGrad_i(\\mathbf{x}) = (x_i - x_i') \\times \\int_{\\alpha=0}^1 \\frac{\\partial F(\\mathbf{x}' + \\alpha(\\mathbf{x} - \\mathbf{x}'))}{\\partial x_i} d\\alpha\n(10)\nHere, \\frac{\\partial F}{\\partial x_i} represents the gradient of the prediction function F with respect to the i-th input feature. \\mathbf{x} is the actual input, and \\mathbf{x}' is the baseline input. The integral accumulates these gradients along the path from \\mathbf{x}' to \\mathbf{x}, weighting them by the difference between \\mathbf{x} and \\mathbf{x}' along each feature dimension.\nFunction F represents the prediction function of the HGNN. It maps the input features of the heterogeneous graph to the output prediction. In our context, F(\\mathbf{x}) is the predicted outcome based on the input features \\mathbf{x}, which include node attributes, edge weights, and other relevant information from the heterogeneous graph.\nIn our HGNN, the Integrated Gradient Explainer generates explanations by calculating the contributions of each feature in the heterogeneous graph to the network's prediction. This approach helps us understand which features are most influential for each specific prediction, thereby making the model's decisions more interpretable."}, {"title": "3.1.6. Generative Explainer", "content": "The generative explainer module uses a structured approach, integrating both flow and payload importance to create human-readable explanations. This process begins by utilizing the output of the Integrated Gradients Explainer to assess the importance of heterogeneous graph features. The extracted importance values are then used to create prompts, which are sent to the LLM (a Llama 3-8B model) to generate comprehensive explanations through zero-shot prompting.\nDeveloping a structured prompt is particularly critical in zero-shot prompting approach because it allows the LLM to generate accurate and contextually relevant explanations without requiring additional training on specific examples. The effectiveness of zero-shot prompting relies heavily on the quality of the prompts. Therefore, developing well-structured prompts is essential to guide the LLM in producing meaningful outputs. The process of crafting these prompts is detailed in Algorithm 3.\nThe first step of this process involves initializing the prompt with a phrase that clearly states the predicted class from the HGNN. Specifically, we used the following initialization phrase (referred to as P_{init}): \u201cThe predicted class from GNN is {PredictedClass}.\u201d This initial prompt sets the context for the LLM to focus on the specific prediction made by the GNN. Following this, the flow importance values are processed by sorting them in descending order and selecting the top features that contributed most to the prediction. These features and their corresponding actual values are then integrated into the second part of the prompt, which is constructed to provide specific details about the top contributing factors. This segment of the prompt is framed as: \u201cThe top features contributing to this prediction are:\u201d followed by a list of features and their actual values (referred to as P_{part2}).\nAn alignment section is then added to the prompt. The alignment phrase (denoted as P_{align}) is crucial as it instructs the LLM to focus on explaining the predicted outcome and its potential reasons without introducing new or unrelated information. The phrase used is: \u201cDon't expect any values on your own. Explain the predicted outcome and its potential reason along with the potential mitigation. Start your answer with \"The predicted outcome is.\"\"\nThese parts-(P_{init}, P_{part2}, and P_{align})-are then combined to form a comprehensive query (Q_{flow}), which is then sent to the LLM to generate the flow-based response. If the GNN predicts a payload-specific attack, such as web-based or bruteforce attacks, additional processing is done for the payload data. In this processing, the payload importance vectors are normalized, and the top payloads are converted into a human-readable ASCII string. Consequently, a second query (Q_{payload}) is constructed to analyze the payload data. This query is prefixed with the phrase assigned to P_{payloadPrefix}: \u201cAnalyze whether this payload of network flow is malicious or not. Give reason concisely.\u201d This query, along with the alignment section (P_{align}), is sent to the LLM to generate a corresponding response.\nFinally, the outputs from the flow and payload-based queries are combined to form the complete generative explanation (G_{exp}).This approach ensures that the explanations are accurate and understandable for both flow-based and payload-specific attacks."}, {"title": "3.2. Dataset", "content": "The CIC-IoT2023 dataset (Neto et al., 2023), developed by the Canadian Institute for Cybersecurity (CIC), is utilized to evaluate"}]}