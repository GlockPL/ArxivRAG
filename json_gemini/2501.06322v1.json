{"title": "Multi-Agent Collaboration Mechanisms: A Survey of LLMs", "authors": ["KHANH-TUNG TRAN", "DUNG DAO", "MINH-DUONG NGUYEN", "QUOC-VIET PHAM", "BARRY O'SULLIVAN", "HOANG D. NGUYEN"], "abstract": "With recent advances in Large Language Models (LLMs), Agentic AI has become phenomenal in real-world\napplications, moving toward multiple LLM-based agents to perceive, learn, reason, and act collaboratively.\nThese LLM-based Multi-Agent Systems (MASs) enable groups of intelligent agents to coordinate and solve\ncomplex tasks collectively at scale, transitioning from isolated models to collaboration-centric approaches. This\nwork provides an extensive survey of the collaborative aspect of MASs and introduces an extensible framework\nto guide future research. Our framework characterizes collaboration mechanisms based on key dimensions:\nactors (agents involved), types (e.g., cooperation, competition, or coopetition), structures (e.g., peer-to-peer,\ncentralized, or distributed), strategies (e.g., role-based or model-based), and coordination protocols. Through a\nreview of existing methodologies, our findings serve as a foundation for demystifying and advancing LLM-\nbased MASs toward more intelligent and collaborative solutions for complex, real-world use cases. In addition,\nvarious applications of MASs across diverse domains, including 5G/6G networks, Industry 5.0, question\nanswering, and social and cultural settings, are also investigated, demonstrating their wider adoption and\nbroader impacts. Finally, we identify key lessons learned, open challenges, and potential research directions of\nMASs towards artificial collective intelligence.", "sections": [{"title": "1 Introduction", "content": ""}, {"title": "1.1 Motivation", "content": "Recent advancements in Large Language Models (LLMs) have transformed artificial intelligence\n(AI), enabling them to perform sophisticated tasks such as creative writing, reasoning, and decision-\nmaking, arguably comparable to human level [156]. While these models have shown remarkable\ncapabilities individually, they still suffer from intrinsic limitations such as hallucination [57], auto-\nregressive nature (e.g., incapable of slow-thinking [49]), and scaling laws [55, 69]. To address these\nchallenges, agentic AI leverages LLMs as the brain, or the orchestrator, integrating them with\nexternal tools and agenda such as planning, enabling LLM-based agents to take actions, solve\ncomplex problems, and learn and interact with external environments\u00b9,\u00b2. Furthermore, researchers\nare increasingly exploring horizontal scaling \u2013 leveraging multiple LLM-based agents to work\ntogether collaboratively towards collective intelligence. This approach aligns with ongoing research\nin Multi-Agent Systems (MASs) and collaborative AI, which focus on enabling groups of intelligent\nagents to coordinate, share knowledge, and solve problems collectively. The convergence of these\nfields has given rise to LLM-based MASs, which harness the collective intelligence of multiple LLMs\nto tackle complex, multi-step challenges [118]. Inspiration for MASs extends beyond technological\nadvancements and finds roots in human collective intelligence (e.g., society of mind [87], theory of\nmind [45]). Human societies excel in leveraging teamwork and specialization to achieve shared\ngoals, from everyday tasks to scientific discoveries. Similarly, MASs are designed to emulate these\nprinciples, enabling AI agents to collaborate effectively by combining their individual strengths\nand perspectives.\nLLM-based MAS can have multiple collaboration channels with different characteristics, as\nillustrated in Fig. 1. MASs have demonstrated notable successes across various domains, enhancing\nthe capabilities of individual LLMs by leveraging collaboration and coordination among specialized\nagents. These systems distribute tasks among agents, allowing agents to share knowledge, execute\nsubtasks, and align their efforts toward shared objectives. The potential benefits of MASs are\ntransformative. They excel in knowledge memorization, enabling distributed agents to retain\nand share diverse knowledge bases without overloading a single system [51, 154]. They enhance\nlong-term planning by delegating tasks across agents, supporting persistent problem-solving\nover extended interactions [58]. Furthermore, MASs enable effective generalization by pooling\nexpertise from multiple models with specialized prompts/personas, allowing them to address diverse\nproblems more effectively than standalone models. Lastly, MASs improve interaction efficiency\nby simultaneously managing subtasks through specialized agents, accelerating the resolution of\ncomplex, multi-step tasks. MAS strives to achieve collective intelligence, where the combined\ncapabilities of multiple agents exceed the sum of their individual contributions [24].\nOne of the main focus for effective MASs is the mechanisms of collaboration [33, 74, 75, 97, 132],\nwhich lead to a transition from traditional, isolated models toward approaches that emphasize\ninteractions, enabling agents to connect, negotiate, make decisions, plan, and act jointly, driving\nforward the capabilities of AI in collective settings. A deeper understanding of how collaboration\nmechanisms operate in MASs is critical to unlocking their full potential."}, {"title": "1.2 State-of-the-Arts and Contributions", "content": "Due to the importance and timely need for LLM-based multi-agent collaborative systems, there\nhave been a couple of surveys on this topic. However, these works often fall short in fully addressing\nthe collaborative aspects and mechanisms of LLM-based MASs, which are crucial to enabling agents\nto work effectively toward shared goals, as summarized in Table 1. For instance, [47, 107, 136]\nfocus on single-agent systems and only touch on multi-agent collaboration at a surface level.\n[136] lays the groundwork by proposing a framework for LLM-based agents, consisting of three\ncomponents: brain, perception, and action. Their work highlights the use of LLMs as the brain\nof agents, leveraging techniques such as input modality integration, prompting, retrieval, and\ntool usage. However, their discussion of multi-agent collaboration is limited to agent behaviors\nand personalities, lacking an exploration of mechanisms that enable agents to work together. [47]\nsurveys the domains and settings where LLM-based MASs have been successfully applied, profiling\nthe communication structures of these systems (layered, decentralized, centralized, and shared\nmessage pools) but without touching other characteristics of collaboration, such as type, strategy,\nor coordination architecture.\nOther works, such as [82], focus on collaborative strategies, categorizing them into merging,\nensemble, and cooperation. Although their survey discusses how these strategies are applied to\nLLMs and extends cooperation beyond traditional fusion techniques, it overlooks other essential\ncollaboration mechanisms, such as competition and coopetition, and dimensions beyond popular\ncollaboration types. In contrast, [120] proposes a generic framework for enhancing LLM capabilities\nvia MASs, showing how tools like Auto-GPT align with their framework. However, the collaboration\nmechanisms remain conceptual, lacking detailed implementation and characterization. In [50], the\nfocus is on configuring LLMs to leverage diverse capabilities and roles, such as integrating memory\nand information retrieval components. Their exploration of multi-agent collaboration primarily\ncenters on planning and orchestration architectures, emphasizing global and local task planning\nbased on agent roles and specializations. Meanwhile, [46] narrows its focus to the application of"}, {"title": "1.3 Paper Organization", "content": "This paper is organized as follows. Section 2 provides the background necessary for understanding\nthis work, including an overview of LLMs, MASs, and collaborative AI. In Section 3, we introduce\nfoundational concepts in LLM-based multi-agent collaborative systems through mathematical\nnotations, emphasizing the vital role of collaboration. Then, in Section 4, we present an extensive\nreview of LLM-based multi-agent collaborative systems, categorized by key characteristics of\ncollaboration, including type, strategy, structure, and coordination and orchestration. Next, Section 5\nreviews key applications of LLM-based multi-agent collaborative systems across both industry and\nacademia. In Section 6, we discuss open problems and potential future research directions in this\nrelatively new and evolving research area. Finally, we conclude this survey paper on LLM-based\nmulti-agent collaborative system in Section 7."}, {"title": "2 Background", "content": ""}, {"title": "2.1 Multi-Agent (AI) Systems", "content": "MAS is a computerized system composed of multiple interacting intelligent agents. The key\ncomponents of MAS are as follows:\n\u2022 Agents: The core actors with roles, capabilities, behaviors and knowledge models. Capabili-\nties like learning, planning, reasoning and decision making lend intelligence to the agents\nand overall system.\n\u2022 Environment: The external world where agents are situated in and can sense and act upon.\nEnvironments can be simulated or physical spaces like factories, roads, power grids etc.\n\u2022 Interactions: Communications between agents happen via standard agent communication\nlanguages. Agent interactions involve cooperation, coordination, negotiation and more\nbased on system needs.\n\u2022 Organization: Agents either have hierarchical control or organize based on emergent be-\nhaviors.\nMASs can solve problems that are difficult or impossible for an individual agent or a monolithic\nsystem to solve [37]. Agents collaboratively solve tasks yet they offer more flexibility due to\ntheir inherent ability to learn and make autonomous decisions. Agents use their interactions with\nneighboring agents or with the environment to learn new contexts and actions. Subsequently,\nagents use their knowledge to decide and perform an action on the environment to solve their\nassigned tasks [43]. It is this flexibility that makes MAS suited to solve problems in a variety of\ndisciplines including computer science, civil engineering, and electrical engineering.\nThe salient features of MAS, including flexibility, and reliability, self-organization, and real-time\noperation make it an effective solution to solve complex tasks, which can be detailed as follows:\n\u2022 Flexibility and Scalability: MAS can flexibly adapt to changing environments by adding,\nremoving, and modifying agents. This makes them highly scalable for solving complex\nproblems.\n\u2022 Robustness and Reliability: Decentralization of control leads to continued system operation\neven with some failed components. This lends greater robustness and fault tolerance.\n\u2022 Self-Organization and Coordination: Agents can self-organize based on emergent behavior\nrules for the division of labor, coordinated decision making, and conflict resolution.\n\u2022 Real-time Operation: Immediate situational responses are possible without the need for\nhuman oversight. Enables applications like disaster rescue and traffic optimization.\nTheir efficiency stems from the division of labor inherent in MAS whereby a complex task is divided\ninto multiple smaller tasks, each of which is assigned to a distinct agent. Naturally, the associated"}, {"title": "2.2 Large Language Models", "content": "LLMs - driven by the development of transformer architectures [127] - represent a significant\nleap in Natural Language Processing (NLP) and AI. These models, such as OpenAI's GPT [4],\nMeta's LLaMA [124], and Google's Gemini series [123], are trained on vast text corpora and\nrely on large-scale artificial neural networks with billions, sometimes trillions, of parameters.\nTheir scale has enabled breakthroughs in language understanding, generation, and task-specific\napplications [38, 93, 101, 110, 125].\nThe defining characteristic of LLMs is their size and the phenomenon of emergent abilities, which\narise when models exceed a certain threshold in terms of parameters. These emergent behaviors\nallow LLMs to solve tasks they were not explicitly trained on, such as analogical reasoning and\nzero-shot learning, where the model can tackle new problems without additional fine-tuning [113].\nThe launch of models like GPT-3 and ChatGPT in recent years has made these capabilities accessible\nto the public, leading to a surge in both academic and industrial research on how to optimize, scale,\nand secure LLMs for real-world use [42].\nDespite the promising innovations, LLMs are not without challenges. Their performance de-\ngrades as real-world knowledge changes, prompting a focus on aligning models with up-to-date\ninformation without retraining from scratch [19, 28]. Moreover, the geopolitical and ethical impli-\ncations of LLM development have become the limelight for policymakers, especially concerning\nthe computational power required and potential misuse by malicious actors [76, 86].\nLLMs are increasingly being utilized as the \"brain\" for individual agents in MASs, bringing\nsophisticated reasoning and language capabilities to each agent. With frameworks like Agent-\nVerse, LLMs enhance agents' autonomy by allowing them to infer tasks, make decisions based\non situational awareness, and even exhibit emergent social behaviors such as collaboration and\nnegotiation [24]. While LLMs have shown remarkable performance in single-agent tasks, their\nlimitations become apparent in multi-agent settings where the complexity of coordination, com-\nmunication, and decision-making is higher. Issues such as cascading hallucinations \u2013 where one\nerroneous output leads to compounding mistakes pose challenges in sustained multi-agent inter-\nactions. However, frameworks like MetaGPT introduce meta-programming techniques including\nstructured workflows and processes within agent interactions to decompose and tackle complex\nproblems, mitigating these issues [56]. Moreover, consensus-seeking mechanisms like those tested\nin the Consensus-LLM project show that LLMs can negotiate and align on shared goals in dynamic\nenvironments [21]. These works showcase LLMs' potential as central decision-making components\nand highlight LLMs' capacity to adapt to the strategies of other LLM-based agents, which could be\nfoundational in multiple applications."}, {"title": "2.3 Collaborative AI", "content": "Collaborative AI often refers to AI systems designed to work together with other AI agents or\nhumans [27]. Collaborative AI emerges from two primary research directions: 1) the advancements\nof AI which resulted in increasingly effective tools for human use and a growing demand for AI\nsystems that can collaborate with other agents (humans or AI models), and 2) the realization that\nactive collaboration among AI models can significantly enhance efficiency and effectiveness. This"}, {"title": "3 Multi-Agent Collaboration Concept", "content": "We introduce the main concepts of LLM-based multi-agent collaborative systems, defining key\ncomponents of agents, systems, and collaboration mechanisms based on insights from recent\nresearch in this emerging area."}, {"title": "3.1 Agent and Collaborative System Definition", "content": "An agent can be mathematically represented by $a = \\{m, o, e, x, y\\}$ as follows:\n\u2022 Model $m = \\{arch, mem, adp\\}$: the AI model, consisting of its architecture ($arch$), agent's\nspecific memory ($mem$), and optional adapters ($adp$). Adapters are adaptive intelligent\nmodules that allow the agent to incorporate additional knowledge from others through\nmechanisms such as speculative decoding and parameter-efficient adapter, which can\nfurther enrich the model's response capabilities [40, 72, 98]. In the case of LLM agents, the\narchitecture $arch$ is a language model, and the agent's specific memory $mem$ is typically\nthe system prompt $r$.\n\u2022 Objective $o$: the objective or goal of the agent, guiding its actions within the system. For ex-\nample, in question-answering tasks, the objective is to minimize the cross-entropy between\nthe generated answer and the ground truth."}, {"title": "4 Methodology", "content": ""}, {"title": "4.1 Overview", "content": "This section provides an extensive review of LLM-based multi-agent collaborative systems, empha-\nsizing their key characteristics, including the mechanisms for coordination and orchestration among\nagents - collaboration channels - types, strategies, and structures. Fig. 2 presents our proposed\nframework for MASs, detailing their core components and interconnections.\nOur survey strategy involves systematically analyzing existing research on MASs to identify the\ndefining characteristics of multi-agent collaboration. From this analysis, we deduce the fundamental\ncomponents and trends in MAS design and synthesize them into a cohesive framework. First, each\nLLM-based agent in the system is equipped with an LLM $m$, current objective $o$, environment $e$, input\nperception $x$, and corresponding output/action $y$. This is visualized in the left part of Figure 2 and\ndescribed formally using mathematical notations in Section 3.1. Our central focus in this framework\nis the collaboration channels $C$ between agents that facilitate coordination and orchestration among\nagents. These channels are characterized by their actors (agents involved), type (e.g., cooperation,\ncompetition, or coopetition), structure (e.g., peer-to-peer, centralized, or distributed), and strategy\n(e.g., role-based, rule-based, or model-based). Collaboration mechanisms span various levels of\nmachine learning processes, including data exchange, shared input embeddings, model sharing,\nand output sharing, enabling agents to interact effectively and leverage each other's strengths.\nFor each component, we discuss the prevailing implementation trends and methodologies ob-\nserved in the literature. We examine how these methods align with our proposed framework. We\nsummarize our main findings and lessons learned at the end of the section, offering guidance for\nfuture research in the field."}, {"title": "4.2 Collaboration Types", "content": ""}, {"title": "4.2.1 Cooperation", "content": "Cooperation in LLM-based MASs occurs when agents align their individual\nobjectives ($o_i$) with a shared collective goal ($O_{collab}$), working together to achieve a mutually\nbeneficial outcome: $O_{collab} = \\bigcup_{i=1}^{n} o_i$. Agents assess each other's needs and capabilities, actively\nseeking collaborative opportunities. Moreover, agents can also be utilized to focus on specific\nsub-tasks within their expertise, enhancing efficiency and reducing completion times [24]. This\ntype of collaboration is essential in tasks where collaborative problem-solving, collective decision\nmaking, and complementary skill sets contribute to achieving complex objectives that a single\nagent could not complete as effectively [26, 29, 33].\nSeveral research papers highlight the importance of cooperation in LLM-based MASs. For in-\nstance, in [117], a feedback loop is carried out as the main collaboration channel, where the task\nis first handled by an LLM model (Actor), then an Evaluator and Self-Reflection model rates the\noutput and results, producing verbal guidance for the Actor to improve. In Theory of Mind for\nMulti-Agent Collaboration [75], agents gain a shared belief state representation within the en-\nvironment $E$, helping them track each other's goals and actions, thereby facilitating smoother\ncoordination and better collaborative outcomes. This shared state has led to emergent collaborative\nbehaviors and high-order Theory of Mind capabilities in LLM agents, though challenges remain\nin optimizing long-horizon planning and managing hallucinations. In AgentVerse [24], agents\nspecialize in distinct roles, such as recruitment, decision-making, or evaluation, within a coopera-\ntive framework, which improves system efficiency by leveraging each agent's unique expertise.\nSimilarly, MetaGPT [56] uses an assembly line model, assigning roles and encoding Standardised\nOperating Procedures (SOPs) into prompts $r_i$ to enhance structured coordination and produce\nmodular outputs $y_i$. MetaGPT underscores the potential of integrating human domain knowledge\ninto MASs. Cooperative approaches have shown success in areas like question answering [54],"}, {"title": "4.2.2 Competition", "content": "Competition happens when there are conflicting objectives or scenarios of\nlimited resources. In this type of interaction, agents prioritize their individual goals ($o_i$), which may\nclash with or oppose the objectives of others, introducing an element of rivalry: $O_{collab} = \\{o_i | o_i \\ne\noj, \\forall i \\ne j\\}$. However, this competition can still orient toward the collective goal $O_{collab}$, such as in\nthe scenario of debate. In LLM-based MASs, competitive dynamics can emerge in tasks such as\ndebate, or strategic gameplay, where agents seek to maximize their own success criteria [22, 155].\nIncorporating competition into collaborative MASs can enable innovation and improve the\nrobustness of agents' responses. Competition encourages agents to develop advanced reasoning\nand more creative problem-solving and strengthens the system's adaptability by testing the limits of\neach agent's capabilities. In frameworks like LLMARENA [22], LLM-based MASs with competition\nas the main collaboration type, are benchmarked across seven dynamic gaming environments. For\ninstance, in the game TicTacToe, the board is represented textually within the environment $E$, and\ntwo LLM agents are instructed (through their system prompts $r_i$) compete, aiming to out-maneuver\neach other since their individual goals $o_i$ are mutually exclusive. Crucially, the authors highlight\nthat competition between LLM agents enables skills such as spatial reasoning, strategic planning,\nnumerical reasoning, risk assessment, communication, opponent modeling, and team collabora-\ntion. However, they also acknowledge that LLMs still have a significant journey ahead in their\ndevelopment towards becoming fully autonomous agents, especially in opponent modeling and\nteam collaboration, due to their intrinsic limited capability to interact with other actors. A game\nenvironment is also simulated in [155], where 2 agents act as two restaurant managers competing\nfor 50 customers. Carefully designed prompts $r$ set the scenario, contextualizing the agents' envi-\nronment ($E$) and providing a comprehensive restaurant management system accessible through\nAPIs (external tools). Each agent's context $e_i$ includes information about the rival's performance\nfrom the previous day, including the menu, number of customers, and feedback. In this scenario,\nthe collaboration channel $c$ between the two managers is competitive, illustrating how structured\ncompetition drives agents to refine strategies, conforming to several classic sociological and eco-\nnomic theories. Similarly, in LEGO [54], a multi-agent collaborative framework is introduced for\ncausality explanation generation, where the competition collaborative link $c$ is also pre-defined.\nThe collaboration consists of 2 LLMs, one serves as Explainer with initial output, and another one\nacts as Critic, with iterative refinement and feedback. In [104], the collaboration between LLM\nagents happens at an earlier stage during training, where multiple expert agents are combined and\ntrained together through an objective that lets the agents compete for the best candidate answer\nand identifying agents trained on the domain of the input question.\nThe competitive approach offers advantages such as promoting robustness, strategic adaptability,\nand complex problem-solving capabilities within MASs. However, competition can also introduce\nchallenges, including potential conflicts that require mechanisms to ensure that competition remains\nconstructive and beneficial to overall system goals. Effective coordination efforts between agents\nare important, especially for competition collaboration type. As studied in [128], a MAS approach\nwith suboptimal design for their competitive collaboration channels can be overtaken by single-\nagent counterparts with strong prompts (including relevant few-shot demonstrations) on a range of\nreasoning tasks and backbone LLMs. In settings where cooperation is desired, excessive competition\nmay hamper alignment, requiring frameworks to balance these aspects effectively."}, {"title": "4.2.3 Coopetition", "content": "Coopetition, a strategic blend of cooperation and competition, enables agents\nto collaborate on certain tasks to achieve shared objectives while simultaneously competing with\nothers. This concept, though relatively new, has been explored in recent studies. For instance, [2, 34]\nsimulate negotiation scenarios where agents with differing, and sometimes conflicting, interests\nengage in trade-offs to reach mutually beneficial agreements. In these scenarios, agents assign\nvarying values to their interests, creating opportunities for compromise and collaboration.\nThe mixture-of-experts (MoE) framework also fits in the coopetition collaboration type [6, 15].\nIn MoE, multiple expert models compete to contribute to the final output, with a gating mechanism\nselecting the most appropriate experts for each input. This competitive selection process ensures\nthat the combined expertise of the selected experts leads to a superior overall model performance.\nThe coopetitive interaction among experts occurs first during the model's training phase, where\nthey are trained to specialize in different aspects of the data, thereby enhancing the model's capacity\nto handle diverse tasks effectively."}, {"title": "4.2.4 Coordination of Different Collaboration Channel Types", "content": "In LLM-based MASs, there is often\nthe need for complex interactions that transcend singular collaboration types like competition\nor cooperation. Different agents may participate in different collaboration channels $C$, each with\ndistinct interaction types, coordinating together to achieve the overall system goal $O_{collab}$. This\nhybrid collaboration model combines features of each collaboration type, such as competition\nor cooperation, leveraging the strengths of each to enhance overall system performance and\nadaptability.\nHybrid collaboration has been explored in various LLM-based MASs. For example, in LEGO [54],\nin the first state of the framework, 3 agents cooperate to augment information about the current\ntask, and in the second state, a competitive channel is created between an Explainer LLM agent\nand a Critic LLM agent to refine their outputs for the task.\nConsider the scenario in [77] where two agents, $a_1$ and $a_2$ engage in a competitive debate to argue\nopposing viewpoints on a topic, aiming to persuade a judge agent $a_3$. The competitive collaboration\nchannel between $a_1$ and $a_2$ can be denoted as $C_{comp}$, characterized by the agents involved and the\ncompetitive interaction type. Simultaneously, agent $a_3$ cooperates with both $a_1$ and $a_2$ to reach a\nfinal decision, forming cooperative collaboration channels $C_{coop}$ with the group of debating agents.\nIncorporating multiple collaboration channels with distinct interaction types in LLM-based MASS\nenriches the interaction dynamics and enhances the system's ability to achieve complex objectives.\nThis design reflects real-world scenarios where diverse interactions contribute to successful out-\ncomes, and it opens avenues for developing more sophisticated and adaptable MASs. However,\ncoordinating multiple collaboration channels introduces complexity. To manage the complexity of\nhybrid collaboration, coordination mechanisms such as role assignments, communication protocols,\nand shared knowledge representations are essential."}, {"title": "4.3 Collaboration Strategies", "content": "In general, there are three different kinds of MAS cooperation strategies: 1) Rule-based, 2) Role-\nbased, and 3) Model-based. Fig. 4 shows instances of three types of strategies. The research on\nseveral cooperation protocols is summarized in Table 3."}, {"title": "4.3.1 Rule-based Protocols", "content": "Interactions among agents in $C$ are strictly controlled by predefined\nrules, ensuring that agents coordinate their actions according to system-wide constraints on\nacceptable inputs $x_{collab}$. These protocols enforce a structured collaboration channel setup, where\nagents act on the basis of specific rule sets rather than probabilistic or role-specific inputs."}, {"title": "4.3.2 Role-based Protocols", "content": "Role-based protocols in MASs leverage distinct predefined roles or\ndivision of work, where each agent, $a_i \\in A$, operates on a segmented objective $o_i \\subset O_{collab}$ -\nusually based on their domain knowledge - that supports the system's overarching goal. The\n\"AgentVerse\u201d model demonstrates the efficacy of assigning specific responsibilities to each agent,\nsimulating human-like collaboration, and strengthening alignment through role adherence [24].\nThis strategy classifies the role of each agent in $C$, enabling them to work proactively and cohesively\nto avoid overlaps. In another study, MetaGPT formalizes role-based protocols by encoding Standard\nOperating Procedures (SOPs), where each agent's role is defined by expert-level knowledge, allowing\nagents to act as specialized operators who can verify each other's results [56]. This protocol prevents"}, {"title": "4.3.3 Model-based Protocols", "content": "Model-based protocols in MASs provide flexibility for decision mak-\ning, especially in environments where uncertainties in input perception may impact agents' actions.\nWithin this structure, the probabilistic nature of decision-making supports each agent $a_i \\in A$ in\nanticipating probable outcomes based on the analysis of input $X_{collab}$, current environmental data\n$E$, and shared collaborative goals $O_{collab}$.\nAn article explores how probabilistic models, specifically through Theory of Mind (ToM) in-\nferences, allow agents to make decisions that account for the likely mental states of their peers,\nimproving task alignment even when agents face divergent objectives within $O_{collab}$ [75]. This\napproach effectively distributes the focus of each agent based on ToM-based predictions, enhancing\ncoordination through probabilistic adjustments in $C$, the collaboration channels. Another paper\nattempts to improve human-AI collaboration by integrating logical rules with ToM to infer hu-\nman goals and guide agent actions [16]. The approach employs probabilistic logical reasoning,\ntreating logic rules as latent variables and utilizing a hierarchical reinforcement learning model\nwith ToM to enable agents to dynamically adapt their beliefs and actions based on observed be-\nhaviors. By combining rule-based probabilistic social perception with dynamic collaboration, the"}, {"title": "4.4 Communication Structures", "content": "Overall, the communication structure of multi-agent collaboration can be categorized into four\nmain classes, referred to as 1) Centralized topology, 2) Decentralized and distributed topology,\nand 3) Hierarchical topology (see Fig. 5). Table 4 demonstrates the summary of research studies\naccording to different communication structures."}, {"title": "4.4.1 Centralized Structure", "content": "The centralized structure (also known as a star structure) is an im-\nplementation where every agent is connected to a central agent. In a centralized structure, the\ncollaboration channels $C = \\{c_j\\}$ are set as the participating-serving nature in a centralized commu-\nnication channel. The serving agent acts as a hub through which all other agents communicate and,\nthus, has the objective of managing, controlling, and coordinating the interactions or collaborations\namong participants within the system. One of the most well-known centralized structures in multi-\nagent collaboration can be aligned with Federated Learning (FL). In general, FL is a MAS where $n$"}, {"title": "4.4.2 Decentralized and Distributed Structure", "content": "Decentralized MAS differs from centralized systems\nby distributing control and decision-making across agents. Each agent operates based on local infor-\nmation and possibly limited communication with other agents, requiring sophisticated algorithms\nfor interaction and decision-making. Decentralized MAS are prevalent in various fields, such as\nrobotics (e.g., swarm robotics), networked systems (e.g., sensor networks), and distributed AI.\nDecentralized communication operates as channel set $C = \\{c_j\\}$ are assigned to peer-to-peer,\nwhere agents directly communicate with each other, a structure commonly employed in world\nsimulation applications. Researchers have found taking multiple LLM instances to debate for a fixed\nnumber of rounds can boost their factuality and reasoning capabilities [41, 77, 140]. On specific\nreasoning tasks, adopting a dynamic directed acyclic graph structure for LLMs has been shown\neffective [152]. Also, recent studies [24, 146, 151] have demonstrated that optimal communication\nstructures vary with tasks and compositions of agents.\nRecent research has explored methods to coordinate agents with diverse expertise to enhance\noutcomes across a wide range of tasks that benefit from varied knowledge domains. For instance,\nMedAgent [122] integrates medical agents with different specialties to deliver comprehensive\nanalyses of patients' conditions and treatment options. Similarly, MetaGPT [56] and ChatDev\n[105] facilitate collaboration among agents representing distinct roles, such as product managers,\ndesigners, and programmers, to improve the quality of software development. MARG [32] provides\na framework that leverages the expertise of multiple specialized agents to review scientific papers.\nCreative content generation tasks, including creative writing and storyboard design, have also\nbenefited from multi-agent collaboration, as demonstrated by AutoAgents [20] and OKR-Agent\n[158]. SOA [59] propose a self-organized MAS that can automatically generate and modify large-\nscale code. With the self-organization of agents, a single agent no longer needs to comprehend\nthe codebase, making it possible to scale up large-scale code simply by increasing the number\nof agents. Authors in [150] propose the agent-based collaborative filtering approach, namely\nAgentCF. Specifically, AgentCF considers not only users but also items as agents. Both kinds of\nagents are equipped with memory modules, maintaining the simulated preferences and tastes of\npotential adopters. At each step, user and item agents are prompted to autonomously interact,\nthereby exploring whether these simulated agents can make consistent decisions with real-world\ninteraction records.\nTo implement the decentralized MAS without a large amount of communication, ProAgent\n[149] utilizes LLMs as a comprehensive guideline for leveraging the powerful reasoning and\nplanning capabilities of LLMs in cooperative settings. From the given guideline, ProAgent can\ninterpretably analyze the current scene, explicitly infer teammates' intentions, and dynamically\nadapt its behavior accordingly. Authors in [99] build an agent society using LLMs augmented with\nmemories to simulate human behavior. To efficiently leverage the prior knowledge of agents in the\nsystem for an efficient MAS collaboration, the generative agents have a mechanism for storing a\ncomprehensive record of each agent's experiences, deepening its understanding of itself and the\nenvironment through reflection, and retrieving a compact subset of that information to inform the\nagent's actions. OpenAgents, proposed by [139], aims to transition LLMs from theoretical tools\nto interactive systems serving diverse users. They include three agents: the Data Agent for data\nanalysis using Python and SQL, the Plugins Agent for API-based tasks, and the WebAgent for\nautonomous web browsing. Through a user-friendly interface, OpenAgents offers swift responses\nand robustness for general users while providing developers and researchers with an efficient local\ndeployment platform for building and evaluating language agents in real-world settings."}, {"title": "4.4.3 Hierarchical Structure", "content": "Layered communication is structured hierarchically, with agents at\neach level having distinct functions and primarily interacting within their layer or with adjacent"}, {"title": "4.5 Coordination and Orchestration", "content": "Coordination and orchestration in LLM-based multi-agent collaborative systems extend beyond\nthe functionality of individual collaboration channels, focusing instead on the relationships and\ninteractions among multiple channels. These mechanisms define how collaboration channels are\ncreated, ordered, and characterized, forming the backbone of multi-agent interactions. Depending\non their design, coordination, and orchestration can be categorized as either static or dynamic,\neach offering distinct advantages. A summary is provided in Table 5."}, {"title": "4.5.1 Static Architecture", "content": "Static architectures rely on domain knowledge and predefined rules to\nestablish collaboration channels. These approaches ensure that interactions align with specific\ndomain requirements, leveraging prior knowledge to optimize the system's performance. For\ninstance, sequential chaining"}]}