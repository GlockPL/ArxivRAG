{"title": "Exploring Large Language Models for Feature Selection: A Data-centric Perspective", "authors": ["Dawei Li", "Zhen Tan", "Huan Liu"], "abstract": "The rapid advancement of Large Language Models (LLMs) has significantly influenced various domains, leveraging their exceptional few-shot and zero-shot learning capabilities. In this work, we aim to explore and understand the LLMs-based feature selection methods from a data-centric perspective. We begin by categorizing existing feature selection methods with LLMs into two groups: data-driven feature selection which requires samples values to do statistical inference and text-based feature selection which utilizes prior knowledge of LLMs to do semantical associations using descriptive context. We conduct extensive experiments in both classification and regression tasks with LLMs in various sizes (e.g., GPT-4, ChatGPT and LLaMA-2). Our findings emphasize the effectiveness and robustness of text-based feature selection methods and showcase their potentials using a real-world medical application. We also discuss the challenges and future opportunities in employing LLMs for feature selection, offering insights for further research and development in this emerging field.", "sections": [{"title": "1. Introduction", "content": "Recent years have witnessed the remarkable development of Large Language Models (LLMs) (Achiam et al., 2023; Brown et al., 2020; Tan et al., 2024a; Touvron et al., 2023) across various domains and areas (Liang et al., 2022; Chang et al., 2023; Li et al., 2024c). By leveraging extensive training corpora and well-designed prompting strategies, LLMs demonstrate impressive few-shot and zero-shot capabilities in diverse tasks such as question answering (Wei et al., 2022; Wang et al., 2023b; Tong et al., 2024), information extraction (Wadhwa et al., 2023; Zhu et al., 2023) and knowledge discovery (Pan et al., 2024; Wang et al., 2024b; 2023a). The tuning-free nature also makes in-context learning (ICL) in LLMs achieve a great balance between efficiency and effectiveness (Tan et al., 2024b).\nFeature selection (Dash & Liu, 1997; Li et al., 2017) is a critical data serving step that ensures relevant and high-quality data for downstream machine learning and data mining applications. While existing data-driven selection methods have achieved great success in scenarios with abundant data and metadata, there is an increasing demand for efficient feature selection methods with few or even zero samples for various reasons (Zhang et al., 2019). This need is particularly pronounced in sensitive applications such as predicting survival times for cancer patients (Tomczak et al., 2015; Wissel et al., 2022), where privacy concerns may prevent hospitals and patients from sharing their data, posing difficulties in the feature selection and engineering process. To address this challenge, recent studies (Jeong et al., 2024; Han et al., 2024) have explored leveraging the few-shot capability in LLMs to perform feature selection in low-resource settings and got promising results.\nIn this work, our objective is to thoroughly explore and understand LLMs-based feature selection methods from a data-centric perspective. The conclusions and insights"}, {"title": "2. Related Work", "content": "2.1. Feature Selection\nFeature selection is the process of identifying and selecting the most relevant and important features or variables from a dataset to improve the performance and efficiency of a machine learning model (Dash & Liu, 1997; Guyon & Elisseeff, 2003; Chandrashekar & Sahin, 2014; Li et al., 2017). These feature selection methods can be generally categorized into three groups: filter, wrapper, and embedded approaches. Filter methods (Lazar et al., 2012) first rank features by performing correlation analysis and then selecting the most important ones for the following learning step. Typical filter methods include mutual information (Lewis, 1992; Ding & Peng, 2005), Fisher score (Hart et al., 2000; Gu et al., 2011) and maximum mean discrepancy (Song et al., 2012). By contrast, wrapper methods (Kohavi & John, 1997) use heuristic search strategies to identify a feature subset that optimally enhances the performance of certain prediction models (e.g., sequential selection (Luo & Chen, 2014) and recursive feature elimination (Guyon et al., 2002)). For embedded approaches, it works together with specific machine learning models in the training phase by adding various regularization items in the loss function to encourage feature sparsity (Tibshirani, 1996; Yuan & Lin, 2006; Feng & Simon, 2017; Lemhadri et al., 2021).\n2.2. Feature Selection with LLMs\nThere are already some works exploring the adaptation of LLMs in feature selection. (Choi et al., 2022) try to extract the relevant knowledge from LLMs as the task prior to performing feature selection, reinforcement learning and casual discovery. For feature selection, they design a prompt to instruct GPT-3 (Brown et al., 2020) to generate whether given features are important by answering \u201cYes\u201d or \u201cNo\u201d. Following them, (Jeong et al., 2024) expand the LLMs-based feature selection and propose three different pipelines that directly utilize the generated text output. They also conduct extensive experiments in evaluation across various model"}, {"title": "3. A Data-centric Taxonomy", "content": "Given a pre-trained LLM M, we follow the scoring-based method proposed by (Jeong et al., 2024), which prompt M to generate an importance score si for the given feature/ concept fi in the dataset d:\n$s_i = M(P_{f_i}), i \\in \\{1, ..., l\\},$ (1)\nwhere l is the total number of the features in dataset d. Pfi refers to the specific prompt we use to generate the importance score. We will discuss two methods for constructing prompts in Sections 3.1 and 3.2, each focusing on different capabilities of LLMs. Figure 2 demonstrates the detailed prompting strategy for each of them."}, {"title": "3.1. Data-driven Feature Selection", "content": "Recently, LLMs have been employed to directly handle numeric data, demonstrating their capabilities in numerical prediction and analytics (Gruver et al., 2024; Jin et al., 2023). Therefore, we build a data-driven feature selection method with LLMs by providing both features' value nf; and the value of the target variable ny. Intuitively, LLMs are supposed to infer the correlation and perform statistical analysis to determine the importance of the given feature in the dataset.\nTo be more specific, assume there are m samples available in the dataset d, we first build the sample pairs SP; using values of the chosen feature and target variable:\n$SP_i = \\{(n_{f_i}^{j}, n_y^{j})\\}, i \\in \\{1, ..., l\\}, j \\in \\{1, ..., m\\}.$ (2)\nThen, we curate the prompt Pf\u2081 using SP\u2081 and other instruction context C:\n$P_{f_i}^{Data} = prompt(C, SP_i),$ (3)\nhere prompt is a function to concatenate the information and build a fluent instruction for LLMs."}, {"title": "3.2. Text-based Feature Selection", "content": "Another line of work (Choi et al., 2022; Jeong et al., 2024) tries to employ the extensive semantics knowledge in LLMs (Li et al., 2024a) to perform feature selection. Specifically, they incorporate detailed dataset descriptions in the prompt, instructing LLMs to semantically distinguish the importance of a given feature using their inherent knowledge and experience.\nIn our studies, we consider two concrete descriptive contexts: dataset description (desd) and feature description (desf\u2081). The dataset description includes the task's objective, details about the dataset's collection, and an explanation of the target variable. The feature description focuses on detailing and clarifying the feature to be scored.\nFormally, we build prompts by integrating the abovementioned information:\n$P_{f_i}^{Text} = prompt(C, des_d, des_{f_i}).$ (4)\nWe give specific instruction examples for the two feature selection methods in Appendix A."}, {"title": "4. Analyses", "content": "4.1. Experiment Settings\nIn this section, we evaluate the performance of the LLM-based feature selection methods using various datasets and models.\nModels. Below are the LLMs used in our experiment.\n\u2022 LLaMA-2 (Touvron et al., 2023): 7B parameters."}, {"title": "4.2. Result Analysis", "content": "We present our main experimental results in Figure 3 and Figure 4 for analyzing, and highlighting the following findings for answering the RESEARCH QUESTION:\nFinding 1: Text-based feature selection is more effective than data-driven ones with LLMs in low-resource settings. As results demonstrated in Figure 3 (a), almost in every LLM and task (except LLaMA-2-7B in classification), the performance of small machine learning models with the text-based feature selection method surpasses that of the data-driven feature selection method. This finding is consistent when we delve into feature selection methods' performance in each data availability, as depicted in Figure 4. Additionally, in Figure 3 (a), we notice for the same LLM, the text-based feature selection method usually leads"}, {"title": "5. Survival Prediction - A Case Study", "content": "We use a biomedical task to showcase the utilization of LLMs-based feature selection in real-world applications. Survival time prediction (Tomczak et al., 2015; Wissel et al., 2022) aims to predict cancer patients' survival time based on their physical and physiological indicators, playing a critical role in patient risk management and boosting treatment selection. One of the significant challenges in survival prediction datasets is the huge volume of features (e.g., there are around 20,000 gene expression features in the TCGA (Tomczak et al., 2015) dataset). While previous studies performed data-driven feature selection methods such as principal component analysis (PCA) to address this issue (Wissel et al., 2023), as we mentioned in Section 1, It would cause serious privacy concerns for both patients and hospitals.\nImpressed by the competitive performance and sample-free nature of text-based feature selection with LLMs, here we adopt it in the survival prediction application. In our preliminary experiments, we found LLMs have difficulties in directly understanding the domain-specific feature name (e.g., gene ID). Therefore, we borrow insights from retrieval-augmented generation (RAG) with LLMs (Gao et al., 2023; Chen et al., 2024; Li et al., 2024b) and propose Retrieval-Augmented Feature Selection (RAFS) to efficiently handle"}, {"title": "5.1. Experiment Settings", "content": "We conduct experiments using the Lung Adenocarcinoma (LUAD) dataset in The Cancer Genome Atlas (TCGA) benchmark (Tomczak et al., 2015). Akin to (Wissel et al., 2023), we use clinical indicators and gene expression as the full feature set and fix the feature selection ratio to be 30%. We use PriorityLasso (Klau et al., 2018) as our machine learning backbone and report three metrics: Antolini's Concordance (Antolini's C) (Tomczak et al., 2015), Integrated Brier score (IBS) (Graf et al., 1999) and D-Calibration (D-CAL) (Haider et al., 2020), all of which are commonly-used metrics for survival prediction."}, {"title": "6. Outlook", "content": "In this section, we discuss potential opportunities for LLMs in feature selection, aiming to provide guidelines and hints for future works.\nSynergy of LLMs-based and traditional feature selection. As we discuss in Section 1 and 4.2, text-based feature selection with LLMs is competitive and resource-efficient compared with traditional feature selection methods. However, each approach relies on different sources of information-specific samples or context descriptions to perform"}, {"title": "7. Conclusion", "content": "In this study, we explore feature selection methods based on LLMs from a data-centric perspective. We categorize existing LLM-based feature selection approaches into two main types: data-driven, which relies on statistical inference from specific samples, and text-based, which utilizes the extensive knowledge of LLMs for semantic association. Our experiments and analyses reveal that text-based feature selection with LLMs outperforms data-driven methods in terms of effectiveness, stability, and robustness. Based on these findings, we introduce a Retrieval-Augmented Feature Selection (RAFS) method designed to manage large volumes of domain-specific feature candidates in the context of cancer survival time prediction. Additionally, we provide"}, {"title": "A. Detailed Instruction", "content": "/* Main System Prompt */\nFor the given feature, your task is to provide a feature importance score (between 0 and 1; larger value indicates greater importance).\n/* Specific Sample Vlaues */\nHere are some data points in the format of (feature value, target value), please refer to this to determine how informative the feature is in predicting the target value:\n(<0, no)\n(no checking, no)\n(<0, no)\n(<0, no)\n(0<=X<200, no)\n(<0, no)\n(>=200, no)\n(<0, no)\n(no checking, yes)\n(no checking, yes)\n(0<=X<200, yes)\n(0<=X<200, yes)\n(no checking, yes)\n(0<=X<200, yes)\n(0<=X<200, yes)\n(<0, yes)\n/* Output Format Instruction */\nHere is an example:\n666\nQuestion: What is the importance score for the given feature\nAnswer: The importance score is 0.9\n/* Main User Prompt*/\nQuestion: What is the importance score for the given feature\nAnswer: The importance score is"}]}