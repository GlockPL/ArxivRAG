{"title": "Emulating Brain-like Rapid Learning in Neuromorphic Edge Computing", "authors": ["Kenneth Stewart", "Michael Neumeier", "Sumit Bam Shrestha", "Garrick Orchard", "Emre Neftci"], "abstract": "Achieving personalized intelligence at the edge with real-time learning capabilities holds enormous promise in enhancing our daily experiences and helping decision making, planning, and sensing. However, efficient and reliable edge learning remains difficult with current technology due to the lack of personalized data, insufficient hardware capabilities, and inherent challenges posed by online learning.\nOver time and across multiple developmental stages, the brain has evolved to efficiently incorporate new knowledge by gradually building on previous knowledge. In this work, we emulate the multiple stages of learning with digital neuromorphic technology that simulates the neural and synaptic processes of the brain using two stages of learning. First, a meta-training stage trains the hyperparameters of synaptic plasticity for one-shot learning using a differentiable simulation of the neuromorphic hardware. This meta-training process refines a hardware local three-factor synaptic plasticity rule and its associated hyperparameters to align with the trained task domain. In a subsequent deployment stage, these optimized hyperparameters enable fast, data-efficient, and accurate learning of new classes. We demonstrate our approach using event-driven vision sensor data and the Intel Loihi neuromorphic processor with its plasticity dynamics, achieving real-time one-shot learning of new classes that is vastly improved over transfer learning. Our methodology can be deployed with arbitrary plasticity models and can be applied to situations demanding quick learning and adaptation at the edge, such as navigating unfamiliar environments or learning unexpected categories of data through user engagement.", "sections": [{"title": "1 Introduction", "content": "The brain's learning strategies differ remarkably with deep neural networks in that learning is local and largely incompatible with gradient backpropagation, and it does not learn tasks from scratch. Throughout evolution, infancy, and adulthood, brains acquire inductive biases to survive and thrive. Even before birth, brains are specialized to solve tasks that are likely to be encountered in their lifetimes and environment [1]. Furthermore, they are equipped with restricted but highly optimized mechanisms to adapt to new variations and situations.\nIn this work, we take inspiration from these observations to lay out an algorithmic framework that equips neuromorphic hardware with optimized mechanisms for rapid and efficient learning at the edge. Neuromorphic electronic systems aim to mimic the structure and dynamics of the brain to facilitate efficient, versatile, and rapid information processing [2, 3, 4, 5, 6]. Neuromorphic hardware generally implements Spiking Neural Networks (SNNs), which exploit temporal sparsity by means of asynchronous, event-based communication [7, 8]. Neuromorphic learning capabilities further enable rapid and energy-efficient learning at the edge via local synaptic plasticity rules [9, 10, 8, 11]. Prior work with neuromorphic systems demonstrated learning with three-factor synaptic plasticity from streaming data to incorporate new information, enabling privacy-preserving and low-latency adaptation to new data [12, 9, 8] at accuracies on par with deep neural networks. However, prior approaches did not deliver viable online learning technology, due to long training times, the temporally correlated and real-time nature of the data, or ineffective learning rules compared to their mathematically derived counterparts [13].\nOur approach solves these problems by distributing the learning process into two stages (Fig. 1). The first stage uses a cycle-accurate differentiable simulator of a target digital neuromorphic learning hardware to pre-train the plasticity and learning dynamics. Its differentiable nature allows for the computation of model parameter and hyperparameter gradients across the learning trajectory. This procedure is a type of bi-level optimization [14], where an outer loop optimizes over tasks sampled from a selected task, and where the inner loop dynamics captures the learning process on the sampled tasks. This bilevel optimization is achieved here using a variation of the Model Agnostic Meta Learning (MAML) algorithm [15, 16], where gradients are computed across the plasticity trajectory. The second stage is the deployment: The model trained in the first stage (called henceforth the pre-trained model) is deployed on the target hardware to learn from streamed event data.\nThe first stage is accomplished offline with high-throughput, flexible computers and a large dataset, while the second stage can take place online with power-efficient and real-time hardware using streaming inputs. This distributed approach shifts the most energy and data intensive stages of learning to data centers, away from the edge where power and chip area are limited. Bi-level optimization has a high energy and time cost since it optimizes the learning trajectory on a large number of tasks. However, in its intended applications, the cost can be amortized by using the same pre-trained model on a large number of learning devices at the edge. Transferring pre-trained learning models to hardware has been previously achieved in SNNs using surrogate gradient methods [17] for digital [18] and mixed-signal [19] neuromorphic hardware. Prior work has also demonstrated such bi-level co-optimization with software-simulated SNNs and surrogate gradients on few-shot learning problems [12]. However, the ability to transfer differentiable synaptic plasticity models for online learning with neuromorphic hardware has not yet been achieved.\nHere, we take an important step beyond prior work by meta-training for digital neuromorphic hardware deployment, and demonstrating this in the case of the Intel Loihi Research Chip (\"Loihi\") and its on-chip synaptic plasticity. Bi-level optimization is used to train network hyperparameters with the specific plasticity dynamics of the neuromorphic hardware and target task domain. Specifically, we use Surrogate-gradient Online Error-triggered Learning (SOEL) [18, 10], a local three-factor synaptic plasticity learning rule previously demonstrated for transfer learning in neuromorphic hardware [10, 20]. The three-factor synaptic plasticity rules used in this work are function of local information, namely from pre- and post-synaptic connections, and a global error used to optimize the synapses towards and objective. Three factor rules are consistent with the dynamics of biological synapses and constitute a normative theory of learning in the brain [21]. Using local information, less information is communicated on-chip [8, 5] enabling highly efficient adaptation to streamed sensory data. Furthermore, this leads to low latency since the update locking is drastically reduced [22].\nIn the following sections we describe the underlying plasticity dynamics and its implementation in digital neuromorphic hardware. Then, we demonstrate its use within the bi-level optimization with meta-learning using Intel's neuromorphic hardware as a case study."}, {"title": "2 Methods", "content": "We use bi-level optimization to train the parameters of SNNs equipped with plasticity dynamics on event-based vision tasks domains. Learning and synaptic plasticity in neuromorphic hardware is challenging"}, {"title": "2.1 Surrogate-gradient Online Error-triggered Learning in Digital Neuromorphic Hardware", "content": "In this work, we focus on digital neuromorphic processors equipped with plasticity dynamics [24, 25, 5], namely the the Intel Loihi which equipped with neuromorphic cores capable of on-chip synaptic plasticity [5, 26]. We utilize a plasticity rule adapted from a three-factor rule called Surrogate-gradient Online Error-triggered Learning (SOEL) [18, 10], which has been successively demonstrated in other few-shot learning scenarios [18, 27]. SOEL features three key properties that make it an excellent candidate for efficient synaptic plasticity rule on digital neuromorphic hardware: (i) Surrogate gradients, (ii) Multifactors, and (iii) Error-triggering, each of which is explained below. (i) The surrogate gradient approach solves the non-differentiability problem of the spiking neuron [17] by using a differentiable surrogate of the network for gradient computation. For the purpose of computing the gradient only, this surrogate network typically replaces the hard threshold firing of the Linear Integrate and Fire (LIF) with a Sigmoid-like function. Due to its simplicity, excellent practical performance, and the ability to leverage existing machine learning hardware and software, the surrogate gradient method has become the de facto method for computing the gradients of SNNs [12, 28, 29, 30, 31, 32].\n(ii) The multi-factor aspect enables an efficient implementation in hardware. The analytical form of the synaptic weight gradients in a single LIF network reveals three factors, a global error signal, a local post-synaptic factor, and a local pre-synaptic factor [31, 17]:\n$\\Awij (t) = \\frac{\\AL(s(t))}{\\dsi(t)} \\frac{\\dsi(t)}{\\du(t)} \\frac{\\dui(t)}{\\dwij} =: error(t)\u03c3' (u(t))pj(t),$"}, {"title": "2.2 Bi-level Optimization algorithm and Meta Learning Algorithms", "content": "We describe here the bi-level optimization procedure. We meta-train models using surrogate gradient MAML similar to MAML SNN [12]. The MAML based framework is used here to learn a parameter initialization"}, {"title": "2.3 Experimental Setup and Datasets", "content": "Few-shot learning aims to achieve rapid adaptation when prior knowledge related to the task domain is available. Rather than iterating many times over many samples of data to learn, few-shot learning utilizes prior knowledge of the task domain to learn from one or a few samples of the data. To accomplish this, we set up N-way K-shot learning experiments. Here, N = 5 is the number of classes to be classified and K = 1 is the number of shots, or sample presentations, given to the model for learning.\nWe evaluated our models on modified datasets captured using event-based vision sensors, including the neuromorphic MNIST (N-MNIST), the American Sign Language Dynamic Vision Sensor (ASL-DVS) and the DvsGesture datasets[38, 39, 40, 41, 42]. Each meta dataset consists of 32x32x100 ms event data sample and are constructed as follows:\n\u2022 Double N-MNIST: From the 10 class N-MNIST datasets' 60k training and 10k test samples, Double N-MNIST horizontally combines two N-MNIST samples, resulting in 100 classes. These 100 classes were divided into 64 meta-train, 16 meta-validation, and 20 meta-test classes.\n\u2022 Double ASL-DVS: Similarly to Double N-MNIST, the Double ASL-DVS' concatenates the 24 classes (A-Y excluding J), 4200 samples per class, resulting in 576 tasks. There were split in 369 meta-train, 92 meta-validation, and 115 meta-test classes.\n\u2022 DvsGesture subject+class: 29 individuals, 10 gestures, 1078 training, and 264 test samples. We created splits that used both gesture and individual, resulting in 319 tasks. These were split in 253 meta-train, and 66 meta-test classes [43, 44]. Examples of images from the DvsGesture dataset and how it is implemented for meta-training and meta-testing are shown in Fig. 2. The task here is to classify the combination of subject and gesture category.\nTo meta-train models compatible with the Intel Loihi, we trained SNNs with Intel's Lava-DL open source library [26], which is the first stage of the meta-learning procedure. Lava-DL is a deep library to facilitate offline training and online training and inference within the Lava framework. The library includes a functional differentiable simulator of the Intel Loihi's neuron dynamics, and quantization-aware training with the same stochastic rounding and precision used in the Loihi chip. Therefore, models meta-trained with Lava-DL are transferable for use with Intel's Loihi hardware.\nThe pipeline for meta-training models compatible with Intel's Loihi hardware for meta-testing on hardware is shown in 3. For all results, we meta-trained models to perform 5-way 1-shot learning with Lava-DL. A Lava-DL network is optimized across tasks using the ADAM optimizer [37] in the outer loop and optimized to one-shot classify 5 tasks at a time using SOEL. The models can then be transferred to the Intel Loihi hardware for adaptation with SOEL for online learning at the edge using NetX. All SNN-based models used a two layer network of linear layers with 512 neurons each, plus an output layer consisting of 5 neurons."}, {"title": "3 Results", "content": ""}, {"title": "3.1 SOEL rule in a Single Neuron", "content": "We first show that the SOEL rule operates as expected in a simple task aimed at adjusting the firing rate of a neuron towards a target value. We show that in a single layer of LIF neurons implemented on the Intel Loihi chip, SOEL reduced the error to zero. Fig. 4 demonstrates how SOEL drives learning and reduces the error of a single neuron in the layer to zero, thereby achieving a target firing rate. The single neuron example uses Intel's Lava2 software simulation of the Loihi 2 plasticity state machine. In Fig. 4 the neuron stimulated by Poisson-distributed spike trains. These inputs elicit firing at a rate that is at first too high or too low. Over time, SOEL plasticity adjusts the synaptic weight according to the error and trace values until it reaches the target firing rate. In Intel Loihi chips, the learning step of the plastic synapse is executed at a"}, {"title": "3.2 Bi-level Optimization and Few-shot Learning in the Intel Loihi", "content": "The bi-level optimization procedure aims to optimize the plastic network parameters hyperparameters to pre-train the network for fast online learning. In this bi-level optimization, SOEL is effectively the inner loop adaptation, while the outer loop consists of a conventional gradient backpropagation-through-time across the network with SOEL.\nHere SOEL is only enabled in the last layer of the network for the following reasons: First, prior work demonstrated that MAML learns a suitable representation for few-shot learning instead of solely rapid learning in both ANNs [45] and SNNs [12], meaning networks with meta-learned initializations can achieve high performance on learning new tasks using only a single gradient update in the last layer. The likely reason for this is that MAML learns an adequate feature representation in the layers prior to the plastic ones [46]. Second, there is no requirement to spatially backpropogate errors in the inner loop, allowing for learning rules such as SOEL to be implemented very efficiently in hardware. Third, the outer loop optimization mitigates the approximations of SOEL by optimizing the hyperparameters accordingly.\nWe emphasize here that although SOEL is used in the final layer, the bi-level optimization modifies the parameters of the entire network. The difference between the final layer synapses and the other layers is that the former undergo changes during the presentation of a new sample and thus specialize in the new task. In contrast, the synaptic weights in the other layers represent features that are common to all tasks in the meta dataset. Although in some cases, optimizing the penultimate layer was reported to also benefit accuracy [46], the results of the previous simulation showed that the expansion of the plasticity deeper into the network produced only marginal improvements [27].\nWe demonstrate one-shot learning on the Loihi neuromorphic hardware using SOEL with a meta-trained network on the datasets described in the following sections. Once the model is meta-trained (the \"first stage\") the network (the \"second stage\") is transferred to the Intel Loihi for online one-shot learning on the device."}, {"title": "Meta-Training for Few-Shot Learning", "content": "To build the prior knowledge for effective few-shot learning in neuromorphic hardware, we optimize for few-shot learning on event-vision classification tasks. We optimize the model for three different event-based vision tasks. The Double NMNIST task [12], a double digit version of the Neuromorphic MNIST dataset [40]; The Double ASL-DVS [12], two American Sign Language letter gestures presented side-by-side recorded with the DAVIS 346 [41] event-vision sensor; and the DVSGesture dataset [42], a mid-air gesture dataset recorded with the DAVIS 128 [38] event-vision sensor. In our experiments with the DVSGesture dataset the task is to not only classify the gesture but the individual performing the gesture as well; therefore, there are 44 classes in total. The details of how the datasets are prepared for the experiments and split for bi-level optimization can be found in Section 2.3.\nWe performed multiple few-shot bi-level learning experiments across the datasets. The meta-test set accuracy results of our few-shot bi-level learning experiments are shown in Table 1. To test the models, each model is tested in a one-shot learning trial. In a trial the model is first given a single shot of data to learn from in an inner loop gradient step, then from the single shot learned parameters inference is performed on 10-shots of the test data. The accuracy values shown in Table 1 are averaged over 200 random trials using the same random seed plus or minus the standard deviation across those trials. Neuromorphic hardware has constraints that limit the network compared to a full precision SNN trained in conventional GPU hardware. These constraints are as follows: i) Quantization: the neuron and synapse states are quantized to fixed-point integer values with signed 8 bits of precision for the weights that are stochastically rounded to even values; ii) Hard reset: the reset of the neuron is hard meaning a neuron that spikes membrane potential will reset to 0; and iii) Plasticity processor: use of the SOEL plasticity rule. The SNN model uses floating point precision by default with a soft reset (i.e. the membrane potential is subtracted by a fixed amount after spiking), as opposed to the hard reset to a reset potential (used in the Intel Loihi). Therefore we demonstrate how the"}, {"title": "4 Discussion", "content": "Neuromorphic hardware equipped with synaptic plasticity utilizes event-driven weight updates to rapidly adjust to new tasks. Due to the mostly local and sparse nature of neuromorphic hardware, it is particularly well suited for online learning at the edge. We adopted a powerful meta-learning strategy that can adapt three-factor plasticity rules for accurate online one-shot adaptation at the edge.\nOur work differs from previous efforts to learn from scratch with neuromorphic hardware [25, 24, 19, 8]. Although such approaches work in theory and well controlled learning procedures, they did not provide a viable learning technology. This is because online learning from streaming data in real-world scenarios has several challenges which are not addressed in prior work: data is not i.i.d., training is lengthy, and impractically small learning rates are necessary to average across the entire dataset.\nWe address these challenges using a combination of offline and online learning. Offline pre-training takes place on high-power, high-throughput hardware with access to extensive datasets allows for the development of initial models that capture common features in the task domain. Gradient-based meta-learning such as MAML automates this pre-training. These pre-trained models can then be fine-tuned or adapted on the device using online learning techniques, such as the SOEL. This hybrid approach strikes a balance between leveraging prior knowledge and adapting to real-time data, offering improved robustness and faster convergence.\nFurthermore, when meta-training a network with plasticity dynamics, the resulting pre-trained model can mitigate the non-idealities of the adaptation rule with respect to gradient descent, at least for the selected number of training steps. This observation means that certain challenging hardware constraints involved in the implementation of the synaptic plasticity rule can be relaxed without significantly losing performance. In the case of SOEL, we relaxed the update frequency and the nature of the post-synaptic factor. Other related work mitigated the downsides of STDP [48] and the non-idealities in hardware [49].\nUsing bi-level optimization to enable fast learning with brain-like synaptic plasticity has previously been attempted [48, 50]. Additionally, other work demonstrated the benefits of bi-level optimization for improving the data and power efficiency of learning at the edge [50]. For example, [48] showed that plasticity can be optimized by gradient descent, or meta-learned, in large artificial networks with Hebbian plastic connections, called differentiable plasticity. Our work is closest to [51]: Building on the differentiable plasticity, they meta-optimized Hebbian-like STDP learning rules and local meta-parameters on the event-based datasets for few-shot learning tasks using a model of the Tianjic hardware. Synapses store two components, one that is optimized during bi-level optimization and one that is updated using STDP like plasticity. This is similar in spirit to optimizing initial weights as in MAML and in our work. Our approach differs in three ways: (i) by using a three-factor synaptic plasticity rule (i.e the SOEL), which takes error signals computed from a custom loss function thus enabling the learning of supervised and self-supervised approaches, (ii) we demonstrate on-line learning in custom digital neuromorphic learning hardware, and (iii) by operating the neural dynamics on finer time scales (1ms time steps compared to 12.5ms time steps in the case of [51], which is closer to conventional frame camera rates), providing more than an order of magnitude in temporal resolution.\nWe demonstrated SOEL and the associated bi-level optimization in a range of event-based classification tasks, with data recorded from event-based vision sensors. The class of few-shot learning problems with event-based data has been identified as a key benchmark and application by the broader neuromorphic engineering community [44]. While our work focused on supervised learning with visual data, our method and general approach is applicable to other supervised learning tasks. In fact, the MAML framework has been established for tasks such as reinforcement learning [52], multilingual speech emotion classification[53], and self-supervised learning [54]. In this work, SOEL was limited to the final layer of the network. This is not a conceptual limitation of SOEL itself, since similar error-triggered learning using local losses was already demonstrated in prior work [20]. Rather, this choice was made because MAML is known to learn a suitable representation for few-shot learning instead of rapid learning [55]. Indeed, simulation results show that extending the plasticity deeper in the network yields marginal improvements [27].\nOne limitation of SOEL is for continual learning: Catastrophic forgetting of previous knowledge will occur after multiple online learning epochs. Looking forward, we envision two approaches to solve this problem: (i) Federated learning and (ii) Continual learning techniques, which we detail below. First, federated learning is dedicated to addressing the problem of sharing knowledge from edge devices to a cloud model, while preserving privacy, communication and accuracy [56, 57, 58, 59]. Using meta-learning approaches, the meta-learned models can also be fine-tuned with the data collected at the edge [60]. Online meta-learning [61, 62, 63, 64] can enable continual meta-learning in the offline loop, provided task-relevant information can be transferred back to the offline agent. Secondly, currently developed methods to use continual learning can be implemented [65]. These consist of dynamic architectures, whereby branches of the network are modulated for example using neuromodulation, metaplasticity where synapses are equipped with internal consolidation variables and replay methods.\nAnother limitation is general to the meta-learning problem: the pre-trained models generalize poorly to tasks that are not present in the meta-training set. An example of such a new task is flipping the event-camera inputs upside down. In such cases, performance drops drastically. Using larger datasets and models is a natural solution to this problem. This is the case with so-called foundational models [66] that demonstrate downstream task performance that sometimes even exceeds those of models specifically trained on such tasks [67]. Although the scale of current digital neuromorphic hardware and datasets are far from those used in foundational models, this gap is closing thanks to a better selection of the dataset and a simplification of foundational models [68] and the development of large-scale neuromorphic hardware.\nBi-level optimization on can be used to achieve high performing rapid learning on ultra-low power neu-romorphic hardware. While our method with MAML and SOEL does not solve the problem of catastrophic forgetting, future work using federated and continual learning techniques could help prevent catastrophic for-getting. Additionally, ongoing work on foundation models and the development of large-scale neuromorphic hardware could benefit from online rapid adaption through bi-level optimization across a multitude of task domains such as autonomous vehicles, and speech translation. We expect that such meta-learning approaches will lead to a substantial redefinition of synaptic plasticity requirements for neuromorphic processors and pave the way for exciting and novel learning applications at the edge."}, {"title": "5 Appendix", "content": ""}, {"title": "5.1 Implementation of SOEL on the Intel Loihi 1 and 2 Plasticity State Machine", "content": "SOEL implemented in the Intel Loihi chip follows Eq. (3), with the difference that a constant factor is introduced to represent negative errors. This is because a post-synaptic trace variable is used as a placeholder for ex(t). Because post-synaptic variables cannot be negative, we offset the values with a constant c as follows:\nei(t) = s \u2212 si(t),\n$\\Yi(t) = {\\begin{cases}c+ei(t), if \u22120 > ei(t) > 0\\\\0, otherwise\\end{cases}$$\\nAwij = \u03b7pj(T)(yi(T) \u2013 \u0441).\nFurthermore, the second order trace pj is computed using a difference of two first order traces (indices j) omitted:\np(t) = x\u00b9(t) \u2212 x\u00b2(t)\nx1(t) = aux\u00b9 (t \u2212 1) \u2212 (1 \u2013 au)s(t)\nx\u00b2(t) = avx\u00b2(t \u2212 1) \u2212 (1 \u2013 au)s(t)\nwith \u03b1\u03bd > \u03b1\u03c5\nOn the Loihi 1 hardware, custom programs run on the Loihi's x86 embedded processors to calculate the error to be written to the post-synaptic variable of the learning rule. The programs are run every learning epoch, with a predetermined timestep interval input to the learning rule whose value can be in the range {0,...,63}. Therefore, multiple updates will typically be performed depending on the number of timesteps of a sample. During a learning epoch the error is calculated as follows. First is the determination of if the learning epoch occurs during a sample presentation or a blank time. A blank time is a period of time in which no sample is presented which can allow traces and neuron parameters to decay back to 0 before presenting another sample. If the learning epoch occurs during a blank time then 0 is written to the post trace and the error is not calculated. Otherwise, a check is performed to determine if learning should occur or simply inference. This is done by checking if a label for the class that should be updated is given in which case an error for that class should be calculated and written to the post-trace and otherwise no learning should be done. If a label is given and the learning epoch does not occur during a blank time then the error will be calculated following Eq. (2) to allow the learning rule to update the synaptic weights. From Eq. (6), s is the target spike rate between learning epochs, si(t) is the actual output spike count between learning epochs by the neuron that should learn to predict the class. The error is only written to the post-trace if it is greater than a threshold; otherwise 0 will be written to the post-trace and no learning will occur. The error is multiplied by the second-order trace p; and the learning rate \u03b7 to calculate the change in synaptic weight at each learning epoch.\nIn addition to the Loihi 1 hardware implementation, we tested SOEL using a software simulation of the Loihi 2 plasticity using Intel's Lava open source software library. The same plasticity dynamics used by Loihi 1 are implemented by Loihi 2, therefore SOEL is implementable on Intel's newer Loihi 2. The Loihi 2 implementation used to obtain the results shown in Tab. 1 and Fig. 4 is algorithmically identical to the Loihi 1 hardware implementation. The plasticity state machine of the Loihi 2 hardware has greater flexibility and more features than the Loihi 1, which will be explored in future work."}, {"title": "5.2 Intel Loihi Neuron Model and Synaptic Plasticity", "content": "The Intel Loihi is a neuromorphic processor equipped with a diverse array of features including dendritic compartments, hierarchical connectivity, synaptic delays, and programmable synaptic learning rules [5, 26]. SNNs on Intel's Loihi 1 uses Current Based (CUBA) Leaky Integrate & Fire (LIF) neuron dynamics and the synaptic weights are integers stochastically rounded to 8-bits of precision signed with a step of two allowing values in the range of {-256, -254,, 252, 254}. Intel's Loihi 2 supports neuron models beyond the CUBA LIF model, but for consistency with the Loihi 1 we use the CUBA LIF model for our Loihi 2 experiments as well. The learning rule for a synaptic weight in the Intel Loihi 1 and 2 take the following sum-of-products form as follows [5]:\n$\\\u0394\u03c9 = \u03a3Ck Vkl,$\nwhere w represents the synaptic weight variable assigned to the updated neuron pair from the source to the destination. Ck is a scaling constant, and Vkl[t] can be programmed to represent different state variables. These variables can be pre-synaptic spikes or traces, and post-synaptic spikes or traces. The traces are represented using first-order linear filters and represent a form of synaptic eligibility similar to the traces in STDP [69, 70]."}, {"title": "5.3 Details to the Neuron Model", "content": "Current-based neurons are commonly used in digital neuromorphic hardware thanks to its simplicity. The CUBA neuron dynamics are described as follows:\nuj(t) = auuj (t \u2212 1) + (1 \u2212 au) Wjxj(t),\nv(t) = \u03b1\u03c5(t \u2212 1) + (1 \u2212 \u03b1\u03c5) \u2211 Uj (t),\ns(t) = v(t) \u2265 v,\nv(t) = v(t) (1 \u2013 s(t))\nwhere u(t) is the synaptic current at time t, au is the decay constant for the current, x(t) is the input at time t, v(t) is the membrane potential at time t, s(t) is a post-synaptic spike, and a is the threshold at which the neuron fires a spike. SOEL is computed using the pre-synaptic trace pj(t), which is analytically computed from$\\frac{duj(t)}{dwij}$. It is then trivial that pj(t) is equivalent to two first order filters applied to x;(t):\nqj(t) = auqj (t \u2212 1) + (1 \u2212 au) xj(t),\npj(t) = avpj (t \u2212 1) + (1 \u2212 av) qj (t),\nTraining SNNs with gradient-based learning typically involves using Back Propagation Through Time (BPTT). The dynamics in Eq. 9 cannot be used with gradient descent because the spike function s(t) = v(t) > v is not differentiable. The surrogate gradient approach approximates the spiking threshold function for gradient estimations with a smooth function."}]}