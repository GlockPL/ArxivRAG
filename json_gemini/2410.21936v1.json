{"title": "LogSHIELD: A Graph-based Real-time Anomaly\nDetection Framework using Frequency Analysis", "authors": ["Krishna Chandra Roy", "Qian Chen"], "abstract": "Anomaly-based cyber threat detection using deep learning is\non a constant growth in popularity for novel cyber-attack detection and\nforensics. A robust, efficient, and real-time threat detector in a large-\nscale operational enterprise network requires high accuracy, high fidelity,\nand a high throughput model to detect malicious activities. Traditional\nanomaly-based detection models, however, suffer from high computa-\ntional overhead and low detection accuracy, making them unsuitable for\nreal-time threat detection. In this work, we propose LogSHIELD, a\nhighly effective graph-based anomaly detection model in host data. We\npresent a real-time threat detection approach using frequency-domain\nanalysis of provenance graphs. To demonstrate the significance of graph-\nbased frequency analysis we proposed two approaches. Approach-I uses\na Graph Neural Network (GNN) LogGNN and approach-II performs fre-\nquency domain analysis on graph node samples for graph embedding.\nBoth approaches use a statistical clustering algorithm for anomaly de-\ntection. The proposed models are evaluated using a large host log dataset\nconsisting of 774M benign logs and 375K malware logs. LogSHIELD ex-\nplores the provenance graph to extract contextual and causal relation-\nships among logs, exposing abnormal activities. It can detect stealthy\nand sophisticated attacks with over 98% average AUC and F1 scores. It\nsignificantly improves throughput, achieves an average detection latency\nof 0.13 seconds, and outperforms state-of-the-art models in detection\ntime.", "sections": [{"title": "1 Introduction", "content": "Anomaly-based intrusion detection approaches are indispensable and widely\nadopted for zero-day attack detection, but they suffer from a high false-alarm\nrate compared to signature and rule-based detectors[25]. Although traditional\nsignature and rule-based approaches achieve higher detection accuracy, they fail\nto detect sophisticated and novel attack campaigns as these detectors depend\non malware signatures. Anomaly-based detectors analyze flow-based data such\nas NetFlow, leveraging a set of flow fields to model anomaly behavior patterns\n[13]. However, the flow sequence analysis models suffer from modeling the long-\nterm dependency of the network activity which limits the detection capability.\nTo this end, the provenance graph of system logs provides a better representa-\ntion of systems and network activities describing the information flow between\nsystem processes for anomaly detection[8]. Graph Neural Networks (GNNs) can\ncapture the rich node semantics of provenance graphs by leveraging graph neigh-\nborhoods. Therefore, Machine learning/Deep learning detectors show promising\nanomaly detection performance utilizing GNN-based provenance graph seman-\ntics [16,26].\nAs the size of provenance graphs grows, graph-based detectors become com-\nputationally expensive. The high computational overhead and increased process-\ning time of deep learning algorithms cause the models to struggle with handling a\nhigh volume of audit data. Therefore, deep learning-based computation-intensive\nmodels can be deployed for offline detection but are challenging to use for real-\ntime detection[3,27].\nFrequency domain analysis (FDA) of audit data is an emerging technique\nfor reducing the computational overload of graph-based detection models. FDA\nleverages the transformation of graphs into the frequency domain to identify\nanomalous behaviors [4]. To leverage a graph representation of audit data and\ndesign a real-time anomaly detection model we propose LogSHIELD, a host\ndata-driven provenance graph analysis framework exploiting FDA. LogSHIELD\nutilizes the causal, sequential, and logical relationship of system logs to construct\na provenance graph. To demonstrate the trade-off between detection accuracy\nand detection time, we propose two graph analysis approaches. Approach-I is\nLogSHIELD with LogGNN, a GNN-based approach for embedding graph nodes\nand identifying abnormal sequences. Approach-II is LogSHIELD with FDA[4], a\nFrequency Domain Analysis (FDA) approach for embedding graph nodes. Upon\ngraph embedding both approaches apply a statistical clustering algorithm using\nthe cosine similarity of the node embedding vectors for anomaly detection.\nApproach-I, LogSHIELD with LogGNN analyzes the log provenance graph\nand generates effective log embedding. However, one major drawback is embed-\nding time and detection latency due to the complex embedding network. To\nhandle the higher detection latency of the deep embedding model, approach-II\nperforms frequency domain analysis on the graph. A bidirectional Long Short-\nTerm Memory (BiLSTM) model in LogGNN is replaced with a frequency anal-\nsis FDA module. FDA extracts high-level features from the log provenance\ngraph without utilizing computation-intensive deep learning models which is the\nkey advantage of approach-II. LogSHIELD with FDA takes significantly less de-\ntection time and achieves higher throughput compromising a small fraction of\ndetection accuracy.\nThe design and implementation of LogSHIELD analyzing host logs pose the\nfollowing challenges. The first challenge is constructing a provenance graph us-\ning redundant and concurrent host logs. Many redundant and system-level noisy\nlogs are generated which causes the graph to have thousands of redundant nodes"}, {"title": "2 Related Work", "content": "This section presents existing research on graph-based anomaly detection, focus-\ning on approaches that utilize deep learning, and machine learning algorithms."}, {"title": "2.1 Real-time Anomaly Detection", "content": "Early detection and prevention of threat actors can mitigate the profound losses\nincurred by cyber threats. However, sophisticated systems and stealthy attacks\nrequire real-time detection. Many researchers working toward reducing the de-\ntection time and achieving real-time anomaly detection [9,7,21,22,8,4,14,23].\nIn [22], Wu et al. proposed \"Paradise,\" a real-time, generalized, and dis-\ntributed provenance-based intrusion detection system. Paradise extracts process\nfeature vectors in a separate environment at the system log level and stores\nthem in high-efficiency memory databases. During the detection phase, it cal-\nculates provenance-based dependencies for intrusion detection. Another graph-\nbased real-time outlier detection technique is proposed in [14], which learns all\npossible process relation semantics. The authors claim that a generalized process\nrelation graph (GPRG) enables the detection of any outlier program with 96%\naccuracy at any time instance. In [9], Irshad et al. proposed TRACE, a scalable,\nreal-time, enterprise-wide provenance tracking system for APT detection. It uses\nstatic analysis techniques to identify unit dependencies and strategies to gener-\nate concise provenance graphs, evaluated during five red-team engagements. In\n[21], Wang et al. proposed LightLog, a lightweight temporal convolutional net-\nwork (TCN) for log anomaly detection in edge devices. LightLog uses word2vec\nto generate low-dimensional semantic vectors from logs and TCN for detection,\nachieving real-time processing and detection. Static log stream feature analysis\napproaches are also adopted by many researchers for real-time anomaly detec-\ntion. In [4], Fu et al. proposed \"Whisper,\" a real-time robust malicious network\ntraffic detection method using frequency analysis. The authors experimented\nwith 42 types of attacks and demonstrated that Whisper achieves high through-\nput with 99% AUC accuracy. While our proposed framework LogSHIELD with\nFDA is inspired by Whisper, there are notable differences. Unlike Whisper,\nwhich uses network traffic features and performs frequency analysis for detection,\nLogSHIELD constructs a provenance graph from host logs, performs RWR node\nsampling, and then applies frequency analysis to the sampled node contents."}, {"title": "2.2 Graph-based Anomaly Detection", "content": "Graph representations of multidimensional and heterogeneous data are used in\nmodeling system behavior, thereby detecting abnormalities and threats within\na system. Many research works have applied graph-based analysis techniques to\nthreat detection. In [12], Liu et al. proposed a graph-based user behavior model-\ning approach for insider threat detection using heterogeneous graph embedding.\nLog2vec uses a set of rules to construct the graph and represents each log entry\nas a low-dimensional vector using a random walk. In [19], Wang et al. intro-\nduced an approach for automatic insider threat detection that utilizes not only\nself-anomalous behaviors of an employee but also anomalies relative to other\nemployees with similar job roles. It infers the correlation graph among the orga-\nnization's employees and identifies potential threats using graph signal process-\ning. A graphical analysis and anomaly detection-based approach was proposed"}, {"title": "3 Proposed LogSHIELD Framework", "content": "We introduce two approaches for graph high-level feature extraction and a sta-\ntistical clustering algorithm for anomaly detection."}, {"title": "3.1 Approach-I: LogSHIELD with LogGNN", "content": "Approach-I consists of four main steps: log data collection, graph construction,\ngraph embedding with LogGNN, and anomaly detection. A constructional di-\nagram of LogSHIELD with LogGNN is presented in Figure 1. LogGNN learns\nthe representation and dependency of the nodes in the provenance graph and\nobtains a semantic embedding vector for each of the nodes in the graph.\nLog Preprocessing The logs in the benign and malware datasets are collected\nusing Windows Logging Service (WLS) in standard JSON format. For the benign\ndataset, we recruit 35 legitimate users from a large enterprise network and collect\ntheir working PCs' host logs over 90 days upon approval from the Institutional"}, {"title": "Graph Construction", "content": "To address system anomaly detection as a graph anal-\nysis problem, we construct a provenance graph from daily host logs within an\nenterprise network, capturing the interrelationship of log entries. This is step 2\nin Approach-I as shown in Figure 1. The log provenance graph (LPG) focuses on\nthree types of relationships: causal, sequential, and logical, to learn the contex-\ntual representation of event logs. For sequential relationships, we consider the\ntimestamps of log entries to resolve out-of-order issues caused by log arrival de-\nlays. Causal relationships among processes (EventID 4688, 4689) are established\nby creating directional connections between parent and child processes using\nthe fields ProcessName, BaseFileName, and ParentProcessName. Additionally,\nLogSHIELD builds logical relationships by connecting log entries with the same\ntimestamp. LogSHIELD constructs the graph using five key event fields: Even-\ntID, ProcessName, BaseFileName, LogonType, and ParentProcessName. This\napproach ensures the graph construction follows these specific rules.\nRule 1: All log entries from the same user are connected sequentially based\non their timestamps, forming the main chain of triggered logs.\nRule 2: Log entries from the same user that are related by a parent-child\nprocess are connected with a directional link.\nRule 3: Log entries from the same user with the same timestamp (concurrent\nlogs) are all connected to the last log of the chain with a distinct timestamp.\nRule 4: Log entries from the same user with the same timestamp maintain\nan internal connection between them."}, {"title": "Log Neighbor Sampling", "content": "This is the beginning of step 3 in approach-I. The\nneighbors of a node significantly contribute to its semantics in representation\nlearning. Therefore, in the first step of graph embedding, it samples represen-\ntative neighbor nodes, performs encoding, and aggregates them to find the em-\nbedding of the target node. Many node neighbor sampling algorithms have been\nadopted recently including random walk sampling [24], direct neighbor sampling\nwith different order [20]. Direct neighbors can differ in number leading to insuffi-\ncient representation of a node and an inability to capture diverse node types in\nthe graph. Random walk helps to capture the heterogeneous node by sampling\nthe n-hop neighbors.\nRandom Walk is one of the most popular neighbor sampling algorithms. In\nthis work, we used a modified random walk with a restart strategy. It generates\npaths traversed by walkers starting from node v \u2208 V. The walker travels through\nn-hop neighbors of the current node and returns back until a fixed number\nof nodes are sampled which is walk length, the walker traverses through the\nneighbors. We sample S(v) neighbor nodes of the node v."}, {"title": "Log and Network Encoding", "content": "The next step of graph embedding is encoding\nheterogeneous contents $C_v$, which are attributes or texts of the nodes from $v \\in V$.\nLogGNN uses word2vec[2] model for encoding log fields. Node content embedding\nis performed using a log parsing algorithm in [17]. The details of the encoding\ntext content of event nodes are presented in this section. In a similar fashion\nto Natural Language Processing (NPL) that converts a group of sentences into\ntokens, the events in the host log are represented to tokens $T = [t_1, t_2,..., t_n]$"}, {"title": "Embedding Aggregation", "content": "As mentioned in section 3.1, the n-hop neighbor\nencoding vectors x of each node in the graph are aggregated using the BiLSTM\nmodel. The neighbor sampling and aggregation are performed for each node of\nthe graph to obtain embedding for all the nodes.\nWe use a module to aggregate content embeddings using a sequence-based\ndeep learning model BiLSTM[16]. In section 3.1, we sampled K neighboring\nnodes for each graph node v \u2208 \u039a(v) using the RWR strategy. Final aggregation\nis achieved in two steps. In the first step, we concatenate the network embedding\n$E_{net}(v)$ and content embedding $E_{cont}(v)$. In the second step, the BiLSTM aggre-\ngation model takes the concatenated node embedding $E_v = E_{net} + E_{cont}$ of all\nthe K sampled nodes and combines them to capture deep feature interactions.\nWe implement the aggregation model using BiLSTM. The overall aggregation\nfunction can be formulated as follows:\n$F_{ag}^m = \\frac{\\sum_{v \\epsilon K(v)}[LSTM\\{E_v\\} + LSTM\\{E_v\\}]}{K},$    (2)"}, {"title": "3.2 Approach-II: LogSHIELD with FDA", "content": "LogSHIELD with FDA uses the same modules of approach-I for graph construc-\ntion, neighbor sampling, and log parsing as presented in Section 3.1 and shown\nin steps 1 and 2 in Figure 5.\nIn this approach, step 3 performs a frequency domain analysis on the sampled\nnodes to extract the semantic features of the sampled graph nodes. Let's consider\nthere are N nodes in the graph and we sample N(v) neighbor nodes of the node\nv. The sampled neighbor set V can be represented as $V = [v_1, v_2,\u2026\u2026, v_m]$,\nwhere m is the number of fields in each log.\nWe perform Discrete Fourier Transformation (DFT) on the N nodes of the\ngraph and N neighbor samples for each node in N. Considering the N samples as\nthe window length, we obtain the frequency domain features using the following\nequation.\n$F_{ik} = \\sum_{n=1}^{N} x_{kn} e^{-\\frac{2\\pi(n-1)(k-1)}{N}}   (1 < k <N),$   (3)\nwhere $k \\in [1 : N]$ which is $k^{th}$ window frequency component of $\\frac{2\\pi(k-1)}{N}$. The\nfrequency domain features $F_{ik} = a_{ik} + jb_{ik}$, are complex numbers and need to\ntransform into real numbers for further clustering.\n$a_{ik} = \\sum_{n=1}^{N} X_{kn} COS \\frac{2\\pi(n-1)(k-1)}{N}$    (4)\n$b_{ik} = \\sum_{n=1}^{N} -X_{kn} sin \\frac{2\\pi (n-1)(k-1)}{N}$"}, {"title": "3.3 Anomaly Detection: Statistical Clustering", "content": "We design an unsupervised statistical clustering algorithm to learn the pattern\nof log neighbor features in both Approach-I and Approach-II. This is step 4\nin both Figure 1 and Figure 5. Conventional clustering algorithms like k-means\nclustering and other similar methods are not suitable because of the initialization\nof cluster centers and the number of clusters k. Therefore, in the detection phase,\nwe cluster the node embeddings {$R_1, R_2, R_3, ...R_N$} using a custom clustering\nalgorithm. We used a cosine-similarity-based log clustering algorithm to cluster\nsystem logs and identify malicious activity. We train the clustering algorithm\nwith the benign dataset. Each node embedding $x_i$ from approach-I or feature\nvector $R_i$ from approach-II where $i \\in N$, is assigned to a cluster using their\ncosine similarity. $C_{ne}$ clusters are achieved where $n_e$ is the number of clusters.\nIf $R_N$ is a set of all log feature vectors and $\\delta$ is a similarity threshold cluster-\ning. It calculates the cosine similarity between two embedding vectors to identify\ncluster members. The clustering process satisfies the following conditions to ob-\ntain clusters {$C_1, C_2,...C_{n_c}$}.\n$\\forall e_x \\epsilon C_1, \\forall e_y \\epsilon C_1, sim(e_x, e_y) \\geq \\delta \\\\ \\forall e_z \\forall e_z \\epsilon S \\backslash C_1, sim(e_x, e_z) < \\delta$  (9)\nwhere $S \\backslash C_1$ is the difference between the two sets. We find the closest cluster\ncenter for each embedding or feature vector and calculate the averaged L2-norm\nrepresenting the training loss.\n$loss_{train} = \\frac{1}{N} \\sum_{i=1}^{N} ||R_i - \\hat{C}||^2$ (10)\nIn the detection phase, the clustering module calculates the distance between\nthe FDA feature of test data sample $R_i$ and the benign cluster centers. The\nclosest cluster center is an estimated cluster of $R_i$ and calculates the L2-norm\nas the prediction loss. If the estimation loss is higher than the training loss the\nlog embedding and feature vector are considered malicious.\n$loss_{test} = min(||R_i \u2013 \\hat{C}||^2),$  (11)\nwhere $\\hat{C}$ is the assigned cluster for each vector."}, {"title": "4 Experimental Evaluation", "content": "In this section, we evaluate the effectiveness of the LogSHIELD framework and\nits components in anomaly detection. In addition, we measure the performance\nof different design parameters. We also perform a thorough ablation study to\ncompare the performance of LogSHIELD with its variants."}, {"title": "4.1 Experimental Setup", "content": "LogSHIELD consists of ~8.1k lines of python code and is deployed on a server\nwith Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz CPU (20 processors) and\n48GB memory."}, {"title": "4.2 Dataset", "content": "To evaluate the proposed anomaly detection framework, we use two real-world\nhost datasets. The first dataset is a benign host dataset and the second dataset\nis a malware dataset with 140 malware sample logs we collected in this work.\nThreat Model LogSHIELD endeavors to develop a module for detecting ab-\nnormal activities based on host data. We consider only host logs from individual\nuser spaces. As the log resources can be manipulated, the integrity of the host\nlog is out of the scope of this paper and assumes the host logs can be trusted.\nDue to data limitations, the system environment is limited to Windows OS for\nbenign and malware data samples. The detection system of LogSHIELD is not\nexposed to any malware data for training and is trained using completely benign\ndata samples. This means that LogSHIELD should be able to detect zero-day\nattacks. For model evaluation and testing, we collected logs for 140 malware\nsamples of 6 malware families (Ransomware, Rootkit, Trojan, Adware, Back-\ndoor, and Browser Hijack)."}, {"title": "4.3 Train and Test Datasets", "content": "LogSHIELD is trained in an unsupervised manner with subsets of the benign\ndataset. The LogGNN embedding model of LogSHIELD approach-I is trained\nwith 35 users' 7 days of benign data (60M of Benign Logs). The detection models\nof both approach-I and approach-II are trained with 90 days of benign data with\n774M of logs.\nTo represent the real scenario where malware activities coincide with benign\nhost activities, both approaches of LogSHIELD are evaluated on a malware\ndataset having around 50% Benign logs (370K). Besides the 50% benign data,\neach malware log with (a 15-minute execution) also contains some benign logs."}, {"title": "4.4 LogSHIELD Implementation Details", "content": "The components of the LogSHIELD framework both approach-I and approach-\nII, including log pre-processing and parsing, graph embedding model LogGNN,\nFDA feature extraction, and downstream clustering models are implemented in\nPytorch[15] and the source code will be available soon.\nHop Count and Sample Size: Node sampling in the LogGNN graph em-\nbedding model is implemented with 3 \u2013 hop Random Walk with Restart(RWR)\nand sampled neighbor size is selected K = 40 based on parameter tuning experi-\nments presented in Section 4.9 to obtain the optimal semantics of the neighboring\nnodes.\nToken Numbers: In the word2vec log encoding model we set a token size of 5\nfrom the most frequently seen fields out of a total of 1,200 unique fields of the\ntraining data to obtain the parameter value vectors.\nWord Embedding Dimension: The embedding dimension is set to e = 100\nwhich is determined based on a separate experiment performed with different\nembedding dimensions presented in Section 4.9. The value of e is passed to the\nFastText model to encode word parameter value vectors to semantic information\nvectors.\nBILSTM Model Deployment: We use the open-source machine learning li-\nbrary Pytorch to build the BiLSTM model. It consists of 2 hidden layers each\nlayer having 64 and 32 units. The input dimension is 100. The ReLU activation\nfunction and the mean absolute error (MAE) loss function is used to train the\nembedding model for 100 epochs. All the model training and testing were per-\nformed using an NVIDIA A100 GPU server with 40GB of memory. We set the\nminibatch size to 128, and the learning rate to 0.0015.\nSimilarity Threshold: The similarity threshold $\\delta$ between two node embedding\nor FDA feature vectors is set to 0.72 for optimal clustering performance. A value\nof $\\delta$ between 0 to 0.5 outputs a large number of clusters whereas $\\delta$ between 0.8\nto 1 gives a small number of clusters missing many suspicious clusters.\nDFT Window Size: In the FDA module the sliding window size of the DFT\nis set to the number of RWR sampled neighbors $N = 40$."}, {"title": "4.5 LogSHIELD Detection Performance", "content": "We perform an anomaly detection experiment to detect malware logs that are\nnever exposed during training. The detection models are trained with benign\ndata only as summarized in Table 2. We evaluate the detection performance in\nterms of Accuracy, Precision, Recall, and F-Score. We also use TPR, FPR, and\nthe area under the ROC curve (AUC) to measure LogSHIELD performance.\nLogSHIELD anomaly detection performance is evaluated across 6 malware\nfamilies, including Ransomware, Rootkit, Trojan, Adware, Backdoor, and Browser\nHijacker. LogSHIELD demonstrated outstanding detection performance for most\nmalware families. Approach-I using LogGNN embedding, achieved an average\nAUC of 98%, a TPR of 0.98, and an FPR of 0.038, while Approach-II showed"}, {"title": "4.6 LogSHIELD Performance Comparison with Baselines", "content": "We performed another study to evaluate LogSHIELD detection AUC, detection\ntime, and throughput in comparison with the other five baseline anomaly detec-\ntion models (Log2vec, DeepLog, Unicorn, LogRobust, and DeepRan). According\nto results presented in Table 4, LogSHIELD with LogGNN embedding outper-\nforms the baseline models in terms of detection performance and achieves 98%\nAUC but the detection time of LogSHIELD with LogGNN is similar to baseline\nmodels. Whereas LogSHIELD with FDA achieves an AUC of 96% which is higher\nthan most of the baseline models. It achieves an anomaly detection time of 0.13\nseconds which is significantly less than LogSHIELD with LogGNN and other\nstate-of-the-art models. Frequency domain analysis on the provenance graph of\nhost data in approach-II effectively extracts graph representation with signifi-\ncantly less computation than approach-I. Therefore, approach-II, LogSHIELD\nwith FDA significantly outperforms most of the baseline models and takes a\nsmall fraction of the detection time of the other models. As FDA uses DFT fre-\nquency analysis for log feature extraction replacing deep graph neural network-\nbased (LogGNN), it has less computational overhead. Therefore, LogSHIELD\nwith FDA can provide real-time detection in an enterprise network."}, {"title": "4.7 Detection Latency and Throughput", "content": "We conduct experiments on a fused dataset of malware data and 25% of the\nlarge benign dataset. The model is trained with the remaining 75% benign\ndata. We measure the anomaly detection time and throughput of the detec-\ntion model using both approach-I and approach-II. The results are shown in\nTable 4. LogSHIELD with FDA performs significantly better than LogSHIELD\nwith LogGNN. Approach-I with LogGNN can detect malware events with an av-\nerage detection time of 1.67 seconds whereas approach-II with FDA can detect\nwith an average detection time of 0.13 seconds. The higher computation overhead\nof LogGNN is one of the main reasons for the higher detection time of approach-\nI. In terms of throughput, Approach-II achieves 11.3 times higher throughput\nthan approach-I with LogGNN. We find that LogSHIELD with FDA achieves\nan average throughput of 5.1 Gbps whereas with the LogGNN graph learning\nmodel, it achieves 0.45 Gbps. In summary, the results show that the frequency\nanalysis model slightly suffers from detection AUC but significantly outperforms\nmachine learning-based models in terms of detection time and throughput. The\nthroughput of the baseline models is not calculated and compared."}, {"title": "4.8 Ablation Analysis", "content": "We perform an ablation study using benign and malware datasets to evalu-\nate different functional modules of LogSHIELD in anomaly detection. In this\nstudy, we present the significance of RWR node sampling, log graph represen-\ntation learning method LogGNN, and FDA in the overall detection framework\nas shown in Table 5. In different combinations, we obtain seven ablation mod-\nels. All the ablation models are trained with 35 users' benign data only and\nevaluated with the malware dataset. We use the same provenance graph con-\nstructed in previous experiments for all the models. According to the results,\nLogSHIELD\u00b9 and LogSHIELD\u00b2 differ on the neighbor sampling and it shows\nthat LogSHIELD\u00b9 significantly outperforms LogSHIELD\u00b2 with AUC of 0.98\nand 0.89 respectively as it has the 3-hop neighbor information contributing to\nsemantic node feature extraction. The latter model has less computation time."}, {"title": "4.9 LogSHIELD Parameter Performance", "content": "LogSHIELD performance depends on some key design parameters such as RWR\nwalk length, number of hops for node sampling, LogGNN embedding dimension,\netc. To evaluate the significance of the design parameters and find the optimal\nvalue we measure the preset performance metrics in different settings. We exper-\niment with random-walk lengths ranging from 10 to 60 with a hop count of 3 as\nshown in Figure 6a. We observe that initially at walk length 10, AUC, Precision,\nRecall, and F-Score all are very low and gradually increase with higher walk\nlength as more neighbors contribute to the semantic feature of the target node.\nAt a walk length of 40, all the scores reach higher than 0.96 and start gradually\ndecaying at later values. Similar behavior is observed for hop count. We measure\nperformance metrics with hop counts ranging from 1 to 6. At a hop count of\n3, LogSHIELD performs with the highest AUC of 0.98 and starts decaying at\nhigher hop counts. The reason for decaying at a higher hop count could be the\nover-aggregation of unrelated neighbors to target node semantics.\nWe also measure the model performance with LogGNN embedding dimen-\nsions ranging from 25 to 150. The results in Figure 6c show that the model"}, {"title": "5 Conclusion", "content": "In this paper, we propose a provenance graph-based real-time anomaly detec-\ntion framework LogSHIELD. We present two graph representation learning ap-\nproaches using the LogGNN model and FDA frequency analysis for real-time\nanomaly detection to reduce the computational overhead and improve the effi-\nciency of the detection model. LogSHIELD with LogGNN achieves 98% average\ndetection AUC whereas with FDA it achieves 96% AUC. On the other hand,\nLogSHIELD with FDA takes 0.13 seconds for detection time whereas LogGNN\ntakes 1.67 seconds. It also outperforms baseline models with higher detection\nAUC and lower detection time. Frequency analysis of host logs with FDA signif-\nicantly benefits the design of a real-time anomaly detection framework. Accord-\ning to results in Table 5, the novel approach LogSHIELD with RWR and FDA\nsignificantly improves anomaly detection efficiency and facilitates real-time de-\ntection. A key challenge for LogSHIELD is the preprocessing of high-volume host\ndata and the construction of graphs for detecting advanced persistent threats.\nIn the future, we plan to further analyze the host data to reduce detection time\nand incorporate more real-host cyber activity. This will allow us to experiment\nwith additional hosts and evaluate the scalability of the framework."}]}