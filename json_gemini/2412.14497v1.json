{"title": "Treatment Effects Estimation on Networked Observational Data using Disentangled Variational Graph Autoencoder", "authors": ["DI FAN", "RENLEI JIANG", "YUNHAO WEN", "CHUANHOU GAO"], "abstract": "Estimating individual treatment effect (ITE) from observational data has gained increasing attention across various domains, with a key challenge being the identification of latent confounders affecting both treatment and outcome. Networked observational data offer new opportunities to address this issue by utilizing network information to infer latent confounders. However, most existing approaches assume observed variables and network information serve only as proxy variables for latent confounders, which often fails in practice, as some variables influence treatment but not outcomes, and vice versa. Recent advances in disentangled representation learning, which disentangle latent factors into instrumental, confounding, and adjustment factors, have shown promise for ITE estimation. Building on this, we propose a novel disentangled variational graph autoencoder that learns disentangled factors for treatment effect estimation on networked observational data. Our graph encoder further ensures factor independence using the Hilbert-Schmidt Independence Criterion. Extensive experiments on two semi-synthetic datasets derived from real-world social networks and one synthetic dataset demonstrate that our method achieves state-of-the-art performance.", "sections": [{"title": "1 INTRODUCTION", "content": "Currently, research on causal effects between different variables has received increasing attention. Among these, learning individual treatment effects of a treatment on an outcome is a fundamental question encountered by numerous researchers, with applications spanning various domains, including education [12], public policy [4], economics [15, 57], and healthcare [42]. For example, in the medical scenario, physicians seek to determine which treatment (such as which medication) is more beneficial for a patient's recovery [52]. This naturally raises a question: how can we accurately infer outcome if an instance were to receive an alternative treatment? This relates to the well-known problem of counterfactual outcome prediction [36]. By predicting counterfactual outcomes, we can accurately estimate each individual's treatment effect, known as individual treatment effect (ITE) [40, 42], thereby assisting decision-making.\nRandomized controlled trials (RCTs) are the gold standard method for learning causal effects [36]. In these trials, instances (experimental subjects) are randomly assigned to either the treatment or control group. However, this is often costly, unethical, or even impractical [16, 54]. Fortunately, the rapid increasing expansion of big data in many fields offers significant opportunities for causal inference research [51, 54], as these observational datasets are readily available and usually contain a large number of examples. Thus, we often concentrate on estimating treatment effects from observational data. Additionally, instances in the dataset are intrinsically linked by auxiliary"}, {"title": "2 RELATED WORK", "content": "Two aspects of related work are introduced in this section: (2) learning ITE from networked observational data; and (3) disentangled representations for treatment effect estimation.\nLearning ITE from i.i.d observational data. Due to the substantial expenses and sometimes infeasi-bility of randomized experiments, there has been significant interest in estimating individual-level causal effects from observational data in recent years, especially with the emergence of big data. BART [9] employed dimensionally adaptive random basis functions for causal effect estimation. Causal Forest [50] is a nonparametric approach that extends Breiman's random forest algorithm to estimate heterogeneous treatment effects. CFR [42] is a representation learning approach that predicts ITE from observational data by projecting original features into a latent space, capturing confounders through minimization of prediction error in factual outcomes and reducing imbalance between treatment and control groups. However, the existing methods that have been previously mentioned depend on the strong ignorability assumption, which essentially ignores the effects of hidden confounding factors and is usually untenable in real-world observational studies. Various approaches have been suggested to relax this strong ignorability assumption. CEVAE [33] followed the causal structure of inference with proxy variables, capable of simultaneously estimating the unknown latent space summarizing confounders and the causal effect. Deep-Treat [3] employed a bias-removing autoencoder, along with a policy optimization feedforward neural network to derive balanced representations and optimal policies from observational data. SITE [55] captured hidden confounders for individual treatment effect estimation through a local similarity-preserving method.\nLearning ITE from networked observational data. Recently, the emergence of networked observa-tional data in various real-world tasks has prompted several studies to relax strong ignorability assumption by utilizing network information among different instances, where the network also serves as a proxy for unobserved confounders. NetDeconf [19] utilized network information and ob-served features to identify patterns of hidden confounders, enabling the learning of valid individual causal effects from networked observational data. CONE [18] further employed Graph Attention Networks (GAT) to integrate network information, thereby mitigating hidden confounding effects. IGNITE [17] introduced a minimax game framework that simultaneously balances representations and predicts treatments to learn ITE from networked observational data. GIAL [10] leveraged network structure to capture additional information by identifying imbalances within the network for estimating treatment effects. Thorat et al. [46] utilized network information to mitigate hidden confounding bias in the estimation of ITE under networked observational studies with multiple treatments. However, these studies uniformly apply all feature information, including network information, to infer latent confounding factors without assuming disentanglement in treatment effect estimation, which may lead to estimation bias. In a network, the treatment administered to one instance may influence the outcomes of its neighbors. This phenomenon is known as spillover effects or interference [2, 22, 37]. Unlike previous works, we follow the assumption by Guo et al. [19] and Veitch et al. [47] that conditioning on potential confounders separates each individual's treatment and outcome from those of others. We will further explore the study of spillover effects as future work."}, {"title": "3 PRELIMINARIES", "content": "In this section, we first introduce the notations used in this article. We then outline the problem statement by providing the necessary technical preliminaries.\nNotations. Throughout this work, we use unbold lowercase letters (e.g., t) to denote scalars, bold lowercase letters (e.g., x) to represent vectors, and bold uppercase letters (e.g., A) for matrices. The (i, j)-th entry of a matrix A is denoted by $A_{ij}$.\nNetworked observational data. In the network observational data, we define the features (covariates) of i-th instance as $x_i \\in \\mathbb{R}^k$, the treatment as $t_i$, and the outcome as $y_i \\in \\mathbb{R}$. We assume that all instances are connected through a network, represented by an adjacency matrix A. We assume that"}, {"title": "4 METHODOLOGY", "content": "In this section, we will first present a theorem on the identifiability of the individual treatment effect. Then, we introduce our TNDVGA framework designed to learn from networked observational data.\n4.1 Identifiability\nWe introduce the model TNDVGA for estimating treatment effects, based on the assumption that the observed covariates x and the network patterns A can be regarded as generated from four distinct sets of latent factors $z = (z_t, z_c, z_y, z_o)$. In this context, $z_t$ represents latent instrumental factors that influence the treatment but not the outcome, $z_c$ includes latent confounding factors (latent"}, {"title": "5 EXPERIMENTS", "content": "In this section, we perform a series of experiments to illustrate the effectiveness of the proposed TNDVGA framework. We first introduce the datasets, evaluation metrics, baselines, and model parameter configurations utilized in the experiments. Then, we compare the performance of different models in estimating ITE. After that, we conduct an ablation study to evaluate the importance of key components in the TNDVGA and conduct a hyperparameter study.\n5.1 Datasets\n5.1.1 Semi-synthetic datasets.\nBlogCatalog. In the BlogCatalog dataset [45], a social blog directory for managing bloggers and their blogs, each individual represents a blogger, and each edge represents a social connection between two bloggers. The features are represented as a bag-of-words representation of the keywords in the bloggers' descriptions. To generate synthetic outcomes and treatments, we rely on the assumptions outlined in [19, 47]. The outcome y refers to the readers' opinion of each blogger, and the treatment t represents whether the blogger's content receives more views on mobile devices or desktops. Bloggers whose content is primarily viewed on mobile devices are placed in the treatment group, while those whose content is mainly viewed on desktops are placed in the"}, {"title": "6 CONCLUSION AND FUTURE WORK", "content": "This paper aims to improve the accuracy of individual treatment effect estimation from networked observational data by modeling disentangled latent factors. The proposed model, TNDVGA, leverages observed features and auxiliary network information to infer and disentangle four distinct sets of latent factors: instrumental, confounding, adjustment, and noise factors. Empirical results from extensive experiments on several semi-synthetic and one synthetic dataset demonstrate that TNDVGA outperforms existing state-of-the-art methods in estimating ITE from networked observational data.\nTwo promising directions for future work are worth exploring. First, we would like to extend TNDVGA to estimate treatment effects for multiple or continuous treatments, which would enhance its applicability to a wider range of real-world scenarios. Second, we are interested in further investigating ITE estimation under network interference within a generative model framework that employs variational inference."}, {"title": "4.1 Identifiability", "content": "We introduce the model TNDVGA for estimating treatment effects, based on the assumption that the observed covariates x and the network patterns A can be regarded as generated from four distinct sets of latent factors $z = (z_t, z_c, z_y, z_o)$. In this context, $z_t$ represents latent instrumental factors that influence the treatment but not the outcome, $z_c$ includes latent confounding factors (latent"}, {"title": "4.2 The proposed framework: TNDVGA", "content": "An overview of the proposed framework, TNDVGA, is shown in Fig. 2, which learns individual treatment effects through networked observational data. The proposed framework consists of the following important components: (1) Learning Disentangled Latent factors through Variational Graph Autoencoder (VGAE); (2) Predicting Potential Outcomes and Treatment Assignments; (3) Enforcing Independence of Latent factors. We will provide a detailed explanation of these four components in the following sections.\n4.2.1 Learning Disentangled Latent factors through VGAE. From the theoretical analysis in the previous section, we have seen that eliminating unnecessary factors is essential to effectively and accurately estimating the treatment effect. However, in practice, we do not know the mechanism of generating x from z and the mechanism of disentangling z into different disjoint sets. This requires us to propose a method that can learn to disentangle the latent factors z and estimate ITE through what the model has learned. Therefore, we aim to infer the posterior distribution $p_{\\theta}(z | x, A)$ of latent factors z through the observed proxy covariates x and network information A, while disentangling z into latent instrumental factors $z_t$, confounding factors $z_c$, adjustment factors $z_y$, noise factors $z_o$. Since exact inference is intractable, we use the variational inference framework to approximate the posterior distribution with the tractable distribution. We adopt Variational Graph Autoencoders (VGAEs) to construct our model. Proposed by Kipf and Welling [28], VGAEs extend Variational Autoencoders (VAEs) to take into consideration the graph structure in the data. For every observed variable x, VGAEs define a multi-dimensional latent variable z. Moreover, VGAEs rely on an adjacency matrix A, which is utilized by the Graph Neural Network (GNN) in the encoder to enforce the structure of the posterior approximation $q_{\\phi}(z | x, A)$. As shown in Fig. 2, we use four separate encoders to approximate the variational posterior $q_{\\phi_t}(z_t | x, A)$,"}, {"title": "4.3 Loss Function of TNDVGA", "content": "In this section, we design a loss function that combines all the key components of ITE estimation, thereby facilitating the end-to-end training of disentangled latent factor representations.\n4.3.1 Loss for VGAE. The encoder and decoder parameters can be learned by minimizing the negative evidence lower bound (ELBO), consistent with the standard VGAE [28], where i denotes the i-th instance:\n$L_{ELBO}(x_i, t_i, y_i) = \\mathbb{E}_{q_{\\phi_t}, q_{\\phi_c}, q_{\\phi_y}, q_{\\phi_o}} [log \\mathbb{P}_{\\theta_x}(x_i | z_{t,i}, z_{c,i}, z_{y,i}, z_{o,i}) + log \\mathbb{P}_{\\theta_t}(t_i | z_{t,i}, z_{c,i}) + log \\mathbb{P}_{\\theta_y}(y_i | t_i, z_{c,i}, z_{y,i})] - D_{KL}(q_{\\phi_t}(z_{t,i} | x_i, A)||p(z_{t,i})) - D_{KL}(q_{\\phi_c}(z_{c,i} | x_i, A)||p(z_{c,i})) - D_{KL}(q_{\\phi_y}(z_{y,i} | x_i, A)||p(z_{y,i})) - D_{KL}(q_{\\phi_o}(z_{o,i} | x_i, A)||p(z_{o,i})).$\n4.3.2 Loss for Potential Outcome Prediction and Treatment Assignment Prediction. The factual loss function for predicting potential outcomes, along with the loss function for predicting treatment assignments, is defined as follows:\n$L_{treat}(t_i, z_{t,i}, z_{c,i}) = - \\mathbb{E}_{q_{\\phi_t}, q_{\\phi_c}}(q_{\\eta_t}(t_i | z_{t,i}, z_{c,i})),$\n$L_{pred}(t_i, y_i, z_{c,i}, z_{y,i}) = - \\mathbb{E}_{q_{\\phi_c}, q_{\\phi_y}}(q_{\\eta_y}(y_i | t_i, z_{c,i}, z_{y,i})).$\n4.3.3 Loss for HSIC Independence Regularizer. We apply pairwise independence constraints to the latent factors $z_t, z_c, z_y$, and $z_o$ in order to improve the statistical independence between disentangled representations. Thus, the HSIC regularizer $L_{reg}$ is calculated as follows:\n$L_{indep}(z_{t,*}, z_{c,*}, z_{y,*}, z_{o,*}) = \\sum_{k,m\\in\\{t,c,y,o\\}\\\\k \\neq m} HSIC(z_{k,*}, z_{m,*}).$\n4.3.4 Loss for Balanced Representation. As shown in Fig. 1, we observe that $z_y \\amalg t$, implying that $p(z_y | t = 0) = p(z_y | t = 1)$. Therefore, following the approach in [21], we aim for the learned $z_y$ to exclude any confounding information, ensuring that all confounding factors are captured within $z_c$. This is crucial for ensuring the accuracy of the treatment effect estimation. To quantify the discrepancy between the distributions of $z_y$ for the treatment and control groups, we use the integral probability metric (IPM) [19, 34, 44]. We define the balanced representation loss as $L_{disc}$,\n$L_{disc}(z_{y,*}) = IPM(\\{z_{y,i}\\}_{i:t_i=0}, \\{z_{y,i}\\}_{i:t_i=1}).$\n4.3.5 The Overall Objective Function. The following provides a summary of the overall objective function for TNDVGA:\n$L_{TNDVGA} = \\frac{1}{n} \\sum_{i=1}^n [L_{ELBO}(x_i, t_i, y_i) + \\alpha_t L_{treat}(t_i, z_{t,i}, z_{c,i}) + \\alpha_y L_{pred}(t_i, y_i, z_{c,i}, z_{y,i})] + \\lambda_1 L_{indep}(z_{t,*}, z_{c,*}, z_{y,*}, z_{o,*}) + \\lambda_2 L_{disc}(z_{y,*}) + \\lambda ||\\Theta||_2^2,$"}]}