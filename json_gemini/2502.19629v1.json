{"title": "Deep Equilibrium Networks", "authors": ["Shaojie Bai", "J. Zico Kolter", "Vladlen Koltun"], "abstract": "We propose Deep Equilibrium Networks (DEQs), a novel approach to deep learning that eschews the traditional layer-by-layer architecture in favor of directly computing the equilibrium point of a single layer.  Specifically, a DEQ defines a layer as a fixed-point iteration, with the forward pass involving finding a solution $z^\u2217 = f(z^\u2217, x)$ for each input $x$, where $f$ is any function.  While at first glance this formulation may seem intractable, we show that fixed-point iterations can in fact be efficiently solved via root-finding algorithms.  Moreover, we show that DEQs can perform competitively with standard deep networks (including ResNets) on image classification tasks such as MNIST, CIFAR-10, and a character recognition task, while also demonstrating several appealing benefits: they have extremely small memory footprints, possess implicit regularization due to the unique training procedure, are robust to the choice of equilibrium solver, and have the potential to efficiently process variable-length data due to their iterative nature.  Finally, we also analyze DEQs from a theoretical perspective, showing that they represent an infinite-depth network with weight tying, and that we can even compute implicit gradients from the equilibrium point without backpropagation.", "sections": [{"title": "1 Introduction", "content": "Despite its tremendous successes, deep learning still faces significant challenges.  For instance, training deep neural networks is often memory intensive, as it requires storing the activations at all intermediate layers for use in backpropagation.  The number of layers in typical neural networks is also often fixed at design time, and changing the number of layers requires re-training of the entire model.  These issues have recently led researchers to consider models that can be seen as infinitely deep networks, a perspective that can potentially address both the memory and flexibility constraints of typical deep networks.  These infinitely deep networks include Deep Equilibrium Models, where the forward pass of each layer requires finding a fixed point to be useful, and other methods based on Neural ODEs, where the gradient in each layer is computed via numerical solvers.  Both of these approaches have appealing properties from the perspective of memory constraints or variable data length, but both also involve additional computational burdens (specifically, solving a fixed-point equation or a numerical differential equation for each layer).  In this paper, we introduce a novel Deep Equilibrium Network (DEQ) model that aims to combine the best characteristics of both these lines of work.  Like Deep Equilibrium Models, the DEQ eschews the traditional layer-by-layer architecture in favor of computing a fixed point.  Specifically, a DEQ defines a layer as a fixed-point iteration, such that the forward pass involves finding a solution $z^\u2217 = f(z^\u2217, x)$ for each input $x$, where $f$ is any function.  A DEQ is a single layer, an infinite depth model where the memory needed for the forward pass is tiny.  Also, thanks to the implicit gradients used for training, training DEQs is often faster than training ordinary deep networks.  Unlike Neural ODEs, DEQs do not require numerical ODE solvers for the forward pass, and unlike both Deep Equilibrium Models and Neural ODEs, we show that DEQs can be efficiently solved via root-finding algorithms.  Furthermore, we demonstrate several additional appealing benefits of DEQs: they possess implicit regularization that leads to more robust performance, they are robust to the choice of equilibrium solver, and they have the potential to efficiently process variable-length data due to their iterative nature.  Finally, we also analyze DEQs from a theoretical perspective, showing that they represent an infinite-depth network with weight tying, and that we can even compute implicit gradients from the equilibrium point without backpropagation.  In Section 2 we present a review of related works on infinitely deep neural networks.  Section 3 then formalizes the concept of DEQs and their properties.  Sections 4 and 5 presents experimental validations of the performance of DEQs on a number of image classification tasks and analyses of their performance, respectively.  Section 6 discusses the performance variations and limitations of our approach, and finally Section 7 concludes."}, {"title": "2 Related Work", "content": "The goal of this section is to provide a brief overview of the two major classes of methods that our work attempts to combine and improve upon.  As such, this section is neither intended to be complete nor exhaustive, and instead attempts to provide a high-level overview of the most relevant aspects.  \nInfinitely Deep Neural Networks.  A number of recent papers have considered various forms of infinitely deep neural networks [5, 6, 9, 18].  E and Yao [6] considered the class of infinitely deep ReLU networks, and provided an analysis that related these networks to Gaussian processes (GPs) in the limit of infinite width.  As part of their derivation, they argued that their analysis can also be used to describe infinitely deep networks with a similar structure.  However, that work only analyzed infinitely deep models at initialization, and did not address the challenges of training such a model.  More recently, Haber et al. [9] proposed Stable Equilibirum Point Networks (L-Deep Nets), a model that resembles both ResNets and Equilibrium Models.  The key idea is to define the activation of each layer via a fixed-point equation, but unlike L-Deep Nets, the fixed-point equation is solved only for the forward pass, and backpropagation is still used to learn the parameters.  More recent works have also proposed approaches based on the numerical solution of ordinary differential equations (ODEs) [4, 23], and have shown that deep networks can be seen as a discretization of a continuous transformation.  One notable benefit of ODE-based models is that their memory footprint is constant with respect to depth, since it is not necessary to store the activations of all intermediate layers for backpropagation.  Finally, another recent work by W and Chen [19] attempts to combine ideas from both infinite-depth ResNets and the ODE-based approach, and shows how to approximate deep ResNets with a few parameters using a numerical ODE solver.  \nImplicit Layers.  The idea of defining layers implicitly has been well-studied in a number of settings.  For instance, interior point methods for solving constrained optimization problems can often be seen as implicitly defined layers [2].  The specific model we consider is also strongly related to the class of equilibrium models [1, 12, 16, 17].  The key idea in equilibrium models is to define each layer as a fixed point; i.e., for each layer with input $x$ the output $z$ must satisfy $z = f(z, x)$ for some function $f$.  This formulation has a number of potential benefits, including memory efficiency and the ability to process variable-length data.  The primary obstacle to the use of equilibrium models is that, in general, it is necessary to solve a fixed-point problem for each layer, which can be computationally expensive.  One approach to training implicit layers has been to use chain-rule differentiation through the fixed-point equation [1, 17]; i.e., if the layer input/output $(x, z)$ satisfies $z = f(z, x)$, then we have $\\frac{dz}{dx} = \\frac{\\partial f}{\\partial z} \\frac{dz}{dx} + \\frac{\\partial f}{\\partial x}$.  \nWith sufficient conditions on $f$, one can then obtain $\\frac{dz}{dx}$ via the solution of a linear system.  Alternatively, methods such as automatic differentiation [22] can be used.  The primary benefit of either implicit differentiation or automatic differentiation is that the memory footprint is constant with respect to depth.  Finally, another relevant work in this area is the model of Terry and Nowlan [16], which learns a two-layer recurrent network that has strong connections to our proposed approach, and we will detail this connection later on."}, {"title": "3 Deep Equilibrium Networks", "content": "In this section, we formally present the concept of a Deep Equilibrium Network (DEQ), and outline both the forward pass and backward pass (training) of the DEQ.  \nWe begin with a brief overview of some preliminary notation.  Let $x \u2208 \\mathbb{R}^{n_x}$ be the input, and let $f : \\mathbb{R}^{n_z} \\times \\mathbb{R}^{n_x} \\rightarrow \\mathbb{R}^{n_z}$ be an arbitrary function.  We will use $\\partial f$ to refer to partial derivatives of $f$ with respect to its arguments.  Throughout the paper, we will use $z$ to refer to the activation (or hidden state) of the layer, and $z^\u2217$ will denote the fixed-point equilibrium.\n3.1 The Forward Pass\nIn a DEQ, we aim to find a $z^\u2217 \u2208 \\mathbb{R}^{n_z}$ such that $z^\u2217 = f(z^\u2217, x)$,  (1)\nIn other words, the forward pass of a DEQ model involves finding the root of an equation.  At first glance, this fixed-point formulation may seem intractable, because it is not obvious how to efficiently solve for $z^\u2217$ given $f$ and $x$.  For instance, it is not immediately obvious how to apply gradient-based optimization to Eq. (1) to solve for $z^\u2217$.  However, we will argue that, in fact, root finding can be solved very efficiently for the case of Eq. (1) via the simple iterative approach of fixed-point iteration: $z_{k+1} = f(z_k, x)$,\n (2)\nIn other words, we simply iterate the function $f$ until convergence.  Clearly, the behavior of such an iterative approach will depend strongly on the function $f$, and specifically whether $f$ is contractive.  In practice, however, we find that Eq. (2) often converges fairly quickly, particularly with the addition of an acceleration scheme such as Anderson Acceleration [3].  Specifically, Anderson Acceleration (AA) can be seen as a generalization of iterative acceleration techniques such as Polyak\u2019s momentum method [11] and heavy-ball method [21].  The key idea is to use a linear combination of past iterate values, rather than just the most recent, to accelerate convergence.  We will use AA for the remainder of the paper, but note that in principle any root-finding algorithm can be used.  Details of the AA algorithm are presented in Algorithm 1.  \nAlgorithm 1: Deep Equilibrium Network (DEQ) Layer Forward Pass\nInput: Input $x$, function $f$, Anderson mixing rank $m$, maximum iterations $K$\nInitialize: $z_0 \u2190 0, H \u2190 [] \u2208 \\mathbb{R}^{m \\times n_z}, F \u2190 [] \u2208 \\mathbb{R}^{m \\times n_z}$\nfor $k = 1, 2, . . . , K$ do\n$v_k \u2190 f(z_{k\u22121}, x)$ # Evaluate the function\nif $k > m$ then # Update the history H, F\n$H \u2190 H \\backslash h_{k\u2212m}$ # Remove the oldest record\n$F \u2190 F \\backslash f_{k\u2212m}$\nend\n$h_k \u2190 z_{k\u22121} \u2212 v_k$ # Record the change\n$f_k \u2190 v_k$ # Record current value of f\nAppend $h_k$ to H\nAppend $f_k$ to F\nif $k > m$ then\n$\u03b1 \u2190 (H^T H + \u03bbI)^{\u22121}H^T (F \u2212 H)$ # Evaluate the mixing weights\n$z_k \u2190 \\sum^k_{i=k\u2212m} \u03b1_i f_i$ # Mix the stored iterates\nelse\n$z_k \u2190 v_k$ # If we don\u2019t have a long enough history, just use the standard fixed point iteration\nend\nif  $|z_k - f(z_k, x)| < \u03b5$  then # Check convergence\nreturn $z_k$ # Return the activation\nend\nend\nreturn z_K # Return the last iterate\nSpecifically, at each iteration, Anderson Acceleration stores the $m$ most recent values of both the iterate, $z_k$, and the output of the function being evaluated, $f(z_k, x)$.  It then finds a linear combination of the most recent values of $f(z_k, x)$ that minimizes the distance (in terms of Euclidean norm) to the current iterate.  The algorithm can be summarized as\n$z_{k+1} = \\sum^m_{i=1} \u03b1_i f(z_{k-i}, x)$,    (3)\nwhere the scalars $\u03b1 \u2208 \\mathbb{R}^m$ are solutions to the least squares problem\n$min_\u03b1 || \\sum^m_{i=1} \u03b1_i f(z_{k-i}, x) \u2212 z_k ||^2,  (4)\nNote that Eq. (3) requires the constraint $\\sum \u03b1_i = 1$, but as noted in previous work [3], this constraint can be avoided in practice (and without loss of generality) by subtracting the residuals in Eq. (4), and leads to more robust performance.  \nIn general, Algorithm 1 can be seen as a special case of the Broyden method for solving non-linear equations [20], with some additional updates to improve robustness.  Given Eq. (1) and Algorithm 1, we can then formalize the general DEQ training process in the following subsection."}, {"title": "3.2 The Backward Pass", "content": "The primary obstacle to training DEQs is that the training process typically relies on backpropagation, but Eq. (1) contains no explicit layers to backpropagate through.  Fortunately, we can rely on the implicit function theorem, which states that given $z = f(z, x)$, the total derivative $\\frac{dz}{dx}$ can be written as  $\\frac{dz}{dx} = \u2212(\\frac{\\partial F}{\\partial z})^{\u22121} \\frac{\\partial F}{\\partial x}$, (5)\nwhere $F(z, x) = z \u2212 f(z, x)$.  In other words, we can express the derivative of $z$ with respect to $x$ using only the partial derivatives of $F$, without explicitly backpropagating through all the individual function evaluations in the fixed-point algorithm.  Thus, Eq. (5) is the key to training DEQs.  Specifically, let $L$ be the loss function, and let  $y = L(z(x))$, (6)\ndenote the overall training objective.  By the chain rule, the gradient of $L$ with respect to parameters in the input can then be expressed as  $\\frac{dL}{dx} = \\frac{dL}{dz} \\frac{dz}{dx} = \u2212\\frac{dL}{dz} (\\frac{\\partial F}{\\partial z})^{\u22121} \\frac{\\partial F}{\\partial x}$, (7)\nwhere $\\frac{dL}{dz} \u2208 \\mathbb{R}^{1 \\times n_z}$ can be computed via standard backpropagation through the loss function $L$.  The remaining computations then only involve manipulating the $n_z \\times n_z$ matrix $\\frac{\\partial F}{\\partial z} = I \u2212 \\frac{\\partial f}{\\partial z}$, which can be done relatively efficiently.  Specifically, we can rewrite Eq. (7) as  $\\frac{dL}{dx} = \\frac{dL}{dz} A$, (8)\nwhere A is the solution to the linear system \n$A \\frac{\\partial F}{\\partial z} = \u2212\\frac{\\partial F}{\\partial x}$. (9)\nThus, assuming the cost of evaluating $\\frac{\\partial F}{\\partial z}$ and $\\frac{\\partial F}{\\partial x}$ are not prohibitively high, we can solve Eq. (9) via any conjugate gradient (CG) method.  Moreover, the memory footprint required for training is again constant with respect to depth (i.e., the number of iterations performed by Algorithm 1), as it is not necessary to store any intermediate values from the fixed-point iteration.  We formalize the entire training process in Algorithm 2.\nAlgorithm 2: Deep Equilibrium Network (DEQ) Layer Training\nInput: Data $x$, labels $y$, learning rate $\u03b7$, function $f$, loss $L$, forward pass algorithm\n(Algorithm 1) Forward(f,x), maximum iterations $K$, conjugate gradient (CG) algorithm\nCG(A, b), implicit differentiation iterations $R$\n$z^\u2217 \u2190 Forward(f,x)$ # Compute the equilibrium point via root finding\nCompute loss $L(z^\u2217, y)$ # Compute the loss given the fixed point and labels\n$\\frac{dL}{dz} \u2190 \\frac{\\partial L}{\\partial z}$  # Compute partial derivatives w.r.t. fixed point (backprop)\n# Now we need to find $\\frac{dz}{dx}$ without going through the layers\ndef  $vec(A) \\mapsto A \\frac{\\partial F}{\\partial z}(z^\u2217, x)$   # Define the operator\n$\\frac{dL}{dx} \u2190 \\frac{dL}{dz} CG(\\frac{\\partial F}{\\partial z}, \u2212\\frac{\\partial F}{\\partial x} )$ # Compute by conjugate gradient method\n\u03b8 \u2190 \u03b8 \u2212 \u03b7$\\frac{dL}{dx}$ # Standard gradient descent update\nWhile at first glance this may seem like a fairly complex and unusual training process, in practice we find that DEQs are fairly straightforward to train.  In the following section, we provide some intuition regarding the behavior of DEQs during training, and then demonstrate empirically that DEQs can be trained with standard optimization algorithms to perform competitively with deep networks."}, {"title": "3.3 DEQs as Infinite Depth Nets with Weight Tying", "content": "In order to gain additional intuition regarding the training of DEQs, it is useful to consider the similarities of DEQs to certain forms of infinitely deep networks.  In this section, we show that DEQs can be seen as a special case of an infinitely deep network with weight tying, a construction which is well-studied (see Section 2).  \nTo see this, consider a standard, $L$-layer neural network of the form \n$z_1 = f(x, \u03b8_1);\nz_2 = f(z_1, \u03b8_2);\n\u00b7 \u00b7 \u00b7\\nz_L = f(z_{L\u22121}, \u03b8_L)$, (10)\nwhere $f(\u00b7, \u00b7)$ is some arbitrary function and $\u03b8_l$ are the parameters of each layer.  Let us further consider a network with \u201clayer-wise weight tying\u201d, such that the parameters are identical at each layer; i.e., $\u03b8 = \u03b8_1 = \u00b7 \u00b7 \u00b7 = \u03b8_L$.  The activation of the last layer can then be expressed as  $z_L = f(f(\u00b7 \u00b7 \u00b7f(x, \u03b8)\u00b7 \u00b7 \u00b7, \u03b8), \u03b8),$\n (11)\nwhere the function $f$ is applied $L$ times, and all are evaluated using the same parameters $\u03b8$.  \nNow consider the limit of infinite layers, $L \u2192 \u221e$.  The result is that $z_L$ will converge to the equilibrium point satisfying $z^\u2217 = f(z^\u2217, x; \u03b8)$.  \nIn other words, DEQs can be seen as an infinite-depth neural network with layer-wise weight tying (i.e., evaluated using the same parameters $\u03b8$ for each layer).  Under certain conditions, this fixed point can be uniquely determined via a standard iterative process.  \nThe interpretation of DEQs as an infinite-depth model with weight tying is useful because it suggests that the training process of DEQs can be interpreted as a form of implicit regularization.  Specifically, the fixed-point condition in Eq. (1) can be seen as constraining the space of functions that a DEQ can express, and the training process can be seen as identifying the subset of this function space that generalizes to the training data.  As part of our experiments, we will demonstrate that DEQs, in fact, do seem to exhibit robustness to overfitting, a characteristic that we attribute to this implicit regularization."}, {"title": "3.4 Implicit Differentiation and Memory Complexity", "content": "As previously mentioned, the implicit differentiation we use for training DEQs also has a number of useful memory benefits. Specifically, the implicit function theorem states that given $z = f(z, x)$, the total derivative $\\frac{dz}{dx}$ can be written as  $\\frac{dz}{dx} = \u2212(\\frac{\\partial F}{\\partial z})^{\u22121} \\frac{\\partial F}{\\partial x}$, (12)\nwhere $F(z, x) = z \u2212 f(z, x)$. The key aspect of this formulation is that it is not necessary to perform any \u201cbackpropagation\u201d through $f$. Given this insight, we can now better formalize the memory complexity of backpropagation for a $L$-layer network:\nStandard Deep Nets.  For deep nets, memory scales linearly with the number of layers in the network; i.e., $O(L)$. This is because all the layer activations have to be stored for backpropagation.  \nDEQs.  For DEQs, on the other hand, memory complexity is constant with respect to \u201cdepth\u201d; i.e., $O(1)$. This is because it is not necessary to store intermediate activations at all, but instead memory consumption is dominated by the evaluation and storage of the $nz \u00d7 nz$ matrix $\\frac{\\partial F}{\\partial z}$, which is constant with respect to \u201cdepth\u201d. It is worth pointing out that the implicit layers used in [1] have the same memory complexity as DEQs, which in fact follows directly from the implicit function theorem.  \nIt is also useful to compare with ODE-based methods. For ODE-based methods, the activations themselves do not need to be stored (since derivatives are calculated by numerically solving differential equations).  However, to implement higher order solvers, it is necessary to store function evaluations (instead of activations) of the layers [4, 23].  As such, the memory cost of training the function $f$ is also constant with respect to depth (i.e., the number of steps used to solve the ODE).  Thus, in terms of memory consumption, DEQs and ODE-based methods are similar; we will see in our experiments, however, that DEQs can typically be trained faster in practice."}, {"title": "4 Experiments", "content": "In this section, we aim to evaluate DEQs both in terms of their classification performance, and to validate a number of the other appealing properties claimed thus far (e.g., implicit regularization, robustness to solver choice, etc.). We consider the standard MNIST and CIFAR-10 image classification datasets [10, 13], and also construct a challenging variant of character recognition task based on scene text. \n4.1 Implementation Details\nFor all experiments, we use both 32 and 64 batch size and train DEQs using Adam [11] and its decoupled variant AdamW [14] with weight decay of 1e-5. We use three Anderson mixing ranks: $m = 5, 10, 15$ and find all configurations to be fairly robust, though we report results for $m=10$ in the interest of space. The number of iterations K to solve the equilibrium is set to 50 for most experiments, with a small convergence tolerance of $1e^{-3}$. We implement the vector-Jacobian product during the CG solver as a single explicit call without unrolling; i.e., the Jacobian is never stored. All models were implemented in PyTorch [15].\n4.2 Classification Performance\nIn this experiment, we compare the performance of DEQs with the most common baseline: Residual Networks (ResNets) [8]. We emphasize that the goal here is not to outperform standard deep nets, but rather to achieve comparable performance while maintaining other appealing benefits (e.g., memory footprint, implicit regularization, etc.). Specifically, we consider the most common ResNet-18 architecture, and compare against DEQs with two different base functions. Both base functions are inspired by the bottlenecks within ResNet blocks. Specifically, we consider a base function with 1) one hidden layer and 2) two hidden layers. For each model, we consider both the standard (ResNet-18) and bottleneck version (ResNet-18-BN) and report the results in Table 1. Results are averaged across 5 runs.\nTable 1: Classification error on several standard datasets. \nDataset | Model | Error (%)\nMNIST | ResNet-18 | 0.67 \u00b1 0.03\nMNIST | DEQ-1HL | 0.77 \u00b1 0.02\nMNIST | DEQ-2HL | 0.74 \u00b1 0.04\nCIFAR-10 | ResNet-18-BN | 7.58 \u00b1 0.11\nCIFAR-10 | DEQ-1HL | 8.01 \u00b1 0.08\nCIFAR-10 | DEQ-2HL | 7.97 \u00b1 0.04\nCharacter | ResNet-18-BN | 1.83 \u00b1 0.02\nCharacter | DEQ-1HL | 1.94 \u00b1 0.03\nCharacter | DEQ-2HL | 1.88 \u00b1 0.03\nOn all three datasets, the DEQ architecture was able to obtain results that were reasonably competitive with standard ResNets. This demonstrates that this novel DEQ layer can perform comparably to more standard architectures, while also demonstrating several unique benefits (see below). To further analyze DEQs we plot the forward and backward computational time in Figure 1."}, {"title": "5 Analysis", "content": "In addition to the classification performance of DEQs, we perform some additional experiments to analyze the other appealing claims made thus far.\n5.1 Robustness to Solver Choice\nThe forward pass of DEQs requires finding the root of a function, which could potentially lead to instability if the root-finding algorithm becomes sensitive to the parameters of the function. In practice, however, we find that DEQs are fairly robust to the choice of root-finding algorithm. As mentioned earlier, all of our results thus far have been based on Anderson Acceleration. We now compare the performance of Anderson Acceleration with two other root-finding algorithms, namely Broyden's method [20] and naive fixed-point iteration. As part of this experiment, we re-train all MNIST models, but this time using the different root-finding algorithms. The classification error of each of these approaches is summarized in Figure 2. As shown in the figure, Broyden\u2019s method is significantly more unstable compared to Anderson Acceleration, and yields fairly poor performance. On the other hand, naive fixed-point iteration performs comparably to Anderson Acceleration, but this comes at the cost of 5x slower convergence. These results suggest that DEQs are, in fact, fairly robust to the choice of solver, but some form of acceleration appears to be necessary for reasonable training time.\n5.2 Memory Usage\nAn appealing aspect of DEQs is that their memory complexity is constant with respect to depth. In this experiment, we directly measure the peak memory usage of training ResNets and DEQs on a large image classification dataset, namely Imagenet [7]. As part of this, we train ResNet-50, DEQ-1HL, and DEQ-2HL for 50 epochs and measure the peak memory usage at each epoch. The results of this analysis are summarized in Figure 3. As shown in the figure, the peak memory usage for DEQs is significantly lower than that of the traditional ResNet-50, which supports our earlier claims regarding memory efficiency. It is also worth noting that the ResNet architecture also has memory complexity linear in L, which leads to much slower backward passes.\n5.3 Implicit Regularization\nAs part of Section 3.3, we claimed that the implicit fixed-point formulation of DEQs might act as a regularizer that is robust to overfitting. In this section, we aim to investigate this claim by analyzing performance as a function of increasing the size of the network. Specifically, we consider the MNIST classification task, and compare ResNet-18, DEQ-1HL, and DEQ-2HL as a function of the number of hidden units. Note that in this case, there are no explicit regularization techniques used. The classification error of each of these approaches is summarized in Figure 4. The results suggest that the DEQ architecture appears to be less susceptible to overfitting for larger number of hidden units. For ResNet-18, on the other hand, the error sharply decreases before increasing due to overfitting."}, {"title": "6 Discussion", "content": "As the experimental results show, DEQs have several interesting properties. As a constant depth model, DEQs have lower memory usage, better solver robustness, and implicit regularization. But DEQs also have their own limitations. \nSolver speed. Although our experiments demonstrated that DEQs can be fairly competitive with ordinary deep networks in terms of convergence time (particularly thanks to the implicit backpropagation), the forward pass of each DEQ layer can sometimes take longer compared to a standard layer. Indeed, unlike standard layers that can be efficiently evaluated in parallel with simple matrix operations, each DEQ layer requires finding the root of a potentially difficult non-linear equation. While Anderson Acceleration is typically quite robust for the models and tasks we consider, we found it is possible for other, more difficult, problems to require a large number of iterations (or even fail to converge). As such, one important aspect for future work is to consider alternative means for finding the fixed point or to improve the robustness of existing techniques. \nVector Jacobian Product. Algorithm 2 states that we need to compute the vector Jacobian product with the conjugate gradient method. However, as shown in [15], automatic differentiation can be used as a generic implementation to compute this operation, with a memory footprint that scales linearly with the batch size. In practice, however, we find that it is possible to optimize this further; specifically, in Section 4.1, we mention that our current implementation performs this vector-Jacobian product with a single explicit call without unrolling, which drastically reduces the memory consumption for DEQs. As part of future work, we hope to more formally characterize the theoretical limitations of memory consumption of this operation. \nVariable Data Length. As mentioned in Section 1, one motivation for exploring DEQs was that their iterative nature might allow for efficient processing of variable-length data. However, such an analysis is beyond the scope of this paper and left as future research. \nApplicability to CNNs. The current architecture of DEQs, which has been tested on multiple problems with multilayer perceptrons, may not be directly applicable to convolutional neural networks, and some modifications are required. This interesting direction is also left for future research. \nTheoretical Justification. Though this paper has presented a theoretical justification for the training process of DEQs, there still lacks a complete understanding of the conditions for fixed-point convergence and the influence on generalization error. An intuitive reason for the good performance is that DEQs impose an implicit constraint on the function space, with further rigorous theoretical justification for their generalization ability left for future work."}, {"title": "7 Conclusion", "content": "We proposed Deep Equilibrium Networks (DEQs), a novel approach to deep learning that eschews the traditional layer-by-layer architecture in favor of directly computing the equilibrium point of a single layer. While at first glance the fixed-point formulation of DEQs may seem intractable, we show that root finding can in fact be solved very efficiently via the simple iterative approach of fixed-point iteration, particularly with the addition of an acceleration scheme such as Anderson Acceleration. As part of our experiments, we demonstrated that the classification performance of DEQs can be reasonably competitive with traditional ResNets while also possessing other appealing benefits such as lower memory complexity, solver robustness, and implicit regularization. Finally, from a theoretical point of view, DEQs can be seen as a special case of infinitely deep networks with weight tying. For future work, we plan to study other methods for finding the fixed point, and to perform an analysis of what types of functions can have the property of fixed-point convergence."}]}