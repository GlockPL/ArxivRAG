{"title": "Leveraging Self-Training and Variational Autoencoder for Agitation Detection in People with Dementia Using Wearable Sensors", "authors": ["Abeer Badawi", "Somayya Elmoghazy", "Samira Choudhury", "Khalid Elgazzar", "Amer Burhan"], "abstract": "Dementia is a neurodegenerative disorder that has been growing among elder people over the past decades. This growth profoundly impacts the quality of life for patients and caregivers due to the symptoms arising from it. Agitation and aggression (AA) are some of the symptoms of people with severe dementia (PwD) in long-term care or hospitals. AA not only causes discomfort but also puts the patients or others at potential risk. Existing monitoring solutions utilizing different wearable sensors integrated with Artificial Intelligence (AI) offer a way to detect AA early enough for timely and adequate medical intervention. However, most studies are limited by the availability of accurately labeled datasets, which significantly affects the efficacy of such solutions in real-world scenarios. This study presents a novel comprehensive approach to detect AA in PwD using physiological data from the Empatica E4 wristbands. The research creates a diverse dataset, consisting of three distinct datasets gathered from 14 participants across multiple hospitals in Canada. These datasets have not been extensively explored due to their limited labeling. We propose a novel approach employing self-training and a variational autoencoder (VAE) to detect AA in PwD effectively. The proposed approach aims to learn the representation of the features extracted using the VAE and then uses a semi-supervised block to generate labels, classify events, and detect AA. We demonstrate that combining Self-Training and Variational Autoencoder mechanism significantly improves model performance in classifying AA in PwD. Among the tested techniques, the XGBoost classifier achieved the highest accuracy of 90.16%. By effectively addressing the challenge of limited labeled data, the proposed system not only learns new labels but also proves its superiority in detecting AA.", "sections": [{"title": "1 Introduction", "content": "Dementia is a term that describes a collection of neurodegenerative symptoms that cause a severe cognitive decline that significantly impacts individuals' abilities and quality of life [1, 2]. Dementia is caused by a range of neurologic, neuropsychiatric, and medical conditions, with Alzheimer's disease and vascular dementia being the most prevalent [3]. The progression of the syndrome leads to increasing dependence and a significant burden on patients, caregivers, and society [4]. The symptoms include cognitive decline, emotional and behavioral changes, and loss of independence. Also, the non-cognitive neuropsychiatric symptoms (NPS) are common in people with dementia (PwD) [5, 6]. Some examples of NPS are agitation, aggression, apathy, sleep, and appetite disturbances. In severe cases, agitation and aggression (AA) pose a frequent source of distress for the patients and those around them [7, 8]. These behaviors are often linked to cognitive impairment, which manifests in various forms such as cursing, hitting, or pacing [9]. Although a cure remains elusive, monitoring systems play a crucial role in supporting PwD and people around them to prevent severe aggressive behavior."}, {"title": "2 Related Work", "content": "Dementia, marked by cognitive decline affecting daily life, often leads to AA in patients [2, 3, 4]. These symptoms, which are linked to factors like mental health history and memory issues, empha-"}, {"title": "3 Research Methodology", "content": "This study introduces a robust methodology for detecting AA in PwD using wearable sensor data collected from the Empatica E4 wristband. The dataset was obtained from three Canadian hospital studies, including the NAB-IT and StaN clinical trials, comprising physiological data such as heart rate, skin conductance, and motion metrics from 14 participants over 48-72 hours of monitoring. First, we present the dataset description in detail, including the number of participants, data collection duration, and labeling of agitation events. Second, we present the proposed system architecture components to classify AA in PwD. We start with the raw wristband data input and the pre-processing steps. Then, we explain the feature extraction techniques used to extract features from the data. Next, we propose Variational Autoencoders (VAE), which are built on the extracted features to represent the features. We then present the Self-training to classify agitation episodes with labeled and unlabeled data. Finally, we evaluate the performance by comparing the model with the baseline supervised models used to classify the fully labeled dataset and explain the balanced accuracy metrics used to evaluate the performance. Each of these stages is discussed in detail in the following subsections."}, {"title": "3.1 Dataset Description", "content": "The first dataset is a result of a pilot study we conducted at the Ontario Shores Center for Mental Health Sciences. The NAB-IT study, aimed at treating AA in individuals with dementia, is an ongoing randomized, double-blind, placebo-controlled clinical trial recruiting participants nationwide. The StaN study, a randomized, controlled, clinical trial from seven sites across Canada, received approval from institutional review boards at all sites. The participants or their substitute decision-makers provided informed consent before any study procedures. Participants in both trials had their physiological data collected using the Empatica E4 wristband. The wristbands were placed on the non-dominant arm by a study team member during participants' psychometric assessments, and the physiological data stored on the E4 wristband's memory card was later synchronized with clinical records.\nA total of 14 participants were included in this work from distinct studies, with nine male and five female. The data from Ontario Shores Hospital was collected over six weeks. The recruitment process included additional criteria such as the requirement of the patients to have a moderately and severe major neurocognitive disorder defined by a Mini-Mental State Examination (MMSE) score [36]. Other requirements included the ability to ambulate independently, without the assistance of another person, with or without a walking aid. Moreover, participants needed to meet the AA criteria defined by the Agitation Definition Working Group from the International Psychogeriatric Association [37]."}, {"title": "3.2 Proposed System Architecture", "content": "The proposed system architecture contains multiple blocks to classify AA in PwD. We start with the raw wristband data input and the pre-processing steps. Then, we explain the feature extraction techniques used to extract features from the data. Next, we propose Variational Autoencoders (VAE), which are built on the extracted features to represent the features. We then present the Self-training to classify agitation episodes with labeled and unlabeled data. Finally, we evaluate the performance by comparing the model with the baseline supervised models used to classify the fully labeled dataset and explain the balanced accuracy metrics used to evaluate the performance. Each of these stages is discussed in detail in the following subsections."}, {"title": "3.2.1 Data Pre-processing and Feature Extraction", "content": "We selected the Empatica E4 wristband in this study due to its lightweight, portable nature, and high precision compared to alternative devices [40]. The smartwatch is equipped with sensors to monitor vital physiological parameters, including heart rate (measured by a Photoplethysmography sensor at 64 Hz), accelerometer (captured by a 3-axis accelerometer at 32 Hz), skin temperature, and electrical properties of the skin (measured by an Electrodermal Activity sensor at 4 Hz). These physiological signals are collected and can be wirelessly transmitted to a smartphone via Bluetooth for real-time analysis. The recorded data is subsequently uploaded to the Empatica website and can be downloaded from the cloud. The pre-processing steps used in this work have proved their efficiency and ability to classify normal and AA events in PwD in our two previous works [41, 42].\nBefore data analysis, it is crucial to pre-process the data to ensure reliability. We use the Flirt toolkit [43], an up-to-date open-source Python library employed for data processing and feature extraction. Flirt is specifically designed for wearable devices, offering various techniques and a wide range of features to extract necessary information. The primary objective is to perform data cleaning and feature extraction for each attribute collected by the E4 device using state-of-the-art techniques. We start with reading the E4 device data, converting it to the correct format with timestamps, and utilizing the Flirt function for various pre-processing steps, including noise removal and sliding windows. Then, we resample the signals to align with the minimum sampling rate of 4 Hz. The Flirt function calculates inter-beat intervals (IBI) and applies a low-pass filter for the heart rate. It also uses a low-pass filter with a 10 Hz cut-off frequency for the accelerometer signal. The EDA signal undergoes artifact removal, noise filtering, and decomposition to generate phasic and tonic components.\nA sliding-window approach with a window size of 1 minute and no overlap is then applied to extract features from the datasets. A feature vector, encompassing the time domain, frequency domain, and statistical features, totaling 198 features, is computed from the four signals. From the 198 features, 88 were from the accelerometer signal, 44 were from the BVP signal, 44 from the EDA signal, and 22 were from the temperature signal. These features cover various domains, including time, frequency, and time-frequency. Out of the total features extracted, only 182 were used in this study. This is because some features yielded inaccurate results, such as NaN or infinity values. The selected features comprehensively represent the physiological markers of the wearable device for subsequent analysis."}, {"title": "3.2.2 Variational Autoencoder", "content": "In this work, we use the VAE to evaluate the ability of autoencoders to select the optimal set of features and reduce the dimensions in the AA classification problem. The VAE marks an intriguing advancement in the field of machine learning, bringing together generative modeling and inference. The fundamental concepts of VAE involve the creation of a probabilistic model for data and a VAE model for latent variables. Rooted in Bayesian inference, VAE aims to represent the underlying probability"}, {"title": "", "content": "distribution of data, enabling the generation of new data samples from this distribution [17]. Our proposed system consists of a VAE model incorporating an encoder, sampling function, and a decoder. The system extracts the encoder features and selects the most important features through the model. The encoder part of the VAE is responsible for mapping the input data to the mean (zmean) and log variance (Zlog_var) of the latent space. The input data is first transformed through a dense neural network layer and then passed through a ReLU activation function, as shown in the equation 1 below. The output is then used to calculate both the mean and the log variance as shown in equations 2 and 3, providing the necessary parameters for the VAE's probabilistic modeling.\n$$h = ReLU(Dense(inputs))$$\n$${z_{mean}} = Dense(h) [44]$$\n$${z_{log-var}} = Dense(h)[44]$$\nThe input layer has input_dim neurons. Dense Layer 1 processes the input through a fully connected layer with 256 neurons, followed by a ReLU activation function. Dense Layers 2 and 3 further reduce dimensionality with 128 and 100 neurons and a ReLU activation. We define a function 'sampling' that takes mean and Zlog_var as arguments and generates a random sample z from the distribution represented by these parameters as shown in 4.4. The sample is obtained using the reparameterization trick.\n$$z = {z_{mean}} + exp\\left(\\frac{1}{2} \\times {z_{log-var}} \\times \\epsilon[45]\\right)$$\n$$\\epsilon \\sim N(0,1)$$\nwhere:z is the sampled point in the latent space, zmean is the mean vector, Zlog_var is the log variance vector, and e is a random sample from a standard normal distribution.\nThe Decoder reconstructs the input data from the samples in the latent space, shown in 5. It mirrors the encoder architecture in reverse order. For Dense Layer 1, it processes the sampled z with 100 neurons and a ReLU activation. Dense Layers 2 and 3 progressively increase the dimensionality by 128 and 256. The output layer reconstructs the input with a sigmoid activation function as shown in 6.\n$$h_{decoded} = ReLU(Dense(z))$$\n$${x_{decoded\\_mean}} = Sigmoid(Dense(h_{decoded}))$$\nWe use a custom loss function to evaluate the VAE architecture. We start with a reconstruction Loss, which is calculated using binary cross-entropy for each feature. This term is scaled by the total number of features. Then, we apply the Kullback-Leibler Divergence kl_loss which encourages the latent variables to follow a specific distribution (typically a multivariate normal distribution). The formula for the KL divergence is:\n$$kl_{loss} = -0.5 x \\sum_{i=1}^{latent\\_dim} (1 + z\\_log\\_var - z\\_mean^2 - e^{z\\_log\\_var})[17]$$\nwhere latent_dim refers to the dimensionality of the latent space. To calculate the total VAE Loss vae_loss, we calculate the sum of the reconstruction loss xent_loss and the KL divergence term averaged over all samples in the batch:\n$$vae\\_loss = mean(xent\\_loss + kl\\_loss)$$\nThe objective during training is to minimize this combined loss, leading to a VAE model that effectively reconstructs input data while regularizing the distribution of latent variables. We trained the autoencoder with 50 epochs and 128 batch size. The encoder part of the trained autoencoder is then isolated and used to transform the dataset into a lower-dimensional space, yielding the encoded features. This process involves passing the input data through the encoder model, where each sample is mapped to a reduced-dimensional representation. The resulting data contain the encoded features,"}, {"title": "3.2.3 Self-training", "content": "Self-training is a semi-supervised learning where a model is initially trained on a small labeled dataset and then iteratively improves itself by incorporating unlabeled data. Self-training in semi-supervised learning is particularly useful when obtaining labeled data, which is expensive or time-consuming, as it allows leveraging a combination of labeled and unlabeled data to improve model performance. The process begins with training a model on the labeled dataset. This model then generates predictions for the unlabeled data, which are treated as pseudo-labels. These pseudo-labeled samples are added to the dataset, creating an augmented training set that combines original labeled data with newly generated pseudo-labeled examples. The model is re-trained on this expanded dataset, gradually improving its generalization ability. This essentially creates a larger dataset with a mix of labeled and pseudo-labeled examples [46].\nThe process is repeated, with the updated model making predictions on additional unlabeled data, generating new pseudo-labels, and adding them to the training set. However, it is crucial to manage the quality of pseudo-labels, as incorrect pseudo-labels can mislead the model during training. Techniques such as thresholding or using a confidence score can be employed to filter out unreliable pseudo-labels. This work sets the decision threshold for adding pseudo-labels to 0.7. If the predicted probability of a sample being in a particular class is above this threshold, it will be added to the training set with the pseudo-label. We also set the maximum number of iterations allowed for the self-training process to 100."}, {"title": "3.3 Performance Evaluation Metrics", "content": "We use three classification models: Extra Trees, Random Forest, and XGBoost classification models to classify the Self-training model-generated labels. Extra Trees and Random Forest are bagging ensemble methods that create multiple decision trees and aggregate predictions to avoid overfitting. Extra Trees introduces extreme randomness in feature selection. In contrast, XGBoost employs a boosting strategy, sequentially building trees to correct errors and optimizing performance through gradient descent and regularization. These models proved to be the most promising models to classify AA in PwD in our previous work [41, 42]. We used a random state for the three models to ensure random splitting is the same every time you run the code. It helps in obtaining consistent results during different runs. We also used stratified sampling to ensure that the distribution of the target variable y is similar in both"}, {"title": "", "content": "the training and testing sets. This is particularly useful for imbalanced datasets such as our dataset to maintain the same proportion of different classes in both sets. We then split the dataset into training and testing sets, with 70% used for training and 30% for testing.\nOn the other hand, we address the imbalanced data problem by selecting a performance evaluation technique that focuses on balanced performance evaluation to overcome this problem. Imbalanced datasets refer to scenarios where the distribution of classes is uneven, with one class significantly outnumbering the other(s). Traditional metrics like accuracy may not comprehensively understand a model's performance in such cases. We extend the conventional classification report by incorporating additional metrics specifically designed to address the challenges posed by imbalanced datasets. Accurate performance evaluation techniques played a pivotal role by providing an intricate breakdown of key metrics when dealing with imbalanced data. We use the balanced accuracy score function, which offers a balance between sensitivity and specificity. This metric accounts for class imbalance, providing a fair classification accuracy assessment. We also use Precision, which represents the proportion of true positive predictions among all positive predictions and showcases the accuracy of positive predictions. Conversely, recall signifies the proportion of true positive predictions among all actual positive instances, offering insights into the model's ability to capture all relevant cases.\nThe Fl-score, the mean of Precision and recall, provides a balanced measure of a model's overall performance. Furthermore, incorporating the Area Under the Receiver Operating Characteristic Curve (AUC) allowed for a nuanced examination of the model's discriminatory power. By weighing the true positive rate against the false positive rate, AUC provided a robust measure of the model's ability to distinguish between classes. In addition to these traditional metrics, the evaluation extended to processing time as a practical consideration. Processing time measures the time required for the classification system to make predictions on the dataset. This aspect is crucial for real-world applications where efficiency is a paramount concern. Thus, the holistic evaluation framework considered the standard metrics like Precision, recall, and F1-score and incorporated processing time, providing a comprehensive understanding of the classification system's performance in the context of PwD and imbalanced datasets."}, {"title": "4 Results and Discussion", "content": "In this section, we present the results of our experiments evaluating our proposed system, which utilizes VAE and Self-training, in comparison with different approaches for AA detection in PwD. To evaluate the proposed system, we compare the system with a fully supervised learning approach. For supervised learning, we only use the labeled data from our dataset. We had a total of 18804 minutes labeled normal and 1475 minutes labeled AA. We start by presenting the results from the baseline, which uses extracted features only with fully labeled data (5 participants) employing supervised learning models. Then, we introduce the proposed VAE for feature representation, which we integrate on top of the features extracted with the fully supervised model. Next, we present the proposed self-training model with extracted features, which includes the full dataset with partially labeled data (14 participants). Lastly, we present our proposed system, which utilizes the VAE features with the self-training model that incorporates the full dataset with partially labeled data (14 participants). Our aim is to compare all scenarios with our proposed system to demonstrate performance across different parameters and approaches. For the discussion, we compare our work with previous works on agitation detection and wearable sensors."}, {"title": "4.1 Agitation Detection using Supervised Learning", "content": "Table 2 presents the baseline model with supervised learning and feature extraction using three prominent classification algorithms-Random Forest, Extra Trees, and XGBoost to classify Normal and AA activities in PwD. In the supervised learning scenario, feature engineering techniques were applied to a dataset consisting of 18,804 minutes labeled as normal and 1,475 minutes labeled as AA from 5 participants. The input dataset comprised 182 features extracted from heart rate, accelerometer, electrodermal activity (EDA), and temperature measurements obtained from the E4 wristband data. Random Forest achieved a balanced accuracy of 78.50%, with precision, recall, and F1-score of 96.9%, 96.8%, and 96.5%, respectively. Extra Trees exhibited improved performance with a balanced accuracy of 79.01%, precision, recall, and F1-score of 97.0%, 96.9%, and 96.6%, respectively. XGBoost outper-"}, {"title": "4.2 Agitation Detection using Supervised Learning and VAE", "content": "This section presents the supervised learning approach for classifying AA in PwD after using THE VAE. We trained the VAE model for 50 epochs. The output indicates that after 50 epochs, the loss on both the training and validation has decreased. The reported values of 0.0019 loss for training and 0.0017 loss for validation represent the mean squared error loss, measuring the dissimilarity between the reconstructed output and the input data. Lower loss values suggest that the autoencoder is successfully learning to reconstruct the input data, capturing essential features in the process. The output of the VAE was used as the input of the supervised models, which have 100 data features. Our analysis involves three prominent classification algorithms: Random Forest, Extra Trees, and XGBoost, utilizing the dataset with 100 features. For the supervised learning scenario shown in Table 3, the model is trained and evaluated using labeled data, consisting of 18,804 minutes labeled as normal and 1,475 minutes labeled as AA. The Balanced Accuracy values for Random Forest, Extra Trees, and XGBoost were 83.1%, 81.5%, and 86.4%, respectively. Precision, recall, and F1-Score metrics revealed that Random Forest achieved 96.3%, 96.1%, and 95.4%, Extra Trees reached 97.4%, 97.3%, and 97.1%, and XGBoost attained 97.9%, 97.9%, and 97.7%. AUC ROC scores were 98.0% for Random Forest, 98.7% for Extra Trees, and 98.8% for XGBoost as shown in Table 3."}, {"title": "4.3 Agitation Detection using Self-training", "content": "In the semi-supervised learning approach, the setting extends the dataset to include 37463 unlabelled data, 18804 labeled as normal, and 1,475 minutes labeled as AA. The input dataset comprised 182 features extracted from heart rate, accelerometer, EDA, and temperature measurements. We train the model using Self-training for our three classification techniques. After training, the dataset was extended to include 55,214/2,523 minutes Normal/AA for Random Forest, 55,648/2,092 minutes Nor-mal/AA for Extra Trees, and 54,768/2,974 minutes Normal/AA for XGBoost as shown in Table 4. Self-training was employed as a semi-supervised learning strategy, utilizing the unlabeled dataset to further enhance model performance. Random Forest in the semi-supervised setting achieved a balanced accuracy of 82.78%, with precision, recall, and F1-score of 97.9%, 97.9%, and 98.6%, respectively with ten iterations."}, {"title": "", "content": "Extra Trees exhibited a balanced accuracy of 81.0%, precision, recall, and F1-score of 97.9%, 98.0%, and 97.7%, respectively with three iterations. XGBoost excelled with a balanced accuracy of 86.02%, precision, recall, and F1-score of 98.4%, 98.4%, and 98.3%, respectively with seven iterations. Random Forest, Extra Trees, and XGBoost achieved AUC ROC values of 99.01%, 99.0%, and 99.4%, respectively. These detailed results highlight the effectiveness of both supervised and semi-supervised approaches, offering insights into the classification performance and processing efficiency of different models in the context of dementia-related activity classification. The utilization of self-training in semi-supervised learning further enhances the models' ability to learn from unlabeled data, contributing to improved performance metrics."}, {"title": "4.4 Agitation Detection using Self-training and VAE", "content": "In the semi-supervised learning approach with VAE as shown in Table 5, the dataset is augmented with additional unlabeled data, and a VAE is introduced for feature extraction, reducing the dimensionality to 100 from 182. The dataset includes 37463 unlabelled data, 18804 labeled as normal, and 1,475 minutes labeled as AA. Self-training is employed as a semi-supervised learning technique. The label increased after the Self-training for the Random Forest model to 54998 labeled normal and 2733 labeled AA, Extra Trees classifier to 55665 labeled normal and 2076 labeled AA, and XGBoost classifier to 54712 labeled normal and 3026 labeled AA."}, {"title": "4.5 Discussion", "content": "The results of our proposed system in subsection 4.4 showcase promising outcomes for classifying AA in PwD with a partially labeled dataset when utilizing VAE and Self-training. We compare our proposed system with different approaches to present the performance in comparison with different"}, {"title": "5 Conclusion", "content": "In conclusion, the proposed study provides a significant advancement in the area of partially labeled data using semi-supervised AA detection in PwD. It specifically incorporates AI with wearable sensor data that collects physiological biomarkers and directly addresses the issue of limited labeled real-world datasets. The datasets used in this study are composed of digital biomarkers collected by wearable sensors worn by patients from different sites across Canada. Our solution introduces a novel application of semi-supervised learning combined with Variational Autoencoders (VAE) for feature extraction and selection. The comparison between the proposed systems and other methods underscores the effectiveness of VAE in improving classification metrics for AA in PwD. The results show that this combination of VAE for feature representation and Self-training for generating pseudo labels for the unlabeled data outperforms the baseline model with feature extraction only or VAE. Out of the three different classifiers used in the comparison between supervised and semi-supervised learning, XGBoost achieved the highest accuracy of 90.18% in the case of semi-supervised learning coupled with VAE. The ability to learn and achieve better performance from limited labeled data showcases the potential for real-world applications in AA detection for PwD. The impact of such applications could transform patient care and improve the quality of life for the patients and those surrounding them. Moreover, these realistic applications that bridge the gap between AI enhancements and data availability open the path for further exploration and utilization of many limited labels gathered from healthcare."}]}