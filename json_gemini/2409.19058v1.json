{"title": "CLLMate: A Multimodal LLM for Weather and Climate Events Forecasting", "authors": ["Haobo Li", "Zhaowei Wang", "Jiachen Wang", "Alexis Kai Hon Lau", "Huamin Qu"], "abstract": "Forecasting weather and climate events is crucial for making appropriate measures to mitigate environmental hazards and minimize associated losses. Previous research on environmental forecasting focuses on predicting numerical meteorological variables related to closed-set events rather than forecasting open-set events directly, which limits the comprehensiveness of event forecasting. We propose Weather and Climate Event Forecasting (WCEF), a new task that leverages meteorological raster data and textual event data to predict potential weather and climate events. However, due to difficulties in aligning multimodal data and the lack of sufficient supervised datasets, this task is challenging to accomplish. Therefore, we first propose a framework to align historical meteorological data with past weather and climate events using the large language model (LLM). In this framework, we construct a knowledge graph by using LLM to extract information about weather and climate events from a corpus of over 41k highly environment-focused news articles. Subsequently, we mapped these events with meteorological raster data, creating a supervised dataset, which is the largest and most novel for LLM tuning on the WCEF task. Finally, we introduced our aligned models, CLLMate (LLM for climate), a multimodal LLM to forecast weather and climate events using meteorological raster data. In evaluating CLLMate, we conducted extensive experiments. The results indicate that CLLMate surpasses both the baselines and other multimodal LLMs, showcasing the potential of utilizing LLM to align weather and climate events with meteorological data and highlighting the promising future for research on the WCEF task. As a representative hub in the \"My Climate Risk\u201d lighthouse activity initiated by the World Climate Research Programme (WCRP), we contribute CLLMate as a component of our regional solution to help forecast environmental risks and mitigate their loss.", "sections": [{"title": "1 INTRODUCTION", "content": "Weather and climate events, namely discrete episodes of extreme weather or abnormal climate conditions [26], pose a significant risk to human society, resulting in potential harm to property, infrastructure, injuries, and even loss of life [56]. Such events (e.g., heatwaves, floods, droughts) have experienced a noticeable surge in frequency, intensity, and duration in recent years due to climate change [1]. Significant concerns have been raised among human society. Appropriate measures and optimal strategies are urgently needed to forecast these events and mitigate their negative impacts.\nConsiderable researchers have studied this topic for years. For example, Kang et al. [29] used factors such as temperature, wind, and pressure data to forecast precipitation. Similarly, Huang et al. [24] relied on historical radiation data to forecast future radiation. However, open-set event forecasting is missed in previous studies since what they actually forecasted were particular meteorological variables for closed-set events. They defined and inferred the closed-set events from the forecasted meteorological variables based on rules and their experience. For example, a heatwave event can be forecasted if maximum temperatures \u2265 95th percentile for \u2265 3 days [74]. In this way, closed-set events directly related to numerical variables can be predicted while open-set events, including their secondary and tertiary disasters, are challenging to forecast. For example, when the road network fails to adapt to climate change, heavy rainfall can lead to road broken, water accumulation, traffic disruptions, and human casualties, which are challenging to pre-defined within a closed-set setting [48].\nTo fill in the research blanks, we propose the Weather and Climate Event Forecasting (WCEF), a new task in the field of environmental forecasting. The task aims to forecast open-set weather and climate events based on meteorological information. The biggest gap between previous studies and WCEF lies in the data required for forecasting. Previous studies typically rely on numerical data (i.e., meteorological raster data) for variable forecasting. However, apart from numerical data, WCEF requires additional multimodal data about various aspects such as urbanization, demographic, and societal aspects [17, 23, 75] because weather and climate events are sensitive to diverse factors. Consequently, traditional forecasting methods [29, 55] focusing on single-modal numerical data cannot be applied to WCEF.\nTo bridge the gap of WCEF, environmental news serves as a valuable source of supplementary information in addition to meteorology data. It not only provides detailed descriptions of weather and climate events [53] but also offers temporal and spatial information that can be valuable for precise event prediction. The emergence of LLMs which are equipped with remarkable advancements in natural language processing [10] further makes the extraction of pertinent information from a vast amount of news articles feasible [8]. Moreover, the multi-modality capability of LLMs offers an opportunity to align and integrate text data and spatio-temporal data for WCEF [73].\nHowever, leveraging the advantages of environmental news and LLMs for WCEF comes with two challenges. First, the pertinent information for WCEF is often obscured within the vast volume of available news articles, which encompass both environmental and non-environmental topics. Even LLMs cannot effectively extract and learn the relevant information. Second, after the information extraction process, the alignment of multimodal data for event forecasting remains largely unexplored. The simultaneous processing of meteorological raster data (numerical spatio-temporal) and weather and climate events (text) is out of the scope of previous multimodal research [28, 34]. On one hand, LLMs lack the ability to effectively process raster data, during the discrepancy between textual data used in pre-training and numerical data in our task [27, 61]. On the other hand, the length of meteorological raster data surpasses the maximum token limit of LLMs, further increasing the complexity.\nIn light of these challenges and the potential of LLM in this downstream domain, we develop a framework to extract knowledge, construct the dataset, and train the LLM for the WCEF task. we first use Llama3-70B [60] to extract knowledge of weather and climate events and then build a knowledge graph. The knowledge graph was described using natural language to let LLMs learn the knowledge. Then we build the mapping between historical meteorological raster data and historical knowledge of weather and climate events to construct the first multimodal instruction dataset for the WCEF task. To efficiently forecast weather and climate events using meteorological raster data and textual data, we propose CLLMate, a multimodal LLM based on Llama3-8B.\nThe core of CLLMate is the alignment of meteorological raster data and textual data for the WCEF task. After observing the obvious meteorological patterns (Figure 3) within meteorological raster data, we propose the utilization of a vision model to detect these patterns. Subsequently, such patterns are embedded into the LLM embedding space to align with textual instructions. By leveraging the supervised multimodal instruction dataset we construct, we instruction-tune the LLM, empowering it to directly predict textual events in the required format based on the numerical meteorological raster data. Our proposed multimodal LLM, CLLMate, can precisely forecast textual weather and climate events in the desired format. This capability proves valuable for domain experts, providing them with intuitive and accurate insights without necessitating manual analysis of predicted numerical variables for event derivation.\nTo evaluate the framework, we invest significant effort since we propose a novel WCEF task and few studies have explored this problem, resulting in few supervised datasets for high-quality model training. Furthermore, the nature of including multimodal data makes such datasets difficult to generate. We construct the dataset from a corpus of over 41,000 highly environment-focused news articles. Then we conduct extensive experiments to evaluate CLLMate on the WCEF task to demonstrate its performance and efficiency. The evaluation not only underscores the advantages of our proposed CLLMate but also highlights a promising future for research on the WCEF task to address the limitations of conventional weather forecasting methods.\nIn terms of application and impacts, as a representative hub of the \"My Climate Risk\" lighthouse activity [50] initiated by the WCRP, we develop CLLMate, which is deeply integrated into our regional solution enabling a bottom-up approach for global climate risk research and an important component in early warning system to effectively mitigate the impact of climate risks. In summary, the key contributions of this paper can be outlined as follows:\n\u2022 We propose the WCEF task to directly forecast textual events based on the numerical meteorological raster data, which differs from traditional weather forecasting. Furthermore, we leverage domain knowledge extracted from the news corpus to establish the first multimodal instruction dataset and the benchmark for the WCEF task.\n\u2022 To the best of our knowledge, we first attempt to align the meteorological raster data, which is dense spatio-temporal, with text to develop CLLMate, a multimodal LLM, capable of forecasting weather and climate events directly and accurately in the required format.\n\u2022 We conduct extensive experiments to evaluate CLLMate on the WCEF task, demonstrating its efficiency in forecasting open-set textual weather and climate events.\n\u2022 As a representative hub of the \"My Climate Risk\" lighthouse activity, we develop the framework that plays a central role in our regional solution for the lighthouse activity to generate real-world impacts and help mitigate risks."}, {"title": "2 PROBLEM FORMULATION", "content": "In this section, we provide a detailed introduction to the data type and outline the formulation of the WCEF task."}, {"title": "2.1 Data Type", "content": "In this work, we used spatio-temporal data, including raster data and event, and knowledge graph for the WCEF task."}, {"title": "2.1.1 Spatio-Temporal Data.", "content": "In this paper, two types of spatio-temporal data are utilized: meteorological raster data and event data. Meteorological raster data is commonly employed in the environmental domain to depict meteorological variables. For instance, one global meteorological variable can be represented as a three-dimensional tensor $R \\in R^{T\\times A\\times \\Phi}$, where T denotes the time dimension, and A and I represent the longitude and latitude dimensions, respectively. Each element $r_{t, \\lambda, \\phi}$ corresponds to the meteorological variable value at a specific time t and location $(\\lambda, \\phi)$.\nOn the other hand, event data, E with the shape of T XA XI, are occurrences of interest at specific points in space and time. For example, a single event can be represented using textual information $e_{t, \\lambda, \\phi}$, indicating the occurrence at a particular time t and location $(\\lambda, \\phi)$. Global or regional weather and climate events can be represented as a collection of all weather and climate events transpiring across various times and locations.\nFrom this description, we can observe two main distinctions between meteorological raster data and event data within our proposed WCEF task: Firstly, meteorological raster data is numerical, while event data is textual. Secondly, meteorological raster data is dense, whereas event data is sparse, featuring specific instances at discrete locations and times."}, {"title": "2.1.2 Knowledge Graph of Weather and Climate Events.", "content": "A knowledge graph of weather and climate events $G = (V,\\&,T)$ is a text-attributed directed graph. It comprises a set of nodes V to represent climate events with a set of text features T, and a set of edges & connecting these nodes. Each edge $e \\in \\&$ is associated with a pair of nodes (u, v) and has a direction, where u is the tail and v is the head, denoting that event u causes event v."}, {"title": "2.2 WCEF Task", "content": "The existing weather forecasting task involves predicting the future target meteorology variable by utilizing either the same or multiple variables. This task can be formulated as follows:\n$R_{C+1:C+F} = f(R_{C-H+1:C})$\nwhere f() denotes the forecasting model, C denotes the current time, F represents the length of the forecasted data, and H signifies the length of historical data used.\nIn the proposed WCEF task, the objective is to predict textual weather and climate events using numerical meteorological raster data. These events can be defined based on meteorological characteristics, such as heatwaves, or the subsequent consequences they entail, such as flooding caused by heavy rain. The scope of such events encompasses primary occurrences like heatwaves and droughts, as well as secondary and tertiary events like landslides and pest infestations that arise as a result of the primary events. These examples illustrate the complexity of deriving such events solely from numerical data. It highlights the significance of the historical event relationships and the valuable knowledge they offer. The WECF task can be formulated as follows:\n$E_{C:C+F-1} = f(R_{C\u2212H+1:C}, Instruction)$\nwhere f() denotes the LLM model, C denotes the current time, F represents the length of the forecasted data, and H signifies the length of historical data used. It is worth emphasizing that, unlike existing forecasting tasks utilizing the same source data, we employ C in both the forecasting and historical data. This is because Ec and RC hold distinct meanings."}, {"title": "3 Methodology", "content": "In this section, we delve into the pipeline to extract weather and climate knowledge and create the multimodal instruction dataset. Additionally, we explain the multimodal instruction-tuning, including the architecture of CLLMate and the objective loss function."}, {"title": "3.1 Multimodal Instruction Dataset", "content": "To create the multimodal instruction dataset, we begin by extracting events and their relationships. Utilizing these events and relationships as vertices and edges, we build a knowledge graph for the LLM's learning. Subsequently, we map these events and meteorological raster data to construct the multimodal instruction dataset."}, {"title": "3.1.1 Extracting Events and Their Relationships.", "content": "Weather and climate events exist within a vast amount of news articles. The initial step of our pipeline is to identify and extract these events, along with their relationships, from each news document. To achieve this, we employ the Llama3-70B and utilize a multipart LLM prompt (Figure 1). The prompt begins with an overview of the task, including the available data, the requirements, and the chain of thought [70] for LLM to perform the task. Next, we define the triple to be extracted. Lastly, the prompt is tailored using few-shot learning (two examples) specifically designed for in-context learning [10], with the valuable guidance of an environmental professor. This approach ensures that events with specialized knowledge receive the benefits of few-shot examples tailored to the environmental domain. By leveraging this approach, we successfully extract triples in the form of subject-predicate-object in English, such as \"event A causes event B,\" while also capturing pertinent location and time information from the news articles. Our focus is specifically on articles that provide well-extracted and unambiguous information. In this step, out of the total 41,088 news articles, we identify that 17,676 articles contain triples that meet the specified requirements and extract a total of 80,870 triples from these 17,676 news articles.\nSubsequently, we filter the news articles based on their geographic location. To accomplish this, we utilize the geopy API [18]"}, {"title": "3.1.2 Building Knowledge Graph.", "content": "Having extracted 70,538 triples, we proceed to build the directed text-attributed knowledge graph $G = (V, \\&, T)$. To prevent duplication, we convert all events to lowercase. Upon completing the graph construction, we obtain a knowledge graph with 6,219 nodes and 19,197 edges. Subsequently, we utilize a Breadth-First Search (BFS) order to enumerate all nodes $u \\in V$. For each node u, we identify all its head nodes $0_1, 0_2, ...$ and express the relationships using natural language. This involves constructing knowledge graph instructions for the LLM in the form of Figure 2. The purpose is to pre-train the LLM so that it can learn knowledge related to weather and climate events."}, {"title": "3.1.3 Mapping events and meteorological raster data.", "content": "Constructing multimodal instructions involves establishing a connection between numerical meteorological raster data and textual event data through temporal alignment. We select weather and climate events occurring on the same date $v \\in V_i$, integrate the meteorological raster data: $r_t$ processed according to the method outlined in subsection 3.2, and incorporate statistical insights from $r_t$. This results in the development of a multimodal instruction dataset for tuning LLM, as illustrated in Figure 3."}, {"title": "3.2 Raster Instruction-Tuning", "content": "Initially, we outline the process of projecting meteorological raster data into the LLM space. Subsequently, we introduce the alignment procedure. Lastly, we detail the objective loss function for multimodal instruction tuning."}, {"title": "3.2.1 Raster Data Embedding.", "content": "We first project meteorological raster data into LLM embedding space to align with text, drawing inspiration from LLaVA [34], which aligns image and text. The framework of CLLMate is illustrated in Figure 4. For our WCEF task, we selected Llama3-8B as our $f_p(.)$, as it has demonstrated exceptional capabilities [60]. Similar to performing object detection on images, we propose employing a vision model with two MLP layers W as the spatial-temporal encoder to detect meteorological patterns. The initial step involves converting dense meteorological raster data into image-like representations. After careful consideration, following the recommendations of environmental experts, we have selected four variables (after normalization): \"2m temperature,\u201d \u201c10m u-component of wind,\u201d \u201c10m v-component of wind,\" and \"total precipitation.\" In Figure 3, they correspond to \u201cT\u201d \u201cU\u201d \u201cV\u201d and \"P\" Notably, the \"10m u-component of wind\" and \"10m v-component of wind\" represent the two components of the wind vector. To calculate the norm of the wind vector, we combine these two components $|w| = \\sqrt{u^2_{wind} + v^2_{wind}}$\nNext, we consider these three variables, \"2m temperature,\" \"10m wind speed,\" and \"total precipitation,\" as individual channels of an RGB image to get meteorology image XST. By representing the meteorological data in this image format, we can effectively visualize the discernible patterns (Figure 3) that can be detectable by the vision model. In future scenarios where additional variables or variables with different shapes need to be taken into account, we can employ convolutional layers to process the meteorological raster data and convert it into image-like representations. This approach allows us to incorporate a broader range of variables and further enhance the capabilities of the model.\nFor the vision model of the spatio-temporal encoder, we train the CLIP visual encoder ViT-L/14 [51] using our multimodal instruction data due to its large amount of pre-trained text-image data. For each XST, the meteorological feature FST is extracted using the trained visual encoder. Based on the ablation study of LLaVA [34], we selected the layer before the last Transformer layer since it has the advantage of detecting localized patterns. To map the features and tokens of LLM, we also train two MLP layers W to project extracted meteorological features into the word embedding space. Finally, we get a language embedding tokens HST. It can be formulated as:\n$H_{ST} = WF_{ST}, where F_{ST} = g(X_{ST})$"}, {"title": "3.2.2 Raster-Text alignment.", "content": "In our proposed WCEF task, meteorological raster data holds significant value in predicting events due to their close correlation. For instance, high temperatures coupled with minimal precipitation can trigger heatwaves and droughts, whereas decreased temperatures and increased precipitation may result in road freezing and"}, {"title": "3.2.3 Multimodal Instruction-Tuning.", "content": "For each day, we construct the conversation (Figure 3) containing meteorological raster data specific to that day as XST, the query containing the date and contextual information as XQuery, and the extracted weather and climate events for that day as XEvent as the ground truth responses. To perform the instruction-tuning, the instruction XInstruct is generated as:\n$X_{Instruct} = [X_{ST}, X_{Query}]$\nRepresenting the tokens for the ith day, with a length of I, as:\n$x_{instruct} = [x_{instruct}^1, x_{instruct}^2..., x_{instruct}^I]$\nAnd denoting the tokens, with a length of Zi, in the corresponding response as:\n$x'_{event} = [x_{event}^1, x_{event}^2..., x_{event}^{Zi}]$\nThen the objective loss function of CLLMate is [49]:\n$\\mathcal{L}[\\psi] = -\\sum_{i=1}^{I} \\sum_{z=1}^{Z_i} log p(x_{event}^{z}|x_{instruct}^{<z+1}, X_{event}^{z}, \\&)$"}, {"title": "4 EVALUATION", "content": "We evaluate the effectiveness of our approach by applying it to forecast weather and climate events using the multimodal instruction dataset we created. Initially, we train the Llama3-8B model on a custom dataset for CLLMate, where we use prompts to convert knowledge graph triples extracted in section 3.1.2 into natural language, enabling the model to learn about weather and climate events. This training phase involves training the model for one epoch using 2 \u00d7 H800 and employing Llama factory [80] along with its recommended hyperparameters. Subsequently, we instruction-tune the model on the multimodal instruction dataset we constructed for three epochs, following the hyperparameters provided by LLaVA."}, {"title": "4.1 Experimental Setting", "content": "In this section, we discuss the datasets we used, including both meteorological raster data and news (textual) data."}, {"title": "4.1.1 Dataset.", "content": "In this section, we discuss the datasets we used, including both meteorological raster data and news (textual) data.\nMeteorological Raster Dataset. The ERA5 reanalysis dataset [20], provided by the European Centre for Medium Range Weather Forecasts, was employed to obtain the meteorology data. Its utilization and performance in climate research have been widely acknowledged for its quality, long-term availability, and accessibility [57]. Under the guidance of a co-author who is a professor in the field of environmental studies, four variables, namely \"2m temperature,\" \"10m u-component of wind,\" \"10m v-component of wind,\" and \"total precipitation,\" were selected for predicting weather and climate events. They are normalized by scaling to the range [0, 1]. The dataset consists of hourly data spanning from July 2015 to June 2023, with a spatial resolution of approximately 27.75 km\u00d727.75 km. To derive daily data for each variable, the average of the 24-hour values (in hours UTC) within a day was utilized.\nEnvironmental News Dataset. We acquired environmental news from Wisers [71] through a procurement process, which consisted of 41,088 highly environment-related news articles from news publishers, mainly covering East Asian regions. The dataset spans from"}, {"title": "4.1.2 Training Dataset and Evaluation Dataset.", "content": "Given the forecasting nature of our proposed WCEF task, we partition our dataset into a training dataset and an evaluation dataset based on the date. The training dataset covers the period from July 2015 to June 2022, while the evaluation dataset spans from July 2022 to June 2023. The evaluation dataset is allocated a proportion of 13% in relation to the entire dataset."}, {"title": "4.1.3 Evaluation Metric.", "content": "Since our new task is to forecast events by text generation, distinct from numerical predictions, we employ BLEU-1, BLEU-2 [46], ROUGE-2, ROUGE-L [32], Meteor [4], and BERTScore [78] as the evaluation metric, which is widely used for validating the quality of text generation. This metric enables us to evaluate the overall performance of the event set while also considering the semantic aspects of individual events. Using BERTScore as the example, it assigns higher scores to predicted events that closely resemble the ground truth events. For instance, even though it may not be an exact match, BERTScore yields a relatively high F1 score of 70.32 for the pair \"extremely high temperature\" and \"heat wave,\u201d and a relatively low F1 score of 65.95 for the pair \"extremely high temperature\" and \"rain\" using the \"scibert_scivocab_uncased\" model [6], as it is specifically tailored for the scientific domain. A score of 100 is assigned when the predicted event is identical to the ground truth event. It can be formulated as:\n$s = f([e \\in E_p], [e \\in E_g])$\nwhere f\u00df is the evaluation model, Ep is the set of predicted events, and Eg is the set of ground truth events. In cases where the lengths of the two sets are unequal, we will iteratively pad the shorter set with its event items in a cyclical manner."}, {"title": "4.1.4 Baseline Models.", "content": "Given the novelty of the WCEF task we introduce, which involves predicting a variable number of events, there are limited existing models specifically designed for this objective. To establish a baseline, we align with current methodologies, called the \"top-1 similarity\" method, in the field where domain experts leverage historical data to identify the most likely events [47] following consultation with the domain experts.\nIn the top-1 similarity method, we aim to identify the meteorological condition that is most similar to the target forecasted meteorological condition. Subsequently, we utilize the climate events associated with the historical meteorological condition as the predicted climate events. The metric employed to determine the most similar meteorological condition is the Euclidean distance between the meteorological raster data of different variables:\n$h = argmin \\sum R_p - R_h|, with h \\in H$\nwhere V is the four variables mentioned in section 3.2, H is the set of historical date, Rp is the meteorological raster data used for"}, {"title": "4.2 Case Study and Qualitative Comparison to Existing Multimodal LLMs", "content": "In this section, we first conducted a case study for CLLMate and then compared the performance of baseline models and various multimodal LLMs employing meteorological raster data to demonstrate CLLMate's ability to comprehend meteorological information and predict potential weather and climate events.\nThe example is shown in Figure 5. In this example, the ground truth events, extracted from historical environmental news, include weather phenomena like \"cold air\", \"rainfall\", and \"rainstorm\u201d, as well as the resulting consequences such as \"flooding\" and \"traffic disruption\". CLLMate exhibits the capability to understand meteorological raster data and effectively capture corresponding patterns, accurately forecasting potential weather and climate events like \"cold air\" and \"rainstorms\". However, CLLMate predicts \"strong wind\", a phenomenon not present in the ground truth events. In terms of the consequences of weather, CLLMate accurately forecasts \"flooding\" and \"traffic disruptions,\" aligning with the ground truth events. Additionally, CLLMate forecasts \"water accumulation\", potentially linked to \"flooding\", and predicts \"traffic congestion\", a scenario similar to \"traffic disruptions\".\nThe top-1 similarity method, which identifies the most similar historical meteorological patterns, can predict some weather and climate events due to the strong correlation between these events and meteorology. However, this method lacks in-depth meteorological pattern analysis, resulting in an excess of historical events that diminish its predictive accuracy. The LLaVA-based tuning model's predictions center on \"high temperature,\" \"dehydration,\" and \"heat stroke,\" which is inaccurate.\nFor other multimodal LLMs, Gemini [59] fails to provide predictions, GPT-4 [44] offers inaccurate analyses based on visual analysis and fails to meet format specifications, while LLaVA outputs wrong information. Their failures may be caused by the complexity of the WCEF task and the lack of training datasets that hinder them from comprehending the task and aligning meteorological raster data with potential events effectively for precise forecasting.\nIt is remarkable that CLLMate demonstrates a capability to comprehend meteorological raster data and accurately forecast weather"}, {"title": "4.3 Quantitative Evaluation", "content": "In order to assess CLLMate quantitatively, we evaluated CLLMate, the top-1 similarity method, and the LLaVA-based tuning model using the evaluation dataset and the specified evaluation metric. The result of our evaluation can be referenced in table 1, where CLLMate outperforms both two baseline methods. We attribute the success of CLLMate to the following factors:\nKnowledge Graph Understanding. We converted the knowledge graph into natural language. Thus CLLMate can learn the relationship between weather and climate events to enhance its forecasting capabilities. For example, in the demonstration (Figure 5), CLLMate accurately predicts \"cold air\" followed by \"rainstorm\", which may be supported by three interconnected edges in the knowledge graph: \"cold air\" \u2192 \"rainstorm\u201d, \u201cstrong cold air\" \u2192 \"rainstorm\u201d, \"weak cold air\" \u2192 \"rainstorm\". Similarly, within the knowledge graph, there exist connections such as \"rainstorm\" \u2192 \"flooding\" and \"flooding\" \u2192 \"traffic disruption\" enabling CLLMate to make precise forecasts regarding \u201cflooding"}, {"title": "4.4 Ablation Study", "content": "The section investigates the influence of different components within our proposed CLLMate model through the process of ablating several components. The result is presented in Table 2."}, {"title": "4.4.1 Ablating the Knowledge Graph: w/o KG.", "content": "By skipping the training step of the CLLMate using the knowledge graph, we could observe a significant performance decline. We concluded that understanding the relationships between weather and climate events plays a pivotal role in enhancing CLLMate's forecasting capability. Furthermore, given its time-independence, historical knowledge regarding weather and climate events remains valid for future instances. Consequently, this reservoir of information serves as a valuable reference for CLLMate during forecasting."}, {"title": "4.4.2 Ablating the Statistical Context: w/o Context.", "content": "We removed the statistical meteorological context part from the multimodal instruction dataset to evaluate the impact of contextual information. The removal resulted in a performance decrease. It highlights the essential nature of the meteorological context in text form to guide the model towards more accurate predictions. We hypothesized that the information extracted from meteorological raster data by the vision model may focus more on the patterns over specific numerical values. The explicit statistical details of variables remain essential for the WCEF task, therefore."}, {"title": "4.4.3 Ablating the Meteorological Raster Data: w/o Raster.", "content": "Through the omission of meteorological raster data in the instruction-tuning process, we assessed its influence on the WCEF task. The absence of meteorological raster data adversely affects the performance of the LLM. This observation underscores the significance of aligning meteorological raster data with text to provide meteorological patterns, thereby enhancing the model's forecasting capability."}, {"title": "5 RELATED WORK", "content": "Weather and climate forecasting is a long-standing research problem in the field of environment. In this paper, we proposed a more challenging task to predict events in open vocabulary using LLMs. There are a few lines of works related to ours:"}, {"title": "5.1 Weather and Climate Events Forecasting", "content": "In the era preceding modern weather prediction, human experience is relied on to align different modalities. This involved connecting diverse natural signs, such as cloud patterns and animal behavior, with weather and their subsequent effects [52]. The transition from ancient to modern weather forecasting was marked with the first modern weather chart [2, 76]. In contemporary weather forecasting, a shift towards efficiency has occurred by consolidating various elements into a unified numerical framework. Two primary numerical methodologies are commonly employed in weather forecasting: numerical weather prediction, which entails utilizing numerical simulation methods [5, 36], and AI-based forecasting, which leverages data-driven approaches [7, 21]. Both of these methods focus on numeric. Then, the experts' expertise is relied on to align the numerical result with its potential consequences.\nWe introduce the WCEF task, where we advocate for the alignment of numerical variables and textual knowledge of events using Language Models (LLM) to directly forecast textual events. The area is in its initial stage with limited exploration within the environmental domain, primarily due to the complexities arising from the diverse modalities. We think that WCEF represents the next transition of weather forecasting methodologies."}, {"title": "5.2 Instruction Tuning of LLMs", "content": "Instruction Tuning is an indispensable stage of training LLMs, and aligned LLMs are strongly preferred by humans over original pre-trained LLMs [12, 79]. Basically, three kinds of methods are studied in collecting instruction datasets. Task-formatted datasets [13, 39, 41, 54, 64, 69] collect instances from a large number of NLP tasks, including natural language inference [43], sentiment analysis [37], machine translation [9], and many other supervision tasks. Those datasets include human-written templates to format the input of each task, such as \"Please translate the following English text into German.\" Another line of work collects authentic user queries, website Q&As, exam questions, and other sources of real-world tasks to create instructions datasets [14, 45, 81]. To lower the cost of manual collection of real-world tasks and human responses, a lot of work [40, 42, 58, 66] has tried to collect synthetic instruction data by prompting strong LLMs, like GPT4. For example, self-Instruct [63] uses GPT3 to generate new instructions and their corresponding responses iteratively with a seed pool of tasks.\nThe multimodal instruction tuning follows the above categorization. For example, [3] used data from various VQA tasks [19, 25, 30, 38]. The InternLM-XComposer2 [16] also used real human queries like ShareGPT [12]. Llava [34] used synthetic data collected with ChatGPT and GPT4. In our work, since we focus on the WCEF task, our method follows the task-formatted method. We collect a large amount of instruction data and turn them into natural language."}, {"title": "5.3 Multimodal LLM", "content": "With the advancement of LLMs, there's been a surge of research on building multimodal LLMs. Their research studies [72, 77] try to incorporate multiple types of data beyond just natural language, such as images, audio, and video. BLIP-2 [31] has developed a large-scale image captioning dataset, combining a language model with a vision encoder to create a multimodal model. Building on this, LLaVA [34] introduces a more cost-effective method for training multimodal models through visual instruction tuning. LLaVA-Next [33] further enhances single-image performance, albeit at the expense of a higher number of image tokens per token. The following multimodal LLMs, including QwenVL [3], CogVLM [62], deepseek-vl [35], intern-vl [11, 16], etc., all follow a similar architecture of LLAVA. Following them, we also use a visual encoder to encode the meteorological data and introduce MLP layers to convert the image"}, {"title": "6 CONCLUSION"}]}