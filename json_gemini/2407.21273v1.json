{"title": "Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net", "authors": ["Rohini Banerjee", "Cecilia G. Morales", "Artur Dubrawski"], "abstract": "Efficient intravascular access in trauma and critical care significantly impacts patient outcomes. However, the availability of skilled medical personnel in austere environments is often limited. Autonomous robotic ultrasound systems can aid in needle insertion for medication delivery and support non-experts in such tasks. Despite advances in autonomous needle insertion, inaccuracies in vessel segmentation predictions pose risks. Understanding the uncertainty of predictive models in ultrasound imaging is crucial for assessing their reliability. We introduce MSU-Net, a novel multistage approach for training an ensemble of U-Nets to yield accurate ultrasound image segmentation maps. We demonstrate substantial improvements, 18.1% over a single Monte Carlo U-Net, enhancing uncertainty evaluations, model transparency, and trustworthiness. By highlighting areas of model certainty, MSU-Net can guide safe needle insertions, empowering non-experts to accomplish such tasks.", "sections": [{"title": "1 Introduction", "content": "Trauma, the leading cause of death among young individuals in the U.S. [25], often results in blood loss, which requires rapid fluid resuscitation for vital organ oxygenation. In austere settings, accessing timely medical care can be challenging due to limited access, dangerous conditions, time constraints, or the absence of medical infrastructure, making expertise for optimal needle insertion sites critical. Autonomous robotic systems can assist in intravenous fluid administration when medical experts are unavailable, providing support in emergencies. These systems can also guide non-experts in accurate performance of phlebotomy tasks, empowering them to contribute effectively in dire medical situations.\nUltrasound imaging is widely used for locating vessels to enable fluid resuscitation due to its affordability, speed, safety, and portability, unlike CT or MRI imaging that are not portable and use ionizing radiation [9]. Despite advancements in autonomous needle insertion into blood vessels [9], a critical challenge persists: inaccurate predictions can lead to severe consequences. Failing to anticipate vessel structure during intravenous cannulation may result in catastrophic"}, {"title": "2 Related Works", "content": ""}, {"title": "2.1 Uncertainty Quantification in Deep Learning", "content": "Uncertainty quantification is vital in understanding the reliability of AI model predictions. Traditionally, the frequentist approach assumes a single point estimate of network weights, using estimated class likelihoods as confidence measures for predictions. However, studies have shown that these likelihoods often overestimate accuracy [11], and the popular metric used to quantify confidence, expected calibration error, has been criticized for bias and inconsistency [10]. This limits utility, motivating the need for alternative approaches to accurately quantify model uncertainty rather than just confidence.\nPredictive uncertainty comprises of aleatoric and epistemic components [8]. Aleatoric uncertainty accounts for inherent noise in observations, while epistemic uncertainty arises from limited training data and model parameter uncertainty. Recent advancements in Bayesian inference and Bayesian neural networks have provided robust frameworks to quantify both forms of uncertainty by estimating posterior distributions over model weights. Gal and Ghahramani [7] introduced Monte Carlo (MC) dropout for Bayesian inference in deep learning, leveraging dropout in convolutional layers for stochastic forward passes to approximate Bayesian variational inference. Bayesian approximation using MC dropout has been extensively applied: Kendall and Gal [13] developed Bayesian SegNet for scene understanding, while Dechesne and Lassalle [4] used it in U-Net for high-accuracy image segmentation. Seedat [22] proposed a human-in-the-loop system using model uncertainty. Yet, single-model architectures are now supplanted by model ensembles due to difficulties in capturing inherent variability."}, {"title": "2.2 Multistage Neural Network Ensembles", "content": "Training multiple individual models through model ensembling offers a range of tools to encourage member model diversity and improve overall accuracy. Di-"}, {"title": "3 Methods", "content": ""}, {"title": "3.1 Monte Carlo U-Net (MCU-Net)", "content": "We introduce stochasticity into our inference process by incorporating dropout layers into our chosen U-Net architecture, thereby enabling MC dropout, as in MCU-Net [22]. MCU-Net is henceforth referred to as our baseline model. Indiscriminately placing dropout after each convolutional layer can lead to reduced fit and poor test performance [13]. We opt to situate dropout layers in the decoder section of our U-Net instead. Each decoder block consists of two sets of convolutional layers (3x3 convolution filter, batch normalization, ReLU activation) and an attention block. This enables us to approximate Bayesian inference by conducting T forward passes, or MC samples, of the U-Net during testing. Our empirical results show no significant improvement beyond T = 30. Our model outputs both logits and logit variances [3] to use for segmentation and epistemic uncertainty maps, with $[p_t, \\hat{\\sigma}_t^2] = f_{\\hat{w}_t}(x)$ representing the t-th forward pass of MCU-Net with learned weights $\\hat{W}_t$. Given sigmoid activation, $\\sigma_{SIG}$, the ensemble prediction is aggregated by averaging individual model outputs, $\\sigma_{SIG}(p_t)$, across all T samples. Similarly, the raw epistemic uncertainty map is obtained by averaging logit variances across all MC samples."}, {"title": "3.2 Multistage U-Net (MSU-Net)", "content": "The MSU-Net architecture, illustrated in Fig 1, is structured in three main stages: (1) ensembling, (2) candidate selection, and (3) combining. In stage 1,"}, {"title": "4 Experiments", "content": "Dataset and Training We used a ultrasound scanning system described by Morales et al. [19] to scan the CAE Blue Phantom anthropomorphic gel model simulating femoral vessels. Equipped with a 5MHz linear transducer, the system can scan up to 5cm in depth, producing 2D transverse ultrasound images. Expert clinicians annotated these images using the Computer Vision Annotating Tool (CVAT) [23], followed by cropping and resizing to 256 \u00d7 256 pixels. The dataset was split into training (1392 images), validation (907 images), and testing (856 images). The validation set was further randomly split into two disjoint sets, VS1 and VS2.\nFor image segmentation, we employed U-Net architectures with a ResNet34 backbone in Pytorch, utilizing the Segmentation Models library [12] pretrained on ImageNet. To integrate MC Dropout, dropout layers with optimal rates of 0.4 and 0.5 were added after each ReLU activation in the decoder [13,14]. Training used a batch size of 8, Adam optimizer with a learning rate of 0.0001, and early stopping based on validation loss stabilization. MSU-Net incorporated bagging for ensembling and the plural-correlation coefficient as a correlation metric.\nDistribution Divergence Estimation Model quality hinges on uncertainty distribution: low for correct, high for incorrect predictions, enhancing calibration and user trust [24]. We utilize the R\u00e9nyi divergence (RD) statistic as our metric for comparison. It is a generalization of Kullback-Leibler (KL) divergence that measures the dissimilarity between two probability distributions p and q. van Erven and Harremo\u00ebs [5] relay an operational characterization of RD as the number of bits by which a mixture of two codes, p and q, can be compressed. For some measurable set Mo that p and q lie in and order $a \\in R \\setminus \\{1\\}$, RD of distribution p from distribution q is defined as:"}, {"title": "", "content": "$R_\\alpha (p || q) = \\frac{1}{\\alpha-1} \\text{In} \\int_{M_0} p^{\\alpha}(x)q^{1-\\alpha}(x)dx$"}, {"title": "", "content": "A nonparametric estimator of RD that is conditionally $L_2$-consistent using only k-nearest-neighbor statistics has been proposed to considerably reduce computational effort [21]. Let $X_{1:n_0} = (X_1, \\ldots, X_{n_0})$ be an i.i.d. sample from a distribution with density p and $Y_{1:n_1} = (Y_1, \\ldots, Y_{n_1})$ an i.i.d. sample from a distribution with density q. We denote $p_{k(i)}$ to be the k-th nearest neighbor of observation $X_i$ in $X_{1:n_0}$ and $v_{k(i)}$ the k-th nearest neighbor of $X_i$ in $Y_{1:n_1}$. With $B_{k,\\alpha} = \\frac{\\Gamma(k-\\alpha+1)\\Gamma(k+\\alpha-1)}{\\Gamma(k)^2}$, we can estimate the RD by:"}, {"title": "", "content": "$R_\\alpha (p || q) = \\frac{1}{\\alpha-1} \\text{In} \\frac{n_0}{n_1} \\sum_{i=1}^{n_0} \\Big(\\frac{(n_0-1)p_{k(i)}}{n_1v_{k(i)}}\\Big)^{1-\\alpha} B_{k,\\alpha}$"}, {"title": "", "content": "We use RD to measure the ability of our method to distinguish correct predictions (p) from incorrect predictions (q). We conduct permutation testing to assess deterministicity and bootstrapping to obtain confidence intervals for the results. Nearest neighbor estimators are sensitive to perturbations in the underlying distribution, and hence their limited variance cannot be consistently estimated by a na\u00efve Efron-type bootstrap [1]. Since this behavior may result in a non-negligible positive bias in bootstrap estimates, we instead apply a direct M-out-of-N (MooN) type bootstrap [26] for this metric, shown in Algorithm 1."}, {"title": "5 Results and Discussion", "content": "We evaluate MSU-Net using quantitative and qualitative metrics. To alleviate heavy class imbalance, we choose to average metrics over a predefined region of interest (ROI), shown in Fig. 2. Fig. 3 displays model uncertainty distributions"}, {"title": "6 Conclusion", "content": "This paper introduces MSU-Net, a multistaged Monte Carlo U-Net for uncertain ultrasound image segmentations. It improves model transparency and trustworthiness compared to standard U-Net by enhancing uncertainty evaluation, despite minimal additional training. Our framework sets a benchmark for future studies, offering qualitative maps for intuitive model assessment. While our preliminary results are limited to phantom data and binary image segmentation, we aim to validate these findings on live animal and human data in future work."}]}