{"title": "Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction", "authors": ["Hyogo Hiruma", "Hiroshi Ito", "Tetsuya Ogata"], "abstract": "This paper proposes a motion generation model, based on deep predictive learning framework. The model is designed to be capable of training on tasks that involve uncertainty, by adding a structure that enhance the applicability against adaptiveness. Concretely, the proposed model introduces a foresight prediction module to conventional RNN models, enables the model to capture accurate uncertainties, which induces adaptive behaviors at necessary situations.", "sections": [{"title": "I. INTRODUCTION", "content": "In the field of robot controlling, the introduction of deep learning methods has enlarged the application area of robot task execution. One representative approach is learning from demonstration (LfD), where neural network models are trained to capture the dynamics of robot tasks through imitation of demonstration data [1]. LfD benefits from its training-efficiency, as robust and flexible robot motions can be acquired from few sets of demonstrations.\nHowever, task environments may embrace hidden properties that cannot be fully covered by the demonstrations. One example is a door opening task, where the robot is trained to open the door without knowing which direction the door could be opened (i.e., pushing or pulling). As it is difficult for LfD methods to incorporate failure demonstrations, such as pushing a pull door by mistake, the method's generalization ability becomes limited in uncertain environments.\nTherefore, adaptiveness of the robot control model becomes important. This is because adaptive behaviors are necessary for reducing the uncertainty, which includes active interaction and feedback collection that aid online policy refinement. Therefore, the robot control models must be equipped with motivations to (1) correctly understand the dynamic uncertainty of the environment and to (2) exploratively derive the optimal action.\nPrevious research [2] proposed a model structure that captures time-dependent uncertainty of the task, but the deterministic nature of Recurrent Neural Networks (RNN) limited the derivation of explorative behaviors. Active In-"}, {"title": "II. METHOD", "content": "The proposed model follows the prediction scheme of deep predictive learning. As shown in Fig. 1(A) the input it is the sensor data at the current time step t, and the output Ot+1 is the expected sensor data at the next time step. The motion is generated by continuously predicting and applying the next sensor values to the robot controller.\nThe temporal relationships of sensor data are modeled using a variant of RNNs which incorporate stochasticity [2]. This model assumes that the output can be modeled as a Gaussian distribution, hence predicts the mean omean and variance o2ar of the expected output. The predicted variance is considered to reflect the uncertainty of the model, which dynamically change depending on the task situation.\nFig. 1(B) shows the Foresight Module, which is used to refine the hidden states of RNNs Ht to Ht, through closed-loop prediction, namely the foresight prediction. Here, closed-loop prediction is a method that performs an internal simulation, by recursively using the self-produced outputs as the next input data. By continuously predicting in closed-loop manner, the model can create future predictions of multiple time steps ahead, based on the belief and the dynamics that the model self-structured; the foresights can be predicted both during and after the training phase.\nThe foresights are predicted as follows. First, Ht is applied with n Gaussian noises that are sampled from N(0, f (o2ar)), where f (\u00b7) normalizes the input values to [0.05, 0.15]. Then, the noised hidden states Hr are used to predict foresights in T time steps ahead, which produces n simulated predictions Omean T and ovar T. Finally, Ht is determined by selecting the hidden state that led to a final output with the lowest expected variance.\nH\u2081 = argmin Hr ovar T\n(1)\nThe proposed model is trained through LfD as in [2], which optimizes the model to maximize the likelihood of the predicted motions."}, {"title": "III. EXPERIMENT AND RESULTS", "content": "The proposed model was evaluated on a door opening task as shown in Fig. 2. The door can be opened one of three directions but cannot be visually distinguished. The model was compared with a conventional RNN model, and its variant which applies random noises to the hidden states at each time step. The models were trained on five demonstrations of door opening motions on each direction, using camera data and joint angle data as inputs.\nThe results showed that the proposed method was able to predict adaptive motions. The success rates were over 80% at the early stage of training, which is higher than those of fully trained conventional models (see details in the video).\nThe model was able to diverge its motion prediction on all three motions, according to the presented door type. As Fig. 3 shows, the trajectory of the RNN hidden states during online prediction fluctuated between those of different motion types. This indicates that the proposed model was able to self-organize a hidden space that can stably transition between different policy attractors based on the acquired feedback.\nConversely, conventional models failed in diverging between different motions, which only succeeded in predicting two out of three motions at the most. This was likely caused by how the model embedded the uncertainty in the RNN hidden states, as described in Fig. 4. Fig. 4 compares on Lyapunov exponents, which reflect the quantity of possible divergence at each time step. The conventional RNN model had small values throughout the task, indicating that small uncertainty, or chaotic properties, were embedded in the model. In contrast, the proposed model and the noised variant showed clear peaks, at when the door handle was grabbed, and when the door started to move, respectively. Such difference suggests that the proposed model embedded the uncertainty on its policy, or the cause, whereas the noised variant embedded on the resultant observation, or the effect. This is can be interpreted that the foresight prediction biased the model to incorporate various future consequences that affect the policy selection. This property is beneficial for implementing adaptive behaviors, because the construction of chaotic attractors is essential for deriving diverse motions during exploration."}]}