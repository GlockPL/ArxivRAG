{"title": "Enhancing Phishing Email Identification with Large Language Models", "authors": ["Catherine Lee"], "abstract": "Phishing has long been a common tactic used by cybercriminals and continues to pose a significant threat in today's digital world. When phishing attacks become more advanced and sophisticated, there is an increasing need for effective methods to detect and prevent them. To address the challenging problem of detecting phishing emails, researchers have developed numerous solutions, in particular those based on machine learning (ML) algorithms. In this work, we take steps to study the efficacy of large language models (LLMs) in detecting phishing emails. The experiments show that the LLM achieves a high accuracy rate at high precision; importantly, it also provides interpretable evidence for the decisions.", "sections": [{"title": "I. INTRODUCTION", "content": "Phishing is a prevalent form of cybercrime that involves the use of deceptive emails to trick recipients into divulging sensitive information, such as passwords, credit card numbers, and other personal data [16]. Modern phishing schemes are highly sophisticated, employing advanced social engineering tactics to increase their effectiveness [25]. In a report published by the Anti-Phishing Working Group (APWG) in 2024, it was noted that there were 116,473 unique phishing email campaigns observed in the first quarter of 2024 [1].\nResearchers have made a concerted effort to develop effective solutions for the automatic detection of these threats. To fortify defenses against phishing emails, numerous studies have focused on machine learning (ML) and deep learning (DL) algorithms that facilitate the analysis and classification of emails [2, 11, 18, 19].\nCurrent approaches in ML-based phishing detection can be categorized by the feature sets utilized with anti-phishing techniques: Sender Information, URL Analysis, Email Content Analysis, Header Information, and Stylometric Features [3, 19, 39, 24].\nHybrid feature selection often involves combining multiple feature selection methods to improve the accuracy and efficiency of identifying phishing emails [2, 26].\nHowever, ML/DL models can overfit the training data, performing well on known examples but poorly on new, unseen phishing attempts, and lack the ability to learn and adapt to evolving attack patterns. As a result, they require frequent retraining to keep up with changes in data [11].\nLarge Language Models (LLMs), such as OpenAI's GPT-4 [23], are advanced DL models trained on vast amounts of text data, and LLMs can perform tasks without dedicated prior training [17]. These models leverage the transformer architecture to understand and generate human-like text, making them highly effective in natural language processing (NLP) tasks [22]. The capabilities of LLMs extend beyond simple text generation; they can analyze and interpret complex language patterns, detect anomalies, and identify subtle cues indicative of phishing attempts. One of the key advantages of LLMs in phishing detection is their ability to understand context and semantics [17]. LLMs can analyze the content of emails holistically, considering factors such as tone, intent, and linguistic nuances [27]. This enables LLMs to detect phishing emails that may bypass conventional filters by mimicking legitimate communication styles.\nIn this study, we propose using LLMs to detect phishing emails through hybrid feature selection. Utilizing a diverse dataset of phishing emails, we include a mixture of datasets featuring different types of phishing (such as spear phishing, traditional phishing, and generative AI (GenAI) phishing). With designed prompt engineering, LLMs leverage their powerful analytical capabilities to detect phishing emails, providing detailed explanations for their classification decisions. We will evaluate and compare the performance of four state-of-the-art LLMs with detection accuracy on their capability for phishing detection. Importantly, we further analyze the result generated by the LLMs on subsequent decisions on false positives and define the current gap in LLM phishing detection.\nThe structure of the paper is as follows: Section II provides an overview of the background of email phishing detection research of machine learning algorithms to classify emails based on the selected features and current studies and gaps on LLMs in cybersecurity and phishing email. Section III outlines the methodology and the decision-making feature selection. Section IV depicts the experimentation results, and Section V discusses the outcomes of the experimentation and indicates the future directions for this research. Section VI concludes the paper."}, {"title": "II. LITERATURE REVIEW (RELATED WORK)", "content": "Before utilizing LLM on phishing detection, many research papers have been published so far on the phishing detection problem using ML and DL approaches on analyzing the email's structure, such as headers information, URLs, syntax, attachments, etc. or on the email's body content [2, 4, 13].\nEarlier works have primarily focused on URL-based feature analysis for phishing detection by analyzing its characteristics and patterns using ML [40, 41]. However, relying solely on URL-based features for phishing detection has its limitations. URLs can often be long and complicated, making them difficult to analyze briefly. Spammers take advantage of URL shorteners (tools like TinyURL) [4] to create shorter, more manageable URLs. These shortened URLs can be included in emails to hide the actual destination of the link. Phishers can obfuscate (hide) the true nature of URLs using these tools, making the links appear legitimate"}, {"title": "III. METHODOLOGY", "content": "This section discusses the mythological steps to implement the phishing email detection framework that uses LLM to detect phishing emails. The general framework throughout includes dataset consideration, data processing, model section, generating prompts, and evaluation.\n\nData selection is a crucial part of any machine learning and deep learning research. The diversity of the data can significantly influence the model's evaluation performance."}, {"title": "A. Data Acquisition", "content": "Data selection is a crucial part of any machine learning and deep learning research. The diversity of the data can significantly influence the model's evaluation performance."}, {"title": "B. Data Processing", "content": "Each dataset has its own unique structure, necessitating the development of a standardized data pipeline to ensure consistency across all datasets. The pipeline converts each dataset into a uniform format with two columns: \"Email\" and \"Class.\"\n\u2022 Email: This column will contain the entire email content, including the subject, sender, and body of the email. The format will be: SUBJECT: <subject>, FROM: <sender>, EMAIL: <email body>.\n\u2022 Class: This column will categorize the emails into two standardized terms: \"Phishing\" (for fraudulent emails) and \"Legit\" (for legitimate emails).\nIn email communication, the incorporation of extensive HTML structures can enhance visual appeal. Therefore, the raw HTML content for emails is extracted into diverse text. From a content analysis perspective, many HTML tags are unnecessary and can be removed. These tags do not contribute to the actual content of the email. This study builds a custom HTML parser that extracts the HTML content into our optimized removal. This study retains only essential HTML elements, specifically the <a> and <img> tags while focusing on pertinent attributes such as href and src. To mitigate long URL tokens, we limit the preservation of URL paths to the first ten tokens [28]. Additionally, it is noteworthy that some emails contain hidden text formatted with small font size (using style=\"font-size:0px). This hidden text often consists of randomly generated content intended to evade detection by users and security systems. These design choices warrant further exploration to understand their implications for email security and user awareness.\nFor handling email content encoded in Multipurpose Internet Mail Extension (MIME) base 64 format, a method for encoding binary data into text. There can be problems with decoding these emails properly due to issues with the encoding. This means that the email content might not be correctly converted back into its original format. The process involves first detecting if the email body is in base 64 format."}, {"title": "C. Development of Evaluation Prompt", "content": "Prompt engineering, which involves customizing input prompts, can enhance the accuracy of LLM responses. This study will apply the prompt engineering technique with role assignment, where the model is instructed to respond as a specific type of expert or in a particular style. The persona we give to the model is a cybersecurity expert who specializes in detecting phishing emails with a guide to the model on what aspect to look at to determine phishing email.\n\"You are a cybersecurity expert specialized in detecting and analyzing phishing emails. Analyze the provided email (including subject line, body text, sender information, and links) to determine whether it is a phishing email or a legitimate email. Your result must follow the provided function call.\"\nIn response to a given prompt, the models will analyze the email based on the given prompt generate a response assign it to either the 'Phishing' or 'Legit' categories. Accompanying this classification is a phishing risk score, ranging from 'low', 'medium', or 'high', reflecting the likelihood that the email is a phishing attempt. Additionally, the framework elaborates on the rationale for its decision, offering a transparent view of its analytical process. The final output is delivered as a JSON response:\n\u2022 \"Is Phishing\": A Boolean variable indicating whether the email is phishing or not.\n\u2022 \"Risk\": where the LLMs indicated the certainty of this email being phishing.\n\u2022 \"Social Engineering Elements\": A list of Social Engineering that the LLMs found in this email.\n\u2022 \"Actions\": A list of recommended actions to apply.\n\u2022 \"Reason\": A summary of the found from the LLMs on why this email is phishing (or legitimate)."}, {"title": "D. Selection of Language Models", "content": "This study will focus on examining the models that are the most widely used open-source models in current research: Llama-3.1-70b, gemma2-9b, Llama-3-8b, and Mistral-large-latest (123b) respectively. Additionally, Llama 3.1 was a newly released model at the time of this experiment, providing an opportunity to evaluate its performance in real-world scenarios. The selection of models with varying parameter sizes, from small to medium, was intentional for resource efficiency."}, {"title": "E. Evaluation Metrics", "content": "To facilitate a comparison several classification metrics are considered including accuracy, precision, recall, and F1-score metrics shown in Eq. 1, 2, 3, and 4, here the TP, TN, FP, and FN, denote true positive, true negative, false positive, and false negative values respectively.\nAccuracy = $\\frac{TP + TN}{TP + TN + FP + FN}$  (1)\nPrecision = $\\frac{TP}{TP + FP}$  (2)\nRecall = $\\frac{TP}{TP + FN}$ (3)\nF1 = 2 x $\\frac{Precision \\times Recall}{Precision + Recall}$  (4)"}, {"title": "IV. RESULTS", "content": "The performance of all four LLMs can be seen in Table 2. All the LLMs achieved more than 80% accuracy in identifying phishing emails. With three models, Llama-3.1-70b stands out with the highest accuracy rate of 97.21%, closely followed by Gemma2-9b at 95.29% and Llama-3-8b at 92.39%, achieved accuracy more than 90% and Mistrial-large-latest 87.95%. Although all models have shown remarkable performance in accuracy, we need to consider other metric indicators to evaluate the overall performance. In terms of precision within the recall rate, Llama-3.1 has a high precision of 98.10% and a recall of 98.00%, indicating its effectiveness in accurately identifying and demonstrating its strong capability in detecting phishing emails. The low false positive rate of 4.7% suggests it is also good at avoiding legitimate emails being flagged as phishing, which can lead to reduced trust in the detection system.\nGemma2 compared to Llama-3.1 indicates it may generate more false positives with a false positive rate (FPR) of 15% indicating it has a higher chance of predicting non-phishing (legit) emails as phishing. Observed the overall accuracy result with FPR and FNR, with the accuracy rate decreasing, the corresponding FPR increases and FNR decreases, generating a negative correlation between the accuracy rate and FPR and a positive correlation between FNR for the four models. The testing dataset used for evaluating the model is imbalanced, with 70% phishing emails and 30% legitimate emails. In such an imbalanced dataset, a model with a high FPR suggests that it's too aggressive in classifying emails as phishing. This aggressiveness might be due to the model's tendency to favor the majority class (phishing emails) rather than performing a thorough analysis of each email. As a result, Mistrial achieves a high recall rate, meaning it correctly identifies a large proportion of actual phishing emails; however, this comes at the cost of lower precision and F1 score. Lower precision indicates that a significant number of legitimate emails are incorrectly classified as phishing (false positives). The F1 score, which is the harmonic mean of precision and recall, is also lower, reflecting the trade-off between these two metrics. Essentially, while Mistrial is good at catching phishing emails, it also incorrectly flags many legitimate emails, reducing its overall effectiveness.\nA reliability score quantifies how dependable an LLM is in generating correct, particularly in phishing email identification, where decision-making depends on the accuracy of the predictions. The reliability score is determined based on the predicted risk and the real class. With correct predictions, each LLM received one score on reliability. However, to increase the robustness of the models, we will assign half a mark if the predicated risk is medium, and the true class is phishing."}, {"title": "V. DISCUSSION", "content": "In this section, we further analyze the detection capabilities of phishing email results generated by LLMs. Figure 4 presents an example of a phishing email sourced from our dataset. To safeguard user privacy, all sensitive information has been replaced with the placeholder \"phishing@pot\" [10].\nThis email masquerades as a system notification from Facebook, informing the user that their account has been accessed from a new device, and requests verification of the user's involvement in this action. At first glance, the visual structure of the email does not provide clear indications of its phishing nature. However, a closer examination reveals critical discrepancies: the sender's email address does not originate from the domain facebook.com, and the link embedded in the \"Report the user\" button redirects to a fraudulent website.\nAll LLMs are capable of accurately identifying suspicious elements in this email. A report from Llama 3.1 indicates that the email address '5a83h@92e4fsmb2e.com' does not match the displayed sender, which is denoted as 'Facebook.' Furthermore, the email contains potentially harmful links: 'ssecnewsso' is present in both the 'Report the user' and 'Yes me' buttons. Additionally, the email includes a hidden image with a suspicious URL, http://thema214.com/track/o49, which may be intended for tracking purposes.\nGemma2 identifies several linguistic indicators that suggest potential phishing activity. The first element is the use of the recipient's username in the greeting, as exemplified by the phrase \"Username in Greeting.\u201d The rationale for this observation is that it is atypical for official correspondence to include the recipient's username. Additionally, the email employs generic greetings, which lack personalization, such as \"Hi phishing@pot.\" Furthermore, there is an element of urgency conveyed by the statement that someone attempted to log into the account. Finally, the email exhibits poor grammar and inconsistent formatting, which serves to undermine its legitimacy."}, {"title": "B. Limitation in Detection", "content": "This section addresses the key issues identified in the overall study. In Section IV, we examine the performance in terms of FPR, focusing on emails misclassified by LLMs. Through analysis supplemented by human feedback, we observed the limitations in the dataset's representation. Specifically, we identified cases where emails were labeled as phishing despite lacking characteristics typically associated with phishing attempts, such as no requests for any personal information or urgency cues, suggesting that the data may have been incorrectly annotated. Another hypothesis that emerged regarding this situation is that certain emails might lack phishing indicators, such as urgent content, but could include malicious URLs not captured due to the conversion of raw email data into plain text in the original dataset. This highlights the potential loss of critical features during preprocessing, which warrants further investigation.\nFor actual misclassified emails, we observed that LLM misclassified phishing emails that show personalization such as addressing the recipient by name, referencing their current position and company, and having a clear and relevant purpose. This level of personalization makes the LLM consider emails to appear legitimate. Additionally, the tone and language used are professional and consistent with a genuine offer. However, this type of email is spearing phishing that targets specific individuals to steal sensitive information.\nWe can observe the same limitations when solely analyzing URL-based features for phishing detection. LLMs might incorrectly flag some legitimate emails that contain uncommon URL domains as phishing emails. LLMs might misinterpret these materials, raising concerns that they could be phishing attempts to compromise personal information. Additionally, we observed that phishing emails containing"}, {"title": "C. Integration with Existing Systems", "content": "Integrating LLMs with existing services represents a transformative approach to enhancing security functionality and efficiency in current cybersecurity. To automatically detect phishing emails with existing email services, we utilized automated routine tasks like email analysis, threat detection, and report generation using the LLM.\nFigure 5 presents an overview of the automated routine framework's architecture that harnesses the power of LLMs. The framework can be divided into the following steps:\n1) New Email Received: The routine will be triggered when a new email is received in the user mailbox.\n2) Filter emails that come from a Trusted source: The system task will first filter emails based on the sender's information such as emails from a legitimate office address and email addresses that are on whitelisting.\n3) HTML parsing: Retrieve the MIME type of subject, from, and the \"text/html\" body of the email. Applied the data cleaning processing proposed in section III part B for HTML parsing.\n4) Run OpenAI API request: After processing, apply the prompt response request with the setting defined in section III part C on Llama3.1-70b.\n5) Email classification result: Once the email is identified as phishing, report this email as phishing to the email system, move the email to the spam folder, and send the report result generated by the LLM to the user explaining why this email is phishing and corresponding actions to apply. The following is an example summary report generation using the LLM on the phishing email shown in figure 4.\nThis email displays multiple red flags that indicate it is a potential phishing attempt. The sender's email address is suspicious, the greeting uses the recipient's username, and the email contains urgent calls to action and clickable links that are likely malicious. It is important to exercise caution and follow the recommended actions to protect yourself from account compromise.\nDo not interact with any links or buttons in the email. Verify account activity through a secure login on the official Facebook website. Report the email to Facebook's support team.\nThe integration of LLMs in email services enhances the identification of emails that were not flagged by existing systems. This technology also aids in recognizing new phishing and social engineering tactics that are currently being addressed in defense systems. The Microsoft Defender team is beginning to develop LLMs to improve threat classification, which helps keep malicious emails out of users' inboxes. Additionally, it provides Security Operations (SecOps) teams with better insights into attacker techniques [35]. As industries increasingly explore the potential of LLMs, it becomes critical to understand their implementation within established systems to maximize benefits while addressing phishing challenges."}, {"title": "D. Feature improvements", "content": "In part B, we reviewed and discussed some limitations of our current studies by analyzing the false positives. However, these false positives also point out the weakness of LLMs, which attackers can intentionally exploit. This section will discuss some potential improvements that can be made to the feature studies.\nLLMs can be vulnerable to adversarial attacks where malicious actors craft emails specifically designed to bypass detection [36]. Research on improving the robustness of LLMs against phishing attacks is still in its early stages. Robustness against diver Attacks can be achieved with fine-tuning training the LLM to recognize and learn from a wide range of examples of comprehensive phishing attack types [37].\nOur diverse dataset lacked some phishing email characteristics, leading to potential misinterpretations. Al-Subaiey et al. [38] created a comprehensive dataset by combining six widely used spam email datasets, carefully selected based on their unique attributes from various sources, to create a comprehensive resource for analysis. This dataset is notable for offering one of the largest collections of approximately 82,500 emails, providing a rich foundation for feature research in phishing email detection.\nLLMs are not specifically designed to identify URLs or domain names. As a result, they might mistakenly flag URLs from uncommon websites as suspicious or phishing attempts. To address this issue, the proposed solution involves adding a new URL analyzer layer to the system architecture. This layer will extract all URLs from the email and then use an API endpoint security tool (virustotal.com) to generate a security report on each URL. This report will assist the LLM in making more accurate decisions about whether an email is a phishing attempt. Essentially, this approach aims to"}, {"title": "VI. CONCUSSION", "content": "This study proposed and studied an LLM-based phishing email detection system. The results showed that our system using Llama-3.1-70b achieved an accuracy of 97.21%, outperforming other models. Through detailed analysis of LLM performance and responses, we can confirm the ability of LLMs to extract key hybrid features in emails, prioritize them, and generate accurate responses, assisting the effectiveness of the defense team in phishing detection. However, we also address several challenges associated with using LLMs in phishing detection and propose potential solutions to these challenges, such as improving LLM robustness with phishing email-specific data and incorporating an extra URL detection layer.\nThe rapid development of LLMs with greater performance capabilities offers new opportunities for in-depth research in this field. These advanced models can potentially provide more effective tools and techniques for identifying and mitigating phishing threats, thereby enhancing cybersecurity measures."}]}