{"title": "Measuring Copyright Risks of Large Language Model via Partial Information Probing", "authors": ["Weijie Zhao", "Huajie Shao", "Zhaozhuo Xu", "Suzhen Duan", "Denghui Zhang"], "abstract": "Exploring the data sources used to train Large Language Models (LLMs) is a crucial direction in investigating potential copyright infringement by these models. While this approach can identify the possible use of copyrighted materials in training data, it does not directly measure infringing risks. Recent research has shifted towards testing whether LLMs can directly output copyrighted content. Addressing this direction, we investigate and assess LLMs' capacity to generate infringing content by providing them with partial information from copyrighted materials, and try to use iterative prompting to get LLMs to generate more infringing content. Specifically, we input a portion of a copyrighted text into LLMs, prompt them to complete it, and then analyze the overlap between the generated content and the original copyrighted material. Our findings demonstrate that LLMs can indeed generate content highly overlapping with copyrighted materials based on these partial inputs.", "sections": [{"title": "CCS Concepts", "content": "* Computing methodologies \u2192 Natural language generation; * Social and professional topics \u2192 Copyrights."}, {"title": "Keywords", "content": "Large Language Model, Copyright, Infringement, Partial Information Probing, Rouge Score, AI, Data Mining"}, {"title": "1 Introduction", "content": "The rapid advancement of Large Language Models (LLMs) in recent years has demonstrated their remarkable capabilities in assisting people with a diverse range of tasks [16, 20]. However, the growing use of LLMs has also given rise to several concerns, particularly regarding copyright infringement [18]. Recently, there has been a surge in litigation concerning alleged copyright violations by LLMs [9, 10]. Consequently, investigating potential copyright infringement by LLMs has become a critical area of scholarly inquiry in contemporary research.\nSeveral studies have demonstrated that LLMs are indeed capable of outputting copyrighted material [8, 14]. Prior research has predominantly focused on exploring the training data of LLMs, a line of inquiry that has yielded notable advancements [6, 7, 15]. However, this approach has limitations: researchers can only infer the use of specific content in LLMs' training data through certain indicators and have not been able to prompt LLMs to directly disclose their training content. Consequently, recent research has shifted focus toward the outputs of"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Copyright Law in the United States", "content": "Copyright protection is automatic from the time the original work is fixed in any tangible medium. Copyright protection for individual creators usually lasts for 70 years after the author's death [11]. Table 1 illustrates which original works are protected by copyright."}, {"title": "2.2 LLMs and Copyright", "content": "Since the potential for copyright infringement by LLMs was first proposed, several methodologies have been proposed to explore this problem. (A) Document-level membership inference attacks have been demonstrated to be highly effective on OpenLlama-7b [6]. (B) Copyright traps represent an enhancement of document level membership inference attacks, employing specific traps to determine whether certain content was utilized in the training process of an LLM [7]. (C) MIN-K% PROB determines whether text belongs to the training data by analyzing token probabilities [15]. (D) Direct Probing and Prefix Probing concentrate on testing the likelihood of LLMs producing infringing content [2]. (E) COPYBENCH, a methodology designed to measure an LLM's capacity to replicate both textual and non-textual content [1].\nThe present study diverges from previous work by focusing on utilizing fragments of copyrighted material to test whether the content generated by LLMs might contain infringing elements. Building on this foundation, we employ iterative probing to observe whether LLMs can produce substantial amounts of copyrighted content when users provide only minimal textual input. Finally, we explore the factors influencing the degree of overlap between LLMs' completions and copyrighted materials."}, {"title": "3 Methods", "content": "This section provides a detailed description of the probing methods used in this study."}, {"title": "3.1 Partial Information Probing", "content": "We constructed multiple datasets to evaluate the infringing behavior of LLMs. These datasets were derived from different textual sources, including bestselling novels, press releases, and popular song lyrics. We segmented each text into multiple samples, with each sample containing a fixed number of words. Subsequently, we utilized the initial portion of each sample as a prefix, which was then provided to the LLMs for completion. For instance, we extracted 20 samples from \"The Hobbit\", each comprising 50 words. The first 20 words of each sample were used as a prefix, which was then input into the LLMs for text generation. To reduce the randomness of the LLMs' output, we set the temperature to 0. While this does not completely eliminate randomness, it significantly reduces it. We then compared the generated content with the remaining part of each sample and calculated the Rouge-L Score."}, {"title": "3.2 Evaluation of Influencing Factors", "content": "This study aims to identify factors that may influence the likelihood of LLMs generating infringing text, following the establishment of their capability to output such material. Our objective is to adjust and test various factors that could affect LLMs' generation of infringing content and to observe whether significant changes occur in the Rouge-L scores of the generated text. For example, if we hypothesize that an LLM's parameter size affects its output, we would conduct tests on models with different parameter sizes to"}, {"title": "3.3 Iterative Prompt", "content": "Having confirmed that LLMs can generate infringing text based on partial content from copyrighted materials, we aim to employ iterative prompting to potentially elicit more infringing content from these models. Specifically, our methodology will proceed as follows: first, we provide a segment of copyrighted material as a prompt and instruct the LLMs to complete it. Then, we use the generated completion as a new prompt, again requesting the LLMs to extend it. This process will be repeated multiple times to observe whether the LLMs can produce additional material that may constitute copyright infringement."}, {"title": "4 Experiment", "content": ""}, {"title": "4.1 LLMs Tested", "content": "We employ multiple LLMs as test subjects, including Llama (Llama2 and Llama3), GPT (GPT-3.5-turbo, GPT-4-turbo, GPT-40), Qwen2 [17], and Yi [19]."}, {"title": "4.2 Datasets", "content": "We selected three types of copyright protected materials for testing: novels, news and lyrics. For the novel section, we chose \"The Hobbit\" and the first three books of the \"Harry Potter\" series. For the news articles section, we selected five articles about the 2014 World Cup reported by The New York Times and The Wall Street Journal. For the song lyrics section, we chose five popular songs from the period of 2010 to 2020. We obtained text documents of these works and extracted samples from them for our experiments."}, {"title": "4.3 Evaluation Metrics: Rouge Score", "content": "This study proposes using Rouge-L to evaluate the degree of overlap between content generated by LLMs and copyrighted material. Rouge is a widely used metric for automatically evaluating text generation tasks, such as machine translation, automatic summarization, and text generation. It assesses the quality of generated text by measuring the overlap between the system-generated content and reference answers. Rouge-L is a variant within the Rouge evaluation framework, where 'L' stands for Longest Common Subsequence (LCS) [3-5].\nRouge-L is calculated as follows:\n$R_{lcs} = \\frac{LCS(X, Y)}{m}$   (1)\n$P_{lcs} = \\frac{LCS(X, Y)}{n}$   (2)\n$F_{lcs} = \\frac{(1 + \\beta^2)R_{lcs} P_{lcs}}{R_{lcs} + \\beta^2 P_{lcs}}$   (3)\nLCS (X, Y) denotes the length of the longest common subsequence between sequences X and Y, with m and n being the lengths of X and Y, respectively. R_lcs, P_lcs, and F_lcs represent the recall, precision, and F-measure based on the longest common subsequence. The F-measure is especially sensitive to the trade-off"}, {"title": "4.4 Result of Infringing Output", "content": "We tested the ability of the aforementioned models to output copyright protected material and calculated the Rouge-L score to evaluate the results. The findings are presented in the form of charts."}, {"title": "4.4.1 Novel", "content": "As shown in Table 2, the maximum Rouge-L score for each model is 1. This demonstrates that every LLM has the capability to output content from the samples that was not included in the prompts, i.e., content that is supposed to be copyright protected."}, {"title": "4.4.2 News", "content": "As shown in Table 3, while the LLMs are not highly proficient at reproducing the complete content of news articles, they can still generate small portions of copyright protected material. Compared to the results for novels, it is evident that LLMs have certain limitations when it comes to generating content from news articles."}, {"title": "4.4.3 Lyrics", "content": "As shown in Table 4, the maximum Rouge-L score for each model is 1, indicating that all these LLMs can reproduce the original lyrics. Additionally, GPT-4-turbo performed exceptionally well, significantly outperforming the other LLMs."}, {"title": "4.5 Analysis of Influence Factors", "content": "Based on the above results, we observe that LLMs can output copyright protected material. Next, we will analyze the factors that influence LLMs in generating such content from the following four aspects."}, {"title": "4.5.1 Parameter Scales", "content": "Among the LLMs selected for this study, all except GPT have disclosed their parameter scales. For example, Llama2 is available in three parameter scales: 7b, 13b, and 70b, while Qwen2 offers four parameter scales: 0.5b, 1.5b, 7b, and 72b. Below, we analyze the results across different parameter scales.\nWe consider outputs with a Rouge-L score exceeding 0.85 to be highly similar to the original copyrighted content. Our analysis will proceed as follows: first, we will compare the mean Rouge-L scores across each parameter scale. If the means are comparable, we will then examine the frequency of results with Rouge-L scores surpassing 0.85.\nAccording to Table 5 and Figure 2, we can visually observe that for Llama2, Llama3, and Yi, a larger parameter scale results in a higher similarity between the generated content and the original text. Although the average Rouge-L score for Qwen2 does not show a significant difference across scales, the number of completions with a Rouge-L score greater than 0.85 is much higher for Qwen2-72b compared to the other parameter scales. From this, we can conclude that models with larger parameter scales have better memory and are more likely to output content that closely matches the original text."}, {"title": "4.5.2 Open-Source vs. Closed-Source", "content": "Closed source LLMs typically exhibit superior performance compared to their open-source counterparts. Our objective is to analyze whether there are discernible differences between open-source LLMs (such as Llama, Qwen, and Yi) and closed-source LLMs (such as GPT).\nAs shown in Table 6, GPT models outperform most open-source models, with the exception of Llama3. Llama3, currently the most powerful open-source model, significantly outperforms its predecessor, Llama2.\nGiven that OpenAI has not disclosed any technical details about GPT-4, we cannot definitively determine the factors contributing to its superior ability to generate copyrighted text compared to"}, {"title": "4.5.3 Text Type", "content": "For this experiment, we selected three different types of texts-novels, news articles, and song lyrics-to ensure the generality of the results. All these texts are copyright protected. Based on the previous experiments, we can also analyze whether LLMs are more likely to output copyright protected material from certain types of texts."}, {"title": "4.5.4 Different Output Lengths", "content": "We also tested whether the length of the output affects the content generated by LLMs. In the LLM settings, max_tokens specifies the maximum length of the output content. Therefore, we tested the Rouge-L Score for the LLMs with max_tokens set to 50, 100, 200 and 300. Due to the length limitations of news articles and song lyrics, we only tested the LLMs' output for novel content. To control variables, the length of the input prompt in all tests in this section was consistently 50 tokens. Table 8 shows the average Rouge-L Scores and the number of scores above 0.85 for different max_tokens. To facilitate observation, we also created Figure 5. As shown in Figure 5, the average Rouge-L Score unexpectedly showed a brief upward trend as"}, {"title": "4.6 Iterative Prompting Result", "content": "We utilized the first, second, and third books of the \"Harry Potter\" series as test materials. The initial sentence of each book was provided to the LLMs as a prompt, followed by iterative prompting, wherein each completion generated by the LLMs was used as a new prompt. The results are illustrated in Figure 8. Our findings indicate that this method indeed enables LLMs to generate more copyrighted content. However, after a certain number of iterations, the LLMs began to produce content entirely unrelated to the copyrighted material. We hypothesize that this deviation may occur due to the LLMs generating content divergent from the original material in one iteration, consequently leading to low overlap in subsequent completions."}, {"title": "4.7 Summary", "content": "In our experiment, the LLMs successfully reproduced text highly similar to the copyrighted material based on the partial content we provided. Models with larger parameter sizes demonstrated a stronger ability to reproduce the copyrighted material. Different text types and variations among LLMs also influenced the final results. Finally, we discovered that each LLM has a certain threshold: when the maximum output text length exceeds this threshold, its reproduction ability significantly weakens."}, {"title": "5 Conclusion", "content": "Our experiment simulated a scenario where individuals obtain a small segment of a copyright protected work and then use current LLMs to generate the subsequent content based on this segment. The results demonstrate that LLMs are capable of generating copyright infringing materials. We identified four factors that influence LLMs' propensity to output infringing content, with the scale of parameters and maximum output length having a significant impact. Additionally, we found that iterative prompting enables LLMs to generate more content that could potentially constitute copyright infringement. However, after a certain number of iterations (for instance, the third output in our experiment), the LLMs began to produce content entirely dissimilar to the original material."}, {"title": "6 Limitations and Future Research Directions", "content": "The datasets employed in this study primarily focus on English-language texts, which may not accurately reflect the behavior of LLMs with copyrighted texts in other languages or other types of materials (such as code). Furthermore, our exclusive use of Rouge-L as the evaluation metric may lead to misclassification for certain samples. Although this study utilized multiple LLMs, numerous recently released models remain untested. These newer models may possess more robust defense mechanisms, potentially reducing their likelihood of generating infringing content. We also experimented with a method that allows LLMs to self-iterate in generating prompts. While this approach led to the production of more infringing content, there remains substantial room for improvement. Potential refinements could include adjusting the maximum output length for iterations to avoid triggering LLMs' safety measures, as well as exploring the use of more powerful models.\nWe propose three directions for future research. First, developing suitable algorithms using LLMs with publicly available training data and details would allow researchers to input a small segment of content and generate extensive subsequent content. Second, examining potential differences between texts in various languages is crucial. For example, comparing English and Chinese texts is important since Chinese uses a completely different tokenizer from English, implying significant differences in training details. To ensure the legality of LLM outputs, special attention must be paid to textual content across different languages. Third, in relation to the Iterative Prompting approach, one could explore the application of jailbreak attacks on LLMs to circumvent their safety protocols, potentially inducing the generation of more infringing content."}]}