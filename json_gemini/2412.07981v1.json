{"title": "Where Common Knowledge Cannot Be Formed, Common Belief Can \u2013 Planning with Multi-Agent Belief Using Group Justified Perspectives", "authors": ["Guang Hu", "Tim Miller", "Nir Lipovetzky"], "abstract": "Epistemic planning is the sub-field of AI planning that focuses on changing knowledge and belief. It is important in both multi-agent domains where agents need to have knowledge/belief regarding the environment, but also the beliefs of other agents, including nested beliefs. When modeling knowledge in multi-agent settings, many models face an exponential growth challenge in terms of nested depth. A contemporary method, known as Planning with Perspectives (PWP), addresses these challenges through the use of perspectives and set operations for knowledge. The JP model defines that an agent's belief is justified if and only if the agent has seen evidence that this belief was true in the past and has not seen evidence to suggest that this has changed. The current paper extends the JP model to handle group belief, including distributed belief and common belief. We call this the Group Justified Perspective (GJP) model. Using experimental problems crafted by adapting well-known benchmarks to a group setting, we show the efficiency and expressiveness of our GJP model at handling planning problems that cannot be handled by other epistemic planning tools.", "sections": [{"title": "1 Introduction and Motivation", "content": "Epistemic planning is a sophisticated branch of automated planning that integrates elements from both classical planning and epistemic logic. It allows the agents to reason about not only the physical world but also other agents' knowledge and beliefs. It is suitable in solving multi-agent cooperative or adversarial tasks.\nThere are two traditional research directions to solving epistemic planning problems: explicitly maintain all epistemic relations, such as Kripke frames (Kominis and Geffner 2015; Bolander and Andersen 2011; Bolander 2014; Cooper et al. 2021); or require an expensive pre-compilation step to convert an epistemic planning problem into a classical planning problem (Muise et al. 2022). Research from both directions faces exponential growth in terms of the epistemic formulae depth.\nRecently, Hu, Miller, and Lipovetzky (2022) proposed a lazy state-based approach called Planning with Perspectives (PWP) that uses F-STRIPS (Geffner 2000) to reason about agent's seeing relation and knowledge. Their intuition is to use perspective functions to model the part of a state that each agent can see, and evaluate epistemic formulae from this. In short, an agent knows a proposition if it can see the variables involved in the proposition, and that proposition is true. They allow perspective functions to be implemented in F-STRIPS external functions, which means new logics can be created; for example, they model proper epistemic knowledge bases (Lakemeyer and Lesp\u00e9rance 2012) and Big Brother logic (Gasquet, Goranko, and Schwarzentruber 2014) in continuous domains, with impressive computational results. Hu, Miller, and Lipovetzky (2023) extended their model to model belief as well as knowledge, permitting e.g. conflicting belief between agents. However, their model could only reason about single agent nested belief, not group belief operators such as common belief.\nIn this paper, we extend their work to model uniform belief, distributed belief and common belief. We follow the intuition that when people reason about something they cannot see, they generate justified beliefs by retrieving the information they have seen in the past (Goldman 1979).\nHowever, applying this intuition of 'belief is past knowledge' na\u00efvely to group belief is neither complete nor consistent. It is possible that some agents in a group see value changes that affect their own knowledge and belief while the group's belief stays the same. In addition, it is possible to form a common belief about a proposition even if there was no prior common knowledge about this previously. For example, consider agent a looking in a box and seeing a coin with heads, and then agent b looking into the box a minute after agent a and seeing it is heads. At no point did they see the coin at the same time, so they cannot form common knowledge that the coin is heads (it may have changed in the minute in between). However, they can form a common belief that it is heads because they each saw heads and have no evidence to suggest the value has changed.\nWe illustrate this idea with an extended (from the coin example from Hu, Miller, and Lipovetzky (2023)) false-belief example.\nExample 1. There are two agents a and b, and there is a number $n \\in \\mathbb{N}$ inside a box. The number can only be seen by the agents when they are peeking into the box. The agents know whether the others are peeking into the box. The actions that agents can do are: peek and return. They cannot peek into the box at the same time, so they need to return to allow the other agent to peek. There are two hidden actions add and subtract, and their effects, are only visible to the agents who are peeking into the box. Initially, both agents a"}, {"title": "2 Background", "content": "2.1 Epistemic planning\nIn epistemic planning, the most popular approach, Kripke structures, model belief and knowledge logic using the possible worlds. The core idea is to use a set of accessibility relations $R_i$ to represent whether agent i can distinguish between two states (possible worlds). An agent knows (believes) a formula $\\phi$ if it is true in every world that the agent considers possible. The difference between knowledge and belief lies in the properties of $R_i$. To reason about knowledge, the agent's accessibility relations need to be Reflexive and Transitive and Euclidean, while the Reflexivity (Axiom T) is lost in belief. Semantically speaking, if $K_i\\varphi$ (agent i knows $\\varphi$ is true) holds (Axiom T), then $\\varphi$ holds; while if $B_i\\varphi$ (agent i believes $\\varphi$), it is not necessarily the case that $\\varphi$ holds. In short: agents can have incorrect beliefs, but not incorrect knowledge. For group beliefs, there are mainly three types: uniform beliefs, also known as shared beliefs; distributed beliefs; and common beliefs.\nUniform belief, denoted $EB_G \\varphi$, is straightforward \u2013 it means that everyone in group G believes proposition $\\varphi$. There are a number of approaches to model uniform belief (Iliev 2013; French et al. 2013).\nDistributed belief, denoted $DB_G \\varphi$, combines the beliefs of all agents in group G. It is, effectively, the pooled beliefs of group G if the agents were to \u201ccommunicate\" everything they believe to each other. Any model has to consider the pooled beliefs from each agent and the pooled beliefs from the group that are not held by any of its individual agents, but are held by the group. For example, if agent a believes x = 1 (and nothing else) and agent b believes y = 1 (and nothing else), distributively, the group {a,b} believes that x = y, even though no individual agent believes this. Distributed belief is challenging because agents can have conflicting beliefs: if agent a believes x = 1 and agent b believes x = 2, what should the distributed belief be?\nThere are two main approaches to model distributed belief: (1) belief merging (Konieczny 2000; Konieczny and P\u00e9rez 2002; Everaere, Konieczny, and Marquis 2015); and (2) merging the agents' epistemic accessibility relations (Halpern and Moses 1992; W\u00e1ng and \u00c5gotnes 2013; Roelofsen 2007; \u00c5gotnes and W\u00e1ng 2017; Solaki 2020; Li 2021; Goubault et al. 2023; van der Hoek, van Linder, and Meyer 1999). Typically, merging conflicting beliefs is"}, {"title": "2.2 Planning with Perspectives", "content": "Hu, Miller, and Lipovetzky (2022) propose a perspective model to lazily evaluate epistemic (knowledge) formulae with external functions, called Planning with Perspectives (PWP). They adapt the seeing operator $S_i$ from Cooper et al. (2016) for individual agent i following the intuition that \"seeing is knowing\"; formally, $K_i\\varphi \\leftrightarrow \\varphi \\wedge S_i\\varphi$. That is, agent i knows $\\varphi$ iff $\\varphi$ is true and it sees the value of $\\varphi$.\nThey define a state as a set of variable assignments x = e, and reason about agents' epistemic formulae based on what the agents can observe from their local state. The key is to define a perspective function for each agent i that takes a state and returns a subset of that state, which represents the part of the state that is observable to agent i. The perspective function $O: S \\rightarrow S$ is a function, where S is the set of all (partial and complete) states. The following properties must hold on a perspective function O:\n(1) $O_i(s) \\subseteq s$\n(2) $O_i(s) = O_i(O_i(s))$\n(3) If $s \\subseteq s'$, then $O_i(s) \\subseteq O_i(s')$\nThese properties ensure that: (1) everything that an agent sees is part of the current state; (2) if an agent observes part of the world, then it observes that it observes that part of the world (it sees what it sees); and (3) the observation function is monotonic. Consider the example in Figure 1. At the final state $s_4$, the global state is ${peeking_a \\rightarrow false, peeking_b \\rightarrow"}, {"title": "2.3 Justified Perspective Model", "content": "Hu, Miller, and Lipovetzky (2023) extend the PWP approach with the Justified Perspective (JP) model, which reasons about belief as well as knowledge. They introduce the belief operator $B_i$ and reason about an agent's belief by generating agent's justified perspective. Their intuition is that agents believe something if they saw it in the past and have no evidence to suggest it has changed. Compared to their previous perspective model in the PWP approach, which was purely based on the observation of the current state, JP model forms perspectives also based on previous observations. However, JP model only models single agent's nested belief under multi-agent settings, not group belief. We define group belief in the current paper.\nThe signature, language and model are the same as ours (defined in Section 3.1), except does not have those group operators. Their model uses the following notation: $dom(s) \\subseteq V$, where V from the signature, a sequence of states is denoted by $\\Im$, the set of all possible state sequences is denoted by $\\hat{S}$, and a state in a sequence $\\Im$ at timestamp t is denoted by $s_t$ or $s[t]$.\nThe retrieval function R identifies the value of the variable v with respect to timestamp $t_s$, which is the latest time an agent saw v in the given sequence $\\Im$. The formal definition they gave is as follows:\nDefinition 1 (Retrieval Function (Hu, Miller, and Lipovetzky 2023)). Given a sequence of states $\\Im$, a timestamp $t_s$ and a variable v, the retrieval function, $R: \\hat{S} \\times \\mathbb{N} \\times V \\rightarrow D$, is"}, {"title": "3 Group Justified Perspective Model", "content": "In this section, we formally propose our group justified perspective (GJP) model by adding group operations for uniform belief, distributed belief, and common belief to the JP model (Hu, Miller, and Lipovetzky 2023), inheriting the existing group modal operators from PWP approach (Hu, Miller, and Lipovetzky 2022).\n3.1 Preliminaries\nA signature is a tuple $\\Sigma = (Agt, V, D_{v_1},..., D_{v_n}, R)$, in which Agt is a finite set of n agent identifiers, V is a finite set of variables such that $Agt \\subseteq V$ (agent identifiers can be used as variables), $D_{v_i}$ is a possibly infinite domain of constant symbols, one for each variable $v_i \\in V$, and R is a finite set of predicate symbols. Domains can be discrete or continuous, and the set of all values is defined as $D = \\bigcup_{v\\in V}D_v$.\nDefinition 4 (Language). Language $\\mathcal{L}(\\Sigma)$ is defined by the grammar:\n$\\alpha ::= r(\\vec{t}) \\mid \\neg\\alpha \\mid \\alpha \\wedge \\alpha \\mid S_iv \\mid S_ia \\mid K_i\\alpha$\n$\\alpha ::= ES_G\\alpha \\mid DS_G\\alpha\\mid CS_G\\alpha \\mid EK_G\\alpha\\mid DK_G\\alpha\\mid CK_G\\alpha$\n$\\varphi ::= \\alpha \\mid B_i\\varphi \\mid EB_G\\varphi\\mid DB_G\\varphi\\mid CB_G\\varphi$\nwhere r \u2208 R, $\\vec{t} \\subseteq V$ are the terms of r, r($\\vec{t}$) are predicates and R is the set of all predicates. The group seeing operators, ES, DS and CS, and knowledge operators, EK, DK and CK are from the PWP model (Hu, Miller, and Lipovetzky 2022), while the $B_i$ operator is from the JP model (Hu, Miller, and Lipovetzky 2023). In this paper, we add the operators $EB_G$, $DB_G\\varphi$ and $CB_G$ to represent that agents from group G jointly, distributedly and commonly believe $\\varphi$ respectively."}, {"title": "3.2 Semantics for Group Belief", "content": "In this section, we define group justified perspective function for uniform belief, distributed belief, and common belief and add ternary semantics for them.\nUniform Belief is straightforward. Since a uniform belief of $\\varphi$ is that everyone in the group believes $\\varphi$, the uniform justified perspective function is just a set union of everyone's individual justified perspectives.\nDefinition 5. (Uniform Justified Perspectives)\n$ef_G(\\Im) = \\bigcup_{i\\in G} f_i(\\Im)$\nDefinition 6 (Ternary Semantics for Uniform Belief). Omitting the model M for readability, uniform belief $EB_G$ for group G is defined:\n(m) $T[\\Im, EB_G\\varphi] = min( {T[\\hat{\\Im},\\varphi] \\mid \\forall \\hat{\\Im} \\in ef_G(\\Im)} )$\nThe ternary value of $T[\\Im, EB_G\\varphi]$ depends on the agent that holds the most conservative beliefs of $\\varphi$.\nDistributed Belief is more challenging than distributed knowledge. The Knowledge Axiom T: $K_i\\varphi \\Rightarrow \\varphi$, which states that knowledge must be true, does not hold for belief. This means that agents can hold incorrect beliefs. If we simply take the distributed union of the perspectives for all agents $i \\in G$, as it is done in PWP, we could obtain conflicting beliefs, so the implicit distributed belief would be inconsistent. To ensure consistency, we form the group distributed justified perspective instead of just uniting each agent's justified perspective. Intuitively, agents follow their own observations and \"listen\" to agents that have seen variables more recently. The distributed perspective function $df_G$ is defined as follows.\nDefinition 7 (Distributed Justified Perspectives). The distributed justified perspective function for a group of agent G is defined as follows:\n$df_G([s_0,..., s_n]) = [\\hat{s_0},..., \\hat{s_n}]$\nwhere for all $t \\in [0,n]$ and all $v \\in dom(\\hat{s_t})$:\n$\\hat{s_t} = {v = e \\mid l_t = max(ats(v)) \\wedge e \\neq None}$,\n$ats(v) = {j \\mid v \\in dom(O_G(s_j)) \\wedge j \\leq t} \\cup {-1}$,\n$e = R([s_0,..., s_t], l_t, v)$\n$O_G(s) = \\bigcup_{i\\in G} O_i(s)$\nIn this definition, the group distributed justified perspective follows everyone's observation, and uses the Retrieval function R (in Definition 1) to identify the value of the variables which are or were not seen by any agent from the group. Intuitively, given any agent i in the group, the value from i's observation in timestamp t, $O_i(s_t)$, which leads to knowledge, must be true (Axiom T) in $\\hat{s_t}$. While, the value of an unseen variable is determined by anyone in the group that saw it last. To be specific, the last timestamp that group sees variable v, $l_t = max(ats(v))$, is determined by the group observation (formed by union), and then, value e is retrieved by identifying the closest value that is consistent with it. So, this definition mimics the definition of belief from Definition 2, except that the value of a variable v in a state $\\hat{s}$ is taken by the agent(s) that have the most recent view of it."}, {"title": "4 Experiments", "content": "Since there are no planning benchmarks for group belief, we select three domains (Number, Grapevine and Big Brother Logic) from existing work (Hu, Miller, and Lipovetzky 2022, 2023) and add several challenging problem instances (7 for each domain) that use group belief, including instances with inconsistent or nested beliefs.\n4.1 Implementation\nThe source code of the planner, the domain, the problem and external function files, as well as experimental results, are downloadable from: omitted to anonymity. We extend the F-STRIPS planner from (Hu, Miller, and Lipovetzky 2023). To demonstrate the efficiency of our model instead of the particular search algorithms, we use the BrFS (breadth-first search) search algorithm with duplicate removal. The experiments are run on a Linux machine (Ubuntu 20.04) with 8 CPUs (Intel i7-10510U 1.80GHz) with 16GB RAM. The external functions, implemented in Python, evaluate the belief formulae (either in action preconditions or goals) as search nodes are generated. We implement the group justified perspective model and its corresponding ternary semantics.\n4.2 Domains\nNumber is an adapted domain from the origin coin domain (Hu, Miller, and Lipovetzky 2023). The problem settings, as described in Example 1, are of agents taking turns to peek into a box containing a changeable number."}, {"title": "5 Conclusion and Future work", "content": "In this paper, we define an extension to the Justified Perspective model (Hu, Miller, and Lipovetzky 2023) to handle group beliefs; implement its ternary semantics as a model-free planning tool; and demonstrate its expressiveness and efficiency on new featured domains. The results show that our approach can effectively handle multi-agent epistemic planning problems with group beliefs and do so efficiently, even with a simple prototype F-STRIPS planner implementing a Breadth First Search.\nFor future work, we will implement efficient search algorithms for our planner. Potential search algorithms may need to create novel non-Markovian search algorithms, as our GJP model works with state sequences. In addition, although there is a growing body of research in epistemic planning, there are still no uniform standards on either epistemic planning language or benchmark domains. It would be valuable to revisit existing approaches and model our benchmarks in those. Besides, current epistemic planning approaches often rely on classical planning assumptions. Future research could broaden the field's applicability by relaxing these assumptions, particularly in dynamic environments and in human-agent interaction domains with formal human belief model."}, {"title": "A Proof for Theorem 3.1", "content": "Theorem 3.1. For any agent $i \\in A$ and perspective $\\Im \\in \\hat{S}$:\n$f_i(\\Im) = f_i(f_i(\\Im))$\nProof. Let s(v) = \u03c4 be v \u2209 s in the following content.\nThe base case is a sequence with one element [s0]. In this case, the above lemma holds trivially, because: $f_i([s_0]) = [O_i(s_0)]; f_i(f_i([s_0])) = f_i([O_i(s_0)]) = [O_i(O_i(s_0))]; and, O_i(s_0) = O_i(O_i(s_0))$.\nFor a sequence for more than one element, $f_i(\\Im)[t]$ depends on the $[O_i(s_0),..., O_i(s_t)]$ and $s_0,..., s_t$. Let v be any variable in V.\nAny variable v \u2208 V can be classified into one of the following conditions:\n1. $v \\in O_i(s_t)$\n2. $v \u2209 O_t \\wedge v \\in O_i(f_i(\\Im)[t])$\n3. $v \u2209 O_t \\wedge v \u2209 O_i(f_i(\\Im)[t])$\nFor Condition (1), we have $f_i(\\Im)[t](v) = O_i(s_t)(v) = s_t(v)$ and $f_i(f_i(\\Im))[t](v) = O_i (f_i(\\Im)[t])(v) = O_i(O_i(s_t))(v) = O_i(s_t)(v) = s_t(v)$, since:v \u2208 O_i(s_t); $O_i(O_i(s_t)); and, O_i(s_t) \\subseteq f_i(\\Im)[t] \\rightarrow O_i(O_i(s_t)) \\subseteq O_i(f_i(\\Im)[t])$. Thus, $f_i(\\Im)[t](v) = f_i(f_i(\\Im))[t](v)$.\nFor Condition (2), we have $f_i(f_i(\\Im))[t](v) = O_i(f_i(\\Im)[t])(v) = f_i(\\Im)[t](v)$. For Condition (3), whether $f_i(\\Im)[t](v) = f_i(f_i(\\Im))[t](v)$ holds depends on whether $f_i(\\Im)[t - 1](v) = f_i(f_i(\\Im))[t - 1](v)$. Then, by recursively apply the above reasoning, we can show if the v matches Condition (3) for every timestamp from t, t \u2212 1 to 0, it matches with our base case above.\nOverall, $f_i (\\Im) = f_i(f_i(\\Im))$ holds."}, {"title": "B Proof for Theorem 3.2", "content": "Theorem 3.2. Given a sequence of states of length n, the upper bound for the number of iterations for $cf_G(\\hat{S})$ converges is $2^{|V| \\times n}$\nProof. Since for each variable in the last state of a justified perspective w, its value is either visible (same as its in the last state of the global perspective), or not visible (same as its in the second-last state from w), the number of possible states in each index of a justified perspectives is $2^{|V|}$. So, the number of possible perspectives given a global state sequence $\\Im$ with length of n is $2^{|V| \\times n}$. In calculating $cf_G(\\Im)$, either the base case holds (that is, combining the perspective of the group for all $s \\in \\hat{S}$ does not change the common perspective), so it terminates and adds no new perspectives; or the recursive step holds. In this case, the input of the $cf_G$ function is set that contains perspectives from each agent in the format of $S = {f_i(\\Im), f_i(\\Im'), ... | \\forall i \\in G}$. Then, we apply f; for each agent j in the group G on each perspective from S as $\\hat{S'} = \\bigcup_{s\\in S} ef_G (\\Im)$. For each $f_i(s)$ from $\\hat{S}$, we have $f_j (f_i(s))$ in $\\hat{S'}$ for each agent j in group G. With Theorem, we have $f_j(f_i(s)) = f_i(s)$ when i = j. Therefore, we have $\\hat{S} \\subseteq \\hat{S'}$. At worst, we add one new sequence each iteration, meaning that $cf_G (S)$ converges by at most $2^{|V| \\times n}$ iterations."}, {"title": "C Semantics", "content": "The language for this full semantics is defined in Definition 4. In order to provide semantics for CS, we need to introduce the perspective (observation) function co from Hu, Miller, and Lipovetzky (2022)'s paper.\nDefinition 11 (Common Observation Function (Hu, Miller, and Lipovetzky 2022)). Given a group of agents G and the current state s, the common observation of the group can be defined as:\n$CO(G, s) = { S if s = \\bigcap_{i\\in G} O_i(s) \\ CO(G, \\bigcap_{i\\in G} O_i(s)) otherwise.}$\nThe variables that are not visible to any agent in the group G are filtered out until the remaining set becomes a fixed point set. That is, every variable in the set is commonly seen by the group G.\nC.1 Ternary Semantics\nHere we provide full ternary semantics. Similar to the complete semantics: item a-g (Hu, Miller, and Lipovetzky 2023) are for individual modal operators using justified perspective function; item h-l (Hu, Miller, and Lipovetzky 2022) are for group seeing and knowledge operators using group perspective functions; item m-o are for group belief operators defined in Section 3.2.\nDefinition 12 (Ternary Semantics). The ternary semantics are defined using function T, omitting the model M for readability:\n(a) $T[s,r(t)] = {1 if \\pi(\\Im[n],r(t)) = true; \\ 0 if \\pi(\\Im[n], r(t)) = false; \\ otherwise}$\n(b) $T[\\Im, \\varphi \\wedge \\psi] = min(T[\\Im, \\varphi], T[\\Im,\\psi])$\n(c) $T[\\Im, \\neg\\phi] = 1 - T[\\Im,\\phi]$\n(d) $T[\\Im, S_iv] = {\\frac{1}{2} if i \\notin \\Im[n] or v \\notin \\Im[n] \\ 0 if v \\notin O_i (\\Im[n]) \\ 1 otherwise}$\n(e) $T[\\Im, S_i\\varphi] = {\\frac{1}{2} if T [\\Im,\\varphi] = \\frac{1}{2} or i \\notin \\Im[n]; \\ 0 if T[O_i(s), \\varphi] = 1; \\ 1 otherwise}$\n(f) $T[\\Im, K_i] = T[\\Im, S_i\\varphi]$\n(g) $T[\\Im, B_i] = T[f_i(\\Im), \\varphi]$\n(h) $T[\\Im, ES_G\\alpha] = min({T[\\Im, S_i\\alpha] | i\\in G})$\n(i) $T[\\Im, DS_Gv] = {\\frac{1}{2} if v \\notin \\Im[n] or \\forall i\\in G, i \\notin [n]; \\ 0 if v \\notin \\bigcup_{i\\in G} O_i(\\Im[n]); \\ 1 otherwise}$\n(j) $T[\\Im, DS_G\\varphi] = {\\frac{1}{2} if T[\\Im,\\varphi] = T[\\Im, \\neg \\varphi] = \\frac{1}{2} or \\forall i\\in G, i \\notin s[n] \\ 0 if T[s', \\varphi] = T[s', \\neg \\varphi] = \\frac{1}{2}, where s' = \\bigcup_{i\\in G} O_i(\\Im[n]); \\ 1 otherwise}$\n(k) $T[\\Im, CS_Gv] = {\\frac{1}{2} if v \\notin s[n] or \\exists i \\in G, i \\notin [n];}$"}]}