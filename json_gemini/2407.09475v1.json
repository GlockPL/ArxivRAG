{"title": "Adaptive Prediction Ensemble:\nImproving Out-of-Distribution Generalization of Motion Forecasting", "authors": ["Jinning Li", "Jiachen Li", "Sangjae Bae", "David Isele"], "abstract": "Deep learning-based trajectory prediction models\nfor autonomous driving often struggle with generalization to out-\nof-distribution (OOD) scenarios, sometimes performing worse\nthan simple rule-based models. To address this limitation, we\npropose a novel framework, Adaptive Prediction Ensemble\n(APE), which integrates deep learning and rule-based prediction\nexperts. A learned routing function, trained concurrently with\nthe deep learning model, dynamically selects the most reliable\nprediction based on the input scenario. Our experiments on\nlarge-scale datasets, including Waymo Open Motion Dataset\n(WOMD) and Argoverse, demonstrate improvement in zero-\nshot generalization across datasets. We show that our method\noutperforms individual prediction models and other variants,\nparticularly in long-horizon prediction and scenarios with a\nhigh proportion of OOD data. This work highlights the potential\nof hybrid approaches for robust and generalizable motion\nprediction in autonomous driving.", "sections": [{"title": "I. INTRODUCTION", "content": "Trajectory prediction is critical for safe and reliable au-\ntonomous vehicle systems. Existing prediction algorithms [1],\n[2], [3], [4] have achieved high accuracy on real-world\nscenarios, such as real traffic datasets. However, most of\nthese algorithms only work best for in-distribution scenarios.\nIntuitively, traffic scenarios in different cities of the same\ncountry should not possess drastic differences, and human\ndriving skills including their prediction and judgment, are\nnot significantly affected. This is unfortunately not the case\nfor deep learning-based prediction algorithms [5], [6], [7].\nIf they are applied to out-of-distribution (OOD) scenes in a\nzero-shot manner, such as predicting vehicle trajectories from\na different dataset than the training dataset, the performance\nwill drop dramatically even though the input representation\nand format are the same. In some cases, a deep learning-based\nprediction algorithm is not even as good as a simple constant\nvelocity model, as shown in Fig. 1. This is unfortunately a\nlargely under-explored topic. One natural way is to combine\nthe prediction from different sources, which resembles the\nmixture of experts. As far as we know, we are the first to\nexplore concrete methods to improve OOD generalization to\ndifferent datasets than training.\nMixture of Experts (MoEs) [8] has gained popularity,\nespecially after the great success of Large Language Models.\nMost of the prior work showed MoEs can reach faster\ninference [9], [10] compared to dense models with the\nsame number of parameters, and can also be pre-trained\nfaster [11], [12]. While they focused on MoEs' advantage\nover a comparable dense model in size, we are more interested\nin investigating the generalization ability improvements upon\na single expert model. We generally find that deep learning\nprediction models tend to overfit their training dataset,\nmaking zero-shot performance unacceptable. Incorporating\na fleet of deep learning prediction experts or adopting a\nsimilar size large dense model would not solve the problem,\nsince increasing the model capacity would not mitigate\nthe overfitting problem if not making it worse. Therefore,\nwe propose to employ a rule-based prediction expert as\nan anomaly-handling strategy for deep learning prediction\nexperts, in light of the insight that rule-based prediction could\nbe more reliable in long-tail cases of deep learning prediction\nexperts.\nThere are other existing methods for domain generalization\nthat usually handle the problem by data manipulation [13],\nrepresentation learning [14], [15], or specially designed\nlearning strategy [16], [17] or inference workflow [18]. If\none aims to improve the generalization upon an existing\nprediction model with prior methods, it is usually inevitable\nto make modifications and re-train the original prediction\nmodel. In comparison, the proposed method in this paper\nis a straightforward yet powerful approach to generalization\nimprovement by establishing a routing function and incorpo-\nrating a rule-based baseline prediction model. The routing\nfunction is trained concurrently with the prediction model\nand decides on whether to switch to the rule-based model"}, {"title": "II. RELATED WORKS", "content": "when the learning-based prediction model is unreliable.\nThe main contributions of this paper are as follows:\n\u2022 We identify the problem of generalization when zero-\nshot evaluating state-of-the-art (SOTA) prediction models\nbetween different benchmark datasets. The performance\n(e.g., minADE and minFDE) of SOTA models drops\ndrastically. For these cases, it is even possible that basic\nrule-based prediction algorithms outperform sophisti-\ncated deep learning-based prediction models.\n\u2022 We propose a novel inference framework, Adaptive\nPrediction Ensemble (APE), where the learning-based\nprediction model will fall back to a rule-based model\naccording to their reliability. Their reliability is estimated\nby a routing function trained concurrently with the\nlearning-based prediction model.\n\u2022 We evaluate the proposed training pipeline and inference\nframework on benchmark datasets including Waymo\nOpen Motion Dataset (WOMD) [19] and Argoverse\ndataset [20], which shows that the proposed method sig-\nnificantly improves prediction performance in zero-shot\nevaluations compared to individual prediction models."}, {"title": "A. Motion Prediction with Uncertainty Estimation", "content": "Motion prediction algorithms for autonomous driving\nhave been successful on many datasets, and have been\nintegrated into the autonomy stack [21], [22], [23], [24], [25].\nHowever, it is not rare that prediction failure causes erroneous\ndownstream motion planning for autonomous vehicles [26].\nTherefore, it is desired to detect such prediction failure in an\nefficient yet reliable manner. There have been many efforts to\nleverage uncertainty estimation to decide whether a prediction\nis reliable [27]. The prediction uncertainty was estimated\nby various methods, including ensemble [28], [29], [30],\ndedicated uncertainty estimation model training [27], rule-\nbased estimation [31], and data augmentation [32]. However,\ntraining new models specialized in uncertainty estimation and\nperforming evaluations on its accuracy is not a straightforward\ntask, because there is often no ground truth. Ensemble-based\nuncertainty estimation is costly both during training and\ninference and may introduce too much variance, reducing\nthe reliability of out-of-distribution detection as we show\nin the ablation study in Sec. V-F. Our method of training\na routing function concurrently with individual learning-\nbased predictors can increase the exposure of the routing\nfunction to anomalous trajectory prediction upon the normal\ntraining dataset, and therefore the final prediction selected\nfrom various predictor experts can have better performance\non zero-shot generalization tasks."}, {"title": "B. Mixture-of-Experts", "content": "There are also mixture-of-experts methods that collect\na set of experts specializing in different sub-tasks, which\nare likely to be included in the target domain [8]. These\nmethods will then choose one suitable expert to be activated\nduring inference. In our setting, we do not assume a pre-\ndefined set of sub-tasks in the target domain, and we also\nobserved that deep learning-based predictors tend to have\nunsatisfying performance on cross-dataset generalization.\nTherefore, we follow the idea of mixture-of-experts but do\nnot train individual experts for specific sub-tasks. We include\nboth deep learning-based and rule-based experts that can\nperform general motion prediction tasks. A routing function\nis trained concurrently with deep learning-based predictors, so\nit is exposed to more diverse trajectory prediction candidates\nand hence the difficulty of ranking anomalous predictions is\nmitigated."}, {"title": "C. Finetuning with Human Feedback", "content": "It is also a popular trend to finetune models on the\ntarget domain to improve generalization with guidance by\nexperts trained from offline human demonstration [33] or\na ranking function trained with human feedback [34], [35].\nWhile these methods are appealing and we could directly\napply the ranking function as a routing function in MoE,\nthey are not viable in our setting as we aim to deal with\nzero-shot generalization, and hence the algorithm does not\nhave access to the target domain or test data. We do not\nhave resources for human feedback on tens of millions of\ntrajectories either, so it is desired to leverage the routing\nfunction trained in an automated pipeline, where we collect\nall the trajectory predictions output by the individual deep\nlearning-based predictor since its training begins. In this way,\nall the footprints of the prediction outputs, no matter bad or\ngood, are included in the routing function training dataset.\nThe increased exposure beyond the training dataset of the\nindividual predictor boosts the ranking ability of the routing\nfunction to differentiate reliable prediction candidates from\nbad ones, and thus improves the zero-shot performance."}, {"title": "III. PROBLEM FORMULATION", "content": "In this paper, we focus on zero-shot learning and evaluate\nthe motion prediction neural network models on samples\nthat were not observed during training in the autonomous\ndriving domain. Specifically, we denote \\(x = \\{x^t | t \\in\n\\{1,...,T\\}\\}\\) as a single agent trajectory in the i-th scene,\nrepresented by a series of features \\(x^t\\) from timestep 1 to T.\nThe agents are constantly interacting with the environment\nfor which the context information can be represented by\n\\(c^t\\) = \\{c^t \\in (1,T)\\}\\). The i-th scene is denoted by \\(s_i\\) =\n\\{(x, c) | \\in (1,T)\\}\\). The task of the prediction model is to\npredict future trajectory distribution \\(p(x_{Th+1:Tf}|x_{1:Th}, c_{1:Th}\\)\\nfor an ego agent given its history features (states) \\(x_{1:Th}\\) and\ncontext information \\(c_{1:Th}\\) in the i-th scene, where \\(T_h\\) is\nthe history horizon and \\(T_f\\) is the lookahead horizon and \\(T =\nTh +Tf\\).\nWe are particularly interested in inspecting and improving\nthe generalization ability upon deep learning-based prediction\nmodel, which is trained on one dataset \\(D_T\\) = \\{s_i | i \\in\n(1, M_T)\\}\\), and evaluated on another dataset \\(D_e\\) = \\{s_i | i \\in\n(1, M_e)\\}\\). Note that in this paper, the training and the\nevaluation datasets are defined differently than the normal\nconvention of training and validation. They may or may not be\ngenerated from the same underlying distribution. We evaluate"}, {"title": "IV. ADAPTIVE PREDICTION ENSEMBLE", "content": "In this section, we present our approach, Adaptive Pre-\ndiction Ensemble, to improving the test-time performance\nof motion prediction algorithms in zero-shot generalization\ntasks. It consists of two stages: 1) during the training stage, a\ndeep learning-based prediction model and a routing function\nare trained concurrently; and 2) during the testing stage, a\nrule-based prediction model is incorporated, and the final\nprediction output is adaptively selected out of both deep\nlearning-based and rule-based prediction candidates by the\nrouting function according to their quality."}, {"title": "A. Deep Learning Prediction Expert", "content": "We propose to adopt high-capacity neural networks with a\npowerful scene encoding module and a motion forecasting\ndecoder module as the backbone for all deep learning models\nin this paper, leveraging their superior scene context encoding\nand understanding ability.\nThe deep learning prediction expert takes in a vector-\nized representation, including both history trajectories of\nthe vehicles in the scene and road map polylines, as the\ninput representation [36], where all the vector inputs are\ncentered around the ego agent. The input should be processed\nby a PointNet-like [37] encoder before being consumed\nby a scene encoder. The scene encoder understands most\nof the context information and generates embeddings for\ndownstream prediction tasks. The extracted scene features are\nfed into a decoder module with multiple layers. This module\nprogressively refines the understanding of the scene dynamics\nand ultimately generates predictions for the future trajectories\nof surrounding vehicles, potentially including multi-modal\npredictions. The predictions are obtained through specialized\nprediction heads attached to the decoder layers. The training\nprocess optimizes the network to maximize the likelihood of\nthe predicted trajectories matching the actual ground truth data.\nThis is achieved by formulating the motion prediction task\nas a Gaussian Mixture prediction and employing a negative\nlog-likelihood loss function \\(L_{pred}\\).\nGenerally speaking, our proposed framework does not have\nany strict requirement on specific deep learning prediction\nmodels as individual predictor experts, rather we could apply\nany high-performance models as long as they have the\naforementioned properties."}, {"title": "B. Rule-Based Prediction Expert", "content": "Rule-based prediction experts can work as a powerful\nbackup plan for the deep learning prediction expert. Deep\nlearning prediction experts suffer from long-tail problems,\nwhich in contrast are not such a challenge for rule-based\nprediction experts. Among numerous rule-based prediction\nalgorithms, we discover that a constant velocity model can be\nsufficient to showcase the improvements upon a single deep\nlearning prediction model on the zero-shot test. Specifically,\nwe adopt a closed-form prediction model to extrapolate the\nego agent's trajectory with a constant velocity,\n\\(x^{t+1} = f(x^t) = [x^t + v_{t,x}, y^t + v_{t,y}, v_{t,x}, v_{t,y}, \\delta^t] \\) (1)\nwhere \\((x^t, y^t)\\) is the position coordinate, \\((v_{t,x}, v_{t,y})\\) is the\nvelocity, \\(\\delta^t\\) is the heading angle of the ego agent at time t"}, {"title": "C. Learned Routing Function", "content": "in the i-th scene. We note that although the prediction of a\nconstant velocity model is always a straight line, it could be\nsufficient if the prediction frequency is high enough because\nthe prediction errors will be small in the short term.\nWith a group of experts available, a learned routing function\nis needed. Its goal is to compare the proposed candidate\npredictions generated by the experts and select the most\nreliable one as the output. Thus, the generalization and zero-\nshot performance of the whole prediction module now relies\non the ability to recognize and handle out-of-distribution\nscenarios of the learned routing function. Because the task is\nto pick the best prediction among a set of existing predicted\ntrajectories, we relax the original requirement on the zero-\nshot performance of the generative model to a zero-shot\nperformance requirement on a discriminative model, i.e.,\nthe learned routing function. In addition to the decrease in\nthe difficulty of the generalization task, the learned routing\nfunction also has access to more data modes, and its self-\nsupervised training style enables further improvements in its\ngeneralization ability.\nWe propose to adopt the same scene context encoder\narchitecture of the deep learning prediction expert and add\na routing decoder head on top of the encoder. A detailed\nstructure illustration is shown in Fig. 2. Both the high model\ncapacity and the superior scene context encoding ability can\nbe inherited, while the difficulty of generalization is reduced\nfor the learned routing function. The routing function model is\ntrained concurrently with the deep learning prediction experts\nby the loss function\n\\(L_{\\theta} = -E_{(s,x)\\sim D} [log(\\sigma(R_{\\theta}(x_{1:Th}, x_{Th+1:T}^{chosen})\n- R_{\\theta}(x_{1:Th}, x_{Th+1:T}^{rejected}))]\\) (2)\nwhere \\(R_{\\theta}(x_{1:Th}, x_{Th+1:T}^{chosen})\\) and \\(R_{\\theta}(x_{1:Th}, x_{Th+1:T}^{rejected})\\) are the scores\ngenerated by the routing function for the chosen prediction\ncandidate and the rejected prediction candidate, respectively,\nand \\(\\sigma(\\cdot)\\) is a ReLU layer. \\(x_{Th+1:T}\\) is the prediction candidate\ngenerated by the individual prediction expert. This loss func-\ntion is adopted from RL with human feedback (RLHF) [38],\nwhich encourages large gaps between the scores of the two\nsamples in the pair. Empirically, we find this loss function\nresults in a more stable training process than other loss\nfunctions such as cross-entropy loss.\nAs the deep learning-based prediction model is being\ntrained, we collect all its multi-modal prediction outputs.\nThese outputs and the predictions of the rule-based experts\nfor the same agent in the same scene are paired and both\ncompared against the ground truth trajectory in terms of some\nmetric, e.g., the average displacement error. Therefore, we\ncan have a ground truth of which predicted trajectory is better\namong the two. These pairs and labels are stored in a new\ndata buffer than the original training dataset and are used\nto train the learned routing function. As the training of the\ntransformer prediction model goes on, its prediction output\ngoes from sub-optimal to more reasonable than the rule-based\nAlgorithm 1: Training and Inference Workflow\n1 Initialize: A motion prediction neural network \\(Q_{\\phi}\\), a\nrouting function network \\(R_{\\theta}\\), a rule-based prediction\nmodel \\(f\\), a training dataset \\(D\\) containing vehicle\ntrajectories for prediction tasks, a data buffer \\(D_{rf}\\) for\nrouting function training;\n2 // Training\n3 for epoch \\(n\\) in range(0, \\(N\\)) do\n4 for sample \\(s\\) in \\(D\\) do\n5 Rule-based prediction: \\(x_r = f(s_{1:T_h})\\);\n6 Learning-based prediction: \\(x_l = Q_{\\phi}(s_{1:T_h})\\);\n7 Update \\(\\phi\\): \\(\\Phi_i \\leftarrow \\phi_{i-1} + \\epsilon_{\\phi}\\nabla_{\\phi}L_{pred}\\);\n8 Rank the predictions \\(x_r, x_l\\) by ADE;\n9 Update \\(\\theta\\) by Eqn. 2 according to the ranking\n10 (\\(s, x_{chosen}, x_{rejected}\\)): \\(\\theta_j \\leftarrow \\theta_{j-1} + \\epsilon_{\\theta}\\nabla_{\\theta}L_{\\theta}\\);\n11 end\n12 end\n13 // Inference\n14 for sample \\(s_{1:T_h}\\) in test dataset \\(D_{test}\\) do\n15 Rule-based prediction: \\(x_r = f(s_{1:T_h})\\);\n16 Learning-based prediction: \\(x_l = Q_{\\phi}(s_{1:T_h})\\);\n17 Output prediction\n18 \\(x = arg max(x_r, x_l, key = R_{\\theta}(s_{1:T_h},\\cdot))\\);\nexpert predictions. Thus, the learned routing function can\nhave access to both cases where transformer prediction is\nworse or better than the rule-based prediction, and hence we\ncan avoid the issue of mode collapse."}, {"title": "D. Practical Implementation", "content": "We summarize our complete algorithm in Algorithm 1.\nDuring the training phase, we train a deep learning prediction\nmodel as one of the experts. As it is being trained, we\ncollect and compare its outputs with predictions from the\nrule-based expert against the ground truth, and use the labeled\npairs of predictions to train a routing function with the same\ntransformer encoder structure and an additional routing head.\nIn the test phase, the environment states are input to both\ndeep learning and rule-based prediction models, which both\nmake proposals. The learned routing function consumes them\nand selects the better one as the final prediction result."}, {"title": "V. EXPERIMENTS", "content": "A. Experiment Setting\n1) Deep Learning Prediction Expert: We adopt the state-of-\nthe-art prediction architecture MotionTransformer (MTR) [2]\nas the backbone of the deep learning prediction expert. It\ningests a vectorized representation, including both history\ntrajectories of the vehicles in the scene and road map polylines,\nas the input representation [36], where all the vector inputs\nare centered around the ego agent. The inputs are first\npreprocessed by a PointNet-like [37] polyline encoder and\nthen fed into the transformer scene context encoder. The scene\nencoder enforces local attention which emphasizes the focus"}, {"title": "C. Evalution Metrics", "content": "on local context information by adopting k-nearest neighbor\nto find k closest polylines to the polyline of interest. The scene\ncontext encoded by the local scene encoder is then enhanced\nby a dense future prediction, containing future interaction\ninformation. A static intention and dynamic searching query\npair is generated and input to the scene decoder, along with the\nenhanced scene context encoding and a query content feature.\nA prediction head is applied to each decoder layer to generate\nfuture trajectories, which are represented by a Gaussian\nMixture Model to capture multimodal agent behaviors. Please\nrefer to [2] for more model details.\n2) Rule-Based Prediction Expert: As described in Sec. IV-\nB, we apply a constant velocity model as the rule-based\nprediction expert. It is also possible to adopt other more\ncomplicated rule-based prediction models to incorporate more\ninformation such as lane and traffic rules. However, this choice\nis to demonstrate that even a basic complement to a deep\nlearning model can improve the generalization ability of the\nwhole algorithm.\n3) Learned Routing Function: Similar to the deep learning\nprediction expert, the routing function also adopts MTR as\nthe backbone for its scene understanding ability. It is trained\nconcurrently with the deep learning prediction expert together\nwith the output of the rule-based prediction expert, such that\nit is exposed to diverse trajectory predictions and hence learns\nthe ability to recognize their quality.\n4) Prediction Tasks: We focus on zero-shot generalization\nof the prediction models across different datasets. Specifically,\nwe choose to use Waymo Open Motion Dataset (WOMD)\nand Argoverse as the two datasets in our experiments. The\nframework is trained on one dataset and is zero-shot tested\non another dataset without finetuning.\nB. Baselines\nWe mainly perform training and evaluation stage isolation\nand combination to evaluate the proposed training framework.\nSpecifically, we compare APE to the following baselines:\n\u2022 MTR: MTR trained on one dataset (WOMD or Argov-\nerse) and zero-shot tested on another.\n\u2022 MTR (Oracle): MTR trained and tested on the same\ndataset, which serves as the performance upper bound.\n\u2022 Constant Velocity Prediction (Const-Vel): The baseline\nrule-based prediction method, which shows the lower\nbound baseline performance.\n\u2022 APE (BS): uses an alternate routing function based on\nthe variance of an ensemble of MTR models. Refer to\nsection V-F for more details."}, {"title": "VI. CONCLUSIONS AND DISCUSSIONS", "content": "We follow the convention in motion prediction and adopt\nthe commonly used metrics for evaluation.\n\u2022 minADE: This metric computes the average of the\n12-displacement between the ground truth trajectory and\nthe closest prediction among six trajectory predictions:\n\\(\\text{minADE} = \\frac{1}{T}\\sum_{t=1}^{T} \\min_{k\\in\\{1,...,\\kappa\\}} ||x_{t}^{SG} - x_{t}^{k,t}||_2\\)\nwhere k represents the number of modes predicted by\nthe model. We choose \\(\\kappa = 6\\) in this paper. We also use\nthis metric to rank the prediction generated by different\nexperts when training the learned routing function.\n\u2022 minFDE: This metric computes the \\(l_2\\)-displacement\nbetween the ground truth trajectory and the closest\nprediction at the last time step:\n\\(\\text{minFDE} = \\min_{k\\in\\{1,...,\\kappa\\}} ||x_{T}^{SG} - x_{T}^{k,T}||_2\\).\n\u2022 Miss Rate: A miss is defined as the condition wherein\nnone of the M predicted object trajectories lie within\nthe specified lateral and longitudinal tolerances of the\nground truth trajectory at a designated time T.\n\u2022 mAP: This metric is computed on top of Miss Rate.\nThe predictions that are classified as a miss are labeled\nas negative, whereas non-miss is positive. Precision and\nrecall are computed based on sorted confidence scores\nassociated with each prediction. The mAP metric is then\ncomputed as the interpolated precision values in [39].\nThis metric offers a holistic assessment of the motion\nprediction performance.\nIn addition to the aforementioned common metrics for\nprediction tasks, we also propose to use Performance Gain\nPercentage to quantify the improvement upon baseline meth-\nods with our proposed method, which is defined as\n\\(\\text{Perf Gain} = 100\\% * \\frac{\\text{Metric(Proposed Method)}}{\\text{Metric(Baseline Method)}}\\) (3)\nand will be applied to ablation study in Sec. V-H and V-G."}, {"title": "D. Implementation Details", "content": "The feature input projection layer is set to be a 3-layer\nMLP with a hidden dimension of 256. We stack 6 transformer\nlayers for the scene encoding layer. The embedding feature\ndimension of these layers is set to be 256. The motion\nprediction decoder and output projection head follow the\nimplementation of MTR [2]. The routing function decoder is\na stack of 6 transformer layers with an embedding feature\ndimension of 256. The output projection head is a 3-layer\nMLP with a hidden dimension of 256. The routing function\ndecoder and output projection are updated with the scene\nencoder frozen, after each time the motion prediction decoder\nis updated. The models are trained by AdamW optimizer on\n4 GPUs (Nvidia RTX 6000) for 30 epochs with a batch size\nof 60 and a learning rate of 1e-4, which is decayed every 2\nepochs by a factor of 0.5."}, {"title": "E. Prediction Generalization Performance", "content": "The full evaluation of the prediction generalization per-\nformance involves a bi-directional zero-shot generalization\nevaluation. For one direction, we train prediction algorithms\non WOMD, and zero-shot test them on Argoverse. The\nopposite direction of generalizing from Argoverse to WOMD\nis also evaluated for completeness. Since Argoverse only\ncontains agent type Vehicle, we only enable predictions\non vehicles in WOMD as well for fairness."}, {"title": "F. Yet Another Routing Function", "content": "We show the performance of APE along with various\nbaselines and variants in Table I, and visualizations of\npredicted trajectories of both experts in different scenarios in\nFig. 3. According to Table I, the proposed Adaptive Prediction\nEnsemble with a mixture of experts outperforms all baselines\nand variants in our bi-directional generalization evaluation.\nWe attribute the performance improvements to the capability\nof the routing function and the contribution from different\nexpert prediction methods. The routing function learns good\nprediction selection skills even though the test scenarios\nare out-of-distribution for individual prediction algorithms\nbecause it gets exposed to more diverse input (i.e., trajectory\nprediction candidates) during its concurrent training with other\nindividual predictors. The difficulty level of its generalization"}, {"title": "D. Practical Implementation", "content": "In this section, we aim to evaluate another type of routing\nfunction and compare it with the proposed learning-based\none that is trained concurrently with the individual predictors.\nThe prediction selection can also be executed by a routing\nfunction based on uncertainty estimation. We choose to use\nthe most widely used method, bootstrapping model output\nvariance, as the uncertainty estimation method in the routing\nfunction variant. The variant with a routing function based on\nbootstrapping uncertainty estimation is named APE (BS) in\nour experiment. Concretely, we use the variance of three MTR\nprediction outputs as the epistemic uncertainty estimation of\nthe learning-based prediction model, where the three MTR\nmodels are randomly initialized and trained on the same\ntraining dataset. If the uncertainty estimation surpasses a\nthreshold, then the predictor will discard MTR predictions\nand choose the constant velocity prediction as the final output,\nand vice versa."}, {"title": "G. In-D and OOD Interpolation Data Mixture", "content": "is mitigated by the exposure to a diverse data distribution.\nTherefore, as a coordinator, the learned routing function can\nstitch a more powerful predictor out of individual experts.\nIt is also interesting to note that the constant velocity\nmodel performs better on Argoverse with a minADE of\n3.2680 m than WOMD with a minADE of 6.5713 m. This\nindicates that WOMD contains more complicated prediction\ntasks than those in Argoverse, possibly with more turns\nand fewer go-straight scenarios. This statement can also\nbe shown from a smaller minADE on Argoverse for MTR\n(Oracle) than WOMD. However, no matter which direction\nof generalization is performed, the proposed method always\noutperforms an individual prediction algorithm, thanks to\nthe concurrent training of the routing function and diverse\nprediction candidates from individual predictors.\nWhen generalizing from Argoverse to WOMD, the constant\nvelocity model outperforms MTR in terms of minADE. This\nshows that it is possible for a rule-based predictor to perform\nbetter than a deep learning-based predictor, and hence it is\nnecessary to design strategies to improve the generalization\nability of a learning-based predictor, with the proposed APE\nas one possible solution."}, {"title": "H. Prediction Horizon vs. Improving Scale", "content": "In this section, we perform an ablation study on the effect\nof different ratios of in-distribution (in-D) and out-of-distribution\n(OOD) test data mixture on the performance improving scale.\nWe adopt the metric, performance gain, defined in Eqn. (3) to\nmeasure the performance improving scale. The in-distribution\ntest data come from the original validation dataset from the\nsame source of the training dataset when MTR is being trained.\nThe out-of-distribution comes from a new and different dataset\nthan the training dataset. Specifically, we choose to use\nWOMD as the training dataset and Argoverse as the test\ndataset. Therefore, WOMD is considered as in-distribution,\nand Argoverse out-of-distribution. In the experiment, we mix\ndifferent ratios of in-D and OOD data into the test dataset.\nThe experiment results are shown in Fig. 4(a). As we can\nsee, the performance gain increases when the ratio of OOD\ndata increases in the test dataset. When the OOD ratio reaches\n100%, the performance gain reflects the results in Table I.\nThe monotonic increase of performance gain aligns with the\nexpectation: The advantage of the routing function should\nnot be obvious when in-D data is the majority. In this case, a\ngood portion of MTR predictions should be the better choice\nover the constant velocity model prediction. As the OOD\nratio goes up, more and more constant velocity predictions\nbecome competent, and therefore, the benefits of leveraging\na routing function become more visible. It is also worth\nnoting that when all data is in distribution, the performance\ngain is slightly below zero. This is not surprising because a\ngood generalization ability typically comes with a sacrifice\nof in-distribution accuracy. The routing function is not 100%\naccurate in selecting a better prediction candidate out of the\nindividual predictors, but as the performance of individual\npredictors decreases with the OOD ratio increase, the routing\nfunction becomes capable of picking the correct one."}, {"title": "D. Practical Implementation", "content": "In this section, we conduct an ablation study on the effect\nof prediction horizon on the performance improving scale by\nEqn. (3) compared to a nominal MTR. As a default setting,\nwe choose to use the common 80 time steps (8 sec) as the\nhorizon of the prediction task. However, it should not be\nsurprising that a shorter horizon can close the gap between\ndeep learning-based and rule-based prediction algorithms,\nno matter which one is better, because it is intuitive that\nwithin a short time window, the trajectory of the traffic agent\nresembles a constant velocity trajectory.\nThe experiment results are shown in Fig. 4(b). As we\ncan see from the figure, the performance gain at one time\nstep is only 4.1%, while it is 57.3% at 80 time steps. The\nperformance gain monotonically increases as the prediction"}, {"title": "V. EXPERIMENTS", "content": "horizon increases from 1 to 80, indicating that APE has\nmore advantage over a single deep learning-based prediction\nalgorithm in longer horizon tasks. This aligns with our\nexpectation that a shorter horizon of trajectories resembles\nconstant velocity trajectories, and both deep learning-based\nand rule-based prediction methods can fit well. As the horizon\nbecomes longer, the advantage of leveraging a routing function\nbecomes more remarkable since it can correctly pick out the\nbetter prediction candidate from the two increasingly different\nprediction candidates.\nAnother observation on Fig. 4 is that the increase of\nperformance gain from 1 to 80 time steps tends to slow\ndown when the horizon becomes longer. This shows that the\ngap between deep learning-based and rule-based prediction\ndoes not increase indefinitely as the horizon increases."}, {"title": "VI. CONCLUSIONS AND DISCUSSIONS", "content": "In this work, we tackled the critical challenge of general-\nizing motion prediction algorithms for autonomous driving\nacross different datasets. The proposed Adaptive Prediction\nEnsemble framework, incorporating a deep learning expert,\na rule-based expert, and a learned routing function, offers\na promising solution to improve zero-shot performance.\nOur experiments demonstrate that by effectively leveraging\nthe strengths of both deep learning and rule-based models,\nwe can achieve substantial gains in prediction accuracy\nand robustness, especially in challenging out-of-distribution\nscenarios and long-horizon predictions. While our approach\nshows promising results, there are several avenues for\nfuture explorations. Investigating more sophisticated rule-\nbased models and incorporating additional expert predictors\ncould further enhance the system's performance. Additionally,\nexploring different uncertainty estimation techniques for the\nrouting function could lead to more refined decision making."}]}