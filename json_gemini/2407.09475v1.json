{"title": "Adaptive Prediction Ensemble:\nImproving Out-of-Distribution Generalization of Motion Forecasting", "authors": ["Jinning Li", "Jiachen Li", "Sangjae Bae", "David Isele"], "abstract": "Deep learning-based trajectory prediction models\nfor autonomous driving often struggle with generalization to out-\nof-distribution (OOD) scenarios, sometimes performing worse\nthan simple rule-based models. To address this limitation, we\npropose a novel framework, Adaptive Prediction Ensemble\n(APE), which integrates deep learning and rule-based prediction\nexperts. A learned routing function, trained concurrently with\nthe deep learning model, dynamically selects the most reliable\nprediction based on the input scenario. Our experiments on\nlarge-scale datasets, including Waymo Open Motion Dataset\n(WOMD) and Argoverse, demonstrate improvement in zero-\nshot generalization across datasets. We show that our method\noutperforms individual prediction models and other variants,\nparticularly in long-horizon prediction and scenarios with a\nhigh proportion of OOD data. This work highlights the potential\nof hybrid approaches for robust and generalizable motion\nprediction in autonomous driving.", "sections": [{"title": "I. INTRODUCTION", "content": "Trajectory prediction is critical for safe and reliable au-\ntonomous vehicle systems. Existing prediction algorithms [1],\n[2], [3], [4] have achieved high accuracy on real-world\nscenarios, such as real traffic datasets. However, most of\nthese algorithms only work best for in-distribution scenarios.\nIntuitively, traffic scenarios in different cities of the same\ncountry should not possess drastic differences, and human\ndriving skills including their prediction and judgment, are\nnot significantly affected. This is unfortunately not the case\nfor deep learning-based prediction algorithms [5], [6], [7].\nIf they are applied to out-of-distribution (OOD) scenes in a\nzero-shot manner, such as predicting vehicle trajectories from\na different dataset than the training dataset, the performance\nwill drop dramatically even though the input representation\nand format are the same. In some cases, a deep learning-based\nprediction algorithm is not even as good as a simple constant\nvelocity model, as shown in Fig. 1. This is unfortunately a\nlargely under-explored topic. One natural way is to combine\nthe prediction from different sources, which resembles the\nmixture of experts. As far as we know, we are the first to\nexplore concrete methods to improve OOD generalization to\ndifferent datasets than training.\nMixture of Experts (MoEs) [8] has gained popularity,\nespecially after the great success of Large Language Models.\nMost of the prior work showed MoEs can reach faster\ninference [9], [10] compared to dense models with the\nsame number of parameters, and can also be pre-trained\nfaster [11], [12]. While they focused on MoEs' advantage\nover a comparable dense model in size, we are more interested\nin investigating the generalization ability improvements upon\na single expert model. We generally find that deep learning\nprediction models tend to overfit their training dataset,\nmaking zero-shot performance unacceptable. Incorporating\na fleet of deep learning prediction experts or adopting a\nsimilar size large dense model would not solve the problem,\nsince increasing the model capacity would not mitigate\nthe overfitting problem if not making it worse. Therefore,\nwe propose to employ a rule-based prediction expert as\nan anomaly-handling strategy for deep learning prediction\nexperts, in light of the insight that rule-based prediction could\nbe more reliable in long-tail cases of deep learning prediction\nexperts.\nThere are other existing methods for domain generalization\nthat usually handle the problem by data manipulation [13],\nrepresentation learning [14], [15], or specially designed\nlearning strategy [16], [17] or inference workflow [18]. If\none aims to improve the generalization upon an existing\nprediction model with prior methods, it is usually inevitable\nto make modifications and re-train the original prediction\nmodel. In comparison, the proposed method in this paper\nis a straightforward yet powerful approach to generalization\nimprovement by establishing a routing function and incorpo-\nrating a rule-based baseline prediction model. The routing\nfunction is trained concurrently with the prediction model\nand decides on whether to switch to the rule-based model\nwhen the learning-based prediction model is unreliable.\nThe main contributions of this paper are as follows:\n\u2022\n\u2022\n\u2022\nWe identify the problem of generalization when zero-\nshot evaluating state-of-the-art (SOTA) prediction models\nbetween different benchmark datasets. The performance\n(e.g., minADE and minFDE) of SOTA models drops\ndrastically. For these cases, it is even possible that basic\nrule-based prediction algorithms outperform sophisti-\ncated deep learning-based prediction models.\nWe propose a novel inference framework, Adaptive\nPrediction Ensemble (APE), where the learning-based\nprediction model will fall back to a rule-based model\naccording to their reliability. Their reliability is estimated\nby a routing function trained concurrently with the\nlearning-based prediction model.\nWe evaluate the proposed training pipeline and inference\nframework on benchmark datasets including Waymo\nOpen Motion Dataset (WOMD) [19] and Argoverse\ndataset [20], which shows that the proposed method sig-\nnificantly improves prediction performance in zero-shot\nevaluations compared to individual prediction models."}, {"title": "II. RELATED WORKS", "content": "Motion prediction algorithms for autonomous driving\nhave been successful on many datasets, and have been\nintegrated into the autonomy stack [21], [22], [23], [24], [25].\nHowever, it is not rare that prediction failure causes erroneous\ndownstream motion planning for autonomous vehicles [26].\nTherefore, it is desired to detect such prediction failure in an\nefficient yet reliable manner. There have been many efforts to\nleverage uncertainty estimation to decide whether a prediction\nis reliable [27]. The prediction uncertainty was estimated\nby various methods, including ensemble [28], [29], [30],\ndedicated uncertainty estimation model training [27], rule-\nbased estimation [31], and data augmentation [32]. However,\ntraining new models specialized in uncertainty estimation and\nperforming evaluations on its accuracy is not a straightforward\ntask, because there is often no ground truth. Ensemble-based\nuncertainty estimation is costly both during training and\ninference and may introduce too much variance, reducing\nthe reliability of out-of-distribution detection as we show\nin the ablation study in Sec. V-F. Our method of training\na routing function concurrently with individual learning-\nbased predictors can increase the exposure of the routing\nfunction to anomalous trajectory prediction upon the normal\ntraining dataset, and therefore the final prediction selected\nfrom various predictor experts can have better performance\non zero-shot generalization tasks.\nThere are also mixture-of-experts methods that collect\na set of experts specializing in different sub-tasks, which\nare likely to be included in the target domain [8]. These\nmethods will then choose one suitable expert to be activated\nduring inference. In our setting, we do not assume a pre-\ndefined set of sub-tasks in the target domain, and we also\nobserved that deep learning-based predictors tend to have\nunsatisfying performance on cross-dataset generalization.\nTherefore, we follow the idea of mixture-of-experts but do\nnot train individual experts for specific sub-tasks. We include\nboth deep learning-based and rule-based experts that can\nperform general motion prediction tasks. A routing function\nis trained concurrently with deep learning-based predictors, so\nit is exposed to more diverse trajectory prediction candidates\nand hence the difficulty of ranking anomalous predictions is\nmitigated.\nIt is also a popular trend to finetune models on the\ntarget domain to improve generalization with guidance by\nexperts trained from offline human demonstration [33] or\na ranking function trained with human feedback [34], [35].\nWhile these methods are appealing and we could directly\napply the ranking function as a routing function in MoE,\nthey are not viable in our setting as we aim to deal with\nzero-shot generalization, and hence the algorithm does not\nhave access to the target domain or test data. We do not\nhave resources for human feedback on tens of millions of\ntrajectories either, so it is desired to leverage the routing\nfunction trained in an automated pipeline, where we collect\nall the trajectory predictions output by the individual deep\nlearning-based predictor since its training begins. In this way,\nall the footprints of the prediction outputs, no matter bad or\ngood, are included in the routing function training dataset.\nThe increased exposure beyond the training dataset of the\nindividual predictor boosts the ranking ability of the routing\nfunction to differentiate reliable prediction candidates from\nbad ones, and thus improves the zero-shot performance."}, {"title": "III. PROBLEM FORMULATION", "content": "In this paper, we focus on zero-shot learning and evaluate\nthe motion prediction neural network models on samples\nthat were not observed during training in the autonomous\ndriving domain. Specifically, we denote $x = \\{x_t | t \\in \\{1,...,T\\}\\}$, as a single agent trajectory in the i-th scene,\nrepresented by a series of features $x_t$ from timestep 1 to T.\nThe agents are constantly interacting with the environment\nfor which the context information can be represented by\n$c_t = \\{c_t \\in (1,T)\\}$. The i-th scene is denoted by $s_i =$\n$\\{(x_t, c_t) | t \\in (1,T)\\}$. The task of the prediction model is to\npredict future trajectory distribution $p(x_{h+1:T_f} | x_{1:T_h}, c_{1:T_h})$\nfor an ego agent given its history features (states) $x_{1:T_h}$ and\ncontext information $c_{1:T_h}$ in the i-th scene, where $T_h$ is\nthe history horizon and $T_f$ is the lookahead horizon and $T =\nTh +Tf$.\nWe are particularly interested in inspecting and improving\nthe generalization ability upon deep learning-based prediction\nmodel, which is trained on one dataset $D_T = \\{s_i | i \\in$\n$(1, M_T)\\}$, and evaluated on another dataset $D_e = \\{s_i | i \\in$\n$(1, M_e)\\}$. Note that in this paper, the training and the\nevaluation datasets are defined differently than the normal\nconvention of training and validation. They may or may not be\ngenerated from the same underlying distribution. We evaluate"}, {"title": "IV. ADAPTIVE PREDICTION ENSEMBLE", "content": "In this section, we present our approach, Adaptive Pre-\ndiction Ensemble, to improving the test-time performance\nof motion prediction algorithms in zero-shot generalization\ntasks. It consists of two stages: 1) during the training stage, a\ndeep learning-based prediction model and a routing function\nare trained concurrently; and 2) during the testing stage, a\nrule-based prediction model is incorporated, and the final\nprediction output is adaptively selected out of both deep\nlearning-based and rule-based prediction candidates by the\nrouting function according to their quality.\nWe propose to adopt high-capacity neural networks with a\npowerful scene encoding module and a motion forecasting\ndecoder module as the backbone for all deep learning models\nin this paper, leveraging their superior scene context encoding\nand understanding ability.\nThe deep learning prediction expert takes in a vector-\nized representation, including both history trajectories of\nthe vehicles in the scene and road map polylines, as the\ninput representation [36], where all the vector inputs are\ncentered around the ego agent. The input should be processed\nby a PointNet-like [37] encoder before being consumed\nby a scene encoder. The scene encoder understands most\nof the context information and generates embeddings for\ndownstream prediction tasks. The extracted scene features are\nfed into a decoder module with multiple layers. This module\nprogressively refines the understanding of the scene dynamics\nand ultimately generates predictions for the future trajectories\nof surrounding vehicles, potentially including multi-modal\npredictions. The predictions are obtained through specialized\nprediction heads attached to the decoder layers. The training\nprocess optimizes the network to maximize the likelihood of\nthe predicted trajectories matching the actual ground truth data.\nThis is achieved by formulating the motion prediction task\nas a Gaussian Mixture prediction and employing a negative\nlog-likelihood loss function $L_{pred}$\u00b7\nGenerally speaking, our proposed framework does not have\nany strict requirement on specific deep learning prediction\nmodels as individual predictor experts, rather we could apply\nany high-performance models as long as they have the\naforementioned properties.\nRule-based prediction experts can work as a powerful\nbackup plan for the deep learning prediction expert. Deep\nlearning prediction experts suffer from long-tail problems,\nwhich in contrast are not such a challenge for rule-based\nprediction experts. Among numerous rule-based prediction\nalgorithms, we discover that a constant velocity model can be\nsufficient to showcase the improvements upon a single deep\nlearning prediction model on the zero-shot test. Specifically,\nwe adopt a closed-form prediction model to extrapolate the\nego agent's trajectory with a constant velocity,\n$x_{t+1} = f(x_t) = [x_t + v_{t,x}, y_t + v_{t,y}, v_{t,x}, v_{t,y}, \\theta_t]^T,$\nwhere $(x_t,y_t)$ is the position coordinate, $(v_{t,x}, v_{t,y})$ is the\nvelocity, $\u03b8_t$ is the heading angle of the ego agent at time t"}, {"title": "C. Learned Routing Function", "content": "With a group of experts available, a learned routing function\nis needed. Its goal is to compare the proposed candidate\npredictions generated by the experts and select the most\nreliable one as the output. Thus, the generalization and zero-\nshot performance of the whole prediction module now relies\non the ability to recognize and handle out-of-distribution\nscenarios of the learned routing function. Because the task is\nto pick the best prediction among a set of existing predicted\ntrajectories, we relax the original requirement on the zero-\nshot performance of the generative model to a zero-shot\nperformance requirement on a discriminative model, i.e.,\nthe learned routing function. In addition to the decrease in\nthe difficulty of the generalization task, the learned routing\nfunction also has access to more data modes, and its self-\nsupervised training style enables further improvements in its\ngeneralization ability.\nWe propose to adopt the same scene context encoder\narchitecture of the deep learning prediction expert and add\na routing decoder head on top of the encoder. A detailed\nstructure illustration is shown in Fig. 2. Both the high model\ncapacity and the superior scene context encoding ability can\nbe inherited, while the difficulty of generalization is reduced\nfor the learned routing function. The routing function model is\ntrained concurrently with the deep learning prediction experts\nby the loss function\n$L_e = -E_{(s,x)\\sim D} [log(\\sigma(R_{\\theta}(s_{1:T_h}, x_{T_h+1:T}^{chosen})))\n+ log(1 - \\sigma(R_{\\theta}(s_{1:T_h}, x_{T_h+1:T}^{rejected})))],\nwhere $R_{\\theta}(s_{1:T_h}, x_{T_h+1:T}^{chosen})$ and $R_{\\theta}(s_{1:T_h}, x_{T_h+1:T}^{rejected})$ are the scores\ngenerated by the routing function for the chosen prediction\ncandidate and the rejected prediction candidate, respectively,\nand $\u03c3(\u00b7)$ is a ReLU layer. $x_{T_h+1:T}^{chosen}$ is the prediction candidate\ngenerated by the individual prediction expert. This loss func-\ntion is adopted from RL with human feedback (RLHF) [38],\nwhich encourages large gaps between the scores of the two\nsamples in the pair. Empirically, we find this loss function\nresults in a more stable training process than other loss\nfunctions such as cross-entropy loss.\nAs the deep learning-based prediction model is being\ntrained, we collect all its multi-modal prediction outputs.\nThese outputs and the predictions of the rule-based experts\nfor the same agent in the same scene are paired and both\ncompared against the ground truth trajectory in terms of some\nmetric, e.g., the average displacement error. Therefore, we\ncan have a ground truth of which predicted trajectory is better\namong the two. These pairs and labels are stored in a new\ndata buffer than the original training dataset and are used\nto train the learned routing function. As the training of the\ntransformer prediction model goes on, its prediction output\ngoes from sub-optimal to more reasonable than the rule-based\nexpert predictions. Thus, the learned routing function can\nhave access to both cases where transformer prediction is\nworse or better than the rule-based prediction, and hence we\ncan avoid the issue of mode collapse."}, {"title": "D. Practical Implementation", "content": "We summarize our complete algorithm in Algorithm 1.\nDuring the training phase, we train a deep learning prediction\nmodel as one of the experts. As it is being trained, we\ncollect and compare its outputs with predictions from the\nrule-based expert against the ground truth, and use the labeled\npairs of predictions to train a routing function with the same\ntransformer encoder structure and an additional routing head.\nIn the test phase, the environment states are input to both\ndeep learning and rule-based prediction models, which both\nmake proposals. The learned routing function consumes them\nand selects the better one as the final prediction result."}, {"title": "V. EXPERIMENTS", "content": "We adopt the state-of-\nthe-art prediction architecture MotionTransformer (MTR) [2]\nas the backbone of the deep learning prediction expert. It\ningests a vectorized representation, including both history\ntrajectories of the vehicles in the scene and road map polylines,\nas the input representation [36], where all the vector inputs\nare centered around the ego agent. The inputs are first\npreprocessed by a PointNet-like [37] polyline encoder and\nthen fed into the transformer scene context encoder. The scene\nencoder enforces local attention which emphasizes the focus"}, {"title": "C. Evalution Metrics", "content": "We follow the convention in motion prediction and adopt\nthe commonly used metrics for evaluation.\nThis metric computes the average of the\n$\\ell_2$-displacement between the ground truth trajectory and\nthe closest prediction among six trajectory predictions:\n$\\minADE = \\frac{1}{T} \\sum_{t=1}^T \\min_{k\\in\\{1,...,\\kappa\\}} ||\\hat{y}_{t}^{k} - y_{t}^{SG}||_2,$\nwhere k represents the number of modes predicted by\nthe model. We choose $\u03ba = 6$ in this paper. We also use\nthis metric to rank the prediction generated by different\nexperts when training the learned routing function.\n$\\ell_2$-displacement\nbetween the ground truth trajectory and the closest\nprediction at the last time step:\n$\\minFDE = \\min_{k\\in\\{1,...,\\kappa\\}} ||\\hat{y}_{T}^{k} - y_{T}^{SG}||_2.$\nA miss is defined as the condition wherein\nnone of the M predicted object trajectories lie within\nthe specified lateral and longitudinal tolerances of the\nground truth trajectory at a designated time T.\nThis metric is computed on top of Miss Rate.\nThe predictions that are classified as a miss are labeled\nas negative, whereas non-miss is positive. Precision and\nrecall are computed based on sorted confidence scores\nassociated with each prediction. The mAP metric is then\ncomputed as the interpolated precision values in [39].\nThis metric offers a holistic assessment of the motion\nprediction performance.\nIn addition to the aforementioned common metrics for\nprediction tasks, we also propose to use Performance Gain\nPercentage to quantify the improvement upon baseline meth-\nods with our proposed method, which is defined as\nPerf Gain = 100% - $\\frac{Metric(Proposed Method)}{Metric(Baseline Method)},$\nand will be applied to ablation study in Sec. V-H and V-G."}, {"title": "D. Implementation Details", "content": "The feature input projection layer is set to be a 3-layer\nMLP with a hidden dimension of 256. We stack 6 transformer\nlayers for the scene encoding layer. The embedding feature\ndimension of these layers is set to be 256. The motion\nprediction decoder and output projection head follow the\nimplementation of MTR [2]. The routing function decoder is\na stack of 6 transformer layers with an embedding feature\ndimension of 256. The output projection head is a 3-layer\nMLP with a hidden dimension of 256. The routing function\ndecoder and output projection are updated with the scene\nencoder frozen, after each time the motion prediction decoder\nis updated. The models are trained by AdamW optimizer on\n4 GPUs (Nvidia RTX 6000) for 30 epochs with a batch size\nof 60 and a learning rate of le-4, which is decayed every 2\nepochs by a factor of 0.5."}, {"title": "E. Prediction Generalization Performance", "content": "The full evaluation of the prediction generalization per-\nformance involves a bi-directional zero-shot generalization\nevaluation. For one direction, we train prediction algorithms\non WOMD, and zero-shot test them on Argoverse. The\nopposite direction of generalizing from Argoverse to WOMD\nis also evaluated for completeness. Since Argoverse only\ncontains agent type Vehicle, we only enable predictions\non vehicles in WOMD as well for fairness.\nWe show the performance of APE along with various\nbaselines and variants in Table I, and visualizations of\npredicted trajectories of both experts in different scenarios in\nFig. 3. According to Table I, the proposed Adaptive Prediction\nEnsemble with a mixture of experts outperforms all baselines\nand variants in our bi-directional generalization evaluation.\nWe attribute the performance improvements to the capability\nof the routing function and the contribution from different\nexpert prediction methods. The routing function learns good\nprediction selection skills even though the test scenarios\nare out-of-distribution for individual prediction algorithms\nbecause it gets exposed to more diverse input (i.e., trajectory\nprediction candidates) during its concurrent training with other\nindividual predictors. The difficulty level of its generalization\nis mitigated by the exposure to a diverse data distribution.\nTherefore, as a coordinator, the learned routing function can\nstitch a more powerful predictor out of individual experts.\nIt is also interesting to note that the constant velocity\nmodel performs better on Argoverse with a minADE of\n3.2680 m than WOMD with a minADE of 6.5713 m. This\nindicates that WOMD contains more complicated prediction\ntasks than those in Argoverse, possibly with more turns\nand fewer go-straight scenarios. This statement can also\nbe shown from a smaller minADE on Argoverse for MTR\n(Oracle) than WOMD. However, no matter which direction\nof generalization is performed, the proposed method always\noutperforms an individual prediction algorithm, thanks to\nthe concurrent training of the routing function and diverse\nprediction candidates from individual predictors.\nWhen generalizing from Argoverse to WOMD, the constant\nvelocity model outperforms MTR in terms of minADE. This\nshows that it is possible for a rule-based predictor to perform\nbetter than a deep learning-based predictor, and hence it is\nnecessary to design strategies to improve the generalization\nability of a learning-based predictor, with the proposed APE\nas one possible solution."}, {"title": "F. Yet Another Routing Function", "content": "In this section, we aim to evaluate another type of routing\nfunction and compare it with the proposed learning-based\none that is trained concurrently with the individual predictors.\nThe prediction selection can also be executed by a routing\nfunction based on uncertainty estimation. We choose to use\nthe most widely used method, bootstrapping model output\nvariance, as the uncertainty estimation method in the routing\nfunction variant. The variant with a routing function based on\nbootstrapping uncertainty estimation is named APE (BS) in\nour experiment. Concretely, we use the variance of three MTR\nprediction outputs as the epistemic uncertainty estimation of\nthe learning-based prediction model, where the three MTR\nmodels are randomly initialized and trained on the same\ntraining dataset. If the uncertainty estimation surpasses a\nthreshold, then the predictor will discard MTR predictions\nand choose the constant velocity prediction as the final output,\nand vice versa.\nFrom Table I, we can see that the performance of APE\n(BS) is in between the constant velocity model and MTR."}, {"title": "G. In-D and OOD Interpolation Data Mixture", "content": "In this section, we perform an ablation study on the effect of\ndifferent ratios of in-distribution (in-D) and out-of-distribution\n(OOD) test data mixture on the performance improving scale.\nWe adopt the metric, performance gain, defined in Eqn. (3) to\nmeasure the performance improving scale. The in-distribution\ntest data come from the original validation dataset from the\nsame source of the training dataset when MTR is being trained.\nThe out-of-distribution comes from a new and different dataset\nthan the training dataset. Specifically, we choose to use\nWOMD as the training dataset and Argoverse as the test\ndataset. Therefore, WOMD is considered as in-distribution,\nand Argoverse out-of-distribution. In the experiment, we mix\ndifferent ratios of in-D and OOD data into the test dataset."}]}