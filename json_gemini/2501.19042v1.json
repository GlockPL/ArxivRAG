{"title": "Swarm-Gen: Fast Generation of Diverse Feasible Swarm Behaviors", "authors": ["Simon Idoko", "B.Bhanu Teja", "K.Madhava Krishna", "Arun Kumar Singh"], "abstract": "Coordination behavior in robot swarms is inherently multi-modal in nature. That is, there are numerous ways in which a swarm of robots can avoid inter-agent collisions and reach their respective goals. However, the problem of generating diverse and feasible swarm behaviors in a scalable manner remains largely unaddressed. In this paper, we fill this gap by combining generative models with a safety-filter (SF). Specifically, we sample diverse trajectories from a learned generative model which is subsequently projected onto the feasible set using the SF. We experiment with two choices for generative models, namely: Conditional Variational Autoencoder (CVAE) and Vector-Quantized Variational Autoencoder (VQ-VAE). We highlight the trade-offs these two models provide in terms of computation time and trajectory diversity. We develop a custom solver for our SF and equip it with a neural network that predicts context-specific initialization. The initialization network is trained in a self-supervised manner, taking advantage of the differentiability of the SF solver. We provide two sets of empirical results. First, we demonstrate that we can generate a large set of multi-modal, feasible trajectories, simulating diverse swarm behaviors, within a few tens of milliseconds. Second, we show that our initialization network provides faster convergence of our SF solver vis-a-vis other alternative heuristics.", "sections": [{"title": "I. INTRODUCTION", "content": "The ability to generate diverse swarm behaviors can have numerous applications. For example, it can be used to create a data-driven simulator to train navigation policies [1], [2], [3]. It also helps to identify trajectories that meet multiple secondary criteria such as visibility [4] and legibility [5]. In spite of its importance, there has been hardly any work on generating diverse multi-modal, feasible trajectories, especially in context of robot swarms. Existing distributed [6], [7], [8] or joint trajectory optimization approaches [9], [10] are capable of generating only a single trajectory for each member of the swarm. Moreover, it is not straightforward to easily manipulate the trajectories these cited approaches generate.\nIn this paper, we leverage generative models to construct multi-modal swarm trajectories between a given start and goal state. We are inspired by the works on trajectory prediction that use generative models to capture the underlying distribution of the expert trajectories [11], [12], [13], [14]. During inference time, we can sample multiple trajectories from the learned model which subsequently leads to diverse swarm behaviors. However, what differentiates our approach from the likes of [11], [12], [13], [14] is the focus on ensuring feasibility of the predicted trajectories, without sacrificing the ability to generate real-time swarm behaviors. The key innovations underlying our approach is described next.\nAlgorithmic Contribution: We fit two generative models namely Conditional Variational Autoencoder (CVAE) and Vector-Quantized Variational Autoencoder (VQ-VAE) on the dataset of expert trajectories. Both these models provide"}, {"title": "II. PRELIMINARIES", "content": "Notations: We will use normal font letters to represent scalars. The vectors and matrices will be represented by bold-faced lower and upper case respectively. We will use $p_{i|t}$ to represent the 3D position of the $i^{th}$ robot at time-step t. The planning horizon will be represented by $H$.\nA. Constraint Description\nWe consider the following set of constraints on the generated trajectories\nBoundary Conditions: The generated trajectories should satisfy the following boundary constraints.\n$(p_{i|0},\\dot{p}_{i|0}, \\ddot{p}_{i|0}) = b_0, (p_{i|H},\\dot{p}_{i|H}, \\ddot{p}_{i|H}) = b_H,$\n(1)\nwhere $b_0$ and $b_H$ are formed by stacking start and goal positions, velocities and accelerations respectively.\nWorkspace Constraints: We require that the generated trajectories be contained within a spheroid shaped workspace. This can be enforced by the following quadratic constraints.\n$\\forall t \\forall i, ||M_w^{-1}(p_{i|t} - p_w)||^2 - 1 \\leq 0,$\n(2)\nwhere $p_w$ is the center of the spheroid and $M_w$ is a diagonal matrix formed with the axial dimension of the spheroid workspace $(a_w, \\alpha_w, b_w)$.\nInter-Robot Collision Avoidance: We model each robot as a spheroid. Thus, to generate safe swarm behaviors, we enforce the following non-convex quadratic constraints between each robot pair.\n$||M_a^{-1}(p_{i,t} - p_{j|t})||^2 - 1 \\geq 0, \\forall k \\forall i,j, \\forall t$\n(3)\nwhere, $M_a$ is a $3 \\times 3$ diagonal matrix formed with sum of individual robot axial dimensions $(\\frac{a}{2}, \\frac{a}{2}, b)$.\nB. Polynomial Parametrization\nWe parametrize the positional trajectory of the $i^{th}$ robot $p_{i|0:H}$ in the following manner:\n$p_{i|0:H} =  \\begin{bmatrix}\nW & 0 & 0\\n0 & W & 0\\n0 & 0 & W\n\\end{bmatrix} \\begin{bmatrix}\nc_{i,x}\\nc_{i,y}\\nc_{i,z}\n\\end{bmatrix} = Wc_i,$\n(4)\nwhere, $W$ is a matrix formed with the time-dependent polynomial basis functions and the $[c_{i,x}, c_{i,y}, c_{i,z}]$ is a vector of coefficients that define the trajectory. The velocities and accelerations can also be expressed in terms of the coefficients through the time dependent matrix $\\dot{W}, \\ddot{W}$\nWe roll the coefficients of all the robots together into a single vector $\\xi = (c_{1,x},...,c_{n,x}, c_{1,y},..., c_{n,y}, c_{1,z},...,c_{n,z})$. Consequently, using (4), we can re-write the constraints of the trajectory generation process in the following form\n$A\\xi = b, g(g) \\leq 0$\n(5)\nwhere the matrix A and vector b are constants. The first equality constraints is a compact representation of (1). The function g is a vectorized re-phrasing of inequalities in (3)-(2)."}, {"title": "III. MAIN ALGORITHMIC RESULTS", "content": "In this section, we present our core building blocks: the generative models and the SF equipped with a initialization network.\nA. Learning VQ-VAE Prior Over Optimal Trajectories\nThe first building block of our pipeline is a generative model that captures the underlying distribution of optimal trajectories. The basic approach is to compress the optimal trajectories to a latent space from which we can sample during the inference time. In this section, we use VQ-VAE to build this generative component because its discrete latent space is well suited to capture the multi-modality inherent in robots' trajectories.\nOur VQ-VAE architecture is shown in Fig. 2 and is a modified version of the original framework introduced in [15] for image generation. We employ a CNN encoder to compress optimal trajectories $T_e$ into a continuous latent space $Z_e \\in R^{L \\times D}$, where $L$ represents the number of latent vectors, each with dimensionality D. Each latent vector(row of $Z_e$), denoted as $z_{e,i}$, is then transformed from continuous space to discrete space by mapping $Z_e$ to $Z_q$. This transformation is done using a latent embedding matrix $E \\in R^{N \\times D}$, also called the code-book, which consists of N vectors $e_j$. For each $z_{e,i}$, the vector $e_j$ is selected based on the nearest neighbor rule (6), creating the corresponding latent vector in $Z_q$.\n$z_{q,i} = e_r$, where $r = arg\\underset{j}{min} ||z_{e,i} - e_j||_2$, for $i \\in \\{1, 2, ..., L\\}$\n(6)\nThe VQ-VAE decoder takes in $Z_q$ and transforms it into an intermediate vector $\\xi'$. This is then fed to a differentiable QP layer to obtain the coefficient $\\xi$ used to reconstruct the optimal trajectories. The role of the QP layer is to ensure that the trajectories resulting from $\\xi$ satisfy the start and goal position, velocity and acceleration constraints. The structure of the QP is same as (10) but without the inequality constraints, and thus have a closed-form solution.\nThe VQ-VAE model is trained using a loss function defined in (7), consisting of three components. The first component is the reconstruction loss which ensures that the encoder-decoder pair accurately reproduces the input trajectory. The other two components, the codebook loss (second term) and commitment loss(third term), serve to adjust the code-book vectors during training and handle the non-differentiable discretization process described in (6).\n$L_{vqvae} = ||W\\xi - T_e||^2 + ||sg[Z_e] - E||^2 + \\beta ||Z_e - sg[E]||^2$\n(7)\nPixelCNN Model: We modify the Conditional PixelCNN model [16] to enable sampling from the trained VQ-VAE. With this approach, we can generate diverse trajectories (via the VQ-VAE decoder) by conditioning the sampling process on features such as the start and goal positions, velocities, accelerations of the robots and workspace boundaries. We represent the conditioning vector as $s$.\nTo understand our PixelCNN model, recall that the discrete latent space, $Z_q$, is structured as a matrix, where each row $z_{q,i}$ is linked to the $r^{th}$ code-book vector using (6). This makes it straightforward to compress the information from $Z_q$ into a vector $h_q$, where each element stores the index of the code-book vector associated with its corresponding $z_{q,i}$. The training process for the VQ-VAE described above gives us the ground truth values for $h_q$. The PixelCNN model predicts a multinomial probability distribution over $h_q$. For example, the first element of $h_q$ can be any integer between 0 to N based on probability generated by PixelCNN (see Fig.3). Thus, sampling from this distribution allows us to create different versions of $h_q$ which in turn, leads to different variations of $Z_q$. These samples can then be passed through the VQ-VAE decoder, generating diverse trajectory outputs.\nA key characteristic of the PixelCNN model is that it generates the probability distribution over $h_q$ in an auto-regressive fashion, using (8). This means that the prediction for each element in $h_q$ is influenced by the predictions of the preceding elements, as well as the conditioning vector. During training, a cross-entropy loss is computed between the true values of $h_q$ (obtained from VQ-VAE) and the values predicted by PixelCNN. This loss is used to optimize the model's parameters for the multinomial distribution $P$.\n$P(h_q|s) = \\prod_{i=1}^{L}[p(h_{q,i}| h_{q,1},..., h_{q,i-1}, s)]$\n(8)\nB. CVAE Prior Over Optimal Trajectories\nThe auto-regressive nature of PixelCNN implies that sampling from a trained VQ-VAE would be computationally expensive, especially when the number of code-book vectors is large. Thus, in this sub-section, we present a CVAE based model, as a cheaper alternative. The latent space of CVAE is Gaussian and thus is amenable to faster sampling. However, on the other hand, the Gaussian latent space may not fully capture the multi-modality of the optimal trajectories.\nOur CVAE architecture, illustrated in Fig.5 and it builds upon the model introduced in [17]. The core idea in CVAE is to compress the expert trajectory into a Gaussian latent space. Thus, in our pipeline, the expert trajectory $T_e$ and the conditioning variable $s$, consisting of start and goal state are fed to a CNN based encoder that outputs the mean ($\\mu$) and standard deviation ($\\sigma$) of the latent variable $z$.\nThe decoder is again based on CNN. It receives the latent variable $Z$ and the conditioning variable $s$ as inputs and produces an intermediate output for the trajectory coefficients $\\xi$ that is passed to a differentiable QP layer. The output of the QP layer is $\\xi$ which is used to reconstruct back the trajectories. We recall that similar to VQ-VAE setting, the differentiable QP layer simply modifies $\\xi$ to ensure that the trajectories resulting from $\\xi$ satisfies the start and goal position, velocity and acceleration constraints.\nBoth the encoder and decoder are trained in an end-to-end fashion with the training loss defined in 9. The first term in (9) is the typical mean-squared-error loss that promotes faithful reconstruction. The second-term is the Kullback Liebler (KL) divergence loss that regulates the latent variable $z$ to be as close as possible to a unit-normal Gaussian.\n$L_{cvae} = ||W\\xi - T_e||^2 + KL[q_{\\phi}(Z|T, s), |N(0|I)]$\n(9)\nC. Safety-Filter(SF)\nOur SF is defined by the following optimization problem.\n$\\underset{\\xi}{min} = \\frac{1}{2} ||\\xi - \\xi^*||^2$\n(10)\n$A\\xi = b, g (\\xi) \\leq 0$\nThe proposed SF computes the minimal correction required to be made to VQ-VAE/CVAE predicted trajectory coefficient $\\xi^*$ to satisfy the collision and workspace constraints. We propose a custom SF solver that reduces the solution process of (10) into a fixed-point operation of the following form, where the left subscript k denotes the iteration number.\n$^{k+1}(\\xi, \\lambda) = f_{FP}(^k\\xi,^{k+1}\\lambda)$\n(11)\nWe derive the mathematical structure of $f_{FP}$ in the Appendix VII, where we also define the Lagrange multiplier $\\lambda$. But some interesting points are worth pointing out immediately. First, by carefully reformulating the quadratic constraints (3)-(2), we can ensure that the numerical computations underlying $f_{FP}$ only requires matrix-matrix products, which can be easily batched and accelerated over GPUs. Secondly, $f_{FP}$ involves only differentiable operation, which allows us to compute how changes in the initialization of $f_{FP}$ affect the convergence process. This differentiability forms the core of our learning pipeline designed to accelerate the convergence of fixed-point iteration (11).\nLearned Initialization for SF: To train an initialization network for the SF solver in a self-supervised manner, we consider a hybrid architecture shown in Fig.4. It consists of a learnable part followed by an unrolled chain of length K of fixed-point iteration. The CNN layer takes the information from the start and goal positions, velocities and accelerations and produces an encoding $c$. This is then stacked together with the trajectory coefficient $\\xi$ predicted by CVAE/VQ-VAE to form the complete context vector $v$. An MLP, then processes the context vector to get the initialization $^0(\\xi, \\lambda)$. Let $^{K}(\\xi, \\lambda)$ be the solution obtained by running the fixed-point iteration for K iterations from the predicted initialization. We formulate the following optimization problem to train the learnable part of the SF.\n$\\underset{\\Theta}{min} \\sum_{k=0}^{K-1} [|| ^{k+1}(\\xi, \\lambda) - f_{FP}(^k(\\xi, \\lambda))||^2 + ||^0\\xi - \\xi^*||^2 ]$,\n(12)\nwhere $\\Theta$ contains the weights of the CNN and MLP modules. The first term in (12) minimizes the fixed-point residual at each iteration and is responsible for accelerating the convergence of (11) [18]. The second term ensures that the initialization predicted from the MLP leads to a solution that is minimally displaced from the original VQ-VAE/CVAE predicted value. During training, the gradient of the loss function is traced through the stacked layers of $f_{FP}$ to the learnable CNN and MLP layers. This ensures that the neural network layers are aware of how its predictions are leveraged by the downstream solver and leads to highly effective warm-start for the fixed-point solver."}, {"title": "IV. CONNECTION TO EXISTING WORKS", "content": "Multi-Agent Trajectory Prediction: Our approach is related to the literature on predicting multi-agent trajectories in autonomous driving [11], [12], [13], [14] and crowd/pedestrian behavior modeling [19], [20]. The core of many of these works are indeed generative models. For example, [11], [14], [20] leverage CVAE to predict multiple trajectories. Unfortunately, translating these cited works for generating diverse robot swarm behaviors has many challenges. For example, since these works focus on trajectory predictions, they are not designed for generating multiple swarm behavior between the same start and goal positions. Moreover, they do not have explicit mechanism to ensure that the predicted trajectories satisfy workspace and collision avoidance constraints.\nOur approach is closest to a recent diffusion based model presented in [21]. The inference-time sampling from diffusion models can be guided through additional cost terms modeling goal reaching and collision avoidance. However, tuning the effect of each cost term could be tricky. Although, it is theoretically possible to extend [21] for predicting multi-modal swarm behaviors, our work provides a better alternative in the following ways. First, our SF based constraint satisfaction requires no tuning and can be accelerated using learning. Second and more importantly, diffusion models can be notoriously slow, especially while sampling a large number of samples from them. In contrast, our approach can be used online. Moreover, we show that due to our SF, simple generative models like CVAE can provide exceptionally effective while being real-time on commodity GPUs.\nLearning to Warm-start Optimization/FP Iteration: The simplest approach towards learning good initialization for optimization/FP solvers is to fit some neural network model over the dataset of optimal solution. Subsequently, the predictions from the learned model can be used to initialize the same optimizer/FP solver from where the dataset was generated [22], [23]. For example, in our context, this would entail storing the solution of (11), fitting a model to it and subsequently leveraging its predictions for warmstart. However, such approaches often fall short in practice. This is because, the notion of \"good initialization\" is very solver-specific [18]. In other words, initializations that work for an interior-point solver may not provide any computational gains if we replace it with a gradient descent routine. Thus, authors in [18] recommend hybrid architectures like that shown in Fig.4 wherein, during the training process, the neural network layers are aware of how its predictions are used by the downstream solver. Our work extends [18] to the non-convex multi-robot trajectory optimization setting.\nContribution Over Author's Prior Works: The proposed work extends [24], [25] to the multi-robot setting. Moreover, our SF solver is an improved and batched version of the optimizer presented in [10]."}, {"title": "V. VALIDATION AND BENCHMARKING", "content": "The objective of this section is twofold. First, we demonstrate that our approach is indeed capable of multi-modal feasible swarm trajectories in a scalable manner. In this context, we study trade-offs between our CVAE and VQ-VAE based approach. Second, to show the role of the initialization network in accelerating the convergence of SF solver.\nA. Implementation Details\nThe VQ-VAE, CVAE, PixelCNN and the SF were all trained using Pytorch. However, for faster inferencing, the learned SF was converted to JAX. For data collection, we uniformly sample start and goal positions from different workspaces of varying dimensions centered around the origin. The start and goal velocities and accelerations wee always kept at zero. We used an improved version of [10] to generate optimal trajectories between the sampled start and goal pairs. These were used to train VQ-VAE and CVAE.\nVQ-VAE Network Details: The VQ-VAE encoder consists of 5 layers, each with a convolution layer (128 output channels), ReLU activation, and batch normalization. The model has 512 codebook vectors (N), each with a 3-dimensional vector (D). The latent vector size (L) is 25 for the 4- and 8-agent models, and 100 for the 16-agent model to accommodate higher complexity. The VQ-VAE decoder has 4 convolution transpose layers, each with 128 output channels, ReLU activation, batch normalization, and dropout layers.\nCVAE Network Details: The CVAE encoder, like the VQ-VAE, has 5 layers with a convolution layer (128 output channels), ReLU activation, and batch normalization. The latent vector (Z) size is 25 for the 4- and 8-agent models, and 100 for the 16-agent model, with each vector having 3 dimensions. This is flattened and passed through two MLP layers to compute the mean and standard deviation of the latent vector distribution. The CVAE decoder consists of 4 convolution transpose layers (128 output channels), leaky ReLU, batch normalization, and dropout layers. Additionally, a network with two convolution layers (ReLU activation and batch normalization) processes the state vector to be concatenated with the latent space vector before being passed to the decoder.\nInitialization Network Details: The CNN layer of the initialization network (recall Fig.4) is similar to PointNet architecture but as 18 input channels. The start and goal position, velocity and accelerations in 3D forms an 18 dimensional vector. These are stacked for all the agents and passed through the input channels of the CNN to obtain a feature vector c. This is then concatenated with the VQ-VAE/CVAE outputs and passed through a 4-layer MLP consisting of linear layers, LeakyReLU activation, and batch normalization. More model details are shown in the accompanying video.\nB. Generating Multi-Modal Swarm Trajectories: CVAE Vs VQ-VAE\nFig.1 shows a typical result obtained with our approach. The first step is to sample a batch coefficients from the learned CVAE/VQ-VAE which are then converted to trajectories using (4) (first column of Fig.1). We then pass these coefficients through the SF optimizer (10) that projects all the sampled coefficients onto the feasible set, in parallel. The output of the SF are typically polynomial coefficients that define multi-modal, feasible trajectories. A few samples of the diverse swarm behavior is shown in Fig.1(b)-(g), (g)-(j). For example, consider the robot with magenta trajectory shown in Fig1(g),(j). In Fig.1(g), the robot flies over the other neighbors to avoid obstacles, while Fig.1(h), it files closer to the ground.\nDiversity: To further compare the generated behaviors with CVAE and VQ-VAE, we generated 3000 random start and goal positions for different number of robots. For each pair, we sampled 50 trajectories from the learned CVAE and VQ-VAE. We then apply SF for 200 iterations to improve the constraint satisfaction of the generated trajectories. Fig.6 (a) expresses the number of feasible solutions obtained after SF operations, as a fraction of total number of sampled trajectories (50). As can be seen, in all the cases, we obtained multiple feasible solutions. Moreover, CVAE produced more feasible solutions. However, more solutions doe not necessarily translate to more diversity. As shown in Fig.6(b), the cosine similarity of VQ-VAE based model is lower than that based on CVAE, implying that VQ-VAE leads to a more diverse swarm behavior. This in turn, can be directly attributed to the discrete latent space of VQ-VAE that is more capable of capturing multi-modality.\ntrajectories). All the timings were obtained on a RTX 3090 GPU. For smaller batch size ($\\approx 10$), both CVAE and VQ-VAE approaches can be run online, with the former capable of running at interactive-rates. For up to 8 agents, the VQ-VAE based approach is only marginally slower than the CVAE counterpart. The larger computation time required for 16 agents can be attributed to the fact that it required a VQ-VAE with a more complex latent space. At larger batch size of 200, VQ-VAE based swarm behavior generation can be done at approximately 2Hz, which is around 10 times slower than that achieved by CVAE based approach. Interestingly, the computation time of both VQ-VAE and CVAE show a very scalable increase with respect to the batch size. This is due to excellent vectorized and GPU accelerated inferencing of the learned neural network models as well as the computations underlying the SF.\nFig.7(c)-(d) show the variation of the computation time with respect to number of SF iterations for a batch size of 10. As can be seen, for both CVAE and VQ-VAE based approach, we get an almost linear growth in run-time. This trend is important as sometimes we need to run the SF for more iterations to ensure feasibility of the generated trajectories. However, in all our experiments, running SF for around 200 iterations proved enough to get a large number of feasible solutions in any given scene (recall Fig.6(a)).\nSummarizing CVAE and VQ-VAE trends\nVQ-VAE based pipeline can generate more diversity in swarm behaviors. For up to 8 agents, it can be run at an interactive rates, even with a large batch size.\nFor larger number of agents, VQ-VAE can be still be preferred choice when generating a small number of swarm behaviors (around 10).\nWhen generating a large number of scenarios for a large swarm size, CVAE can be a good alternative, especially if there are hard run-time constraints.\nWe can create an ensemble of CVAE and VQ-VAE based predictions.\nC. Validating the Efficacy of SF Initialization Network\nFig.8 shows the primal residuals of SF solver across iterations for different initialization strategies. Its mathematical formula is defined in (25)(Appendix) and dictates the feasibility of the trajectories. As can be seen, the fastest reduction in the primal residuals is observed when the SF solver is initialized with the network trained using (12). In comparison, the residual trends obtained when initialized with a naive zero vector is demonstrably worse. When the SF is directly initialized with CVAE/VQ-VAE samples, the residuals shows a mixed trend. The VQ-VAE samples are poor initializers for SF, while CVAE samples show competitive performance. This unreliability is not surprising as neither VQ-VAE nor CVAE training is aware of how SF operates. To obtain consistently good warm-start performance, it is important to embed the SF fixed-point solver within the learning pipeline (Fig.4), which ensures that the neural network layers are aware of how its predictions are leveraged by the downstream solver during training."}, {"title": "VI. CONCLUSION", "content": "We tackled an important but relatively unaddressed problem of generating multiple feasible and diverse trajectories for robot swarms. At an abstract level, this is similar to identifying diverse solutions of a highly non-convex problem. Our approach was based on combining generative models with a SF based inference-time corrections. Moreover, to ensure computational efficiency, we also trained an initialization network that dramatically accelerated the convergence of our custom SF solver. We empirically analyzed the use of CVAE and VQ-VAE as generative models from the point of view of trajectory diversity and computation time. We believe our approach is a first of its kind that opens up new possibilities in data-driven simulation and multi-robot coordination. Although not presented here, we also did extensive experimentation with diffusion models. But the slow diffusion sampling, especially for larger batch size implied slow generative process. We believe VQ-VAE in conjunction with SF provides a good trade-off between model complexity and trajectory diversity. In future, we aim to apply our approach for controlled traffic generation for autonomous driving simulation and develop ways to condition the generative process on natural language descriptions. For the former application, we are looking to bring in ways to enforce road-structure or map constraints into our generative process."}, {"title": "VII. APPENDIX", "content": "In this section", "10": "to incorporate workspace constraints ((2)) and show that our SF optimizer steps are differentiable and can be run in a batched fashion over GPUs.\nA. Custom SF optimizer\n1) Quadratic Constraints in Spherical Form: The inter-robot collision avoidance constraints (3) can be re-phrased into the following spherical form.\n$p_{i|t"}, "p_{j|t} =  \\begin{bmatrix}\na_{ij|t} d_{ij|t} cos \\alpha_{ij|t} sin \\beta_{ij|t}\\na_{ij|t} d_{ij|t} sin \\alpha_{ij|t} sin \\beta_{ij|t}\\nb_{ij|t} d_{ij|t} cos \\beta_{ij|t}\n\\end{bmatrix}, 1 \\leq d_{ij|t} \\leq \\infty,$ (13)\nwhere $\\alpha_{ij|t}, \\beta_{ij|t}$ and $d_{ij|t}$ are the spherical angles and normalized line of sight-distance between the agents. These are unknown and will be obtained by the SF optimizer along with other variables.\nFollowing a similar notation, we can re-write the workspace constraints (2) in the following manner.\n$p_w =  \\begin{bmatrix}\na_w d_{w,i|t} cos \\alpha_{w,i|t} sin \\beta_{w,i|t}\\na_w d_{w,i|t} sin \\alpha_{w,i|t} sin \\beta_{w,i|t}\\nb_w d_{w,i|t} cos \\beta_{w,i|t}\n\\end{bmatrix}, 0 \\leq d_{w,i|t} \\leq 1,$\n(14)\n2) Reformulated Problem: Using (13)-(14) and the polynomial representation (4), we get the following reformulation of the SF optimizer.\n$\\underset{\\xi,\\alpha,\\alpha,\\beta}{min} \\frac{1}{2} ||\\xi - \\xi^*||^2$\n(15)\n$A\\xi = b$\n(16)\n$F\\xi = e(\\tilde{\\alpha}, \\tilde{\\beta}, d)$\n(17)\n$d_{min} \\leq d \\leq d_{max}$\n(18)\n$F =  \\begin{bmatrix}\nF_o\\n0\\n0\\n0\\n\\end{bmatrix}, e = \\begin{bmatrix}\nc d cos \\alpha sin \\beta\\nX_w + a_w d cos \\alpha_w sin \\beta_w\\nc d sin \\alpha sin \\beta\\nY_w + a_w d sin \\alpha_w sin \\beta_w\\nc d cos \\beta\\nZ_w + b_w d cos \\beta_w\n\\end{bmatrix},$\n(19)\n$\\tilde{\\alpha} = (\\alpha, \\alpha_w), \\tilde{\\beta} = (\\beta, \\beta_w), d = (d, d_w)$. The $\\alpha$ is formed by stacking $\\alpha_{ij|t}$ for all agent pairs $(i,j)$ and all time step t. Similarly, $\\alpha_w$ is formed by stacking $\\alpha_{w,i|t}$ for all $i$ and t. We follow similar construction for $\\beta, \\beta_w, d$, and $d_w$. The constants $(X_w, Y_w, Z_w)$ are the components of the workspace center $p_w$. The matrix $F$ is defined in the following manner.\n$F = \\begin{bmatrix}\nF_{0,1} & F_{0,2} & ... & F_{0,n-1}\n\\end{bmatrix}, F_{0,i} = [F_i \\otimes I"], "Process": "We relax the non-convex equality constraints (17) as penalties and augment them into the cost function using the Augmented Lagrangian method\n$\\mathcal{L} = \\frac{1}{2} ||\\xi - \\xi^*||^2 + \\frac{\\rho}{2} ||F\\xi - e(\\tilde{\\alpha},\\tilde{\\beta},d) - \\lambda||_A^2,$\n(22)\nwhere $\\rho$ is a known constant and the variable $\\lambda$ are so-called Lagrange multipliers. We minimize (22) subject to (16) through an Alternating Minimization (AM) approach, wherein at each step, only one variable group among $\\xi, \\tilde{\\alpha}, \\tilde{\\beta}, d$ is optimized while others are held fixed. Specifically, the AM routine decomposes into the following iterative steps, wherein the left superscript k tracks the values of a variable across iterations. For example, $^k\\xi$ is the value of $\\xi$ at iteration k.\n$^{k+1}\\tilde{\\alpha} = arg\\underset{\\tilde{\\alpha}}{min} \\mathcal{L}(^k\\xi,\\tilde{\\alpha},^k\\tilde{\\beta},d, ^k\\lambda) = f_1(^k\\xi)$\n(23a)\n$^{k+1}\\tilde{\\beta} = arg\\underset{\\tilde{\\beta}}{min} \\mathcal{L}(^k\\xi,^{k+1}\\tilde{\\alpha},\\tilde{\\beta},d, ^k\\lambda) = f_2(^k\\xi)$\n(23b)\n$^{k+1}d = arg\\underset{d_{min} < d < d_{max}}{min} \\mathcal{L}(^k\\xi,^{k+1}\\tilde{\\alpha},^{k+1}\\tilde{\\beta},d, ^k\\lambda) = f_3(^k\\xi)$\n(23c)\n$^{k+1}\\lambda = ^k\\lambda + \\rho F(F^k\\xi - e(^{k+1}\\tilde{\\alpha}, ^{k+1}\\tilde{\\beta}, d))$\n(23d)\n$^{k+1}\\xi = arg\\underset{A\\xi = b}{min} \\mathcal{L}(\\xi, e(^{k+1}\\tilde{\\alpha}, ^{k+1}\\tilde{\\beta}, d), ^{k+1}\\lambda)$\n(23e)\n$^{k+1}\\xi = M^{-1}\\eta$\n(23f)\n$M = I + \\rho F^T F , \\eta = \\rho F^T(^{k+1}e - \\frac{^{k+1}\\lambda}{\\rho}) + \\xi^*,\\begin{bmatrix}\nA\\\\A^T & 0\n\\end{bmatrix} \\begin{bmatrix}\n\\xi\\\\\\lambda\n\\end{bmatrix} =  \\begin{bmatrix}\n\\rho F^T(^{k+1}e + \\frac{^{k+1}\\lambda}{\\rho}) + \\xi^*\\\\b\n\\end{bmatrix},$\n(24)\nThe minimization (23a)-(23c) have a closed-form solution which can be expressed as a function of $^k\\xi$ [6], [10]. Similarly, (23e)"}