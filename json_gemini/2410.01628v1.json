{"title": "ENTROPY-BASED UNCERTAINTY MODELING FOR TRAJECTORY PREDICTION IN AUTONOMOUS DRIVING", "authors": ["Aron Distelzweig", "Andreas Look", "Eitan Kosman", "Faris Janjo\u0161", "J\u00f6rg Wagner", "Abhinav Valada"], "abstract": "In autonomous driving, accurate motion prediction is essential for safe and efficient motion planning. To ensure safety, planners must rely on reliable uncertainty information about the predicted future behavior of surrounding agents, yet this aspect has received limited attention. This paper addresses the so-far neglected problem of uncertainty modeling in trajectory prediction. We adopt a holistic approach that focuses on uncertainty quantification, decomposition, and the influence of model composition. Our method is based on a theoretically grounded information-theoretic approach to measure uncertainty, allowing us to decompose total uncertainty into its aleatoric and epistemic components. We conduct extensive experiments on the nuScenes dataset to assess how different model architectures and configurations affect uncertainty quantification and model robustness.", "sections": [{"title": "INTRODUCTION", "content": "In a machine learning driven Autonomous Driving (AD) stack, motion prediction connects the upstream task of environment perception with the downstream task of ego-motion planning (Hu et al., 2023). The role of a motion predictor is to infer the future motion of traffic agents relevant to the ego, ensuring safe and efficient progress toward a goal (Hagedorn et al., 2024). To achieve this, a predictor must tackle several challenges such as imperfect perception, complex interactions between traffic agents, as well as the multitude of distinct potential actions each agent might undertake, motivated by different goals. Such challenges drive the need to consider the problem in a probabilistic manner and incorporate uncertainty into prediction outputs. Accurately quantifying prediction uncertainty is essential for ensuring interpretability and building trust in the overall system.\nIn the AD community, the future motion of surrounding traffic agents is often modeled in the form of trajectories. Thus, probabilistic trajectory prediction involves capturing a distribution p(y|x, D) of future trajectories y conditioned on contextual data x and a dataset D. Contextual data x usually contains past trajectories of surrounding agents and map information. There are different strategies for capturing this highly multi-modal distribution owing to the distinct actions or goals. Some methods attempt to directly predict the modes of the distribution along with their associated weights (Gao et al., 2020; Kim et al., 2021; Deo et al., 2022). Others use a parametric mixture distribution, such as a Gaussian Mixture Model (GMM), where the modes correspond to the predicted trajectories (Tolstaya et al., 2021; Varadarajan et al., 2022; Liu et al., 2024; Look et al., 2023). Alternatively, generative trajectory prediction models use well-known autoencoder or diffusion architectures to model latent variables and draw trajectory samples (Salzmann et al., 2020; Seff et al., 2023; Janjo\u0161 et al., 2023a; Jiang et al., 2023).\nThe majority of approaches for modeling the distribution of future trajectories, p(y|x, D), in AD rely on neural networks. They are often underspecified by the available data, meaning that no single parameter configuration is favored. When considering uncertainty in the model parameters, the predictive distribution (Kapoor et al., 2022; MacKay, 1992) over future trajectories is computed as\n$p(y|x, D) = \\int p(y|x, W)p(W|D)dW \\approx \\int p(y|x,W)q(W)dW,$\nwhere W represents the neural network weights, and p(W|D) represents the posterior distribution. The predictive distribution represents a Bayesian model average, meaning that instead of relying on a single hypothesis with a specific set of parameters, it considers all possible parameter configurations, weighted by their posterior p(W|D). This marginalization process removes the reliance on a single weight configuration in the predictive distribution, resulting in better calibration and accuracy compared to traditional training methods (Wilson & Izmailov, 2020). Since the exact posterior is often intractable, various approximations q(W) have been developed, such as variational inference (Graves, 2011), Dropout (Gal & Ghahramani, 2016), Laplace approximation (Ritter et al., 2018), deep ensembles (Lakshminarayanan et al., 2017), or Markov Chain Monte Carlo (MCMC) methods (Welling & Teh, 2011).\nDespite many successful approaches of approximating the posterior distribution, the AD prediction community has not yet tried to quantify or to decompose the uncertainty of trajectory prediction models in a theoretically principled manner (Wilson, 2020). This gap is notable, especially considering the potential benefits of decomposing the uncertainty. The total uncertainty can be decomposed into two types: aleatoric and epistemic uncertainty (Wimmer et al., 2023; H\u00fcllermeier, 2021). Aleatoric uncertainty represents the inherent variability within the data, such as the equal likelihood of a vehicle turning left or right at a T-junction. This type of uncertainty cannot be reduced, even with more data. In contrast, epistemic uncertainty arises from the lack of knowledge or information and can be reduced by collecting more data (Wimmer et al., 2023). Knowledge of epistemic uncertainty is helpful in various contexts, e.g. risk-sensitive reinforcement learning (Depeweg et al., 2018) and Out-of-Distribution (OOD) detection (Amini et al., 2020). By understanding the sources of uncertainty, one can confirm that an autonomous vehicle finds itself in an OOD scenario by observing a higher epistemic uncertainty. This can be an important signal for a planner that uses predictions in its decision-making. By incorporating this information, planners can make more informed decisions and potentially take preventative actions in situations of high uncertainty."}, {"title": "2 MEASURING THE UNCERTAINTY FOR TRAJECTORY PREDICTION", "content": "This section details our method for decomposing uncertainty into aleatoric and epistemic components. We start by defining the problem of uncertainty decomposition in trajectory prediction in Sec. 2.1. Then, in Sec. 2.2, we describe our approach for calculating these uncertainties using an MC approximation. We provide pseudo-code in App. A. Finally, we discuss the limitations of our approach with possible avenues to address these limitations in Sec. 2.3."}, {"title": "2.1 PROBLEM STATEMENT", "content": "Our method focuses on uncertainty quantification in trajectory prediction tasks. The problem is defined as predicting the future trajectory of a target agent in a driving scene based on current observations. Formally, let x \u2208 RTin\u00d7Fin represent the past features of an agent, where Tin is the number of observed timesteps and Fin denotes the number of input features, such as coordinates, velocities, accelerations, and other relevant data. In line with recent trajectory prediction literature (Deo et al., 2022; Liu et al., 2024; Kim et al., 2021), we also incorporate additional contexts, such as static map information and the past trajectories of surrounding agents, into the model input. A trajectory prediction model f(x) = y, parameterized by W, uses this input to estimate a future trajectory y \u2208 RTout\u00d7Fout. Here, Tout represents the prediction horizon, and Fout is the number of output features to predict, such as coordinates. Given the multi-modal nature of an agent's future behavior, an extended version of this model predicts multiple future trajectories. The distribution over potential future outcomes, p(y|x, W), can take various forms, such as a categorical distribution Deo et al. (2022), a mixture of Laplacians (Liu et al., 2024), a GMM (Nayakanti et al., 2023), or a non-parametric form (Jiang et al., 2023). Finally, we define an ensemble (Zhou, 2012) as a set of M trajectory prediction models. These models may have different parameterizations and could belong to different model families. The ensemble can be constructed using various techniques, such as Dropout (Gal & Ghahramani, 2016), Stochastic Gradient Langevin Dynamics (SGLD) (Welling & Teh, 2011), or deep ensembles (Lakshminarayanan et al., 2017). This ensemble introduces a distribution q(W) over neural network parameters, which is an approximation to the true posterior p(W|D) (Wilson & Izmailov, 2020).\nOur objective is to develop a method for uncertainty quantification to assess a model's trustworthiness. However, the type of uncertainty to address is not always clear. On one hand, high uncertainty may stem from novel, previously unseen traffic scenarios. On the other hand, randomness arising from unpredictable driver behavior can lead to multiple plausible predictions. While previous works, such as Gilles et al. (2022) and Janjo\u0161 et al. (2023b), do not distinguish between uncertainty types, we argue that decomposing uncertainty is crucial for understanding the sources of a model's predictions. Therefore, following concurrent literature (Der Kiureghian & Ditlevsen, 2009; H\u00fcllermeier, 2021), we decompose uncertainty into epistemic and aleatoric components."}, {"title": "2.2 MONTE CARLO APPROXIMATION OF THE CONDITIONAL ENTROPY AND MUTUAL INFORMATION AS A MEASURE OF ALEATORIC AND EPISTEMIC UNCERTAINTY", "content": "To quantify uncertainty, we use entropy as a measure of total uncertainty. This allows us to frame our decomposition in terms of entropy subcomponents. Following Mobiny et al. (2021); Depeweg et al. (2018), we compute epistemic uncertainty as the difference between total and aleatoric uncertainty\n$I(y, W|x, D) = H(y|x, D) \u2013 E_{p(W|D)}[H(y|x, W)] .\n$\nAbove, I(y, Wix, D) represents the mutual information between the model's predictions and its parameters, while H(y|x, D) denotes the total entropy of the predictive distribution. The entropy of a distribution can be computed in closed form for simple cases, such as categorical distributions or univariate Gaussians. However, in trajectory prediction, the predictive distribution can take complex forms, such as a GMM (Nayakanti et al., 2023), making closed-form solutions to Eq. 2 unavailable. To address this, we use a Monte Carlo approximation. For a given input x, the entropy is approximated via set of N samples from the predictive distribution, yn ~ p(y|x, D), as below\n$H(y|x, D) = E_{y} [- log p(y|x, D)] \\approx \\frac{1}{N} \\sum_{n=1}^{N} log p(y_{n}|x, D) = \\hat{H}(Y|x, D).$\nNext, we replace the true posterior over neural network parameters p(W|D) with the approximate posterior q(W). The approximate posterior is a discrete distribution over a set of M neural network parameter values Wm, allowing us to approximate the predictive distribution as\n$p(y|x, D) = E_{p(W|D)}[p(y|x, W)] \\approx E_{q(W)} [p(y|x, W)] = \\frac{1}{M} \\sum_{m=1}^{M} p(y|x, W_{m}).$\nThe choice of the model composition q(W) significantly impacts the results, as different models may produce varied predictions, which will be explored further in Sec. 3. We then continue by inserting both Eq. 3 and 4 into the original problem as defined in Eq. 2\n$I(y,W|x,D)\\approx \\hat{H}(y|x, D) \u2013 E_{q(W)}[\\hat{H}(y|x, W)],$\n$\\frac{1}{N} \\sum_{n=1}^{N} log p(y_{n}|x, D) - E_{q(W)} [\\frac{1}{N} \\sum_{n=1}^{N}log p(y_{n}|x, W)],$\n$\\frac{1}{N} \\sum_{n=1}^{N} log (\\frac{1}{M} \\sum_{m=1}^{M}p(y_{n}|x, W_{m}) + - \\frac{1}{M} \\sum_{m=1}^{M} (\\frac{1}{N} \\sum_{n=1}^{N} log p(y_{n}|x, W_{m})).$\nAbove, ym represents the n-th sample from the m-th model, i.e., ym ~ p(y|x, Wm). In contrast, Yn represents the n-th sample from the predictive distribution after integrating out the weights, i.e., Yn ~ p(y|x, D). We visualize the sampling of yn in Fig. 2. In essence, we first collect equally-sized sets of N' samples from each distribution p(y|x, Wm), such that N = N' \u00b7 M. Concatenating them generates N samples from the distribution p(y|x, D), as the weights Wm are equally weighted.\nOur proposed approach formalized in Eq. 2-5 assumes a generic form of the distribution p(y|x, Wm). In practice, we use a continuous GMM that is ubiquitous in trajectory prediction for AD, see Sec. 4.1. Thus, we fit samples from a trajectory prediction model to a GMM, or directly use the GMM if the predictor provides one. Details around the GMM design choice can be found in App. B. In Fig. 2, we visualize GMMs fitted to the predictions from M=3 ensemble components, as well as samples from each GMM over a two-dimensional grid."}, {"title": "2.3 DISCUSSION", "content": "The approach presented above effectively quantifies uncertainty in trajectory prediction. Yet, it is important to acknowledge some current limitations and potential solutions. One notable concern is the increased memory and computational burden, which may be prohibitive for a real-time application such as trajectory prediction. A possible avenue to address this limitation is through the use of ensemble distillation. Studies have shown that it is possible to distill an ensemble into a single model, thereby significantly reducing computational overhead while maintaining comparable accuracy Malinin et al. (2019). These technique offers a promising direction for future work, ensuring that our approach remains both efficient and performant."}, {"title": "3 EXPERIMENTS", "content": "In this paper, we introduce a novel information-theoretic approach to measure and decompose the uncertainty of the predictive distribution of trajectory prediction models in the AD domain. We model the approximate posterior q(W) over neural network weights via sampling-based methods, such as dropout (Gal & Ghahramani, 2016) and deep ensembles Lakshminarayanan et al. (2017). For simplicity, we refer to any collection of neural networks as an ensemble. Our experimental analysis is divided into four parts, where we explore both the uncertainty quantification capabilities of our method and the impact of different ensemble compositions. First, in Sec. 3.1, we benchmark our method against an alternative approach to quantify the uncertainty on the original nuScenes dataset (Caesar et al., 2020), which is a commonly used real-world trajectory prediction dataset for AD. We measure the correlation between the uncertainty and the prediction error and explore how epistemic and aleatoric uncertainties complement each other. In the subsequent parts, we create artificial OOD scenarios by manipulating the nuScenes dataset in various ways. Specifically, we propose four different methods for manipulating the original nuScenes dataset, such as removing lane information or omitting parts of the past trajectories of various agents. A detailed explanation of our nuScenes manipulations is provided in App. D. In the second experimental part in Sec. 3.2, we examine the robustness of various models and ensembles across different OOD scenarios. We observe an overall increase in prediction error, indicating that our artificial OOD scenarios are more challenging than the original dataset. In the third part in Sec. 3.3, we investigate how the correlation between uncertainty and prediction error is affected in these OOD scenarios. Lastly, in Sec. 3.4, we study whether we can detect OOD scenarios by analyzing the different types of uncertainty.\nThroughout our experiments, we use our novel method to measure the total uncertainty and decompose it into aleatoric and epistemic components to understand their relative importance. We generate trajectory predictions from the ensemble using the approach described in Distelzweig et al. (2024), which involves Model-Based Risk Minimization (MBRM) to draw trajectories from an ensemble of prediction models. For single models, we generate trajectories via Topk sampling, which selects the most likely trajectories (Liu et al., 2024). We rely on LAformer Liu et al. (2024), PGP Deo et al. (2022), and LaPred Kim et al. (2021) to construct different ensembles of trajectory prediction models. These three models are among the best-performing models with available open-source implementations. In our experiments, we evaluate different ensemble configurations, including deep ensembles, dropout ensembles, and single models. We use an ensemble size of three in all experiments; for deep ensembles, we sample three different models, and for dropout ensembles, we sample three different masks. Prediction performance is assessed in terms of minADE and Minimum Final Displacement Error (minFDE) over k proposals. The minADE\u0141 measures the average point-wise L2 distances between the predicted trajectories and the ground truth, returning the minimum over the k proposals (Caesar et al., 2020). In contrast, minFDEk considers only the final predicted point. Detailed prediction results for different models and ensemble configurations on the original nuScenes dataset are provided in App. \u0421."}, {"title": "3.1 CORRELATION BETWEEN PREDICTION ERROR AND DIFFERENT UNCERTAINTY TYPES", "content": "Identifying scenarios with high prediction error is critical for safety, as it helps determine when to trust the system or when the driver needs to take control. In this experiment, we study the correlation between different types of uncertainty and prediction error using the original nuScenes dataset. More concretely, we compute the Pearson correlation coefficient p between each type of uncertainty and the minADEk. We benchmark our proposed method against Filos et al. (2020), which is an uncertainty quantification approach for planning. Prediction and planning are closely related tasks in AD (Hagedorn et al., 2024), and to the best of our knowledge, Filos et al. (2020) is the only other method with an architecture-agnostic approach that addresses uncertainty quantification in these domains. Filos et al. (2020) estimates the uncertainty by calculating the variance of the log-likelihood of future trajectories with respect to the parameters, i.e., Varq(w) [logp(y|x, W)]. Unlike our method, this approach requires access to the future trajectory y. We report the correlation coefficient between different uncertainty types and the minADE5 in Tab. 1. Additionally, results for minADE\u2081 and minADE10 are provided in App. E."}, {"title": "3.2 ROBUSTNESS OF PREDICTIONS IN OOD SCENARIOS", "content": "In the previous experiment, we analyzed the correlation between uncertainty and prediction error in in-distribution scenarios. We now shift our focus to examining whether prediction performance degrades in OOD scenarios and to what extent. We report the changes in the minADE5 metric with respect to the original dataset in Fig. 3. App. I and App. J provide additional visualizations for minADE\u2081 and minADE10 as well as numerical values.\nOverall, we observe that prediction error increases across all datasets in OOD scenarios. However, model ensembles consistently outperform individual models as in all model configurations, more than 50% of the data points fall within the upper green triangle on Fig. 3. This suggests that ensembles offer greater robustness and resilience in OOD scenarios. When comparing deep ensembles composed of the same model to their dropout-based alternatives, the performance is similar"}, {"title": "3.3 QUANTIFYING THE UNCERTAINTY IN OOD SCENARIOS", "content": "In Sec. 3.1, we investigated whether the uncertainty estimates from our method offer indications of the reliability of our model's predictions. However, it remains unclear if these findings are also applicable to OOD scenarios. In this experiment, we analyze the correlation between uncertainty and prediction error in OOD scenarios across different ensembles, and we compare these correlation coefficients with those obtained from the original dataset. We report the correlation coefficient between the total uncertainty and the minADE5 in Fig. 4. App. G and App. H provide additional visualizations for minADE\u2081 and minADE10 as well as numerical results.\nWe first compare the correlation values from the original dataset represented by the circle marker in Fig. 4 with those from the OOD datasets represented by all other markers. The results present a mixed picture \u2013 in some OOD scenarios, the correlation coefficient decreases while in others, it increases. Nevertheless, there is a general trend toward a decrease in the correlation coefficient in most OOD cases. Interesting observations can be made when focusing on a specific model ensemble, e.g. the mixed ensemble consisting of LAformer, PGP, and LaPred. Despite being applied to OOD scenarios, this ensemble maintains a higher correlation coefficient than that achieved by the alternative uncertainty quantification method proposed by Filos et al. (2020) on the in-distribution scenarios of the original dataset. This suggests that our proposed method and selected ensemble models offer more robust uncertainty quantification even under challenging conditions.\nNext, we investigate whether using an ensemble of models is more advantageous than relying on a single model in OOD scenarios. To assess this, we compare the correlation between uncertainty and prediction error for ensembles versus individual models. Our findings reveal that the ensemble configurations consistently outperform the single model baselines. This conclusion is supported by the fact that in every configuration, more than 50% of the data points lie within the green triangle. This suggests that ensembles provide a more reliable measure of uncertainty in OOD scenarios compared to single models. Lastly, we compare different model ensembles. Specifically, we compare"}, {"title": "3.4 DETECTING OOD SCENARIOS", "content": "In this experiment, our objective is to determine whether we can identify OOD scenarios in the first place. Recognizing such scenarios is critical for improving the performance and robustness of an AD system over time, as it facilitates the collection of challenging cases for re-training and evaluation. We present the uncertainty values for different types of uncertainty in Fig. 5 for both the original nuScenes dataset and various OOD scenarios. For this analysis, we restrict our focus to a mixed deep ensemble consisting of LAformer, PGP, and LaPred, as this ensemble demonstrated the best correlation between uncertainty and prediction error in previous experiments. Additionally, we include OOD detection results for other model ensembles in App. F.\nWhen analyzing epistemic uncertainty, we observe that OOD scenarios exhibit a higher median value than the upper quartile of the original dataset, with the exception of the blackout scenario, where only the median of the original dataset is exceeded. In terms of aleatoric uncertainty, the median for OOD scenarios consistently exceeds the median observed in the original dataset. The total uncertainty follows a similar pattern to aleatoric uncertainty but exhibits a more pronounced difference between OOD and in-distribution cases. These trends indicate that OOD scenarios can be identified with the highest confidence by assessing epistemic uncertainty, a finding that aligns with existing research in uncertainty quantification (H\u00fcllermeier, 2021)."}, {"title": "4 RELATED WORK", "content": "Anticipating the future motion of traffic participants is a critical component of autonomous driving systems (Hu et al., 2023). Due to the safety-critical nature of these systems, it's essential to account for and propagate uncertainties across the entire prediction stack (McAllister et al., 2017). For instance, planners need to factor in motion prediction uncertainty to accurately assess the risks associated with various driving maneuvers (Filos et al., 2020). In the following subsections, we review related work on both motion prediction as well as quantification and decomposition of uncertainty."}, {"title": "4.1 MOTION PREDICTION FOR AUTONOMOUS DRIVING", "content": "The future motion of other traffic participants is influenced by a multitude of observable and un-observable factors, rendering it a challenging modeling task. These factors include, among others, the latent goals and preferences of traffic participants, social norms and traffic rules, complex interactions with surrounding traffic, as well as constraints induced by the static environment (Rudenko et al., 2020). The shortcomings of the perception system, which provides noisy and partial observations, pose an additional challenge. These challenges necessitate a probabilistic formulation of the prediction task to adequately model the uncertain and multi-modal nature of future motion. In general, prediction models consist of two components: a behavior backbone, which encodes the traffic scene, and a decoder, which models the predictive distribution. We will highlight various implementations of the two components below.\nEarly prediction approaches (Casas et al., 2018; Chai et al., 2020; Phan-Minh et al., 2020) propose encoding the past trajectory of observed traffic participants and the elements of the static environment (e.g., lane boundaries, crosswalks, traffic signs) by rendering the scene in a semantic bird's eye view image and applying well-established convolutional neural networks (He et al., 2016). Such image-based representations of the scene have largely been replaced by vectorized representations due to their inefficiency (Gao et al., 2020; Zhao et al., 2021; Kim et al., 2021; Deo et al., 2022; Nayakanti et al., 2023). In a vectorized representation, all entities of the static and dynamic environment are approximated by a sequence of vectors. Models for sequential data, such as temporal convolutional networks (van den Oord et al., 2016) or recurrent neural networks (Hochreiter & Schmidhuber, 1997; Chung et al., 2014) are used to encode the sequences and interactions between entities are modeled using pooling operations (Alahi et al., 2016), graph neural networks (Hamilton, 2020), or Transformers (Vaswani et al., 2017).\nThe future motion of traffic participants is typically characterized by a sequence of states over multiple time steps, known as trajectories (Ngiam et al., 2022; Varadarajan et al., 2022). Several strategies are employed to capture the highly multi-modal distribution over trajectories conditioned on the encoded scene. Many approaches represent the distribution by a set of trajectories with associated mode probabilities. The trajectories are either regressed by the model (Cui et al., 2019; Liang et al., 2020; Kim et al., 2021; Deo et al., 2022) or fixed a priori (Phan-Minh et al., 2020). Other approaches use parametric mixture distributions, such as GMMs (Khandelwal et al., 2020; Tolstaya et al., 2021; Varadarajan et al., 2022) or mixtures of Laplacians (Liu et al., 2024). Alternatively, generative models such as conditional variational autoencoders (Lee et al., 2017; Bhattacharyya et al., 2019;"}, {"title": "4.2 UNCERTAINTY MODELING, DECOMPOSITION AND QUANTIFICATION", "content": "The majority of current trajectory prediction models solely account for aleatoric uncertainty by modeling a probability distribution on the output space (Varadarajan et al., 2022). To incorporate epistemic uncertainty in a theoretically sound manner, one can adopt a Bayesian framework (Kendall & Gal, 2017; Depeweg et al., 2018; Wilson & Izmailov, 2020; Wilson, 2020). A Bayesian neural network assumes a distribution over the network weights instead of a point estimate to account for the lack of knowledge about the data-generating process (H\u00fcllermeier, 2021; Jospin et al., 2022). Since analytically evaluating the posterior distribution over the weights is intractable for modern neural networks, approximate inference techniques such as Variational Inference (VI) or forms of MCMC must be considered (Jospin et al., 2022). Due to its simplicity, MC Dropout, which can be interpreted as an approximate VI method (Gal & Ghahramani, 2016), is used by many perception approaches in AD (Kendall & Gal, 2017; Abdar et al., 2021) and is also employed by Janjo\u0161 et al. (2023b) for modeling epistemic uncertainty of a trajectory predictor. Another well-established approach to account for epistemic uncertainty is deep ensembles (Lakshminarayanan et al., 2017; Jospin et al., 2022; Wilson & Izmailov, 2020). Prior work (Filos et al., 2020) uses deep ensembles to approximate the posterior distribution in their epistemic uncertainty-aware planning method. We apply MC Dropout as well as deep ensembles to approximate the uncertainty over network weights and systematically assess their performance in the context of trajectory prediction.\nA common information-theoretical measure for the uncertainty is the entropy of the predictive distribution as a measure of the total uncertainty, which can be additively decomposed into the conditional entropy and mutual information, representing a measure of aleatoric and epistemic uncertainty (Depeweg et al., 2018; Smith & Gal, 2018; H\u00fcllermeier, 2021; Wimmer et al., 2023). Alternative measures based on the variance were proposed by Depeweg et al. (2018). While variance-based measures are suitable in cases where the predictive distribution is a uni-modal Gaussian, it is less suitable for multi-modal outputs, such as trajectories. Our approach thus relies on entropy-based measures to quantify the uncertainties of trajectory prediction models. However, variance can be useful in other contexts; e.g., Gilles et al. (2022) uses the variance of the predicted heat map over future positions as an uncertainty measure. Another variance-based uncertainty heuristic is proposed by Filos et al. (2020) in the related field of motion planning for AD. This approach, however, only quantifies the epistemic uncertainty and requires access to the future trajectory. Some methods train separate models (Pustynnikov & Eremeev, 2021) or include additional heads with auxiliary tasks (Wiederer et al., 2023; Janjo\u0161 et al., 2023b) to learn a proxy measure of the uncertainty of a trajectory prediction model without a proper decomposition.\nTo the best of our knowledge, we are the first to thoroughly investigate the theoretically sound modeling, decomposition, and quantification of uncertainties for trajectory prediction models. All other published trajectory prediction approaches either do not holistically consider all three aspects or resort to heuristics."}, {"title": "5 CONCLUSION", "content": "Understanding and addressing uncertainty in probabilistic motion prediction for AD remains a key challenge. This paper addresses this gap by proposing a general approach to quantify and decompose uncertainty using an information-theoretic framework. We demonstrate that our estimates of aleatoric and epistemic uncertainty provide meaningful indicators of prediction error, making them reliable for assessing prediction performance. Through an extensive evaluation, we examine both in-distribution and out-of-distribution scenarios under various posterior assumptions. Overall, our approach advances principled uncertainty modeling in motion prediction for AD.\nA promising future direction is to integrate our uncertainty quantification framework in the planning system of an autonomous vehicle (Teng et al., 2023; Hagedorn et al., 2024). This opens the possibility of combining autonomous driving planning research with risk-sensitive reinforcement learning (Depeweg et al., 2018), enabling the system to make informed decisions in uncertain situations."}, {"title": "A PSEUDO CODE", "content": "The below pseudo code outlines the method of computing and decomposing uncertainties. Here, Gm refers to the Gaussian Mixture Model (GMM) from which we draw and score samples. We use the functions Sample and Score that implement the standard procedures for sampling and computing the probability of a sample given the distribution (Dempster et al., 1977). The Sample function takes a probability distribution as input and returns a sample. The Score function takes both the probability distribution and a sample as inputs and returns the likelihood (or score) of the sample."}, {"title": "B DISTRIBUTION ASSUMPTIONS", "content": "In this section, we briefly cover the choice of a GMM for the distribution p(y|x, Wm) assumed in Eq. 5. Note that p(y|x, Wm) can initially take either categorical or continuous forms, depending on the model. However, we transform p(yx, Wm) into a GMM, a continuous distribution, for two reasons. First, for a categorical distribution, the probability p(y|x, Wm) is zero for any sample not generated by the model with parameters Wm. This is because categorical distributions only assign non-zero probabilities to discrete outcomes they were trained on, making them unsuitable for"}, {"title": "C PERFORMANCE ON THE ORIGINAL NUSCENES DATASET", "content": "In the below table, we report the performance of different ensembles and base models on the original nuScenes dataset. We generate trajectory predictions from the ensemble using the approach described in Distelzweig et al. (2024), which involves MBRM to draw trajectories from an ensemble of prediction models. For single models, we generate trajectories via Topk sampling, which selects the most likely trajectories (Liu et al., 2024).\nIn MBRM, the below equation is optimized during inference with respect to the trajectories \u1ef9\n$\\hat{y} \\approx argmin \\sum_{m=1}^{M} \\sum_{n=1}^{N} w_{m} minADE(y_{m}^{n}, \\tilde{y}).$\nAbove ym \u2208 RT\u00d72 represents the n-th proposal trajectory of the m-th model and wm \u2208 R+ represents the corresponding weight. The number of total models is M. For more details, we refer to Distelzweig et al. (2024)."}, {"title": "D GENERATION OF OOD SCENARIOS", "content": "We create artificial OOD scenarios by manipulating the original nuScenes dataset. Below we describe our manipulation techniques.\n\u2022 RevertEGO: We revert the history of the ego/target vehicle.\n\u2022 ScrambleEGO: We randomly shuffle the history of the ego/target vehicle.\n\u2022 Blackout: We set 1/2 of the history to zero for the ego/target and all surrounding vehicles.\n\u2022 LaneDeletion: We randomly delete 3/4 of all lanes considered by the model.\nBeyond that, we consider combinations of manipulations."}]}