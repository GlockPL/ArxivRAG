{"title": "Neuro-symbolic Learning Yielding Logical Constraints", "authors": ["Yuan Yao", "Zenan Li", "Yunpeng Huang", "Zhaoyu Li", "Jingwei Xu", "Taolue Chen", "Xiaoxing Ma", "Jian L\u00fc"], "abstract": "Neuro-symbolic systems combine neural perception and logical reasoning, representing one of the priorities of AI research. End-to-end learning of neuro-symbolic systems is highly desirable, but remains to be challenging. Resembling the distinction and cooperation between System 1 and System 2 of human thought (\u00e0 la Kahneman), this paper proposes a framework that fuses neural network training, symbol grounding, and logical constraint synthesis to support learning in a weakly supervised setting. Technically, it is cast as a game with two optimization problems which correspond to neural network learning and symbolic constraint learning respectively. Such a formulation naturally embeds symbol grounding and enables the interaction between the neural and the symbolic part in both training and inference. The logical constraints are represented as cardinality constraints, and we use the trust region method to avoid degeneracy in learning. A distinguished feature of the optimization lies in the Boolean constraints for which we introduce a difference-of-convex programming approach. Both theoretical analysis and empirical evaluations substantiate the effectiveness of the proposed framework.", "sections": [{"title": "1 Introduction", "content": "Perception and reasoning serve as fundamental human abilities that are intrinsically linked within the realm of human intelligence. The objective of our study is to develop a learning framework for neuro-symbolic systems (e.g., the one illustrated in Figure 1), enabling simultaneous learning of neural perception and symbolic reasoning.\nThe merit of neuro-symbolic learning lies in resembling the integration of System 1 and System 2 of human minds. First, it eliminates unnatural and sometimes costly human labeling of the latent variables and conducts learning in an end-to-end fashion. Second, it generates not only a neural network for perception, but also a set of explicit (symbolic) constraints enabling exact and interpretable logical reasoning. Last but not least, the mutually beneficial interaction between the neural and the symbolic parts during both training and inference stages potentially achieves better performance than separated learning approaches.\nHowever, existing approaches do not provide an adequate solution to the problem. They either (1) are not end-to-end, i.e., human intervention is employed to label the latent z so that the task can be divided into a purely neural subtask of image classification and a purely symbolic subtask of constraint solving, or (2) are not interpretable, i.e., can only approximate symbolic reasoning with neural network but without explicit logical constraints generated, which inevitably sacrifices the exactness and interpretability of symbolic reasoning, resulting in an inaccurate black-box predictor but not a genuine neuro-symbolic system."}, {"title": "2 Neuro-symbolic Learning Framework", "content": "In this paper, we focus on end-to-end neuro-symbolic systems comprising two components: (1) neural network $f_\\theta : \\mathcal{X} \\rightarrow \\mathcal{Z}$, which transforms the raw input $x \\in \\mathcal{X}$ into a latent state $z \\in \\mathcal{Z}$; and (2) symbolic reasoning $g_\\Phi : \\mathcal{Z} \\rightarrow \\mathcal{Y}$, which deduces the final output $y \\in \\mathcal{Y}$ from state $z \\in \\mathcal{Z}$. Both components are built simultaneously, taking only the input x and output y as supervision. We assume that $\\mathcal{Z}$ and $\\mathcal{Y}$ are represented by finite sets, and thus we can encode z and y by binary vectors using"}, {"title": "2.1 Efficient and Effective Logical Constraint Learning", "content": "For efficient learning of logical constraints, we adopt cardinality constraint to represent logical constraint. Cardinality constraints can be easily arithmetized, enabling the conventional optimization method and avoiding the computationally expensive model counting or sampling , which significantly boosts the learning efficiency. In addition, the conjunctive normal form and cardinality constraints can be easily converted from each other, ensuring not only the expressiveness of the learned constraints, but also the seamless compatibility with existing reasoning engines.\nFormally, we denote the column concatenation of z and y by $(z; y)$, and define a cardinality constraint $h_\\Phi(z, y) := w^T (z; y) \\in [b_{min}, b_{max}]$, where $\\Phi = (w, b_{min}, b_{max})$, $w \\in \\mathcal{B}^{u+v}$ is a Boolean vector, and $b_{min}, b_{max} \\in \\mathbb{N}^+$ are two positive integers. Moreover, we can directly extend $h_\\Phi$ to the matrix form representing m logical constraints, i.e.,\n$h_\\Phi(z, y) := W(z; y) = (w_1^T (z; y), . . ., w_m^T (z; y)) \\in [b_{min}, b_{max}]$,\nwhere $\\Phi = (W, b_{min}, b_{max})$, $W := (w_1; . . .; w_m) \\in \\mathcal{B}^{m \\times (u+v)}$, and $b_{min}, b_{max} \\in \\mathbb{N}^m$.\nFor effective learning of logical constraints, one must tackle the frequent problem of degeneracy that causes incomplete or trivial constraints. First, for the bounding box $[b_{min}, b_{max}]$, any of its superset is a feasible result of logical constraint learning, but we actually expect the tightest one. To overcome this difficulty, we propose to use the classic mean squared loss, i.e., defining $l_2(h_\\Phi(z,y), 1) = ||W(z; y) - b||^2$, where b can be computed in optimization or pre-defined. Then, our logical constraint learning problem can be formulated as a Boolean least squares problem . The unbiased property of least squares indicates that $b \\approx (b_{min} + b_{max})/2$, and"}, {"title": "2.2 Neural Network Learning in Tandem with Constraint Learning", "content": "A key challenge underlines end-to-end neuro-symbolic learning is symbol grounding, which is to tackle the chicken-and-egg situation between network training and logical constraint learning: training the network requires the supervision of symbol z that comes from solving the learned logical constraints, but the constraint learning needs z as input recognized by the trained network. Specifically, since matrix W is often underdetermined in high-dimensional cases, the constraint $z = \\text{arg} \\text{min}_{z \\in \\mathcal{Z}} l_2(h_\\Phi(z, y), 1) := ||W(z; y) - b||^2$ often has multiple minimizers (i.e., multiple feasible groundings of z), all of which satisfy the logical constraints $h_\\Phi(z,y) = 1$. Moreover, matrix W is also a to-be-trained parameter, meaning that it is highly risky to determine the symbol grounding solely on the logical constraints.\nTo address these issues, instead of (approximately) enumerating all the feasible solutions via model counting or sampling , we directly combine network prediction and logical constraint satisfaction to establish symbol grounding, owing to the flexibility provided by the cardinality constraints. Specifically, for given $\u03b1 \\in [0, +\\infty)$, the constraint in network learning can be rewritten as follows,\nz = \\text{arg} \\text{min}_{z \\in \\mathcal{Z}} ||W(z; y) - b||^2 + \u03b1||z - f_\u03b8(x)||^2.\nThe coefficient \u03b1 can be interpreted as the preference of symbolic grounding for network predictions or logical constraints. For $\u03b1 \\rightarrow 0$, the symbol grounding process can be interpreted as distinguishing the final symbol z from all feasible solutions based on network predictions. For $\u03b1 \\rightarrow +\\infty$, the symbol grounding process can be viewed as a \"correction\" step, where we revise the symbol grounding from network's prediction towards logical constraints. Furthermore, as we will show in Theorem 1 later, both symbol grounding strategies can finally converge to the expected results.\nThe optimization problem of network training in (1) can be written as\nmin E(x,y)~D[||f_\u03b8(x) - z||^2],\ns.t.z = \\text{arg} \\text{min}_{\u017e\u2208Z} ||W(\u017e; y) - b||^2 + \u03b1||\u017e - f_\u03b8(x)||^2.\nwhere we also use the mean squared loss, i.e., $l_1 (f_\u03b8(x), z) = || f_\u03b8(x) - z||^2$, for compatibility."}, {"title": "3 Algorithms and Analysis", "content": "Our general framework is given by (1), instantiated by (2) and (3). Both optimizations contain Boolean constraints of the form $||Qu - q_1||^2 + \u03c4||u - q_2||^2$ where u are Boolean variables. We propose to relax these Boolean constraints by difference of convex (DC) programming . Specifically, a"}, {"title": "3.1 Algorithms", "content": "For a given dataset $\\{(x_i, y_i)\\}_{i=1}^N$, $X = (x_1,...,x_N)$ and $Y = (y_1,...,y_N)$ represent the data matrix and label matrix respectively, and $f_\u03b8^{(k)}(X)$ denotes the network prediction at the k-th iteration.\nLogical constraint learning. Eliminating the constraint in (2) by letting $Z = f_\u03b8^{(k)}(X)$, the empirical version of the logical constraint learning problem at the (k+1)-th iteration is\nmin \\sum_{i=1}^m || (f_\u03b8^{(k)}(X); Y)w_i - b_i||^2 + \u03bb||w_i - w_i^{(0)} ||^2 + t_1 (e - 2w_i^{(k)})^T w_i,\nwhere $w_i^{(k)},..., w_m^{(k)}$ are parameters of logical constraints at the k-th iteration. In this objective function, the first term is the training loss of logical constraint learning, the second term is the trust region penalty to avoid degeneracy, and the last term is the DC penalty of the Boolean constraint.\nTo solve this problem, we adopt the proximal point algorithm (PPA) , as it overcomes two challenges posed by stochastic gradient descent. First, stochastic gradient descent has an implicit inductive bias , causing different $w_i$, $i = 1, . . ., m$, to converge to a singleton. Second, the data matrix $(f_\u03b8^{(k)}(X); Y)$ is a 0-1 matrix and often ill-conditioned, leading to diverse or slow convergence rates of stochastic gradient descent."}, {"title": "3.2 Theoretical Analysis", "content": "Theorem 1. With an increasing (or decreasing) $\u03b1$, the constraint learning and network training performed by Algorithm 1 converge to the stationary point of (2) and (3), respectively. Specifically, it satisfies\n$E[||\u2207_\u03b8 l(\u03b8^*)||^2] = O(\\frac{1}{\\sqrt{K + 1}})$, and $E[||\u2207_\u03a6 l_2(\u03a6^*)||^2] = O(\\frac{1}{\\sqrt{K + 1}})$"}, {"title": "4 Experiments", "content": "We carry out experiments on four tasks, viz., chained XOR, Nonogram, visual Sudoku solving, and self-driving path planning. We use Z3 SMT (MaxSAT) solver for symbolic reasoning. Other implementation details can be found in Appendix E. The experimental results of chained XOR and Nonogram tasks are detailed in Appendix F. The code is available at https://github.com/Lizn-zn/Nesy-Programming."}, {"title": "4.1 Visual Sudoku Solving", "content": "Datasets. We consider two 9 \u00d7 9 visual Sudoku solving datasets, i.e., the SATNet dataset and the RRN dataset , where the latter is more challenging (17 - 34 versus 31 - 42 given digits in each puzzle). Both datasets contain 9K/1K training/test examples, and their images are all sampled from the MNIST dataset. We typically involve two additional transfer tasks, i.e., training the neuro-symbolic system on SATNet dataset (resp. RRN dataset), and then evaluating the system on RRN dataset (resp. SATNet dataset).\nBaselines. We compare our method with four state-of-the-art methods, i.e., RRN, SATNet, SATNet* , and L1R32H4 . RRN is modified to match visual Sudoku as done by Yang et al. [2023]. SATNet* is an improved version of SATNet that addresses the symbol grounding problem by introducing an additional pre-clustering step. As part of our ablation study, we introduce two variants of our method (NTR and NDC) where NTR removes the trust region penalty (i.e., setting $\u03bb = 0$), and NDC removes the DC penalty (i.e., fixing $t_1 = t_2 = 0$) and directly binarizes (W, b) as the finally learned logical constraints.\nResults. We report the accuracy results (i.e., the percentage of correctly recognized boards, correctly solved boards, and both) in Table 1.5 A more detailed version of our experimental results is given in Appendix F. The results show that our method significantly outperforms the existing methods in all cases, and both trust region penalty and DC penalty are critical design choices. The solving accuracy is slightly higher than the perception accuracy, as the MaxSAT solver may still solve the problem correctly even when the perception result is wrong. Notably, our method precisely learns all logical constraints, resulting in a logical reasoning component that (1) achieves full accuracy when the neural perception is correct; (2) ensures robust results on transfer tasks, in comparison to the highly sensitive existing methods."}, {"title": "4.2 Self-driving Path Planning", "content": "Motivation. Self-driving systems are fundamentally neuro-symbolic, where the primary functions are delineated into two components: object detection empowered by neural perception and path planning driven by symbolic reasoning. Neuro-symbolic learning has great potential in self-driving, e.g., for learning from demonstrations and to foster more human-friendly driving patterns .\nDatasets. We simulate the self-driving path planning task based on two datasets, i.e., Kitti and nuScenes . Rather than provide the label of object detection, we only use planning paths as supervision. To compute planning paths, we construct obstacle maps with 10 x 10 grids, and apply the A* algorithm with fixed start points and random end points. Note that Kitti and nuScenes contain 6160/500 and 7063/600 training/test examples, respectively, where nuScenes is more difficult (7.4 versus 4.6 obstacles per image on average).\nBaselines. We include the best competitor L1R32H4 in the previous experiment as comparison. Alongside this, we also build an end-to-end ResNet model (denoted by ResNet) and an end-to-end recurrent transformer model (denoted by RTNet) . These models take the scene image, as well as the start point and the end point, as the input, and directly output the predicted path. Finally, as a reference, we train a ResNet model with direct supervision (denoted by SUP) by using labels of object detection, and the logical reasoning is also done by the A* algorithm.\nResults. We include the F\u2081 score of predicted path grids, the collision rate of the planning path, and the distance error between the shortest path and the planning path (only computed for safe paths) in Table 2. The results show that our method achieves the best performance on both datasets, compared with the alternatives. Particularly, the existing state-of-the-art method L1R32H4 fails on this task,"}, {"title": "5 Related Work", "content": "Neuro-symbolic learning. Neuro-symbolic learning has received great attention recently. For instance, Dai et al. [2019] and Corapi et al. [2010] suggest bridging neural perception and logical reasoning via an abductive approach, where a logic program is abstracted from a given knowledge base. To reduce reliance on knowledge bases, Ciravegna et al. [2020] and Dong et al. [2019] directly represent and learn constraints using neural networks. However, the learned constraints are still uninterpretable. To improve interpretability, Wang et al. [2019] introduce SATNet, a method that relaxes the MaxSAT problem with semidefinite programming and incorporates it as a layer into neural networks. SATNet is further followed up by several works [Topan et al., 2021, Lim et al., 2022, Yang et al., 2023]. However, how to explicitly extract and use the learned constraints is still unclear for these works. In contrast to the existing neuro-symbolic learning methods, our method can synthesize explicit logical constraints supporting exact reasoning by off-the-shelf reasoning engines.\nConstraint learning. Our work is also related to constraint learning, which can be traced back to Valiant's algorithm [Valiant, 1984] and, more generally, inductive logic programming [Muggleton and De Raedt, 1994, Bratko and Muggleton, 1995, Yang et al., 2017, Evans and Grefenstette, 2018]. However, Cropper and Duman\u010di\u0107 [2022] highlight that inductive logic programming is limited when learning from raw data, such as images and speech, as opposed to perfect symbolic data. To this end, our method goes a step further by properly tackling the symbol grounding problem.\nBoolean quadratic programming and its relaxation. Many constraint learning and logical rea- soning tasks, e.g., learning Pseudo-Boolean function [Marichal and Mathonet, 2010], MaxSAT learning [Wang et al., 2019] and solving [Gomes et al., 2006], and SAT solving [Lipp and Boyd, 2016], can be formulated as Boolean quadratic programming (i.e., quadratic programming with binary variables) [Hammer and Rubin, 1970]. However, commonly used techniques, such as branch and bound [Buchheim et al., 2012] and cutting plane [Kelley, 1960], cannot be applied in neuro-symbolic learning tasks. In literature, semidefinite relaxation (SDR) [d'Aspremont and Boyd, 2003, Gomes et al., 2006, Wang and Kolter, 2019] and difference-of-convex (DC) programming [Tao and Hoai An, 1997, Yuille and Rangarajan, 2003, Lipp and Boyd, 2016, Hoai An and Tao, 2018] are two typical methods to relax Boolean constraints. Although SDR is generally more efficient, the tightness and recovering binary results from relaxation are still an open problem [Burer and Ye, 2020, Wang and K\u0131l\u0131n\u00e7-Karzan, 2022], compromising the exactness of logical reasoning. In this work, we choose DC programming and translate DC constraints to a penalty term with gradually increasing weight, so as to ensure that the Boolean constraints can be finally guaranteed."}, {"title": "6 Limitations", "content": "In this section, we discuss the limitations of our framework and outline some potential solutions.\nExpressiveness. The theoretical capability of cardinality constraints to represent any propositional logic formula does not necessarily imply the practical ability to learn any such formula in our frame-"}, {"title": "7 Conclusion", "content": "This paper presents a neuro-symbolic learning approach that conducts neural network training and logical constraint synthesis simultaneously, fueled by symbol grounding. The gap between neural networks and symbol logic is suitably bridged by cardinality constraint-based learning and difference- of-convex programming. Moreover, we introduce the trust region method to effectively prevent the degeneracy of logical constraint learning. Both theoretical analysis and empirical evaluations have confirmed the effectiveness of the proposed approach. Future work could explore constraint learning using large language models to trim the search space of the involved logical variables, and augment reasoning efficiency by further combining logical reasoning with neural perception."}]}