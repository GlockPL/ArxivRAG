{"title": "Re-Thinking Process Mining in the AI-Based Agents Era", "authors": ["Alessandro Berti", "Mayssa Maatallah", "Urszula Jessen", "Michal Sroka", "Sonia Ayachi Ghannouchi"], "abstract": "Large Language Models (LLMs) have emerged as powerful conversational interfaces, and their application in process mining (PM) tasks has shown promising results. However, state-of-the-art LLMs struggle with complex scenarios that demand advanced reasoning capabilities. In the literature, two primary approaches have been proposed for implementing PM using LLMs: providing textual insights based on a textual abstraction of the process mining artifact, and generating code executable on the original artifact. This paper proposes utilizing the AI-Based Agents Workflow (AgWf) paradigm to enhance the effectiveness of PM on LLMs. This approach allows for: i) the decomposition of complex tasks into simpler workflows, and ii) the integration of deterministic tools with the domain knowledge of LLMs. We examine various implementations of AgWf and the types of AI-based tasks involved. Additionally, we discuss the CrewAI implementation framework and present examples related to process mining.", "sections": [{"title": "1 Introduction", "content": "Process Mining (PM) is a branch of data science aiming to infer process-related insights starting from the event data recorded by the information systems supporting the execution of the processes. Several types of techniques have been proposed within process mining, including process discovery (the automated discovery of a process model), conformance checking (comparing the behavior of an event log against the process model), and predictive analytics (next activity/remaining time in a case)."}, {"title": "3 Methodology", "content": ""}, {"title": "3.1 AI-Based Agents Workflows", "content": "In Def. 1, we propose the definition of AI-Based Agents Workflow (AgWf). The definition contains deterministic tools (F) transforming strings to other strings, and AI-based (non-deterministic) tasks (T). We indicate with the symbol a non-deterministic function, providing possibly different outputs for the same input. Each task in T may be associated with a set of tools (via the \"tools\u201d function). The selection of the tool for the purpose is also a non-deterministic (AI-based) function. We indicate with Us the universe of all strings.\nDefinition 1 (AI-Based Agents Workflow (AgWf)).\nAn AI-Based Agents Workflow (AgWf) is a tuple (F,T, tools, selector, prec, t1, tf) for which:\nF\u2286 (U2 \u2192 Us) is a set of tools.\nT\u2286 (U\u2211 \u2192 Us) is a set of (AI-based) tasks.\ntools : T \u2192 P(F) associates a set of tools to a task.\nselector : U2 \u00d7P(F) \u2192 F selects a tool (for the given inquiry) among the available ones."}, {"title": "", "content": "prec: T\u2192P(T) associates a task with a set of preceding tasks.\nt1 ET is the initial task of the workflow.\ntf ET is the final task of the workflow.\nIn the definition, we never explicitly mention the term agent. We assume that the (AI-based) agent is the underlying executor of the (AI-based) tool. In particular, the (AI-based) agent is involved in the execution of two different non-deterministic activities:\nThe selection of the tool, among the available ones for the task, to be used for the purpose (while the selected tool itself is deterministic).\nThe execution of the task itself, which leads to the final response of the task.\nDifferent (AI-based) tasks can be associated with different (AI-based) agents, accounting for the different types of skills of the agents. For example, simpler tasks could be executed with simpler agents (decreasing the costs and the execution times), while more complex tasks require competent agents.\nWe also note that in Def. 1, the tasks/tool selections are non-deterministic, but the definition of the workflow is static. In Section 5, we discuss the next natural step in the definition of AI-based agents: the automatic orchestration of the workflows (the tasks and their order are decided by an orchestrator).\nIn Def. 2, we define the execution of an AI-based workflow. First, a sequence of tasks respecting the provided order is extracted from the workflow. Then, each task is executed, leading to an output that is appended (via the function) to the original inquiry. While the definition in Def. 2 could be modified to account for concurrent executions of the tasks, the currently available implementation framework (for AgWf) works stably within sequential executions.\nDefinition 2 (AgWf Execution - Sequential).\nLet AgWf = (F, T, tools, selector, prec, t1, tf) be an AI-based agents workflow. We define as execution a tuple ExAgWf = (AgWf, ST, S\u2211) such that:\nST = (t1,...,tf), with t1,...,tf \u2208T, is a sequence of tasks respecting prec.\nS\u2211 = (\u03c3\u03bf, \u03c31,...,of) is a sequence of strings, with \u03c3\u03bf being the initial state of the workflow (i.e., the initial inquiry of the user).\nFor each i \u2208 {1, ..., f}:\n\u2022 If tools(ti) = \u00d8, \u03c3\u2081 = 0i\u22121 \u2295ti(0i\u22121).\n\u2022 If tools(ti) \u2260 0, oi = 0i\u22121 \u2295 ti(0i\u22121 \u2295 selector(oi\u22121, tools(ti))(0i\u22121)).\nIn Def 2, we separate between tasks without associated tools and tasks with associated tools. For the first type, the state of the workflow is defined as the concatenation of the previous state and of the result of the execution of the (AI-based) task. For the second type, we execute:\n1. The selection of the tool, among the available ones.\n2. The (deterministic) tool applied on the previous state.\n3. The (AI-based) task is executed on the previous state and on the result of the application of the selected tool.\nWhile the output of the deterministic tool is not persisted in Def. 2, it is actively used in determining the final answer of the (AI-based) task."}, {"title": "3.2 AgWf Running Example", "content": "In Fig. 2, we see an example of AI-based agents workflow, aiming to exploit two different abstractions (directly-follows graph and process variants) to respond to the inquiry of the user. The individual results are eventually merged by an ensemble, extracting the best of the single answers. The strategy, requiring the execution of four different prompts, potentially leads to better results since different abstractions represent different views on a given PM artifact. For example, in [4] it is discussed that the variants abstraction could be better suited for root cause analysis, while for semantic anomaly detection tasks, the knowledge of the directly-follows graph may be sufficient. However, in some instances, the opposite choice might be more effective. For instance, in a process in which the performance problems lay in a single transition between two activities, the DFG abstraction might be more effective in showing the root cause of the performance issue. On the other hand, in a P2P process, if an invoice is paid twice non-consecutively, that would be hidden in the directly-follows graph abstraction but would be visible in the variants abstraction.\nConsidering always Fig. 2, we see clear start/end tasks (T1 and T4). Two different sequences of tasks are allowed by the workflow (since T2 and T3 are interleaved): (T1, T2, T3, T4) and (T1, T3, T2, T4). The execution of each task appends the result to the input string. For instance, an initial inquiry of the user, Tell me the violations in the process contained in the event log at /home-/erik/p2p.xes, can be optimized by T1 appending Could you analyze the behavior in the process, providing a list of anomalous behavior?. Then T2 would append its analysis based on the DFG, for instance, \"Create Purchase Requisi-tion\u201d should never transition to \u201cCreate Purchase Order\u201d without approval. T3, on the other hand, would exploit the behavior evidenced in the variants, appending \"You should never pay twice the same invoice\". Eventually, T4 would provide a composition of the two provided insights, appending \"In conclusion, the main problems are the lack of standardization in the management of purchase requisitions and multiple payments for the same invoice.\"."}, {"title": "3.3 Possible Implementations", "content": "Several possible implementations of AgWf(s) are possible for the same tasks In Fig. 3, Fig. 4, and Fig. 5, we see different implementations of AgWf for the same problem (bias detection). However, arguably, there is a clear rank of effectiveness in the implementations.\nThe least effective implementation is represented in Fig. 3. There is a single task, whose final output should be an estimation of the unfairness level in the considered event log. The task would be resolved by a human analyst as follows [13]:"}, {"title": "3.4 Types of Tasks", "content": "In Fig. 2 and Fig. 5, we show the role of tasks in AgWf workflows. In this section, we aim to discuss different types of tasks and their utility, especially focusing on the PM context.\nPrompt Optimizers: tasks accepting the original inquiry of the user and transforming it to a language tailored to the capabilities of the AI agents. They usually are not associated with any tool, as their role is to optimize the cleanliness and effectiveness of the inquiry.\nEnsembles: tasks accepting a prompt containing a collation of insights (col-lected from different tasks offering a different perspective) and returning a coherent text containing the main results of the analysis. For example, the ensemble could summarize analyses over different dimensions (control-flow, temporal, data, resource) into a unified report on the process.\nRouters: tasks accepting a prompt and deciding which one of the depending nodes should be executed. While explicit routing is not allowed within the context of Def. 1, the following tasks could be instructed to consider the output of the routing node and possibly skip the production of further output. For example, in Fig. 6, we see a typical routing decision, i.e., choosing if the problem should be resolved directly by the LLM as it is a semantical task and/or it does not require extensive access to the attributes of the event log, or generating some code executable against the event log using a PM library such as pm4py.\nEvaluators: tasks evaluating the output of a previous task and assessing the quality, for instance, assigning a score between 1.0 and 10.0. This might help to understand the effectiveness of the task's execution. While the definition of AgWf does not allow for loops, in case of outputs with low quality is it possible to implement a \"wrap back\" mechanism in which the execution is taken back to a previous state and repeated.\nOutput Improvers: trying to enhance the quality of the output of the previous tasks. For instance, the insights could be refined (\u201csecond opinion\") or, in the case of code generation, the quality or security of the code can be improved.\""}, {"title": "4 Implementation Framework", "content": "In this section, we present the CrewAI Python framework https://github.com/crewAIInc/crewAI for the implementation of AgWf(s) on top of Large Language Models. It is based on the following concepts:\nAI-based agents are defined as LLMs plus system prompts. The system prompt tailors the behavior of a given LLM to a given role (role prompting [18]).\nAI-based tasks are defined based on a textual instruction. They are associated with an AI-based agent.\nTools are defined as Python units (classes/functions). A task can be connected to some tools. The selection operates on the documentation string of the different tools, including the input arguments and the type of the output.\nIn the traditional implementation, a sequential order of execution for the tasks is defined. More recently, a concept of concurrent execution (hierarchical processes) has been tried, but further work is needed.\nAn important criteria for the selection of the LLM is its ability as selector for the most suitable tool. Notably, LLMs such as Llama-3.18, Qwen 2.0\u00ba, Mistral Large"}, {"title": "5 Next Steps", "content": "Automatic Definition of AgWf(s): In the previous sections, we show how tasks could be decomposed into an AgWf. However, decomposition is done by humans. Some approaches [14,17] show that the same decomposition task could be performed by an \"orchestrating\" LLM. In particular, the original task is decomposed into a sequence of smaller tasks assigned to specialized agents. One of the main challenges identified in [14] is the comprehension of the original task. In particular, it is argued that the orchestrating LLM should be instructed to request clarifications on the task.\nTasks Keeping the Human-in-the-Loop: AgWf(s) could be used to automate many tasks. However, the execution of some tasks might benefit from clarifications provided by the end user [1]. For instance, the prompt optimizer depicted in Fig. 2 could struggle to optimize a very generic inquiry (such as \"What are the problems in the process?\"), and could benefit from additional clarifications provided by the user.\nEvaluating AgWf(s): In this paper, we argue that AgWf(s) are useful tools to increase the quality of the output on a specific task by decomposing it into smaller tasks executed by specialized agents. The assessment of LLM-based outputs is challenging, with the LLMs-as-a-Judge paradigm [6] being a popular solution. Within AgWf(s), the overall effectiveness (quality of the final output) depends on the effectiveness of the single agents. For instance, errors in the initial routing of the inquiry can result in a significantly lower quality output even if all the other tasks are performed optimally. Therefore, we argue that the quality of the output of the single tasks should be assessed.\nAlso, when multiple agents are involved, the collaboration and psychological traits should be considered [20,16]. Tasks could be implemented with self-awareness or also awareness of the context (overarching goal/workflow context).\""}, {"title": "6 Conclusion", "content": "In this paper, we analyzed the limitations of the currently proposed implementations for PM-on-LLMs, proposing AgWf(s) as a possible solution involving i) the decomposition of the original task in smaller units; ii) the combination between AI-based task execution and \"deterministic\" tools (for instance, using the features offered by process mining libraries). AgWf(s) have a different goal (i.e., maximizing the quality of the output) than previously proposed scientific workflows (i.e., allowing the reproducibility of scientific experiments). We propose different types of AI-based tasks useful for process mining applications, including prompt optimizers, ensembles, routers, evaluations, and output improvers. We use the CrewAl framework to implement some example AgWf(s) (including root cause analysis and bias detection in process mining event logs).\nWe also discuss future directions for research and development, including the automatic definition of the workflows, evaluation frameworks for agents, and increased maturity of the underlying frameworks/tool support. Overall, AgWf(s) offer a powerful tool for PM-on-LLMs, requiring a divide-et-impera mindset."}]}