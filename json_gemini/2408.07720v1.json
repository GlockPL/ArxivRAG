{"title": "Re-Thinking Process Mining in the AI-Based Agents Era", "authors": ["Alessandro Berti", "Mayssa Maatallah", "Urszula Jessen", "Michal Sroka", "Sonia Ayachi Ghannouchi"], "abstract": "Large Language Models (LLMs) have emerged as powerful conversational interfaces, and their application in process mining (PM) tasks has shown promising results. However, state-of-the-art LLMs struggle with complex scenarios that demand advanced reasoning capabilities. In the literature, two primary approaches have been proposed for implementing PM using LLMs: providing textual insights based on a textual abstraction of the process mining artifact, and generating code executable on the original artifact. This paper proposes utilizing the AI-Based Agents Workflow (AgWf) paradigm to enhance the effectiveness of PM on LLMs. This approach allows for: i) the decomposition of complex tasks into simpler workflows, and ii) the integration of deterministic tools with the domain knowledge of LLMs. We examine various implementations of AgWf and the types of AI-based tasks involved. Additionally, we discuss the CrewAI implementation framework and present examples related to process mining.", "sections": [{"title": "1 Introduction", "content": "Process Mining (PM) is a branch of data science aiming to infer process-related insights starting from the event data recorded by the information systems supporting the execution of the processes. Several types of techniques have been proposed within process mining, including process discovery (the automated discovery of a process model), conformance checking (comparing the behavior of an event log against the process model), and predictive analytics (next activity/remaining time in a case)."}, {"title": "2 Related Work", "content": "Process Mining on LLMs: In [5], textual abstractions of PM artifacts are provided to the LLMs in order to respond to inquiries. On the other hand, the translation of the inquiry to SQL statements executable against the original data source is proposed in [7], along with error-correction mechanisms. In [3], some types of PM that could be implemented on LLMs (semantic anomaly detection, root cause analysis, visual recognition, fairness assessments) are discussed. Moreover, different implementation paradigms (direct provision of insights, code generation, and hypotheses generation) are proposed. In [2], a comprehensive benchmark for PM tasks on LLMs is proposed.\nConnection to Traditional Process Mining Workflows: Scientific workflows, for example based on RapidMiner [11], Knime [8], or SLURM [15], have been used in PM to increase reproducibility and standardize large-scale experiments. However, the overarching goal of AgWf(s) is not to ensure reproducibility or standardization but to ensure the feasibility of the overall pipeline by adopting a divide-et-impera approach and using the right tool for every task. Moreover, AgWf(s) are non-deterministic by nature, while for most PM workflows, the same output would be obtained starting from the same inputs (determinism)."}, {"title": "3 Methodology", "content": ""}, {"title": "3.1 AI-Based Agents Workflows", "content": "In Def. 1, we propose the definition of AI-Based Agents Workflow (AgWf). The definition contains deterministic tools (F) transforming strings to other strings, and AI-based (non-deterministic) tasks (T). We indicate with the symbol ~ a non-deterministic function, providing possibly different outputs for the same input. Each task in T may be associated with a set of tools (via the \u201ctools\u201d function). The selection of the tool for the purpose is also a non-deterministic (AI-based) function. We indicate with Us the universe of all strings.\nDefinition 1 (AI-Based Agents Workflow (AgWf)).\nAn AI-Based Agents Workflow (AgWf) is a tuple (F,T, tools, selector, prec, t1, tf) for which:\n$F \\subseteq (U_s^2 \\rightarrow U_s)$ is a set of tools.\n$T \\subseteq (U_s \\leadsto U_s)$ is a set of (AI-based) tasks.\ntools : T \u2192 P(F) associates a set of tools to a task.\nselector : $U_s^2$ \u00d7P(F) \u2192 F selects a tool (for the given inquiry) among the available ones."}, {"title": "3.2 AgWf Running Example", "content": "In Fig. 2, we see an example of AI-based agents workflow, aiming to exploit two different abstractions (directly-follows graph and process variants) to respond to the inquiry of the user. The individual results are eventually merged by an ensemble, extracting the best of the single answers. The strategy, requiring the execution of four different prompts, potentially leads to better results since different abstractions represent different views on a given PM artifact. For example, in [4] it is discussed that the variants abstraction could be better suited for root cause analysis, while for semantic anomaly detection tasks, the knowledge of the directly-follows graph may be sufficient. However, in some instances, the opposite choice might be more effective. For instance, in a process in which the performance problems lay in a single transition between two activities, the DFG abstraction might be more effective in showing the root cause of the performance issue. On the other hand, in a P2P process, if an invoice is paid twice non-consecutively, that would be hidden in the directly-follows graph abstraction but would be visible in the variants abstraction.\nConsidering always Fig. 2, we see clear start/end tasks (T1 and T4). Two different sequences of tasks are allowed by the workflow (since T2 and T3 are interleaved): (T1, T2, T3, T4) and (T1, T3, T2, T4). The execution of each task appends the result to the input string. For instance, an initial inquiry of the user, Tell me the violations in the process contained in the event log at /home-/erik/p2p.xes, can be optimized by T1 appending Could you analyze the behavior in the process, providing a list of anomalous behavior?. Then T2 would append its analysis based on the DFG, for instance, \"Create Purchase Requisi-tion\u201d should never transition to \u201cCreate Purchase Order\u201d without approval. T3, on the other hand, would exploit the behavior evidenced in the variants, appending \"You should never pay twice the same invoice\". Eventually, T4 would provide a composition of the two provided insights, appending \"In conclusion, the main problems are the lack of standardization in the management of purchase requisitions and multiple payments for the same invoice.\"."}, {"title": "3.3 Possible Implementations", "content": "Several possible implementations of AgWf(s) are possible for the same tasks In Fig. 3, Fig. 4, and Fig. 5, we see different implementations of AgWf for the same problem (bias detection). However, arguably, there is a clear rank of effectiveness in the implementations.\nThe least effective implementation is represented in Fig. 3. There is a single task, whose final output should be an estimation of the unfairness level in the considered event log. The task would be resolved by a human analyst as follows [13]:"}, {"title": "3.4 Types of Tasks", "content": "In Fig. 2 and Fig. 5, we show the role of tasks in AgWf workflows. In this section, we aim to discuss different types of tasks and their utility, especially focusing on the PM context.\nPrompt Optimizers: tasks accepting the original inquiry of the user and transforming it to a language tailored to the capabilities of the AI agents. They usually are not associated with any tool, as their role is to optimize the cleanliness and effectiveness of the inquiry.\nEnsembles: tasks accepting a prompt containing a collation of insights (collected from different tasks offering a different perspective) and returning a coherent text containing the main results of the analysis. For example, the ensemble could summarize analyses over different dimensions (control-flow, temporal, data, resource) into a unified report on the process.\nRouters: tasks accepting a prompt and deciding which one of the depending nodes should be executed. While explicit routing is not allowed within the context of Def. 1, the following tasks could be instructed to consider the output of the routing node and possibly skip the production of further output. For example, in Fig. 6, we see a typical routing decision, i.e., choosing if the problem should be resolved directly by the LLM as it is a semantical task and/or it does not require extensive access to the attributes of the event log, or generating some code executable against the event log using a PM library such as pm4py.\nEvaluators: tasks evaluating the output of a previous task and assessing the quality, for instance, assigning a score between 1.0 and 10.0. This might help to understand the effectiveness of the task's execution. While the definition of AgWf does not allow for loops, in case of outputs with low quality is it possible to implement a \"wrap back\" mechanism in which the execution is taken back to a previous state and repeated.\nOutput Improvers: trying to enhance the quality of the output of the previous tasks. For instance, the insights could be refined (\u201csecond opinion\") or, in the case of code generation, the quality or security of the code can be improved.\""}, {"title": "4 Implementation Framework", "content": "In this section, we present the CrewAI Python framework https://github.com/crewAIInc/crewAI for the implementation of AgWf(s) on top of Large Language Models. It is based on the following concepts:\nAI-based agents are defined as LLMs plus system prompts. The system prompt tailors the behavior of a given LLM to a given role (role prompting [18]).\nAI-based tasks are defined based on a textual instruction. They are associated with an AI-based agent.\nTools are defined as Python units (classes/functions). A task can be connected to some tools. The selection operates on the documentation string of the different tools, including the input arguments and the type of the output.\nIn the traditional implementation, a sequential order of execution for the tasks is defined. More recently, a concept of concurrent execution (hierarchical processes) has been tried, but further work is needed.\nAn important criteria for the selection of the LLM is its ability as selector for the most suitable tool. Notably, LLMs such as Llama-3., Qwen 2.0, Mistral Large or GPT-4O/GPT-4O-Mini offer excellent support to implement AgWf. Also, since a workflow contains potentially many different tasks, the speed of the model is important. For instance, Llama 3.1 70B and GPT-4O-Mini could be a preferred choice over their bigger siblings Llama 3.1 405B and GPT-40 due to their satisfactory performance at a lower computational price.\nCrewAI supports also additional concepts in comparison to Def. 1:\nThe entity memory is a dictionary persisting variables produced/accessed during the execution of the workflow. For instance, from an initial log log, we could create two sub-logs (for example, training and test). The training log could be then accessed to generate some hypotheses that are then tested on the test log.\nPython functions (callbacks) could be called at the end of the execution of some tasks (for example, to persist the result, or check the formal correctness).\nIn the following, we will propose two examples of AI-based workflows. We implemented in CrewAI the fairness workflow shown in Fig. 4. A Jupyter notebook is available at the address https://github.com/fit-alessandro-berti/agents-trial/blob/main/02_fairness_assessment.ipynb. The selected LLM for the task is Qwen 2.0 72B. In particular, the first task (identification of the protected group) generates some code (SQL statement) executed against the event log in order to split the behavior between \"protected\" and \"non-protected\" cases. Using the advanced features provided by CrewAI, both event logs are stored in the entity memory for usage in the following task. The following task (comparison between protected and non-protected groups) calls the computation of the DFG on both event logs and returns a textual list of insights. We see that we assign each task to a different agent. Despite both agents are being supported by the same LLM (Qwen 2.0 72B), the system prompt defines a different purpose for each LLM. The tasks are defined, following the CrewAI framework implementation, with a description and an expected output.\nWe also define another AgWf for root cause analysis, including two different mechanisms of evaluation, at the address\nhttps://github.com/fit-alessandro-berti/agents-trial/blob/main/01_root_cause_analysis_insights.ipynb. The workflow is shown in Fig. 7. In particular, the first step T1 performs root cause analysis starting from the DFG abstraction, producing a list of potential root causes. Then, T2 assigns to each insight a confidence score [9] from 1.0 (minimum) to 10.0 (maximum). T3 needs to provide the chain-of-thought [19] for the first of the provided insights, so the detailed reasoning steps. The graded insights and the detailed reasoning steps (for the first insight) are then returned at the end of the workflow. We see that we also define three different agents on the same LLM with different system prompts."}, {"title": "5 Next Steps", "content": "Automatic Definition of AgWf(s): In the previous sections, we show how tasks could be decomposed into an AgWf. However, decomposition is done by humans. Some approaches [14,17] show that the same decomposition task could be performed by an \"orchestrating\" LLM. In particular, the original task is decomposed into a sequence of smaller tasks assigned to specialized agents. One of the main challenges identified in [14] is the comprehension of the original task. In particular, it is argued that the orchestrating LLM should be instructed to request clarifications on the task.\nTasks Keeping the Human-in-the-Loop: AgWf(s) could be used to automate many tasks. However, the execution of some tasks might benefit from clarifications provided by the end user [1]. For instance, the prompt optimizer depicted in Fig. 2 could struggle to optimize a very generic inquiry (such as \"What are the problems in the process?\"), and could benefit from additional clarifications provided by the user.\nEvaluating AgWf(s): In this paper, we argue that AgWf(s) are useful tools to increase the quality of the output on a specific task by decomposing it into smaller tasks executed by specialized agents. The assessment of LLM-based outputs is challenging, with the LLMs-as-a-Judge paradigm [6] being a popular solution. Within AgWf(s), the overall effectiveness (quality of the final output) depends on the effectiveness of the single agents. For instance, errors in the initial routing of the inquiry can result in a significantly lower quality output even if all the other tasks are performed optimally. Therefore, we argue that the quality of the output of the single tasks should be assessed.\nAlso, when multiple agents are involved, the collaboration and psychological traits should be considered [20,16]. Tasks could be implemented with self-awareness or also awareness of the context (overarching goal/workflow context)."}, {"title": "6 Conclusion", "content": "In this paper, we analyzed the limitations of the currently proposed implementations for PM-on-LLMs, proposing AgWf(s) as a possible solution involving i) the decomposition of the original task in smaller units; ii) the combination between AI-based task execution and \"deterministic\" tools (for instance, using the features offered by process mining libraries). AgWf(s) have a different goal (i.e., maximizing the quality of the output) than previously proposed scientific workflows (i.e., allowing the reproducibility of scientific experiments). We propose different types of AI-based tasks useful for process mining applications, including prompt optimizers, ensembles, routers, evaluations, and output improvers. We use the CrewAl framework to implement some example AgWf(s) (including root cause analysis and bias detection in process mining event logs).\nWe also discuss future directions for research and development, including the automatic definition of the workflows, evaluation frameworks for agents, and increased maturity of the underlying frameworks/tool support. Overall, AgWf(s) offer a powerful tool for PM-on-LLMs, requiring a divide-et-impera mindset."}]}