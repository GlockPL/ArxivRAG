{"title": "VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning and Abstract Syntax Tree (AST)-based Waveform Tracing Tool", "authors": ["Chia-Tung Ho", "Haoxing Ren", "Brucek Khailany"], "abstract": "Due to the growing complexity of modern Integrated Cir-cuits (ICs), automating hardware design can prevent a sig-nificant amount of human error from the engineering process and result in less errors. Verilog is a popular hardware de-scription language for designing and modeling digital sys-tems; thus, Verilog generation is one of the emerging ar-eas of research to facilitate the design process. In this work, we propose VerilogCoder, a system of multiple Artificial In-telligence (AI) agents for Verilog code generation, to au-tonomously write Verilog code and fix syntax and functional errors using collaborative Verilog tools (i.e., syntax checker, simulator, and waveform tracer). Firstly, we propose a task planner that utilizes a novel Task and Circuit Relation Graph retrieval method to construct a holistic plan based on module descriptions. To debug and fix functional errors, we develop a novel and efficient abstract syntax tree (AST)-based wave-form tracing tool, which is integrated within the autonomous Verilog completion flow. The proposed methodology suc-cessfully generates 94.2% syntactically and functionally cor-rect Verilog code, surpassing the state-of-the-art methods by 33.9% on the VerilogEval-Human v2 benchmark\u00b9.", "sections": [{"title": "Introduction", "content": "Designing modern integrated circuits requires designers to write code in hardware description languages such as Ver-ilog and VHDL to specify hardware architectures and model the behaviors of digital systems. Due to the growing com-plexity of VLSI design, writing Verilog and VHDL is time-consuming and prone to bugs, necessitating multiple iter-ations for debugging functional correctness. Consequently, reducing design costs and designer effort for completing hardware specifications has emerged as a critical need.\nLarge Language Models (LLMs) have shown remarkable capacity to comprehend and generate natural language at a massive scale, leading to many potential applications and benefits across various domains. In the field of coding, LLM can assist developers by suggesting code snippets, offering solutions to fix bugs, and even generating the code with ex-planation (Mastropaolo et al. 2023; Nijkamp et al. 2023). Several works have focused on refining LLMs with selected datasets for Verilog generation (Liu et al. 2023a; Thakur et al. 2024). Pei et al. (Pei et al. 2024) proposed leveraging instruct-tuned LLM and a generative discriminators to opti-mize Verilog implementation with the considerations of PPA (Power, Performance, Area). However, these works lack of a mechanism to fix syntactic or functional errors, thus, they still struggle to generate functionally correct Verilog code. Recently, Tsai et al. (Tsai, Liu, and Ren 2023) presented an autonomous agent framework incorporating feedback from simulators and Retrieval Augmented Generation to fix syn-tax errors, but it failed to improve the functional success rate. In this work, we propose a framework leveraging multi-ple Artificial Intelligence (AI) agents for Verilog code gen-eration, which autonomously writes the Verilog code and fixes syntax and functional errors using collaborative Ver-ilog toolkits and the ReAct (Yao et al. 2022) technique. In the framework, we develop a novel task planner to generate high-quality plans, and integrate a crafted Abstract Syntax Tree (AST)-based waveform tracing tool for improving the functional success rate. Our contributions are as follows.\n\u2022 We are the first to explore the use of multiple AI agents for autonomous Verilog code completion, including syn-tax correction, and functional correction.\n\u2022 We have developed a novel Task and Circuit Relation Graph (TCRG) based task planner to create a high-quality plan with step-by-step sub-tasks and related cir-cuit information (i.e., signal, signal transition, and single examples). These sub-tasks are then executed by desig-nated agents autonomously and sequentially.\n\u2022 We propose a novel Abstract Syntax Tree (AST)-based waveform tracing tool to assist the LLM agent in fixing functional correctness.\n\u2022 We conduct extensive and holistic ablation studies of each key component (i.e., task planner, waveform de-bugging tools) on the VerilogEval-Human v2 bench-mark (Pinckney et al. 2024). We demonstrate the pro-posed VerilogCoder achieve 94.2% pass rate, including syntax and functional correctness, and outperform the one of the state-of-the-art methods by 33.9%.\nThe remaining sections are organized as follows. We first review prior work on AI agents and provide a brief intro-duction to multi-AI agent framework. Then, we introduce and describe our novel VerilogCoder in details. Lastly, we present main experimental results and conclude the paper."}, {"title": "Background", "content": "Autonomous agents have long been a research focus in aca-demic and industrial communities across various fields. Re-cently, LLMs have shown great potential of human-level in-telligence through the acquisition of vast amounts of knowl-edge, documents and textbooks, leading to a surge in re-search on LLM-based autonomous agents. Here, we firstly review prior Al agent works and introduce the multi-AI agent frameworks below."}, {"title": "AI Agent", "content": "Several works study the architecture of LLM-based au-tonomous agents to effectively perform diverse tasks (Wang et al. 2024; Weng 2023). From these studies, an LLM-powered autonomous agent system is composed of several key components: (a) Planning, (b) Memory, (c) Action, etc. The planning module enables the agent to break down large tasks into smaller, manageable sub plans, enabling efficient handling of complex tasks. In the memory module, short-term memory consists of chat history and in-context learn-ing techniques to guide LLM actions. Long-term memory consolidates important information over time and provides the agent with the capability to retain and recall it over ex-tended periods. The action module translates the agent's de-cisions into outcomes for solving tasks. The actions of an autonomous LLM-based agent can be categorized into two classes: (1) External tools for additional information and the expansion of the agent's capabilities, and (2) Internal knowl-edge of the LLMs, such as summary, conversation, etc. Recently, AI agents empowered by LLMs (i.e., Open-Devin (OpenDevin Team 2024), SWE-agent (Yang et al. 2024), AgentCoder (Huang et al. 2023), etc) have shown impressive performance in software engineering for solving real world challenging benchmarks (i.e., SWE-Bench, Hu-manEval) through planning, memory management, actions involving external environment tools."}, {"title": "Multi-AI Agents", "content": "In addition to single AI agents, many researchers are start-ing to explore the capabilities of multiple AI agents for solv-ing complex tasks. Autogen (Wu et al. 2023) has been pro-posed to enable multiple agents to operate in various modes (i.e., hierarchical chat, multi-agent conversation, etc.) that employ combinations of LLMs, human inputs, and tools. crewAI (crewAI Inc. 2024) facilitates process-oriented solv-ing with a crew of customized multi-AI agents operating as a cohesive unit. Currently, the applications of these multi-AI agent frameworks are mostly for general tasks (i.e., QA, summarization, coding copilot, etc.)."}, {"title": "Motivation and Preliminary Study", "content": "Given a hardware module description, hardware designers usually write Verilog using the following steps: (1) decom-pose the task into manageable sub-tasks, (2) implement Ver-ilog code for each sub-task, and (3) iterate between Verilog simulations, signal waveform debugging, and code updates until all output signals match expected behavior. It is very challenging to autonomously complete a functionally cor-rect Verilog module using LLM agents since it requires do-main knowledge to break down the task into meaningful sub-tasks and comprehend the hardware descriptions and wave-form during the functional debug process. Consequently, we first discuss the issues of using traditional LLM planning on writing Verilog code of a Finite State Machine (FSM) mod-ule. Then, we study the functional debug process of a Ver-ilog module and propose a debugging tool that enables LLM agents to autonomously correct the functional errors."}, {"title": "Planning", "content": "Planning is one of the core modules for an agent (Wang et al. 2024; Weng 2023). Traditional planning would leverage a LLM to analyze the task and decompose the complex task into manageable sub-tasks. For Verilog coding, the tradi-tional LLM-generated plans usually lack of the details of rel-evant signals, and signal transitions for each sub-task, thus, leading to incorrect functionality implementation of Verilog modules. Figure 1(A) shows an illustration of using the tra-ditional LLM planning approach on a FSM module imple-mentation. The implementation of traditional LLM planning lost part of the state transitions for S_next, and S1_next sig-nals, thus, leading to an incorrect FSM module. Therefore, it is important to guide the agent to implement each sub-task step by step with essential signals, and state transition infor-mation. As shown in Figure 1(A), once the state transition information and signal definitions are included with the sub-task plan, LLM can generate the correct code. Signals and state transition information can be extracted from the prob-lem descriptions. In this work, we structure sub-task, signal, and state transition information in a graph format and call it the TCRG. Consequently, we study the benefits of lever-aging the TCRG to assist the planning to generate sub-tasks that include not only high-level task goals but also the sig-nal, and signal transition information to complete functional correct Verilog module."}, {"title": "Functional Debug with Waveform", "content": "Figure 1(B) shows a typical functional debug process for a human Verilog designer. Given the mismatched signals, a human Verilog designer traces the signals and their wave-form iteratively until they know how to fix the functional-ity. This backtracing procedure is the same as tracing the RVALUE of the target signals in the AST. Inspired by the human Verilog designer debug process, we propose to in-corporate the hardware signal structure, and waveform, to assist LLM agents in fixing functional errors of the gener-ated Verilog module. This process can be implemented with a tool based on AST and waveform tracing. Several prior works (Alon et al. 2019; Bairi et al. 2024; Bui et al. 2023) de-veloped AST-based methods/tools (i.e., encoded AST paths,"}, {"title": "VerilogCoder", "content": "We introduce the details of VerilogCoder, which consist of a task planning and Verilog code implementation. The multi-AI agents of VerilogCoder operate with developed TCRG re-trieval and Verilog tools through the ReAct (Yao et al. 2022) technique in a cohesive and orchestrated manner."}, {"title": "Flow Overview", "content": "We outline the overall flow of VerilogCoder in Figure 2(a). Given the natural language problem description of a mod-ule (Pinckney et al. 2024), the novel Task and Circuit Re-lation Graph (TCRG) based task planner first generates the task plans. Then, a task dependency graph is built according to the task plans and its sub-tasks are assigned to Multi-LLM agents that write Verilog code and correct the functionality using a collaborative Verilog toolkit (i.e., syntax checker, simulator, and the proposed novel AST-based waveform tracing tool). In the flow, each agent may consist of multiple LLMs with different roles, which are listed in Figure 2(b), to complete each step correctly and consistently. Some of the agents are equipped with provided TCRG and Verilog tools to reason and act through Thought, Action, and Ob-servation tracing of the ReAct prompting mechanism (Yao et al. 2022). For agent memory, we keep the original query and the last four chats in the chat history. The correspond-ing testbench of the module is used only for running Verilog simulator to check the functional correctness."}, {"title": "Task Planning", "content": "We introduce a novel and effective TCRG based Task Plan-ner that constructs a high-quality plan encompassing not only the high-level objectives but also the relevant descrip-tions or definitions of signals, signal transitions, and ex-amples for each sub-task. Recently, many works have uti-lized large language models (LLMs) to analyze texts and extract entities and relations for knowledge graph construc-tion (Edge et al. 2024; Kommineni, K\u00f6nig-Ries, and Samuel 2024; Zhang and Soh 2024). Inspired by these works, we leverage LLM agents to construct the TCRG with designer guidelines. In Figure 2(a), the task plan generation flow comprises four components: (1) High-level planner agent, (2) Circuit signal, transition, example extraction agent, (3) TCRG construction, and (4) Task-driven circuit relation graph retrieval agent. Figure 2(c) shows the configuration and tools of each AI agent in TCRG based Task Planner."}, {"title": "High-level planner agent", "content": "The high-level planner agent consists of a planner and a plan verification assistant, as shown in Figure 2(c). Given the module description or spec-ification, the planner first decomposes the task into sub-tasks, which mostly consist of high-level task descriptions. Then, the plan verification assistant checks the consistency between the sub-tasks and the module description, provid-ing suggestions to modify the plan if any inconsistencies are found. This iterative process continues until the planner's plan is verified to be consistent with the module description."}, {"title": "Circuit signal, transition, example extraction agent", "content": "A LLM acts as a Verilog engineer, extracting circuit signals, transitions, and examples from the given module description or specification into JSON format, as shown in Figure 2(c). The extracted information is represented as nodes in the sub-sequent TCRG construction. The examples of extracted sig-nals, transitions, and signal examples are \"w: input signal examined by FSM in state B\", \"State A to State B: FSM moves to state B when s = 1.\", and \"For example, when the input w = 1, 1, 0 in these three clock cycles, output z is set to 1 for the following cycle.\u201d, respectively."}, {"title": "TCRG construction", "content": "We create nodes from the previously generated high-level task descriptions, extracted circuit sig-nals, transitions, and examples. We then sequentially cre-ate the relations (edges) between nodes: task nodes to signal nodes, signal nodes to transition nodes, and signal nodes to example nodes, using \"IMPLEMENTS\", \"SIGNALTRAN-SITION\", and \"EXAMPLES\u201d relationships, respectively."}, {"title": "Task-driven circuit relation graph retrieval agent", "content": "Here, an LLM (acting as a Verilog Engineer) autonomously re-trieves relevant signal and circuit descriptions and compiles this information for each sub-task using the collaborative TCRG retrieval tool through Thought-Action-Observation ReAct tracing (Yao et al. 2022), as shown in Figure 2(c). We firstly introduce the tool and then describe the workflow of the retrieval agent. TCRG retrieval tool assists the task-driven circuit relation graph retrieval agent in obtaining relevant descriptions or definitions of signals, signal transitions, and examples re-lated to a specified sub-task in the constructed TCRG. The inputs are the sub-task description in string format and an integer value, k, which indicates the number of hops for re-trieval from the sub-task node in the graph. Here, k is deter-mined by the AI agent automatically through the Thought-Action-Observation reasoning trace. The output consists of the retrieved k-hop signals, signal transitions, and examples corresponding to the sub-task node. The retrieval agent reasons and interacts with the TCRG retrieval tool to incorporate additional information as illus-trated in Figure 3. Ultimately, the retrieval agent compiles the retrieved circuit and signal information from the graph and removes irrelevant information from the final answer."}, {"title": "Verilog Code Implementation", "content": "We describe the Verilog code implementation flow of writ-ing Verilog code and ensuring the functionality of the written Verilog module in detail. Given a task plan, the task depen-dency graph is created. A child task can not be executed until all its parent tasks have been completed without errors. The sub-tasks are divided into two types: (1) Type1: Writing Ver-ilog code for partial function/logic, and (2) Type2: Verify-ing and debugging the generated Verilog module. The code agent and debug agent are assigned to complete the Typel sub-task and Type 2 sub-task, respectively. We first discuss the Verilog tools including a third-party simulator (i.e., iver-ilog (Williams and Baxter 2002)) and customized AST-based waveform tracing tool. Then, we introduce a code agent and a debug agent."}, {"title": "Verilog Tools", "content": "The Verilog tools to assist agents for code implementation are listed below.\nSyntax checker tool: We use iverilog to compile the gener-ated Verilog code module and provide compiled messages as feedback for syntax checking.\nVerilog simulator tool: We use iverilog to compile the gener-ated Verilog code module and launch the Verilog simulation. If the generated Verilog code module contains syntax errors, the tool reports the lines where these errors occur. On the other hand, the tool also reports the simulation results, in-cluding the number of mismatches in output signals and the first mismatched time point. Additionally, the tool generates a VCD file format for waveform tracing.\nAST-based waveform tracing tool (AST-WT): We developed a novel AST-based waveform tracing tool to assist agents in back-tracing the waveform of signals from mismatched output signals. Here, we extract the AST of generated Ver-ilog module using Pyverilog library (Takamaeda-Yamazaki 2015). By inputting the mismatched output signals from the Verilog simulation tool and the desired back-tracing level, the tool starts from the mismatched signal and iteratively extracts the RVALUE signals until it reaches the specified back-tracing level in the AST, as the illustration shown in Figure 1(B). The back-tracing level parameter is determined dynamically by the AI agent through the Thought-Action-Observation reasoning trace. The output includes the Ver-ilog code reference, a tabular waveform of the mismatched signal, and the extracted RVALUE signals."}, {"title": "Code Agent", "content": "For the code agent to write syntax-correct and consistent Verilog code, there are two LLMs: one acting as a Verilog Engineer and the other as a Verilog Verification Assistant, as shown in Figure 2(d). The Verilog Engineer writes the Verilog code according to the sub-task, while the Verilog Verification Assistant ensures that the written Ver-ilog code is consistent with the sub-task requirements and free of syntax errors using the syntax checker tool. If there are syntax errors or inconsistencies between the written Ver-ilog code and the sub-task description, the Verilog Verifica-tion Assistant will provide suggestions to the Verilog Engi-neer for fixing the issues. This process continues iteratively between the Verilog Engineer and the Verilog Verification Assistant until the generated Verilog code is free of syntax errors and consistent with the sub-task description."}, {"title": "Debug Agent", "content": "The Debug Agent verifies the functional-ity and modifies the Verilog code to pass the functionality check from a provided testbench using collaborative Verilog verification tools as shown in Figure 2(d). Given the gener-ated Verilog module from the previous task, the LLM-based Verilog Engineer performs reasoning and interacts with Ver-ilog simulators, as well as the novel AST-based waveform tracing tool through a Thought-Action-Observation process until the generated Verilog code passes the functionality check. Figure 4 shows an example of the Thought-Action-Observation process of the Verilog engineer fixing function-ality issues through reasoning and interaction with Verilog simulator tool and AST-WT."}, {"title": "Experimental Results", "content": "Our work is implemented in Python and is built on top of the Autogen (Wu et al. 2023) multi-AI agent framework. We employ VerilogEval-Human v2 (Pinckney et al. 2024), which extends the 156 problems of VerilogEval-Human from (Liu et al. 2023a) to specification-to-RTL tasks, as our evaluation benchmark\u00b2. To check the functional correct-ness, the generated Verilog code is tested with the provided golden testbench. We measure Verilog functional correct-ness by running the VerilogCoder once for each problem in the benchmark. Firstly, we demonstrate the Verilog func-tional correctness of prior works and the proposed Verilog-Coder in the Main Results. Next, we conduct an ablation study on the impact of various types of planners and on the effect of using the proposed AST-WT."}, {"title": "Main Results", "content": "We demonstrate the pass-rates of the proposed method and prior works on the VerilogEval-Human v2 bench-mark. We use OpenAI's GPT-4 Turbo (OpenAI 2024) and Llama3 (Meta 2024b) as the LLM models for the proposed VerilogCoder (Llama3) and VerilogCoder (GPT-4 Turbo), respectively, in the main experiment. The temperature and top_p parameters of the LLM are set to 0.1 and 1.0, re-spectively. As we are the first to explore using an agent-based methodology to generate functionally correct Verilog code, we compare the proposed VerilogCoder with recent LLMs using prompt engineering approaches. Table 1 shows the pass rates for RTL-Coder (Liu et al. 2023b), DeepSeek Coder (Guo et al. 2024), CodeGemma (CodeGemma Team, Google 2024), CodeLlama (Meta 2024a), Llama3 (Meta 2024b), Mistral Large (AI 2024), GPT-4 (OpenAI 2023), GPT-4 Turbo (OpenAI 2024), and the proposed Verilog-Coder. For a fair comparison, we select the highest pass rate among 0-shot, 1-shot, and a sample size ranging from 1 to 20 of Specification-to-RTL tasks from (Pinckney et al. 2024). For the VerilogEval-Human v2 benchmark, the proposed VerilogCoder (Llama3) successfully improves the Verilog coding ability of the open-source model and achieves 25.6% and 7.3% higher pass rates than Llama3 and GPT-4 Turbo with few-shot and in-context learning techniques (Pinckney et al. 2024), respectively. Moreover, the proposed Verilog-Coder (GPT-4 Turbo) not only achieves a 94.2% pass rate but also outperforms the state-of-the-art recent LLMs GPT-4 and GPT-4 Turbo by 43.6% and 33.9%, respectively. Here, the average number of group chat rounds for the high-level planner agent and the TCRG retrieval agent is 1.58 and 1.09, respectively. The code agent makes an average of 2.37 Ver-ilog simulator tool calls and 1.37 AST-WT calls."}, {"title": "Ablation Study", "content": "We conducted an ablation study to evaluate the impact of various types of planners, both with and without the pro-posed AST-based waveform tracing tool. We list two types of planners: (a) Planner1: A multi-LLM agent consisting of a planner and verilog engineer, and (b) Planner2: The pro-posed TCRG based task planner for task-oriented solving. In Plannerl, given a module description or specification, the planner first decomposes the task into sub-tasks, and the Ver-ilog engineer generates functionally correct Verilog code, in-cluding interactions with the provided Verilog verification tools. If syntax or functionality errors occur, the planner de-bugs and suggests alternative fixes for the Verilog engineer to correct the code. This iterative process between the plan-ner and the Verilog engineer continues until the syntax and functionality are correct or the number of consecutive auto-replies in the group chat exceeds the maximum limit of 100."}, {"title": "Conclusion and Future Work", "content": "Our proposed VerilogCoder has demonstrated the capabil-ity to autonomously write Verilog code and fix syntax and functional errors using the Verilog simulator and the pro-posed AST-WT. The ablation study reveals that the proposed novel TCRG based task planner and task-oriented solving approach shows a 7.7% improvement in pass-rate, partic-ularly for the Comb (Kmap) and FSM (Transition Table) problem categories. Additionally, the proposed AST-WT pro-vides a 11.5% improvement in pass-rate, mainly for the Application (Description), Comb+Seq+FSM (Description), and Comb+Seq+FSM (Waveform) problem categories. In summary, with the proposed TCRG based task planner and AST-WT, the proposed Verilogcoder achieves a 33.9% higher pass rate compared to the state-of-the-art method, i.e. with-out an agent-based approach.\nWe also believe that important directions for future Ver-ilog agent-based research include: (1) training LLMs with high-quality Verilog code to improve accuracy of various agents processing or generating Verilog code within the overall framework, (2) improving the generated Verilog code by considering PPA (Power, Performance, Area) metrics through efficient retrieval-augmented generation or effective domain-specific fine-tuning, and (3) incorporating more ef-ficient self-learning techniques and memory systems to en-able the agent to accumulate experiences and continuously improve the quality of the generated Verilog code in terms of PPA metrics in the design flow."}, {"title": "Prompts of Task Planning", "content": "We present the prompts of the agents for task planning as follows: (1) high-level planner agent, (2) circuit signal, transition, and example extraction agent, and (3) task-driven circuit relation graph retrieval agent. Figure 1 shows the prompt used to decompose the task into manageable sub-tasks in JSON format. For creating the Task and Circuit Relation Graph, the circuit signal, transition, and example extraction agent extracts the circuit-related signals using the prompt in Figure 2. Lastly, after constructing the Task and Circuit Relation Graph, the task-driven circuit relation graph retrieval agent retrieves detailed signal descriptions for each sub-task. Figure 3 shows the prompt for the task-driven circuit relation graph retrieval agent to retrieve information for each sub-task."}, {"title": "Prompts of Verilog code implementation", "content": "We present the prompts for the code agent and the debug agent for Verilog code implementation task. The code agent's prompt is illustrated in Figure 4. The code agent completes the current sub-task by considering the examples, module description, and partial Verilog code from previous tasks. Figure 5 shows the prompt template for the debug agent. This prompt includes the module description and the completed Verilog code from the code agent. The agent must run the simulator and debug until the module functions correctly."}, {"title": "Inconsistent Specification and Reference Design Module in the VerilogEval-Human v2 Benchmark", "content": "We observed approximately 7% inconsistency between specifications and reference design modules in the VerilogEval-Human v2 benchmark, available at https://github.com/NVlabs/verilog-eval. Below, we list common inconsistencies between specifica-tions and reference design modules across a few representative cases.\nModule port definition or wrong combination logic description Figure 6 illustrates representative cases of this type of inconsistency. In the case of Prob134_2014_q3c, the description omits the input clk, which is present in the refer-ence design module. For Prob045_edgedetect2 description, the output port anyedge is defined with the wrong direction. In Prob074_ece241_2014_q4, the output z is defined as the result of a three-input XNOR gate, but the reference design module implements a NOR gate for the output z."}, {"title": "State condition of finite state machine", "content": "In some cases, the descriptions define a one-hot encoded Moore state machine but fail to provide information indicating that the input state port could be a combination of multiple one-hot encoded states. The testbench, however, expects the Verilog module to generate valid output signals, which creates confusion when large language models attempt to write a functionally correct Verilog module, especially when debugging a waveform with the input state port containing multiple one-hot encoded states. For instance, Figure 7 highlights the inconsistency between the description and the reference design module concerning the input state (i.e., y[5:0]) port and the expected behavior of the output ports in Prob099_m2014_q6c."}, {"title": "Examples of Fixing Functionality of Verilog Module", "content": "Here, we demonstrate an example of fixing the functionality of a Finite State Machine module for receiving serial input data. The debugging trace of the Debug Agent, which leverages the developed AST-based waveform tracing tool to fix functional errors, is shown below."}]}