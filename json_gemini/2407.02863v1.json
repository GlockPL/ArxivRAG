{"title": "Fast maneuver recovery from aerial observation: trajectory clustering and outliers rejection", "authors": ["Nelson de Moura", "Augustin Gervreau-Mercier", "Fernando Garrido", "Fawzi Nashashibi"], "abstract": "Abstract-The implementation of road user models that realistically reproduce a credible behavior in a multi-agent simulation is still an open problem. A data-driven approach is proposed here to infer behaviors that may exist in real situation to obtain different types of trajectories from a large set of observations. The data, and its classification, could then be used to train models capable to extrapolate such behavior. Cars and two different types of Vulnerable Road Users (VRU) will be considered by the trajectory clustering methods proposed: pedestrians and cyclists. The results reported here evaluate methods to extract well-defined trajectory classes from raw data without the use of map information while also separating \"eccentric\" or incomplete trajectories from the ones that are complete and representative in any scenario. Two environments will serve as test for the methods develop, three different intersections and one roundabout. The resulting clusters of trajectories can then be used for prediction or learning tasks or discarded if it is composed by outliers.", "sections": [{"title": "I. INTRODUCTION", "content": "Simulation is a indispensable tool to prove the efficacy and viability of any framework or system capable to drive an Automated Vehicle (AV) before integration with a prototype. In most cases these simulations reproduce the behaviors of other road users based on real recordings, which in this case the behavior of all road users is fixed ahead of time, or it relies on hybrid approaches, mixing real information with some a priori hypothesis, modeling and/or knowledge about the agents being represented. The main goal of this work is to produce classifications of trajectories to feed these hybrid methods with reliable and diverse set of trajectories, for different situations and different road users while being fast to execute and reliable enough to sift through outliers at input.\nTrajectory clustering has been a long research topic in the AV area. Many articles deal specially with the analysis of vehicle trajectory as a way to retrieve the possible trajectories in an environment, to study the traffic flow intersections [1], to discover possible longitudinal behaviors of vehicles [2], to execute some learning task [3] or even to examine the scenarios that might happen during driving [4]. Thus, the goal of this paper is to propose a fast and robust way to recover sets of trajectories for vehicles and vulnerable road users (VRU), delivering sets of trajectory samples as input to all the aforementioned tasks in a simple manner.\nApproaches based on clustering with dynamic time warp-ing (DTW) are the norm in the literature. In [4] three different threshold comparisons were made using the DTW distance metric to establish a similarity relationship between scenarios involving multiple road users. K-means and fuzzy c-means were used for [1], [5] with longest common sub-sequence (LCSS) to cluster trajectories in intersections so to derive insights about the traffic flow in multiple lane cross-intersections. Changing from the urban to aerial traffic, [6] proposed a method to combine k-means with outlier removal based on information theory by the minimization of the holoentropy and achieving good results clustering flight trajectories. With a different motivation, [2] implemented a fast k-means clustering method only for vehicles and bypassing the outliers problem. And on a totally different scale [3] applied the same idea of trajectory clustering but on a city scale, learning an embedding to simplify the trajectory representation and then clustering the projected data to find vehicles with similar behavior.\nThe contribution of this paper is two-fold: First, to propose a fast clustering method for maneuver retrieval from real observations that do not need any map information and that is compatible with vehicles and VRUs. Second, to adapt this model to deal with trajectories that can be considered as outliers, separating these \"eccentric\"\u00b9 and/or erroneous in-stances without disturbing the clustering process. A preview of the results obtained can be seen in Figure 1. Given the"}, {"title": "II. SEPARATING TRAJECTORIES OF INTEREST", "content": "Differently from the vehicle trajectories studied in [2], VRU trajectories are less constraint by its environment and are also more prone to acquisition error as well (shadows, changes in direction, multiple users close by). Also, when a scenario for observation is defined some of the less intuitive trajectories become superfluous, considering the interest of keeping only those which represent behaviors that can be transposed in other scenarios. Take, for example, the tra-jectories displayed in Figure 2 (white cross represents the beginning of the trajectory and black cross the end): these three different sets may represent a real-life situation, like getting out of a store and entering in a car but they are not of interest since they are scenario-specific. These types of trajectories will be qualified as eccentric from now on.\nThe main focus is to sift through entire datasets and isolate the eccentric trajectories (like the ones in Figure 2a) and erroneous ones (like vehicles starting their trajectory in the middle of an intersection) in specific clusters and trajectories of interest Figure 2b in their own clusters. The final result can then be visually inspected to discard some and retain others. Both figures were produced using the data available in the InD Dataset [7].\nGiven the difficulties that methods of the similar inspi-ration of k-means have with outliers, other clustering algo-rithms were considered to deal with pedestrian and cyclist trajectories. All of them using a pre-calculated dissimilarity matrix (Equation (1)) where each element is the result of the Dynamic Time Warping (DTW, subsection II-A) distance measure of two trajectories."}, {"title": "A. Dynamic time warp (DTW)", "content": "DTW was first introduced in the speech processing domain as a way to compare two time series that have different phases. Even though the trajectories studied here were sam-pled at the same frequency, they may have different lengths and although corresponding to the same maneuver in an intersection. Consider two discrete time series, represented by (2) and (3), with different sizes n and m, where K = {k\u2080, k\u2081, ..., k\u2099, ..., k\u2098, ...} represents the sampled periods:\n\\begin{equation}\nR[K] = r[k_0], r[k_1],...,r[k_n]\n\\end{equation}\n\\begin{equation}\nS[K] = s[k_0], s[k_1],..., s[k_m]\n\\end{equation}\nThe goal of the DTW is to calculate the optimal sequence of pairs of point indexes, one from each time series. This is done by minimizing the euclidean distance between the points indicated by the index pair, from (r[k\u2080], s[k\u2080]) to (r[k\u2099], s[k\u2098]), using a certain set of increments to walk from the former to the latter. In the standard implementation (equation 5) three steps are tested: +1 on the index 1, +1 on the index 2 or +1 in both. Equation (4) defines the DTW from R and S as the calculated sum of distances, which are determined by the recursion in Equation (5), for 0 \u2264 i \u2264 k\u2099 and 0 \u2264 j \u2264 k\u2098.\n\\begin{equation}\nDTW(R, S) = \\gamma(k_n, k_m)\n\\end{equation}\n\\begin{equation}\n\\gamma(i, j) = d(r[k_i], s[k_j])+ \\min [\\gamma(i \u2013 1, j), \\gamma(i, j \u2212 1), \\gamma(\u0456 \u2212 1, j \u2212 1)]\n\\end{equation}\nThere are multiple DTW variants, some changing the walk used in the recursion (5) (constraint DTW [11]) or adopting restriction on the elements to be considered by Equation (5) (Sakoe-Chiba band [12]; Itakura parallelogram [13]). Usually, when the Euclidean metric is used, the centroid of a set of series can be calculated simply by summing all the elements and dividing by the number of series in the set. One can do the same with series of different lengths using the Dynamic Barycenter Averaging (DBA) [14], however the result of this algorithm usually is a non-differentiable array always with the same size of the biggest array in the set. When a time-series is necessary to represent the ensemble of a cluster, the medoid will be chosen, according to Equation (6), where X is the set being considered and d in our case is the DTW distance.\n\\begin{equation}\nX_{med} = arg \\min_{x \\in X} \\sum_{i=0}^{N} d_{DTW}(x, x_i)\n\\end{equation}"}, {"title": "B. Clustering methods", "content": "Three main methods were used to cluster the trajectories using the DTW distance: hierarchical clustering, partition around medoids (or k-medoids) and dissimilarity matrix clustering.\n1) Hierarchical clustering: The hierarchical clustering used was based on a agglomerative processes, i.e., it starts with each sample being a cluster and at each step it merges the two most similar clusters, to then continue this process until the desired number of clusters is achieved [15]. The metric used to measure the similarity of two clusters, thus to decide with clusters should be merged at a given iteration, was the average linkage, Equation (7):\n\\begin{equation}\nd_{c_i, c_j} = \\frac{1}{N \\cdot M} \\sum_{x_i \\in C_i} \\sum_{x_j \\in C_j} d(x_i, x_j)\n\\end{equation}\nWhere C\u1d62 and C\u2c7c are two clusters being evaluated and N and M are the number of elements inside each respective cluster. The distance measure used is the DTW (from (1)).\n2) Partition around medoids (or k-medoids): It uses the same sequence of calculation - allocation of elements in clus-ter then center recalculation - from the k-means algorithm but using the medoid element as the cluster center (equation 6), not a synthetic average of elements [16]. Such adaptation is common in cases where it is difficult to calculate the average of elements being clustered, as for example when these do not have the same length.\n3) Dissimilarity matrix clustering: The algorithm was proposed to accelerate the clustering of vehicle's trajecto-ries in [2], in comparison with the k-means algorithm. To simplify the k-means calculation, it is applied at each row of the dissimilarity matrix for the entire dataset to look for the smallest cluster center of all rows (which will be the one that has the smallest sum of distances to the element represented by the row). Then, all the elements assigned to this minimal cluster are removed from the matrix and the process is executed again, until the desired number of clusters is achieved. If there are any left, then they are assigned to the cluster in which it has the smallest distance to its medoid."}, {"title": "III. METHODS EVALUATED", "content": "Independently from the clustering method used from the proposed in the previous section, some errors in classification might still appear, even if a higher number of clusters is used. To cluster using the DTW distance considers only the shape of the trajectory, which might mix trajectories that have small but important differences at its origin or terminus but that share an important part of its path. Hence, to correct this errors the initial and final points shall be used in a separate clustering procedure split the elements based on these points. Then, it will be necessary to check if any of the just-obtained sub-clusters should be fused back together, if they really are on the same maneuver, or even if they should be merged with other sub-clusters, to determine the final result. Algorithm 1 shows how the entire clustering process with this post-processing operation works. The interval [nkmin, nkmax] refers to the minimal and maximal number of clusters to be evaluated."}, {"title": "A. Reorganization using initial and final points", "content": "Two different approaches were taken to evaluate the best solution to further divide the clusters according to their initial and final points:\n\u2022 Cluster both initial and final points on the same array, establishing automatically the sub-cluster groupings\n\u2022 Cluster the initial point, then the final point and list the grouping created comparing both results.\nGiven that a search based on a number of clusters is already being executed, the mean-shift algorithm was used to execute these two options of post-processing, avoiding a nested search. After the merge process will happen, to fuse clusters with fairly similar characteristics, only differing from a few meters from each other while retaining its significant part, for example a left turn, a street crossing, etc.\nEvaluating if two sub-clusters should be merged is done using the medoid of each cluster, together with the spread of elements in each sub-cluster, Equation (8). The variable m\u1d62 represents the medoid of the cluster C\u1d62 and N\u1d62 its number of trajectories. To merge one sub-cluster with another it is necessary that the distance between both medoids be smaller than the sum of spreads for the respective clusters (line 5 of algorithm 2). To discard small differences, the medoid of one cluster is projected into the other (line 3 of algorithm 2), so that the similarity disregard any errors in tracking or even small differences in the start or terminus of the trajectory. If this condition is true, there is another to be fulfilled: the calculated projection should be equal or higher than a certain percentage of the original trajectory (which is defined in Table II for all cases examined here).\n\\begin{equation}\nsprc_i = \\frac{1}{N_i} \\sum_{x_i \\in C_i} d_{DTW}(m_i, x_i)\n\\end{equation}\nEquations (9) and (10) show how one trajectory is pro-jected onto another. For two generic trajectories tra = (P\u2090\u2080, P\u2090\u2081, \u2026, P\u2090\u2099) and try = (Pb\u2080, Pb\u2081,\u2026\u2026\u2026, Pb\u2098), two loops are executed: one for the initial point of tra and another its final point. Inside these loops the index j in increased from 0 (or decreased from N\u2080 for the terminus) to find the interval of points where pa\u2080 (or pa\u2099) is perpendicularly projected. The cutting point is obtained when \u03bb\u2c7c \u2208 [0,1], meaning that the projection of pa\u2080 (or pa\u2099), is between points j and j + 1 from try. If no cutting point is detected then all the trajectory is used in the comparison."}, {"title": "B. Evaluating cluster partition quality", "content": "Finally, it is necessary to evaluate the clusters according to the similarity of elements inside each cluster and in other clusters as well. Three metrics will be used for it: the Davies-Bouldin index the Silhouette score and the spread on cluster, proposed here. The DB index will be slightly modified to allow a better representation of the distribution quality for a certain number of clusters, while the latter will be used as it was defined in [17].\n1) Davies-Bouldin index (DB): The Davies-Bouldin index (DB) is originally defined as the average of the maximal value of R\u1d62\u2c7c, as if defined in Equations (11) and (12). Equation (8) is used to calculate the spread s\u1d62. Since it is the maximal value of R\u1d62\u2c7c that is used to calculate the final score, it has creates a dependency to the number of clusters, i.e. the decrease on the score is connected to a higher number of cluster and not necessarily a better distribution.\n\\begin{equation}\nR_{ij} = \\frac{(s_i + s_j)}{d_{ij}}\n\\end{equation}\n\\begin{equation}\nDB_{nc} = \\frac{1}{N_c} \\sum_{i=0}^{N_c}  \\max_{j=1,...,n_c, i \\neq j} R_{ij}\n\\end{equation}\nThus, a small modification was done, to use the average of R\u1d62\u2c7c, not its maximal value, as it can be seen in Equation (13). This offers less bias to the number of clusters, considering always all the distribution of elements being evaluated. The 1 discounts the distance of the medoid to itself, which is zero.\n\\begin{equation}\nDB_{nc} = \\frac{1}{n_c} \\frac{1}{n_c - 1} \\sum_{i=0}^{n_c} \\sum_{j=0}^{n_c} R_{ij}\n\\end{equation}\n2) Silhouette score (Slh.): Another metric to evaluate the clustering quality is the silhouette score, proposed in [17]. Differently from the DB score, it is calculated for each element being clustered, with a(i) begin the average dissim-ilarity (DTW distance in this case) of element i to all other elements in its cluster. The other value necessary to calculate the silhouette is the minimum average dissimilarity between the element in question to the other clusters, Equation (15).\n\\begin{equation}\nsc_i(i) = \\frac{b(i) \u2013 a(i)}{max (a(i), b(i))}\n\\end{equation}\n\\begin{equation}\nb(i) = min_{C_j \\neq C_i} d_{DTW} (b(i), C_j)\n\\end{equation}\nWith the s(i) for each trajectory, the silhouette score for the clustering is the average score for all elements. This score is contained in [-1,1], with a score close to 1 being excellent (distances inside cluster are much smaller than distance between clusters). As the DB score it compares a infra-cluster spread measure with inter-cluster distances, but in a individual level. As it will be seen, in some situations where many different clusters co-exist close to each other (subsection IV-B), it will not be a representative measure of cluster quality.\n3) Spread on cluster (Spr.): This measure is somewhat similar to Equation (9) but was changed to capture the biggest difference between two members of the same cluster. In Equation (16) the average of all the spreads divided by the number of members in the respective cluster define the metric.\n\\begin{equation}\n\\Theta_c = \\frac{1}{\\|C\\|} \\sum_{i=0}^{\\|C\\|}  \\max_{j, k \\in C_i, } \\frac{d_{DTW} (z_j, z_k)}{\\|C_i\\|}\n\\end{equation}\nThis metric will be specially important for the pedestrian case, where the silhouette score is not representative given the close proximity of multiple clusters."}, {"title": "IV. RESULTS", "content": "Two different sources of data will be used to test the algorithms proposed here: the inD dataset [7] and the roundD dataset [8]. Both are obtained using a unnamed aerial vehicle (UAV), the former containing four different intersections and the latter three roundabouts, all in Germany. The information about the number of trajectories per scenario and per road user can be found in table I; the number of files refers to the data-batch file division for each scenario: in the inD case only the first three intersections were used for the VRU (for the vehicle case all intersection were tested) and for the roundD there are two files with two different roundabouts that are not used (only a few observations); the other scenarios are obtained from the observation of a third one (files 02 to 23). This data was split into three scenarios, given the number of trajectories (the clustering results of the three scenarios could be merged using the algorithm proposed in [2]). For the clustering execution all three road user trajectories from inD were used (in blue at Table I), while for the rounD only the vehicles' trajectories could be used, due to the low number of observations for pedestrians and cyclists (in red at Table I).\nTable II shows the parameters used for the tests that will be presented next. The number of cluster established the interval clusters tested by the methods, while the Min. trace refers to the minimal percentage that the projected medoid must have to be merged with another cluster (subsection III-A, algorithm 2).\nThe choice for this specific datasets was motivated because both of them are captured by drone, not by an automated ve-hicle in the environment, which could modify the behaviors observed and also because the metadata present in the dataset allows the trajectories to be plotted in a realistic background image. But the method presented here could be used in any other ensemble of trajectories. Also, all the data is used as-is, no trajectory in the dataset is discarded beforehand only a normalization is done on each dimension of the trajectory before calculating the dissimilarity matrix (Equation 1). All the methods were implemented in Python."}, {"title": "B. Pedestrians", "content": "There are three intersection scenarios for pedestrians, all in the inD dataset. The most important problem with pedestrians is the high variability of maneuvers, because it have an almost constraint-free environment to evolve and also due to detection and tracking errors during the dataset acquisition and post-processing. It is a real challenge for the clustering process to treat all these problems and produce a compact cluster set. The results for scenarios 0 and 2 can be seen in table III and table IV.\nThe abbreviation Agglo refers to the pure agglomerative clustering, A2MS to the agglomerative followed by two mean-shits, on the initial and final points separately and A1MS to one mean-shift on the initial and final points on the same array. For all tables, III through XI, the time indicated is the average clustering time per cluster calculated. In the column best nk the first value is the nominal value of the number of clusters used, and in parenthesis it is the final number of clusters, and in the last column the percentage of the original trajectories present in the final classification (in parenthesis the number of rejected trajectories).\nBoth scenarios are two extremes for the clustering pro-cess: one has few trajectories and not many options for a pedestrian to evolve in the environment and the other has much more of both. It is exactly of possible destinations and the possibility to use the same space in both directions that make the silhouette measure to fail when choosing the best method. Since the number of optimal clusters for each method is different, the spread on cluster, defined in III-B.3 is the best choice of criteria to select the best method overall and in the current case it indicates that the agglomerative clustering with two mean-shift applications (A2MS) is the best option for the scenario 0 and 2 (for the 1 as well, for space limitations it will not be shown here).\nFor both scenarios the same observation can be made: the A2MS method has the lowest DB score and spread while the pure agglomerative method has the biggest silhouette score. This is exactly because the latter method some clusters that should be separated end up together while for the former one they usually can be separated by the second clustering. In both cases, clusters with a single element are discarded from the final distribution (and not accounted for during the calculation of the scores presented in each table). The exactly same observations can be made for the scenario 22.\nDifferences between pure agglomerative against both mean-shift post-processing one are clearly visible, but in scenario 2 the results are more similar. This is probably due to the high number of samples, with helped the pure agglomerative method to sift through the outliers, but as it can be seen in Figure 4, not enough; it can also be seen the efficacy of the A2MS method to remove mixed clusters.\nConcerning the comparison with the PAM and dissimi-larity methods, one can see that they are inefficient in both fronts being evaluated here: take more time to calculate and do not produce tight clusters, specially because of the outliers present in the scene. In [2], these methods were used to discover the different maneuvers of vehicles, but it must be highlighted that car's behaviors are much more constrained than pedestrians (and thus prone to outliers) and that the few outliers observed were removed before execution."}, {"title": "C. Cyclists", "content": "The cyclist data was acquired at the same intersections than the pedestrians. From the set of trajectories given by the dataset the approximate cyclist behavior can be considered as somewhat between cars and pedestrians, with a constrained movement, but still able to access multiple parts of the road environment. For scenario 1 results (Table V) the main distinction that can be made from the pure agglo. and its modification is the opposite of what was observed with pedestrians.\nSome of the trajectories were split between multiple clus-ters for the pure agglomerative method while for the A*MS (meaning both A1MS and A2MS) methods these clusters could be merged together, specially in scenario 2. There are other instances of this same behavior in different clusters as well. Both A*MS methods can attribute their superior scores to the ability to remove outliers from clusters, as illustrated in Figure 5."}, {"title": "D. Vehicles", "content": "For vehicles the volume of data increases, with the addi-tion of inD dataset scenario 3 and the entire rounD dataset. Since the movements for vehicles are very constrained there are almost none eccentric behavior, hence the goal here is to eliminate all the erroneous samples; for example, trajectories that end at the middle of the intersection. In some cases this was possible, notably on scenarios 1 and 2 for the inD dataset, however, in scenario 0 one maneuver got separated as the result of the mean-shift and merge mechanism for the A2MS method (Figure 6). Beyond that all other maneuvers for 0 were correctly determined.\nFor scenario 1 the agglo., A2MS and A1MS were spot on, with the sole difference that two clusters detected by the agglo and the A1MS are actually outliers and were rejected by A2MS before they formed clusters.\nFor scenario 3 the A1MS actually is the better option, but there is only a difference of two samples classified differently from this case.\nSince the trajectories for the rounD dataset are fairly different in length and direction the DTW distance measure is able to really account trajectories from different maneuvers, as it can be seen in table XI.\nBut there is something that are not as salient in the short turns in the intersection from inD dataset but is in this case. Given the size of the roundabout the position in which the vehicles execute the trajectory becomes a discriminating parameter, i.e. the clusters also accounted if they are on the inside or outside (Figures 9a and 9b comparing with 9c) together with the lane in which the vehicle ends or starts its trajectory. This difference mostly impacted the merge step given that now there is a lateral distance through the curve that is bigger than the spread over both clusters. If this division is appropriate or not is in the eye of the beholder.\nAs a general comment, for the current use-case, the method A2MS proved vastly better than any other, which was made clear by the spread on cluster score defined here. It captures the tightness of each cluster much better than the DB index, which ends up being translated as clusters with few to none outliers in their midst."}, {"title": "V. CONCLUSION", "content": "A new method to cluster trajectories, A2MS, together with a metric defined for the trajectory clustering case, the spread on cluster, were proposed and tested with the datasets inD and rounD. Using an hierarchical clustering combined with DTW distance measure and a as cluster distribution measure, A2MS proved to be the most efficient in the tested methods to produce tight and concentrated clusters with minimal number of outliers.\nThe immediate next step is to use this clustering method in conjunction with the longitudinal approach proposed by [2] to extract drivers' behaviors from real data. But more broadly the method proposed here has multiple uses, from prepare data to learning tasks for planning, decision-making or prediction to even the study of traffic flow in a predeter-mined zone. Ultimately, this method allows in the future to collect data to train a representation of trajectories so that comparisons could be made with trajectories from different road configurations."}]}