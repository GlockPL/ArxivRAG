{"title": "A Closer Look at Data Augmentation Strategies for Finetuning-Based Low/Few-Shot Object Detection", "authors": ["Vladislav Li", "Georgios Tsoumplekas", "Ilias Siniosoglou", "Vasileios Argyriou", "Anastasios Lytos", "Eleftherios Fountoukidis", "Panagiotis Sarigiannidis"], "abstract": "Current methods for low- and few-shot object detection have primarily focused on enhancing model performance for detecting objects. One common approach to achieve this is by combining model finetuning with data augmentation strategies. However, little attention has been given to the energy efficiency of these approaches in data-scarce regimes. This paper seeks to conduct a comprehensive empirical study that examines both model performance and energy efficiency of custom data augmentations and automated data augmentation selection strategies when combined with a lightweight object detector. The methods are evaluated in three different benchmark datasets in terms of their performance and energy consumption, and the Efficiency Factor is employed to gain insights into their effectiveness considering both performance and efficiency. Consequently, it is shown that in many cases, the performance gains of data augmentation strategies are overshadowed by their increased energy usage, necessitating the development of more energy efficient data augmentation strategies to address data scarcity.", "sections": [{"title": "I. INTRODUCTION", "content": "In today's commercial and industrial ecosystem, Artificial Intelligence (AI) has become a key driver in upgrading services, products, and operations, due to its powerful nature that supports real-time and high-fidelity predictions. However, training Machine Learning (ML) and Deep Learning (DL) models can be an arduous and computationally expensive task due to the lengthy training sessions required to adapt to large volumes of data [1]. Additionally, there are various cases where collecting abundant data can be challenging due to increased costs (e.g., industrial sector) or privacy concerns (e.g., healthcare sector). To address this data scarcity that is often encountered in these domains, various Data Augmentation (DA) approaches have been developed in recent years. These approaches effectively increase dataset size by applying various transformations to the data, which facilitates training, enhances model generalization, and improves model robustness.\nAnother pervasive issue with conventional Al models in industrial applications is their struggle to adapt to novel categories (classes) added after training, requiring costly and energy-intensive retraining. While continual/incremental learning approaches can circumvent this limitation, they often come with added complexity, making them impractical for many industrial use cases.\nGiven the pressing nature of dealing with the modern energy crisis, tackling these common limitations of AI systems is crucial [2]. This is particularly true for real-time industrial applications where ML/DL models are expected to run on resource-constrained edge devices, rendering energy efficiency a critical requirement. Recently, low-shot learning (LSL) and few-shot learning (FSL) have emerged as promising solutions that leverage prior knowledge and transfer it to novel tasks, requiring only small amounts of labeled data to generalize and make accurate predictions. This significantly reduces the need for large datasets and extensive computational resources, making model training more efficient and effective while enabling adaptation to new task requirements (e.g., additional classes) using only a small amount of data.\nDespite the emergence of various energy-efficient LSL/FSL approaches in recent years, limited attention has been given to evaluating the energy efficiency of DA methods for LSL/FSL, which are widely used in practice. This work aims to fill this gap by investigating the overall efficiency of such DA approaches used during finetuning a lightweight object detector to novel downstream tasks under data scarcity (LSL and FSL scenarios). Specifically, the main objective of this empirical study is to provide a clear perspective on the efficacy of these techniques in low-capacity systems, like edge devices and embedded systems, by evaluating both their energy efficiency during the finetuning process as well as the generalization capabilities of the resulting models under varying levels of data availability. The contributions of this research can be summarized as follows:\n\u2022 A performance and energy efficiency analysis of utilizing various DA strategies during finetuning on three benchmark datasets for low- and few-shot object detection is provided.\n\u2022 An ablation study further examining the performance differences between custom and automated DA methods"}, {"title": "II. RELATED WORK", "content": "Following the broader paradigm of LSL and FSL, low/few-shot detection techniques can be categorized into meta-learning and finetuning-based approaches. Meta-learning approaches involve creating low/few-shot tasks during training and learning how to transfer knowledge to novel tasks in a class-agnostic manner. Several existing object detector architectures have been adapted for this purpose, including Meta Faster R-CNN [3] and Meta-DETR [4]. On the other hand, finetuning-based approaches are pretrained in a base dataset with abundant annotated data and then finetuned in the low/few-shot tasks incorporating techniques such as finetuning only the final classification layer [5], contrastive learning [6] and gradient scaling and stopping [7].\nIn recent years, new approaches have been developed to address data scarcity in the LSL and FLS settings using DAs. These include employing a hallucinator network to generate novel image [8] and RoI [9] samples, using a Variational Autoencoder (VAE) that generates novel features in the model's latent space [10], processing RoIs extracted from the original images in multiple scales [11], and semantically separating foreground objects from their backgrounds and fusing them with novel ones [12]. However, it remains unclear whether these approaches are optimal when considering energy efficiency due to their increased complexity.\nGreen AI has recently emerged as a nascent area that aims to address the energy efficiency and carbon footprint concerns of modern deep learning approaches by developing more energy efficient models. In the field of computer vision, in [13], model energy consumption is estimated using a bilinear regression model and used in a constrained optimization problem to obtain a compressed and energy efficient model. Additionally, in [14] the architecture settings of a CNN are treated as hyperparameters to be optimized using Bayesian optimization, with the optimization problem taking into consideration both model performance and energy efficiency.\nRecently, energy efficiency has also been examined in the context of object detection in [15], which evaluates different components of object detectors regarding energy efficiency and proposes an architecture and data augmentation strategy based on their findings. Nevertheless, there has been limited assessment of the energy efficiency of LSL/FSL for object detection, with the exception of [16], where the authors assess the efficiency of finetuning-based approaches in this context and propose a novel metric aimed at consolidating model performance and energy efficiency into a single value.\nDAs for deep learning-based methods, particularly for computer vision applications, have been extensively researched in previous years. In the context of object detection, DAs usually refer to basic hand-crafted operations selected for specific models and datasets and can be broadly categorized as image manipulation (e.g., rotation, translation, shearing), image erasing (e.g., random erasing, Cutout), and image mixing (e.g., mixup [17]). More recently, a novel line of DA approaches has also emerged where selecting a DA strategy is formulated as a discrete space search problem and is solved using reinforcement learning [18], random selection [19] or by enforcing consistency between original and augmented images [20]. However, the assessment of these techniques in terms of energy efficiency has been limited, especially in the context of LSL and FSL. Our study examines both hand-crafted DA techniques and automated methods for their performance vs energy efficiency trade-offs."}, {"title": "III. METHODOLOGY", "content": "In the context of few-shot object detection (FSOD) and low-shot object detection (LSOD), the goal is to develop object detectors capable of rapidly adapting to novel downstream tasks containing only a few training images of previously unseen objects. Following the standard formulation introduced in [21], an object detector is initially trained on a base dataset with abundant data of $C_{base}$ classes and is subsequently adapted to a novel dataset with limited data of $C_{novel}$ previously unseen classes, i.e., $C_{base} \\cap C_{novel} = \\emptyset$. More specifically, we define the base dataset as $D_{base} = \\{(I_n, y_n)\\}_{n=1}^N$, where $I_n \\in I$ is an input image and $y_n \\in Y$ is its corresponding label and bounding box annotations. In particular, image $I_n$ contains $B_n$ objects, so $y_n = \\{(c_b, box_b)\\}_{b=1}^{B_n}$, where $c_b \\in C_{base}$ is the object label and $box_b = (x_b, y_b, w_b, h_b)$ is the object's box location. Typically, N is large, and as a result, an object detector $f_{\\theta}$, parameterized by $\\theta$, can be effectively trained in this dataset using standard supervised learning approaches.\nFollowing the pretraining of the model on $D_{base}$, the next step is to adapt $f_{\\theta}$ in the novel dataset which can be defined as $D_{novel} = \\{(I_m, y_m)\\}_{m=1}^M$, where $I_m$ is the input image but now $y_m = \\{(c_b, box_b)\\}_{b=1}^{B_m}$ with $c_b \\in C_{novel}$. In $D_{novel}$ there are only K labeled bounding boxes for each class, and the images having these bounding boxes constitute the support set S of $D_{novel}$. Additionally, $D_{novel}$ also contains a set of images used for evaluating the final model's performance in the $C_{novel}$ classes, called the query set Q.\nBased on this formulation, a straightforward way to adapt $f_{\\theta}$ on $D_{novel}$ is to finetune the model on S replacing only its final classification layer. Finetuning can be either full (whole model) or partial (e.g., frozen backbone), and the resulting model $f_{\\theta'}$ is finally evaluated on Q.\nThis work aims to evaluate the performance and energy efficiency of DA strategies used for LSL/FSL. One effective"}, {"title": "IV. EXPERIMENTAL SETTING", "content": "In the following experiments, three datasets containing images of objects and hazards commonly found in industrial settings are used to assess the examined DA techniques. For each dataset, the images in the training set are utilized to create the low/few-shot training tasks for finetuning the object detectors. Model performance on the validation set images is used to determine the number of training epochs through an early stopping procedure. Finally, all reported performance metrics of the finetuned models are based on evaluation using the test set images.\nIn the following experiments, we utilize the YOLOv8n variant of the YOLOv8 model, pretrained on the MS COCO dataset, as our initial model before finetuning. The model contains approximately 3.2M parameters, but only the parameters of the three detection modules are finetuned, resulting in \u2248750K trainable parameters during finetuning. The initial model is finetuned for 1000 epochs using Early Stopping with patience set to 100 epochs. During optimization, AdamW with a learning rate of 0.01 is employed, and the batch size is set to 32. The resulting model is denoted as FT.\nAs for the DA strategies followed, all images are initially resized to 640 \u00d7 640 pixels. All custom augmentation techniques are implemented using the Albumentations [24] library with default settings provided. We denote augmentations targeting data scarcity as DA (1), augmentations tackling overfitting as DA (2), and their combination as DA (1+2). As for the automated DA selection techniques, the pool of DAs includes"}, {"title": "V. FEW-SHOT LEARNING RESULTS", "content": "In the FSL setting, the models are finetuned using N-way K-shot tasks, where N is the number of classes in the dataset and $K \\in \\{1, 2, 3, 5, 10, 30\\}$ is the number of bounding box annotated objects used as support set samples for each class, while the entire test set of each dataset is used as the query set."}, {"title": "C. Evaluation Metrics", "content": "Following the standard evaluation procedures for object detection models, we use $AP_{50}$, which represents the model's Average Precision (AP) using a fixed Intersection over Union (IoU) threshold of 50%, to evaluate model performance. In addition to model performance, we are also interested in assessing the energy efficiency of the models during the fine-tuning process. This is achieved by measuring each model's energy consumed during finetuning using the CodeCarbon library. While the specific hardware configuration can impact these measurements, the relative differences between the various examined approaches will remain consistent, making the results valuable even to users with different hardware setups.\nFinally, to consider both model performance and efficiency, we utilize a modified form of the Efficiency Factor (EF) metric, which was introduced in [16] and is defined as follows:\n$EF = \\frac{AP_{50}}{1 + EC}$\nwhere $AP_{50} \\in [0,100]$ is used instead of the $mAP$ in the original formulation, and $EC \\in (0,+\u221e)$ is the model's energy consumption measured in Wh."}, {"title": "A. Main Results", "content": "Table II shows the model performance of different DA strategies for each dataset's support set for varying shots. It is evident that increasing the number of shots in all cases leads to improved performance since more training samples become available during the finetuning process. Additionally, the three examined automated DA selection methods (FT+AutoAugment, FT+RandAugment, FT+AugMix) demonstrate the same performance in all cases, possibly due to the limited DA pool that leads to the selection of the same DAs by all three methods.\nFor the PPE dataset, model performance is similar for a small number of shots. However, the gap increases for a greater number of shots, with automated DA selection methods leading to improved results (33.59%) compared to custom DAs (28.11% for FT+DA (1+2)) and finetuning without DA (23.99%). Similar conclusions can be drawn for the CS dataset where automated DA selection methods significantly outperform custom DA (45.68% vs. 37.84% for FT+DA(2)) and vanilla FT (45.68% vs 32.25%). In the Fire dataset, custom DA methods and mostly FT+DA (1) produce strong results for a small number of shots, which could be attributed to the fact that it generates additional samples and assists in tackling the extreme data scarcity in these settings. However, in the 30-shot scenario, automated DA selection methods lead to the best results. Finally, it is worth noticing that since the number of classes affects the number of training samples available in the N way K shot formulation of tasks in FSL, models struggle in datasets such as Fire with only one class available, and their performance improves in datasets with more classes such as PPE and CS.\nTable III includes the energy consumed by each examined model during the finetuning process for each dataset and a varying number of shots. Generally, increasing the number of shots in the PPE and CS datasets leads to increased energy consumption. This behavior is expected since increasing the shots leads to more samples that need to be processed and, consequently, more finetuning epochs for the models"}, {"title": "B. Effect of Custom Augmentations", "content": "Fig. 1 illustrates model performance in terms of AP50 with respect to the energy consumed during finetuning using vanilla FT or one of the three examined custom DA approaches. We have included the relevant plots only for the PPE and CS datasets since the extreme data scarcity in the Fire dataset does not allow for a valid interpretation of the obtained results. Overall, in both datasets, it is evident that FT leads to the most optimal performance vs. energy efficiency trade-off followed by FT+DA(1), FT+DA(2), and finally FT+DA(1+2). It is also worth noticing that almost all curves corresponding to a different method (shown with different colors in the plot) can be approximated by a straight line, indicating that energy consumption grows exponentially compared to AP50. This also verifies our findings that EF values tend to drop as the number of shots increases. The only case where this does not seem to be true is for FT in the CS dataset, where there appears to be a linear relationship between model performance and energy consumption."}, {"title": "C. Effect of automated augmentations", "content": "Fig. 2 illustrates the energy consumption difference between the automated DA selection techniques and the vanilla FT approach. Since all methods achieve the same AP50 performance in all cases, this provides a valid comparison to determine the optimal strategy among the three. Following our previous observations, for the PPE dataset, automated DA selection methods result in increased energy consumption compared to FT, except for the 30-shot case, where the finetuning procedure converges faster. For the Fire dataset, there appears to be a trend where increasing the number of shots leads to a growing"}, {"title": "D. Finetuning with and without DAs", "content": "In the final assessment under the FSL scenario, we compare the performance of the best custom and automated DA approaches to the vanilla FT in terms of the EF metric. Table V shows the percent change between the EF of FT+DA(1) (best custom DA technique in terms of EF) and FT+AugMix (best automated DA selection technique in terms of EF) compared to the EF value of FT. Interestingly, for the PPE dataset, DA approaches lead to worse EF performance, except FT+AugMix in the 30-shot scenario. In the Fire dataset, FT+DA (1) leads to a significant boost, especially when the number of shots is small. However, for a larger number of shots, that boost becomes small, and eventually, DA approaches perform worse than FT in the 30-shot scenario. Lastly, the benefits of utilizing FT+AugMix in the CS dataset are clearly illustrated, supported by the fact that the improvement upon the FT baseline generally increases as the number of shots increases. Consequently, there are no strong indications that DA approaches are always beneficial for FSL when considering both model performance and energy efficiency."}, {"title": "VI. Low-SHOT LEARNING RESULTS", "content": "Unlike the FSL setting, where training tasks are constructed based on the number of bounding box annotations available for each class during training, a percentage of the total available training images is used for finetuning in the LSL setting. We define scenarios where D% of the available training images are used, including all bounding boxes found in these images, with D\u2208 {5, 20, 25, 50, 75, 100}. In the LSL scenario, we mainly focus on the proposed custom DA approaches and thus have included FT+DA (1), which was particularly effective in the FSL scenario and FT+DA (1+2) to obtain a full view of utilizing the custom DAs altogether. Finally, we also include the results from finetuning a randomly initialized YOLOv8n model (results omitted in the FSL scenario since the model"}, {"title": "A. Main Results", "content": "Table VI includes the model performance of the examined methods under varying sizes of the training set in each dataset. In the PPE and CS datasets, vanilla FT leads to the best performance when the percentage of utilized data is small (5% for PPE and 5% and 20% for CS), followed by FT+DA(1+2). However, when the number of available training data increases, FT+DA(1+2) leads to optimal performance results in both cases. As for the Fire dataset, the application of custom DA approaches leads to improved results regardless of the training set size with FT+DA(1+2) achieving the best results for 5%, 20%, 25% and 100% of training data used and FT+DA(1) for 50% and 75%. Furthermore, it is clear that Base yields poor results in all cases, demonstrating the importance of combining pretraining and finetuning. This is also illustrated in Fig. 3 where using finetuning-based approaches can lead to significant improvements in AP50 that exceed 50% in some cases. However, in the CS dataset, using FT+DA(1) can lead to performance degradation when more than 5% of the available training data is used, possibly due to the fact that FT+DA (1) introduces novel diverse training samples that cannot sufficiently be exploited by lightweight object detectors such as YOLOv8n [15].\nTable VII contains the energy consumption during the finetuning process for each model in each dataset. It is important to note that training a model from scratch is highly inefficient compared to the finetuning approach in all cases, with energy requirements being three to four orders of magnitude higher. Overall, vanilla FT demonstrates the lowest energy consumption, especially as the number of available training data increases. When the percentage of training data is small, utilizing custom DA approaches can result in faster model convergence and thus lower energy consumption, as is the case for FT+DA (1) for 5%, 20%, and 25% in the PPE dataset and FT+DA (1) for 5% in the Fire dataset. Additionally, similar to the findings in the FSL case, energy consumption generally increases as the number of available training samples increases."}, {"title": "B. Performance vs Efficiency Trade-offs in the LSL Setting", "content": "While the results mentioned above suggest that using DA techniques can enhance model performance at the cost of increased energy consumption, it remains uncertain whether this trade-off is beneficial when taking both performance and energy efficiency into account. To address this question, Table IX includes the percent change of the EF metric values between the best custom DA approaches and vanilla FT for the examined LSL scenarios. Interestingly, utilizing DA methods is optimal only in the PPE dataset, mainly because they significantly improve AP50. However, even in this scenario, as the number of available training samples increases, the"}, {"title": "VII. CONCLUSION", "content": "While low/few-shot object detection has been extensively studied in recent years, the performance impact of different data augmentation strategies on finetuning-based models and their energy efficiency have yet to be fully explored. This paper aims to address these gaps by conducting an empirical study that evaluates data augmentation strategies in data-scarce settings and their effect on a lightweight object detector's performance and energy consumption. Results on three challenging industrial object detection tasks with limited data show that while data augmentations can improve performance, the additional energy consumption often outweighs the performance gains. Finally, a novel Efficiency Factor metric is employed to assess both model performance and energy efficiency, concluding that the effectiveness of data augmentations highly depends on the dataset and may not always lead to improved results. In the future, it would be interesting to explore how these insights can be utilized in designing augmentation strategies that enhance both model performance and energy efficiency in these settings as well as other application domains with similar requirements, e.g., healthcare and the energy sector."}]}