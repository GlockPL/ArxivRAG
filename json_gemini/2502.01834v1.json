{"title": "Building a Cognitive Twin Using a Distributed Cognitive System and an Evolution Strategy", "authors": ["Wandemberg Gibaut", "Ricardo Gudwin"], "abstract": "This work presents a technique to build interaction-based Cognitive Twins (a computational version\nof an external agent) using input-output training and an Evolution Strategy on top of a framework\nfor distributed Cognitive Architectures. Here, we show that it's possible to orchestrate many simple\nphysical and virtual devices to achieve good approximations of a person's interaction behavior by\ntraining the system in an end-to-end fashion and present performance metrics. The generated Cognitive\nTwin may later be used to automate tasks, generate more realistic human-like artificial agents or further\ninvestigate its behaviors.", "sections": [{"title": "1. Introduction", "content": "This work proposes an approach that uses an evolution-\nary algorithm along traditional Machine Learning methods\nto build a digital, distributed cognitive agent capable of\nemulating the potential actions (input-output behavior) of\na user while allowing further analysis and experimentation\n- at a certain level - of its internal structures. We focus\non the usage of simple devices and the automation of this\nbuilding process, rather than manually designing the agent.\nTo accomplish this, we used DCT (Gibaut and Gudwin,\n2020), a tool to build distributed cognitive architectures\nacross multiple physical and virtual devices. We argue that\nthis brings some advantages, like true, massively parallel\nprocessing, low computing power device usage, and the\nexploration of different ways in which each part of the system\nmight interact with others. In this introduction, we provide\na primer on cognitive systems (subsection 1.1), system of\nsystems (subsection 1.2), Cyber-Physical Systems (1.3), and\nrelated work on cognitive twins (subsection 1.4). In section\n2, we describe DCT, providing an architectural overview of\nDCT, its codelets, and memory structure, introducing impor-\ntant terminologies to be used later in this article. In section 3\nwe describe our vision on how to evolve a cognitive twin,\nand in section 4 we describe our experiments. Finally, in\nsection 5 we discuss our results, provide some conclusions,\nand indicate future works related to this research."}, {"title": "1.1. Cognitive Systems", "content": "The research area of Cognitive Systems emerged in\nthe early 90s, derived upon the research on Expert Sys-\ntems, Production Systems, and Knowledge-Based Systems\n(Newell and Simon, 1961; Simon and Newell, 1971). Inves-\ntigating the origins of human knowledge, Anderson (1989)\ndeveloped the ACT-R Cognitive Architecture (Anderson,\nBothell, Byrne, Douglass, Lebiere and Qin, 2004; Anderson,\n2009). Approximately at the same time, based on the ideas\npresented by Newell, Rosenbloom and Laird (1989), Laird\nreleased early versions of the SOAR cognitive architecture\n(Laird and Rosenbloom, 1996; Laird, 2012). By the end of\nthe 1990s, a large group of researchers involved in the Simu-\nlation of Adaptive Behavior shaped the concept of Cognitive\nArchitecture as an essential set of structures and processes\nnecessary for the generation of a computational, cognitive\nmodel that could be used in several areas relating cognition\nand behavior. Sloman (2002), for example, discussed the \"ar-\nchitectural\" question of representing mental concepts, and\nSun (2004) proposed a set of requirements needed to build a\nCognitive Architecture. Next, Sun (2007) investigated issues\nand challenges in the development of such models. Langley,\nLaird and Rogers (2009) analyzed several existing Cognitive\nArchitectures, evaluating the overall progress in the research\narea. These studies indicated that the main advantage of\ncharacterizing a system as cognitive is the possibility of\nobtaining a concrete framework for cognitive modeling, in\nsuch a way that these models could be concretely tested.\nSuch characterization might allow the definition of a set of\nstructures, modules, and basic processes, creating a common\nlanguage so that different researchers could explore their\nproposals for cognitive models.\nFollowing this tradition, we understand a Cognitive Sys-\ntem as a general-purpose control system inspired by scien-\ntific theories developed to explain the process of cognition\nin humans and animals. The idea of having an architecture is\nto decompose the cognitive phenomenon into a spectrum of\ncapabilities, e.g. perception, attention, memory, reasoning,\nlearning, behavior generation, and others. Furthermore, such\narchitectures would also function as theoretical models of\ncognitive processes, allowing such theories to be tested and\nreused in different applications.\nCognitive architectures have been tested in several ap-\nplications, from robot control to decision-making processes\nin intelligent agents, and substantially facilitate efforts to"}, {"title": "1.1.1. Digital and Cognitive Twins", "content": "In the past few years, due to the rise of new technologies\nand the challenges of a hyper-connected digital world, there\nis a growing interest in digital copies of physical entities,\nwhich are usually referred to as Digital Twins. Although\nthere is no consensus on the definition of a Digital Twin,\na good definition is presented by Lim, Zheng and Chen\n(2019), as a \"high fidelity virtual replica of the physical\nasset with real-time two-way communication for simulation\npurposes and decision-aiding features for product service\nenhancement\". There are many uses of a digital replica of\nan entity, and Zhang, Bahsoon and Theodoropoulos (2020)\npresent a hierarchy that classifies Digital Twins from the\nsimplest, descriptive type to the more complex ones. These\nare classified as Cognitive Digital Twins and can replicate,\nup to some level, human cognitive processes, acting with\nminimal or no human intervention. In this case, cognition\nmeans processes like self-awareness, dynamic knowledge\nacquisition, and management and decision-making capabili-\nties in both digital and physical worlds, in an info-symbiotic\nmanner.\nAmong other definitions, Abburu, Berre, Jacoby, Ro-\nman, Stojanovic and Stojanovic (2020b) present three levels\nof Digital Twins, being a Cognitive Twin (CT) defined as a\nhybrid, self-learning, and proactive system that optimizes its\ncognitive capabilities over time based on collected data and\ngained experience. It combines AI analytics techniques and\nexpert knowledge to control the system's behavior, solving\nemerging problems.\nIn a more agent-centered vision, Somers, Oltramari and\nLebiere (2020) understand a CT as a \"digital reflection of\nthe user, intended to make decisions and carry out tasks on\nthe user's behalf\", to \u201chighlight the key role that cognitive\nmechanisms play in modeling human decision-making in the\nIoT digital space\". There, they apply this concept as a way to\nmodel cognitive processes underlying the user's decisions.\nIn this same direction, Du, Zhu, Shi, Wang, Lin and Zhao\n(2020) introduce a personal DT model of information-driven\ncognition (Cog-DT) as a \"digital replica of a person's cogni-\ntive process concerning information processing\" including a\nVR platform and an adaptive UI.\nAs pointed out by Abburu, Berre, Jacoby, Roman, Sto-\njanovic and Stojanovic (2020a), despite the existence of\nmany definitions, there is an agreement that a Cognitive\nTwin is an extension of a Digital Twin with some cognitive\ncapabilities, even though there is no consensus on what those\ncapabilities might be. Each definition has its own set of\ncapabilities, which better suit the area and application the\ndefinition came from."}, {"title": "1.2. Systems of Systems", "content": "According to Gudwin, Paraense, de Paula, Fr\u00f3es, Gibaut,\nCastro, Figueiredo and Raizer (2016), the term Systems of\nSystems (SoS, Systems of Systems) began to appear in the\n1990s and still today, continues to attract interest. Although\nbeing a widely discussed issue, the community has not\nyet converged to a common understanding of its meaning.\nAccording to (Gorod, Sauser and Boardman, 2008), which\ntries to track the origin of the term, the first researcher to\npropose something related to the modern idea of an SoS\nwas Boulding (1956), who imagined SoS as a \"gestalt\" in\ntheoretical construction creating a \"spectrum of theories\"\ngreater than the sum of its parts. Later, Jackson and Keys\n(1984) suggested the use of \u201cSoS methodologies\" as the\ninterrelationship between different systems-based problem-\nsolving methodologies in the field of operation research.\nAlthough the field has some pioneers, as shown above, it was\nonly in 1989 that we find the first use of the term \"system-\nof-systems\" to describe an engineered technology system, in\nthe Strategic Defense Initiative (Jacob and Spillmann, 1974;\nGPO, 1989; Gorod et al., 2008).\nFrom 1989 onward, modern research taking into account\nthe term System of Systems was initiated. By that time, the\nconcept of SoS was still very simple and poorly defined\n(Gorod et al., 2008). Among other definitions, Eisner et al.\n(Eisner, Marciniak and McMillan, 1991; Eisner, McMillan,\nMarciniak and Pragluski, 1993) defined an SoS as a set of\nsystems (developed using a nominal systems engineering\nprocess) composed of interdependent systems combined to\noperate in a multifunctional solution, to achieve a common\nmission. Shenhar (1994) defined an SoS as an \"array\" of\nsystems, a large collection or network of systems working\ntogether to achieve a common goal. Holland (1995), in 1995,\ncarried out studies on SoS from different perspectives. He\ndescribed an SoS as an artificial complex adaptive system\nthat, in continuous change, \u201cself-organizes\u201d with adaptive\nrules, to increase its complexity. In the same year, Maier\nproposed a characterization approach to differentiate a com-\nmon system from a system of systems. According to him, an\nSoS must include \"operational interdependence of elements,\nmanagerial independence of elements, evolutionary devel-\nopment, emergent behavior, and geographic distribution\".\nCurrently, Maier is one of the main contributors studying\nthe field of SoS. In 1998, Maier proposed an SoS as a\nset of assembled components (which, in particular, are sys-\ntems in themselves) exhibiting operational and managerial\ncomponent interdependence (Maier, 1996; Maeir, 1998).\nKotov (1997) and Lukasik (1998) then addressed the issue\nof modeling an SoS. Further, Boardman and Sauser (2006)\nstudied more than 40 SoS concepts, creating a common view\non SoS.\nFollowing Boardman and Sauser (2006), and also in\nconsonance with others (Jamshidi and Sage, 2011; Gorod,"}, {"title": "1.3. Cyber-Physical Systems", "content": "During the 90s, different research communities were ex-\nploring the development of \"embedded systems\". From the\nintegration between dedicated computer hardware and the\nautomatic control of physical processes, a new technology\nstarted to emerge: Cyber-Physical Systems (CPS). Accord-\ning to Lee and Seshia (2011), a CPS refers to embedded\ncomputers and networks monitoring and controlling phys-\nical processes, usually comprising feedback loops where\nphysical processes affect computations and vice versa.\nThe term \"Cyber-Physical Systems\" was originally coined\nby Helen Gill, from the National Science Foundation, in\nthe United States in 2006. The prefix cyber in CPS comes\nfrom \"Cybernetics\", a transdisciplinary approach, defined by\nNorbert Wiener in 1948, for exploring regulatory systems,\ntheir structures, constraints, and possibilities. In other words:\nthe study of the effects of feedback in systems theory to\nimplement some sort of control on the system's variables.\nThere are many definitions of CPS in the literature, but\nthe most common definition among contributors is that a\nCPS has to do with exposing parts of the urban environment\nto the Internet, where in some way, computational systems\nuse environmental information collected by sensory devices\nto develop the control of environmental assets such that\nsome goals are achieved, and some performance indexes are\noptimized. Also, CPS are defined as integrated systems that\nprovide computation, networking, and physical processes.\nAnother definition might be: a system where the physical\nenvironment and software components are tightly interre-\nlated, each of them operating on different spatial and tem-\nporal scales, performing different behavior modalities, and\ninteracting with each other. (Conti, Das, Bisdikian, Kumar,\nNi, Passarella, Roussos, Tr\u00f6ster, Tsudik and Zambonelli,\n2012; Sha, Gopalakrishnan, Liu and Wang, 2009; Horvath\nand Gerritsen, 2012; Lee, 2009; NSF, 2013; Khaitan and\nMcCalley, 2015).\nAccording to Miclea and Sanislav (2011) and Khaitan\nand McCalley (2015), a CPS presents a set of fundamental\ncharacteristics:\nFeedback Mechanism: All physical components have a\ncyber capability (feedback loop).\nAutomation: High levels of automation.\nScalability: Networking at multiple scales.\nIntegrability: Integration at multiple temporal and spatial\nscales.\nReconfigurable: Configuring and reconfiguring in real-\ntime, dynamically.\nThe term cyber can also be referred to the cyberspace,\ni.e., the Internet, or the cyber world. Events in the real\nworld need to reflect in the cyber world, and consequently,\nthe cyber world needs to communicate with the physical\nworld, such that decisions can be passed to actuators. This\ncommunication should be performed in real time and with"}, {"title": "1.4. Related Work", "content": "In Abburu et al. (2020a), the authors apply a Cognitive\nDigital Twin to a real-world problem concerning predictive\ncontrol in a steel-processing industry. Somers, Oltramari,\nand Lebiere (Somers, Oltramari and Lebiere, 2021; Somers\net al., 2020) use a Cognitive Architecture to build a Cognitive\nTwin as a personal assistant that learns user behavior from\npast data on a user's social network. Then, as a proof-of-\nconcept case, it uses this knowledge to select attendees to a\nparty.\nEirinakis, Kalaboukas, Lounis, Mourtos, Ro\u017eanec, Sto-\njanovic and Zois (2020) present the concept of Enhanced\nCognitive Twin, in which they use Data Analytics and Ma-\nchine Learning to provide them with a tool to solve en-\nvironmental challenges, like decision-making capabilities,\nautonomous detection of anomalies and opportunities, and\nlong-term optimization of and reasoning.\nRozanec, Jinzhi, Kosmerlj, Kenda, Dimitris, Jovanoski,\nRupnik, Karlovcec and Fortuna (2020) use Cognitive Digital\nTwins in a manufacturing scenario to improve Key Perfor-\nmance Indicators (KPIs) by detecting possible anomalies\nand predicting their impact on production and by planning\nsome aspects of production itself, like rescheduling existing\nplans.\nIn the Symbiotic Autonomous Systems White Paper II\n(Initiative, 2018), the authors put Cognitive Digital Twins\nas an almost essential asset to manage the knowledge gap,\nwhich would greatly impact future education.\nAbout using bio-inspired Evolutionary methods, Zhang\n(2020) applied a Classifier System in the context of Cog-\nnitive Robotics, building an emotional model for a robot.\nBellas, Duro, Fai\u00f1a and Souto (2010) showed us a Cognitive\nArchitecture that uses an evolutionary approach to provide\nan agent - hence a robot - with lifelong learning capabilities.\nThat Architecture, the Multilevel Darwinist Brain, was also\napplied as a control method on two physical robots, Sony\nAIBO and Pioneer 2 (Bellas, Fai\u00f1a, Prieto and Duro, 2006).\nTo the best of our knowledge, we found no prior work on\nCognitive Architectures and Evolution Strategy."}, {"title": "2. The DCT", "content": "In this section, we will briefly explain our main tool.\nThe DCT (Gibaut and Gudwin, 2020), an acronym for Dis-\ntributed Cognitive Toolkit, is a bare-bones toolkit to help the\ndevelopment of cognitive systems in a distributed, language-\nagnostic fashion. A cognitive agent created with DCT should\nbe able to run across multiple physical (desktops, small\ncomputers like Raspberries, or microcontrollers like Ar-\nduino) or virtual devices (like Docker containers). It is a re-\nimplementation of the ideas first seen in the CST main article\n(Paraense, Raizer, de Paula, Rohmer and Gudwin, 2016), as\nsome features like being inherently single-device and being\nwritten in Java may be a shortcoming, sometimes. As ex-\npected, it also follows some theory lines like being Codelet-\noriented, present in the Copycat architecture (Hofstadter and\nMitchell, 1994).\nTo better understand the DCT, one should first refer\nto the Cognitive Systems Toolkit (CST), the toolkit that\ncame before. As its name suggests, CST is a toolkit for\nthe development of cognitive architectures. Its purpose is\nto facilitate the creation of such systems the way the user\nwants, as long it respects its premises. In the core of CST\nare two basic entities that serve as building blocks: Codelets\nand Memories. A Codelet is a non-blocking, parallel process\nthat runs continuously and represents a very specific piece\nof the cognition process of biological creatures. Likewise,\na memory is a storage structure from which Codelets read\nand write information. A user may create any architecture\nthat also follows a Codelet-oriented specification, based on\nalready existing theories or new ones.\nMany Cognitive Architectures like e.g. MECA (Gudwin,\nParaense, de Paula, Fr\u00f3es, Gibaut, Castro, Figueiredo and\nRaizer, 2017), LIDA (Franklin, Madl, D'mello and Snaider,\n2014), and others may be seen as multi-agent systems.\nFollowing this paradigm, DCT conceives a distributed Cog-\nnitive System as a multi-agent system, where a standard pro-\ntocol is used for the communication among the agents. Also,"}, {"title": "2.1. The DCT Architectural Overview", "content": "From an architectural perspective, the DCT is composed\nof a set of Nodes communicating to each other and integrat-\ning, as a whole, a functional system with cognitive capabili-\nties. Theoretically, different subsets of the same collection\nof Nodes could even act as different systems. Here, the\nterm Node represents an entity (logical or physical), which\nworks as a storage for groups of Codelets and/or Memories\nand is responsible for their operation and life cycles. Figure\n1 illustrates the idea of this non-homogeneity in device\nconfigurations. The subsection 2.4 shows further details on\nthis entity.\nTo communicate with each other, Nodes follow a proto-\ncol regulating the interaction among them. Following CST\nspecifications, Codelets only interact with Memories that is,\na Codelet represents a block of computing unity, applying\nsome process on data, but not holding it. This data storage\nis performed by Memories, which can be of different tech-\nnologies. For this communication, DCT uses, canonically,\njson formatted messages. This allows the use of a good\nrange of technologies and simple sockets and databases like\nMongoDB and Redis are already supported by existing code.\nBy following these directives, a user may use any language\nor technology suitable to a device in which the Node is.\nFormally, we can conceive a Cognitive System created\nwith DCT in the following way:\nDefinition 2.1 (A DCT Cognitive System). Let N be a set\nof Nodes, where a Node is an entity (logical or physical) that\nencapsulates one or more Codelets and/or Memories meant\nto be run under the supervision of a single Node Master\nwithin an operational system.\nTo each Node, there is an Interface I = {MO, S}, where\nMO is a subset of the Memories implemented within a Node,\nwhich will be accessed from other external Nodes and S is a\nServer that listens to a URI. This server S should listen for\nrequests and respond with json formatted messages.\nA Cognitive System created with DCT is defined by\nthe interaction between the elements of N following some\nCodelet-oriented Cognitive Theory, like MECA or LIDA."}, {"title": "2.2. The DCT Codelet structure", "content": "A DCT Codelet is composed of a callable program file\nin a user-specified language that follows some guidelines\nand some configuration files that can be used to dynamically\nchange some properties, like which Memories it can access.\nFigure 2 illustrates this structure. It is valid to note that, since\nit was first implemented, some improvements have been\nmade in how a Codelet works. The files that characterize a\nCodelet are:\n\u2022 A Codelet compiled program or script, which runs\nuntil be ordered (by the Node Master) to stop\n\u2022 The Codelet configuration file (fields.json). This file\ncontains some information regarding the Codelet be-\nhavior, like its inputs, and should be possible to dy-\nnamically change it.\nAlso, if needed for a problem-specific reason, additional\nfiles may be used (a.ini file, for example). In this work,\nCodelet is implemented in Python language."}, {"title": "2.3. The DCT Memory structure and default\nsupport", "content": "The other core structure, Memory, is a generic term for\nthe data structure that holds the information that Codelets\nconsume and/or process. Also, it contains some other meta-\ninformation, e.g. its name, URL, type, and an evaluation.\nAs said before, this information is standardized as a json\nstructure.\nA Memory should contain the following information:\n\u2022 name: String\n\u2022 IP/port: String\n\u2022 type: String\n\u2022 I: String\n\u2022 eval: Double"}, {"title": "2.4. DCT Node", "content": "In the DCT, a Node is an abstraction for a physical or\nvirtual device that contains an arbitrary number of Codelets\nand/or Memories and is supervised by a single Node Master.\nThis definition allows us to consider a computer to be a\nsingle Node if all relevant entities run in the same environ-\nment, or to have multiple Nodes if each of them runs in a\nseparated container with its Node Master. This Node Master\nis responsible for starting, killing, adding, and removing\nCodelets and/or Memories, which are running through its\nsupervision. Also, it should periodically check the health\nof its system, re-executing dead processes, and listen for\nexternal requests, like information requests or even requests\nto shut itself down.\nBesides Codelets and Memories, a Node should also\nimplement an Interface in which its internal entities may\ncommunicate with outside sources, e.g. a server with open\nsockets."}, {"title": "3. An Evolutionary Cognitive Twin", "content": "Since we have already introduced some key concepts\nand the tool we're using, we can now discuss the proposed\ntechnique. Here, the main point is to build a Cognitive Twin\nusing a vast amount of simple devices, orchestrated to work\ntogether as a single system, even if each device is a system of\nits own and may, theoretically, be a part of another system.\nHere in this work, based on the definitions in section 1\nand within the scope of what will be presented, the following\ndefinition will be presented:\nA Cognitive Twin is a digital replica of the dynamics and\ncognitive - or just cognitive - processes of an intelligent\nphysical system, usually aimed at a partial representation of\na person. These cognitive processes refer to those identified\nin cognitive theories, such as perception, memory, behavior,\nadaptation, planning, learning, Reasoning etc. The classi-\nfication of an agent as Cognitive Twin refers not only to\nthe duplication of observable behavior of the virtual agent\nconcerning the original but also to the possibility of in-depth\ninvestigation of the original individual through its copy.\nThe most fundamental idea here is the Codelet, already\ndiscussed in section 2. We argue that sensors and actuators\ncan be seen as Sensory and Motor Codelets, respectively.\nTo make that consideration, we considered that both sensors\nand actuators are simple devices that do a very specific task,\nfollowing the idea of Codelet, as seen in sections 1 and 2.\nThis consideration allows us to model our desired agent as\na composition of simpler elements that interact with each\nother as needed.\nFollowing that perspective, we postulate that the connec-\ntions between sensors and actuators are given by some com-\nbination of elements that group and give them some sense,\nand elements that use that information to control actuators.\nThis lets us use the concepts of Perceptual Codelets and Be-\nhavioral Codelets, respectively, largely used in other works\nthat follow a Codelet-oriented Cognitive agency paradigm.\nAlso, these premises fit in the concepts presented in section\n1: The System is composed of devices that are themselves\nsystems connected through a network with an orchestration\nto build a Cognitive Agent that bridges virtual and physical\ndomains.\nBut we have two main constraints: first, we sought to\nuse simple, low computing power devices, and we do not"}, {"title": "3.1. Devices internal structure", "content": "First, we to define the internal structure of the devices\nwe worked on. For the sake of simplicity, we used only\nvirtual devices, as defined in section 2, running Python\nCodelets on Docker. That allowed us to better manipulate\nsome structures, like sending or requesting data from the\nmaster program to/from each Codelet and creating or de-\nstroying those virtual devices as we needed them. Even so,\nwe kept the internal structures simple to draw a parallel with\nlow-power devices.\nAs we mentioned before, we follow MECA Theory,\nwhich uses both Osman (2004) theory of two, separated\nCognition Systems working together and a Codelet-oriented\nstructure. Here we present a System 1 approach, which\nmeans that we'll be working only with four types of Codelets:\nSensory, Perceptual, Behavioral and Motor Codelets. We\nwill briefly explain each of them."}, {"title": "3.1.1. Sensory Codelets", "content": "The simplest of them all, Sensory Codelets represent\nactual sensors, either physical or virtual. Like sensors, they\nare responsible for introducing the raw data into the system.\nFor example, if we consider a human eye a sensor, the raw\ndata is the light that enters the pupils. Here, it requests infor-\nmation about a specific attribute - temperature or luminosity,\nfor example of an environment. In this work, Sensory\nCodelets' internal structures will not be changed, simulating\nvery simplistic devices, like a digital thermometer."}, {"title": "3.1.2. Perceptual Codelets", "content": "The subsequent structures in the information flow are\nPerceptual Codelets. These structures are responsible for\naggregating the raw data that comes from Sensory Codelets\nin structures called Perceptions. In our human eye example,\noutputs of Perceptual Codelets would be depth, objects,\nrelational properties (like distance from something), and so\non. Notice that Perceptual Codelets, in a sense, represent\nhow an agent experiences the world, as the information it\ncould extract from data is heavily dependent on them. In\nthis work, the internal structure of a Perceptual Codelet is\nrepresented by a Decision Tree Classifier, where the inputs\nare sensory data and the output is an integer value that\nrepresents a unique identifier (a token) of the input sensor's\nreadings. Each Perceptual Codelet differs from another by"}, {"title": "3.1.3. Behavioral Codelets", "content": "Next, we have the Behavioral Codelets. The main pur-\npose of these structures is to, based on previously structured\ninformation, activate one or more protocols to control what\nthe agent should do, that is, to control one or more Motor\nCodelets. This Activation is usually encoded in a 0 to 1\nfloat value representing a Signal Strength, a way to measure\nhow important that Behavior is to the current situation.\nNote that this so-called protocol may be anything from a\nsimple heuristic to a whole Machine Learning method and\nthe input of the Behavioral Codelet may include not only\nPerception but other information like those coming from a\nMotivational or even Emotional subsystem. Also, as a single\nMotor Codelet may have multiple Behavioral Codelets as\ninput, those behaviors effectively compete to prevail and\nhave their commands accepted.\nIn this work, the Behavioral Codelets have also a Deci-\nsion Tree Classifier as a method to decide what to send to its\nMotor Codelets based on Perception."}, {"title": "3.1.4. Motor Codelets", "content": "The last basic structure here is the Motor Codelet. As\nmentioned before, this represents a direct parallel with an\nactuator, being physical or not. It simply responds to what\nwas put as input and, through another Decision Tree, it\nsends a command to the corresponding entity in our virtual\nenvironment. This could be a direct association (\"if this then\nthat') but, to make further usage of the code easier, we used a\nmethod that could accept more than one Behavioral without\nhaving to rewrite it completely."}, {"title": "3.2. The optimization", "content": "The general process of building the architecture for our\nCognitive Twin involves determining the connection topol-\nogy between the different types of Nodes and adjusting the\ninternal functions of each Codelet to reproduce the overall\nbehavior of a primordial agent. This is a two-step offline\noptimization process, the first being an optimization of the\nconnection topology between Nodes and the second being\na conventional training process of the Codelets' internal\nMachine Learning models in each Node. The connections\nbetween the Nodes will be defined through an evolutionary\nstrategy and, given the connection configurations of each in-\ndividual of a given generation, supervised training methods\nwill be used to minimize the error between the expected and\nobtained outputs. In this work, the internal structures of the\nSensory Codelets are not changed, simulating very simplistic\ndevices, such as a digital thermometer."}, {"title": "3.2.1. Evolution Strategy details", "content": "In this part of the process, we want to, through an evolu-\ntion process, define the best configuration of the connections\nbetween Perceptual and Behavioral Codelets and Behavioral\nand Motor Codelets. The connections between Sensorial and\nPerceptual Codelets are fixed and explained in subsection\n3.1.2.\nTo apply an Evolution Strategy, we need to do some\ndefinitions. First, we need to define our Individual encoding.\nHere, our Individual is a binary vector with the length of\nthe number of total Perceptual Codelets plus the number\nof total Behavioral Codelets, where each index represents a\nspecific Codelet. In that definition, a '1' represents that the\ncorresponding Codelet is active on the Agent composition\nand a '0' means a non-connected Codelet."}, {"title": "3.2.2. The training process", "content": "To build our distributed agent correctly, we need a train-\ning process to ensure it accurately maps the system's inputs\nto the expected outputs. This training is done a) by changing\nits topology, choosing which Perceptual and Behavioral\nCodelets are composing the agent, and b) by fitting the data\nthrough all individual components consistently.\nThe main component of the optimization process is very\nstraightforward: it is a simple - yet efficient - Evolution Strat-\negy to define the agent topology. But our evaluation method requires\nmore attention. It is in this part that we try to perform an\ninput-output mapping."}, {"title": "4. Experiments", "content": "To test our model", "on\"\nor \"off\".\nAs explained before, one of the main processes in the\ntraining of our Cognitive Twin is the Evolution Strategy,\nwhere we let a set of random choices of Perceptual and\nBehavioral Codelets be part of the agent. Each Perceptual\ndiffers from the other by the sensors it collects information": "nthis may be any number between half of the available sensors\nand all of them, chosen randomly. Each Behavioral Codelet\ndiffers from others in the Motor Codelet (or Codelets) it\nfeeds.\nEach individual is defined by an array of binary values\nrepresenting the agent, so the mutation process is a \"bit-flip\"\nprobability, and we choose not to use crossing-over methods.\nThe selection method is \"best five\", meaning that we keep\nthe best five individuals in each generation. The population\nat the beginning of each generation has twenty individuals\nand the initial population was randomly generated with each\nindividual having a 20% probability of '1' in each gene,\nwhich roughly reflects as a \"mean participating number of\nCodelets\" of 20%.\nThe experiments were aimed to be relatively human-like,\neven if"}]}