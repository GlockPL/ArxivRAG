{"title": "Real-Time Integrated Dispatching and Idle Fleet Steering with Deep Reinforcement Learning for A Meal Delivery Platform", "authors": ["Jingyi Cheng", "Shadi Sharif Azadeh"], "abstract": "To achieve high service quality and profitability, meal delivery platforms like Uber Eats and Grubhub must strategically operate their fleets to ensure timely deliveries for current orders while mitigating the consequential impacts of suboptimal decisions that leads to courier understaffing in the future. This study set out to solve the real-time order dispatching and idle courier steering problems for a meal delivery platform by proposing a reinforcement learning (RL)-based strategic dual-control framework. To address the inherent sequential nature of these problems, we model both dispatching and steering as Markov Decision Processes. Trained via a deep reinforcement learning (DRL) framework, we obtain strategic policies by leveraging the explicitly predicted demands as part of the inputs. In our dual-control framework, the dispatching and steering policies are iteratively trained in an integrated manner. These forward-looking policies can be executed in real-time and provide decisions while jointly considering the impacts on local and network levels. To enhance dispatching fairness, we propose convolutional deep Q networks to construct fair courier embeddings. To simultaneously rebalance the supply and demand within the service network, we propose to utilize mean-field approximated supply-demand knowledge to reallocate idle couriers at the local level. Utilizing the policies generated by the RL-based strategic dual-control framework, we find the delivery efficiency and fairness of workload distribution among couriers have been improved, and under-supplied conditions have been alleviated within the service network. Our study sheds light on designing an RL-based framework to enable forward-looking real-time operations for meal delivery platforms and other on-demand services.", "sections": [{"title": "1 Introduction", "content": "The rapid development of information technology has changed the way we live, also the way we 'eat'. The On-Demand Meal Delivery (ODMD) service has been one of the fastest-expanding businesses in recent years. The meal delivery platforms connect customers and restaurants by enabling online order placements and providing a convenient click-to-door service to deliver freshly prepared meals from restaurants to households [1]. During the global Covid-19 pandemic, the market for meal delivery services has more than doubled in the United States [2]. With an expected annual growth rate of 6.95% from 2023 to 2027, the on-demand meal delivery has become a 222.50 billion dollar business covering more than 1 billion users around the world [3]. From the platform perspective, the interests of customers, restaurants, and couri-ers should all be taken into account to run a successful business. Despite the massive market volume and huge potential in the ODMD industry, the current meal deliv-ery business is highly cost-intensive, as described by the chief operating officer of DoorDash during an interview [4]. To establish a solid user base, platforms need to uphold high customer satisfaction, which is closely related to the quality and relia-bility of service [5, 6]. It means the customers generally have low patience for delay and they expect to receive fresh meals. Reliability relates to providing robust service to deliver the orders correctly and timely according to promise. In this context, can-celing accepted orders due to understaffing of couriers significantly damages customer satisfaction and the trust of restaurants. Operation efficiency is crucial for the prof-itability of ODMD companies. While hiring a larger fleet simplifies the courier-order matching problem, it also incurs higher costs due to employing more couriers than nec-essary. Therefore, platforms need to strategically plan deliveries and optimize courier utilization to maximize profit margins by minimizing operating costs Attention should be paid to the welfare of couriers in the operational decision pro-cess to run a sustainable and ethical ODMD business. In recent years, several courier strikes have occurred in different parts of the world [7-9], highlighting two significant concerns from the perspective of couriers. The first concern relates to 'productiv-ity over safety' due to unreasonable workload. When the system fails to respond to unexpected spikes in demand, couriers may be overwhelmed by the intensive work-load and strict performance requirements. The other concern regards the payment. Currently, most meal delivery service providers operate as gig platforms, which hire couriers as independent contractors with the commission fee per order as their major part of income. But many couriers struggle to earn a satisfying wage. Motivated by this payment scheme, gig couriers prioritize acting in the best interest of their time. It is common for gig couriers to reject orders that are not profitable to them. And they"}, {"title": null, "content": "are often overcrowded in popular restaurant areas without communication with each other. The individual decision-making of couriers can lead to service inequalities and lower operating efficiency of the platform. The intense competition among couriers also promotes risky riding. Recently, the concept of employing hourly-paid couriers has been introduced to protect the welfare of couriers [10]. However, the potential impact of this new operating scheme on delivery performance remains uncertain. Operating a successful on-demand meal delivery service is a challenging task not only because of the complex relationship between different parties but also because of its unique characteristics of operation. First of all, the couriers and orders are distributed dynamically within the service network. Restaurants are typically located in different parts of the city, which differs from other last-mile delivery problems where the pickup location is fixed at the warehouse. Platforms often keep their couriers free-flowing in the city. The other aspect to consider is the uncertain preparation time of the order. The actual preparation time often deviates from the expectation. To maintain high delivery quality and fleet efficiency, the time of arrival of the courier at the restaurant should ideally be as close as possible to the ready time of order. Additionally, since arrivals of orders are not known in advance, the dispatching operations of the current orders should be generated in real-time without perfect information about future orders. Furthermore, given the perishable property of meals and the cus-tomers' low tolerance for delay, meals are delivered the sooner, the better. Therefore, we assume the dispatching decision is made once a new order comes in, instead of waiting for the order buffer to be filled up to a specific size and then generating the decisions altogether. Although bundling is a well-working strategy in same-day pack-age delivery [11], letting a ready-to-go order wait for other similar orders for bundling does not guarantee improvement in service quality nor reduction in operational cost, as shown by [12]. Hence, couriers are assumed to carry at most one order per trip in our study. Characterized by the inherent urgency, uncertainty, and dynamic nature of order delivery tasks, as well as the complex multi-objective nature of the business, the on-demand meal delivery service is widely acknowledged as the ultimate challenge in last-mile logistics. It garners significant interest from scholars in both the fields of operations research and machine learning. Much attention has been paid to the order assignments of ODMD. Treating the order dispatching problem of ODMD as a combined variant of the classic vehicle routing problems (VRP) and traveling salesman problems (TSP), operations research (OR) methods, such as heuristic and metaheuristic approaches, are proposed to gen-erate optimal bipartite matching between orders and couriers [12-17]. However, many OR approaches are solved myopically in a rolling window manner without considering the long-term influence of decisions. Additionally, real-time execution is challenging for most OR approaches in a large system. To encounter the sequential impact of decisions as well as improve the generation speed of decisions, reinforcement learn-ing (RL)-based approaches are studied to provide real-time decisions according to the learned policy. To reduce the computation complexity, studies [18] and [19] model each courier as a decision agent. But their approaches have come across scalability issues and cannot be applied to more than ten couriers. [20] introduce a centralized RL-based"}, {"title": null, "content": "dispatching framework, which manages to solve large-scale order dispatching prob-lems using historical data collected from a platform. Nevertheless, their model hasn't incorporated the uncertainty in meal preparation times for decision-making since they assume orders are always ready to be picked up upon arrival of the couriers. Steering strategies for supply-demand rebalancing aims to proactively match the number of available couriers to the pickup requests from restaurants in the future. While proactive demand steering operations typically relate to dynamic pricing strat-egy and order rejections, supply steering operations often include the reallocation of idle couriers to the under-supplied area. From the demand steering side, RL-based strategies involving order rejections have been widely discussed in the literature on on-demand meal delivery [18, 19], as well as other dynamic pickup and delivery services [21, 22]. On the other hand, little attention has been paid to real-time supply steer-ing operations for ODMD, such as idle fleet steering. Splitting the city into several large regions, [23] introduce an RL-based framework to dynamically reallocate couri-ers across regions. Utilizing demand anticipation, [17] introduce an OR optimization framework that dynamically and simultaneously steers the demand and fleet. The pos-sibility of reallocating idle couriers at the micro-level (i.e., from one grid to another) has not been much explored yet in the field of ODMD. In addition, the learning-based framework for order dispatching and steering operations has not been jointly studied in the previous literature of ODMD. The goal of this research is to design an efficient reinforcement learning (RL)-based strategic dual-control framework that leverages predicted short-term demand informa-tion to generate both optimal order dispatching and idle courier steering policies for an on-demand meal delivery platform (ODMD). Particularly, for this multi-objective on-demand delivery system, we wonder whether the policies learned by our framework can improve the system-level delivery efficiency, ease the under-supplied condition within the service network, and improve the fairness of workload distribution among couriers. We are also curious whether the use of explicitly predicted demand to con-struct forward-looking policies leads to an improvement in performance. We assume the operational decisions are generated from the platform perspective since we are most interested in whether the meal delivery platform can be a self-organized system. The main novelties of our study arise from the following aspects. In order to upscale the limited dataset for the data-intensive training of RL algorithms, we bootstrap the data by creating an order sampler implemented by the parameters estimated from the data. For short-term demand forecasting, a lagged-dependent XGBoost regression model is applied to generate adaptive predictions of demand within the network in real time. Then the predicted demand information is applied to the dual-control frame-work to assist strategic decision-making of the system. Making use of a multi-objective reward function, the order dispatching obtained from our RL-based framework aims to balance the delivery performance at both current order and system level. Moreover, our model allows postponing as a possible decision, in case the platform believes a more suitable courier will show up in the near future. To prevent algorithmic biases, we propose Convolutional Deep Q Network (Conv-DQN) as the value function approx-imator to create fair feature embeddings of couriers through the convolutional filter. To enable decentralized executions while reserving optimally at the network level,"}, {"title": null, "content": "our trained idle courier reallocation policy generates local reallocation decisions by using the mean-field approximated supply-demand balancing information of the local neighborhoods. Within this framework, a sequential decision framework is designed to maintain the supply and demand balance within the service network by coordi-nating the passive and active rebalancing decisions from the order dispatching and fleet steering decisions. We also introduce the 'sandwich learning strategy' to jointly train the order dispatching and fleet steering policies in an iterative manner within our simulated system. The remainder of this paper is structured as follows. We review the relevant recent literature in Section 2. Then, we describe the on-demand meal delivery system by providing the basic definitions and assumptions in Section 3. The structure of our strategic dual-control framework is explained in Section 4, where we introduce the short-term demand prediction model and the design of the RL-based order dispatching and idle courier reallocation methods. Next, Section 5 elaborates on the dataset, policy training strategy, and performance evaluation scheme utilized in our experiments. The results of our study are presented in Section 6, followed by our discussion in Section 7. Lastly, we summarize our study, reflect on the limitations of this research, and provide suggestions for future research in Section 8."}, {"title": "2 Literature Review", "content": "With the development of technologies, on-demand services have revolutionized the business by offering their users great flexibility in accessing the service anytime they want without the need for prior scheduling. However, along with the benefits, the emer-gence of on-demand services has also introduced new challenges. On-demand service providers are required to generate decisions in real-time while optimizing the network-level performance with the presence of uncertainty and dynamic arrivals of requests in the system. The operational challenges of on-demand meal delivery, along with sim-ilar on-demand services like ride-hailing and instant parcel pickup and delivery, can be categorised as subproblems within the broader field of dynamic pickup and deliv-ery problems (DPDP). In this section, we review the recent studies on ODMD and its closely related problems on the topics of order dispatching and supply steering, with an emphasis in the discussion of incorporation of forward-looking information, consideration of dynamic and stochasticity from the environment, the scalability and real-timeness of solutions."}, {"title": "2.1 Predict-then-Optimize", "content": "Demand forecasting has been adopted as the first step in many studies to provide anticipatory insights to enhance the operations of a dynamic system. This sequential method is also known as the 'predict-then-optimize' approach, where the parameter for forecasting is firstly estimated to minimize prediction errors, then the predictors are implemented sequentially in the downstream optimization model. [24] introduce demand-aware route planning for shared mobility service to improve overall efficiency by considering the spatial distribution of future demand and estimate the likelihood of getting new orders on the route. In order to rebalance the supply and demand in the"}, {"title": null, "content": "service network, [25] introduces a vehicle relocation algorithm, where the predicted demand distribution is considered for strategic fleet steering. For the optimization of order dispatching decisions, [26] propose DeepPool to utilize the predicted demand spatial distribution for a ride-sharing platform. Among the literature for on-demand delivery, machine learning approaches have been frequently considered for the task of short-term demand forecasting. [27] employ and compare different forecasting models to predict spatial-temporal demand at aggre-gated time intervals of 10 minutes for a ride-hailing platform. In their study, the non-parametric machine learning method gradient boosted trees obtains the highest prediction quality among other models. In order to predict the per 15-minute demand for taxi service in New York City, [28] propose a data-driven approach named boosting Gaussian conditional random field (boosting-GCRF) to provide both robust determin-istic and probabilistic predictions. Research that is dedicated to demand forecasting to on-demand meal delivery is still sparse in the literature. Using empirical data from a meal delivery platform, [29] evaluate the hourly aggregate demand predictions gen-erated by both classic univariate and machine learning predictors. And they conclude that the prediction accuracy of random forest based approaches is higher when only limited data (4-6 weeks) is available."}, {"title": "2.2 Order Dispatching", "content": "The order dispatching problems of the on-demand meal delivery service system are about assigning the orders to the couriers. Various studies have been conducted to investigate the order dispatching problems using OR-based methods. [12] simplify the dispatching task by assuming the perfect order information is known in advance and solving it with a Clairvoyant decision maker. Under the static-deterministic assump-tion, they find evidence that order bundling can neither improve delivery performance nor reduce operational costs. Assuming no autonomous decisions from the couriers, [13] propose a bi-objective algorithm to match couriers and orders optimally within each fixed length time window. By relaxing the deterministic assumption of the sys-tem, this study finds that the click-to-door time and meal ready to delivered time only increase mildly if the ready time of orders are uncertain. It is worth noting that the order density of their experiments is rather low. A higher demand level may lead to different conclusions. [14] investigate the virtual food court delivery problem where an order from the same customer may contain items from multiple restaurants. They introduce a proactive auction-based heuristic that utilizes anticipation of the system's future state to provide dispatching decisions, which is solved with a mixed-integer lin-ear programming method. Next to the operational cost and delivery quality, fairness and other factors have also been included as part of the multi-objective function for dis-patching problems. [16] emphasize long-term fairness among couriers' income as part of the objective in dispatching decisions. [15] aim to optimize the order dispatching and routing decisions by maximizing customer satisfaction and fair workload distribution among couriers, as well as minimizing the total carbon emissions for delivery. [30] introduce an Approximate Dynamic Programming (ADP)-based method to generate optimal routing and order assignment policies for a meal delivery system under the assumptions of stochastic arrivals and uncertain ready times of orders."}, {"title": null, "content": "Modeling each courier in the system as a decision agent, [18] introduce an RL-based framework to train a uniform policy. In their simulated environment, orders arrive dynamically to the platform but with exact preparation times. Positive reward is given when an order is delivered within deadline, while late delivery and order rejection grant penalty. Travelling cost only counts for relocation. In terms of computational perfor-mance, their results only limit to at most 7 couriers with low demand assumptions that might not be applicable to large cities. [19] propose an RL-based approach that models each courier as a decision agent to generate their own routing and assignment decisions. By default, a new order is firstly offered to the available courier nearest to the pickup point. They define a scenario specified reward function such that a large penalty is given if an invalid action is taken. In their results, DDQN achieves higher total rewards. However, they reported at max 3 couriers can be included in experi-ments due to the scalability issue of their framework. Modeling the delivery routing and order bunching problems as large but finite MDPs, [20] introduce a centralized dispatching framework that applies DDQN where the platform dispatches each new order to couriers. The state vector contains the restaurant address of the related order and full information about each courier's current route. After the dispatching decision is generated, a DP-based model is utilized as the second step to update the related courier's route. A fixed reward is granted to every on-time delivery, while a fixed penalty for each late delivery. The proposed two-stage approach can effectively manage a large number of couriers within a vast city network. Furthermore, the computation time has shown to be much faster compared to a pure routing planning algorithm in OR. However, the meal preparation time is omitted in their design of simulations. And orders are assumed to be always ready upon the arrival of couriers, which might not be the case in practice."}, {"title": "2.3 Supply Steering", "content": "Fleet steering problems involve efficiently repositioning resources to address current open requests and proactively meeting upcoming orders based on anticipated future demand distributions. For operational convenience, it is a common practice to rep-resent the map using a grid system, interpreting reposition decisions as movements between grids [31]. Centralized reallocation decision-making has been studied with OR researchers. The real-time fleet steering problem for ODMD has been studied by [17] with a deterministic clairvoyant model with static order information and a forward-looking probabilistic model incorporating the predictive demand insights and anticipation of uncertainty. The decisions are generated for the whole fleet at each decision point. Within the field of RL, most studies have investigated the possibility of decentral-ized reallocation via generating local decisions from a multi-agent RL framework to match supply and demand distribution. Among the literature that adopt multi-agent RL, many studies model each driver or rider as a decision agent [32-34]. To improve system-level coordination, the agent's reward function often needs to be carefully designed to encourage coordination and avoid agents overcrowding at the high-demand areas and motivate relocation to under-supplied areas. For the vehicle steering prob-lem for a ride-sharing system, [32] propose to split rewards among all the driver agents"}, {"title": null, "content": "in the same grid to prevent overcrowding. Dealing with the taxi supply and demand balancing problem, [34] assign a fixed positive reward to all drivers if the group of relo-cation actions leads to a supply-demand balance, otherwise assign a minor negative reward to everyone. Aiming to solve the cross-regional courier displacement problems to balance supply and demand for ODMD, [23] propose a courier displacement frame-work that provides regional reallocation instruction to couriers. In this multi-agent RL approach, the couriers act individually as homogeneous decision agents that follow the same centralized contextual policy. The relocation action space is limited to the adjacent regions of the courier's current region. Each courier's state input contains the shared global state information about the spatial distributions of idle couriers, couriers in service, open orders, and time, as well as the local information about the courier's current grid ID and serving time. At each time step, a reward is received by each courier, which is defined to be the order response expected ratio obtained by the number of responded orders divided by the number of couriers within the same region."}, {"title": "2.4 Research Gap and Our Contributions", "content": "Realistic assumptions and model designs are crucial to generate solutions with good practical values. The unique stochastic, dynamic, and multi-objective properties, as well as the real-time and forward-looking decision-making requirements make the ODMD operational problems complicated and challenging. Therefore, the solutions proposed for other on-demand applications, such as ride-hailing, cannot be directly applied to ODMD. In the practice of ODMD, the ready time of meal is stochastic, unlike the cases where passengers or parcels are ready for pickup at a predetermined location. Thus, the order dispatching problem of ODMD needs to decide the optimal timing to send the courier over to avoid wasting the driver's time on waiting while preventing any negative impact on performance due to late arrivals of courier. In order to operate under the pressure of high request frequency and strict delivery deadlines, many platforms opt to perform 'instant delivery' where normally only one order is carried per trip [35, 36]. On the other hand, previous literature concentrates on the order batching strategy by studying ODMD as a variant of dynamic pickup and delivery problem with multiple orders per trip. To fill up these gaps from previous research, we assume the orders to arrival dynamically with stochastic ready time and each courier can carry at most one order at the same time. Scalability still remains an issue in the order dispatching policy training of [18] and [19]. Both studies model couriers as the decentralized decision agents in their multi-agent RL frameworks. In our study, the convergence of training is sped up by our proposed convolutional DDQN (Conv-DDQN) algorithm, where fair embeddings of couriers are first created to reduce the information dimension. Additionally, the state vector in our approach is more concise compared to those from previous studies. Making use of the predicted demand in the near future, the multi-objective reward function for order dispatching jointly considers the future supply and demand distri-bution, the sunk cost of the courier's waiting time at the restaurant, and the delivery efficiency of the current order altogether. By reactively rebalancing supply and demand"}, {"title": null, "content": "while reserving delivery efficiency, the dispatching decisions can achieve system-level coordination without direct communication between orders. Although fleet steering problems have been extensively studied for taxis and ride-hailing systems, little attention has been paid to real-time steering for meal delivery couriers. Previous research that applies RL for meal delivery problems often model couriers as decision agents who relocate themselves under the motivation of personal incomes [18, 19, 24]. It has not been explored that whether the platform can provide reallocation instruction to its couriers to directly rebalance the supply and demand within the service network. In this study, we study a real-time idle courier reallocation policy that aims to resolve the spatial supply and demand distribution mismatches. To date, the discussion about designing a 'predict-then-optimize' framework with RL-based techniques for ODMD operation problems is still sparse in the literature. Therefore, our study aims to fill the gap by investigating the potential advantages of leveraging demand predictions to develop strategic order dispatching and idle fleet steering policies. We compare their performance against that of myopic policies, which are trained without anticipatory demand information. For performance evaluation, existing literature on meal delivery planning problems adopts the average order response rate and rate of before-deadline delivery as the pri-mary performance measures for service quality. However, few studies have analyzed operation performance measures, such as courier utilization efficiency and potential assignment bias among couriers. In this study, we propose additional metrics to com-prehensively evaluate the balance between supply and demand in the network, pickup distances from couriers to restaurants, and the fairness reflected in the workload distribution among couriers."}, {"title": "3 Problem Description", "content": "In this section, we provide an overview of the on-demand meal delivery platform. To begin with, we describe how an on-demand meal delivery platform connects different parties during the delivery process in Section 3.1. Then, we explain the fundamental concepts of a meal delivery system and introduce the modeling assumptions we have made in this study."}, {"title": "3.1 On-Demand Meal Delivery System", "content": "From placement to delivery, the process of order involves four parties: the platform, restaurant, courier, and customer. When a new order is placed by the customer on the platform, it notifies the platform of the order details. Next, the order is forwarded to the associate restaurant, which sends a confirmation back to the platform, providing an expected meal preparation time. While the meal is being prepared in the restaurant's kitchen, the platform is responsible for assigning the order to a working courier in the service area. The process of order and courier matching is known as order dispatching. Following the platform's dispatching instructions, the courier heads to the restaurant to pick up the meal when he/she is available. The courier collects the order and heads out to the customer if the meal has been prepared. Otherwise, the courier should wait until the meal is ready for delivery. The delivery is completed when the order"}, {"title": null, "content": "is handed to the customer at the doorstep. After completing all assigned tasks, we assume the couriers to remain idle at the destination area of their last active task, awaiting further instruction from the platform. To enhance delivery efficiency, the platform proactively reallocates idle couriers towards the area where (is expected to) require more couriers for order pick-up. Throughout operations, the platform collects information on the spatial distribution of idle couriers and anticipates the demand distribution in the city. To rebalance the future supply-demand spatial distribution, the platform sends reallocation instructions to couriers who have been idle for some time. The decision-making process for empty fleet reallocations is often referred to as idle courier steering."}, {"title": "3.2 Grids, Distances and Travelling Speed", "content": "To protect user privacy, the original addresses are hashed into hexagonal grids accord-ing to Uber's H3 spatial indexing system at resolution level 8 in our empirical dataset [37]. Each hexagonal grid on the map is sized identically, covering an area of 0.74 km\u00b2 with an edge length of about 0.53 km. Hence, the distance is around 0.92 km to travel"}, {"title": null, "content": "from the center of a grid to the center of its adjacent grid. We assume the biking speed of couriers to be about 16-17 km/h on E-bikes. Due to the unavailability of specific addresses, we are unable to provide detailed route planning between locations. To simplify the problem, we assume the traveling time to be constant between a given pair of grids, irrespective of the specific loca-tions within those grids. Also, we define the travel distance between the centers of adjacent grids to be one unit, and the travel time speed of couriers to be 3 minutes per unit of distance. The travel distance is determined based on the number of grid layers between the grids. As illustrated by the example in Figure 2a, the travel dis-tances are determined as follows: it takes zero units of distance to travel within the same grid, one unit to adjacent grids on the first surrounding layer, and two units to the grids at the next layer, and so on. A network can be created by connecting the hexagonal grid centers in a service region. Based on our assumptions, this network forms a triangulated structure with equal-length edges, making it easy to determine the shortest routes between grids. In Figure 2b, we present several examples of short-est paths between grids. It's important to note that there exist multiple alternative shortest paths for travelling between non-adjacent grids in the network."}, {"title": "3.3 Couriers", "content": "In this research, the couriers are assumed to be employed by shifts. They are paid on an hourly basis with a small amount of commission fee for each delivery or reallocation task they perform. But the hourly payment serves as the primary source of income for the couriers. For the same shift, we assume the fleet is planned ahead with a"}, {"title": null, "content": "fixed number of couriers. During a shift, the scheduled couriers stay active for task assignments. They cannot sign in late to work or sign out early from work as they wish. Based on the task being executed, a courier can have one of the five different statuses. If the courier is not currently assigned to any tasks, the courier is idle. Oth-erwise, he/she is busy. During a delivery task, the courier's status will be 'on the way to pick up' if they are en route to the restaurant, 'waiting at the restaurant' if they have arrived but the meal is not yet prepared, and 'on the way to delivery' if they have collected the order and are heading to the customer. When the courier is reallo-cated to an adjacent grid, the status will be \u2018reallocating'. Additionally, each courier maintains an individual queue of his/her on-going tasks. We restrict the couriers from holding more than two delivery tasks simultaneously. It implies that a courier who is already busy with delivery may be assigned at most one additional order. However, couriers who are currently reallocating can be assigned two delivery tasks. Moreover, the reallocation task can only be assigned to couriers who have been idle for more than five minutes. In our experiment, we consider a fleet of 25 active couriers for the two-hour shift we simulate. At the start of the shift, the couriers are idle, indicating they have no ongoing tasks or preassigned deliveries. Also, their initial locations are randomly chosen from the grids within the sample service region."}, {"title": "3.4 Orders and Order Sampler", "content": "Orders are received dynamically in the system, which means that the platforms do not possess perfect future knowledge to schedule trips in advance. Additionally, the preparation time for meals is often uncertain, especially during busy dinner hours when the kitchen is catering to both in-house customers and delivery orders. Having observed that the demand level varies among different restaurant-household grids in Section 5.1, we decide to sample the dynamic arrivals of orders for each restaurant-household grid $g_r \\in G_r$ independently, following an inhomogeneous Poisson process with time-dependent arrival rates of orders $\\lambda_{g_r}(t)$. And we estimate the hourly order arrival rates $A_{g_r}(h)$ of restaurant-household grid $g_r$ by the average number of orders received during hour $h, h \\in \\{19, 20\\}$ from historical data. The simulation time step of this study is set to be 1 minute. Therefore, the expected total number of orders sampled per minute at hour $h$ is $\\sum_{g_r \\in G} \\frac{A_{g_r}(h)}{60}$. Given the restaurant grid of an order is $g_r$, the household grid $g_h$ of this order is cho-sen randomly based on the pairwise origin-destination probabilities $P(g^r, g^h), g^h \\in G_h$. These probabilities are the estimated likelihoods from the historical transaction data for an order to be picked up from $g^r$ and delivered to $g^h$. Hence, these pairwise prob-abilities fulfil the relation $\\sum_{g_h \\in G_h} P(g^r, g^h) = 1$. The estimated preparation duration $\\hat{\\tau}_o$ (measured in minutes) of order $o$ is randomly sampled from a normal distribu-tion with a mean of 10 minutes and a variance of 2: $\\hat{\\tau}_o \\sim N(\\mu = 10, \\sigma^2 = 2)$. The estimated preparation time is shared by the restaurant with the platform upon con-firmation of the new order, which is available for decision-making. Additionally, we sample the actual preparation duration $\\tau_o$ of order $o$ as the estimated preparation time with a small deviation factor drawn from a standard normal distribution: $\\tau_o = \\hat{\\tau}_o + \\epsilon$, where $\\epsilon \\sim N(\\mu = 0, \\sigma^2 = 1)$."}, {"title": "4 RL-based Strategic Dual-Control Framework", "content": "In this section, we propose the reinforcement learning-based dual-control framework with both strategic order dispatching and idle courier reallocation implemented. In Section 4.1, we introduce the short-term demand forecasting method which provides the anticipated demand distribution that we later use to generate strategic insights into the service network. Then, we formulate the order dispatching problem and illus-trate our design of an RL-based model for dispatching decision-making in Section 4.2, followed by our problem formulation and model description for idle courier realloca-tion in Section 4.3. Lastly, we explain how the dispatching and steering decisions are made sequentially in our dual-control framework in Section 4.4. In Appendix.B, we first provide a recap of reinforcement learning techniques. Then, we describe the Dou-ble Deep Q Networks (DDQN) algorithm and related hyperparameters we utilize for dispatching and reallocation models."}, {"title": "4.1 Short-Term Demand Prediction with XGBoost", "content": "By integrating short-term predictive insights into the system, the platform can gen-erate proactive decisions in real-time. Recognizing the dynamic demand patterns of the meal delivery system and the need for real-time decision-making, we employ an adaptive forecasting method that enables fast-generating demand predictions for the service network. To ensure operational flexibility and minimize noises in prediction, we have opted for a short-term prediction window of 15 minutes. In the field of forecasting, the classic parametric time series models, such as exponential smoothing and Autoregressive Integrated Moving Average (ARIMA), are univariate models, where only the historical values of the target variable are used as input features. They are good at interpreting the univariate sequential relations between the previous values and the target of prediction. And the predictions are adaptive to the recent changes in the dynamics of demand. However, these forecasting models require expertise and manual efforts to select a proper formulation. Neverthe-less, the forecasting is limited to the recent observations of demand as input, which makes the identification of patterns implicit and potentially challenging. Temporal features like the day of the week and the hour of the day can be used to describe the pattern of demand. Known for the capability of capturing the non-linear rela-tions between features and the target variables to predict demand patterns, machine learning (ML) techniques such as random forest regression start to gain popular-ity in short-term demand predictions. Classic time series forecasting methods often require professional knowledge in selecting the components before parameter estima-tion. Although this manual selection is not required in ML methods, ML predictors normally require a sufficient amount of data to uncover the demand patterns. Joining the strengths of both approaches, we employ the lagged-dependent eXtreme Gradient Boosting (LD-XGBoost) as our short-term demand forecasting algorithm to predict the number of orders expected in the next 15 minutes for each grid with restaurants in the service network. Introduced by [38], XGBoost is an advanced non-parametric ensemble method in machine learning, derived from random forest. It excels"}, {"title": "4.2 Strategic Order Dispatching", "content": "The sequential decision-making of the order dispatching problem for ODMD can be formulated as a Markov Decision Process (MDP), since the next dispatching decision inline for the following order can be considered only related"}]}