{"title": "A Context-Enhanced Framework for Sequential Graph Reasoning", "authors": ["Shuo Shi", "Chao Peng", "Chenyang Xu", "Zhengfeng Yang"], "abstract": "The paper studies sequential reasoning over graph-structured data, which stands as a fundamental task in various trending fields like automated math problem solving and neural graph algorithm learning, attracting a lot of research interest. Simultaneously managing both sequential and graph-structured information in such tasks presents a notable challenge. Over recent years, many neural architectures in the literature have emerged to tackle the issue. In this work, we generalize the existing architectures and propose a context-enhanced framework. The crucial innovation is that the reasoning of each step does not only rely on the outcome of the preceding step but also leverages the aggregation of information from more historical outcomes. The idea stems from our observation that in sequential graph reasoning, each step's outcome has a much stronger inner connection with each other compared to traditional seq-to-seq tasks. We show that the framework can effectively integrate with the existing methods, enhancing their reasoning abilities. Empirical evaluations are conducted on the challenging CLRS Reasoning Benchmark, and the results demonstrate that the proposed framework significantly improves the performance of existing architectures, yielding state-of-the-art results across the majority of the datasets within the benchmark.", "sections": [{"title": "Introduction", "content": "Recent years have witnessed a steady growth in exploring the reasoning capacity of deep learning [He et al., 2023; Jiang et al., 2022; de Rezende et al., 2021]. This research domain holds profound significance in the field of artificial intelligence it enables AI not only to recognize patterns but also to deduce new knowledge from existing information, thereby broadening the capacity for complex problem-solving. As a variety of reasoning tasks can be formulated into graph problems, there is an increasing focus and attention on deep graph reasoning [Wang et al., 2023; Ling et al., 2022; Zhu, 2022]. This trend delves into the study of graph-structured data and aims to build specialized network structures that can learn to reason over them.\nIn this paper, we consider sequential graph reasoning, one of the most challenging tasks in deep graph reasoning. Diverging from conventional reasoning tasks like graph (node) classification [Wu et al., 2019], this type of task goes beyond the one-shot model and targets step-by-step reasoning over graphs. The applications of seq-graph reasoning span across various domains in artificial intelligence. For instance, in AI-powered math problem solving [Lample and Charton, 2020; Huang et al., 2022; Drori et al., 2020], neural networks are expected to provide the entire process of solving a mathematical problem, rather than a mere final answer. Another emerging application is neural algorithm learning [Diao and Loynd, 2023; Ibarz et al., 2022; Jain et al., 2023], where networks are anticipated to sequentially imitate individual steps of classical graph algorithms.\nThere have been many recent advances in seq-graph reasoning [Li et al., 2023; Zhao et al., 2024; Gerasimova et al., 2023]. While the proposed neural architectures exhibit diversity, they generally adhere to a common sequential paradigm. In the framework, graph-structured hidden states are maintained in memory. At each step, the outcome of the preceding step serves as input, integrating with the hidden states for reasoning. Variations among existing works arise in the specifics of their integration processes. Numerous graph networks (e.g. GAT [Velickovic et al., 2018] and MPNN [Gilmer et al., 2017]) that excel at one-shot reasoning have been investigated.\nThe current paradigm is essentially a direct combination of the techniques for processing serialized data and those for handling graph-structured data. We notice that such a straightforward combination may fall short of yielding competitive reasoning capabilities due to the distinctive nature of seq-graph reasoning. Compared to traditional seq-to-seq tasks [Yu, 2017], each step's outcome in seq-graph reasoning has a much stronger intrinsic connection with the others. For example, in automatic geometric problem solving [Schreck and Mathis, 2016], the outcome sequence forms an entire problem-solving process, which can even be represented by an extra reasoning graph. However, most existing works fail to capture these intrinsic connections."}, {"title": "1.1 Our Contributions", "content": "Motivated by the observation above, this paper proposes a framework to capture the contextual patterns of step out-comes in seq-graph reasoning. To evaluate the reasoning ability of this framework, we conduct empirical evaluations on the challenging CLRS Reasoning Benchmark [Velickovic et al., 2022]. This benchmark consists of 30 different algorithmic tasks for probing the reasoning capabilities of graph-structured networks. The contributions of the paper are summarized as follows:\n\u2022 We introduce a Context-Enhanced Framework (CEF) for seq-graph reasoning. The framework extends the existing paradigm and exhibits notable flexibility, allowing for adjustments based on available memory space during implementation.\n\u2022 We show that the framework can effectively integrate with various existing architectures. Specifically, the paper categorizes existing methods into two types: GNN-based and Transformer-based, and provides detailed CEF implementations for both.\n\u2022 We perform a diverse range of experiments on the CLRS benchmark. The results demonstrate that, for both types of existing architectures, our framework significantly enhances their performances across the majority of the datasets within the benchmark. When integrated with the latest architectures, we achieve new state-of-the-art results."}, {"title": "1.2 Related Work", "content": "Graph Neural Networks. Graph neural networks have emerged as a powerful tool for effectively capturing and leveraging the structural relationships present in graph-structured data. Numerous neural architectures have been proposed in this domain, such as Graph Convolution Networks (GCN) [Kipf and Welling, 2017], Graph Attention Networks (GAT) [Velickovic et al., 2018], Message Passing Neural Networks (MPNNs) [Gilmer et al., 2017] and so on. These architectures excel not only in one-shot graph reasoning [Ma et al., 2023] but also demonstrate comparable performance in seq-graph reasoning tasks [Ramesh et al., 2023]. Recently, [Ibarz et al., 2022] introduced a novel GNN architecture called triplet-GMPNN. They augment the classical MPNN to perform message passing toward edges and have achieved remarkable results in neural algorithmic reasoning.\nGraph Transformers. Transformers and its variants play a crucial role in domains such as natural language processing, computer vision, and time series analysis [Vaswani et al., 2017]. Consequently, leveraging Transformers for tasks related to graph reasoning has emerged as a recent research focus, leading to the development of several variants of Transformers tailored for handling graph-structured data [Wu et al., 2021; Hussain et al., 2022]. A recent advancement in this direction is proposed by [Diao and Loynd, 2023]. They introduced Relational Transformers, which enhance attention computation by aggregating edge and graph feature information with node features."}, {"title": "Beyond One-Shot Graph Reasoning", "content": "The architectures mentioned above are fundamentally tailored for one-shot reasoning. When addressing seq-graph reasoning tasks, they necessitate the paradigm stated in the introduction. There have been some recent advances in exploring competitive paradigms for seq-graph reasoning [Numeroso et al., 2023; Jain et al., 2023; J\u00fcr\u00df et al., 2023]. Notably, the studies most closely related to our research were recently introduced by [Jain et al., 2023] and [J\u00fcr\u00df et al., 2023], where the GNN architectures are augmented with a priority queue and a stack, respectively."}, {"title": "1.3 Paper Organization", "content": "The paper is organized as follows. Section 2 provides preliminaries, including a problem definition and a paradigm widely used in the literature. In Section 3, we introduce our framework, and subsequently, Section 4 details the concrete implementations of our framework for different types of existing approaches. Empirical evaluations are presented in Section 5. Finally, Section 6 concludes the paper."}, {"title": "Preliminaries", "content": "The section formalizes the problem setup and introduces a widely-used paradigm. In a seq-graph reasoning task, we are given graph-structured data and required to perform reasoning over it at most T times. The given data is represented by a graph G = (V, E) with n nodes and m edges, where each node v \u2208 V has feature $x_v^{(0)}$ and each edge e \u2208 E has feature $x_e^{(0)}$. For the notational simplicity, define $X_V^{(0)} := {x_v^{(0)}}_{v\\in V}, X_E^{(0)} := {x_e^{(0)}}_{e\\in E}$, and $X^{(0)} = {X_V^{(0)}, X_E^{(0)}}$. Further, for each training data, we are provided with the ground truth $Y^{(t)}$ of each reasoning step $t \\in [T]$.\nA widely used paradigm in the literature is the encode-process-decode paradigm [Ibarz et al., 2022]. In this paradigm, there are three modules: encoder E, processor P, and decoder D. In each step $t \\in [T]$, the input tensors $X^{(t-1)}$ undergo three successive transformations E, P,D and then yield $X^{(t)}$, which serves as the input for the next step.\nEncoder Module. There are usually two encoder networks in this module, each tasked with encoding node features and edge features respectively. Thus, after feeding $X^{(t-1)}$ to the encoder module, we obtain latent features $L^{(t)}$ for nodes and edges in the graph:\n$L_V^{(t)}, L_E^{(t)} = E(X^{(t-1)})$.\nProcessor Module. This module is the central component of the entire paradigm, where most prior works primarily vary. It consists of a (standard) graph-structured network (e.g., graph neural networks or graph transformers), and maintains a hidden state for each node and edge. Denote by $H_V^{(t-1)}$, $H_E^{(t-1)}$ the hidden states of the node set and the edge"}, {"title": "3 CEF: A Context-Enhanced Framework", "content": "The section presents a framework that generalizes the standard encode-process-decode paradigm. Before stating the details, let us give some intuition first. Compared to the traditional seq-to-seq tasks, we observe that the ground truths in seq-graph reasoning have a much stronger inner connection with each other. For example, in neural graph algorithm learning, the goal is to imitate the execution of a classical graph algorithm like Prim's algorithm [Prim, 1957]. In this scenario, each $Y^{(t)}$ corresponds to an individual step of Prim's algorithm, and the entire ground truth sequence represents the process of solving the minimum spanning tree problem by Prim's algorithm, which is an optimization problem-solving procedure. Thus, similar to the consideration of momentum in historical gradients during gradient descent, in seq-graph reasoning, momentum concerning the outcome at each step should also be introduced and taken into account. This observation motivates our framework.\nThe framework builds upon the encode-process-decode paradigm and newly introduces a Preprocessor module between the encoder and processor. See Figure 1 for an illustration. This module is designed to capture dependencies and patterns on the latent feature sequence < $L^{(1)}, L^{(2)}, ..., L^{(t)}, ... $> , which are also referred to as \u201ccontext\u201d information. Hence, we term the new framework a Context-Enhanced Framework (CEF). More precisely, the module maintains a context state for each node and edge, storing the information aggregated from historical latent features. For each node v (resp. edge e), denote by $c_v^{(t)}$ (resp. $c_e^{(t)}$) the context state at the beginning of step t. Note that $c_v^{(t)}$ can be a direct concatenation of historical latent features or the outcome of applying some dimensionality reduction techniques (e.g. gating mechanisms) to them. For simplicity, $C^{(t-1)}$, $C_V^{(t-1)}$ and $C_E^{(t-1)}$ are defined similarly.\nThe module involves two pivotal operations: context enhance function $f_{enhance}$ and context update function $f_{update}$. The application of $f_{enhance}$ aims to augment latent features with contextual information, subsequently serving as input to the processor module:\n$S^{(t)} = f_{enhance} (L^{(t)}, C^{(t)})$.\nConcurrently, $f_{update}$ is employed to update the context state"}, {"title": "4 Applications", "content": "As outlined in Section 1.2, existing (processor) architectures fall within two categories: GNN-based and Transformer-based. This section considers both processor types and presents specific implementations of the framework for each."}, {"title": "4.1 Integration with GNN-based Processors", "content": "This subsection considers GNN-based processors. We follow the literature [Ibarz et al., 2022] and formulate this type of processor into the model below. Note that the existing GNN-based processors only maintain hidden states for nodes. In each step $t \\in [T]$,\n$\\forall v \\in V : z_v^{(t)} = s_v^{(t)} || h_v^{(t-1)}$\n$r_v^{(t)} = f_1 (z_v^{(t)})$\n$m_v^{(t)} = \\bigoplus_{u:(u,v) \\in E} f_2(r_v^{(t)}, r_u^{(t)}, s_v^{(t)})$\n$h_v^{(t)} = f_3 (r_v^{(t)}, m_v^{(t)})$.\nVarious processors may utilize distinct $f_1, f_2, f_3$ and aggregation function $\\bigoplus$. Since only node hidden states are preserved and computed in such processors, we also focus on the transformation of node latent features in the preprocessor module and let $s_e^{(t)} = l_e^{(t)}$ directly for each edge $e \\in E. We introduce a novel gating mechanism to preprocess each node latent feature. Further, the weight sharing technique [Garland and Gregg, 2018] is employed to make the module more memory-efficient and reduce the risk of overfitting. We implement the preprocessor as follows:\n$\\forall v \\in V : v_v = ReLU (tanh (f_{linear} (c_v^{(t)})))$\n$s_v^{(t)} = c_v^{(t+1)} = a_v \\cdot c_v^{(t)} + (1 - a_v) \\cdot l_v^{(t)}$"}, {"title": "4.2 Integration with Transformer-based Processors", "content": "This subsection considers Transformer-based processors. They maintain hidden states for both nodes and edges. We propose a model below to capture the common structures of such processors. Use N(v) := {u|(v, u) \u2208 E} to denote the neighbors of v. In each step $t \\in [T]$,\n$\\forall v \\in V :$\n$q_v = f_{query} (z_v^{(t)}, {l_v^{(0)}}_{v\\in (v)})$\n$K_v = f_{key} ({z_u^{(t)}, {l_u^{(0)}}}_{u\\in N(v)} \\cup {z_v^{(t)}, {l_v^{(0)}}})$\n$\\theta_v = f_{value} ({s_u^{(t)}, {l_u^{(0)}}_{u\\in N(v)} \\cup {s_v^{(t)}, {l_v^{(0)}}})$\n$h_v^{(t)} = f_{node} (z_v^{(t)}, q_v, K_v, \\theta_v)$\n$\\forall (u, v) \\in E :$\n$h_{(u,v)}^{(t)} = f_{edge} (h_u^{(t)}, h_v^{(t)}, l_{(u,v)}^{(t)}, {s_u^{(0)}}_(u,v), {s_v^{(0)}}_(u,v))$\nThe model extends the QKV attention mechanism, taking into account the incorporation and subsequent updating of edge features. Different processors employ different f functions within the model. Certainly, we could adopt a context enhancement approach similar to the one in Section 4.1. However, we notice that, unlike existing GNN processors, the Transformer processors in the literature do not utilize gating mechanisms in the update of hidden states. Thus, to capture the contextual information of latent features and hidden states simultaneously, we propose a refined framework that seamlessly integrates the preprocessor and processor, allowing for mutual sharing of states. Initially, the preprocessor utilizes hidden states for context state updates.\n$\\forall v \\in V :$\n$z_v^{(t)} = l_v^{(t)} \\oplus h_v^{(t-1)}$\n$a_v = sigmoid (f_{linear-1} (c_v^{(t)}))$\n$c_v^{(t+1)} = a_v \\cdot c_v^{(t)} + (1 - a_v) \\cdot z_v^{(t)}$\n$\\forall e \\in E :$"}, {"title": "5 Experiments", "content": "This section validates the empirical performance of our framework and aims to investigate the following questions:\n\u2022 Can the framework simultaneously enhance the reasoning capabilities of GNN-based and Transformer-based architectures? If so, is there a noticeable discrepancy in the performance improvements between these two architectural types?\n\u2022 Consider an architecture faced with a reasoning task in which it inherently performs sub-optimally. If our framework is applied, can we expect an enhancement in performance? In simpler terms, does the framework push the original architecture towards a more \u201cextreme\u201d or improved state?\nTo this end, we apply the framework to two state-of-the-art architectures: Triplet-GMPNN [Ibarz et al., 2022], a GNN-based model, and RT [Diao and Loynd, 2023], a Transformer-based model. We refer to their implementations as CEF-GMPNN and CEF-RT, respectively. We remark that in the main body, we focus on the exploration of the aforementioned two questions; the ablation experiments regarding implementation details are deferred to the appendix. The code is available at https://github.com/Ghost-st/CEF."}, {"title": "5.1 Setup", "content": "The experiments are conducted on a machine equipped with an i7-13700K CPU and an RTX 4090 GPU. The results are averaged over 5 runs with random seeds 5, 18, 25, 30, and 42.\nDatasets. We use the CLRS Algorithmic Reasoning Benchmark [Velickovic et al., 2022], a proven benchmark that offers a unified evaluation (micro-F1 score) for assessing the (seq-graph) reasoning capabilities of neural networks. It is derived from a foundational algorithms textbook \"Introduction to Algorithms\" [Cormen et al., 2009] and consists of 30 algorithmic reasoning tasks, covering a wide range of algorithmic procedures including sorting, searching, dynamic programming, graph algorithms, string algorithms, and geometric algorithms. The inclusion of such a variety of tasks enables us to draw meaningful conclusions about the effectiveness of the proposed framework.\nBaselines. The two most crucial baselines we compare against are Triplet-GMPNN [Ibarz et al., 2022] and RT [Diao and Loynd, 2023], which play a pivotal role in addressing the aforementioned questions. Moreover, we include Memnet [Sukhbaatar et al., 2015], MPNN [Gilmer et al., 2017], PGN [Velickovic et al., 2020], and NPQ [Jain et al., 2023] in experiments as important references for comparison.\nTraining Details. In our implementations, $f_{linear}$, $f_{linear-1}$ and $f_{linear-2}$ are individual linear layers. To ensure fair comparisons, we employ the experimental hyperparameter settings used in triplet-GMPNN [Ibarz et al., 2022] and Relational Transformer [Diao and Loynd, 2023] for CEF-GMPNN and CEF-RT, respectively. Specifically, for CEF-GMPNN, we set the batch size to 32 and the network is trained for 10,000 steps by Adam optimizer with a learning rate of 0.001; while for CEF-RT, we set the batch size to 4 and the network is trained for 10,000 steps by Adam optimizer with a learning rate of 0.00025. We remark that with the introduction of a preprocessor module in our framework, the average training time increases by 3 to 5 minutes for both methods. This increment represents less than 10% of the total runtime, indicating the efficiency of our implementations."}, {"title": "5.2 Comparison with GNN-based Processors", "content": "In this experiment, we compare our method CEF-GMPNN with Triplet-GMPNN across 30 reasoning tasks within the CLRS dataset. The results are shown in Figure 2. Bar charts illustrating average scores, with standard deviations denoted by black lines, are presented for each task. Additionally, the tasks are arranged in descending order of improvement magnitude to better showcase trends.\nFrom Figure 2, we see that our framework demonstrates enhancement across all 30 reasoning tasks, implying that our framework pushes the Triplet-GMPNN architecture towards"}, {"title": "5.3 Comparison with Transformer-based Processors", "content": "In this experiment, we compare our method CEF-RT with RT across 30 reasoning tasks within the CLRS dataset. The results are shown in Figure 3.\nWe observe a trend different from the previous experiment. The framework enhances the performance of RT across the majority of CLRS datasets. Specifically, in tasks related to graph optimization, such as strongly connected components (SCC) and depth-first search (DFS), there is a noteworthy increase in test scores of over 30%. However, for sorting tasks where the original RT approach exhibits poor average scores with very large derivations, our framework leads to a decrease in performance. This phenomenon indicates that for Transformer-based Processors, our framework steers them to-ward a more \"extreme\" state."}, {"title": "5.4 Summarized Results and Analysis", "content": "We summarize the experiential results in Table 1. Due to space limitations, we use column \"Prior Best\" to represent the best results among Memnet [Velickovic et al., 2022], PGN [Velickovic et al., 2022], MPNN [Velickovic et al., 2022], and NPQ [Jain et al., 2023]. Note that [Jain et al., 2023] proposed four variants of the NPQ approach, and for each task, we have chosen the best scores among these variants as reference items.\nIn the table, we present the specific test scores for each task, along with summarizing the average scores. Additionally, in line with prior work [Ibarz et al., 2022], we provide the respective proportions of tasks achieving scores greater than 90%, 80%, and 60%. We see the following trends:\n\u2022 Our framework yields state-of-the-art results across the majority of the CLRS benchmark, demonstrating higher average scores and lower deviations compared to prior work. The overall average score of CEF-GMPNN is"}, {"title": "6 Conclusion", "content": "The paper studies seq-graph reasoning. We introduce a context-enhanced framework for such tasks and show that it can effectively integrate with various existing approaches. Our experiments reveal that the proposed framework consistently enhances the reasoning capabilities of both GNN-based and Transformer-based architectures, achieving new state-of-the-art results on the CLRS benchmark.\nThere are several intriguing avenues for future research. One interesting direction involves refining our current framework. As discussed in Section 1, the outcome sequence may form an entire problem-solving or optimization process, potentially represented by an additional reasoning graph. Therefore, it is worthwhile to explore a framework capable of efficiently capturing such graph structures hidden in the data.\nAnother promising direction could be concentrating on the CLRS benchmark, aiming to design novel architectures that could yield further performance improvements."}, {"title": "A Attention-Based Preprocessor", "content": "In this section, we introduce a QKV attention-based preprocessor. Recall two functions in the preprocessor module:\n$S^{(t)} = f_{enhance} (L^{(t)}, C^{(t)})$\n$C^{(t+1)} = f_{update} (L^{(t)}, C^{(t)})$\nWe employ a node-wise (resp. edge-wise) concatenation function for $f_{update}$ and a QKV attention network for $f_{enhance}$. For each node v \u2208V,\n$q_v =f_{linear-q} (l_v^{(t)})$\n$k_v =f_{linear-k} (c_v^{(t)})$\n$\\theta_v =f_{linear-v} (c_v^{(t)})$\n$s^{(t)} =softmax\\left(\\frac{q_v^T k_v}{\\sqrt{d_{kv}}}\\right) \\theta_v$\n$c^{(t+1)} = l_v^{(t)} || c_v^{(t)}$\nThe above is a standard QKV attention mechanism. Function $f_{linear-q}, f_{linear-k}, f_{linear-v}$ are linear layers and $d_{kv}$ is the dimension of $k_v$. In our empirical evaluation, we apply such an implementation to the Triplet-GMPNN processor and call it CEF-GMPNN-ATT.\nIt is evident that the demand for memory substantially increases with a rise in the total number of reasoning steps, as $c^{(t+1)}$ grows larger over successive steps. This approach proves to be excessively resource-intensive and, thus, is not suitable for all tasks in CLRS, especially those tasks with a large number of reasoning steps like quicksort (2079 steps). Thus, in the experiments, we pick several tasks with a modest graph size and a limited number of reasoning steps and compare CEF-GMPNN-ATT with CEF-GMPNN on these tasks."}, {"title": "B Ablation Study of Gating Mechanism Implementation", "content": "In this section, we conduct three ablation experiments on some tasks in CLRS to investigate the effects of certain algorithms. All ablation experiments are repeated three times with random seeds of 18, 30, and 42. Apart from the experimental settings described for each experiment, all other settings remain consistent with those mentioned in the main text. In all the tables, the column containing the ablation experiments is referred to as \"Ablation\". In addition, we use \u2191 and after each item in that column to represent the increase and decrease in inference performance.\nThe first experiment is performed on the CEF-GMPNN model, where the activation function for calculating the forget factor is replaced from tanh + ReLU to sigmoid. The experimental results are presented in Table 3. Based on the results of this experiment, we can conclude that when using the CEF framework in GNN-based architectures, the model tends to set the forget factor's value to 0, which can be effectively achieved through the combination of tanh + ReLU.\nThe second experiment replaces the sigmoid activation function with tanh + ReLU for calculating the forget factor in CEF-RT, which is converse to the first experiment. The experimental results are presented in Table 4. It can be observed that the Transformer-based processor, when combined with the CEF framework, prefers the sigmoid activation function. An intuitive explanation is that such processors require more flexibility in assigning values to the forget factor compared to the GNN-based model architecture.\nThe third experiment involves replacing the operation of using C as the key and value in the attention mechanism in CEF-RT with the operation of directly assigning C to z, similar to CEF-GMPNN. The algorithm for updating node features with attention then utilized the self-attention mechanism from RT. The experimental results are presented in Table 5. Through this experiment, we demonstrate the necessity of using a contextual storage module as the key and value for cross-attention in the Transformer architecture within the CEF framework."}, {"title": "C Exploration of the Forget Factor", "content": "In order to further explore the selection of the forget factor in CEF for GNN-based and Transformer-based architectures, we conducted experiments using different values of the forget factor in CEF-GMPNN and CEF-RT. The experimental results were visualized as two heatmaps shown below. From Figure 4 and Figure 5, it can be observed that CEF-GMPNN performs best when the forget factor value is close to 0, while CEF-RT does not exhibit such a trend."}, {"title": "D Training Time", "content": "In this section, we present a comparative analysis of the training time before and after integrating the CEF framework with Relational Transformer and Triplet-GMPNN. From Table 6, it can be observed that there is no significant improvement in training time after incorporating our framework. It serves as evidence for the efficiency of CEF."}]}