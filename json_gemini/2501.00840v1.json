{"title": "Distilled Lifelong Self-Adaptation for Configurable Systems", "authors": ["Yulong Ye", "Tao Chen", "Miqing Li"], "abstract": "Modern configurable systems provide tremendous opportunities for engineering future intelligent software systems. A key difficulty thereof is how to effectively self-adapt the configuration of a running system such that its performance (e.g., runtime and throughput) can be optimized under time-varying workloads. This unfortunately remains unaddressed in existing approaches as they either overlook the available past knowledge or rely on static exploitation of past knowledge without reasoning the usefulness of information when planning for self-adaptation. In this paper, we tackle this challenging problem by proposing DLiSA, a framework that self-adapts configurable systems. DLiSA comes with two properties: firstly, it supports lifelong planning, and thereby the planning process runs continuously throughout the lifetime of the system, allowing dynamic exploitation of the accumulated knowledge for rapid adaptation. Secondly, the planning for a newly emerged workload is boosted via distilled knowledge seeding, in which the knowledge is dynamically purified such that only useful past configurations are seeded when necessary, mitigating misleading information. Extensive experiments suggest that the proposed DLiSA significantly outperforms state-of-the-art approaches, demonstrating a performance improvement of up to 229% and a resource acceleration of up to 2.22\u00d7 on generating promising adaptation configurations. All data and sources can be found at our repository: https://github.com/ideas-labo/dlisa.", "sections": [{"title": "I. INTRODUCTION", "content": "Software systems are often highly configurable [1]\u2013[5]. However, their operation environment is often confronted with dynamic and uncertain conditions that change over time [6], [7], which is crucial to their performance (e.g., runtime [8]). Taking the H2 database system as an example, its real-time workloads are known to highly fluctuate, prompting the system to dynamically adjust its configuration options to accommodate such changes [9].\nTo mitigate this, one promising way is to engineer self-adaptive configurable systems\u2014a specific type of self-adaptive systems that, when the workload changes, self-adapt their configurations to meet different performance needs [10]\u2013[13]. The critical challenge of self-adaptation lies in planning [14]\u2013[16], i.e., how to identify the most effective configuration (a.k.a. adaptation plan) amidst constantly changing workload at runtime. Recently, Search-Based Software Engineering (SBSE) has been considered a promising direction for solving this challenge, which tries to iteratively search for and refine configurations to locate the optimal one by using tailored search algorithms [17]\u2013[20]. The inherent search and optimization properties of SBSE make it well-suited to addressing the complexities of huge configuration spaces encountered in adapting configurable systems. Importantly, SBSE exhibits highly extensible potentials for complementing other approaches, such as control theoretical [21]\u2013[23] and learning-based methods [24]\u2013[29], to achieve integrated schemes, thereby providing a comprehensive solution for runtime planning.\nBeyond the exponentially growing search space and the non-linear interaction among configuration options, the ever-changing workload further intensifies the planning difficulties when self-adapting configurable systems. Particularly, the landscape of the search space may shift dramatically across different workloads, suggesting that a configuration optimized for one workload may become suboptimal or even perform poorly in another [11]. This dynamic nature requires planning to not only search for an optimal configuration under a newly emerged workload but should be doing so rapidly.\nA promising resolution to that end is to reuse \"past knowledge\", i.e., configurations that were optimized under the previous workloads, for the planning to start working with under the current workload [20]. However, unfortunately, existing works often assume a stationary adaptation, which restarts the planning process from scratch following each workload change or at a fixed frequency. Such methods may be inefficient, as they fail to fully utilize historical search experiences, resulting in repetitive effort and a waste of valuable information that could inform more effective adaptation planning [17], [18], [30]. Indeed, certain approaches have followed a dynamic adaptation [19], [20], [31] that exploit configurations found previously to speedup the planning (i.e., seeding). This, while running continuously, can still generate negative outcomes as the way how knowledge is exploited follows a static strategy: all (or randomly selected) configurations from the most recent past workload are used while any of those from earlier workloads are discarded. That said, the idea seems intuitive-the latest workload that has been changed may provide more useful information for the current newly emerged one while those older workloads may often be less useful. Yet, since the order of workload arriving in the system is uncertain, there is no guarantee that the configurations from the latest workload are all promising for the current one nor those from earlier workloads are completely irrelevant, as what has been implied in prior work [9] and observed from our study in Section-II.C.\nTo fill the above gap, in this paper, we propose a framework, dubbed DLiSA, to self-adapt configurable systems at runtime based on the MAPE-K loop [32]. DLiSA comes with a combination of two properties that makes it distinctive: (1) lifelong planning, where we leverage an evolutionary algorithm in the planning that runs continuously throughout the lifetime of the system while providing the foundation for seeding; and (2) distilled knowledge seeding\u2014a truly dynamic knowledge exploitation strategy such that it not only seeds past configurations when there is evidence that they can be beneficial but also extracts the most useful ones to seed from all historical workloads, hence mitigating the misleading noises while keeping the most useful information. In this way, DLiSA ensures that the exploitation of past knowledge is neither static nor completely abandoned, which fits with the characteristics of configurable systems.\nIn a nutshell, our main contributions are as follows:\n\u2022 We show, by examples of configurable systems' landscapes, the key characteristic faced by self-adapting configuration at runtime under changing workloads.\n\u2022 We develop a ranked workload similarity analysis to excavate correlations and patterns of past workloads, helping to extrapolate the traits of the new workload for more informed adaptation planning.\n\u2022 We propose a weighted configuration seeding that distills the past knowledge, seeding only the most useful configurations and mitigating the misleading ones.\n\u2022 DLiSA is experimentally evaluated against four state-of-the-art approaches on nine real-world systems with different performance objectives, scales, and complexity, including 6-13 time-varying workloads. This leads to a total of 93 cases to investigate. Experimental results encouragingly demonstrate that DLiSA exhibits significant improvements in both efficacy (up to 2.29x) and efficiency (up to 2.22\u00d7).\nThe rest of this paper is organized as follows. Section II introduces the background and motivation. Section III provides the details of our proposed DLiSA. Section IV presents our experiment methodology, followed by the experimental results in Section V. Section VI discusses the most noticeable aspects of DLiSA. Threats to validity, related work, and conclusion are presented in Sections VII, VIII, and IX, respectively."}, {"title": "II. BACKGROUND AND MOTIVATION", "content": "In this section, we discuss the preliminaries and main motivation of this work.\nA. Self-Adaptive Configurable Systems\nIn this work, we focus on self-adaptive configurable systems. According to a well-known taxonomy [10], the self-adaptive configurable systems differ from the other concepts as follows:\n\u2022 Self-Adaptive Systems: These systems adapt to changes by modifying their behaviors, which could be any system's states (including structure and parameters) at runtime [10].\n\u2022 Self-Reconfigurable Systems: A special type of self-adaptive systems that primarily alter their structure/architecture (including parameters) to adapt [33].\n\u2022 Self-Adaptive Configurable Systems: Unlike others, these systems specifically adapt by adjusting configuration parameters [34].\nClearly, the self-adaptive configurable system is a type of self-adaptive/self-reconfigurable systems that primarily adjust configuration parameters at runtime to optimize their performance [10], [33], [34], focusing at the intersection between self-optimized and self-configured systems [10], which have been frequently studied in prior work involving dynamic workloads [11]\u2013[13].\nB. Problem Formalization\nWithout loss of generality, self-adaptation planning for a given configurable system involves the following key concepts, as shown in Figure 1.\n\u2022 System: A configurable system with configurable options that can be adjusted at runtime.\n\u2022 Workload: The time-varying and uncertain receiving jobs for which the system handles. The concrete instance can vary. For example, the workloads refer to different types and volumes of queries that emerged for database system H2; for file compressors such as KANZI, this becomes the incoming files to be compressed, which could be of diverse formats and sizes.\n\u2022 Configuration: An instance of variability for a configurable system, formed by a set of values for the configurable options. In this work, we consider both the configurations (and options) that require system rebooting and those that do not.\n\u2022 Performance: The metric(s) that evaluates the behavior of the system, such as runtime (i.e., the time taken by the system to process a given workload) and throughput.\n\u2022 Budget constraint: The budget of cost allowed for self-adaptation planning under the workload for a particular timestep. While the definition of budget varies, in this work, we use the number of system measurements during planning as the budget, which means that we can only measure a certain number of configurations as our constraint. The measurement is chosen because: (1) it is independent of the implementation, such as language and hardware; (2) it eliminates the interference of clock time caused by the running system to be adapted, when it is run at the same machine as the planning process; (3) it has been widely used in existing work [2], [35].\nWhen a single performance objective is of concern, the goal of planning when self-adapting a configurable system S is, for each timestep t in which the system handles a workload over the time horizon, to identify a configuration that optimizes the specific performance attribute, e.g., minimizing runtime or maximizing throughput, of the target system, subject to a budget constraint for planning. Formally, this can be defined as:\n$\\arg \\min f_t(x) \\text{ or } \\arg \\max f_t(x), \\\ns.t. r_t < R_t,$\n(1)\nwhere $x = (x_1, x_2,...,x_n)$ is a configuration with the values of $n$ options (e.g., $x_n$) in search space $X$. $f_t$ represents the performance attribute of the target system. $r_t$ and $R_t$ respectively denote the cost consumption and the budget allowed for planning at timestep $t$.\nC. Motivation and Challenges\nIt is well-known that, when self-adapting configurable systems, the configurations produced under one workload might be useful to the other workloads [9], [12], [27]. However, it remains unclear how to explicitly extract the key knowledge and whether there exists irrelevant or even misleading information, i.e., noises. To uncover these underlying issues, we analyze the datasets collected from commonly used configurable systems and their workload from prior studies [9], [36]\u2013[38]. The goal is to investigate what are the similarities and discrepancies between the configuration landscapes of different workloads. Figure 2 shows the top 50 performing configurations for two systems under different workloads and we observe the following patterns (similar observations exist in other systems):\n\u2022 There could be a strong overlap of the promising configurations across workloads (the connected points). That said, a promising configuration under a workload could also be promising under the others. For example, the points connected by dashed lines for workloads large, vmlinux, and misc of KANZI in Figure 2a.\n\u2022 It is also possible that the promising configurations for each individual workload differ significantly. For instance, the points under workloads of H2 in Figure 2b rarely overlap with each other. The same phenomenon occurs even for the workloads of the same system, e.g., workload deepfield against the others for KANZI.\nThe above leads to a key characteristic for configurable systems, which motivates our work:\n-Key Characteristic\nTop-performing configurations between workloads can be very similar or very discrepant, depending on both the systems (e.g., KANZI and H2) and the workloads within a single system (e.g., between workload deepfield and the others for KANZI).\nSince the order of workloads arriving at a system is uncertain, the above suggests that \u201cseeding\u201d promising configurations optimized for the past workloads to the planning under the current workload can be beneficial, as long as we can:\n\u2022 Challenge 1: extract the most useful configurations discovered previously (the configurations that are promising across workloads), if any, while doing so without injecting misleading information (the configurations that are \"good\" under the past workloads only);\n\u2022 Challenge 2: and detect when it is generally more harmful to seed than simply restart planning.\nNevertheless, existing approaches have failed to explicitly handle the above characteristics and challenges of configurable systems when running under changing workloads: on one hand, stationary adaptation approaches (e.g., FEMOSAA [30]) restarts a new search/planning from scratch with each workload change, but clearly, according to the above characteristic, this would waste the valuable knowledge from the past workload instances that could have been exploited [39]. On the other hand, the dynamic adaptation approaches (e.g., Seed-EA [20]) rely on a static assumption for the knowledge exploitation strategy: all configurations accumulated to the most recent past workload are useful for seeding, while those from previous ones are discarded. Besides, they always trigger seeding even when the benefits are unjustified. Because the seeds retain the planning state, indeed, the dynamic approaches\nSeeding is a mechanism that benefits the planning for the current workload by reusing configurations optimized under the past workloads [20], [31]."}, {"title": "III. THE DLISA FRAMEWORK", "content": "To tackle the current limitation and handle the key characteristic/challenges discussed in Section II-C, we propose DLiSA a distilled lifelong planning framework for self-adapting configurable systems with time-varying workloads. DLiSA comes with two unique properties:\n\u2022 Lifelong planning: The planning runs continuously and adapts to workload changes-a typical case of dynamic optimization [41]\u2014in which the state optimized across different workloads can be preserved. This provides the foundation for addressing Challenge 1.\n\u2022 Distilled knowledge seeding: The knowledge of seeding is dynamically distilled, i.e., DLiSA extracts the most useful configurations from all past workloads to seed into the current planning process; or triggers randomly-initialized planning from scratch when the overall distilled knowledge is deemed not sufficiently useful. This tackles both Challenge 1 and Challenge 2.\nNext, we will articulate DLiSA's designs in great detail.\nA. Architecture Overview\nWe design DLiSA using the typical MAPE-K architecture [32], as shown in Figure 3 and Algorithm 1. In a nutshell, MAPE-K distinguishes two sub-systems-the managed system refers to the configurable systems that should be managed; and the managing system governs the self-adaptation, i.e., DLiSA. Once a workload change has been detected (e.g., a new incoming job), the Monitor informs the Analyzer to analyze the current and past status, which then triggers Planner for reasoning about the best self-adaptation plan (configuration), subject to a given budget constraint. Finally, the best-optimized configuration is set to the managed system via Executor. The Knowledge refers to the preserved data that can be used by any phases in the MAPE loop. In this work, the knowledge we retain is the workloads experienced by the systems and all the corresponding configurations that were measured/discovered in the planning previously (line 7).\nB. Knowledge Distillation\nAs shown in Figure 3, with the dynamic exploitation strategy realized by knowledge distillation, DLiSA seeks to distill the configurations optimized for all past workloads in two steps during planning: firstly, it selects representative configurations evaluated to assess the overall similarity amongst their performance across the workloads using a ranked similarity metric at the workload level. A high value of the metric represents a higher likelihood of the seeding being useful. Next, if there is convincing evidence that seeding can be beneficial for planning, we probabilistically extract N most useful configurations amongst those preserved for seeding using a quality weight at the configuration level; otherwise, a random initialization process is used instead. An algorithmic illustration has also been shown in Algorithm 2.\nRanked Workload Similarity Analysis (When to seed?): For the trigger of seeding, the idea is that, if the majority of those configurations that were discovered under the past workloads are \"similarly good\", then it is likely that there is a strong chance for certain promising configurations optimized previously to be equally good under the current, newly emerged workload, i.e., the seeding should be beneficial.\nAs a result, we propose a ranked workload similarity analysis at the workload level using all the common configurations searched across workloads (including those that were ruled out). In particular, we quantify the similarity level between two workloads by using a pairwise ranking loss [44]. The rationale is that while the concrete performance of a configuration may fluctuate with workload changes, the relative rankings can remain indicative of similarity while being scale-free.\nWe do so via the following steps (lines 1-6):\n1) For every pair of adjacent workloads (e.g., $t$ and $t + 1$), retrieve all the evaluated configurations $D_t$ and $D_{t+1}$.\n2) Identify their common configurations $D_{t+1}^+$ (line 2).\n3) Compute the ranking loss by quantifying the number of misranked pairs in $D_{t+1}^+$ (line 3):\n$C(D_{t+1}^+) = \\sum_{j=1}^{N_{t+1}} \\sum_{k=1}^{N_{t+1}} \\mathbb{1}((f_t(x_j) < f_t(x_k)) \\oplus (f_{t+1}(x_j) < f_{t+1}(x_k)))$,  (2)\nwhereby $\\oplus$ is the exclusive-or operator; $N_{t+1}$ is the number of configurations evaluated in both workloads $t$ and $t + 1$ (i.e., the size of $D_{t+1}^+$). The ranking loss $L(D_{t+1}^+)$ represents the number of misranked pairs of configurations between adjacent workloads at timesteps $t$ and $t + 1$, reflecting the discrepancy among them.\n4) Assess the similarity between $t$ and $t + 1$ ($S_{t+1}$) using the percentage of the order-preserving pairs, as follows:\n$S_{t+1} = 1 - \\frac{C(D_{t+1}^+)}{N_{pairs}},$ (3)\nwhere $N_{pairs}$ is the number of configuration combination in $D_{t+1}^+$ (line 3).\n5) Calculate the average similarity score for all pairs of adjacent workloads, i.e., $S_{sav}$ (line 6).\nThe seeding is said to be beneficial and should be triggered only if $S_{sav} > \\alpha$, where $\\alpha$ is a given threshold. Note that, if no common configurations are found between a pair of adjacent workloads, we set their similarity $S_{t+1}$ with a random value that is less than $\\alpha$, serving as a reasonable guess when no reliable information can be extracted.\nWeighted Configuration Seeding (What to seed?): When DLiSA determines that the seeding is necessary, we need to further select the most useful configurations for seeding the current workload. As observed in Section II-C, there could be a strong overlap of good configurations across different workloads, yet sometimes, the promising ones for different workloads can be highly discrepant. Our idea here is to design a weighting scheme, such that it can discriminate the past configurations based on the likelihood of them being promising under the current workload. To this end, we design a two-stage weighted seeding that operates at the configuration level, considering only the good configurations preserved. As such, we say a past configuration is useful for seeding if (1) it is good within its own workload (line 8) while (2) being robust and timely across all past workloads (lines 9-12).\nThe first stage\u2014the local stage weighting\u2014focuses on selecting the best configurations locally (based on the performance objective) under each workload. This is because those configurations that perform badly in a workload would be less meaningful for seeding. To that end, we filter the preserved configurations at each workload by 50%, i.e., only configurations are considered where $N$ is the number of configurations to be seeded in the end (line 8).\nIn the second stage, we seek to globally weight the configurations across all the past workloads. The hypotheses are:\n\u2022 preserved configurations that have demonstrated robustness in many past workloads (as they were not ruled out) are likely to perform well in the new workload;\n\u2022 since planning under a later workload might have evolved by integrating previously accumulated knowledge, configurations preserved in such a later workload are likely to exhibit good performance in the new workload.\nTherefore, we use quality weight to sort the previously selected configurations from the first stage and it has two components: a robustness weight and a timeliness weight (lines 9-12). Specifically, a robustness weight is allocated to each configuration based on its recurrence across multiple past workloads (line 10). Configurations that appear in a larger number of workloads receive higher robustness weights, reflecting their robustness for being preferred frequently and the likelihood of successful performance:\n$W_{c,r} = \\frac{O_c}{H},$ (4)\nwhere $O_c$ is the count of past workloads in which the configuration $c$ is preserved and $H$ denotes the total number of past workloads. In contrast, the timeliness weight of a configuration is calculated based on the chronological occurrence of the latest workload where the configuration is preserved (line 10). Configurations associated with more recent workloads are presumed to have integrated prior knowledge and are thus given higher timeliness weights:\n$W_{c,t} = \\frac{S_c}{H},$ (5)\nwhere $S_c$ is the sequential number of the latest workload that the configuration $c$ is associated with, indicating the most recent (largest) order in which the configuration appears across the past workloads.\nSince both $w_{c,r}$ and $w_{c,t}$ range between 0 and 1, the quality weight of configuration $c$ is then computed as:\n$W_c = w_{c,r} + w_{c,t}$ (6)\nIn the end, we stochastically select N configurations according to $w_c$ for seeding, where a greater value of $w_c$ stands a higher probability of being favored. This, compared with selecting them deterministically, still retains a low possibility of selecting \"less useful\" configurations for seeding, hence maintaining diversity to escape from the local optima.\nNotably, when there is exactly one previous workload, only the first stage would work as the number of configurations to be chosen ($\\frac{N}{2}$) is smaller than the number required (N). The remaining configurations are then randomly generated. Of course, there will be no seeding under the very first workload.\nC. Evolutionary Planning\nAs mentioned, DLiSA works the best with using evolutionary algorithms for planning because (1) they are based on population which fits well with the seeding-it caters to a set of configurations instead of one; (2) they have been widely studied in SBSE/self-adaptation [43], [45]. In this work, we employ Genetic Algorithm (GA) [46] for seeded planning. In a nutshell, GA works by iteratively reproducing from promising configurations via crossover and mutation, as evaluated on the"}, {"title": "IV. EXPERIMENTAL SETUP", "content": "We experimentally assess the performance of DLiSA by unraveling the following research questions (RQs):\n\u2022 RQ1: How effective is DLiSA against state-of-the-art approaches?\n\u2022 RQ2: How efficient is DLiSA compared with others?\n\u2022 RQ3: What benefits do ranked workload similarity analysis and weighted configuration seeding each provide?\n\u2022 RQ4: How does \u03b1 affect DLiSA's performance?\nAll experiments are run in a Python environment on MacOS with a quad-core 1.4 GHz CPU and 8GB RAM.\nA. Subject Systems, Workloads, and Configurations\n1) Systems: We follow all the systems from a prior empirical study [9] as our subjects, which investigates a range of widely studied configurable systems [36]\u2013[38]. Our selection aligns with this study to ensure consistency and comprehensiveness. Specifically, these systems are carefully chosen to span a variety of application domains, performance objectives, and programming languages, including both Java and C/C++, thereby providing a solid foundation for our investigation into systems with diverse characteristics, as shown in Table II. More details on how to use these systems for conducting experiments can be found in [9], [48].\n2) Workloads: The workloads we studied are diverse and domain-specific. For example, for SMT solver Z3, the workload can be different SMT instances that are of diverse complexity, e.g., QF_RDL_orb08 and QF_UF_PEQ018; for database system H2, the workloads are requests with different rates and types (e.g., read-only or read-write), such as tpcc-2 and ycsb-2400. In this study, we use the same various workloads as in [9], which range from 6 to 13 depending on the systems (denoted as W1, W2,..., W13). Self-adaptations are triggered as those different workloads arrive at the system in a certain order. Here, we randomly shuffle the order of all workloads to arrive at a system and test self-adaptation therein.\n3) Configurations: Each system in our study features a distinct configuration space, covering different option types (e.g., integers, boolean, and enumerates) and dimensions. Overall, these diverse systems and workloads provide a robust foundation for assessing the efficacy and efficiency of our approach across different contexts and configurations.\nB. Compared Adaptation Approaches\nFor the comparative analysis in our study, we compare DLiSA with the following state-of-the-art approaches:\n\u2022 FEMOSAA2 (Stationary Adaptation) [30]: The approach responds to workload changes by triggering a new search from scratch with randomly initialized configurations.\n\u2022 Seed-EA (Dynamic Adaptation) [20]: By using an evolutionary algorithm, the approach seeds all the configurations preserved from the most recent past workload for planning under the new workload.\n\u2022 D-SOGA (Mixed Adaptation): As a single-objective variant of D-NSGA-II [40], this approach retains 80% randomly chosen configurations from the most recent past workload with 20% new randomly initialized configurations to preserve diversity when the workload change.\n\u2022 LiDOS (Dynamic Adaptation) [11]: The approach transforms single-objective problems into multi-objective ones via an auxiliary objective, thereby leveraging non-dominance relations to retain local optimal configurations under the most recent past workload to be seeded for the new workload.\nC. Component and Parameter Settings\nFor a fair comparison across all approaches, the parameters of all stochastic search algorithms in the planning are standardized, where binary tournament is employed for mating selection, together with the boundary mutation and single-point crossover. The mutation and crossover rates are set at 0.1 and 0.9, respectively, with a population size of 20, which is widely used in prior works [5], [30]. For DLiSA, we set its only parameter \u03b1 = 0.3, unless otherwise stated, as this tends to be the generally best setting (see Section V-D).\nIn this study, we use Cyber-Twin to mimic the behaviors of the managed systems, which aims to expedite configuration evaluation in planning by using less time/resources without interfering with the managed system. There are different ways to create such a Cyber-Twin [58], e.g., (1) building a data driven surrogate model; (2) using existing benchmarks; or (3) creating a low-cost simulator/replica. Here, we chose existing benchmarks from [9] as the Cyber-Twin for all the compared adaptation approaches in experiments, which is straightforward and easy to implement, providing reliable performance data for accurate configuration measurements [11], [35]. Particularly, the budget constraint is 80 measurements (i.e., Rt = 80), which is sufficient for the approaches to"}, {"title": "V. RESULTS AND ANALYSIS", "content": "A. RQ1: Effectiveness\n1) Method: To answer RQ1, we compare DLiSA with four state-of-the-art approaches discussed in Section IV-B. We aggregate and scrutinize the best-performing configurations from 100 independent runs (each with randomly ordered workloads) under every workload, across a total of 93 cases (9 systems and each with 6 to 13 workloads). We also use the Scott-Knott test [61] for our analysis. All other settings are the same as discussed in Section IV-C.\n2) Result: The experimental results are summarized in Table III. As can be seen, overall, DLiSA demonstrates superior performance, ranking first in 69 out of 93 cases, while FEMOSAA, Seed-EA, D-SOGA, and LiDOS achieve the best ranks in 11, 33, 29, and 10 out of 93 cases, respectively. Notably, within the 69 cases where DLiSA achieved first rank, it also realized the best performance values in 65 cases, highlighting the efficacy and robustness of DLiSA in self-adaptation. In particular, DLiSA achieves up to 2.29\u00d7 enhancement compared with its counterparts (W8 of the KANZI).\nThe above efficacy of DLiSA lies in its knowledge distillation for seeding, tailored to the characteristics of changing workloads in configurable systems. This empowers DLiSA to judiciously and dynamically distill the most useful configurations and ignore the misleading ones to enhance planning or engage a conservative stance in case the past configurations are generally useless. Other approaches, in contrast, either ignore the valuable past knowledge or leverage it without catering to the noise, due to the stationary setting and the static knowledge exploitation strategy.\nHowever, there are also some edge cases where other approaches are competitive to DLiSA. For instance, in LRZIP, DCONVERT, and BATLIK systems, the relatively high similarity across different workloads suggests that consistently effective configuration in one workload tends to perform well in others. This consistency favors the Seed-EA approach, which simply seeds all the configurations preserved in preceded planning without specific responses to workload changes. An interesting observation arises within 23 system, in which D-SOGA exhibits relatively superior performance. This could be attributed to a possible moderate similarity across workloads, which allows the combination of historical insights and random configurations in D-SOGA to thrive.\nBased on the above analysis, we can conclude that:\nRQ1: DLiSA is effective as it is generally ranked better (in the statistical sense) than state-of-the-art in 74% cases (69 out of 93) with significant performance improvements of up to 2.29\u00d7.\nB. RQ2: Efficiency\n1) Method: To evaluate the resource efficiency in RQ2, for each case out of the 93, we employ the following procedure:\n\u2022 A baseline, b, is identified for each counterpart approach, representing the smallest number of measurements necessary for it to reach its best performance, denoted as T, averaging over 100 runs.\n\u2022 For DLiSA, find the smallest number of measurements, denote as m, at which the average result of the performance (over 100 runs) is equivalent to or better than T.\n\u2022 The speedup of DLiSA over a counterpart is reported as $s = \\frac{b}{m}$, which is a common metric used in [5], [62].\nIf DLiSA is efficient, then we expect $s > 1$; $0 < s < 1$ and $s = 1$ means DLiSA has worse efficiency and they are equally efficient, respectively. We use s = N/A to denote the case where DLiSA cannot achieve the T reached by its counterpart. All other settings are the same as RQ1.\n2) Result: The results are depicted in Table IV, clearly, DLiSA consistently outperforms or equalling its counterparts in the majority of cases. Specifically, compared with FEMOSAA, DLiSA attained superior speedup in 88 cases (up to 2.16x) with equal efficiency in 1 case. When contrasted to Seed-EA, DLiSA excelled in 57 cases with a maximum of 2.22x speedup and matched in 16. For the comparisons with D-SOGA and LiDOS, DLiSA maintained a remarkable speedup within 58 and 79 (up to 2.05\u00d7) out of 93 cases, respectively. These observations illustrate DLiSA's ability to deliver robust performance in utilizing resources for self-adapting configurable systems. Therefore, we say:\nRQ2: DLiSA is considerably more efficient than state-of-the-art approaches in the majority of the cases, achieving up to 2.22x speedup.\nC. RQ3: Ablation Analysis\n1) Method: To understand which parts in the knowledge distillation of DLiSA work, in RQ3, we design two variants to compare with the original DLiSA over the 93 cases:\n\u2022 DLiSA-I: We replace the weighted configuration seeding with a random seeding of preserved past configurations.\n\u2022 DLiSA-II: We disable the ranked workload similarity analysis but randomly trigger the seeding of planning.\nSince there are only pairwise comparisons, we leverage the Wilcoxon rank-sum test and A12 effect size across 100 runs.\n2) Result: The results are summarized in Table V. Clearly, we see that DLiSA exhibits a remarkable improvement over its variants from the 93 cases: DLiSA wins DLiSA-I in 50 cases with 43 ties, reflecting the effectiveness of weighted configuration seeding. Against DLiSA-II, DLiSA wins in 39 cases; draws in 53 cases; and loses only in one case, indicating the usefulness of the workload similarity analysis. These results prove the benefit of seeding only when needed and the positive implication of considering the most useful configurations while excluding the misleading ones\u2014all of which are specifically designed in our knowledge distillation according to the key characteristic of configurable systems under changing workloads discussed in Section II-C.\nIn light of these observations, we can conclude that:\nRQ3: Each individual parts in the knowledge distillation in DLiSA contribute significantly to its superiority.\nD. RQ4: Sensitivity to \u03b1\n1) Method: The parameter \u03b1 determines the likelihood of triggering seeding, in RQ4, we examine the sensitivity of"}, {"title": "VI. DISCUSSION", "content": "A. How Workload Similarity Analysis Helps?\nTo understand why the ranked workload similarity analysis can help, Figure 5a shows the changing similarity scores on two exampled orders of the time-varying workloads for z3. As can be seen, the similarity scores differ depending on the sequence of the emergent workloads in some cases, they are higher than the threshold \u03b1 = 0.3 while in some other cases, they are lower. Such a discrepancy reflects the likelihood of seeding being beneficial: in the former cases, the seeding is constantly triggered because configurations found via the planning are sufficiently similar; while in the latter cases, randomly initialized configurations are used instead as seeding would likely be more harmful due to the misleading information caused by rather different landscapes between the workloads. In this way, DLiSA retains robust adaptability to diverse and changing workloads on configurable systems.\nB. Why Weighted Configuration Seeding Work?\nTo demonstrate how configurations are weighted for knowledge distillation, Figure 5b visualizes the seeds extraction process for self-adaptation planning under workload artificl C. What Are the Implications of DLiSA?\nLifelong self-adaptation (or self-evolving systems), as highlighted in prior work [11], [43], is an emerging paradigm for ensuring that systems can evolve autonomously under unanticipated changes. This study works along this direction from the perspective of seeding under changing workloads. It shows that the evolutionary planning that runs continuously for self-adaptation is beneficial. We have demonstrated the effectiveness of the two key contributions designed in DLiSA-ranked workload similarity analysis and weighted configuration seeding-in achieving lifelong self-adaptation for configurable systems: DLiSA considerably enhances system performance by identifying and leveraging useful historical knowledge while alleviating the impact of misleading information. These results hold substantial implications for the field of Software Engineering, as they support the development of more resilient and dependable software systems that make use of existing useful knowledge while filtering out useless knowledge at varying workloads. As such, we anticipate that our results will further advance the existing research in engineering self-adaptive configurable systems."}, {"title": "VII. THREATS TO VALIDITY", "content": "Our investigation acknowledges the potential threats to internal validity associated with the parameter \u03b1, which we have set to 0.3. This choice is grounded in empirical evidence from our experiments in RQ4, where \u03b1 = 0.3 is a \u201crule-of-thumb\" that yields generally favorable outcomes. We admit that the best value for \u03b1 may differ on a system-by-"}]}