{"title": "A Survey on Deep Neural Networks in Collaborative Filtering Recommendation Systems", "authors": ["Pang Li", "Shahrul Azman Mohd Noah", "Hafiz Mohd Sarim"], "abstract": "This survey provides a examination of the use of Deep Neural Networks (DNN) in Collaborative Filtering (CF) recommendation systems. As the digital world increasingly relies on data-driven approaches, traditional CF techniques face limitations in scalability and flexibility. DNNs can address these challenges by effectively modeling complex, non-linear relationships within the data. We begin by exploring the fundamental principles of both collaborative filtering and deep neural networks, laying the groundwork for understanding their integration. Subsequently, we review key advancements in the field, categorizing various deep learning models that enhance CF systems, including Multilayer Perceptrons (MLP), Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Graph Neural Networks (GNN), autoencoders, Generative Adversarial Networks (GAN), and Restricted Boltzmann Machines (RBM). The paper also discusses evaluation protocols, various publicly available auxiliary information, and data features. Furthermore, the survey concludes with a discussion of the challenges and future research opportunities in enhancing collaborative filtering systems with deep learning.", "sections": [{"title": "1. INTRODUCTION", "content": "Recommender system is a technology that uses user data to provide personalized recommendations, and is widely used in the fields of e-commerce, social media and content recommendation. Its core goal is to recommend content that may be of interest to users by analyzing their historical behaviors and preferences, thereby increasing user satisfaction and platform revenue. The generation of recommendation lists is based on user preferences, item characteristics, historical user-item interactions, and other additional information (e.g., temporal and spatial information) [77]. Current research directions in recommender systems are divided into three main categories: collaborative filtering (CF)-based recommender systems, content filtering (CBF)-based recommender systems, and hybrid recommender systems [78]. CF recommender systems suggest items preferred by users with similar characteristics, while CBF recommender systems try to match items based on the user's previously preferred content. Hybrid recommender systems are a combination of CF and CBF, combining the advantages of both."}, {"title": "2. BACKGROUND", "content": "In this section, we provide an overview of the two key components that form the foundation of our study: Collaborative Filtering (CF) Recommendation Systems and Deep Neural Networks."}, {"title": "2.1 Collaborative Filtering Recommendation Systems", "content": "Collaborative Filtering (CF) [78] is a widely used technique in recommendation systems that predicts the interests of a specific user in unknown items by analyzing and comparing user preferences or behavior patterns towards items. This technique assumes that users with similar preferences will have similar interests in items in the future. Collaborative filtering has undergone significant transformation since its inception, marked by advancements from elementary Matrix Factorization (MF) algorithms to sophisticated machine learning techniques.\nMatrix Factorization. Matrix factorization [89] plays a central role in transforming the sparse user-item interaction matrix into two lower-dimensional latent feature matrices (see Figure 3), where rows represent users and columns represent items. The elements in the matrix represent user ratings or other forms of interaction with items. This technique uses the matrix to identify similarities between users or items and, based on these similarities, predicts items that a user may be interested in. The calculation of similarity typically uses the cosine similarity formula:\n$\\text{similarity } (u,i) = \\text{cos } (\\theta) = \\frac{r_u r_i}{||r_u|| ||r_i||}$          (1)\nwhere and $r_u$ and $r_i$ represent the rating vectors of two users or two items, respectively."}, {"title": "Challenges with Implicit Feedback.", "content": "In dealing with implicit feedback, which is inherently binary (represented by 1s and 0s), traditional matrix factorization reveals a significant drawback. Here, a '1' in the user-item interaction matrix Y indicates that an interaction between a user and an item has been observed, implying that the user has noticed and interacted with the item. Conversely, a '0' does not necessarily signify disinterest but might instead suggest that the user is simply unaware of the item [90]. This dichotomy presents a challenge in learning from implicit data, as it provides only noisy signals about users' preferences. While observed entries at least reflect users' interest in items, the unobserved entries could just be missing data and there is a natural scarcity of negative feedback. The recommendation problem with implicit feedback is formulated as the problem of estimating the scores of unobserved entries in Y, which are used for ranking the items. Model-based approaches assume that data can be generated (or described) by an underlying model. Formally, they can be abstracted as learning $y_{ui} = f(u,i|\\Theta)$, where $y_{ui}$ denotes the prediction of user u interacting with item i, and O represents the model parameters."}, {"title": "Neural Collaborative Filtering (NCF) [90].", "content": "Figure 4 shows the development of collaborative filtering from dot product methods to neural network models. Traditional dot product methods calculate ratings through the inner product of user and item vectors, while modern neural network models capture the nonlinear relationships between users and items using more complex functions and neural network architectures. The formulation of NCF is given by:\n$\\hat{r}_{ui} = \\sigma(h^T(f(P_u, Q_i)),$              (2)"}, {"title": "2.2 Deep Neural Networks", "content": "Deep Neural Networks (DNNs) are a subfield of machine learning focused on deep learning, achieving high levels of nonlinear mapping of data through the construction of multilayered network structures, thereby learning complex feature representations and abstract concepts [92]. These networks consist of multiple layers, each containing a large number of neurons, with each neuron functioning as a node performing mathematical operations. As input data is processed through these layers, increasingly abstract features are extracted. A key advantage of deep neural networks is their hierarchical structure [93], which allows them to automatically learn useful features from data without the need for manually designed feature extraction algorithms. In machine learning tasks, deep neural networks are broadly applied to two major types of learning: supervised and unsupervised learning [94]. Supervised learning is one of the most common paradigms in machine learning, where the model is trained using a set of labeled training data with the aim of learning how to map inputs to the correct outputs. In this setup, each training sample is a pair consisting of input features and a corresponding output label. Applications of deep neural networks in this domain include image recognition, speech recognition, and text classification, where the network needs to accurately predict the category labels or continuous output values of the input data. Unsupervised learning, in contrast to supervised learning, does not rely on labeled training samples. This type of learning aims to discover the intrinsic structure and patterns within data, such as through cluster analysis or anomaly detection. Examples of deep neural networks in unsupervised learning include autoencoders and Generative Adversarial Networks (GANs). Autoencoders are used to learn compressed representations of data, while GANs are utilized to generate new data samples that are similar to real data. Through the implementation of these multilayered nonlinear transformations, deep neural networks demonstrate exceptional efficacy in handling complex machine learning tasks. Table 1 illustrates a series of architectural frameworks that are particularly relevant to this survey."}, {"title": "3. NEURAL COLLABORATIVE FILTERING RECOMMENDER SYSTEMS", "content": "In this section, we delve into the core and advanced neural network models that have revolutionized collaborative filtering recommender systems. We start with fundamental models, such as Multilayer Perceptrons (MLPs), which form the backbone of neural collaborative filtering. Then, we explore more advanced techniques that represent the state-of-the-art in the field, highlighting their unique approaches and superior performance in capturing user-item interactions."}, {"title": "3.1 Fundamental Neural Network Models: Multilayer Perceptrons", "content": "Multilayer Perceptrons (MLPs) are a fundamental neural network architecture extensively used in collaborative filtering. Figure 5 shows a sampe of Multilayer Perceptron architecture. MLPs consist of multiple layers of neurons, each layer fully connected to the next, enabling the model to learn complex, non-linear representations of the data. In this context, the interaction between users and items is modeled by concatenating their embedding vectors, $P_u$ and $Q_i$, as $x_{ui} = [P_u,Q_i]$. This concatenated vector is passed through several hidden layers with non-linear activation functions, typically ReLU, as follows:$h_1 = ReLU(W_1x_{ui} + b_1)$, $h_2 = ReLU(W_2h_1+b_2), \\dots h_L = ReLU(W_1h_{L-1}+b_1)$. Finally, the output layer applies a linear transformation followed by a sigmoid function to predict the rating: $\\hat{r}_{ui} = \\sigma (W h_L+b_0)$. This structure allows MLPs to capture complex patterns and non-linear relationships between users and items, leading to more accurate and personalized recommendations compared to traditional linear methods."}, {"title": "Interpretability.", "content": "Pugoy and Kao [2] introduced the EscoFilt model, which integrates BERT, K-Means clustering, and MLP for extractive summarization-based collaborative filtering. This model enhances rating prediction accuracy and interpretability by combining advanced feature extraction and clustering techniques with MLP in processing user review data."}, {"title": "Data sparsity.", "content": "Addressing data sparsity issues, several research groups have employed innovative MLP models to optimize data usage. Lin et al. [3] proposed the NCF-MS model, integrating stacked denoising autoencoders (SDAE) and MLP with a cloud-edge collaborative computing architecture to merge multi-source data and address data sparsity. Kim and Lim [4] developed a deep neural collaborative filtering model for e-book service recommendations, utilizing an MLP structure with Bayesian optimization for hyperparameter tuning. Farhan Ullah et al. [7] introduced the Deep Edu model for educational service recommendations, using embedding layers and MLP to effectively learn nonlinear relationships between features."}, {"title": "Learning explicit ratings and implicit interactions.", "content": "Wang et al. [6]'s CEICFNet model integrates MLP to learn explicit ratings and implicit interactions in a cross-domain setting, using domain-shared and domain-specific networks to learn the latent factors of users and items. Yu et al. [5] introduced the CFFNN model, which combines MLP with a cross-feature fusion mechanism to address the relationship between user preferences and item features. This model employs a self-attention mechanism to accurately extract and merge user and item features."}, {"title": "Protecting user privacy.", "content": "Perifanis and Efraimidis [1] proposed the Federated Neural Collaborative Filtering (FedNCF) model, which combines federated learning and neural collaborative filtering to enhance recommendation performance and protect user privacy."}, {"title": "3.2 Advanced Neural Network Techniques: State-of-the-Art", "content": "In this subsection, recent advancements in neural network techniques have significantly improved collaborative filtering methods, incorporating the below state-of-the-art architectures to address complex challenges."}, {"title": "3.2.1 Convolutional Neural Networks", "content": "Convolutional Neural Networks (CNNs) are widely used in collaborative filtering due to their powerful feature extraction capabilities. The process begins with an input image representing user-item interactions. The convolutional layer applies convolution operations to extract relevant features from the input data. Following this, pooling layers reduce the dimensionality of the feature maps, retaining the most critical information. The pooled feature maps are then flattened into a vector that serves as input to the fully connected layers. These layers perform the final ranking and output the predicted results. The figure below illustrates the architecture of a CNN in the context of collaborative filtering."}, {"title": "Enhancing Co-occurrence Pattern Recognition.", "content": "Recent studies have employed CNNs to enhance collaborative filtering techniques by capturing co-occurrence patterns, leveraging hybrid methods, and improving adversarial robustness and contextual features. Chen et al. [8] introduced the CoCNN model, which leverages co-occurrence patterns within user-item and item-item relationships to enhance recommendation performance. Similarly, Lin et al. [9] proposed the COMET model, which constructs embedding maps from user and item interactions and applies CNNs with varying kernel sizes to extract interaction features. This approach allows COMET to effectively model and leverage complex user-item interactions."}, {"title": "Addressing the challenge of adversarial attacks.", "content": "Gao et al. [10] proposed the Adversarial Neural Collaborative Filtering model with Embedding Dimension Correlations (ANCF). This model employs Adversarial Personalized Ranking (APR) to enhance robustness and uses the outer product to learn pairwise embedding correlations. Bhuvaneshwari et al. [11] introduced a Top-N recommendation system that leverages explicit feedback and outer product-based residual convolutional neural networks (OPBR-CNN). This model utilizes an explicit user-item sparse rating matrix and residual connections to capture complex user-item interaction signals."}, {"title": "Incorporating user reviews and contextual features.", "content": "Dezfouli et al. [12] proposed the MatchPyramid Recommender System (MPRS), which leverages user reviews by framing the recommendation problem as a text matching task. The system constructs a matching matrix from user and item review texts, which is then processed by CNNs to compute matching scores for user-item pairs. Alrashidi et al. [13] developed a social recommender system (SRSCNN) that integrates CNNs with tagging and contextual features. This model captures user and item factors effectively by combining features from item titles and tags, thereby enhancing recommendation accuracy."}, {"title": "Hybrid methods that integrate various feedback types.", "content": "Drammeh and Li [14] enhanced neural collaborative filtering with hybrid feature selection, combining global and local item correlations using pointwise convolution and average pooling. This method captures richer latent signals and prevents overfitting by optimizing network weights with Generalized Matrix Factorization (GMF). Gurav et al. [15] proposed the IA-CNN architecture, which integrates behavioral features into dense vectors using a heatmap matrix. This approach uses convolutional layers to extract new features from user and product word embeddings, capturing complex interactions. Li and Xia [16] introduced the CMAMG_ALSCF model, combining ALS collaborative filtering with deep learning to process web data, reducing noise and normalizing inputs. This system uses CNNs to classify data based on user evaluations and interests, improving movie recommendation accuracy."}, {"title": "3.2.2 Recurrent Neural Networks", "content": "Figure 7 illustrates the architecture of a Recurrent Neural Network. RNNs are particularly effective for modeling user interactions over time, allowing for more accurate predictions of future user preferences. An RNN processes sequences of data by maintaining a hidden state that captures information from previous time steps. The hidden state at time step t is computed as:\n$h_t = \\sigma(W_h h_{t-1} + W_x x_t + b_h),$        (3)\nwhere $W_h$ and $W_x$ are weight matrices, $b_h$ is a bias vector, $x_t$ is the input at time step $t$, and o is an activation function, typically tanh or ReLU."}, {"title": "Models Based on LSTM.", "content": "Several studies have enhanced recommendation systems using Long Short-Term Memory (LSTM) networks. Manotumruksa et al. [17] introduced the CRCF model, combining LSTM and contextual attention to capture short-term user preferences, considering time and geographical factors. Do and Nguyen [18] developed a semantic-enhanced NCF model using LSTM and knowledge graphs for improved movie recommendations. Fu Chen et al. [25] proposed the SDCF model, leveraging LSTM and self-attention to model learning outcomes in assessments. Karabila et al. [26] combined sentiment analysis and collaborative filtering using Bi-LSTM for personalized e-commerce recommendations. Ebrahimian and Kashef [22] used CNNs and RNNs to detect shilling attacks in recommendation systems. Li et al. [23] integrated LSTM to predict student mastery levels in educational recommendations, optimizing collaborative filtering and cognitive diagnosis."}, {"title": "Models Based on GRU.", "content": "Xia et al. [21] proposed the AGAMF model, which uses attention-based Gated Recurrent Units (GRU) and adversarial learning to improve recommendation performance. GRU extracts contextual relationships from user information, while adversarial learning enhances model robustness. Liang et al. [24] introduced RNCF, a method for Quality of Service (QoS) prediction in the Internet of Vehicles (IoV). This model employs a multi-layer GRU to capture dynamic environmental and network conditions, improving QoS prediction accuracy."}, {"title": "Models Integrating RNN with Other Techniques.", "content": "Chung-Ming Huang and Chen-Yi Wu [19] proposed a POI recommendation method for Mobile Digital Cultural Heritage (M-DCH) using RNNs and user collaborative filtering to analyze user behaviors and preferences. This method achieves high precision, recall, and diversity in recommendations without using a rating mechanism by analyzing historical user behavior and leveraging collaborative filtering of similar users. Ibrahim et al. [20] introduced the HNCF model, integrating hierarchical user and product attention, deep collaborative filtering, and a neural sentiment classifier. This model uses RNNs and MLPs to deeply fuse user and product features, enhancing recommendation performance."}, {"title": "3.2.3 Graph Neural Networks", "content": "Graph Neural Networks (GNNs) are highly effective for collaborative filtering tasks due to their ability to model relationships in graph-structured data. The following figure illustrates the process of using GNNs in collaborative filtering."}, {"title": "Graph Construction.", "content": "Starting with a user-item interaction matrix, we construct a bipartite graph where nodes represent users and items, and edges represent interactions.\n21\nData Matrix=$[\\frac{1}{1 0}]$\nThis matrix is converted into a graph with nodes for users and items, and edges reflecting the interactions."}, {"title": "Graph Neural Network.", "content": "A GNN is then used to learn node embeddings. Each node updates its embedding by aggregating information from its neighbors. The rule is:\n$h_v^{(k)} = \\sigma (\\sum_{u \\in N(v)} w u v^{(k)} h_u^{(k-1)}), $\"         (4)\""}, {"title": "Contrastive Learning.", "content": "Contrastive learning enhances model representation by maximizing similarity from different perspectives. Li et al. [29] proposed the MD-GCCF model, using multi-view deep graph contrastive learning to address over-smoothing in GNNs and enhance feature diversity. Lin et al.'s NCL [27] model improves recommendation quality in sparse data environments by introducing structured and semantic neighborhood concepts. Xia et al.'s HCCF framework [30] and Ren et al.'s DCCF model [40] enhance user and item representations and disentangle intents using hypergraph contrastive learning and self-supervised learning, respectively."}, {"title": "High-Order Relationship Capturing.", "content": "Capturing high-order relationships is crucial in collaborative filtering. Dynamic graph models like DGCF by Xiaohan Li et al. [32] and DMGCF by Tang et al. [28] integrate temporal and collaborative information through dynamic graphs and dynamically generate user and item graphs, achieving more efficient recommendation systems."}, {"title": "Information Fusion.", "content": "Information fusion plays a significant role in enriching the contextual information of recommendation systems. Peng et al.'s KGCFRec model [33] enhances recommendation system performance and robustness by integrating knowledge graph and collaborative filtering information."}, {"title": "Denoising.", "content": "Denoising techniques enhance recommendation performance in noisy data environments. Tian et al.'s RGCF model [42] reduces noisy interaction impact on GNN representation learning with hard and soft denoising strategies. Xia et al.'s SimRec model [45] combines knowledge distillation and contrastive learning to address over-smoothing and noise, maintaining system diversity."}, {"title": "Interpretability.", "content": "Enhancing the interpretability of recommendation systems aids in user trust and system optimization. Wang et al.'s DGCF model [35] improves interpretability by dividing user and item representations into independent components and updating intention-aware graphs iteratively. Wenqi Fan et al. [31] proposed the GTN method, addressing non-adaptive propagation and unreliable interactions in GNN models using trend filtering. Sangeetha et al. [34] introduced NGCF, leveraging high-order connectivity for encoding collaborative signals on a user-item bipartite graph. Chen Li et al. [36] developed SHCF, combining sequential patterns with high-order heterogeneous collaborative signals in a heterogeneous information network. Xia et al. [37] introduced SimRec, transferring knowledge from a teacher GNN to a lightweight student network to preserve global signals and address oversmoothing. Su et al. [38] proposed GMCF, which models intra- and cross-interactions through a graph matching structure. Wang et al. [39] developed ADAPT, an adaptive graph pre-training framework for localized collaborative filtering to tackle data sparsity. Liu et al. [41] created a GNN-based attack method to increase product exposure through gradient optimization. Chen et al. [43] introduced GDSRec, a decentralized collaborative filtering model reweighting social connections based on user preference similarity. Hu et al. [44] proposed MGDCF, applying a distance-based Markov process to incorporate high-order neighbor information in GNN-based collaborative filtering."}, {"title": "3.2.4 Autoencoders", "content": "Autoencoders are a type of neural network designed to learn efficient codings of input data. They play a crucial role in collaborative filtering by capturing the underlying patterns in user-item interactions. The architecture of an autoencoder consists of two main parts: the encoder and the decoder [51]. The encoder compresses the input data into a latent space representation, often referred to as the \"code\". This process involves multiple layers that gradually reduce the dimensionality of the data, retaining only the most essential features. The central layer, or the \"code\" layer, holds the compressed representation of the input data. The decoder then reconstructs the input data from the code. This process involves multiple layers that gradually increase the dimensionality of the data back to its original form. The goal is to achieve an output that closely resembles the original input. In the context of collaborative filtering, autoencoders are used to learn latent factors representing users and items. These latent factors can then be utilized to predict user preferences and generate recommendations."}, {"title": "Privacy Protection.", "content": "Zhang et al. [47] proposed the N3S model, a federated autoencoder framework that combines hybrid negative sampling and secret sharing to protect user data privacy and reduce communication overhead. Polato et al. [66] introduced the Federated Variational Autoencoder (FedVAE) model, which enhances collaborative filtering performance through distributed computation while safeguarding privacy."}, {"title": "High-Order Relations and Data Augmentation.", "content": "Nguyen et al. [48] proposed the HACF framework, using a graph autoencoder to enhance collaborative filtering by integrating high-order connections and data augmentation. Noshad et al. [50] combined mutual information and autoencoders to generate user rating vectors and calculate user similarity. Zheng et al. [64] introduced the UIAE model, integrating user and item interactions with autoencoders. Xia et al. [53] proposed CRANet, combining reflection reception and information fusion autoencoders to capture implicit user preferences. Bobadilla et al. [65] developed a deep variational model combining VAE and DeepMF for robust latent spaces. Alharbe et al. [49] introduced UI2vec, using word embedding techniques for recommendations. Zeng et al. [61] proposed NCAR, integrating implicit trust relationships and user-item interactions."}, {"title": "Applications of Variational Autoencoders.", "content": "Shenbin et al. [51] introduced RecVAE, a Variational Autoencoder (VAE) for implicit feedback Top-N recommendations, with innovations like a composite prior distribution and user-specific \u1e9e settings, outperforming models like Mult-VAE and RaCT. Zhong and Zhang [62] proposed the Wasserstein Autoencoder (aWAE) for collaborative filtering, using L1 regularization and a new loss function to learn sparse low-rank representations and minimize reconstruction errors. Truong et al. [63] developed the Bilateral Variational Autoencoder (BiVAE) for binary user-item interaction data, combining generative and inference models to capture latent representations and alleviate posterior collapse. Zhong et al. [67] introduced the Gaussian Copula Variational Autoencoder (GCVAE), using the Copula method to better capture dependencies between latent variables and a new reparameterization technique for improved sampling. Carraro et al. [68] proposed a Conditional Variational Autoencoder (C-VAE) to improve interpretability, visualizing latent spaces and clustering users by movie genres for recommendations and profiling, demonstrating effective genre association learning on the MovieLens dataset."}, {"title": "Efficiency and Scalability.", "content": "Chen et al. [52] introduced FastVAE, a fast variational autoencoder using an inverted multi-index for collaborative filtering, achieving efficient sampling in sub-linear or constant time and enhancing sampling quality. Liu et al. [54] developed AutoSeqRec, an efficient sequential recommendation model using multi-information encoders and decoders to capture user preferences. AutoSeqRec updates only the input matrix for incremental recommendations, improving efficiency and accuracy. Van\u010dura et al. [55, 56] proposed ELSA, a scalable linear shallow autoencoder with low-rank plus sparse structures, reducing memory consumption and computation time for large-scale interaction matrices. Spi\u0161\u00e1k et al. [57] introduced sansa, an asymmetric approximate autoencoder for collaborative filtering, which scales to millions of items with low memory requirements and reduced training time."}, {"title": "Integration of Social and Contextual Information.", "content": "Tahmasebi et al. [59] proposed a social movie recommendation system using deep autoencoder networks and Twitter data. This method combines collaborative and content-based filtering while accounting for users' social influence, measured by their Twitter activity. The system was evaluated with data from MovieTweetings and OMDB. Pan et al. [60] developed a model using deep autoencoders to learn social representations for recommendations. Their Sparse Stacked Denoising Autoencoder (SSDAE) addresses data sparsity and imbalance by extracting features from social information through multi-layer neural networks and matrix factorization techniques."}, {"title": "3.2.5 Generative Adversarial Networks", "content": "Generative Adversarial Networks (GANs) [71] aim to generate new, synthetic data that resembles a given training dataset. In the context of collaborative filtering, GANs can be used to enhance recommendation systems by generating plausible user-item interaction data. A GAN consists of two main components: the generator network and the discriminator network. The generator network creates fake data by transforming random noise into data points that mimic the real data. The discriminator network, on the other hand, evaluates the authenticity of the data, distinguishing between real data from the training set and fake data produced by the generator.\nThe Figure 10 illustrates the architecture of a GAN. The left side represents the generator network, which takes random noise as input and generates fake data. The right side depicts the discriminator network, which receives both real and fake data and outputs its evaluation of their authenticity."}, {"title": "Despite the complexity and challenges in GAN training", "content": "Recent studies have explored their potential in improving collaborative filtering (CF) recommendation systems. Liu et al. [69] proposed CoFiGAN, which enhances recommendation performance through adversarial training by generating positive and negative samples to improve user behavior modeling. Bobadilla et al. [70] introduced a GAN-based method for generating synthetic datasets, using dense embeddings for fast and accurate learning. Dervishaj et al. [71] developed GANMF, applying GANs to matrix factorization and using a feature matching technique for stable training. Ding et al. [72] proposed the BiGAN model, combining ForwardGAN and BackwardGAN to leverage user behavior and friend information for better user and item representations."}, {"title": "3.2.6 Restricted Boltzmann Machines", "content": "Restricted Boltzmann Machines (RBMs) are a type of stochastic neural network that can learn a probability distribution over its set of inputs. An RBM consists of two layers: a visible layer and a hidden layer. The visible layer represents the input data, while the hidden layer captures the latent features. The connections between these layers are undirected and fully connected, meaning every node in the visible layer is connected to every node in the hidden layer, but there are no connections within a layer. The Figure 11 shows the architecture of an RBM."}, {"title": "Chen et al. [73] proposed the CRBM-IR model", "content": "Transforming the rating matrix into inspection, positive feedback, and negative feedback matrices to improve recommendation performance using Conditional Restricted Boltzmann Machines. Harshvardhan et al. [74] introduced UBMTR, a time-aware recommendation system that utilizes temporal information and features from user-movie ratings, employing the contrastive divergence algorithm. Kuo et al. [76] presented the DE-CRBM model, combining CRBM with a differential evolution algorithm to optimize parameters and enhance prediction accuracy. Yang et al. [75] proposed a distributed parallel training method using the Horovod framework to accelerate RBM training, significantly reducing training time from 5 hours to under 12 minutes on 64 CPU nodes. This method enhances the feasibility of RBM models in real-world applications requiring frequent retraining."}, {"title": "4. DATASETS, EVALUATION METRICS, AND APPLICATIONS", "content": "In this section, we provide an overview of the frequently used datasets, evaluation metrics, and the applications and problems addressed by deep neural networks in collaborative filtering recommendation systems."}, {"title": "4.1 Datasets", "content": "In this section, we outline the most frequently used datasets in collaborative filtering recommendation systems based on an analysis of approximately 80 research papers. The Table 2 lists these datasets along with key statistics such as the number of users, items, ratings, and sparsity, providing valuable resources for training and evaluating recommendation models. Here are brief descriptions of each dataset:\n\u2022 MovieLens: Collected from the MovieLens website, including MovieLens-1M\u00b9, and MovieLens-10M\u00b2. These datasets contain user-item rating pairs with timestamps, movie attributes, tags, and user demographic features. Ratings range from 1 to 5, making them widely used benchmarks in collaborative filtering.\n\u2022 Amazon: Include reviews, product metadata, and links (e.g., also viewed/bought graphs). Sub-datasets like Amazon-Electronics\u00b3 and Amazon-Movies4 are used to test performance in collaborative filtering and sequential recommendation.\n\u2022 Pinterest: This dataset includes user interactions with pins on the Pinterest platform, highlighting user engagement and preferences in a social media context. It is often used to test recommendation algorithms in social media settings.\n\u2022 Yelp6: Contains user check-ins and reviews for local businesses. It is frequently updated and used in collaborative filtering and POI (Point of Interest) recommendation tasks, providing insights into local business preferences.\n\u2022 Gowalla7: This check-in dataset includes user locations and social relationships.It is a classical dataset for POI recommendation and is used in both collaborative filtering and sequential recommendation studies.\n\u2022 LastFM8: Features user interactions with music tracks, including user ratings and listening history. This dataset is crucial for developing and testing music recommendation systems, capturing user preferences in the music domain."}, {"title": "4.2 Evaluation Metrics", "content": "In this section, Table 3 shows the evaluation metrics commonly used in the selected papers for assessing the performance of collaborative filtering models. The table below summarizes the metrics and the corresponding papers that reference them. The most frequently used evaluation metrics include Recall@k, NDCG@k, HR@k, RMSE, and MAE. These metrics are essential for evaluating the accuracy and effectiveness of recommendation systems. Recall@k and NDCG@k are often used together to measure the relevance of the top-k recommendations. RMSE and MAE are standard metrics for measuring prediction errors."}, {"title": "4.3 Why use deep neural networks in collaborative filtering?", "content": "Deep neural networks (DNNs) demonstrate significant advantages in collaborative filtering recommendation systems due to their powerful feature extraction capabilities, high flexibility, ability to handle complex nonlinear relationships, and excellent generalization. DNNs can automatically learn feature representations from vast amounts of data, reducing the reliance on manual feature engineering, and can adapt to various data distributions and diverse user behavior patterns. Through their multi-layer structure, DNNs can capture high-order features and complex interactions within the data, thereby enhancing the accuracy and personalization of recommendations. This section delves into the reasons for incorporating deep neural networks in collaborative filtering and provides a classification of their applications in the field of collaborative filtering recommendation systems, as illustrated in Figure 12.\nDeep neural networks have revolutionized collaborative filtering by addressing several critical system challenges.\n\u2022 Privacy Protection: With increasing concerns over data privacy, models like FedNCF [1] employ federated learning to ensure user data remains decentralized and secure, thus protecting user privacy while still enabling effective recommendations.\n\u2022 Defensive Mechanisms: Deep neural networks enhance the robustness of recommendation systems. Advanced models efficiently detect and mitigate shilling attacks, thereby preserving the integrity and reliability of recommendations.\n\u2022 Distributed Processing: Leveraging cloud-edge collaboration, models such as NCF-MS [3] efficiently distribute computational tasks, enabling scalable and real-time recommendation processing, which is crucial for handling large-scale data environments.\nDeep neural networks also significantly enhance the performance and optimization of recommendation systems.\n\u2022 Cold Start Problem: By incorporating hierarchical and contextual data, models like DeepEdu [7] and HNCF [20] effectively address the cold start problem, facilitating accurate recommendations even for new users and items.\n\u2022 Data Sparsity: Techniques used in models like FEDNCF [4] and SRSCCNN [13] adeptly manage data sparsity, utilizing sparse data to extract meaningful patterns and improve recommendation accuracy.\n\u2022 Explicit and Implicit Features: Models such as CEICFNet [6] and MPRS [12] integrate both explicit feedback (like user reviews) and implicit behavior (like browsing history), thereby enriching the recommendation process with comprehensive user insights.\nAdvanced capabilities of deep neural networks further extend their utility in collaborative filtering.\n\u2022 Deep Feature Extraction: Models like CoCNN [8]and CFFNN [5] excel in extracting complex co-occurrence relationships and fusing cross-feature information, leading to more accurate and nuanced recommendations.\n\u2022 Adaptive Propagation: Techniques in models like CARA [17] and Semanticenhanced NCF [18] allow for dynamic adjustment of propagation mechanisms, tailoring the recommendation process to evolving user behaviors and preferences.\n\u2022 Explainability: Enhancing the transparency and interpretability of recommendations."}, {"title": "5. CONCLUSION AND FUTURE WORKS", "content": "In this survey, we explored the transformative role of deep neural networks (DNNs) in collaborative filtering recommendation systems. DNNs have been proven to be powerful tools for enhancing the accuracy, efficiency, and personalization of recommendations by effectively addressing key challenges such as data sparsity, cold start problems, and the extraction of both explicit and implicit features. Their ability to handle complex nonlinear relationships and capture high-order interactions within the data makes them indispensable in modern recommendation systems. We discussed various DNN architectures and techniques, highlighting their unique contributions and applications. These models have demonstrated significant improvements in capturing user preferences, handling large-scale data, and providing robust and interpretable recommendations. Future research on DNN-based collaborative filtering recommendation systems should focus on enhancing scalability and efficiency to handle larger datasets, improving robustness and security against adversarial attacks, and increasing model interpretability. Additionally, integrating multimodal data, advancing personalization through context-aware models, and optimizing federated learning techniques for privacy preservation are essential areas for further exploration. These advancements will continue to push the boundaries of what recommendation systems can achieve, making them more intelligent, efficient, and user-centric."}]}