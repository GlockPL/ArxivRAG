{"title": "Analysis on Riemann Hypothesis with Cross Entropy Optimization\nand Reasoning", "authors": ["Kevin Li", "Fulu Li"], "abstract": "In this paper, we present a novel framework for the analysis of Riemann Hypothesis [27], which\nis composed of three key components: a) probabilistic modeling with cross entropy optimization\nand reasoning; b) the application of the law of large numbers; c) the application of mathematical\ninductions. The analysis is mainly conducted by virtue of probabilistic modeling of cross\nentropy optimization and reasoning with rare event simulation techniques. The application of\nthe law of large numbers [2, 3, 6] and the application of mathematical inductions make the\nanalysis of Riemann Hypothesis self-contained and complete to make sure that the whole\ncomplex plane is covered as conjectured in Riemann Hypothesis. We discuss finite precision\nmodeling in terms of the computation of the value of Riemann Zeta functions from a practical\nperspective with respect to the quantization modeling and the number of bits for the variables\ncommonly used in today's computing facilities. We also discuss the method of enhanced top-p\nsampling with large language models (LLMs) for reasoning, where next token prediction is not\njust based on the estimated probabilities of each possible token in the current round but also\nbased on accumulated path probabilities among multiple top-k chain of thoughts (CoTs) paths.\nEssentially, we propose the use of a combination of top-p sampling method and beam search\nwith a beam width of k for chain of thoughts (CoTs) reasoning with large language models\n(LLMs). The probabilistic modeling of cross entropy optimization and reasoning may suit well\nwith the analysis of Riemann Hypothesis as Riemann Zeta functions are inherently dealing with\nthe sums of infinite components of a complex number series.\nWe hope that our analysis in this paper could shed some light on some of the insights of\nRiemann Hypothesis, in particular from the perspective of of probability convergence of\nrandom samples with cross entropy optimization and reasoning as well as the application of the\nlaw of large numbers and the application of mathematical inductions as well as the method of\nenhanced top-p sampling with large language models (LLMs) for reasoning. The framework\nand techniques presented in this paper, coupled with recent developments with chain of thought\n(CoT) or diagram of thought (DoT) reasoning in large language models (LLMs) with\nreinforcement learning (RL) [1, 7, 18, 21, 24, 34, 39-41], could pave the way for eventual proof\nof Riemann Hypothesis [27].", "sections": [{"title": "1. Introduction", "content": "About 165 years ago, Riemann Hypothesis (RH) was proposed by Bernhard Riemann in 1859 regarding the\ninput-value conditions, i.e., input variables, and the zero-function-value distributions of Riemann Zeta\nfunction, which could have great implications on the distribution of prime numbers [27] and other well-\nknown mathematical conjectures such as Goldbach's conjecture for odd numbers [14]. The Riemann Zeta\nfunction or Euler-Riemann Zeta function was first introduced by Leonhard Euler in the early 1700 when\nEuler computed the infinite sum of the inverse of squares of integers. Euler studied the Zeta functions with\nthe input variable of real numbers in the first half of the 18th century. It was Bernhard Riemann who\nextended Euler's definition of the Zeta function to complex variables. Riemann conjectured in his landmark\npaper [27] that Riemann Zeta function has its complex zeros only at the negative even integers for the real"}, {"title": "2. Related Work", "content": "In the Pursuit of the Proof of Riemann Hypothesis. In the early 1900, Hardy in [13] and Hardy, Fekete\nand Littlewood in [14] proved that there are infinitely many zeros for Riemann Zeta functions on the critical\nline, by considering moments of certain functions related to the Riemann Zeta function. Alan M.Turing, who\nis widely considered as the farther of Artificial Intelligence (AI), and Lehman presented methods for the\ncomputation of the number of zeros for Riemann Zeta functions in a given region [19, 37].\nIn general, the pursuit of the proof of Riemann Hypothesis can be classified into two categories: a)\nTransforming Riemann Hypothesis into another equivalent problem of B, by proving the correctness of\nproblem B, essentially Riemann Hypothesis also gets proved; b) Computing and locating zeros of Riemann\nZeta functions in the critical strip region of {s \u2208 C : 0 < R(s) < 1} and verifying that if those non-trivial\nzeros are all on the critical line of {s \u2208 C : R(s) = 1/2}.\nFor the first category, we can take a look at the following example: The de Bruijn-Newman constant,\ndenoted by A, is defined as the unique real number such that the function H(\u03bb, z), defined with a real\nparameter \u03bb, a complex variable z and a super-exponentially decaying function of \u0424(u), has only real zeros\nif and only if 2 > \u039b. Since Riemann Hypothesis is equivalent to the claim that all the zeroes of H(0,z) are\nreal, Brad Rodgers and Terence Tao discovered that Riemann Hypothesis is equivalent to A = 0 by proving\nzero to be the lower bound of the constant of A [30]. Proving zero to be the upper bound of A would also\nprove the correctness of Riemann hypothesis.\nFor the second category, we can take a look at the following endeavors: The basic idea is to verify Riemann\nHypothesis up to a given imaginary part of T. For Riemann Zeta function of ((s) with a complex variable of\ns, we have s = \u03c3 + it, where t is the imaginary part. This is done by computing the total number of zeros of\nRiemann Zeta function in a given region using Turing method [19,37] and checking that if it is the same as\nthe number of zeros found on the critical line of {s \u2208 C: R(s) = 1/2}, as conjectured in Riemann\nHypothesis. As pointed out in [25] that extensive computations by O. Bohigas and M. Gianonni in [5], and\nby A. Odlyzko in [23] have confirmed the statistics with high accuracy for the verification of Riemann\nHypothesis. In particular, Platt and Trudgian have reported that the computation of Riemann zeros with\naccuracy to various millions and imaginary parts to the height of 3 \u00d7 1012 in the year of 2020 [26]. We refer\ninterested readers on how numerical calculations of Riemann Zeta function is done with respect to the\ncritical line to [5, 23, 26] for details.\nIn addition, there are quite a lot of efforts for better understanding of Riemann Hypothesis and Riemann Zeta\nfunctions during the last 165 years and we just list a few of them here due to limited space [4, 5, 8-17, 19, 22,\n23, 25, 26, 30, 35-37], all of which constitute this seemingly never-ending tide of pursuit for the proof of\nRiemann Hypothesis, wherever it might lead to.\nProbabilistic Modeling with Cross Entropy Optimization and Reasoning. The basic idea of cross entropy\n(CE) method [20, 31, 32] is to translate the deterministic optimization problem into a corresponding\nstochastic one and then use rare event simulation techniques to find the optimal solution. It works in an\niterative fashion by generating a large number of random samples at each round based on some probability\ndistribution over a given value set. At the end of each round, performance evaluation is conducted for each\nrandom sample with respect to the optimization objectives. The central step of cross entropy method is to\nadjust the probability distribution based on which the random samples are generated, where those samples\nwith better performance in the last round in terms of the optimization objectives are given higher\nprobabilities to generate samples in the current round.\nIn [20], Li et al presented a random tree optimization approach for the construction of the most parsimonious\nphylogenetic trees based on CE method, where an iterative optimization process is applied to reduce the\nparsimony score of a tree with the principle of cross entropy optimization. As discussed in [20, 31, 32], cross\nentropy (CE) method differs from other well-known random search algorithms for global optimization such"}, {"title": "3. Analysis of Riemann Hypothesis with Cross Entropy Optimization and Reasoning", "content": "Riemann Zeta function revisited. Riemann Zeta function, say \u03b6(s), is a function of a complex variable of\ns, where s = \u03c3 + it, with o and t being real numbers. Riemann Zeta function can be written as a converging\nsummation or as an integral when R(s) = \u03c3 > 1:\n\u22111/ns = 1/\u0393(s)\u222b0^\u221e xs-1ex/(ex-1)dx                                      (1)\nwhere \n\u0393(s) = \u222b0^\u221e xs-1e-xdx                                       (2)\nRiemann extended Riemann Zeta function beyond R(s) = \u03c3 > 1 to the whole complex plane by means of\nanalytic continuation with Riemann's functional equation that he discovered. The basic idea is to first\nestablish some functional equation on smaller domain, then using this functional equation to extend to the\nwhole complex domain.\nRiemann's functional equation. Riemann discovered that Riemann Zeta function satisfied the functional\nequation as follows:\n\u03b6(s) = 2^s\u03c0^(s\u22121)sin(\u03c0s/2)\u0393(1 \u2212 s)\u03b6(1 \u2212 s)                          (3)\nwhere \u0393(s) is the Gamma function indicated in Equation (2). Equation (3) is an equality of meromorphic\nfunctions that are valid on the whole complex plane. From Equation (3), we can observe that Riemann Zeta\nfunction (s) has the value of zeros when s = 2n, where s is even negative values due to the zero value of\nsin(\u03c0s/2). However, when s = 2n, where s is even positive values, the product of sin(\u03c0s/2)\u0393(1 \u2013 s) on the\nright side of the equation in Equation (3) is not zero. This is due to the fact that Gamma function of \u0393(1 \u2013 5)\nhas a simple pole, which cancels out the simple zero of the sine factor of sin(\u03c0s/2).\nPlease note that for random sampling of Riemann Zeta function in our proposed cross-entropy optimization\nand reasoning in the critical strip of {s \u2208 C : 0 < R(s) < 1}, we use Riemann's functional equation, i.e.,\nEquation (3), for arithmetic calculations of Riemann Zeta function value.\nCross entropy optimization and reasoning. The basic idea is that we examine the distribution of Riemann\nZeta function zeros in the critical strip region of {s \u2208 C : 0 < R(s) < 1} by random sampling of s in a\ngiven sub-region of the critical strip region based on some probability distribution of p(s) for the\ncomputation of Riemann Zeta function value of \u03b6(s) in an iterative process with cross entropy optimization\nand reasoning. The probability distribution of p(s) is updated after each round based on some performance\nmetric with respect to the distribution of Riemann Zeta function zeros in the critical strip region (see\nEquation (4) for details). If the number of random samples of s for each round is large enough and the\nnumber of iterations in cross entropy optimization and reasoning is big enough, probability convergence can\nbe observed with respect to the distribution of Riemann Zeta function zeros, which is the central point of\nRiemann Hypothesis. We use the application of Bernoulli's law of large numbers to guarantee that the\nobserved distribution of Riemann Zeta function zeros is asymptomatically approaching its probability. The\ntotal number of Riemann Zeta function zeros can be computed for a given region according to Turing method\n[19, 37]. We use the application of mathematical inductions to make sure that the whole complex plane can\nbe covered as conjectured in Riemann Hypothesis by organically expanding the examined sub-regions of the\ncritical strip region to the whole critical strip region and beyond.\nFollowing [21], we assume that the computation of Riemann Zeta function values are done with 32 or 64 bit\nfloating point numbers, where the output of each arithmetic operation is rounded to the closest floating point\nnumber representable by a fixed number of digits following IEEE 754 standard, avoiding the unrealistic\ninfinite precision assumptions during the calculation of the values of Riemann Zeta function of ((s) for\ns\u2208 C. We refer interested readers to [21] for details on the finite precision modeling for arithmetic\ncalculations.\nWe have some basic notations for the analysis of Riemann Hypothesis with cross entropy optimization and\nreasoning as follows:. Let f ((s)) stand for the performance metric for a given Riemann Zeta function value\nwith a given value of s and we have the following definitions of f ((s)):\nf(\u03b6(s)) = {1, if \u03b6(s) = 0 and R(s) = 1/2\n                -\u221e, if \u03b6(s) = 0 and R(s)\u2260 1/2\n                0, otherwise                                                    (4)\nwhere s is a complex number in the critical strip region, i.e., {s \u2208 C : 0 < R(s) < 1}.\nRecall that Riemann Zeta function of ((s) is a function of a complex variable of s, where s = \u03c3 + it, with \u03c3\nand t being real numbers. For a given sub-region of the critical strip region, where \u03c3 \u2208 (0, 1), t \u2208 [a, b]"}, {"title": "4. Application of Bernoulli's Law of Large Numbers", "content": "We use the application of Bernoulli's law of large numbers [2, 3, 6] to guarantee that when the number of\nrandom samples used in the cross entropy optimization and reasoning for the analysis of Riemann\nHypothesis is large enough, the frequency of the event that the value of Riemann Zeta function of ((s) is\nzero and the corresponding s is not located on the critical line of {s \u2208 C : R(s) = 1/2} is essentially\nasymptotically approaching to the probability of the event, where the total number of Riemann Zeta function\nzeros can be computed and the total number of zeros of Riemann Zeta functions for a given region is fixed\n[19, 37].\nLet u be the number of times that event A occurs during n independent trials and let p denote the probability\nthat event A occurs for every trial. According to Bernoulli's law of large numbers [2, 3, 6], for any positive\nreal number of e, we have\nlim n->\u221e Pr{|\u03bc/n \u2212 p | < \u03f5} = 1                                                                    (13)\nIn the case of the analysis of Riemann Hypothesis with cross entropy optimization and reasoning, event A is\nthe event that the value of Riemann Zeta function of ((s) is zero and the corresponding s is not located on the\ncritical line of {s \u2208 C : R(s) = 1/2}. The random sampling for the calculation of Riemann Zeta function in a\ngiven region can be described by the binomial distribution: either the value of Riemann Zeta function of ((s)\nis zero and the corresponding s is not located on the critical line of {s \u2208 C : R(s) = 1/2} or not. When a\ngiven region is fixed, the total number of Riemann Zeta function zeros can be computed and the total number\nof zeros of Riemann Zeta functions is fixed according to Turing method [19, 37]. So, for a given region, the\nprobability of p for the event that the value of Riemann Zeta function of ((s) is zero and the corresponding s\nis not located on the critical line of {s \u2208 C : R(s) = 1/2} exists and it is fixed. Therefore, Bernoulli's law of\nlarge numbers can be applied in this case."}, {"title": "5. Application of Mathematical Inductions", "content": "We use the application of mathematical indications to make sure that the whole complex plane is covered as\nconjectured in Riemann Hypothesis. For the sake of simplicity, let us first start from the critical strip region\nof {s \u2208 C : 0 < R(s) < 1}. The basic idea is to split the critical strip region into a series of contiguous\nsmaller unit square regions, then we apply the techniques of mathematical inductions to prove that the whole\ncomplex plane can be covered for the computation of Riemann Zeta functions and for the analysis of\nRiemann Hypothesis. The application of mathematical inductions is needed in our analysis on Riemann\nHypothesis with cross entropy optimization and reasoning as random samples of s for the computation of\nRiemann Zeta functions of ((s) with cross entropy optimization and reasoning are drawn from a fixed region\nand the whole complex plane has to be covered as conjectured in Riemann Hypothesis.\nAccording to Turing method in [19, 37], the total number of zeros, i.e., the total number of cases where the\nvalue of Riemann Zeta function of ((s) is zero, can be computed for Riemann Zeta function of ((s) for a\ngiven region. Using the critical strip region of {s \u2208 C : 0 < R(s) < 1} as an example, with the application\nof mathematical inductions, we show that the total number of zeros of Riemann Zeta functions can be\ncomputed for any given region across the whole complex plane and the total number of zeros of Riemann\nZeta functions for any given region across the whole complex plane is fixed."}, {"title": "6. Enhanced Top-p Sampling with LLMs for Reasoning", "content": "Mathematical reasoning capabilities of large language models (LLMs) can be improved with chain of\nthought (CoT) annotations and reinforcement learning [1, 7, 18, 21, 24, 34, 39-41]. In general, there are\nmainly two stages in which we can make further enhancement by adding diversity, i.e., more degree of\nfreedom, in terms of either training paths or inference paths for large language models (LLMs). In the\ntraining stage, multiple reasoning paths with multiple valid chain of thought (CoT) annotations for the same\nquestion can be explored. On the other hand, for the inference stage, the chain of thought (CoT) generation\nprocess can be decomposed into a sequence of next token prediction actions and multiple chain of thoughts\n(CoTs) can be generated for the same question during the intermediate reasoning process to further enhance\nthe reasoning capabilities of large language models (LLMs). In this paper, we only focus on the inference\nstage. Let e stand for a chain of thought (CoT) process with a sequence of next token prediction actions of\na1,a2,...,a,, the accumulated path probabilities of pe can be expressed as:\npe = pa\u2081 \u00d7 pa2X ... \u00d7 par                                                    (14)\nwhere pa, is the next token probability at the ith step of next token prediction action.\nNotably, top-p sampling method is widely used for next token prediction in Transformer-based [38] large\nlanguage models due to its superior performance over greedy search, beam search, top-k sampling (choosing\nk most likely tokens) and others. Here is how it works: in top-p sampling method, it chooses from the\nsmallest possible set of tokens whose cumulative probability exceeds the probability p. The probability mass\nis then redistributed among this set of tokens by means of normalization. This way, the number of chosen\ntokens can dynamically change based on the next token's probability distribution.\nIn the following, we present the method of enhanced top-p sampling with large language models (LLMs) for\nreasoning, in particular for the generation of the action sequence in multiple chain of thoughts (CoTs), where\nnext token prediction is not just based on the estimated probabilities of each possible token in the current\nround but also based on accumulated path probabilities, i.e., chain of thought probabilities, among multiple\ntop-k paths as only k chain of thoughts (CoTs) paths are kept during the intermediate reasoning process.\nRecall that for a decoder-only Transformer-based [38] large language model (LLM) system, a language"}, {"title": "7. Summary and Future Directions", "content": "It has been 165 years since Bernhard Riemann presented his famed Riemann Hypothesis in his landmark\npaper [27]. Despite numerous notable attempts by some of the best minds in recent history, Riemann\nHypothesis remains unsolved till today. As discussed in [25] that the truth of Riemann Hypothesis might\neventually depend on the techniques of a mixture of analytic and arithmetic ingredients. In this paper, we\npresent a novel framework for the analysis of Riemann Hypothesis, which is composed of three key\ncomponents: a) probabilistic modeling with cross entropy optimization and reasoning; b) the application of\nthe law of large numbers; c) the application of mathematical inductions. The analysis is mainly conducted by\nvirtue of probabilistic modeling of cross entropy optimization and reasoning with rare event simulation\ntechniques. The application of the law of large numbers [2, 3, 6] and the application of mathematical\ninductions make the analysis of Riemann Hypothesis self-contained and complete to make sure that the\nwhole complex plane is covered as conjectured in Riemann Hypothesis. We discuss finite precision modeling\nin terms of the computation of the value of Riemann Zeta functions from a practical perspective with respect\nto the quantization modeling and the number of bits for the variables commonly used in today's computing\nfacilities. We also discuss the method of enhanced top-p sampling with large language models (LLMs) for\nreasoning, where next token prediction is not just based on the estimated probabilities of each possible token\nin the current round but also based on accumulated path probabilities among multiple top-k chain of thoughts\n(CoTs) paths. Essentially, we propose the use of a combination of top-p sampling method and beam search\nwith a beam width of k for chain of thoughts (CoTs) reasoning with large language models (LLMs). The\nprobabilistic modeling of cross entropy optimization and reasoning may suit well with the analysis of\nRiemann Hypothesis as Riemann Zeta functions are inherently dealing with the sums of infinite components\nof a complex number series.\nWe will conduct extensive simulations for the analysis of Riemann Hypothesis with cross entropy\noptimization and reasoning for the validation of the distribution of Riemann Zeta function zeros as our future\ndirections. We will also conduct extensive experiments to explore multiple chain of thoughts (CoTs) paths\nfor the use of a combination of top-p sampling method in next token prediction actions and beam search with\na beam width of k for chain of thoughts (CoTs) reasoning with large language models (LLMs) during\nintermediate reasoning process as one of our future endeavors.\nThe framework of cross entropy optimization and reasoning for the analysis of Riemann Hypothesis\npresented in this paper, coupled with recent developments with chain of thought (CoT) or diagram of thought\n(DoT) reasoning in large language models (LLMs) with reinforcement learning (RL) [1, 7, 18, 21, 24, 34,\n39-41], could pave the way for eventual proof of Riemann Hypothesis [27]."}]}