{"title": "AI-Augmented Ethical Hacking: A Practical Examination of Manual Exploitation and Privilege Escalation in Linux Environments", "authors": ["Haitham S. Al-Sinani", "Chris J. Mitchell"], "abstract": "This study explores the application of generative AI (GenAI) within manual exploitation and privilege escalation tasks in Linux-based penetration testing environments, two areas critical to comprehensive cybersecurity assessments. Building on previous research into GenAI's role in the ethical hacking lifecycle, this paper presents a hands-on experimental analysis conducted in a controlled virtual setup to evaluate GenAI's utility in supporting these crucial, often manual, tasks. Our findings demonstrate that GenAI can streamline processes, such as identifying potential attack vectors and parsing complex outputs for sensitive data during privilege escalation. The study also identifies key benefits and challenges associated with GenAI, including enhanced efficiency and scalability, alongside ethical concerns related to data privacy, unintended discovery of vulnerabilities, and potential for misuse. This work contributes to the growing field of AI-assisted cybersecurity by emphasising the importance of human-AI collaboration, especially in contexts requiring careful decision-making, rather than the complete replacement of human input.", "sections": [{"title": "Introduction", "content": "Ethical hacking [15] is a fundamental component of contemporary cybersecurity, yet it remains a highly time-intensive and resource-demanding field. The process requires not only advanced technical expertise but also ongoing knowledge updates to anticipate rapidly evolving threats. Traditional ethical hacking approaches involve significant human input across all stages from reconnaissance to vulnerability scanning and exploitation-thus increasing both the time and costs associated with security assessments.\nMoreover, ethical hacking efforts rely heavily on skilled professionals to effectively identify and exploit vulnerabilities, which poses a challenge in meeting the demands of increasingly complex and large-scale environments. The limited capacity of human operators, without substantial investments in training and resources, restricts the scalability and efficiency of these operations.\nThe integration of AI technologies, particularly generative AI (GenAI), offers promising solutions to these challenges by automating and enhancing various aspects of ethical hacking. Tools such as ChatGPT3 [6] enable ethical hackers to streamline repetitive tasks, make quicker decisions, and reduce the extent of human intervention typically required. This approach addresses time and capacity limitations while lowering implementation costs. Notably, GenAI has lowered the barrier to entry in the field, allowing younger or less experienced individuals to practice ethical hacking with greater ease and effectiveness than previous generations. GenAI's capabilities in data analysis, real-time insight generation, and workflow optimisation contribute to more efficient and cost-effective security assessments.\nThis report presents an in-depth experimental study evaluating the practical use of GenAI within a controlled, Linux-based virtual environment. By simulating key stages of ethical hacking, such as reconnaissance, scanning, gaining, escalating and maintaining access, and covering tracks, this study illustrates the potential of GenAI to enhance these processes and strengthen cybersecurity defences. The findings and insights documented here add to the ongoing discussion surrounding AI-human collaboration in cybersecurity, highlighting GenAI's ability to improve efficiency and reduce costs, while underscoring the importance of expert oversight.\nWhile previous research has broadly explored the role of GenAI in cybersecurity, this report specifically investigates its application in manual exploitation and privilege escalation within Linux-based environments - frequent targets in both penetration testing and real-world attacks. This work builds on our previously published research, where we proposed a conceptual model that leverages GenAI capabilities to support ethical hackers across the five stages of ethical hacking [4]. It also extends a proof-of-concept implementation used to conduct experimental studies on the integration of GenAI into ethical hacking on both Windows machines [3] and Linux-based VMs [2]. While our previous work holistically examined GenAI's practical application across the five stages of ethical hacking, using automated tools like Metasploit - particularly in the exploitation phase it did not incorporate any analysis of manual exploitation techniques or privilege escalation.\nManual exploitation is critical in real-world scenarios where initial automated tools may be inadequate, and privilege escalation is typically essential, as initial access usually grants only standard user-level privileges. Escalating these privileges to administrator or root access is often necessary to proceed with further ethical hacking tasks, such as maintaining access. This report addresses these gaps by focusing on manual exploitation techniques and privilege escalation, offering a detailed examination of GenAI's application in these specific areas.\nThe remainder of this document is organised as follows. Section 2 explores GenAI and ChatGPT. Section 3 presents the laboratory setup, and section 4"}, {"title": "Generative AI and ChatGPT", "content": "The advent of GenAI, with models like ChatGPT4 [6] being prominent, represents a major shift in the AI landscape. These systems, moving beyond the traditional AI focus on pattern recognition and decision-making, excel in content creation, including text, images, video, and code. The ability to learn from extensive datasets and produce outputs that mimic human creativity is a major advance.\nCentral to this revolution is the GPT (Generative Pre-trained Transformer) architecture, the basis of models like ChatGPT. Developed by OpenAI, GPT models are built on deep learning techniques using transformer models, designed specifically for handling sequential data. These models undergo pre-training, where they learn from a wide array of various resources, including Internet texts, followed by fine-tuning for specific tasks. This process enables models to grasp not just the structure of language but also its context, essential for generating human-like text.\nEach iteration of ChatGPT has demonstrated enhanced contextual understanding and output relevance. Its primary function lies in interpreting user prompts and generating coherent, contextually appropriate responses. This versatility extends from conducting conversations to performing complex tasks, including coding, content creation, and, as we propose in this report, ethical hacking. The GPT model family, including ChatGPT, owes much of its success to the transformer model, introduced by Vaswani et al. in 2017 [16]. This architecture revolutionises sequence processing through attention mechanisms, enabling the model to focus on different parts of the input based on its relevance to the task.\nThe latest iteration, GPT-4o5, provides significant advances in speed, multimodal capabilities, and overall intelligence. GPT-4o, now available to a broader user base, including free-tier users, improves upon the GPT-4 model by offering enhanced performance in understanding and generating text, as well as new capabilities in processing voice and images. These improvements position GPT-4o as a powerful tool not only in natural language processing but also in applications such as real-time communication and data analysis, making it a key asset in modern cybersecurity practices.\nIn exploring the intersection of AI and cybersecurity, understanding ChatGPT's foundational aspects is vital. Its generative nature, contextual sensitivity, and adaptive learning capacity can lead to innovative approaches in cybersecurity practices. Our focus will be on how these qualities of ChatGPT can be"}, {"title": "Laboratory Setup", "content": "The experiments used a standard MacBook Pro with 16 GB RAM, a 2.8 GHz Quad-Core Intel Core i7 processor, and 1 TB of storage, providing sufficient computational capabilities for virtualisation (see Figs. 1 and 2).\nVirtualisation of the network was achieved using VirtualBox 7 (see Fig. 3), a reliable tool for creating and managing virtual machine environments. The virtual setup included the following VMs.\n1. Kali Linux VM: this machine functioned as the primary attack platform for conducting the penetration tests. It is equipped with the necessary tools and applications for ethical hacking.\n2. Windows VM: this machine, running a 64-bit version of Windows Vista with a memory allocation of 512 MB, was the principal target for penetration testing within a previously conducted experiment [3].\n3. Linux VM 1: this 64-bit Debian Linux system, allocated 512 MB of memory, is one of the main targets in this study and is configured as a primary focus for various ethical hacking phases.\n4. Linux VM 2: another 64-bit Linux-based system with 1024 MB of memory allocation, this VM serves as an additional target in this report, providing an alternative focus for specific penetration testing tasks..\nThe network configuration was established in a local NAT (Network Address Translation) setup, allowing for seamless communication between the VMs and simulating a realistic network environment suitable for penetration testing (see Fig. 4).\nThe experiments leveraged ChatGPT-4o6 (a paid version) for its advanced AI capabilities and efficient response time. The selection of ChatGPT-4 was also based on its prominent status as a leading GenAI tool, offering cutting-edge technology to enhance the ethical hacking process. Of course, other GenAI tools are also available, e.g. Google's Bard7 and GitHub's Co-Pilot8, which could potentially be used in similar contexts. The methodologies and processes described are applicable to both the paid and free versions of ChatGPT, with the paid version chosen for improved performance in this study."}, {"title": "Methodology", "content": "The experiment followed the structured phases of ethical hacking listed below, with ChatGPT's guidance integrated at each step.\n1. Reconnaissance: ChatGPT was used to gather and analyse information about the target VMs, including scanning to discover live machines.\n2. Scanning and Enumeration: Network and vulnerability scanning were conducted using tools such as nmap, with ChatGPT helping to interpret the scan results and identify potential vulnerabilities.\n3. Gaining Access (Linux VM1 and VM2): This phase emphasised manual exploitation tactics to gain initial access to the target VMs. ChatGPT provided guidance on selecting suitable manual exploitation methods based on detected vulnerabilities, enabling targeted attack sequences for both Linux VM1 and VM2.\n4. Maintaining & Elevating Access: ChatGPT suggested strategies for maintaining access post-exploitation, such as creating persistent backdoors. Additionally, the model assisted in identifying privilege escalation opportunities within the compromised system. GenAI's support included recommending methods for privilege escalation to root-level access, which was essential for further exploration and control over the system.\n5. Covering Tracks & Documentation: In this phase, ChatGPT advised on strategies to effectively erase traces of the penetration test, thereby reducing the likelihood of detection by system administrators. This included log manipulation and account removal. Additionally, ChatGPT assisted in documenting the ethical hacking process, ensuring comprehensive reporting of methodologies, findings, and recommendations for enhancing system security.\nWe initiated the experiment by asking ChatGPT to provide a concise explanation of the five ethical hacking stages, along with a list of commonly used Kali commands for each stage. ChatGPT provided an informative response, as illustrated in Fig. 5."}, {"title": "Execution", "content": "In this phase, we followed the same procedure as detailed in our previous research work [2]. In summary, reconnaissance can be either passive (observing without interaction) or active (direct engagement for information). In this study, we emphasised active reconnaissance, following a systematic approach to identify potential targets in the network. Initially, we informed ChatGPT about our"}, {"title": "Scanning & Enumeration", "content": "In this phase, we followed a similar procedure as detailed in our previous research work [2]. We began by consulting ChatGPT to determine the most suitable commands to scan our target Linux system (IP address 192.168.1.7) for vulnerabilities, including port and vulnerability scanning, using our Kali machine. ChatGPT recommended an nmap command (\u2018nmap -p- -A -T4 -oA scan_results 192.168.1.7 192.168.1.10') that scans all TCP ports, enables OS and version detection, performs script scanning and traceroute, and saves the output in multiple formats for thorough analysis. We executed this command, which provided extensive information about the two targets (see Figs. 7 and 37), helping us prepare for the next phase of gaining unauthorised access."}, {"title": "Gaining Access", "content": "In this phase, we sought guidance from ChatGPT to gain access to our target Linux VMs using our Kali attack VM, as detailed below.\nWe first requested ChatGPT to analyse the nmap scan output (see Fig. 7), and present it in a concise table format, focusing on the following categories: 'Port Number', 'Running Service', 'Potential Issues', 'Steps for Exploitation', and \u2018Kali Commands' (see Figs. 8 and 9). ChatGPT provided the requested analysis (see Fig. 10).\nChatGPT's analysis of the nmap scan identified several potential attack vectors on the target machine, as follows.\nFTP (Port 21): Anonymous login was enabled, granting access to files like note.txt.\nHTTP (Port 80): The server displayed the default Apache page, suggesting potential vulnerabilities in Apache 2.4.38. Further exploitation could involve directory enumeration or testing for common web vulnerabilities.\nSSH (Port 22): While no immediate vulnerabilities were evident, brute-forcing weak credentials or exploiting potential issues in OpenSSH 7.9p1 could be pursued for access."}, {"title": "Gaining Access to VM 1: 192.168.1.7", "content": "We requested ChatGPT to provide step-by- step instructions for retrieving the 'note.txt' file via anonymous FTP in a concise table format. ChatGPT accurately delivered the instructions (see Fig. 11).\nIn summary, we followed a simple, step-by-step approach to access the 'note.txt' file via anonymous FTP. First, we connected to the target FTP service using the command ftp 192.168.1.7 and logged in as an anonymous user. After listing the available files in the FTP directory using 1s, we downloaded the 'note.txt' file with the get command. Finally, we viewed the file's contents using cat note.txt (see Fig. 13), and closed the session with bye (see Fig. 12).\nWe then asked ChatGPT to analyse the contents of the 'note.txt' file to assist us in gaining access. ChatGPT provided the following analysis. In summary, the note.txt file provides several key insights that can be leveraged for further exploitation. It contains a hashed password (cd73502828457d15655bbd7a63fb0bc8), likely MD5, which can be cracked using tools like Hashcat or John the Ripper. To crack the hash using Hashcat, the following command can be used:\nhashcat -m 0 -a 0 cd73502828457d15655bbd7a63fb0bc8 rockyou.txt\nwhere:\n-m 0 specifies the hash type, with 0 indicating MD5;\n-a 0 sets the attack mode to dictionary, comparing the target hash against entries in a wordlist (rockyou.txt);\ncd73502828457d15655bbd7a63fb0bc8 is the MD5 hash to be cracked; and\nrockyou.txt: is the wordlist file used in the attack, containing common passwords.\nThis command instructs hashcat to hash each entry from rockyou.txt with MD5 and check if it matches the target hash. If successful, it reveals the original password.\nThe note also reveals a SQL INSERT statement, suggesting the application may be vulnerable to SQL Injection. Additionally, the file provides a StudentRegno (10201321) and pincode (777777), which could be used for login attempts. Key actions include cracking the hash, testing for SQL injection, and exploring potential vulnerabilities in the open-source project.\nFollowing ChatGPT's guidance, we successfully cracked the MD5 hash using the Hashcat command, which revealed the password: student (see Fig. 14). This password is likely to prove useful in later stages of the exploitation process."}, {"title": "HTTP Attack Vector (Port 80)", "content": "With the hash successfully cracked, our focus shifted towards gaining access via port 80, the HTTP service. We consulted ChatGPT for the next steps to access the target VM, which provided a structured approach (see Fig. 15). The recommended steps are as follows.\n1. Open a browser and visit http://192.168.1.7 to access the target's web application.\n2. Navigate to the login page (e.g., /login).\n3. Use the StudentRegno (10201321) and the cracked password (student) to log in.\n4. Explore the web application for potential vulnerabilities, such as file uploads, admin functions, or sensitive data.\n5. Attempt SSH login using student@192.168.1.7 and the cracked password.\n6. Once logged in, run sudo -1 to check for sudo privileges.\n7. Explore the filesystem to identify sensitive files or misconfigurations for privilege escalation.\nHowever, when we followed these steps, we were unable to locate the login page. As a result, we consulted ChatGPT again for guidance. This time, ChatGPT recommended scanning the website for hidden directories, such as login or admin pages, using tools like dirb or gobuster (see Fig.16). After experimenting with the dirb command, we chose to proceed with gobuster. Following ChatGPT's instructions (see Fig.17), we ran the command:\ngobuster dir -u http://192.168.1.7 -w directory-list-2.3-medium.txt\nwhere:\ngobuster is the tool used for brute-forcing web directories and files;\ndir specifies directory brute-forcing mode;\n-u http://192.168.1.7 is target URL for the scan (u: URL); and\n-w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt is the path to the wordlist used for directory and file name guessing (w: wordlist).\n(see Fig. 18). Gobuster successfully discovered three hidden directories on the site: uploads, academy, and phpmyadmin, which could be accessed by appending the directory names to the site URL, e.g.: http://192.168.1.7/academy/.\nAfter conducting initial reconnaissance on the three discovered website directories, we decided to explore the academy path (http://192.168.1.7/ academy/). Here, we found an online login form for what appeared to be academy-related courses. We captured a screenshot of the login form and shared it with ChatGPT, asking for guidance on which credentials to use. ChatGPT correctly recommended the credential pair (10201321 & student), which it deduced from the note.txt file and the previously cracked hash (see Fig. 19). As a result, we successfully logged in.\nFollowing this, we consulted ChatGPT for the next steps (see Fig. 20). We encountered a profile editing page that allowed users to upload a profile picture,"}, {"title": "Elevating Access: VM 1", "content": "To assist us in elevating our access level, we turned to ChatGPT for guidance, which provided several valuable suggestions (see Figs. 22 and 23).\nSince we only had limited access through the www-data user account, we didn't have the necessary privileges to view the hashed passwords stored in the /etc/shadow file. However, we were able to view the password file (/etc/passwd), where we discovered a user named grimmie (see Fig. 24). We then navigated to the home directory of grimmie by using the /home/grimmie path from the password file. Upon listing the contents, we discovered a file named backup.sh (see Fig. 25).\nNext, we used the command cat /etc/crontab to check for any cron jobs automated tasks scheduled to run at specific intervals by the system, such as running backups or updating logs. We found that the backup.sh script was scheduled to execute every minute (see Fig. 26). After consulting ChatGPT about the significance of this finding, it highlighted that since backup.sh runs with the permissions of the owner (grimmie), this could serve as a potential privilege escalation vector. If we could modify the contents of the script, we could insert a reverse shell or other malicious commands, which would be executed with grimmie's privileges by the cron job every minute (see Fig. 27).\nHowever, we found that we were unable to modify the file due to insufficient privileges. ChatGPT confirmed that only the owner grimmie or someone with higher privileges like root could modify the file (see Fig. 28).\nTo proceed, we needed to escalate from our limited www-data account to the potentially higher-privileged grimmie account in order to enable us to modify the backup.sh script. We revisited ChatGPT's original suggestions for privilege escalation (see Fig. 23). One key recommendation was to use LinPEAS, a script designed for automated privilege escalation scans, identifying misconfigurations or vulnerabilities in Linux systems. We asked ChatGPT for detailed guidance on using LinPEAS, which it provided (see Fig. 29).\nIn summary, we used LinPEAS to enumerate potential privilege escalation vectors on the target machine. First, we downloaded the LinPEAS script onto our Kali attack platform using the command wget https://github.com/ carlospolop/PEASS-ng/releases/latest/download/linpeas.sh. To facilitate the transfer of the script to the target, we started a simple HTTP server on our Kali VM using the command python3 -m http.server 8000. This made the LinPEAS script accessible to the target machine via HTTP. On the target, we navigated to the /tmp directory, a commonly writable location, by executing cd /tmp. We then downloaded LinPEAS onto the target using wget http://192.168.1.4:8000/linpeas.sh, where 192.168.1.4 is the IP address of our Kali machine. Once the script was downloaded, we set the executable permissions with chmod +x linpeas.sh and ran the script using ./linpeas.sh. This process enabled us to gather detailed information on potential privilege escalation opportunities within the target system.\nThe output from LinPEAS is structured and visually formatted, but it is also exceedingly detailed and typically very lengthy (see Fig. 30), making it"}, {"title": "Elevating Access: VM 2", "content": "Our initial attempts to escalate privileges on VM2 (192.168.1.10) began by consulting ChatGPT, which suggested several approaches (see Fig. 69). While ChatGPT is generally a valuable tool, these initial attempts failed to achieve the desired escalation (see Figs. 71 and 72). Recognising the need for an alternative approach, we leveraged our expertise and asked ChatGPT about a well-known resource that documents privilege escalation techniques involving Unix binaries. ChatGPT correctly identified this resource as GTFOBins (see Fig. 73), which maintains a curated list of binaries that can be exploited when given specific sudo permissions.\nArmed with this knowledge, we manually navigated to GTFOBins (https://gtfobins.github.io/) and found the entry for the zip command when executable with sudo privileges. Following the guidance provided on the site, we applied the necessary commands:\nCreate a Temporary File and Run Zip with Sudo: We executed TF=$(mktemp -u); sudo zip $TF /etc/hosts -T -TT 'bash #' (see Fig. 74), leveraging zip to spawn a root shell by specifying an arbitrary command (bash) via the -TT option."}, {"title": "Maintaining Access", "content": "In this phase, our objective is to ensure we can re-enter the target system in the future, ideally without detection. Achieving persistent access typically requires elevated privileges, such as administrator or root access. Fortunately, as detailed in the previous section, we successfully obtained root access (see Fig. 75), providing us with the highest level of control over the system.\nFor this stage, we followed the same procedures outlined in our earlier research [2]. In brief, we consulted ChatGPT for guidance on maintaining persistent access. In response to our query (see Fig. 76), ChatGPT offered a range of recommendations for establishing persistent access in Linux machines (see Fig. 77). These suggestions included creating a new root user for alternative access, setting up a persistent reverse shell, installing an SSH key for passwordless access, configuring a cron job for regular reverse shell connections, and backing up important files. Further details on some of these techniques are available in our prior work [2]."}, {"title": "Covering Tracks and Documentation", "content": "This (final) ethical hacking phase has two main components:\n1. covering our tracks, which involves erasing or minimising evidence of our activities within the target system, crucial to avoid detection and maintain the system as close to its original state as possible; and\n2. documentation, involving creating the pen-test report, a topic discussed later.\nCovering Tracks In this phase, we followed the procedures outlined in our previous research [2] to ensure our activities remain covered. For guidance, we consulted ChatGPT, which provided a structured list of actions to effectively"}, {"title": "Discussion: Benefits, Risks and Limitations", "content": "Ethical hacking, a critical component of comprehensive security strategies, is a promising arena for the application of advanced AI systems like ChatGPT. Using the generative and understanding capabilities of ChatGPT we can envision a paradigm shift in how security assessments and penetration tests are conducted.\nThe interactive nature of ChatGPT positions it as a supportive assistant for real-time problem-solving during penetration testing. Ethical hackers can consult the model for troubleshooting, brainstorming exploitation strategies, or learning about novel vulnerabilities and techniques on the fly. For instance, in the Gaining Access phase, ChatGPT provided detailed guidance for exploiting vulnerabilities in VM1 based on nmap scan results.\nChatGPT's extensive knowledge base also served as a valuable reference for the latest Common Vulnerabilities and Exposures (CVEs), enhancing responsiveness in identifying and addressing security risks. In the Scanning & Enumeration phase, for example, ChatGPT analysed nmap results and provided insights on service versions, such as OpenSSH 7.9p1, which could potentially have known vulnerabilities. It also suggested exploring misconfigurations in Apache HTTP and NFS services and identifying possible vulnerabilities in Bolt CMS running on VM2. This guidance directed the focus toward exploitable services and associated CVEs, making the assessment process more efficient.\nBeyond just vulnerability identification, ChatGPT's real-time problem-solving capabilities proved invaluable in troubleshooting exploitation issues. When the initial PHP reverse shell upload attempt on VM1 did not yield a connection, ChatGPT recommended using BurpSuite to identify the specific URL path of the uploaded shell file, which ultimately led to successful shell access. Similarly, in VM2, after gaining access to the NFS service and retrieving a protected zip file, ChatGPT guided the process of cracking the zip's password using John the Ripper and converting the zip file to a hash for this purpose, which revealed critical credentials. This step-by-step guidance proved especially useful in overcoming challenges that required quick adaptation.\nFurthermore, ChatGPT's command recommendations improved the agility and responsiveness of penetration testing efforts. It consistently suggested efficient commands for each phase, such as nmap and arp-scan for reconnaissance and hydra for brute-forcing, allowing testers to move seamlessly through stages without needing to experiment with multiple command syntaxes. This structured workflow carried into the privilege escalation phase, where ChatGPT recommended the use of LinPEAS to scan for privilege escalation paths in VM1 and GTFOBins for exploiting sudo permissions in VM2. By enabling a targeted approach to privilege escalation, ChatGPT significantly reduced time spent on trial and error, streamlining the overall workflow and maximising effectiveness.\nThese examples collectively demonstrate ChatGPT's value as a real-time, knowledgeable assistant. Its ability to provide structured, targeted guidance and reference up-to-date security knowledge empowers penetration testers to adapt swiftly and effectively to evolving testing scenarios, enhancing agility and responsiveness throughout the ethical hacking process.\nEfficient Data Extraction One of ChatGPT's most notable strengths in penetration testing engagements is its ability to sift through extensive, complex data and rapidly extract critical pieces of sensitive information. This capability was"}, {"title": "Potential Risks", "content": "However, when integrating AI, particularly Chat-GPT, into ethical hacking, a thorough examination of ethical considerations is essential. Using AI in cybersecurity aids efficiency and effectiveness but also raises serious concerns around data privacy, informed consent, and potential misuse. For example, during the privilege escalation phase, ChatGPT analysed LinPEAS output, which contained highly sensitive system details and configuration data. Without careful handling, AI-driven analysis of such data could expose sensitive information, thus necessitating strict data privacy guidelines and adherence to legal frameworks governing data use.\nThe reliance on advanced AI systems like ChatGPT poses risks, such as the unintentional discovery and exploitation of zero-day vulnerabilities. In one case, ChatGPT flagged specific vulnerabilities in SSH and HTTP services that could potentially serve as undisclosed attack vectors. Its ability to identify and exploit such entry points highlights the need for careful oversight to ensure that these vulnerabilities are responsibly disclosed to avoid accidental exposure to malicious actors before they are patched. This could inadvertently provide malicious actors with powerful tools to exploit these vulnerabilities before they are known to the broader security community. Moreover, the automation of processes like social engineering by AI raises significant ethical questions. For example, ChatGPT's ability to craft custom reverse shell payloads and develop structured exploitation sequences illustrates its potential to automate complex tasks, which, if misused, could enable highly targeted and sophisticated attacks.\nAI systems inherently process vast amounts of data, some of which may be sensitive or personal, thus their use necessitates strict adherence to data privacy laws and ethical guidelines. In the experiments, ChatGPT's guidance was sought on highly specific details, such as examining configuration files (config.yml) and analysing sensitive system settings, reinforcing the importance of compliance with data protection standards to prevent misuse of such information. Ensuring that the data used for training and operation is in compliance with privacy laws and ethical guidelines becomes paramount to maintaining the integrity of cybersecurity efforts. The ethical hacking principles of \"legality, non-disclosure, and intent to do no harm\" must be rigorously upheld in the AI domain to prevent unauthorised or unintended use. In the LinPEAS analysis and post-exploitation phases, where ChatGPT advised on privilege escalation and log-clearing commands, maintaining these ethical boundaries was crucial to ensuring that actions adhered to the ethical scope of testing."}, {"title": "Limitations and Future Research Directions", "content": "This study highlights ChatGPT's potential as an AI assistant in penetration testing, but several limitations need to be acknowledged to contextualise the findings accurately and to outline directions for future research.\nAlthough ChatGPT assisted across the standard phases of the penetration testing process, its performance was only evaluated within a limited scope of ethical hacking techniques. Due to the complexity and time constraints of penetration testing, not all potential AI-driven capabilities (e.g., advanced vulnerability analysis, lateral movement, and comprehensive post-exploitation tasks) were explored in depth. As a result, while ChatGPT proved highly beneficial in initial reconnaissance, scanning, exploitation, privilege escalation, covering tracks and documentation, further studies are needed to assess its utility in more advanced testing tactics and to evaluate how it interacts with other commonly used security tools.\nChatGPT's guidance is limited by the model's pre-existing training data, which may not include recent vulnerabilities, software updates, or specific niche hacking techniques. This limitation can affect the relevance and accuracy of the assistance provided, as demonstrated by instances where ChatGPT suggested deprecated commands or configurations. Additionally, ChatGPT may occasionally produce \"hallucinations\" or inaccurate responses, which require human oversight to validate and correct, as seen in our troubleshooting processes. This limitation highlights the need for cautious reliance on AI in critical security tasks.\nThis study was conducted in a controlled, virtual lab environment with two specific Linux VMs as targets. While this setup provided a structured approach to evaluate ChatGPT's capabilities, it inherently limits the generalisability of the findings. However, our previous research has explored the integration of GenAI tools in ethical hacking activities against Windows-based targets ([3], [4]). Real-world environments are more complex, typically involving a broader range of operating systems, such as macOS and Android, varied network configurations, and defensive mechanisms that may affect ChatGPT's effectiveness. Future studies could incorporate more diverse and realistic setups to better assess ChatGPT's performance across different security landscapes."}, {"title": "Related Work", "content": "The intersection of AI and cybersecurity is a highly active area of research, with studies ranging from Al's role in detecting intrusions to aiding in offensive security including ethical hacking. The rise of sophisticated language models like GPT-3, introduced by Brown et al. [6], has expanded research possibilities by enabling strong performance on various tasks, including of course cybersecurity as we show in this report. Handa et al. [10] review the application of machine learning in cybersecurity, emphasising its role in areas like zero-day malware detection and anomaly-based intrusion detection, while also addressing the challenge of adversarial attacks on these algorithms. Other studies, including that by Gupta et al. [9], examine the dual role of GenAI models like ChatGPT in"}, {"title": "Conclusions and Directions for Further Research", "content": "In this study, we have proposed an approach to enhancing ethical hacking by leveraging GenAI to support manual exploitation and privilege escalation within Linux-based environments. Through a structured experimental approach, we demonstrated how GenAI can assist penetration testers by efficiently identifying vulnerabilities, parsing complex outputs, and providing real-time guidance on exploitation techniques. Our findings underscore GenAI's potential to enhance penetration testing by reducing time spent on repetitive tasks and offering real-time guidance on complex exploitation and post-exploitation techniques. However, the study also highlights the importance of maintaining a careful balance between AI assistance and human oversight, ensuring that AI tools are used to complement rather than replace -human expertise in cybersecurity.\nThis research contributes valuable insights into GenAI's capabilities in ethical hacking, yet further research is needed to evaluate its effectiveness across a broader array of operational contexts. Future studies should explore GenAI's application in more diverse and complex environments, including macOS, Android, and iOS systems, to assess its adaptability and robustness. Extending GenAI's utility to encompass other cybersecurity domains, such as wireless security, OWASP top 10 vulnerabilities12, and mobile app security13, would broaden its applicability and value for ethical hacking and security assessments.\nFinally, addressing the ethical implications of GenAI in cybersecurity remains a critical area of focus. Future research should aim to establish frameworks that ensure data privacy, informed consent, and responsible use, while also mitigating challenges such as potential biases, over-reliance on AI, and unintended consequences of AI-driven automation. Through these ongoing efforts, we aim to create a secure and ethical foundation for AI integration in cybersecurity, enhancing its resilience and effectiveness amid evolving cyber threats."}]}