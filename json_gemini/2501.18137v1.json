{"title": "Tensor Completion for Surrogate Modeling of Material Property Prediction", "authors": ["Shaan Pakala", "Dawon Ahn", "Evangelos Papalexakis"], "abstract": "When designing materials to optimize certain properties, there are often many possible configurations of designs that need to be explored. For example, the materials' composition of elements will affect properties such as strength or conductivity, which are necessary to know when developing new materials. Exploring all combinations of elements to find optimal materials becomes very time consuming, especially when there are more design variables. For this reason, there is growing interest in using machine learning (ML) to predict a material's properties. In this work, we model the optimization of certain material properties as a tensor completion problem, to leverage the structure of our datasets and navigate the vast number of combinations of material configurations. Across a variety of material property prediction tasks, our experiments show tensor completion methods achieving 10-20% decreased error compared with baseline ML models such as GradientBoosting and Multilayer Perceptron (MLP), while maintaining similar training speed.", "sections": [{"title": "1 Introduction", "content": "Material property prediction is a crucial aspect of designing new materials, in order to design a material with optimal properties. This includes designing strong materials (Gongora et al. 2024), magnetic materials (Wang et al. 2020), and semiconductor materials (Haghshenas et al. 2024). Machine learning (ML) is becoming a very prominent technique for this problem, and we see both composition-based (using the chemical formula) and structure-based (using the structure) material property prediction (Gongora et al. 2024; Hu et al. 2024; Li et al. 2024). Among the material properties being predicted, there is a lot of attention around predicting band gap, which directly affects the conductivity of materials (Alsalman, Alqahtani, and Alharbi 2023; Hu et al. 2024). This is very useful in fields such as semiconductor development, where knowing the conductivity is crucial. There is also work on predicting the formation energy (Jha et al. 2019; Xie and Grossman 2018; Jha et al. 2022). We also see prediction of magnetism, which is important for designing materials with ideal magnetic properties (Li, Shan, and Shek 2022).\nUnfortunately, issues tend to arise with a lack of training data (Xin et al. 2021), as is typical in any ML problem, especially when deep learning is introduced. In this work, we use tensor completion algorithms, designed for sparse datasets, to infer a material's properties (Sidiropoulos et al. 2016). We model material property prediction tasks as tensors. This allows us to use tensor completion for composition-based material property prediction, where we use the chemical formula to predict material properties. By leveraging tensor completion algorithms, we take advantage of the structure of our datasets to infer material property values."}, {"title": "2 Methods", "content": "Here we outline our methods for dataset generation and tensor completion for materials' property prediction."}, {"title": "2.1 Tensor Dataset Generation", "content": "To generate tensors used for our experiments, each tensor mode corresponds to either a unique element in the material, or the amount of each unique element in the material. An example fourth order tensor is shown below. The highlighted value represents the chemical formula AuBr5."}, {"title": "2.2 Tensor Completion for Materials Design", "content": "By using tensor completion, we leverage the inherent structure in our multidimensional datasets to predict the results of the entire space of combinations, using few training values.\nTensor Decomposition Tensor decomposition is a key technique to extract information from tensor data. For example, CPD (Canonical Polyadic Decomposition) (Harshman 1970) is a common approach, factoring the tensor into the sum of rank 1 tensors. Tensor decomposition is crucial for tensor completion, which fills in a tensor's missing values.\nTensor Completion Models In our experiments, we use a variety of tensor completion models. These include CPD (Harshman 1970), CPD-S (Pakala et al. 2024; Ahn, Jang, and Kang 2021), and NeAT (Ahn et al. 2024).\nPerformance Evaluation We randomly sample train values, using the rest to calculate Mean Absolute Error (MAE). For true value y and predicted \u0177, $MAE = \\frac{1}{n}\\Sigma_{i=1}^{n}|y_i-\\hat{y_i}|$"}, {"title": "3 Experimental Evaluation", "content": "Here we experimentally evaluate the viability of using tensor completion on the following tasks that we have defined:\nTask 1: Total magnetization prediction, using just chemical formula. 50,000 training, 50,000 test values.\nTask 2: Formation energy per atom prediction, using just chemical formula. 8000 training, 959 test values.\nTask 3: Band gap prediction, using just chemical formula. 8000 training, 959 test values.\nTask 4: Band gap prediction, using just chemical formula. 1000 training, 290 test values."}, {"title": "3.1 Tensor Model Comparison", "content": "For each tensor completion model, we display the average MAE over 5 iterations. We also compare non-tensor models: GradientBoosting (Pedregosa et al. 2011), XGBoost (Chen and Guestrin 2016), and an MLP (Paszke et al. 2019)."}, {"title": "3.2 Individual Samples' Comparison", "content": "To observe how useful our methods are in practice, we look at 5 randomly sampled values and predictions for each task."}, {"title": "3.3 Efficiency Analysis", "content": "Here we observe the performance and training time for different models with respect to the number of training values."}, {"title": "4 Conclusion", "content": "By modeling material property prediction tasks as tensor completion problems, we leverage the inherent structure in our datasets to fill in missing entries. We show the viability of modeling various types of composition-based material property prediction problems as tensor completion problems, predicting band gap, formation energy, and total magnetization. This way we significantly accelerate material design problems by using just a small fraction of computed values to infer the results unobserved materials' values."}]}