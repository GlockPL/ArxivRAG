{"title": "Coarse-to-Fine Detection of Multiple Seams for Robotic Welding", "authors": ["Pengkun Wei", "Shuo Cheng", "Dayou Li", "Ran Song", "Yipeng Zhang", "Wei Zhang"], "abstract": "Efficiently detecting target weld seams while ensuring sub-millimeter accuracy has always been an important challenge in autonomous welding, which has significant application in industrial practice. Previous works mostly focused on recognizing and localizing welding seams one by one, leading to inferior efficiency in modeling the workpiece. This paper proposes a novel framework capable of multiple weld seams extraction using both RGB images and 3D point clouds. The RGB image is used to obtain the region of interest by approximately localizing the weld seams, and the point cloud is used to achieve the fine-edge extraction of the weld seams within the region of interest using region growth. Our method is further accelerated by using a pre-trained deep learning model to ensure both efficiency and generalization ability. The performance of the proposed method has been comprehensively tested on various workpieces featuring both linear and curved weld seams and in physical experiment systems. The results showcase considerable potential for real-world industrial applications, emphasizing the method's efficiency and effectiveness.", "sections": [{"title": "I. INTRODUCTION", "content": "According to data published by the International Federation of Robotics (IFR), welding robots account for the second largest market share of industrial robots globally. In recent years, although there are studies on in-welding monitoring of weld pool dynamics [1] and post-welding quality inspection [2], [3], the majority of research still primarily focuses on pre-welding seams Recognition and localization [4]\u2013[11].\nHowever, most of these methods are designed for a single weld seam to ensure accuracy, in other words, the sensor's field of view contains information for only one weld seam at a time. It implies that in industrial practice, the position information of all weld seams on a workpiece can only be determined one by one. In this process, multiple manual demonstrations of scanning positions are required, which leads to low efficiency.\nLaser sensors are widely used in weld seam detection with the advantage of high accuracy. However, considering the limited receptive field of laser sensors, we recommend using structured light vision sensors with a larger field of view to improve detection efficiency. A larger field of view implies a larger volume of point cloud data and potentially lower accuracy of the raw data. Improving the detection efficiency while maintaining the recognition accuracy is the other key challenge.\nIn order to address the aforementioned issues, in this paper we introduce a multiple weld seam edges extraction algorithm based on an RGB-D camera that can simultaneously detect all weld seams within a larger field of view while ensuring accuracy. The method consists of a coarse positioning module based on deep learning methods and a fine-edge extraction module using region growth. In our experiments, we found that only the point cloud surrounding the weld seams contains relevant information, while a significant amount of computational resources is wasted on other redundant parts. The deep learning module utilizes semantic segmentation results from the RGB images processed by the Fast Segment Anything Model (FastSAM) to obtain the approximate positions of the weld seam edges and crops the raw point cloud accordingly. The region growing module first downsamples the cropped point cloud to ensure further efficiency while preserving as much geometric information as possible. Then, the algorithm will extract all weld seams from the preprocessed point cloud at once and generate a welding path with 6-DOF. Finally, the robot arm welding system performs the execution. The contributions of this paper are as follows:\n\u2022 A redundant point cloud information removal algorithm based on FastSAM segmentation information applied to weld seam edges extraction is proposed\n\u2022 Development of a region-growing edge extraction algorithm that can be used to extract and fit workpiece weld seams and generate weld paths that meet the requirements of sub-millimeter welding accuracy.\nThe effectiveness of the algorithm was validated on physical experimental systems in both laboratory and industry scenarios."}, {"title": "II. RELATED WORK", "content": "The entire welding process can be divided into several subtasks, including weld detection [4]-[7], [9], [12], weld tracking [13]-[19], melt pool monitoring [1] and weld defect inspection [2], [3], [20]. The detection and location of weld seams, which serve as a pivotal and initial step in the welding process, directly affect the quality of welding."}, {"title": "A. Laser sensor-based Methods", "content": "Due to the challenges involved in performing weld seam detection and localization on the entire workpiece, most methods are targeted at single weld seam. Laser sensors are widely used in the welding field relying on their high precision characteristics. Zhang et al. [4] proposed a grayscale image features extraction method based on laser structure light and reconstructed the curve seam model using a cubic spline smoothing technique. Ma et al. [5] proposed a novel self-updating template matching (SUTM) method for circular welds to extract features and an algorithm for spatial circle center fitting based on random sampling consensus (RANSAC). Fan et al. [6] developed a seam tracking system specifically designed for narrow seams with widths less than 0.2mm. The system performs laser scanning at multiple pre-set positions to identify the position of the narrow seam. For laser sensor images, Li et al. [18] proposed a welds extraction method based on the improved target detection model CenterNet, and Zhang et al. [19] presented a deep neural network-based weld feature point extraction method, which were used for seam tracking and posture adjustment. Although the methods based on laser sensors have the advantage of small errors, the disadvantage of narrow perception range usually restricts them to a single weld seam, which significantly reduces the efficiency."}, {"title": "B. Other sensor-based Methods", "content": "An edge density-based welding seam edges extraction method using an RGB-D camera was proposed in [10]. In addition to visual sensors, Ganguly and Khatib [11] also proposed a welding seam edge detection algorithm through tactile exploration with sub-millimeter accuracy. However, its prolonged exploration time and computational time are highly unfavorable for industrial assembly line production. Efficiently and accurately identifying all the weld seams to be welded has become a pressing challenge in the industrial field, demanding an urgent solution.\nNext, we will introduce a method using an RGB-D camera for extracting multiple weld seam edges. The method uses a coarse-to-fine framework to efficiently detect weld seams with comparable accuracy. Furthermore, we deployed our algorithm on different physical systems for various workpieces and achieved the desired results."}, {"title": "III. METHOD", "content": "The input of the whole system is an RGB image and raw point cloud of the workpiece acquired in the same shooting posture, while the output is a robot-executable welding path $W = \\{\\Psi_1, \\Psi_2, \u2026, \\Psi_n\\}$ with 6-DOF where each $\\Psi_i$ is represented by $[P_i, R_i]$ in the world coordinate system. $P_i$ (x, y, z) represents a point position in the world coordinate system and $R_i$ (w, p, r) represents the end-effector pose of the robot."}, {"title": "B. Workpiece Edge Model", "content": "In the field of welding, a weld seam typically refers to the junction position between two mental plates to be welded, and the plates could be flat or curved. Types of weld seams include butt weld, lap weld, fillet weld, and T-joint weld, etc. Each type of weld seam can further be subdivided into many specific types. However, based on the geometry of the weld seams, they can generally be classified into linear and curved weld seams.\nLinear Weld Seams. Linear weld seams are the most common type of weld seam structure. We set the world coordinate system to completely coincide with the base coordinate system of the robotic arm. Typically, we use the starting point $P^{world}_{start}$ (x, y, z) and the ending point $P^{world}_{end}$ (x, y, z) in the world coordinate system to represent a straight-line weld seam. We assume that the adjacent regions on both sides of the weld seam can be abstracted as C2-continuous surfaces $S_1$ and $S_2$, i.e., the curvature remains constant within the neighborhood except for the abrupt change in the weld seam region itself.\nIn RGB images, according to the mapping relationship from three-dimensional to two-dimensional space, a straight line in space is also mapped as a straight line on the two-dimensional plane. We will represent a linear weld seam in the image coordinate system using the starting pixel $P^{image}_{start}$ (x, y) and the ending pixel $P^{image}_{end}$ (x, y). Furthermore, we can obtain the weld seam's starting point $P^{camera}_{start}$ (x, y, z) and the weld seam's ending point $P^{camera}_{end}$ (x, y, z) in the camera coordinate system. Then the spatial correspondence between any point $P^{camera}_{i}$ in the camera coordinate system and its corresponding point $P^{world}_{i}$ in the world coordinate system is given by the following equation:\n$p^{world}_{i} = M^{world}_{tool} \\cdot M^{tool}_{camera} \\cdot p^{camera}_{i}$         (1)\nwhere $M^{camera}_{tool}$ denotes the rotation and translation matrix from the camera to the tool obtained through hand-eye calibration, while $M^{world}_{tool}$ is the transformation matrix from the tool coordinate system to the world coordinate system, which can usually be easily obtained from the teach pendant of the robotic arm.\nIn the acquired point cloud data, we use a set of $N_L$ points $P = \\{P_1, P_2, \u2026, P_{N_L} \\}$ in the neighborhood of the weld seam to fit a straight line which is represented by [ $P_{start}, P_{end}$]. Since the point cloud data is also represented in the camera coordinate system, the relationship from the camera coordinate system to the world coordinate system for $P_{start}$ and $P_{end}$ also satisfies Eq. (1).\nCurved Weld Seams. We assume that each curved weld seam $E$ is composed of $N_C$ edge segments $\\{e_1, e_2, ... , e_{N_G}\\}$ that are C2-continuous, and its two side regions can be similarly abstracted into two C2 continuous"}, {"title": "C. Coarse Seam Detection Using VLM", "content": "During point cloud processing, we found that only the point cloud around the weld seams contains rich information, while the remaining parts contribute little to weld seam detection, resulting in a waste of computational resources. Thus, we aim to filter out the irrelevant point cloud and focus on the part containing the weld seam. As shown in Fig. 2, we propose to distill weld seam priors as coarse positioning from pre-trained VLMs to obtain useful parts of the raw point cloud and then implement a region-growing edge extraction algorithm to detect weld seams.\nSegment Anything Model (SAM) [21] is trained on web-scale datasets with powerful image segmentation capabilities and represents a paradigm shift towards more flexible and generalized segmentation models. Moreover, the SAM model introduces a new approach to image segmentation that allows interactive, point-based user input to guide the segmentation process. SAM can accept the following prompts: bounding box, point, mask, and text. FastSAM [22] is a novel real-time CNN-based solution for Segment Anything tasks that significantly reduces computational requirements while maintaining a competitive performance similar to SAM. Considering the computational resource limitations of practical industrial deployments, we choose FastSAM as the large model for welding segmentation to distill some useful priors. The prompts are obtained by clicking the center of each workpiece surface simply. Based on these prompts, FastSAM can segment each surface of the workpiece. The intersection area between the surfaces indicates the approximate location of the weld seams, aiding us to obtain fine-grained point clouds for subsequent processing.\nHuman interaction is the most accurate way to give the required prompts for FastSAM. However, for an automated welding industrial line, manual interaction will cause a dramatic loss of productivity. Therefore, we explore an automatic prompt generation method based on keypoint detection techniques to produce suitable click prompts. Compared to the prompts of the bounding box, annotating key points is much more efficient (only 4 key points need to be labeled for an open square weldment). We adopt the keypoint as the prompt for FastSAM. In practice, We annotate some data for keypoint detection algorithm training. Consequently, we can obtain fine-grained point clouds from the coarse ones to get useful weld seam information for successive processes."}, {"title": "D. Fine Edge Extraction Based on Region-Growing", "content": "We propose an algorithm based on region growing to detect the weld seam edges in point cloud data. The algorithm can take either the raw point cloud data or the cropped point cloud data as input and output the position information of the weld seams. The efficiency of the execution of the algorithm varies depending on the input data, which we will explain in detail in the experiments section. The algorithm consists of the following main steps:\n\u2022 the raw point cloud needs to be preprocessed, including pass-through filtering and downsampling, and building"}, {"title": "Preprocessing of The Raw Point Cloud", "content": "The raw point cloud obtained from the camera usually contains a significant amount of noise. To extract the region of interest and remove irrelevant points, we apply a pass-through filter to the point cloud based on prior knowledge such as the optimal working range of the camera and the known height of the workbench. We voxel-downsample the point cloud after filtering, which divides the space into small rasters of voxels, replacing all points in the raster with the center of gravity of the point cloud within each raster. For any $P_i$(x, y, z) in the point cloud we can use the following formula to calculate the raster index $(h_x, h_y, h_z)$ at which the point is located.\n$h_k = \\lfloor (k - k_{min})/r \\rfloor, k = x, y, z$         (2)\nwhere r is the side length of the raster and $(X_{min}, Y_{min}, Z_{min})$ represents the minimum coordinates of the point cloud on each axis.\nThis step helps to reduce the density of the point cloud while preserving the overall shape and structural information of the workpiece. To further improve efficiency, we utilize the KD-tree data structure for point cloud processing. KD-tree is a data structure used in computer science to organize points in a space with k dimensions. It is commonly applied in point cloud range search and nearest-neighbor search, enabling a reduction in time complexity to $O(nlog_2 n)$."}, {"title": "Region-Growing Algorithm for Edge Extraction", "content": "We demonstrated the entire process of region-growing segmentation. The curvature of all points is calculated according to the following formula and the points are sorted based on the curvature value, then the point with the smallest curvature value is selected as the initial seed point $P_{initial}$ to be added to the seed set $S_{seed}$. According to the edge model established earlier, the smoother the region in the point cloud, the less likely it is to be a weld region, and growing from the smoothest region could improve efficiency.\n$\\delta = \\frac{1}{k}M = \\sum_{i=1}^{k} (P_i - P_0) (P_i - P_0)^T$\n$ \\delta = \\frac{\\lambda_0}{\\lambda_0 + \\lambda_1 + \\lambda_2}$            (3)\nwhere M donates the covariance matrix of the neighborhood formed by the k nearest points to $p_i$, $p_0$ represents the barycenter of the neighborhood, $\\lambda_0$, $\\lambda_1$, $\\lambda_2$ represents the three eigenvalues of the covariance matrix M, and $\\lambda_0 < \\lambda_1 < \\lambda_2$, then a smaller value of $\\delta$ indicates a flatter neighborhood, whereas a more rugged neighborhood."}, {"title": "Welding Path Generation", "content": "Next, we need to fit the precise point cloud of the weld seam edge in order to generate the welding path. We first use the weld edge point cloud to fit the Plane [A, B, C, D] it lies on, then project the point cloud onto this plane, and finally construct a rotation matrix to convert any projected point cloud $P^{camera}$ (x, y, z) in the camera coordinate system to $P^{plane}$ (x, y, z) in the planar coordinate system, which has a z-axis perpendicular to the plane itself. So the z after the conversion is a fixed value, and we only need to fit the (x, y). The weld path contains the weld trajectories and the corresponding welding torch poses. The welding trajectories can be obtained by uniformly sampling points from the fitted edge. The selection of welding torch poses follows two principles: one is not to make the welding torch collide with the workpiece, and the other is to make the welding torch as perpendicular as possible to the tangent line of the welded place in order to ensure the quality of the weld. We take points within the field of the weld point cloud obtained in the previous step and compute their mean vector direction as the welding pose."}, {"title": "IV. EXPERIMENTS", "content": "In order to validate the proposed method, we conducted several experiments on a robotics welding system based on a UR5 robotic arm. Next, we evaluated the system by performing a series of experiments on two linear-weld-seam workpieces and one curved-weld-seam workpiece. It is worth mentioning that we have also attempted to deploy our method in real industrial welding scenario and achieved promising results."}, {"title": "A. Effect of the Downsampling Parameter", "content": "As the sensor field of view increases, the number of point clouds to be processed also increases dramatically. When dealing with point cloud data, it is common to use down-sampling as a means to reduce the density of point clouds. Downsampling can effectively reduce the number of point clouds, thereby reducing the consumption of computational resources and speeding up subsequent processing, while still preserving as much geometric information as possible.\nIn the proposed method, we employed the voxel grid downsampling method, which works by dividing the whole point cloud into regular cubic grid cells and selecting a representative point for each grid cell to represent all points within that cell. We can adjust the edge length of the grid, and a larger grid size results in sparser point clouds and fewer points after downsampling. However, it also implies lower data precision.\nWe conducted experiments to illustrate how to choose the grid size to balance accuracy and efficiency. performed experiments on a weldment containing five linear weld seams and a curved weldment, and sequentially tested the variation of point cloud quantity and error as the voxel grid size changed from 1mm to 10mm. The root mean square error (RMSE) was used to represent the gap between the path points generated by our method and the ground truth points which were obtained by manually annotating high-precision point clouds. We uniformly selected 3 points on each linear weld seam and 10 points on the curved weld"}, {"title": "B. Quantitative Comparison", "content": "Zhou Peng et al. [10] proposed a novel point cloud intensity-based method to extract edge points and generate weld paths. Peng Rui et al. [9] proposed a welding groove detection algorithm and conducted experiments to validate the accuracy and efficiency of the algorithm. Yang et al. [12] designed a fringe projection system to measure the appearance of welding workpieces and proposed a 3D seam extraction algorithm based on point cloud segmentation. The previous methods are all based on point cloud, Ganguly et al. [11] proposed a method for robotic welding through tactile exploration. Next, We will compare our method with these baselines on two types of workpieces.\nWe prefer to take the time of the entire process into account as opposed to comparing the algorithm runtime alone. Thus, we divide the total time cost into exploration time and computation time. Exploration time refers to the time spent on acquiring the input data to be processed by the sensors, while computation time refers to the time taken for the algorithm to perform. Since most existing methods have test data for a single weld seam, our proposed method is capable of extracting multiple weld seams simultaneously. In the end, we will compare the average time for each weld seam. To ensure fairness, the exploration time for all methods, except the tactile-exploration-based method, is set to ten seconds per capture. The exploration time includes the time for teaching the capture positions and the time taken for actual capturing. According to the experimental data, we achieved the highest efficiency in terms of average time spent on the two types of workpieces. It is worth noting that our average time decreases as the number of weld seams captured in each shot increases.\nTo validate the effectiveness of our proposed FastSAM-based coarse localization cropping method, we design comparative experiments to compare the number of point clouds that the algorithm needs to process and the time required with and without the inclusion of the cropping module. Taking the workpiece containing ten linear weld seams as an example, the experimental results demonstrate that adding the cropping module can remove over 80% of redundant point clouds and save approximately 68.5% of computational time."}, {"title": "C. Application in Industry Scenario", "content": "To further validate the effectiveness of the proposed algorithm in real industrial scenarios, we conducted experiments on a welding system based on the Fanuc M-10iD/8L robot arm equipped with a ground track. The workpieces to be welded are conventional steel structures, which are widely applied in various fields such as bridges, buildings, and ships, offering broad application prospects. The task is to weld the ribs to the main body of the workpiece, where the ribs play a role in enhancing structural strength and providing support. Depending on the requirements, the ribs can be connected to the main body at either one end or both ends."}, {"title": "V. CONCLUSIONS", "content": "This paper presents a multi-weld-seam detection method applied in the field of robotic welding. For the RGB images and point cloud data acquired by sensors, a coarse-to-fine weld seam edge extraction algorithm is designed and tested in both laboratory and factory scenarios. We quantitatively compare the proposed method with existing methods in terms of accuracy and efficiency on different linear and curved workpieces. The experimental results demonstrate that our method can improve the efficiency of detecting weld seams while ensuring comparable accuracy. Regarding the voxel grid downsampling method, we designed experiments to demonstrate how to select an appropriate grid size for the voxel grid.\nIn the future, we will introduce the point cloud reconstruction method to reconstruct the more complex weldments such as those containing both straight and curved weld seams, and we will try to extract the weld seams in the reconstructed point cloud."}]}