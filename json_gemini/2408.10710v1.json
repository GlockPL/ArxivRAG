{"title": "Coarse-to-Fine Detection of Multiple Seams for Robotic Welding", "authors": ["Pengkun Wei", "Shuo Cheng", "Dayou Li", "Ran Song", "Yipeng Zhang", "Wei Zhang"], "abstract": "Efficiently detecting target weld seams while ensur-ing sub-millimeter accuracy has always been an important chal-lenge in autonomous welding, which has significant application inindustrial practice. Previous works mostly focused on recognizingand localizing welding seams one by one, leading to inferiorefficiency in modeling the workpiece. This paper proposes anovel framework capable of multiple weld seams extraction usingboth RGB images and 3D point clouds. The RGB image is usedto obtain the region of interest by approximately localizing theweld seams, and the point cloud is used to achieve the fine-edgeextraction of the weld seams within the region of interest usingregion growth. Our method is further accelerated by usinga pre-trained deep learning model to ensure both efficiencyand generalization ability. The performance of the proposedmethod has been comprehensively tested on various workpiecesfeaturing both linear and curved weld seams and in physicalexperiment systems. The results showcase considerable potentialfor real-world industrial applications, emphasizing the method'sefficiency and effectiveness. Videos of the real-world experimentscan be found at https://youtu.be/pq162HSP2D4.", "sections": [{"title": "I. INTRODUCTION", "content": "According to data published by the International Federationof Robotics (IFR), welding robots account for the secondlargest market share of industrial robots globally. In recentyears, although there are studies on in-welding monitoring ofweld pool dynamics [1] and post-welding quality inspection[2], [3], the majority of research still primarily focuses onpre-welding seams Recognition and localization [4]\u2013[11].\nHowever, most of these methods are designed for a singleweld seam to ensure accuracy, in other words, the sensor'sfield of view contains information for only one weld seamat a time. It implies that in industrial practice, the positioninformation of all weld seams on a workpiece can only bedetermined one by one. In this process, multiple manualdemonstrations of scanning positions are required, whichleads to low efficiency.\nLaser sensors are widely used in weld seam detection withthe advantage of high accuracy. However, considering thelimited receptive field of laser sensors, we recommend usingstructured light vision sensors with a larger field of view toimprove detection efficiency. A larger field of view impliesa larger volume of point cloud data and potentially loweraccuracy of the raw data. Improving the detection efficiencywhile maintaining the recognition accuracy is the other keychallenge.\nIn order to address the aforementioned issues, in this paperwe introduce a multiple weld seam edges extraction algorithmbased on an RGB-D camera that can simultaneously detectall weld seams within a larger field of view while ensuringaccuracy. The method consists of a coarse positioning modulebased on deep learning methods and a fine-edge extractionmodule using region growth. In our experiments, we foundthat only the point cloud surrounding the weld seams containsrelevant information, while a significant amount of computa-tional resources is wasted on other redundant parts. The deeplearning module utilizes semantic segmentation results fromthe RGB images processed by the Fast Segment AnythingModel (FastSAM) to obtain the approximate positions of theweld seam edges and crops the raw point cloud accordingly.\nThe region growing module first downsamples the croppedpoint cloud to ensure further efficiency while preserving asmuch geometric information as possible. Then, the algorithmwill extract all weld seams from the preprocessed point cloudat once and generate a welding path with 6-DOF. Finally,the robot arm welding system performs the execution. Thecontributions of this paper are as follows:\n\u2022 A redundant point cloud information removal algorithmbased on FastSAM segmentation information applied toweld seam edges extraction is proposed\n\u2022 Development of a region-growing edge extraction algo-rithm that can be used to extract and fit workpieceweld seams and generate weld paths that meet therequirements of sub-millimeter welding accuracy.\nThe effectiveness of the algorithm was validated onphysical experimental systems in both laboratory andindustry scenarios."}, {"title": "II. RELATED WORK", "content": "The entire welding process can be divided into severalsubtasks, including weld detection [4]\u2013[7], [9], [12], weldtracking [13]\u2013[19], melt pool monitoring [1] and weld defectinspection [2], [3], [20]. The detection and location of weldseams, which serve as a pivotal and initial step in the weldingprocess, directly affect the quality of welding."}, {"title": "A. Laser sensor-based Methods", "content": "Due to the challenges involved in performing weld seamdetection and localization on the entire workpiece, mostmethods are targeted at single weld seam. Laser sensorsare widely used in the welding field relying on their highprecision characteristics. Zhang et al. [4] proposed a grayscaleimage features extraction method based on laser structurelight and reconstructed the curve seam model using acubic spline smoothing technique. Ma et al. [5] proposed"}, {"title": "B. Other sensor-based Methods", "content": "An edge density-based welding seam edges extractionmethod using an RGB-D camera was proposed in [10]. Inaddition to visual sensors, Ganguly and Khatib [11] alsoproposed a welding seam edge detection algorithm throughtactile exploration with sub-millimeter accuracy. However,its prolonged exploration time and computational time arehighly unfavorable for industrial assembly line production.Efficiently and accurately identifying all the weld seams tobe welded has become a pressing challenge in the industrialfield, demanding an urgent solution.\nNext, we will introduce a method using an RGB-Dcamera for extracting multiple weld seam edges. The methoduses a coarse-to-fine framework to efficiently detect weldseams with comparable accuracy. Furthermore, we deployedour algorithm on different physical systems for variousworkpieces and achieved the desired results."}, {"title": "III. METHOD", "content": "The input of the whole system is an RGB image and rawpoint cloud of the workpiece acquired in the same shootingposture, while the output is a robot-executable welding path\\(W \\) {1, 2, \u2026, \u03a8n} with 6-DOF where each i isrepresented by [Pi, Ri] in the world coordinate system. Pi(x, y, z) represents a point position in the world coordinate\nsystem and Ri (w, p, r) represents the end-effector pose ofthe robot."}, {"title": "B. Workpiece Edge Model", "content": "In the field of welding, a weld seam typically refers to thejunction position between two mental plates to be welded,and the plates could be flat or curved. Types of weld seamsinclude butt weld, lap weld, fillet weld, and T-joint weld, etc.Each type of weld seam can further be subdivided into manyspecific types. However, based on the geometry of the weldseams, they can generally be classified into linear and curvedweld seams shown in Fig. 1. Next, we will model these twocases separately.\nLinear Weld Seams. Linear weld seams are the mostcommon type of weld seam structure. We set the worldcoordinate system to completely coincide with the basecoordinate system of the robotic arm. Typically, we use thestarting point Pworld tort (x, y, z) and the ending point Pworld (x,y, z) in the world coordinate system to represent a straight-line weld seam shown in Fig. 1. We assume that the adjacentregions on both sides of the weld seam can be abstracted asC2-continuous surfaces S\u2081 and S2, i.e., the curvature remainsconstant within the neighborhood except for the abrupt changein the weld seam region itself.\nIn RGB images, according to the mapping relationshipfrom three-dimensional to two-dimensional space, a straightline in space is also mapped as a straight line on the two-dimensional plane. We will represent a linear weld seam inthe image coordinate system using the starting pixel pimage(x, y) and the ending pixel Pimage (x, y). Furthermore, we\ncan obtain the weld seam's starting point Peamera (x, y, z)\nand the weld seam's ending point Pamera (x, y, z) in the\ncamera coordinate system. Then the spatial correspondencebetween any point Pcamera in the camera coordinate systemand its corresponding point world in the world coordinatesystem is given by the following equation:\n\\(p^{world} - M_{tool}^{world}. M_{camera}^{tool} p^{camera}\\) \\(1\\)\nwhere \\(M_{camera}^{tool}\\) denotes the rotation and translation matrixfrom the camera to the tool obtained through hand-eyecalibration, while \\(M_{tool}^{world}\\) is the transformation matrix fromthe tool coordinate system to the world coordinate system,which can usually be easily obtained from the teach pendantof the robotic arm.\nIn the acquired point cloud data, we use a set of NLpoints P {P1, P2, , PNL } in the neighborhood of theweld seam to fit a straight line which is represented by [Pstart, Pend]. Since the point cloud data is also representedin the camera coordinate system, the relationship from thecamera coordinate system to the world coordinate system forPstart and Pend also satisfies Eq. (1).\nCurved Weld Seams. We assume that each curvedweld seam E is composed of Nc edge segments{e1, 2, ... ENG} that are C2-continuous, and its two sideregions can be similarly abstracted into two C2 continuous"}, {"title": "C. Coarse Seam Detection Using VLM", "content": "During point cloud processing, we found that only the pointcloud around the weld seams contains rich information, whileremaining parts contribute little to weld seam detection,resulting in a waste of computational resources. Thus, we aimto filter out the irrelevant point cloud and focus on the partcontaining the weld seam. As shown in Fig. 2, we propose todistill weld seam priors as coarse positioning from pre-trainedVLMs to obtain useful parts of the raw point cloud and thenimplement a region-growing edge extraction algorithm todetect weld seams.\nSegment Anything Model (SAM) [21] is trained on web-scale datasets with powerful image segmentation capabili-ties and represents a paradigm shift towards more flexibleand generalized segmentation models. Moreover, the SAMmodel introduces a new approach to image segmentationthat allows interactive, point-based user input to guide thesegmentation process. SAM can accept the following prompts:bounding box, point, mask, and text. FastSAM [22] is anovel real-time CNN-based solution for Segment Anythingtasks that significantly reduces computational requirementswhile maintaining a competitive performance similar toSAM. Considering the computational resource limitations ofpractical industrial deployments, we choose FastSAM as thelarge model for welding segmentation to distill some usefulpriors. The prompts are obtained by clicking the center of eachworkpiece surface simply. Based on these prompts, FastSAMcan segment each surface of the workpiece. The intersectionarea between the surfaces indicates the approximate locationof the weld seams, aiding us to obtain fine-grained pointclouds for subsequent processing.\nHuman interaction is the most accurate way to give therequired prompts for FastSAM. However, for an automatedwelding industrial line, manual interaction will cause adramatic loss of productivity. Therefore, we explore an auto-matic prompt generation method based on keypoint detectiontechniques to produce suitable click prompts. Compared tothe prompts of the bounding box, annotating key points ismuch more efficient (only 4 key points need to be labeledfor an open square weldment). We adopt the keypoint as theprompt for FastSAM. In practice, We annotate some data forkeypoint detection algorithm training. Consequently, we canobtain fine-grained point clouds from the coarse ones to getuseful weld seam information for successive processes."}, {"title": "D. Fine Edge Extraction Based on Region-Growing", "content": "We propose an algorithm based on region growing to detectthe weld seam edges in point cloud data. The algorithm cantake either the raw point cloud data or the cropped pointcloud data as input and output the position information of theweld seams. The efficiency of the execution of the algorithmvaries depending on the input data, which we will explain indetail in the experiments section. The algorithm consists ofthe following main steps as shown in Alg. 1:\n\u2022 the raw point cloud needs to be preprocessed, includingpass-through filtering and downsampling, and buildinga KD-tree from the obtained point cloud to improve theefficiency of range search and nearest neighbor search.The cropped point cloud can be processed directly fromdownsampling.\n\u2022 utilizing the region-growing algorithm to segment theworkpiece and its individual surfaces.\n\u2022 obtaining the point cloud near the edges and using theleast squares method to fit it. Simultaneously, calculatingthe welding pose to get the welding path.\nPreprocessing of The Raw Point Cloud. The raw pointcloud obtained from the camera usually contains a significantamount of noise. To extract the region of interest and removeirrelevant points, we apply a pass-through filter to the pointcloud based on prior knowledge such as the optimal workingrange of the camera and the known height of the workbench.We voxel-downsample the point cloud after filtering, whichdivides the space into small rasters of voxels, replacing allpoints in the raster with the center of gravity of the pointcloud within each raster. For any Pi(x, y, z) in the point cloudwe can use the following formula to calculate the raster index(hx, hy, hz) at which the point is located.\n\\(h_{k} = [(k - k_{min})/r], k = x, y, z\\) \\(2\\)\nwhere r is the side length of the raster and (Xmin, Ymin, Zmin)represents the minimum coordinates of the point cloud on\neach axis.\nThis step helps to reduce the density of the point cloudwhile preserving the overall shape and structural informationof the workpiece. To further improve efficiency, we utilize theKD-tree data structure for point cloud processing. KD-tree isa data structure used in computer science to organize pointsin a space with k dimensions. It is commonly applied in pointcloud range search and nearest-neighbor search, enabling areduction in time complexity to O(nlog2 n).\nRegion-Growing Algorithm for Edge Extraction. Wedemonstrated the entire process of region-growing segmen-tation in Alg. 1. The curvature of all points is calculatedaccording to the following formula and the points are sortedbased on the curvature value, then the point with the smallestcurvature value is selected as the initial seed point Pinatial tobe added to the seed set Sseed. According to the edge modelestablished earlier, the smoother the region in the point cloud,the less likely it is to be a weld region, and growing fromthe smoothest region could improve efficiency.\n\\(\u03b4 = \\frac{1}{k} M = \\sum_{i=1}^{k}(P_{i}-P_{0}) (P_{i} \u2013 P_{0})^{T} \\\\ \\\\ k = \\frac{\u03bb_{0}}{\u03bb_{0} + \u03bb_{1} + \u03bb_{2}}\\) \\(3\\)\nwhere M donates the covariance matrix of the neighborhoodformed by the k nearest points to pi, po represents thebarycenter of the neighborhood, \u03bb\u03bf, \u03bb1, 2 represents the threeeigenvalues of the covariance matrix M, and \u03bb\u03bf < 1 < \u03bb2,then a smaller value of 8 indicates a flatter neighborhood,whereas a more rugged neighborhood."}, {"title": "IV. EXPERIMENTS", "content": "In order to validate the proposed method, we conductedseveral experiments on a robotics welding system based ona UR5 robotic arm shown in Fig. 4. Next, we evaluated thesystem by performing a series of experiments on two linear-weld-seam workpieces and one curved-weld-seam workpiece.It is worth mentioning that we have also attempted to deployour method in real industrial welding scenario and achievedpromising results."}, {"title": "A. Effect of the Downsampling Parameter", "content": "As the sensor field of view increases, the number of pointclouds to be processed also increases dramatically. Whendealing with point cloud data, it is common to use down-sampling as a means to reduce the density of point clouds.Downsampling can effectively reduce the number of pointclouds, thereby reducing the consumption of computationalresources and speeding up subsequent processing, while stillpreserving as much geometric information as possible.\nIn the proposed method, we employed the voxel griddownsampling method, which works by dividing the wholepoint cloud into regular cubic grid cells and selecting arepresentative point for each grid cell to represent all pointswithin that cell. We can adjust the edge length of the grid,and a larger grid size results in sparser point clouds and fewerpoints after downsampling. However, it also implies lowerdata precision.\nWe conducted experiments to illustrate how to choose thegrid size to balance accuracy and efficiency. As shown in Fig.5, we performed experiments on a weldment containing fivelinear weld seams and a curved weldment, and sequentiallytested the variation of point cloud quantity and error as thevoxel grid size changed from 1mm to 10mm. The root meansquare error (RMSE) was used to represent the gap betweenthe path points generated by our method and the groundtruth points which were obtained by manually annotatinghigh-precision point clouds. We uniformly selected 3 pointson each linear weld seam and 10 points on the curved weld"}, {"title": "B. Quantitative Comparison", "content": "Zhou Peng et al. [10] proposed a novel point cloud intensity-based method to extract edge points and generate weld paths.Peng Rui et al. [9] proposed a welding groove detectionalgorithm and conducted experiments to validate the accuracyand efficiency of the algorithm. Yang et al. [12] designed afringe projection system to measure the appearance of weldingworkpieces and proposed a 3D seam extraction algorithmbased on point cloud segmentation. The previous methodsare all based on point cloud, Ganguly et al. [11] proposed amethod for robotic welding through tactile exploration. Next,We will compare our method with these baselines on twotypes of workpieces.\nWe prefer to take the time of the entire process intoaccount as opposed to comparing the algorithm runtime alone.\nThus, we divide the total time cost into exploration timeand computation time. Exploration time refers to the timespent on acquiring the input data to be processed by thesensors, while computation time refers to the time taken forthe algorithm to perform. Since most existing methods havetest data for a single weld seam, our proposed method iscapable of extracting multiple weld seams simultaneously. Inthe end, we will compare the average time for each weld seam.To ensure fairness, the exploration time for all methods, exceptthe tactile-exploration-based method, is set to ten seconds percapture. The exploration time includes the time for teachingthe capture positions and the time taken for actual capturing.According to the experimental data shown in I, we achievedthe highest efficiency in terms of average time spent on thetwo types of workpieces. It is worth noting that our averagetime decreases as the number of weld seams captured in eachshot increases.\nTo validate the effectiveness of our proposed FastSAM-based coarse localization cropping method, we design com-parative experiments to compare the number of point cloudsthat the algorithm needs to process and the time required withand without the inclusion of the cropping module. Taking theworkpiece containing ten linear weld seams as an example,the experimental results demonstrate that adding the croppingmodule can remove over 80% of redundant point clouds andsave approximately 68.5% of computational time."}, {"title": "C. Application in Industry Scenario", "content": "To further validate the effectiveness of the proposed algo-rithm in real industrial scenarios, we conducted experimentson a welding system based on the Fanuc M-10iD/8L robotarm equipped with a ground track. The workpieces to bewelded are conventional steel structures, which are widelyapplied in various fields such as bridges, buildings, and ships,offering broad application prospects. The task is to weldthe ribs to the main body of the workpiece, where the ribsplay a role in enhancing structural strength and providingsupport. Depending on the requirements, the ribs can beconnected to the main body at either one end or both ends. As"}, {"title": "V. CONCLUSIONS", "content": "This paper presents a multi-weld-seam detection methodapplied in the field of robotic welding. For the RGB imagesand point cloud data acquired by sensors, a coarse-to-fineweld seam edge extraction algorithm is designed and testedin both laboratory and factory scenarios. We quantitativelycompare the proposed method with existing methods in termsof accuracy and efficiency on different linear and curvedworkpieces. The experimental results demonstrate that ourmethod can improve the efficiency of detecting weld seamswhile ensuring comparable accuracy. Regarding the voxelgrid downsampling method, we designed experiments todemonstrate how to select an appropriate grid size for thevoxel grid.\nIn the future, we will introduce the point cloud reconstruc-tion method to reconstruct the more complex weldments suchas those containing both straight and curved weld seams, andwe will try to extract the weld seams in the reconstructedpoint cloud."}]}