{"title": "Explainable AI for Multivariate Time Series Pattern Exploration: Latent Space Visual Analytics with Time Fusion Transformer and Variational Autoencoders in Power Grid Event Diagnosis", "authors": ["Haowen Xu", "Ali Boyaci", "Jianming (Jamie) Lian", "Aaron Wilson"], "abstract": "Detecting and analyzing complex patterns in multivariate time-series data is crucial for decision-making in urban and environmental system operations. However, challenges arise from the high dimensionality, intricate complexity, and interconnected nature of complex patterns, which hinder the understanding of their underlying physical processes. Existing AI methods often face limitations in interpretability, computational efficiency, and scalability, reducing their applicability in real-world scenarios. This paper proposes a novel visual analytics framework that integrates two generative AI models, Time Fusion Transformer (TFT) and Variational Autoencoders (VAEs), to reduce complex patterns into lower-dimensional latent spaces and visualize them in 2D using dimensionality reduction techniques such as PCA, t-SNE, and UMAP with DBSCAN. These visualizations, presented through coordinated and interactive views and tailored glyphs, enable intuitive exploration of complex multivariate temporal patterns, identifying patterns' similarities and uncover their potential correlations for a better interpretability of the AI outputs. The framework is demonstrated through a case study on power grid signal data, where it identifies multi-label grid event signatures, including faults and anomalies with diverse root causes. Additionally, novel metrics and visualizations are introduced to validate the models and evaluate the performance, efficiency, and consistency of latent maps generated by TFT and VAE under different configurations. These analyses provide actionable insights for model parameter tuning and reliability improvements. Comparative results highlight that TFT achieves shorter run times and superior scalability to diverse time-series data shapes compared to VAE. This work advances fault diagnosis in multivariate time series, fostering explainable AI to support critical system operations.", "sections": [{"title": "1. Introduction", "content": "Exploring patterns in multivariate time-series data is challenging due to the complexity, heterogeneity, and high dimensionality inherent in many environmental and urban datasets (Catley et al., 2008). These datasets often involve multiple interdependent variables measured over time, interacting in non-linear ways and across different time scales (Goswami, 2019). Temporal dependencies, varying trends, noise, missing data points, and irregular sampling intervals further complicate the identification of meaningful patterns, which may correspond to specific physical phenomena or events in real-world systems (Weerakody et al., 2021; Sun et al., 2020). To address these challenges, a range of AI-driven methods has been developed to enhance the classification and clustering of multivariate time-series data (Rojat et al., 2021). Traditional machine learning approaches, such as Principal Component Analysis (PCA) (Li, 2019) and Self-Organizing Maps (SOM) (D'Urso et al., 2014), have been widely applied. More recently, advanced deep learning models have demonstrated significant capabilities. Recurrent Neural Networks (RNNs) (Ienco and Interdonato, 2020; Wang et al., 2016) and Long Short-Term Memory (LSTM) networks (Karim et al., 2019; Hong and Yoon, 2017) excel in capturing temporal dependencies, while Convolutional Neural Networks (CNNs) effectively identify spatial and temporal patterns (Liu et al., 2018; Tripathi and Baruah, 2020). Generative algorithms, particularly Transformer models (Liu et al., 2021; Zuo et al., 2023; Le et al., 2024; Zerveas et al., 2021), have emerged as powerful tools for modeling long-range dependencies in sequential data, making them highly suitable for multivariate time-series analysis (Zhou et al., 2021). Variational Autoencoders (VAEs) are also gaining traction for their ability to handle missing data imputation and anomaly detection (Graving and Couzin, 2020; Lafabregue et al., 2022; Pham et al., 2022; Yokkampon et al., 2022). These deep generative models effectively learn data distributions in high-dimensional spaces by mapping them to lower-dimensional latent spaces, enabling more accurate and efficient analysis.\nDespite advancements in AI-based methods, human-in-the-loop (HitL) approaches remain essential for interpreting and validating AI-generated insights (Kumar et al., 2024; G\u00f3mez-Carmona et al., 2024). Human expertise ensures these patterns are relevant to specific domains, such as power system operations, where grid event data often comprised of multivariate time-series recordings such as voltage, frequency, and current requires careful interpretation to maintain reliable and efficient operations (Tocchetti and Brambilla, 2022; Wilson et al., 2024). These signatures often indicate system inefficiencies or disruptions, such as faults, generation/load imbalance, and inverter-induced oscillations, which can significantly impact grid reliability and stability if not addressed (Rivas and Abrao, 2020; Das, 2024). In addition, developing efficient AI-powered methods to uncover potential connections and interactions between different types of grid disturbances can enhance researchers' understanding of system complexity, enabling the development of more effective operational practices. While AI can detect these disturbances, human involvement is critical for contextualizing and applying these insights in real-world urban power system operations. This interplay highlights the importance of explainable AI (XAI) methods, which enhance transparency and empower operators to act confidently on AI-generated insights (Nallakaruppan et al., 2024). Visual analytics further strengthens human-AI collaboration by enabling intuitive understanding of deep learning models through interactive visualizations, emphasizing the need to integrate visual analytics into XAI methodologies (Niloofar et al., 2023; Xu et al., 2024).\nAddressing the challenges of analyzing complex patterns in multivariate time series data requires innovative approaches that bridge the gap between advanced deep learning models and interpretability. This paper introduces a visual analytics framework that reduces and represents these patterns in lower-dimensional latent spaces using the Time Fusion Transformer (TFT) and Variational Autoencoder (VAE) approaches. Dimensionality reduction techniques such as PCA, t-SNE, and UMAP are employed to visualize these representations in 2D as latent vector maps, enabling intuitive exploration of data patterns. Distance metrics are used to uncover correlations and topological relationships between patterns, enhancing the interpretability of generative models for exploratory fault pattern analysis. To ensure robust and efficient performance, the framework integrates evaluation metrics and advanced visualizations, enabling comparative analysis and validation of TFT- and VAE-based methods through domain knowledge. These tools facilitate parameter tuning, improving model reliability and scalability.\nA case study on power grid signal data demonstrates the framework's ability to identify grid event signatures\u2014distinctive patterns associated with faults and abnormal behaviors such as capacitor switching, load shedding, and inverter mal-functions, to name a few\u2014while revealing potential connections between these events. In the case study, the per-formance of both TFT and VAE-based methods was evaluated under varying configurations, including latent vector dimensions (e.g., 8, 32, 64, 128, 256, and 640) and different dimensionality reduction algorithms. Two VAE-based methods were developed: one using 1D convolutional layers and the other leveraging LSTM for encoding multivariate time series data. Three validation methods are employed to assess the outputs of different models: internal validation metrics, a Human-in-the-Loop approach, and a relative validation technique that involves comparing outputs from various models using corresponding plots and shape-matching methods. The comparative analysis showed a consis-tency of 86-92% between the 2D latent vector representations produced by TFT and the VAE-based methods under optimized model configurations and dimension reduction algorithms (e.g., t-SNE), and revealed that TFT outperforms VAE in run-time and scalability for diverse data shapes. By integrating TFT with visual analytics, this work advances fault diagnosis in multivariate time series data, fostering explainable AI approaches that improve decision-making in critical system operations."}, {"title": "2. Literature Review", "content": "Analyzing patterns in multivariate time-series data, characterized by high dimensionality and complexity, requires interdisciplinary approaches to support effective decision-making. This literature review is structured into four sec-tions. First, it identifies research needs for multivariate pattern analysis in urban and environmental studies. Second, it examines applications in power grid operations, where inherently multivariate data from diverse sensors provide practical use cases for disturbance diagnosis and pattern analysis. Third, it reviews AI and Human-in-the-Loop (HitL) methods for dimensionality reduction, enabling visual exploration and interpretation of complex datasets. Finally, it addresses challenges in current applications, emphasizing limitations in supporting experts with complex multivari-ate time-series data. Using power grid signal data as a case study, this review identifies knowledge gaps and drives"}, {"title": "2.1. Multivariate Pattern Detection and Exploration in Broad Urban Management Applications", "content": "Exploring multivariate patterns in urban and environmental data, often surrogates for underlying physical pro-cesses, is crucial for managing smart city systems. This approach supports hypothesis generation, anomaly detection, and fault diagnosis (Erhan et al., 2021; Sarker, 2022). By analyzing spatial and temporal variability across environ-mental attributes, infrastructure features, and urban characteristics, urban planners and environmental scientists can uncover insights into complex, interconnected systems such as transportation (Berres et al., 2021a; Pack, 2010; Berres et al., 2021b), building energy (Xu et al., 2022b; Cottafava et al., 2018), public health (Xu et al., 2021; Preim and Lawonn, 2020), and watershed management (Xu et al., 2022a, 2020). These insights drive the development of holistic management practices, enhancing the sustainability, resilience, and efficiency of urban environments (Bibri, 2021). \nTo emphasize the importance of interpreting multivariate data patterns, we review notable studies in environmen-tal and urban management. Xu et al. (2019) developed a web-based geovisual analytics platform leveraging machine learning and visual analytics to address culvert sedimentation, a key infrastructure issue in watershed management. The platform integrates diverse data sources and uses a tree-based feature selection algorithm and self-organizing maps (SOMs) to identify sedimentation drivers, visualize multivariate patterns, and inform mitigation strategies. This scalable, explainable AI tool is adaptable to broader environmental challenges. In the transportation sector, Dadashova et al. (2021) used multivariate time series analysis to explore how socioeconomic factors impact urban traffic conges-tion. Using data from 51 U.S. metropolitan areas, they incorporated variables such as employment rates and fuel prices into vector autoregressive models with exogenous factors (VAR-X). These models provided interpretable insights for forecasting congestion metrics and informing targeted, data-driven management strategies. Sanhudo et al. (2021) applied machine learning to improve building energy management through clustering and regression techniques. By using k-medoids clustering and dynamic time warping to enhance weather data quality, and Artificial Neural Net-works (ANN) and Support Vector Regression (SVR) to rectify errors, the study demonstrated significant potential for energy optimization. However, limited explainability of these models restricts deeper insights into underlying patterns. Finally, Hsieh (2004) extended classical techniques like PCA and CCA to nonlinear variants (NLPCA and NLCCA) using neural networks. Applied to climate and oceanographic data, these methods revealed intricate patterns in complex systems such as El Ni\u00f1o, offering valuable tools for managing multivariate data in smart grid systems and other resilient infrastructure applications.\nBased on these example studies, it can be concluded that in various fields of urban and environmental studies, analyzing multivariate spatial and time-series data supports researchers and decision-makers in several key ways:\nPerform Dimensionality reduction to group features based on multivariate similarities, facilitating the clustering of complex data. This approach aids in identifying environmental or urban phenomena by analyzing specific attributes of one or more data features (Xu et al., 2020; Sanhudo et al., 2021)."}, {"title": "Explore Dependencies", "content": "Explore Dependencies among time series of multiple variables to enable causal inference, providing insights into the underlying physical processes represented by these data variables (Dadashova et al., 2021).\nBy analyzing surrogate data to understand environmental or urban phenomena and the interdependencies between physical processes, researchers can derive insights to inform effective management practices. This approach facilitates the promotion or mitigation of specific phenomena and their underlying processes, reducing potential hazards and faults in urban systems."}, {"title": "2.2. Multivariate Pattern Detection and Exploration in Grid Operations", "content": "As a critical urban subsystem, smart grids generate vast amounts of multivariate time-series data from various devices and sensors (Syed et al., 2020). Smart meters at consumer sites record variables such as power consump-tion, voltage, and frequency, offering insights into energy usage patterns (Wang et al., 2020). Digital Fault Recorders (DFRs) capture high-frequency recordings of disturbances, namely faults, on the order of microseconds, typically capturing point-on-wave (PoW) voltages and currents at various points in a distribution system. Phasor Measurement Units (PMUs) at substations typically stream measurements such as voltage, current, frequency, and phase angle, enabling real-time stability monitoring(Biswal et al., 2023). SCADA systems aggregate data from Remote Termi-nal Units (RTUs) and Intelligent Electronic Devices (IEDs) across substations, continuously monitoring grid health through variables like voltage, current, power flow, and equipment status (Manoj, 2021), though they report read-ings on the order of seconds rather then milliseconds, in the case of PMUs, or microseconds in the case of DFRs. Distributed Energy Resources (DERs), including solar and wind energy systems, provide data on generation levels, voltage, and frequency, which are critical for renewable energy integration. Environmental sensors add weather-related data-temperature, humidity, and wind speed-essential for predicting energy demand and supply (Nyangon, 2024). Together, these data streams enable comprehensive grid analysis and control.\nIn the past decades, advanced time-series classification methods have been adopted into many power grids as a critical component of their monitoring and controls systems to facilitate anomaly detection, root cause analysis, and control purposes (Susto et al., 2018). For instance, Ceci et al. (2020) introduces ECHAD (Embedding-based CHAnge Detection), an unsupervised machine learning method for detecting shifts in multivariate time-series data, such as en-ergy metrics. ECHAD adapts dynamically to real-time patterns, improving resilience to collinearity and noise while monitoring renewable energy fluctuations and power loads. Although robust, its reliance on embeddings and one-class learning limits explainability. Similarly, Pinz\u00f3n and Colom\u00e9 (2019) proposes a Random Forest (RF)-based method for short-term voltage stability (STVS) assessment using PMU data. By classifying voltage states under disturbances like fast voltage collapses, the model provides interpretable alerts, aiding real-time decision-making. However, its reliance on predefined labels restricts its adaptability to new, unlabeled patterns. Alaca et al. (2024) introduce a two-step phase fault classification method for analyzing power grid data using convolutional neural networks (CNNs). The first step involves fault detection, determining if a fault exists in the signal, while the second step identifies fault types, such as single-line-to-ground or line-to-line faults. Various feature extraction techniques, including ampli-"}, {"title": "tude and phase (AP), fast Fourier transform (FFT), wavelet transform (WT), and power spectral density (PSD)", "content": "tude and phase (AP), fast Fourier transform (FFT), wavelet transform (WT), and power spectral density (PSD), were explored to optimize performance. The study demonstrates that combinations like AP-AP and FFT-WT yield the highest accuracy. Simulation and real-world tests validate the method's superiority over conventional one-step clas-sification, highlighting its potential for real-time fault analysis in smart grid systems. (Bakdi et al., 2021) introduces a novel data-driven methodology for analyzing multivariate time series data in grid-connected photovoltaic (GPV) systems. It employs Principal Component Analysis (PCA) for dimensionality reduction and decorrelation, followed by Kullback-Leibler Divergence (KLD) to detect anomalies. Kernel Density Estimation (KDE) refines the density estimation of transformed components (TCs) derived from PCA, enabling nonparametric and adaptive fault detection. This approach overcomes limitations of Gaussian assumptions, computational complexity, and parametric constraints. The methodology is validated through extensive experiments with real-world faults under Maximum and Intermediate Power Point Tracking (MPPT/IPPT) modes, demonstrating improved detection sensitivity, computational efficiency, and robustness to varying environmental conditions. Despite its high accuracy, both the methods are primarily designed to classify phase faults, rather than enabling an interactive ways to help domain experts explore and analyze different types of faults, and their potential connections.\nMultivariate temporal pattern analysis in grid operation sectors often focuses on detecting data anomalies in con-tinuous streams from devices such as Phasor Measurement Units (PMUs) and smart meters to extract operational insights and support decision-making. These analyses aim to enhance Fault Detection and Isolation (FDI), Predictive Maintenance, and Cybersecurity in grid management (Susto et al., 2018). Practical grid management faces several challenges that include heterogeneous data sources, nonstationary signals, computational complexity, scalability, and missing data. These challenges call for scalable, generative AI-powered methods capable of handling diverse grid time-series data efficiently to enable real-time, actionable insights for grid operations."}, {"title": "2.3. Latent Space Cartography and Visual Analytics", "content": "Deep generative models serve as universal tools for learning data distributions in high-dimensional spaces by mapping them to lower-dimensional latent spaces, enabling efficient representation and synthesis of complex data patterns (Frenzel et al., 2019). To increase the explainability and interprebility of these deep generative models and their outputs, a few recent studies have provided methodologies to visualize the latent representations of the complex high-dimension data. The latent representation is a compressed, lower-dimensional encoding of input data that is produced by generative AI models captures its essential features and structures while discarding irrelevant details, it can carry valuable information to help researcher explains how the AI models proceeds the complex data and produce the analytical outputs, such as clusters and classifications. Methodologies presented through these studies are often known as the \"Latent Space Cartography\" and \"Latent Space Visual Analytics\" Liu et al. (2019); Kwon et al. (2023), and have been developed to help users extract and analyze patterns in various types of data, emphasizing the interpretability and practical utility of latent spaces in diverse domains.\nAs examples, Frenzel et al. (2019) proposed metric-based transformations designed to improve the geometric"}, {"title": "structure of latent spaces generated by deep generative models, such as Variational Autoencoders (VAEs) and Gener-ative Adversarial Networks (GANs)", "content": "structure of latent spaces generated by deep generative models, such as Variational Autoencoders (VAEs) and Gener-ative Adversarial Networks (GANs). Their approach targets a significant gap in ensuring that latent space distances accurately represent semantic relationships, particularly in high-dimensional, non-Euclidean data like those encoun-tered in natural language processing. This method enables enhanced clustering and interpolation, which are critical for applications such as language modeling and feature synthesis. Liu et al. (2019) developed the concept of \"Latent Space Cartography\", an integrated visual analytics framework that facilitates tasks such as analogy construction, semantic dimension mapping, and latent space comparison. Designed for diverse datasets, including emojis, word embeddings, and biological features, their system employs user-defined semantic axes and advanced projection strategies, such as t-SNE and PCA, to uncover nuanced relationships within the data. By enabling interactive exploration, it bridges the gap between static visualizations and actionable insights, making it particularly valuable for scientific feature analysis and machine learning evaluation. Kwon et al. (2023) introduced the \"Latent Space Explorer\", a multimodal visual-ization tool tailored for datasets such as cardiac MRIs and ECGs. This system provides a comprehensive workflow that integrates subgroup exploration, interactive decoding, and phenotype prediction accuracy analysis. By addressing the challenges of multimodal latent representation, the tool supports domain experts in uncovering subgroup-specific correlations and testing biases, thus enhancing clinical applications in cardiovascular health. O'Mahony et al. (2022) further extended the latent space visualization paradigm by incorporating non-Euclidean geometries and multi-task metric learning to disentangle complex subgroup features in dynamic systems. Their methodology uses cartographic techniques to display latent spaces as two-dimensional visualizations, enabling users to examine patterns, correlations, and subgroup behaviors within fine-grained datasets. Applications include biological processes, where latent spaces reveal dynamic relationships affected by temporal or environmental factors, and physical systems, where domain knowledge informs geometric transformations for more robust interpretability.\nThese methodologies address key challenges in latent space analysis, such as enhancing interpretability, preserving geometric coherence, and accommodating specific data modalities. By emphasizing tailored visualization tools, they enable meaningful insights from complex data, driving advancements in AI-powered exploratory analysis across scientific, medical, and industrial fields."}, {"title": "2.4. Knowledge Gaps and Motivation", "content": "While existing methodologies in latent space cartography are valuable, they can benefit from further refinement. By integrating more advanced visual analytics techniques, such as sophisticated user interactions, enhanced analytical reasoning, and tailored visual encoding, these applications can be improved to handle more complex real-world urban data. Such enhancements would foster greater data interpretability and model explainability, supporting practical training, education, and decision-making in urban system management and operations. In the context of facilitating multivariate temporal pattern explorations to support piratical urban applications, such as the fault diagnosis in power grid data, the existing methods face the following limitations:\nKG1. Lacking Efficient Methods for Multivariate Time-series Analysis: Most existing studies employ GAN, VAE,"}, {"title": "and sentence transformer to analyze semantic data, text data, image data, and single variate time-series data", "content": "and sentence transformer to analyze semantic data, text data, image data, and single variate time-series data. VAE and GAN are not proven to be computational efficient for analyzing complex multivariate time-series analysis Studies that utilize dedicated\nKG2. Limited Scalability and Adaptibility to Varying Data Shapes: The length and number of features in time-series data collected from various sensors across urban systems can vary significantly. Existing methods that rely on Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) to derive latent vec-tors often lack scalability and generalizability for datasets with diverse shapes. These approaches frequently require substantial modifications to the AI models to adapt to differing dataset dimensions, posing challenges for efficient and flexible implementation.\nKG3. Limited Visual Analytical Reasoning for Complex Data: Most existing latent space cartography studies rely on simple 2D scatter plots with color coding to visualize the distribution of complex data after dimensionality reduction. However, this approach has significant limitations when it comes to representing data with multiple labels or diverse characteristics. The 2D color-coded point representation is inherently constrained, as it can visually encode only a very limited number of data features. Consequently, it fails to effectively capture and represent multi-faceted datasets, such as ensemble or multi-label data.\nGiven these challenges and knowledge gaps, we are motivated to develop a visual analytical framework that leverages the Temporal Fusion Transformer (TFT)\u2014a state-of-the-art generative AI model based on the transformer architecture for temporal data analytics\u2014along with advanced visual analytics techniques. Our approach seeks to facilitate the extraction and exploration of multivariate temporal patterns in complex urban data. By harnessing the TFT's high efficiency, scalability, and adaptability for handling time-series data, we aim to address knowledge gaps KG 1 and KG 2. Through the design and experimentation of advanced visual analytics techniques, such as novel visual encodings and interactive user interfaces, we propose a comprehensive visual analytical workflow. This workflow will enable the effective visualization of complex latent vectors (embeddings) generated by the Temporal Fusion Transformer (TFT), including ensemble and multi-label data. By providing deeper insights into complex patterns, our proposed framework seeks to significantly enhance pattern exploration and interpretation in urban data systems, addressing knowledge gap KG 3.\nTo evaluate the performance and accuracy of the TFT-based method, we implemented two VAE-based mod-els\u2014one utilizing a 1D convolution layer and the other employing an LSTM as the encoder\u2014to validate the outputs generated by the TFT. Alongside this task, we developed an evaluation workflow that incorporates novel metrics and ensemble visualizations to comprehensively compare multiple aspects of the TFT and VAE-based methods."}, {"title": "3. Methodology", "content": "3.1. Design Requirements\nThe target users of our framework include data scientists, domain experts, and management personnel across various urban systems. For instance, in the context of our case study using power grid data, grid operators responsible for managing urban energy systems would significantly benefit from this framework.\nTo address the identified challenges and knowledge gaps, we have established the following design requirements as the foundation of our approach:\nScalability and Efficiency in Time-Series Analytics: The proposed approach will leverage the Temporal Fusion Transformer (TFT) for its exceptional efficiency and scalability in processing multivariate time-series data. The method will ensure that the architecture adapts seamlessly to datasets of varying dimensions and complexities, providing a robust and versatile framework for diverse analytical scenarios.\nExploratory Visual Analytics: Advanced visual analytics techniques will be integrated to enhance the exploration and interpretation of multivariate temporal patterns. The framework will feature advanced user interactions, data transformation processes, tailored visual encodings, and coordinated multiple views to effectively represent en-semble and multi-label data. This comprehensive approach aims to uncover intricate patterns and relationships within the data.\nInteractive and Accessible User Interface: Intuitive, interactive web-based tools, such as online visual dashboards, will be developed to facilitate user-driven exploration of temporal data patterns and latent vector embeddings. These tools will provide an accessible and user-friendly platform for dynamic data analysis, empowering users to uncover deeper insights and interact with complex datasets meaningfully and efficiently.\nEnhanced and Customized Visual Encoding: Innovative, customized visual encodings and representations will be designed to facilitate the visualization of multiple facets of the complex latent embeddings generated by the TFT. These visualizations will support the discovery of intricate temporal and feature-level patterns, addressing the limitations of traditional latent space cartography methods and enabling multi-faceted data analysis and interpretation.\nEvaluation and Benchmarking: Validation workflows will be implemented using generative AI models established in previous latent space cartography studies, such as VAE-based models, to benchmark the performance and accuracy of the TFT-based approach. Novel metrics and ensemble visualizations will be designed and employed to comprehensively compare temporal dependencies and feature extraction capabilities across models.\nMulti-label Dependency Exploration: The proposed methods will enable users to visually explore dependencies between multiple labels in multi-label time-series data by analyzing pattern similarities through distance met-rics and other measures derived using the TFT. Real-world urban data often encompasses multiple labels created"}, {"title": "using taxonomies from different domains, which highlight interactions between diverse physical processes", "content": "using taxonomies from different domains, which highlight interactions between diverse physical processes. For example, in power grid data, event signatures frequently involve multiple labels categorized based on various technical or scientific criteria, such as weather impacts, equipment conditions, and operational states. Captur-ing and visualizing these interdependencies will provide domain scientists with deeper insights and facilitate hypothesis generation.\nThese design requirements ensure that the proposed framework effectively addresses the challenges in extracting and interpret patterns from complex multivariate temporal data, while offering robust, scalable, and interpretable solutions for analyzing multivariate urban time-series."}, {"title": "3.2. Framework Design", "content": "Our visual analytics framework comprises four key components: data preparation and preprocessing, generative AI models for dimensional reduction, visual analytical dashboards, and validation and evaluation metrics. The overall design of our framework is depicted in Figure 1."}, {"title": "3.3. Data Preparation and Preprocessing", "content": "Our framework is designed to analyze multivariate time-series data and can be adapted to facilitate pattern exploration across various disciplines. In this study, we demonstrate the framework's capabilities using power grid data as a showcase. The dataset originates from the Grid Event Signature Library (GESL), a resource developed by Oak Ridge National Laboratory (ORNL), Lawrence Livermore National Laboratory (LLNL), and Pacific Northwest National Laboratory (PNNL) under the U.S. Department of Energy's Office of Electricity. Additional details about this dataset are provided in Section 4.1.\nSimilar to many compiled time-series datasets, the data collected from GESL consists of time-series measurements from diverse electrical systems provided by various data sources (e.g., utilities, industry, and academia). This diversity results in a heterogeneous structure with varying sampling rates, scales, and feature sets, posing challenges for con-sistent analysis and classification. All of the data contained in the GESL come from field measurements; no simulated data has been used in this study, or housed in the GESL.\nTo preprocess the data, we first address its heterogeneity by normalizing all numeric features to a uniform scale. Signals with varying sampling rates are resampled to a common rate\u2014such as 20 ksps for certain providers\u2014using linear interpolation, ensuring temporal consistency across the dataset. The time-series signals are then analyzed for anomalies by calculating differences between consecutive cycles. For example, using data from Provider 1, one cycle corresponds to 333 samples at 60 Hz. Deviations exceeding a predefined threshold are flagged as anomalies, enabling the identification of event-related irregularities.\nTo isolate baseline behavior, the data are segmented into 1-second intervals, ensuring uniform segment length. For files with insufficient data, padding is applied using the largest identified non-event region. Non-event segments are repeated as needed to achieve the required length, with smooth transitions ensured by aligning with the tail of the existing data. This preserves phase, amplitude, and temporal continuity. This segmentation and padding approach ensures all data segments are consistent and prepared for downstream analysis."}, {"title": "3.4. Generative AI Models", "content": "After preprocessing the data, we construct and apply two types of generative models with encoding capabilities: the Temporal Fusion Transformer (TFT) and a Variational Autoencoder (VAE). These models are used to perform di-mensionality reduction, capturing multivariate temporal patterns within the time-series data with multiple features by deriving latent vectors across a range of dimensions. The optimal latent dimension is determined through heuristic exploration facilitated by a visual analytics interface. This interface enables users to interact directly with the gen-erative AI models, experiment with different combinations of hyperparameters, and visually explain and interpret the results. In this study, we employed two types of VAEs: a 1D-Convolutional VAE and a VAE-LSTM, which are detailed through the following subsections."}, {"title": "3.4.1. TFT", "content": "The Temporal Fusion Transformer (TFT) is a specialized neural network architecture designed for temporal data representation and feature extraction (Lim et al., 2021). The model leverages a Transformer-based framework, starting with a linear input projection layer that maps input features into a high-dimensional embedding space optimized for sequence modeling (Cristian et al., 2024). To preserve temporal order information, positional encodings are incorporated into the embeddings, enabling the model to effectively capture sequential dependencies. In recent studies, the TFT has been widely employed for prediction and forecasting tasks using multivariate time-series data (Lim et al., 2021; Liao, 2024).\nIn this study, the core of the TFT architecture consists of Transformer encoder layers, which are utilized to model complex temporal dependencies and interactions across the sequence. These layers allow the model to effectively capture both short- and long-term relationships within the temporal data. To aggregate the temporal information, the output of the Transformer encoders undergoes mean pooling across the sequence length, producing a summarized representation. This representation can be further refined through an optional linear projection to generate the final embeddings for each input sample. Our TFT architecture is designed to process batches of temporal data with dimen-sions corresponding to the batch size, input feature dimension, and sequence length. It outputs latent embeddings that encapsulate both temporal and feature-level characteristics, making them suitable for a range of downstream tasks. In evaluation mode, the trained model computes embeddings for the input data, which are subsequently stored and mapped to corresponding filenames for further analysis. This architecture and workflow enable robust time-series representation learning, feature extraction for temporal prediction models, and domain-specific applications requiring detailed temporal embeddings. By employing Transformer encoders, the TFT demonstrates high expressivity and adaptability, making it particularly effective in capturing intricate temporal dependencies and providing a versatile solution for temporal data analytics."}, {"title": "3.4.2. 1D-Convolutional VAE", "content": "In this study, Variational Autoencoders (VAEs) are utilized to learn compact latent representations of multivariate time-series data, with an emphasis on capturing both temporal and feature-level dependencies. The 1D CNN VAE architecture consists of three main components: an encoder, a latent space representation, and a decoder. The encoder employs 1D convolutional layers to extract hierarchical temporal features from the input time series. These convolu-tional layers are followed by fully connected layers that parameterize the mean and log-variance of the latent space distribution. The latent space is sampled using the reparameterization trick, which allows for differentiability and ensures stable optimization during backpropagation. The decoder reconstructs the original input data from the latent representations using transposed convolutional layers to upsample the data back to its original dimensions.\nThe training process is driven by a composite loss function that combines Mean Squared Error (MSE), which re-construction loss, which measures the fidelity of the reconstructed output to the input data, and the Kullback-Leibler (KL) divergence. The KL divergence regularizes the latent space to follow a standard Gaussian distribution, enabling"}, {"title": "meaningful and compact representations", "content": "meaningful and compact representations.\nThe model is optimized over multiple epochs using the Adam optimizer with a low learning rate to ensure training stability. After training, the latent vectors are extracted for all samples, providing a compressed and semantically rich representation of the input time series. These latent vectors are subsequently saved and mapped to corresponding filenames for downstream applications. This implementation offers a robust framework for capturing and compressing the spatiotemporal structure of multivariate time series into a latent embedding space. These embeddings are highly versatile, supporting tasks such as anomaly detection, clustering, and predictive modeling, and demonstrating the effectiveness of the VAE for temporal data representation and feature extraction."}, {"title": "3.4.3. VAE with a LSTM Layer", "content": "Building upon the VAE architecture with 1D convolutional layers described earlier, this research also explores a complementary approach by integrating a Variational Autoencoder (VAE) with an LSTM-based architecture. This variant is designed to handle temporal data with a focus on preserving sequential dependencies, making it particularly suited for time-series data with intricate temporal dynamics.\nThe encoder employs bidirectional LSTM layers to capture both forward and backward temporal relationships in the data. This design ensures a comprehensive understanding of sequential dependencies across the entire time horizon. The sequential output from the LSTM layers is then flattened and passed through a fully connected layer, which parameterizes the latent space by computing the mean and log-variance of the latent distribution. The latent space representation is sampled using the reparameterization trick, facilitating smooth gradient flow during backpropagation while maintaining differentiability. The decoder reconstructs the input sequences from the latent vectors using a combination of fully connected and LSTM layers. This reconstruction pathway is carefully designed to preserve the temporal structure of the original data, ensuring accurate sequence generation.\nSimilar to the VAE with 1D convolutional layers, the training process optimizes a composite loss function that balances MSE and KL divergence. The model is trained over multiple epochs using the Adam optimizer, with batched data to enhance computational efficiency. After training, the latent vectors are extracted, serving as compressed representa-tions of the input sequences for downstream tasks such as clustering, anomaly detection, or predictive modeling. In addition to handling temporal data, this implementation incorporates metadata processing to enhance analysis. Event tags associated with the input sequences are parsed to generate binary vectors indicating the presence of specific events. These vectors are visually encoded using smooth color gradients, improving interpretability and facilitating the exploration of relationships between latent vectors and metadata. A mapping from filenames to event tags, binary arrays, and associated properties supports detailed metadata analysis, integrating advanced deep learning with visual analytics.\nThis VAE-LSTM approach complements the VAE with 1D convolutional layers by offering an alternative architecture that excels in tasks requiring explicit modeling of long-term sequential dependencies, thereby enriching the analytical capabilities for temporal data representation and interpretation. Both of them are later used as the benchmark to"}, {"title": "evaluate the performance of the TFT", "content": "evaluate the performance of the TFT."}, {"title": "3.5. Latent Space Visual Analytics"}]}