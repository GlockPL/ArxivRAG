{"title": "MULTI-AGENT PATH FINDING IN CONTINUOUS SPACES WITH PROJECTED DIFFUSION MODELS", "authors": ["Jinhao Liang", "Jacob K. Christopher", "Sven Koenig", "Ferdinando Fioretto"], "abstract": "Multi-Agent Path Finding (MAPF) is a fundamental problem in robotics, requiring the computation of collision-free paths for multiple agents moving from their respective start to goal positions. Coordinating multiple agents in a shared environment poses significant challenges, especially in continuous spaces where traditional optimization algorithms struggle with scalability. Moreover, these algorithms often depend on discretized representations of the environment, which can be impractical in image-based or high-dimensional settings. Recently, diffusion models have shown promise in single-agent path planning, capturing complex trajectory distributions and generating smooth paths that navigate continuous, high-dimensional spaces. However, directly extending diffusion models to MAPF introduces new challenges since these models struggle to ensure constraint feasibility, such as inter-agent collision avoidance. To overcome this limitation, this work proposes a novel approach that integrates constrained optimization with diffusion models for MAPF in continuous spaces. This unique combination directly produces feasible multi-agent trajectories that respect collision avoidance and kinematic constraints. The effectiveness of our approach is demonstrated across various challenging simulated scenarios of varying dimensionality.", "sections": [{"title": "1 Introduction", "content": "Multi-agent path finding (MAPF) is a critical problem in robotics and autonomous systems, where the goal is to compute collision-free paths for multiple agents navigating from their respective start positions to designated goals in a shared environment Stern et al. [2019]. This problem finds formulation in numerous domains, such as gaming, automated warehouses, and aircraft taxing Li et al. [2021a]. The problem is inherently challenging due to the high-dimensional joint configuration space and the need for coordination among multiple agents to avoid collision. The complexity increases exponentially with the number of agents, making scalability a significant issue for traditional MAPF algorithms. Additionally, existing studies typically consider discrete environments Stern et al. [2019], Hopcroft et al. [1984], thus further limiting their applicability in scenarios in-the-wild.\n\nThe complexity of MAPF in continuous or high-dimensional environments calls for approaches that move beyond traditional discretized methods. Within this context, trajectory optimization has recently been tackled using diffusion models, a powerful class of generative models originally developed for tasks in image and signal processing Song and Ermon [2019], Ho et al. [2020]. These models approximate high-dimensional probability distributions by itera-"}, {"title": "2 Related Work", "content": "Multi-Agent Path Finding. The classical MAPF problem assumes that time and the environment are discretized into time steps and grids, respectively Stern et al. [2019]. Under this assumption, numerous search algorithms have been developed to efficiently obtain near-optimal solutions for MAPF in discrete environments, even for scenarios involving hundreds of agents Li et al. [2019, 2021b], Okumura et al. [2022a], Li et al. [2021b]. While this assumption significantly reduces the complexity of MAPF, it creates a gap between the problem's formulation and real-world ap-plications, posing challenges in many domains Shaoul et al. [2024]. Some studies attempt to generalize MAPF to con-tinuous environments using probabilistic roadmaps Kavraki et al. [1996] and rapidly exploring random trees LaValle[1998]. Another line of research formulates MAPF as a constrained optimization problem with continuous variables, employing methods such as sequential convex programming Augugliaro et al. [2012], Chen et al. [2015] and the al-ternating direction method of multipliers Chen et al. [2023]. However, these methods often fail to find any solution if there are a large number of agents and obstacles, even if one exists.\n\nPath Finding with Generative Models. There has been a growing interest in leveraging generative models for path finding problems. Existing studies primarily focus on using diffusion models to solve single-agent path finding problems Janner et al. [2022], Carvalho et al. [2023]. Besides these approaches, Okumura et al. utilizes a conditional variational autoencoder to predict cooperative timed roadmaps to aid in solving MAPF in continuous spaces. Shaoul et al. uses diffusion models to generate a trajectory for a single agent and employs classical searching algorithms to determine the final solutions. However, these methods do not ensure the feasibility of the diffusion model outputs and"}, {"title": "3 Preliminaries", "content": "Diffusion Models. Diffusion Models (DMs) are a class of probabilistic generative models designed to transform simple noise distributions into complex target data distributions. They operate through two Markov chains: (1) a forward diffusion process that progressively adds noise to data samples, and (2) a reverse denoising process that iteratively removes noise to recover data samples Yang et al. [2023]. In the forward process, Gaussian noise is incrementally added to the data x0 ~ q(x0) over T timesteps, producing a sequence of noisy samples x1, x2,..., XT:\n\n\n\nwhere \u1e9et \u2208 (0, 1) is a predefined variance schedule controlling the amount of noise added at each step, ensuring that the final distribution approximates an isotropic Gaussian. The reverse process begins with a sample from the noise distribution XT ~ N(0, I) and aims to reconstruct data samples by sequentially removing noise:\n\n\n\nwhere @ represents the learned parameters of neural networks, and \u03bc\u03b5 and Se are functions parameterizing the mean and covariance, respectively. Through this process, DMs iteratively transform random noise samples into data resem-bling the target distribution q(x0).\n\nScore-based DMs employ a neural network se to approximate the score function \u2207xt log q(xt), which points in the direction of the steepest ascent of the data density at each noise level Song et al. [2020]. The training objective is to minimize the difference between the true score and the network's approximation Yang et al. [2023]:\n\n\n\nAs shown by Yang et al. [2023], classical DMs are a special case of score-based DMs. In the subsequent sections, our focus will be on score-based DMs due to their flexibility and effectiveness."}, {"title": "3.1 Multi-Agent Path Finding in Continuous Space", "content": "Multi-Agent Path Finding (MAPF) involves computing collision-free trajectories for multiple agents moving from their respective start locations to designated goals within a shared environment. Consider a set of Na agents A = {a1, a2,..., an } operating on a two-dimensional plane, in a continuous space. Each agent a\u017c is modeled as a sphere with radius r\u2081 and has a trajectory over H time steps denoted by \u03c0\u2081 = [\u03c0\u1f76,\u03c0?,...,\u3160], where \u03c0\u1e25 = (x, y) represents the position of agent a\u017c at time h. The agents have start positions B = [b1,b2,...,bna] and goal posi-tions E = [e1, 2,...,ena]. In addition, their movement must adhere to kinematic constraints, such as maximum velocities. The environment contains No obstacles O = {01,..., ON\uff61}. The objective is to find a set of trajectories \u03a0 = {\u03c01, \u03c02, ..., \u03c0\u2163\u300f }, each associated with agent ai, that minimizes a cost function while ensuring feasibility with respect to environmental constraints and inter-agent collision avoidance.\n\nThe MAPF problem can be formulated as the following constrained optimization:\n\n\n\n\n\n\n\n\n\nwhere I : RNa\u00d7H\u00d72 \u2192 R is the cost function (e.g., total travel time or energy consumption), and Nobs denotes the feasible region of the environment considering obstacles. Constraints (4b) ensure that agents avoid obstacles, (4c)"}, {"title": "4 Constrained Diffusion Models", "content": "In this section, we first revisit the sampling process for DMs and then investigate the integration of DMs and optimiza-tion to constrain the output of DMs satisfying constraints."}, {"title": "4.1 Recall The Sampling Process in DMs", "content": "Since the sampling process in DMs is a Markov process, we generate x0 by iterative sampling from the conditional distribution xt ~ q(x+xo) as t \u2192 0, where q(xt|x0) shifts from Gaussian noise to the training data distribution as t decreases. The sample is optimized with respect to each interim data distribution by M iterations of Stochastic Gradient Langevin Dynamics (SGLD):\n\n\n\nwhere z is standard normal, yt > 0 is the step size, and \u2207x log q(x|xo) is approximated by the learned score function So(xt,t).\n\nChristopher et al. [2024] derive theory connecting the application of SGLD for sampling to iterative, gradient-based optimization algorithms. The described process ensures that, under appropriate conditions, samples are distributed according to the target distribution q(xt). As shown by Christopher et al. [2024], SGLD converges toward a stationary distribution under mild assumptions, transitioning toward deterministic gradient ascent as the stochastic component diminishes. This connects the reverse diffusion process to an optimization problem, minimizing the negative log-likelihood of the data distribution and forming the foundation for constrained sampling via iterative projections."}, {"title": "4.2 Projected Diffusion Models", "content": "In this subsection, we introduce Projected Diffusion Models (PDM) to ensure that generated outputs satisfy predefined constraints. While the objective remains consistent with traditional score-based DMs, the solution is restricted to lie within a feasible region \u03a9. This transforms the optimization problem into a constrained formulation Christopher et al. [2024]:\n\n\n\n\n\nThe reverse sampling process in PDM aligns closely with that of traditional score-based DMs. Specifically, the score network se(xt, t) estimates the gradient of the objective in Equation (6a), enabling iterative updates as defined in"}, {"title": "5 Efficient Projections for MAPFS", "content": "While PDM provides a useful method to steer samples generated by the generative model to satisfy relevant constraints, projecting onto nonconvex sets can be a computationally expensive operation, especially when it is required to be computed at each step of the sampling process. To address this shortcoming, we develop a projection mechanism to generate feasible trajectories for all agents. To accelerate the projection process, we adopt the augmented Lagrangian method (ALM) Boyd et al. [2011] to the projection process."}, {"title": "5.1 Collision-free Trajectories Projection Mechanism", "content": "In the following, we define the mathematical formulation of the feasible region \u03a9 for the MAPF problem, distinguish-ing between convex and nonconvex constraints.\n\nConvex Constraints. First, each agent's trajectory must start and end its specified start and goal points, as specified in Constraints (4c) and (4d).\n\nAdditionally, agents must adhere to maximum velocity limits between consecutive time steps:\n\n\n\nwhere vmax denotes the maximum allowable velocity for agent ai, and At is the time interval between steps.\n\nTogether, these constraints define a convex set:\n\n\n\nNonconvex Constraints. To ensure collision avoidance between agents, we impose the following nonconvex con-straints:\n\n\n\nwhere Ra denotes the minimum distance between agents at each time.\n\nSimilarly, to avoid collisions between agents and static obstacles, we have:\n\n\n\nwhere R\u00ba denotes the minimum distance between agents and obstacles to guarantee noncollision. Similarly, these two constraints define\n\n\n\n\nThe complete feasible set is given by: \u03a9 = \u03a9\u03a9n. Although the projector P\u03a9 can generate feasible MAPF trajec-tories, the nonconvex constraints result in high computational costs."}, {"title": "5.2 ALM for Efficient Projection", "content": "To address this issue, we seek to relax the nonconvex constraints in MAPF to transform the original nonconvex quadrat-ically constrained quadratic problem (QCQP) into a convex QCQP. To facilitate analysis, we rewrite the inequality constraints as equalities:\n\n\n\n\n\nwhere di,j,h and di,j,h (with vector form d\u00ba and d\u00b0, respectively) are positive dummy variables. The Lagrangian function is defined as:\n\n\n\nwhere va and vare Lagrangian multipliers, Ha and Ho represent the equality constraints defined by (14a) and (14b), respectively. Specifically, Ha corresponds to the agent collision avoidance constraints (Ra)\u00b2 \u2013 (\u03c0 - \u03c0)\u00b2 + di,j,h = 0, \u2200i, j, i \u2260 j, \u2200h, and Ho corresponds to the obstacle collision avoidance constraints (R\u00ba)2 \u2212 (\u03c0\u1e25 - oj)\u00b2 + di,j,1 = 0, Vi, j, Vh. To improve the poor convergence of the classical lagrangian function, we can augment the Lagrangian function with a penalty on the constraint residuals Boyd et al. [2011], Kotary et al. [2022]:\n\n\n\nwhere pa and po are chosen penalty weights on the equality residuals. The corresponding Lagrangian Dual function can be defined:\n\n\n\nThe Lagrangian Dual Problem is to maximize the dual function:\n\n\n\n\n\nThrough weak duality, solving the dual problem (18) can provide a lower bound for the original problem's optimal solution. Specifically, a feasible solution \u266b to the Primal problem can be derived from the dual solution (v, v) via the stationarity condition:\n\n\n\n\nThe dual problem (18) can be solved iteratively, named the Dual Ascent method (DAM):\n\n\n\n\n\n\n\nUsing ALM significantly accelerates the projection process, especially in complex scenarios. The augmented sampling process is described in Algorithm 2."}, {"title": "6 Experiments", "content": "We evaluate the performance of PDM in generating feasible trajectories for MAPF in continuous spaces. We com-pare PDM against standard Diffusion Models (SDM) and Guided Diffusion Models (GDM) across three challenging scenarios: Narrow Corridors, Obstacle-Dense Environments, and Agent-Dense Environments."}, {"title": "6.1 Experimental Setup", "content": "We conduct experiments in the following scenarios:\n\n\u2022 Narrow Corridors: Scenarios where agents must exchange positions in confined spaces, requiring precise coordination to avoid collisions."}, {"title": "6.2 Evaluation on Narrow Corridors", "content": "The Narrow Corridor scenarios are designed to test the ability of the methods to generate feasible trajectories in tight spaces where agents must exchange positions. Figures 1(a) and 1(b) illustrate the trajectories generated by PDM in two different narrow corridor scenarios. Agents (solid circles) successfully reach their respective goals (empty circles) by"}, {"title": "6.3 Evaluation on Obstacle-dense Scenarios", "content": "In the Obstacle-Dense scenarios, we test the methods in environments with twenty randomly placed obstacles and four agents. Figures 2(a) and 2(b) show the trajectories generated by PDM, demonstrating its ability to navigate complex environments while avoiding collisions even when agents need to navigate scenarios presenting a large number of obstacles."}, {"title": "6.4 Evaluation on Agent-dense Scenarios", "content": "Finally, we test the ability of our proposed method to handle a large collection of agents. An increasing number of agents significantly introduces computational costs during projection, which makes standard projection methods challenging to handle. To address this, we use the ALM method to efficiently address Agent-dense Scenarios. Table 3 evaluates PDM, DM, and GDM in agent-dense scenarios (AS 1 and AS 2). PDM achieves the lowest violation rates (0.31 and 0.17) and shortest path lengths (5.2021 and 5.1631), highlighting its efficiency in handling high agent density. GDM also shows moderate performance, with higher violation rates and longer path lengths compared to PDM. DM performs the worst, with significantly higher violation rates (3.78 and 2.99) and longest paths (11.1599 and 11.4114), indicating limited suitability for agent-dense conditions.\n\nThese results are significant as they demonstrate the power of combining diffusion models with constrained optimiza-tion techniques to address problems that would be otherwise challenging to be tackled by these two areas indepen-dently."}, {"title": "7 Conclusion", "content": "In this paper, we have presented a novel approach that combines constrained optimization techniques with DMs to generate collision-free trajectories for MAPF in continuous spaces. By integrating constraints directly into the diffusion process, our method enables the direct generation of feasible solutions for MAPF without the need for expensive rejection sampling or post-processing steps. This integration ensures that the generated trajectories satisfy all necessary constraints, including collision avoidance between agents, adherence to kinematic limits, and compliance with start and goal positions.\n\nTo address the computational challenges inherent in handling complex constraints, especially in scenarios with a large number of agents or obstacles, we designed an ALM to efficiently manage the projection process within the diffusion framework. The ALM significantly accelerates the computation by transforming the constrained optimization problem into a series of unconstrained problems augmented with penalty terms and Lagrange multipliers. This enhancement makes our approach scalable and practical for real-world applications where computational resources and time are critical factors.\n\nOur preliminary experiments across various challenging scenarios\u2014including narrow corridors, obstacle-dense envi-ronments, and agent-dense environments-demonstrate the effectiveness and robustness of our proposed method. In narrow corridor scenarios, where precise coordination is crucial, our PDM successfully generated feasible trajectories that allowed agents to exchange positions without collisions. In obstacle-dense environments, PDM consistently navi-gated agents through complex paths while maintaining zero violation rates and optimizing path lengths. In agent-dense scenarios, despite the increased complexity due to the higher number of agents, PDM maintained superior performance with the lowest violation rates and shortest total path lengths.\n\nCrucially, the integration of constrained optimization into the diffusion process not only ensures constraint satisfaction but also improves the overall quality of the generated trajectories. By embedding constraint handling directly within the generative model, the aim is to eliminate the reliance on heuristic adjustments, leading to a cohesive and effective solution. We hope that applications like this one would help to bridge the gap between probabilistic generative models and constrained optimization, opening new avenues for applying diffusion models to complex multi-agent robotic systems."}]}