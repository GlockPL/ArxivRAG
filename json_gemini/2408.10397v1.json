{"title": "Webcam-based Pupil Diameter Prediction Benefits from Upscaling", "authors": ["Vijul Shah", "Brian B. Moser", "Ko Watanabe", "Andreas Dengel"], "abstract": "Capturing pupil diameter is essential for assessing psycho- logical and physiological states such as stress levels and cognitive load. However, the low resolution of images in eye datasets often hampers pre- cise measurement. This study evaluates the impact of various upscaling methods, ranging from bicubic interpolation to advanced super-resolution, on pupil diameter predictions. We compare several pre-trained methods, including CodeFormer, GFPGAN, Real-ESRGAN, HAT, and SRResNet. Our findings suggest that pupil diameter prediction models trained on upscaled datasets are highly sensitive to the selected upscaling method and scale. Our results demonstrate that upscaling methods consistently enhance the accuracy of pupil diameter prediction models, highlighting the importance of upscaling in pupilometry. Overall, our work provides valuable insights for selecting upscaling techniques, paving the way for more accurate assessments in psychological and physiological research.", "sections": [{"title": "1 Introduction", "content": "The widespread adoption of eye-tracking technology in daily life is accelerating, as highlighted by innovations like Apple's camera-based eye tracking [2, 13]. As a fortunate side-effect, these technologies enable the analysis of human cognitive states, which are deeply connected to observable features in the eyes [9, 10]. While much of the existing research focuses on blink detection [17] and gaze estimation [4, 38, 51], which employ biomarker usage [29], infrared reflections [12], or image analysis techniques [16], there is comparatively less emphasis on measuring pupil diameters [5, 41]. Yet, accurately capturing pupil size is critical for assessing various physiological and psychological conditions: Recent research shows that the diameter of the pupil can indicate levels of stress [39], focus [30, 47], or cognitive load [20, 24, 40]. Moreover, pupil size is linked to the activity of the locus coeruleus [19, 34], a crucial brain region for memory management over both short and long terms [20, 25]. It is also vital in other medical contexts, such as evaluating the pupillary light reflex in patients with brain injuries in intensive care settings [23]. Therefore, precise estimation of pupil diameter is essential for advancing the effectiveness of image-based eye-tracking technologies."}, {"title": "2 Related Work", "content": "In this section, we briefly review the usage of image SR as a pre-processing step for downstream tasks and survey the state-of-the-art of pupil diameter estimation."}, {"title": "2.1 Super-Resolution as Pre-Processing", "content": "Image SR is the process of transforming a LR image into a HR one, effectively solving an inverse problem [31]. More explicitly, a SR model $M_{\\theta} : R^{H\\times W\\times C} \\rightarrow R^{s.H\\times s.W\\times C}$ is trained to inverse the degradation relationship between a LR image $x \\in R^{H\\times W\\times C}$ and the HR image $y \\in R^{s\\cdot H\\times s\\cdot W\\times C}$, where s denotes the scaling factor and the degradation relationship can be described by\n$x = ((yk) \\downarrow_{s}+n)_{JPEGq}$,\nwhere k is a blur kernel, n the additive noise, and q the quality factor of a JPEG compression. In a supervised setting, the training is based on a dataset $D_{SR} = \\{(x_i, y_i)\\}_{i=1}^{N}$ of LR-HR image pairs of cardinality N and on the overall optimization target\n$\\theta^* = \\underset{\\theta}{arg\\,min} \\sum_{(x_i,y_i) \\in D_{SR}} ||M_{\\theta}(x_i) - y_i||^2$"}, {"title": "2.2 Pupil Diameter Estimation", "content": "Ni et al. introduced a method named BINOMAP for estimating pupil diameter, utilizing dual cameras referred to as master and slave - as a binocular geometric constraint for analyzing gaze images [37]. This model is built on Zhang's algorithm, which recorded a mean absolute error of 0.022\u00b10.017mm [53]. Similarly, Caya et al. used a camera positioned 10cm away from the subject's face to capture facial images. These images were then processed on a Raspberry Pi, which involved converting RGB images to grayscale, adjusting contrast and brightness, reshaping images, and applying the Tiny-YOLO algorithm for pupil diameter estimation [21]. Their approach resulted in measurement accuracies with a percent difference of 0.58% for the left eye and 0.48% for the right eye. Both works face significant constraints related to specific conditions, including the necessity for dual cameras and maintaining a constant, fixed distance between the face and the camera. Another major limitation of these works is that their datasets are not publicly available, contrary to the EyeDentify dataset [42]."}, {"title": "3 Methodology", "content": "The goal of this work is to apply SR models of the form $M_{\\theta}: R^{H\\times W\\times C} \\rightarrow R^{sH\\times s.W\\times C}$ to improve the quality of eye images derived from face webcam images, denoted as $D_{eyes} \\subset D_{faces}$, which is crucial for accurate pupil diam- eter estimation and cognitive state analysis. More formally, we aim at con- structing $D_{eyes}^{M_{\\theta}} = \\{(M_{\\theta}(x_i), y_i)\\}_{i=1}^{N}$, where $(x_i, y_i) \\in D_{eyes} \\subset R^{H \\times W \\times C} \\times \\mathbb{R}$"}, {"title": "3.1 SR Techniques", "content": "Regarding SR methodologies, we identify two primary factors that fundamentally influence the performance and outcomes of SR models $M_{\\theta}$: the architecture of the models and their training objectives to optimize $\\theta$ [33]. Based on the latter, SR models can be broadly categorized into two groups: regression-based models, which typically employ a regression loss, and generative SR models, which utilize adversarial loss mechanisms. These distinctions are crucial as they result in varying SR approximations, which can subsequently impact the accuracy of pupil diameter estimations. To encompass the breadth of techniques available and ensure a comprehensive evaluation, we have selected at least two distinct approaches from each category:\nRegression-based Models:\n\u2022 SRResNet: A general SR method that draws architectural inspiration from ResNet [15, 26].\n\u2022 HAT: A state-of-the-art vision transformer designed for image SR [8, 11]."}, {"title": "3.2 EyeDentify++", "content": "As a result of the examination of GFPGAN, CodeFormer, Real-ESRGAN, HAT, and SRResNet SR models for pupil diameter estimation, we can create five additional datasets containing left and right eye images separately, which we call EyeDentify++. Due to the different SR approximations, the later stages, where we recognize faces, crop eyes, and detect blinks, result in retaining and discarding different amounts of images. More formally, $\\gamma_{blink}(D_{eyes}^{GFPGAN\\times2})| \\neq \\gamma_{blink}(D_{eyes}^{HAT\\times2})|$. Figure 3 compares the number of images in the original dataset with those in the SR datasets after blink detection. The results indicate that S enhances the accuracy of blink classification by improving the calculation of the EAR ratio through clearer eye landmark detection on the 2x and 4x up-scaled images and providing higher-quality images for feature extraction in the subsequent blink detection phase [42]."}, {"title": "4 Experiments", "content": "In this section, we present our experimental part, which consists of model and training details as well as quantitative and qualitative results."}, {"title": "4.1 Model Details", "content": "For pupil diameter prediction, we employed the same regression models as suggested in EyeDentify [42]: ResNet18, ResNet50, and ResNet152, with the same model configuration and processing steps. The datasets created through SR methods were used to train and evaluate these ResNet models. We upscaled the eye images by 2x and 4x using bi-cubic interpolation to reach 64 x 32 and 128 x 64 dimensions. We then refined the images using SR models (e.g., GFPGAN, CodeFormer, Real-ESRGAN, HAT, and SRResNet)."}, {"title": "4.2 Training Details", "content": "We followed the training setup from the original work [42]. Using 5-fold cross- validation, we trained ResNet18, ResNet50, and ResNet152 from scratch on all datasets for 50 epochs, with a batch size of 128, separately for left and right eyes. We used the AdamW optimizer with default settings, a weight decay of $10^{-2}$, and an initial learning rate of $10^{-4}$, which was reduced by 0.2 every 10 epochs."}, {"title": "4.3 Results", "content": "Table 1 presents 5-fold cross-validation results for ResNet18, ResNet50, and ResNet152 on SRx2 and SRx4 datasets. Compared to the original EyeDentify dataset, we can observe that upscaling greatly benefits pupil diameter prediction.\nScale Sensitivity. Table 1 reveals a complex relationship between the scale factor and the performance of SR methods. There is no consistent trend of improvement or deterioration as the scale increases from \u00d72 to \u00d74 across all methods.\nPotential Overfitting. Certain SR methods exhibit exceptional performance in specific configurations but perform poorly in others. For instance, while ResNet152 shows improved results with bicubic interpolation at \u00d72 scale, it tends to overfit with SR at higher scales. This variability could indicate overfitting to particular network architectures, highlighting a need for robustness in classifier selection rather than focusing solely on image enhancement.\nBest Models. Across different setups, bicubic upsampling frequently achieves optimal performance for both left and right eyes, particularly notable in the ResNet18 architecture. However, advanced SR methods like Real-ESRGAN and SRResNet also consistently demonstrate lower error rates, underscoring their potential effectiveness in specific configurations. These findings suggest a balanced approach in selecting SR methods, considering both traditional techniques and advanced models based on specific needs.\nVisualizations. Figure 5 shows the Class Activation Maps (CAM) [54] from the final convolution layer for each model, tested on a participant viewing the same display color across all datasets. The CAM visualizations show that upscaling affects where prediction models focus their attention, with variations in the same image revealing shifts in attention patterns. The top-performing models usually show high activation corresponding to the shape of the eye (see"}, {"title": "5 Limitations", "content": "This study faces several challenges, as shown in Figure 4. Participants were recorded in natural postures with varying distances from the webcam and no strict positioning guidelines, leading to inconsistencies like movement (A), gaze shifts (B), head/body turns (C), and actions like talking or smiling (D). Differences in eye structure, skin tone, and iris color across diverse nationalities and demographics make it difficult to generalize the model. Variations in lighting and screen color"}, {"title": "6 Conclusion & Future Work", "content": "In this work, we investigated the role of SR techniques in enhancing the accuracy of pupil diameter prediction from webcam-based images, which is crucial for assessing psychological and physiological states. Our experiments, across multiple upscaling methods and neural network architectures, demonstrate that SR can significantly refine the feature details necessary for more precise pupil measurements. Key findings indicate that while the benefits of SR are clear, they are not uniformly distributed across different scales and methods. For instance, although traditional bicubic upscaling often performs well, advanced SR techniques like Real-ESRGAN and SRResNet generally provide superior error rates under specific conditions. In conclusion, while SR presents a promising avenue for enhancing low-quality, webcam-derived images for pupilometry, it requires nuanced application and thorough validation to fully realize its benefits. Future work will aim to extend these initial findings by exploring additional SR methods and integrating more diverse data conditions to ensure the robustness and applicability of pupil diameter estimation techniques in real-world scenarios. This research not only advances our understanding of image upscaling in pupilometry but also sets a strong foundation for future advancements in eye-tracking technologies."}]}