{"title": "Universal Quantum Tomography With Deep Neural Networks", "authors": ["Nhan T. Luu", "Truong Cong Thang"], "abstract": "Quantum state tomography is a crucial technique for characterizing the state of a quantum system, which is essential for many applications in quantum technologies. In recent years, there has been growing interest in leveraging neural networks to enhance the efficiency and accuracy of quantum state tomography. Still, many of them did not include mixed quantum state, since pure states are arguably less common in practical situations. In this research paper, we present two neural networks based approach for both pure and mixed quantum state tomography: Restricted Feature Based Neural Network and Mixed States Conditional Generative Adversarial Network, evaluate its effectiveness in comparison to existing neural based methods. We demonstrate that our proposed methods can achieve state-of-the-art results in reconstructing mixed quantum states from experimental data. Our work highlights the potential of neural networks in revolutionizing quantum state tomography and facilitating the development of quantum technologies.", "sections": [{"title": "I. INTRODUCTION", "content": "A promising avenue for both research and technological advancements has been presented thanks to progress in con- trolling capacity and manipulation of small quantum systems. These systems offer potential applications in various fields such as quantum information processing and computation [1]\u2013 [3], quantum chemistry simulations [4]\u2013[6], secure communi- cation [7], [8], among with others notable works [4], [9], [10]. In recent breakthroughs, the successful demonstration of a 53- qubit quantum computer accomplishing a computational task in a fraction of the time expected on a classical supercomputer [11] underscore the remarkable speedup achievable through quantum systems. This acceleration is attributable in part to the exponentially vast state space available for storing and manipu- lating information in quantum systems [12]\u2013[14]. Nonetheless, while the expansive state space offers opportunities, it also presents challenges in accurately characterizing and describing these systems.\nQuantum State Tomography (QST) [15]\u2013[17] aims to ascer- tain the unknown quantum state by conducting measurements on a finite set of identical copies of the system. If the state is characterized by the density matrix o, residing in ad- dimensional Hilbert space, approximately O(d/e) copies are necessary to achieve an estimate of @ with an error (measured as total variation distance) less than \u025b [18]. This underscores the considerable resource demands of QST for large-scale systems.\nIn a broader context, QST can be viewed as an inverse problem [19], [20]. Consequently, linear inversion [21] is often considered the most straightforward approach. However, it has drawbacks, such as the potential to yield a non-physical state and the inability to analytically determine the mean squared error bound of the estimate. To address these limitations, sev- eral alternative QST methods have been developed, including maximum-likelihood estimation (MLE) [22], [23], Bayesian tomography [24], [25], compressed sensing techniques [26], [27], and matrix-product states [28], [29], where MLE remains the most commonly employed approach.\nIn recent times, machine learning techniques have been employed in QST, showing promising outcomes [30]\u2013[32]. Specifically, generative models [33]\u2013[35], often in the form of restricted Boltzmann machines (RBMs), have emerged as effective Ans\u00e4tze with minimal parameters to depict a quantum state and understand the probability distribution of anticipated outputs [30], [36], [37]. Additionally, deep neural networks have been utilized in QST, enabling physicists to harness the swift advancements in machine learning methodologies.\nIn our research, we introduce QST with 2 type of neural networks (NNs) architecture: Restricted Feature Based Neural Network (RFB-Net) and Mixed States Conditional Generative Adversarial Network (MS-CGAN). RFB-Net is a modified QST-NN [38] with modified regression modules that can classify quantum states into specific specific class and pointing out its features of the quantum state within certain constraints, finally using these features and classes to infer the full state of the system. On the other hand, MS-CGAN is an architecture derived from QST conditional-GAN (QST-CGAN) [39], which contain certain modifications from the original work to extend its reconstruction range to include mixed states. This network is improved for a better estimation of the density matrix of the system while extend reconstruction range to multiple type of quantum states. Both of these techniques can accurately construct many types of given simulated measurement and shown great promise in practical intermediate-scale quantum systems."}, {"title": "II. EXPERIMENTAL DATA", "content": "By the assisstance of QuTiP [40], our generated QST dataset include (but not limited to) 10000 Husimi Q measurements of 32-qubit Coherent states, Fock states, Thermal states, Cat states, Num states [41], [42], Binomial states [41], [42] and GKP states [41], [43], [44] (number of samples uniformly distributed between states), along with the original density ma- trices, labels and generated values based on certain constraints. Using this diverse set of states in our dataset, we are able to extract many types of information and features.\nTypically, these states exist within a Hilbert space that has infinite dimensions. However, we can create a limited representation of these states with finite dimensions by setting a threshold on their energy levels, which is why in our experiments a Hilbert-space cutoff of N = 32 is used for all cases. To prevent artefacts resulting from truncation, the maximum photon number of the states is limited to 16 after the displacements are applied. Different types of quantum optical states used in the research are defined based on the original paper of QST-NN [38], including three well-known basic classes and four states from bosonic codes designed for quantum error correction."}, {"title": "A. Fock state", "content": "Eigenstates of the Fock basis:\n$|\u03c8_{fock}) = |N_{photon}) $ \n(1)"}, {"title": "B. Coherent state", "content": "Displaced vacuum states, characterized by the complex displacement amplitude a:\n$|coherent(a)) = |a) = D(a) |0),$\n$D(a) = exp(a \u00d7 a\u207a \u2013 a \u00d7 a)$ \n(2)\nD(a) is the displacement operator where a is the annihila- tion and (at) is the creation operator of the bosonic mode."}, {"title": "C. Thermal state", "content": "Mixed states where the photon number distribution follows super-Poissonian statistics:\n$P_{thermal}(n_{th}) = \\sum_{n=0}^{N_{c}-1} \\frac{1}{n_{th}+1} (\\frac{n_{th}}{n_{th} + 1})^{n}|(n)|(n)|$ \n(3)"}, {"title": "D. Cat state", "content": "Bosonic-code states consisting of superpositions of coherent states up to a normalization N with projections I given by:\n$|\u03c8_{cat}) = \\frac{1}{N} \\sum_{j=0}^{J_{k}=0,1}  \\Pi(S+1)\u00b5{\\alpha e^{i \\frac{2 \\pi j}{K}}}\n\\Pi, = \\sum_{m=0}^{\\infty} |2m(S + 1) + r) (2m(S + 1) + r|$\n(4)"}, {"title": "E. Num state", "content": "Specific set of bosonic-code states, consisting of superposi- tions of a few Fock states, numerically optimized for quantum error correction, and characterized by their average photon number n"}, {"title": "F. Binomial state", "content": "Bosonic-code states constructed from a superposition of Fock states weighted by the binomial coefficients:\n$|V_{binomial}) = \\frac{1}{\\sqrt{2^{N+1}}} \\sum_{m=0}^{N+1}  (-1)^{i(m} \\sqrt{\\binom{N+1}{m}}|(S+1)m) $ \n(5)"}, {"title": "G. GKP state", "content": "Finite Gottesmann-Kitaev-Preskill states, limits the lattice and adds a Gaussian envelope to make the state normalizable:\n$|\u03c8_{GKP}) = \\sum_{a \\in K(\u00b5)} e^{-\\delta^{2} a^{2}} e^{-iRe[a]Im[a]} |a),$\n$\u039a(\u03bc) = \\sqrt{(2n_{1} + \u03bc) + i\\sqrt{n_{2}}$\n(6)"}, {"title": "III. ARCHITECTURE AND TRAINING SETTINGS", "content": "We utilizes the PyTorch [45] framework to implement a deep convolutional neural network (CNN) similar to QST-NN. In our proposed architecture, we aim to extract relevant infor- mation from input measurements that are provided in the form of 32x32 density matrices. To accomplish this, we employ a series of 6 convolutional heads, which are interspersed with Gaussian noise, dropout, and leaky ReLU activation functions to extract meaningful features from the input.\nSubsequently, we feed the extracted features into both a classification tail and a regression tail. The classification tail is responsible for predicting the label, while the regression tail computes three features of the state. To generate the final state prediction, we sum the predicted label output with the extracted features and utilize the regression tail to predict the three essential features of the state.\nThese three features are then fed into a specialized Recon- structor module, which is designed explicitly to reconstruct the state by taking 3-length value vectors as input and generating the predicted states."}, {"title": "A. Restricted Feature Based Neural Network", "content": "We train our model using a linear combination of cross- entropy loss for the label and the sum of MAE loss for the real and imaginary parts of the regression output F as a feature vector:\n$loss = \\sum_{i=1}^{N}  \\frac{1}{N}log(label_{pred,N})+\\alpha ( \\frac{1}{N}\\sum_{i=1}^{N}|F_{real} - F_{real}^{out}| +\\frac{1}{N}\\sum_{i=1}^{N}|F_{imag} - F_{imag}^{out}|)$\n(7)\nIn general, the RFB-Net architecture is capable of not only reconstructing states from input measurements but also recon- structing the state from input measurements, which can be viewed as a form of multitasking architecture. In this architec- ture, the decoder produces both output labels and reconstructed operators. The ability to perform multiple tasks simultaneously is a key feature of multitasking architectures, which are increasingly being used in machine learning applications. By combining multiple tasks into a single architecture, multi- tasking models can improve efficiency and accuracy, while reducing the computational overhead associated with running separate models for each task. RFB-Net's ability to perform both state reconstruction and label prediction highlights its potential as a versatile and efficient multitasking architecture for quantum information applications. Furthermore, the ability to reconstruct the state from input measurements is particularly useful in quantum information processing, where it is essential to accurately recover the state of a quantum system from measurements. Overall, RFB-Net's multitasking capabilities make it a promising architecture for a wide range of quantum information tasks."}, {"title": "B. Mixed State Conditional Generative Adversarial Network", "content": "Building upon the seminal work of QST-CGAN, we have developed a novel neural architecture for state prediction, uti- lizing the powerful and versatile TensorFlow [46] framework. Our proposed model is designed to accommodate a batch of measurements in the form of 32x32 density matrices, as well as label vectors representing the target state. To facilitate efficient processing, we have implemented a series of pre-processing steps, which include flattening the measurements to a 1024- length vector and one-hot encoding the label to a 7-length vector.\nSubsequently, we feed the label vector through a dense layer, which enables us to encode it into a 1024-length vector that can be mapped to the same size as the measurements. By adding the resulting vector and the flattened measurements, we generate a final feature that captures the essence of the underlying quantum state. This final feature is then fed through a series of convolutional layers, batch normalization, and leaky ReLU activation, resulting in a batch of 2x32x32 tensor, where the two channels correspond to the real and imaginary components of the quantum state.\nFollowing the generation of the complex tensor batch, we proceed to further process the data by passing it through a DensityMatrix layer, which is responsible for normalizing the quantum state in accordance with specific constraints. Subse- quently, we pass the normalized state through an Expectation layer, which is designed to measure the state by calculating the expected values of various observables.\nUnlike the original architecture, which only utilizes the lower half of the result to obtain a Hermitian matrix, our novel approach simulate a Cholesky decomposition [22] to the upper half of the result, thereby optimizing the number of parameters utilized in the process. By subtracting the two obtained matrices and normalizing the result, we are able to generate a density operator that encompasses positive semi- definite, negative semi-definite, and even indefinite outcomes. This approach is particularly relevant in situations where the creation of an odd cat state is required, and can be achieved through the subtraction of two coherent states |\u03b1) and |-\u03b1):\n$V_{cat}) = \\frac{1}{\\sqrt{2(1-e^{-2/|a|^{2})}}} (|\u03b1) - |-\u03b1))$\n(8)\nModel's loss function is a linear combination of MAE loss of input measurement $M_{in}$ and the measurement from created density matrix $M_{pred}$ with the weighted sum (with a scalar \u03b1 = 100) of MAE loss for the real and imaginary parts ($D_{real}$ and $D_{imag}$) of the density operator:\n$loss = \\sum_{i=1}^{N}|M_{in} - M_{pred}|+\\alpha ( \\sum_{i=1}^{N}|D_{real} - D_{real}^{pred}|+\\sum_{i=1}^{N}|D_{imag} - D_{imag}^{pred}|)$\n(9)\nThe model is optimized for 100 epochs on dataset using Adam [47] with lr = 1e - 4 and \u03b2 = (0.9, 0.999). Our experimental results show that our proposed architecture has the potential to cover every quantum state that can be represented as a density operator, which is a Hermitian matrix with unit trace. This makes our architecture a more optimized solution for state prediction problems in various applications, as it can handle a wider range of quantum states."}, {"title": "C. Accuracy metrics", "content": "In both of our experiment, we will be using quantum fidelity to measure the similarity between two quantum states. Quantum fidelity is a key concept in quantum information theory and plays a critical role in many quantum informa- tion protocols, including quantum error correction, quantum teleportation, and quantum cryptography. Given two density matrices p and o, the fidelity is defined by :\n$F(\u03c1, \u03c3) = (tr(\\sqrt{\u03c1\u03c3}))^{2}$ \n(10)\nwhere if F(\u03c1, \u03c3) == 1, the two states are identical. If the fidelity is 0 < F(\u03c1,\u03c3) < 1, the two states differ, and the degree of difference is quantified by the fidelity value."}, {"title": "IV. RESULT", "content": "Within this section, we shall expound upon the findings of our investigation, in which we leveraged two distinct neural network architectures for quantum tomography. Our analysis of these models yielded remarkable outcomes, as both demonstrated adequate performance in reconstructing the states of quantum systems.\nThe experimentation of both models are conducted on a single NVIDIA GeForce RTX 3080 GPU."}, {"title": "A. Restricted Feature Based Neural Network", "content": "RFB-Net were initially trained for 100 epochs using Adam [47] optimizer with lr = 1e-4 and \u03b2 = (0.9, 0.999). Although the model have already converge majorly post training with this setting, we want to explore how long would it take for the model to completely converge close to state of the art result. After throughout examining, we see that it took at least around 1000 epochs for model to converge close to state of the art result.\nFigure 12 demonstrate that the model's degree of fidelity converges to a noteworthy value within the initial 100 epochs. However, to achieve an even higher degree of fidelity, it is necessary to engage in a protracted training process of over 1300 epochs, which can be considerably time-consuming. The probable cause behind this gradual convergence is due to the model's need for a more extensive fine-tuning process, which would enable it to make accurate predictions of vectors that contain small values, such as when predicting the mean photon number of a coherent state. This implies that the model's ability to make precise predictions is contingent on the length of the fine-tuning process, and a lengthier process would enable the model to offer better predictions.\nTo attain fidelity of the proposed architecture, the deploy- ment of the Reconstruction module is imperative to restore the state from the predicted values. Given the significant compu- tational expense incurred during the process of reconstruction, a judicious decision was made to evaluate the architecture's fidelity after every 100 epochs. This approach allows for a systematic assessment of the performance of the architecture, while minimizing the computational burden of reconstructing the state at every epoch."}, {"title": "B. Mixed State Conditional Generative Adversarial Network", "content": "The MS-CGAN architecture exhibits a distinct characteristic when compared to the RFB-Net architecture, in that it is capable of converging to desired values within a training period consisting of no more than 100 iterations, despite requiring an extra label input in comparison to the RFB-Net architecture. Notably, the MS-CGAN architecture is primarily focused on reconstruction, but this does not detract from its robustness, given its swift convergence when trained on relevant data. It is therefore reasonable to conclude that the MS-CGAN architecture is a viable alternative to the RFB-Net architecture, given its impressive performance characteristics in terms of convergence speed and accuracy, despite having distinct differences in terms of input requirements and model focus."}, {"title": "C. Compare with existing methods", "content": "In order to ensure a more robust and comprehensive com- parison between our proposed model and the original model, we have undertaken a meticulous and rigorous experimental procedure that involves the use of a QST-CGAN model trained on the same dataset for a prolonged period of 100 epochs, utilizing the original configuration parameters and settings as described in the seminal paper. This approach is intended to provide a more nuanced and detailed analysis of the comparative performance of the two models, by subjecting both models to identical experimental conditions, and enabling us to assess their relative strengths and weaknesses in a more systematic and rigorous manner.\nUpon conducting this extensive analysis, we have observed that the QST-CGAN model, while exhibiting notable strengths and advantages in certain areas, has encountered certain chal- lenges and limitations in the reconstruction of specific batches of states, resulting in an unstable and erratic convergence on the dataset. These limitations are reflected in the aver- age fidelity score, which is found to be hovering around a modest 0.19, indicating a suboptimal and unsatisfactory level of accuracy and precision. In contrast, our proposed solution has proven to be more superior and effective in overcoming these challenges, by demonstrating a higher degree of stability, robustness, and accuracy, as well as a more consistent and reliable performance."}, {"title": "D. Benchmarking with noise", "content": "The presence of noise, which refers to any unwanted fluctuations or disturbances in the experimental setup, is an inescapable factor that pervades most scientific investigations, and consequently poses significant challenges for accurate and reliable data analysis. Given this ubiquitous nature of noise, it is imperative that any method employed for state reconstruction is designed and optimized to be robust and resilient against various types of noise, to ensure that the final results are valid and trustworthy.\nMoreover, it is essential to recognize that noise can infiltrate the system at multiple stages, leading to a potentially complex and nuanced interplay of factors that can affect the experi- mental outcome. Specifically, noise can manifest itself during the preparation of the state to be reconstructed, where errors in the preparation procedure can introduce small deviations in the actual state of interest, resulting in a distorted or altered version of the target state. Additionally, the measurement pro- tocol itself can be a source of noise, as any calibration errors or other external influences may cause us to measure something other than what we intended to measure, leading to further inaccuracies in the final results. Finally, noise can arise during the data collection process itself, where amplification errors or photon shot noise can corrupt the signal, leading to further challenges in data interpretation and analysis. Therefore, a comprehensive and multifaceted approach is needed to account for the various sources of noise and ensure that any method for state reconstruction is adequately robust and resilient against these influences, to provide accurate and reliable results that can be used to advance scientific knowledge and understand- ing.\nIn this research, our approach involves the utilization of various noise generating techniques, akin to the employed dataset, taken from QST-NN. In particular, we have employed three types of noise in our experiment, which include additive mixed state noise, photon loss noise, and pepper noise. Rather than introducing the noise during the training phase, whereby the model would gradually learn and adapt to it, we have opted to evaluate the performance of two distinct architectures devoid of exposure to noisy data. This is to ascertain whether our models can generalize well under these conditions or not.\nUpon analyzing the sample input and prediction, it is evident that the RFB-Net exhibits a commendable performance in noisy environments in comparison to the MS-CGAN with regards to fidelity, albeit the reconstructed operator showcasing some dissimilarities from its original form. On the other hand, the MS-CGAN's performance is more stable, particularly when dealing with pepper noise added samples, and shows superior feature extraction capabilities compared to RFB-Net."}, {"title": "V. CONCLUSION", "content": "In summary, this research paper explored the application of neural networks in quantum tomography, and the findings suggest that they offer a promising approach to solving the challenges associated with reconstructing quantum states. The results demonstrate that neural network architectures, when trained on appropriate datasets, can produce accurate and efficient reconstructions of quantum states. Furthermore, the approach presented in this paper is scalable and can be extended to large-scale quantum systems. It is clear that the combination of neural networks and quantum tomography has great potential for advancing the field of quantum information processing, and we anticipate that this research will inspire further exploration and development of these methods in the future."}]}