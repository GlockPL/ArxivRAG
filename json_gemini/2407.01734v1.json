{"title": "Universal Quantum Tomography With Deep Neural Networks", "authors": ["Nhan T. Luu", "Truong Cong Thang"], "abstract": "Quantum state tomography is a crucial technique for characterizing the state of a quantum system, which is essential for many applications in quantum technologies. In recent years, there has been growing interest in leveraging neural networks to enhance the efficiency and accuracy of quantum state tomography. Still, many of them did not include mixed quantum state, since pure states are arguably less common in practical situations. In this research paper, we present two neural networks based approach for both pure and mixed quantum state tomography: Restricted Feature Based Neural Network and Mixed States Conditional Generative Adversarial Network, evaluate its effectiveness in comparison to existing neural based methods. We demonstrate that our proposed methods can achieve state-of-the-art results in reconstructing mixed quantum states from experimental data. Our work highlights the potential of neural networks in revolutionizing quantum state tomography and facilitating the development of quantum technologies.", "sections": [{"title": "I. INTRODUCTION", "content": "A promising avenue for both research and technological advancements has been presented thanks to progress in con- trolling capacity and manipulation of small quantum systems. These systems offer potential applications in various fields such as quantum information processing and computation [1]\u2013 [3], quantum chemistry simulations [4]\u2013[6], secure communi- cation [7], [8], among with others notable works [4], [9], [10]. In recent breakthroughs, the successful demonstration of a 53- qubit quantum computer accomplishing a computational task in a fraction of the time expected on a classical supercomputer [11] underscore the remarkable speedup achievable through quantum systems. This acceleration is attributable in part to the exponentially vast state space available for storing and manipu- lating information in quantum systems [12]\u2013[14]. Nonetheless, while the expansive state space offers opportunities, it also presents challenges in accurately characterizing and describing these systems.\nQuantum State Tomography (QST) [15]\u2013[17] aims to ascer- tain the unknown quantum state by conducting measurements on a finite set of identical copies of the system. If the state is characterized by the density matrix o, residing in ad- dimensional Hilbert space, approximately O(d/e) copies are necessary to achieve an estimate of @ with an error (measured as total variation distance) less than \u025b [18]. This underscores the considerable resource demands of QST for large-scale systems.\nIn a broader context, QST can be viewed as an inverse problem [19], [20]. Consequently, linear inversion [21] is often considered the most straightforward approach. However, it has drawbacks, such as the potential to yield a non-physical state and the inability to analytically determine the mean squared error bound of the estimate. To address these limitations, sev- eral alternative QST methods have been developed, including maximum-likelihood estimation (MLE) [22], [23], Bayesian tomography [24], [25], compressed sensing techniques [26], [27], and matrix-product states [28], [29], where MLE remains the most commonly employed approach.\nIn recent times, machine learning techniques have been employed in QST, showing promising outcomes [30]\u2013[32]. Specifically, generative models [33]\u2013[35], often in the form of restricted Boltzmann machines (RBMs), have emerged as effective Ans\u00e4tze with minimal parameters to depict a quantum state and understand the probability distribution of anticipated outputs [30], [36], [37]. Additionally, deep neural networks have been utilized in QST, enabling physicists to harness the swift advancements in machine learning methodologies.\nIn our research, we introduce QST with 2 type of neural networks (NNs) architecture: Restricted Feature Based Neural Network (RFB-Net) and Mixed States Conditional Generative Adversarial Network (MS-CGAN). RFB-Net is a modified QST-NN [38] with modified regression modules that can classify quantum states into specific specific class and pointing out its features of the quantum state within certain constraints, finally using these features and classes to infer the full state of the system. On the other hand, MS-CGAN is an architecture derived from QST conditional-GAN (QST-CGAN) [39], which contain certain modifications from the original work to extend its reconstruction range to include mixed states. This network is improved for a better estimation of the density matrix of the system while extend reconstruction range to multiple type of quantum states. Both of these techniques can accurately construct many types of given simulated measurement and shown great promise in practical intermediate-scale quantum"}, {"title": "II. EXPERIMENTAL DATA", "content": "By the assisstance of QuTiP [40], our generated QST dataset include (but not limited to) 10000 Husimi Q measurements of 32-qubit Coherent states, Fock states, Thermal states, Cat states, Num states [41], [42], Binomial states [41], [42] and GKP states [41], [43], [44] (number of samples uniformly distributed between states), along with the original density ma- trices, labels and generated values based on certain constraints. Using this diverse set of states in our dataset, we are able to extract many types of information and features.\nTypically, these states exist within a Hilbert space that has infinite dimensions. However, we can create a limited representation of these states with finite dimensions by setting a threshold on their energy levels, which is why in our experiments a Hilbert-space cutoff of N = 32 is used for all cases. To prevent artefacts resulting from truncation, the maximum photon number of the states is limited to 16 after the displacements are applied. Different types of quantum optical states used in the research are defined based on the original paper of QST-NN [38], including three well-known basic classes and four states from bosonic codes designed for quantum error correction.\nEigenstates of the Fock basis:\n$\\left|\\psi_{\\text {fock }}\\right\\rangle=\\left|N_{\\text {photon }}\\right\\rangle$\nDisplaced vacuum states, characterized by the complex displacement amplitude a:\n$\\left|\\text { coherent }(a)\\right\\rangle=|a\\rangle=D(a)|0\\rangle$,\n$D(a)=\\exp \\left(a \\times a^{+}-a \\times a\\right)$\n$D(a)$ is the displacement operator where $a$ is the annihila- tion and $(a+)$ is the creation operator of the bosonic mode.\nMixed states where the photon number distribution follows super-Poissonian statistics:\n$P_{\\text {thermal }}\\left(n_{\\text {th }}\\right)=\\frac{1}{n_{\\text {th }}+1}\\left(\\frac{n_{\\text {th }}}{n_{\\text {th }}+1}\\right)^{n}$"}, {"title": "III. ARCHITECTURE AND TRAINING SETTINGS", "content": "We utilizes the PyTorch [45] framework to implement a deep convolutional neural network (CNN) similar to QST-NN. In our proposed architecture, we aim to extract relevant infor- mation from input measurements that are provided in the form of 32x32 density matrices. To accomplish this, we employ a series of 6 convolutional heads, which are interspersed with Gaussian noise, dropout, and leaky ReLU activation functions to extract meaningful features from the input.\nSubsequently, we feed the extracted features into both a classification tail and a regression tail. The classification tail is responsible for predicting the label, while the regression tail computes three features of the state. To generate the final state prediction, we sum the predicted label output with the extracted features and utilize the regression tail to predict the three essential features of the state.\nThese three features are then fed into a specialized Recon- structor module, which is designed explicitly to reconstruct the state by taking 3-length value vectors as input and generating the predicted states.\nWe train our model using a linear combination of cross- entropy loss for the label and the sum of MAE loss for the real and imaginary parts of the regression output F as a feature vector:\n$\\operatorname{loss}=\\sum_{i=1}^{N}\\left(-\\sum_{N=1}^{7} \\operatorname{label}_{\\text {real, } N} \\log \\left(\\operatorname{label}_{\\text {pred }, N}\\right)+\\ \u03b1 \\frac{1}{N} \\sum_{i=1}^{N}\\left|F_{\\text {reat }}-F_{\\text {real }}^{\\text {out }}\\right|+\\frac{1}{N} \\sum_{i=1}^{N}\\left|F_{\\text {imag }}-F_{\\text {imag }}^{\\text {out }}\\right|\\right)$"}, {"title": "B. Mixed State Conditional Generative Adversarial Network", "content": "Building upon the seminal work of QST-CGAN, we have developed a novel neural architecture for state prediction, uti- lizing the powerful and versatile TensorFlow [46] framework. Our proposed model is designed to accommodate a batch of measurements in the form of 32x32 density matrices, as well as label vectors representing the target state. To facilitate efficient processing, we have implemented a series of pre-processing steps, which include flattening the measurements to a 1024- length vector and one-hot encoding the label to a 7-length vector.\nSubsequently, we feed the label vector through a dense layer, which enables us to encode it into a 1024-length vector that can be mapped to the same size as the measurements. By adding the resulting vector and the flattened measurements, we generate a final feature that captures the essence of the underlying quantum state. This final feature is then fed through a series of convolutional layers, batch normalization, and leaky ReLU activation, resulting in a batch of 2x32x32 tensor, where the two channels correspond to the real and imaginary components of the quantum state.\nFollowing the generation of the complex tensor batch, we proceed to further process the data by passing it through a DensityMatrix layer, which is responsible for normalizing the quantum state in accordance with specific constraints. Subse- quently, we pass the normalized state through an Expectation layer, which is designed to measure the state by calculating the expected values of various observables.\nUnlike the original architecture, which only utilizes the lower half of the result to obtain a Hermitian matrix, our novel approach simulate a Cholesky decomposition [22] to the upper half of the result, thereby optimizing the number of parameters utilized in the process. By subtracting the two obtained matrices and normalizing the result, we are able to generate a density operator that encompasses positive semi- definite, negative semi-definite, and even indefinite outcomes. This approach is particularly relevant in situations where the creation of an odd cat state is required, and can be achieved through the subtraction of two coherent states a) and |-\u03b1):\n$\\left|\\Psi_{\\text {at }}\\right\\rangle=\\frac{1}{\\sqrt{2\\left(1-e^{-2 / a^{2}}\\right)}}(|\u03b1\\rangle-|-\u03b1\\rangle)$\nModel's loss function is a linear combination of MAE loss of input measurement $\\mathbb{M}_{i n}$ and the measurement from created density matrix $\\mathbb{M}_{\\text {pred }}$ with the weighted sum (with a scalar"}, {"title": "IV. RESULT", "content": "Within this section, we shall expound upon the findings of our investigation, in which we leveraged two distinct neural network architectures for quantum tomography. Our analysis of these models yielded remarkable outcomes, as both demonstrated adequate performance in reconstructing the states of quantum systems.\nThe experimentation of both models are conducted on a single NVIDIA GeForce RTX 3080 GPU.\nRFB-Net were initially trained for 100 epochs using Adam [47] optimizer with lr = 1e-4 and \u03b2 = (0.9, 0.999). Although the model have already converge majorly post training with this setting, we want to explore how long would it take for the model to completely converge close to state of the art result. After throughout examining, we see that it took at least around 1000 epochs for model to converge close to state of the art result.\nFigure 12 demonstrate that the model's degree of fidelity converges to a noteworthy value within the initial 100 epochs. However, to achieve an even higher degree of fidelity, it is necessary to engage in a protracted training process of over 1300 epochs, which can be considerably time-consuming. The probable cause behind this gradual convergence is due to the model's need for a more extensive fine-tuning process, which would enable it to make accurate predictions of vectors that contain small values, such as when predicting the mean photon number of a coherent state. This implies that the model's ability to make precise predictions is contingent on the length of the fine-tuning process, and a lengthier process would enable the model to offer better predictions.\nTo attain fidelity of the proposed architecture, the deploy- ment of the Reconstruction module is imperative to restore the state from the predicted values. Given the significant compu- tational expense incurred during the process of reconstruction, a judicious decision was made to evaluate the architecture's fidelity after every 100 epochs. This approach allows for a systematic assessment of the performance of the architecture, while minimizing the computational burden of reconstructing the state at every epoch.\nThe MS-CGAN architecture exhibits a distinct characteristic when compared to the RFB-Net architecture, in that it is capable of converging to desired values within a training period consisting of no more than 100 iterations (Figure 13 and 14), despite requiring an extra label input in comparison to the RFB-Net architecture. Notably, the MS-CGAN architecture is primarily focused on reconstruction, but this does not detract from its robustness, given its swift convergence when trained on relevant data. It is therefore reasonable to conclude that the MS-CGAN architecture is a viable alternative to the RFB-Net architecture, given its impressive performance characteristics in terms of convergence speed and accuracy, despite having distinct differences in terms of input requirements and model focus."}, {"title": "V. CONCLUSION", "content": "In summary, this research paper explored the application of neural networks in quantum tomography, and the findings suggest that they offer a promising approach to solving the challenges associated with reconstructing quantum states. The results demonstrate that neural network architectures, when trained on appropriate datasets, can produce accurate and efficient reconstructions of quantum states. Furthermore, the approach presented in this paper is scalable and can be extended to large-scale quantum systems. It is clear that the combination of neural networks and quantum tomography has great potential for advancing the field of quantum information processing, and we anticipate that this research will inspire further exploration and development of these methods in the future."}]}