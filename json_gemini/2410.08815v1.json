{"title": "STRUCTRAG: BOOSTING KNOWLEDGE INTENSIVE REASONING OF LLMS VIA INFERENCE-TIME HYBRID INFORMATION STRUCTURIZATION", "authors": ["Zhuoqun Li", "Xuanang Chen", "Haiyang Yu", "Hongyu Lin", "Yaojie Lu", "Qiaoyu Tang", "Fei Huang", "Xianpei Han", "Le Sun", "Yongbin Li"], "abstract": "Retrieval-augmented generation (RAG) is a key means to effectively enhance large language models (LLMs) in many knowledge-based tasks. However, existing RAG methods struggle with knowledge-intensive reasoning tasks, because useful information required to these tasks are badly scattered. This characteristic makes it difficult for existing RAG methods to accurately identify key information and perform global reasoning with such noisy augmentation. In this paper, motivated by the cognitive theories that humans convert raw information into various structured knowledge when tackling knowledge-intensive reasoning, we proposes a new framework, StructRAG, which can identify the optimal structure type for the task at hand, reconstruct original documents into this structured format, and infer answers based on the resulting structure. Extensive experiments across various knowledge-intensive tasks show that StructRAG achieves state-of-the-art performance, particularly excelling in challenging scenarios, demonstrating its potential as an effective solution for enhancing LLMs in complex real-world applications.", "sections": [{"title": "1 INTRODUCTION", "content": "With the advancement of deep learning technology, large language models (LLMs) have demonstrated considerable strengths in natural language tasks and are extensively applied in complex real-world scenarios (OpenAI et al., 2024; Yang et al., 2024a). However, they still exhibit limitations in factual tasks due to a lack of domain-specific knowledge, real-time updated information, and proprietary knowledge (Huang et al., 2023; Sui et al., 2024). To address this, retrieval-augmented generation (RAG) methods have been developed to effectively provide essential external knowledge (Yu et al., 2022; Gao et al., 2024). Typically, RAG methods involve splitting original documents into shorter chunks, retrieving the most relevant ones based on the query, and then using these chunks to enable LLMs to generate reliable answers (Ma et al., 2023; Li et al., 2024a). Due to their strong performance through this straightforward process, RAG methods are commonly employed in various knowledge-based question-answering tasks (Shi et al., 2024; Wang et al., 2024b).\nUnfortunately, current RAG approaches cannot effectively handle knowledge-intensive reasoning tasks due to the scattered nature of related information needed to solve these tasks (Kuratov et al., 2024; Yang et al., 2024b). Specifically, knowledge-intensive reasoning tasks often require a large amount of useful information which is dispersed across many locations in the provided documents, meanwhile the model needs to perform integrated reasoning after retrieving useful information (Yang et al., 2024b; Wang et al., 2024a). Taking financial report analysis as an example, given a large number of financial documents and the need to compare the development trends of multiple companies, LLMs need to dig out all relevant financial indicators scattered across original documents and then generate insights by carefully comparing and comprehensively analyzing these indicators. In such scenarios, standard RAG methods face challenges in accurately retrieving all"}, {"title": "2 RELATED WORK", "content": null}, {"title": "2.1 RETRIEVAL-AUGMENTED GENERATION", "content": "RAG technology achieves good performance in the era of LLMs by providing external knowledge to assist answering questions and reducing hallucinations (Jiang et al., 2023; Asai et al., 2023; Gao et al., 2024; Chen et al., 2024). The initial strategy of RAG involves using a retriever to search for and retain highly relevant chunks from a knowledge base based on a query, these chunks are then fed into the generation module as external knowledge, enhancing its performance (Qi et al., 2019; Lewis et al., 2020; Gur et al., 2021; Yu et al., 2022). To improve RAG effectiveness, some approaches have introduced iterative RAG, proposing various enhancements such as query expansion and rewriting (Ma et al., 2023; Li et al., 2024a; Chan et al., 2024; Shi et al., 2024), and others try to improve the corporation between retrieval and generation (Qian et al., 2024; Su et al., 2024; Luo et al., 2024; Zhang et al., 2024). Although existing methods achieve strong performance on multi-hop tasks like HotpotQA, chunk-based RAG struggles with knowledge-intensive tasks (Wang et al., 2024a). This is because chunks must contain excessive text noise and do not capture the interconnections among information, thus LLMs cannot effectively use augmented knowledge."}, {"title": "2.2 GRAPH RETRIEVAL-AUGMENTED GENERATION", "content": "Recently, to assist LLMs in handling complex question-answering tasks, some works introduce graph structures into RAG systems (Edge et al., 2024; Panda et al., 2024; Peng et al., 2024). One kind of approach uses pre-built knowledge graphs, extracting subgraph based on queries, which are then encoded as soft prompts or flattened into plain text for the generation module (Tang et al., 2024; He et al., 2024; Guan et al., 2024). Another kind of approach involves extracting entity-relation triples from given text documents based on query requirements to construct graph structures, which are then used for knowledge augmentation (Fang et al., 2024; Edge et al., 2024; Panda et al., 2024). Although these approaches significantly improve performance on multi-hop question-answering tasks, they focus solely on graph-based knowledge via the format of triplets, thus limiting their practical applicability in various domain and application of knowledge-intensive reasoning tasks."}, {"title": "3 STRUCTRAG VIA HYBRID INFORMATION STRUCTURIZATION", "content": "As mentioned, due to badly dispersed information in knowledge-intensive reasoning tasks, the traditional retrieval module in RAG could retrieve chunks containing substantial textual noise, making it difficult for the generation module to extract useful information for inference. Drawing inspiration from cognitive theories on how humans tackle such tasks, this paper proposes StructRAG, which utilizes a hybrid information structurization mechanism to construct and leverage structured knowledge in its optimal form. Specifically, as illustrated in Figure 1, StructRAG first employs a hybrid structure router to identify the most appropriate structure type for the given task, and then employs a scattered knowledge structurizer to transform raw documents into structured knowledge in that format, and finally incorporates a structured knowledge utilizer to break down complex questions into simpler sub-questions, enabling more accurate reasoning on structured knowledge.\nTask Formulating. Knowledge-intensive reasoning tasks involved in this paper provide a question q and a large set of documents D as input, with the goal of deriving an answer a based on the provided documents, which can be expressed as follows:\n$a = F(q, D), where D = {d^{(i)}}_{i=1}^{m}$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              (1)\nwhere m is the number of documents, which can exceed 20, resulting in a total token of up to 200K. Thus, the most obvious characteristic of these tasks is that useful information is dispersed across the"}, {"title": "Hybrid Structure Router", "content": "From a human perspective, when solving knowledge-intensive reasoning tasks, individuals tend to use the type of structured knowledge that best matches the specific requirements of faced task. To this end, StructRAG incorporates a hybrid structure router R to select the optimal structure type. Specifically, the router leverages the question q and the core content C of documents D to make its decision and generate the most suitable structure type t, as it is impractical to process the entire set of documents at once.\n$t = R(q, C'), where C = {c^{(i)}}_{i=1}^{m}$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      (2)\nThe core content C is the concentrate of the titles or the first few sentences from each document d^{(i)}. In our work, there are five candidate structure types for five kinds of knowledge-intensive tasks: table for statistical tasks, graph for long-chain tasks, algorithm for planning tasks, catalogue for summarizing tasks, and chunk for simple single-hop tasks. Considering the core effect of the router in the overall framework, our work designs a DPO-based training method to develop a router that excels in knowledge type decision, which is detailed in Section 4."}, {"title": "Scattered Knowledge Structurizer", "content": "After identifying the most suitable structure type, StructRAG extracts the textual knowledge scattered across raw documents and reconstructs it into structured knowledge. This process requires a comprehensive understanding of all raw documents and and precise formatting of the information, making it a challenging and flexible problem. Therefore, StructRAG employs an LLM-based scattered knowledge structurizer to facilitate the structurization process. Specifically, as shown in Eq. 3 the structurizer S takes the question q, the selected type t, and each raw document d^{(i)} as input, and extract the structured knowledge $k_t^{(i)}$ from the document via the powerful understanding and generation ability of LLMs. In addition, a description of the structured knowledge $b_t$ is also generated.\n$k_t^{(i)}, b_t^{(i)} = S(q, t, d^{(i)})$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          (3)\nAfter that, all output structured knowledge will be collected as the overall one $K_t = {k_t^{(i)}}_{i=1}^{m}$, and the overall description of the whole structured knowledge is constructed as $B_t = {b_t^{(i)}}_{i=1}^{m}$. In term of detailed representation of each kind of structure, the table is by markdown, graph by in list of head-relationship-tail triplets, chunk is by regular text, algorithm is by pseudo code, and catalogue is by text with hierarchical number (e.g., Section One, 1.1, 1.1.2) as explicitly chapter identifier."}, {"title": "Structured Knowledge Utilizer", "content": "After obtaining the structured knowledge in its optimal type, StructRAG performs reasoning to answer the question. Given that the question can be highly combinatorial, this may hinder the identification and use of relevant information in the structured knowledge. Therefore, StructRAG employs an LLM-based structured knowledge utilizer to facilitate question decomposition, precise knowledge extraction, and final answer inference. Specifically, the decomposition process of the utilizer takes the original question q and the overall description of structured knowledge $B_t$ as input, breaking the question down into several simple and intuitive sub-questions $\\hat{q}^{(i)}$. Next, the extraction process aims to find out precise knowledge $\\hat{k}^{(i)}$ for each sub-question $\\hat{q}^{(i)}$ from the whole structured knowledge $K_t$. Finally, the inference process integrates all the sub-questions and their extracted precise knowledge to generate a final answer a, which can be expressed as follows:\n$Q = U_{decompose}(q, B_t) = {\\hat{q}^{(i)}}_{i=1}^{n}$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (4)\n$K_t = {U_{extract}(\\hat{q}^{(i)}, K_t)}_{i=1}^{n} = {\\hat{k}^{(i)}}_{i=1}^{n}$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        (5)\n$a = U_{infer}(q, Q, K_t)$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      (6)\nwhere n is number of sub-questions, Q is set of all sub-questions, $K_t$ is whole precise knowledge for all sub-questions, and $U_{decompose}$, $U_{extract}$ and $U_{infer}$ are process of decomposition, extraction and inference, respectively. More details about the utilizer are shown in Appendix A.3."}, {"title": "4 HYBRID STRUCTURE ROUTER TRAINING", "content": "In the StructRAG framework described above, the core factor is accurately determining the most suitable structure type based on the input task, and the performance of the hybrid structure router directly influences the overall effectiveness of the framework. Therefore, to achieve a high-performance router, we propose a training method to enhance the ability of LLMs in identifying the suitable structure type of knowledge. Specifically, given the strong capabilities of reinforcement learning in decision-making scenarios, we train the router using the DPO algorithm, which achieves results similar to reinforcement learning while avoiding the need for additional reward models. Regarding training data, since there is no existing preference data for the optimal structure type selection task, we design a synthesizing-simulating-judging method to efficiently construct preference pairs for training. A detailed explanation is provided in the following paragraphs, along with examples and prompts in the Appendix A.1."}, {"title": "Data Constructing", "content": "Due to the scarcity of training data for selecting the optimal structure type in the current NLP community, we employ a synthesizing-simulating-judging method to construct preference pairs for training the router. Specifically, as illustrated in Figure 2, given several manually collected seed tasks that covering the possible structure types, we first use LLMs to synthesize a set of new tasks by the in-context learning method, where each task contains a question and core context for documents. Then, for each synthetic task, LLMs is employed to simulate the process of addressing this task by structured knowledge in different types, thus getting different simulated solutions. Finally, a LLM-based judge compares these simulated solutions for solving the task, generating preference pairs regarding the structure types. Each constructed data entry includes a question, the core contents of documents, the chosen structure type, and the rejected structure type, as expressed as follows:\n$D_{synthetic} = {\\{q^{(k)}, C^{(k)}, t_w^{(k)}, t_l^{(k)}\\}}_{k=1}^{N}$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        (7)\nwhere $t_w$ and $t_l$ are chosen structure type and rejected structure type, respectively. In addition, synthetic preference pairs include both English and Chinese data in order to improve the universality."}, {"title": "Preference Training", "content": "Inspired by the success of using reinforcement learning to train LLMs for decision-making tasks, we employ the DPO algorithm to train the router module, which can get the same effectiveness as reinforcement learning without adding additional reward models. Specifically, the input for training the router includes a question and the core contents of documents, and the output is one kind of structure type (e.g., \"table\", \"graph\"). As described in last paragraph, we simulate and construct a set of preference pairs for DPO training, which can be formulated as following:\n$L_{DPO}(\\pi_{\\theta}; \\pi_{ref}) = -E_{(q, C, t_w, t_l) \\sim D_{synthetic}}[log\\sigma(\\beta log \\frac{\\pi_{\\theta}(t_w | q, C)}{\\pi_{\\theta}(t_l | q, C)} - log \\frac{\\pi_{ref}(t_w | q, C)}{\\pi_{ref}(t_l | q, C)})]$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (8)\nwhere $\\pi_{\\theta}$ and $\\pi_{ref}$ are target policy and reference policy, respectively, and $\\beta$ is a hyperparameter. As analyzed later, this preference training enables the model to differentiate between various types of knowledge and their suitability for a given task, resulting in better performance compared to zero-shot and few-shot settings."}, {"title": "5 EXPERIMENTS", "content": null}, {"title": "5.1 EXPERIMENTAL SETTINGS", "content": "Evaluation Datasets. This paper includes various knowledge-intensive reasoning tasks in evaluation. First, this paper chooses the Loong benchmark (Wang et al., 2024a), which includes four tasks (Spotlight Locating, Comparison, Clustering, and Chain of Reasoning) and four document length settings, as the length of the document increases, the useful information needed to solve the task becomes more dispersed. As for metrics, this paper adheres to original settings in Loong and use the official code repository\u00b9 in evaluation, involving using LLMs to decide a score from 0 to 100 and the exact matching (EM) rate. In addition, this paper chooses Podcast Transcripts, which is a query-focused summarization task reported by GraphRAG (Edge et al., 2024). As for metrics, this paper follows GraphRAG settings, involving head-to-head win rate by a LLM judgement, across four kinds of dimension, which are comprehensiveness, diversity, empowerment, and directness.\nImplementation Details. We build framework based on Qwen2 series models (Yang et al., 2024a). For the hybrid structure router, StructRAG uses Qwen2-7B-Instruct as the base model and implement DPO training by trl2. As for the details of hybrid structure router training, StructRAG constructs and uses a total of 900 preference data, setting the learning rate as 1e-5, number of epochs as 3 and the \u03b2 as default in training. For the scattered knowledge structurizer and strutured knowledge utilizer, StructRAG directly uses Qwen2-72B-Instruct as base model and deploy models as API using vllm\u00b3 following the same setting as in Loong (Wang et al., 2024a).\nSelected Baselines. We select baselines from commonly used or recent methods for knowledge-based question-answering tasks. Specifically, (1) Long-Context (Yang et al., 2024a), which extends the input window of LLMs to up to 128K tokens through extrapolation techniques, allowing large-scale documents to be directly input into the model. (2) RAG (Lewis et al., 2020), which splits the given documents into multiple short chunks and uses a retriever to retain only the most relevant chunks as augmentation based on the question. (3) RQ-RAG (Chan et al., 2024), which uses a trained LLM to decompose and refine the original question to more accurately find the required chunk augmentation. (4) GraphRAG (Edge et al., 2024), which extracts triples (head, relationship, tail) from raw documents and constructs into multi-layered graphs, then uses structured information in graphs to help the generation model answer questions. In implement, for Long-Context and RAG, we directly follow the experimental settings reported in Loong (Wang et al., 2024a), and for RQRAG\u2074 and GraphRAG5, we evaluate the performance based on the official code repositories. Noting that, for fair comparison, we also set Qwen-72B-Instruct as base model of GraphRAG."}, {"title": "5.2 OVERALL RESULTS", "content": "Results compared with baselines are shown in Table 1 and Table 2, there are two main conclusions:\n1) StructRAG is a powerful solution to addressing knowledge-intensive reasoning tasks. Based on the experimental results in Table 1, StructRAG outperforms the baselines in most tasks and document length settings, and in the overall metric, StructRAG exceeds all baselines in both LLM score and EM rate. In addition, as shown in Table 2, StructRAG achieves the best average performance compared to all baselines in Podcast Transcripts. All in all, these experimental findings demonstrate that StructRAG can effectively address knowledge-intensive reasoning tasks and improve a lot compared with previous long-context methods, and different kind of existing powerful RAG techniques.\n2) StructRAG is particularly suitable for complex tasks, performance improvement becomes more significant in scenarios with more dispersed information. Based on the overall performance in Table 1, the performance comparison between StructRAG and the long-context baseline shows that StructRAG achieves performance improvements of approximately 9, 15, 22, and 23 on Set 1, Set 2, Set 3, and Set 4, respectively. Similarly, comparing StructRAG with RAG shows performance"}, {"title": "5.3 ABLATION RESULTS OF MODULES", "content": "To validate the role of each module in StructRAG, we perform ablation experiments. As shown in Table 3, \"w/o router\" refers to random routing, \"w/o structurizer\u201d means using only chunks, and \"w/o utilizer\" refers to directly concatenating the structured knowledge with the original question for answer generation. There are following conclusions:\n1) All three modules contribute positively to the overall framework. The table shows that removing any of the three modules results in a noticeable performance decline. The overall performance will reduce from 60.38 to 45.33, 53.92 and 55.94 for the router, structurizer, and utilizer, respectively. This proves that all three modules play an irreplaceable role, and StructRAG tightly and orderly combines these three modules to achieve excellent overall performance.\n2) Choosing the suitable structure type and constructing documents into structured knowledge are more crucial than designing complex utilization methods. A comparison in the table reveals that different modules are with different importance. The performance drop is most significant when"}, {"title": "5.4 DETAILED ANALYSIS", "content": "In this section, we do some detailed analysis, including, performance and impact of the router, drawback of using fixed structure type, case study about EM rate performance, and efficiency reports."}, {"title": "5.4.1 EFFECT OF THE ROUTER", "content": "To explore the necessity of constructing data and conducting DPO training, and relationship between performance of hybrid structure router and overall StructRAG, we first compare our router with raw LLMs, and then draw curl of router and overall StructRAG score. There are following conclusions:\n1) Selecting the optimal type of knowledge based on the task is challenging for raw LLMs without special training. Based on the experimental results in Table 4, the router trained based on Qwen2-7B-Instruct model significantly outperforms the 72B model with few-shot setting. This indicates that LLMs need some special training to get the ability of selecting the optimal structure type based on needs of the task, even when the model scale reaches 72B.\n2) The performance of hybrid structure router is with significant relevance with the final performance of StructRAG. As shown in Figure 3, we select Qwen2-72B-Instruct (zero-shot) as the weak router, and design a completely random router and a completely incorrect bad router. The curves in the figure clearly show a positive correlation between router accuracy and the overall performance of the StructRAG framework. This further demonstrates that selecting knowledge types that match the task needs for augmentation is crucial in knowledge-intensice reasoning tasks."}, {"title": "5.4.2 DRAWBACK OF A FIXED TYPE OF KNOWLEDGE", "content": "To further verify the importance of containing hybrid types of structure rather than a fixed type, we freeze the structure type used in the framework as either chunk, graph, table, algorithm or catalogue for all evaluation tasks. There are the following conclusions:\nUsing a single fixed type of knowledge cannot achieve good performance on diverse tasks. Based on the experimental results in Table 5, it shows that for both scores and exact matching rate, using a single fixed type performs worse than selecting the optimal structure type for needs of the"}, {"title": "5.4.3 CASE STUDY ABOUT EM METRIC", "content": "According to the experimental results in Table 1, StructRAG surpasses baselines in general score, but falls short in seven sub-situations for the exact matching rate. Therefore, we analysis some cases that StructRAG method gets high score but fails exact matching. The reason is mainly about structurization process may alter the textual format of original information. As shown in Table 5, there are some wording differences between structured knowledge and raw information (e.g. from original \u201c$ 1,308,463\u201d to \u201c138463\u201d in the table). Intuitively this aligns with the common sense, where structurizer is a probabilistic language model rather than rule-based model, thus some possible textual loss may be unavoidable, and output from GraphRAG method also show similar issue."}, {"title": "5.4.4 EFFICIENCY REPORT", "content": "In this section, we report average latency of StructRAG and compare it with the RQ-RAG (Chan et al., 2024) and GraphRAG (Edge et al., 2024). The latency includes two components: The first part is constructing latency, referring to the process of iteratively retrieving chunks for RQ-RAG, constructing graphs for GraphRAG, and determining the optimal knowledge type and constructing corresponding structure for StructRAG. The second part is reading latency, referring to the process of using augmented knowledge to generate final answers. As shown in Table 4, StructRAG has slightly higher latency compared to RQ-RAG but is obviously faster than GraphRAG. Therefore, StructRAG is a kind of high-performance framework with available implementing speed."}, {"title": "6 CONCLUSION", "content": "In this paper, noticed the limitation of existing RAG methods in knowledge-intensive reasoning tasks, and inspired by cognitive theories about how human beings solve such tasks, we propose a new framework, StructRAG via hybrid information structurization, which can construct and utilize structured knowledge in the optimal format as augmentation. StructRAG includes a hybrid structure router to precisely select the optimal structure type, then a scattered knowledge structurizer to convert raw documents into structured knowledge, and finally a structured knowledge utilizer to decompose complex questions and infer the final answer via the constructed structured knowledge. Furthermore, in order to get a high-performance hybrid structure router, we construct training data by"}]}