{"title": "Mind the Gap: Promoting Missing Modality Brain Tumor Segmentation with Alignment", "authors": ["Tianyi Liu", "Zhaorui Tan", "Haochuan Jiang", "Xi Yang", "Kaizhu Huang"], "abstract": "Brain tumor segmentation is often based on multiple magnetic resonance imaging (MRI). However, in clinical practice, certain modalities of MRI may be missing, which presents an even more difficult scenario. To cope with this challenge, knowledge distillation has emerged as one promising strategy. However, recent efforts typically overlook the modality gaps and thus fail to learn invariant feature representations across different modalities. Such drawback consequently leads to limited performance for both teachers and students. To ameliorate these problems, in this paper, we propose a novel paradigm that aligns latent features of involved modalities to a well-defined distribution anchor. As a major contribution, we prove that our novel training paradigm ensures a tight evidence lower bound, thus theoretically certifying its effectiveness. Extensive experiments on different backbones validate that the proposed paradigm can enable invariant feature representations and produce a teacher with narrowed modality gaps. This further offers superior guidance for missing modality students, achieving an average improvement of 1.75 on dice score.", "sections": [{"title": "I. INTRODUCTION", "content": "Malignant brain tumors severely threaten people's lives. Accurate brain tumor segmentation is crucial for treatment planning [1]. Multiple Magnetic Resonance Imaging (MRI), such as Fluid Attenuation Inversion Recovery (Flair), contrast-enhanced T1-weighted (T1ce), T1-weighted (T1) and T2-weighted (T2), are common tools to segment brain tumors [2]. Since different modalities complement each other in understanding physical structure and physiopathology, combining them may naturally improve tumor segmentation [3]\u2013[6].\nHowever, due to difficulties such as data corruption and scanning protocol variations, in real clinical practice, certain modalities may often be missing [7]\u2013[10]. Therefore, designing a generalized multi-modal approach to overcome difficulties brought by missing modalities is critical for practical clinical applications.\nTo address this challenge, knowledge distillation (KD) has emerged as one promising solution. Recent efforts in KD [1], [11]\u2013[13] initially train a teacher with complete modalities that will then be used to supervise students to access missing modalities. To distill knowledge from teachers, KD-Net [12] employs the Kullback-Leibler (KL) loss to minimize the latent space divergence between teachers and students; PMKL [1] is later designed to enhance KD-Net by incorporating contrastive loss. Besides, ProtoKD [13] engages a prototype knowledge distillation loss to encourage simultaneous intra-class concentration and inter-class divergence. Moreover, Style matching U-Net addresses this problem by disentangling content and style components in the latent space [11].\nWhile the above-mentioned wisdom enhances the segmentation capabilities of students, their effectiveness is limited by their teachers which remain sub-optimal and insufficiently explored. Concretely, in these methods, teachers simply treat different modalities as distinct channels and typically ignore the modality gaps. However, given that these MRI are captured by different imaging principles, modality gaps unfortunately exist as always (see Figure 1 (a)). As such, the teachers may fail to learn invariant features, which further prevents the model from learning shared representations across different modalities and consequently degrades the prediction performance.\nIlluminated from alignment approaches in narrowing domain gaps in classification tasks [14]\u2013[16], in this paper, we investigate whether alignment can also be used to reduce modality gaps for brain tumor segmentation tasks. To this end, we propose a novel alignment paradigm where teachers"}, {"title": "II. THEORETICAL MOTIVATIONS", "content": "Notations. Considering J modalities of medical images with paired observations and targets {Xj}Jj=1 and Y. Note for medical modalities, Y remains static for all modalities. For the teacher of medical segmentation with missing modalities, the encoders are denoted as T : T(Xj) \u2192 Z where Z represents the produced latent features. Simultaneously, a predictor C that predicts segmentation masks from {Zj}Jj=1 as C* : C*({Zj}Jj=1) \u2192 Y. Correspondingly, we denote the possible downstream model for the jth target modality as Sj: Sj(Xj) \u2192 Zj of each modalities with their predictor Cj: Cj(Zj) \u2192 Y. Let P(\u00b7), DKL(\u00b7||\u00b7), He(\u00b7, \u00b7), I(\u00b7;\u00b7) denote the probability of a random variable from the distribution, KL divergence, cross-entropy, and mutual information, respectively.\nPrevious methods. The original objective used in [1], [11]\u2013 [13] of training teacher can be treated as using a fixed linear T. Thus its objective is:\n$max\\limits_{C^*}  \\sum\\limits_{j=1}^J E_{z_j \\sim P(z_j)} [ln P(Y|C^*(Z_j))].$ (1)\nIn the scope of information theory, it can be altered as:\n$min\\limits_{C^*}  H_c(P(C^* (Z), P(Y)).$ (2)\n$j=1$\nMeanwhile, for Sj that leverages knowledge from T, its objective is:\n$max\\limits_{S_j,C_j} Ez_j\\sim P(Z_j) [ln P(Y | C(Z_j))] \u2013 DKL(P(Z_j)||P(Z)).$ (3)\nIn practice, the modality which Sj aims to is unknown for T. Thus, we expect the sum of risks for all possible students (shown in Eq. (3)) to be minimized:\n$max \\sum\\limits_{S_j,C_j} j=1 [Ez_j ~P(Z_j) [lnP(Y|C(Z_j))]-DKL(P(Z_j)||P(Z))]$\n$ \\stackrel{(5)}{=} min \\sum\\limits_{S_j,C_j} j=1 [DKL(P(Z)||P(Z_j))$\n$+ H_c(P(C_j(Z_j)), P(Y))].$ (4)"}, {"title": "Our alignment paradigm", "content": "To alleviate the modality gaps, our alignment paradigm aligns all modal latent features to a pre-defined distribution Pmix, as shown in Figure 1(b) with Phix and Pmix column. This part provides more details about our approach. Different from previous studies [1], [11]\u2013 [13], we further define a continuous distribution Pmix as the targeted latent space distribution of Z* for the teacher.\nProposition 1. For training a multi-modal teacher model, it is assumed that Zi | Zj where i,j \u2208 {1, ..., J},i \u2260 j. In this scenario, there exists a probability distribution Pmix that can be used as an anchor distribution to align the latent variables Z*, while preserving sufficient information for accurate prediction of the segmentation labels Y.\nProof. The modality-independent assumption is derived from the fact that each modality is independent of each other. If Pmix preserves sufficient information for accurate prediction of the segmentation labels Y, based on the joint and marginal mutual information, we have\n$\\sum\\limits_{j=1}^J I(P_{mix}(Z_j); P(Z_j)) \\leq I(P_{mix}(Z^*); P(Z^*)).$ (5)\nEq. (5) shows that individually mapping each modality Z to Pmix is a lower bound of mapping all modalities together to Pmix.\nProposition 1 is single-letterization that simplifies the op- timization problem over a large-dimensional (i.e., multi-letter) problem. Therefore, we individually align the representations of each modality to the anchor Pmix, rather than the whole distribution of all representations from all modalities:\n$\\sum\\limits_{j=1}^J Ez~P(Z_j) [ln P(Y|C^*(Z)) \u2013 DKL(P(Z)||Pmix)]$\n$<Ez^*~P(z^*) [ln P(Y|C^*(Z^*))-DKL(P(Z^*)||Pmix)].$ (6)\nThe former is termed Evidence Lower Bound (ELBO) [17], which is tighter than the latter. Thus, minimizing the gap between all modalities and Pmix, the alternative objective for teacher is further derived as:\n$min \\sum\\limits_{j=1} [DKL(P(Z) || Pmix)+Hc(P(C^*(Z)); P(Y))].$ (7)\nAs shown in Eq. (7), the essential point is to find a feasible Pmix that anchors all latent features in the space while preserving the prediction ability from the latent features to targets for all students.\nPossible approximations of Pmix. It is intractable to obtain the ideal Pmix in practice. Therefore, different pre-defined Pmix approximations are made. Similar to VAE, a possible"}, {"title": "III. METHODOLOGY", "content": "A. Proposed alignment paradigm\nThe overall alignment paradigm consists of training teachers and students. The structure diagram of the teacher is exhibited in the bottom left part of Figure 1. For training the teacher, each modality is initially encoded into the same latent space and then individually aligned to the pre-defined anchor Pmix as shown in Eq. (5). Finally, following the previous baselines, a 3D U-Net is used as the predictor (C*) for segmentation based on the aligned latent features.\nThen the enhanced prior knowledge obtained by the teach- ers are leveraged to students by implanting to different backbones (see Sec. IV-A). We train students by distilling knowledge from the trained teachers in the missing modal- ity scenario [1], [11]\u2013[13]. The loss to be optimized is: LS = Lseg + LT, where Lseg represents the segmentation loss guided by ground truth labels, and LT denotes the loss that receives supervision from the teacher used in the previous works.\nB. Alignment with various Pmix\nThis alignment towards Pmix standardizes data distributions from diverse sources into a consistent distribution, facilitating the learning of unique features across modalities. Specifically, we provide details of the alignment to various empirical forms of Pmix (which are denoted as Pmix, Pmix, and Pmix).\nAligning to Pkin. The kth modality that has the most feature invariant representation is a reasonable choice for Pmix (see more details in Sec. IV-C), i.e., PmixP(Z=k). The alignment of other modalities to the chosen optimal modality is facilitated through Mean Squared Error (MSE). Here we minimize: E[||Z - Z||2] for each paired sample.\nAligning to Pmix. In the quest to derive a more conducive latent space for integrating all modalities, we have advanced an innovative methodology termed Adaptive Alignment. This approach will transcend the basic alignment method that confines the latent space to a specific modality. Adaptive Alignment operates under the presumption that an optimal latent space for a prior modality can serve as a foundational anchor. Then we have: \\argmin \\sum\\limits_{j=1}; || - ||2, where wj are learnable weights. Note that the teacher is not frozen during training, with the purpose to enable the teacher find the adaptive latent space.\nAligning to Pmia. Since Pomiar is the selected form P(Z) and Pmix is a weighted mixture of P(Z)'s, the relationship"}, {"title": "IV. EXPERIMENTS", "content": "Data and implementation details. The 2018 Brain Tumor Segmentation Challenge (BRATS) dataset [4], [20], consisting of 285 subjects with four MRI modalities (T1, T1c, T2, and FLAIR), is employed to evaluate the proposed paradigm and other baselines. Annotations are given by normal tissue regions and three tumor-related masks, i.e., whole tumor (WT), tumor core (TC), and enhancing core (EC). Image intensities are normalized to [-1,1]. Each volume is augmented by randomly cropping each training example as 80 \u00d7 80 \u00d7 80 [1], while the dataset is split following [13]. Teachers and students are optimized with Adam. Batch size is set as 4. Learning rates are initialized as le-\u00b3 which are gradually decayed by le-5 for both teachers and students.\nA. Comparison with state-of-the-art methods\nTable I reports how our proposal could promote state-of- the-art (SOTA) approaches in guiding students, including KD- Net [12], PMKL [1], ProtoKD [13] and SMU-Net [11]. When three modalities (the most challenging setting) are missing, the anchor Pix, could lead to an improvement of 1.75 dice score on average for various SOTA students. We also carry out experiments on other less difficult scenarios. These additional results can be referred to in Table III.\nB. Find the teacher with the best prior knowledge\nFigure 1 presents distributions of anchors among PN, pk mix' and Pmix Consistent with the theoretical analysis presented in Sec. II, modality gaps are not narrowed at all. As such, the space cannot be filled with Pmix in (c), suggesting that Pmix N(0, 1) cannot be placed as a fixed anchor to be aligned to. On the contrary, as shown in (d) and (e) when anchors Pk Phix and Pmix are employed, distributed centers of each modality are almost overlapped, demonstrating that modality gaps are narrowed. Table IV statistically demonstrates that Pix, as the best anchor for teacher, generates an improvement by 1.03 dice score.\nC. Effectiveness verification of the student\nProper Phix to be aligned. To design a pre-defined anchor Pk Pmix, we train the teachers with each single modality. As shown in Table V, treating T1ce modality as Prix achieves the best dice score 41.15 across all the testing sets. This implies that Tice encompasses the most comprehensive information, making it an ideal fixed anchor for enhancing feature invariant representation learning. Additionally, we also find that the learning parameters in Pmix of T1, T2, T1ce and Flair are 0.7759, 0.8977, 2.2055 and 0.3055 respectively. Apparently, Tlce enjoys the biggest weight, meaning that it is the most informative modality. Conversely, an unsuitable fixed anchor will significantly impair segmentation performance, as discussed in Table II.\nOptions of anchors. Table I also shows that students trained by teachers with Pmix performs better than teachers with Phi; in addition, teachers with Prix is the worst one. Pix"}, {"title": "V. CONCLUSION", "content": "In this paper, we present a novel alignment framework to narrow the modality gaps whilst learning simultaneously invariant feature representations in segmenting brain tumors with missing modalities. Specifically, we invent an alignment paradigm for the teacher with latent space distribution Pmix as the aligning anchor, thereby building the reliable prior knowledge to supervise training students. Meanwhile, we pro- vide theoretical support for the proposed alignment paradigm, demonstrating that individually aligning each modality to Pmix certifies a tighter evidence lower bound than map- ping all modalities as a whole. Extensive experiments have demonstrated the superiority of the proposed paradigm in several latest state-of-the-art approaches, enabling them to better transfer knowledge from the multi-modality teacher to the student with missing modalities."}]}