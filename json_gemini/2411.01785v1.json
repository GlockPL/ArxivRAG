{"title": "Transferable Sequential Recommendation via Vector Quantized Meta Learning", "authors": ["Zhenrui Yue", "Huimin Zeng", "Yang Zhang", "Julian McAuley", "Dong Wang"], "abstract": "While sequential recommendation achieves significant progress on capturing user-item transition patterns, transferring such large-scale recommender systems remains challenging due to the disjoint user and item groups across domains. In this paper, we propose a vector quantized meta learning for transferable sequential recommenders (MetaRec). Without requiring additional modalities or shared information across domains, our approach leverages user-item interactions from multiple source domains to improve the target domain performance. To solve the input heterogeneity issue, we adopt vector quantization that maps item embeddings from heterogeneous input spaces to a shared feature space. Moreover, our meta transfer paradigm exploits limited target data to guide the transfer of source domain knowledge to the target domain (i.e., learn to transfer). In addition, MetaRec adaptively transfers from multiple source tasks by rescaling meta gradients based on the source-target domain similarity, enabling selective learning to improve recommendation performance. To validate the effectiveness of our approach, we perform extensive experiments on benchmark datasets, where MetaRec consistently outperforms baseline methods by a considerable margin.", "sections": [{"title": "I. INTRODUCTION", "content": "Thanks to recent advances in language modeling, sequential recommendation has experienced significant improvements in capturing user-item transition patterns [1]\u2013[6]. While sequential recommendation outperforms traditional methods, a common challenge is that well-trained models cannot be reused for an unseen domain. As such, transferable recommenders are proposed for quick adaptation to a different target domain [7], [8]. One popular approach is to leverage shared information across domains (e.g., shared items) to enhance adaptation performance [9]\u2013[11]. Another stream of cross-domain recommendation aims at learning domain-invariant features [12]-[14]. However, the mentioned approaches assume (partially) overlapping user / item groups or require explicit correspondences. Therefore, they are inapplicable upon large source-target domain discrepancy [15]. Recently, transfer learning methods are proposed by utilizing auxiliary information, where descriptive input (e.g., item title) is encoded as features [16]-[18]. Yet current approaches may cause performance drops due to the over-emphasis of domain-specific features [19]. Additionally, such methods require additional input, rendering them less effective in text-scarce or sensitive domains.\nTo generalize transferable sequential recommenders to universal model architectures and recommendation scenarios, we consider an ID-only, non-overlapping and multi-source transfer learning setting, where items are solely represented with IDs and user interaction histories are sequences of item IDs in chronological order. Moreover, we assume zero overlapping of shared information across domains, that is, the involved domains only comprise of mutually exclusive user and item groups. Consequently, our approach enables the transfer of knowledge from arbitrary source domains to a different target domain in spite of the input heterogeneity, which significantly extends the applicability of cross-domain recommendation. The primary challenge of this setting is twofold: (1) the disjoint input spaces and item-level differences can lead to alignment difficulties across different domains; and (2) user behavior patterns in source domains may differ from those in the target domain, potentially causing negative transfer (e.g., performance drop) upon large domain discrepancy.\nTo this end, we propose vector quantized meta learning for universally transferable sequential recommenders (MetaRec). MetaRec can accommodate arbitrary recommender architecture and consists of: (1) vector quantization (VQ) and (2) meta transfer. VQ solves the input heterogeneity problem by mapping the original item embeddings to a shared feature space. Instead of introducing additional parameters, we apply weights from the target domain embedding table as codebook in VQ. Then, the output vectors in the aligned feature space are used as item features to predict the next interaction. Despite quantizing the item representations, transition patterns from the source domains may be of different similarity to the target domain. Therefore, we additionally design meta transfer that adaptively learns to transfer knowledge from data-intensive source domains to the data-scarce target domain. Specifically, we update the parameters with sampled source domain data (i.e., source tasks), followed by deriving meta gradients using sampled target domain examples. Based on source-target gradient similarity, we rescale the meta gradients to optimize the learning from different source tasks. As such, MetaRec learns domain-invariant features from source optimization paths with the objective of improving the target domain performance. We summarize our contributions below:\n1) To the best of our knowledge, we are the first to propose a solution for cross-domain sequential recommendation"}, {"title": "II. RELATED WORK", "content": "Transferable recommender systems are proposed to improve performance in data-scarce settings [20]. There exist several approaches to address transfer learning, with the majority of existing work relying on the assumption of shared user or item groups [11], [21]. Another possible approach is to leverage generalized representations for improved knowledge transfer [14], [22]. Recently, auxiliary features are proposed to improve cross-domain recommendation performance, where additional modalities (e.g., text) or auxiliary information (e.g., item category) are adopted to generate item features based on the associated descriptive input [18], [23]. However, existing approaches either require shared information across domains or use additional auxiliary information for recommendation. Therefore, we propose a generalized transfer learning framework that solely relies on item IDs to extend the applicability of transferable sequential recommenders."}, {"title": "B. Vector Quantization", "content": "Vector quantization (VQ) refers to mapping high-dimensional vectors to discrete codes using prototype vectors, which are often learnt in an unsupervised fashion [24]. Recently, VQ is known for being used in generative models for discrete representations in the latent space [25]. Vector quantization is also applied to learn compact features or semantic IDs for improved efficiency and performance in recommenders [26], [27]. For cross-domain recommendation, VQ-Rec proposes to leverage VQ that generates discrete codes upon textual features [19]. Yet previous VQ methods focus on improving recommendation efficiency or domain-invariant semantic IDs, the potential of vector quantization in learning domain-invariant item features remains unexplored for sequential recommender systems."}, {"title": "C. Meta Learning", "content": "Meta learning (i.e., learning to learn) demonstrates superior performance in few-shot learning, where limited training examples are provided for the desired task [28]. A common meta learning approach is to construct a meta-learner that guides the optimization of the learner's parameters [29], [30]. For example, model-agnostic meta learning (MAML) uses second-order optimization to learn initial parameters that quickly adapt to a new task [31]. In recommender systems, meta learning methods have also been applied to improve data-scarce recommendation or enhance recommendation fairness [32], [33]. Unlike previous works, we consider cross-domain setting and propose meta learning-based transferable recommendation, which 'learns to transfer' from multiple sources to optimize the target domain recommendation."}, {"title": "III. METHODOLOGY", "content": "Our transfer learning framework is based on sequential recommendation, in which user interaction history x is used as input. Specifically, x is a sequence of user interactions [x\u2081,x\u2082,...,x_T] with length T in chronological order, where the items are represented with unique IDs in the item space I (i.e., x\u1d62 \u2208 I, i = 1, 2, ..., T). The output of the recommender is the prediction scores \u0177 \u2208 \u211d^|I| over input space I, whereas the ground truth item is denoted with y \u2208 I. We consider the multi-source transfer learning setting:\n\u2022 Source Domain: Let {D^s_i}^M_{i=1} be the set of M source domains (M > 1), each source domain D^s is defined by its item space I^s, user group U^s and dataset X^s, in which U^s data examples are provided (i.e., X^s = {(x,y)}^|U^s|). All source domain datasets are available to facilitate the transfer learning process.\n\u2022 Target Domain: Similar to the source domain, we define the target domain D^t with item space I^t, user group U^t and dataset X^t. Target data X^t = {(x,y)}^|U^t|_{i=1} is also provided (smaller than source datasets). To make our setting universally applicable, we additionally assume non-overlapping user and item groups across all domains, i.e., I^s_i \u2229 I^t = \u2205, U^s_i \u2229 U^t = \u2205, with i = 1, 2, ..., M.\nWe denote the recommender model with f, which is parameterized by \u03b8 (i.e., \u0177 = f(\u03b8;x)). The model f comprises a embedding table (denoted with f_e) and an encoding model f_m, with f = f_m f_e. Ideally, the highest ranked item in \u0177 matches the ground truth y (i.e., y = arg max \u0177). The objective of our framework is to optimize the target domain performance. In other words, we seek to minimize the expectation of recommendation loss L w.r.t. parameters \u03b8 over X^t:\n$$ \\min_\\theta [\\mathbb{E}_{(x^t, y^t) \\sim X^t} [\\mathcal{L}(f(\\theta; x^t), y^t)]]. $$"}, {"title": "B. Vector Quantization", "content": "1) Mapping Quantized Representations: Our VQ module consists of a multi-head codebook e \u2208 \u211d^(H\u00d7K\u00d7D), where H, K, D represent the head number, codebook size and hidden dimension. To avoid introducing additional parameters and overfitting to the limited target data, we reshape the target domain embedding table to obtain the codebook e. Consequently, K is the size of target domain items |I^t| and H \u00d7 D is equal to the hidden dimension of the model f. Here, we denote the j-th embedding vector of the i-th head as e^i_j \u2208 \u211d^D, with i\u2208 {1,2,..., H} and j \u2208 {1, 2, ..., K}. For simplicity, the embedding of item x is referred as z_e in the following discussion (i.e., z_e = f_e(x)). We split the hidden dimension of z_e into H equal dimensions (i.e., z_e = [z^1_e; z^2_e; ... ; z^H_e]), as we find"}, {"title": "C. Meta Transfer", "content": "1) Formulation: Given f parameterized by \u03b8, X^s and X^t, meta transfer can be seen as a bi-level optimization problem:\n$$ \\min_\\theta [\\mathbb{E}_{(x^t, y^t) \\sim X^t} [\\mathcal{L}(f(Alg(\\theta, X^s); x^t), y^t)]], $$\nwhere we seek to minimize L w.r.t. \u03b8 over X^t. For a collection of source datasets {X^s_i}^M_{i=1}, we can similarly write $$ \\min_\\theta \\mathbb{E}_{X^s \\sim \\{X^s_i\\}^M_{i=1}, (x^t, y^t) \\sim X^t} [\\mathcal{L}(f(Alg(\\theta, X^s); x^t), y^t)] $$. This is also called outer-level optimization. Nevertheless, the original parameter set \u03b8 is not directly used to compute the outer-level loss L. Instead, we first optimize upon source data X^s with Alg (e.g., gradient descent) to obtain the task-specific parameter set \u03c6 (i.e., \u03c6 = Alg(\u03b8,X^s)), which is known as inner-level optimization. After that, outer-level optimization is performed to compute meta gradients w.r.t. \u03b8.\n2) Optimization: In inner-level optimization (i.e., source task), we compute \u03c6 upon sampled data from X^s via Alg. Alg refers to some gradient descent-based optimization algorithm and is formulated as:\n$$ \u03c6 = Alg(\u03b8, X^s) = \\arg \\min_\\theta \\mathbb{E}_{(x,y) \\sim X^s} [\\mathcal{L}(f(\\theta; x^s), y^s)]. $$\nIn our experiments, we sample from X^s and perform multiple steps of gradient descent with learning rate \u03b1 to approximate Equation (5). For each source domain, inner-level optimization only requires first-order derivatives. However, to optimize the outer-level problem, we differentiate through Alg (i.e., \u03c6) back to \u03b8, which requires second-order derivatives:\n$$ \\frac{d \\mathcal{L}(f(Alg(\\theta, X^s); x^t), y^t)}{d \\theta} = \\frac{d Alg(\\theta, X^s)}{d \\theta} \\nabla_\\varphi \\mathcal{L}(f(Alg(\\theta, X^s); x^t), y^t), $$\nrecall that Alg(\u03b8, X^s) computes \u03c6, and thus \\frac{d Alg(\u03b8, X^s)}{d \\theta} is equivalent to \\frac{d \\varphi}{d \\theta}. The right-hand side \\nabla_\\varphi \\mathcal{L}(f(Alg(\\theta, X^s); x^t), y^t) refers to first-order gradients by computing the meta loss over the sampled (x^t, y^t). In this term, we consider the derivatives of the meta loss w.r.t. \u03c6 (i.e., L \u2192 \u03c6). However, \\frac{d Alg(\\theta, X^s)}{d \\theta} is non-trivial as it requires second-order derivatives (i.e., Hessian matrix) to track parameter-to-parameter changes from \u03c6 through Alg to the original \u03b8. In our implementation, we differentiate the meta loss w.r.t. \u03b8 by retaining the computational graph [31].\n3) Gradient Rescaling: While optimizing Equation (4) improves the target domain performance, it does so by uniformly learning without accounting for domain similarity. Therefore, we introduce a gradient rescaling algorithm that adaptively updates the parameter set \u03b8. Specifically for the i-th source task, the original parameters \u03b8 are updated with first-order derivatives as we sample from X^s. As we update \u03c6 multiple times to obtain \u03c6\u1d62, we denote the gradients of the i-th source task with \u2207_\u03c6\u1d62 L for simplicity. Subsequently, the meta loss is computed using \u03c6\u1d62 and examples sampled from X^t (as in Equation (4)). Simplified from Equation (6), we use \u2207_\u03c6\u1d62 L"}, {"title": "IV. EXPERIMENTS", "content": "1) Dataset: We select source and target domains datasets following [18], [19], [35]. In particular, we adopt Automotive, Cell Phones and Accessories, Clothing Shoes and Jewelry,\nElectronics, Grocery and Gourmet Food, Home and Kitchen, Movies and TV and CDs and Vinyl as our source datasets (i.e., Source). For target datasets, we select Industrial and Scientific (Scientific), Musical Instruments (Instruments), Arts, Crafts and Sewing (Arts), Office Products (Office), Video Games (Games) and Pet Supplies (Pet). For preprocessing, we follow previous works [17]\u2013[19], [36] by performing k-core filtering.\n2) Evaluation: Following [18], [19], [36], we adopt the leave-one-out approach, which uses the last two items in each sequence for validation and test. We adopt normalized discounted cumulative gain (NDCG@k), recall (Recall@k) and mean reciprocal rank (MRR) with k = 10 as metrics. We save the model with best validation NDCG@ 10 scores for evaluation on the test set. We compute the metric values by ranking the ground-truth item against all items in the target dataset. For baselines, we select GRU4Rec [37], NARM [38], SASRec [1], BERT4Rec [2], FMLP-Rec [4] and LRURec [34]."}, {"title": "A. RQ1: How does MetaRec perform in cross-domain sequen-tial recommendation?", "content": "We first evaluate the cross-domain recommendation performance of MetaRec with other ID-based baseline methods. The evaluation results for each target dataset are reported in Table I. Overall, the baselines are consistently outperformed by MetaRec, confirming the effectiveness of the proposed MetaRec in cross-domain recommendation. Specifically, we observe: (1) MetaRec performs the best across all scenarios, successfully improving target domain performance without requiring auxiliary information. On average, MetaRec achieves 6.36% improvements on NDCG@10 compared to the best-performing baseline. (2) MetaRec shows significant improvements on Office and Games (7.39% on NDCG@10), while achieving moderate gains on Arts and Pet (3.05% on NDCG@10). These results suggest that MetaRec may perform differently across domains. (3) In contrast to recall scores, MetaRec demonstrates a better ranking performance. For instance on the Scientific dataset, the performance on NDCG@10 increases by 8.44%, while the relative improvement on Recall@10 is lower at 0.63%. Overall, the results in Table I show a significantly improved transfer performance by MetaRec, suggesting the efficacy of the proposed method."}, {"title": "B. RQ2: What contributes to the performance of MetaRec?", "content": "In this research question, we evaluate the effectiveness of MetaRec by ablating the proposed method. Specifically, we study variants of MetaRec to assess the effectiveness of individual modules. We report the performance of MetaRec and its variants in Table II, including: (1) MetaRec without multi-head VQ; (2) MetaRec without VQ; (3) MetaRec without gradient rescaling; and (4) We additionally substitute meta transfer with joint training (i.e., MetaRec w/o meta transfer). We observe the following: (1) the proposed multi-head VQ performs well in aligning item features. In contrast, substituting the multi-head approach or removing VQ causes consistent performance drops, suggesting the effectiveness of employing multi-head VQ while sharing weights with target domain embeddings. (2) Removing gradient rescaling or meta transfer also leads to consistent performance deterioration across metrics. On average, 2.19% NDCG@10 improvements can be attributed to the proposed gradient scaling, whereas removing meta transfer causes 14.86% NDCG@10 drops. In summary, the ablation results confirm the effectiveness of the parameter-efficient VQ and meta transfer mechanisms in MetaRec, consistently enhancing recommendation performance in cross-domain transfer scenarios."}, {"title": "V. CONCLUSION", "content": "In this work, we investigate an ID-only, non-overlapping and multi-source setting for universal transfer learning on sequential recommenders. In particular, we design vector quantized meta transfer for sequential recommenders (MetaRec). The VQ module is designed to map domain-specific item embeddings into a shared feature space. Moreover, the proposed meta transfer adaptively learns from the source domains to guide the transfer of source knowledge to the target domain. As such, MetaRec maximizes the transfer learning performance via generalizable representations and exploitation of the source domains."}]}