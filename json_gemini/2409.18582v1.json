{"title": "Optimistic Games for Combinatorial Bayesian Optimization with Application to Protein Design", "authors": ["Melis Ilayda Bal", "Pier Giuseppe Sessa", "Mojm\u00edr Mutn\u00fd", "Andreas Krause"], "abstract": "Bayesian optimization (BO) is a powerful framework to optimize black-box expensive-to-evaluate functions via sequential interactions. In several important problems (e.g. drug discovery, circuit design, neural architecture search, etc.), though, such functions are defined over large combinatorial and unstructured spaces. This makes existing BO algorithms not feasible due to the intractable maximization of the acquisition function over these domains. To address this issue, we propose GAMEOPT, a novel game-theoretical approach to combinatorial BO. GAMEOPT establishes a cooperative game between the different optimization variables, and selects points that are game equilibria of an upper confidence bound acquisition function. These are stable configurations from which no variable has an incentive to deviate \u2013 analog to local optima in continuous domains. Crucially, this allows us to efficiently break down the complexity of the combinatorial domain into individual decision sets, making GAMEOPT scalable to large combinatorial spaces. We demonstrate the application of GAMEOPT to the challenging protein design problem and validate its performance on four real-world protein datasets. Each protein can take up to 20X possible configurations, where X is the length of a protein, making standard BO methods infeasible. Instead, our approach iteratively selects informative protein configurations and very quickly discovers highly active protein variants compared to other baselines.", "sections": [{"title": "Introduction", "content": "Many scientific and engineering problems such as drug discovery (Negoescu et al., 2011), neural architecture search (Kandasamy et al., 2018), or circuit design (Lyu et al., 2018) require optimization of expensive-to-evaluate black-box functions over combinatorial unstructured spaces involving binary, integer-valued, and categorical variables. As a concrete example, consider the protein design problem, i.e., finding the optimal amino acid sequence to maximize the functional capacity (fitness) of the protein. Such fitness functions are highly complex, one can, in most cases, only be elucidated from real-world protein synthesis experiments. Moreover, exhaustive exploration is infeasible for both traditional lab methods and computational techniques (Romero et al., 2013) due to combinatorial explosion: a typical protein has 300 amino acid sites, each to be filled with one of twenty natural amino acids, yielding 20300 candidate variants.\nBayesian optimization (BO) is an established framework for optimizing black-box functions with the goal of minimizing the number of evaluations needed to certify optimality (Mockus, 1974). \u0412\u041e"}, {"title": "Problem Statement and Background", "content": "Problem statement We consider the problem of optimizing a costly-to-evaluate, black-box function $f: \\mathcal{X} \\rightarrow \\mathbb{R}$ over a combinatorial unstructured space $\\mathcal{X}$ without a lattice form. Suppose each element $x \\in \\mathcal{X}$ can be represented by $n$ discrete variables $x_1, x_2, ..., x_n$, where each $x^i$ takes values from a set $\\mathcal{X}^{(i)}$, this makes the domain of $n > 1$ variables $\\mathcal{X} = \\mathcal{X}^{(1)} \\times ... \\mathcal{X}^{(n)}$. Assuming $|\\mathcal{X}^{(i)}| = d, \\forall i$, the size of the combinatorial space $\\mathcal{X}$ is $d^n$.\nAs a concrete motivating example, consider the protein design problem given in Section 5. There, $f(x)$ corresponds to the fitness value of the designed amino acid sequence $x$, and each $x$ can take $20^n$ values where $n$ is the number of protein sites. Moreover, a (noisy) evaluation $f(x)$ is a labor-intensive process, requiring extensive efforts and specialized laboratory equipment.\nGaussian Processes (GPs) Bayesian Optimization (Mockus, 1974) is a versatile framework for optimizing complex, noisy, and expensive-to-evaluate functions. BO leverages Bayesian inference to model the underlying function with a surrogate, e.g., a Gaussian Process (GP) and iteratively selects evaluation points that are the most informative in terms of reducing uncertainty or enhancing model performance.\nFormally, a Gaussian Process $GP(\\mu(\\cdot), k(\\cdot,\\cdot))$ over domain $\\mathcal{X}$ is specified by a prior mean function $\\mu(x) : \\mathcal{X} \\rightarrow \\mathbb{R}$ and a covariance function $k(x,x') : \\mathcal{X} \\times \\mathcal{X} \\rightarrow \\mathbb{R}$, denoted by $f(x) \\sim GP(\\mu(x), k(x, x'))$, where $f(x)$ represents the function value at input $x$.\nGiven a set of observed data points $X_t$ up to iteration $t$ and their corresponding vector of noisy observations $Y_t = f(X_t) + \\epsilon_t$ with Gaussian noise $\\epsilon_t \\sim \\mathcal{N}(0, \\sigma_t^2)$, and a GP prior defined by $GP(\\mu_t(x), k_t(x, x'))$, the posterior distribution of the GP at iteration $t + 1$ given new observations $X_{t+1}$ is again Gaussian $p(f_{t+1} | X_t, X^\u2020, f_t) = \\mathcal{N}(\\mu_{t+1}, \\sigma_{t+1}^2)$ with posterior mean and variance (Rasmussen et al., 2006).\nBayesian Optimization (BO) To maximize $f$, BO algorithms iteratively select evaluation points so as to balance exploration and exploitation. At each iteration the method selects the maximizer of an acquisition function, for example, the widely-adopted Upper-Confidence Bound (UCB) (Srinivas et al., 2009) function. Given a GP model at iteration $t$, the UCB function is defined as\n$\\text{UCB}_t(\\text{GP}, x) = \\mu_t(x) + \\beta_t \\sigma_t(x),$ (1)\nwhere $\\mu(x)$ and $\\sigma(x)$ are the posterior mean and standard deviation at point $x$ according to GP, and $\\beta_t \\in \\mathbb{R}$ is a confidence parameter influencing the width of the set that can be selected to ensure the validity of the confidence set. The UCB function defines an optimistic estimate of the underlying objective $f$, and can effectively balance exploration (i.e., favoring points with large uncertainty $\\sigma_t(x)$) with exploitation (i.e., selecting points with large posterior mean $\\mu_t(x)$).\nWhile standard BO methods can efficiently optimize UCB(GP,\u00b7) in efficiently enumerable or continuous domains, they become very soon intractable in the case of combinatorial unstructured domains, such as the space of possible amino acid sequences. In the next section, we propose GAMEOPT, a novel BO approach that circumvents such prohibitive difficulty."}, {"title": "GAMEOPT algorithm", "content": "In a nutshell, the proposed GAMEOPT (Optimistic Games) approach circumvents the combinatorial optimization of the UCB function by defining a cooperative game among the $n$ input variables and computes the associated equilibria as candidate evaluation points. More formally, at each iteration $t$, GAMEOPT defines a cooperative game (Fudenberg and Tirole, 1991) involving $\\mathcal{N} = \\{1, ..., n\\}$ players, each player $i$ taking actions in the discrete set $\\mathcal{X}^{(i)}$. In such a game, the players' interests are aligned towards the goal of maximizing the function $\\text{UCB}(\\text{GP}_t, \\cdot) : \\prod_{i=1}^n \\mathcal{X}^{(i)} \\rightarrow \\mathbb{R}$, where $GP_t$ is the current GP estimate at iteration $t$. Thus, it can be interpreted as an optimistic game with respect to the true unknown $f$. In such a game, the goal of the players is to compute game (Nash) equilibria, defined as follows.\nDefinition 3.1 (Nash equilibrium (Nash, 1951)). Let $r^i : \\mathcal{X} \\rightarrow \\mathbb{R}$ be the reward function of each player $i$. A joint strategy profile $x^{\\text{eq}} = (x_1^{\\text{eq}}, ..., x_n^{\\text{eq}})$ is a Nash equilibrium if, for every player $i \\in \\mathcal{N}$, $r_i(x_i^{\\text{eq}}, x_{-i}^{\\text{eq}}) \\geq r_i(x^i, x_{-i}^{\\text{eq}}), \\forall x^i \\in \\mathcal{X}^{(i)}$, where $x_{-i}^{\\text{eq}}$ is the joint equilibrium strategy of all players except $i$.\nThe existence of such equilibrium point(s) is guaranteed since players and actions are finite (Fudenberg and Tirole, 1991). Moreover, because players' reward functions are aligned and coincide with UCB(GP, \u00b7), efficient polynomial-time equilibrium-finding methods can be employed, such as Iterative Best-Response (IBR), where players update their actions sequentially, or simultaneous multiplicative weights updates such as the HEDGE (Freund and Schapire, 1997) algorithm. We report these two possible strategies in Algorithms 2 and 3 in Section 3.1. Intuitively, equilibria are computed by breaking down the complex decision space into individual decision sets, as illustrated in Figure 1. Mathematically, we refer to this operation as,\n$\\mathcal{X}^{eq} = \\underset{x_i \\in \\mathcal{X}^{(i)};i\\in[n]}{\\text{arg eq}} \\text{UCB}(\\text{GP}_t, (x_1,...,x_n)).$ (2)\nOur overall approach is summarized in Algorithm 1. In practice, we compute $M > 1$ equilibria and subselect a batch of top $B < M$ equilibria according to the UCB(GP, \u00b7) criterion. Subsequently, such a batch is evaluated by $f$, the GP model is updated accordingly, and a new game with an updated reward function is defined at the next iteration based on the updated posterior.\nA form of local optimality Within GAMEOPT, each player strategically selects actions to maximize their collective payoff, much like seeking local optima in a continuous multi-dimensional function (see Figure 1). In continuous optimization, a local optimum is a point, where there is no direction that leads to an improvement, similarly, as in our framework there is not a player that can unilaterally improve the value of the collective pay-off. In essence, seeking equilibria is analogous to seeking local optima of a continuous acquisition function, and our game-based approach allows us to effectively pinpoint them within an unstructured combinatorial space. We remark that GAMEOPT computes equilibria of the current $\\text{UCB}(\\text{GP}^t, \\cdot)$ function which, as we show in Section 5, are better and better approximations of equilibria of the unknown objective $f$.\nPrice of Anarchy But how good are equilibria compared to the global optimum? The quality of equilibria (also known as the efficiency of the game) can be quantified via the game-theoretic notion of Price of Anarchy (PoA) (Christodoulou and Koutsoupias, 2005), defined as the ratio between the worst equilibrium and the global optimum, i.e., PoA := $\\underset{x \\in \\mathcal{E}}{\\text{min}} f(x)/\\underset{x}{\\text{max}} f(x)$ where $\\mathcal{E}$ is the set of all equilibria of $f$. PoA has been extensively studied for various classes of games and can sometimes be upper-bounded given further assumptions on $f$. As an example, in case $f$ is a submodular function (over binary, integer, or continuous domains), PoA is guaranteed to be at least 0.5 (Vetta, 2002; Sessa et al., 2019b). Although such a PoA guarantee does not readily apply to our setting, we believe similar ones could be proved for the case of unstructured domains though this is beyond the scope of our work. In practice, given an unknown function $f$ (such as the protein's fitness function in our experiments of Section 5), not all equilibria may achieve high function values (i.e. PoA can be very low). Nevertheless, GAMEOPT computes multiple equilibria ($M > 1$) at each iteration and selects only the top B according to their UCB value. We believe this is a key form of robustness that can effectively filter out suboptimal equilibria and empower GAMEOPT's experimental performance."}, {"title": "Equilibrium finding subroutines", "content": "We present a set of established algorithms for finding an equilibrium of the game introduced in Eq. (2).\nIterative best responses One possible subroutine for Algorithm 1 is Iterative Best Response (IBR) procedure as provided in Algorithm 2. Concretely, under the cooperative game setting outlined in Section 3 and given GP-predicted UCB function, each player iteratively selects the response that maximizes the value of the game given that the other players play the joint strategy from the previous round. Each player is sequentially selected to play their best response in a round-robin fashion. Because action space is finite, this procedure is guaranteed to converge to a local maximum of the UCB function i.e., an equilibrium of the underlying game (Fudenberg and Tirole, 1991).\nMultiplicative weights updates Alternatively, we can compute game equilibria letting players simultaneously act according to a multiplicative weights update algorithm such as HEDGE (Freund and Schapire, 1997), see Algorithm 3. We can cast equilibrium computation as an instance of adversarial online learning among multiple learners (Cesa-Bianchi and Lugosi, 2006). Here, each player selects a strategy based on their available options and, after observing the joint payoff, players' strategies are re-weighted based on past performance. Through repeated rounds of play and re-weighting, the empirical frequency of play forms a coarse correlated equilibrium (a weaker notion of Nash equilibrium), see e.g. (Cesa-Bianchi and Lugosi, 2006), while convergence to pure Nash equilibria is also guaranteed in some cases (Kleinberg et al., 2009; Palaiopanos et al., 2017)."}, {"title": "Related work", "content": "While there exist rather few works in the area (Papenmeier et al., 2023), existing combinatorial BO methods either target surrogate modeling with discrete variables (Baptista and Poloczek, 2018; Oh et al., 2019; Garrido-Merch\u00e1n and Hern\u00e1ndez-Lobato, 2020; Kim et al., 2021; Deshwal et al., 2023) or optimizing acquisition function within discrete spaces (Baptista and Poloczek, 2018; Deshwal et al., 2020, 2021a,b; Khan et al., 2023). However, they often require a parametric surrogate model with higher-order interaction specifications for combinatorial structures (Baptista and Poloczek, 2018) or domain-specific knowledge (Deshwal et al., 2020). In contrast, GAMEOPT relies on a non-parametric surrogate model, without the need for domain-specific knowledge.\nClosest to ours is (Daulton et al., 2022), which also targets optimizing the acquisition function in high-cardinality discrete/mixed search spaces via a probabilistic reparameterization (PR) that maximizes the expectation of the acquisition function. However, PR fails at being tractable since it requires evaluating the expectation over the joint distribution of all decision variables, requiring combinatorially many elements to be summed. An accurate estimate would require extensive sampling without special structural assumptions. In contrast, GAMEOPT treats each variable independently (potentially in parallel) within the game, keeping the values of the remaining variables fixed during each strategy update. We use PR as a baseline to evaluate our approach in Section 5, and demonstrate improved performance of our method on protein design problems.\nRecently, the interplay between BO and game theory has been explored by the line of works (Sessa et al., 2019a, 2022; Dadkhahi et al., 2020), but its connection with combinatorial BO is novel."}, {"title": "Sample-Complexity Guarantees", "content": "In this section, we derive sample-complexity guarantees for GAMEOPT. Namely, we characterize the number of interaction rounds $T$ required to reach approximate equilibria (i.e., local optima) of the true function $f$. For simplicity, we assume GAMEOPT is run with batch size $B = 1$, though our results can be generalized to larger $B$.\nThe obtained guarantees are based on standard regret bounds of Bayesian optimization adapted to our equilibrium finding goal. These are characterized by the widely utilized notion of maximum information gain (Srinivas et al., 2009):\n$\\gamma_t = \\frac{1}{2} \\log |\\mathcal{I}_t + \\sigma^{-1}K_t|.$ (3)\nThis is a kernel-dependent ($K_t$) quantity that quantifies the maximal uncertainty reduction about $f$ after $t$ observations. Further, to characterize our sample complexity, we define the notion of $\\epsilon$-approximate Nash equilibrium.\nDefinition 4.1 ($\\epsilon$-approximate Nash equilibrium). A strategy profile $x^{\\text{eq}}$ is a $\\epsilon$-approximate (Nash) equilibrium of $f$ if, for each $i \\in \\mathcal{N}, f(x^{\\text{eq}}) \\geq f(x^i, x_{-i}^{\\text{eq}}) - \\epsilon, \\forall x^i \\in \\mathcal{X}^{(i)}.\nIn the next main theorem, we provide a lower bound on the number of iterations $T$ to reach approximate equilibria. After $T$ rounds, we assume GAMEOPT returns $x^\u2020$ with:\n$T^* := \\text{arg} \\underset{t \\in [T]}{\\text{min}} \\underset{i,x^i}{\\text{max}} [\\text{UCB}(GP_t, x^i, x_{-i}) - \\text{LCB}(GP_t, x_t)],$\nwhere LCB is the lower confidence bound function $\\text{LCB}(GP_t, x) = \\mu_t(x) - \\beta_t \\sigma_t(x)$. That is, among the selected points $x_1,..., x_T, x_T$ is the one that guarantees the minimum worst-case single-player deviation. The deviation above is computed according to the UCB and with respect to the LCB, thus representing an upper bound on the actual deviation in terms of $f$. We can affirm the following.\nTheorem 4.2 (Sample complexity of GAMEOPT). Assume $f$ satisfies the regularity assumptions of Section 2, and GAMEOPT is run with confidence width $\\beta_t = 2n \\text{log} (\\underset{i \\in [n]}{\\text{sup}} |\\mathcal{X}_i|)$. Then, with probability at least $1 - \\delta$ and for a given accuracy $\\epsilon \\geq 0$, the strategy $x^\u2020$ returned by GAMEOPT is a $\\epsilon$-approximate Nash equilibrium when\n$T \\geq \\Omega(\\frac{\\beta_T\\gamma_T}{\\epsilon^2}).$ (4)\nAn equivalent interpretation of the above result is as follows: After $T$ iterations, GAMEOPT returns an $\\epsilon_T$-approximate Nash equilibrium of $f$, with approximation factor $\\epsilon_T < O(T^{-\\frac{1}{2}} \\sqrt{\\beta_T \\gamma_T})$. Note that the latter bound is the typical rate of convergence of BO algorithms (Srinivas et al., 2009) to the global maximizer. Instead, in our combinatorial BO setup \u2013where global optimization is intractable\u2013 it corresponds to the rate of convergence to equilibria. A more explicit convergence guarantee can be obtained by employing existing bounds for $\\gamma_T$ which are known for commonly used kernels (Srinivas et al., 2009). E.g., for squared exponential kernels $\\gamma_T = O(\\log(T)^{nd})$ where $d$ is the dimension of each input space $\\mathcal{X}^{(i)}$ for each player $i \\in \\mathcal{N}$, with $|\\mathcal{N}| = n.$"}, {"title": "Application to Protein Design", "content": "In this section, we specialize the GAMEOPT framework to protein design, a problem defined over the space of possible amino acid sequences. Note that such domains are highly combinatorial (their size grows exponentially with the sequence length) and unstructured (i.e. they lack a lattice structure). In this context, computing game equilibria follows the natural principle of promoting beneficial mutants and mirrors the proteins' mutation and selection process. In Algorithms 4 and 5 (Appendix B), we provide a detailed elaboration of GAMEOPT for protein design using equilibrium-finding methods. We showcase its performance in four real-world protein datasets.\nIn the protein design context, GAMEOPT establishes a cooperative game among the different protein sites $i \\in \\{1, ..., n\\}$, where $n$ is the length of the protein sequence. Each site $i$ chooses an amino acid from the set $\\mathcal{X}^{(i)} = \\{\\text{A, C, D, E, F, G, H, I, K, L, M, N, P, Q, R, S, T, V, W, Y}\\}$, where the switching can be thought of as biological mutation. The joint objective of the players is to converge to a highly"}, {"title": "Datasets", "content": "We empirically evaluate GAMEOPT on real-world protein design problems, specifically focusing on the following instances: protein G domain B1, GB1, binding affinity to an antibody IgG-FC (KA), examined on two distinct datasets, GB1(4) (Wu et al., 2016) and GB1(55) (Olson et al., 2014), characterized by sequence lengths of 4 and 55, respectively; three critical amino acid positions in an iron/a-ketoglutarate-dependent halogenase with sequence length 3 (B\u00fcchler et al., 2022); and Aequorea victoria green-fluorescent protein (GFP) of length 238 (Prasher et al., 1992; Biswas et al., 2021). The former GB1 dataset is fully combinatorial, i.e., covering fitness measurements of 204 variants. Here, each protein site is treated as a player in the GAMEOPT. The latter is non-exhaustive, including only 2-point mutations of GB1. Thus, an MLP having R2 = 0.93 on a test set is trained and treated as the ground truth fitness for the fully combinatorial dataset. For GB1(55), we also consider a modified setup where \u201conly\u201d 10 sites can be mutated. Similarly, Halogenase and GFP are also non-exhaustive involving fitness measurements for 605 and 35, 584 unique variants, respectively. To obtain the complete protein fitness landscape, we once again construct oracles for these datasets, utilizing MLPs achieving R\u00b2 = 0.96 and R2 = 0.90 on their respective test sets. In the case of the Halogenase dataset, each protein site is treated as a player, while for the GFP dataset, 6 and 8 sites are designated as players. Further experimental details are in Appendix D."}, {"title": "Experimental setup", "content": "In all experiments, we use a GP surrogate with an RBF kernel for GP-based methods. The RBF specifies lengthscales for each input variable separately sometimes known as ARD kernels (Rasmussen et al., 2006). To handle categorical inputs to the GP surrogate, we employ feature embeddings as representations for these inputs using the ESM-1v transformer protein language model by (Meier et al., 2021). The prior mean for the GP is pre-defined as the average log fitness value over the whole dataset. Kernel hyperparameters are optimized prior to the start of optimization and remain fixed throughout the BO iterations; specifically, lengthscales are optimized over the training set at the start of each replication using Bayesian evidence, and the outputscale is fixed to the difference between the maximum fitness value observed in the dataset & mean. In other words, we also fit a prior mean. A consistent observation noise of 0.0004 is maintained for each training example. Moreover, we use batch size B = 5. In Appendix D, we provide the (hyper)parameter settings (see Table 1) and the detailed setup for the experiments."}, {"title": "Baselines", "content": "We benchmark GAMEOPT against the following baselines:\n1. GP-UCB (Srinivas et al., 2009) selecting -at each iteration- the best B points in terms of UCB value. Note that this is feasible (though computationally expensive) only for the GB1(4) and Halogenase datasets, while it is prohibitive for GB(55) and GFP\n2. IBR-FITNESS, which mimics directed evolution (Arnold, 1998) through a series of local searches on the fitness landscape, iteratively selecting the B best-responses based on log fitness criterion\n3. PR (Daulton et al., 2022), a state-of-the-art discrete/mixed BO approach picking B points using the expected UCB criterion\n4. RANDOM baseline randomly sampling B random sequences at each iteration.\nFurther details and pseudo codes of such baselines are in Appendix C.\nWe assess our method using two key metrics: convergence speed and sampled batch diversity w.r.t. past, (i.e., the degree of distinctiveness among newly acquired samples in comparison to the original data point particularly in the context of the input space) for BO evaluation. The latter can also be regarded as the measure of exploration. Convergence speed is tracked by the log fitness value of the best-so-far discovered protein variant across BO iterations. We monitor the diversity of the sampled batch concerning the past across BO iterations through (1) the average Hamming distance between the executed variant and the proposed variant from the previous iteration (pairwise distance) and (2) the average Hamming distance of the executed variant from the nearest initial training point.\nIn Appendix E, we provide additional performance metrics such as the fraction of global optima discovered, the fraction of discovered solutions above a fitness threshold, cumulative maximum, and mean pairwise Hamming distances. Moreover, we compare with discrete local search methods (Balandat et al., 2020) and report their respective runtimes."}, {"title": "Results", "content": "GAMEOPT variants, with IBR and HEDGE equilibrium computation subroutines, consistently out-perform baselines across all experiments, discovering higher fitness protein sequences faster (see Figure 2)."}, {"title": "Further discussion and limitations", "content": "In our experiments, we compare to IBR-FITNESS, which simulates currently employed strategies in the iterative protein optimization literature. This is by no means the only methodology applied in this field, and a comprehensive comparison is beyond the scope of this work. Similarly, in our experiments, we use batch size B = 5. While we acknowledge this is a restrictive setup given the technological needs of common screenings, nevertheless, our results should be transferable and applicable irrespective of the batch size which differs to each laboratory setting."}, {"title": "Conclusions", "content": "We introduced GAMEOPT, a novel tractable game-theoretical approach to combinatorial BO that leverages game equilibria of a cooperative game between discrete inputs of a costly-to-evaluate black-box function to tractably optimize the acquisition function over combinatorial and unstructured spaces, and select informative points. Empirical analysis on challenging protein design problems showed that GAMEOPT surpassed baselines in terms of convergence speed, consistently identifying better protein variants more quickly, thereby being more resource-efficient. GAMEOPT is a versatile framework, allowing for exploration with different acquisition functions or mixed equilibrium concepts. As for future work, an adaptive grouping of players and employing joint strategies should be further investigated."}, {"title": "Societal impact statement", "content": "Protein engineering presents vast opportunities, including advancements in healthcare, biotechnology, and environmental sustainability. However, it also entails inherent risks, such as the inadvertent creation of pathogens or other unintended consequences. While our focus in this paper is primarily on the technical aspects of our work, we remain cognizant of the ethical, safety, and regulatory considerations that accompany protein design research."}]}