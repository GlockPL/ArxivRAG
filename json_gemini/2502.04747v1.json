{"title": "Every Software as an Agent: Blueprint and Case Study", "authors": ["Mengwei Xu"], "abstract": "The rise of (multimodal) large language models (LLMs) has shed light on software agent - where software can understand and follow user instructions in natural language. However, existing approaches such as API-based and GUI-based agents are far from satisfactory at accuracy and efficiency aspects. Instead, we advocate to endow LLMs with access to the software internals (source code and runtime context) and the permission to dynamically inject generated code into software for execution. In such a whitebox setting, one may better leverage the software context and the coding ability of LLMs. We then present an overall design architecture and case studies on two popular web-based desktop applications. We also give in-depth discussion of the challenges and future directions. We deem that such a new paradigm has the potential to fundamentally overturn the existing software agent design, and finally creating a digital world in which software can comprehend, operate, collaborate, and even think to meet complex user needs.", "sections": [{"title": "1 Introduction", "content": "The complexity of modern software, such as mobile and desktop applications, often hampers users' ability to interact with these systems efficiently, particularly for individuals with cognitive challenges. This complexity is manifested in the increasing number of features, the density of graphical user interface (GUI) elements within a window, and the depth of action sequences required to complete tasks. Even when users are capable of operating the software, external factors such as driving can restrict their ability to interact with the system.\nTo enhance software accessibility at all times and in any context, various approaches have leveraged machine learning-powered software agents [11]. The ultimate objective is to enable software to understand natural language instructions and perform tasks autonomously, akin to human behavior. This goal has become increasingly viable with the advent of large language models (LLMs), which are adept at natural language understanding, reasoning, and planning. Broadly, there are two primary paths for creating software agents: API-based and GUI-based agents.\nAPI-based agents [19, 4] necessitate that software developers pre-define API functions that map to user instructions. However, this approach suffers from limited scalability and flexibility, making it ill-suited for handling arbitrary user commands, and thus does not lend itself to the creation of a general software agent. On the other hand, GUI-based agents [16, 6, 26] \u2013 by mimicking human understanding and actions on graphical interfaces \u2013 have recently been identified as a promising direction towards more generalized software agents. While multimodal LLMs have shown impressive performance in GUI understanding, the success rate of end-to-end task completion remains low, due to error accumulation across multi-step GUI interactions. Additionally, task completion times are often prolonged by the need for multiple rounds of rendering and LLM invocations.\nBoth approaches, however, assume that LLMs have no access to the software's internal workings. We argue that this assumption presents a fundamental barrier to building a truly powerful, efficient, and general software agent. In response, this work proposes granting LLMs access to the software's internals \u2013 specifically, the complete source code, documentation, and the ability to inject generated code for real-time execution within the software runtime.\nThis paper introduces a novel approach to software-as-agent: just-in-time code generation and in-software execution (denoted as JiT-Codegen). Drawing an analogy to just-in-time (JIT) compilation, JiT-Codegen enables an agent to generate action code that directly interacts with the software's runtime context such as functions, data structures, databases, and UI elements. By providing the agent with full access to the software's source code, the LLM can translate a user's natural language instruction into executable code that operates within the runtime environment. While previous research has explored software functionality understanding through offline self-exploration and leveraging LLMs for runtime software interaction [17, 12, 10], JiT-Codegen represents the first attempt to have an LLM generate and execute code within the software runtime itself. Figure 1 illustrates an example where a JiT-Codegen agent efficiently addresses a complex task involving five GUI interactions with just two lines of code.\nNotably, JiT-Codegen is not mutually exclusive to API-based or GUI-based agents; rather, these approaches can complement one another. For example, JiT-Codegen can be seen as an on-demand API-based solution, where a function is dynamically created at runtime based on the task at hand. This approach prioritizes flexibility over certainty. Furthermore, once a generated action code successfully completes a task, it can be encapsulated into an API for future invocation. Additionally, JiT-Codegen can leverage GUI understanding and manipulation at the code level, recognizing that GUIs are ultimately rendered and controlled through source code (e.g., Android's View and OnClickListener).\nThis paper serves as a blueprint for JiT-Codegen agents, presenting an overall design architecture, case studies utilizing web-based PC applications, and an in-depth discussion of the challenges and future directions. Our long-term vision is to transform all software into agents, creating a multi-agent system in which software works collaboratively to meet user needs in a more intelligent and dynamic a digital world where software comprehends, actions, and cooperates as humans."}, {"title": "2 The Status Quo and Their Inadequacies", "content": "While the efforts to enable natural language communication between users and software date back to the 1960s [8], the recent emergence of large language models (LLMs) has significantly advanced the practical application of this concept. This section provides an overview of the current practice to build software agents.\nAPI-based Approach. The most direct method to facilitate natural language interactions with software is through pre-defined APIs (often referred to as intents), created by developers for key software functions. Prior to the advent of LLMs, classification models were employed to map user instructions to one of several pre-defined API calls, sometimes with associated parameters. The zero-shot language understanding capabilities of LLMs now enable more precise identification of APIs and parameters, as well as dynamic function registration [19, 4]. However, the API-based approach has a notable limitation: it depends on developers to define functions, which restricts its ability to address more general or open-ended user tasks in a dynamic fashion.\nGUI-based Approach. The GUI-based approach mimics human-device interaction by interpreting and manipulating device screen elements or pixels [26], as demonstrated in applications like Claude Computer Use [1] and OpenAI Operator [14]. This approach has garnered significant attention in both academic and industrial circles due to the success of visual language models (VLMs). Unlike the API-based method, the GUI-based approach can, in theory, address any task that users can perform, as both approaches operate at the same granularity (UI elements). Nevertheless, practical challenges remain, such as the inaccuracy of VLMs in grounding complex visual objects. Furthermore, GUI-based operations often involve multiple steps, each requiring screen re-rendering and understanding. Errors accumulating at each step can ultimately lead to task failure.\nGUI-to-API Approach. A hybrid model explores software GUI states offline to extract APIs for online use. Upon receiving a user task, the agent first employs an LLM to map the instruction to the corresponding function, then executes it through the underlying GUI operations. This approach treats GUI operations as function calls. For example, AXIS [12] uses LLM-based agents to explore the software environment via a unified interface to gather runtime knowledge, which is then consolidated into APIs for online invocation. AutoDroid-v2 [17] leverages the coding capabilities of small language models to generate UI operation scripts for online execution. Although this hybrid approach balances ubiquity and efficiency, it is constrained by two primary drawbacks: (1) the need for a cumbersome offline GUI exploration phase, and (2) difficulty in managing tasks with high GUI dynamics.\nAll existing methods are \u201cnon-intrusive\u201d, assuming that the LLM has no access to the software's runtime environment and cannot influence its execution. We deem such an assumption fundamentally constrain the agent's ability to perform complex user tasks. On both desktop and mobile application benchmarks [27, 18, 15], current agents exhibit low task completion rates (typically under 20%)."}, {"title": "3 A Vision of Software Agent", "content": "We propose a fundamentally distinct approach for software agents: just-in-time code generation and in-software execution. As illustrated in Figure 2, a JiT-Codegen-based software agent comprises two core components: an LLM-powered Code Agent, which generates \"action code\" based on user instructions, and an Execution Sandbox, responsible for executing the generated action code within the software's runtime context. A key distinguishing feature of this design, compared to existing code-generation-based agents [17, 10], is that it injects the generated code directly into the software runtime, enabling it to interact with the runtime's rich context to accomplish complex and pervasive tasks. This runtime context includes in-memory data structures, code, open files, databases, and UI elements. The design is inspired by the Linux kernel's eBPF subsystem, which enables user programs to inject code that executes in kernel mode and access certain kernel data structures to a limited extent.\nThe interaction between CodeAgent and Sandbox is bi-directional and iterative. By bi-directional, CodeAgent sends action code to Sandbox for on-demand execution, and in turn, the Sandbox provides valuable feedbacks to the CodeAgent to refine the generated code through multi-step, more precise iterations. This feedback could include error messages from the language runtime (e.g., JVM or JavaScript engine) or execution results that inform subsequent rounds of code generation. The necessity of such multi-round interactions will be demonstrated in Section 5. In essence, the Sandbox functions as an external tool through which the CodeAgent interacts with the runtime.\nJiT-Codegen-based agents assume full access to the software's source code and should be deployed by developers. This is reasonable, as developers have strong incentives to make their software more accessible and \"agentic\" for end-users.\nThe design of CodeAgent is critical to the overall performance of agent. To render the approach practical, it must generate accurate, safe action code in an efficient manner. Accuracy refers to the agent's ability to successfully complete user tasks, while safety ensures that even if the action code fails to accomplish the intended task, it does not cause harmful or irreversible consequences, such as corrupting a local database. Section 5 will delve deeper into these two aspects. Efficiency concerns the time required for the Code Agent to generate action code, ensuring that the user experiences minimal latency. There has been extensive research aimed at improving the efficiency of LLMs and agent systems [20].\nThe design of Sandbox must strike a balance between programming flexibility, safety, and developer efforts. Through the Sandbox, the generated action code needs to access necessary in-memory data structures and functions to accomplish user tasks, either through direct memory access (if both in the same process) or inter-process communications. Simultaneously, the Sandbox must enforce safety constraints on the action code, ensuring that only safe operations are performed by adhering to developer-defined safety rules. To optimize both flexibility and safety, additional effort from developers may be required, such as defining safety rules or exposing IPC mechanisms across processes. The specific implementation of the Sandbox will also depend on the programming language or framework used to develop the software.\nFigure 3 provides a high-level comparison of different types of software agents, treating the software runtime as a state machine. API-based agents directly transits from the beginning state to the completion state, but with some states unreachable (not pre-defined); GUI-based agents can reach a broader set of states through multi-step interactions, where each step leads to an intermediate state. JiT-Codegen-based agents allow direct transitions to any target state, effectively enabling a one-step transition\u00b2. Table 1 further contrasts these agents along multiple dimensions. The advantages of"}, {"title": "4 Case Studies of Desktop Applications", "content": "We have implemented a minimal prototype of JiT-Codegen framework for software built on Elec-tron 3, a web-based, cross-platform development framework for desktop apps. Popular apps built with Electron includes Dropbox, VS Code, Github Desktop, etc. To demonstrate the capability of JiT-Codegen, we use two popular open-sourced apps using Electron: marktext 4 (a markdown editor) and YesPlayMusic 5 (a music player). Both projects receive more than 30K stars in Github and have been widely adored by end users. We used Copilot for the code searching and Claude 3.5/GPT-40/01/01-mini for code generation. To be noted, this is a simplistic, vanilla implementation of JiT-Codegen agents, with less than 200 LoC in JavaScript and 300 LoC in Python. We expect it to be a baseline version for future research, e.g., more powerful models and agentic workflow.\nAs an initial attempt, we selected 5 practical tasks for each app, as shown in Table 2. We tested the implementation on Apple M2 Pro with MacOS version 13.4.1.\n1 // 1st Iteraction (failed): \"TypeError: Cannot read property 'volume'\n= vueInstance.player.volume;\nnewVolume = Math.min(currentVolume + 0.1, 1);\nvueInstance.player.volume = newVolume;\nconsole.log('Volume increased to', newVolume);\n8 let player = (vueInstance.$refs && vueInstance.$refs.player) ?\nvueInstance.$refs.player : vueInstance.player;\n9 if (!player) {\nthrow new Error('Player component not found');\n12 let currentVolume = player.volume;\nnewVolume = Math.min(currentVolume + 0.1, 1);\n14 player.volume = newVolume;\n15 console.log('Volume increased to', newVolume);\n38 let player = vueInstance.player || (window.yesplaymusic && window.\nyesplaymusic.player) || (vueInstance.$store && vueInstance.$store.\nstate && vueInstance.$store.state.player);\n39 if (!player) {\nthrow new Error('Player component not found');\n22 let currentVolume = player.volume;\nlet newVolume = Math.min(currentVolume + 0.1, 1);\nplayer.volume = newVolume;\nconsole.log('Volume increased to', newVolume);\nOverall task completion success rate. Among the 10 tasks tested, GPT 4o successfully solves 8 tasks with 80% task completion ratio. Surprisingly, the reasoning models (01 and 03-mini) solve only 7 tasks, which is likely attributed to the ineffective prompt engineering. Figure 4 compares the output from different LLMs on task \"Create a new tab with contents as the first 3 paragraphs of this file\".\nFeedbacks from execution sandbox helps (sometimes). We observe that sometimes the response from the execution sandbox (error messages) can help the code agent to generate the right code through reflection. An example of 3-round interactions is shown in Listing 1.\nvueInstance.$router.push(\"/library\").then(() => {\n// Select all tabs within the tabs container\nconst tabs = document.querySelectorAll('.tabs .tab');\n// Check if the Play History tab exists\n// (assuming it's the 6th tab, index 5)\nif (tabs.length >= 6) {\ntabs[5].click();\nelse {\nconsole.error(\"Play History tab not found.\");\nAn analysis of failed cases. For most failed cases, we observe \u201csalient failure\", where the action code does not successfully accomplish the user task, neither the execution reports any runtime error. In such cases, the code agent will not continue generating action code, unless the users give extra feedbacks. For examples, all LLMs encounter salient failure when automating \u201cshow my listening history\u201d on the music player. However, we also observe that if we manually keep prompting, the LLM can generate a workable action code eventually, as shown in Listing 2."}, {"title": "5 Challenges and Future Directions", "content": "5.1 Safeguarding against Vulnerable Action Code\nFlexibility comes with cost on safety. As the action code generated is executed in the software runtime context with access to any data in the memory and disk literally, it could do harmful and irreversible damage to the software as well. We discuss a few potential safeguarding techniques here. Notably, the execution sandbox added to software runtime that executes code dynamically downloaded also exposes great security issue which has been characterized by prior work [25].\nAction code sandboxing. One of the most effective ways to prevent unsafe operations is to execute the action code within a restricted environment (sandbox). A sandbox isolates the code from critical system resources (e.g., memory, disk, network), limiting its access to only the necessary parts of the software's runtime. By constraining the execution environment, even if the code is malicious or erroneous, the potential for damage is minimized.\nStatic code analysis and validation. Before executing the action code, the agent could run static analysis tools to inspect the code for potential risks such as unsafe memory access, database modification commands, or network access. The goal is to verify that the code adheres to safe practices and\ndoes not introduce vulnerabilities. For instance, one could check for unauthorized database writes or calls to sensitive system APIs. Take a step further, we can leverage LLM-assisted code verifier, i.e., a \"safeguarding agent\", to check the generated action code independently.\nAudit logs and rollback. Another way is to implement real-time monitoring and logging of all actions performed by the action code. By tracking each execution, any unexpected or dangerous behavior can be identified and flagged for review. Audit logs could also allow for a rollback or undo functionality if something goes wrong during execution, particularly for tasks involving sensitive data like database updates. For tasks that might involve significant risk (e.g., database updates), implement a snapshot or rollback mechanism that saves the state before the code is executed. This allows the system to revert to a known good state if the action produces an unintended or harmful result, reducing the impact of any errors.\nRule-enforced LLM generation. If we can give concrete \"safety rules\" (e.g., no updates to database), we can enforce LLM to generate code that follows such rules. If possible, this approach avoids false action code generation, while static/dynamic approaches only detects error but cannot correct it. Several approaches can potentially achieve such a goal: prompt engineering with safety rule, reinforcement learning with safety rules (RLHF), rule-based post-processing such as filtering, model fine-tuning with safety-focused synthesis data, etc. A more advanced direction would be token-level constrained decoding [2, 3]. Nevertheless, formulating \"safety rules\" for JiT-Codegen would be challenging and often ad-hoc for developers.\nAll of the approaches discussed involve trade-offs between flexibility, safety, ease of development, and runtime efficiency. The most effective solution is likely to combine several of these methods, striking a balance among these factors based on the specific requirements of developers and users.\n5.2 Improving Action Code Accuracy\nIn addition to adopting a more powerful LLM, there have been several potential directions to improve the action code generation accuracy.\nCodebase-specific agent customization. One opportunity is that the codebase of a released software remains mostly static across time, therefore the agent workflow could be fully tuned to it. For example, one can enhance contextual code understanding through codebase preprocessing. Rather than retrieving code snippets blindly, preprocess the source code to index key components like functions, classes, variables, and comments. Indexing could be based on semantic understanding, such as function signatures, docstrings, or frequently used design patterns. This enables more precise retrieval of contextually relevant code for the task. One can also use graph-based representation by treating the software's source code as a graph, where functions and data structures are nodes, and relationships are edges (e.g., function calls or data flow). Use graph structure to retrieve and present the most relevant sections of code based on the user's request, which improves retrieval precision.\nBeyond retrieval, one can use the codebase to customize the LLM weights as well. Through domain-specific fine-tuning the LLM on a dataset of code that reflects the specific codebase, the model better learns nuances, such as preferred coding styles, libraries, and frameworks, resulting in more accurate and contextually appropriate code. The agent can also utilize a few-shot learning approach where the model is given a set of examples that demonstrate how to translate user instructions into specific actions. This could include common tasks for the software (e.g., updating a database, interacting with an API, etc.), allowing the model to generalize better to new instructions.\nAgent-friendly programming language and framework. A more fundamental approach to im-proving the performance of software agents involves redesigning the programming language or framework to enhance its comprehensibility and interpretability by LLMs. Traditional programming languages are often designed for human readability and computational efficiency, but they may not align with the way LLMs process and understand code. By tailoring languages to better suit LLMs' capabilities \u2013 such as adopting more consistent syntax, semantic structures, and modularity \u2013 one could significantly improve code generation accuracy and reduce ambiguity. For example, incorporating natural language-like constructs, well-defined and reusable building blocks, and rich metadata annotations could facilitate more seamless integration between the LLM and the software environment. Moreover, optimizing languages for context-aware code generation, such as ensuring explicit runtime information and variable dependencies are easily accessible, would empower LLMs to produce more contextually relevant and functionally accurate code. This rethinking of program-\nming languages not only promises to enhance LLM performance but could also drive the development of more intuitive, human-computer collaborative programming environments, where natural language commands are more directly translatable into executable code. Notably, such \u201cprogramming for agents\" is fundamentally different from \u201cprogramming agents\" [9].\nAccurate and timely execution feedbacks. As our case study suggests, LLMs can benefit from the feedbacks on the action code execution results (e.g., error messages, task completion or not). However, most unmanaged programming language like C/Rust do not allow catching runtime error, but instead goes to crash directly. In such circumstance, how shall the execution sandbox be designed to balance the usability and safety? Another aspect is on the task completion verification. The easiest way is human-in-the-loop \u2013 asking users to indicate if the task is successfully completed. Would it be possible to ask the code agent to generate another piece of \u201cverification code\" that can check if the action code successfully accomplish the task? This is based on the assumption that generating correct verification code is easier as compared to generating correct action code. We may use two different models (or two fine-tuned variants) to generate two different kinds of code independently.\n5.3 On-Cloud vs On-Devices Codegen\nThere has been growing interest in deploying agents and large language models (LLMs) on local devices, such as smartphones and PCs [22, 24, 23]. For software agents, on-device LLMs can enhance user privacy by eliminating the need to transmit user instructions to a centralized server, thus preventing the potential leakage of sensitive information. Additionally, on-device processing can reduce end-to-end generation latency, improving the overall responsiveness of the system. However, two significant challenges may hinder the widespread adoption of on-device LLMs for code generation. First, the limited code understanding and generation capabilities of small language models [13] restrict their effectiveness in handling complex tasks. Second, on-device code generation requires access to the software's source code, which poses a privacy risk, as this code could potentially be exposed to third parties.\nUnlike large-scale models hosted on powerful servers, on-device models are constrained by factors such as memory, processing power, and energy consumption. These limitations prevent them from comprehensively understanding complex code structures and generating highly accurate action code. Moreover, on-device models may struggle with the context-dependent nature of code generation, where understanding the broader software architecture, interdependencies, and runtime environment is crucial. Potential solutions to this challenge include developing more compact yet efficient LLM architectures that are specifically fine-tuned for on-device applications or making large models afford-able on devices through algorithm-system optimizations [21]. Additionally, the use of specialized models for specific domains (e.g., mobile UI development or database interactions) could improve performance by focusing the model's capabilities on a narrower range of tasks, making it more resource-efficient.\nThe second challenge is the need for on-device code generation to access the software's source code, which raises significant privacy and security concerns. For effective code generation, an LLM needs to understand the structure, logic, and dependencies within the software's source code. However, storing and processing the source code locally on the device exposes it to potential risks, particularly if the device is compromised or if third-party applications gain unauthorized access. This situation is especially critical in scenarios where the software handles sensitive user data, such as in banking or healthcare applications, where privacy and security are paramount. One potential solution is to implement more robust access control mechanisms that limit which parts of the source code are accessible to the on-device agent. For example, source code could be encrypted or obfuscated in a way that allows the LLM to generate code without directly exposing sensitive details.\n5.4 Multi-Software Agent Systems\nOnce every software can talk and action as humans, a digital world can be established where every software agent behaves as an independent entity and communicates with others in natural language. Figure 5 shows an illustrative of how multiple software agents collaboratively solves a user task. Such a system differs from existing multi-agent systems [7] that every software has rich, independent, and dynamic context (e.g., software source code, documentation, and runtime). Accordingly, interesting research questions arise, including but not limited to the followings.\nScaling to a large number of software agents. It is critical to scale up the capability and efficiency of multi-agent system with increased number of software agents involved. Many aspects of research problems need to be addressed. For example, the system must take a proper communication topology, among choices of centralized, decentralized, hierarchical, shared message pool, etc. As the number of agents increases, maintaining performance and responsiveness becomes a challenge. Strategies like load balancing, dynamic agent allocation, and distributed task management can help address these scalability concerns while maintaining efficient resource utilization. Second, software agents may proactively share/transfer knowledge, i.e., when one agent learns or performs a task, the outcome or insight could be transferred to other agents in the system. For example, an agent that performs a software update could pass knowledge about new APIs or changes in the software to other agents, ensuring uniform knowledge across the system. This approach enables scalability and reduces the need for redundant computations. Third, for complex user tasks, how to route the task to the proper software agents (groups) is non-trivial as often multiple software agents can potentially solve the same task. Morever, in a multi-agent environment, failure of one agent should not result in the failure of the entire system. Mechanisms such as agent redundancy, failover protocols, and self-healing systems (where agents can repair or replace faulty agents) could be employed to ensure continuous, reliable operation.\nPermission Control Allowing direct communication and collaboration between software agents introduces significant challenges in permission control, as each agent may have different levels of access to data, functions, and system resources. For instance, a software agent without direct permission to access sensitive data, such as GPS location, could potentially obtain that data through another agent, thereby bypassing established security protocols. This situation resembles permission re-delegation attacks in web browsers and mobile devices, where malicious apps gain unauthorized access by exploiting the permissions granted to other apps [5]. Therefore, implementing effective permission management is essential to ensure that agents operate within the boundaries set by system administrators or users, preventing unauthorized actions and mitigating security risks. Agents must be restricted to only the permissions necessary to perform their tasks, and these restrictions should be dynamically adaptable based on the context of each interaction. Without proper controls, the interactions between agents could lead to privilege escalation, data leakage, or malicious activity.\nHowever, managing permissions in a multi-agent system is inherently complex. Since agents communicate in natural language, the intentions and scope of permissions are often ambiguous and difficult to interpret. Natural language, by its very nature, lacks the precision required for clear-cut permission definitions, leading to the possibility of miscommunication or unintended access."}, {"title": "6 Conclusions", "content": "This paper introduces a novel approach to transforming software into intelligent agents through just-in-time code generation and in-software execution. Unlike traditional API-based or GUI-based agents, which are limited by pre-defined functions or static interaction models, JiT-Codegen empowers software agents with full access to a program's source code and runtime context. By leveraging large language models (LLMs), JiT-Codegen enables dynamic, on-the-fly generation of action code that interacts directly with a software's runtime environment, facilitating seamless and efficient task execution. This work presents a overall design for JiT-Codegen, illustrating its application in web-based PC applications, and demonstrates how it complements existing agent frameworks, enabling a more flexible, scalable, and powerful approach to software automation."}]}