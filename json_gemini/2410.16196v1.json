{"title": "Information for Conversation Generation: Proposals\nUtilising Knowledge Graphs", "authors": ["Alex Clay", "Ernesto Jim\u00e9nez-Ruiz"], "abstract": "LLMs are frequently used tools for conversational generation. Without additional information LLMs can generate\nlower quality responses due to lacking relevant content and hallucinations, as well as the perception of poor\nemotional capability, and an inability to maintain a consistent character. Knowledge graphs are commonly used\nforms of external knowledge and may provide solutions to these challenges. This paper introduces three proposals,\nutilizing knowledge graphs to enhance LLM generation. Firstly, dynamic knowledge graph embeddings and\nrecommendation could allow for the integration of new information and the selection of relevant knowledge\nfor response generation. Secondly, storing entities with emotional values as additional features may provide\nknowledge that is better emotionally aligned with the user input. Thirdly, integrating character information\nthrough narrative bubbles would maintain character consistency, as well as introducing a structure that would\nreadily incorporate new information.", "sections": [{"title": "1. Introduction", "content": "Large Language Models (LLMs) have quickly become the standard for the generation of conversational\nAl responses, due in part to the popularity of ChatGPT. However, without augmentation, LLMs are prone\nto a number of pitfalls, namely that of responses lacking valuable content [1] and hallucinations [2], as\nwell as lack of emotional capability [3], and inconsistent character [4]. External knowledge such as\nknowledge graphs (KG) can be used to improve the first two instances through supplying additional\ninformation, and may be key to resolving the latter two through retrieval augmented generation.\nResponses lacking content and hallucinations are often due to incomplete information, as LLMs use\ninformation stored within their parameters from when they were trained [5]. These challenges would\nstill persist when utilizing static knowledge base, as out of date knowledge is known to contribute to\nhallucinations [2]. Knowledge graphs are able to dynamically add information through the addition of\nnew triples, but require embedding to predict new relationships between existing entities [6]. As such,\nthe adaptation of a knowledge graph embedding (KGE) to readily incorporate new information without\nrequiring retraining would utilize the benefits of both KGs and KGEs, and better address content poor\nresponses and hallucinations. The selection of the information is as crucial as the information itself.\nTherefore, a recommender could utilise the information stored in a KG to determine what would be\nmost relevant to a user input.\nSupplying the emotion through auxiliary information to the LLM at time of generation could provide\na means for emotional integration. By selecting information that is more emotionally aligned with\nthe user input through comparing emotional scores stored as features in the KG, it may be possible to\ngenerate a response that is more emotionally appropriate and increases the users' perception of the\nagent's emotional capability.\nAdditions of character to LLMs often utilize user supplied background information which guides the\ngeneration of character responses.Grounding an LLM with a knowledge base specifically for providing"}, {"title": "2. Proposals for Information for Conversation Generation", "content": null}, {"title": "2.1. New Information Integration and Recommendation", "content": "Active integration of new information in knowledge bases is crucial for maintaining relevant and up-to-\ndate information, and could reduce hallucinations on the part of the LLM [2]. While new information\ncan readily be added to knowledge graphs as they do not require training, the same is not true of\nKGEs, which require training to create embeddings. As language models can neither easily integrate\nnew information or modify their knowledge [10], it is a crucial facet of the external knowledge base.\nTherefore, a Dynamic KGE (DKGE) would be ideal, as DKGEs are KGEs which are able to add new data\ninto the embeddings without requiring retraining of the entire graph [11], and could provide means to\nleverage the additional value of KGEs without the knowledge base being static. This reduces instances\nwhere the LLM lacks the necessary information to generate a correct response and causes frustration to\nthe user [7].\nIn order to utilize the information stored within the DKGE, a recommender could take the user input\nand supply relevant information to the LLM at the time of generation. Knowledge Graph Embeddings\n(KGEs) have been utilised for recommendation in a number of approaches [12, 13, 14], which highlights\nthe feasibility of integrating recommendation with a DKGE.\nIn recommendation, typically there are users and products with the intention of using available\ninformation to recommend the best product to the target user [15]. When a user is previously unknown\nor otherwise lacks interaction and preference information, it is regarded as a cold start problem [16]. To\nutilise this approach for information recommendation, the user input would take the role of an unknown\nuser, for which supporting factual information would be provided instead of a product recommendation.\nThis would be achieved through the use of a link prediction task where utterances and information\nare stored as different entity types in a heterogeneous knowledge graph, and a relation is predicted\nbetween the user input as an utterance type entity to a piece of information.\nFor example, if the user were to initiate a conversation about dinosaurs they might make a statement\nsuch as \"There is evidence the T. Rex may have been as intelligent as a crocodile.\". This statement would\nthen be handled as an entity (kg:utterance1, rdf:type, kg:Utterance) (kg:utterance1,\nkg:text, \"There is evidence the T. Rex may have been as intelligent as a\ncrocodile.\") for which a tail would be predicted for the relation, relevant_to for a piece of\nbackground information. This would ideally return entities like (kg: T. Rex, rdfs:subClassOf,\nkg:CarnivorousDinosaur) which would be given to the LLM as AT. Rex is a carnivorous\ndinosaur for incorporation into an information rich response."}, {"title": "2.2. Emotional Features for Entities", "content": "The display of emotion and emotional understanding are crucial for the success of conversational AI\ndue to their necessity in human conversation [17, 18, 19]. Such cues are often expected by the user [3]\nand can increase the perception of friendliness and intelligence of an AI [20].\nA potential means of integrating emotion into generated text is through influencing the supplemental\ninformation given to the LLM at the time of generation to be more emotionally in line with that of the\nuser. In taking an otherwise purely factual knowledge base and adding emotional values as features\nto the entities prior to training, and to the user input at runtime. Supplying more specificity than\nemotional labels, Valence, Arousal, and Dominance (VAD) scores [21] are commonly used to denote\nemotions as a point in space and could provide rich feature information. A recommendation structure\nbased off of this may yield better supplementary data.\nFor instance, compare the statements \u201cRosalyne is picky\" and \u201cRosalyne is meticulous\". A human\ncan recognise that while the meaning is very similar, meticulous has a positive connotation and picky\ndoes not, however an LLM would not necessarily have a means of differentiating such words without\nemotional delineation. As another example, in a situation without the emotional values, a statement of\n\"The weather is lovely today\" could theoretically return sunny and rainy with equal likelihood. However,\nwith the introduction of an emotion value if the input above was assigned a value closer to that of\npleasant, and with the expectation that sunny would have a closer value to pleasant than rainy, the\nrecommended information would be more pertinent to the conversation.\nThe introduction of the emotional score then not only increases the likelihood of the returned\ninformation being more emotionally similar to the input, but also supplies an additional feature to the\ninput entity which may improve the cold start recommendation."}, {"title": "2.3. Character Dimension Through Experience From Novels", "content": "Companies like Character.AI in industry supply a means by which to add a character atop an LLM\n[22] through character information supplied by the user and likely achieved through a form of prompt\nengineering. These approaches can lead to generic responses that do not integrate relevant character\ninformation [22]. Moreover it is unlikely that the character information prompt is updated during\ninteraction, instead remaining static and relying on further details to be generated in response to user\ninput. This can cause inconsistency and might lead a lengthy conversation to become nonsensical.\nA potential solution is to introduce character information from a structured storage to the LLMs\ngeneration of the conversational agent's responses. Such a method could allow for the incorporation\nof more character information and responses potentially more similar to that of the character. The\nuse of KGs in such a situation would reduce the number of needed tokens for an initial prompt, as\nthe character would not require an initial explicit definition, but rather incorporate relevant character\ninformation as needed throughout the interaction. KGs would also provide consistent information,\nrather then relying on generation to supply details adhoc which may not be retained between responses.\nAdditionally, providing supporting information from an auxiliary knowledge base allows for a larger\namount of character information to be stored and integrated into conversation. A particular attribute of\nKGs that could further improve the quality of responses is the latent information in relations that KGs"}, {"title": "3. Conclusion", "content": "LLMs provide a powerful tool for generating conversational responses, however their responses lack\nvaluable content and hallucinations, as well as lack of emotional capability, and inconsistent character.\nThis paper has introduced proposals for solving these challenges. Firstly, through utilizing dynamic\nknowledge graph embeddings with recommendation to provide up-to-date and relevant information to\nthe LLM at time of generation to improve the content of responses and reduce likelihood of hallucinations.\nAdditionally, using emotional values as features for entities to improve alignment with user input to\nincrease the perception of emotional capability. Finally, the concept of storing character information\nin narrative bubbles was introduced, which could be updated without requiring retraining, to provide\nmeans for the portrayal of richer characters in LLM based conversation generation."}]}