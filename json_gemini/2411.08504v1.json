{"title": "Towards Objective and Unbiased Decision Assessments with LLM-Enhanced Hierarchical Attention Networks", "authors": ["Junhua Liu", "Kwan Hui Lim", "Roy Ka-Wei Lee"], "abstract": "How objective and unbiased are we while making decisions? This work investigates cognitive bias identification in high-stake decision making process by human experts, questioning its effectiveness in real-world settings, such as candidates assessments for university admission. We begin with a statistical analysis assessing correlations among different decision points among in the current process, which discovers discrepancies that imply cognitive bias and inconsistency in decisions. This motivates our exploration of bias-aware AI-augmented workflow that surpass human judgment. We propose BGM-HAN, a hierarchical attention network enhanced by byte-pair encoding, multi-head attention and gated residual connection. Using it as backbone model, we further propose a Shortlist-Analyse-Recommend (SAR) agentic workflow, which simulate real-world decision-making. In our experiments, both the proposed model and the agentic workflow significantly improves on both human judgment and alternative models, validated with real-world data.", "sections": [{"title": "1 Introduction", "content": "Decision making in high-stake scenarios is often done by human experts leveraging their domain expertise and experience to optimize decision quality [1]. However, subjectivity and cognitive biases, such as anchoring bias [12] and confirmation bias [10], are often difficult to detect and avoid [14]. Mitigating decision biases is critical to ensure long-term sustainable outcomes and fairness to stakeholders, especially in high-stakes environments [11].\nIn this regard, this work aims to contribute to AI-augmented, bias-aware decision making in a real world setting, such as university admissions. Current processes involve complex, semi-structured data that requires nuanced assessment across multiple dimensions. Through statistical analysis, we identified non-trivial discrepancies between human evaluations and final outcomes, suggesting inconsistencies and cognitive biases. This motivates our approach, which seeks not only to automate but also to enhance decision consistency and reduce subjective influences through structured Al interventions.\nWe proposed Byte-Pair Encoded Gated Multi-head Hierarchical Attention Network (BGM-HAN), which takes an leverage hierarchical learning approach to better capture and interpret multi-level semi-structured data. Using BGM-HAN as backbone, we introduce a Shortlist-Analyze-Recommend (SAR) agentic workflow to simulate existing human decision processes."}, {"title": "2 Problem Formulation", "content": "In the university admissions scenario, the input space consists of student profiles $P = {p_1, ..., p_n}$, where each profile $p_i$ comprises four key components: GCE A-Level results ($f_{GCEA}$), GCE O-Level results ($f_{GCEO}$), leadership records ($f_{Leadership}$), and Personal Insight Questions responses ($f_{PIQ}$). These components present varying processing challenges. Academic records ($f_{GCEA}, F_{GCEO}$) contain structured grade information that requires normalization across different subjects and years. Leadership records ($f_{Leadership}$) present semi-structured text detailing roles, years, categories, and participation levels. PIQ responses ($f_{PIQ}$) consist of unstructured text requiring sophisticated semantic understanding to evaluate candidates' motivation, challenges, creativity, uniqueness, and institutional fit.\nThe objective is to develop a mapping $D : P \\rightarrow {0, 1}$ that transforms each profile into an admission decision, where 1 represents an offer and 0 represents a rejection. This mapping must optimize for fairness by eliminating cognitive biases, consistency in treating similar profiles, and interpretability in providing transparent decision rationale."}, {"title": "3 Data Analysis", "content": "This section discusses the admission dataset and the statistical analyses performed on the data."}, {"title": "3.1 Dataset", "content": "Our experiments utilize a corpus that consists of real-world university admissions data, with student profiles from the 2024 admission cycle. Each profile in our dataset integrates four key components essential for admission decisions: academic records, leadership experiences, personal insight questions (PIQ), and final admission decisions. The academic records encompass both GCE A-Level (GCEA) and O-Level (GCEO) results. GCEA include elements such as high school, University Admission Score (UAS) and detailed subject grades across H1, H2, and H3 levels, as well as GCE O-Level results, providing a comprehensive view of academic achievement.\nLeadership experiences are documented in a semi-structured format, capturing roles, positions, years of involvement, and participation levels across various categories such as Sports, Performing Arts, and Community Service. The Personal Insight Questions component consists of five essay responses where candidates articulate their motivation for application, describe significant challenges they've overcome, showcase creative achievements, highlight unique qualities, and explain their institutional fit. Each profile is labeled with a binary admission decision indicating whether an offer was made (1) or not (0).\nFor profiles receiving offers, we additionally collect detailed analyses generated by experienced evaluators. These analyses provide structured rationale for decisions, highlighting key strengths and potential concerns in each profile. This analytical component serves dual purposes: providing training data for the Analysis Agent (AA) and establishing a benchmark for evaluating the quality of automated analyses."}, {"title": "3.2 Decisions Correlation Analysis", "content": "While investigating human decision quality in the current admission process. We first study the correlations among difference decision points in the current admission process. The decision points include Shortlisting (SL), Admission Recommendation (AR), Scholarship Recommendation (SR), Degree Offered (DO), Scholarship Offered (SO) and Admission Outcome (Adm). SL provides a preliminary screening process to determine if the students are fit for interview. AR and SR are made based on the findings of structured interviews by the interviewers who are either faculty members or university staffs. DO and SO are the final decision points by a admission committee to decide if the students receive a degree offer and a scholarship offer. The options from each category are ranked into scores and used to calculate the correlation matrix.\nIntuitively, we expect the admission decision (i.e. DO) to adhere to SL and AR, where students who are shortlisted and/or recommended for admission should have a high ratio of receiving degree offers. However, despite the strong correlations between SL and DO (0.67) and between AR and DO (0.62), they are far from perfect correlations of 1.0.\nTherefore, the observation suggests variability in evaluations, which could be influenced by subjectivity and cognitive biases [19]. For instance, interviewers' subjective judgments during AR and SR could be affected by biases such as anchoring, stereotyping, confirmation bias or the halo effect [14], leading to inconsistencies."}, {"title": "4 Methodology", "content": "We propose a novel Byte-pair encoded, Gated residual and Multi-head enhanced Hierarchical Attention Network (BGM-HAN) that serves as the backbone of the $A_S$ and $A_R$ agents (introduced in section 4.2).", "4.1 Enhanced Hierarchical Attention Network": ""}, {"title": "4.1.1 Base Architecture", "content": "BGM-HAN is designed on a base architecture inspired by Hierarchical Attention Network(HAN) [27], which demonstrated proficiency in capturing the latent information of textual data where its structure embeds additional insights. Candidate profiles consist of multi-level textual information in a semi-structured manner. For example, in academic records, subjects and grades form an entry and multiple entries form a field; similarly in leadership records, Activity, Level, Year and Category form an entry, and zero to many entries form a field (refer to section 3 and table 1 for more detail). On the other hand, HAN's dual-level attention mechanisms at both entry and field levels enable the model to focus on the most informative parts of the text across hierarchy. We observe high relevance between neural architecture of HAN and the multi-level semi-structured nature of our data. This capability is particularly crucial for candidates assessments and decision recommendations, where key insights that influence decisions may be dispersed throughout different sections of an applicant's profile.\nBasing on HAN, we further introduce effective enhancements including widely adopted mechanisms such as byte-pair encoding [29], multi-head attention [24] and gated residual connections [22] to improve the network's ability to capture complex patterns in the text. As a result, BGM-HAN allows each agent to process textual data through multiple hierarchical levels."}, {"title": "4.1.2 Byte-Pair Encoding and Embedding", "content": "To effectively handle the diverse and variable-length textual data in student profiles, we employ a two-stage tokenization (Algorithm 1) and embedding (Algorithm 2) process.\nWe choose Byte-Pair Encoding (BPE) as the tokenizer as it shows superior ability in handling out-of-vocabulary issues, which makes it popular among state-of-the-art LLMs, such as the LLaMa3 [9] and GPT-4 [18]. BPE first creates a subword vocabulary of size V = 5000, then iteratively merges the most frequent pairs of symbols in the data, enabling effective representation of both common and rare words while minimizing the out-of-vocabulary problem.\nUsing this learned BPE vocabulary, we then transform each text field into a fixed-dimensional tensor through a hierarchical embedding process described in Algorithm 2. The process maintains the structural hierarchy of the text by operating at sentence and word levels, with dimension constraints (s, w, d) = (10, 50, 768) for maximum sentences, words per sentence, and embedding dimension.\nEach field embedding $E_f \\in R^{s \\times w \\times d}$ is constructed through consistent padding and truncation operations at both word and sentence levels, ensuring uniform tensor dimensions across varying input lengths. This hierarchical representation preserves both local (word-level) and global (sentence-level) semantic information, providing a rich foundation for the subsequent attention mechanisms."}, {"title": "4.1.3 Multi-Head Attention", "content": "We add multi-head attention [24] to capture multiple dependencies and interactions within the text simultaneously, allowing the model to attend to different different positions and capture latent patterns and relationships in the data. The multi-head attention mechanism processes inputs $X \\in R^{l \\times d}$:\n$head_i = Attention(XW_i^Q, XW_i^K, XW_i^V)$\nwith learnable parameters $W_i^Q$, $W_i^K$ $W_i^V \\in R^{d \\times d_k}$, and:\n$Attention(Q, K, V) = softmax(\\frac{Q K^T}{\\sqrt{d_k}}) V$\nThe attention heads' outputs are concatenated and projected:\n$MultiHead(X) = [head_1;...; head_h]W^O$\nwhere $W^O \\in R^{hd_k \\times d}$"}, {"title": "4.1.4 Gated Residual Network", "content": "The gated residual connection is defined as:\n$GRN(X) = LayerNorm(\\gamma \\odot FFN(X) + X)$\nwhere $\\gamma \\in R^d$ is a learnable gate parameter, $\\odot$ denotes element-wise multiplication, and FFN is a feed-forward network:\n$FFN(X) = GELU(XW_1 + b_1)W_2 + b_2$"}, {"title": "4.2 Agentic Workflow", "content": "We propose a Shortlist-Analyze-Recommend agentic workflow $W_{SAR}$ that combines specialized decision agents to automate and enhance the admissions decision-making process. Specifically, the agents are:\n\u2022 Shortlisting Agent ($A_S$): Evaluates each profile to determine if the candidate should be shortlisted for further consideration.\n\u2022 Analysis Agent ($A_A$): Generates detailed analyses for shortlisted candidates, providing interpretative insights into the candidate's profile.\n\u2022 Recommendation Agent ($A_R$): Integrates both the profile and the analysis to make a final recommendation decision.\nEach agent $A_i$ is designed to perform a distinct role within the workflow, leveraging an enhanced Hierarchical Attention Network (HAN) for processing textual data. The enhanced HAN incorporates multi-head attention mechanisms and gated residual connections to improve the representation of textual inputs.\nLet $P = {p_1,..., p_n}$ represent a set of student profiles, where each profile $p_i$ consists of four text fields:\n$p_i = {f_{GCEA}, f_{GCEO}, f_{Leadership}, f_{PIQ}}$\nThe workflow $W_{SAR}$ operates in three main stages, with each stage orchestrated by a specific agent $A_i$:\n(1) Shortlisting Agent ($A_S$): Evaluates each profile $p_i$ to compute a shortlisting probability $P_S(p_i)$. If $P_S(p_i) > \\tau$, the candidate is shortlisted for further consideration.\n(2) Analysis Agent ($A_A$): For shortlisted candidates, generates a detailed analysis $a_i$ using a large language model."}, {"title": "(3) Recommendation Agent ($A_R$)", "content": "Integrates both the profile $p_i$ and the analysis $a_i$ to compute a final recommendation probability $P_r(p_i)$.\nFormally, the agentic workflow can be expressed as:\n$W_{SAR}(p_i) = \\begin{cases}\nA_R(p_i, a_i), & \\text{if } A_S(p_i) > \\tau \\\\\n\\text{Not recommended}, & \\text{otherwise}\n\\end{cases}$\nwhere $a_i = A_A(p_i)$."}, {"title": "4.3 Decision Agents", "content": ""}, {"title": "4.3.1 Shortlisting Agent ($A_S$)", "content": "The Shortlisting Agent $A_S$ processes each profile field $f$ (such as $f_{GCEA}, f_{GCEO}, f_{Leadership}, f_{PIQ}$) to compute a shortlisting probability. Each field $f$ is first encoded into a hierarchical attention embedding, denoted as $h_f$, through the enhanced Hierarchical Attention Network (HAN):\n$h_f = BGM-HAN(f)$\nwhere $h_f \\in R^d$ represents the d-dimensional embedding for field $f$, capturing the multi-level structure of each field.\nThe embeddings are then concatenated and passed into a MLP to calculate the shortlisting probability $P_S(p_i)$:\n$P_S(p_i) = A_S(p_i) = \\sigma (MLP ([h_{GCEA}; h_{GCEO}; h_{Leadership}; h_{PIQ}]))$\nwhere $\\sigma$ is the sigmoid function."}, {"title": "4.3.2 Analysis Agent ($A_A$)", "content": "The Analysis Agent $A_A$ utilizes the Gemini-1.5-Pro-002 large language model to generate detailed analyses for shortlisted candidates during data preparation. Each analysis $a_i$ is generated using a structured prompt with generation parameters $\\theta$ (see Appendix A):\n$a_i = LLM (prompt(p_i); \\theta)$"}, {"title": "4.3.3 Recommendation Agent ($A_R$)", "content": "For shortlisted candidates, the Recommendation Agent $A_R$ incorporates both the profile and the analysis to compute the recommendation probability:\n$P_r(p_i) = A_R(p_i, a_i) = \\sigma (MLP ([h_{profile}; h_{analysis}]))$\nwhere $h_{profile}$ is the combined embedding of the profile fields, and $h_{analysis}$ is the embedding of the analysis text."}, {"title": "4.4 Training", "content": ""}, {"title": "4.4.1 Loss Function", "content": "The agents are trained using a weighted cross-entropy loss to address class imbalance, ensuring appropriate emphasis on minority classes:\n$L = - \\sum_{i=1}^{N} W_{y_i} (y_i log(\\hat{y_i}) + (1 - y_i) log(1 - \\hat{y_i}))$\nwhere $w_{y_i}$ is the class weight for each sample i, defined as:\n$W_{y_i} = \\frac{N}{2N_{y_i}}$\nwith $N_{y_i}$ representing the number of samples in the class of sample i. This weighting approach balances the scale of the loss function to handle class imbalance."}, {"title": "4.4.2 L2 Regularization", "content": "A weight decay factor is added to the loss function to control overfitting and improve generalization. The modified loss function is expressed as:\n$L_{reg} = L + \\lambda \\sum_{i=1}^{|\\Theta|} ||\\theta_i||^2$\nwhere $\\lambda$ is the weight decay parameter and $\\theta_i$ are model parameters."}, {"title": "4.5 Inference", "content": "WSAR processes each profile $p_i$ at inference-time as follows:\nShortlisting: the candidate is shortlisted if $P_S(p_i) = A_S(p_i) > \\tau$.\nAnalysis: the Analysis Agent $a_i = A_A(p_i)$ generates analyses.\nRecommendation: the final recommendation probability is computed as $P_r(p_i) = A_R(p_i, a_i)$.\nAdmission decision $d_i$ is determined by thresholds $\\tau$ and $\\delta$:\n$d_i = \\begin{cases}\n1, & \\text{if } P_S(p_i) > \\tau \\text{ and } P_r(p_i) > \\delta\\\\\n0, & \\text{otherwise}\n\\end{cases}$"}, {"title": "5 Experiments", "content": "We conducted a series of experiments to evaluate the effectiveness of the Agentic Workflow and its constituent Agents. This section details the experimental setup, including the software environment, hardware configuration, and experiment tracking mechanisms."}, {"title": "5.1 Training Settings", "content": ""}, {"title": "5.1.1 Learning Rate Scheduling", "content": "To maintain efficient convergence, we apply a learning rate scheduler that reduces the learning rate by a factor of $\\alpha = 0.1$ when validation accuracy does not improve for k consecutive epochs (patience).\nFormally, the learning rate at epoch t is updated as:\n$\\eta_t = \\eta_{t-1} \\cdot \\alpha \\text{ if no improvement in last k epochs}$\nThe minimum learning rate is constrained to $\\eta_{min} = 10^{-7}$ to avoid premature convergence."}, {"title": "5.1.2 Gradient Clipping", "content": "To prevent exploding gradients, especially in deep networks, we apply gradient clipping with a maximum norm of 1.0, ensuring stability during training:\n$clip(\\nabla L, max\\_norm = 1.0)$"}, {"title": "5.1.3 Early Stopping", "content": "If no improvement in validation accuracy is observed for a maximum of p = 10 epochs, training is terminated early to prevent overfitting."}, {"title": "5.2 Hyperparameter Optimization", "content": "We performed an extensive grid search to optimize the hyperparameters of the BGM-HAN model. The search space encompassed key architectural and training parameters:\nEach configuration was evaluated using early stopping with a patience of 10 epochs to prevent overfitting, with a maximum of 50 epochs per trial. To assess model performance, we use the validation accuracy as the primary metric for selecting the optimal configuration. Gradient clipping is used with a threshold of 1.0 and utilized the AdamW optimizer with a ReduceLROnPlateau scheduler. The optimal hyperparameters were selected based on the highest achieved validation accuracy while considering model stability and convergence characteristics. The optimial set of hyperparameters for BGM-HAN is bolded in the list."}, {"title": "5.3 Data Processing", "content": ""}, {"title": "5.3.1 Analysis Generation", "content": "the Analysis Agent AA generates the analyses $a_i$ for each shortlisted profile using the large language model and a structured prompt (see Appendix A). The generated analyses are stored in the dataset and used as additional input features for the Recommendation Agent Ar."}, {"title": "5.3.2 Handling Missing Data", "content": "Missing values in text fields are replaced with NaN to ensure consistent input dimensions across all samples. This approach avoids introducing biases due to varying input lengths from missing data."}, {"title": "5.3.3 Dataset Splitting", "content": "The dataset is split into training, validation, and test sets with a ratio of 90-5-5 using stratified sampling to maintain class proportions, ensuring balanced evaluation."}, {"title": "5.4 Baseline Models", "content": ""}, {"title": "5.4.1 Traditional Machine Learning Baselines", "content": "Our traditional baselines include XGBoost, which uses concatenated BERT embeddings, and a TF-IDF with logistic regression model that directly processes raw text. These provide a foundational comparison to neural and retrieval-based methods."}, {"title": "5.4.2 Neural Network Models", "content": "Discriminative neural networks such as sequence models [5, 13, 16], attention-based models [25, 27] and pretrained models [6, 15, 17] perform well in many text classification tasks. To benchmark, we evaluate several neural architectures, beginning with an MLP that applies ReLU activation to concatenated BERT embeddings [6]. Next, we assess two bidirectional LSTM (BiLSTM) [16] configurations: one that processes concatenated embeddings and another that treats each text field independently. Lastly, a Hierarchical Attention Network (HAN) [27] model enables adaptive weighting of text fields, allowing the model to emphasize relevant portions of the input."}, {"title": "5.4.3 Retrieval-Based Models", "content": "Basu et al. [4] showed that by breaking down a underlying learning task into local sub-tasks, retrieval-based models with a low complexity parametric component performance well in classification tasks. Motivated by this work, we include the retrieval-based models as baselines using FAISS by Meta Research [7]. We implement FAISS-based k-NN models, using both L2 distance and cosine similarity. Additionally, a category-specific k-NN model performs weighted voting across different text fields, tailoring retrieval to each field's characteristics."}, {"title": "5.4.4 Large Language Models", "content": "Recent LLMs [3, 9, 18] showed superior performance in general natural language understanding and generation tasks. We intend to investigate pretrained LLMs' ability to perform zero-shot and few-shot classification without finetuning. Specifically, we choose the best LLM i.e. GPT-40 [18] in two settings: zero-shot classification and a Retrieval-Augmented Generation (RAG) approach. The former investigates LLM's classification ability by implicit knowledge, while the latter examines the effect of in-context learning on improving classification performance."}, {"title": "5.4.5 Hyperparameters and evaluation metrics", "content": "Each baseline model processes fields including high school grades, middle school grades, leadership records, and self-assessments. The BERT embeddings are generated using bert-base-uncased model with a maximum sequence length of 512 tokens. For neural models, we use the Adam optimizer with a learning rate $2 \\times 10^{-5}$ and train for up to 100 epochs with early stopping triggered by a moderate patience of 10 epochs. Model performance is evaluated using accuracy, precision, recall, F1-score, and confusion matrices, providing a comprehensive assessment of the agents' predictive capabilities and ensuring both high precision and recall."}, {"title": "5.5 Experimental Results", "content": "Table 3 summarises the experimental results across proposed models, human evaluation, and different categories of baseline models. We discuss our observations and interpretation as follows:"}, {"title": "5.5.1 Proposed Models", "content": "BGM-HAN and BGM-HAN-WSAR demonstrate effectiveness in representing hierarchical text features and show the best performance across all metrics. BGM-HAN achieved a macro-averaged F1-score of 0.8453 and accuracy of 0.8506, outperforming all baseline models and approaching human evaluation benchmarks. Enhanced by the proposed agentic workflow, BGM-HAN-WSAR displays the best results among all, achieving an F1-score of 0.8945 and accuracy of 0.8966."}, {"title": "5.5.2 Discriminative Classification", "content": "We observe that both traditional discriminative models, such as XGBoost, and neural networks discriminative models, such as BiLSTM, can perform well in the decision assessment tasks. Specifically, XGBoost achieves an F1-score of 0.7878 and accuracy of 0.7931, whereas BiLSTM-Concat performs 0.8176 in F1-score and 0.8276 in accuracy, despite its simple and small structure relatively to LLMs."}, {"title": "5.5.3 LLMs for Classification", "content": "The performance of GPT-40 in a zero-shot is poor, with an F1-score of 0.4111 and accuracy of 0.5600. The GPT-40 with retrieval augmentation (RA) shows significant improvements, achieving an F1-score of 0.7352 and accuracy of 0.7371. This observation suggests that provding relevant context through RA does effectively enhance the LLM's classification ability. However, both models still under-perform as compared to other discriminative approaches. We believe that without domain-specific fine-tuning, LLMs could not perform effective classification by its pre-trained knowledge."}, {"title": "5.5.4 Retrieval Approach", "content": "Although LLM with RA shows significant improvement to LLM with zero-shot inference, the retrieval-based models perform poorly as compared to all other categories, showing that retrieval alone could not perform well in the classification tasks."}, {"title": "5.6 Ablation Study", "content": ""}, {"title": "5.6.1 Component-wise ablation", "content": "From table 3, we observe that HAN without enhancement has an F1-score and accuracy of 0.7711 and 0.7759 respectively, while our proposed enhancement contributes to 9.6% improvement, bringing the F1-score and accuracy to 0.8453 and 0.8506. Specifically, we observe approximately 1.8% improvement by introducing BPE tokenization, 5.2% by multihead self-attention, and 2.6% improvement by gated residual connections."}, {"title": "5.6.2 Backbone models ablation", "content": "We conduct ablation study on using other baseline models for $A_S$ and $A_R$. The results are summarized in Table 4. We observe that all other approaches, such as traditional classifiers, neural models and retrieval-based models, perform much poorly than the proposed BGM-HAN. As BGM-HAN's performance, i.e., an F1-score of 0.8453 and accuracy of 0.8506, outperforms all alternative backbones by a large margin, showing BGM-HAN as the optimal backbone for this task."}, {"title": "5.6.3 LLMs ablation", "content": "The proposed agentic workflow WSAR uses an LLM to generate analysis of the report. We created analyses for all profiles using base models of Gemini-1.5-pro, Gemini-1.0-pro, GPT-40 and gpt-4-turbo. All versions contribute to around 0.049 to 0.051 improvement in accuracy. We chose Gemini-1.5-pro as base LLM model as its impact is marginally better than the rest."}, {"title": "6 Related Work", "content": "Classification for decision making. High-stakes decision making is often done by human experts [1]. Yang et al. [28] introduced Hierarchical Attention Network (HAN for document classification, effectively utilizing word and sentence-level attention mechanisms to enhance performance. Building upon this, Ribeiro et al. [21] proposed enhancements to HANs through pruning and Sparsemax to improve interpretability and efficiency in text classification tasks. Various neural networks, such as sequence models [5, 13, 16], attention-based models [25, 27] and pretrained models [6, 15, 17], showed promising classification ability. Recent LLMs show superior performance in general tasks [3, 9, 18], which could be further enhanced by retrieval augmentationBasu et al. [4].\nDecision bias. The notion of decision-making bias has been critically examined by [20], who analyzed cognitive biases and their impact on decision-making consistency, highlighting the need for unbiased automated systems in high-stakes environments. Algorithmic bias was identified in the predictions in criminal justice [2, 8]. Several recent work explored AI-based and data-driven methods to mitigate human biases in decision-making processes. Yang and et al. [26] propose a fairness-aware AI system to guide individuals toward unbiased decision-making. Haag et al. [12] proposed and investigated the use explainable AI (XAI) to reduce anchoring bias in consumer decisions. Echterhoff and et al. [10] introduce Bias-Buster, a framework for identifying and addressing cognitive biases in large language models, with applications in high-stakes contexts. Ghai and Mueller [11] present D-BIAS, a human-in-the-loop tool that applies causal analysis to audit and mitigate social biases, emphasizing the importance of interactive AI in tackling algorithmic bias effectively."}, {"title": "7 Impact Statement", "content": "The university admissions process presents a significant challenge, particularly given the exhaustive shortlisting, interview and offer decisions for thousands of candidates each year. Our work investigates the possibility of automating such processes in part of in full, while maintaining or even enhancing decision quality.\nTo ensure practicality and usability of the outcome, the authors work closely with the university admission office throughout the project. All analysis and predictions are based on actual data with anonymization to remove personal identifiable information while retaining its features.\nThis work is being piloted with the university admission team and scheduled to go in production by the first quarter of 2025, for assessing the upcoming applications.\nThe proposed methods in this work can extend to other high-stake scenarios where decision quality are critical. Examples include assessing job applicants for Human Resource departments, vendor selection in Procurement, and loan approval in financial institutions."}, {"title": "8 Conclusion", "content": "This study addresses the significant challenge of enhancing objectivity and consistency in high-stakes decision-making processes, such as university admissions, where biases and subjectivity can negatively impact decision outcomes. We proposed the Byte-Pair Encoded, Gated Multi-head Hierarchical Attention Network (BGM-HAN) model, which leverages a hierarchical learning approach to effectively capture and interpret multi-level semi-structured data. Through an extensive data analysis of existing admission decisions, we identified correlations and discrepancies in human evaluative processes, motivating the development of a more consistent, AI-augmented approach to mitigate biases and subjectivity.\nThe proposed Shortlist-Analyse-Recommend (SAR) agentic workflow combines specialized agents to mimic real-world decision processes while leveraging BGM-HAN as the backbone. Experimentally, the proposed workflow demonstrates superior performance over baseline models, showing over 9.6% improvement in both F1-score and accuracy compared to human evaluators. This agentic approach aligns with related works advocating for fairness-aware Al and transparency in automated decision systems, further demonstrating how explainable AI frameworks can be integrated to address potential biases in high-stakes decisions.\nFuture work may extend to broader applications where decision quality and bias mitigation are critical, such as in HR assessments, financial loan approvals, and vendor selection processes."}, {"title": "A Prompt and Model Configurations", "content": ""}, {"title": "A.1 Prompt", "content": "The following prompt was used to generate the analysis for each candidate:\nYou are an experienced university admission officer. Your task is to analyze and summarise this candidate's profile comprehensively across multiple aspects:\n(1) Academic Strength Assessment:\n(2) Technical Aptitude:\n(3) Leadership & Soft Skills:\n(4) Personal Insight Questions Analysis:\nIn the actual prompt, placeholders such as {GCEA Results}, {GCEO Results}, {Leadership Experience}, and {Personal Insight Questions} are replaced with the candidate's actual data."}, {"title": "A.2 Model Configurations", "content": "We used the gemini-1.5-pro-002 model from Google Generative AI with the following configuration settings:"}]}