{"title": "Medical-GAT: Cancer Document Classification\nLeveraging Graph-Based Residual Network for\nScenarios with Limited Data", "authors": ["Elias Hossain", "Tasfia Nuzhat", "Shamsul Masum", "Shahram Rahimi", "Sudip Mittal", "Noorbakhsh Amiri Golilarz"], "abstract": "Accurate classification of cancer-related medical abstracts is crucial for healthcare management and research. However, obtaining large, labeled datasets in the medical domain is challenging due to privacy concerns and the complexity of detailed clinical data. This scarcity of annotated data impedes the development of effective machine learning models for cancer document classification. To address this challenge, we present a curated dataset of 1,874 biomedical abstracts, categorized into thyroid cancer, colon cancer, lung cancer, and generic topics. Our research focuses on leveraging this dataset to improve classification performance, particularly in data-scarce scenarios. We introduce a Residual Graph Attention Network (R-GAT) with multiple graph attention layers that effectively capture the semantic information and structural relationships within lengthy cancer-related documents. Our R-GAT model is compared with various techniques, including transformer-based models such as Bidirectional Encoder Representations from Transformers (BERT) and the Robustly Optimized BERT Pretraining Approach (ROBERTa), as well as domain-specific transformer models, i.e., Bidirectional Encoder Representations from Transformers for Biomedical Text (BioBERT) and Bio+ClinicalBERT. We also evaluated deep learning-based models (e.g., CNNs, LSTMs) and traditional machine learning models (e.g., Logistic Regression, SVM) for a comprehensive comparison. Additionally, we explore ensemble approaches that combine multiple deep learning models to further enhance classification performance. Various feature extraction methods are assessed, including Term Frequency-Inverse Document Frequency (TF-IDF) with unigrams and bigrams, Word2Vec, and tokenizers from BERT and ROBERTa. The R-GAT model outperforms other techniques, achieving precision, recall, and F1 scores of 0.99, 0.97, and 0.98 for thyroid cancer; 0.96, 0.94, and 0.95 for colon cancer; 0.96, 0.99, and 0.97 for lung cancer; and 0.95, 0.96, and 0.95 for generic topics. Furthermore, the R-GAT model demonstrates better generalizability compared to both machine learning and transformer-based models. The dataset is publicly available at\u00b9.", "sections": [{"title": "I. INTRODUCTION", "content": "Cancer is a major global health issue affecting millions of\npeople annually, with thyroid, colon, and lung cancers being\nthe most prevalent [1]. Patients often experience symptoms\nrelated to the affected organs, such as neck lumps, changes\nin bowel habits, or a chronic cough. Recent data shows a\nsignificant increase in cancer incidence, with 238,000 reported\ncases of thyroid cancer in 2016 rising to 567,000 by 2018 [1].\nThe World Health Organization (WHO) reported in 2020 that\nover 1.9 million people were affected by colorectal cancer,\nresulting in approximately 930,000 deaths [2]. Lung cancer\ndata surpasses other types, with 2,094,000 cases reported in\n2018 [3].\nAs cancer rates rise, efficient documentation and assessment\nmethods become vital. Electronic Health Records (EHRs) have\nemerged as important tools for managing vast amounts of\nmedical data and analyzing trends, which practitioners use for\noptimal patient care. However, EHRs are often unstructured,\nwith missing information and inconsistent formatting, making\nthem challenging for cancer research. Additionally, access\nis restricted due to patient confidentiality, and organizations\noften do not disclose data for research purposes, complicating\nefforts to obtain the large datasets necessary to advance cancer\nresearch.\nGiven these limitations, there is a pressing need for alterna-\ntive data sources to support cancer research. Medical abstracts,\nwhich offer insights from various publications, present a\nvaluable resource. These abundant abstracts provide diverse\nperspectives on cancer types, including \u201cthyroid\u201d, \u201ccolon\u201d, and\n\"lung\" cancers. To address limited data availability, we devel-\noped a dataset of 1,874 biomedical abstracts from PubMed,\ncategorized into \"thyroid cancer\u201d, \u201ccolon cancer\", \"lung can-\ncer\", and \"generic topics\" (not specifically related to cancer).\nThis dataset aims to bridge the gap left by EHR limitations"}, {"title": "II. LITERATURE REVIEW", "content": "and support automated cancer classification systems. Our goal\nis to enhance healthcare systems by providing a well-defined\ndataset that supports research and improves the accuracy of\ncancer document classification, especially where large, labeled\ndatasets are scarce.\nBuilding on this dataset, we implemented the R-GAT to\nclassify cancer types using graph-based approaches. This is\nthe first labeled and well-defined dataset that includes thyroid,\ncolon, and lung cancers in biomedical abstracts. The R-GAT\nmodel was selected because it represents connections between\nentities using graphs, unlike conventional machine learning\nor deep learning methods that treat text as flat sequences. Its\nattention mechanism highlights critical information, allowing\nthe model to gather structural context and improve perfor-\nmance on text analysis tasks. R-GAT is particularly beneficial\nin limited data scenarios, as its ability to utilize structural\nlinks enhances classification performance even with smaller\ndatasets. Incorporating R-GAT into our dataset contributes\nvaluable insights to cancer research and improves cancer\ntreatment effectiveness. The key contributions of this research\nare outlined as follows:\n\u2022 We publicly release a specialized dataset of \u2248 1,874\ncancer-related publications, categorized into thyroid,\ncolon, and lung cancers, which can serve as a key\nresource for targeted healthcare research.\n\u2022 We introduced an enhanced residual graph attention net-\nwork (R-GAT) to improve feature extraction and reduce\ninformation loss in complex cancer records.\n\u2022 We assessed various ML and DL models, including\nensemble and transformer-based approaches, identifying\ntheir limitations and areas for improvement.\nThe rest of the article is structured into four sections. In\nSection II, we provide a literature review. Section III describes\nthe R-GAT model architecture and methodology. Section IV\npresents the study's findings, including analyses and insights.\nFinally, Section V concludes the manuscript.\nThis section provides a literature review of cutting-edge ap-\nproaches used to classify cancers from various text-based data,\nalongside other solutions that support healthcare research.\nNguyen et al. [4] developed a summarization method using\nDutch radiology report data, creating a hybrid model that\ncombines an encoder-decoder language model with an atten-\ntion mechanism and a Breast Imaging-Reporting and Data\nSystem (BI-RADS) score classifier. The model achieved a\nROUGE-L F1-score of 51.5% for Dutch reports. Another\nclassifier reached 83.3% accuracy, surpassing the language\nmodel's 79.1% in BI-RADS classification. Although the model\nperformed well, it was deemed unsuitable for clinical use, and\nNguyen et al. suggested that this hybrid approach could guide\nfuture research efforts.\nTang et al. [5] employed attention-based deep learning\nmodels with BERT to categorize progress notes and extract\nkeywords. Their fine-tuned BERT model with an attention\nlayer achieved 97.6% accuracy, outperforming the baseline.\nThis underscores the effectiveness of hybrid and attention-\nbased models in enhancing clinical data classification and\nsummarization. In another study, Hepsa\u011f et al. [6] compiled\na dataset of 62 mammography records from Turkish patients,\nmanually classified by an expert for breast cancer diagnosis.\nThey applied conventional machine learning models, including\npre-trained BERT and DistilBERT, along with an ensemble\nvoting technique. Their results showed that BERT yielded the\nbest performance on Turkish radiology reports, achieving a\n91% F1-score.\nTurning to the other side, Ai et al. [7] developed the\nEdge-Enhanced Minimum-Margin Graph Attention Network\n(EMGAN) to improve short-text classification by addressing\nfeature sparsity and weak contextual relationships, using a\nHeterogeneous Information Graph (HIG) and a Minimum\nMargin Graph Attention Network (MMGAN). Another study\nby Wei et al. [8] introduced a graph convolutional attention\nnetwork (GCAN) to enhance the prediction of remaining\nuseful life (RUL) in engineered systems. The method uses\ntemporal convolution-aware nested residual connections to\npreserve temporal features, while an attention mechanism\nprioritizes the most relevant features, improving prediction\naccuracy.\nIn addition, Song et al. [9] developed Graph Sequence Pre\nTraining with Transformer (GSPT) for text-attributed graphs\n(TAGS), leveraging large language models (LLMs) to unify\nfeature spaces across different graphs. GSPT emphasizes fea-\nture reconstruction to improve knowledge transferability and\nperformance in node classification and link prediction tasks.\nBesides, Rao et al. [10] proposed a method for knowledge\ngraph completion (KGC) using a Multi-layer Residual Atten-\ntion Network (MRAN), which integrates categorical informa-\ntion with textual descriptions to improve entity embeddings.\nThis approach enhances contextual understanding between en-\ntities and relationships, significantly improving link prediction\nperformance.\nIn the above studies, researchers focused on different\ncancers and clinical note classification using various deep\nlearning or transformer-based approaches. Recent studies have\nalso prioritized capturing semantic information from datasets,\nleading to the growing popularity of graph-based approaches\nin the scientific community. However, multi-cancer types such\nas thyroid, colon, and lung have not been extensively studied,\nand no publicly available datasets exist for their classification.\nAdditionally, biomedical abstract-based text classification has\nreceived less attention, presenting an opportunity for research\nto develop effective solutions that can support healthcare pro-\nfessionals in diagnosing medical diseases or patient treatment.\nFurthermore, while many studies have explored graph-based\ntechniques, the R-GAT model has not yet been utilized in\nprevious research. However, we have addressed these gaps\nby creating our own dataset related to biomedical abstracts,\ncategorizing three types of cancers. We developed a pipeline\nthat allows effective work even with a limited data sample. Our\nfindings and experiments will benefit the research community\nby providing a foundation for extending this research and\ndeveloping solutions to support healthcare research."}, {"title": "III. METHODOLOGY", "content": "This section outlines the classification of medical docu-\nments related to thyroid cancer, colon cancer, lung cancer,\nand generic topics divided into four subsequent phases. In\nthe first phase, medical abstracts related to these cancers\nwere collected from the PubMed database. The second phase\ninvolved text preprocessing, where the raw data underwent\nseveral techniques to produce a high-quality dataset, including\ntokenization, spelling checks, and text normalization, such as\nlemmatization.\nThe third phase included the R-GAT model, which unfolds\nacross four distinct steps. Initially, a graph was constructed to\nrepresent node features and the adjacency matrix in the first\nstep. In the second step, this graph was processed through two\nGraph Attention Network (GAT) layers before entering to the\nResidual Block. The third step introduced a Residual Block,\na crucial component comprising three GAT layers, each with\nits activation function, as depicted in Fig. 1. After that, in\nthe forth step, a Global Average Pooling layer aggregated the\nfeatures.\nUltimately, in the final phase of our workflow, a fully con-\nnected layer was used for classification. Elaborately, the first\ntwo steps are described in IV-A1 and IV-A2, while the\nfollowing subsections will detail phase 3, the R-GAT model,\noutlining its functionalities and mathematical perspective."}, {"title": "A. Graph Construction", "content": "The first step is to create a graph that visually represents\nthe cancer documents and their interconnections. In the node\nfeature representation, each medical text document is assigned\na feature vector to reflect its content. The feature matrix,\ndenoted as $X \\in \\mathbb{R}^{N \\times F}$, represents the document features, with\n$N$ representing the number of nodes in the graph and $F$\nis the number of features per node. An adjacency matrix\n$A \\in \\mathbb{R}^{N \\times N}$ is utilized to represent the relationships between\ndocuments, with $A_{ij}$ denoting the strength of the connection\nbetween document i and document j. The edge weights can be\nacquired through training or determined using domain-specific\nknowledge."}, {"title": "B. Graph Layers with Attention Mechanism", "content": "A key component of our research is the use of the Graph\nAttention Mechanism, which computes attention scores for\nsurrounding documents. The attention scores for a certain\nnode i are calculated as follows: We use Equation 1 to\napply a Leaky Rectified Linear Unit (LeakyReLU) activation\nfunction to the concatenation of linear transformations of the\nfeature vectors of nodes i and j, where nodes i and j feature\nrepresentations are denoted by $h_i$ and $h_j$, respectively; a is a\nlearnable attention weight vector and W is a learnable weight\nmatrix. The (T) represents that vector a is transposed before\nperforming the dot product to ensure appropriate dimension\nalignment for matrix multiplication. In addition, a double\nvertical bar sign denotes concatenation.\n$e_{ij} = LeakyReLU(a \\cdot [Wh_i||Wh_j])$ (1)\nTo obtain attention coefficients, we normalize the attention\nscores using the SoftMax function in Equation 2. In this\nregard, $N(i)$ represents the collection of surrounding nodes\nof node i."}, {"title": "C. Residual Blocks with Graph Attention Layers", "content": "To improve our model and capture complex interactions, we\nuse a Residual Block that combines multiple GAT layers, each\nfollowed by an activation function. The input $h_i$ in Equation\n3 is the result of two previous GAT layers before the Residual\nBlock. Equations 3\u20136 mathematically describe the structure\nof the Block, where A represents the adjacency matrix. \u03a4\u03bf\nbe more precise, $h_{i,1}$ and $h_{i,2}$ represent the outputs of the\nfirst and second GAT layers, respectively; $h_{i,3}$ is the result of\nadding the residual connection shown in (Equation 5). Finally,\n$h'_i$ is the outcome of processing through the third GAT layer\nof the Residual Block.\n$h_{i,1} = GATLayer^1(h_i, A)$ (3)\n$h_{i,2} = GATLayer^2(h_{i,1}, A)$ (4)\n$h_{i,3} = h_i + h_{i,2}(Residual Connection)$ (5)\n$h'_i = GATLayer^3(h_{i,3}, A)$ (6)\nThe use of attention coefficients $a_{ij}$ helps consolidate\ninformation from adjacent nodes, resulting in an improved\nrepresentation for each particular node i.\n$h'_i = \\sum_{j \\in N(i)} a_{ij} Wh_j$ (7)\nSimultaneously, to capture a wide range of patterns con-\ntained in the data, we employ several K independent attention\nheads. Each attention head, K, which operates independently,\ncaptures different aspects of the interactions between nodes\nin the network. These different attention heads increase the\nmodel's ability to focus on diverse patterns at the same\ntime. Also, the non-linear activation function, denoted as $\\sigma$\nfurther contributes to this process by introducing non-linearity,\nallowing the model to learn intricate relationships within data.\n$\\Vert h_i\\Vert = ||\\sigma(\\sum_{j \\in N(i)} \\sum_k^K a_{ij}^{k} W^k h_j)||$ (8)"}, {"title": "D. Global Average Pooling Layer", "content": "The final node representation is created by concatenating\nor averaging the results. Our network uses global average\npooling, which computes the mean feature vector to represent\nthe entire graph. Finally, the average feature vector passes\nthrough a dropout layer and then a fully connected layer,\nfollowed by a SoftMax activation function to forecast the\ncancer document classes. Algorithm 1 is the pseudocode of the\nR-GAT model, which illustrates the major steps and processes\nin the design."}, {"title": "IV. EXPERIMENTAL RESULTS AND DISCUSSIONS", "content": "This section presents and analyzes the results of our ex-\nperiments. We provide a detailed overview of data collection\nand preprocessing, followed by an in-depth explanation of\nthe findings from several machine learning and deep learning\nmodels. We also evaluate the performance of the R-GAT\nmodel, conduct inference tests, compare our findings with\nexisting studies, and discuss the limitations of our study."}, {"title": "A. Experimental Setup", "content": "1) Dataset Collection: We collected 1,874 medical ab-\nstracts on thyroid, colon, and lung cancers, as well as general\ntopics, using the open-source \"Entrezpy\" [11] Python library,\nwhich provides access to PubMed, a major NCBI database\ncontaining a wealth of biological literature. The data collection\ntook place between January and March 2024. We retrieved\nabstracts using specific search terms and keywords such as\n\"thyroid cancer\", \"colon cancer\", \"lung cancer\", and other\ngeneral topics, prioritizing studies from the past five years\nto ensure the dataset's relevance. Inclusion criteria were based\non the abstracts' direct relevance to the specified cancer types.\nWe excluded irrelevant, duplicate, or non-English abstracts, as\nwell as those with insufficient detail. After retrieval and by\nsubject matter experts, the abstracts were manually reviewed\nand categorized into four groups: thyroid, colon, lung, and\ngeneric. The resulting dataset consists of abstracts with an\naverage length of 200 words, encompassing a wide range of\nrecent research articles from various medical journals.\n2) Data Preparation: Before analyzing the data, we\ncleaned it properly to ensure quality, so that it could be\nutilized for various machine learning or deep learning models.\nCleanup steps include detection of missing features, tokeniza-\ntion, lemmatization, handling class imbalance issues, removal\nof redundant words, and vectorization.\nFirstly, missing attributes are often present in the dataset\nbecause the data is collected from various sources and not\nall attribute information is available at the time of collection,\nleading to missing values. Hence, any missing values should be"}, {"title": "B. Result and Discussion", "content": "identified and addressed before using the dataset in a machine\nlearning model. Then, tokenization helps the model capture\nmeaningful information effectively as it breaks down a longer\nparagraph or sentence into smaller parts. We used the Natural\nLanguage Toolkit (NLTK) library for tokenization [12].\nNext, we turn to the process of lemmatization, which is the\nreduction of words to their most basic or original form. By\nconsidering distinct versions of the same word as interchange-\nable, this technique helps models understand the links between\nwords. Furthermore, our dataset had class imbalance problems,\nwhich meant that the data length varied for each class. To suc-\ncessfully address the class imbalance issues, we employed the\nSynthetic Minority Oversampling Technique (SMOTE) [13],\nwhich creates synthetic data samples. Furthermore, we filtered\nout less significant words from our dataset, as not all parts of\na sentence contribute significantly to model training. Lastly,\nwe converted the text data into numerical vectors using a\nvariety of vectorization techniques, including Term Frequency-\nInverse Document Frequency (TF-IDF) [14], Word to Vector\n(Word2Vec) [15], and Bidirectional Encoder Representations\nfrom Transformers (BERT) [16] tokenizer.\n3) Assessment Metrics: We employed several methodolo-\ngies to examine the performance of different models, including\na confusion matrix, precision, recall, and F1-score. These indi-\ncators are extremely useful in understanding actual prediction\nand how models recognize all relevant instances, allowing\nus to receive a balanced assessment of model performance.\nWe analyze multiple models to help everyone understand how\ndifferent models interact while dealing with limited medical\nabstracts. Without adequate validation, we may not acquire full\ninformation about a model. Hence, these indicators allowed us\nto understand better the effectiveness of each model utilized in\nthis study. We provided a detailed explanation of the evaluation\nprocess in IV-B3.\nThis section presents the findings from our experiments and\nthe conclusions drawn from the various models. The classifi-\ncation reports of various machine learning models is explained\nin IV-B1; the performance of deep learning-based models\nis discussed in IV-B2; the assessment of our proposed R-\nGAT model is illustrated in IV-B3; in IV-B4, we demonstrate\nhow the R-GAT model performs when observing unseen data\nthrough an inference test; in IV-B5, we compare the R-GAT\nwith existing studies; and finally, in IV-B6, we highlight the\nlimitations of this research."}, {"title": "1) Classification Report of Traditional Machine Learning\nModels", "content": "Table I presents a classification report for several\nmachine learning models and feature extraction strategies\nacross four classes: thyroid, colon, lung, and generic. The\ntable compares various models, including Decision Tree [17],\nRandom Forest [18], K-Nearest Neighbors [19], Multinomial\nNa\u00efve Bayes [20], Gradient Boosting [21], Adaptive Boosting\n[22], Support Vector Machine [23], Extreme Gradient Boost-\ning (XGBoost) [24], and Logistic Regression [25], based on\nfeature extraction approaches such as TF-IDF (Unigram and"}, {"title": "2) Performance Analysis of Deep Learning Models", "content": "Bigram) [26] and Word2Vec [15]. Taking a closer look at Table\nI, we can observe that Random Forest and Logistic Regression\nperformed well with TF-IDF (Unigram) for classifying the\nthyroid, colon, lung, and generic classes, as demonstrated by\nthe performance metrics. It is also worth noting that TF-\nIDF (Unigram) proved to be suitable across various feature\nextraction approaches.\nTurning to the TF-IDF (Bigram) and Word2Vec techniques,\nwe notice that the K-Nearest Neighbors model performed\ninconsistently. Furthermore, it is also obvious that using\nWord2Vec features significantly reduces the performance of\nMultinomial Na\u00efve Bayes, whereas other models, e.g., De-\ncision Trees and Gradient Boosting models, produce mixed\nresults.\nTable\nII presents an analysis of the performance of various deep\nlearning models on this data set, including Convolutional Neu-\nral Networks (CNN) [27], Recurrent Neural Networks (RNN)\n[28], Long Short-Term Memory Networks (LSTM) [29], Bidi-\nrectional Long Short-Term Memory Networks (BI-LSTM)\n[30], Stacked Long Short-Term Memory Networks (Stacked\nLSTM) [31], Stacked Bidirectional Long Short-Term Memory\nNetworks (Stacked B-LSTM) [32], Hybrid Ensemble Models\n[33], Bidirectional Encoder Representations from Transform-\ners (BERT) [16], Bidirectional Encoder Representations from\nTransformers for Biomedical Text Mining (BioBERT) [34],\nRobustly optimized BERT approach (ROBERTa) [35], and\nClinical BERT for Biomedical Text (Bio+ClinicalBERT) [36],\nusing advanced feature extraction techniques.\nWhen it comes to Keras embedding-based feature extrac-\ntion, models such as CNN, RNN, LSTM, GRU, BI-LSTM,\nstacked LSTM, and stacked Bi-LSTM exhibit balanced per-\nformance, as demonstrated by evaluation metrics (i.e., P, R,\nand F1) across four distinct classes. It is noticeable that\nStacked LSTM performs the worst in the case of the BERT-\nbased tokenizer, although CNN and hybrid ensemble models\noutperform other models by a significant margin.\nFurthermore, comparing the performance of domain-specific\nmodels such as BioBERT, Bio+ClinicalBERT, ROBERTa, and\nBERT, it was found that BioBERT performed best, while the\nBERT model turned out to be overfitted, indicating that it\nwas unable to capture semantic information in cases where\ndata samples are not comprehensive. To further investigate\nthe efficacy, we applied zero-shot training on BERT and\nROBERTa, and we found that they did not capture information\naccurately and lacked generalization. Upon closer inspection,\nthe R-GAT model performs better across all classes and shows\nno signs of overfitting. This is because the model makes\nuse of a graph-based feature representation technique, which\nenables it to better capture more semantic information without\nexperiencing overfitting."}, {"title": "3) Model Assessment and Justification", "content": "In order to have\na better understanding of the efficacy of various machine\nlearning or deep learning-based models, we can refer to the\nconfusion matrix as a performance evaluation technique. To\nput it simply, true positive, false positive, true negative, and\nfalse negative are the four values that comprise its foundation."}, {"title": "5) Comparative Review of Existing Studies", "content": "since we discovered its balanced performance, as evident in\nTable I. Examining Fig. 2, it is evident that the R-GAT model\nproduces good results when correctly identifying the four dis-\ntinct classes (thyroid, colon, lung, and generic) at 94%, 96%,\nand 97%, respectively. We may see some misclassifications\neven if the majority of the records are correctly classified.\nFor instance, 3% of instances of lung cancer are mistakenly\ndiagnosed as thyroid cancer, whereas 4% of cases of colon\ncancer are anticipated to be lung cancer. It is also incorrect\nto classify 4% of cases of thyroid cancer as colon cancer.\nNotwithstanding a few small mistakes, the model performs\nadmirably overall.\nNext, our evaluation shifted towards k-fold cross-validation,\na process where we allocate some data for training and testing\nfrom the same dataset. In the case of the R-GAT model,\nwe applied 5-fold cross-validation, and this process helped\nenhance both performance and generalizability.\nFollowing that, we examine a validation loss graph to\nconfirm the R-GAT model's performance. Looking at Fig.\n3, it reveals that, in 5-fold cross-validation, all folds show\na rapid decline in loss over the first few epochs, indicating\nquick learning. The model has been trained successfully when\nthe validation loss steadies over all folds at roughly 10 epochs\nwith little fluctuations. Based on the consistency of loss across\nfolds, we can denote that the model has excellent capability\nto be generalized on various subsets of data. In addition, as\ntraining advances, the loss approaches zero, suggesting great\nperformance on the validation set with no notable evidence of\noverfitting.\nWhen comparing the outcomes of the various models, it\nis worth noting that some machine learning models, such as\nlogistic regression, exhibited evidence of overfitting. Almost\nall of the traditional machine learning models were overfitted\nto some extent. This happens because these models tend to\nmemorize specific patterns in training data, especially when\nthe sample size is limited.\nDeep learning ensemble models, while more resilient than\nclassic machine learning approaches, were limited in their gen-\neralizability. Ensembles integrate numerous models to increase\nperformance, but we observed that they fail to capture intricate\nrelationships in the case of the limited data samples, and we\nbelieve that this approach did not carefully consider the data's"}, {"title": "4) Inference Testing", "content": "Additionally, examining Table III, it is evident that trans-\nformer based models were employed in the earlier research,\nbut the R-GAT model has not yet been applied to the classi-\nfication of medical cancers. It is also discovered that previous\nstudies were mostly concentrated on the other downstream\nactivities indicated in Table III, and as a result, they did not\naddress thyroid, colon, or lung cancers.\nOur objective was to implement a model capable of ex-\ntracting semantic information from lengthy documents, such\nas medical abstracts related to thyroid, colon, and lung cancers.\nTo validate our R-GAT model, we tested it against sev-\neral transformer-based methods, including BERT, BioBERT,"}, {"title": "5) Comparative Review of Existing Studies", "content": "underlying structure and model architecture as well. While\nensembles can decrease overfitting by averaging predictions\nfrom numerous models, they frequently shortfall attention to\nrelational structures present in more advanced models such as\nR-GAT.\nDomain-specific transformer models, such as BioBERT and\nBio+ClinicalBERT, are specifically designed for biomedical\ntext and benefit from intensive pre-training on relevant collec-\ntions. However, in cases with insufficient data, we found that\nthese models overfit because of their complicated structures\nand huge number of parameters. This intricacy caused the\nmodels to memorize the training data rather than generalize\nproperly, resulting in good performance on the training set but\nlower generalization to new, unseen data.\nOn the other hand, the R-GAT model performs well due\nto its ability to capture semantic relationships within long\nmedical documents using the graph attention technique. This\napproach enables the model to focus on key areas of the\ndata, hence boosting its generalization capabilities, particularly\nin data-scarce settings. The ability to properly use graph-\nbased attention and residual connections is a major reason for\nits excellent performance in both the training and validation\nphases. This, combined with its modest loss fluctuations and\nlow overfitting risk, makes it more generalized than other\nmodels.\nThe predicted results of the R-GAT\nmodel are displayed in Fig. 4. In Fig. 4 (a), we observe\nthe inference result of the R-GAT model, where the output\nclass label is \"Thyroid Cancer,\u201d corresponding to the input\ntext discussing the telomere-telomerase complex in familial\nand sporadic cases. Similarly, in Fig. 4 (b), the R-GAT model\ncategorizes the input text about lung cancer treatments. The\ntext discusses using nitrosoureas, such as BCNU, CCNU, and\nmethyl-CCNU, in combination with other medications to treat\nbronchogenic cancer. It outlines how certain combinations\noutperform standard therapy, particularly in squamous lung"}, {"title": "6) Study Limitations", "content": "data scenarios. To achieve this, we introduced an R-GAT\nmodel for classifying cancer-related abstracts. We validated\nour R-GAT model through rigorous evaluation and found that\nit outperformed conventional machine learning (ML) and deep\nlearning (DL) approaches in terms of generalizability. While\nwe fine-tuned domain-specific transformer models, such as\nBioBERT, ROBERTa, and Bio+ClinicalBERT, their generaliza-\ntion performance was less effective on our curated dataset. Our\nfindings demonstrate that the R-GAT model excels at capturing\nrelationships between aspects in biomedical abstracts, such\nas diseases or treatments, by arranging the data as a graph.\nThis strategy enables the model to take advantage of the cor-\nrelations between these elements, increasing its effectiveness\nin circumstances with limited data. In contrast, transformer\nmodels, e.g., BioBERT, only focus on word order and may not\nfully capture these interactions. Moreover, transformers often\nrequire substantial datasets to function well, and when data\nis limited, they tend to overfit, which lowers their capacity to\ngeneralize to new or unseen data.\nThis study created a dataset and\napplied several models to classify cancers such as thyroid,\ncolon, lung, and generic subjects. Although our study achieved\ninteresting results, it has some shortcomings. First, our dataset\nwas quite small and may not yield comprehensive patterns;\nTherefore, given a complex medical abstract to classify, the\nmodels may not generalize accurately.\nSecond, our dataset contains abstracts related to specific\ntypes of cancer. Each abstract focuses only on its designated\ntopic, so there is no overlap with other cancer types or\nunrelated topics. This means that the dataset may not capture\nvariations that may arise from abstracts discussing multiple\nsubjects or cancer types, potentially affecting the robustness\nof the data. Additionally, subject matter experts have not\nevaluated the effectiveness of the presented model in any\npractical setting.\nRegarding model constraints, we introduced the R-GAT\nmodel, a graph-based approach. Although this method can\nbe effective with limited data, its generalizability may be\nlimited by the nature of the data used for training. As a\nresult, we cannot confidently conclude that this model is robust\nto different scenarios. Therefore, in future works, we plan\nto address these limitations by including a larger and more\ndiverse dataset and evaluating our R-GAT model in real-world\nsettings."}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "In future research, we aim to integrate the relational rea-\nsoning of R-GAT with the deep contextual understanding of\ndomain-specific transformer models like BioBERT, ROBERTa,\nor Bio+ClinicalBERT. We envision developing a hybrid en-\nsemble model that better captures the semantic informa-\ntion from the dataset and potentially improves performance.\nAdditionally, we will look into approaches to improve the\ngeneralization capabilities of transformer-based models when\nused with our curated dataset.\nThis paper presents the first labeled dataset of biomedical\nabstracts related to cancers such as thyroid, colon, and lung,\nas well as more generic topics. The goal of this study was to\nassess the effectiveness of state-of-the-art methods in limited"}, {"title": "DECLARATION OF COMPETING INTEREST", "content": "The authors declare that the research was conducted in the\nabsence of any commercial or financial relationships that could\nbe construed as a potential conflict of interest."}]}