{"title": "PRECISE: Pre-training Sequential Recommenders with Collaborative and Semantic Information", "authors": ["Chonggang Song", "Chunxu Shen", "Hao Gu", "Yaoming Wu", "Lingling Yi", "Jie Wen", "Chuan Chen"], "abstract": "Real-world recommendation systems commonly offer diverse content scenarios for users to interact with. Considering the enormous number of users in industrial platforms, it is infeasible to utilize a single unified recommendation model to meet the requirements of all scenarios. Usually, separate recommendation pipelines are established for each distinct scenario. This practice leads to challenges in comprehensively grasping users' interests. Recent research endeavors have been made to tackle this problem by pre-training models to encapsulate the overall interests of users. Traditional pre-trained recommendation models mainly capture user interests by leveraging collaborative signals. Nevertheless, a prevalent drawback of these systems is their incapacity to handle long-tail items and cold-start scenarios. With the recent advent of large language models (LLMs), there has been a significant increase in research efforts focused on exploiting LLMs to extract semantic information for users and items. However, text-based recommendations highly rely on elaborate feature engineering and frequently fail to capture collaborative similarities.\nTo overcome these limitations, we propose a novel pre-training framework for sequential recommendation, termed PRECISE. This framework combines collaborative signals with semantic information. Moreover, PRECISE employs a learning framework that initially models users' comprehensive interests across all recommendation scenarios and subsequently concentrates on the specific interests of target-scene behaviors. We demonstrate that PRECISE precisely captures the entire range of user interests and effectively transfers them to the target interests. Additionally, we introduce practical training strategies that enhance the model's performance in real-world applications. Empirical findings reveal that the PRECISE framework attains outstanding performance on both public and industrial datasets. PRECISE has been deployed in multiple online recommendation scenarios within WeChat, and online A/B tests demonstrate substantial improvements in core business metrics.", "sections": [{"title": "I. INTRODUCTION", "content": "In online recommendation systems, diverse recommendation scenarios are often encountered. For instance, within the WeChat 1 ecosystem, users can consume multiple types of content as illustrated in Figure 1. Users can view short videos in Channels, watch live shows in Live, enjoy music in Listen, read articles in Top Stories and engage with games in Games. Capturing user behaviors across the entire platform could"}, {"title": "II. RELATED WORK", "content": "In this section, we introduce studies on pre-training recommendation models as well as recent works that adopt LLMs for recommendation."}, {"title": "A. Pre-training in Recommendation", "content": "Recently, pre-trained models have achieved significant success in the field of Natural Language Processing (NLP). The predominant approach involves pre-training models on large-scale datasets followed by fine-tuning on the target domain datasets, such as BERT [21] and LEGAL-BERT [22]. Research in recommendation systems has also sought to harness the power of the pre-training paradigm to capture users' long-term and cross-scene interests.\nPre-training recommendation models often unfold in two distinct manners. The first type of approach utilizes multi-modal information for pre-training [2], [4], [8], [23]\u2013[27]. Hou et. al. [23] and Yang et. al. [25] construct text-based attributes to represent item features and use behavioral sequences to align semantic representation with behavioral interest. Li et. al. [24] and Zhang et. al. [24] construct advanced"}, {"title": "B. LLMs for Recommendation", "content": "With the huge success of LLMs, many researchers have endeavored to integrate the capabilities of LLMs into their recommendation models. The first type of study involves transforming user behaviors into natural language descriptions and employing prompt-tuning to enable the LLMs to directly infer subsequent recommendation outcomes [17], [32]. Liao et. al. [17] employ a projector to align ID embeddings with the LLM's input space and adopt a curriculum learning strategy to progressively guide the learning of LLM. Ning et. al. [32] integrate pre-trained user embeddings with LLMs with cross-attention, enabling LLMs to generate responses based on the context of a user's past behaviors. These methodologies neces-"}, {"title": "III. PRELIMINARY", "content": "Assume we have a set of users $u \\in U$ and a set of items $i \\in I$, u and i represent user and item IDs respectively. For each user u, $S_u = [i_{u,1}, i_{u,2},..., i_{u,n}]$ denotes the sequence of historical interacted items in chronological order, where $n = |S_u|$ indicates the number of interacted items. For each item i, $T_i = [t_{i,1},t_{i,2},..., t_{i,m}]$ denotes the text tokens of item i in its description, where $m = |T_i|$ is the length of items' maximum token length. For article i, $T_i$ can be extracted from article titles and texts. For a short video i, $T_i$ can be retrieved from video titles and hashtags. For live show i, $T_i$ represents show titles and texts recognized from speech."}, {"title": "IV. METHODOLOGY", "content": "In this section, we first introduce the overall framework of PRECISE and then elaborate on each module in detail. Lastly, we discuss practical training strategies for achieving optimal results in real-world recommendation systems."}, {"title": "A. Overall Framework", "content": "In this paper, we propose a pre-training framework for sequential recommendation named PRECISE. The overall framework is depicted in Figure 2. As shown in the figure, PRECISE consists of three modules. In the Embedding Fusion module, we generate item embeddings for each item in a user's behavior sequence. We employ an embedding module to obtain the ID embeddings, concurrently utilizing a Large Language Model (LLM) to generate token representation to initialize token embeddings. Note that both ID embedding and token are trainable variables in our framework. Subsequently, a Mixture of Experts (MoE) network is applied to distill the token embeddings into semantic representation, which is further concatenated with ID embedding to form the final item"}, {"title": "B. Embedding Fusion Module", "content": "In the context of sequential recommendation, the representation of sequences as a series of embeddings allows for the modeling of complex user-item interactions. The Embedding Fusion module takes in the interacted items of user u, which are placed in chronological order. It constructs the embedding matrix $E_u$ where each row corresponds to the embedding $e_i$ of an item i, as shown in Figure 2."}, {"title": "C. Universal Training Module", "content": "In the Universal Training module, we train a decoder-only Transformer model to represent the all-scene behavior sequences. Transformer architecture has emerged as a powerful model design in the domain of sequential recommendation [33], [34]. Each Transformer layer is composed of a Masked Multi-head Self-attention module (MMS) and a Feed-forward Network (FFN). The implementation details of the Transformer module can be found in [33]. Masked Multi-head Self-attention module employs a masking matrix for modeling item correlations in sequences. The lower triangular part of the masking matrix is set to 0 and the remaining part -$\\inf$, allowing each item to attend to past items, but preventing"}, {"title": "D. Targeted Training Module", "content": "In the Targeted Training module, we use target-scene behavior sequences to train a Transformer model $f_{TT}$. Firstly, we warm-start all parameters in $f_{TT}$ from the Transformer model $f_{UT}$ in Universal Training module. Subsequently, the model parameters are trained from behavioral data specific to particular scenarios or tasks. Since Universal Training utilizes behaviors from all scenarios, the parameters from Universal Training can be adapted to many Targeted Training models where each model corresponds to a distinct scenario as illustrated in Figure 3.\nTo better accommodate the recommendation task, we have made two modifications in model training. Firstly, when computing the attention weights between items in behavior sequences, we have adopted bi-directional attention for all"}, {"title": "E. Discussion on Training Strategies", "content": "In this section, we elucidate the challenges and issues encountered during the training process of models along with our solutions."}, {"title": "1) Periodical Warm-up:", "content": "In large language models, the pre-training process is conducted on a vast corpus, while fine-tuning focuses on corpora from a specific domain. This approach is applicable when the total number of tokens remains constant. However, in recommendation scenarios, new items are produced every minute. If the Targeted Training module warm-start the parameters from the Universal Training model only at the starting point of model training, items produced after the starting point will not have been trained by the Universal Training module. We illustrate this issue with Figure 4a. Assume that we start Targeted Training on Day 1 and do not warm up the parameters with the Universal Training model afterwards, the proportion of exposed items trained with all-scene behaviors decrease significantly each day. However, if we periodically warm up the parameters with Universal Training model, the proportion of pre-trained items remains above 70%. As we show in experiments, Universal Training is critical in improving the recommendation performance and hence we periodically warm up the Targeted Training model with parameters from the Universal Training model. The specific warm-up cycle can be determined based on the iteration rate of new items on specific recommendation platforms."}, {"title": "2) Alternate Training:", "content": "One important innovation of this work is the combination of item ID representations with item text representations. During model training, we observe that since text representations are derived from well-trained large language models, the model training heavily relies on semantic embeddings, leading to insufficient training of ID representations. We illustrate this issue with Figure 4b. We sample item-pairs < i,j > that are considered similar to each other given their overall item embeddings < $e_i$, $e_j$ >. Afterwards, We specifically compute the cosine similarity of < i,j > with their ID embeddings. The blue line represents the similarity distribution of ID embeddings trained along with token embedding while the orange line represents the similarity distribution of ID embeddings trained with token embedding fixed. As we can see in Figure 4b, when ID embeddings are trained without token embeddings held constant, the cosine similarity remains approximately around 0.55. This value is noteworthy as it is only slightly higher than"}, {"title": "V. OFFLINE EXPERIMENTS", "content": "In this section, we conduct experimental studies on offline datasets to verify PRECISE's effectiveness and scalability, followed by ablation studies to validate the contribution of each component in PRECISE."}, {"title": "A. Experimental Setup", "content": "Datasets. We use two datasets for offline experiments. The first dataset is the Amazon book review dataset\u00b2 which consists of users' reviews on purchased books. These reviews span from a low of 1 to a high of 5, with 1 representing minimal interest and 5 indicating considerable enthusiasm. We regard the reviews with scores of 3 or above classified as positive feedback. We adopt the 'leave-one-out' strategy for testing and only collect users' purchased sequence of no less than 3 items as our training examples. Notably, to ensure comparability with ID-centric approaches, our testing dataset includes only items that have been previously presented in the training dataset. Item representation is accomplished by incorporating the book title, description, and categories as textual elements."}, {"title": "B. Overall Performance", "content": "Table III shows the performance of PRECISE-UT compared with all SOTA methods in both academic and industrial datasets. As we can see, PRECISE-UT outperforms all baseline methods in both Amazon and WeChat-AllScene datasets. This is because PRECISE-UT combines both ID and text token embedding to enhance item representation while baseline approaches either utilize ID embedding or text embedding alone, leaving their combination unexplored. We also notice that the HLLM model is a strong baseline model, indicating that items can be effectively represented by text. However, LEARN performs poorly, which is attributed to the fact that it employs fixed token embeddings, leaving the token embedding and LLM parameters untrained. However, both HLLM and PRECISE permit updates to the token embeddings, thereby enabling more profound adaptation to parameters induced by collaborative signals. In the context of pure ID models, HSTU demonstrates a superior performance over SAS-Rec due to its improvements in attention mechanism to fit recommendation task. However, neither SAS-Rec nor HSTU gives the"}, {"title": "C. Ablation Studies of Inputs", "content": "As discussed above, PRECISE-UT outperforms baseline methods based on its utilization of ID and text information. Next, we perform ablation studies of ID and text embedding, as well as the MoE network for combining token embeddings. In PRECISE-ID, we remove the LLM module and only use ID for embedding module. Note that PRECISE-ID is similar to SAS-Rec. In PRECISE-LLM, we remove the ID embedding module and only use LLM encoding for semantic representation. In PRECISE-Pool, we use average pooling to combine token embeddings of an item without the adaptation of MoE layers. Note that the modified models are based on and compared with PRECISE-UT model. We report the results using the WeChat-AllScene dataset in Table VI."}, {"title": "D. Scalability", "content": "In this section, we attempt to study the scalability of the PRECISE-UT model in different directions, i.e. training data and model parameters. The scale of the dataset in training language models considers the amount of textual sentences. In our experiment, we vary the length of the behavior sequence from 100 to 500 as longer sequences bring in more training samples in the Next-item Prediction task. The scale of parameters comes in twofold in this paper. Firstly, the LLM model that generates the token embedding determines the quality of semantic representation. As reported in many studies, the scale of LLM model parameters largely determines the quality of LLM's output. We evaluate PRECISE-UT given different scales of LLM models. Secondly, the scale of transformer layer parameters is another determining factor in PRECISE-UT. We report the performance of PRECISE given different number of layers of transformer blocks. The results are reported with the industrial dataset WeChat-AllScene in Table V."}, {"title": "E. Effectiveness of Framework", "content": "In this section, we discuss the effectiveness of our designed progressive training framework, which increments from Universal Training to Targeted Training. We use WeChat-Click and WeChat-Share for targeted training for two tasks, i.e. clicking and the sharing respectively. WeChat-click collects users' clicking behaviors in a specific scenario and the clicking task is used to test PRECISE's ability to transform from all-scene click behaviors to target-scene behaviors. WeChat-share consists of sharing behaviors from all scenarios and the sharing task is used to test PRECISE's transferability in cross-task situations. We compare PRECISE with models that only utilize Universal Training (PRECISE-UT) and models that only utilize Targeted Training (PRECISE-TT)."}, {"title": "VI. ONLINE EXPERIMENTS", "content": "We apply PRECISE in article recommendation services in WeChat. In this section, we present the strategies employed for deploying our pre-trained embeddings into online services in detail, along with an analysis of the online performance achieved in recall and ranking."}, {"title": "A. Training and Prediction", "content": "WeChat, being a major platform where users can publish original articles, offers multiple channels for article viewing. These include the Subscription Channel (showing only subscribed accounts' articles), Friend Circle (displaying only friends' shared articles), and Recommendation Box (employing a recommendation system).\nFor Universal Training, user behaviors from March 2023 to November 2024 across all these scenarios are collected to form the training data. For Targeted Training, two tasks are considered: clicking and sharing. Clicking behaviors in the Recommendation Box are used for the clicking task's Targeted Training, while sharing behaviors from all scenes are used for the sharing task's Targeted Training.\nThe training process is illustrated in Figure 5. The Universal Training model is trained daily. Subsequently, the Targeted Training model loads the parameters from the Universal Training model and incrementally trains for the target tasks. The training strategies introduced in Section IV-E are utilized.\nDuring the prediction phase, due to the large number of users, full-scale predictions for users are performed daily. The prediction model loads the latest checkpoint from the Targeted Training model each day for user embedding prediction. For"}, {"title": "B. Online Serving in Recall", "content": "Leveraging the embedding server and similarity server [39], PRECISE's serving in the recall phase has two paradigms: User - Item (U2I) recall and User - Item - Item (U2I2I) recall. Figure 6 shows the details. In U2I recall, the user embedding is retrieved from the user embedding server using the user's ID as the query key. Then, it is input to the similarity server to obtain the item IDs with the least cosine distance in embedding. For U2I2I recall, users' interacted item sequences are first retrieved based on the target task. That is, for the clicking task, users' recently clicked items are retrieved, and for the sharing task, users' recently shared items are retrieved. Then, these items' pre-trained embeddings are retrieved from the item embedding server. These item embeddings are input to the similarity server to obtain the most similar items as recall results.\nBoth U2I and U2I2I recall paradigms are deployed in the Article Recommendation task. The pre-trained embedding-based recall is augmented for two types of user populations: the entire user base and cold-start users. The baseline group"}, {"title": "C. Online Serving in Ranking", "content": "In the online ranking phase, we adopt pre-trained user and item embeddings as features to enhance the performance of the ranking model. In a typical recommendation system's ranking model, the discrete features of users and items are first embedded through an embedding layer and then input into a Deep & Cross Network (DCN) architecture for feature interaction [42]. Eventually, they are fed into the output layers to obtain the ranking results. To incorporate the pre-trained embeddings, we perform two operations as shown in Figure 7: 1) we concatenate the pre-trained embeddings with the output of the ranking model's embedding layer. The concatenated embedding is further fed into the DCN network for feature crossing. 2) we compute the dot product of the user and item embeddings and concatenate the resulting score with the output embedding from the ranking model's DCN module. Through these operations, the ranking model can treat the pre-trained embeddings as feature inputs and utilize the pre-trained scores to evaluate the similarity between users and items."}, {"title": "VII. CONCLUSION", "content": "In this paper, we propose PRECISE, a sequence recommendation pre-training framework. PRECISE adopts an MoE structure to effectively combine token embeddings from LLMs. The combined embeddings are further concatenated with ID embedding for integrating semantic information with collaborative behavior. Subsequently, through a Universal Training plus Targeted Training paradigm that transitions from a holistic scenario to a target scenario or task, we model the comprehensive behavior of users and rapidly adapt to target interests. We have achieved superior performance compared to state-of-the-art solutions on both public and industrial datasets. Most importantly, our model framework has been fully deployed online and has yielded significant benefits. Future work includes research methods for faster convergence of Targeted Training models. Additionally, the application of pre-trained embeddings in industrial recommendation systems is worth exploring. This will help to further improve the performance and applicability of PRECISE in real-world scenarios."}], "equations": ["\\arg \\max_{i \\Xi I} P(i_{u,n+1} = i|S_u)", "x_i = LLM(T_i)", "gate(x_i) = softmax(topk(x_i \\cdot W_{gate}))", "e_i = ID(i)+MoE(x_i) = ID(i)+(\\sum_{j=1}^{K} gate(x_i)_j \\cdot Attn_j(x_i))", "h^0 = E_u", "h^l = TransformerBlock(h^{l-1})", "h_u = h_{u,n}^H = f_{UT}(E_u|\\theta_{UT})[n]", "L_{nip} = -\\sum_{u\\in U, i\\in S_u} \\log (\\sigma(h_{u,i}^H \\cdot e_{i+1})) + \\sum_{j\\in N_u, j \\neq i+1} \\log (1 - \\sigma(h_{u,i}^H \\cdot e_{j}))", "L_{bpr} = - \\sum_{u\\in U} \\sum_{u' \\in U, u' \\neq u} \\log (\\sigma(h_u \\cdot e_{u,n+1} - h_{u'} \\cdot e_{u,n+1}))"]}