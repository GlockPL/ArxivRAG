{"title": "Autonomous Deep Agent", "authors": ["Amy Yu", "Erik Lebedev", "Lincoln Everett", "Xiaoxin Chen", "Terry Chen"], "abstract": "This technical brief introduces Deep Agent, an advanced autonomous AI system designed to manage complex multi-phase tasks through a novel hierarchical task management architecture. The system's foundation is built on our Hierarchical Task DAG (HTDAG) framework, which dynamically decomposes high-level objectives into manageable sub-tasks while rigorously maintaining dependencies and execution coherence. Deep Agent advances beyond traditional agent systems through three key innovations: First, it implements a recursive two-stage planner-executor architecture that enables continuous task refinement and adaptation as circumstances change. Second, it features an Autonomous API & Tool Creation (AATC) system that automatically generates reusable components from UI interactions, substantially reducing operational costs for similar tasks. Third, it incorporates Prompt Tweaking Engine and Autonomous Prompt Feedback Learning components that optimize Large Language Model prompts for specific scenarios, enhancing both inference accuracy and operational stability. These components are integrated to form a service infrastructure that manages user contexts, handles complex task dependencies, and orchestrates end-to-end agentic workflow execution. Through this sophisticated architecture, Deep Agent establishes a novel paradigm in self-governing AI systems, demonstrating robust capability to independently handle intricate, multi-step tasks while maintaining consistent efficiency and reliability through continuous self-optimization.", "sections": [{"title": "Introduction", "content": "Modern artificial intelligence systems increasingly confront complex, multi-phase tasks that demand the orchestration of business workflows, in-depth analyses, and changing demands and contexts. These complex tasks feature dynamic dependencies where subsequent steps could rely on earlier outcomes, with requirements that evolve in real time. As the Large Language Models (LLM) become more powerful, we witness a decisive shift from single-step AI solutions toward autonomous deep agents capable of planning, executing, and adapting throughout entire processes (Masterman et al., 2024). The most recent advances include OpenAI's DeepResearch (OpenAI, 2025a) and Operator (OpenAI, 2025b). Through the integration of multi-step logical reasoning, external memory architectures, and sophisticated tool utilization capabilities, the next generation of AI agents is positioned to revolutionize end-to-end process automation (Metz, 2025). This evolution toward autonomous agents that can reason and act on behalf of users-managing task coordination, handling complex dependencies, and responding to new information-represents a significant frontier in AI capabilities.\nIn this technical brief, we introduce Deep Agent, our novel LLM-driven AI framework designed to address these challenges and advance autonomous task execution and management.\nDeep Agent models complex tasks using a Hierarchical Task DAG (HTDAG), which recursively represents sub-tasks and their dependencies across multiple layers of a Directed Acyclic Graph (DAG). This DAG-based design enables a dynamic decomposition of high-level goals into a network of interrelated sub-tasks (nodes in the graph), with directed edges capturing their dependencies and constraints. Unlike static workflows, our HTDAG facilitates dynamic task management, allowing for the expansion of nodes into finer-grained sub-tasks as needed and modification of the graph in real time as new information becomes available or objectives change. DAG naturally supports user chiming in anytime to pause, terminate, resume or adjust the task, such as \"let me review first after you found the recipes\". This ensures flexibility and effectiveness in environments with evolving requirements or un-"}, {"title": "Framework Design", "content": "2.1 Hierarchical Task DAG\nOur framework employs a Hierarchical Task DAG (HTDAG) to model complex task workflows and their dependencies. While DAGs have long been utilized in computer science for task scheduling and dependency management, our hierarchical adaptation provides unique advantages for autonomous agent systems. Figure 1 presents a high-level overview of Deep Agent, highlighting HTDAG as the principal component, while Figure 2 illustrates our two-stage planner-executor architecture for each node.\nHTDAG in general operates through a recursive two-stage planner-executor cycles for each break down, as demonstrated in Figure 2. The planner component dynamically constructs a next-level sub-task DAG given all available information at the mo-"}, {"title": "Auto API & Tool Creation", "content": "Deep Agent incorporates a novel component for Autonomous API & Tool Creation (AATC). Unlike traditional LLM-driven systems that rely only on pre-defined API/tool sets, our framework can autonomously analyze, design, and build new reusable APIs and tools on top of UI interactions, and existing APIs & tools). Once created, these APIs and tools become part of the system's permanent capabilities, significantly reducing the marginal cost of handling similar tasks by eliminating the need for repeated LLM inference on the UI interaction flow again.\nThe AATC leverages the core Deep Agent frame-work with specialized prompting for API and tool"}, {"title": "Prompt Tweaking Engine", "content": "A significant challenge in developing generic AI agents is balancing prompt design between generality and specificity. Deep Agent strives to use a minimal set of generic prompts, while still effectively handling diverse scenarios that may require specific rules. For instance, the rule of \"prioritizing location verification\" is critical for ordering from chain restaurant (e.g., Starbucks) and instant delivery platforms (e.g., Uber Eats, DoorDash) where store and service availability are location-dependent. In contrast, these rules are less relevant for national e-commerce platforms like Amazon or Nike, where delivery address verification can be deferred until checkout. However, such specialized rules tend to accumulate over time, particularly through the autonomous feedback learning process (Section 2.5) that addresses edge cases by introducing additional rules. The resulting expansion of prompt complexity can lead to degraded LLM performance.\nDeep Agent addresses this challenge through its Prompt Tweaking Engine (PTE), which dynamically optimizes prompts before task execution. While maintaining only a few base prompts containing both generic and specific instructions, PTE introduces a pre-processing step to filter out irrelevant rules based on the task context. This optimization process adds overhead typically under a dozen seconds even when employing techniques detailed in Section 2.4 - which is not negligible but reasonable compared to typical agent workflow durations of several minutes (e.g., 2-3 minutes"}, {"title": "Test-Time Computation, Reflection & Validation", "content": "Deep Agent implements test-time computation and reflection mechanisms, following recent researches in LLM performance optimization (Snell et al., 2024). We ask LLM backend to concurrently generate multiple responses. For simplicity, we apply simpler techniques such as token-level beam search with increased temperature, increase top_k values and reduced top_p to promote diversity, or parallel inference runs with different hyperparameter configurations after prefill. Each response undergoes a reflection phase, followed by an integration step that combines the improved responses. Both reflection and integration utilize LLMs with predefined hyperparameters. Through our experiments, we found the test-time computation helped us improve the user experience of the most intricate scenarios, such as prompting C&D to the user at the right time and only with minimal necessary questions, and such as customizing a large number of options on the UI to exactly the right user specification.\nDeep Agent also incorporates an optional Validator component within the executor to enhance agent system robustness and reliability. The Validator captures snapshots of outcomes after each atomic action, API call, or tool invocation (e.g., screenshots of the UI after actions). These outcome snapshots are analyzed together with the input by more powerful models, which, despite introducing some latency, provide stronger reasoning and in-depth verification. When errors are detected, the Validator halts pending nodes in the task DAG, flagging them for re-planning, and signals the planner to initiate re-planning as needed to consider the impact of the detected error. This particular re-planning with detected error, might temporarily switch to the more powerful model to handle added complexity.\nWhile these mechanisms introduce additional computational overhead, their impact is significantly mitigated by AATC described in Section 2.2. AATC itself is leveraging Deep Agent to pre-build"}, {"title": "Auto Prompt Feedback Learning", "content": "Autonomous prompt feedback learning has emerged as a powerful technique to enhance LLM performance without requiring model re-training or fine-tuning (Yang et al., 2024; Yilar et al., 2024). Deep Agent implements this approach through a self-instructed feedback workflow that continuously refines prompts based on the agent system's real-world performance and detected errors.\nThe feedback learning system collects error cases from multiple sources to ensure comprehensive coverage: 1) direct user corrections, 2) reflection disagreements identified during test-time computation, 3) Validator-detected errors during task execution, and 4) additional error cases detected during the autonomous prompt feedback update process (the process requires constant evaluation of prompts, which might reveal new errors).\nThe collected error cases undergo a systematic refinement process, as illustrated in Figure 8. Our approach innovates by improving prompts through iterative processing of error batches. The system leverages Deep Agent in \"Prompt Editor Mode\" to analyze each error batch and propose improve-"}]}