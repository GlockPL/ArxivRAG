{"title": "Enhanced FIWARE-Based Architecture for Cyber-Physical Systems with tinyML and MLOps: A Case Study on Urban Mobility Systems", "authors": ["Javier Conde", "Andr\u00e9s Munoz-Arcentales", "\u00c1lvaro Alonso", "Joaqu\u00edn Salvach\u00faa", "Gabriel Huecas"], "abstract": "The rise of artificial intelligence and the Internet of Things is accelerating the digital transformation of society. Mobility computing presents specific barriers due to its real-time requirements, decentralization, and connectivity through wireless networks. New research on Edge Computing and tinyML explores the execution of Artificial Intelligence models on low-performance devices to address these issues. However, there are not many studies proposing agnostic architectures that manage the entire lifecycle of Intelligent Cyber-Physical Systems. This paper extends a previous architecture based on FIWARE software components to implement the Machine Learning Operations flow, enabling the management of the entire tinyML lifecycle in Cyber-Physical Systems. We also provide a use case to showcase how to implement the FIWARE architecture through a complete example of a smart traffic system. We conclude that the FIWARE ecosystem constitutes a real reference option for developing tinyML and Edge Computing in Cyber-Physical Systems.", "sections": [{"title": "EXTENDING THE FIWARE ARCHITECTURE TO INTEGRATE MLOPS LIFECYCLE AND TINYML IN CPS", "content": "Obtaining efficient Machine Learning Models is not the only task in tinyML. Kolltveit and Li [12] differentiate between two phases, development, and operational-ization. In the development phase, the ML model is trained and evaluated. It requires batch processing of large amounts of data. In the operationalization phase, the model is loaded in the final device that is the one that executes it. The MLOps methodology establishes a fine-grained division of all tasks involving the ML lifecyle. According to Amine et al. [13] the MLOps process includes (1) data retrieval, (2) data preparation, (3) model training, (4) evaluation, (5) tun-ing, (6) deployment, and (7) monitoring. These phases"}, {"title": "Collecting data from IoT devices", "content": "The first phase consists of generating historical data to train ML models. The historical data comes from measurements of the devices themselves, so it is necessary to define an architecture for data collection, data homogenization, and data storage. According to Nikolaos et. al [9] data collection from sensors is a required task when there are not specific datasets to the use case, or there are not datasets with the level of quality needed.\nFIWARE IDAS offers a set of components called IoT Agents that facilitate the integration of exter-nal systems, including IoT devices into the FIWARE ecosystem. IoT Agents act as middleware between the Context Broker and the physical device. That is, they translate NGSI-LD HTTP requests coming from the Context Broker into the native data format and protocol of the loT device. The Context Broker communicates with the loT device through commands processed by the loT Agent, and the loT Agent communicates with the Context Broker by updating the properties of the corresponding NGSI-LD entity.\nIoT Agents ease the dataset generation but also the deployment phase, which is transparent to the"}, {"title": "Modeling and storing data", "content": "Data in the CPS are modeled through NGSI-LD, which is agnostic to the use case. The FIWARE Smart Data Models initiative defines specific data models for di-verse smart domains. In this sense, NGSI-LD allows homogenizing data formats, while the FIWARE Smart Data Models allow homogenizing data models. Both are essential for complex systems such as CPS, where many actors are involved.\nFIWARE Draco 6, based on Apache Nifi, is a high-scalable tool for transforming and routing data in real-time. It is used to integrate systems different from IoT devices in the CPS and to generate historical data for the training phase."}, {"title": "Training Data and Managing ML Versions", "content": "The training phase can begin once the historical data are available. Different frameworks and libraries adapted to tinyML scenarios are mentioned in the literature (e.g., TensorFlow Lite, uTensor, Pythorch Mo-bile). One of the most widely used is TensorFlow Lite because of its efficiency in compressing models and adapting them to a wide variety of microcontrollers.\nMachine learning does not follow a linear cycle, it is an iterative process. Better models can be obtained by tuning the hyperparameters, changing the algo-rithm, increasing the quality and/or quantity of historical data, etc. We have identified the necessity of ML orchestrators that help to monitorize and automatize all phases of the MLOPs life cycle. Open source tools"}, {"title": "Deployment and monitoring", "content": "Once an efficient and device-compatible model has been obtained, it is necessary to define a mechanism to deploy it. The IoT Agents can send commands to be executed on the loT devices and notify them of the existence of a new model. This approach makes it easy to keep the sensor up-to-date and facilitates the automation of the process.\nRegarding monitoring, the device can also send its predictions to the Context Broker through its respective"}, {"title": "USE CASE OF A TINYML-MLOps PIPELINE FOR A SMART TRAFFIC SYSTEM", "content": "Given that FIWARE technology is agnostic to the use case and that the Smart Data Models initiative covers a wide range of scenarios [14], this makes our proposal implementable in any field, including smart agriculture, smart aerospace, smart energy, etc.\nAs an example of implementation, we present a use case for an automatic traffic barrier system that serves as a reference guide for the integration of the MLOps process for TinyML in CPS mobility systems. This scenario contains two sensors that are not connected to each other. The first detects the density of vehicles in a specific area. The second is an smart traffic barrier that controls traffic of such area.\nThe main goal is to train a Machine Learning model and deploy it in the traffic control system. The model predicts the density of vehicles in the area, and based on the result obtained, the smart traffic barrier allows vehicles to pass or not. The scenario is dockerized so it can be easily replicated and deployed. All the code is available in a public repository17."}, {"title": "Data Collection and Generation of the Dataset", "content": "In the pre-training phase, it is necessary to generate historical data if it they do not exist previously. In this scenario data were collected from a loop situated on a road of Santander city (Spain) which records the den-sity of vehicles (vehicles/minute) passing over it. The dataset also includes meteorological information from Santander provided by the Spanish government. Data were collected throughout half of the year of 2021, with one measurement every 15 minutes. Draco was used to generate the historical data. Upon changes in real-time NGSI-LD entities, Draco receives notifications, processes them, and stores the results in a Mongo database, which was used to generate the training CSV."}, {"title": "Training the density of vehicle model", "content": "Once the information is stored in Mongo, the data are cleaned and processed. The predictor uses the environment data, date, and time information to train a model that classifies the density as low, when there are less than ten vehicles per minute; and high, in the opposite case. The binary classifier is a random forest implemented by the scikit-learn library. Firstly, we trained a model named large_model, configuring the RF with 50 trees and a maximum depth of 10, resulting in a model accuracy of 91.4%. This model took 301.83 ms to train and 9.18 ms to make 3,267 predictions (with an average of 2.81 \u00b5s per prediction), and it occupies 2.79 MB. The resultant model is transformed by the emlearn library so that it can be deployed and executed on the barrier controller. The tiny model was compressed by reducing the RF to 10 trees, with a maximum depth of 8 levels, achieving an accuracy of 89.7% (1.7% lower than the uncompressed model). It took 65.54 ms to train and transform the model (78.3% less time), 1.61 ms to make 3,267 predictions (with an average of 0.49 \u03bcs per prediction), and occupies 0.13 MB (95.35% smaller than the large_model.), making the model fit within an ESP32 with 4MB of mem-ory. The training process is managed within MLFlow. MLFlow generates metadata of the process such as the algorithm, the hyperparameters, the link to the historical data, the evaluation results, or the version.\nThe outcome of this module is a new version of the Machine Learning model ready to be deployed on the smart traffic barrier."}, {"title": "Execution of the model in the smart traffic barrier", "content": "Once the data model has been generated it can be uploaded to the smart traffic barrier and it can start operating. In a traditional approach, the prediction would be made in the cloud and the result would be transmitted to the smart traffic barrier. In contrast, with our proposal based on tinyML, the model is loaded onto the loT device, which executes the prediction internally, saving battery, time, and without interacting with other systems.\nThe whole process is automated through Airflow. A Direct Acyclic Graph (DAG) schedules a new ML cycle by training and deploying a new tinyML model when new data are collected. In our scenario, the model was retrained with a dataset covering all of 2021 instead of just half the year. The newly compressed model improved its accuracy to 93.1%, took 103 ms to train, and occupies 0.13 MB."}, {"title": "CONCLUSION AND FUTURE WORK", "content": "The evolution of loT has motivated the trend of bringing computing closer to the edge of the network, includ-ing the execution of Machine Learning models. Most tinyML research focuses on hardware improvement and the generation of efficient models to transfer pro-cessing to the IoT device. However, a complete archi-tecture that performs all prerequisites through MLOps must be implemented. In this article, we propose to ex-tend the FIWARE ecosystem, which has already been validated to implement DTs and CPS, by incorporating tinyML and MLOps capabilities. We explained the ben-efits of our proposal, which fulfills the requirements for CPS deployed in heterogeneous environments. More-over, this article has a practical approach, including a use case of a smart traffic system. From our work, we can conclude that we have enhanced the FIWARE capabilities for developing CPS by integrating tinyML capabilities managed by the MLOps life cycle.\nFor future research, the architecture can be ex-tended with new MLOps and high-level orchestrators, and it will be validated within new use cases from dif-"}]}