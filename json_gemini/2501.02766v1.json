{"title": "Are GNNs Effective for Multimodal Fault Diagnosis in Microservice Systems?", "authors": ["Fei Gao", "Ruyue Xin", "Yaqiang Zhang"], "abstract": "Fault diagnosis in microservice systems has increasingly embraced multimodal observation data for a holistic and multifaceted view of the system, with Graph Neural Networks (GNNs) commonly employed to model complex service dependencies. However, despite the intuitive appeal, there remains a lack of compelling justification for the adoption of GNNS, as no direct evidence supports their necessity or effectiveness. To critically evaluate the current use of GNNs, we propose DiagMLP, a simple topology-agnostic baseline as a substitute for GNNs in fault diagnosis frameworks. Through experiments on five public datasets, we surprisingly find that DiagMLP performs competitively with and even outperforms GNN-based methods in fault diagnosis tasks, indicating that the current paradigm of using GNNs to model service dependencies has not yet demonstrated a tangible contribution. We further discuss potential reasons for this observation and advocate shifting the focus from solely pursuing novel model designs to developing challenging datasets, standardizing preprocessing protocols, and critically evaluating the utility of advanced deep learning modules.", "sections": [{"title": "I. INTRODUCTION", "content": "Microservice systems (MicroSS) underpin modern distributed applications in cloud environments, providing scalability, flexibility, and modular development. These systems are decomposed into interdependent services and monitored through multimodal data, including logs, metrics, and traces. Faults in MicroSS may manifest in single or multiple modalities and propagate through intricate service dependencies [1], making fault diagnosis in MicroSS a significant challenge. Recent studies [2]-[8] employ Graph Neural Networks (GNNs) to integrate local multimodal observation data with global service dependencies for fault diagnosis, aiming to address this challenge. Despite growing interest in this area [9], evidence remains limited regarding the necessity and effectiveness of GNNs in capturing service dependency information, raising a critical question about whether the current paradigm of using GNNs to model these dependencies is genuinely effective.\nThis paper critically examines the current research paradigm in multimodal fault diagnosis for MicroSS, specifically questioning the effectiveness of using GNNs for these tasks. To address this, we introduce DiagMLP, a simple yet robust baseline model based on a topology-agnostic Multi-Layer Perceptron (MLP) framework, serving as a substitute for the GNN module. DiagMLP is evaluated against state-of-the-art GNN-based methods, and experimental results across five public datasets yield a surprising insight: the minimalist design of DiagMLP not only achieves competitive performance but also outperforms several sophisticated GNN-based models in fault detection, localization, and classification tasks. The contributions of this work are threefold:\n1. We present a unified GNN-based fault diagnosis framework, synthesizing existing research and questioning the necessity of GNNs given the sufficient preprocessing of multimodal data.\n2. We propose DiagMLP, a simple yet effective baseline model, challenging the prevailing paradigm of using GNNs to model service dependencies.\n3. Through experiments on five datasets, we demonstrate the limited utility of GNNs in current fault diagnosis tasks and provide actionable insights to inform future research.\nAs the first work to critically examine the effectiveness of GNNs in fault diagnosis for MicroSS, our results underscore the importance of adopting non-trivial datasets and standardized preprocessing to properly assess the need for complex models. And we advocate for a shift in focus within the research community toward practical, interpretable, and effective solutions. We also caution against the use of complex deep learning models that provide only marginal improvements."}, {"title": "II. GNN-BASED FAULT DIAGNOSIS METHODS", "content": "Existing researches typically follow a common paradigm, wherein dependency graphs are constructed to represent the relationships among service instances (nodes) based on trace data and system deployment configuration, node features are extracted through multimodal data fusion, and graph-based representations are subsequently employed for fault diagnosis. GNNs, known for capturing complex interactions and relationships between nodes, have become a prevalent choice for fault diagnosis in MicroSS [7], [10]. We summarize a general framework of existing researches including several key design elements as illustrated in Fig. 2.\na) Preprocessing: Multimodal raw data, including metrics, logs, and traces, is typically unprocessed and lacks standardization, making preprocessing both crucial and diverse. The first step in preprocessing is aligning the multimodal data by timestamps. For log data, log parsing tools, such as Drain3 [11], are commonly used to extract log templates. Through heuristic filtering [4], logs are transformed into time series of template occurrences [6], [7], [12]. Although this reduces semantic richness, it effectively mitigates redundancy in raw log text. Metrics are processed using standard techniques for multivariate time series, with dimensionality reduction achieved through clustering [2]. Traces are used to extract latency time series, which serve as edge [7] or node features. Additionally, combined with deployment configurations [3], [5], traces are employed to construct dependency graphs of service instances. Due to the rarity of anomalies, processed time series may still contain redundant information. Lightweight anomaly detection techniques, such as 3-sigma [3], [4], can be applied to generate alert event sequences, offering a unified representation that balances informativeness and efficiency across modalities [10], [13].\nb) Embedding: To preserve both temporal and semantic information, carefully selected models are employed to embed preprocessed data. For time-series data, advanced sequence models such as Temporal Convolutional Networks (TCN) [14] and Transformers [15] are commonly used to capture complex temporal dependencies. Event sequences are embedded using language models like FastText [16] and GloVe [17], while raw log text is encoded into contextual embeddings through pretrained language models such as BERT [18]. Embedding modules influence the model's training process, which may involve either a pretraining strategy [3]-[5] or end-to-end integration within the fault diagnosis pipeline.\nc) GNN-based Modeling: Faults in MicroSS propagate through service dependencies, often leading to cascading failures. Integrating multimodal observations with dependency graphs using GNNs is considered a promising approach for diagnosis. The most commonly used GNN architectures include basic models such as GCN, GAT, and GraphSAGE. More advanced and specialized GNN variants have also been proposed. For example, DGERCL [19] employs a stream-based dynamic GNNs to model temporal sequences of service invocations, while DeepHunt [5] introduces a graph autoencoder framework for self-supervised learning that effectively addresses the challenge of limited labeled data.\nThe review of existing literature reveals two key observations that underpin our research. First, while preprocessing and embedding methodologies vary significantly, the modeling stage predominantly relies on GNNs, whose effectiveness has not been rigorously benchmarked against minimal baselines. Second, preprocessing\u2014particularly for trace data often incorporates system dependency topology into feature representations, which may overshadow the unique contributions of GNNs. These observations call for a thorough re-evaluation of GNNs' efficacy in fault diagnosis for MicroSS, raising the question of whether their complexity is justified given the extensive preprocessing that already captures critical topological information."}, {"title": "III. A TOPOLOGY-AGNOSTIC BASELINE", "content": "State-of-the-art GNN-based models usually optimize the entire pipeline of fault diagnosis tasks, making it unclear whether performance gains result from the GNNs or other components like multimodal data and preprocessing. We hypothesize that the improvements largely come from non-GNN elements, considering that preprocessing of multimodal data already extracts rich information. To test the hypothesis, we propose a topology-agnostic baseline to isolate and evaluate the true contributions of GNN-based models.\nA. Problem Formulation\nGiven a MicroSS represented as a set of N nodes (service instances), each node $i \\in \\{1,...,N\\}$ is associated with multimodal features:\n$X_i = [x_i^{metric}, x_i^{log}, x_i^{trace}]$,\nwhere $x_i^{metric}, x_i^{log}, x_i^{trace} \\in \\mathbb{R}^{d}$ are embeddings derived from metric, log, and trace data, respectively. These embeddings can be generated using any preprocessing and embedding pipeline, without imposing restrictions on the specific methods employed.\nThe goal is to learn a mapping $f : \\{X_i\\} \\rightarrow \\mathbb{R}^{c}$ that determines whether the system is anomalous (for $c = 2$), identifies the root cause (for $c = N$), and classifies the type of failure (where $c$ is the number of failure types).\nB. DiagMLP\nWe propose a minimal fault diagnosis model based on a topology-agnostic MLP, named DiagMLP, which serves as a null model for evaluating GNN-based methods. The architecture of DiagMLP is defined in Eq. 2:\n$\\bar{x_i} = [x^{metric}_i \\oplus x^{log}_i \\oplus x^{trace}_i \\oplus p_i]$,\n$x_i = Modal\\_Fusion\\_MLP(\\bar{x_i})$,\n$x_g = x_1 \\oplus x_2 \\oplus ... \\oplus x_N$,\n$y_g = Node\\_Fusion\\_MLP(x_g)$,\nwhere $\\oplus$ denotes the concatenation operator, $p_i \\in \\mathbb{R}^{d}$ is the learnable position embedding [20] for node i, and $y_g$ is the system-wise representation. The two Fusion MLP modules share the same simple architecture, defined as follows in Eq. 3:\n$Fusion\\_MLP(x) = Dropout(ReLU(LN(Wx+b)))$,\nwhere $LN$ refers to layer normalization, $ReLU$ introduces non-linearity, and $Dropout$ serves as regularization to prevent overfitting.\nAs illustrated in Fig. 3, DiagMLP maps node-level embeddings into task-oriented system-level representations, imposing no constraints on the embedding module or downstream tasks. This adaptability positions DiagMLP as a topology-agnostic replacement for GNNs modules in existing frameworks.\nC. Design Choices of DiagMLP\nThe design of DiagMLP prioritizes simplicity and effectiveness by incorporating several key decisions:\na) Learnable Position Embeddings: DiagMLP includes a learnable position embedding for each node, which empirically improves performance. This is likely due to improved node discrimination, which allows the model to capture node-specific patterns that are critical to fault diagnosis.\nb) Single-Layer MLP: A single-layer MLP is used instead of a deeper architecture because of the empirical effectiveness of linear transformations of raw features in fault diagnosis. This choice minimizes complexity while maintaining strong performance, reducing overfitting, and emphasizing the impact of preprocessing and embedding steps.\nc) Fusion by Concatenation: Modal-wise and node-wise features are integrated through straightforward concatenation to retain the full breadth of input information. While this method proves effective, it results in the parameter space of the Node Fusion MLP scaling linearly with the number of nodes N. Although this complexity is manageable for publicly available multimodal datasets, it poses significant challenges to scalability in larger systems. To overcome these limitations, future research could investigate more sophisticated and scalable alternatives, such as DeepSets [21] or Set Transformers [22]."}, {"title": "IV. EXPERIMENTS", "content": "To validate our hypothesis, we integrate DiagMLP as a substitute for the GNNs components in SOTA fault diagnosis frameworks. Crucially, we maintain consistency across all other pipeline components, including the raw dataset, preprocessing methods, embedding techniques, objectives, and training strategies. This controlled experimental design ensures that any observed performance differences are attributable solely to the modeling stage, thereby minimizing the influence of confounding variables.\nA. Experimental Settings\na) Baselines: We use 3 recently proposed methods-Eadro [2], TVDiag [4], and DeepHunt [5] as backbone frameworks, replacing their GNNs components with our topology-agnostic DiagMLP, to validate the effectiveness of our model. Additionally, we include two other methods, DiagFusion [3] and CHASE [12], as they follow the same evaluation protocols.\nb) Datasets: To ensure maximum control over experimental variables, we adopt the datasets used in the corresponding papers: Social Network (SN) and Train Tickets (TT) datasets from Eadro, the GAIA dataset from TVDiag, and the D1 and D2 datasets from DeepHunt. Specifically, we reimplement\u2074 the preprocessing codes for SN and TT datasets, as the original preprocessing scripts were not provided. For GAIA, D1, and D2, we directly use the preprocessed multimodal data publicly provided by the authors. This ensures consistency and comparability across all experiments. We present in Table I the statistics of the datasets used.\nc) Evaluation Metrics: For fault detection and classification tasks, we evaluate model performance using precision, recall, and F1 score. In fault localization, we assess performance through Topk accuracy, which is the proportion of cases in which the faulty node is correctly identified within the top k predictions.\nd) Notes: (1) We do not attempt to evaluate all models on all datasets, which is unnecessary for the purpose of our experiments. (2) We have identified and addressed flaws in existing frameworks, such as the window splitting strategy in Eadro that could result in data leakage. Furthermore, we introduce a validation set to align with standard best practices in machine learning evaluation.\nB. Results\nWe present the fault detection results for the SN and TT datasets in Table II, the fault localization results across all datasets in Table IV, and the fault classification results for the D1 and D2 datasets in Table III."}, {"title": "V. ANALYSIS AND DISCUSSION", "content": "The competitive performance of the topology-agnostic Di-agMLP suggests that current state-of-the-art methods fail to fully exploit the assumed advantages of modeling system dependencies with GNNs. In fact, the use of GNN modules may even degrade model accuracy. We analyze two possible reasons: (1) topological dependencies may be either redundant or not fully utilized, and (2) the preprocessing steps may have already embedded essential topological information into node embeddings. As for the first reason, prior studies have demonstrated the effectiveness of leveraging topological dependencies in related domains [26], [27]. Therefore, we argue that existing fault diagnosis methods fail to effectively leverage topological dependency information. The second hypothesis suggests that the datasets used in existing studies may be too small in scale or simplistic in structure, rendering global topological information unnecessary for achieving competitive diagnostic performance.\nBased on these observations, we urge the MicroSS research community to exercise greater caution when introducing complex models like GNNs for multimodal fault diagnosis. It is crucial to clearly distinguish the innovations that genuinely advance the field. Furthermore, we emphasize the need for larger-scale, more complex public datasets, alongside standardized preprocessing protocols. We also advocate for adherence to best practices in deep learning, including rigorous validation and testing protocols, to ensure the reproducibility and generalizability of experimental results."}, {"title": "VI. CONCLUSION", "content": "This paper critically evaluates the effectiveness of GNNs in fault diagnosis for MicroSS by proposing a topology-agnostic baseline model, DiagMLP. Experiments on five datasets reveal that the GNN modules used in state-of-the-art methods provide no substantial performance gains. In contrast, DiagMLP achieves comparable, and in some cases superior, results in fault detection, localization, and classification tasks. These findings suggest that improvements are largely driven by multimodal data preprocessing and embedding techniques, rather than GNN-based dependency modeling. The study also highlights the limitations of existing datasets and experimental designs, calling for larger, more complex datasets and standardized preprocessing protocols. This work not only challenges the prevailing assumptions about the utility of GNNs in this domain but also provides a robust methodological foundation and clear directions for future research in microservice fault diagnosis."}]}