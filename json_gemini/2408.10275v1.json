{"title": "FedKBP: Federated dose prediction framework\nfor knowledge-based planning in radiation therapy", "authors": ["Jingyun Chen", "Martin King", "Yading Yuan"], "abstract": "To address the growing demand for radiation therapy in cancer treatment, knowledge-based planning (KBP) has been introduced to streamline\nthe planning process and reduce treatment lead time\u00b9. Central to KBP is the dose prediction, which automatically estimates patient-specific\ndose distribution for treatment plan evaluation and optimization. Recent advances in deep learning-based dose prediction methods2,3,4,5 have\nhighlighted the challenge of limited training data availability, necessitating collaboration among diverse data contributors. Federated learning\n(FL) has emerged as a solution, enabling medical centers to jointly train deep-learning models without compromising patient data privacy\n(Figure 1). To evaluate the effectiveness of federated dose prediction in KBP, we developed a framework named FedKBP to access the\nperformances of centralized, federated, and individual (i.e. separated) training of dose prediction model on same dataset.", "sections": [{"title": "1. PURPOSE", "content": "To address the growing demand for radiation therapy in cancer treatment, knowledge-based planning (KBP) has been introduced to streamline\nthe planning process and reduce treatment lead time\u00b9. Central to KBP is the dose prediction, which automatically estimates patient-specific\ndose distribution for treatment plan evaluation and optimization. Recent advances in deep learning-based dose prediction methods2,3,4,5 have\nhighlighted the challenge of limited training data availability, necessitating collaboration among diverse data contributors. Federated learning\n(FL) has emerged as a solution, enabling medical centers to jointly train deep-learning models without compromising patient data privacy\n(Figure 1). To evaluate the effectiveness of federated dose prediction in KBP, we developed a framework named FedKBP to access the\nperformances of centralized, federated, and individual (i.e. separated) training of dose prediction model on same dataset."}, {"title": "2. METHODS", "content": ""}, {"title": "2.1 Data", "content": "This study employed the public dataset from open-access knowledge-based planning (OpenKBP) grand challenge7. The OpenKBP dataset\ncontains a total of 340 cases (i.e. plans) for head and neck cancer treatment, including 200 training cases, 40 validating cases, and 100 testing\ncases. The prescribed plans were 70, 63 and 56 Gy in 35 fractions. The organs at risk (OARs) include brain stem, right parotid, left parotid,\nspinal cord, larynx, mandible and esophagus. To simulate the distributed training environment, we randomly divided the 200 training cases\nand 40 validating cases into 8 groups, representing 8 training sites. To evaluate the effect of inter-site data variation on model training, we\nimplemented two types of case distributions: 1) Independent and identically distributed (IID), where the training and validating cases were\nevenly divided among the 8 sites, and 2) non-IID, where some sites have more cases than others. Table 1 showed the case numbers of each site\nunder IID and non-IID data distributions. The 100 testing cases were used as out-of-sample testing cases by each site, regardless of data\ndistribution type."}, {"title": "2.2 Dose prediction model", "content": "In this study, we implemented the Scale Attention Network (SANet) for 3D dose prediction, with voxel-wise Mean Absolute Error (MAE)\nbetween dose prediction and ground truth as the loss function2,8. SANet features a dynamic scale attention mechanism to incorporate low-lever\ndetails with high-level semantics from feature maps at different scales, thus, to better integrate information across different scales. It has\ndemonstrated strong performance in dose prediction as well as tumor segmentation9,10."}, {"title": "2.3 Baselines and evaluation", "content": "We evaluated three different training methods: 1) Pooled model (PM), which is trained with all 8 sites' training data together. 2) Individual\nmodel (IM), which is trained on each site trains with its local data individually without exchanging models. 3) FedAvg: which forms a consensus\nmodel at each round by weighted average of the local models from all sites (Figure 1). For FedAvg and IM, we further evaluated the two types\nof data distributions (IID and non-IID). The resulting model performances are accessed with dose score and dose-volume histogram (DVH)\nscore as defined in OpenKBP challenge7. For both scores, smaller value represents higher prediction accuracy and better model performance."}, {"title": "2.4 Implementation", "content": "All three training methods (PM, FedAvg, IM) were carried out with in-house developed FedKBP framework on Nvidia GTX 1080 TI GPUs\nwith 11 GB memory. Each method was trained for 100 epochs. For FedAvg and IM, each site was assigned a separate GPU for training."}, {"title": "3. RESULTS", "content": "Table 2 contains the model prediction accuracy (in terms of mean dose and DVH scores) for different training scenarios. For PM and FedAvg,\nthe corresponding global models are evaluated. For IM, the testing scores of local models are computed and averaged to represent the global\nperformance.\nOn global/average level, PM showed high performance on both dose and DVH scores as expected, since it was trained on all the data pooled\ntogether. FedAvg consistently outperformed IM on both testing scores (dose and DVH) and both data divisions (IID and non-IID), showing\nprevalent advantages of FedAvg over IM. Notably, the IID FedAvg showed comparable performance to PM, with larger dose score (2.7254 vs\n2.6758) but smaller DVH score (1.8530 vs 1.8990). This indicates FL can potentially achieve similar performance as compared to pooled\ntraining, even though the former is trained on distributed data. As compared to IID FedAvg, non-IID FedAvg suffered with larger testing scores,\nfor both dose (2.9001 vs 2.7254) and DVH (1.9979 vs 1.8530). This finding confirms the challenge of non-IID data in FL, which is consistent\nwith reports from previous publications11,12.\nOn local/individual level, the IID IM showed coherent performances among local sites, while exhibiting some individual variability. For the\nnon-IID IM, larger sites (i.e. sites with more cases) tend to have better performance than smaller sites. For example, the largest non-IID site\n(Site0, with 40 training and 8 validating cases) outperformed the smallest non-IID site (Site7, with 10 training cases and 2 validating cases) by\n18% on dose score (3.1687 vs 3.7557) and 19% on DVH score (2.3872 vs 2.8450). This finding shows the benefit of large dataset and confirms\nthe necessity of collaboration among data contributors for improved performance.\nFigure 2 shows the validation loss over epoch, representing the model optimization over time, under different training scenarios. For FedAvg\nand IM, the validation losses of local sites are averaged to compare with the global validation loss of PM. As expected, the validation loss of\nPM displays fastest decrease and lowest final value among all training scenarios. Empowered by model exchange at each epoch, the validation\nloss of FedAvg showed faster decrease and lower final values than IM under both IID and non-IID data distributions, reflecting the enhanced\nmodel optimization in FedAvg over IM. In both FedAvg and IM, the non-IID group are consistently outperformed by the IID counterpart,\nconfirming the hindrance to model optimization by non-IID data distributions."}, {"title": "4. NEW WORK TO BE PRESENTED", "content": "We developed a novel framework, namely FedKBP, for simulating and benchmarking various training scenarios of 3D dose prediction models.\nUnder FedKBP framework, we accessed the dose prediction models from three distinctive training approaches under IID and non-IID data\ndistributions. The results underscored FL as a promising solution for training dose prediction model over distributed data, while also confirmed\nthat non-IID data distribution poses a challenge to FL."}, {"title": "5. CONCLUSIONS", "content": "Federated learning (FL) offers a promising alternative to centralized data-pooling, delivering comparable performance while preserving data\nprivacy at local sites. However, non-IID data distribution across sites may hinder model optimization in FL. Therefore, more sophisticated FL\nmethod is needed to tackle data variations among participating sites and achieve enhanced performance."}]}