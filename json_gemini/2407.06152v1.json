{"title": "Uni-ELF: A Multi-Level Representation Learning Framework for Electrolyte Formulation Design", "authors": ["Boshen Zeng", "Sian Chen", "Xinxin Liu", "Changhong Chen", "Bin Deng", "Xiaoxu Wang", "Zhifeng Gao", "Yuzhi Zhang", "Weinan E", "Linfeng Zhang"], "abstract": "Advancements in lithium battery technology heavily rely on the design and engineering of electrolytes. However, current schemes for molecular design and recipe optimization of electrolytes lack an effective computational-experimental closed loop and often fall short in accurately predicting diverse electrolyte formulation properties. In this work, we introduce Uni-ELF, a novel multi-level representation learning framework to advance electrolyte design. Our approach involves two-stage pretraining: reconstructing three-dimensional molecular structures at the molecular level using the Uni-Mol model, and predicting statistical structural properties (e.g., radial distribution functions) from molecular dynamics simulations at the mixture level. Through this comprehensive pretraining, Uni-ELF is able to capture intricate molecular and mixture-level information, which significantly enhances its predictive capability. As a result, Uni-ELF substantially outperforms state-of-the-art methods in predicting both molecular properties (e.g., melting point, boiling point, synthesizability) and formulation properties (e.g., conductivity, Coulombic efficiency). Moreover, Uni-ELF can be seamlessly integrated into an automatic experimental design workflow. We believe this innovative framework will pave the way for automated AI-based electrolyte design and engineering.", "sections": [{"title": "1. Introduction", "content": "Lithium-based rechargeable batteries are a cornerstone of modern energy storage technologies, offering exceptional potential for high energy density, rapid charging capabilities, and longevity. Functioning as an ionic conductor and electronic insulator between electrodes while maintaining stability under extreme chemical conditions, the electrolyte, which interfaces with every other component, plays a vital role in battery operation 1-3. As we enter the era of high-energy-density batteries that place higher demands on electrolytes, especially with high-voltage cathode materials 4,5 and high-energy-density anode materials like lithium metal6,7, the design and engineering of electrolytes emerge as the main challenges. Current electrolyte systems based on ethylene carbonate (EC) are increasingly inadequate for these next-generation energy storage solutions 8,9. Consequently, breakthroughs in materials and chemistries crucial for next-generation batteries hinge on mastering electrolyte design.\nThe research and development of electrolytes present two primary challenges: innovating molecular design and manipulating electrolyte formulation. These challenges stem from the need to fine-tune the electrolyte's conductivity 10\u201312, solubility 13-15, stability 7,16, and compatibility with electrode materials 2,3 to meet stringent performance criteria. Unlike other fields, such as drug design, which mainly focus on the design and synthesis of monomeric small molecules, the design at the electrolyte formulation level is particularly crucial. This involves providing recommendations and predictions for the mixing ratio of molecules, including lithium salts, solvents, and functional additives. The interplay between these different components can significantly affect the energy density, cycle life, and overall performance of the batteries 17,18. The variety of molecular space further exacerbates the challenge for potential candidates and the abundance of mixing possibilities, especially in multi-component systems 12,13,19. We refer to Figure 1(a) for an illustration of electrolyte design at multiple levels.\nThe methodologies that heavily rely on trial-and-error lack the efficiency required for the rapid development of electrolyte systems. Over the past few decades, progress in computational approaches such as density functional theory (DFT) 20,21 and molecular dynamics 22 has enabled the deciphering of dynamic behaviors at the electronic and atomic levels, thereby deducing macroscopic properties through statistical mechanics. However, the complex nature inside batteries, especially across multiple scales, hinders a complete understanding of mechanisms, the development of highly capable and predictive simulators, and the realization of an ultimately rational design scheme 19. Moreover, the computational costs originating from the curse of dimensionality-the O(N\u00b3) complexity of DFT with respect to atoms, and the need for adequate sampling of necessary microscopic states\u2014are not capable of matching the high-throughput screening in industrial research and development scenarios.\nOn the other hand, data-driven schemes such as quantitative structure-property relationships have been developed, wherein the molecular representation is attained through feature engineering23\u201329. The manual design of features or descriptors requires extensive domain knowledge and tends to be disadvantageous when confronting large-scale and high-dimensional problems. Furthermore, the scarcity of informative data makes the transferability of data-driven models uncertain. The rapid growth of deep learning techniques, especially molecular representation learning along with the pretraining-finetuning paradigm, has alleviated this problem 30-33. Among these methods, the Uni-Mol framework 34, which properly incorporates the 3D information of a molecule, has achieved widespread success in a series of chemistry and material science fields, including small organic molecules 35, organic light-emitting diodes 36, and metal-organic frameworks37, mostly focusing on the relationship between individual molecules and their properties. However, a similar approach has been lacking at the level of formulations, for which existing attempts are primarily based on traditional regression methodologies and conventional machine learning models such as random forest 28 and XGBoost 38.\nIn this study, we introduce the Universal Electrolyte Formulation (Uni-ELF) framework, which excels in predicting electrolyte properties and designing electrolyte formulations through a multi-level pretraining scheme: at the molecular level, it reconstructs three-dimensional molecular structures using the Uni-Mol model; while at the mixture level, it predicts statistical structural properties, such as radial distribution functions, derived from molecular dynamics simulations. Systematic experiments demonstrate that, after pretraining, Uni-ELF exceeds existing state-of-the-art (SOTA) methods across a broad spectrum of tasks, accurately predicting crucial properties at both molecular and mixture levels. The performance of Uni-ELF is anticipated to further improve by integrating physics-driven modeling and leveraging high-quality data acquired through autonomous experiments. We posit that Uni-ELF not only represents an innovative approach to unifying representation learning tasks for electrolytes across different levels but also serves as a timely and effective tool for intelligent battery design at the industrial scale."}, {"title": "2. Multi-Level Representation Learning", "content": "In the Uni-ELF scheme, we first acquire molecular and formulation representations through pretraining. After this phase, the model can be fine-tuned for various tasks by linking these representations to different fitting networks. For a visual overview, please refer to Figure 1(b), which illustrates representation learning at both the molecular and formulation levels."}, {"title": "2.1. Representation Learning at Molecular Level", "content": "The molecule-level representation learning approach is built upon Uni-Mol34, a three-dimensional molecular representation framework that leverages self-supervised pretraining to reconstruct molecular structures. As illustrated in Figure 1(b1), molecules, including key electrolyte components such as lithium hexafluorophosphate (LiPF6), ethylmethyl carbonate (EMC), ethylene carbonate (EC), and propylene carbonate (PC), are encoded using their three-dimensional coordinates and atom types. These encodings are refined to generate atom-pair representations and atomic representations. During pretraining, the model unmaskes atom types and denoises atom pair distances. Following pretraining on 209 million molecular conformations, we employ average pooling over all atomic representations to derive molecular representations, which are subsequently used for predicting molecular properties or serving as input for the formulation-level model.\nIn greater detail, the 3D structures of input molecules are generated using the MMFF94 force field39 from RDKit40. The Uni-Mol framework34 serves as the encoder, comprising 15 layers with an embedding dimension of 512 and a feedforward network dimension of 2048. Each encoder layer is equipped with 64 attention heads, utilizing GELU 41 for activation and tanh42 for pooler activation. The [CLS] token43, a virtual atom positioned at the center of mass of the molecule, is preserved to represent the entire structure in Uni-Mol. This design enables the model to capture long-range interactions between atoms, particularly within larger molecules. In tasks involving molecular charge distribution such as predicting the dielectric constant and refractive index-atomic representations are used to simultaneously predict Gasteiger charges44 within the molecule, thereby enhancing the model's ability to capture relevant electrostatic properties. The mean squared error (MSE) of the predicted charges is included as a loss term, with a weight of 0.1."}, {"title": "2.2. Representation Learning at Formulation Level", "content": "To enhance predictive capabilities, the formulation model should integrate specific inductive biases. Recognizing that entities are characterized not only by their intrinsic properties but also by their interactions with other entities, the model must distinguish between identical molecular species in varying contexts. Additionally, it should uphold permutation invariance for molecular input sequences, ensuring consistent output regardless of the order of inputs.\nTo achieve these goals, we designed the Uni-ELF backbone employing a transformer encoder architecture, as depicted in Figure 1(b2, c). At the formulation level, the model processes molecular representations weighted by their molar ratios, refining the representations of both individual molecular species and their interactions. These refined representations are then aggregated on the basis of their molar ratios. For tasks that involve environmental temperature, we introduce a temperature embedding block utilizing a Gaussian kernel. This block encodes temperature values through a set of evenly distributed Gaussian basis functions with specified means and standard deviations.\nThe model undergoes pre-training to predict solution structures, thereby learning formulation representations. Given the scarcity of experimental data, we supplement this with physical modeling to provide an additional source of structural data for transfer learning. Within the Uni-ELF framework, molecular dynamics simulations generate extensive data on the trajectories of solution particles. These trajectories are statistically averaged to extract the structural characteristics of the solution. Specifically, the radial distribution functions (RDFs) provide the density probability for a particle to have a neighbor at a given distance r, revealing the fine structure of the solution. The RDFs of molecular pairs (detailed in Supplementary Information) are particularly suitable for edge-level tasks using pair representations in the transformer encoder, thus chosen as the data for the pretraining task.\nDuring pretraining, Uni-ELF receives not only molecular species and their molar ratios but also a range of radial distance values r. These radial distances are embedded using a Gaussian kernel. The model maintains pairwise representations of molecular species, leveraging the symmetry inherent in the RDF between molecules. Specifically, it sums the attention representations of matrix elements i, j and j, i to form the pairwise representation. This summed representation is then concatenated with the embedded radial distance values to predict the RDF \\(g_{ij}(r)\\) for the molecular pair i, j at a given radial distance r.\nIn predicting RDFs, the model achieves a final test set root mean square error (RMSE) of 0.06. As illustrated in Figure 2, the strong concordance between the predicted and true RDFs for a test set comprising the LiPF6/PC/EMC system underscores the accuracy of the Uni-ELF model during pretraining. This high level of accuracy in reproducing the structural information of the formulations indicates a promising transfer of these learned representations to downstream property prediction tasks.\nWe refer to the Supplementary Information for more details of formulation-level model architecture, pretraining scheme, as well as molecular dynamics simulations."}, {"title": "3. Results on Downstream Tasks", "content": "We begin by leveraging the molecular representation capabilities of Uni-ELF to predict properties critical for electrolyte design. As illustrated in Figure 3, Uni-ELF demonstrates superior performance compared to state-of-the-art methods. For melting point prediction, it achieves an \\(R^2\\) of 0.857 and an RMSE of 34.31 \u00b0C, outperforming the previous benchmark of \\(R^2\\) 0.830 and RMSE 36.88 \u00b0C45. In the prediction of boiling points and vapor pressures, Uni-ELF surpasses the OPERA model24, with an \\(R^2\\) of 0.975 and an RMSE of 13.49 \u00b0C for boiling points, and an \\(R^2\\) of 0.951 and an RMSE of 0.79 Log mm/Hg for vapor pressures. Additionally, it exceeds QSPR models in predicting dielectric constant, refractive index, and density, achieving \\(R^2\\) values of 0.966, 0.982, and 0.992, with corresponding RMSEs of 2.70, 0.082, and 0.025 g/cm\u00b3, respectively 23,25,26. These results underscore the advantage of representation learning over traditional QSPR methods in predicting molecular properties.\nTo further explore the model's capability in identifying promising electrolyte molecules, we evaluate its performance on molecular synthesizability prediction. Predicting the synthesizability of new molecules is a challenging task, often dependent on the intuition and experience of chemists. Lee et al. 29 curated a dataset from QM946, comprising 126,405 entries, to assess molecular synthesizability. They classified QM9 molecules as synthesizable if they were listed in either the PubChem47 or eMolecules 48 databases, while unlisted molecules were presumed unsynthesizable. In this task, our model achieves an area under the curve (AUC) of 0.965, surpassing the previous best AUC of 0.95529. Although the absence of a molecule in these databases does not definitively indicate unsynthesizability, it provides valuable insights into the relative ease or difficulty of synthesis. By coupling the conditions required for electrolytes, such as a wide liquid range and solubility for lithium salts, with trained models for melting point, boiling point, dielectric constant, and synthesizability, our approach offers a robust reference for evaluating the potential suitability and synthetic feasibility of virtually generated molecules as electrolytes.\nWe refer to the Supplementary Information for more details and additional benchmarks on molecular-level tasks, confirming the superior performance of Uni-ELF in various cases."}, {"title": "3.2. Formulation-Level Tasks", "content": "To validate the efficacy of our multi-level representation learning architecture and transfer learning strategy for predicting solution structures, we applied the framework to the prediction of electrolyte formulation properties. Specifically, we reviewed and corrected two datasets from original sources: one on Coulombic efficiency (CE) for lithium metal anode batteries 28, and another on electrolyte conductivity 27. For the Coulombic efficiency dataset, we removed an entry with a repeated ratio but different measurement methods and values, and corrected errors in some ratios and molecular information. This resulted in a refined dataset consisting of 149 entries of logarithmic Coulombic efficiency (LCE, defined as - log(1 \u2013 CE)). For the conductivity dataset, errors were similarly corrected, and polymers were filtered out to focus on liquid electrolytes. The final conductivity dataset, curated at various temperatures, consisted of 2,588 entries.\nBoth datasets were split into training and test sets using a 7:3 ratio. Additionally, to evaluate the model's ability to predict novel formulation systems, we employed an additional group split method for the conductivity dataset. In this method, data from formulation systems containing identical sets of molecular species were grouped and then randomly divided into training and test sets according to these groups. We utilized five-fold cross-validation during training to enhance the model's robustness. The final model was an ensemble of the five models trained in each fold, with performance metrics derived from the averaged test set predictions.\nWe establish several baseline methods for constructing formulation fingerprints at both the molecular and formulation levels, utilizing XGBoost 38 for regression prediction. These methods include: one-hot encoding for all types of molecules in the dataset, where the formulation fingerprint contains only molecular species and ratio information without any molecular or solution structure details; Morgan fingerprints for encoding molecular structures49; and Uni-Mol fingerprints derived from the Uni-Mol pre-trained model 34, which do not dynamically adjust features. To enhance predictive accuracy in the electrolyte scenario, we partition the formulation fingerprint into solvent and salt components. Specifically, the fingerprints of molecules or ions are weighted by their molar ratios to generate the corresponding parts' fingerprints, which are then concatenated to form the complete formulation fingerprint. Additionally, for the conductivity dataset, temperature is incorporated as a one-dimensional feature within the formulation fingerprint.\nA summary of the performance of various molecular representation schemes on different tasks is provided in Table 1. Notably, all the discussed schemes significantly outperform recent work by Kim et al. 28. Across all tasks, a consistent trend in performance is observed: the pre-trained Uni-ELF model achieves the best results, followed by the non-pre-trained Uni-ELF model, then the Uni-Mol fingerprint, Morgan fingerprint, and finally, the one-hot embedding. For instance, on the LCE dataset, the pre-trained Uni-ELF model achieves an RMSE of 0.184, reducing the error by approximately 14% compared to the non-pre-trained Uni-ELF model, which has an RMSE of 0.215. Similarly, for the conductivity dataset, the pre-trained Uni-ELF model achieves an RMSE of 0.50 mS/cm (random split) and 2.15 mS/cm (group split), reducing the error by about 6% and 13%, respectively, compared to the non-pre-trained Uni-ELF model.\nThe alignment of these performance results with intuitive expectations is evident. One-hot embeddings, being simple numerical representations without structural information, perform the worst. Morgan fingerprints, which capture some molecular-level features, show moderate improvement. Uni-Mol fingerprints, containing richer molecular structures, further enhance performance. The superior outcomes of the non-pre-trained Uni-ELF model over Uni-Mol fingerprints with XGBoost highlight the efficacy of the transformer-based Uni-ELF architecture. Finally, the pre-trained Uni-ELF model, which incorporates even richer formulation-level structural information, achieves the best performance across all tasks.\nAs illustrated in Figure 4, the agreement between Uni-ELF predictions and experimental results is evident. Specifically, Figure 4(c) shows that while a group split may introduce more deviations\u2014since some tested data belong to groups not present in the training data-the predictions still maintain a consistent trend. This demonstrates the robustness of the Uni-ELF model in handling diverse datasets and its ability to generalize well even under challenging conditions.\nIn conclusion, the pre-trained Uni-ELF model sets a new benchmark for predictive accuracy in this domain, demonstrating the critical importance of capturing comprehensive molecular and formulation-level information for superior performance in downstream tasks."}, {"title": "4. Applications", "content": "Although a comprehensive computational-experimental validation is deferred to future studies due to associated costs, we present the potential of Uni-ELF for molecular and formulation design via a conceptual application. In this context, we illustrate the rediscovery of fluoroacetonitrile (FAN), a high-conductivity solvent system recently reported by Lu et al. in Nature3, with minimal constraints on the molecular search space. We start by constraining the search space to molecules that are organic aprotic solvents containing cyano and fluoro groups, incorporating at least a four-membered ring if cyclic, and comprising up to eight heavy atoms. Compatibility with high-voltage cathodes is ensured by the inclusion of electron-withdrawing cyano (-C\u2261N) groups, while anode compatibility is facilitated by fluorinated (-F) groups.\nAs shown in Figure 5(a), the conceptual experiment applies three objectives: high ionic conductivity for fast charging, wide liquid range for the solvent, and ease of synthesis, alongside four constraints mentioned above. To address these constraints, we begin by employing graph theory to enumerate potential molecules, starting with formonitrile (H-C\u2261N). Utilizing a breadth-first search (BFS), we progressively add carbon (C), oxygen (O), or fluorine (F) atoms to the chain. Duplicates are filtered out on the basis of graph isomorphism, and the search continues until we generate chain molecules containing up to eight heavy atoms. Subsequently, we enumerate all possible configurations to form 4-6 membered rings, again eliminating duplicates. Unstable structures, such as those containing O-O bonds, or proton groups unsuitable for use as electrolytes, such as carboxyl groups, are discarded, resulting in a set of 1,165 candidate molecules. This entire search process is completed in under 30 seconds on a standard computer CPU.\nFollowing the identification of 1,165 candidate molecules, we employed Uni-ELF models to efficiently screen these compounds for their molecular and formulation properties. Molecular level properties, including melting point, boiling point, synthetic accessibility (synthesizability), and electrolyte conductivity, are predicted using Uni-ELF trained by publicly available data, with little direct information of the 1,165 candidates. At the formulation level, we generated a grid of 120 formulation points by systematically combining each molecule with LiPF6, LiTFSI, and LiFSI salts at varying concentrations. This approach enabled us to predict the room temperature conductivity for each formulation, providing a robust basis for chemists to establish evaluation criteria for subsequent experimental testing.\nWe filter and rank the molecules using the following criteria: (1) predicted melting point < 40\u00b0C and boiling point > 40\u00b0C; (2) presence in PubChem 47 or CAS, or synthetic accessibility probability \u2265 90%; (3) highest predicted room temperature conductivity among all formulations. Through prediction and screening, we identify the top 10 candidate molecules, shown in Figure 5(c). The top-ranked molecule is fluoroacetonitrile (FAN), with a predicted maximum room temperature conductivity of 26.35 mS/cm, significantly surpassing the second-ranked molecule. According to Lu et al. 3, FAN exhibits a high ionic conductivity of 40.3 mS/cm as a lithium-ion electrolyte. Notably, FAN was not present in the model's training datasets, suggesting that the model independently identified FAN as a promising electrolyte material.\nUsing additional data published by Lu et al.3, we further explore the few-shot generalization capability of Uni-ELF. As shown in Figure 5, after few-shot learning with 3 data points corresponding to the endpoint concentrations (0.1 and 4 M) and the concentration with the highest predicted conductivity-the model accurately predicts the conductivity-concentration relationships for both LiFSI/FAN and LiTFSI/FAN systems. We perform 10-fold cross-validation, train 10 models, and average their predictions. The uncertainty values are provided by the standard deviation, and the curves fitting the experimental and predicted values are displayed using a fourth-order polynomial. In the low concentration region, the two curves almost coincide; in the high concentration region, the model's prediction uncertainty is higher, which can be attributed to fewer high concentration data points in the training dataset.\nFurthermore, we used the model to predict the conductivity-temperature relationship at the concentration with the highest conductivity for both LiFSI/FAN and LiTFSI/FAN systems, as shown in Figure 5. Using only 1 data point-the room temperature data for retraining, the model successfully predicts the high ionic conductivity performance of the LiFSI/FAN system at low temperatures. We fit the model predictions for both systems using the Arrhenius relationship, obtaining ln(\u03c3) = -0.698 \u00d7 (\\(\\frac{1000}{T}\\)) + 5.962 (R2 = 0.983) for LiFSI/FAN and ln(\u03c3) = -1.131 \u00d7 (\\(\\frac{1000}{T}\\)) + 6.797 (R2 = 0.994) for LiTFSI/FAN. This indicates that the model effectively learns the Arrhenius relationship of conductivity with temperature from the original dataset and successfully transfers this knowledge to the FAN system.\nIn summary, Uni-ELF demonstrates the ability to effectively integrate physical modeling and publicly available experimental data to achieve accurate predictions of molecular and formulation-level properties. This predictive accuracy enabled the model to independently rediscover high-performing molecules like FAN, underscoring Uni-ELF's potential in advancing electrolyte design. Furthermore, the capability of Uni-ELF to perform few-shot learning suggests its potential for low-cost, efficient optimization of high-dimensional formulation spaces, presenting a promising avenue for future integration into robotic automated experimentation."}, {"title": "5. Conclusion and Outlook", "content": "In this work, we have introduced Uni-ELF, a multi-level representation learning framework designed to advance the formulation and optimization of electrolytes for lithium batteries. By leveraging a two-stage pretraining approach-reconstructing three-dimensional molecular structures using the Uni-Mol model and predicting statistical structural properties from molecular dynamics simulations-we have demonstrated significant improvements in predictive capabilities for both molecular and formulation properties.\nOur results show that Uni-ELF outperforms current state-of-the-art methods in predicting key properties such as melting point, boiling point, synthesizability, conductivity, and Coulombic efficiency. Notably, Uni-ELF can be seamlessly integrated into an automatic experimental design workflow, bridging the gap between computational predictions and experimental validation.\nLooking forward, the methodology presented here holds promise for broader applications beyond electrolyte design. For example, this approach could be extended to other areas requiring formulation-level prediction or generation, such as the design of pharmaceuticals and the extraction of formulation information from spectral data. We are optimistic that further refinement and validation of this framework will enhance its utility and impact across various scientific and engineering domains."}, {"title": "Data and Code Availability", "content": "Data and code used in this work will be made publicly available after the paper is published. For trial use of Uni-ELF, please refer to the Bohrium App at https://bohrium.dp.tech/apps/uni-elf."}, {"title": "Conflict of Interests", "content": "DP Technology holds intellectual property rights pertinent to the research presented herein."}, {"title": "Supplementary Information", "content": "Formulation-Level Model Architecture\nThe Uni-ELF backbone consists of three main parts: the temperature embedding block, the formulation transformer encoder, and the molecular pair RDF block (see Figure 1(c)).\nTemperature Embedding Block: The temperature input is transformed using a Gaussian kernel followed by layer normalization51. The Gaussian kernel embeds the temperature value into a 256-dimensional feature utilizing 512 Gaussian basis functions, with a nonlinear projection reducing the dimensionality from 512 to 256. The means and standard deviations of these Gaussian basis functions are initialized uniformly between -80 and 150, and 0 and 230, respectively. Subsequently, layer normalization stabilizes the temperature embeddings' means and variances, ensuring a stable distribution for further processing.\nFormulation Transformer Encoder: The formulation transformer encoder integrates molecular representations with their corresponding normalized molar ratios. Initially, the molecular representations are scaled by their normalized molar ratios. These scaled representations are then fed into a multi-head attention layer52, which employs 64 attention heads to compute interaction scores between the input features. Each attention head has a dimension of 8, resulting in a total embedding dimension of 512. The output from the attention mechanism is then normalized using layer normalization and combined with the input of the attention layer via a residual connection53. Following this, a feedforward network comprising two linear layers is applied. The first linear layer expands the input dimension from 512 to 2048. The output of this layer is activated using a GELU function41 and then mapped back to 512 dimensions by the second linear layer. The feedforward network's output undergoes another layer normalization and is added to its input through an additional residual connection. After three such layers, the refined molecular representations are aggregated by weighted summation and concatenated with the temperature embeddings to form the final formulation representation.\nMolecular Pair RDF Block: During pretraining, the molecular pair RDF block refines the formulation representation by incorporating radial distance information. The radial distance is encoded using another Gaussian kernel, which transforms the distance into 128 Gaussian basis functions with means and standard deviations uniformly initialized between 0 and 1.5. A nonlinear layer further reduces the 128-dimensional encoding to a 64-dimensional radial distance embedding, followed by layer normalization. The molecular pair representation, which has 64 dimensions corresponding to the number of attention heads, is then concatenated with the radial distance embeddings. This combined representation is fed into a linear layer with an input dimension of 128 (64 from the molecular pair representation and 64 from the radial distance embeddings) and an output dimension of 128. The output of this linear layer is activated using a tanh function42 to introduce non-linearity. Finally, a second linear layer maps these 128-dimensional features to a single scalar value, representing the RDF prediction for a molecular pair.\nFormulation-Level Pretraining\nFor the electrolyte systems used in pretraining, we select classic binary mixtures of linear carbonate and cyclic carbonate solvents. The linear carbonates include ethylmethyl carbonate (EMC), dimethyl carbonate (DMC), and diethyl carbonate (DEC), while the cyclic carbonates consist of ethylene carbonate (EC) and propylene carbonate (PC). For each type of solvent component, one molecule is selected, and five points are uniformly generated within the molar fraction range of 0-1. At each grid point, random perturbations are applied within a molar fraction range of 0.15. The lithium salts used are either lithium hexafluorophosphate (LiPF6) or lithium bis(fluorosulfonyl)imide (LiFSI), with salt molality chosen as 0.5, 1.0, and 1.5 mol/kg solvent, resulting in 180 formulations for classical molecular dynamics simulations.\nEach formulation contains up to four types of molecules or ions (with the salt split into cations and anions), resulting in up to ten pairs of molecular RDFs. Each pair of molecular RDFs includes approximately 900 data points (r, g(r)) within the range of radial distance r from 0 to 2.0 nm, ultimately generating a dataset of approximately 160,000 data points. For the purpose of learning the inter-molecular interactions in the pretraining procedure, all inner-molecular contributions of RDFs are ignored. The dataset is split into training, validation, and test sets in a ratio of 8:1:1 for pretraining. The model is trained to minimize the RMSE between the predicted and true RDFs."}, {"title": "Details of Molecular Dynamics Simulations", "content": "The Molecular Dynamics (MD) simulations of electrolyte formulations were carried out using GROMACS54 package. Parameters of Generated Amber force field (GAFF) for all electrolyte solutes and solvents were obtained using Antechamber55 in Ambertools23 package and ACPYPE software56. Atomic partial charges were generated via RESP scheme as follows: All molecules are optimized in B3LYP/6-311g(d,p) DFT level using Gaussian 16 software57, where solvent effect is introduced using PCM method. Then, RESP charges are fitted from the optimized geometry and wave function using Multiwfn software 58.\nAll electrolyte molecules were put intis used for possible pressure control. The particle-mesh Ewald (PME) method is used for electrostatics. Atoms linking with hydrogen atoms are restrained by LINCS algorithm.\nThe systems are firstly equilibrated at 298 K, 1000 atm in NPT ensemble for 200 ps with a time step of 2 fs to reach a reasonable density. A further pre-equilibrium process of 95000 ps in total is conducted, which is consisted of several simulated annealing processses and NPT processes. After the pre-equilibrium process, the systems are adjusted to the average density for the generation of a 5000 ps trajectory files in NVT ensemble. The details of simulation settings are listed in Table 1.\nThe radial distribution functions (RDFs) were calculated using GROMACS, ranging from 0 to the radius of the simulation box with a bin width of 0.002 nm. For components A and B, the RDF between them is computed using the following equation:\n\\(g_{AB}(r) = \\frac{\\langle \\rho_B(r) \\rangle}{\\langle \\rho_B \\rangle_{local}} = \\frac{1}{4\\pi r^2} \\frac{1}{N_A N_B} \\sum_{i \\in A} \\sum_{j \\in B} \\delta(r_{ij} - r)\\)\nwhere \\(g_{AB}(r)\\) is the radial distribution function between components A and B at a distance r, \\(\\langle \\rho_B(r) \\rangle\\) is the average local density of component B at distance r from a particle of component A, \\(\\langle \\rho_B \\rangle_{local}\\) is the particle density of type B averaged over all spheres around particles A with radius \\(r_{max}\\), \\(N_A\\) is the number of particles of component A, \\(N_B\\) is the number of particles of component B, \\(r_{ij}\\) is the distance between particle i of component A and particle j of component B, and \\(\\delta(r_{ij} - r)\\) is the Dirac delta function, which is 1 when \\(r_{ij} = r\\) and 0 otherwise."}, {"title": "Details of the Downstream Tasks", "content": "The experimental evaluation methods vary among the different approaches we compare. To ensure fair comparisons, we align our evaluation settings as closely as possible with those of the compared methods, particularly in the way training and test sets are divided. If the original method provides specific training and test sets, we use those. If only the division ratio is stated, we split the data using three random seeds and report the average metrics of three test results. During training, we employ five-fold cross-validation to enhance the robustness of the model. In each fold, the model undergoes training for 200 epochs, selecting the checkpoint demonstrating optimal performance on the validation set. The final model combines the predictions from the five models trained in each fold, averaging these predictions to determine the performance metrics. The comparison results are listed in Table 5.\nMelting Point Predicting the melting point has long been a challenging task in cheminformatics59. The highest quality dataset available, to the best of our knowledge, is the 2014 Jean-Claude Bradley Open Melting Point Dataset60, which comprises 19,933 entries and 28,645 measurement records, some of which are marked as erroneous."}]}