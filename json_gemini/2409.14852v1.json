{"title": "FUSED-Net: Enhancing Few-Shot Traffic Sign Detection with Unfrozen Parameters, Pseudo-Support Sets, Embedding Normalization, and Domain Adaptation", "authors": ["MD. ATIQUR RAHMAN", "NAHIAN IBN ASAD", "MD. MUSHFIQUL HAQUE OMI", "MD. BAKHTIAR HASAN", "SABBIR AHMED", "MD. HASANUL KABIR"], "abstract": "Automatic Traffic Sign Recognition is paramount in modern transportation systems, motivating several research endeavors to focus on performance improvement by utilizing large-scale datasets. As the appearance of traffic signs varies across countries, curating large-scale datasets is often impractical; and requires efficient models that can produce satisfactory performance using limited data. In this connection, we present 'FUSED-Net', built-upon Faster RCNN for traffic sign detection, enhanced by Unfrozen Parameters, Pseudo-Support Sets, Embedding Normalization, and Domain Adaptation while reducing data requirement. Unlike traditional approaches, we keep all parameters unfrozen during training, enabling FUSED-Net to learn from limited samples. The generation of a Pseudo-Support Set through data augmentation further enhances performance by compensating for the scarcity of target domain data. Additionally, Embedding Normalization is incorporated to reduce intra-class variance, standardizing feature representation. Domain Adaptation, achieved by pre-training on a diverse traffic sign dataset distinct from the target domain, improves model generalization. Evaluating FUSED-Net on the BDTSD dataset, we achieved 2.4\u00d7, 2.2\u00d7, 1.5\u00d7, and 1.3\u00d7 improvements of mAP in 1-shot, 3-shot, 5-shot, and 10-shot scenarios, respectively compared to the state-of-the-art Few-Shot Object Detection (FSOD) models. Additionally, we outperform state-of-the-art works on the cross-domain FSOD benchmark under several scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "Traffic sign recognition plays a crucial role in enhancing road safety, supporting autonomous vehicle technology, and assisting in efficient driving [1]. However, interpreting traffic signs in real-time can be challenging because of issues such as environmental factors, distance, and limited visibility [2], which can lead to misrecognition and potentially catastrophic accidents [3]. To mitigate these risks, Advanced Driver Assistance Systems [4] and Automated Driving Systems [5] have been developed in the literature, with traffic sign detection being a key component of their functionality. Hence, accurate traffic sign detection is vital for the effective operation of these systems, especially in real-world conditions.\nOver the years, traffic sign detection systems have evolved from manually engineered features to Deep Learning (DL)- based methods, particularly Convolutional Neural Networks (CNNs) [6]. These methods are generally categorized into two categories: one- and two-stage detectors [7]. One-stage detectors such as YOLO [8] treat sign detection as a regression problem. Here, a single convolutional network simulta-"}, {"title": "II. RELATED WORKS", "content": "Few-Shot Object Detection (FSOD) has emerged as a critical research area due to the growing need for models that can effectively detect objects with minimal labeled data [15]. As traditional object detection methods typically require large- scale annotated datasets to achieve high performance, FSOD seeks to overcome this limitation by enabling models to generalize well even when only a few instances of the target objects are available.\nThe literature on FSOD is extensive and diverse, with several approaches being proposed and refined over the years. According to [19], FSOD techniques can be broadly catego- rized into three primary categories: transfer learning-based, meta-learning-based, and metric learning-based approaches. Transfer learning in FSOD leverages a pre-trained network's\nUnlike conventional few-shot object detection models that selectively freeze parameters during training, we propose an architecture where the entire network re- mains unfrozen throughout the training process. This approach allows the model to fully adapt to the lim- ited number of available samples, enabling more robust learning and representation extraction from the few ex- amples in the target domain.\nTo mitigate the challenge of data scarcity inherent in few-shot learning, we leverage a novel technique called pseudo-support sets that are generated by applying data augmentation techniques to the few available labeled samples per class. This approach not only increases the diversity of the training data but also significantly en- hances the model's detection performance by compen- sating for the limited sample size in the target domain.\nWe incorporate a cosine similarity-based classifier in our architecture to implement Embedding Normaliza- tion (EN). By reducing intra-class variance, EN ensures that the feature representations of traffic signs are more standardized and consistent across the limited number of samples. This improves the model's ability to differen- tiate between subtle class differences, leading to more precise detection and classification.\nWe enhance the generalization capability of the pro- posed architecture through a Domain Adaptation strat- egy. By pre-training the model on a diverse traffic sign dataset that is distinct from the target query set, we enable the model to better adapt to the specific character- istics of the target domain. This approach significantly boosts performance on datasets with minimal overlap between the training and test domains, proving crucial for cross-domain few-shot detection tasks.\nThe remainder of this paper is organized as follows. In Section II, we review the relevant literature, focusing on exist- ing approaches to Few-Shot Traffic Sign Detection and Few- Shot Object Detection in general, highlighting the current challenges and limitations. Section III presents our proposed FUSED-Net, detailing the baseline and the modifications made to the Faster R-CNN framework. In Section IV, we conduct extensive experiments on multiple datasets demon- strating the performance of FUSED-Net in various few-shot scenarios and compare the results with the state-of-the-art FSOD models. We also discuss the effectiveness of our key contributions and cross-domain generalization performance. Section V concludes the paper, summarizing our findings and offering directions for future research in few-shot traffic sign detection."}, {"title": "III. PROPOSED METHODOLOGY", "content": "Our proposed framework is built upon Faster R-CNN, pre- trained on the MS COCO dataset [32], due to its established robustness in object detection tasks [33]. Recognizing the challenges inherent in few-shot traffic sign detection, we introduced several key modifications to adapt Faster R-CNN for this specialized task. These modifications are designed to enhance the model's ability to generalize from a small number of examples, a crucial capability for effective few- shot learning.\nWe employ a few key strategies: keeping the entire network unfrozen to allow all layers to adapt to the new data and creating a pseudo-support set through data augmentation, which increases the diversity of the training data and enhances the model's resilience to real-world variations. Again, we replace the original classifier with a cosine similarity-based classifier to enable embedding normalization that enhances generalization from limited training samples by focusing on intrinsic relationships between instances and classes. This approach mitigates high intra-class variance, which is particu- larly challenging in few-shot scenarios. Furthermore, we fine- tune the entire network end-to-end using the MTSD dataset to ensure that the learned features are specifically tailored to the characteristics of traffic signs, which differ from those of general objects in the COCO dataset. Finally, we evaluate the performance of FUSED-Net on the target dataset across various few-shot scenarios (1, 3, 5, and 10-shot) to ensure that it is well-suited to the specific challenges of traffic sign detection in a data-scarce environment.\nTo thoroughly understand the strategies we leveraged to adapt Faster R-CNN for few-shot traffic sign detection, it is crucial to first grasp the architecture of Faster R-CNN and its evolu- tion from earlier models. The foundation of Faster R-CNN lies in the progression from RCNN (Region-based Convo- lutional Neural Network) [34] to Fast R-CNN [35], each of which introduced key innovations in object detection.\nFast R-CNN [35] addressed these inefficiencies by intro- ducing the Region of Interest (ROI) pooling layer, which al- lowed for the extraction of fixed-size feature vectors directly from a shared feature map. This innovation enabled all region proposals to share computation, significantly speeding up the process. Furthermore, Fast R-CNN eliminated the need for caching features on disk, as it could process all proposals within a single forward pass through the network, thereby streamlining the object detection pipeline.\nBuilding on Fast R-CNN, Faster R-CNN [11] introduced the Region Proposal Network (RPN), a fully convolutional\nIn modern implementations, Faster R-CNN typically em- ploys deep neural networks like ResNet [39] or VGG [40] as the backbone for feature extraction, often enhanced with a Feature Pyramid Network (FPN). These backbones are cru- cial for generating robust, multi-scale feature representations, which are particularly important in detecting objects that vary in size and shape. The integration of the FPN allows the network to exploit features at multiple scales, improving detection accuracy for small and large objects alike.\nGiven the widespread success of Faster R-CNN in various object detection tasks [41]\u2013[44], many FSOD frameworks [11], [20], [27]\u2013[29], including our own, are built upon this architecture. Specifically, our approach uses a variant of"}, {"title": "B. UNFROZEN PARAMETERS", "content": "When training deep learning models, it is common practice to 'freeze' certain layers, especially when fine-tuning a pre-trained model on a new task [45]. Freezing layers means that the weights of those layers are kept constant during the training process, and only the weights of the unfrozen layers are updated. This technique is particularly useful when the new task is similar to the original task the model was trained on, as it helps retain the learned features while allowing the model to adapt to the new task with minimal computational overhead [34], [46], [47].\nHowever, in the context of cross-domain tasks, few-shot traffic sign detection in particular, the target domain (e.g., traffic signs from a specific region or country) can be sig- nificantly different from the base domain (e.g., general object detection on datasets like MS COCO) representing unique en- vironmental challenges [39], [48], [49]. In such cases, freez- ing layers can be counterproductive, as it limits the model's ability to learn new features that are crucial for accurately detecting and recognizing objects in the target domain. The frozen layers may still carry biases and features specific to the base domain, leading to suboptimal performance when the model is applied to the target domain [50].\nTo overcome this limitation, we chose to keep the entire ar- chitecture unfrozen during the fine-tuning stage. This means that all components of our detector, including the Backbone, Region Proposal Network (RPN), Feature Pyramid Network (FPN), and fully connected layers, are updated during train- ing. By allowing every part of the network to adapt, we ensure that the model can learn new, domain-specific fea- tures that are essential for detecting traffic signs in different environments. This approach contrasts with the conventional method of freezing certain layers and allows our model to better handle the significant differences between the base and target domains. As a result, our model demonstrates improved adaptability and accuracy in the target domain."}, {"title": "C. PSEUDO SUPPORT SETS (PSS)", "content": "In FSOD, the limited availability of labeled training data presents a significant challenge in developing robust models. To address this, data augmentation is a common technique used to enhance the diversity and variability of the training data. In our methodology, we implemented a data augmen- tation strategy during the fine-tuning stage by generating a 'Pseudo-Support Set (PSS)' by augmenting the original support set. The creation of this pseudo-support set involves applying random Color Jitter to each sample in the original support set. Color Jitter is a data augmentation technique that randomly alters the brightness, contrast, saturation, and hue of an image. These specific transformations were cho- sen because they closely mimic the kinds of variations that are commonly encountered in real-world scenarios, such as changes in lighting conditions, different times of the day, weather conditions, and even camera settings. Brightness adjustment simulates conditions ranging from very bright, sunny environments to dim, overcast scenarios. Contrast al- teration affects the differentiation between light and dark areas in an image, allowing the model to recognize objects in both high-contrast situations like strong shadows, and low- contrast environments like foggy weather. Saturation changes the intensity of colors, helping the model learn to detect traffic signs that might appear more muted or vividly colored due to different camera sensors or environmental conditions. Hue adjustment shifts the overall color balance of the image, which can account for the color variances caused by different lighting sources (e.g., fluorescent vs. natural light).\nBy creating PSS through this augmentation process, we introduce a broader range of visual characteristics into the training data. The PSS, which combines the original samples with their augmented versions, provides the model with a richer and more varied dataset. This helps the model learn to recognize patterns under diverse conditions, improving its generalization ability and reducing the risk of overfitting to the limited original data.\nThis approach also enhances the model's robustness, mak- ing it less sensitive to slight changes in input data that could lead to misclassification. By training on the pseudo-support set, the model becomes better equipped to handle the un- predictable variations it will encounter in real-world traffic sign detection tasks, ensuring more reliable and accurate performance across different environments."}, {"title": "D. EMBEDDING NORMALIZATION (EN)", "content": "Embedding Normalization (EN) is a key component of our proposed method, especially in the context of few-shot learn- ing, where the challenge of high intra-class variance be- comes particularly pronounced [20]. In few-shot scenarios, the model is trained on a limited number of examples, which can lead to significant variation in feature representations within the same class. This variance often results in a model that is overly sensitive to outliers, thereby compromising its generalization ability. To mitigate this issue, we implemented EN to standardize the feature representations of individual instances. This standardization process ensures that the fea- tures extracted from each instance are on a comparable scale, regardless of the inherent differences in the dataset. By reduc- ing the intra-class variance, the model becomes more robust to variations within the same class, which is essential in few- shot learning where such differences can otherwise lead to misclassifications. The normalization technique plays a piv- otal role in aligning the features more closely, making it easier for the classifier to distinguish between different classes even when only a few examples are available for training.\nTo incorporate EN, we integrated a cosine similarity-based classifier into our model. This classifier focuses on the an-"}, {"title": "E. DOMAIN ADAPTATION", "content": "In traditional machine learning, it is generally assumed that the training and testing datasets originate from the same fea- ture space and follow similar joint probability distributions. This assumption is critical for ensuring that the model gen- eralizes well from the training data to unseen test data. How- ever, in many real-world scenarios, this assumption is often violated. For instance, in tasks such as traffic sign detection, the training data may consist of images collected in one coun- try, while the test data could come from a different country with different types of signs, environmental conditions, and even visual styles. This discrepancy in data distribution can lead to a significant drop in the model's performance when applied to new, unseen data.\nTo address this challenge, the concept of domain adaptation has been introduced in the field of machine learning [51]. Domain adaptation is a subset of transfer learning that specif- ically aims to reduce the distributional differences between a source domain (training data) and a target domain (test data). The primary objective is to enable the model to generalize effectively to the target domain, despite the differences in feature distributions.\nIn our approach, we employ domain adaptation by training our model on traffic signs from different countries, thereby exposing it to a diverse set of visual features and styles. This diverse training data helps minimize the distributional discrepancy between the base domain (e.g., traffic signs in the training dataset) and the target domain (e.g., traffic signs from another country with limited data). By leveraging this approach, our model becomes more generalized and robust, capable of accurately detecting and recognizing traffic signs across different domains. The effectiveness of this strategy is reflected in the improved performance of our model, which we will discuss in the results section."}, {"title": "IV. RESULTS & DISCUSSION", "content": "In this section, we present a comprehensive analysis of our proposed FUSED-Net framework, focusing on the datasets used, implementation details, ablation study, error analysis, and performance comparisons with state-of-the-art models. We introduce the Merged Traffic Sign Detection Dataset (MTSD) and the Bangladeshi Traffic Sign Detection Dataset (BDTSD) to highlight the diverse and challenging conditions under which our model was trained and tested. We also dis- cuss our implementation within the Detectron2 framework, detailing the hyperparameters and experimental environment. We follow that up with an ablation study showing the in- cremental benefits of each component in our model, while performance comparisons underscore FUSED-Net's superi- ority over other models in various few-shot traffic sign de- tection scenarios. Finally, we provide qualitative and cross- domain performance analyses, demonstrating the robustness and adaptability of FUSED-Net in real-world and cross- domain settings."}, {"title": "A. DATASETS", "content": "One of our primary objectives in constructing MTSD was to maximize the variation in the samples. To achieve this, we selected datasets from two different continents: Europe\nThe BDTSD dataset was specifically chosen as the target dataset for both our ablation studies and performance compar- isons with other state-of-the-art architectures. This decision was driven by its distinctiveness compared to the datasets used to compile MTSD. While the datasets in MTSD contain more standardized samples, BDTSD reflects the real-world variability and complexity found in Bangladeshi traffic sign scenarios. The aforementioned challenges such as occlusion by other vehicles or objects, signs captured at various dis- tances and angles, and the presence of environmental con- ditions like rain or fog, can significantly affect the clarity of the signs. Given these unique challenges, BDTSD pro- vides a rigorous testing ground to evaluate the generalization capabilities of our model. By using BDTSD as the target dataset, we ensure that our model is tested against a broad spectrum of conditions, allowing us to assess its robustness and adaptability to real-world situations."}, {"title": "B. IMPLEMENTATION DETAILS", "content": "Our proposed framework, FUSED-Net, leverages a variant of Faster R-CNN that is seamlessly integrated within the Detectron2 framework. Specifically, we employ ResNet-101 in combination with a Feature Pyramid Network (FPN) as the backbone of the architecture, ensuring robust multi-scale feature extraction. For optimization, we utilized the standard Stochastic Gradient Descent (SGD) solver with a momentum of 0.9, accompanied by a weight decay parameter of $10^{-4}$ to prevent overfitting. Data augmentation was a critical aspect of our implementation, and we applied color jitter with an 0.8 probability using the transformations provided by the torchvision library [58], enhancing the diversity and resilience of the training data.\nIn our experimental setup, we benchmarked our framework against several state-of-the-art architectures, including TFA w/cos, A-RPN, DeFRCN, FRCN-ft, and CD-FSOD. During the initial trials, we encountered NAN/INF bounding box errors, which arose due to the constraints imposed by our single GPU environment. These issues were linked to the original configurations of the SOTA architectures, which were not directly compatible with our computational setup. The Detectron2 framework provided a solution to this chal- lenge by recommending adjustments to the base learning rate and batch size according to the number of available GPU devices. To ensure that all comparisons were fair and consis- tent, we standardized the experimental conditions across all architectures, setting the batch size to 2 and the base learning rate to 0.0025. Aside from these adjustments, we adhered closely to the standard Faster R-CNN configuration as pro- vided by the Detectron2 framework to implement FUSED- Net. To maintain impartiality in the performance comparison of FUSED-Netwith other SOTA architectures, we have used 11% of the total data available in BDTSD [18] as the query set. We have utilized COCO-style average precision (AP). This measurement is taken over several thresholds, from 0.5 to 0.95, with a step size of 0.05.\nFor transparency and to facilitate future research, all code related to our implementation, including the modifications necessary for each architecture, will be made publicly avail- able on GitHub upon acceptance of this manuscript."}, {"title": "C. ABLATION STUDY", "content": "To assess the contribution of the individual components of FUSED-Net, we conducted an ablation study. The study was performed on BDTSD across 1-shot, 3-shot, 5-shot, and 10- shot scenarios. Our model integrates four key modifications: unfrozen parameters, pseudo-support set, embedding nor- malization, and domain adaptation. The results, presented in Table 1, demonstrate the incremental improvements each modification contributes to the overall system performance, measured by mAP.\nThe decision to unfreeze all layers of our architecture during fine-tuning stage played a pivotal role in improving cross- domain detection accuracy. Unlike conventional practices where certain layers are frozen to retain pre-trained knowl- edge, our approach allows every layer-from the Backbone to the Region Proposal Network, Feature Pyramid Network, and fully connected layers-to adjust its weights. This flex- ibility is helpful in scenarios where the target domain (e.g., Bangladeshi Traffic Signs) is significantly different from the base domain (e.g., general object detection datasets). As a result, the model can learn new, domain-specific features that are essential for detecting traffic signs under diverse conditions. The ablation study reveals that unfreezing the parameters alone provides a moderate boost in performance, yielding an 11.2 mAP in the 1-shot scenario, and continues to enhance performance as more shots are introduced.\nTo overcome the challenge of limited training data inherent in FSL, we introduced a pseudo-support set through data augmentation. By applying random color jitter to the original support set, we created a richer, more diverse dataset that better represents the variability encountered in real-world scenarios. This approach proved to be particularly effective, as evident from the performance gains. For example, the addition of the pseudo-support set increased the mAP by 1.0% in the 1-shot scenario and by a more pronounced 3.7% in the 10-shot scenario. The augmented support set allowed the model to generalize more effectively, improving its ability to detect traffic signs despite the limited number of examples available for training.\nIncorporating embedding normalization further refined our model's ability to handle high intra-class variance. By stan- dardizing the feature representations of individual instances, our approach reduces the impact of outliers and ensures that features are comparable across different instances. This nor- malization is enabled by a cosine similarity-based classifier, which focuses on the angular relationships between feature vectors, thereby reducing the influence of magnitude differ- ences. The results shown in Table 1 highlight the significant improvement this modification brings, particularly in 10-shot scenarios, where mAP increased by 4.6% compared to the baseline. This demonstrates the effect of embedding normal- ization in enhancing the model's robustness and generaliza- tion capabilities.\nDomain adaptation had the most significant impact on our model's performance. By training the model on traffic signs from diverse countries, we reduced the distributional variance between the source and target domains. This strategy was crucial in enabling the model to generalize effectively across different environments. The results in Table 1 underscore the effectiveness of domain adaptation, showing a dramatic increase in mAP across all shot scenarios. Even in the 1-shot scenario, the mAP jumps by 18.2% compared to the baseline. It remains substantial across higher-shot scenarios, demon- strating the effectiveness of this technique in addressing the challenges posed by domain discrepancies."}, {"title": "D. PERFORMANCE COMPARISON WITH THE STATE-OF-THE-ART IN FEW-SHOT TRAFFIC SIGN DETECTION", "content": "As shown in Table 2, the performance of our proposed ar- chitecture was benchmarked against several state-of-the-art FSOD models on BDTSD across 1-shot, 3-shot, 5-shot, and 10-shot scenarios."}, {"title": "E. QUALITATIVE ANALYSIS", "content": "For the qualitative analysis, we evaluated our model's per- formance by fine-tuning it on the MTSD dataset and testing it with a 5-shot scenario from BDTSD. In Figs. 5 and 6, the green bounding boxes represent detections made by our model, while the blue bounding boxes denote the ground truth annotations. The labels above the blue boxes indicate the actual class labels, whereas the labels above the green boxes indicate the class labels predicted by our model. Note that, only detected boxes with confidence scores of 0.5 or higher are displayed.\nAs demonstrated in 5a, our model effectively detects traffic signs that are blurry and located at significant distances from the camera, a challenging scenario that often leads to detec- tion failures in other models. Additionally, 5b shows that our model can accurately detect and classify multiple traffic signs within a single image, even when they are positioned at varying distances and embedded in complex backgrounds. This ability to handle both single and multiple instances under challenging conditions underscores the robustness of our approach in real-world scenarios.\nHowever, our analysis also reveals areas for improvement. As shown in Fig. 6, while the model successfully detects traf- fic signs that are extremely distant and blurred, it sometimes fails to correctly classify them. This misclassification likely stems from the difficulty of discerning complex symbols on distant signs, a challenge even for human observers. This limitation suggests that although our model is effective in detection, the performance of the classifier could be enhanced by refining its ability to interpret subtle visual cues in chal- lenging contexts. Future work could focus on improving the sensitivity of the classifier to these complex visual patterns, especially in low-visibility conditions, to further enhance the overall performance of the model."}, {"title": "F. PERFORMANCE ANALYSIS ON CROSS-DOMAIN FEW-SHOT OBJECT DETECTION (CD-FSOD) BENCHMARK", "content": "To thoroughly assess the cross-domain performance of our proposed architecture, we conducted extensive experiments on the CD-FSOD benchmark, which evaluates models us- ing base datasets from one domain (MS COCO) and novel datasets from distinct domains (ArTaxOr, UODD, DIOR). The results of these experiments, as shown in Table 3, offer insights into the efficacy of our approach compared to the state-of-the-art (SOTA) FSOD models.\nAs discussed before, the traditional FSOD benchmarks, such as MS COCO and Pascal VOC, typically involve divid- ing data into base and novel sets drawn from the same domain. However, this does not reflect real-world applications where domain shifts are common. For instance, a model trained on natural images might need to detect objects in aerial or optical remote sensing images-domains with significantly different characteristics. Models fine-tuned within the same domain may perform well under such circumstances but often struggle when applied across domains. To identify whether it can excel in cross-domain settings, our proposed model, while originally intended for few-shot traffic sign detection, was subjected to rigorous testing on the CD-FSOD benchmark to evaluate its versatility. The results across 1-shot, 5-shot, and 10-shot scenarios on the ArTaxOr, UODD, and DIOR datasets consistently demonstrate our model's superior performance. Notably, our model achieves the highest average mAP across all datasets and shot settings (14.2), outperforming the lead- ing SOTA models, including CD-FSOD which introduced the benchmark.\nSOTA architectures, such as TFA w/cos, A-RPN, FSCE, Metha-RCNN, H-GCN, and DeFRCN, involve freezing cer- tain components during fine-tuning, which may stabilize the model within the same domain but often leads to poor per- formance in cross-domain settings. The data clearly shows that models with frozen components struggle with signifi- cant domain shifts, achieving lower mAPs across the board. For instance, TFA w/cos only achieved a 7.2 average mAP, reflecting its limited adaptability when faced with diverse domains.\nAlthough FRCN-ft and CD-FSOD do not freeze any com- ponents, our model surpasses them in average performance. The performance disparity with FRCN-ft stems from its re- liance on a limited number of labeled samples during fine- tuning, which hampers its ability to generalize in FSL. This scarcity leads to inadequate learning of novel classes, espe- cially in complex domains such as the CD-FSOD benchmark, resulting in suboptimal performance. In contrast, our model utilizes a pseudo-support set technique to amplify the data available during fine-tuning by generating additional samples from labeled data. This broader data exposure allows our model to learn more robust features, enhancing generalization and reducing overfitting, leading to superior performance.\nOur proposed FUSED-Net model even surpasses the aver- age performance of CD-FSOD, which was designed specif- ically for cross-domain scenarios. This success can be at- tributed to FUSED-Net's straightforward yet effective train- ing strategy. Unlike CD-FSOD, which employs a complex two-model system with adaptive learning based on augmenta- tions, our approach uses a single model trained with a pseudo- support set. This method not only simplifies the training process but also enhances generalization by effectively in- creasing the data supply during fine-tuning.\nIn conclusion, our model FUSED-Net demonstrates out- standing performance in cross-domain FSOD, surpassing current SOTA architectures in terms of average mAP. This achievement, coupled with the model's simplicity and robust- ness, positions our approach as a highly effective solution for real-world FSOD tasks, even in scenarios involving signifi- cant domain shifts."}, {"title": "V. CONCLUSION", "content": "In this work, we presented FUSED-Net, a novel Few-Shot Traffic Sign Detector, designed to address the challenges of traffic sign detection in scenarios with limited labeled data. Our model integrates domain adaptation and a pseudo- support set to significantly enhance the detection accuracy of traffic signs, where state-of-the-art methods often falter. Both approaches can be seamlessly incorporated into existing detection architectures without disrupting the training pro- cess, offering practical solutions to the data scarcity problem in traffic sign detection in remote areas. We also examined the limitations of freezing model components, a common practice in current SOTA architectures, which we found to be detrimental in few-shot detection tasks. By allowing for greater adaptability through unfrozen parameters, combined with embedding normalization, FUSED-Net demonstrates superior generalization capabilities across diverse domains. Our work not only advances the field of few-shot traffic sign detection but also highlights the importance of adaptable model components and domain-aware techniques in over- coming the challenges of few-shot learning. We hope this work inspires further innovation and exploration in few-shot learning, particularly in specialized domains like traffic sign detection, where data availability is often limited."}]}