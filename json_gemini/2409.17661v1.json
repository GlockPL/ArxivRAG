{"title": "A Fuzzy-based Approach to Predict Human\nInteraction by Functional Near-Infrared Spectroscopy", "authors": ["Xiaowei Jiang", "Liang Ou", "Yanan Chen", "Na Ao", "Yu-Cheng Chang", "Thomas Do", "Chin-Teng Lin"], "abstract": "The paper introduces a Fuzzy-based Attention (Fuzzy\nAttention Layer) mechanism, a novel computational approach\nto enhance the interpretability and efficacy of neural models\nin psychological research. The proposed Fuzzy Attention Layer\nmechanism is integrated as a neural network layer within the\nTransformer Encoder model to facilitate the analysis of complex\npsychological phenomena through neural signals, such as those\ncaptured by functional Near-Infrared Spectroscopy (fNIRS). By\nleveraging fuzzy logic, the Fuzzy Attention Layer is capable\nof learning and identifying interpretable patterns of neural\nactivity. This capability addresses a significant challenge when\nusing Transformer: the lack of transparency in determining\nwhich specific brain activities most contribute to particular\npredictions. Our experimental results demonstrated on fNIRS\ndata from subjects engaged in social interactions involving\nhandholding reveal that the Fuzzy Attention Layer not only\nlearns interpretable patterns of neural activity but also enhances\nmodel performance. Additionally, the learned patterns provide\ndeeper insights into the neural correlates of interpersonal touch\nand emotional exchange. The application of our model shows\npromising potential in deciphering the subtle complexities of\nhuman social behaviors, thereby contributing significantly to the\nfields of social neuroscience and psychological AI.", "sections": [{"title": "I. INTRODUCTION", "content": "HUMAN Interaction Behaviour emerges at the confluence\nof psychology, engineering and artificial intelligence,\nmarking a developing yet pivotal field aimed at decoding the\nintricate dynamics of human social behaviors. This domain tra-\nditionally harnesses psychological and neuroscientific theories\nto explore the nuances of individual interactions and emotional\nbonds [1-7] and be applied to robotics [8]. In this context,\na focal point of non-verbal communication is interpersonal\ntouch [1, 2], specially handholding, which originates as the\nforemost sensory channel during prenatal development [9]\nand persists as a crucial medium for expressing intentions\nand emotions in adulthood [10, 11]. The profound impact of\ntouch is evidenced in its essential role across diverse social\nfunctions-ranging from flirtation and dominance assertion\nto comfort and caregiver-child bonding-thereby enriching\nsocial exchanges with emotional depth and fostering feelings of\nsupport, calmness, trust, and security among close individuals\n[12].\nDespite its rich theoretical reinforcements, the field has\nprimarily employed methods with limited capacity to validate\nimperfect theoretical claims, thus presenting a significant\nchallenge in demonstrating foundational assumptions [13\u201315].\nExplainable AI (xAI) has recently been developed to elucidate\nthe results of supervised machine learning models [16]. The\nadvent of xAI introduces innovative methods for analyzing and\ninterpreting high-dimensional data, such as neural responses,\noffering a promising avenue for integrating psychological\ntheories and neuroscientific insights within social cognitive\nand affective neuroscience-a venture that remains largely\nuntapped.\nSeveral popular xAI methods include perturbation-based\napproaches [17], which perturb features and observe prediction\nchanges, and Local Interpretable Model-Agnostic Explanations\n(LIME) [18], which analyzes changes in individual predic-\ntions based on input variations. LIME generates interpretable\nindications of each feature's contribution by controlling the\nfeature value in a single input. Deep Learning Important\nFeaTures (DeepLIFT) [19] explains output predictions by\nback-propagating neuron contributions in a neural network,\nusing a partial derivative-like function with the chain rule to\ncalculate feature importance scores. SHAP (SHapley Additive\nexPlanations) [20] uses Shapley values from game theory to\nexplain model outputs, detailing each feature's contribution.\nDeepSHAP [21] combines SHAP values and DeepLIFT to\nassess feature significance through linear composition rules\nand backpropagation. However, these methods have drawbacks,\nsuch as sensitivity to minor changes causing instability [22]\nand high computational complexity.\nIn neuroscience and psychology, explaining a theory involves\nelucidating the underlying mechanisms and processes that\naccount for observed behaviors and phenomena. Traditional\nmethods, like t-tests or ANOVA, can describe differences\nbetween groups, while the General Linear Model (GLM)\nis another popular approach for analyzing neural signals.\nHowever, these methods cannot accurately describe the data\nat an individual level, as they only yield group-level results.\nTo overcome these limitations and achieve more precise and\nindividualized insights, advanced techniques such as machine\nlearning and xAI are increasingly being utilized [23-25].\nFor instance, EEGNet [26] designs a CNN-based model and\nexplains frequency and space features using kernels in different\nlayers. Another example is based on fNIRS [27], which\ncombines CNN and LSTM as feature extractors and then"}, {"title": "II. RELATED WORK", "content": "Over the past decade, significant advances have been made in\nbrain decoding, particularly in the realm of human interactions.\nResearch in this area generally falls into two categories: verbal\nand non-verbal communication. Earlier studies focused on the\nevolution of spoken language, exploring the connection between\nsemantic features and neural activities [36]. Pioneering work"}, {"title": "B. Fuzzy Inference Systems", "content": "Rooted in Fuzzy Logic, Fuzzy Inference Systems (FISs),\nparticularly the Takagi-Sugeno\u2013Kang (TSK) inference system,\nhave collaborated with state-of-the-art AI technology and\nyielded significant advances [28]. FISs are composed of several\nIF-THEN rules, as follows:\nIf x is \u03bcr, Then the output is ur, (1)\nwhere x denotes the input variable, \u03bcr is the firing strength\nof fuzzy set r, and ur is the output of rule r. The \u03bcr in\nTSK is calculated using the product of Gaussian membership\nfunctions:\n\u03bcr(x)=\u220fdexp\u2061((\u221212(xd\u2212md,r\u03c3d,r)2)). (2)"}, {"title": "III. METHODOLOGY", "content": "The overall process of the Fuzzy Attention Layer is illustrated\nin Figure 1B, where the fNIRS data of two individuals in one\npair are put into the same feature extractor and extract the\nembedding of the neural responses in the same embedding\nspace."}, {"title": "A. Task Definition", "content": "Given the fNIRS data recorded from two individuals observ-\ning the same image under two distinct conditions\u2014handholding\nand not handholding our task is to develop a classifier capable\nof discerning the participants' interaction state. The fNIRS\ndata, denoted as D\u2081 and D2 for each participant, are obtained\nwhile simultaneously engaging with the visual stimulus. The\nclassifier aims to predict the binary label H \u2208 {0,1}, where\nH = 1 corresponds to a handholding condition, and H = 0\nindicates no handholding. The challenge lies in capturing the\nsubtle physiological synchronies and disparities influenced\nby the interpersonal touch encoded in the hemodynamic\nresponses as measured by fNIRS. This task extends upon the\nemerging discourse in social neuroscience regarding the neural\nunderpinnings of human physical interactions as explored\nin Section II-A. Our approach leverages a paired-sample\nframework, incorporating both within- and between-subject\nvariations to accurately classify the interaction states, thus\nadvancing the understanding of neural connectivity patterns\nassociated with social touch."}, {"title": "B. Fuzzy Attention Layer", "content": "While cosine similarity-based scoring is\neffective in NLP tasks, it may prove inefficient for sparse data\npatterns. Cosine similarity assigns high scores when the correct\norientation is identified and low scores for other orientations.\nIn contrast, the fuzzy distance matrix displays high values in\nspecific neighborhoods and low values in remote areas, offering\na distinct advantage in capturing complex patterns.\nFrom the TSK model, the firing strength of a fuzzy rule,\ndenoted as fr(x), can be expressed as follows:\nfr(x)=\u03bcr(x)\u2211i=1R\u03bci(x)=softmaxi,r\u239b\u239d\u2212\u2211d=1D(xi,d\u2212mr,d)22\u03c32r,d\u239e\u23a0=softmaxi,r\u239b\u239d\u2211d=1Dxia+m2r,d\u22122xi,dmr,d2\u03c32r,d\u239e\u23a0=softmaxi,r\u239b\u239d\u2211d=1Dxia2\u03c32+mr,d2\u03c32+\u2212\u2211d=1DXi,dmr,d\u03c32\u239e\u23a0(4)\nwhere r is the index of the fuzzy rule among the total R rules,\nxd is the input at dimension d, mr.d and \u03c3r,d represent the\ncenters and widths of the fuzzy rule at dimension d. Similarly,\nthe formula for attention weights can be written as:\nAttention(i,j)=softmaxi,j(QiKjT\u221adk)=softmaxi,j\u239b\u239d\u2211d=1DXi,dkj,d\u221adk\u239e\u23a0(5)\nHere, each xi and kj are vectors in the embedded dimension,\nand their dot product is a scalar. By comparing equation 5\nwith 4, we observe that the fuzzy firing strength incorporates\na term similar to the dot-product self-attention similarity. The\ndifferences between the TSK-type firing strength and dot-\nproduct self-attention are:"}, {"title": "C. Fuzzy Transformer for fNIRS modeling", "content": "Our model comprises two main components: the feature\nextractor and the classification head. The feature extractor\nfollows the structure of a Transformer Encoder, where the\nattention layers are replaced by a Fuzzy Attention Layer.\nAs depicted in Figure 1B, this extractor is utilized for both\nparticipants in a pair. The output embedding from the encoder\nis concatenated and then processed by the classification head.\nFollowing equations 4, our proposed Fuzzy Attention Layer\nthe input sequence with:\nFuzzyAttention(x)=softmax((Q(x)\u2212\u03bc)22\u03c32) (12)\nwhere the Q(x) s the linear projection from the input sequence,\nand \u03bc and are the Gaussian membership parameters, and\nu the consequent of the fuzzy rule. From the attention view,\nthe fuzzy attention score replaces the attention score matrix\nfrom the dot product similarity to an L2 distance weighted\nby \u03c3. This attention score has been observed to be beneficial\nin fNIRS data modeling. The objective is to classify whether\nindividuals are holding hands. We employ the cross-entropy\nloss, which is defined as\nloss(yo,c,po,c)=M\u2211c=1yo,clog(po,c) (13)\nwhere yo,c is the true label, po,c is the predicted probability\nfor class c, and M represents the total number of classes in\nthe classification problem."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "To evaluate our proposed Fuzzy Attention Layer aimed at\ndecoding brain signals, we implemented two datasets in our\nstudy, each with different experimental setups named Picture\nRecognition and Picture Rating. Both experiments involved\npairs of participants who performed tasks under two conditions:\nwith and without handholding. The experiments were structured\nto minimize interaction by seating participants back-to-back.\nFigure 2D illustrates the fNIRS channel locations.\n1) Picture Recognition: The study adopted a two-factor\nmixed experimental design focusing primarily on the vari-\nables of hand-holding (hand-holding vs. non-hand-holding)\nand image type (negative vs. neutral). In this experiment,\nparticipants arrived at the laboratory and were briefed about\nthe study's procedures without revealing the hypotheses. They\nwere reassured about the safety of the experiment and provided\nwritten informed consent. Before the start of the experiment,\neach participant was isolated in separate rooms to fill out initial\nquestionnaires. Preparation included donning necessary devices.\nThe protocol consisted of three sessions of approximately 5\nminutes each for relaxation and briefing, interspersed with\ntwo task sessions lasting around 20 minutes each. During the\nrelaxation phases, participants were instructed to remain still,\nclose their eyes, and relax. Task sessions involved emotional\nimage recognition tasks performed both in hand-holding and\nnon-hand-holding condition, with participants responding to\nemotional stimuli presented on the screens using a two-button\nkeypad pressing the left button for negative images and the\nright for neutral ones. Each image was displayed following a\n2-second fixation cross, and the response period was followed\nby feedback lasting 1 second. Each trial ensured a minimum\nduration of 11 seconds, extending up to 13 seconds to facilitate\nrelaxation.\n2) Picture Rating: Similarly, The study also adopted a two-\nfactor mixed experimental design focusing primarily on the\nvariables of hand-holding (hand-holding vs. non-hand-holding)\nand image type (negative vs. neutral). The design was organized\ninto a Block design. The protocol was divided into two main\nblocks based on hand-holding conditions and 16 sub-blocks\nbased on the type of image presented, with each sub-block\ncontaining 10 trials of either negative or neutral images. To\ncontrol for sequence effects, the order of the image type blocks\nwas systematically varied using an ABBA-style arrangement.\nEach trial commenced with a 2-second presentation of a fixation\npoint, followed by a 2-second solitary display of the image.\nParticipants had 2 seconds to rate the emotional valence (from\n1, negative, to 9, positive) and arousal (from 1, calm, to\n9, excited). Upon completing ratings, the next trial began.\nBreaks of 30 minutes and 5 minutes were observed after each\nimage type and hand-holding block, respectively. Participants\nstarted with a 5-minute baseline data collection session to\nmeasure resting neural activity. Following non-hand-holding\ntasks, the experiment introduced the hand-holding condition,\nwhere participants held hands and repeated the image evaluation\ntask. The study concluded with another 5-minute resting state\ndata collection session to assess any neural changes post-\nexperiment.\n3) fNIRS Setup and Preprocessing: During two experiments,\nfNIRS signals were recorded from two participants simultane-\nously at a sampling rate of 7.8125 Hz. This was accomplished\nusing 8 sources and 7 detectors on each participant, resulting\nin a network of 20 source-detector pair channels (CH) per\nindividual covering the Prefrontal Cortex (PFC). To ensure\nsignal quality, we calculated the scalp coupling index (SCI)\nfor each channel, excluding those with an SCI below 0.5.\nSubsequently, the data underwent artifact removal and baseline\ncorrection, with hemoglobin concentrations computed using\nthe Beer-Lambert law. Finally, all fNIRS data were band-pass\nfiltered between 0.01 Hz and 0.2 Hz."}, {"title": "B. Implementation Details", "content": "In our study, the implementation of the neural network\nmodel was tailored with specific optimization strategies to"}, {"title": "C. Evaluation Metrics", "content": "To assess the performance of our classifier in determining\nhandholding conditions from fNIRS data, we employed six\nwidely recognized metrics: accuracy, recall, precision, F1 score,\narea under the receiver operating characteristic curve (ROC\nAUC), and area under the precision-recall curve (PR AUC)."}, {"title": "D. Ablation Study", "content": "1) Exploring the Impact of Fuzzy Attention Layer Re-\nplacements within Transformer Encoders: In our pursuit to\nunderstand the impact of the Fuzzy Attention Layers in the\nTransformer Encoder, we use the Picture Recognition dataset\nand replace the attention layers in two different structures (time-\nfirst and channel-first) in a 3-layer model as a demonstration.\nThis experimental design allows us to systematically explore the\neffects of layer-specific modifications within our Transformer\nencoder architecture. We evaluate the performance of each\nstructure containing replaced layers in various combinations\n(individual layers, two layers, and all three layers together,\ntotal 6 combinations). The performance metrics are calculated\nfor each experiment, providing a comprehensive view of the\nimpact of these replacements. The results, as detailed in Table\nII, show that different structures respond uniquely to replacing\nattention layers. For example, replacing all three layers in the\nchannel-first structure significantly enhances both the model's\naccuracy and recall, suggesting a cumulative benefit of layer\nreplacement in complex encoding scenarios. Conversely, in\nthe time-first structure, the selective replacement of individual"}, {"title": "V. DISCUSSION", "content": "This section presents a detailed examination of how we\nidentify and interpret neural activity patterns."}, {"title": "A. Fuzzy Set and Feature Distribution", "content": "The fuzzy set distributions of each fuzzy rule, as depicted in\nFigure 6, illustrate the temporal dynamics and channel speci-\nficity of fuzzy membership functions over multiple experimental\nconditions."}, {"title": "B. Sample-wised Interpretability Analysis", "content": "To provide an intuitive illustration of how the Fuzzy\nAttention Layer identifies the handholding condition from\nfNIRS data, we present a demo sample from the top-performing\nmodel, where the subject holds a hand."}, {"title": "C. Group-level Interpretability Analysis", "content": "To investigate the decision-making mechanism of the rule\nas a filter, we conducted statistical analyses to assess the\ndifferences between two labels under one rule at the group\nlevel."}, {"title": "D. Result Explanation", "content": "The PFC encompasses several key areas integral to cognitive\nand emotional regulation."}, {"title": "VI. CONCLUSION", "content": "In this work, we introduce a new attention layer, the Fuzzy\nAttention Layer, to identify interpretable patterns of neural\nactivity, which are crucial for detailed analysis and under-\nstanding of the decision-making process of the neural network\nfor individual cases. This method enhances the correlation\nmodeling ability for fNIRS data. Our paper demonstrates\nthat the Fuzzy Attention Layer outperforms vanilla self-\nattention in modeling boundary relations. Additionally, the\ntransformer model with a Fuzzy Attention Layer achieves\nhigher approximation accuracy than the vanilla transformer.\nThis finding is validated with two fNIRS datasets, where\nrelevant neural activity patterns are identified. Given the\npotential of the Fuzzy Attention Layer, it could be applied\nto other types of neural data, such as EEG or fMRI, aiding\nneuroscience and BCI technology in understanding decodable\nand human-interpretable neural patterns. Our contribution paves\nthe way for significant breakthroughs in understanding the\nbrain's complex mechanisms and enhancing neurotechnology."}, {"title": "VII. LIMITATIONS", "content": "This study has identified several limitations. First, the\ncomputational speed is notably low due to the reliance on\nthe Transformer architecture. A potential remedy is to reduce\nthe model size to enhance processing efficiency. Second, the\npresence of similar rules contributes to redundancies in model\nparameters."}]}