{"title": "Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for\nKnowledge Graph Completion", "authors": ["Muzhi Li", "Cehao Yang", "Chengjin Xu", "Xuhui Jiang", "Yiyan Qi", "Jian Guo", "Ho-fung Leung", "Irwin King"], "abstract": "The Knowledge Graph Completion (KGC) task\naims to infer the missing entity from an in-\ncomplete triple. Existing embedding-based\nmethods rely solely on triples in the KG,\nwhich is vulnerable to specious relation pat-\nterns and long-tail entities. On the other hand,\ntext-based methods struggle with the seman-\ntic gap between KG triples and natural lan-\nguage. Apart from triples, entity contexts\n(e.g., labels, descriptions, aliases) also play a\nsignificant role in augmenting KGs. To ad-\ndress these limitations, we propose KGR\u00b3, a\ncontext-enriched framework for KGC. KGR\u00b3\nis composed of three modules. Firstly, the\nRetrieval module gathers supporting triples\nfrom the KG, collects plausible candidate an-\nswers from a base embedding model, and re-\ntrieves context for each related entity. Then,\nthe Reasoning module employs a large lan-\nguage model to generate potential answers for\neach query triple. Finally, the Re-ranking mod-\nule combines candidate answers from the two\nmodules mentioned above, and fine-tunes an\nLLM to provide the best answer. Extensive\nexperiments on widely used datasets demon-\nstrate that KGR\u00b3 consistently improves various\nKGC methods. Specifically, the best variant\nof KGR\u00b3 achieves absolute Hits@1 improve-\nments of 12.3% and 5.6% on the FB15k237\nand WN18RR datasets. The code is anony-\nmously available at https://anonymous.\n4open.science/r/RRR-KGC-CBA3/.", "sections": [{"title": "1 Introduction", "content": "Knowledge Graphs (KGs) are graph-structured\nknowledge bases (KBs) that organize factual knowl-\nedge as triples in the form of (head entity, rela-\ntion, tail entity). Recently, KGs have become a\ncrucial foundation for various downstream appli-\ncations, such as recommendation systems (Wang\net al., 2019), question answering (Sun et al., 2024),\nand sentiment analysis (Wang and Shu, 2023). Nev-\nertheless, mainstream KGs such as Freebase (Bol-\nlacker et al., 2008) and Wordnet (Miller, 1995) suf-\nfer from serious incomplete issues. This problem\nhighlights the importance of the Knowledge Graph\nCompletion (KGC) task, which aims to predict the\nmissing entity from an incomplete triple.\nExisting KGC methods can be roughly catego-\nrized into embedding-based methods (Bordes et al.,\n2013; Yang et al., 2015; Sun et al., 2019; Cao et al.,\n2022) and text-based methods (Yao et al., 2019;\nWang et al., 2021, 2022). Embedding-based meth-\nods implicitly learn rules based on relation patterns\nobserved in triples and make predictions based on\nthe likelihood of these patterns occurring (Wu et al.,\n2023). For example, from triple (X, works in, Y)\nand (Y, city of, Z), it is very likely to deduce that\n(X, citizen of, Z). However, these methods ignore\nthe contextual semantics supporting these triples,\nleading to conclusions that do not align with the\nfacts. Text-based methods employ pre-trained lan-"}, {"title": "Related Works", "content": "Embedding-based methods Embedding-based\nmethods are fundamental in KGC, which focuses\non learning a set of low-dimensional embeddings\nfor entities and relations with certain geomet-\nric or mathematical constraints. Most typically,\nTransE (Bordes et al., 2013) assumes the translated\nhead embedding of a triple are close to the em-\nbedding of the tail. DistMult (Yang et al., 2015)\naims to maximize the Hadamard product of the\nhead, relation, and tail embeddings of each triple.\nTo model symmetric and anti-symmetric relations,\nComplEx (Trouillon et al., 2016) generalizes Dist-\nMult by introducing complex embeddings with Her-\nmitian dot product. RotatE (Sun et al., 2019) in-\nterprets relation as a rotation operation in complex\nspace, which can effectively infer inversion and\ncomposition patterns. ATTH (Chami et al., 2020)\nand GIE (Cao et al., 2022) further leverage hyper-\nbolic embeddings and operations to capture the\nintrinsic hierarchical structure in KGs. Recently,\nGraph Neural Networks (GNNs) have emerged\nas powerful methods for graph embedding (Zhou\net al., 2020). Considering the heterogeneity of KGs,\nRGCN (Schlichtkrull et al., 2018), WGCN (Zhao\net al., 2021), and CompGCN (Vashishth et al.,"}, {"title": "3 Problem Specifications", "content": "A Knowledge Graph (denoted as G = {E,R,T})\ncan be represented as a set of triples in the form\nof (h, r, t) \u2208 T, where h,t \u2208 E, r \u2208 R. The no-\ntations h and t denote the head and the tail entity\nof a triple. E, R, T are the set of entities, relations,"}, {"title": "4 Methods", "content": "In this section, we introduce our proposed context-\nenriched KGC framework KGR\u00b3, which consists\nof three components: (1) Retrieval, (2) Reasoning,\nand (3) Re-ranking."}, {"title": "4.1 Stage 1: Retrieval", "content": "The retrieval module focuses on gathering struc-\ntural and semantic knowledge that may contribute\nto the completion of certain incomplete triples."}, {"title": "4.1.1 Supporting Triple Retrieval", "content": "In KGs, the attributes of an entity are represented\nin structural triples. Different entities connected\nby the same relation often share common salient\nproperties. The internal knowledge inherent in the\ngraph structure provides the most direct support to\nthe validity of a triple. Given an incomplete query\ntriple in the form of (h,r,?) or (?, r,t), we aim\nto retrieve k supporting triples that are the most\nsemantically similar to the incomplete query triple.\nIntuitively, we prioritize triples with the same entity\nand relation from the training set. If the number\nof available triples is less than k, we broaden our\nchoices to triples with the same relation, and with\nentities that are semantically similar to the known\none in the query triple."}, {"title": "4.1.2\nTextual Context Retrieval", "content": "We note that there is a significant semantic gap\nbetween structural triples and natural language\nsentences. For example, in Figure 2, entity\n\"Kasper Schmeichel\u201d is originally represented by\nan unique entity id \"/m/07h1h5\" while relation\n\u201cplays for sports teams\u201d is originally represented"}, {"title": "4.1.3 Candidate Answer Retrieval", "content": "The widely adopted ranking-based evaluation for\nthe KGC task requires the model to score the plau-\nsibility of each entity in the KG as a potential re-\nplacement for the missing entity in the query triple.\nHowever, given the vast number of entities in the\nKG, employing LLMs to score and rank each en-\ntity is computationally expensive and impractical.\nInspired by (Lovelace et al., 2021; Wei et al., 2023;\nLi et al., 2024), we employ a base KGC model to"}, {"title": "4.2 Stage 2: Reasoning", "content": "In the second stage, we first exploit the supporting\ntriples to direct the LLM in performing the KGC\ntask. In addition, we employ the LLM to generate\nseveral possible answers drawing upon the descrip-\ntion of the known entity in the query triple."}, {"title": "4.2.1\nSupporting Triple Demonstrations", "content": "In this sub-section, we present the design of our\nprompt tailored for the demonstration, which is cru-\ncial in facilitating in-context learning (Wei et al.,\n2023). For each supporting triple, we first provide\nLLM with the description of the head entity. The\nentity description serves three objectives: (1) dis-\nambiguate entities with the same label, (2) rejuve-\nnate the LLM's memory about known entities, and\n(3) provide essential information for entities that\nare not included in the LLM pre-training corpus."}, {"title": "4.2.2 Context-aware Reasoning", "content": "We anticipate that LLMs can harness their infor-\nmation extraction and semantic understanding ca-\npabilities by utilizing comprehensive contextual\ninformation about the known entity, thereby gen-\nerating potential answers. Similarly, we pass the\ndescription of the known entity and the question\ntranslated from the query triple to the LLM. The\nLLM is then instructed to output a list of answers\nin its response. It should be noted that generative\nLLMs do not guarantee that output answers will\nconform to entities in the KG. Therefore, we post-\nprocess the LLM output by replacing entity aliases\nwith entity labels and filtering out invalid and unre-\nliable answers that do not appear within the top-positions of $A_{KGC}$. Finally, we obtain a list of m\nanswers, which are formally denoted as:\n$A_{LLM} = [e^{(1)}, e^{(2)}, ..., e^{(m)}]$ \n$= f_{LLM}(q, c(q), D(q)) \u2229 A_{KGC}[0 : \u03b4]$, (2)\nwhere q, c(q) and D(q) denote the question, de-\nscription of the known entity, and supporting triple\ndemonstrations. Entities in $A_{LLM}$ are ensured to\nbe simultaneously supported by the LLM and the\nbase KGC model."}, {"title": "4.3 Stage 3: Re-ranking", "content": "Motivated by the complementary nature of seman-\ntic and structural knowledge, we aim to exploit the\ncandidate answer list generated by the LLM and\nthe base KGC model to compose our final rankings.\nTo better enable the LLM in utilizing entity de-\nscriptions and structured neighbor facts for ranking\ncandidate answers to query triples, we introduce\nsupervised fine-tuning (SFT) with LoRA adapta-\ntion (Chao et al., 2024). Inspired by DIFT (Liu\net al., 2024), the training objective of SFT is to\nfind out the missing entity of an incomplete triple\nfrom a set of candidate answers. Specifically, we\nconstruct training samples by corrupting the tail (or\nhead) entity of each triple in the training set. For\neach corrupted triple, we randomly sample $n_1$\nnegative samples from the entity set, where half\nof them are connected by the same relation as the\ncorrupted ground truth entity. Incorporating these\nhard negative samples helps the LLM to distinguish\nbetween different entities with the same property,\nwhich is crucially important since candidate enti-\nties suggested by base KGC models usually yield\nsimilar characteristics. After that, we translate the\nmasked triple to a natural language question, and\ngather the label and description for each candidate\nentity. Finally, we provide the question q, retrieved\nneighbor facts N(q), and the description of the\nknown entity c(q), along with candidate answers A\nand their descriptions c(A) to the LLM, and fine-\ntune the LLM to output the label y of the ground\ntruth entity. Formally, we have the SFT loss:\n$L_{SFT} = \\sum_{i=1}^{T} log(y/q, N(q), c(q), A, c(A))$. (3)\nIt is important to emphasize that the SFT process\ndoes not rely on the prior inference results from\nexisting KGC approaches. This ensures that the\nKGR\u00b3 framework can be implemented as a plug-\nand-play solution.\nDuring the inference stage, we construct a candi-\ndate answer set Ac, which is composed of top-p en-\ntities from AKGC and top-(n \u2013 p) entities in ALLM\nthat are not previously encountered. Formally, we\nhave:\n$Ac = A_{KGC} [0: p] \u222a {A_{LLM}\\A_{KGC}[0 : p]}[0 : n \u2212 p]$.\n(4)\nIf ALLM contains fewer than (n \u2013 p) entities (e.g.\nm < n-p), we supplement the candidate answer\nset with additional entities from AKGC to reach a\ntotal of n entities. Similarly, we instruct the fine-\ntuned LLM to select the most appropriate candidate\nentity to complete the query triple, and output its"}, {"title": "5 Experiments", "content": "In this section, we assess the effectiveness of the\nKGR\u00b3 framework in the KGC task."}, {"title": "5.1 Datasets", "content": "We utilize two widely-used benchmark datasets,\nnamely FB15k237 and WN18RR to evaluate the\nproposed method. FB15k237 is derived from Free-\nbase (Bollacker et al., 2008), an encyclopedic KG\ncontaining general knowledge about topics such\nas celebrities, organizations, movies and sports.\nWN18RR is a subset of WordNet (Miller, 1995), a\nlexical KG with knowledge about English morphol-\nogy. To prevent potential data leakage, FB15k237\nand WN18RR excludes reversible relations from\ntheir backend KGs."}, {"title": "5.2 Baselines and Evaluation Metrics", "content": "We compare the KGR\u00b3 framework with four types\nof baseline methods: (1) traditional KG Embed-\nding methods TransE (Bordes et al., 2013), Com-\nplEx (Trouillon et al., 2016), RotatE (Sun et al.,\n2019), TuckER (Balazevic et al., 2019); (2) GNN-\nbased embedding methods CompGCN (Vashishth\net al., 2020), NBF-Net (Zhu et al., 2021); (3) text-\nbased methods KG-BERT (Yao et al., 2019), MEM-\nKGC (Choi et al., 2021), SimKGC (Wang et al.,\n2022), CoLE (Liu et al., 2022); and (4) LLM-based\nmethods KICGPT (Wei et al., 2023), DIFT (Liu\net al., 2024). Among these baselines, we select\nTransE, RotatE, GIE, SimKGC, CoLE, and NBF-\nNet as our base KGC models because these meth-\nods are highly representative and exhibits strong\nperformance.\nWe utilize the widely adopted evaluation metrics,\nnamely Hits@k (k = 1,3,10) and MRR to eval-\nuate our proposed method. Hits@k measures the\nproportion of query triples which the ground truth\nentities are ranked within the top-k position. MRR\nmeasures the mean reciprocal rank for each ground\ntruth entities. Higher results indicates a better per-\nformance."}, {"title": "5.3 Main Results", "content": "Table 2 summarizes the performance of the KGR3\nframework on six different base KGC methods.\nThe experiment results show that the best variant of\nKGR\u00b3 significantly outperforms all baseline meth-\nods among all evaluation metrics. Compared to\nthe previous state-of-the-art baseline, KGR\u00b3, with\nLlama3-8B as the backbone LLM, achieves ab-\nsolute Hits@1 improvements of 11.3% and 4.0%\non the FB15k237 and the WN18RR datasets, re-\nspectively. * It demonstrates that KGR\u00b3 is highly\neffective for the KGC task.\nNotably, the improvement in Hits@1 is more\nsubstantial than that in Hits@3 and Hits @10. This\nindicates that the KGR\u00b3 framework is particu-\nlarly effective at identifying the most accurate an-\nswers. Since our framework primarily focuses on\nre-ordering top-n entities from the initial ranked\nentity list, the upper bound of Hits@1,Hits@3, and\nHits@10 are implicitly constrained by the Hits@n\nperformance of the base KGC model. Given that\nHits@1 is typically further from this upper bound,\nthe potential for improvement will be greater. Ad-\nditionally, by leveraging semantic knowledge from\nentity contexts, the LLM gains a more comprehen-\nsive understanding of the entities, thereby enabling\nmore precise inferences, particularly for top-ranked\ncandidate answers.\nCompared to the selected base KGC models, the\ncorresponding variants of KGR\u00b3 consistently boost\nthe performance on both datasets to a large mar-\ngin. It shows that KGR\u00b3 is compatible with various\ntypes of KGC models, confirming its strong gen-\nerality and plug-and-play capability. In contrast,\nKICGPT fails to outperform the state-of-the-art\nGNN-based or text-based methods, which under-\nutilizes the power of the LLM. In addition, variants\nof KGR\u00b3 consistently outperform counterparts of\nthe LLM-based baseline DIFT (Liu et al., 2024)\nwith the same base KGC models. The performance"}, {"title": "5.4 Ablation Studies", "content": "We verify the effectiveness of each component in\nthe KGR\u00b3 framework by answering the following\nresearch questions (RQs). Table 3 and 4 shows the"}, {"title": "6 Conclusion", "content": "In this paper, we propose KGR\u00b3, an LLM-based\ncontext-enriched KGC framework with three mod-\nules: Retrieval, Reasoning, and Re-ranking. By\nleveraging contextual information, KGR\u00b3 effec-\ntively bridges the semantic gap between structural\nKG triples and natural language. Experimental re-\nsults show that incorporating supporting triples and\nentity descriptions with LLM in-context learning\nand SFT significantly improves the KGC perfor-\nmance. Future work will focus on adapting LLMs\nto other KG reasoning tasks such as inductive KGC\nand knowledge-based question answering."}, {"title": "Limitations", "content": "Although the proposed framework achieves a sig-\nnificant breakthrough in the KGC task, it still has\nsome remaining issues to be resolved in the future.\nFirstly, the proposed KGR\u00b3 framework is not capa-\nble of handling the KGC task under an \u201cinductive\nsetting\". The KGC task discussed in this paper,\nalong with most related works, operates under a\n\"transductive setting\", where entities in test triples\nalso exist in the training set. We plan to tackle\nunseen entities that are not present in the KG in the\nfuture. Secondly, the commonly adopted evaluation\nmetrics Hits@k necessitate ranking the plausibility\nof all entities within the KG for each query triple.\nDue to the limitations imposed by the maximum\nsequence length of LLMs, it is impractical to rank\ntens of thousands of entities within a KG. To meet\nthe evaluation criteria, one may have to select a\nproper subset of entity candidates using existing\nKGC models. Hence, the base KGC model may\ninevitably constrain the final performance of the\nproposed framework."}, {"title": "Ethics Statement", "content": "To the best of our knowledge, this work does not\ninvolve any discrimination, social bias, or private\ndata. All the datasets are constructed from open-\nsource KGs such as Wikidata. Therefore, we be-\nlieve that our study complies with the ACL Ethics\nPolicy."}, {"title": "A Appendix", "content": "A.1 Prompt templates of Reasoning stage\nTable 5 shows the prompt templates of the Reasoning stage and provides an example.\n## In-context Demonstrations:\nUser: Washington County: county in Pennsylvania, U.S. The question is to predict the head entity\n[MASK] from the given ([MASK], location adjoining_relationship adjoins, Washington County) by\ncompleting the sentence 'Washington County is the adjoins of what location? The answer is '.\nAssistant: The answer is Westmoreland County, so the [MASK] is Westmoreland County. Westmoreland\nCounty: county in Pennsylvania, United States\nUser: Rockland County: suburban county in New York, United States The question is to predict the head\nentity [MASK] from the given ([MASK], location adjoining_relationship adjoins, Rockland County) by\ncompleting the sentence 'Rockland County is the adjoins of what location? The answer is '.\nAssistant: The answer is Bergen County, so the [MASK] is Bergen County. Bergen County: county in\nNew Jersey, United States\n## Query triple: ([MASK], /location/adjoining_relationship/adjoins, Champaign)\n## Reasoning prompts:\nUser: The question is to predict the head entity [MASK] from the given ([MASK], location adjoin-\ning_relationship adjoins, Champaign) by completing the sentence 'Champaign is the adjoins of what\nlocation? The answer is '. Output all some possible answers based on your own knowledge, using the\nformat '[answer1, answer2, ..., answerN]' and please start your response with 'The possible answers:'.\nDo not output anything except the possible answers.\n## Context-aware Reasoning:\nUser: Here are some materials for you to refer to:\nChampaign: Champaign is a city in Champaign County, Illinois, United States. The population was 88,302\nat the 2020 census. It is the tenth-most populous municipality in Illinois and the fourth most populous\ncity in the state outside the Chicago metropolitan area. It is a principal city of the Champaign-Urbana\nmetropolitan area, which had 236,000 residents in 2020.\nThe question is to predict the head entity [MASK] from the given ([MASK], location adjoin-\ning_relationship adjoins, Champaign) by completing the sentence 'Champaign is the adjoins of what\nlocation? The answer is '. Output all the possible answers you can find in the materials using the format\n'[answer1, answer2, answerN]' and please start your response with 'The possible answers:'. Do not\noutput anything except the possible answers. If you cannot find any answer, please output some possible\nanswers based on your own knowledge.\n## Reasoning results:\nAssistant: The possible answers: [Urbana, Champaign County, Illinois Silicon Prairie, Parkland College]"}]}