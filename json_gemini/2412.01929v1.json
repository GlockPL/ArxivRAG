{"title": "ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals", "authors": ["Poorya Aghaomidi", "Ge Wang"], "abstract": "Accurate sleep stage classification is essential for understanding sleep disorders and improving overall health. This study proposes a novel three-stage approach for sleep stage classification using ECG signals, offering a more accessible alternative to traditional methods that often rely on complex modalities like EEG. In Stages 1 and 2, we initialize the weights of two networks, which are then integrated in Stage 3 for comprehensive classification. In the first phase, we estimate key features using Feature Imitating Networks (FINs) to achieve higher accuracy and faster convergence. The second phase focuses on identifying the N1 sleep stage through the time-frequency representation of ECG signals. Finally, the third phase integrates models from the previous stages and employs a Kolmogorov-Arnold Network (KAN) to classify five distinct sleep stages. Additionally, data augmentation techniques, particularly SMOTE, are used in enhancing classification capabilities for underrepresented stages like N1. Our results demonstrate significant improvements in the classification performance, with an overall accuracy of 80.79% an overall kappa of 0.73. The model achieves specific accuracies of 86.70% for Wake, 60.36% for N1, 83.89% for N2, 84.85% for N3, and 87.16% for REM. This study emphasizes the importance of weight initialization and data augmentation in optimizing sleep stage classification with ECG signals.", "sections": [{"title": "I. INTRODUCTION", "content": "Sleep disorders are a persistent challenge throughout the human history. Despite significant advancements in medicine, the prevalence of these disorders remains high, and their impact on public health continues to be profound. This paradox may be partly explained by significant changes in modern human behaviors, particularly the widespread use of digital devices. Exposure to artificial blue light from screens disrupts our circadian rhythms, which are genetically programmed to be influenced by natural sunlight. Studies have shown that excessive exposure to blue light, especially during the evening and night, can suppress melatonin production, delay sleep onset, and disrupt the overall sleep cycle [1], [2]. This may contribute to the increasing incidence of sleep disorders in the modern population, despite our advances in understanding and treating these conditions.\nSleep is not a simple binary state of being awake or asleep; rather, it is a complex process that occurs in stages. The American Academy of Sleep Medicine (AASM) and the Rechtschaffen and Kales (R&K) criteria are the two primary standards for classifying sleep stages. The R&K criteria, established in 1968, are the first standardized system for sleep stage classification. These criteria divide sleep into two main categories: Non-Rapid Eye Movement (NREM) sleep, which is further subdivided into stages N1, N2, N3, and N4, and Rapid Eye Movement (REM) sleep. NREM sleep stages progress from light to deep sleep, with stage N4 being the deepest and most restorative stage [3].\nThe AASM standards, introduced in 2007, refined the R&K criteria. The AASM reduced the number of NREM stages from four (as in the original R&K criteria) to three by merging stages 3 and 4 into a single stage (now called N3). This change was made based on evidence that these stages represent a similar level of sleep and are difficult to distinguish using traditional Polysomnography (PSG). The AASM guidelines also provides more detailed criteria for scoring arousals, respiratory events, and limb movements, which are essential for diagnosing sleep disorders [4].\nTraditionally, experts rely on PSG data to classify sleep stages. PSG is a comprehensive sleep study that records various physiological signals, including Electroencephalogram (EEG), Electrocardiogram (ECG), Electromyogram (EMG), and Electrooculogram (EOG). Analyzing these signals to determine sleep stages is a complex task, often requiring significant expertise. The transitions between stages are subtle and can be challenging to identify, leading to potential errors even for experienced clinicians.\nThe advent of machine learning and more recently"}, {"title": "II. METHODS", "content": "In this study, we propose a three-stage approach for sleep stage classification using ECG signals. The first phase involves estimating key statistical features, such as kurtosis and skewness. The second phase focuses on identifying the N1 sleep stage through the time-frequency representation of ECG signals. Finally, the third phase integrates the models trained in the previous stages and employs a Kolmogorov-Arnold Network to classify the five stages of sleep. An overview of this methodology is illustrated in Fig. 1.\nDataset\nThe dataset utilized in this study is sourced from the MIT-BIH Polysomnographic Database, which includes recordings of various physiological signals during sleep. These recordings were collected from subjects at"}, {"title": "B. Stage 1", "content": "FIN is a neural network designed to approximate one or more closed-form statistical features of a dataset. By initializing its weights, a FIN can achieve exceptional performance for various downstream signal processing tasks while requiring less data and fine-tuning compared to traditional networks[20]. In this study, we trained our FIN to calculate kurtosis and skewness. These statistical features are crucial for analyzing ECG signals due to their sensitivity to outliers and abnormalities in the signal distribution. The purpose of the FIN pretraining was to initialize the weights of our model with values close to optimal rather than random initialization, providing a robust starting point for training on real ECG data.\nData Synthesis: To train the FIN, we generated synthetic signals composed of chirp signals, step signals, and random uniform noise. These types of signals were selected because, together, they span a wide range of kurtosis and skewness values. This diversity in the data allowed the FIN to learn to calculate these statistical measures under varying conditions. Each synthetic signal was 3,000 samples long, mirroring the length of real ECG data. The dataset included 20,000 signals for training, 2,000 for validation, and 2,000 for testing.\nArchitecture: The FIN model starts with five Convolutional Neural Network (CNN) blocks, each designed to progressively learn local and global features. Each block includes a 1D convolutional layer with a kernel size of 3 and filter numbers of 16, 32, 64, 128, and 256 in each respective block. Following the convolution, a ReLU activation function is applied, along with batch normalization, and a max pooling layer.\nFollowing the CNN blocks, a Liquid Neural Network (LNN) was incorporated, which transformed the outputs from 256 to 128 units. LNNs are a type of neural network that differ from traditional recurrent neural networks (RNNs) by their ability to handle continuous, time-dependent data more effectively. Unlike RNNs that rely on static architectures with fixed time steps, LNNs use differential equations to model the dynamics of neurons over time, allowing them to adapt continuously to changes in input data. The \"units\" refer to the dimensionality of the feature space or the number of neurons in the LNN layer, where each unit represents a learned feature that contributes to the network's ability to process temporal patterns. By modeling neuron states as dynamic systems, LNNs can capture intricate time-varying relationships in the data, making them particularly effective for applications involving sequential or time-dependent inputs.\nThis design makes LNNs particularly suitable for analyzing ECG signals, which are naturally continuous and exhibit temporal dependencies. Given that our input length is 3,000 samples, the LNN's dynamic nature is essential for maintaining the temporal context throughout the signal processing pipeline. This allows it to retain important features from earlier segments of the ECG signal while processing later parts, which is critical for tasks requiring an understanding of both short-term variations and longer-term trends in the data, such as for sleep stage classification.\nFinally, fully connected layers responsible for the computation of kurtosis and skewness were added. Before branching into the two tasks, a common part consisting of a dense layer with 64 units followed by a ReLU activation function and a dropout layer with a rate of 0.2. This was followed by another dense layer with 32 units, also utilizing a ReLU activation function and a dropout layer with a rate of 0.2. For kurtosis, a dense layer with 16 units and a ReLU activation function was followed by another dense layer with 1 unit. The same structure was applied for skewness, enabling the network to compute these statistical features from the learned signal representations.\nWe trained the model using the Huber loss function with a batch size of 8 and the Adam optimizer at an initial learning rate of 0.001 over 20 epochs. To optimize training, we implemented ReduceLROnPlateau to dynamically decrease the learning rate when performance plateaued.\nTo evaluate the FIN after pretraining, we compared the true values of kurtosis and skewness from the synthetic signals with the predicted values generated by the FIN. Mean Squared Error (MSE) and Mean Absolute Error (MAE) were used as evaluation metrics to measure the model's accuracy in estimating these features. This step is crucial in confirming the FIN's capability to approximate these features before its integration into the sleep stage classification model."}, {"title": "C. Stage 2", "content": "The classification of the N1 sleep stage presents considerable challenges due to its transitional nature and overlap with adjacent stages. To address this, we introduced a dedicated stage in our model aimed at improving N1 detection. This stage involved a binary classification task that distinguishes N1 signals from non-N1 signals, helping to train a robust encoder tailored to capture the subtle features of N1.\nPreprocessing: Given the imbalance in the dataset, we curated a balanced subset for the N1 classification task. The N1 class consisted of 1,815 signals, so we selected 454 signals from each of the remaining classes"}, {"title": "D. Stage 3", "content": "In the third stage of our model, we integrate the previously trained components to enhance the overall performance of sleep stage classification. This integration combines insights from the first two stages, where"}, {"title": "III. RESULTS", "content": "In this section, we first present the performance of the FIN from Stage 1, followed by an evaluation of the N1 detection model from Stage 2. Lastly, we discuss the"}, {"title": "A. Stage 1 Results", "content": "To evaluate the effectiveness of FIN, we compared the predicted and true values for skewness and kurtosis across synthetic signals. The model's performance in approximating these statistical features demonstrates its capacity to learn and generalize well on unseen data. As shown in Figures 3, the predicted values closely match the true values.\nThe MSE and MAE for skewness and kurtosis during pretraining are as follows: for skewness, the MSE was 0.0066 and the MAE was 0.056, while for kurtosis, the MSE was 0.0059 and the MAE was 0.040."}, {"title": "B. Stage 2 Results", "content": "During the second stage, the model was trained specifically to discern between N1 sleep and the other classes, focusing on extracting relevant features for N1 identification. Despite the complexity of this task, the model achieved a balanced accuracy of 76.56%. The precision, recall, and F1 scores for both classes are shown in Table I."}, {"title": "C. Stage 3 Results: The Effect of Data Augmentation", "content": "To optimize the model's performance and handle class imbalances, we applied several data augmentation techniques. After augmentation, we achieved desirable changes in the sample numbers for each class. The augmentation techniques we used include SMOTE, ADASYN, and custom augmentation.\nTable II presents the overall and per-class accuracy of the model trained on these augmented datasets. The best-performing augmentation technique, SMOTE, yielded the highest performance metrics, as highlighted in bold."}, {"title": "D. Stage 3 Results: The Effect of Different Model Components", "content": "Furthermore, we evaluated the impact of various components integrated into the final model architecture during Stage 3. The analysis was focused on the contributions of weight initialization strategies and the utilization of KAN in enhancing model performance.\nEffects of Weight Initialization: Weight initialization plays a critical role in the training dynamics. We analyzed the consequences of omitting weight initialization for either the FIN or the N1 detector. The effects of these weight initialization strategies are depicted in Table II.\nNo Weight Initialization for FIN: Without the pretrained FIN, starting with random weights in Stage 3 resulted in a slower convergence rate as illustrated in Fig. 4 and also a decrease in accuracy. This highlights the importance of pretraining in enhancing learning efficiency and model stability.\nNo Weight Initialization for N1 Detector: Similarly, not initializing the N1 detector by omitting Stage 2 and beginning with random weights in Stage 3 led to slower convergence and lower accuracy, particularly for N1 identification."}, {"title": "E. Stage 3 Results: Best Model Results", "content": "We evaluated the final model on the non-augmented test dataset consisting of 3,000-sample ECG signals. The model trained on the SMOTE-augmented dataset achieved an overall best accuracy of 80.79% and a Cohen's kappa score of 0.73. The per-class performance metrics are outlined in Table III.\nThe confusion matrix in Fig. 5, provides a detailed breakdown of how each sleep stage was classified by the model. This allows us to analyze the specific misclassifications between stages, particularly challenging transitions like N1 vs N2 and N1 vs REM. In Table IV, we compare the performance of our proposed method with other ECG-based sleep stage classification studies."}, {"title": "IV. DISCUSSIONS", "content": "The results of this study highlight several key contributions to improving sleep stage classification, particularly the role of FINs, the N1 detector, and data augmentation techniques. Together, these components"}, {"title": "V. CONCLUSION", "content": "In conclusion, we have presented a novel approach to sleep stage classification using single-channel ECG signals, achieving high performance without using traditional multi-channel EEG data. By integrating FINs and an N1-specific detector, alongside data augmentation techniques especially SMOTE, the model has addressed key challenges such as class imbalance and the accurate classification of transitional sleep stages. The enhanced convergence speed and classification accuracy highlight the efficiency and effectiveness of this architecture in tackling the complexities of sleep stage classification.\nThese results open the door for more practical and less intrusive sleep monitoring applications, with potential for wearable or home-based devices. The ability to achieve strong performance with minimal data input suggests a"}]}