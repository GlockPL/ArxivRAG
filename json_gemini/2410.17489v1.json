{"title": "Unsupervised Domain Adaptation for Action\nRecognition via Self-Ensembling and Conditional\nEmbedding Alignment", "authors": ["Indrajeet Ghosh", "Garvit Chugh", "Abu Zaher Md Faridee", "Nirmalya Roy"], "abstract": "Abstract-Recent advancements in deep learning-based wear-\nable human action recognition (wHAR) have improved the cap-\nture and classification of complex motions, but adoption remains\nlimited due to the lack of expert annotations and domain dis-\ncrepancies from user variations. Limited annotations hinder the\nmodel's ability to generalize to out-of-distribution samples. While\ndata augmentation can improve generalizability, unsupervised\naugmentation techniques must be applied carefully to avoid intro-\nducing noise. Unsupervised domain adaptation (UDA) addresses\ndomain discrepancies by aligning conditional distributions with\nlabeled target samples, but vanilla pseudo-labeling can lead\nto error propagation. To address these challenges, we propose\n\u00b5DAR, a novel joint optimization architecture comprised of three\nfunctions: (i) consistency regularizer between augmented samples\nto improve model classification generalizability, (ii) temporal\nensemble for robust pseudo-label generation and (iii) conditional\ndistribution alignment to improve domain generalizability. The\ntemporal ensemble works by aggregating predictions from past\nepochs to smooth out noisy pseudo-label predictions, which are\nthen used in the conditional distribution alignment module to\nminimize kernel-based class-wise conditional maximum mean\ndiscrepancy (kCMMD) between the source and target feature\nspace to learn a domain invariant embedding. The consistency-\nregularized augmentations ensure that multiple augmentations\nof the same sample share the same labels; this results in (a)\nstrong generalization with limited source domain samples and (b)\nconsistent pseudo-label generation in target samples. The novel\nintegration of these three modules in \u00b5DAR results in a range\nof \u2248 4-12% average macro-F1 score improvement over six state-\nof-the-art UDA methods in four benchmark wHAR datasets.\nIndex Terms-Human Activity Recognition, Consistency Reg-\nularization, Temporal Ensembling, Cross-user Adaptation", "sections": [{"title": "I. INTRODUCTION", "content": "Over the past decade, wearable human activity recognition\n(wHAR) has enabled applications in healthcare [16], sports\nanalytics [7], and fitness tracking [26], leveraging inertial,\ngyroscopic, and magnetometric sensors in smartphones and\nsmartwatches to capture motion data, with neural process-\ning units facilitating real-time inference. However, traditional\nmodels rely on supervised learning and extensive labeled data,\nlimiting scalable, robust activity recognition. While Activities"}, {"title": "II. RELATED WORK", "content": "We discuss the relevant literature to \u00b5DAR on UDA in the\nWHAR and consistency regularization area with an emphasis\non handling cross-user variations and limited labeled data and\nto differentiate \u00b5DAR from the SOTA approaches.\n1) Wearable-based Unsupervised Domain Adapta-\ntion (UDA): have been significant advances in wearable-\nbased recognition of daily human activities [11], scaling\nthese models to more niche areas where annotations are\nscarce has been an open challenge, especially for activities\nthat require expert execution like sports and gym activities.\nUDA has become a valuable method for overcoming the\nchallenge of limited labelled data as it capitalizes on the\nabundance of available unlabeled data to enhance the model's\ngeneralizability and robustness. One of the few works\nincorporating UDA to tackle limited label data is [10],\nwhere the authors introduced a novel sample differentiation\ntechnique, utilizing a parameterized network to identify\nwhether a sample is from the source or target domain and\nadditionally involves assigning weights to pseudo labels for\ntarget samples based on the confidence level of the domain\nclassifier. However, recent SOTA studies have addressed\nminimal label information by minimizing conditional feature\ndistributions. In contrast, this work focuses on tackling\nlimited label data by minimizing conditional discrepancies.\n2) Consistency Regularization: has recently become promi-\nnent, especially in developing robust models invariant to data\nvariations, i.e., augmented samples [28]. The core principle"}, {"title": "III. METHODOLOGY", "content": "In this section, we present the \u00b5DAR framework for the\nwHAR domain, designed to recognize ADL actions, including\ngym and sports activities. We briefly outline the problem\nformulation and highlight the key functional and learning\ncomponents of \u00b5DAR."}, {"title": "A. Problem Formulation", "content": "Cross-user variations and limited expert-labeled datasets\nhinder the effectiveness of wHAR methods. We leverage\nlabeled data from experienced users (source domain), D = {(x\u1d62, y\u1d62)}\u1d62\u208c\u2081\u207f, and unlabeled data from new users (target\ndomain), D\u209c = {x\u1d62}\u1d62\u208c\u2081\u1d50. Here, n and m represent the number\nof instances in the source and target domains, respectively,\nwith both sharing the same label space, y, y \u2208 {1,2,...,c},\nwhere e denotes the number of activity classes. UDA aims\nto identify activities for new users by utilizing labeled source\ndata alongside unlabeled target data. This assumes that both\ndomains use identical sensors and placements, performing\nthe same activities, despite conditional distribution shifts, i.e.,\nP(y | x\u209b) \u2260 P(y | x\u209c).\nFigure 1 illustrates the proposed UDA framework, compris-\ning four key components to tackle these challenges: (i) learn-\ning source-specific features to capture trained user character-\nistics; (ii) generating high-quality pseudo labels via temporal\nensembling; (iii) aligning source and target features using the\nproposed kCMMD loss; and (iv) applying unsupervised data"}, {"title": "B. Supervised Learning Source-specific Feature Learning", "content": "We explore the supervised training process designed to\ncapture the unique features of the source domain data. Our\napproach involves a specifically tailored supervised training\narchitecture. This architecture consists of three convolutional\nlayers, each with an increasing number of filters and pro-\ngressively smaller kernel sizes. Each convolutional layer is\ncoupled with batch normalization and max-pooling layers to\nminimize internal covariate shifts and enhance learning of\nthe high and low-level features, respectively. Followed by\ntwo fully connected layers and a softmax layer for output.\nThe training objective is to minimize the CE supervised\nloss L\u209b\u2097 = -\u03a3\u1d62\u208c\u2081\u207f{P(y\u209b\u1d62|x\u209b\u1d62) log P(\u0177\u209b\u1d62|x\u209b\u1d62)} and ensure\naccurately predict the class distribution P(\u0176|X)."}, {"title": "C. Extracting Pseudo Labels using Temporal Ensembling", "content": "Adapting our supervised training pipeline from a well-\nlabeled source domain to a target domain devoid of labeled\ndata presents a significant challenge. This is further com-\nplicated by activities' inherent variability and complexity,\nespecially when dealing with data from synchronized sensors\non multiple wearable devices. To effectively generate high-\nquality pseudo labels in this context, we implement temporal\nensembling [12]. This method is designed to maximize the\nconcurrent extraction of mutual information from both the\nsource and target domains, which aims to enhance the pseudo-\nlabel generation process by aggregating model predictions in\nan iterative refinement update method highlighted in Eq. 1,\nwhere L, \u03b8, \u03b7, t and \u2207\u03b8L represents loss, model parameters,\nlearning rate, iteration step and gradient update, respectively.\nThis aggregation smoothens the overall label prediction and\nenhances the quality of the pseudo labels for the target domain.\nTemporal ensembling is a robust mechanism for identifying\nand learning domain-invariant features, thereby reducing dis-\ncrepancies between the source and target data over time. The\nmodel's adaptation to the target domain improves significantly\nby averaging predictions over time. Temporal ensembling\nmitigates class imbalance [4] by generating pseudo-labels and\nenabling stable learning, which helps in learning a balanced\ndata representation and alleviates the skew toward majority\nclasses seen in the labeled data. We determine the optimal\nsetting for a using a grid-search method and then fine-tuned\nit for the optimal performance across the datasets."}, {"title": "D. UDA via kernel-based class-wise conditional mean maxi-mum discrepancy (kCMMD)", "content": "We focus on aligning conditional distributions using our\nproposed kernel-based class-wise conditional mean maximum\ndiscrepancy (kCMMD) approach in the Reproducing Kernel\nHilbert Space (RKHS) [19]. In RKHS, conditional distri-\nbutions are mapped to a high-dimensional feature space,\nand kCMMD computes the mean discrepancy between these\nembeddings to minimize domain shifts. This reduces the\nconditional probability gap between the source (P\u209b (Z|Y)) and\ntarget (P\u209c(Z|Y)) domains, establishing a robust conditional\ndomain-invariant feature space. The generalized kCMMD loss\nis defined in Eq. 2, where C represents the number of classes,\nand n\ud835\udcb8 and m\ud835\udcb8 denote the number of samples from class c in\nthe source and target domains, respectively, with x\u1d62, x\u2c7c, x\u1d62*,\nand x\u2c7c* representing feature embeddings.\nConsidering our problem scenario, where the source domain\nis represented by a feature set x \u2208 \u211d\u207f\u00d7\u1d48 with corresponding\nlabels y\u209b, and a target domain represented by x\u209c \u2208 \u211d\u1d50\u00d7\u1d48 with\npseudo-labels \u0177\u209c, the kCMMD loss focuses on minimizing\ndistribution differences for each class c\u2208 C. kCMMD\nutilizes the Radial Basis Function (RBF) kernel, defined as\nK(\u03c6)(x, x') = exp(-\u03b3|x \u2212 x'|\u00b2), where \u03b3 is the kernel band-\nwidth parameter. For each class c from the source (X\u209b) and\ntarget (X\u209c) domains, we compute the following kernel matrices\n(KM), quantifying intra- and inter-domain discrepancies using\nelement-wise multiplication []:\nHere, I denotes the regularization constant added to the\ndiagonals of the source-source and target-target kernel ma-\ntrices to prevent issues like ill-conditioning, control overfit-\nting [19, 18] and class-imbalance during intra-domain com-\nputation. This regularization ensures that the learned features\nare adaptable and generalizable across users. Kernel methods\nare instrumental in capturing non-linear features and mapping\ndata into higher-dimensional spaces so non-linear relationships\ncan be linearly separated. The kCMMD loss is calculated as\nthe mean of discrepancies across all classes using a function\n\u03b4, which computes the mean discrepancy for each class. The\noverall regularized kCMMD discrepancy loss function for the\nkernel matrices K\u209b\u209b, K\u209c\u209c, and K\u209b\u209c is defined in Equation (3):\nEquation 3 measures the overall conditional discrepancy be-\ntween the source and target domain distributions. Regularized\nK\u209b\u209b and K\u209c\u209c represent the mean intra-domain similarities for\nthe source and target domains, respectively, while K\u209b\u209c quanti-\nfies the mean inter-domain similarity. The equation calculates\ndomain discrepancy by adding the mean similarities within\neach domain and subtracting twice the mean cross-domain"}, {"title": "E. Unsupervised Data Augmentation Module", "content": "We address user variability such as differences in activity\nexecution, proficiency levels and individual traits by integrat-\ning an unsupervised data augmentation approach [27] to build\nrobustness against cross-user variations. Our augmentation\nmodule ensures that (i) augmented samples are valid and real-\nistic, (ii) they exhibit diversity, and (iii) they introduce specific\ninductive biases. Recognizing that sudden temporal shifts in\nwearable data can impair model performance, we develop a\nmodel invariant with such transformations. To achieve this,\nwe implement two geometric-based augmentations: jitter in-\ntroduces high-frequency fluctuations in the data, distinct from\nactual motion, thereby adding stochastic noise and rotation\nwhich involves angular displacement or orientation change,\nquantifying the degree and axis of rotational movement which\nare well-established for capturing real-world variations in\nWHAR tasks [25]. Let G denote the geometric augmentation\napplied to the source and target data, x\u209b and x\u209c, defined as\nG = [r\u2091, \u03c3]. The augmented samples are then x' = G.x, and\nx' = G.x\u209c. Our goal is to enforce consistency between the\nmodel's predictions on original and augmented data, ensuring\nrobustness to user-specific variations. We employ a consistency\nloss (Eq. (4)), where f(x\u209b), f(x'\u209b), f(x\u209c), and f(x\u209c')\nrepresent predictions for real and augmented samples. This\napproach aligns with the Lipschitz continuity theorem [9],\nensuring the model's outputs change proportionally with input\nvariations, enhancing generalization to diverse user variations."}, {"title": "F. DAR Training Procedure", "content": "The overall aim is to obtain a set of optimized model\nparameters trained on labeled source data that work well on\nthe target domain and generate high-quality pseudo labels for\nthe target domain. To generate high-quality pseudo labels,\nwe utilize the ensembling approach due to the ability to\nsmoothen noisy pseudo labels. Additionally, we adopted a\nconditional probability alignment approach, which provides a\nrobust domain-invariant feature embedding. We highlight the\noverall joint optimization objective function for \u00b5DAR frame-\nwork enumerated in Equation (5). In the overall formulation,\n\u0398 encompasses all the parameters within the deep network.\nThe hyperparameters \u03b2\u2080 and \u03b2\u2081 are set to 1, facilitating the\nfne-tuning of the overall objective function."}, {"title": "IV. EXPERIMENTS", "content": "We evaluate \u00b5DAR via extensive experiments on the prob-\nlem of limited supervision settings for ADLs action recogni-\ntion by investigating the following research questions (RQs):\n(i) RQ1 (Accuracy): How well is \u00b5DAR performing on\npublically available datasets? (ii) RQ2 (Robustness): How can\nwe adapt \u00b5DAR for accurate recognition across different users'\nproficiency levels in wHAR? (iii) RQ3 (Compatibility): Is\n\u00b5DAR optimized for high quality pseudo-labels generation?\n(iv) RQ4 (Comparative Analysis): Is \u00b5DAR minimizing\nconditional data distribution discrepancies?"}, {"title": "A. Setup", "content": "1) Datasets: We selected four publicly available datasets\n(1) Badminton Activity Recognition (BAR) Dataset [8],\ncapturing 12 badminton strokes from 11 subjects in controlled\nand uncontrolled environments, with 30 iterations per stroke.\n(2) Daily and Sports Activity (DSADS) Dataset [1], fea-\nturing 9-DOF sensor data from eight individuals performing\n19 activities, recorded at 25 Hz. (3) Physical Activity Mon-\nitoring (PAMAP2) Dataset [17], consisting of 18 activities\nfrom nine subjects, captured at 100 Hz from three sensors. (4)\nWorkout Activities (MM-DOS) Dataset [21], with IMU data\nfrom 50 participants performing four gym workouts, recorded\nat 50 Hz across nine body locations.\n2) Baselines: We evaluate and contrast the performance\nof \u00b5DAR with six SOTA UDA algorithms including SWL-\nAdapt [10], ContrasGAN [20], AdvSVM [13], HoMM [3],\nDUA [15] and CoTMix [5]."}, {"title": "B. Implementation Details", "content": "1) Data Pre-Processing: This study uses raw signals from\naccelerometers, gyroscopes, and magnetometers in a body-\nworn IMU sensor network as input features. To address\nmotion artifacts, we applied a median filter and normalized\n48 features using a min-max scaler for the BAR dataset,\nwhich includes data from three sensor axes. Due to signal\nclipping beyond \u00b12g in the low-noise accelerometer, we used\nwide/high-range accelerometers to capture rapid movements\nmore effectively. For feature extraction, we applied a sliding\nwindow technique with varying overlap and sampling rates\nacross the BAR, PAMAP2, DSADS, and MMDOS datasets to"}, {"title": "C. Results and Discussion", "content": "1) Classification Performance (RQ1): In this analysis,\nwe compare and contrast \u00b5DAR against six state-of-the-art\n(SOTA) UDA algorithms, demonstrating a significant average\nimprovement of \u2248 4-12% across four public datasets. Our re-\nsults distinguish the top-performing and second-best methods,\nrevealing that SWL-Adapt frequently surpasses other UDA\nalgorithms, likely due to its meta-optimized loss function,\nwhich assigns sample weights, enhances domain alignment,\nand improves cross-user adaptation, as shown in Table II.\nNotably, \u00b5DAR excels across all datasets, covering activ-\nities from complex gym and sports-related actions to ADLS\nand iADLs. Its strength lies in using temporal ensembling to\ngenerate reliable pseudo-labels and integrating kernel-based\nclass-wise conditional mean maximum discrepancy (kCMMD)\nto enhance domain adaptation. Additionally, performance im-\nproves with consistency regularization, effectively handling\naugmented sample variations in real-world settings and further\nsupporting analyses are presented in section IV-C4."}, {"title": "2) Robustness of \u00b5DAR to User-Variations (Proficiency levels) (RQ2)", "content": "We assess the robustness and scalability of\nthe \u00b5DAR framework by comparing across SOTA baseline\nalgorithms for handling cross-user proficiency variations. The\nexperiment trains models using expert data (source users)\nand evaluates their performance on beginner data (target\nusers). Results show that \u00b5DAR significantly outperforms\nbenchmarks, with an average macro F1 score improvement\nof [7.3 \u00b1 (1.54)]%. \u00b5DAR's success is due to its effective\nuse of temporal ensembling, where the \u03b1 parameter helps\nidentify unique instance-based features across genders. By\nincorporating kCMMD loss and consistency, regularization\ncaptures non-linear features in high-dimensional space and\nensures consistent predictions. Further analysis on optimizing\nthe \u03b1 parameter and its impact on pseudo-label quality is\nhighlighted in section IV-C3.\nWe present the cross-proficiency user adaptation perfor-\nmance comparing the best accuracy SOTA SWL-Adapt al-\ngorithm and \u00b5DAR using the MM-DOS dataset and DAR\nachieves an approximate 11% improvement over SWL-Adapt\nas shown in Figure 4. Additionally, the results demonstrate\nthat \u00b5DAR outperforms SOTA UDA algorithms in the wHAR\ndomain across cross-user and cross-dexterity variations."}, {"title": "3) Compatibility Study (RQ3)", "content": "In this study, we evalu-\nated the effectiveness of self-ensembling for generating reli-\nable pseudo-labels in the target domain. We used entropy,\n{H(x) = \u03a3\u1d62\u208c\u2081\u1d9cP(x\u1d62) log(p(x\u1d62))}, to quantify prediction\nuncertainty. As shown in Figure 2b, there is an inverse rela-\ntionship between the \u03b1 parameter of ensembling and entropy:\nhigher \u03b1 leads to lower uncertainty, indicating more stable\npseudo labels. Our experiments found that an \u03b1 range of [0.55-\n0.75] is optimal for generating high-quality pseudo-labels."}, {"title": "4) Comparative Analysis (RQ4)", "content": "This analysis evaluates\nthe individual and combined effects of temporal ensembling,\nkCMMD loss, and consistency regularization on \u00b5DAR's per-\nformance across four SOTA datasets. We report normalized F1\nscores to demonstrate the synergy across three augmentation\nsettings, as shown in Figure 3, highlighting the generalizability\nand robustness of \u00b5DAR. Our results show a significant\nimprovement of [22-26%] when incorporating all methods\nover the baseline (no adaptation), as depicted in Fig. 3a, 3b,\nand 3c. This synergy enhances overall performance, advancing\ndomain generalization for the wHAR domain."}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "This work introduces a novel single-stage joint optimization\nstrategy for cross-user wHAR domain. Our approach integrates\ntemporal-ensembling with kernel-based class-wise conditional\nmean maximum discrepancy (kCMMD), effectively generating\nhigh-quality pseudo labels and minimizing conditional domain\ndiscrepancies. Additionally, using KL divergence for consis-\ntency regularization stabilizes label predictions in the presence\nof augmented samples. The \u00b5DAR framework demonstrated\nnotable superiority over benchmark UDA algorithms in ex-\ntensive experiments, showing generalizability and robustness,\noutperforming SOTA approaches by \u2248 4-12%.\nIn the future, we plan to expand the capabilities of the\n\u00b5DAR framework by exploring higher-order statistics-based\nmethods, such as cross-covariance estimation for conditional\nembedding alignment. These enhancements will advance do-\nmain generalization in the wHAR domain, paving the way for\nmore versatile and effective action recognition systems."}], "equations": ["\u03b8\u209c\u208a\u2081 = \u03b8\u209c - \u03b7 . \u2207\u03b8L", "Lc = E\u2093\u209b ~ D\u209b, x'\u209b ~ t(x\u209b) [DKL(f\u03b8(x\u209b)||f\u03b8(x'\u209b))] +\n        E\u2093\u209c ~ D\u209c, x+ ~t(x\u209c) [DKL(f\u03b8(x\u209c)||f\u03b8(x\u209c'))]", "min Loverall = LSL + \u03b2\u2080LkCMMD +\n    \u0398\nDomain Adaptation\n\u03b2\u2081LC\nConsistency Regularizer"]}