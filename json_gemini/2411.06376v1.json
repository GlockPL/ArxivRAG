{"title": "Phantom: Constraining Generative Artificial Intelligence Models for Practical Domain Specific Peripherals Trace Synthesizing", "authors": ["Zhibai Huang", "Yihan Shen", "Yongchen Xie", "Zhixiang Wei", "Yun wang", "Fangxin Liu", "Tao Song", "Zhengwei Qi"], "abstract": "Peripheral Component Interconnect Express (PCIe) is the de facto interconnect standard for high-speed peripherals and CPUs. Prototyping and optimizing PCIe devices for emerging scenarios is an ongoing challenge. Since Transaction Layer Packets (TLPs) capture device-CPU interactions, it is crucial to analyze and generate realistic TLP traces for effective device design and optimization. Generative AI offers a promising approach for creating intricate, custom TLP traces necessary for PCIe hardware and software development. However, existing models often generate impractical traces due to the absence of PCIe-specific constraints, such as TLP ordering and causality. This paper presents Phantom, the first framework that treats TLP trace generation as a generative AI problem while incorporating PCIe-specific constraints. We validate Phantom's effectiveness by generating TLP traces for an actual PCIe network interface card. Experimental results show that Phantom produces practical, large-scale TLP traces, significantly outperforming existing models, with improvements of up to 1000x in task-specific metrics and up to 2.19x in Fr\u00e9chet Inception Distance (FID) compared to backbone-only methods.", "sections": [{"title": "Introduction", "content": "Artificial intelligence tasks, including training, inference, and deployment, rely heavily on Peripheral Component Interconnect Express (PCIe) devices. Optimizing systems to support AI workloads through these peripherals has become a research focus. PCIe is the most common interconnection network for peripherals and hosts and is essential for devices like graphics cards, SSDs, and network interface cards. Transaction Layer Packets (TLP) are the smallest units of information transmitted within a PCIe network, similar to IP packets. Understanding a device's TLP transaction pattern is crucial for modeling its impact on the CPU and assisting in design. However, identifying these patterns is challenging due to variations in task loads, network configurations, device models, and software updates. Therefore, preserving these patterns in some form for subsequent use is necessary. These patterns can be captured and formatted into traces suitable for subsequent analysis and storage. By replaying execution traces, developers can recreate environments and uncover hidden issues. If a TLP transaction trace for a device is obtained, the modeling for this device is nearly complete. However, obtaining the necessary traces can be daunting. For instance, collecting traces from a running server cluster could disrupt performance. Collecting traces from prototype hardware without actual samples is impractical when co-designing hardware-software. Even if traces are available, they may contain noise, making data collection and cleaning labor-intensive.\nTherefore, relying solely on collected traces is restrictive, and synthetic traces should be considered. Unfortunately, synthesizing PCIe TLP traces is challenging. Consider Figure 1, which illustrates the interaction between a PCIe Network Interface Card (NIC) and the CPU, highlighting characteristics reflected in the collected trace. Most PCIe operations use Memory-Mapped Input/Output (MMIO), which operations at different addresses interact with different components within the peripheral. For instance, operations at different positions within the BAR register mapping area affect different device registers, configuring various electrical states. Bulk data transfers rely on address constraints for asynchronous data transfer via the DMA engine. Given the influence of the software and hardware stack, TLP trace entries inherently include constraints such as order, causality, and data size limits. Ignoring these constraints in synthesized traces would render the content meaningless.\nWhile traditional statistical-based methods for synthesizing traces offer controllability and interpretability, they often fall short of capturing the complex patterns inherent in PCIe TLP transactions. These methods, such as sampling and rule-based stitching, lack the flexibility and precision needed for high accuracy in this domain. As a result, there is growing interest in leveraging generative AI, which has proven successful in other areas like network traffic generation, security testing, and hardware design. However, applying AI to PCIe TLP trace synthesis presents its own set of challenges: (1) how to convert the problem to a typical content generation task to leverage successful practices from related fields, and (2) how to introduce domain expertise as constraints to ensure controllability and predictability.\nTo address these challenges, we propose Phantom, a synthesizer using generative AI, meanwhile ensuring the traces generated by the backbone model align with user requirements and closely resemble real data. Phantom comprises a backbone generative AI and a content calibration post-processor, as illustrated in Figure 2. The content calibration post-processor is divided into three stages: normalization, calibration, and decoding. To address the challenges mentioned above, we design a mapping between TLP operations and RGB triplets, redefining the PCIe TLP generation problem as an image generation task implemented in the normalization and decoding stages. Additionally, we employ a convolution-like method based on pixel dispersion, enabling selective inclusion of generated patterns or prior knowledge through hyperparameters. This forms the core of the calibration stage. This approach allows domain expertise to guide trace generation directly. The key contributions of our work can be summarized as follows:\n1. We redefine the synthesis of PCIe TLP traces as an image generation problem, enabling the application of image-based designs and concepts to serve as building blocks.\n2. To our knowledge, this is the first work that translates PCIe domain expert knowledge into constraints for generative AI, ensuring that the generated trace is both controllable and predictable.\n3. We systematically construct a PCIe TLP trace synthesizer called Phantom, designed to assist with the research and design of new peripherals and related systems.\n4. Extensive experiments demonstrate that Phantom can adapt to various existing AI generators and significantly improve performance on task-specific metrics by up to 1000x, as well as the Fr\u00e9chet Inception Distance (FID) metric by up to 2.19\u00d7, efficiently calibrating generated data.\nOur work has been made open-source and is available for public use\u00b9."}, {"title": "Related Work", "content": "Peripherals are vital to modern computer architecture and are a significant area of focus in research on both architecture and system software. Although there has been substantial research on PCIe peripherals, the PCIe network,"}, {"title": "Constraints for generation tasks", "content": "Generative AI models have seen widespread application in design and research, with successful practices including the use of GANs and diffusion models for generating traffic data, as well as automatic code and test case generation in software engineering. However, controlling the output of these models is crucial for producing meaningful content. For instance, prompts and semantic guidance are used in large language models and traditional generative approaches to manage the content generated.\nTo produce desired content, specific task-related constraints must be applied to generative models. A significant challenge that previous research has overlooked is the need to map the ordering and causality in TLP traces to AI model constraints. Phantom addresses this issue by aligning PCIe hardware constraints with AI models, employing an image-inpaint-like strategy to identify and correct counterfactual errors in generated content. This approach ensures compatibility with existing constraint methods while maintaining performance comparable to the backbone model and offering higher interpretability than traditional methods."}, {"title": "Methodology", "content": "In this study, we address an optimization problem focused on designing a Generator and fine-tuning its parameters \u03b8 so that the generated trace data Generator(\u03b8, prompt) closely approximates the real trace data T. The generated trace data is required not only to resemble the real trace data T but also to incorporate the pattern described by the prompt, with the stipulation that this pattern must also be present in T. The objective of this optimization is to minimize the distance D(T, Generator(\u03b8, prompt)) between the generated trace data and the real trace data, formulated as:\n$\\min_{Generator, \\theta} D(T, Generator(\\theta, prompt))$\nThis is subject to the constraints defined by the mapping function M(prompt) and the pattern detection function f, specifically:\n$M(prompt) \\subseteq f(T)$\nand\n$M(prompt) \\subseteq f(Generator(\\theta, prompt))$\nIn production environments, traces are typically stored and processed in text form due to its accuracy and conciseness, making it ideal for logs in computer systems. However, simple textual descriptions of PCIe TLP traces can be counter-intuitive for human analysis and challenging for AI models to capture relevant features. This is because the human brain is less responsive to text than images, and language models struggle with long text generation, as required for PCIe TLP traces. To overcome these challenges,"}, {"title": "Visual Encoding and Decoding of TLP Traces", "content": "we propose a bidirectional mapping method to encode text-based traces into a visual format. This method will enhance human analysis and pattern selection while enabling image generation models to produce the required traces, broadening the range of available backbone models. We start by defining PCIe TLP trace data:\nA record $S_i \\in {S}_{i=1}^{N}$ is defined by data size $S_{byte}$, transmission direction $S_{dir}$, and timestamp $S_{time}$ as $S_i = (S_{byte}, S_{dir}, S_{time})$. A trace T is a finite set of records $T = {T}_{i=1}^{|T|}$, each representing a TLP transaction.\nUnlike the trace depicted in Figure 1, the target address is omitted for simplicity, with future work focused on addressing more complex scenarios. Since timestamps from sorted real data can be reused, generating new timestamps is unnecessary. Instead, ensuring the sequence is time-ordered allows us to discard the timestamp information and use the entry's position as a logical timestamp, simplifying the triplet to a pair. We can then define a mapping from the transaction triplet to an RGB triplet $D_i$ as follows:\n$H_i = \\frac{S_{byte}}{256}$\n$D_i = (H_i, S_{byte} - 256 \\times H_i, S_{dir} \\times 255)$\nThe inverse mapping can be naturally derived from the given mapping and is not elaborated further. With these mappings, we achieve bidirectional conversion between transaction triplets and RGB triplets. Once this mapping between a PCIe TLP trace's smallest unit, the transaction triplet, and the smallest unit of an image, the RGB pixel, is established, we only need to map the arrangement of transaction triplets in the trace to the arrangement of RGB pixels in the image. This foundation sets the stage for the Dispersion-Based Calibration Method, which further builds on these visual encoding principles to enhance the analysis of PCIe TLP traces."}, {"title": "Dispersion-Based Calibration Method", "content": "Building on the visual encoding and decoding of TLP traces, we design a method to quantitatively calibrate the generated data using real data. The backbone model may generate content with singularities that are incompatible with actual device TLP patterns. These singularities, which could be noise introduced during generation or inherent errors, need to be identified for calibration. A straightforward approach is to draw on successful practices in image denoising. However, these methods often assume the images are inherently trustworthy. In our case, singularities may result from the model's failure to capture required patterns, rather than simple noise, making direct application of these methods ineffective. To address the problem, we can use mathematical techniques to statistically analyze image features and identify the singularities.\nFirst, we assume the backbone generation model is capable of producing content with \u201creal\u201d patterns and that a large dataset of real data is available to encompass all learnable patterns. By comparing the generated content to a similar prior knowledge sample, considered as ground truth, we can identify \u201csingularities\u201d by measuring discrepancies between them. The challenge lies in accurately identifying the ground truth. In practice, finding a perfect match is nearly impossible, so not all discrepancies can be assumed as singularities. We must distinguish whether these differences result from pattern mismatches or actual singularities. To this end, we design a convolution-like method to calculate the degree of dispersion, as defined below:\nDenote the tensor corresponding to $S_i$ and $T_i$ under the map (4) as $\\tilde{S_i}$ and $\\tilde{T_i}$. Through a feature extractor $extractor(\\cdot)$ (e.g., AI models), we obtain the embedding of $S_i$ and $T_i$ denoted as $s_{encode}$ and $t_{encode}$. The distance between $s_{encode}$ and $t_{encode}$, is denoted as $dist_{encode}$, using metric $dist_{encode}(\\cdot)$ (e.g., cosine similarity). Define a new metric\n$dist_{pixel}(x, y) = \\sum_{i=1}^3 a_i |x_i - y_i|, \\quad a_i > 0$\nThe neighborhood of indices is defined as\n$B_n(l, m) = \\{(l_0, m_0)| |l - l_0| \\le n, |m - m_0| \\le n\\}$\nFor fixed indices i and j, the maximal and minimal distance denote\n$M_{ij} = \\max_{1 \\le l, m \\le 512} dist_{pixel}(\\tilde{S}_{l,m,:}, \\tilde{T}_{l,m,:})$,\n$m_{ij} = \\min_{1 \\le l, m \\le 512} dist_{pixel}(\\tilde{S}_{l,m,:}, \\tilde{T}_{l,m,:})$\nTo distinguish whether dots in $\\tilde{T_i}$ is a singularity, the dispersion vector $T_{l,m,:}$ is calculated as follows\n$\\tilde{T}_{l,m,:} = \\frac{dist_{encode} - M_{ij}}{M_{ij} - m_{ij}}$\n$T_{l,m,:} = \\sum_{(l_0,m_0) \\in B_2(l,m)} \\beta_i \\tilde{T}_{l_0,m_0:}$\nwhere $dist_{pixel}(x, y)$ represents the pixel-wise distance between the selected real sample x and the generated content y, and Tim is the resulting dispersion vector. Users can specify weights to compute and identify \u201csingularities\u201d in the generated content for subsequent calibration.\nThis method provides considerable design flexibility for matching the real sample with the generated content and calibrating the singularitys. We choose a straightforward approach: extracting embeddings of the input image for matching and directly replacing pixels in the generated content with those from the corresponding positions in the real sample, based on a user-defined acceptance threshold. The pseudocode for our dispersion-based calibration method is provided in Algorithm 1. This approach equips Phantom with the capability of selectively combining patterns from prior knowledge and generated contents, as shown in Figure 3."}, {"title": "Design of Phantom", "content": "With the core mechanisms of visual encoding and decoding of TLP traces and the dispersion-based calibration method in place, we proceed to design the synthesizer for specific tasks. Phantom is structured as a pipeline with one generation stage followed by three calibration stages. To ensure its practicality, Phantom only requires that the backbone generative AI model can produce content in text or image format, with no further restrictions. Additional training or fine-tuning may be needed for generating specific content.\nThe calibration process is divided into three stages: normalization, calibration, and decoding. The main tasks of these stages are as follows:\nNormalization Stage If the input is in text form, it is converted into a human-readable and analyzable image format using the mapping in Equation 4. If the input is already in image form, it undergoes pre-processing, including pruning and basic noise removal. Once this stage is complete, all content is converted into a normalized image format.\nCalibration Stage This stage comprises two components: a feature extractor and a filter. The feature extractor generates embedding vectors from the input content and compares them with vectors from a real dataset to identify the most similar real data sample. This sample and the generated content are then passed to the filter for calibration. Similarity is measured using metrics like cosine similarity and Peak Signal-to-Noise Ratio (PSNR). Feature extractors include pre-trained and custom-trained deep neural networks, as well as simple row vector methods. The filter applies dispersion-based calibration as described in Algorithm 1. Calibration can be disabled or the generated content can be entirely rejected by setting the acceptance threshold to 1 or 0. Users can adjust the acceptance threshold and weights for distance and dispersion to modify the generated content, reducing uncertainty and uncontrollability.\nDecoding Stage After calibration, this stage decodes the image-form content into the final synthesized PCIe TLP trace using the inverse mapping in Equation 4. This trace can assist in validating and developing new designs.\nThe structure of Phantom is presented in Figure 2. Encoding the generated content into image format allows users to intervene at any stage, further enhancing controllability. This design maximizes the backbone generative model's controllability and removes obstacles to applying AIGC in this field."}, {"title": "Experiments", "content": "We conduct experimental evaluations of Phantom on the same X86 personal computer used for dataset collection. For computing pixel distances, the parameter \u03b1 in Equation 5 is uniformly set to (1, 100, 10000), and for dispersion calculation, the parameter \u03b2 in Equation 7 for calculating singularities is uniformly set to (1/12, 1/6, 1/2, 1/6, 1/12). The acceptance threshold is dynamically adjusted according to different evaluation features and metrics, within a range from 1 to $1 \\times 10^{-10}$.\nAs an essential element within the Phantom framework, we utilize various deep neural networks with distinct characteristics as generators, including GAN, VAE, Stable Diffusion, Long Short-Term Memory (LSTM), Llama, and GPT40. Besides large language models and Stable Diffusion, we implement additional generator models based on open-source code and train them using the collected dataset. LLMs and Stable Diffusion are quickly engineered and fine-tuned to meet our specific requirements.\nAnother crucial component of Phantom, the feature extractors, involves three types of deep neural networks: simple methods, pre-trained networks, and networks specifically trained for the given data. We compare five extractors (extractor(\u00b7)) and two similarity metrics (distencode (.)): naive (N), MobileNet (M), Inception V3 (I), VAE-encoder (V), GAN-discriminator (G), and the similarity metrics cosine similarity (c) and PSNR (p)."}, {"title": "Evaluation Metrics", "content": "Unlike traditional generation tasks, generating TLP traces requires a much lower error tolerance. Even minor inaccuracies can lead to generated content that does not reflect rational transaction logic. Thus, traditional generation task evaluation metrics alone are insufficient. Considering these factors specific to peripheral TLP trace generation tasks, we design two new evaluation metrics: Transmission Package Error and Transmission Traffic Error. These metrics assess the rationality and correctness of the generated entries corresponding to TLP transactions within a frame. The definitions of these two metrics are as follows:\n\u2022 Transmission Package Error (PE):\n$\\frac{\\sum_{i=1}^{T} (w_t \\cdot \\frac{\\sum_{j=1}^{m} \\left| \\Delta_{i,j} \\right|}{m})}{\\sum_{i=1}^{T} (w_t)} $\n\u2022 Transmission Traffic Error (TE):\n$\\sum_{i=1}^{T} \\left( \\frac{\\sum_{dir=0}^{1} ( \\sum_{j=1}^{m} ( \\frac{w_{j, dir} \\cdot \\left| \\Delta_{dir, j, i} \\right|}{W_{total, dir}}) + w_t \\cdot \\frac{\\sum_{j=1}^{m} \\left| \\Delta_{0, j, i} + \\Delta_{1, j, i} \\right|}{m}) }{2} + w_t \\cdot \\frac{\\sum_{j=1}^{m} \\left| \\Delta_{1, 3, i} \\right|}{m} \\right)$\nThe metrics use the following variables: wt is the penalty weight for total throughput or wrong direction. wj represents the penalty weights for each of the m segments. wj is the penalty weight vector for each segment, including wj,0 for the send direction and wj,1 for the receive direction. Wtotal, dir is the penalty weight for the total send/receive direction (dir = 0 for send and dir = 1 for receive). Dsynth, dir,j,i and Dreal,dir,j,i are the synthetic and real data values at the i-th time frame, j-th segment, and dir direction. The difference between synthetic and real data is \u0394dir,j,i = Dsynth,dir,j,i \u2212 Dreal,dir,j,i. T is the number of time frames, and m is the number of segments.\nIn addition to task-specific metrics, we also use Fr\u00e9chet Inception Distance (FID) as a representative metric for traditional generation models. To calculate PE and TE, each generated image is compared to the closest real content, as identified by the feature extractor. A batch of four generated images is processed alongside"}, {"title": "Experiment on Task-Specific Metrics", "content": "We test Phantom's performance improvement over using generators without calibration. Several neural network generators and a baseline random generator with an acceptance threshold of 1 \u00d7 10-8 are evaluated. As shown in Table 1, PE typically improves by double digits. For VAE and LSTM, Phantom often eliminates PE, benefiting from VAE's high-quality content and LSTM's reliance on real data to correct singularities. Fine-tuned feature extractors perform better, emphasizing the value of using similar ground truth data for calibration."}, {"title": "Ablation Study", "content": "To assess the impact of Phantom's components on generation quality, we conduct tests on several cases under different component setups. We select feature extractor configurations that best optimize TE. As shown in Figure 5, Phantom's performance on FID appears suboptimal. This is because the FID metric is not designed for TLP trace generation tasks, and our configurations are optimized for minimizing TE rather than FID. Notably, simply adding the filter for calibration does not always improve performance, as the prior knowledge samples used might differ too much from the generated content. However, with embedding matching, the similarity between the two increases significantly, making calibration more effective and resulting in substantial improvement."}, {"title": "Generation Quality Convergence", "content": "Finally, we assess Phantom's convergence. As shown in Figure 6, except for the worst-case random generation, both Stable Diffusion and GPT4o exhibit a decreasing trend in FID after Phantom calibration. This demonstrates Phantom's ability to align generated content more closely with real TLP trace data in accordance with user requirements."}, {"title": "Conclusion", "content": "In this study, we presented a novel approach to generating TLP traces for PCIe peripherals using generative AI, facilitating device prototyping and development. By reframing PCIe trace generation as an image generation problem, we successfully applied advanced image generation techniques to this domain. We addressed the critical challenge of controlling the generative AI model by mapping PCIe patterns to AI constraints, thereby enhancing the predictability and controllability of the generated traces. We develop Phantom, a versatile generator compatible with state-of-the-art generative models that are designed to produce high-performance PCIe traces. Phantom's outputs, guided by user-defined hyperparameters, range from baseline AI-generated traces to those closely resembling real data. Extensive experimental evaluations demonstrate that Phantom significantly outperforms standalone AI generators across both task-specific and general metrics, marking a substantial advancement in synthesizing PCIe TLP traces."}]}