{"title": "Improving the Quality of Persian Clinical Text with a Novel Spelling\nCorrection System", "authors": ["Seyed Mohammad Sadegh Dashti", "Seyedeh Fatemeh Dashti"], "abstract": "Background: The accuracy of spelling in Electronic Health Records (EHRs) is a critical factor for\nefficient clinical care, research, and ensuring patient safety. The Persian language, with its\nabundant vocabulary and complex characteristics, poses unique challenges for real-word error\ncorrection. This research aimed to develop an innovative approach for detecting and correcting\nspelling errors in Persian clinical text.\nMethods: Our strategy employs a state-of-the-art pre-trained model that has been meticulously\nfine-tuned specifically for the task of spelling correction in the Persian clinical domain. This model\nis complemented by an innovative orthographic similarity matching algorithm, PERTO, which\nuses visual similarity of characters for ranking correction candidates.\nResults: The evaluation of our approach demonstrated its robustness and precision in detecting\nand rectifying word errors in Persian clinical text. In terms of non-word error correction, our model\nachieved an F1-Score of 90.0% when the PERTO algorithm was employed. For real-word error\ndetection, our model demonstrated its highest performance, achieving an F1-Score of 90.6%.\nFurthermore, the model reached its highest F1-Score of 91.5% for real-word error correction when\nthe PERTO algorithm was employed.\nConclusions: Despite certain limitations, our method represents a substantial advancement in the\nfield of spelling error detection and correction for Persian clinical text. By effectively addressing\nthe unique challenges posed by the Persian language, our approach paves the way for more\naccurate and efficient clinical documentation, contributing to improved patient care and safety.\nFuture research could explore its use in other areas of the Persian medical domain, enhancing its\nimpact and utility.", "sections": [{"title": "1. Introduction", "content": "Spelling correction is a vital task in all text processing environments, with its importance amplified\nfor languages with intricate morphology and syntax, such as Persian. This significance is further\nheightened in the realm of clinical text, where precise documentation is a cornerstone for effective\npatient care, research, and ensuring patient safety The written text of medical findings remains the\nessential source of information for clinical decision making. Clinicians prefer to write unstructured\ntext rather than filling out structured forms when they document the progress notes, due to time\nand efficiency constraints [1]. The quality and safety of health care depend on the accuracy of\nclinical documentation [2]. However, misspellings often occur in clinical texts because they are\nwritten under time pressure [3].\nThe process of spelling correction primarily tackles two types of errors: non-word errors, which\nare nonsensical words not found within a dictionary, and real-word errors, that are correctly spelled\nwords but utilized inappropriately in context. These errors can stem from various sources including\ntypographical mistakes, confusion between similar sounding or meaning words [4], incorrect\nreplacements by automated systems like AutoCorrect features [5], and misinterpretation of input\nby ASR and OCR systems [6-9].\nThe Persian language, with its rich vocabulary and complex properties, presents unique challenges\nfor real-word error correction. Features unique to Persian such as homophony (words that are\npronounced identically yet carry distinct meanings), polysemy (words with multiple meanings),\nheterography (words that share identical spelling but their meanings vary based on how they are\npronounced), and word boundary issues contribute to this complexity.\nDespite these challenges, numerous efforts have been made to develop both statistical and\nrule-based approaches for identifying and rectifying both classes of errors in the general Persian\ntext domain; however, the work in the Persian medical domain and specifically the Persian clinical\ntext is very limited. Moreover, these methods have attained only limited success. In this study, we\nintroduce an innovative method to detect and correct word errors in Persian clinical text, aiming\nto significantly improve the accuracy and reliability of healthcare documentation. Our key\ncontributions include:\n\u2022\nLanguage Representation Model: We showcase a pre-trained language representation model\nthat has undergone meticulous fine-tuning, specifically for the task of spelling correction in\nthe Persian clinical domain."}, {"title": "2. Related Works", "content": "Automatic word error correction is a crucial component in NLP systems, particularly in the\ncontext of EHR and clinical reports. Early techniques were based on edit distance and phonetic\nalgorithms [10-13]. The incorporation of context information has been demonstrated to be\neffective in boosting the efficiency of auto-correction systems [14]. Contextual measures like\nsemantic distance and noisy channel models based on N-grams have been employed across\nnumerous NLP applications [4, 5, 15-17]. A novel approach was also developed to correct multiple\ncontext-sensitive errors in excessively noisy situations [18]. Dashti developed a model that\naddressed the identification and automatic correction of context-sensitive errors in cases where\nmore than one error existed in a given word sequence [19].\nCutting-edge methods in NLP systems utilize context information through neural word or\nsense embeddings for spelling correction [20]. Pretrained contextual embeddings have been used\nto detect and rectify context-sensitive errors [21]. The issue of spelling correction has been\naddressed using deep learning techniques for various languages in recent years. For example, a\nstudy in 2020 proposed a deep learning method to correct context-sensitive spelling errors in\nEnglish documents. [22]. Another work developed a BERT-Based model for the same purpose\n[23]. NeuSpell is a user-friendly neural spelling correction toolkit that offers a variety of pre-\ntrained models [24]. SpellBERT is a lightweight pre-trained model for Chinese spelling check\n[25]. A disentangled phonetic representation approach for Chinese spelling correction was\nproposed [26]. Other approaches for Chinese spelling correction utilized phonetic pre-training\n[27]. An innovative approach was devised specifically for the purpose of contextual spelling\ncorrection within comprehensive speech recognition systems [28]. A dual-function framework for\ndetecting and correcting spelling errors in Chinese was proposed [29]. Liu and colleagues proposed\na method, known as CRASpell, which is resilient to contextual typos and has been developed to\nenhance the process of correcting spelling errors in Chinese [30]. AraSpell is an Arabic spelling\ncorrection approach that utilized a Transformer model to understand the connections between\nwords and their typographical errors in Arabic [31].\nIn the realm of healthcare, the application of spelling correction techniques has been\ninstrumental in expanding acronyms and abbreviations, truncating, and rectifying misspellings. It\nhas been observed that such instances constitute up to 30% of clinical content [32]. In the last\ntwenty years, a significant amount of research has been conducted on spelling correction methods\nspecifically designed for clinical texts [1]. The majority of these studies have primarily focused on\nEHR [33], while a few have explored consumer-generated texts in healthcare [34, 35].\nSeveral noteworthy contributions in this field include the French clinical record spell\nchecker introduced by Ruch and colleagues, which boasts a correction rate of up to 95% [36]."}, {"title": "2.1 Persian Spelling Challenges", "content": "Persian, alternatively referred to as Farsi, belongs to the Indo-Iranian subgroup of the Indo-\nEuropean family of languages. It holds official language status in countries such as Iran, Tajikistan,\nand Afghanistan. Over time, Persian has incorporated elements from other languages such as\nArabic, thereby enriching its vocabulary. Despite these influences, the fundamental structure of\nthe language has largely remained intact for centuries [55, 59].\nWhile Persian is a vibrant and expressive language, it presents several challenges for language\nprocessing:\n1. Character Ambiguity: Persian characters like \u201c\u0649\u201d and \u201c\u064a\" are often used interchangeably\nbut represent different sounds [60].\n2. Rich Morphology: New words can be created by adding prefixes and suffixes to a base\nword like \"\u062f\u0633\u062a\u201d )hand) to \u2018\u2018\u062f\u0633\u062a\u0647\u0627\u201d )hands( ]61[.\n3. Orthography: Persian involves a combination of spaces and semi-spaces, which can lead\nto inconsistencies [62].\n4. Co-articulation: The pronunciation of a consonant like \u201c\u0628\u201d can be affected by the\nsubsequent vowel [63].\n5. Dialectal Variation: Persian has several standard varieties such as Farsi, Dari, and Tajik\n[64].\n6. Cultural Factors: The phenomenon of persianization can shape the way Persian is used\nand interpreted.\n7. Lack of Resources: Often, Persian is classified as a language with limited resources, given\nthe scarcity of accessible data and tools for Natural Language Processing [61].\n8. Free Word Order: Persian allows for the rearrangement of words within a sentence\nwithout significantly altering its meaning [65].\n9. Homophony: Different words have identical pronunciation but different meanings, like\n)\u06af\u0630\u0627\u0631\" /guzar transition') and )\u06af\u0632\u0627\u0631 /guzar/ predicate'( ]66[.\n10. Diacritics: They are frequently left out in writing, leading to ambiguity in word recognition\n[67].\n11. Rapidly Changing Vocabulary: Persian's vocabulary is rapidly evolving due to factors\nsuch as technology, globalization [68].\n12. Lack of standardization: There isn't a single standard for Persian text, which can\ncomplicate the development of language processing models capable of handling a variety\nof dialects and styles [69].\nA significant issue is the treatment of internal word boundaries, often represented by a zero-width\nnon-joiner space or \u201cpseudo-space\". Ignoring these can lead to text processing errors. Pre-\nprocessing steps can help resolve these issues by correcting pseudo and white spaces according to\ninternal word boundaries and addressing tokenization problems.\nThese challenges highlight the need for robust computational models and resources that can handle\nthe intricacies of the Persian language while ensuring accurate language processing."}, {"title": "3. Material and Methods", "content": "Our methodology detects and corrects two categories of mistakes in Persian clinical text: Non-\nword and Real-word errors. The architecture of the proposed system is depicted in Figure 1. The\nsystem design is composed of five distinct modules that communicate via a databus.\nThe INPUT module accepts raw test corpora. The pre-processing component normalizes the\ntext and addresses word boundary issues. The contextual analyzer module assesses the contextual\nsimilarity within desired word sequences.\nFor error detection, we implement a dictionary reference technique to pinpoint non-word errors\nand use contextual similarity matching to detect real-word errors. The error correction module\nrectifies both classes of errors using context information from a fine-tuned contextual embeddings\nmodel, in conjunction with orthographic and edit-distance similarity measures.\nThe corrected corpora or word sequence is then delivered through the OUTPUT module."}, {"title": "3.1 Pre-processing step", "content": "Text pre-processing is a crucial step in numerous NLP applications, which includes the\nsegmentation of sentences, tokenization, normalization, and the removal of stop-words. The\nsegmentation of sentences involves determining the boundaries of a sentence, usually marked by\npunctuation such as full stops, exclamation marks, or question marks. Tokenization is the process\nof decomposing a sentence into a set of terms that capture the sentence's meaning and are utilized\nfor feature extraction. Normalization is the procedure of converting text into its standard forms\nand is particularly important in NLP applications for Persian, as it is for many other languages. A\nkey task in normalizing Persian text is the conversion of pseudo and white spaces into regular\nforms, replacing whitespaces with zero-width non-joiners when necessary.\nFor example )\u0645\u06cc\u0634\u0648\u062f mi f\u00e6v\u00e6d/ 'is becoming') is replaced with )\u2018\u0645\u06cc\u0634\u0648\u062f / mi\u017f\u00e6v\u00e6d / is\nbecoming'). Persian and Arabic have numerous similarities, and certain Persian alphabets are\nfrequently incorrectly written using Arabic versions. It is often advantageous for researchers to\nnormalize these discrepancies by substituting Arabic characters )\u064a \u2018Y' /j/; \u06a9 \u2018k' /k/; \u0647\u2018h' /h/) with\ntheir corresponding Persian forms. For instance)\u0628\u0631\u0627\u064a b\u00e6ray/ 'for') is transformed to )\u2018\u0628\u0631\u0627\u06cc\u2019\n/b\u00e6ray/ 'for'). Normalization also includes removing diacritics from Persian words; e.g., )\u2018\u0630\u0631\u0651\u0647\u2019\n/z\u00e6rre/ \u2018particle) is changed to )\u2018\u0630\u0631\u0647\u2019 /z\u00e6re/ \u2018particle). Additionally, Kashida(s) are removed from\nwords; for instance)\u0628\u0640\u0640\u0640\u0640\u0640\u0640\u0640\u0627\u0646\u062f /band/ band') is transformed to )\u2018\u066c\u0628\u0627\u0646\u062f /band/ \u2018band'(. \nIn order to accomplish the goal of normalization, a dictionary named Dehkhoda, which includes\nthe correct typographic form of all Persian words, is utilized to determine the standard form of\nwords that have multiple shapes [70]."}, {"title": "3.2 Damerau-Levenshtein distance and candidate generation", "content": "Our methodology employs the Damerau-Levenshtein distance metric to generate potential\nrectifications for both non-word and real-word errors. [11]. This measure considers insertion,\ndeletion, substitution, and transposition of characters. For instance, the measure of Damerau-\nLevenshtein distance between \"KC\" and \"CKE\" equals 2. It's found that around 80% of human-\ngenerated spelling errors involve these four error types [71]. Studies indicate that context-sensitive\nerror constitute approximately 25% to 40% of all typographical errors in English documents. [72,\n73].\nOur model utilizes an extensive dictionary to pinpoint misspellings. This dictionary is\nbifurcated into two segments: general and specialized terms. For the general segment, we employ\nthe Vafa spell-checker dictionary, a highly respected spell checker for the Persian language. This\ndictionary encompasses 1,095,959 terms, all of which are general terms, but it excludes specialized\nmedical terminology. In this research, we utilized the texts we trained to formulate a custom\ndictionary. This dictionary integrates specialized terminology found in breast ultrasonography,\nhead and neck ultrasonography, and abdominal and pelvic ultrasonography texts. It was further\nenriched with translations from the Radiological Sciences Dictionary by David J Dowsett to\npinpoint misspellings of specialized terms [74]. This dictionary comprises 10,332 terms, all of\nwhich are specialized terms in the field of breast ultrasound, head and neck ultrasound, and\nabdominal and pelvic ultrasound. However, this specialized dictionary does not encompass general\nterms.\nTo circumvent duplication of specialized terms, we juxtaposed our comprehensive\ndictionary with the Radiological Sciences Dictionary using a custom software developed by the\nresearchers of this study. This ensured that no term was included more than once in the dictionary,\nas some terms might be present in both dictionaries.\nUpon our analysis of the test data, we concluded that an edit distance of up to 2 between\nthe candidate corrections and error would be ideal. With an edit distance set to one, an average of\nthree candidates are generated as potential replacements for a target context word. However, when\nthe edit distance is increased to 2, the average number of generated candidates rises to 15.\nCorrespondingly, the computation time also increases. We ensure that the generated candidates\nare validated against the reference lexicon."}, {"title": "3.3. Contextual embeddings", "content": "Word embeddings, which analyze vast amounts of text data to encapsulate word meanings\ninto low-dimensional vectors [75, 76], retain valuable syntactic and semantic information [77] and\nare advantageous for numerous NLP applications [78]. However, they grapple with the issue of\nmeaning conflation deficiency, which is the inability to differentiate between multiple meanings\nof a word.\nTo tackle this, cutting-edge approaches represent specific word senses, referred to as contextual\nembeddings or sense representation. Context-sensitive word embedding techniques such as ELMo\nconsider the context of the input sequence [64]. There exist two main strategies for pre-training\nlanguage representation model: feature-oriented methods and fine-tuning methods [79]. Fine-\ntuning techniques train a language model utilizing large datasets of unlabeled plain texts. The\nparameters of these models are later fine-tuned using data that is pertinent to the task at hand [79-\n81]. However, pre-training an efficient language model demands substantial data and\ncomputational resources [82-85]. Models that are multilingual have been formulated for languages\nthat share morphological and syntactic structures. However, languages that do not use the Latin\nscript significantly deviate from those that do, thereby requiring an approach that is specific to\neach language [86]. This challenge is also common in the Persian language. Although some\nmultilingual models encompass Persian, their performance may not match that of monolingual\nmodels, which are specifically trained on a language-specific lexicon with more extensive volumes\nof Persian text data. As far as we are aware, ParsBert [87] and SinaBERT [88] are the sole efforts\nto pre-train a Bidirectional Encoder Representation Transformer (BERT) model explicitly for the\nPersian language."}, {"title": "3.3.1 Pre-trained Language Representation Model", "content": "Persian is often recognized as an under-resourced language. Despite the existence of language\nmodels that support Persian, only two, namely ParsBert [87] and SinaBERT [88], have been pre-\ntrained on large Persian corpora. ParsBERT was pre-trained on data from the general domain,\nwhich includes a substantial amount of informal documents such as user reviews and comments,\nmany of which contain misspelled words.\nConversely, SinaBERT was pre-trained on unprocessed text from the overarching medical\nfield. The data for SinaBERT was compiled from a diverse set of sources such as websites that\nprovide health and medical news, websites that disseminate scientific information about health,\nnutrition, lifestyle, and more, journals (encompassing both abstracts and complete papers) and\nconference proceedings, scholarly written materials, medical reference books and dissertations,\nonline forums centered around health, medical and health-related Instagram pages, along with\nmedical channels and groups on Telegram.\nThe data primarily consisted of general medical domain data, a portion of which was\ninformal and contained misspellings. These factors make these pre-trained models unsuitable for\nPersian clinical domain spelling correction tasks. The lack of an efficient language model in this\ndomain poses a considerable hurdle. In the subsequent section, we will explore our Persian Clinical\nCorpus and the procedure of pre-training our language representation model."}, {"title": "3.3.2 Data", "content": "While numerous formal general domain Persian medical texts are freely accessible, they\nmay not be ideal for spelling correction in clinical texts. Conversely, Persian clinical texts are not\nwidely available to the public. Nevertheless, the use of Persian clinical text is essential for pre-\ntraining a language representation model specifically for spelling correction in Persian clinical\ntext. Consequently, we assembled a substantial collection of Persian Clinical texts to train an\neffective model for spelling correction in Persian.\nOur data comprises a total of 78,643 ultrasonography reports, which were obtained from\nthree distinct datasets. These datasets were generously provided by the Department of Imaging's\nHIS at Tehran's Imam Khomeini Hospital. For a detailed breakdown of these datasets, please refer\nto Table 2."}, {"title": "3.3.3 Model Architecture", "content": "The structure of our suggested model is founded on the original BERTBASE setup, which\ncomprises 12 hidden layers, 12 attention heads, 768 hidden sizes, and a total of 110M parameters.\nOur model is designed to handle a maximum token capacity of 512. The architecture of the model\nis depicted in Figure 2. BERT's success is often attributed to its MLM pre-training task, where it\nrandomly masks or replaces tokens before predicting the original tokens [80]. This feature makes\nBERT particularly suitable for a spelling checker, as it interprets the masked and altered tokens as\nmisspellings. In the embedding layer of BERT, each input token, denoted as $T_i$, is indexed to its\ncorresponding embedding representation, $ER_i$. This $ER_i$ is then forwarded to BERT's encoder\nlayers to obtain the subsequent representation, $HR_i$.\n$ER_i$ = BERT - Embedding($T_i$) (1)\n$HR_i$ = BERT \u2013 Encoder($ER_i$) (2)\nIn this context, both $ER_i$ and $HR_i$ belong to the real number space $R^{1*d}$, where $d$ represents the\nhidden dimension. Subsequently, the similarities between $HR_i$ and all token embeddings are\ncalculated to predict the distribution of $Y_i$ over the existing vocabulary.\n$Y_i$ = Softmax($HR_i$, $E^T$) (3)\nwhere $E \u2208 R^{V*d}$ and $Y_i \u2208 R^{1*V}$; here V signifies the size of the vocabulary and $E$ represents the\nBERT embedding layer. The ith row of $E$ aligns with $ER_i$ in accordance with Equation 1. The\nultimate rectification outcome for $T_i$ is the $T_k$ token, whose corresponding $ER_k$ exhibits the\ngreatest similarity to $HR_i$."}, {"title": "3.4.5 Fine-tuning for Spelling Correction Task", "content": "We fine-tuned the pre-trained model specifically for the task of spelling correction in\nPersian clinical text, aiming to achieve optimal performance. For this fine-tuning process, we\nutilized 10% of the reserved sentences from the training corpus, amounting to 170,066 sentences.\nEach input to the model was a single sentence ending with a full stop, as our primary focus was\non training the model for spelling correction. Upon examining the test set, we found that many\nsentences were short, and masking a few tokens would significantly reduce the context.\nConsequently, we excluded sentences with fewer than 20 words from the corpus. In the end, we\nselected 122,162 sentences, each with a minimum length of 20 words. However, since the input\nwas a list of sentences that couldn't be directly fed into the model, we tokenized the text. The\nobjective of the error correction task is to predict target or masked words by gaining context from\nadjacent words. Essentially, the model tries to reconstruct the original sentence from the masked\nsentence received in the input at the output. Therefore, the target labels are the actual input_ids of\nthe tokenizer.\nIn the original BERTBASE model, 15% of the input tokens were masked, with 80% replaced\nwith [mask] tokens, 10% replaced with random tokens, and the remaining 10% left unchanged.\nHowever, in our fine-tuning task, we only replaced 15% of the input tokens with [mask], except\nfor special ones; we did not use [mask] tokens to replace [SEP] and [CLS] tokens. We also avoided\nthe random replacement of tokens to achieve better results. We used TensorFlow [89] for training\nwith Keras [90]. Additionally, we used the Adam optimizer with a learning rate of 1E-4. The batch\nsize was 32 and each model was run for 4 epochs."}, {"title": "3.5\nPERTO Algorithm", "content": "We have designed an algorithm called PERTO, which stands for Persian Orthography\nMatching. This algorithm ranks the most likely candidate words derived from the output of a pre-\ntrained model, based on shape similarity. In this algorithm, every character in the Persian script is\ngiven a distinct code. Characters that share similar forms or glyphs are classified under the same\ncode, enabling words with similar shape characters to be identified, even if there are slight spelling\nvariations. Our pioneering hybrid model classifies characters with the same shapes into identical\ngroups, as depicted in Table 3.\nIn order to identify shape similarity in Persian, a PERTO code is generated for the\nincorrectly spelled word. This code is subsequently matched with the PERTO codes of all potential\nwords generated via edit distance. Our model distinctively merges PERTO with a contextual score\nranking system. PERTO is solely utilized for substitution errors. In cases of insertion or deletion\ntype errors, where the PERTO codes of all potential words do not correspond to the PERTO code\nof the misspelled word, our model depends entirely on contextual scores derived from the pre-\ntrained model. Pseudocode1 outlines the implementation details of the PERTO algorithm.\nTo illustrate the PERTO code generation process, let us consider the word \"\u067e\u0631\u06af\u0627\u0632\" which\ntranslates to \"a stomach full of gas\" in English. The generation of the PERTO code for this word,\nas per the method outlined in Pseudocode1, is as follows:\n1)We begin with the first character on the right side of the word and find its hash code from Table\n3. The code for \"\u067e\" is which we store in an empty string.\n2(Moving one unit to the left, we retrieve the hash code for the character \"\u0631,\" which is 24, and add\nthis digit to the string.\n3)This process continues for each character in the word until no characters are left.\n4(For \"\u06af\u0627\u0632,\" the respective codes are \"9,\" \"0\" and \"4,\" following the same lookup and concatenation\nprocedure.\n5)In the end, we obtain the PERTO code \"14904\" for the given word, which has the same length\nas the original word."}, {"title": "3.6\nError Detection Module", "content": "The error detection module utilizes two separate strategies based on the nature of the error\nbeing identified. For non-word errors, a lexical lookup approach is employed, while real-word\nerrors are addressed through contextual analysis. The initial step in error detection, irrespective of\nthe error type, involves boundary detection and token identification. Upon receiving an input\nsentence S, the model first demarcates the start and end of the sentence with Beginning of Sentence\n(BoS) and End of Sentence (EoS) markers, respectively, markers respectively, and approximates\nthe word count in the sentence:\n< BoS > W\u00a1 Wi+1 Wi+2... Wn < EoS >\nIt's crucial to note that the word count corresponds to the maximum number of iterations the\nmodel will undertake to identify an error in the sentence."}, {"title": "3.6.1 Non-word Error Detection", "content": "Spell checkers predominantly employ the lexical lookup method to detect spelling errors.\nThis technique involves comparing each word in the input sentence with a reference dictionary in\nreal-time, which is usually built using a hash table. Beginning with the BoS marker, the model\nscrutinizes every token in the sentence for its correctness based on its sequence. This process\ncontinues until the EoS marker is reached. However, if a word is identified as misspelled, the error\ndetection cycle halts and the error correction phase commences. Here's an illustration of non-word\nerror detection:"}, {"title": "3.6.2\nReal-word error detection", "content": "In this study, we employ contextual analysis for the detection of real-word errors. Traditional\nstatistical models relied on n-gram language models to examine the frequency of a word's\noccurrence and assess the word's context by considering the frequency of the word appearing with\n\"n\" preceding terms. However, contemporary approaches use neural embeddings to evaluate the\nsemantic fit of words within a given sentence. In our proposed methodology, we utilize the mask\nfeature and leverage contextual scores derived from the fine-tuned bidirectional language model\nto detect and correct word errors. The process of real-word error detection is explained as follows:\n1) The model begins with the BoS marker and attempts to encode each word as a masked\nword, starting with the first word.\n2) A list of potential replacements for the masked word is derived from the output of the pre-\ntrained model.\n3) Based on the candidate generation scenario, replacement candidates are generated within\nedit-distances of 1 and 2 from the masked word.\n4) The list of candidates, along with the original token, is cross-verified against the pre-trained\nmodel's output for the masked token.\n5) If a candidate demonstrates a probability value that surpasses that of the masked word, the\ninitial word is considered erroneous, thus bringing the procedure to a close.\n6) However, if no error is detected, the model shifts one unit to the left, and the same steps\nare reiterated for all words within the sentence until the EoS marker is encountered.\nTherefore, the moment an error is identified, the correction process is initiated immediately;\nsubsequently, the model advances to the next sentence. Pseudocode2 offers an in-depth exploration\nof the Real-word error detection process."}, {"title": "3.7\nError Correction Module", "content": "The error correction phase is initiated when an error is identified in the input. In this stage,\nwe devise a ranking algorithm that primarily relies on the contextual scores obtained from the fine-\ntuned pre-trained model and the corresponding PERTO codes between potential candidates and\nthe errors."}, {"title": "3.7.1\nNon-word Error Correction Process", "content": "In the non-word error correction process, the following steps are undertaken:\n1) The model initially employs the Damerau-Levenshtein edit distance measure to generate\na set of replacement candidates within 1 or 2 edits.\n2) The misspelled word is subsequently encoded as a \u201cmask\" and input into the fine-tuned\nmodel.\n3) The model extracts all probable words from the output and matches them against the\ncandidate list.\n4) The model then retains a certain number of candidates with the highest contextual scores.\nBased on our observations, the optimal number is 10.\n5) The method proceeds to compare the PERTO similarity between the erroneous word and\nthe remaining replacement candidates. If the error and candidate share the same code,\nthat candidate is considered the most suitable word. However, if two or more probable\ncandidates carry the same PERTO code as the erroneous word, then the candidate with\nthe highest contextual score is selected as the replacement for the error.\nPseudocode3 delivers a comprehensive exploration of the Non-word error correction mechanism."}, {"title": "3.7.2\nReal-word Error Correction Process", "content": "In the scenario of real-word error correction, the process is as follows:\n1) The contextual scores of potential candidates are retrieved from the fine-tuned model.\n2) The model retains a certain number of candidates with the highest contextual score.\nBased on our observations, the optimal number is 10.\n3) The method then compares the PERTO similarity between the erroneous word and the\nreplacement candidates. If the error and the candidate share the same code, that candidate\nis deemed the most suitable word.\n4) However, if two or more probable candidates carry the same PERTO code as the\nerroneous word, then the candidate with the highest contextual score is selected as the\nreplacement for the error.\nPseudocode4 delivers a comprehensive exploration of the Non-word error correction mechanism."}, {"title": "4. Evaluation and Results", "content": "In this section, we first conduct an analysis of the test data. Following this, we evaluate our\nmethod's performance and compare it with various baseline models in the task of spelling\ncorrection. This comparison will offer valuable insights into the efficacy and precision of our\napproach in identifying and rectifying spelling errors."}, {"title": "4.1 Test Dataset", "content": "Our test datasets consist of 188,963 reserved sentences derived from the Persian clinical\ncorpus. Upon scrutinizing the errors present in the test dataset, we found that 1.20% of sentences\nexhibited instances of non-word errors, which equates to 120 errors in every 10,000 sentences. In\naddition, 0.29% of sentences contained a real-word error, corresponding to 29 errors in every\n10,000 sentences. We examined all the erroneous words to categorize them into one of the\npredefined classes of errors, such as substitution, transposition, insertion, and deletion. The\nfrequency of these errors, based on the error type, is illustrated in Table 5. When addressing both\nreal-word and non-word errors, substitution errors are more prevalent than other types of errors.\nFurthermore, insertion errors are quite common when dealing with both classes of error, while\ndeletion and transposition errors are the least common.\nWe also analyzed the test dataset for the number of edit distances required for spell correction,\nthe results of which are presented in Table 6. In dealing with both real-word and non-word errors,\n86.1% of misspellings required an edit distance of 1 to correct the incorrect word. 13.7% of errors\nwere rectified with an edit distance of 2, and a mere 2.1% of errors fell within an edit-distance of\n3 or more. Due to the combinatorial explosion when generating and examining candidates within\ndistance 3, these classes of error were excluded from the dataset.\nUpon conducting a more thorough analysis of the data, we found that 0.8% of sentences\ncontained more than one error. As our method is designed to handle only one-error-per-sentence,\nwe removed these sentences from the test dataset."}, {"title": "4.2 Evaluation metrics", "content": "The principal metrics for evaluating the effectiveness of models on tasks related to non-\nword and real-word error identification and rectification are precision (P), recall (R), and the F-\nmeasure (F1-Score). Precision (P) quantifies the model's accuracy, whereas recall evaluates its\ncomprehensiveness or sensitivity. The F1-Score, a weighted harmonic average of these two\nmetrics, can be computed by integrating them. In F1, both precision and recall are given equal\nweight. Equation 4 describes the F1-Score evaluation measure.\nF1 - Score = 2 * $\\frac{P*R}{P+R}$"}, {"title": "4.3 Baseline Models", "content": "In our research, we implemented two baseline models for non-word correction in Persian\nclinical text to ensure a comprehensive comparison. These models include the four-gram model\nintroduced by [57], and a Persian Continuous Bag-of-Words (CBOW) model [91]. Both models\nwere developed using Python and trained on the same dataset as the pre-trained model. Our aim is\nto understand the strengths and weaknesses of these models, and leverage this understanding to\nenhance error correction in Persian language processing. Unfortunately, for real-word error\ncorrection in the Persian medical domain, no prior work has been introduced. Therefore, a\nmeaningful comparison is not achievable at this time. This highlights the novelty and importance\nof our research in this specific area."}, {"title": "4.3.1 Yazdani, et al.", "content": "The statistical methodology, pioneered by Yazdani and colleagues, stands out as a\npromising approach for rectifying non-word errors. It is meticulously crafted to address\ntypographical inaccuracies prevalent in Persian healthcare text, thereby enhancing the quality and\nreliability of the information [57"}]}