{"title": "Logic Synthesis Optimization with Predictive Self-Supervision via Causal Transformers", "authors": ["Raika Karimi", "Faezeh Faez", "Yingxue Zhang", "Xing Li", "Lei Chen", "Mingxuan Yuan", "Mahdi Biparva"], "abstract": "Contemporary hardware design benefits from the abstraction provided by high-level logic gates, streamlining the implementation of logic circuits. Logic Synthesis Optimization (LSO) operates at one level of abstraction within the Electronic Design Automation (EDA) workflow, targeting improvements in logic circuits with respect to performance metrics such as size and speed in the final layout. Recent trends in the field show a growing interest in leveraging Machine Learning (ML) for EDA, notably through ML-guided logic synthesis utilizing policy-based Reinforcement Learning (RL) methods. Despite these advancements, existing models face challenges such as overfitting and limited generalization, attributed to constrained public circuits and the expressiveness limitations of graph encoders. To address these hurdles, and tackle data scarcity issues, we introduce LSOformer, a novel approach harnessing Autoregressive transformer models and predictive SSL to predict the trajectory of Quality of Results (QoR). LSOformer integrates cross-attention modules to merge insights from circuit graphs and optimization sequences, thereby enhancing prediction accuracy for QoR metrics. Experimental studies validate the effectiveness of LSOformer, showcasing its superior performance over baseline architectures in QoR prediction tasks, where it achieves improvements of 5.74%, 4.35%, and 17.06% on the EPFL, OABCD, and proprietary circuits datasets, respectively, in inductive setup.", "sections": [{"title": "1\nINTRODUCTION", "content": "In contemporary hardware design, the creation of hardware devices is facilitated by the abstraction provided by high-level logic gates, liberating designers from the intricacies of Integrated Circuit (IC) implementation. During the IC fabrication process, the conceptual designs are translated into tangible layouts with the aid of Electronic Design Automation (EDA) tools. In essence, EDA tools afford designers the opportunity to focus exclusively on the functional aspects of their designs at a high-level by employing hardware description languages (HDL) like Verilog.\nlogic synthesis optimization (LSO) in which a logic circuit is transformed into an functionally equivalent and optimized representation is a part of EDA workflow [26]. In LSO, a sequence of optimization transformations supported by academia and industry [4] and named recipe are applied to logic-level circuit designs to optimize performance criteria such as size and speed, named Quality of Results (QoR), in the final IC.\nDue to high latency and long running time of EDA tools, there is an huge surge of interest to use Machine Learning (ML) for EDA [11, 13, 16, 28, 39], specifically ML-guided logic synthesis [16], [38]. In addressing this, logic synthesis designers frequently employ policy-based Reinforcement Learning (RL) methods to identify optimal sequences of optimizations [14]. Given the time-intensive nature of these searches, leveraging pre-trained policy functions can expedite RL processes [8]. This has led researchers to explore new challenges in developing ML models that exhibit robust generalization capabilities for predicting the final QoR based on gate-level circuit representations and optimization sequences [10].\nMost models in this domain input logic-level circuit designs in And-Inverter Graph (AIG) format [21], capitalizing on the inductive bias inherent in the Directed Acyclic Graph (DAG) structure [22] whose nodes are partially ordered. Significant research is dedicated to inject the inductive bias of DAGs into message-passing graph encoders [29] or Graph Transformers [20] to enhance expressiveness. One contribution of our paper builds on top of these concepts, effectively generating graph-level representations that are well-suited for AIGs.\nThe current LSO models often experience overfitting due to a limited number of publicly available circuits used during training, resulting in a lack of generalization, especially when tested on unseen circuits that differ in size and characteristics from the training circuits. Additionally, these models struggle with imbalanced input samples across different modalities; typically, there are more recipe available than AIGs. This disparity can lead to prominent overfitting, particularly due to the low expressiveness of graph encoders, which becomes exacerbated when the model excessively adapts to the encoder part handling recipe.\nRecently, self-supervised learning has addressed both the scarcity of data, offering an alternative to costly data augmentation methods, and issues of expressiveness in various downstream tasks related to LSO [7, 32]. This approach involves pre-training the circuit encoder component in advance, followed by fine-tuning it on specific downstream tasks. Inspired by predictive SSL [19], another contribution of our work is the definition of an auxiliary task that involves predicting intermediate QoRs. This joint training mechanism provides a stronger supervisory signal during training, enhancing the learning process.\nAnother drawback of existing method is that the encoder used for encoding recipe lacks information from the input graphs, leading to an information bottleneck. This bottleneck occurs particularly when graph embeddings and recipe embeddings are merged using standard concatenation techniques. This limitation motivated us to develop a decoder-only transformer model for training, employing a joint loss function. As a result, the model contextualizes the embeddings of heuristics using AIG embeddings through a Cross-Attention module, facilitating more effective integration of information.\nIn summary, we propose the following innovations to address aforementioned drawbacks:\n\u2022 Level-wise Graph Pooling: An efficient graph pooling mechanism tailored for DAG structures that transforms AIG into a sequence of embeddings.\n\u2022 QoR Trajectory Prediction: An auxiliary predictive SSL task designed to predict intermediate QoR for joint training.\n\u2022 Causal Transformer: A decoder-only transformer model that causally predicts QoR based on the recipes and AIGs.\n\u2022 Contextualized Fusion: An efficient mechanism to fuse embeddings of AIGs and recipes using a cross-attention module. This approach contextualizes the embeddings of recipes with AIGs, enabling the model to learn which parts of the graph each heuristic attends to.\nOur SOTA model has been tested across multiple datasets, showcasing superior performance in terms of Mean Absolute Percentage Error (MAPE) when compared to conventional baseline architectures for QoR prediction. Furthermore, our ablation studies justifies that the novel architecture designed for downstream task aligns effectively with predictive SSL tasks. This synergy enhances overall performance beyond that of individual models, also suggesting that the challenges associated with limited datasets have been effectively mitigated through the SSL approach."}, {"title": "2 RELATED WORK", "content": "Logic synthesis necessitates thorough adjustment of the synthesis optimization procedure, with the QoR contingent upon the optimization sequence applied. Effectively exploring the design space presents a challenge due to the exponential array of potential optimization permutations [12]. Consequently, fast and efficient automation of the optimization procedure becomes imperative [17, 27]. [8, 9, 14, 15, 23, 31] introduce innovative methodologies based on Qlearning-based, Bayesian Optimization, and policy-based RL, which autonomously traverse the optimization space, obviating the need for human intervention.\nSeveral policy-based RL methodologies, such as those discussed in [8, 36, 38], leverage a pre-trained function that correlates initial circuits and recipe with the ultimate QoR. This architecture is split into two primary branches: one for encoding AIGs and another for recipes, along with a fusion branch that maps the embeddings onto the predicted QoR. Similar efforts to forecast QoRs based on initial graphs and recipe are documented in [10, 35\u201338, 40], where various graph and sequence encoders are explored. Discussions abound concerning the most effective AIG encoders and methods for integrating sequence embeddings with graph embeddings. As a result, improvements in encoder and fusion modules are crucial for enhancing prediction performance. For example, [10] utilizes a GCN to encode graphs and a CNN for recipes, employing both mean and max pooling for graph combination. Meanwhile, [37] employs GraphSage for graph encoding and a transformer for recipe encoding. Similar to one of recent baselines, LOSTIN [35], [38] integrates a Graph Isomorphism Network (GINE) for graph learning with an LSTM for recipe encoding. Additionally, [36] explores various graph encoders, such as PNA and pooling techniques, alongside virtual supernodes in conjunction with hierarchical learning and RL methods. In all aforementioned methods, recipe embeddings and Graph embeddings are fused using concatenation. The MLP decoder has been used to generate the predicted QoR after fusion. However, none of these models utilize an attention mechanism to fuse the two branches, which would contextualize the embeddings for more accurate final predictions. There are several attempts toward fast and effiecient LSO models\nSSL for EDA: Various forms of SSL, including predictive and contrastive approaches, have demonstrated substantial enhancements in tasks within the graph domain [34]. Different SSL protocols can be devised for pre-training or jointly training graph encoders through graph-level pretext tasks [19]. Additionally, SSL provides an alternative to costly data augmentation for AIGs [18], offering a"}, {"title": "3\nMETHODOLOGY", "content": "In this section, we formalize and describe the Logic Synthesis Optimization (LSO) problem. Next, we present the LSOformer pipeline, specifically designed for LSO, which features a novel architecture tailored for the QoR prediction task. Then, we introduce a Self-Supervised Learning (SSL) auxiliary task aiming at predicting the trajectory of the QoRs given recipe and And-Inverter Graphs (AIG) graphs.", "subsections": [{"title": "3.1 Problem Definition", "content": "The logic-level designs stored in BENCH format are first converted into AIGs, a format initially proposed in [6] for representing logic circuits. An AIG is a type of Directed Acyclic Graph (DAG) [21], characterized by nodes representing 2-input AND functions and edges signifying either NOT or buffer functions [3]. This structure simplifies the representation and manipulation of boolean functions, facilitating various logic synthesis and optimization tasks.\nConsequently, the input AIGs are transformed into attributed directed acyclic graphs (DAGs) $G = (V, &, X^\\mathcal{V})$, comprising N nodes and E = $|&|$ directed edges. Node features $X^\\mathcal{V}$ are categorized into two types: $X^{type} \\in \\{0, 1, 2\\}$ and $X^{inverted} \\in \\{0, 1, 2\\}$. These features represent the classification of nodes (input, output, or intermediate) and the count of inverted predecessors for each gate, respectively. The set of recipe, denoted as $R = \\{r_1, r_2, ..., r_p\\}$, comprises R recipes, each containing M sequentially ordered heuristics, selected from a set $T = \\{t_1, t_2, ..., t_c\\}$, which consists of C types of heuristics. Each element in T is an optimizer."}, {"title": "3.2 Task Definition", "content": "Technology Mapping: The process involves transforming a network of technology-independent logic gates into a network consisting of logic cells tailored to the layout of a target integrated circuit (IC), such as a Field-Programmable Gate Array (FPGA). The metrics such as delay, area, space can be measured after this step.\nGround Truth Generation: In the EDA workflow, we can optimize logic-level circuites modeled by AIG graphs G given the recipe through the time consuming tools like ABC. After sequentially applying the $i^{th}$ heuristic and optimizing the logic-level representation, technology mapping is then applied to map the optimized version, with the ground truth QoR after each step shown by $y^i$. The final QoR after $M^{th}$ heuristics, named y, is the ground truth of the model that our proposed model is expected to predict given the input AIGs and recipe during inference mode."}, {"title": "3.2.1 Self-Supervised Learning Auxiliary task", "content": "As an auxillary task helping the model during training, we train the model to predict the trajectory of QoR evolution. To achieve this, the model step by step predicts all M intermediate QoRs in a causal manner. For predicting the $i^{th}$ QoR, the model takes as input all heuristics before the $i^{th}$ step, $(r_1, r_2, ..., r_i)$. This predictive SSL task by it self is aligned with architecture of our transfomrer decoder to help model benefits from extra information within intermediate steps."}, {"title": "3.2.2 Final QoR prediction", "content": "The QoR prediction task aims to find the learnable function $f_\\theta$ that maps a pair of recipe and AIG graph, (G, ri) to a numerical value $\\hat{y}$ which is a prediction of final ground truth QoR such as delay and area. More specifically, the task is as follows:\n$\\hat{y} = f_\\theta (G, r_i)$  (1)\nThe final loss which is Mean Squared Error is defined as follows:\n$loss = \\sum_{k=1}^{M} MSE(\\hat{y}^k, y^k)$  (2)"}]}, {"title": "3.3 Architecture", "content": "The architecture of our system consists of three main components: the graph encoder, the recipe encoder, and the fusion mechanism coupled with the decoder. The novelty of our work primarily lies in the enhancements to the decoding process as well as modifications to the other components. These innovations are detailed below, emphasizing the unique aspects of our approach within each block.", "subsections": [{"title": "3.3.1 Graph Encoder", "content": "In the AIG segment, we employ a graph encoder & based on the following formulation:\n$H = &(G)$  (3)\nHere, $H = \\{h_1, h_2, ..., h_N\\}$ represents the set of node embeddings and$h_i \\in \\mathbb{R}^{d_h}$ is ith node embedding. Similar to the approach used in OpenABC [10], we utilize a Graph Convolutional Neural Network (GCN) with the same node embedding approach to encode the AIGs."}, {"title": "3.3.2 Level-wise Node Pooling", "content": "Although the GCNs can encode graphs properly, they are unable to particularly incorporate the inductive bias of DAGs. To benefit from this bias to improve the graph representation learner, we propose an unique pooling mechanism called level-wise pooling.\nSimilar to the work proposed in [20] the depth of a node v is calculated through the function $depth(v)$ because of the partial order intrinsic to the DAG. The set of node embeddings can be partitioned based on the depth of the each node as follows:\n$H = \\{H^0, H^1, ..., H^D\\}$  (4)\nWhere $H^l$ represents the set of embeddings for nodes located at $l^{th}$ level of AIG. Finally, the AIG graph is represented as a sequence for the decoder layer described in the next section. The sequence is derived according to the combination of mean and max poolings as follows:\n$\\mathcal{H} = (h_0, h_1, ..., h_D), \\qquad h_l = POOL_{level}(H^l)$  (5)\nwhere $\\mathcal{H}$ is the sequence of representation of DAG and $h_l \\in \\mathbb{R}^{2 \\times d_h}$ is the embedding of $l^{th}$ level of AIG. The $POOL_{level}$ is the concatenation of mean and max poolings."}, {"title": "3.3.3 Heuristic Tokenization and Embedding", "content": "Each recipe, denoted as $r_i = (u_1, u_2, ..., u_m)$, where each $u_j \\in T$ represents the j-th heuristic within the recipe, is tokenized using a one-hot vector of length C. A lookup table is utilized to generate learned embeddings to convert the input tokens to vectors $\\bar{u}_j \\in \\mathbb{R}^{2 \\times d_h}$ within the sequence of embeddings $\\bar{r}_i = (\\bar{u}_1, \\bar{u}_2, ..., \\bar{u}_M)$."}, {"title": "3.3.4 Transformer Decoder", "content": "Once the recipes are embedded and the AIG is converted to a sequence, inspired by Machine Translation models [30], we propose a sequence to sequence alignment module using only transformer decoder module to fuse the AIG sequence with heuristics' embeddings. In other words, this transformer module maps AIG sequence and heuristics' embeddings to the trajectory of QoRs in causal manner. More specifically:\n$\\mathcal{Y} = Transformer(\\mathcal{H},\\bar{r}_i)$  (6)\n$\\hat{\\mathcal{Y}} = (\\hat{y}^1, ..., \\hat{y}^M)$  (7)\nwhere $\\hat{\\mathcal{Y}}$ consists of the QoRs of the trajectory. Our transformer decoder containing 6 main components is designed and formulated as follows:\nPositional Encoding: Sine/Cosine positional encoding (PE) is added to the sequence of heuristics embeddings element-wise as follows:\n$PE(m,2k) = sin(\\frac{m}{10000^{k/d_h}})$  (8)\n$PE(m,2k+1) = cos(\\frac{m}{10000^{k/d_h}})$  (9)\n$Z_i = \\bar{r}_i + PE$  (10)\nWhere $z_i$ is the sequence of positionally encoded embeddings of Optimizers.\nMasked Multi-Head Self-Attention: If $Q = z_iW_q \\in \\mathbb{R}^{M \\times 2d_h}$, $K = z_iW_k \\in \\mathbb{R}^{M \\times 2d_h}$, and $V = z_iW_v \\in \\mathbb{R}^{M \\times 2d_h}$ are the query, key, and value matrices, the contextualized heuristics' embedding ($z_i$) is derived as follows:\n$\\hat{z}_i = Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_h}} + M)V$  (11)\nThe mask M is typically an upper triangular matrix with zeros on and below the diagonal and -\u221e above the diagonal for each sequence in the batch. This structure effectively impose causality and ensures that each position in the sequence can only attend to itself and previous positions, not to any future positions.\nCross-Attention: This module computes the attention weights between the element of AIG sequence and contextualized heuristics' embeddings. Finally, a Feed-Forward layer (FFN) with Relu function is applied element-wise to the sequence.\n$\\hat{h} = FFN(MultiHeadAttention(\\hat{z}_i, \\mathcal{H}, \\mathcal{\\hat{H}}))$  (12)\nWhere $\\hat{h} = (\\hat{u}_1, \\hat{u}_2, ..., \\hat{u}_M)$ is the output sequence of embeddings for input AIG and $i^{th}$ recipe; $\\hat{u}_j \\in \\mathbb{R}^{2 \\times d_h}$ represents generated embedding correspoding to $i^{th}$ QoR. Add & Norm: Each sub-layer (self-attention and feed-forward network) includes a residual connection followed by layer normalization:\n$LayerNorm(x + Sublayer(x))$  (13)\nMLP Regressor: Once the embeddings for each QoR has been generated sequentially, we use a MLP module to map the embeddings to final QoR as follows:\n$\\hat{y} = MLP(\\mathcal{H})$  (14)"}]}, {"title": "4\nEXPERIMENTAL EVALUATION", "content": "In this section, we have structured experiments to robustly validate the three main contributions outlined in this work. Following the experimental design, we assess the performance of the proposed architecture across various setups and scenarios, providing a comprehensive evaluation of its effectiveness and adaptability in handling different computational challenges.", "subsections": [{"title": "4.1 tools", "content": "Commercial EDA tools offer standardized operating systems [5], whereas the academic, open-source tool ABC [5] provides specialized heuristic commands for circuit optimization. We employ OpenROAD v1.0 EDA [1] for logic synthesis, with Yosys [33], version 0.9, serving as the frontend engine. Yosys works in collaboration with ABC to carry out post-technology mapping and generate a minimized logic circuit specifically optimized for the final QoR. Post-technology mapping, the area and delay of these designs are evaluated using the NanGate 45nm technology library and the 5K_heavy wireload model. Furthermore, we utilize PyTorch v1.13 and PyTorch Geometric v2.2.0 to generate AIGs."}, {"title": "4.2 Datasets", "content": "Three datasets have been employed for the experiments, each comprising a collection of circuit designs along with a set of recipe. Since each dataset is utilized in different studies, we have opted not to combine datasets in order to simplify comparisons with counterpart baselines. Additionally, we report performance metrics individually for each dataset. A consistent set of 1500 unique recipes borrowed from [10] was applied across all datasets. Each recipe was constructed utilizing seven primary heuristics and their associated flags from the ABC toolkit. These heuristics include Balance, Rewrite (rw, rw -z), Refactor (rf, rf -z), and Re-substitution (rs, rs -z).\nEPFL: Introduced in 2015, the EPFL Combinational Benchmark Suite comprises combinational circuits specifically designed to test the capabilities of modern logic optimization tools [2]. This benchmark suite has been complemented by an open-source leaderboard, which aims to establish a new comparative standard within the"}, {"title": "4.3 Experimental Protocol", "content": "The efficacy of our model is assessed under both transductive and inductive settings to demonstrate its superiority over competing architectures. The dataset is split into training and validation sets with ratios of 0.66 and 0.33, respectively, for both setups. Additionally, zero-mean normalization has been applied to normalize the final QORs. Additionally, intermediate QoRs are normalized using the mean and standard deviation derived from the final QoRs. In the ablation study, we focus exclusively on the inductive setting, which presents the most challenging scenario for the LSO problem. In these experiments, given the challenges associated with predicting timing, delay has been selected as the target variable for QoR prediction.\nInductive Setup (Circuit-wise Inductive): In this setup, the circuits used during the training phase are different from those employed in testing. It is noteworthy that all recipes from the sample set are observed and applied to the circuits introduced to the model during training."}, {"title": "4.3.1 Implementation Details and Parameter Settings", "content": "In accordance with [10], for delay prediction, the AIG encoder uses two layers of GCN with a hidden embedding size of 32, while for area prediction, it employs 10 layers of GIN with batch normalization. Additionally, mean and max pooling were applied combined to generate embeddings for each level of AIG; hence, the dimension of the transformer decoder is set to 64. The number of levels is determined by the maximum depth of existing circuits for each dataset. Circuits with a lower depth are zero-padded to align their length. Early stoping has been utilized to report the best validation result in Table 2."}, {"title": "4.4 Results", "content": ""}, {"title": "4.4.1 Comparison Study Result", "content": "In Table 2, we evaluate the MAPE performance of various QOR prediction models against the baseline in multi trials across two setups for predicting delay and area. The baseline model is the architecture proposed in the OABCD paper [10]. In the IP-inductive setup, the LSOformer surpasses all existing models and outperforms the baseline by 5.74%, 4.35%, and 17.06% for the EPFL, OABCD, and PD datasets, respectively, in terms of delay prediction. For area prediction, LSOformer reduces the MAPE across all datasets compared to the baseline and nearly all models. However, on the OABCD dataset, the GNN-H model achieves the highest performance, demonstrating a 14% improvement over the baseline. This pattern holds in the recipe-inductive setup for both delay and area predictions across the three datasets, where LSOformer exceeds the baseline by 11.40%, 2.38%, and 12.82% for the EPFL, OABCD, and PD datasets in delay prediction, respectively."}, {"title": "4.4.2 Ablation Study", "content": "We assess the impact of the SSL auxilary loss integratd to the training pipeline. Similar to the benchmark SSL works [19], for the random setup, different parts of architecture are freezed to generate the lower bound of performance for SSL task. The difference between the results of random encoders and supervised models is considered the gap that the frozen model can potentially bridge in the best-case scenarios. Freezed LSOformer in Table 4, benefiting from QoR trajectory prediction, has performance near that of the supervised LSOformer and shows better results compared to the baseline, although it has not trained on final QoR. Table 5 details an ablation study on the integration of transformer architecture and SSL auxiliary tasks within the LSOformer model. It examines the impact of combining QoR trajectory predictions with various architectures. The results indicate that integrating our"}, {"title": "4.4.3 In-depth Analysis", "content": "We assess the performance of our model on a test set in comparison to established baselines. In this configuration, the model is trained using PD datasets and primarily evaluated using OABCD and EPFL datasets. The analysis involves a randomized execution across a predetermined set of IPs, with results illustrated in Figure 2. Each column, representing an individual IP, displays the MAPE in logarithmic scale for area and delay for each model, as shown in Figure 2a and Figure2b, respectively. The IP names are arranged in ascending order from left to right based on the number of nodes. The final column presents the average MAPE across all IPs within the EPFL and OABCD datasets. Overall, LSOformer surpasses all competing models in this setup, affirming its dominance in the LSO task. Additionally, LSOformer demonstrates a notable improvement in area performance, approximately 6%, across all IPs. For delay, although the improvement margin is narrower, there is a consistent enhancement observed across all selected IPs. The improvement gain of LSOformer, calculated as the difference from the baseline divided by the baseline performance, is displayed above each bar. For all sampled IPs, both LSOformer and the baseline outperform other methods, except for the i2c IP, where PNA and Transformer demonstrate exceptional performance in predicting area."}]}, {"title": "5 CONCLUSION", "content": "This paper introduces an innovative solution to the Quality of Results (QoR) prediction for Logic Synthesis Optimization (LSO) problem. A novel architecture is enhanced and integrated with a Self-Supervised Auxiliary task, designed to forecast the intermediate metrics of designs. These metrics are equivalent to those generated following post-technology mapping at each optimization phase. Additionally, we introduce a distinctive pooling mechanism for encoding And-Inverter Graphs (AIGs), which is combined with heuristic inputs using a transformer decoder architecture to predict QoRs at each step in a causal manner. The efficacy of this architecture is validated against conventional models across three primary datasets. Additionally, we demonstrate the robust alignment of the proposed architecture with the Self-Supervised Learning (SSL) auxiliary task specifically defined for this problem."}]}