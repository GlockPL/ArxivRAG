{"title": "SFA-UNet: More Attention to Multi-Scale Contrast and Contextual Information in Infrared Small Object Segmentation", "authors": ["Imad Ali Shah", "Fahad Mumtaz Malik", "Muhammad Waqas Ashraf"], "abstract": "Computer vision researchers have extensively worked on fundamental infrared visual recognition for the past few decades. Among various approaches, deep learning has emerged as the most promising candidate. However, Infrared Small Object Segmentation (ISOS) remains a major focus due to several challenges including: 1) the lack of effective utilization of local contrast and global contextual information; 2) the potential loss of small objects in deep models; and 3) the struggling to capture fine-grained details and ignore noise. To address these challenges, we propose a modified U-Net architecture, named SFA-UNet, by combining Scharr Convolution (SC) and Fast Fourier Convolution (FFC) in addition to vertical and horizontal Attention gates (AG) into U-Net. SFA-UNet utilizes double convolution layers with the addition of SC and FFC in its encoder and decoder layers. SC helps to learn the foreground-to-background contrast information whereas FFC provide multi-scale contextual information while mitigating the small objects vanishing problem. Additionally, the introduction of vertical AGs in encoder layers enhances the model's focus on the targeted object by ignoring irrelevant regions. We evaluated the proposed approach on publicly available, SIRST and IRSTD datasets, and achieved superior performance by an average 0.75\u00b10.25% of all combined metrics in multiple runs as compared to the existing state-of-the-art methods. The code can be accessed at https://github.com/imadalishah/SFA UNet", "sections": [{"title": "I. INTRODUCTION", "content": "Infrared small object segmentation (ISOS) plays an essential role in a wide range of computer vision applications, that includes early warning systems, night navigation, maritime surveillance, and UAV search and tracking. The importance of ISOS stems from its all-weather working capabilities, long-range detection, and concealment properties. Despite decades of research, ISOS remains a challenging task due to the low contrast, and insufficient information regarding the shape and texture of objects. Additionally, the potential loss of information during high-level semantic feature processing is another issue in ISOS.\nExisting approaches to ISOS can be broadly categorized into 1) traditional methods focusing on image processing-based object detection that require prior knowledge about the object, and 2) Deep Learning Architectures (DLA) based methods such as Convolutional Neural Networks and Vision Transformers [1]. Despite the significant success of DLAs in experimental scenarios as compared to traditional methods; they are sensitive to the selection of hyper-parameters, lack"}, {"title": "II. RELATED WORK", "content": "A. Traditional Models\nTraditional methods such as Max-mean-Max-medium [11] and morphological operators such as Top-Hat [12] employed filters to extract the target object from the background. Approaches like LCM [13] with variants ILCM [14], TLLCM [15], and MPCM [16] focused on designing salient measures to segment small objects. The IPI model [17] and variants utilized low-rank decomposition to solve the issue by interpreting input as a superposition of low-rank background and sparse target. Even though the proposed models achieved early promising results in the field of ISOS, these methods suffered from low performance in complex scenarios due to dependence upon the prior knowledge of the segmented target object.\nB. Deep Learning Architectures (DLAs)\nIn contrast to traditional methods, DLAs have become increasingly dominant in object detection, thanks to their experimentally proven robustness and generalization capabilities since the success of CNN by AlexNet [18]. Multi-scale feature learning has been a popular approach to address ISOS challenges. Existing object detection approaches, such as Faster R-CNN [19], SSD [20], RetinaNet [21], and U-Net [22], incorporated multi-scale feature learning to enhance their detection performance. Feature Pyramid Networks (FPN) [23] combined low-and-high resolution with semantically strong and weak features respectively to improve upon ISOS performance. Wang et al [24] balanced the miss detection and false alarm, named MDvsFA, by the effective utilization of conditional GAN with two generators and one discriminator. Dei Y et al introduced Asymmetric Contextual Modulation (ACM) [9] model to enhance the overall network performance and also presented the first public ISOS based dataset, named SIRST, built from real scenes. Liu et al [25] achieved promising results with their introduced multi-head self-attention for ISOS tasks. Recent works have further advanced the ISOS field such as AGPCNet [26] which incorporated attention-guided context blocks and context pyramid modules, and ISNet [10] model with an additional introduction of ISOS-based dataset, named IRSTD, which took object shapes into account. However, the inherent problems of DLAs are still faced due to potential loss of information in deep models, and limitations in capturing both multi-scale contrast and contextual information, which are crucial for robust and accurate detection.\nIII. MAKING ISOS SALIENT WITH DLA-BASED CONVENTIONAL TECHNIQUES\nA. Contrast Information \u2013 Central Difference Operators\nTraditional convolution operators can be sub-optimal for certain tasks, as they treat all input pixels as valid. As a result,"}, {"title": "B. Global Information Extraction \u2013 Expanding Receptive Fields", "content": "The ability of a network to capture multi-scale contextual information is crucial for effective ISOS. While local context, in general, is easy to be extracted using convolution; the degree of global information is usually determined by the network's receptive fields. Strategies for expanding receptive fields to extract global information include stacking convolutions, down-sampling layers, and variants of dilated convolutions such as dilation Atrous Pyramid Pooling (ASPP), and hybrid dilated convolution [29][30] and atrous convolutions [31]. FFC performs convolution operations in the frequency domain and can extract image-level information. Approaches like LAMA [32] and FFC-based monocular depth estimation and semantic segmentation [33] have shown success in different applications.\nC. Capture Fine-Grain Details - Focused Object Detection\nAttention mechanisms [5] helped in capturing global information by calculating the correlation between individual pixels. Due to their ability to selectively focus on relevant features and suppress irrelevant information, they gained popularity in several computer vision applications including ISOS. Several works incorporated attention mechanisms into DLAs, such as the CBAM [34] and the Squeeze-and-Excitation (SE) block [35]. Attention-Guided Pyramid Feature Fusion [36] integrated attention mechanisms into FPN to adaptively fuse features at different scales. RefineDet [37] incorporated attention mechanisms into the single-shot detection (SSD) framework. MI\u00b2T-UNet [38] combined the output of each encoder block to its next encoder block output through AGs. These attention-based methods have shown promising results in enhancing feature representations and improving detection performance."}, {"title": "IV. METHODOLOGY", "content": "A. Overview of SFA-UNet\nSFA-UNet is based on original U-Net with AG architecture with addition of SC and FFC layers utilized in encoder-decoder block, and additional vertical AGs, as shown in Figure 1. Similar to AGs within the encoder-decoder pairs of a U-Net, vertical AGs are incorporated for encoder-encoder layers. SFA-UNet has three encoder-decoder layers to read the input image with dimensions (256, 256, 1) and the depth of different blocks remained; input image (1), encoder (32, 64, 128), middle (256), decoder (128, 64, 32), and output (1) respectively. Each block had double convolution layers (DCL) and employed additional layers of SC-FFC concatenation in between the first and second convolutions layers. Each DCL block comprised of 3 parts; 1) first Convolution (Conv), Batch Normalization (BN) and Rectifier Linear Unit (ReLU) activation, then 2) SC-FFC block, and 3) second Conv-Bn-Relu (or CBR) layers. Encoder DCL ended with max pooling"}, {"title": "B. Scharr-fast Fourier Convolutions (SC-FFC) Block", "content": "SC is a gradient-based technique for edge detection in images. It employs two distinct kernels, Gx and Gy, to find edges in horizontal and vertical directions. Scharr is more potent than Prewitt and Sobel (modified Prewitt with Gaussian) operators, in terms of detecting edges and enhances image contrast information. FFC transforms images into the frequency domain, enabling faster convolution and efficient for extracting global contextual information, thus remains crucial for tasks like ISOS. FFC uses a larger kernel to gather data from the entire image and does not only rely on local information giving the advantage of in extraction of global contextual information. FFC was utilized as local and global context extraction branch for rich overall information: -\n\u2022\nAcquisition of input (spatial domain), and conversion to the frequency domain by utilizing Real FFT2d and then concatenating the real and imaginary parts: -\nReal FFT2d: $R^{H \\times W \\times C} \\rightarrow C^{\\frac{H}{2} \\times W \\times C}$\nComplex To Real : $C^{\\frac{H}{2} \\times W \\times C} \\rightarrow I R^{\\frac{H}{2} \\times W \\times 2 C}$\n\u2022\nApply Conv-Bn-ReLU layers in the frequency domain:-\nConv Norm Act: $R^{\\frac{H}{2} \\times W \\times 2 C} \\rightarrow R^{\\frac{H}{2} \\times W \\times 2 C}$\n\u2022\nConvert back to spatial domain from frequency domain by utilizing Real IIFT2d:-\nReal To Complex : $R^{\\frac{H}{2} \\times \\frac{W}{2} \\times 2 C} \\rightarrow C^{\\frac{H}{2} \\times \\frac{W}{2} \\times C}$\nInverse Real FFT2d : $C^{\\frac{H}{2} \\times \\frac{W}{2} \\times C} \\rightarrow R^{H \\times W \\times C}$"}, {"title": "C. Vertical and Horizontal Attention Gates", "content": "In the modified U-Net with AG, the horizontal AGs retain their original configuration. However, the vertical AGs are set up to operate in dual directions by integration into each encoder blocks. In this arrangement, each block is divided into two parts, and the vertical AGs are positioned in between them. The combination of SC, and FFC into DCLs and in addition to the introduction of cross AGs allows effective focus on the target object and capture multi-scale contrast and contextual information. The modified DCL blocks for encoders and decoders with SC, FFC, and vertical AGs are shown in Figure 1."}, {"title": "V. EXPERIMENTATION AND FINDINGS", "content": "A. Datasets\nWe used publicly available SIRST [9] and IRSTD [10] datasets that are valuable resources for ISOS research, details are shown in Table 1. SIRST is a single-frame dataset of infrared images with low contrast between foreground and background. Whereas, IRSTD provides a wider range of target shapes and detailed annotations. Both datasets serve as valuable benchmarks for advancing ISOS development and are developed for ISOS tasks.\nB. Metrics\nIn line with other literature on ISOS, we evaluated our proposed approach using pixel-level metrics (IoU and nIoU), object-level (Pd and Fa), and model-level (F-Score and AUC). Formulas for Intersection over Union (IoU), normalized IoU (nIoU), probability of detection (Pd), and false alarm rate (Fa) are: -\n$IoU = \\frac{1}{n} \\sum_{i=0}^{n} t p_{i}$\n$nIoU = \\frac{1}{n} \\sum_{i=0}^{n} \\frac{t p_{i}}{(f p_{i}+f n_{i}-t p_{i})}$\n$Pd = \\frac{1}{n} \\frac{N_{p r e d}}{N_{a l l}}$\n$Fa = \\frac{1}{n} \\frac{P_{\\text {false }}}{P_{\\text {all }}}$\nWhere n, tp, fp, and fn stands for total number of samples, true positive, false positive, and false negative, respectively. $P_{\\text {false }}, P_{\\text {all }}$ stands for the pixels of falsely identified objects and the pixels of all objects, and $N_{\\text {pred }}, N_{\\text {all }}$ stands for the number of correctly detected objects and the total number of objects.\nC. Implementation Details\nWe carried out our studies utilizing freely accessible resources of Google Colaboratory [39] and the model was implemented in TensorFlow. We utilized binary cross-entropy loss [40] as our criterion and AdamW optimizer with combination of 0.001 and 0.004 as it's initial learning and weighted decay rates [41] respectively. Each experiment had a batch size of 8, and a maximum epoch of 150 was used to train it.\nD. Quantitative and Qualitative Comparisons\nThe qualitative results achieved by the components used in SFA-UNet are shown in Figure 2, where its promising effects can be validated. Furthermore, the quantitative performance of SFA-UNet as compared to other selective top performing conventional and DLAs based methods are given in Tables 2-3, respectively. It is clear from these results that SFA-UNet has better demonstratable performance on both ISOS datasets. The improvement of SFA-UNet's performance can be attributed to its modifications discussed in Section IV, allowing a better fusion of feature extraction and information-sharing across multi-scales."}, {"title": "VI. CONCLUSION", "content": "In this paper, we identified the prevailing issues in ISOS that affect model accuracy and performance. Inspired by these challenges, we proposed SFA-UNet, a modified U-Net with attention gate (AG) based architecture. SFA-UNet contains Scharr and fast Fourier based convolutions (SC-FFC) in encoder-decoder blocks and vertical AGs within-encoder block. The proposed model effectively addressed the inherited issues in ISOS-based DLA approaches. Specifically, to address the issues of insufficient information in small objects and potential loss in deep models, SC-FFC layers helped to capture multi-scale contrast and contextual information. To deal with the issue of effective extraction of fine-grained details while ignoring potential background noise, addition of vertical AGs within the respective encoder layers of U-Nets, enhanced the model's focus on the targeted object and ignored irrelevant regions. Experimentations validated that the proposed SFA-UNet model demonstrate significant performance and produced an average 0.75\u00b10.25% of all combined metrics in multiple runs as compared to the existing state-of-the-art approaches on both datasets. Moreover, insights from SFA-UNet can be utilized for ongoing ISOS research in infrared based applications, such as remote sensing and surveillance etc."}]}