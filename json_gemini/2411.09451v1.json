{"title": "DiffRoad: Realistic and Diverse Road Scenario Generation for Autonomous Vehicle Testing", "authors": ["Junjie Zhou", "Lin Wang", "Qiang Meng", "Xiaofan Wang"], "abstract": "Generating realistic and diverse road scenarios is essential for autonomous vehicle testing and validation. Nevertheless, owing to the complexity and variability of real-world road environments, creating authentic and varied scenarios for intelligent driving testing is challenging. In this paper, we propose DiffRoad, a novel diffusion model designed to produce controllable and high-fidelity 3D road scenarios. DiffRoad leverages the generative capabilities of diffusion models to synthesize road layouts from white noise through an inverse denoising process, preserving real-world spatial features. To enhance the quality of generated scenarios, we design the Road-UNet architecture, optimizing the balance between backbone and skip connections for high-realism scenario generation. Furthermore, we introduce a road scenario evaluation module that screens adequate and reasonable scenarios for intelligent driving testing using two critical metrics: road continuity and road reasonableness. Experimental results on multiple real-world datasets demonstrate DiffRoad's ability to generate realistic and smooth road structures while maintaining the original distribution. Additionally, the generated scenarios can be fully automated into the OpenDRIVE format, facilitating generalized autonomous vehicle simulation testing. DiffRoad provides a rich and diverse scenario library for large-scale autonomous vehicle testing and offers valuable insights for future infrastructure designs that are better suited for autonomous vehicles.", "sections": [{"title": "I. INTRODUCTION", "content": "TESTING and validating autonomous vehicles (AVs) necessitate a substantial number of diverse scenarios [1]. Road scenarios are the foundation for autonomous driving tests [2]. However, there is a significant lack of comprehensive road scenario libraries suitable for digital twin-based simulation testing [3]. The complexity and variability of real-world road scenarios critically affect the safety and overall performance of AVs. One critical bottleneck in AV simulation testing is the limited availability of diverse road scenarios for simulation purposes, with existing scenarios being predominantly homogeneous. Therefore, there is a pressing need for an effective road scenario generation method that can produce realistic and diverse road scenarios to enhance AV testing.\nIn addition, the rapid advancement of AV technology is ushering in a transformative era in the transportation sector [4]. Unlike human-driven vehicles, AVs operate in fundamentally different ways [5]. However, the existing road infrastructure, primarily developed for human drivers, may not fully capitalize on the benefits provided by this emerging technology [6]. To ensure seamless integration and optimal performance, road infrastructure needs to adapt accordingly. There is an urgent need for a comprehensive library of road scenarios tailored for digital twin-based AV testing. Such a library is essential for guiding the future design of road infrastructure, ensuring it meets the unique requirements of AVs and maximizes their potential benefits.\nTo achieve high-precision intelligent driving simulation tests, several road scenario formats have been proposed, including OpenDrive [7], Lanelet2 [8], and CommonRoad [9]. Among these, OpenDrive is widely used by most well-known simulators, such as Intel's CARLA [10], Virtual Test Drive (VTD) [11], Apollo [12], PreScan [13], and SUMO [14]. Despite its widespread use, there is little work on generating realistic and diverse road scenarios. Current methods for constructing test road scenarios rely primarily on aerial imagery [15], sensor data reconstruction [16], or manual creation using commercial tools such as MATLAB RoadRunner [17]. Besides, the CommonRoad Scenario Designer is designed in [18] to to convert OpenStreetMap (OSM) [19] maps maps to CommonRoad format. This scenario designer only enables scenario format conversion and cannot generate more scenarios for AV testing. A model-driven approach is proposed in [20] to generate interchanges based on the topology graph. However, this method can only generate specific types of interchanges scenarios. In addition, all existing methods are limited to either converting road scene formats or generating a single type of road scene from existing data, and they fall short of generating large-scale, realistic, and diverse road scenes. Therefore, an efficient method for generating a comprehensive library of realistic and diverse road scenarios for AV testing has become a critical challenge.\nTo address the challenges in road scenario generation for AV testing, we introduce DiffRoad, a diffusion model-based framework that can effectively capture the spatial distribution of road structures and generate high-quality road scenarios. The core idea behind this approach is to perturb the road distribution with noise through a forward diffusion process and then recover the original distribution from Gaussian noise via a learning-based denoising process. This approach results in a highly flexible road scenario generation model. To achieve controllable road scenario generation, we introduce an innovative road attribute embedding module. This module encodes road attribute information through a wide and deep network, enabling controllable, high-precision road scenario generation. Besides, to further improve the realism and usability of the generated road scenarios, we develop a scene evaluation and screening model. Finally, the evaluated scenarios are automatically converted into a generic OpenDRIVE format, facilitating digital twin-based AV testing.\nIn summary, our main contributions are as follows:\n\u2022 We introduce DiffRoad, the first work to utilize the diffusion model for 3D road scenario generation, pioneering the creation of a diverse lane-level road scenario library. DiffRoad effectively harnesses the diffusion model to capture the distribution of real-world road structures, thereby enabling the generation of realistic and varied road scenarios with high efficiency and transferability.\n\u2022 To capture the spatial distribution of road structures and achieve controllable, high-fidelity road scenario generation, we design a novel denoising network architecture called Road-UNet. Road-UNet integrates the FreeU architecture to optimize the balance between the backbone and skip connections, significantly enhancing the quality of generated road scenarios. Furthermore, we introduce a smoothness regularization mechanism to improve the continuity and realism of the generated roads, ensuring smoother transitions and more realistic road layouts.\n\u2022 We propose a scene-level scoring function to select the generated road scenarios that are more realistic and sensible. To enhance the generalizability of the generated road scenarios, we automatically convert them into the OpenDRIVE format, making them compatible with mainstream simulation test platforms.\nThe effectiveness of DiffRoad is validated using three road datasets that we collected. The results demonstrate that our method can generate high-fidelity road scenarios while preserving essential statistical properties."}, {"title": "II. RELATED WORK", "content": "Existing road scenarios for simulation testing are usually created manually using commercial tools or converted from existing data [18], [31]. The CommonRoad Scenario Designer [18] was widely used for converting road scenario formats, including OpenDRIVE, OSM, Lanelet2, and CommonRoad. Additionally, the model-driven method [20] was proposed for generating a specific type of interchange scenario. Ikram et al. [25] proposed procedural methods for roundabout generation. However, all these methods are limited to generating specific types of road scenarios, which significantly restricts the scale and diversity of the generated scenario library.\nHartmann et al. [21] developed a method that converts road network patches into binary images where pixel intensity indicates street presence or absence. Then, they trained a generative adversarial network (GAN) to synthesize street networks. However, this approach lacks precision and only generates macroscopic road network images. Similarly, Kelvin et al. [22] used conditional GAN for game map image generation, which proved effective for map image generation. Nevertheless, existing map image generation methods make it difficult to translate into OpenDRIVE road structure data for simulating realistic driving behavior in the virtual simulation software. These methods are limited to macroscopic images and fail to produce accurate micro road structures necessary for AV simulation testing."}, {"title": "III. METHODOLOGY", "content": "DiffRoad aims to generate realistic and diverse road scenarios for AV testing. In this paper, a road scenario is denoted as a complex set of n interconnected roads, denoted by $x = \\{r_1, r_2, ..., r_n\\}$, where each road $r_i = \\{m_1^i, m_2^i, ..., m_{n_i}^i\\}$ is a sequence of sampled road shape points. The j-th road shape point in the i-th road is denoted as a tuple $m_j^i = [lat_j^i, Ing_j^i]$, where $lat_j^i$ and $Ing_j^i$ indicate latitude and longitude, respectively.\nThe diffusion probabilistic model utilizes a progressive process wherein noise is incrementally added to the data through a forward diffusion process, subsequently estimating the added noise at each step through a reverse diffusion process, and gradually attenuating the data by removing the noise to recover noise-free data [33]. Essentially, the diffusion probabilistic model embodies a Markovian architecture.\nDuring the forward diffusion, T time steps of Gaussian noise $\\mathcal{N}(\\cdot)$ are gradually appended to the original data $x_0 \\sim q(x_0)$ to obtain the latent variables $x_1,...,x_T$, where T is an adjustable parameter denoting the maximum diffusion step. According to denoising diffusion probabilistic models (DDPMs) [33], the forward diffusion process is expressed as:\n$x_t = \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon$, (1)\n$\\bar{\\alpha}_t = \\prod_{i=1}^t (1 - \\beta_i)$, (2)\nwhere $\\alpha_t$ denotes the noise level, $\\epsilon$ denotes the noise sampled from the Gaussian distribution $\\mathcal{N}(0, I)$, and $\\beta_i \\in (0, 1)$ is the variance schedule.\nIn the reverse diffusion process, the conditional diffusion model is designed to reconstruct the original road scenario data $x_0$ from the Gaussian noise data $x_T \\sim \\mathcal{N}(0,I)$. We design attributes such as road type and road size as conditional information to guide the diffusion model in generating road scenarios that are noise-free and meet specific control requirements. The reverse diffusion process is defined by:\n$p_\\theta(x_{0:T}|c) = p(x_T|c) \\prod_{t=1}^T p_\\theta(x_{t-1}|x_t, t, c)$, (3)\n$p_\\theta(x_{t-1}|x_t, t, c) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t, c), \\Sigma_\\theta(x_t, t,c))$, (4)\nwhere $\\mu_\\theta(x_t, t, c)$ and $\\Sigma_\\theta(x_t, t, c)$ are the mean and variance of the reverse process at each step t, respectively, $p(x_T|c) = p(x_T) \\sim \\mathcal{N}(0,I)$, and $\\theta$ indicates the parameters of the conditional diffusion model. Based on previous studies [33], the mean and variance of the reverse process can be calculated by:\n$\\mu_\\theta(x_t, t, c) = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\epsilon_\\theta(x_t, t, c))$,\n$\\Sigma_\\theta(x_t, t, c) = \\sigma_t^2I, \\text{ where } \\sigma_t^2 = \\begin{cases} \\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_t} \\beta_t, & t > 1, \\\\ \\beta_t & t = 1, \\end{cases}$ (5)\nwhere $\\epsilon_\\theta(x_t, t, c)$ indicates the predicted noise under conditions t and road attributes c.\nThe primary goal of DiffRoad is to generate realistic and diverse 3D road scenarios that adhere to specific conditional constraints and preferences. The overarching framework of DiffRoad primarily comprises the road structure data generation model based on the enhanced conditional diffusion model, alongside the scene-level evaluation and filtering module, as depicted in Fig. 1. The integration of road structure data encoding and road attribute embedding empowers DiffRoad with comprehensive information, ensuring the controllable generation of road scenarios essential for AV testing. DiffRoad incorporates the road attention mechanism and Road Multi-FreeU-Net (Road-UNet) module, iteratively refining the noise estimation based on real-world road data and corresponding attribute information to synthesize the final road scenarios. Furthermore, we introduce a smoothness regularization term to enhance the overall smoothness of the generated roads.\nTo address the possibility of generating unrealistic scenarios by the generative model, we introduce a scenario evaluation model aimed at ensuring the usability and realism of the simulation test scenarios. The evaluated road scenarios are subsequently transformed into OpenDRIVE format [7] for AV testing, which has greater compatibility and generalizability for use with a wide range of AV simulation software.\nTo ensure accurate prediction of noise at each diffusion time step, the generative model needs to capture the spatial dependencies between road structures. Therefore, we leverage the Road-UNet architecture to construct a network to infer the noise at each diffusion time step in the DiffRoad. The Road-UNet comprises two main components: down-sampling and up-sampling, with each layer containing multiple 1D-CNN-based stacked residual network blocks (Resnet blocks). Additionally, a transition module based on the attention mechanism is integrated between these components. To enhance noise learning at each diffusion time step, the Road-UNet employs the Sinusoidal embedding method to embed the time step information, which is then fed into each block. Furthermore, Road-UNet incorporates two shared-parameter fully connected layers, which are added to the input of the Resnet block."}, {"title": "Algorithm 1 The main processes of DiffRoad", "content": "Input: Real-world road structure data x, road attributes c\nOutput: Generated road scenes $\\hat{x}_0$\nTraining Process:\n1: while not done do\n2: Get conditional guidance c\n3: Sample $x_0 \\sim q(x_0)$\n4: Sample $t \\sim Uniform(1, . . ., T), \\epsilon \\sim \\mathcal{N}(0, I)$\n5: $x_t = \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon$\n6: $L(\\theta) = L_{mse}(\\theta) + wL_s(\\theta)$\n7: $\\theta = \\theta - \\nabla_\\theta L(\\theta)$\n8: end while\nGenerating Process:\n9: Get road attributes c\n10: Sample $x_T \\sim \\mathcal{N}(0, I)$\n11: for $t \\in [T, 1]$ do\n12: Compute $\\mu_\\theta(x_t, t, c)$ and $\\Sigma_\\theta(x_t, t, c)$\n13: Compute the scaling factor $a_z$ and the Fourier mask $\\beta_{z,j}$\n14: Concatenate augmented skip feature $h_z^j$ and modified backbone feature $\\hat{x}_z^j$\n15: Compute $p_\\theta(x_{t-1}|x_t, t, c)$\n16: end for\nTo achieve controllable and realistic 3D road scene generation, we meticulously designed the Road-UNet architecture. In contrast to the conventional U-Net model [41], we integrate FreeU operations to enhance the quality of road scene generation. Previous research [42], [43] indicates that backbone features contribute significantly to denoising capabilities, while skip connections enhance high-frequency features in the U-Net model, facilitating noise prediction convergence within the decoder module. However, it will weaken the denoising ability of the backbone. To address this, we introduce Multi-FreeU operations to balance these feature mappings. Specifically, our Road-UNet incorporates two scalar factors, the backbone feature scaling factor $b_z$ for $x_z$ and the skip feature scaling factor $s_z$ for $h_z$, where $x_z$ denotes the backbone feature in the z-th block of the Road-UNet decoder, and $h_z$ denotes the skip connection feature in the z-th block. For the backbone features $x_z$, we adaptively scale the scaling factor $a_z$ based on the average feature map $\\bar{x}_z$:\n$a_z = (b_z - 1) \\cdot \\frac{\\bar{x}_z - Min(\\bar{x}_z)}{Max(\\bar{x}_z) - Min(\\bar{x}_z)} + 1$, (6)\n$\\hat{x}_{z,j} = \\begin{cases} x_{z,j} \\cdot a_z, & \\text{if } j < \\frac{B}{2} \\\\ x_{z,j}, & \\text{otherwise}, \\end{cases}$ (7)\nwhere $b_z$ is the scalar constant, $\\bar{x}_{z,j}$ denotes the j-th channel of the feature map $x_z$, $B$ denotes the total number of channels in $x_z$, and $\\cdot$ denotes element-wise multiplication. To preserve some of the high-frequency details and enhance the realism of the road scene generation, we confine the scaling operation to half of the channels of $x_z$, as described in Equation (7)."}, {"title": "D. Controllable Road Structure Generation", "content": "To generate controllable, realistic, and diverse road scenarios, we propose a novel consistent conditional diffusion method for creating a large number of road scenarios for AV testing. The primary objective of DiffRoad is to approximate the distribution of real-world road scenarios, denoted as $q(x_0|c)$, using a parameterized model $p_\\theta(x_0|c)$. This objective is achieved through a rigorous training and generation process, as detailed in Algorithm 1.\nDuring the training process, the wide and deep networks [44] are initially utilized to encode and embed road attribute information, such as road type and road scale. Subsequently, the DiffRoad model estimates the noise in the reverse process based on the conditional embedding c and diffusion time step t. The objective of training the diffusion model is to minimize the mean square error between the noise $\\epsilon$ and the noise $\\epsilon_\\theta(x_t, t, c)$ predicted by the model:\n$L_{mse}(\\theta) = \\mathbb{E}_{c,t,x_0,\\epsilon}[||\\epsilon - \\epsilon_\\theta(x_t, t, c) ||^2]$. (10)\nTo improve the smoothness of the generated road scenarios, we introduce a regularization term into the training objective. This term evaluates smoothness by comparing the distances between adjacent sampling points in the generated scenario with those in real-world road scenarios. Specifically, it ensures that the spacing between points in the generated road scenario mirrors that of actual road data. This smoothness loss term helps align the generated samples with real-world data, minimizing discrepancies and enhancing the fidelity of the generated road scenarios. The smoothness loss term is defined as follows:\n$L_s(\\theta) = \\mathbb{E}_{c,t,x_0,\\epsilon}[||(\\epsilon_{p+1} - \\epsilon_p) - (\\hat{\\epsilon}_{p+1} - \\hat{\\epsilon}_p)||^2]$, (11)\nwhere $\\epsilon_{p+1}$ and $\\epsilon_p$ represent the (p + 1)-th point and p-th point in the added Gaussian noise $\\epsilon$, respectively, $\\hat{\\epsilon}_{p+1}$ and $\\hat{\\epsilon}_p$ represent the (p + 1)-th point and p-th point in the predicted noise $\\hat{\\epsilon}$, respectively.\nBy combining the noise prediction loss and the smoothness loss, we define a novel hybrid objective loss function $L(\\theta)$:\n$L(\\theta) = L_{mse}(\\theta) + wL_s(\\theta)$, (12)\nwhere w is the hyperparameter utilized to balance the smoothness loss term ($L_s$) and the mean square error loss ($L_{mse}$) to ensure that $L_s$ does not dominate $L_{mse}$."}, {"title": "E. 3D Road Structure Generation", "content": "In this paper, according to the road structure design regulations [45]\u2013[47], the maximum longitudinal gradient varies with the design speed. For instance, at 80 km/h, the maximum permissible gradient is 5%. Vehicles should not be subjected to centrifugal forces $F_c$ exceeding the maximum permissible limits $F_{max}$ when navigating up and down ramps. To ensure the safety and comfort of vehicles on ramps, we formulate the following slope calculation formula in combination with the curvature of the road:\n$F_c = \\frac{mv^2 cos(\\rho_c)}{r} < F_{max}$, (13)\n$\\rho = min(\\rho_c, \\rho_{max})$, (14)\nwhere $\\rho$ is the gradient, m is the mass of the vehicle, v is the road design speed limit, and r is the radius of curvature."}, {"title": "F. Scene-level Evaluation Module", "content": "Given that the generative model may produce road scenarios that do not meet specified criteria, we propose a road scene evaluation and screening model to address this issue. This model comprises two key metrics: the road continuity metric and the road reasonableness metric. The generated road scenes are screened with reference to the road structure design regulations [45]\u2013[47] to obtain compliant road scenarios for AV testing.\nSpecifically, the road continuity metric is derived by calculating the difference between the mean curvature change rate of the actual road scenario and that of the generated road scenario, denoted as $w_1(x_0)$. The road reasonableness metric assesses whether there are overlapping roads in the generated road scenario, quantified by the proportion of overlapping roads to the total number of roads, which is denoted as $w_2(x_0)$. The final road evaluation function is expressed as follows:\n$S(x_0) = 100 \u2013 (w_1(x_0) + \\lambda w_2(x_0))$, (15)\nwhere $\\lambda$ is the weighting factor used to balance the two terms."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "To demonstrate the effectiveness of DiffRoad, extensive experiments were conducted using three real-world road datasets we collected. The experimental results indicate that DiffRoad can generate all types of road scenarios globally for AV testing."}, {"title": "V. CONCLUSION", "content": "To achieve realistic and diverse 3D road scene generation for AV testing, we propose DiffRoad, a novel architecture based on the improved diffusion model that automates the entire process by learning the data distribution of real-world road structures. To ensure controllability, we design a road attribute information embedding module that guides the generation of specific types of road scenes. To capture real-world road structural features and enhance generation quality, we develop the Road-UNet architecture, incorporating the FreeU network for more accurate noise level prediction. Furthermore, we introduce a scene-level evaluation module to filter and select the most realistic road scenes for AV testing. The generated road scenes are automatically converted into the generic OpenDRIVE format, ensuring compatibility with existing mainstream autonomous driving simulation software. Extensive experiments demonstrate that DiffRoad can generate realistic, diverse, and controllable road scenes that align with the statistical characteristics of real-world road scenes. Further experiments validate the effective application of DiffRoad-generated road scenes in digital twin-based intelligent driving simulation tests. In the future, it is worth exploring the use of the large-scale road scenario library generated by DiffRoad to further accelerate intelligent driving testing and investigate road infrastructure that is more suitable for AVs."}]}