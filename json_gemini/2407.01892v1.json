{"title": "GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning", "authors": ["Zhisheng Tang", "Mayank Kejriwal"], "abstract": "Spatial reasoning, an important faculty of human cognition with many practical\napplications, is one of the core commonsense skills that is not purely language-\nbased and, for satisfying (as opposed to optimal) solutions, requires some minimum\ndegree of planning. Existing benchmarks of Commonsense Spatial Reasoning\n(CSR) tend to evaluate how Large Language Models (LLMs) interpret text-based\nspatial descriptions rather than directly evaluate a plan produced by the LLM in\nresponse to a spatial reasoning scenario. In this paper, we construct a large-scale\nbenchmark called GRASP, which consists of 16,000 grid-based environments\nwhere the agent is tasked with an energy collection problem. These environments\ninclude 100 grid instances instantiated using each of the 160 different grid settings,\ninvolving five different energy distributions, two modes of agent starting position,\nand two distinct obstacle configurations, as well as three kinds of agent constraints.\nUsing GRASP, we compare classic baseline approaches, such as random walk\nand greedy search methods, with advanced LLMs like GPT-3.5-Turbo and GPT-\n40. The experimental results indicate that even these advanced LLMs struggle to\nconsistently achieve satisfactory solutions.", "sections": [{"title": "1 Introduction", "content": "Spatial reasoning, a fundamental aspect of human cognition, is a core commonsense skill that allows\npeople to navigate, interact with, and manipulate their environments effectively [8, 17, 11, 10]. This\ncognitive ability involves recognizing and understanding the spatial relations among different entities,\n[19], as well as actively using it to navigate through space while manipulating objects within it [15],\nwhich is essential in day-to-day activities such as walking and driving. An adequate spatial reasoning\nability means more than just recognizing the relative spatial relationships between objects but also\nusing such relationships, in combination with planning skills, to achieve satisfying, if not optimal,\nsolutions for tasks at hand.\nWith the advancement of Large Language Models (LLMs) in understanding and generating natural\nlanguage [1, 29, 24, 23], exhibiting near human-level commonsense reasoning abilities [12, 30, 20],\nas well as their increasing integration into applications requiring spatial awareness [9, 3, 27, 31],\nevaluating their spatial reasoning capabilities has raised significant attention [21, 25, 26, 2]. Several\nbenchmarks, such as SpartQA [16], StepGame[22], and BabyAI[4], have been proposed to evaluate\nthese abilities by simulating visual or textual spatial relationships. However, these benchmarks focus\non interpreting spatial descriptions, whether textually or visually, and neglect the practical aspect of\nspatial reasoning."}, {"title": "2 Related Work", "content": "Increasing attention has been focused on investigating the spatial reasoning abilities of LLMs\n[26, 2, 16, 14, 25, 2]. Specifically, SpartQA [16], a textual Question-Answering (QA) benchmark,\nis constructed using grammar and reasoning rules to automatically generate a spatial description\nof visual scenes and corresponding QA pairs. Furthermore, Shi et al. [22] introduced StepGame,\na multi-hop spatial reasoning benchmark that investigates the navigation ability of LLMs through\ncomplex spatial descriptions. Similarly, Liu et al. [14] explored spatial commonsense by exploiting\nvisual signals and evaluating LLMs' understanding of the relative scales of objects and the positional\nrelationship between people and objects. Com\u0219a and Narayanan [6] focused on reasoning with\nspatial prepositions, which is essential for accurately describing and interpreting spatial relationships.\nHowever, these benchmarks focus on interpreting and understanding spatial relationships in textual or\nvisual formats, while our benchmark evaluates the ability to utilize spatial information to accomplish\nrelated tasks. Our distinct approach assesses the practical application of spatial reasoning, requiring\nmodels to navigate and make plans based on spatial information. Another key distinction is that\nthese benchmarks frequently depend on textual descriptions of scenes to convey spatial relationships.\nIn contrast, our benchmark directly integrates text renderings of the environment to insert spatial\ninformation."}, {"title": "3 GRASP: Benchmark Construction", "content": "GRASP evaluates the commonsense spatial reasoning ability of LLMs by testing their capability to\nnavigate in a grid-base environment while assigned an energy collection task. The benchmark is a\ncombination of grid environments and agent constraints. The grid environment, $G$, can be understood\nas a 2D square array of cells $C_{ij}$, indexed from 0 to k and from left to right and top to bottom, with i\nrepresenting row index and j representing column index: $C_{00}, ..., C_{0k}, C_{10}, ..., C_{1k}, ..., C_{k0}, ..., C_{kk}$.\nA cell can either be empty ($C_{ij}$ = Null), contain one unit of energy ($C_{ij}$ = E), have an obstacle\n($C_{ij}$ = 0), or be the starting point of the agent ($C_{ij}$ = A).\nAs for the agent constraints, the agent is allowed pre-defined (n) steps. At each step, the agent can\nchoose from a set of movement-related actions ($\\mu$) that allows it to move around the grid environment"}, {"title": "3.1 Grid Environments", "content": "We establish the side length k of the grid environment to be 11. As a result, there are 11 \u00d7 11\n= 121 cells in the grid. Based on this setup, we construct a set of grid templates that can be\nfurther instantiated to become a grid instance. Each grid template consists of three controls: Energy\nassignment, Obstacle construction, and Starting position. Each control can take several different\nvalues.\nSpecifically, for the energy assignment, the random distribution assigns an equal probability of having\none unit of energy in each cell, setting a baseline test bed for the agent's ability. The vertically-skewed\nand horizontally-skewed distributions introduce asymmetry in the energy assignment, testing for any\nspatial bias in the agent's decisions. Furthermore, cluster distribution introduces localized energy\nclusters, and spiral distribution generates an energy path from the center, both exploring the agent's\nability to identify and target specific regions or parts of the grid. Details about the five distinct types\nof energy assignment are described in the following:\n\u2022 Random distribution of energy means that each cell in the grid has the same probability\nof containing one unit of energy. This probability is determined in during instantiation and\nfollows a uniform distribution between 0.3 and 0.7. For one grid template, $P(C_{ij} = E) =$\n$p, p \\sim U(0.3, 0.7), \\forall i, j$.\n\u2022 Vertically-skewed distribution means the cells in the top-half-part of the grid (rows 0 to\n5) are more likely or less likely (determined in instantiation) to contain one unit of energy\nthan the bottom-half-part of the grid (rows 6 to 10). In instantiation, the probability $P_{top}$\nof a top-half-part cell containing one unit of energy is randomly instantiated from one of\nthe two uniform distributions: $U(0.3, 0.4)$ and $U(0.6, 0.7)$. Then, the probability $P_{bottom}$\nof a bottom-half-part cell containing one unit of energy is defined as $P_{bottom} = 1 - P_{top}$.\nFormally, $P(C_{ij} = E) = P_{top}, \\forall 0 <= i <= 5,j$ and $P(C_{ij} = E) = P_{bottom},$\n$6 <= i <= 10, j$. As for $P_{top}$,\n$P_{top} \\sim\n\\begin{cases}\nU(0.3, 0.4) & \\text{with probability 0.5} \\\\\nU(0.6,0.7) & \\text{with probability 0.5}\n\\end{cases}$\n\u2022 Horizontally-skewed distribution is similar to the vertically-skewed distribution. According\nto this distribution, cells in the left-half-part of the grid (columns 0 to 5) are more likely\nor less likely (determined in instantiation) to contain one unit of energy than the right-\nhalf-part of the grid (columns 6 to 10). In instantiation, the probability $P_{left}$ of a left-\nhalf-part cell containing one unit of energy is randomly instantiated from one of the two\nuniform distributions: $U(0.3, 0.4)$ and $U (0.6, 0.7)$. Then, the probability $P_{right}$ of a right-\nhalf-part cell containing one unit of energy is defined as $P_{right} = 1 - P_{left}$. Formally,\n$P(C_{ij} = E) = P_{left}, \\forall i, 0 <= j <= 5$ and $P(C_{ij} = E) = P_{right}, \\forall i, 6 <= j <= 10$.\nAs for $P_{left}$,\n$P_{left} \\sim\n\\begin{cases}\nU(0.3,0.4) & \\text{with probability 0.5} \\\\\nU(0.6,0.7) & \\text{with probability 0.5}\n\\end{cases}$\n\u2022 Cluster distribution creates a number of energy clusters around the grid. Each cluster\nenables the cells in a 3 by 3 grid to be filled with energy. The centers of the clusters are\nchosen randomly. Hence, it is possible for clusters to overlap each other. The number of\nclusters is randomly chosen between 3, 4, and 5 during instantiation. All other cells do not\ncontain any energy. Formally, if the center of the cluster is denoted by the cell $C_{ab}$, then\n$P(C_{ij} = E) = 1, \\forall a - 1 <= i <= a + 1, b - 1 <= j <= b + 1$ and $a \\sim U\\{0, 10\\}$ and\n$b \\sim U\\{0, 10\\}$."}, {"title": "3.2 Agent Constraints", "content": "Along with different grid environments, we also consider constraints that the agent needs to follow\nwhen accomplishing the task. First of all, we fix the number of steps the agent can take to be n = 20\nsteps. Additionally, the agent cannot move beyond the boundary of the grid, and any invalid action\nwill result in no change to the environment.\nFor each step, we design two sets of movement-related actions that the agent is allowed to take:\n$\\mu_1 = \\{UP, DOWN, LEFT, RIGHT\\}$, $\\mu_2 = \\{UP, DOWN, LEFT, RIGHT, UPLEFT, UPRIGHT,\nDOWNLEFT, DOWNRIGHT\\}$. The outcome of each action corresponds to the characteristics\nsuggested by its name. For example, UP allows you to move one cell up in one step, and UPLEFT\nallows you to move diagonally one cell up and left in one step. The two sets of movement-related\nactions offer the agent varying degrees of movement flexibility, with one offering basic movements\nwhile the other allows for additional diagonal movements. Additionally, we design two resource-\nrelated actions: $\\rho = \\{TAKE, DROP\\}$. TAKE allows the agent to take the energy from the cell if\nthe agent is moved to a cell with energy, and DROP allows the agent to drop all the energy that the\nagent carries to the cell that the agent is currently on.\nFurthermore, we design two constraints that could potentially affect the agent's behaviors. The first\nconstraint, if active, adds a limit on the number of energy units that the agent can carry to a maximum\nof 2 units, requiring the agent to drop energy before acquiring any more of it beyond two units.\nThe second constraint, if active, adds a cost to each action, forcing the agent to consider the energy\nexpenditure of its actions. This cost is defined as 0.3 units of energy per action. Combining each\nof the 2000 grid environment instances with the three different agent constraints, we have a total of\n2000 \u00d7 2 \u00d7 2 \u00d7 2 = 16000 different instances of the benchmark."}, {"title": "3.3 Grid Representation to An LLM-based Agent", "content": "So far, we have described the grid as an abstract environment. However, to present it to an LLM-\nbased agent, the grid needs a concrete representation. Previous works either use text descriptions\n[16, 22] or involve another modality (i.e., visual) [4, 5]. While textual description can convey spatial"}, {"title": "4 Experiments", "content": "Two baseline approaches are evaluated. The first is the random walk method. This method simulates\nan agent who has no knowledge about the grid, the agent constraints regarding the limit on the number\nof energy that the agent can carry, and the cost of each action, but is only aware of the set of available\nactions. The random walk method randomly selects one out of the four or eight movement-related\nactions, depending on the available actions. Following each of the movement-related actions, this\napproach will select the TAKE action to take the energy from the cell, whether or not the cell has\nany energy. This 'move and take' behavior will continue for 6 times. Then, this approach will select\nthe complement of the movement-related actions that were selected before in reverse order to get\nback to the starting position and finally select DROP to drop all the energy. The complement of a\nmovement-related action is defined as the complementary action that exactly reverses the movement.\nFor example, if the initial movement-related action was \u2018UP,\u201d the complementary action would be\n'DOWN.' In total, this will take 19 steps, which is within the required 20 steps.\nThe second baseline approach is the greedy search method. This method simulates an agent with\nperfect knowledge of the grid environment but no planning abilities and no knowledge about the\nagent constraints except the available movement-related actions. This agent starts from the agent's\ncurrent position and uses a Breadth-First Search algorithm to navigate the grid. It considers all four\n$\\mu_1$ or eight $\\mu_2$ possible movement-related actions, depending on the available actions. At each step, it\nchecks the neighboring cells in all directions. The sequence of the neighboring cells in consideration\nis randomized. If a neighboring cell contains energy, the search stops, and the path to this cell is\nrecorded. If all neighboring cells are either empty or obstacles, the search continues to the next set\nof neighboring cells. Once the nearest energy cell is found, the recorded path is used to move the\nagent step-by-step towards that cell. This will continue until a neighboring cell that has energy is too\nfar from the current position, and the remaining number of steps is not enough for the agent to go\nthere and get back to the starting position using the complement of past movement-related actions in\nreverse order. At this point, the agent simply uses the complement of past movement-related actions\nin reverse order to get back to the starting cell and drop all the collected energy. The pseudo-code of"}, {"title": "4.1 Results", "content": "Table 2 displays the average number of steps taken and units of energy collected and dropped for the\ntwo baseline agents (Random Walk and Greedy Search) and the two LLM-based agents (GPT-3.5-\nTurbo and GPT-40), evaluated using GRASP. Most Energy results are negative numbers because they\nare averaged across all control settings, including a 0.3 unit energy cost per step that can lead to a\nnegative energy result if the energy cost exceeds the energy collected. When considering the overall\nperformance of each agent, we find that the Greedy Search agent performs the best across all settings,\nwhile GPT-3.5-Turbo performs the worst in 13 out of 14 settings. Additionally, GPT-40 performs\nbetter than GPT-3.5-Turbo but worse than the Greedy Search agent and is roughly on par with the\nRandom Walk agent.\nFocusing on the performance within each control, we observed Energy differences of 0.4, 0.5, and\n0.6 between the two settings of 'Obstacle,' 'Movement-related Action Set,' and 'Energy Carrying\nLimit' for GPT-40. This agent performs the best without any obstacles and energy carrying limit\nwhile using the action set $\\mu_1$, which only includes the four regular movements (i.e., UP, DOWN,\nLEFT, RIGHT) without the diagonal movements. However, these differences are less apparent\nfor GPT-3.5-Turbo, with the maximum difference being only 0.56 units of energy in the 'Energy\nCarrying Limit' control. Notably, GPT-4o achieves, on average, 5.08 units less energy when given\nthe constraint regarding the energy cost per step than when given no such constraint. A similar\nphenomenon is also observed for the GPT-3.5-Turbo agent. Additionally, the \u2018Energy Distribution'\nand 'Starting Position' controls seem to play a lesser role in affecting the performance of GPT-40\nand GPT-3.5-Turbo, as the difference in the amount of energy collected and dropped is less apparent\n(with the maximum difference being less than 0.35). However, for GPT-3.5-Turbo, the \u2018Energy\nDistribution' control shows a more significant impact, with a maximum difference of 0.68 between\nthe 'Spiral' and \u2018Vertically-skewed' distributions. Turning to the average length of the steps taken\nby each agent, we observe that GPT-40 takes the least number of steps among the four agents, often\nbetween 16 to 17 steps, while GPT-3.5-Turbo takes the most number of steps, taking 19 to 20 steps."}, {"title": "5 Discussion", "content": "In this paper, we introduce GRASP, a comprehensive benchmark designed to evaluate the Com-\nmonsense Spatial Reasoning (CSR) abilities of LLMs within structured grid environments. GRASP\nassesses agents' abilities to navigate the grid environments and collect energy, presenting 16,000\ndiverse environments characterized by five types of energy distributions, two distinct obstacle con-\nfigurations, two modes of agent starting position, and three kinds of agent constraints, including\ntwo sets of movement-related actions, two limits on the amount of energy that can be carried, and\ntwo different energy costs for each step. We evaluate the performance of two classic algorithms\n(Random Walk and Greedy Search) and advanced LLMs (GPT-3.5-Turbo and GPT-40) using GRASP.\nOur findings show that GPT-3.5-Turbo under-performs compared to the Random Walk agent, often\nunable to successfully navigate the grid, avoid obstacles, and return to the starting point to drop the\ncollected energy, suggesting a lack of CSR abilities. On the other hand, GPT-40 performs similarly\nto the Random Walk agent but is still less efficient than the Greedy Search agent. While GPT-40\ncan recognize spatial relationships and navigate around the grid environments, showing a primitive\ncapability of CSR, its use of spatial information to come up with efficient plans remains limited.\nOur study comes with several limitations. Firstly, the synthetic nature of GRASP's grid environments\nmay not fully capture the complexity of real-world CSR tasks, which include more dynamic and\nunpredictable environments with a greater variety of objects and incomplete or even hidden spatial"}, {"title": "6 Appendix", "content": "6.1 Various grid instances"}, {"title": "6.2 The pseudo-code for the two baseline agents", "content": "Algorithm 1 Random Walk Method\nRequire: The set of available movement-related actions \u03bc\n1: Initialize an empty list actions\n2: for i \u2190 1 to 6 do\n3: Randomly select an action a from \u03bc\n4: Append the selected action a to actions\n5: Execute the selected action a\n6: Execute TAKE action\n7: end for\n8: for i \u2190 6 to 1 step -1 do\n9: Execute the complement of actions[i]\n10: end for\n11: Execute DROP action"}, {"title": "6.3 Prompt used for evaluating the two LLM-based agents", "content": "The system prompt:\nYou are an agent in a grid world. The grid world consists of cells. Each cell may\nhave one unit of energy or no energy at all. {obstacle_prompt} The goal for you\nis to collect as much energy as possible and put the collected energy back in\nthe cell where you started. You have 20 steps. {movement_prompt} You can collect\nenergy from a cell by being in the cell and TAKE the energy from the cell. If\nthere is no energy in the cell, you cannot take any energy from it.{energy_limit_prompt} You can not move across the boundary of the grid world.\nYou can drop all your energy by DROP.{cost_of_step_prompt} You can use less\nthan 20 steps. Any invalid step will not cause any change in the grid world.\nThe variables encapsulated in {} are depended upon the specific environment that the agent is in.\nIf the grid has obstacles, then the obstacle_prompt is 'Some cells are blocked by obstacles. You\ncannot move to or through these cells.' If the grid does not have obstacles, the obstacle_prompt\nis left as blank. If the agent's movement-related action set is $\u03bc_1$, the movement_prompt is 'For\neach step, you can choose UP, DOWN, LEFT, RIGHT, TAKE, and DROP. UP allows you to move\none cell up in one step. The other movements are similar.' If the agent's movement-related action\nset is $\u03bc_2$, the movement_prompt is 'For each step, you can choose UP, DOWN, LEFT, RIGHT,\nUPLEFT, UPRIGHT, DOWNLEFT, DOWNRIGHT, TAKE, and DROP. UPLEFT allows you to move\ndiagonally one cell up and left in one step. The other movements are similar.' If the agent has no\nlimit on the number of energy that it can carry, the energy_limit_prompt is left as blank. If the agent\nhas a limit of 2 units of energy that it can carry, the energy_limit_prompt is \u2018You can only carry two\nunit of energy at a time.' If the agent has a zero cost per step, then the cost_of_step_prompt is left as\nblank. If the agent has a cost of 0.3 unit of energy per step, then the cost_of_step_prompt is 'Each\nstep costs you 0.3 unit of energy.'\nThe user prompt:\nYou are given the following as the representation of the grid world, where A is you,\nE is energy{user_obstacle_prompt}:\n{GRID}Give your sequence of steps as a\nlist. For example: [STEP, STEP, ...]\nThe variables encapsulated in are depended upon the specific environment that the agent is in. If the\ngrid has obstacles, then the user_obstacle_prompt is \u2018, O is an obstacle'. If the grid does not have\nobstacles, the user_obstacle_prompt is left as blank. The GRID variable is the text representation of\nthe grid."}, {"title": "6.4 The complete GRASP grid environments", "content": "We provide all grid environments, relevant code, and results in GitHub (https://github.com/\njasontangzsO/GRASP)."}, {"title": "6.5 GPT-40 selective results", "content": "We provide 7 different instances where GPT-40 exhibits inefficient behaviors or even fails to obey the\nrule."}]}