{"title": "A Green Multi-Attribute Client Selection for Over-The-Air Federated Learning: A Grey-Wolf-Optimizer Approach", "authors": ["MARYAM BEN DRISS", "ESSAID SABIR", "HALIMA ELBIAZE", "ABDOULAYE BANIR\u00c9 DIALLO", "MOHAMED SADIK"], "abstract": "Federated Learning (FL) has gained attention across various industries for its capability to train machine learning models without centralizing sensitive data. While this approach offers significant benefits such as privacy preservation and decreased communication overhead, it presents several challenges, including deployment complexity and interoperability issues, particularly in heterogeneous scenarios or resource-constrained environments. Over-the-air (OTA) FL was introduced to tackle these challenges by disseminating model updates without necessitating direct device-to-device connections or centralized servers. However, OTA-FL brought forth limitations associated with heightened energy consumption and network latency. In this paper, we propose a multi-attribute client selection framework employing the grey wolf optimizer (GWO) to strategically control the number of participants in each round and optimize the OTA-FL process while considering accuracy, energy, delay, reliability, and fairness constraints of participating devices. We evaluate the performance of our multi-attribute client selection approach in terms of model loss minimization, convergence time reduction, and energy efficiency. In our experimental evaluation, we assessed and compared the performance of our approach against the existing state-of-the-art methods. Our results demonstrate that the proposed GWO-based client selection outperforms these baselines across various metrics. Specifically, our approach achieves a notable reduction in model loss, accelerates convergence time, and enhances energy efficiency while maintaining high fairness and reliability indicators.", "sections": [{"title": "1 INTRODUCTION", "content": "Artificial intelligence (AI) can transform many aspects of human society. With applications spanning healthcare, education, finance, transportation, and beyond, Al's capacity to analyze extensive datasets, predict outcomes, and automate tasks stands poised to enhance efficiency, accuracy, and the overall quality of life. However, traditional machine learning (ML) in massive and sensitive environments faces several challenges caused by the nature of large-scale datasets, distributed data sources, and their constraints such as data privacy, limited resources, and network heterogeneity. To address these issues, federated learning (FL) is a promising approach to train ML algorithms where devices collaborate to create and improve a shared model while preserving users' privacy and reducing communication overhead [10, 19]. Instead of sending raw data to a central server for aggregation, each device maintains its dataset, trains a local model, sends model updates or gradients to the server that aggregates these updates, and then sends back the refined model to the individual devices. This process iterates until the global model reaches the desired accuracy. Over-the-air federated learning (OTA-FL) [39] is a specific implementation of FL that uses wireless communication channels for transmitting model updates which greatly reduces the cost of communicating model updates from the edge devices.\nImplementing OTA-FL in heterogeneous scenarios, where clients have different data distribution, limited bandwidth, and less reliable network conditions, faces several challenges including limited computing capabilities, data quality, and fairness between FL agents. Thus, the client selection step is crucial and the set of participants in each training round is a key factor in addressing these challenges and enhancing the learning process [4, 17]. By strategically choosing clients based on their data quality and computational capabilities, the FL system can effectively navigate through communication constraints, privacy concerns, and other challenges. Additionally, the client selection process is essential for ensuring the efficiency of model update distribution and the quality of the aggregated global model [22]. It ensures that the devices involved make valuable contributions to the shared learning, improving the overall effectiveness of FL algorithms. By carefully selecting which devices participate in the collaborative learning process, we can maximize the impact of each contribution, leading to better model performance and more reliable results."}, {"title": "2 BACKGROUND", "content": ""}, {"title": "2.1 Federated Learning", "content": "FL is designed to train models across a network of decentralized devices while keeping data private. Individual devices collaboratively create a shared model without the need to share their raw data with a central server (see Fig.1). The process involves the following steps:\n(1) Initialization: A central server generates an initial global model for the selected devices.\n(2) Local training: Each device trains a local model using its dataset, which is not transmitted to the central server.\n(3) Local model update: Each device produces a model update or gradient based on the differences between its local and global models.\n(4) Aggregation: The central server collects the updates from all participants and refines the global model through aggregation (e.g., averaging).\n(5) Global model update: The refined global model is then sent back to all participating devices.\n(6) Iteration: The process of local training, local model update, aggregation, and global model update is repeated over multiple iterations. As each iteration progresses, the overall model's performance improves.\nOTA-FL is a promising concept that allows clients to share the same spectral resources by transmitting their local model updates and aggregating these models over the air in a \"one-time\" manner. This enables the efficient sharing of model updates over the air without relying on traditional wired networks [44]. The benefits of the OTA-FL are:\n\u2022 Efficiency: OTA-FL can be more efficient in wireless environments, where wired connections might not be available or practical.\n\u2022 Scalability: It allows for the scalability of FL to a large number of devices, especially in settings where devices are mobile or have limited connectivity.\nWhile FL has significant advantages, it presents several challenges including communication overhead, resource constraints, and deployment complexity [36]. Therefore, client selection has been introduced as a strategy to limit the number of communicating parties at every process step."}, {"title": "2.2 Client selection", "content": "Client selection strategy involves determining which devices participate in each round of model training and contributing their updates to the central server to improve the FL quality and balance the need for privacy, data diversity, and model performance. However, randomly sampling clients in each training round may not fully exploit the local updates from"}, {"title": "2.3 Grey Wolf Optimizer", "content": "The GWO is a metaheuristic optimization algorithm inspired by the social behavior of grey wolves in nature. It was introduced in 2014 [23]. The algorithm simulates the grey wolves' leadership hierarchy and hunting mechanisms to solve optimization problems. The GWO is characterized by simulating the social hierarchy of a wolf pack with alpha, beta, delta, and omega wolves representing different solutions. It balances exploration and exploitation by assigning roles: the alpha wolf explores, while beta and delta wolves exploit. The omega wolf maintains diversity. Encouraging collaboration mimics real wolf pack cooperation, aiding in escaping local optima. Positions of wolves are iteratively updated based on movement equations inspired by hunting and social behaviors, contributing to the algorithm's convergence towards the global optimum in the search space. The basic steps of the GWO can be summarized as follows:\n(1) Initialization: Initialize a population of wolves, representing potential solutions to the optimization problem.\n(2) Objective function: Evaluate the objective function for each wolf in the population.\n(3) Update positions: Update the positions of wolves based on the movement equations inspired by wolf behavior.\n(4) Boundary handling: Ensure that the updated positions of wolves remain within the defined search space.\n(5) Selection: Update the alpha, beta, and delta wolves based on their fitness values.\n(6) Iteration: Repeat the process until a stopping criterion is met such as a maximum number of iterations or a desired level of convergence.\nThe GWO has been applied to various optimization problems in engineering, economics, and other fields [12, 20] due to its benefits, such as:\n\u2022 Global Search Capability: GWO exhibits a robust global search capability, making it well-suited for optimization tasks where finding a global optimum is crucial. This characteristic is particularly advantageous in complex problem spaces with multiple peaks.\n\u2022 Fast Convergence Rate: The algorithm is known for its fast convergence, allowing it to reach near-optimal solutions quickly. This is advantageous in scenarios where computational resources are limited, and rapid decision-making is required.\n\u2022 Ease of Implementation: GWO's simplicity facilitates straightforward implementation, making it accessible to practitioners with varying levels of expertise. The ease of implementation expedites the integration of GWO into diverse applications."}, {"title": "3 RELATED WORK AND OUR CONTRIBUTION", "content": "Recent advances in FL have focused on various aspects, including communication efficiency, privacy preservation, and robustness to adversarial attacks. However, the challenge of optimal client selection remains underexplored. Effective client selection is crucial for fast convergence, accurate models, fairness, and efficient communication. This section presents a literature review focused on optimizing client selection through various methods and highlights our contribution to this area."}, {"title": "3.1 Random Selection", "content": "This client selection method is achieved by randomly selecting a subset of clients to participate in the FL process. The work in [25] mitigates this problem and performs FL while actively managing clients based on their resource conditions by asking the randomly selected clients to send their resource information and participate in determining which of them go to complete the FL process. However, this approach presents several challenges such as building and maintaining client trust and ensuring high data quality. The random selection's implementation is simple but may lead to uneven data distribution and performance."}, {"title": "3.2 Learning-based Selection", "content": "Some papers implement client selection using ML techniques, where a central model predicts which clients provide high-quality updates. For instance, reinforcement learning is deployed to improve client selection performance by involving a reinforcement learning agent that learns a client selection policy [8]. The authors in [24] introduced a clustering-based client selection framework to decrease the communication costs for training FL models by reducing the number of training devices at every round and the number of rounds required to reach convergence. Another"}, {"title": "3.3 Heuristic Algorithm-based Selection", "content": "Some methods formulate the client selection strategy as a mathematical optimization problem. Then, clients are selected using mathematical methods such as the dynamic programming model in [42], where the authors proposed a framework to balance the trade-off between the energy consumption of the edge clients and the learning accuracy of FL. The authors in [2] proposed a predictive quality of service paradigm that allows devices to self-adjust their power allocation to maintain reliability and latency within the tolerated range of the URLLC application. In [41], the authors proposed a delay-constrained client selection framework for heterogeneous FL in intelligent transportation systems to improve the model performance such as accuracy, training, and transmission time. The multi-armed bandit (MAB) model is used in [14] to work for the hierarchical FL in MEC networks by estimating the participation probability for each client using the following information wireless channel state, local computing resources, and previous performance. The authors of [29] also formulated the client selection problem as an MAB problem to design a selection framework where the network operator learns the number of successful participating clients to improve the training performance as well as under the limited budget on each edge server. Contextual combinatorial MAB is used in [32] to formulate a client selection problem to boost volatile FL by speeding up model convergence, promoting model accuracy, and reducing energy consumption. The authors in [43] leveraged the MAB framework and the virtual queue technique in Lyapunov optimization to conduct client selection with a fairness guarantee in the asynchronous FL framework. In [15], it was found that fairness criteria play a critical role in the FL training process. A fairer client selection strategy can lead to higher final accuracy, though it may come at the cost of some training efficiency. Authors of [16] proposed a client selection method using a Genetic algorithm, which enables faster central model training at a lower cost based on the client's cost and the result of its local update. A dynamic and multicriteria scheme for client selection is developed in [6] to offer more volume and heterogeneity of data in the FL process using a genetic algorithm."}, {"title": "3.4 Our contributions", "content": ""}, {"title": "3.4.1 Multi-attribute client selection", "content": "Based on related works (See Table 1), certain selection methods choose the clients with the best performance or high resources. This approach results in clients with low-level resource capacity being unable to participate in the training process, and their datasets being ignored. This leads to biased and unfair selection, which ultimately results in an underfitting of the learned global model for those low-level clients. Moreover, some proposed methods suffer from some futility of the clients which train their local models and then the server does not aggregate them. This leads to a waste of client energy. While existing works have primarily focused on accuracy and cost criteria for client selection, it is imperative to take into account other attributes such as reliability, fairness, privacy preservation, and energy efficiency. By incorporating these additional dimensions, we can foster more"}, {"title": "3.4.2 Integration of GWO with client selection", "content": "Given the scalability and efficiency requirements of OTA-FL, the GWO holds significant promise for optimizing client selection strategies. By leveraging GWO's global search capability and fast convergence rate, we can design client selection algorithms that effectively balance exploration and exploitation. Additionally, GWO's ease of implementation makes it well-suited for deployment in distributed environments with resource-constrained devices. Furthermore, GWO's ability to maintain diversity in the population of wolves can address the challenge of heterogeneity among FL clients. By ensuring that the client selection process considers diverse attributes and characteristics of participating devices, we can enhance the performance and robustness of OTA-FL systems. As shown in Table 1, GWO has not been applied to optimize client selection to enhance FL model's accuracy, cost, energy efficiency, reliability, and fairness. This notable absence of GWO-based approaches in existing literature underscores a significant research gap and provides compelling motivation to explore its potential in this context. Our contributions are summarized below:\n\u2022 Offering a multi-attribute client selection framework that is noticed in the \"select then train\" method. It balances the accuracy with energy, delay, reliability, and fairness criteria to tackle the OTA-FL challenges such as security risks, limited computational capability, and unstable networks.\n\u2022 Adopting the grey wolf algorithm to choose the set of eligible clients to join the learning process.\n\u2022 Evaluating the proposed approach and analyzing the FL model performance in terms of accuracy, convergence time, and energy efficiency."}, {"title": "4 MULTI-ATTRIBUTE CLIENT SELECTION", "content": "We consider an FL framework consisting of a single base station and n clients $N = \\{1, 2, ..., n\\}$. Each client i possesses local data, denoted as $D_i$. For each communication round, the server aims to learn a global model with the data $D_i$ distributed across the selected clients.\nTo model the FL problem, we define the weight vector w to capture the parameters related to the global model. We introduce the loss function $l(w, x_j, y_j)$, which captures the FL performance over input vector $x_j$ and output $y_j$ for each $D_i$. The categorical cross-entropy is used as a loss function in performing the classification problem in our paper. The total loss function of client i writes [40]:\n$F_i(w) = \\frac{1}{D_i}\\sum_{j=1}^{D_i}l(w, x_j, y_j).$ (1)\nThe FL training problem can be formulated as follows:\n$\\min F(w) = \\sum_{i=1}^{n}F_i(w),$ (2)\nwhere $D = \\sum_{i=1}^{n}D_i$ is the total data samples of all clients."}, {"title": "4.1 Delay", "content": "To implement FL over wireless networks, wireless devices must train the model locally and transmit their results over wireless links. However, this computation and transmission introduce a delay that impacts the overall FL performance."}, {"title": "4.1.1 Computation Delay", "content": "The computation delay is determined by the type of learning models and the desired learning accuracy $e_i$, the computation time at user i needed for processing is [40]:\n$\\tau_i^c = \\frac{C_iD_i}{f_i}v_ilog_2(\\frac{1}{e_i})$ (3)\nwhere $v_ilog_2(1/{\\epsilon_i})$ is the number of local iterations required for client i to reach the desired accuracy $e_i$, $C_i$ (cycles/bit) is the number of CPU cycles required for computing one sample data at user i, and $f_i$ is the computation capacity of user i, which is measured by the number of CPU cycles per second."}, {"title": "4.1.2 Transmission Delay", "content": "After local computation, all users upload their local FL parameters to the server, the quality of the wireless channel is the primary factor that determines the transmission rate in each round that is given by:\n$r_i = b_ilog_2(1+ \\frac{g_ip_i}{No b_i}),$ (4)\nwhere $b_i$ represents the bandwidth allocated to user i, $p_i$ is the transmit power of user i, $g_i$ is the channel gain between user i and the BS, and $N_o$ is the power spectral density of the Gaussian noise.\nThe model size determines the transmission time between the client and server, expressed as M(w). The model transmission time is calculated using the following formula:\n$\\tau_i^t = \\frac{M(w)}{r_i}$ (5)"}, {"title": "4.2 Energy", "content": "Energy is a critical factor to consider when deploying FL, to implement energy-efficient ML algorithms, optimize communications, use low-power hardware accelerators, and develop energy-aware scheduling strategies. Balancing the benefits of FL with the energy constraints of participating devices is crucial for its widespread adoption and long-term sustainability. The energy consumption of each client i is the sum of the energy used to train the model on each client's device and the energy used to transmit the local model from the device to the server."}, {"title": "4.2.1 Computation Energy", "content": "The computing resources consumed by model training depend on the size of local data $D_i$, which is expressed as [7]:\n$e_i^c = l_ifi \\cdot \\tau_i^c f_i = l_if_i^2\\frac{C_iD_i}{f_i}v_ilog_2(\\frac{1}{Ei})$ (6)\nwhere $i$ is the energy consumption coefficient depending on the chip of each client i's device. Note that, since the server has a continuous power supply, we do not consider the energy consumption of the server in our problem."}, {"title": "4.2.2 Transmission Energy", "content": "The energy consumption of client i in model transmission is expressed as:\n$e_i^t = P_i t = P_i\\frac{M(w)}{r_i}$ (7)"}, {"title": "4.3 Reliability", "content": "Choosing clients capable of completing local training is a crucial maintenance metric to measure performance, safety, and equipment design, especially for critical or complex assets. The reliability of the client's device ensures the"}, {"title": "4.4 Fairness", "content": "During the FL process, the client selection method often prioritizes devices with low latency. However, this bias towards speed may not be fair to clients with high data quality, the local dataset which has a larger size and whose distribution is more similar to the global distribution plays a more important role, and the corresponding clients should participate in more communication rounds. Therefore, it is important to consider the fairness constraint to avoid an overabundance of relevant clients [33]. The fairness constraint is considered to \"tell\" each client how many communication rounds they should participate [38]. We introduce the following constraint on a minimum selection fraction for each client i [18]:\n$\\frac{1}{T}\\sum_{t=1}^{T} E[a_i(t)] \\geq c_i,$ (10)\nwhere $E[.] is the expectation operator and $c_i \\in (0, 1)$ is the minimum fraction of communication rounds required to choose client i. T is the total number of rounds and $a_i(t)$ is a binary variable defined as an indicator with $a_i(t) = 1$ indicating that client i is selected in round t, and $a_i(t) = 0$ otherwise."}, {"title": "4.5 Problem Formulation", "content": "Our approach involves a \"select then train\" client selection method where the server invites clients who meet the constraints of accuracy, energy, delay, reliability, and fairness to participate in the FL algorithm. We formulate our problem whose goal is to minimize the loss function of an FL algorithm by optimizing the various wireless parameters, as follows:\n$\\min F(w) = \\frac{1}{D}\\sum_{i=1}^n \\sum_{j=1}^{D_i}l(w, x_{ji}, y_{ji})$ (11)\ns.t. $\\tau_i^c + \\tau_i^t \\leq \\tau_i^r,$ $ \\forall i \\in N$ (11a)\n$0 < e_i^c + e_i^t \\leq e_i^r,$ $\\forall i \\in N$ (11b)\n$p_i(t) \\geq p,$ $ \\forall i \\in N$ (11c)\n$\\frac{1}{T}\\sum_{t=1}^{T}E[a_i(t)] = c_i$ $\\forall i \\in N$ (11d)\n$\\{min} \\leq \\epsilon_i \\leq 1$ $ \\forall i \\in N$ (11e)\n$0 \\leq f_i \\leq f_i^{max}$ $ \\forall i \\in N$ (11f)\n$0 \\leq P_i \\leq P^{max}$ $ \\forall i \\in N$ (11g)\n$\\sum_{i=1}^{n} b_i \\leq B$ $ \\forall i \\in N$ (11h)\n$0 \\leq c_i \\leq 1$ $ \\forall i \\in N$ (11i)\nwhere yr is the maximum delay to join the FL system, YE is the energy consumption of the FL algorithm, YR is the minimum reliability needed to participate to the FL process.\nConstraint (11a) indicates that the execution time of the local tasks and transmission time for all clients should not exceed the maximum completion time for the whole FL algorithm. (11b) is the energy consumption constraint to perform the learning task. Constraint (11c) is the client's device reliability condition for joining the FL algorithm. Constraint (11d) is the fairness constraint to participate in the FL algorithm. The local accuracy constraint is given by (11e). Constraints (11f) and (11g) respectively represent the maximum local computation capacity and average transmit power limits of all clients. Due to the limited bandwidth of the system, we have (11h), where B is the total bandwidth. Constraint (11i) is the fraction of communication rounds required to ensure a fair selection."}, {"title": "5 GREY WOLF OPTIMIZER-BASED CLIENT SELECTION", "content": ""}, {"title": "5.1 Federated Learning Algorithm", "content": "Our FL system is depicted in the pseudo-algorithm 1. It is divided into two pieces, one executed by the server and the other by the clients. The server first initializes the global model parameters with random values. The server coordinates different rounds of execution. At each round, the server selects the set of clients using Algorithm 2 and, in parallel, sends a copy of the training model. To fine-tune the copy of the training model, each client performs a series of gradient descent steps using its data. After training, each client sends back the weights and biases of the local model to the server. The server aggregates the updates from all clients and starts a new round."}, {"title": "5.2 Client Selection Algorithm", "content": "The GWO is a metaheuristic algorithm inspired by the social hierarchy and hunting behaviors of grey wolves in nature. It leverages these natural processes to efficiently search for optimal solutions in complex optimization problems due to the advantages of fewer parameters, simple principles, and implementation [23]. In this work, we employ the grey wolf model for Optimizing the client selection problem (Eq. 11), wherein the wolf is represented as the set of clients that are eligible to join the learning process (See Fig.2).\nLet's assume that there are S solutions (sets of clients) in the search space, GWO classifies these solutions based on the objective function (Eq.11) for four categories as follows: the best solution is alpha (\u03b1), the second-best is beta (\u03b2), the third-best delta (\u03b4) and the rest solutions are omega (w). The best three solutions (\u03b1, \u03b2, \u03b4) are used to guide the other solutions (w) for improving the search space. During the optimization, there are three main phases of hunting behavior: Encircling, hunting, and attacking which will be detailed later."}, {"title": "5.2.1 Encircling Phase", "content": "The grey wolves start hunting by creating a circle around the prey. The mathematical model of the encircling phase is developed using the following equations:\n$X(t + 1) = X_p (t) \u2013 A \\times d.$ (12)"}, {"title": "5.2.2 Hunting Phase", "content": "During the hunting phase, the three most promising solutions denoted by (\u03b1, \u03b2, \u03b4) are obtained. As for the other research agents (w), they need to update their positions by moving towards the average of the three best-known positions since they have better knowledge about the optimal location of the prey. In this regard, the following equations have been presented with i \u2208 {\u03b1, \u03b2, \u03b4}:\n$X_i(t + 1) = X_i(t) \u2013 a_i \\times d_i,$ (17)\nwhere $d_i$ is estimated using the following:\n$d_i = |C_i \\times X_i(t) \u2013 X(t)|.$ (18)\nLet pi be the positive weight associated with wolf i \u2208 {\u03b1, \u03b2, \u03b4} such that $\\sum p_i = 1$. Given the positions of wolves \u03b1, \u03b2, and \u03b4, a good estimation of the average position of the optimal solution at round t is given by:\n$X(t+1) = \\sum_{i \\in \\{\\alpha,\\beta,\\delta\\}} p_i \\cdot X_i(t + 1).$ (19)"}, {"title": "5.2.3 Attacking Phase", "content": "GWO finishes hunting by attacking the prey when it stops moving, to model approaching the prey we use Eq. (16) as the parameter a is responsible for making the balance between exploration and exploitation, the value of a linearly decreased from 2 to 0 over iterations, consequently, the parameter A takes a random value in the interval [-2a, 2a] given by Eq. (14). The wolves take a random position when A > 1 or A < -1 and are forced to move towards the prey when -1 \u2264 A \u2264 1.\nThe multi-attribute client selection is provided in Algorithm.2. First, the GWO parameters are initialized by the base station by randomly setting the positions of wolves within the defined problem bounds, ensuring diversity in the initial population. The $X_a$, $X_\\beta$, and $X_\\delta$ wolves, representing the best solutions found, are initially set to zero vectors and updated as the algorithm progresses. The coefficient a decreases linearly from 2 to 0 over the iterations, balancing exploration and exploitation. A and C used in the position update formulas are derived from a and random values r1 and r2. Second, the GWO calculates the score of the best clients based on the lowest loss value, lowest computation and transmission delay, lowest energy consumption, highest reliability, and fairness. The best score value is sent to the BS from each set of clients. The algorithm tracks the best positions for the $X_a$, $X_\\beta$, and $X_\\delta$ wolves based on their fitness, updating these whenever a better solution is discovered. We set maxitr to 50, consistent with common practice in the"}, {"title": "6 EXPERIMENTAL INVESTIGATION", "content": "To assess the effectiveness of the proposed multi-attribute client selection algorithm for FL systems, we conducted experiments to analyze the performance of the global model and investigate the effects of delay, energy consumption, reliability, and fairness constraints. In this section, We offer a comparative analysis between our solution and several existing methods, including dynamic programming, multi-armed bandit, and genetic algorithms. Our evaluation will be based on various datasets including MNIST, CIFAR-10 and Fashion MNIST, considering test loss, test accuracy, energy consumption, training time, reliability, and fairness as key metrics."}, {"title": "6.1 Experimental setup", "content": "Under our problem formulation, the \"select then train\" method is effectively implemented using client metadata and historical performance data. Although the objective function is dependent on the model parameters and local datasets, the selection process leverages surrogate metrics derived from client profiles, which include computational capabilities, data size, and distribution summaries. These profiles are updated periodically and shared with the server, allowing it to make informed decisions without direct access to the local data. We implement our FL model using the following datasets:\n\u2022 MNIST, comprising 60,000 28 x 28 images of handwritten digits from 0 to 9.\n\u2022 CIFAR-10, which includes 60,000 32 x 32 color images in 10 classes, with 6,000 images per class.\n\u2022 Fashion MNIST, consisting of 70,000 28 x 28 grayscale images of 10 different categories of clothing items.\nThese datasets are distributed among 50 clients to train the FL model, and each client possesses unique hardware parameters, metadata, and statistics. This includes information such as data size, historical performance, device"}, {"title": "6.2 Comparison Scheme", "content": "In our previous work [9], we compared random client selection, loss-aware client selection, and our multi-attribute client selection using the MNIST dataset. This comparison demonstrated the effectiveness of our multi-attribute method in achieving superior performance metrics compared to simpler client selection techniques. The experimental results indicate that the proposed multi-attribute client selection can reduce energy consumption by up to 43% compared to the random client selection method. Additionally, our multi-attribute method outperforms the loss-aware method in terms of time reduction, computational efficiency, and energy consumption. These ablation experiments demonstrate that a comprehensive approach considering various attributes for client selection such as delay, energy, fairness, and reliability is more effective for FL systems.\nTo further validate our approach, we conduct experiments on larger datasets with a larger number of clients. We compare the proposed solution with the following approaches:\n\u2022 Dynamic programming (DP): is a classic algorithm to solve the knapsack problem, an optimization problem that involves selecting a subset of items from a given set, each with a weight and a value. The objective is to maximize the total value of the chosen items while ensuring that the cumulative weight does not surpass a specified capacity [3].\n\u2022 Genetic algorithm (GA): is an evolutionary optimization technique inspired by the process of selection and genetics. It mimics natural evolution, where individuals with higher fitness are more likely to survive and reproduce, leading to the emergence of better solutions over generations [34].\n\u2022 Multi-armed bandit (MAB): is a classic problem in probability theory and decision-making, often used in the context of optimization and resource allocation. The name originates from the idea of a gambler facing multiple slot machines (the \"bandits\"), each with potentially different payoff probabilities, and need to decide which machine to play to maximize their total reward over time [5]. We implemented the upper confidence bound (UCB) algorithm, which is designed to address this trade-off by selecting options based on a combination of their average rewards and the uncertainty or confidence interval around those rewards. The UCB algorithm"}, {"title": "6.3 Experimental Results", "content": "To demonstrate the efficiency of our client selection approach in OTA-FL, we analyze the FL model using the MNIST, CIFAR10, and Fashion MNIST classification problems. This analysis aimed to evaluate various performance metrics, including the global model accuracy, loss probability, convergence time, energy consumption, energy efficiency, reliability, and fairness. Furthermore, we conducted a comparative assessment, juxtaposing the outcomes of our multi-attribute client selection employing GWO against those of other established methods, such as dynamic programming, multi-armed bandit, and genetic algorithms."}, {"title": "6.4 System scalability", "content": "To analyze the scalability of our multi-attribute client selection using the GWO, we evaluate performance metrics with varying numbers of clients. As the number of clients increases, accuracy improves (Fig.3), indicating that the model benefits from learning from a more diverse set of client data, which enhances generalization. This improvement demonstrates that more clients contribute valuable and varied data, leading to a better-performing model. The energy efficiency shows significant improvement to indicate that while more clients require more resources, the utilization of these resources becomes more effective (Fig.6). However, convergence time rises significantly with more clients (Fig.5). This increase is primarily due to the additional communication overhead and computational complexity associated with aggregating updates from a larger number of clients. Furthermore, the reliability and fairness of the model improve with the addition of more clients demonstrating that a larger number of clients leads to a more stable and equitable distribution of resources and benefits. In summary, scaling up the number of clients enhances model accuracy, energy efficiency, reliability, and fairness at the price of increased complexity. In our daily lives, most applications require acceptable accuracy which may need a low-average number of clients keeping the complexity at acceptable levels."}, {"title": "6.5 Discussion & Insights", "content": "By leveraging the multi-attribute client selection using GWO, we aim to optimize the process of choosing clients based on multiple attributes crucial to the success of OTA-FL. One key aspect is the ability of our solution to enhance the selection of participants based on their proficiency in providing informative updates. In OTA-FL, the quality of model updates plays a pivotal role in the overall learning process. Clients capable of contributing insightful and relevant updates contribute significantly to the effectiveness and generalization of the global model (see Table 4). The GWO-based approach helps us identify and prioritize clients with a higher potential for delivering informative contributions, thereby enriching the learning experience. Moreover, the GWO assists in striking a balance between the informative updates and the associated communication costs.\nTable 8 shows that each multi-attribute client selection method balances exploration and exploitation differently to optimize performance. The MAB-based method focuses on exploring various client combinations while favoring those with higher expected rewards, with computational complexity scaling logarithmically with the number of selected clients (num_clients). GA-based selection emphasizes diversity and refinement of promising solutions through crossover and mutation, exhibiting linear complexity with selected clients and communication rounds. The DP-based selection primarily exploits the best client combination within resource constraints, its complexity tied to the required energy consumption dimensionality (E_dim). At the same time, the GWO-based method combines exploration and exploitation by iteratively refining client selections, with a complexity similar to the GA-based method.\nAnalyzing the robustness of our multi-attribute client selection approach to factors such as noise, outliers, and changes in network conditions provides valuable insights into its reliability and resilience in real-world scenarios. Noise in client data, arising from measurement errors or inconsistencies, can potentially impact the performance of client selection algorithms by introducing inaccuracies or biases. For future work, we aim to evaluate the ability of this approach to handle noisy data effectively, either by incorporating noise-reduction techniques or by adapting selection criteria to account for variability in data quality."}, {"title": "7 CONCLUSION", "content": "We proposed a multi-attribute client selection framework utilizing the GWO to strategically manage the number of participants in each round and"}]}