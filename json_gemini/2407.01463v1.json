{"title": "Retrieval-augmented generation in multilingual settings", "authors": ["Nadezhda Chirkova", "David Rau", "Herv\u00e9 D\u00e9jean", "Thibault Formal", "St\u00e9phane Clinchant", "Vassilina Nikoulina"], "abstract": "Retrieval-augmented generation (RAG) has recently emerged as a promising solution for incorporating\nup-to-date or domain-specific knowledge into large language models (LLMs) and improving LLM\nfactuality, but is predominantly studied in English-only settings. In this work, we consider RAG in the\nmultilingual setting (mRAG), i.e. with user queries and the datastore in 13 languages, and investigate\nwhich components and with which adjustments are needed to build a well-performing mRAG pipeline,\nthat can be used as a strong baseline in future works. Our findings highlight that despite the availability\nof high-quality off-the-shelf multilingual retrievers and generators, task-specific prompt engineering is\nneeded to enable generation in user languages. Moreover, current evaluation metrics need adjustments\nfor multilingual setting, to account for variations in spelling named entities. The main limitations to be\naddressed in future works include frequent code-switching in non-Latin alphabet languages, occasional\nfluency errors, wrong reading of the provided documents, or irrelevant retrieval. We release the code\nfor the resulting mRAG baseline pipeline at https://github.com/naver/bergen\u00b9.", "sections": [{"title": "1. Introduction", "content": "Retrieval-augmented generation (RAG) (Lewis et al.,\n2020; Ram et al., 2023, inter alia) has recently emerged\nas a promising solution for incorporating up-to-date or\ndomain-specific knowledge into large language mod-\nels (LLMs) and improving LLM factuality, especially in\nknowledge-intensive tasks such as open-domain ques-\ntion answering or fact-checking. RAG augments user\nqueries with relevant context retrieved from the Inter-\nnet or a given collection and then passes the result to\nan LLM to generate a knowledge-grounded response.\nRecent works focus on improving various components\nof the complex RAG pipeline, e.g. generator (Yoran\net al., 2024) or search query processor (Ma et al., 2023),\nas well as addressing fragility of the RAG approach,\ne.g. filtering irrelevant retrieved context (Wang et al.,\n2023; Xu et al., 2023; Kim et al., 2024) or dynamically\ndeciding for which user queries retrieval is actually\nneeded (Jiang et al., 2023; Asai et al., 2024).\nUnfortunately, all listed efforts are focusing on English\nas the data language in their experiments, i.e. the lan-"}, {"title": "2. Related Work", "content": "Despite mRAG being not well studied in the literature,\nsome of the individual components of the RAG pipeline\nwere rather well developed for multilingual settings,\ne.g. multilingual retrievers and generator LLMs; we\ndiscuss them in Section 3.\nThe closest line of work to ours is multilingual open\nquestion answering (Asai et al., 2021b; Muller et al.,\n2022; Sorokin et al., 2022; Asai et al., 2022, inter alia)\ndefined as a the task of answering non-English ques-\ntions from a large collection of multilingual documents,\nas introduced in (Asai et al., 2021b). Those aforemen-\ntioned works train task-specific models combining cross-\nlingual retrievers and multilingual generation models,\ne.g. with iterative extension of annotated data used\nin the CORA approach (Asai et al., 2021b). The key\ndifference of our work is that we compose the mRAG\nsystem in a zero-shot manner, using off-the-shelf com-\nponents without dedicated training. This approach,\ndominating nowadays in the literature, is enabled by"}, {"title": "3. Multilingual RAG pipeline", "content": "The high-level illustration of the mRAG pipeline is pre-\nsented in Figure 1. The input is represented by a user\nquery q in language Lq. This could be an arbitrary user\nrequest to an LLM. Following the common practice of\ntesting RAG systems on open-domain question answer-\ning, we assume q is an information-seeking question.\nThe model is expected to output response r which cor-\nrectly answers the given question. An important (and\nreasonable) expectation is that the model replies in the\nuser language, i.e. r is written in Lq.\nStep 1: retrieval. The first step in mRAG is retrieving\ncontext c relevant to the query q from the Internet or\na particular collection C, using the retriever system R:\nc = R(\u1fb7, C), q = Q(q). Here Q denotes an optional query\ngeneration model which infers a search query \u1fb7 from\na user query c, e.g. it can be an LLM prompted to\nreformulate the query, or simply copying the user query\nq. Following a standard practice in testing RAG systems,\nwe use Wikipedia as our collection C. In most of the\nexperiments we assume monolingual C in language Lc\n(English or user language), but we also experiment with"}, {"title": "4. Experimental details", "content": "Retrieval. We follow Asai et al. (2021b) and\n(Karpukhin et al., 2020) and construct passages by"}, {"title": "5. Results and discussion", "content": "Table 1 summarizes the results across different lan-\nguages on MKQA and XOR TyDi QA datasets. We ob-\nserve a high performance improvement brought by RAG\nfor all languages, but in many cases there is an impor-\ntant gap in performance in English and non-English.\nIn what follows we present multiple ablation studies\nto demonstrate steps needed to achieve shown results,\nto better understand the reasons behind the gap with\nEnglish, and identify future research directions. We\nstudy the effect of the system prompt, generator model,\nretrieval system and language. We run ablations on\nthree languages: French, Korean, and Russian."}, {"title": "6. Conclusion", "content": "In this work we study RAG in multilingual settings and\nbuild a strong pipeline to be used as a baseline in future\nworks. Better understanding of mRAG would enable\nreliable information access across different languages\nand cultures. We analyze an impact of each mRAG\ncomponent impact on overall performance and provide\nguidelines and future research direction to further im-\nprove it.\nPossible research directions include:\n\u2022 The need for stronger multilingual LLMs and decod-\ning strategies. Our study highlights multilingual\ngeneration as a weakest part of the mRAG pipeline,\nespecially with mixed-language context. We show\nthat even strongest available multilingual LLMs can\nget distracted by the language of the prompt, and\nrequire ad-hoc prompting to enable consistent gen-\neration in the user language. Even then, they are\nstill prone to code-switching especially when writ-\ning named entities. We believe listed limitations\ncould be addressed by including mixed-language\nexamples in instruction tuning or by developing\nspecific decoding strategies.\n\u2022 LLM-based evaluation in multilingual settings. In\nour work we rely on the lexical matching-based\nmetrics due to their transparency and interpretabil-\nity. At the same time, recent works use LLM-based\nevaluation which captures better semantic similar-\nities but is currently underexplored in multilingual\nsettings.\n\u2022 Multi-domain multilingual retrieval. Current multi-\nlingual retrievers and rerankers are predominantly\ntrained on Wikipedia-based data which could limit\ntheir applicability to other domains.\nLimitations\nFollowing common practice in RAG and as a first step in\nmRAG, we run evaluation on the open question answer-"}, {"title": "Ethics Statement", "content": "We do not anticipate negative societal impact from our\nwork and on the reverse hope that it will help to broaden\nthe accessibility of modern NLP to other languages."}, {"title": "A. Additional related works", "content": "Lorem ipsum dolor sit amet, consectetuer adipiscing\nelit. Ut purus elit, vestibulum ut, placerat ac, adipiscing\nvitae, felis. Curabitur dictum gravida mauris. Nam arcu\nlibero, nonummy eget, consectetuer id, vulputate a,\nmagna. Donec vehicula augue eu neque. Pellentesque\nhabitant morbi tristique senectus et netus et malesuada\nfames ac turpis egestas. Mauris ut leo. Cras viverra\nmetus rhoncus sem. Nulla et lectus vestibulum urna\nfringilla ultrices. Phasellus eu tellus sit amet tortor gra-\nvida placerat. Integer sapien est, iaculis in, pretium\nquis, viverra ac, nunc. Praesent eget sem vel leo ul-\ntrices bibendum. Aenean faucibus. Morbi dolor nulla,\nmalesuada eu, pulvinar at, mollis ac, nulla. Curabitur\nauctor semper nulla. Donec varius orci eget risus. Duis\nnibh mi, congue eu, accumsan eleifend, sagittis quis,\ndiam. Duis eget orci sit amet orci dignissim rutrum.\nNam dui ligula, fringilla a, euismod sodales, sollicitudin\nvel, wisi. Morbi auctor lorem non justo. Nam lacus\nlibero, pretium at, lobortis vitae, ultricies et, tellus.\nDonec aliquet, tortor sed accumsan bibendum, erat\nligula aliquet magna, vitae ornare odio metus a mi.\nMorbi ac orci et nisl hendrerit mollis. Suspendisse ut\nmassa. Cras nec ante. Pellentesque a nulla. Cum sociis\nnatoque penatibus et magnis dis parturient montes,\nnascetur ridiculus mus. Aliquam tincidunt urna. Nulla\nullamcorper vestibulum turpis. Pellentesque cursus\nluctus mauris.\nNulla malesuada porttitor diam. Donec felis erat, con-\ngue non, volutpat at, tincidunt tristique, libero. Vivamus\nviverra fermentum felis. Donec nonummy pellentesque\nante. Phasellus adipiscing semper elit. Proin fermen-\ntum massa ac quam. Sed diam turpis, molestie vitae,\nplacerat a, molestie nec, leo. Maecenas lacinia. Nam\nipsum ligula, eleifend at, accumsan nec, suscipit a, ip-\nsum. Morbi blandit ligula feugiat magna. Nunc eleifend\nconsequat lorem. Sed lacinia nulla vitae enim. Pellen-\ntesque tincidunt purus vel magna. Integer non enim.\nPraesent euismod nunc eu purus. Donec bibendum\nquam in tellus. Nullam cursus pulvinar lectus. Do-\nnec et mi. Nam vulputate metus eu enim. Vestibulum\npellentesque felis eu massa.\nQuisque ullamcorper placerat ipsum. Cras nibh. Morbi\nvel justo vitae lacus tincidunt ultrices. Lorem ipsum\ndolor sit amet, consectetuer adipiscing elit. In hac habi-\ntasse platea dictumst. Integer tempus convallis augue.\nEtiam facilisis. Nunc elementum fermentum wisi. Ae-\nnean placerat. Ut imperdiet, enim sed gravida sollicitu-\ndin, felis odio placerat quam, ac pulvinar elit purus eget\nenim. Nunc vitae tortor. Proin tempus nibh sit amet\nnisl. Vivamus quis tortor vitae risus porta vehicula.\nFusce mauris. Vestibulum luctus nibh at lectus. Sed\nbibendum, nulla a faucibus semper, leo velit ultricies\ntellus, ac venenatis arcu wisi vel nisl. Vestibulum diam."}]}