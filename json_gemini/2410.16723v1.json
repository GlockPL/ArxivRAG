{"title": "Resource-Efficient Sensor Fusion via System-Wide Dynamic Gated Neural Networks", "authors": ["C. Singhal", "Y. Wu", "F. Malandrino", "S. Ladron de Guevara Contreras", "M. Levorato", "C. F. Chiasserini"], "abstract": "Mobile systems will have to support multiple AI-based applications, each leveraging heterogeneous data sources through DNN architectures collaboratively executed within the network. To minimize the cost of the AI inference task subject to requirements on latency, quality, and crucially - reliability of the inference process, it is vital to optimize (i) the set of sensors/data sources and (ii) the DNN architecture, (iii) the network nodes executing sections of the DNN, and (iv) the resources to use. To this end, we leverage dynamic gated neural networks with branches, and propose a novel algorithmic strategy called Quantile-constrained Inference (QIC), based upon quantile-Constrained policy optimization. QIC makes joint, high-quality, swift decisions on all the above aspects of the system, with the aim to minimize inference energy cost. We remark that this is the first contribution connecting gated dynamic DNNs with infrastructure-level decision making. We evaluate QIC using a dynamic gated DNN with stems and branches for optimal sensor fusion and inference, trained on the RADIATE dataset offering Radar, LiDAR, and Camera data, and real-world wireless measurements. Our results confirm that QIC matches the optimum and outperforms its alternatives by over 80%.", "sections": [{"title": "I. INTRODUCTION", "content": "Several emerging mobile applications are powered by artificial intelligence (AI) algorithms, often processing and fusing the data produced by multiple sensors and data sources. Many of such algorithms take the form of deep neural networks (DNNs). An intriguing class of neural architectures include branches, also known as early exits [1]. These architectures are dynamic, as the execution adapts to the characteristics of the input: the branches are sequentially executed until a satisfactory output is produced. The state of the art in neural networks evolved past early exits, and recently models with more structured and complex adapt- ability were developed. Specifically, these models are articulated into sections, connected by neural structures called gates. The gates directly control the internal routing of information based on optimal execution strategies learned during training [2]. In their simplest form, gates pre-select a full model, or a set of models in mixture of experts settings, based on simple features of the input. In more complex instances, such as that in [3] and the one considered in this paper, gated models are crafted as the composition of stems extracting features from a diverse set of sensors, and branches that process these intermediate features to produce a final output. The gates, then, control the activation of the stems, and the way features referring to different input sensors are fused and analyzed, and, in the model developed in this paper, the modality of sensor fusion. This class of models, whose design and training are highly non-trivial, perform a dynamic and context-aware form of sensor fusion.\nCurrent literature develops and analyzes these models in isolation, and considering execution on a single device. In contrast, this paper represents the first contribution considering dynamic gated models in the context of layered computing/communication infrastructures \u2013 i.e., those composed of interconnected mobile nodes and edge servers. In such setting, these architectures represent a significant opportunity, as they enable a flexible and efficient allocation of computing and communication load across different layers of the system. Importantly, as the gates control the structure of the neural network model and the use of data sources (that is, the combination of stems and branches mapping the input to the output) in response to input characteristics, the whole resource allocation strategy becomes context and input aware. We, thus, define the gates as connected to an infrastructure-level orchestrator that directly controls the activation of the DNN sections, and the resources on which they will be executed. That is, the model can be split at the gates and executed on different system resources (mobile nodes and edge server). Such characteristics and interplay between the inner neural network structure and the operations of the infrastructure becomes especially important when considering multiple applications \u2013 each with different accuracy and latency requirements \u2013 coexisting on the same resources.\nThe use of such architectures therefore results in (potentially) effective data analysis, improved efficiency, and lower costs. At the same time, achieving these results requires swift, high-quality, and joint decisions about such diverse aspects as: 1) the data sources to leverage for each application; 2) the DNN sections (i.e., stems and branches) to use; 3) the network nodes where stems and branches shall run; 4) the computation and communication resources to devote to each application and at each node. All these decisions have to be made with the goal of minimizing the cost (e.g., energy) of inference, subject to inference quality (e.g., accuracy) and latency requirements. We remark that each data source is connected to a different stem of the DNN, which produces features that are then processed by a branch tailored to the quantity and type of the data the source produces (e.g., 2D or 3D images), to generate the final inference output. Also, importantly, we do not express inference quality requirements in terms of average/expected values (e.g., the expected accuracy), but rather in terms of a target quantile thereof (e.g., the 90th percentile of accuracy). On the one hand, this reflects the time- and performance-critical nature of many modern applications, which need to make correct decisions with"}, {"title": "II. RELATED WORK", "content": "Dynamic DNNs have gained popularity for adding flexibility to inference processes and enhancing both the accuracy and efficiency of deep learning-based object detection and image classification [4], [5]. However, prior work has considered input data from only one source or the fixed deployment on a single computing node. In our work, we explore the use of multiple data sources and the dynamic deployment of the stem-branch architecture across the network nodes in an energy- efficient manner.\nInference of DNNs using collaborative mobile device-cloud computation has been modeled in [6] using a directed acyclic graph. However, [6] does not consider the dynamic variation of system parameters, multiple input sources, the stem-branch architecture, or the reliability of the inference process. While [3] delves into sensor fusion, it predominantly focuses on the training phase, neglecting the inference stage. On the other hand, [7] investigates energy-efficient inference processes but does so by selecting all available inputs, resulting in suboptimal energy utilization. Energy is instead considered in [8], which develops a framework to deploy DNNs with early-exits in distributed networks.\nAs for graph-based modeling of real applications, the dynamic graph model-based optimization [9] has been used,e.g., for wire- less vehicular networks [10]. However, dynamic graph modeling for real-time applications requires multi-constrained temporal path discovery. In [11], this has been solved using adaptive Monte Carlo Tree Search algorithm, MCTP. In our work, we compare the performance of our proposed framework to this state-of-the-art algorithm."}, {"title": "III. SYSTEM SCENARIO", "content": "This section first introduces the system scenario we consider by characterizing the data sources and the mobile-edge contin- uum nodes, as well as their interaction. Then it describes the dynamic gated DNN model that we developed and that we take as reference neural network model for our study.\nWe consider a network system consisting of data sources (Camera (Left/Right), Radar, LiDAR), mobile devices, and edge servers. As discussed in detail later in the paper, the notion of context is instrumental for the overall optimization, and the DNN configuration is greatly influenced by environmental conditions. Each mobile device is associated with an environmental context (e.g., Sunny, Motorway, and Night), which, as discussed later, drives performance given the configuration. Intelligent applications (denoted in Fig. 1(a) using different arrow colors) require the inference task to be performed with the required level of performance guarantees (latency and accuracy). In the example scenario, Application 1 (black arrows) uses Camera (L- R) input on a mobile node in a Sunny context and the dynamic DNN for this application is deployed on the mobile node and the edge server (ES). Application 2 (blue arrows) uses LiDAR input and the dynamic DNN is deployed on the mobile node with the Motorway context and on the ES. The same ES is used to deploy both Applications 1 and 2. Application 3 (green arrows) uses Radar input and the DNN model is deployed on the mobile node with Night context and on a different ES.\nThe devices acting as data sources, the mobile nodes, and the ESs are connected over a wireless network (i.e., data sources could be either co-located with mobile nodes or connected to them). The communication resources of the network and the computation resources of the mobile nodes and ESs are shared for executing the inference tasks using the dynamic deployment of a pre-trained dynamic DNN model. To effectively"}, {"title": "B. Dynamic DNN model", "content": "One of the core contributions of this paper is accounting for the deep interplay between innovative dynamic neural models and the resource allocation strategy of the collaborative edge computing system described previously. In this section, we present the instance of dynamic gated neural network model that we developed. At a high level, the architecture performs dynamic, adaptive and context-aware sensor fusion on Camera, LiDAR, and Radar data for object detection. Fig. 2 summarizes the structure of the model. Our model architecture adopts and extends the HydraFusion framework [3], introducing a scalable design to accommodate the varying computational demands of the applications to be supported via our gated mechanism. We remark how the adaptation of the ability of the model to change the computing workload is instrumental to integrate the models in a system-wide resource allocation framework.\nAs illustrated in Fig. 2, a gate module controls the acti- vation of the stems, determining how features from different input sensors are fused and analyzed. Contrary to the gating mechanism employed in [3], which selects branches during the training phase to enhance accuracy, our study implements the gating mechanism during the inference phase, in order to optimize the tradeoff between output accuracy, energy expense, and latency given the current context.\nOur neural model architecture processes input data from vari- ous modalities to facilitate object detection. We integrate ResNet- 18/50/101 [12], our base architecture, within a faster Recursive- Convolutional Neural Network (R-CNN). Specifically, initial sensor data from various modalities are analyzed by distinct CNNs, referred to as \"stems\". These stems, serving as feature extractors, are specialized to process the respective sensor inputs, transforming them into initial sets of features. These stems correspond to the first block of the ResNet architecture. An early fusion mechanism concatenates the features from each stem, resulting in three augmented stems that enhance context-specific accuracy. A 2D convolution layer merges these concatenated features, which are inputs to the subsequent ResNet layers, termed \"branches\".\nThe architecture consists of single-sensor branches as Left Camera, Right Camera, LiDAR, and Radar, alongside early fusion branches combining Left and Right Cameras, LiDAR and Radar, and Left Camera and LiDAR. This configuration results in 6 branches, each presenting 3 levels of complexity aligned with the ResNet 18/50/101 models, resulting in a total of 18 selectable branches. A second gate module then determines the most suitable branch or branches for the task.\nFurthermore, we integrate late fusion as a post-processing step exclusively for the (less complex) ResNet18 branches, con- strained by computational efficiency. We applied Non-Maximum Suppression (NMS) as our late fusion mechanism to the outputs from the ResNet-18 branches to balance deployment efficiency. Indeed, empirical evidence from our pre-trained models indicates that late fusion improves accuracy. However, it necessitates the complete deployment of multiple branches, which escalates energy consumption. Consequently, our gating mechanism con- sistently avoids selecting late fusion for ResNet-50 and ResNet- 101 branches.\nFig. 2 illustrates the decision process, highlighted by bold arrows, starting from the selection of data sources, leading to the choice of early fusion branches of a specific complexity level, excluding late fusion. Dashed lines represent potential, yet unselected, pathways available to the gating module.\nWe remark how different configurations of the gates result in a different computing load associated with stems and branches, as well as a different data flow input-to-stems and stems- to-branches. Further, this interrelation heavily depends on the"}, {"title": "IV. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "We represent the above system scenario by defining a set of network nodes, $\\mathcal{N}=\\{\\mathcal{N}^d \\cup \\mathcal{N}^m \\cup \\mathcal{N}^e\\}$, including: 1) data sources (hence, data modes) in $\\mathcal{N}^d$; 2) mobile nodes (which can host either only the stems or the stems along with the branches of the DNN model) in $\\mathcal{N}^m$; 3) edge servers (ESs) (which can host either only the branches or the stems along with the branches of the DNN model), in $\\mathcal{N}^e$. $\\mathcal{N}=\\left|\\mathcal{N}\\right|$, $\\mathcal{N}^d$, $\\mathcal{N}^m$, and $\\mathcal{N}^e$ denote (resp.) the number of all nodes, sources, mobile nodes, and edge servers.\nFor each node $n \\in \\mathcal{N}^d \\cup \\mathcal{N}^m$, the amount of (uplink) commu- nication resources at its disposal, e.g., the number of resource blocks a mobile node can use to communicate with the edge servers, is denoted with $B_n$. Similarly, $C_n$ denotes the amount of computational (e.g., CPU or GPU) resources (in number of executable instructions/s) available at node $n \\in \\mathcal{N}^m \\cup \\mathcal{N}^e$, which can be used for sensor fusion and inference.\nApplications are denoted by elements $h \\in \\mathcal{H}$, and are associated with a maximum latency requirement $l_h^{\\text{max}}$ and a minimum accuracy requirement $\\alpha_h^{\\text{min}}$, both expressed in terms of the quantile $w \\in [0, 1]$. Considering different quantiles allows us to balance efficiency (e.g., energy consumption) against inference quality and latency guarantees. We can thus limit the extent of an undesirable event (failing to meet the application requirements) by tweaking $w$, depending upon the scenario and application at hand. Intuitively, one might use more lightweight models in scenarios/applications where occasional failures can be accepted. On the other hand, critical scenarios where accuracy guarantees are required call for more robust models even if they have more substantial resource requirements. We remark how the resource usage versus accuracy performance tradeoff is informed by the context.\nFor each application $h$, we have a set of possible data sources $\\mathcal{N}_h \\subseteq \\mathcal{N}^d$, corresponding to nodes equipped with a sensor (e.g., Camera, LiDAR, or Radar) that can be used for application $h$. The quantity $o_n^h$ represents the quantity of data (in bits) emitted by source $n$ when used for application $h$.\nAlso, each application is associated with a splittable dynamic DNN model, composed of stems $\\mathcal{A}sh$ and branches $\\mathcal{A}bsh$ (al- though simply referred to as branches, the latter ones may come with an additional stem at the end, as described in Sec.III-B). More specifically, the model can be split by deploying stems and branches at different nodes. For each stem and branch in $a \\in \\mathcal{A}_{s,h} \\cup \\mathcal{A}_{b,h}$, and for each node $i \\in \\mathcal{N}^m \\cup \\mathcal{N}^e$, we know the quantity $d_a^h$ outgoing from stem (or branch) $a$ when used by application $h$. For each stem $a \\in \\mathcal{A}_{h}$ (branch $a \\in \\mathcal{A}_{b,h}$) and application $h$, we are also given the computational complexity of each stem (branch), expressed in number of operations $\\upsilon_a^h$"}, {"title": "V. QIC: A DYNAMIC DEPENDABLE SOLUTION", "content": "Given the dynamic nature of the system, in our solution approach we introduce the notion of time by extending the static sensor fusion and inference graph model (discussed in the previous section) to an attributed dynamic graph model. Then, in light of the problem complexity, we also apply the Quantile Constrained Policy Optimization (QCPO) reinforcement learning algorithm [13] to the attributed dynamic graph and find the efficient set of data sources to be used and the DNN deployment configuration and resource allocation in the dynamic system for heterogeneous applications.\nA schematic illustration of our proposed QIC framework is presented in Fig. 3. It consists of two blocks: the Graph Builder and the QCPO. Given time t=0, the first block creates the initial attributed dynamic graph, $G^{(0)}$, i.e., the attributed graph reflect- ing the system at the initial time instant. The QCPO block instead performs quantile constrained reinforcement learning (RL) [13]. It takes $G^{(0)}$ as input and selects the action, i.e., the configuration (DNN stems and branches, where they are deployed and the corresponding resource allocation), that maximizes a reward function matching the objective in (4a). Based on the selected action, the Graph Builder updates the attributed dynamic graph, yielding $G^{(1)}$. The procedure is repeated for $P_{max}$ epochs, thus generating $G^{(\\tau)}$ at every epoch $\\tau$, and the solution to be enacted at time $t$ will be given by the action selected in the last epoch. Below, we give further details on our solution approach."}, {"title": "A. Attributed dynamic graph model", "content": "We account for the temporal variations of the applications, network conditions, and context (e.g., Sunny, Motorway, Night) by combining the static sensor fusion and inference graph representation of the system (Fig. 1) given for each time instant into an attributed dynamic graph model (Fig. 4). By doing so, the attributed dynamic graph can represent a time-based deployment of dynamic DNNs with stems and branches in the mobile-edge continuum to provision sensor fusion and inference tasks for heterogeneous applications.\nEach edge in an attributed dynamic graph contains multiple dynamic attributes, each specifying a different system-level constraint. This facilitates the identification through the graph of the solution to our time-varying, multi-constrained problem. The dynamic graph is $G={G_1, G_2, ...G_T}$, where: \n$G_t={V_t, E_t, F_t}$, t=1, . . .T, models the system at time t; \n$V_t$ is the set of vertices of $G_t$, representing data sources $n_{dt, i}$, i $\\in$ {1,2,... N}, mobile nodes $n_{mt, i}$, i $\\in$ {1, 2, ... $N_m$ }, and edge servers $n_{et, i}$,i$\\in${1,2,... $N_e$}, plus a source, $S_u$, and a destination, $D_u$, as fictitious vertices representing (resp.) the starting and ending point of the system configuration process; \n$E_t$ is the set of edges of $G_t$. An edge e$\\in$$E_t$ is defined as a tuple (u, v, {$b_h^u, c_h^u$}$_{h \\in [1,H]}$, $p_u$) where: (i) u, v$\\in$$V_t$, (ii) the number of resource blocks ($b_h^u$) and compute resources ($c_h^u$) is the assignment for each application h at node u such that $\\sigma$(h, u)=a, with a$\\in$$\\mathcal{A}_{s,h}$ $\\cup$ $\\mathcal{A}_{b,h}$, if one or more stems or branches of the DNN are deployed on node u for application h, (iii) and $p_u$ is the uplink per-resource block data rate at u. The same holds if $\\sigma$(h, u)=data, but for the compute resources allocation which in this case is $c_h^u$=0;"}, {"title": "B. The QCPO solution framework", "content": "Using the QCPO approach [13], the decision process can be modelled as a constrained Markov decision process and, accordingly, the dynamic system can be defined by the tuple $\\left<\\mathcal{S}, \\mathcal{S}_a, r, c, M, \\gamma\\right>$, where $\\mathcal{S}$ is the state space, $\\mathcal{S}_a$ is the action space, $r : \\mathcal{S} \\times \\mathcal{S}^a\\rightarrow\\mathbb{R}$ is the reward function, $c : \\mathcal{S} \\times \\mathcal{S}^a\\rightarrow \\mathbb{R}+$ is the cost function, $M : \\mathcal{S}^a \\times \\mathcal{S}^a \\times \\mathcal{S}\\rightarrow[0, 1]$ is the state transition probability, and $\\gamma$ is a discount factor used for computing the accumulated cost of the Markov decision process over the epochs. In the following, we fix the time instant t and drop the dependency on t whenever clear from the context. We instead denote with $\\tau$ the epoch of the QCPO process, which is performed at each t to adapt the selected configuration to the system's dynamics. The system state is then given by the set $\\mathcal{S}_t=\\mathcal{S}^{\\tau}=\\{B_n, C_n, p_n\\}_n$ and an action is represented by the set $a=\\{\\sigma_n^h, b_{n}^{h}, c_{n}^{h}\\}_{h,n}$ (with $a_t=a^{P_{max}}$, i.e., the action to be enacted at time t is the one selected at $\\tau=P_{max}$). QCPO implements a policy $\\pi$, which selects the action maximizing the reward function (specified below). The edges ($E_t$) and attribute function"}, {"title": "VI. REFERENCE SCENARIO", "content": "In this section, we describe the sensors dataset we use for our performance evaluation, as well the radio link measurements we carried out to account for real-world conditions.\nDataset and dynamic DNN model. We employ the RA- DIATE dataset [15], which offers data of Navtech CTS350-X Radar, a Velodyne HDL-32e LiDAR, and left and right ZED"}, {"title": "VII. PERFORMANCE EVALUATION", "content": "We now show QIC's performance in a small- and a large-scale dynamic scenario, against the following benchmarks:\nMulti-Constrained Shortest Temporal Path selection (MCTP) [11], applied on the attributed dynamic graph. It is based on an adaptive Monte Carlo Tree Search, which finds a path between a graph source and destination nodes so as to satisfy the multiple end-to-end constraints on the attributed edge weights. We select [11] because no scheme exists that specifically tackles the problem at hand.\nOptimum (Opt), obtained through exhaustive search (only in the small-scale scenario where its computation is feasible).\nParameters are set as listed in Table III. As mentioned, in both the small-scale and large-scale scenario, the available radio resources and the MCS index that can be used by each mobile node are changing over time.\nSmall-scale scenario. The scenario, depicted in Fig. 1(a), includes 4 data sources, 3 mobile nodes, 2 ESs, and 3 appli- cations. We associate each mobile node with one application and a specific context, and investigate the impact on energy consumption of accuracy and latency constraints. We begin by looking at the performance in the case of the mobile node with the Sunny context. In Fig. 6(a), we fix the latency target to $l_h^{\\text{max}}$=50 ms with quantile w=0.9 and vary the accuracy target $\\alpha_h^{\\text{min}}$; as one might expect, a tighter accuracy target results in a larger energy consumption for all strategies. More importantly, QIC greatly outperforms MCTP, yielding savings that exceed 25%, and it almost always matches the optimum. In Fig. 6(b), we fix the accuracy target to $\\alpha_{h, min}$=50% with quantile w=0.9 and change the latency target (again, MCTP cannot meet the target accuracy and latency with higher w's). Besides noticing that shorter latency results in higher energy con- sumption, remarkably, QIC can achieve the same performance as the optimum, except when latency constraints are very tight, and consistently outperforms MCTP, on average, by 80%. The same behavior can be observed for the Night and Motorway contexts (Figs. 6(c)-6(d) and Figs. 6(e)-6(f), resp.). Since the maximum accuracy for Night and Motorway is now limited to the less stringent requirement of 60%, the difference between the different schemes is occasionally slightly smaller than in the Sunny context. Nevertheless, QIC consistently makes optimal or near-optimal decisions, while MCTP always incurs 25% higher energy consumption relatively to QIC.\nLarge-scale scenario. Next, we apply QIC to a scenario with multiple mobile nodes and 10 ESs. Context (Sunny, Night, and Motorway) and applications are uniformly assigned to mobile nodes. We set $l_h^{\\text{max}}$=50 ms, $\\alpha_h^{\\text{min}}$=50%, and w=0.9"}, {"title": "VIII. CONCLUSIONS", "content": "We targeted dynamic scenarios where multiple DNN-based applications can leverage multiple data sources for their infer- ence task. Given DNN's architecture with multiple stems and branches that can be dynamically selected, we proposed QIC to jointly choose (i) the input data sources and (ii) the DNN sections to use, and (iii) the nodes where each stem and branch is deployed, along with (iv) the resources to use therein. We proved QIC's polynomial worst-case time complexity and, using a dynamic DNN architecture, a real-world dataset and radio link measurements, showed that QIC closely matches the optimum and outperforms its benchmarks by over 80%."}]}