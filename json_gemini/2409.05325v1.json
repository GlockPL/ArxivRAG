{"title": "Sample-Efficient Bayesian Optimization with Transfer Learning for Heterogeneous Search Spaces", "authors": ["Aryan Deshwal", "Sait Cakmak", "Yuhou Xia", "David Eriksson"], "abstract": "Bayesian optimization (BO) is a powerful approach to sample-efficient optimization of black-box functions. However, in settings with very few function evaluations, a successful application of BO may require transferring information from historical experiments. These related experiments may not have exactly the same tunable parameters (search spaces), motivating the need for BO with transfer learning for heterogeneous search spaces. In this paper, we propose two methods for this setting. The first approach leverages a Gaussian process (GP) model with a conditional kernel to transfer information between different search spaces. Our second approach treats the missing parameters as hyperparameters of the GP model that can be inferred jointly with the other GP hyperparameters or set to fixed values. We show that these two methods perform well on several benchmark problems.", "sections": [{"title": "1 Introduction", "content": "Bayesian optimization (BO) is a popular technique for sample-efficient black-box optimization that has been successfully leveraged for a wide range of applications such as hyperparameter tuning for machine learning models (Snoek et al., 2012; Turner et al., 2021), A/B testing (Letham et al., 2019), chemical engineering (Hern\u00e1ndez-Lobato et al., 2017), materials science (Ueno et al., 2016), control systems (Candelieri et al., 2018), and drug discovery (Negoescu et al., 2011). Many approaches to BO target the setting of expensive black-box functions where we only have access to a small number of function evaluations. To further improve the performance of BO in this setting, transfer learning can be used as a way of leveraging relevant historical information. While transfer learning has been thoroughly studied in the BO literature, traditional transfer learning approaches typically assume that all related experiments have exactly the same (homogeneous) search space. This assumption simplifies the modeling process, but significantly limits the applicability of these methods in real-world scenarios where search spaces often vary between experiments. For instance, when tuning the hyperparameters of machine learning models, practitioners often make changes to the search space to add and/or remove parameters or update their ranges.\nIn this regime, we need a BO method that can seamlessly transfer information from several historical experiments with different search spaces. To achieve this, we propose two methods targeting the setting of a small number of function evaluations where we do not have access to additional domain knowledge, e.g., user priors. Our first method leverages a conditional kernel that defines a similarity measure between heterogeneous spaces by leveraging a tree-structured representation of the search spaces. This method has the advantage that it requires no additional hyperparameters. Our second method employs a learned imputation which treats missing parameters as hyperparameters that can be learned jointly with the other GP hyperparameters. Both methods allow incorporating task-level similarity information and naturally correspond to standard transfer learning BO in the special case when the search spaces are identical. Our main contributions are:\n1. We propose two methods (conditional kernel-based and learned imputation-based) for BO with transfer learning for heterogeneous search spaces."}, {"title": "2 Related Work", "content": "Transfer Learning in Bayesian Optimization (BO). BO has been previously explored with the common goal of leveraging information from historical source tasks to improve optimization efficiency on a new target task (Bai et al., 2023). Early work by (Swersky et al., 2013; Yogatama and Mann, 2014)) employed multi-task Gaussian Processes (MTGPs) to model task similarities. In addition, (Tighineanu et al., 2022) provide a unified view of hierarchical GP models for transfer learning in BO. Ensemble methods have also been utilized as surrogate models in the context of transfer learning (Feurer et al., 2018; Schilling et al., 2016).\nRecent work has also considered learning neural network-parameterized GP priors from previ-ous tasks (Perrone et al., 2018; Wang et al., 2021; Wistuba and Grabocka, 2021). Additionally, (Dai et al., 2022; Shilton et al., 2017; Wang et al., 2018) performed a theoretical analysis for the regret metric commonly employed in BO. However, all these approaches focus on the setting where the search spaces are homogeneous across tasks, i.e., all tasks share the same search space. This limits these methods applicability for problems with different (heterogeneous) search spaces.\nBO with Heterogeneous Search Spaces. (Fan et al., 2024) recently proposed a method for transfer learning across heterogeneous search spaces that leverages a neural network mapping from domain-specific contexts to specifications of hierarchical GPs. The data requirements of neural networks and the need for manually defined domain-specific contexts may limit the applicability of this method in settings where small amounts of data is available. Another class of recent methods leverage text-based sequential modeling approaches for meta black-box optimization (Chen et al., 2022; Song et al., 2024). While this sequential modeling can naturally handle heterogeneous search spaces, these methods require massive amounts of training data. During paper review, we became aware of (Stoll et al., 2020), which motivates the heterogeneity through the adjustments made across a sequence of hyperparameter optimizations for machine learning models. They introduce the problem, a series of benchmark problems and baseline algorithms; and demonstrate that transferring knowledge across experiments can lead to significant savings in experimentation budget."}, {"title": "3 Background", "content": "Bayesian Optimization. Bayesian optimization (BO) is an iterative approach to black-box optimiza-tion, see (Frazier, 2018; Garnett, 2023) for a comprehensive overview. BO consists of two main steps where we first build a probabilistic surrogate model from available data followed by optimizing an acquisition function to select the most promising candidate(s) to evaluate next. This iterative process continues until the evaluation budget has been exhausted. The probabilistic surrogate model is commonly a Gaussian process (GP) (Rasmussen et al., 2006) and a common choice of acquisition function is the expected improvement (EI) (Jones et al., 1998).\nBayesian Optimization with Transfer Learning. Our goal is to optimize a target black-box function (task) f(x) where each evaluation of f(x) is expensive and the number of function evaluations is limited. We assume a budget of n function evaluations for f\u2081(x), where n is commonly between 5 and 40. In the transfer learning setting we are also given data from a set of t \u2013 1 related optimization experiments, referred to as source tasks, f1, f2, . . ., ft-1. We want to leverage this existing data to improve the sample-efficiency of BO on the target task f\u2081(x)."}, {"title": "4 BO with Transfer Learning for Heterogeneous Search Spaces", "content": "In this section, we will propose two methods for BO with transfer learning for heterogeneous search spaces. Our first method uses a conditional kernel which allows us to leverage a GP model to correlate the common parameters across tasks. Our second method treats the missing parameters for each task as hyperparameters that will need to be inferred when training the GP model. A clear benefit of these methods compared to existing methods in the literature, e.g., (Chen et al., 2022; Fan et al., 2024; Song et al., 2024), is that neither method assumes additional information beyond the previously evaluated inputs and corresponding function values of the source and target tasks."}, {"title": "4.1 MTGP with Conditional Kernels", "content": "Next, we will describe a GP model that employs a new kernel (referred as Conditional Kernel) to handle the challenge of modeling heterogeneous search spaces across different tasks. The key idea behind Conditional Kernel is to leverage a set of base kernels, e.g., Matern-5/2, to conditionally compare inputs from different tasks based on their matching parameters in a dependency tree representing the search spaces of all the tasks.\nTree-Structured Representation of Heterogeneous Search Spaces. To make this more concrete, let U = U=1 X\u2081 be the universal set of parameters from all the tasks. We create a tree-representation of this universal set U where each node of the tree corresponds to a subset of parameters. Starting from the root node, we assign a maximal subset of parameters to each node that are common across as many tasks as possible. Subsequently, we define a set of base kernels that is equal to the number of nodes in the tree.\nConditional kernel. The Conditional Kernel (Kc) of any two inputs x and x' coming from two tasks i, i' is defined as the sum of base kernels over all nodes that contain the common parameters across both task i and task i':\n$K_c(\\lbrace x, i \\rbrace, \\lbrace x', i' \\rbrace) = \\sum_{j=1}^{P} \\mathbb{I}[N_{U}[j] \\subset X_{i} \\cap X_{i'}] \\cdot k_{j}(x[N_{U}[j]], x'[N_{U}[j]]]),$"}, {"title": "4.2 MTGP with Imputed Values", "content": "In many applications, the missing parameters represent fixed settings that have not been tuned in the experiment. With this motivation, we propose an approach that treats each missing (from the union of search spaces) parameter in a task as an additional hyperparameter (for the unknown fixed value) in the MTGP model. These missing parameters can either be learned jointly with the other GP hyperparameters or set to some fixed value. While this approach introduces additional hyperparameters (one per missing parameter per task), the computational complexity of GP training is on the same order as an MTGP defined over the union of search spaces."}, {"title": "5 Experiments", "content": "In this section, we provide an empirical evaluation of different methods for BO with heterogeneous search spaces. All experiments use 100 replications and we show the mean performance with two standard errors in all plots. All methods use a squared exponential (SE) kernel. We use the Log-Normal priors proposed in (Hvarfner et al., 2024), which are designed to be performant in both low and high-dimensional settings, using length-scale priors that scale by VD. We use the recently proposed LogEI extension of the popular Expected Improvement (EI) acquisition function (Ament et al., 2023). For each replication, we initialize all methods with exactly the same initial random points and generate a new set of random trials for the source tasks.\nMethods. We compare six different methods. Random Search which samples randomly from the search space. Vanilla BO uses standard BO on the target task and ignores the data from the source tasks. MTGP with Conditional Kernels uses the approach described in Sec. 4.1. MTGP on Common Parameters uses an MTGP + LogEI on the common parameters and samples other parameters randomly. Imputed MTGP uses the imputed model as described in Sec. 4.2 and sets missing parameters to the center of the parameter range. Learnable Imputed MTGP uses the imputed MTGP from Sec. 4.2 and learns the missing parameters jointly with the other GP model hyperparameters.\nSynthetic problems. Our first test problem uses the popular synthetic Hartmann6 function. We use one source task which corresponds to a 4D search space where last 2 parameters are fixed to 0. The target task is the original Hartmann6 problem.\nHPO-B benchmark problems. HPO-B is a large transfer learning benchmarking suite for hyper-parameter optimization (Pineda et al., 2021). We construct two different test problems based on problems available in HPO-B. The first problem is Ranger, which has 11 tunable parameters. We use search space ids 5965 (missing parameter index 10) and 7607 (missing parameter index 5 and 9) as the source tasks. The target task is search space id 5889 with parameters [0, 1, 2, 3, 6, 7]. The second problem is Rpart where we use search space ids 5636 and 5859 (both with all 6 parameters) as source tasks. The target task has search space id 4796 and only has parameters [0, 2, 3]."}, {"title": "5.1 Ablation study", "content": "We perform an ablation study where we vary the number of source trials on the 11D Ranger problem."}, {"title": "6 Conclusions", "content": "Our results show that BO with transfer learning can be successfully leveraged in the setting of heterogeneous search spaces where we have access to small amounts of historical data. For future work, we plan on exploring ways of leveraging additional domain-specific information. Additionally, leveraging other probabilistic models, e.g., Bayesian neural networks, may address some of the scaling limitation of our approach that come from leveraging exact MTGP models."}, {"title": "7 Broader Impact", "content": "After careful reflection, the authors have determined that this work presents no notable negative impacts to society or the environment."}, {"title": "A Example conditional kernel construction", "content": "Without loss of generality, we can assign each parameter a unique integer id.\n\n\u2022 Search space of f\u2081: X\u2081 = {1: learning rate, 2: dropout rate}\n\n\u2022 Search space of f2 : X2 = {1: learning rate, 2: dropout rate 3: batch size}\n\n\u2022 Search space of f3: X3 = {1: learning rate, 2: dropout rate, 4: number of hidden layers}\n\nThis means that the universal set of parameters is U = {1, 2, 3, 4}. The conditional kernel can be constructed as follows:\n\n1. First, we construct a set U of size p consisting of subsets of ids that are common across as many tasks as possible.\n2. We define p base kernels {k\u2081, k2, \u2026, kp} for each subset in U.\n3. The conditional kernel Kc value of two inputs x and x' coming from two tasks i, i' is then defined as the sum of the base kernels that correspond to the subsets containing common parameters of both task i or task i':\n$K_c(\\lbrace x, i \\rbrace, \\lbrace x', i' \\rbrace) = \\sum_{j=1}^{P} \\mathbb{I}[\\bar{U}[j] \\subset X_{i} \\cap X_{i'}] \\cdot k_{j}(x[\\bar{U}[j]], x'[\\bar{U}[j]]),$\n\nSimilarly, if the inputs x and x' are from the same task 2, the conditional kernel is:\n\n$K_c(\\lbrace x, i \\rbrace, \\lbrace x', i' \\rbrace) = k_1(x[1, 2], x'[1, 2]) + k_2(x[3], x'[3])$"}]}