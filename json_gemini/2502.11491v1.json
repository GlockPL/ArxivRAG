{"title": "Ontology-Guided Reverse Thinking Makes Large Language Models\nStronger on Knowledge Graph Question Answering", "authors": ["Runxuan Liu", "Bei Luo", "Jiaqi Li", "Baoxin Wang", "Ming Liu", "Dayong Wu", "Shijin Wang", "Bing Qin"], "abstract": "Large language models (LLMs) have shown\nremarkable capabilities in natural language pro-\ncessing. However, in knowledge graph ques-\ntion answering tasks (KGQA), there remains\nthe issue of answering questions that require\nmulti-hop reasoning. Existing methods rely\non entity vector matching, but the purpose of\nthe question is abstract and difficult to match\nwith specific entities. As a result, it is diffi-\ncult to establish reasoning paths to the purpose,\nwhich leads to information loss and redundancy.\nTo address this issue, inspired by human re-\nverse thinking, we propose Ontology-Guided\nReverse Thinking (ORT), a novel framework\nthat constructs reasoning paths from purposes\nback to conditions. ORT operates in three key\nphases: (1) using LLM to extract purpose labels\nand condition labels, (2) constructing label rea-\nsoning paths based on the KG ontology, and (3)\nusing the label reasoning paths to guide knowl-\nedge retrieval. Experiments on the WebQSP\nand CWQ datasets show that ORT achieves\nstate-of-the-art performance and significantly\nenhances the capability of LLMs for KGQA.", "sections": [{"title": "1 Introduction", "content": "LLMs have made significant achievements in natu-\nral language processing, excelling in tasks such as\nsemantic understanding (Raiaan et al., 2024), text\ngeneration (Shen et al., 2024a), machine translation\n(Hu et al., 2024a), dialogue systems (Zhang et al.,\n2019), sentiment analysis (Devlin et al., 2019), and\ntext summarization (Basyal and Sanghvi, 2023).\nThe rapid development of LLMs has sparked in-\nterest in combining LLMs with knowledge graphs\nto improve KGQA performance (Hu et al., 2024b).\nExisting approaches typically adopt two paradigms.\nFine-tuning methods like LPKG (Wang et al.,\n2024b) and RoG (Luo et al., 2024). However, creat-\ning high-quality training data is resource-intensive\n(Cao et al., 2023). Additionally, knowledge graphs\nare highly structured data, and when faced with\nquestions that have not been fine-tuned, the quality\nis difficult to guarantee (Jiang et al., 2024). Em-\nbedding + Search methods such as MindMap (Wen\net al., 2024) and Think-on-Graph (Sun et al., 2023)\nrely on entity embeddings and graph traversal, but\ndo not handle conceptual targets absent in KG en-\ntities. As shown in Figure 1, \u201cstadium\u201d is a con-\ncept, not an entity in the knowledge graph, so \u201cEm-\nbedding + Search Strategy\" can only find paths\nbetween \"1995 Rugby World Cup\u201d and \u201cIreland\nTeam\" and their neighbors, but cannot reach"}, {"title": "2 Methodology", "content": "As shown in Figure 2, the entire algorithm is di-\nvided into three steps:\n1. Condition and Aim Recognition: Prompt\nthe LLM to understand the known conditions\nand the solving aims of the question.\n2. Ontology-Guided Reverse Thinking Rea-\nsoning: Use the Reverse Thinking Reasoning\nmethod to construct label reasoning paths on\nthe knowledge graph ontology.\n3. Guided Answer Mining: Use the label rea-\nsoning paths to guide querying and prompt\nthe LLM to generate the final answer."}, {"title": "2.1 Aim and Condition Recognition", "content": "This step extracts the condition entities $CE$ =\n${C_1, C_2,..., C_n}$, labels of condition entities\n$CL$\n= {$cl_1, Cl_2, ..., cl_n$}, aim entities $AE$ =\n{$a_1, a_2,..., a_n$}, and labels of aim entities $A_l$ =\n{$al_1, al_2, ..., al_n$} from the question by prompting\nLLM.\nCondition is defined as the known key informa-\ntion in the question, while Aim is defined as the\ncontent the user wants to query through the ques-\ntion.\nWe provide the LLM with a Label List of the\nknowledge graph, prompting the LLM to first ex-\ntract CE and AE, and then assign labels to the\nrespective entities. The main content of the prompt\ntemplate is shown in Figure 3, and the complete\ncontent of the prompt can be found in Appendix C."}, {"title": "2.2 Ontology-Guided Reverse Thinking\nReasoning", "content": "Knowledge graph reasoning differs from document\nreasoning in that its data is structured, making\nthe effective use of structural information particu-\nlarly important (Thambi and Reghuraj, 2022). We\npropose for the first time the use of a knowledge\ngraph ontology (KG ontology) to construct label\nreasoning paths, thereby guiding KG queries to\nenhance the reasoning ability of LLM with knowl-\nedge graphs.\nThe way we construct paths on KG ontology is\nReverse Thinking Reasoning. The constructed path"}, {"title": "2.2.1 Step I. Construct the Neighbor Label\nDictionary", "content": "The ontology of the knowledge graph consists of\nseveral relation-defined triples. For each label $l_i$ in\na triple, we collect all other labels $l_k, l_{k+1},...$ that\nappear in the same relation-defined triple.\nTo express this, we introduce a function $N(l_i)$,\nwhich denotes the set of labels $l_k$ that appear in the\nsame triple as $l_i$:\n$N(l_i) = {l_k | (l_i, relationship, l_k) \\in G}$ (1)\nwhere $G$ represents the set of all triples in the knowl-\nedge graph. Then, we construct a neighbor label\ndictionary, denoted as $D$, where $l_i$ is the key, and\n$N(l_i)$ is the value associated with it:\n$D = {l_i : N(l_i)}$ (2)\nFor example, given the following relationships\nin the knowledge graph ontology: $l_1 \\rightarrow l_2, l_1 \\rightarrow l_3$,\nand $l_3 \\rightarrow l_1$, the neighbor label dictionary $D$ will\nbe:\n$D =\\begin{cases}\nl_1: [l_2,l_3],\\\\\nl_2:[l_1],\\\\\nl_3:[l_1]\n\\end{cases}$"}, {"title": "2.2.2 Step II. Construct the Reverse\nReasoning Tree", "content": "First, since the length of $A_l$ may be greater than 1,\nwe create a virtual root node and add all aim labels\n$A_L = {al_1, al_2, . . ., al_m}$ as its child nodes.\nThen, we recursively traverse all child nodes,\nquerying the neighbor label dictionary $D$ to add\nall neighboring labels $N(l_i)$ as child nodes of each\ncurrent node.\nThis process continues recursively until the max-\nimum recursion depth max_pop is reached. The\nmaximum recursion depth is determined based on\nthe number of hops of the question.\nThe reverse reasoning tree, denoted as $T$, is built\nas a recursive structure where the nodes represent\nlabels from the knowledge graph, and the edges\nrepresent the relationships between them."}, {"title": "2.2.3 Step III. Prune By Conditions", "content": "Starting from the root node, we perform a depth-\nfirst search (DFS) and record the current path."}, {"title": "2.2.4 Step IV. Prune Cycle Sub-paths", "content": "Due to the possibility of bidirectional relationships\nbetween two labels, cycles may exist in the reason-\ning paths.\nA depth-first search (DFS) is performed on\n$T_{Condition}$, adding the current node's name to the\nvisited set visited. The pruning algorithm is re-\ncursively called for each child node of the current\nnode. If the current node's name already exists in\nthe visited set visited, the edge between the current\nnode and its parent is removed, effectively elimi-\nnating the cycle. During backtracking, the current\nnode's name is removed from the visited set so that"}, {"title": "2.2.5 Step V. Prune By Semantics", "content": "As shown in Figure 2, after pruning by conditions\nand cycles, interference paths such as \u201cteam \u2192\nconference \u2192 venue\" may still exist. To remove\nthese irrelevant paths, semantic information is used\nfor pruning.\nA depth-first search (DFS) is performed on all\npaths of $T_{cycle}$, and the paths are reversed to for-\nward paths. These paths, together with the problem,\nare input into LLM. The model is prompted using\na template to output the paths that are beneficial\nfor answering the question. The main content of\nthe prompt template is shown in Figure 4, and the\ncomplete content can be found in Appendix C."}, {"title": "2.3 Guided Answer Mining", "content": "Through Ontology-Guided Reverse Thinking Rea-\nsoning, abstract reasoning paths for solving the\nproblem are obtained. They are then used to guide\nthe forward knowledge graph query process to col-\nlect entity reasoning paths.\nA tree structure is used to store the results of\neach query step. The process is driven by travers-\ning the abstract path, which consists of a sequence\nof labels. For each reasoning path, the first node is\na condition node, and all entities that satisfy the la-\nbel of this node are added as child nodes to the tree.\nThen, for each of these child nodes, the next label\nin the abstract path is used to query the neighboring\nentities of the current entity. Only those neighbors\nwhose label matches the next label in the abstract\npath are retained and added as children of the cur-\nrent child node. This process continues iteratively,\nfollowing the order of labels in the abstract path.\nIf there are many neighboring entities satisfying\nthe next label, and the number exceeds the limit,\ntop_k neighboring entities are randomly selected"}, {"title": "3 Experiments", "content": "3.1 Experimental Setup\nBenchmarks We conducted experiments on two\nwidely used KGQA datasets: WebQuestionSP (We-\nbQSP) (tau Yih et al., 2016) and Complex We-\nbQuestions (CWQ) (Talmor and Berant, 2018).\nBoth datasets are constructed by extracting data\nfrom the Freebase knowledge graph. In our exper-\niments, we follow ROG (Luo et al., 2024) to con-\nstruct knowledge graphs for WebQSP and CWQ.\nMore details can be found in Appendix A.\nEvaluation Metrics Following previous work\n(Luo et al., 2024; Zhang et al., 2022; Li et al., 2024;\nTan et al., 2024), we use Hit@1 and F1 as eval-\nuation metrics. We also provide detailed results\nfor accuracy, precision, and recall in Appendix B."}, {"title": "3.2 ORT Achieves SOTA", "content": "As shown in Table 1, ORT achieves state-of-the-art\nperformance on both WebQSP and CWQ. The base\nLLM for all LLM+KGs(non-Fine-tuned) meth-\nods including our method shown in Table 1 is\nDeepSeek-v3.\nCompared to small-scale models based on em-\nbedding or retrieval, on WebQSP, Hit@1 improves\nby 20% to 42.7%, and F1 improves by 7.7% to\n37.3%; on CWQ, Hit@1 improves by 22.7% to\n54.5%, and F1 improves by 15.5% to 46.9%.\nORT also outperforms partially KGR FT meth-\nods such as KD-CoT and RoG. This demon-\nstrates that our method not only enhances question-\nanswering performance but also reduces costs, im-\nproves model scalability, and enhances adaptability\nto different knowledge graphs.\nBesides, compared to pure LLM and KGR w/o\nFT methods, ORT also achieves significant im-\nprovements, which will be discussed later."}, {"title": "3.3 Soars LLM's KGQA Ability", "content": "As shown in Figure 6, we conducted comparative\nexperiments on three LLMs: GPT-40, DeepSeek-\nv3, and Qwen-Max. Compared to direct answers,\nLLMs using ORT led to more than a 25% improve-\nment in Hit@1 and F1 scores across both datasets.\nOn WebQSP, Hit@1 of the three LLM respec-\ntively improved by 25.7%, 25.3%, and 29.14%,\nand F1 score increased by 28.23%, 27.96%, and\n31.69%. On CWQ, Hit@1 improved by 27.23%,\n31.79%, and 31.45%, and F1 score increased by\n25.82%, 28.83%, and 28.30%. Details can be\nfound in Table 2.\nThis not only demonstrates that ORT effectively\nenhances the performance of LLMs on KGQA\ntasks but also highlights that ORT is not limited to a\nspecific LLM. It serves as a universal enhancement\nstrategy and can be directly used for improving\nLLM performance. It has the potential to become\nan effective, convenient, and important tool in such\na domain."}, {"title": "3.4 ORT Outperforms Peers", "content": "ORT achieves better performance compared to\nother methods of the same type. Using the same\nbase LLM (GPT-4, DeepSeek-v3, and Qwen-max),\nORT was compared with MindMap and KG Re-\ntriever, as shown in Table 3. On WebQSP, ORT\nachieved an average improvement of 26.56% in\nHit@1 and 26.27% in F1 over MindMap across the\nthree base models. On CWQ, ORT outperformed\nMindMap with an average improvement of 20.18%\nin Hit@1 and 16.86% in F1."}, {"title": "3.5 Ablation Study", "content": "Through ablation study, we aim to demonstrate\nthe effectiveness and necessity of Reverse Think-\ning Reasoning, Knowledge Graph Structure-Based\nReasoning, and Rule-Guided Reasoning. We de-\nsigned it in three parts:\n1. w/o LLM Filter: In this part, we removed us-\ning LLMs for pruning based on the semantics\nof questions and paths."}, {"title": "4 Related Work", "content": "Small-scale models for KGQA Small-scale\nmethods for knowledge graph question answer-\ning (KGQA) can be divided into two categories:\nembedding-based and retrieval-based methods.\nEmbedding-based methods, such as KV-Mem\n(Miller et al., 2016) and NSM (He et al., 2021), rep-\nresent entities and relations in a low-dimensional\nvector space, performing well on simple, single-\nhop queries. However, they struggle with com-\nplex, multi-hop queries due to difficulty in cap-\nturing intricate path information. To address this,\nretrieval-based models like GraphNet (Sun et al.,\n2018) and SR (Zhang et al., 2022) construct sub-\ngraphs or paths for reasoning, showing improve-\nments in multi-hop tasks by better leveraging struc-\ntural relationships. Yet, both methods are limited\nby incomplete utilization of the full structural in-\nformation in the knowledge graph.\nFine-tuning LLMs for KGQA In recent years,\nthe rapid development of large language models\n(LLMs) has sparked interest in combining LLMs\nwith knowledge graphs to improve KGQA perfor-"}, {"title": "5 Conclusion", "content": "In this paper, we simulate the cognitive paradigm\nthat humans use to solve complex problems and\npropose the Ontology-Guided Reverse thinking\nmethod for knowledge graph question answering.\nWe use LLMs to understand the intent of the ques-\ntion and generate the corresponding labels. By\nleveraging the knowledge graph ontology, we use\nReverse-Thinking Reasoning to form label reason-\ning paths, followed by guided knowledge graph\nqueries and answer aggregation. Experimental re-\nsults show that our method significantly improves\nthe accuracy and answer coverage."}, {"title": "Limitations", "content": "For this work, we want to address two areas for\nimprovement in the future. First, when querying\nthe knowledge graph along reasoning paths, there\nmay be a large number of entities satisfying the\nlabel constraints, which could lead to irrelevant re-\nsults. Second, when generating the final answer,\ninputting all entity paths into the LLMs may in-\ntroduce irrelevant paths, potentially lowering the\naccuracy of the answer."}, {"title": "A EXPERIMENT DETAILS", "content": "A.1 Datasets\nTo evaluate the performance of ORT on knowledge\ngraph question and answer tasks, we conducted\nexperiments on two multi-hop datasets (CWQ (Tal-\nmor and Berant, 2018) and WebQSP (Devlin et al.,\n2019)). The questions in both datasets cover vari-\nous domains, including people, places, events, etc.\nDue to the complexity of the questions, traditional\nquestion answering systems and search-based en-\ngines often struggle to provide valuable knowledge.\nFreeBase (Bollacker et al., 2008) serves as the back-\nground knowledge graph for both datasets, con-\ntaining approximately 88 million entities, 20,000\nrelationships, and 126 million triples.\nSimilar to the datasets used in ROG, we ex-\ntracted 3,531 question-answer pairs from the CWQ\ndataset as the test set, which includes 2,294,264\ntriples and 4,726 relationships. We also extracted\n1,628 question-answer pairs from the WebQSP\ndataset as the test set, which includes 2,277,228\ntriples and 5,051 relationships. For details, see\nTable 5."}, {"title": "A.2 Metrics", "content": "Accuracy is the ratio of the number of correct pre-\ndictions to the total number of predictions. The\nformula is as follows:\n$Accuracy =\\frac{\\sum_{i=1}^N \u2161(\u0177_i \\in A_{gold,i})}{N}$ (3)\nHit@1 is whether the most probable prediction\namong the model's multiple outputs contains the\nground truth. If yes, the Hit@1 score is 1; other-\nwise, the score is 0. Because our method has only\none output, there is no need to select the prediction\nwith the highest probability. For example, consider\nthe question \"What religion does India follow?\"\nThe correct answer is \"Hinduism,\" and the model's\npredicted answers are \"Christianity, Hinduism, Is-\nlam.\" In this case, since \"Hinduism\" appears in\nthe model's predicted answers and it is the correct\nanswer, the Hit@1 score is 1. The formula is as\nfollows:\n$Hit@1 = I(\u2203\u0177_i \\in A_{gold})$ (4)\nPrecision is the ratio of the number of correct\npredictions to the total number of predictions. The\nformula is as follows:\n$Precision = \\frac{\\sum_{i=1}^N \u2161(Yi \\in A_{gold,i})}{N_{pred}}$ (5)"}, {"title": "A.3 Baselines", "content": "Baselines are grouped into 12 baseline methods\ninto 5 categories: 1) Embedding-based meth-\nods, 2) Retrieval-augmented methods, 3) LLM,\n4) LLM+KGs (Fine-tuned), and 5) LLM+KGs\n(non-Fine-tuned). The detailed information for\neach baseline is as follows:\nEmbedding-based methods\n\u2022 KV-MEM (Miller et al., 2016) employs a key-\nvalue memory network to store triples and\nperforms multi-hop reasoning by iterating op-\nerations over memory.\n\u2022 NSM(He et al., 2021) uses a sequential model\nto mimic the multi-hop reasoning process.\nRetrieval-augmented methods\n\u2022 GraftNet (Sun et al., 2018) retrieves relevant\nsubgraphs from knowledge graphs with entity\nlinking.\n\u2022 SR+NSM (Zhang et al., 2022) introduces a\nrelation-path retrieval mechanism to fetch sub-\ngraphs for multi-hop reasoning.\n\u2022 SR+NSM+E2E (Zhang et al., 2022) further\nadopts an end-to-end training strategy to\njointly train the retrieval and reasoning mod-\nules of SR+NSM.\nLLM methods\n\u2022 GPT-4 is a large language model developed\nby OpenAI, renowned for its excellent perfor-\nmance across a wide range of natural language\nprocessing tasks.\n\u2022 DeepSeek-v3 (DeepSeek-AI et al., 2024) is an\nadvanced model designed for deep reasoning\nand retrieval-augmented tasks, focusing on\ndomain-specific knowledge extraction.\n\u2022 Qwen-max is a large model optimized for mul-\ntilingual and multi-task learning, known for\nits strong capabilities in both generative and\nanalytical tasks.\nLLM+KGs (Fine-tuned) methods\n\u2022 KD-COT (Wang et al., 2023) retrieves rele-\nvant knowledge from KGs to formulate faith-\nful reasoning plans for LLMs.\n\u2022 ROG (Luo et al., 2024) combines knowl-\nedge graphs (KGs) and large language mod-\nels (LLMs) to achieve reliable and in-\nterpretable reasoning through a planning-\nretrieval-reasoning framework.\nLLM+KGs (non-Fine-tuned) methods\n\u2022 KG Retriever aims to find the shortest path\nbetween each pair of question entities, and\nthen retrieves the final prompt from the KG\nto guide the LLM in answering the question.\nThe key difference between MindMap and\nKG Retriever is that they do not use diverse\nmultiple pieces of evidence in the LLM, nor\ndo they ORT the evidence sources.\n\u2022 MindMap (Wen et al., 2024) integrates knowl-\nedge graphs (KGs) and large language mod-\nels (LLMs) by using KGs to provide explicit\nknowledge and reasoning paths, enhancing\nthe LLM's reasoning ability and transparency\nwhile revealing the thought process of the\nLLM."}]}