{"title": "Federated Continual Learning: Concepts, Challenges, and Solutions", "authors": ["Parisa Hamedi", "Roozbeh Razavi-Far", "Ehsan Hallaji"], "abstract": "Federated Continual Learning (FCL) has emerged as a robust solution for collaborative model training in dynamic environments, where data samples are continuously generated and distributed across multiple devices. This survey provides a comprehensive review of FCL, focusing on key challenges such as heterogeneity, model stability, communication overhead, and privacy preservation. We explore various forms of heterogeneity and their impact on model performance. Solutions to non-IID data, resource-constrained platforms, and personalized learning are reviewed in an effort to show the complexities of handling heterogeneous data distributions. Next, we review techniques for ensuring model stability and avoiding catastrophic forgetting, which are critical in non-stationary environments. Privacy-preserving techniques are another aspect of FCL that have been reviewed in this work. This survey has integrated insights from federated learning and continual learning to present strategies for improving the efficacy and scalability of FCL systems, making it applicable to a wide range of real-world scenarios.", "sections": [{"title": "1. Introduction", "content": "The increasing number of interconnected devices and the growing demand for the use of intelligent systems in practice has sparked the interest into the concepts of distributed and incremental learning [1, 2]. A noticeable trend is Federated Learning (FL), which has established itself as an efficient mechanism to accomplish collaborative training of machine learning models across decentralized devices and resolve privacy and communication issues by keeping data where it belongs [3, 4]. On the other hand, Continual Learning (CL) aims to solve the problem of forcing models to learn and forget knowledge as the target data distribution changes, and, thus, it is relevant to non-static scenarios [1, 5]. There is growing interest in the broader distribution and generation of information. Consequently, FCL has attracted significant attention from researchers for its ability to integrate the strengths of FL and CL, making it ideal for practical applications such as distributed and incremental learning.\nFCL draws the foundation from the literature in FL and CL [6]. FL addresses key challenges such as data and system heterogeneity, communication overhead, and privacy preservation in distributed systems. It enables global model training across diverse clients without centralizing data. However, it assumes static data distributions, making it less suited for dynamic environments where data streams continuously. While CL addresses issues with the presence of non-stationary data, a method that could deal with issues through techniques such as experience replay, regularization, or modification in architecture so as to ensure models stay time-robust and adapt to new incoming tasks without forgetting obtained knowledge in the previous state. FCL bridges between these domains by integrating FL concepts along with CL to effectively control evolving data [7, 8]. For example, heterogeneity and privacy challenges brought about by FL are more complex in FCL because data streams dynamically, while solutions provided for incremental learning should be adapted to work under FL constraints such as non-IID data and limited communication [9]. These cross-domain interactions help us to better understand how existing research on FL and CL is fundamentally important in advancing FCL.\nFCL is imperative in facilitating intelligent systems, where data is both distributed and non-stationary. The application of FCL ranges from personalized healthcare to real-time IoT analytics and edge-based autonomous systems [10, 11]. Some of the unique challenges in FCL, such as addressing global and local catastrophic forgetting, heterogeneous client behavior, and scalable knowledge transfer across clients, remain barely explored in the literature. These challenges require new methodologies that effectively combine FL's focus on collaboration and privacy with CL's ability to adapt over time. Furthermore, practical issues such as dynamic client participation, resource constraints, and real-world non-IID data distributions make things even more complicated. Despite its promise, the area of FCL lacks a comprehensive overview of its challenges, methodologies, and applications. This gap calls for a dedicated survey to consolidate knowledge, identify open problems, solutions, and guide future research.\nCurrently, the literature offers only a couple of surveys on FCL. The first published survey categorizes methods based on knowledge fusion mechanisms and introduces synchronous and asynchronous FCL frameworks[6]. In addition, a recent preprint focuses on FCL within Edge-AI environments, with an emphasis on task-specific classifications and hardware-algorithm co-design [12].While these surveys have contributed valuable insights on FCL, focusing on knowledge fusion, task-specific classifications, and Edge-AI contexts. However, they lack a comprehensive taxonomy of key challenges, such as heterogeneity, communication overhead, and model stability, and offer limited cross-domain insights from FL and CL. This survey aims to build on prior works to address these gaps.\nThis survey addresses the pressing need for a detailed examination of FCL, motivated by its relevance to real-world applications and the open problems in the field. By systematically exploring how FL and CL challenges converge in FCL, this work aims to provide researchers with a clear understanding of the domain's current state and future directions. Specifically, it highlights critical issues such as catastrophic forgetting in federated settings, non-stationary client environments, and the interplay of privacy, communication, and computational constraints. By bridging the gap between FL and CL, this survey aims to serve as a foundational reference for developing robust and scalable FCL systems, ultimately contributing to the broader adoption of intelligent, adaptive, and decentralized AI solutions.\nThe remainder of this survey is organized as follows. Section 2 reviews the preliminaries of concepts such as FL, CL, and FCL. Section 3 discusses challenges and solutions associated with FL comonents of FCL. Section 4 elaborates on diffiaulties of CL and the potential solutions. Section 5 explains problems that are specific to FCL and overviews the key approaches for mitigating them. Section 6 elaborates on future research directions that are crucial in FCL. Finally, the paper is concluded in Section 7."}, {"title": "2. Federated Continual Learning", "content": "The data-driven world requires learning from continuous data in a distributed manner, while respecting privacy. FCL emerges as a robust solution for scenarios involving both collaborative learning and streaming data. FCL seamlessly integrates FL principles with the capability to manage continuous data streams, offering a versatile and efficient approach to contemporary data challenges. By leveraging FCL, it is possible to achieve the dual objectives of collaboratively training models without centralized data collection and maintaining up-to-date models through continual learning from streaming data.\nThe first step toward understanding FCL is to understand its base ideas: FL and CL. FL refers to a variety of model training that involves multiple devices/nodes in collaboration, not sharing raw data with each other for privacy and scalability reasons. On the other hand, CL deals with models' capabilities of incremental learning on non-IID evolving data streams, while retaining knowledge of previous tasks. These two paradigms, while different, meet at the intersection of FCL in the quest to build models that continuously learn from new data without violating the privacy and heterogeneity of decentralized systems. In-depth knowledge of FL and CL puts one in a better perspective to understand the challenges and opportunities that come with FCL."}, {"title": "2.1. Federated Learning", "content": "FL is a collaborative method for training machine learning models across multiple devices or nodes with the guarantee that raw data would remain on the local devices. It is motivated by the urgent need for privacy-preserving and efficient learning systems in recent distributed environments, such as smartphones, IoT devices, and edge computing networks. In particular, unlike traditional, top-down approaches to learning in a decentralized system, FL lets owners of data participate in training the model without necessarily revealing personally identifiable or commercially sensitive information.\nBy keeping data decentralized, FL protects user privacy and also allows compliance with strict data protection regulations, such as GDPR. It reduces the risk of data breaches and ensures that the training data remains local; hence, trust among participants can be fostered. FL also leverages the heavy computational power of distributed devices, hence enhancing scalability, and, thus, enabling the creation of models that can make the most out of diverse data sources. This generally results in more generalizable and robust models for applications in which data across users may vary substantially, such as personalized recommendation systems, healthcare, and autonomous systems. FL will be capable of harnessing decentralized data and resources, thus becoming one of the cornerstones for developing intelligent, privacy-aware systems in modern, connected environments."}, {"title": "2.2. Continual Learning", "content": "In dynamic environments such as real-time sensor networks or streaming applications, data is continuously generated and needs to be processed in a timely manner. For instance, consider a smart city scenario where traffic cameras, weather sensors, and social media feeds constantly produce data streams. In such an environment, which is known as non stationary environment, it is essential for models to be updated continuously with new data to maintain their performance. However, traditional models often struggle to adapt to changes in data distributions, leading to a decrease in performance over time. This challenge is addressed by CL, which focuses on the ability to incrementally learn from new data, while retaining knowledge from previous tasks [1, 13]. By effectively managing the evolving nature of data, CL ensures that models remain robust and adaptable, preventing the degradation of performance that can occur with static training methods.\nCL provides several significant advantages that enhance the effectiveness and adaptability of machine learning models. These key benefits include incremental learning, knowledge transfer, avoiding catastrophic forgetting, adaptability and flexibility, resource efficiency, improved generalization, and application versatility. Firstly, CL allows models to learn incrementally, building on previously acquired knowledge and enabling adaptation to new tasks without forgetting old ones, which is particularly useful in dynamic environments, where data evolves over time [5]. Secondly, it facilitates the transfer of knowledge from one task to another, improving learning efficiency for new tasks by leveraging previously acquired skills, thereby leading to faster learning and better performance on related tasks [14, 15].\nFurthermore, a main advantage is its ability to mitigate catastrophic forgetting, using techniques such as experience replay, regularization, and dynamic architecture growth to maintain old knowledge [16]. Additionally, CL models are highly adaptable, making them suitable for non-stationary, continuously changing real-world applications [17]. Moreover, they emphasize resource efficiency by reusing existing knowledge and minimizing the need for retraining, which leads to significant savings in computational resources and time. For instance, [18] introduces a method for performing text classification using pre-trained transformers on a sequence of classification tasks, achieving significant memory efficiency and faster inference time compared to state-of-the-art methods, while maintaining competitive predictive performance without requiring extensive retraining. By continually learning from new data, CL models also improve their generalization capabilities, making them more robust to data variations and better at handling unseen scenarios [19]. Finally, CL has broad applications across various domains, including robotics, healthcare, and autonomous systems, where the ability to learn and adapt continuously is critical [20]."}, {"title": "3. Challenges of Federated Learning", "content": "Part of the challenges in FCL are assocciated to the FL structure of this approach as detailed in this section."}, {"title": "3.1. Heterogeneity", "content": "In collaborative learning, different clients contribute to training, which can enhance overall training performance by leveraging server computational power and improving convergence rates and globalization [21, 22]. However, this diversity can introduce heterogeneity, stemming from factors such as geographical differences, variations in data source distribution, differing data formats, inconsistent data quality, variations in data collection methods, discrepancies in labeling practices, and differences in feature representation [23]. Heterogeneity, which refers to the presence of differences and diversity within a set of elements, is one of the prominent challenges in collaborative learning. [24] highlights the severe impacts of device and behavioral heterogeneity on model performance, showing substantial degradation in model quality and fairness. Another study on dialogue generation focuses on branch homogeneity problems in collaborative learning and proposes methods to enhance branch heterogeneity for improved performance [25]. Tailored strategies are essential for managing heterogeneity, as it can hinder the effectiveness of collaborative learning. Effective management is crucial to fully realize the potential of collaborative learning. This subsection explains different types of heterogeneity and proposes methods to address them effectively, categorizing heterogeneity into two primary types: data heterogeneity and system heterogeneity.\nData heterogeneity arises from the varied nature of data contributed by different clients. Data heterogeneity is generally classified into statistical and conceptual subsets, each of which presents a distinct challenge that needs to be addressed in detail."}, {"title": "3.1.1. Statistical Heterogeneity", "content": "Statistical heterogeneity refers to differences in the statistical properties of datasets used by different nodes in a distributed learning system. This can include variations in data distributions, sample sizes, and data quality across different sources. Two critical subsets of statistical heterogeneity are Non-IID (Independent and Identically Distributed) data and imbalanced data.\nNon-IID Data. Many machine learning algorithms assume that the training data are independent and identically distributed (IID), meaning each data point is independent of others and follows the same probability distribution. When data from different clients violate this assumption, they are considered non-IID. These dependencies arise from differences in input space or behavioral differences among clients.\nDifferences in input space occur when client i and client j contribute to the training and their local datasets have different distributions $P(x_i) \\neq P(x_j)$. On the other hand, behavioral differences refer to variations in the way different clients generate, collect, or label their data, leading to different perspectives on events for the machine learning models $P(y_i|x_i) \\neq P(y_j|x_j)$. These differences can impact the performance of machine learning models trained on such datasets. Imagine a smart home energy management system deployed across households in different regions, each acting as a client contributing data to a global energy optimization model. Client i in Region A (temperate climate) has energy usage peaks during winter for heating and summer for cooling, with high Heating, Ventilation, and Air Conditioning (HVAC) consumption. Client j in Region B (tropical climate) has consistently high energy usage for cooling year-round. Thus, their energy consumption patterns differ significantly ($P(x_i) \\neq P(x_j)$). Households in Region A follow consistent daily routines, leading to predictable energy usage peaks in the morning and evening. In contrast, households in Region B have varied routines, with unpredictable energy usage patterns throughout the day. These behavioral differences lead to variations in energy consumption metrics $P(y_i|x_i) \\neq P(y_j|x_j)$. To address Non-IID data as a prominent challenge in distributed systems, the proposed methods are reviewed here to clarify the importance of each way.\nTo address changes in the input space through clients, three different methods are proposed. Firstly, domain transformation involves techniques designed to align the data distributions from multiple clients to create a more unified input space for a machine learning model. One approach focuses on domains with particular features, leveraging the unique characteristics of each domain to enhance performance. For instance, studies [93, 94, 95] address the issue that each domain may have its own unique set of features to characterize samples, leading to incompatibilities across domains, and they develop methods to extract a common feature representation. To talk in detail, deep learning models are utilized for learning complex relations between features [96], and domain generalization [97]. Moreover, [98] proposed an approach in which feature transformation and KL divergence minimization are used to align source and target data distributions. Another approach, performed in [99, 100, 101, 102, 103, 104], is domain factorization, which decomposes data into shared and domain-specific components using methods such as matrix factorization. This isolates common patterns and unique features, allowing models to better understand the underlying structure. These techniques improve the robustness and effectiveness of machine learning models across diverse datasets.\nMoreover, due to the significant variations in data distributions across different clients, personalization in FL is essential for addressing changes in the input space. This approach involves tailoring a global machine learning model to better fit the unique data and usage patterns of individual users. By doing so, the model becomes not only broadly effective but also finely tuned to the specific needs and behaviors of each user. [105] underscores the importance of personalization, while [106] explores methods to enhance the performance of FL models by incorporating personalization techniques, thereby addressing the challenges posed by data heterogeneity across different clients. Personalization methods are categorized into two subsets of client level personalization and group level personalization. Client level personalization tailors the model to the specific data characteristics and patterns of each individual client. For instance, [107] address the heterogeneity of data across different clients by learning personalized self-attention layers for each client, while aggregating other parameters among clients. Also, [108] aims to customize the global machine learning model to better fit the unique data distributions of individual clients. Another idea, explored in [109, 110, 111], involves adapting algorithms from the Model-Agnostic Meta-Learning (MAML) framework for use in FL settings. Instead of personalizing the model for each individual client, in group level personalization the model is tailored for groups with homogeneous data distributions. [112] leverages group-level personalization by clustering clients based on inference similarity, addressing the non-IID data distribution problem and enhancing the overall performance and efficiency of FL models.\nAnother approach for addressing the changes in clients' input space is domain adaptation, which addresses the challenge of adapting a model trained on one domain (source domain) to perform well on a different but related domain (target domain) [113]. [114] provides a comprehensive overview of the methods and techniques used in multi-source domain adaptation (MSDA), addressing challenges such as class distribution alignment and domain shifts. There are three different approaches for domain adaptation, dissimilarity methods, sample reweighting, and Generative Adversarial Networks (GANS) [115, 116, 117]. Dissimilarity methods aim to reduce the difference between the source and target domain distributions by explicitly measuring and minimizing discrepancies. These methods often focus on aligning the statistical properties of the two domains. For instance, [118] proposes the Manifold Maximum Mean Discrepancy (M3D) to measure and minimize local distribution discrepancies. On the other hand, [119] introduces a novel method for unsupervised domain adaptation (UDA) that leverages similarity learning to improve the classification performance on an unlabeled target domain using features learned from a labeled source domain. Sample Reweighting is another approach, which involves adjusting the weights of source domain samples to make the source distribution more similar to the target distribution. In particular, [120] proposes a reweighting method for model aggregation in FL that considers the volume and variance of local datasets among clients to address the issue of class label heterogeneity. Also, [121, 122] propose methods to learn across various domains in Natural Language Processing (NLP) tasks by leveraging confidence-weighted parameter combinations, parameter combinations from multiple classifiers. Besides, GANS are used in domain adaptation to generate synthetic data that bridges the gap between the source and target domains. By training a generator and discriminator[117], GANs can create data that is indistinguishable from the target domain, facilitating better adaptation. Accordingly, several papers have contributed significant insights and methodologies, for instance, by leveraging multiple adversarial networks [123], considering a more realistic setting compared to traditional domain adaptation, where it is often assumed that the label spaces of the source and target domains are fully shared [124], using deep models, particularly when only a few labeled samples are available in the target domain [125], and addressing challenges of improving generalization in FL environments, where domain shifts occur [126]. After exploring changes in the input space and the methods for addressing these challenges, it is time to address the changes in the behavior of clients' datasets, which are categorized into"}, {"title": "Imbalanced Data", "content": "Besides non-IID data, imbalanced data is another subset of statistical heterogeneity, which refers to a situation where certain classes or labels in the dataset are under-represented compared to others. This imbalance can lead to biased model performance, favoring the majority class and neglecting the minority class. Imbalanced data is categorized into two subsets, which are unequal sample sizes and skewed data distribution. When different classes in the dataset have a vastly different number of samples causes unequal sample sizes, leading to fail in correctly classifying the minority class due to the overwhelming presence of the majority class. This can result in high accuracy for the majority class but poor performance for the minority class, which is often more critical in applications such as fraud detection, intrusion detection, or disease diagnosis. To address this challenge, techniques such as undersampling the majority class or over-sampling the minority class are commonly used, which is explored in [139, 140, 141]. On the other hand, skewed data distribution refers to the asymmetry in the data distribution for a particular variable or feature, which means that the frequency of occurrence of some classes is significantly higher than others, leading to a disproportionate representation of classes, making it difficult for models to learn the decision boundary for the minority class. This often results in poor generalization of new data, especially for the minority class. Addressing skewed distributions involves strategies such as clustering and density-based approaches to balance the data before training [142]. The upper part of Figure 1, statistical heterogeneity, is addressed through this part, in which most of the solutions are the subsets of FL. In the following part the conceptual heterogeneity and its subsets are addressed."}, {"title": "3.1.2. Conceptual Heterogeneity", "content": "Conceptual heterogeneity arises from differences in data distribution, computational power, and network conditions among participating nodes, leading to challenges in achieving efficient and robust training performance. This discussion focuses on the subset of conceptual heterogeneity related to data heterogeneity, where clients have different types of data. These differences manifest in label distribution or feature distribution, as depicted in the middle part of Figure 1. When considering label distribution heterogeneity, different clients may have datasets with varying sets of labels (diverse label sets). For example, one node might have data labeled for dog breeds, while another has labels for car models, complicating the training of a unified model. To address this, [133] proposes FL along with a multi-task learning approach to enable each client to learn its specific task, while simultaneously sharing and benefiting from a common representation or model, thereby improving both individual and global learning outcomes. Besides, [143] by proposing an unsupervised domain adaptation approach aims to improve the performance of a model on a target domain (which has no labeled data) by leveraging labeled data from a source domain. Finally, [144] reviews transfer learning, in which the core idea is to transfer the representations, parameters, or knowledge from the source task to the target task, thereby enhancing the model's performance on the target task despite differences in label distributions.\nThis helps in dealing with diverse label sets by accommodating varying tasks and labels. Additionally, inconsistencies in how data is labeled across different clients (inconsistent labeling) can occur. For instance, one node might label an image as \"cat\", while another node labels a similar image as \"feline\", leading to confusion during model training. [3] introduces an approach in which clients can periodically align their labeling schemes through consensus mechanisms, ensuring that the labels become more consistent over time. This can be done through FL protocols that involve occasional exchanges of labeled examples or metadata. Also, [145] addresses inconsistent labeling by aligning feature distributions between source and target domains using deep adaptation layers and domain adversarial training (label normalization and standardization). This creates a shared feature space, minimizing the impact of label discrepancies. Semi-supervised learning is another approach, which is reviewed in [146], to address inconsistent labeling by leveraging a small amount of labeled data along with a large amount of unlabeled data to improve the overall labeling quality. Feature distribution heterogeneity occurs when clients have different features available in their datasets (varying feature sets) or when the scale of features varies across nodes (feature scaling differences). For example, in a healthcare system using datasets from several hospitals, one hospital might record patient data with features such as age and weight, while another hospital records features such as blood pressure and cholesterol levels, complicating model integration. Methods such as feature alignment techniques [147], data augmentation [148], and collaborative feature selection [149] are utilized for addressing this challenge. Feature scaling differences arise if one hospital records blood pressure in mmHg, while another records it in kPa. In this case, standardization and normalization [150], Federated Preprocessing [151], and Metric Learning [152] are proposed for addressing this.\nWhen different clients participate in training a model their differences in the components and capabilities lead to system heterogeneity. This heterogeneity can be broadly categorized into two main subsets: hardware heterogeneity and software heterogeneity. Hardware heterogeneity encompasses differences in computational power, memory and storage capacities, and network connectivity among the devices. For example, some devices might have high-end processors capable of fast computations, while others may have limited processing power, leading to synchronization issues during model training. Similarly, variations in memory and storage capacities can result in some nodes struggling with large datasets or complex models, creating bottlenecks. Diverse network connectivity also plays a role, with some devices connected via high-speed broadband and others relying on slower mobile data, affecting data transmission rates and overall system efficiency. On the other hand, software heterogeneity involves the diversity of operating systems, software versions, and programming languages or frameworks used across different nodes. Devices in the system might run on various operating systems such as Android, iOS, Windows, or Linux, requiring robust software solutions that are compatible across all platforms. Different versions of the same software or libraries can cause execution inconsistencies, necessitating careful version control and updates. Additionally, the use of various programming languages and frameworks, such as Python, Java, TensorFlow, or PyTorch, requires interoperability solutions to integrate these diverse technologies seamlessly. Addressing both hardware and software heterogeneity is crucial for the efficient and effective operation of FL and distributed systems, ensuring consistent performance and reliability across all nodes."}, {"title": "3.2. Resource Constraints", "content": "Collaborative machine learning, where multiple users contribute their computational power and data, is promising but faces significant challenges due to resource constraints. These constraints can limit the efficiency and effectiveness of the collaborative learning process. Accordingly, [153] states that heterogeneity and limited computation and communication resources are the key factors that challenge machine learning at the network edge. These constraints hinder efficiency in the application of edge servers in collaborative learning processes, most especially under edge-cloud collaborative machine learning systems. This makes achieving an optimal balance between learning performance and resource consumption challenging. Additionally, in Federated Edge Learning (FEEL), the high communication costs due to the involvement of numerous remote devices pose a significant resource constraint. Efficient algorithms that speed up convergence can help alleviate these costs, which is addressed by [154]. Moreover, collaborative machine learning techniques such as FL often suffer from low resource utilisation due to sequential computation and communication, which limits their efficiency. Leveraging pipeline parallelism can significantly improve resource utilisation and reduce training time [155]. Moreover, dynamic resource allocation and task offloading in multi-access edge computing (MEC) environments can help overcome resource constraints by optimizing the use of available resources and minimizing energy consumption, while meeting delay constraints [156]."}, {"title": "3.3. Communication Overhead", "content": "In collaborative machine learning, multiple devices work together to train a model. This process, while beneficial, introduces significant communication overhead, which can hinder efficiency and scalability. Effective strategies to reduce communication overhead are crucial for optimizing the collaborative learning process. Several factors lead to communication overhead, including communication-efficient FL, local updates before communication, compression techniques, selective communication strategies, and decentralized learning algorithms. Frequent model updates in FL involve continual exchange of updates among devices, leading to significant communication delays. Strategies such as probabilistic device selection, quantization methods, and efficient wireless resource allocation can help reduce to communication load and improve convergence speed [157, 158, 159]. These strategies collectively enhance FL's performance and scalability by mitigating communication overhead."}, {"title": "3.4. Model Stability", "content": "When multiple clients participate in the training process, it is crucial to consider the global model's ability to maintain consistent and reliable performance as it is updated over multiple rounds with data from various distributed sources. This is the essence of model stability, which involves managing the inherent variations and challenges posed by the FL environment. Key aspects of model stability include consistent performance, convergence, and scalability. Consistent performance means that the model should show stable performance metrics across different training rounds, avoiding significant fluctuations. Convergence ensures that the model parameters and performance metrics gradually stabilize, indicating effective learning and adaptation. Scalability involves the model's ability to maintain stability and performance as the number of participating clients increases, handling the added complexity and variability without degradation. Together, these factors contribute to a robust and reliable global model that generalizes well across diverse and distributed client data.\nSeveral techniques can be employed to enhance model stability in FL, including Federated Averaging (FedAvg), regularization, learning rate scheduling, data augmentation, client selection strategies, and adaptive aggregation. The FedAvg algorithm, introduced by [3], enhances model stability by allowing clients to perform local updates on their data and then averaging these updates to form a global model. This method significantly reduces communication overhead and maintains robust performance, even with non-IID data distributions, contributing to consistent and reliable model training across multiple rounds.\nApplying regularization techniques (e.g., L2 regularization, dropout) is another approach to prevent overfitting and ensure smoother convergence. [160] demonstrates that dynamic regularization can significantly improve the robustness and effectiveness of FL models. Learning rate scheduling, which involves dynamically adjusting the learning rate, helps ensure steady progress in model updates and prevents overshooting or slow convergence.\nTo address model stability, enhancing the diversity of training data on clients through data augmentation is essential. [161] proposes a FL method based on data augmentation, abbreviated as FedM-UNE, which implements the classic data augmentation technique MixUp in federated scenarios without transferring raw data. This approach aims to enhance model stability and performance by leveraging the benefits of data augmentation, while maintaining data privacy and minimizing communication overhead.\nMoreover, selecting a representative subset of clients for each training round is important to balance the contributions from different data distributions, which can tackle model instability. [162] proposes a client selection strategy that considers both the computational capabilities and communication bandwidth of clients to optimize the training process. By prioritizing clients with adequate resources, the method aims to reduce training time and improve the overall efficiency and performance of FL. Using adaptive methods for aggregating model updates, such as weighting updates based on the quality or quantity of client data, is another approach for tackling the model instability problem. [163] proposes an approach that includes adaptive aggregation methods and client selection strategies to optimize the utilization of computational and communication resources. By adapting to the varying resource constraints of edge devices, the proposed framework aims to improve the efficiency, scalability, and performance of FL."}, {"title": "3.5. Privacy Preservation", "content": "When different clients participate in training models, privacy preservation is essential to protect sensitive data, comply with regulatory requirements, maintain user trust, mitigate risks, and enhance data utility. By implementing robust privacy-preserving techniques, organizations can ensure the secure and responsible handling of data in distributed environments, fostering a safer and more trustworthy digital ecosystem [164]. Several techniques and frameworks have been developed to address these concerns effectively.\nHomomorphic Encryption (HE). It is a powerful cryptographic mechanism that enables computations to be performed directly on encrypted data, eliminating the need for decryption during processing. This approach ensures that data privacy is maintained throughout the computational process. In the context of FL, HE can be applied to encrypt local model parameters before they are transmitted to a centralized server. The server then aggregates these encrypted parameters without decrypting them, thereby preserving the privacy of individual data points and preventing any potential exposure of sensitive information [165, 166, 167].\nDifferential Privacy (DP). It is a technique that enhances data privacy by adding controlled noise to the data or model parameters, thereby preventing the extraction of sensitive information while preserving the overall utility of the data. In FL, Local Differential Privacy (LDP) can be employed to add noise to the data before it leaves the user's device. This method ensures that the central server, which aggregates the data from various users, cannot infer any private information from the aggregated data, effectively maintaining user privacy. For instance, [168] introduces a framework where artificial noise is added to client parameters before aggregation to ensure privacy. This method, called \"noising before model aggregation FL\" (NbAFL), satisfies differential privacy by adjusting noise variance. The authors also develop a theoretical convergence bound, showing a trade-off between privacy and performance, and propose a K-client random scheduling strategy to optimize this trade-off. Evaluations confirm that the theoretical results match simulations, aiding the design of privacy-preserving FL algorithms.\nSecure Multi-Party Computation (SMC). This approach allows multiple parties to collaboratively compute a function over their inputs, while ensuring that each party's inputs remain private. This mechanism ensures that no single party gains access to all the data, preserving the confidentiality of individual inputs. In FL frameworks, SMC can be employed to securely aggregate model updates from multiple users, thereby preventing the exposure of their individual data. This method provides a robust guarantee of data privacy, making it a vital tool for maintaining security and trust in collaborative machine learning environments [169].\nSecure Aggregation. Secure aggregation protocols ensure that individual updates from local models are securely aggregated without exposing individual contributions. These protocols are"}, {"title": "4. Challenges of Continual Learning", "content": "Despite the advantages of CL, streaming data inherently leads to concept drift, a phenomenon where the underlying data distribution changes over time, which can lead to a decrease in model performance as the data distribution evolves."}, {"title": "4.1. Concept Drift", "content": "Concept drift can be categorized into three main types: virtual drift, real drift, and hybrid drift."}, {"title": "4.1.1. Virtual Drift", "content": "Virtual drift, also known as temporary drift [193], sampling shift [194], and feature change [195], refers to changes in the distribution of input data $P(X)$ over time without altering the underlying relationship between inputs and outputs. For instance, consider an e-commerce website, where the traffic sources initially consist of 50% from search engines, 30% from social media, 10% from email campaigns, and 10% from direct visits.\nOver time, due to new marketing strategies, this distribution shifts to 30% from search engines, 50% from social media, 10% from email campaigns, and 10% from direct visits. This shift, while not changing the relationship between traffic and sales, can cause the predictive model based on the original data to perform poorly. To maintain accuracy, the model must be updated to reflect the new distribution of traffic sources."}, {"title": "4.1.2. Real Drift", "content": "On the other hand, real drift occurs when the relationship between the input data and the target variable $P(y|X)$ changes over time. This means the underlying concept that the model is trying to learn is itself changing. For instance, in a financial market prediction model, the factors that influence stock prices may change due to new regulations, economic policies, or shifts in market dynamics. As a result, the relationship between the input features (e.g., economic indicators) and the target variable (e.g., stock prices) changes."}, {"title": "4.1.3. Hybrid Drift", "content": "Hybrid drift involves both virtual and real concept drifts occurring simultaneously. This means that there are changes in the data distribution $P(X)$ as well as changes in the underlying relationship between the features and the target variable $P(y|X)$. Hybrid concept drift is particularly challenging because it requires models to adapt to both types of changes simultaneously. For example, in a recommendation system for an online store, the types of products offered (input distribution) might change, and at the same time, customer preferences (relationship between inputs and outputs) might also change.\nAfter exploring the various changes in data distribution caused by streaming data, this section proposes and addresses the different challenges that occur in non-stationary environments, including dealing with limited data, managing class incremental learning, and mitigating catastrophic forgetting."}, {"title": "4.2. Solutions", "content": "To effectively address these changes over time", "196": ".", "into": "rehearsal methods and generative methods. On the one hand rehearsal methods store a subset of previous data and mix it with new data during training, which can prevent catastrophic forgetting. For instance, [197", "198": "which selectively rehearses past experiences that are most likely to suffer interference from new data. Accordingly, [199", "200": "utilizes meta-learning to enable the model to learn continually. Inspired by human concept learning, a generative classifier is developed that effectively leverages data-driven experiences to learn new concepts from just a few samples, while remaining immune to forgetting. This"}]}