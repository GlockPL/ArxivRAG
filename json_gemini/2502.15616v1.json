{"title": "Pastiche Novel Generation: Creating Fan Fiction You Love in Your Favorite Author's Style", "authors": ["Xueran Han", "Yuhan Liu", "Mingzhe Li", "Wei Liu", "Sen Hu", "Rui Yan", "Zhiqiang Xu", "Xiuying Chen"], "abstract": "Great novels create immersive worlds with rich character arcs, well-structured plots, and nuanced writing styles. However, current novel generation methods often rely on brief, simplistic story outlines and generate details using plain, generic language. To bridge this gap, we introduce the task of Pastiche Novel Generation, which requires the generated novels to imitate the distinctive features of the original work, including understanding character profiles, predicting plausible plot developments, and writing concrete details using vivid, expressive language. To achieve this, we propose WriterAgent, a novel generation system designed to master the core aspects of literary pastiche. WriterAgent is trained through a curriculum learning paradigm, progressing from low-level stylistic mastery to high-level narrative coherence. Its key tasks include language style learning, character modeling, plot planning, and stylish writing, ensuring comprehensive narrative control. To support this, WriterAgent leverages the WriterLoRA framework, an extension of LORA with hierarchical and cumulative task-specific modules, each specializing in a different narrative aspect. We evaluate WriterAgent on multilingual classics like Harry Potter and Dream of the Red Chamber, demonstrating its superiority over baselines in capturing the target author's settings, character dynamics, and writing style to produce coherent, faithful narratives. We hope this work inspires literary creativity in NLP: WriteAgent.", "sections": [{"title": "1 Introduction", "content": "Novels create rich, immersive worlds with intricate plots and distinct styles, captivating readers through complex storytelling (Bai et al., 2024). A significant amount of research (Ammanabrolu et al., 2020; Yao et al., 2019) has proposed new model architectures to improve story generation. With the emergence of LLMs, recent efforts have shifted towards improved prompt-based techniques (Wang et al.; Han et al., 2024). For example, Ma et al. (2024) proposed modular premise synthesis, providing concrete information such as background, persona, and theme to guide the generation process. While these methods have enhanced novel generation performance (Hu et al., 2024b), they fall short in capturing the irreplaceable qualities of real-world literary classics: engaging plots, vivid characters, and distinctive language that immerse readers in complex and authentic storytelling.\nHence, in this work, we propose the Pastiche Novel Generation task, which aims to generate novels that faithfully emulate the original author's style and narrative depth. This task presents two key challenges: (1) plot planning that aligns with the novel's established worldview and character dynamics, and (2) stylish writing that produces narrative text reflecting the target author's personalized writing style. As illustrated in Figure 1, for instance, given the rich context of Dream of the Red Chamber, with its intricate interpersonal conflicts and lavish lifestyles, the model should predict significant plot outcomes, such as the eventual downfall of the Jia family. Additionally, the model must accurately reproduce the linguistic and stylistic features of the original text, including evocative phrases like \"rolled up their sleeves\" and \"please issue the decree\", which reflect the author's unique writing style.\nTo address these challenges, we propose WriterAgent, a novel generation model designed to emulate a target author's writing style. The model is trained in sequence on four core tasks to master key narrative and stylistic elements of the author's work. This sequential training follows the natural writing process, from conceptual elements like language style and world-building to high-level plotting and fine details: 1) Language Style Learning: Teaching the LLM to capture the author's distinctive writing style through tasks like next-word prediction, ensuring consistent character voices. 2) World Building: Guiding the model to introduce characters and define their relationships, constructing an interconnected world aligned with the original narrative. 3) Plot Planning: Enabling the model to generate coherent plotlines that evolve character arcs in line with the story's structure. 4) Stylish Writing: Enhancing descriptive details of settings, character interactions, and events, ensuring immersive storytelling that reflects the author's tone and depth. To train WriterAgent efficiently, we propose Writer-LoRA, an extension of the Low-Rank Adaptation (LORA) (Hu et al., 2021). The original LoRA A and B matrices act as a general expert, preserving the original text's style as a reference. We augment this with specialized B matrices dedicated to specific aspects such as world-building, plot, and detail writing, trained sequentially in a curriculum-based approach from simple to complex tasks.\nWe evaluated WriterAgent on the English Harry Potter series and the Chinese Dream of the Red Chamber. Given the absence of prior work on the personalized novel generation task, we developed a set of automatic metrics to assess writing style, including language style, expression methods, and sentence complexity, and plot development, covering the story mainline, character behavior, and emotions. Both automatic evaluations and human annotations demonstrate that WriterAgent effectively captures the target author's style and constructs coherent, engaging narratives.\nOur main contributions are as follows: (1) We introduce the Pastiche Novel Generation task, which aims to generate novels that mimic a target author's style, narrative structure, and character development. (2) We develop WriterAgent, an LLM with a WriterLoRA structure, trained to learn character profiles, predict future plotlines, and reconstruct full stories, enabling consistent and context-aware storytelling. (3) We demonstrate that WriterAgent outperforms baseline models in mimicking multilingual classics such as Harry Potter, which highlights new possibilities for literary creativity and personalized storytelling."}, {"title": "2 Related Work", "content": "Story Generation. The task of long-form story generation has received significant attention in recent years due to advancements in LLMs. Early approaches primarily focused on developing new modules to enhance narrative coherence and consistency. For example, Ammanabrolu et al. (2020); Fan et al. (2019, 2018) leveraged graph structures to organize events more effectively and improve narrative consistency. Another example is Peng et al. (2018), which introduced an interface for human-computer interaction to generate personalized stories and applied it to RNN-based models for controlling story endings and storylines. However, these methods often struggled to maintain coherence and consistency over extended sequences. More recently, prompt engineering techniques have been adopted to tap into the generative power of LLMs (Giray, 2023). For instance, Han et al. (2024) proposed a director-actor agent collaboration framework for controllable and interactive drama script generation, while Huang et al. (2023) explored dynamic beam sizing and affective reranking to generate engaging narratives.\nDespite these advancements, existing methods lack a framework to emulate complex narratives and distinct authorial styles, essential for real-world long-form novel writing.\nParameter-Efficient Fine-Tuning. Parameter-efficient fine-tuning (PEFT) (He et al.) reduces the computational costs of fine-tuning LLMs by introducing additional modules, avoiding direct updates to the large-scale pretrained weights. Adapters (Houlsby et al., 2019) insert extra feature transformations between model blocks, while prefix tuning (Li and Liang, 2021) optimizes parameters through learnable prefixed embeddings without modifying the pretrained weights. More recently, LORA (Hu et al., 2021) introduces low-rank"}, {"title": "3 Problem Formulation", "content": "We begin by introducing the notations and key concepts for the task of personalized long-form novel generation. Formally, the training dataset for a novel is hierarchically structured into character profiles, plots, and words. Each character profile Ci consists of the i-th character's name and a detailed description, including key traits and relationships with other characters. The narrative text is divided into segments of words $(x_1, x_2,...,x_n)$, each corresponding to an individual plot summary $P_j$, where j represents the plot index within the chapter. These plots $\\{P_j\\}$ capture the key story developments within their respective text segments.\nThe task involves two core subtasks: (1) plot prediction, where the model predicts the next plot $P_t$ based on previous plots $\\{P_1,..., P_{t-1}\\}$ and ensures logical consistency by comparing it to the ground truth plot $P_t$; (2) stylish writing, where the model generates a word sequence $Y_t = \\{x_1,x_2,..., x_n\\}$ from the predicted plot $P_t$ and ensures coherence and stylistic alignment by comparing it to the ground truth text $Y_t = \\{X_1,X_2, ..., X_n\\}$."}, {"title": "4 Method", "content": "In this section, we first introduce the vanilla LoRA, then present our adapted WriterLoRA built on it, along with the overall WriterAgent framework, as shown in Figure 2.\n4.1 Preliminaries\nLORA fine-tunes LLMs efficiently by adding trainable low-rank matrices instead of updating all parameters, reducing computational cost. Concretely, a pre-trained weight matrix $W_0 \\in \\mathbb{R}^{d \\times k}$ is updated using a low-rank decomposition $W_0 + \\Delta W = W_0 + BA$, where $B \\in \\mathbb{R}^{d \\times r}$ and $A \\in \\mathbb{R}^{r \\times k}$, with $r < min(d, k)$. Here, B and A are the trainable low-rank matrices, and r represents the rank of the decomposition. During training, $W_0$ is frozen and does not receive gradient updates, while A and B are optimized. Given an input $x \\in \\mathbb{R}^k$, the forward pass through the modified weight matrix is:\n```latex\nh' = W_0 x + \\Delta Wx = W_0 x + BAx. (1)\n```\nHere, A serves as an encoder-like transformation, mapping $x \\in \\mathbb{R}^k$ into a lower-dimensional representation $z \\in \\mathbb{R}^r$, while B acts as a decoder-like transformation, projecting z back into output space.\n4.2 Curriculum Learning Tasks\nOur training tasks are inspired by real-world observations of how authors create novels. Typically, an author begins by determining the work's style, defining key characters and their traits, outlining interactions, and ultimately developing a complete narrative based on these plots. Following this natural progression, our model training tasks are designed to emulate this process. First, the model is pretrained on a next-word prediction task for learning the writing style. Then, we design three downstream fine-tuning tasks:"}, {"title": "World-Building Learning", "content": "In this task, the model maps character names, represented as $N = \\{N_1, N_2,..., N_n\\}$, to their corresponding profiles $C = \\{C_1, C_2, ..., C_n\\}$. For each character name $N_i$, the model generates a detailed profile $C_i$, including the character's attributes, relationships, and role in the narrative. This process is formulated as:\n```latex\n\\hat{C_i} = f_{world}(N_i).\n```\nThis task ensures that the model develops a comprehensive understanding of the story world, forming the foundation for subsequent tasks.\nPlot Structure Learning Building on the character profiles established in the previous task, this step focuses on predicting narrative progression. The model is trained to generate the next plot $P_t$ based on the most recent $N_p$ predicted plots:\n```latex\nP_t = f_{plot}(P_{t-N_p},..., P_{t-1}).\n```\nUsing the $N_p$ most recent plots, the model ensures narrative continuity and coherence within the story's timeline.\nStylish Writing Following plot prediction, the Stylish Writing task involves generating the narrative text based on the predicted plot $P_t$.The model produces a sequence of words $\\hat{Y_t} = {\\hat{x_1},\\hat{x_2},..., \\hat{x_n}}$ as follows:\n```latex\n\\hat{Y_t} = f_{writing}(P_t).\n```\nThe generated text is then compared with the ground truth $Y_t = \\{X_1,X_2, ..., X_n\\}$, ensuring coherence with the plot and stylistic alignment with the author's writing."}, {"title": "4.3 WriterLoRA", "content": "A straightforward approach to train an LLM involves sequentially training it on the above tasks in a parameter-efficient manner using LoRA. However, this method may fail to optimize task-specific performance while maintaining cross-task synergy. To address this limitation, we propose WriterLoRA, a structured multi-task learning framework that maximizes efficiency through shared components while ensuring task-specific specialization.\nShared Foundation Initially, the model undergoes next-word prediction training on the entire corpus, using a pair of LoRA matrices, $A_{Fdn.}$ and $B_{Fdn.}$. Here, $A_{Fdn.}$ serves as the shared matrix across all tasks, while $B_{Fdn.}$ collaborates with task-specific B-matrices. The motivation for sharing the A-matrix is to enhance learning efficiency and task synergy. As a compression matrix, $A_{Fdn.}$ extracts core representations for language understanding and generation, ensuring consistency across tasks while reducing redundancy and improving cross-task transfer learning. After pretraining, $A_{Fdn.}$ is fixed to maintain stable representations and prevent catastrophic forgetting.\nTask-Specific Adaptations The weight update process originally defined in Equation 1 is extended to account for task-specific requirements, beginning with language style learning and progressing through subsequent tasks. The weight update process defined in Equation 1 is extended to meet task-specific requirements, starting with language style learning and progressing through world-building, plot structure, and stylish writing tasks. During language style learning, the model uses $B_{Fdn.}$ and $A_{Fdn.}$ for next-word prediction, capturing linguistic and stylistic nuances. For world-building, the model maps character names to profiles using $B_{world}$ alongside $B_{Fdn.}$ to define characters and relationships. In plot structure learning, both $B_{plot}$ and $B_{world}$ are used, where $B_{plot}$ controls narrative flow and $B_{world}$ ensures consistency. For stylish writing, $B_{writing}$ integrates with $B_{Fdn.}$, $B_{world}$, and $B_{plot}$ to generate coherent, stylistic text.\nThe generalized weight update is:\n```latex\nh' = W_0 x + (B_{Fdn.}A_{Fdn.} + \\Sigma_t a_t B_t A_{Fdn.}) x.\n```\nThe task-specific weights $a_t$ are computed using:\n```latex\na_t = \\frac{exp(w_t)}{\\Sigma_{t'} exp(w_{t'})},\n```\nwhere $w_t$ = 1 for the active task and $w_{t'}$ = 0 for others. This ensures the active task's matrix $B_t$ dominates, while others provide auxiliary contributions, enabling efficient task adaptation and knowledge sharing."}, {"title": "5 Experimental Setup", "content": "5.1 Dataset\nWe selected two renowned literary works for our dataset: the classic Chinese novel Dream of the Red Chamber and the Harry Potter series, chosen for their rich narratives and literary significance. For Dream of the Red Chamber, the first 80 chapters were used for training and the last 40 for testing. Similarly, the first six Harry Potter books were used for training, with the final book for testing.\nIn addition to the primary text, our dataset incorporates supplementary information to enhance its utility. First, we collected detailed, human-written introductions for the main characters. These character profiles provide valuable context for tasks such as role-playing and characterization. Specifically, profiles for Dream of the Red Chamber were sourced from Sohu website, while those for Harry Potter were obtained from Wikipedia. Secondly, we used GPT-4 to segment the text into sections and generate concise plot summaries for each section. A section is smaller than a chapter but longer than a paragraph, with the division based on self-contained and relatively complete narrative events. These summaries offer structured descriptions of key narrative developments, supporting tasks such as plot-aware content generation.\n5.2 Comparison Methods\nWe selected ChatGLM and Qwen as backbone models for evaluating Chinese language performance, and Llama3 for English tasks. The key models included in our comparisons are as follows: (1) Qwen2-7B-Instruct (Bai et al., 2023): An instruction-tuned variant of Qwen2-7B, optimized for handling complex queries and interactive tasks. (2) ChatGLM2-6B (Zhang et al., 2023b): A bilingual LLM optimized for both English and Chinese languages. (3) Llama3-8B (Touvron et al., 2023): Excels in reasoning, creative writing, and coding tasks. We also include fine-tuned LLMs tailored for novel generation: (4) LoRA (Hu et al., 2021): An efficient fine-tuning method applying low-rank updates without modifying all model parameters. (5) MOELORA (Liu et al., 2024a): Combines LORA with MoE architecture, activating subsets of parameters. MoELORA uses three pairs of A and B matrices, each specialized for world building, plot learning, or stylish writing.\n5.3 Implementation Details\nWe implemented our experiments using PyTorch and conducted them on an NVIDIA A100 GPU. All models were configured with a maximum sequence length and cutoff length of 2048 tokens. We trained the model for 3 epochs using the AdamW optimizer and BF16 precision for efficiency. The learning rate was set to 1.0e-4 and scheduled using a cosine decay strategy with a warmup ratio of 0.1. A dropout rate of 0.05 was applied to prevent overfitting. The rank r was set to 8 for both LoRA and each LoRA module within MoELORA. To simulate a larger batch size, we set the batch size to 1 and applied gradient accumulation over 8 steps. More implementation details are in Appendix A.\n5.4 Evaluation Metrics\nNovel Generation Evaluation: The primary goal of our task, novel generation, is evaluated using both traditional metrics and six advanced aspect-based metrics. Traditional metrics like"}, {"title": "6 Experimental Results", "content": "6.1 Main results\nTable 1 and Table 2 present the experimental results of Qwen-2, Pretrain, SFT, MoELORA, and WriterAgent across two datasets.\nFirstly, evaluation results reveal that different metrics capture complementary aspects of writing quality. ROUGE favors models like LoRA for content coverage and structural alignment, while aspect-based metrics highlight Pretrain and MoELORA's strengths in plot coherence and emotional tone. This underscores the need for diverse evaluation frameworks to fully assess model performance. Secondly, MoELORA, the best-performing baseline, benefits from specialized multi-task training, producing coherent plots and well-aligned emotional tones, but its language style is not well-preserved due to the loss of pre-trained textual style during multi-task learning. Finally, our proposed WriterAgent consistently outperforms all baselines across datasets and metrics, achieving significant improvements in plot coherence, character development, emotional depth, and overall narrative quality. Additionally, it addresses MoELORA's language style limitation by freezing the matrix A, thereby preserving the pre-trained writing style and ensuring stylistic consistency in the generated narratives.\n6.2 Ablation Study\nWe conduct an ablation study on Dream of the Red Chamber to evaluate the impact of different learning strategies and LoRA configurations in our model, as shown in Figure 4. Removing the curriculum learning strategy led to a significant performance drop across all metrics, showing that learning all tasks simultaneously without a structured progression reduces the model's effectiveness. Similarly, removing WriterLoRA with only one LORA weakened task-specific adaptation, reducing the model's ability to handle diverse constraints. Finetuning the foundation matrix $A_{fdn.}$ instead of keeping it fixed led to performance degradation, showing the importance of a stable foundation for consistent improvements.\n6.3 Analysis of Curriculum Learning\nOur curriculum learning consists of three stages: world building, plot prediction, and stylish writing. Figure 3 presents a case study showing the model's output after each stage. After curriculum 1 (world building), the generated text demonstrates characters and traits that closely align with the original work's character settings. However, the plot structure and textual details remain significantly different from the original. After curriculum 2 (plot prediction), the output retains the vivid character traits learned in the first stage. For instance, Wang Xifeng is depicted as highly fond of wealth and enthusiastic about managing the household, consistent with her original portrayal. However, since the plot construction relies on modern vernacular organization, the model's ability to capture writing details and mimic the original literary style is insufficient. Finally, after incorporating the final step of curriculum learning, the overall performance improves significantly in terms of word choice, plot structure, and style, as shown in Figure 5. We present Chinese output in Figure 11.\n6.4 Human Evaluation\nIn addition to automatic evaluation, we conducted a human evaluation with two PhD annotators, both native speakers with strong literary backgrounds. They select the best-performed model on the Dream of the Red Chamber dataset. The re-"}, {"title": "7 Conclusion", "content": "We introduce WriterAgent, an LLM designed for novel generation by learning character profiles, predicting plotlines, and reconstructing full stories. Unlike traditional models reliant on prompt engineering, WriterAgent internalizes novel-related knowledge, reducing external dependencies. At its core, WriterLoRA employs LoRA modules and curriculum learning to progressively master narrative elements, enhancing coherence and stylistic consistency. Experiments on two datasets show that WriterAgent outperforms baselines in capturing complex settings and character dynamics. In the future, we aim to extend WriterAgent's capabilities to broader literary genres and refine its adaptability across diverse storytelling styles."}, {"title": "Limitation", "content": "Despite the effectiveness of WriterAgent in generating pastiche novels, several limitations remain. First, while determining the plot before drafting is a natural part of the writing process, plots typically exist in the author's mind rather than as explicit, structured data. As a result, we need to manually construct plot datasets, which introduces potential biases and may not fully capture the organic, evolving nature of storytelling. Second, automatic evaluation heavily relies on LLMs' ability to understand an author's style, yet current LLMs do not possess comprehensive knowledge of all literary nuances. To mitigate this, we incorporated few-shot prompting in our evaluation, allowing the model to refine its understanding of specific authors. However, this approach is still limited and cannot fully replace human judgment, as LLM-based evaluation may overlook deeper stylistic elements and narrative coherence that human readers naturally perceive. These limitations highlight the challenges in literary pastiche generation and evaluation, underscoring the need for future research on more refined plot modeling and improved evaluation frameworks that better align with human literary perception."}, {"title": "Ethical Considerations", "content": "The development of WriterAgent involves certain ethical considerations, primarily regarding intellectual property, authenticity, and responsible use. Our goal is to learn and emulate an author's style rather than directly replicate their work, and we prioritize fairness and compliance when working with copyrighted texts. Additionally, generating text that closely resembles an author's writing style may raise discussions about authenticity. Therefore, we encourage responsible usage and advocate for AI to function as an assistive tool in a collaborative creative environment, fostering literary diversity while respecting the original authors' writing styles and creative spirit. To this end, we can implement measures such as limiting outputs to derivative or transformative works, providing transparency about AI-generated content, and ensuring that the system serves as a tool for creative inspiration rather than a substitute for human authorship."}, {"title": "A Implementation Details", "content": "The training progress was monitored every 10 steps, with checkpoints saved every 500 steps to enable recovery and evaluation. Loss curves were plotted to track convergence, with the output directory overwritten during updates to maintain consistency. To improve efficiency, data preprocessing utilized 8 parallel workers. During training, we set the batch size to 1 and used gradient accumulation over 8 steps to simulate a larger batch size. The number of samples was limited to 1000 to control training time. The training dataset followed the Alpaca format, and for the multi-task MoE model, a task_id field was added to the data to classify tasks during training.\nWe used the AdamW (Loshchilov, 2017) optimizer for training, which decouples weight decay from gradient updates, improving both training stability and generalization. This makes it particularly effective for large-scale models, such as Transformers, by avoiding overfitting and enhancing optimization efficiency.\nThe version of the Transformers library was chosen to match the architectures of the models being trained. For the ChatGLM2-6B model, which adopts a GLM (General Language Model) architecture with bidirectional and autoregressive training, version 4.30.2 of Transformers was used. However, for the Llama 3-8B and Qwen2-7B-Instruct models, the recommended version was 4.45.0 to ensure compatibility and optimal performance."}, {"title": "B Case Study of Harry Potter", "content": "In this case study, we evaluate different models on their ability to generate coherent plots and novels and maintain consistency with the world and character personalities of the Harry Potter series.\nAs shown in Figure 6, the baseline models and our WriterAgent are tested on their performance in predicting plot progressions that align with prior story context. The results reveal significant differences in coherence, character consistency, and adherence to the magical world's logic. The Base Llama model frequently generates plots disconnected from previous events, with characters behaving inconsistently with their established traits. For example, Harry's decisions often lack continuity and conflict with his determined, courageous nature in the novels. The LoRA model improves slightly but suffers from repetitive content and omits key world-building knowledge, such as the importance of destroying Horcruxes to defeat Voldemort. By contrast, WriterAgent generates coherent plot progressions where Harry's actions align with his character and successfully weaves in critical elements of the magical world, like his mission to destroy Horcruxes."}, {"title": "C Case Study of Red Chamber", "content": "In Figure 8, we show a case of generated plot, and Chinese version in Figure 9. The QWen model continues the story directly, overlooking potential objections from the Jia family about Xichun becoming a nun, as well as the family's power dynamics. Jia Mu, as the family matriarch, would likely not agree easily, making the model's output feel oversimplified and lacking in emotional depth. The LoRA model generates a classical-style continuation but focuses on a specific detail, with Xichun's tone becoming harsh and defiant. While emotional, this feels abrupt and lacks narrative coherence. In contrast, our WriterAgent model shows the Jia family's complex reactions\u2014shock, reluctance, and eventual acceptance\u2014better fitting the worldview"}, {"title": "D Analysis of Human Annotation Results", "content": "In addition to automatic evaluation, we conducted human evaluation with two PhD annotators, both native speakers with strong literary backgrounds. They assessed the generated text by comparing it with the ground truth and selecting the bestperforming model on the Dream of the Red Chamber dataset.\nTo analyze the results, we calculated the average hit rate for each model's output and visualized it as a pie chart, as shown in Figure 12. The results indicate that our model was preferred in 73.1% of cases. The probability of experts selecting the base model's output was 0%, the pre-trained model's output 3.8%, the fine-tuned model's output 15.4%, and the MoE-LORA trained model's output 7.7%.\nFrom the results, we observe that the hit rate of SFT is slightly higher than that of MoE-LoRA. This is because the model trained with the MoE-LORA method exhibits improved instruction-following capability. However, in some cases, the MoE-LoRA"}, {"title": "E Evaluation Prompts", "content": "Here, we provide the prompt for evaluating model output using ChatGPT-40.First, here is the prompt for the English dataset.\nEvaluation Criteria:\nStylistic Similarity:\nLanguage Style: Analyze the similarity in vocabulary choice, sentence structure, tone, and overall mood to determine whether the imitated text aligns with the writing style of the Harry Potter series.\nExpression Techniques: Examine whether emotional expressions, descriptive language, and the use of metaphors are consistent between the two texts.\nSentence Length and Complexity: Compare sentence length, structural complexity, and paragraph organization in both texts.\nPlot Similarity:\nMain Storyline: Assess whether the core plotlines are similar and whether they present the same themes or narrative progression.\nCharacter Behavior and Motivation: Analyze whether the characters in the given text align with those in Harry Potter in terms of personality, actions, and motivations, ensuring they fit the story's logical development.\nEmotions and Conflict Analysis: Evaluate whether the relationships between characters, emotional dynamics, and plot developments are consistent with those in Harry Potter.\n The following are two example evaluations:"}]}