{"title": "A Mathematics Framework of Artificial Shifted Population Risk and Its Further Understanding Related to Consistency Regularization", "authors": ["Xiliang Yang", "Shenyang Deng", "Shicong Liu", "Yuanchi Suo", "Wing.W.Y NG", "Jianjun Zhang"], "abstract": "Data augmentation is an important technique in training deep neural networks as it enhances their ability to generalize and remain robust. While data augmentation is commonly used to expand the sample size and act as a consistency regularization term, there is a lack of research on the relationship between them. To address this gap, this paper introduces a more comprehensive mathematical framework for data augmentation. Through this framework, we establish that the expected risk of the shifted population is the sum of the original population risk and a gap term, which can be interpreted as a consistency regularization term. The paper also provides a theoretical understanding of this gap, highlighting its negative effects on the early stages of training. We also propose a method to mitigate these effects. To validate our approach, we conducted experiments using same data augmentation techniques and computing resources under several scenarios, including standard training, out-of-distribution, and imbalanced classification. The results demonstrate that our methods surpass compared methods under all scenarios in terms of generalization ability and convergence stability. We provide our code implementation at the following link: https://github.com/ydlsfhll/ASPR.", "sections": [{"title": "1 Introduction", "content": "Data augmentation creates a training dataset using synthetic data from the prior knowledge. It improves the generalization of machine learning models, particularly in the case of deep neural networks. For decades, its reliable performance has been verified in various of computer vision tasks such as image classification"}, {"title": "2 Related Work", "content": "Data Augmentation Frame Work Data augmentation methods play a crucial role in improving the performance of machine learning models in practical applications. These methods encompass a range of techniques, including traditional fixed augmentation methods like Cutout [6], Mixup [29], and Cutmix [26]. Additionally, there are adaptive augmentation methods such as AutoAugment [4], Fast AutoAugment [16], DADA [15], and CMDA [22], which dynamically design augmentations based on the dataset. Despite the availability of these diverse augmentation methods, there is a dearth of theoretical frameworks for analyzing the population shift phenomenon induced by data augmentation and the associated shifted population risk.\nA recent work [3] provides a theoretical framework that defines the augmentation operator as a group action. However, their framework has certain limitations, as evidenced by several common augmentation operators that are incompatible with the group action framework, as detailed in the Appendix D.1. Our proposed framework can be applied to a wider range of data augmentation operators compared to theirs.\nPopulation Shift Population shift is a common concern in machine learning robustness and generalization problems. It refers to a problem in which the population of data changes during some processes, such as a distribution being transformed to other distributions within the same distribution family, and the change of the parameters of a distribution. A common example for population shift in machine learning is the different semantic styles between the training and testing sets, such as PACS [14], Rotated MNIST, Color MNIST [1], VLCS, and Office-Home [24]. However, not all types of population shifts are natural. Style shifts such as PACS are naturally generated distributions, while population shifts such as Rotated MNIST and Color MNIST are artificially generated. It is obvious that all data augmentations will produce an artificial population shift. This work aims to provide a theoretical framework for artificial population shifts and analyze the relationship between the shifted population risk and the original population risk."}, {"title": "3 Method", "content": ""}, {"title": "3.1 Revisiting Data Augmentation with Empirical Risk", "content": "We conduct research in the case of classification and denote the data space and label space as X and Y and a joint distribution p is defined on X \u00d7 Y, with marginal distribution p(x) and conditional distribution p(y|x). We call a sample x drawn from p(x) a \"clean sample\". We aim to train a model f : X \u2192 Y by minimizing the following risk with a loss function L(\u00b7,\u00b7):\n\\(R_f(p) = \\int L(f(x), y)dp(x,y),\\) (1)\nAs (1) is usually intractable, the empirical risk minimization principle is used, aiming at optimizing an unbiased estimator of (1) over a training dataset D = {(xi, Yi)}1:\n\\(R_f(p) = \\frac{1}{N} \\sum_{i=1}^N L(f(x_i), Y_i),\\) (2)\nFollowing [25], we introduce the following assumption to build a bridge between empirical risk and expected risk:\nClaim. Let C(f) be some complexity metric of f, N be the number of data (don't have to be independent), B(N) be the \"independence\" of the input data. For d > 0, we assume that the following holds with probability 1 \u2013 \u03b4:\n\\(R_f(p) - R_f(p) \\leq \\phi(C(f), B(N), \\delta).\\) (3)\nWhere (.) is a function of these three terms, and it monotonically increases with respect to the second variable.\nWe refer the readers to [18] for more detail about the convergence in the non iid case. It is worth noting that data augmentation produces an augmented sample x', which is a distinct random variable from the clean sample x, with a different distribution p*(x') but the same probability space triplet. This leads to a new population p(x', y) and an expected risk defined on it. Specifically, the empirical risk function is defined as follows:\n\\(R_f(p^*) = \\frac{1}{N} \\sum_{i=1}^N L(f(x'_i), Y_i).\\) (4)\nIt is important to note that minimizing (4) does not necessarily result in the minimization of (1) or even (2). Meanwhile, data augmentation is also recognized as a regularization technique that can reduce generalization error without necessarily reducing training error [7,28]. Our proposed decomposition as well as the framework should be helpful when one tries to overcome these struggles."}, {"title": "3.2 The Augmented Neighborhood", "content": "Data augmentation is typically applied directly to a clean sample x to generate an augmented sample x'. The augmentation is usually designed to preserve the semantic consistency between x and x', hence it is often referred to be \"mild\". However, the data augmentation is usually controlled by a set of parameter when it is applied to a fixed clean sample x. When the parameters are iterated, a large set of augmented samples are produced, among which there are samples are over augmented and should not be considered \"mild\". As a result, a series of rigorous mathematical definitions are required, so one may draw a line between \"ordinary\" data augmentation and a \"mild\" one.\nThe Augmentation and Limitation We begin this section with the definition of data augmentation:\nDefinition 1. Let X be the data space, endow X with Borel - algebra F, let the data augmentation A\u017c(\u00b7,\u00b7) be a map from X \u00d7 \u0398(Ai) to X satisfying:\n1. For every fixed x in X, the map 0 \u2192 Ai(0,x), is differentiable and injective. We denote the inverse of this map as h-1Aix\n2. For every fixed 0 in O(Ai), the map Ai(0,\u00b7) is an F\u2212 measurable map.\n3. \u2200x \u2208 X \u2203ei \u2208\u0398(Ai) s.t. A(ei,x) = x and such ei is unique.\nwhere (Ai) is the parameter space of A\u00bf(\u00b7,\u00b7).\nThe differentiability of some popular data augmentations has been proven in [22]. The injectivity of the data augmentation is always guaranteed given proper parameterization and a carefully chosen parameter space. The measurable assumption is required to ensure that A(0,x) is still measurable, which is necessary for the adjoint random variable x'. However, the tractability of h-1 Ai,x is not always guaranteed, but the good news is that it is not always required in practice. More detailed discussion is provided in Section 3.2, where we discuss how to sample from the conditional distribution p(x'|x).\nDenote the set of data augmentation as A = {A1,... Am}, among which Ai corresponds to a certain type of data augmentation such as rotation, Gaussian blur and so on. Denote dim(\u0398(Ai)) = di, where (Ai) denotes the parameter space of Ai. For example, the parameter space of rotation is usually chosen as (0,2\u03c0) and the dimension is 1. The distribution of the parameter defined on (A) is denoted as pi(\u03b8). Now for a given clean sample xo, we consider all of its augmented sample, which is the image of the mapping A\u00bf(xo,\u00b7), defined on \u0398(\u0391):\nDefinition 2. For any given clean sample xo \u2208 X and data augmentation Ai with parameter space \u0472(Ai), the augmentation neighborhood of xo induced by Ai is defined as:\n\\(A_i(x) := \\bigcup_{\\theta \\in \\Theta (A)} A_i(\\theta, x).\\) (5)"}, {"title": "3.2 The Augmented Neighborhood", "content": "Now we should add some restrictions to this set so make it \"mild\".\nAt first we introduce the conception C, a map from input space X to the label space L = {C1,...,cq} where I denotes the number of class, such that for every clean sample pair (x,y) ~ p(x,y), C(x) = y \u2208 L, conception is the desired ground truth map. C induces a partition of the sample space, by giving I mutually disjoint sets such that i = {x|C(x) = ci}, what we call level set. We denote the level set of the class of a sample 10 with \u0413xo, and we use this level set to describe the semantic consistency. The conception C represents the prior knowledge of people when they perform data augmentation. The definition is given as followed:\nDefinition 3. For any given clean sample xo \u2208 X, and augmentation Ai with parameter space \u0472(Ai), the consistency augmentation neighborhood (CAN for short) of xo induced by A\u00a1 is defined as:\n\\(O_{A_i}^{x_0} := A_i(x_0) \\cap \\Gamma_{x_0}.\\) (6)\nNow we will introduce how to sample from the CAN.\nSampling from CAN of xo An augmented sample is generated given a clean sample, together with the aforementioned mild argument, we claim that the sampling procedure should be described with a conditional distribution p(x'|x), whose supporting set is CAN of 10. The fact that \u2200x' \u2208 OA, there exists only one := h-1 A\u043a\u043e (x') \u2208 \u0398(A) such that x' = A(0,x) which is ensured by our definition. Furthermore, with the measurability of A\u2081(\u00b7,x), x' is a random variable. Therefore, for any given data augmentation Ai, the conditional distribution p(x'x) induced by A\u00bf is defined as:\nDefinition 4. For any given clean sample x ~ p(x), the conditional distribution p(x'x) of the adjoint variable x' with supp(p(x'|x)) = Oai is given as\n\\(p(x'|x) \\propto p_i(h^{-1}_{A_i,x}(x')) \\frac{\\partial A_i(\\theta, x)}{\\partial \\theta}|_{\\theta = h^{-1}_{A_i,x}(x')} \\mathbb{I}_{x' \\in O_{A_i}^{x_0}}.\\) (7)\nSampling from A\u2081(x) is equivalent to sampling from pi(0) defined on (Ai), for h Ai(x)) = \u0398(A\u2081), given the injectivity of A(\u00b7, x). Furthermore, to sample from A\u2081(x) \u2229 \u0393, we need to sample from the truncated distribution:\n\\(P_i(\\theta) \\mathbb{I}_{ \\theta \\in h^{-1}_{A_i,x} O_{A_i}^{x_0}}\\) (8)\nRejection sampling is one effective way to generate augmented samples, but it may be infeasible in high-dimensional cases due to its computational cost. Although various methods, such as nested sampling, adaptive multilevel splitting, or sequential Monte-Carlo sampling, could be viable alternatives, we leave the exploration of these methods for future work. Additionally, the rejection step can be seen as a way to inject humane prior knowledge to samples, which aligns"}, {"title": "3.2 The Augmented Neighborhood", "content": "with the intuition on the process of data augmentation. In our experiment, we assume that it would be enough to sample from the subset of h (OA), we use human prior knowledge in rejection sampling to roughly determine a subset of it. We begin by selecting the candidate of edges of these subsets, then apply A(\u03b8,x) for parameters of these edges, and reject or accept these edges by observing the output samples. However, this method is inefficient and risky, rejection sampling is infamous for its inefficiency and the initial selection of edges could be problematic since they may be too small compared to the ground truth. We plan to develop better methods based on our framework in future work.\nThe conditional distribution p(x'x) is now well-defined, with its marginal distribution given by p* (x') = \u222b p(x'|x)p(x)dx. However, it is important to note that p(x'x) is unlikely to be tractable. The description above is useful in understanding that an augmented sample is a random variable induced from the of data augmentation, given the measurability of A(x, .).\nFinally, it's worth mentioning that generating M samples for each of the N clean samples does not result in M \u00d7 N completely independent augmented samples. But (4) still yields an unbiased estimator of the shifted population risk, due to the following equation:\n\\(E_{p(x'|y)} [L(y, f(x'))] = E_{p(x|y)} [E_{p(x'|x,y)} [L (y, f (x'))| x]],\\)\n\\( = E_{p(x|y)} [E_{p(x'|x)} [L (y, f(x'))|x]],\\)\n\\(R_f(p^*) = \\frac{1}{N} \\sum_{i=1}^N \\frac{1}{M} \\sum_{j=1}^M L(y, f(x'_j)),\\)\nTaking expectation on the both side of the third equation yields the desired result. One should notice that augmented sample x' is independent of y once its original clean sample x is given, which explains the second equality.\nThe above definition in the case of a finite set of data augmentations and the composition order is given in Appendix A.\nBy establishing these definitions and concepts in this section, we are provided with a comprehensive understanding of the topic at hand. Which provides a solid foundation for the decomposition of the expected risk in the coming section."}, {"title": "3.3 The Artificial Shifted Population Risk", "content": "After defining the augmented neighborhood and giving sampling method by defining the adjoint variable x' and its conditional distribution p(x'x), we then evaluate the risk on the shifted population p(x', y). One should realize that the collection of all the samples generated from p(x) is a subset of the samples generated from p*(x').\nFor simplicity, we only consider the risk function in the case of cross-entropy and softmax on the shifted population p(x', y), and our method should be able to extend to the other cases similarly:"}, {"title": "8", "content": "Rf (p*) = Ep*(x') [H(p(y|x'), q\u00a2(y|x'))],\n= Ep(y)p(x'|y) [-ln q4 (y|x')]\n= Ep(y)p(x',x|y) [\u2212 ln q\u00a2(y|x')], (9)\namong which & denotes the parameter of the neural network and q represents a probabilistic surrogate model. The decomposition of this shifted population risk is examined with the following theorem:\nTheorem 1. With the shifted population risk in the form of (9), we have the following decomposition:\nEp*(x') [H(p(y|x'), q\u00a2(y|x'))]\n= Ep(x) [H(p(y|x), q$(y|x))] + Ep(x)p(yz)p('\\z) In Joy\\x'). (10)\nThe proof of the Theorem 1 can be found in Appendix B.1. This demonstrates that in the case of cross-entropy and softmax, the shifted population risk is actually the sum of the original population expected risk and a gap term that can be viewed as a consistency regularization term. Next, we provide a theorem that explains the second term."}, {"title": "3.4 Understanding the decomposition of shifted population risk", "content": "From the last section, we have:\n\\(E_{p(x)p(y|x)p(x'x)} [In \\frac{q_\\phi(y|x)}{q_\\phi(y|x')} = E_{p(x)p(x'|x)} [Im In \\frac{q_\\phi(Y_x|x)}{q_\\phi(Y_x|x')}. ,\\) (11)\nwhere yx is the ground true label of clean sample x. Since q (yx) is modeled with softmax, we have:\n\\(q_\\phi(Y_i| x) = \\frac{exp(w_i h_\\phi(x))}{\\Sigma_{j=1} exp(w_j h_\\phi(x))},\\) (12)\nwhere ho(x) = (h\u2081(x), h2(x),...,ha(x),...,hp(x))T (the subscript 0 of the component is omitted for convenience) is the feature vector of x, and W = (W1,..., w\u2081) is the weight of the output layer, now \u03c6 = {0, W}. For every feature ha(x), its density is:\n\\(q_\\phi(Y_i|h_d(x)) = \\frac{exp(w_{i,d}h_d(x))}{\\Sigma_{j=1}^l exp(w_{j,d}h_d(x))},\\) (13)\nInspired by [10], we partition the features into major features and minor features by information gains. For major features, the density function q(y|ha) concentrates on some point mass. For minor features, the possibility density_q$(y|ha) is relatively uniform."}, {"title": "9", "content": "Then for every given x, we have:\n\\(E_{p(x'|x)} [In \\frac{q_\\phi(Y_x|x)}{q_\\phi(Y_x|x')} = E_{p(x'|x)} [In \\frac{\\Sigma_{j=1}^l \\Sigma_{i=1}^l exp ((w_j - w_x)^Th_\\phi(x'))}{\\Sigma_{j=1}^l \\Sigma_{i=1}^l exp ((w_j-w_x)^Th_\\phi(x))}],\\)\n(14)\nFor convenience, we denote\nexp ((wj - wx)The(x)) = \u03c1\u03b8,x,j,\n\u03a3\u03c1\u03b8,\u03c0,j = \u03c1\u03b8,\u03b1,\nj=1\n(15)\nwe then examine the relationship of feature and the second term with the following theorem:\nTheorem 2. Assuming that for every 0, sample pair (x, x') and indicies j, there exist \u1e9e1,j, A1,j > 0 such that\n\u03b11,j < \u03c1\u03b8,x,j, \u03c1\u03b8,x',j < \u03b21,j,\n(16)\nThen for any given x, we have:\n\\(E_{p(x'|x)} [In \\frac{q_\\phi(Y_x|x)}{q_\\phi(Y_x|x')}] = E_{p(x'|x)} [\\Sigma_{j=1} O ((w_j - w_x)^T (h_\\phi(x) \u2013 h_\\phi(x')))],\\)\n(17)\nThe proof of the Theorem 2 can be found in the Appendix B.2. With Theorem 2, we show how the second term affects the weights. Since the data augmentation must cause a large variance in some features particularly in early training phases, which means that\n\u2203\u03b7\u2081 > 0, ha(x) \u2013 ha(x')| > 71,\n(18)\nfor some features including minor and major features. This forces that Vj E {1,...,1}, wj,d \u2192 Wx,d, resulting in a uniform distribution of q$(y|ha(x)), and such regularization of wj,d is not appropriate for major features. Now let us see how the first term affects the weights\n\\(E_{p(x)} [H(p(y|x), q_\\phi(y|x))] = [\\Sigma exp ((w_j-w_x)^Th_\\phi(x))];,\\) (19)\nAnd for any minor feature, its variation should not change the result, hence we have wj,d \u2248 Wi,d, 1 \u2264 i, j \u2264 1. In contrast, the weights of major features should be different:\n372 > 0, Wj,d - Wx,d| > N2\n(20)\nnow we realize that, with the effect of data augmentation, the first term and the second term have different impacts on the weight of some major features and the same impact on minor features. Since our model mainly relies on major"}, {"title": "10", "content": "features to provide prediction, such an effect causes an unstable convergence. To highlight the positive effect provided by the first term at the beginning, a simple trick is to add a coefficient \u5165 (\u03bb < 1) to the second term.\nNow we discuss how A may help refine the generalization of the model. We denote the model trained using augmented samples as faug:\nRfaug (p*) = Ep(y)p(x'|y) [L(y, f(x'))],\nRfaug (p) = Ep(y)p(x|y) [L(y, f(x))], (21)\nNote that we train our model using Rfaug (p*) and evaluate the generalization of our model using Rfang (p). Based on the assumption 3.1, with augmented sample and clean sample pairs instead of clean samples alone, we have:\nRfaug (p*) <Rfaug (p*) + $(C(f), B(N \u00d7 M), \u03b4), (22)\nTheorem 1 can then be reformulated with our new formulation:\nRfaug (p*) = Rfaug (p) + GAP,\nRfaug (p*) = Rfaug (P) + GAP MXN, (23)\nwhere GAP is the second term in the right hand side of Theorem 1 and GAPMXN is its empirical estimator using M \u00d7 N non iid pairs of (x,x'). Hence, (22) is reformulated by:\nRfaug (p) < Rfaug (p) + (C(f), B(N \u00d7 \u041c), \u03b4)+\n\\widetilde{GAP}M \\times N \\widetilde{GAP}.\nNow we show that the noise GAPMXN GAP \u2192 0:\n\\(GAP = E_{p(x)p(y/x)p(x'x)} [ln \\frac{q_\\phi(y|x)}{q_\\phi(y|x')}],\\)\n(24)\nwe denote B(y, g(x, x')) = ln 94(y/x), then we assume that given any clean sample\npair (xi, Yi):\nVarp(x'|xi) [B(yi, g(xi, x'))] \u2264 B,\nthen for the estimator:\nEp(x,y)p(x'\\x) [B(y, g(x, x'))]\n= Ep(x,y) [Ep(x'|x) [B (y, g(x, x'))| x,y]],\n\n\\frac{1}{N} \\Sigma_{i=1}^N \\frac{1}{M} \\Sigma_{j=1} B(Y_i, g(x_i, X'_{iz})),\nwhere x denotes augmented samples from p(x'|xi) consider its variance:\nVar (\\widetilde{GAP}M \\times N) = \\frac{1}{N2M} \\Sigma_{i=1}^N Varp(\\cdot|x_i) [B(y_i, g(x_i, x'))],"}, {"title": "11", "content": "with the assumption:\n\\(Var (\\widetilde{GAP}M \\times N) \\leq \\frac{B}{NM},\\)\nthen the variance is of order O(1/NM), which indicates the faster convergence speed.\nWe determine that the generalization of model depends on Rfaug (p) instead of what we directly optimize: Rfaug (p*). Hence we would like to keep the consistency between Rfaug (p) and Rfaug (p*), i.e., the decreasing of Rfaug (p*) guarantees that of Rfaug (p) to ensure the improvement of generalization when training the model.\nAs it is analyzed before, GAPMXN may lead to different weights of some major features compared with Rfaug (p) in early training stages, which will destroy such consistency. This indicates the importance of our proposed coefficient \u03bb."}, {"title": "4 Experiment", "content": "We demonstrate the standard training strategy in Algorithm 1 and our proposed training strategy in Algorithm 2 in Appendix C. We also conduct an experiment on the selection of the hyperparameter A of Algorithm 2 in Appendix E."}, {"title": "4.1 Experiment Implementation", "content": "Standard Scenario Experiment: Validation Models and Datasets We have conducted experiments on CIFAR10/100 [12], Food101 [2], and ImageNet (ILSVRC-2012) [20] with various models to evaluate our training strategy. For each of them, a validation set is split from the training set to find networks with the best performances. More dataset splitting details are shown in Appendix F.1. In this paper, ResNet [9] and WideResNet [27] are trained with different strategies. For datasets CIFAR10/100 and Food101, ResNet-18, ResNet-50, WideResNet-28-10 and WideResNet-40-2 are chosen as our baseline models. For ImageNet, ResNet-50 and ResNet-101 are used for evaluation. All images in baseline (standard method) and our method are processed with same augmentation (horizontal flips, random crops and random rotation). A was selected to 0.5 for it achieve the best performance among all the experiments with our strategy. For a fair comparison, we set the basic batch size (bbs) and performed standard method experiments with both 1x bbs and 2x bbs (our method actually takes twice the amount of data sample) to ablate the estimation error effect caused by the batch size. More details about data augmentation and network training are shown in Appendix F.2 and Appendix F.3.\nTo ensure that our strategy is applicable to other settings, we conduct experiments in the following two cases:\nOOD Scenario Experiment: Validation Models and Datasets Experiments on PACS [14] are conducted using ResNet-18 and ResNet-50 [9]. In these experiments, we employed the leave-one-domain-out strategy for OOD validation. For"}, {"title": "5 Conclusion and Discussion", "content": "Rethinking of Shifted Population In this paper, we develop a new set of definitions for shifted population, augmented samples and its conditional distribution. We leverage our proposed definition to establish the decomposition of the shifted population risk, providing an explanation for how data augmentation enhances the generalization ability of model."}, {"title": "5", "content": "Better Training Strategy Based on the proposed decomposition, we realize that the key to improving generalization lies in keeping the consistency between Rfaug (p*) and Rfaug (p), which is likely to be violated by the gap term specifically in the early training stages. Adding a coefficient to the gap term refines this, and it is proposed as a training strategy with augmentation. As demonstrated in our experiment, our method outperforms the standard augmentation training strategy. Meanwhile, our proposed strategy is highly related to the augmentation schedule, an existing training strategy. Our work could provide comprehensive understanding on how it works. What's more, there is more than one solution to the problem of the gap term, which is left for future work.\nLimitation Considering the fact that this paper mainly conducts analysis in the case of classification tasks, some of the results proposed in this paper lack versatility. However, the framework of the analysis is transferable, and based on the definition of expected risk, similar results can be attained on other tasks. Conditional distribution of adjoint variable p(x'x) is intractable given the fact that although the differentiability of most of the classic augmentations has been verified in other works, there are data augmentations that have not, some of them may even be not genuinely differentiable. Hence, other definitions of p(x'|x) that bypass the necessity of differentiability can be explored in future work."}, {"title": "A Supplementary Definition", "content": "In this section we introduce the CAN of xo together with the conditional distribution defined on it induced by a finite set of augmentations {A\u2081,... Am} with parameter space \u0398(A1), ... \u0398(Am) for a given composite order \u03c3. Realizing that with the given order of composition, there is a new data augmentation:\n\\(A_{im} ... A_{i_1}: (\\Theta(A_{im}) \\times \\dots \\times \\Theta(A_{i_1})) \\times X \\rightarrow X\\)\n\\(((0_{im},...0_1), x_0) \\rightarrow A_{im}(0_{im}) \\circ \\dots \\circ A_{j_1}(0_{1}, x)\\) (25)\nNote that \u2200x' \u2208 X,\u03b8\u2081 \u2208 \u0398(Ai), \u03b8j \u2208 \u0472(Aj), Ai(\u03b8i)\u0970Aj(\u03b8j, x') = Ai(\u03b8i, Aj (\u03b8j, x')).\nThe augmentation neighborhood of 10 induced by A with composite order \u03c3 is:\nDefinition 5. For any given clean sample x \u2208 X, and the finite set of augmentations A = {A1,... Am} with parameter space, for a given composite order \u03c3 such that \u03c3(1,..., m) = (j1, ..., jm), the augmentation neighborhood of xo induced by A for a given composite order o is defined as:\n\\(A^{\\sigma} (x) = \\bigcup_{\\substack{(\\theta_{j_1} \\dots \\theta_{j_m}) \\in \\Theta(A_{j_1}) \\Theta(A_{j_2}) \\times \\dots \\times \\Theta(A_{j_m})}} (A_{j_m} (\\theta_{j_m})\\circ \\dots \\circ A_{j_2} (\\theta_{j_2}) \\circ A_{j_1} (\\theta_{j_1}, x))\\) (26)\nAlthough there are m! different ways of composition and composite order matters, but for simplicity, leave the matter to future work. We usually omit this superscript and denote it as A(x).\nNow the CAN of 20 induced by A with composite order o is:\nDefinition 6. For any given clean sample x \u2208 X, and the finite set of augmentations A = {A1,... Am} with parameter space \u0472(\u04101), ... \u0398(Am) and a given order of composition \u03c3, the consistent augmentation neighborhood (CAN for short) of xo induced by A is defined as :\n\\(O_A^{\\sigma} := A^{\\sigma}(x) \\cap \\Gamma_x\\)\nFor the same reason that the permutation ois assumed to be given, part of the superscript is omitted and can be simplified as OA.\nWhen we need to sample in the CAN of x induced by a finite set of augmentation A for a given order of composition \u03c3. For any x' \u2208 AP(x), there exists only one 0 = hamo... Ai,x (X') = (0im,... 011). Since (0im,...0i\u2081) are mutually independent, the conditional distribution p(x'|x) induced by it with a supporting set on OA is defined as:"}, {"title": "18", "content": "Definition 7. For a given clean sample x ~ p(x), the conditional distribution p(x'|x) of the adjoint variable x' with supp(p(x'|x)) = OA is given as\np(x'x)\nPi1 (0:1)... Pim (im)\nJA(0m)00A(\u03b8)00A(11,x))\n10=hAimo... Aiz(x)\n-1xE0A\n(28)\nZ3 is the normalization constant since it is limited on the level set of xo, and the sampling method is similar to that when single augmentation is considered."}, {"title": "B Proof of Theorems", "content": ""}, {"title": "B.1 Proof of Theorem 1", "content": "Theorem 3. equation: ShiftDecomp In the case of cross-entropy and softmax, the shifted population risk has the following decomposition:\nEp*(x') [H (p(y|x'), q\u00a2(y|x'))]\n= Ep(x) [H(p(y|x), q\u00a2(y|x))] + Ep(x)p(y|x)p(x'x) In (29)\nProof.\nEp(y)p(x',x|y) [- ln q$(y|x')]\n= Ep(y)p(x'|x)p(x|y) [- ln q$(y|x')]\n= Ep(x)p(y|x)p(x'|x) [- ln q$ (y|x')]\nIn\nEp(x)p(yz)p(x/2) 11 (2)\n+ ln \nq$(y/x')\n= Ep(x)p(x'|x)p(y|x) [- ln q\u00a2(y|x)] + Ep(x)p(x'x)p(y|x) In (30)\n= Ep(x)p(y|x) [- ln q$(y|x)] +Ep(x)p(x'x)p(y|x)\n= Ep(x) [H(p(y|x), q\u00a2(y|x))] + Ep(x)p(y|x)p(x'\\x)\nOne should note that the first equation holds because p(x', xy) = p(x'|x, y)p(xy) is p(x'x)p(xy) since x' is a random variable that independent of y after x is given."}, {"title": "B.2 Proof of Theorem 2", "content": "Theorem 4. theorem: OrderofSecondterm Assuming that for every 0 and every (x,x'), there exist \u1e9e1,j,A1,j > 0 such that\nA1,j < \u03c1\u03b8,x,j, \u03c1\u03b8,x',j < \u03b21,j (31)"}, {"title": "19", "content": "Then for any given x", "have": "n\\(E_{p(x'|x)} [In \\frac{q_\\phi(Y_x|x)}{q_\\phi(Y"}]}