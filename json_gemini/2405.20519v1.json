{"title": "Diffusion On Syntax Trees For Program Synthesis", "authors": ["Shreyas Kapur", "Erik Jenner", "Stuart Russell"], "abstract": "Large language models generate code one token at a time. Their autoregressive\ngeneration process lacks the feedback of observing the program's output. Training\nLLMs to suggest edits directly can be challenging due to the scarcity of rich\nedit data. To address these problems, we propose neural diffusion models that\noperate on syntax trees of any context-free grammar. Similar to image diffusion\nmodels, our method also inverts \"noise\" applied to syntax trees. Rather than\ngenerating code sequentially, we iteratively edit it while preserving syntactic\nvalidity, which makes it easy to combine this neural model with search. We\napply our approach to inverse graphics tasks, where our model learns to convert\nimages into programs that produce those images. Combined with search, our\nmodel is able to write graphics programs, see the execution result, and debug them\nto meet the required specifications. We additionally show how our system can\nwrite graphics programs for hand-drawn sketches. Video results can be found at\nhttps://tree-diffusion.github.io.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) have made remarkable progress in code generation, but their au-\ntoregressive nature presents a fundamental challenge: they generate code token by token, without\naccess to the program's runtime output from the previously generated tokens. This makes it difficult\nto correct errors, as the model lacks the feedback loop of seeing the program's output and adjusting\naccordingly. While LLMs can be trained to suggest edits to existing code [6, 42, 17], acquiring\nsufficient training data for this task is difficult.\nIn this paper, we introduce a new approach to program synthesis using neural diffusion models that\noperate directly on syntax trees. Diffusion models have previously been used to great success in\nimage generation [14, 22, 31]. By leveraging diffusion, we let the model learn to iteratively refine\nprograms while ensuring syntactic validity. Crucially, our approach allows the model to observe the\nprogram's output at each step, effectively enabling a debugging process.\nIn the spirit of systems like AlphaZero [29], the iterative nature of diffusion naturally lends itself\nto search-based program synthesis. By training a value model alongside our diffusion model, we\ncan guide the denoising process toward programs that are likely to achieve the desired output. This\nallows us to efficiently explore the program space, making more informed decisions at each step of\nthe generation process.\nWe implement our approach for inverse graphics tasks, where we posit domain-specific languages for\ndrawing images. Inverse graphics tasks are naturally suitable for our approach since small changes in\nthe code produce semantically meaningful changes in the rendered image. For example, a misplaced\nshape on the image can be easily seen and fixed in program space.\nOur main contributions for this work are (a) a novel approach to program synthesis using diffusion on\nsyntax trees and (b) an implementation of our approach for inverse graphics tasks that significantly\noutperforms previous methods."}, {"title": "Background & Related Work", "content": "Neural program synthesis Neural program synthesis is a prominent area of research, in which\nneural networks generate programs from input-output examples. Early work, such as Parisotto et al.\n[23], demonstrated the feasibility of this approach. While modern language models can be directly\napplied to program synthesis, combining neural networks with search strategies often yields better\nresults and guarantees. In this paradigm, the neural network guides the search process by providing\nproposal distributions or scoring candidate programs. Examples of such hybrid methods include\nBalog et al. [2], Ellis et al. [12], and Devlin et al. [9]. A key difference from our work is that these\nmethods construct programs incrementally, exploring a vast space of partial programs. Our approach,\nin contrast, focuses on editing programs, allowing us to both grow programs from scratch and make\ncorrections based on the program execution.\nNeural diffusion Neural diffusion models, a class of generative models, have demonstrated im-\npressive results for modeling high-dimensional data, such as images [14, 22, 31]. A neural diffusion\nmodel takes samples from the data distribution (e.g. real-world images), incrementally corrupts the\ndata by adding noise, and trains a neural network to incrementally remove the noise. To generate new\nsamples, we can start with random noise and iteratively apply the neural network to denoise the input.\nDiffusion for discrete data Recent work extends diffusion to discrete and structured data like\ngraphs [35], with applications in areas such as molecule design [15, 27, 8]. Notably, Lou et al. [20]\nproposed a discrete diffusion model using a novel score-matching objective for language modeling.\nAnother promising line of work for generative modeling on structured data is generative flow networks\n(GFlowNets) [3], where neural models construct structured data one atom at a time."}, {"title": "Method", "content": "The main idea behind our method is to develop a form of denoising diffusion models analogous to\nimage diffusion models for syntax trees.\nConsider the example task from Ellis et al. [11] of generating a constructive solid geometry (CSG2D)\nprogram from an image. In CSG2D, we can combine simple primitives like circles and quadrilaterals\nusing boolean operations like addition and subtraction to create more complex shapes, with the\ncontext-free grammar (CFG),\n$S \\rightarrow S + S | S - S | Circle_{x,y}^{r} | Quad_{x,y}^{\\omega,h,\\theta}$\nIn Figure 2, zo is our target program, and xo is the rendered version of xo. Our task is to invert xo\nto recover 20. Our noising process randomly mutates y=16 to y=10. It then mutates the whole\nsub-tree with two shapes with a new sub-tree with just one shape. Conditioned on the image xo, and\nstarting at x3, X3, we would like to train a neural network to reverse this noising process to get to zo.\nIn the following sections, we will first describe how \u201cnoise\" is added to syntax trees. Then, we will\ndetail how we train a neural network to reverse this noise. Finally, we will describe how we use this\nneural network for search."}, {"title": "3.1 Sampling Small Mutations", "content": "Let zt be a program at time t. Let $p_N(z_{t+1}|z_t)$ be the distribution over randomly mutating program\nZt to get $z_{t+1}$. We want $p_N$ mutations to be: (1) small and (2) produce syntactically valid $z_{t+1}$'S.\nTo this end, we turn to the rich computer security literature on grammar-based fuzzing [41, 13, 32, 36].\nTo ensure the mutations are small, we first define a function \u03c3(z) that gives us the \u201csize\u201d of program z.\nFor all our experiments, we define a set of terminals in our CFG to be primitives. As an example, the\nprimitives in our CSG2D language are {Quad, Circle}. In that language, we use \u03c3(z) = \u03c3primitive(z),\nwhich counts the number of primitives. Other generic options for \u03c3(z) could be the depth, number of\nnodes, etc.\nWe then follow Luke [21] and Zeller et al. [41] to randomly sample programs from our CFG under\nexact constraints, omin < \u03c3(z) \u2264 max. We call this function ConstrainedSample(omin,max).\nSetting a small value for max allows us to sample small programs randomly. We set omax = small\nwhen generating small mutations.\nTo mutate a given program z, we first generate a set of candidate nodes in its tree under some small,\n$C = {n \u2208 SyntaxTree(z) | \u03c3(n) \u2264 \u03c3small}.$\nThen, we uniformly sample a mutation node from this set,\n$m \\sim Uniform[C].$\nSince we have access to the full syntax tree and the CFG, we know which production rule produced\nm, and can thus ensure syntactically valid mutations. For example, if m were a number, we know to\nreplace it with a number. If m were a general subexpression, we know we can replace it with any\ngeneral subexpression. Therefore, we sample m', which is m's replacement as,\n$m' \\sim ConstrainedSample(ProductionRule(m), small).$"}, {"title": "3.2 Policy", "content": "3.2.1 Forward Process\nWe cast the program synthesis problem as an inference problem. Let p(x|z) be our observation model,\nwhere x can be any kind of observation. For example, we will later use images x produced by our\nprogram, but x could also be an execution trace, a version of the program compiled to bytecode, or\nsimply a syntactic property. Our task is to invert this observation model, i.e. produce a program z\ngiven some observation x.\nWe first take some program zo, either from a dataset, $D = {z_0, z_1, . . . }$, or in our case, a randomly\nsampled program from our CFG. We sample zo's such that \u03c3(20) \u2264 max. We then add noise to zo\nfor s ~ Uniform[1, Smax], steps, where smax is a hyper-parameter, using,\n$z_{t+1} \\sim P_N(z_{t+1}/z_t).$\nWe then train a conditional neural network that models the distribution,\n$q_\\phi(z_{t-1}|z_t, x_t; x_0),$\nwhere \u03c6 are the parameters of the neural network, zt is the current program, xt is the current output\nof the program, and 20 is the target output we are solving for."}, {"title": "3.2.2 Reverse Mutation Paths", "content": "Since we have access to the ground-truth mutations, we can generate targets to train a neural\nnetwork by simply reversing the sampled trajectory through the forward process Markov-Chain,\n$z_0 \\leftarrow z_1 \\leftarrow  z_2 \\leftarrow \\cdots \\leftarrow  z_t$.\nAt first glance, this may seem a reasonable choice. However, training to simply\ninvert the last mutation can potentially create a much noisier signal for the neural network.\nConsider the case where, within a much larger syntax tree, a color was mutated as,\n$Red \\rightarrow Blue \\rightarrow Green.$\nThe color in our target image, xo, is Red, while the color in our mutated image, x2, is Green. If we\nnaively teach the model to invert the above Markov chain, we are training the network to turn the\nGreen to a Blue, even though we could have directly trained the network to go from Green to a Red.\nTherefore, to create a better training signal, we compute an edit path between the target tree and the\nmutated tree. We use a tree edit path algorithm loosely based on the tree edit distance introduced by\nPawlik and Augsten [25, 24]. The general tree edit distance problem allows for the insertion, deletion,\nand replacement of any node. Unlike them, our trees can only be edited under an action space that\nonly permits small mutations. For two trees, z\u0104 and zB, we linearly compare the syntax structure.\nFor changes that are already \u2264 small, we add that to our mutation list. For changes that are > small,\nwe find the first mutation that reduces the distance between the two trees. Therefore, for any two\nprograms, ZA and zB, we can compute the first step of the mutation path in O(|zx| + |2B|) time."}, {"title": "3.3 Value Network & Search", "content": "We additionally train a value network, v\u3085(XA, XB), which takes as input two rendered images, XA\nand XB, and predicts the edit distance between the underlying programs that generated those images.\nSince we have already computed edit paths between trees during training, we have direct access to\nthe ground-truth program edit distance for any pair of rendered images, allowing us to train this value\nnetwork in a supervised manner.\nUsing our policy, q\u00a2(Zt\u22121|Zt, Xt; X0), and our value, V\u00a2(Xta, Xte), we can perform beam-search for\na given target image, xo, and a randomly initialized program zt. At each iteration, we maintain a\ncollection of nodes in our search tree with the most promising values and only expand those nodes."}, {"title": "3.4 Architecture", "content": "Figure 3 shows an overview of our neural architecture. We use a vision-language model described\nby Tsimpoukelli et al. [33", "38": "of NF-ResNet-26 as our image encoder", "4": "to avoid test time instabilities with Batch-Norm [40", "26": ".", "tokens": "an <EDIT> token, which serves as a start-of-sentence token\nfor the model; and  tokens, which allow the model to reference positions within its context.\nGiven a current image, a target image, and a current tokenized program, we train this transformer\nmodel to predict the edit position and the replacement text autoregressively. While making predictions,"}]}