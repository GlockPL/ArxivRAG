{"title": "Multiple Kronecker RLS fusion-based link propagation for drug-side effect prediction", "authors": ["Yuqing Qian", "Ziyu Zheng", "Prayag Tiwari", "Yijie Ding", "Quan Zou"], "abstract": "Drug-side effect prediction has become an essential area of research in the field of pharma-cology. As the use of medications continues to rise, so does the importance of understanding and mitigating the potential risks associated with them. At present, researchers have turned to data-driven methods to predict drug-side effects. Drug-side effect prediction is a link pre-diction problem, and the related data can be described from various perspectives. To process these kinds of data, a multi-view method, called Multiple Kronecker RLS fusion-based link propagation (MKronRLSF-LP), is proposed. MKronRLSF-LP extends the Kron-RLS by finding the consensus partitions and multiple graph Laplacian constraints in the multi-view setting. Both of these multi-view settings contribute to a higher quality result. Extensive experiments have been conducted on drug-side effect datasets, and our empirical results provide evidence that our approach is effective and robust.", "sections": [{"title": "Introduction", "content": "Pharmacovigilance is critical to drug safety and surveillance. The field of pharmacovigilance plays a crucial role in public health by continuously monitoring and evaluating the safety profile of drugs. Pharmacovigilance involves collecting and analyzing data from various sources, including health care professionals (Yang et al., 2016), patients, regulatory authorities, and pharmaceutical companies. These data are then used to identify possible side effects and assess their severity and frequency (Da Silva & Krishnamurthy, 2016; Galeano et al., 2020). Traditionally, drug-side effects were primarily identified through spontaneous reporting systems, where health care professionals and patients reported adverse events to regulatory authorities. However, this approach has limitations, such as underreporting and delayed detection.\nTo overcome these limitations, researchers have turned to data-driven methods to find drug-side effects. With the advent of electronic health records, large-scale databases containing valuable information on medication usage and patient outcomes have become available. These databases have allowed researchers to analyze vast amounts of data to identify patterns between drugs and side effects."}, {"title": "Problem description", "content": "Identification of drug-side effects is an example of the link prediction problem, which has the aim of predicting how likely it is that there is a link between two arbitrary nodes in a network. This problem can also be seen as a recommendation system (Jiang et al., 2019; Fan et al., 2021) task.\nLet the drug nodes and side effect nodes of a network be $D = {d_1, d_2,...,d_N }$ and $S = {s_1, s_2,...,s_M}$, respectively. We denote the number of drug and side effect nodes by N and M, respectively.\nWe define an adjacency matrix $F \\in R^{N \\times M}$ to represent the associations between drugs and side effects. Each element of F is defined as $F_{i,j} = 1$ if the node pair $(d_i, s_j)$ is linked and $F_{i,j} = 0$ otherwise.\nThe link prediction has the aim of predicting whether a link exists for the unknown state node pair $(d_i, s_j) \\in D \\times S$. Thus, it is a classification problem. Most methods use regression algorithms to predict a score (ranging from 0-1), which we call the link confidence. Then, a class of 0 or 1 is assigned to the predicted score by the threshold. Higher link confidence indicates a greater probability of the link existing, while lower values indicate the opposite. We define a new matrix $\\hat{F}$, which is estimated by the prediction model. Each of elements $\\hat{F}_{ij}$ represents the predicted link confidence for the node pair $(d_i, s_j)$. Figure 5 summarizes the link prediction problem discussed in this paper."}, {"title": "Related work", "content": ""}, {"title": "Regularized Least Squares", "content": "The objective function of Regularized Least Squares (RLS) regression is:\n$\\arg \\min_f \\frac{1}{2} ||F - f(K)||^2 + \\frac{\\lambda}{2} ||f||_K^2,$\nwhere $\\lambda$ is a regularization parameter, $||f||_K$ denotes the RKHS norm (Kailath, 1971) of f (\u00b7). f (\u00b7) is the prediction function and be defined as:\n$f (K) = K \\alpha,$\nwhere $\\alpha$ is the solution of the model, F is a kernel matrix with elements\n$K_{i,j} = k (d_i, d_j) (i, j = 1, . . ., N),$\nand k represents the kernel function.\nBy formulating the stationary points of Equation 1 and elimination the unknown parameters $\\alpha$, the following solution is obtained\n$\\hat{F} = K(K + \\lambda I_N)^{-1}F.$"}, {"title": "Kronecker Regularized Least Squares", "content": "Combining the kernels of the two spaces into a single large kernel that directly relates drug-side effect pairs would be a better option. Kronecker product kernel (Hue & Vert, 2010) is used for this. Given the drug kernel KD and side effect kernel KS, then we have the kronecker product kernel\n$K = K_S \\otimes K_D,$"}, {"title": "Kronecker Regularized Least Squares with Multiple Kernel Learning", "content": "Kron-RLS is a kind of kernel method. It can be difficult for nonexpert users to choose an appropriate kernel. To address such limitations, Multiple Kernel Learning (MKL) (G\u00f6nen & Alpayd\u0131n, 2011) is proposed. Since kernels in MKL can naturally correspond to different views, MKL has been applied with great success to cope with the multi-view data (Wang et al., 2021; Xu et al., 2021; Guo et al., 2021; Qian et al., 2022a; Wang et al., 2023b) by combining kernels appropriately.\nGiven predefined base kernels ${K_i^D}_{i=1}^P$ and ${K_j^S}_{j=1}^Q$ from drug feature space and side effect feature space, respectively. These kernels can be built from different types or views. The optimal kernel can be combined by a linear function corresponding to the base kernels:\n$K_P^{opt} = \\sum_{i=1}^{P} w_i K_i^D.$\nUsually, an additional constraint is imposed on the corresponding combination coefficient $w$ to control its structure:\n$\\sum_{i=1}^{P} w_i^2 = 1, w_i \\geq 0, i = 1, ..., P.$"}, {"title": "Proposed method", "content": "Existing multi view fusion methods based on Kron-RLS all follow MKL framework. These methods optimize the optimal pairwise kernel as a linear combination of a set of base kernels. Prior to training, all views are fused, and information is not shared during training phase. This is typical early fusion technology. Our proposal addresses this limitation by fusing multi-view information in a consensus partition. Compared with MKL framework, the advantage of the proposed method is that it allows sub partitions to have a certain degree of freedom to model the single information. Further, multiple graph Laplacian regularization is introduced into the consensus partition to boost performance. Fig. 2 illustrates the main procedure of MKronRLSF-LP."}, {"title": "The construction of kernel matrix", "content": "Kron-RLS is a kind of kernel method. We construct drug kernels using five different kinds of functions.\nGaussian Interaction Profile (GIP):\n$[K_{GIP,D}]_{i,j} = exp(-\\gamma ||d_i - d_j ||^2),$\nwhere $\\gamma$ is the gaussian kernel bandwidth and $\\gamma = 1.$"}, {"title": "The MKronRLSF-LP model", "content": "Let us define two sets of base kernel sets separately:\n$K_D = {K_1^D,..., K_P^D},$\n$K_S = {K_1^S,...,K_Q^S},$\nwhere P and Q represents the numbers of drug and side effect kernels, respectively. Based on the KD and KS, we can get a set of pairwise kernels:\n$K = {K^1 = K_1^D \\otimes K_1^S, ..., K^V = K_P^D \\otimes K_Q^S},$\nwhere V denotes the numbers of base pairwise kernels. Obviously, V is equal to PxQ.\nBy using multiple partitions, we can manipulate multiple views in a partition space, which enhances the robustness of the model. The following ensemble KronRLS model is obtained\n$\\arg \\min_\\alpha^v \\sum_{v=1}^V (||\\vec(F) - K^v \\alpha^v||^2 + \\alpha^{v^T}K^v\\alpha^v).$\nIn multi-view methods, the consensus principle establishes consistency between partitions from different views. However, it's essential to find that these partitions deliver varying degrees of importance to the final prediction, unlike fusion without discrimination. To facilitate this, we introduce a consensus partition, denoted by $\\hat{F}$. It is a weighted linear combination of partitions $\\hat{F}^v$ from multiple distinct views. A variable $w_v$ is introduced for view v which characterizes its importance, which is calculated based on the training error. To prevent sparse situations, we employ $||\\cdot||_2$ to smooth the weights. Then, we have the following optimization problem\n$\\arg \\min_{\\hat{F}, \\alpha, w} \\frac{1}{2} ||\\vec(\\hat{F}) - \\sum_{v=1}^V w_v K^v \\alpha^v||^2 + \\mu \\sum_{v=1}^V (\\frac{w_v}{2} ||\\vec(\\hat{F}) - K^v \\alpha^v||^2 + \\frac{\\lambda_v}{2} \\alpha^{v^T}K^v\\alpha^v) + \\frac{\\beta}{2} ||w||_2^2,$\ns.t. $\\sum_{v=1}^V w_v = 1, w_v \\geq 0, v = 1, . . ., V.$\nIn Equation 23, we observe that the consensus partition $\\hat{F}$ fits to an adjacency matrix $F$ by an indirect path. As described in section 2, false zeros represent unobserved links in the network. Hence, we must avoid overfitting the observed matrix F. Inspired by manifold scenarios, the Laplacian operator adeptly mitigates overfitting and noise, preserving the original data structure and keeping nodes with common labels closely associated. This approach is simple, and empirical evidence confirms its effective performance (Pang & Cheung, 2017; Chao & Sun, 2019; Jiang et al., 2023). Here, we apply multiple graph Laplacian regularization to Equation 23, which can effectively explore multiple different views and boost the performance of $\\hat{F}$. Specifically, the Kronecker product Laplacian matrix is calculated from the optimal drug and side effect similarity matrix, which are weighted linear combinations of multiple related kernel matrices. The weight of each kernel can be adaptively optimized during the training process and reduce the impact of noisy or less relevant graphs. The optimization problems for MKronRLSF-LP can be formulated as:\n$\\arg \\min_{\\hat{F}, \\alpha^v, w, \\Theta_D, \\Theta_S} \\frac{1}{2} ||\\vec(\\hat{F}) - \\sum_{v=1}^V w_v K^v \\alpha^v||^2 + \\mu \\sum_{v=1}^V (\\frac{w_v}{2} ||\\vec(\\hat{F}) - K^v \\alpha^v||^2 + \\frac{\\lambda_v}{2} \\alpha^{v^T}K^v\\alpha^v) + \\frac{\\beta}{2} ||w||_2^2 + \\frac{\\sigma}{2} \\vec(\\hat{F})^T L \\vec(\\hat{F}),$\ns.t. $\\sum_{v=1}^V w_v = 1, w_v \\geq 0, v = 1, ..., V,$\n$L = I_{NM} - (H_S^{0.5}K_S H_S^{0.5})^\\dagger (H_D^{0.5}K_D H_D^{0.5})^\\dagger,$\n$K_D = \\sum_{i=1}^P [\\Theta_D]_i K_i^D, K_S = \\sum_{i=1}^Q [\\Theta_S]_i K_i^S,$\n$\\sum_{i=1}^Q [\\Theta_S]_i = 1, [\\Theta_S]_i \\geq 0, i = 1, ..., Q, \\sum_{i=1}^P [\\Theta_D]_i = 1, [\\Theta_D]_i \\geq 0, i = 1, . . ., P.$\nwhere L is a normalized laplacian matrix, $H_S$ and $H_D$ are diagonal matrix with the jth diagonal elements as $\\sum_k [K_S]_{j,k}$ and $\\sum_k [K_D]_{j,k}$, respectively. And, $\\varepsilon > 1$, guaranteeing each graph has a particular contribution to the Laplacian matrix.\nDue to the lack of space, we present optimization algorithm of the Equation 24 in Appendix Section A.1."}, {"title": "Experiments", "content": "In this section, the performance of MKronRLSF-LP is shown, and we make comparisons with baseline methods and other drug-side effect predictors."}, {"title": "Dataset", "content": "Four real drug-side effect datasets are used to assess the effectiveness of our proposed method. Pau dataset is derived from the SIDER database (Kuhn et al., 2010) which contains information about drugs and their recorded side effects. Miz dataset includes information about drug-protein interactions and drug-side effect interactions, obtained from the DrugBank (Wishart et al., 2006) and SIDER database, respectively. There were 658 drugs with both targeted protein and side effect information. Additionally, Liu et al. mapped drugs in SIDER to DrugBank 3.0 (Knox et al., 2010), resulting in a final dataset of 832 drugs and 1385"}, {"title": "Parament setting", "content": "In this paper, the objective function 24 contains the following regularization parameters: $\\mu, \\beta, \\sigma, \\epsilon$ and $\\lambda_v, v = 1,..., V$. To find the right combinations of the regularization parameters of MKronRLSF-LP to give the best performance, the grid search method is performed on the Pau dataset. The optimal parameters with the best AUPR are selected.\nWe first select $\\lambda^v, v = 1, . . ., V$ by the relative pairwise kernel with a single view Kron-RLS model. For each parameter $\\lambda^v$, we select it in the range from $2^{-5}$ to $2^{5}$ with step $2^{1}$. The optimal parameters $\\lambda^v$ are shown in Table 4. According to a previous study(Shi et al., 2019), the performance is not affected by parameter $\\epsilon$, so it is set to 2. Then, we fix $\\lambda_v, v = 1,..., V$ at the best values and tune $\\mu, \\beta, \\sigma$ from within the range $2^{-10}$ to $2^{0}$ with step $2^{1}$. The optimal regularization parameters are $\\mu = 2^{-7}, \\beta = 2^{0}$ and $\\sigma = 2^{-8}$."}, {"title": "Baseline methods", "content": "In this work, we compare MKronRLSF-LP with the following baseline methods: BSV, Comm Kron-RLS (Perrone & Cooper, 1995), Kron-RLS+CKA-MKL(Ding et al., 2019), Kron- RLS+pairwiseMKL(Cichonska et al., 2018), Kron-RLS+self-MKL(Nascimento et al., 2016), MvGRLP(Ding et al., 2021) and MvGCN(Fu et al., 2022). Due to the lack of space, we present details of these baseline methods in Appendix Section A.3. For a fair comparison, the same input as our method is fed into these baseline methods. To achieve the best performance, we also adopt 5-fold CV on the Pau dataset to tune the parameters."}, {"title": "Threshold finding", "content": "Because the MKronRLSF-LP and baseline methods only output the value of regression, we apply a threshold finding operation. For a certain validation set in the five-fold cross-validation (5-fold CV) procedure, we collect the labels and their corresponding predicted scores. Then, we obtain the optimal threshold by maximizing the $F_{score}$ on the predicted scores and labels from this validation sets. A trend of Fscore, Recall and Precision with different thresholds over four datasets is shown in Fig. 6. While the threshold of prediction rises, the values of Recall is rising. Oppositely, Precision is falling. The $F_{score}$ is the harmonic mean of the Recall and Precision. It thus symmetrically represents both Recall and Precision in one metric. Here, we find the optimal threshold under maximizing the value of $F_{score}$. Table 5 summarizes the thresholds of different baseline methods on different datasets."}, {"title": "Comparison with baseline methods", "content": "We conduct the 5-fold CV to evaluate the performance of our method versus the baseline method. To further provide a fair and comprehensive comparison, each algorithm is iterated 10 times with different cross index, and then the mean values and standard deviations are reported in Table 3. The best single view is $K_{GIP,D} \\otimes K_{NTK,S}$, which is selected by 5-fold CV on Pau dataset.\nFirst, we observe that the proposed method has the best AUPR and $F_{score}$ on all datasets. Especially, the proposed method has a higher AUPR and $F_{score}$ than BSV on datasets. This indicates the improvement in using multiple views. The simple coupling frameworks BSV and Comm perform well on the Pau dataset. However, BSV and Comm cannot perform as well on other datasets, which indicates that the simple fusion schemes are sensitive to the dataset and not robust. Furthermore, Kron-RLS+pairwiseMKL achieves the highest AUC of 95.01%, 95.02% and 94.70% on the Liu, Pau and Miz datasets, respectively. This shows slight improvements of 0.23%, 0.21% and 0.23% over our method, respectively. As we discussed in Section 5.1, drug-side effect prediction is an extremely imbalanced classification problem. The AUC can be considered"}, {"title": "Ablation study", "content": "To validate the benefits of jointly applying the consensus partition and multiple graph Laplacian constraint, we conduct an ablation study by excluding a particular component. First, we construct a Kron-RLS based on each pairwise kernel separately. Each partition learns independently, so it can be regarded as an ensemble Kron-RLS, and its objective function is Equation 22. The results should be consistent for each view, and heterogeneous views have varying degrees of importance in the final prediction. Therefore, we set a consensus partition $\\hat{F}$, which is a weighted linear combination of base partitions (as shown in Equation 23). To further improve the performance and robustness of the model, we apply multiple graph Laplacian constraints to the consensus partition. Finally, the objective function 24 of MKronRLSF-LP is obtained. The results of the ablation study are shown in Fig. 4. It can be observed that the consensus partition and the multiple graph Laplacian constraint is helpful for MKronRLSF-LP to achieve the best results."}, {"title": "Comparisons of computational speed", "content": "In order to demonstrate the effectiveness of MKronRLSF-LP, we are now comparing it to different baseline methods in terms of computational speed. Except MvGCN, other methods are performed on a PC equipped with an Intel Core i7-13700 and 16GB RAM. Because MvGCN is a deep learning-based method, it is performed on a workstation equipped with a NVIDIA GeForce RTX 3090 GPU. For all baseline methods, we tested 10 times to report the mean running time. The results are shown in Table 2. The results do not include the kernel calculation time.\nAs expected, learning from multiple views takes more time than learning from only one view (BSV). Also, since MKronRLSF-LP fuses multiple views at the partition level, it requires more running time than Kron-RLS+CKA-MKL and Kron-RLS+self-MKL. Another observation is that MKronRLSF-LP is much faster than Kron-RLS+pairwiseMKL. This can be explained by looking at the time complexity of MKronRLSF-LP and Kron-RLS+pairwiseMKL. The inverse of pairwise kernels dominates the time com-plexity of both methods. In our optimization algorithm, we use eigendecomposition techniques to compute the approximate inverse. The time complexity of our method is $O((P + Iter)N^3 + (Q + Iter)M^3)$. Dif-"}, {"title": "Comparison with other drug-side effect predictors", "content": "A comparison of the proposed drug-side effect prediction method with state-of-the-art methods is also pro-vided. Tables 6,7, 8 and 9 present the results of 5-fold CV in terms of AUPR, AUC, Recall, Precision and $F_{score}$ on the four datasets, respectively. We have highlighted the best results in bold and underlined the second-best results.\nObviously, MKronRLSF-LP achieves the highest AUPR and $F_{score}$ on all datasets. In the problem of drug-side effects prediction, AUPR and $F_{score}$ more desirable metrics (Ezzat et al., 2017; Li et al., 2021). Therefore, we conclude that our method outperforms the other assessed methods. GCRS (Xuan et al., 2022) and SDPred (Zhao et al., 2022) are deep learning-based methods. GCRS constructs multiple heterogeneous graphs and multi-layer convolutional neural networks with attribute-level attention to predict drug-side effect pair nodes. SDPred fuses multiple side information (including drug chemical structures, drug target, drug word, side effect semantic similarity, side effect word) by feature concatenation and adopts CNN and MLP for prediction tasks. However, on Luo dataset, GCRS and SDPred perform poorly; this is probably because they are pairwise learning methods and randomly negative sampling to construct the training set. The randomly negative sampling method cannot be guaranteed due to the reliability and quality of negative sample pairs, which results in a certain loss of information (Zhang et al., 2015; Ali & Aittokallio, 2019). The ensemble model (Zhang et al., 2016) combine Liu's method (Liu et al., 2012), Cheng's method (Cheng et al., 2013), INBM and RBM by the average scoring rule. It is obvious that the results of the ensemble model are significantly improved than the results of the sub-model on four datasets."}, {"title": "Conclusion", "content": "This paper presents MKronRLSF-LP for drug-side effect prediction. The MKronRLSF-LP method solves the general problem of multi-view fusion-based link prediction by utilizing the consensus partition and multiple graph Laplacian constraint. MKronRLSF-LP allows for some degree of freedom to model the views differently and combination weights for each view to find the consensus partition. Each view's weight is dynamically learned and plays a crucial role in exploring consensus information. It is found that the use of Laplacian regularization enhances semi-supervised learning performance, so a term of multiple graph Laplacian regularization is added to the objective function. Finally, we present an efficient alternating optimization algorithm. The results of our experiments indicate that our proposed methods are superior in terms of their classification results to other baseline algorithms and current drug-side effect predictors."}, {"title": "Appendix", "content": ""}, {"title": "Optimization", "content": "It is difficult and time-consuming to solve the Equation 24 because it contains multiple variables and large pairwise matrices. In this section, we divide the original problem into five subproblems and develop an iterative algorithm to optimize them. And, we avoid explicit computation of any pairwise matrices in the whole optimization, which makes our method suitable for solving problems in large pairwise spaces.\nF-subproblem: we fix $\\alpha^v$, $w$, $\\Theta_D$ and $\\Theta_S$ to optimize variants $\\hat{F}$. Let $A = H_D^{0.5}K_D H_D^{0.5}$, $B = H_S^{0.5}K_S H_S^{0.5}$ and $\\vec{v} = \\sum_{v=1}^V w_v K^v \\alpha^v$. Then, the optimization model of $\\hat{F}$ as follows:\n$\\arg \\min_{\\hat{F}} \\frac{1}{2} ||\\vec(\\hat{F}) - \\vec{v}||^2 + \\frac{\\sigma}{2} \\vec(\\hat{F})^T L \\vec(\\hat{F}),$\ns.t. $L = I_{NM} - A \\otimes B.$\nLet the derivative of Equation 25 w.r.t $\\hat{F}$ to zero, the solution of $\\hat{F}$ can be obtained:\n$\\vec(\\hat{F}) = ((1+\\sigma) I_{NM} - \\sigma A \\otimes B)^{-1} (\\sum_{v=1}^V w \\vec{\\alpha^v}).$"}, {"title": "Measurements", "content": "Considering that drug-side effect prediction is an extremely imbalanced classification problem and we do not want incorrect predictions to be recommended by the prediction model, we utilize the following evaluation parameters:\n$Recall = \\frac{TP}{TP + FN},$\n$Precision = \\frac{TP}{TP + FP},$\n$Fscore = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall},$\nwhere TP, FN, FP and TN are the number of true-positive samples, false-negative samples, false-positive samples and true-negative samples, respectively. The area under the ROC curve (AUC) and area under the precision recall curve (AUPR) is also used to measure predictive accuracy, because they are the most commonly used evaluate metrics in the biomedical link prediction. The precision-recall curve shows the tradeoff between precision and recall at different thresholds. $Fscore$ is calculated from Precision and Recall. The highest possible value of an $Fscore$ is 1, indicating perfect precision and recall, and the lowest possible value is 0, if either precision or recall are zero. AUC can be considered as the probability that the classifier will rank a randomly chosen positive instance higher than a randomly chosen negative instance (Li et al., 2021). Therefore, we consider AUPR and $Fscore$ more desirable metrics (Ezzat et al., 2017; Li et al., 2021)."}, {"title": "Baseline methods", "content": "\u2022 Best single view (BSV): Applying Kron-RLS to the best single view. The one with the maximum AUPR is chosen here.\n\u2022 Committee Kron-RLS (Comm Kron-RLS)(Perrone & Cooper, 1995): Each view is trained by Kron- RLS separately, and the final classifier is a weighted average.\n\u2022 Kron-RLS with Centered Kernel Alignment-based Multiple Kernel Learning (Kron-RLS+CKA- MKL)(Ding et al., 2019): Multiple kernels from the drug space and side effect space are linearly weighted by the optimized CKA-MKL. Finally, Kron-RLS is employed on optimal kernels.\n\u2022 Kron-RLS with pairwise Multiple Kernel Learning (Kron-RLS+pairwiseMKL)(Cichonska et al., 2018): First, it constructs multiple pairwise kernels. Then, the mixture weights of the pairwise kernels are determined by CKA-MKL. Finally, it learns the Kron-RLS function based on the opti- mal pairwise kernel.\n\u2022 Kron-RLS with self-weighted multiple kernel learning (Kron-RLS+self-MKL)(Nascimento et al., 2016): The optimal drug and side effect kernels are linearly weighted based on the multiple base kernel. The proper weights assignment to each kernel is performed automatically.\n\u2022 Multi-view graph regularized link propagation model (MvGRLP)(Ding et al., 2021): This is an extension of the graph model (Zha et al., 2009). \u03a4\u03bf fuse multi view information, multi-view Laplacian regularization is introduced to constrain the predicted values.\n\u2022 Multi-view graph convolution network (MvGCN)(Fu et al., 2022): This extends the GCN (Zhang et al., 2019) from a single view to multi-view by combining the embeddings of multiple neighborhood information aggregation layers in each view."}, {"title": "Code and Data Available", "content": "The code and data are available at https://github.com/QYuQing/MKronRLSF-LP."}, {"title": "Figures", "content": null}, {"title": "Tables", "content": null}]}