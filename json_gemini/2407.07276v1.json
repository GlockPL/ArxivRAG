{"title": "Exploring Camera Encoder Designs for Autonomous Driving Perception", "authors": ["Barath Lakshmanan", "Joshua Chen", "Shiyi Lan", "Maying Shen", "Zhiding Yu", "Jose M. Alvarez"], "abstract": "The cornerstone of autonomous vehicles (AV) is a solid perception system, where camera encoders play a crucial role. Existing works usually leverage pre-trained Convolutional Neural Networks (CNN) or Vision Transformers (ViTs) designed for general vision tasks, such as image classification, segmentation, and 2D detection. Although those well-known architectures have achieved state-of-the-art accuracy in AV-related tasks, e.g., 3D Object Detection, there remains significant potential for improvement in network design due to the nuanced complexities of industrial-level AV dataset. Moreover, existing public AV benchmarks usually contain insufficient data, which might lead to inaccurate evaluation of those architectures. To reveal the AV-specific model insights, we start from a standard general-purpose encoder, ConvNeXt and progressively transform the design. We adjust different design parameters including width and depth of the model, stage compute ratio, attention mechanisms, and input resolution, supported by systematic analysis to each modifications. This customization yields an architecture optimized for AV camera encoder achieving 8.79% mAP improvement over the baseline. We believe our effort could become a sweet cookbook of image encoders for AV and pave the way to the next-level drive system.", "sections": [{"title": "I. INTRODUCTION", "content": "The ability to accurately understand and react to the surrounding environment is paramount for autonomous driving. This demands a well-designed perception system, with 3D object detection playing a crucial role. Notably, multi-camera-based methods have emerged as the dominant approach for this task, leveraging their affordability, adaptability, and rich 360-degree visual data to pinpoint location, size, and types of surrounding objects such as cars, bikes, and pedestrians.\nA strategically deployed multi-camera system, utilizing cameras with diversified field-of-view and resolution, captures overlapping data segments of the vehicle's surrounding environment. Each sensor provides partial environmental information, necessitating data from all the cameras to be collectively processed and transformed. A typical pipeline includes calibration, encoding, 2D-3D transformation, BEV encoder-decoder, and finally, the output prediction as shown in Fig.1. The encoder plays a critical role in this pipeline, employing either a classical CNN model or a modern transformer that also includes CNN models as feature extractor.\nWhile numerous pre-trained models [1], [2], [3], [4], [5] demonstrate impressive performance on general-purpose dataset like Imagenet, leveraging them directly for industrial-level AV dataset has many challenges. First, general-purpose datasets feature many classes, while AV datasets typically involve a restricted set of object classes with substantially more images per class, increasing the class distribution. Second, unlike general-purpose datasets, AV datasets are captured using a rich mix of camera sensor types with contrasting fields of view and resolution. Third, industrial AV datasets have an expansive detection range compared to public datasets like Waymo open dataset [6] and nuScenes dataset [7], demanding models to have more powerful localization ability, especially for small and distant objects. Lastly, indrustrial-level AV dataset encompass significantly more diverse scenarios compared to public dataset which are limited in scope, hindering accurate evaluation. This fundamental data disparity necessitates domain-specific architecture customization to maximize performance.\nAlthough there are many network architecture search (NAS) works [8], [9], [10] for obtaining high-performance and high-efficiency image encoders, we argue that it is important to gather insights into the model design than proposing intricate architecture. Therefore, we start with the state-of-the-art ConvNeXt [1], a simple and popular general-purpose architecture. First, the original ConvNeXt model blocks are modified to facilitate hardware acceleration. Then, leveraging our model insights for AV dataset and conducting systematic analysis to guide the modifications, we alter the design of key components like stages, blocks, channels, stage-compute-ratio, attention mechanism, and input resolution.\nOur work shows that customization of the encoder design to the specific characteristics of AV dataset yields 8.79% relative mAP (mean average precision) improvement over the vanilla model. Further, adapting hybrid architecture brings a separate 1.2% relative mAP improvement. We also show that the optimized model can effectively scale to create a family of models suitable for different online and offline processing needs."}, {"title": "II. RELATED WORK", "content": "Current research on adapting existing deep learning models to specific domains remains limited. While promising for designing optimal architectures, methods like NAS are often constrained by the computational burdens associated with exploring vast search spaces, particularly on large-scale datasets. This section details the state-of-the-art architectures that have demonstrated capabilities in AV and provides a description of publicly available AV datasets."}, {"title": "A. AI Models for Encoder", "content": "Convolutional neural networks (CNNs) have played a pivotal role in advancing vision models. Early approaches [11], [12] relied on multi-stage architecture demonstrating significant performance gains. Single-stage detectors such as SSD [13] and YOLO [14] perform dense predictions in a single shot, but often at the cost of accuracy. CenterNet [15] and FCOS [16] introduced a paradigm shift by moving from anchor-based prediction to per-pixel prediction, simplifying the detection pipeline. Deep3DBox [17] leveraged 2D detections for 3D bounding box regression via the minimization of 2D-3D projection error. The use of 2D detectors as a starting point for 3D computation has become a standard approach [18], [19].\nTransformers, with their spatial and temporal attention mechanisms, excel at modeling inter-object relationships across multiple frames. DETR [20] revolutionized object detection by eschewing traditional convolutional neural networks for a purely transformer-based approach, achieving comparable performance to CNN. Deformable DETR [21] builds upon the DETR framework by incorporating deformable attention mechanisms, leading to more accurate bounding box predictions.\nHybrid architectures [2], [22] aims to bridge the gap between CNNs and Transformers by leveraging both strengths. CNNs excel at extracting local features and capturing spatial relationships within images, while Transformers possess superior capabilities for modeling long-range dependencies and global context. CoAtNet [2] focuses on optimizing convolutions in shallow layers, demonstrating their effectiveness in capturing local spatial features. MoAT [22], introduces Multi-scale Object Attention, a novel attention module that dynamically weights feature maps across multiple scales within the network. This allows MoAT to effectively capture both fine-grained and global context, leading to state-of-the-art performance on image classification tasks. These works highlight the importance of a solid CNN feature extractor and its synergy along with the attention mechanism.\nCustomizing the architecture of CNN is crucial for optimizing the performance of both pure CNN models and hybrid models. Recent research [1] demonstrates that meticulously crafted CNN architectures like ConvNeXt can achieve performance on par with transformers, suggesting that architectural optimization within the CNN paradigm holds significant potential. Furthermore, studies [23], [24], [25] highlight the limitations of repurposing architectures designed for generic image tasks like ImageNet. The field necessitates a shift towards architectures crafted specifically for the nuances of the target domain."}, {"title": "B. Dataset for Autonomous Driving", "content": "Developing autonomous driving algorithms necessitates thorough training and validation across various driving scenarios. This section highlights two prominent datasets, nuScenes and Waymo Open Dataset, with a focus on their camera data characteristics.\n1) nuScenes: Captured in Boston and Singapore, nuScenes [7] boasts diverse urban driving environments with 1000 scenes, each 20 seconds long. It includes six synchronized cameras providing 360\u00b0 surround view coverage: five monocular cameras with 1600\u00d7900 resolution and one wide-FOV stereo camera with 1920 \u00d7 1080 resolution. The dataset has annotations for 23 classes, including cars, pedestrians, bicycles, and traffic signs.\n2) Waymo Open Dataset: The Waymo Motion Dataset [6], which comprises over 20,000 labeled driving segments collected from six cities across the United States. Each segment features data from six synchronized cameras mounted on the vehicle's roof, ensuring a 360\u00b0 surround view perspective. The cameras have varied resolutions, ranging from 1920 x 1080 to 1280 x 720. The dataset has annotations of 35 object classes, including vehicles, pedestrians, cyclists, and road elements."}, {"title": "III. BASE ARCHITECTURE DESIGN", "content": "In this section, we introduce the architectural design of our baseline camera feature encoder, which serves as the starting point of our exploration. The feature encoder is a key component of any 3D perception system (Fig. 1) that extracts meaningful features from data using CNNs or Hybrid architectures. Our encoder builds upon ConvNeXt [1], a transformer-like architecture that unlocks impressive performance gains in image classification, object detection, and segmentation among others. Some of the key features from ConvNeXt includes, large initial kernels, inverted bottlenecks, and depthwise separable convolutions.\nThe base model is a four-stage hierarchical design for extracting features from the input image, as illustrated in Fig. 2. The encoding process begins with a downsample block that reduces the spatial dimensions of the input image. Each stage consists of a downsample block and a variable number of convolutional blocks. The output from the second and third stages are skip-connected to the final stage. These skip connections help preserve important details from the earlier processing stages, allowing for a more robust and accurate output.\nThere are a multitude of design parameters in the model, including but not limited to the width and depth of the model, stage compute ratio, attention mechanisms, and input resolution. As detailed in our experimental section (Section IV), these parameters needs to be tuned to the needs of the data as they have a profound influence on the model's ultimate performance."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "We examine the model's micro-architecture design, fine-tuning its internal components like layers, kernels, normalization, and attention mechanism. Next, we explore macro-architecture design, including number of stages, blocks, block width & stage-compute-ratio. Then, we focus on altering the input resolution to maximize performance further. Lastly, we experiment with scaling the model to craft a spectrum of architecture with varying complexity for diverse deployment needs."}, {"title": "A. Experimental setup", "content": "To comprehensively evaluate the model efficacy and explore different design choices, we conduct experiments on our internal multi-camera 3D object detection dataset.\nDataset: Our internal large-scale experimental research dataset is annotated with up to four categories: car, truck, person, and bike. While publicly available datasets like Waymo and NuScenes serve well for research purposes, they lack the nuanced data crucial for industrial-level AV like long-range detection using high-resolution cameras and telephoto lenses. Our dataset has a significantly larger volume of data containing 2M scenes and an expansive detection range reaching 250 meters, surpassing the typical 50-100m range observed in the public dataset. The data is collected using eight cameras strategically placed around the vehicle with a resolution up to 3840 x 2160."}, {"title": "B. Micro-architecture Design", "content": "1) Block design: To optimize GPU performance, we modify ConvNeXt blocks with 3 \u00d7 3 convolutions for hardware compatibility and replace layer normalization with efficient batch normalization. We adopt a two-layered approach comprising of large kernel (LK) convolution and large channel (LC) convolution with bottleneck design (shrink-then-expand channels) for powerful feature extraction without sacrificing efficiency. This revised architecture, dubbed DriveNeXt, shown in Fig. 3, forms the core of our base model.\n2) Adding attention blocks: Inspired by CoAtNet [2], we strategically integrated attention modules to enhance feature representation and boost performance. We combined depthwise convolutions with multi-head self-attention in a stacked architecture, see Fig. 3. We place attention in third stage as per CoAtNet. Examining the impact of attention depth, four attention blocks emerged as optimal.\nMotivated by MOAT, we investigated alternating convolutional and attention layers. However, this offered no substantial gains (see Fig. 4). Consequently, we adopted a streamlined architecture with attention solely at the end, achieving 0.9% absolute mAP gain. While the hybrid architecture demonstrated a measurable performance boost, to prioritize training efficiency for subsequent explorations, we will use pure convolution based DriveNeXt block design."}, {"title": "C. Macro-architecture Design", "content": "1) Changing block width: Increasing the number of channels in layers is generally expected to provide better accuracy but at increased computation cost. We observe that increasing the number of channels in a large kernel layer beyond a certain level had marginal performance at best. For our model we found 128 channel count for large kernel layers to be optimal.\nSequentially increasing channel count across layers has been effective for general-purpose datasets as it demands learning a wider variety of abstract features to accommodate a large number of object classes. With AV dataset we observe that reducing the number of channels in the later stages of the model favorably improves the model speed without affecting mAP.\n2) Changing number of stages: we systematically varied the number of stages from 2 to 5 while ensuring that the model's complexity remained constant through adjustments in the number of blocks. From our analysis we found that a 4-stage architecture emerges as the optimal choice for our dataset with high resolution and expansive detection range. Architectures with fewer stages exhibit limited hierarchical representation, resulting in a constricted receptive field conducive to detect distant and small objects. Conversely, architectures with a more number of stages have broader receptive field, providing uniform performance across a spectrum of object scales within the image.\n3) Changing number of blocks: We examined the performance impact of increasing the number of blocks in each stage by factors of 2, 4, and 6 in our architecture. The resulting performance trend shown in Fig. 5, reveals a critical finding: early stages significantly benefit from additional blocks, while later stages exhibit diminishing returns.\n4) Tuning stage compute ratio: Optimizing the stage-wise compute ratio, defined as the relative computational expenditure assigned to each stage, is paramount to balancing model performance and efficiency for our specific task: detecting smaller objects in datasets with a limited number of classes. Through a systematic exploration of a range of compute ratios, we identified that a 1:7:4: 1 ratio emerged as the most effective configuration for encoder architecture. We show the relative performance of top-performing models across different classes in Fig. 6. While no single model dominates across all classes, the stage computes the ratio of 1-7-4-1 and exhibits balanced performance across all classes."}, {"title": "D. Effect of input resolution", "content": "We explore further performance gains by investigating the model's sensitivity to input resolution. Previous works [3], [1] have successfully employed downsampling techniques to improve computational efficiency during training. As we need our model to be effective in detecting long distance objects, we remove the initial downsample layer to make the network operate at its native resolution i.e., double the input size. The full-resolution model achieved a 2% absolute mAP improvement compared to its downsampled counterpart. This comes at a quadrupled compute cost but improves model performance, particularly when detecting distant objects.\nOur design decisions have collectively enhanced the model's performance, resulting in an improvement over the baseline model from 72.8% mAP to an optimal model with 79.2% mAP. Fig. 8 summarizes improvement in model performance with each stage of tuning."}, {"title": "E. Experimenting with Architectural Scaling", "content": "We construct different variants of the model, Tiny/Small/Base/Large (denoted at T/S/B/L for simplicity), to be of similar complexities to CoAtNet [2]. The Tiny & Small variants are suitable for online processing whereas the Base & Large variants are targeted for offline processing. Our base model is the end product of the progressive architecture refinement. The variants only differ in the number of channels, and the number of blocks in each stage. We summarize the configurations in Table I.\nAs seen from our results in Fig. 7 the optimized model scales well across the spectrum, offering versatility for different online and offline processing needs."}, {"title": "V. DISCUSSION", "content": "Adapting the model to AV data led to significant design modifications. In this section we summarize the key findings.\n\u2022 Prioritizing feature extraction and amplification in the initial stages with more number of blocks/channels, where larger feature map facilitates long range detection, proved to be more beneficial than the traditional approach of expanding the network width in deeper layers.\n\u2022 Reducing the model capacity in later stages reduces the complexity while maintaining accuracy, a further advantage facilitated by the smaller number of classes compared to models trained on large class datasets.\n\u2022 We underscore the importance of tailoring stage-compute-ratio to individual tasks and datasets. This optimal configuration not only delivers superior performance for our specific objective but also opens doors for potential application to other tasks involving small object detection or limited class sets.\n\u2022 By integrating a self-attention module into our CNN architecture, we achieve additional performance gains, demonstrating the strong potential of hybrid approaches.\n\u2022 Interestingly, no single model achieves peak performance across all object classes. This observation highlights the potential for further exploration and targeted model specialization to achieve best class-wise accuracy.\n\u2022 Operating the network at higher resolution contributed to improved accuracy, despite the quadrupled computational overhead. While we simply remove the initial downsample layer of the model, there are multiple ways to effectively leverage the high resolution details which could likely lead to better accuracy and lower computational overhead."}, {"title": "VI. CONCLUSIONS", "content": "This work presents a series of design changes that adapts the model to address the needs of AV dataset. Our results show that the customization has led to significant accuracy improvement over the baseline, culminating in an optimized family of model architectures. Our findings not only pave the way for further advancements in AV perception but also highlight the value of customization to achieve best performance on any new dataset."}]}