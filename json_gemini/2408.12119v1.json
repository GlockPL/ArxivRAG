{"title": "Understanding Data Reconstruction Leakage in Federated Learning from a Theoretical Perspective", "authors": ["Zifan Wang", "Binghui Zhang", "Meng Pang", "Yuan Hong", "Binghui Wang"], "abstract": "Federated learning (FL) is an emerging collaborative learning paradigm that aims to protect data privacy. Unfortunately, recent works show FL algorithms are vulnerable to the serious data reconstruction attacks. However, existing works lack a theoretical foundation on to what extent the devices' data can be reconstructed and the effectiveness of these attacks cannot be compared fairly due to their unstable performance. To address this deficiency, we propose a theoretical framework to understand data reconstruction attacks to FL. Our framework involves bounding the data reconstruction error and an attack's error bound reflects its inherent attack effectiveness. Under the framework, we can theoretically compare the effectiveness of existing attacks. For instance, our results on multiple datasets validate that the iDLG attack inherently outperforms the DLG attack.", "sections": [{"title": "1 Introduction", "content": "The emerging federated learning (FL) [31] has been a great potential to protect data privacy. In FL, the participating devices keep and train their data locally, and only share the trained models (e.g., gradients or parameters), instead of the raw data, with a center server (e.g., cloud). The server updates its global model by aggregating the received device models, and broadcasts the updated global model to all participating devices such that all devices indirectly use all data from other devices. FL has been deployed by many companies such as Google [15], Microsoft [32], IBM [21], Alibaba [2], and applied in various privacy-sensitive applications, including on-device item ranking [31], content suggestions for on-device keyboards [6], next word prediction [27], health monitoring [38], and medical imaging [23].\nUnfortunately, recent works show that, though only sharing device models, it is still possible for an adversary (e.g., malicious server) to perform the severe data reconstruction attack (DRA) to FL [57], where an adversary could directly reconstruct the device's training data via the shared device models. Later, a bunch of follow-up enhanced attacks [20, 45, 55, 51, 47, 53, 22, 56, 9, 3, 30, 11, 43, 48, 18, 49, 35]) are proposed by either incorporating (known or unrealistic) prior knowledge or requiring an auxiliary dataset to simulate the training data distribution.\nHowever, we note that existing DRA methods have several limitations: First, they are sensitive to the initialization (which is also observed in [47]). For instance, we show in Figure 1 that the attack performance of iDLG [55] and DLG [57] are significantly influenced by initial parameters (i.e., the mean and standard deviation) of a Gaussian distribution, where the initial data is sampled from. Second, existing DRAs mainly show comparison results on a FL model"}, {"title": "2 Related Work", "content": "Existing DRAs to FL are roughly classified as optimization based and close-form based.\nOptimization-based DRAs to FL: A series of works [20, 57, 45, 55, 47, 53, 22, 9, 3, 11, 48, 30] formulate DRAs as the gradient matching problem, i.e., an optimization problem that minimizes the difference between gradient from the raw data and that from the reconstructed counterpart. Some works found the gradient itself includes insufficient information to well recover the data [22, 56]. For example, [56] show there exist pairs of data (called twin data) that visualize different, but have the same gradient. To mitigate this issue, a few works propose to incorporate prior knowledge (e.g., total variation (TV) regularization [13, 53], batch normalization (BN) statistics [53]) into the training data, or introduce an auxiliary dataset to simulate the training data distribution [20, 45, 22] (e.g., via generative adversarial networks (GANs) [14]). Though empirically effective, these methods are less practical or data inefficient, e.g., TV is limited to natural images, BN statistics are often unavailable, and training an extra model (e.g., GAN [14]) requires a large amount of data samples."}, {"title": "3 Preliminaries and Problem Setup", "content": ""}, {"title": "3.1 Federated Learning (FL)", "content": "The FL paradigm enables a server to coordinate the training of multiple local devices through multiple rounds of global communications, without sharing the local data. Suppose there are N devices and a central server participating in FL. Each k-th device owns a training dataset $\\mathcal{D}^{k}=\\left{\\left(x_{j}, y_{j}\\right)\\right\\}_{j=1}^{n_{k}}$ with $n_k$ samples, and each sample $x$ has a label $y$. FL considers the following distributed optimization problem:\n$$\\min _{w} L(w)=\\frac{1}{N} \\sum_{k=1}^{N} \\rho_{k} L_{k}(w),$$\nwhere $\\rho_{k} \\geq 0$ is the weight of the k-th device and $\\Sigma_{k=1}^{N} \\rho_{k}=1$; the k-th device's local objective is defined by $L_{k}(w)=\\frac{1}{n_{k}} \\sum_{j=1}^{n_{k}} l(w ;(x, y))$, with $l(\\cdot ;)$ an algorithm-dependent loss function.\nFedAvg [31]: It is the de factor FL algorithm to solve Equation (1) in an iterative way. In each communication round, each k-th device only shares the gradients $\\nabla_{w} L_{k}(w)$ instead of the raw data $\\mathcal{D}^{k}$ to the server. Specifically, in the current round $t$, each k-th device first downloads the latest global model (denoted as $w^{t-1}$) from the server and initializes its local model as $w_{k}^{0}=w^{t-1}$; then it performs (e.g., $E$) local SGD updates as below:\n$$w_{k}^{t+j}=w_{k}^{t+j-1}-\\eta_{t+j} \\nabla l\\left(w_{k}^{t+j-1} ; \\xi_{t+j}^{k}\\right), j=1, \\ldots, E$$ where $\\eta_{t+j}$ is the learning rate and $\\xi_{t+j}^{k}$ is sampled from the local data $\\mathcal{D}^{k}$ uniformly at random. Next, the server updates the global model $w_{t}$ by aggregating full or partial device models. The final global model, i.e., $w_T$, is downloaded by all devices for their learning tasks.\n$\\text{N}$$\\text{N}$$\\text{N}$N$$\\sum_{k \\in \\mathcal{S}t}$$\\text{C}$\u2022 Full device participation. It requires all device models for aggregation, and the server performs $w_{t} \\leftarrow \\sum_{k=1}^{N} \\rho_{k} w_{k}^{t}$ with $\\rho_{k}=\\frac{n_{k}}{\\sum_{i=1}^{N} n_{i}}$ and $w_{k}^{t}=w_{k}^{t+E}$. This means the server must wait for the slowest devices, which is often unrealistic in practice.\n\u2022 Partial device participation. This is a more realistic setting as it does not require the server to know all device models. Suppose the server only needs $K(<N)$ device models for aggregation and discards the remaining ones. Let $\\mathcal{S}_{t}$ be the set of $K$ chosen devices in the t-th iteration. Then, the server's aggregation step performs $w_{t} \\leftarrow \\sum_{k=1} C kE \\rho_{k} w_{k}^{t}$ with $w_{k}^{t}=w_{k}^{t+E}$\nQuantifying the degree of non-IID (heterogeneity): Real-world FL applications often do not satisfy the IID assumption for data among local devices. [28] proposed a way to quantify the degree of non-IID. Specifically, let $\\mathcal{L}^{*}$ and $\\mathcal{L}_{k}^{*}$ be the minimum values of $\\mathcal{L}$ and $L_k$, respectively. Then, the term $I=\\mathcal{L}^{*}-\\sum_{k=1}^{N} \\rho_{k} \\mathcal{L}_{k}^{*}$ is used for quantifying the non-IID. If the data are IID, then $I$ goes to zero as the number of samples grows. If the data are non-IID, then $I$ is nonzero, and its magnitude reflects the heterogeneity of the data distribution."}, {"title": "3.2 Optimization-based DRAs to FL", "content": "Existing DRAs assume an honest-but-curious server, i.e., the server has access to all device models in all communication rounds, follows the FL protocol, and aims to infers devices' private data. Given the private data $x \\in[0,1]^{d}$ with private label $y^{1}$, we denote the reconstructed data by a malicious server as $(\\tilde{x}, \\tilde{y})=\\mathcal{R}\\left(w_{t}\\right)$, where $\\mathcal{R}(\\cdot)$ indicates a data reconstruction function, and we can be any intermediate global model.\nModern optimization-based DRAs use different $\\mathcal{R}(\\cdot)$, but majorly base on gradient match- ing. Specifically, they solve the optimization problem:\n$$(\\tilde{x}, \\tilde{y})=\\mathcal{R}\\left(w_{t}\\right)=\\arg \\min _{\\mathbf{x}^{\\prime} \\in[0,1]^{d}, y^{\\prime}} G M L\\left(g_{w_{t}}(x, y), g_{w_{t}}\\left(x^{\\prime}, y^{\\prime}\\right)\\right)+R e g\\left(x^{\\prime}\\right)$$\nwhere we denote the gradient of loss w.r.t. $(x, y)$ be $g_{w_{t}}(x, y)=\\nabla_{w} L\\left(w_{t} ;(x, y)\\right)$ for notation simplicity. $GML(\\cdot, \\cdot)$ means the gradient matching loss (i.e., the distance between the real gradients and estimated gradients) and $R e g(\\cdot)$ is an auxiliary regularizer for the reconstruction. Here, we list $GML(\\cdot, \\cdot)$ and $R e g(\\cdot)$ for three representative DRAs, and more attacks are shown in Appendix D.2.\n\u2022 DLG [57] uses mean squared error as the gradient matching loss, i.e., $G M L\\left(g_{w_{t}}(x, y), g_{w_{t}}\\left(x^{\\prime}, y^{\\prime}\\right)\\right)=\\left\\|g_{w_{t}}(x, y)-g_{w_{t}}\\left(x^{\\prime}, y^{\\prime}\\right)\\right\\|_{2}^{2}$ and uses no regularizer.\n\u2022 iDLG [55] estimates the label $y$ before solving Equation (3). Assuming the estimated label is $\\hat{y}$, iDLG solves $x=\\arg \\min _{x^{\\prime}, \\mathbf{E}_{x}} \\left[G M L\\left(g_{w_{t}}(x, y), g_{w_{t}}\\left(x^{\\prime}, \\hat{y}\\right)\\right)+\\lambda R e g\\left(x^{\\prime}\\right)\\right]$, where it uses the same $GML(\\cdot)$ as DLG and also has no regularizer.\n\u2022 InvGrad [13] improves upon DLG and iDLG. It first estimates the private label as $\\hat{y}$ in advance. Then it uses a negative cosine similarity as GML(\u00b7) and a total variation regularizer $R e g_{T V}(\\cdot)$ as an image prior. Specifically, InvGrad solves for $\\mathbf{x}=\\arg \\min _{x^{\\prime}, \\mathbf{E}_{x}}\\left[1-\\frac{\\left\\langle g_{w_{t}}(x, y), g_{w_{t}}\\left(x^{\\prime}, \\hat{y}\\right)\\right\\rangle}{\\left\\|g_{w_{t}}(x, y)\\right\\|_{2}\\left\\|g_{w_{t}}\\left(x^{\\prime}, \\hat{y}\\right)\\right\\|_{2}}+R e g_{T V}\\left(x^{\\prime}\\right)\\right]$.\nAlgorithm 1 shows the pseudo-code of iterative solvers for DRAs and Algorithm 4 in Appendix shows more details for each attack. As the label $y$ can be often accurately inferred, we now only consider reconstructing the data $x$ for notation simplicity. Then, the attack performance is measured by the similarity $s i m(x, \\tilde{x})$ between y and x. The larger similarity, the better attack performance. In the paper, we use the common similarity metric, i.e., the negative mean-square-error $\\operatorname{sim}(x, \\tilde{x})=-\\mathbf{E}\\left\\|x-\\tilde{x}\\right\\|^{2}$, where the expectation $\\mathbf{E}$ considers the randomness during reconstruction."}, {"title": "4 A Theoretical Framework to Understand DRAS to FL", "content": "Though many DRAs to FL have been proposed, it is still unknown how to theoretically compare the effectiveness of existing attacks, as stated in Introduction. In this section, we understand DRAs to FL from a theoretical perspective. We first derive a reconstruction error bound for convex objective losses. The error bound involves knowing the Lipschitz constant of the data reconstruction function. Directly calculating the exact Lipschitz constant is computationally challenging. We then adapt existing methods to calculate its upper bound. We argue that"}, {"title": "4.1 Bounding the Data Reconstruction Error", "content": "Give random data x from a device, our goal is to bound the common norm-based reconstruction error2, i.e., $\\mathbf{E}\\|x-\\mathcal{R}\\left(w_{t}\\right)\\|^{2}$ at any round t, where $\\mathcal{R}(\\cdot)$ can be any DRA and the expectation considers the randomness in $\\mathcal{R}(\\cdot)$, e.g., due to different initializations. Directly bounding this error is challenging because the global model dynamically aggregates local device models, which are trained by a (stochastic) learning algorithm and whose learning procedure is hard to characterize during training. To alleviate this issue, we introduce the optimal global model $w^{*}$ that can be learnt by the FL algorithm. Then, we can bound the error as follows:\n$$\\begin{aligned} \\mathbf{E}\\left\\|x-\\mathcal{R}\\left(w_{t}\\right)\\right\\|^{2} & =\\mathbf{E}\\left\\|x-\\mathcal{R}\\left(w^{*}\\right)+\\mathcal{R}\\left(w^{*}\\right)-\\mathcal{R}\\left(w_{t}\\right)\\right\\|^{2} \\\\ & \\leq 2\\left(\\mathbf{E}\\left\\|x-\\mathcal{R}\\left(w^{*}\\right)\\right\\|^{2}+\\mathbf{E}\\left\\|\\mathcal{R}\\left(w^{*}\\right)-\\mathcal{R}\\left(w_{t}\\right)\\right\\|^{2}\\right). \\end{aligned}$$\nNote that the first term in Equation (4) is a constant and can be directly computed under a given reconstruction function $\\mathcal{R}(\\cdot)$ and a convex loss used in FL. Specifically, if the loss in each device is convex, the global model can converge to the optimal $w^{*}$ based on theoretical results in [28]. Then we can obtain $\\mathcal{R}(w^{*})$ per attack and compute the first term. In our experiments, we run the FL algorithm until the loss difference between two consecutive iterations is less than 1e-5, and treat the final global model as $w^{*}$.\nNow our goal reduces to bounding the second term. However, it is still challenging without knowing any property of the reconstruction function $\\mathcal{R}(\\cdot)$. In practice, we note $\\mathcal{R}(\\cdot)$ is often Lipschitz continuous, which can be verified later.\nProposition 1. $\\mathcal{R}(\\cdot)$ is $L_{\\mathcal{R}}$-Lipschitz continuous: there exists a constant $L_{\\mathcal{R}}$ such that $\\left\\|\\mathcal{R}(v)-\\mathcal{R}(w)\\right\\| \\leq L_{\\mathcal{R}}\\|v-w\\|, \\forall v, w$. The smallest $L_{\\mathcal{R}}$ is called the Lipschitz constant.\nNext, we present our theoretical results and their proofs are seen in Appendix B and Appendix C, respectively. Note that our error bounds consider all randomness in FL training and data reconstruction."}, {"title": "4.2 Computing the Lipschitz Constant for Data Reconstruction Functions", "content": "We show how to calculate the Lipschitz constant for data reconstruction function. Our idea is built upon the strong connection between optimizing DRAs and the corresponding unrolled deep networks; and then adapt existing methods to approximate the Lipschitz upper bound.\nIterative solvers for optimization-based DRAs as unrolled deep feed-forward net- works: Recent works [7, 29, 34] show a strong connection between iterative algorithms and deep network architectures. The general idea of algorithm unrolling is: starting with an abstract iterative algorithm, we map one iteration into a single network layer, and stack a finite number of (e.g., H) layers to form a deep network, which is also called unrolled deep network. Feeding the data through an H-layer network is hence equivalent to executing the iterative algorithm H iterations. The parameters of the unrolled networks are learnt from data by training the network in an end-to-end fashion. From Algorithm 1, we can see the trajectory of"}, {"title": "5 Evaluation", "content": ""}, {"title": "5.1 Experimental Setup", "content": "Datasets and models: We conduct experiments on three benchmark image datasets, i.e., MNIST [25], Fashion-MNIST (FMNIST) [50], and CIFAR10 [24]. We examine our theoretical results on the FL algorithm that uses the l2-regularized logistic regression (l2-LogReg) and the convex 2-layer linear convolutional network (2-LinConvNet) [37], since their loss functions satisfy Assumptions 1-4. In the experiments, we evenly distribute the training data among the N devices. Based on this setting, we can calculate L, \u03bc, \u03c3\u03ba, and G used in our theorems, respectively. In addition, we can compute the Lipschitz constant LR via the unrolled feed-forward network. These values together are used to compute the upper bound of our Theorems 1 and 2. More details about the two algorithms, the unrolled feed-forward network, and the calculation of these parameter values are shown in Appendix D.\nAttack baselines: We test our theoretical results on four optimization-based data recon- struction attacks, i.e., DLG [57], iDLG [55], InvGrad [13], and GGL [30]. The algorithms and descriptions of these attacks are deferred to Appendix D. We test these attacks on recovering both the single image and a batch of images in each device.\nParameter setting: Several important hyperparameters in the FL training (i.e., federated l2-LogReg or federated 2-LinConvNet) that would affect our theoretical results: the total number of devices N, the total number of global rounds T, and the number of local SGD updates E. By default, we set T = 100 and E = 2. We set N = 10 on the three datasets for the single image recovery, while set N = 15,10,5 on the three datasets for the batch images recovery, considering their different difficulty levels. we consider full device participation. When studying the impact of these hyperparameters, we fix others as the default value."}, {"title": "5.2 Experimental Results", "content": "In this section, we test the upper bound reconstruction error by our theoretical results for single image and batch images recovery. We also show the average (across 10 iterations) reconstruc- tion errors that are empirically obtained by the baseline DRAs with different initializations. The best possible (one-snapshot) empirical results of baseline attacks are reported in Table 1."}, {"title": "5.2.1 Results on single image recovery", "content": "Figure 3-Figure 8 show the single image recovery results on the three datasets and two FL algorithms, respectively. We have several observations. First, iDLG has smaller upper bound errors than DLG, indicating iDLG outperforms DLG intrinsically. One possible reason is that iDLG can accurately estimate the labels, which ensures data reconstruction to be more stable."}, {"title": "5.2.2 Results on batch images recovery", "content": "Figures 9-11 show the results of batch images recovery on the three image datasets. As feder- ated 2-LinConvNet has similar trends, we only show federated l2-LogReg results for simplicity. First, similar to results on single image recovery, GGL performs the best; InvGrad outperforms iDLG, which outperforms DLG both empirically and theoretically. Moreover, a larger E and N incur larger upper bound error, while a larger T generates smaller upper bound error. Second, both empirical errors and upper bound errors for batch images recovery are much larger than those for single image recovery. This indicates that batch images recovery are more difficult than single image recovery, as validated in many existing works such as [13, 53]."}, {"title": "6 Discussion", "content": "First term vs second term in the error bound: We calculate the first term and second term of the error bound in our theorem in the default setting. The two terms in DLG, iDLG, InvGrad, and GGL on MNIST are (30.48, 396.72), (25.25, 341.10), (22.06, 218.28), and (20.21, 29.13) respectively. This implies the second term dominates the error bound.\nError bounds vs. degree of non-IID: The non-IID of data across clients can be controlled by the number of classes per client-small number indicates a larger degree of non-IID. Here, we tested #classes=2, 4, 6, 8 on MNIST and the results are shown in Figure 12a. We can see the bounded errors are relatively stable vs. #classes on DLG, iDLG, and GGL, while InvGrad has a larger error as the #classes increases. The possible reason is that DLG and iDLG are more stable than InvGrad, which involves a more complex optimization.\nError bounds vs. batch size: Our batch results use a batch size 20. Here, we also test batch size=10, 15, 25, 30 and results are in Figure 12b. We see bounded errors become larger with larger batch size. This is consistent with existing observations [13] on empirical evaluations.\nError bounds on closed-form DRAs: Our theoretical results can be also applied in closed- form attacks. Here, we choose the Robbing attack [11] for evaluation and its details are in Appendix D.2. The results for single image and batch images recovery on the three datasets and two FL algorithms are shown in Figures 13, 14, and 15, respectively. We can see Robbing obtains both small empirical errors and bounded errors (which are even smaller than GGL). This is because its equation solving is suitable to linear layers, and hence relatively accurate on the federated 12-LogReg and federated 2-LinConvNet models."}, {"title": "7 Conclusion", "content": "Federated learning (FL) is vulnerable to data reconstruction attacks (DRAs). Existing attacks mainly enhance the empirical attack performance, but lack a theoretical understanding. We study DRAs to FL from a theoretical perspective. Our theoretical results provide a unified way to compare existing attacks theoretically. We also validate our theoretical results via evaluations on multiple datasets and baseline attacks. Future works include: 1) designing better or adapting existing Lipschitz estimation algorithms to obtain tighter error bounds; 2) generalizing our theoretical results to non-convex losses; 3) designing theoretically better DRAs (i.e., with smaller Lipschitz) as well as effective defenses against the attacks (i.e., ensuring larger Lipschitz of their reconstruction function), inspired by our framework; and 4) developing effective provable defenses against DRAs."}, {"title": "A Assumptions", "content": "Assumptions on the devices' loss function: To ensure FedAvg guarantees to converge to the global optimal, existing works have the following assumptions on the local devices' loss functions {Lk}.\nAssumption 1. {Lk}'s are L-smooth: $L_{k}(v) \\leq L_{k}(w)+(v-w)^{T} \\nabla L_{k}(w)+\\frac{L}{2}\\|v-w\\|^{2}, \\forall v, w$."}, {"title": "B Proof of Theorem 1 for Full Device Participation", "content": "Our proof is mainly inspired by the proofs in [41, 54, 28].\nNotations: Let $N$ be the total number of user devices and $K(\\leq N)$ be the maximal number of devices that participate in every communication round. Let $T$ be the total number of every device's SGDs, and $E$ be the number of each device's local updates between two communication rounds. Thus $T / E$ is the number of communications, assuming $E$ is dividable by $T$.\nLet $w_{k}^{t}$ be the model parameter maintained in the $k$-th device at the $t$-th step. Let $\\mathbb{I}_{E}$ be the set of global aggregation steps, i.e., $\\mathbb{I}_{E}=\\{n E \\mid n=1,2, \\ldots\\}$. If $t+1 \\notin \\mathbb{I}_{E}$, i.e., the devices communicate with the server and the server performs the FedAvg aggregation on device models. Then the update of FedAvg with partial devices active can be described as\n$$\\begin{aligned} v_{k}^{t+1} & =w_{k}^{t}-\\eta_{t} \\nabla L_{k}\\left(w_{k}^{t}, \\xi_{t}^{k}\\right), \\\\ w_{t+1} & =\\left\\{\\begin{array}{ll} v_{t+1} & \\text { if } t+1 \\notin \\mathbb{I}_{E}, \\\\ \\sum_{k=1}^{N} \\rho_{k} v_{k}^{t+1} & \\text { if } t+1 \\in \\mathbb{I}_{E}. \\end{array}\\right. \\end{aligned}$$\nMotivated by [41, 28], we define two virtual sequences $v_{t}=\\sum_{k=1}^{N} \\rho_{k} v_{k}^{t}$ and $w_{t}=\\sum_{k=1}^{N} \\rho_{k} w_{k}^{t}$.\n$v_{t+1}$ results from an single step of SGD from $w_{t}$. When $t+1 \\notin \\mathbb{I}_{E}$, both are inaccessible. When $t+1 \\in \\mathbb{I}_{E}$, we can only fetch $w_{t+1}$. For convenience, we define $g_{t}=\\sum_{k=1}^{N} \\rho_{k} \\nabla L_{k}\\left(w_{k}^{t}\\right)$ and $g_{t}=\\sum_{k=1}^{N} \\rho_{k} \\nabla L_{k}\\left(w_{k}^{t}, \\xi_{t}^{k}\\right)$. Hence, $v_{t+1}=w_{t}-\\eta_{t} g_{t}$ and $\\mathbb{E} g_{t}=g_{t}$.\nBefore proving Theorem 1, we need below key lemmas that are from [41, 28].\nLemma 2 (Results of one step SGD). Assume Assumptions 1 and 2 hold. If $\\eta_{t} \\leq \\frac{1}{\\mu}$, we have\n$$\\begin{aligned} \\mathbb{E}\\left\\|v_{t+1}-w^{*}\\right\\|^{2} & \\leq\\left(1-\\eta_{t} \\mu\\right) \\mathbb{E}\\left\\|w_{t}-w^{*}\\right\\|^{2}+\\eta_{t}^{2} \\mathbb{E}\\left\\|g_{t}-g_{t}\\right\\|^{2}+6 L \\eta_{t} \\Gamma+2 L \\eta_{t} \\sum_{k=1}^{N} \\rho_{k}\\left\\|w_{k}^{t}-w_{t}\\right\\|^{2} \\end{aligned}$$\nwhere $\\Gamma=\\mathcal{L}^{*}-\\sum_{k=1}^{N} \\rho_{k} \\mathcal{L}_{k}^{*} \\geq 0$."}, {"title": "CProofs of Theorem 2 for Partial Device Participation", "content": "Recall that $w_{k"}, {"28": "we can use a thought trick to circumvent this difficulty. Specifically", "as": "n$$\\begin{aligned"}, "v_{k}^{t+1} & =w_{k}^{t}-\\eta_{t} \\nabla l\\left(w_{k}^{t}, \\xi_{t}^{k}\\right), \\\\ w_{t+1} & =\\left\\{\\begin{array}{ll} v_{t+1} & \\text { if } t+1 \\notin \\mathbb{I}_{E}, \\\\ \\text { samples } \\mathcal{S}_{t+1} \\text { and average }\\left\\{v_{k}^{t+1}\\right\\}_{k \\in \\mathcal{S}_{t+1}} & \\text { if } t+1 \\in \\mathbb{I}_{E}. \\end{array}\\right. \\end{aligned}$$\nNote that in this case, there are two sources of randomness: stochastic gradient and random sampling of devices. The analysis for Theorem 1 in Appendix B only involves the former. To distinguish with it, we use an extra notation $\\mathbb{E}_{S_{t}}(\\cdot)$ to consider the latter randomness.\nFirst, based on [28"]}