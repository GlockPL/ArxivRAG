{"title": "Understanding Data Reconstruction Leakage in Federated Learning from a Theoretical Perspective", "authors": ["Zifan Wang", "Binghui Zhang", "Meng Pang", "Yuan Hong", "Binghui Wang"], "abstract": "Federated learning (FL) is an emerging collaborative learning paradigm that aims to protect data privacy. Unfortunately, recent works show FL algorithms are vulnerable to the serious data reconstruction attacks. However, existing works lack a theoretical foundation on to what extent the devices' data can be reconstructed and the effectiveness of these attacks cannot be compared fairly due to their unstable performance. To address this deficiency, we propose a theoretical framework to understand data reconstruction attacks to FL. Our framework involves bounding the data reconstruction error and an attack's error bound reflects its inherent attack effectiveness. Under the framework, we can theoretically compare the effectiveness of existing attacks. For instance, our results on multiple datasets validate that the iDLG attack inherently outperforms the DLG attack.", "sections": [{"title": "1 Introduction", "content": "The emerging federated learning (FL) [31] has been a great potential to protect data privacy. In FL, the participating devices keep and train their data locally, and only share the trained models (e.g., gradients or parameters), instead of the raw data, with a center server (e.g., cloud). The server updates its global model by aggregating the received device models, and broadcasts the updated global model to all participating devices such that all devices indirectly use all data from other devices. FL has been deployed by many companies such as Google [15], Microsoft [32], IBM [21], Alibaba [2], and applied in various privacy-sensitive applications, including on-device item ranking [31], content suggestions for on-device keyboards [6], next word prediction [27], health monitoring [38], and medical imaging [23].\nUnfortunately, recent works show that, though only sharing device models, it is still possible for an adversary (e.g., malicious server) to perform the severe data reconstruction attack (DRA) to FL [57], where an adversary could directly reconstruct the device's training data via the shared device models. Later, a bunch of follow-up enhanced attacks [20, 45, 55, 51, 47, 53, 22, 56, 9, 3, 30, 11, 43, 48, 18, 49, 35]) are proposed by either incorporating (known or unrealistic) prior knowledge or requiring an auxiliary dataset to simulate the training data distribution.\nHowever, we note that existing DRA methods have several limitations: First, they are sensitive to the initialization (which is also observed in [47]). For instance, we show in Figure 1 that the attack performance of iDLG [55] and DLG [57] are significantly influenced by initial parameters (i.e., the mean and standard deviation) of a Gaussian distribution, where the initial data is sampled from. Second, existing DRAs mainly show comparison results on a FL model"}, {"title": "2 Related Work", "content": "Existing DRAs to FL are roughly classified as optimization based and close-form based.\nOptimization-based DRAs to FL: A series of works [20, 57, 45, 55, 47, 53, 22, 9, 3, 11, 48, 30] formulate DRAs as the gradient matching problem, i.e., an optimization problem that minimizes the difference between gradient from the raw data and that from the reconstructed counterpart. Some works found the gradient itself includes insufficient information to well recover the data [22, 56]. For example, [56] show there exist pairs of data (called twin data) that visualize different, but have the same gradient. To mitigate this issue, a few works propose to incorporate prior knowledge (e.g., total variation (TV) regularization [13, 53], batch normalization (BN) statistics [53]) into the training data, or introduce an auxiliary dataset to simulate the training data distribution [20, 45, 22] (e.g., via generative adversarial networks (GANs) [14]). Though empirically effective, these methods are less practical or data inefficient, e.g., TV is limited to natural images, BN statistics are often unavailable, and training an extra model (e.g., GAN [14]) requires a large amount of data samples."}, {"title": "3 Preliminaries and Problem Setup", "content": ""}, {"title": "3.1 Federated Learning (FL)", "content": "The FL paradigm enables a server to coordinate the training of multiple local devices through multiple rounds of global communications, without sharing the local data. Suppose there are N devices and a central server participating in FL. Each k-th device owns a training dataset $D^k = \\{(x_j, y_j)\\}_{j=1}^{n_k}$ with $n_k$ samples, and each sample $x_j$ has a label $y_j$. FL considers the following distributed optimization problem:\n\n$\\min_w L(w) = \\frac{1}{N}\\sum_{k=1}^{N} \\rho_k L_k(w),$                                  (1)\n\nwhere $\\rho_k \\geq 0$ is the weight of the k-th device and $\\Sigma_{k=1}^{N} \\rho_k = 1$; the k-th device's local objective is defined by $L_k(w) = \\frac{1}{n_k}\\Sigma_{j=1}^{n_k} l(w; (x_j, y_j))$, with $l(\\cdot;)$ an algorithm-dependent loss function.\nFedAvg [31]: It is the de factor FL algorithm to solve Equation (1) in an iterative way. In each communication round, each k-th device only shares the gradients $\\nabla_w L_k(w)$ instead of the raw data $D^k$ to the server. Specifically, in the current round $t$, each k-th device first downloads the latest global model (denoted as $w^{t-1}$) from the server and initializes its local model as $w_k^0 = w^{t-1}$; then it performs (e.g., $E$) local SGD updates as below:\n\n$w_k^{t+j} = w_k^{t+j-1} - \\eta_{t+j} \\nabla_w l(w_k^{t+j-1}; \\xi_{t+j}^k), j = 1, \\dots, E$                                (2)\n\nwhere $\\eta_{t+j}$ is the learning rate and $\\xi_{t+j}^k$ is sampled from the local data $D^k$ uniformly at random. Next, the server updates the global model $w_t$ by aggregating full or partial device models. The final global model, i.e., $w_T$, is downloaded by all devices for their learning tasks.\n\n*   Full device participation. It requires all device models for aggregation, and the server\n    performs $w_t \\leftarrow \\Sigma_{k=1}^{N} \\rho_k w_k^{t+E}$ with $\\rho_k = \\frac{n_k}{\\Sigma_{j=1}^{N} n_j}$ and $w_k^{t+E} = w_k$. This means the server\n    must wait for the slowest devices, which is often unrealistic in practice.\n*   Partial device participation. This is a more realistic setting as it does not require the\n    server to know all device models. Suppose the server only needs $K (< N)$ device models\n    for aggregation and discards the remaining ones. Let $S_t$ be the set of $K$ chosen devices\n    in the $t$-th iteration. Then, the server's aggregation step performs $w_t \\leftarrow \\Sigma_{k \\in S_t} \\rho_k w_k^{t+E}$\n    with $w_k^{t+E} = w_k$.\n\nQuantifying the degree of non-IID (heterogeneity): Real-world FL applications often do not satisfy the IID assumption for data among local devices. [28] proposed a way to quantify the degree of non-IID. Specifically, let $L^*$ and $L_k^*$ be the minimum values of $L$ and $L_k$, respectively. Then, the term $I = L^* - \\sum_{k=1}^N \\rho_k L_k^*$ is used for quantifying the non-IID. If the data are IID, then $I$ goes to zero as the number of samples grows. If the data are non-IID, then $I$ is nonzero, and its magnitude reflects the heterogeneity of the data distribution."}, {"title": "3.2 Optimization-based DRAs to FL", "content": "Existing DRAs assume an honest-but-curious server, i.e., the server has access to all device models in all communication rounds, follows the FL protocol, and aims to infers devices' private data. Given the private data $x \\in [0, 1]^d$ with private label $y^1$, we denote the reconstructed data by a malicious server as $(\\hat x, \\hat y) = R(w_t)$, where $R(\\cdot)$ indicates a data reconstruction function, and $w_t$ can be any intermediate global model.\nModern optimization-based DRAs use different $R(\\cdot)$, but majorly base on gradient match- ing. Specifically, they solve the optimization problem:\n\n$(\\hat x, \\hat y) = R(w_t) = \\underset{x'\\in[0,1]^d,y'}{\\text{arg min}} GML(g_{w_t}(x, y), g_{w_t}(x', y')) + Reg(x')$                      (3)\n\nwhere we denote the gradient of loss w.r.t. $(x, y)$ be $g_{w_t}(x, y) = \\nabla_w L(w_t; (x, y))$ for notation simplicity. $GML(\\cdot, \\cdot)$ means the gradient matching loss (i.e., the distance between the real gradients and estimated gradients) and $Reg(\\cdot)$ is an auxiliary regularizer for the reconstruction. Here, we list $GML(\\cdot, \\cdot)$ and $Reg(\\cdot)$ for three representative DRAs, and more attacks are shown in Appendix D.2.\n\n*   DLG [57] uses mean squared error as the gradient matching loss, i.e., $GML(g_{w_t}(x, y), g_{w_t}(x', y')) = ||g_{w_t}(x, y) - g_{w_t}(x', y') ||_2^2$ and uses no regularizer.\n*   iDLG [55] estimates the label $y$ before solving Equation (3). Assuming the estimated\n    label is $\\hat y$, iDLG solves $x = \\underset{x'}{\\text{arg min}}_x E_x[GML(g_{w_t}(x, y), g_{w_t}(x', \\hat y)) + \\lambda Reg(x')]$, where it\n    uses the same $GML(\\cdot)$ as DLG and also has no regularizer.\n*   InvGrad [13] improves upon DLG and iDLG. It first estimates the private label as\n    $\\hat y$ in advance. Then it uses a negative cosine similarity as $GML(\\cdot)$ and a total vari-\n    ation regularizer $Reg_{TV}(\\cdot)$ as an image prior. Specifically, InvGrad solves for $x =$\n    $\\underset{x'}{\\text{arg min}}_x E_x \\Big[1 - \\frac{(g_{w_t}(x,y),g_{w_t}(x',\\hat y))}{\\|g_{w_t}(x,y)\\|_2\\|g_{w_t}(x',\\hat y)\\|_2} + Reg_{TV}(x') \\Big]$.\n\nAlgorithm 1 shows the pseudo-code of iterative solvers for DRAs and Algorithm 4 in Ap- pendix shows more details for each attack. As the label $y$ can be often accurately inferred, we now only consider reconstructing the data $x$ for notation simplicity. Then, the attack performance is measured by the similarity $sim(x, \\hat x)$ between $y$ and $x$. The larger similarity, the better attack performance. In the paper, we use the common similarity metric, i.e., the negative mean-square-error $sim(x, \\hat x) = -E||x - \\hat x||^2$, where the expectation $E$ considers the randomness during reconstruction."}, {"title": "4 A Theoretical Framework to Understand DRAS to FL", "content": "Though many DRAs to FL have been proposed, it is still unknown how to theoretically compare the effectiveness of existing attacks, as stated in Introduction. In this section, we understand DRAs to FL from a theoretical perspective. We first derive a reconstruction error bound for convex objective losses. The error bound involves knowing the Lipschitz constant of the data reconstruction function. Directly calculating the exact Lipschitz constant is computationally challenging. We then adapt existing methods to calculate its upper bound. We argue that"}, {"title": "4.1 Bounding the Data Reconstruction Error", "content": "Give random data $x$ from a device, our goal is to bound the common norm-based reconstruction error$^2$, i.e., $E||x - R(w_t)||^2$ at any round $t$, where $R(\\cdot)$ can be any DRA and the expectation considers the randomness in $R(\\cdot)$, e.g., due to different initializations. Directly bounding this error is challenging because the global model dynamically aggregates local device models, which are trained by a (stochastic) learning algorithm and whose learning procedure is hard to characterize during training. To alleviate this issue, we introduce the optimal global model $w^*$ that can be learnt by the FL algorithm. Then, we can bound the error as follows:\n\n$E||x - R(w_t)||^2 = E||x - R(w^*) + R(w^*) - R(w_t) ||^2$\n$\\le 2(E||x - R(w^*)||^2 + E||R(w^*) - R(w_t) ||^2)$.                                               (4)\n\nNote that the first term in Equation (4) is a constant and can be directly computed under a given reconstruction function $R(\\cdot)$ and a convex loss used in FL. Specifically, if the loss in each device is convex, the global model can converge to the optimal $w^*$ based on theoretical results in [28]. Then we can obtain $R(w^*)$ per attack and compute the first term. In our experiments, we run the FL algorithm until the loss difference between two consecutive iterations is less than 1e-5, and treat the final global model as $w^*$.\nNow our goal reduces to bounding the second term. However, it is still challenging without knowing any property of the reconstruction function $R(\\cdot)$. In practice, we note $R(\\cdot)$ is often Lipschitz continuous, which can be verified later.\n\nProposition 1. R(\u00b7) is $L_R$-Lipschitz continuous: there exists a constant $L_R$ such that $||R(v) - R(w)|| \\le L_R||v - w||, \\forall v, w$. The smallest $L_R$ is called the Lipschitz constant."}, {"title": "4.2 Computing the Lipschitz Constant for Data Reconstruction Functions", "content": "We show how to calculate the Lipschitz constant for data reconstruction function. Our idea is built upon the strong connection between optimizing DRAs and the corresponding unrolled deep networks; and then adapt existing methods to approximate the Lipschitz upper bound.\nIterative solvers for optimization-based DRAs as unrolled deep feed-forward net- works: Recent works [7, 29, 34] show a strong connection between iterative algorithms and deep network architectures. The general idea of algorithm unrolling is: starting with an ab- stract iterative algorithm, we map one iteration into a single network layer, and stack a finite number of (e.g., $H$) layers to form a deep network, which is also called unrolled deep network. Feeding the data through an H-layer network is hence equivalent to executing the iterative algorithm $H$ iterations. The parameters of the unrolled networks are learnt from data by training the network in an end-to-end fashion. From Algorithm 1, we can see the trajectory of"}, {"title": "5 Evaluation", "content": ""}, {"title": "5.1 Experimental Setup", "content": "Datasets and models: We conduct experiments on three benchmark image datasets, i.e., MNIST [25], Fashion-MNIST (FMNIST) [50], and CIFAR10 [24]. We examine our theoretical results on the FL algorithm that uses the $l_2$-regularized logistic regression (l2-LogReg) and the convex 2-layer linear convolutional network (2-LinConvNet) [37], since their loss functions satisfy Assumptions 1-4. In the experiments, we evenly distribute the training data among the N devices. Based on this setting, we can calculate L, \u03bc, \u03c3k, and G used in our theorems, respec- tively. In addition, we can compute the Lipschitz constant LR via the unrolled feed-forward network. These values together are used to compute the upper bound of our Theorems 1 and 2.\nAttack baselines: We test our theoretical results on four optimization-based data recon- struction attacks, i.e., DLG [57], iDLG [55], InvGrad [13], and GGL [30]. The algorithms and descriptions of these attacks are deferred to Appendix D. We test these attacks on recovering both the single image and a batch of images in each device.\nParameter setting: Several important hyperparameters in the FL training (i.e., federated l2- LogReg or federated 2-LinConvNet) that would affect our theoretical results: the total number of devices N, the total number of global rounds T, and the number of local SGD updates E. By default, we set T = 100 and E = 2. We set N = 10 on the three datasets for the single image recovery, while set N = 15,10,5 on the three datasets for the batch images recovery, considering their different difficulty levels. we consider full device participation. When studying the impact of these hyperparameters, we fix others as the default value."}, {"title": "5.2 Experimental Results", "content": "In this section, we test the upper bound reconstruction error by our theoretical results for single image and batch images recovery. We also show the average (across 10 iterations) reconstruc- tion errors that are empirically obtained by the baseline DRAs with different initializations.\n5.2.1 Results on single image recovery\nFigure 3-Figure 8 show the single image recovery results on the three datasets and two FL algorithms, respectively. We have several observations. First, iDLG has smaller upper bound errors than DLG, indicating iDLG outperforms DLG intrinsically. One possible reason is that iDLG can accurately estimate the labels, which ensures data reconstruction to be more stable."}, {"title": "5.2.2 Results on batch images recovery", "content": "Figures 9-11 show the results of batch images recovery on the three image datasets. As feder- ated 2-LinConvNet has similar trends, we only show federated l2-LogReg results for simplicity. First, similar to results on single image recovery, GGL performs the best; InvGrad outperforms iDLG, which outperforms DLG both empirically and theoretically. Moreover, a larger E and N incur larger upper bound error, while a larger T generates smaller upper bound error. Second, both empirical errors and upper bound errors for batch images recovery are much larger than those for single image recovery. This indicates that batch images recovery are more difficult than single image recovery, as validated in many existing works such as [13, 53]."}, {"title": "6 Discussion", "content": "First term vs second term in the error bound: We calculate the first term and second term of the error bound in our theorem in the default setting. The two terms in DLG, iDLG, InvGrad, and GGL on MNIST are (30.48, 396.72), (25.25, 341.10), (22.06, 218.28), and (20.21, 29.13) respectively. This implies the second term dominates the error bound.\nError bounds vs. degree of non-IID: The non-IID of data across clients can be controlled by the number of classes per client-small number indicates a larger degree of non-IID. Here, we tested #classes=2, 4, 6, 8 on MNIST and the results are shown in Figure 12a. We can see the bounded errors are relatively stable vs. #classes on DLG, iDLG, and GGL, while InvGrad has a larger error as the #classes increases. The possible reason is that DLG and iDLG are more stable than InvGrad, which involves a more complex optimization.\nError bounds vs. batch size: Our batch results use a batch size 20. Here, we also test batch size=10, 15, 25, 30 and results are in Figure 12b. We see bounded errors become larger with larger batch size. This is consistent with existing observations [13] on empirical evaluations.\nError bounds on closed-form DRAs: Our theoretical results can be also applied in closed- form attacks. Here, we choose the Robbing attack [11] for evaluation and its details are in Appendix D.2. The results for single image and batch images recovery on the three datasets and two FL algorithms are shown in Figures 13, 14, and 15, respectively. We can see Robbing obtains both small empirical errors and bounded errors (which are even smaller than GGL). This is because its equation solving is suitable to linear layers, and hence relatively accurate on the federated l2-LogReg and federated 2-LinConvNet models."}, {"title": "Defending against DRAs", "content": "Various defenses have been proposed against DRAs [46, 57, 43, 12, 26, 17, 19]. However, there are two fundamental limitations in existing defenses: First, empirical defenses are soon broken by stronger/adaptive attacks [8, 40, 4]. Second, provable defenses based on differential privacy (DP) [10, 1, 52, 17, 19]) incur significant utility losses to achieve reasonable defense performance since the design of such randomization-based de- fenses did not consider specific inference attacks. Vert recently, [35] proposed an information- theoretical framework to learn privacy-preserving representations against DRAs, and showed better utility than DP-SGD [1, 17] under close privacy performance. It is interesting future work to incorporate information-theoretical privacy into FL to prevent data reconstruction."}, {"title": "7 Conclusion", "content": "Federated learning (FL) is vulnerable to data reconstruction attacks (DRAs). Existing attacks mainly enhance the empirical attack performance, but lack a theoretical understanding. We study DRAs to FL from a theoretical perspective. Our theoretical results provide a unified way to compare existing attacks theoretically. We also validate our theoretical results via evaluations on multiple datasets and baseline attacks. Future works include: 1) designing better or adapting existing Lipschitz estimation algorithms to obtain tighter error bounds; 2) generalizing our theoretical results to non-convex losses; 3) designing theoretically better DRAs (i.e., with smaller Lipschitz) as well as effective defenses against the attacks (i.e., ensuring larger Lipschitz of their reconstruction function), inspired by our framework; and 4) developing effective provable defenses against DRAs."}, {"title": "A Assumptions", "content": "Assumptions on the devices' loss function: To ensure FedAvg guarantees to converge to the global optimal, existing works have the following assumptions on the local devices' loss functions {Lk}.\n\nAssumption 1. {Lk}'s are L-smooth: $L_k(v) \\le L_k(w)+(v-w)^T \\nabla L_k(w)+\\frac{L}{2}||v-w||^2, \\forall v, w$.\n\nAssumption 2. {Lk}'s are \u03bc-strongly convex: $L_k(v) \\ge L_k(w) + (v - w)^T \\nabla L_k(w) + \\frac{\\mu}{2} ||v - w||^2, \\forall v, w$.\n\nAssumption 3. Let $\\xi_t^k$ be sampled from k-th device's data uniformly at random. The variance of stochastic gradients in each device is bounded: $E||\\nabla L_k(w; \\xi_t^k) - \\nabla L_k (w)||^2 \\le \\sigma_k^2, \\forall k$.\n\nAssumption 4. The expected squared norm of stochastic gradients is uniformly bounded, i.e., $E ||\\nabla L_k(\\xi_t^k, w)||^2 \\le G^2, \\forall k,t$.\nNote that Assumptions 1 and 2 are generic. Typical examples include regularized linear regression, logistic regression, softmax classifier, and recent convex 2-layer ReLU networks [37]. For instance, the original FL [31] uses a 2-layer ReLU networks. Assumptions 3 and 4 are used by the existing works [41, 42, 54, 28] to derive the convergence condition of FedAvg to reach the global optimal. Note that the loss of deep neural networks is often non-convex, i.e., do not satisfy Assumption 2. We acknowledge it is important future work to generalize our theoretical results to more challenging non-convex losses."}, {"title": "B Proof of Theorem 1 for Full Device Participation", "content": "Our proof is mainly inspired by the proofs in [41", "28": ".", "n\nNotations": "Let N be the total number of user devices and $K(\\le N)$ be the maximal number of devices that participate in every communication round. Let T be the total number of every device's SGDs"}, {"28": "we define two virtual sequences $v_t = \\sum_{k=1"}, 1, 1, 41, 28], "sketch": "Lemma 2 is mainly from Lemma 1 in [28]. The proof idea is to bound three terms, i.e., the inner product $(w_t - w^*, \\nabla L(w_t))$, the square norm $||\\nabla L(w_t)||^2$, and the inner product $(\\nabla L_k(w_t), w - w_k^t), \\forall k$. Then, the left-hand term in Lemma 2 can be rewritten in terms of the three terms and be bounded by the right-hand four terms in Lemma 2. Specifically, 1) It first bounds $(w_t - w^*, \\nabla L(w_t)))$ using the strong convexity of the loss function (Assumption 2); 2) It bounds $||\\nabla L(w_t)||^2$ using the smoothness of the loss function (Assumption 1); and 3) It bounds $(\\nabla L_k(w_t), w - w_k^t), \\forall k$ using the convexity of the loss function (Assumption 2).\nLemma 3 (Bounding the variance). Assume Assump. 3 holds. Then $E||\\hat g_t - g_t||^2 \\le \\sum_{k=1}^N \\rho_k^2 \\sigma_k^2$\nLemma 4 (Bounding the divergence of $\\{w_t^k\\}$). Assume Assump. 4 holds, and $\\eta_t$ is non-increasing and $\\eta_t \\le 2\\eta_{t+E}$ for all $t$. It follows that $E [\\sum_{t=1}^E \\sum_{k=1}^N \\rho_k || w_k^t - w_t ||^2] \\le 4\\eta_1^2 (E - 1)^2 G^2$.\nNow, we complete the proof of Theorem 1.\nProof. First, we observe that no matter whether $t + 1 \\in Z_E$ Or $t + 1 \\notin Z_E$ in Equation (8), we have $w_{t+1} = v_{t+1}$. Denote $\\Delta_t = E ||w_t - w^*||^2$. From Lemmas 2 to 4, we have\n\n$\\Delta_{t+1} = E ||w_{t+1} - w^*||^2 = E ||v_{t+1} - w^*||^2 \\le (1 - \\eta_t \\mu) \\Delta_t + \\eta_t^2 \\hat B$            (9)\n\nwhere $\\hat B = \\sum_{k=1}^N \\rho_k^2 \\sigma_k^2 + 6L \\Gamma + 8(\\mathbb E - 1)^2 G^2$.\nFor a diminishing stepsize, $\\eta_t = \\frac{\\beta}{t+\\gamma}$ for some $\\beta > \\frac{1}{\\mu}$ and $\\gamma > 0$ such that $\\eta_1 \\le \\min\\{\\frac{1}{\\mu}, \\frac{\\beta}{\\gamma}\\}$ and $\\eta_t \\le 2\\eta_{t+E}$. We will prove $\\Delta_t \\le \\frac{v}{t+\\gamma}$ where $v = \\max\\{ \\frac{\\hat B}{\\mu (\\frac{\\beta \\mu}{\\mu - 1}) - 1}, (\\gamma + 1) \\Delta_1 \\}$.\nWe prove it by induction. Firstly, the definition of $v$ ensures that it holds for $t = 1$. Assume the conclusion holds for some $t$, it follows that\n\n$\\Delta_{t+1} \\le (1 - \\eta_t \\mu) \\Delta_t + \\eta_t^2 \\hat B$\n$\\le \\Big[1 - \\frac{\\beta \\mu}{t+\\gamma}\\Big] \\frac{v}{t+\\gamma} + \\frac{\\hat B \\beta^2}{(t + \\gamma)^2}$\n$\\le \\frac{v}{t+\\gamma + 1} + \\Big[\\frac{\\beta \\mu - 1}{(t + \\gamma)^2}v + \\frac{\\hat B \\beta^2}{(t + \\gamma)^2}\\Big]$\n$\\le \\frac{v}{t+\\gamma + 1}.$\nBy the L-Lipschitz continuous property of Rec(\u00b7),\n\n$||Rec(w_t) - Rec(w^*)|| \\le \\mathcal{L} \\cdot ||w_t - w^*|| .$\nThen we have\n\n$E||Rec(w_t) - Rec(w^*) ||^2 \\le \\mathcal{L}^2 \\cdot E ||w_t - w^*||^2 \\le \\mathcal{L}^2\\Delta_t \\le \\frac{\\mathcal{L}^2 v}{t+\\gamma} .$\nSpecifically, if we choose $\\beta = \\frac{1}{\\mu}$, $\\gamma = \\max\\{\\frac{\\hat B}{\\mu^2(1 - \\frac{1}{\\beta \\mu}) - 1},  E\\} - 1$, then $\\eta_t = \\frac{1}{\\mu(t+E) - 1}$. We also verify that the choice of $\\eta_t$ satisfies $\\eta_t \\le 2\\eta_{t+E}$ for $t > 1$. Then, we have\n\n$v = \\max \\{\\frac{\\hat B}{\\mu^2 (\\beta \\mu - 1) - 1}, (\\gamma + 1) \\Delta_1\\} \\le \\frac{\\hat B}{\\mu^2 - 1} + (\\gamma + 1) \\Delta_1 = \\frac{\\hat B}{\\mu^2 - 1} + \\Big(  E+1 - \\frac{\\hat B}{\\mu^2 (1 - \\frac{1}{\\beta \\mu}) - 1}\\Big) \\Delta_1.$\nHence,\n\n$E||Rec(w_t) - Rec(w^*) ||^2 \\le \\frac{\\"}