{"title": "Long-Term Interest Clock: Fine-Grained Time Perception in Streaming Recommendation System", "authors": ["Yongchun Zhu", "Guanyu Jiang", "Jingwu Chen", "Feng Zhang", "Xiao Yang", "Zuotao Liu"], "abstract": "User interests manifest a dynamic pattern within the course of a day, e.g., a user usually favors soft music at 8 a.m. but may turn to ambient music at 10 p.m. To model dynamic interests in a day, hour embedding is widely used in traditional daily-trained industrial recommendation systems. However, its discreteness can cause periodical online patterns and instability in recent streaming recommendation systems. Recently, Interest Clock has achieved remarkable performance in streaming recommendation systems. Nevertheless, it models users' dynamic interests in a coarse-grained manner, merely encoding users' discrete interests of 24 hours from short-term behaviors. In this paper, we propose a fine-grained method for perceiving time information for streaming recommendation systems, named Long-term Interest Clock (LIC). The key idea of LIC is adaptively calculating current user interests by taking into consideration the relevance of long-term behaviors around current time (e.g., 8 a.m.) given a candidate item. LIC consists of two modules: (1) Clock-GSU retrieves a sub-sequence by searching through long-term behaviors, using query information from a candidate item and current time, (2) Clock-ESU employs a time-gap-aware attention mechanism to aggregate sub-sequence with the candidate item. With Clock-GSU and Clock-ESU, LIC is capable of capturing users' dynamic fine-grained interests from long-term behaviors. We conduct online A/B tests, obtaining +0.122% improvements on user active days. Besides, the extended offline experiments show improvements as well. Long-term Interest Clock has been integrated into Douyin Music App's recommendation system.", "sections": [{"title": "1 INTRODUCTION", "content": "Time exerts a remarkable and considerable influence on users' interests during the course of a single day. In the early morning hours, users are prone to being inclined towards content that fosters a sense of calm. Specifically, they may exhibit a preference for listening to soft, soothing music. Towards the late hours of the night, when the body and mind are nearing a state of rest, users are likely to have a predilection for more tranquil and meditative content, such as ambient music. Thus, it is crucial for recommendation systems [9-11], which aims to provide satisfying contents to users according to their current interests, to capture users' dynamic interests in a day.\nAs a typical common solution to enable models to perceive time information, the hour embedding method [3, 5], which transforms the hour within a day into hour embeddings, has been widely adopted by the early industrial recommendation systems. These systems typically adopt a daily-trained framework, gathering all samples from a single day and then randomly shuffling them for the training process. In recent years, a growing number of companies have deployed real-time streaming recommendation systems, which presents a new challenge to time perception. Within the streaming framework, at any given moment, all training samples possess identical time characteristics. Additionally, recommendation systems possess the capability to produce tens of millions of samples on an hourly basis. This phenomenon consequently causes the recommendation model to merely adapt to the current time features and discard the information acquired during other time periods. This discreteness of the hour embedding methods can lead to the emergence of periodic online patterns and bring about instability [10], which shows unsatisfying performance in real-time streaming recommendation systems."}, {"title": "2 RELATED WORK", "content": "In this section, we will introduce the related work on Time Perception and Long-term Sequence Modeling.\nTime Perception. Hour embedding [3, 5] is a widely adopted method in the industry, which encodes the hour of a day into hour embeddings. However, the hour embedding methods convert time into discrete embeddings, which is ineffective in modern real-time streaming recommendation systems. For takeaway recommendation, [9] divided a day into four periods, including morning, noon, night, and last night, and used different graph models for different periods, which is difficult to deploy in other scenarios. For streaming recommendation systems, Interest Clock [10] encodes personalized user interests of 24 hours into a clock, but it only models short-term discrete interests in a coarse-grained manner.\nLong-term Sequence Modeling. Most existing methods [1, 2, 4, 6, 7] adopt a two-stage search framework, which is composed of a General Search Unit and an Exact Search Unit. They mainly consider the similarity between the long sequence and the candidate item. Some of them [1, 2, 6] also take into account the context similarity. However, these methods use hour embedding to represent time information, which is ineffective in streaming recommendation systems. To the best of our knowledge, we are the first to tackle the time perception problem from the perspective of long-term interests in real-time streaming recommendation systems."}, {"title": "3 LONG-TERM INTEREST CLOCK", "content": "In this section, we provide a detailed introduction to the proposed Long-term Interest Clock. In Section 3.1, we briefly explain the problem definition. In Section 3.2, we introduce the details of Clock-GSU. In Section 3.3, we introduce the details of Clock-ESU."}, {"title": "3.1 Problem Statement", "content": "In recommendation systems, each sample contains the input raw features and a label $y \\in \\{0, 1\\}$, and these features are converted into vectors, named feature embeddings, denoted as $\\{v_1,...,v_N\\}$, where $N$ indicates the number of raw features. The prediction of a recommendation model $f(.)$ with the embeddings as inputs is formulated as $\\hat{y} = f([v_1,\\cdots, v_N])$. The cross-entropy loss is often used as the optimization target for binary classification:\n$L = -y \\log \\hat{y} - (1 - y) \\log(1 - \\hat{y}).$ \t\t(1)\nIn this paper, we focus on extracting the representations of the user's current interests $v_{cur}$ according to current time $t_{cur}$, the candidate item and long-term behaviors. The candidate item contains lots of item features, and the concentrated embedding is utilized as a query denoted as $q \\in \\mathbb{R}^H$. Each behavior contains an item and its features, and the behavior embedding is denoted as $b \\in \\mathbb{R}^L$, where $L$ denotes the dimension of $b$. Thus, long-term behaviors is denoted as $\\{b_1,..., b_M\\}$, and $M$ indicates the length of long sequence. The time at which the m-th behavior occurs is defined as $t_{bm}$."}, {"title": "3.2 Clock-Based General Search Unit", "content": "Clock-GSU aims to extract a sub-sequence from long-term behaviors, and the sub-sequence is relevant to the candidate item q and is around the current time $t_{cur}$. Firstly, we define a function $g(.)$ to extract hours, minutes, and seconds, e.g., $g(2024.12.10 \\, 13:30:00) = 13:30:00$. Then, the relative time gap between two behavior $b_n$ and $b_m$ is indicated as $\\Delta(t_{bn}, t_{bm})$, e.g., $\\Delta(23: 00: 00, 1: 00: 00) = 120$(minutes) and $\\Delta(11:00:00, 17:00:00) = 360$(minutes).\nThe relevant score $a \\in \\mathbb{R}$ between the candidate item and a historical behavior is calculated as:\n$a(b_m, q) = \\frac{(W_b x b_m) (W_q x q)^T}{\\sqrt{V_a}} + s(\\Delta(t_{bm}, t_{cur})), \\qquad(2)$\nwhere $W_b \\in \\mathbb{R}^{d\\times L}$ and $W_q \\in \\mathbb{R}^{d\\times H}$ are learnable parameters, and $d$ indicates the dimension of latent vectors. $s()$ is a two-layer neural networks with $[\\Delta, \\sqrt{\\Delta}, \\Delta^2, \\log(\\Delta + 1)]$ as input. With the relevant scores, Clock-GSU can proceed with the top-K search over ten thousand length of user behaviors. The top-K sub-sequence is denoted as $\\{z_1,..., Z_K\\}$, where $K = 100$ in LIC.\nNote that, different from our proposed relative time gap, most existing context-aware methods [1, 2, 4, 6] use absolute time gap as input, which cannot model user's dynamic interests within a day in streaming recommendation systems. To further speed up the top-K search, the results of $W_b \\times b_m$ and $W_q \\times q$ are pre-computed and stored in online parameter servers (PS). This allows for convenient direct access and retrieval of the results, facilitating a rapid computation of the relevant score. The parameters of $s()$ with dimensions [8, 1] are also stored in online PS. The structure of s() is simple, so the time complexity is substantially lower than $(W_b \\times b_m) (W_q \\times q)^T$."}, {"title": "3.3 Clock-Based Exact Search Unit", "content": "With Clock-GSU, the sub-sequence of top-K items $\\{z_1,..., Z_K\\}$, which is relevant to the candidate item around current time, is retrieved from long-term behaviors. Clock-ESU aims to extract the representations of the user's current interests, denoted as $v_{cur}$.\nInspired by multi-head attention in long-term sequential methods [1, 4, 6], we utilize a multi-head time-gap-aware attention mechanism to calculate the relevant score. Let $Z \\in \\mathbb{R}^{K \\times L}$ indicate the matrix of top-K behaviors $\\{z_1, \\cdots, z_k\\}$. To further enhance the time perception capability of Clock-ESU, we concentrate $[\\Delta, \\sqrt{\\Delta}, \\Delta^2, \\log(\\Delta + 1)]$ into representations of top-K behaviors $z_i$. Thus, the representation of one head $r_i \\in \\mathbb{R}^d$ is denoted as:\n$r_i = Softmax(a_i)^T ZW_{vi}, \\qquad(3)$\nwhere $W_{vi} \\in \\mathbb{R}^{L\\times d}$ is the learnable parameter matrix of the i-th head, and $a_i$ indicates the top-K relevant scores of the i-th head, computed with Equation (2). Note that each head has different parameter matrices $W_b$ and $W_q$. In practice, the number of heads is four, and the representation of the user's current interests is formulated as:\n$v_{cur} = h([r_1,\\cdots, r_4]), \\qquad(4)$\nwhere $h()$ is a two layer deep network. The user's current interests $v_{cur}$ are fed into $f(.)$ for final predictions.\nNote that both Clock-GSU and Clock-ESU incorporate the aspect of time similarity. As a result, Clock-GSU is capable of retrieving relevant items in proximity to the current time, while Clock-ESU can adaptively model the relevance of the retrieved top-K behaviors based on both item similarity and time similarity. With Clock-GSU and Clock-ESU, the proposed Long-term Interest Clock can adaptively model users' current interests. In addition, both the two modules utilize the multi-head attention mechanism. In Clock-GSU, $(W_b \\times b_m)$ and $(W_q \\times q)$ of each head are pre-computed and stored in online PS. In practical computation, we directly concatenate the pre-computed embeddings of each head to calculate item similarity."}, {"title": "4 EXPERIMENTS", "content": "In this section, we conduct extensive offline and online experiments to demonstrate the effectiveness of the propose method.\nDatasets. We evaluate the Long-term Interest Clock with baselines on a large-scale industrial recommendation dataset. Note that Long-term Interest Clock requires a substantial amount of data with long-term behaviors (spanning one year) from streaming recommendation systems. However, currently, there is no public dataset that is suitable for this purpose. Thus, we only adopt the industrial dataset DouyinMusic-20B from our system.\nDouyinMusic-20B: Douyin offers a music recommendation service, which has over 10 million daily active users. Zhu et al. [10] collect from the impression logs and get one dataset. The dataset contains more than 20 billion samples, denoted as DouyinMusic-20B. Each sample in the industrial dataset includes over a hundred features. These features consist of non-ID meta features such as gender, age, genre, mood, scene, etc., as well as ID-based personalized features like user ID, item ID, artist ID, and interacted ID sequence, which can effectively represent real-world scenarios. The DouyinMusic-20B dataset contains samples from Douyin Music across the time span of 8 weeks from August to September 2023. Following [10], we use 'Finish' as the label and take the first 6 weeks as the training set, the following 1 week as the validation set, and the remaining 1 week as the test set.\nOnline A/B Testing. To verify the real benefits Long-term Interest Clock brings to our system, we conducted online A/B testing experiments for more than one month for the ranking task in Douyin Music App. We evaluate model performance based on one main metric, Active Days. We also take additional metrics, which evaluate user engagement, including Like, Finish, DisLike, and Play, which are usually used as constraint metrics [10]. We apply the proposed Interest Clock on a DCN-V2-based multi-task model [8] which is deployed in the online ranking tasks. The online A/B results are shown in Table 1. For the main metrics Active Days, the proposed Interest Clock achieves a large improvement of +0.122% for all users with statistical significance, which is remarkable given the fact that the average Active Days improvement from production algorithms is around 0.05%.\nOffline Results. We utilize AUC, UAUC, and the relative improvements (RelaImpr) as offline metrics. We compare the proposed LIC with (1) Base Model is a DCN-V2-based model [8] without any time modeling method, (2) Hour Embedding, (3) Naive Clock, (4) Adaptive Clock, and (5) Gaussian Clock. It should be noted that all the baseline models employ the same base model, and Naive/Adaptive/Gaussian Clock methods are the same as Zhu et al. [10]. The experimental results on the industrial dataset are shown in Table 2. The results further reveal several insightful observations. Hour Embedding method proves ineffective in streaming data. UAUC of Adaptive Clock is inferior to that of the baseline, potentially because the adaptive weights of time information are challenging to learn in streaming recommendation systems. Long-term Interest Clock could outperform the best baseline Gaussian Interest Clock significantly, which demonstrates empirical Gaussian weights are effective."}, {"title": "5 CONCLUSION", "content": "In this paper, with the aim of endowing streaming recommendation systems with the ability to perceive time alterations, we propose an effective method named Long-term Interest Clock (LIC). LIC consists of a Clock-GSU and a Clock-ESU. Clock-GSU retrieves a sub-sequence from long-term behaviors, which is around the current time and relevant to a candidate item. Clock-ESU employs a time-gap-aware attention mechanism to extract a representation of the user's current interests from the sub-sequence. We demonstrated the superior performance of the proposed Long-term Interest Clock in both offline and online experiments, which demonstrates its effectiveness. Moreover, Long-term Interest Clock has been deployed on ranking tasks in multiple applications of Douyin Group."}]}