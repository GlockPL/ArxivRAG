{"title": "Heterogeneous Multi-Agent Bandits with Parsimonious Hints", "authors": ["Amirmahdi Mirfakhar", "Xuchuang Wang", "Jinhang Zuo", "Yair Zick", "Mohammad Hajiesmaili"], "abstract": "We study a hinted heterogeneous multi-agent multi-armed bandits problem (HMA2B), where agents can query low-cost observations (hints) in addition to pulling arms. In this framework, each of the M agents has a unique reward distribution over K arms, and in T rounds, they can observe the reward of the arm they pull only if no other agent pulls that arm. The goal is to maximize the total utility by querying the minimal necessary hints without pulling arms, achieving time-independent regret. We study HMA2B in both centralized and decentralized setups. Our main centralized algorithm, GP-HCLA, which is an extension of HCLA, uses a central decision-maker for arm-pulling and hint queries, achieving O(M\u00b2K) regret with O(MK log T) adaptive hints. In decentralized setups, we propose two algorithms, HD-ETC and EBHD-ETC, that allow agents to choose actions independently through collision-based communication and query hints uniformly until stopping, yielding O(M\u00b3 K\u00b2) regret with O(M\u00b3 K log T) hints, where the former requires knowledge of the minimum gap and the latter does not. Finally, we establish lower bounds to prove the optimality of our results and verify them through numerical simulations.", "sections": [{"title": "1 Introduction", "content": "The multi-agent multi-armed bandit (MA2B) problem (Liu and Zhao 2010; Anandkumar et al. 2011) is a sequential decision making task consisting of K \u2208 N+ arms and M \u2208 N+ agents. In each of the total T \u2208 N+ decision rounds, each agent selects one arm to pull and observes its reward if no other agent pulls the same arm (called no collision). This model has applications in wireless communication (Jouini et al. 2009, 2010), caching (Xu, Tao, and Shen 2020; Xu and Tao 2020), and edge computing (Wu et al. 2021). Among various models in MA2B, the heterogeneous multi-agent multi-armed bandit (Bistritz and Leshem 2018; Shi et al. 2021) is a more realistic variant for these applications where agents have different reward distributions over the arms, e.g., in a wireless communication scenario where agents have different channel qualities due to different geographical locations. In this heterogeneous MA2B model, the optimal action of all agents is a bipartite matching (between agents and arms) that maximizes the total reward, called the optimal matching. An algorithm's performance is evaluated by regret, the difference between the accumulative reward of keeping to choose the optimal matching in all decision rounds and the total reward of the bandit algorithm. A smaller expected regret implies a better algorithm.\nRecently, learning-augmented approaches are emerging, e.g., Lykouris and Vassilvitskii (2021); Bamas, Maggiori, and Svensson (2020); Bhaskara et al. (2023). This stream of research studies how to assist an algorithm with hints (a.k.a., predictions) queried from existing ML models, e.g., large language model (Achiam et al. 2023), deep convolutional neural network (Krizhevsky, Sutskever, and Hinton 2017), and deep reinforcement learning (Fran\u00e7ois-Lavet et al. 2018).\nIn this paper, we study the utilization of hint information in heterogeneous multi-agent multi-armed bandits. In addition to receiving feedback from pulling arms, agents can sequentially query hints about the potential rewards of other arms, assisting in their decision-making process. We call the model Hinted Heterogeneous Multi-Agent Multi-Armed Bandits (HMA2B). Specifically, we consider a simple and accurate hint mechanism where agents can query the reward of an arm without pulling it, with no regret incurred from the queried hint. Despite assuming accurate hints, this model poses challenges, such as balancing hint queries and arm-pullings while accounting for agent heterogeneity and potential future collisions. In addition to minimizing regret, we aim to reduce hint complexity, the total number of queried hints, as querying hints, such as via the GPT-4 API (Achiam et al. 2023), can be costly. Efficiently leveraging hints is crucial in scenarios where hint costs are significantly lower than the costs of taking actions. For instance, in labor markets, structured, low-cost interviews provide hints to improve applicant-role matching, reducing the risk of human resource misallocation. Similarly, in radio channel assignments, test signals serve as hints to allocate high-bandwidth channels effectively, preventing delays and disruptions in critical applications like disaster recovery, where drones depend on reliable communication channels.\nWe study two scenarios of HMA2B: centralized and decentralized setups. In the centralized setup, an omniscient decision-maker determines which arm each agent should pull or query hints from, similar to decision-making in hiring processes where the employer has access to the applicants' information to decide which of them to interview and which"}, {"title": "1.1 Contributions", "content": "For the centralized setup (Section 3), we propose two algorithms: HCLA and GP-HCLA. Both use empirical means to select a matching to pull and kl-UCB indices (Capp\u00e9 et al. 2013) to identify another matching, querying a hint if the latter has a higher value. Additionally, we analyze an intermediate algorithm, G-HCLA (Appendix A), which operates similarly to HCLA but differs from GP-HCLA in how it selects the matching to hint after deciding to query. As summarized in Table 1, both GP-HCLA and G-HCLA-extensions of HCLA-achieve time-independent regret with an asymptotically optimal number of hints. We further prove that the upper bound on the hint complexity for GP-HCLA is tight, with both GP-HCLA and G-HCLA matching the established lower bounds. In the decentralized setup (Section 4), we introduce two algorithms: HD-ETC and EBHD-ETC. Both divide the time horizon into three phases: exploration, communication, and exploitation, with a key difference in how they transition to the exploitation phase. In the exploitation phase, no further communication, exploration, or hint querying occurs, and the two algorithms handle this transition differently. In HD-ETC, agents know the minimum gap-the smallest utility difference between the optimal and other matchings-and the time horizon T, allowing them to switch to exploitation at a fixed time step T0. Conversely, EBHD-ETC does not require this knowledge, using an edge elimination strategy to determine the transition point, which makes it a random variable. This results in slightly higher hint queries and regret compared to HD-ETC. We provide regret bounds for both algorithms that align with the lower bounds, accounting for uncertainties due to delayed communication."}, {"title": "1.2 Related Works", "content": "Heterogeneous MMAB (HMMAB) HMMAB is one of the standard models in multi-player multi-armed bandits with collision literature; to name a few, Rosenski, Shamir, and Szlak (2016); Boursier and Perchet (2019); Mehrabian et al. (2020); Bistritz and Leshem (2018); Shi et al. (2021). Among them, Bistritz and Leshem (2018) was the first to study the HMMAB, where they proposed a decentralized algorithm with O(log\u00b2 T) regret. Later on, the regret bound of this model was improved to O(M\u00b3 K logT) by Mehrabian et al. (2020) and further to O(M\u00b2K logT) by Shi et al. (2021) that is the state-of-the-art result. We are the first to introduce the hint mechanism to \u0397\u039c\u039c\u0391\u0392.\nBandits with Hints Learning algorithms with hints (or predictions) are part of the emerging literature on learning-augmented methods, as seen in works like (Lykouris and Vassilvitskii 2021; Purohit, Svitkina, and Kumar 2018; Mitzenmacher and Vassilvitskii 2022), etc. The hint mechanism was initially explored in the basic stochastic multi-armed bandits model by Yun et al. (2018). Later, Lindst\u00e5hl, Proutiere, and Johnsson (2020) examined a more realistic hint mechanism, which includes failure noise, for the same model. Additionally, Bhaskara et al. (2023) investigated the impact of hints in adversarial bandits. We are the first to study the hint mechanism in a multi-agent scenario."}, {"title": "2 Hinted Heterogeneous Multi-Agent Multi-Armed Bandits", "content": "Basic model A Hinted Heterogeneous Multi-agent Multi-Armed Bandit (HMA2B) model consists of a set of K arms"}, {"title": "3 Algorithms for Centralized Hinted Heterogeneous Multi-Armed Bandits", "content": "In the Centralized Hinted Heterogeneous Multi-Armed Bandit (C_HMA2B) setup, we consider an omniscient decision maker who selects both the matching and the hint graph at each round. The agents then follow the decision maker's instructions to pull arms and query hints. We propose two learning policies for this setup: the Hinted Centralized Learning Algorithm (HCLA) and the Generalized Projection-based Hinted Centralized Learning Algorithm (GP-HCLA).\nUnder both policies, the decision maker treats each matching G\u2208 Gas a super arm for hint inquiries. However, the handling of observations differs between the two: in HCLA, observations are maintained for each matching, while in GP-HCLA, they are treated at the edge level. This distinction allows us to reduce the potentially exponential regret relative to the size of G to a polynomial regret upper bound in the number of edges, MK.\nWe first introduce the statistics maintained by agents in HCLA and GP-HCLA, aiding the central decision maker in deciding when and how to query hints. Next, we describe HCLA as a baseline for designing GP-HCLA, our main algorithm. We also present an intermediate algorithm, G-HCLA,"}, {"title": "3.1 Preliminaries", "content": "Beyond the generic empirical means matrix $\\hat{\\mu}$, the decision maker employs kl-UCB indices d (Capp\u00e9 et al. 2013) as upper confidence bounds for $\\mu$ in the C_HMA2B setup to determine when to query a hint. These indices are defined as:\n$\\mu_{G}(t) := \\frac{\\sum_{t'=1}^{t}1\\{G(t') = G\\}U(G(t');r(t'))}{N_{G}(t)}$ (2)\n$\\mu_{m,k}(t) := \\frac{\\sum_{t'=1}^{t}1\\{(m, k) \\in G(t')\\}r_{m}(t')}{N_{m,k}(t)}$ (3)\n$d_{G}(t) := \\sup \\{q \\geq 0 : N_{G}(t) kl (\\mu_{G}(t), q) \\leq f(t)\\}$ (4)\n$d_{m,k}(t) := \\sup \\{q \\geq 0 : N_{m,k}(t) kl (\\mu_{m,k}(t), q) \\leq f(t)\\}$ (5)\nfor any matching G\u2208 G and edge (m,k) \u2208 M \u00d7 K, respectively, where kl is the Kullback-Leibler divergence, and f(t) = log t + 4 log log t. Here, NG(t) and Nm,k(t) represent the number of times matching G or edge (m, k) has been pulled or hinted.\nBefore detailing the algorithm, we define a fixed set R := {R1,..., RK} of K pairwise edge-disjoint matchings that cover all edges (m,k) \u2208 M \u00d7 K, referred to as covering matchings. For uniquely labeled agents and arms in [M] and [K], R\u2081 \u2208 R is the matching where agent m is paired with arm (m + i \u2212 1) mod K. By pulling or hinting each covering matching in R at least once, agents can observe all G \u2208 G at least once. This set serves as a hint pool, from which all hint graphs Ghint will be selected."}, {"title": "3.2 Warm-up: The HCLA Algorithm", "content": "As noted earlier, the HCLA algorithm treats each G\u2208 G as a super arm and maintains separate statistics: empirical mean $\\hat{\\mu}_{G}(t)$, kl-UCB index dG(t), and counters NHCLA (t). At each time step t, the central decision maker selects a matching G(t) with the maximum empirical mean $\\hat{\\mu}_{G}(t)$ and another matching G'(t) with the maximum dG(t) (Lines 3\u20134). If $d_{G'}(t) (t) > \\mu_{G(t)} (t)$, the decision maker chooses Ghint(t) as either G'(t) or a uniformly at random chosen matching Ghint(t), each with probability 1/2. It then queries a hint from Ghint(t) and updates suchint(t) (t + 1) based on the hint observation (Lines 5\u201310). Finally, the decision maker pulls G(t), updates suchg(t) (t + 1) with the reward observation, and recalculates dg(t + 1) for all G\u2208 G (Lines 11-10). The detailed pseudocode of the HCLA algorithm is provided in Algorithm 1.\nNext, we present the upper bounds for the time-independent regret and the number of queried hints LHCLA (T) for the HCLA algorithm in Theorem 1. The detailed proof is presented in Appendix B.1.\nTheorem 1. For 0 < \u03b4 < $\\frac{\\Delta_{match}}{2}$ and policy \u03c0 = HCLA, the policy \u03c0 has\n1. time-independent regret $R^{\\pi} (T) \\in O (MK^{2^{M}})$,,\n2. hint complexity $L^{\\pi} (T) \\in O \\Big(\\frac{MK^{M} log T}{\\Delta_{kl}}\\Big)$\nwhere $\\Delta_{kl} = kl(U (G^{*}; \\mu) - \\frac{\\Delta_{match}}{min} + \\delta, U(G^{*}; \\mu) - \\delta)$.\nThe regret of HCLA is time-independent, but the exponential constants in its regret and hint upper bounds are unsatisfactory. To address this, we propose a new algorithm called GP-HCLA, which provides a more refined analysis while maintaining the same hint inquiry and arm-pulling approach but using observations differently."}, {"title": "3.3 The GP-HCLA Algorithm", "content": "We present GP-HCLA in Algorithm 2. The GP-HCLA algorithm follows steps similar to HCLA to identify G(t) and G'(t). However, unlike HCLA, the central decision maker maintains statistics $\\mu_{m,k}(t)$ and dm,k(t) for each edge (m,k) \u2208 M \u00d7 K. It then defines $d_{G}(t) := \\sum_{(m,k)\\in G} d_{m,k}(t)$, with a slight abuse of notation, enabling the use of the Hungarian algorithm (Kuhn 1955), which finds the matching with maximum additive utility in a"}, {"title": "4 Algorithms for Decentralized Hinted Heterogeneous Multi-Armed Bandits", "content": "We study the Decentralized Hinted Heterogeneous Multi-Armed Bandits (D_HMA2Bs), where no central decision maker coordinates agents to avoid collisions while learning the optimal matching G*. Theorem 3 demonstrates that sub-linear regret is unattainable in a decentralized setup without agents sharing statistics, making communication essential in D_HMA2Bs. To enable communication, agents intentionally collide to exchange statistics like $\\mu$s, while non-colliding agents continue pulling their assigned arms km from the matching G\u2208 G without interference (Shi et al. 2021; Wang et al. 2020). Communication order is determined by unique agent ranks, as discussed below.\nTheorem 3 (Necessity of Communication). No decentralized learning algorithm can achieve sub-linear instance-independent regret in HMA2Bs without communication.\nBuilding on Theorem 3, we propose a cooperative learning framework for the Hinted Decentralized Explore-then-Commit (HD-ETC) and Elimination-Based Hinted Decentralized Explore-then-Commit (EBHD-ETC) algorithms. These divide time into Initialization, Exploration, and Communication phases, where agents request hints in a round-robin manner until meeting a stopping condition, after which they transition to the Exploitation phase with no further hints or communication."}, {"title": "4.1 Decentralized Learning Framework", "content": "We first outline the common framework for the HD-ETC and EBHD-ETC algorithms. Both divide the T decision-making rounds into alternating exploration and communication phases. A counter p tracks exploration epochs, and Nm.k records the number of times agent m has pulled or hinted at arm k by the start of epoch p. The decentralized learning framework for HMA2B consists of four phases:\nInitialization phase: Assigning unique ranks among the agents. The detailed rank assignment procedure and analysis follows Wang et al. (2020) (detailed in Appendix D).\nExploration phase: Agents use the gathered statistics to identify the best matching G\u00ba at the start of each epoch p using Hungarian algorithm. They then commit to their corresponding arm ka for K rounds until the epoch ends. At the end of epoch p, agents signal the communication phase by creating collisions on arms pulled by other agents.\nCommunication phase: Before each exploration epoch p, agents transmit their statistics $\\mu$ to others, denoted as $\\mu^{p}$. This communication is realized via the intentional collision signals, where a collision represents a '1' and its absence a '0' information bits (Boursier and Perchet 2019), with agents"}, {"title": "4.2 Warm-Up: The HD-ETC algorithm", "content": "The HD-ETC algorithm builds on the learning framework in Section 4.1, extending the Explore-then-Commit (ETC) method in bandits literature. To follow this method, agents uniformly query hints for covering matchings R\u2208 R, Lines 9\u201311, until time step $T^{HD-ETC}$, determined by the assumed knowledge of $\\Delta_{match}^{min}$\nAt $T^{HD-ETC}$ where p is the index of the last exploration epoch, agents run $\\text{Hungarian} (\\bar{\\mu}^{p})$ to identify the matching G'*, which they commit to for all t > $T^{HD-ETC}$, i.e., G(t) = G'* (Lines 18\u201320). Theorem 4 establishes that with a properly chosen $T^{HD-ETC}$, which depends on $\\Delta_{match}^{min}$, the algorithm achieves time-independent exploration regret while ensuring asymptotically optimal hint and communication usage. Detailed proofs are provided in Appendix F.1."}, {"title": "4.3 The EBHD-ETC algorithm", "content": "In EBHD-ETC, agents transition into the exploitation phase differently compared toHD-ETC. Accordingly, each agent maintains a set of active edges C\u00ba, which includes edges likely to be in G\u00ba for the upcoming epoch p, initially"}, {"title": "5 Experiments", "content": "We executed the algorithms HCLA, GP-HCLA, G-HCLA, HD-ETC, and EBHD-ETC with M = 4, K = 4, and $\\Delta_{match}^{min}$ < 0.18, averaging regret and hint complexity over 50 replications for 105 rounds. We also benchmarked the Beacon algorithm (Shi et al. 2021) and compared its regret $R_{Beacon}^{exp} (T)$ with ours. Figs. 2b and 2c demonstrate that our centralized algorithms achieve better hint-query efficiency than HD-ETC and"}, {"title": "6 Conclusion", "content": "In this paper, we studied how hints enhance learning in the HMA2B problem, with heterogeneous rewards and collisions. We proposed both centralized and decentralized algorithms, analyzing their regret and hint usage. An interesting future work is extending these methods to two-sided matching markets, where both sides have preferences, and ties are broken due to them while collision occurs. This could enable the design of decentralized algorithms without communication to learn matchings with the same regret and hint optimality."}, {"title": "A The G-HCLA Algorithm", "content": "Here we analyse hint complexity of algorithm G-HCLA that is a variation of HCLA. In this algorithm a matching G'(t) satisfying U(G'(t); d(t)) > U(G(t); \u03bc(t)) would be served as Ghint(t) with probability 1/2."}, {"title": "B Analysis of HCLA,GP-HCLA, and G-HCLA", "content": "Our proofs use an event-based analysis inspired by Wang et al. (2020), which was originally developed for homogeneous multi-armed bandits. We have adapted this method for the heterogeneous setting, addressing its unique challenges. We will now explain the Event-Based Regret Analysis and how it applies to regret and hint complexity analysis of HCLA, GP-HCLA, and G-HCLA. The regret analysis for the decentralized algorithms HD-ETC and EBHD-ETC follows the same approach, but their detailed analysis is deferred to Appendix F.3. This method mainly focuses on bounding the number of times specific events that affect regret occur, as defined below.\nDefinition 1. We define the following sets of time steps at which specific events occur as:\nA := {t > 1 : G(t) \u2260 G*}\nB := {t > 1 : |U (G(t); \u00ee\u00fb(t)) \u2013 U (G(t); \u03bc)| \u2265 \u03b4}\nC := {t > 1 : U (G*; d(t)) < U (G*; \u03bc)}\nD := {t > 1 : t \u2208 A \\ (BUC), |U (G*; \u00ee\u00fb(t)) \u2013 U (G*; \u03bc)| \u2265 \u03b4}\nE := {t > 1 : U (G'(t), d(t)) > U(G*, \u03bc(t))}\nIntuitively, A contains the time steps at which a sub-optimal matching is pulled, incurring regret. We also need to bound the size of the set B, which includes the time steps where the chosen matching is not well-estimated, potentially leading to the selection of a sub-optimal G(t). The sets C and D help us bound the exploration needed to identify G* through hints when a sub-optimal matching is selected. Finally, & bounds the number of required hints when G* is detected, to explore potential matchings that might not have been chosen as G(t) due to potentially inaccurate estimations.\nWe can observe that for a policy \u03c0\u2208 {HCLA, G-HCLA, GP-HCLA},\n$R^{\\pi} (T) < ME [|A|],$"}, {"title": "B.1 Proof of Theorem 1", "content": "Theorem 1. For 0 < \u03b4 < $\\frac{\\Delta_{match}}{2}$ and policy \u03c0 = HCLA, the policy w has\n1. time-independent regret $R^{\\pi} (T) \\in O (\u041c\u041a^{2^{\u041c}})$,,\n2. hint complexity $L^{\\pi} (T) \\in \u041e \\Big(\\frac{MKM log T}{\\Delta_{kl}}\\Big)$,\nwhere $\\Delta_{kl} = kl(U(G^{*}; \\mu) - \\frac{\\Delta_{match}}{min} + \\delta, U(G^{*}; \\mu) - \\delta)$.\nProof. We bound the size of the sets of time steps defined in Definition 1 as follows:\nBy Lemma 3, we can prove that E [|B|] \u2264 4 + 28-2. Bounding E [|C|] is also a straightforward application of Lemma 2 by replacing (m,k) \u2208 M \u00d7 K with G \u2208 G to have E [|C|] \u2264 15. We can also prove that at every time step t \u2208 D, U(G*; d(t)) > U(G(t); \u03bc(t)), thus decision maker hints at that time under HCLA algorithm. It the hints the G* with probability at least 1/2KM, which implies $E [|D|] < \\frac{KM}{(KM + 8^{-2})}$ by applying Lemma 3. Therefore, we can write\n$R^{HCLA} (T) \\overset{(a)}{\\leq} M (E [|B|] + E [|C|] + E[|D|])$,,\n$\\leq 4M + 2M8^{-2} + 15M + MK^{2^{M}} + MK^{M}8^{-2}$.\nwhere inequality (a) is directly adopted from Wang et al. (2020) in which the authors showed that $A\\cup B \\cup C\\cup D$.\nWe next prove an upper bound on the LHCLA(T) by bounding the number of time steps the condition in Line 5 of the HCLA occurs. For a fixed matching G' \u2208 G, we define EG' as\n$E_{G'} := \\{t \\in E : G'(t) = G', d(t) > \\hat{\\mu}(t)\\} .$\nNow, we can write\n$\\mathbb{E} [L^{HCLA} (T) \\leq M \\sum_{G'\\in G} \\mathbb{E} [|E_{G'}|]$,\n$\\leq \\frac{2MKM (log T + 4 log log T)}{\\Delta_{kl}} + \\frac{MK^{M} (4 + 28^{-2})}{2}$,\nThe inequality (a) is obtained by applying Lemma 3 to the established argument in (Wang et al. 2020), noting that under HCLA, the probability of requesting a hint for Ghint(t) = G' is at least 1/2 at those hint inquiry time steps. For further details, readers can refer to the Proof of Lemma 7, where the same argument is validated using edge-level analysis. We skip the detailed proof here as a warm-up for our main algorithm GP-HCLA.\nFinally, we conclude that $R^{HCLA}(T) \\in O (MK^{2^{M}})$ and $L^{HCLA}(T) \\in \u041e \\Big(\\frac{MKM log T}{\\Delta_{kl}}\\Big)$"}, {"title": "B.2 Proof of Theorem 2", "content": "Theorem 2. For 0 < \u03b4 < $\\frac{\\Delta_{match}}{2}$ and policy \u03c0 = GP-HCLA, the policy \u03c0 has\n1. time-independent regret $R^{\\pi} (T) \\in O (M\u00b2K)$ regret,\n2. hint complexity $L^{\\pi} (T) \\in \u041e \\Big(\\frac{MK log T}{\\Delta_{kl}}\\Big)$\nwhere Akl = kl(U(G*; \u03bc) \u2013 $\\Delta_{match}^{min}$ + 8, U(G*; \u03bc) \u2013 \u03b4).\nProof. Using Lemma 1 we can write:\n$R^{GP-HCLA} (T) \\leq M (E [|B|] + E [|C|] + E [|D|])$,,\n$\\leq 15M\u00b2 + 4M\u00b2K + 16M2k2 + 6M4K8^{-2}$,\nwhere inequality (a) holds by aggregation over the results of Lemmas 4, 5, and 6. Therefore, the total regret of GP-HCLA is included to be in O (M\u00b2K).\nNow that we bounded E [|B|] + E [|C|] + E [|D|], we bound the hints that GP-HCLA queries for after detecting the G*. By directly applying the result of Lemma 7, we can write\n$L^{GP-HCLA} (T) < \u039c \\sum_{G'\\in G} \\mathbb{E} [[E_{G'}]],$ < 4MK\u00b3 + 2M\u00b3 K8^{-2} + $\\frac{2MK log T}{\\Delta_{kl}}$,,\nwhich implies that $L^{GP-HCLA}(T) \\in \\mathrm{O} \\Big(\\frac{MK log T}{\\Delta_{kl}}\\Big)$ that wraps the proof up."}, {"title": "B.3 Detailed Lemmas Required to Analyze G-HCLA and GP-HCLA", "content": "Concentration bounds\nHere we introduce lemmas play very central role in our event-based analysis.\nLemma 2 (Combes et al. (2015), Lemma 6). For any (m, k) \u2208 M \u00d7 K, we have\n$\"\\\"\"\n\\sum_{t\\geq1} Pr [d_{m,k}(t) \\leq \\mu_{m,k}] \\leq 15$.\nLemma 3 (Wang et al. (2020), Lemma 9). Let (m, k) \u2208 M \u00d7 K, and c > 0. Let H be a random set of rounds such that for all t, {t \u2208 H} \u2208 Ft\u22121. Assume that there exists (Cm,k(t))t>0, a sequence of independent binary random variables such that for any t \u2265 1, Cm,k(t) is Ft-measurable and Pr [Cm,k(t) = 1] \u2265 c. In addition, assume that for any t \u2208 H, agent m pulls the arm k if Cm,k(t) = 1. Then,\n$\\sum_{t\\geq1} Pr [\\{t\\in H, |\\mu_{m,k}(t) - \\mu_{m,k}| \\geq \\epsilon\\}] \\leq 2c^{-1} (2c^{-1} + \\epsilon^{-2}) .$\nEvent-Based Analysis Lemmas\nHere, we prove the lemmas necessary to analyze the regret and hint complexity of GP-HCLA using the event-based analysis described above.\nLemma 4. For policy \u03c0 = {G-HCLA, GP-HCLA}, the expected size of set B is bounded by\n$E [|B|] \\leq 4MK + \\frac{2M^{3}K}{\\delta^{2}}$.\nProof. To bound E [|B|], we start by defining a new set of time steps as follows:\n$\"\\\"\"\nB_{m,k} := \\{t\\geq 1 : |\\mu_{m,k(t)} - \\mu_{m,k(t)} | \\geq \\frac{\\delta}{M}\\}.\nNow we show that\n$E [|B|] < \\sum_{(m,k)\\in M\\times K} E [|B_{m,k}|].$"}, {"title": "B.4 Proof of Theorem 6", "content": "The main difference between GP-HCLA and G-HCLA is the determining Ghint as the same event is triggered. Thus", "as": "nE1", "G'": {"EG'": "U (G'; \u00fb(t)) \u2013 U (G'; \u03bc(t))| \u2265 \u03b4"}, "n$E_{2,G'}": {"E_{G'}": "sum_{t'=1"}, "t_{o}\\}$,\n$\"\\\"\"\nX_{1,m,k}": {"E_{G'}": "mu_{m", "frac{\\delta}{M}\\},$\n$X_{1,m,k}": {"1": "m", "frac{\\delta}{M}\\},$\n$X_{2,m,k}": {"1": "sum_{t'=1"}, "E1,G'|": "nand also\n$\\sum_{G'\\in G"}, "E_{2,G'}|": "leq \\sum_{(m", "X_{2,m,k}|": ".", "writing": "n$\\sum_{G'\\in G} \\mathbb{E} [|E_{G}|", "E_{1,G'}|": "mathbb{E} [|E_{2,G'}|"}}]}