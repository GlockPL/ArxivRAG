{"title": "A Multi-Task Learning Approach to Linear Multivariate Forecasting", "authors": ["Liran Nochumsohn", "Hedi Zisling", "Omri Azencot"], "abstract": "Accurate forecasting of multivariate time series data is important in many engineering and scientific applications. Recent state-of-the-art works ignore the inter-relations between variates, using their model on each variate independently. This raises several research questions related to proper modeling of multivariate data. In this work, we propose to view multivariate forecasting as a multi-task learning problem, facilitating the analysis of forecasting by considering the angle between task gradients and their balance. To do so, we analyze linear models to characterize the behavior of tasks. Our analysis suggests that tasks can be defined by grouping similar variates together, which we achieve via a simple clustering that depends on correlation-based similarities. Moreover, to balance tasks, we scale gradients with respect to their prediction error. Then, each task is solved with a linear model within our MTLinear framework. We evaluate our approach on challenging benchmarks in comparison to strong baselines, and we show it obtains on-par or better results on multivariate forecasting problems. The implementation is available at: https://github.com/azencot-group/MTLinear", "sections": [{"title": "1 Introduction", "content": "Time series forecasting (TSF) with deep learning leverages neural networks to model and predict sequential data over time, enabling accurate predictions and insights into future trends. Its importance lies in its ability to handle complex temporal dependencies and patterns, making it invaluable for tasks such as financial forecasting, resource planning, and demand prediction in various industries. While most existing TSF approaches are based on N-BEATS and the Transformer [23, 32], a recent work finds simple linear layers to be highly effective [37, 16]. However, linear models are naturally limited, and thus, current efforts focus on developing nonlinear approaches where state-of-the-art (SOTA) techniques incorporate the linear module as the final decoder layer [22, 42].\nGenerally, TSF frameworks are designed to accept univariate and multivariate temporal data. In the multivariate case, time series data has multiple dimensions per sequence sample, whereas univariate data is one dimensional. Remarkably, while TSF is assumed to benefit from the inter-relations underlying multivariate information [9, 27], recent methods opt to handle each variate independently [37, 22]. Nevertheless, dominant variate signals may disproportionally affect forecast performance, especially in limited linear models. Several research questions arise from the latter straightforward observation: how to model different variates? how to treat similar vs. dissimilar variates? how to balance the contribution of variates in the context of forecasting?\nTowards addressing the above questions, we interpret time series forecasting with deep learning through the lens of multi-task learning (MTL) [39]. MTL trains a single model to perform multiple related tasks simultaneously, leveraging shared representations to improve performance across tasks, enable knowledge transfer, and facilitate efficient learning. Our view of TSF as MTL is based on the assumption that similar variates should be modeled similarly, and dissimilar variates encode different forecasting tasks. When considered as separate tasks within MTL formalism, we can harness tools, observations, and the general advances in MTL to better solve time series forecasting problems.\nParticularly, a recent work [35] formulates some of the challenges underlying multi-task learning with respect to the tragic triad. The authors advocate that conflicting gradients, varying gradient magnitudes, and highly curved loss manifolds hinder MTL methodologies. Further, identifying which tasks can learn together is crucial to effective multi-task learning [7]. For instance, assigning conflicting tasks to a separate set of network weights was suggested in [11]. In our study, we explore how to group variates together, and how to weigh different variate groups during training. To our knowledge, deep TSF from a multi-task learning perspective has received only limited attention.\nGiven the success of linear models in TSF, we are motivated to study the use of one linear model per similar variates group, and to balance dissimilar variate groups based on their dominance. Specifically, we analyze the gradients of linear modules, and we observe the factors affecting the norm of the gradients and their direction. Based on our derivative analysis, we propose to group variates by their Pearson correlation coefficient, encoding linear relationships. Then, we construct a multi-head linear model (MTLinear), where each head learns from a separate variate group. Finally, we scale the gradients using the variate's characteristics. Our contributions can be summarized as follows:\n\u2022 We suggest to interpret time series forecasting as multi-task learning, where similar variates are grouped together, and each group forms a separate task. Variate grouping and per group balancing is inspired by our gradients analysis of linear TSF.\n\u2022 We propose a simple, efficient and effective multi-head linear network (MTLinear) for solving multivariate time series forecasting tasks.\n\u2022 We extensively evaluate our method on challenging TSF benchmarks, and compare our results to state-of-the-art (SOTA) models, showing that MTLinear is a strong standalone technique and it can be considered as a building block module for TSF."}, {"title": "2 Background", "content": "Multi-task learning (MTL) aims to optimize a set of weights \u03b8 that simultaneously minimize k different tasks, each corresponding to a different loss function Li(\u03b8). A typical single-objective function that combines all tasks takes the following form:\n\u03b8* = arg min L(\u03b8) := arg min (1/k) \u03a3 Li(\u03b8),                                  (1)\nwhere all tasks are averaged together to form a single loss L(\u03b8) that can be directly minimized via gradient descent. In this setting, each loss Li(\u03b8) is associated with a gradient gi := \u2207Li(\u03b8). The total gradient reads\n\u2207L(\u03b8) = (1/k) \u03a3 gi  = (1/k) \u03a3 \u2207Li(\u03b8).                              (2)\nFollowing [35], we detail fundamental challenges inherent to multi-task learning, termed as the tragic triad. First, conflicting gradients arise when the inner product between a pair of task gradients gi, gj is negative, i.e., giTgj < 0. Geometrically, it means that their angle is greater than \u03c0/2, and therefore, optimizing \u03b8 is carried by non-aligned directions. Second, when a set of gradients have a large gradient magnitude difference, larger gradients may shadow weaker gradients. This issue becomes especially problematic when gradients are also conflicting, leading to long and unstable training [24]. Finally, highly curved loss landscapes negatively affect the optimization of neural networks [15].\nMultivariate TSF deals with predicting future values of multiple inter-related variates over the time domain. Particularly, we are given in the multivariate case k inter-related components X1,X2,...,xk \u2208 Rl of length l, whereas the time series is univariate if k = 1. In TSF we predict the corresponding future values, denoted by Y1, Y2,..., Yk \u2208 Rh. Formally, TSF solves\n\u03b8* = arg min F(\u03b8) := arg min (1/k) \u03a3 Fi(\u03b8),                           (3)\nwhere the loss for forecasting tasks is the mean squared error (MSE), i.e., Fi(\u03b8) := [M(xi, \u03b8) \u2013 yi]2 \u2208 R with M(\u00b7,\u00b7) being a parametric model such as a deep neural network or a linear module.\nLinear forecasting with Linear, NLinear, and DLinear in [37] includes a single linear layer. While extremely simple, these models have achieved remarkable results in comparison to many Transformer-based approaches. Yet, they fall short with respect to recent SOTA techniques [22, 42]. Notably, the latter works often include in their architectures a linear decoder, similar in structure and role to the linear layers proposed in [37]. Formally, a standard linear layer is defined as,\n\u1ef8T = XT\u04e8 + b,\nwhere X = [X1,X2,...,Xk] \u2208 Rl\u00d7k is the input lookback, Y = [Y1, Y2,..., Yk] \u2208 Rh\u00d7k is the forecast horizon output, and \u0398 = [01, 02, ..., \u03b8\u03b7] \u2208 Rl\u00d7h and b\u2208Rh are the model weights and bias, respectively. We denote by Y \u2208 Rhxk the ground-truth horizon values."}, {"title": "3 Related Work", "content": "Multivariate time series forecasting. Significant efforts have been dedicated to modeling and predicting sequential information using deep neural networks [8]. In particular, recurrent neural networks (RNNs) such as LSTM and GRU with their gating mechanisms obtained groundbreaking results on various vision and language tasks [13, 5]. Alas, not until recently, pure deep models were believed to be unable to outperform non-deep or hybrid tools [23]. Nevertheless, within a span of two years, pure deep methods based on RNNs [26], feedforward networks [23], and the Transformer [40] have appeared, demonstrating competitive results and setting a new SOTA bar for long-term TSF.\nFollowing these breakthroughs, numerous works have emerged, most of them are based on the Transformer architecture [33, 41, 38]. Recently, a surprising work [37] has shown remarkable TSF results with a simple single-layer linear model, competing and even surpassing the best models for that time. Notably, the linear model applied weights along the time axis, in contrast to the more conventional practice of applying weights along the variate axis. Subsequently, new SOTA techniques [22, 34] and a recent foundation model for time series [42] have integrated a similar linear module as their final decoder to attain better forecasts.\nMulti-task learning. Improving learning on multiple tasks follows three different categories: gradient manipulation, task grouping, and architecture design. Manipulating gradients is done by imposing weights [10], shift gradient directions [35], and add an optimization step to balance gradients or resolve conflicts [3, 28, 17]. In task grouping, previous works attempted to cluster different tasks based on similarity measures, thereafter assigning them to separate models [36, 30, 7, 29]. Lastly, multiple forms of architecture design have been introduced to support MTL including hard-parameter sharing [31], soft-parameter sharing [20, 14], and mixing solutions [11]. For time series data, a multi-gate mixture of experts for classification was suggested in [19], whereas a soft-parameter sharing RNN-based model was proposed in [4]. However, most of the multi-task techniques mentioned above focus mostly on vision problems. Consequently, little attention has been given to analyzing and mitigating the multi-task learning challenges for time series problems, particularly TSF."}, {"title": "4 Method", "content": "We analyze linear forecasting (Sec. 4.1), motivating our variate grouping (Sec. 4.2), gradient scaling 4.3, and yielding an efficient and effective TSF model (Sec. 4.4).\nThe following preliminary example motivates our perspective of TSF as MTL. We compare gradient conflicts vs. variate correlation by training a vanilla TSF model, and counting the number of conflicts between gradients after every epoch. We used the DLinear [37] and PatchTST [22] TSF models and ETTm2 and Weather datasets. The results are shown in Fig. 1, where every line plot shows the conflicts number for a pair of variates. The correlation (corr) per pair is detailed in the legend, where corr\u2248 1 and corr\u22480 denote strong and weak linear correlations, respectively. Clearly, variates with a strong linear relationship (negative or positive) have fewer conflicts and vice versa, consistent across both DLinear and PatchTST architectures."}, {"title": "4.1 Linear Analysis", "content": "To motivate our approach, we present below a gradient analysis of the linear model in Eq. (4). We begin by noting that since \u0398 is applied in the temporal domain, every forecast horizon j = 1,..., h is obtained with a separate set of weights, i.e., dj \u2208 Rl and bj \u2208 R. Indeed, we have that XT\u04e8 = [XT01, XT02,..., XT0h] = [Y1, Y2,..., Yn], where \u1ef8j represents the j-th row of \u0176T, and we incorporated the bias bj in dj, for all j. Thus, the MSE loss corresponding to Eq. (4) is given by\nF(\u0398) = |\u03a7\u0398 \u2013 YT|2 := (1/kh) \u03a3\u03a3 (xTj0i \u2013 Yji)2,   (5)\nwhere Y \u2208 Rhxk are the true values, and we split every XT0j to individual coordinates via xT0ji. The objective in Eq. (5) is quadratic, and thus, its gradient is linear in \u0398. Given the above discussion, F can be viewed either as a function F(\u04e8) : R(l+1)\u00d7h \u2192 R or as a sum of functions Fj(0j) : Rl+1 \u2192 R for j = 1,...,h. The gradient for the latter form reads\n\u22070jF(0j) = (1/k) \u03a3 xi (xTji0j \u2013 Yj,i).                             (6)\nWe provide the full derivation in App. A. The expression in Eq. (6) highlights that multivariate TSF and MTL are closely related, in the sense that the k variates represent k different tasks sharing the same set of weights 0j. Thus, multivariate forecasting may potentially face similar challenges as multi-task learning.\nThe simplicity of the linear model and its gradients allows to characterize the direction and scale of gradients. Based on Eq. (6), we arrive at the following two straightforward observations: 1) The direction of the gradient is governed by xi \u2208 Rl+1; and 2) The gradient's scale is affected by 2(xTji0j \u2013 yj,i) \u2208 R. Using these observations, we also consider the relation of different tasks, i.e., the angle and balance between the gradients associated with different variates xa and xb.\nTo this end, the first observation reveals that each task is updated simply along the direction of its corresponding variate xi. Thus, the angle between gradients is equivalent to the angle \u03b1 between variates xa and xb, which is given by their cosine similarity, cosxa,x\u044c (\u03b1) = xaT\u0445\u044c/(|xa|\u00b7|xb|). The cosine similarity"}, {"title": "4.2 Variate grouping", "content": "Based on Sec. 3, one common approach to deal with some of the challenges underlying MTL is to assign non-conflicting tasks to separate sets of weights [7, 11, 29]. A direct implementation of this idea in TSF will result in an independent model per variate, which may be highly demanding computationally for data with many variates (App. C.4). An optional middle-ground toward an efficient framework is to assign separate weights for a-priori clustered variates. Namely, we identify similar variates, clustering them into groups with separate network weights. Importantly, forecasting is different from multi-task learning problems in, e.g., vision, where task relationships can not be necessarily extracted directly from the input. In comparison, the objective in TSF is to accurately predict the future horizon, which shares fundamental features with the input lookback, such as trend, seasonality, periodicity, and data distribution. Moreover, our analysis in Sec. 4.1 shows that tasks' alignment can be deduced in practice by estimating the correlation between different variate vectors.\nOur a-priori clustering and weights assignment method follows three simple steps: 1) Compute the absolute-value correlation matrix for variates, defined via Rx = (| cosxa,x\u044c (\u03b1)|) for a, b = 1, . . ., k. 2) Perform agglomerative clustering on Rx, based on a threshold \u0101, encoding the maximum angle between two variates. Note that variates with |\u03b1| <\u0101 are grouped together. Sec. 5.2 justifies empirically grouping variates with a strong negative correlation, as they share a similar optimization trajectory. 3) Finally, for each variates cluster, assign a separate linear-based neural network (Sec. 4.4)."}, {"title": "4.3 Gradient manipulation", "content": "Even though dissimilar variates are assigned to different sets of weights, the risk of having a subset of variates dominating the optimization process within each group still prevails. Thus, we introduce a gradient magnitude penalty w \u2208 R+ that incorporates the error ei,j of its associated gradient. The penalty wij multiplies the loss for every admissible i, j, and the new loss is formally given by Fw (\u0398) = |XT\u04e8 \u2013 YT|2wa, where\n|\u03a7\u0398 \u2013 YT|2wa = \u03a3\u03a3 wij (xTj0i \u2013 Yi,j)2,                                     (7)\nwhere |A|2wa = ATWA, Wa = (wij) \u2208 Rkxh, and the weights wij are defined as follows,\nwij = (1/(Kj \u00b7 Hi)\u03b1) , K = \u03a3 Kj/k, H = \u03a3 Hi/h.                              (8)\nEssentially, wij addresses dominant scales along the horizon axis and the variates axis. Specifically, Kj is the mean error of different variates for the same horizon j, whereas Hi is the mean error of different horizons for a given variate i. Thus, wa j balances both means when they attain high magnitudes. The parameter \u03b1 controls the intensity of our penalty. During training, we treat wij as a constant scalar (i.e., a computational graph leaf), thus Eq. (7) avoids additional gradient computations. Consequently, the computational complexity of our gradient manipulation is O(1), unlike other methods [3, 35, 17] whose complexity is O(k). This procedure is applied individually to each group's linear model."}, {"title": "4.4 Multi-task Linear Model", "content": "The individual linear models mentioned in Sec. 4.2 are added to a training framework we call MTLinear. MTLinear is a single multi-head linear layer with c heads, each corresponding to a group of variates. Importantly, the separate heads can be trained in parallel, reducing the overall computational footprint of our approach. Each head of MTLinear is based on the linear models proposed in [37]. Specifically, we focus on the DLinear and NLinear baselines. DLinear decomposes the time series to a trend component and a remainder component, where each component is handled by a separate set of weights. The trend is extracted with a standard average pooling kernel. NLinear introduces a \"normalization\" pre-processing mechanism where the last values of the lookback are subtracted from the series before the forward pass, and are added back in when computation finishes. Our overall pipeline for time series forecasting is illustrated in Fig. 2."}, {"title": "5 Experiments", "content": "Details regarding the datasets, models, experimental setup and implementation notes are provided in App. D. We tested our approach based on DLinear and NLinear vs. SOTA nonlinear Transformer models. The results in Tab. 1 show the MSE and MAE scores. Each score represents the average of four forecast horizons h \u2208 {24,36,48,60} and 36 input length for ILI, as well as h\u2208 {96, 192, 336, 720} and 96 input length for the remaining. We use a similar format also in Tabs. 2, 3, and 4. Our results indicate that MTLinear has an overall superior performance with a best global MSE and MAE corresponding to 0.550 and 0.423 with MTNLinear, and second best MSE 0.575 with MTDLinear. In general, we outperform the transformer models, obtaining 11 top scores whereas iTransformer and PatchTST account for only 6. The full results are presented in Tab. 7, along with an extension to the 336 lookback length where we also compare to the original PatchTST and GPT4TS results reported in Tab. 8."}, {"title": "5.1 Ablation of MTLinear Components", "content": "The proposed MTLinear method incorporates variate clustering and a gradient penalty, which, although separate components, work synergistically to address the tragic triad issues. Specifically, clustering helps manage gradient conflicts, while scaling addresses the varying gradient magnitudes. In the following experiment, we evaluate the effect of each component individually and in combination, with results presented in Tab. 2. Our ablation study reveals that in some datasets, using only one component may provide minimal benefit or even degrade performance. However, the combined approach consistently outperforms, with both components together yielding superior results in most cases."}, {"title": "5.2 Longer Lookbacks and Grouping Criteria", "content": "Longer lookbacks. Constraining a forecast model to a fixed lookback, such as 96, reduces its robustness and adaptability to different problems with varying lookback lengths. Here, we evaluate MTLinear's performance across different lookbacks\u2014192, 336, 512, and 720-and compare it with iTransformer and PatchTST. As shown in Fig. 3, MTLinear variants consistently outperform iTransformer across all cases, with particularly strong results for the 720 lookback. While PatchTST proves competitive, MTLinear surpasses its performance across all lookbacks and datasets, except for Electricity at 192 and 336 lookbacks. Overall, MTLinear consistently improves as the lookback length increases, a trend not typically observed with transformer-based models [37].\nGrouping criteria. We now examine the effect of various angles, \u03b1 \u2208 \u03c0/2,\u03c0/3, \u03c0/4, \u03c0/6,0, each representing a maximum cosine similarity threshold for grouping variates. Specifically, \u03b1 = 0 enforces strict clustering, with one variate per cluster, while \u03b1 = \u03c0/2 results in a single model across all variates, as groups are formed based on absolute correlation values. In Fig. 4, we plot MTLinear's performance for each \u03b1 on the x-axis, with corresponding MSE scores on the y-axis. Our findings indicate that \u03b1 impacts datasets differently, likely due to varying degrees of the tragic triad issues. Weather and ETTm1 perform well with most groupings, suggesting that a shared model does not eliminate gradient conflicts. Conversely, for ILI, \u03b1 = \u03c0/2 proves optimal. Additionally, model size plays a role, as groupings with \u03b1 > 0 yield a more compact model-especially relevant for datasets with numerous variates. Tab. 6 shows that this approach can reduce model size by more than half while enhancing performance. Notably, in each sub-plot of Fig. 4, several MTLinear configurations outperform iTransformer, indicating that linear forecasters remain effective in TSF and merit inclusion in new methods. Finally, we study the correlation-conflict similarity in Fig. 6, finding that the correlation and conflict matrices are similar for DLinear and PatchTST but not for Autoformer. This difference may stem from PatchTST and DLinear's use of weight-per-time linear layers, unlike Autoformer."}, {"title": "5.3 Variants of Gradient Manipulation", "content": "We compare our approach with robust gradient manipulation baselines, including GradNorm [3] and PC-Grad [35], which adjust gradients per task to address magnitude and conflict issues. Additionally, we benchmark against Cov-Weighting (CoV-W) [10], which emphasizes tasks with higher trailing variance, assuming that reduced variance indicates a satisfied loss. We also include CAGrad [17] and Nash-MTL [21]. Exploring different scaling schemes helps assess whether the variance of ei,j impacts results beyond the error alone. As shown in Tab. 3, MTLinear outperforms these methods while being more efficient, requiring only a single backward pass compared to the k passes needed by PCGrad and GradNorm. We further analyze the link between error term ei,j and gradient magnitude in Fig. 5, where we find a strong correlation across the Weather, ETTm2, and ILI datasets, with higher errors corresponding to larger gradients\u2014motivating our penalty in Sec. 4.3."}, {"title": "5.4 Model Variations and Linear Probing", "content": "The MTLinear method is versatile and can integrate with linear layers beyond NLinear or DLinear, including a standard linear layer, to boost performance. We present these results in Tab. 4, where MTLinear-based approaches consistently improve baseline MSE scores by up to 18% for ILI and 10% across other datasets.\nIn TSF transfer learning with foundation models and Transformer architectures, a common approach is linear probing, where only the final linear layer is fine-tuned on a pre-trained model [22, 42, 2]. To assess the transfer capabilities of TSF models, we conducted an experiment where several baselines were first trained on a source dataset and then fine-tuned on a target dataset. The baselines include MTLinear, MTLinear Probing, Zero-shot, and PatchTST. MTLinear Probing refers to PatchTST with our MTLinear module replacing its decoder, while Zero-shot involves no fine-tuning. MSE results are presented in Tab. 5, with the top table showing results for Electricity as the source dataset with Weather and ETTm2 as targets, and the bottom table displaying Weather as the source dataset with Electricity and ETTm2 as targets. All experiments"}, {"title": "6 Conclusion", "content": "In this work, we considered the task of multivariate time series forecasting. While several strong existing works treat different variates independently, we offered to exploit their inter-relations. We do so by viewing multivariate forecasting as a multi-task learning problem, allowing to consider forecasting through the tragic triad challenges. Our analysis of linear models and their gradients suggest that variates are optimized along the direction of the variate, and scaled proportionally to the prediction error. Based on our analysis, we propose to group variates together if the angle between them is small, and to balance variate groups using their error. Ultimately, each variate group is viewed as an independent task, solved using a single linear module, and combined into an optimization framework we named MTLinear. Our approach shows competitive results in several benchmarks in comparison to strong baseline methods. While our method effectively utilizes inter-related variate information, its structure limits the exploitation of non-correlated cross-variate information. This is significant, as different variates-regardless of their correlation-may contain unique information that could enhance the overall predictive performance. Another limitation is our reliance on a specific linear layer type, such as DLinear or NLinear. We believe that a unified framework combining these or incorporating additional layer types would further strengthen the MTLinear approach.\nIn the future, we plan to investigate the incorporation of the multi-head MTLinear as a decoder in state-of-the-art methodologies. Additionally, we will explore the effect of learning the clusters during training, instead of computing them as a pre-processing step. Lastly, we wish to address the limitations of our work. In general, we believe that further studying the inter-relations between variates of real-world time series data is important, and our work is a first step toward achieving that goal."}, {"title": "A Linear Analysis Proof", "content": "Below, we provide the full derivation for the gradient provided in Eq. (6). We recall that F(O) can be viewed as a function F(\u04e8) : Rl+1\u00d7h \u2192 R or as a sum of functions F(0j) : Rl+1 \u2192 R. After flattening, the gradient of the first function is an object of size 1+1h, where every 1 + 1 elements correspond to a particular gradient for F(0j), j = 1, ...,h. Thus, it is sufficient to derive the gradient of F(0j), as we detail below.\nF(\u0398) = (1/kh) \u03a3\u03a3 (xTj0i \u2013 Yji)2, F(0) = (1/k) \u03a3 (xTj0i \u2013 Yji)2\nF(0j + 80j) \u2013 F(0) = (1/k)\u03a3 ((xTj(0j + 80j) - yj,i)2 \u2013 (xTj0j \u2013 yj,i)2)\n= (1/k) \u03a3 (xTj (0j + 80j) (xTj (0j + 80j) \u2013 yj,i) \u2013 xTj0j(xTj0j - yj,i))\n= (1/k) \u03a3 (xTj (0j + 80j) (xTj0i \u2013 yj,i)+ xTj(0j + 80j)(xTj +80j \u2013 yj,i) \u2013 xTj0j(xTj0j - yj,i))\n= (1/k) \u03a3 (xTj (0j + 80j) (xTj0i \u2013 yj,i))\n= (1/k) \u03a3 (xTj80jxTj0i \u2013 yj,i)\nwhere the starred pass is where we leave only elements that depend on 0j, and the double starred pass is due to eliminating non first-order in 80j elements."}, {"title": "B Convergence Proof", "content": "In what follows, we provide a straightforward proof for the convexity of our optimization, detailed in Eq. (7). Then, under certain mild conditions that are satisfied by our problem, stochastic gradient descent (SGD) is guaranteed to converge [1]. We recall that per cluster, our loss take the form of |XT\u04e8 \u2013 YT|2wa, where X \u2208 Rlxk, Y \u2208 Rh\u00d7k,0 \u2208 Rlxh, and Wa \u2208 Rhxk. The norm |A|2wa := trace(AT WA), where is an element-wise multiplication operation. To prove that Eq. (7) is convex, we will show that its Hessian is a fixed, semi-positive definite (SPD) matrix. First, we observe that since each element Wij \u2265 0 by Eq. (8), then it holds that |A|2wa = trace[AT \u221aWa\u221a\u221a(Wa)T\u00a9 A], where \u221aA is the element-wise square-root of the matrix A. Additionally, we denote by Aw a matrix scaled by \u221aWa, i.e., Aw = \u221a(Wa)TA. Then, it follows that\n|XTO \u2013 YT |wa = trace[\u221a(Wa)\u221a(Wa)T (XT\u04e8 \u2013 YT)]\n= trace [(TXw - Yw)(\u03a7\u0398 \u2013 Y)].\nWe differentiate with respect to under the trace(\u00b7) operation and obtain\n(d/d\u0398) |XTO \u2013 YT|wa = trace [(TXw - Yw)(\u03a7\u0398 \u2013 Y)]\n= 2Xw (\u03a7\u0398 \u2013 Y),\nwhich follows from properties of the trace(.) and computing the derivative per element. Taking another derivative yields\n(d/d\u0398) [2Xw(\u03a7\u0398 \u2013 Y)] = 2XwXw,\nwhich is an SPD matrix as it is the product of a matrix multiplied by the same matrix transposed."}, {"title": "C Variate Grouping", "content": "C.1 Correlation and Conflict Matrices\nIn this section, we present the correlation matrices and conflict matrices for the datasets Weather and ETTm2. In Fig. 6, each cell in the conflict matrices represents the count of all conflicts between two variates occurred during training. A resemblance is apparent mostly for DLinear and PatchTST. One interesting observation is that strong negative correlations between variates are associated with a low number of conflicts.\nC.2 Task Affinity Grouping (TAG)\nTask affinity grouping (TAG) [7] is a task grouping method, that suggests to select task groups based on the quality of transferability between tasks. In this context, the term inter-task affinity encodes the transferability of each task with the remaining tasks during training. TAG proposes two steps. First, obtain a measure of pair-wise task similarity by training a shared model across tasks and observing the contribution of single-task optimization updates on the remaining tasks; the inter-task affinity between tasks is collected and later acts as a measure of task similarity. The next step is calculating the optimal task groups with a selection process that maximizes the total affinity score. When applied to time series forecasting, certain elements in TAG pose serious difficulties: 1) Training the first steps of this framework could impose a great amount of overhead when applied to the dataset Electricity or Weather since they contain 321 and 21 variates (tasks) respectively. 2) After collecting all the inter-task affinities the selection process maximizes the total affinity score. However, this problem is NP-hard, and thus it requires approximation for using a large number of tasks. Therefore, MTLinear (our approach) can be seen as a more practical approach to variate grouping, and model assignment in TSF settings.\nC.3 Hierarchical Clustering\nIn this section, we briefly present the hierarchical clustering algorithm [12] we utilize in Sec. 4.2. Hierarchical clustering is a general name for a bottom-up (agglomerative) strategy or top-down (divisive) strategy. In this work, we focus on agglomerative clustering which commences with each individual object forming its distinct group. It then systematically combines objects or groups that are proximate to each other until all groups are"}, {"title": "C.4 Memory Usage", "content": "Since MTLinear relies on duplicated versions of a single linear model variation, the memory usage of each model can be easily computed according to the number of selected groups. Therefore, Tab. 6 also describes the memory complexity in units of a single linear model variation memory usage. For example, MTLDinear for Electricity \u03b1 = \u03c0/6 consists of 175 times the memory of a single DLinear model. While this number may seem large, in practice, it is part of a single module implemented in Pytorch where all linear components are stacked such that only the depth of one layer remains. Another benefit of MTLinear is an effective and efficient implementation of quasi-channel independent modeling, where the full memory usage of a channel independent approach (\u03b1 = 0) is replaced with a smaller and utilized representation."}, {"title": "D Experimental Details", "content": "Datasets. The proposed method is extensively evaluated on seven common benchmark datasets from different sectors: industrial", "experiments": "PatchTST [22", "18": "Crossformer [38", "41": "Autoformer [33", "42": "as well as linear based models Linear, DLinear, NLinear, RLinear [37, 16"}, {"18": "except for ILI, where the results for Crossformer, FEDformer, and Autoformer were imported from the original paper and the latter was reproduced. In Tab. App. 8 the results for PatchTST, GPT4TS, DLinear, and NLinear are the original reported results. The remaining experiment tables and figures are reproduced based on the original implementation and hyper-parameters.\nExperimental setting. For all experiments we take the average score of three different seeds. For each seed, we perform grid search and select the setting with the best validation score. The given grid search includes \u1fb6\u2208 {\u03c0/2, \u03c0/3, \u03c0/4, \u03c0/6} and a \u2208 {1,2} for the grouping and penalty parameters, respectively. The other reported results rely on the original implementation and hyperparameters. Most experiments use the standard lookback l of 96, unless mentioned otherwise.\nMTLinear implementation details. MTLinear and its multi-head linear modules are implemented in Pytorch [25"}]}