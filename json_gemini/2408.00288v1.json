{"title": "Gradient Harmonization in Unsupervised Domain Adaptation", "authors": ["Fuxiang Huang", "Suqi Song", "Lei Zhang"], "abstract": "Unsupervised domain adaptation (UDA) intends to transfer knowledge from a labeled source domain to an unlabeled target\ndomain. Many current methods focus on learning feature representations that are both discriminative for classification and invariant\nacross domains by simultaneously optimizing domain alignment and classification tasks. However, these methods often overlook a\ncrucial challenge: the inherent conflict between these two tasks during gradient-based optimization. In this paper, we delve into this\nissue and introduce two effective solutions known as Gradient Harmonization, including GH and GH++, to mitigate the conflict between\ndomain alignment and classification tasks. GH operates by altering the gradient angle between different tasks from an obtuse angle to\nan acute angle, thus resolving the conflict and trade-offing the two tasks in a coordinated manner. Yet, this would cause both tasks to\ndeviate from their original optimization directions. We thus further propose an improved version, GH++, which adjusts the gradient\nangle between tasks from an obtuse angle to a vertical angle. This not only eliminates the conflict but also minimizes deviation from the\noriginal gradient directions. Finally, for optimization convenience and efficiency, we evolve the gradient harmonization strategies into a\ndynamically weighted loss function using an integral operator on the harmonized gradient. Notably, GH/GH++ are orthogonal to UDA\nand can be seamlessly integrated into most existing UDA models. Theoretical insights and experimental analyses demonstrate that the\nproposed approaches not only enhance popular UDA baselines but also improve recent state-of-the-art models.", "sections": [{"title": "1 INTRODUCTION", "content": "EEP convolutional neural networks and transformers,\ndriven by extensive labeled samples, have achieved\nremarkable success in various computer vision tasks such as\nclassification, semantic segmentation and object detection.\nHowever, these models often demonstrate high vulnerabil-\nity when deployed in novel application scenarios due to\ndata distribution discrepancies. The process of collecting\nand annotating data across various domains is expensive,\nlabor-intensive and time-consuming. Consequently, Unsu-\npervised Domain Adaptation (UDA) arises to transfer the\nknowledge from a labeled source domain to an unlabeled\ntarget domain [15], [37], [56], [65].\nIn recent years, UDA algorithms have made significant\nprogress in enhancing classification performance [9], [43],\n[55], [59], [87], [94], [95]. The primary focus of these ap-\nproaches is to acquire domain-invariant feature represen-\ntations, thereby achieving domain alignment and narrow-\ning the probability distributions across domains. Currently,\ndomain alignment methods fall into two main categories:\ndistance metrics-based methods [1], [28], [54], [57], [73], [76]\nand adversarial learning-based methods [4], [8], [14], [20],\n[44]. The distance metrics-based approaches align the source"}, {"title": "2 RELATED WORK", "content": "2.1\nUnsupervised Domain Adaptation (UDA)\nUnsupervised Domain Adaptation (UDA) aims to leverage\nthe knowledge learned from a labeled source dataset to"}, {"title": "3 PROPOSED APPROACH", "content": "3.1 Problem Definition\nGiven a labeled source domain D, = {x;,y;};, with ns\nsamples and an unlabeled target domain D\u2081 = {x}+1\nwith nt samples, where y; is the class label of the ith source\nsample x;. Ds and Dt share the same feature space and\ncategory space, but have different data distributions. Our\npurpose is to utilize the labeled data Ds and unlabeled data\nDt to learn a deep model, which can accurately predict the\nclass label of samples in the target domain."}, {"title": "3.2 A General Framework of UDA", "content": "Adversarial learning has proven to be an effective method\nfor domain alignment, starting from Domain Adversarial\nNeural Network (DANN) [25]. The basic idea is to trick\nthe domain discriminator D by generating features via a\nfeature generator G. Then the domain discriminator predicts\nwhether the generated feature by G is from the source\ndomain or the target domain. The training of domain align-\nment is achieved through the game between generator and\ndomain discriminator. The parameter og of generator G and\nthe parameter da of domain discriminator D are optimized\nby the following domain alignment objective function.\n\\(L_{dom}(\\theta_g, \\theta_d) = E_{x \\sim D_s}log[D(G(x))]+\nE_{x \\sim D_t}log[1 - D(G(x))].\\) (1)\nIn order to improve the classification performance of\nthe target domain samples, we must first ensure that the\nclassifier C can correctly classify the samples from the\nsource domain. Thus, the supervised classification loss can\nbe described as\n\\(L_{cls}(\\theta_g, \\theta_c) = \\frac{1}{N_s}\\sum_{i=1}^{N_s}L_{ce}(C(G(x_i; \\theta_g); \\theta_c),y_i),\\) (2)\nwhere Lce is the standard cross-entropy loss function.\nDuring training stage, the existing methods usually\njointly optimize the two objective functions (Ldom and Lels)\nto obtain domain-invariant and class-discriminant feature\nrepresentation. The overall minimax objective function is\n\\(min_{\\theta_d,\\theta_c} max_{\\theta_g} L_{dom} + L_{cls},\\) (3)\nwhere \u03b8\u03b1, \u03b8\u03b1, \u03b8\u03b5 denote the parameters of feature generator,\ndomain discriminator and classifier, respectively."}, {"title": "3.3 Gradient Harmonization (GH)", "content": "Domain alignment and classification are two different tasks.\nTheir optimal gradient descent directions may not be co-\nordinated, which results in the optimization conflict of\nthe two loss functions in the training process and deteriorates\nthe final domain adaptation performance.\nIn order to ensure that the two target tasks can be\noptimized in a coordinated manner, we propose an idea\nof de-conflict on the gradients, which then formulates the\nproposed GH technique, i.e., altering the gradient angle be-\ntween different tasks from an obtuse angle to an acute angle.\nThe de-conflict process for the gradients (i.e., g1 and g2) is\nschematically shown in Fig. 4. Specifically, we first provide\nthree Lemmas to support our idea. Then the proposed GH\nis summarized as Theorem 1. For convenience, we define\nL\u2081(\u0398) and L2(\u0398) as the general form of any two conflicted\nloss functions. In UDA, L\u2081(\u0398) and L2(\u0398) represent the do-\nmain alignment loss Ldom(0g, 0d) and the classification loss\nLcls(09, 0c), respectively. \u04e8 {09, 04, 0c} indicates model\nparameters of generator, discriminator and classifier. In fact,\nthe three Lemmas aim to deduce the gradient harmonization\nformula during model optimization (training) phase, by\nexhausted mathematical solving process.\nLemma 1. Given two objective functions L\u2081(\u04e8) and L2(\u04e8),\nwe define 91 and g2 as their gradient, respectively, and \u011f\u0131 is\nthe result of harmonizing the gradient 91. For minimizing the"}, {"title": "3.4 Essence and Insights of GH", "content": "To understand the essence of GH more intuitively, we\ndemonstrate the proposed gradient harmonization by back-\nward inference in this section. Fig. 6 (a) and (b) show the\nessential analysis by performing gradient harmonization\non original gradients 91 and g2, respectively. Note that we\nmainly consider the case where gradient conflict exists, that\nis, the angle between g\u2081 and g2 is an obtuse angle.\nFirst, we analyze the essence of gradient harmonization\nfor g1 (i.e., Fig. 6 (a)). 0 denotes the angle between original\ngradients g1 and g2. n is the projection of g\u2081 on the reversely\nextended line of 92. m is perpendicular to 92. Note that each\nletter except @ on the figure represents a vector. Naturally,\nm can be derived as Eq. (31), from which we can see that\nthe expression of the vector m is the same as Eq. (4) when\n9192 < 0. That is, the vector m is the result of gradient\nharmonization of g1 (i.e., \u011f1).\n\\(m = g_1 - n = g_1 - |g_1| \\cdot cos(\\pi - \\theta) \\cdot \\frac{g_2}{|g_2|}\\)\n\\(=g_1 - |g_1|cos\\theta \\cdot \\frac{g_2}{|g_2|}\\)\n\\(=g_1 - \\frac{(g_1,g_2)}{|g_2|^2} g_2\\)\n\\(=g_1 - \\frac{g_1^T g_2}{\\|g_2\\|^2} g_2.\\) (31)\nwhere (\u00b7) is the inner product operator.\nSecond, we analyze the essence of gradient harmoniza-\ntion for g2 (i.e., Fig. 6 (b)). Similar to (a), the vector e is the\nprojection of g2 on the reversely extended line of g1. The\nvector f is perpendicular to 91. Through the derivation of\nEq. (32), it can be found that the expression of the vector f\nis the same as Eq. (24) when gf 92 < 0. That is, the vector f\nis the result of harmonizing the gradient g2 (i.\u0435., \u011f2).\n\\(f = g_2 - e=g_2 - |g_2| \\cdot cos(\\pi - \\theta) \\cdot \\frac{g_1}{|g_1|}\\)\n\\(=g_2 - |g_2|cos\\theta \\cdot \\frac{g_1}{|g_1|}\\)\n\\(=g_2 - \\frac{(g_1,g_2)}{|g_1|^2} g_1\\)\n\\(=g_2 - \\frac{g_1^T g_2}{\\|g_1\\|^2} g_1.\\) (32)\nFrom the above derivations, the nature of GH is summa-\nrized as follows. 1) The harmonic gradient \u011f\u0131 is essentially"}, {"title": "3.5 Improved Version: GH++", "content": "In this section, we propose an improved version called\nGH++, which aims to adjust the gradient angle between\nthe two tasks from an obtuse angle to a vertical angle, i.e.,\nmaking them orthogonal. This is to eliminate the conflict but\nsimultaneously relieve the gradient deviation. Fig. 7 visually\nillustrates the concepts of the proposed GH and GH++, with\na primary focus on scenarios where gradient conflict exists,\ni.e., when the angle between 91 and g2 is obtuse.\nGradient deviation. For clarity, we designate the original\ngradients as g1 = OA and g2 = OB. Let 0 represent the\nangle between g1 and g2. As illustrated in Fig. 7 (a), we\ndenote the gradients after applying GH as \u011f\u2081 = O and\n92 = OD, where OC I OB and OD | OA. Apparently,\nthe sum of the angles deviated from the original direc-\ntions is 2(0-\u03c0), i.e., \u2220AOC + \u2220DOB. In other words,\nalthough GH can promote the positive correlation between\nthe two gradients, its optimization gradient is seriously\ndeviated from the original gradient. Therefore, we propose\nan improved version, GH++, to eliminate the conflict and\nminimize the sum of the gradient deviations. As shown in\nFig. 7 (b), GH++ adjusts the gradient angle between the two\ntasks from an obtuse angle to a vertical angle, i.e., \u2220EOF.\nThe sum of the gradient deviation angles is (0 \u2013 \u03c0) i.e.,\n\u2220AOE + \u2220FOB, which is half of the sum of the gradient\ndeviations of GH.\nSpecifically, as shown in Fig. 7 (b), let denote the har-\nmonized gradients of GH++ as \u011f\u2081 = O\u1eba and 92 = OF. In\norder to resolve the conflict and relieve the deviation from\nthe original gradient directions, we designate OE I OF,\ni.e., \u2220EOF = \u03c0, where points E and F move along arcs AC\nand BD, respectively. Intuitively, \u25b3EOF forms a rotatable\nright triangle. We define the direction of rotation from g\u2081 to\n91 as positive. B represents the rotating angles from g\u2081 to\n91, which is a positive angle and \u1e9e represents the rotating\nangles from g2 to 92, which is a negative angle. According\nto Fig. 7 (b), the harmonization gradients of GH++, i.e., \u011f\u0131\nand \u011f2, can be represented as\n\\(\\begin{aligned}\ng_1 &= \\overrightarrow{OE} = \\overrightarrow{OA} + \\overrightarrow{AE} = g_1 + \\overrightarrow{AE},\ng_2 &= \\overrightarrow{OF} = \\overrightarrow{OB} + \\overrightarrow{BF} = g_2 + \\overrightarrow{BF}.\n\\end{aligned}\\) (33)"}, {"title": "3.6 Equivalent Model of UDA with GH/GH++", "content": "By combining the general UDA model (Eq. (3), described\nin Section 3.2) with gradient harmonization strategies (Eq.\n(29)/Eq. (40), a well-balanced UDA model can be trained\nand implemented. However, the gradient aggregation op-\nerator in Eq. (29)/Eq. (40) is intricate and has an im-\npact on optimization efficiency. Therefore, we introduce\na computation-efficient alternative model that is function-\nally equivalent to UDA with GH/GH++. For convenience,\nwe can express the proposed gradient harmonization ap-\nproaches, i.e., Eq. (29)/Eq. (40), as follows:\n\\(g=T_1g_1+T_2g_2,\\) (41)\nwhere T1 and 12 are constants that can be calculated by using\nthe original gradients 91 and 92. Notably, the gradient 91 of\nthe original loss L\u2081(O) and the gradient 92 of the original\nloss L2(O) can be easily computed, only if the UDA model\nis fixed. Then, if GH is chosen to resolve the conflict, T\u2081 and\nT2 can be calculated as follows.\n\\(T_1 = 1 - \\delta(g_1^T g_2 < 0) \\frac{g_2^T g_1}{\\|g_1\\|^2},\\)\n\\(T_2 = 1 - \\delta(g_1^T g_2 < 0) \\frac{g_1^T g_2}{\\|g_2\\|^2}\\) (42)\nIf GH++ is used to eliminate the conflict, T\u2081 and T2 can be\ncalculated as follows.\n\\(T_1=(1+2\\delta(g_1^Tg_2<0) \\sin(\\frac{(\\arccos\\frac{g_1^Tg_2}{\\|g_1\\||\\g_2\\|}-\\frac{\\pi}{2})}{2})),\\)\n\\(T_1=(1+2\\delta(g_1^Tg_2<0) \\sin(\\frac{(\\arccos\\frac{g_1^Tg_2}{\\|g_1\\||\\g_2\\|}-\\frac{\\pi}{2})(\u03bb-1)}{2})).\\) (43)\nUltimately, we can derive the equivalent UDA model em-\nbedded GH/GH++ by conducting the integral operation\non the gradient in Eq. (41). The overall loss of UDA with\nGH/GH++ model can be represented as\n\\(L = \\int (T_1g_1+T_2g_2)d\\Theta = T_1L_1(\\Theta) + T_2L_2(\\Theta),\\) (44)\nwhere L\u2081(\u04e8) and L2(\u04e8) can be the domain alignment\nloss and classification loss described in Eq. (1) and Eq. (2),"}, {"title": "4 EXPERIMENTS", "content": "4.1 Datasets\nOffice-31 [69] is a mainstream benchmark dataset for vi-\nsual domain adaptation, which consists of three distinct\ndomains: Amazon (A), DSLR (D), Webcam (W). It totally\ncontains 4,652 images from 31 categories. We evaluate our\nmethod in all 6 different transfer tasks across domains.\nOffice-Home [79] is a more challenging and harder\nbenchmark than Office-31. It contains 15.5K images across\n65 object categories from 4 different domains: Artistic im-\nages (Ar), Clip Art (Cl), Product images (Pr), and Real-World\nimages (Rw). We evaluate our method in all 12 different\ntransfer tasks across domains.\nDigits Datasets. We mainly study three datasets: MNIST\n(M) [91], USPS (U) [36] and SVHN (S) [64]. MNIST and USPS\nare two general handwriting recognition datasets involving\n10 categories. SVHN is obtained from house numbers in"}, {"title": "4.2 Implementation Details", "content": "We compare our method with the following state-of-the\nart unsupervised domain adaptation methods: ResNet [32],\nDAN (Deep Adaptation Networks) [54], DANN (Domain-\nadversarial Neural Networks) [25], JAN (Joint Adaptation\nNetworks) [58], DRCN (Deep Reconstruction-Classification\nNetworks) [29], CoGAN (Coupled Generative Adversarial\nNetworks) [52], ADDA (Adversarial Discriminative Do-\nmain Adaptation) [75], CyCADA (Cycle-consistent Ad-\nversarial Domain Adaptation) [33], CAT (Cluster Align-\nment with a Teacher) [17], TPN (Transferrable prototyp-\nical networks) [66], LWC (Light-weight Calibrator) [92],\nETD (Enhanced Transport Distance) [43], TAT (Transferable"}, {"title": "4.3 Results on UDA", "content": "Tables 1, 2, 3, 4 and 5 present evaluation results on Office-31,\nOffice-Home, VisDA-2017, Digits and DomainNet, respec-\ntively. Generally, the transformer-based results, such as TVT\nand SSRT, are much better than CNN-based results, which\nhas been validated in previous work. For TVT and SSRT,\nthe ViT backbone pre-trained on ImageNet-1K is slightly\ninferior than ImageNet-21K (i.e., TVT* &TVT, SSRT*&SSRT).\nConsidering that the CNNs are pre-trained on ImageNet-1K,\nwe take SSRT* for fair analysis as default in the following."}, {"title": "5 MODEL ANALYSIS AND DISCUSSION", "content": "5.1 Feature Visualization\nFig. 8 describes the t-SNE [77] visualizations of features\nlearned by MCD (baseline) and MCD+GH on the tasks of U\n\u2192 M and M \u2192 U. Fig. 8 (a) and (c) are visualization features\ngenerated by MCD. Fig. 8 (b) and (d) are visualization\nfeatures generated by MCD+GH. It can be observed that\nboth features learned by MCD and MCD+GH achieve well-\nperformed global alignment effect with 10 clusters under\ntwo tasks. Further, the visualization feature distributions\nwith GH deployed have better clustering effect and have\nfewer samples distributed across class boundaries, which\nintuitively boosts the feature discriminability. In addition,"}, {"title": "5.2 Convergence Analysis", "content": "We present the convergence curves of test error with respect\nto the number of iterations on tasks of U \u2192 M and Synthetic\n\u2192 Real as shown in Fig. 9. For each subfigure, the blue\nline represents the test error of different baselines, and\nthe red line represents the test error for baseline+GH (e.g.,\nCDAN+GH). Obviously, compared with baselines, the intro-\nduction of GH can further improve the test performance and\nconvergence. This fully indicates that GH plays an active"}, {"title": "5.3 Confusion Matrix Visualization", "content": "Fig. 10 displays the visualizations of confusion matrix for\nthe classifier trained by DWL and DWL+GH. DWL ob-\ntains several uncertain predictions with small values while\nDWL+GH obtains more confident predictions. Comparing\nwith Fig. 10 (a) and (b), the confusing \u201cClass 1, 2, 7, 8, and\n9\" are correctly recognized in DWL+GH. From Fig. 10 (c)\nand (d), the confusing \u201cClass 8\" is corrected in DWL+GH."}, {"title": "5.4 Balance Analysis of GH-based UDA", "content": "Fig. 11 shows MMD distance [3] and the max J(W) [10]\nvalues based on the feature representation learned by\nMCD+GH. The left vertical axis corresponding to the red\ncurve represents the MMD distance used to measure the"}, {"title": "5.5 Training Speed and Accuracy", "content": "In order to observe the efficiency of the proposed equivalent\nmodel more clearly, we present the training speed and clas-\nsification accuracy before and after applying GH. As shown\nin Table 6, for tasks M\u2192U and U\u2192M on digits datasets, the\ntraining speed of MCD+GH is 0.14254 s/epoch and 0.09809\ns/epoch longer than MCD, respectively. In other words,\nMCD+GH takes less training time than MCD in training\nprocess, but can get 2.5%/2.7% classification accuracy gain.\nThe computational cost of employing GH is quite low, and\nthus GH is a powerful and efficient auxiliary tool to facilitate\nthose popular domain adaptation baselines towards more\noutstanding classification performance."}, {"title": "5.6 Gradient Inner Product Visualization", "content": "Fig. 12 presents inner product distributions of two gradients\nbetween domain alignment and classification tasks before\nand after applying Gradient Harmonization for MCD. From\nFig. 12 (a), we observe the acute and obtuse angles between\ngradients of the two tasks before coordination. The obtuse\nangles account for about 40% of the total number, which\nexhibits the identical property as Fig. 2. In other words,\nthere exists between-task conflict in the model optimization\nprocess but paid less attention. After Gradient Harmoniza-\ntion, as shown in Fig. 12 (b), the inner products of the\ntwo gradients are all positive. That is, the gradient angles\nbetween the two tasks are coordinated into acute angles. The\nproposed GH avoids the optimization conflict by separately\nadjusting the gradients of the two tasks to achieve the\npurpose of optimal coordination. Experimental results fully\nillustrate the effectiveness of the proposed GH."}, {"title": "5.7 Rationality and Comparison to Other Alternatives", "content": "The proposed_GH/GH++_aims at altering the gradient\nangle between two different tasks from an obtuse angle"}, {"title": "5.8 Parameter Sensitivity Analysis", "content": "To investigate the effect of the parameter \u5165 in GH++, we\nconduct experiments on three tasks (i.e., M\u2192U, U\u2192M\nand S\u2192M) based on MCD and GVB by varying \u03bb\u2208\n{0, 0.1, 0.3, 0.5, 0.7, 0.9, 1}. The results are presented in Fig\n14. We can observe GH++ is little sensitive to the scale\nvariety of A, which indicates that GH++ is robust across\ndifferent baselines and tasks. Besides, we observe that when\nX = 0.5, models generally achieve the best performance. In\nother words, when the gradient deviation of the two tasks\nis relieved, the performance can be largely improved."}, {"title": "5.9 Scalability to Other Multi-task Problems", "content": "To further demonstrate the universality and scalability of\nthe proposed approaches, we evaluate GH/GH++ in the\nobject detection and multi-modal interactive retrieval fields,\nwhich also involves optimization of multiple objectives.\nDataset. We select widely used benchmarks, i.e., PAS-\nCAL VOC 2007 [22] and CSS [80] for object detection"}, {"title": "6 CONCLUSION", "content": "In this paper, we pay attention to the optimization conflict\n(i.e., imbalance or incoordination) problem between differ-nent tasks (i.e., the alignment task and the classification task)\nin alignment-based unsupervised domain adaptation mod-els. To mitigate this problem, we propose two simple yet\nefficient Gradient Harmonization approaches, including GH\nand GH++, which take measures to de-conflict between the\ngradients of both tasks in optimization. Besides, to facilitate\nthe harmonization during adaptation, we derive the equiv-alent but more efficient model of UDA with GH/GH++,\nwhich becomes a dynamically reweighted loss function of\nmost existing unsupervised domain adaptation models. Fur-ther, the essence and insights of the proposed approaches\nare provided to indicate its rationality. Exhaustive experi-ments and model analyses demonstrate that the proposed\napproaches significantly improve the existing UDA mod-els and contribute to achieving state-of-the-art results. Inaddition, we have verified that the proposed approaches\ncan be adapted to other problems and areas, such as objectdetection and multi-modal retrieval, to de-conflict betweenthe gradients of any two tasks in optimization and improvemodel performance."}]}