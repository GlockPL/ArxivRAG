{"title": "GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable Recommendation", "authors": ["Fei Tang", "Yongliang Shen", "Hang Zhang", "Zeqi Tan", "Wenqi Zhang", "Guiyang Hou", "Kaitao Song", "Weiming Lu", "Yueting Zhuang"], "abstract": "Large language model-based explainable recommendation (LLM-based ER) systems show promise in generating human-like explanations for recommendations. However, they face challenges in modeling user-item collaborative preferences, personalizing explanations, and handling sparse user-item interactions. To address these issues, we propose GaVaMoE, a novel Gaussian-Variational Gated Mixture of Experts framework for explainable recommendation. GaVaMoE introduces two key components: (1) a rating reconstruction module that employs Variational Autoencoder (VAE) with a Gaussian Mixture Model (GMM) to capture complex user-item collaborative preferences, serving as a pre-trained multi-gating mechanism; and (2) a set of fine-grained expert models coupled with the multi-gating mechanism for generating highly personalized explanations. The VAE component models latent factors in user-item interactions, while the GMM clusters users with similar behaviors. Each cluster corresponds to a gate in the multi-gating mechanism, routing user-item pairs to appropriate expert models. This architecture enables GaVaMoE to generate tailored explanations for specific user types and preferences, mitigating data sparsity by leveraging user similarities. Extensive experiments on three real-world datasets demonstrate that GaVaMoE significantly outperforms existing methods in explanation quality, personalization, and consistency. Notably, GaVaMoE exhibits robust performance in scenarios with sparse user-item interactions, maintaining high-quality explanations even for users with limited historical data.", "sections": [{"title": "Introduction", "content": "Recommendation systems have become ubiquitous in the digital age, offering personalized suggestions to help users navigate vast amounts of information [36]. As these systems evolve, the ability to explain recommendations has emerged as a critical factor in enhancing user trust, decision-making, and satisfaction [44, 45]. Clear and meaningful explanations not only aid users in making better choices but also increase their confidence in the recommendation process. Consequently, developing effective explainable recommendation systems has become a key research focus [9], driving the creation of more user-centric and trustworthy AI-driven experiences.\nRecent advancements [6, 35, 37] in large language models have opened new avenues for generating human-like explanations in recommendation systems, leading to the development of LLM-based ER systems [2, 10, 23, 27, 42]. Recent works such as PEPLER [23], LLM2ER [42], and XRec [27] have demonstrated the potential of LLMs in generating contextually rich and coherent explanations. PEPLER [23] pioneered this field by utilizing GPT-2 [29] and user-item IDs as prompts, demonstrating the potential of transfer learning in recommendation systems. LLM2ER [42] built upon this foundation by introducing a personalized prompt module, addressing the limitations of solely relying on user-item IDs. XRec [27] further advanced the field by incorporating user and item profiles and integrating collaborative filtering signals, bridging the gap between conventional recommendation techniques and LLM-based approaches.\nDespite their promising potential, current LLM-based ER systems face several critical challenges that limit their effectiveness. First, these systems struggle to adequately model user-item collaborative preferences, particularly in capturing the complex, non-linear relationships that exist between users and items. Second, the generated explanations frequently lack sufficient personalization, failing to reflect the nuanced preferences and behaviors of individual users. This results in generic recommendations that may not resonate with users' specific interests or needs. Third, LLM-based ER approaches perform poorly when confronted with sparse user-item interactions, a common scenario in real-world recommendation systems. This sparsity problem significantly hampers the ability of these models to generate accurate and meaningful explanations,\nTo address these challenges, we propose GaVaMoE, a novel Gaussian-Variational Gated Mixture of Experts framework for explainable recommendation. GaVaMoE introduces two key components that work together to improve personalization and effectively mitigate data sparsity. The first component, a rating reconstruction module, employs Variational Autoencoder (VAE) [17] in conjunction with a Gaussian Mixture Model (GMM) [16] to capture deep user-item collaborative preferences. This module maps user-item pairs into a latent space and clusters users with similar behaviors, uncovering underlying patterns even in sparse data scenarios. Building upon these learned representations and user clusters, the second component implements a multi-gated mixture of experts. A dynamic multi-gating mechanism, informed by the GMM clustering, routes user-item pairs to the appropriate fine-grained experts, ensuring highly personalized and contextually relevant explanations. As illustrated in Figure 1, GaVaMoE first processes user-item interactions through VAE encoding and GMM clustering, then uses the multi-gating mechanism to activate the most suitable experts for explanation generation. This architecture enables GaVaMoE to produce more personalized and contextually relevant explanations compared to previous LLM-based ER systems, which typically use LLMs with generic prompts.\nGaVaMoE offers significant advantages in three key areas: (1) Enhanced Collaborative Preference Modeling: The VAE explicitly models latent factors influencing user-item interactions, allowing GaVaMoE to capture complex, non-linear relationships and encode user-item collaborative preferences directly into the latent space. (2) Improved Personalization: The GMM clustering identifies distinct user groups based on their rating behaviors, enabling more nuanced user representation. The multi-gating mechanism ensures that explanations are tailored to specific user types and preferences, with each gate specializing in routing user-item pairs to suitable experts. (3) Effective Handling of Data Sparsity: By employing GMM for clustering user-item interactions and utilizing multiple expert models, the system can leverage similarities among users to generate meaningful explanations, even for those with limited interaction history.\nOur main contributions can be summarized as follows:\n\u2022 We introduce GaVaMoE, an novel framework that integrates a VAE with GMM (VAE-GMM) for rating reconstruction and a Multi-gating Mixture of Experts for explanation generation. This design allows for more accurate modeling of user-item collaborative preferences and generates highly personalized, contextually relevant explanations.\n\u2022 We develop a dynamic multi-gating mechanism that efficiently routes user-item pairs to expert models based on clustered user behaviors. This mechanism enhances the system's ability to handle sparse data and generate tailored explanations for diverse user groups, ensuring that even users with limited interaction histories receive meaningful, high-quality recommendations and explanations.\n\u2022 We conduct extensive experiments on three real-world datasets, demonstrating that GaVaMoE significantly outperforms previous methods across multiple metrics, including explanation quality, personalization, and consistency, and effectively addressing data sparsity challenges."}, {"title": "Related Works", "content": "Explainable Recommendation System. Explainable recom-mendation provides explanations that clarify why certain items are recommended, thereby enhancing the transparency and persuasiveness of the recommendation systems [36, 45]. Explainable recommendations can be presented in various format, such as pre-defined templates [19, 33, 46], reasoning rules [3, 32]. However, these methods are expensive to maintain and fail to produce diverse, personalized explanations, resulting in poor generalization. Related works of Explainable recommendation based on item features [11, 39], knowledge graph paths [1, 8, 40], and ranked text [20, 21] also similarly face the problem of low generalization and poor personalization. To address these challenges, more and more explainable recommendation systems based on natural language processing techniques have been studied. These works focus on using generative models to directly obtain personalized explanations. NRT [24] simultaneously performs accurate score prediction while generating high-quality summarized prompts by integrating user and item latent factors. Co-Attentive Multi-Task Learning (CAML ) [4] integrates a multi-task learning mechanism and adopts the joint attention proposed in [34]. PETER[22] employs a small, unpre-trained Transformer, connecting user and item IDs with generated text through a designed context prediction task for personalized text generation.\nRecently, research on LLM-based ER systems has gained significant attention. ReXPlug is an end-to-end explainable recommendation framework that generates high-quality personalized natural language reviews for users by plugging in and utilizing a plug-and-play language model. PEPLER [23] utilizes a pretrained language model GPT2 [29] to generate explainable recommendations by incorporating user and item ID vectors into prompts. LLM2ER [42] utilizes a personalized prompt learning module to match user preference and fine-tunes the model with reinforcement learning using two innovative explainability quality reward models to generate"}, {"title": "Method", "content": "In this section, we present GaVaMoE, a novel explainable recommendation system based on a Mixture of Experts model. We begin by providing a detailed definition of the explainable recommendation task (Section 3.1). Then, we introduce our proposed framework, illustrated in Figure 2, which consists of two main components: VAE-GMM for Rating Reconstruction (Section 3.2), and Multi-gating Mixture of Experts (Section 3.3). Finally, we detail the two-stage training process of our framework (Section 3.4), demonstrating how these components work in concert to produce personalized and contextually relevant explanations."}, {"title": "Task Formulation", "content": "The explainable recommendation task involves generating personalized item recommendations along with human-readable explanations. Formally, given a user-item pair $y \\in Y$, which consists of a user ID $u \\in U$ and an item ID $i \\in I$, we consider the rating $r_{u,i} \\in \\mathbb{R}_{>0}$ as an indicator of user $u$'s positive attitude towards item $i$. Each item $i$ is associated with a set of features $f_{u,i} \\in F$, which describe its characteristics (e.g., \"thrilling\" or \"comedy\" for a movie). These features play a crucial role in generating explainable text, as"}, {"title": "VAE-GMM for Rating Reconstruction", "content": "To effectively capture deep collaborative preferences and cluster users with similar behaviors, we propose a Variational Autoencoder (VAE) integrated with a Gaussian Mixture Model (GMM). This component serves as the foundation for modeling complex user-item collaborative preferences and acts as a routing strategy for our multi-gating mechanism, addressing the challenge of data sparsity."}, {"title": "Rating Reconstruction with Variational Autoencoder", "content": "We employ a VAE to learn compact representations of user-item interactions. Given a user-item pair (u, i) where u \u2208 U and i \u2208 I, the encoder E of the VAE predicts the mean \u00b5 and log-variance $log(\\sigma)^2$ of the latent representation:\n$[\\mu, log(\\sigma)^2] = E(u, i)$ (1)\nTo enable backpropagation during training, we utilize the reparameterization trick [25, 31], which transforms the random sampling process into a differentiable operation:\n$z = \\mu + \\epsilon\\sigma, \\epsilon \\sim \\mathcal{N}(0, 1)$ (2)\nwhere \u03b5 is randomly sampled from a standard normal distribution. The decoder D then reconstructs the rating from the latent z:\n$\\hat{r}_{u,i} = D(z)$ (3)\nThis reconstruction process allows the model to learn a compact representation of user-item interactions, effectively modeling complex collaborative preferences."}, {"title": "User Clustering with Gaussian Mixture Model", "content": "To cluster users with similar collaborative preferences, we extend the above VAE by incorporating a Gaussian Mixture Model (GMM). Following the approach in [16], we assume that user-item pair embeddings follow a mixed Gaussian distribution, which allows us to cluster users with similar collaborative preferences. We define a Gaussian mixture distribution $P = GMM(\\pi, \\mu, (\\bar{\\sigma})^2)$, where \u03c0 represents the prior distribution, and \u00b5 and $(\\bar{\\sigma})^2$ represent the mean and variance of the Gaussian mixture distribution, respectively.\nAssuming K clusters, the process of sampling and clustering from the latent space can be represented as:\n$p(x, z, c) = p(x|z)p(z|c)p(c)$ (4)\nwhere x represents the observed sample, z is the embedding of the user-item pair (u, i), and c is the cluster assignment. The probabilities are defined as follows:\n$p(c) = Cat(cr)$ (5)\n$p(z|c) = \\mathcal{N}(z|\\mu_c, (\\sigma_c)^2I)$ (6)\n$p(x|z) = Ber(x|\\mu_x)$ (7)\nwhere Cat(\u03c0) is a categorical distribution parameterized by \u03c0, and $Ber(x|\\mu_x)$ denotes a multivariate Bernoulli distribution for the output of decoder D."}, {"title": "Multi-gating Mixture of Experts", "content": "Building upon the VAE-GMM component, we introduce a novel multi-gating mixture of experts architecture to generate explanations. This architecture combines a dynamic routing mechanism with fine-grained experts to enhance personalization and efficiency. Our approach extends the traditional Mixture of Experts (MoE) concept by introducing a multi-gating mechanism informed by user clustering and a fine-grained expert strategy."}, {"title": "Multi-gating Mechanism for Expert Selection", "content": "Our multi-gating mechanism leverages the clustering information obtained from the VAE-GMM process (Section 3.2) to route user-item pairs to the most appropriate experts. For a given input sample represented by its latent embedding z, we compute the probability of it belonging to each cluster c using the following equation:\n$\\gamma_c = \\frac{\\pi_c \\cdot \\mathcal{N}(z|\\mu_c, (\\sigma_c)^2)}{\\sum_{c'} \\pi_{c'} \\cdot \\mathcal{N}(z|\\mu_{c'}, (\\bar{\\sigma}_{c'})^2)}$ (8)\nThis probability calculation allows us to identify the most likely cluster for each input sample. Our design incorporates a one-to-one correspondence between clusters and gates, where each cluster"}, {"title": "Fine-grained Mixture of Experts", "content": "To address issues of knowledge hybridity and knowledge redundancy [5], we modify the original structure by dividing the fully connected network layers into smaller, more specialized units. Specifically, we reduce the intermediate hidden dimensions of the fully connected layers to 1/r of their original size, effectively splitting each expert Feed-Forward Network (FFN) into r smaller experts. Assuming the original number of experts is N, the number of experts is now rN after reduction. This fine-grained expert strategy allows the model to achieve increased specialization without additional computational cost.\nGiven an input x, after determining the corresponding gate $\\mathcal{G}_{\\bar{c}}$ through the multi-gating mechanism, we proceed to select the most"}, {"title": "Two-stage Training Objective", "content": "To effectively train the GaVaMoE model, we employ a two-stage training process. This approach allows us to first capture deep collaborative preferences and then leverage this information for personalized explanation generation. The two stages are as follows:"}, {"title": "Stage 1: Rating Reconstruction Training", "content": "The first stage focuses on training the VAE-GMM by rating reconstruction. Importantly, the VAE-GMM serves as a key component for the multi-gating mechanism. Our goal here is to capture nuanced user-item collaborative preferences and create user clusters. We optimize the Evidence Lower Bound (ELBO) as our objective function:\n$\\mathcal{L}_{ELBO} (x, \\beta) = \\mathbb{E}_{q(z, c|x)} [log p(x|z)] \u2013 \\beta\\cdot KL (q(z, c|x)||p(z, c))$ (12)\nThis function balances two key aspects: the reconstruction of user-item interactions and the organization of these interactions into distinct clusters. The first term encourages accurate reconstruction, while the second term, controlled by the hyperparameter \u03b2, ensures that our latent representations are well-structured and informative."}, {"title": "Stage 2: Explanation Generation Training", "content": "With our collaborative preferences captured, the second stage focuses on training the Multi-gating Mixture of Experts to generate personalized explanations. We leverage the user clusters and latent representations learned in the first stage. Our objective function for this stage combines rating prediction accuracy with explanation quality:\n$\\mathcal{L}_{total} = \\alpha \\mathcal{L}_{ELBO} + (1 \u2212 \\alpha) \\cdot \\mathcal{L}_{explanation}$ (13)\nHere, \u03b1 balances the importance of accurate rating predictions $\\mathcal{L}_{ELBO}$ with the quality of generated explanations $\\mathcal{L}_{explanation}$. The $\\mathcal{L}_{explanation}$ is the negative log-likelihood of generating the correct explanation.\nThis two-stage approach allows GaVaMoE to excel in both collaborative filtering and personalized explanation generation. By first building a VAE-GMM in understanding user-item interactions, and then leveraging this understanding for tailored explanations, we create a model capable of providing highly personalized and contextually relevant recommendations and explanations."}, {"title": "Experiment", "content": "To comprehensively evaluate GaVaMoE, we utilized three diverse real-world datasets: TripAdvisor\u00b2, Amazon (Movies & TV)\u00b3, and Yelp\u2074. TripAdvisor represents the travel and hospitality sector with hotel and attraction reviews, Amazon focuses on the entertainment domain with movie and TV show ratings, while Yelp encompasses a broad spectrum of local businesses including restaurants, services, and retail. As shown in Table 1, these datasets exhibit varying scales and potential sparsity levels, with Yelp being the largest and potentially most sparse, followed by Amazon and TripAdvisor. This diversity in data characteristics enables us to evaluate GaVaMoE's adaptability and robustness in handling different user behavior patterns and data sparsity challenges. For our experiments, each dataset was randomly split into training, validation, and test sets at a ratio of 8:1:1."}, {"title": "Implementation Detail", "content": "GaVaMoE employs a two-layer Transformer encoder and a two-layer MLP for the decoder in the VAE. The latent space size is 128, with user and item embeddings of 768. We set batch size to 4096, learning rate to 1e-5, \u03b2 to 0.1 and 30 training epochs. For explanation generation training, we set the batch size to 1, learning tate to 3e-5.The training process utilizes AdamW with a gradient accumulation of 8 and a clipping norm of 0.3. GaVaMoE uses LLaMA3.1-8B [6] with 32 GaVaMoE blocks, replacing the FFN with MoE (hidden size 1280, 12 experts, 2 activated per pass). The number of gates matches user clusters, and explanation generation training lasts 3 for epochs."}, {"title": "Compared Methods", "content": "We compare our model's performance against the following competiable baselines in explainable recommendation:\n\u2022 NETE[19]: presents a gated fusion recurrent unit that leverages neural templates to generate high-quality, explainable text for recommendation systems.\n\u2022 PETER [22]: utilizes Transformer to integrate user and item IDs into generated explanations.\n\u2022 PEPLER [23]: adopts a pre-trained GPT-2 model with prompt tuning for explanation generation.\n\u2022 PEVAE [2]: extends hierarchical VAEs to address data sparsity in LLM-based recommendation systems, aligning with our focus on sparse interaction scenarios.\n\u2022 XRec [27]: generates explanatory texts by integrating high-order collaborative signals encoded by graph neural networks and the text generation capabilities of LLMs.\nThese baselines were carefully selected to represent the progression of explainable recommendation systems, from template-based approaches (NETE) to advanced LLM-based models (XRec)."}, {"title": "Evaluation Metrics", "content": "To comprehensively evaluate GaVaMoE's performance, we employ metrics assessing three key dimensions: explanation quality, personalization, and consistency. For explanation quality, we use BLEU [28] (BLEU-1 and BLEU-4) and ROUGE [26] (ROUGE-1 and ROUGE-L) to assess fluency, grammatical correctness, and content overlap. For personalization, we employ Distinct-1 and Distinct-2, evaluating unigram and bigram diversity in generated text. For consistency, we utilize BERTScore [43], capturing deeper semantic similarities using contextual embeddings. While BLEU and ROUGE are widely used, they have limitations in capturing true semantic information, relying primarily on n-gram overlap. BERTScore addresses this limitation with a more sophisticated approach to evaluating semantic consistency. This diverse set of metrics allows for a comprehensive evaluation of GaVaMoE's performance across various aspects of explanation generation, assessing not only linguistic quality but also personalization and semantic consistency."}, {"title": "Results and Analysis", "content": "Main Results. Table 2 presents the performance comparison of various explanation generation methods across TripAdvisor, Yelp, and Amazon (Movie & TV) datasets. GaVaMoE consistently outperforms all baselines, including the state-of-the-art XRec model, across all metrics and datasets. Specifically, GaVaMoE achieves significant improvements over XRec: 6.39% on TripAdvisor, 4.46% on Yelp, and 2.57% on Amazon on average. In terms of text quality, GaVaMoE achieves the highest BLEU-4 and ROUGE-L scores across all datasets. For instance, on the Amazon dataset, GaVaMoE's BLEU-4 score of 1.75% surpasses XRec's 1.73%. The model's superior performance in these metrics indicates its ability to generate high-quality, fluent explanations. GaVaMoE also demonstrates enhanced consistency, as measured by BERTScore. On the Amazon dataset, GaVaMoE achieves a BERTScore-F of 0.412, compared to XRec's 0.401. Notably, on the sparser Yelp dataset, GaVaMoE's BERTScore-F"}, {"title": "Ablation Study", "content": "To further evaluate the efficacy of GaVaMoE's components, we conducted a comprehensive ablation study across three diverse datasets. We compared the following variants:\n\u2022 GaVaMoE[LLaMA3.1]: Our full model, incorporating both the multi-gating mechanism and the enhanced MoE architecture.\n\u2022 GaVaMoE[LLaMA3.1] w/o Multi-gating: A variant that retains the MoE architecture but removes the multi-gating mechanism.\n\u2022 GaVaMoE[LLaMA3.1] w/o Fine-grained experts: A variant that retains the multi-gating mechanism but removes the fine-grained experts.\n\u2022 Base [LLaMA3.1]: A baseline version using only the LLAMA 3.1 language model, without the multi-gating mechanism and MoE architecture.\n\u2022 GaVaMoE [GPT2]: Uses GPT2 as the base language model while retaining our multi-gating and MoE components.\nFigure 3 presents our ablation study results, comparing BLEU-4 and BERTScore metrics across three datasets. Key findings include: (1) Effectiveness of Multi-gating Mechanism and Fine-grained Experts: GaVaMoE[LLaMA3.1] consistently outperformed its variants without multi-gating or fine-grained experts. For instance,"}, {"title": "Analysis of Multi-gating Mechanism", "content": "To evaluate the impact of our multi-gating mechanism, we varied the number of gates from 2 to 5 across three datasets. Table 3 shows distinct optimal gate configurations for each dataset: 3 gates for TripAdvisor, 2 gates for Amazon, and 3 gates for Yelp.\nThese variations in optimal gate numbers reflect the intricate relationship between dataset characteristics and model performance. With fewer gates, user-item collaborative preferences within each cluster tend to be more consistent, enabling better pattern learning and generalization. However, as the number of gates increases, data dispersion may introduce noise, potentially reducing the model's generalization ability. The effectiveness of the multi-gating mechanism also depends on balanced data distribution across gates. An imbalance, such as one gate receiving significantly fewer items, can lead to incomplete training of both the gate and its associated experts, impacting overall performance.\nOur analysis underscores the importance of tuning the number of gates based on dataset-specific characteristics. The optimal configuration balances capturing diverse user-item preferences with maintaining sufficient data consistency within clusters."}, {"title": "Analysis of Data Sparsity", "content": "To evaluate GaVaMoE's robustness against data sparsity, we conducted a comprehensive evaluation"}, {"title": "Human Evaluation", "content": "To validate GaVaMoE's effectiveness in real-world scenarios, we conducted a human evaluation study using 2,000 randomly sampled entries from the Yelp dataset. We compared GaVaMoE against XRec and PEPLER, employing three professionals to assess the generated explanations based on personalization (P), text quality (Q), and user satisfaction (U). Each criterion was scored on a 1-to-5 scale, with details provided in Appendix B. We computed a composite Human-Score using a weighted formula:\n$Human{\\text-Score} = \\lambda_pP_{score} + \\lambda_qQ_{score} + \\lambda_uU_{score}$ (14)\nWhere $\\lambda_p = 0.4$, $\\lambda_q$, and $\\lambda_u = 0.3$. The scores P, Q, and U represent the metrics for personalization, text quality, and user satisfaction, respectively."}, {"title": "Case Study", "content": "To further evaluate GaVaMoE's effectiveness in generating personalized and relevant explanations, we conducted a detailed case study comparing our model's performance with baseline methods under different user interaction scenarios. Table 5 presents a comparative analysis of explanations generated by GaVaMoE and baseline methods under two distinct scenarios: limited and sufficient user-item interactions. GaVaMoE demonstrates superior performance across both cases, effectively addressing the challenges of data sparsity and personalization. In the limited interaction scenario (Case 1), GaVaMoE captures all key item features (\"undoubtedly,\" \"stunning,\" \"movie\"), showcasing its robustness in sparse data conditions. The model's explanation closely mirrors the ground truth while adding relevant details about \"visuals and performances,\" providing a more comprehensive insight. Similarly, in the sufficient interaction case (Case 2), GaVaMoE accurately captures the essence of J.K. Rowling's magical world and the fantasy genre, demonstrating its ability to leverage richer user history. Across both scenarios, GaVaMoE maintains appropriate sentiment and context, avoiding the introduction of irrelevant or inaccurate information a pitfall observed in some baseline methods like XRec. In contrast, PETER and PEPLER consistently produce generic statements lacking specific descriptors, highlighting GaVaMoE's superior feature integration and contextual understanding. These observations underscore GaVaMoE's effectiveness in generating highly personalized, contextually relevant, and informative explanations, regardless of the extent of user interaction history. The model's performance aligns with our initial goals of enhancing explainable recommendations through improved collaborative preference modeling and personalization, particularly in scenarios with sparse user-item interactions."}, {"title": "Conclusion", "content": "In this paper, we introduced GaVaMoE, a novel Gaussian-Variational Gated Mixture of Experts framework for explainable recommendation systems. GaVaMoE addresses critical challenges in existing LLM-based ER systems through two key innovations: (1) a rating reconstruction module employing VAE with GMM for capturing complex user-item collaborative preferences, and (2) a multi-gating mechanism coupled with expert models for generating personalized explanations. Our approach enhances collaborative preference modeling, improves personalization, and effectively handles data sparsity. Extensive experiments on three real-world datasets demonstrate that GaVaMoE significantly outperforms state-of-the-art methods across multiple metrics, including explanation quality, personalization, and consistency. Notably, GaVaMoE exhibits robust performance in sparse data scenarios, maintaining high-quality explanations even for users with limited historical data."}, {"title": "ELBO in GaVaMoE", "content": "In GaVaMoE, our objective is to maximize the likelihood of user-item pairs, equivalent to maximizing log p(x). Adopting Jensen's inequality, we derive the variational evidence lower bound (ELBO) as follows:\n$\\mathcal{L}_{ELBO}(x) = \\mathbb{E}_{q(z,c/x)} log \\frac{p(c, z, x)}{q(z, c|x)} = \\mathbb{E}_{q(z,c|x)} [log p(x|z) + log p(z|c) + log p(c)] \u2013\\mathbb{E}_{q(z,c|x)} [log q(z|x) + log q(c|x)] = \\mathbb{E}_{q(z,c|x)} log p(x|z) + log \\frac{p(z, c)}{q(z, cx)}$ (15)\nThe first term represents the reconstruction loss, allowing the model to discover deep level user-item interactions. The second term calculates the Kullback-Leibler divergence between the mixed Gaussian prior distribution q(z|x) and the variational posterior p(z, c). To learn more disentangled representations, according to B-VAE[12] approach, we added a hyperparameter \u03b2 to the KL divergence term, rewriting the formula as follows:\n$\\mathcal{L}_{ELBO} (x, \\beta) = \\mathbb{E}_{q(z,c|x)} [logp(x|z)] \u2013 \\beta \\cdot KL (q(z, c|x)||p(z,c))$ (16)\nwhere \u03b2 balances the reconstruction loss and the KL regularization term. The KL regularization term is derived as:\n$KL(q(z, cx)||p(z, c)) = \\frac{1}{2} \\sum_{c=1}^{K} Y_{i,c} \\sum_{d=1}^{D} (1 + log \\frac{\\sigma_{i,d}^{2}}{\\bar{\\sigma}_{c,d}} \\frac{\\bar{\\sigma}_{c,d}^{2}}{\\sigma_{i,d}^{2}} +  \\frac{(\u00b5_{i,d} - \\bar{\u00b5}_{c,d})^2}{\\sigma_{c,d}^{2}} - log(\\frac{\\pi_{c}}{Yi,c}) + \\sum_{c=1}^{K}  \\sum_{d=1}^{D} log(\\bar{\\sigma}_{c,d})^{2} + \\frac{1}{2}$ (17)\nIn this formulation, K represents the number of clusters, D is the dimensionality of the latent space, yi,c is the probability that the i-th sample belongs to cluster c, and re is the prior probability of cluster c. The parameters ui,d and oid are the mean and standard deviation of the i-th sample in the d-th dimension, while \u016bc, d and \u014dc, d are the mean and standard deviation of cluster c in the d-th dimension.\nBy optimizing this ELBO, GaVaMoE can effectively learn a structured latent space that captures both user-item interactions and user clustering information, which is crucial for the subsequent multi-gating mechanism and personalized explanation generation."}, {"title": "Human scoring Criteria", "content": "This guide provides detailed instructions for evaluating generated explanations on a 1-to-5 scale across three dimensions: Personalization, Text Quality, and User Satisfaction:\n\u2022 Personalization (P): Consider the user's past interactions, stated preferences, and behavioral patterns when assessing alignment. Look for specific mentions of user-relevant features or experiences.\n\u2022 Text Quality (Q): Evaluate the explanation's grammatical correctness, logical flow, and appropriate use of language. Consider whether the text would be easily understood by the average user.\n\u2022 User Satisfaction (U): Assess whether the explanation would likely motivate the user to engage further with the recommended item or the platform. Consider factors such as informativeness, persuasiveness, and appeal."}]}