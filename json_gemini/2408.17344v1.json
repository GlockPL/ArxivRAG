{"title": "rerankers: A Lightweight Python Library to Unify Ranking Methods", "authors": ["Benjamin Clavi\u00e9"], "abstract": "This paper presents rerankers, a Python library which provides an easy-to-use interface to the most commonly used re-ranking approaches. Re-ranking is an integral component of many retrieval pipelines; however, there exist numerous approaches to it, relying on different implementation methods. rerankers unifies these methods into a single user-friendly interface, allowing practitioners and researchers alike to explore different methods while only changing a single line of Python code. Moreover, rerankers ensures that its implementations are done with the fewest dependencies possible, and re-uses the original implementation whenever possible, guaranteeing that our simplified interface results in no performance degradation compared to more complex ones. The full source code and list of supported models are updated regularly and available at https://github.com/answerdotai/rerankers.", "sections": [{"title": "Introduction", "content": "A common approach to information retrieval is the use of a two-stage retrieval pipelines: a small set of candidate documents is first retrieved by a computationally efficient retrieval method, to then be re-ranked by a stronger, generally neural network-based, model [10]. This method is used in order to mitigate latency constraints: while models frequently used for re-ranking are particularly powerful, as they're aware of both documents and queries at encoding time [12], this efficiency comes at a prohibitive computational cost [11]. As a result, in order to use them on any larger scale document sets, it is necessary to use more lightweight method, such as BM25 [17] or DPR [25], which do not require such expensive calculation, to create a smaller set of document. This smaller set can then be processed in a short amount of time by the re-ranking model.\nThis approach has been widely adopted in Information Retrieval systems, consistently yielding stronger results than relying on a single retriever without re-ranking [16,9]. Moreover, such models are very powerful, as their output scores can be used for knowledge distillation [5], where first-stage retrieval models are trained to emulate the scores generated by re-ranking models. Knowledge Distillation from re-ranking model scores has been consistently shown to allow the training of stronger first-stage retrievers [2,7,16,18].\nOver time, there has been an increasing number of neural re-ranking methods. Most early neural re-ranking models were cross-encoders, [12], framing"}, {"title": "Contribution", "content": "These methods all come with different trade-offs, and may be more or less well-suited to different usecases. However, the multiplication of approach makes keeping up with existing research and evaluating new methods is often needlessly difficult. In some cases, adopting a different method might require substantial code changes, due to the wide variety of dependencies and input/output formats across methods. This issue also makes it more difficult for newer approaches to reach large adoption, as their exploration represents a cost which can be prohibitive.\nTo alleviate these issues, we introduce rerankers, a simple, light-weight Python library which seeks to unify re-ranking methods. rerankers relies on three core principles: \u2460 It must provide an easy way to load, use, and swap inout various re-ranking methods, \u2461 It should be as non-intrusive as possible, without requiring the user to greatly modify their environment or codebase to adopt and 3 It must not result in a ranking performance degradation when compared to existing implementations. The library is compatible with all modern Python versions and provides a simple, user-friendly interface to most common re-ranking approaches. In doing so, it also comes with utility to accommodate various use-cases, such as retrieving only the top-k candidates for a given query, or only outputting scores to use for knowledge distillation."}, {"title": "System Overview", "content": "Everything within the library is organised around a central class named Reranker. It is used as the main interface to load models, no matter the underlying implementation or requirements. Its interface is demonstrated in Listing 1.1.\nThe Reranker class has a single exposed method, rank, which takes in a query and a set of document and returns a RankedResults object, presented in Section 2.2, containing the re-ranked documents.\nrerankers is fully integrated into the huggingface transformers ecosystem [24], and can load any model compatible with it directly from the HuggingFace hub, as well as models stored locally."}, {"title": "Handling RankedResults", "content": "Similarly to how Reranker serves as a single interface to various models, RankedResults objects are a centralised way to represent the outputs of various models, themselves containing Result objects.\nThis class comes with various helper methods, presented in Listing 1.2, which makes result easy to retrieve for common use cases. Both RankedResults and Result are fully transparent, allowing you to iterate through RankedResults and retrieve any of their attributes."}, {"title": "Extensibility and Modularity", "content": "Modularity rerankers is designed specifically with ease of extensibility in mind. All approaches are independently-implemented and have individually-defined sets of dependencies, which users are free to install or not based on their needs. Informative error messages are shown when a user attempts to load a model type that is not supported by their currently installed dependencies.\nExtensibility As a result, adding a new method simply requires making its inputs and outputs compatible with the rerankers-defined format, as well as a simple modification of the main RERANKER class to specify a default model. This approach to modularity has allowed us to support all the approaches with minimal engineering efforts. We fully encourage researchers to integrate their novel methods into the library and will provide support for those seeking to do so."}, {"title": "Comparison with Existing Tools", "content": "As of the making of this work, no library providing a consistent API to access common reranking methods existed, as such, rerankers has no direct equivalent.\nFor most individual methods integrated within rerankers\u00b9, an existing implementation or way to access the online API already existed. rerankers is not a direct competitor to any of these implementations. In fact, our library often re-uses parts of the original authors' code or acts as a wrapper around their library, if a mature one with moderate dependencies exists [15,14,21]."}, {"title": "Performance", "content": "In order to ensure performance parity with existing implementations, we conduct top-1000 reranking evaluations on three commonly used datasets\u00b2.\nFor most models implemented in the library, over 5 runs, we achieve parity with either the existing implementation code and reported results from the literature. A notable exception is RankGPT [20], where our results over all runs were noticeably different from the paper's reported results 3. We observed similar behaviour when using the author's own code, and believe that this is likely due to the difficulty of reproducing experiments with unreleased, API-only models such as the GPT family [6]."}, {"title": "Conclusion", "content": "In this work, we introduced rerankers, a lightweight python library to support the use of various re-ranking methods in various retrieval usecases. rerankers provides a simple, unified interface to using nearly all commonly encountered approaches to re-ranking in a single, lightweight package, without any detriment to performance. We hope that re-rankers will support both practitioners and researchers in the future, by considerably lowering the barrier to entry formerly present for less well-known approaches and providing easy extensibility to implement upcoming re-ranking methods within a familiar interface.\nIn the future, we are hoping for the rerankers library to also support fine-tuning, to simplify training and comparing in-domain models within a familiar interface.\nFinally, it is worth noting that rerankers has already contributed to scholarly work, by producing the model scores used in distillation [2], or becoming the authors' way of releasing their new Portuguese re-ranking models [13]."}]}