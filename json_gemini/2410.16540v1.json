{"title": "A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and Error-Aware Demonstration", "authors": ["Yingqian Cui", "Pengfei He", "Xianfeng Tang", "Qi He", "Chen Luo", "Jiliang Tang", "Yue Xing"], "abstract": "Few-shot Chain-of-Thought (CoT) prompting has demonstrated strong performance in improving the reasoning capabilities of large language models (LLMs). While theoretical investigations have been conducted to understand CoT, the underlying transformer used in these studies isolates the CoT reasoning process into separated in-context learning steps (Stepwise ICL). In this work, we theoretically show that, compared to Stepwise ICL, the transformer gains better error correction ability and more accurate predictions if the reasoning from earlier steps (Coherent CoT) is integrated. Given that this coherent reasoning changes the behavior of the transformer, we further investigate the sensitivity of the transformer with Coherent CoT when the demonstration examples are corrupted at the inference stage. Our theoretical results indicate that the transformer is more sensitive to errors in intermediate reasoning steps than the final outcome. Building upon this observation, we propose an improvement on CoT by incorporating both correct and incorrect reasoning paths in the demonstration. Our experiments validate the effectiveness of the proposed approach.", "sections": [{"title": "1 Introduction", "content": "Few-shot Chain-of-Thought (CoT) prompting has emerged as a highly effective technique to enhance the reasoning capabilities of large language models (LLMs) [27]. Given a few examples of step-by-step reasoning at the inference stage, the model can generalize the reasoning process to new tasks, demonstrating significant improvement in solving complex problems, particularly in mathematical reasoning and common-sense inference [27, 12, 18].\nAside from these empirical successes, recent efforts have provided valuable theoretical insights into CoT. In the literature, two main approaches are typically used to analyze the ability of transformers in CoT tasks (and more broadly, ICL). In the first approach, to show the existence of transformers that are capable of performing CoT, people explicitly construct a transformer by specifying its parameters and assigning each component to perform a specific task. The second approach defines a specific data format to organize different reasoning steps and then trains a transformer model to learn a step-by-step prediction process. Subsequent analysis focuses on the properties of this trained model. Using these approaches, previous studies are able to explain the expressiveness power of the transformer in CoT tasks and understand how different components of the model contribute to the multi-step reasoning [16, 17, 11, 23].\nHowever, a key limitation of these analyses is that they often overlook the connections among multiple reasoning steps. In the approach where a transformer is directly constructed to perform CoT, predictions at each reasoning step are based solely on the result from the previous step. Similarly, when training a transformer from scratch on CoT tasks, to simplify the analysis, a \"filtering\" process is used to retain only the information from the most recent step [16]. In summary, when constructing/training the transformer from either way mentioned above, the prediction process for a training sample (a CoT prompt) involves multiple reasoning steps, and each step only focuses on the immediate task at hand without incorporating earlier reasoning steps. We refer to this prediction process as \"Stepwise"}, {"title": "ICL", "content": "(formally defined in Definition 3.1).\nHowever, in real-world scenarios, e.g., next token prediction, the LLM takes into account all the previous tokens in the context window, rather than treating each step in isolation (referred to as \"Coherent CoT\", defined in Definition 3.2). Observing this discrepancy between Stepwise ICL and Coherent CoT, we extend the theoretical framework in [31] and study the properties of a model trained using Coherent CoT and compare it with the model trained with Stepwise ICL. Based on our result, using Coherent CoT instead of Stepwise ICL during the training stage provides better prediction performance. Intuitively, when treating CoT as a holistic process where later steps integrate the reasoning from earlier steps the transformer will consider the potential errors in previous predictions and adjust subsequent predictions accordingly, which provides a form of self-correction and enhances the prediction performance.\nWhile Coherent CoT potentially outperforms Stepwise ICL as elaborated in our first contribution, it requires training the model on the entire reasoning chain, which alters the model's optimal parameters and changes the behavior of the model. This change introduces uncertainty about which steps in the reasoning chain are most sensitive to errors, highlighting the necessity for sensitivity analysis. This leads to our second contribution, which focuses on the sensitivity of the trained Coherent CoT model to perturbations in the demonstration examples at the inference stage. To quantify the sensitivity, we examine how the Coherent CoT model reacts with random perturbations at different reasoning steps. We reveal that, during inference, the Coherent CoT model is more sensitive to noise in the intermediate reasoning steps of the demonstration examples than to inaccuracies in their final outcomes.\nInspired by the sensitivity analysis, our third contribution is to propose a prompt composing method to enhance CoT performance at the inference stage. Based on our sensitivity result, CoT is more sensitive to possible incorrectness at the intermediate reasoning steps, thus improving the accuracy of these steps can better enhance the overall CoT performance. We propose to incorporate both correct and incorrect reasoning paths in the demonstrations to enhance the accuracy of the intermediate reasoning steps. Experiments are conducted to validate the effectiveness of the proposed method."}, {"title": "2 Related Works", "content": "Empirical Insights in CoT. Chain-of-Thought (CoT) prompting, introduced by [27], has proven to be highly effective in enhancing the reasoning capabilities of LLMs by breaking complex tasks into step-by-step processes. This technique has been expanded into various variants and extensions, including Zero-shot CoT [15], Self-Consistency [26], Auto-CoT [32], Tree-of-Thought [30], and Graph-of-Thought [4], to further improve efficiency or model performance.\nBuilding upon the success of CoT, recent studies seek to deepen the understanding behind CoT by empirically exploring its mechanisms. For example, [28] finds that CoT enables the model to maintain the attention robust and stable on the semantically relevant tokens in the prompt. [19] defines the key components of a prompt as symbols, patterns, and text, and investigates how each of these elements and their interaction contribute to the superior performance of CoT. Additionally, [25] validates that the relevance of the demonstration example to the query and the correct ordering of reasoning steps are key factors for the effectiveness of CoT, and [14] examines the relationship between CoT's effectiveness and reasoning step length. Based on [14], simpler tasks require fewer reasoning steps, while more complex tasks benefit greatly from more detailed inference sequences.\nTheories in ICL and CoT. The mechanism of ICL has been extensively studied in the theoretical literature. For example, studies such as [24, 1, 2, 31, 13] have explained how ICL learns to perform linear regression using gradient descent. The work by [8] extends these analyses by investigating how transformers can apply ICL to non-linear functions, while [3] focuses on generalized linear models, ridge regression, and LASSO. Additionally, [10, 7] explains why multi-head attention is preferred than single-head attention when performing ICL.\nBesides ICL, recent research also starts to establish theoretical frameworks to understand CoT. For example, Li et al. [16] offers a specific framework that views CoT as a series of ICL components, each addressing a smaller subproblem. [11] constructs a transformer that solves arithmetic and linear equation tasks using CoT. [20] offers a Bayesian perspective on how intermediate steps improve reasoning. Additionally, [17] provides a TC\u00b0 upper bound for the expressiveness of constant-precision transformer, and [23] introduces a two-level hierarchical graphical model to explain how LLMs generate sequences of reasoning steps."}, {"title": "3 Theoretical Results", "content": "We extend the existing theory of ICL in transformers, e.g., [31], to a CoT scenario to conduct our theoretical investigation. Briefly speaking, there are two key observations: (1) Compared to Stepwise ICL, using"}, {"title": "ICL at the training stage results in a model with better inference performance. (2) When noises exist in the demonstration examples at the inference stage, the model with Coherent CoT is more sensitive to perturbations in the reasoning steps than the inaccuracies in the final response.", "content": "In the following, we introduce some setups in Section 3.1 for data generation and the transformer architecture, then present the theoretical results for (1) and (2) respectively in Section 3.2 and 3.3."}, {"title": "3.1 Model Setup", "content": "Data generation process. Since demonstration examples are needed in the prompt in CoT, we define how the examples as well as the query data are generated as follows.\nAssumption 3.1 (Data Generation Process) In each prompt, the examples $(x_i, z_i, y_i)$ and the query data $(x_q, z_q, y_q)$ are i.i.d sampled from the following \"two-layer\" noisy regression:\n\u2022 The independent variable $x \\in \\mathbb{R}^d \\in N(0, I_d)$.\n\u2022 The intermediate response $z = \\beta^T x$.\n\u2022 The final response $y = z + \\epsilon, \\epsilon \\in N(0, \\sigma^2)$.\nFor each prompt, all the examples and the query data share the same $\\beta$. In different prompts, $\\beta$ is i.i.d. uniformly sampled from unit sphere, i.e., $|\\beta|_2 = 1$.\nAssumption 3.1 is primarily based on [16] with some modifications about the relation between y and z. Following [16], we assume x follows a Gaussian distribution to simplify the analysis. In terms of the final response y, we assume $y = \\beta^T x + e$, a linear mapping of x with added noise. To improve the prediction of y, an intermediate response $z = \\beta^T x$ is introduced. As a noise-free representation of the relationship between x and y, introducing z helps to mitigate the impact of noise e and guide a more accurate prediction of y. An additional discussion on potential relaxations of the assumptions can be found in Remark 3.1.\nCoherent CoT and Stepwise ICL. We define \"Coherent CoT\" and \"Stepwise ICL\" as follows:\nDefinition 3.1 (Stepwise ICL) There are two separate ICL steps involved in the Stepwise ICL process, and each is performed by a different model. First, the intermediate response $z_q$ is predicted using the model $f_1$ (to be defined later) as $z_q = f_1(E_{ICL}^{(1)})_{d+1, D+1}$, where the input prompt is formatted as\n$E_{ICL}^{(1)} = \\begin{pmatrix} x_1 & x_2 & \\dots & x_D & x_q \\\\ z_1 & z_2 & \\dots & z_D & 0 \\end{pmatrix} \\in \\mathbb{R}^{(d+1) \\times (D+1)}$.\nObtaining $z_q$, the input prompt of the second step is\n$E_{ICL}^{(2)} = \\begin{pmatrix} z_1 & z_2 & \\dots & z_D & z_q \\\\ y_1 & y_2 & \\dots & y_D & 0 \\end{pmatrix} \\in \\mathbb{R}^{2 \\times (D+1)}$.\nThe final prediction is obtained using the model $f_2$ as $\\hat{y_q} = f_2(E_{ICL}^{(2)})_{d+1, D+1}$.\nDefinition 3.2 (Coherent CoT) An Coherent CoT process involves two steps. In the first step, the input prompt is formatted as:\n$E_{CoT}^{(1)} = \\begin{pmatrix} x_1 & x_2 & \\dots & x_D & x_q \\\\ z_1 & z_2 & \\dots & z_D & 0 \\\\ y_1 & y_2 & \\dots & y_D & 0 \\end{pmatrix} \\in \\mathbb{R}^{(d+2) \\times (D+1)}$\nThe intermediate response $z_q$ is predicted as $\\hat{z_q} = f_1(E_{CoT}^{(1)})_{d+1, D+1}$. After $z_q$ is obtained, it is plugged into the input prompt, forming:\n$E_{CoT}^{(2)} = \\begin{pmatrix} x_1 & x_2 & \\dots & x_D & x_q \\\\ z_1 & z_2 & \\dots & z_D & \\hat{z_q} \\\\ y_1 & y_2 & \\dots & y_D & 0 \\end{pmatrix} \\in \\mathbb{R}^{(d+2) \\times (D+1)}$.\nThe final prediction of the query input is made by $\\hat{y_q} = f(E_{CoT}^{(2)})_{d+2, D+1}$ using the same transformer.\nFor both Stepwise ICL and Coherent CoT, we consider that the input prompt follows a structured data format. While some existing literature attempts to relax the assumption on the restrictive structured data format condition, e.g., [29], it is observed that the performance of ICL with structured data serves as a lower bound for the best possible performance.\nThe main difference between Coherent CoT and Stepwise ICL is that, in the second step of Stepwise ICL, the input prompt only includes the intermediate and final responses, $z_i$s and $y_i$s, of the in-context examples. In contrast, Coherent CoT plugged the predicted $z_q$ back into the original input prompt to form the input prompt for the second step and retains the initial inputs $x_i$s. This allows Coherent CoT to leverage both the intermediate reasoning and the original input when making the final prediction.\nModel architecture. We follow [31] and use transformers with one single-head linear attention layer as the model, which is defined as\n$f(E) = W_{out} W_V E \\cdot ((W_K E)^T W_Q E)$,\nwhere E denotes the input prompt, $W^Q, W^K, W^V \\in \\mathbb{R}^{m \\times m}$ refer to the key, query and value matrix of the attention node and $W^{out} \\in \\mathbb{R}^{m \\times m}$ refers to a fully-connected layer conducted to the output of the attention node. For $f_1(\\cdot)$ in Stepwise ICL, $m = d + 1$; for $f_2(\\cdot), m = 2$. For CoT, $m = d + 2$."}, {"title": "Training objectives.", "content": "For both Stepwise ICL and Coherent CoT, to train a model, we minimize the following loss function:\n$\\mathcal{L}(\\Theta) = E_{\\{x\\},x_q} (y_q \u2013 \\hat{y_q})^2$,\nwhich represents the mean squared error (MSE) between the predicted response $\\hat{y_q}$ and the true response $y_q$ of the query example. Here, $\\Theta$ denotes the set of parameters in the transformer."}, {"title": "3.2 Coherent CoT vs Stepwise ICL", "content": "This section presents the main results of comparing Coherent CoT and Stepwise ICL. To simplify the derivation, we assume a specific format for the optimal attention parameters as follows:\nAssumption 3.2 We consider the following specific formulations of the matrices $W^K, W^Q, W^{out}$ and $W^V$ for Stepwise ICL and Coherent CoT.\n\u2022 For Stepwise ICL, the specific format for the parameters of $f_1(\\cdot)$ is: $(W^K)^T W^Q = \\begin{bmatrix} u_x I_d \\\\ 0 \\end{bmatrix}$ and $(W^{out}W^V)_{d+1,:} = [u_z, 0]$, we assume $(W^K)^T W^Q = \\begin{bmatrix} u_x I_d \\\\ 0 \\end{bmatrix}$ and $(W^{out}W^V)_{2,:} = (0,...,0,1/u_x)$. For $f_2(\\cdot)$, we assume $(W^{out}W^V)_{2,:} = (0,1/u_z)$.\n\u2022 For Coherent CoT, we assume\n$(W^K)^T W^Q = \\begin{bmatrix} u_x I_d & 0 \\\\ 0 & u_z \\\\ 0 & v_y \\end{bmatrix}$ and $(W^{out}W^V)_{d+1,:} = (0,..., 0,1/v_x, 0)$ , $(W^{out}W^V)_{d+2,:} = (0, . . ., 0, 1/v_y)$.\nAssumption 3.2 is built upon the observations in [31, 10]. Based on these studies, in order to optimize the task of x \u2192 z in ICL, the corresponding off-diagonal elements of $(W^K)^T W^Q$ and the first d elements in the $(W^{out} W^V)_{d+1,:}$ vector should be all zero when x follows N(0, Id). Since each step of the Coherent CoT process utilizes the same transformer model, we consider the same format for the z \u2192 y process, and assume all off-diagonal elements of $(W^K)^T W^Q$ are zero and $(W^{out}W^V)_{d+1,:} = (0,..., 0, v_y)$. With Assumption 3.2, we can rewrite $\\mathcal{L}(\\Theta)$ to $\\mathcal{L}(u_x, u_z)$ for Stepwise ICL or $\\mathcal{L}(v_x, v_y, v_z)$ for Coherent CoT to highlight these parameters.\nGiven Assumption 3.2, we figure out the optimal solution of Stepwise ICL in Theorem 3.1.\nTheorem 3.1 Under Assumption 3.1 and 3.2, the optimal expected loss of Stepwise ICL is achieved when"}, {"title": "ux \u2260 0 and uz \u2260 0 are satisfied. The corresponding optimal loss is", "content": "$\\mathcal{L}(u_x^*, u_z^*) = \\sigma^2 + \\frac{\\sigma^2}{D} + \\frac{7+d}{D} + \\mathcal{O}(\\frac{1}{D^2})$.\nThe proof of Theorem 3.1 can be found in Appendix A.1. In short, we separate the MSE loss of the prediction into multiple terms and taking the expectation of each term considering D \u2192 \u221e.\nRemark 3.1 In Assumption 3.1, we assume that $x \\sim N(0,I_d)$. The exact Gaussian distribution is used to derive the closed-form expression of the loss. If we relax it to other distributions, there will be no closed-form expression of the loss to exactly compare Coherent CoT and Stepwise ICL. Nonetheless, the high-level intuition on why Coherent CoT outperforms Stepwise ICL still holds: Stepwise ICL misses information on the previous reasoning steps, thus the prediction is worse than Coherent COT.\nTo compare with the optimal results of Stepwise ICL, we derive the optimal solution for Coherent CoT and present the results in Theorem 3.2.\nTheorem 3.2 Under Assumption 3.1 and 3.2, the optimal parameters $v_x, v_y$ and $v_z$ that minimize the Coherent CoT's loss satisfying $v_y = (x + z)$. The corresponding loss for Coherent CoT becomes\n$\\mathcal{L}(v_x, v_y, v_z) = \\sigma^2 + \\frac{d \\sigma^2}{D} + \\frac{1+d}{D} + \\frac{4 \\frac{u_x u_z}{v_y} + \\frac{6 v_z^2}{v_y}}{D} + \\frac{(\\frac{v_x + v_z}{v_y})^2(\\frac{2 \\sigma^2}{v_x v_z})}{D} + \\mathcal{O}(\\frac{1}{D^2})$.\nTo minimize the above loss, it is require that $v_y = \\frac{4 v_x u_z}{(d-1)^2 \\sigma^2 + 2 v_x^2}$ = $\\frac{(d-1)^2 + 2 v_x}{(d-1) \\sigma^2 - 2 u_z}$ (where $v_z, v_x, v_y \\ne 0$). Then the optimal expected loss of Coherent CoT is\n$\\mathcal{L}(v_x^*, v_y^*, v_z^*) = \\sigma^2 + \\frac{d \\sigma^2}{D} + \\frac{1+d}{D} + \\frac{(\\frac{v_x + v_z}{v_y})^2(\\frac{d (d \u2212 1)^2 + 2\\sigma^2}{(d \u2212 1)^2 + 2})}{D}$.\nThe proof of Theorem 3.2 is similar to that of Theorem 3.1, whose details are shown in Appendix A.2.\nBuilding on the above results, Proposition 3.1 below directly compares the expected loss of Coherent CoT and Stepwise ICL.\nProposition 3.1 Given that $d\\ge 2$, the expected loss of Coherent CoT equals to the expected loss of Stepwise ICL when $v_x = 0$ and $v_z = v_y$. In addition, the minimal expected loss of Coherent CoT is smaller than the one of Stepwise ICL."}, {"title": "The proof of Proposition 3.1 is in Appendix A.3.", "content": "Proposition 3.1 indicates that, regardless of the values of d and \u03c3, the optimal expected loss of Coherent CoT is smaller than that of Stepwise ICL. To explain this, when vx = 0 and vz = vy, Coherent CoT is equivalent to Stepwise ICL, and this condition also aligns with the optimal solution of Stepwise ICL. On the other hand, since (Vx = 0,Uz = Vy) is not the optimal solution of Coherent CoT, Coherent CoT can achieve a smaller loss given its corresponding optimal solution.\nInsights from the theory. To further investigate how the xis and zis contribute to the final prediction of \u0177g in CoT, we present the following proposition:\nProposition 3.2 For any \u03c3 and d, uz and vy always share the same sign for optimal Coherent CoT. In addition, the ratio $\\frac{u_z}{v_y}$ for the optimal Coherent CoT is consistently smaller 1. Meanwhile, when vx, uz and vy are set such that Coherent CoT reduces to Stepwise ICL, the ratio $\\frac{u_z}{v_y}$ satisfies $\\frac{u_z}{v_y} = 1$.\nBased on Theorem 3.2 and Proposition 3.2, the prediction of the final response can be formulated as\n$\\hat{y_i} = \\frac{1}{D v_y} \\sum Y_i (u_x^T x_i x_q + u_z z_i z_q)$.\nThe above formulation indicates how xis and yis impact the final prediction of \u0177q. According to Proposition 3.2, in Coherent CoT, the initial inputs xis always positively contribute to the final prediction \u0177q. Additionally, the final prediction \u0177q in Coherent CoT relies less on the zis and 2q compared to Stepwise ICL, indicating a reduced dependency on these intermediate values when using the optimal Coherent CoT.\nBased on Proposition 3.2, the consequence of leveraging Coherent CoT to train a model is that, when there is an error in the prediction of zq, Coherent CoT's reduced reliance on 2q, along with its attention to xq, ensures that the error in the prediction of zq has a smaller impact on the final prediction. Moreover, since the final prediction of yq incorporates both xis and zis, when 2 is inaccurate, the model can better adjust its prediction using the xis values. This inherently provides a form of self-correction by leveraging the combined information from both xis and zis values.\nNotably, the theorems in Section 3.2 and the later Section 3.3 focus on different stages of the model's application. The theorem in Section 3.2 highlights that compared with Stepwise ICL, using Coherent CoT during the training stage provides a better inference performance of the model. The theorem in Section 3.3, which examines the sensitivity of Coherent CoT to random noise, focuses on the inference stage."}, {"title": "3.3 Sensitivity against Random Perturbation", "content": "While Section 3.2 investigates how Coherent CoT gains a better prediction performance compared to Stepwise ICL by considering all the previous steps during the reasoning process, this holistic process may also lead to a different sensitivity to potential errors/corruptions in each reasoning step. Therefore, in Section 3.3, with a model trained with Coherent CoT, we investigate the model's sensitivity and quantify the impact of random perturbations at different reasoning steps $y_i$, $x_i$, and $z_i$ at the inference stage. The results are summarized in the following theorems respectively.\nTheorem 3.3 Under Assumption 3.1 and 3.2, when there is random perturbation $\\delta_i \\sim N(0, \\sigma^2)$ added to $y_i$, we denote the loss for Coherent CoT as $\\mathcal{L}'_y(v_x, v_y, v_z)$. When $v_x, v_y$ and $v_z$ takes the optimal values, we have $\\mathcal{L}'_y(0) - \\mathcal{L}(v_x^*, v_y^*, v_z^*) = \\mathcal{O}(1/D)$."}, {"title": "Theorem 3.4.", "content": "Under Assumption 3.1 and 3.2, when there is a random perturbation $\\delta_i \\sim N(0, \\sigma^2)$ added to $x_i$ in inference, the expected loss for CoT becomes\n$\\mathcal{L}'_x(v_x, v_y, v_z) = \\frac{1+d}{D} + \\frac{4 \\frac{u_x u_z}{v_y} + \\frac{6 v_z^2}{v_y}}{D} + \\frac{d \\sigma^2}{D} + \\mathcal{O}( \\frac{d^2 \\sigma^2}{D} + \\sigma^2 + \\mathcal{O}(\\frac{1}{D})$.\nThe theorem below is for the corruptions in $z_i$s.\nTheorem 3.5 Under Assumption 3.1 and 3.2, when there is a random perturbation $\\delta_i \\sim N(0, \\sigma^2)$ added to $z_i$ in inference, the expected loss for CoT becomes\n$\\mathcal{L}'_z(v_x, v_y, v_z) = \\frac{1+d}{D} + \\frac{4 \\frac{u_x u_z}{v_y} + \\frac{6 v_z^2}{v_y}}{D} + \\frac{d \\sigma^2}{D} + \\mathcal{O}(\\frac{d^2 \\sigma^2}{D} + \\sigma^2 + \\mathcal{O}(\\frac{1}{D})$.\nThe proof of Theorem 3.4 and 3.5 are similar to that of Theorem 3.3, whose details are shown in Appendix A.5 and A.6.\nGiven the results in Theorem 3.4 and 3.5, the following proposition provides a clearer comparison:\nProposition 3.3 When $v_x, v_y$ and $u_z$ takes the optimal values, we have (1) $L'_x(v_x^*, v_y^*, u_z^*) > L'_y(v_x^*, v_y^*, u_z^*)$ and $L'_z(v_x^*, v_y^*, u_z^*) > L'_y(v_x^*, v_y^*, u_z^*)$ for any values of $d$ and $\\sigma$; (2) $L'_x(v_x^*, v_y^*, u_z^*) > L'_z(v_x^*, v_y^*, u_z^*)$ for $\\sigma^2 \\in [0, a) \\cup (b, \\infty)$ and $L'_x(v_x^*, v_y^*, u_z^*) < L'_z(v_x^*, v_y^*, u_z^*)$ for $\\sigma^2 \\in (a, b)$, where b > a are the positive roots of $f(0) = (d\u2212 1)^2 0^3 + (3d \u2013 7) (d \u2013 1) 0^2 \u2013 (4d + 8d^2) 0+12 = 0$.\nThe proof of Proposition 3.3 is shown in Appendix A.7.\nInsights from the theory. The results in Proposition 3.3 indicate that when a certain level of random noise is introduced to CoT, whether adding noise to the xis or the zis leads to a higher expected loss depends on the scale of the variance \u03c3\u00b2. Compared the"}, {"title": "results with that of adding noise to yi, adding noise to Xi or zi leads to a greater influence on the performance of CoT. An important insight from this result is that, compared to the noise in the final label (mislabeling), errors occurring in the reasoning steps of CoT have a greater influence on the accuracy of the final prediction. From this perspective, CoT is more sensitive to mistakes made during the reasoning process than to the noise in the final response. As a result, when asking the model to account for potential errors during reasoning, it is crucial to pay more attention to error in the intermediate reasoning steps rather than label noise.", "content": "Simulation Results. The simulation illustrating the sensitivity of CoT to random perturbations at different reasoning steps is shown in Figure 22. The training setup is similar to the experiment in Figure 1, with the variance of the noise, \u03c32, set to 1. From the figure, we observe that when random perturbations are added to the yis, the loss remains close to the case where there is no noise. However, when noise is introduced to the xis or zis, the loss increases significantly. This result is consistent with our theoretical findings, confirming that CoT is more sensitive to perturbations in the earlier reasoning steps than label noise."}, {"title": "4 Improving CoT through Error-Aware Demonstrations", "content": "The analysis in Section 3.3 reveals that, at the inference stage, CoT is more sensitive to errors in the intermediate reasoning steps of the demonstration than to errors in the final outcome. Inspired by this, we conjecture that it is beneficial for the model to learn"}, {"title": "4.1 Methodology", "content": "We use a date understanding problem as an example to explain the proposed method in detail, and present the demonstration format in Figure 3. In standard CoT prompting, few-shot examples with correct reasoning paths are provided in the prompt demonstration. In contrast, in the proposed demonstration format, after presenting the question, we first provide a potentially incorrect reasoning path, clearly labeled as a wrong solution. We then provide a detailed explanation of why this reasoning is incorrect, pointing out specific missteps or logical errors. Both the incorrect reasoning path and the analysis of why it is flawed are created manually. After analyzing the incorrect path, we provide a step-by-step correct reasoning process that leads to the correct answer.\nBy incorporating both correct and incorrect reasoning paths in the demonstrations, the proposed method teaches the model not only the correct reasoning path but also how to identify and handle potential reasoning errors. This error-aware approach helps improve the model's ability to adjust predictions and enhances its overall performance in reasoning tasks."}, {"title": "4.2 Experiments", "content": "In this section, we evaluate our proposed method with various LLMs on multiple benchmarks."}, {"title": "4.2.1 Experimental setup", "content": "Language Models. Our experiments involve four LLMs: GPT-3.5-Turbo [6], GPT-40-mini [6]3, Gemini Pro [22]4 and DeepSeek 67B [5] 5. For generation, we set the temperature to 0 to ensure deterministic outputs.\nBenchmarks. We use five datasets from two benchmarks for the experiments: the BBH benchmark [21] and the GSM8k benchmark [9]6. The BBH benchmark focuses on reasoning tasks, and we select Disambiguation QA, Tracking Shuffled Objects (7 objects), Date Understanding, and Penguins in a Table from this benchmark. Each of these datasets contains 250 examples. Besides the BBH benchmark, we also use"}, {"title": "4.3 Main Results", "content": "In Table 1, we demonstrate the performance of various LLMs across different datasets when using standard CoT prompting (w/o IR) and our proposed method, which incorporates Incorrect Reasoning (IR) in the demonstrations (w/ IR). From Table 1, we can see that in most cases, adding handcrafted incorrect reasoning paths to CoT demonstrations improves the models' performance. In some settings, our proposed method brings a significant improvement exceeding 5%. For example, in the Tracking Shuffled Objects dataset, Gemini Pro shows a 6.60% improvement (from 58.20% to 64.80%), and in Penguins in a Table, DeepSeek 67B demonstrates an increase of 6.17% (from 73.97% to 80.14%). These results highlight the positive impact of exposing models to incorrect reasoning paths."}, {"title": "4.4 Additional Experiments", "content": "Necessity of including error explanation. We present an ablation study to evaluate our proposed"}, {"title": "5 Conclusion", "content": "This paper provides a theoretical analysis of Coherent CoT by investigating its advantages over Stepwise ICL, showing that treating CoT as a holistic process leads to improved error correction and prediction accuracy."}, {"title": "In addition, we examine Coherent CoT's sensitivity to errors in different reasoning steps of the demonstration examples during the inference stage. We observe that Coherent CoT is more sensitive to the error in the intermediate reasoning process than the inaccuracies in the final response. Inspired by this result, we propose to incorporate both correct and incorrect reasoning paths in demonstrations to improve the accuracy of the intermediate steps to enhance CoT performance.", "content": "Experimental results validate the effectiveness of this approach."}, {"title": "A Proofs", "content": ""}, {"title": "A.1 Proof of Theorem 3.1:", "content": "The proof begins by decomposing the mean square loss into distinct components involving attention scores. Each term's expectation is then calculated separately, are combined to represent the total expected loss.\nRecalling that for"}]}