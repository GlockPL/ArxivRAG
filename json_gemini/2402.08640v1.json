{"title": "Forecasting high-impact research topics via machine learning on evolving knowledge graphs", "authors": ["Xuemei Gu", "Mario Krenn"], "abstract": "The exponential growth in scientific publications poses a severe challenge for human researchers. It forces attention to more narrow sub-fields, which makes it challenging to discover new impactful research ideas and collaborations outside one's own field. While there are ways to predict a scientific paper's future citation counts, they need the research to be finished and the paper written, usually assessing impact long after the idea was conceived. Here we show how to predict the impact of onsets of ideas that have never been published by researchers. For that, we developed a large evolving knowledge graph built from more than 21 million scientific papers. It combines a semantic network created from the content of the papers and an impact network created from the historic citations of papers. Using machine learning, we can predict the dynamic of the evolving network into the future with high accuracy, and thereby the impact of new research directions. We envision that the ability to predict the impact of new ideas will be a crucial component of future artificial muses that can inspire new impactful and interesting scientific ideas.", "sections": [{"title": "Introduction", "content": "As we see an explosion in the number of scientific articles [1-4], it becomes increasingly challenging for researchers to find new impactful research directions beyond their own expertise. Consequently, researchers might have to focus on narrow subdisciplines. A tool that can read and intelligently act upon scientific literature could be an enormous aid to individual scientists in choosing their next new and high-impact research project, which on a global scale - could significantly accelerate science itself.\nThese days, a natural first choice for an AI-assistant would be powerful large-language-models (LLM) such as GPT-4 [5], Gemini [6] or LLaMA-2 [7] or custom-made models [8]. However, these models often struggle in scientific reasoning, and it remains unclear how they can suggest new scientific ideas or evaluate their impact in a reliable way in the near term.\nAn alternative and complementary approach is to build scientific semantic knowledge graphs. Here, the nodes represent scientific concepts and the edges are formed when two concepts are researched together in a scientific paper [2]. While this approach extracts only small amounts of information from each paper, surprisingly non-trivial conclusions can still be drawn if the underlying dataset of papers is large. An early example of this is a work in biochemistry [9]. The authors use their semantic network, where nodes represent biomolecules, to find new potentially more efficient exploration strategies for the bio-chemistry community on a global scale. In these semantic networks, an edge between two concepts indicates that researchers have jointly investigated these research concepts. The edges are drawn from papers, thus they are created at a specific time when the paper was published. In this way, one creates an evolving semantic network that captures what researchers have investigated in the past. With such an evolving network, one can ask how the network might evolve in the future. In the scientific context, this question can be reformulated into what scientists will research in the future. For example, if two nodes do not share an edge, one can ask whether they will share an edge in the next three years - or, alternatively, whether scientists will investigate these two concepts jointly within three years. This question, denoted as link-prediction problem in network theory [10], has been successfully demonstrated with high prediction quality for semantic networks in quantum theory [11] and artificial intelligence [4].\nNovelty plays an essential role in scientific ideas, but being novel doesn't automatically mean that an idea will have a high impact. Impact in the scientific community is often approximated (for lack of better metrics [12, 13]) by citations [1, 2, 14, 15], including exciting results that find interpretable mathematical models to describe citation evolution [16-19]. Beside concrete mathematical modelling, impact of scientific papers has also been predicted using advanced statistical and machine-learning methods that use meta-data such as including authors and affiliations [20], the content and the references of the paper [21, 22]. Techniques employed for the predictions of individual paper impact using a combination of characteristics include support-vector machines [23], regression [24-26], dense [27] or graph neural networks [28].\nThe prediction of a paper's impact however is only possible after the research is completed, and long after its underlying idea is created. A true scientific assistent or muse however should contribute at the earliest stage of the scientific cycle, when the idea for the next impactful research project is born. One solution is the prediction at the concept level. Specifically, we can ask the question Which scientific concepts, that have never been investigated jointly, will lead to the most impactful research?."}, {"title": "The Knowledge Graph", "content": "Creating a list of scientific concepts \u2013 At the heart of our knowledge graph are scientific concepts, as depicted in Fig. 1. We chose not to rely on existing concept lists, such as the APS or computer science ontology [40], for several reasons. Firstly, our goal is to ultimately cover"}, {"title": "Results", "content": "Forecasting impact of newly created concept connections - With an evolving knowledge graph from the past, we can formulate the prediction of impact for new concept pairs as a supervised learning task, as illustrated in Fig. 4. For a vertex pair that has not had any connection in the year 2016, we predict whether 3 years later this vertex pair accumulated more than a certain number of citations. Using the historical knowledge graph, we possess an ideal supervision signal for our binary classification task. During the training phase, we selected pairs of vertices that were not connected and calculated 141 features for each pair. These features include 41 network features, divided into 20 node features (such as the number of neighbors and PageRank [43] over the past three years) and 21 edge features (including cosine, geometric, and Simpson similarities [44]). Additionally, we incorporated 100 impact features: 58 of these are node citation features, covering total citations and the count of papers mentioning the concept within the last three years. The other 42 features are about vertex pairs and include measures such as the citation ratio between them. The network feature is inspired by the winner of the Science4Cast competition [11, 45], and the citation features are developed empirically and could potentially be improved by careful feature importance analysis. Our neural network is a fully connected feed-forward network with four hidden layers of 600 neurons each. The exploration of more advanced architectures might improve the prediction qualities further. The neural network has to predict whether the unconnected vertex pair in 2019 will have more than $IR$ citations ($IR$ is impact range).\nWe perform the training from $IR = 1$ to $IR = 200$. We quantify the quality with the area under curve (AUC) of the receiver operating characteristic curve (ROC) [46]. The AUC gives a measure of classification quality and stands for the probability that a randomly chosen true example is ranked higher than a randomly chosen false example. A random classifier has $AUC = 0.5$. We measure the AUC for a test set (which contains unconnected pairs not in the training set) for a prediction from 2016 to 2019, and for an evaluation dataset, with 10 million random data from 2019 to 2022 (while keeping the training data of the neural network from the year 2016 to 2019). The evaluation dataset shows how well the neural network performs on future, never-seen datasets. This is motivated by our goal that ultimately we want to train a neural network with all available data (let's say, until the end of 2023) and predict what happens until the future in 2026. In Fig. 5(a), we find that the AUC scores for both the test set and the evaluation set are beyond 0.8, in most of the cases beyond 0.9, for different values of the impact range IR. We can conclude that the neural network can forecast a high impact of previously\nnever-investigated concept connections to a high degree. In Fig. 5(b), we sort the concept pairs of the evaluation dataset with the neural network (IR = 100), and plot their true citation counts. We further divide the 10 million evaluation dataset into 20 equal parts and plot their average citation count (represented by green bars) for each 5% segment. This clearly demonstrates very good predictions at the individual concept pair level.\nForecasting genuine impact beyond link prediction - Next, we perform an even more challenging, genuine impact prediction task that goes beyond link prediction (i.e., predicting which concept pairs will be investigated in the future by a scientific paper). Concretely, in this second task training data is conditioned on unconnected vertex pairs from 2016 which are actually connected in 2019. The neural network only gets information from 2016 and has to predict whether the newly generated concept pair will be highly impactful or not. For that, our classification task asks whether the newly generated edge will receive between 0-5 citations or above 100 (Fig. 5(c)). We see that the AUC is beyond 0.7 (for the test set) and beyond 0.67 for the evaluation set, clearly indicating that the neural network can predict impact properties that go beyond the simpler link-prediction task.\nExtracting highly impactful cliques of concepts - In what follows, we show one way how our results can be applied to inspire new directions that potentially human researchers would not have thought about. So far, we have limited our predictions to pairs of concepts. However, incorporating a larger number of concepts could more directly indicate a research direction. Directly predicting high-impact concept triples or quadruples is either highly computationally expensive or necessitates en-"}, {"title": "Outlook", "content": "We show how to forecast the impact of future research topics. Although we view this as a significant step towards developing truly useful AI-driven assistants, achieving this goal requires numerous further advancements. Firstly, developing methods to extract more complex information from each paper will be crucial, for instance by employing hyper-graph structures that carry more information from each paper [47, 48], which has already been demonstrated to lead to exciting results in other domains[2, 49, 50]. This might also allow for the forecast of new concepts [51, 52] and their impact. Secondly, it will be interesting to approximate impact with metrics that go beyond citations - which is a crucial topic in computational sociology and the study of the science of science [1, 2]. Additionally, introducing metrics of surprise, as discussed in [53, 54], could serve as a complementary metric to citation prediction for ranking suggestions. Finally, while the suggestion of impactful new ideas might be a crucial component of future AI assistants, it will be crucial to study its relation to the scientific interest of working researchers."}]}