{"title": "NDAI", "authors": ["Matt Stephenson", "Andrew Miller", "Xyn Sun", "Bhargav Annem", "Rohan Parikh"], "abstract": "We study a fundamental challenge in the economics of innovation: an inventor must reveal details of a new idea to secure compensation or funding, yet such disclosure risks expropriation. We present a model in which a seller (inventor) and buyer (investor) bargain over an information good under the threat of hold-up. In the classical setting, the seller withholds disclosure to avoid misappropriation, leading to inefficiency. We show that trusted execution environments (TEEs) combined with AI agents can mitigate and even fully eliminate this hold-up problem. By delegating the disclosure and payment decisions to tamper-proof programs, the seller can safely reveal the invention without risking expropriation, achieving full disclosure and an efficient ex post transfer. Moreover, even if the invention's value exceeds a threshold that TEEs can fully secure, partial disclosure still improves outcomes compared to no disclosure. Recognizing that real AI agents are imperfect, we model \"agent errors\" in payments or disclosures and demonstrate that budget caps and acceptance thresholds suffice to preserve most of the efficiency gains.\nOur results imply that cryptographic or hardware-based solutions can function as an \"ironclad NDA,\" substantially mitigating the fundamental disclosure-appropriation paradox first identified by Arrow (1962) and Nelson (1959). This has far-reaching policy implications for fostering R&D, technology transfer, and collaboration.", "sections": [{"title": "Introduction: The Disclosure Paradox", "content": "What if you discovered something beyond belief, but revealing it meant giving it away for free? That was the predicament of John Harrison, the humble English clockmaker who solved a riddle that had confounded luminaries like Galileo, Huygens, and Newton. His life's work-the Marine Chronometer was so revolutionary it was likened to finding \"the Fountain of Youth, the secret of perpetual motion, or the formula for transforming lead into gold\" [Sobel, 2005].\nUnfortunately for Harrison, the year was 1714, and he had no access to AI Agents or Trusted Execution Environments (\u201cTEE\u201ds). So when he unveiled his chronometer to claim his reward\u2014literally a king's ransom he became entangled in decades of struggle with bureaucrats who repeatedly moved the goalposts to prevent paying him his due. Now that he had revealed his invention, what incentive remained for these elites to pay this \"man of simple birth\" at all? And so they didn't. It took forty years and the personal intervention of a new king, George III-before an aged and exhausted Harrison finally secured his rightful reward [Bennett, 2003, Sobel, 2005].\nThis story reflects a well-established tension identified by Arrow [1971] and Nelson [1959], wherein an inventor must reveal information to capture its economic value but, by revealing it, risks losing the ability to appropriate it. This dilemma is fundamental to information goods, arising because disclosed knowledge cannot typically be undisclosed. John Harrison couldn't gain leverage on the bureaucrats by threatening to un-disclose his design. Likewise, Pythagoras could not reveal his theorem to someone and then say, \"Forget everything you just heard unless you pay me.\" Once the knowledge was out, it was out for good. But today in light of our sci-fi present, we can re-consider this disclosure problem and progress toward a solution."}, {"title": "1.1 Why Patents and NDAs Often Fail", "content": "John Harrison revealed valuable information, but were it not for the eventual intervention of a king, he may have regretted it. Inventors who anticipate Harrison-type difficulties and never reveal-or don't even develop their inventions in the first place- are preventing expropriation through withholding. But by withholding they sacrifice potential gains from trade, investment, collaboration, and so on.\nSuch strategic withholding of information is a form of ex ante \"enforcement\" that Arrow modeled. And beyond the theory, there are studies like Dushnitsky and Shaver [2009] which observes 1,600 start-up ventures seeking funding and finds that \"many relationships do not form because... the entrepreneur may be wary of disclosing an invention, fearing imitation.\"\nAn alternative is using legal protections such as NDAs, patents, or trade secret law. These are attempts at ex post enforcement- once an unauthorized use or disclosure is detected, the injured party must gather evidence, pursue litigation, and demonstrate harm to obtain damages or injunctive relief. But ex post enforcement is costly, uncertain, and highly imperfect, due to the very nature of intangible knowledge which makes monitoring and proof of misappropriation difficult. [Graham, 2005, Morgan, 2015, Contigiani and Hsu, 2019]. In principle, one must effectively monitor every possible use of the disclosed information.\nAnd then there is the matter of enforcement. Insufficient enforcement makes these legal protections less valuable. But aggressive enforcement creates the potential for harmful Type-I errors (\"false positives\"), where innocent parties are penalized. This is exemplified, for instance, in the chilling effect on innovation caused by patent trolls. [Cohen et al., 2019]\nBy contrast, our approach leverages ex interim enforcement via agentic bargaining within a secure Trusted Execution Environment (TEE). No external copies or usage can occur during negotiations, nor can they occur in the absence of mutual agreement. Thus disclosure is effectively 'conditional' on reaching agreement. This prevents any unauthorized use from arising in the first place, obviating ex post enforcement challenges. Because the TEE is relatively low-cost and eliminates the need for costly oversight or litigation, we avoid the intractable monitoring problem of needing to observe essentially every conceivable subsequent use of the disclosed information. Type I risks don't show up overtly in our setting, since there is no \"over enforcement.\" However, there is the possibility in our model of agent overpayment errors, which do analogize to Type-I risks. But in our setting these risks are local and don't induce the broad chilling effect on innovation than patent trolling does.\nAs a result, this the TEE approach may substitute or complement traditional legal instruments by shifting enforcement inside the technology rather than relying solely on ex post legal remedies or ex ante information withholding."}, {"title": "1.2 Background and Related Work", "content": "The incentive incompatibility of disclosure is a classic economic dilemma. And this incompatibility imposes serious costs: inventors cannot trust that their disclosures will remain protected, and so many potential breakthroughs may remain hidden or never be developed in the first place. And, since new innovations themselves are often spurred through recombining of ideas [Fleming, 2001], this effect can have long-lasting stifling implications.\nUnder incomplete contracts, parties must balance the need to disclose private information to realize gains from trade against the risk that disclosed information may be appropriated [Arrow, 1972]. This trade-off is especially stark for innovators or entrepreneurs, who often incur large fixed costs to develop a new product or idea but cannot attract funding without revealing it [Nelson, 1959].\nOur analysis builds on several literature streams. First, we extend work on information disclosure in contracting [Crawford and Sobel, 1982, Okuno-Fujiwara, 1991] by explicitly modeling disclosure as a continuous choice under uncertainty. Second, we connect to research on hold-up problems and incomplete contracts [Hart and Moore, 1988, Aghion and Howitt, 1992, Grossman and Hart, 1986, Bernheim and Whinston, 1987, Anton and Yao, 1994], showing how technological solutions like trusted execution environments can mitigate appropriation risks. AI agents in our treatment are not quite automata in a machine game, as in Rubinstein [1986] but could modeled as such. Our treatment of TEE-resident AI agents is closer to the principle agent setting of Aghion and Tirole [1997], where agents have some congruence parameter measuring how closely its objectives match the principal's.\nBy introducing cryptographic and hardware-based solutions, our framework departs from traditional reliance on legal instruments such as patents or NDAs, offering a technologically enforced approach to secure collaboration. This complements the partial disclosure focus in Anton and Yao [1994, 2002] by suggesting that if inventors can reliably limit expropriation through secure hardware, they may opt for more complete disclosure earlier in the R&D timeline, thereby accelerating cumulative innovation in the spirit of Scotchmer [1999].\nFinally, we also note that this problem mirrors the time-priority exploitation common in blockchain MEV [Daian et al., 2020], where e.g. order flow information necessary for market function enables front-running. This is a major inspiration for our solution as well as connecting this work to the literature on MEV and mechanism design in decentralized systems [Roughgarden, 2020, Capponi et al., 2023]."}, {"title": "Contributions.", "content": "We highlight our key contributions as follows:\n1.  Formalizing the disclosure-expropriation trade-off. We develop a simple game-theoretic model in which a seller (inventor) chooses how much to disclose to a buyer (investor) before a potential transaction, under the threat of expropriation. Absent any protective mechanism, full or partial disclosure is thwarted by hold-up.\n2.  Introducing a TEE-based mechanism to resolve hold-up. We show that delegating decisions to AI agents operating inside a trusted execution environment (TEE) can render disclosure incentive-compatible. Under sufficient security, full disclosure and investment can be achieved, raising total surplus and yielding Pareto improvements.\n3.  Modeling TEE security risk for high-value secrets. To address the concern that real-world TEES are not perfectly secure, we formalize the expected gain from malfeasance using threshold encryption and positive detection probabilities from the TEE. This yields a \"scope condition\" under which even high-value ideas can be partially or fully protected, bridging theory and practical adoption.\n4.  Extending the analysis to imperfect (\u201cnoisy\u201d) agents. We relax the assumption of perfectly congruent agents to allow for random errors in payments or disclosure. We show that a simple budget cap for the buyer's agent and a reject-option for the seller's agent can contain the risk of overpayments or underpayments, preserving most gains from trade even with high error rates.\n5.  Implications for policy and mechanism design. Our results illustrate how cryptographic or hardware-based safeguards can substitute for rather than merely supplement costly legal instruments like NDAs. This has broad ramifications for protecting intellectual property, incentivizing R&D, and promoting collaborative innovation across firms and industries."}, {"title": "1.3 Model Framework and Roadmap", "content": "We develop a model where two parties must choose disclosure levels before learning if gains from trade exist. Higher disclosure increases the probability of realizing potential gains but also raises appropriation risk. The model demonstrates how uncertainty about trade value interacts with expropriation risk to create undesirable equilibria.\nWe then propose a technological approach that reduces expropriation risk by leveraging secure environments rather than relying on contractual solutions alone. Specifically, we show how AI agents in trusted execution environments can improve efficiency by making disclosure conditional on agreement, at the cost of some potential uncertainty.\nRoadmap. The remainder of the paper is structured as follows. Section 2 introduces our baseline disclosure game under expropriation, highlighting why the seller must withhold information absent a protective mechanism. Section 3 then presents our trusted-execution-environment (TEE) setting, demonstrating how secure hardware and AI agents can restore efficient disclosure. Section 4 characterizes equilibrium behavior in this TEE-based setting, while Section 5 extends the analysis to consider realistic AI-agent errors. Finally, Section 6 discusses broader policy implications and concludes."}, {"title": "2 A Baseline Model of Innovation Disclosure", "content": "We develop a model of bargaining over a divisible information good (e.g. an invention). A seller has an information good that can realize higher value if outside investment is achieved. They may seek investment from a buyer who does not observe the good's value directly and must rely on disclosure by the seller to learn about its quality. However, any disclosure-whether partial or full-risks expropriation of the information by the buyer."}, {"title": "2.1 Setup and Payoffs", "content": "Types and disclosure. A seller $i$ has a divisible information good $w_i$, privately drawn from a commonly known $U \\sim [0, 1)$. We let $w_i$ stand here for both the value of the seller's information good and to denote the seller's type. The buyer does not observe $w$ directly, and thus relies on the seller to disclose some portion $\\tilde{w} < w$ to convey its quality. The buyer is unwilling to invest without disclosure. However, if full or partial details are revealed, the buyer can expropriate them by engaging in ex post renegotiation with the seller.\nOutside Options. If the seller discloses nothing ($\\tilde{w} = 0$), the buyer learns no information and thus receives their outside option which is normalized at 0. By retaining the invention, the seller obtains $\\alpha_0 w$, with $\\alpha_0 \\in (0,1]$. This discounted private value can be interpreted as the invention's residual value if the seller must develop or commercialize it without the buyer.\nPayoffs from trade vs. expropriation. If the buyer invests-paying price $P$ -we treat the joint surplus as $\\tilde{w}$, split via $P$ in favor of the seller. More precisely,\n\n$u_S(w; \\text{Invest}) = P + \\alpha_0(w - \\tilde{w}), \\quad u_B(w; \\text{Invest}) = \\tilde{w} - P$.\n\nAlternatively, if the buyer expropriates the disclosed portion $\\tilde{w}$ outright, the payoffs become\n\n$u_S(w; \\text{Expropriate}) = \\alpha_0(w - \\tilde{w}), \\quad u_B(w; \\text{Expropriate}) = \\tilde{w}$."}, {"title": "2.2 The Breakdown Under Hold-Up", "content": "It is straightforward to see that, once the seller discloses any $\\tilde{w} > 0$, the buyer can expropriate it without paying. Hence the seller discloses $\\tilde{w} = 0$, and the outcome is:\n\n$v_S(w) = \\alpha_0 w, \\quad v_B(w) = 0$.\n\nThis is the familiar hold-up problem: no sale, no investment, and the seller is left with only partial value $\\alpha_0 w$."}, {"title": "3 Building an Ironclad NDA: Trusted Execution and AI Agents", "content": ""}, {"title": "3.1 AI Delegation via Secure Hardware", "content": "We assume each player $i$ can delegate decisions to a program $A_i$, which we call an agent. Formally, each agent $A_i$ is a function\n\n$A_i: (x_i, m_{ji}, \\varepsilon_i) \\rightarrow a_i$,\n\nwhere\n\u2022 $x_i$ is player $i$'s private input (e.g. the seller's private $w$),\n\u2022 $m_{ji}$ represents messages or data received from other agents,\n\u2022 $\\varepsilon_i$ is a random variable capturing stochastic or approximate behavior by $A_i$,\n\u2022 and $a_i$ is the action chosen by agent $A_i$ on behalf of player $i$.\nEach agent $A_i$ aims to maximize player $i$'s payoff, subject to the noise or imprecision captured by $\\varepsilon_i$. The agents $A_1,..., A_n$ run inside a secure environment with cryptographic guarantees.\nSecure Execution Environment In practice, this secure environment may be implemented using trusted execution environments (TEEs). Real-world TEEs (e.g. Intel SGX) can run arbitrary code, permitting programs (agents) to process private data while enforcing secrecy. While in theory other cryptographic primitives may offer similar benefits (see Appendix A for a brief survey), TEEs offer a practical and sufficiently general solution. Thus we treat agents as \"TEE-resident\" programs.\nTEE Functionality. We combine the agents ${A_i}$ into a single secure TEE function $T$. This function collects private inputs $(x_1,...,x_n)$ from the $n$ players, mediates any necessary inter-agent messaging, and finally agent actions $(a_1,...,a_n)$. Thus:\n\n$T((x_1,...,x_n), \\varepsilon) = f(a_1,..., a_n)$,\n\nwhere $\\varepsilon = (\\varepsilon_1,..., \\varepsilon_n)$ captures the randomness or error terms associated with each agent's decision process. Inside $T$, each agent $A_i$ receives $(x_i, m_{j\\i}, \\varepsilon_i)$ and returns $a_i$. If the environment is fully secure, no player learns more about another player's private input than is revealed by the final outputs $f(a_i)$, ensuring privacy and security."}, {"title": "3.2 Provisioning the TEE", "content": "The TEE is used to protect invention of value $w > 0$ but in practice TEEs are not perfectly secure, and are periodically exposed to opportunistic hacks and jailbreaks. To secure against this, players may collectively employ n distinct Trusted Execution Environments (TEEs), each belonging to a different provider, and use a (k, n)-threshold encryption scheme with secret sharing. Concretely, each TEE holds only an encrypted partial share of the secret, so that no subset of size $k-1$ or smaller can reconstruct $w$. We assume colluding groups are precisely size $k$, since any larger groups e.g. $k+1$ don't attain more surplus (i.e. they would have the same \"characteristic function\".)\nObserve that TEEs often employ physical micro-architectures and firmware [Costan and Devadas, 2016, ARM, 2020] that exhibit tamper-evident properties. For example, an attempted TEE breach may compromise the microcode or trigger platform-level logs, leaving a detectable trail. This gives rise to some positive probability of any breach, an effect which may compound under our scheme."}, {"title": "Modeling the Scope Conditions for Security", "content": "Let $p$ be the probability that a breach is detected. If caught, the provider incurs a penalty $C$. From the TEE provider's perspective, the expected net benefit of colluding on a size-k expropriation is\n\n$(1-p)^k w - \\frac{w}{k}$ versus the penalty $p_k C$.\n\nThus, to deter expropriation, the principals must ensure a k and w such that the expected colluders' gain is no larger than the penalty:\n\n$(1-p)^k \\frac{w}{k} \\leq p_k C \\quad \\Rightarrow \\quad w < \\frac{k (1 - (1 - p)^k)}{(1-p)^k} C = \\Phi(k, p, C)$.\n\nScope Condition on Secure Value. A secret of value w is safe if and only if\n\n$w < \\Phi$.\n\nIn other words, security holds whenever w does not exceed the threshold $\\Phi$. We characterize this further in Appendix D, showing that for plausible parameter choices a threshold-TEE approach can plausibly protect quite large values."}, {"title": "4 Perfect Agents, Perfect Security: The Main Theorem", "content": "Next, suppose the seller and buyer both opt in to the TEE-based arrangement described in Section 3. Each party delegates to an agent $A_i$ that runs securely within the TEE, exchanging data (like $w$) without external leakage. This eliminates expropriation risk and leads to maximal secure disclosure within the scope conditions, $w = \\min{w, \\Phi}$ and efficient trade."}, {"title": "4.1 Mechanism and Timeline", "content": "(1) Nature draws $w \\sim U(0, 1)$, observed only by the seller.\n(2) Delegation. Both parties choose whether to delegate to the TEE: if either refuses, we revert to the baseline \u00a72.2 outcome.\n(3) Budget and thresholds. The buyer endows its agent $A_B$ with a budget $P$. The seller discloses some value $\\tilde{w} \\leq \\Phi$ to its agent.\n(4) Secure bargaining. Inside the TEE, $A_S$ privately reveals $w$ to $A_B$ (no risk of expropriation). The agents bargain to on some split of $\\tilde{w}$. Then $A_B$ either (a)offers payment $P < \\bar{P}$ and indicates accept to the TEE or (b) offers no deal, indicating exit to the TEE. $A_S$ checks that $P$ reflects the bargaining split, indicating accept or exit.\n(5) TEE Output. On mutual accept, the transaction completes and $w$ is released to the buyer and $P$ to the seller. If either agent indicates exit the TEE deletes the session and terminates."}, {"title": "4.2 TEE Equilibrium with Congruent Agents", "content": "Bargaining Setup. Inside the TEE, the buyer's agent and the seller's agent solve a symmetrical Nash-bargaining problem over how to split $\\tilde{w}$. The seller's threat point is $\\alpha_0 \\tilde{w}$ (reflecting an outside option or status quo payoff), and the buyer's threat point is 0. Formally,\n\n$\\max_{u_S, u_B} (u_S - \\alpha_0 \\tilde{w}) \\times (u_B - 0) \\quad \\text{subject to} \\quad u_S + u_B = \\tilde{w}, u_S \\geq \\alpha_0 \\tilde{w}, u_B \\geq 0$."}, {"title": "A straightforward Nash bargaining argument shows that the solution is", "content": "\n$u_S^* = \\alpha_0 \\tilde{w} + \\frac{1}{2}(\\tilde{w} - \\alpha_0 \\tilde{w}), \\quad u_B^* = \\frac{1}{2}(\\tilde{w} - \\alpha_0 \\tilde{w})$.\n\nIt follows that the fraction of $\\tilde{w}$ accruing to the seller is given by\n\n$\\theta = \\frac{1 + \\alpha_0}{2}$.\n\nAccordingly, the buyer receives $(1 - \\theta) \\frac{\\tilde{w}}{2} = \\frac{1}{2} \\alpha_0 \\tilde{w}$. We denote $\\theta$ as the seller's equilibrium share throughout the analysis.\nHence, the price the buyer pays in equilibrium is\n\n$P^* = \\theta \\tilde{w}$,\n\nmatching the split derived above.\nBuyer's Budget Choice. Since in equilibrium the largest possible $\\tilde{w} = \\min{\\omega, \\Phi}$, a lower budget risks losing out on high-type deals, while a higher budget would allow overpayments exceeding the total surplus. This yields:\n\n$\\bar{P} = \\min{\\omega, \\Phi}$\n\nSeller's Disclosure Choice. It's straightforward that $\\frac{d u_S}{d w} > 0$, and so the seller's utility is increasing in disclosure (possibly bound by the security constraint). The seller thus discloses to the agent:\n\n$\\forall i, \\tilde{w}_i = \\min{w_i, \\Phi}$\n\nIf $w < \\Phi$, then all sellers disclose maximally to agents who, by the same logic, disclose within the TEE. If $w_i > \\Phi$, the seller discloses only $\\tilde{w}_i = \\Phi$ (because revealing more is insecure), and the buyer pays $\\min{\\theta \\omega_i, \\theta \\Phi}$."}, {"title": "Theorem 1 (TEE Mitigates Hold-Up).", "content": "Under the TEE arrangement with maximally aligned agents and sufficient security $w < \\Phi$ the unique equilibrium outcome is full disclosure ($\\tilde{w} = w$) and investment at price $P = \\theta w$. Both parties strictly prefer this agreement over the no-TEE baseline, which gives $(\\alpha_0 w, 0)$.\nSimply, because the TEE prevents misappropriation, the seller's agent $A_S$ freely discloses $w$ to $A_B$. The buyer's agent then pays $P = \\theta w$, which is accepted because it meets $A_S$'s threshold. Both sides are strictly better off than the fallback equilibrium $(\\alpha_0 w, 0)$. No deviation is profitable, so this outcome is unique.\nNote Equivalent logic holds for $w_i > \\Phi$. If $w > \\Phi$, the seller discloses $\\Phi$, earning a correspondingly higher payoff than the outside option $\\alpha_0 w$, though not the full $w$. In this case some fraction of the invention's surplus remains undisclosed and unsecured. This partially mitigates hold-up, making both parties better off, but not fully eliminating it.\nTheorem 1 shows how secure TEEs plus perfectly congruent agents can resolve Arrow's disclosure-expropriation dilemma, at least with respect to some security bounds. In practice, of course, real AI agents are imperfect. We address that next."}, {"title": "5 Robustness to Agent Errors: How Good Do These Agents Need to Be?", "content": "We now relax the assumption of perfectly aligned, error-free agents. In reality, the buyer's agent may occasionally overpay, while the seller's agent might misreport $w$. Rather than causing a complete breakdown of the agreement, these mistakes are constrained by two natural features of the mechanism: (i) the buyer's budget cap, which prevents unbounded overpayment, and (ii) the seller's acceptance threshold, which rejects overly low offers. Even if errors are frequent, these features ensure that most realized payoffs remain above the no-TEE baseline."}, {"title": "6 Conclusion and Policy Implications", "content": ""}, {"title": "6.1 Implications for Policy and Regulation", "content": "Our analysis shows how trusted execution environments (TEEs) can drastically reduce the expropriation risk inherent in disclosing valuable inventions or ideas. From a policy perspective, this highlights several opportunities:\n\u2022 Promoting secure hardware adoption. Governments or regulators looking to spur innovation might consider incentives for broader TEE use- e.g., certifying TEE security standards or funding research to better secure them.\n\u2022 Supporting a market for \"secure collaboration.\u201d Institutions (funding agencies, public research labs) could provide or subsidize common TEE infrastructures. This would facilitate safer partnerships between inventors, investors, or large R&D labs, potentially leading to more rapid technological diffusion.\n\u2022 Strengthening or clarifying liability rules. Where TEEs are not yet fully reliable, clarifying the legal ramifications of agent misbehavior or data leaks can complement the hardware solution. Hybrid arrangements secure hardware plus more effective \"breach liability\"-can offer robust protection without stifling cooperative innovation.\nIn short, the policy takeaway is that cryptographic or hardware-based solutions can be a powerful supplement to legal frameworks like patents or NDAs. Far from a minor improvement, these methods can transform disclosure from a perilous gamble to a routine, secure transaction, thereby mitigating Arrow's core information paradox."}, {"title": "6.2 Limitations and Possible Extensions", "content": "While our model shows the promise of TEE-based disclosure, several limitations remain:\n\u2022 Hardware trust assumptions. We assume TEEs are fully secure. In reality, side-channel attacks and other vulnerabilities could undermine secrecy if the hardware is compromised. A ideally secure implementation under today's technology would supplement the TEE with other security measures, such as \"proof of cloud\" to secure against physical access.\n\u2022 Agent collusion or correlation of errors. We treat agent errors as idiosyncratic and independent of the invention's complexity. If errors become systematically larger for more complex inventions, the model's predictions may require re-examination. Because of the budget cap, this is unlikely to affect incentive compatibility but may affect surplus, perhaps substantially.\n\u2022 Real-world adoption frictions. Institutional inertia, user mistrust of agents or \"black-box\" solutions, or high costs could slow TEE adoption, potentially limiting their transformative impact on R&D collaboration.\nAddressing these issues might require combining trusted hardware with further security measures or legal guarantees. Future work can incorporate these real-world frictions into the theoretical framework, illuminating how robust the TEE solution remains under more complex settings."}, {"title": "6.3 Summarizing", "content": "We studied the fundamental problem of disclosing valuable information under the threat of expropriation. Drawing on the classical tension posed by Arrow [1971] and Nelson [1959], we developed a model in which a seller (the inventor) cannot fully appropriate her innovation if she reveals it prematurely. Traditionally, such scenarios yield low- or no-disclosure equilibria, stifling socially beneficial trades.\nOur main contribution is to show that trusted execution environments (TEEs) together with AI agents can restore efficient disclosure. By delegating the decision process to secure programs that verify invention quality without unconditionally revealing it to the buyer, the seller can disclose confidentially, extract fair compensation, and thus avoid hold-up. Even when the agents themselves are imperfect subject to \"errors\" in disclosure or payment the mechanism remains robust for a broad range of error magnitudes, thanks to natural design features such as budget caps and acceptance thresholds.\nThis framework has broad implications. It effectively provides an \"ironclad NDA,\" substituting for uncertain legal enforcement with cryptographic or hardware-level assurances. Policymakers seeking to promote R&D can encourage TEE adoption to mitigate risks that often deter inventors from sharing their breakthroughs. Future work can enrich this approach by analyzing repeated interactions, reputation effects, or competition among multiple buyers. Our results highlight that, as trusted hardware and AI advance, we may see a new paradigm of secure information exchange-expanding the frontiers of innovation without the specter of expropriation."}, {"title": "Appendix", "content": ""}, {"title": "A Discussion of Alternate Cryptographic Techniques to solve the Disclosure Game", "content": "Our main analysis relies on Trusted Execution Environments (TEEs) to implement a secure, tamper-proof environment for disclosure. However, other cryptographic primitives and protocols could, in principle, achieve similar functionality under different trust or disclosure structures. In this section we will attend to some alternatives one might consider that don't rely on trusted hardware assumptions.\nVirtues of the TEE setting In our setup, \"Agents\" stand in for the players and bargain in a secure environment without fear of disclosure. We regard it as helpful that agents can interact (bargain) in an \"open\" way that simulates full disclosure and inspection as one might find in a real-world transaction. The TEE ensures that this openness does not introduce expropriation risks. It does of course introduce agency risks, which we attend to directly in the main body of the text as errors."}, {"title": "A.1 Partial Revelation Approaches using ZK or FHE", "content": "Cryptographic primitives like Zero-knowledge Proofs (ZKP) or Fully Homomorphic Encryption (FHE.) could allow sellers to prove (or buyers to query) some aspects of a good while protecting others. In our baseline game, the seller might prove that \"w contains a process that can produce property z\" without revealing the process itself.\nThese approaches are extremely useful and could be used cleverly to enhance our scheme. But we note two drawbacks of proving only some selective aspects of a good without revealing the good itself: adverse selection faced by the buyer and externalities from partial revelation faced by the seller.\nAdverse Selection under \"proof\" schemes Observe that the buyer would like to know all properties of the good that would be pertinent to their decision. Learning presumably positive properties like \"x can lift 10,000 pounds with gasoline consumption < y\" might sound enticing to someone who thinks they are buying a forklift. But suppose when they complete the purchase based on learning this x turns out to be an elephant. The proven property does of course hold, but the buyer wasn't fully informed without knowing e.g. \"x responds poorly to emotional neglect and needs to consume 40 gallons of water daily.\" The buyer, by not considering whether to ask about emotional neglect, has been adversely selected against.\nThus the buyer must play a complex version of 20 questions or risk adverse selection. And meanwhile, proving each property as above involves costly computation at every step. The key insight for our setting is that, intuitively, knowing x itself (e.g. if it is an elephant or a forklift) better enables a buyer to home in on the relevant properties to be proven. This is a virtue of mechanisms like TEE Disclosure which enable x to be directly disclosed and thereby guide an assessment of the relevant properties.\nExternalities from partial revelation Even disregarding adverse selection and the costs of mitigating it, partial disclosure itself may leak valuable information. It's sometimes the case that knowing a property holds (or knowing that a certain feat is achievable) is itself highly valuable information. Thus, if we would like to prove \"w contains a process that can produce property X\", without revealing the process, even that partial revelation would constitute valuable disclosure."}, {"title": "A.2 Full revelation using Secure Multi-party Computation (MPC) or Indistin-guishability Obfuscation (iO)", "content": "Secure Multi-Party Computation Another possible approach is to run a multi-party computation (MPC) protocol, perhaps combined with a threshold signature scheme, where no single party holds all the information needed to reconstruct the invention w or forcibly expropriate it. Instead, the information and any necessary keys could be split among multiple signers, and the protocol would reveal output only if enough signers collectively approve.\nIndeed, we use such a setup to enhance the TEE security in our model. In practice, attending to the risk of collusion among threshold signers, or avoiding the potential for the \"threshold\" signer to acquire extractive bargaining power, is a strategic problem to be solved. MPC is not a standalone substitute, but rather a complement here and in general using it requires the sort of strategic considerations which we have attended to.\nIndistinguishability Obfuscation Indistinguishability Obfuscation (iO) is a powerful cryptographic primitive that, if realized in practical form, could theoretically replicate the core TEE functionality: it would allow the agents to operate within an \"obfuscated\" program, checking and disclosing all properties of the seller's invention w, without leaking information about the invention or its properties. At a high level, iO means that if you have two equivalent circuits (they produce the same input-output mapping) run programs, the resulting obfuscated programs are computationally indistinguishable.\nIn principle, one could obfuscate the logic so that the players obtain only an ultimatum (e.g. \"agree\" or \"disagree\") without learning any internal details of the invention $w$. This mirrors the TEE's role in preventing expropriation: the invention or its properties are never revealed in the clear. And these assurance would be stronger as they would be provable by math rather than hardware design and incentives, as TEEs are. While iO doesn't produce \"stateful\" execution, it could be combined with blockchains to replicate such properties.\nThat said, iO remains largely theoretical today, requiring complex hardness assumptions and lacking widely accepted, efficient constructions. This makes it a less practical choice compared to TEEs (which are commercially available commodities), but it remains conceptually interesting for future research."}, {"title": "Summary", "content": "In short, while each of these cryptographic primitives can accomplish some version of \"secure disclosure,\" their off-the-shelf usage often either imposes costs on the buyer and/or leaks valuable partial information (ZKP, FHE) or introduces new trust assumptions (threshold schemes) or relies on still mostly theoretical constructions (iO). By contrast, trusted execution environments (TEEs) combine (a) hardware-enforced security guarantees with (b) market availability (e.g. Intel SGX) and (c) straightforward enforcement of \"all-or-nothing\" payoffs. Thus, in our model, TEEs are a conceptually and practically simple device for guaranteeing full disclosure without expropriation or unintended leakage."}]}