{"title": "CoActionGraphRec: Sequential Multi-Interest Recommendations Using Co-Action Graphs", "authors": ["Yi Sun", "Yuri M. Brovman"], "abstract": "There are unique challenges to developing item recommender systems for e-commerce platforms like eBay due to sparse data and diverse user interests. While rich user-item interactions are important, eBay's data sparsity exceeds other e-commerce sites by an order of magnitude. To address this challenge, we propose CoActionGraphRec (CAGR), a text based two-tower deep learning model (Item Tower and User Tower) utilizing co-action graph layers. In order to enhance user and item representations, a graph-based solution tailored to eBay's environment is utilized. For the Item Tower, we represent each item using its co-action items to capture collaborative signals in a co-action graph that is fully leveraged by the graph neural network component. For the User Tower, we build a fully connected graph of each user's behavior sequence, with edges encoding pairwise relationships. Furthermore, an explicit interaction module learns representations capturing behavior interactions. Extensive offline and online A/B test experiments demonstrate the effectiveness of our proposed approach and results show improved performance over state-of-the-art methods on key metrics.", "sections": [{"title": "1 INTRODUCTION", "content": "Item recommender systems have become an indispensable part of ecommerce platforms, playing a crucial role in connecting users with relevant items that they may be interested in. The eBay e-commerce platform has 2 billion live listings (items) and 132M active buyers (users). From a recommender system perspective, this is a very sparse dataset. Furthermore, in addition to the cold start problem, many items are volatile: many new items are listed daily and some items expire without accumulating substantial user interaction. This paper presents an approach for generating personalized item recommendations in this challenging data environment.\nIn general, similar to information retrieval (IR) systems, recommender systems operate in two stages: candidate generation and ranking [8]. The candidate generation stage efficiently retrieves a set of relevant items from the large item corpus, while the ranking stage sorts the items optimizing a business relevant metric such as user engagement or conversion. In this paper, we will focus on the candidate generation stage. Personalizing the candidate generation stage with user information using sequence-based recommendation has attracted significant research interest [5, 7, 14, 16, 25]. Additionally, multi-interest learning methods that capture users' diverse interests from their behavior sequences have shown promising results for long term user sequential modeling [3, 13, 17, 18], and it has become one of the common industrial solutions for the candidate generation stage.\nWhile existing sequential recommendation techniques form a solid foundation, there are still some limitations which we found that could be improved during our development of an e-commerce industrial solution.\nLeverage co-action items. Sparsity is a common phenomenon in behavioral data of item recommender systems, particularly evident in some industrial-level scenarios. Due to extreme sparsity, we lack sufficient collaborative filtering signals to accurately calculate the relevance between a given user and an item. In order to make better use of the already sparse interaction behavior, we supplement the target item with its co-action items as additional features on the Item Tower of our CAGR deep learning model. These co-action items refer to item pairs in which users have interacted with both items. We employed a graph neural network (GNN) structure to fully leverage the co-action graph for enhanced item representations. During training, we employ a dual-objective loss to tune the importance of collaborative aspects.\nExplicit sequential interaction modeling. While existing multi-interest learning methods have shown promise in extracting user interests from behavior sequences, they lack explicit modeling of interactions between user actions. It is quite common that users make purchase decisions after extensive product comparisons considering factors like item aspects, seller quality, price, etc., and it often results in repeated views of same items as well. Thus, modeling the behavior interaction by explicitly comparing item attributes between two user action items in a pairwise manner can better reflect comparison processes in shopping activities. For example,"}, {"title": "2 RELATED WORK", "content": "Multi-Interest Learning. Typical sequential recommendation systems often model users' preferences as a single low-dimensional vector, which is not sufficient to accurately capture the diverse set of interests of a user. Recognizing this limitation, MIND [13] introduced a dynamic routing mechanism that aggregates users' historical behaviors into multiple interest capsules. Building upon this work, ComiRec [3] further explored multi-head attention-based multi-interest routing to capture users' diverse interests and introduced diversity controllable methods. PIMIRec [6] and UMI [4] further incorporated additional factors such as time information, interactivity, and user profiles. Additionally, Re4 [27] and REMI [23] optimized the training process by considering new loss terms and negative sampling strategies.\nGraph Neural Network for Recommendation. Graph Neural Networks (GNNs) have emerged as a powerful tool for recommendation systems, enabling more accurate and personalized recommendations. PinSage [24] introduced the application of Graph Convolutional Networks (GCN) to pin-board graphs, marking the first work to incorporate GCN into industrial recommender systems. LightGCN [11] employed matrix factorization to derive user"}, {"title": "3 METHODOLOGY", "content": null}, {"title": "3.1 Problem Formulation", "content": "Assume we have a set of users u \u2208 U and each user u has a sequence of actions Su\u2081,..., Sur, where su\u2081 = (xui, bui, tui), xu\u2081 represents the item of ith action, bu, is the behavior type of ith action, and tu; is the behavior timestamp of ith action. In addition, given an item xq, we define two types its co-action items: xqc \u2208 Cq when there is at least one user have click on both xq and xqc, which we will refer to as co-click items; xqp \u2208 Pq when there is at least one user have purchase on both xq and xqp, which we will refer to as co-purchase items. Our goal is to predict the next action of the user from a set of items i e I."}, {"title": "3.2 Model Architecture", "content": "Figure 2 represents the overall architecture of our CAGR model in this paper, which is a typical two tower model. After a shared Embedding Module, each item x that feed into the model will be converted into embedding representation e. Then we have a Co-action Aggregation Module on the Item Tower that aggregates the target item and its co-action items, generating a final item representation. Furthermore, we have a Graph Construction Module that converts the user's action sequence into a fully connected graph, which followed by an Explicit Interaction Module that learns the interaction relationships among user actions, finally we extract multiple interest representations of user actions"}, {"title": "3.3 Item Tower: Co-action Aggregation Module", "content": "We can consider the full set of item-to-item relationships at eBay as a co-action graph. On the Item Tower of our CAGR model, we construct a localized subgraph by considering the co-action items of the neighbors of a target item. Figure 3 a) shows the relationship between the global item graph and the item subgraph. We then use a GNN to aggregate information within this subgraph and obtain an embedding representation for the target item. Inspired by [1, 10, 19], this module is basically composed of two steps. In step 1 we employ an attention mechanism to aggregate the neighboring nodes. Given each co-click item embedding eqcn, we calculate its attention aqcn with target item eq using the method in [1], and execute a weighted sum cn = aqcneqcn to get the aggregated co-click embedding, denoted as zqc. For co-purchase items we can generate the corresponding embedding zqp as well. And in step 2 we concatenate the aggregated neighbors and transformed with a linear layer to obtain the final item embedding zq, i.e. zq = Wzq\u00b7CONCAT(eq, Zqc, Zqp)+bzq where Wzq and bzq are model weights."}, {"title": "3.4 User Tower: Graph Construction Module", "content": "In this module, we transform the user's sequence of behaviors into a fully connected graph. The graph is a directed graph where each node represents a user action {click, add to watchlist, add to cart, purchase} on a specific eBay item. Each edge connects two user actions on eBay items to capture the temporal relationships between these actions based on the user's sequential behavior. We make the graph directed because early-occurring actions can affect later-occurring actions but not vice versa, so the direction of information aggregation should be one-way. Figure 3 b) gives an example of how to convert the sequence data into a sequence graph.\nThe main task in this module is to generate the representation for each node and edge on the graph. For each node we directly use its item embedding representation as node representation. For each edge we use E(su\u2081, Suj) to denote an edge which connects the i-th and j-th action of user u. To construct the edge information, we mainly build from pairwise relationship information. This type of information is calculated based on the features of a given node pair. Calculating pairwise level information provides an explicit way to represent the behavior interaction, which corresponds to our motivation. Here, we design several different types of functions based on the different characteristics of item features. For item x, we use x(f) to denote one of its features.\n\u2022 For one-hot features contained in items, such as item ID, category ID, parent category ID, seller ID, etc., we define the function I to compare if they are the same.\n$I(x_a^{(f)},x_b^{(f)}) = \\begin{cases} 1 & \\text{if } x_a^{(f)} = x_b^{(f)} \\\\ 0 & \\text{otherwise} \\end{cases}$\n(1)\n\u2022 For numerical value features contained in items, such as processed price information, we define the function G to measure the gap between them.\n$G(x_a^{(f)}, x_b^{(f)}) = |x_a^{(f)} - x_b^{(f)}|$\n(2)\n\u2022 For ordinal features that can represent relative relationships, such as the seller's level, or bucketized numerical feature like price range level, we define the function H to compare and return their order relationship.\n$H(x_a^{(f)}, x_b^{(f)}) = sign(x_a^{(f)} - x_b^{(f)})$\n(3)\nBesides the pairwise information from item features, the behavior type bu; and timestamp tu; are considered as one-hot and numerical features separately, applying the above functions to them. We also convert bu\u2081 and bu; into embedding representations bu; and buj, and include them directly as part of the edge information."}, {"title": "3.5 User Tower: Explicit Interaction Module", "content": "In this module, we learn the explicit interaction between user behaviors based on the constructed sequence graph. The entire process is described in Algorithm 1. The algorithm can be seen as an L-layer Graph Neural Network. Our initial input is obtained from the sequence graph output by the previous module. For a particular layer l, we perform an attention based graph layer for each node. The attention here is a customized attention mechanism that needs to consider both node and edge information. We borrow the attention calculation method from both GAT (additive attention) and Transformer (dot product attention). To be concrete, we generate the query embedding q(1) and key embedding k based on the"}, {"title": "3.6 User Tower: Interest Extraction Module", "content": "After the aforementioned steps, we have obtained a behavior representation matrix Hu = (hu\u2081, hu\u2082,..., h\u0438\u0442). Next, we employ a interest extraction module to extract the user's multiple interest representation. We adopt the exact self attentive approach in [3], which is also used as Multi-Interest Extraction Layer in [6]. The output of this module, which is the user's interest representation matrix, can be denoted as Ou = (Ou\u2081, Ou2, ..., Ouk), where Ou\u2081 is the representation vector for the i-th interest of the user, and K is a preset parameter representing the number of interests."}, {"title": "3.7 Training Phase", "content": "Now we have the interest representation matrix Ou for a given user, as well as the representation vector zq for any target item. We follow the common approach in [3] and [6] to pick the interest vector oug that generate the highest dot product score which is the affinity score on the model architecture figure among the user interest vectors, i.e. oud = Ou [argmax(Ozq)], and define the loss Lz as the sampled softmax loss where the target item is positive and random selected items are negatives. In addition, we compute the the score between the user vector and the embedding eq of the item itself as an auxiliary score, and select the activated interest vector ouq oud = Ou [argmax(Oeq)] in a similar manner. With ou we define a corresponding loss Le which is also the sampled softmax loss. While co-action items making full use of collaborative signals, they inevitably introduces some noise. Therefore, we define this auxiliary loss to allow us to intervene in the importance ratio between collaborative signals and the item itself during training, guiding the model to learn better embeddings. Thus, the final loss function is:\n$L = L_z + \\lambda L_e$\n(7)\nWhere \u03bb is a hyperparameter to balance the ratio between Lz and Le.\nThe learned user embeddings Ou and item embedding zq based on the given user u and item q can be used for calculate the user's score for the item:\n$\\gamma_{uq} = \\max_{1<i<K} (O_{u_i}^T z_q)$\n(8)"}, {"title": "4 OFFLINE EVALUATION", "content": "Dataset and evaluation protocols. We selected two datasets for evaluating recommendation performance, one public dataset and one industrial dataset. The statistics of the two datasets are shown in Table 2.\n\u2022 The Taobao user behavior dataset\u00b9 is a publicly available dataset. To maintain consistency with related work, we refer to [3] and retain only items and users with at least 5 clicks, truncate the length of user behavior sequences to a maximum of 50, and use a user based split for training/validation/testing set. All four types of behaviors in the dataset are considered, but we limit the prediction target to click behavior.\n\u2022 For the industrial dataset, we collects 8 days of eBay user behavior data, including click, add to watchlist, add to cart, and purchase. For this dataset, user behavior sequences are truncated at the length of 200. We perform a time-based split for training and testing, where the first 7 days of data are used for training, and the 8th day's data is used for testing. This split differs from the Taobao dataset as a time-based split ensures that the use of co-action behavior data as features does not encounter feature leakage during evaluation, and it aligns with the practical model training process in the industry.\nBaseline Models Baseline models which we compare with our approach are YoutubeDNN [8], MIND [13], ComiRec [3], PIMIRec [6]. Considering our CAGR method use multi-behavior signals, we also use the multi-behavior sequence when implementing baseline methods. Additionally, when conducting experiments on the Taobao dataset, our proposed method only utilizes the User Tower improvement, as the user based split in this dataset does not allow"}, {"title": "5 LIVE EXPERIMENT AND ONLINE SERVING", "content": "In addition to offline evaluations, we also conducted a 14-day online A/B experiment. The control variant represents the production version deployed online, while the treatment variant incorporated our proposed CAGR method as an additional candidate generation recall set. We selected key performance metrics, including clicks, purchases, and revenue, as evaluation criteria. The results of the A/B experiment showed that our method led to a 1.82% increase in clicks, a 2.16% increase in purchases, and a 3.59% increase in revenue over the production baseline.\nIn terms of the online serving of the model, since multi-interest models are better at mining users' long-term historical behaviors, under multi-recall online recommendation architecture which is a"}, {"title": "6 CONCLUSIONS", "content": "In this work we proposed a multi-interest model that leverages a graph of co-action items of the target item, and enhanced User Tower with GNN based modules that learns pairwise interaction from the user behavior sequence. During the training phase, we introduced an auxiliary loss term to balance the model's emphasis on target item and its co-action items, enabling the model to better learn the representation. Both offline experiment and live A/B experiment shows the effectiveness of our proposed CAGR model over the baseline methods. In the future, we will consider adding more fine-grained co-action behaviors, such as incorporating user information into co-action events, and also expanding the training goals of our CAGR model beyond just click behavior to include other actions like add to cart, purchasing, and so on. At the same time, we will also consider integrating temporal graph-based techniques such as [28] and [9]."}]}