{"title": "Enhancing Auto-regressive Chain-of-Thought through Loop-Aligned Reasoning", "authors": ["Qifan Yu", "Zhenyu He", "Sijie Li", "Xun Zhou", "Jun Zhang", "Jingjing Xu", "Di He"], "abstract": "Chain-of-Thought (CoT) prompting has emerged as a powerful technique for enhancing language model's reasoning capabilities. However, generating long and correct CoT trajectories is challenging. Recent studies have demonstrated that Looped Transformers possess remarkable length generalization capabilities, but their limited generality and adaptability prevent them from serving as an alternative to auto-regressive solutions. To better leverage the strengths of Looped Transformers, we propose RELAY (REasoning through Loop Alignment iteratively). Specifically, we align the steps of Chain-of-Thought (CoT) reasoning with loop iterations and apply intermediate supervision during the training of Looped Transformers. This additional iteration-wise supervision not only preserves the Looped Transformer's ability for length generalization but also enables it to predict CoT reasoning steps for unseen data. Therefore, we leverage this Looped Transformer to generate accurate reasoning chains for complex problems that exceed the training length, which will then be used to fine-tune an auto-regressive model. We conduct extensive experiments, and the results demonstrate the effectiveness of our approach, with significant improvements in the performance of the auto-regressive model. Code will be released at https://github.com/qifanyu/RELAY.", "sections": [{"title": "1. Introduction", "content": "Reasoning plays a central role in shaping effective decision-making processes and guiding problem-solving strategies in artificial intelligence systems. For large language models (LLMs), the most effective way to achieve reasoning is through Chain-of-Thought (Wei et al., 2022; Khot et al., 2022), which generates all intermediate steps token by token until the final answer is reached. However, generating the correct reasoning process using LLMs is challenging. On one hand, the Chain-of-Thought process can be very long, sometimes growing polynomially with respect to the prompt length (Feng et al., 2024; Merrill & Sabharwal, 2024). When the reasoning length exceeds the training data length, it encounters the length generalization problem, where accuracy can drop significantly (Xiao & Liu, 2023; Jin et al., 2024). On the other hand, web data is often noisy, and learning from incorrect trajectories can lead to incorrect answers. While synthetic data could mitigate this issue (Lightman et al., 2024), it requires significant human effort and knowledge to generate and curate.\nRecently, an alternative framework has gained attention, known as the looped Transformer (Giannou et al., 2023). In general, the looped Transformer is a standard Transformer model with cross-block parameter sharing, like AL-BERT (Lan et al., 2020). In this framework, the input prompt (i.e., the problem) is processed through repeated iterations of the same block, with the number of iterations adaptively determined by the problem complexity. See Figure 1 for an illustration. Several preliminary results (Fan et al., 2024) show that the looped Transformer model has better length generalization capabilities, partially because the increase in problem complexity (e.g., problem length) is not as significant as in the Chain-of-Thought steps.\nHowever, the success of this approach comes with some practical limitations. While determining appropriate loop iterations is feasible for reasoning tasks, it becomes problem-atic in general tasks, such as translation and summarization. Furthermore, although the looped Transformer can handle specific reasoning tasks, it remains unclear whether it possesses the capability to manage multiple reasoning tasks within a single model. Given these concerns, a natural question arises: if the looped Transformer is a general reasoner, can we explore ways to integrate its capabilities into the Chain-of-Thought framework of standard auto-regressive models? This integration would allow us to leverage the looped Transformer's strong performance on complex reasoning problems while preserving the versatility that allows auto-regressive models to excel in diverse language tasks.\nIn this paper, we introduce RELAY (REasoning through Loop Alignment iteratively), a novel framework that leverages looped Transformer's superior capabilities to help auto-regressive models handle longer reasoning chains. At its"}, {"title": "2. Related Work", "content": ""}, {"title": "2.1. Auto-regressive LLM with Chain-of-Thought", "content": "Chain-of-Thought (CoT) has emerged as a powerful tech-nique for enhancing language models' reasoning capabilities both empirically (Wei et al., 2022; Khot et al., 2022) and theoretically (Feng et al., 2024; Merrill & Sabharwal, 2024), especially in latest models such as OpenAI O1\u00b9, DeepSeek r1 (DeepSeek-AI et al., 2025) and Qwen QwQ\u00b2. By gen-erating intermediate reasoning steps token by token, these models effectively decompose complex problems into se-quential subprocesses. However, two critical challenges persist. First, obtaining high-quality CoT training data re-mains time-consuming and labor-intensive (Lightman et al., 2024), especially for problems requiring sophisticated rea-soning chains. Second, the generation and understanding of extended reasoning sequences can be problematic (Xiao & Liu, 2023; Jin et al., 2024; Mao et al., 2024)."}, {"title": "2.2. Looped Transformer", "content": "Research on looped Transformers has evolved significantly over recent years. The initial studies by Dehghani et al. (2019) and Lan et al. (2020) demonstrated the effectiveness of parameter sharing across layers in supervised learning and BERT pretraining. This line of research has since ex-panded in both theoretical and practical directions. On the theoretical front, Giannou et al. (2023) and Xu & Sato (2024) established fundamental properties of looped Trans-formers, proving their Turing completeness and characteriz-ing their approximation capabilities. Gatmiry et al. (2024) further advanced this understanding by showing how to in-corporate inductive biases for learning iterative algorithms, particularly in the context of multi-step gradient descent for in-context learning. Empirically, looped Transformers have shown promising results across various applications. Yang et al. (2024) demonstrated their parameter efficiency in data-fitting tasks, while de Luca & Fountoulakis (2024) and Chen et al. (2024) revealed their potential in graph al-gorithm simulation and in-context learning enhancement. Notably, Fan et al. (2024) established their superior length generalization capabilities in RASP-L tasks. In the domain of algorithm learning, Gao et al. (2024) introduced Algo-Former, a framework that leverages looped Transformers for algorithm representation and learning. While these works have extensively explored various aspects of looped Trans-formers, our work takes a distinct direction. We specifi-cally focus on leveraging the better length generalization of looped Transformers for helping standard auto-regressive Transformers."}, {"title": "2.3. Approaches for Length Generalization", "content": "The capability of Transformers to generalize to longer se-quence is influenced by their positional encodings (Press et al., 2022). Recent research has pursued two primary directions to enhance length generalization capabilities of LLMs. The first focuses on developing advanced relative positional encoding schemes (Raffel et al., 2020; Press et al., 2022; Chi et al., 2022; Sun et al., 2023; Chi et al., 2023; Li et al., 2024), while the second explores modifications to positional representations through index granularity adjust-ments (Chen et al., 2023; Peng et al., 2024) and strategic index shifting (Ruoss et al., 2023; Zhu et al., 2024). These works are orthogonal to the central contributions of this paper. A parallel line of work focuses on improving the reasoning capabilities of LLMs through better training data. These methods typically leverage accessible labels or re-wards to generate and filter reasoning steps, selecting those that yield correct solutions or high rewards (Zelikman et al., 2022; Yuan et al., 2024; Singh et al., 2024; Hosseini et al., 2024). However, a critical limitation emerges from LLMs' tendency to generate incorrect or superfluous intermedi-ate reasoning steps while still arriving at correct solutions"}, {"title": "3. Methodology", "content": ""}, {"title": "3.1. Notation", "content": "Any reasoning task can be decomposed into three compo-nents: the problem tokens, the reasoning tokens (i.e., chain-of-thought steps), and the answer tokens. Let the problem token sequence be represented as x = [x\u2081, x\u2082 , ..., x\u2099]. The Chain-of-Thought (CoT) process generates a sequence of in-termediate reasoning tokens z = [z\u2081, z\u2082, ..., z\u2098], where n and m denote the number of problem tokens and reasoning tokens respectively. In this work, we focus on a simple set-ting where the problem's answer is represented by a single token, denoted as y.\nCoT Auto-regressive Generation. For auto-regressive generation, the mapping from the problem sequence x to the answer y is performed through generating the intermediate tokens z token by token. Formally, this can be expressed as:\nz\u1d62 ~ P(z\u1d62|z_{<i}, x; \u03b8), for i = 1, 2, ..., m,  (1)\nwhere z_{<i} = [z\u2081, z\u2082, ..., z_{i\u22121}] represents precedent rea-soning tokens. and the final answer is obtained at the final step:\ny ~ P(y|z, x; \u03b8).  (2)\nLooped Model. Different from the auto-regressive model that generates explicit tokens to obtain the answer, the looped model implicitly maps the input sequence x to the final answer y by executing the same function (e.g., a multi-layer Transformer block) for T times in the representation space. The number of iterations T depends on the problem comlexity. The forward process consists of three steps: First, the token sequence x is mapped to embeddings through an embedding function h:\ne\u2080 = h(x; \u03b8_{emb}),  (3)\nwhere e\u2080 \u2208 \u211d^{d\u00d7n} and d is the hidden dimension. Second, the embeddings are iteratively refined through transforma-tion f:\ne\u209c = f(e_{t-1}; \u03b8_{model}), for t = 1, 2, . . ., T,  (4)\nwhere f is usually a Transformer model and the number of iterations T is adaptively determined based on the problem length. Finally, the answer is predicted through a final-answer prediction head based on the representations in the last layer:\ny ~ P(y|e_T; \u03b8_{pred}).  (5)"}, {"title": "3.2. Length Generalization on Single Reasoning Task", "content": "Before introducing our RELAY framework, we first empiri-cally demonstrate the superior length generalization capa-bility of looped Transformers compared to standard auto-regressive models. This analysis serves as the foundation and motivation for our proposed framework.\nTask Descriptions. To validate the capabilities of differ-ent methods, we use three representative tasks adapted from Feng et al. (2024), including Arithmetic, a mathemat-ical task, and two dynamic programming (DP) problems: Edit Distance (ED) and Longest Increasing Subsequence (LIS). These tasks are selected for their diverse problem-solving patterns and varying levels of complexity, and the fact that they can be solved through a Chain-of-Thought rea-soning process to arrive at the final answer. Performance is evaluated based on the accuracy of the final answer for both models. Detailed descriptions of these tasks are provided in Appendix A.\nExperimental Setup. For each task, we construct a dataset consisting of 1 million training samples and 100 k test sam-ples, respectively. For the Arithmetic task, the problem com-plexity is defined as the number of operators. For the Edit Distance (ED) task, the problem complexity corresponds to the length of the shorter string in each pair. For the Longest Increasing Subsequence (LIS) task, we define the problem complexity as \u2308n/10\u2309, where n is the length of the input sequence, as our dataset is structured with 10 numbers per reasoning step (see Appendix A for details). The training datasets are constructed with the length of the problem token sequence x \u2264 15, 30, and 100 for Arithmetic, ED, and LIS, respectively. To evaluate the model's generalization capabilities, test datasets are created with problem lengths in the ranges [15, 25] for Arithmetic, [30, 40] for ED, and [100, 120] for LIS."}, {"title": "3.3. Loop-Enhanced Chain-of-Thought Reasoning", "content": "A straightforward way to leverage a well-trained looped model to enhance the auto-regressive CoT model is by using it as a verifier. When a problem is presented, both models generate a final answer, and if both answers match, the CoT output is trusted. However, this approach often fails in practice, as CoT models can produce incorrect reasoning trajectories even when reaching the correct final answer (see Section 4.3), making it unreliable to rely solely on the accuracy of the final answer as the guiding signal.\nOur key insight is that an alignment can be established be-tween the iterative structure of the looped Transformer and the stepwise nature of CoT reasoning. As shown in Figure 3, unlike the step-by-step token generation in CoT, looped models update their representations simultaneously in each iteration, and the number of such iterations naturally corre-sponds to the number of reasoning rounds. This structural similarity opens up the possibility of training the looped model to generate the corresponding CoT tokens for each round in parallel, while maintaining its ability to predict the final answer. With this insight, we propose RELAY (REasoning through Loop Alignment iteratively), a two-stage framework that bridges looped and auto-regressive models.\nStage I: Training Looped Model with Explicit CoT Align-ment. In the first stage, we train the looped model to generate intermediate reasoning processes that align with CoT steps. To formalize this alignment, assume we have a reasoning chain with T rounds. Given reasoning tokens Z = [z\u2081, z\u2082, ..., z\u2098], denote k\u209c as the start token position of t-th reasoning round, where each round contains valid reasoning tokens Z[k\u209c:k_{t+1}\u22121] = [z_{kt}, z_{kt+1}, ..., z_{kt+1\u22121}]. Taking arithmetic reasoning as an example, consider a se-quence of tokens representing the complete reasoning chain, \"3\u00d72+6\u00f73=6+6\u00f73=6+2=8\". This sequence can be naturally divided into T = 3 rounds using the equal signs as delimiters: Given the input problem \"3 \u00d7 2+6\u00f73=\", the first round corresponds to \u201c6 + 6 \u00f7 3 =", "6 + 2 =\", and the third (last) round presents the final answer \"8\".\nAlthough the number of rounds aligns with the iteration count of the looped model, a key challenge arises from the mismatch in token lengths across different reasoning steps. For instance, earlier steps involving complex expressions (e.g., \"6+6\u00f73=\") typically require more tokens than later steps (e.g., \"6 + 2 =": "."}, {"title": "representations of size n across iterations.", "content": "To address this length mismatch while preserving the paral-lel processing capability of the looped model, we employ a right-aligned padding strategy. For the t-th iteration, we construct a fixed-length sequence Z\u209c of length n by right-aligning the ground truth reasoning tokens Z[k\u209c:k_{t+1}\u22121] and filling the remaining left positions with <pad> tokens. The fixed-length is determined based on the maximum length among all reasoning rounds and the original input problem (note that the length of a reasoning round usually does not exceed the length of the input problem; otherwise, each round can be further divided into shorter rounds). To track both valid reasoning tokens and the boundary of padding, we introduce a binary mask:\nM\u209c[i] = { 1, if i = p\u209c or \u017e\u209c[i] \u2260 <pad>,\n0, otherwise,  (6)\nwhere M\u209c indicates the positions of valid reasoning tokens and the position of the last <pad> token p\u209c.\nUsing this alignment strategy, we train the looped model to predict the corresponding CoT tokens at each iteration, enabling it to generate CoT-aligned intermediate outputs. In detail, at each iteration t, we train the model to predict both the valid reasoning tokens and the last <pad> token through an intermediate prediction head:\nP(\u017e\u209c|e\u209c; \u03b8_{pred-cot}),  (7)\nFor the intermediate reasoning steps, we ignore all pre-ceding <pad> tokens except the last one, as they have no impact on the reasoning process. The loss of this part can"}, {"title": "be formulated as :", "content": "L_{iter} = 1/T \u03a3 CrossEntropy(P(\u017e\u209c|e\u209c; \u03b8_{pred-cot}), \u017d\u209c) \u2299 M\u209c,  (8)\nt=1\nwhere the element-wise multiplication \u2299 ensures that the loss is computed only on valid reasoning tokens and the last <pad> token.\nFor the final answer, we have the answer prediction loss to ensure correct final predictions:\nL_{ans} = CrossEntropy(P(y|e_T; \u03b8_{pred}), y),  (9)\nwhere y is the ground truth answer. The total training loss is then:\nL = L_{ans} + \u03bbL_{iter},  (10)\nwhere \u03bb is a hyperparameter balancing the two objectives.\nThis design enables the looped model to accurately pre-dict the answer and provide interpretable intermediate rea-soning steps that can be effectively utilized to guide the auto-regressive model in Stage II."}, {"title": "Stage II: Enhancing Auto-regressive CoT Models. In", "content": "the second stage, we leverage the trained looped model to enhance auto-regressive CoT models through a systematic process:\nFirst, we use the trained looped model in Stage I to gen-erate reasoning demonstrations for problems of increasing complexity. For each problem x, we obtain:\n(z, y) ~ p(x; \u03b8\u2081),  (11)\nwhere \u03b8\u2081 denotes the trained looped model from Stage I, z = [z\u2081, z\u2082, ..., z\u2098] represents the generated reasoning tokens across iterations, and y is the predicted answer."}, {"title": "We then utilize these demonstrations to fine-tune an auto-regressive model.", "content": "For problem lengths beyond the original training range, we generate a comprehensive dataset of rea-soning demonstrations using the looped model. This newly generated data is then merged with the original training dataset, which contains problems within the initial training length. The combined dataset, spanning both the original and extended problem lengths, is then used to fine-tune the auto-regressive model in a single step. This approach allows the model to retain its original reasoning capabilities while acquiring the ability to effectively tackle more complex, longer problems, utilizing the structured insights provided by the demonstrations.\nComparison with Synthetic Data Generation Ap-proaches. To effectively guide the LLMs to handle com-plex problems, prior works (Hendrycks et al., 2021; Light-man et al., 2024) have explored the synthetic data generation approach, where human labelers construct data generation pipelines based on their understanding of both the task and its solution process. This approach requires labelers to pos-sess comprehensive knowledge in three aspects: (1) prob-lem construction, (2) problem-solving strategies, and (3) pipeline development skills. While effective, this creates a high barrier for deployment across diverse domains, as find-ing experts who excel in all three areas can be challenging.\nIn contrast, RELAY reduces these requirements. Our ap-proach follows a more automated pipeline: training data \u2192 looped model with strong generalization capability \u2192 longer problem construction \u2192 automated reasoning gen-eration \u2192 auto-regressive CoT model training. The human involvement is primarily limited to longer problem construc-tion, eliminating the need for expertise in solution strategies and pipeline development. This reduction in human ex-pertise requirements makes our method more practical and scalable across different domains. Additionally, by leverag-ing the looped models' inherent generalization capabilities rather than manually designed rules, our approach can po-tentially capture more nuanced reasoning patterns that might be overlooked in hand-crafted pipelines."}, {"title": "4. Experiments", "content": "This section presents a comprehensive empirical evaluation of our RELAY framework through a series of experiments designed to address four key research questions:\n\u2022 Q1: How effectively does the looped model with ex-plicit CoT alignment serve as a general-purpose rea-soner across diverse tasks? (Section 4.1)\n\u2022 Q2: What advantages does the looped model with explicit CoT alignment demonstrate in length gener-alization compared to auto-regressive CoT models? (Section 4.1)"}, {"title": "Q3: How can the length generalization capabilities of", "content": "the looped model with explicit CoT alignment be lever-aged to enhance auto-regressive CoT models? (Sec-tion 4.2)\n\u2022 Q4: How reliable are the intermediate reasoning steps generated by the looped model with explicit CoT align-ment? (Section 4.3)\nWe address each question through carefully designed exper-iments, as detailed below."}, {"title": "4.1. Multitask Training", "content": "Following the single-task evaluation discussed in Sec-tion 3.2, we extend our analysis to a multitask learning setting to explore the general reasoning capabilities of three models: the looped model with explicit CoT alignment, the auto-regressive CoT model, and the vanilla looped model. In this setup, we jointly train the models on three repre-sentative reasoning tasks: Arithmetic, Edit Distance (ED), and Longest Increasing Subsequence (LIS), each requiring multi-step reasoning to arrive at accurate final answers. This setting enables a thorough comparison of the models' ability to generalize effectively across diverse tasks.\nFor a detailed description of the tasks, including example inputs, expected answers, and the corresponding Chain-of-Thought (CoT) reasoning steps, please refer to Appendix A.\nExperimental Setup. We conduct experiments on the three tasks: Arithmetic, Edit Distance (ED), and Longest In-creasing Subsequence (LIS), to evaluate the generalization capabilities of the looped model with explicit CoT align-ment in comparison with the auto-regressive CoT model and the vanilla looped model. Training datasets retain the same problem lengths as in Section 3.2: operator counts of < 15 for Arithmetic, input string lengths of < 30 for ED, and sequence lengths < 100 for LIS. Similarly, test datasets are constructed with extended problem lengths of [15, 25], [30, 40], and [100, 120] for Arithmetic, ED, and LIS, respectively, to assess length generalization.\nIn this setup, each model\u2014the looped model with explicit CoT alignment, the auto-regressive CoT model, and the vanilla looped model is trained jointly on all three tasks by prepending a task-specific problem token ([ARI], [ED], [LIS]) to the input sequence, which distinguishes among tasks. All models are evaluated under the same metric, considering only the accuracy of final answer."}, {"title": "Results.", "content": "Figure 4 illustrates the comparative performance of the three models across the three tasks. All models achieve nearly 100% accuracy on all tasks within the train-ing distribution, demonstrating that the looped model with explicit CoT alignment can serve as a general-purpose rea-soning engine capable of handling diverse tasks requiring"}, {"title": "multi-step reasoning. (Q1)", "content": "However, for problems with lengths exceeding the train-ing range, the looped model with explicit CoT alignment and the vanilla looped model significantly outperform the auto-regressive CoT model, showcasing the superiority of loop-based architectures in addressing tasks requiring gen-eralization to longer inputs. Furthermore, the looped model with explicit CoT alignment not only maintains the strong length generalization capability of the vanilla looped model but even surpasses it notably, benefiting from the explicit alignment between CoT reasoning steps and loop iterations. This alignment provides structural guidance that enhances the model's reasoning capabilities over extended lengths as well as the ability to generate explicit intermediate CoT reasoning chains, making it both accurate and interpretable. These results establish the looped model with explicit CoT alignment as both a robust reasoning framework and a gen-erally effective solution for length generalization challenges, outperforming standard auto-regressive CoT models across diverse tasks. (Q2)"}, {"title": "4.2. Enhancing Auto-regressive Model with RELAY-Generated CoT Data", "content": "In this section, we utilize the looped model with explicit CoT alignment trained in Section 4.1 to enhance the perfor-mance of the auto-regressive CoT model via effective data generation. Specifically, we leverage its ability to produce accurate reasoning chains for complex problems exceeding the training lengths. These reasoning chains serve as high-quality data, which are subsequently employed to fine-tune the auto-regressive CoT model.\nExperimental Setup. First, we employ the looped model with explicit CoT alignment to generate CoT rea-soning chains for problems of increased complexity, cover-ing problem lengths of [15, 25], [30, 40], and [100, 120] for Arithmetic, ED, and LIS tasks, respectively. These newly generated data is then merged with the original training dataset, which contains problems within the initial train-ing length. Details of the sample proportions for different"}, {"title": "problem lengths when merging datasets are provided in Appendix D.2.", "content": "Next, we fine-tune the auto-regressive CoT model on this augmented dataset in a single phase. This fine-tuning pro-cess builds upon the well-trained auto-regressive CoT model from Section 4.1, retaining the same model structure while updating the weights with the augmented dataset. This pro-cess enables the model to incorporate longer CoT chains, thereby enhancing its reasoning capabilities on extended sequences.\nResults. Figure 4 presents the accuracy curves of the RELAY-enhanced auto-regressive CoT model across prob-lem lengths for the three tasks. Compared to the base-line auto-regressive CoT model, the auto-regressive CoT model fine-tuned with data generated by RELAY (i.e., by the looped model with explicit CoT alignment) exhibits significant improvements on problems exceeding the orig-inal training length. Notably, its performance approaches and even slightly surpasses that of the looped model with explicit CoT alignment in some cases, while consistently outperforming the baseline auto-regressive CoT model.\nThese results indicate that our RELAY framework effec-tively utilizes the length generalization capabilities of the looped model with explicit CoT alignment to improve the overall performance of auto-regressive model. By gener-ating high-quality CoT reasoning data, RELAY enables the auto-regressive CoT model to better handle problems beyond its original training range, without altering its archi-tecture. (Q3)"}, {"title": "4.3. Evaluating the Reliability of RELAY-Generated Intermediate Reasoning Steps", "content": "This section aims to demonstrate the reliability of CoT chains generated by the looped model with explicit CoT alignment compared to the auto-regressive CoT model's self-generated data. Specifically, we highlight that the gen-erated data from the auto-regressive CoT model, even when the final result is correct, often contains incorrect intermedi-ate steps, which is why utilizing these data fails to improve"}, {"title": "the model's performance in complex problems with longer lengths.", "content": "In contrast, data generated by the looped model with explicit CoT alignment avoids these issues by ensuring both accurate intermediate reasoning steps and the final an-swer, enabling effective fine-tuning of the auto-regressive model and significantly enhancing its performance.\nExperimental Setup. We evaluate the effectiveness of two types of generated data: by the looped model with explicit CoT alignment and the auto-regressive CoT model. This evaluation focuses on two metrics: (1) hit matrix and (2) bit accuracy, which provides a detailed perspective on reasoning steps reliability.\nFor the hit matrix, we select the LIS task as an example due to the structured nature of its reasoning steps. The interme-diate reasoning steps of LIS tasks follows a T \u00d7 11 matrix format, where T corresponds to the number of CoT steps as well as the iteration number of the looped model, and 11 represents the number of tokens per step (10 numbers as prescribed in our dataset, along with one delimeter <sep>). This structured format makes the LIS task particularly suit-able for evaluating and visualizing reasoning step reliability, offering an intuitive representation of the proportion of to-kens at each position that match the ground truth reasoning steps.\nBit accuracy is provided across all three tasks of varying lengths, evaluating token-wise counted accuracy for the whole reasoning step. Comparisons are made between the auto-regressive CoT models fine-tuned by the two types of generated data respectively.\nFor the auto-regressive CoT model self-generated data, we conduct the following experiment under two parallel set-tings, using either a vanilla looped model or ground-truth answers as verifiers. The experiment consists of the follow-ing steps: (1) Use the auto-regressive CoT model to generate CoT chains for long problem lengths. (2) Filter these data by the looped model or ground-truth, retaining only those where the final answers match. (3) The filtered data are then used to fine-tune the auto-regressive CoT model. The fine-tuning process aims to improve the model's ability to"}, {"title": "Accuracy", "content": "generate reasoning trajectories and reach the correct final answer for longer problems.\nMeanwhile, data generated by the looped model with ex-plicit CoT alignment is employed as the fine-tuning dataset for the same initial auto-regressive CoT model checkpoint, under the same fine-tuning parameters and controlled ra-tio of samples with different lengths. Both approaches are evaluated across three tasks with varying lengths to assess performance improvements.\nResults. We evaluate the hit accuracy matrix for the LIS task with a problem length of 105, which corresponds to T = \u2308105/10\u2309 = 11 steps, resulting in an 11 \u00d7 11 ma-trix (We also provide results for problem length of 101 in Appendix B). As shown in Figure 5, data generated by the looped model with explicit CoT alignment achieves consis-tently high token accuracy across all positions, with most values approaching 100%, demonstrating its ability to pro-duce high-quality and reliable data. (Q4) In contrast, the data generated by the auto-regressive CoT model exhibits high token accuracy only in the first few positions, while the accuracy steadily decreases in later steps. Although the delimiter tokens <sep> at the end of each step achieve high accuracy, this simply implies that the auto-regressive CoT model has only captured the basic format of the rea-soning process but fails to predict accurate tokens, which indicates its limited capability to maintain accurate predic-tion throughout the reasoning process for longer problems.\nThe bit accuracy results for the models fine-tuned with dif-ferent datasets across the three tasks (Arithmetic, ED, LIS) and varying problem lengths are provided in Appendix C.\nWe additionally provide the accuracy of the final answer for the auto-regressive CoT model fine-tuned with self-generated data in Figure 4, noted as \u201cAR-CoT + Self Chains & Loop/GT Answers\u201d, corresponding to data filtered by the looped model or ground-truth answers, respectively, which only shows a slight improvement over the baseline model."}, {"title": "5. Conclusion", "content": "This paper introduces RELAY (REasoning through Loop Alignment iteratively), a framework enhancing Chain-of-Thought reasoning by combining looped and auto-regressive Transformers. Our contributions show that (1) a looped Transformer can serve as a general-purpose reasoner with strong length generalization, (2) iteration-wise alignment enables accurate reasoning chain generation beyond training length, and (3) RELAY improves auto-regressive models through high-quality generated reasoning chains. Future work could explore the theoretical foundations of looped Transformers' length generalization and extend RELAY to broader language tasks."}, {"title": "Impact Statement", "content": "This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here."}, {"title": "A. Task Descriptions", "content": "Below, we present the detailed descriptions of each task from Feng et al. (2024), including examples of inputs, expected answers, and the corresponding Chain-of-Thought (CoT) reasoning steps used to derive the final answers."}, {"title": "1. Arithmetic.", "content": "This task involves computing the answer of arithmetic expressions containing numbers, basic operations (+, -, \u00d7, \u00f7, =), and brackets. For example:\n\u2022 Input: (6+9)\u00f7(7+2\u00d75-4 \u00d7 3) =\n\u2022 CoT Steps:\n15\u00f7(7+2\u00d75 - 4 \u00d7 3) =\n15 \u00f7 (7 +10 - 4 \u00d7 3) =\n15 \u00f7 (17-4 \u00d7 3) =\n15 \u00f7 (17-12) =\n15\u00f75=\n\u2022 Answer: 3"}, {"title": "2. Edit Distance (ED).", "content": "This task requires computing the minimum number of operations (insert, delete, or replace) needed to transform one sequence into another. The input consists of two sequences separated by a delimiter |:\n\u2022 Input: otml|ottml <sep>\n\u2022 CoT Steps:\n0 2 4 6 7\n2 0 2 4 6\n4 2 3 2 4\n6 4 5 4 2,\n\u2022 Answer: 2\nEach row corresponds to the edit distance matrix, and the final answer is the edit distance."}, {"title": "3. Longest Increasing Subsequence (LIS).", "content": "This task identifies the length of longest strictly increasing subsequence in a numerical sequence. The input is a sequence of integers followed by a delimiter <sep>:\n\u2022 Input: 103 110 145 217 233 18 30 82 141 150 159 161 167 239 <sep>\n\u2022 CoT Steps:\n1 2 3 4 5 1 2 3 4 5 <sep>\n6 7 8 9 9 9 9 9 9 9 <sep>\n\u2022 Answer: 9\nHere, each CoT step represents an intermediate computation in the dynamic programming process, folded into fixed-size groups (10 numbers per step in our setting) to align with the model structure. If the last group has fewer than 10 numbers, the last number is repeated until the group size reaches 10."}, {"title": "B. Hit Matrix for LIS Task with Length 101", "content": "We also analyze the hit accuracy matrix for the LIS task with a problem length of 101, corresponding to T = \u23081"}]}