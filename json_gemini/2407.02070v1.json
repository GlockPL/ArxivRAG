{"title": "Latent Diffusion Model for Generating Ensembles of Climate Simulations", "authors": ["Johannes Meuer", "Maximilian Witte", "Claudia Timmreck", "Thomas Ludwig", "Christopher Kadow"], "abstract": "Obtaining accurate estimates of uncertainty in climate scenarios often requires generating large ensembles of high-resolution climate simulations, a computationally expensive and memory inten- sive process. To address this challenge, we train a novel generative deep learning approach on ex- tensive sets of climate simulations. The model consists of two components: a variational autoen- coder for dimensionality reduction and a denois- ing diffusion probabilistic model that generates multiple ensemble members. We validate our model on the Max Planck Institute Grand Ensem- ble and show that it achieves good agreement with the original ensemble in terms of variabil- ity. By leveraging the latent space representation, our model can rapidly generate large ensembles on-the-fly with minimal memory requirements, which can significantly improve the efficiency of uncertainty quantification in climate simulations.", "sections": [{"title": "1. Introduction", "content": "Climate simulations are essential tools for understanding Earth system processes and supporting diverse applications. However, these simulations exhibit internal variability due to chaotic variability and unknown forcings. Ensemble- based approaches, such as the Max Planck Institute (MPI) Grand Ensemble (Maher et al., 2019), address these uncer- tainties by providing a collection of simulations with varied initial conditions and model parameters. Nevertheless, these ensembles are computationally expensive and often limited in scope.\nMachine learning has emerged as a promising complemen- tary tool, capable of uncovering patterns and correlations. Reichstein et al. (2019) discuss the growing role of deep learning in improving climate science, highlighting its po- tential to identify non-linear relationships between climate variables. Their work illustrates how deep learning can reveal previously hidden patterns that improve climate sim- ulations. Ensemble-based learning, as explored by (Lorenz et al., 2018), further improves predictive accuracy by weight- ing climate models based on their historical performance. This approach allows better integration of the strengths of different models, leading to more robust predictions.\nRecent work using generative adversarial networks (GANs) shows promise in climate modelling by generating realistic weather simulations that match high-resolution numerical models. Brochet et al. (2023) demonstrate how GANs can provide multivariate emulation of numerical weather pre- dictions. However, while GANs are powerful in generating plausible simulations, ofthen they suffer from mode col- lapse, where the generator produces limited types of output and fails to cover the diversity of the training data. This deficiency is particularly problematic in climate modelling, where robust sampling from the distribution of climate sim- ulations is crucial for uncertainty quantification.\nDenoising Diffusion Models (Ho et al., 2020) solve this problem by sampling from a Gaussian noise distribution and minimising the KL divergence between the distribu- tion of the predictions and the training data. This allows stable training and effective uncertainty quantification. For example, Rasul et al. (2021) use an autoregressive diffusion model to perform multivariate probabilistic forecasting, sig- nificantly improving the ability to simultaneously predict different climate-related variables. Another notable appli- cation is the use of generative diffusion models to capture the inherent uncertainties in weather forecasting with Gen- Cast by Price et al. (2023). By creating an ensemble of forecasts, GenCast provides a range of probable weather scenarios, which is crucial for medium-range forecasting. Their approach helps in better capturing the variability and uncertainties associated with weather patterns.\nWe address the challenges of ensemble climate modelling with a machine learning technique based on generative diffu- sion models. We generate temporally coherent simulations conditioned on a single climate simulation. With this ob- jective, we can efficiently sample an implicit representation of the distribution that specifies the uncertainty conditioned"}, {"title": "2. Methodology", "content": "2.1. Latent Diffusion Model\nOur model (see 2) uses a diffusion process in latent space (Rombach et al., 2022) generated by a pre-trained varia- tional autoencoder (VAE) (Kingma & Welling, 2013). This approach significantly reduces spatial complexity while pre- serving essential features of the climate simulations. The pre-trained VAE, described in detail in the appendix A, com- presses each simulation x into a lower-dimensional latent space z using the encoder E:\n$$z = E(x)$$\nThe VAE is unaware of the time dimension and treats each timestep independently. The diffusion model, detailed in Appendix B, is trained on the latent representations of the climate simulations, conditioned on a single simulation xc being mapped into latent space, giving a general focus on long-term trends in climate evolution: $z_c = E(x_c)$. The\nprediction task is defined as the difference between a target latent z and the conditioned latent simulation zc, where zy represents the residual that the diffusion model has to learn:\n$$z_y = z - z_c$$\nDuring training, the diffusion model is optimised to pre- dict this residual in latent space. The diffusion model is a U-Net (Ronneberger et al., 2015) using BigGAN (Brock et al., 2018) residual blocks followed by down-sampling convolutions in the encoder and up-sampling convolutions in the decoder. After training, during inference, we use the diffusion model (DDM) to generate a large number of residuals zy in the latent space:\n$$z_y = DDM(z_c)$$\nTo speed up the inference time of the diffusion model, we apply a denoising diffusion implicit sampler (Song et al., 2020), which provides a more efficient generation process by using deterministic steps. The final simulations are re- constructed by adding the generated residuals back to the"}, {"title": "2.2. Sequence Generation", "content": "We explore two approaches to generating long sequences in the latent space:\n2.2.1. AUTOREGRESSIVE PREDICTION\nThis approach iteratively generates long sequences by pre- dicting the next latent state based on a window of previous states and the conditioned simulation zc. Given an input sequence $z_{t-n+1:t} = [z_{t-n+1}, z_{t-n+2},..., z_t]$, the model predicts:\n$$z_{t+1} = DDM(z_{t-n+1:t}, z_c)$$\n2.2.2. TRANSFORMER-BASED ATTENTION MECHANISM\nInspired by natural language processing (Vaswani et al., 2017), this approach uses a transformer to process the entire time domain at once. This allows parallel processing and accelerates sequence generation. Each transformer block sequentially applies spatial attention, focusing on spatial patterns, and temporal attention, focusing on temporal cor- relations, following a residual block. To manage memory costs, we implement a cascaded transformer mechanism. The higher levels of the diffusion network focus on small time scales, capturing detailed short-term patterns. The lower levels deal with overall time scales, ensuring a com- prehensive understanding of long-term trends. A detailed description of the model can be found in Appendix B. The transformer processes the entire sequence in a single step and is not additionally conditioned on an initial state:\n$$z = DDM(z_c)$$"}, {"title": "3. Results", "content": "Our model is trained and evaluated on the 200 ensemble members from the historical simulations of the MPI Grand Ensemble (Maher et al., 2019). This ensemble covers the pe- riod from 1850 to 2005 with a monthly temporal frequency and a spatial resolution of 1.8\u00b0 (192x96 grid). The focus of this analysis is on surface temperatures.\nDuring training, we used one member as input for condi- tional simulation. For model evaluation, we used another member for conditioning during inference. We trained on the remaining 198 members over the entire time range. After training, we generated 100 new artificial ensemble members. These generated members are then analysed to compare their annual mean surface temperatures over the entire historical period with the first 100 members of the original MPI Grand Ensemble. The comparison focuses on two key statistical measures: the ensemble mean and the spread in the temper- atures. Figure 3 shows the results of our transformer-based model. While the ensemble mean contains signatures of the forced response to climate change, the ensemble standard deviation represents the internal variability of the climate system.\nThe ensemble mean and variability of the generated mem- bers closely mirror those of the original ensemble members with respect to annual spatially averaged temperatures. This highlights the ability of the model to reproduce central ten- dencies such as the global warming trend and global cooling following major volcanic eruptions (1883, 1963, 1982 and 1991). This validates the ability of our machine learning ap- proach to reproduce complex climate dynamics. Appendix C also provides an analysis of uncertainty quantification for an unseen time range, where the autoregressive model was trained on data from 1850 to 1975 only and iteratively generated simulations for 1975 to 2000.\nIn a further analysis, we looked specifically at the El Ni\u00f1o- Southern Oscillation (ENSO) (Trenberth, 1997) timelines of a selected member to assess the model's ability to cap- ture more localised and medium-term climate phenomena. Figure 1 shows the anomaly maps of the strongest El Ni\u00f1o event from an original simulation and a selected member, which was generated by our autoregressive model. Although the El Ni\u00f1o appears less pronounced in our generated simu- lation, the model is able to generate temporally and spatially coherent El Ni\u00f1o patterns. This can be also seen in Figure 4, which shows the ENSO timeline from 1950 to 2005. The generated data show a realistic pattern of recurring ENSO events, similar to those observed in real climate data. This similarity confirms that our model not only maintains gen-"}, {"title": "4. Conclusion and Outlook", "content": "We present a latent diffusion model for numerical climate model emulation, highlighting its ability to reproduce both global and local climate phenomena. Our results show that the model effectively captures central tendencies such as the global warming trend and significant cooling events fol- lowing major volcanic eruptions. Furthermore, the model successfully generates coherent temporal and spatial pat- terns, such as the El Ni\u00f1o-Southern Oscillation, even when trained on limited historical data.\nWe carried out a detailed analysis of two different diffu- sion models: An autoregressive prediction approach and a transformer-based approach. When evaluated on the MPI Grand Ensemble, the generated ensemble members of the transformer-based approach show remarkable agreement with the original ensemble in terms of mean and variabil- ity, confirming the robustness and reliability of the model. The autoregressive approach showed the ability to generate realistic climate patterns over extended periods, including unseen time spans, and good performance in temporally coherent simulations. Future work will investigate the com- bination of the two techniques to leverage the strengths of both.\nThe promising results of our approach open up several av- enues for future research and development. Future work can extend the training data to include more recent years, higher spatial resolutions and multiple climate models. This would allow the model to capture more detailed and recent climate phenomena, improving its applicability to contemporary climate studies. In addition, the inclusion of more climate variables such as precipitation, sea level pressure and ocean currents could provide a more comprehensive understanding of climate dynamics and improve the predictive capabilities of the model. The techniques and insights from this work could be applied to other fields requiring time-series pre- diction and uncertainty quantification, such as economics, epidemiology and energy systems. A deeper exploration of uncertainty quantification would provide more insight into the confidence and reliability of predictions, which is crucial for policy making and scientific research.\nOur latent diffusion model not only quantifies uncertainty, but also provides real scenarios that support the uncertainty quantification. Unlike traditional methods, which often pro- vide abstract uncertainty metrics, our approach generates diverse and plausible climate simulations, providing con- crete scenarios for better understanding and decision mak- ing. Compared to numerical models for ensemble genera- tion, our method could provide a much less computationally expensive alternative."}, {"title": "A. Variational Autoencoder", "content": "The Variational Autoencoder (VAE) is based on Rombach et al. (2022) and focuses on perceptual image compression. The encoder (E) encodes an image x \u2208 $R^{H \\times W \\times 3}$ into a latent representation z = E(x), where z \u2208 $R^{h \\times w \\times c}$. The decoder D reconstructs the image from the latent representation, giving x = D(z) = D(E(x)). The compression factor is given by f = $\\frac{HW}{hw}$. In our setup, we use a compression factor of f = 8 and a latent dimension of c = 4, giving us a total compression of 16.\nThe given objective $L_{VAE}$ combines the reconstruction loss, adversarial loss, and Kullback-Leibler divergence (KL- divergence) regularization for training the VAE with adversarial training. The reconstruction loss $L_{rec}$ measures the $L_2$ distance between the original image x and the reconstructed image x to produce images that are close to the input in pixel space:\n$$L_{rec} = ||x - \\tilde{x}||_2$$\nThe adversarial loss ensures that the reconstructed images are perceptually similar to the real images by adding a discriminator D:\n$$L_{adv} = E_{x\\sim p_{data}(x)} [log D(x)] + E_{\\tilde{x}\\sim p_{model}(\\tilde{x})} [log(1 - D(x))]$$\nThe KL divergence regularizes the latent space by making the distribution of the encoded latent variables $q(z|x)$ close to a prior distribution $p(z)$, in our case a standard normal distribution. The overall objective for the VAE with adversarial training is given by:\n$$L_{VAE} = E_{x\\sim P_{data}(x)} [\\lambda_{rec}||x - \\tilde{x}||^2_2 + \\lambda_{adv}(E_{x\\sim p_{data}(x)} [log D(x)] + E_{\\tilde{x}\\sim p_{model}(x)} [log(1 - D(x))]) + \\lambda_{KL}KL(q(z|x)||p(z))]$$\nWe evaluated the performance of our VAE independently of the overall setup to ensure that the diffusion model was provided with high quality latent data. To do this, we mapped our complete data set of simulations into latent space using the encoder E and reconstructed all the data using the decoder D. Our VAE achieved a pixel-wise RMSE of 0.25\u00b0C. Figure 5 also shows the comparison of the spatial annual mean and spread from the original and reconstructed datasets over the full time range."}, {"title": "B. Denoising Diffusion Model", "content": "Diffusion models generate images by reversing a gradual noise process (Sohl-Dickstein et al., 2015). The process starts with pure noise and iteratively denoises it to produce a high-quality image. The main steps in this process are a forward and a backward diffusion process. The forward process gradually adds Gaussian noise to the data over a series of diffusion steps. Starting from the original image $x_0$, noise is added at each diffusion step t to produce a noisy image $x_t$. This process can be described by the following equation, where $\u03b2_t$ is a variance schedule that controls the amount of noise added at each step:\n$$q(x_t|x_{t-1}) = N(x_t; \\sqrt{1 - \u03b2_t}x_{t-1}, \u03b2_tI)$$\nThe reverse diffusion process is learned by training a neural network to predict the noise component added at each step. The model e predicts the noise given the noisy image xt and the diffusion step t. The objective is to minimise the difference between the predicted noise and the true noise, in our case using a mean square error loss:\n$$L = E_{t,x_0,\\epsilon} [||\\epsilon - \\epsilon_\\theta(x_t, t)||^2]$$\nThe reverse process can then generate $x_{t-1}$ from xt using the learned model, where $\u03bc_\\theta$ and $\u03a3_\\theta$ are functions of the predicted noise:\n$$p_\\theta(x_{t-1}|x_t) = N(x_{t-1}; \u03bc_\\theta(x_t, t), \u03a3_\\theta(x_t, t))$$\nOur model is based on the work of Dhariwal & Nichol (2021) and implements a UNet architecture with residual blocks as described by Brock et al. (Brock et al., 2018). Similar to the original implementation used for image synthesis, we apply spatial attention mechanisms in the upper layers of the model. To address the time cost associated with iterative inference over large data sequences, our model operates in the latent space. For autoregressive prediction sequence processing, the temporal dimension of the latent simulations is encoded within the channel dimension of the model.\nThe transformer-based component of our model processes temporal information in an additional dimension. Each transformer block consists of three parts: a spatial attention mechanism, a temporal attention mechanism, and a multilayer perceptron (MLP). The core concept of the transformer (Vaswani et al., 2017) is the self-attention mechanism, which allows the model to evaluate the importance of different regions in the spatial dimension or time steps in the temporal dimension. The data is divided into patches (either spatial or temporal) and transformed into three vectors: Query (Q), Key (K) and Value (V). The size of the temporal patches varies with the depth of the network; higher layers consider smaller timescales, while the bottleneck layer includes all timescales. Attention scores are computed by taking the dot product of the query vector with all key vectors, followed by a softmax function to obtain weights. These weights are then used to compute a weighted sum of the value vectors:\n$$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$\nInstead of performing a single attention function, the transformer uses multiple attention heads to capture different aspects of the relationships between elements. Each head has its own set of Q, K and V matrices, and their outputs are concatenated and linearly transformed. In our model, the number of attention heads increases with layer depth, starting with fewer heads in the early layers and reaching a maximum number in the bottleneck layer. Following the multi-head attention mechanisms, a residual connection MLP network is applied. This consists of a layer normalisation, a linear layer and a Gaussian Error Linear Unit (GELU) activation function."}, {"title": "C. Extended Analysis", "content": "We investigated the generalisability of our model to unseen time periods. The channel-based autoregressive diffusion model was trained on all historical MPI-GE members from 1850 to 1975. We then conditioned the trained model on a single simulation from 1975 to 2000, generating 100 members. Figure 6 shows the results. While the mean and spread of the generated simulations do not perfectly match the original ones, the simulations successfully capture the ongoing global warming trend despite not being trained on this period. In addition, the generated simulations strongly reflect the major volcanic eruptions of 1982 and 1991."}]}