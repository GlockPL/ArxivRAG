{"title": "Deep Learning for Early Alzheimer Disease Detection with MR\u012a Scans", "authors": ["Mohammad Rafsan", "Tamer Oraby", "Upal Roy", "Sanjeev Kumar", "Hansapani Rodrigo"], "abstract": "Alzheimer's Disease is a neurodegenerative condition characterized by dementia and impairment in neurological function. The study primarily focuses on the individuals above age 40, affecting their memory, behavior, and cognitive processes of the brain. Alzheimer's disease requires diagnosis by a detailed assessment of MRI scans and neuropsychological tests of the patients. This project compares existing deep learning models in the pursuit of enhancing the accuracy and efficiency of AD diagnosis, specifically focusing on the Convolutional Neural Network, Bayesian Convolutional Neural Network, and the U-net model with the Open Access Series of Imaging Studies brain MRI dataset. Besides, to ensure robustness and reliability in the model evaluations, we address the challenge of imbalance in data. We then perform rigorous evaluation to determine strengths and weaknesses for each model by considering sensitivity, specificity, and computational efficiency. This comparative analysis would shed light on the future role of AI in revolutionizing AD diagnostics but also paved ways for future innovation in medical imaging and the management of neurodegenerative diseases.", "sections": [{"title": "Author summary", "content": "Why was this study done?\n\u2022 Alzheimer's disease is the most common cause of dementia, affecting millions worldwide, and yet the diagnosis remains challenging in the early stage.\n\u2022 The state-of-the-art methods in diagnosis include MRI scans and neuropsychological tests that require significant expertise and time.\n\u2022 The current study focuses on deep learning models and their possible application to improving the accuracy of early-stage Alzheimer's disease diagnosis."}, {"title": "Introduction", "content": "Alzheimer's disease is a progressive neurodegenerative disorder and the most common cause of dementia among older adults, affecting memory, thinking, and behavior. According to the World Health Organization, AD accounts for 60-70% of dementia cases worldwide, making it a significant public health concern [1]. Early diagnosis and monitoring of AD are important in managing disease progression and planning appropriate treatment strategies. The diagnosis of AD has conventionally been made by clinical evaluations, including neuropsychological testing and neuroimaging techniques such as MRI scans. While these methods are effective, they demand a great deal of expertise and time for analysis. AD is one of the most important challenges in the field of neurodegenerative diseases, with continuous disturbance in cognitive decline and loss of neurons. As the most common cause of dementia, AD significantly affects not only the quality of life of those concerned but also burdens health-care systems and caregivers all over the world. For this reason, the establishment of more effective therapies depends essentially on early detection to properly manage its course and attenuate its impacts.\nIn the last few years, AI, especially Deep Learning, has emerged as a force of transformation in many fields, including healthcare and medical imaging. These DL models, known for their capability of learning complex patterns from big datasets, have"}, {"title": "Literature Review", "content": "Accurate medical picture categorization is a challenging undertaking due to the intricate process of acquiring medical data sets [14]. Medical data sets, in contrast to other types of data sets, are created by qualified professionals and include confidential and sensitive patient information that is not allowed to be made public. Because of this, organizations and institutions that provide medical data sets, such as the Alzheimer's Disease Neuroimaging Initiative (ADNI) [13] and the OASIS [10], have screening procedures for accessing their data sets. These procedures require the researcher to fill out an application and agree to terms, which restricts the researcher's ability to use the data only for research purposes [15], [16]. Since it is difficult to assemble a data set with an equal amount of participants with health and illness samples, medical data sets are intrinsically extremely unbalanced. The methods for solving this issue are somewhat difficult by themselves [17].\nEskildsen et al. [18] employed cortical thickness measurements to determine distinct patterns of atrophy, and attributes were picked from these patterns to predict AD in patients with moderate cognitive impairment (MCI). A deep learning-based technique for evaluating the Mini-Mental State Examination (MMSE) using resting-state functional"}, {"title": "Materials and methods", "content": "In this section are the details of the methodologies adopted in this research deal with the effectiveness of DL techniques in early detection through the use of neuroimaging data. Early markers of AD in imaging data are complex and require a strong, advanced model to make reliable diagnostic predictions."}, {"title": "Data Description", "content": "The present work is based on data from the Open Access Series of Imaging Studies OASIS [11], a publicly accessible repository with MRI data from nondemented and from subjects with different stages of AD. In summary, the dataset comprises neuroimaging carried out on 1378 subjects (ages 18 - 96, median = 54 years, IQR: 51 years), separated according to the Clinical Dementia Rating (CDR) that varies from non-demented subjects to moderate AD cases. For each subject, various images are available; among them, one can find an average image, that is, a motion-corrected coregistered average of all available data. From the OASIS raw data, the original .img and .hdr files were converted into Nifti format.nii by the free, non-commercial FSL (FMRIB Software Library). The MRI scans in .nii format were then converted into.jpg files using NiBabel (Python), a library of Python programming language designed to make the work of reading and manipulating Nifti format easy. Using NiBabel, one may extract slices of data and save them in image formats such as .jpg.\nClinical diagnosis was made according to the CDR scale and expressed in terms without resorting to psychometric tests and excluding other causes of dementia [12]. Diagnosis of AD required evidence of progressive loss of memory and decline in other cognitive functions. CDR provides scores for memory, orientation, judgment, community affairs, home and hobbies, and personal care. These scores then give a global CDR: 0 represents no dementia, and the scores 0.5, 1, 2 and 3 correspond to very mild, mild, moderate and severe dementia, respectively [10]. Given the abovementioned CDR scores, the study identifies four classes of dementia, which are respectively, NOD, VMD, MD and MOD, giving rise to a total of 11655 images to be considered for the study. The distribution of the 11,655 images across categories of dementia is given below: 'Mild Dementia' comprising 1,573 images, 'Moderate Dementia' consists of 124 images, 'Non-Demented' comprises 5,849 images, and 'Very Mild Dementia' accounts for 4,109 images."}, {"title": "Deep Neural Networks (DNNs)", "content": "Deep neural networks are a class of machine learning algorithms that learn to perform tasks by learning from examples in a way inspired by the thinking process of a human mind. Any feed-forward network with a number of hidden layers is called DNN. DNNS would simply mean multiple layers of artificial neurons or nodes, which are math functions emulating the neural activities of the human brain. Each additional layer increases the feature extraction and processing on the input data, with early layers identifying simple features and deeper layers recognizing complex patterns; thus, it learns from a wide array of data and makes decisions."}, {"title": "Convolutional Neural Networks (CNNs)", "content": "As the subclass of deep neural networks, CNN usually fits in with the data of grid-like topology, such as an image-one of the simplest 2-D arrays of pixels. Unlike other deep neural networks, CNNs make use of special layers that effectively learn spatial hierarchies and patterns. The usual CNN architecture has the following general mathematical representation:\n1. Convolutional Layer: Applies a convolution operation between the input data X and a set of learnable filters or kernels K. For an input image $X \\in R^{H \\times W \\times C}$ and a filter $K \\in R^{k \\times k \\times C}$, the convolution operation for a single filter is defined as:\n$Z_{ij} = (K * X)_{ij} = \\sum_{m=1}^{k} \\sum_{n=1}^{k} K_{mn}X_{i+m-1,j+n-1}$    (4)\nwhere $Z \\in R^{(H-k+1)\\times(W-k+1)}$ is the output feature map, * denotes the convolution operation, H and W are the height and width of the input image, C is the number of channels, and k is the filter size.\n2. Pooling Layer: Reduces the spatial dimensions (width and height) of the input volume for the next convolutional layer. A common pooling operation is max pooling with a pooling window of size p \u00d7 p, which is defined as:"}, {"title": "Bayesian CNN", "content": "The strong backbone of CNNs, especially their prowess at processing and interpreting spatial information, laid a very firm foundation for further innovations into neural network architectures. A recent innovative extension of this family is a Bayesian Convolutional Neural Network, BayesianCNN. While traditional CNNs use point estimates for weights at the time of inference, BayesianCNN introduces probabilistic weights that allow the network to estimate uncertainty in its prediction.\nBayesianCNN introduces probabilistic approaches to the weights in the network, enabling the model to express uncertainties. This is approached using Variational Inference (VI) and, specifically, through the methodology of Bayes by Backprop itself, which approximates intractable true posterior distributions over weights with variational distributions.\nVI is an extremely powerful way of approximating Bayesian posterior distributions, which are usually intractable. The key idea of VI is to find an approximate distribution to the true weighted posterior distribution w and data, Dis p(w|D) with a more tractable distribution $q_{\\phi}(w)$, where $q_{\\phi}(w)$ is the variational distribution of the weights, parameterized by \u00f8. This approximation minimizes the Kullback-Leibler (KL) [35] divergence between $q_{\\phi}(w)$ and the true posterior, effectively turning the inference problem into an optimization problem.\nIn general, the objective of VI is defined as:\n$L(\\phi) = E_{q_{\\phi} (w)} [logp(D|w)] \u2013 D_{KL}(q_{\\phi}(w) || p(w))$  (8)\nwhere $L(\\phi)$ is the variational lower bound, or evidence lower bound (ELBO), the expectation term $E_{q_{\\phi}(w)} [logp(D|w)]$ evaluates the likelihood of the data under the current model parameters, promoting the accuracy of predictions. p(D\u2758w) is the likelihood of the data given the parameters, p(w) is the prior distribution over the weights and KL represents the Kullback-Leibler divergence between the variational distribution and the prior. For the equation 8, the closer KL diverges to '0', minimum $L(\\phi)$ value is obtained.\nSo, the variational objective, i.e., the loss function of a Bayesian CNN, is formulated to measure how well the model adheres to the data while also constraining the parameters in a Bayesian framework. This objective combines the likelihood of the observed data given the model's parameters with the KL divergence between the variational distribution of the weights and its prior distribution. This serves as a regularizer that discourages the distance of the variational distribution to the prior knowledge, taken into account to the prior knowledge while keeping overfitting in check by driving the weight distribution to be simple. So, including the data D, we can rewrite equation 8 as following:\n$L(\\phi; D) = E_{q_{\\phi}(w)} [logp(D|w)] \u2013 D_{KL}(q_{\\phi}(w|D) || p(w|D))$    (9)\nIn practice, VI is implemented using the Stochastic Gradient Variational Bayes (SGVB) technique, which employs stochastic gradient descent to optimize $L(\\phi; D)$. The gradients are estimated using samples from $q_{\\phi}(w|D)$, allowing the use of mini-batch optimization methods common in machine learning. The general expression for a gradient update is given by:\n$\\phi \\leftarrow \\phi \u2013 \\eta \\nabla_{\\phi}\u00a3(\\phi; D),$  (10)\nwhere $\\eta$ is the learning rate. The gradients are approximated using:\n$\\nabla_{L(\\phi; D)} \\approx \\frac{1}{M} \\sum_{i=1}^{M} [log q_{\\phi} (w^{(i)} |D) (log p(D|w^{(i)}) \u2013 log q_{\\phi} (w^{(i)} |D) + log p(w^{(i)}|D))]$    (11)\nwith w(i) sampled from $q(w|D)$, and M being the number of samples used to estimate the gradient."}, {"title": "U-Net", "content": "While BayesianCNNs were quite robust in handling the uncertainties within deep learning models, there are applications-for instance, medical image segmentation-that require architectures which represent fine-grained spatial hierarchies with high preciseness. U-Net, originally designed for biomedical image segmentation, addresses the requirements by introducing a very unique architecture that remarkably improved the effectiveness of localizing and segmenting objects within an image. The following section describes the U-Net architecture, its design, and operation, including reasoning as to why it is particularly suited to tasks such as segmenting complex anatomical structures in medical imaging.\nU-Net Architecture\nU-Net's architecture at Fig 3 is an advanced encoder-decoder network that uses skip connections to enhance feature integration across the network, facilitating precise localization and context incorporation.\nEncoder Path\nThe encoder, or the contraction path, comprises several convolutional and pooling layers designed to capture the hierarchical features of the input image. Each layer in the encoder can be represented as:\n$C_{i} = P(ReLU(C'(W_{i-1} * X_{i-1} + b_{i-1})))$  (27)\nwhere Ci is the output of the i-th convolutional layer, P denotes a max-pooling operation, ReLU is the rectified linear activation function, the letter C stands for the convolution operation, which is a fundamental building block of the U-Net model, allowing it to extract hierarchical features from the input images. The Wi-1 and bi\u22121 are the weights and biases of the convolutional layer, Xi-1 is the input to the i-th layer, and * represents the convolution operation.\nDecoder Path"}, {"title": "Results", "content": "In this section we show the experimental setup, the details of the implementation, and the results of the extensive evaluation of our 3 DL models on the OASIS dataset, which has been balanced by using the SMOTE-Tomek \"Data Pre-processing & Data Balancing with SMOTE-Tomek\" technique to mitigate issues related to class imbalance. Each model's performance is tested based on a variety of metrics that include accuracy, precision, recall, f1_score, and area under the ROC curve (AUC), which together present a full view of the capabilities and limitations of dealing with balanced neuroimaging data. The following subsections will describe in detail the balancing of the data using SMOTE-Tomek, the DL models, their training procedures, and the resultant analyses."}, {"title": "Data Pre-processing & Data Balancing with SMOTE-Tomek", "content": "Synthetic Minority Over-sampling Technique (SMOTE) and Tomek links to solve class imbalance problem in machine learning data. SMOTE, initially introduced by Chawla et al. [38] in 2002, is a well-regarded method for oversampling the minority class by creating synthetic samples rather than simply duplicating existing samples. This method is useful to achieve better generalization than memorization during the training of the model.\n(In contrast), Tomek links [39] are employed for undersampling, by detecting pairs of closely related instances of opposite class and removing majority class instances from such pairs. This technique, introduced by Tomek, who first described it in 1976 [40], is especially useful for cleaning overlapping between class data points improving the performance of the classifier by making the decision boundary more discriminative.\nIt increases minority class representation via synthetic sample generation (SMOTE), and in the mean time refines training dataset that removes Tomek links that are either noise or borderline samples. The integration of this combination of techniques leads to a more balanced dataset with which to train the model, which leads to improved model performance, especially in terms of both accuracy and the stability of the classification boundaries. This dual approach not only tackles the problem of imbalanced classes more effectively but also enhances the quality of the synthetic samples produced, leading to improved learning outcomes in predictive modeling tasks."}, {"title": "Results of CNN, BayesianCNN & U-Net Models", "content": "The models under investigation include the CNN based Alzheimer Disease Detection Network (ADD-Net) model, BayesianCNN model & U-Net model."}, {"title": "Masking", "content": "Masking, when applied to U-net, means applying a mask which allows only some of the pixels in the output image to contribute towards the loss during training. This is important in medical images where only some regions are relevant, say, tissues or organs, and other areas should be ignored. This more acts like the ground truth. Masking will ensure that the model pays attention to only relevant parts of an image in the process of yielding more accurate, highly relevant segmentation results.\nOne limitation concerning our U-Net model is that we have skipped the masking part here. The reason behind this is that most of the time, masking is done with manual FLAIR abnormality through expert medical officials. If proper masking is not done, then the model may learn the irrelevant features of the image that decrease the precision in segmentation. It overfits to noise and irrelevant details, thinking that these are essential features, hence compromising the generalization capability on unseen data.\nAlso, if the same images are used as inputs and masks without actual masking, then it will lead the model to learn everything about the image, which may be irrelevant. It would mess up the model by telling it to focus on which features and ultimately deteriorate the performance it gives for segmentation as it couldn't highlight the important boundaries and features during the training."}, {"title": "Discussion and Conclusion", "content": "The study offers a comparative study of two different models, ADD-Net and BayesianCNN, by using SMOTE-Tomek balanced datasets. An interpretable network in which Grad-CAM helps identify the key areas responsible in brain scan images characterizes ADD-Net. Batch normalization, adding further convolution layers, and the dropout enhancement have yielded greater accuracy and robustness with some modifications. BayesianCNN addresses uncertainty related to medical images through variational inference and dual convolution operations on the other side. While promising, its application currently is confined to the Kaggle brain MRI dataset; it needs further adaptation to the OASIS dataset for wider clinical applications.\nBoth models have challenges that include computational demands and a risk of overfitting due to synthetic oversampling techniques such as SMOTE-Tomek. How"}, {"title": "Supporting information", "content": "As we already discussed in Section Architecture & Result of ADD-Net, the Gradient-weighted Class Activation Mapping (Grad-CAM) is used to generate heatmaps on the brain images. These heatmaps help in visualizing which parts of the brain images the model is focusing on for its predictions, potentially revealing regions of interest for further analysis or interpretation in medical diagnosis. Here, in summary, the color coding across all Grad-CAM images is consistent:\n\u2022 Red: Most important regions.\n\u2022 Yellow: Moderately important regions.\n\u2022 Green and Blue: Less important regions.\nThe following visualizations illustrate the brain areas the models focus on for their predictions, highlighting potential regions of interest for further analysis or interpretation in medical diagnosis."}]}