{"title": "A Metric for the Balance of Information in Graph Learning", "authors": ["Alex O. Davies", "Nirav S. Ajmeri", "Telmo de Menezes e Silva Filho"], "abstract": "Graph learning on molecules makes use of information from\nboth the molecular structure and the features attached to that\nstructure. Much work has been conducted on biasing either\ntowards structure or features, with the aim that bias bolsters\nperformance. Identifying which information source a dataset\nfavours, and therefore how to approach learning that dataset,\nis an open issue. Here we propose Noise-Noise Ratio Differ-\nence (NNRD), a quantitative metric for whether there is more\nuseful information in structure or features. By employing iter-\native noising on features and structure independently, leaving\nthe other intact, NNRD measures the degradation of infor-\nmation in each. We employ NNRD over a range of molecular\ntasks, and show that it corresponds well to a loss of informa-\ntion, with intuitive results that are more expressive than sim-\nple performance aggregates. Our future work will focus on\nexpanding data domains, tasks and types, as well as refining\nour choice of baseline model.", "sections": [{"title": "Introduction", "content": "Graphs are an intuitive way to represent data in many fields\nof industry and science, including chemistry (Gilmer et al.\n2017), infrastructure planning (Khodayar et al. 2019), biol-\nogy (Li, Huang, and Zitnik 2022) and social network anal-\nysis (Davies, Ajmeri, and Silva Filho 2022). Here we focus\non molecular graphs, which have seen a great deal of re-\nsearch and use (G\u00f3mez-Bombarelli et al. 2018; Khemchan-\ndani et al. 2020; Popova et al. 2019). Tasks on molecular\ngraphs typically consist of learning to predict a property, for\nexample solvation energy, from a set of molecular graphs.\nMolecular graphs are defined by both structure and fea-\ntures. Graph learning can then be framed as the process of\nextracting useful information from graphs for a given tar-\nget. Structure contains atoms and bonds, defining the con-\nnections between atoms within the graph. Features then give\ninformation about individual atoms and bonds.\nThe degree to which Graph Neural Network (GNN) mod-\nels rely on either structural or feature information during\nlearning is highly varied. Some works target structural learn-\ning specifically, aiming to improve performance by biasing\ntowards the information encoded in patterns between nodes\n(Chen, Coskunuzer, and Gel 2021; Horn et al. 2021). Other\nworks make the point that the optimal solution may not in-\nclude graph structure at all (Bechler-Speicher et al. 2024).\nThere are currently no metrics for whether a dataset and\nmodel combination leans towards structure or feature infor-\nmation, leading to complicated design processes for users.\nHere we propose and demonstrate Noise-Noise Ratio Dif-\nference (NNRD), a metric for assessing how strongly a\ndataset relies on either feature-based or structure-based in-\nformation, with clear applications for chemistry and other\nfields. Following an intuitive noising process along either\nfeatures or structure, NNRD gives a bounded and under-\nstandable value with which data publishers or users can tai-\nlor their approaches from the outset."}, {"title": "Background and Related Work", "content": "GNNs, or more specifically Message Passing Neural Net-\nworks (MPNNs), parametrise message passing and aggre-\ngation, allowing deep-learning techniques to be applied on\ngraph data. For a dataset with features $X \\in \\mathbb{R}^{|V|\\times D}$ and\nsimilar for edges, structure as an edgelist $E : \\{(V_1, V_2), ...\\}$,\nand graph labels $y$, graphs are $G : \\{X, E\\}$. For a molecule,\nnodes are atoms and edges are bonds, with features giving\ninformation on individual atoms and bonds. When a given\nmodel aims to learn some mapping $f (G) \\rightarrow y$, in reality this\nis $f(X, E) \\rightarrow y$. The usual graph learning assumption is that\ntopology $E$ and features $X$ must be considered together for\ninformation to be useful. In other words their combination\nhas mutual information with a target $y$, $I(y; X, E)$.\nWu et al. (2020) explore the expressive power of GNNs,\nintroducing the information bottleneck principle. Alon and\nYahav (2021) perform similar analysis. The core thesis of\nboth works is that a compromise often must be struck be-\ntween different information sources in graph learning. More\nrecent works have elaborated on the same theme, often em-\nphasising that structural information can be difficult to ef-\nfectively incorporate (Wu et al. 2023). Other works instead\nshow that node information can be lost during GNN use,\nwith original feature similarities distorted during message\npassing and aggregation (Jin et al. 2021). In a similar vein\nsome works explicitly detach features and structure, with\nperformance benefits, despite the loss of information from\ntheir inter-relation (Wang et al. 2024).\nClear from the literature is that the balance between struc-\ntural and feature information, and how to effectively bal-"}, {"title": "NNRD: Noise-Noise Ratio Difference", "content": "We define NNRD here in the domain-agnostic case. As-\nsume that in the absence of features, structural information\nis still present, i.e. $I(y; E) \\ge 0$, as well as that features con-\ntain their own useful information, $I(y; X) \\ge 0$. Further we\ncan assume some imbalance between features and structure,\n$I(y; X) \\neq I(y; \u0415)$.\nHere we propose a way of investigating this imbalance\nbetween feature information and structure information. By\ndegrading the useful information in either (or both of) $X$\nand $E$, the degree to which performance relies on one or the\nother should be apparent. A caveat here is that degrading\neither will presumably also degrade the information from\ntheir interdependence.\nConsider some destructive noising process $N_t(\\cdot)$, that de-\ngrades the useful information in either $X$ or $E$. $N_0(x) = x$,\nwith no useful information after $N_T(\\cdot)$. Some imperfect\nmodel produces predictions $f(X, E) \\rightarrow \\hat{y}$. Performance is\nsome $h(y, \\hat{y})$ between real and predicted values. We can then\nsample $h(y, f(N_X,N_E) \\rightarrow \\hat{y})$, the useful information in\nboth $X$ and $E$, and whether performance requires both to be\npresent, should be observable.\nWe propose Noise-Noise Difference Ratio (NNRD), a\nmetric for how much a given task relies on data from fea-\ntures compared to structure. Here we denote $h_x(t)$ the per-\nformance of a given model on a task with no structural noise\nand feature noise at some noising step $t$. Similarly $h_e(t)$ is\nperformance at structural noise step $t$ with no feature noise.\nt and $h_x(t)$, $h_e(t)$ should monotonically increase to-\ntogether, as information for downstream tasks is necessarily\nremoved by our noising functions. If equal information is in\nstructure and features, they will descend at the same rate. If\nnot, one will fall faster than the other.\nFrom this we can define NNRD for performance metrics:\n$NNRD = log(\\frac{1}{T} \\sum_{t} \\{\\frac{h_x(t)}{h_e(t)}\\})$\nHere we expect h to increase with increasing performance.\nNNRD is 0 when features and structure contain equal infor-\nmation, > 0 when structure contains more information, and\n< 0 when features contain more information. In the same\nmanner, when an error is tracked instead of a performance\nmetric, the ratio term is simply inverted. This makes direct\ncomparison between datasets with different performance tar-\ngets, for example ROC-AUC and RMSE, possible."}, {"title": "Experiments", "content": "We measure NNRD over the graph-level tasks from the\nOpen Graph Benchmark (OGB) (Hu et al. 2020). These are\na mix of binary classification, multi-class binary classifica-\ntion, and single-target regression datasets. As some multi-\ntask datasets have missing values for different tasks, we train\nand report metrics by masking task-wise.\nWe use three Graph Isomorphism Network (GIN) layers\n(Xu et al. 2019) as our model, given their guarantees on ex-\npressivity, with a hidden dimension of 100 and trained with\na learning rate of 0.001. We train each model and noised\ndataset five times, measuring the mean performance across\nten increasing noise levels.\nWe use random edge removal/addition for structure noise,\nwith an example shown in Figure 1. At t, we remove | Er =\nP_t |V | (with 0 \u2264 pt < 1) edges at random from the graph,\nE' = E \\ Er. We then add an equal number of randomly\nchosen edges Ea| = pt. |V|, for a final noised edgelist\nE\" = E' U Ea. Where edge features are present, they are\ntransferred from removed edges onto newly added edges.\nThis is very close to the procedure taken by graph diffusion\nmodels as forward noising processes (Vignac et al. 2023).\nAtt = T, pt = 1, and the structure is a random graph with\nthe same density as the original.\nFor feature noise we employ random feature permutation.\nAt t, we completely permute the features of a proportion\npt of nodes across the dataset. Let node (or edge) features\nacross a whole dataset be X \u2208 {0,1}N\u00d7D with N points\nand D features. At t we randomly select Nf = ptN nodes\nto permute. The features of the selected nodes are then\nrandomly permuted, across the whole dataset, removing the\nuseful feature information from the selected nodes, while\nmaintaining marginal distributions."}, {"title": "Results", "content": "We show visualisations of increasing structure and feature\nnoise, and its influence on model performance, in Figure 2.\nHere we show NNRD, and also NNRDe, which is calcu-\nlated only at the extreme noise level t = T. Here we see\na variety of trends, varying by datasets. On the bbbp and\ntox21 datasets there is a reliance on feature-based informa-\ntion, with scores dropping a large margin as feature noise\nincreases, but structure noise having little effect.\nOn other datasets, such as the esol dataset, performance\nseems to decrease at an equal rate when structure and fea-\nture noise increase. On the bace dataset, interestingly, the\nperformance of the model actually increases with structure\nnoise. This may be due to additional long-range connections\nfrom edge swapping.\nNotably, only on the clintox dataset do we see a pref-\nerence for structural information over feature information.\nOddly performance actually increases as more noise is ap-\nplied to features. Performance over structure noises is close\nto constant, as on other datasets. The likely conclusion here\nis that the model is simply unable to learn the dataset use-\nfully enough to accurately predict the test set.\nIn Table 1 we record quantitative metrics. Here the same\ntrends as discussed from Figure 2 are present, although the\nsimple aggregate metrics we report are of a lower fidelity\nthan the visualisations. Crucially, in some cases, these ag-\ngregates are be misleading.\nTaking the esol dataset as an example, the performance\nachieved at maximum noise values would indicate that struc-\ntural information plays a more significant part than feature\ninformation. However, from Figure 2 we can see that in-fact\nthey increase at very similar rates, indicating a near-balance\nin useful information contained by each. NNRD instead re-\nports a value very close to zero, indicating near-parity be-\ntween the information in structure and features."}, {"title": "Discussion", "content": "While NNRD corresponds with the visualisations in Fig-\nure 2, there are some cases where it fails. The critical ex-\nample here is the clintox dataset, where the test set deviates\nsignificantly from the train set, and performance on the test\nset is consistently worse-than-random as a result. That said,\nthis dataset is constructed as a challenging benchmark, and\non other datasets NNRD is a useful quantitative measure.\nAn obvious point is that NNRD, in its current form, varies\non a per-model basis. This is a difficult obstacle to overcome,\nin that there is not currently a de-facto best model to use\nacross all datasets. Instead, by fixing the model used, NNRD\ncould be reported on a per-model basis. That said, the same\ntrends would likely be present with other models.\nWe envision use-cases mainly in data publishing. At the\ntime of publishing, NNRD can be reported for a few fixed\nmodels, giving an indication to users of whether to design\nfor structure or feature information."}, {"title": "Conclusion & Future Work", "content": "We have proposed a metric Noise-Noise Ratio Difference\n(NNRD) to evaluate whether the useful information on a\ngiven graph task weighs towards structure or features. By\nimplementing additive noise functions over structure and\nfeatures, and making use of OGB datasets, we have demon-\nstrated the efficacy of NNRD. Our future work will follow\nseveral key directions:\nWider range of datasets By including datasets from a\nwider range of domains, types and tasks, instead of only\nmolecule graphs here, we can establish whether NNRD\nis also useful outside of chemistry.\nModel selection We plan to refine and tailor the models\nwe use to calculate NNRD. Though a one-size-fits-all\nmethod is unlikely, a selection of different graph model\napproaches - for example linear models with random ker-\nnels - might provide adequate coverage."}]}