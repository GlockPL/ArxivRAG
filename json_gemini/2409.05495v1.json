{"title": "Using machine learning for fault detection in lighthouse light sensors", "authors": ["Michael Kampouridis", "George Rayment", "Nikolaos Vastardis"], "abstract": "Lighthouses play a crucial role in ensuring maritime safety by signaling hazardous areas such as dangerous coastlines, shoals, reefs, and rocks, along with aiding harbor entries and aerial navigation. This is achieved through the use of photoresistor sensors that activate or deactivate based on the time of day. However, a significant issue is the potential malfunction of these sensors, leading to the gradual misalignment of the light's operational timing. This paper introduces an innovative machine learning-based approach for automatically detecting such malfunctions. We evaluate four distinct algorithms: decision trees, random forest, extreme gradient boosting, and multi-layer perceptron. Our findings indicate that the multi-layer perceptron is the most effective, capable of detecting timing discrepancies as small as 10-15 minutes. This accuracy makes it a highly efficient tool for automating the detection of faults in lighthouse light sensors.", "sections": [{"title": "I. INTRODUCTION", "content": "The General Lighthouse Authority (GLA) of the UK and Ireland is dedicated to providing a reliable, efficient, and cost-effective navigation aid service for the maritime community's safety and benefit. The GLA Research and Development (GRAD) division, serving all three General Lighthouse Authorities in the UK and Ireland, is at the forefront of this mission. GRAD is responsible for researching and developing both physical and radio marine aids to navigation (AtoNs), as well as supporting systems and their integration, to uphold the GLA's commitment to delivering top-notch AtoNs for the safety and benefit of mariners.\nGRAD manages a variety of AtoNs, including lighthouses, buoys, light-vessels, beacons, and electronic navigation systems. These aids are crucial for safely guiding mariners through some of the UK's most trafficked waters, like the Dover Strait, the world's busiest shipping lane.\nAmong these aids, lighthouses play a vital role in marking perilous coastlines, shoals, reefs, rocks, and assisting in both sea and aerial navigation. A critical component of a lighthouse is its photoresistor sensor, which automates the light's operation. However, sensor malfunctions pose significant risks, such as delayed activation of lights, endangering ships in the vicinity by not alerting them to nearby hazards.\nThe challenge lies in monitoring and addressing sensor malfunctions in lighthouses, often situated in remote and hard-to-access locations. Reaching these sites, sometimes requiring costly helicopter transport, drives up maintenance expenses significantly. As a result, it's more feasible to replace unreliable components during regular maintenance visits rather than immediately upon detecting a fault.\nTo proactively detect potential sensor faults and efficiently plan maintenance, we propose utilizing machine learning (ML) to identify early signs of malfunction in lighthouse light sensors. A major hurdle is the absence of historical data on verified sensor failures, largely due to preemptive replacements during scheduled maintenance. Sensor failures can be gradual, showing increasing delays in light activation, or abrupt, such as a total breakdown. Our focus is on the former, the more complex scenario, as abrupt failures are straightforward and don't require ML intervention.\nTo overcome the data limitation, we simulate gradual photoresistor sensor faults and apply pre-trained ML models to this data. This approach helps us evaluate how effectively these models can detect declines in performance metrics like accuracy and F1 score. We also explore the models' capability to swiftly pinpoint potential faults. Our analysis includes four prominent algorithms: decision trees, random forest, extreme gradient boosting, and multi-layer perceptron. The goal is to develop a system that enables early detection of light sensor faults, aiding GRAD in prioritizing lighthouse maintenance.\nThe structure of this paper is as follows: Section II reviews existing literature and sets the context for AtoNs, highlighting the scarcity of ML applications in this domain. Section III details our methodology, while Section IV describes the experimental setup. Section V discusses our findings, and finally, Section VI concludes the paper and suggests directions for future research."}, {"title": "II. BACKGROUND INFORMATION AND LITERATURE REVIEW", "content": "Machine learning has garnered considerable attention across various sectors, including economics [1], finance [2], autonomous vehicles [3], smart homes [4], facial and image recognition [5], [6], telecommunications [7], weather [8], and object detection [9].\nDespite its widespread application, the realm of Aids to Navigation (AtoN), such as lighthouses, remains largely untouched by automation, particularly in maintenance practices. Current literature does not encompass the use of automated methods like machine learning for detecting AtoN failures. However, there is a substantial body of work on fault detection in various maritime industry aspects, including emissions monitoring [10], risk assessment in gas turbine systems on specialized tankers [11], analysis of risks in ship mooring operations [12], maintenance prioritization in ship systems [13], predictive maintenance of marine main engines [14], exhaust gas valve monitoring [15], condition monitoring in marine engines [16], diagnosis of engine cylinder covers [17], naval vessel system decay studies [18], and damaged mooring equipment detection [19]. Beyond the maritime sector, machine learning has been applied in detecting failures in agricultural machinery [20], wind turbines [21], aircraft components [22], and in production plants [23]. Failure identification encompasses various aspects, including detection, diagnosis, condition monitoring, prediction, and forecasting of variables like remaining useful life or degradation [24].\nA notable challenge in failure detection is the scarcity of labeled data indicating failures. While there's ample data on functional vessel components, data showcasing failures are rare. To overcome this, researchers often resort to creating simulated data for various fault scenarios [25]\u2013[27].\nIn our study, we encounter a similar challenge due to the lack of labeled features signifying failures. Although there's an abundance of historical data on photoresistor sensor activity (e.g., times when a light sensor was activated or deactivated), instances of sensor failures are minimal. This scarcity is attributed to the GLA's preventive maintenance approach during scheduled engineer visits. Due to the insufficiency of historical data on sensor failures, training a machine learning model on existing data to predict future failures is not feasible. To address this, we simulate various sensor failures and examine the response of pre-trained machine learning models to these scenarios, aiming to identify potential faults. The following section details this process and outlines the remainder of our methodology."}, {"title": "III. METHODOLOGY", "content": "Our research aims to enable the early detection of faulty sensors, a crucial step in ensuring timely replacement by the GLA maintenance team. Timely identification of such faults is not only critical for navigational safety, but also aids in efficient planning. Given that lighthouses are distributed across the UK, often in remote and hard-to-access locations, pinpointing faulty sensors can significantly enhance the logistics of maintenance trips, thereby reducing associated costs.\nWe tackle this challenge by framing it as a classification problem\u00b9. In this setup, we aim to predict the operational status of lighthouse lights (on or off) by analyzing a set of climate-related features. This predictive approach not only assists in the immediate identification of malfunctioning sensors but also contributes to more strategic, cost-effective maintenance planning across the network of lighthouses.\nConfronted with the absence of labeled fault instances in our sensor data logs, we have adopted an alternative approach. Our first step involves training various machine learning (ML) algorithms on historical data. The objectives are twofold: (i) to determine the most effective algorithm for our needs, and (ii) to establish a baseline of what constitutes 'normal' behavior for the sensors at a specific lighthouse. Detailed insights into the classification task are provided in Section III-A.\nOnce we have established this baseline, we proceed to simulate faults within the data. The purpose of this simulation is to examine the impact of these induced irregularities on the performance of the pre-trained ML models. For instance, if a model demonstrates a 90% accuracy rate with the 'normal' data (baseline), we would expect a noticeable decrease in accuracy when the model is applied to data that exhibits consistent irregular sensor behavior. The methodology behind our simulation of this irregular behavior is further elaborated in Section III-B.\n\nThe GRAD team records a variety of data from light sensors at lighthouses, including the date and time of each observation, the sun angle, and the operational status of the sensor light (either on or off), which forms the basis of our binary classification problem. To enrich this dataset, we've incorporated several climate-related variables: temperature, dew point, pressure, precipitation, global horizontal irradiance (GHI), diffuse horizontal irradiance (DHI), and Beam Normal Irradiation (BNI). The inclusion of these climate variables is crucial as they could significantly influence the sensor's functionality. For example, intense precipitation could result in darker atmospheric conditions, potentially triggering the lighthouse light.\nUsing these features, our objective is to train machine learning algorithms to develop models capable of discerning the climate conditions under which a lighthouse light is either on or off. We employ the sklearn Python library [28] for implementing algorithms like decision trees, random forest, extreme gradient boosting, and multi-layer perceptron. We standardize all features using sklearn's StandardScaler, which normalizes the data by eliminating the mean and scaling to unit variance. The performance of each classifier is evaluated"}, {"title": "B. Drifting sensor on/off times", "content": "A sensor failure is defined as a malfunction where the sensor does not activate or deactivate the lighthouse light precisely at the critical moments of sunset and sunrise. Such failures can manifest either gradually, with increasing delays in response to reduced light sensitivity, or abruptly, where the sensor ceases to function entirely. The latter scenario is more straightforward; a completely non-functional sensor means the light remains perpetually on or off, eliminating the need for machine learning analysis.\nTo focus on gradual sensor failures, we have implemented a 'drift' in the timing of the light's activation in the evening and deactivation in the morning. This is based on the premise that a malfunctioning sensor would likely have a delayed response to changing light conditions, resulting in a slower reaction both in the morning (leading to delayed light deactivation) and in the evening (causing delayed light activation).\nGradual photoresistor sensor faults manifest in two distinct ways: first, a decrease in the sensor threshold, where even minimal sunlight can trigger a change in the light source status; and second, an increase in the threshold, necessitating more sunlight to prompt a status change. The decreased threshold fault is particularly critical, as it can lead to the AtoN failing to operate its light source in poor visibility conditions, such as limited sunlight or fog, thereby increasing the risk of accidents. Consequently, our research predominantly addresses faults involving a gradually decreasing sensor threshold.\nTo accurately simulate these decreasing threshold faults, we employ a drifting operation in our data processing. This involves adding a fixed amount of time to the dataset entry timestamp for events when the light source turns on, while subtracting the same duration for turn-off events. This approach not only modifies the event timestamps but also necessitates the adjustment of related features (such as sun angle and climate data) to align with the updated, 'drifted' times. As a result, each newly created dataset offers a realistic representation of data from a faulty light sensor.\nFor our experiments, we generate several datasets with varying degrees of drift-specifically, 1, 5, 10, 15, 20, 25, and 30 minutes. The rationale behind creating multiple datasets with different drift intervals is to examine how the algorithms' performance, particularly in terms of classification accuracy and F1 scores, is affected as the degree of time drift increases.\nTo analyze these potential performance declines, we refer back to the best performing classifier identified in the classification step (see Section III-A). This classifier serves as the baseline for our drift experiments. By applying the same trained model across different drifted datasets, we anticipate a consistent decline in accuracy and F1 scores as the drift magnitude escalates. Our experiments aim to determine whether all lighthouses' trained ML models exhibit this continuous degradation in accuracy and F1 scores under varying drift conditions."}, {"title": "IV. EXPERIMENTAL SETUP", "content": "In this section, we present the details of our experimental setup. We first present in Section IV-A the datasets used in our experiments. Then, in Section IV-B, we present the machine learning algorithms used in our experiments, along with the hyperparameter tuning process.\n\nThe experimental work detailed in Sections III-A and III-B was conducted using datasets from seven lighthouses, all under the jurisdiction of Trinity House (TH). These lighthouses include Bishop Rock, Eddystone, Godrevy, Lizard, Longships, Trevose, and Wolfrock. Our analysis encompasses 3.5 years of data, spanning from June 2017 to December 2021.\nThe data components, specifically the timestamps, sun angle, and sensor light status, were sourced from Trinity House. In addition, we incorporated a range of climate variables into our study, including temperature, dew point, pressure, precipitation, Global Horizontal Irradiance (GHI), Diffuse Horizontal Irradiance (DHI), and Beam Normal Irradiation (BNI). These climate variables were obtained from the Copernicus EU Project's Climate Data Store (CDS) and Atmospheric Data Store (ADS) online archives [29], [30].\nThe number of observations in each dataset varies, contingent on the frequency of the light's on/off cycles. This variation is expected, given that multiple factors can influence the lighthouse light's operation. For instance, cloudy conditions might activate the light, which could then deactivate when the sky clears a cycle that can occur several times in a single day. On average, each dataset contains approximately 3,500 to 4,500 observations.\n\nWe use python's sklearn library to run four machine learning algorithms, namely: decision trees, random forest, extreme gradient boosting (XGBoost), and multi-layer perceptron (MLP).\nTo tune each algorithm's hyperparameters, we use 10-fold cross validation, by using sklearn's built-in GridSearchCV function. Given that each algorithm is separately tuned for each dataset, the resulted tuned hyperparameters are tuned for each individual dataset. The range of hyperparameter values used for tuning each algorithm are presented in Table I."}, {"title": "V. RESULTS", "content": "As previously mentioned, the primary goal of our experiments is to enable the early detection of lighthouse photoresistor sensor faults. To achieve this, we first establish a baseline of classification performance using historical data for each lighthouse. The results of this initial phase are detailed in Section V-A, where we report the accuracy and F1 scores for each classifier across the different datasets.\nSubsequently, in Section V-B, we delve into the impact of applying pre-trained machine learning models to 'drifted' data. This step is crucial for determining whether the classification performance shows continuous declines, a pattern that would indicate the potential of ML algorithms to effectively identify faulty sensors. By analyzing these performance trends, we aim to validate the effectiveness of machine learning techniques in the early detection of sensor malfunctions.\n\nTable II in our study presents the test set accuracy results for the four machine learning (ML) algorithms across the seven datasets. The results indicate high accuracy levels for all algorithms, generally ranging between 80-85%. An outlier in this trend is the Godrevy dataset, which exhibits notably higher accuracy, around 96-97%. However, it's important to emphasize that the primary focus of our investigation is not to pinpoint the dataset with the most accurate classification results. Instead, these figures serve as a baseline or a representation of 'normal' behavior for each specific lighthouse.\nThe significance of these baseline results will become evident when we begin simulating sensor faults, as discussed in Section V-B. This simulation allows us to analyze the impact of faults on classification performance, such as observing how accuracy might decrease when sensor faults cause delays in the lighthouse lights turning on or off. Results are very similar for the F1 score for both the 'On' (Table III) and the 'Off' (Table IV) classes, where we can again observe values of 80-85% for all lighthouses apart from Godrevy, which is again around 96-97%.\nTo determine the most effective machine learning (ML) algorithm among those tested, we employed the non-parametric Friedman test. This test operates under the null hypothesis that all algorithms' observations are drawn from the same continuous distribution. The results of this test are displayed in Table V, which shows the average rank of each algorithm in terms of accuracy (left column), F1 score for the 'On' class (middle column), and F1 score for the 'Off' class (right column). Additionally, the table includes the adjusted p-values according to the two-stage Benjamin/Hochberg post hoc test, a method for controlling the false discovery rate.\nStatistical significance in this context is defined by a p-value below 0.05, indicative of a 5% significance level. Our observations reveal that the Multi-Layer Perceptron (MLP) algorithm consistently ranks first across all three metrics. While it does not achieve statistical significance over the other ML algorithms, it does approach significance at the 10% level when compared to Extreme Gradient Boosting (XGBoost) and Decision Trees (DT) in terms of accuracy and F1 score for the 'Off' class, with p-values of 0.13 and 0.11, respectively.\nAlthough the MLP doesn't exhibit statistical significance in comparison to the other algorithms, this is not a major concern for our study. As previously mentioned, the primary objective of this phase of the experiment was to establish a baseline for the subsequent drift experiments, rather than to conclusively identify the superior algorithm. The key takeaway is that the MLP ranks first in both accuracy and the two F1 scores. Therefore, we will utilize the MLP for the forthcoming set of experiments.\n\nAs detailed in Section III-B, we simulate sensor errors that introduce delays in the activation and deactivation of lighthouse lights. These delays are set at 1, 5, 10, 15, 20, 25, and 30 minutes. Consequently, we generate seven distinct datasets for each lighthouse, each one applying a drift of the recorded observations by one of the specified time intervals. The primary objective of these experiments is to assess whether the classification performance of the top-performing MLP model, trained as discussed in Section V-A, exhibits a decline as the duration of drifting increases. Our working hypothesis posits that, given the model's training on a specific dataset, its accuracy and F1 score will progressively decrease with longer drift duration.\nOur initial hypothesis appears to be confirmed, as evidenced by the trends depicted in Figures 1 to 3, which illustrate the accuracy and F1 scores. These visualizations reveal a consistent decline in all performance metrics across the various datasets. Notably, significant decreases in accuracy become evident at the 5 or 10-minute mark, with the exception of Godrevy, which exhibits a more gradual decline in accuracy. On average, the smallest accuracy decrease is observed in Godrevy at 7.88%, while the most substantial decrease occurs in Lizard at 44.52%. Similarly, Figures 2 and 3 illustrate analogous continuous decreases in the F1 scores."}, {"title": "VI. CONCLUSION", "content": "In conclusion, this article addresses the challenge of fault detection in lighthouse light sensors. Given the absence of historical data to train machine learning models for fault prediction, the approach of simulating faults and detecting them early is explored. The experiments demonstrate that machine learning can detect sensor behavior drifts within 10-15 minutes. Moreover, it is observed that accuracy and F1 scores continuously decrease over time, serving as an effective early warning mechanism for sensor fault detection.\nFuture work can focus on trying to train ML algorithms on combined lighthouse stations' data. At the current paper, ML algorithms were trained per station. However, this can lead to difficulties in maintaining multiple models. An alternative could be to combine all lighthouse data and apply ML algorithms to create a single, 'global', trained model"}]}