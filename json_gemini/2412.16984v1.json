{"title": "LLM-Powered User Simulator for Recommender System", "authors": ["Zijian Zhang", "Shuchang Liu", "Ziru Liu", "Rui Zhong", "Qingpeng Cai", "Xiangyu Zhao", "Chunxu Zhang", "Qidong Liu", "Peng Jiang"], "abstract": "User simulators can rapidly generate a large volume of timely user behavior data, providing a testing platform for reinforcement learning-based recommender systems, thus accelerating their iteration and optimization. However, prevalent user simulators generally suffer from significant limitations, including the opacity of user preference modeling and the incapability of evaluating simulation accuracy. In this paper, we introduce an LLM-powered user simulator to simulate user engagement with items in an explicit manner, thereby enhancing the efficiency and effectiveness of reinforcement learning-based recommender systems training. Specifically, we identify the explicit logic of user preferences, leverage LLMs to analyze item characteristics and distill user sentiments, and design a logical model to imitate real human engagement. By integrating a statistical model, we further enhance the reliability of the simulation, proposing an ensemble model that synergizes logical and statistical insights for user interaction simulations. Capitalizing on the extensive knowledge and semantic generation capabilities of LLMs, our user simulator faithfully emulates user behaviors and preferences, yielding high-fidelity training data that enrich the training of recommendation algorithms. We establish quantifying and qualifying experiments on five datasets to validate the simulator's effectiveness and stability across various recommendation scenarios.", "sections": [{"title": "Introduction", "content": "Reinforcement Learning (RL)-based recommender systems have become increasingly important due to their capability to capture user preferences (Zhao et al. 2021a, 2023b; Liu et al. 2023b; Zhang et al. 2020) and long-term engagement (Liu et al. 2023a; Zhao et al. 2018a,b, 2019). They require interactive training where agent learns to make decisions by interacting with an environment. Online data reflects the real-time user feedback and behavioral patterns, which is critical for continuously refining recommender systems and solving real-world problems (Li et al. 2023; Han et al. 2024; Zhang et al. 2023, 2024c). However, due to the difficulty in obtaining online user interaction data, high collection costs, and user privacy concerns (Wang et al. 2023a), effectively simulating user interaction behavior has become an urgent problem to be solved. User simulators can quickly generate user behavior data, thus accelerating the evaluation process, and they guarantee user privacy without collection and use of real user data (Zhao et al. 2021b).\nDespite the promising progress of user simulators for recommender systems (Wang et al. 2023a; Ie et al. 2019; Corecco et al. 2024; Zhang et al. 2024a; Huang et al. 2024), existing research has two principal deficiencies. Firstly, current simulators fail to explicitly model user preferences, which is a critical function for accurately predicting user choices. VirtualTaobao (Shi et al. 2019) leverages GAN to simulate user interaction distribution and KuaiSim (Zhao et al. 2023a) employs an offline trained transformer to emulate user's responses to recommendations. Secondly, there is an absence of an efficient evaluative framework to assess the fidelity of simulated interactions with real user behavior. Consequently, there is an urgent need for the advancement of user simulators that can operate with higher degrees of fidelity and transparency in replicating the complex dynamics of user-system interactions.\nRecently, Large Language Models (LLMs) have demonstrated remarkable effectiveness in maintaining common knowledge and inferential capabilities across a spectrum of fields (Jia et al. 2023; Fu et al. 2023; Wang et al. 2024a,b; Liu et al. 2024a,b). This prowess positions LLMs as a promising avenue for simulating user behavior in recommendation systems. SUBER (Corecco et al. 2024) harnesses the semantic comprehension capabilities of LLMs to directly infer user engagement with items. Agent4Rec (Zhang et al. 2024a) equips user simulation by integrating LLM agents. It supports a wide range of behaviors, including taste-driven actions, such as viewing and rating items, as well as emotion-driven actions, including exiting the system and feedback through comments. However, the application of LLMs in user simulation is not without drawbacks. Primarily, the computational and time cost of calling LLM for simulations is substantial, posing a significant barrier to the training of the recommendation system (Corecco et al. 2024; Huang et al. 2024). What's more, an overreliance on LLMs also introduces the risk of hallucination, where the model generates factually incorrect or misleading inferences (Ji et al. 2023; Yao et al. 2023). These challenges must be navigated carefully to harness LLMs in crafting user simulators that are both efficient and grounded in reality.\nIn this paper, we first figure out a fundamental logic governing user interactions with recommended items, as illustrated in Figure 1. Taking movie recommendations as an example, a user's engagement with a recommended action movie begins with recognizing what the movie is, i.e., identifying its genre and characteristics that might lead to a liking or disliking sentiment. This recognition is followed by a deeper inquiry into how the item aligns with the user's tastes, i.e., analyzing his past preference to this genre, and considering the general comments to this movie. Based on item characteristics and the user's preference information, our goal is to explicitly utilize the fundamental logic of user interactions and predict their behavior towards an item in a transparent and understandable manner.\nIt is nontrivial to achieve this goal, and several main challenges must be conquered. First, how to depict the user preference explicitly? Translating user preferences into a clear and understandable model is inherently difficult. Existing deep collaborative filtering models with trainable embedding are hardly explainable, let alone indicating user preference. To address this, we propose leveraging LLM to analyze and interpret item characteristics from various angles, including genre, potential likes and dislikes, and user sentiments. By harnessing the rich analytical capabilities of LLM, we develop a logical model that captures the nuanced decision-making processes underlying user interactions.\nSecond, how to alleviate computational cost and the hallucination issue when using LLM? The computational demands of LLM and the risk of hallucination present substantial hurdles in system reliability (Ji et al. 2023). Instead of inferring the user interaction directly based on LLM (Zhang et al. 2024a; Corecco et al. 2024), we use LLM to distill the reasons a user might like or dislike an item, condensing and filtering this reasoning into concise keywords that minimize the impact of outliers. In addition, we complement this with a statistical model, i.e., a trained sequential model, that provides a regularizing effect on the predictions. Our ensemble model integrates the strengths of both logical reasoning and statistical learning, enhancing the reliability and efficiency of user interaction simulations synergistically.\nThird, how to evaluate the user simulator? Lacking a standardized metric for evaluation, we face the challenge of assessing the effectiveness of our user simulator.\nTo tackle this, we establish a series of experiments that span a wide range of applications, i.e., five public datasets encompassing POI, music, movie, game, and anime recommendation, to ensure that our tests are generalizable. By training reinforcement learning algorithms within these domains and comparing their performance, we aim to validate the simulator's ability to provide meaningful insights into user behavior within recommendation systems.\nThe main contributions of this paper are as follows:\n\u2022 We identify the intrinsic logic governing user engagement with items in recommendation, and propose a logical model that explicitly infers user interaction.\n\u2022 We construct an ensemble model consisting of rule-based logical and data-driven statistical models to imitate human interaction, maintaining consistency and reducing the likelihood of erroneous inferences.\n\u2022 We conduct both qualifying and quantifying experiments on five benchmark datasets that span a variety of application fields to verify the efficacy of the proposed method."}, {"title": "Preliminaries", "content": "User Simulator. User simulator in recommendation aims to infer the engagement as a real human user with candidate item ic offered by recommender systems. It can be formulated as P(y|h, ic), where y represents the interaction given by the user simulator, such as rating, buy, and dislike. In this paper, we consider like and dislike for clear descriptions. h = {(i1, Y1), . . ., (in, Yn)} is the user's historical interactions, consisting of his past responses of n items."}, {"title": "Methodology", "content": "Framework Overview\nIn this section, we implement the user engagement process with recommended items. The workflow of our system is depicted in Figure 2. The sequence of operations proceeds from left to right, beginning with an analysis of the potential item, followed by a comparison with the user's past interactions, culminating in a reasoned inference.\nTo express the logic of user interactions in a clear way, we use LLM to examine items and produce informative descriptions. We extract keywords that indicate why items might be liked or disliked based on both the item's features and user reviews. We also create an ensemble model consisting of three base models. This model suite evaluates the user's past preferences and the current item to produce an inference result. By combining these models, we aim to deliver a more precise and dependable assessment.\nObjective Item Description Collection\nTo discern what the item is, we initially leverage the items' factual descriptions. Our approach is to pinpoint the category $D_{cate}$ and delineate objective reasons for liking or disliking the item, i.e., $D_{pos}$ and $D_{neg}$. This objective item description analysis contributes to a comprehensive understanding of the item's attributes and potential user reactions."}, {"title": "Objective Description Prompt Template $T_{obj}$", "content": "Given a Movie named NAME and its characteristics, I need you to provide pros and cons, corresponding evidence and keywords from a customer perspective. Movie has the following attributes: ATTRIBUTES. Categories of the movie include CATEGORIES. Reasons, keywords, and evidence should be concise and reasonable. Keywords should appear positive or negative. Evidence should refer to the information given. Strictly follow the reply format, fill [], do not say anything else: Pros 1: [pros 1] Evidence: [evidence of pros 1] Keywords: [keywords of pros 1] Pros 2: [pros 2] Evidence: [evidence of pros 2] Keywords: [keywords of pros 2] Pros 3: [pros 3] Evidence: [evidence of pros 3] Keywords: [keywords of pros 3] Cons 1: [cons 1] Evidence: [evidence of cons 1] Keywords: [keywords of cons 1] Cons 2: [cons 2] Evidence: [evidence of cons 2] Keywords: [keywords of cons 2] Cons 3: [cons 3] Evidence: [evidence of cons 3] Keywords: [keywords of cons 3]"}, {"title": "Subjective Item Description Collection", "content": "To comprehend how a user views an item, public opinions can greatly influence the decision-making process. For example, a considerable proportion of users tend to choose mainstream options. Hence, we examine the comments to find keywords that indicate liking or disliking sentiments."}, {"title": "Subjective Description Prompt Template $T_{sub}$", "content": "To accomplish this, we devise a prompt template $T_{sub}$ that encompasses the item's descriptions and the user's feedback. We ensure that the LLM is instructed to generate reasons for a positive rating when the user provides one, and vice versa for negative ratings. For instance, when presenting a prompt for a positive rating, we use \u201cPros\u201d; we use \"Cons\" for a negative rating. The template $T_{sub}$ with positive rating is illustrated as follows, with placeholders for RATING, COMMENTS, NAME, ATTRIBUTES, and CATEGORIES to be filled with actual data. The LLM's response will answer the query indicated by the placeholder in red text."}, {"title": "Subjective Description Prompt Template $T_{sub}$", "content": "A customer rates RATING to the movie with comments: COMMENTS The information of this movie is: name: NAME, attributes: ATTRIBUTES, categories: CATEGORIES. I need you to provide Pros, corresponding evidence and keywords of the rating based on given information. Evidence should refer to the information given. Strictly follow the reply format, fill [], do not say anything else: Pros 1: [pros 1] Keywords: [keywords of pros 1] Evidence: [evidence of pros 1] Pros 2: [pros 2] Keywords: [keywords of pros 2] Evidence: [evidence of pros 2] Pros 3: [pros 3] Keywords: [keywords of pros 3] Evidence: [evidence of pros 3]"}, {"title": "Logical Model", "content": "Following the explicit user interaction logic, we design a logical model to simulate user engagement with the recommended candidate item. To decide whether to like or dislike a candidate item, users consider the characteristics of historical liking items and the potential reasons for liking candidate items and compare them with the characteristics of historical disliking items and the potential reasons for disliking candidate items. In this subsection, we devise two types of logical models leveraging the distilled information of items, i.e., keywords matching model and similarity calculation model."}, {"title": "Keywords Matching Model", "content": "Given user's historical interacted item list h = {(ik, Yk)}=1 containing indicative features, we design a keywords matching model, which concentrates on the direct matching of textual keywords. Firstly, to retrieve user's preference explicitly, we extract historical interacted items with the same category of ic, noted as hc := {(ik,Yk)}=1 with C items. When there are no historical items with the same category, we set hc = h. Then, we extract item set from he with positive rating Yk = 1 as historical liking items $I_{pos} := \\{i_k\\}_{k=1}^{C_{pos}}$ and item set with negative rating yk = 0 as historical disliking items $I_{neg} := \\{i_k\\}_{k=1}^{C_{neg}}$, where $C = C_{pos} + C_{neg}$.\nGiven the user historical preference Ipos and Ineg, we design a keywords matching model $f_{mat}(I_{pos}, I_{neg}, i_c)$ to infer the user's inclination towards liking or disliking candidate item ic. To implement this, we calculate the number of matched keywords of historical liking reasons, i.e., Dpos of items in Ipos, and potential liking reasons for the candidate item, i.e., Dpos of ic. Similarly, we calculate the alignment of historical disliking reasons, i.e., Dneg of items in Ineg and potential disliking reasons of candidate item, i.e., Dneg of ic. Denote the keywords for positive and negative reasons of item i with $D_{i_{pos}}$ and $D_{i_{neg}}$, respectively. The number of matched keywords for positive and negative attitudes apos and aneg can be formulated as:\n$\\alpha_{pos} = \\sum_{i \\in I_{pos}} D^{i_{pos}}_{pos} \\cap D^{i_c}_{pos}$ (1)\n$\\alpha_{neg} = \\sum_{i \\in I_{neg}} D^{i_{neg}}_{neg} \\cap D^{i_c}_{neg}$ (2)\nApos and Aneg capture the degree of overlap between the candidate item's potential reasons for liking/disliking and the user's historical preferences, quantifying the user's potential inclination towards the item. The keywords matching model can be represented by Eq. 3:\n$f_{mat}(I_{pos}, I_{neg}, i_c) = \\begin{cases}\n1 & \\text{if } \\alpha_{pos} > \\alpha_{neg},\\\\\nrand\\{0,1\\} & \\text{if } \\alpha_{pos} = \\alpha_{neg},\\\\\n0 & \\text{if } \\alpha_{pos} < \\alpha_{neg}.\n\\end{cases}$ (3)"}, {"title": "Similarity Calculation Model", "content": "To enhance the underlying interaction logic simulation process beyond mere keyword matching, we introduce similarity calculation model $f_{sim}(I_{pos}, I_{neg}, I_c)$ that leverages embedding representations for a nuanced understanding of user preferences. Akin to the keywords matching model, this model focuses on the relationship among items within the same category he and its respective positive and negative subsets, i.e., Ipos and"}, {"title": "Statistic Model", "content": "Beyond the two logical models, we augment our user simulator with a statistical model to enhance the reliability of the generated user inferences. To achieve this, we employ a deep model, SASRec (Kang and McAuley 2018), and train on the user's historical interaction data. Specifically, we pre-train the statistical model fsta(h, ic) with the dataset. Subsequently, we load the pretrained model parameter to infer the engagement with the candidate item.\nThis approach introduces the power of traditional statistical model, trained on user historical interaction data, to predict the user's inclination towards a candidate item. It enhances the reliability of the user simulator by integrating statistical learning with logical reasoning."}, {"title": "Ensemble User Simulator", "content": "Given the established two logical models, i.e., keywords matching model fmat and similarity calculation model fsim, and statistic model fsta, we construct an ensemble model to synergize the user interaction simulation performance.\nBy integrating the strengths of both logical reasoning and statistical learning, our ensemble model offers a comprehensive and robust framework for simulating user preferences and behaviors in recommendation scenarios.\nNext we introduce the training pipeline with reinforcement learning-based recomender system in this subsection."}, {"title": "MDP Formulation", "content": "In reinforcement learning-based recommender system training, the sequential item interactions can be formulated by a Markov Decision Process (MDP) (Puterman 1990). In this pipeline, recommender system serves as an agent, user interaction and preference are the environments, recommendation of item is action, user's response towards recommendation is the reward signal.\n\u2022 State (s \u2208 S): the set of all possible states of the environment, including user profile, historical interactions h, and current context including Ipos and Ineg.\n\u2022 Action (ic \u2208 A): the set of all possible actions the recommender system can take, where an action represents one recommended item ic.\n\u2022 Transition Probabilities (P(s'|s, ic)): the probabilities of transitioning to a new state s' given the current state s and action ic from recommender system.\n\u2022 Reward Function (R(s, ic, s')): assigns a numerical reward to each transition from state s to s' by action ic. We craft an ensemble model to serve as the user simulator, and the reward function is determined by the consensus reached among three constituent base models, which could be formulated as Eq. 9:\n$R(s,ic, s') = \\begin{cases}\n1 & \\text{if } f_{mat} + f_{sim} + f_{sta} \\geq 2,\\\\\n0 & \\text{if } f_{mat} + f_{sim} + f_{sta} < 2.\n\\end{cases}$ (9)\n\u2022 Discount Factor \u03b3: A number between 0 and 1 used to discount future rewards."}, {"title": "Experiments", "content": "Experimental Setup\nTo verify the efficacy of the proposed ensemble user simulator, we incorporate datasets from diverse fields:"}, {"title": "Case Study", "content": "In this subsection, we delve into case studies to further demonstrate the effectiveness of our user simulator. We first illustrate the recommendations by the DQN on Yelp in Table 3. Due to space limitation, we showcase a selection of 3 historical items (it-3, it-2, and it-1) and 3 RL recommended items (it, it+1, and it+2) highlighting their notable pros and cons. We omit cons for positive historical items and pros for negative ones. The user simulator's detailed inference process on the RL recommendations is presented in Table 4. For instance, for it, the matching cons with it\u22121 results in a fmat output of 0. Similarly, fmat for it+2 is 1, as its pros align with those of it-2. The fmat for it+1 being 1 is incidental, given the lack of matching pros or cons.\nWhen faced with items featuring new genres, such as it+1, the logical model assesses both the matching of pros and cons and the overall similarity to the historical item set, which may somewhat reduce precision. Nonetheless, our statistical model fsta serves as a crucial fallback. Its collaborative filtering capabilities ensure that the inference remains accurate and well-informed.\nIn conclusion, our ensemble user simulator harnesses the advantages of both logical and statistical models to explicitly generate user interactions that reflect user preferences. The logical model ensures transparency and consistency in user engagement, while the statistical model captures the subtleties of user behavior, enhancing the simulator's fidelity and effectiveness in emulating real-world user interactions."}, {"title": "User Simulator Comparison", "content": "To clearly position our user simulator with existing user simulators, we present the main features in Table 5.\nFor RL-based recommender systems, traditional user simulators typically rely on statistical models to generate user inferences. our simulator provides a transparent and logical method for inferring user engagement, enhancing transparency and realism. The reliance on LLMs for inference will inevitably introduce implementation complexity and computational cost, particularly when dealing with large datasets or high-frequency user interactions. Moreover, the hallucination in LLMs can impede performance, which is an issue that still lacks an effective solution. Unlike other LLM-based simulators that face issues like computational cost and hallucination during training, our approach utilizes the LLM for offline analysis, avoiding direct calls during the training phase and thus mitigating related challenges.\nAccording to the performance comparison in Table 6, our simulator consistently outperforms the state-of-the-art simulators, which proves its precise approximation to user preference. It also achieves competitive efficiency against both LLM- and non-LLM-based simulators."}, {"title": "Related Works", "content": "Traditional User Simulator To bridge the performance gap between offline metrics and online performance of recommender systems, RecoGym (Rohde et al. 2018) simulates user behavior in e-commerce and their responses to recommendations. Both organic user interactions on e-commerce sites and bandit sessions are incorporated. RecSim (Ie et al. 2019) provides a customizable environment for testing user interaction hypotheses, allowing for tailored user preferences, latent states, dynamics, and choice models. Virtual-Taobao (Shi et al. 2019) uses GANs for realistic customer feature simulation and multi-agent adversarial imitation learning for generalized customer action generation. Similarly, Chen et al. (Chen et al. 2019) uses GANs to model online interaction rewards, introducing a model-based RL technique that enhances sample efficiency in policy learning. Kuaisim (Zhao et al. 2023a) integrates a transformer model for user responses and sets benchmarks at the request, session, and cross-session levels for comprehensive recommender system evaluation.\nLLM-based User Simulator Given the successful precedents in related areas (Bubeck et al. 2023; Bommasani et al. 2021), there emerge LLM-based user inference simulations leveraging LLM's outstanding semantic understanding and inferring capability. With an empirical study on ChatGPT's performance in conversational recommendation using benchmark datasets, Wang et al. (Wang et al. 2023b) advocate to consider two types of interaction: attribute-based question answering and free-form chit-chat. Aiming at simulating search users, USimAgent (Zhang et al. 2024b) devises LLM agent to fabricate complete search sessions, including querying, clicking, and stopping behaviors, based on specific search tasks. SUBER (Corecco et al. 2024) utilizes LLMs as synthetic users within a gym environment, marking progress towards more realistic training environments for recommender systems. Agent4Rec (Zhang et al. 2024a) focuses on developing a simulator that accurately reflects user preferences and social traits. It leverages LLMs to create agents, each initialized with a unique user profile that includes tastes and social traits, ensuring agents' behaviors mirror those of real human users."}, {"title": "Conclusion", "content": "This paper presents a novel user simulator for RL-based recommender systems. To address the prevalent issues of opacity and simulation evaluation in current systems in existing user simulators, we introduce an LLM-powered user simulator designed to explicitly model user preferences and engagement. Our method identifies explicit logic of user preferences, utilizing LLMs to analyze item characteristics and distill user sentiments. We propose a novel ensemble model that integrates both logical and statistical insights, enhancing the reliability and fidelity of user interaction simulations. We conduct comprehensive experiments across five datasets, demonstrating the simulator's effectiveness and stability in various recommendation scenarios.\nCurrently, this simulator only infers binary interactions of 'like' or 'dislike'. Future work will focus on integrating additional interaction signals, such as duration, rating, and retention, to enrich the application of the simulator."}]}