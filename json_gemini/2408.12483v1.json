{"title": "Not All Samples Should Be Utilized Equally: Towards Understanding and Improving Dataset Distillation", "authors": ["Shaobo Wang", "Yantai Yang", "Qilong Wang", "Kaixin Li", "Linfeng Zhang", "Junchi Yan"], "abstract": "Dataset Distillation (DD) aims to synthesize a small dataset capable of performing comparably to the original dataset. Despite the success of numerous DD methods, theoretical exploration of this area remains unaddressed. In this paper, we take an initial step towards understanding various matching-based DD methods from the perspective of sample difficulty. We begin by empirically examining sample difficulty, measured by gradient norm, and observe that different matching-based methods roughly correspond to specific difficulty tendencies. We then extend the neural scaling laws of data pruning to DD to theoretically explain these matching-based methods. Our findings suggest that prioritizing the synthesis of easier samples from the original dataset can enhance the quality of distilled datasets, especially in low IPC (image-per-class) settings. Based on our empirical observations and theoretical analysis, we introduce the Sample Difficulty Correction (SDC) approach, designed to predominantly generate easier samples to achieve higher dataset quality. Our SDC can be seamlessly integrated into existing methods as a plugin with minimal code adjustments. Experimental results demonstrate that adding SDC generates higher-quality distilled datasets across 7 distillation methods and 6 datasets.", "sections": [{"title": "1 Introduction", "content": "In an era of data-centric AI, scaling laws [19] have shifted the focus to data quality. Under this scenario, dataset distillation (DD) [46, 39] has emerged as a solution for creating high-quality data summaries. Unlike data pruning methods [13, 7, 45, 1] that directly select data points from original datasets, DD methods are designed to generate novel data points through learning. The utility of DD methods has been witnessed in fields such as privacy protection [6, 29, 4, 11], continual learning [38, 15, 50, 32], neural architecture search [2, 34, 43], and federated learning [14, 28, 18].\nAmong the various DD techniques, matching-based methods, particularly gradient matching (GM) [52, 51, 25, 20] and trajectory matching (TM) [3, 8, 12, 16], have demonstrated outstanding perfor- mance. However, a gap remains between their theoretical understanding and empirical success. To offer a unified explanation of these methods, we aim to explore the following question:\nQuestion 1: Is there a unified theory to explain existing matching-based DD methods?\nTo address Question 1, we first empirically examine the differences between matching-based distilla- tion methods. It is widely acknowledged that sample difficulty (Definition 1) is a crucial metric in data-centric AI that significantly affects model performance, as seen in dataset pruning [44, 31, 30, 42],"}, {"title": "2 Preliminaries and Related Work", "content": "Dataset distillation involves synthesizing a small, condensed dataset $\\mathcal{D}_{syn}$ that efficiently encapsulates the informational essence of a larger, authentic dataset $\\mathcal{D}_{real}$.\nGradient Matching (GM) based methods are pivotal in achieving distillation by ensuring the alignment of training gradients between surrogate models trained on both the original dataset $\\mathcal{D}_{real}$ and the synthesized dataset $\\mathcal{D}_{syn}$. This method is first introduced by DC [52]. Let $\\theta_t$ represent the network parameters sampled from distribution $P_{\\theta}$ at step $t$, and $C$ symbolizes the categories within $\\mathcal{D}_{real}$. The cross-entropy loss, denoted by $\\mathcal{L}$, is employed to assess the matching loss by comparing the gradient alignment over a time horizon of $T$ steps. The formal optimization objective of DC is:\n$\\arg \\min \\limits_{\\mathcal{D}_{syn}} \\mathbb{E}_{\\theta_0 \\sim P_{\\theta},c\\sim C} \\sum\\limits_{t=0}^{T} D\\Big[ \\nabla_{\\theta} \\mathcal{L}_{D_{real}} (\\theta_t), \\nabla_{\\theta} \\mathcal{L}_{D_{syn}} (\\theta_t)\\Big]$\nwhere $D$ measures the cumulative distances (e.g., cosine/L2 distance in DC) between the gradients of weights corresponding to each category output. The parameter updates for $\\theta$ are executed in an inner loop via gradient descent, with a specified learning rate $\\eta$:\n$\\theta_{t+1} \\leftarrow \\theta_{\\tau} - \\eta \\cdot \\nabla_{\\theta} \\mathcal{L}_{D_{syn}} (\\theta_t)$.\nBuilding upon this, DSA [51] enhances DC by implementing consistent image augmentations on both $\\mathcal{D}_{real}$ and $\\mathcal{D}_{syn}$ throughout the optimization process. Moreover, DCC [25] refines the gradient matching objective by incorporating class contrastive signals at each gradient matching step, which results in enhanced stability and performance. Combining DSA and DCC, DSAC [25] further introduces improvements by synergizing these techniques. The revised optimization objective for DCC and DSAC is formulated as:\n$\\arg \\min \\limits_{\\mathcal{D}_{syn}} \\mathbb{E}_{\\theta_0 \\sim P_{\\theta}} \\sum\\limits_{t=0}^{T} D\\Big[ ECEC[\\nabla_{\\theta} \\mathcal{L}_{D_{real}} (\\theta_t)], ECEC[\\nabla_{\\theta} \\mathcal{L}_{D_{syn}} (\\theta_t)]\\Big]$\nTrajectory matching (TM) based approaches aim to match the training trajectories of surrogate models by optimizing over both the real dataset $\\mathcal{D}_{real}$ and the synthesized dataset $\\mathcal{D}_{syn}$. TM-based methods were initially proposed in MTT [3]. Let {\\$ \\theta_{t}^{D_{real}} \\$_{t=0} denote the expert training trajectories, represented as a sequential array of parameters {\\$\\theta_{t}^{D_{real}} \\$}_{t=0}, obtained from training a network on the real dataset $\\mathcal{D}_{real}$. In parallel, {\\$\\theta_{t}^{D_{syn}} \\$} refers to the parameter set of the network trained on $\\mathcal{D}_{syn}$ at step t. In each iteration, parameters \\$\\theta_{t}^{D_{real}} \\$ and {\\$\\theta_{t}^{D_{syn}} \\$} are randomly selected from the expert trajectory pool {\\$ \\tau_{D_{real}} \\$}, serving as the initial and target parameters for trajectory alignment, where $M$ is a predetermined hyperparameter. TM-based methods enhance the synthetic dataset $\\mathcal{D}_{syn}$ by minimizing the loss defined as:"}, {"title": "3 Method", "content": "3.1 A Closer Look at Sample Difficulty\nIn this subsection, we aim to intuitively understand dataset distillation through the concept of sample difficulty (Definition 1), which is pivotal in data-centric AI [44, 31, 30, 5, 49, 9, 26]. We begin by empirically observing the evolution of sample difficulty during the distillation process. Firstly, we introduce the commonly used definition of sample difficulty, namely the GraDN score (Definition 2), and validate the reliability of this metric. Furthermore, we track the GraDN score across current dataset distillation methods to delve deeper into their underlying mechanisms.\nDefinition 1 (Sample Difficulty [33]). Given a training pair $(x, y)$ and a series of pretrained models at training time $t$, the sample difficulty, denoted $\\chi(x, y; \\Theta_t)$, is defined as the expected probability of $(x, y)$ being misclassified by an ensemble of models $\\Theta_t \\in \\Theta_t$. Formally, it is presented as:\n$\\chi(x, y; \\Theta_t) = \\mathbb{E}_{\\theta_t\\in\\Theta_t} [\\mathbb{I}(y \\neq \\theta_t(x))]$,\nwhere $\\mathbb{I}(z)$ is an indicator function that equals 1 if the boolean input $z$ is true, and 0 otherwise. In this case, the indicator function equals to 1 if the sample $(x, y)$ is misclassified by the model with parameters $\\theta_t$, and 0 otherwise.\nDefinition 2 (GraDN Score [37]). Consider a training pair $(x, y)$, with $\\mathcal{L}$ representing the loss function. At time $t$, the GraDN score for $(x, y)$ is calculated as the average gradient norm of the loss $\\mathcal{L}$ across a diverse ensemble of models with parameters $\\theta_t \\in \\Theta_t$:\n$GraDN(x, y; t) = \\mathbb{E}_{\\theta_t\\in\\Theta_t} [|| \\nabla_{\\theta} \\mathcal{L}(x, y; \\theta_t)||_2]$,\nwhere $\\nabla_{\\theta} \\mathcal{L}(x, y; \\theta_t)$ denotes the gradient of loss $\\mathcal{L}$ on sample $(x, y)$ w.r.t. the model parameters $\\theta_t$, and $|| \\cdot ||_2$ denotes L2 norm."}, {"title": "3.2 An Analytical Theory for Explaining Matching-based Dataset Distillation", "content": "In Section 3.1, we empirically observed distinct trends in sample difficulty across various dataset distillation methods. Here, we propose an analytical theory based on the neural scaling law to formally analyze sample difficulty in matching-based methods. We extend the theory of data pruning presented by [42] and validate its applicability within the context of DD using an expert-student perceptron model. Unlike data pruning, where the pruned dataset is directly selected from the original dataset, DD involves synthesizing a small, new, unseen dataset.\nWe start our analysis with tools from statistical mechanics [35]. Let us consider a classification problem in dataset $\\mathcal{D}_{real}$ containing $d_{real}$ samples {xi, yi}i=1,...,dreal, where xi \u2208 Rd \u223c N(0, Id) are i.i.d. zero-mean, unit variance Gaussian inputs, and yi = sign($\\Theta_{Dreal}$xi) \u2208 {\u22121,+1} are labels generated by an expert perceptron $\\Theta_{Dreal}$ \u2208 Rd. Our analysis is within the high-dimensional statistics limit, where d, dreal \u2192 \u221e while maintaining the ratio of total training samples to parameters atot = dreal/dat \u2261 O(1). The general distillation algorithm proceeds as follows:\n1. Train a student perceptron on $\\mathcal{D}_{real}$ for a few epochs to obtain weights $\\Theta_{probe}$. The gap between can be measured by the angle \u03b3 between the probe student $\\Theta_{probe}$ and the expert $\\Theta_{real}$. If $\\Theta_{probe}$ \u2248 $\\Theta_{real}$, we denote the $\\Theta_{probe}$ as a perfect probe (\u03b3 = 0). Otherwise, in imperfect probe cases, \u03b3 \u2260 0.\n2. Compute the margin mi = ($\\Theta_{probe}$ (yixi) for each training example, categorizing large (small) margins as easy (hard) samples."}, {"title": "3.3 Matching with Sample Difficulty Correction", "content": "Based on our theoretical analysis of matching-based dataset distillation, we propose a novel method to enhance existing techniques for synthesizing higher-quality distilled datasets. Although TM-based methods have achieved relative success on current benchmark datasets, they do not explicitly consider sample difficulty, which could ensure higher synthetic dataset quality.\nA direct approach to impose constraints on sample difficulty is to calculate the gradient norm for each sample as a metric to determine its utility. Let us consider the case of GM-based methods. At step t, a batch of real samples $\\mathcal{B}_{real} \\sim \\mathcal{D}_{real}$ of class c\u2208 C is to be matched with the gradients of a synthetic batch $\\mathcal{B}_{syn} \\sim \\mathcal{D}_{syn}$. To decide whether to utilize each sample in $\\mathcal{B}_{real}$, it is natural to compute the gradient norm of each sample and utilize those with a score smaller than a predefined threshold \u03c4.\nSpecifically, a sample (x, y) is utilized if $||\\nabla_{\\theta}\\mathcal{L}(x, y; \\theta_t)||_2 \\leq \\tau$. Consequently, the modified loss for matching only easy samples is:\n$\\mathcal{L}_{B_{real}} = \\mathbb{E}_{(x,y) \\in \\mathcal{B}_{real}} [\\mathcal{L}(x, y; \\theta_t)], \\mathcal{L}_{B_{syn}} = \\mathbb{E}_{(x,y) \\in \\mathcal{B}_{syn}} [\\mathcal{L}(x, y; \\theta_t)]$,\nwhere $\\mathcal{B} = \\{(x,y)| (x,y) \\in \\mathcal{B}_{real}, ||\\nabla_{\\theta}\\mathcal{L}(x,y; \\theta_t)||_2 \\leq \\tau\\}$ denotes the modified batch with only easy samples, and $\\mathcal{B}_{syn}$ denote a sampled batch from $\\mathcal{D}_{syn}$ with the same size as $\\mathcal{B}_{real}$. The corresponding matching loss should be:\n$\\mathcal{L}(\\theta) = D \\Big( \\nabla_{\\theta}\\mathcal{L}_{B_{real}} (\\theta_t), \\nabla_{\\theta}\\mathcal{L}_{B_{syn}} (\\theta_t)\\Big)$,\nHowever, the computational cost of constructing reduced easy sample batch $\\mathcal{B}_{real}$ from $\\mathcal{B}_{real}$ is unrealistic in real-world scenarios because it requires calculating the gradient norm for each sample independently, resulting in a tenfold or greater increase in time. Besides, determining the difficulty threshold \u03c4 is also ad-hoc and challenging for each sample. Therefore, we take an alternative approach, i.e., we consider adding the overall sample difficulty of the whole batch $\\mathcal{B}_{syn}$ as an implicit regularization term in the matching loss function. Our proposed methods, named Sample Difficulty Correction (SDC), can be incorporated into current matching methods with minimal adjustment of code implementation. Specifically, for a single-step GM, we have the following modified loss:\n$\\mathcal{L}_{\\lambda}(t) = D \\Big( \\nabla_{\\theta}\\mathcal{L}_{B_{real}} (\\theta_t), \\nabla_{\\theta}\\mathcal{L}_{B_{syn}} (\\theta_t)\\Big) + \\lambda ||\\nabla_{\\theta}\\mathcal{L}_{B_{syn}}||_2$,\nFor TM-based methods that do not explicitly focus on sample difficulty during distillation, we compute the average gradient norm of the whole dataset $\\mathcal{D}_{syn}$ during the optimization of the student network $\\theta_{syn}$ w.r.t. the training loss as the regularization term. Specifically, we have:\n$\\mathcal{L}_{\\lambda}(\\theta_{syn}) = D \\Big( \\frac{1}{D(\\mathcal{D}_{real})} D( \\theta_{t+M}^{D_{real}}, \\theta_{t+N}^{D_{real}}) / D(\\theta_{t}^{D_{real}}, \\theta_{t+M}^{D_{real}})\\Big) + \\lambda ||\\nabla_{\\theta}\\mathcal{L}_{D_{syn}}||_2$,\nBy adding the gradient norm regularization, we can implicitly enforce current matching-based methods to mainly concentrate on synthesizing easy samples to achieve better synthetic data quality. We provide the detailed algorithm pseudocodes for GM- and TM-based methods in Appendix B.3."}, {"title": "4 Experiments", "content": "4.1 Basic Settings\nDatasets and baselines. For GM-based methods, we followed previous works to conduct experiments on MNIST [10], FashionMNIST [48], SVHN [36] datasets. We utilized current GM-based methods, including DC [52], DSA [51], and DSAC [25] as baselines. For TM-based methods, we followed the recent papers to use CIFAR-10, CIFAR-100 [21], and Tiny ImageNet [23] datasets. We performed experiments on current baselines including MTT [3], FTD [12], TESLA [8], and DATM [16]. We"}, {"title": "4.2 Main Results", "content": "GM-based methods on MNIST, FashionMNIST, and SVHN. As presented in Table 1, we report the results of three GM-based methods applied to MNIST, FashionMNIST, and SVHN datasets. Each method was evaluated with IPC (images-per-class) values of 1, 10, and 50. Notably, adding SDC improves the test accuracy of baseline methods across all datasets and IPC values, demonstrating the effectiveness of our approach. Notably, adding SDC to the original method improved the test accuracy of DSA by 1.2% on the SVHN dataset with IPC = 1, and by 1% with IPC = 50. For DC on the FashionMNIST dataset with IPC = 50, the test accuracy was increased by 1.1% with SDC. All hyperparameters are detailed in Table 4.\nTM-based methods on CIFAR-10/100 and Tiny ImageNet. As shown in Table 2, we present the results of four TM-based methods trained on CIFAR-10, CIFAR-100 and Tiny ImageNet. By incorporating the average gradient norm as a regularization term during matching with SDC, the resulting test accuracy was generally improved. Notably, employing SDC improved the test accuracy of FTD on CIFAR-10 by 1.2% with IPC = 10 and 1.1% with IPC = 50, and enhanced the test accuracy of DATM on Tiny ImageNet by 0.6%. For FTD, we used EMA (exponential moving average) just as in the original method[12]. All hyperparameters are detailed in Tables 5, 6, 7, and 8.\nGeneralization performance to other architectures. We evaluated the generalizability of synthetic datasets generated through distillation. Specifically, we used DSAC and DATM, which are current SOTA methods in GM-based and TM-based distillation, respectively. After distillation, the synthetic datasets were assessed using various neural networks, including ResNet-18 [17], VGG-11 [41], AlexNet [22], LeNet [24] and MLP. As shown in Table 3, even though our synthetic datasets were distilled using ConvNet, it generalizes well across most networks. Notably, for the experiment of DATM on CIFAR-10 with IPC = 1, employing SDC resulted in an accuracy improvement of 4.61% when using AlexNet. Employing SDC to DSAC led to an accuracy improvement of 0.9% on SVHN with IPC = 10 when using MLP. Additional results can be found in Appendix C.1."}, {"title": "4.3 Further Discussions", "content": "Discussion of SDC coefficient \u03bb. The selection of the regularization coefficient \u03bb is pivotal for the quality of the distilled dataset. Our theory suggests that a larger \u03bb typically produces better synthetic datasets for smaller IPC values. Ideally, for low IPC settings, it is better to employ a large \u03bb to strongly penalize sample difficulty, whereas, for high IPC settings, the required \u03bb can be small or even close to zero in extreme cases. For simplicity and to maintain consistency across different datasets and baseline methods, we have set x = 0.002 as the default value in most of our experiments. As demonstrated in Figure 5, this choice of \u03bb aligns with the IPC values. Results for FTD and TESLA are based on CIFAR-10, results for DSA are based on SVHN, and results for DSAC are based on MNIST. Additionally, we further show that the choice of \u03bb is not sensitive in Appendix C.3.\nAdaptive sample difficulty correction by adaptively increasing \u03bb during distillation. While our SDC seeks simplicity in regularization, DATM [16] claims that the matching difficulty is increased through optimization. Inspired by their observation, we implemented a strategy where \u03bb increases progressively throughout the matching phases. This method is designed to incrementally adjust the focus from easier to more complex patterns. Inspired by their observation, we applied an Adaptive Sample Difficulty Correction (ASDC) strategy in our experiments with a TM-based method on the CIFAR-100 with IPC = 1 and with a GM-based method on the FashionMNIST with IPC = 1. The \u03bb of DATM was initialized to 0.02 and logarithmically increased to 0.08 over 10,000 iterations and DSAC was initialized to 0.002 and logarithmically increased to 0.008 over 10,000 steps. For DATM, we use max test accuracy, while for DSAC, we use test accuracy. Experimental results of ASDC validate its potential to significantly enhance learning by finetuning regularization according to the complexity of the learned patterns. Figure 6 illustrates that ASDC further improves our method within SOTA matching methods. Additional results are provided in Appendix C.2."}, {"title": "5 Conclusion", "content": "In this study, we empirically examine the matching-based dataset distillation method in relation to sample difficulty, observing clear trends as measured by gradient norm. Additionally, we adapt a neural scaling law from data pruning to theoretically explain dataset distillation. Our theoretical analysis suggests that for small synthetic datasets, the optimal approach is to generate data using easier samples from the original dataset rather than harder ones. To facilitate this, we propose a simplicity-centric regularization method, termed Sample Difficulty Correction (SDC), aimed at improving synthetic data quality by predominantly utilizing easier samples in the data generation process. This method can be easily incorporated to existing matching-based methods, and can be implemented with a few lines of code. Experimental results underscore the importance of proper regularization within the optimization process for dataset distillation. We anticipate that this work will deepen the theoretical understanding of dataset distillation."}, {"title": "B More Details of Experiments", "content": "B.1 Parameter Tables\nB.1.1 GM-based Methods\nRegarding the GM-based methods, Table 4 provides the corresponding \u03bb values after applying SDC. All results are obtained from a single experiment, and evaluated 20 times. Baseline results are obtained using identical configurations with the original methods' implementations (please refer to DC and DSA2, and DCC3). Experiments with our SDC share consistent hyperparameters with the corresponding baselines."}, {"title": "B.1.2 TM-based Methods", "content": "The hyperparameters used in our TM-based methods differ slightly from the original methods (see original implementations of MTT4, DATM, TESLA, and FTD7), particularly in terms of synthesis steps, number of evaluations, and evaluation interval. Our baseline results used the settings in Table 5, Table 6, Table 7 and Table 8. The experiments of applying SDC were conducted in the same setting as in the baselines. In Table 6, and Table 7, we report the optimal hyperparameters using the ConvNetD3 network. All combinations in Table 7 and Table 8 used the ZCA."}, {"title": "B.2 Limitation", "content": "Computational Cost: Similar to other methods, we have not yet addressed the large computational cost associated with the dataset distillation. Our experiments were conducted on a mix of RTX 2080 Ti, RTX 3090, RTX 4090, NVIDIA A100, and NVIDIA V100 GPUs. The cost in terms of computational resources and time remains significant for large datasets and high IPC experiments. For example, distilling Tiny ImageNet using DATM with IPC = 1 requires approximately 150GB of GPU memory, and for IPC = 50, a single experiment can take nearly 24 hours to complete.\nHyperparameter Tuning: The selection of the \u03bb requires manual adjustment, which may involve additional costs. The extensive training durations and substantial GPU memory requirements make it challenging to conduct exhaustive experiments with multiple \u03bb values to identify the global optimum, given our computational resource limitations. By exploring a wider range of \u03bb values, it is possible to obtain better results."}, {"title": "B.3 Pseudocodes of adding SDC on Matching-based Distillation Methods", "content": "We provide detailed pseudocodes for GM-based methods and TM-based methods. We take DC as the standard GM-based method, and MTT as the standard TM-based method. The detailed pseudocodes are shown in Algorithm 1 for GM-based methods and Algorithm 2 for TM-based methods."}, {"title": "C Exploring the Effectiveness of SDC in Additional Experiments", "content": "C.1 More Results on the Cross-architecture Evaluation\nTo evaluate the performance of distilled datasets on different network architectures using SDC (marked as +SDC in the tables) and other methods (DATM and DSAC), we conducted cross-architecture evaluation experiments. We compared the effects of DATM and SDC on CIFAR-10, CIFAR-100, and Tiny ImageNet datasets, and the effects of DSAC and SDC on MNIST, FashionMNIST, and SVHN datasets. Finally, we further evaluated the performance differences between DSAC and SDC methods on MNIST, FashionMNIST, and SVHN datasets with IPC = 50. The cross-architecture evaluation experiments for DSAC and DATM, as well as the use of the SDC method on datasets with IPC = 1 of DATM and IPC = 10 of DSAC, can be found in Table 3.\nThe results of evaluating distilled datasets learned through DATM and SDC methods on CIFAR-10, CIFAR-100, and Tiny ImageNet datasets using ResNet-18, VGG-11, AlexNet, LeNet, and MLP networks are presented in Table 9. For instance, on the CIFAR-100 dataset, the accuracy of the VGG-11 network improved by 1.46%. It can be observed that the performance after applying SDC is generally better than DATM."}, {"title": "C.3 Sensitivity Analysis of SDC coefficient \u03bb.", "content": "In this section, we conducted extensive experiments to study the sensitivity of the hyperparameter \u03bb. Specifically, we conducted experiments of DSA on SVHN dataset with IPC = 1, and DC on SVHN dataset with IPC = 10. As shown in Figure 14, the choice of \u03bb is not sensitive among different matching-based dataset distillation methods."}, {"title": "D Analytical Theory for Dataset Distillation", "content": "In this section, we introduce a theory, adapted from data pruning [42], to the context of dataset distillation within an expert-student perceptron framework, utilizing the tools of statistical mechanics. We investigate the challenge of classifying a dataset Dreal consisting of dreal samples {xi, yi}i=1,...,dreal, where the inputs xi ~ N(0, Id) are i.i.d. zero-mean, unit-variance random Gaussian variables, and the labels yi = sign($\\Theta_{Dreal}$xi) are generated by an expert perceptron $\\Theta_{Dreal}$ \u2208 Rd. We assume that the expert perceptron $\\Theta_{Dreal}$ is randomly drawn from a uniform distribution on the sphere $\\Theta_{Dreal}$ ~ Unif(Sd-1(\u221ad)). Our analysis is situated within the high-dimensional statistics limit where d, dreal\u2192\u221e but the ratio areal = drea1/d remains O(1).\nSpecifically, consider synthesizing a dataset by matching only the samples with the smallest margin |zi| = |$\\Theta_{probe}$ Xi| along a probe student $\\Theta_{probe}$. The distilled dataset will then follow a distribution p(z) in the direction of ($\\Theta_{probe}$ while remaining isotropic in the null space of ($\\Theta_{probe}$. We assume, without loss of generality, that $\\Theta_{probe}$ has developed some overlap with the expert, quantified by the angle \u03b3 = cos-1(  $\\frac{\\Theta_{probe Dreal}}{\\|\\Theta_{probe} \\|_2 \\|\\Theta_{D real} \\|_2}$    ).\nOnce the dataset has been distilled, we consider training a new student $\\Theta_{syn}$ from scratch on this distilled dataset. A typical training algorithm aims to find the solution $\\Theta_{syn}$ which classifies the training data with maximal margin \u03ba = mini ($\\Theta_{Dsyn}$yixi). Our goal is to compute the generalization error \u025b of this student, governed by the overlap between the student and the expert: \u025b = cos-1(R)/\u03c0,\nwhere R = $\\frac{PsynDreal}{\\|\\Theta_{Dsyn} \\|_2 \\|\\Theta_{D real} \\|_2}$   .\nWe provide saddle point equations for the cosine similarity R between the probe $\\Theta_{probe}$ and the expert $\\Theta_{Dreal}$, which will be discussed in Section D.1 and Section D.2. For our simulations, we set the"}, {"title": "D.1 Perfect Expert-Teacher Settings", "content": "The solution is given by the following saddle point equations for perfect exeprt-teacher settings, i.e., y = 0. For any given asyn, these equations can be solved for the order parameters R, K. From these parameters, the generalization error can be computed as \u025b = cos-1(R)/\u03c0.\nR =   $\\frac{2\\theta_{syn}}{f\\sqrt{2\\pi}\\sqrt{1 - R^2}} \\int\\limits_{0}^{\\infty} Dt\\ exp(\\frac{- \\frac{R^2t^2}{2}}{1 - R^2}) [1 - exp(-\\frac{\\gamma(\\gamma - 2Rt)}{2(1 - R^2)})]$\n1 - R2 =$\\frac{2\\theta_{syn}}{f} \\int\\limits_{0}^{\\infty} Dt\\ H(\\frac{Rt}{\\sqrt{1 - R^2}}) [1 - exp(-\\frac{(\\kappa - t)^2}{\\nu})]\nWhere H(x) =  $\\frac{1}{2}\\int\\limits_{x}^{\\infty} e^{\\frac{-t^2}{2}} dt$. This calculation produces the solid theoretical curves shown in Figure 4, which exhibit an excellent match with numerical simulations. Please refer [42] for detailed deductions."}, {"title": "D.2 Imperfect Expert-Teacher Settings", "content": "We have shown the perfect student settings in Section D.1. When the probe student does not exactly match the expert, an additional parameter 60 characterizes the angle between the probe student and the expert. Furthermore, an additional order parameter p = @Dreal (Dsyn represents the typical student- probe overlap, which must be optimized. Consequently, we derive three saddle point equations.\n$\\frac{R-pcosy}{sin^2 \u03b3} =  \\frac{\\theta_{syn}}{\\pi\\Lambda}\\int\\limits_{-\\infty}^{\\infty} dt\\ exp(-\\frac{\\Delta(t, z)}{\\nu}) H(\\frac{\\Gamma(t, z)}{\\sqrt{1 - \\rho^2} \\Lambda})\n$\\frac{\u03c1^2 + R^2 - 2pR cos y}{sin^2 \u03b3} = 2\\theta_{syn}\\int\\limits_{-\\infty}^{\\infty}\\frac{e^{\\frac{(t-pz)^2}{2(1-p^2)}}}{\u221a2\u03c0\u221a1 - \u03c1\u00b2\\Lambda} \\int\\limits_{0}^{\\infty} H(\\frac{\\Gamma(t, z)}{\\sqrt{1 - \\rho^2} \\Lambda}) dt\\frac{(\\kappa - t)^2}{2}\n$\\frac{\u03c1 - R cos y}{sin^2 \u03b3} = 2\\theta_{syn} \\int\\limits_{-\\infty}^{\\infty} dt\\frac{e^{\\frac{(t-pz)^2}{2(1-p^2)}}}{\u221a2\u03c0\u221a1 - \u03c1\u00b2}  *\\frac{\\sqrt{\\pi}}{2\u039b}H(\\frac{\\Gamma(t, z)}{\\sqrt{1 - \\rho^2} \\Lambda})(-)\\int\\limits_{0}^{\\infty}   exp( -\\frac{\\Delta(t, z)}{\\nu }) (p - cos y) \\frac{\u221a2\u03c0}{2}  H(\\frac{\\Gamma(t, z)}{\\sqrt{1 - \\rho^2} \\Lambda})\nWhere,\nA = \u221a sin\u00b2 y \u2013 R\u00b2 \u2013 p\u00b2 + 2pR cos y,\n$\\Gamma(t, z) = z(\\rho R \u2013 cos \\gamma) \u2013 t(R \u2013 \\rho cos y)$,\n$\\Delta(t, z) = z\u00b2 (\\rho\u00b2 + cos\u00b2 \\gamma \u2212 2\\rho R cos \\gamma) + 2tz(R cos \\gamma \u2212 \\rho) + t\u00b2 sin\u00b2 \\gamma$.\nThe notation (\u00b7)z denotes an average over the pruned data distribution p(z) for the probe student. For any given asyn, p(z), y, these equations can be solved for the order parameters R, \u03c1, \u03ba. From these parameters, the generalization error can be readily obtained as \u025b = cos-1(R)/\u03c0. Our simulation results are shown in Figure 15. Please refer [42] for detailed deductions."}]}