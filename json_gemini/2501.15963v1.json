{"title": "EVALUATING DATA INFLUENCE IN META LEARNING", "authors": ["Chenyang Ren", "Huanyi Xie", "Shu Yang", "Meng Ding", "Lijie Hu", "Di Wang"], "abstract": "As one of the most fundamental models, meta learning aims to effectively address few-shot learning challenges. However, it still faces significant issues related to the training data, such as training inefficiencies due to numerous low-contribution tasks in large datasets and substantial noise from incorrect labels. Thus, training data attribution methods are needed for meta learning. However, the dual-layer structure of mata learning complicates the modeling of training data contributions because of the interdependent influence between meta-parameters and task-specific parameters, making existing data influence evaluation tools inapplicable or inaccurate. To address these challenges, based on the influence function, we propose a general data attribution evaluation framework for meta-learning within the bilevel optimization framework. Our approach introduces task influence functions (task-IF) and instance influence functions (instance-IF) to accurately assess the impact of specific tasks and individual data points in closed forms. This framework comprehensively models data contributions across both the inner and outer training processes, capturing the direct effects of data points on meta-parameters as well as their indirect influence through task-specific parameters. We also provide several strategies to enhance computational efficiency and scalability. Experimental results demonstrate the framework's effectiveness in training data evaluation via several downstream tasks.", "sections": [{"title": "1 Introduction", "content": "Bilevel Optimization (BLO) has received significant attention and has become an influential framework in various machine learning applications including hyperparameter optimization Sun et al. (2022); Okuno et al. (2021), data selection Borsos et al. (2020, 2024), meta learning (Finn et al., 2017), and reinforcement learning Stadie et al. (2020). A general BLO framework consists of two hierarchical optimization levels (outer and inner levels) and can be formulated as the following:\n\n$\\min_{\\lambda} f(\\lambda, \\theta^*(\\lambda)) \\quad \\text{s.t.} \\quad \\theta^*(\\lambda) \\in \\arg \\min_{\\theta'} g(\\lambda, \\theta'),$\nwhere the objective and variables of the outer-level problem f are influenced by the inner-level problem g.\nAmong the various instantiations of BLO, meta learning has gained considerable interest due to its effectiveness in addressing the challenges of few-shot learning Finn et al. (2017); Jamal and Qi (2019); Hospedales et al. (2021); Franceschi et al. (2018); Yang et al. (2021). Meta learning involves two interdependent sets of parameters: meta parameters and task-specific parameters. Its inner level focuses on independently training across multiple few-shot tasks using the meta parameters \u5165 supplied by the outer level to derive the task-specific parameters \\theta^* (\\lambda). The outer level, in turn, evaluates the performance of the inner level's task-specific parameters trained based on the meta parameter. Specifically, the outer level guides and assesses the training process of the inner level, while the outcomes of the inner level training provide essential task-specific model support for the outer level.\nRecent advancements highlight the applicability of meta learning across various domains, including federated learn- ing Fallah et al. (2020) and multi-task learning Wang et al. (2021), underscoring its versatility and potential. However,"}, {"title": "2 Related Work", "content": "Meta Learning. Meta learning, often described as \"learning to learn,\" has emerged as a pivotal approach for enabling models to rapidly adapt to new tasks by leveraging prior experience Thrun and Pratt (1998). Finn et al. (2017) introduced Model-Agnostic Meta-Learning (MAML), framing the meta learning process as a bilevel optimization problem where the inner loop adapts model parameters to specific tasks, and the outer loop optimizes for performance across tasks."}, {"title": "3 Preliminaries", "content": "Notation. For a twice differentiable function $\\mathcal{L}(\\lambda,\\theta(\\lambda);\\mathcal{D})$, $\\partial_{\\lambda}\\mathcal{L}(\\lambda,\\theta(\\lambda);\\mathcal{D})$ denotes the direct gradient (partial derivative) of $\\mathcal{L}$ w.r.t. $\\lambda$ and $\\partial_{\\theta}\\mathcal{L}(\\lambda,\\theta(\\lambda);\\mathcal{D})$ denotes the direct gradient of $\\mathcal{L}$ w.r.t. $\\theta(\\lambda)$. And the total gradient (total derivative) of $\\mathcal{L}(\\lambda, \\theta(\\lambda);\\mathcal{D})$ w.r.t. $\\lambda$ is calculated as $D_{\\lambda}\\mathcal{L}(\\lambda,\\theta(\\lambda);\\mathcal{D}) = \\partial_{\\lambda}\\mathcal{L}(\\lambda,\\theta(\\lambda);\\mathcal{D}) + \\frac{d\\theta(\\lambda)}{d\\lambda} \\cdot \\partial_{\\theta}\\mathcal{L}(\\lambda,\\theta(\\lambda);\\mathcal{D})$.\nInfluence Function. The influence function (Huber, 1981) quantifies how an estimator relies on the value of each individual point in the sample. Consider a neural network $\\hat{\\theta} = \\arg \\min_{\\theta} \\mathcal{L}(\\theta, \\mathcal{D}) = \\sum_{i=1}^n l(z_i; \\theta)$ with loss function l and dataset $\\mathcal{D} = \\{z_i\\}_{i=1}^n$. When an individual data point $z_m$ is removed from the training set, the retrained optimal retrained model is denoted as $\\hat{\\theta}_{-z_m}$. The influence function method provides an efficient way to approximate $\\hat{\\theta}_{-z_m}$ without the need of retraining. By up-weighing $z_m$-related term in the loss function by $\\epsilon$, a series of $\\epsilon$-parameterized optimal models $\\theta_{-z_m,\\epsilon}$ will be obtained by\n\n$\\theta_{-z_m,\\epsilon} = \\arg \\min_{\\theta} [\\mathcal{L}(\\theta, \\mathcal{D}) + \\epsilon \\cdot l(z_m; \\theta)].$\nConsider the term\n\n$\\nabla \\mathcal{L}(\\theta_{-z_m,\\epsilon}, \\mathcal{D}) + \\epsilon \\cdot \\nabla l(z_m; \\theta_{-z_m,\\epsilon}) = 0,$\n\nwe perform a Taylor expansion at $\\hat{\\theta}$ and incorporate the optimal gradient condition at $\\theta_{-z_m}$ and $\\hat{\\theta}$:\n\n$\\sum_{i=1}^n \\nabla l(z_i; \\hat{\\theta}) + \\epsilon \\cdot \\nabla l(z_m; \\hat{\\theta}) + H_{\\hat{\\theta}} (\\theta_{-z_m,\\epsilon} - \\hat{\\theta}) \\approx 0,$\nwhere $H_{\\hat{\\theta}} = \\sum_{i=1}^n \\nabla^2 l(z_i; \\hat{\\theta})$ is the Hessian matrix. Consequently, the Influence Function is defined as the derivative of the change in parameters of the retrained model due to perturbation with respect to the perturbation:\n\n$IF(z_m) = \\frac{d \\hat{\\theta}_{-z_m, \\epsilon}}{d \\epsilon}|_{\\epsilon=0} \\approx -H_{\\hat{\\theta}}^{-1} \\cdot \\nabla l(z_m;\\hat{\\theta}).$"}, {"title": "4 Modeling Data Influence in Meta Learning", "content": "It is evident that the datasets utilized for meta learning exhibit a hierarchical structure. Specifically, the whole dataset consists of multiple task-specific datasets. Consequently, when evaluating data influence in meta learning, we can assess the influence of individual tasks on training outcomes while also conducting a detailed analysis of the impact of specific data points\u2014i.e., instances\u2014within a given task.\nDue to the bilevel structure in meta learning, note that for instances, it is crucial to distinguish whether tthey are in the training dataset or the validation dataset. Consider the k-th task; if the data point we are concerned about is in the validation dataset, then only the meta parameter will be impacted, and we can directly apply the influence function method to evaluate its contribution. The data from the task validation set directly influences the update of meta parameters. In contrast, the impact of the task training set data on meta parameters is more complex; it indirectly affects the update of meta parameters by influencing the few-shot learning parameters that are relevant to the task. The following sections will provide our general frameworks for task and instance levels' data influence evaluation."}, {"title": "4.1 Evaluating the Influence of Tasks", "content": "Consider the k-th task, the information related to this task includes $\\mathcal{D}_k = \\mathcal{D}^{tr}_k \\cup \\mathcal{D}^{val}_k$. We will leverage influence function to evaluate how $\\mathcal{D}_k$ will affect the model given by meta learning. When we remove the k-th task from meta learning, the k-th inner training task will be completely eliminated. This is reflected in the outer layer, where $\\mathcal{L}_{k, val} (\\lambda, \\theta_k(\\lambda); \\mathcal{D}^{val}_k)$ will disappear. Therefore, we can ignore the specifics of the k-th inner training and focus solely on the outer level. The retrained meta parameter is defined as\n\n$\\lambda^*_{-k} = \\arg \\min_{\\lambda} \\sum_{i\\neq k} \\mathcal{L}_{i, val} (\\lambda, \\theta_i(\\lambda); \\mathcal{D}^{val}_i) + \\frac{\\delta}{2} ||\\lambda||^2.$"}, {"title": "A Direct Approach.", "content": "If we directly adopt the same idea of the original influence function and consider $\\mathcal{D}_k$ as a data point, we then may up-weight the loss for the k-th task $\\mathcal{L}_{k, val} (\\lambda, \\theta_k (\\lambda); \\mathcal{D}^{val}_k)$ by a small perturbation $\\epsilon$ and replace the $\\lambda^*_{-k}$ by the minimizer of the $\\epsilon$-parameterized model $\\lambda^*_{\\epsilon}$. Ignoring the dependence between the task-specific parameters and the meta parameters, one can intuitively derive an influence function by using a similar Taylor expansion of the partial derivative w.r.t. $\\lambda$ of the outer objective function as\n\n$IF(\\mathcal{D}_k) = (\\delta \\cdot I + H_{\\lambda, direct})^{-1} \\cdot \\partial_{\\lambda} \\mathcal{L}_{k, val} (\\lambda^*, \\theta_k(\\lambda^*); \\mathcal{D}^{val}_k),$\nwhere $H_{\\lambda, direct}$ is the Hessian matrix directly with respect to $\\lambda$, defined as\n\n$H_{\\lambda, direct} = \\sum_{i \\in I} \\partial_{\\lambda \\lambda} \\mathcal{L}_{i, val} (\\lambda^*, \\theta_i(\\lambda^*); \\mathcal{D}^{val}_i).$"}, {"title": "Our Method.", "content": "However, this method is flawed as it overlooks an important aspect: $\\theta_i(\\lambda)$ is dependent on $\\lambda$, and the experimental results in Table 1 further demonstrate the inaccuracy of this method. Mathematically, in the original IF definition, since there is no inner level function, we have $\\nabla \\mathcal{L}(\\hat{\\theta}); \\mathcal{D}) = 0$ and $\\nabla l(z_m; \\hat{\\theta}) = 0$. However, as in bilevel optimization the outer objective function $\\mathcal{L}_{Total}$ dependents both $\\lambda$ and $\\{\\theta(\\lambda)\\}_{i \\in I}$, for $\\lambda^*$ we do not have the direct gradient $\\partial_{\\lambda} \\mathcal{L}_{Total} (\\lambda^*, \\theta(\\lambda^*); \\mathcal{D}) = 0$ and its corresponding (1). Thus, we cannot use a similar Taylor expansion to (1) and get (6).\nTo address the above issue, the key observation is that while the direct gradient at $\\lambda^*$ is non-zero, its corresponding total gradient of the loss function is zero, i.e., $D_{\\lambda} \\mathcal{L}_{Total} (\\lambda^*, \\theta(\\lambda^*); \\mathcal{D}) = 0$. The following result provides a result on the computation of the total gradient."}, {"title": "Theorem 4.1.", "content": "The total gradient of the i-th task related outer loss $\\mathcal{L}_{i, val} (\\lambda, \\theta_i(\\lambda); \\mathcal{D}^{val}_i)$ with respect to $\\lambda$ can be written as:\n\n$D_{\\lambda} \\mathcal{L}_{i, val} (\\lambda, \\theta_i(\\lambda); \\mathcal{D}^{val}_i)\n= \\partial_{\\lambda} \\mathcal{L}_{i, val} (\\lambda, \\theta_i(\\lambda); \\mathcal{D}^{val}_i) + \\frac{d \\theta_i(\\lambda)}{d \\lambda} \\cdot \\partial_{\\theta_i} \\mathcal{L}_{i, val} (\\lambda, \\theta_i(\\lambda); \\mathcal{D}^{val}_i).$\nThe term $\\frac{d \\theta_i(\\lambda)}{d \\lambda}$ can be calculated by\n\n$\\frac{d \\theta_i(\\lambda)}{d \\lambda} = -\\partial_{\\lambda \\theta_i} \\mathcal{L}_{i} (\\lambda, \\theta_i(\\lambda); \\mathcal{D}^{tr}_i) \\cdot H_{i,in}^{-1},$\nwhere $H_{i,in}$ is the i-th inner-level Hessian matrix, defined as $H_{i,in} = \\partial_{\\theta_i \\theta_i} \\mathcal{L}_{i} (\\lambda, \\theta_i(\\lambda); \\mathcal{D}^{tr}_i)$.\nBased on the discussion above, it is clear that the direct Hessian matrix in (7) is also inadequate for the influence function in the bilevel setting. Therefore, we propose an expression for the total Hessian matrix that incorporates the total derivative."}, {"title": "Definition 4.2.", "content": "The total Hessian matrix of the outer total loss $\\mathcal{L}_{Total} (\\lambda, \\theta(\\lambda); \\mathcal{D})$ with respect to $\\lambda$ is defined as:\n\n$H_{\\lambda, Total} = \\sum_{i \\in I} (D_{\\lambda} D_{\\lambda} \\mathcal{L}_{i, val} (\\lambda, \\theta_i(\\lambda); \\mathcal{D}^{val}_i)).$"}, {"title": "Theorem 4.3.", "content": "Define the task-IF of the k-th task in the meta parameter $\\lambda^*$ as\n\n$task\\text{-}IF(\\mathcal{D}_k; \\lambda^*, \\theta_k(\\lambda^*))\n= -(\\delta \\cdot I + H_{\\lambda, Total})^{-1} \\cdot D_{\\lambda} \\mathcal{L}_{k, val} (\\lambda^*, \\theta_k(\\lambda^*); \\mathcal{D}^{val}_k).$\nThen after the removal of the k-th task, the retrained meta parameter $\\lambda^*_{-k}$ can be estimated by\n\n$\\lambda^*_{-k} \\approx \\lambda^* - para\\text{-}IF(\\mathcal{D}_k; \\lambda^*, \\theta_k(\\lambda^*)).$\nRemark 4.4. Note that the task influence function depends on the total Hessian matrix. For simplicity, we denote $\\mathcal{L}_{i, val} (\\lambda, \\theta_i(\\lambda); \\mathcal{D}^{val}_i)$ as $\\mathcal{L}_{i,0}$, then it can be written as\n\n$H_{\\lambda, Total} = \\sum_{i \\in I} (\\partial_{\\lambda \\lambda} \\mathcal{L}_{i,0} + 2 \\cdot \\frac{d \\theta(\\lambda)}{d \\lambda} \\sum(\\partial_{\\lambda \\theta_i}^2 \\mathcal{L}_{i,0}\n+ \\frac{d^2\\theta_i(\\lambda)}{d \\lambda^2} \\partial_{\\theta_i} \\mathcal{L}_{i,0} + \\frac{d \\theta_i(\\lambda)}{d \\lambda} \\cdot \\partial_{\\theta_i \\theta_i} \\partial_{\\lambda} \\mathcal{L}_{i,0}).$\nDue to the complex definition of $\\frac{d \\theta_i(\\lambda)}{d \\lambda}$ as discussed in (8), $\\frac{d^2\\theta_i(\\lambda)}{d \\lambda^2}$ requires a three-order partial derivative, presenting significant computation challenges. To address these complexities, we will introduce several accelerated algorithms in Section 5.1."}, {"title": "4.2 Evaluating the influence of Individual Instance", "content": "There are two instances in the meta learning dataset: instances in the training dataset and instances in the validation dataset. The validation instance appears on the outer level and will only influence the meta parameter without directly impacting the task-specific parameter. The training instances appear at the inner level and impact the task-specific parameter, thereby influencing the meta parameter indirectly. Therefore, we must delve into the inner training process and conduct a two-stage evaluation. In a word, the evaluation of validation instances is similar to the task evaluation problem, while evaluating training instances is more challenging and requires new techniques.\nValidation Data Influence. We first focus on the evaluation of influence for the validation data $z = (x, \\tilde{y})$ of the k-th task. Since the validation data was not used in the inner level loss, we can directly follow the idea of task-IF to the outer loss function (4). The only difference is that we up-weigh a term related to data point $\\tilde{z}$ in the k-th task $l(\\tilde{z}; \\theta_k(\\lambda))$ rather than the task term $\\mathcal{L}_{k, val}(\\lambda, \\theta_k(\\lambda); \\mathcal{D}^{val}_k)$. Then similar to Theorem 4.3, we obtain the following theorem."}, {"title": "Theorem 4.5", "content": "(Instance-IF for Validation Data). The influence function of the validation data $\\tilde{z} = (x, \\tilde{y})$ is\n\n$instance\\text{-}IF(\\tilde{z}; \\lambda^*, \\theta_k(\\lambda^*))\n= -(\\delta \\cdot I + H_{\\lambda, Total})^{-1} \\nabla l(\\tilde{z}; \\theta_k(\\lambda^*)).$\nAfter the removal of $\\tilde{z}$, the retrained optimal meta parameter $\\lambda^*_{\\tilde{z}}$ can be estimated by\n\n$\\lambda^*_{\\tilde{z}} \\approx \\lambda^* - instance\\text{-}IF(\\tilde{z}; \\lambda^*, \\theta_k(\\lambda^*)).$\nTraining Data Influence. We evaluate the influence of training data first. We will employ a two-phase analysis to analyze the impact of an individual data point $z = (x, y)$ in the k-th task. Initially, we utilize the IF to assess the data point's effect on its corresponding task-related parameter $\\theta_k(\\lambda)$. Since the meta parameter, $\\lambda$ is passed from the outer level and remains fixed during each inner-level training period. Thus, we can use the classical influence function directly to $\\mathcal{L}_{i} (\\lambda_i, \\theta_i; \\mathcal{D}_i)."}, {"title": "Theorem 4.6.", "content": "The influence function for the inner level (inner-IF) of $z = (x, y)$ from the training set is\n\n$inner\\text{-}IF(z; \\theta_k(\\lambda^*)) = -H_{k,in}^{-1} \\cdot \\nabla_{\\theta_k} l(z; \\theta_k(\\lambda^*)),$\nwhere $H_{k,in} = \\partial_{\\theta_k \\partial_{\\theta_k}} \\mathcal{L}_{i} (\\lambda^*, \\theta_k(\\lambda^*); \\mathcal{D}_k^{tr})$ is the k-th inner-level Hessian matrix.\nAfter the removal of z, denote $\\theta^*_k(\\lambda^*)$ as its corresponding retrained task-parameter $\\theta^*_z(\\lambda^*) = arg \\min_{\\theta_i} \\mathcal{L}_{i} (\\lambda^*, \\theta^*_z; \\mathcal{D}_k^{tr} \\backslash z))$. Then it can be estimated by\n\n$\\theta^*_z(\\lambda^*) \\approx \\theta_k(\\lambda^*) - inner\\text{-}IF(z; \\theta_k(\\lambda^*)).$\nNow we aim to approximate the influence of replacing $\\theta_k$ by $\\theta^*_z$ in the outer level. That is, how will the optimal meta parameter $\\lambda^*$ change under the removal of z. Note that the outer level loss in (4) only depends on the validation data and remains unchanged after the removal of z. This challenges applying up-weighting to the influence function effectively as the change of the outer loss is implicit. The result, which is shown in Theorem 4.7, shows the change in the outer-level loss function resulting from the removal of z."}, {"title": "Theorem 4.7.", "content": "If the k-th task related parameter changes from \\theta_k to \\theta^*_z, we can estimate the related loss function difference\n\n$\\mathcal{L}_{k, val} ((\\lambda, \\theta^*_z (\\lambda)) ; \\mathcal{D}^{val}_k) - \\mathcal{L}_{k, val} (\\lambda, \\theta_k(\\lambda); \\mathcal{D}^{val}_k)$\nby $\\mathcal{P}(\\lambda, \\theta_k (\\lambda); z)$, which is defined as\n\n$-\\nabla_{\\theta_k}\\mathcal{L}_{k, val} (\\lambda, \\theta_k (\\lambda); \\mathcal{D}^{val}_k)^T inner\\text{-}IF(z; \\theta_k(\\lambda)).$\nNow we can derive the influence function. Motivated by the above result, instead of up-weighting the loss function term, we focus on up-weighting the data influence term $\\mathcal{P}(\\lambda, \\theta_k(\\lambda); z)$. We add this term into the outer level loss function and up-weight it by a small $\\zeta$, which varies from 0 to 1. Then the outer level loss function becomes to\n\n$\\lambda^*_{\\zeta,z} = \\arg \\min_{\\lambda} \\sum_{i \\in I} \\mathcal{L}_{Total} (\\lambda; \\theta(\\lambda); \\mathcal{D}) + \\zeta \\cdot \\mathcal{P}(\\lambda, \\theta_k(\\lambda); z).$\nWhen $\\zeta = 1$, the influence of z is fully removed by adding this term into the loss function."}, {"title": "Proposition 4.8", "content": "(Instance-IF for Training Data). Let $\\zeta \\rightarrow 0$, we can obtain the influence function of the outer level as follows:\n\n$instance\\text{-}IF(z; \\lambda^*, \\theta_k(\\lambda^*)) = -H_{Total}^{-1} \\cdot D_{\\lambda} \\mathcal{P}(\\lambda^*, \\theta_k(\\lambda^*); z).$\nAfter the removal of z, the optimal meta parameter $\\lambda^*_z$ can be estimated by\n\n$\\lambda^*_z \\approx \\lambda^* - instance\\text{-}IF(z; \\lambda^*, \\theta_k(\\lambda^*)).$"}, {"title": "5 Computation Acceleration and Practical Applications", "content": "5.1 Computation Acceleration\nAlthough the results in Section 4 are closed-form solutions for evaluating data influence, they involve extensive calculations of the inverse Hessian-vector product (iHVP), which are coupled with other computational steps and also necessitate the computation of third-order partial derivatives. Thus, developing acceleration techniques is essential to enhance the scalability of our methods. We now present approximation methods designed to accelerate iHVP and third-order partial derivatives."}, {"title": "iHVP Acceleration via EK-FAC.", "content": "Due to the specific method for calculating the derivative of task-related parameter $\\theta_i(\\lambda)$ in (8) and the iHVP calculation in Theorem 4.6, our algorithm involves the computation of iHVP at several different stages. To expedite this computation and eliminate the need to store the Hessian matrix explicitly, we employ the EK-FAC method (Kwon et al., 2023). Additional implementation details can be found in the Appendix."}, {"title": "Total Hessian Matrix Approximation.", "content": "As we mentioned in Remark 4.4, computing the total Hessian matrix efficiently for large-scale neural networks presents significant challenges, primarily due to the requirement of calculating the third-order partial derivatives of the loss function with respect to the parameters. Given that the information conveyed by third-order derivatives is relatively limited compared to that of first and second-order derivatives, we propose an approximation for the total Hessian."}, {"title": "Theorem 5.1.", "content": "To approximate total Hessian $H_{\\lambda, Total}$, we can replace the following term in total Hessian (see 4.4)\n\n$H' = \\sum_{i \\in I} \\left[ \\frac{d^2\\theta_i(\\lambda)}{d \\lambda^2} \\partial_{\\theta_i} \\mathcal{L}_{i,0} + \\frac{d \\theta_i(\\lambda)}{d \\lambda} \\cdot \\partial_{\\theta_i \\theta_i} \\partial_{\\lambda} \\mathcal{L}_{i,0} \\right]$\nby $\\Gamma = \\sum_{i \\in I} ||\\partial_{\\theta_i} \\mathcal{L}_{i,0}||_1 \\cdot I$, where $I$ is the identity matrix.\nGenerally, compared to the original term H', $\\Gamma$ reflects the extent to which each parameter influences the loss function and captures significant gradient information by focusing on the main influencing factors via ignoring the second-order derivative terms. This enables the practical simplification of complex mathematical expressions while preserving essential information.\nHowever, EK-FAC is no longer applicable for computing the iHVP for the total Hessian proposed in this paper. This is because EK-FAC is based on the assumption that the parameters between different layers are independent. In contrast, the definition of the total Hessian in (4.4) needs interactions between different layers. Therefore, EK-FAC may not provide sufficiently accurate results in this context. To ensure precise, efficient, and stable computation of the iHVP, we propose the following accelerated method for our algorithm:"}, {"title": "Neumann Series Approximation Method.", "content": "For a vector v, we can express $H_{\\lambda, Total}^{-1} \\cdot v$ through the Neumann series:\n\n$H_{\\lambda, Total}^{-1} \\cdot v = v + \\sum_{j=1}^{+\\infty} (I - H_{\\lambda, Total})^j \\cdot v.$\nBy truncating this series at order J, we derive the following approximation:\n\n$H_{\\lambda, Total}^{-1} \\cdot v \\approx v + (I - H_{\\lambda, Total}) \\cdot v + \\cdot \\cdot \\cdot (I - H_{\\lambda, Total})^J \\cdot v.$\nIt is important to note that we do not specifically accelerate the inversion of the Hessian matrix; rather, we directly optimize the iHVP procedure. As a result, throughout the entire computation process, there is no need to simultaneously store the large Hessian matrix, which significantly reduces the memory requirements of our method."}, {"title": "5.2 Applications of Influence Functions", "content": "In this section, we present application methods for downstream tasks based on the previously derived influence functions for tasks and instances."}, {"title": "Model Editing by Data Removal.", "content": "We can use IFs to update the model under the removal of certain data or tasks. Specifically, the model after removing the k-th task can be estimated as $\\lambda^* - task\\text{-}IF(\\mathcal{D}_k; \\lambda^*, \\theta_k (\\lambda^*))$. Additionally, the model for removing instance z from the k-th task can be estimated as $\\lambda^* - instance\\text{-}IF(z; \\lambda^*, \\theta_k(\\lambda^*))$."}, {"title": "Data Evaluation", "content": "By appropriately selecting the model evaluation function, we can define influence scores(ISs), which measure the influence of specific tasks or instances on new tasks. These scores can then be applied to task selection in order to enhance meta learning performance or to adversarial attacks to assess model robustness."}, {"title": "Definition 5.2", "content": "(Evaluation Function for Meta Learning). Given a new task specific dataset $\\mathcal{D}_{new} = \\mathcal{D}^{tr}_{new} \\cup \\mathcal{D}^{val}_{new}$ , the few-shot learned parameter $\\theta'$ for the task is obtained by minimizing the loss $\\mathcal{L}_i(\\lambda^*, \\theta; \\mathcal{D}^{tr}_{new})$. We can evaluate the performance of the meta parameter $\\lambda^*$ based on the loss of $\\theta'$ on the validation dataset, expressed as $\\sum_{z \\in \\mathcal{D}^{val}_{new}} l(z; \\theta')$.\nBased on this metric, we propose a calculation method for the task and instance Influence Score, defined as $IS = \\sum_{z \\in \\mathcal{D}^{val}_{new}} \\nabla l(z; \\theta') \\cdot IF$. A detailed theoretical derivation can be found in the Appendix."}, {"title": "6 Experiments", "content": "In this section, we demonstrate our main experimental results on utility, efficiency, effectiveness, and the ability to identify harmful data."}, {"title": "6.1 Experimental Settings", "content": "Dataset. We utilize three datasets: omniglot Lake et al. (2015), MNIST LeCun et al. (1998) and MINI-Imagenet Vinyals et al. (2016). omniglot contains 1,623 different handwritten characters from 50 different alphabets. Each of the 1,623 characters was drawn online via Amazon's Mechanical Turk by 20 different people. MNIST is a hand-writing digits dataset, it has a training set of 60,000 examples, and a test set of 10,000 examples. MINI-Imagenet consists of 50,000 training images and 10,000 testing images, evenly distributed across 100 classes.\nBaselines. For the task level, we employ two baseline methods to compare with our proposed task-IF in Theorem 4.3: Retrain and direct IF. Retrain: We retrain the model from scratch after removing the selected tasks from the training set. direct IF: As discussed in Section 4.1, this method is a direct implementation of (6), which is a direct generalization of the original IF.\nFor the instance level, we employ retrain as the baseline method. Retrain (Training/Validation): We retrain the model after removing the selected instance from the training/validation dataset for some task-related dataset. We further conduct experiments based on instance-IF (Training/validation). instance-IF (Training) is a direct implementation of Proposition 4.8. Instance-IF (Validation) is a direct implementation of Theorem 4.5. Relevant algorithms for all task and instance evaluation methods are provided in the Appendix.\nEvaluation Metric. We utilize two primary evaluation metrics to assess our models: Accuracy and runtime (RT). The Accuracy measures the model's performance as the proportion of correct predictions to the total predictions. Runtime, measured in seconds, evaluates the running time of each method to update the model.\nImplementation Details. Our experiments used an Intel Xeon CPU and a GTX 1080 ti GPU. For task-level evaluation, we train the MAML model, randomly remove some tasks, and then use direct IF and task-IF to update the model. For instance level, we randomly remove 40% sample for 20 tasks. During the training phase, we update the model for 5000 iterations and randomly sample 10,000 tasks for the omniglot and MINI-Imagenet datasets and 252 tasks for the MNIST dataset. We repeat the experiments 5 times with different random seeds."}, {"title": "6.2 Evaluation of Utility and Editing Efficiency", "content": "To evaluate the utility and editing efficiency of our methods, we compare our algorithms with random removal from the perspectives of accuracy and runtime. Our experimental results, as presented in Table 1, demonstrate the superiority of task-IF compared to baseline approaches while highlighting the critical trade-off between computational efficiency and accuracy. Specifically, on the Omniglot dataset, task-IF achieved accuracy scores close to those of retraining (0.7804 vs. 0.7908) while significantly reducing the runtime from 316.74 to 65.69. This pattern is consistently observed across other datasets, particularly in MINI-ImageNet, where the runtime decreased dramatically from 682.56 via retraining to 74.63 via task-IF, with an acceptable accuracy difference (0.3071 to 0.2668). These results underscore task-IF's capability to"}, {"title": "6.3 Results of Harmful Data Removal", "content": "Another application of our influence functions is to evaluate how harmful or helpful one task is for our model. To validate our method", "metrics": "test accuracy and the fraction of mislabeled tasks identified across different proportions of training data checked.\nThe left plot shows that our IS-based approach consistently outperforms random removal across all checking ratios. When examining 25% of the training data, the IS-based method achieves a test accuracy of approximately 62.5%, while random removal yields only 55% accuracy. This significant performance gap of 7.5 percentage points indicates that our method effectively identifies and removes truly harmful tasks rather than arbitrary ones.\nThe right plot further validates our approach's effectiveness in identifying mislabeled tasks. The IS-based method demonstrates remarkably efficient detection, identifying nearly 100% of mislabeled tasks after checking only 40% of the training data. In contrast, the random removal baseline shows a linear relationship between the fraction checked and identified, achieving only about 45% detection rate even after examining 95% of the training data. This substantial difference in detection efficiency (approximately 2.2\u00d7 better) underscores our method"}]}