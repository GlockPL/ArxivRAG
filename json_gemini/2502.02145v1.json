{"title": "Risk-Aware Driving Scenario Analysis with Large Language Models", "authors": ["Yuan Gao", "Mattia Piccinini", "Johannes Betz"], "abstract": "Large Language Models (LLMs) can capture\nnuanced contextual relationships, reasoning, and complex\nproblem-solving. By leveraging their ability to process\nand interpret large-scale information, LLMs have shown\npotential to address domain-specific challenges, including\nthose in autonomous driving systems. This paper proposes\na novel framework that leverages LLMs for risk-aware\nanalysis of generated driving scenarios. We hypothesize that\nLLMs can effectively evaluate whether driving scenarios\ngenerated by autonomous driving testing simulators are\nsafety-critical. To validate this hypothesis, we conducted an\nempirical evaluation to assess the effectiveness of LLMs\nin performing this task. This framework will also provide\nfeedback to generate the new safety-critical scenario by\nusing adversarial method to modify existing non-critical\nscenarios and test their effectiveness in validating motion\nplanning algorithms. Code and scenarios are available at:\nhttps://github.com/yuangao-tum/Riskaware-Scenario-analyse", "sections": [{"title": "I. INTRODUCTION", "content": "The autonomy of vehicles has advanced rapidly in recent\nyears, reaching a level where human intervention is barely\nor not at all required in certain Operational Design Domains\n(ODDs). Leading the way are vehicle manufacturers such as\nMercedes and BMW, which offer production vehicle at SAE\nLevel 3, depending on the system's design. Additionally,\ncompanies like Waymo have introduced fully autonomous\nrobotaxi services operating at SAE Level 4 in selected\nODDs, showcasing the potential of driverless technology in\nurban environments. This progress is largely attributed to\ndeveloping and validating highly reliable Automated Driving\nSystems (ADS). Traditionally, validation has been conducted\nin real-world test environments, such as on-road testing\n[1]. However, uncertainties remain regarding whether these\nADS are sufficiently safe and robust in corner cases or\nsafety-critical situations [2].\nMany researchers and companies are focusing on\nscenario-based approaches to testing ADS, not only\nbecause it is a cost-effective method for simulating\nrealistic driving conditions [3], but also because distinct\nsafety-critical scenarios can effectively simulate corner cases\nthat are either rare or not captured in real-world data\n[4]. However, determining whether these scenarios are\nsufficiently safety-critical is a crucial challenge. To address\nthis, it is essential to consider safety-critical metrics [5],\nsuch as Time-to-Collision (TTC), which are instrumental in\nidentifying safety-critical situation based on quantitative risk\nassessment by using temporal proximity.\nCurrent research has identified a range of proximity\nmetrics, which can be classified into temporal and\nnon-temporal indicators [6]. Generally, these metrics\nare calculated by test engineers to assess whether a\ngenerated scenario is safety-critical. However, with the\nrelease of OpenAI's ChatGPT-a powerful AI chatbot-the\noutstanding capabilities of LLMs have emerged in tasks such\nas text generation, summarization, and reasoning."}, {"title": "II. RELATED WORK", "content": "Recently, many publications have emerged on\nscenario-based testing, focusing on generating various\nsafety-critical scenarios for evaluation of ADS. By leveraging\ninformation from the real collected datasets, the data-driven\nmethod is proposed to generate a scenario that reflects\nreality and improves the diversity of the scenario to avoid\nthe risk of over-fitting by using Bayesian Networks [11] and\nDeep Generative Modles [12]. The adversarial generation\nmethod is used to generate scenarios more efficiently\nsince it actively creates risky scenarios by attacking the\nADS. Additionally, differentiable renders would be used\nto generate the static scenarios [13], and dynamic scenario\ngeneration could be usually formatted in an Reinforcement\nLearning (RL) framework [14]. Meanwhile, to improve\nthe controllability of specific scenarios, a knowledge-based\napproach is proposed based on pre-defined rules with\ndomain expertise [15] or knowledge-guided learning like\ncombining the feasible constraints with adversarial policy\ndevelopment [16] based on RL framework.\nWith the increasing demand for LLMs' powerful functions\nlike reasoning and understanding ability, researchers have\nbegun applying them to systems and applications related\nto autonomous driving in the last two years, such as\nvisual perception [17], motion planning [18], vehicle control\n[19] etc. In the context of LLMs-based driving scenario\ngeneration, it could be classified into microscopical and\nmacroscopical categories depending on the simulator used,\nsuch as CARLA to evaluate specific driving behaviors\nof ego vehicle and SUMO to produce large-scale traffic\nscenarios. In Chatscene [20] and TTSG [21], the pipeline of\ntext description by using LLMs with prompt techniques to\ngenerate safety-critical scenarios in CARLA was proposed,\nespecially in Chatscene [20] they use the newly generated\nscenario to train and improve the control algorithm of the ego\nvehicle. For the large-scale scenario generation, ChatSUMO\n[22] and OmniTester [23] are proposed to generate the\naccurate urban simulation by using the text description.\nOverall, the above publication analyzed the domain-specific\nlanguage for each simulator, then used the template-based\nmethod and chain of thought in prompts to improve the\nperformance of LLMs-based scenario generation. After that,\nthey used specific metrics to evaluate whether the generated\nscenario fulfilled the demand like rarety, diversity, safety\ncriticality and so on.\nAfter driving scenarios are generated using the above\nclassical and LLMs-based methodes, several publications\nhave recently addressed this challenging topic safety-critical\ngenerated scenarios identification. In [24], safety-critical\nscenarios are defined as scenarios in which the autonomous\nvehicle causes or nearly causes a collision. Safety metrics\nlike time to collision, time to brake, required deceleration,\nand new traffic quality metrics were combined for the\nidentification of safety-critical scenarios in [25]. Until now,\nafter calculation for the safety metrics, scenarios would be\nidentified by human experts or test engineers. In considering\nLLMs-based scenario analysis, LLMs are first used to\nempirically identify the realistic driving scenarios in [26].\nAlso, in the OmniTester [23], the researcher uses LLMs as an\nevaluator to evaluate the accuracy of the generated scenario\ncompared to the text description.\nOverall, little attention has been paid to identifying\nsafety-critical scenarios using LLMs, as well as generating\nsuch scenarios through LLM-based adversarial methods,\nwhich can efficiently provide more corner-case benchmarks."}, {"title": "III. METHODOLOGY", "content": "In this paper, we analyze scenarios from real-world\ndatasets re-simulated within the CommonRoad simulation\nframework, which serves as a benchmark for testing motion\nplanning algorithms, and our proposed analysis framework\nis illustrated in Figure 2. Initially, we focus on the\nCommonRoad scenario format, where a CommonRoad XML\nfile encapsulates a Driving simulation environment and a\nPlanningProblem.\nSubsequently, we extend the 6-layer model introduced\nin [27], which describes the six essential elements for\nthe driving scenario by integrating the driving simulation\nenvironment and PlanningProblem with the ego layer\nfrom motion planner to comprehensively represent driving\nscenario within the context of motion planning. In our paper,\nwe use one of the high performance modular motion Planner\nFrenetix motion planner [28] from our lab. After that we\nparse relevant information from road, traffic sign, obstacle,\nand ego layers to construct effective prompting context for\ndownstream analysis.\nUsing a combination of role prompting, chain-of-thought\nreasoning and template-based techniques, we leverage\nsafety-critical metrics to guide LLMs in analyzing the\nsafety-criticality of the scenarios. These metrics ensure a\nrobust analysis, enabling identifying and evaluating potential\nhazards and safety concerns within the scenarios."}, {"title": "A. CommonRoad Scenario format", "content": "The CommonRoad scenario format is a standardized\nrepresentation that facilitates the simulation of various\ndriving scenarios, providing a comprehensive framework for\ntesting and benchmarking motion planning algorithms. It"}, {"title": "B. Layer Model", "content": "The CommonRoad XML format is complex and\nchallenging for LLMs to interpret directly. Therefore, we\nneed to decode this format by importing the layer model.\nThe 6-layer model is a conceptual framework that describes\nthe six essential elements of a driving scenario: the road,\nthe traffic sign, temporary change, the traffic participants,\nthe traffic environment, and the digital map. We do not\nneed to consider the temporary change and environmental\nconditions for CommonRoad simulation. Therefore, in the\nlayer model we used to analysis CommonRoad XML file,\nwe got information about the element lanelet representing\nthe road layer, the traffic sign layer model from traffic sign\nand traffic light elements, the obstacle elements represent the\ntraffic participants layer. Additionally, to build the new ego\nlayer, we consider the Planning Problem, which represents\nthe ego vehicle's initial state and goal state, to combine\nthe simulated trajectory from the Frenetix motion planner.\nMoreover, for each Scenario S could be describe by:\n$S = {L,T,O,E}$                                                              (1)\nwhere L represents the lanelet, T denotes the traffic sign, O\nstands for the obstacle, and & represents the ego vehicle.\nFurthermore, this decoding process involves extracting\nrelevant information from the XML file and from ego\ntrajectory CSV file by converting these into JSON files and\ntranslating them into a structured format for each layer. After\nthat we need to parse layer model information into a context\nfor the prompt message of LLMs."}, {"title": "C. Prompt techniques", "content": "Prompt techniques are essential for guiding LLMs in\nanalyzing complex problems. General prompt techniques\ninclude zero-shot [29] and few-shot prompting [30].\nZero-shot prompting involves providing the model with\na task description without any examples, while few-shot\nprompting includes a few examples to help the model\nunderstand the task better. However, these general techniques\nare not able to analyze complicated scenarios due to their\ncomplexity and the need for detailed reasoning.\nTo address these challenges, we employ more advanced\ntechniques, such as role prompting, chain-of-thought\nreasoning, and template-based prompts. We use role\nprompting techniques by introducing detailed system\nmessages to provide more information about the role\nof our LLMs agent, the definition of the risk score,\nand the used metrics. This helps the LLM adopt the\nperspective of a domain expert and generate responses\naligned with that expertise. In the user message, combining"}, {"title": "\u2022", "content": "\u2022\nthe chain-of-thought reasoning, we provide the context of\nthe scenario and the guidance for the LLMs to analyze the\nsafety criticality of the scenario, ensuring a more robust and\ntransparent evaluation.\nAdditionally, we use template-based techniques with\nspecific context parts and outputs format to ensure the\nrobustness, accuracy of each prompting, and consistency of\nthe response of LLMs. In the Figure 3, we have listed three\nprompt templates: Cartesian coordinates template, Frenet\ncoordinates template, and safety-critical metrics template.\nSpecifically, each template uses a different context C. To\ncombine the relevant information from the context C by\nparsing the lanelet information, the status of obstacles,\nand the ego vehicle for each timestep which allows the\nLLMs to understand the motion development of each vehicle\nand process the information, leading to more accurate and\nreliable analysis. To convert Scenario S into context C by\nusing the parsing function F\n$C = F(S)$                                                              (2)\nCartesian coordinates context provides a global view\nwith x and y Cartesian coordinates of the scenario,\nincluding the positions, speeds, accelerations, and the\nlocation in the lanelet of all vehicles, which are easy to\nget. The format of the parsing function $F_{cart}$ is shown\nbelow,\nID: Vehicle_id (with ego Vehicle)\nPosition: (x, y) m\nOrientation: $\\Theta_{cart}$ rad\nVelocity: v m/s\nAcceleration: a m/s\u00b2\nLanelet: l"}, {"title": "\u2022", "content": "\u2022\nFrenet [31] coordinates context provides a detailed view\nof the scenario based on the coordinates of the ego car,\nincluding the relative directions, positions, speeds, and\naccelerations of the ego vehicle and the surrounding\nvehicles. We convert the parsing function $F_{cart}$ into\n$F_{fren}$:\nID: Obstacle_id,\nRelative direction: $\\Theta_{fren}$ ,\nPosition: (s, d) m,\nVelocity: (vs, va) m/s,\nAcceleration: (as, ad) m/s\u00b2,\nMotion: (ms, ma)."}, {"title": "\u2022", "content": "\u2022\nwhere $\\Theta_{fren}$ is defined as:\nFront: If $s > L_{veh}  |d|< W_{veh}$.\nFront-Left: If $s > L_{veh}  d > W_{veh}$.\nFront-Right: If $s > L_{veh}  d < -W_{veh}$.\nBehind: If $s <-L_{veh}  |d| \u2264 W_{veh}$.\nRear-Left: If $s <-L_{veh}  d > W_{veh}$.\nRear-Right: If $s <-L_{veh}  d <-W_{veh}$.\nLeft: If d > W_{veh} s  L_{veh}.\nRight: If d <-W_{veh} s  L_{veh}.\nand $L_{veh}, W_{veh}$ are the length and width of the ego\nvehicle. Based on the relative direction, motion m is\ndetermined as:\n$M_s [0]$, if $U_{rel, s} > 0  \\Theta_{fren} \u2208 {Front, Front-Left, Front-Right}$ ,\n$M_s [1]$, if $U_{rel, s} <0 \\Theta_{fren} \u2208 {Front, Front-Left, Front-Right}$ ,\n$M_s [2]$, if $U_{rel, s} > 0 \\Theta_{fren} \u2208 {Behind, Rear-Left, Rear-Right}$ ,\n$M_s [3]$, if $U_{rel, s} <0 \\Theta_{fren} \u2208 {Behind, Rear-Left, Rear-Right}$ ,\n$M_s [4]$, if $U_{rel, s} = 0$ ,\n$M_s [5]$, otherwise.\n$M_d[0]$, if $U_{rel, d} > 0 \\Theta_{fren} \u2208 {Left, Front-Left, Rear-Left}$ ,\n$M_d[1]$, if $U_{rel, d} <0 \\Theta_{fren} \u2208 {Left, Front-Left, Rear-Left}$ ,\n$M_d[2]$, if $U_{rel, d} > 0 \\Theta_{fren} \u2208 {Right, Front-Right, Rear-Right}$ ,\n$M_d[3]$, if $U_{rel, d} <0 \\Theta_{fren} \u2208 {Right, Front-Right, Rear-Right}$ ,\n$M_d[4]$, if $U_{rel, d} = 0$,\n$M_d[5]$, otherwise.\n$M_s$ = \n$M_d$ = \nSafety critical metrics context provides the key values,\nsuch as the relative distance and the time to collision\nbetween vehicles and ego car. Furthermore, the system\nmessage provides more information about calculating\nthe risk score. The format of the parsing function $F_{metrics}$\nfor the context is shown as:\nID: Obstacle_id,\nRelative Direction: $\\Theta_{fren}$ ,\nDistance to Collision: $(dtc_{long}, dtc_{lat})$ m,\nTime to Collision: $(ttc_{long}, ttc_{lat})$ rad,\nMotion: (ms, ma)."}, {"title": "D. Safety-Critical Metrics", "content": "In our LLMs-based analysis, we consider two kinds of\nclassical safety-critical metrics. One is time to collision\n(TTC) [5], and the other is a distance-based metric minimal\ndistance to collision (MDC), which is a simplified version of\nProportion of Stopping Distance (PSD) [32] independent of\nbraking dynamics since it is unknown in the CommonRoad\nsimulation. These definitions are in the following:\nTTC(t) = $\\frac{X_{i-1}(t) - X_{i}(t) - L_{i}}{V_{i}(t) - V_{i-1}(t)}$\nMDCi (t) = |Xi\u22121(t) \u2013 Xi(t) \u2013 Li, \n\u2022 V: Vehicle velocity vector\n\u2022 X: Vehicle position vector\n\u2022 L: Subject vehicle's length\nCombining TTC and MDC provides a multi-dimensional\nview of safety-criticality, addressing both the temporal and\nspatial factors of potential collisions. This synergy enhances\nthe ability to detect, assess the collision situation.\nIt is important to note that we did not give the detailed\nequations of TTC and MDC metrics in the Cartesian\ncoordinate prompt and Frenet coordinates prompt as\nshown in Figure 3. We also do not calculate the related\nmetrics since we want to test LLMs' reasoning and\nunderstanding ability. Compared to these two prompts, in\nsafety-critical metrics prompts, we provide the detailed\nrelated values of TTC and MDC in the context by using\nthe parsing function Fmetrics and give the logical threshold in\nthe system message. However, LLMs still need to understand\nthe logical information to determine the final risk score based\non these frames."}, {"title": "IV. RESULTS & ANALYSIS", "content": "In this section, we evaluate empirically the performance of\nour proposed LLM-based scenario analysis framework. The\nevaluation is conducted on 100 simulated collision scenarios\nfrom the CommonRoad by using a Frenetix motion planer.\nWe assess the effectiveness of our framework using our three\nproposed prompt templates and compare the results with\nhuman annotated label."}, {"title": "A. Experimental Setup", "content": "To evaluate our framework, we use the following setup:\nDataset: We randomly run the ego vehicle with Frenetix\nmotion planer in 6000 real recorded driving simulation"}, {"title": "B. Results", "content": "We present the results of our framework in the following\nsubsections.\n1) Accuracy: The framework's performance across three\nmodels and in three distinct templates is measured in\nterms of accuracy in Figure 4 and is evaluated by\ncomparing the LLM's predictions collision ID or near\nnear-collision ID with the ground truth labels provided\nby human experts. The results demonstrate that model\nperformance improves with structured and detailed prompts.\nUnsurprisingly, GPT-40-mini underperforms compared to\nGPT-40 and Gemini 1.5 Pro, with GPT-40 achieving the\nbest results across all templates. LLMs' reasoning ability\nis proven reliable using Frenet-coordinates prompts, as they\ncan effectively interpret and analyze scenarios even when\ndetailed equations or calculations, such as TTC and MDC,\nare omitted in the prompt. However, the safety-critical\nmetrics prompt, which provides structured TTC and\nMDC values via the parsing function Fmetrics and logical\nthresholds in the system message, significantly enhances\nLLM performance. This setup enables the models to act as\n\"experts in collision analysis,\" leveraging domain-specific\nknowledge to determine risk scores based on logical\ninformation, delivering robust and accurate results closely\naligned with human analysis.\n2) Response times: We record response times across\nmodels and templates to compare the computational\nefficiency of LLMs in generating results for different\ndriving scenarios. Figure 5 presents a boxplot of response\ntime distributions per model and template, analyzing 100\nscenarios at the final timestep."}, {"title": "V. DISCUSSION", "content": "The results demonstrate the effectiveness of our\nLLM-based scenario analysis framework. Furthermore, this\nframework accurately identifies safety-critical scenarios\nacross models and templates. Overall, GPT-40 offers the\nbest overall balance between accuracy and efficiency.\nAdditionally, based on the safety-critical metrics template,\nthe LLM's reasoning capabilities are comparable to\nhuman experts, especially in showcasing its potential for\nautonomous scenario analysis.\nHowever, one of the powerful abilities of LLMs is\ncounterfactual reasoning, which allows them to suggest\nmodifications that could increase safety-criticality in\nscenarios. By leveraging this capability, we can obtain\nfeedback on modifying a non-critical scenario into a\nsafety-critical one."}, {"title": "A. Feedback", "content": "Firstly, we use our proposed LLM-based scenario analysis\nframework to analyze the non-critical scenario called\nBEL_Antwerp-1_14_T-1.XML of the 4700 scenarios\nwhere the Frenetix motion planner indeed finds an optimal\ntrajectory.\nSince in Figure 4 the combination between LLMs-GPT-40\nwith safety-critical metrics prompt templates performs better\nthan the others, we use this combination to get the feedback\nby adding a new following requirement in the output format\nof safety-critical metrics templates:\n### Safety analysis for timestep <timesteps>:\nObstacle Analysis:\n### Summary in JSON Format:\n***If no collision risk is detected, suggest\nmodifications to the obstacle's motion to\ninduce a collision by adjusting the Distance\nto Collision or Time to Collision.\nFor example: \"For Obstacle 1, reducing the\nlateral DTC to 0.5 m or the TTC to 0.5s\nwould lead to a collision.\" Additionally,\nidentify the obstacle ID for which a collision\ncan be most easily achieved by modifying its\nmotion, and outline the reasoning process.***"}, {"title": "B. Scenario modification", "content": "Now, we use simplified zero-shot prompts to modify\nthis CommonRoad BEL_Antwerp-1_14_T-1.XML file. In\nthis prompt, we provide the context about the Cartesian\ncoordinates information for obstacle 30762 and ego vehicle,\nas well as the relative information from Frenet coordinates of\nobstacle 30762, including the above suggestions. Although it\nis not a systematical template, after trying different zero-shot\nprompts, we generate a new safety-critical scenario as shown\nin Figure 6. Indeed, this is a new LLMs-based adversarial\nmethod for safety-critical scenario generation which integrate\nour LLMs-based scenario analysis framework."}, {"title": "VI. CONCLUSION & OUTLOOK", "content": "This paper proposes a novel LLMs-based scenario analysis\nframework to assess the safety-criticality of driving scenarios\nfrom CommonRoad across different models and prompt\ntemplates. We empirically evaluate the performance of our\nframework and prove the reasoning and understanding ability\nof LLMs in driving scenario analysis. We also extend the\nproposed framework to generate new safety-critical scenarios\nby using the adversarial method in consideration of the\nfeedback from LLMs. For future work, we could extend\nthis framework to another simulator, such as in nuPlan\nand CARLA; we will also develop systematic templates to\nenhance the LLMs-based adversarial scenario generation."}]}