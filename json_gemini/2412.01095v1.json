{"title": "VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models", "authors": ["Muchao Ye", "Weiyang Liu", "Pan He"], "abstract": "The rapid advancement of vision-language models (VLMs) has established a new paradigm in video anomaly detection (VAD): leveraging VLMs to simultaneously detect anomalies and provide comprehendible explanations for the decisions. Existing work in this direction often assumes the complex reasoning required for VAD exceeds the capabilities of pretrained VLMs. Consequently, these approaches either incorporate specialized reasoning modules during inference or rely on instruction tuning datasets through additional training to adapt VLMs for VAD. However, such strategies often incur substantial computational costs or data annotation overhead. To address these challenges in explainable VAD, we introduce a verbalized learning framework named VERA that enables VLMs to perform VAD without model parameter modifications. Specifically, VERA automatically decomposes the complex reasoning required for VAD into reflections on simpler, more focused guiding questions capturing distinct abnormal patterns. It treats these reflective questions as learnable parameters and optimizes them through data-driven verbal interactions between learner and optimizer VLMs, using coarsely labeled training data. During inference, VERA embeds the learned questions into model prompts to guide VLMs in generating segment-level anomaly scores, which are then refined into frame-level scores via the fusion of scene and temporal contexts. Experimental results on challenging benchmarks demonstrate that the learned questions of VERA are highly adaptable, significantly improving both detection performance and explainability of VLMs for VAD.", "sections": [{"title": "1. Introduction", "content": "Video anomaly detection (VAD) aims to automatically identify unexpected and abnormal events in video sequences, with broad applications ranging from autonomous driving [2] to industrial manufacturing [34]. While achieving good performance in VAD is essential, providing clear explanations for detected anomalies is even more crucial.\nTo this end, our work primarily focuses on explainable VAD, which requires both comprehensive visual un-"}, {"title": "Key Observations and Research Question.", "content": "While prior research demonstrates the potential of applying VLMs to VAD, we identify that this new paradigm is hindered by a shared critical issue: the use of additional reasoning modules or fine-grained labeled datasets incurs significant computational cost either in the inference or training phases.\nFirst, decoupling a VAD system into a frozen VLM and an extra LLM introduces more overhead in inference, because it separates the description generation and reasoning processes. Secondly, although IT-based methods enable VLMs to effectively integrate description and reasoning for VAD, they require additional manpower and computational resources for annotating and finetuning on fine-grained labeled instruction datasets, which is time-consuming and not scalable for large-scale datasets. In light of this, we investigate the following unexplored yet important question:\nCan we enable a frozen VLM to integrate description and reasoning for VAD without instruction tuning?"}, {"title": "Our Approach.", "content": "This research question is nontrivial because the reasoning ability of a frozen VLM is limited in general visual tasks, and it struggles to handle complex reasoning tasks like VAD, which requires the understanding of subtle, context-dependent outliers. To illustrate, Table 1 shows that prompting frozen VLMs with simple VAD questions used in existing works leads to unsatisfactory results. Thus, instruction-tuning a VLM seems necessary to make it responsive to specific instructional cues and capture delicate visual variations. In this paper, we question the necessity of such an operation and propose a principled approach to tailor frozen VLMs for VAD.\nSpecifically, our solution is guided by the intuition that the reasoning ability of VLMs for VAD will improve if we find questions with suitable and concrete description of abnormal patterns rather than with abstract and general words like \"anomaly\" to prompt them. Our idea is to iteratively refine anomaly descriptions from abstract ones (e.g., \"is there any anomaly?\") to detailed, specific characterizations.\nDriven by such insight, we propose a framework, termed VERA, to explore verbalized learning for VAD. This framework considers the practical constraint that it is suboptimal to manually write down VAD guiding questions across VLMs, so it introduces a data-driven learning task to identify suitable anomaly-characterization questions containing concrete abnormal patterns for the frozen VLM using coarsely labeled datasets, eliminating the need for IT. Specifically, in the training phase, VERA treats the questions guiding the reasoning of VLMs in VAD as learnable parameters, improving them based on the verbal feedback from an optimizer VLM on the performance of a learner VLM on an intermediate VAD subtask\u2014binary video classification for each video in the VAD training set. This design is both efficient and appropriate for VAD, as it accounts"}, {"title": "3. The VERA Framework", "content": "Our approach adapts VLMs to detect video anomalies without additional reasoning modules or instruction tuning. We now formulate the VAD task and detail the design of VERA."}, {"title": "3.1. Problem Formulation", "content": "Video Anomaly Detection. Let V be a video with F frames, represented as $V = \\{I_i\\}_{i=1}^F$, where $I_i$ is the i-th frame ($1 \\leq i \\leq F$). Our objective is to locate and detect the start and end of anomalous events within V. In standard labeling, any frame associated with an anomaly is labeled as 1, and normal frames are labeled as 0. Therefore, the ground truth label sequence for V is $Y = [Y_1,...,Y_F]$, where $Y_i \\in \\{0,1\\}$ represents the fine-grained label for $I_i$. We aim to use a frozen VLM, $f_{VLM}$, to generate anomaly score predictions across all frames, $\\hat{Y} = [\\hat{y}_1,..., \\hat{y}_F]$, where $\\hat{y}_i \\in [0, 1]$ is a continuous anomaly score for $I_i$.\nAvailable Training Data for VAD. Typically, VAD datasets only provide coarsely labeled training sets [25, 28, 35, 45]. We denote a VAD training set as $D = \\{(V^{(j)},Y^{(j)})\\}_{j=1}^N$, where N is the total number of training videos, $V^{(j)}$ represents the j-th video ($1 \\leq j \\leq N$) and $Y^{(j)}$ is the corresponding video-level label. $Y^{(j)} = 1$ if $V^{(j)}$ contains any anomaly defined by the dataset annotators, e.g., abuse or arson activities, and $Y^{(j)} = 0$ if $V^{(j)}$ has no anomalies. For $V^{(j)}$, we suppose it contains $F_j$ frames and denote the frames sequence as $V^{(j)} = \\{I_i^{(j)}\\}_{i=1}^{F_j}$, where $I_i^{(j)}$ is the i-th frame ($1 \\leq i \\leq F_j$) in $V^{(j)}$."}, {"title": "3.2. Training in VERA: Finding Guiding Questions for VAD via Verbalized Learning", "content": "Training Objective. We aim to learn guiding questions that break down a complex and ambiguous concept (i.e., what is an \"anomaly\") into a set of identifiable anomalous patterns to unlock reasoning capabilities within frozen VLMs for VAD tasks. Those patterns vary among datasets, making manually designed descriptions ineffective for generalization. To address this, we propose a general verbalized learning framework shown in Fig. 2 to generate the desired guiding questions. We denote the guiding question set as $Q = \\{q_1,..., q_m\\}$, where $q_i$ is the i-th question ($1 \\leq i \\leq m$) and m is the number of questions. The training framework considers Q as the learnable parameters, which are optimized through verbal interaction between a learner and an optimizer, modeled by VLMs through leveraging their ability to follow instructions with given prompts.\nTraining Data. The training data for learning Q consist of paired sampled video frames and video-level labels. Sampling is necessary because the amount of video frames is so huge that we cannot compute with every frame. We explore three types of sampling strategies and find that uniform sampling [57] yields the best results. We will use it for"}, {"title": "Updating Q via Learner and Optimizer.", "content": "Since Q are verbal expressions for specific anomaly patterns, VERA inherits the idea of VML [47] in training: optimizing language-based parameters by verbal communication between a learner agent $f_{learner}$ and an optimizer agent $f_{opt}$, rather than by numerical optimization algorithms like Adam [18]. We take an arbitrary iteration t for illustration in this section. Please refer to Algorithm 1 in Sec. A for the complete iterative training in VERA.\nLearner and Optimizer. We denote any LLM-based model as $f(x; \\phi)$ where x represents the input data, and $\\phi$ denotes the natural language instructions for f to follow, which is considered as learnable parameters in our verbalized learning framework. Specifically, Q contains parameters to be learned in VERA. As depicted in Fig. 2, in each iteration t, the learner agent $f_{learner}^{(t)}$ is modeled by the frozen VLM $f_{VLM}(\\cdot)$ used for VAD with a specific prompt template $\\theta$ that guide $f_{VLM}(\\cdot)$ to conduct a learning task by pondering on current guiding questions $Q_t$. We denote the learner agent as $f_{learner}^{(t)}(x) = f_{VLM}(x; (\\theta, Q_t))$, where x is"}, {"title": "Learning Task for", "content": "$f_{learner}$. The learner executes the \"forward pass\" and outputs a prediction. Recall that we only use the original coarsely labeled information for training. Thus, we design a binary classification task for $f_{learner}$, which accounts for the temporal nature of video data, the sparsity of anomalies, and the weak supervision in VAD datasets. In this task, the job of the learner $f_{learner}$ is to produce a binary classification prediction $\\hat{Y}^{(i)}$ to determine whether there is an anomaly in the video based on the sampled frames $V^{(i)}$. As shown in Fig. 2, we explain the task in natural language in the \"Model Description\" section in $\\theta$. Guiding questions $Q_t$ are inserted in the \"Prompt Questions\" section in $\\theta$ to elicit reasoning of the VLM. This template design is based on the prompt structures used in VML, with targeted modifications to help the learner effectively address this WS learning task. Due to the space limit, please refer to the Ap-"}, {"title": "3.3. Inference in VERA: Coarse-to-Fine Anomaly Scoring by Guiding Questions and Contexts", "content": "Given $Q^*$, VERA yields fine-grained anomaly score $\\hat{Y}$ for a test video V via a coarse-to-fine process shown in Fig. 3.\nStep 1: Initial Anomaly Scores via Learned Guiding Questions. We divide the video into segments and analyze each segment independently first. Following [55], we perform equidistant frame sampling within V to obtain the set of each segment center C, resulting in $C = \\{I_1, I_{d+1},..., I_{(h-1)\\cdot d+1}\\}$, where d is the interval between centers and $h = floor(F/d)$ is the total number of segments. For each center frame $I_{(u-1)\\cdot d+1}$ ($1 \\leq u \\leq h$), we define a 10-second window around it as the u-th segment, within which we uniformly sample 8 frames. We denote the sampled frame set in the u-th segment as $V_u$. Next, we input $V_u$ in $f_{VLM}$ with the prompt $(\\theta, Q^*)$ to get the initial score\n$\\tilde{y}_u = f_{VLM}(V_u; (\\theta, Q^*))$,\nwhere $\\tilde{y}_u = 1$ if $f_{VLM}$ thinks the segment contains an anomaly after reasoning via $Q^*$ with $V_u$, and otherwise, $\\tilde{y}_u = 0$. By repeating Eq. (3) for each segment, we have a segment-level initial anomaly score set $\\tilde{Y} = [\\tilde{y}_1,..., \\tilde{y}_h]$.\nStep 2: Ensemble Segment-Level Anomaly Scores with Scene Context. Note that the scores derived above only examine a short moment in a long video without considering"}, {"title": "Step 3: Frame-level Anomaly Scoring with Temporal Context.", "content": "Given $\\tilde{Y}$, we aim to incorporate temporal context to capture how events evolve over time when computing frame-level anomaly scores, for the abnormality of an event often depends on the timing and progression of observed activities. To detail, we first apply Gaussian smoothing [12] to aggregate local temporal context into the segment-level anomaly scores. We denote the Gaussian kernel (suppose the filter size is w) as $G(p) = exp(-\\frac{p^2}{2\\sigma_1^2})$ where p is the distance from the kernel center and $\\sigma_1$ is the variance. We update segment-level scores as $\\Gamma = \\tilde{Y} * G = [\\gamma_1,..., \\gamma_h]$,"}, {"title": "Explainable VAD by VERA.", "content": "When using template $\\theta$ embedded with $Q^*$ to compute $\\hat{Y}$, we ask the VLM to \u201cprovide an explanation in one sentence\" when reasoning, and VLM will explain the anomaly score it assigns afterward based on $Q^*$. Please refer to Sec. 4.4 and Sec. B.4 in the Appendix for the demonstration of explainable VAD by VERA."}, {"title": "4. Experiments and Results", "content": "In this section, we present an evaluation of VERA as follows, addressing key questions of interest including: (Q1) Does it enhance the effectiveness of frozen VLMs in VAD? (Q2) Is its design reasonable and well-structured? (Q3) How well does it generalize across different scenarios?"}, {"title": "4.1. Experimental Settings", "content": "Datasets. We conduct experiments on two large-scale VAD datasets: (1) UCF-Crime [35] and (2) XD-Violence [45].\nThe details are as follows:\n\u2022 UCF-Crime dataset is collected from real-world surveillance videos (128-hour long in total), covering crime-related anomalies including abuse, arrest, arson, assault, burglary, explosion, fighting, road accident, robbery, shoplifting, shooting, stealing, and vandalism. The training set has 1610 videos (810 abnormal ones and 800 normal ones), while the test set has 290 videos (140 abnormal ones and 150 normal ones). The total number of test frames is over 1 million (1,111,808), and abnormal frames account for 7.92%. The average duration of a test video is 2.13 minutes, which is relatively long compared to common video datasets and serves as a benchmark.\n\u2022 XD-Violence is another representative large-scale (217-hour long in total) VAD dataset with 6 anomaly categories, i.e., abuse, car accident, explosion, fighting, riot, and shooting, which defines anomalous events as the"}, {"title": "Metrics.", "content": "Following approaches in [55, 58], we evaluate VAD performance using the Area Under the Curve (AUC) of the frame-level Receiver Operating Characteristic (ROC) curve, as it provides a comprehensive measure of model performance across all thresholds. It is a comprehensive representation for evaluating the ability of a method to distinguish between anomaly and normality across different thresholds in VAD. As for average precision (AP), the area under the frame-level precision-recall curve, it is another VAD performance metric mostly used for the XD-Violence dataset. Compared to AUC, this metric mainly focuses on the performance of VAD method in identifying anomalous events. In other words, AP pays attention to classifying the anomaly correctly rather than the overall separation. We report AP results for XD-Violence in the Appendix."}, {"title": "Baselines.", "content": "We categorize baselines into non-explainable approaches and explainable ones as [58] does. Non-explainable ones are obtained by WS learning [7, 10, 17, 19, 21, 35, 38, 44\u201346, 53, 54, 60] and unsupervised learning [14, 28, 36, 37, 40, 41]. These non-explainable approaches cannot provide language-based explanations for VAD and have following characteristics:\n\u2022 WS learning methods [7, 10, 17, 19, 21, 35, 38, 44-46, 53, 54, 60] usually use task-specific learning models with pretrained weights such as C3D [39], I3D [5], VideoSwin [27], ResNet [15], and ResNext [48] to extract feature for each video segment. Based on that, they form the training of classifiers, which output predictions after the feature extractors, as a multiple instance learning task, regarding the segments containing anomaly scenes as positive bags and the others as negative bags to handle the lack of frame-level annotations and the uncertainty of the anomaly locations in the video. Such learning objectives can fully use the only available video-level label information and effectively improve the discriminative ability of the classifiers in the network. However, the trained neural networks from these methods operate on highly abstract features that are hard for humans to interpret.\n\u2022 Unsupervised learning methods [14, 28, 36, 37, 40, 41] improve the discriminative ability of the models regarding anomalies and normality without any knowledge of the video label. Note that we include one-class learning [14, 28, 40, 41] methods in this category. Unsupervised methods mostly learn reconstruction models from unlabeled data and use reconstruction errors to distinguish normal and abnormal video frames. Another common strategy [36, 37] is introducing pseudo-labels for un-"}, {"title": "4.2. Comparison to State-of-the-art Methods", "content": "We address Q1 by empirically comparing VERA to existing VAD methods. First, in Table 2, VERA achieves the highest AUC among explainable VAD methods on UCF-Crime, outperforming Holmes-VAD and VADor (without instruction tuning, as reported in their papers) in a fair comparison. Importantly, unlike these methods, VERA does not need to modify the model parameters, demonstrating its suitability to directly adapt VLM to the VAD task with minimal training requirements. Moreover, VERA surpasses LAVAD by 6% in AUC on UCF-Crime, uniquely integrating both description and reasoning capabilities in VAD. Compared to non-explainable methods, VERA achieves AUC performance that is comparable to one of the top-performing"}, {"title": "4.3. Ablation Studies", "content": "We perform necessary ablation studies on UCF-Crime to answer both Q2 and Q3 for a comprehensive evaluation.\nTraining Frame Sampling Strategy. We compare three frame sampling strategies for obtaining each $V^{(i)}$ in training: uniform sampling, random sampling, and TSN sampling (random sampling from equally divided segments). Table 4 shows that uniform sampling performs the best (with batch size n = 2 and S = 8). This is because uniform sampling preserves the temporal structure and maintains consistent motion patterns throughout the long video, making it easier for VLMs to understand the video and update Q.\nBatch Size and Sampled Frame Number. Key hyperparameters that need to be set in training are the batch size n and the number of sampled frames S for each video $V^{(i)}$ in the verbalized learning framework. The selection of S and n are correlated because they determine the total number of frames for the optimizer to skim and provide feedback as S\u00b7n. In implementation, we will face memory constraints when implementing VLMs on GPUs. In our training, we"}, {"title": "Generalizability Test.", "content": "We further examine the generalizability of VERA across different model sizes,"}, {"title": "4.4. Qualitative Results and Case Studies", "content": "To illustrate how VERA performs video anomaly detection, we take one video for a qualitative demonstration of the explainability brought by the learned Q, as shown in Fig. 5. Please refer to the Appendix for more qualitative examples if interested. The main anomaly in this video is that a man tries to steal money from the washing machines in a laundromat and is arrested after being found by the police. In Fig. 5, we provide the guiding questions learned by VERA and take 6 main video segments (each with 2 sampled frames and their time indices are given in Fig. 6)"}, {"title": "5. Concluding Remarks and Limitations", "content": "We propose a novel pipeline, VERA, which can effectively elicit the reasoning ability from VLMs to perform explainable VAD without additional computation overhead. This is done through an effective and novel application of verbalized machine learning [47] to VLM. In training, VERA obtains the guiding questions detailing anomaly patterns through the verbal interaction between the learner and the optimizer agents. In inference, VERA uses them to enhance VLMs for identifying anomalies and compute frame-level anomaly scores in a coarse-to-fine process. Experimental results validate the effectiveness of the VERA framework in achieving state-of-the-art explainable VAD performance."}]}