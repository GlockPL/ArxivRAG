{"title": "UNIFYING SEQUENCES, STRUCTURES, AND DESCRIPTIONS\nFOR ANY-TO-ANY PROTEIN GENERATION WITH\nTHE LARGE MULTIMODAL MODEL HELIXPROTX", "authors": ["Zhiyuan Chen", "Tianhao Chen", "Chenggang Xie", "Yang Xue", "Xiaonan Zhang", "Jingbo Zhou", "Xiaomin Fang"], "abstract": "Proteins are fundamental components of biological systems and can be represented through various\nmodalities, including sequences, structures, and textual descriptions. Despite the advances in deep\nlearning and scientific large language models (LLMs) for protein research, current methodologies\npredominantly focus on limited specialized tasks \u2013 often predicting one protein modality from another.\nThese approaches restrict the understanding and generation of multimodal protein data. In contrast,\nlarge multimodal models have demonstrated potential capabilities in generating any-to-any content\nlike text, images, and videos, thus enriching user interactions across various domains. Integrating\nthese multimodal model technologies into protein research offers significant promise by potentially\ntransforming how proteins are studied. To this end, we introduce HelixProtX, a system built upon the\nlarge multimodal model, aiming to offer a comprehensive solution to protein research by supporting\nany-to-any protein modality generation. Unlike existing methods, it allows for the transformation\nof any input protein modality into any desired protein modality. The experimental results affirm the\nadvanced capabilities of HelixProtX, not only in generating functional descriptions from amino acid\nsequences but also in executing critical tasks such as designing protein sequences and structures from\ntextual descriptions. Preliminary findings indicate that HelixProtX consistently achieves superior\naccuracy across a range of protein-related tasks, outperforming existing state-of-the-art models.\nBy integrating multimodal large models into protein research, HelixProtX opens new avenues for\nunderstanding protein biology, thereby promising to accelerate scientific discovery.", "sections": [{"title": "1 Introduction", "content": "Proteins are fundamental entities in the life sciences, performing diverse and crucial functions within living organisms.\nThey provide structural support, catalyze biochemical reactions as enzymes, and facilitate the transport and storage of\nessential molecules. Additionally, proteins also play a critical role in a wide array of biological functions, involved in cell\nsignaling, immune response, and gene regulation. The study of proteins can be approached through multiple modalities\nincluding amino acid sequences, three-dimensional structures, and textual descriptions \u2013 each offering unique insights\ninto understanding proteins from different perspectives: (1) The amino acid sequence, also referred to as the primary\nstructure of a protein, encodes the genetic information and is typically analyzed using sequence-based deep learning\nmodels, such as those outlined by [1] to investigate the associations across the residues. (2) The three-dimensional\nstructural conformation, also known as the folded state, greatly influences a protein's functional activities. Various\nadvanced structural encoders, like Geometric Vector Perceptron (GVP) [2], Protein Message-Passing Neural Network\n(ProteinMPNN) [3], and Invariant Point Attention (IPA)[4], have been investigated to elucidate the complex spatial\ninteractions among residues or atoms within a protein. (3) The textual description offers a narrative perspective on\nprotein functionalities as documented in the scientific literature. This textual modality provides valuable insights that\nenhance our understanding of the diverse roles and characteristics of proteins.\nDeep learning-based protein research predominantly focuses on singular-task methodologies, with most studies aiming\nto predict one protein modality from another. For example, many studies, such as [5, 6, 7, 8], have inferred biological\nprotein functions from sequences [5, 6] or structures [7, 8]. This process, which facilitates functional annotation and\nthe discovery of novel functions, essentially generates textual descriptions from protein sequence or structure data\n(sequence-to-description and structure-to-description). Recently, deep learning has significantly advanced protein\nstructure prediction, as demonstrated by AlphaFold II [4] and RoseTTAfold [9], which predicts the three-dimensional\nprotein structural conformation from amino acid sequences (sequence-to-structure). Furthermore, AI-driven protein\ndesign has garnered considerable research interest. This field aims to generate sequences that can fold into specific\nthree-dimensional structures (structure-to-sequence) [10, 3, 11] and to create protein sequences [12, 13, 14, 15] or\nstructures [15] based on a given tag [12, 13] or description [14, 15] (description-to-sequence or description-to-structure).\nDespite significant technological advancements in these tasks, current models typically specialize in singular protein-\nrelated tasks. This specialization requires researchers to understand multiple models to meet their objectives, thereby\ncomplicating the research process. Moreover, the need to manage varying input and output formats and reconcile\npotentially inconsistent findings across different models further increases the research burden. A holistic solution\ncapable of addressing multiple protein-related challenges simultaneously would substantially reduce these complexities\nand streamline research efforts.\nOngoing efforts have been made to develop specialized scientific Large Language Models (LLMs) for the life sciences,\nyet these primarily focus on one or two protein-related tasks. Given the significant success of LLMs in addressing\na wide range of tasks across diverse fields [16], the introduction of scientific LLMs for protein research represents a\nhighly promising and intriguing direction. However, current efforts remain somewhat constrained, primarily focusing\non processing natural language queries or converting text descriptions into other modalities. For instance, BioMedGPT\n[17] excels in responding to natural language inquiries in bioinformatics, small molecule analysis, and protein research.\nMeanwhile, MolInstruction [18] is capable of predicting molecular functions and using textual descriptions to design\nprotein sequences within language models.\nNevertheless, our perspective is that integrating the large multimodal model with any-to-any generation capabilities\ninto protein research holds considerable potential to transform how proteins are studied. Recent advancements in large\nmultimodal model research [19], particularly the any-to-any generation technique [20, 21, 22] which integrates multiple\ntasks into a unified model, demonstrate the potential for high-quality content generation across modalities such as text,\nimages, speech, and video. For example, CoDi, introduced in [20], utilizes diffusion models to facilitate any-to-any\nmultimodal generation. This capability is further enhanced in CoDi-2 [21] and NExT-GPT [23], both of which exploit\nthe synergy between LLMs and diffusion models to improve any-to-any multimodal generation performance. Despite\nthe considerable potential, the application of any-to-any multimodal generation techniques to protein research remains\nlargely unexplored, offering an exciting avenue for future investigations.\nTo address this potential, we introduce HelixProtX, a system built upon a large multimodal model for any-to-any protein\ngeneration. Designed to unify protein sequences, structures, and descriptions, HelixProtX offers a comprehensive\nsolution for protein research by facilitating any-to-any protein generation. The primary goal of HelixProtX is to leverage\nany-to-any protein generation to transform the methodologies used in protein research, thereby making protein-related\ninvestigation more efficient and comprehensive. As depicted in Figure 1a, HelixProtX enables the generation of different\nprotein modalities from any given input by seamlessly integrating sequences, structures, and textual descriptions. Upon\nuser interaction, the system analyzes the semantics and context of each query before generating precise and detailed\nresponses across different protein modalities, as illustrated in Figure 1b.\nWe systematically evaluated the performance of HelixProtX across a diverse array of protein-related tasks, including\ndescription prediction (sequence-to-description and structure-to-description), sequence design (structure-to-sequence\nand description-to-sequence), and structure prediction/design (sequence-to-structure and description-to-structure), to\nverify the effectiveness of HelixProtX. Across most tasks, HelixProtX consistently outperformed existing benchmarks,\nleveraging the advanced capabilities of large multimodal models. The system demonstrated robustness across proteins\nof varying lengths and families. Notably, HelixProtX exhibited exceptional potential in text-guided protein design\napplications, including description-to-sequence and description-to-structure tasks. The proteins designed by HelixProtX\nclosely matched reference proteins in terms of compatibility, with the distributions of the designed protein sequences\nand structures showing rationality and coherence. By harnessing the capabilities of large multimodal models for\nany-to-any protein generation, HelixProtX can provide novel insights into protein biology and has the potential to\nsignificantly accelerate scientific discovery in this field."}, {"title": "2 Method", "content": "2.1 Overview\nHellixProtX is an advanced multi-modal system designed to comprehend and generate diverse protein modalities\nincluding sequence, structure, and description. It facilitates user interaction through natural language-style question\nanswering, addressing a variety of protein-related tasks.\nThe architecture of HelixProtX, as illustrated in Figure 2a, is centered on the large language model LLM, utilizing\nERNIE-Lite, a streamlined version of ERNIE BOT\u00b3. This model processes inputs composed of three key components:\nthe system message, the condition message, and the user message, as shown in Figure 2c. The system message provides\ncontextual cues to guide the LLM's responses across various generation tasks, the condition message specifies the\ngeneration conditions, and the user message delivers specific input from the user.\nBuilding on the foundational architecture centered around the LLM, HelixProtX further enhances its capabilities\nby aligning multimodalities of proteins. A pre-trained Sequence Encoder and a pre-trained Structure Encoder are\nintroduced to encode amino acid sequences and the three-dimensional structures, respectively. To ensure alignment\namong different protein modalities and textual queries, we incorporate Sequence Abstractor and Structure Abstractor\nmodules. These modules condense sequence and structure information into a set of learnable tokens. For queries that\ndepend on protein sequences or structures as conditions, their representations are generated by abstractors and serve as\nthe condition message. For queries dependent on descriptions as conditions, the corresponding text is used directly as\nthe condition message.\nHellixProtX supports tasks across multiple protein modalities, with a primary focus on predicting functional descriptions,\ndesigning protein sequences, and predicting or designing protein structures. In tasks like description prediction and\nsequence design, the Language Model Head leverages the latent representations from the LLM to generate responses by\ncomputing probability distributions across token vocabularies. For the task of structure prediction/design, we introduce\na specialized Residue Angle Head, designed to forecast the six angles describing the relative position of all backbone\natoms in the residue, thereby facilitating the prediction of the protein backbone structure.\nThe training process of HelixProtX is divided into two stages, as depicted in Figure 2b. Initially, the parameters\nof the abstractors are optimized exclusively during the first stage. Subsequently, in the second stage, gradients are\nbackpropagated to optimize all all model parameters.\n2.2 Input Format\nThe input of HelixProtX generally follows the conventional paradigm of multimodal instruction tuning [24]. Each\ninput consists of three parts: a system message, a condition message, and a user message. The input format for various\nprotein-related tasks is illustrated in Figure 2c.\nThe system message provides an overview, helping the model understand its role and capabilities within the system. It\nspecifies the model's characteristics and responsibilities, serving as a comprehensive guide to ensure that the model\nresolves protein-related tasks.\nFollowing the system message, the condition message provides the specific conditions required to perform the given\ntask. For example, in a sequence design task, the condition message might include details of the desired protein structure\nand function description. In the HelixProtX model, the condition message could be the output of a sequence abstractor,\na structure abstractor, or a representation of a functional description.\nLastly, the user message clarifies the intentions and specific requests of the user. It provides essential context and\ndetails, enabling HelixProtX to accurately perform specialized tasks. The user message serves to articulate the user\nintent, instructing HelixProtX on which task to perform. Examples of user messages for different tasks can be found in\nFigure 2c.\n2.3 Multimodal Encoders with Alignment\nConventional natural language models[25] typically only accept natural language tokens as input. To enable their\ncapability to handle both amino acid sequence and three-dimensional structural modalities, we introduce two pre-trained\nmodules: the Sequence Encoder and the Structure Encoder. The Sequence Encoder is designed to capture representations\nof amino acid sequences, whereas the Structure Encoder focuses on structural modalities. While it is possible to directly\ninput amino acid sequences and their coordinates into a natural language model without any encoding, this approach\nmay fail to effectively capture the important co-evolutionary and spatial relationships between amino acids. These\nrelationships are crucial for accurately representing the complexity and multifaceted nature of proteins. To address this,\nwe introduce these two specialized encoders, enhancing the model's understanding and processing of protein data.\nSequence Encoder. The amino acid sequence of a protein serves as the input for the sequence encoder. We opt to\nemploy our previous work, HelixFold-Single [26], as the Sequence Encoder, chosen for its robust protein structure\nprediction capabilities. HelixFold-Single is composed of a Protein Language Model (PLM) and a Geometry Modeling\nmodule. The PLM, undergoing self-supervised learning on a comprehensive protein sequence dataset, can capture\nco-evolutionary information[27] among amino acids. Subsequently, the Geometry Modeling module extracts spatial\nrelationships among them. Specifically, to process each amino acid sequence, it is input into HelixFold-Single. The\nsequence first is processed by the PLM to understand co-evolutionary patterns. Following this, the representation is\nthen fed into the Geometry Modeling module to refine this data into a spatial context. The output from this module is\nthen utilized as the input for the Abstractor.\nStructure Encoder. The three-dimensional structure of a protein serves as the input for the Structure Encoder. We\nutilize the well-established protein design model, ProteinMPNN [3], as the Structure Encode. Specifically, we used the\noutput representations from the last encoder layer of ProteinMPNN as structure embedding. ProteinMPNN has been"}, {"title": "2.4 Multimodal Generation", "content": "In this section, we introduce the implementation of multimodal generation within HelixProtX. Unlike typical LLMs that\ndecode only sequential information through a Language Model Head, HelixProtX is uniquely equipped to handle both\nsequence and structural decoding, broadening its applicability in processing protein data. For sequence decoding, we\nemploy the standard Language Model Head, which generates sequential data of proteins. Complementarily, structural\ndecoding utilizes a novel Residue Angle Head, specifically designed to predict the angles between amino acids. This\ncomponent enables the precise reconstruction of a protein's three-dimensional structure.\nLanguage Model Head to Learn Description Prediction and Sequence Design. In the realm of generative pre-\ntrained models (e.g. GPT [29] ), a commonly adopted approach for pre-training involves maximizing the likelihood\nof predicting the subsequent token in a sequence based on its preceding tokens. This is achieved through the use of\nthe negative log-likelihood (NLL) loss function during a training phase. For tasks encompassing textual description\ngeneration and amino acid sequence generation, we adhere to this prevalent pre-training loss mechanism to effectively\nfine-tune the model for improved performance and adaptability. The Language Model Head and the NLL loss function\n$L_{NLL}(x)$ are defined as:\n$P(x_i | x_{<i}) = Softmax(LanguageModelHead(h_i)),$\n$L_{NLL}(x) = - \\sum_{i=j}^{n} log(P(x_i | x_{<i})),$ \nwhere LanguageModelHead(.) is a multi-layer perceptron. $x_i$ represents the i-th token, $h_i$ denotes the representation of\ntoken $x_i$ produced by the final layer of the Language Model, j is the starting index of the response, and n is the number\nof input tokens.\nResidue Angle Head to Learn Structure Prediction/Design. The structure of a protein can be characterized by a\nsequence of angles that describe the relative orientation of its backbone atoms. In a manner similar to the decoding\nprocess of conventional language models, HelixProtX adopts an autoregressive approach to decode the angles associated\nwith each amino acid. Following prior research [30], HelixProtX predicts the six angles for amino acids rather than the\ncoordinates of atoms with variable numbers, streamlining the structure decoding process and preserving the inherent\ntranslational and rotational invariance of the protein backbone structure. Once the Language Model Head decodes\na special token [NUM], the Residue Angle Head is activated to output the angles of the amino acids. The outputted\nangles are adapted into the word embedding space as the input of the LLM to produce the next token. Details on how\nto generate such Residue Angle Embedding are provided in the Appendix, Section 2.2, which also offers an in-depth\nunderstanding of this process."}, {"title": "2.5 Training Stages", "content": "HelixProtX employs a two-stage training approach to optimize the model. The first stage focuses on optimizing\nthe Abstractor module while other modules remain frozen, aiming to align the sequence, structure, and description\nrepresentations. This alignment is crucial for ensuring that the model comprehensively integrates these varied modalities\nof protein data. The second stage is dedicated to addressing specific protein-related tasks, during which all modules are\noptimized except for the pre-trained encoders. The detailed architecture and training process are illustrated in Figure 2b,\nwhich visually outlines the progression and focus of each training stage.\nStage I. In the first stage, we align the sequence representation proudced by the Sequence Encoder and the structure\nrepresentation proudced by the Structure Encoder to the textual description representation. All model parameters are\nkept frozen except for those of the Sequence Abstractor and the Structure Abstractor. We use data from sequence-to-\ndescription and structure-to-description tasks for training, ensuring the effective alignment of sequence and structure\nrepresentations with the natural language feature space of the language model.\nStage II. In the second stage, we focus on training for protein-related tasks, as depicted in Figure 2b. During this stage,\nwe optimize all model parameters except those of the Sequence Encoder and Structure Encoder, which remain fixed to\npreserve the integrity of their initial representations. To ensure balanced learning across various tasks, we sample data\nfor each of the six protein-related tasks with a probability of 15%. This approach allows the model to evenly develop\ncapabilities to tackle these protein-related challenges. Additionally, we sample dialogue data with a 10% probability to\nmaintain the model's conversational abilities. This balanced sampling strategy is crucial for equipping the model to\neffectively address both specialized and general interaction tasks."}, {"title": "3 Results", "content": "We assess the potential of HelixProt in protein-related tasks by focusing on three key areas: description prediction,\nsequence design, and structure prediction/design. Furthermore, we demonstrate the benefits of training a unified\nmodel-capable of handling multiple protein tasks\u2014over the traditional approach of training multiple task-specific\nmodels independently\nTo build a comprehensive multimodal dataset, we curated resources from UniProtQA [17], which provided functional\ndescriptions and sequence data, and SwissProt [31], which contributed structural data. We organized each data item\ninto six pairings, creating modal pairs that support different multimodal protein tasks including sequence-to-description,\nstructure-to-description, description-to-sequence, structure-to-sequence, sequence-to-structure, and description-to-\nstructure. This approach yielded a dataset of 361, 498 x 6 = 2, 168, 988 instances. We have divided the datasets for\neach task into training, validation, and test sets, maintaining an 8:1:1 ratio to ensure training and evaluation of the\nmodel's performance."}, {"title": "3.1 Description Prediction", "content": "The description prediction task involves generating the functional description of a protein from its sequence or\nstructure. A protein's functional description is encapsulated in a series of natural language texts that pertain to\nfour distinct categories: the protein's function, its classification within a protein family, its official name, and its\nsubcellular localization. To investigate HelixProtX's potential for protein description prediction, we present the results\nof HelixProtX in inferring functional descriptions from protein sequences (denoted as HelixProtX seq-to-desc) and\nfrom protein structures (denoted as HelixProtX struct-to-desc) in Figure 3. For the sequence-to-description comparison,\nwe use BioMedGPT [17], another bioinformatics large language model, as the baseline. For the structure-to-description\ntask, to our knowledge, there are no existing large models that effectively address this task.\nFirstly, we begin by analyzing the overall performance of HelixProtX in predicting functional descriptions. We employ\ncommonly used evaluation metrics in natural language processing, namely BLEU score and ROUGE score [32], which\nare usually used in machine translation and summarization tasks, to assess the consistency between generated functional\ndescriptions and ground truth descriptions. As shown in Figure 3a, HelixProtX outperforms BioMedGPT across\nall metrics in the sequence-to-description task, indicating higher accuracy and fluency in the generated descriptions.\nAlthough there is no direct baseline for the structure-to-function task, comparing HelixProtX struct-to-desc with\nBioMedGPT allows us to infer that HelixProtX performs well in this task as well. Compared to HelixProtX seq-to-desc,\nthe scores for HelixProtX struct-to-desc are slightly lower. We speculate that this could be attributed to the advantage of\nHellixProtX's sequence encoder, HelixFold-Single, which benefits from a greater quantity and diversity of training data\nencompassing both sequence and structural information, compared to its structure encoder ProteinMPNN. We further"}, {"title": "3.2 Sequence Design", "content": "The protein sequence design task involves designing amino acid sequences with specific functions or structures based\non input descriptions of desired functionalities or protein scaffold structures. This task has significant and wide-ranging\napplications. To evaluate the efficacy of HelixProtX, we compared it against two established methods: ProteinMPNN\n[3], which infers amino acid sequences from protein structures, and Chroma [15], which designs protein sequences\nbased on textual descriptions. We use Sequence Identity [33] as the metric to measure the similarity between the\nsequences predicted by the model and the reference sequences.\nInitially, we evaluate the overall accuracy of HelixProtX in the description-to-sequence task. As shown in Figure 4a, the\nprotein sequences designed by HelixProtX exhibit significantly higher sequence identity with the reference sequences,\noutperforming the baseline method Chroma by several folds. This exceptional matching performance is particularly\nevident with shorter protein sequences. Compared to the baseline method, We think this notable performance advantage\nis largely attributed to HelixProtX's utilization of a large-scale language model, which significantly enhances its capacity\nto comprehend and process textual descriptions.\nIn addition to evaluating the sequence similarity between the designed sequences and the reference sequences, we\nalso assessed the validity and diversity of the designed protein sequences. Figure 4c illustrates the distribution of\n3000 reference protein sequences and designed protein sequences for arbitrary text descriptions, represented by gray\ncircles and squares, respectively. Distributions for sequences designed for five key functions: Argininosuccinate Lyase,\nRNA Polymerases, Argininosuccinate Synthase, Lactase, and Oxygen Transport, with 40 sequences per function, are\nshown with colored circle and square markers. We apply t-Distributed Stochastic Neighbor Embedding (t-SNE) to\nvisualize the data on a two-dimensional plane. At first, this visualization demonstrates the validity of HelixProtX. The\nanalysis reveals that the overall distribution of the designed protein sequences closely matches that of the reference\nsequences. Specifically, the distribution of gray squares aligns well with the distribution of gray circles, affirming\nthe plausibility of the designed sequences. Furthermore, the distribution of the designed protein sequences for each\nspecific function closely matches that of the reference sequences. Second, this analysis also illustrates the diversity of\nthese designed sequences. As we can see from Figure 4c, the designed protein sequences for each function exhibit\nconsiderable diversity, clustering in a relatively close area without collapsing into a single point, thereby demonstrating\nthe model's capacity to capture the inherent functional diversity inherent of protein sequences.\nIn the structure-to-sequence task, HelixProtX achieves a notably high level of similarity between its designed sequences\nand the reference sequences, as demonstrated in Figure 4b. Across the vast majority (98%) of samples, HelixProtX\nsignificantly surpasses ProteinMPNN, a baseline method specialized for inverse folding, in terms of sequence similarity.\nFurthermore, we utilize the HelixFold-Single model to predict the three-dimensional structures of the designed\nsequences and assess their alignment with the input structures using structure alignment scores. The results, detailed in\nTable 4.1 in Appendix, further confirm the superiority of sequences designed by HelixProtX. Comparative analysis\nof the results of HelixProtX in Figure 4a and Figure 4b indicates that HelixProtX exhibits better performance in the\nstructure-to-sequence task than in the description-to-sequence task. This difference is likely due to the more definitive\nguidance provided by structural inputs compared to the inherent ambiguity in textual descriptions.\nIn Figure 4d, we showcase a sequence designed by HelixProtX to assess the rationality of its amino acid sequence\ngeneration. To identify evolutionarily conserved functional key sites within the reference sequences, we use ESM-\nScan[34], a tool based on the protein language model ESM-2[35], to identify key sites. We then compare how well\nthe sequences designed by HelixProtX and Chroma align with these identified key sites. Our analysis reveals that\nHellixProtX preserves nearly all of the critical sites found in the reference sequences, demonstrating its effectiveness\nin maintaining essential functional and structural elements. In contrast, the Chroma-designed sequences exhibit less\nconsistency with these key sites. This high level of site preservation underscores HelixProtX's robustness and accuracy\nin protein design, validating its potential as a valuable tool for protein engineering."}, {"title": "3.3 Structure Prediction / Design", "content": "HelixProtX can not only predict the protein scaffold structure based on a given amino acid sequence (sequence-\nto-structure) but also design protein scaffold structures that meet specific functional requirements based on textual\ndescriptions of protein functions (description-to-structure). For the description-to-structure task, we once again use\nChroma as our comparative baseline. As for the sequence-to-structure task, we compare HelixProtX with HelixFold-\nSingle, which is a well-established model for protein structure prediction based on a protein language model. Root\nMean Square Deviation (RMSD) is used to evaluate the error between the model-generated structures and the reference\nstructures.\nFigure 5a compares the RMSD scores between HelixProtX and Chroma for the description-to-structure task. HelixProtX\nperforms well across proteins of varying lengths, demonstrating its ability to effectively design protein backbones based\non textual descriptions of their functions. This capability is largely due to the foundation model trained on a large\ncorpus of text data, enabling it to effectively understand textual descriptions of proteins. Besides, as protein length\nincreases, the spatial complexity of the design expands accordingly. Consequently, errors in model structure design\ntend to amplify. Figure 5d presents an example of HelixProtX's performance on the description-to-structure task. The\nstructure designed by HelixProtX closely matches the reference structure.\nIn contrast to its performance in the description-to-structure task, HelixProtX exhibits less accurate results than\nHellixFold-Single in the sequence-to-structure task, also commonly referred to as protein folding. As shown in Figure 5b,\nthe prediction performance of HelixProtX, as measured by the Root Mean Square Deviation (RMSD), is notably less\nprecise. This discrepancy can be attributed to several factors. First, HelixProtX faces challenges in accurately modeling\nthe spatial relationships of amino acids. Unlike HelixFold-Single, which includes a specially designed component for\nsuperior geometric learning, HelixProtX uses a general language model approach that may not capture these complex\nspatial interactions effectively. Second, HelixProtX's method of decoding structural angles individually can lead\nto cumulative errors. This approach follows the common paradigm of LLMs but does not adequately address the\ncomplexities of protein structure prediction. Lastly, the process of transforming sequences into structures involves\nlearning the complex physicochemical process of protein folding, a task of which general language models may have\nlimited knowledge. This highlights the necessity for specially designed model architectures and training methodologies\nthat are tailored to the challenges of unique tasks like sequence-to-structure transformation.\nHellixProtX estimates protein backbone structures by predicting six torsion angles of amino acids. We examined whether\nthe distributions of these predicted angles align with the distributions of the actual angles. As shown in Figure 5c,\nour observations indicate that the generated distributions closely mimic the real distributions, with almost complete\noverlap for all angles. This holds true for both the low-variance, near-Gaussian distributed angles (\u03c9, 01, 02, 03) and the\nhigh-complexity distributed angles (4 and 4). Such results provide indirect validation of the reliability and accuracy of\nthe structural models generated by HelixProtX, proving its effectiveness in detailed protein structure prediction."}, {"title": "3.4 Advantages of Training a Unified Model for Protein-related Tasks", "content": "Most previous work employs different models to independently train each protein-related task. In contrast, HelixProtX\nutilizes a unified model to jointly train multiple protein-related tasks simultaneously. Figure 6 examines the accuracy\nbenefits of joint training multiple tasks within a unified model compared to independently training multiple task-specific\nmodels. We employ BLEU-4, Sequence Identity, and TM-score to evaluate performance in description prediction,\nsequence design, and structure prediction/design tasks, respectively.\nOur results indicate that joint training across various tasks in a unified model yields consistent improvements in accuracy\nover independent training for most tasks. This enhancement can be largely attributed to the model's ability to capture\nand leverage shared patterns and dependencies across tasks, leading to more robust and generalizable representations."}, {"title": "4 Conclusions and Future Work", "content": "The improvements are particularly notable in tasks involving structural modalities, whether these modalities serve as\nconditions or outputs. This is likely because the differences between structural modalities and text in large language\nmodels are substantial, and joint training effectively aligns these modalities, leveraging the strengths of large language\nmodels more efficiently.\nProteins, as the fundamental building blocks of biological systems, can be represented through different modalities,\nincluding sequences, structures, and textual descriptions. Understanding the multimodal nature of protein data is crucial\nfor scientific discoveries. HelixProtX, as a unified large multimodal model system, has successfully achieved the\ninter-mapping of different protein modalities. Our research results have demonstrated the superiority of HelixProtX in\nprotein description prediction and sequence design tasks over baseline methods, validating the feasibility of HelixProtX\nfor protein structure prediction/design tasks. Furthermore, our study has shown that employing a unified model for\nvarious protein-related tasks enhances the accuracy across multiple tasks. In summary, our study confirms the significant\npotential of large multimodal models in life sciences, offering new avenues for understanding protein biology and\naccelerating scientific discoveries in this domain. Promising directions for future research include:\n\u2022 Enhancing structure prediction/design: While HelixProtX shows promise, its performance in the structure\nprediction/design task requires further improvement. Exploring more sophisticated network architectures and\nrefining optimization objectives to more effectively capture the complexities of protein spatial structures may\nbe possible for improving future task performance.\n\u2022 Broadening the scope of applications: It is interesting to expand the dataset to include additional life science\ndomains, such as small molecules and RNA. This can help to construct a large multimodal model with a\nbroader application range, capable of handling diverse biological data types."}, {"title": "1 Dataset", "content": "We have meticulously curated a comprehensive multimodal protein dataset by integrating resources from UniProtQA\n[17] and SwissProt [31]. From UniProtQA, we extracted amino acid sequences and their corresponding functional\ndescriptions, all derived from the extensive UniProt database [36]. Additionally, we obtained amino acid sequences\nand their corresponding three-dimensional structures from SwissProt. By matching the amino acid sequences, we\npaired the functional descriptions from UniProtQA with the structures from SwissProt. This integration has resulted\nin the creation of a multimodal dataset comprising 361,498 proteins. Each protein's information can be used to\ngenerate six samples, corresponding to the tasks: sequence-to-function, structure-to-function, description-to-sequence,\nstructure-to-sequence, description-to-structure, and sequence-to-structure. In addition to the multimodal protein data,\nwe augmented our training with self-collected conversational data, ensuring the model maintains strong conversational\ncapabilities. Furthermore, we applied a filtration criterion to exclude samples with a token count exceeding 1024,\nstreamlining the dataset for efficient model training."}, {"title": "2 Model Architecture", "content": "HelixProtX takes three inputs: the system message $m_{sys}$, the user message $m_{usr}$, and the condition $f_{cond}$. Both $m_{sys}$\nand $m_{usr}$ are sequences of textual tokens. The condition $f_{cond}$ can be one of the following: the text token sequence\n$f_{desc}$ representing the protein description, the amino acid sequence $f_{seq}$, or the coordinates of all atoms in the protein\n$f_{struct}$. For description prediction and sequence design tasks, HelixProtX generates a textual response X. For structure\nprediction and design tasks, HelixProtX produces a sequence of residue angles A.\nAlgorithm 1 outlines the main inference steps of HelixProtX. Lines 1 to 7 organize and concatenate the input information\nto form the LLM input $f_{input}$. The sequence condition, structure condition, and textual description condition are each\nprocessed through their respective Sequence Encoder, Structure Encoder, and the LLM's WordEmbedding for feature\ntransformation. Lines 9 to 18 are focused on decoding outputs based on the specific task. For description prediction\nand sequence design tasks, text tokens are decoded by the LanguageModelHead (line 11). For structure prediction and\ndesign tasks, residue angles are decoded by the ResidueAngleHead (line 15) when the predicted text token is [NUM].\n$d_1$=4096 is the\nhidden size of the language model. Both the LanguageModelHead and the ResidueAngleHead are implemented as\nMLP layers. The decoded residue angles are then processed by the ResidueAngleEmbedding module (see Subsection\n2.2) to prepare them for subsequent prediction iterations."}, {"title": "2.1 Abstractor", "content": "Abstractor modules (Algorithm 2) map sequence and structure representations into the LLM's input space. We simplify\nthe Abstractor designed by [28", "28": "are a set of learnable parameters utilized to"}]}