{"title": "LICENSE PLATE IMAGES GENERATION WITH DIFFUSION MODELS", "authors": ["Mariia Shpir", "Nadiya Shvai", "Amir Nakib"], "abstract": "Despite the evident practical importance of license plate recognition (LPR), corresponding research is limited by the volume of publicly available datasets due to privacy regulations such as the General Data Protection Regulation (GDPR). To address this challenge, synthetic data generation has emerged as a promising approach. In this paper, we propose to synthesize realistic license plates (LPs) using diffusion models, inspired by recent advances in image and video generation. In our experiments a diffusion model was successfully trained on a Ukrainian LP dataset, and 1000 synthetic images were generated for detailed analysis. Through manual classification and annotation of the generated images, we performed a thorough study of the model output, such as success rate, character distributions, and type of failures. Our contributions include experimental validation of the efficacy of diffusion models for LP synthesis, along with insights into the characteristics of the generated data. Furthermore, we have prepared a synthetic dataset consisting of 10,000 LP images, publicly available at https://zenodo.org/doi/10.5281/zenodo.13342102. Conducted experiments empirically confirm the usefulness of synthetic data for the LPR task. Despite the initial performance gap between the model trained with real and synthetic data, the expansion of the training data set with pseudolabeled synthetic data leads to an improvement in LPR accuracy by 3% compared to baseline.", "sections": [{"title": "1 Introduction", "content": "LPR plays important role in traffic management, automatic ticketing, security and surveillance. For the last decade, the state-of-the-art results in LPR have been achieved with deep learning methods [1, 2, 3, 4, 5]. The unprecedented success of neural networks (NN) in this and other computer vision tasks is based on the usage of large datasets. However, privacy protection laws such as GDPR [6] in European Union impose severe limitations on data collection, storage, and usage. Consequently, only a limited number of open LPR datasets are available, many of them including fewer than a thousand images [7, 8, 9, 10, 11], particularly for those of European origin.\nOne viable solution to restricted data availability is synthetic data. Template-based LP image generation [12] is a robust and controllable approach that, nevertheless, requires meticulously handcrafted data augmentations to transform the template into a realistic image. Furthermore, it is highly dependable on the template itself and cannot be easily transferred to a similar problem. Generative adversarial networks (GANs) have allowed researchers to automate the template-to-real-image transformation [13, 14], and to achieve higher diversity and real-life likeliness [15]. However, stability of GAN training remains a challenge.\nInspired by recent advances of diffusion models for image and video generation, we propose to apply them to LP synthesis. To experimentally validate this approach, we trained a Denoising Diffusion Probabilistic Model (DDPM) [16] on a Ukrainian LP dataset consisting of 78k images. Consequently, 1000 images were generated for a detailed analysis. They were manually classified as success and failure cases. Successfully generated LPs were annotated with the corresponding LP text. Based on these annotations, a character distribution analysis was performed. Furthermore, synthetic LPs were labeled for LPR task, and corresponding model was compared to the baseline trained with a real LP dataset.\nOur contributions in this research can be summarized as follows:\n\u2022 we experimentally verify the viability of realistic LP synthesis with diffusion models;\n\u2022 we analyze the outputs of the generative model, particularly the success rate, the character distribution, and the failure cases;\n\u2022 we prepare a large synthetic dataset of 10,000 LP images that we release [17] alongside this paper;\n\u2022 we empirically confirm the usefulness of synthetic data for the LPR task.\nThe rest of the paper is organized as follows: Section 2 discusses the related work on LP generation and open LPR datasets. Section 3 provides details on the experiments methodology, results and their analysis. Section 4 briefly describes the dataset of synthetic Ukrainian LPs publicly released as a result of this work. Finally, Section 5 concludes the article. Additional information regarding the dataset, including sample images, can be found in the Appendix."}, {"title": "2 Related Work", "content": "Generating synthetic LP images has become a practical solution to address the restrictions imposed by privacy protection laws on data collection and usage. Over the past few years, researchers have been investigating different methods to create realistic LP images for the purpose of training deep learning models in LPR tasks.\nIn the early days, computer graphics techniques were employed to generate LPs by creating artificial images using pre-designed templates and fonts. These methods are still being applied due to their robustness and controllability. Notably, Silvano et al. [12] have proposed synthesizing Mersocur LP based on template and carefully designed image augmentations. These methods, although successful in producing significant amounts of data, frequently fell short in terms of diversity and realism required for training resilient LPR models. Moreover, they are difficult to extend due to their heavy dependence on a specific template.\nResearchers have been investigating the potential of GANs in generating LP images that are more realistic. GAN-based approaches have demonstrated great potential in capturing the diverse range of factors present in real-world LPs, such as various fonts, lighting conditions, and backgrounds. In particular, Wang et al. [13] have proposed an improvement of the CycleGAN based model [18] that learns the mapping between the synthetic images generated by a script, and real images. Wu et al. [14] have adopted a similar approach and improve the image-to-image based Pix2Pix generative architecture [19]. Nevertheless, the challenges of generating high-quality images and ensuring a stable training process have been persistent in these approaches.\nIn recent times, diffusion models have gained significant attention as a compelling alternative for image generation tasks. Inspired by their success in producing high-quality photos and videos, we propose using diffusion models for LP synthesis. Diffusion models have numerous advantages, such as the capability to accurately model complex data distributions and produce a wide range of high-quality samples. Through this study, we explore the possibility of using diffusion models to create realistic Ukrainian LP images and examine their potential in tackling the challenge of limited data in LPR research."}, {"title": "2.1 License Plate Generation", "content": ""}, {"title": "2.2 License Plate Datasets", "content": ""}, {"title": "3 Experiments, Results and Discussion", "content": "In this section, we outline the experimental setup and conduct a thorough analysis of the generated images."}, {"title": "3.1 Experimental Setup", "content": ""}, {"title": "3.1.1 Dataset", "content": "Standardization of Ukrainian Vehicle License Plate Codes. In 1995, Ukraine standardized its vehicle LP codes to include only 12 Ukrainian Cyrillic letters with Latin alphabet visual equivalents: A, B, E, I, K, M, H, O, P, C, T, X. Additionally, a two-digit regional code was added to the LP.\nIn 2004, numerical regional codes were replaced with new letter codes. In 2013, further modifications were made, replacing the initial letters in existing codes as follows: A to K (except Crimea, where AK became MA), B to H, and C to I. Table 2 presents the list of LP prefixes introduced in 2004, along with their corresponding 2013 codes and associated regions.\nSince 2015, a new design featuring a blue band on the left side of the plate with the letters \"UA\" in white below the Ukrainian national flag was introduced. In 2021, Ukrainian regions were assigned two additional letter codes, although these have not yet been widely adopted. Furthermore, since 2020, vehicles powered by electric motors without internal combustion engines are designated with the characters Y or Z in their LP numbers.\nCurrently, all LPs issued in Ukraine, including Soviet-era plates, remain valid and can still be legally used on the country's roads. For this study, we will focus on one-line optimized plates of Type 1 (Regular vehicles) and Subtype 1-1-1 (Electric motor-powered vehicles), with codes registered between 2004 and 2021 [30]. These specific types of plates are the most commonly observed and used in Ukraine.\nDataset Details. Our study uses a private dataset of Ukrainian LP images, each captured in different lighting conditions and angles. In total, the dataset has 78,855 images (75,654 of Type 1, and 3,201 of Subtype 1-1-1), offering a wide range of real-world scenarios. See Figure 1 for more examples from the dataset."}, {"title": "3.1.2 Generative Model Training", "content": "For our experiments, we used the Denoising Diffusion Probabilistic Model (DDPM), a class of generative models that iteratively reduce noise from a sample over a set number of steps. This process progressively transforms a sample from a noise distribution to a data distribution. We followed the training configuration proposed by the authors in the original DDPM paper, with specific adjustments tailored to our task.\nImages were resized to 64x64 pixels without center cropping or flipping. For training, we used a batch size of 64. The chosen model consists of five feature map resolutions, ranging from 64x64 to 4x4, with dimensions [128, 128, 256, 256, 512]. The model includes two convolutional residual blocks per resolution level and self-attention blocks at the 16x16 and 8x8 resolutions between the convolutional layers.\nThe learning rate was initially set to 10-4, and subsequently changed using a cosine scheduler and a 5000-step warmup phase. Higher learning rates led to unstable training convergence. We used the AdamW optimizer with standard hyperparameters and applied EMA with a decay rate of 0.9999 to stabilize training. A dropout rate of 0.1 was applied to reduce overfitting.\nThe diffusion model was trained for a total of 100 epochs on a Tesla T4 GPU with 15GB of VRAM, which took approximately 30 hours to complete. For inference, the generated images were initially produced at a resolution of 64 \u00d7 64 pixels and later resized to 193 \u00d7 72 pixels to match the average aspect ratio of the training dataset."}, {"title": "3.2 LP Generation Results", "content": "Successful Image Generation Criteria. For further analysis, we established criteria for successful image generation. The criteria were based on the images being fully readable and meeting the following requirements:\n\u2022 The LP pattern must adhere to the format \"AA0000AA,\" which is the standard LP format registered between 2004 and 2021.\n\u2022 The prefix must correspond to a valid region code as per the Ukrainian regions listing (refer to Table 2).\n\u2022 The suffix is limited to the characters A, B, C, E, I, K, M, H, O, P, T, X, Y, and Z.\nImages that do not meet these criteria were classified as failed image generation."}, {"title": "3.3 Character Distribution Analysis", "content": "Symbol Distribution Analysis. We analyzed the distribution of prefix, digit, and suffix symbols in synthetic and real LPs (see Figure 6). The distributions show that synthetic data closely replicates real data, with only minor differences. For instance, the prefix symbol 'A' is highly frequent in both datasets, appearing in over 30% of the images. The digit symbols are also similarly distributed, with '0' being the most common at around 12% for both synthetic and real plates. However, some inconsistencies were observed.\nSpecifically, the digit '8' and the letter 'B' show differences in their frequencies. In synthetic LPs, '8' appears slightly more frequently than in real plates, and 'B' is more common as a suffix in generated LPs. This discrepancy could be due to the complexity in accurately drawing these symbols. The symbol 'I,' represented as a simple line, also appears more frequently in synthetic plates. This suggests that the model may prefer simpler shapes, which are easier to generate.\nInterestingly, the variance in symbol distributions for prefix symbols is minimal compared to digits and suffix symbols. This is likely because there are fewer prefix combinations in the training data, leading to less variation in their synthetic representation.\nRegional Distribution Analysis We also analyzed the regional distribution of LPs from different periods and types (synthetic and real) as shown in Figure 7. Despite the complexity of regional data, the synthetic models show a high degree of similarity to the real data. However, some inconsistencies are present, which could be due to the model's difficulty in replicating the exact distribution of complex regional data. These variations highlight areas where the model could be refined for better accuracy."}, {"title": "3.4 LPR with Synthetic Data", "content": "Methodology for Training Character Detection Models. To evaluate the usefulness of generated LP images for LPR task, we adopted the OCR-by-character-detection method prevalent in this domain [28, 27, 1].\nWe initiated the process by manually labeling 864 successfully generated synthetic LP images with bounding boxes. For a fair comparison, we also labeled 864 randomly sampled images from the training dataset. We then trained the YOLOv9-c model [32], chosen for character detection. The model trained on the real subset of images served as a baseline for accuracy comparison.\nThe YOLOv9-c model was trained using the Adam optimizer with a learning rate of 0.001 and a batch size of 16. We applied various image enhancement techniques, such as HSV adjustment, rotation, translation, scaling, shearing, and perspective transformation. To address the challenge of unbalanced character distribution, the training process incorporated image weights, allowing for image sampling proportional to the number of targets per image and inversely proportional to class frequency. The best model from this phase was selected based on the highest validation loss observed over 30 epochs. A dataset share of 10% was reserved for validation.\nFor the synthetic data, we trained several instances of the model based on a gradual training dataset expansion with pseudolabeling. Initially, 864 synthetic images were manually annotated and used for training. Subsequently, an additional 5,000 synthetic images were pseudolabeled using the model trained on the initial 864 synthetic images, expanding the synthetic dataset to 5,864 images. In the final phase, 10,000 more synthetic images were pseudolabeled using the model trained on the 5,864-image dataset, bringing the total to 15,864 synthetic images.\nTo ensure high-quality image samples during pseudolabeling, we set the confidence threshold to 0.8. Each pseudolabeled image was selected based on the successful criteria described in Section 3.2. Each synthetic dataset was used to train separate models under the same setup as the baseline. It is important to note that pseudolabeling models are sensitive to overfitting, as overfitting can lead to the model ignoring failed parts of letters and focusing only on the main symbol features and their placement.\nValidation and Testing of LPR Models. Validation involved 200 real images to determine the optimal confidence threshold, maximizing LPR accuracy across the models. We considered the binary accuracy measure: 1 for a correctly read LP text and 0 for an incorrectly read LP text, regardless of the number of errors in the LP text or their type. The results of the validation experiments are shown in Table 3.\nThe test phase used 1,000 real LP images to evaluate the model performance. The models were applied with the optimal confidence thresholds found during the validation phase. The test results are given in Table 3.4. The baseline model, trained with 864 manually labeled real images, resulted in 94.1% LPR accuracy. Its direct competitor, the model trained with 864 manually labeled synthetic images, showed a lower performance of 90.9%. However, as the number of synthetic images increased, the LPR accuracy improved significantly. We observe that with equal manual labeling effort (of 864 images), generating and pseudolabeling more images significantly improves the LPR accuracy. The accuracy reaches 96.3% with 5,864 synthetic images and further increases to 97.5% with 15,864 synthetic images, both of which outperform the baseline accuracy of 94.1% achieved by the model trained on real images.\nThese results demonstrate the high potential of synthetic data for enhancing LPR accuracy in scenarios with limited data availability, with a clear benefit from increasing the volume of synthetic training data."}, {"title": "4 Dataset Description", "content": "To address the challenge of data scarcity in LPR tasks and to fill the gap in available Ukrainian LP datasets, we are releasing a dataset of 10,000 synthetic Ukrainian vehicle LP images [17]. This dataset, which was instrumental in the second step of our dataset expansion process and contributed to training the highest-performing model in our experiments, is intended to serve as a robust resource for the training and validation of LPR models. By providing diverse conditions, including variations in lighting and angles, this dataset supports the exploration of model performance in real-world scenarios, ultimately aiding the development of more accurate and resilient LPR systems.\nDataset Composition The dataset contains 10,000 images, each with a resolution of 193 \u00d7 72 pixels. These images represent two main types of Ukrainian LPs: regular vehicles and electric motor-powered vehicles. The dataset covers a wide range of scenarios, including variations in lighting conditions, viewing angles, and regional codes, ensuring coverage of the standard LP formats used in Ukraine between 2004 and 2021.\nNote: As the data samples are synthetically generated, there may be slight inaccuracies in the representation of the intended distance between the letters and the exact color of the LPs. While these aspects have been approximated to closely resemble real-world conditions, they might not perfectly match the specifications of actual LPs.\nData Annotation Each image in the dataset is annotated in the YOLO Darknet format, which includes precise bounding box coordinates for each character on the LP. The annotations follow the standard LP format \"AA0000AA,\" where:\n\u2022 AA represents the regional code.\n\u2022 0000 represents the numerical sequence.\n\u2022 AA represents the suffix, corresponding to specific Ukrainian Cyrillic letters with Latin equivalents.\nDistribution Analysis We conducted a detailed analysis of the character and regional distributions within the dataset. The frequency of digits and letters at each LP position is visualized in heatmaps (see Appendix, Figures 9), while the regional distribution based on LP prefixes is shown in a bar chart (see Appendix, Figure 10). Additionally, we have included sample images in the Appendix (see Figure 8) that highlight different scenarios and conditions, providing a better sense of the dataset's quality and variety."}, {"title": "5 Conclusions", "content": "In this paper, we have proposed a novel approach for synthesizing realistic LPs using diffusion models, addressing the challenge of limited data availability in LPR tasks. Through experimental validation, we have demonstrated the efficacy of diffusion models in generating synthetic LP images that closely resemble real-world data and their usefulness for the LPR task. Our analysis of success rates, character distributions, and failure cases provides valuable insights into the capabilities and limitations of the proposed approach.\nFurthermore, the creation of a synthetic dataset comprising 10,000 LP images adds to the existing resources available for LPR research, offering researchers and practitioners access to a diverse set of data for training and evaluation purposes. By releasing this dataset alongside the paper, we aim to contribute to the advancement of LPR technology and foster further research in this area.\nLooking ahead, future research directions could explore enhancements to the proposed synthesis approach, such as incorporating additional sources of variability to generate more diverse LP images. Additionally, investigating the generalization capabilities of models trained on synthetic data to real-world scenarios would be a valuable avenue for further exploration.\nOverall, our work highlights the potential of synthetic data generation using diffusion models in augmenting data availability for LPR tasks and lays the groundwork for future advancements in this field."}, {"title": "A Distribution Analysis and Sample Images", "content": ""}, {"title": "A.1 Character Distribution by Position", "content": "Figure 9 shows the distribution of digits and letters across different positions in the synthetic license plates. The heatmaps highlight the frequency of each character at specific positions, revealing patterns that align with common license plate structures in Ukraine."}, {"title": "A.2 Regional Distribution", "content": "Figure 10 presents the regional distribution of license plates based on their prefixes. This bar chart illustrates the number of license plates generated for each region, reflecting the dataset's geographic diversity."}, {"title": "A.3 Sample Images", "content": "To provide a clear understanding of the visual quality and diversity of the dataset, Figure 8 includes a selection of synthetic license plate images. These samples represent various conditions such as different lighting, angles, and regional codes, demonstrating the dataset's capability to mimic real-world scenarios."}]}