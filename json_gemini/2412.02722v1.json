{"title": "Enhanced N-BEATS for Mid-Term Electricity Demand Forecasting", "authors": ["Mateusz Kasprzyk", "Pawe\u0142 Pe\u0142ka", "Boris N. Oreshkin", "Grzegorz Dudek"], "abstract": "This paper presents an enhanced N-BEATS model, N-BEATS*, for improved mid-term electricity load forecasting (MTLF). Building on the strengths of the original N-BEATS architecture, which excels in handling complex time series data without requiring preprocessing or domain-specific knowledge, N-BEATS* introduces two key modifications. (1) A novel loss function combining pinball loss based on MAPE with normalized MSE, the new loss function allows for a more balanced approach by capturing both L\u2081 and L\u2082 loss terms. (2) A modified block architecture \u2013 the internal structure of the N-BEATS blocks is adjusted by introducing a destandardization component to harmonize the processing of different time series, leading to more efficient and less complex forecasting tasks. Evaluated on real-world monthly electricity consumption data from 35 European countries, N-BEATS* demonstrates superior performance compared to its predecessor and other established forecasting methods, including statistical, machine learning, and hybrid models. N-BEATS* achieves the lowest MAPE and RMSE, while also exhibiting the lowest dispersion in forecast errors.", "sections": [{"title": "Introduction", "content": "Mid-term load forecasting (MTLF) is essential for power system operators and planners, as it involves predicting electricity demand over a time horizon of several weeks to a year. Accurate MTLF supports informed decision-making across multiple aspects of power system management, including power plant scheduling, infrastructure expansion, market operations, and maintaining grid reliability and security. By anticipating future demand, utilities can optimize maintenance schedules, secure fuel supplies, and plan necessary capacity additions. Additionally, accurate forecasts across various time horizons are crucial for ensuring grid stability by maintaining the balance between supply and demand. Furthermore, precise forecasting enables strategic decision-making in energy markets, guiding the timing of electricity purchases and sales. In summary, load forecasting serves as a cornerstone for efficient, reliable, and resilient power system operations."}, {"title": "Related Work", "content": "MTLF methodologies have evolved significantly over the years, encompassing a wide range of techniques from traditional statistical approaches to cutting-edge artificial intelligence solutions. Recent research in this area has focused on improving accuracy and robustness, particularly in the face of increasing uncertainty and complexity in energy systems.\nMTLF strategies generally fall into two categories: conditional and autonomous modeling [13]. Conditional modeling integrates broader economic and infrastructural contexts, utilizing variables such as economic indicators and power grid characteristics. Autonomous modeling, on the other hand, relies primarily on historical consumption data, temperature patterns, and seasonality factors, making it more suitable for economies with stable energy demand patterns [6].\nHistorically, classical statistical methods like ARIMA and exponential smoothing (ETS) dominated the MTLF landscape [3, 14]. However, their limitations in capturing non-linear relationships and adapting to complex patterns prompted researchers to explore more sophisticated approaches [28]. Machine learning offered enhanced adaptability and the ability to capture intricate patterns. Examples include support vector machines [17], neural"}, {"title": null, "content": "networks (NNs) [26], and fuzzy systems [1], which significantly improved forecast accuracy in scenarios where traditional methods fell short.\nMTLF time series exhibit significant seasonal patterns, prompting researchers to employ pattern-based methods and initial preprocessing before applying forecasting models. This approach has proven effective in both classical [22] and neural network [11] methodologies.\nThe advent of deep learning (DL) marked a paradigm shift in MTLF. DL architectures, with their ability to leverage massive datasets and extract complex patterns, overcame many limitations of classical NNs. Recurrent NNs such as Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) networks demonstrated remarkable efficacy in handling long-term dependencies in time series data [30, 18]. They are combined with classical methods to preprocess complex data. For instance, Bedi and Toshniwal [5] proposed a DL framework that integrates Empirical Mode Decomposition (EMD) with LSTM for electric load forecasting, showing promising results in handling non-stationary and non-linear load data. Similarly, Dudek et al. [12] introduced a hybrid hierarchical model for MTLF, which integrates Exponential Smoothing (ETS) with advanced LSTM networks and ensemble techniques, showcasing improved forecasting accuracy.\nRecent years have seen the emergence of even more advanced DL architectures. The integration of attention mechanisms into DL models has advanced forecasting capabilities by enabling models to prioritize the most relevant parts of the input sequence. Attention-based architectures, such as the Transformer model, excel in capturing long-range dependencies within data, albeit with increased computational demands [29, 19]. Notably, in [16], a transformer-based MTLF model is proposed, capable of generating probabilistic forecasts with improved interpretability and the ability to handle data at low temporal resolutions.\nA notable recent development is the N-BEATS architecture, which has achieved state-of-the-art performance across various forecasting tasks [20]. Initially designed for general time series applications, N-BEATS has been successfully tailored for MTLF, showcasing its adaptability and effectiveness. In a study by Oreshkin et al. [21], the N-BEATS model demonstrated superior performance in MTLF, outperforming both traditional and contemporary forecasting methods while maintaining computational efficiency. This study further refined N-BEATS to align with the specific requirements of MTLF, leading to increased forecast accuracy and robustness.\nAnother emerging trend is the focus on interpretability in MTLF models."}, {"title": null, "content": "Baur et al. [4] reviews literature on explainable and interpretable machine learning methods for electric load forecasting, identifying trends and techniques to improve forecast transparency and interpretability. An example of an MTLF model with interpretability features is presented in [16], where the transformer model is capable of explaining the contribution of each input feature to the predicted load at different times of the day. Such capabilities not only improve trust in the model's predictions but also provide valuable insights for decision-making in energy management.\nIn conclusion, the field of MTLF has undergone a significant transformation, progressing from classical statistical methods through early machine learning applications to advanced deep learning architectures and hybrid models. Recent studies, such as those on N-BEATS in MTLF, interpretable DL models, and ensemble forecasting methods [7], demonstrate that this field continues to evolve, offering increasingly accurate and flexible tools for load forecasting while addressing crucial aspects like interpretability and computational efficiency."}, {"title": "Motivation and Contributions", "content": "N-BEATS is one of the most advanced machine learning models for time series forecasting, incorporating unique features that enhance its effectiveness and flexibility [20]. It utilizes a modular block structure, where each block is specifically designed to capture distinct components of the data, enabling the model to decompose forecasts into patterns. Additionally, N-BEATS includes backward and forward residual connections between blocks, allowing it to learn complex temporal patterns through iterative refinement, which improves both predictive accuracy and convergence speed.\nThe architecture of N-BEATS is designed to handle complex time series data without requiring specialized preprocessing or feature engineering, making it highly adaptable across various forecasting tasks. As a purely data-driven model, N-BEATS does not rely on domain-specific assumptions or prior knowledge, which enables it to adapt seamlessly to diverse datasets without substantial modifications, supporting robust predictions for both short- and long-term forecasting horizons.\nMost existing models for MTLF primarily focus on enhancing forecasting accuracy, while neglecting the potential bias in the forecasts, which plays a crucial role in MTLF. The N-BEATS implementation in [21] addresses this gap by introducing an effective mechanism to control forecasting bias using"}, {"title": null, "content": "the pinball-MAPE loss function, demonstrating its effectiveness on real-world data.\nGiven these strengths, we selected N-BEATS to address our MTLF problem, introducing modifications to further enhance its accuracy. Our first enhancement involves designing a tailored loss function, building on prior research [21] that demonstrated the substantial benefits of optimized loss functions in forecasting accuracy. We refine this approach here to better align with MTLF requirements. The second modification involves adjusting the internal architecture of the blocks to better suit different forecasting tasks, further improving the model's performance.\nOur contributions can be summarized as follows:\n1. Novel Loss Function for MTLF: We introduce a new loss function that combines pinball loss based on MAPE with normalized MSE. This formulation captures both L\u2081 and L\u2082 loss terms, allowing for a more balanced approach. Additionally, the pinball loss aspect enables control over forecast bias and can be used for forecasting quantiles, further enhancing the model's flexibility.\n2. Novel Block Architecture for N-BEATS: We propose a modification to the internal architecture of the N-BEATS blocks by introducing a destandardization component. This component harmonizes the different time series processed by the blocks, making the forecasting tasks they solve less complex and more efficient.\n3. Empirical Results for MTLF: We empirically demonstrate, using real-world data from 35 European countries, that the proposed N-BEATS* model significantly outperforms its predecessor as well as well-established statistical and state-of-the-art machine learning methods in terms of forecasting accuracy.\nThe rest of the paper is organized as follows. Section 2 provides an overview of the data and formulates the forecasting problem. Section 3 introduces the proposed N-BEATS* model for MTLF. The experimental framework used to evaluate the model's performance is detailed in Section 4. Section 5 explores the model's innovations, practical implications, and limitations, while also outlining potential directions for future research. Finally, Section 6 presents the conclusions of the study."}, {"title": "Data and Forecasting Problem", "content": "Monthly electricity demand time series exhibit intricate dynamics characterized by a non-linear trend, seasonal patterns, and stochastic variations. Examples of these time series are shown in Fig. 1, with more detailed analyses and visualizations available in [21], [12] and [10]. The trend component is shaped by country-specific factors, including economic growth rates, industrial activity, and climate variations [8]. Seasonal fluctuations largely reflect regional climatic influences and weather patterns [2], along with the heterogeneous makeup of electricity consumers within each nation. These seasonal patterns, with their regular cycles, offer critical insights into recurring demand behaviors.\nDespite these identifiable patterns, accurate forecasting is challenged by several disruptive factors. Unanticipated economic events, extreme weather episodes, and changes in political or regulatory policies introduce considerable volatility and uncertainty into demand patterns [9]. Such disruptions amplify the complexity of forecasting future electricity demand and complicate the extraction of reliable signals from historical data.\nLet $Y = \\{y_1,..., y_T\\}$ represent a monthly electricity demand time series, where $y_t \\in R$ denotes the observed value at time step t and T is the total length of the time series. The goal of MTLF is to predict the future values of the time series over a forecasting horizon H, i.e. values $Y_T = [y_{T+1},..., y_{T+H}]$. To achieve this, the model takes as input a lookback window of length w < T, which contains the most recent observations up to $y_T$. This lookback window, denoted by $x_T = [y_{T-w+1},..., y_T]$, serves as the historical context for the forecast. In this study, no exogenous variables are incorporated as additional inputs, so the approach focuses on univariate"}, {"title": null, "content": "MTLF, relying solely on the demand series itself.\nThe forecasting model is expressed as $f(x; \\Theta)$, where $\\Theta$ represents the model's parameters and hyperparameters. It is trained on historical data, $\\{(x_t, y_t\\)}_{t \\in \\Xi}$, where \u039e is a set of input-output pairs selected from past observations. Model training aims to minimize the difference between the actual and predicted values, typically using a predefined loss function. Our model is trained in a global (cross-learning) setting, utilizing monthly electricity demand time series data from multiple countries. This approach requires equipping the model with mechanisms to handle differences in scale and variability inherent to each time series, ensuring adaptability to diverse demand patterns across countries.\nPerformance evaluation of the model typically relies on metrics such as Mean Absolute Percentage Error (MAPE), Root Mean Square Error (RMSE), or other domain-relevant measures, which assess both accuracy and robustness in predicting electricity demand."}, {"title": "Forecasting Model", "content": "N-BEATS (Neural Basis Expansion Analysis for time-series Forecasting) is a deep neural network model designed for time-series forecasting [20]. Unlike many other forecasting models, N-BEATS frames forecasting as a non-linear multivariate regression task rather than a sequence-to-sequence problem. Its design philosophy centers around conceptual simplicity, flexibility, and high performance without requiring domain-specific feature engineering or time-series decomposition. N-BEATS offers two configurations: the generic version, which optimizes performance without requiring interpretable outputs, and the interpretable version, which decomposes the forecast into human-understandable components such as trend and seasonality. This decomposability makes N-BEATS suitable for applications where interpretability is crucial. In this study, we use the generic version. N-BEATS was adapted for MTLF in [21]. Here, we present further development of the model, which we henceforth refer to as N-BEATS*, including the refinement of the time-series processing within network blocks and a new loss function. These modifications enhance the model by addressing the unique challenges associated with the MTLF problem."}, {"title": "N-BEATS* Architecture", "content": "The N-BEATS* model is illustrated in Fig. 2. It is composed of the stack of blocks connected via residual connections, forming a deep hierarchy. This allows the model to capture complex, nonlinear relationships in time-series data, leveraging both forward and backward residual links. Residual connections facilitate better gradient flow during training, allowing effective stacking of numerous blocks. The stacked block architecture enables the model to iteratively refine its predictions, making it highly effective at capturing patterns such as trends and seasonality. The forecasts generated by each block are summed to produce the final forecast. Each block in the N-BEATS* model consists of fully connected layers followed by non-linear activations, typically ReLU (MLP component in Fig. 2). The architecture features a dual-path mechanism (a fork) that predicts both a forecast for future values (termed as the forecast path) and a reconstruction of past values (termed as the backcast path).\nWe enhance the standard N-BEATS block by introducing a destandard-"}, {"title": null, "content": "ization step for the forecast and backcast vectors (represented as MEAN and STD components in Fig. 2). This transformation simplifies the task of the backcast/forecast fork by allowing it to predict sequences that are standardized, with zero mean and unit variance, rather than sequences varying in level and variance. As a result, the forecast and backcast vectors predicted for different countries differ only in shape, not in level or variance. The appropriate level and variance are subsequently restored through the MEAN and STD components, making the model more robust and consistent across diverse time-series. This adjustment is particularly important given that the model is trained in cross-learning mode, meaning it learns simultaneously from time-series data across multiple countries.\nNote that the residual connections between blocks are transformed using the ReLU function, eliminating negative values from the inputs to the next block. Additionally, the model's input x-vectors are normalized (shown as the NORM component in Fig. 2) by dividing each by its maximum value. This normalization unifies the input vectors, ensuring that each has a maximum value of 1. Consequently, the model operates on normalized data and generates consistent forecasts, which are then denormalized (via the DENORM component in Fig. 2) to restore the appropriate scale (the maximum value of the original input vector).\nThe N-BEATS* model can be expressed by the following equations:\nINPUT NORMALIZATION: $x^{(1)} = \\frac{x}{\\text{max}(x)}$\nFOR BLOCK m = 1... M : $h^{(m)} = FC(x^{(m)})$ , $x'^{(m)} = \\text{LINEAR}(h^{(m)}) \\cdot \\text{STD}(x^{(m)}) + \\text{MEAN}(x^{(m)})$ , $\\hat{y}^{(m)} = \\text{LINEAR}(h^{(m)}) \\cdot \\text{STD}(x^{(m)}) + \\text{MEAN}(x^{(m)})$ , $x^{(m+1)} = \\text{RELU}(x'^{(m)} - \\hat{y}^{(m)})$\nOUTPUT: $\\hat{y} = \\text{max} (x) \\cdot \\sum_{m=1}^{M} \\hat{y}^{(m)}$\t\t\t(1)"}, {"title": "Loss Function", "content": "Given that MAPE is a well-established performance metric for electricity load forecasting, [21] introduces the pinball-MAPE loss function, which aligns training and evaluation metrics and provides a leverage for controlling"}, {"title": null, "content": "forecast bias:\n$P\u041c\u0410P\u0415(y, \\hat{y}, \\tau) = \\frac{1}{N \\cdot H} \\sum_{i=1}^{N} \\sum_{j=1}^{H} \\begin{cases} \\tau \\frac{(y_{i,j}-\\hat{y}_{i,j})}{|y_{i,j}|} & \\text{if } y_{i,j} \\geq \\hat{y}_{i,j}, \\\\ (1 - \\tau) \\frac{(\\hat{y}_{i,j} - y_{i,j})}{|y_{i,j}|} & \\text{otherwise.} \\end{cases}$\nHere N represents the number of forecasted sequences evaluated by the loss function (e.g. the batch size), \u0397 is the forecast horizon, \u03c4 defines the quantile probability (\u03c4 = 0.5 corresponds to the median). In this study, we extend the pinball-MAPE (PMAPE) by adding the NMSE (normalized MSE) term, formulated as follows:\n$NMSE(y, \\hat{y}) = \\frac{1}{N \\cdot H} \\sum_{i=1}^{N} \\sum_{j=1}^{H} \\frac{(y_{i,j} - \\hat{y}_{i,j})^2}{VAR(y_i)}$\t\t\t(2),\nwhere VAR denotes the variance. This can be interpreted as the ratio of two MSEs: one for the model-generated forecast and one for a baseline forecast given by the mean of the target sequence. Thus, the normalized MSE equals 1 when the model's squared error matches the error of the mean-based baseline. The proposed loss combines the two losses described above with coefficient \u03bb \u2265 0 controlling the relative influence of NMSE and PMAPE over the overall loss function:\n$L(y, \\hat{y}, \\tau) = PM\u0410P\u0415(y, \\hat{y}, \\tau) + \\lambda \\cdot NMSE(y, \\hat{y})$.\t\t\t(3)\nFigure 3 shows the components of the proposed loss function. For \u03c4 = 0.5, PMAPE is symmetric, meaning that positive and negative deviations are treated equally. When \u03c4\u2260 0.5, however, the pinball function becomes asymmetric, which can aid in correcting forecast bias. If the model produces biased forecasts, slightly adjusting \u03c4 can help reduce this bias. Thus, the asymmetric loss function provides flexibility for bias mitigation. The NMSE component of the loss function penalizes larger errors more heavily than the PMAPE component, emphasizing the reduction of significant deviations. The combined effect of these two components ensures a balanced approach, improving both accuracy and robustness in forecasting."}, {"title": "Experiments", "content": "In this section, we evaluate the proposed N-BEATS* model on the MTLF task, benchmarking its performance against a range of models, including classical statistical methods, machine learning techniques, and hybrid approaches."}, {"title": "Data", "content": "This study uses real-world data from the ENTSO-E platform (www.entsoe. eu), comprising monthly electricity consumption time series for 35 European countries. The longest series span from 1991 to 2014 (11 countries), while others cover shorter periods: 17 years (6 countries), 12 years (4 countries), 8 years (2 countries), and 5 years (12 countries). Visualizations are available in [10], [21]. Each country's time series exhibits unique dynamics and characteristics, including trends, seasonality, and random fluctuations. This diversity offers a robust testing ground for evaluating the ability of forecasting models to capture and predict complex electricity demand patterns."}, {"title": "Optimization, Training and Evaluation Setup", "content": "The dataset was divided into three subsets for model development and evaluation. The test set consists of the final twelve months (2014) of each time series, while the validation set contains the preceding twelve months (2013). The training set encompasses all remaining historical data prior to 2013. We employed a two-stage process for model development. First, we used the training and validation subsets to optimize hyperparameters. Then, after determining the optimal hyperparameters, we merged the training and validation sets to train the final model. Finally, we evaluate the model's performance on the held-out test set. This split ensures proper temporal separation between model development and final evaluation, while maximizing the data available for the final model training.\nThe optimization and training methodology followed the approach established for the N-BEATS* predecessor in [21]. Hyperparameter configurations"}, {"title": "Baseline Models", "content": "In our comparative studies, we evaluate the performance of N-BEATS* against several baseline models. The optimization and training procedures for these baseline models are similar to those used for N-BEATS*, with hyperparameter settings described in detail in [21].\n\u2022 ARIMA and ETS: Classical statistical models, implemented using the auto.arima and ets functions from the R package forecast [15]."}, {"title": null, "content": "Both models leverage the Akaike information criterion (AICC) to automatically determine the optimal model structure and order.\n\u2022 k-NNw+ETS, FNM+ETS, N-WE+ETS, GRNN+ETS: Hybrid models that combine either k-nearest neighbor weighted regression, fuzzy neighborhood model, Nadaraya-Watson estimator, or general regression neural network for seasonal component forecasting, with ETS for trend and dispersion forecasting [10].\n\u2022 MLP: A perceptron with a single hidden layer and sigmoid non-linearities [24].\n\u2022 ANFIS: A standard adaptive neuro-fuzzy inference system [23].\n\u2022 LSTM: A standard LSTM model [25].\n\u2022 ETS+RD-LSTM: A hybrid model that combines ETS, an advanced LSTM architecture with residual and dilated connections [12].\n\u2022 N-BEATS: The predecesor of N-BEATS* described in [21]."}, {"title": "Data Processing by N-BEATS*", "content": "Fig. 4 illustrates the data processing flow across successive blocks. The input to BLOCK 1 is a normalized yearly demand curve for a given country. This block produces a forecast vector, which forms the primary component of the final forecast, and a backcast vector. After subtracting the backcast vector from the input to BLOCK 1 and applying the ReLU function, the resulting vector becomes the input to the second block. As shown in Fig. 4, the input vectors to BLOCKS 2-6 are highly similar, as are the forecast and backcast vectors produced by these blocks. The forecast vectors generated by BLOCKS 2-6 serve as incremental adjustments to the main forecast produced by BLOCK 1. With each successive block, the refined forecast curve increasingly aligns with the target curve (see the bottom-right plot in Fig. 4). As more blocks are added, MAPE decreases progressively, from 7.89 to 1.86 in the example shown."}, {"title": "Results", "content": "Table 2 presents the forecasting metrics averaged across 35 countries: the median absolute percentage error (MedAPE), mean absolute percentage error (MAPE), interquartile range of APE (IQR APE), root mean square error"}, {"title": null, "content": "(RMSE), and mean percentage error (MPE). As shown in this table, our proposed N-BEATS* model achieves the lowest errors across several metrics: it yields the lowest Median APE, MAPE, and RMSE, and also produces forecasts with the least dispersion, as indicated by the lowest IQR APE. Compared to N-BEATS, N-BEATS* reduces MAPE by up to 9% and RMSE by 1.6%. To statistically confirm the improved accuracy of N-BEATS* over N-BEATS, we applied the Diebold-Mariano test, which assesses the equality of forecasting accuracy between two models under general assumptions. The test statistic, which follows an asymptotic standard normal distribution, was calculated as -3.05. This value is below the critical z-value of -2.576 for a significance level of \u03b1 = 0.01, indicating statistically significant superiority"}, {"title": null, "content": "of N-BEATS*. Furthermore, in [21], we demonstrated that N-BEATS outperforms each baseline model listed in Table 2 at the \u03b1 = 0.01 significance level. Together, these results confirm the overall superiority of N-BEATS* over both N-BEATS and all baseline models.\nFig. 5 shows a country-by-country comparison of MAPE between N-BEATS and N-BEATS*. In this analysis, N-BEATS* outperforms N-BEATS in 20 out of 35 cases, while N-BEATS has a slight edge in 15 cases. The largest improvement, observed for Montenegro (ME), reaches 38.5%, as further illustrated in Figure 6.\nForecast examples generated by N-BEATS* and N-BEATS are shown in Fig. 6. Note that the forecasts for Great Britain (GB) are underestimated, a result of an unexpected rise in demand during the forecast year despite a preceding downward trend. Conversely, for France (FR), an opposite trend led to a slight overestimation. The most accurate forecast, with a MAPE of 0.97%, is for Ireland (IE), while the least accurate, with a MAPE of 12.67%, is for Montenegro (ME), influenced by an outlier in the series in the year preceding the forecast (see Fig. 1).\nMPE, shown in Table 2, provides insight into the forecast bias of both the proposed and baseline models. Notably, N-BEATS* is the only model that"}, {"title": null, "content": "produces positively biased forecasts, indicating a tendency for underprediction, whereas all other models tend to overpredict. N-BEATS* achieves one of the lowest biases, with MPE of 0.56%, closely following N-BEATS, which has MPE of -0.34%. Fig. 7 illustrates the MPE distributions for these two models, where N-BEATS* shows a higher concentration of forecasts with MPE values close to zero, indicating more frequent low-bias predictions.\nIn terms of skewness, N-BEATS* exhibits a skewness of 1.73, suggesting a more balanced error profile with a mild tendency toward overprediction. In contrast, N-BEATS has a negative skewness, indicating a propensity for occasional, larger overpredictions.\nBoth models show high kurtosis values, suggesting that their error distributions include more extreme deviations or outliers. However, the reduction in both kurtosis and skewness from N-BEATS to N-BEATS* is beneficial, as it implies that N-BEATS* produces a more consistent error pattern with fewer significant directional biases. This improvement contributes to the overall reliability of the forecasts."}, {"title": "Ablation Study", "content": "In this section, we perform an ablation study to assess the impact of various modifications to the N-BEATS* model on its forecasting performance. We evaluate the following simplified variants of N-BEATS*:\nnoL2 N-BEATS* without the NMSE term in loss function (3).\nnoVar N-BEATS* without normalizing the L\u2082 component by the target series variance (omitting VAR(y) in (3))."}, {"title": null, "content": "noDestd N-BEATS* without the destandardization of the forecast and backcast outputs (removal of the MEAN and STD components, as depicted in Fig. 1).\nnoReLU N-BEATS* without the ReLU activation function applied to the inputs of blocks 2 to M (omission of the RELU components in Fig. 1).\nTable 3 compares forecasting errors for the full model and its reduced variants. Based on the results from this table, the most significant performance degradation occurs when the NMSE term and its normalization by variance are removed, with the noVar variant showing the highest error rates. In contrast, the removal of destandardization and the ReLU activation function"}, {"title": null, "content": "has a more moderate impact, with similar performance declines across these variants. Proper formulation of the loss function, including the NMSE term with variance normalization, is crucial for maintaining forecasting accuracy in the N-BEATS* model."}, {"title": "Discussion", "content": "The results presented in Section 4.5 demonstrate that N-BEATS* exhibits superior performance compared to an array of forecasting methods, including statistical models (ARIMA and ETS), classical machine learning techniques (MLP, ANFIS, and LSTM), and hybrid approaches. Notably, N-BEATS* consistently achieves the lowest Median APE, MAPE, and RMSE values, while simultaneously demonstrating the lowest dispersion of forecast errors, as reflected by its IQR APE."}, {"title": "Sophisticated Architecture for Raw Time Series", "content": "Several factors contribute to the success of N-BEATS*. The model's inherent ability to effectively handle raw time series data without requiring"}, {"title": null, "content": "decomposition or preprocessing is a significant advantage. Many statistical and machine learning methods struggle with non-stationarity, non-linear relationships, and seasonal variations, often necessitating preliminary steps such as differencing, detrending, deseasonalization, or decomposition. In contrast, N-BEATS* leverages its sophisticated architecture, incorporating backward and forward residual links, a deep stack of fully connected layers, forecast and backcast paths, and hierarchical aggregation of partial forecasts, to adeptly process raw time series data. This architectural advantage, in conjunction with the final ensembling process, results in highly accurate forecasts."}, {"title": "Ensembling", "content": "The ensemble approach is a key factor in the model's success, significantly enhancing its forecasting accuracy and reliability. By aggregating predictions from multiple ensemble members (64 in our implementation), the model reduces the variability and overfitting often associated with single-model predictions. In N-BEATS*, variability among individual ensemble members arises from random initialization and random batch selection during training. This diversity strengthens the ensemble's robustness and generalization, resulting in consistently more accurate and dependable forecasting outcomes."}, {"title": "Cross-learning", "content": "The cross-learning approach employed during the training of N-BEATS* is another critical factor in its success. By training on multiple time series simultaneously, the model captures shared features and components, accelerating learning and optimization, particularly crucial for complex deep learning models with numerous parameters and hyperparameters. While other models, except for ETS+RD-LSTM, undergo separate training and optimization for each time series, N-BEATS* leverages the collective information embedded within multiple time series to achieve superior performance."}, {"title": "Key Innovations", "content": "The introduction of the destandardization component in the block architecture simplifies forecasting tasks by harmonizing time series with varying scales. This innovation enables the model to handle cross-learning more effectively, leveraging shared patterns across multiple time series. As a result, N-BEATS* demonstrates improved accuracy and robustness, particularly in datasets characterized by non-stationarity and high variability."}, {"title": "Practical Implications", "content": "The enhanced performance of N-BEATS* translates directly to practical benefits for power system operators. Improved accuracy reduces the risk of under- or over-allocation of resources, while the model's bias control ensures reliability in planning scenarios. The ability to train the model on raw time series without requiring domain-specific preprocessing makes N-BEATS* particularly suited for large-scale deployment across diverse regions."}, {"title": "Limitations", "content": "While N-BEATS* demonstrates clear advantages, certain limitations warrant further exploration and refinement:\n\u2022 Generalizability to Other Forecasting Problems: This study focuses on applying N-BEATS* to MTLF, leveraging its strengths in midterm time horizons. However, further investigation is needed to evaluate its performance on problems with different characteristics, such as varying data frequencies, shorter time horizons, or specific domain requirements. For instance, the model's effectiveness in short-term forecasting tasks with triple seasonality and hourly resolutions has not yet been explored. While the original N-BEATS was designed for general time series forecasting, adapting N-BEATS* to broader contexts remains an open question.\n\u2022 Limited Use of Exogenous Variables: The current implementation of N-BEATS* is designed for univariate time series, relying solely on historical demand data. Many forecasting tasks, such as weather prediction or sales forecasting, require the integration of exogenous variables to improve accuracy. The absence of support for external inputs limits the applicability of N-BEATS* to problems where external factors play a significant role in influencing outcomes."}, {"title": null, "content": "\u2022 Computational Cost: While N-BEATS* maintains a relatively efficient design for deep learning models, its deep architecture with stacked blocks and ensembling approach still demands substantial computational resources for training and optimization. This complexity could pose challenges when scaling to very large datasets or deploying in applications with strict real-time constraints. Strategies to simplify the architecture without compromising performance may help address this limitation.\n\u2022 Interpretability: Although an interpretable variant of N-BEATS exists, this study employs the generic version, prioritizing performance over transparency. The impact of the introduced modifications, such as the new loss function and the modified block architecture, on the interpretability of the network has not been assessed. A lack of transparency could hinder adoption in domains where decision-making requires clear explanations for predictions.\n\u2022 Sensitivity to Data Quality: As a purely data-driven model, N-BEATS* heavily relies on the quality and representativeness of the training data. Issues such as outliers, missing values, or inconsistencies can negatively affect its accuracy and robustness.\n\u2022 Sensitivity to Hyperparameter Tuning: N-BEATS* performance depends on carefully tuned hyperparameters, such as the pinball quantile probability (\u03c4), the loss function's NMSE weight (\u03bb), and the look-back window size (w). Determining optimal values for these parameters can require extensive experimentation, which might limit the ease of use and adaptability of the model in new contexts.\n\u2022 Potential for Overfitting: The deep architecture of N-BEATS*, with numerous trainable parameters, introduces a risk of overfitting, particularly when trained on limited datasets. While cross-learning and ensembling techniques help mitigate this risk, careful application of regularization methods and robust validation procedures remain crucial to ensure the model generalizes well to unseen data.\n\u2022 Dependency on Cross-Learning: N-BEATS* benefits from cross-learning by identifying shared patterns across multiple time series. While this approach is highly effective for MTLF, it may perform less"}, {"title": null, "content": "effectively on datasets consisting of isolated or highly heterogeneous time series. For such cases, alternative training paradigms or domain-specific adaptations may be necessary to achieve optimal performance.\n\u2022 Dependence on Ensembling: The high accuracy of N-BEATS* largely stems from leveraging an ensemble of multiple models. Individual models typically produce less accurate forecasts, making ensemble averaging a critical component for improved performance. However, this dependency significantly increases computational demands, potentially posing challenges in resource-constrained environments.\nAddressing these limitations through further research and innovation could broaden the applicability and impact of N-BEATS*, making it a more versatile and robust tool for time series forecasting."}, {"title": "Future Research Directions", "content": "Future work could focus on extending N-BEATS* to incorporate exogenous variables, such as economic indicators or weather data, to enhance its MTLF predictive accuracy. Additionally, leveraging the interpretable"}]}