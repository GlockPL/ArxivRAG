{"title": "Revisiting Fake News Detection: Towards Temporality-aware Evaluation by Leveraging Engagement Earliness", "authors": ["Junghoon Kim", "Junmo Lee", "Yeonjun In", "Kanghoon Yoon", "Chanyoung Park"], "abstract": "Social graph-based fake news detection aims to identify news articles containing false information by utilizing social contexts, e.g., user information, tweets and comments. However, conventional methods are evaluated under less realistic scenarios, where the model has access to future knowledge on article-related and context-related data during training. In this work, we newly formalize a more realistic evaluation scheme that mimics real-world scenarios, where the data is temporality-aware and the detection model can only be trained on data collected up to a certain point in time. We show that the discriminative capabilities of conventional methods decrease sharply under this new setting, and further propose DAWN, a method more applicable to such scenarios. Our empirical findings indicate that later engagements (e.g., consuming or reposting news) contribute more to noisy edges that link real news-fake news pairs in the social graph. Motivated by this, we utilize feature representations of engagement earliness to guide an edge weight estimator to suppress the weights of such noisy edges, thereby enhancing the detection performance of DAWN. Through extensive experiments, we demonstrate that DAWN outperforms existing fake news detection methods under real-world environments. The source code is available here.", "sections": [{"title": "1 INTRODUCTION", "content": "The advent of social media platforms has made it possible for news to travel to a vast amount of people, allowing for greater accessibility and efficiency when obtaining information. However, the propagation of news articles containing false information has also become much easier. The spreading of such fake news has a detrimental effect on societal security and public health, ranging from potentially affecting presidential election results [1] to inciting distrust and panic during a pandemic [2, 20]. As such, the field of fake news detection, which aims to identify fabricated news articles, has gained increasing attention and importance in recent years [31, 40].\nRecent fake news detection methods can be classified into two main categories. Content-based methods leverage patterns that can be obtained from the news article text itself, such as semantic representations or emotional features [6, 9, 10, 28]. On the other hand, social graph-based methods utilize social context knowledge, including user information, tweets and comments, in addition to textual contents [7, 25, 36, 37]. Specifically, social context knowledge can be beneficial for fake news detection since retweets on news pieces can reveal different propagation patterns for real and fake news, while user interactions and responses indicate how these types of news attract different user groups. Existing approaches model such contexts into graph structures, e.g., linking news article pairs based on the amount of tweets shared by readers. By utilizing Graph Neural Networks (GNNs) to model the relationship between news veracity and the structural patterns involved in rich social information, social graph-based methods often outperform their content-based counterparts and appear to be a promising area of research [29, 36].\nHowever, we point out that conventional social graph-based methods are trained and evaluated under an unrealistic scenario [7, 36]. Specifically, they divide news articles into training and test sets via random split or use social contexts that occur after the training time for training the model. Such temporality-ignorant settings (See Fig. 1(a) left) would lead to information leakage as the model can access future knowledge not only on article-related data (e.g., textual contents and veracity labels) but also context-related data (e.g., users, tweets and comments). We argue that this is inconsistent with real-world scenarios, where the detection model would be trained on offline data collected in advance, and then tested on online data delivered in real-time. Thus, it is more practical for the model to be trained by only utilizing data up to a certain point in time, while future data should only be available at test time, which we call a temporality-aware setting (See Fig. 1(a) right).\nIn Fig. 1(b), we examine the performance of existing social graph-based fake news detection methods (e.g., GCNFN [25], UPFD [7], FANG [26] and DECOR [36]) when they are trained and evaluated under the temporality-aware setting. Our empirical results on two prominent fake news datasets [30] reveal that when all related data are split into train/test considering the temporality (yellow bar), the performance of conventional methods decrease sharply, with a decline up to 8.6%p in F1 score. Such performance drops can be attributed to the inherent design flaws of these methods; that is, they construct a graph based on the complete information regarding social context given in the dataset regardless of the temporal information, leading to potential information leakage, which results in a single fixed structure for both training and testing (See Fig. 1(a) left). On the other hand, in the temporality-aware setting, the structure would change substantially after training (See Fig. 1(a) right).\nIn this work, we revisit the training and evaluation setting of social graph-based fake news detection methods, and propose a novel method that is applicable to real-world learning environments in which the temporal information should not be overlooked. The main idea is to utilize time-independent patterns in the graph, i.e., patterns representing general social user behaviors that occur similarly even at different points in time, so that the model is less affected by how the graph is constructed. Our method, called Detecting fake news via eArliness-guided re Weighting (DAWN), takes into account the earliness-related patterns of users and tweets. These patterns are based upon fundamental and well-explored theory on social behaviors, i.e., the confirmation bias theory [27], and thus the features extracted from them differ less before and after training, making them more robust against temporality-aware settings.\nThrough an extensive data analysis in Section 4, we find that users on social media who have stronger opinions and thus more rapidly engage (e.g., consume or repost) with news articles are more inclined to be attracted to articles of the same veracity, i.e., either only real news or only fake news. From these observations, we obtain some valuable insights: (1) earlier engagements tend to connect articles of the same veracity, while (2) the existence of later engagements leads to a higher probability of the labels being different, which can manifest as noisy edges in social graphs (i.e., edges linking real news-fake news pairs). Based on our findings suggesting that appropriately utilizing knowledge on engagement earliness can help identify the edge noise, we suppress the weights of such noisy edges aiming at enhancing the model's discriminative capabilities. To this end, we employ a Graph Structure Learning (GSL) framework, where we train an edge weight estimator to assign new weights to existing edges. By leveraging feature representations of edge-specific engagement earliness, we can successfully guide the edge weight estimator to downweight noisy edges.\nOverall, our contributions can be summarized as follows:\n\u2022 A realistic scenario for fake news detection. We argue that the assumption made by existing social graph-based methods that all relevant information is accessible during training is unrealistic, leading to potential information leakage. As such, we present a temporality-aware setting for fake news detection (both article-wise and context-wise) in which existing methods underperform owing to their inherent design flaws.\n\u2022 Earliness-related empirical findings. We analyze how the engagement earliness regarding users and tweets in a social network relate to the veracity label consistency of news article pairs.\n\u2022 Earliness-guided GSL. We propose a novel GSL-based fake news detection framework, called DAWN, that leverages our earliness-related insights to downweight noisy edges in a social graph.\n\u2022 Effectiveness. DAWN outperforms existing methods by a large margin on two real-world fake news datasets, highlighting the robustness of our simple yet effective earliness-based framework under the temporality-aware training and evaluation setting."}, {"title": "2 RELATED WORKS", "content": "2.1 Fake News Detection\nFake news detection aims to determine whether a given news article contains false information or not, and can generally be seen as a binary classification task that predicts its veracity label (0 if real, 1 if fake). Among the two main categories for fake news detection research, content-based methods utilize patterns from within the news article text itself. Such patterns include semantic representations [6, 22], emotional features [9, 10] and writing style [10, 28].\nMeanwhile, social graph-based methods [7, 25, 26, 36, 37] additionally incorporate various social contexts including user information, tweets and comments, and have shown state-of-the-art performance, generally improving over content-based methods. For instance, GCNFN [25] constructs propagation trees for each news article by utilizing user responses and user following relations. FANG [26] learns the representations of a heterogeneous social graph, consisting of users, news articles and sources. DECOR [36] links news article pairs based on co-user engagement knowledge. The social graphs constructed in these works utilize the entire information on social context, resulting in a single fixed structure for both training and testing. In other words, they are inherently designed to leverage future contextual data for model training leading to potential information leakage, which especially aggravates when the news articles are randomly split as well.\nIn this paper, we emphasize the importance of simulating real-world learning environments to enhance the applicability of fake news detection methods. Specifically, as information that appears during test time would not be available at training time under real-world scenarios, such temporality-aware settings should be properly deployed when evaluating model performance. To the best of our knowledge, we are the first to consider both article-wise (textual contents and veracity labels) and context-wise (social knowledge on users and tweets) temporality-aware settings for social graph-based fake news detection.\n2.2 Graph Structure Learning\nVarious downstream tasks on graphs have been shown to be successfully tackled by Graph Neural Networks (GNNs) [11, 18, 32]. However, the performance of such GNNs are vulnerable to the existence of noisy edges that connect dissimilar nodes [8], either through structural adversarial attacks or inherent noise within the data [4, 5, 14, 16, 33, 34, 38]. As such, many Graph Structure Learning (GSL) studies have aimed to downweight such noisy edges by optimizing the adjacency matrix. Guided by node feature similarity, prior studies have utilized various similarity metrics and link predictor training schemes to alleviate the effect of edge noise [4, 8, 13, 15, 35].\nA recent study, called DECOR [36], has attempted to apply GSL to fake news detection, and has shown that constructing edge-specific features representing social patterns is much more effective than previous node feature-based methods when training the link predictor to suppress noisy edges. Despite its effectiveness, the degree-related patterns utilized by DECOR are obtained from a single fixed social graph, i.e., the patterns are subject to substantial changes under real-world environments where the graph structure greatly differs before and after training time, hindering detection performance. Motivated by this, our work aims to exploit new features whose underlying patterns are independent of time and thus are more robust under temporality-aware settings."}, {"title": "3 PRELIMINARIES", "content": "3.1 Problem Statement\nDefinitions. Let $D = (P, U, R)$ be a fake news detection dataset. $P$ is a set of questionable news articles, where each news article $p_n \\in P$ contains the corresponding article text and the time of its publication $t_h$. $U$ is a set of active users on social media, where each user has had at least $m$ engagements (an engagement occurs when a user reposts a news article). $R$ is a set of such engagements, where each engagement $r_i \\in R$ is defined as $\\{(u, p, t_i)|u \\epsilon U, p \\epsilon P\\}$ (i.e., user $u$ has reposted news article $p$ at time $t$)."}, {"title": "Temporality-aware Fake News Detection", "content": "Given a news dataset $D = (P,U,R)$ and timestamps $t_{train}, t_{val}$ and $t_{test}$, our goal is to learn a fake news detector, i.e., binary classifier. Specifically, we first train the classifier on $(P_{train}, U_{train}, R_{train})$ and validate on $(P_{val}, U_{val}, R_{val})$. Then, given $(P_{test}, U_{test}, R_{test})$, the classifier would predict the veracity labels $Y_{test}$ for news articles in $P_{test}$."}, {"title": "3.2 Social Graph Construction", "content": "Following [36, 37], we construct a social graph that effectively captures the relationship between news articles through user engagements. Specifically, we first obtain an engagement matrix $E \\in \\mathbb{R}^{|U|\\times|P|}$, where each element $E_{ij}$ represents the number of times user $u_i$ has interacted with news article $p_j$, the value of which being the number of the associated engagements in $R$. Then, we construct a graph $G = (P, A)$, where a node denotes an article and an edge denotes the co-engagement patterns between a pair of articles. Specifically, the associated adjacency matrix $A \\in \\mathbb{R}^{|P|\\times|P|}$ is generated by retrieving co-engagement patterns from the engagement matrix, i.e., $A = E^TE$. Each element $A_{ij}$ represents the edge weight between a pair of news articles $p_i$ and $p_j$, where a weight of zero indicates no shared users between them (i.e., none of the users have reposted both articles). If there are multiple users who have reposted multiple responses on both articles, the weight would increase accordingly. In other words, the edge weights in $A$ denote the intensity of the co-engagement between article pairs.\nTo incorporate the realistic temporality-aware setting, we expand on the above procedure and construct three separate graphs for training, validation and testing. In detail, we obtain a training engagement matrix $E_{train} \\in \\mathbb{R}^{|U_{train}|\\times|P_{train}|}$ only utilizing $(P_{train}, U_{train}, R_{train})$. From this we construct a training graph $G_{train} = (P_{train}, A_{train})$, where $A_{train} \\in \\mathbb{R}^{|P_{train}|\\times|P_{train}|}$ is defined as $A_{train} = E_{train}^T E_{train}$. Similarly, we construct validation and test graphs $G_{val} = (P_{val}, A_{val})$ and $G_{test} = (P_{test}, A_{test})$ from $(P_{val}, U_{val}, R_{val})$ and $(P_{test}, U_{test}, R_{test})$, respectively."}, {"title": "4 DATA ANALYSIS: ENGAGEMENT EARLINESS\nAND VERACITY LABEL CONSISTENCY", "content": "In this section, we explore the relationship between engagement earliness and the veracity label consistency of news article pairs. Our analysis is performed on two prominent fake news datasets PolitiFact and GossipCop from the FakeNewsNet [30] benchmark.\nFollowing [37], we define a Fake News Affinity (FNA) score for each user $u \\in U$ (we set $m = 3$ for all analysis in this section) as:\n$FNA(u) = \\frac{\\text{# of engagements with fake news by u}}{\\text{# of all engagements by u}}$\nFig. 2 shows the distribution of users' FNA scores via histograms. The results indicate that users generally have FNA scores close to 1 (i.e., only engage with fake news) or 0 (i.e., only engage with real news), implying that users tend to consume and spread news articles of the same veracity. In other words, users engaging with news articles on social media would be attracted to similar articles regarding veracity, according to their highly polarized opinions [19, 23]. This is in line with the well-known confirmation bias theory [27] stating that people have a tendency to be drawn to information that affirms and reinforces their prior beliefs and preferences.\nBuilding upon this, we now investigate how the behaviors change in terms of engagement earliness. More precisely, as users with stronger opinions would generally act quicker when consuming and reposting news (i.e., engagements) that reflect their beliefs, we hypothesized that confirmation bias would exacerbate in users displaying earlier engagement patterns. In the following, we investigate earliness patterns in terms of each engagement in $R$ and user in $U$."}, {"title": "4.1 Engagement-wise Earliness Patterns", "content": "First, we defined a deadline $t_d$, where a certain engagement $r_i \\in R$ can be considered early if $t - t_h < t_d$, meaning the engagement occurred within a fixed timespan determined by the deadline after the corresponding news article has been posted. Engagements that occur after the deadline can be considered as late. We divided all engagements into two groups (early and late) according to the deadline (set to 30 minutes for PolitiFact and 5 minutes for GossipCop), then obtained the FNA scores separately within each group.\nThe difference in distributions are shown in Fig. 3, where the FNA scores associated with early engagements are much more skewed towards 0 or 1, compared to those associated with late engagements. In other words, we can observe that confirmation bias does indeed occur more intensely in users with \"earlier engagements.\""}, {"title": "4.2 User-wise Earliness Patterns", "content": "While our previous analysis assigned earliness categories in terms of each engagement, we also observed patterns when they are assigned in terms of each user. Specifically, we defined a User Earliness (UE) score for each user as:\n$UE(u) = \\frac{\\text{# of early engagements by u}}{\\text{# of all engagements by u}}$\nwhere early engagements are determined by the previously defined deadline. Users whose UE score exceeds a certain threshold $thres_u$ are classified as early users; those that don't are late users.\nThe distributions of the FNA scores of the two different user groups ($thres_u$ was set to 0.8 for both datasets) are shown in Fig. 4. We can once again observe that the skewness in the FNA scores increases among early users as opposed to that among late users. Such results indicate that engagements by \"earlier users\" are more likely to display patterns of confirmation bias."}, {"title": "4.3 Joint Earliness Patterns", "content": "Finally, we explore what happens when the previous viewpoints - both engagement-wise and user-wise - are taken into account simultaneously. Keeping $t_d$ and $thres_u$ the same as before, we divided all engagements into four groups: early users' early engagements (EE), early users' late engagements (EL), late users' early engagements (LE) and late users' late engagements (LL).\nThe distributions of the FNA scores are shown in Fig. 5, where we observe some interesting results. (1) While in our previous observation the late engagement group's FNA scores were less skewed (See Fig. 3), dividing the group further through user-wise earliness we can see that group EL is more skewed compared to group LL. (2) Similarly, dividing the late user group further through engagement-wise earliness, it can be seen that group LE is more skewed compared to group LL.\nImplications. Our extensive analyses on earliness-related patterns reveal that earlier user engagements have a stronger tendency to be linked with news articles of the same veracity, supporting our hypothesis. The major implication is that within the social graph constructed through the procedure detailed in Section 3.2, edges containing later engagements have a higher likelihood of connecting \"real news\"-\"fake news\u201d pairs than those containing earlier engagements. In other words, in the original $A$ where all engagements are treated equally when determining edge weight, such \"later\" edges are more likely to be noisy edges that hinder the performance of existing social graph-based fake news detection models."}, {"title": "5 PROPOSED METHOD: DAWN", "content": "Based on our findings regarding engagement earliness, we propose DAWN, a novel method for Detecting fake news via eArliness-guided reWeighting. Fig. 6 illustrates the overall framework of DAWN, consisting of three components. (1) We first construct edge-specific features for each existing edge in the social graph. Stemming from our insights in Section 4, we represent the joint earliness patterns within the edges as 4-dimensional vectors. (2) The features are then fed into an edge weight estimator $f$, which is a link predictor aiming to adjust the weights of existing edges. Further guided by a ranking loss, $f$ suppresses the weights of noisy edges as opposed to that of clean edges (noisy edges connect real news-fake news pairs, while clean edges connect real news-real news or fake news-fake news pairs), resulting in a reweighted adjacency matrix $W$. (3) Finally, a GNN classifier $g$ utilizes the newly obtained $W$ alongside node features extracted from the article texts to predict the veracity labels of the nodes."}, {"title": "5.1 Edge Feature Construction", "content": "Our empirical analysis indicates that earliness-related engagement patterns can help in determining the likelihood of a certain edge in the social graph being clean or noisy. Motivated by this, we construct earliness-related features specific to each edge, which can in turn successfully identify \"later\" edges. Our observations regarding the simultaneous consideration of both engagement-wise and user-wise earliness patterns suggest that focusing on either one on its own can lead to critical loss of information, e.g., ignoring the entire late user group will result in ignoring the LE group as well, despite them displaying more skewed patterns."}, {"title": "5.2 Noisy Edge Suppression Module", "content": "The normalized edge features are then fed into an MLP-based edge weight estimator $f$ to obtain adjusted edge weights. This process is formulated as:\n$W_{ij} = f(\\tilde{z}_{ij}) = sigmoid(MLP(\\tilde{z}_{ij})),$ where the MLP outputs a single value that is then activated through a sigmoid function, resulting in estimated edge weight $w_{ij} \\in [0, 1]$.\nOur objective is to enable $f$ to learn earliness-related patterns in $\\tilde{z}_{ij}$, allowing it to assign decreased weights to noisy edges and increased weights to clean edges within a fixed range. By replacing the edge weights of the original adjacency matrix $A$ with the estimated weights, we can obtain a reweighted adjacency matrix $W$.\nTo further guide $f$ in distinguishing noisy edges displaying later patterns from clean edges displaying earlier patterns, we additionally introduce a regularization term for the estimated edge weights. Specifically, as we have access to the ground-truth veracity labels of news articles in the training set, we can divide all edges within the training graph into clean edge or noisy edge groups. A straightforward way of utilizing this information would be through a binary classification loss [4], penalizing noisy and clean edge weights when they are far from 0 and 1, respectively. However, as the rate of earliness is different for each edge, we discover that ignoring this and strictly sending all weights to 0 or 1 hinders performance (refer to Section 6.3). As such, we impose constraints that guide reweighting in a less strict manner, by utilizing a ranking loss. Specifically, we randomly sample K edges from both clean and noisy edge groups, and then emphasize the difference within each clean edge-noisy edge pair via the following loss function:\n$\\mathcal{L}_{rank} = \\frac{1}{K^2} \\sum_{i=1}^{K} \\sum_{j=1}^{K} max(0, - (w_{clean}^{(i)} - w_{noisy}^{(j)}) + margin),$ where $w_{clean}^{(i)}$ and $w_{noisy}^{(j)}$ denote the estimated edge weight of the $i$-th and $j$-th sample from the clean edge and noisy edge group, respectively. By penalizing cases where clean edges have smaller weights than noisy edges, further enhanced by a preset margin value, we can give regularization to relatively reduce the influence of noisy edges. During training, $\\mathcal{L}_{rank}$ can guide the edge weight estimator $f$ to obtain a reweighted training adjacency matrix $W_{train}$.\nWhile comparing all possible pairs during training would be ideal, we empirically show that observing $K^2$ sampled pairs still achieves competitive performance in Section 6.4."}, {"title": "5.3 Fake News Detection Module", "content": "Following prior studies [7, 36], we extract the initial node feature $x_n$ of a news article $p_n \\in P$ from the article text via a pre-trained BERT [6]. Utilizing the node features and reweighted adjacency matrix $W$ obtained via edge weight estimator $f$, we can learn the representation of nodes through expressive GNN architectures [11, 18, 32]. Based on this learned representation, the veracity of article $p_n$ is predicted in the form of $\\hat{y}_n = softmax(h_n)$. $h_n \\in \\mathbb{R}^2$ is the output of the GNN classifier $g(X, W)$ for article $p_n$, where $X$ is the collection of all relevant node features in the form of a single matrix. During training, the inputs for $g$ are the node features corresponding to news articles in the training set and $W_{train}$, and the resulting GNN prediction loss is as follows:\n$\\mathcal{L}_{GNN} = \\sum_{p_n \\in P_{train}} l(\\hat{y}_n, y_n),$ where $l(\\hat{y}_n, y_n)$ denoting the cross entropy between $\\hat{y}_n$ and $y_n \\in Y_{train}$."}, {"title": "5.4 Final Training Objective", "content": "The final loss function for training is as follows:\n$\\mathcal{L}_{final} = \\underset{\\theta, \\phi}{arg \\, min} \\, \\mathcal{L}_{GNN} + \\alpha \\mathcal{L}_{rank},$ where $\\theta$ and $\\phi$ are the learnable parameters of GNN classifier $g$ and edge weight estimator $f$, respectively. $\\alpha$ is a hyperparameter for balancing the contribution of the ranking loss. DAWN follows an end-to-end approach in which $f$ and $g$ are learned simultaneously.\nAfter training on $G_{train}$, $f$ adjusts the weights of $A_{val}$, resulting in a reweighted $W_{val}$. The best performing model on the validation set is then used for final prediction on the test set. Similarly, we adjust the test adjacency matrix through $f$ to obtain $W_{test}$, which is then fed into $g$ alongside the node features. Through this procedure, DAWN effectively mitigates the effect of noisy edges and detects fake news using low-dimensional earliness-related edge features."}, {"title": "6 EXPERIMENTS", "content": "In this section, we conduct comprehensive experiments to answer the following research questions:\n\u2022 RQ1. How well does our proposed DAWN perform in detecting fake news compared with baselines?\n\u2022 RQ2. How effective are our constructed edge features and additional modules in enhancing DAWN's performance?\n\u2022 RQ3. How does DAWN perform under various hyperparameters?\n\u2022 RQ4. How efficient is DAWN on large-scale social networks?\n\u2022 RQ5. Does DAWN successfully downweight noisy edges?"}, {"title": "6.1 Experimental Setup", "content": "Datasets. We evaluate DAWN on two prominent fake news datasets, i.e., PolitiFact and GossipCop from the FakeNewsNet benchmark [30]. They contain news articles labeled as real or fake by leading fact-checking websites, along with related tweets by users on X (formerly known as Twitter). The statistics can be found in Table 1.\nUnder our temporality-aware evaluation scheme, $t_{train}$, $t_{val}$ and $t_{test}$ are set so that 70%, 10% and 20% of the news articles (in temporal order) are assigned to the training, validation and test sets, respectively. The social contexts regarding users and tweets are also split accordingly.\nBaselines. We compare DAWN with the following baselines, which can be further categorized by model architecture: content-based methods (G1) (dEFEND\\c [29], DualEmo\\c [39], BERT [6] and GPT3.5), social graph-based methods (G2) (GCNFN [25], UPFD [7], FANG [26], GCN [18], GAT [32] and GraphSAGE [11]) and Graph Structure Learning methods (G3) (RS-GNN [4] and DECOR [36])."}, {"title": "Evaluation Metrics", "content": "Following previous works [7, 36], we adopt accuracy (acc.) and F1 score (f1.) to evaluate performance. For all experiments, we report the average of 5 independent runs."}, {"title": "6.2 Detection Performance (RQ1)", "content": "Table 2 compares the performance of DAWN and baseline models, where the bold (underlined) values indicate the best (second best) results. We can observe that (1) social graph-based methods (G2) generally outperform content-based methods (G1), including LLMs. This highlights the importance of utilizing social contexts for fake news detection. (2) Within group G3, RS-GNN is shown to be less effective than DECOR. This indicates that GSL guided by node features is less suited for the fake news detection task as opposed to leveraging edge-specific features. (3) DAWN outperforms baseline models by a substantial margin, enhancing accuracy and F1 score by up to 5.6%p and 7.3%p over the most competitive baseline on the GossipCop dataset, respectively. This demonstrates that under the temporality-aware setting where accessible information and social structures change greatly before and after training, DAWN displays more robust detection performance despite its simpler methodology. As previously discussed, this is thanks to the proposed earliness-related patterns being based upon general social behaviors that occur similarly even at different points in time.\nAdditionally, we also investigate the performance of DAWN and existing social graph-based methods when evaluated under the conventional temporality-ignorant setting. In Fig. 1(b), we observe that DAWN significantly outperforms baselines and displays marginal performance difference between the two settings as opposed to previous methods that suffer substantial degradation. Such results further highlight the effectiveness of our time-independent features and demonstrate the versatility of our proposed method, as it displays superior performance under various scenarios."}, {"title": "6.3 Ablation Study (RQ2)", "content": "We conduct ablation studies to validate (1) the effectiveness of our earliness-related edge features proposed in Section 4.3, and (2) the model components of DAWN. Specifically, DAWN+RAND replaces our features with random values from the uniform distribution. DAWN-USER and DAWN-ENG remove user-wise and engagement-wise earliness patterns from the edge features, respectively. DAWN+RATIO constructs edge features in an alternate way, by retrieving the relative ratio of each group (EE, EL, LE and LL) size. DAWN+NF replaces our features with concatenated features of a node pair for each edge (i.e., concatenation of two 768-dimensional BERT embedding vectors). Meanwhile, DAWN-RANK removes $\\mathcal{L}_{rank}$ from the final loss function by setting $\\alpha = 0$, and DAWN+BC replaces $\\mathcal{L}_{rank}$ with a binary classification loss as mentioned in Section 5.2.\nThe results are summarized in Table 3. DAWN is shown to outperform all variants. In detail, DAWN+RATIO, DAWN+RAND and DAWN+NF display worse results when compared to DAWN, highlighting the effectiveness of our earliness-related edge features and supporting our observation in Section 6.2. Additionally, DAWN outperforms DAWN-USER and DAWN-ENG as well, which is in line with our analysis in Section 4.3 that jointly considering both user-wise and engagement-wise earliness patterns results in richer patterns than focusing on either one on its own.\nFurther, we observe that DAWN outperforms DAWN-RANK, proving the effectiveness of $\\mathcal{L}_{rank}$. In addition, DAWN+BC is inferior to DAWN-RANK, supporting our claim that strictly sending edge weights to 0 or 1 is unfit for our task and hinders performance."}, {"title": "6.4 Hyperparameter Sensitivity (RQ3)", "content": "In this section, we explore how the performance of DAWN is affected by varying the values of key hyperparameters, i.e., K, margin, $t_d$ and $thres_u$. \nWe observe that DAWN significantly outperforms DECOR under different variations of the sample size K and margin used in Equation 4. The detection performance shows an upward trend when increasing K, which is expected since more edge pairs are involved during training. It is important to note that sampling only 10 edges per group (i.e., K = 10) significantly reduces computation time yet still shows performance comparable to the cases with larger Ks, even surpassing DECOR, indicating the effectiveness of DAWN.\nIn terms of deadline $t_d$ and threshold $thres_u$, we have some interesting observations. In detail, the performance on GossipCop peaks at a much shorter deadline $t_d$ than on PolitiFact, i.e., engagements need to occur much quicker to be considered early in GossipCop. Similarly, the performance on GossipCop is subpar when the threshold $thres_u$ is set to lower values, while on PolitiFact a threshold value too large significantly hinders performance, meaning early users respond much more quickly to news in Gossipcop. Both results indicate that what is considered \"early\" varies depending on the dataset, where much stricter standards should be used for GossipCop over PolitiFact."}, {"title": "6.5 Efficiency on Large Networks (RQ4)", "content": "To assess the applicability of DAWN on real-world tasks with massive social networks, we evaluate its computational cost on GossipCop as it is a much larger dataset compared with PolitiFact. Specifically, we train GCN, DECOR and DAWN under identical settings, and report the mean runtime per epoch and resulting F1 score in Table 4. We observe that although DAWN requires relatively higher computational cost, which is expected due to the introduction of $\\mathcal{L}_{rank}$ in Equation 4, it achieves much quicker convergence, as shown in Fig. 8. In practice, DAWN's fast convergence is likely to offset the slightly higher computational cost per epoch, leading to an overall more efficient training process. Further, we point out that the performance of DAWN is significantly higher than that of GCN or DECOR. These results demonstrate DAWN's practical applicability in real-world fake news detection, as it substantially enhances performance while only modestly compromising efficiency."}, {"title": "6.6 Case Study (RQ5)", "content": "We conduct a case study to further illustrate how DAWN successfully distinguishes and reweights clean and noisy edges, especially compared to a similar reweighting framework DECOR [36"}]}