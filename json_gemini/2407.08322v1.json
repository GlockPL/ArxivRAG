{"title": "Intelligent Multi-Document Summarisation for Extracting Insights on Racial Inequalities from Maternity Incident Investigation Reports", "authors": ["Georgina Cosma", "Mohit Kumar", "Patrick Waterson", "Gyuchan Thomas Jun", "Jonathan Back"], "abstract": "In healthcare, thousands of safety incidents occur every year, but learning from these incidents is not effectively aggregated. Analysing incident reports using AI could uncover critical insights to prevent harm by identifying recurring patterns and contributing factors. To aggregate and extract valuable information, natural language processing (NLP) and machine learning techniques can be employed to summarise and mine un- structured data, potentially surfacing systemic issues and priority areas for improvement. This paper presents I-SIRch:CS, a framework designed to facilitate the aggregation and analysis of safety incident reports while ensuring traceability throughout the process. The framework integrates concept annotation using the Safety Intelligence Research (SIRch) taxon- omy with clustering, summarisation, and analysis capabilities. Utilising a dataset of 188 anonymised maternity investigation reports annotated with 27 SIRch human factors concepts, I-SIRch:CS groups the annotated sentences into clusters using sentence embeddings and k-means cluster- ing, maintaining traceability via file and sentence IDs. Summaries are generated for each cluster using offline state-of-the-art abstractive sum- marisation models (BART, DistilBART, T5), which are evaluated and compared using metrics assessing summary quality attributes. The gen- erated summaries are linked back to the original file and sentence IDs, ensuring traceability and allowing for verification of the summarised in- formation. Results demonstrate BART's strengths in creating informa- tive and concise summaries.", "sections": [{"title": "1 Introduction", "content": "In recent years, deep learning (DL) and natural language processing (NLP) mod- els have demonstrated immense potential for automatically analysing and sum- marising textual data across application areas. Within the healthcare domain,"}, {"title": "2 Related work", "content": "Models including Long Short-Term Memory (LSTM) networks and Transformer- based architectures have been at the forefront, leveraging their ability to under- stand context and sequence in texts. Specifically, the use of pretrained mod- els such as BERT (Bidirectional Encoder Representations from Transformers) and its adaptations in the medical domain (e.g., BioBERT, ClinicalBERT) have demonstrated promising results in improving the accuracy and relevance of sum- maries. For instance, LSTM and Transformer models have been applied to sum- marise patient Electronic Health Records (EHRs), extracting critical information that can aid in diagnosis, treatment planning, and patient monitoring. These summaries provide a comprehensive view of a patient's med- ical history, current condition, and potential risks, distilled into a format that is easily accessible to healthcare providers. The introduction of models such as BERT (Bidirectional Encoder Representations from Transformers) and"}, {"title": "3 I-SIRch:CS Framework", "content": "We propose an automated system for summarising text data, capable of cluster- ing sentences by similarity, determining the best number of clusters, and gen- erating concise summaries and keywords for each cluster. This process trans- forms raw text into structured, actionable insights. We utilised offline generative models to ensure patient confidentiality by anonymising and synthesising data, preserving the integrity of insights while safeguarding personal information. Algorithm (1) provides the text clustering and summarisation process. The algo- rithm takes as input a set of sentences, denoted mathematically as set $S$, along with an associated set of labels (a.k.a concepts) $L$ that categorises the sentences. It also requires two machine learning models a clustering model $M_c$ and a pre- trained summarisation model $M_s$. In the first stage, the algorithm groups the input sentences by their labels (i.e. concepts) in $L$. For each label $l \\in L$, it extracts the subset of sentences $S_l$ that have that label value $l$ assigned. Next, it applies the clustering model $M_c$ to embed the sentences in a vector space and determine an optimal number of clusters based on the elbow method. The sentences with the same label $l$ are then clustered into these topics, denoted by $\\{C_1, C_2,..., C_k\\}$. The second stage is a summary and evaluation loop over the clusters. For each cluster $C_i$ covering a topic, the sentences are concatenated into a single text excerpt $T_i$. This is passed into the summarisation model $M_s$ to generate a summary text $S_i$. Additional metadata including a heading $H_i$ and the sentence IDs used are also extracted for summary $S_i$. Evaluation metrics are then calculated for summary $S_i$ - including quantification of the diversity,"}, {"title": "4 Methodology", "content": "The Healthcare Services Safety Investigation Branch (HSSIB) provided a ran- dom set of 188 anonymised investigation reports describing adverse maternity incidents. The reports were written between 2019 to 2022. The number of reports for each year is as follows: 4 reports in 2019, 115 reports in 2020, 42 reports in 2021, and 27 reports in 2022. Ethnicity was provided for 76 reports."}, {"title": "4.2 Experiment methodology", "content": "The I-SIRch:CS framework is presented in Fig. 1 and its components are de- scribed as follows. Healthcare reports repository: The I-SIRch tool is used for loading, cleaning, and preparing reports. During processing, the tool gener- ates a text file in CSV format that includes File IDs, Sentence IDs, sentences, and concepts derived from the SIRch taxonomy. This phase involves cleaning the files by selecting particular sentences from each report, specifically targeting those with negative connotations, references to physical characteristics, and men- tions of medication names associated with dispensing. These selected sentences are annotated according to the SIRch taxonomy and aggregated into a CSV file for subsequent clustering and summarisation tasks. \nDynamic clustering: Employs the all-MiniLM-L6-v2 Sentence Transformer model for sentence embeddings and the elbow method with KMeans for cluster- ing. This process groups text data into semantically similar clusters, maintain- ing traceability via file and sentence IDs. Generative summarisation and heading generation: Selects from predefined offline models (e.g., BART, T5, DistilBART) for summarisation. Keywords extracted by KeyBERT for headings ensure summaries are informative and traceable to original file and sentence IDs. Analytics engine (Qualitative results): Outputs include the textual sum- maries and their corresponding topic headings, where each summary is linked to each file and sentence ID. Analytics engine (Quantitative results): Out- puts include a detailed CSV report with analysis on summarisation models, clustering, generated headings, summaries, and evaluation metrics, ensuring ex- plainability through file and sentence ID traceability. Batch processing and process automation: The framework's scalable design allows for automated batch processing, enhancing the system's ability to handle large datasets effi- ciently, with a focus on traceability and organisation."}, {"title": "4.3 Methods", "content": "We employed the following transformer-based architectures that have been fine- tuned for summarisation, and which have demonstrated their capability to ad- dress complex NLP challenges, particularly in healthcare. Sentence Trans- formers ('all-MiniLM-L6-v2'): A compact model that generates semantically meaningful sentence embeddings suitable for semantic search, clustering and summarisation, balancing performance with computational efficiency. BART"}, {"title": "4.4 Evaluation metrics", "content": "Several metrics have been used to assess different aspects of summarisation qual- ity, including diversity, relevance, coverage, coherence, conciseness, and read- ability. Each metric provides insights into how well the summarisation process captures and conveys the essential information from the original text. Higher values across these metrics indicate better summarisation model performance in producing summaries that are diverse, relevant, comprehensive, logical, concise and readable.\nDiversity measures the variety of vocabulary used in the summary. It is calcu- lated as the ratio of unique words to the total number of words in the summary.\n$\\text{Diversity} = \\frac{\\text{Number of Unique Words}}{\\text{Total Number of Words}} $ (1)\nRelevance assesses the similarity between the original text and its summary.\nCosine similarity between the vector representations of the original text and the"}, {"title": "5 Results", "content": "The IDs of sentences assigned to each cluster are tracked and used for generating the summary of that cluster. Hence, all sentences grouped into a specific cluster are considered in the summarisation process. However, the actual summary may not incorporate these sentences verbatim. Instead, the summary provides a con- densed version that captures the main points from these sentences. An analysis of the summaries is presented below."}, {"title": "5.1 Performance comparison of summarisation methods", "content": "Table 2 provides the results when comparing the summarisation models using the evaluation metrics defined in section 4.4. Fig. 2 provides an overview of the"}, {"title": "5.2 BART's summarisation performance across concepts", "content": "Fig. 3 depicts the performance of BART's summarisation model across each con- cept. The x-axes show the concept numbers, and these correspond to the IDs found in Table 1. Hence number 1 on the x-axis of Fig. 3(a) corresponds to the Acuity concept that has ID 1 in Table 1.\nThe areas of strength are: Relevance: Across all labels, the model consistently showed high relevance scores, with means above 0.9. This indicates that the model is adept at generating content that is closely related to the given topics. Low standard deviations in relevance scores, such as 0.012 for Acuity and 0.007 for Assessment, investigation, testing, screening, suggest that the model main- tains this relevance across different instances reliably. Coherence: The model also performed well in terms of coherence, particularly for labels such as COVID, with a mean of 0.836 and Acuity with a mean of 0.809. These scores suggest that the generated text logically flows from one sentence to the next, making it easier for readers to follow the narrative.\nThe areas for improvement are: Coverage: The model struggled with coverage across several labels, notably so for Assessment, investigation, testing, screening, with a mean of 0.03 and a very low standard deviation, indicating consistently narrow topic coverage. This suggests that the model may not fully address all rel- evant aspects of a topic, possibly omitting important details. Diversity: While"}, {"title": "5.3 Evaluating equity in summaries of investigation reports", "content": "Table 3 and Fig. 4 present a summary of various evaluation metrics across differ- ent ethnic groups: Asian, Black, Data not received (DNR), Mixed Background (MB), Other White (OW), and White British (WB) when using BART. Diversity: The diversity scores are relatively similar across all ethnicities, rang- ing from 0.64 to 0.69, with small standard deviations (0.04 to 0.08). This suggests that the BART model generates diverse outputs for all ethnicities. Relevance and Coverage: The relevance and coverage scores are identical for each ethnic- ity, indicating that these metrics are closely related. Asian, Black, DNR, MB, and OW have high scores (0.87 to 0.97) with small standard deviations (0.04 to 0.18), suggesting that the model generates relevant and comprehensive outputs for these ethnicities. However, WB has a lower score (0.40) with a larger standard deviation (0.22), indicating that the model's outputs for this ethnicity may be less relevant and comprehensive. Coherence: The coherence scores vary across ethnicities, with DNR and MB having the highest scores (0.65 and 0.63) and moderate standard deviations (0.26 and 0.18). Asian, Black, and OW have lower scores (0.42 to 0.54) with larger standard deviations (0.27 to 0.32), suggesting that the model's outputs for these ethnicities may be less coherent. WB has the lowest coherence score (0.18) with a small standard deviation (0.19), indicating that the model's outputs for this ethnicity are the least coherent. Conciseness: All ethnicities have the same conciseness score (0.01) with no standard deviation, suggesting that the model generates equally concise outputs for all ethnicities. Readability: The readability scores range from 16.08 to 21.54, with standard deviations ranging from 0.59 to 5.12. MB has the lowest readability score (16.08) with the smallest standard deviation (0.59), indicating that the model's outputs for this ethnicity are the most readable and consistent. Asian has the highest readability score (21.54) with the largest standard deviation (5.12), suggesting that the model's outputs for this ethnicity are the least readable and have the most variability. In summary, the BART model generates diverse, relevant, and concise outputs for most ethnicities, with some variations in coherence and read- ability. The model's performance appears to be the weakest for the WB ethnicity,"}, {"title": "6 Ethical risks of abstractive summarisation models", "content": "Risk of information hallucination and bias amplification: Abstrac- tive summarisation models like BART, T5, and DistilBART risk generat- ing content not found in the original data and amplifying biases from their training data. Mitigation: Diversifying training datasets, implementing de- biasing techniques, and cross-referencing with original texts. Regular bias audits and integrating ethical guidelines directly into the training process can enhance accuracy, transparency, and fairness.\nRisk of inadequate control over content: Unlike extractive methods, abstractive models generate summaries based on learnt patterns, which can result in misrepresentation or underrepresentation of certain groups or inci- dents. Mitigation: Developing more sophisticated models with embedded ethical and fairness constraints, and employing precise source mapping mech- anisms like sentence IDs, can strengthen control and ensure verifiability and trustworthiness of the content generated.\nRisk in processing sensitive data: Utilising online LLMs for sensitive data can pose risks of data breaches and privacy violations. Mitigation: Switching to offline LLMs lessens these risks but may reduce performance, as it depends on local computing resources. Organisations need to balance security against performance to find an appropriate balance.\nSample Size and Variability: Large datasets, whilst rich in information, present challenges due to variability and the potential inclusion of low-quality data. This complexity hinders a model's ability to learn consistent patterns, adversely affecting summarisation metrics. Mitigation: Explore robust data preprocessing techniques to enhance data quality. Utilising machine learn- ing algorithms customised for high variability will enhance consistency and equity in summarisation outcomes across diverse groups."}, {"title": "7 Conclusion", "content": "The I-SIRch:CS framework automates the analysis and summarisation of textual data in maternity incident reports, holding significant potential for uncovering critical insights and contributing factors to preventable harm. Future work will prioritise enhancing the framework's traceability capabilities by implementing mechanisms to provide clear links between generated summaries and original reports, allowing for easy verification of accuracy and context. Explainable AI techniques will also be explored to offer insights into how models generate sum- maries. A key limitation of the I-SIRch:CS framework is the lack of Patient and Public Involvement (PPI) in assessing its outputs. PPI is crucial as it ensures solutions are relevant to patient needs and experiences, potentially improving the framework's summaries and their real-world applicability. Engaging with patients and the public could also increase the model's transparency and trust- worthiness. Future development will aim to integrate PPI feedback, enhancing the framework's effectiveness and its contributions to patient safety and care quality."}]}