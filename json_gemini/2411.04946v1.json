{"title": "SPGD: Steepest Perturbed Gradient Descent Optimization", "authors": ["Amir M. Vahedi", "Horea T. Ilies"], "abstract": "Optimization algorithms are pivotal in advancing various scientific and industrial fields but often encounter obstacles such as trapping in local minima, saddle points, and plateaus (flat regions), which makes the convergence to reasonable or near-optimal solutions particularly challenging.\nThis paper presents the Steepest Perturbed Gradient Descent (SPGD), a novel algorithm that in-novatively combines the principles of the gradient descent method with periodic uniform perturbation sampling to effectively circumvent these impediments and lead to better solutions whenever possible. SPGD is distinctively designed to generate a set of candidate solutions and select the one exhibiting the steepest loss difference relative to the current solution. It enhances the traditional gradient descent approach by integrating a strategic exploration mechanism that significantly increases the likelihood of escaping sub-optimal local minima and navigating complex optimization landscapes effectively. Our approach not only retains the directed efficiency of gradient descent but also leverages the exploratory benefits of stochastic perturbations, thus enabling a more comprehensive search for global optima across diverse problem spaces. We demonstrate the efficacy of SPGD in solving the 3D component packing problem, an NP-hard challenge. Preliminary results show a substantial improvement over four established methods, particularly on response surfaces with complex topographies and in multidimensional non-convex continuous optimization problems. Comparative analyses with established 2D benchmark functions highlight SPGD's superior performance, showcasing its ability to navigate complex optimiza-tion landscapes. These results emphasize SPGD's potential as a versatile tool for a wide range of optimization problems.", "sections": [{"title": "Introduction", "content": "Mathematical optimization is a fundamental process in engineering, science, and economics. Its main objective is to find solutions that minimize a predefined objective, typically expressed in terms of a real-valued function, while adhering to given constraints. This pursuit of optimal solutions is crucial in solving complex problems, where achieving the best possible results necessitates a careful balance of numerous factors and variables.\nAmong the many optimization techniques available, the gradient descent (GD) method stands out as a foundational and extensively used tool, and its origins can be traced back to Cauchy's pioneering work [1]. However, despite its widespread use, the gradient descent method has certain limitations. One of its major drawbacks is its tendency to get trapped in sub-optimal states, including saddle points and local minima, which may offer minimal improvement in solution quality. Additionally, the method may encounter difficulties in making progress towards the desired outcome when faced with flat regions in the problem space.\nTo address these challenges, extensive research efforts have been focused on enhancing the performance of the gradient descent method. As a result, numerous variants have been developed, each specifically designed to overcome the aforementioned pitfalls [2]. One notable variant is the Perturbed Gradient Descent (PGD), which has gained attention for its ability to navigate away from saddle points and potentially converge towards second-order optimal points [3]."}, {"title": "Related Work", "content": "Simulated annealing (SA) [4] and genetic algorithm [5] are heuristic optimization algorithms that use randomness and selection mechanisms inspired by natural processes to explore the solution space and select the best candidates for further iteration. These algorithms can be used for different types of optimization problems such as continuous, discrete, non-convex, and multi-objective problems [6, 7]. These methods may require significant computational resources and careful tuning of parameters (e.g., temperature in simulated annealing or mutation rate in evolutionary algorithms) to balance exploration and exploitation effectively.\nThe gradient descent (GD) method is a first-order optimization algorithm that updates the design variables in the direction opposite to the gradient of the objective function with respect to those variables [2]. It's widely used due to its simplicity and efficiency in convex problems. The gradient descent method converges to a local optimal solution with a mathematical guarantee. Gradient descent tends to exploit local information to improve the solution iteratively. However, it may not explore the search space effectively, potentially getting trapped in local minima or saddle points, particularly in non-convex optimization landscapes. It struggles with flat areas where the gradient is close to zero, leading to slow or no progress [3].\nNesterov's Accelerated Gradient (NAG) method enhances traditional gradient descent by incorpo-rating a forward-looking step. This tweak allows the optimizer to anticipate future gradients, reducing oscillations and speeding up convergence, particularly in convex settings. NAG is highly effective in train-ing deep neural networks due to its efficiency in navigating high-dimensional data spaces. However, its performance can vary in non-convex environments with complex landscapes [8, 9].\nIn the exploration of hybrid optimization methods, a notable approach combines the exploratory strengths of Simulated Annealing (SA) with the precise, local search capabilities of Gradient Descent (GD). This method strategically employs SA to break free from local optima by conducting a thorough"}, {"title": "SPGD", "content": "Traditional gradient descent algorithms efficiently exploit local gradient information to improve solutions iteratively. To minimize a given function $f : R^n \\rightarrow R$, the updating rule at each iteration is [3]:\n$X_{i+1} = X_i - \\alpha \\nabla f(x_i)$\nwhere i is the number of current iteration, and $\\alpha > 0$ is the step size, and $\\nabla f$ is the gradient of f. However, in non-convex high-dimensional problems, the gradient descent method can become trapped in local minima or saddle points, missing out on globally optimal configurations. To address this limitation, we propose a novel algorithm that combines gradient descent with periodic randomized perturbations. These perturbations are particularly effective in non-convex, high-dimensional problems, where even small modifications can significantly alter the solution's position within the search space. This sensitivity to per-turbations is crucial in navigating the complex terrain of such problems, where the landscape of potential solutions is riddled with local optima. By introducing strategically randomized perturbations, our algo-rithm enhances its ability to escape these local optima, thereby facilitating a more extensive exploration of the solution space. This periodic application of perturbations is key to avoiding the oscillatory behavior often observed in optimization trajectories of sampling-based methods, which can lead to inefficiencies and slow convergence. This approach proves particularly advantageous in complex optimization scenarios characterized by challenges such as flatness, ruggedness, or saddle points of the objective surface, where conventional optimization algorithms might falter in making meaningful progress. These perturbations"}, {"title": "Numerical Results", "content": "We present here a thorough evaluation of the proposed Steepest Perturbed Gradient Descent (SPGD) algorithm, comparing its performance against several established optimization methods. The comparison includes traditional gradient descent (GD), Perturbed Gradient Descent (PGD), MATLAB fmincon function which is a versatile solver for constrained optimization problems [16], and Simulated Annealing (SA) [17].\nOur initial analysis is conducted through the lens of four challenging 2D benchmark functions, se-lected for their known difficulties and relevance in assessing optimization algorithms' efficacy. These test functions are recognized benchmarks within the optimization community, providing a diverse set of land-scapes to evaluate each algorithm's ability to navigate complex, non-convex, and potentially deceptive optimization spaces [18]. For each test function, we apply fmincon, Simulated Annealing, traditional gradient descent, PGD, and SPGD, meticulously recording and analyzing the results. In both the SPGD and PGD algorithms, the amplitude of the perturbation is set to be the same, ensuring comparability, Iterp is set to 5, and Np is set to 10. Furthermore, the gradient function is explicitly passed to the fmincon function in each scenario to guide the optimization process.\nKey performance indicators include the accuracy of the solution, measured by the proximity to the known global optimum[19]; the computational efficiency, quantified by the number of function evaluations and CPU execution time. The SPGD algorithm's source code, along with comparative analyses against the discussed methods using additional 2D challenging test functions, is publicly accessible on GitHub 3.\nTest function 1\nThe MATLAB Peaks function [20] presents a formidable challenge for optimization algorithms due to its intricate landscape, which features one global minimum, multiple local minima, a saddle point, and extensive flat regions. This complexity makes the Peaks function a critical benchmark for assessing the capabilities of optimization techniques, particularly those based on gradient descent. Traditional gradient descent methods often struggle with such landscapes, as they can easily become trapped in local minima or stall in flat areas, failing to make significant progress towards the global optimum [21]. The mathematical expression defining the Peak test function is given as follows:\n$f(x,y) = 3e^{-\\left(y+1\\right)^2-x^2} \\left(x - 1\\right)^2+\\frac{e^{-\\left(x+1\\right)^2-y^2}}{3} + e^{-x^2-y^2} \\left(10 x^3 - 2x + 10 y^5\\right)$\nIt has a global minimum point located at x = 0.2283, y = -1.6256 with an optimal function value of f(x*) = -6.5511. The initial condition is chosen randomly to be (-2.81, -1.47), and the Amp is set to 2.5."}, {"title": "Test function 2", "content": "The Ackley function is a well-known non-convex optimization benchmark that poses a significant chal-lenge to optimization algorithms, particularly due to its deceptive landscape characterized by a global optimum surrounded by a multitude of local minima [22]. This function is specifically designed to test the ability of optimization methods to escape local minima and efficiently search for the global optimum in a complex, multidimensional space. The Ackley function's landscape features a large number of local minima leading towards the global minimum, making it an exemplary test case for evaluating the ro-bustness and effectiveness of algorithms against the risk of premature convergence. The global minimum of the Ackley function is located at the origin (x = 0, y = 0), with an optimal function value of zero (f(x*) = 0), which further serves as a clear target for optimization efforts. The formula representing the Ackley test function is articulated below:\n$f(x,y) = -20 \\exp\\left(-0.2\\sqrt{\\frac{1}{2}\\left(x^2+y^2\\right)}\\right) - \\exp \\left(\\frac{1}{2}\\left(\\cos(2\\pi x) + \\cos(2\\pi y)\\right)\\right) + 20 + e$\nThe initial condition is chosen randomly to be (-3.75, -1.96), and the Amp is set to 2.5."}, {"title": "Test function 3", "content": "The Easom function stands as a notable unimodal steep ridge [18] test function within the realm of optimization, particularly distinguished by its singular global optimum that resides in an extensive flat area. This flat region is characterized by minimal gradient variations, presenting a unique challenge for optimization algorithms, especially those reliant on gradient information to navigate the search space. The function is defined over a domain of (-100, 100) for both x and y dimensions, emphasizing the necessity for optimization techniques to efficiently explore large search areas to locate the optimum [23]. The significance of the Easom function as a test scenario with simple mathematical formulation lies in its ability to simulate real-world optimization problems where the solution space is largely homogeneous, yet contains a singular, critical point of interest. This function tests the exploration strategies of algorithms, challenging them to avoid the pitfalls of vast non-informative regions. It emphasizes the importance of balance between exploration and exploitation, as effective optimization methods must not only navigate vast spaces efficiently but also recognize and converge to the global optimum with high precision. Mathematically, the Easom function's global optimum is uniquely situated at (x = \u03c0, y = \u03c0), where it attains a value of f(x*) = \u22121. The formula of the Easom test function is provided below:\n$f(x, y) = - \\cos(x) \\cos(y) \\exp \\left(- ((x - \\pi)^2 + (y - \\pi)^2)\\right)$\nThe initial condition is chosen randomly to be (69.33, 12.23), and the Amp is set to 5."}, {"title": "Test function 4", "content": "The Levy Function No. 13, characterized by its multimodality and non-convexity, presents a unique challenge for optimization algorithms with its single global optimum amidst a noisy, periodic distribution of local minima. This function tests an algorithm's precision in distinguishing the global optimum from numerous suboptimal states, a key trait for solving complex real-world problems. It serves as a critical benchmark for evaluating the balance between exploration and exploitation in optimization techniques, underscoring its significance in both theoretical and practical applications. The global optimum of this function is strategically located at (x = 1, y = 1), where it attains a value of f(x*) = 0. The expression for the Levy Function No. 13 is detailed below [24]:\n$f(x, y) = \\sin^2(3\\pi x) + (x - 1)^2 \\left(1 + \\sin^2(3\\pi y)\\right) + (y - 1)^2 \\left(1 + \\sin^2(2\\pi y)\\right)$\nThe initial condition is chosen randomly to be (-3.75, -1.96), and the Amp is set to 2.5."}, {"title": "3D Component Packing Problem", "content": "In the 3D component packing problem, we focus on arranging 3D objects with arbitrary shapes as com-pactly as possible without collision, akin to a simplified version of the interconnected systems with physical interactions (SPI2) problem but without considering the routing interconnections between objects [33]. Optimization methods often face challenges in this landscape, such as getting trapped in local minima or stalling in flat areas, thus failing to advance significantly towards the global optimum. The non-convex nature of the objective function, characterized by multiple local optima and saddle points, poses sub-stantial challenges to any standard optimization technique. Nonetheless, our SPGD algorithm, which integrates randomized perturbations, is tailored to navigate these complex landscapes more effectively, demonstrating its adaptability and enhanced performance compared to conventional techniques.\nOur 3D packing scenarios presented here are specialized instances of those tackled by SPI2-F a novel and more general packing and layout optimization presented in [34], that performs both packing and layout optimization of complex interconnected systems in a multi-physics environment. The specialized scenarios presented below have been chosen to include cases that have known global optima. We note that an efficient packing method based on Fast Fourier Transforms was introduced recently in [38], which restricts the orientation of the objects to an axis-alignment and hence allows rotations in 90-degree increments. By contrast, our method allows arbitrary rotations and alignments in space.\nIn the 3D component packing problem, our primary objectives are twofold: minimize the volume of the bounding box containing the components (V) while avoiding collisions between the components. Therefore, we define the mathematical expression of the objective function as follows:\n$f = w_b \\times V_1 - w_c \\times \\log(e + min(dist))$\nwhere $w_b = 20$ represents the weight associated with the bounding box volume, $w_c =1e-4$ is the weight related to collision avoidance, $e =1e-5$ is a small value to avoid singularity, and $min(dist)$ denotes the minimum distance between the spheres of different components.\nThe complexity and high dimensionality of this problem are underscored by the fact that each object in our example consists of $num_{sphere} = 100$ spheres, and each component is controlled by six variables three for displacement and three for orientation. The problem also incorporates constraints related to collision avoidance. To effectively navigate the highly non-convex and constrained space of the component packing problem, our approach involves tailored adaptations to the perturbation mechanism used in the Steepest Perturbed Gradient Descent (SPGD) algorithm. Perturbations are applied separately to the components' displacement and orientation, ensuring a thorough optimization of both aspects of component placement.\nIn the early iterations, we enhance the exploration and facilitate the escape from suboptimal solutions by accepting solutions with worse volume outcomes by a prescribed factor. This acceptance factor de-creases in a linear profile over the iterations until it reaches 1.0, at which point the algorithm only accepts new solutions that have the same or lower volume, thus refining the search towards the most compact configurations. Additionally, the amplitude of the perturbations for both displacement and orientation is controlled through a lower-bounded linear profile, which ensures that perturbations decrease in mag-nitude as the optimization process progresses, aligning more closely with the finer adjustments needed"}, {"title": "Initial Configuration and Setup", "content": "Before delving into the comparative results, it is essential to note that both the SPGD and GD algorithms were initiated from the same configuration in each scenario to ensure a fair comparison. The initial setup involved distributing the objects well within the 3D space, providing sufficient free space around each object to avoid immediate collisions. Furthermore, the orientations of the objects were randomly chosen, introducing additional complexity and ensuring that the problem remained challenging for the optimizers. This initialization strategy was crucial for testing the algorithms' abilities to effectively explore and optimize from a non-advantageous starting point."}, {"title": "Experimental Scenarios and Results", "content": "The following scenarios were considered for the comparison:\n\u2022 Scenario 1: Four identical cubes, where the global optimum is known, and cubes are packed together with the same orientation.\n\u2022 Scenario 2: Eight identical cubes, testing the scalability and spatial reasoning of the algorithms.\n\u2022 Scenario 3: Eight cubes of varying sizes, introducing a non-uniform configuration without a known global optimum, to evaluate heuristic capabilities.\n\u2022 Scenario 4: Eight objects of different complex shapes (gears, hooks, rivets, etc.), representing an industrial challenge with an unknown optimal packing configuration."}, {"title": "Analysis of Scenario 1: Four Identical Cubes", "content": "In Scenario 1, the initial configuration of the four identical cubes is depicted in Figure 15. This setup was designed to test each algorithm's ability to navigate a relatively simple scenario where the global optimum involves aligning all cubes in a compact configuration. The results of the final configurations found by the GD and SPGD algorithms are illustrated in Figure 16, showing both Gradient Descent and Steepest Perturbed Gradient Descent results side by side.\nThe outcomes depicted in the figures reveal that, due to the collision constraint, GD struggled to converge to the global solution and settled in a suboptimal local minimum. In contrast, SPGD success-fully converged to the global optimal configuration, effectively avoiding local minima and fulfilling the collision constraints more efficiently. To further illustrate the performance dynamics over the course of the optimization, the loss convergence history for both algorithms is plotted in Figure 17. This figure shows loss values as a function of elapsed time and the number of iterations.\nAlthough SPGD achieved the optimal configuration more rapidly in terms of the number of iterations, it required more computational time overall compared to GD. These plots (Figures 17) help demonstrate that while SPGD's iterations are more effective at progressing toward the global optimum, they are computationally more intensive, likely due to the complexity of the perturbation calculations and the more sophisticated collision checks involved.\nThis scenario underscores SPGD's strengths in effectively navigating optimization landscapes with collision constraints and its ability to reach global optima where traditional GD may fail. However, the increased computational demand highlights an area for further optimization and efficiency improvements in SPGD's implementation."}, {"title": "Analysis of Scenario 2: Eight Identical Cubes", "content": "In Scenario 2, the initial configuration of eight identical cubes is depicted in Figure 18. This scenario was designed to assess each algorithm's ability to scale and manage increased numbers of objects while maintaining an efficient packing configuration. The outcomes of the final configurations found by the GD and SPGD algorithms are illustrated in Figures 19a and 19b, respectively.\nDuring the optimization process, the GD algorithm encountered significant issues and ceased further packing adjustments due to a collision between the yellow and red cubes, effectively stopping the opti-mization prematurely. In contrast, the SPGD algorithm managed to navigate around this problem and did not converge to the global optimal solution but found a notably more compact suboptimal solution, approximately three times more space-efficient than the configuration found by GD.\nTo further illustrate the performance dynamics over the course of the optimization, the loss convergence history for both algorithms is plotted in Figure 20, showing loss values as a function of elapsed time and the number of iterations.\nAlthough SPGD did not achieve the global optimum, it provided a significant improvement over GD by finding a much more compact solution rapidly. This scenario demonstrates SPGD's superior capability in effectively navigating complex landscapes and managing collision constraints dynamically compared to GD. The increased performance in finding a substantially better solution highlights the potential of"}, {"title": "Analysis of Scenario 3: Eight Cubes of Different Sizes", "content": "In Scenario 3, which introduces a higher level of complexity due to the use of eight cubes of different sizes, the initial configuration is shown in Figure 21. This setup challenges the algorithms' ability to efficiently manage and optimize space in a more heterogeneous environment.\nThe SPGD algorithm's performance in this scenario was notably superior, as it converged to a more compact solution significantly faster than the traditional GD method. The results of the final configura-tions found by the GD and SPGD algorithms are shown in Figures 22a and 22b, respectively.\nDespite the lack of a known global optimal solution due to the varying sizes and potential configu-rations, SPGD effectively utilized its perturbation mechanism to explore and optimize the packing ar-rangement. This scenario highlights the algorithm's adaptability and efficiency in handling diverse object dimensions, which is crucial for real-world applications.\nTo further evaluate the performance dynamics, the loss convergence history for both algorithms is plotted in Figure 23, showing loss values as a function of elapsed time, and the number of iterations."}, {"title": "Analysis of Scenario 4: Eight Objects of Different Shapes", "content": "Scenario 4, the most complex of the scenarios tested, involved packing eight objects of different, irregular shapes such as gears, hooks, and rivets. The initial configuration is illustrated in Figure 24, which presents a diverse and challenging packing environment.\nIn this demanding scenario, the SPGD algorithm demonstrated its robust capability by converging to a significantly more compact solution compared to the traditional GD method. Although the time taken by SPGD to find the optimal solution was comparable to that of GD, the overall optimization process required more time due to the termination condition set for no improvement in the loss value over 2000 iterations. The final configurations achieved by the GD and SPGD algorithms are shown in Figure 25a and 25b, reflecting the SPGD algorithm's effectiveness in handling complex and varied object forms."}, {"title": "Conclusion", "content": "The SPGD algorithm presents a novel integration of deterministic optimization with strategic stochastic perturbations, designed to overcome the limitations of traditional gradient descent methods in non-convex landscapes and plateaus. Through comparative analyses, SPGD has demonstrated potential advantages in complex non-convex optimization challenges, highlighting its utility across various optimization scenarios. Looking ahead, SPGD shows promise for broader applications in diverse domains and enhancements in machine learning methodologies:\n\u2022 Expanding Application Domains: Future investigations could explore SPGD's application to fields like engineering design optimization [39], logistics, energy management, bioinformatics, and fuzzy logic parameter tuning optimization [40], showcasing its versatility and robustness.\n\u2022 Enhancements in Machine Learning: There is potential for SPGD to significantly enhance neural network training, especially within deep learning frameworks by improving convergence rates and navigating complex parameter spaces.\n\u2022 Integration with Machine Learning Frameworks: SPGD has already been implemented using the PyTorch framework for the 3D component packing problem, demonstrating its adaptability to complex optimization tasks. Future work could extend this integration to machine learning projects, particularly in training neural networks, thereby potentially broadening its user base and enhancing its utility in diverse applications.\n\u2022 Adaptive Perturbation Strategies: Developing adaptive perturbation techniques that respond to specific characteristics of the optimization landscape could further refine SPGD's effectiveness, making it more problem-specific.\n\u2022 Extension to Complex Systems: Exploring the 3D Component Packing Problem within the SPI2 framework could pave the way for handling interconnected systems with physical interactions, where topology and collision constraints add layers of complexity.\nThese future directions not only aim to broaden the utility of SPGD but also open new avenues for innovative research in the field of optimization."}]}