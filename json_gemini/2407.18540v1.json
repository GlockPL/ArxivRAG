{"title": "A Universal Prompting Strategy for Extracting\nProcess Model Information from Natural\nLanguage Text using Large Language Models", "authors": ["Julian Neuberger", "Lars Ackermann", "Han van der Aa", "Stefan Jablonski"], "abstract": "Over the past decade, extensive research efforts have been\ndedicated to the extraction of information from textual process descrip-\ntions. Despite the remarkable progress witnessed in natural language\nprocessing (NLP), information extraction within the Business Process\nManagement domain remains predominantly reliant on rule-based sys-\ntems and machine learning methodologies. Data scarcity has so far pre-\nvented the successful application of deep learning techniques. However,\nthe rapid progress in generative large language models (LLMs) makes it\npossible to solve many NLP tasks with very high quality without the need\nfor extensive data. Therefore, we systematically investigate the potential\nof LLMs for extracting information from textual process descriptions,\ntargeting the detection of process elements such as activities and actors,\nand relations between them. Using a heuristic algorithm, we demonstrate\nthe suitability of the extracted information for process model generation.\nBased on a novel prompting strategy, we show that LLMs are able to\noutperform state-of-the-art machine learning approaches with absolute\nperformance improvements of up to 8% F1 score across three different\ndatasets. We evaluate our prompting strategy on eight different LLMs,\nshowing it is universally applicable, while also analyzing the impact of\ncertain prompt parts on extraction quality. The number of example texts,\nthe specificity of definitions, and the rigour of format instructions are\nidentified as key for improving the accuracy of extracted information.\nOur code, prompts, and data are publicly available.", "sections": [{"title": "1 Introduction", "content": "In the field of Business Process Management (BPM), process models are estab-\nlished tools for designing, implementing, enacting, and analyzing enterprise pro-"}, {"title": "2 Task Descriptions and Challenges", "content": "In this section, we describe the three main (sub)tasks of process information\nextraction (Section 2.1), before highlighting a range of challenges associated\nwith such extraction and with the use of LLMs for it (Sections 2.2-2.3)."}, {"title": "2.1 Task descriptions", "content": "Our work focuses on three established subtasks of (process) information extrac-\ntion from text: Mention Detection (MD), Entity Resolution (ER), and Relation\nExtraction (RE) [2, 7, 23, 26].\nMention Detection (MD) is concerned with finding and extracting text frag-\nments that contain process relevant information, such as activities (or actions),\nprocess-relevant objects or data (i.e., business objects), or involved persons and\ndepartments (i.e., actors). For instance, in Figure 1, the upper example shows\nmentions of data, actions, and actor, whereas the lower one focuses on activities.\nThis definition is similar to Named Entity Recognition (NER), though we also\nextract spans not covered by the traditional definition of NER, e.g., activities.\nEntity Resolution (ER) aims to recognize when different mentions refer to\nthe same process entity. For example, in Figure 1, successful ER would identify\nthat the word it in \"it is examined\" corresponds to the claim mentioned in\nthe previous phrase. Another common example is using ER to recognize that\nthe same actor (across mentions) performs different steps. ER is a super-set of\nco-reference resolution and anaphora resolution [29] and is a crucial step when\ndealing with process-related texts, which frequently involve repeated mentions\nacross sentences or even paragraphs [23].\nRelation Extraction (RE) is the task of detecting and classifying relations\nbetween mentions. Relations are usually directed and have one (unary relation),\nor two (binary relations) arguments. For instance, the upper example in Figure 1\nshows three kinds of relations: uses signals which data objects are used by an ac-\ntivity, performer captures which actor performed an activity, and flow captures\na sequential relation between two activities. RE is crucial when it comes to infor-\nmation extraction in our context, given that processes inherently involve process\nsteps (i.e., activities) that are connected to each other through relations. Note\nthat we regard constraint extraction [2, 26] (CE), which relates to declarative\nprocess modeling, as an RE problem: constraints have one or two arguments,\nare directed, and carry type information (e.g., Succession, Init)."}, {"title": "2.2 Challenges of Process Information Extraction from Text", "content": "Information extraction, a common task in natural language processing (NLP),\nfaces general challenges, which are also well-known in BPM literature [1,15], and\noften central elements of interest in the design of rule-based and learning-based\nsystems alike [2,23]. Simply using LLMs for process information extraction solves\nsome of these challenges and justifies the investigation of their applicability.\nIn the context of process-related texts Linguistic Variance means that the\nsame behavior or process characteristics can be described in a variety of ways\nsuch as, for instance, active and passive voice. Context Cues are a challenge in\nthat single words can fundamentally alter the meaning of a process description\n(e.g., \u201cfirst, a claim is created\u201d and inverted semantics in \u201cfinally, a claim is cre-\nated\". Processes are typically described in sequential form, although they usually\ncontain branches (e.g. XOR decision branches). This results in Long-distance"}, {"title": "2.3 Challenges of Process Information Extraction Using LLMs", "content": "Using LLMs for process information extraction from texts helps with linguistic\nchallenges, but adds itself several additional challenges. We discuss these here\nand reference them later in Section 6.3 to show how we can deal with them.\n(C1) Limited output control. Input and output consist of plain text.\nGiven that the input for inference is raw text, it inherently suits LLMs for our\ntasks (cf. Section 2.1). However, as the expected output should adhere to a\nspecific schema, it becomes necessary to instruct the LLM to conform to this\nschema. Moreover, this principle necessitates a robust output parser, as LLMs\ntend to exhibit variability in their output, which presently cannot be entirely\neradicated. Having only limited control over generated output is especially prob-\nlematic for the BPM domain, where definitions for relevant information often\noverlap, e.g., actions (just predicate) versus activities (predicate and object).\n(C2) Input presentation dependencies. Although LLMs provide an in-\nterface for natural language input, the quantity, form and level of detail must be\ncarefully matched to the task at hand. The LLM faces the challenge of determin-"}]}