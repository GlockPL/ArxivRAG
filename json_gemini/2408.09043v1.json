{"title": "Improving VTE Identification through Language Models from Radiology Reports: A Comparative Study of Mamba, Phi-3 Mini, and BERT", "authors": ["Jamie Deng", "Yusen Wu", "Yelena Yesha", "Phuong Nguyen"], "abstract": "Venous thromboembolism (VTE) is a critical cardio- vascular condition, encompassing deep vein thrombosis (DVT) and pulmonary embolism (PE). Accurate and timely identi- fication of VTE is essential for effective medical care. This study builds upon our previous work, which addressed VTE detection using deep learning methods for DVT and a hybrid approach combining deep learning and rule-based classification for PE. Our earlier approaches, while effective, had two major limitations: they were complex and required expert involvement for feature engineering of the rule set. To overcome these challenges, we utilize the Mamba architecture-based classifier. This model achieves remarkable results, with a 97% accuracy and F1 score on the DVT dataset and a 98% accuracy and F1 score on the PE dataset. In contrast to the previous hybrid method on PE identification, the Mamba classifier eliminates the need for hand-engineered rules, significantly reducing model complexity while maintaining comparable performance. Additionally, we evaluated a lightweight Large Language Model (LLM), Phi-3 Mini, in detecting VTE. While this model delivers competitive results, outperforming the baseline BERT models, it proves to be computationally intensive due to its larger parameter set. Our evaluation shows that the Mamba-based model demonstrates su- perior performance and efficiency in VTE identification, offering an effective solution to the limitations of previous approaches.", "sections": [{"title": "I. INTRODUCTION", "content": "Venous thromboembolism (VTE) [1], encompassing deep vein thrombosis (DVT) and pulmonary embolism (PE), is the third most common cardiovascular condition globally [2]. DVT is characterized by the formation of a blood clot within a deep vein, commonly affecting the lower extremities, while PE occurs when a clot detaches and travels to the lungs through the bloodstream. VTE significantly complicates surgical pro- cedures and leads to longer hospital stays and higher mortality rates if undetected [3]. The risk of VTE can increase up to 20- fold after surgery [4]. Therefore, the prompt identification of VTE is crucial for medical decision-making, and the adoption of automated methods for diagnosing VTE could significantly enhance healthcare practices.\nThe wide adoption of electronic health record systems (EHRs) across US hospitals offers a significant opportunity to utilize advanced data analytics for the classification of postoperative VTE. Clinical notes and reports contain vital de- tails about postoperative complications [5]. To extract valuable information from these unstructured and free-text documents, Natural Language Processing (NLP) employs computational linguistics to analyze the textual data. The use of NLP has been increasingly common in the analysis of radiologist reports from medical imaging [6]. Given that the diagnosis of VTE heavily relies on imaging findings, the application of NLP can help in automatically identifying patients with VTE through radiology reports.\nIn our previous study [7] of VTE identification by fine- tuning deep learning models, we developed a system that employs ClinicalBERT [8] and Bi-LSTM [9] to identify DVT, and integrates these deep learning models with a rule- based classifier (hybrid model) to detect PE from unstruc- tured free-text radiology reports. Our results demonstrate the system's effectiveness, achieving high accuracy and F1 scores. However, the work is still facing some challenges. The system is complex with multiple components. The PE rule set requires manual feature engineering by clinical experts, which restricts its generalization ability when applied to other medical domains. Furthermore, the input sequence length of BERT models is limited to 512 tokens, posing challenges when applying the model to longer textual data. Any medical reports exceeding this length are truncated, potentially losing important contextual information.\nTo tackle these challenges, we aim to:\nReduce Components for Efficiency: This involves simpli- fying the classifier's architecture to reduce computational complexity and enhance processing speed.\nExpand the Context Window of the Model: Enhancing the model's capacity to consider a broader range of contextual information can significantly improve its per- formance and accuracy in understanding complex patterns and relationships within the data.\nEliminate Rule Sets for Generalization: By removing rigid rule-based classifier, the model can adapt more flexibly to various scenarios, improving its ability to generalize across different contexts and data types."}, {"title": "II. PROPOSED METHODS", "content": "We propose to utilize the Mamba [11] architecture based classifier to do text classification on the VTE datasets of radiology reports. The Transformer architecture has played a crucial role in the success of Language Models and has widely applied in many different NLP tasks, powering nearly all widely used models today, such as LLM and BERT. To push the boundaries of Language Models, researchers are exploring new architectures that could surpass the Transformer. One promising approach is Mamba architecture."}, {"title": "A. SSM Fundamentals", "content": "Mamba is a State Space Model (SSM) architecture that demonstrates promising performance on information-rich tasks like language modeling, where earlier sub-quadratic models have struggled to match the effectiveness of Transformers. It builds on advancements in structured state space models and features a hardware-optimized design and implementation, in- spired by the efficiency of Flash Attention [17]. Mamba offers a more efficient approach for long sequences with its linear complexity and simplified architecture, making it a promising alternative for tasks requiring long-term dependencies such as textual data.\nA SSM is a mathematical representation of a system using a set of input, output, and state variables. The state variables define the values of the output variables and evolve over time based on their current values and the input variables. A SSM is defined by these two equations. It maps a 1-D input signal x(t) to an N-D latent state h(t) before projecting to a 1-D output signal y(t).\n$h'(t) = Ah(t) + Bx(t)$\t State equation\n$y(t) = Ch(t) + Dx(t)$\t Output equation\nSSM is used as a black-box representation in a deep sequence model, where A, B, C, D are parameters learned through gradient descent. They are in matrix format. Parameter D is usually omitted since it's similar to a skip connection. A SSM maps a input x(t) to a state representation vector h(t) and an output y(t). Assume the input and output are one-dimensional, and the state representation is multi-dimensional. The state equation describes how h(t) changes over time. The output equation defines how the state is translated to the output. By solving these equations, we can predict the state of a system based on observed data: input sequence and previous state.\nFor language modelling, we need to use the discrete version of SSM and recurrent representation. SSM can also be repre- sented as convolution therefore increasing training efficiency. The parameter A captures information about the previous state to build the new state. In order for matrix A to retains long history of states, HiPPO [18] technique is used to address long range dependencies. It works by transforming input data into a higher-dimensional space using polynomial functions to capture complex relationships, which are then fed into neural networks for improved learning efficiency.\nMamba introduces two more innovations: Selective Scan Al- gorithm, which enables the model to focus on pertinent data by filtering out the irrelevant. Hardware-Aware Algorithm, which Enhances efficiency by streamlining storage and processing via parallel operations, kernel fusion, and recomputation. These innovations lead to the Selective SSMs (S6 models), which are utilized in Mamba blocks much like self-attention mechanisms in Transformers."}, {"title": "B. Classification Model", "content": "Mamba architecture is particularly well-suited for handling long sequences of text, making it an ideal choice for the classification tasks of medical reports. For the backbone to the classifier, we chose the Mamba-130M model, which is the smallest version of Mamba with 130 million parameters. This is a significant reduction in size compared to our earlier research using ClinicalBERT and Bi-LSTM models. For in- stance, a standard BERT model has 110 million parameters, while a Bi-LSTM could have many more, depending on the input size and hidden layer dimensions. We add a linear layer to serve as the classification head, which allows the model to output predicted labels.\nThe Mamba block is a key component of the Mamba architecture, featuring linear projections that prepare the input sequence for further processing and a convolutional mode for efficient parallel training. At its core is the Selective SSM, which updates the sequence's state representation and focuses on key parts of the input. The SiLU (Sigmoid Linear Unit) activation introduces non-linearity after the convolution and SSM processing. The SSM output is combined with a gated projection output through multiplication, integrating different input aspects. Finally, the combined result undergoes a projection and adds a skip connection. The Mamba-130M model comprises 24 layers. Each block or layer processes the input sequentially, with the output of one block serving as the input for the next. We fine-tune the entire model, including the pre-trained Mamba backbone and the added linear layer, on the radiology report datasets. This process allows the model to adapt to the specific characteristics of the datasets and learn to classify the text effectively.\nTo explore the ability of Large Language Model (LLM) in the text classification tasks. We select one of the small LLMs for the NLP tasks. The Phi-3 Mini [14], with its 3.8 billion parameters, is lightweight, state-of-the-art open source model that can capture complex relationships and patterns in text data. By fine-tuning the Phi-3 Mini using the QLoRA [19] method, we can adapt the model to our specific tasks. QLORA (Quantized Low-Rank Adaptation) fine-tuning is a technique used particularly in the realm of LLM, to make the fine-tuning process more efficient and less resource-intensive. It enables the model to learn from a limited amount of labeled data, making it a practical choice for our research. To evaluate the effectiveness of the Mamba classifier, we compare it against two Transformer-based BERT models, DistilBERT [15] and DeBERTa [16], as baselines for the classification tasks."}, {"title": "III. EXPERIMENT RESULTS", "content": null}, {"title": "A. VTE Datasets", "content": "We use the same two datasets from our previous work [7], which contain medical imaging reports for VTE classification (DVT and PE). These datasets comprise de-identified and la- beled medical reports. They were sourced from the University of Maryland Medical Center (UMD). The de-identification and labeling of datasets were done by medical experts from UMD.\nThe first dataset includes 1,000 free-text duplex ultrasound imaging reports. The reports were classified into 3 categories by a Radiologist: Class 0 - No acute DVT, Class 1 - Upper extremity acute DVT, and Class 2 - Lower extremity acute DVT. A total of 78% of data samples fall into the category of class 0, and 11% for class 1 and 2 respectively. The dataset consists primarily of structured reports containing concise texts, with the majority of them being less than 170 words in length.\nThe second dataset includes 900 free-text chest computed tomography (CT) angiography scan reports. It has fewer samples than the first dataset and is more imbalanced. The reports were classified into 2 categories: class 0 No PE (88%), class 1 PE (12%). These CT scan reports contain mostly unstructured texts and are longer in length. Most of them are around 200 words. Some reports exceed 600 words."}, {"title": "B. Experimental Settings", "content": "To assess the effectiveness of the Mamba classifier, we con- ducted two series of experiments. The first series employed the DVT dataset, composed of shorter, well-structured text from Ultrasound reports. In this series, we tested the Mamba-based classifier proposed in this study alongside several baseline classifiers. The second series of experiments focused on the PE dataset, which contains longer, more complex text from CT scan reports. This dataset is both limited in size and imbalanced.\nWe divided the datasets into 80% training and 20% test sets. The training sets were further split into 90% training and 10% validation sets. The input texts are truncated to match the input limits of the different classifiers. The DVT dataset consists of shorter texts, which are well within the input limit of all classifiers. However, the PE dataset contains longer texts that exceed the sequence length limit of BERT models. For BERT models, the maximum input sequence length is 512 tokens. In contrast, the Mamba model allows a maximum input length of 8,000 tokens, having been pre-trained on sequences of 2,000 tokens. As a result, the Mamba classifier can handle longer text sequences than BERT models."}, {"title": "C. Model Performance", "content": "We compare the proposed method with two baseline Trans- former based BERT model as well as a small LLM.\nThe baseline Transformer based classifiers include:\nDistilBERT [15]: A smaller pretrained general-purpose language representation model. It is a compact, effi- cient, and cost-effective Transformer based model, trained through the distillation of BERT base. It has 40% fewer parameters than google-bert/bert-base-uncased, runs 60% faster, and retains over 97% of BERT's performance.\nDeBERTa [16]: It enhances the BERT and ROBERTa models by incorporating disentangled attention and an improved mask decoder. These advancements enable De- BERTa to outperform RoBERTa on most NLU tasks using 80GB of training data. Efficiency is further boosted through ELECTRA-style pre-training with Gradient Dis- entangled Embedding Sharing, leading to significant im- provements in performance on downstream tasks.\nPhi-3 Mini 128k [14]: It's a 3.8 billion-parameter, state- of-the-art, lightweight open model trained on the Phi-3 datasets. This dataset comprises both synthetic data and filtered publicly available website data, with a focus on high-quality, reasoning-intensive content. The model is part of the Phi-3 family, with the Mini version available in two variants, 4K and 128K, representing the context length (in tokens) it can handle.\nThe DistilBERT model has 66 million parameters, while the DeBERTa base model has 134 million parameters, comparable to the Mamba-130M model's size. In contrast, the Phi-3 Mini model is significantly larger, designed to handle more complex NLP tasks such as chat-based instructions, beyond just text classification, requiring a more extensive parameter set. The Phi-3 Mini model features a context window of 128K tokens, enabling it to manage long sequence texts effectively.\nWe perform experiments with aforementioned classifiers and compare the results to those from our previous work, which involved ClinicalBERT and Bi-LSTM model, and a rule-based classifier.\nThe classifiers in the experiment yield comparable results with high accuracy and F1 scores, indicating their effectiveness on the DVT dataset. The dataset, consisting of straightforward and concise medical texts, allows even the smallest DistilBERT model with fewer parameters to achieve results comparable to larger models. During the train- ing phase, the Mamba classifier exhibits signs of overfitting on the training dataset, leading to a slight reduction in sensitivity to 0.92 in the resulting trained model. However, for all other metrics, the Mamba classifier delivers performance on par with the other models. The ClinicalBERT and Bi-LSTM models from our previous research demonstrate the highest sensitivity score but exhibit a slightly lower specificity score.\nIn Table II, the outcomes of different classifiers on the PE dataset are displayed. Due to the complexity and length of the medical reports in the PE dataset, the BERT models encounter difficulties during training. The input limit of BERT models is 512 tokens, which restricts their ability to process longer texts, leading to truncation during preprocessing. In contrast, the Phi-3 Mini and Mamba models have significantly longer sequence lengths, enabling them to handle the PE reports more effectively than the BERT models. Consequently, language models with extended sequence lengths yield better results in terms of accuracy and F1. The Mamba model demonstrates comparable performance to the hybrid model (combining deep learning and rule-based approaches) from our previous research and exhibits higher sensitivity and specificity.\nThe Mamba model significantly outperforms the two Transformer-based models, primarily due to its longer sequence length, which preserves the context of the entire medical reports. In contrast, the DistilBERT model, with its smallest parameter size, performs the worst."}, {"title": "IV. RELATED WORK", "content": "Conventional NLP systems for text classification relied on either rule-based methods, which required significant manual effort from domain experts for feature selection, or statistical machine learning approaches, which demanded large amounts of training data. Deep learning (DL) has shown promising results in various studies. Many medical text classification tasks have taken advantage of Deep Learning approaches. However, few works have employed DL methods for clas- sifying VTE from medical report datasets, likely due to the limited availability of data. To the best of our knowledge, no previous work has focused on using Mamba models for VTE identification."}, {"title": "A. Traditional approaches", "content": "Nelson et al. [2] integrated statistical machine learning with rule-based NLP methods to detect postoperative VTE in surgical patients at VA hospitals. However, their NLP system was ineffective in accurately identifying postoperative VTE events from clinical notes. Sabra et al. [20] introduced a method called Semantic Extraction and Sentiment Assessment of Risk Factors, which generated feature inputs for a support vector machine classifier aimed at VTE identification. Due to the limited dataset of clinical narratives from electronic health records (EHR), their model achieved an F1 score of only 0.7.\nShi et al. [5] created an NLP system that tokenized patient reports into sentences, identified relevant concepts, and aggre- gated these semantic representations back to the document and patient level for VTE classification. This approach resulted in an AUC of 0.9 for PE and an AUC of 0.92 for DVT. Verma et al. [21] utilized an NLP algorithm based on weighted regular expression rules to classify radiologist reports of medical images for VTE, with the rules being manually selected by domain experts. Their methods achieved a PPV of 0.90 and an AUC of 0.96 for DVT identification, while for PE, the results were a PPV of 0.89 and an AUC of 0.96."}, {"title": "B. Deep Learning and Hybrid methods", "content": "Mulyar et al. [22] investigated various architectures for phe- notyping, utilizing BERT representations of free-text clinical notes. Similarly, Olthof et al. [23] found that deep learning- based BERT models outperformed traditional machine learn- ing and rule-based approaches in the classification of radiology reports. Goodrum et al. [24] extracted text from EHRs and assessed multiple text classification models, including bag-of- words and other machine learning methods. Their findings indicated that a deep learning model using ClinicalBERT yielded the best performance, confirming the effectiveness of deep learning methods in identifying clinically relevant content. Lee et al. [25] demonstrated that RNN-based networks were capable of classifying significant findings in radiology reports with high F1 scores.\nIn a hybrid study focused on VTE risk factor identification from electronic medical records, Chen et al. [26] employed BERT for word embedding and Bi-LSTM for information extraction, followed by rule-based reasoning to assess PE risk. The experimental results showed that this approach achieved F1 scores of 93.3% for entity recognition and 94.3% for relation extraction. In our previous work [7], we introduced a deep learning approach for identifying DVT from radiology re- ports using ClinicalBERT and Bi-LSTM models. Additionally, we proposed a hybrid method combining these deep learning models with a rule-based classifier to detect PE from medical reports. This approach significantly enhanced the accuracy and robustness of PE identification, especially in dealing with imbalanced datasets, resulting in high F1 scores."}, {"title": "C. Mamba language models", "content": "Grazzi et al. [27] utilized Mamba models for both simple function estimation and natural language processing tasks that involve learning from context. Their findings demonstrated that the Mamba models' performance matches that of Trans- former networks in these applications. Yang et al. [28] leverage the linear computational efficiency of Mamba models to handle long sequences of clinical notes, reaching up to 16K tokens. They pre-trained the model on the MIMIC-III [29] dataset, and evaluating its capabilities in cohort selection and ICD coding tasks. The results highlighted that the Clinical Mamba model outperforms both the standard Mamba and the clinical Llama models, particularly when dealing with longer sequences of clinical text. Lu et al. [30] explore the application of SSM in the classification of long texts, tackling the efficiency issues associated with the Transformer architecture. They showed that their SSM approach matches the performance of attention based models while being approximately 36% more efficient. Furthermore, their method proved to be robust against noisy inputs, even under severe conditions. Song et al. [12] demon- strated that Mamba based model outperformed BERT models in long text classification tasks while also achieving higher efficiency."}, {"title": "V. FUTURE WORKS", "content": "In order to address the challenges of efficiently deploy- ing Language Models in clinical environments, while our current study highlights Mamba's effectiveness in classifying VTE, the practical application of such models in real-world healthcare settings requires further refinement. One key area of focus should be the optimization of these models for deployment across various clinical settings, including both resource-constrained edge devices and cloud-based systems used in hospital settings.\nTo achieve this, future research could explore techniques such as model pruning and quantization. These methods can significantly reduce the model's size and computational demands, making it more suitable for deployment on de- vices with limited resources. For example, pruning could help remove non-essential components of the model, while quantization reduces memory usage by lowering the precision of the model's weights. By applying these methods, a model like Mamba, which originally requires 520 MB of memory with 32-bit precision, could see its memory footprint reduced to 130 MB through the use of 8-bit quantization. This would represent a 75% reduction in memory usage, making it far more efficient and practical for deployment in a wide range of clinical settings.\nAnother important area for future research is knowledge distillation, where a smaller model is trained to replicate the outputs of a larger, more complex model. This process allows for the creation of lightweight models that maintain high performance while being less resource-intensive. Such models are especially suitable for real-time clinical applications, where computational efficiency is crucial."}, {"title": "VI. CONCLUSION", "content": "In this study, we employ the Mamba architecture-based classifier to effectively identify VTE based on free-text clin- ical reports from medical imaging. Additionally, we evaluate the performance of one lightweight LLMs (Phi-3 Mini) in classifying VTE, which also delivers comparable results. This research builds upon our previous work, which utilized a hybrid approach involving deep learning (ClinicalBERT and Bi-LSTM models) and a rule-based classifier to identify PE from medical reports. While the hybrid method is effective in terms of performance, it had a complex architecture that involves multiple components. Particularly, the rule-based classifier requires careful manual feature selection by domain experts, which limits its generalization ability when applying the method to other medical domains. In contrast, the new Mamba architecture offers an efficient and effective approach to both training and inference on complex and lengthy texts.\nThe Mamba model achieved impressive results, with 97% accuracy and F1 score on the DVT dataset and 98% accuracy and F1 score on the PE dataset. It delivers comparable results to the hybrid method while eliminating the need for hand-engineered rules, thereby reducing the model's complexity. The Phi-3 Mini classifier also outperforms the two BERT models. However, this LLM has a significantly larger number of parameters, making it computationally intensive. For clas- sification tasks involving long texts, LLM is not an efficient method. The experimental findings support the effectiveness of Mamba-based models for VTE identification."}]}