{"title": "SDA-GRIN for Adaptive Spatial-Temporal Multivariate Time Series Imputation", "authors": ["Amir Eskandari", "Aman Anand", "Drishti Sharma", "Farhana Zulkernine"], "abstract": "In various applications, the multivariate time series often suffers from missing data. This issue can significantly disrupt systems that rely on the data. Spatial and temporal dependencies can be leveraged to impute the missing samples. Existing imputation methods often ignore dynamic changes in spatial dependencies. We propose a Spatial Dynamic Aware Graph Recurrent Imputation Network (SDA-GRIN) which is capable of capturing dynamic changes in spatial dependencies. SDA-GRIN leverages a multi-head attention mechanism to adapt graph structures with time. SDA-GRIN models multivariate time series as a sequence of temporal graphs and uses a recurrent message-passing architecture for imputation. We evaluate SDA-GRIN on four real-world datasets: SDA-GRIN improves MSE by 9.51% for the AQI and 9.40% for AQI-36. On the PEMS-BAY dataset, it achieves a 1.94% improvement in MSE. Detailed ablation study demonstrates the effect of window sizes and missing data on the performance of the method.", "sections": [{"title": "I. INTRODUCTION", "content": "Multivariate Time Series (MTS) data finds extensive appli-cations in diverse domains, from healthcare [1] and geoscience [2] to astronomy [3], and neuroscience [4]. MTS often exhibits numerous missing samples due to various factors, which can lead to deficiencies in systems that rely on this data. Various interconnected devices in Internet of Things (IoT) generate data continuously, typically in the form of MTS, with each sensor representing a variable. These sensors, due to their deployment in the same environment, often exhibit dependencies that can be used to enhance imputation methods.\nEstablished methods for MTS imputation use both spatial and temporal dependencies for imputation [5] [6] [7]. These methods often make assumptions about the Spatial Depen-dencies (SD), that can be wrong due to the complex nature of MTS. These assumptions limit methods from effectively capturing information among variables leading to reduced accuracy. Incorrect assumptions result from (i) overlooking the dynamic nature of SD among variables and using a static graph to represent SD [7]; (ii) employing similarity measurement functions that are not appropriate for the type of the data, e.g., using linear metrics for variables with non-linear relationships; (iii) depending on geo-proximity information, that can be misleading, instead of relying on data-driven measurements [8], e.g., two closely located sensors might capture data on entirely different traffic types.\nTo overcome these problems, we propose SDA-GRIN (Spatial Dynamic Aware Graph Recurrent Imputation Net-works). SDA-GRIN uses Multi-Head Attention (MHA) with a Message-Passing Recurrent Neural Network (MPRNN) [7] to effectively process and extract spatial and temporal de-pendencies for MTS imputation. The MHA attends to each variable and generates attention weights matrices, which are used to adapt the static adjacency matrix with time. Next, the feature processing part uses a GRU-based architecture [9] where instead of a simple MLP, an MPNN is employed. We evaluate SDA-GRIN on four datasets: AQI and AQI-36 [8] [10] from air quality domain, PEMS-BAY [11] and METR-LA [11] from traffic data domain. Our method outperforms previous state-of-the-arts [7] [10] on all datasets. In summary, our contributions are: (1) We introduce SDA-GRIN, a spatial-temporal framework that enhances MTS imputation by cap-turing dynamic SD changes. (2) We demonstrate significant performance improvements on benchmark datasets. (3) Our ablation study offers insights into the impact of missing data rate and window size."}, {"title": "II. RELATED WORK", "content": "MTS imputation has been widely studied in the liter-ature. Traditional methods, like k-nearest neighbors [12], expectation-maximization [13], support vector machines [14], matrix factorization, and matrix completion [15] [16] tech-niques have been explored for this problem. State-space meth-ods [17] [18] focus on preserving the original structure of the data while filling in gaps. In recent years, deep learning tech-niques such as Generative Adversarial Networks (GANs) [19] and Recurrent Neural Networks (RNNs) [20] [10] have been used for MTS imputation. BRITS [10] used a bidirectional recurrent-based architecture.\nGraph-Based Methods: Recent advances in MTS impu-tation and forecasting have leveraged GNNs [21] [22] [23] [24] [25] [26] [27] [28]. Cini et al. [7] proposed GRIN,"}, {"title": "III. SDA-GRIN: OVERVIEW", "content": "We propose the Spatial Dynamic Aware Graph Recurrent Imputation Network (SDA-GRIN) for Multi-Variate Time Se-ries Imputation (MTSI) built on top of GRIN [7]. SDA-GRIN models MTS as a sequence of temporal graphs, where each time step t is represented by a weighted directed graph $G_t$ with N nodes. Each graph $G_t = <X_t, A_t>$ consists of a node-attribute matrix $X_t \\in \\mathbb{R}^{N \\times T}$ and a weighted adjacency matrix $A_t \\in \\mathbb{R}^{N \\times N}$. $X_t$ contains T (window size) samples and N variables, i.e., $x_{t,i} = [X_{(t-T+1),i},..., X_{t,i}] \\in \\mathbb{R}^T$, where $i \\in \\{1,..., N\\}$. SDA-GRIN processes $X_t$ and $A_t$ to extract relationships both within and across variables, utilizing a Message-Passing Neural Network (MPNN) with a recurrent processing mechanism.\nTime order acts as a signal for a variable to extract and learn the temporal patterns. There is no explicit indicator that helps to understand the relationships among variables. Thus, we make assumptions and use graphs to represent the relationships among variables. These relationships can change over time and violate the assumptions. SDA-GRIN applies an adaptive mechanism to consider the changes in relationships using a Multi-Head Attention (MHA)-based module, as discussed in section III-A. We follow the GRIN [7] framework for the Sptial-Temporal (ST) feature extraction, processing, and impu-tation. Equations (2) and (4) encode the spatial and ST features respectively using the GRU-based architecture by relying on the message-passing layers instead of MLPs. Equations (1) and (3) perform the first and second imputation stages respectively. Equations (5) is used in bidirectional settings.\n$\\hat{Y}_t^{(1)} = \\Phi(X_t^{(1)}), X_t^{(1)} = H_{t-1} V_h + b_h$ (1)\n$S_t = MPNN(X_t^{(1)}, M_t, H_{t-1}, A_t)$ (2)\n$\\hat{Y}_t^{(2)} = \\Phi(X_t^{(2)}), X_t^{(2)} = [S_t || H_{t-1}] V_s + b_s$ (3)\n$H_t = MPGRU(X_t^{(2)}, M_t, H_{t-1}, A_t)$ (4)\n$\\hat{H}^t = MLP([S_t^{fwd} || H_{t-1}^{fwd} || S_{t+1}^{bwd} || H_{t+1}^{bwd}])$ (5)\nIn (1) and (3), $\\Phi$ is the filtering operator, $\\Phi(\\hat{Y}_t) = M_t \\odot X_t + M_t \\odot \\hat{Y}_t$. In the above equations, $M_t \\in \\mathbb{R}^{N \\times T}$ represents the binary masking matrix, with 0 for missing and 1 for available samples. $V_h, b_h, V_s$, and $b_s$ are learnable parameters. $X_t^{(2)}$ and $\\hat{Y}_t$ are the final results in the unidirectional, and the bidirectional settings, respectively. We use the bidirectional setting in SDA-GRIN. We train the model with mean absolute error (MAE) between the ground truth and imputed samples, calculating the loss across various imputation stages and directions (forward and backward)."}, {"title": "A. Spatial Dependency Awareness", "content": "We use MHA across variables over data samples within a fixed time window, $X_t \\in \\mathbb{R}^{N \\times T}$ which has missing samples as zero, indicated by $M_t \\in \\mathbb{R}^{N \\times T}$. MHA extracts dynamic relationships among variables. For each variable, we can rewrite it as $x_{t,i} \\in \\mathbb{R}^{T}$ where $i \\in \\{1, 2, . . ., N\\}$. We calculate the attention weights between each pair of variables. First, we generate the query and key matrices as follows:\n$Q^l = XW_Q^l, K^l = XW_K^l$ (6)\nwhere $W_Q^l \\in \\mathbb{R}^{T \\times d}$ and $W_K^l \\in \\mathbb{R}^{T \\times d}$ are learnable matrices for the query and key, respectively, where $l$ denotes a head index. Next, we compute the attention weights:\n$\\hat{A}_t^{(l)} = softmax(\\frac{Q^l (K^l)^T}{\\sqrt{d}})$ (7)\nwhere $\\hat{A}_t^{(l)} \\in \\mathbb{R}^{N \\times N}$ is the attention weights matrix for $l$-th head. In a multi-head setting, we have different $\\hat{A}_t^{(l)}$ for each head. We apply average pooling over the results of different heads.\n$A_t^{pooled} = \\frac{1}{L} \\sum_{l=1}^{L} \\hat{A}_t^{(l)}$ (8)\nL is the number of attention heads. MHA results in a dense matrix, making the graph fully connected, which can cause is-sues [7]. In GNN layers, a sparse adjacency matrix is preferred. We use the static adjacency matrix in the datasets to make $A_t^{pooled}$ sparse, $A_t = A_t^{pooled} \\odot (A > 0)$. $\\odot$ denotes the element-wise multiplication and $A \\in \\mathbb{R}^{N \\times N}$ is the static adjacency matrix which we calculate following previous methods [10] [8] [31] [11]."}, {"title": "IV. EXPERIMENTAL DESIGN", "content": "We use four datasets from Air Quality (AQ) and Traffic domains. The AQI dataset includes variables from 437 moni-toring stations across 43 cities in China, representing different air quality indices. We use only the PM2.5 pollutant. Hourly measurements were collected from May 1, 2014, to April 30, 2015. The AQI-36 dataset is a smaller version of the AQI dataset, containing only 36 sensors. We use the location information to generate the static adjacency matrix. We follow the same preprocessing, and evaluation settings from previous works [10] [8]."}, {"title": "C. Results and Discussion", "content": "Tables I, and II show the performance of all the methods. We perform the training and testing for SDA-GRIN five times and report the mean and standard deviations and include the results of baselines from [7]. For the AQ datasets, as shown in Table I, SDA-GRIN demonstrates significant improvement. For AQI-36, our method achieves a 0.25% improvement in MAE and a 9.40% improvement in MSE. For AQI, SDA-GRIN improves MAE by 2.04%, MSE by 9.51%, and MRE by 1.05%. For the PEMS-BAY dataset our method achieves improvements of 1.49%, 1.94%, and 0.93%, on MAE, MSE, and MRE respectively compared to the best model in the literature [7]. Based on our observations, we believe that these improvements are mainly due to awareness of SD changes gained through MHA. Furthermore, SDA-GRIN's effectiveness across diverse datasets from multiple domains highlights its generalizability."}, {"title": "Ablation Study.", "content": "The two key parameters in the experiments that affect the method's performance are window size (see Table III) and missing data rate (see Fig. 3). The window size determines the number of samples of variables that the MHA can attend to at each step. We experiment with four different window sizes: T = {32,64,128, 254}. As shown in Table III, For PEMS-BAY, METR-LA, and AQI, the largest window size performs the best. We attribute this to the fact that a larger context length allows MHA to better understand the dynamics.\nHowever, this is not the case for the AQI-36 dataset, where the smallest window size shows the best performance. We believe that this observation is due to the dataset's low number of variables (36) compared to greater than 200 variables in the other datasets. For the missing rate, we experimented SDA-GRIN with missing rate values ranging from 10% to 90% with PEMS-BAY and METR-LA datasets. Fig. 3 shows that SDA-GRIN's performance declines as the missing rate increases. This decline occurs because, at higher missing rates, most samples of variables are filled with zeros (representing missing values), making it difficult for the MHA mechanism to detect changes and adapt the graph structure effectively."}, {"title": "V. CONCLUSION", "content": "In this paper, we propose SDA-GRIN, to enhance spatial-temporal feature extraction to understand changes of spatial dependencies among multiple variables in time series data for missing value imputation. Using static spatial dependencies is not enough when relations change over time. We use a multi-head attention-based mechanism to adapt to changes in spatial dimension. The empirical results demonstrate that SDA-GRIN achieves significant improvement over previous baselines on datasets from traffic and air quality domains. We achieved 2.04% MAE and 9.51% MSE improvements on AQI, and 0.25% MAE and 9.40% MSE improvement on AQI-36, and a 1.49% MAE and 1.94% MSE improvement on PEMS-BAY. SDA-GRIN particularly is more effective when the relationships among variables in the data have high variance over time. Our ablation study also demonstrates that greater window size can capture more context for adaptation mechanisms for datasets having a comparable number of variables. Also, it indicates that the adaptation mechanism is sensitive to high levels of missing data, as the MHA struggles to capture changes when only a few samples are available within a given window."}]}