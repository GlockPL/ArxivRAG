{"title": "A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios", "authors": ["Christian Ganh\u00f6r", "Marta Moscati", "Anna Hausberger", "Shah Nawaz", "Markus Schedl"], "abstract": "Most recommender systems adopt collaborative filtering (CF) and provide recommendations based on past collective interactions. Therefore, the performance of CF algorithms degrades when few or no interactions are available, a scenario referred to as cold-start. To address this issue, previous work relies on models leveraging both collaborative data and side information on the users or items. Similar to multimodal learning, these models aim at combining collaborative and content representations in a shared embedding space. In this work we propose a novel technique for multimodal recommendation, relying on a multimodal Single-Branch embedding network for Recommendation (SiBraR). Leveraging weight-sharing, SiBraR encodes interaction data as well as multimodal side information using the same single-branch embedding network on different modalities. This makes SiBraR effective in scenarios of missing modality, including cold start. Our extensive experiments on large-scale recommendation datasets from three different recommendation domains (music, movie, and e-commerce) and providing multimodal content information (audio, text, image, labels, and interactions) show that SiBraR significantly outperforms CF as well as state-of-the-art content-based RSs in cold-start scenarios, and is competitive in warm scenarios. We show that SiBraR's recommendations are accurate in missing modality scenarios, and that the model is able to map different modalities to the same region of the shared embedding space, hence reducing the modality gap.", "sections": [{"title": "1 Introduction", "content": "Recommender systems (RSs) offer powerful solutions for navigating the vast amounts of multimedia content available today, helping users find new and interesting items. Modern RSs can handle diverse media types such as text, audio, image, and video, both as their output, i. e., items to recommend, and as modalities the items in the catalog are composed of. While the vast majority of RSs still build upon collaborative filtering (CF) techniques, research advancements in multimedia content analysis and neural learning-to-rank models have enabled the development of effective content-based RSS [10] (CBRSs). Since CF techniques solely rely on past collective interaction data, these algorithms often struggle to provide accurate recommendations when users or items do not appear in the past interactions, a scenario referred to as cold start. On the other hand, pure CBRSs are often effective for cold start, but relying solely on content information might limit the performance of such algorithms in warm scenarios. Therefore, the most effective way to provide accurate recommendations both in warm and cold-start scenarios is to simultaneously leverage collaborative data and side information on items and users. The resulting hybrid architectures\u00b9 therefore naturally belong to the domain of multimodal learning, where one or more content modalities have to be used in combination with interaction data. As such, CBRSs are still prone to decreases in"}, {"title": "2 Related Work", "content": "Relevant previous work falls within two strands of research: CBRSs for targeting cold start and multimodal representation learning. As our main focus are cold start and missing modality, we exclude general CBRSs not designed for these scenarios and refer the reader to Musto et al. [37]."}, {"title": "2.1 Content-Based Cold-start Recommendation", "content": "Recommending items in cold-start scenarios is one of the main challenges of RSs [53, 57]; For a recent literature review we refer the reader to Panda et al. [42]. Recent approaches [5, 23, 28, 40, 65, 68, 74] use meta-learning for cold-start recommendation, which might not tackle scenarios where no interactions at all are available for certain users or items. When certain users or items completely lack user-item interactions, RSs often rely on side information. This is done by either adding a content loss term, or adapting the learning process without any additional loss term [63]; Models of the first type are often referred to as explicit, and those in the second as implicit [66].\u00b2 Within explicit methods, Wei et al. [67] combine CF with contrastive losses between two representations of items, one obtained from collaborative signals and the other from content representations; The resulting deep neural network (NN)-based content encoder is therefore trained to obtain representations that are as similar as possible to the representations of the collaborative"}, {"title": "2.2 Multimodal Representation Learning", "content": "Multimodal learning leverages information from multiple modalities, such as audio, image, or text, to improve the performance on various machine learning (ML) tasks, such as classification, retrieval, or verification [2, 71]. Although multimodal tasks differ, the way they are usually addressed is very similar and relies on learning joint representations from multiple modalities. Several multimodal methods explored the use of NNs to map multimodal information to joint representations. For example, multi-branch NNs use separate independent and modality-specific NNs to map each modality to a joint embedding space [1, 38, 39, 50, 54]. Recently, multi-branch architectures have also been extended with the use of transformers [30, 59, 62, 71]. Such multi-branch methods have achieved remarkable performance using modality-complete information, i. e., when all modalities are available for training and evaluation. However, they suffer from performance deterioration if a modality is missing either during training or evaluation [24, 27, 31]. Recently, single-branch models [55], i. e., models that share the same embedding NN across multiple modalities, have shown promising results in multimodal learning. Although effective for other multimodal ML tasks, these models have never been translated to the domain of recommendation. Our work fills this gap in the current status of research by proposing SiBraR, a novel multimodal RS based on a single-branch architecture. Furthermore, we analyze the effectiveness of single-branch architectures in missing modality scenarios, which are related to cold start in recommendation."}, {"title": "3 Methodology", "content": "In this section, we introduce our multimodal Single-Branch embedding network for Recommendation (SiBraR). We introduce the notation and mathematical formulation of the problem. We then describe how SiBraR leverages multimodal information for recommendation in warm and cold-start scenarios.\nNotation. We denote with $U = \\{u_i\\}_{i=1}^{M}$ the set of M users and $I = \\{i_j\\}_{j=1}^{N}$ the set of N items and refer to users and items as entities. We consider the scenario of implicit feedback and represent the user-item interactions as a binary matrix $R \\in \\mathbb{R}^{M \\times N}$ with nonzero entries $R_{ij} = 1$ for a positive interaction of user $u_i$ with item $i_j$. We refer to rows of R as user profiles $u_i \\in \\mathbb{R}^{N}$; Profiles store information on the items with which user $u_i$ interacted. Analogously, we refer to columns of R as item profiles $i_j \\in \\mathbb{R}^{M}$."}, {"title": "SiBraR", "content": "The proposed model outputs a recommendation score $\\hat{y}_{ij}$ for a given user-item pair $(u_i, i_j)$, by assigning an embedding vector $e_i$ to user $u_i$ and an embedding vector $e_j$ to item $i_j$, and by computing their scalar product $\\hat{y}_{ij} = e_i \\cdot e_j$. The ordered list of the top k items that were not already interacted with by user $u_i$ (i. e., such that $R_{ij} = 0$) constitutes the recommendations for user $u_i$. Based on the assumption that different modalities of the same entity contain similar semantic representations, SiBraR aims at constructing embedding vectors for accurate recommendations by taking any available modality as input and projecting them into the same shared space. Therefore, SiBraR leverages weight-sharing and uses the same deep NN g to embed different modalities. The network g is optimized to provide accurate recommendations with any of the modalities as input. This encourages the model to encode modalities of the same entity to similar embeddings; For instance, for the same user $u_i$: $g(m_1) \\approx g(m_2) \\forall m_1, m_2 \\in M_{user}$. We now describe our proposed SiBraR architecture in its variant leveraging multimodal item side information. We denote this variant by Item-SiBraR. Item-SiBraR is designed to tackle scenarios of item cold start and missing item modality, while the SiBraR variant leveraging multimodal user side information User-SiBraR is designed for user cold start and missing user modality."}, {"title": "Item-SiBraR", "content": "Figure 1 sketches the architecture and training strategy of Item-SiBraR, while Algorithm 1 provides the pseudocode for the computation of the batch loss used for its training. In the case of Item-SiBraR, we denote the item embedding function with g and the user embedding function with h. For Item-SiBraR, the item embedding function g is the core component, and is described in detail below, while for the user embedding function h we consider either an embedding lookup table, where for each user a unique embedding is randomly initialized and optimized during training, or an architecture similar to DeepMF [72], employing deep NNs to embed the users by taking their profile as input.\u00b3 During training, Item-SiBraR samples a set $N_{ij}$ of $n_{neg} = |N_{ij}|$ negative items uniformly at random. For each user-item pair, the user embedding is obtained as $e_i = h(u_i)$. The model then samples $n_{mod}$ modalities uniformly at random from the set of item modalities $M_{item}$. The positive item and each of the negative items are embedded as follows. First, each sampled modality is projected to the input dimension of the shared network g with a shallow network $f_i$ consisting of a linear layer and an activation function. The resulting vectors are then passed through the single-branch network g, i. e., the same network is used irrespective of the modality. The resulting vectors are then averaged to compute the embedding of the item to be used to compute the recommendation score:\n$e_j = \\frac{1}{n_{mod}}(g(m_1) + \\dots + g(m_{n_{mod}}))$                                  (1)\nThe user and item embeddings, $e_i$ and $e_j$, respectively, are used to compute the recommendation scores by taking their scalar product. This is done for both the positive item $i_j$, for which $\\hat{y}_{ij} = e_i \\cdot e_j$, and for the negative items $i_k \\in N_{ij}$, for which $\\hat{y}_{ik} = e_i \\cdot e_k$. Based on the scores, the recommendation loss for Bayesian Personalized Ranking (BPR) [52] is computed. Therefore, for a single user-item interaction pair $(u_i, i_j)$, the recommendation loss is given by\n$\\mathcal{L}_{BPR}^{(U_i, i_j)} = \\sum_{k \\in N_{ij}} ln\\sigma(\\hat{y}_{ij} - \\hat{y}_{ik}).$                                  (2)\nWhile sharing the embedding network has been proven effective to combine modalities in multimodal ML [55], we also consider the use of a contrastive loss to further align the embeddings from different modalities. When the contrastive loss is not applied, $n_{mod}$ is set to 1 and only one modality is sampled for each user-item interaction pair $(u_i, i_j)$. As the modality sampling is done per interaction pair, over the course of training, all available modalities are used. \u2074 When the contrastive component is applied, $n_{mod}$ is set to 2 and in addition to the recommendation loss, Item-SiBraR models apply the symmetric Info Noise Contrastive Estimation loss [48, 60] $\\mathcal{L}_{SInfoNCE}$ between the two item modality embeddings. To this purpose, we contrast the two modalities of the positive item $i_j$ with the two modalities of the negative samples in $N_{ij}$. The loss between modalities $m_1$ and $m_2$ is therefore computed as"}, {"title": "4 Experimental Setup", "content": "In this section, we describe the experimental setup for our experiments, including the datasets, the baselines used for comparison, the evaluation protocol, the training procedure and hyperparameter tuning. We also provide the code used to carry out our experiments.\u2075"}, {"title": "4.1 Datasets", "content": "We carry out experiments on datasets from three domains: music, movie, and e-commerce. The datasets were selected by considering their popularity for benchmarking RSs, their number of content features, and the multimodality of side information available. We consider an implicit feedback scenario with a binary user-item interaction matrix R: $R_{ij} = 1$ if user $u_i$ interacted with item $i_j$ and $R_{ij} = 0$ otherwise."}, {"title": "4.2 Dataset Splitting", "content": "To evaluate the RSs in warm as well as user and item cold-start scenarios, we split the datasets in three different ways.\nWarm split. For every user, we split the data into a training, a validation, and a test set, respectively consisting of 80%, 10%, and 10% of the number of their interactions, randomly selected.\nUser Cold start. We split the users into disjoint sets of training, validation, and test users, respectively consisting of 80%, 10%, and 10% of the number of users. All interactions of train users are considered during training, and are neglected during validation and testing. All interactions of validation (test) users are considered during validation (testing), and are neglected during training and testing (validation). Since test users are not seen during training, this scenario is apt to measure the performance of RSs in the user cold-start scenario.\nItem Cold start. Similar to user cold start, we split the items into"}, {"title": "4.3 Baselines", "content": "We compare the performance of SiBraR with two CBRSs for cold-start recommendation. We also include two CF models leveraging only collaborative data. For CBRS we evaluate SiBraR against CLCRec [67] and DropoutNet [63], selected since they are often used as baselines for CBRS addressing cold-start scenarios, and since they cover both explicit (CLCRec) and implicit (DropoutNet) approaches.\u00b9\u2077 For CF, we include matrix factorization (MF) with BPR [52] and Deep Matrix Factorization (DeepMF) [72]. We select MF since it is the simplest yet effective latent-representation-based model for recommendation, and DeepMF due to its effectiveness in leveraging a two-tower deep NN for recommendation by taking the user and item profiles as inputs. Additionally, we include two naive baselines: Rand, which randomly selects the items to recommend to each user, and Pop, which recommends the same most popular items to all users, measuring popularity in terms of number of interactions in the training set."}, {"title": "4.4 Metrics", "content": "We evaluate the performance of the algorithms on lists of k = 10 recommended items, as common in the recommendation domain. We measure accuracy in terms of Normalized Discounted Cumulative Gain (nDCG).\u00b9\u2078"}, {"title": "4.5 Hyperparameter Tuning", "content": "We carry out an extensive hyperparameter optimization to rigorously evaluate the effectiveness of SiBraR and of the baselines. For all models, we tune the learning rate, the weight decay, the embedding dimension, and - whenever the model employs NNs - the number of layers and the number of nodes of each layer. For CBRSs, we treat the training modalities as hyperparameters.\u00b9\u2079 For DropoutNet and SiBraR, which support the use of one or more modalities in addition to interaction data, we consider all possible modality combinations of length 1 up to the number of available"}, {"title": "5 Results", "content": "In this section, we report the performance of SiBraR and of the baselines in standard and cold-start scenarios. We then analyze the effect of the single-branch in mapping multiple modalities to the shared embedding space."}, {"title": "5.1 Performance Comparison", "content": "Table 2 shows the nDCG@10 results\u00b2\u2074 of the algorithms on three datasets. For Onion and ML-1M, where both user and item information is available, we show the results on the three evaluation scenarios described in Section 4.4. Since user information is not available for Amazon, we restrict ourselves to the random and item cold start for this dataset. Each row refers to a different algorithm. Solid lines divide the algorithms in the three categories described in Section 4.4. For SiBraR (DropoutNet), which allows leveraging more than one modality, we include both SiBraRone (DropoutNetone) and SiBraRbest (DropoutNetbest). The sign\u2020 indicates significant improvement of the best performing RS over all other RS (paired t-tests with p < 0.05 considering Bonferroni correction to account for multiple comparisons).\nWarm split. In the random split scenario, corresponding to the"}, {"title": "5.2 Modality Gap", "content": "In this section we analyze to which extent SiBraR is able to map different modalities to the same region of the embedding space, hence filling the modality gap often displayed by multimodal models [22, 26]. We consider SiBraRbest trained on the Onion random split, which during training relies on all available modalities. Figure 3 shows the embeddings of the five item modalities (text, audio, image, genres, and interactions) after training. The left plot shows the embeddings used as input to the single-branch network g, while"}, {"title": "6 Conclusion and Future Work", "content": "In this paper, we propose SiBraR, a novel multimodal RS that leverages a single-branch architecture to encode multimodal user and item information, including collaborative data. The single-branch design allows SiBraR to provide accurate recommendations from any modality. As a result, SiBraR's recommendations are accurate also in scenarios of missing modality, including cold start. We show through extensive quantitative experiments that SiBraR significantly outperforms CF as well as CBRSs in terms of accuracy of recommendations in item cold-start scenarios, and that it is competitive with both CF and CBRSs in warm-start as well as user cold-start scenarios. Furthermore, we analyze the impact of missing modalities on the performance of SiBraR, showing that the proposed model reaches its best performance when all modalities are leveraged, but it is still able to outperform CF and other CBRSs models when input modalities are missing. Moreover, we analyze SiBraR's embedding space shared by the multiple modalities and show that as a result of its design, SiBraR is able to reduce the modality gap. SiBraR's ability to combine multimodal representations relies on the use of the single-branch, which does not exclude the use of a contrastive loss. The impact of the contrastive loss on SiBraR can be analyzed by means of an ablation study; The performance of SiBraR can also be compared with that of multi-branch architectures with contrastive loss. We focused on a version of SiBraR with an underlying RS architecture similar to DeepMF and envision as future work variants of SiBraR based on other core RS. A deeper analysis on the modality gap of SiBraR could analyze the distance in the embedding space between multimodal embeddings of a same"}]}