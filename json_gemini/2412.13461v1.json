{"title": "Look Inside for More: Internal Spatial Modality Perception for 3D Anomaly Detection", "authors": ["Hanzhe Liang", "Guoyang Xie", "Chengbin Hou", "Bingshu Wang", "Can Gao", "Jinbao Wang"], "abstract": "3D anomaly detection has recently become a significant focus in computer vision. Several advanced methods have achieved satisfying anomaly detection performance. However, they typically concentrate on the external structure of 3D samples and struggle to leverage the internal information embedded within samples. Inspired by the basic intuition of why not look inside for more, we introduce a straightforward method named Internal Spatial Modality Perception (ISMP) to explore the feature representation from internal views fully. Specifically, our proposed ISMP consists of a critical perception module, Spatial Insight Engine (SIE), which abstracts complex internal information of point clouds into essential global features. Besides, to better align structural information with point data, we propose an enhanced key point feature extraction module for amplifying spatial structure feature representation. Simultaneously, a novel feature filtering module is incorporated to reduce noise and redundant features for further aligning precise spatial structure. Extensive experiments validate the effectiveness of our proposed method, achieving object-level and pixel-level AUROC improvements of 4.2% and 13.1%, respectively, on the Real3D-AD benchmarks. Note that the strong generalization ability of SIE has been theoretically proven and is verified in both classification and segmentation tasks.", "sections": [{"title": "Introduction", "content": "3D anomaly detection (AD) plays a crucial role in industrial and medical applications by identifying abnormalities in complex structures. Traditional methods, such as BTF (Horwitz and Hoshen 2022), primarily focus on single-sample analysis, while recent deep learning-based approaches have improved detection by incorporating cross-sample information. However, these methods often rely on intuitive feature extraction, which may overlook deeper anomalies. Researchers are exploring different strategies to uncover finer details, with some emphasizing 3D data alone and others integrating multi-modal approaches.\nThe methods centered on 3D structures emphasize the unique feature representation of the structure. For example, (Bergmann and Sattlegger 2022) used geometric descriptors with a teacher-student model to achieve promising results, while (Rudolph et al. 2022) introduced asymmetric networks to enhance discrimination further. Additionally, (Li et al. 2023) focused on improving local feature representations, and (Kruse et al. 2024) proposed leveraging pose information for better anomaly detection across different viewpoints. Despite these advancements, many methods start from an intuitive structure, potentially leading to incomplete information coverage. On the other hand, multi-modal methods provide richer feature representations by integrating different data modalities. For instance, combining RGB 2D and 3D data (Wang et al. 2023) or using independent evaluations of both (Chu et al. 2023) has enhanced detection capabilities. (Zavrtanik, Kristan, and Sko\u010daj 2023) leveraged depth and RGB information to identify anomalies better, while (Bhunia, Li, and Bilen 2024) advanced 2D-3D detection by constructing a query image database. However, challenges such as feature alignment losses and increased sensor data demands persist. To address these issues, (Cao, Xu, and Shen 2023) introduced a pseudo-modal approach that projects 3D data into 2D images for supplementary information. While this method offers a more comprehensive representation, it still neglects internal structural details, resulting in incomplete feature coverage and reducing detection performance.\nCould we shift focus toward internal information for more comprehensive anomaly detection? To tackle the challenges of insufficient internal information utilization and difficulties in aligning data across different modalities in anomaly detection using pseudo-modalities, we propose a novel method centered on internal spatial pseudo-modalities. Figure 1 shows the comparison between our method's internal perception and counterparts that obtain global features from the outside. Our approach effectively captures the internal characteristics of 3D structures, even in low-sample environments, by leveraging the internal spatial features of point clouds. It facilitates better interactions between internal structures and surface regions, creating a complementary relationship between internal and external information. The core of our method, the Internal Spatial Modality Perception (ISMP) framework, includes a Spatial Insight Engine (SIE) that captures global features, an enhanced feature extraction module for local details, and a feature filtering module to suppress redundant data. Together, these components significantly improve anomaly detection accuracy. Note that our SIE indicates strong generalization capabilities, making it suitable for a broader range of point cloud tasks.\nThe main contributions of this paper are summarized as follows:\n\u2022 To our best of knowledge, we are the first to focus on the internal structure of point clouds, thereby improving the extraction of internal structural features.\n\u2022 A new Internal Spatial Modality Perception (ISMP) module and an Enhanced feature extraction combined with a feature filtering module, are designed to improve the perception and alignment of local features of key points.\n\u2022 The feasibility of Spatial Insight Engine (SIE) is explored in tasks of classification and segmentation, emphasizing the strong generalization ability of the internal spatial pseudo-modality.\n\u2022 Numerous experiments demonstrate the superiority of ISMP, surpassing the state-of-the-art methods on Real3D-AD with 13.1% and 4.1% improvements in P-AUROC and O-AUROC."}, {"title": "2D Anomaly Detection", "content": "2D image anomaly detection, a widely studied area, typically involves two main components: feature extraction and feature modeling. Feature extraction aims to derive discriminative features that distinguish normal from anomalous data. In contrast, feature modeling captures the distribution of normal features and detects deviations when anomalies are present. Early methods focused on learning features from scratch, such as through autoencoders and inpainting tasks, with notable approaches like RIAD, and DRAEM making significant strides in this area (Bergmann et al. 2019; Park et al. 2023; Zavrtanik, Kristan, and Sko\u010daj 2021). However, recent advancements have demonstrated the effectiveness of using pre-trained networks for anomaly detection. Techniques like knowledge distillation, as employed in ST and AST, align features between teacher and student networks to detect anomalies, addressing issues like overgeneralization (Yamada and Hotta 2022; Rudolph et al. 2022). Further innovations include normalizing flow and memory bank techniques to model normal feature distributions more effectively (Gudovskiy, Ishizaka, and Kozuka 2021). These developments improve 2D anomaly detection and lay the groundwork for extending these methods to 3D and multimodal detection, driving further progress in the field."}, {"title": "3D Anomaly Detection", "content": "3D anomaly detection, such as point cloud AD, is crucial in domains like autonomous vehicular navigation and industrial inspections (Solaas, Tuptuk, and Mariconti 2024; Cui et al. 2022). Deep learning-based anomaly detection leverages neural networks to capture intricate point cloud structures. Techniques like PatchCore and its successors have made significant strides by learning point cloud representations directly from raw data (Tu et al. 2024; Roth et al. 2022). These methods emphasize efficient feature extraction and fusion, crucial for effective anomaly detection. Advanced approaches like PointNet++ and Point Transformer improve feature extraction by incorporating hierarchical and attention mechanisms (Wu et al. 2024; Zhao et al. 2021; Qi et al. 2017b). Additionally, techniques like PointMAE and PointMLP further enhance local feature extraction and fusion (Pang et al. 2022; Ma et al. 2022). Mathematical strategies, including coupled Laplacian eigenmaps and locality-sensitive methods, also contribute to more nuanced point cloud representations, enhancing 3D anomaly detection (Bastico et al. 2024; Chen et al. 2023; Bergmann and Sattlegger 2022). Finally, point cloud coordinates, exemplified by methods like FPFH, provide essential feature information for anomaly detection (Rusu, Blodow, and Beetz 2009).\nIn parallel, pseudo-modality techniques, which simulate modality data through a single modality or fabricated features, aim to enhance feature representation by combining diverse types of information. Recent advancements have addressed some of these shortcomings. For instance, methods discussed in (Cao, Xu, and Shen 2023) have focused on leveraging pseudo-modal features from multiple viewpoints. Building on this, (Bhunia, Li, and Bilen 2024) further improves the capture of texture information by aligning and transposing 2D features onto 3D point clouds using extensive 2D image databases for referencing. However, despite these advancements, these methodologies commonly need to work on fully exploiting the intricate internal structure of point clouds. They predominantly focus on extrinsic information while overlooking essential internal complexities. Consequently, this oversight limits their effectiveness in fully capturing the nuanced internal features necessary for comprehensive anomaly detection."}, {"title": "Method", "content": "Figure 2 provides an overview of our method. We have developed a robust model (SIE) that seamlessly converts 3D point cloud structures into 2D pseudo-modal data using advanced four projection slices (P1, P2, P3, P4), as shown in Figure 2. These meticulously designed slices conduct thorough top-down and bottom-up analyses at the point cloud's top, middle, and bottom. More notably, the middle slice (P2, P3) expertly partitions the point cloud into two parts, working synergistically with the other slice to extract comprehensive features from both segments. The visualization of the projection slices is shown in Figure 3.\nTaking the upper part of the point cloud as an example, we explain why extracting features from the SIE can capture more information and effectively detect anomalies.\nThe amount of information can be defined as:\n$\\mathcal{P} = \\{p_i = (x_i, y_i, z_i) \\mid i \\in \\{1,2,...,N\\}\\},$ (1)\nwhere $\\mathcal{P}$ is the set of points, $p_i$ represents individual points with coordinates $(x_i, y_i, z_i)$, and $N$ is the total number of points. And the midpoint $Z_{mid}$ is defined as:\n$Z_{mid} = \\frac{Z_{min} + Z_{max}}{2},$ (2)\nwhere $Z_{mid}$ is along the z-axis, $Z_{min}$ and $Z_{max}$ are the minimum and maximum z-coordinates, respectively.\n$I_{top} = \\sum_{i=1}^{N}(Z_{max} - z_i),$ (3)\nwhere $I_{top}$ is the top information, $z_i$ is the z-coordinate of point i. Based on our SIE calculation, we have the global information:\n$I_{global} = \\sum_{i=1}^{N} [(Z_{max} - z_i) + max(0, z_i - Z_{mid})].$ (4)"}, {"title": "", "content": "After rewriting, we have:\n$I_{global} = I_{top} + \\sum_{i:z_i > Z_{mid}} (z_i - Z_{mid}) \\geq I_{top}.$ (5)\nTherefore, we observe that $I_{global}$ has more information than $I_{top}$, which is standard external projection manner. The same goes for the lower half of the point cloud. In this way, the final information obtained by the point cloud will be more reliable than if only external modes are used.\nDeep information contains important exception information (Liu et al. 2024). An anomaly can be detected when the discrepancy between the depth values from the two views significantly deviates from the expected range for normal points. That is\n$|AD(p_i) - \\mu_{AD}| > k\\sigma_{AD},$ (6)\nwhere $AD(p_i)$ is the discrepancy between top-down and middle-up depth values. Besides, $\\mu_{AD}$ and $\\sigma_{AD}$ are the mean and standard deviation of $AD$ for average points respectively, with k as a threshold constant.\nGiven these constraints, the SIE enhances global information by observing from an internal perspective, significantly improving anomaly detection compared to relying solely on external spatial capture."}, {"title": "Enhanced Feature Extraction", "content": "Following the instructions in the relevant work, we utilize Farthest Point Sampling (FPS) to obtain a set of center points, treating the k-nearest neighbors around each center point as a patch for processing (Qi et al. 2017b). Following the PointMAE method, we derive the patch features (Pang et al. 2022). Then, we perform feature extraction on the center points according to FPFH, obtaining more comprehensive features (Rusu, Blodow, and Beetz 2009). We have:\n$FPS(X) = \\{x_i\\}_{i=1}^{k},$ (7)\nwhere X represents the original point cloud and $\\{x_i\\}$ are the sampled center points.\nFor each center point $x_i$, we define its patch $P_i$ as:\n$P_i = \\{x \\in X \\mid ||x - x_i|| \\leq r\\},$ (8)\nwhere r is the radius defining the neighborhood of $x_i$. Using PointMAE, we extract features for each patch ($P_i$). Then, we use Fast Point Feature Histograms (FPFH) to further enhance feature representation for each center point."}, {"title": "Feature Filtering Module", "content": "The information extracted from the point cloud is often too miscellaneous, and we usually need to perform noise reduction and other processing on the direct information extracted from the point cloud (Cao et al. 2023). The Laplacian transform (Kipf and Welling 2017) is widely used in feature filtering to enhance the quality of features by removing noise and redundant information. It helps in achieving better feature representation and alignment, especially in high-dimensional data such as point clouds (Shao et al. 2017; Ghojogh et al. 2022). By applying the Laplacian transform, models can achieve smoother and more accurate feature extraction, which is crucial for tasks requiring precise geometric representations.\nThe Laplacian matrix L is denoted as:\n$L = D - A,$ (9)\nwhere D is the degree matrix and A is the adjacency matrix of the graph. This transformation allows for the enhancement of the overall feature quality by smoothing out irregularities and focusing on the intrinsic geometric structure (Zeng et al. 2019).\nTo achieve better alignment of features from SIE and enhancements, we develop a controllable feature filtering module using the Laplace transform to enhance geometric features in point clouds. This method is outlined in pseudo-code and relies on specific parameters. The process can be summarized by the following equation:\n$\\text{Fill}(X|\\alpha, \\beta, \\gamma) = X_{\\text{enhanced}},$ (10)\nwhere $\\alpha$, $\\beta$, and $\\gamma$ are the parameters that control the influence of the enhanced Laplacian, the decay rate of the weight matrix, and the contribution of the anomaly metric, respectively. X is the original feature matrix, and $X_{\\text{enhanced}}$ is the resulting enhanced feature matrix. The overall implementation of this module is shown in Algorithm 1."}, {"title": "Anomaly Score Calculation", "content": "We utilize the feature memory bank $M^C_F$ and the coordinate memory bank $M^C_C$ to compute anomaly scores. Here, we illustrate the scoring process using the $M^C_F$ memory bank as an example. We find the nearest neighbor in the $M^C_F$ for the test object's point-level feature $P^{(mtest)}_F$. The nearest neighbor search method (Liu et al. 2023) is denoted as:\n$m_F^{test,*} = \\underset{m^{test} \\in P^{(xtest)}_F}{\\text{arg} \\underset{m' \\in M_F}{\\text{min}}} ||m^{test} - m'||_2,$ (11)\n$m_F^* = \\underset{m' \\in M_F}{\\text{arg} \\text{min}} ||m_F^{test,*} - m'||_2.$"}, {"title": "Experiments", "content": "In this section, we firstly evaluated the effectiveness of ISMP in the anomaly detection task and secondly supplemented the assessment with the generalization ability of SIE across multiple tasks."}, {"title": "Implementation", "content": "We conducted comparative experiments on two mainstreaming datasets, namely Real3D-AD and Anomaly-ShapeNet. (1) The Real3D-AD dataset (Liu et al. 2023) is a high-resolution, large-scale anomaly dataset containing 1,254 samples across 12 categories. The training set for each category includes four normal samples, while the test set for each category contains both normal samples and anomalous samples with various defects. (2) The Anomaly-ShapeNet dataset (Li et al. 2023) provides 40 categories, containing over 1,600 positive and negative samples. The training set for each category includes four normal samples, while the test set for each category contains both normal samples and anomalous samples with various defects.\nThe quantitative comparisons of ISMP with competing models are presented in Table 1. We observed that other models exhibit biases in high-precision anomaly localization tasks, making accurate localization challenging. Our method achieved O-AUROC and P-AUROC scores of 0.767 and 0.836, respectively, significantly improving state-of-the-art (SOTA) methods."}, {"title": "", "content": "Calculate the nearest neighbor distance as the local feature anomaly score $s_F$: \n$s_F^* = ||m_F^{test,*} - m_F^*||_2.$\n\nThe anomaly score is adjusted using a re-weighting method (Liu and Tao 2016), which is denoted as:\n$S_F = \\frac{\\text{exp }||m_F^{test,*} - m_F^*||_2}{\\sum_{m \\in N_3(m^*_F)} \\text{exp }||m_F^{test,*} - m||_2} \\cdot S^*_F.$\n\nPerform similar calculations using the $M^C_C$ to obtain the coordinate anomaly score $s^C$.\n$s = \\frac{s^F + s^C}{2}.$\n\nCompute the overall anomaly score for each point cloud s by averaging the $s^F$ and s using Equ. (14)."}, {"title": "Ablation Study", "content": "We evaluated each module's effectiveness on Real3D-AD, as summarized in Table 3. The worst performance occurred with only coordinates and PointMAE features, emphasizing the need for improved local coordinate representation. Incorporating PFPH around sampled points increased P-AUROC by 18.9%, and further optimization with a feature filtering module added another 1.8%. Without global features, O-AUROC stayed at 65.6%, but introducing internal spatial modality features raised it by 11.1%. Notably, using only the two outer projection slices, omitting the internal slice, produced the second-best results, showing internal features are more reliable. These findings confirm our model's optimal composition.\nOur model achieved outstanding performance but grappled with inference efficiency challenges linked to incorporating extra modality information, as evidenced in Table 4. The ISMP lacks sufficient training and reasoning speed compared to its competitors."}, {"title": "Analysis of the Feature Filtering Module", "content": "The mean and variance of feature matrices play a crucial role in anomaly detection, as more concentrated feature distributions are beneficial for detecting anomalies (Wang et al. 2023). To further investigate the impact of the feature filtering module on feature matrices under different parameter settings, we present the effects of various parameters on the feature matrices in Figure 4. The variance of the feature matrix has a greater impact on distinguishing between abnormal and normal features than the mean. Specifically, controlling the variance in the feature matrix is crucial for better feature distinction. Notably, features from PointMAE resemble a standard normal distribution after normalization."}, {"title": "Evaluation of SIE Generalization", "content": "To verify the effectiveness of SIE for the feature perception in 3D anomaly detection, we have designed two related tasks for point clouds, namely classification and segmentation. From the results, we can observe that SIE can provide more adequate information.\nWe used intraspace pseudo-modality as a crucial supplementary input for point cloud classification in PointNet++. As shown in Table 5, a simple feature injection is sufficient to enhance the performance of point cloud classification, since the intraspace pseudo-modality provides significant additional information for point clouds. It is proved that SIE has potential in point cloud classification tasks.\nUsing the global information from SIE as a supplement to features extracted by PointNet++ for part segmentation, we observed enhanced performance, as shown in Table 6. The results demonstrate SIE's potential in aligning local and global information. Overall, ISMP excels in 3D anomaly detection, while SIE shows strong generalization and robustness, making it adaptable to other tasks."}, {"title": "Conclusion", "content": "We propose a novel 3D AD method equipped with Internal Spatial Modality Perception (ISMP) to address the issue of underutilizing internal information in samples. Our approach consists of three modules, namely a novel perception module based on the Spatial Insight Engine (SIE), an enhanced feature extraction module, and a feature filtering module. The experimental results demonstrate the effectiveness of our proposed method. Besides, we verified the effectiveness of ISMP in the AD task and the generalization ability of SIE. Limitation. Given the limits of the test cost, we aim to improve the model's inference speed in future work."}]}