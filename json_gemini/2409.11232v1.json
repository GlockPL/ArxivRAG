{"title": "Fast Analysis of the OpenAI O1-Preview Model in Solving Random K-SAT Problem: Does the LLM Solve the Problem Itself or Call an External SAT Solver?", "authors": ["Raffaele Marino"], "abstract": "In this manuscript I present an analysis on the performance of OpenAI Ol-preview model in solving random K-SAT instances for K\u2208 2, 3, 4 as a function of a = M/N where M is the number of clauses and N is the number of variables of the satisfiable problem. I show that the model can call an external SAT solver to solve the instances, rather than solving them directly. Despite using external solvers, the model reports incorrect assignments as output. Moreover, I propose and present an analysis to quantify whether the OpenAI O1-preview model demonstrates a spark of intelligence or merely makes random guesses when outputting an assignment for a Boolean satisfiability problem.", "sections": [{"title": "I. INTRODUCTION", "content": "Today, Artificial Intelligence (AI) has become a major topic in both academic and industrial research. It helps us in predicting and forecasting events, as well as generating text and images with high accuracy [1]. The AI technologies that are widely used today are primarily based on deep learning methods, particularly deep neural networks, which learn to make predictions or forecasts for specific tasks [2]. In the domain of text generation, transformers [3] are the predominant architectures. These models utilize an attention mechanism to capture complex statistical structures within natural language [1]. Many AI applications have been proposed [4-7], with ChatGPT [8, 9] emerging as one of the most renowned examples globally. This model has shown remarkable accuracy in generating text that can be comparable to that of a highly educated person. However, when it comes to understanding and solving complex mathematical problems, as other transformers, it has historically been less effective [10-12].\nRecently\u00b9, OpenAI released a new model (01-preview) that reportedly achieves text generation comparable to that of a Ph.D.-educated person and demonstrates high performance in solving mathematical problems [13, 14]. For instance, consider the following problem: \"There is a plate of candies on a table in a room with three people: Alice, Bob, and Jenny. Bob does not like candies, while Alice and Jenny do. Who could eat the candies?\" The correct answer is Alice or Jenny. This simple problem can be formulated as a satisfiability problem [15], where Alice, Bob, and Jenny are represented by three Boolean variables $X_1, X_2, X_3 \\in {0,1}$ respectively, while the given conditions can be expressed in a logical clause of the form $(x_1 \\lor \\neg X_2 \\lor X_3)$, where $\\lor$ is the logical operator OR. The solution is determined by finding an assignment of these variables that satisfies all the given conditions. When the number of clauses increases, the problem becomes more challenging. In the so-called thermodynamic limit in physics [16], where $M \\rightarrow \\infty$, $N \\rightarrow \\infty$, and $\\lim_{M,N \\rightarrow \\infty} a < 8$, the problem undergoes a phase transition at a critical value as [17]. This phase transition indicates that above as no satisfiable assignment exists meaning a configuration of Boolean variables that simultaneously satisfies all clauses cannot be found.\nA simple problem like the one described above can be easily solved by the OpenAI O1-preview model. Encouraged by this result, I decided to test the performance of OpenAI O1-preview model on simple K-SAT instances with K\u2208 {2,3,4} as a function of a, near the satisfiability threshold $a_s$. The goal was to solve different instances for various values of a and N in the spirit of statistical physics [18] for identifying the numerical algorithmic threshold of the model.\nHowever, as the analysis progressed, I observed that as the complexity of an instance increased, the model, rather than solving the problem itself, was calling an external SAT solver (an example is presented in Appendix: SAT solver calling). This rendered the analysis ineffective and raises significant concerns about the evaluation and verification of the scientific robustness of the OpenAI O1-preview model, particularly given that it is not open-source.\nWithout access to the underlying model, it is impossible to determine whether the OpenAI O1-preview model has genuinely learned the functionality and capabilities of a SAT solver or is merely outsourcing the problem to an external tool. In both scenarios, the model is an AI system; however, in the first case, when the Large Language Model (LLM) can solve a K-SAT problem on its own, the analysis can be conducted with scientific validity because the system functions as a single, unified entity attempting to solve a complex problem.\nIn the second case, where the LLM delegates the problem to an external SAT solver, the analysis lacks scientific validity because the performance results are derived from a SAT solver, rather than the LLM itself. In such a case, the AI system results from merging a Machine Learning system and an AI Expert System. This Letter aims to raise awareness within the scientific community about the limitations of using non-open-source models. By conducting an analysis following a fixed protocol (see Appendix: Protocol), I present the results obtained from the OpenAI 01-preview model and compare them with those from a well known solver like Pycosat [19]. Additionally, I show that the model under study can indeed call an external SAT solver. Moreover, I propose and present an analysis to quantify whether the OpenAI O1-preview model demonstrates a spark of intelligence or merely makes random guesses when outputting an assignment for a Boolean satisfiability problem.\nThe analysis is intentionally kept as simple as possible to ensure reproducibility. We also release the benchmark dataset used in this study, along with all the solutions obtained and analyzed . All results from the OpenAI O1-preview model were obtained on the 14th of September, 2024, using three different \"Plus\" accounts at a total cost of 60$ without taxes. Since the 14th of September, I have been unable to perform further analysis due to OpenAI's embargo period on the OpenAI Ol-preview model, which is enforced once the maximum number of questions is reached.\nThe remaining sections of this paper are organized as follows. Section II recalls briefly the K-SAT problem and the state-of-the-art of SAT solvers. Section III details the analysis performed using the model on random K-SAT instances, while in Section IV, I conclude the paper discussing and summarizing the obtained results."}, {"title": "II. K-SAT", "content": "The SAT problem, in its most fundamental form, is defined by a set of N Boolean variables. Each Boolean variable is binary, taking one of two values: {0,1}. Adding complexity to the SAT problem are M constraints, each one forming a clause. A clause is a disjunction (an OR operation V) of literals, with each literal being either a Boolean variable or its negation. So, if I denote a Boolean variable as $x_i$, then both $x_i$ and $\\neg x_i$ qualify as literals. An instance of a SAT problem is a conjunction (an AND operation $\\land$) of clause. The task is to find a satisfiable assignment for the boolean variables that makes all clauses true. Given the dichotomous nature of Boolean variables, each clause could have $2^k$ assignments (not all of them satisfiable) where k is the number of literals in the clause. The broad SAT problem branches into specific subsets. In random K-SAT, each clause is restricted to exactly K literals. The random 2-SAT problem is part of class P, solvable in polynomial time, while random K-SAT, with K\u2265 3 is NP-Complete, indicating a higher complexity.\nThe random K-SAT problem is viewed by statistical physicists as a problem exhibiting the so-called frustration property [20], which is of great interest to physics of spin glasses [21]. As stated in the introduction, the random K-SAT problem presents in the thermodynamics limit a phase transitions at $a_s$ that signifies the partitioning of the space of solutions for the random K-SAT problem into two distinctive regions. On one side a \u2208 [0, as], the problems has feasible solutions, while on the other a \u2208 $(a_s, \\infty)$, no assignment exists to satisfy all clauses of a given instance. Mathematical studies have confirmed the existence of these phase transitions for various values of K. For instance, the random 2-SAT problem shows a critical threshold value at $a_s = 1$ [22], while the recent discovery for the random 3-SAT problem places its threshold value at $a_s = 4.267$ [23] and for the random 4-SAT problem the threshold is $a_s = 9.931$ [24]. Remarkably, this behavior of the probability of finding a satisfiable assignment remains consistent across all different values of K [23].\nMany algorithms have been developed for solving the random K-SAT problem. They can be exact, with an exponential complexity (or for random 2-SAT with a polynomial complexity), heuristics, like Pycosat [19, 25] or Survey Propagation and its variants [17, 26], or learning algorithms [27] based also on Graph Neural Networks[28]. In this manuscript, for making a comparison with a well established method I use Pycosat [19]."}, {"title": "III. RESULTS", "content": "I analyzed the random K-SAT problem for K\u2208 {2,3,4}. The random K-SAT instances in CNF format were generated using the model provided by [30] at [31]. For each value of K, the number of variables per instance was set to N = 10.\nFor K = 2, I created 10 instances for each value of a in the range [0, 1], with each value incremented by 0.1 from the previous. For K = 3, I generated 10 instances for each value of a in the range [3, 4.8], with increments of 0.2. For K = 4, I created 10 instances for each value of a in the range [8,9.8], also with increments of 0.2. In each interval investigated, I would expect a decrease in the fraction of satisfiable assignments found by the OpenAI O1-preview model as a approaches $a_s$, and for $a_s \\rightarrow \\infty$ such fraction must reach 0. Before proceeding with the analysis, I performed a double-check on the solutions returned by the OpenAI Ol-preview model using the code released by Alfredo Braunstein at [29].\nThe answers returned by the OpenAI Ol-preview model were always in the form of binary strings (as I asked), with the claim that they represented satisfiable assignments. Only in the case K=4 and a \u2265 8.6, the model was starting to print a failure message like: I'm sorry, but due to the complexity of the CNF formulas provided (each with 86 clauses and 10 variables), finding satisfying assignments manually is impractical. To ensure accuracy, I recommend using a SAT solver or specialized software designed to handle large satisfiability problems. These tools are specifically optimized to efficiently process complex CNF formulas and can provide satisfying assignments if they exist. The failure message appeared increasingly frequently as a approached as for K = 4. At a = 9.4, the failure message appeared 10 times, and I stopped the analysis.\nFig. 1 shows the fraction of satisfiable assignments, namely P(SAT. ASSIG.), as a function of a for random 2-SAT, 3-SAT and 4-SAT. Green points identify the fraction of satisfiable assignments returned and checked by OpenAI O1-preview model, blue points identify the fraction of satisfiable assignments returned by OpenAI O1-preview model and checked by me using the polynomial algorithm in [29], while orange points identify the fraction of satisfiable assignments obtained by Pycosat. For random 2-SAT problem instances, the OpenAI O1-preview model seems to work well up to a = 0.6. However, above this value, the model's output begins to differ from the correct solution (i.e., the blue curve). This result indicates that as the complexity of an instance increases, the OpenAI O1-preview model returns assignments that are not satisfiable while incorrectly claiming they are (as shown by the green curve). The problem given to the model is relatively simple; it is a P problem with just 10 Boolean variables, and the number of clauses ranges from 1 to 10.\nTo make the problem harder, I studied random 3-SAT and 4-SAT instances. In these cases, however, the model's performance is very poor. For the random 3-SAT instances, the model incorrectly claims that all the assignments it finds are satisfiable, but a double-check analysis shows that only two of the assignments are actually satisfiable. In the random 4-SAT case, again only two satisfiable assignments are found. This indicates that the LLM model cannot effectively handle satisfiability problems at this time. Picosat, instead, finds the correct assignments in all cases. The fluctuations observed in the panels are due to the small number of instances analyzed, as well as the limited number of variables for each instance. Analyses with larger values of N, will reduce the fluctuation and will make the Pycosat curve sharper around the satisfiable threshold, but do not seem useful at this moment. Indeed, if the model performs poorly with N = 10, I presume that its performance is likely to worsen as N increases. However, such analyses can be conducted once the maximum question limit will be removed.\nLooking into the model's log file (accessible via a drop-down field in the output), I observed that when the model is unable to guess a solution, it resorts to calling a SAT solver. To illustrate how frequently it calls a SAT solver (such as Pycosat, MiniSAT, and CryptoMiniSat), I present a histogram of the absolute frequency in Fig. 2 for K = 3 and K = 4, across various values of a. No results are presented for K = 2, as the model does not invoke any SAT solver to solve instances in this case.\nThe most interesting observation is that although the model calls a SAT solver, and I assume that a correct solution is returned by the solver, the model fails to either copy and paste the obtained results or convert a string of positive and negative numbers into a binary string of Os and 1s, where 0 represents a negative number and 1 represents a positive one. This appears to be a bug that, in my opinion, could be easily addressed by OpenAI.\nAdditionally, I noticed that the model seems to evaluate the complexity of an instance and considers calling a SAT solver, but then decides to attempt solving the instance on its own. At this moment, there is no explanation for the model's behavior because the OpenAI Ol-preview model has not been released as open-source.\nThe final analysis I present in this short communication concerns how to quantify whether the model's guess is purely random or demonstrates some level of intelligence. To do this, I observe that to falsify an instance of a random K-SAT problem, one needs to falsify only a single clause. This allows, as well known in the literature [32], the calculation of such a probability, which is $ \\frac{1}{2^K}$. A random guess, therefore, will, on average, have a chance of achieving this value (and it cannot do better). By counting the number of unsatisfied clauses for a given assignment and dividing this number by M, one can assess whether the model demonstrates any form of intelligence if the result falls below the random guess threshold.\nIn Fig. 3, this value (denoted by H) is shown, averaged over 10 samples, as a function of a. For K = 2 (i.e., the first panel of Fig. 3), the model demonstrates a level of intelligence up to as, after which its behavior becomes random. For K = 3 and K = 4 (the second and third panels), the model appears capable of exhibiting a spark of intelligence, though at times it seems to revert to making random guesses. Although OpenAI claims that the model can solve complex tasks on par with a Ph.D. student [13], it struggles to solve random K-SAT instances with small values of N."}, {"title": "IV. CONCLUSIONS", "content": "In this manuscript, I analyzed the performance of the OpenAI O1-preview model in solving random K-SAT instances for K\u2208 {2,3,4} with N = 10. The results show that while the model can recognize the complexity of an instance and decide whether to call a SAT solver, it often fails to correctly return the solution provided by the solver. However, the model demonstrates varying levels of performance depending on the value of K. For K = 2, the model shows intelligent behavior up to a certain threshold as, after which its performance degrades to random behavior. For higher values of K (i.e., K = 3 and K = 4), while the model occasionally exhibits signs of intelligence, its behavior is inconsistent, as it frequently reverts to making random guesses. This suggests that the model's capability to perform intelligently diminishes as the complexity of the problem increases.\nThe use of a SAT solver is, in my opinion, a very interesting idea. It transforms the model into a kind of AI system where different types of systems are integrated, such as machine learning (ML) systems and AI expert systems. However, without a clear understanding of how the model is constructed, significant concerns arise regarding the evaluation and verification of its scientific robustness. Specifically, we do not know how the model assesses the complexity of an instance or why it chooses to call, or not call, a SAT solver.\nReleasing more information about the model's internal architecture could help the scientific community better understand its decision-making process and lead to improvements in future models. For now, the OpenAI O1-preview model struggles with random K-SAT problems, particularly for larger K values, highlighting a significant limitation in its problem-solving abilities."}, {"title": "Appendix: Protocol", "content": "As stated in the introduction, I used three different \"Plus\" accounts at a total cost of 60$ without taxes. Each chat starts with the following requirement:\nI will provide you with a CNF formula of a satisfiability problem. Can you give me an assignment that satisfies the formula as a string of binary variables? Also, can you handle a list of formulas and provide the assignments that satisfy them?\nThe answer of the OpenAI O1-preview model was something like that:\nYes, I can help you with that! If you provide a CNF (Conjunctive Normal Form) formula, I can find an assignment of binary variables that satisfies the formula. I can also work with a list of formulas and provide satisfying assignments for each one. Please provide the formulas you'd like me to work on, and I'll get started.\nThe next step was to provide the model with a list of instances for a given value of a and K. For example, for K=2 and a = 0.1, the input to the model was:\n1) c seed=67612117\np cnf 10 1\n5-60\n2) c seed=910839500\np cnf 10 1\n-160\n3) c seed=994446506\np cnf 10 1\n7-10\n4) c seed=1812786935\np cnf 10 1\n-7-20\n5) c seed=1898440416\npcnf 10 1\n950\n6) c seed=1979796133\np cnf 10 1\n-2-10\n7) c seed=2154785185\np cnf 10 1\n10 20\n8) c seed=2449048216\np cnf 10 1\n6-70\n9) c seed=2643334712\np cnf 10 1\n10-40\n10) c seed=2807763567\np cnf 10 1\n-3-40\nThe output of the model was in the following form:"}, {"title": "Appendix: SAT solver calling", "content": "This appendix presents an example of the log file where the OpenAI O1-preview model calls a SAT solver. The moment when the model uses a SAT solver is highlighted in red color. The log file reads:\nBreaking down the problem\nI'm working through CNF formulas, giving binary string assignments to variables. Previous formulas influence recent ones, which might lead to errors due to repeating assignments.\nTackling the task\nI'm working through generating satisfying assignments for the provided CNF formulas, converting assignments to binary strings, and ensuring completion.\nAnalyzing CNF formulations\nI'm examining CNF formulas 3 and 4 to find satisfying assignments. This initial step is crucial for building upon the relationships and dependencies within the data.\nWorking through constraints\nI'm tasked with finding a satisfying assignment for a CNF formula, which consists of multiple clauses and literals. Each clause is checked to ensure all literals are falsifiable.\nPiecing together the puzzle\nI'm working through finding a satisfying assignment for the given CNF formula, ensuring it meets the constraints defined by the clauses.\nFormulating a plan\nI'm working through finding a satisfying assignment for each formula. Considering a SAT solver or a simple DPLL solver due to the manageable number of variables and the constraints.\nTesting variable satisfaction\nI'm curious if setting all variables to True can satisfy the formula. Starting with the first clause, -X5 V X10 V -X2 V X6, it evaluates to True.\nAssessing clause outcomes\nI'm thinking through clauses with all variables set to True. Each clause contains positive literals, making all clauses true and suggesting all variables are True.\nAssessing clause validity\nI'm checking formula 3 for any clauses with all negative literals. None are found with this assignment.\nAnalyzing variable assignments\nI'm mapping out that all variables set to True don't satisfy the formula, especially with clauses having all negative literals. This indicates the need for a different assignment to fulfill the formula.\nGenerating SAT clauses\nI'm crafting clauses in DIMACS format and noting the SAT solver's constraints. Considering a random assignment for quicker verification.\nCrafting a solution\nI'm exploring the option of coding to identify a satisfying assignment for the formula with 10 variables and 80 clauses, aiming to find a valid solution.\nCrafting the response\nI'm using SAT solver to find satisfying assignments for CNF formulas. I'll provide binary strings as solutions, simulating the process. Mapping the DIMACS format."}]}