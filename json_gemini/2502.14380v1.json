{"title": "Affinity and Diversity: A Unified Metric for Demonstration Selection via Internal Representations", "authors": ["Mariko Kato", "Hakaze Choo", "Yoshihiro Sakai", "Naoya Inoue"], "abstract": "The performance of In-context Learning (ICL) is highly sensitive to the selected demonstrations. Existing approaches to demonstration selection optimize different objectives, yielding inconsistent results. To address this, we propose a unified metric-affinity and diversity-that leverages ICL model's internal representations. Our experiments show that both affinity and diversity strongly correlate with test accuracies, indicating their effectiveness for demonstration selection. Moreover, we show that our proposed metrics align well with various previous works to unify the inconsistency.", "sections": [{"title": "1 Introduction", "content": "Language Models (LMs) show In-Context Learning (ICL) ability (Dong et al., 2024), learning to solve tasks without updating model parameters by processing a query along with demonstrations of input-label pairs. The performance of ICL is highly sensitive to the quality of demonstrations (Liu et al., 2021), and previous work has proposed several strategies for selecting better demonstrations.\nOne prominent approach is to select demonstrations based on their similarity to queries. Here, the similarity is computed by models independent of the ICL-executed LMs, e.g., off-the-shelf document retrievers (Rubin et al., 2022), such as BM25 (Robertson and Zaragoza, 2009), fine-tuned document retrievers (Luo et al., 2024), and encoder-based pretrained LMs (Chen et al., 2024). While these previous methods have improved ICL performance, we find that they capture different aspects of demonstration quality and do not converge on a consensus measure (Fig. 5, Left). Developing a unified metric that integrates various metrics leads to a deeper understanding of demonstration quality and further enhances ICL performance.\nTherefore, in this paper, we propose a novel approach that leverages the ICL model's internal representations to unify previous selection methods.\nWe first identify a self-attention head that is critical for ICL, and on the subspace defined by the $W_QW_K$ of this attention head, we define two new metrics: (i) affinity between a query and demonstrations and (ii) diversity among demonstrations. Our experiments show that proposed metrics correlate with existing demonstration selection methods (Fig.5, Left) and are useful for identifying better demonstrations (Fig. 1).\nOur contributions are:\n\u2022 We propose internal representation-based affinity and diversity as a better joint metric on ICL for demonstration selection (\u00a74.2), which unifies the previous selection methods (\u00a75.2).\n\u2022 We empirically show that previous demonstration selection methods focus on different aspects of selected demonstrations, showing that they are not always positively correlated with other selection methods (\u00a75.3)."}, {"title": "2 Background", "content": "Given k input-label pairs (demonstrations) and a query for a classification task, the demonstrations and query are concatenated in natural language form and fed to LMs (e.g., for k = 2, \"Good movies. Label: Positive. That's too cruel. Label: Negative. I like it. Label: \"). Here, \u201c: \u201d serves as a forerunner token to concatenate inputs and labels, and trigger the prediction of the label tokens. The LMs return a probability distribution over the next tokens, and ICL selects the token with the highest probability as the final prediction."}, {"title": "2.2 Induction Circuit", "content": "An induction circuit is an abstraction of some attention heads to lead the inference of ICL (Elhage et al., 2021), which consists of several interacting attention heads across different layers: (i) previous token heads, which copy information from previous tokens to the current token, and (ii) induction heads, which attend to tokens based on context and boost the probability of predicting token [B] when [A][B]...[A'] is provided as input. In this paper, we find the most effective induction head, and define the affinity-diversity metrics on the $W_QW_K$ mappings of this head."}, {"title": "2.3 Demonstration Selection Methods", "content": "There are two main approaches for retrieving demonstrations. One is to use off-the-shelf retrievers, such as BM25 (Robertson and Zaragoza, 2009) or BGE M3 (Chen et al., 2024). Off-the-shelf retrievers approaches may be sub-optimal since they are not finetuned for specific tasks. Another approach is to train retrievers, e.g., using encoder-based LMs, based on supervision signals from ICL models. To optimize such retrievers, various loss functions (e.g., List-wise Ranking Loss (Li et al., 2023) and InfoNCE Loss (Rubin et al., 2022)) and training strategies (e.g., iterative training or contrastive training) are employed. Note that while learning-based methods learn signals from ICL models during training, they solely rely on the trained retriever during ICL. However, in \u00a75.3, we show that there is no consistent correlation between these previous approaches, leading to disagreement in the selected demonstrations across different objectives and optimization methods, that should be unified for consistent demonstration selection."}, {"title": "3 Proposed Metrics: Affinity, Diversity", "content": "Since induction circuits play a crucial role in ICL, we hypothesize that induction circuits can also be used to assess the quality of demonstrations. We first identify induction heads (\u00a73.1) and then compute affinity and diversity in their subspace (\u00a73.2)."}, {"title": "3.1 Step 1: Extract Internal Representation", "content": "To identify induction heads, we follow Cho et al. (2025): for each attention head h at layer l, we compute s(h), the sum of attention scores from the last token of the query to all the correct label tokens (i.e., tokens that match the ground-truth label of the query) in the demonstrations, and identify \"the best induction head\" as the head h at layer \u00ce with the highest s(h).\nWe then extract the label token representations ${d_{label}^{(i)}}_{i=1}^k$ of each demonstration i and the last token's representation $d_q$ of the query from the best induction head h. In detail, given a token index j and the hidden state $h_j^l$ of j-th token from the previous layer of h after the layer normalization, we extract the inner representation of j-th token as follows:\n$d_j = W_Qh_j^lW_Kh_j^l$\nwhere $W_Q$ and $W_K$ are the query projection and"}, {"title": "3.2 Step 2: Compute Affinity and Diversity", "content": "We define affinity as the mean of the cosine similarity between all the label token representations and the query representation as follows:\n$Aff\\ [d_q, {d_{label}^{(i)}}_{i=1}^k] = \\frac{1}{k} \\sum_{i=1}^k cos\\ [d_q, d_{label}^{(i)}]$\nWe define diversity as the variance (the trace of the covariance matrix) across the label token representations of all demonstrations as follows:\n$Div\\ [{{d_{label}^{(i)}}}_{i=1}^k] = \\frac{1}{k}tr[\\Sigma]_{i \\in [1,k]}$\nHere, $D$ represents the covariance operator."}, {"title": "4 Experiments", "content": "We demonstrate that affinity and diversity serve as effective metrics for demonstration selection."}, {"title": "4.1 Experimental Settings", "content": "We conduct experiments on Llama 3 8B (AI@Meta, 2024). The model parameters are loaded from HuggingFace."}, {"title": "Dataset", "content": "For all experiments, we use 10 classification datasets. For details of the dataset, please refer to Appendix A.1. We use k = 2, 4, 8, 12, 16, and input sequences are built by library StaICC (Cho and Inoue, 2025)."}, {"title": "Evaluation", "content": "For each test instance, we randomly sample k demonstrations, run ICL, and record the prediction. Next, we sort all instances based on their affinity or diversity values and group them into bins of 30 instances each. For each bin, we calculate the average affinity or diversity, and also the accuracy. These averages and accuracies are then used to compute the correlation between the proposed metrics and accuracy. For affinity, we use Spearman's rank correlation coefficient. For diversity, we apply Ridge regression with a Laplacian kernel to capture non-linear relationships, with the $R^2$ coefficient as the measure of goodness-of-fit."}, {"title": "4.2 Main Results: Affinity and Diversity Measure the Effectiveness of Demonstrations", "content": "The Spearman's rank correlation coefficient for affinity and $R^2$ coefficient for diversity are shown in Fig. 2 and Fig. 3. These indicate that affinity shows a positive correlation across various tasks, and diversity achieves a high $R^2$ coefficient in nearly all tasks. Fig. 4 (Left) and Fig. 4 (Right) provide examples of diversity/affinity-accuracy scatter plots, which further support these trends."}, {"title": "5 Analysis", "content": "Next, we show that affinity and diversity strongly correlate with the scores from previous demonstration selection methods, addressing the inconsistency issue in the previous work (\u00a75.2). We also show that the scores from previous demonstration selection methods disagree with each other (\u00a75.3). Moreover, the demonstrations selected by previous work practically improve affinity, but not diversity. These observations suggest that it is required a new demonstration selection method based on affinity and diversity (\u00a75.4)."}, {"title": "5.1 Experimental Setup", "content": "We use three previous methods to compare affinity and diversity, BM25 and BGE-M3 for training-free methods, and EPR for training methods. For"}, {"title": "5.2 Affinity and Diversity Correlate with the Score of Previous Methods", "content": "We measure the similarity scores from the previous methods using the same prompts described in \u00a74.1 and compute the Spearman's rank correlation among these similarity scores, accuracy, affinity, and diversity. The results of k = 16 on SST2 are shown in Fig. 5 (Left), where both affinity and diversity show a positive correlation with the similarity scores and accuracy. This indicates that affinity and diversity consistently measure the effectiveness of the demonstrations in terms of accuracy."}, {"title": "5.3 Previous Methods are Not Always Positively Correlated with Each Other", "content": "Meanwhile, no consistent positive correlation is observed among the similarity scores from previous selection methods. Even worse, in some cases, negative correlations (e.g., EPR and BM25) are observed, suggesting that they may not consistently produce optimal results. EPR shows a positive correlation with BGE, likely due to their reliance on a BERT-based encoder."}, {"title": "5.4 Better Selection of Demonstrations Improves Affinity and Diversity", "content": "In this section, we evaluate the previous demonstration selection methods on the proposed affinity and diversity, and show that affinity and diversity are improved by the previous methods. We build prompts with the same query as \u00a74.1 select demonstrations by previous methods and input them into an LM to measure the accuracy, affinity, and diversity.\nThe results are shown in Fig. 5 (Middle) for the affinity and accuracy, where better accuracy co-occurrence with greater affinity, while, when no improvement is observed in the affinity, then no accuracy can be observed in the accuracy, on some of the scenarios. Moreover, the results of diversity are shown in Fig. 5 (Left), with a less significant co-occurrence between better accuracy and greater diversity. We infer that the reason is: existing methods select demonstrations based on their similarity to the query, without a focus on the diversity, showing a possibility towards better selection methods based on the joint metric of affinity and diversity. Due to space limitations and computational resources, we leave the demonstration selection method as future work."}, {"title": "6 Conclusion", "content": "In summary, we propose affinity and diversity to evaluate demonstration selections in the ICL scenario. Our experiments show that affinity and diversity consistently measure the effectiveness of the demonstration well, raising the possibility of better demonstration selection methods."}, {"title": "7 Limitations", "content": "Due to computability limitations, we are not able to compare the performance of affinity and diversity with the learning-based retriever for diversity or order of demonstrations."}, {"title": "A Experimental Details", "content": "We build ICL-formed test inputs from 10 classification tasks datasets: GLUE-SST2 (SST2) (Socher et al., 2013), Rotten tomatoes (Rott.T) (Pang and Lee, 2005), Finacial Phrasebank (Fina.P) (Malo et al., 2014), Stanford Sentiment Treebank (SST5) (Socher et al., 2013), TREC (TREC) (Li and Roth, 2002; Hovy et al., 2001), AGNews (AGNews) (Zhang et al., 2015), Subjective (Subjective) (Conneau and Kiela, 2018), Tweet Eval Emotion (TEE) (Mohammad et al., 2018), Tweet Eval Hate (TEH) (Basile et al., 2019), Hate Speech 18 (HS18) (de Gibert et al., 2018)."}, {"title": "A.2 Previous methods", "content": "We conduct experiments to compare affinity and diversity using previous methods:\n\u2022 BM25: selecting the demonstrations with the similarity score to query, by an expanded TF-IDF (BM25).\n\u2022 BGE M3: selecting the demonstrations with the most cosine similarity between the encoding vectors of the demonstrations and query, by BGE M3. The model parameters are loaded from HuggingFace.\n\u2022 Efficient Prompt Retrieval (EPR) (Rubin et al., 2022): selecting the same way as BGE M3, by the dense encoder trained to retrieve a better demonstration with each ICL datasets."}, {"title": "C Statements", "content": "Models Llama 3 8B is under its specific license."}, {"title": "Datasets", "content": "We list the open-source license for the datasets used in this paper as follows:\n\u2022 CC-by4.0: Tweet eval emotions, Tweet eval hate\n\u2022 CC-BY-NC-SA-3.0: Financial phrasebank\n\u2022 CC-BY-SA-3.0: Hate speech 18\n\u2022 BSD: TREC, Subjective\n\u2022 Unknown: GLUE-SST2, Rotten tomatoes, Stanford sentiment treebank, AGNews"}, {"title": "C.2 Statistics For Data", "content": "We list the number of examples of datasets used in this paper as follows Table 1."}, {"title": "C.3 AI Agent Usage", "content": "AI Agents are only used for writing improving and grammar checking in this paper."}]}