{"title": "Forming Auxiliary High-confident Instance-level Loss to\nPromote Learning from Label Proportions", "authors": ["Tianhao Ma", "Han Chen", "Juncheng Hu", "Yungang Zhu", "Ximing Li"], "abstract": "Learning from label proportions (LLP), i.e., a challeng-\ning weakly-supervised learning task, aims to train a clas-\nsifier by using bags of instances and the proportions of\nclasses within bags, rather than annotated labels for each\ninstance. Beyond the traditional bag-level loss, the main-\nstream methodology of LLP is to incorporate an auxil-\niary instance-level loss with pseudo-labels formed by pre-\ndictions. Unfortunately, we empirically observed that\nthe pseudo-labels are are often inaccurate due to over-\nsmoothing, especially for the scenarios with large bag sizes,\nhurting the classifier induction. To alleviate this problem,\nwe suggest a novel LLP method, namely Learning from\nLabel Proportions with Auxiliary High-confident Instance-\nlevel Loss (L2P-AHIL). Specifically, we propose a dual\nentropy-based weight (DEW) method to adaptively measure\nthe confidences of pseudo-labels. It simultaneously em-\nphasizes accurate predictions at the bag level and avoids\noverly smoothed predictions. We then form high-confident\ninstance-level loss with DEW, and jointly optimize it with\nthe bag-level loss in a self-training manner. The experimen-\ntal results on benchmark datasets show that L2P-AHIL can\nsurpass the existing baseline methods, and the performance\ngain can be more significant as the bag size increases.", "sections": [{"title": "1. Introduction", "content": "During the past decades, supervised learning has been\nproven to gain significant success in diverse real-world ap-\nplications, in which one can easily collect loads of training\ninstances with precise supervision [10, 38]. Unfortunately,\nin many scenarios, it is challenging to collect a sufficient\nnumber of precisely labeled training instances due to vari-\nous difficulties such as high annotation costs [16, 32] and\nprivacy protection concerns [11]. Consequently, training\ninstances with incomplete, inexact, and inaccurate super-\nvision are often available only [50]. The demand for learn-\ning with such weak supervision facilitates the development\nof Weakly-Supervised Learning (WSL)[37], ranging many\nspecific paradigms, e.g., semi-supervised learning [18, 49],\npartial label learning [19, 24], and positive-unlabeled learn-\ning [8, 12], to name just a few.\nRecently, an emerging paradigm of WSL, known as\nLearning from Label Proportions (LLP) as shown in Fig.1,\nhas gained increasing attention within the machine learning\ncommunity [2, 4, 9, 48], and it has been broadly applied in a\nwide range of domains such as disease diagnosis [39], pop-\nulation census [1], and spam email filtering [30]. Techni-\ncally, LLP, as its name suggests, refers to the classification\nproblem where a certain number of training instances are\ngrouped into many bags with the corresponding proportion\nof classes, rather than annotated labels for each instance.\nNaturally, such sparse and inexact supervision from LLP\ncauses significant difficulties in inducing effective classi-\n1"}, {"title": "2. Related Work", "content": "Learning from Label Proportions. EPRM [46] theoret-\nically demonstrated that an instance-level classifier can be\ntrained using bag-level proportion information. Building on\nthis theory, DLLP [1] proposed a bag-level loss that aligns\nthe average of all instances' predictions within a bag with\nthe target distribution. Many methods have been developed\nbased on this loss. LLP-GAN [20] introduced a genera-\ntor to produce fake instances, increasing the class count to\nK + 1, enabling the model to classify these fake instances\nas the (K + 1)th class. LLP-VAT [40] uses a consistency\nregularization loss to maintain uniform predictions for an\ninstance across various data augmentations. [26, 45] intro-\nduced self-training with a contrastive learning loss to aid\ntraining. These methods incorporate self-supervised rep-\nresentation learning, but without instance-level supervised\ntraining, it is difficult to train a well-performing instance-\nlevel classifier.\nTo improve instance-level classification performance,\nsome approaches employ the model's predictions as\npseudo-labels for self-training. SELF-LLP [22] employs\nthe model's predictions from different epochs as pseudo-\nlabels for training. PLOT and ROT [7, 21] utilize pseudo-\nlabels generated through optimal transport for training. In\nthe study by [25], they employed an online pseudo-labeling\nmethod with regret minimization. However, due to the sig-\nnificant smoothing of model predictions, especially with\nlarger bag sizes, it naturally leads to the generation of nu-"}, {"title": "3. Proposed L2P-AHIL Method", "content": "In this section, we introduce the proposed LLP method\nnamed (L2P-AHIL).\nTask formulation of LLP. We now introduce essential\nnotations to formulate the LLP task. Typically, we are\ngiven an LLP training dataset of N proportion-labeled bags\n$\\mathcal{D} = \\{(B_i, p_i)\\}_{i=1}^N$, where each $B_i = \\{x_{i,j}\\}_{j=1}^M$ denotes\na bag of M instances represented by x. Its corresponding\nproportion label $p_i \\in \\triangle^{C-1}$ denotes the proportion of C\npre-defined classes in the bag. The value of $m = P_{i,c}M$\nrepresents the number of instances of class c in $B_i$. Gener-\nally, all bags are disjoint, i.e., $B_i \\cap B_k = \\emptyset$, $ \\forall i \\neq k$. The\ngoal of LLP is to induce a classifier over $\\mathcal{D}$ with weakly\nsupervised signals, i.e., the bag-level label proportion only."}, {"title": "3.1. Overview", "content": "Overall speaking, our L2P-AHIL method is denoted as\n$f_W(\u00b7)$, parameterized by W, which ingests an instance x\nand outputs its prediction $\\hat{y} = f_W(x)$. We follow the\nmethodology of incorporating an auxiliary instance-level\nloss with pseudo-labels. For the instance-level loss, we\nadopt the commonly used \"Weak and Strong Augmenta-\ntion\" strategy in the semi-supervised learning domain [36]\nto enhance the model's representational learning capabili-\nties. For each instance x, we transform it into a weakly\naugmented version $x^w$ and a strongly augmented version\n$x^s$, where $x^w$ is specifically used to form the correspond-\ning pseudo-label and $x^s$ is used as a training sample. The\npredictions for them are represented by $\\hat{y}^w = f_W(x^w)$ and\n$\\hat{y}^s = f_W(x^s)$, respectively. With the predictions of all in-\nstances, we can formulate the objective of L2P-AHIL with\nrespect to W as follows:\n$\\mathcal{L}(W) = \\mathcal{L}_b(p, \\hat{y}^w) + \\lambda \\mathcal{L}_i(\\tilde{y}, \\hat{y}^s)$,                                                                   (1)\nwhere $\\mathcal{L}_b(p, \\hat{y}^w)$ is the bag-level proportion loss; $\\mathcal{L}_i(\\tilde{y}, \\hat{y}^s)$\nis the instance-level self-training loss and $\\tilde{y}$ denotes the\npseudo-label; $\\lambda$ is coefficient parameter used to balance the\ntwo losses."}, {"title": "Bag-level proportion loss.", "content": "Following [1], L2P-AHIL con-\ntinues to utilize this loss for bag-level proportion learning.\nIt is defined as the cross-entropy between prior and poste-\nrior proportions which can be formulated as follows:\n$\\mathcal{L}_b(P, \\hat{y}^w) = \\frac{1}{N} \\sum_{i=1}^N H(p_i, \\hat{p}_i),$                                                                                                    (2)\nwhere $\\hat{p}_i = [\\hat{P}_{i,c}]_{c=1}^{C-1}$ denotes the predicted proportion in\n$B_i$, and $H(\u00b7, \u00b7)$ denotes the cross-entropy loss. The value of\n$\\hat{P}_{i,c}$ is computed by averaging the predicted probabilities of\nclass c across all instances in $B_i$. It can be represented by\nthe formula:\n$\\hat{P}_{i,c} = \\frac{1}{M} \\sum_{j=1}^M \\hat{y}_{j,c}^w,$                                                                                                  (3)\nwhere $\\hat{y}_{j,c}^w$ represents the predicted probability of class c\nfor $x_{i,j}^w$.\nInstance-level self-training loss. We define the pseudo-\nlabels y as the hardened version of $\\hat{y}^w$. This means that for\neach $x_{i,j}$, its pseudo label $\\tilde{y}_{i,j} = [Y_{i,j,c}]_{c=1}^{C}$ has one class\nwith a probability of 1, while the probabilities for all other\nclasses are set to 0. Formally, this can be expressed as:\n$\\Upsilon_{i,j,c} =\\begin{cases}1, & \\text{if } c = \\text{arg max}(\\hat{y}_{j,c}^w), \\\\0, & \\text{otherwise}.\\end{cases}$                                                                                                                                (4)"}, {"title": "3.2. Dual Entropy-based Weight", "content": "Based on the assumption that lower entropy values imply\nhigh confidence in LLP, we propose a DEW weight for com-\nputing $w_{i,j}$. Specifically, we consider the confidence from\nboth bag and instance levels. Accordingly, we design $w_{i,j}$ as\na product of a bag-level adaptive weight $w_c^b$ and an instance-\nlevel adaptive weight $w_{i,j}^l$ as follows:\n$w_{i,j} = w_c^b \u00b7 w_{i,j}^l$                                                                                                                                                                                    (6)\nwhere $w_{i,j}^l$ represents the adaptive weight for $x_{i,j}$ and here,\n$c = \\text{arg max} \\hat{y}_{j,c}^w$ denotes the class with the highest proba-\nbility. We calculate $w_c^b$ and $w_{i,j}^l$ based on the entropy dif-\nferences between the predicted distribution and the target\ndistribution at the bag level and instance level, respectively."}, {"title": "3.2.1 Bag-level Adaptive Weight", "content": "At the bag level, we construct a predicted distribution that\nincludes the prediction results for class c from all instances\nin $B_i$, expressed as $h'^{b}_{i,c} = [\\hat{y}^w_{i,j,c}]_{j=1}^{M}$. To ensure that the\nelements of this distribution sum up to 1, we apply L1 nor-\nmalization to $h'^{b}_{i,c}$, i.e., $\\hat{h}^{b}_{i,c} = h'^{b}_{i,c} / ||h'^{b}_{i,c}||_1$.\nBased on practical knowledge, we define this target dis-\ntribution as $h^b_c$, which is composed as follows: there are\n$m_i$ instances predicted as class c with the highest proba-\nbility, i.e., $1/m_i$, while the remaining $(M \u2212 m_i)$ instances\nhave the lowest probability, i.e., 0. It can be expressed as\nfollows:\n$\\hat{h}_c^b = \\text{L1-Normalization}([\\underbrace{1, ..., 1}_{m_i},\\underbrace{0, ..., 0}_{M-m_i}])$                                                                        (7)\nThe entropy of the target distribution can then be calcu-\nlated as $H(\\hat{h}^b_c) = \\text{log} m_i$. As the predicted distribu-\ntion approaches the target distribution, the adaptive weight\ntends toward 1; conversely, it tends toward 0 when the\ndistributions diverge. Therefore, we introduce $\\sigma(x; \\beta) =\\text{exp}(\\frac{-x^2}{\\beta})$\nas a mapping function, which allows us to de-\nrive the bag-level adaptive weight:\n$w_{i,c}^b = \\sigma(\\mathcal{H}(\\hat{h}_c^b) - \\mathcal{H}(\\hat{h}^{b}_{i,c}); \\beta_b)$                                                                                                                                                   (8)\n$= \\text{exp} \\begin{cases} -\\frac{[\\mathcal{H}(\\hat{h}_c^b) - \\mathcal{H}(\\hat{h}^{b}_{i,c})]^2}{\\beta_b} \\end{cases}$                                                                                                                                 \n$= \\text{exp} \\begin{cases} -\\frac{[\\text{H}(\\hat{h}_c^b) - \\text{log} m_i]^2}{\\beta_b} \\end{cases}$"}, {"title": "3.2.2 Instance-level Adaptive Weight", "content": "At the instance level, the predicted distribution is derived\nfrom the prediction results of individual instances. Specifi-\ncally, for each instance $x_{i,j}$, we define $h_{i,j} = [\\hat{y}^w_{i,j,c}]_{c=1}^{C}$ to\nmeasure the confidence of the instance.\nFor the target distribution, we consider a label to have\nhigh confidence when its predicted probabilities are con-\ncentrated on a single class. Therefore, we define the target\ndistribution as $\\hat{h}_{i,j}$, where only one class has a probability\nof 1, and the probabilities of all other classes are set to 0,\ni.e.,\n$\\hat{h}_{i,j} = [\\underbrace{1,0, ..., 0}_{C-1}]$                                                                                                                                                          (9)\nIt is straightforward to calculate that the entropy of the tar-\nget distribution is 0, i.e., $H(\\hat{h}_{i,j}) = 0$. With the same map-\nping function as the bag level, the instance-level adaptive\nweight is obtained with a hyper parameter $\\beta_l > 0$:\n$w_{i,j}^l = \\sigma(\\mathcal{H}(\\hat{h}_{i,j}) - \\mathcal{H}(h_{i,j}); \\beta_l)$                                                                                                                                                   (10)\n$= \\text{exp} \\begin{cases} -\\frac{[\\mathcal{H}(\\hat{h}_{i,j}) - \\mathcal{H}(h_{i,j})]^2}{\\beta_l} \\end{cases}$\n$= \\text{exp} \\begin{cases} -\\frac{[\\mathcal{H}(\\hat{h}_{i,j})]^2}{\\beta_l} \\end{cases}$"}, {"title": "4. Experiments", "content": "Datasets We assessed L2P-AHIL on four benchmark\ndatasets for LLP: Fashion-MNIST [43], SVHN [27],\nCIFAR-10, CIFAR-100 [15] and Mini-ImagNet [42].\nFashion-MNIST is a dataset consisting of 60,000 training\nand 10,000 test examples. Each example is a 28x28 gray-\nscale image, representing 10 categories of fashion items.\nThe SVHN dataset is composed of 32x32 RGB images of\ndigits, featuring 73,257 training examples and 26,032 test-\ning examples, along with an additional 531,131 training\nsamples that we do not utilize in our experiments. CIFAR-\n10 and CIFAR-100 datasets each contain 50,000 training\nand 10,000 testing examples, with every example being a\n32x32 color natural image. They are categorized into 10 and\n100 classes, respectively. MiniImageNet is a subset of the\nImageNet dataset, consisting of 100 selected classes. Each\nclass contains 80 images for training and 20 images for test-\ning, with all images resized to 64x64.\nBag generation. For each dataset, with a specified bag\nsize M, we randomly select M samples from the training\nset $\\mathcal{D}$ to form a bag $B_i$. The samples in distinct bags do\nnot overlap. We compute the class proportion information\nwithin each bag to guide the training, but real labels are not\nused during training. Following prior studies, we choose\nM from the set \\{16, 32, 64, 128, 256\\}. As every dataset\ncontains an equal number of samples across classes, the\nbags created through this method exhibit relatively balanced\nproportions, leading to more challenging LLP tasks, as evi-\ndenced by [46]."}, {"title": "4.2. Implementation Details", "content": "For SVHN, Fashion-MNIST, and CIFAR-10, we used the\nWRN-28-2 [47] architecture as the encoder, and for CIFAR-\n100, the WRN-28-8. For MiniImageNet, we employed the\nResNet-18 architecture. The classifier consists of a single\nlinear layer. Each training step utilizes a batch size equal to\nthe bag size multiplied by the number of bags, amounting to\n1024. Models are trained using Stochastic Gradient Descent\n(SGD) [29], with a momentum of 0.9 and a weight decay\nof 5e-4 for WRN-28-2, 1e-3 for WRN-28-8, and le-4 for\nResNet-18. The initial learning rate is set to \u03b7o = 0.03\nfor all datasets, except for MiniImageNet, where it is set to\n\u03b7o = 0.05, following a cosine learning rate decay schedule\n[23] as $\u03b7 = \u03b7_0 \\text{cos} (\\frac{\u03c0k}{K} )$, where k is the current training\nstep and K is the total number of steps, set to 2^20. We train\nour models for 1024 epochs. Weak augmentations include"}, {"title": "4.3. Results and Analysis", "content": "L2P-AHIL achieves SOTA results. We present results on\nfour benchmark datasets in Table 1. We observe that L2P-\nAHIL significantly outperforms the majority of baseline\nmethods across all benchmark datasets and for every bag\nsize. Compared with FLMm, which utilizes a stronger pre-"}, {"title": "4.4. Ablation Study", "content": "In this section, we perform an ablation study to assess the\ninfluence of two central elements of L2P-AHIL: bag-level\nand instance-level adaptive weight. Experiments were con-\nducted on the CIFAR-10 and CIFAR-100 datasets, with re-\nsults presented in Table 2. The first row shows that re-\nmoving both adaptive weight. With smaller bag sizes and\nfewer classes, the pseudo-labels generated by the model\nwere relatively accurate, and the classification performance\ndid not decline significantly, as seen with bag sizes from\n16 to 64 on CIFAR-10. However, for larger bag sizes,\nsuch as 256, accuracy plummeted to merely 51.90%. On\nthe more complex CIFAR-100, with a greater number of\nclasses, the model's performance deteriorated substantially.\nOn CIFAR-100, we observe that the model's performance\ndrops sharply between adjacent bag sizes. The large num-\nber of classes and the reduction in supervisory informa-\ntion make the model more prone to generating inaccurate"}, {"title": "4.5. Parameter Sensitivity", "content": "In this paragraph, we investigate how $\u03b2_b$ and $\u03b2_l$, key hy-\nper parameters in L2P-AHIL, influence its performance. We\nconduct experiments on CIFAR-10 and CIFAR-100 with a\nbag size of 128(Fig.6). For the 100-class task CIFAR-100,\nthe best result is achieved with $\u03b2_b$ = 5 and $\u03b2_l$ = 5. For\nthe 10-class task, represented by CIFAR-10, the optimal re-\nsult is obtained with $\u03b2_b$ = 1 and $\u03b2_l$ = 1. We selected\nour hyper parameters $\u03b2_b$ and $\u03b2_l$ based on these tests. When\n$\u03b2_b$ and $\u03b2_l$ are small, the weights are highly sensitive to\nchanges in entropy, and some accurate pseudo-labels may\nbe assigned low weights, preventing the model from fully\nutilizing them. For example, when $\u03b2_b$ = 2 and $\u03b2_l$ = 2, the\naccuracy on CIFAR-100 is only 64.81%. Conversely, when\n$\u03b2_b$ and $\u03b2_l$ are too large, many smooth but inaccurate pseudo-\nlabels are given high weights, which hampers the training of\nthe classifier. For instance, with $\u03b2_b$ = 40 and $\u03b2_l$ = 40, the\nmodel fails to converge on CIFAR-100."}, {"title": "5. Conclusion", "content": "In this paper, we evaluated the problem of imprecise\npseudo-labels in existing LLP methods. Addressing these\nchallenges, we introduced L2P-AHIL, a novel approach that\nmeasures pseudo-label confidence using both bag-level and\ninstance-level entropy values, and then adaptively adjusts\nthe pseudo-label weight for each instance. Our extensive"}, {"title": "6. Limitations", "content": "The major limitation of L2P-AHIL is that the hyper pa-\nrameters of the adaptive weight is relatively sensitive to\nthe datasets with various class numbers. Besides, our test\ndataset is considered classical and easily accessible, yet it\nhas not been evaluated on larger, more complex datasets."}, {"title": "Broader Impacts", "content": "The paper focuses solely on the technical aspects of LLP\nalgorithms. Therefore, this work can benefit a wide range\nof machine learning researchers. Also, we do not expect our\nefforts to have any negative consequences."}]}