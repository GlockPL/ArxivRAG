{"title": "A Study on Effect of Reference Knowledge Choice in\nGenerating Technical Content Relevant to SAPPHIRE\nModel Using Large Language Model", "authors": ["Kausik Bhattacharya", "Anubhab Majumder", "Amaresh Chakrabarti"], "abstract": "Representation of systems using the SAPPHIRE model of causality\ncan be an inspirational stimulus in design. However, creating a SAPPHIRE\nmodel of a technical or a natural system requires sourcing technical knowledge\nfrom multiple technical documents regarding how the system works. This re-\nsearch investigates how to generate technical content accurately relevant to the\nSAPPHIRE model of causality using a Large Language Model, also called\nLLM. This paper, which is the first part of the two-part research, presents a\nmethod for hallucination suppression using Retrieval Augmented Generating\nwith LLM to generate technical content supported by the scientific information\nrelevant to a SAPPHIRE construct. The result from this research shows that the\nselection of reference knowledge used in providing context to the LLM for gen-\nerating the technical content is very important. The outcome of this research is\nused to build a software support tool to generate the SAPPHIRE model of a giv-\nen technical system.", "sections": [{"title": "Introduction", "content": "In two-part research, the authors investigate whether a Large Language Model\n(LLM) can be used to accurately generate the technical content relevant to a SAP-\nPhIRE representation of technical systems. However, LLM is not explicitly trained in\nSAPPHIRE ontology definitions, and hallucination of LLM is a major concern in gen-\nerating relevant information. The first part of this two-part research, presented in this\npaper, demonstrates the significance of a reference knowledge choice as the contextu-\nal knowledge in Retrieval Augmented Generation (RAG), a popular method for hallu-\ncination mitigation. The second part of the research, presented in the paper titled \"De-\nvelopment and Evaluation of a Retrieval-Augmented Generation Tool for Creating\nSAPPHIRE Models of Artificial Systems\" by the authors, presents a new support tool\nto generate technical content relevant to all the constructs of SAPPHIRE model using\nan LLM and RAG method. The overall research plan, following the Design Research\nMethodology [1], is shown in Figure 1."}, {"title": "Application of Large Language Models in Product Design", "content": ""}, {"title": "Large Language Models and Its Challenges", "content": "Large language models are at the forefront of Artificial Intelligence (AI) driven\ntext generation, creating content that closely resembles natural human writing.\nTrained on extensive corpora of text, they can produce coherent and contextually\nrelevant narratives, articles, and dialogues [2, 3]. Their advanced algorithms analyze\npatterns in language use, enabling them to predict and generate text with a high de-\ngree of accuracy [4]. Hallucination in large language models (LLMs) refers to the\ngeneration of incorrect or nonsensical information that the model presents as fact [5].\nTo mitigate these risks, it is essential to implement robust validation mechanisms and\nhuman oversight to ensure the accuracy of the model's outputs. As LLMs become\nmore integrated into various sectors, addressing hallucinations remains a key chal-\nlenge in the field of AI [6]. Research also shows that base LLMs alone are currently\nnot sufficient for learning domain-specific ontologies [7]."}, {"title": "Application of Large Language Models in Product Design", "content": "Though the application of LLM in engineering is new, its adoption is growing. Re-\nsearch is looking to develop useful applications with LLM in design. It is used for\nunderstanding and reasoning in Bio-inspired Design [8], in design ideation using\nTRIZ [9] and FBS-based design ideation using prompt engineering [10]. However,\nnone of these works reported any hallucination-related issues and, therefore, did not\nlook into hallucination mitigation. On the other hand, other research looked at differ-\nent ways of addressing hallucinations in LLM. For example, a system engineering\nmodel using Object-Process Methodology is used with LLM for spacecraft design\n[11]. Retrieval Augmented Generation (RAG) is a popular and effective method em-\nployed in multiple applications where a domain-specific knowledge base is used to\nground an LLM's responses [12, 13]. Causal ontologies like FBS [14] or SAPPHIRE\n[15] are powerful in design ideation. Hence, in this research, we look into RAG-based\nmethods for generating information relevant to SAPPHIRE model using LLM."}, {"title": "Design Representation using SAPPHIRE Model", "content": "Representation of natural or artificial systems working using the SAPPHIRE model\ncan act as creative stimulation during design ideation [16, 17, 18]. Hence, a method\nwas developed to extract information about systems working from natural language\ntechnical documents and represent them using the SAPPHIRE model [19]. The SAP-\nPhIRE model [15] has seven layers of abstraction, namely, State Changes, Actions,\nParts, Phenomena, Inputs, oRgans, and Effects. A SAPPHIRRE model represents the\nsystem's physical components and their interface. It describes the physical interactions\nbetween a physical component and its surroundings involving the transfer or trans-\nformation of energy, material and information with the underlying scientific law and\nthe condition for the physical interaction. A SAPPHIRE model can produce a rich\nsystem representation and is used in the analysis and synthesis of product design [18].\nThe SAPPHIRE model with an example (heat transfer from a hot body to cool sur-\nrounding air) is shown in Figure 3."}, {"title": "Research Question and Research Method", "content": "LLM's content is generated by the model, which is trained on a very large text cor-\npus (several hundred billion tokens) with a wide variety of content from both tech-"}, {"title": "Generating Technical Content Relevant to SAPPHIRE Model", "content": "By integrating external knowledge sources, RAG provides a \u2018context' to the LLM,\nensuring that the information they produce is grounded in reference knowledge [21].\nThus, the RAG method allows LLMs to access information beyond their training data.\nThis research implemented a computer program for content generation with the RAG\nmethod using (a) ChatGPI API [22] calls via (b) LangChain API [23] and (c) Chroma\nvector database API [24]. Temperature was set at 0.0 in ChatGPT API calls with the\n'GPT-4-Turbo' model. The final prompt to the LLM includes the user query and the\n'context' embedded into it. The user query is the 'ask' to the LLM to generate exam-\nples of a named scientific phenomenon and explain the physical interaction involved\nand its condition. Scientific knowledge regarding the physical interaction and its con-\ndition is supplied as the 'context' via RAG method in the LLM prompt."}, {"title": "Study on the Effect of \u2018Context' in LLM Responses", "content": ""}, {"title": "Numerical Experiments", "content": "Two scientific phenomena, namely (a) Vaporization and (b) Generation of EMF\ndue to the Seebeck effect, are considered in both numerical experiments. Common\nscientific phenomena taught in high school physics and undergraduate courses are\nused so that the accuracy of the information can easily be verified.\nIn the first numerical experiment, for a given scientific phenomenon, technical\ncontents are generated from the engineering domain as LLM response by using a\nprompt in two information categories, namely (a) Physical Interaction and (b) Condi-\ntion for Physical Interaction. LLM response is generated with two different \u2018contexts'\nin each information category. In each 'context,' reference knowledge relevant to the\ninformation category is provided for RAG, and nine technical contents are generated\nfor each given 'context.' One of the two 'contexts' in each information category is\nassumed to be ground truth, and a similarity score is calculated for each response\nagainst it. A one-way ANOVA test was done to check the effect of 'context'\nknowledge in LLM responses. Table 1.1 summarizes all the cases in the first numeri-\ncal experiment.\nIn the second numerical experiment, for a given scientific phenomenon, technical\ncontents are generated from the engineering domain in two information categories,\nnamely (a) Physical Interaction and (b) Condition for Physical Interaction. Technical\ncontent is generated in these two information categories with three different 'con-\ntexts.' In each \u2018context,' reference knowledge relevant to the information category is\nprovided for RAG. Since a physical interaction and its conditions can be expressed in\nmany ways, three different 'contexts' are used. Three technical contents are generat-\ned for each given 'context,' and all these responses belong to the same group. Re-\nsponses generated using a different 'context' belong to a different group. The\nknowledge of the 'context' is assumed to be the ground truth in that group, and a"}, {"title": "Results", "content": "Numerical Experiment 1: Table 2.1 summarizes the results from the ANOVA test.\nThe 'context' knowledge used in Context-1 is taken as the reference knowledge to\ncalculate the similarity score. Figure 3 shows the similarity scores of each response\nfor both scientific phenomena."}, {"title": "Discussions and Conclusions", "content": "Since the p-value in all the test cases in Numerical experiment 1 is less than 0.05\n(level of significance assumed in this experiment), we can safely reject the null hy-\npothesis that response groups corresponding to Context-1 and Context-2 are the same.\nThe ANOVA test results of Numerical experiment 1 show that the 'context' used in\nthe RAG method influences the responses generated by the LLM. In this experiment,\nif Context-1 is assumed as the true knowledge, the responses generated using Con-\ntext-1 in RAG will be more grounded to the truth value.\nResults from Numerical experiment 2 show that LLM is generating responses\nbased on the context provided by retrieval. The average similarity score and average\nsimilarity distance are found to be higher in Group-2. Multiple 'contexts' used for the\nsame information group can be assumed to be different expressions of the scientific\ntruth. The results show that Context-2 produces more relevant responses to the ground\ntruth. Since scientific knowledge can be expressed in many ways, this experiment's\nresults proved that certain descriptions of scientific knowledge will produce better\nresponses by an LLM.\nSince the p-value in all the test cases in Numerical experiment 3 is less than 0.05\n(level of significance assumed in this experiment), we can safely reject the null hy-\npothesis that response groups corresponding to Context-1 and Context-2 are the same.\nThe ANOVA test results of Numerical experiment 3 show that the level of details in a\n'context' used in the RAG method influences the responses generated by the LLM.\nIt is therefore seen in this paper that (a) with scientific knowledge provided as the\ncontext, LLM can produce rich and relevant content about the physical interaction of\na system and the condition, (b) the responses generated by the LLM follow the con-\ntent of the document used as 'context,' and (c) the choice of reference knowledge\nmatters when generating LLM responses for SAPPHIRE construct. However, this\nresearch generated responses for only two constructs, namely, Phenomenon (i.e.,"}]}