{"title": "Chatbots im Schulunterricht: Wir testen das Fobizz-Tool zur automatischen Bewertung von Hausaufgaben", "authors": ["Rainer M\u00fchlhoff", "Marte Henningsen"], "abstract": "Die vorliegende Studie untersucht das Kl-gest\u00fctzte Korrekturtool \u201eKI-Korrekturhilfe\" des Unternehmens Fobizz, das Lehrkr\u00e4ften Unterst\u00fctzung bei der Bewertung und R\u00fcckmeldung von Sch\u00fclerarbeiten bieten soll. Im gesellschaftlichen Kontext eines \u00fcberlasteten Bildungssystems und wachsender Erwartungen an den Einsatz von k\u00fcnstlicher Intelligenz zur L\u00f6sung dieser Probleme analysiert die Untersuchung die funktionale Eignung des Tools anhand von zwei Testreihen. Dabei zeigen die Ergebnisse erhebliche Defizite: Die numerischen Bewertungen und qualitativen R\u00fcckmeldungen des Tools h\u00e4ngen h\u00e4ufig vom Zufall ab und verbessern sich nicht durch die Einarbeitung der Verbesserungsvorschl\u00e4ge des KI-Tools. Eine Bestbewertung ist nur mit Texten erreichbar, die von ChatGPT geschrieben sind. Falschbehauptungen und Nonsense-Abgaben werden h\u00e4ufig nicht erkannt, und die Umsetzung einiger Bewertungskriterien ist unzuverl\u00e4ssig und intransparent. Da diese M\u00e4ngel aus den fundamentalen Einschr\u00e4nkungen gro\u00dfer Sprachmodelle (LLMs) resultieren, sind grundlegende Verbesserungen dieses oder \u00e4hnlicher Tools nicht unmittelbar zu erwarten. Die Studie kritisiert den allgemeinen Trend, KI als schnelle L\u00f6sung f\u00fcr systemische Probleme im Bildungswesen einzusetzen. Sie kommt zu dem Schluss, dass die Vermarktung des Tools durch Fobizz als objektive und zeitsparende L\u00f6sung irref\u00fchrend und unverantwortlich ist und mahnt zu systematischer Evaluation und fachdidaktischer Pr\u00fcfung des Einsatzes von KI-Tools im Schulkontext.", "sections": [{"title": "I. Einleitung", "content": "1. Der Ruf nach mehr Kl im Schulunterricht\nEmpirische Erhebungen und \u00f6ffentliche Berichterstattung beschreiben seit Jahren einen besorgniserregenden Zustand des deutschen Bildungssystems. In einer Statista-Studie von 2024 geben nur 30% der befragten B\u00fcrger:innen an, mit dem Schulsystem \u201czufrieden\" oder \"sehr zufrieden\" zu sein. Bei einer Befragung der Robert Bosch Stiftung gaben knapp 70% der Lehrkr\u00e4fte an, dass sie sich mindestens einmal die Woche durch ihre Arbeit ersch\u00f6pft f\u00fchlten, und 43% gaben an, sie seien mindestens einmal die Woche bereits vor dem Beginn des Schultags wieder m\u00fcde. Die Autor:innen des Bildungsberichts 2024 sprechen davon, dass das System \"am Anschlag arbeitet\". In wirtschaftlicher Hinsicht moniert das ifo-Zentrum f\u00fcr Bildungs\u00f6konomik, dass das Schulsystem unterfinanziert sei und an einem Investitionsr\u00fcckstand leide. In der Politik der aktuellen Legislatur wurden diese Befunde in den manischen Ruf nach \"mehr Tempo\u201d bei der Digitalisierung \u00fcbersetzt ein Argument, das nach der Corona-Pandemie h\u00e4ufig vorgebracht wird. Dabei verweisen die meisten Studien als Ursache der Krise des Bildungssystems auf Lehrkr\u00e4ftemangel, \u00dcberarbeitung der vorhandenen Lehrkr\u00e4fte, die insgesamt schlechten Arbeitsbedingungen an Schulen und mangelnde Wertsch\u00e4tzung des Berufs.\nSp\u00e4testens seit der Markteinf\u00fchrung von ChatGPT, dem beliebten Chatbot-System des US-amerikanischen Unternehmens OpenAl, das seit Herbst 2022 verf\u00fcgbar ist, wird \"k\u00fcnstliche Intelligenz\" (KI) auf der Basis gro\u00dfer Sprachmodelle (LLMs, large language models) als ein wesentlicher Baustein digitaler L\u00f6sungen f\u00fcr das Bildungsproblem gehandelt. Basierend auf den spezifischen (neuen) M\u00f6glichkeiten, die generative LLM-Systeme bieten, wird von zahlreichen kleineren Startups und gro\u00dfen Unternehmen (z. B. Microsoft) eine neue Generation von KI-Tools f\u00fcr den Bildungsbereich angeboten. Bei diesen Tools steht die text- und sprachbasierte Interaktion im Vordergrund: sei es zwischen Sch\u00fcler:in und Computersystem, Lehrkraft und Computersystem, oder Sch\u00fcler:in und Lehrkraft vermittelt durch Kl-basierte Computersysteme. W\u00e4hrend zum Beispiel in London derzeit eine ganze Klasse einer Privatschule \"lehrerlos\" in das neue Schuljahr startet und ausschlie\u00dflich \u201cvon einer Kombination aus KI-Plattformen und Virtual Reality Brillen unterrichtet wird\", nehmen wir auch im Deutschen Kontext einen zwar weniger auf Vollautomatisierung abstellenden, dennoch aber immer lauter werdenden Ruf nach mehr KI-Technologie im Schulkontext wahr. So beobachten wir als wichtigste Anwendungen dieser Technologie im deutschsprachigen Diskurs vor allem die folgenden Trends:"}, {"title": "II. Untersuchungsziele und Methodik", "content": "Unser Ziel ist die qualitativen Untersuchung des Korrekturtools (\u201cAl Grading Assistant\") von Fobizz.\nEine solche Untersuchung steht vor mindestens zwei besonderen Herausforderungen, einer prinzipiellen und einer technischen.\nPrinzipiell: Die Produktion von Feedback und sogar Bewertungen auf Lernleistungen ist stets Gegenstand verfeinerter fachdidaktischer und p\u00e4dagogischer Expertise, systematischer Ausbildung und Trainings, sowie der Kultivierung zwischenmenschlicher Sensibilit\u00e4ten und F\u00e4higkeiten. Die Beurteilung der Qualit\u00e4t von automatisch (oder auch nicht automatisch) produzierten R\u00fcckmeldungen und Bewertungen ist somit eine normativ hochgradig investierte und mitunter umstrittene Frage. Man wird sie nicht angehen k\u00f6nnen, ohne implizit oder explizit ein Verst\u00e4ndnis davon zugrunde zu legen, was \u00fcberhaupt \u201cgutes\u201d und \u201cangemessenes\u201d Feedback und eine \"gute\" und \u201cangemessene\u201d Bewertungspraxis ist. In diese Debatten m\u00f6chten wir mit dieser Untersuchung jedoch nicht einsteigen denn eine allgemeing\u00fcltige und hinreichend leicht operationalisierbare Antwort hierauf zu finden erscheint uns vermessen und aussichtslos.\nWir beschr\u00e4nken uns deshalb darauf, nach offensichtlichen Unzul\u00e4nglichkeiten des Korrekturtools zu suchen. Damit meinen wir Inkonsistenzen, die bei allen Differenzen um didaktische und p\u00e4dagogische Methodologie mehr oder weniger unumstritten als Mankos aufgefasst werden. Wir untersuchen also nicht, ob das Korrekturtool gutes oder angemessenes Feedback produziert, sondern nur, ob es \u00fcberhaupt die Mindestvoraussetzungen daf\u00fcr erf\u00fcllt. Im Umkehrschluss hei\u00dft das nicht, dass wenn alle hier angef\u00fchrten \"Fehler\" des Tools behoben w\u00e4ren, sein Einsatz automatisch empfehlenswert ist. Bei den im Folgenden angef\u00fchrten Punkten handelt es sich nur um offensichtliche Missst\u00e4nde, durch die das Tool den notwendigen Mindeststandard f\u00fcr einen realen Einsatz verfehlt. Die Behebung dieser Missst\u00e4nde ist eine notwendige, aber keine hinreichende Voraussetzung, den Einsatz des Korrekturtools bef\u00fcrworten zu k\u00f6nnen.\nTechnisch: Das Korrekturtool von Fobizz basiert auf dem gro\u00dfen Sprachmodell GPT-4 von OpenAl, das auch in dem bekannten Chatbot \u201cChatGPT\u201d zum Einsatz kommt. Es liegt in den technischen Eigenschaften solcher Chatbotsysteme begr\u00fcndet, dass die \"Antworten\u201d auf \u201cPrompts\" randomisiert werden, also nicht-deterministisch durch den Prompt bestimmt sind. Das bedeutet: Mehrfache Wiederholung desselben Prompts f\u00fchrt zu mehr oder weniger stark unterschiedlichen Antworten, weil Zufallsfaktoren in die Verarbeitung einbezogen werden. Diese technische Eigenschaft, die von ChatGPT gut bekannt ist und leicht selbst reproduziert werden kann, f\u00fchrt zu dem methodologischen"}, {"title": "III. Ergebnisse", "content": "Wie in Abschnitt II erl\u00e4utert, beschr\u00e4nken wir uns in dieser Untersuchung bewusst auf die Beobachtung solcher Unregelm\u00e4\u00dfigkeiten, die nicht von einer bestimmten didaktischen Auffassung in Bezug auf eine gute Bewertungspraxis abh\u00e4ngig sind. Das hei\u00dft, wir stellen lediglich objektive Funktionsdefizite des Korrekturtools heraus, die bereits vor einer didaktischen Beurteilung stehen und \u00fcbergreifend anzuerkennen sind.\nTestreihe A\n1. Zuf\u00e4lligkeit von Bewertungen und R\u00fcckmeldungen\na. Zuf\u00e4lligkeit der vorgeschlagenen Gesamtnote\nTestreihe A umfasste die f\u00fcnfmal wiederholte Erstellung einer Bewertung f\u00fcr jede der 10 exemplarischen Abgaben zu unserer Aufgabenstellung. Diese Methodologie gestattet es, das Tool hinsichtlich Konsistenz und Robustheit von Feedback und Bewertungen hin zu untersuchen.Abbildung #fig:E:volatilit\u00e4t visualisiert das f\u00fcr jede der Abgaben (X-Achse) resultierende Spektrum der empfohlenen Gesamtbewertung.\nb. Zuf\u00e4lligkeit der inhaltlichen Bewertung und qualitativen R\u00fcckmeldung\nNicht nur die numerische Benotung hat sich im Vergleich der Korrekturdurchl\u00e4ufe als stark schwankend erwiesen; selbes ist auch f\u00fcr die qualitative Bewertung und W\u00fcrdigung zu beobachten. Die durch das Korrektur-Tool erstellte Bewertung enth\u00e4lt immer einen Abschnitt \u201cGesamtbewertung\u201d, welcher das Feedback summarisch zusammenfasst. Abbildungen #fig:E:6-3 und #fig:E:6-4 zeigen exemplarisch diese Abs\u00e4tze f\u00fcr Abgabe Nr. 6, Korrekturdurchl\u00e4ufe 6.3 und 6.4.\n2. Unzuverl\u00e4ssige Erkennung inhaltlicher Defizite\na. Falschbehauptungen\nUnsere simulierten Sch\u00fcler:innen-Abgaben enthielten teilweise simple inhaltliche Fehler. So hat beispielsweise Text 5 behauptet, das Wahlalter f\u00fcr die Europawahl sei k\u00fcrzlich auf 14 Jahre abgesenkt worden (Abbildung #fig:E:5-2).\nb. Nonsense, Arbeitsverweigerung, Thema verfehlt\nDrei unserer Simulierten Abgaben stellen Arbeitsverweigerungen oder Verfehlungen des Themas dar: Abgabe 3 (Gesamtbewertung zwischen 9 und 12 Punkte) begr\u00fcndet eine der Positionen mit der Meinung der Oma. Abgabe 7 (Gesamtbewertung zwischen 8 und 9 Punkte) umfasst nur rund ein Drittel der geforderten Mindestwortzahl und f\u00fchrt als Hauptargument gegen die Absenkung des Wahlalters aus, dass 14-J\u00e4hrige noch nicht so gut Kreuze setzen k\u00f6nnen wie Erwachsene. Abgabe 8 (Gesamtbewertung zwischen 1 und 14 Punkte) verfehlt das Thema, indem von einem Schwimmbadbesuch erz\u00e4hlt wird.\n3. Unzuverl\u00e4ssige Umsetzung einzelner Bewertungskriterien\nDas Korrekturtool bietet eine freie Eingabem\u00f6glichkeit f\u00fcr Bewertungskriterien (siehe Abbildung #fig:T:kriterien) durch die Lehrkraft, inklusive relativer Gewichtung der Kriterien f\u00fcr die Gesamtnote. So wirbt Fobizz in einer Video-Anleitung zum Korrekturtool explizit mit der M\u00f6glichkeit, nach Belieben eigene Bewertungsketgorien einzusetzen. Die Umsetzung und Ber\u00fccksichtigung dieser Kriterien bei der Bewertung ist allerdings unzuverl\u00e4ssig und intransparent, wie die folgenden Beobachtungen zeigen.\na. Textl\u00e4nge als Kriterium\nUnsere exemplarische Aufgabenstellung enth\u00e4lt einen vorgegebenen Wortumfang von 150 bis 250 W\u00f6rtern und wir haben die Befolgung als ein Bewertungskriterium eingestellt (siehe Abbildung #fig:T:kriterien). Unter den zehn exemplarischen Abgaben gibt es f\u00fcnf, deren Wortumfang au\u00dferhalb der vorgegebenen Grenzen liegt: 2, 7 und 8 sind zu kurz; 4 und 6 sind zu lang (siehe Tabelle #tab:T:A). Bei den Abgaben 2, 7 und 8, also bei den zu kurzen Texten, wurde daf\u00fcr in s\u00e4mtlichen Korrekturdurchl\u00e4ufen eine niedrigere Bewertung gegeben; die Bewertungen reichten hier von 30% bis\nb. Kl-generierte Abgaben erkennen\nZu den von uns eingestellten Bewertungskriterien geh\u00f6rte auch die Kategorie \"Nicht von KI geschrieben\", um \u00fcberpr\u00fcfen zu lassen, ob der Text unter Zuhilfenahme von KI-Tools wie ChatGPT erstellt wurde. Bekannterma\u00dfen ist die automatisierte Erkennung von Kl-generierten Texten ein ungel\u00f6stes Problem. Auch Fobizz erkl\u00e4rt in einem Blogpost auf seiner Webseite, dass so eine Erkennung nicht m\u00f6glich ist. Wenn jedoch eine Nutzer:in, wie wir es getan haben, \"Nicht von KI geschrieben\" in die freie Liste von Bewertungskriterien einf\u00fcgt, dann erzeugt das Tool ohne entsprechenden Hinweis ein Feedback, in dem das Bewertungskriterien aufgef\u00fchrt und mit einer Teilnote versehen wird. Das Feedback suggeriert damit, dass in dieser Kategorie wirklich eine Beurteilung vorgenommen wurde. In unseren Tests liegt die Bewertung in dieser Kategorie in allen 50 Durchl\u00e4ufen bei 100%, versehen mit einem Kommentar, dass der Text authentisch und nicht von einer KI generiert worden sei (siehe exemplarisch Abbildung #fig:E:9-3 f\u00fcr den Durchlauf 9.3). Dies wird auch bei Text 9 behauptet, der tats\u00e4chlich mithilfe von ChatGPT erstellt wurde.\n4. Inkonsistentes Feedback\na. Uneinheitliche und zuf\u00e4llige Bezeichnung von Fehlerkategorien\nDie Zuordnung der erkannten Fehler zu jeweils einer Fehlerkategorie (dritte Spalte der tabellarischen Auflistung \"Fehlerliste\u201d, siehe Abbildung #fig:E:bewertung) ist ein integraler Bestandteil des automatisch generierten Feedbacks. Dabei f\u00e4llt im Vergleich verschiedener Korrekturdurchl\u00e4ufe nicht nur die uneinheitliche Benennung der dritten Spalte dieser tabellarischen Ausgabe auf (\"Fehlerart\u201d, \"Fehlertyp\"), sondern viel mehr noch eine stark variierende Benennung der Fehlerkategorien. Anhand der Sichtung von 50 Bewertungen haben wir die folgenden Benennungen von Fehlerkategorien extrahiert. Die unten vorgeschlagene Clusterung der Benennungen bildet Synonym-Cluster, aus denen das Korrektur-Tool bei jedem Durchlauf ohne erkennbares Prinzip, also scheinbar zuf\u00e4llig, einen Begriff ausw\u00e4hlt.\nb. Fehler, die keine sind\nDie automatisch erstellte Bewertung des Korrektur-Tools enth\u00e4lt stets eine tabellarische Auflistung von Fehlern, bestehend aus den Spalten \"Fehler\", \"Korrektur\" und \"Fehlerart\" (wobei die letzte Spalte nach keinem erkennbaren Prinzip teilweise auch mit \"Fehlertyp\" \u00fcberschrieben ist). In 10 der 50 getesteten\nc. Widerspr\u00fcchliche Angabe der Gesamtnote\nWie beschrieben erw\u00e4hnt, enth\u00e4lt die automatisierte Bewertung immer einen Abschnitt \"Gesamtbewertung\", welcher unregelm\u00e4\u00dfig in einigen Durchl\u00e4ufen die vorgeschlagene Gesamtnote mit anf\u00fchrt und in anderen nicht (vgl. Abbildungen #fig:E:1-3 und #fig:E:1-4). Dieses inkonsistente Verhalten tritt noch in einer versch\u00e4rften Form auf, wenn die vorgeschlagene Gesamtnote mehrfach im Bewertungsdokument angef\u00fchrt wird (dies ist der Fall bei den Durchl\u00e4ufen 3.2, 3.3 und 6.3). In diesen F\u00e4llen kommt es mehrheitlich vor, dass die angegebene Gesamtnote innerhalb des Dokuments widerspr\u00fcchlich ist, die Note also nicht identisch wiederholt wird (dies ist der Fall bei 3.2 und 3.3, siehe exemplarisch Abbildung #fig:E:3-3).\nTestreihe B\n5. Die Umsetzung des Feedbacks f\u00fchrt nicht zur Verbesserung\na. Fehlende Monotonie bei der Einarbeitung von Vorschl\u00e4gen\nIn Testreihe B haben die Abgaben Nr. 1 und 10 einer Serie von Verbesserungen und automatisierten Bewertungen unterzogen: Beginnend bei der Originalabgabe haben wir stets die Verbesserungsvorschl\u00e4ge aus der Fehlerliste der automatisierten Bewertung umgesetzt und den Text dann neu bewerten lassen. Dies erfolgte \u00fcber 7-12 Iterationsstufen, wobei wir f\u00fcr die letzte Iterationsstufe den Text mittels des frei zug\u00e4nglichen und bei Sch\u00fcler:innen sehr beliebten KI-Tools \"ChatGPT\" von OpenAl haben verbessern lassen (was einer T\u00e4uschung gleichkommt).\nb. Irrfahrt-Charakter des qualitativen Feedbacks\nBereits dem Verlauf der numerischen Gesamtbewertung in Abbildung #fig:E:irrfahrt ist ein \"flatterhafter\" Charakter zu eigen - wir bezeichnen das als \"Irrfahrt\". Selbige Beobachtung gilt auch f\u00fcr das qualitative Feedback in Form der Fehlerliste und der Abschnitte \"Was du gut gemacht hast\" bzw. \"Was du verbessern kannst\". So ist im Verlauf der sukzessiven Umsetzung der Verbesserungsvorschl\u00e4ge stets ein Punkt zu erkennen, ab dem die R\u00fcckmeldungen \u201cim Kreis fahren\".\n6. Erreichbarkeit einer Bestbewertung nur durch Einsatz von ChatGPT (T\u00e4uschung)\nIn beiden Serien haben wir nach 7-12 Iterationen einen Punkt erreicht, an dem das weitere Einarbeiten der R\u00fcckmeldungen nicht sinnvoll zu sein schien, weil die R\u00fcckmeldungen zwischen zwei Optionen oszillierten (siehe vorherigen Punkt) und sich in marginalen Details festgebissen hatten. An diesem Punkt wurde f\u00fcr eine finale \u00dcberarbeitung ChatGPT verwendet, Abbildung #fig:E:chatgpt-prompt zeigt exemplarisch den daf\u00fcr in Fall von Text 1 verwendeten Prompt."}, {"title": "IV. Diskussion", "content": "Im Folgenden diskutieren wir die oben relativ technisch zusammengetragenen Beobachtungen hinsichtlich ihrer Auswirkungen auf den Bildungsalltag und ihrer Bedeutung f\u00fcr die Qualit\u00e4t und Benutzbarkeit des Korrekturtools. Dies gilt zugleich als eine \u00fcbersichtliche Zusammenfassung der beobachteten M\u00e4ngel. In einem folgenden Abschnitt werden wir herausstellen, dass nur die wenigsten der M\u00e4ngel eine technische L\u00f6sung erwarten lassen, w\u00e4hrend die meisten auf prinzipielle Limitationen von gro\u00dfen Sprachmodellen (LLMs) zur\u00fcckgehen."}, {"title": "V. Fazit", "content": "Das Lesen, Kommentieren und Bewerten von Aufs\u00e4tzen kostet Zeit, Geduld und Besonnenheit. Das Versprechen einer Zeitersparnis in diesem Bereich d\u00fcrfte deshalb einen neuralgischen Punkt bei vielen \u00fcber Monate an ihrer Belastungsgrenze arbeitenden Lehrkr\u00e4ften treffen. Aber l\u00e4sst sich diese T\u00e4tigkeit wirklich automatisieren? Immerhin umfasst Bewerten und Beurteilen mehr, als Rechtschreibfehler zu finden was jedes Textverarbeitungsprogramm durch einen mechanischen Abgleich mit einem W\u00f6rterbuch erledigen kann. Bewerten und Beurteilen erfordert in einem umfassenderen Sinne menschliches Urteilsverm\u00f6gen, didaktische Expertise und zwischenmenschliches Feingef\u00fchl. Aus all diesen Gr\u00fcnden ist die Automatisierung von Beurteilung und Bewertung ein mit besonderer Vorsicht zu genie\u00dfendes Wertversprechen auf dem Markt f\u00fcr KI-Angebote f\u00fcr Lehrkr\u00e4fte. All dies motivierte uns dazu, aus der Angebotspalette von Fobizz speziell die \"KI-Korrekturhilfe\" unter die Lupe zu nehmen.\n1. Die \"KI-Korrekturhilfe\u201d von Fobizz sollte im Schulalltag nicht eingesetzt werden\nUnsere empirische Untersuchung hat sich auf funktionale Mindestbedingungen f\u00fcr die Gebrauchstauglichkeit der Fobizz \"KI-Korrekturhilfe\" fokussiert und mehrere gravierende Beeintr\u00e4chtigungen gefunden (siehe Tab. #tab:D:gravit\u00e4t und Abschnitt III). Zu den gravierendsten M\u00e4ngeln geh\u00f6ren:\n(1) eine starke Zufallsabh\u00e4ngigkeit der numerischen Bewertung und der qualitativen R\u00fcckmeldung, was erst bei mehrfacher Wiederholung der automatisierten Bewertung f\u00fcr dieselbe L\u00f6sung erkennbar ist."}, {"title": "2. Kl in der Schule ist keine L\u00f6sung f\u00fcr den Lehrkr\u00e4ftemangel und Produkt eines gef\u00e4hrlichen gesellschaftlichen Trends", "content": "Unsere Untersuchung nimmt nur ein exemplarisches KI-Tool in den Blick. Mit der Automatisierung von Bewertung und R\u00fcckmeldung m\u00f6chte dieses exemplarische Tool ein zentrales Wertversprechen LLM-basierter KI-Systeme f\u00fcr den Bildungskontext einl\u00f6sen. Gerade weil viele der beobachteten M\u00e4ngel allerdings typisch f\u00fcr LLM-Systeme im Allgemeinen sind, ist es an dieser Stelle sinnvoll, den Blick wieder auf den gesellschaftspolitischen Kontext zu weiten und einige Verallgemeinerungen aus den exemplarischen Beobachtungen zu extrapolieren.\nDie gesellschaftliche Situation, in der KI-Tools f\u00fcr den Einsatz in der Schule angeschafft werden, ist wie in Abschnitt I geschildert durch Lehrkr\u00e4ftemangel, eine chronische \u00dcberlastung des Bildungssystems und der vorhandenen Lehrkr\u00e4fte, sowie unzureichende Finanzierung des Bildungssystems gekennzeichnet. In dieser Situation ist der Ruf nach k\u00fcnstlicher Intelligenz als schnelle L\u00f6sung der typische Fall eines \u201cTechno Fix\u201d im Sinne des \"Techno Solutionism\". Denn hiermit erfolgt die Verschiebung eines sozialen und politischen Problems in die Sph\u00e4re der Technologie - sozialpolitisches Versagen soll mittels Technik gel\u00f6st werden. Eine Industrie und spezialisierte Gesch\u00e4ftsmodelle stehen bereit, um solchen Gemengelagen Kapital zu schlagen, indem sie den oftmals weniger fachkompetenten politischen Entscheidungstr\u00e4ger:innen vordergr\u00fcndig innovative, aber ungetestete Produkte in einem experimentellen Entwicklungsstadium verkaufen. Der Fall der Fobizz \u201eKI-Korrekturhilfe\u201c l\u00e4sst sich mit einem Automobilhersteller vergleichen, der ein Auto ohne Bremsen und R\u00fcckspiegel auf den Markt bringt und sich erst nachtr\u00e4glich um Sicherheitstests und eine m\u00f6gliche T\u00dcV-Zulassung k\u00fcmmert."}]}