{"title": "Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts", "authors": ["Sukai Huang", "Nir Lipovetzky", "Trevor Cohn"], "abstract": "Large Language Models (LLMs) have shown promise in solving natural language-described planning tasks, but their direct use often leads to inconsistent reasoning and hallucination. While hybrid LLM-symbolic planning pipelines have emerged as a more robust alternative, they typically require extensive expert intervention to refine and validate generated action schemas. It not only limits scalability but also introduces a potential for biased interpretation, as a single expert's interpretation of ambiguous natural language descriptions might not align with the user's actual intent. To address this, we propose a novel approach that constructs an action schema library to generate multiple candidates, accounting for the diverse possible interpretations of natural language descriptions. We further introduce a semantic validation and ranking module that automatically filter and rank the generated schemas and plans without expert-in-the-loop. The experiments showed our pipeline maintains superiority in plan- ning over the direct LLM planning approach. These findings demonstrate the feasibility of a fully automated end-to-end LLM-symbolic planner that requires no expert intervention, opening up the possibility for a broader audience to engage with AI planning with less prerequisite of domain expertise\u00b9.", "sections": [{"title": "Introduction", "content": "The advent of Large Language Models (LLMs) has opened new avenues for solving natural language-described planning tasks (Kojima et al. 2022). However, direct plan generation using LLMs, while seemingly straightforward, has been criticized for inconsistent reasoning and hallucination, which undermines their reliability in critical planning sce- narios (Valmeekam et al. 2022, 2023; Huang et al. 2023). In response, researchers have advocated for more robust ap- proaches that combine the flexibility of LLMs with the cor- rectness of symbolic planning to solve planning tasks (Palla- gani et al. 2024; Oswald et al. 2024). To improve the sound- ness of generated plans, a hybrid LLM-symbolic planning pipeline has emerged. As shown in Figure 1, instead of re- lying solely on LLMs to generate sequences of action plans through in-context learning, this pipeline begins by lever- aging LLMs to extract abstract symbolic action specifica- tions from natural language descriptions, known as action schemas. These schemas define the essential components of an action in a structured format understandable by sym- bolic planners. Once these schemas are generated, a classical planner can take over to search for feasible plans that fulfill the task specifications (Liu et al. 2023; Silver et al. 2023; Guan et al. 2023; Kambhampati et al. 2024).\nYet, this method is brittle, as a single missing or contra- dictory predicate in an action schema can prevent the plan- ner from finding a valid plan. Thus, current pipelines of- ten require multiple iterations of expert intervention to re- fine and validate the generated action schemas. For instance, Guan et al. (2023) reported that the expert took 59 iterations to fix schema errors for a single task domain. This process demands substantial time and expertise, which significantly hinders the scalability of the method. More critically, due to budget constraints, often only one expert is involved in the process. This creates a critical vulnerability: the potential for interpretation mismatch between the expert and the user. Ex- perts, while knowledgeable, inevitably bring their own sub- jective interpretations to the task descriptions, often formal- izing them in a single, specific way. This limits the system to a single perspective of the task. However, unlike formal lan- guage designed to have an exact, context-independent mean- ing, natural language inherently contains ambiguities that yield diverse valid interpretations of the same description."}, {"title": "Related Work", "content": "Direct Plan Generation with LLMs: The use of LLMs for direct action plan generation has been explored across various domains, including embodied tasks (Wang et al. 2Sentence encoders are neural network models that transform sentences into dense vector representations, capturing semantic meaning\n2023; Xiang et al. 2024), and other language grounding en- vironments (Ahn et al. 2022; Huang et al. 2022). These ap- proaches are built upon the idea that LLMs' reasoning capa- bilities can be effectively elicited through in-context learn- ing techniques, particularly the Chain-of-Thought (CoT) ap- proach. CoT prompts the model to generate a series of in- termediate reasoning steps before arriving at the final an- swer, resulting in more coherent and logically sound rea- soning (Wei et al. 2022). Building upon CoT, Yao et al. (2024) proposed Tree-of-Thought (ToT) framework, which explores multiple reasoning pathways, generating diverse plans and ranking them based on self-verification heuristics. These heuristics are verbalized confidence scores produced by LLMs themselves, a method supported by studies show- ing that LLMs are effective as zero-shot ranking models (Lin et al. 2022; Hou et al. 2023; Zhuang et al. 2023).\nCriticism and Hybrid Planning: Despite the promising results, researchers have raised concerns about the reliability and soundness of LLM-generated plans (Valmeekam et al. 2022, 2023; Huang et al. 2023). A critical issue highlighted by Kambhampati et al. (2024) is that planning and reason- ing tasks are typically associated with System 2 compe- tency, which involves slow, deliberate, and conscious think- ing (Sloman 1996; Kahneman 2011). However, LLMs, be- ing essentially text generators, exhibit constant response times regardless of the complexity of the question posed. This behavior suggests that no first-principle reasoning is occurring, contradicting the expectations for true planning capabilities. To this end, researchers have explored hybrid approaches that utilize LLMs to generate symbolic represen- tations of tasks, which are then processed by external sym- bolic planners to search for feasible plans (Liu et al. 2023; Guan et al. 2023). However, existing pipelines emphasize the necessity of expert intervention for action schema val- idation and refinement. While Kambhampati et al. (2024) proposed using LLMs as semi-expert critics to assess output quality, this approach still necessitates expert involvement for final decision-making. In contrast, our work strives to re- duce the dependency on expert intervention, offering a more accessible approach to hybrid LLM-symbolic planning that also addresses the inherent ambiguity in natural language descriptions.\nAcquiring Action Models: It is important to acknowl- edge the rich body of work that has focused on acquiring symbolic action models before the advent of LLMs (Mourao et al. 2008; Aineto et al. 2019). Our approach introduces sig- nificant complexity due to the inherent ambiguity in natural language descriptions. However, it also offers greater acces- sibility, allowing users to describe domains without requir- ing specialized knowledge of planning formalisms."}, {"title": "Problem Setting and Background", "content": "We consider a scenario where an agent generates action plans for natural language-described planning tasks. A task description typically consists of: (1) a domain description outlining general task information and possible high-level actions, and (2) a problem instance description specify- ing the initial and goal states. The study of LLM-symbolic planning pipelines is grounded in the formal framework of"}, {"title": "Methodology", "content": "As illustrated in Figure 3, the proposed pipeline stands in contrast to existing expert-dependent approaches and con- sists of three key steps: (1) Building a Diverse Schema Li- brary (\u00a74.1), (2) Semantic Coherence Filtering (\u00a7 4.2) and (3) Plan Scoring and Ranking (\u00a7 4.4)."}, {"title": "Building a Diverse Schema Library", "content": "A key challenge in translating natural language descriptions into symbolic action schemas is the inherent ambiguity of language itself. Different interpretations of the same de- scription can lead to variations in action schemas, impacting"}, {"title": "Semantic Coherence Filtering", "content": "The previous method alone faces two limitations. First, as task complexity grows, the \"brute-force\" approach of com- bining and evaluating all possible sets becomes increasingly inefficient. Second, solvability does not guarantee semantic correctness \u2013 schemas may not accurately reflect the task descriptions, potentially leading to incorrect or nonsensical plans. Therefore, it is crucial to implement a filtering mech- anism that autonomously assesses the semantic correctness of individual action schemas, filtering out low-quality can- didates before they enter the combination process.\nOur approach is grounded in the concept of semantic equivalence across different representations of the same con- tent, as discussed by Weaver (1952) in his memorandum \"Translation.\" Weaver emphasized that the most effective way to translate between languages is to go deeper to un-"}, {"title": "Finetuning with Manipulated Action Schemas", "content": "Hard negative samples have been shown to enhance repre- sentation learning by capturing nuanced semantic distinc- tions (Robinson et al. 2023). In our context, we found that structured action schemas are particularly ideal for generat- ing hard negatives. By manipulating predicates in the pre- condition or effect expressions of true action schemas, we create hard negatives with subtle differences. During fine- tuning, a triplet loss function is employed, where each train- ing sample consists of a triplet: the natural language descrip- tion of an action (Z(a)), the true action schema (a), and a negative sample (aneg). A negative sample is of three types \u2013 (1) Easy Negatives: action schemas from other planning do- mains (inter-domain mismatch); (2) Semi-Hard Negatives: action schemas from the same domain but referring to dif- ferent actions (inter-domain mismatch); and (3) Hard Nega- tives: manipulated versions of the true action schema in the same domain (see Table 1)."}, {"title": "Plan Generation and Ranking", "content": "Action schemas that more accurately represent the intended tasks described in natural language are likely to yield higher- quality, more reliable plans. Leveraging this causal relation- ship, we assess and rank the generated plans based on the cumulative semantic similarity scores of their constituent ac- tion schemas. Specifically, we feed each solvable set of ac- tion schemas into a classical planner, which generates a cor- responding plan. Then, the ranking score for a plan is calcu- lated as \u03a3\u039ci=1 E(Z(\u03b1i)) E(\u03aci)\n||EZ(a))||||E(&)||, where Z(ai) is the natural language description of the i-th action in the domain and \u00e2\u2081 is the corresponding generated action schema. It ensures that the structured symbolic model comprising the plans are se- mantically aligned with the descriptions of the planning do- main (see step 3 in Figure 3). Furthermore, this approach al- lows for optional lightweight expert intervention as a final, non-iterative step. By presenting the ranked schema sets and their corresponding plans, experts can determine the most appropriate one, providing a balance between autonomy and expert guidance.\nOverall, our pipeline bridges the gap between ambiguous task descriptions and the precise requirements of symbolic planners. By generating a diverse pool of action schemas and leveraging semantic similarity for validation and rank- ing, we achieve two key advancements. First, we reduce the"}, {"title": "Experiments", "content": "Our experiments test the following hypotheses: (H1) Se- mantic equivalence across different representations, as dis- cussed by Weaver, holds true in our context. (H2) Ambi- guity in natural language descriptions leads to multiple in- terpretations. (H3) Our pipeline produces multiple solvable candidate sets of action schemas and plans without expert intervention, providing users with a range of options. (H4) Our pipeline outperforms direct LLM planning approaches in plan quality, demonstrating the advantage of integrating LLM with symbolic planning method."}, {"title": "Experimental Setup", "content": "Task and Model Setup. We introduces several key en- hancements that distinguish it from previous work. (1) Novel"}, {"title": "Semantic Equivalence Analysis", "content": "To investigate H1, we initially assessed the cosine similar- ity of sentence embeddings for matched and mismatched pairs of action schemas and natural language descriptions. We used two large-scale sentence encoders, text-embedding-International Planning Competition, a benchmark event for au- tomated planning systems using PDDL.\nBusiness school students with no prior knowledge of PDDL programming or computational logic"}, {"title": "Pipeline Performance and Efficiency", "content": "Our pipeline's performance and efficiency are highlighted through several key observations. Firstly, the use of action schema library effectively produces solvable action schema sets without requiring expert-in-the-loop, as demonstrated in Figure 7. Notably, deploying 10 LLM instances is suffi- cient to generate solvable schema sets for all test domains, supporting H3. Secondly, Figures 7 and 8 reveal a clear pat- tern: when confronted with inherently ambiguous layman descriptions from non-expert participants, our pipeline gen- erates a significantly increased number of distinct solvable schema sets (e.g., from 3419 to 8039 when LLM# = 10 w/o CP), thereby supporting H2. This phenomenon stems pri- marily from the varied selection of predicates in the action"}, {"title": "Human Evaluation on Plan Quality", "content": "To further validate our approach, we conducted a human evaluation comparing the top two plan candidates generated by our pipeline against those from the ToT framework and a gold-standard plan derived from the reference PDDL do- main model. Four expert assessors with extensive PDDL ex- perience ranked the plans based on their feasibility in solv- ing the given problems. The results, summarized in Table 3, clearly support H4.\nFor a deeper insight into our pipeline's capabilities, we specifically tested the Sussman Anomaly, a well-known planning problem that requires simultaneous consideration of multiple subgoals, as solving them in the wrong order can undo previous progress (see Figure 1). As shown in Table 4, ToT approaches using various LLMs, including state-of-the- art models like GPT-40, consistently fail to solve this prob- lem. The failure arises from the mistaken assumption that the first subgoal mentioned (i.e., placing book 1 on top of book 2) should be addressed first, leading to incorrect plans. Inter- estingly, GPT-3.5 and GPT-40 exhibited different behaviors"}, {"title": "Failure Case Analysis", "content": "Schema Set with No Plan Found: We encountered in- stances where no solvable action schema set was generated, primarily due to limitations in the LLM's reasoning capabil- ities. The use of open-source LLMs, while more accessible, may result in a lower success rate compared to more ad- vanced proprietary models like GPT-40. Specifically, with 7 LLM instances, we observed occasional failures of gener- ating solvable sets action schemas for the libraryworld and minecraft domains. Nevertheless, solvable schema sets were consistently obtained across all domains when the number of LLM instances was increased to 10 (see Appendix F for"}, {"title": "Conclusion", "content": "Existing methods for generating action schemas and plans in LLM-symbolic planning systems typically provide users with a single option. This limitation stems from the heavy reliance on expert intervention, which creates an efficiency bottleneck and risks introducing biased interpretations that misinterpret the true intention of a task. To address these challenges, we propose a novel 3-step pipeline that gener- ates multiple action schema and plan candidates, offering users a range of ranked options to choose from. Our findings demonstrate that a full end to end LLM-symbolic planner is possible without expert intervention, paving the way for de- mocratizing planning systems for a broader audience. One limitation in this work is the lack of direct evaluation meth- ods for assessing the quality of generated action schema sets. Metrics like \"bisimulation\" (Coulter et al. 2022) or \"heuris- tic domain equivalence\u201d (Oswald et al. 2024) require the generated schema sets to have the same action parameters as a predefined reference set. This approach doesn't suit our context, where action parameters are flexible and inferred in real-time from natural language descriptions. This high- lights the need for new evaluation metrics suited to such dy- namically generated action schema models."}, {"title": "Experimental Setup Details", "content": "This section consists of the following:\n\u2022 \u00a7E.1: Detailed natural language descriptions and reference PDDL models for the testing domains Libraryworld and Dun- geon.\n\u2022 \u00a7E.2: Details on the CO-STAR prompt engineering framework used for LLM prompt engineering.\n\u2022 \u00a7E.3: Prompt template used for generating action schemas, including how to structure few-shot learning examples in the prompt and how to obtain CoT reasoning examples automatically from advanced LLMs.\n\u2022 \u00a7E.4: Prompt template used for Tree-of-Thought direct LLM-based planning.\n\u2022 \u00a7E.5: Syntax correction process for the generated action schemas.\n\u2022 \u00a7E.6: LLM model configurations and training configurations for the sentence encoder model."}, {"title": "Testing Tasks Specifications", "content": "Domain Description: This domain is structured to allow organizing and managing books within a library setting. The actions and predicates support the movement of books between tables and shelves, ensuring that conditions like accessibility and the librarian's hands being free are met. Additionally, it includes managing book categories, shelf space, and check -out/return processes to reflect a more complex library system."}]}