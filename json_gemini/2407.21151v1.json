{"title": "Private Collaborative Edge Inference via Over-the-Air Computation", "authors": ["Selim F. Yilmaz", "Burak Has\u0131rc\u0131o\u011flu", "Li Qiao", "Deniz G\u00fcnd\u00fcz"], "abstract": "We consider collaborative inference at the wireless edge, where each client's model is trained independently on their local datasets. Clients are queried in parallel to make an accurate decision collaboratively. In addition to maximizing the inference accuracy, we also want to ensure the privacy of local models. To this end, we leverage the superposition property of the multiple access channel to implement bandwidth-efficient multi-user inference methods. Specifically, we propose different methods for ensemble and multi-view classification that exploit over-the-air computation. We show that these schemes perform better than their orthogonal counterparts with statistically significant differences while using fewer resources and providing privacy guarantees. We also provide experimental results verifying the benefits of the proposed over-the-air multi-user inference approach and perform an ablation study to demonstrate the effectiveness of our design choices. We share the source code of the framework publicly on Github to facilitate further research and reproducibility.", "sections": [{"title": "I. INTRODUCTION", "content": "The increasing adoption of Internet of Things (IoT) devices results in the collection and processing of massive amounts of mobile data at the wireless edge. Conventional centralized machine learning (ML) methods are impractical for edge applications due to privacy concerns and limited communication resources. Implementing decentralized ML models at the edge solves this issue, and thus, edge learning and edge inference have attracted significant attention over the recent years [2]-[6]. Edge learning aims to train large ML models in a distributed setting, whereas edge inference aims to make inferences in a distributed manner at the edge.\nAlthough collaborative training (e.g., federated learning (FL)) at the edge can bring significant advantages, it requires coordination and communication across nodes. Moreover, limited wireless resources are a major bottleneck, and noise, interference, and lack of accurate channel state information can prevent or slow down the convergence of learning algorithms or result in reduced accuracy [7]. Therefore, in this paper, we consider collaborative inference using independently trained models at the edge nodes. While a growing body of work studies distributed training over wireless networks, the literature on distributed wireless inference, particularly using deep learning techniques, is relatively limited [8]-[10]. Moreover, beyond a few exceptions, such physical factors affecting edge inference have not been explored in the literature [2].\nWe treat the resultant problem as a collaborative edge inference problem, where the individual hypotheses of the clients need to be conveyed to the central inference server (CIS), and combined for the most accurate decision. Moving sensing to the edge reduces latency and improves privacy since it removes the requirement to communicate the data or the models. Often the data is not accumulated at a single client or cannot be shared between clients due to privacy or latency constraints. When data offloading or collaborative training are not possible, locally trained models are suboptimal and a collaborative inference solution is needed that incorporates the decisions at different clients. We, therefore, introduce a distributed inference solution that incorporates all the data and models while limiting privacy leakage during inference time through differential privacy (DP) guarantees.\nPrivacy is an important concern in all ML applications since the data used for training can reveal sensitive information about their owner. In the case of ensemble inference, when the models are queried, their outputs may reveal sensitive information about their training sets. For instance, even when an adversary has black-box access to a model, whether or not a data sample is used during training can be inferred via membership inference attacks [11], or even the whole model can be reconstructed via model inversion attacks [12]. Hence, even if adversaries can only observe the inference results, we need to introduce some additional mechanisms to protect the sensitive information. \nDP guarantees can be obtained by introducing additional randomness to the output, such as adding noise, at the expense of some accuracy loss. Since DP bounds the amount of information leaked about the individuals, DP mechanisms make black-box attacks less effective. One approach to provide DP guarantees to ML is differentially private training [13]."}, {"title": "A. Contributions", "content": "The main contributions of our work are summarized as follows:\n1) We introduce a novel distributed inference framework at the wireless edge that exploits OAC while providing bandwidth efficiency and variability. To the best of our knowledge, the conference version of this paper [1] was the first in the literature to exploit OAC for distributed inference.\n2) We provide flexible privacy guarantees depending on the scenario without imposing any restrictions on the training phase.\n3) We systematically compare and discuss the privacy of the introduced collaborative classification methods, and show that the proposed framework with OAC performs significantly better than its orthogonal and digital counterparts while using fewer wireless resources under privacy constraints. We also provide statistical significance tests to show the reliability of the obtained results.\n4) To facilitate further research and reproducibility, we publicly share the source code of our framework on github.com/ipc-lab/collaborative-inference-oac."}, {"title": "B. Organization of This Article", "content": "The rest of the article is organized as follows. In Section II, we describe related works from wireless communications and machine learning literature. In Section III, we define distributed inference problem over a MAC and describe our threat model and target problem. In Section IV, we introduce our novel distributed inference method for the wireless edge that exploits the superposition property of MAC. In Section VI, we demonstrate the performance and bandwidth gains of our introduced methodology. We conclude our work in Section VII."}, {"title": "II. RELATED WORK", "content": "A. Distributed Inference at the Edge\nFor IoT and Internet of Everything (IoE) applications, moving inference from cloud to edge can be desirable or needed in both static and dynamic environments [2]. Static environments, e.g., surveillance cameras or sensor networks, might desire edge inference due to latency and privacy constraints [26], [27]. Dynamic environments are even more challenging with the same demands due to their high mobility. In both static and dynamic environments, edge devices can even generate data faster than their upload speed to the cloud, which makes it impossible to employ a cloud-centric solution while utilizing all the data [2].\nEdge inference in dynamic environments, such as the ones including self-driving cars, drones and mobile phones, might require adaptive solutions due to latency, privacy, and accuracy constraints [2], [4], [28], [29]. In a collaborative system, client participation depends on the privacy, security, energy and utility requirements [30], [31]. Clients may choose not to participate due to various reasons such as (1) hardware failures, (2) to reduce or balance the power consumption, (3) to prevent accuracy drop of the CIS due to noisy data receipt or unconfident local prediction, (4) to prevent leakage to possible eavesdroppers, (5) to prevent transmission over a low-quality wireless channel, and (6) to improve DP guarantees. In this study, we focus on amplifying DP guarantees by random participation.\nB. OAC for FL\nFL [32] has found applications in many areas including, but not limited to, finance [33], medicine [34], [35] and wireless communications [36]\u2013[38]. In FL, multiple devices are coordinated by a central server to train a shared neural network model. FL lifts the requirement to communicate data samples, i.e., the data stays at local devices, and allows collaborative training to benefit from distributed local data samples. OAC has been shown to have a considerable amplification effect on DP thanks to the natural aggregation of multiple model updates and the channel noise over the wireless medium. Such an amplification effect of OAC has been studied previously in several works providing better convergence, privacy and accuracy for FL [21]-[25]. However, this framework assumes model training among physically colocated nodes, which may limit its practical applicability since such collaborative training may require an enormous amount of communication and computation resources. Instead, in this paper, we focus on edge inference with relatively simpler models that are trained independently.\nC. OAC for Edge Inference\nFollowing our initial work [1], OAC has been adopted to multi-device edge inference in several studies [39]\u2013[42]. Specifically, in [39]\u2013[41], feature vectors are extracted at multiple local devices and transmitted via OAC, then the neural network employed at the server performs inference based on the superposed feature vectors. Due to observations from multiple devices, the server can achieve better inference results. Moreover, power allocation, transmit precoding, and receive beamforming are optimized to maximize the inference-oriented criterion in [39] and [40]. In addition, contrastive learning has been used to exploit feature correlations among devices to maximize the image retrieval accuracy in [41]. The authors of [42] proposed an OAC-based multi-view pooling technique to improve classification accuracy with less communication latency. However, to the best of our knowledge, only [1] and the current paper consider the privacy aspects of distributed edge inference.\nD. Ensemble and Multi-View Classification\nEnsemble learning methods combine multiple hypotheses instead of constructing a single best hypothesis to model the data [43]. In ensemble learning, each hypothesis votes for the final decision, where votes can have weights depending on their confidence. It is generally intractable to find the optimal hypothesis, and choosing a model among a set of equally good models has the risk of choosing the model that has worse generalization performance; however, averaging these models would reduce this risk [43], [44]. Furthermore, weighted or voting-based ensemble methods have theoretical guarantees; for example, it can be shown that the expected error of an averaging ensemble of models is not greater than the average of the expected errors of individual models with a mean square objective [44].\nEnsemble methods achieve higher accuracy when local models are diverse [45]. Our setting is similar to dagging [46], where individual models of the ensemble are trained on disjoint datasets. Dagging is a very similar technique to the well-known bagging [47], with the difference in disjoint training subset sampling like ours instead of sampling with replacement. We employ models trained on disjoint datasets due to the nature of our target problem, which improves the diversity and privacy of the local models.\nMulti-view classification deals with multiple feature perspectives, e.g., different views of the same scene, while ensemble classification performs classification on the same whole instance. Both approaches aim to improve the classification performance. In multi-view classification, the inputs are often correlated, and therefore the aim is to utilize these correlations among different views [48]. \u03a4\u03bf fuse information from other modalities or views, data-level, feature-level or decision-level fusion techniques have been commonly employed [49], [50]. Among them, decision-level fusion does not require any data or feature sharing between models, and therefore improves latency and privacy. For this purpose, decision-level fusion is a commonly employed technique while benefiting from the local models or datasets of individual clients.\nAveraging, weighted averaging and voting are common methods for decision-level fusion [43]. Weighted averaging is more general than simple averaging and voting as these methods are special cases of weighted averaging. Various empirical studies show that simple averaging is not worse than weighted averaging [51], [52]. Yet, in general, weighted averaging is a better choice when individual models have significantly different performances on the target task [53]. Simple averaging can be a better choice when individual models have similar performances since weights need to be determined, and they may not be reliable due to noise and insufficient amount of data [53]."}, {"title": "III. SYSTEM MODEL AND PROBLEM DEFINITION", "content": "A. Notation\nUnless stated otherwise; boldface lowercase letters denote vectors (e.g., p), boldface uppercase letters denote matrices (e.g., P), non-boldface letters denote scalars (e.g., p or P), and uppercase calligraphic letters denote sets (e.g., P). Blackboard bold letters denote function domains (e.g., P). R, N, C denote the set of real, natural and complex numbers, respectively. P denotes the cardinality of set P. We define [n] = {1, 2, \u2026\u2026, n}, where n \u2208 N\u207a.\nB. System Model\nWe consider privacy-preserving multi-user classification at the wireless edge for both ensemble and multi-view cases. In our model, we consider n clients each with a separate model $f_i : \\mathbb{R}^l \\rightarrow \\mathbb{R}^k, i \\in [n]$, trained on dataset $D_i \\subset D$ for either a multi-class or a binary classification task, where $D = \\bigcup_{i \\in [n]} D_i$, and $D_i \\cap D_j = \\emptyset$ for clients $i \\neq j$. Each client also has access to a common validation dataset $D_{val}$.\nA new query to be classified arrives at each timestep t, and all clients receive a view of the query, $x_{i,t} \\in \\mathbb{R}^l$. Then, each participating client makes an inference with its local model denoted by $f_i(x_{i,t}) \\in \\mathbb{R}^k$ and then encodes it into d channel symbols, which is the total available bandwidth per query."}, {"title": "IV. METHODOLOGY", "content": "In this section, we gradually introduce the modules of our framework."}, {"title": "A. Fusion Methods", "content": "In the following, we present alternative methods to perform local prediction for participating clients, having received the query $x_{i,t}$.\nLet $r_{i,t} \\in \\mathbb{R}^k$ be a vector containing classifier scores (beliefs) for each class at client i for the sample received at time slot t, where k is the number of classes, and the jth element of $r_{i,t}$, denoted by $(r_{i,t})_j$, contains the score for class j. We normalize the sum of the scores in $r_{i,t}$ to 1, i.e., $||r_{i,t}||_1 = 1$, and hence, the maximum possible score of a class is 1.\nWe now present three different models to be used as $f_i$: belief averaging with OAC (BA-OAC), weighted belief averaging with OAC (WBA-OAC), majority voting with OAC (MV-OAC).\nBA-OAC method averages beliefs of the participating clients for all the classes, and the CIS selects the class with the highest total score. Thus, it uses the following model for client i:\n$\\qquad f_i(x_{i,t}) = r_{i,t}.$   (3)\nWBA-OAC method employs normalized weighted average of the beliefs of the participating clients by class-wise accuracy. Then, similarly to BA-OAC, the CIS selects the class with the highest total score. Therefore, it uses the following function at every client i:\n$\\qquad f_i(x_{i,t}) = w_i \\odot r_{i,t},$   (4)\nwhere $w_i \\in \\mathbb{R}^k$ is a vector containing normalized per-class accuracy on $D_{val}$ for client i satisfying $||w_i||_1 = 1$, and $\\odot$ denotes the element-wise multiplication.\nDefinition 1. OneHot(j, l) function outputs an l-dimensional one-hot vector for $j \\leq l$, where only the $j^{th}$ dimension is 1 and the rest are 0.\nMV-OAC method allows participating clients to vote for a class and the CIS selects the class with the highest number of votes. Hence, at client i, we have\n$\\qquad f_i (x_{i,t}) = OneHot\\Big(arg \\underset{j \\in [k]}{max} (r_{i,t})_j, k\\Big).$   (5)\nWhile BA-OAC and WBA-OAC combine local discriminative scores, MV-OAC combines predicted labels. We then apply mean centering by subtracting $\\overline{f_i(x_{i,t})}$'s mean, which is $\\overline{(f_i(x_{i,t}))} = \\frac{1}{k}, \\forall j \\in [k]$, for MV-OAC, i.e.,\n$\\qquad f_i (x_{i,t}) = f_i(x_{i,t}) - \\overline{f_i(x_{i,t})}.$   (6)"}, {"title": "B. Ensuring Privacy", "content": "Next, we explain how we make our inference procedure privacy-preserving by introducing some randomness. First, we formally define DP for our ensemble inference task.\nLet L, L' \u2208 L be the sets of local models of the clients, which differ at most in one of the clients, i.e., $L = \\{f_j\\} \\cup \\{f_i : i \\in [n] \\backslash j\\}$ and $L' = \\{f'_j\\} \\cup \\{f_i : i \\in [n] \\backslash j\\}$ such that $f_j \\neq f'_j$ and L is the set of all possible local models of n clients. Such L and L' are called neighbouring sets. In our case, since we aim to protect the local models' privacy against CIS, we require that the CIS cannot distinguish between L and L' by observing $z_t$. Hence, the DP guarantees considered in the paper are all local-model-level DP, i.e., the replacement of one client's local model with another model does not generate a distinguishable effect on the observation of the CIS.\nLocal-model-level privacy guarantees might seem too conservative, but besides protecting against inferring sensitive features of the local datasets, local-model-level privacy provides protection against model stealing attacks, i.e., the CIS will not be able to accurately reconstruct the local model parameters.\nNext, we formally define the notion of DP which characterizes the indistinguishability of $z_t$ against the local model sets L and L'. For this, for a clearer notation, let us consider the signal observed by the CIS, $z_t$, as the output of a randomized function $M(X_t, L)$, which represents all the local prediction, randomization and transmission phases, where $X_t \\in \\mathbb{R}^{l\\times n}$ is the matrix whose $i^{th}$ column represents the query received by client i.\nDefinition 2. Consider the signal observed by the CIS, $z_t$, as the output of a randomized function $M : \\mathbb{R}^{l\\times n} \\times L \\rightarrow \\mathbb{R}^d$ and let L and L' be two possible neighbouring model sets. For $\u03b5 > 0$ and $\u03b4 \u2208 [0,1)$, M is called (\u03b5, \u03b4)-DP if\n$\\qquad Pr(M(X_t, L) \\in R) \\leq e^\\epsilon Pr(M(X_t, L') \\in R) + \\delta, \\qquad$(7)\nfor all neighboring pairs (L, L'), $\\forall X_t \\in \\mathbb{R}^{l \\times n}$ and $R \\subset \\mathbb{R}^d$.\nIn the above definition, \u03b5 indicates the amount of privacy loss and hence, smaller \u03b5 implies a stronger privacy guarantee. On the other hand, \u03b4 characterizes the failure probability of this guarantee, i.e., bad events in which $Pr(M(L) \\in R) \\leq e^\\epsilon Pr(M(L') \\in R)$ does not hold. Hence, \u03b4 should be close to zero for a strong privacy guarantee. For further discussion on the meaning of \u03b5 and \u03b4, and the techniques for appropriately choosing them, we refer the readers to [54]\u2013[56].\nTo achieve DP guarantees, the output released to an adversary should be randomized. In our paper, we consider releasing a noisy version of model outputs, $f_i(x_{i,t})$, for each client by adding Gaussian noise [57]. Each client can generate a noisy version of its model prediction as follows:\n$\\qquad g_i(x_{i,t}) = f_i(x_{i,t}) + m_{i,t},$   (8)\nwhere $m_{i,t} \\sim N(0, \\sigma_{client}^2 I_k)$. One of the main advantages of OAC is that the noise terms added by different clients are automatically aggregated at CIS. Thus, it has a further privacy amplification effect. We provide the analysis of the privacy guarantees achieved by our framework in Section V. This analysis reveals that DP guarantees are directly dependent on the variance of the aggregated noise at the CIS. Hence, to obtain DP guarantees, each client should add a Gaussian noise with $\\sigma_{client}^2 = \\sigma^2/|P_t|$, where $\u03c3^2$ is a constant depending on the desired DP guarantees and Pt is the set of participating clients. Hence, we assume that the number of participating clients is known by the other participating clients, but is secret from the CIS.\nRemark 3. Note that in OAC, $z_t$ already has channel noise that provides some degree of privacy guarantees, which can even be amplified by fading [23]. However, to achieve the desired level of DP, channel noise power may not be sufficient. First of all, channel noise may not follow a Gaussian distribution in practice (which is often used as worst-case assumption for channel capacity). More importantly, the clients cannot control or reliably know the noise variance or channel gain, as they rely on the CIS for this information. Thus, it is not a reliable source of randomness [21], and we ignore the channel noise and fading while analysing privacy guarantees. Instead, we have each client add some additional Gaussian noise before releasing their contributions. Hence, in reality, the privacy guarantees are slightly better than the ones we obtain in this work due to the presence of additional channel noise. If we were not ignoring the channel noise, each client would need to add less noise to the decision vectors, i.e., noise variance of $(\\sigma^2 - \\sigma_n^2)/|P_t|$ would suffice instead of $\\sigma^2/|P_t|$.\nWe discuss the DP guarantees of our method in Section V. In the next section, we describe the transmission method of the clients."}, {"title": "C. Transmission", "content": "Before transmission, all the clients check whether they participate or not at time t. That is, each client participates with probability p independent of other clients. If no client participates at time t, which has a very low probability, then the clients repeat the coin tosses for their participation until at least one client participates, i.e., until $|P_t| > 0$. Therefore, each client needs to know the number of participating clients at time t, i.e., $|P_t|$. Clients can decide on the number of participating clients and their identities via a procedure that is unknown to the CIS. Such a procedure is possible without any communication via common randomness, i.e., by choosing the participating clients depending on a pseudo random variable generated by a common seed. Note that such protocol is not possible when we want participation to depend on the channel states.\nFurthermore, we use linear projection before transmission to adapt to the available bandwidth d. When the number of classes k is smaller than d, it is reasonable to employ the whole bandwidth to improve the transmission quality against channel noise. However, the number of classes k can be much larger than d, e.g., the number of labels ranges from thousands to billions in extreme classification problems [58], [59]. In this case, to enable latency critical applications [60], it is better to project the decision vector $g_i(x_{i,t}) \\in \\mathbb{R}^k$ to a d-dimensional space to reduce the bandwidth, albeit with lower reliability. Therefore, for more generality, we adopt a linear projection of the decision vector $g_i(x_{i,t}) \\in \\mathbb{R}^k$ to dimension d.\nOur objective is to recover the superposition of projected signals at the CIS with the least error possible, while we can expand or collapse the bandwidth. In particular, we employ the same projection matrix $P \\in \\mathbb{R}^{d \\times k}$ at all the clients to produce d-dimensional transmit vectors. To generate P, we first sample $M \\sim N (0_c,I_c)$, where $c = \\{d, k\\}$. Then, we apply QR factorization to M using the procedure in [61] to generate an orthogonal matrix Q as:\n$\\begin{array}{l}Q', R = QRFactorization (M), \\d = Sign (Diagonal (R)), \\Q = d \\cdot Q,\n\\end{array}$\nwhere Diagonal of the input matrix, and Sign replaces negative elements with -1 and positive elements with +1. Then, we select the first d rows and k columns as $P = Q_{1:d,1:k}$. Since the CIS is only interested in the final decision, it only needs to pinpoint the maximum value of the superposed decision vector rather than estimating the entire decision vector. In addition, most of the clients may make the same decision; hence, it is feasible to identify the maximum value even when $d < k$.\nRemark 4. Any orthogonal matrix can be used instead of Q. When d < k, P can also be designed as a matrix. e.g., a Gaussian or Bernoulli random matrix, that satisfies the restricted isometry property of compressed sensing [62].\nWe need to make sure that each client's noisy decision vector $g_i(x_{i,t})$ is received at the CIS at the same power level. Recall that the channel gain for each client is assumed to be perfectly known by that client, which then employs channel inversion to cancel its effect. Thus, each client scales its signal by $1/h_{i,t}$ prior to transmission. Note that, since a client does not participate in the inference process if its channel has a low gain, this scaling does not result in excessive power usage. The CIS may require a specific power level for the reception of the signals depending on the available power of the clients or the channel's power constraint. Typically, an average power constraint is imposed. We satisfy the average power constraint in Eq. (2) by scaling via \u03b3, whose calculation is provided in Section IV-E. Lastly, we normalize by $|P_t|$ so that the receiver receives the average of all the users.\nAfter these steps, the signal transmitted by the $i^{th}$ client is given by\n$\\qquad y_{i,t} = \\begin{cases} \\frac{P \\gamma \\frac{g_i(x_{i,t})}{||g_i(x_{i,t})||_2}}{P_t h_{i,t}}, & \\text{if } i \\in P_t, \\\\0, & \\text{otherwise,}  \\end{cases}$   (9)\nwhere $P_t$ is the set of participating clients.\nNow, all participating clients transmit their signals synchronously over a MAC. Thanks to the common randomness, it is reasonable to assume that multiple clients are symbol-level synchronized as in [17] and [18]. Hence, their signals are superposed at the CIS. If there exists synchronization errors, various approaches have been discussed in [20], [63] to acquire an estimation of the superposed signal at the CIS."}, {"title": "Algorithm 1 OAC-Based Private Collaborative Inference", "content": "Input: Trained client model $f_i(\u00b7)$ for every client i, CIS model s(\u00b7), new samples $x_{i,t}$ $\\forall$i $\\in$ [n] at timestep t\nOutput: Index of the decided class\n$\\textbf{function}$ PRIVATE$\\_$COLLABORATIVE$\\_$INFERENCE\n Let Pt contain each client i with probability p, determined via a common seed among clients.\n $\\textbf{for}$ all client i $\\in$ Pt in parallel $\\textbf{do}$\n  Client i receives $x_{i,t}$\n  Calculate $f_i(x_{i,t})$  $\\triangleright$ Client Model\n  $g_i(x_{i,t}) = f_i(x_{i,t}) + N(0, \\sigma^2/|P_t|I_k)$  $\\triangleright$ Add noise\n  Transmit $y_{i,t} = \\frac{P \\gamma g_i (x_{i,t})}{||g_i(x_{i,t})||_2}/(|P_t| h_{i,t})$\n $\\triangleright$ Air Sum\n $Z_t = n_t + \\sum_{i\\in P_t}  g_i(X_{i,t})$\n CIS receives $z_t$\n $\\textbf{return} s(z_t)$  $\\triangleright$ CIS Model"}, {"title": "D. Final Decision by the CIS", "content": "The signal received by the CIS at time t after passing through the channel defined in Eq. (1) is given as follows:\n$\\qquad \\begin{aligned}z_t & = \\sum_{i\\in P_t} h_{i,t}y_{i,t} + n_t \\\\& \\stackrel{(a)}{=} \\sum_{i\\in P_t} h_{i,t} \\frac{P \\gamma \\frac{g_i(x_{i,t})}{||g_i(x_{i,t})||_2}}{|P_t| h_{i,t}} + n_t \\\\& \\stackrel{(b)}{=}  \\frac{P \\gamma}{|P_t|} \\sum_{i \\in P_t} (f_i(x_{i,t}) + m_{i,t}) + n_t \\\\& = \\frac{P \\gamma}{|P_t|} \\sum_{i \\in P_t} f_i(x_{i,t}) + \\frac{P \\gamma}{|P_t|} \\sum_{i \\in P_t} m_{i,t} + n_t,  \\qquad (10)\\end{aligned}$\nwhere (a) follows from Eqs. (8) and (9) and (b) follows from the linearity properties of the projection and scalars. After receiving $z_t$, CIS decision function $s(\u00b7)$ multiplies the received signal by $P^T$ to recover the desired signal, which is the average of votes, local beliefs or weighted local beliefs:\n$\\qquad \\begin{aligned}\\tilde{s} (z_t) &= P^T z_t\\\\& = \\frac{P^T P \\gamma}{|P_t|} \\sum_{i \\in P_t} f_i(x_{i,t}) + \\tilde{b}_t,  \\qquad (11)\\end{aligned}$\nwhere $\\tilde{b}_t \\sim N \\Big(0, \\frac{P^T P \\gamma^2}{||P_t||^2} + P^T P \\frac{\\gamma^2 \\sigma_{client}^2}{|P_t|} \\Big)$ is the accumulated noise due to privacy and wireless channel. Note that when $d \\geq k$, we have $P^T P = I_k$ due to the orthogonality property; and therefore, the CIS reconstructs the average of participating clients' score vectors along with some noise. Then, the CIS applies the arg max function to decide the most probable class, i.e.,\n$\\qquad s(z_t) = arg \\underset{j \\in [k]}{max} \\tilde{s} (z_t)_j.$   (12)\nAlgorithm 1 summarizes all the steps introduced in this section. In the next section, we derive the scaling factor \u03b3."}, {"title": "E. Determining the Scaling Factor", "content": "Here, we derive the scaling factor \u03b3 to normalize the prediction vectors with additional noise introduced due to privacy according to the average power constraint defined in Eq. (2). In our setting, each client i wants to transmit $\\gamma \\frac{P g_i(x_{i,t})}{||g_i(x_{i,t})||_2}$ to the CIS. For a clearer notation, we drop the time index for the rest of this subsection. To account for channel gains and to satisfy the average power constraint in Eq. (2), before transmitting $\\frac{g_i}{||g_i||}$, we scale it by $\\frac{\\gamma}{h_i}$, where \u03b3 is a scalar chosen to satisfy the average power constraint. In the following, we derive it in detail. For $i \\in [n", "Big[||y_i||^2\\Big": "E \\Big[\\frac{P \\gamma^2}{h_i^2  ||g_i(x_{i,t})||^2_2} \\Big"}, {"Big[||y_i||^2\\Big": "E \\Big[\\frac{\\gamma^2}{h_i^2} E  \\Big[||\\frac{P g_i(x_{i,t})}{||g_i(x_{i,t})||_2}||^2\\Big", "Big": "frac{\\gamma^2}{|P_t|^2}  E \\Big[\\frac{1}{h_i^2} \\Big"}, {"Big": "stackrel{(a)}{=} \\frac{\\gamma^2}{|P_t|^2  \\mu_{1/h}} E \\Big[||\\frac{P g_i}{||g_i||}||^2\\Big"}, {"Big": "triangleq \\mu_{1/h} &= \\int_{-\\infty}^{\\infty}  \\frac{1}{\\sqrt{2 \\pi \\sigma_h}} \\frac{1}{h_{min}} e^{-\\frac{x^2}{2 \\sigma_h^2}} d x\\\\& = \\frac{1}{\\sqrt{2 \\pi} \\sigma_h} \\int_{h_{min}}^{\\infty} \\frac{1}{h} e^{-\\frac{h^2}{2 \\sigma_h^2}} dh\\\\& = - \\frac{1}{\\sqrt{2 \\pi} \\sigma_h} \\int_{\\frac{h_{min}}{(\\sqrt{2} \\sigma_h)"}], "frac{p_i}{||p||})^2\\Big": "frac{\\gamma^2}{|P_t|^2  \\mu_{1/h}} P^2 \\frac{S_pi}{||S_p||_2^2},$   (16)\nRecall that $g_{pi} = P g_i(x_{i,t}) = P(f_i(x_{i,t}) + m_{i,t})$. Since $m_{i,t}$ consists of independent Gaussian random variables with variance $\\sigma_{client}^2$, we have\n$\\qquad \\frac{\\gamma^2}{|P_t|^2  \\mu_{1/h}} || \\frac{S_pi}{||S_p||_2} ||^2 = \\frac{\\gamma^2}{|P_t|^2  \\mu_{1/h}} (||P f_i(x_{i,t})|| + d \\sigma_{client}^2).$   (17)\nTo bound $||P f_i(x_{i,t})||$, first, let us consider $P \\in \\mathbb{R}^{d \\times k}$, where $d \\geq k$. In this case"}