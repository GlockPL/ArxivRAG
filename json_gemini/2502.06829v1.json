{"title": "Convolution-Based Converter : A Weak-Prior Approach For Modeling Stochastic Processes Based On Conditional Density Estimation", "authors": ["Chaoran Pang", "Shuangrong Liu", "Shikun Tian", "WenHao Yue", "Xingshen Zhang", "Lin Wang", "Bo Yang"], "abstract": "In this paper, a Convolution-Based Converter (CBC) is proposed to develop a methodology for removing the strong or fixed priors in estimating the probability distribution of targets based on observations in the stochastic process. Traditional approaches, e.g., Markov-based and Gaussian process-based methods, typically leverage observations to estimate targets based on strong or fixed priors (such as Markov properties or Gaussian prior). However, the effectiveness of these methods depends on how well their prior assumptions align with the characteristics of the problem. When the assumed priors are not satisfied, these approaches may perform poorly or even become unusable. To overcome the above limitation, we introduce the Convolution-Based converter (CBC), which implicitly estimates the conditional probability distribution of targets without strong or fixed priors, and directly outputs the expected trajectory of the stochastic process that satisfies the constraints from observations. This approach reduces the dependence on priors, enhancing flexibility and adaptability in modeling stochastic processes when addressing different problems. Experimental results demonstrate that our method outperforms existing baselines across multiple metrics.", "sections": [{"title": "1. Introduction", "content": "Stochastic processes provide a powerful mathematical framework for describing dynamic systems that evolve over time under uncertainty (Doob, 1942), enabling the analysis and prediction of complex dependencies and dynamic behaviors. They find broad applications in diverse real-world problems where uncertainty, variability, and randomness are inherent, such as in financial markets risk analysis (Dupacova et al., 2002; Jiang et al., 2019), biological processes (Reid, 1953), the design of optimization algorithms (Najim et al., 2004), and spatial data modeling (Banerjee et al., 2008).\nResearchers have developed various methods (Pavliotis, 2014) for modeling stochastic processes. Among these, Stochastic Differential Equations (SDEs)-based methods (Van Kampen, 1976), known for their simplicity and ease of use, are widely employed to address continuous-time stochastic modeling problems (Mao, 2013), by explicitly defining differential equations based on expert knowledge. However, SDE-based methods simplify problem constraints when defining the equation structure and diffusion term, which limits their ability to model complex systems. Additionally, solving SDEs poses significant numerical challenges (Wilkie, 2004), particularly in high-dimensional or highly nonlinear settings (Platen, 1999).\nConditional Density Estimation (CDE) methods, e.g., Markov-based models (Feller, 1991) and Gaussian Processes (GPs) (Seeger, 2004), can directly capture dependency relationships from data in modeling stochastic processes, without the need to explicitly construct dynamic equations. Markov-based models offer a computationally lightweight framework for modeling sequential dependencies by the assumption that future states depend solely on the current state (Chung, 1967). However, this assumption limits their ability to capture long-term dependencies and complex dynamics. Additionally, these models often struggle to achieve satisfactory performance with limited data due to their high data requirements for accurately representing state transitions (Rabiner, 1989). Compared to Markov-based models, GPs introduce a strong prior assumption, where any finite set of random variables follows a joint Gaussian distribution (Seeger, 2004). This prior enables GPs to capture complex dependencies among variables and make high-confidence probabilistic predictions, even in dynamic and data-scarce scenarios (Wilson et al., 2011).\nWhile GPs have demonstrated considerable success across various applications, the strong prior assumption limits their broader applicability (Bishop & Nasrabadi, 2006). When the data conforms to the assumed prior, these models can deliver robust performance. However, significant deviations from this prior often lead to substantial performance degradation.\nNeural Network-based CDE methods, such as Mixture Density Network (Bishop, 1994) and Deconvolutional Density Network (Chen et al., 2022), aim to adaptively model stochastic process, eliminating the need for strong prior assumptions regarding the explicit structural design of stochastic processes. However, their performance heavily depends on the size of the training data, leading to a substantial reduction in the reliability and generalization performance when faced with scenarios involving limited data(Starkman et al., 2023). Therefore, developing methods for limited data stochastic process modeling under weak prior conditions remains a critical open challenge.\nTo address the above challenges, we propose a Convolution-Based Converter (CBC), a weak-prior assumption method for establishing stochastic processes that can adapt to adverse situations even with limited data. Unlike above approaches, CBC does not rely on strong or fixed prior assumption, e.g., Markov properties or Gaussian prior, in modeling stochastic process. Instead, it adaptively estimate the probability distribution of random variables and the dependency relationships between of them, through a Convolution-Based Converter. CBC transforms trajectories of an arbitrary initial stochastic process into trajectories of an expected stochastic process that satisfy observational conditions. By influencing the observations, the entire stochastic process is affected, enabling CBC to maintain generalization capability even in limited-data scenarios.\nThe main contributions of this study are summarized as follows.\n\u2022 The Convolution-Based converter is proposed to enhance the broad-spectrum adaptability of stochastic process modeling methods across diverse problems by removing strong prior assumptions.\n\u2022 The dependence network generation paradigm is designed to model dependencies among random variables in stochastic processes through convolutional-deconvolutional operations.\n\u2022 Experiments show that CBC outperforms different types of stochastic process modeling methods, including strong prior and neural network-based approaches, on diverse problems."}, {"title": "2. Related Work", "content": "SDE-based Models Stochastic Differential Equations-based methods (SDEs) are classical approaches for modeling stochastic processes. They utilize explicit differential equations, comprising a drift term and a diffusion term, to describe the instantaneous changes of a stochastic process (Oksendal, 2013)(Kloeden et al., 1992). Researchers have developed various modeling strategies based on the SDEs framework, including linear (Arminger, 1986), nonlinear (Overgaard et al., 2005), and jump-diffusion SDEs (Jiang et al., 2019). Key techniques, such as parameter estimation (Nielsen et al., 2000), numerical solutions (Burrage et al., 2004), and stochastic control (Nisio, 2015), have also been extensively explored. These methodological advancements have established SDEs as a fundamental and versatile tool in stochastic process modeling. However, while the theory of SDEs is elegant and capable of describing a wide range of stochastic processes, SDE-based methods oversimplify the real problems by assumptions about system dynamics and noise distributions (Przyby\u0142owicz et al., 2022). These assumptions are often simplified to ensure analytical tractability, potentially leading to significant deviations from real-world complexities (Oksendal, 2013), thus limiting the model's accuracy and generalization ability. Furthermore, SDEs often face difficult-to-solve problems, especially for high-dimensional or nonlinear systems (Platen, 1999).\nMarkov-based Models Markov-based models, such as Markov chains (Chung, 1967) and Hidden Markov Models (HMMs) (Eddy, 1996), explicitly model state transition probabilities, effectively capturing the dynamic evolution of stochastic processes over time and thus modeling processes with temporal properties. Discrete-time Markov chains (G\u00f3mez et al., 2010) directly represent the conditional probabilities of state transitions at each time step, offering a tractable method for modeling sequence-dependent stochastic processes (Craig & Sendi, 2002), typically expressed as $P(X_{i+1}|X_i)$. HMMs further extend this capability by introducing hidden states, allowing the model to capture more complex observation sequences in which observable data are generated based on the evolution of unobserved hidden states. However, Markov-based models assume that future states depend solely on the current state, making it difficult to capture long-range dependencies and complex dynamics (Rabiner, 1989). Moreover, the accuracy of Markov models heavily relies on having sufficient data. When data are limited, the estimation of state transition probabilities may become unreliable, thereby affecting both predictive performance and generalization.\nGaussian Processes-based Models Gaussian processes (GPs) serve as a conditional probability estimation method by assuming that every finite subset of random variables in the stochastic process follows a multivariate Gaussian distribution (Seeger, 2004), we can write a Gaussian process as $GP \\sim (m(i), K(i, i'))$, where $m$ is the mean function and $K$ is covariance function, Gaussian Process stands as the a CDE approach for modeling stochastic process. It operates under the assumption that each random variable distribution is Gaussian, employing carefully chosen mean"}, {"title": "3. Methodology", "content": "A stochastic process can be represented as $X = {X(i)}_{i \\in I}$ (Doob, 1942), where i serves as the index indicating the locations of the random variables. The index set I is composed of both the observed locations S and the target locations T, formally expressed as $I = S \\cup T$, for $Vs \\in S$, the corresponding observed values are denoted as $O_s$, where $O = {O_s|s \\in S} = X(s)$. Let P be the joint probability distribution over the stochastic process, and therefore a conditional distribution $P(X(T)|X(S) = O)$, our task is to predict the conditional probability distribution for every t \u2208 T given O.\nGeneral CDEs-based methods often rely on strong priors over the stochastic process (Wilson et al., 2011) (Rabiner, 1989). However, these strong priors restrict the model's flexibility and can lead to significant deviations when the prior is misspecified. Neural Network-based CDE methods has the potential to weaken such strong priors, However, their performance is highly dependent on large-scale training data, often resulting in compromised performance in limited-data scenarios. Consequently, modeling stochastic processes with weak priors while maintaining reliability in limited-data scenarios remains a critical research challenge.\nWe introduce a Convolution-Based Converter (CBC), designed to implicitly estimate the conditional probability distribution $P(X(T)|X(S) = O)$ without relying on strong or fixed prior assumptions. Instead, it transforms initial stochastic process trajectories into expected trajectories that are consistent with observations. CBC trains a neural network-based converter to learn how to transform initial stochastic process trajectories into target stochastic process trajectories that satisfy observational constraints. During training, a loss function is applied at the observation points to guide the neural network in continuously optimizing the trajectory transformation. This process ultimately achieves an effective mapping from the initial stochastic process to the stochastic process based on observations, thereby implicitly modeling the stochastic process."}, {"title": "3.1. Formulation", "content": "CBC does not impose strong or fixed priors. Instead, it strives to achieve greater flexibility and adaptability within a weak prior framework, allowing for better handling of the diverse challenges in stochastic process modeling. During the transition, we directly generate complete trajectories consisting of both observation and target variables. Although the constraints only affect the observation variables, the entire trajectory is influenced by constructing dependencies among the random variables. This allows the targets to be indirectly estimated through the constraints imposed on observations.Compared to directly modeling $P(X(I)|I)$ can generalize to the entire stochastic process modeling with limited data.\nGenerating stochastic process trajectories is a key focus of CBC. We represent the stochastic process as $X = {\\Chi (\\omega, i)}_{i \\in I}, \\omega ~ P(w)$, where w is a random variable sampled from a predefined distribution. Using this representation, we can directly construct a simple initial stochastic process, such as a Gaussian white noise process(Balakrishnan & Mazumdar, 2011). We define a neural network-based transformation process:$X(i) = Q_\\theta(\\omega,i)$, where $Q_\\theta$ is a neural network parameterized by learnable parameters $\\theta$. After sampling entire trajectories from the initial stochastic process, we apply this transformation to obtain trajectories that satisfy observational constraints. We model this transformation process using a Bayesian framework(Howson & Urbach, 2006), leveraging Bayes' theorem to infer the conditional distribution.\n$P(X(T) | X(S) = O) = \\frac{P(X(S) = O, X(T))}{P(X(S) = O)}$\n(1)\nThe joint probabilities in the numerator can be expressed in an integral form over the initial random variable \u03c9:\n$P(X(S) = O, X(T)) = \\int 1{X(S) = O, X(T)} p(w) dw$\n(2)"}, {"title": "3.2. FrameWork of Convolution-Based Converter", "content": "The indicator function 1{} is:\n$1{X(S) = O, X(T)} = $\n$\\begin{cases}\n1, if X(S)=O\\\\\n0, otherwise.\n\\end{cases}$\n\nThe marginal probability is likewise obtained via integration, considering only the probability of the observed portion:\n$P(X(S) = O) = \\int 1{X(S) = O, X(T)} p(w) dw$ (3)\nIn practice, directly using an indicator function is not differentiable and thus not well-suited for neural network training. Instead, we adopt a mean squared error (MSE) loss to approximate the constraint X(S) = O. Specifically, we define\n$L(\\theta) = \\mathbb{E}_{wp(w)}[\\sum_{s\\in S} (Q_\\theta (\\omega, s) - O_s)^2]$.\n(4)\nBy iteratively updating \u03b8 to minimize L via gradient-based methods, we encourage the network to generate trajectories that closely match the observations at S, thereby implicitly satisfying the indicator constraint in a differentiable manner.\nDuring the training phase, we input sampled trajectories from a Gaussian white noise process, and employ a loss function to force the network to output trajectories conditioned on observations. Once trained, we only need to re-input random trajectories, and then the network will generate samples of trajectories that are consistent with observations.\nThe transformation of trajectories between stochastic processes has the potential to estimate $P(X(T)|X(S) = O)$ under a weak prior assumption. However, designing a converter capable of generating stochastic process trajectories with complex dependencies between random variables remains a key challenge. For instance, a Markov process represents stochastic process structures by enforcing the memoryless property and constructing a state transition matrix, while a Gaussian process employs a covariance function to compute correlation matrices. The effectiveness of these strongly prior-driven representations depends on how well their prior assumptions align with the intrinsic regularities of the problem. However, when the prior is mismatched, it can result in significant performance degradation or even complete failure. To effectively capture these complex dependencies in stochastic processes, we need an approach based on a weak prior that can adaptively model diverse stochastic processes.\nWe interpret the network's goal as mapping an initial random process into one with complex dependencies via trajectory transformations. These complex dependencies manifest in the trajectory generation process and may involve long-range correlations, multi-level structures, non-stationarity, or nonlinear relationships. Convolution stands out as a powerful candidate for building such a converter network, due to its more flexible modeling capacity. In traditional frameworks like Gaussian processes or Markov processes, the prior structure is explicit and closed-form; by contrast, CBC places the prior primarily in the network's architecture design and parameter initialization, yielding greater adaptability.\nFurthermore, the learned kernel (i.e., the convolutional kernel) can be viewed as a \"learnable covariance structure\" that is no longer bound by strict positive-definiteness or 'memoryless' assumptions, thus accommodating more intricate scenarios. Convolution naturally supports hierarchical feature extraction, enabling the model not only to capture local dependencies but also to progressively incorporate contextual information and ultimately learn longer-range or even global structures.\nThe network framework is introduced as below, as shown in Figure1.\nInitial Stochastic Process We start with a white noise stochastic process that is independent and has no prior dependency structure, ensuring flexibility in subsequent modeling of dependencies.\n$X(i) = X (\\omega, i), \\omega ~ p(\\omega)$ (5)\nPreliminary dependency constructor By employing several layers of MLP mapping(Rumelhart et al., 1986), we create a preliminary model of relationships between stochastic process trajectories.\n$X^{(0)} (i) = \\sigma(b^{(0)} + \\sum_{j=0}^{K-1} W_{j,i} X_i + b_j, j = 1, ..., m)$ (6)"}, {"title": "4. Experiment", "content": "Convolution-Based multi-layer dependency constructor A local-to-global dependency structure is constructed by exploiting multi-layer convolutional (LeCun et al., 1998) designs with sliding kernels to iteratively combine local dependencies and extend the scope outward.\n$X^{(1)} (i) = \\sigma(b^{(1)} + \\sum_{k=0}^{K-1} X(i \u2013 k)w^{(1)} (k)$\n(7)\n$x^{(n)} (i) = \\sigma(b^{(n)} + \\sum_{k=0}^{K-1} X(i \u2013 k)w^{(n)} (k)$\n(8)\nwhere K denotes the size of the convolutional kernel, b denotes the bias, X (1) is the layer index of the convolution, and i is the index of the random variable.\nWe have also specifically designed a Smooth Convolution Converter shown as Figture 2 for smooth stochastic processes. It employs Deconvolution consisting of multi-layer upsample-convolution-layers to effectively construct smooth trajectories, thereby modeling smooth stochastic processes in images. This design enhances the model's ability to generate continuous and coherent image completions, as the Smooth Convolution Converter adapts flexibly to the inherent data patterns without being constrained by specific prior structural assumptions.\nOutput Layer The final layer maps above output to the trajectory values of the expected stochastic process. If needed, a specific activation function can be applied to map the trajectory values to a designated output space.\n$X(i) = \\sigma(X^{(n)} (i))$\n(9)"}, {"title": "4.1. 1-D Stochastic Processes", "content": "In this subsection, we test CBC for modeling 1-D stochastic processes. VVFWe generate three different toy datasets, each representing a distinct modeling task for stochastic processes in different scenarios: a Gaussian process with an inherently smooth kernel, a Markov process with intrinsic temporal dependencies, and a uniform process with independent samples. The datasets are designed as follows:\n\u2022 Gaussian Process Dateset: $GP ~ (m(i), K(i, i'))$,\n$m(i) = 0, k(i, i') = \\sigma^2 exp(-\\frac{||i-i' ||^2}{2l^2}), \\sigma = 1.0, i \\in [0, 6\\pi]$\n\u2022 Uniform Process Dataset: $X(i) \\stackrel{iid}{\\sim} U(-4, 4), i \\in [0, 6\\pi]$\n\u2022 Markov Process Dateset: MP ~ P(X)\n$P(X) = \\prod_{i=1}^N P(X_i | X_{i-1})$\n$= exp(- \\sum_i \\theta_i X_i \u2013 \\sum_{i,j} d_{ij} X_i X_j), X(i) \\in {0,1}$\nWe sampled three sequences from each specific random process (where three denotes the number of test sequences), with each sequence comprising 200 random variables. Subsequently, we applied masking at arbitrary positions within these sequences. To evaluate the model's uncertainty inference capabilities under both low-sample and ample-sample conditions, we incrementally increased the number of masked points, specifically setting the number of masked points to [50, 100, 150].\nUsing the CBC model described in Figure1, we sample from a Gaussian white noise process with a sequence length of 5, which is then fed into a three-layer MLPs. The output of the linear layer is reshaped into a multi-channel representation. We then apply 5 layers of transposed convolution to generate the final conditional estimation results. Finally, we impose constraints at observations X(S)=O and optimize the model via gradient descent until the loss converges.\nOur experiment compares the performance of the CBC with the Gaussian Process (GP) (Wilson et al., 2011), the Hidden Markov Model (HMM) (Eddy, 1996), Wrapped Gaussian Process (WGP) (L\u00e1zaro-Gredilla, 2012), and the neural network-based CDE method Deconvolutional Density Network (DDN) (Chen et al., 2022) across different types of datasets, using negative log-likelihood (NLL) as the evaluation metric in Table 1.\nOn datasets generated by Gaussian processes and Markov processes, GP and HMM demonstrate superior per-"}, {"title": "4.2. 2-D Stochastic Processes", "content": "We consider image completion as a problem of modeling a 2-D stochastic process(Garnelo et al., 2018). Specifically, we consider each pixel in an image as a random variable within this process, where its value is inherently dependent on its two-dimensional spatial indices. The spatial dependencies and the underlying image structure dictate that this stochastic process evolves across both dimensions. Consequently, a model designed for image completion must be adapted to capture these two-dimensional dependencies. To this end, we replace the 1-D Convolution-Converter with 2-D Convolution-Converter, allowing the model to operate directly within the two-dimensional image space. Additionally, we employ a 2-D initial Gaussian white noise process to provide a suitable initial state for the image generation process. A sigmoid activation layer was used as the final layer to constrain the output pixel values within the range of [0, 1].\nWhen training, we first randomly select an image from the dataset. Subsequently, we select a subset of pixels from the selected image to serve as observations. We input an initial two-dimensional Gaussian white noise vector, and"}, {"title": "5. Conclusion", "content": "This paper introduces Convolution-Based Converter (CBC), a novel method for modeling stochastic processes that addresses the limitations of traditional SDEs, Markov models, and Gaussian Processes, as well as limited-data challenges for neural network-based conditional density estimation methods. By leveraging a weak-prior assumption and employing a Convolution-Based converter to transform initial stochastic process trajectories into observation-constrained expected trajectories, CBC adaptively learns dependencies without relying on pre-defined stochastic process structures, thus enhancing flexibility and adaptability."}]}