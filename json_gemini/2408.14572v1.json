{"title": "CURLORA: STABLE LLM CONTINUAL FINE-TUNING AND\nCATASTROPHIC FORGETTING MITIGATION", "authors": ["Muhammad Fawi"], "abstract": "This paper introduces CURLORA, a novel approach to fine-tuning large language models (LLMs)\nthat leverages CUR matrix decomposition in the context of Low-Rank Adaptation (LoRA). Our\nmethod addresses two critical challenges in LLM fine-tuning: mitigating catastrophic forgetting\nduring continual learning and reducing the number of trainable parameters. We propose a unique\nmodification to the CUR decomposition process, utilizing inverted probabilities for column and row\nselection which acts as an implicit regularization, and initializing the U matrix as a zero matrix, and\nonly fine-tuning it. We demonstrate through experiments on multiple datasets that CURLORA out-\nperforms standard LoRA in mitigating catastrophic forgetting. It maintains model stability and per-\nformance across tasks while significantly reducing the number of trainable parameters. Our results\nshow that CURLORA achieves very good and stable task accuracy while maintaining base model's\nperplexity scores fixed compared to LoRA upon continual fine-tuning, particularly in scenarios with\nlimited data.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs) have revolutionized natural language processing, demonstrating remarkable capa-\nbilities across a wide range of tasks [1]. However, fine-tuning these large models for specific tasks requires a lot of\ncomputational resources making it challenging to adapt these models efficiently, especially when working with lim-\nited datasets and in resource-constrained environments. [2]. Parameter-Efficient Fine-Tuning (PEFT) Methods have\ngained a lot of attention because they make fine-tuning large models accessible and possible. [3]\nLow-Rank Adaptation (LoRA) [4] has emerged as an efficient PEFT method, enabling fine-tuning large language mod-\nels on custom tasks while decreasing the number of trainable parameters hence requiring less resources. LoRA works\nby decomposing pre-trained weight matrices into low-rank matrices and fine-tune these ones instead of the original\nmatrix. Although LoRA has proven to be very excellent and promising, it still faces challenges with catastrophic\nforgetting. Catastrophic forgetting in LLMs is a critical issue where the model loses previously acquired knowledge\nwhen fine-tuned on new tasks [5]. It occurs due to the overwriting of previously learned (pre-trained) weights during\nthe fine-tuning process. In LoRA, this often happens as the adapted output can significantly deviate from the original:\n$$y = xW + xW_{adapted} = x(W + AB)$$\nwhere $$W\u2208 R^{m\u00d7n}$$ is the original weight matrix, and AB is the low-rank update from multiplying $$A\u2208 R^{m\u00d7r}$$ by\n$$B\u2208 R^{r\u00d7n}$$ where $$r < n$$.\nThis work introduces CURLORA, a novel approach that applies low-rank adaptation (LoRA) to pre-trained weight\nmatrices using CUR matrix decomposition [6] instead of random initiation of the low-rank A or B matrices. We\npropose a unique modification to the CUR decomposition process and demonstrate its effectiveness in mitigating\ncatastrophic forgetting while also reducing the number of trainable parameters. While LoRA successfully reduces\ncomputational costs by decomposing weight updates into low-rank matrices, it still suffers from catastrophic forgetting.\nCURLORA leverages CUR decomposition with inverted probabilities and initiating U matrix as zero to further mitigate\nthis issue."}, {"title": "Related Work", "content": "2.1 Catastrophic Forgetting\nCatastrophic forgetting is a big challenge in machine learning, particularly in the context of continual learning [5].\nVarious approaches have been proposed to address this issue:\n\u2022 Elastic Weight Consolidation (EWC) [7] uses Fisher information to measure the importance of parameters\nand selectively slow down learning on important parameters.\n\u2022 Progressive Neural Networks [8] propose to freeze the network trained on previous tasks and add lateral\nconnections to new columns for new tasks.\n\u2022 Memory-based approaches like Experience Replay [9] store and replay examples from previous tasks\nduring training on new tasks.\n2.2 Efficient Fine-tuning of Large Language Models\nAs LLMs have grown in size, efficient fine-tuning methods have become crucial:\n\u2022 Adapter layers [10] introduce small trainable modules between layers of a pre-trained model.\n\u2022 Low-Rank Adaptation (LoRA) [4] decomposes weight updates into low-rank matrices, significantly reduc-\ning the number of trainable parameters.\n\u2022 Prefix-tuning [11] prepends trainable continuous prompts to the input, allowing for task-specific adaptations.\n2.3 CUR Matrix Decomposition\nCUR decomposition has been applied in various domains for its interpretability and efficiency:\n\u2022 In data analysis, CUR has been used for feature selection and dimensionality reduction [6].\n\u2022 In scientific computing, CUR has been applied to accelerate large-scale matrix computations [12].\n\u2022 In machine learning, CUR has been explored for model compression and interpretation [13].\nHowever, to the best of our knowledge, CUR decomposition has not been previously applied to the problem of fine-\ntuning large language models or addressing catastrophic forgetting in this context."}, {"title": "Background on CUR Decomposition", "content": "CUR decomposition is a matrix factorization technique that approximates a matrix A as the product of three matrices:\nC, U, and R. Unlike Singular Value Decomposition (SVD), CUR decomposition uses actual columns and rows from\nthe original matrix, making it more interpretable.[6].\nGiven a matrix $$A \u2208 R^{m\u00d7n}$$, CUR decomposition approximates A as:\n$$A\u2248 CUR$$\nwhere:\n\u2022 $$C\u2208 R^{m\u00d7c}$$ consists of c columns of A\n\u2022 $$R\u2208 R^{r\u00d7n}$$ consists of r rows of A\n\u2022 $$U\u2208 R^{c\u00d7r}$$ is a small matrix that ensures CUR is close to A\nThe columns and rows are typically chosen based on their statistical leverage scores. [12] Leverage scores indicate the\nimportance of columns and rows in representing the original matrix. High leverage scores identify influential columns\nand rows, while low scores identify less critical ones."}, {"title": "This Work", "content": "In this section, we present CURLORA, our novel approach to fine-tuning large language models that leverages a mod-\nified CUR matrix decomposition to mitigate catastrophic forgetting. We provide a detailed mathematical formulation\nof the approach, analyze it theoretically, and explain how it addresses the challenge of catastrophic forgetting upon\ncontinual learning.\n4.1 CURLORA\nThe core idea is to decompose the pre-trained weight matrices using a modified CUR approach and then fine-tune\nonly the U matrix. This approach constrains the parameter space of possible adaptations keeping the fine-tuned\nparameters as small as possible to keep $$||W_{adapted} - W || F$$ close to the original weight matrix frobenius norm ($$||W||_F$$)\ni.e. $$W + W_{adapted}$$ is so close to W to avoid the deviation of the adapted output.\n4.2 Mathematical Formulation\nGiven a weight matrix $$W \u2208 R^{m\u00d7n}$$, we first compute the probability of each column:\n$$P_j = \\frac{||W_{:j}||^2}{||W||}$$\nwhere $$W_{:j}$$ is the j-th column of W, while $$|| \u00b7 ||_2$$ denotes the square of the L2 norm of the column and $$|| \u00b7 ||$$ denotes\nthe square of the Frobenius norm of W. This will give us the probability of each column. For instance, if W has three\ncolumns with norms 2, 3, and 5, the probabilities are 4/38, 9/38, and 25/38 respectively.\nWe then invert these probabilities:\n$$P_j = \\frac{1/P_j}{\\Sigma_{i=1}^n 1/P_i}$$\nwhere $$\\overline{p_j}$$ is the inverted probability of the j-th column of W. The same steps are followed for rows. Inverted probabil-\nities are used to sample columns and rows with lower leverage scores, which implicitly regularize the model and limit\nthe magnitude of fine-tuning adjustments.\nThen, we sample r columns and rows, where $$r < n$$, according to these inverted probabilities to construct C and R,\nwhich will always be fixed, with columns and rows with lower original probabilities. This trick plays a major role in\nthe approach as it serves two purposes:\n\u2022 It acts as a form of regularization, preventing the model from overfitting or moving too much towards the task\nand limiting the adaptation of the U matrix stopping it from growing so big in magnitude.\n\u2022 It preserves the model's original behavior by focusing adaptations on less influential parts of the weight\nmatrix. In addition, since C and R contain actual columns and rows from the original matrix, they contribute\nto the stability of the fine-tuning process.\nCURLORA's approach differs significantly from other initialization methods. Unlike LoRA's random initialization\nusing Kaiming-uniform or Gaussian for weight A and zeros for weight B [4], or the SVD-based initialization [14],\nCURLORA offers more controlled adaptation. While these other methods ensure starting from the base model, they\ndon't inherently limit the growth of the adaptation matrix (AB in LoRA), potentially leading to significant deviations\nduring training. In contrast, CURLORA initializes the U matrix as zeros, and importantly, constructs C and R matrices\nusing columns and rows with lower original probabilities (i.e., lower values). This unique combination ensures that\nthe fine-tuning process not only starts from the base configuration but also remains constrained throughout training.\nThe low-value C and R matrices act as natural limiters on the growth of U, thereby preventing large deviations and\ncontributing to enhanced model stability during the fine-tuning process.\n$$C = SampleColumns(W, r, p)$$\n$$R = SampleRows(W, r, p)$$\n$$U_{init} = 0$$"}, {"title": "Theoretical Analysis of Catastrophic Forgetting Mitigation", "content": "Where W is the original weight matrix, r is the rank (number of columns/rows to sample) and p represents the inverted\nprobabilities used for sampling.\nDuring fine-tuning, we update only the U matrix, keeping C and R fixed as they play a crucial role in ensuring the\nstability of the process by limiting the increase of U:\n$$W_{adapted} = CUR$$\n4.3 Theoretical Analysis of Catastrophic Forgetting Mitigation\nTo understand how CURLORA helps mitigate catastrophic forgetting, we analyze its properties mathematically:\n4.3.1\nParameter Space Constraint\nIn CURLORA, we decompose the original weight matrix W as:\n$$W\u2248 CUR$$\nDuring fine-tuning, we're optimizing:\n$$W_{adapted} = C(U + \u2206U)R$$\nwhere AU represents the changes made to U during fine-tuning. By constraining the updates to the subspace defined\nby C and R, CURLORA limits drastic changes, thereby preserving the model's original knowledge.\n4.3.2 Implicit Regularization\nBy initializing U as a zero matrix, and C and R with columns and rows of low weight values, the ones with lower\nprobabilities, we provide an implicit regularization where C and R will always limit the unnecessary increase of U.\nThis can be seen as adding a regularization term to the loss function quantified by the norm of the matrix U that is\naimed to be kept small:\n$$L_{CURLORA}(0) = L_{task}(0) + ||U||_F$$\nwhere $$||U||_F$$ is the Frobenius norm of the U matrix that is being fine-tuned. This implicit regularization term encour-\nages the model to keep the changes small. For instance, if U is initially zero, this term will push the fine-tuning process\nto make only necessary adjustments, preventing overfitting and excessive reliance on the fine-tuned parameters.\n4.3.3 Reduced Interference\nDuring fine-tuning, W is fixed, so the variable gradient flows through $$W_{adapted}$$, which is itself updated through U as\nC and R are fixed. Considering the gradients of the loss L with respect to the parameters, we can, in a simple way,\nexpress the gradient of the loss with respect to $$W_{adapted}$$ as follows:\n$$\\frac{\\partial L}{\\partial W_{adapted}} = C \\frac{\\partial L}{\\partial U} R$$\nThis means that the gradient of the loss with respect to $$W_{adapted}$$ is dependent on the gradients with respect to U scaled\nby the fixed matrices C and R. By projecting the gradients onto the subspace defined by C and R, the updates to\n$$W_{adapted}$$ are constrained. This means that changes during fine-tuning are less likely to interfere with the model's ability\nto perform the original task, potentially reducing interference with directions important for the original task.\n4.3.4 Reduced Degree of Freedom\nIf $$W \u2208 R^{m\u00d7n}$$ and we use a rank-k adaptation, then:\n\u2022 Full fine-tuning has mn degrees of freedom\n\u2022 LoRA has k(m + n) degrees of freedom"}, {"title": "Stability Analysis", "content": "\u2022 CURLORA has only $$k^2$$ degrees of freedom\nThis significant reduction in degrees of freedom inherently limits how far the model can stray from its original config-\nuration.\n4.3.5 Stability Analysis\nWe can analyze the stability of the adapted and fine-tuned weights and how its change is bounded using the fact that\nthe change that happens to original W is $$W_{adapted}$$.\n$$AW = W_{fine-tuned} - W = W + W_{adapted} - W = W_{adapted}$$\nTo quantify this change, we can use the Frobenius norm, $$|| W_{adapted} || F$$. By utilizing the submultiplicativity property of\nthe Frobenius norm, we can say that the growth of $$W_{adapted}$$ is controlled through the norms of C, U, and R:\n$$||W_{adapted} || F = ||CUR||_F \u2264 ||C||_F||U||_F||R||_F$$\nThis equation ensures that the Frobenius norm of the adapted weight matrix $$W_{adapted}$$ has an upper bound. Since C and\nR are fixed and U starts at zero, the fine-tuning process focuses on minimizing $$W_{adapted}$$. As a result, the adaptation\nremains stable and the model preserves its original knowledge while allowing for necessary adjustments.\nEmpirical results (see Section 7) demonstrate that the Frobenius norm of $$W_{adapted}$$ remains bounded across multiple\ntasts, validating the theoretical stability analysis.\n4.4 Theoretical Analysis of Output Shift\nTo understand why CURLORA is expected to perform better than standard LoRA in terms of catastrophic forgetting,\nwe can analyze the shift in the output during fine-tuning.\nFor a given input x, the original output is $$y = xW$$. After fine-tuning:\nFor LoRA: $$Y_{adapted} = x(W + AB)$$\nFor CURLORA: $$Y_{adapted} = x(W + CUR)$$\nWe can quantify the shift using the Frobenius norm of the difference:\n$$||Y - Y_{adapted} || F = ||xW - x(W + W_{adapted})||_F = ||xW \u2013 XW \u2013 xW_{adapted}||_F = ||XW_{adapted} || F$$\nFor LoRA: $$||x(AB)||_F$$\nFor CURLORA: $$||x(CUR) || F$$\nThis equation measures the shift in the model's output after fine-tuning. y is the original output, and $$Y_{adapted}$$ is the\noutput after fine-tuning. After fine-tuning for a different task, the adapted output $$Y_{adapted}$$ might shift. We use the\nFrobenius norm to quantify this shift. If the shift is small, it means that the model's predictions haven't changed much,\nindicating that the model has retained its original knowledge. As shown, the shift depends on $$W_{adapted}$$ i.e. to make\nsure the shift isn't so big, we need to keep $$W_{adapted}$$ as small (in magnitude or size) as possible.\nCURLORA's main aim is to minimize $$W_{adapted}$$ while ensuring that the difference $$||W \u2013 W_{adapted}|| F$$ remains close to\n$$||W|| F$$. By focusing on minimizing $$W_{adapted}$$, CURLORA effectively controls the shift in the output, thereby preserving\nthe model's original behavior and mitigating catastrophic forgetting.\nTheoretically, CURLORA should result in a smaller shift because:\n1. The C and R matrices are directly sampled from W, maintaining some structure of the original matrix.\n2. The C and R matrices are sampled from columns and rows with lower values.\n3. Only U is trained, which is constrained by C and R.\n4. The initialization of U as a zero matrix.\nThis constrained adaptation in CURLORA is expected to lead to better preservation of the model's original knowledge,\nthereby reducing catastrophic forgetting."}, {"title": "Memory Efficiency", "content": "4.5 Memory Efficiency\nCURLORA offers significant memory savings compared to full fine-tuning and even LoRA. For a weight matrix\n$$W \u2208 R^{m\u00d7n}$$, the number of trainable parameters for each method, considering rank r where $$r < n$$, is:\n\u2022 Full fine-tuning: mn\n\u2022 LoRA (rank r): mr + nr\n\u2022 CURLORA (rank r): $$r^2$$\nThe memory savings can be substantial, especially for large matrices. In our Mistral experiment, with rank 16, the\ntrainable parameters were:\n\u2022 Full fine-tuning: 7,248,023,552 parameters\n\u2022 LoRA: 9,437,184 parameters\n\u2022 CURLORA: 24,576 parameters\nThis reduction in trainable parameters not only saves memory but also potentially leads to faster training and inference\ntimes.\nIn conclusion, CURLORA provides multiple mathematical mechanisms that can help mitigate catastrophic forgetting:\n\u2022 It constrains the parameter space of possible adaptations.\n\u2022 It provides implicit regularization towards the original weights.\n\u2022 It preserves important directions from the original weight matrix.\n\u2022 It reduces the degrees of freedom in adaptation, limiting potential deviation.\n\u2022 It allows for direct control and analysis of weight stability through the U matrix.\nThese properties suggest that CURLORA can indeed help in reducing catastrophic forgetting while still allowing for\nmeaningful and good adaptation to new tasks. The effectiveness of these theoretical mechanisms are validated through\nour experiments on various tasks and datasets, as detailed in the following sections."}, {"title": "Methodology", "content": "5.1 CURLORA Implementation\nOur CURLORA implementation consists of the following steps:\n1. Decomposition: For each weight matrix W in the layers we want to apply CURLORA to, we perform the\nfollowing:\n\u2022 Compute column probabilities: $$p_j = \\frac{||W_{:j}||^2}{||W||^2}$$\n\u2022 Invert probabilities: $$\\overline{p_j} = \\frac{1/P_j}{\\Sigma_{i=1}^n 1/P_i}$$\n\u2022 Sample columns and rows according to $$\\overline{p_j}$$ to construct C and R\n\u2022 Initialize U as a zero matrix\n2. Fine-tuning:\n\u2022 Objective:\nThe primary objective of the experiment is to evaluate catastrophic forgetting during continual learn-\ning, rather than to optimize accuracy for each individual task.\n\u2022 Model Specific Adjustments:\nFor GPT-2 and Mistral, the model's \"lm_head\" is replaced with a task-specific output layer. During\ntraining, only the U matrix is continually updated, while C and R remain fixed.\nReplacing the \"lm_head\" ensures that each task has its own task-specific output layer that remains\nuntouched when the model is being fine-tuned on a different task, contributing to the mitigation of\ntask knowledge degradation.\n\u2022 Continual Learning Strategy:\nOnce a weight matrix is decomposed, C and R are fixed permanently. The U matrix is continually\nupdated for each new task to facilitate continual learning.\n\u2022 Application of CURLORA:\nCURLORA is applied to the attention layers (Query, Key, Value). [15]\n3. Inference: Use the adapted weight matrix $$W_{adapted} = CUR$$ for forward passes along with the original W\nmatrix i.e. x(W + CUR)."}, {"title": "Experiment Setup", "content": "6.1 Datasets\nWe used the following datasets for our experiments:\n\u2022 GLUE-MRPC: Microsoft Research Paraphrase Corpus for paraphrase detection [16]\n\u2022 GLUE-SST-2: Stanford Sentiment Treebank for binary sentiment classification [17]\nThese datasets are part of the General Language Understanding Evaluation (GLUE) benchmark [18], which\nincludes a diverse set of tasks for evaluating natural language understanding systems.\n\u2022 Sentiment140: A large-scale sentiment analysis dataset [19]\n\u2022 WikiText-2: A dataset that we use to measure language model perplexity [20]\nThe datasets were selected for their diverse task requirements and common use in benchmarking.\n6.2 Model and Hyperparameters\nWe used Mistral 7B (v0.3) [21] and GPT-2 Large [22] as our base models. For both LoRA and CURLORA, we used\nthe following hyperparameters:\n\u2022 Ranks: [8, 16, 24]\n\u2022 Alpha: 1\n\u2022 Optimizer: AdamW\n\u2022\nLearning rate: 2.5e-4\n\u2022 Scheduler: Cosine with 500 warmup steps\n\u2022 Training epochs: 3\n\u2022 Batch size:\nMistral: 8\nGPT-2: 32\n\u2022 Max length:\nMistral: 512\nGPT-2: 256\n6.2.1 Notes on hyperparemeters and architecture\n\u2022 Robustness and Regularization:\nCURLORA's performance was evaluated across different ranks, demonstrating robustness to moderate\nchanges. Optimal results can be achieved by fine-tuning other hyperparameters, such as the learning\nrate. Dropout was not utilized, as the objective was to observe the implicit regularization effects of\nCURLORA without the influence of explicit regularization.\n\u2022 Data Constraints:\nFor Mistral, each fine-tuning task was limited to 1000 records to simulate scenarios with limited data\nand resources for large models.\nFor GPT-2, the SST-2 fine-tuning task was limited to 5000 records due to resource constraints.\nFor the sentiment analysis task, the Sentiment140 test dataset was used for training, while the train\ndataset was used for evaluation. This choice was made because the test dataset has three labels, whereas\nthe train dataset has only two. This allowed for fine-tuning the models on a multi-class task rather than\na binary one.\n\u2022 Task Specific Adjustments:\nFor the sentiment analysis task with GPT-2, due to the small size of the dataset used for fine-tuning, the\nnumber of epochs was adjusted to 5, and the learning rate scheduler was not used."}, {"title": "Evaluation Metrics", "content": "6.3 Evaluation Metrics\nWe used the following metrics for evaluation:\n\u2022 Accuracy: For classification tasks (MRPC, SST-2, Sentiment140)\n\u2022 Perplexity: For language modeling capability (WikiText-2)\n6.4 Experimental Procedure\nOur experimental procedure was as follows:\n1. Measure initial perplexity of the base model on WikiText-2 concatenating the whole dataset into a single\nstring.\n2. Fine-tune on MRPC and evaluate.\n3. Fine-tune on SST-2 and evaluate, then re-evaluate on MRPC.\n4. Fine-tune on Sentiment140 and evaluate, then re-evaluate on MRPC and SST-2.\n5. Re-calculate perplexity on WikiText-2.\nThis procedure was carried out for both LoRA and CURLORA independently."}, {"title": "Results and Discussion", "content": "7.1 Performance Analysis\n7.1.1 Task-Specific Performance\nCURLORA consistently performed well on different tasks, showing high accuracy even after fine-tuning on subsequent\ntasks. This suggests that CURLORA is more effective at preserving task-specific knowledge.\nBased on the experiments, CURLORA may require a slightly higher learning rate than LoRA to achieve comparable\naccuracy. This is due to the implicit regularization introduced by the C and R matrices, which constrain the adapta-\ntion space of the U matrix. However, this same property makes CURLORA more robust against overfitting, even at\nhigher learning rates. In contrast, while LoRA might achieve good performance with lower learning rates, it can be\nmore susceptible to overfitting when learning rates are substantially increased. This trade-off highlights CURLORA's\npotential for more stable and controlled fine-tuning, particularly in scenarios where aggressive learning rates might be\nnecessary.\n7.1.2 Catastrophic Forgetting and Stability\nThe stability of CURLORA's performance across tasks is particularly noteworthy. While (Mistra) LoRA-16's accu-\nracy, for example, on MRPC dropped from 0.6495 to 0.32 after fine-tuning on other tasks, CURLoRA-16 (Mistral)\nmaintained its accuracy at 0.66. This demonstrates CURLORA's superior ability to mitigate catastrophic forgetting.\n7.1.3 General Language Modeling Capability\nThe final perplexity scores on WikiText-2 provide strong evidence for CURLORA's effectiveness in preserving general\nlanguage modeling capabilities. While all LoRA's perplexity, in both Mistral and GPT2, increased dramatically, all\nCURLORA models maintained the original perplexity, indicating no degradation in general language understanding.\n7.2 Theoretical Insights\nThe experimental results align with our theoretical analysis:\n\u2022 Parameter Space Constraint: The stability of CURLoRA's performance across tasks supports our hypothe-\nsis that constraining adaptations to the subspace spanned by C and R helps preserve original knowledge.\n\u2022 Implicit Regularization: The maintained perplexity on WikiText-2 suggests that CURLORA's implicit regu-\nlarization effectively prevents overfitting to specific tasks.\n\u2022 Reduced Interference: The consistent performance across tasks indicates that CURLORA successfully re-\nduces interference between task-specific adaptations.\n7.3 Limitations and Future Work\nWhile CURLORA shows promising results, there are several areas for future research:\n\u2022 Scalability: While CURLORA shows promising results, its scalability to larger models needs further inves-\ntigation. Further studies are needed to assess CURLORA's performance on larger models and more diverse\ntasks like instruction tuning and datasets.\n\u2022 Computational Complexity: Conducting detailed analysis of time and space complexity compared to full\nfine-tuning and LoRA.\n\u2022 Implicit Regularization Limitation: Implicit regularization via zero initialization of U has to be further\nstudied especially in highly dynamic environments where more flexible adaptations are needed.\n\u2022 Optimal Rank and Alpha Selection: Investigating methods for automatically selecting the optimal rank and\nalpha for CURLORA could further improve performance.\n\u2022 Combination with Other Techniques: Exploring the integration of CURLORA with other continual learning\ntechniques could yield even better results."}, {"title": "Conclusion", "content": "This paper introduced CURLORA, a novel approach to fine-tuning large language models that leverages CUR matrix\ndecomposition to mitigate catastrophic forgetting and improve computational efficiency. Through theoretical analy-\nsis and empirical experiments, we demonstrated that CURLORA outperforms standard LoRA in maintaining model\nstability and performance across tasks while significantly reducing the number of trainable parameters.\nKey contributions of this work include:\n\u2022 A novel modification to CUR decomposition using inverted probabilities for column and row selection and\ninitiating U matrix as zeros. Sampling columns and rows based on inverted probabilities distinguishes CUR-\nLORA from traditional CUR, offering better stability and performance.\n\u2022 Theoretical analysis of how CURLORA addresses catastrophic forgetting.\n\u2022 Empirical evidence of CURLORA's effectiveness across multiple tasks and evaluation metrics with multiple\nmodels.\nOur results suggest that CURLORA is a promising approach for efficient and stable fine-tuning of large language mod-\nels, particularly in scenarios with limited fine-tuning data. CURLORA's approach to mitigating catastrophic forgetting\nhas broad implications for continual learning in NLP and beyond. Future research could explore its integration with\nother adaptation techniques to enhance model robustness"}]}