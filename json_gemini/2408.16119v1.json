{"title": "Data Formulator 2: Iteratively Creating Rich Visualizations with AI", "authors": ["Chenglong Wang", "Bongshin Lee", "Steven Drucker", "Dan Marshall", "Jianfeng Gao"], "abstract": "To create rich visualizations, data analysts often need to iterate back and forth among data processing and chart specification to achieve their goals. To achieve this, analysts need not only proficiency in data transformation and visualization tools but also efforts to manage the branching history consisting of many different versions of data and charts. Recent LLM-powered AI systems have greatly improved visualization authoring experiences, for example by mitigating manual data transformation barriers via LLMs' code generation ability. However, these systems do not work well for iterative visualization authoring, because they often require analysts to provide, in a single turn, a text-only prompt that fully describes the complex visualization task to be performed, which is unrealistic to both users and models in many cases. In this paper, we present Data Formulator 2, an LLM-powered visualization system to address these challenges. With Data Formulator 2, users describe their visualization intent with blended UI and natural language inputs, and data transformation are delegated to AI. To support iteration, Data Formulator 2 lets users navigate their iteration history and reuse previous designs towards new ones so that they don't need to start from scratch every time. In a user study with eight participants, we observed that Data Formulator 2 allows participants to develop their own iteration strategies to complete challenging data exploration sessions.", "sections": [{"title": "Introduction", "content": "From an initial design idea, data analysts often need to go back and forth on a variety of charts before reaching their goals. Throughout this iterative process, besides updating the chart specifications, analysts face the challenges to transform and manage different data formats to support these visualization designs. Iterative chart authoring is prevalent in exploratory data analysis [42], where analysts often discover new directions from initial charts. For example, after noticing that the line chart about renewable energy percentage in Figure 1 are quite dense for comparing different countries' trends, the analysts may want to filter it to show only top 5 CO2 emitter's trends, or visualize ranks of these countries each year instead. To achieve these, the analysts need different data transformations: the former requires filtering the data with each country's aggregated CO2 emission values, and the latter requires partitioning the data by year to compute each country's ranking. Similar challenges are also relevant in the data-driven storytelling context [40, 41], where authors needs to derive new data to refine chart designs (e.g., annotation). For example, to highlight which countries are leading in renewable energy adoption, the author would superimpose a trend line of global median adoption rates over the line chart; the author may later convert the chart into small multiples to tell a story about most sustainable countries from each continent. Again, these new designs require data transformation from the current results.\nManaging different data and chart designs together in these iterative authoring processes is challenging. As the analyst comes up with new chart designs, they need not only to understand the data format expected by the chart and tool, but also need to know how to use diverse transformation operators (e.g., reshaping, aggregation, window functions, string processing) in data transformation tools or libraries to prepare the data. Many AI-powered tools have been developed to tackle these visualization challenges (e.g., [2, 9, 26, 31, 54, 55]). These tools let users describe their goals using natural language, and they leverage the underlying AI models' code generation ability [1, 5] to automatically write code to transform the data and create the visualization. Despite their success, current tools do not work well in the iterative visualization authoring context. Most of them require analysts to provide, in a single turn, a text-only prompt that fully describes the complex visualization authoring task to be performed, which is usually unrealistic to both users and models.\n\u2022 First, despite free-form text prompts provide unbounded expressiveness for users to describe their visualization intent, they miss UI interactions' precision and affordance, making it difficult for users to clearly describe complex designs they come up in later iteration stages. For example, the user needs a verbose prompt to clearly elaborate which fields they would like to use in each visual channel to create a faceted bar chart; without it, AI models could misinterpret the intent and create undesired charts, requiring further disambiguation efforts from the user. and the system can provide immediate visual feedback to the user. In fact, writing high-quality prompts requires skill and efforts. Even with clear goals in mind, it is challenging for inexperienced users to clearly describe their intent [48, 64].\n\u2022 Second, existing AI-powered tools support only either single-turn or linear interactions with AI models, and therefore do not accommodate branching and backtracking that commonly occur in the iterative authoring process. To use single-turn text-to-vis tools in an iterative manner, users need to re-specify their intent from scratch each time they create a new design, even though the design update is minor. This not only is time consuming for the user, but also increases the chance of the AI model to fail the task, since the model needs to solve a complex task in one shot. While chat-based tools [26, 34, 66] support multi-turn interactions by reusing previous outputs in subsequent turns, they do not work well for branching contexts. When non-linear contexts are merged into a linear history, it is not only challenging for users to communicate which designs should be used towards next iterations, but also challenging for AI model to correctly retrieve relevant content from the long conversation history [14, 21, 65].\nTo overcome these limitations, we design a new interaction approach for iteratively chart authoring. Our key idea is to blend GUI and natural language (NL) inputs so that users can specify charts both precisely and flexibly, and we"}, {"title": "Chart specification with blended UI and NL inputs", "content": "Resembling shelf-configuration UIs [40, 55], the concept encoding shelf allows users to drag existing data fields they wish to visualize and drop them to visual channels to specify chart designs. Differently, with concept encoding shelf, users can also input new data field names in the chart configuration to express their intent to visualize fields that they want from a transformed data. Then, they can provide a supplemental NL instruction to explain the new fields and ask the AI to transform data and instantiate the chart. This blended UI and NL approach for chart specification makes user inputs both precise and flexible. Since Data Formulator 2 can precisely extract chart specification from the encoding shelf, the user doesn't need verbose prompt to explain the design. By conveying data semantics using NL inputs, the user delegates data transformation to AI, and thus they doesn't need to worry about data preparation. This approach also improves the task success rate of AI models. Because Data Formulator 2 can infer the visualization script directly from UI input, the AI model only needs to generate data transformation code. With the chart design provided as contexts to the AI model, the model has more information to ground the user's instruction for better code generation. Managing"}, {"title": "and leveraging iteration contexts with data threads", "content": "Data Formulator 2 presents the user's non-linear iteration history as data threads and lets them manage data and charts created throughout the process. With data threads, users can easily navigate to an earlier result, fork a new branch, and reuse its context to create new charts. This way, users only need to inform the model how to update the previous result (e.g., \"show only top 5 CO2 emission countries' trends\", Figure 1) as opposed to re-describing the whole chart from scratch. When the user decides to reuse, the Data Formulator 2 tailors the conversation history to include only contexts relevant to that data to derive new result, allowing the AI to generate code with clear contextual information free from (irrelevant) messages from other threads. Besides general navigation and branching supports, data threads also provide shortcut for users to quickly backtrack and revise prompts to update recently created charts, which can be useful for analysts to explore alternative designs or correct errors made by AI."}, {"title": "System Overview", "content": "Based on these two key designs, we developed Data Formulator 2, an AI-powered visualization tool for iterative visualization authoring. Data Formulator 2 supports diverse visualizations provided by Vega-Lite marks and encodings, and the AI can transform data flexibly to accommodate different designs, supporting operators like reshaping, filtering, aggregation, window functions, and column derivation. Like other AI tools [9, 55], Data Formulator 2 also provides users panels to view generated data, transformation code and code explanations to inspect and verify AI outputs.\nTo understand how Data Formulator 2's multi-modal interaction benefits analysts in solving challenging data visualizations tasks, we conducted a user study consisting of eight participants with varying data science expertise. They were asked to reproduce two professional data scientists' analysis sessions to create a total of 16 visualizations, 12 of which require non-trivial data transformations (e.g., rank categories by a criterion and combine low-ranked ones into one category with the label, \u201cOthers\"). The study shows that participants can quickly learn to use Data Formulator 2 to solve these complex tasks, and that Data Formulator 2's flexibility and expressiveness allow participants to develop their own verification, error correction, and iteration strategies to complete the tasks. Our inductive analysis of study sessions reveals interesting patterns of how users' experiences and expectations about the AI system affected their work styles.\nIn summary, the main contributions of this paper are as follows:\n\u2022 We design a multi-modal UI, composed of concept encoding shelf and data threads, to blend UI and NL interactions for users to specify their intent for iterative chart authoring."}, {"title": "Illustrative Scenarios: Exploring Renewable Energy Trends", "content": "In this section, we describe scenarios to illustrate users' experiences of creating a series of visualizations to explore global sustainability from a dataset of 20 countries' energy from 2000 to 2020. The initial dataset, shown in Figure 2-1, includes each country's energy produced from three sources (fossil fuel, renewables, and nuclear)"}, {"title": "Exploration with computational notebooks", "content": "Heather is an analyst who is proficient with a computational notebook and R libraries, ggplot2 and tidyverse. Because ggplot2 expects all data fields to be visualized on visual channels (e.g., x, y-axes, color, facet) are columns in the input data, Header uses tidyverse for data transformation."}, {"title": "Exploration with Data Formulator 2", "content": "Megan is a journalist who has a solid understanding about data visualization. She utilizes visualizations effectively in her work but she doesn't program. Megan can create and refine rich visualizations iteratively with Data Formulator 2 (Figure 3), which inherits the basic experience of shelf-configuration style tools. She can specify charts by mapping data fields to visual channels of the selected chart and provide additional contexts using natural language."}, {"title": "Comparison of Exploration Experiences", "content": "The experience of Heather and Megan exploring global sustainability (using data 1) demonstrates an inherently iterative process. Both of them started with a high-level goal without concrete designs in mind and gradually formed the design from explorations in various branches. This iterative exploration process required a series of data transformation and the management of provenance, and thus is challenging for people not proficient in data transformation and programming. Here, we compare their exploration experiences to highlight how Data Formulator 2 bridges Megan's skill gap, enabling her to achieve the analysis Heather, an experienced data analysis, performed."}, {"title": "Multi-modal UI: Decoupling chart specification and data transformation", "content": "Data Formulator 2 decouples chart specification and data transformation so that users can benefit from both the precision of UI interaction to configure chart designs and the expressiveness of NL descriptions to specify"}, {"title": "Data transformation with AI", "content": "From the concept encoding shelf, Data Formulator 2 assembles a prompt and queries LLM to generate a python code to transform data. The data transformation prompt contains three segments: the system prompt, the data transformation context and the goal (illustrated Figure 6-2, full prompt is shown in the Appendix):\n\u2022 The system prompt describes the role of the LLM and output format. Besides generic role descriptions (i.e., LLM as a data scientist to help with data transformation), the system prompt instructs LLM to solve the data transformation task in two steps: (1) refine the user's goal and output as a json object, recapitulating intermediate fields and final fields to be computed from the original data and (2) generate a python code following a provided template. The system prompt ends with an input output example (following few-shot prompting strategy) demonstrating the process. The design rationale behind the \u201cgoal refinement\u201d step is to allow LLM to reason about potential discrepancy between users' provided fields and their instruction (e.g., the user may ask about color by energy type but didn't put \"energy type\" on the color encoding) and determine the final list of fields to be computed.\n\u2022 Data Formulator 2 then assembles a section of context prompts that describe the data transformation contexts to be performed. When the chart is created from scratch, the context prompts describe the input data to be transformed, including its data fields (data type and example values) as well as first five rows of the data. The data context not only helps the LLM understand semantics of new fields specified by the user, but also provides essential information related to data formats (especially data type, string formats and whether columns contains null values) to ensure the generated transformation code is executable on the given data. When the chart is specified on top of previous results, the dialog history between Data Formulator 2 and the LLM leading to that data (including both instructions from the user and previous code generated by the LLM) is also appended in context. This way, despite users' followup prompts can be short, the grounded contexts help the model to understand user intent and reuse previously generated code."}, {"title": "Data threads: navigating the iteration history", "content": "During the iterative visualization process, the analyst needs to navigate their authoring history to locate relevant artifacts (data or charts) to take actions (delete, duplicate or followup). Data Formulator 2 introduces data threads to represent the tree-structured iteration history to support navigation tasks. In data threads, we treat data as the first class objects (nodes in data threads) that are connected according to the user's instruction provided to the AI model (edges), and visualizations are attached to the version of data they are created from. Centering the iteration history around data benefits user navigation because it directly reflects the sequence of user actions in creating these new data. This design also benefits the AI model: when user issues a follow-up instruction, Data Formulator 2 automatically retrieves its conversation history with the AI towards the current data and then instruct the AI model to rewrite the code towards new goals based on the retrieved history. This way, the AI model does not pose risk of incorrectly using conversation history from other branches to make incorrect data transformation. As shown in Figure 8, the code and the conversation history is attached to each data nodes. Each turn when the user provides a follow-up instruction, the AI model generates new code by updating the previous code (could be deletion, addition or both) to achieve the user's goal; this way, the code always takes the original data as the input with all information accessible. Comparing to an alternative design where we only pass current data to the AI model and asks it to write a new code to further transform it (i.e., reusing the data as opposed to reusing the computation leading to the data), our design has more flexibility to accommodate different styles of followup instructions either the user wants to further update the data (e.g., \u201cnow, calculate average rank for each country\u201d), revise previous the computation (e.g., \"also consider nuclear as renewable energy\") or creating an alternatives (e.g., \u201crank by CO2 instead\u201d) since the AI has access to the full dialog history and the full dataset. In contrast, the data-only reuse approach restricts the AI model's access to only the current data, limiting its ability to support \"backtracking\u201d or \u201calternative design\" styles instructions."}, {"title": "Miscellaneous: inspecting results and styling charts", "content": "As an AI-powered tool, Data Formulator 2 lets the user verify AI-generated results and resolve mistakes made by AI. It displays transformed data, visualization, the code, and an explanation of the code in the main panel. This design accommodates various user verification styles identified by prior work [12, 54]: e.g., viewing high-level correctness from chart, inspecting corner cases in data, inspecting the transformation output, as well as understanding the transformation process from code. Data Formulator 2 utilizes a code explanation module to query the AI model to translate code into step-by-step explanations assist users to understand the process. Furthermore, despite data transformations generated in the later iteration stages can be complex, users only need to verify its correctness against its predecessor because Data Formulator 2 users create visualizations incrementally. This considerably lowers users' verification efforts, as we discovered in our study in Section 4. As previously mentioned in Figure 8, when the user discovers errors, they can take advantages of the data thread's iterative mechanism to rerun, follow up or revise instructions to correct results.\nBenefiting from the decoupled chart specification and data transformation processes, when the user wants to update visualization styles (e.g., change color scheme, change sort order of an axis, or swap encodings) that do not require additional data transformation, they can directly perform edits in the concept encoding shelf, by expanding the channel property and update parameters or swapping encoded fields. These updates are directly reflected in the Vega-Lite script and rendered in the main panel. Unlike interactions with AI which has a slightly delayed response time, this approach allows the user to achieve quick and precise edits with immediate visual feedback to refine the design."}, {"title": "Implementation", "content": "Data Formulator 2 is implemented as a React web application, with a backend Python server running on a Dv2-series CPU with 3.5 GiB RAM. Data Formulator 2 has been tested with different versions with OpenAI models, including GPT-3.5-turbo, GPT-4, GPT-4o and GPT-40-mini (we used GPT-3.5-turbo in our user study) all of which except GPT-4 can generally response within 10 seconds. Since the LLM generates code to manipulate data as opposed to directly consume data, data size does not affect its response time. Data Formulator 2 can sometimes be slow due to Vega-Lite rendering overhead (e.g., large dataset with > 20,000 rows, long data threads with > 20 charts), we envision that on-demand re-rendering of charts can improve its performance in deployment."}, {"title": "Evaluation: Iterative Exploratory Analysis", "content": "We conducted a user study to understand potential benefits and usability issues of Data Formulator 2, as well as strategies developed by users when iteratively creating visualizations in an exploratory data analysis session."}, {"title": "Study Design", "content": "Participants. After piloting and refining the design of user study and Data Formulator 2 with three volunteers, we recruited eight participants from a large company. Participants self rated their skills (Figure 9) on a scale (\"Novice,\u201d \u201cIntermediate,\u201d \u201cProficient,\u201d and \u201cExpert\") in the following aspects: (1) chart creation \u2013 experience with chart authoring tools or libraries, (2) data transformation \u2013 experience with data transformation tools and library expertise, (3) programming, and (4) AI assistants \u2013 experience with large language models (e.g., ChatGPT [1]) and prompting."}, {"title": "Results", "content": "Task completion. All participants successfully completed all 16 visualizations (Figure 9): participants took less than 20 mins on average to finish the seven charts in task 1, and about 33 mins for the nine charts in task 2. Since we let participants deviate from the main exploration task (e.g., in task 2, P4 asked to sort the bar chart for top profitable movies are based on their profits, even though it was not required), the recorded completion time is an overestimate of the actual task time. During the study, six participants asked for hints to get unstuck during tasks; we categorize them as follows:"}, {"title": "Iteration styles", "content": "Data Formulator 2 lets users develop their own iteration strategies. We observed three major distinct styles of iteration, in terms of which tables or charts participants chose to derive a new chart.\nThe first type of users preferred to achieve a particular chart through small, incremental changes from an existing chart that shared either similar data fields or similar chart configuration. For example, P2 and P3 chose to create the line chart showing profit ratio trends overtime on top of the bar chart showing the average profit ratio per genre, and next visualized movies with highest profit ratio further on top, since they share the same derived field profit ratio. P2 mentioned \"I definitely like to be able to just work on top of that and like going forward by just giving a new prompt, because it remembers the context prior to the last one, it ends up generating the right data and visualization.\" P2 further commented that they did not like too much branching: \"...felt that it would be harder to go back to the source and fix every single time.\" P7 also preferred incremental changes, but with a focus on visual similarity as opposed to data similarity."}, {"title": "Verification", "content": "To proceed through iterative exploration, or repeat/correct a step, participants needed to verify that the chart or transformation was performed correctly. Some used the explanations of the code, some (even non-python programmers) used the actual code, and some used the result tables to validate the impact of the transformations. P3 mentioned \u201cas an expert, I like to see the prompt to the model, and then the code generated; but as a business user, I would imagine using more data, chart, and explanations.\u201d P4 mentioned \"[explanation] steps were really, really helpful in terms of figuring out whether it is doing the right thing as to what I'm asking it to do. That and also the data chart underneath.\u201d Interestingly, P7 stated that they preferred to use code rather than explanations of the code, but in the study, they used almost exclusively the explanations. They stated that they felt some pressure from the study environment not to spend too much time understanding code for which they were not familiar with, but they would trust code more. We also observed participants who developed trust in a workflow (by examining code and data tables) when it was straightforward, and then, they assumed the more complicated transformations built on top of these steps worked."}, {"title": "Related Work", "content": "Data Formulator 2 builds on top of existing work on data transformation, chart authoring, and AI-powered visualization tools.\nLLM-powered visualization tools. Large language models' code generation ability [1, 5, 24, 50] motivates the designs of new AI-powered visualizations tools [10, 26, 49, 55] that allows users to create visualization using high-level natural language descriptions. For example, given a dataset and a visualization prompt, LIDA [9] automatically generates a data summary and prompts the LLM to generate python code to transform data and generate visualizations. Because LLMs can struggle in understanding complex chart logics, ChartGPT [49] decomposes visualization tasks into fine-grained reasoning pipelines (e.g., data column selection, filtering logic, chart type, visual encoding), using chain-of-thoughts prompting [56] to guide LLMs to generate code step by step. Data Formulator [55] leverages LLMs to derive new data columns that can be used in traditional shelf-configuration UI. Because these tools focuses on single-turn user interaction with abstract NL descriptions, they are not suitable for iterative analysis where the analyst may branch or revise designs throughout. For multi-turn interactions, users can directly have conversation with LLMs in Code Interpreter [1] or Chat2Vis [26]: Code Interpreter equips the LLM with a Python interpreter so that the model can generate and execute code to transform data and create visualizations with the user interactively; Chat2Vis further includes visualization-specific prompts to help the model generate visualizations more reliably. Since these tools organize the dialog linearly, when the context contains branches, the user needs extract efforts to explain the task so that the model can retrieve the correct context, otherwise the model are more likely to produce undesired results [14, 21, 65]. Besides, since these tools are based on NL inputs, when the user has concrete designs in mind, they need additional efforts to elaborate the design clearly (especially when the design is complex) so that the model can produce their desired results."}, {"title": "Conclusion", "content": "Visualization authors often create visualizations in an iterative fashion, going back and forth between data transformation and visualization steps. To achieve such iterative analysis process, authors not only needs to to be proficient with data transformation and visualization tools, but also needs to spend considerable efforts managing the branching history consisting of many different versions of data and charts. Despite AI-powered tools have been developed to reduce users efforts, they do not work well for iterative analysis, because they often expect users to specify their intent all at once with only NL inputs. We presented Data Formulator 2, an interactive system for iterative creation of rich visualizations. Data Formulator 2 features a multi-modal UI that lets users to specify visualization with blended UI and NL inputs. Benefiting from both the precision of UI interaction and expressiveness of NL descriptions, users can more precisely convey complex designs without verbose prompts. To support management of the iteration history, Data Formulator 2 introduces data threads, where users can navigate, branch and reuse previous designs towards new ones as opposed to creating everything from scratch. In the user study, we invited eight participants to reproduce two challenging data exploration sessions consisting of 16"}]}