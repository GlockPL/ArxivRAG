{"title": "pyrtklib: An open-source package for tightly coupled deep learning and GNSS integration for positioning in urban canyons", "authors": ["Runzhi Hu", "Penghui Xu", "Yihan Zhong", "Weisong Wen"], "abstract": "Artificial intelligence (AI) is revolutionizing numerous fields, with increasing applications in Global Navigation Satellite Systems (GNSS) positioning algorithms in intelligent transportation systems (ITS) via deep learning. However, a significant technological disparity exists as traditional GNSS algorithms are often developed in Fortran or C, contrasting with the Python-based implementation prevalent in deep learning tools. To address this discrepancy, this paper introduces pyrtklib, a Python binding for the widely utilized open-source GNSS tool, RTKLIB. This binding makes all RTKLIB functionalities accessible in Python, facilitating seamless integration. Moreover, we present a deep learning subsystem under pyrtklib, which is a novel deep learning framework that leverages pyrtklib to accurately predict weights and biases within the GNSS positioning process. The use of pyrtklib enables developers to easily and quickly prototype and implement deep learning-aided GNSS algorithms, showcasing its potential to enhance positioning accuracy significantly.", "sections": [{"title": "I. INTRODUCTION", "content": "With the rapid growth of computing speed and power, artificial intelligence (AI), epitomized by deep learning (DL), is now practical for everyday use. Due to its excellent non-linear fitting capability, deep learning has proven effective in numerous fields, including computer vision (CV) and natural language process (NLP). In modern intelligent transportation systems (ITS), deep learning also demonstrates potential in areas such as traffic control [1], autonomous driving (AD) [2], and human behavior analyze [3]. Global positioning, commonly known as global navigation satellite system (GNSS) positioning, is crucial for perception and decision-making within ITS [4]\u2013[6]. Consequently, there is a pressing need within the ITS community to integrate deep learning techniques into global positioning strategies.\nCurrently, GNSS positioning accuracy can achieve centimeter-level precision under open skies. However, in urban canyons, the performance dramatically declines as GNSS signals are diffracted, reflected, and even obstructed by high-rise buildings [4], [7]. To mitigate the adverse effects of non-line-of-sight (NLOS) and multipath interference, two strategies are implemented: directly correcting measurements to improve accuracy and downweighing measurements from low-quality signals in the weight least squares (WLS) solution process [8]. Traditional methods use physical models and empirical formulas to model biases and weights, providing high interpretability but often struggling in complex and dynamically changing environments. In contrast, data-driven deep learning approaches can potentially model biases and weights more effectively, provided that the training data is of high quality.\nDeep learning frameworks and applications have overwhelmingly adopted Python due to its simplicity, flexibility, and the vast ecosystem of libraries and tools available, such as TensorFlow [9] and PyTorch [10]. This accessibility and ease of use facilitate rapid prototyping and deployment of complex models, making Python the language of choice for most new developments in deep learning and AI. Meanwhile, GNSS software historically leans on programming languages like Fortran and C [11]\u2013[13]. Though these languages offer high performance and control over hardware interaction, which are critical for the real-time processing demands and precision required in satellite navigation, these languages are not equipped with good compatibility with Python. This divergence in technological stacks presents a significant challenge for integrating cutting-edge AI methodologies, like deep learning, directly into traditional GNSS software systems. Bridging this gap requires either extending these systems to interface with Python-based tools or developing new capabilities within the GNSS software to support advanced machine learning techniques directly in C or Fortran, both of which entail substantial development and potential refactoring of existing codebases.\nTo fill this gap, we make the Python binding, named pyrtklib, for the most popular open-source GNSS library, RTKLIB [12]. pyrtklib provides access to the full functionalities of RTKLIB, combining the speed of C with the convenience of Python. Additionally, we introduce a deep learning subsystem within pyrtklib for predicting weights and biases, which has been validated on our datasets. The following contributions of this paper are presented:\n1) This paper developes a network to predict pseudorange biases and integrates these predictions into the correction of GNSS pseudorange measurements, tightly coupling them within the least squares process.\n2) This paper has designed a network specifically to predict weights for each measurement, which are then utilized in the weighted least squares process."}, {"title": "II. RELATED WORKS", "content": "There are several existing GNSS tools as shown in Table I. Bernese GNSS [11] and MuSNAT [13] are two popular commercial GNSS software, however, their closed-source nature limits their usability for algorithm development. NavSU, MAAST, and goGPS [16] are open-source software programs written in Matlab. Despite their open-source status, a paid Matlab license is still required for their use. Laika and gnss_lib_py both are Python libraries, but they only provide basic GNSS functions and lack the support for real-time kinematic (RTK) and precise point positioning (PPP). RTKLIB is a comprehensive open-source GNSS tool that enjoys widespread use not only within the GNSS community but also in the robotics sector [17]\u2013[20]. However, its C-based architecture poses integration challenges with Python. Additionally, while the above tools utilize empirical formulas to predict variance and control weights, they lack the capability to correct pseudorange biases. To address this need, we developed pyrtklib. This library, written in C++ and integrated into Python, combines the efficiency of C with the ease of use of Python.\nIn our recent review paper [21], we categorize the application of deep learning in GNSS as follows:\n1) Improved pseudorange measurement\n2) Measurement status prediction\n3) Positioning level information\n4) Measurement error prediction\nThe approach outlined in 1) aims to enhance the correlator and discriminator at the receiver level to improve signal quality control [22]\u2013[24]. These methods are highly integrated, forming a super tightly coupled relationship between deep learning and GNSS. However, upgrading the receiver hardware is challenging to scale rapidly. The objective of 2) is to utilize deep learning to classify NLOS and multipath signals in advance, thus eliminating or mitigating their adverse effects [25]\u2013[38]. The goal of 3) is to predict the final positioning error and apply corrections [39]\u2013[44]. These strategies represent preprocess and postprocess applications that are loosely coupled with deep learning in GNSS. Lastly, the algorithms discussed in 4) have a direct impact on the measurements and are considered tightly coupled [31], [37], [45], [46].\nSuper tightly coupled methods require support from either hardware or software-based receivers. In contrast, the labels for loosely coupled methods are easily accessible when the ground truth position is known, allowing the training process to be decoupled from the positioning process. However, for tightly coupled methods, measurement correction is intricately linked to positioning, making it impractical to separate training and positioning processes. In such scenarios, it is advantageous for both positioning and training to be conducted in the same programming language. To this end, our framework built on pyrtklib is specifically designed to support tightly coupled deep learning and GNSS approaches. We anticipate that our framework will facilitate the development of tightly coupled algorithms."}, {"title": "III. TIGHTLY COUPLED DEEP LEARNING FRAMEWORK FOR GNSS", "content": "A standard GNSS model can be formulated as:\np = r + c\\Delta t + I +T+\\epsilon\\tag{1}\nHere, p represents the pseudorange measured by the receiver, \u0441 is the speed of light, and I and T signify the ionospheric and tropospheric delays, respectively. These delays are typically estimated using atmospheric models in single point positioning. \\Delta t denotes the receiver's time bias and \\epsilon represents Gaussian noise. The variable r denotes the distance between the satellite and the receiver, which is formulated as follows:\nr = \\sqrt{(x_s \u2212 x_r)^2 + (y_s \u2013 y_r)^2 + (z_s \u2013 z_r)^2}\\tag{2}\nwhere $x_s$, $y_s$, $z_s$ and $x_r$, $y_r$, $z_r$ are the coordinates of the satellite and the receiver in Earth-centered, Earth-fixed (ECEF) coordinate system respectively. When there are n pseudorange measurements, the observation function is:\n\\bm{Z} = h(\\bm{y}) = \\begin{bmatrix}r_1 + c\\Delta t + I_1 + T_1\\\\ r_2 + c\\Delta t + I_2 + T_2\\\\ ...\\\\ r_n + c\\Delta t + I_n + T_n\\end{bmatrix}\\tag{3}\nwhere $\\bm{Z}$ = $[p_1, p_2 ..., p_n]^T$ and $\\bm{y}$ = $(x_r, y_r, z_r, \\Delta t)$, which are the measurements and state respectively. The first-order approximation of the function can be written as:\nh(\\bm{y} + \\Delta \\bm{y}) \\approx h(\\bm{y}) + \\bm{H}\\Delta \\bm{y}\n$\\bm{H}$ is the Jacobian matrix:\n\\bm{H} = \\begin{bmatrix}\\frac{x_1-x_r}{r_1} & \\frac{y_1-y_r}{r_1} & \\frac{z_1-z_r}{r_1} & c\\\\ \\frac{x_2-x_r}{r_2} & \\frac{y_2-y_r}{r_2} & \\frac{z_2-z_r}{r_2} & c\\\\ ... & ... & ... & ...\\\\ \\frac{x_n-x_r}{r_n} & \\frac{y_n-y_r}{r_n} & \\frac{z_n-z_r}{r_n} & c\\end{bmatrix}\\tag{5}\nThe Gussian-Newton-based non-linear weight least squares (WLS) is employed to solve the unknown state y by iteration as follows:\n\\Delta y = (\\bm{H}^T \\bm{W} \\bm{H})^{-1} \\bm{H}^T \\bm{W} (\\bm{Z}-h(y_i))\\tag{6}\ny_{i+1} = y_i + \\Delta y\\tag{7}\nwhere W is the weight square matrix, and yo is the initial guess of the state, typically set to set (0,0,0,0). The iteration process is halted once ||\u2206y|| falls below a predefined threshold, at which point the final y represents the determined position.\nNote that the WLS positioning process requires two inputs, W and Z, We simplify the expression using the following equation:\ny = f_{WLS}(\\bm{W},\\bm{Z})\\tag{8}\nAlthough the description above represents an ideal scenario, various factors such as NLOS and multipath effects, imprecise ephemerides, or receiver errors can introduce biases. Consequently, the model can be reformulated as follows:\np = r + c\\Delta t +I+T+b+ \\epsilon\\tag{9}\nwhere b is the unmodeled bias. To achieve more accurate positioning results despite these biases, two strategies are employed. The first strategy involves directly correcting the pseudorange measurements, while the second strategy entails down-weighting the unhealthy measurements. In the following subsection, we will introduce a tightly coupled deep learning and GNSS framework designed for bias correction and weight prediction."}, {"title": "B. Tightly coupled deep learning/GNSS framework", "content": "As illustrated in equation (8), achieving optimal positioning results relies on accurately predicting the weights W or obtaining improved measurements Z. By utilizing the ground truth position and employing the mean square error (MSE) as the loss function, we can optimize both the measurements and weights using the following equations:\nL(y_{gt}, y) = (y_{gt} - y)^2\\tag{10}\n\\frac{\\partial L}{\\partial \\bm{Z}} = \\frac{\\partial L}{\\partial y} \\frac{\\partial y}{\\partial \\bm{Z}}\\tag{11}\n\\frac{\\partial L}{\\partial \\bm{W}} = \\frac{\\partial L}{\\partial y} \\frac{\\partial y}{\\partial \\bm{W}}\\tag{12}\nEquation (10) defines the loss function. Equations (11) and (12) demonstrate the gradients of $\\bm{Z}$ and $\\bm{W}$, respectively, calculated using the chain rule under the specified conditions of the loss function. Should $\\bm{W}$ and $\\bm{Z}$ be derived from a neural network, these gradients are then propagated backward through the backpropagation process.\nIn this demonstration, three key features are selected as inputs:\nCarrier-to-noise density (C/N0): C/N0 is an essential parameter that quantifies the quality of the received signal. It is defined as the ratio of the carrier power to the noise power per unit bandwidth and is typically expressed in decibels-hertz (dB-Hz).\nElevation Angle: The elevation angle is the vertical angle measured from the receiver's horizon to the line of sight of a satellite. This measurement indicates the satellite's position relative to the receiver's location on Earth. In urban environments, satellites with higher elevation angles are often line-of-sight (LOS) satellites and are less likely to be obstructed.\nResiduals from Equal Weight Least Squares Solution: Initially, the position is calculated using an equal weight least squares solution. The residuals from each measurement are then analyzed. This feature aids in identifying potentially problematic or unhealthy measurements, thereby enhancing the reliability of the positioning data.\nThese three features are compiled into a vector x = [C/N0, Elevation, Residual] for the network input.\n1) Pseudorange bias correction network: The detailed structure of the bias network is depicted in Figure 1a. This network comprises a straightforward four-layer architecture, including:\nAn input layer, which has a configuration of 3 \u00d7 1, corresponding to the three input features.\nTwo hidden layers, sized 64 \u00d7 1 and 128 \u00d7 1 respectively, designed to progressively refine the feature representations.\nAn output layer, configured as 1 \u00d7 1, which outputs the predicted bias.\nThe rectified linear unit (ReLU) is employed as the activation function throughout the network to introduce non-linearity, enhancing the model's capability to learn complex patterns."}, {"title": null, "content": "The final output represents the desired bias, which is used to predict the pseudorange bias as follows:\nb = f_{nn,b}(\\bm{X}; \\Theta)\\tag{13}\nwhere $\\bm{X}$ represents the batch input, defined as $\\bm{X}$ = $[\\bm{X_1},\\bm{X_2},...,\\bm{X_n}]$ and $\\bm{b}$ = $[b_1, b_2,...,b_n]$ denotes the corresponding batch output. $\\Theta$ symbolizes the set of parameters within the neural network. Using these definitions, the corrected measurements and resultant positions can be expressed as follows:\n\\hat{\\bm{Z}} = \\bm{Z}-\\bm{b}\\tag{14}\n\\hat{y} = f_{WLS}(\\bm{W},\\hat{\\bm{Z}}) = f_{WLS}(\\bm{W},\\bm{Z} - f_{nn,b}(\\bm{X}; \\Theta))\\tag{15}\nThe training process can be formulated as follows:\nargmin\\sum_{i=1}^{n}L(y_{gt}, f_{WLS}(\\bm{W}, \\bm{Z} - f_{nn,b}(\\bm{X_i}; \\Theta)))\\tag{16}\n\\Theta\n\\frac{\\partial L}{\\partial \\Theta} = \\frac{\\partial L}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial \\hat{\\bm{Z}}} \\frac{\\partial \\hat{\\bm{Z}}}{\\partial \\bm{b}} \\frac{\\partial \\bm{b}}{\\partial \\Theta}\\tag{17}\n\\Theta_{n+1} = \\Theta_{n} - \\eta \\frac{\\partial L}{\\partial \\Theta}\\tag{18}\nEquation (16) illustrates that the training objective is to identify the optimal network parameters, $ \\Delta \\Theta$, that minimize the loss function. Equation (17) details the gradient transfer process, with \u03b7 representing the learning rate.\n2) Weights prediction network: The detailed structure of the weight network is depicted in Figure 1b. While similar to the bias network, this network employs a sigmoid activation function instead of ReLU. The network is designed to predict the weights as follows:\nw = f_{nn,w}(\\bm{X}; \\Theta)\\tag{19}\n\\bm{W} = diag(w)\\tag{20}\nwhere $w$ = $[w_1, w_2, ..., w_n]$ represents the vector of predicted weights in the batch output. W is a diagonal matrix composed of the elements from w. The position process is then formulated as follows:\n\\hat{y} = f_{WLS}(\\hat{\\bm{W}}, \\bm{Z}) = f_{WLS}(f_{nn,w}(\\bm{X}; \\Theta), \\bm{Z})\\tag{21}\nThe training process is formulated as follows:\nargmin\\sum_{i=1}^{n}L(y_{gt}, f_{WLS}(f_{nn,w}(\\bm{X_i}; \\Theta), \\bm{Z}))\\tag{22}\n\\Theta\n\\frac{\\partial L}{\\partial \\Theta} = \\frac{\\partial L}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial \\hat{\\bm{W}}} \\frac{\\partial \\hat{\\bm{W}}}{\\partial \\Theta}\\tag{23}\n\\Theta_{n+1} = \\Theta_{n} - \\eta \\frac{\\partial L}{\\partial \\Theta}\\tag{24}\nEquation (23) demonstrates the gradient transfer process within the tightly coupled deep learning and GNSS framework, tracing the path from the position loss function to the network parameters through the weights."}, {"title": null, "content": "3) Bias correction and weights prediction network: The previously described frameworks focus exclusively on either bias or weight prediction, yet it is possible to predict both simultaneously. The architecture of this dual-prediction network is illustrated in Figure 1c. In this network, ReLU serves as the activation function for the initial two layers. The output layer features two outputs: one for bias and another for weight. To ensure that the weight values range from zero to one, a sigmoid function is applied specifically to the weight output. This design allows the bias and weight predictions to share network parameters, effectively extracting information from the input. The predicted bias and weight are denoted as follows:\n(b, \\hat{\\bm{W}}) = f_{nn,bw} (\\bm{X}; \\Theta)\\tag{25}\n\\bm{b} = f^{b}_{nn,bw} (\\bm{X}; \\Theta)\\tag{26}\n\\hat{\\bm{W}} = f^{w}_{nn,bw} (\\bm{X}; \\Theta)\\tag{27}\nThe superscript b and w represent the bias output and the weight output, respectively. With these outputs defined, the positioning process can be formulated as follows:\n\\hat{\\bm{Z}}\n\\hat{y} = f_{WLS}(\\hat{\\bm{W}}, \\bm{Z} - \\bm{b})\\tag{28}\n= f_{WLS}(f^{w}_{nn,bw}(\\bm{X}; \\Theta), \\bm{Z} - f^{b}_{nn,bw} (\\bm{X}; \\Theta))\nThe training process is delineated as follows:\n\\hat{\\bm{Z}}\n\\Theta = argmin \\sum_{i=1}^{n} L(y_{gt}, f_{WLS}(\\hat{\\bm{W}}, \\bm{Z} - \\bm{b}))\\tag{29}\n\\Theta\n\\frac{\\partial L}{\\partial \\Theta} = \\frac{\\partial L}{\\partial \\bm{b}} \\frac{\\partial \\bm{b}}{\\partial \\Theta} + \\frac{\\partial L}{\\partial \\hat{\\bm{W}}} \\frac{\\partial \\hat{\\bm{W}}}{\\partial \\Theta}\\tag{30}\n\\Theta_{l+1} = \\Theta_{l} - \\eta \\frac{\\partial L}{\\partial \\Theta}\\tag{31}\nEquation (30) encapsulates how the gradients are derived from both the biases and weights, effectively linking the loss function to the network parameters \\Theta through tightly integrated feedback loops."}, {"title": "IV. EXPERIMENT", "content": "In the preceding section, we detailed the training and prediction processes for our tightly coupled deep learning GNSS positioning framework. In this section, we will evaluate our approach and compare its performance against other tools. To facilitate a concise discussion, we will use the abbreviations TDL-B, TDL-W, and TDL-BW to refer to the bias correction network, weight prediction network, and combined bias correction and weight prediction network, respectively."}, {"title": "A. Experiment Setup", "content": "Four datasets are utilized for evaluation. Three of these datasets were collected in the urban areas of Hong Kong's Kowloon Tong (KLT), and one dataset was gathered in the Whampoa area of Hong Kong. KLT is characterized as a light urban area, whereas Whampoa is considered a deep urban area with an approximate 2D positioning error of 18 meters. The specific details of each dataset are provided in Table II, where DoU represents the degree of urbanization. KLT3 was designated for training, while the remaining datasets were used for testing.\nA Ublox-F9P receiver was utilized to receive and decode GNSS signals at a frequency of 1Hz. Additionally, a NovAtel SPAN-CPT system [47], providing a Real-Time Kinematic (RTK) GNSS/INS integrated solution, was used to generate centimeter-level ground truth data at 100Hz. Further details are provided in Table III. These setups are consistent with those used in our previously open-sourced UrbanNav datasets [48].\nDetails of the training process for the three networks are outlined in Table IV. While most parameters are consistent across the networks, the number of training epochs varies. Specifically, the TDL-BW model utilizes fewer epochs to prevent overfitting, which is a risk due to its complex nature. The training loss curves for each network are illustrated in Figure 2.\nThe training process involves a critical detail regarding the initial state yo, which should not be set as (0,0,0,0). As depicted in Equations (22), (16), and (29), the process consists of a two-step optimization. Initially, the position state is solved using WLS optimization, and this solution is then tightly coupled to the network. The gradient of the weight in Equation (6) largely depends on the H matrix, which is derived from the current position solution. Per Equations (6) and (7), the solution accumulates iteratively. In early iterations,"}, {"title": "B. Experiment Result", "content": "1) Competing methods: In this section, we present our results and compare them with those obtained using RTKLIB and goGPS. Specifically, in RTKLIB, the weights assigned to each measurement are primarily derived from the elevation angles:\n\\sigma^2 (\\theta) = a^2 + \\frac{b^2}{sin^2\\theta}\\tag{32}\n\\bm{W} = \\frac{1}{\\sigma^2 (\\theta)}\\tag{33}\nIn RTKLIB, the weight assigned to each measurement depends on the elevation angle, denoted by \u03b8. The coefficients a and b, known as super parameters, are typically set at 0.3. Meanwhile, in goGPS [16], weights are computed based on both the C/N0 and the elevation angle, as follows:\nw = \\{\\begin{matrix}\\frac{k_1(s)}{sin^2\\theta}, C/N0 \\geq s_1\\\\ \\frac{1}{2} { ( (\\frac{sin^2\\theta}{\\frac{\\pi}{2} (a + tan^{-1} (k_2(s) -1) ) }) + 1) }, S  < s_1\\end{matrix}\\tag{34}\nIn this formula, S represents the C/N0, and \u03b8 denotes the elevation angle. The parameters A, a, s0, and s1 are super parameters and are typically set to 30, 20, 10, and 50, respectively. These values are crucial for determining the weights based on the quality and position of the satellite signals."}, {"title": "V. DISCUSSION", "content": "In the section, we focus on two typical outliers of TDL-BW in the two representative scenarios, Case A and Case B, depicted in Figure 6. The errors in the two cases are 31.89 meters and 1061.09 meters respectively. These scenarios highlight the challenges posed by LOS and NLOS conditions on satellite signal reception and the consequent effects on positioning accuracy.\nIn case A, as illustrated in Figure 6a and detailed in Table VII, the TDL-BW network outputs show a clear differentiation between LOS and NLOS signals, as indicated by the color-coded PRN entries (green for LOS and red for NLOS). This scenario, characterized by a tree canopy, predominantly exhibits NLOS conditions, impacting the weight distribution among satellites. Notably, satellites labeled as LOS (G07 and G01) receive non-zero weights, affirming the network's capability to identify viable signals amidst obstructions. However, the network misclassifies satellite G22, positioned near the edge of a building possibly affected by diffraction, assigning it no weight. A critical observation here is the excessive elimination of NLOS satellites, which, while reducing noise from obstructed signals, also minimizes redundancy in the available data for accurate positioning, potentially compromising the robustness of the positioning solution.\nPresented in Figure 6b and Table VIII for case B, this scenario demonstrates a similar pattern where the network effectively identifies and assigns higher weights to LOS satellites (C10 and G19). It also appropriately categorizes C07, which, despite potential obstructions, is deemed reliable. However, akin to Case A, the network's stringent filtering leads to the exclusion of numerous NLOS satellites, manifesting in an overly sparse dataset that might detract from the accuracy of the resultant positioning due to insufficient satellite coverage and geometry.\nBoth cases underscore the TDL-BW network's proficiency in distinguishing between LOS and NLOS satellites and its consequential decision-making concerning weight assignments. While this ability is advantageous for enhancing signal quality by excluding NLOS influences, it also raises concerns regarding the adequacy of satellite data for reliable positioning. The elimination of too many satellites, particularly under dense canopy or urban settings where NLOS conditions are prevalent, could severely limit the system's operational effectiveness by reducing the geometric diversity necessary for optimal positioning. The less robust performance of TDL-W in several situations is also due to the failure to allocate weights to enough measurements. In contrast, the results from TDL-B in the two cases are 5.52 meters and 223.50 meters, which are much better than TDL-BW and TDL-W. Therefore, due to the unreliable results from TDL-W and TDL-BW, where only a few measurements are weighted, it is advisable to switch to TDL-B."}, {"title": "VI. CONCLUSION", "content": "In this paper, we introduced pyrtklib, a Python binding for the widely-used GNSS library, RTKLIB. Utilizing pyrtklib, we developed a tightly coupled deep learning subsystem that predicts weights and biases for each satellite, thereby enhancing positioning performance. Our methods were compared against RTKLIB and goGPS. The results demonstrate that TDL-BW, which simultaneously predicts both weights and biases, outperforms the others. This network effectively differentiates between line-of-sight (LOS) and non-line-of-sight (NLOS) satellites, assigning appropriate weights and biases accordingly. Both pyrtklib and the deep learning subsystem are available as open-source resources at https://github.com/IPNL-POLYU/pyrtklib and https://github.com/ebhrz/TDL-GNSS. As shown in Figure 7, pyrtklib has been downloaded approximately 20,000 times over the past six months.\nThe network structure employed in this demonstration is relatively straightforward, and the feature set used is limited. Looking ahead, our framework is designed to seamlessly incorporate a broader range of deep learning approaches. We plan to enhance the network architecture to account for spatial and temporal variations, and to integrate multi-modal inputs such as images, point clouds, and maps. Our aim is to contribute significantly to the community by bridging the gap between AI and GNSS technologies, enriching the potential applications and effectiveness of both fields."}, {"title": "VII. BIOGRAPHY SECTION", "content": "Runzhi Hu was born in Leshan, Sichuan, China.\nHe received his B.S and master degrees in mechanical engineering and computer science, respectively, from China Agricultural University. He now is a Ph.D candidate at the Hong Kong Polytechnic University. His research interests include HD map, multi-sensor fusion, SLAM, and GNSS positioning in urban canyons.\nPenghui Xu (Graduate Student Member, IEEE) received a B.S. degree from South China Agricultural University in 2015. In 2017, he obtained his MSc degree in mechanical engineering from The Hong Kong Polytechnic University. After that, he mainly works in machine learning algorithm development. Currently, he is a Ph.D. candidate at The Hong Kong Polytechnic University. His research interests include machine learning, GNSS urban localization, and multi-sensor integration for positioning.\nYihan Zhong received the bachelor's degree in process equipment and control engineering from Guangxi University, Nanning, China, in 2020, and the master's degree from The Hong Kong Polytechnic University (PolyU), Hong Kong, in 2022, where he is currently pursuing the Ph.D. degree with the Department of Aeronautical and Aviation Engineering (AAE). His research interests include collaborative positioning and low-cost localization.\nWeisong Wen (Member, IEEE) received a BEng degree in Mechanical Engineering from Beijing Information Science and Technology University (BISTU), Beijing, China, in 2015, and an MEng degree in Mechanical Engineering from the China Agricultural University, in 2017. After that, he received a PhD degree in Mechanical Engineering from The Hong Kong Polytechnic University (PolyU), in 2020. He was also a visiting PhD student with the Faculty of Engineering, University of California, Berkeley (UC Berkeley) in 2018. Before joining PolyU as an Assistant Professor in 2023, he was a Research Assistant Professor at AAE of PolyU since 2021. He has published 30 SCI papers and 40 conference papers in the field of GNSS (ION GNSS+) and navigation for Robotic systems (IEEE ICRA, IEEE ITSC), such as autonomous driving vehicles. He won the innovation award from TechConnect 2021, the Best Presentation Award from the Institute of Navigation (ION) in 2020, and the First Prize in Hong Kong Section in Qianhai-Guangdong-Macao Youth Innovation and Entrepreneurship Competition in 2019 based on his research achievements in 3D LiDAR aided GNSS positioning for robotics navigation in urban canyons. The developed 3D LiDAR-aided GNSS positioning method has been reported by top magazines such as Inside GNSS and has attracted industry recognition with remarkable knowledge transfer."}]}