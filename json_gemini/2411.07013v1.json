{"title": "A neural-network based anomaly detection system and a safety protocol to protect vehicular network", "authors": ["Marco Franceschini"], "abstract": "The increasing need of road efficiency, driving safety, and sustainable transport relies on Cooperative Intelligent Transport Systems (CITS) developments in modern transportation, with a stress on the Co Communications. By enabling vehicles to communicate with each other, exchanging real-time data through an ad-hoc network, CITS can improve road safety and efficiency. Some of the challenging tasks in vehicular networks include the protection and the guarantee of correctness of the exchanged data. The common practice to deal with those tasks involves utilizing a Public Key Infrastructure to authorize vehicles using the network. Despite this, it doesn't mean that an authorized vehicle cannot misbehave. To achieve driving safety, a standard solution is using a Misbehavior Detection System that can detect malfunctions leading to wrong, missing, or misleading messages in the network by analyzing the data exchanged in every message.\nThis thesis presents a simple Machine Learning framework based on Long- short Term Memory neural networks, a standard approach in the referring literature for misbehavior detection. The detection system must be trained off-line, as usually done, on a standard dataset, and for this purpose, the VeReMi dataset has been chosen. Many works focus only on the off-line model, trying to reach the best scores on the whole dataset. This thesis aims to introduce the simple detection framework at run-time on a completely different scenario, compared to the one on which the dataset was built, suitable to be executed on single vehicles while they communicate. The detector is validated within a platooning application, showing that, if properly used, the predictions can prevent practically all accidents caused by misbehavior. In particular, the detector's predictions are provided to a simple defense protocol that dismantles the platoon if a message is detected to be anomalous.\nThe results show that the detection system and the defense protocol can save almost all the accidents due to misbehavior conditions in the simulated set. In particular, detecting a general misbehavior condition is precisely predicted, with an excellent accuracy score. Although those results, the detection system cannot identify each kind of misbehavior by assigning a label to each one, with reasonable accuracy results, due to very different traffic conditions while running on-line. This suggests that designing a more complex defense protocol with personalized responses for each misbehavior, usable in all traffic conditions, is impossible, even with more sophisticated Artificial Intelligence solutions. Despite this, the developed system gives a solid basis to work on it, and with", "sections": [{"title": "Introduction", "content": "Cooperative Intelligent Transport Systems (CITS) represent a significant ad- vance in modern transportation, potentially transforming how vehicles and infrastructure interact on the road [1]. As urbanization and traffic conges- tion continue to increase, the necessity of creating more efficient, safe, and sustainable transport systems has never been greater. The significance of CITS lies in its ability to improve road safety, traffic congestion, and decrease emissions. By enabling vehicles to communicate with each other and with infrastructures, CITS applications can help prevent accidents by sending timely warnings, optimizing traffic flow through smart intersection management, and reducing fuel consumption through features such as platooning\u00b9, eco-driving support\u00b2, intersection management\u00b3, emergency vehicle preemption\u2074, and many others. Studies [2]-[4] suggest that the implementation of CITS could result in a 50% reduction in road fatalities and a 20% decrease in fuel consumption and greenhouse gas emissions. Indeed, given the prevalence of human errors in vehicular accidents, it is not difficult to predict that the road accidents reduction can even approach 100%, as it is today in well managed railways. With their offer of benefits in safety, efficiency, and sustainability, CITS are a cornerstone of the future of transportation. As these technologies continue to"}, {"title": "Thesis Goals", "content": "To achieve CITS's objectives, with a specific emphasis on driving safety, a cryptographic defense based on PKI is not sufficient. It also requires a system capable of identifying malfunctions in authorized vehicles. The literature review about those MDSs is presented in detail in Sect. 2.2. Analyzing the works made about those kinds of systems, it emerges that the researchers are moving to Artificial Intelligence (AI) based solutions, focusing in particular on Neural Network (NN) models. To train an MDS based on an AI solution, a dataset containing misbehavior data and the exchanged messages in the VN is mandatory; the larger and more comprehensive the dataset is, the better. Then one can imagine solutions that keep learning from real traffic, but an initial base is mandatory to create a reliable system that analyze the exchange of messages in the real world to identify anomalies. Since many different models have been developed over the years, maintaining a standard dataset is a good practice to compare the results with the previous works and to increase the complexity of the same dataset while introducing new attacks and data. The Vehicular Reference Misbehavior (VeReMi) dataset [6], [7], a standard reference for evaluating misbehavior detection mechanisms for VANETs in many different works, is used for this thesis, and it is indeed one of the very few dataset available for research in this area. The original dataset includes several simple attacks. The purpose of this dataset is not only to establish a basis for comparing detection methods but also to act as a foundation for developing more complex attacks and find the relative countermeasures.\nThe literature analysis reveals that many works focus only on creating a good MDS trained on the whole VeReMi dataset, but they evaluate it only offline, using for the testing part of the same VeReMi dataset, failing to evaluate the MDS on-line, while the vehicles are running, exchange messages and behave on the road based on the information they receive. Obviously, when we talk about on-line testing we refer to a simulation environment, as experiments with real vehicles are still impossible in this field: indeed, also the VeReMi dataset is obtained with extended simulation experiments. The idea of this"}, {"title": "Thesis Structure", "content": "After analyzing the state of the art about this topic in Chapter 2, the first step to reach the goals defined is the definition of an MDS with an NN model, trained over the VeReMi dataset properly adapted and manipulated to fit the"}, {"title": "Related work", "content": "This literature review chapter aims to provide a comprehensive overview of the existing research and developments in security and privacy within VN, as well as the application of AI techniques for MDS. The chapter is divided into two main sections. The first section reviews the state-of-the-art in security and privacy management for VNs, covering standardization efforts, secure communication protocols, privacy-preserving techniques, and challenges associated with the deployment of secure vehicular communication systems. The second section focuses on the literature surrounding MDSs, particularly those utilizing AI and ML methodologies, which are pivotal for identifying and mitigating malicious activities and ensuring the robustness of VN. By synthesizing the findings from these domains, this chapter lays a solid foundation for understanding the current landscape of VN security and misbehavior detection. It also identifies gaps in the existing research, thereby setting the stage for developing advanced protocols and systems to enhance the security and reliability of future VNs."}, {"title": "Security and Privacy in Vehicular Networks", "content": "The first step in analyzing the state-of-the-art about security and privacy in VNs is to examine the current status of the standardization process.\nVarious standards have been already established related to this topic, partic- ularly by the European Telecommunications Standards Institute (ETSI). The recent document [8] (V2.1.1 \u2013 March 2024) details the requirements and the protocols for the distribution of security credentials in the Intelligent Transport Systems (ITS) framework. The specifications are technology-agnostic (i.e., they"}, {"title": "Standardization", "content": "Privacy management in VNs involves strategies and technologies designed to pro- tect the identity and location information of vehicles and their occupants while ensuring secure communication. After the standardization, significant advance- ments have been made to enhance privacy. The key strategy is pseudonymity [13], where vehicles use temporary identifiers that do not reveal the real identity of the vehicle's owner. Vehicles obtain pseudonyms from a trusted authority and use them to sign messages within the network. These pseudonyms are"}, {"title": "Privacy management", "content": "Cooperative Adaptive Cruise Control (CACC) [18] systems enable efficient transportation by allowing vehicles to communicate and behave cooperatively. However, this dependence on communication exposes vehicles to various security"}, {"title": "Studied attacks on Cooperative Adaptive Cruise Control", "content": "From a deep analysis of the literature about security and privacy, it emerges that standardization has made a lot of progress in that field by designing a secure architecture from a cryptographic point of view and some good approaches that could be used as privacy management, in order to maintain security and safety in the VN environment, but also remove some possible problems about privacy that a driver could require. Furthermore, by analyzing some other attacks, in particular, focusing on cooperative systems, it emerges that, even with this kind of security already standardized, a safe system against some possible attacks, like false data injection or possible misbehavior of the communication systems of some vehicles on the road, could be necessary. In particular, integrating an MDS on board could be the best solution to defend against that kind of problem."}, {"title": "Achievement", "content": "As the previous section said, traditional security mechanisms are sometimes insufficient because they only exclude outsider attackers who lack the proper cryptographic keys. However, insiders can still pose a threat since they might possess valid credentials, and the vehicles may still misbehave due to malfunc- tioning or malicious behavior. To address these security gaps, the authors of [5] introduce and analyze various misbehavior detection mechanisms that are capable of identifying insider attacks or malfunctioning based on the analysis of behavioral patterns. Here follows an overview of the types of misbehavior detection mechanisms analyzed:\n\u2022 Behavioral detection: Identifies anomalies by monitoring network nodes' behavior, such as message frequency and adherence to protocol norms. An example is a watchdog that checks packet forwarding without needing to understand message content.\n\u2022 Trust-based detection: Creates a reputation system where nodes earn and update trust scores based on their actions, often using voting mechanisms.\n\u2022 Consistency-based detection: Compares data from different nodes about the same event to find discrepancies indicating falsified information."}, {"title": "Misbehavior detection systems literature", "content": "These mechanisms have strengths but also some limitations, especially against an attacker who uses sophisticated strategies to mimic normal behaviors. So future researches in CITS focus on enhancing security and efficiency through hybrid detection mechanisms and advanced AI. Key areas include improving scalability, addressing new vulnerabilities, and balancing security with privacy.\nThe survey faced up in [5] prepared the field for new research topics, and one of the main ones could be the usage of ML and AI techniques to help and design some misbehavior detection algorithms. In [26] is presented a comprehensive overview of how ML techniques are utilized to enhance misbehavior detection in VNs. In the survey is highlighted that while ML offers significant advantages for security, challenges such as adapting to dynamic environments and ensuring privacy remain. Here are the primary ML methods discussed:\n\u2022 Supervised learning: Trains models using labeled data, subdivided into classification and regression.\n\u2022 Unsupervised learning: Identifies patterns in data without labels, useful for anomaly detection and clustering similar objects, which helps discover new misbehavior in VNs.\n\u2022 Reinforcement learning: Adapts by continuously improving decisions based on feedback, dynamically adjusting security measures.\n\u2022 Deep learning: Utilizes layered NNs to process large data volumes and extract complex features.\n\u2022 Transfer learning: Transfers knowledge from one problem to a related one, enhancing efficiency and scalability.\nThe first important comparison is between an NN approach against other types of algorithms. In particular two studies [27], [28] compare the same simulation structure firstly with ML-based algorithms unsupervised and semi- supervised, like k-Nearest Neighbors (k-NN), One-class Support Vector Machine and Isolation Forest, and then with an NN approach with algorithms like Au- toencoder Replicator Neural Networks and Long Short-Term Memory (LSTM) Networks. To compare those different approaches, the papers use the same sim- ulation environment, based on the Luxembourg SUMO Traffic (LuST) scenario"}, {"title": "Long Short-Term Memory systems", "content": "The first and most common approach to a misbehavior detection system based on an NN is to use LSTM to manage the data sequence. In particular, in [29], the VeReMi dataset is manipulated in a way to obtain sequences of 20 vectors with a sliding window of size 10, labeled as malicious or not. In this case, a Support Vector Machine (SVM) classifier is also used to extract 11 more features, which include behavioral deviation, location plausibility, velocity information, and comprehensive information. The model is trained on 90% of the sequences labeled as normal (non-misbehaving vehicles) and the experimental results show that the combined LSTM model, followed by an SVM classifier, achieves high detection accuracy.\nAnother approach that includes time sequences is [30]; the data are heavily manipulated in this work. Unnecessary labels such as sender ID and message ID were removed, and only the X and Y coordinates of vehicle position and speed were retained for training. Moreover, Ground Truth files and vehicle communication log files were combined to create a comprehensive dataset that includes both actual and claimed vehicle data. In the end, duplicate messages and unnecessary indexes were deleted using Matlab scripts. Like the previous approach, the input is a sequence of messages sorted by communication time, capturing the temporal dependencies of vehicle position and speed. The Softmax activation function was used in the output to classify the data into six categories (one normal vehicle type and five attacker types). The LSTM model"}, {"title": "Reinforcement Learning", "content": "LSTMs represent only the simplest approach to the problem. More complicated solutions, always working on the same dataset, were adopted over the years. In [32] the researchers present a novel approach utilizing Reinforcement Learning (RL) to enhance misbehavior detection in V2X communications. The NN used in the RL model is structured around a Q-learning framework tailored for time-series data analysis in V2X scenarios. The network includes a LSTM layer, which is crucial for capturing temporal dependencies in the data. This LSTM layer feeds into a fully connected layer that outputs Q-values, representing the potential utility of actions taken by the network in given states. The model employs an e-greedy strategy for exploration and exploitation, enhancing its ability to learn from new data and adjust to evolving conditions effectively.\nThe results of the simulations demonstrate the high efficacy of the RL-based misbehavior detection model. The model achieved a remarkable recall of 99.70% and an F1 score of 98.45%, indicating a superior ability to accurately identify misbehavior without a high rate of false positives."}, {"title": "Federated Learning", "content": "Another complex solution is presented in [33] where a Federated Learning (FL) approach is used. In particular, this solution presents the possibility of using a cloud-based solution, thanks to the use of some local deep learning techniques like Variational Autoencoders (VAEs) and Gaussian Mixture Models (GMMs). Each vehicle uses its locally refined VAE, after being provided from a centralized RSU, to monitor incoming data for potential misbehavior. The likelihood function from the GMM first assesses if new data points conform to the expected distributions of benign behavior. Points that raise suspicions based on the GMM likelihood are then processed through the VAE, where a significant reconstruction error indicates potential misbehavior. This complex solution is certainly interesting, but to achieve an on-line detection in which each vehicle can predict independently from a centralized solution, FL doesn't"}, {"title": "On-line simulations approach", "content": "All the solutions presented from now only do an offline approach by training and testing their model on the dataset, leaving out the possibility of simulating the misbehavior detection in a real-world scenario. Right now, the focus is moved on works that present some simulations results in addition to creating a misbehavior detector ML-base. The first example presented is [34], in which a model that leverages a combination of ML techniques and RL for effective misbehavior detection is used. This example provides simulations using CARLA, SUMO, and ARTERY simulators, and in particular, it tried to replicate the scenario used to create the VeReMi dataset. At a certain point, various types of misbehavior are injected into the simulation environment, such as false data injection, message tampering, and DoS attacks. Consequently, a real-time detection based on the detector is used to predict the misbehavior and make proper decisions.\nAnother important example is the research made in [35]. This example, in particular, defines a setup of a simulation environment using OMNET++ and SUMO in which every vehicle, equipped with a ML algorithm selected from a pool of six possibilities, has to face up some misbehavior like constant position attack, constant offset position attack, random position attack, random offset attack, eventual stop attack. In particular, when a vehicle intercepts a misbehavior, it has to report the detection or the accident to a centralized trusted authority."}, {"title": "Achievement", "content": "What is possible to see, from a deep analysis of some papers about MDSS based on an NN approach, is that the literature is full of possible models that, in particular, work well on the VeReMi dataset, properly created to work on misbehavior or attacks. What is missing in a lot of works about this subject is firstly the definition of a set of simulations that are independent from the VeReMi dataset and not centralized, in a way to see if the detection system can truly work well in a different environment and on every vehicle, and then the definition of a safe protocol to manage the detection in a proper way.\nBy analyzing the literature, as anticipated in Sect. 1.1, the purpose set for this thesis is not to define the best NN system to detect all the attacks in"}, {"title": "Misbehavior detection system", "content": "The first step to reach the goals set for this thesis is the creation of an MDS. This system is intended to detect anomalies that can cause the vehicle, or those near it, to behave improperly during the traffic flow while using cooperative driving systems based on the V2X communication. An example of an anomaly could be the malfunction of the GPS. From the review in Sect. 2.2, it emerged that the recent works focus on systems based on an NN approach. Along with the MDS implementation, a standard and well-formed dataset to train an NN for this purpose has to be chosen. Still from the literature review, in Sect. 2.2, many ML-based model developed used the VeReMi dataset, a standard for what concerns misbehavior detection. Considering VeReMi as the basis for the thesis MDS implementation, the data have to be manipulated to fit the input of a selected NN, in particular, making feature engineering (Sect. 3.1.3) and embedding (Sect. 3.1.5) choices. Once the NN has been selected (Sect. 3.2) and trained on the properly modified data, a portion of the dataset is used to validate the model offline, understand its performances and what it has to be expected from the further insertion in the on-line simulations."}, {"title": "Dataset", "content": "The most used dataset in the works analyzed is the VeReMi dataset 1 [6], [7].\nThe VeReMi dataset was created to overcome the challenges of reproducibility and comparability in research on vehicular misbehavior detection. Before its creation, studies in this domain relied on individually designed simulation"}, {"title": "Misbehavior presented", "content": "The most recent version of the dataset includes 19 types of malfunctions, anomalies, or attacks. For what concerns misbehavior, these are the main ones:\n\u2022 Position malfunctions: are usually a result of a positioning system failure (e.g., GPS). These failures affect the longitude and latitude fields of the safety messages and could manifest as one of these four use cases:\n1. The position is constant throughout the simulation: $Pos_{t+1} = Pos_{t}$\n2. The position is random at every time-step, considering an interval through all the surface of simulation: $Pos = U[min, max]$\n3. A constant offset is added to the real position: $Pos_{t} = Pos_{t} + off$\n4. A random offset is added to the real position: $Pos_{t} = Pos_{t} + U[offsetMin, offsetMax]$"}, {"title": "Selected Anomalies", "content": "In this research, as explained i Sect. 1.1, the choice is not to create an NN on all the scenarios available, but a good amount of cases, from those presented in the previous section, that can be easily replicated and studied in a real- world scenario, i.e., the simulation environment that is explained in Chapter 4. In particular, the chosen misbehavior are position malfunctions, in constant, random, and random offset position scenarios, speed malfunctions, in random and random offset scenarios, eventual stop, disruptive attacks and data replay. The malfunctions are selected because, in a real-world scenario, these kinds of anomalies can truly happen, e.g., GPS malfunctions that can transmit wrong positions or OBU anomalies. The other misbehavior selected can be replicated in simulation without many problems, allowing an on-line study of the MDS implemented on every vehicle in different real-world scenarios, e.g., urban or highway.\nIt's important to underline that the constant offset scenario was not used from the position and speed malfunctions. In fact, during the VeReMi dataset simulations, as shown in Fig. 3.1, every vehicle can be regular\u00b2, which means that every message sent is without anomalies, or misbehavior, which means that every message sent is with the specified anomaly. However, no one can be mixed\u00b3, and this behavior is clearly not representative of a real-world scenario, since in the world there's not a beginning or an end of a simulation. Moreover, since the thesis simulations aim to represent a real-world scenario and detect misbehavior while a simulation is running, every vehicle could be considered mixed, as defined. Given all the misbehavior beginning while the simulation is running, it is sufficient to train the model on the random offset scenario to intercept also the constant offset. In fact, at the beginning of the misbehavior, the first constant offset message, that is the one that determines the meaningful prediction of the MDS and the application of the protocol further defined in Chapter 5, is seen as a random offset since the message includes any offset compared to the previous one. So both random and constant offset can be called more in general offset. Since training the NN on the random offset scenario is sufficient to intercept every offset malfunction, even if it's constant, to avoid some noise that can be introduced from the constant offset scenario while training the model, that is particularly difficult to learn, the decision is"}, {"title": "Feature engineering", "content": "The data in the extended version of the VeReMi are presented as a folder for every scenario, which can be between 7 a.m and 9 a.m. or 2 p.m and 4 p.m., containing a GroundTruth file, or more than one, and a Log file for each vehicle in the simulation. In particular, each log file contains all the messages received from the other vehicles in the simulation, which are then represented in the Ground Truth JSON with the real data. So, referring to the example in Fig. 3.2, if the message from 2 is misbehavior with false position data, the truth message from 2 contains the real position of the vehicle 2 for that specific message."}, {"title": "Labels", "content": "The most important feature to be recovered from the dataset and needed to train the NN is the label that represents a kind of misbehavior. The choice is between using a single label model, in which the label feature can be only two values: 0 for the regular vehicles and 1 for the misbehavior ones, or using a multiple label model that aims to not only intercept the misbehavior but also identify they. Since the protocol, presented in Chapter 5, uses only the prediction between misbehavior or not, the feature label can be single. Considering that this protocol is straightforward and many modifications can be applied, particularly exploiting the differences between the various misbehavior adopting different responses based on the prediction, a multiple label is chosen. Since to save a vehicle on the road with the thesis protocol, the single label is\nenough, the metrics results are presented in Chapter 6 both for the single and multiple label evaluation, in particular considering all the misbehavior label of the multiple option as a general misbehavior for the single case. In particular, the multiple labels assigned are:\n\u2022 0: regular\n\u2022 1: constant position\n\u2022 2: random position\n\u2022 3: random position offset\n\u2022 4: random speed\n\u2022 5: random speed offset\n\u2022 6: eventual stop\n\u2022 7: disruptive\n\u2022 8: data replay\nWith this kind of feature, it's possible to consider a supervised learning solution for offline training. So, to build this feature, all the messages in the log files are merged with the respective messageID of the Ground truth, as\nshown in Fig. 3.4."}, {"title": "Embedding", "content": "As said in Sect. 1.1, to emulate the on-line evaluation, a structure of simulators is used, in particular involving SUMO, a time-driven simulator used to emulate the urban mobility that orders chronologically the events. Given the mobility simulation ordered by time, also the messages exchanged between vehicles will consequently be time ordered, particularly by looking into the sendTime field of every message. Since also the VeReMi dataset simulations act in the same way, an important choice is how to deal with the sequence of messages ordered by time, since the sequentiality is important while training the model and while using it on a vehicle. In Chapter 2, some works present a possible approach by defining a sliding window dimension containing a message sequence. In particular, in [29], a sliding window of size 10 is used. By following some research papers, the choice is to use a window of messages and not compute the prediction on every message received. This could also be a good approach that can help the NN in learning the misbehavior patterns provided. In particular,"}, {"title": "Population differences", "content": "Given the vector processed, some other problems have to be faced. The VeReMi dataset was created based on the LuST scenario, an urban scenario created on the city of Luxembourg map. At the same time, if the result that this thesis aims to achieve is a universal misbehavior detector, a population bias problem must be deleted somehow. It's enough to consider that the thesis simulation scenario is highway-based. The speed and acceleration data could be different from an urban scenario. Another problem also involves the position features; in fact, the dataset is simulated in the Luxembourg coordinates system, while the test's simulations could be different, or if other researchers wanted to use the model in a completely different environment, the coordinates have to be transformed in an absolute way. The last significant difference is that during the simulation, sometimes a jumping window containing information not every 1 second (the beacon time used in the dataset) appears. In this case, it's important to consider a time delta between the messages. To delete those biases, some solutions are adopted:\n\u2022 Coordinates system: To manage this problem, a solution that signif- icantly changes the embedding of the input data is used. Considering the first message received from the group of five as a reference, all the sequential four messages are changed by evaluating a difference between the message considered and the first. This solution is adopted for the position, speed and acceleration features to obtain the delta of those dataset columns. In this way, those features now represent the evolution in the four steps considered, given the first message as a reference and not an absolute position anymore. The speed and acceleration features are also transformed since, as an input of the NN, it could be good to present the delta evolution for all the data.\n\u2022 Population bias: Given the previous solution, the speed and acceleration values bias is removed since the evaluation is on the delta and not the absolute value anymore. Another bias on the population could be that the deltas learned are smaller due to the urban scenario used. Still, in this case, a smaller beacon time is helpful to balance between the bigger deltas ordinarily present in a highway and the training population. In particular, with a frequency of 10 Hz, the deltas are considered on an"}, {"title": "Neural Network", "content": "The choice presented in Sect. 3.1.5 is to work with data sequences ordered by time and grouped in a jumping window of five messages. As said in Sect. 1.1, to evaluate the MDS designed on-line, a simulation structure that includes SUMO, a time-driven simulator, is used to emulate urban mobility. SUMO is a tool in which the operations of a system are represented as a chronological sequence of events. Given the analysis made in Chapter 2, the simplest but most effective NN model for managing chronological data sequences is a Recurrent Neural Network (RNN). In particular, the most common NN used is the LSTM, which is a type of RNN aimed at dealing with the vanishing gradient problem present in traditional RNNS. LSTMs are considered one of the most advanced models to forecast time series."}, {"title": "Long Short-Term Memory", "content": "The LSTM NNs is a type of RNN architecture designed to overcome the limitations of traditional RNNs, especially in learning and retaining information over long data sequences. Introduced by Hochreiter and Schmidhuber in 1997 [36], LSTM networks are effective at learning long-term dependencies, which makes them suitable for various sequential data tasks. The LSTM network includes several vital components and formulas, presented in Fig. 3.9, that enable it to process sequential data effectively. The Cell State (C) is a memory carrying information across different time steps. The Forget Gate (f) determines what information to discard from the cell state, calculated as $f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$, in which o is the Sigmoid function, $W_f$ is the weight matrix for the forget weight, $[h_{t-1},x_t]$ is the concatenation of the previous hidden state and the current input and $b_f$ represents the bias vector for the forget gate. The Input Gate (i) decides what new information to add with the formula $i_t = \\sigma(W_i\\cdot [h_{t-1}, x_t] + b_i)$, while the Candidate Cell State ($C_t$) creates new candidate values to be added given by $C_t = tanh(W_c. [h_{t-1}, x_t] + b_c)$, in which tanh is the hyperbolic tangent function, which squashes values between -1 and 1. The Output Gate (o) decides what information from the cell state to output, using $o_t = \\sigma(W_o\\cdot [h_{t-1}, x_t] + b_o)$. Finally, the Hidden State (h), which is the output based on the cell state, is computed as $h_t = o_t * tanh(C_t)$.\nLSTM networks are well-suited for sequential data and time series because"}, {"title": "Structure", "content": "Given the data vector X, composed of a group of four rows and six columns that represent the features, after inserting a first Input layer that specifies the size of the training vector, the decision is to put an LSTM layer of dimension 256, followed by a Dense layer of dimension 156, with relu activation function, and a finale Dense layer of dimension 9, that has the softmax as an activation function since it has to be the output layer and classifies the input messages through all the available labels. Here is the Python code used to create this model:\n1 model Sequential ([\n2 Input (shape=(4,6)),\n3 LSTM(256, return_sequences=False),\n4 Dense (156, activation=\"relu\"),\n5 Dense (9, activation=\"softmax\")\n6])\nThe solution is simple but enough to deal with the misbehavior pattern provided.\nThe NN model's summary is presented in Fig. 3.10."}, {"title": "Training", "content": "Before doing the training, more work has to be done. In particular, the dataset has to be balanced because otherwise, label 0, which represents the regular vehicles, has a huge number of messages compared to the other. Balancing the dataset when using LSTM networks or any ML model is generally a good practice because it addresses the issue of class imbalance, which can significantly affect model performance. LSTM networks, like other ML models, learn patterns based on the data they are trained on. Suppose the dataset is imbalanced, meaning one class has significantly more samples than others. In that case, the LSTM is more likely to predict the majority class simply\nbecause it appears more frequently in the training data. An imbalanced dataset can also cause the LSTM to generalize poorly because it might not learn the underlying features of the minority class as effectively as those of the majority class. In the end balancing the dataset before training an LSTM can lead to improved model performance, especially when dealing with tasks where the minority class is of significant importance [38], [39].\nIn the VeReMi dataset all the simulations are just replications of the same, all the misbehavior labels have the same number of messages. The decision is to take random messages from regular messages, i.e., label 0, in a double quantity with respect to a misbehavior label. This bias is introduced to take advantage of the regular label and reduce the possibility of predicting misbehavior instead of an regular message in a false positive way since it is more probable that a vehicle is not misbehaving compared to any kind of anomaly presented; the goal to avoid the false positive prediction is explained in Sect. 1.2.\nAnother processing adopted for the data is scaling, in particular using the Standard Scaler, a pre-processing technique used to transform the features of a dataset so that they have a mean of zero and a standard deviation of one [40]. Using the Standard Scaler helps normalize the feature values, leading to improved performance, stability, and convergence in various ML algorithms. By ensuring that features contribute equally and consistently, the Standard Scaler enhances the overall effectiveness and reliability of the models.\n1 scaler = Standard Scaler ()\n2 scaler.fit (X)\nThe scaler is also exported using the pickle library in a way to later be used in the simulation environment to scale the data while the simulation is running.\nThe last step before effectively training the model is dividing the dataset between the train and the test set. To evaluate the offline training, 33% of the dataset is used to compose the validation set, which is used to validate the model trained on the remaining 77%. In this way, it's possible to obtain a full report composed of all the metrics useful in the ML environment to evaluate a\nmodel.\n1 X train, X test, y train, y test = train test split(X diff scaled,\n2 y, test_size=0.33, random_state=42)\nThe training of the previous explained NN with the processed dataset is executed with a batch_size of 64, 100 epochs and also the EarlyStopping callback as it follows:\n1 es = EarlyStopping (\n2 monitor='val_accuracy',"}, {"title": "Performance", "content": "To evaluate the performance of the detector on the offline testing (the validation set)", "are": "n\u2022 Accuracy: is a measure of the overall correctness of the model. It is the ratio of correctly predicted observations to the total observations. The formula is:\n$Accuracy = \\frac{TP+TN"}, {"Precision": "is a measure of the correctness of positive predictions. It is the ratio of correctly predicted positive observations to the total predicted positive observations. The formula is:\n$Precision = \\frac{TP"}, {"Recall": "also known as Sensitivity or True Positive Rate", "is": "n$Recall = \\frac{TP"}, {"F1-Score": "is the harmonic mean of Precision and Recall", "is": "n$F1\\_Score = 2 x \\frac{Precision"}]}