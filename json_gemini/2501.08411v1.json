{"title": "BiDepth Multimodal Neural Network: Bidirectional Depth Deep Learning Arcitecture for Spatial-Temporal Prediction", "authors": ["Sina Ehsani", "Fenglian Pan", "Qingpei Hu", "Jian Liu"], "abstract": "Accurate prediction of spatial-temporal (ST) information in dynamic systems, such as urban mobility and weather patterns, is a crucial yet challenging problem. The complexity stems from the intricate interplay between spatial proximity and temporal relevance, where both long-term trends and short-term fluctuations are present in convoluted patterns. Existing approaches, including traditional statistical methods and conventional neural networks, may provide inaccurate results due to the lack of an effective mechanism that simultaneously incorporates information at variable temporal depths while maintaining spatial context, resulting in a trade-off between comprehensive long-term historical analysis and responsiveness to short-term new information. To bridge this gap, this paper proposes the BiDepth Multimodal Neural Network (BDMNN) with bidirectional depth modulation that enables a comprehensive understanding of both long-term seasonality and short-term fluctuations, adapting to the complex ST context. Case studies with real-world public data demonstrate significant improvements in prediction accuracy, with a 12% reduction in Mean Squared Error for urban traffic prediction and a 15% improvement in rain precipitation forecasting compared to state-of-the-art benchmarks, without demanding extra computational resources.", "sections": [{"title": "1 Introduction", "content": "Spatio-temporal (ST) data, characterized by observations that vary spanning both spatial and temporal continuum, have become increasingly prevalent and critical in various domains, such as climate science (Aburas et al, 2019), urban planning (Song et al, 2019; Xia et al, 2025), transportation (Ling et al, 2023; Ehsani et al, 2024), and environmental monitoring (Amato et al, 2020). These datasets capture complex (ST) dynamics, offering valuable insights into evolving patterns and trends. A prime example is the New York City (NYC) Taxi and Limousine Commission Trip Record Data (\"TLC data\" hereafter - refer to Section 3.1.1 for details on this dataset.), which provides detailed information on taxi trips, including pick-up and drop-off locations, times, and associated attributes (NYC Taxi and Limousine Commission, 2024). The analysis of such ST data is crucial for understanding urban mobility patterns, optimizing transportation systems, and informing policy decisions (Zhou and Hirasawa, 2019).\nThe inherent complexity of ST data presents significant challenges for analysis and forecasting (Yuan and Li, 2021), stemming from their unique ST characteristics manifested as spatial and temporal correlations. Spatial correlations imply that observations at certain locations tend to be more inter-related than those at other locations, creating complex spatial patterns (Li et al, 2017). For example, in the TLC Data, taxi demands in one neighborhood often correlates with demands in adjacent neighborhoods. Temporal correlations refer to the inter-relationship between successive data points, with the influence from historical values varying based on temporal proximity. For instance, a surge in taxi pickups at a particular time is likely to be influenced by the pickups in preceding time intervals. The spatial and temporal interaction (ST correlations) creates intricate patterns, making it critical yet difficult to build models that can simultaneously capture both aspects without losing critical information. For example, in the TLC data, higher taxi pickups in outlying areas in the early morning can indicate increased demand in Midtown during evening rush hour.\nAdditionally, ST data exhibits non-stationary and multi-scale dynamics, characterized by short-term fluctuations and long-term trends that vary over multiple spatial and temporal scales simultaneously (Lai et al, 2018). Short-term fluctuations refer to immediate, transient changes in the data, such as daily peaks in taxi demand during morning and evening rush hours. Long-term trends denote the overall direction or movement in the data over extended periods, such as seasonal variations or a gradual increase in taxi usage over several years due to population growth. These evolving non-stationary patterns add another layer of complexity to modeling ST data, as models must adapt to changes over both short and long-term periods. Furthermore, ST data often exhibit high dimensionality due to the combination of numerous spatial locations and time intervals, increasing computational complexity (Geng et al, 2019). For example, the NYC TLC data divides the city into over 200 taxi zones, and data is collected over several years, resulting in high-dimensional data matrices where each dimension represents a spatial location at a specific time.\nFacing the challenges posed by these ST characteristics - ST correlation complexity, non-stationary patterns, and high dimensionality - the goal of this research is to"}, {"title": "2 Methodology", "content": "The BDMNN, delineated in this section, presents a novel method to navigate the intricate corridors of ST data analysis, addressing methodological gaps in the existing analytical models. Centralized around two pivotal components the BiDepth Encoder and the TimeSeries Encoder graphically illustrated in Figure 1. Initially, we present a brief overview of the entire operation, followed by a detailed exploration of each individual component.\nAt the core of this framework is the BiDepth Encoder, which orchestrates the processing of each timestamp within a given sequence through convolutional layers. The Encoder integrates the BDMNN's dual aspects: a DeepShallow network and a ShallowDeep network. The DeepShallow network employs a decreasing layer depth along the temporal context, which reduces the layer depth for recent data and thus enables swift adaptation to new information, while the ShallowDeep network does the opposite, applying increased depth to recent data to capture complex, short-term dependencies. The rationale behind this BiDepth approach stems from the characteristics of ST data, where relationships between variables can vary in complexity over time and space. For instance, in the TLC data, taxi demand may have direct and straightforward relationships with recent past data at a local level-the demand in a specific neighborhood in the previous hour may closely predict the current demand. However, there may also be complex recent events, such as sudden traffic congestion due to an\naccident, that require a more complex model structure (i.e., deeper layers) to capture non-linear and intricate dependencies across a broader spatial area. Non-linear dependencies refer to relationships that cannot be captured by linear models, often arising from high-dimensionality and non-stationarity in the data. By using both decreasing and increasing layer depths, the model can capture simple, localized direct relations with shallow layers (simpler model structure) and more complex, overall spatial patterns with deeper layers. Similarly, for longer-term dependencies, sometimes simple patterns like weekly seasonality (e.g., higher demand on Friday evenings in certain neighborhoods) can be captured with shallow layers focused on localized trends, while other times, more complex seasonal patterns (e.g., city-wide changes due to holidays or special events) require deeper layers to model effectively across the entire spatial domain. If we were to use only one directional depth assignment, we might miss capturing either the simple, localized relationships or the complex, global dependencies, leading to suboptimal performance. An equal depth approach may not provide the flexibility needed to adapt to varying complexities in the data over different time scales and spatial scales. Our experiments, as discussed in Section 3.3, demonstrate that the BiDepth approach outperforms single-directional (i.e. DeepShallow (Ehsani and Liu, 2024) or ShallowDeep) or equal-depth architectures (i.e. ConvLSTM (Shi et al, 2015) or ViViT (Arnab et al, 2021)) in capturing the diverse temporal and spatial patterns present in ST data.\nThis combination of layer depth, alternating between the DeepShallow and ShallowDeep methodologies, allows the model to proficiently handle the intricate demands of ST data analysis. This flexible architecture not only adjusts to the varying complexity of the data but also ensures comprehensive processing of both historical and recent data, offering a nuanced understanding of the entire temporal spectrum.\nAs illustrated in Figure 1, we represent our ST data as a tensor $X \\in R^{b \\times n \\times c \\times h \\times w}$. Here, b denotes the batch size, indicating the number of samples processed in parallel; n is the number of historical time steps (i.e., the window size), reflecting how many previous time intervals are considered, c represents the number of feature channels at each spatial location, such as 15-minute intervals capturing events like rush hours (e.g., c = 16 for a 4-hour evening rush period). Finally, h, w correspond to the spatial height and width of the grid, where h and w partition the city into spatial regions (e.g., NYC taxi zones). This tensor format cohesively encapsulates ST data, including multiple time intervals, sequences of historical windows, and the spatial layout of the city.\nGiven a prediction time t and utilizing historical data spanning up to n time steps preceding t (represented as a window of size n), the historical inputs $X_{t-1},..., X_{t-n}$ are processed by the BiDepth Encoder. Here, each $X_{ti}$ represents the spatial data (e.g., taxi demands across all zones) at time t - i. The BiDepth Encoder takes the entire historical window {$X_{t-1},..., X_{t-n}$} as input and learns the spatio-temporal characteristics of the data, focusing on non-stationarity and complex spatial patterns. This results in a set of transformed sequences {$X'_{-1},..., X'_{_n}$}, which encapsulate the learned spatial features and patterns. For convenience, we denote the collective transformed historical data as X', where X' = {$X'_{-1}, \u2026, X'_{_n}$}. These transformed"}, {"title": "2.1 BiDepth Encoder", "content": "The BiDepth Encoder, illustrated in Figure 2, is designed to integrate the capabilities of the two complementary networks: the DeepShallow and ShallowDeep encoders. This encoder serves as the backbone for processing ST data, ensuring a comprehensive and balanced analysis.\nEach input, $X_{t-i}$ at a specific historical timestamp, t-i, is processed through both DeepShallow and ShallowDeep networks. In the context of our datasets, this input represents the spatial data at time ti, such as the taxi demand across all zones in the TLC dataset or the precipitation measurements across all grid points in the GPM dataset (described in Section 3.1.2). After processing, the BiDepth Encoder combines the outputs of these two encoders. This concatenation step (Szegedy et al, 2015) is pivotal, as it merges insights into a unified representation. The concatenated output is then fed into the TimeSeries Encoder of the BDMNN for subsequent processing and forecasting.\n$X' = Concat(X^{DS}_{t-i}, X^{SD}_{t-i})$, for i = 1,...,n,                                                       (3)\nwhere $X'$ represents the output of the BiDepth Encoder at timestamp t-i, and $X^{DS}_{t-i}$ and $X^{SD}_{t-i}$ are the outputs of the DeepShallow and ShallowDeep encoders, respectively, at the same timestamp t - i. The construction of the network can be summarized in Algorithm 1."}, {"title": "2.1.1 DeepShallow Encoder", "content": "The DeepShallow encoder is characterized by two key architectural features: (i) a dynamic adjustment of CNN layer depths as time progresses and (ii) a shared-weight mechanism for layers exhibiting identical depth. We focus on these two features because they are essential for adapting the model to temporal dynamics and improving computational efficiency. These features distinguish our approach from traditional methods that often use fixed-depth layers without weight sharing.\nAt its core, the DeepShallow encoder processes sequences by channeling each timestamp through a set of CNN layers, as illustrated in Figure 2. Unlike conventional models, these layers are dynamic in depth, changing based on the timestamp's temporal position. The rationale behind varying the layer depth is to capture the varying complexity of patterns over different time scales. For earlier (older) timestamps, deeper layers can capture complex long-term dependencies, while shallower layers (fewer layers) are sufficient for more recent timestamps where patterns may be simpler or more directly related to the prediction target.\nThis feature is adjusted by a user-defined function, depth_function, potentially a linear function, that orchestrates the depth transition throughout the sequence. The"}, {"title": "2.1.2 ShallowDeep Encoder", "content": "The Shallow Deep encoder adopts an inverse strategy compared to the DeepShallow encoder. Instead of decreasing layer depth over time, it increases the number of convolutional layers for more recent timestamps, focusing on short-term, complex patterns. This approach allows for more detailed modeling of recent data, where abrupt changes and localized events may require a higher number of convolutional layers. The depth function for the Shallow Deep encoder is defined as:\n$D^{SD}_{(t-i)} = max(1, [\\frac{(i - 1)(L-1)}{n-1}]+1)$, for i = 1,..., n,                                          (6)\nwhere $D^{SD}_{(t-i)}$ specifies how many convolutional layers are applied at timestamp t \u2013 i. The depth increases from 1 for the oldest timestamp to L for the most recent, reflecting the need for deeper modeling of current short-term dependencies. Similar to the DeepShallow encoder, the ShallowDeep encoder employs a weight-sharing mechanism where all layers at the same depth index share a common set of weights $W_d$. Given the shared weights for each depth level, the output $X^{SD}_{t-i}$ is:\n$X^{SD}_{t-i} = CNN_{D^{SD}_{(t-i)}}(X_{t-i}; {W_d}^{D^{SD}_{(t-i)}}_{d=1})$, for i = 1,..., \u043f.                                 (7)\nIn this operation, $CNN_{D^{SD}_{(t-i)}}(.)$ applies $D^{SD}_{(t-i)}$ convolutional layers in sequence, each identified by a depth index d. Layers sharing the same depth index use the same weights $W_d$ across all timestamps, ensuring consistent feature extraction and efficient parameter utilization."}, {"title": "2.2 TimeSeries Encoder", "content": "The TimeSeries Encoder is responsible for modeling the temporal dependencies in the transformed spatial representations X' produced by the BiDepth Encoder. It takes\n$X' \\in R^{b \\times n \\times c \\times h \\times w}$ as input, where the dimensions b, n, c, h, w follow the definitions provided in the BiDepth Encoder section.\nWhile our framework can employ various temporal modeling approaches, such as a Convolutional LSTM (Shi et al, 2015), our primary contribution lies in the development of a Convolutional Transformer-based TimeSeries Encoder. This design leverages CASC to capture temporal dependencies without discarding spatial information. The CASC developed in our work addresses the challenge of effectively retaining spatial information during the application of attention mechanisms (Guo et al, 2019). Our experimental results (see Section 3.3) indicate that this Convolutional Transformer approach outperforms the ConvLSTM baseline, particularly in handling complex ST correlations and multi-scale dynamics.\nThe CSAC, as illustrated in Figure 3, extends the self-attention mechanism by preserving spatial structures through convolutional operations. Let $X \\in R^{b \\times n \\times c \\times h \\times w}$ be the input sequence of transformed spatial features over n time steps. We employ three separate convolutional operations to generate query (Q), key (K), and value (V) tensors from X. Formally, we define:\n$Q = CNN(X; W_Q), K = CNN(X; W_K), V = CNN(X; W_V)$,                                                  (8)\nwhere Q, K, and V represent convolutional mappings (LeCun et al, 1998), each parameterized by its own weights (WQ, WK, Wv). These convolutions retain the spatial dimensions (h, w), ensuring that spatial relationships are not lost. After reshaping"}, {"title": "2.3 Evaluation Metrics", "content": "Our primary quantitative measures for model assessment were the Mean Squared Error (MSE) and the Mean Absolute Error (MAE). Both metrics are widely used in regression tasks, offering complementary insights into the model's predictive performance (Pan et al, 2024). The MSE is defined as:\n$MSE = \\frac{1}{s}\\sum_{i=1}^{s} \\frac{1}{hxw} \\sum_{j=1}^{h} \\sum_{k=1}^{w} (X_{i,j,k} - \\hat{X}_{i,j,k})^2$,                                          (13)\nwhere $X_{i,j,k}$ and $\\hat{X}_{i,j,k}$ denote the true and predicted values at spatial coordinates (j, k) for the i-th sample, and s, h, w represent the number of samples, and the spatial"}, {"title": "2.4 Model Hyperparameter Tuning", "content": "The performance of the BDMNN depends on several hyperparameters that control the architecture and training process. Key hyperparameters include the initial depth of the convolutional layers, the window size (number of historical timestamps used), the choice of activation functions, learning rate, batch size, and the number of filters in the convolutional layers. Among these, the initial depth of the convolutional layers (L) in the BiDepth Encoder is a significant hyperparameter that directly affects the model's capacity to capture both historical and recent trends in the data. The initial depth (L) determines the maximum number of convolutional layers through which the data passes at each timestamp, as governed by the depth functions defined in Equations (4) and (6).\nOur analysis has shown that increasing L can lead to improved model performance up to a certain point. Specifically, as the depth increases, the MSE on the validation set decreases, indicating better predictive accuracy. However, this comes at the cost of increased computational complexity and longer training times. There is a trade-off between model depth, predictive performance, and computational cost. An optimal depth exists where the MSE is minimized without incurring unnecessary computational overhead. Selecting this optimal depth requires balancing the benefits of increased model capacity with the practical considerations of training time and resource availability.\nIn our experiments, detailed in Section 3.4, we empirically evaluate the impact of the initial depth on the BDMNN's performance using the TLC data. The results corroborate the conceptual understanding, showing that beyond a certain depth, further increases do not significantly improve MSE but do increase training time."}, {"title": "3 Case Studies", "content": "To demonstrate the effectiveness of the proposed BDMNN, we conducted two case studies with two different ST datasets: the NYC TLC data and the GPM datasets. By leveraging these datasets, we aim to validate our model's versatility across diverse"}, {"title": "3.1 Data Preprocessing", "content": "3.1.1 TLC Data\nOriginating from the NYC TLC, the TLC Trip Record Data offers an exhaustive snapshot of taxi trips in New York City (NYC Taxi and Limousine Commission, 2024). The data, sourced from authorized technology providers under the Taxicab & Livery Passenger Enhancement Programs (TPEP/LPEP), encompasses attributes such as pick-up and drop-off dates/times, locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts. Despite TLC's continuous reviews to ensure completeness and accuracy, the published data may not encapsulate all trips dispatched by TLC-licensed bases, highlighting the vast and complex nature of urban transport data. This dataset spans from 2009 to 2023, offering a comprehensive temporal landscape to evaluate the BDMNN. However, leveraging this dataset for our BDMNN required transforming it into a format that captures both ST dynamics. Consequently, our primary aim was to sculpt a ST tensor representing the taxi traffic patterns for a day based on the data from the preceding day.\nThe dataset was divided into a training set that includes data from 2021 and 2022, and a testing and validation set that contains data from 2023. By allocating older data for training and more recent data for validation and testing, we simulate a realistic forecasting scenario where the model predicts future patterns without access to future information during training. This chronological division reduces the risk of the model overfitting to temporal trends observed in future data, thereby ensuring a more unbiased and reliable model assessment. For a rigorous model evaluation, we split the 2023 data into two: the initial half (January to March) served as the validation"}, {"title": "3.1.2 GPM Data", "content": "We utilized the GPM dataset described by Ehsani et al (2022) in their NowCasting research. This dataset spans six years (2015-2020) and consists of the Global Precipitation Measurement (GPM) Integrated Multi-satellite Retrievals for GPM (IMERG) early run products (Huffman et al, 2020). It offers half-hourly precipitation maps at a spatial resolution of 0.1\u00b0 across the Continental United States (CONUS).\nThe dataset was divided into training (85%), validation (5%), and testing (10%) sets based on chronological order, with the most recent 10% reserved for testing. This approach ensures the model is trained on past precipitation patterns and evaluated on future periods, mirroring real-world forecasting conditions. Throughout the training period, the model consistently uses a 24-hour historical window to predict the subsequent 4 hours of precipitation, maintaining a uniform training strategy over the entire training dataset."}, {"title": "3.2 Computational Setup", "content": "All experiments were conducted on NVIDIA A100 GPUs to ensure consistency across different datasets. The BDMNN and all baseline models were implemented using PyTorch. We employed hyperparameter tuning for all experiments to optimize model"}, {"title": "3.3 Results", "content": "The evaluation utilized the MSE loss mentioned in Section 2.3. This section aims to delve into the performance of the BDMNN and its variants, providing insights into the model's capabilities across the datasets."}, {"title": "3.3.1 TLC Trip Record Prediction", "content": "For the TLC data, Table 3 showcases the performance of different models on the TLC Data, emphasizing the improvements realized by incorporating the BiDepthNet structure."}, {"title": "3.3.2 GPM Forecasting", "content": "The results for the GPM dataset are presented in Table 4. Consistent with the findings from the TLC dataset, the BiDepth variants outperformed the baseline models, showing over a 14.58% improvement when added to the ConvSelfAttention model and a 17.92% improvement when compared to the widely used ConvLSTM baseline. This consistent superiority across diverse datasets highlights the robustness and adaptability of the BDMNN, indicating its potential for a wide range of ST forecasting applications. In the context of weather forecasting, improvements in MSE can yield substantial real-world benefits enhancing resource planning, risk mitigation, and operational efficiency. The demonstrated improvements underscore the BDMNN's capacity to more effectively capture complex spatio-temporal correlations, thus providing more reliable predictions in demanding scenarios."}, {"title": "3.4 Impact of Initial Depth in the BDMNN", "content": "The initial depth in our BDMNN, a significant hyperparameter, determines the extent of depth possibly needed to capture both historical and recent trends. To understand this relationship, we varied the initial depth and monitored its influence on the MSE in the Validation set as well as the training time for the TLC data."}, {"title": "4 Conclusion and Future Work", "content": "In this study, we introduced the BDMNN, a novel architecture adept at capturing intricate temporal dependencies by dynamically adjusting its depth. Our experiments spanned two distinct datasets, providing a comprehensive evaluation of the proposed model. The BDMNN network consistently outperformed benchmark models across diverse datasets, testifying to its robustness and adaptability. Incorporating attention mechanisms further enhanced the model's predictive prowess, emphasizing the significance of context-aware temporal learning. An exploration into the model's depth revealed a balance between immediate and historical data, suggesting an optimal temporal granularity for prediction tasks. Spatial analyses highlighted the BDMNN's capacity to uniformly capture ST patterns, an attribute crucial for applications in dynamic urban environments.\nThe ConvSelfAttention mechanism demonstrated superior performance compared to ConvLSTM and enabled parallel tensor processing, but it exhibits limitations related to model size scaling. Unlike ConvLSTM, whose parameter count is primarily defined by hyperparameters and not directly by input size, ConvSelfAttention's parameter size scales with the spatial dimensions of the input. For smaller spatial"}]}