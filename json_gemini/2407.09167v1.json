{"title": "SE(3)-bi-equivariant Transformers\nfor Point Cloud Assembly", "authors": ["Ziming Wang", "Rebecka J\u00f6rnsten"], "abstract": "Given a pair of point clouds, the goal of assembly is to recover a rigid transformation\nthat aligns one point cloud to the other. This task is challenging because the point\nclouds may be non-overlapped, and they may have arbitrary initial positions.\nTo address these difficulties, we propose a method, called SE(3)-bi-equivariant\ntransformer (BITR), based on the SE(3)-bi-equivariance prior of the task: it\nguarantees that when the inputs are rigidly perturbed, the output will transform\naccordingly. Due to its equivariance property, BITR can not only handle non-\noverlapped PCs, but also guarantee robustness against initial positions. Specifically,\nBITR first extracts features of the inputs using a novel $SE(3) \\times SE(3)$-transformer,\nand then projects the learned feature to group $SE(3)$ as the output. Moreover,\nwe theoretically show that swap and scale equivariances can be incorporated into\nBITR, thus it further guarantees stable performance under scaling and swapping\nthe inputs. We experimentally show the effectiveness of BITR in practical tasks.", "sections": [{"title": "1 Introduction", "content": "Point cloud (PC) assembly is a fundamental machine learning task with a wide range of applications\nsuch as biology [13], archeology [34], robotics [26] and computer vision [22]. As shown in Fig. 1,\ngiven a pair of 3-D PCs representing two shapes, i.e., a source and a reference PC, the goal of assembly\nis to find a rigid transformation, so that the transformed source PC is aligned to the reference PC.\nThis task is challenging because the input PCs may have random initial positions that are far from the\noptimum, and may be non-overlapped, e.g., due to occlusion or erosion of the object."}, {"title": "2 Related works", "content": "A special case of PC assembly is PC registration, where the correspondence between input PCs is\nassumed to exist. A seminal work in this task was conducted by [2], which provided a closed-form\nsolution to the problem with known correspondence. To handle PCs with unknown correspondence,\nmost of the subsequent works extend [2] by first estimating the correspondence by comparing\ndistances [4], or features [24, 22, 38] of the PCs, and then aligning the PCs by aligning the estimated\ncorresponding points. Notably, to obtain SE(3)-bi-equivariance, SO(3)-invariant features [39, 11,\n40] have been investigated for correspondence estimation. However, since these methods require a\nsufficient number of correspondences, they have difficulty handling PCs where the correspondence\ndoes not exist. In addition, they often have difficulty handling PCs with large initial errors [42].\nThe proposed BITR is related to the existing registration methods because it can be seen as a\ngeneralization of Arun's method [2]. However, in contrast to these methods, BITR is correspondence-"}, {"title": "3 Preliminaries", "content": "This section briefly reviews Arun's method and the concept of equivariance, which will be used in\nBITR."}, {"title": "3.1 Group representation and equivariance", "content": "Given a group G, its representation is a group homomorphism $\\rho : G \\rightarrow GL(V)$, where V is a linear\nspace. When G is the 3D rotation group SO(3), it is convenient to consider its irreps (irreducible\northogonal representation) $\\rho_p: SO(3) \\rightarrow GL(V_p)$, where $p \\in \\mathbb{N}$, is the degree of the irreps, and\n$dim(V_p) = 2p + 1$. For $r \\in G$, $\\rho_p(r) \\in \\mathbb{R}^{(2p+1) \\times (2p+1)}$ is known as the Wigner-D matrix. For\nexample, $\\rho_0(r) = 1$ for all $r \\in SO(3)$; $\\rho_1(r) \\in \\mathbb{R}^{3 \\times 3}$ is the rotation matrix of r. More details can be\nfound in [5] and the reference therein.\nIn this work, we focus on the group G of two independent rotations, i.e., $G = SO(3) \\times SO(3)$, where\n$\\times$ represents the direct product. Similar to SO(3), we also consider the irreps of G. A useful fact is\nthat all irreps of G can be written as the combinations of the irreps of SO(3): the degree-(p, q) irreps\nof G is $\\rho_{p,q} = \\rho_p \\otimes \\rho_q : SO(3) \\times SO(3) \\rightarrow GL(V_p \\otimes V_q)$, where $p, q \\in \\mathbb{N}$, $\\rho_p$ and $\\rho_q$ are irreps of\nSO(3), and $\\otimes$ is tensor product (Kronecker product for matrix). For example, $\\rho_{0,0}(r_1 \\times r_2) = 1 \\in \\mathbb{R}$;\n$\\rho_{1,0}(r_1 \\times r_2) \\in \\mathbb{R}^{3 \\times 3}$ is the rotation matrix of $r_1$; $\\rho_{1,1}(r_1 \\times r_2) = \\rho_1(r_1) \\otimes \\rho_1(r_2) \\in \\mathbb{R}^{9 \\times 9}$ is the\nKronecker product of the rotation matrices of $r_1$ and $r_2$.\nGiven two representations $\\rho : G \\rightarrow GL(V)$ and $\\tau : G \\rightarrow GL(W)$, a map $\\Phi : V \\rightarrow W$ satisfying\n$\\Phi(\\rho(g)x) = \\tau(g)\\Phi(x)$ for all $g \\in G$ and $x \\in V$ is called G-equivariant. When $\\Phi$ is parametrized by\na neural network, we call $\\Phi$ an equivariant neural network, and we call the feature extracted by $\\Phi$ an\nequivariant feature. Specifically, a degree-p equivariant feature transforms according to $\\rho_p$ under the\naction of SO(3), and a degree-(p, q) equivariant feature transforms according to $\\rho_p \\otimes \\rho_q$ under the\naction of SO(3) $\\times$ SO(3). For simpler notations, we omit the representation homomorphism $\\rho$, i.e.,\nwe write $r$ instead of $\\rho(r)$, when $\\rho$ is clear from the text."}, {"title": "3.2 Arun's method", "content": "Consider a PC assembly problem with known one-to-one correspondence: Let $Y = \\{y_v\\}_{v=1}^N \\subset \\mathbb{R}^3$\nand $X = \\{x_u\\}_{u=1}^M \\subset \\mathbb{R}^3$ be a pair of PCs consisting of N points, and let $\\{(x_u, y_u)\\}_{u=1}^N$ be their\ncorresponding point pairs. What is the optimal rigid transformation that aligns X to Y?"}, {"title": "4 SE(3)-bi-equivariant transformer", "content": "This section presents the details of the proposed BITR. BITR follows the same principle as Arun's\nmethod [2]: it first extracts SO(3) $\\times$ SO(3)-equivariant features as a generalization of the correlation\nmatrix $\\tau$ (2), and then projects the features to SE(3) similarly to (1). Specifically, we first propose\na SE(3) $\\times$ SE(3)-transformer for feature extraction in Sec. 4.2. Since this transformer is defined\non 6-D space, i.e., it does not directly handle the given 3-D PCs, it relies on a pre-processing step\ndescribed in Sec. 4.3, where the input 3-D PCs are merged into a 6-D PC. Finally, the Arun-type\nSE(3)-projection is presented in Sec. 4.4. An overview of BITR is presented in Fig. 2."}, {"title": "4.1 Problem formulation", "content": "Let $Y = \\{y_v\\}_{v=1}^N \\subset \\mathbb{R}^3$ and $X = \\{x_u\\}_{u=1}^M \\subset \\mathbb{R}^3$ be the PCs sampled from the reference and source\nshape respectively. The goal of assembly is to find a rigid transformation $g \\in SE(3)$, so that the\ntransformed PC $gX = \\{rx_i + t\\}_{i=1}^M$ is aligned to Y. Note that we do not assume that X and Y are\noverlapped, i.e., we do not assume the existence of corresponding point pairs."}, {"title": "4.2 SE(3) $\\times$ SE(3)-transformer", "content": "To learn SO(3) $\\times$ SO(3)-equivariant translation-invariant features generalizing $\\tau$ (1), this subsection\nproposes a SE(3) $\\times$ SE(3)-transformer as a generalization of SE(3)-transformer [12]. We present\na brief introduction to SE(3)-transformer [12] in Appx. A for completeness.\nAccording to the theories developed in [5], to define a SE(3) $\\times$ SE(3)-equivariant transformer, we\nfirst need to define the feature map of a transformer layer as a tensor field, and specify the action"}, {"title": "4.3 Point cloud merge", "content": "To utilize the transformer model defined in Sec. 4.2, we need to construct a 6-D PC as its input. To\nthis end, we first extract key points from the raw 3-D PCs, and then concatenate them to a 6-D PC to\nmerge their information. Thus, the resulting 6-D PC is not only small in size but also contains the key\ninformation of the raw PCs pairs.\nFormally, we extract L ordered key points $\\tilde{X} = \\{\\tilde{x}_u\\}_{u=1}^L$ and $\\tilde{Y} = \\{\\tilde{y}_v\\}_{v=1}^L$ from X and Y\nrespectively, and then obtain $Z = \\{\\tilde{x}_u \\oplus \\tilde{y}_u\\}_{u=1}^L$. Note that we do not require $\\tilde{X}$ ($\\tilde{Y}$) to be a subset\nof X (Y). Specifically, we represent the coordinates of the key points as a convex combination of the\nraw PCs:\n$\\tilde{X} = SoftMax(F_X)X, \\\\ \\tilde{Y} = SoftMax(F_Y)Y, \t$ \t (10)\nwhere $X \\in \\mathbb{R}^{M \\times 3}$ and $Y \\in \\mathbb{R}^{N \\times 3}$ represent the coordinates of X and Y respectively, and $SoftMax(\\cdot)$\nrepresents the row-wise softmax. $F_X \\in \\mathbb{R}^{L \\times M}$ and $F_Y \\in \\mathbb{R}^{L \\times N}$ are the weights of each point in\nX and Y respectively, and they are degree-0, i.e., rotation-invariant, features computed by a shared\nSE(3)-transformer $\\Phi_E$:\n$\\begin{aligned}F_X = \\Phi_E(X), \\\\ F_Y = \\Phi_E(Y). \\end{aligned}$  \t (11)\nFurthermore, inspired by [37], we fuse the features of X and Y in $\\Phi_E$ before the last layer, so that\ntheir information is merged more effectively, i.e., the selection of $\\tilde{X}$ or $\\tilde{Y}$ depends on both X and Y.\nSpecifically, the fused features are\n$\\begin{cases}\nf_{out, X}(x_u) = f_{in, X}(x_u) + Pool_v (f_{in,Y}(y_v)) \\oplus f_{in, X}(x_u) \\\\\nf_{out, Y}(y_v) = f_{in, Y}(y_v) \\oplus Pool_u (f_{in, X}(x_u)) + f_{in, Y}(y_v),  \t\n\\end{cases}  \t (12)\nwhere we only consider degree-0 and degree-1 features. $f_{\\cdot,X}$ and $f_{\\cdot,Y}$ represent the features of X\nand Y, and Pool is the average pooling over the PC."}, {"title": "4.4 SE(3)-projection", "content": "We now obtain the final output by projecting the feature extracted by the SE(3) $\\times$ SE(3)-transformer\nto SE(3). Formally, let f be the output tensor field of the SE(3) $\\times$ SE(3)-transformer. We compute\nthe final output $g = (r, t) \\in SE(3)$ using an Arun-type projection as follows:\n$\\begin{cases}\n\\hat{r} = SVD(\\hat{r}) \\\\\nt = (m(Y)+\\hat{t}_y) - \\hat{r}(m(X)+\\hat{t}_x),  \t\n\\end{cases}  \t (13)\nwhere $\\hat{r} = unvec(\\tilde{r}) \\in \\mathbb{R}^{3 \\times 3}$, $\\hat{t}_x \\in \\mathbb{R}^3$ and $\\hat{t}_y \\in \\mathbb{R}^3$ are equivariant features computed as\n$\\hat{r} = Pool_u (f_{1,1}), \\, \\hat{t}_x = Pool_u (f_{1,0}), \\, \\hat{t}_y = Pool_u (f_{0,1}).$\nWe note that projection (13) extends Arun's projection (1) in two aspects. First, although $\\hat{r}$ in (13) and\n$\\tau$ (2) are both degree-(1, 1) features, $\\hat{r}$ is more flexible than $\\tau$ because $\\hat{r}$ is a learned feature while $\\tau$ is\nhandcrafted, and $\\hat{r}$ is correspondence-free while $\\tau$ is correspondence-based. Second, projection (13)\nexplicitly considers non-zero offsets $\\hat{t}_x$ and $\\hat{t}_y$, which allow solutions where the centers of PCs do\nnot match.\nIn summary, BITR computes the output g for PCs X and Y according to\n$g = \\Phi_P \\circ \\Phi_S(X, Y),$ \t \t (14)\nwhere $\\Phi_S: S \\times S \\rightarrow \\mathbb{F}$ is a SE(3) $\\times$ SE(3)-transformer (with the PC merge step), $\\Phi_P : \\mathbb{F} \\rightarrow SE(3)$\nrepresents projection (13), and $\\mathbb{F}$ is the set of tensor field. We finish this section with a proposition\nthat BITR is indeed SE(3)-bi-equivariant.\nProposition 4.1. Under a mild assumption (C.4), BITR (14) is SE(3)-bi-equivariant."}, {"title": "5 Swap-equivariance and scale-equivariance", "content": "This section seeks to incorporate swap and scale equivariances into the proposed BITR model. These\ntwo equivariances are discussed in Sec. 5.1 and Sec. 5.2 respectively."}, {"title": "5.1 Incorporating swap-equivariance", "content": "This subsection seeks to incorporate swap-equivariance to BITR, i.e., to ensure that swapping X\nand Y has the correct influence on the output. To this end, we need to treat the group of swap as\n$\\mathbb{Z}/2\\mathbb{Z} = \\{1, s\\}$ where $s^2 = 1$, i.e., s represents the swap of X and Y, and properly define the action\nof $\\mathbb{Z}/2\\mathbb{Z}$ on the learned features.\nFormally, we define the action of $\\mathbb{Z}/2\\mathbb{Z}$ on field f (3) as follows. We first define the action of s on the\nbase space $\\mathbb{R}^6$ as swapping the coordinates of X and $\\tilde{Y}$: $s(z) = z_2 \\oplus z_1$, where $z = z_1 \\oplus z_2$, and\n$z_1, z_2 \\in \\mathbb{R}^3$ are the coordinates of X and $\\tilde{Y}$ respectively. Then we define the action of s on feature f\nas $(s(f))^{p_1,q}(z) = (f^{q,p}(s(z)))^T$, where we regard a degree-(p, q) feature $f^{p,q}$ as a matrix of shape\n$\\mathbb{R}^{(2p+1) \\times (2q+1)}$ by abuse of notation, and $(\\cdot)^T$ represents matrix transpose.\nIntuitively, according to the above definition, degree-(1, 1), (1,0) and (0, 1) features will become\n(the transpose of) degree-(1, 1), (0, 1) and (1,0) features respectively under the action of s, i.e., $\\hat{r}$\nwill be transposed, $\\hat{t}_x$ and $\\hat{t}_y$ will be swapped. This is exactly the transformation needed to ensure\nswap-equivariant outputs. We formally state this observation in the following proposition.\nProposition 5.1. For a tensor field f and a projection $\\Phi_P$ (13), $\\Phi_P (s(f)) = (\\Phi_P(f))^{-1}.$\nNow the remaining problem is how to make a SE(3) $\\times$ SE(3)-transformer $\\mathbb{Z}/2\\mathbb{Z}$-equivariant. A\nnatural solution is to force all layers in the SE(3) $\\times$ SE(3)-transformer to be $\\mathbb{Z}/2\\mathbb{Z}$-equivariant. The\nfollowing proposition provides a concrete way to achieve this.\nProposition 5.2. Let $\\tilde{\\cdot}$ represent the swap of index, e.g., if o = (01, 02), then $\\tilde{o} = (02, 01)$. 1) For\na transformer layer (5), if the self-interaction weight satisfies $W^o = W^{\\tilde{o}}$, the weight of query (7)\nsatisfies $W_{Q}^{i,o} = W_{Q}^{\\tilde{i},\\tilde{o}}$, and the radial function satisfies $\\varphi_{J_1,J_2}^{i,o}(\\|z_1\\|, \\|z_2\\|) = \\varphi_{J_2,J_1}^{\\tilde{i},\\tilde{o}}(\\|z_2\\|, \\|z_1\\|)$ for\nall i, o, $J_1, J_2$, $z^1$ and $z^2$, then the transformer layer is $\\mathbb{Z}/2\\mathbb{Z}$-equivariant.\n2) For an Elu layer (9), if $W_\\mu^{i} = W_{\\mu}^{\\tilde{i}}$ and $W_v^{i} = W_v^{\\tilde{i}}$ for all i, then the Elu layer is $\\mathbb{Z}/2\\mathbb{Z}$-equivariant.\nMore details, including the complete matching property (Prop. C.12), can be found in Appx. C.3.1."}, {"title": "5.2 Incorporating scale-equivariance", "content": "This subsection seeks to incorporate scale equivariance to BITR, i.e., to ensure that when X and Y\nare multiplied by a scale constant $c \\in \\mathbb{R}_+$, the output result transforms correctly. To this end, we\nneed to consider the scale group $(\\mathbb{R}_+, \\times)$, i.e., the multiplicative group of $\\mathbb{R}_+$, and properly define\nthe $(\\mathbb{R}_+, \\times)$-equivariance of the learned feature. For simplicity, we abbreviate group $(\\mathbb{R}_+, \\times)$ as $\\mathbb{R}_+$.\nWe now consider the action of $\\mathbb{R}_+$ on field f (3). We call f a degree-p $\\mathbb{R}_+$-equivariant field ($p \\in \\mathbb{N}$)\nif it transforms as $(c(f))(z) = c^pf(c^{-1}z)$ under the action of $\\mathbb{R}_+$, where $z \\in \\mathbb{R}^6$ and $c \\in \\mathbb{R}_+$.\nWe immediately observe that degree-1 $\\mathbb{R}_+$-equivariant features lead to scale-equivariant output.\nIntuitively, if r, $\\hat{t}_x$ and $\\hat{t}_y$ are degree-1 $\\mathbb{R}_+$-equivariant features, then they will become $cr$, $c\\hat{t}_x$ and\n$c\\hat{t}_y$ under the action of c, and the projection step will cancel the scale off while keeping the scale of\n$\\hat{t}_x$ and $\\hat{t}_y$, which is exactly the desirable results. Formally, we have the following proposition.\nProposition 5.3. Let $\\Phi_P$ be projection (13), f be a degree-1 $\\mathbb{R}_+$-equivariant tensor field, and\n$(r, t) = \\Phi_P(f)$. We have $\\Phi_P(c(f)) = (r, ct) \\, \\forall c \\in \\mathbb{R}_+$.\nThe remaining problem is how to ensure that a SE(3) $\\times$ SE(3)-transformer is $\\mathbb{R}_+$-equivariant and\nits output is of degree-1, so that scaling the input can lead to the proper scaling of output. Here we\nprovide a solution based on the following proposition.\nDefinition 5.4. $\\varphi : \\mathbb{R} \\times \\mathbb{R} \\rightarrow \\mathbb{R}$ is a degree-p function if $\\varphi(cx, cy) = c^p \\varphi(x, y)$ for all $c \\in \\mathbb{R}_+$.\nProposition 5.5. 1) Denote $\\varphi_K$ and $\\varphi_V$ the radial functions used in K and V respectively. Let $K$\nbe a degree-0 function, fin be a degree-0 $\\mathbb{R}_+$-equivariant input field. For transformer layer (5), if $\\varphi_V$\nis a degree-1 function and the self-interaction weight $W = 0$, then the output field fout is degree-1\n$\\mathbb{R}_+$-equivariant; If $\\varphi_V$ is a degree-0 function, then the output field fout is degree-0 $\\mathbb{R}_+$-equivariant.\n2) For Elu layer (9), if the input field is degree-p $\\mathbb{R}_+$-equivariant, then the output field is also degree-p\n$\\mathbb{R}_+$-equivariant."}, {"title": "6 Experiments and analysis", "content": "This section experimentally evaluates the proposed BITR. After describing the experiment settings in\nSec. 6.1, we first present a simple example in Sec. 6.2 to highlight the equivariance of BITR. Then\nwe evaluate BITR on assembling the shapes in ShapeNet [6], BB dataset [29], 7Scenes [30] and\nASL [21] from Sec. 6.3.1 to Sec. 6.4. We finally apply BITR to visual manipulation tasks in Sec. 6.6."}, {"title": "6.1 Experiment settings", "content": "We extract L = 32 key points for each PC. The SE(3)-transformer and the SE(3) $\\times$ SE(3)-\ntransformer both contain 2 layers with c = 4 channels. We consider k = 24 nearest neighborhoods\nfor message passing. We only consider low degree equivariant features, i.e., p, q $\\in$ {0, 1} for\nefficiency. We train BITR using Adam optimizer [17] with learning rate 1e-4. We use the loss\nfunction $L = ||r_{tgt}^T \\hat{r} - I||_2 + ||t_{tgt} - \\hat{t}||_2$, where $(\\hat{r}, \\hat{t})$ are the output transformation, $(r_{tgt}, t_{tgt})$ are\nthe corresponding ground truth. We evaluate all methods by isotropic rotation and translation errors:\n$\\Delta r = (180/\\pi)\\arccos(1/2 (tr(\\hat{r}^Tr_{tgt}) - 1)))$, and $\\Delta t = ||t_{tgt} - \\hat{t}||$ where $tr(\\cdot)$ is the trace of a matrix.\nWe do not use random rotation and translation augmentations as [22]. More details are in Appx. D.1."}, {"title": "6.2 A proof-of-concept example", "content": "To demonstrate the equivariance property of BITR, we train BITR on the bunny shape [31]. In each\ntraining iteration, we first construct the raw PC S by uniformly sampling 2048 points from the bunny\nshape and adding 200 random outliers from [-1, 1]\u00b3, then we obtain PCs $\\{X_P, Y_P\\}$ by dividing S\ninto two parts of ratio (30%, 70%) using a random plane P. We train BITR to reconstruct S using\n$\\big\\{X_P, Y_P\\big\\}$. To construct the test set, we generate a new sample $\\{X_P, Y_P\\}$, and additionally construct\n3 test samples by 1) swapping, 2) scaling (factor 2) and 3) randomly rigidly perturbing $\\{X_P, Y_P\\}$.\nThe assembly results of BITR on these four test samples are shown in Fig. 3. We observe that\nBITR performs equally well in all cases. Specifically, the differences between the rotation errors in\nthese four cases are small (less than 1e-3). The results suggest that BITR is indeed robust against\nthese three perturbations, which verifies its swap-equivariance, scale-equivariance and SE(3)-bi-\nequivariance. More experiments can be found in the appendix: a numerical verification of Def. 3.1 is\npresented in Appx. D.2, an ablation study of swap and scale equivariances are presented in Appx. D.3,\nand the verification of the complete-matching property C.12 is presented in Appx. D.4."}, {"title": "6.3 Results on ShapeNet", "content": "In this experiment, we evaluate BITR on assembling PCs sampled from a single shape. When the\ninputs PCs are overlapped, this setting is generally known as PC registration. We construct a dataset\nsimilar to [38]: for a shape in the airplane class of ShapeNet [6], we obtain each of the input PCs by\nuniformly sampling 1024 points from the shape, and keep ratio s of the raw PC by cropping it using\na random plane. We vary s from 0.7 to 0.3. Note the PCs may be non-overlapped when s < 0.5.\nWe compare BITR against the state-of-the-art registration methods GEO [22] and ROI [40], and\nthe state-of-the-art fragment reassembly methods NSM [7] and LEV [36]. For NSM and LEV, we"}, {"title": "6.3.1 Single shape assembly", "content": ""}, {"title": "6.3.2 Inter-class assembly", "content": "To evaluate BITR on non-overlapped PCs, we extend the exper\niment in Sec. 6.3.1 to inter-class assembly. We train BITR to\nplace a car shape on the right of motorbike shape, so that their\ndirections are the same and their distance is 1. We consider\ns = 1.0 and 0.7. Note that this task is beyond the scope of\nregistration methods, since the input PCs are non-overlapped."}, {"title": "6.4 Results on fragment reassembly", "content": "This subsection evaluates BITR on a fragment reassembly task. We compare BITR against NSM [7],\nLEV [36] and DGL [41] on the 2-fragment WineBottle class of the BB dataset [29]. The data\npreprocessing step is described in Appx. D.7.\nWe test the trained BITR 3 times, and report\nthe mean and standard deviation of (Ar, At)\nin Tab. 1. We observe that BITR outperforms\nall baseline methods: BITR achieves the low-\nest rotation errors, and its translation error is\ncomparable to DGL, which is lower than other\nbaselines by a large margin. We provide some\nqualitative comparisons in Appx. D.7."}, {"title": "6.5 Results on real data", "content": "This subsection evaluates BITR on an indoor dataset 7Scenes [30] and the outdoor scenes in ASL\ndataset [21]. We train BITR to align the adjacent frames that are arbitrarily rigidly perturbed. The\nresults are reported in Appx. D.8."}, {"title": "6.6 Results on visual manipulation", "content": "This subsection applies BITR to visual manipulation tasks. Following [25], we consider two tasks:\nmug-hanging and bowl-placing, where the goal is to find a rigid transformation so that the cup can be\nhung to the stand, or the bowl can be placed on the plate. The details can be found in Appx. D.9."}, {"title": "7 Conclusion", "content": "This work proposed a PC assembly method, called BITR. The most distinguished feature of BITR is\nthat it is correspondence-free, SE(3)-bi-equivariance, scale-equivariance and swap-equivariance. We\nexperimentally demonstrated the effectiveness of BITR. The limitation of BITR and future research\ndirections are discussed in Appx. E."}, {"title": "A SE(3)-equivariant Transformers", "content": "A well-known SE(3)-equivariant network is SE(3)-transformer [12], which adapts the powerful\ntransformer structure [33] to SO(3)-equivariant settings. In this model, the feature map f of each\nlayer is defined as a tensor field supported on a 3-D PC:\n$f(x) = \\sum_{u=1}^M f_u\\delta(x - x_u),$ \t \t (15)\nwhere $\\delta$ is the Dirac function, $X = \\{x_u\\}_{u=1}^M \\subseteq \\mathbb{R}^3$ is a point set, and $f_u$ is the feature attached to $x_u$.\nHere, feature $f_u$ takes the form of $f_u = \\bigoplus_p f^p$, where the component $f^p\\in V_p$ is the degree-p feature,\ni.e., it transforms according to $\\rho_p$ under the action of SO(3). For example, when $f_u$ represents the\nnorm vector of a point cloud, then $f_u = f^1 \\in \\mathbb{R}^3$. We also write the collection of all degree-p\nfeatures at $x_u$ as $\\mathbb{F}^P(x_u) \\in \\mathbb{R}^{c \\times (2p+1)}$, where c is the number of channels.\nFor each transformer layer, the degree-k output feature at point $x_i$ is computed by performing message\npassing:\n$\\begin{aligned}\nf^{out}(x_u) = W^\\ell F^k(x_u)+\\sum_{l}\\sum_{v\\in N(u)\\{u\\}} A_{uv} V_{ik}\n\\end{aligned}$\t \t (16)\nwhere $N (u)$ represents the neighborhood of u, $W^l \\in \\mathbb{R}^{1 \\times c}$ is the learnable weight for self-interaction,\nc represents the number of channels, and\n$A_{uv} = \\frac{\\exp \\big<Q_u, K_{uv}\\big>}{\\sum_{v'}\\exp \\big<Q_u, K_{uv'}\\big>}$ \t \t (17)\nis the attention from v to u. Here, key K, value V and query Q are\n$Q_u = \\bigoplus_l W^\\ell Q(x_u), K_{uv} = \\bigoplus_l \\sum_i W^K(x_v - x_u) f^i(x_v), V^{lk} = W^V(x_v - x_u) f^i(x_v)$ \t \t (18)\nwhere $W^l \\in \\mathbb{R}^{1 \\times (2l+1)}$ is a learnable weight, and the kernel $W^{lik}(x) \\in \\mathbb{R}^{(2l+1) \\times (2k+1)}$ is defined as\n$\\begin{aligned}\nvec(W^{lk}(x)) = \\sum_J \\varphi(\\lVert x \\rVert) \\circ Q_{J, k \\oplus l} Y_J(x/\\lVert x \\rVert),\n\\end{aligned}$\t \t (19)\nwhere vec(\u00b7) is the vectorize function, the learnable radial component $\\varphi : \\mathbb{R}_+ \\rightarrow \\mathbb{R}$ is parametrized\nby a neural network, and the non-learnable angular component is determined by Clebsch-Gordan\nconstant Q and the spherical harmonic $Y_J: \\mathbb{R}^3 \\rightarrow \\mathbb{R}^{2J+1}$."}, {"title": "B Derive of the Convolutional Kernel", "content": "To"}]}