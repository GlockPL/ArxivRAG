{"title": "CrediRAG: Network-Augmented Credibility-Based Retrieval for Misinformation Detection in Reddit", "authors": ["Ashwin Ram", "Yigit Ege Bayiz", "Arash Amini", "Mustafa Munir", "Radu Marculescu"], "abstract": "Fake news threatens democracy and exacerbates the polarization and divisions in society; therefore, accurately detecting online misinformation is the foundation of addressing this issue. We present CrediRAG, the first fake news detection model that combines language models with access to a rich external political knowledge base with a dense social network to detect fake news across social media at scale. CrediRAG uses a news retriever to initially assign a misinformation score to each post based on the source credibility of similar news articles to the post title content. CrediRAG then improves the initial retrieval estimations through a novel weighted post-to-post network connected based on shared commenters and weighted by the average stance of all shared commenters across every pair of posts. We achieve 11% increase in the F1-score in detecting misinformative posts over state-of-the-art methods. Extensive experiments conducted on curated real-world Reddit data of over 200,000 posts demonstrate the superior performance of CrediRAG on existing baselines. Thus, our approach offers a more accurate and scalable solution to combat the spread of fake news across social media platforms.", "sections": [{"title": "1 Introduction", "content": "The increasing reliance on social media as a primary source of news consumption has dramatically reshaped the information landscape. Approximately two-thirds of American adults now access news through platforms like Facebook, Twitter, and Reddit, with Facebook being the most popular for news consumption [12]. While social media has increased exposure to the news, particularly among younger and less-engaged audiences [9], it has also created a fertile ground for the spread of fake news and misinformation. Around 23% of social media users occasionally share fake news, with over 60% of users experiencing confusion about the veracity of news due to misinformation [35]. Misinformation on social media is a critical issue because it has real-world consequences, particularly during crises like the COVID-19 pandemic, where it fueled vaccine hesitancy, led to harmful health practices, and increased mortality rates [11, 41]. Beyond public health, misinformation has caused widespread psychological distress and social tensions and eroded public trust in institutions, undermining the societal capacity to respond effectively to emergencies [24, 39]. As such, automatically detecting misinformation became crucial because it can enable timely intervention to prevent the widespread harm caused by false information.\nMost social media platforms, including Reddit and Twitter have a structure where users can create posts and engage with them through comments and other forms of interaction. This hierarchical structure typically forms a tree-like pattern, with the original post at the root and subsequent comments and replies branching off. These interactions offer valuable network information, capturing the flow and propagation of content within the platform. Such interaction-driven engagement data has been utilized in various research areas, such as bot detection [18], where the interaction patterns between users and posts are analyzed to identify suspicious behavior. Reddit's unique community-based model, where subreddits focus on specific topics and the interaction between posts can reveal news source credibility patterns, is rich for studying these dynamics [3, 5, 10, 22, 23, 40]. Importantly, this interaction-based approach is not limited to Reddit, but is generalizable to other social media platforms with similar comment chain structures, making it"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Large Language Models (LLMs) for Fake News Detection", "content": "Large Language Models (LLMs) have shown significant promise in detecting fake news due to their ability to process large amounts of textual data [19]. However, they face several limitations, including reliance on static external knowledge sources, vulnerabilities to adversarial attacks, and challenges with cross-domain generalization [13, 16, 27, 32, 46]. For example, knowledge-enhanced models [45] and modular architectures like Self-Checker [27] improve detection by integrating external databases but are limited by the quality and availability of external knowledge, reducing their real-time efficiency.\nOther studies have explored prompt engineering techniques to optimize LLMs, as seen in the detection of \"cheap-fakes\" [46], though such approaches struggle with more complex forms of disinformation like deepfakes. Additionally, the dual-use nature of LLMs raises ethical concerns, as they can be exploited to generate misinformation [17]. Fine-tuning and weak supervision methods [23, 36] enhance LLMs' domain-specific performance, but come with significant computational costs and inconsistencies in handling noisy, real-world data.\nA key issue with LLMs is their propensity to \"hallucinate\" facts, generating incorrect information [13]. Moreover, these models are susceptible to adversarial attacks such as clean-label poisoning [29], further undermining their reliability. While hybrid models that combine human intelligence and LLMs show promise [47], they suffer from potential biases and decreased accuracy in dynamic social media environments [31].\nCross-domain generalization remains a significant challenge. Retrieval-augmented frameworks like RAEmoLLM [32] have integrated emotional cues for improved misinformation detection, but this introduces risks of misclassification when emotional intensity does not align with truthfulness. Query-based fact-checking models like \"TrumorGPT\" [16] rely heavily on query quality, making them less reliable when faced with poorly formulated queries."}, {"title": "2.2 Graph Neural Networks (GNNs) for Fake News Detection", "content": "Graph Neural Networks (GNNs) have gained prominence in detecting fake news by modeling the complex relationships among users, content, and interactions. Despite their strong performance, GNNs face significant limitations related to explainability, scalability, and sensitivity to dynamic social media environments. While continual learning [15] and geometric deep learning [33] can mitigate model degradation over time and improve accuracy, the increased complexity limits models' interpretability. Bi-directional Graph Convolutional Networks (GCNs) [6] further enhance rumor detection by capturing the spread and propagation of information, though their decision-making processes remain opaque, challenging public trust.\nKey GNN architectures, such as Graph Convolutional Networks (GCNs) [21] and Graph Attention Networks (GATs) [44], allow models to prioritize influential nodes, but attention mechanisms and large-scale graph structures introduce scalability issues, with models struggling to handle vast and intricate social networks."}, {"title": "2.3 Contributions", "content": "This paper distinguishes itself from the existing body of work with the following three contributions:\n\u2022 Novel Integration of Graph Community Structures and Credibility-Driven Retrieval: We are the first to leverage Reddit's intricate graph community structure and dynamic credibility-driven retrieval for more accurate fake news detection. This approach uniquely exploits the relational dynamics within social media platforms to enhance detection performance.\n\u2022 CrediRAG Model with Post-to-Post Network Architecture: We propose the CrediRAG model which improves accuracy and enhances explainability. By assigning initial credibility estimates based on similar news articles and improving them by incorporating a novel post-to-post network, our model captures the graph-level information often overlooked by text-based classifiers while providing the explainability behind the decision-making often missed in traditional graph-based methods.\n\u2022 Curated Fake News Dataset: We introduce a new labeled dataset of over 60,000 Reddit posts from 2016-2018, curated by matching verified fake news titles from the ISOT Dataset [1, 2] to Reddit submissions. This dataset offers a valuable resource for advancing graph-based misinformation research and enhancing the detection of fake news across social platforms."}, {"title": "3 Data", "content": "Given the lack of substantially labelled Reddit data, for our experiments, we created our own labelled dataset as described below. We also validated our results through experiments on the r/Fakeddit dataset [34]."}, {"title": "3.1 Dataset Construction", "content": "We develop a novel approach by leveraging the ISOT Fake News Datasets and aligning it with unlabeled subreddit data extracted from Pushshift.io [1, 2, 4]. Our goal is to enrich the dataset by matching Reddit submissions to known fake and true news articles from the ISOT dataset. This was achieved through a two-step process. First, we collect Reddit submissions and comments and then subsequently match them with fake and true news articles based on temporal proximity and textual similarity."}, {"title": "3.1.1 Subreddit Selection", "content": "To ensure that our dataset captures relevant discussions prone to misinformation, we carefully select subreddits that frequently discuss controversial topics, especially politics and social issues. Some of the top subreddits included in our data are shown in Table 1.\nThese communities are selected because they frequently involve discussions surrounding political ideologies, health misinformation (e.g., COVID-19, anti-vaccination), and global events (e.g., the war in Ukraine). They are also known to be common spaces for both legitimate and false information. Note all the data is in English only."}, {"title": "3.1.2 Data Preprocessing", "content": "Initially, we filter the data by comment number to retain only the most significant posts for analysis. For each submission, we then compare the publication date of the Reddit post with the dates of ISOT articles. Submissions and comments that fell within a predefined window of time-two days -around the publication dates of fake or true news articles were retained for further matching. This process allows us to filter out irrelevant data and focus only on posts that were temporally aligned with news events."}, {"title": "3.1.3 News Matching", "content": "To match Reddit submissions and ISOT news articles, we employ the SentenceTransformer model, specifically the all-MiniLM-L6-v2 architecture [38]. This model generates dense vector representations of the text input. Given a title from a Reddit post, represented as text input Tr, the model produces an embedding A for Tr. Similarly, it generates a high dimensional latent space embedding B for a news article title Tn. The model optimizes for embeddings such that semantically similar text inputs (e.g., titles discussing the same event) have closer representations in this vector space. We compute the cosine similarity between article title embeddings A and B as follows:\n$$S(A, B) = \\frac{A \\cdot B}{||A||||B||},$$\nwhere $A \\cdot B$ is the dot product of the two vectors, and $||A||$ and $||B||$ represent the 2-norm of the vectors A, B respectively. Cosine similarity yields a score between -1 and 1, where 1 indicates perfect similarity. In our implementation, we set a similarity threshold of 0.7, meaning that only submissions whose titles have a similarity score greater than or equal to 0.7 with a news article title are considered matched. The final dataset consists of posts matched with fake or true news articles, labeled based on the corresponding news article. The proposed method is conservative, matching posts with news only when both textual and temporal similarities are"}, {"title": "3.2 Dataset Statistics", "content": "We illustrate the specifics of our top subreddits in Table 1. Note that we train our corrective Graph Attention Network detailed in the methodology section (Section 4) on r/Conservative and r/Democrats, and test it on r/Libertarian and r/Impeach Trump from our curated dataset. On the r/Fakeddit data, we train on their entire text-only training data containing around 100,000 posts and test on their entire text-only testing data containing around 8, 000 posts."}, {"title": "4 Methodology", "content": "We present a robust pipeline for classifying misinformation on Reddit through the combination of graph networks with information retrieval. Figure 1 provides a high-level overview of the process."}, {"title": "4.1 Retrieval-Augmented Generation (RAG)", "content": "Accurate detection of fake news is a challenging task, particularly in dynamic environments like social media, where information is rapidly produced and shared. Traditional approaches to fake news detection often rely on static classifiers or models trained on manually curated datasets. However, these methods can struggle with crude labeling practices and limited context, leading to reduced accuracy in real-world scenarios. To address these limitations, we use RAG [25], which enhances detection by incorporating external knowledge dynamically during inference. RAG offers a significant advantage by retrieving relevant information in real-time.\nWe use the AskNews corpus to dynamically retrieve relevant similar news articles to the submission body of a post [43]. The AskNews API provides an efficient way to integrate real-time news into LLM applications. Using its RAG architecture, AskNews processes over 300,000 articles daily, embedding them into a vector database that can be queried with natural language.\nDuring inference, our model retrieves the top-k news articles that semantically align with the test post, ensuring that the model's predictions are informed by up-to-date and contextually relevant content. Our RAG approach mitigates the weaknesses of crude"}, {"title": "4.2 Label Refinement", "content": "Despite their high accuracy in fake-news detection tasks, retrieval-based methods suffer from several problems that limit their usefulness in a social network setting [32]. Firstly, these methods only take the content of the message into account, therefore they omit the underlying user interactions in their label assignment. Such interactions can be highly informative in determining fake news as they contain information about the community structure and the echo chambers within the social network. Secondly, some of the posts may contain text that is either too short or absent entirely. For instance, if the post itself is an image, the title itself may not contain sufficient information to determine the credibility of the entire content.\nTo alleviate these issues and improve prediction accuracy, we employ a refinement step of a graph attention network over the post-to-post networks. Intuitively, this step corrects the errors in the initial credibility assignments made in the retrieval-based generation step using the post-to-post network as side information."}, {"title": "4.2.1 Post-to-Post Network Construction", "content": "Given a set of posts labeled as real_news or fake_news, we construct a graph where nodes represent individual posts, and edges capture the relationship between posts that share commenters. Formally, let P = {$P_1, P_2, ..., P_n$} represent the set of posts, and C = {$C_1, C_2, ..., C_m$} represent the set of commenters. An undirected edge $e_{ij}$ exists between two posts $P_i$ and $P_j$ if they share at least one commenter, i.e.,"}, {"title": "4.2.2 Graph Attention Networks", "content": "Graph Neural Networks (GNNs) have become a powerful tool for modeling relational data, such as social networks, citation networks, and knowledge graphs, as demonstrated in various studies [6, 15, 21, 33, 44, 49]. At their core, GNNs propagate information through a graph by leveraging the graph's connectivity structure to improve node-level predictions. One commonly used GNN model is the Graph Convolutional Network (GCN), which updates a node's representation by aggregating features from its neighbors. For a graph G = (V, E), where V is the set of nodes and E is the set of edges, the update rule for each node $v_i \\in V$ in a GCN can be written as:\n$$h_i^{(l+1)} = \\varphi(\\sum_{j \\in N(i)} \\frac{1}{\\sqrt{d_id_j}} W h_j^{(l)}),$$\nwhere $h_i^{(l)}$ is the feature vector of node i at layer l, $W^{(l)}$ is a learnable weight matrix, N(i) is the set of neighbors of node i, $d_i$ is the degree of node i, and $\\varphi$ is an activation function, such as ReLU. However, this aggregation process in GCNs treats all neighbors equally, weighted only by their degree. This is a limitation when some neighbors are more relevant or influential than others, particularly in heterogeneous graphs like ours, where certain posts are more influential than others.\nGiven that our dataset contains posts of varying importance based on their connectivity and credibility, we require a model that can dynamically adjust the contribution of each neighbor. To address this, we adopt Graph Attention Networks (GATs), which use attention mechanisms to weigh the importance of neighboring nodes.\nOnce the post-to-post graph is constructed, we train a GAT to classify each node (post) as either real_news or fake_news. Let G = (V, E) represent our graph, where V is the set of posts and E is the set of weighted edges. For each node $v \\in V$, the GAT computes the attention coefficient $a_{ij}$ for every neighboring node $v_j \\in N(v)$ as follows:\n$$\\alpha_{ij} = \\frac{\\exp \\left(\\operatorname{LeakyReLU}\\left(\\mathbf{a}^T \\left[\\mathbf{W} \\mathbf{h}_i \\| \\mathbf{W} \\mathbf{h}_j\\right]\\right)\\right)}{\\sum_{k \\in \\mathcal{N}(i)} \\exp \\left(\\operatorname{LeakyReLU}\\left(\\mathbf{a}^T \\left[\\mathbf{W} \\mathbf{h}_i \\| \\mathbf{W} \\mathbf{h}_k\\right]\\right)\\right)},$$\n$$\\mathbf{h}_i^{\\prime} = \\varphi\\left(\\sum_{j \\in \\mathcal{N}(i)} \\alpha_{i j} \\mathbf{W} \\mathbf{h}_j\\right),$$\nwhere $\\varphi$ is the activation function. This attention mechanism allows the GAT to dynamically focus on more relevant or credible neighbors, giving the model a greater ability to distinguish between real and fake news.\nDuring training, we need a large set of posts with both ground truth credibility labels and initial credibility assignments from the retrieval-based method. However, querying a retrieval model for each post is computationally expensive. To mitigate this, we generate fictitious initial credibility assignments by randomly corrupting a subset of the labels and training the GAT to reconstruct the original ground truth. This process aims to improve the model's robustness by learning to correct errors in the initial labeling.\nThe ratio r of corrupted labels must be tuned to reflect the false classification rate of the retrieval-based classifier. In our experiments, we found that setting r = 15% yielded optimal results, based on preliminary evaluations of the retrieval-based classifier."}, {"title": "5 Results and Discussion", "content": "We present the performance of various models across both the ISOT Reddit and r/Fakeddit datasets in Table 2. Here, accuracy refers to the proportion of correctly classified posts (both real and fake) out of the total number of posts, while F1-score gives a better indication of the model's performance in identifying fake news posts especially considering class imbalance. Our proposed model, CrediRAG with Weighted GAT, consistently outperforms all other baselines in terms of accuracy and F1-score across both datasets."}, {"title": "5.1 Performance on ISOT Reddit", "content": "As shown in Table 2, on the ISOT Reddit dataset, CrediRAG with Weighted GAT achieves the highest accuracy of 0.8667 and an F1-score of 0.811, outperforming all other models. The next best model, CrediRAG with un-weighted GAT, achieves an accuracy of 0.764 and an F1-score of 0.766. This clear improvement of approximately 10% in accuracy and 4.5% in F1-score demonstrates the critical impact of introducing weighted edges in the graph attention mechanism. Through these ablation tests, we reveal that the improvement in performance is due to our various architectural choices in designing CrediRAG.\nWe also evaluated a variant of our model, CrediRAG without GAT, which omits the graph attention component. This variant achieves an accuracy of 0.732 and an F1-score of 0.722, indicating a substantial decline in performance compared to models utilizing graph-based attention. These results illustrate that while RAG contributes to performance gains, the inclusion of GAT layers is essential for capturing the complex relationships between posts and comments within Reddit discussions. The GAT layers enable the model to learn more effectively from the network structure of the data, allowing it to better classify posts as misinformative or not. In contrast, approaches like Google-search based retrieval models [42] are limited in their ability to generalize to complex and dynamic discussions on platforms like Reddit. Google search accesses content from a broader web index and retrieves documents with little consideration of the conversation's context or the interactions between users. This makes it less effective for detecting misinformation within highly interactive, user-generated environments like Reddit, where understanding the relationships between posts, replies, and user behaviors is crucial. By integrating the GAT into our RAG framework, CrediRAG offers superior performance in both classification and generalization, successfully leveraging both content and relational structures within social media platforms."}, {"title": "5.2 Performance on r/Fakeddit", "content": "On the r/Fakeddit dataset, the performance of CrediRAG with Weighted GAT is even more pronounced, with an accuracy of 0.9437 and an F1-score of 0.920, once again demonstrating a significant improvement over other baselines. The next best model, CrediRAG with un-weighted GAT, achieves an accuracy of 0.850 and an F1-score of 0.890, confirming that the weighted GAT mechanism captures more nuanced interactions between nodes in the graph and reinforcing the impact of our post-to-post network weighting structure.\nIt is important to note that the optimistic performance on r/Fakeddit may partially stem from the dataset's labeling scheme. In r/Fakeddit, all posts from certain subreddits are pre-labeled as either fake or real. This subreddit-wide labeling may artificially inflate the accuracy and F1-score, as models can exploit these global patterns rather than focusing solely on the content of individual posts. Therefore, while the performance improvements on r/Fakeddit are significant, the labeling approach should be considered when interpreting these results."}, {"title": "5.3 Significance of the Results", "content": "The results in Table 2 demonstrate that integrating GNN-based attention and retrieval-augmented generation in CrediRAG significantly outperforms models like BERT, GPT3.5-turbo, TextCNN, and TextGCN. While BERT achieves an accuracy of 0.624 and an F1-score of 0.667 on ISOT Reddit, CrediRAG with Weighted GAT improves accuracy by 24% and F1-score by 14.4%. This highlights the importance of graph-based attention in modeling user interactions and post-comment relationships.\nThe enhanced performance of CrediRAG with Weighted GAT underscores the value of edge weights in GAT layers. Assigning"}, {"title": "5.4 Case Study: Generalizability of CrediRAG", "content": "In addition to ablation tests, we perform a case study using three subreddits to evaluate the generalizability of CrediRAG. Figure 3 shows ROC and calibration curves for the models trained on both ISOT Reddit and r/Fakeddit datasets, evaluated on r/SandersForPresident, r/EnoughTrumpSpam, and r/DonaldTrumpWhiteHouse."}, {"title": "5.4.1 ROC Curves: Discriminative Power", "content": "The ROC (Receiver Operating Characteristic) curves assess the ability of the model to discriminate between true and false classifications by plotting the true positive rate (TPR) against the false positive rate (FPR). A higher Area Under the Curve (AUC) indicates better performance.\nAs shown in the ROC curves (Figure 3), CrediRAG with Weighted GAT demonstrates superior AUC scores on both the ISOT Reddit and r/Fakeddit datasets, significantly outperforming the baseline models such as BERT and Web-Retrieval LLM Agent. This steep rise in TPR with minimal increase in FPR indicates that CrediRAG is particularly adept at distinguishing between fake and real news, even across unseen subreddits."}, {"title": "5.4.2 Calibration Plots: Confidence in Predictions", "content": "The calibration plots evaluate the reliability of the model's predicted probabilities by comparing them to the actual outcomes. A well-calibrated model should closely follow the diagonal line, where predicted probabilities match observed frequencies.\nAs seen in the calibration plots, CrediRAG with Weighted GAT is well-calibrated on both datasets, with most points aligning with the perfect calibration line. In contrast, models like BERT and Random deviate substantially from the diagonal, indicating overconfidence or underconfidence in their predictions. The accurate probability estimates provided by CrediRAG are crucial in real-world applications such as content moderation, where both accuracy and model confidence are necessary for decision-making."}, {"title": "5.4.3 Significance of Results", "content": "The results, illustrated by both ROC and calibration plots, show that CrediRAG with Weighted GAT not only excels at distinguishing between fake and real news but also provides well-calibrated confidence estimates, making it a robust choice for fake news detection. The model's generalizability across subreddits further demonstrates its adaptability to unseen data, a critical factor for real-world deployment in misinformation detection.\nWhile r/Fakeddit's optimistic results can be attributed to the dataset's labeling scheme-where entire subreddits are classified as either fake or real-CrediRAG's superior performance on the more granular ISOT Reddit dataset highlights that its performance is not merely the result of exploiting global patterns but is driven by its advanced design. This makes CrediRAG well-suited for detecting misinformation in diverse Reddit communities."}, {"title": "6 Broader Impacts", "content": "The advancements of CrediRAG have significant implications for fake news detection on platforms like Reddit. By combining graph-based attention with retrieval-augmented generation, CrediRAG models both the content and relational structure of discussions, crucial for understanding how misinformation spreads through user interactions and threads.\nOur results highlight the potential of integrating GNNs with retrieval techniques for more effective misinformation detection. Additionally, our findings emphasize the need for robust dataset labeling, as simplistic labels (e.g., from r/Fakeddit) can inflate performance by revealing exploitable global patterns. To support further research, we open-source both our code and labeled dataset for graph-based fake news detection on Reddit."}, {"title": "6.1 Ethics Statement", "content": "Our work uses publicly available Reddit data in compliance with Reddit's terms of service, ensuring user anonymity by not collecting or storing any personally identifiable information. While CrediRAG enhances misinformation detection through source credibility and generative AI, low-credibility outlets may still influence scores. Though our graph-based refinement reduces this risk, we advise users to use the tool cautiously, recognizing its limitations. It is intended as a supplementary resource, and its results should be considered alongside broader assessments of context and credibility."}, {"title": "7 Conclusion", "content": "In this work, we introduce CrediRAG, a novel model that combines RAG with a GAT and a distinct post-to-post structure for the task of fake news detection on Reddit. Through comprehensive evaluations"}, {"title": "A Baseline Descriptions and Fairness of Comparisons", "content": "In this section, we describe the baselines used for model evaluation and explain why each serves as a fair comparison for assessing the performance of our CrediRAG model with weighted GAT. The baselines span several architectures that are commonly used in fake news detection, natural language processing (NLP), and misinformation detection tasks, ensuring a robust and meaningful evaluation."}, {"title": "A.1 Random Baselines", "content": "We include two random baselines to provide a lower-bound performance comparison:\n\u2022 Random: This baseline assigns labels randomly, providing a baseline to show how much better an informed model performs compared to uninformed guessing.\n\u2022 Majority: This baseline always predicts the most common class in the dataset. It serves as a fair reference for understanding the impact of class imbalance on model performance."}, {"title": "A.2 Neural Network-Based Baselines", "content": "Neural network models have been foundational in text classification and fake news detection. We include these baselines to compare against graph and transformer-based methods.\n\u2022 TextCNN [20]: TextCNN represents a traditional neural network architecture for sentence classification. Its inclusion ensures comparison with established non-graph methods.\n\u2022 TextGCN [48]: TextGCN introduces graph-based learning using word co-occurrence graphs. This baseline helps assess whether our more advanced graph neural network (GNN) approaches outperform standard graph-based text classification methods.\n\u2022 GAT-only [44]: The GAT-only model evaluates the effectiveness of graph attention networks (GATs) without retrieval augmentation. By comparing it to retrieval-based models, we can isolate the impact of incorporating external knowledge in our model."}, {"title": "A.3 Transformer-Based Baselines", "content": "Transformers are known for achieving state-of-the-art results in various NLP tasks, including fake news detection. Thus, they serve as strong baselines for evaluating our work.\n\u2022 BERT [8]: BERT is a transformer model that has set benchmarks in text classification. Including it allows us to show whether our approach improves over traditional transformer architectures.\n\u2022 GPT3.5-turbo [7]: GPT-3.5 represents a powerful large language model with access to vast amounts of training data. Its inclusion demonstrates how our more specialized retrieval-augmented approach compares to these large-scale pretrained models.\n\u2022 CrediBERT [3]: CrediBERT is specifically designed for credibility assessment, making it a fair comparison against our work, which also focuses on misinformation detection."}, {"title": "A.4 RAG-Based Baselines", "content": "RAG (Retrieval-Augmented Generation) models incorporate external knowledge sources to inform their predictions. These baselines test the efficacy of retrieval-based models.\n\u2022 Web-Retrieval LLM Agent [42]: This baseline retrieves real-time information from the web to enhance the language model's factual accuracy. Testing against this model (note that the base LLM here is GPT-40) ensures a fair comparison of retrieval-augmented models.\n\u2022 CrediRAG without GAT (Ours): This variant of our model omits the GAT component, allowing us to measure how much graph-based reasoning contributes to the overall performance."}, {"title": "A.5 GNN + RAG Baselines", "content": "Our main contribution combines GNNs with RAG for fake news detection. These baselines show how adding graph-based attention improves retrieval-augmented methods.\n\u2022 CrediRAG with un-weighted GAT (Ours): This baseline includes an unweighted GAT in our architecture. By comparing against our weighted version, we quantify the performance gain attributed to attention-based weighting in our GNN."}, {"title": "A.6 Fairness of Comparison", "content": "It is essential to ensure that all comparisons are fair, particularly when dealing with models that may have different sources of external information. In our experiments, the AskNews knowledge base, which powers our retrieval in CrediRAG, only contains information from 2023 onward. Similarly, the Google search engine used by the Web-Retrieval LLM baseline also has access to data from 2023. Therefore, when we test on datasets like ISOT Reddit from 2017, neither retrieval system is accessing future information, ensuring that both models are evaluated under the same conditions with regard to the availability of external knowledge. This parity ensures a fair comparison between our CrediRAG model and the Web-Retrieval LLM Agent."}, {"title": "B Experiment Details", "content": ""}, {"title": "B.1 Dataset Statistics", "content": "The ISOT Reddit dataset is constructed by combining Reddit submissions and comments with ground-truth labels from the ISOT Fake News dataset, which includes true and fake news articles from 2016 to 2017. The dataset is structured to match Reddit posts with news articles based on semantic similarity and publication date, creating a rich set of labeled data for misinformation detection tasks. Below are the details on how the dataset is created:\nPreprocessing: We begin by loading the ISOT Fake News dataset, which consists of two parts: true news articles and fake news articles. The publication dates of these articles are standardized using Python's datetime module. Any missing or ambiguous dates are handled by using multiple date formats. The true and fake articles are then aligned to a reference date, set as January 1st, 2016, to calculate how many days have passed since that point for each article. This forms the basis for matching the news articles with Reddit posts.\nReddit Submission and Comment Collection: To gather Reddit data, we process submissions and comments from relevant subreddits. The subreddits are chosen based on their relevance to political and news-related discussions during the period of interest (2016-2017). For each subreddit, we filter submissions by year, score, and number of comments to ensure that only highly engaging content is retained. Submissions are enriched with metadata, including the time of submission (in Unix time) and the number of days since the reference date.\nMatching Reddit Posts with News Articles: Once the Reddit submissions and comments are cleaned, we proceed to match them with articles from the ISOT Fake News dataset. Using a pre-trained"}, {"title": "B.2 AskNews Retrieval Process", "content": "For retrieving news articles that are relevant to a given Reddit submission, we employ the AskNews retrieval system, which allows for searching through a large corpus of news articles while ensuring diversity in sources. However, a unique challenge arises from the constraint that AskNews only allows searches for one month of data at a time. This necessitates a month-by-month search over the entire corpus to gather the most relevant articles.\nRetrieval Methodology: To overcome the one-month constraint, we designed a method that iteratively searches for news articles by processing each month separately. For each Reddit submission, we execute a semantic search across all months, using natural language processing (NLP) techniques to find articles with high textual similarity to the submission. As we move through the months, we maintain a set of articles that meet the similarity threshold, ensuring that only those with a similarity score above 0.8 are considered relevant, and keeping the 50 highest similarity articles with the post content in the end.\nThe searching is done as follows:\nresponse = ask.news.search_news(\n\tquery=submission_text,\n\tn_articles=k,\n\treturn_type=\"dicts\",\n\tmethod=\"both\",\n\tdiversify_sources=True,\n\thistorical=True,\n\tsimilarity_score_threshold=0.8\n)"}, {"title": "B.2.1 Adversarial Training using GAT Model", "content": "In our approach to classify posts as either \"correct\" or \"misinformed", "we utilize a Graph Attention Network (GAT) with adversarial training. The GAT operates on a post-to-post network, capturing relationships between posts, while adversarial perturbations help simulate noisy data and improve model robustness.\nGraph Attention Network (GAT)": "The GAT model is designed to perform node classification by focusing on important neighboring nodes in a graph. Each node in our graph represents a post", "layers": "n\u2022 The first layer applies attention to the input node features (posts) and outputs hidden representations.\n\u2022 The second layer performs binary classification (correct or misinformed) based on the attention-weighted node representations.\nAdversarial Perturbation: To train the GAT model, we introduce adversarial"}]}