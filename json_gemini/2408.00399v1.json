{"title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures", "authors": ["Alexandre TRILLA", "Nenad MIJATOVIC"], "abstract": "A fundamental task in science is to determine the underlying causal relations because it is the knowledge of this functional structure what leads to the correct interpretation of an effect given the apparent associations in the observed data. In this sense, Causal Discovery is a technique that tackles this challenge by analyzing the statistical properties of the constituent variables. In this work, we target the generalizability of the discovery method by following a reductionist approach that only involves two variables, i.e., the pairwise or bi-variate setting. We question the current (possibly misleading) baseline results on the basis that they were obtained through supervised learning, which is arguably contrary to this genuinely exploratory endeavor. In consequence, we approach this problem in an unsupervised way, using robust Mutual Information measures, and observing the impact of the different variable types, which is oftentimes ignored in the design of solutions. Thus, we provide a novel set of standard unbiased results that can serve as a reference to guide future discovery tasks in completely unknown environments.", "sections": [{"title": "1. Introduction", "content": "Causal Discovery methods are able to identify the causal structure from the joint distribution of the data by introducing assumptions that restrict the model of their generating process [1]. In a multivariate setting, the traditional constraint-based and score-based methods exploit conditional independence relationships in the data [2]. These approaches have found a great deal of success in challenging environments such as biology and the Earth sciences [3]. Nevertheless, they do not necessarily provide complete causal information because they output Markov Equivalence Classes, i.e., a set of causal structures that satisfy the same conditional independence statements. Moreover, they cannot handle isolated cause-effect settings that lack the diversity of other variables for the conditional tests. Therefore, the single reduced cause-effect association, also known as the pairwise or bivariate scenario, constitutes an essential building block of more complex causal structures.\nTo distinguish cause from effect in this pairwise setting, one needs to find a way to capture the asymmetry between the two variables [2]. In this sense, computational methods based on properly defined Functional Causal Models (FCMs) are able to distinguish different structures in the same equivalence class. A FCM represents the effect variable Y as a function of its direct causes X and some noise term &, i.e., $Y = f(X,\u03b5)$, where & is independent of X. Thanks to the restricted functional classes, the causal direction between X and Y is generally identifiable because the independence between the noise and the cause holds only for the true causal direction and is violated for the wrong direction [4] (unless the variables are jointly Gaussian, which render the orientation unidentifiable). Additionally, the identifiability of pairwise FCM generalizes to the identifiability of multivariate FCM [5].\nIn this work, we argue that some reference benchmark results for pairwise causal discovery could be misleading because they tackle this genuinely exploratory objective as a classical supervised classification problem, inducing them to possibly learn specific contextual details beyond causality that tend to overestimate their actual performance [6]. Moreover, there exists a tight relationship between the nature of data and the specific tools from statistics that could also accrue the estimation of skewed results, which was not originally addressed. Consequently, we propose a reevaluation of the benchmark driven by the heterogeneity of the data and also by following an unsupervised learning approach. Our method leverages linear functional causal models and combines different unconditional independence tests based on robust Mutual Information measures. The paper is organized as follows: Section 2 introduces the fundamental concepts for pairwise causal discovery, Section 3 describes the enhanced method proposed in this work, Section 4 shows the novel benchmarked results, Section 5 discusses the approach from a causal perspective, along with its limitations, and Section 6 concludes the article."}, {"title": "2. Background", "content": "This section reviews the fundamental concepts that support the discovery of causality in the bivariate or pairwise setting."}, {"title": "2.1. Identifiability of a Linear Model with Non-Gaussian Noise", "content": "The fundamental principle that enables the identification of cause and effect lies in the asymmetry of the association between them: the causal direction, i.e., from cause to effect, is functionally simpler than the anticausal one, i.e., from effect to cause, which requires a more complex application [2]. Thus, a given model with limited capacity will be able to faithfully capture the expressiveness of only one of these two causal orientations.\nLinear additive noise models assume that the effect Y is a linear function of the cause X plus a noise term & that is independent of the cause, formally defined as: $Y = bX +\u03b5$. The linear FCM is learnable if at most one of X and & is Gaussian [7]. Pairwise discovery approaches such as this one are regarded to be very flexible for identifying causal models in the general case because they don't require a third variable for conditioning. In specific scenarios such as multivariate time series, they can even improve the performance of traditional constraint-based approaches such as the Peter-Clark algorithm and others that utilize Granger causality [3].\nThe linear model with non-Gaussian noise can be estimated from (unconfounded) observational data by exploiting the inherent asymmetry between cause and effect through a regression as follows: for both directions (i.e., causal and anticausal), the FCM is fit; then, the amount of association between the estimated noise term (i.e., the regression residual) and the hypothetical cause is computed; finally, the direction assignment which gives an independent noise term is considered plausible [2].\nObviously, the cornerstone of this regression-based method is the measure of dependence between the regression residual and its associated potential cause. The next section describes a solution to estimate the strength of this association."}, {"title": "2.2. Mutual Information as a Measure of Association", "content": "The amount of association between the regression residual RR and the hypothetical cause HC signals the causal direction. However, these variables are uncorrelated by construction of the regression. To properly quantify this dependence, the Mutual Information (MI) measure provides a reliable indicator, which is defined as\n$MI(RR,HC) = \\sum_{RR,HC} P_{RR,HC} log (\\frac{P_{RR,HC}}{P_{RR} P_{HC}})$ (1)\nwhere $P_{RR,HC}$ represents the (discrete) joint probability between RR and HC, and $P_{RR}$ and $P_{HC}$ represent their marginal distributions, respectively.\nFor illustrative purposes, the following variable dependencies are defined. First, a random Uniform noise sample U is independently assigned to Z, Xind and Yind. Then, the following structural variable associations are created: Ydep \u2190 Xind+Z, Xconf \u2190 Xind+Z, and Yconf Yind + Z, which yield the subsequent relationships:\nCausal Between Xind and Ydep: X \u2192 Y\nAnticausal Between Ydep and Xind: Y \u2190 X\nIndependent Between Xind and Yind: X Y\nConfounded Between Xconf and Yconf: X \u2192 Y\nFigure 1 shows the distribution of MI between the regression residual and the hypothetical cause considering the preceding types of structural variable associations for a random sample of 1000 instances. The different density plots show how the causal orientation can be reliably recovered using MI when the model assumptions are respected. Note that the overlap between Causal and Independent structures will be disambiguated when both experiments are conducted regarding the different causal direction hypotheses. Finally, MI is also able to detect latent confounding, which is oftentimes assumed (and required) not to occur for discovery [2], i.e., the causal sufficiency principle [8]. This feature adds value to the robustness of the MI indicator.\nWhile the distribution of MI is a useful tool to visualize the different causal structures, there is still a missing criterion to make a classification decision in order to construct the underlying causal structure from the data. The next section addresses this point."}, {"title": "2.3. Pearson's x\u00b2 as an Unconditional Independence Test", "content": "In a real-word scenario, one cannot expect to get a null measure of association because of sampling noise, the sample size, etc. In this case, the use of an (unconditional) independence test is the proper way to handle this situation. In general, this is known as the REgression with Subsequent Independence Test (RESIT) procedure [9]. Once the independence test is in place, a confidence interval needs to be observed to obtain actionable results. To this end, Pearson's x2 test is here introduced as a fundamental method to inform the decision process [10].\nThe Pearson's x2 test is a statistical hypothesis test used in the analysis of contingency tables for categorical variables. It is used here to determine whether there is a statistically significant difference between the expected frequencies E for independence (i.e., the marginal probabilities) and the observed frequencies O in one or more categories i of the contingency table (RR,HC), formally defined as\n$x\u00b2(RR, HC) = \\sum_{i\u2208(RR,HC)} \\frac{(O\u00a1 - E\u2081)\u00b2}{E\u2081}$ (2)\nThe test is valid as long as its statistic is x\u00b2 distributed under the null hypothesis. Note that x2(RR, HC) is in its essence related to the MI measure of association as is used for the discovery of causal structure.\nWhile the x2 test is most suitable for discrete variables [11], a general causal discovery method should be able to seamlessly deal with continuous variables. Typically, a uniform grid is applied to discretize a real-valued space prior to conducting the test. Following the former illustrative example, Table 1 shows the p-values for the different causal structures. Once a threshold is introduced through the confidence interval, e.g., p<0.05 for a given number of degrees of freedom related to the resolution of the grid, passing the test becomes the rule for making further decisions. Note that in all cases, there is a unique combination of results for the two hypothesized causal directions that identifies the true underlying causal structure. Also note that the threshold may be adjusted to require further decision strength because the closer the variables get to a Gaussian distribution, the harder it is to distinguish the direction of causation [2]."}, {"title": "2.4. Total Information Coefficient as a Robust Independence Test", "content": "The Total Information Coefficient (TIC) is a robust independence test based on MI for real-valued variables that features the two important heuristic properties of generality and equitability [12], which are defined as follows:\nGenerality With sufficient sample size the statistic should capture a wide range of interesting associations, not limited to specific function types.\nEquitability The statistic should give similar scores to equally noisy relationships of different types.\nFor a pair of (RR, RC) variables, the TIC algorithm applies a search procedure to partition their joint probability function and find the grid with the highest induced MI. TIC operates by summing over optimal grids G on the joint density distribution of the two variables, such that it exhibits a stronger power against independence [11], formally expressed as\n$TIC(RR, HC) = \\sum_{G} \\frac{MI((RR, HC)|G)}{log || G ||}$, (3)\nwhere || G || denotes the minimum of the number of rows and columns of G. This can be viewed as a regularized version of MI that penalizes complicated grids. Figure 2 shows qualitatively the impact of the optimum grids G.\nThe performance of TIC has been positively rated with other successful approaches for causal discovery dealing with continuous variables, such as the Hilbert-Schmidt independence criterion [13]. Finally, an additional motivation for considering TIC in this work is to increase the odds of success in case of model hypothesis violations, i.e., the functional form of the relationship Y = f(X), which is crucial for causal identification."}, {"title": "3. Method", "content": "In the pursuit of a general approach to causal discovery combining several methods [8,14], one common point of success is found in the use of information-theoretic measures, such as Mutual Information, to quantify the amount of regularity in the data [15]. However, the nature of the variables, i.e., discrete or continuous, can be problematic in an heterogeneous context if the statistical methods are confused [14]. Moreover, supervised learning approaches are excluded from the general objective because these methods do not yet work as standalone techniques for causal learning [4]. Therefore, the desideratum in causal discovery is to have methods that work on a broad range of problems under different conditions with relaxed assumptions [16], ideally showing a certain degree of robustness regarding violations of the model hypothesis [17].\nIn this work we propose a general method to discover the causal structure in heterogeneous data based on a bivariate linear FCM by implementing a flexible RESIT procedure, see Section 2.3, where the unconditional independence test, e.g., x\u00b2 or TIC, also see Section 2.4, is driven by the nature of the variables involved. The proposed strategy is described with comments in Algorithm 1. Note that the orientation decision rules follow from the evidence given by the illustrative setting in Section 2.3, which is regarded as self-evident. Such explicitly-stated logic rules are meant to increase the interpretability and explainability of the proposed method. Also note that discrete variables are assimilated to real-valued variables for computing the regression residuals on which the RESIT method is based. Finally, since our contribution targets the problem of applying one single discovery technique on data with different types of variables, and we focus our effort at the integration level rather than at the fundamental level, we refer the interested reader to the references for the specific methods being integrated for further details about their comparison to other methods from the literature. We rely on the advice from Peters, Reshef, and colleagues [4,11], to select the best methods that we integrate in RESFIT in order to cover a broad range of techniques, and we provide an analysis on how these separate tools perform when they are put together."}, {"title": "4. Results", "content": "This section describes the reference benchmark dataset that was used to evaluate the introduction of the flexible independence test selection, the results that were obtained, and the tools for the implementation of the research."}, {"title": "4.1. Reference Benchmark Dataset", "content": "The \"ChaLearn cause-effect pair (SUP2)\" is taken for reference as the recommended benchmark dataset to evaluate the performance of pairwise causal discovery [6]. It comprises pairs of artificially generated dependent variables with different types (numerical, categorical and binary) for the full causal discovery task (orientation, independence and confounding). The dataset features a balanced number of unique values across all classes and includes around 6000 pairs. In terms of data type balance, the majority is comprised of numerical and mixed variable pairs. Finally, the average median length of an instance is around 2000 values."}, {"title": "4.2. Performance Scores", "content": "The accuracy classification score, i.e., the total rate of correct predictions statistically given by the overall amount of true positives and true negatives, is used in this research following the previous benchmark evaluation approaches [6], yielding a baseline around 65\u00b12% for the supervised learning setting [15]. To further assess the stability of our scores in the unsupervised scenario, statistical bootstrapping is introduced in line with this former work. Moreover, Gaussianity is asserted with the Lilliefors normality test [18], and the main descriptive statistics are extracted despite the low amount of available performance samples, well under 30, which are commonly required to obtain reliable estimations [19]. Finally, in terms of statistically significant comparisons, the t-test has been used [20]. Table 2 shows the results of the experiments. Note that they are presented separately by data type and independence test, whereas the proposed RESFIT algorithm automatically integrates them. This is done for illustrative purposes and for enriching the ensuing discussion.\nThe first straightforward conclusion that the results show is that, in all cases, there is a statistically significant difference between the accuracy averages for the two unconditional independence tests within each data type stratum. Therefore, introducing a selection action on the test function is expected to impact on the discovery of causal associations. Additionally, TIC yields a slightly smaller variance in all the scores. Finally, when numerical data types are present, the standard deviation in accuracy drops an order of magnitude.\nThe code for this research is available here\u00b9. The next section discusses the global results with respect to the perspective of a causal effect, and addresses the limitations of the proposed approach."}, {"title": "5. Discussion", "content": "This section delves into the finer details of the results that were obtained, and sheds light on the actual value introduced by the flexibility in selecting the unconditional independence test for causal discovery."}, {"title": "5.1. Average Causal Effect of the Flexible Test Selection", "content": "To properly quantify the impact of introducing the flexibility on the unconditional independence test, this section treats this selection action as a \"treatment\" variable X and studies its impact on the \u201coutcome\" discovery accuracy score Y. The Average Causal Effect (ACE) of X \u2192 Y is expressed using the following counterfactual notation\n$ACE=E[Y_{1} - Y_{0}] = E[Y_{1}] - E[Y_{0}] = E[Y(X = 1)] \u2013 E[Y (X = 0)]$\n$=E[Y|X = 1] - E[Y|X = 0]$, (4)\nwhere Yx refers to the value the Y accuracy result would have if X was set to x, i.e., Y(X = x). Here, X could take the values x = 1 to indicate flexibility of independence test, and x = 0 to indicate no preference (i.e., the null random choice). The conditionals that eventually follow are the values that are actually observed in the results. Note that all these expected quantities can be exactly calculated because the different experiments can be conducted on the same data (also dispelling any doubts about latent confounding). This setting is thus not subject to the fundamental problem of causal inference where only one of the potential outcomes can be observed [21].\nEquation (4) is shown to be an unbiased estimator for the ACE [22]. For computing the expectations in the causal effect comparison, a weighted mixture of Gaussian random variables is required. The quantity of the reference potential outcome E[Yo], where no smart selection occurs, is given by the arithmetic mean value of the total results, and it yields an accuracy score of 0.3531\u00b10.0357. Alternatively, the potential outcome E[Y1], where the smart flexible test selection is introduced, is given by the average of the best performance results among the different variable types, i.e., a sum weighted by their balance in the dataset, and it yields a value of 0.3866\u00b10.0690. Therefore, the ACE is of 3.36%, and this estimated difference is statistically significant. However, the absolute results are far from the 65% baseline, which suggests that the original supervised approach may have leaked statistical patterns beyond causation. Although the unsupervised learning approach does not seem to offer any pragmatic quantifiable advantage, we believe that its adoption is a must for tackling the inherently hard exploratory objective of causal discovery and avoid any qualms with regards to learned biases."}, {"title": "5.2. Limitations", "content": "The realization that TIC, which was conceived for numerical data, performed better on discrete data is surprising. Also, x2, which is defined for discrete data, performed better on numerical data. This counterintuitive behavior where theory and practice disagree may suggest that the independence tests that were used are subject to some inherent limitations such as the sample size. We regard the shortage of samples to be the main limitation of our approach on real-world data applications such as the Tuebingen dataset [23]. Finally, while the approach that we propose is able to welcome any testing technique, we selected RESIT flexibly paired with TIC and x2 following the advice of Peters, Reshef, and colleagues [4,11]. To the best of our knowledge, this limited choice should be sufficient to generally cover the spectrum of approaches."}, {"title": "6. Conclusion", "content": "Environments with heterogeneous data pose challenging questions to the discovery of causal structure, and leveraging one single method may lead to erroneous results in gen-eral. In this work, we propose an unsupervised pairwise approach using linear functional causal models and different unconditional independence tests based on Mutual Information measures, the selection of which is driven by the nature of data and the empirical results from a reference benchmark. The introduction of this independence test selection flexibility is estimated to have a positive and statistically significant average causal effect over 3% in accuracy. These scores may establish the first standard baseline for this kind of flexible focus, but more research is needed because the limitations of the data size and the statistical techniques can result in counterintuitive results."}]}