{"title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures", "authors": ["Alexandre TRILLA", "Nenad MIJATOVIC"], "abstract": "A fundamental task in science is to determine the underlying causal relations because it is the knowledge of this functional structure what leads to the correct interpretation of an effect given the apparent associations in the observed data. In this sense, Causal Discovery is a technique that tackles this challenge by analyzing the statistical properties of the constituent variables. In this work, we target the generalizability of the discovery method by following a reductionist approach that only involves two variables, i.e., the pairwise or bi-variate setting. We question the current (possibly misleading) baseline results on the basis that they were obtained through supervised learning, which is arguably contrary to this genuinely exploratory endeavor. In consequence, we approach this problem in an unsupervised way, using robust Mutual Information measures, and observing the impact of the different variable types, which is oftentimes ignored in the design of solutions. Thus, we provide a novel set of standard unbiased results that can serve as a reference to guide future discovery tasks in completely unknown environments.", "sections": [{"title": "1. Introduction", "content": "Causal Discovery methods are able to identify the causal structure from the joint distribution of the data by introducing assumptions that restrict the model of their generating process [1]. In a multivariate setting, the traditional constraint-based and score-based methods exploit conditional independence relationships in the data [2]. These approaches have found a great deal of success in challenging environments such as biology and the Earth sciences [3]. Nevertheless, they do not necessarily provide complete causal information because they output Markov Equivalence Classes, i.e., a set of causal structures that satisfy the same conditional independence statements. Moreover, they cannot handle isolated cause-effect settings that lack the diversity of other variables for the conditional tests. Therefore, the single reduced cause-effect association, also known as the pairwise or bivariate scenario, constitutes an essential building block of more complex causal structures.\nTo distinguish cause from effect in this pairwise setting, one needs to find a way to capture the asymmetry between the two variables [2]. In this sense, computational meth-"}, {"title": "2. Background", "content": "This section reviews the fundamental concepts that support the discovery of causality in the bivariate or pairwise setting."}, {"title": "2.1. Identifiability of a Linear Model with Non-Gaussian Noise", "content": "The fundamental principle that enables the identification of cause and effect lies in the asymmetry of the association between them: the causal direction, i.e., from cause to effect, is functionally simpler than the anticausal one, i.e., from effect to cause, which requires a more complex application [2]. Thus, a given model with limited capacity will be able to faithfully capture the expressiveness of only one of these two causal orientations.\nLinear additive noise models assume that the effect Y is a linear function of the cause X plus a noise term $\\varepsilon$ that is independent of the cause, formally defined as: $Y = bX + \\varepsilon$. The linear FCM is learnable if at most one of X and $\\varepsilon$ is Gaussian [7]. Pairwise discovery approaches such as this one are regarded to be very flexible for identifying causal models in the general case because they don't require a third variable for conditioning. In specific scenarios such as multivariate time series, they can even improve the performance of traditional constraint-based approaches such as the Peter-Clark algorithm and others that utilize Granger causality [3].\nThe linear model with non-Gaussian noise can be estimated from (unconfounded) observational data by exploiting the inherent asymmetry between cause and effect"}, {"title": "2.2. Mutual Information as a Measure of Association", "content": "The amount of association between the regression residual RR and the hypothetical cause HC signals the causal direction. However, these variables are uncorrelated by construction of the regression. To properly quantify this dependence, the Mutual Information (MI) measure provides a reliable indicator, which is defined as\n$MI(RR,HC) = \\sum_{RR,HC} P_{RR,HC} log(\\frac{P_{RR,HC}}{P_{RR} P_{HC}})$\nwhere $P_{RR,HC}$ represents the (discrete) joint probability between RR and HC, and $P_{RR}$ and $P_{HC}$ represent their marginal distributions, respectively.\nFor illustrative purposes, the following variable dependencies are defined. First, a random Uniform noise sample U is independently assigned to Z, Xind and Yind. Then, the following structural variable associations are created: $Y_{dep} \\leftarrow X_{ind}+Z$, $X_{conf} \\leftarrow X_{ind}+Z$, and $Y_{conf} \\leftarrow Y_{ind} + Z$, which yield the subsequent relationships:\nCausal Between Xind and Ydep: X \u2192 Y\nAnticausal Between Ydep and Xind: Y \u2190 X\nIndependent Between Xind and Yind: X Y\nConfounded Between Xconf and Yconf: X \u2192 Y\nWhile the distribution of MI is a useful tool to visualize the different causal structures, there is still a missing criterion to make a classification decision in order to construct the underlying causal structure from the data. The next section addresses this point."}, {"title": "2.3. Pearson's x\u00b2 as an Unconditional Independence Test", "content": "In a real-word scenario, one cannot expect to get a null measure of association because of sampling noise, the sample size, etc. In this case, the use of an (unconditional) independence test is the proper way to handle this situation. In general, this is known as the REgression with Subsequent Independence Test (RESIT) procedure [9]. Once the independence test is in place, a confidence interval needs to be observed to obtain actionable results. To this end, Pearson's x2 test is here introduced as a fundamental method to inform the decision process [10].\nThe Pearson's x2 test is a statistical hypothesis test used in the analysis of contingency tables for categorical variables. It is used here to determine whether there is a statistically significant difference between the expected frequencies E for independence (i.e., the marginal probabilities) and the observed frequencies O in one or more categories i of the contingency table (RR,HC), formally defined as\n$\\chi^2(RR, HC) = \\sum_{i \\in (RR,HC)} \\frac{(O_i - E_i)^2}{E_i}$"}, {"title": "2.4. Total Information Coefficient as a Robust Independence Test", "content": "The Total Information Coefficient (TIC) is a robust independence test based on MI for real-valued variables that features the two important heuristic properties of generality and equitability [12], which are defined as follows:\nGenerality With sufficient sample size the statistic should capture a wide range of interesting associations, not limited to specific function types.\nEquitability The statistic should give similar scores to equally noisy relationships of different types.\nFor a pair of (RR, RC) variables, the TIC algorithm applies a search procedure to partition their joint probability function and find the grid with the highest induced MI. TIC operates by summing over optimal grids G on the joint density distribution of the two variables, such that it exhibits a stronger power against independence [11], formally expressed as\n$TIC(RR, HC) = \\sum_{G} \\frac{MI((RR, HC)|G)}{log || G ||}$"}, {"title": "3. Method", "content": "In the pursuit of a general approach to causal discovery combining several methods [8,14], one common point of success is found in the use of information-theoretic measures, such as Mutual Information, to quantify the amount of regularity in the data [15]. However, the nature of the variables, i.e., discrete or continuous, can be problematic in an heterogeneous context if the statistical methods are confused [14]. Moreover, supervised learning approaches are excluded from the general objective because these methods do not yet work as standalone techniques for causal learning [4]. Therefore, the desideratum in causal discovery is to have methods that work on a broad range of problems under different conditions with relaxed assumptions [16], ideally showing a certain degree of robustness regarding violations of the model hypothesis [17].\nIn this work we propose a general method to discover the causal structure in heterogeneous data based on a bivariate linear FCM by implementing a flexible RESIT procedure, see Section 2.3, where the unconditional independence test, e.g., x\u00b2 or TIC, also see Section 2.4, is driven by the nature of the variables involved. The proposed strategy is described with comments in Algorithm 1. Note that the orientation decision rules follow from the evidence given by the illustrative setting in Section 2.3, which is regarded as self-evident. Such explicitly-stated logic rules are meant to increase the interpretability and explainability of the proposed method. Also note that discrete variables are assimilated to real-valued variables for computing the regression residuals on which the RESIT method is based. Finally, since our contribution targets the problem of applying one single discovery technique on data with different types of variables, and we focus our effort at the integration level rather than at the fundamental level, we refer the interested reader to the references for the specific methods being integrated for further details about their comparison to other methods from the literature. We rely on the advice from Peters, Reshef, and colleagues [4,11], to select the best methods that we integrate in RESFIT in order to cover a broad range of techniques, and we provide an analysis on how these separate tools perform when they are put together."}, {"title": "4. Results", "content": "This section describes the reference benchmark dataset that was used to evaluate the introduction of the flexible independence test selection, the results that were obtained, and the tools for the implementation of the research."}, {"title": "4.1. Reference Benchmark Dataset", "content": "The \"ChaLearn cause-effect pair (SUP2)\" is taken for reference as the recommended benchmark dataset to evaluate the performance of pairwise causal discovery [6]. It comprises pairs of artificially generated dependent variables with different types (numerical, categorical and binary) for the full causal discovery task (orientation, independence and confounding). The dataset features a balanced number of unique values across all classes and includes around 6000 pairs. In terms of data type balance, the majority is comprised of numerical and mixed variable pairs. Finally, the average median length of an instance is around 2000 values."}, {"title": "4.2. Performance Scores", "content": "The accuracy classification score, i.e., the total rate of correct predictions statistically given by the overall amount of true positives and true negatives, is used in this research following the previous benchmark evaluation approaches [6], yielding a baseline around 65\u00b12% for the supervised learning setting [15]. To further assess the stability"}, {"title": "5. Discussion", "content": "This section delves into the finer details of the results that were obtained, and sheds light on the actual value introduced by the flexibility in selecting the unconditional independence test for causal discovery."}, {"title": "5.1. Average Causal Effect of the Flexible Test Selection", "content": "To properly quantify the impact of introducing the flexibility on the unconditional independence test, this section treats this selection action as a \"treatment\" variable X and studies its impact on the \u201coutcome\" discovery accuracy score Y. The Average Causal Effect (ACE) of X \u2192 Y is expressed using the following counterfactual notation\n$ACE=E[Y_1 - Y_0] = E[Y_1] - E[Y_0] = E[Y(X = 1)] \u2013 E[Y (X = 0)] =E[Y|X = 1] - E[Y|X = 0]$,\nwhere Yx refers to the value the Y accuracy result would have if X was set to x, i.e., Y(X = x). Here, X could take the values x = 1 to indicate flexibility of independence test, and x = 0 to indicate no preference (i.e., the null random choice). The conditionals that eventually follow are the values that are actually observed in the results. Note that all these expected quantities can be exactly calculated because the different experiments can be conducted on the same data (also dispelling any doubts about latent confounding). This setting is thus not subject to the fundamental problem of causal inference where only one of the potential outcomes can be observed [21].\nEquation (4) is shown to be an unbiased estimator for the ACE [22]. For computing the expectations in the causal effect comparison, a weighted mixture of Gaussian random variables is required. The quantity of the reference potential outcome E[Yo], where no smart selection occurs, is given by the arithmetic mean value of the total results, and it yields an accuracy score of 0.3531\u00b10.0357. Alternatively, the potential outcome E[Y1], where the smart flexible test selection is introduced, is given by the average of the best performance results among the different variable types, i.e., a sum weighted by their balance in the dataset, and it yields a value of 0.3866\u00b10.0690. Therefore, the ACE is of 3.36%, and this estimated difference is statistically significant. However, the absolute results are far from the 65% baseline, which suggests that the original supervised approach may have leaked statistical patterns beyond causation. Although the unsupervised learning approach does not seem to offer any pragmatic quantifiable advantage, we believe that its adoption is a must for tackling the inherently hard exploratory objective of causal discovery and avoid any qualms with regards to learned biases."}, {"title": "5.2. Limitations", "content": "The realization that TIC, which was conceived for numerical data, performed better on discrete data is surprising. Also, x2, which is defined for discrete data, performed better on numerical data. This counterintuitive behavior where theory and practice disagree may suggest that the independence tests that were used are subject to some inherent limitations such as the sample size. We regard the shortage of samples to be the main limitation of our approach on real-world data applications such as the Tuebingen dataset [23]. Finally, while the approach that we propose is able to welcome any testing technique, we selected RESIT flexibly paired with TIC and x2 following the advice of Peters, Reshef, and colleagues [4,11]. To the best of our knowledge, this limited choice should be sufficient to generally cover the spectrum of approaches."}, {"title": "6. Conclusion", "content": "Environments with heterogeneous data pose challenging questions to the discovery of causal structure, and leveraging one single method may lead to erroneous results in general. In this work, we propose an unsupervised pairwise approach using linear functional causal models and different unconditional independence tests based on Mutual Information measures, the selection of which is driven by the nature of data and the empirical results from a reference benchmark. The introduction of this independence test selection flexibility is estimated to have a positive and statistically significant average causal effect over 3% in accuracy. These scores may establish the first standard baseline for this kind of flexible focus, but more research is needed because the limitations of the data size and the statistical techniques can result in counterintuitive results."}]}