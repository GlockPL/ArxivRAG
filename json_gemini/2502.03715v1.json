{"title": "Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models", "authors": ["Rui Cai", "Chao Wang", "Qianyi Cai", "Dazhong Shen", "Hui Xiong"], "abstract": "Knowledge Graph-based recommendations have gained significant attention due to their ability to leverage rich semantic relationships. However, constructing and maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracy of KGs can suffer from noisy, outdated, or irrelevant triplets. Recent advancements in Large Language Models (LLMs) offer a promising way to improve the quality and relevance of KGs for recommendation tasks. Despite this, integrating LLMs into KG-based systems presents challenges, such as efficiently augmenting KGs, addressing hallucinations, and developing effective joint learning methods. In this paper, we propose the Confidence-aware KG-based Recommendation Framework with LLM Augmentation (CKG-LLMA), a novel framework that combines KGs and LLMs for recommendation task. The framework includes: (1) an LLM-based subgraph augmenter for enriching KGs with high-quality information, (2) a confidence-aware message propagation mechanism to filter noisy triplets, and (3) a dual-view contrastive learning method to integrate user-item interactions and KG data. Additionally, we employ a confidence-aware explanation generation process to guide LLMs in producing realistic explanations for recommendations. Finally, extensive experiments demonstrate the effectiveness of CKG-LLMA across multiple public datasets.", "sections": [{"title": "1 Introduction", "content": "Recommender systems [Wang et al., 2023; Wu et al., 2024] have become essential tools for content creation and personalization, especially in addressing the information overload issue. A promising approach within this domain is the integration of Knowledge Graphs (KGs) [Wang et al., 2019b; Yang et al., 2023; Wang et al., 2024], which utilize KG triplets as side information to enrich user/item representations by encoding additional item-wise semantic relationships. This method effectively mitigates the data sparsity problem commonly encountered in traditional recommender systems [He et al., 2020; Wu et al., 2021]. However, constructing and maintaining KGs is resource-intensive, requiring significant human and computational efforts. Moreover, ensuring the accuracy of the knowledge in KGs is fraught with challenges, such as the introduction of noise in the form of irrelevant or erroneous triplets [Wang et al., 2024], and the static nature of many KGs [Guo et al., 2020] limits the ability to revise the outdated relations. These limitations highlight the need for more adaptable and less labor-intensive methods to maintain the relevance and robustness of KGs in recommender systems.\nTraditional KG-based methods focus on extracting auxiliary content from KG for modeling user/item representations. For example, KGCN [Wang et al., 2019a] incorporates high-order entities' information in KGs, and KGAT [Wang et al., 2019b] applies attentive aggregation for user-item-entity joint graph. More recently, research has shifted towards addressing the inherent noise within KGs, acknowledging that not all entities and relations are equally reliable. For example, KGCL [Yang et al., 2022] performs contrastive learning to address noisy entities in KG, while KGRec [Yang et al., 2023] drops triplets with lower rationale scores before building contrastive objectives. However, these methods are constrained by their reliance solely on information provided by the KG itself, which may be inherently noisy, outdated, or incomplete. Fortunately, recent advancements [Wu et al., 2023] in Large Language Models (LLMs) have shown that LLMs demonstrate efficacy in refining KGs through eliminating spurious triplets and augmenting potential entity relationships [Zhang et al., 2024] by leveraging their sophisticated semantic comprehension capabilities and extensive knowledge repositories. Therefore, we aim to boost KG-based recommendations with LLM's assistance.\nNotwithstanding the potential of LLMs to enhance KG-based recommender systems, several critical challenges remain unaddressed. Primarily, the token limit constraints inherent in existing LLMs necessitate a robust prompting design to augment all triplets in the whole KG effectively and consistently. Secondly, the susceptibility of LLMs to hallucination phenomena [Agrawal et al., 2023] poses a significant risk of introducing erroneous triplets into original KGs. A robust confidence mechanism is essential to enhance the denoising process by accurately identifying potentially erro-"}, {"title": "2 Related Works", "content": "Related works can be divided into two main categories: KG-based recommendations and unifying KGs and LLMs."}, {"title": "2.1 KG-based Recommendations", "content": "Existing KG-based approaches can be roughly classified into three categories: embedding-based, path-based, and GNN-based methods. Embedding-based techniques, such as CKE [Zhang et al., 2016], enhance recommendation performance by integrating collaborative filtering with modeling of diverse item-related side information. Path-based approaches like KPRN [Wang et al., 2019c] employ LSTM [Graves and Graves, 2012] networks to model relational meta-paths from KGs. However, the fixed design of these meta-paths limit their scalability and general applicability. Currently, GNN-based methods are considered the forefront KG-based recommendation endeavors with remarkable efficiency. For example, KGAT [Wang et al., 2019b] employs graph attention networks [Veli\u010dkovi\u0107 et al., 2017] to prioritize neighbor aggregation based on their relative importance, while KGIN [Wang et al., 2021] enhances this approach by integrating user-specific relational embeddings into the aggregation process. Similarly, KGCL [Yang et al., 2022] introduces KG semantics to mitigate data noise in recommendation systems through knowledge-guided contrastive learning, utilizing KG-aware data augmentation to probe the influence of items on user modeling. KGRec [Yang et al., 2023] implements an knowledge rationalization mechanism that assesses triplets with rationale scores, subsequently integrating them into MAE-based [He et al., 2022] reconstruction learning and building contrastive objectives. However, these methods are limit in fixed KG, inhibiting their ability to capture and leverage the useful dynamic semantic information extracted by LLMs."}, {"title": "2.2 Unifying KGs and LLMs", "content": "The integration of LLMs and KGs can be categorized into three primary approaches: KG-enhanced LLMs, LLM-augmented KGs, and synergistic combinations. KG-enhanced LLMs, exemplified by Think-on-graph [Sun et al., 2023], utilize KGs to guide LLMs in producing reasoned outputs. Conversely, LLM-augmented KGs leverage LLMs' knowledge editing capabilities to enhance KG performance in downstream tasks, as demonstrated by MPIKGC [Xu et al., 2024] which query LLMs to enriches context in knowledge graph completion task. Synergistic approaches, such as GreaseLM [Chen et al., 2023], aim to create frameworks where LLMs and KGs mutually enhance each other's capabilities. In the recommendation domain, methods like LKPNR [Runfeng et al., 2023] exploit LLMs' text processing abilities to improve content personalization. On the contrary, we propose to integrate LLMs and KGs bidirectionally, using LLMs to augment KG-based recommenders while leveraging the enriched KGs to guide LLMs in generating explanations."}, {"title": "3 Methodology", "content": "We present the overall architecture of CKG-LLMA in Figure 1. Details are discussed in following sub-sections."}, {"title": "3.1 Definition and Overview", "content": "We first introduce the notions and definitions used throughout this paper, and and formally defining the LLM-enhanced KG-based recommendation task.\nUser-Item Interaction Graph (IG) In the typical recommendation scenario, there is a user set U and an item set I. A bipartite graph $Y \\in |U| \\times |I|$ is used to represent the collaborative signals among users and items, denoted as $Y = {\\langle u, Y_{ui}, i \\rangle | u \\in U, i \\in I}$, where $Y_{ui} = 1$ indicates an observed interaction of user u over item i, and vise versa.\nTripartite Relational Knowledge Graph (TKG) We define the concept of TKG as a heterogeneous graph contains 3 kinds of triplets.\n\u2022 UI triplets User behaviors are triplets (u, interact, i) to represent the corresponding signal $Y_{ui=1}$ for user u and item i in IG, which denoted as $G_{UI} = {\\langle u, interact, i \\rangle | \\langle u, 1, i \\rangle \\in Y}$.\n\u2022 IA triplets Item knowledge are side information for items (e.g., item attributes or external knowledge), and we denote IA triplets (e.g., (apple, has category, fruit)) records such triplet facts between item set I and entity set A as $G_{IA} = {\\langle i,r,a \\rangle | i \\in I, r \\in R_{IA}, a \\in A}$.\n\u2022 II triplets Item correlations are auxiliary triplets that capture the shared relationships with entities between items. For instance, apple and banana both have category fruit, so there exists a triplet (apple, same category, banana) in II triplets. We define the set of item correlations as $G_{II} = {\\langle i,r', j \\rangle | r' \\in R_{II}, i, j \\in I}$."}, {"title": "3.2 LLM-based Subgraph Augmenter", "content": "Manual knowledge graphs often have inaccuracies due to outdated or incorrect relationships, impacting recommendations. To enhance the quality of knowledge graphs, we propose to refine and augment the extracted knowledge subgraphs with the goal of knowledge completion by LLMs.\nSubgraph Extraction and Prompt\nDue to token limitations of LLMs, it is impractical to enhance using information from the entire graph. Instead, we utilize subgraph-based enhancements with LLMs. For N collaborative singals $y_{sub} = {\\langle U_k,Y_{U_k i_k}=1, i_k \\rangle}_{k=1}^N$, we extract all related triplets $G_{sub}$ in all three background KG $G_{IA}$, $G_{II}$, and $G_{UI}$, denoted as $G_{sub} = G_{UI}^{sub} \\cup G_{II}^{sub} \\cup G_{IA}^{sub}$.\nPast work [Wei et al., 2024] demonstrates that LLMs process item side information as explicit knowledge, employing fact verification for triple augmentation. Conversely, LLMs treat user behaviors as implicit knowledge, augmenting these triples through reasoning. Based on this phenomenon, we design 2 kinds of extraction logic (User-view and item-view) with unique prompts to guide LLM in enhancing KG from a multi-view perspective.\n\u2022 User-view Extraction The subgraph, denoted as $G_{sub}^{UI}$, consists of $G_{UI}^{sub}$ and $G_{IA}^{sub}$. With an user-based prompt, we want LLM focuses on both rectifying explicit item-attribute triplets through fact verification, and pruning user-item interaction through implicit reasoning.\n\u2022 Item-view Extraction The subgraph, denoted as $G_{sub}^{I}$, consists of $G_{IA}^{sub}$ and auxiliary triplets $G_{II}^{sub}$. With an item-based prompt, we want LLM focuses on rectifying the item-attribute triplets with explicit knowledge and auxiliary triplets of item correlations.\nLLM Augmentation ($P_{add}^{UI}$, $P_{del}^{UI}$, $P_{add}^{I}$, $P_{del}^{I}$)\nOur prompt design leverages the LLM's ability to detect contextual nuances in diverse subgraph patterns and provide modification advice enriched with domain-specific information. We transform the ID-based triplets into textual information for LLM understanding using prompts. In user-view prompting, we expect LLM to rectify $G_{UI}^{sub}$ and $G_{IA}^{sub}$ with addition and deletion, and prune $G_{UI}^{sub}$ to $G_{UI}^{sub}$ with deletion. The add and delete triplets are saved as two pools, denoted as $P_{add}^{UI}$ and $P_{del}^{UI}$, while $P_{del}^{UUI} = P_{del}^{UI} \\cup P_{del}^{UIA}$ involves 2 sets representing the fact verification and reasoning results. In item-view prompting, we expect LLM to thoroughly rectify $G_{IA}^{sub}$ and $G_{II}^{sub}$ and respectively save two pools of modificationa as $P_{add}^{I}$ and $P_{del}^{I}$. Details can be found at Appendix."}, {"title": "3.3 Confidence-aware MOE Message Propogation", "content": "Due to the existance of hallucination problems in LLM, erroneous generated triplets in pools $P_{add}^{UI}$ and $P_{add}^{I}$ could bring meaningless links in origin G as new noise. To reduce such potential disturbances and effectively aggregate knowledge within KG structures, we introduce a learnable edge confidence for each item-attribute triplet, considering the relation heterogeneity. This approach assigns a confidence score for LLM-enhanced edges, significantly boosting their robustness in handling diverse relational data.\nTo enhance the correlations between attributes and items and better incorporate with LLM introduced information, inspired by GAT [Veli\u010dkovi\u0107 et al., 2017], we initially apply an aggregation layer on items of G, where the updated item embedding $x_i'$ is computed as:\n$x_i' = x_i + \\sum_{k=1}^{N_i} \\alpha_{ik} x_{ak}, \\alpha_{ik} = \\frac{exp(o(a^{\\top} [W_1 x_i || W_1 x_{ak}]))}{\\sum_{j \\in N_i} exp(o(a^{\\top} [W_1 x_i || W_1 x_{aj}]))}$   (1)\nwhere $W_1 \\in \\mathbb{R}^{d \\times d}$, $a_1 \\in \\mathbb{R}^{d}$ are attention weights in each layer and o is the LeakyReLU activation function.\nThen we introduce LLM generated triplets to G with an designed confidence algorithm. Firstly, to reflect the contribution of each triplet for user preference, a confidence weighting function $\\varphi(\\cdot)$ is implemented with a designed confidence-aware mixture of experts [Shazeer et al., 2017] layer $\\xi(\\cdot)$. Specifically, for triplet t = (i, r, a), its confidence is:\n$\\varphi(i, r, a) = g(x_r, W [x_i || x_a])$,  (2)\nwhere $x_i$, $x_r$ and $x_a \\in \\mathbb{R}^{d}$ are the embedding of i, r and a. $W \\in \\mathbb{R}^{d \\times 2d}$ is a learnable transition matrix. $\\xi(\\cdot)$ contains a set of feed-forward neural networks {$E_i(x)$}$_{i=1}^{N_e}$ of $N_e$ experts. In order to capture the fine-grained information behind KG triplets, $\\xi(\\cdot)$ first computes the gate value of each expert i based on entity features $f_t = W [x_i || x_a]$ of t as:\n$w_i = \\frac{e_i^{W_r^{\\top} f_t}}{\\sum_{j=1}^{N_e} e_j^{W_r^{\\top} f_t}}$,  (3)\nthen the output computation of $\\xi$ is the linearly weighted combination of each expert's computation as:\n$\\xi(x_r, f_t) = \\sum_{i=1}^{N_e} w_i x E_i(f_t)$,  (4)\nwhere we use linear layers for each expert E here. We further calculate each triplet's confidence with renewed embeddings $x_i'$ in equation 2. After obtaining the confidence $\\varphi(t)$ for each triplet t = (i, r, a) \\in G, we aggregate the confidence-aware attribute embeddings to generate final aggregated item representations $x_i''$ as:\n$x_i'' = x_i' + \\sum_{k=1}^{N_i} \\frac{exp(\\sigma(\\varphi(i, r, a))))}{\\sum_{j=1}^{N_i} exp(\\sigma(\\varphi(i, r_j, a_j))))} x_{ak}$  (5)"}, {"title": "3.4 Dual-view Two-step Contrastive Learning", "content": "While aggregating side information to enhance item representations, in order to learn more essential aspects (e.g., extracting useful information for the recommendation task from the KGs and reducing the impact of noise data in the KGs) in user preferences modeling from the KG refined by large language models, we construct a dual-view contrastive learning framework, as the inherent connections between external elements can be utilized to direct data augmentation through cross-view self-supervised signals. We first adopt a differentiable KG augmentation strategy, then enhance IG from a \"View-and-Stability\" perspective.\nStep1: Differentiable Knowledge Graph Augmentation\nTo incorporate the LLM-generated information (User-view & Item-view) into origin G, we first randomly sample triplets from $P_{add}^{UI}$ and $P_{add}^{I}$ at a ratio of $\\mu_{\\alpha}$ relative to the number of triplets in G, and similarily sample triplets from $P_{del}^{UI}$ and $P_{del}^{I}$ in a ratio $\\mu_{\\alpha}$ to form 4 sets as:\n$M_{add}^{UI} = {m_{add}^{UI}}^{N_{add}^{UI}}_{i=1}, M_{del}^{UI} = {m_{del}^{UI}}^{N_{del}^{UI}}_{i=1}, M_{add}^{I} = {m_{add}^{I}}^{N_{add}^{I}}_{i=1}, M_{del}^{I} = {m_{del}^{I}}^{N_{del}^{I}}_{i=1}$,  (6)\nDuring the knowledge aggregation process, we only consider combining information from IA triplets $G_{IA}$ as this is the main modified part in KG augmentation. We incorporate above sampled triples into G and build two different KGs $G_U$ and $G_I$ from two views as initially augmented graphs, i.e.,\n$G_U = G \\cup M_{add}^{UI} \\backslash M_{del}^{UI}, G_I = G \\cup M_{add}^{I} \\backslash M_{del}^{I}$. (7)\nTo reduce potential noise within the origin G and brought by LLM generated information, we apply the confidence for each triplet in graphs to drop links by learnable probabilities. Specifically, we calculate the confidence of each triplet t = (i,r,a) in $G_U$ and $G_I$ as $\\phi(t)$ with Equation 2. We then transform the confidence $\\phi(t)$ into a selection probability P(t) using function P(\u00b7) as :\n$P(t) = Sigmoid(\\phi(t) * K)$, (8)\nwhere K is a scalable hyper-parameter to control the probability. This is the kept probability P(t) for each triplet t after the information incorporation of KG and LLM. Following [Jang et al., 2016], gumbel softmax strategy is used to approximate the discrete sampling with differential consistency, allowing gradient propagation in this augmentation process. With sampling decision $d_t$, we gather all decisions in two graphs $G_U$ and $G_I$ to renew two graphs by an operator $\\psi(\\cdot)$: \n$\\psi(G_U) = G_U \\copyright D_U, \\psi(G_I) = G_I \\copyright D_I$,   (9)\nwhere $D_U = {d_t| t \\in G_U}$ and $D_I = {d_t| t \\in G_I}$ are the sets of selection decisions for triples in augmented KGs.\nStep2: IG Enhancement via View-and-Stability\nTo fully exploit the LLM-enhanced information, we augment the interaction graph combining views and a designed item stability. After the knowledge graph augmentation procedure, we derive $\\psi(G_U)$ and $\\psi(G_I)$ as view-specific augmented KGs and consolidate the graphs with item embeddings through Equations 1 and 5 and obtain view-specific item representations $x_i^U$ and $x_i^I$. Similar as [Yang et al., 2022], to explore the invariance property of item representations in different augmented views, we define the cross-view stability $s_i$ of item i between the representations aggregated from knowledge of distinctive views though cosine similarity function $C(\\cdot)$ of embeddings as:\n$s_i = C(x_i^U, x_i^I)$. (10)\nThe cross-view stability score $s_i$ serves as an indicator of an item's resilience to changes in topological information. Items with higher $s_i$ values demonstrate less sensitivity to such changes. The stability indicator provides a way to mitigate the negative effects of both knowledge graph dependencies and noise in IG Y by incorporating auxiliary self-supervised signals, thereby guiding the IG augmentation. Specifically, we tend to drop item nodes in Y with lower stability, so we"}, {"title": "3.5 Model Optimization", "content": "For the main recommendation task, we use the dot product between user & item representations as the prediction, which is denoted as $\\hat{Y}_{ui} = x_u^{\\top} x_i$. To optimize the model parameters, we adopt Bayesian Personalized Ranking loss to optimize thhe model parameters as follows:\n$L_{bpr} = \\sum_{(u,i,j) \\in D} -log \\sigma (\\hat{Y}_{ui} - \\hat{Y}_{uj})$,  (13)\nWe construct the training instances $D = {(u,i,j)}$, where $(u, 1, i) \\in Y$ is the ground-truth and $(u,0,j) \\in Y$ is a randomly sampled negative interaction. To optimize all loss functions, we use a joint learning approach with the following overall loss function:\n$L = L_{bpr} + \\lambda_c * L_{con} + \\lambda_o * ||\\Theta||^2$,  (14)\nwhere $\\lambda_c$ and $\\lambda_o$ are loss weight parameters and $\\Theta$ represents the learnable model parameters."}, {"title": "3.6 Confidence-aware Explanation Generation", "content": "With the trained predictive function F to forecast user-item interactions, we turn to construct an explanation generation module elucidating user behaviors. Specifically, we first combine two add pools $P_{add}^{UI} \\cup P_{add}^{I}$ and filter out triplets less than a threshold $\\mu$ to construct an unified augmented KG as $G_{aug}$. Then for user u \u2208 U and any interacted item i \u2208 I, we aim to generate a natural language sentence to justify why i is recommended to u. We design a two-step chain-of-thought [Wei et al., 2022] reasoning procedure to instruct LLM for this explanation generation task:\nKG Information Extraction We first extract domain-specific information for user u and item i from the TKG G: a) UI triples: We extract all interactions between user u and its interacted items $Z_u = {j|(u,1,j) \\in Y}$ to form $G_{UI}' = {\\langle u, interact,j \\rangle | j \\in Z_u}$. b) II triples: We find all items in $Z_u$ that contain a relation with target item i to form $G_{II}' = {\\langle j, r, i \\rangle | \\langle j, r, i \\rangle \\in G, j \\in I_u, r \\in R_{II}}$. c) We search an attribute a \u2208 A from $G_{IA}$ that associated to each item-item triplet in $G_{II}'$, then connect this attribute to the items in each triplet to form $G_{IA}'$. Eventually, we regard each triplet (h, r, t) as a reason flow from h to t, then identify and filter all triplet paths $P_R$ that could reason from u to i within $G_{UI}'$ and $G_{II}'$.\nPath Analysis and Confidence-based Reasoning To guide LLM in selecting the most suitable path p from $P_R$, we calculate the confidence score of each triplet in $G_{IA}'$ to form a confidence set $C_{IA}$. Confidence scores actually represent the global users' behaviors in the dataset domain, which provides LLM with a general user preference of u. To enrich user-specific information, we then randomly select items in $Z_u$ excluded from the items selected in reason paths $P_R$ and add interactions of user u and these selected items into $G_{VI}$. We finally combine information from $P_R$, $C_{IA}$ and $G_{VI}$ to prompt LLM to determine the most plausible reasoning path and generate an explanation. Details are shown at Appendix."}, {"title": "4 Experiments", "content": "Here, we conduct extensive experiments to evaluate our CKG-LLMA model comparing with various baselines."}, {"title": "4.3 Ablation Study", "content": "In the ablation study, we assess the individual contributions of CKG-LLMA with the following variants. The results are shown in table 3.\nw/o Confidence: We disable the confidence-based dropout process in knowledge graph augmentation. The observed significant performance degradation underscores the efficacy of the confidence-aware differentiable KG augmentation in capturing valuable semantics generated by LLM to enhance the KG structural information.\nw/o Contrastive Loss: We nullified the contrastive loss by setting its weight $\\lambda_c$ to zero, training the model solely on lbpr without LLM-enhanced information or the confidence-aware denoising mechanism. The resultant performance degradation indicates that user/item representations become contaminated with KG noise in the absence of contrastive learning, significantly impacting model efficacy.\nDifferent Proportions of LLM: To assess the quality of LLM-generated information, we randomly sampled triplets from $P_{add}^{UI}$, $P_{del}^{UI}$, $P_{add}^{I}$, $P_{del}^{I}$ at ratios of 20%, 40%, 60%, and 80%. We then evaluated our model's performance using these subsets, maintaining consistent add ratio and delete ratio with the 100% baseline. The observed positive correlation between performance metrics and sampling ratios suggests that the LLM-based Subgraph Augmenter effectively identifies latent entity relationships within KG, thereby enriches auxiliary information and enhances user modeling."}, {"title": "4.4 Parameter Analysis", "content": "We analyze our model's sensitivity to the following parameters: Delete ratio $\\mu_{\\alpha}$ and Add ratio $\\mu_{\\alpha}$. The results are presented in Figure 2. We varied the add ratio from 0% to 100% across two datasets while fixing $\\mu_{\\alpha}$ at 4% for AmazonBook and 8% for Steam. The results show that CKG-LLMA achieves best performance at $\\mu_{\\alpha}$ = 60% for the AmazonBook dataset and $\\mu_{\\alpha}$ = 70% for the Steam dataset. As"}, {"title": "4.5 Case Study in Explanation Generation", "content": "Here we present case to show the explainable power of our model. We select a positive pair from the testset of Steam dataset, (user8614, game4705), where the corresponding triplet (user8614, interacted, game4705) is not in augmented $G_{aug}$. Details are shown in table 4. We first collect all items which has been interacted with user8614, and filter out the rest items (game2949, game1858, game7489) which has an item-item relationship with target item game4705. We construct the candidate paths based on the 3 items, and calculate confidence scores of triplets in each path (eg. Confidence of (game2949, has spec, Single Player) is 2.132). We then query LLM with a prompt combining interacted items of user8614, candidate paths and associated confidences scores and derive the user-review alike explanation. The result indicates that Confidence scores enable LLM to better understand path relevance to user preferences, while without them, LLM resort to random path selection."}, {"title": "5 Conclusion", "content": "In this paper, we introduced the Confidence-aware KG-based Recommendation Framework with LLM Augmentation (CKG-LLMA), which effectively integrates Large Language Models (LLMs) with Knowledge Graphs (KGs) to enhance recommendations. Our framework introduces an LLM-based subgraph augmenter for enriching KGs, implements a confidence-aware mechanism for filtering noise, and employs a dual-view contrastive learning schema to enhance user-item representations. Experiments show that CKG-LLMA outperforms existing methods and generates high-quality, interpretable recommendations."}, {"title": "6 Appendix", "content": "6.1 Prompt Details\nPrompts in LLM-based Subgraph Augmenter\nThe designed prompts for augmenting subgraphs in two views are shown in figure 3. The differences between prompts of two views are mainly the provided information, the constitution of triples and the designed tasks, in which User-view prompt instructs LLM to rectify I-A triplets through fact verification, and prune the provided user-item interactions through reasoning; Item-view prompt directs LLM to meticulously rectify I-A triplets and utilizes auxiliary information from I-I triplets to enhance the rectification process.\nPipeline and Prompt in Confidence-aware Explanation Generation\nThe overall pipeline of the explanation generation module and the designed prompt template are shown in figure 4. For certain user-item interaction pair (u, i), the module initially retrieves interacted items of user u to search for relevant U-I triplets. Then we identify items with an item-item relationship to target item i and derive all corresponding I-I triplets. In the next step, find the co-occupied attribute in each I-I triplet and obtain two item-entity triplets based on this attribute. We then categorizes collected triplets into distinct reason paths, and explicates each component and the structure of these paths in the prompt. Eventually, we fill the prompt template with collected information to instruct LLM to generate an review-alike explanation from user u to item i.\nThe reasoning process follows a structured chain-of-thought approach to ensure a coherent and interpretable explanation. To achieve this, we apply the following step-by-step approach based on [Wei et al., 2022]:\n\u2022 1. Understand User Preferences:Analyze user u's past interactions and extract relevant patterns from U-I triples, providing an overview of the user's previous choices.\n\u2022 2. Identify Item Similarities: Examine I-I triples to find connections between item i and previously interacted items, emphasizing the contextual relevance.\n\u2022 3. Attribute-Based Justification: Leverage I-A triples to recognize shared features (e.g., genre, category, style) that make item i appealing to user u.\n\u2022 4. Evaluate Confidence Scores: Prioritize highly confident paths and reinforce strong recommendation rationales by assigning reliability scores to I-A triples.\n\u2022 5. Generate a Colloquial Explanation: Construct a natural, engaging, and intuitive review of item i for user u without explicitly listing the provided data, ensuring that the explanation remains user-friendly and comprehensible.\nBy following these structured reasoning steps, the LLM is guided to generate coherent, persuasive, and contextually relevant explanations that align with user preferences and in"}, {"title": "6.2 Hyperparameter Configuration", "content": "The hyperparameter setting of CKG-LLMA in dataset AmazonBook is shown at table 5."}, {"title": "7 Model Complexity Analysis", "content": "CKG-LLMA maintains comparable parameter and time complexity to SOTA models like LLM-based [Ren et al., 2024], KG-based [Yang et al., 2022] works. Regarding model complexity(W1), the learnable parameters include user, item, and attribute embeddings, with a complexity of O((|U| + |I| + |A|) \u00b7 d), plus a confidence-aware aggregation with O(2d\u00b2). Notably, Our model maintains comparable parameter complexity with KGCL, while being more efficient than KGRec through fewer modules and loss functions, and achieves better parameter efficiency than alignment-based LLMRec and RLMRec. Time complexity scales linearly with the number of user-item interactions and KG triplets in dataset, consisting these components: (1)Confidence-aware propagation with O(|GIA|\u00b7|R|\u00b7d) for confidence computation and O(|GIA|\u00b7d) for aggregation. (2)Differentiable KG augmentation with O(GIA|(|R|\u00b7d + 1)). (3)Contrastive learning with LightGCN O(|G_UI + G_I| \u00b7 d) and con-loss O(B \u00b7 (|U| + |I|) \u00b7 d)."}, {"title": "8 Experimental Cost", "content": "The cost is low as we only uses LLMs during preprocessing. For example, the CHATGPT API costs just 27usd on AmazonBook and 68usd on Steam, as CKG-LLMA performs subgraph augmentation offline, with no LLM inference during training. While we used GPT-3.5-turbo for its performance and affordability, CKG-LLMA can also use open-source LLMs."}]}