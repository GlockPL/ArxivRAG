{"title": "Relational Neurosymbolic Markov Models", "authors": ["Lennert De Smet", "Gabriele Venturato", "Luc De Raedt", "Giuseppe Marra"], "abstract": "Sequential problems are ubiquitous in AI, such as in reinforcement learning or natural language processing. State-of-the-art deep sequential models, like transformers, excel in these settings but fail to guarantee the satisfaction of constraints necessary for trustworthy deployment. In contrast, neurosymbolic AI (NeSy) provides a sound formalism to enforce constraints in deep probabilistic models but scales exponentially on sequential problems. To overcome these limitations, we introduce relational neurosymbolic Markov models (NeSy-MMs), a new class of end-to-end differentiable sequential models that integrate and provably satisfy relational logical constraints. We propose a strategy for inference and learning that scales on sequential settings, and that combines approximate Bayesian inference, automated reasoning, and gradient estimation. Our experiments show that NeSy-MMs can solve problems beyond the current state-of-the-art in neurosymbolic AI and still provide strong guarantees with respect to desired properties. Moreover, we show that our models are more interpretable and that constraints can be adapted at test time to out-of-distribution scenarios.", "sections": [{"title": "Introduction", "content": "Markov models are the theoretical foundation for many successful applications of artificial intelligence, such as speech recognition (Juang and Rabiner 1991), meteorological predictions (Khiatani and Ghose 2017), games (Schrittwieser et al. 2020), music generation (Austin et al. 2021), sports analytics (Van Roy et al. 2023) and many more (Mor, Garhwal, and Kumar 2020). They are so popular mainly because they naturally factorise a sequential problem into step-wise probability distributions. Such a decomposition leads to better predictions in terms of bias and variance compared to models that do not incorporate the sequential nature of the problem (Bishop 2006).\nNeurosymbolic AI (NeSy) has also enjoyed a tremendous increase in attention. Its general goal is to combine the generalisation potential of symbolic, i.e. logical, reasoning with the representational learning prowess of neural networks. This integration leads to interpretable models that can provably satisfy logical constraints. For example, to guarantee the safety of an autonomous agent (Yang et al. 2023), to constrain autoregressive language generation (Zhang et al. 2023) or to impose physical modelling into temporal forecasting (Reichstein et al. 2019).\nSuch a combination already exists in many different flavours, using either fuzzy logic (Badreddine et al. 2022) or probabilistic logic (Manhaeve et al. 2021; Yang, Ishay, and Lee 2020; Huang et al. 2021; De Smet et al. 2023), and either propositional or relational logic (Marra et al. 2024). The probabilistic case is of special interest, as probabilistic NeSy systems provide a sound semantics to handle uncertainty, as well as to tackle generative tasks. The relational case is also of special interest as relational logic is a popular and very expressive representation for representing states in, for instance, databases and planning (Russell and Norvig 2020). Moreover, relational representations facilitate strong generalisation behaviour (Hummel and Holyoak 2003). Unfortunately, existing probabilistic or relational NeSy models can not exploit the sequential decomposition inherent to temporal reasoning tasks, thereby limiting their applicability in complex sequential problems. Therefore, there are still no inference algorithms for such NeSy models that are tailored to scale in sequential settings.\nIn order to overcome these limitations, we identify four desiderata that a model and its inference algorithm should satisfy. (D.I) It must be able to model and exploit relational logical constraints on states and transition functions. It should use relational states as in planning, and ideally it can cope with both continuous and discrete aspects of reality. (D.II) It has to exploit sequential dependencies without restricting the modelling power, allowing it to scale further than existing NeSy systems. (D.III) It must be properly neurosymbolic, that is, it must support transition functions that are logical, neural or purely probabilistic in nature, or any combination thereof. Moreover, it must be end-to-end differentiable to allow for the optimisation of any neural components of the model. (D.IV) It can tackle both discriminative and generative tasks in a probabilistic fashion.\nBoth existing probabilistic techniques and neurosymbolic AI are insufficient. On the neurosymbolic side, scalability (D.II) remains the biggest problem, and generative capabilities (D.IV) are also lacking. Purely exact techniques (Manhaeve et al. 2021; Yang, Ishay, and Lee 2020) do not scale to non-trivial time horizons, while approximate"}, {"title": "Preliminaries", "content": "Hidden Markov models (HMMs) are sequential probabilistic models for discrete-time Markov processes (Baum and Petrie 1966). Given sequences of states $X = (X_t)_{t \\in \\mathbb{N}}$ and observations $Z = (Z_t)_{t \\in \\mathbb{N}}$, an HMM factorises the joint probability distribution $p(X, Z)$ as,\n$p(Xo)p(Zo | Xo) \\prod_{t \\in \\mathbb{N}} P(X_{t+1} | X_t)p(Z_{t+1} | X_{t+1})$,                                  (1)\nwhere $X_t$ is a fully latent state (Figure 1a). If $X_t$ has a known factorisation in the form of a Bayesian network (BN) (Pearl 1988), then the process and its observations encode a Markovian dynamic Bayesian network (DBN) (Dean and Kanazawa 1989). Note that $X_t$ and $Z_t$ are random vectors that can have both discrete and continuous components. In all that follows, a specific assignment of a random variable or vector will be written in lowercase. For example, $X_t = (x_{t,1},..., x_{t,D})$ is an assignment of the random vector $X_t = (X_{t,1},..., X_{t,D})$ of dimension D."}, {"title": "Probabilistic Neurosymbolic AI", "content": "Probabilistic NeSy methods originate from the field of statistical relational AI (StarAI) that integrates statistical AI with logic (De Raedt et al. 2016; Marra et al. 2024). This integration leads to systems capable of performing inference and learning with uncertainty over symbolic, i.e. logical, knowledge. For example, the logical relations player_at(player1, locationl) and monster_at(monster1, locationl) can be used to apply the rule hit(P,M) :- player_at(P,L), monster_at(M,L) and deduce that player1 is hit by monster1 because they are in the same location. Moreover, this knowledge is often uncertain in practice, resulting in uncertainty on whether the deduced logical relations hold. For example, consider the case of a sneaky monster. If we are unsure whether monster_at(monster1, location1) is true or not, we will also be uncertain whether the player is hit or not. Notice that uncertain logical relations can be modelled as binary random variables, which justifies the integration with statistics.\nWhile StarAI assumes knowledge to be neatly represented as a symbolic state $S$, such an assumption does not always hold. Images, sound waves or natural language are usually represented as subsymbolic data, i.e. tensors, that are not directly usable by relational AI. Therefore, probabilistic NeSy methods use neural predicates to map subsymbolic data to a probability distribution over symbolic representations that can be used by StarAI. Figure 1b depicts a probabilistic graphical model (PGM) (Koller and Friedman 2009) representation of a NeSy system. More formally, given a boolean variable Y from S with domain {y, \u00acy} and a set of rules R on the symbols in S, inference in NeSy computes the probability that the query Y is true via weighted model integration (WMI) (Morettin et al. 2021)\n$P(y | n) = \\int 1_{s \\models R}y P_Y(s | n) ds$,                                                     (2)\nwhere the distribution of S is parametrised by a neural network from the subsymbolic state n.\nA prominent way of representing neurosymbolic models is via probabilistic logic programming (PLP) (De Raedt, Kimmig, and Toivonen 2007). A running example will illustrate the main concepts, while a more technical exposition is given in Appendix A."}, {"title": "Relational Neurosymbolic Markov Models", "content": "Relational neurosymbolic Markov models (NeSy-MMs) combine the sequential and partially observable nature of HMMs and DBNs (Figure 1a) with neurally parametrised relational probability distributions (Figure 1b). That is, we consider Markov processes $X = (X_t)_{t \\in \\mathbb{N}}$ with observations $Z = (Z_t)_{t \\in \\mathbb{N}}$ where the state $X_t$ is now a neurosymbolic state $X_t = (N_t, S_t)$. Figure 1c depicts the graphical model of this novel integration. NeSy-MMs represent joint probability distributions $p (N, S, Z)$ that factorise as\n$p_Y(So | No)p(No)p(Zo | So) \\prod_{t \\in \\mathbb{N}} [P(S_{t+1} | S_t, N_{t+1})p(N_{t+1})p(Z_{t+1} | S_{t+1})$.                      (3)\nDespite the similarity with Eq. 1, NeSy-MMs are complex models that define a wide variety of distributions, taking into account our four desiderate of interest (D.I) - (D.IV).\nNeSy-MMs explicitly model symbols and their relations. Having a NeSy state means we perform inference in a symbolic state space where relational logic rules R govern the relationship between symbols, both within a single time slice and in the transition between states. This relational symbolic space allows NeSy-MMs to incorporate human knowledge into our reasoning process, giving guarantees on how the sequential process evolves, e.g. we can guarantee safety properties throughout the entire sequence (see Example 3.1). Additionally, the relational aspect significantly enhanced the out-of-distribution generalisation potential (Section 5).\nNeSy-MMs factorise symbols over sequences. Standard NeSy systems (Figure 1b) must model the full joint distribution over time, i.e. $p(S) = p(S_1, . . ., S_t)$. In contrast, we can factorise the distribution thanks to the Markovian neurosymbolic transition function $p_Y(S_{t+1} | S_t, N_{t+1})$, allowing for the definition of probabilistic temporal relations between symbols. Moreover, such a factorisation dramatically simplifies the symbolic space by exploiting the sequential dependencies that standard NeSy systems ignore.\nNeSy-MMs integrate neural and logical parametrisations. The symbols of a NeSy-MM and their transitions need not be purely logical and can be parametrised by neural networks. This flexibility in parametrisation not only bridges the gap between subsymbols and symbols, but also allows for neural networks to fill in gaps in background knowledge. For example, when faced with learning the behaviour of another entity in a game while being constrained by the rules of the game (Section 5.2). In essence, NeSy-MMs place symbols and logic where knowledge is available, while using neural nets to parametrise symbols and structure where necessary.\nNeSy-MMs express discriminative and generative neurosymbolic models. When given a target variable Y, which can be any of the symbols in S or a logical derivation thereof, a NeSy-MM can answer conditional discriminative NeSy queries of the form $p(y | n, z)$ via\n$P\u03c6 (So | no, Zo) \\prod_{t \\in \\mathbb{N}} [Py (St+1 | St, nt+1, Zt+1) ds$.                              (4)\nAlternatively, we can assume a generative perspective by defining the neural parametrisation of our model with a generative model (Goodfellow et al. 2020; Dinh, Sohl-Dickstein, and Bengio 2016; Ho, Jain, and Abbeel 2020), i.e. the inverted og edges in Figure 1c. This perspective leads to the factorisation\n$P\u03c6 (so, No | Zo) \\prod_{t \\in \\mathbb{N}} [Py(St+1, Nt+1 | St, Zt+1) ds$,                             (5)\nof $p (N | z)$. That is, NeSy-MMs can tackle generative tasks where samples n from $p(N | z)$ that satisfy the possibly logical evidence z are asked. We showcase this functionality in Section 5.3, where we use a VAE (Kingma and Welling 2013) to generate sequences of images of a game that adhere to the rules of the game."}, {"title": "Inference and Learning", "content": "To bridge the gap between NeSy and sequential probabilistic models, we propose a new, differentiable inference technique that combines non-parametric approximate Bayesian inference with exact NeSy inference. In the following sections, we will distinguish between random variables with finite and infinite domains. The latter includes both countably infinite and continuous (uncountable) domains."}, {"title": "Differentiable NeSy-MM Particle Filtering", "content": "Traditional particle filters are not differentiable because they perform resampling (Appendix B). Resampling is needed because the observations $Z_t$ are separated from the transitions $P(X_{t+1} | X_t)$, which means the conditional distribution $(X_{t+1} | X_t, Z_{t+1})$ is not readily available. The current state-of-the-art solution is to recover the differentiability of resampling (\u015acibior, Masrani, and Wood 2021; Corenflos et al. 2021; Younis and Sudderth 2023). On the contrary, we propose a novel solution that takes advantage of the neurosymbolic nature of a NeSy-MM. In particular, we circumvent the problem of differentiating through resampling by using a Rao-Blackwellised particle filter (RBPF) (Murphy and Russell 2001). A RBPF assumes $p_Y (X_{t+1} | X_t, Z_{t+1})$ can be computed exactly and uses it to recursively compute $P(X_{t+1} | Z_{0:t+1})$ as\n$\\int P(X_{t+1} | xt, Z_{t+1})P(xt | Z_{0:t}) dxt$.                               (6)\nWe claim it is viable to compute $p_Y (X_{t+1} | X_t, Z_{t+1})$ in our NeSy setting because, when $X_t$ is purely discrete, computing these probabilities can leverage the advances in exact inference from both neurosymbolic AI (Kisa et al. 2014; Tsamoura et al. 2021) and probabilistic AI (Darwiche 2020; Holtzen, Van den Broeck, and Millstein 2020).\nBy removing resampling and having access to the exact transition probabilities, we can exploit an up-until-now unexplored synergy with gradient estimation. State-of-the-art unbiased discrete gradient estimation algorithms (Kool, van Hoof, and Welling 2019; De Smet, Sansone, and Zuidberg Dos Martires 2023) use samples and the gradients of the probability of those samples to approximate the gradients of finite distributions. In other words, they need the exact probabilities of these distributions to function. Hence, since our RBPF computes $p_Y(X_{t+1} | X_t, Z_{t+1})$ exactly, gradient estimation can be used to recursively get approximate gradients for the distribution $p_Y (X_{t+1} | Z_{0:t+1})$. For example, using the Log-Derivative trick (Williams 1992)\n$\\nabla_\u03b8 P(X_{t+1} | Z_{0:t+1})\n= E_{X_t}[P(X_{t+1} | X_t, Z_{t+1})] \n+ E_{X_t} [P(X_{t+1} | X_t, Z_{t+1})\\nabla log p_Y (X_t | Z_{0:t})]$.                              (7)\nIn our implementation, we opted for the state-of-the-art performance of RLOO (Kool, van Hoof, and Welling 2019) for gradient estimation. More precise details on our application of gradient estimation can be found in Appendix C."}, {"title": "NeSy inference via cluster factorisation", "content": "Unfortunately, computing $p_Y (X_{t+1} | x_t, Z_{t+1})$ exactly when $X_{t+1}$ also contains variables with an infinite domain is generally only possible under strict assumptions such as Gaussian densities. Moreover, it can still become prohibitively expensive in the purely finite case when ignoring the internal dependency structure of $X_{t+1}$. We mitigate these problems by factorising the NeSy-MM further into clusters of variables that become independent when conditioning on Z. Specifically, a conditional probability distribution $p(X | Z)$ can be factorised as\n$p(X | Z) = \\prod_{i=1}^B [p(X^i | Z)$,                                                            (8)\nwhere B is the maximal number of clusters. Intuitively, variables within the same cluster must always be sampled together and hence comprise minimal subproblems to be solved. The distribution $p(X^i | Z)$ of each of the subproblems can be computed separately to alleviate the computational bottleneck of computing $p(X | Z)$ exactly.\nApplying the cluster factorisation to the conditional probability distribution $p_Y (X_{t+1} | x_t, Z_{t+1})$ with clusters $\\{X_{t+1}^i\\}_{i=1}^B$ yields\n$P\u03c6(X_{t+1} | xt, Zt+1) = \\prod_{i=1}^B P(X^i_{t+1} | xt, Zt+1)$.                            (9)\nIf we split every cluster $X_i$ into a finite part F and infinite part I, this factorisation can be further refined into\n$\\prod_{i=1}^B P (F^i_{t+1} | I^i_{t+1} xt, Z_{t+1})P(I^i_{t+1} | xt, Z_{t+1})$.                       (10)\nBy first obtaining samples for the infinite random variables $I_i$ in every $i^{th}$ cluster using a traditional particle filter, we are again left with a purely finite probability distribution $P\u03c6 (F_{t+1}^i | I_{t+1}^i x_t, Z_{t+1})$ that we compute exactly such that discrete gradient estimation can be applied.\nFor infinite random variables, we can recover differentiability using any of the proven and tailored gradient estimation algorithms (\u015acibior, Masrani, and Wood 2021; Corenflos et al. 2021; Younis and Sudderth 2023). In our case, we followed the work of Scibior, Masrani, and Wood (2021) as it provides strong baseline performance. In summary, we recover gradient-based optimisation of infinite, finite and binary logical variables by joining local exact inference with specialised gradient estimation. The result is a novel Rao-Blackwellised particle filter for NeSy-MMs that handles hybrid domains and exploits the inner conditional dependency structure of the NeSy states $X_t$."}, {"title": "Experiments", "content": "In the following two sections, we present our generative and discriminative benchmarks, and show that NeSy-MMs are capable of tackling both settings (D.IV). We will also clearly show how the presence of relational logic in NeSy-MMs significantly and positively impacts both in- and out-of-distribution performance compared to state-of-the-art deep (probabilistic) models (D.I). In doing so, we show that NeSy-MMs scale to problem settings far beyond the horizon of existing NeSy methods (D.II). In total, NeSy-MMs are successful neurosymbolic models capable of optimising various neural components while adhering to logical constraints (D.III)."}, {"title": "Generative", "content": "Our generative experiment is inspired by the Mario experiment of Misino, Marra, and Sansone (2022), extended using MiniHack (Samvelyan et al. 2021), a flexible framework to define environments of the open-ended game NetHack (K\u00fcttler et al. 2020). The dataset consists of trajectories of images of length T representing an agent moving T steps in a grid world of size N\u00d7N surrounded by walls. The starting position of the agent is randomly initialised and the actions the agent takes are uniformly sampled among the four cardinal directions, i.e. up, down, left, right (Figure 4a). The actions the agent took at every time step are also given in the trajectory. During training, the model takes sequences of both MiniHack images and actions and learns to reconstruct the given images. At test time, the model should then be able to generate sequences of MiniHack images that follow a given sequence of actions and satisfy the rules of NetHack.\nWe use VAEL (Misino, Marra, and Sansone 2022) as a neurosymbolic baseline and two other fully neural baselines: a variational transformer architecture (VT); and a NeSy-MM without logical rules and with neural networks as transition function (Deep-HMM). Since Deep-HMMs are subsumed by NeSy-MMs, the baseline was implemented in our framework to allow it to benefit from our Rao-Blackwellised inference and learning strategy.\nWe consider two metrics for the evaluation. First, the reconstruction error (RE), measured by the mean absolute difference in pixel values, which is first averaged over the images, then separately averaged over all images of the sequence. Second, the reconstruction accuracy (RA), which uses a pre-trained classifier for the location of the agent and measures how much the reconstructed trajectory aligns with the ground truth. This is crucial to understand whether the agent is moving according to the actual rules of the game."}, {"title": "Discriminative", "content": "The next setting consists of a discriminative task, where the goal is to classify trajectories of symbolic states. The main challenge is that the transition function is now partially unknown and needs to be learned from examples. That is, we do not use neural networks for perception as is usually done in NeSy, but have a transition that is both neural and logical. More concretely, the dataset for the discriminative task consists of trajectories similar to the generative dataset. However, there are now also enemies present that are trying to kill the agent (Figure 4b). The input to the model in this case is fully symbolic, meaning we do not input images, but rather the precise starting coordinate of the agent and the list of actions performed by the agent. On top of that, we observe if one of the enemies hits the agent, i.e. the observations $Z_t$ are binary random variables. The discriminative task is binary classification, where a trajectory has label 1 if the agent dies somewhere in the trajectory and 0 otherwise. While we know the basic rules of NetHack, such as permitted movements and damage mechanics, we do not know the transition function of the enemy. That is, we don't know the behaviour of the enemies and fill this gap in knowledge with a neural network that should respect the known rules of NetHack (see Appendix D). We assume that all the enemies share the same behaviour.\nSimilar to the generative experiment, we use a transformer and a Deep-HMM as baselines, this time in a discriminative configuration (Appendix D). To specifically gauge the out-of-distribution (OOD) generalisation capabilities of all methods, we train only using simple sequences of length 10 containing just one enemy moving on a 10\u00d710 grid and we test on more complex sequences. The OOD cases consider different combinations of sequences on grids of size 10\u00d710 or 15\u00d715, length 10 or 20, and with 1 or 2 enemies. When more enemies are present or the sequences are longer, it is naturally easier for the agent to be killed. Conversely, the enemies might need more steps to reach the agent when the"}, {"title": "Results", "content": "Results for the generative experiment are reported in Table 2 while the results for the discriminative task can be found in Table 3 and Table 4. We report the mean and standard error for all the metrics. We discuss the main findings of both experiments by highlighting the advantages of NeSy-MMs.\nBetter generative consistency. Integrating knowledge about the environment is clearly advantageous to the generation process in terms of logical consistency, as can be seen from the reconstruction accuracies. NeSy-MMs signif-"}, {"title": "Conclusion", "content": "We introduced relational neurosymbolic Markov models (NeSy-MMs), a powerful new class of relational probabilistic models that can incorporate neural networks beyond just perception modules. These models are provided with a novel scalable and differentiable particle filtering technique for inference and learning, facilitating the bidirectional flow of information necessary for a proper neurosymbolic model (D.III). Our empirical results show that the integration of relational symbolic knowledge into deep Markov models leads to significant improvements in generative and discriminative tasks (D.IV), while also providing guarantees that neural models alone cannot achieve. Importantly, we stressed the relational aspect of NeSy-MMs by showing that purely neural models and even deep probabilistic models struggle to learn representations that generalise to unseen data and settings (D.I). While such generalisation behaviour is inherent to many neurosymbolic approaches, our experiments showed that NeSy-MMs scale to sequential settings beyond the reach of existing NeSy systems (D.II).\nFuture work will focus on further applying NeSy-MMs to new settings, such as reinforcement learning and applications where continuous random variables are used differently from image generation, e.g. physical systems."}, {"title": "Reproducibility Checklist", "content": "We answer affirmatively to the checklist point \"All novel datasets introduced in this paper are included in a data appendix\". However, we do not include the actual datasets (\u2248 70GB), but the code to generate them and the seed used. With this information, the dataset is deterministically generated and can be perfectly reproduced (see Appendix D.3)."}, {"title": "Architectures", "content": "Generative Task. The variational transformer architectures consist of a separate initial convolutional VAE architecture coupled with a transformer decoder that autoregressively generated the next images in the sequence. This transformer has a causal self-attention layer with 8 heads and 64 keys, followed by a cross attention layer with the same parameters. After these layers, the decoder portion of the VAE is used to generate the images. The NeSy-MM model used multiple smaller networks as it is naturally decomposed. Concretely, there is a small convolutional neural network that classifies the initial location of the agent from the first image into either (5 + 2)2 = 49 or (10 + 2)2 = 144 classes, depending on the grid size. Additionally, a small convolutional encoder network encodes the same initial image into a two-dimensional Gaussian distribution. The NeSy-MM moves the location of the agent according to the rules of MiniHack for a given set of actions, resulting in an estimated distribution for the agent at every subsequent time step. A final convolutional decoder, the same as used by the transformer architecture, then generates an image from the encoding of the initial image together with the planned location of the agent for every time step. The deep Markov model (Deep-MM) uses the exact same setup, only replacing the logical transitions by small neural networks with two hidden layers of size 64 and 32.\nDiscriminative Task. Our transformer architecture follows the usual pattern of an encoder-free transformer. That is, it has a decoder component that operates on a sequence of embedding vectors of size 32. At the start, there is only one embedding containing the two-dimensional starting location of the agent as the first two components, followed by a series of zeroes. The decoder then autoregressively computes the next embedding from all previous embeddings by applying, in sequence, a dropout operation with probability 0.1, a causal self-attention layer with 8 heads and key dimension 64, and finally a cross-attention layer with as context the incoming action and observation on whether the agent was hit or not. The cross-attention layer again has 8 heads and key dimension 64 and both attention layers also use dropout internally with a probability of 0.1. To provide the final sequence classification, a simple MLP network with 2 hidden layers of sizes 64 and 32 with ReLU activations is used. It takes the final embedding vector as input such that it can deal with sequences of varying length, i.e. it is relational in time. The dense output layer is of dimension 1 and uses a sigmoid activation, predicting the probability that the agent dies in the trajectory or not.\nOur NeSy-MM model and Deep-HMM are again close in terms of architecture, but differ in their use of neural networks. Both models take the initial location of the agent as input and estimate the location of all enemies by a uniform prior. They transition these locations to future time steps using actions. For the enemies, the actions are not given and this is where the NeSy-MM uses a simple MLP with two hidden ReLU layers of size 64 and 32 and an output log softmax layer of size 8, as the enemies can move vertically, horizontally, and diagonally. In short, the NeSy-MM transitions the agent from its previous location using the given action, while the enemies are transitioned from their sampled previous locations and predicted actions. Deep-HMMs use a neural network to immediately predict the next location for both the agent and the enemy. In case of the agent, the neural net takes both location and given action as input. The architecture is the same as the action network of the NeSy-MM, albeit with an output of size (N + 2)2 where N is the grid size, predicting a distribution over grid cells. Here we can also see why the NeSy-MM can tackle larger grid sizes while the Deep-HMM can not. Our NeSy-MM uses a relational logic transition to move entities in the world (Appendix D.2) while the Deep-HMM instead uses a neural network that necessarily has a fixed output dimension in terms of the grid size. Next, both models exactly condition, in the probabilistic sense, the predicted distribution of future locations on the incoming evidence whether the agent was hit or not. For the NeSy-MM, the observation function is again logical, meaning it computes the probability that the agent is hit, given the agent location and all enemy locations. This involves knowing the probability that an attack from an enemy succeeds. Since this information can be seen as part of the behaviour of the monster, we do not give it as input to our model and instead replace it by a learnable parameter. For the Deep-HMM, the observation function is completely replaced by a neural network with two hidden ReLU layers of size 64 and 32 followed by a dense log softmax output layer modelling the log probability. That is, computing the probability that an enemy hits the agent from their locations is computed by a neural net for each enemy separately and then combined into the total probability of hitting following the correct expression for the probability of the union of multiple events. Finally, both models explicitly model the health of the agent and subtract an estimate of the damage based on the computed probability of hitting. The final probability that the agent is dead predicted by the models is then given by the frequency of sampled trajectories where the agent dies."}, {"title": "Rules of NetHack", "content": "Our NeSy-MM relies on relational logical knowledge. In this section, we describe in detail the knowledge that we included in our model.\nGenerative Task. The knowledge necessary in this case is very simple and can be summarised by the following logic program.\nagent(X, Y, T) ~ detector (Image,T).\naction (A, T) ~ categorical(\n[0.25, 0.25, 0.25, 0.25],\n[up, down, left, right]\n).\nagent (X, Y+1,T) :- action (up, T-1), agent(X,Y,T-1).\nagent (X, Y-1,T) :- action (down, T-1), agent(X,Y,T-1).\nagent (X+1, Y,T) :- action (right, T-1), agent(X,Y,T-1).\nagent (X-1, Y,T) :- action (left,T-1), agent(X,Y,T-1).\nWhere, on the first line, we say that the agent location at time T is given by a neural detector. Then, we just describe that there are four possible mutually exclusive actions (up, down, left, and right). Finally, we describe the effect of each action on the agent's location.\nDiscriminative Task. In this experiment, we do not get the agent's location by applying a neural detector to an image. Instead, the exact and deterministic initial symbolic location is given. The remainder of the logic for how the agent transitions is the same as in the generative task\nFor the enemies, the setup is analogous, at least in terms of how they transition. The difference being that the enemies' location is initially completely uncertain, modelled by a uniform categorical over the entire grid. Additionally, the actions are not uniformly sampled, but are predicted by the neural network that we are trying to optimise.\nTo eventually deduce whether the agent has died or not, we need to keep track of the agent's health and model the damage the agent takes\ndamage (T, Damage) ~ categorical(\n[0.25, 0.25, 0.25, 0.25],\n[1, 2, 3, 4]\n).\nagent_hp(0, 12).\nagent_hp (T, HP) :-\nagent_hp (T-1, HP),\nnot hit(T).\nagent_hp (T, HP - Damage) :-\nagent_hp (T-1, HP),\ndamage (T, Damage),\nhit(T).\nAt the beginning when T is 0, the agent has 12 hitpoints (HP) that decreases by the amount Damage if there is a hit. The damage value is dependent on the enemy type. In our case, we used the NetHack imp that has a claw attack with 1d4 damage. Hence, the damage is modelled by a uniform categorical variable over the domain [1, 2, 3, 4]. Furthermore, a hit can occur only if the enemy is in one of the 8 cells around the agent, because the claw attack is a melee attack:\nhit(T) ~ bernoulli (t(_)) :-\nagent (Xa, Ya, T), A = [Xa, Ya],\nenemy (Xe, Ye, T), E = [Xe, Ye],\ndistance (A, E, D), D = 1.\nNotice that the hit variable is Bernoulli distributed and the parameters are learned as indicated by the predicate t(_). This predicate represents a learnable variable. In this case the probability that a hit succeeds, which we do not assume to know as we consider it as part of the unknown behaviour of the enemy. Therefore, we do not know when the hit is successful, but we observe the hit variable during training. Finally, we need a rule to understand when the agent is dead:\nagent_dead (T) :-\nagent_hp (T, HP),\nHP =< 0."}, {"title": "Setup and hyperparameters", "content": "We ran the experiments on an NVIDIA P100 SXM2@1.3 GHz (16 GB HBM2) GPU"}]}