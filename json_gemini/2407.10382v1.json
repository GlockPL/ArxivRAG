{"title": "Communication- and Computation-Efficient Distributed Decision-Making in Multi-Robot Networks", "authors": ["Zirui Xu", "Sandilya Sai Garimella", "Vasileios Tzoumas"], "abstract": "We provide a distributed coordination paradigm that enables scalable and near-optimal joint motion planning among multiple robots. Our coordination paradigm is in contrast to the current paradigms that are either near-optimal but impractical for replanning times or real-time but offer no near-optimality guarantees. We are motivated by the future of collaborative mobile autonomy where distributed teams of robots will be coordinating via vehicle-to-vehicle (v2v) communication to execute information-heavy tasks such as mapping, surveillance, and target tracking. To enable rapid distributed coordination, we need to curtail the explosion of information-sharing across the network, thus, we need to limit how much the robots coordinate. However, limiting coordination can lead to suboptimal joint plans, causing non-coordinating robots to execute overlapping trajectories, instead of complementary. In this paper, we make theoretical and algorithmic contributions to characterize and balance this trade-off between decision speed and optimality. To this end, we introduce tools for distributed submodular optimization. Submodularity is a diminishing returns property typically arising in information-gathering tasks such as the aforementioned ones. On the theoretical side, we provide an analysis of how the network topology at the local level -each robot's local coordination neighborhood- affects the near-optimality of coordination at the global level. On the algorithmic side, we provide a communication- and computation-efficient coordination algorithm that enables the agents to individually balance the trade-off. Our algorithm is up to two orders faster than competitive near-optimal algorithms. In simulations of surveillance tasks with up to 45 robots, the algorithm enables real-time planning at the order of 1 Hz with superior coverage performance. To enable the simulations, we provide a high-fidelity simulator that extends AirSim by integrating a collaborative autonomy pipeline and simulating v2v communication delays.", "sections": [{"title": "I. INTRODUCTION", "content": "In the future, distributed teams of robots will be coordinating via robot-to-robot communication to execute tasks such as collaborative mapping [1], surveillance [2], and target tracking [3] (Fig. 1). To this end, the robots will be adapting the information flow in the team to enable rapid and optimal decision-making (Fig. 2). Specifically, subject to their computation and communication bandwidth constraints, the robots will be choosing what information to receive and from who such that they can jointly plan actions in real-time, ensuring that their planned actions complement each other, instead of duplicating each other.\nHowever, these capabilities of efficiency and effectiveness are currently challenging to achieve. The current literature on distributed coordination via vehicle-to-vehicle (v2v) communication imposes a trade-off between decision speed and optimality. On the one hand, algorithms that minimize the action overlap among robots may not be real-time since they can require an explosion of information sharing and processing across the robot network: processing and transmitting information cannot happen instantaneously in the context of multi- robot tasks such as mapping, surveillance, and target tracking, real-time may indicate a replanning frequency at the order of 1Hz. On the other hand, heuristic approaches can be real-time but cannot guarantee minimal action overlap since they achieve rapid decision-making by heuristically limiting the coordination among a few, possibly randomly chosen, robots. We need algorithms that can balance the trade-off by enabling the robots to choose what information to receive and from who.\nContributions. We show that it is possible to balance the trade-off of decision speed and near-optimality. Particularly, we provide a rigorous coordination approach that enables robots to self-configure their communication neighborhood (the set of robots to coordinate with) to tune the trade-off, that is, prioritize decision speed over near-optimality, as needed. To this end, we make theoretical and algorithmic contributions as follows, introducing tools for distributed submodular optimization. Submodularity is a diminishing returns property typically arising in information gathering tasks such as the aforementioned ones; we introduce it rigorously in Section III.\nOn the theoretical side, we provide an analysis of how the network topology at the local level -neighborhood of each robot- affects the near-optimality of coordination at the global level (Section V). The characterization quantifies the intuition that the more centralized the coordination (with larger neighborhoods), the slower the decision speed but the smaller the action overlap. It thus offers insights into how the robots can configure their network to balance the trade- off of decision speed and near-optimality. Importantly, we identify the existence of an inflection point that corresponds to the degree of centralization that optimizes the trade-off: with larger neighborhoods, we prove that the decision time increases faster than the action overlap decreases. Therefore, beyond a degree of centralization, the cost of sacrificing real- time performance will be higher than the gain in the actions.\nOn the algorithmic side, we present a communication- and computation-efficient distributed coordination algorithm that can be both real-time and near-optimal (Section IV). The algorithm is up to two orders faster than the competitive state- of-the-art near-optimal algorithms (Section VI). In simulated scenarios of map exploration with up to 45 robots, where we also simulate v2v communication delays (Section VII), the algorithm achieves replanning frequencies at the order of 1Hz with superior performance. The algorithm's decision time scales linearly with the number of robots, and sublinearly when parallelization is possible. For example, parallelization is possible in spatially distributed settings where robots are far enough from one another and have little action overlap.\nThe algorithm's approximation guarantee captures the intu- ition that when a robot chooses not to coordinate with some other robots but ends up choosing an action that overlaps with these non-neighbors, then the achievable global optimality degrades. Specifically, we prove that the suboptimality degra- dation is proportional to the overlap. To enable our analysis, we quantify the suboptimality cost as a function of the action overlap between a robot and its (non-)neighbors. We introduce to this end a mutual-information-like quantity over sets that we term Centralization of Information.\nThe algorithm is built on a resource-aware distributed coor- dination framework introduced in Section III. The framework is resource-aware in that it requires each robot to coordinate actions with its neighbors only, receiving and processing infor- mation only about them instead of more robots in the network. As such, the framework is communication- and computation- efficient, curbing the explosion of information passing and processing in the network, thus, keeping low the delays due to limited computation and v2v communication speeds.\nSimulator. To demonstrate the efficiency and effectiveness of our coordination algorithm, we integrate it in a simulated"}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "We first present background on distributed coordination, and explain that distributed coordination can be hard since it often takes the form of submodular set-function maximization, which is NP-hard. Then, we discuss the state of the art.\nA. Background on Distributed Coordination\nDistributed coordination via v2v communication is chal- lenging in multi-robot tasks such as mapping, surveillance, and target tracking, modeled as submodular set-function optimiza- tion problems [1]\u2013[3], [7]\u2013[14], which are NP-hard [15], [16]. Submodularity is a diminishing returns property, capturing the intuition that when the same information is collected by two or more robots, its value to the task cannot be double- counted. Thereby, submodular multi-robot tasks are difficult to efficiently solve even in centralized settings. Rigorously, submodular multi-robot tasks take the optimization form:\n$\\max f(\\lbrace a_i \\rbrace_{i\\in \\mathcal{N}}),$\\na_i \\in V_i, \\forall i \\in \\mathcal{N} (1)\nwhere $\\mathcal{N}$ is the set of robots, $a_i$ is robot i's action, $\\{a_i\\}_{i\\in \\mathcal{N}}$ is the ordered set of all robots' actions, $V_i$ is robot i's set of available actions, and $f: 2^{\\bigcup_{i \\in \\mathcal{N}} V_i} \\rightarrow \\mathbb{R}$ is the objective function that captures the (submodular) task utility.\nFor example, in road coverage with multiple drones (Fig. 1), $\\mathcal{N}$ is the set of drones, $V_i$ is the set of available trajectories the drone i can choose from, and f is the total road area covered by the drones' collective field of view by the time their actions have been executed. This f can be shown to be submodular. Intuitively, if two drones observe the same road area upon executing their actions, then either of the drones is redundant in the presence of the other. Therefore, to maximize the total covered road area, the drones need to minimize their action overlap via coordination.\nWithin the collaborative autonomy pipeline in Fig. 2, the optimization problem in eq. (1) models the action coordination stage, that is, the stage where robots jointly plan actions over a look-ahead horizon of optimization. Then, upon making the joint plans, each robot individually executes its action in a receding-horizon fashion till its action is updated via the subsequent coordination stage.\nB. Related Work\nWe discuss the related work across four dimensions: (i) near-optimal but not necessarily real-time coordination algo- rithms; (ii) rapid but not necessarily near-optimal coordination algorithms; (iii) works on the trade-off between decision speed and optimality; and (iv) communication simulators."}, {"title": "III. RESOURCE-AWARE DISTRIBUTED COORDINATION", "content": "We define the problem of Resource-Aware Distributed Co- ordination (Problem 1) with regard to the action coordination module in Fig. 2. To this end, we use the notation:\n$\\mathcal{E}$ is the set of communication channels among the robots;\n$V_N = \\prod_{i \\in \\mathcal{N}} V_i$ is the cross-product of sets $\\{V_i\\}_{i\\in \\mathcal{N}}$;\n$f(a | A) = f(A \\cup \\{a\\}) - f(A)$ is the marginal gain due to adding a to A, given a set function $f : 2^V \\rightarrow \\mathbb{R}$.\nWe also lay down the following framework for the robot-to- robot communication network and the objective function that captures the multi-robot task at hand.\nCommunication Neighborhood. At the beginning of each planning step (Fig. 2), given the observed environment and state of the robots, the robots decide with which others to establish communication, subject to their onboard bandwidth constraints. Specifically, we assume that each robot i can receive information from up to $a_i$ other robots due to on- board bandwidth constraints. Thus, it must be $N_i < a_i$. In Section V, we provide theoretical characterizations that inform how the robots may select their neighbors to optimize the coordination performance. In our simulations over a scenario of road coverage, the robots select their neighbors based on physical proximity, as justified by the results in Section V.\nWhen a communication channel is established from robot j to robot i, i.e., $(j \\rightarrow i) \\in \\mathcal{E}$, then robot i can receive, store, and process information from robot j. The set of all robots that robot i receives information from is denoted by $N_i$. We refer to $N_i$ as robot i's neighborhood.\nCommunication Network. The resulting communication network can be directed and even disconnected. When the network is fully connected (all robots receive information from all others), we call it fully centralized. In contrast, when the network is fully disconnected (all robots receive no information from other robots), we call it fully decentralized. We assume communication to be synchronous.\nCommunication Data Rate. All communication channels $(j \\rightarrow i) \\in \\mathcal{E}$ have finite data rate, i.e., communication speed. In the simulations, we assume the data rate is 10MBytes/sec, in accordance with typical v2v communication speeds [38]. Due to the finite data rate, the decision time of action coordination depends on both (i) the number of communication rounds and (ii) the size of transmitted messages it requires for the robots to find a joint plan. Without loss of generality, we assume all communication channels have the same data rate in this paper.\nObjective Function. The robots coordinate their actions to maximize an objective function. In active information gathering tasks, such as area coverage, target tracking, and per- sistent monitoring, typical objective functions are the covering"}, {"title": "IV. RESOURCE-AWARE DISTRIBUTED GREEDY (RAG) ALGORITHM", "content": "We present the Resource-Aware distributed Greedy (RAG) algorithm. Examples of how the algorithm works are given in Fig. 4. Therein, we also compare RAG to the Sequential Greedy algorithm (SG) [18]. SG is the \"gold standard\" in submodular maximization. SG is presented in (Section IV-B).\nA. The Resource-Aware distributed Greedy (RAG) Algorithm\nThe pseudo-code of RAG, as it is used onboard an robot i, is presented in Algorithm 1. The purpose of each iteration of RAG, namely, of each \"while loop\" (lines 2\u201315), is to enable robot i to decide whether to select an action over its neighbors at this iteration or to pass because a neighbor has an action with a higher marginal gain. If passing, then the robot must wait for a future iteration to select an action. In more detail, at each \"while loop\":\nrobot i finds an action $a_i$ with the highest marginal gain $g_i$ given the actions selected by neighbors $I_i \\subseteq N_i$ so far (lines 3-4).\nrobot i receives the respective highest marginal gain $g_j$ of all neighbors j that have not selected an action yet, namely, of all $j\\in N_i \\setminus Z_i$ (line 5).\nrobot i compares $g_i$ with all $g_j$'s (line 6).\nIf $g_i > g_j, \\forall j \\in N \\setminus I_i$, then robot i selects $a_i$, i.e., $a^{RAG}\\leftarrow a_i$, broadcast $a^{RAG}$, and RAG terminates onboard robot i (lines 6-8 and 2, respectively).\nOtherwise, robot i passes (line 9), and receives the actions selected at this iteration by its neighbors with the highest marginal gain among their respective neighbors, if any (line 11) -the set of these neighbors is denoted as $S^{new}$ (line 10). Particularly, $S^{new}$ may be empty if no neighbor can select an action per their onboard iteration of RAG.\nRemark 1 (Directed, Possibly Disconnected Communication Topology). RAG is valid for directed and even disconnected communication topologies. For example, RAG can be applied to a robot i that is completely disconnected from the network.\nB. Comparison to the Sequential Greedy algorithm (SG)\nRAG is compared with SG [18] in Fig. 4. We rigorously present SG next, and provide a qualitative comparison with"}, {"title": "V. APPROXIMATION GUARANTEES: CENTRALIZATION VS. DECENTRALIZATION PERSPECTIVE", "content": "We present the a priori and posteriori suboptimality bounds of RAG (Theorems 1 and 2). They both capture the suboptimal- ity cost due to decentralization, that is, due to each agent coor- dinating only with a few agents - its neighbors and receiv- ing information only about them, in favor of decision speed. The two bounds are useful as follows: The a priori bound enables each agent to design its neighborhood to minimize its local suboptimality cost subject to its communication- bandwidth constraints. The a posteriori bound results in two practical observations: first, decentralized coordination can marginally be as near-optimal as centralized coordination (Remark 7); second, larger neighborhoods do not necessarily result in better coordination performance when we account for both the decision time and the suboptimality of the algorithm (Remark 8). We validate and leverage the above in the experimental results of Section VII.\nIn the following paragraphs, we first introduce the novel notion of Centralization of Information to quantify the a priori suboptimality bound (Section V-A). Then, we present first the a priori bound of RAG that involves the proposed novel notion (Section V-B) and second the a posteriori bound (Section V-C). Finally, we compare the a priori bound with the a priori bounds in the state of the art (Section V-D).\nA. Centralization of Information\nWe introduce the notion of centralization of information (coin). In Section V-B, we use the notion to quantify the suboptimality cost due to decentralization. Particularly, coin measures how the agents' actions overlap due to the agents not coordinating with their non-neighbors. We also relate coin to the classical notion of total curvature [44] and to pair-wise consistency [39] (Remarks 2 and 3), and show that coin is a less conservative measure of action overlap.\nWe use the following notation and definition:\n$\\bar{N}_i = \\mathcal{N} \\setminus \\{N_i \\cup \\{i\\}\\}$ is the set of robot i's non-neighbors, i.e., the robots beyond i's neighborhood (see Fig. 5(b)).\nThe total curvature [44] of a function $f: 2^{V_N} \\rightarrow \\mathbb{R}$ that is non-decreasing and submodular, and that, without loss of generality, $f(a) \\neq 0$, for any agent's action a, i.e., for any $a \\in \\bigcup_{i \\in \\mathcal{N}} V_i$, is defined as:\n$K_f = 1 - \\min_{A \\subseteq V_N} \\min_{a \\in A} \\frac{f(A) - f(A \\setminus \\{a\\})}{f(a)}$ (5)\n$K_f$ measures how the action a of an agent can overlap with the actions of all other agents in the worst case. Particularly, $K_f \\in [0, 1]$, and if $K_f = 0$, then $f(A) - f(A \\setminus \\{a\\}) = f(a)$, for all $a \\in A$, i.e., the action a of an agent does not overlap with the actions of any other agents. In contrast, if $K_f = 1$, then there exists $a \\in A$ such that $f(A) = f(A \\setminus \\{a\\})$, i.e., the agent with the action a has no contribution to f(A) in the presence of all other agents.\nDefinition 3 (Centralization of information). Consider a func- tion $f : 2^{V_N} \\rightarrow \\mathbb{R}$ and a communication network $\\{N_i\\}_{i \\in \\mathcal{N}}$ where each agent $i \\in \\mathcal{N}$ has an selected an action $a_i$. Then, agent i's centralization of information is defined as\n$coin_{f,i}(N_i) = f(a_i) - f(a_i | \\{a_j\\}_{j \\in \\bar{N}_i}) .$ (6)\n$coin_{f,i}$ measures how much the action $a_i$ of the agent i can be substituted from the actions $\\{a_j\\}_{j \\in \\bar{N}_i}$ of its non- neighbors. In the best case where $a_i$ cannot be substituted at all, i.e., $f(a_i | \\{a_j\\}_{j \\in \\bar{N}_i}) = f(a_i)$, then indeed $coin_{f,i} = 0$. In the worst case instead where $a_i$ is fully substituted, i.e., $f(a_i | \\{a_j\\}_{j \\in \\bar{N}_i}) = 0$, then indeed $coin_{f,i} = f(a_i)$.\nFrom an information-theoretic perspective, $coin_{f,i}$ measures how much the information collected by $a_i$ overlaps with the information collected by $\\{a_j\\}_{j \\in \\bar{N}_i}$. Rigorously, if f is an entropy metric, then $coin_{f,i}$ is mutual information [45]. Thus, in this context, $coin_{f,i} = 0$ if and only if the information collected by $a_i$ is decentralized from (independent of) the information collected by $\\{a_j\\}_{j \\in \\bar{N}_i}$. In this sense, $coin_{f,i}$ cap- tures the decentralization of information across the network.\nRemark 2 (Relation to Total Curvature [44]). $coin_{f}$ is a less conservative measure of action overlap compared to $K_f$. $K_f$ measures the overlap of an agent's action with the actions of all other agents, whereas $coin_{f,i}$ measures the overlap of an agent's action with the actions of its non-neighbors only. Particularly, we prove that, for all $i \\in \\mathcal{N}, coin_{f,i} / f(a_i) \\leq K_f$ (see Proposition 1, which is presented later on in this section).\nRemark 3 (Relation to Pairwise Redundancy [39]). $coin_{f}$ generalizes the notion of pairwise redundancy to capture the"}, {"title": "VI. DECISION TIME ANALYSIS", "content": "We present the decision time of RAG, that is, the time it takes for RAG to terminate, and provide an approximate solution to Problem 1. RAG's decision time scales linearly with the size of the network, up to two orders faster than the state-of-the-art algorithms. We summarize the decision time of the state of the art and of RAG in Table I, where we use the notation:\n$T_f$ is the time required for one evaluation of f;\n$T_c$ is the time for transmitting an action through a communication channel $(i \\rightarrow j) \\in \\mathcal{E}$;\n$T_{\\#}$ is the time for transmitting a real number through a communication channel $(i \\rightarrow j) \\in \\mathcal{E}$; evidently, $T_{\\#} \\ll T_f$ and $T_{\\#} < T_c$.\n$diam(G)$ is the diameter of a graph G, i.e., the longest shortest path among any pair of nodes in G [50].\nWe base our analysis on the observation that the decision time of any distributed algorithm depends on the algorithm's:\ncomputational complexity, namely, the number of function evaluations required till termination (ignoring addition and multiplications as negligible in comparison); and\ncommunication complexity, namely, the number of commu- nication rounds needed till termination, accounting for the length of the communication messages per each round.\nA. Decision Time of RAG\nWe next first analyze the computational and communication complexities of RAG and then present its decision time.\nProposition 3 (Computational Complexity). RAG requires each agent i to perform at most $|V_i||N_i|$ function evaluations.\nProof: For each agent i, $A_i$ increases by at least one with each \"while loop\" iteration of RAG. At each such iteration, agent i needs to perform $|V_i|$ function evaluations to evaluate its marginal gain of all $v \\in V_i$ (lines 3\u20134). Since $|A_i| \\leq |N_i|$, agent i will perform at most $|V_i||N_i|$ function evaluations.\nProposition 4 (Communication Complexity). RAG requires at most $|\\mathcal{N}|-1$ communication rounds where a real number is transmitted, and at most $|\\mathcal{N}|-1$ communication rounds where an action is transmitted.\nProof: The number of \u201cwhile loop\u201d iterations of RAG is at most $|\\mathcal{N}|-1$ because at each iteration at least one agent will select an action. Besides, each \u201cwhile loop\u201d iteration includes two communication rounds: one for transmitting a marginal gain value (line 5), and one for transmitting an action (lines 8 and 11). Hence, Proposition 4 holds.\nTheorem 3 (Decision Time of RAG). RAG terminates in at most $(T_c + T_{\\#}) (|\\mathcal{N}|-1) + T_f \\max_{i \\in \\mathcal{N}} (|V_i||N_i|)$ time.\nProof: Theorem 3 holds from Propositions 3 and 4.\nB. Comparison to the State of the Art\nWe summarize the decision times of the state of the art and of RAG in Table I. RAG's decision time scales linearly with the network's size, namely, $|\\mathcal{N}|$, whereas, in the worst case, the state of the art scales at least quadratically with $|\\mathcal{N}|$. Specifically, RAG has computational time that is linear in $|V_i||N_i|$, independent of $|\\mathcal{N}|$, and communication time linear in N. The comparison is summarized in Table I. Therein, for the sake of the comparison, we assume for simplicity that $|V_i| = |V|, \\forall i, j \\in \\mathcal{N}$. Also, we divide the state of the art into algorithms that solve Problem 1 either indirectly in the continuous domain via employing the multi-linear extension [48] of the set function f [20], [46], [47], or directly in the discrete domain [21], [31], [32], [39], [43]:\na) Computation time: RAG requires $T_f \\sum_{i \\in \\mathcal{N}} |N_i||V_i|$ com- putation time. The method in [21] requires computation time $T_f \\sum_{i \\in \\mathcal{N}} |V_i| = T_f |V_i||\\mathcal{N}|$ since each agent i needs to perform $|V_i|$ computations and the agents perform the computations sequentially. Given a pre-specified information access prescribed by directed acyclic graph (DAG) $G_{info}$, the methods in [31], [32] also instruct the agents to select actions sequentially leading to a computation time at most $T_f |V_i||\\mathcal{N}|$. This time excludes the time needed to find the $G_{info}$ given an arbitrary communication graph G. The method in [39] enables"}, {"title": "VII. EVALUATION IN ROAD DETECTION AND COVERAGE", "content": "We evaluate RAG in two scenarios of simulated experiments of road detection and coverage tasks, one involving 15 and the other 45 robots. In both cases, the robots operate fully as a distributed/mesh network. RAG achieves planning at the order of 1Hz and has superior coverage performance against the competitive near-optimal algorithms.\nTo perform the evaluations, we extend AirSim [4] to the multi-robot setting, simulating v2v communication delays (Fig. 3). We use ROS1. Thus, the evaluations include ROSI's inherent time delays due to the transport layer and message passing overhead, as reported in Figs. 7\u201310.\nThe code of the simulator will be made available herein.\nCommon Simulation Setup across Simulated Scenarios. We first define the task of road detection and coverage (Fig. 1), then introduce the compared algorithms, and, finally, present the simulation pipeline (Fig. 3).\na) Road detection and coverage task: Multiple aerial robots with onboard cameras are deployed in an unknown urban environment and tasked to detect and monitor the roads (Fig. 1). To perform the task, given the currently visible environment, the robots jointly plan how to move per the collaborative autonomy pipeline in Fig. 2. Particularly, the task takes the form of the optimization problem in eq. (1) where f denotes the number of road pixels captured by all robots' collective FOV after they traverse their planned trajectories $\\{a_i\\}_{i \\in \\mathcal{N}}$ \u2014f is non-decreasing, submodular, and 2nd-order submodular [39] and $V_i$ denotes robot i's available trajec- tories at the current planning step. Specifically, $V_i$ defines the possible directions that the robot can move in, and the speed the robot can move with. We assume that every robot can move in any of the 8 cardinal directions \u2014N ES W NE SE NW SW- relative to its body frame, for 10 m at 3 m/s.\nWithout loss of generality, the deployed robots are assumed to have the same onboard sensing and communication capabil- ities: all robots are equipped with (i) an inertial measurement unit (IMU); (ii) a GPS signal receiver; (iii) a downward-facing camera mounted on a gimbal that enables the camera to point to any of the 8 cardinal directions relative to the robot's body frame; and (iv) a communication module that enables 10 MByte/s data rate per inter-robot communication channel. Each robot can establish a few communication channels per a specified communication bandwidth constraint, only with those robots that are within 100 m.\nb) Compared algorithms: Across various bandwidth con- straints for the robots, we compare RAG with two competitive near-optimal algorithms: the Sequential Greedy (SG) algo- rithm [18], also known as Coordinate Descent [1], and its state-of-the-art Depth-First-Search variant (DFS-SG) [21]. Each algorithm is tested in 30 trials, each lasting 2 minutes. In more detail, the setup is as follows:\nWe test RAG for different bandwidth constraints that vary from 0 up to 6. In each case, the same bandwidth constraint applies to all robots. Each such version of RAG is denoted by RAG-knn, where k = 0, . . ., 6. For each k, the communication network is determined by having each robot select k nearest other robots as neighbors subject to the 100 m communication range. If fewer than k others are within the communication range, then all are selected as neighbors.\nThe SG algorithm requires the robots to be arranged on a line graph that defines the order in which the robots select actions per eq. (4) and enables the information relay from robots that have already selected actions to the robot currently selecting an action. To ensure the existence of a line graph in our simulations of SG, we randomly generate one, adjusting the robots' communication ranges to infinity.\nThe DFS-SG algorithm enables SG to be applied to networks that are not necessarily a line graph, but the networks still need to be strongly connected. To this end, we construct strongly connected graphs by first randomly constructing line graphs as for SG, then randomly adding a few undirected edges to the line graphs, particularly, 30 edges for the 15-robot case and 90 edges for the 45-robot case. At each planning round, DFS-SG randomly picks the first robot to select an action, and the order of all other robots is determined by a distributed method based on depth-first search. The resulting decision sequence may involve relay robots that transmit information between robots that are not directly connected and, thus, DFS-SG generally requires longer decision times than SG.\nc) Simulation pipeline: The simulation pipeline consists of the following modules (Fig. 3):\nNetwork Self-Configuration: This module applies only to RAG since only RAG enables the network to self-configure itself across the planning steps subject to the robots' band-"}, {"title": "VIII. CONCLUSION AND FUTURE WORK", "content": "Summary. We provided a rigorous coordination algorithm that enables teams of distributed mobile robots to self- configure their communication topology to achieve real-time and near-optimal coordination. Our coordination paradigm is in contrast to the current paradigms that are either near-optimal but impractical for replanning times or real-time but offer no near-optimality guarantees. We made theoretical and al- gorithmic contributions to characterize and balance this trade- off between decision speed and optimality. On the theoretical side, we provided an analysis of how the network topology at the robot level -each robot's coordination neighborhood\u2014 affects the near-optimality of the coordination at the global level. On the algorithmic side, we provided a communication- and computation-efficient algorithm that enables the agents to balance the trade-off. Our algorithm is up to two orders faster than competitive near-optimal algorithms. In realistic simulations of surveillance tasks with up to 45 robots, the algorithm enabled real-time planning at the order of 1 Hz"}]}