{"title": "DDPM-MoCo: Advancing Industrial Surface Defect Generation and Detection with Generative and Contrastive Learning", "authors": ["Yangfan He", "Xinyan Wang", "Tianyu Shi"], "abstract": "The task of industrial detection based on deep learning often involves solving two problems: (1) obtaining sufficient and effective data samples, (2) and using efficient and convenient model training methods. In this paper, we introduce a novel defect-generation method, named DDPM-MoCo, to address these issues. Firstly, we utilize the Denoising Diffusion Probabilistic Model (DDPM) to generate high-quality defect data samples, overcoming the problem of insufficient sample data for model learning. Furthermore, we utilize the unsupervised learning Momentum Contrast model (MoCo) with an enhanced batchcontrastive loss function for training the model on unlabeled data, addressing the efficiency and consistency challenges in large-scale negative sample encoding during diffusion model training. The experimental results showcase an enhanced visual detection method for identifying defects on metal surfaces, covering the entire process, starting from generating unlabeled sample data for training the diffusion model, to utilizing the same labeled sample data for downstream detection tasks. This study offers valuable practical insights and application potential for visual detection in the metal processing industry.", "sections": [{"title": "1 Introduction", "content": "The defect detection of industrial products requires a large number of feature samples to train the network so that the model can distinguish individuals of the same type as the training samples. This presents two main challenges: acquiring a sufficient amount of sample data and annotating the distinguishing features in the data. In reality, obtaining a large dataset of product defects is difficult, and manually labeling each sample is tedious and monotonous. This study focuses on defect detection in industrial products, specifically on the surfaces of precision aluminum plates. This task presents a particular challenge due to the efforts of manufacturing enterprises to reduce the incidence of product defects to a minimum[Yang et al., 2020]. In general, metal surface defects include corrosion, cracks, dents, scratches, ink marks, and brittleness. These defects not only affect the appearance of the product but also indicate potential quality issues [Tao et al., 2018]. In this research, we mainly focus on three surface defects that impact high-end aluminum products: dents, scratches, and corrosion. Dent is a single or multiple non-smooth depression defects produced by mechanical collision of aluminum plate, which is very destructive to the surface of the material. The scratch is a common defect in the processing, storage, and transportation of aluminum plates, caused by friction or scratching on the surface, and scratches damage the oxide film and the aluminum cladding layer, reducing the corrosion resistance of the material. The specific characteristics of corrosion are a little bit of white or black spots on the surface of the aluminum plate, which is caused by the production, packaging, transportation, storage process contact with acid or water. If the corrosion defects are not found and treated in time, they will not only make the surface of the aluminum plate lose its luster, but also reduce the corrosion resistance and comprehensive performance of the material [Vasagar et al., 2024].\nTo be more specific, firstly, we utilize the probabilistic diffusion model (DDPM) to generate defect samples [Ho et al., 2020]. Then, we combine the MoCo model with momentum contrast learning for efficient training without annotations [He et al., 2020]. Specifically, only a single sample is required"}, {"title": "2 Related work", "content": ""}, {"title": "2.1 Synthesis Defect Generation", "content": "Due to a shortage of defective samples, many researchers [Schl\u00fcter et al., 2022; Zavrtanik et al., 2021; Defard et al., 2021; Yang et al., 2023] have to make fake defects to enhance anomaly detection (AD) performance. They often do this by adding unusual pixels to normal images as a basic way to change the data. Baseline methods like CNN with cutout [DeVries and Taylor, 2017] and the cutpaste approach [Li et al., 2021] randomly cut regions from normal images and paste them into \"incorrect\" places as artificial defects, creating artificial anomalies. Meanwhile, other techniques such as Crop&Paste [Lin et al., 2021] and PRN [Zhang et al., 2023a] enhance anomaly detection (AD) by extracting real defect zones from flawed images and transferring them to flawless ones. While these methods outperform conventional one-class approaches, they lack the ability to generate novel defect patterns, potentially leading to overfitting issues. To increase the variations of anomalies, techniques like DeSTseg [Zhang et al., 2023b], MegSeg [Yang et al., 2023], DRAEM [Zavrtanik et al., 2021] and ReSynthDetect [Niu et al., 2023] include extra datasets combined with Berlin noise to create fabricate defects, but the distribution of these defects may not accurately reflect actual defects and thus there is considerable uncertainty regarding the performance gain. With the recent adavancement of AIGC(AI Generated Contents), some efforts have been made to create more realistic and diverse simulated defects. Generative Adversarial Network(GANs) [Radford et al., 2015; Goodfellow et al., 2020; Niu et al., 2020] have been notable in research for their capability to generate high-fidelity industrial defect images, but they often present challenges such as difficult training processes and potential mode collapse. Moreover, Auto-regressive models [Bu et al., 2010;\nKulkarni et al., 2019] used in industrial image generation excel at detailing defect detection by sequentially processing pixels or blocks, nonetheless, they notably struggle with computational intensity and long-range dependencies, impacting their efficiency and scalability. Additionally, Variational Autoencoders (VAEs) [Rescsanski et al., 2023; Lu et al., 2023] are favored for their robustness in handling different data distributions, yet they often produce blurry outputs and struggle in generating high-quality industrial defect images. Furthermore, Normalizing Flows [Rudolph et al., 2021; Rudolph, 2024; Kobyzev et al., 2020] are used in industrial defect image generation, offering precise modeling through exact likelihood calculations, however, they face challenges with high-dimensional data and require complex architectures that increase computational demands, which may limit their effectiveness compared to other models like GANs or VAEs. Conversely, Denoising Diffusion Probabilistic Models (DDPM) [Ho et al., 2020; Lin et al., 2024; Honghui and Qiuyu, 2023] have demonstrated significant promise in accurately and diversely generating industrial defect images, which is critical for advancing anomaly detection in industrial settings, thereby contributing to the development of more sophisticated diagnostic tools."}, {"title": "2.2 Improving Industrial Defect Detection via Contrastive Learning as Pretask Tasks", "content": "Self-supervised learning methods typically emphasize pretext tasks. The term \"pretext\" implies that the task serves primarily to learn data representations rather than as the ultimate objective. Various pretext tasks often utilize contrastive loss functions, with instance discrimination [Wu et al., 2018] methods associated with exemplar-based tasks [Dosovitskiy et al., 2014] and NCE [Gutmann and Hyv\u00e4rinen, 2010]. In defect detection, self-supervised learning methods are crucial due to the time-consuming nature and potential oversight of minor defects in manual inspection. They utilize self-supervised learning as pre-training tasks, leveraging contrastive loss functions crucial for handling industrial defect images lacking explicit labels [Xie et al., 2021; Chen et al., 2020b; Oord et al., 2018]. This approach enables accurate evaluation of sample similarity in the data representation space, effectively distinguishing between normal and abnormal conditions [He et al., 2020; Hjelm et al., 2018; Wu et al., 2018]. Specifically, in industrial defect detection, contrastive loss functions assist the algorithm in capturing subtle disparities in industrial images, such as variations in color, texture, or shape, thereby enhancing the discrimination of potential defects through improved latent representations."}, {"title": "3 Methodologies", "content": "Our work is based on [Chen et al., 2020c; Ho et al., 2020]. The model we are using is U-Net architecture from guided diffusion, and the attention mechanism is also applied in DDPM. In this section, we illustrate step by step how we apply a diffusion process to metallic surface defect generation, and we demonstrate the application of a MoCo process for model training performed with unlabeled sample data."}, {"title": "3.1 Evolving Image Generation: From Deep Models to DDPM", "content": "Denoising Diffusion Probabilistic Models (DDPM) [Ho et al., 2020], a particularly influential class of deep generative models, generate high-fidelity images from random noise, rivaling or surpassing traditional models like GANs and VAEs. The recent surge in advanced diffusion models is largely due to DDPM's foundational principles, which include a forward process, a backward pass, training methodologies, and practical applications, providing a comprehensive framework for image generation that excels in versatility and performance.\nForward process (diffusion process)\nThe original defect image \\(x_0\\) is transformed into \\(x_T\\) by gradually adding Gaussian noise, so as to achieve the purpose of distorting the image. The forward process can be formulated as follows:\n\\[x_t = \\sqrt{\\bar{\\alpha}_t}x_{t-1}+ \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon_{t-1}\\]\n(1)\nwhere \\(\\{\\bar{\\alpha}_t\\}_{t=1}^T\\) is a pre-defined hyper parameter, called Noise schedule, which often includes columns with very small values. \\(\\epsilon_{t-1}\\sim N(0, 1)\\) is Gaussian noise.\nAs pointed out in [Ho et al., 2020], this iterative noising process can be simplified through an identity transformation, resulting Equation 2:\n\\[x_t = \\sqrt{{\\alpha}_t}x_{0} + \\sqrt{1 - {\\alpha}_t}\\epsilon\\]\n(2)\nHere \\({\\alpha}_t\\) is also a super parameter set within the noise schedule, \\(\\epsilon \\sim N (0, 1)\\) is an equivalent Gaussian noise. So the forward process can be depicted by Equation 1 or 2, and the Equation 1 destroys an input image step by step, but 2 do it in one step.\nBackward process (denoising process)\nThe reverse process is to gradually restore the damaged \\(x_T\\) to \\(x_0\\) by estimating the noise and iterating many times. The backward process can be formulated as follows:\n\\[x_{t-1} = \\frac{1}{\\sqrt{{\\alpha}_t}}x_{t} - \\frac{1 - {\\sqrt{\\alpha}_t}}{\\sqrt{{\\alpha}_t}}\\epsilon_\\theta(x_t, t) + \\sigma_t\\]\n(3)\nThe Figure 2 illustrates the training process of DDPM. Since the real noise \\(\\epsilon\\) in Equation 2 can not be used in the restoration process, the key to DDPM is to train a model \\(\\epsilon_\\theta(x_t,t)\\) that estimates the noise from the actual \\(x_t\\) at time t. Here is the training parameter of the model. \\(\\sigma_t \\sim N(0,1)\\) is Gaussian noise indicating the difference between the estimate and the actual. In DDPM, U-Net serves as a framework for estimating noise.\nModel training\nFrom the above, we know the key to DDPM is to train a model \\(\\epsilon_\\theta(x_t, t)\\)and it should be made to predict \\(\\hat{\\epsilon}\\) close to the \\(\\epsilon\\) that is actually used for destruction. So L2 distance is a good way to describe the similarity and the Loss is formulated as:\n\\[Loss = ||\\epsilon - \\epsilon_\\theta(x_t, t) ||^2 = ||\\epsilon - {\\epsilon}_\\theta (z_t, t) ||^2\\]\n(4)"}, {"title": "3.2 Enhancing Data Representation and Extraction with MoCo", "content": "Momentum Contrast (MoCo)\nThe MoCo algorithm [He et al., 2020] enhances unsupervised learning through a dynamic dictionary for contrastive learning and optimizes data representation using an adjusted Noise-Contrastive Estimation (NCE) loss [He et al., 2020] , described as the original loss in subsequent sections of our paper (see Equation 5). It utilizes a temperature parameter \\(\\tau\\) to differentiate a query q from \\(k_+\\) among k+1 options by comparing q to one positive key \\(k_+\\) and K negative keys. This method promotes learning from both matched and unmatched image views:\n\\[L_q = -log \\frac{exp (q\\cdot k_+/\\tau)}{\\sum_{i=0}^K exp (q\\cdot k_i/\\tau)}\\]\n(5)\nAnd MoCo enhances model flexibility and scalability by managing a dynamic queue that enqueues new mini-batches and dequeues the oldest, thereby decoupling dictionary size from mini-batch size and continuously updating the dictionary with unique mini-batch elements. The algorithm stabilizes the learning process through a momentum-based update mechanism, where the key parameters \\(\\theta_k\\) are incrementally updated in relation to the query encoder parameters \\(\\theta_q\\), which are updated via gradient descent.\n\\[\\theta_k \\leftarrow m\\theta_k + (1 - m)\\theta_q,  m\\in [0,1)\\]\n(6)\nThis update mechanism ensures gradual changes, minimizing feature discrepancies and thereby enhancing the stability and performance of the learning model.\nEnhanced Batch Contrastive Representation Loss\nOur DDPM model has a structure broadly similar to the aforementioned DDPM model, as formalized in Equation 7.\n\\[L_q = - \\sum_{j=1}^n \\frac{exp (q \\cdot k_j/\\tau)}{log \\sum_{i=1}^K exp (q \\cdot k_i/\\tau)}\\]\n(7)\nCompared with the structure of Equation 5, our dataset-level discrimination (Equation 7) referred to as the improved loss in subsequent sections, with n as the mini-batch size is improved by not performing element-wise multiplication and summing between each query q and its corresponding positive key \\(k_+\\) (i.e., \\(n\\times c,  n \\times c \\rightarrow n\\times n\\) process), but by considering all positive key samples globally. Specifically, each query matrix performs standard matrix multiplication with all \\(k_+\\) matrices (\\(n \\times c\\times cn \\rightarrow n \\times n \\times n\\)), generating a n \u00d7 n \u00d7 n three-dimensional matrix. We then average across the third and second dimensions, ultimately reducing it to n \u00d7 1. Additionally, our loss function calculates the global average of the product of each query with all positive samples, and also averages each individual product result. This approach not only reflects the characteristics of global positive keys but also enhances the robustness and expressiveness of the model through averaging. The treatment of negative samples remains unchanged."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Experiment Setting", "content": "1) Datasets\nOur experimental setup utilized a GS3-U3-50S5M-C camera to photograph the surface of an aluminum plate, segmented into six 80mm \u00d7 80mm blocks. We introduced three types of defects, dent, scratches and errosion using an electric drill on each block, alongside identifying products with common production defects. We have four types of images in our collection: one type is of normal conditions, and the other three types feature metal defects-dents, corrosion, and scratches, with 50 images for each category. To expand our dataset, we first applied traditional data augmentation techniques such as random flipping, edge padding, and contrast enhancement to 200 collected sample images of four types. This increased the sample size to 1600 images (400 images for each category). Subsequently, we deployed four untrained diffusion models, each embedded with t = 1000 time embeddings, designed\nspecifically to train on four types of enhanced images including. After training, each model processed a substantial volume of random noise images, producing a significant collection of images across the four categories respectively. Regarding dataset partitioning, we allocated 80% to the training set and 20% to the test set, ensuring ample data for effective model training and performance evaluation. Consequently, 80% of the expanded dataset of 20,000 images (5000 images for each category) were distributed across numerous batches, each with a size of 32, for subsequent contrastive learning training.\n2) Utilizing Backbones:\nResNet50 with 'skip connections' is used for both encoderq and encoderk in contrastive learning on four types of aluminum defects; after removing encoderq, encoderk is modified with an average pooling and a fully connected layer, with its fixed backbone parameters refined via supervised learning on labeled images for classification.\nViT-B/16 [Dosovitskiy et al., 2020] uses a Transformer encoder to process images into patches for contrastive learning on aluminum defects, training encoderk with gradient descent and updating encoderq via momentum; after discarding encoderq, encoderk gains a \"classification token\" and its neck and MLP head are precisely fine-tuned using labeled images in supervised learning, keeping backbone parameters fixed.\n3) Evaluation metric for anomaly detection:\n1. Precision : evaluates the classification accuracy of the four types in generated images, defined as the ratio of true positives to all predicted types. High precision indicates fewer false positives.\n2. Recall: assesses the model's ability to identify all four types of images, calculated as the ratio of true positives to total actual types, crucial for comprehensive type detection despite potential false positives.\n3. AUC-PR(AP): The Area Under the PR Curve (AUC-PR) is a key metric for evaluating classification models. It summarizes the model's performance with a single scalar value by measuring the area under the PR Curve. A higher AUC-PR indicates better accuracy in defect detection, essential for industrial reliability.\n4) Evaluation metric for Generation Quality:\n1. Fr\u00e9chet Inception Distance (FID): The FID quantifies"}, {"title": "4.2 Implementation of DDPM-MoCo for defect generation", "content": ""}, {"title": "Implementation of DDPM", "content": "The images from our dataset are cropped to small patches (640x640) and then resized to a smaller resolution (512x512) as input to the diffusion model. The processed data \\(x_t\\) and time will be input into the U-Net main network of the diffusion model. The module Attn utilizes a linear attention mechanism [Vaswani et al., 2017] to interact and reorganize input data, extracting key information while maintaining the original data dimension. This aims to generate more representative output The output of the model under the current batch input, \\(\\epsilon_\\theta\\) in Equation 4, can be obtained after multiple feature extraction and time information fusion."}, {"title": "Improved training loss schedule", "content": "The problem of infinite loss in the training process is addressed by proposing a dynamic model learning rate adjustment plan based on the training step, and we propose a learning rate adjustment scheme based on the cosine transformation, shown as Equation 8, where current_steps is the number of epochs currently trained, and total_steps is the total number of epochs (epochs) of training. Obviously, due to the sine function, the learning rate of model training will gradually decreases from 1 to 0 during training, which ensures the stability of training to the greatest extent.\n\\[lr = \\frac{1}{2}(1+cos(\\pi\\frac{current\\_steps}{total\\_steps}))\\]\n(8)"}, {"title": "Implementation of Momentum Comparison Model (MoCo)", "content": "The model uses three critical hyperparameters: dictionary size K, momentum m, and temperature \\(\\tau\\) for the contrastive loss. The encoder \\(f_q\\) and encoder \\(f_k\\) handle matching samples and dictionary entries, respectively, using two distinct sets of backbone architectures. The first set employs the ResNet50 backbone architecture for both encoder_q and encoder_k, while the second set uses the Vitb-16 backbone architecture for these encoders. Our training set contains 16,000 samples. The training parameters were set as follows: K = 16384, m = 0.999, \\(\\tau\\) = 0.07, a batch size of 32, and an initial learning rate of 0.03, which was dynamically adjusted using a cosine transformation (Equation 8). The training was conducted over 200 epochs using an NVIDIA GeForce RTX 3090 GPU."}, {"title": "4.3 Quantitative results", "content": "1) Image Quality:\nTable 1 showcases the FID and IS scores for both the original and extensively augmented datasets, emphasizing the maintained image quality. The substantial expansion of the augmented dataset is critical, particularly in scenarios where defect images are scarce, as it significantly enhances contrast learning. The low FID and high IS scores for the augmented data demonstrate that, despite a significant increase in the number of synthetic images, the quality and diversity of these images remain comparable to the original real images. This confirms that our data augmentation techniques effectively preserve image quality without compromise, even with a substantial increase in image quantity.\n2) Results under Original Loss and Improved Loss for Resnet-50 and ViT-B/16.\nThe dataset-level discrimination loss, detailed in Equation 7, significantly boosts the performance of ViT-B/16 and Resnet-50 models, as shown by their PR curves. Initially, ViT-B/16 with the original loss (Equation 5) records AP values for classes 0 to 3-corrosion, dent, scratch, and smooth-as 0.72, 0.80, 0.63, and 0.83 respectively in Figure 5. Implementing our improved loss function raised these to 0.80, 0.87, 0.79, and 0.97 in Figure 6. Similarly, Resnet-50's initial AP values using the original loss were 0.70, 0.72, 0.66, and 0.82 (Figure 7), which improved to 0.82, 0.87, 0.83, and 0.96 with the improved loss (Figure 8). Particularly, the improved loss function most significantly enhanced Class 3's performance, boosting it from 0.83 to 0.97 for ViT-B/16 and to 0.96 for Resnet-50, probably due to its simple attributes, which facilitate easier learning. The improved loss function aligns PR curves closer to the upper-right corner, indicating enhanced detection accuracy and robustness across classes, and highlights the models' dynamic performance sensitivity to threshold adjustments.\n3) Results on argumented data\nWe used two model frameworks, Resnet-50 and Vision Transformer B-16 (Vitb-16), to evaluate the Average Precision (AP) for four categories (erosion, dent, scratch, smooth) under original loss (I-L) and improved loss (D-L), as well as with original versus augmented data. The results in Table 2 showes that transitioning from original to improved loss notably improves AP values; for example, AP in the erosion category increases from 72.12 to 79.97 with Resnet-50, and from 70.02 to 82.87 with Vitb-16. Further analysis reveals that augmented data provided higher AP values under improved loss conditions than original data, with Resnet-50 and Vitb-16 achieving 79.97 and 82.87, respectively, significantly outperforming the original data's 33.46 and 33.69. These results underscore the significant impact of data augmentation on enhancing model performance in complex prediction tasks and confirm that both models achieve optimal comprehensive performance under combined"}, {"title": "4.4 Visualization results", "content": "As shown in Figure 4, the first row displays defect image samples from the real world, characterized by their high realism. The second row features our augmented images, which are primarily synthetic and created using the diffusion model based on the original data. These synthetic images surpass the originals in terms of color fidelity, realism, texture, and perceptual quality, and are also more numerous. Additionally, as detailed in Figure 9, we evaluated the outputs from four generative models: GAN, VAE, Flow-based model, and Diffusion model. Our analysis demonstrates that the Diffusion model excelled among them, producing defect images of superior quality with notable textures and enhanced details, thus delivering higher perceptual quality."}, {"title": "5 Conclusion", "content": "This paper presents the DDPM-MoCo framework, addressing the issue of limited training data for defect detection in aluminum plates. It also enhances defect learning and overall contrastive performance by improving the contrastive loss for ResNet50 and ViT-B-16 backbone models in contrastive learning. Additionally, integrating neck and head modules from ResNet50 and ViT-B-16, with extra supervised training, boosts downstream prediction performance. In future work, we aim to demonstrate the framework's effectiveness in generating abundant high-quality images across various defect types and materials. We also plan to validate DDPM-MoCo's efficacy in enhancing feature extraction across a broader range of backbone models and also in improving the prediction accuracy by integrating corresponding neck and head modules into backbone models through further supervised training."}]}