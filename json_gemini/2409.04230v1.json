{"title": "SPACE: A Python-based Simulator for Evaluating Decentralized Multi-Robot Task Allocation Algorithms", "authors": ["Inmo Jang"], "abstract": "Abstract-Swarm robotics explores the coordination of multiple robots to achieve collective goals, with collective decision-making being a central focus. This process involves decentralized robots autonomously making local decisions and communicating them, which influences the overall emergent behavior. Testing such decentralized algorithms in real-world scenarios with hundreds or more robots is often impractical, underscoring the need for effective simulation tools. We propose SPACE (Swarm Planning and Control Evaluation), a Python-based simulator designed to support the research, evaluation, and comparison of decentralized Multi-Robot Task Allocation (MRTA) algorithms. SPACE streamlines core algorithmic development by allowing users to implement decision-making algorithms as Python plug-ins, easily construct agent behavior trees via an intuitive GUI, and leverage built-in support for inter-agent communication and local task awareness. To demonstrate its practical utility, we implement and evaluate CBBA and GRAPE within the simulator, comparing their performance across different metrics, particularly in scenarios with dynamically introduced tasks. This evaluation shows the usefulness of SPACE in conducting rigorous and standardized comparisons of MRTA algorithms, helping to support future research in the field.", "sections": [{"title": "I. INTRODUCTION", "content": "Swarm robotics is a field that studies the coordination of multiple robots to perform tasks collectively, offering promising potential for future technological advancements. A unique characteristic of control strategies in swarm robotics is their high-level layer called the collective decision-making process [1], where each robot evaluates available options, selects one of them, and then communicates this local decision to its neighboring agents. This process, coupled with the large number of robots typically involved in swarm robotics, leads to significant inter-robot interactions that influence the overall emergent behavior. Analyzing these interactions and understanding how to achieve desired emergent behaviors is a central research focus [2]. While real-world experimentation with dozens of robots is feasible, testing decentralized algorithms with hundreds or more robots is impractical in an academic setting, emphasizing the crucial role of simulation in this field [3].\nSeveral simulators exist for robotics, although few are specifically tailored for studying collective decision-making algorithms in swarm robotics (see Section II-A for a review of existing simulators). Evaluating high-level decision-making algorithms, such as Multi-Robot Task Allocation (MRTA) problems, does not necessarily require highly powerful computing resources. Decentralized algorithms involve each"}, {"title": "II. RELATED WORK", "content": "Each simulator has distinct design goals, and this fact makes direct comparisons not straightforward [13]. Despite the challenge, this section aims to review the features of simulators that have been ever updated in the past five years [3], specifically focusing on Gazebo, Webots, CoppeliaSim, ARGOS, and Stage, from the perspective of high-level collective decision-making algorithm research.\nGazebo, Webots, CoppeliaSim are well-known for their high-fidelity simulations in the robotics domain. They provide precise physical modeling, creating realistic environments for testing and validating robotic algorithms. However, their focus on high-fidelity makes real-time simulation of even dozens of robots challenging [14], limiting their effectiveness for large-scale swarm robotics studies.\nARGOS [14] is a simulator that balances realism and per-formance, efficiently managing larger robot swarms through its modular architecture that accommodate various simulation requirements. It supports agent-level programming, as well as local communication and sensing. However, despite its use in evaluating multi-robot task allocation algorithms [15], the need for C++ implementation to set up simulations with specific MRTA features can be challenging for researchers who prefer higher-level languages for rapid prototyping, quick testing, and comparative analysis.\nStage [16] is known for its lightweight nature, making it one of the simplest simulators available for multi-robot systems. Although it natively supports agent local sensing, it lacks support for local communication. Additionally, its last update was nearly five years ago, and its documentation and tutorials are not comprehensive enough.\nOur work was inspired by SwarmLab [17], a MATLAB-based simulator developed to create standardized processes and metrics for assessing the performance of swarm algorithms. SwarmLab functions as both a development tool and a comparative platform for the aerial swarm research commu-nity and for educational purposes. The simulator proposed in this study aligns with SwarmLab's aim. Nevertheless, SPACE is distinct in that it is specifically tailored for MRTA research, whereas SwarmLab concentrates on the navigation of aerial swarms in cluttered environments. To minimize coding effort and support complex agent behaviors, the architecture of our simulator employs behavior trees and includes a graphical user interface tool for easy adjustment of these trees, enhancing both usability and flexibility in simulation setup."}, {"title": "B. Multi-Robot Task Allocation", "content": "As robotic systems mature, interest in deploying multiple robots has grown. This has brought attention to Multi-Robot Task Allocation (MRTA) problems, which focus on deter-mining which robot should perform which tasks to optimize system-level objective functions. MRTA are classified into various taxonomies based on the characteristics of the robots and tasks involved (see [12], [18] for more details). Among these, the two most studied types are Multi-Task robots with Single-Robot tasks (MT-SR) and Single-Task robots with Multi-Robot tasks (ST-MR) [18]. To demonstrate the usefulness of the SPACE simulator, we compare representative decentralized algorithms for these two types (see Section V). Therefore, the remainder of this section provides brief reviews of these algorithms.\nCBBA [5] is a decentralized method for MT-SR scenarios, where each agent performs multiple tasks sequentially, and each task requires only one agent. Agents in CBBA greedily build task bundles by bidding on their desired tasks and sharing these bids with neighbors. Through a consensus process, they resolve inter-agent conflicts and determine task assignments without a central auctioneer. CBBA has inspired various extensions. ACBBA [6] introduces asynchronous operations, eliminating the need for agents to synchronize between the decision-making and conflict resolution phases. CBBA with Partial Replanning (CBBA-PR) handles newly emerging tasks by resetting parts of previous allocations during bidding rounds [19]. Grouped CBBA [20] improves communication efficiency by organizing agents into groups. GRAPE [7] is a decentralized algorithm that leverages an anonymous hedonic game framework. It was originally developed for ST-MR scenarios [21], [22], where each agent is responsible for a single task that requires the collaboration of multiple robots. The algorithm aims to achieve a Nash stable partition, where no agent has an incentive to unilaterally deviate, indicating that the swarm system has reached an agreed assignment. A few GRAPE variants have recently emerged, extending to accommodate heterogeneous robots that can perform distinct services [23]. Some studies have enhanced convergence speed by utilizing a bipartite algorithm for initial partitioning [24] or by refining partition selection during its conflict resolution process [25]."}, {"title": "C. Contributions", "content": "In this study, we propose SPACE, a Python-based simulator for MRTA research. We detail the development philosophy and software architecture behind its implementation (Section III). As a use case, we demonstrate how to implement CBBA and GRAPE as decision-making plugins within SPACE, specifically for scenarios where tasks are newly added over time. Additionally, we describe the adaptation of GRAPE, initially developed for ST-MR scenarios, to accommodate MT-SR scenarios (Section IV). We then provide a performance comparison of the two algorithms in terms of mission completion time, distance traveled by the agents, and tasks completed, discussing the distinct characteristics of each algorithm based on these metrics (Section V)."}, {"title": "Below are the key features of the SPACE simulator:", "content": "Optimized for swarm robotics research, supporting large-scale simulations with a lightweight design.\nUses behavior trees to define and manage agent behaviors, allowing for flexible and structured decision-making.\nCompatible with Groot2\u00b9 for visualizing and editing behavior trees, enhancing ease of use and analysis.\nEasily configurable via a YAML file, enabling customization without modifying the source codes of the simulator.\nIntegrates custom decision-making algorithms as plugins, allowing for tailored testing and experimentation.\nAgents communicate locally within specified radii and maintain situational awareness based on their situational awareness ranges.\nSupports the creation of tasks dynamically during the simulation, adapting to evolving scenarios.\nFacilitates the comparison of different decision-making algorithms within a consistent simulation environment and supports Monte Carlo tests for statistical analysis."}, {"title": "III. SOFTWARE ARCHITECTURE", "content": "The core components of SPACE, as shown in Figure 2, are as follows: behavior tree, agent, decision-making plug-in, task, and simulation tools."}, {"title": "A. Behavior Tree", "content": "The simulator is developed using pygame, with each agent operating according to its own behavior tree. Behavior trees are increasingly popular in open-source robotics projects due to their modularity and flexibility [11], which also motivated their use in our simulator. In each game loop iteration, the behavior tree of each agent is executed from the root. The simulator assumes that the behavior tree computation would be completed within a predefined control loop period, necessitating adjustments to the simulation frame rate parameter based on actual robot computation times for more realistic simulation.\nOur behavior tree implementation currently supports control nodes (e.g., Sequence, Fallback) and action nodes (e.g., DecisionMaking Node, TaskExecutionNode, ExplorationNode, LocalSensingNode). Information exchange between action nodes is facilitated through a mechanism known as blackboard [10], [11]. Users can extend functionality by adding custom action nodes, and a detailed tutorial for this is available on the official documentation website. Custom behavior trees can be easily defined by dragging, dropping, and connecting nodes using Groot2."}, {"title": "B. Agent", "content": "The Agent class encapsulates the core attributes and methods relevant for each agent in the simulator. Each agent instance possesses several fundamental attributes such as its status information (e.g., identification number, position, veloc-ity, acceleration, rotation), and its mobility capabilities (e.g., maximum linear speed, maximum angular speed, maximum acceleration). Each agent instance also has an attribute called work rate, which specifies the amount of task workload the agent can perform per second.\nEach agent also has attributes related to its local percep-tion capabilities. These include its communication range, which defines the distance within which the agent can interact with neighboring agents, and its situational aware-ness range, which determines the area within which the agent can perceive nearby tasks. A crucial function for local communication, local_message_receive(),col-lects local decision data from neighboring agents. When each agent executes its decision-making process at the DecisionMakingNode, it stores the resulting local decision data in message_to_share, a Python dic-tionary. The use of a dictionary allows users to de-fine the message structure flexibly within their decision-making plugins (see Section III-C), adapting the format as needed. The local message_receive() function retrieves these local data and appends them to a Python list messages_received of the agent. This function is invoked by the LocalSensingNode of the behavior tree in each game loop.\nAgents are modeled as point masses and move in straight lines toward their assigned tasks, which is executed at"}, {"title": "C. Decision-making Plug-in", "content": "Inspired by the approach used in Navigation2 [26], which allows for easy replacement of planners or controllers, our simulator is designed to enable users to effortlessly swap decision-making algorithms by modifying config.yaml file, treating it as a plugin. Three decision-making plugins are currently implemented and will be detailed in Section IV.\nUsers can also implement their own decision-making algorithms as custom plugins in separate Python files. Our simulator aims to simplify the process of implementing algorithms from pseudocodes found in the literature. For instance, decentralized algorithms typically involve a two-step process [4], [5], [7]: first, each agent performs local decision-making and shares the results with neighboring agents; second, the agent uses the shared information to resolve conflicts. Handling local communication requires extra coding efforts, but the SPACE simulator streamlines this process by providing built-in support for local communication. Users can imple-ment the first step by simply storing data to be shared (e.g., local decision data) in the message_to_share attribute of an agent before exiting the DecisionMakingNode. The simulator automatically manages the distribution of this data, ensuring that, in the next game loop, each agent receives the data from its neighboring agents during the LocalSensingNode. Consequently, agents can then use this data to perform conflict resolution."}, {"title": "D. Task", "content": "The Task class contains attributes for each task, includ-ing its identification number, position, and workload. To manage these tasks, two key functions are utilized. The reduce_amount() function decreases the workload ac-cording to the work rate of an agent performing the task. The set_done() function is called when the workload reaches zero, updating the completed attribute of the task to True."}, {"title": "E. Other Features", "content": "Upon completion of a simulation, metrics such as the distance traveled and workload completed by the agents are recorded, not only offering a time-wise summary of the simulation progress but also capturing the individual agent-level data at the end of the mission. Both results are saved in CSV files.\nThe simulator supports two testing modes: with screen rendering and without. In screen rendering mode, the simula-tion can be visualized using pygame, and the output can be saved as a GIF through an optional feature.\nA notable feature of this simulator is its support for Monte Carlo experiments. To conduct these experiments, users begin by configuring a scenario in a config.yaml, specifying parameters such as the decision-making plugin, agent, and task settings. Multiple configurations can be developed to explore various parametric studies. A set of these configurations can be defined in a separate YAML file, where the number of Monte Carlo runs for each scenario is also specified. The simulator then automatically performs the tests repeatedly according to the defined parameters."}, {"title": "IV. PLUG-IN IMPLEMENTATION EXAMPLES", "content": "This section presents examples of how to implement decision-making plugins within the SPACE simulator. We implemented CBBA [5], GRAPE [7], and a simple algorithm named First-Claimed Greedy. Drawing from our development experience, we outline a recommended structure for decision-making plugins. We then discuss additional modifications made to GRAPE and CBBA, which extend beyond their"}, {"title": "A. Structure Overview", "content": "Basically, a decision-making plugin is supposed to be de-fined as a Python class (see Class 1), with a member function DECIDE() that is invoked by the DecisionMakingNode in the behavior tree. The node acts as a wrapper that connects the behavior tree with the plugin. Any elements that require initialization at the start of the mission should be placed in a separate initialization function. For example, the boolean variable satisfied (Line 7) should be initially set to False (not shown here for simplicity)."}, {"title": "B. GRAPE Modifications", "content": "In the scenario involving dynamic task generation, addi-tional modifications are made to the original GRAPE. First, we incorporate a mechanism where each agent decentralizedly constructs an initial partition such that each neighbor agent is assigned a task closest to it as the starting point. As shown by [24], setting an initial partition can accelerate convergence to a Nash stable partition, thereby facilitating better adaptation to dynamic environments. This process is implemented at the initialization function of the decision-making plugin and also during the post-processing after a task is completed (Line 3).\nAlthough GRAPE has been theoretically proven to converge to a Nash stable partition when agents are connected in a strongly connected topology, determining whether all agents have converged requires global information. Hence, we imple-ment such that each agent assesses convergence based solely on its local information. Specifically, the agent compares its locally-known partition with the partition resulted from the distributed-mutex algorithm [7] (Line 13). If there is no difference between the two partitions, the agent concludes that its locally-known partition becomes Nash-stable, and satisfied remains True (Line 14). However, if the agent receives a new partition information from another agent further than one hop away, satisfied might be set to False. This triggers to proceed the decision-making process based on the new information.\nFor the individual utility function of agent $a_i \\in A$ with respect to $t_j$, we use the following equation:\n$U_i(t_j, S_j) = \\frac{R_j}{|S_j|} - C_{i,j} |S_j| f_s$,\n(1)"}, {"title": "C. CBBA Modifications", "content": "In dynamic environments, as noted by [6], [19], \u0421\u0412\u0412\u0410 may need to be rerun to address outdated information or significant changes in situational awareness. Our empirical experiments also reveal that discrepancies between bid costs and actual execution results further affect the phenomenon. For instance, we observed scenarios where an agent, after winning a task with a high bid value, later removed the task from its task bundle when a more attractive one emerged. Consequently, the task remained unassigned, as the other agents were unable to bid on it due to its high cost.\nTo address the problem of invalid bid values and unassigned tasks, we introduce a simple mechanism: if the task bundle of an agent remains empty for a certain period, the agent resets all of its known winning bid values and winning agent IDs. Although resetting bid values was also proposed in CB\u0412\u0410-PR [19], our study aims to compare the baseline versions of CBBA and GRAPE. Thus, we implement this simple modification to CBBA instead of using CBBA-PR to evaluate its effectiveness in dynamic environments.\nFor the scoring function of agent $a_i$ with regard to its task-execution path $p_i$, we use the time-discounted reward [5]:\n$S_i^{p_i} = \\sum_j \\lambda^{\\tau(p_i)}.R_j$ \n(2)\nwhere $\\lambda \\in [0,1]$ is the discount factor; $\\tau \\in R^+$ represents the estimated time for the agent to finish task $t_j$, taking into account the distance to the task along the path, and its work rate. $R_j$ is the reward received upon task completion."}, {"title": "D. First-Claimed Greedy Algorithm", "content": "We implement a simple algorithm where each agent selects the task nearest to itself based on local task information. In making this selection, the agent also considers messages received from its neighboring agents. If the agent realizes that the chosen task has already been assigned to another agent, it abandons that task and tries the task selection process again in the next game loop. We refer to this approach as the First-Claimed Greedy algorithm, as it ensures that the initial claim of an agent on a task is confirmed."}, {"title": "V. USE CASE: COMPARISON OF ALGORITHMS", "content": "This section demonstrates the usefulness of the SPACE simulator by comparing three algorithms, GRAPE, CBBA, and First-Claimed Greedy (FCG), in a MT-SR scenario. Our goal aims to showcase how SPACE can be used to evaluate and contrast these algorithms effectively."}, {"title": "A. Experiment Setting", "content": "The common settings for the scenario are as follows. Basi-cally, the simulation loop occurs with 1 Hz with consideration of potentially low communication bandwidth between agents. The map has dimensions of 1400 units in width and 1000 units in height. The scenario starts with 250 tasks, with an additional 50 tasks being generated every 1000 seconds for 3 times, resulting in 400 tasks in total. These tasks are distributed randomly across the map according to a uniform distribution. Each task takes between 6 and 60 seconds to complete, as all agents work at the same work rate of 1. Each agent has the same mobility capabilities as shown in Table I, and has a situation awareness range with 300 units. Regarding the utility functions for GRAPE and CBBA, i.e., Equations (1) and (2), we use the following parameters: Rj is set to be the workload of task tj; the social inhibition factor fs is 100; the discount factor A is 0.999.\nOur experiments evaluate the performance of GRAPE, CBBA, and FCG algorithms under varying conditions. We vary the number of agents $n_a \\in$ {10,30,50} and communication radii $r_c \\in$ {100, 200, 300} to assess their impact on each algorithm. Specifically, we test a total of 27 scenarios, corresponding to all combinations of agent numbers, communication radii, and algorithms, with 100 Monte Carlo simulations conducted for each scenario. The performance of each algorithm is assessed based on three key metrics: (1) mission completion time, (2) distance traveled by the agents, and (3) workload done by the agents. Note that all experiments are conducted using SPACE's Monte Carlo simulation support, as detailed in Section III-E."}, {"title": "B. Comparative Results", "content": "Figure 3 presents the results of mission completion time, average travel distance per agent, and average workload per agent for scenarios with 10, 30, and 50 agents over 100 episodes. These results are visualized using boxplots, with varying communication ranges of 100, 200, and 300, and for the algorithms GRAPE (blue), CBBA (orange), and FCG (green).\nRegardless of the number of agents, algorithm used, or communication range, the average workload per agent remains consistent. This can be explained by the fixed number of tasks. Given that the task workload ranges between [6, 60] with a total of 400 tasks, the expected workload sum is approximately 13,200. Thus, with the fixed number of tasks, increasing the number of agents leads to a decrease in individual agent workload. Since all tasks must be completed to conclude the mission, the average workload per agent remains unaffected by variations in communication range or the choice of algorithm.\nAs communication range increases, the travel distance decreases for all algorithms and scenarios. This effect is more noticeable with a higher number of agents. A shorter communication range leads to conflicts between agents that are not immediately aware of each other during local decision-making processes.\nFor CBBA and FCG, mission completion time decreases as communication range increases. In CBBA, each agent only needs to verify the convergence of its task bundle. Even if some other agents within the communication radius have not yet converged on their bundles, conflicts are avoided as long as the agent does not prefer any of the tasks selected by them. For each agent, once its task bundle converges, it proceeds to execute the assigned tasks.\nHowever, in the case of GRAPE, since the partition information itself must converge, even if other agents select tasks without conflict, the partition information is still affected, resulting in False after the distributed mutex algorithm. This effect extends the convergence time as the communication range widens."}, {"title": "VI. CONCLUSION", "content": "In this study, we proposed SPACE, a Python-based simu-lator designed for MRTA research, and outlined the design philosophy and software architecture underlying its develop-ment. To demonstrate its practical utility, we implemented CBBA and GRAPE as decision-making plugins within SPACE and compared their performance across various metrics, par-ticularly in scenarios where tasks are dynamically introduced over time. This evaluation revealed distinct characteristics of each algorithm, providing valuable insights into their respective strengths and weaknesses. These findings highlight the usefulness of SPACE as a tool for conducting in-depth comparisons and analyses of different algorithms, thereby facilitating future research in MRTA.\nFor future work, we plan to enhance SPACE by developing a reinforcement learning interface that functions similarly to the OpenAI Gym environment. This enhancement will enable SPACE to support multi-agent reinforcement learning [27] specifically focused on MRTA research. Additionally, we aim to broaden the range of scenarios beyond the currently implemented MT-SR scenario, including more complex scenarios such as delivery task allocation [28], where tasks have constraints on starting and ending positions. Extending the behavior tree by adding behavior nodes for path planning and control could be a valuable direction as well."}]}