{"title": "AI-driven multi-omics integration for multi-scale predictive modeling of causal genotype-environment-phenotype relationships", "authors": ["You Wu", "Lei Xie"], "abstract": "Despite the wealth of single-cell multi-omics data, it remains challenging to predict the consequences of novel genetic and chemical perturbations in the human body. It requires knowledge of molecular interactions at all biological levels, encompassing disease models and humans. Current machine learning methods primarily establish statistical correlations between genotypes and phenotypes but struggle to identify physiologically significant causal factors, limiting their predictive power. Key challenges in predictive modeling include scarcity of labeled data, generalization across different domains, and disentangling causation from correlation. In light of recent advances in multi-omics data integration, we propose a new artificial intelligence (AI)-powered biology-inspired multi-scale modeling framework to tackle these issues. This framework will integrate multi-omics data across biological levels, organism hierarchies, and species to predict causal genotype-environment-phenotype relationships under various conditions. AI models inspired by biology may identify novel molecular targets, biomarkers, pharmaceutical agents, and personalized medicines for presently unmet medical needs.", "sections": [{"title": "Introduction", "content": "A fundamental challenge in the field of biology is to predict phenotypes, which are the observable traits of an organism, considering the complex interaction between various genetic makeups (genotypes) and environmental influences and perturbations[1]. The genotype refers to the hereditary information stored in an organism's DNA, whereas the phenotype refers to the manifestation of that genetic information at the organismal level. In addition to genetics, environmental factors such as nutrition, pollution, infections, radiation exposure, microbiota, and drug usage play a role in shaping and altering phenotypes.\nThe phenotype can be defined by observable physical characteristics (e.g., eye color), behavioral patterns (e.g., memory), physiological functions (e.g., blood pressure), and clinical manifestations (e.g., pain), among others. However, the organism's phenotype does not immediately rise from its genotype. There exist several intermediate phenotypes, known as endophenotypes[2], which delineate molecular attributes at an intermediate level of organization, complexity, or scale between the molecular/genetic level and the organismal phenotype. The endophenotype typically includes RNA expression, protein expression and post-translational modifications, metabolite concentrations, and so on. To establish causal linkages between genotype, environment, and phenotype, it is essential to utilize endophenotype as a means to connect the genotype and the phenotype of an organism. Firstly, the endophenotype encompasses the biological mechanisms that link the genetic makeup to the final organismal phenotype. Additionally, alterations in endophenotypes occur before or concurrently with modifications in the organismal phenotype. Therefore, endophenotypes are more responsive markers of genetic or environmental impacts compared to the organismal phenotype. Furthermore, endophenotypes are frequently able to be objectively measured and quantified. This facilitates the replication and comparison of data across many investigations, as well as the development of computer models. Ultimately, endophenotypes serve as biomarkers, such as \u03b2-amyloid indicating Alzheimer's disease, for clinical disorders. They also offer specific targets that are linked to the causes of diseases, which in turn facilitates the development of effective and safe therapeutic interventions.\nThe latest development in sequencing and high-throughput technology has generated a vast amount of multiple omics data including but not limited to genomics, epigenomics, transcriptomics, proteomics, metabolomics, lipidomics, glycomics, cytomics/cellomics, microbiomics, metagenomics, radiomics, interactomics, and chemical genomics[3]. With the exception of genomics and epigenomics data that characterize genotypes, and microbiomics, metagenomics and chemical genomics data that provide information about environmental factors, most omics data reveals the molecular landscape of distinct endophenotypes at various levels. These omics data are crucial in linking genetic information to phenotypic outcomes and predicting phenotype responses to environments. For example, analyzing transcriptomics data identifies which genes are upregulated or downregulated in response to genetic variations or environmental perturbations. Proteomics data aids in connecting genetic information to proteins that"}, {"title": "Introduction", "content": "carry out most cellular functions. Metabolites are the end products of many cellular processes. They reflect the functional output of the genome, transcriptome, and proteome of an organism and environment, and capture the organism's response to external stimuli and environmental influences.\nWhile each omics type provides a unique perspective on the molecular processes occurring within cells, tissues, or organisms, it is essential to combine all layers of omics data in order to fully understand the complexity and interdependencies of biological systems[4]. Firstly, rooted in the central dogma of molecular biology, it is necessary to connect multiple levels of omics data, encompassing DNAs, RNAs, proteins, and phenotypic outcomes, in order to gain a full understanding of how genetic information is converted into functional molecules and eventually, phenotypes. Secondly, integrating data across several omics levels enables identification of key regulatory elements that act as critical points of control in cellular pathways and the complex interactions and feedback loops that govern cellular processes. Finally, individual omics datasets only provide partial information about a biological system. Their integration will enhance the predictive power of computational models that aim to establish a connection between genetics and phenotype.\nThe human body consists of a diverse array of cell types (e.g., epithelial cells, blood cells, immune cells, etc.) The organization of the human cells follows a hierarchical structure. Cells combine to form tissues, tissues form organs, and organs work together to create a functional organism. Cells communicate through chemical signals such as hormones and neurotransmitters. The progress in single-cell and spatial omics techniques makes it possible to observe and quantify heterogeneous cellular processes and cell-cell communications across the hierarchy of an organism at a single-cell resolution[5, 6, 7, 8]. Spatial single-cell omics data will be the cornerstone to link molecular events to organism phenotypes [9, 10, 11, 12]. Thus, it is critical to integrate omics data across biological scales from cell to tissue to organ to organism.\nIn addition to the integration of omics data across various biological levels and across organismal scales, it is imperative to also integrate omics data across different species [13, 14, 15]. Omics studies conducted in model systems are essential for enhancing our understanding of biology. This is due to specific advantages offered by model organisms, such as short generation times, ease of genetic manipulation, and similarities to more complex organisms including humans. Model organisms have long been instrumental in investigating the functions of specific genes and the regulatory mechanisms that control them. They have also helped in comprehending cellular processes, tissue formation, and organ development, as well as shedding light on the genetic factors influencing complex behaviors. Genetically engineered models are indispensable tools for understanding the molecular mechanisms underlying diseases, evaluating possible treatments, and assessing the safety and efficacy of therapeutic interventions. As stated by Theodosius Dobzhansky, Nothing in biology makes sense except in the light of evolution [16]. Comparative genomics studies identify the similarities and differences in the genomes of different species, leading to"}, {"title": "Introduction", "content": "understanding the genetic basis of human traits and diseases. Recent advances in functional genomics such as CRISPR-Cas9 and perturb-seq make it possible to assess gene functions and dissect gene regulatory networks on a large scale. As the amount of multi-omics data from model organisms becomes more accessible, there is a need for innovative methods to transfer this knowledge from model organisms to humans. This will facilitate advancing fundamental and translational biomedical sciences.\nCross-level, cross-scale, cross-species multi-omics data integration and predictive modeling of causal genotype-environment-phenotype relationships will not only provide new knowledge about the basic principles of life but also be the driving force for the identification of new molecular targets, biomarkers, pharmaceutical agents, and personalized medicines for unmet medical needs, as shown in Figure 1. The target-based drug discovery and development approach, which follows the human genome revolution and now dominates the pharmaceutical industry, is widely recognized for its time-consuming, expensive, and unproductive nature. Artificial Intelligence (AI) shows great potential in expediting the process of drug discovery. Nonetheless, if adhering to the current drug discovery paradigm, AI may merely make failures faster and cheaper but not improve the success rate of identifying effective and safe treatments for incurable ailments. As highlighted by Bender et al.[17], there exists a substantial disparity between molecules that are optimized for target binding affinities or other proxy objectives and medications that demonstrate both clinical efficacy and safety. A survey conducted recently indicates that over 90% of the medications that have been approved are derived from the process of phenotype drug discovery and development[18]. However, conventional phenotype screening approaches based on cellular or organismal phenotypes are medium- or low-throughput and lack information about drug modes of action.\nPerturbation functional omics profiling offers a quantitative, mechanistic, and high-throughput phenotype readout for compound screening, thereby boosting the power of phenotype drug discovery[19]. Nevertheless, the molecular omics profiles only characterize endophenotypes. It remains a challenge to connect endophenotypes to clinical outcomes. Moreover, due to the impracticality of measuring compound responses in a living patient, we must rely on a model system during the early and pre-clinical stages of drug discovery and development. In order to accurately translate chemical activity observed in a model system to the effectiveness and side effects of a medicine in a clinical setting, it is necessary to have an unbiased and comprehensive phenotype readout that bears information of target transferability, drug mode of action and pharmacokinetics. An integrated molecular profile derived from transcriptomic, proteomic, metabolomic, and other endophenotypes both before and after the treatment of tested compounds is highly suitable for this objective and has shown potential in phenotype compound screening [20] and physiologically based pharmacokinetics[21].\nIn summary, elucidating genetic and molecular underpins of complex human traits and disorders, as well as predicting organismal phenotypes under the interplay of diverse genotypes and environmental perturbations, requires integrating multiple omics data across data modalities, biological levels, and"}, {"title": "Perturbation omics data resources", "content": "Predictive modeling of phenotypes from genotypes under perturbations needs labeled data. A large number of perturbation omics data have been collected. Although these data are highly biased to certain biological conditions (cell types,"}, {"title": "State-of-the-art of machine learning methods for multi-omics data integration and predictive modeling", "content": "One of the major technical challenges faced by multi-omics data integration is data distribution shifts. The data shift in omics data mainly comes from two sources: technical confounders such as batch effects and biological confounders (e.g., sex, age, disease state, etc.). Traditional statistical methods provided a foundation for multi-omics data integration. These approaches encompass a variety of techniques including correlation-based analysis (e.g., BindSC[60], Seurat v3[61], Scanorama[62] and MaxFuse[63]), matrix factorization (iNMF[64] and LIGER[65]), Bayesian-based methods (MOFA+[66]), nearest neighbor-based (e.g., fastMNN [67] and Seurat v4[68]), and dictionary learning (e.g., Seurat v5[69]). Our focus, however, is on deep representation learning methods, which have shown great promise in addressing the aforementioned challenges. The representative techniques include autoencoder, transformer, and contrastive learning. The power of these methods comes from the fact that they do not need labeled phenotypic data that is scarce, and often infeasible to obtain."}, {"title": "Autoencoder", "content": "Deep generative models, particularly Variational Autoencoders (VAEs), are at the forefront of analyzing complex, high-dimensional single-cell sequencing data. VAEs employ an encoder to interpret input data and a decoder to reconstruct it, learning a latent distribution. The objective that it optimizes is to mirror the input while minimizing the Kullback-Leibler divergence between the latent embedding's prior and posterior distributions.\nscVI[38] models gene expression in scRNA-seq data using VAE with a zero-inflated negative binomial distribution, conditioned on batch annotations and two unobserved variables: a cell-specific scaling factor and a latent biological variable. Neural networks map these latent variables to the distribution parameters, producing batch-corrected, normalized transcript estimates for differential expression and imputation. A separate neural network, trained via variational inference and stochastic optimization, approximates the posterior distribution of latent variables, ensuring scalable and accurate analysis of single-cell RNA-seq data.\nThe same group further developed scANVI[39], which integrates semi-supervised learning with cell type annotations. It can be useful for transfer labels while measuring uncertainty, especially when dealing with complex label structures such as hierarchical cell types. However, both models are limited on RNA-seq data as a single modality.\nTotalVI[40] took advantage of the CITE-seq technique, which can simultaneously measure the abundance of the proteins on the cell surface, to provide the"}, {"title": "Autoencoder", "content": "opportunity for multifaceted analysis of both RNA-seq and the functional information in proteins. It uses VAEs to learn a joint probabilistic representation of the paired measurements that counts for batch effects for both modalities. The RNA modeling strategy is similar to scVI [38]. The protein modeling explicitly has modality-specific technical factors such as a protein background, which enable a denoised view of data. However this method requires paired measured samples, nor there is domain alignment consideration.\nMore recent tool Cobolt[41] introduces a symmetric multi-modal VAE network for multi-omics data integration with a Product of Experts model (PoE) model [70]. PoE combines the variational posteriors of the multiple modalities (the experts) by taking their product and normalizing the result. It was trained on paired multi-omics data to guide the integration of unpaired data, resulting in a joint representation of single-cell RNA-seq and ATAC-seq datasets, which can be beneficial for various downstream tasks. Despite its guidance on the unpaired datasets, this method assumed a multinomial distribution for both modalities which may cause potential information loss.\nIn contrast, MultiVI[42] employs a modality-specific noise system suited to both gene expression and chromatin accessibility, with negative binomial distribution and Bernoulli distribution respectively. In contrast to Cobolt's POE technique, MultiVI utilizes a distributional mean and penalization strategy for a more optimized integration of latent embeddings. Moreover, its ability to incorporate cell surface protein abundance broadens its scope, allowing for a richer understanding of cellular properties.\nThe strengths of both MultiVI and Cobolt, which implemented symmetric multimodal VAE for joint modality representations, are tempered by the challenges of extreme sparsity and random noise in the datasets. These factors can confound the biological variance, posing obstacles to downstream analysis and scalability of the model. Addressing this, scMVP[43], employs a non-symmetric framework that enables the construction of a unified latent space for scRNA-seq and scATAC-seq data. This is achieved via a clustering consistency-enforced multi-view VAE, which is further enhanced by multi-head self-attention mechanisms and a cycle-GAN module, thereby increasing the robustness across both modalities. However, it again requires simultaneous multi-modality measurements with individual cells to function effectively.\nTo address the challenge of information loss when integrating data across different modalities, GLUE[44] employs a modality-specific graph VAE to refine the feature transformation process by modeling regulatory relationships between chromatin regions and genes. It learns not only local but also global information. With a scalable adversarial alignment, GLUE also enables the integration of three modalities such as gene expression, chromatin accessibility, and DNA methylations.\nBiolord[45] is a deep generative method designed to predict cellular responses to unseen drugs and genetic perturbations. It uses an autoencoder to separately encode multiple attributes of cellular identity, along with a single encoding for unknown attributes. This setup defines a decomposed latent space, serving as the input for the generative module to provide measurement predictions. The"}, {"title": "Autoencoder", "content": "authors claim this design disentangles the representation with respect to known attributes. However, further exploration of the representation of unknown attributes would enhance the model's generalizability.\nHetzel et al. introduced ChemCPA[46] a model that incorporates knowledge about compound structures and transfers bulk RNA-seq data into both identical and different gene sets between source (bulk) and target (single-cell) datasets. It uses an encoder-decoder architecture with adversarial training, allowing the model to disentangle representations of various attributes and study the effects on specific sources. Although the model was evaluated on unseen compounds, it would be more interesting if it could also work on unseen cell lines."}, {"title": "Transformer", "content": "In research areas such as natural language processing (NLP) and computer vision (CV), Transformer as highlighted by the attention mechanism has gained significant attention in recent years, as evidenced by its successful deployment in foundation models. Pioneering models such as BERT [71], GPT[72, 73], PaLM[74, 75], and LLaMA[76] have set benchmarks in NLP as well as DALL-E[77] in CV have made significant contributions to various downstream tasks.\nIn a biological context, similar to how words construct a sentence, genes construct cells. Analogous to how natural language acts as a foundational layer for interpreting human behavior, the transcriptome similarly serves as a fundamental layer for unraveling the intricacies of gene regulatory mechanisms in biology. Studies have utilized single-cell transcriptomic data to construct pre-trained foundation models, such as scGPT[47], Genefomer[78] and scFoundation[79]. The representative work scGPT constructed the first foundation model through pretraining on over 10 million cells with a 12-layered transformer architecture. It also supports multiple omics data integration from paired data sources. The utilization of the self-attention approach over genes enables the encoding of gene-gene interaction, and the cell conditional tokenization also allows the model to learn cell-specific information, such as different batches and sequencing modalities. However, this technique is constrained by paired data, and exhibits limited reliability in zero-shot settings [80].\nWhile foundation models have achieved notable successes in a variety of downstream tasks, their potential has not yet been leveraged for cross-species data integration. However, the conserved nature of gene regulatory mechanisms across different species presents an outstanding opportunity to delve into the complexities of gene regulation through such integrative analysis. Bridging the cross-species analytical gap, GeneCompass [14] emerges as an innovative foundation model, extensively pre-trained on a vast dataset comprising over 120 million single-cell transcriptomes from human and mouse origins. It integrates gene IDs, expression values, and prior knowledge together as gene tokens, implementing a 12-layer transformer model for encoding encoding. It also facilitates a variety of downstream tasks through supervised learning, encompassing gene regulatory network elucidation, predictions of drug effects, gene dosage implications, and cellular responses to perturbations. However, GeneCompass is limited to"}, {"title": "Transformer", "content": "transcriptomics data."}, {"title": "Other techniques (contrastive learning etc.)", "content": "SATURN[48] stands out as the first model that combines protein embeddings, generated using large protein language model ESM2[81], with gene expression from scRNA-seq datasets. Overcoming the challenges of absent direct one-to-one orthologs, it couples protein embeddings with gene expression, employing soft clustering to form 'macrogene' groups. This approach allows the model to learn universal cell embeddings that bridge differences between individual single-cell experiments even when they have different genes. It combines training with conditional autoencoders with ZINB loss inspired by Lopez et al. [38], and other learning metrics by forcing the different cells within the same dataset far apart using weakly supervised learning and similar cells across the dataset closer to each other in an unsupervised manner. But it requires paired information.\nscCLIP [49] introduces a novel application of transformers to scATAC-seq data, drawing inspiration from the contrastive learning principles of CLIP [82], it trains a pair of transformer-based encoders on multimodal single-cell data, utilizing a contrastive loss function for optimization. The result is scCLIP's adeptness at integrating multimodal data into a singular, unified embedding space, with the scalability to accommodate extensive tissue and organismal data from large-scale atlas projects.\nRecent applications of optimal transport (OT) in single-cell data analysis have enabled the identification of cellular dynamics and the alignment of multi-omics datasets. MatchCLOT[50] leverages these advancements by training two modality-specific encoders to project single-cell multimodal measurements onto a unified latent space. A novel OT algorithm is then employed for the soft-matching of cells between modalities, using batch labels to narrow the search space and mitigate distribution shifts."}, {"title": "Multi-modal supervised learning", "content": "Yang et al. [51] propose a method using autoencoder across different modalities to achieve integration, each modality is encoded using a local network, such as a convolutional network for image data, fully connected network for sequence data (RNA-seq and ATAC-seq), graph convolutional network for Hi-C. The joint representations are learned from the shared latent space, facilitating the translation between different modalities via a combination of encoders and decoders.\nFaisal et al. [52] adopt a deep learning-based multimodal fusion algorithm to integrate H&E whole slide images (WSIs) and molecular profile features, including Copy-Number of Variation (CNV), RNA-seq, and Mutation Status (MUT). Their method is particularly rigorous for its comprehensive application in survival prediction and patient risk stratification, enhanced by a focus on interpretability through the analysis of feature importance and gene attributions."}, {"title": "Multi-modal supervised learning", "content": "Deep Subspace Integration Representation (DSIR) [53] represents another technique for multi-modality integration, utilizing deep subspace learning to simultaneously learn the local and global structures. By constructing a consensus similarity matrix, DSIR finetunes its model for cancer subtype identification through spectral clustering.\nSimilarly, DLSF[54] also obtains the self-representation coefficient matrix for disease subtype identification, what it differs from DSIR is the exploration of the shared global similarity structure, because DLSF uses cycle autoencoders with a shared self-expressive layer to adaptively extract a consistent sample manifold a multi-omics level.\nMoreover, A geometrical approach Module-based Omics Data Integration MOMA [55] vectorizes genes and modules, using the vector sum of genes within a module to represent it. The incorporation of an attention mechanism as a mediator allows the model to identify the most related modules among multiple omics data types, by training with various tasks of predicting phenotypes.\nFor all the multi-modal techniques mentioned above, despite their potential for cross-modal integration, those approaches require paired data from the various modalities and are tailored to individual cancer types, limiting their generalizability."}, {"title": "Knowledge graph and other techniques", "content": "Graph (network) representation has been widely applied in systems biology to represent biological organizations and interactions [83]. It is successful in integrating diverse types of biological and chemical data for representing genotype-environment-phenotype relationships [84]. Compared with multi-modal supervised learning, graph learning directly encodes complex interactions between entities and captures semantic relationships underlying data. This allows for the seamless integration of information from diverse sources, the deduction of new information based on existing knowledge, and a deeper understanding of context and interconnections between entities.\nLee et al. [56] propose a machine learning model to predict cancer response to immune checkpoint inhibitors (ICIs). The network is constructed on cell-cell communication with cell types as nodes and communication strength as edges, which is deconvoluted from the patient's bulk tumor transcriptomics data. The model can also identify key communication pathways that are consistent with single-cell level information. However, the graph is shallowly designed and more sophisticated deep learning models could be utilized to reveal complex relationships.\nBioBridge [57] is representative of the integration of multimodal foundation models. To overcome the singularity of foundation models by applying knowledge graphs to learn the transformation between one unimodal foundation model and another, and only the bridge module needs training while all the base foundation models are kept fixed, resulting in great computational efficiency. A various range of prediction tasks can be performed via BioBridge including cross-modality retrieval tasks, semantic similarity inference, protein-protein in-"}, {"title": "Knowledge graph and other techniques", "content": "teraction, and cross-species protein-phenotype matching. But it lacks quantitative evidence for molecular generation tasks.\nThe OFA [58] approach suggests using text-attributed graphs to represent the diverse cross-domain attributes and connections in a graph to combine various types of graph data. This method involves converting these descriptions into feature vectors in the same embedding space using language models, regardless of their original domain. Additionally, the method introduces \"nodes-of-interest\" to standardize how we approach different graph-related tasks using a single task. OFA also uses a unique method called graph prompting by adding special structures to the graph that act like prompts, allowing the model to perform a wide range of tasks without fine-tuning. The model is designed to handle various fields, such as citation networks, molecular structures, and knowledge bases. Despite the strengths of this method, the performance for individual tasks seems suboptimal.\nIntegrating deep learning with a knowledge graph of gene-gene interactions, GEARS[59] predicts transcriptional responses to both single and multigene perturbations using single-cell RNA sequencing data from perturbational screens. It employs a Graph Neural Network (GNN) to study genetic relationships and perturbational expression changes, enabling predictions for gene combinations not experimentally perturbed. However, the model is limited to the same cell type or experimental condition, and its reliance on combinatorial perturbational data introduces confounding factors that need further addressing."}, {"title": "Challenges in machine learning techniques", "content": "Despite significant progress in applying machine learning to the integration of multi-omics data and predictive modeling of genotype-environment-phenotype relationships, several challenges persist. These include the need for biologically informed representation learning, scarcity and ambiguity of labeled data, inability to generalize out-of-distribution, and dealing with incomplete and noisy graphs."}, {"title": "Need for biologically informed representation learning", "content": "A fundamental hurdle arises from the multi-level hierarchical organization of biological systems, as discussed in the Introduction section. On one hand, multiple statistically insignificant variations at a lower level can collectively result in significant changes at a higher level (e.g., gene expression)[85]. Hence, a network biology approach is imperative to enhance biological signals [86]. On the other hand, many genotypes exert a pleiotropic effect on complex diseases and traits[87]. Consequently, a higher-level endophenotype demonstrates greater discriminatory power concerning the organismal phenotype than a lower-level one. Therefore, a cross-level modeling approach is necessary to simulate the asymmetrical information transmission process between genotype and phenotype[88]."}, {"title": "Need for biologically informed representation learning", "content": "This, in turn, will enhance model interpretability and facilitate the elucidation of molecular underpinnings of phenotypes [89, 90]."}, {"title": "Scarcity and ambiguity of labeled data", "content": "The scarcity of labeled data significantly hinders the application of machine learning in the predictive modeling of genotype-environment-phenotype relationships through multi-omics data. Current multi-modal learning often necessitates paired omics data with shared labels, a challenge exacerbated by the infrequent availability of such labeled data in many instances. For example, transcriptomics and proteomics data from the brain tissues of Alzheimer's disease patients can only be obtained from post-mortem persons. Consequently, constructing a practical machine learning model for living patients relies on genomics or brain imaging data, despite transcriptomics and proteomics data exhibiting stronger predictive power for phenotypic responses to drug treatments and other environmental influences than genomics and brain imaging data.\nThe issue of phenotype label ambiguity is a concern that has not received sufficient attention in machine learning. Recent efforts, including the Phenotype and Trait Ontology (PATO) [91], pave the way to address this problem. PATO provides a standardized vocabulary for describing phenotypic qualities in a manner that can be consistently applied across different species. However, additional efforts are needed to incorporate ontologies into machine learning models."}, {"title": "Inability to generalize out-of-distribution", "content": "A more pressing data issue emerges with an out-of-distribution (OOD) scenario, where new unseen cases differ significantly from the data used to train the model[92]. Technological limitations and human biases have illuminated only a fraction of the vast biological and chemical universe. For instance, among over 20,000 human genes, only proteins encoded by hundreds of genes have known small molecule ligands, without accounting for isoforms, protein complexes, mutation states, and conformations. Despite an estimated 1060 small organic molecules in the chemical space, only approximately 108 have known bioactivities. Single-cell profiling techniques have generated omics data for numerous cell types, but only around 100 of them have controlled perturbations and functional genomics readouts. The combined space of chemicals, biomolecules, and endo- and organismal phenotypes is staggeringly vast [93].\nAnother significant issue arises due to a notable distribution shift from in vitro to in vivo settings. This shift often results in disease models failing to accurately reflect the efficacy and toxicity of drugs in humans. There is a critical need for a computational approach that can effectively disentangle confounding factors while preserving unique features. Existing methods that fail to adequately address confounding factors often overlook their connection to clinical outcomes. A more systematic approach is required to address this challenge."}, {"title": "Inability to generalize out-of-distribution", "content": "To address the OOD problem, it becomes imperative to quantify the prediction uncertainty of new cases [94, 95]. Uncertainty quantification is particularly critical in high-stakes applications like drug discovery and precision medicine. Given the resource-intensive nature of drug discovery, uncertainty quantification aids in decision-making by offering insights into the confidence levels associated with predictions. In precision medicine, where erroneous predictions about drug efficacy or safety can have severe consequences, uncertainty quantification is essential for assessing the risks associated with model predictions."}, {"title": "Incomplete and noisy graphs", "content": "In the realm of predictive modeling for genotype-environment-phenotype relationships, two key issues within graph learning remain inadequately addressed: the incorporation of novel nodes lacking previously recognized connections in an established graph model and the identification of dubious or conflicting relationships.\nThe construction of a high-quality graph model for a biological system is a labor-intensive, domain-specific task that often demands manual data curation. Furthermore, the graph model may fall short in capturing implicit knowledge and intricate patterns not explicitly represented in the data, restricting its ability to unveil novel discoveries. This limitation is particularly critical in biology, where a vast number of biological and chemical entities remain uncharted, lacking any annotations. These unannotated nodes become isolated in the graph model, impeding inference for them. For instance, a drug-like chemical compound lacking significant structural similarity to existing drugs and without known protein targets becomes an isolated node in a drug-gene-disease graph. It becomes impractical and unreliable to infer its associations with diseases.\nVarious machine learning-based automatic processes have been developed to enhance graph models, such as predicting gene-disease associations through Natural Language Processing [96, 47, 48, 14], and drug-target interaction predictions[97, 98, 99]. However, these predicted relationships may be inaccurate, resulting the introduction of false positives and conflicting relationships. Few attention have been paid to addressing the issue of dubious relationships in the knowledge graph, especially when it is generated from biomedical publications many of which cannot be reproduced [100, 101, 102]."}, {"title": "AI-powered knowledge-enriched multi-scale genotype-environment-phenotype predictive modeling", "content": "Recent advances in deep learning, coupled with the growing accessibility of multi-omics data, have opened avenues for predicting emergent phenotypes through novel perturbations under diverse genotypes. Leveraging these developments, we propose two complementary approaches and their combinations: (1) biology-inspired end-to-end multi-modal multi-task deep learning, (2) physics-informed context-specific multi-scale knowledge graphs."}, {"title": "Biology-inspired end-to-end multi-modal multi-task deep learning", "content": "Compared to classical machine learning, one of the unique features of deep neural networks is their capacity for end-to-end learning. End-to-end learning tackles a complex task from inception to completion, as opposed to dividing the task into smaller sub-tasks and addressing them independently. In the context of predictive modeling for genotype-environment-phenotype relationships, an end-to-end deep neural network explicitly models asymmetric information flows from DNAs to RNAs to proteins to metabolites and ultimately to the organismal phenotype, following the central dogma of molecular biology, as illustrated in Figure 2. A foundation model for each data modality can be pre-trained and fine-tuned using modality-specific unlabeled and labeled data. When paired data across two biological levels is available, the models from different levels can be connected through contrastive learning [88], transfer learning[103], or other techniques[104]. With labeled organismal phenotype data, all modalities are interconnected and fine-tuned from genotypes to phenotypes. Environmental factors can be applied to any level, contingent on the nature of influences and perturbations - examples include CRISPR-Cas9 on DNA, RNAi on RNA, and small molecule inhibitors on proteins. Utilizing a fully-trained end-to-end model, it becomes feasible to incorporate endophenotype information, even if it cannot be directly obtained (such as brain tissue proteomics for a living AD patient), thereby improving predictions of organismal phenotypes from a genotype."}, {"title": "Biology-inspired end-to-end multi-modal multi-task deep learning", "content": "The biology-inspired end-to-end model can address the OOD and label scarcity problem from various perspectives. The pre-trained foundation model has exhibited notable generalization capabilities. For instance, the protein language model has proven successful in tasks such as protein structure predictions[105], protein design [106], and predicting protein-chemical interactions[97]. Contrastive learning has proven successful in integrating multi-omics data, as demonstrated in the previous section. Notably, several proof-of-concept studies have shown the promise of end-to-end models that adhere to the multi-level organization of a biological system. For example, the Cross-Level Information Transmission (CLEIT) network employs transcriptomics endophenotypes as an intermediate layer to connect genomic mutations with cellular phenotypes through"}, {"title": "Biology-inspired end-to-end multi-modal multi-task deep learning", "content": "contrastive learning[88]. This approach enhances phenotype predictions from genotypic data. Leveraging transfer learning, TransPro predicts proteomics profiles induced by unobserved chemicals based on transcriptomics data[103]. It is observed that predicting organismal phenotypes via predicted and imputed proteomics signatures by TransPro is more accurate than relying on experimentally determined transcriptomics or proteomics data, which often suffer from noise and sparsity. Combining contrastive learning with multi-task learning guided by clinical features, Guided-Stab achieved survival prediction by cancer transcriptomics[104]. An end-to-end model, which links genotypes to phenotypes by integrating multiple endophenotypes based on their biological relationships, is anticipated to offer a robust tool for establishing causal genotype-environment-phenotype relationships."}, {"title": "Personalized physics-informed multi-scale knowledge graph", "content": "Considering the elevated incidence of false negatives and false positives in relationships, as well as the presence of coarse-grained and ambiguous phenotypes in current biological network models, we propose three solutions to harness the potential of graph learning for predictive modeling of genotype-environment-phenotype relationships. These solutions comprise (1) the explicit representation of physical interactions within molecular networks, (2) the construction of context-dependent networks with fine-grained phenotypes, and (3) the development of multi-scale network models.\nGenotype-phenotype relationships in many existing network models, such as gene-disease networks, primarily rely on statistical correlations derived from Genome-Wide Association Studies (GWAS). Without insight into the underlying molecular interactions, determining the molecular drivers responsible for a phenotype and predicting phenotypic responses to novel perturbations becomes challenging. By incorporating quantitative details of molecular interactions into the network, it becomes possible to rationalize how molecular changes may impact phenotypes. For example, mutations in DNA sequence can alter regulatory DNA-protein, regulatory RNA-protein, or protein-protein interactions, subsequently influencing the binding affinity or kinetics of these interactions, leading to changes in gene expression, signaling transduction, or metabolism. Illustrated in Figure 3, representing these interactions in a network model with weighted and signed edges encoding the degree (or certainty) and direction of interaction changes allows for more confident inference of causal genotype-phenotype relationships[107]. High-throughput techniques have emerged to explore understudied molecular interactions[108, 109]. New machine learning methods, e.g., model-agnostic semi-supervised meta-learning, can efficiently explore OOD drug-target interactions, metabolite-enzyme interactions, and microbiome metabolite-human receptor interactions[110]. Transfer learning enables predicting functional activities of ligand binding, i.e., antagonist vs agonist[111]."}, {"title": "Personalized physics-informed multi-scale knowledge graph", "content": "Many existing network models are canonical aggregations across different conditions. For instance, in a gene-disease network, Alzheimer's disease\u201d (AD) is often depicted by a single node, and the gene-gene interaction network remains constant across all diseases. However, AD has several subtypes resulting from different etiologies (e.g., APOE4 vs. TREM2). Similarly, the gene-gene interaction network undergoes rewiring dependent on biological contexts (such as cell types, disease stages, and species). This coarse-grained representation falls short of capturing the complexities of biology. We propose to decompose the aggregated network model into an interconnected multiplex network model. Each plex in the network represents a subtype or an individual. In the case of a gene-disease network, using disentangled embeddings of disease biomarkers (e.g., brain imaging for AD), a subtype of AD or an individual patient (i.e., phenotype) can be represented by a class-specific embedding and a subtype/individual-specific embedding, which can be derived from patient-level data like medical imaging and electronic health records. Subtype/individual-specific gene-gene interaction networks can be derived from gene embeddings learned from a large language model[47, 78]. It is anticipated that such a fine-"}, {"title": "Personalized physics-informed multi-scale knowledge graph", "content": "grained network model will be more potent in predictive modeling of genotype-environment-phenotype relationships compared to a coarse-grained aggregated model.\nThe inherent complexity and hierarchical organization of a biological system naturally lend themselves to representation on a multi-scale. For instance, a tissue can be portrayed through a cell-cell interacting network, and each cell can be captured by a cell type-specific gene-gene interacting network. Algorithmically, a multi-scale cell-cell interacting network can be conceptualized as a network of networks. While the network of networks concept has found widespread application in modeling areas such as the internet, smart cities, social networks, supply chains, telecommunications, cloud computing, and financial systems[112], its utilization in systems biology remains relatively limited[113]. Given the abundance of single-cell and spatial omics data, there is a compelling opportunity to explore the application of the network of networks paradigm for omics data integration and analysis in systems biology."}, {"title": "Integration of machine learning models, knowledge graphs, and generative AI", "content": "The proposed machine learning and knowledge graph approaches mentioned above are complementary. Integrating these two approaches will further enhance the predictive power of genotype-environment-phenotype relationships. Although the machine learning model excels at discerning subtle patterns from raw data and augmenting missing links within a knowledge graph, it may lack a comprehensive understanding of the global contexts of these patterns. Conversely, a knowledge graph can consolidate patterns into a cohesive network within a broader context. Inference of missing links from a knowledge graph can both validate and refute predictions made by a machine learning model.\nBoth machine learning models and knowledge graphs, which focus on predictive analytics, can benefit from integration with generative AI models. On one hand, a generative model can enhance predictive models in several ways. Generative models have the capability to generate synthetic data samples that closely resemble real data. These synthetic samples can effectively augment the training dataset of predictive models, particularly in scenarios where real data is limited. Furthermore, generative models can learn the underlying distribution of observed data, enabling them to identify outliers or OOD cases effectively. Additionally, they can be utilized to impute missing values by generating plausible values conditioned on the observed data. On the other hand, machine learning models can enhance personalization and mitigate hallucination in generative models through techniques such as reinforcement learning, attention mechanisms, conditional generation, active learning, and others 4."}, {"title": "Conclusion", "content": "The fusion of multi-omics data and AI techniques marks a significant advancement in comprehending complex biological systems and predicting outcomes across diverse environments and perturbations. In this paper, we have explored the interleaved interactions between genotype, environment, and phenotype, highlighting the pivotal role of endophenotypes as intermediate markers linking genetic makeup to observable traits. Central to our discussion is the integration of multi-omics data, spanning various biological levels from single cells to whole organisms, and encompassing different data modalities and species. We have addressed the shortcomings of current machine learning methods, particularly in accurately predicting causal relationships between genotype, environment, and phenotype. Our proposed framework, inspired by biology and driven by AI, aims to untangle the complexities of living organisms and lay the groundwork for personalized medicine.\nIt is important to underscore that AI alone cannot accomplish our objectives. A comprehensive representation of human biology and physiology needs a digital twin that captures micro and macro dynamics of the human body and its interactions with the environment[114, 115, 116]. This necessitates the integration of AI with mechanism-based modeling, a promising technique for addressing challenges in machine learning. For example, constraint-based metabolic network modeling can predict organismal phenotypes directly, such as growth"}, {"title": "Conclusion", "content": "rates under diverse conditions. Unlike black box machine learning models, mechanism-based models explicitly represent system processes and interactions, offering insights into underlying principles. Leveraging existing knowledge, they can make predictions even with limited data, exhibiting greater generalizability across scenarios. Their transparency facilitates interpretation and understanding of influencing factors, crucial for applications like biomedicine. Additionally, the seamless integration of prior knowledge enhances prediction accuracy and relevance. In conclusion, A biology-inspired AI model, coupled with mechanism-based modeling, holds considerable promise for advancing our understanding of genotype-environmental-phenotype relationships and informing critical decision-making."}]}