{"title": "AI-driven multi-omics integration for multi-scale\npredictive modeling of causal\ngenotype-environment-phenotype relationships", "authors": ["You Wu", "Lei Xie"], "abstract": "Despite the wealth of single-cell multi-omics data, it remains challenging to predict the consequences of novel genetic and chemical perturbations in the human body. It requires knowledge of molecular interactions at all biological levels, encompassing disease models and humans. Current machine learning methods primarily establish statistical correlations between genotypes and phenotypes but struggle to identify physiologically significant causal factors, limiting their predictive power.\nKey challenges in predictive modeling include scarcity of labeled data, generalization across different domains, and disentangling causation from correlation. In light of recent advances in multi-omics data integration, we propose a new artificial intelligence (AI)-powered biology-inspired multi-scale modeling framework to tackle these issues. This framework will integrate multi-omics data across biological levels, organism hierarchies, and species to predict causal genotype-environment-phenotype relationships under various conditions. AI models inspired by biology may identify novel molecular targets, biomarkers, pharmaceutical agents, and personalized medicines for presently unmet medical needs.", "sections": [{"title": "Introduction", "content": "A fundamental challenge in the field of biology is to predict phenotypes, which\nare the observable traits of an organism, considering the complex interaction\nbetween various genetic makeups (genotypes) and environmental influences and\nperturbations[1]. The genotype refers to the hereditary information stored in an\norganism's DNA, whereas the phenotype refers to the manifestation of that ge-\nnetic information at the organismal level. In addition to genetics, environmental\nfactors such as nutrition, pollution, infections, radiation exposure, microbiota,\nand drug usage play a role in shaping and altering phenotypes.\nThe phenotype can be defined by observable physical characteristics (e.g., eye\ncolor), behavioral patterns (e.g., memory), physiological functions (e.g., blood\npressure), and clinical manifestations (e.g., pain), among others. However, the\norganism's phenotype does not immediately rise from its genotype. There ex-\nist several intermediate phenotypes, known as endophenotypes[2], which delin-\neate molecular attributes at an intermediate level of organization, complexity,\nor scale between the molecular/genetic level and the organismal phenotype.\nThe endophenotype typically includes RNA expression, protein expression and\npost-translational modifications, metabolite concentrations, and so on. To es-\ntablish causal linkages between genotype, environment, and phenotype, it is\nessential to utilize endophenotype as a means to connect the genotype and the\nphenotype of an organism. Firstly, the endophenotype encompasses the biolog-\nical mechanisms that link the genetic makeup to the final organismal pheno-\ntype. Additionally, alterations in endophenotypes occur before or concurrently\nwith modifications in the organismal phenotype. Therefore, endophenotypes\nare more responsive markers of genetic or environmental impacts compared to\nthe organismal phenotype. Furthermore, endophenotypes are frequently able\nto be objectively measured and quantified. This facilitates the replication and\ncomparison of data across many investigations, as well as the development of\ncomputer models. Ultimately, endophenotypes serve as biomarkers, such as \u03b2\n-amyloid indicating Alzheimer's disease, for clinical disorders. They also offer\nspecific targets that are linked to the causes of diseases, which in turn facilitates\nthe development of effective and safe therapeutic interventions.\nThe latest development in sequencing and high-throughput technology has\ngenerated a vast amount of multiple omics data including but not limited to\ngenomics, epigenomics, transcriptomics, proteomics, metabolomics, lipidomics,\nglycomics, cytomics/cellomics, microbiomics, metagenomics, radiomics, inter-\nactomics, and chemical genomics[3]. With the exception of genomics and epige-\nnomics data that characterize genotypes, and microbiomics, metagenomics and\nchemical genomics data that provide information about environmental factors,\nmost omics data reveals the molecular landscape of distinct endophenotypes at\nvarious levels. These omics data are crucial in linking genetic information to\nphenotypic outcomes and predicting phenotype responses to environments. For\nexample, analyzing transcriptomics data identifies which genes are upregulated\nor downregulated in response to genetic variations or environmental perturba-\ntions. Proteomics data aids in connecting genetic information to proteins that"}, {"title": "", "content": "carry out most cellular functions. Metabolites are the end products of many cel-\nlular processes. They reflect the functional output of the genome, transcriptome,\nand proteome of an organism and environment, and capture the organism's re-\nsponse to external stimuli and environmental influences.\nWhile each omics type provides a unique perspective on the molecular pro-\ncesses occurring within cells, tissues, or organisms, it is essential to combine\nall layers of omics data in order to fully understand the complexity and in-\nterdependencies of biological systems[4]. Firstly, rooted in the central dogma\nof molecular biology, it is necessary to connect multiple levels of omics data,\nencompassing DNAs, RNAs, proteins, and phenotypic outcomes, in order to\ngain a full understanding of how genetic information is converted into func-\ntional molecules and eventually, phenotypes. Secondly, integrating data across\nseveral omics levels enables identification of key regulatory elements that act as\ncritical points of control in cellular pathways and the complex interactions and\nfeedback loops that govern cellular processes. Finally, individual omics datasets\nonly provide partial information about a biological system. Their integration\nwill enhance the predictive power of computational models that aim to establish\na connection between genetics and phenotype.\nThe human body consists of a diverse array of cell types (e.g., epithelial cells,\nblood cells, immune cells, etc.) The organization of the human cells follows\na hierarchical structure. Cells combine to form tissues, tissues form organs,\nand organs work together to create a functional organism. Cells communicate\nthrough chemical signals such as hormones and neurotransmitters. The progress\nin single-cell and spatial omics techniques makes it possible to observe and\nquantify heterogeneous cellular processes and cell-cell communications across\nthe hierarchy of an organism at a single-cell resolution[5, 6, 7, 8]. Spatial single-\ncell omics data will be the cornerstone to link molecular events to organism\nphenotypes [9, 10, 11, 12]. Thus, it is critical to integrate omics data across\nbiological scales from cell to tissue to organ to organism.\nIn addition to the integration of omics data across various biological lev-\nels and across organismal scales, it is imperative to also integrate omics data\nacross different species [13, 14, 15]. Omics studies conducted in model systems\nare essential for enhancing our understanding of biology. This is due to specific\nadvantages offered by model organisms, such as short generation times, ease\nof genetic manipulation, and similarities to more complex organisms including\nhumans. Model organisms have long been instrumental in investigating the\nfunctions of specific genes and the regulatory mechanisms that control them.\nThey have also helped in comprehending cellular processes, tissue formation,\nand organ development, as well as shedding light on the genetic factors in-\nfluencing complex behaviors. Genetically engineered models are indispensable\ntools for understanding the molecular mechanisms underlying diseases, evalu-\nating possible treatments, and assessing the safety and efficacy of therapeutic\ninterventions. As stated by Theodosius Dobzhansky, \"Nothing in biology makes\nsense except in the light of evolution\" [16]. Comparative genomics studies iden-\ntify the similarities and differences in the genomes of different species, leading to\nunderstanding the genetic basis of human traits and diseases. Recent advances"}, {"title": "", "content": "in functional genomics such as CRISPR-Cas9 and perturb-seq make it possible\nto assess gene functions and dissect gene regulatory networks on a large scale.\nAs the amount of multi-omics data from model organisms becomes more acces-\nsible, there is a need for innovative methods to transfer this knowledge from\nmodel organisms to humans. This will facilitate advancing fundamental and\ntranslational biomedical sciences.\nCross-level, cross-scale, cross-species multi-omics data integration and pre-\ndictive modeling of causal genotype-environment-phenotype relationships will\nnot only provide new knowledge about the basic principles of life but also be\nthe driving force for the identification of new molecular targets, biomarkers,\npharmaceutical agents, and personalized medicines for unmet medical needs, as\nshown in Figure 1. The target-based drug discovery and development approach,\nwhich follows the human genome revolution and now dominates the pharma-\nceutical industry, is widely recognized for its time-consuming, expensive, and\nunproductive nature. Artificial Intelligence (AI) shows great potential in expe-\nditing the process of drug discovery. Nonetheless, if adhering to the current drug\ndiscovery paradigm, AI may merely make failures faster and cheaper but not\nimprove the success rate of identifying effective and safe treatments for incurable\nailments. As highlighted by Bender et al.[17], there exists a substantial disparity\nbetween molecules that are optimized for target binding affinities or other proxy\nobjectives and medications that demonstrate both clinical efficacy and safety.\nA survey conducted recently indicates that over 90% of the medications that\nhave been approved are derived from the process of phenotype drug discovery\nand development[18]. However, conventional phenotype screening approaches\nbased on cellular or organismal phenotypes are medium- or low-throughput and\nlack information about drug modes of action.\nPerturbation functional omics profiling offers a quantitative, mechanistic,\nand high-throughput phenotype readout for compound screening, thereby boost-\ning the power of phenotype drug discovery[19]. Nevertheless, the molecular\nomics profiles only characterize endophenotypes. It remains a challenge to con-\nnect endophenotypes to clinical outcomes. Moreover, due to the impractical-\nity of measuring compound responses in a living patient, we must rely on a\nmodel system during the early and pre-clinical stages of drug discovery and\ndevelopment. In order to accurately translate chemical activity observed in a\nmodel system to the effectiveness and side effects of a medicine in a clinical\nsetting, it is necessary to have an unbiased and comprehensive phenotype read-\nout that bears information of target transferability, drug mode of action and\npharmacokinetics. An integrated molecular profile derived from transcriptomic,\nproteomic, metabolomic, and other endophenotypes both before and after the\ntreatment of tested compounds is highly suitable for this objective and has\nshown potential in phenotype compound screening [20] and physiologically based\npharmacokinetics[21].\nIn summary, elucidating genetic and molecular underpins of complex hu-\nman traits and disorders, as well as predicting organismal phenotypes under\nthe interplay of diverse genotypes and environmental perturbations, requires\nintegrating multiple omics data across data modalities, biological levels, and"}, {"title": "Perturbation omics data resources", "content": "Predictive modeling of phenotypes from genotypes under perturbations needs\nlabeled data. A large number of perturbation omics data have been collected.\nAlthough these data are highly biased to certain biological conditions (cell types,"}, {"title": "State-of-the-art of machine learning methods\nfor multi-omics data integration and predic-\ntive modeling", "content": ""}, {"title": "Unsupervised learning", "content": "One of the major technical challenges faced by multi-omics data integration is\ndata distribution shifts. The data shift in omics data mainly comes from two\nsources: technical confounders such as batch effects and biological confounders\n(e.g., sex, age, disease state, etc.). Traditional statistical methods provided a\nfoundation for multi-omics data integration. These approaches encompass a va-\nriety of techniques including correlation-based analysis (e.g., BindSC[60], Seurat\nv3[61], Scanorama[62] and MaxFuse[63]), matrix factorization (iNMF[64] and\nLIGER[65]), Bayesian-based methods (MOFA+[66]), nearest neighbor-based\n(e.g., fastMNN [67] and Seurat v4[68]), and dictionary learning (e.g., Seurat\nv5[69]). Our focus, however, is on deep representation learning methods, which\nhave shown great promise in addressing the aforementioned challenges. The rep-\nresentative techniques include autoencoder, transformer, and contrastive learn-\ning. The power of these methods comes from the fact that they do not need\nlabeled phenotypic data that is scarce, and often infeasible to obtain."}, {"title": "Autoencoder", "content": "Deep generative models, particularly Variational Autoencoders (VAEs), are at\nthe forefront of analyzing complex, high-dimensional single-cell sequencing data.\nVAEs employ an encoder to interpret input data and a decoder to reconstruct\nit, learning a latent distribution. The objective that it optimizes is to mirror\nthe input while minimizing the Kullback-Leibler divergence between the latent\nembedding's prior and posterior distributions.\nscVI[38] models gene expression in scRNA-seq data using VAE with a zero-\ninflated negative binomial distribution, conditioned on batch annotations and\ntwo unobserved variables: a cell-specific scaling factor and a latent biological\nvariable. Neural networks map these latent variables to the distribution param-\neters, producing batch-corrected, normalized transcript estimates for differential\nexpression and imputation. A separate neural network, trained via variational\ninference and stochastic optimization, approximates the posterior distribution of\nlatent variables, ensuring scalable and accurate analysis of single-cell RNA-seq\ndata.\nThe same group further developed scANVI[39], which integrates semi-supervised\nlearning with cell type annotations. It can be useful for transfer labels while\nmeasuring uncertainty, especially when dealing with complex label structures\nsuch as hierarchical cell types. However, both models are limited on RNA-seq\ndata as a single modality.\nTotalVI[40] took advantage of the CITE-seq technique, which can simultane-\nously measure the abundance of the proteins on the cell surface, to provide the"}, {"title": "", "content": "opportunity for multifaceted analysis of both RNA-seq and the functional infor-\nmation in proteins. It uses VAEs to learn a joint probabilistic representation of\nthe paired measurements that counts for batch effects for both modalities. The\nRNA modeling strategy is similar to scVI [38]. The protein modeling explicitly\nhas modality-specific technical factors such as a protein background, which en-\nable a denoised view of data. However this method requires paired measured\nsamples, nor there is domain alignment consideration.\nMore recent tool Cobolt[41] introduces a symmetric multi-modal VAE net-\nwork for multi-omics data integration with a Product of Experts model (PoE)\nmodel [70]. PoE combines the variational posteriors of the multiple modalities\n(the experts) by taking their product and normalizing the result. It was trained\non paired multi-omics data to guide the integration of unpaired data, resulting\nin a joint representation of single-cell RNA-seq and ATAC-seq datasets, which\ncan be beneficial for various downstream tasks. Despite its guidance on the\nunpaired datasets, this method assumed a multinomial distribution for both\nmodalities which may cause potential information loss.\nIn contrast, MultiVI[42] employs a modality-specific noise system suited to\nboth gene expression and chromatin accessibility, with negative binomial dis-\ntribution and Bernoulli distribution respectively. In contrast to Cobolt's POE\ntechnique, MultiVI utilizes a distributional mean and penalization strategy for\na more optimized integration of latent embeddings. Moreover, its ability to\nincorporate cell surface protein abundance broadens its scope, allowing for a\nricher understanding of cellular properties.\nThe strengths of both MultiVI and Cobolt, which implemented symmetric\nmultimodal VAE for joint modality representations, are tempered by the chal-\nlenges of extreme sparsity and random noise in the datasets. These factors can\nconfound the biological variance, posing obstacles to downstream analysis and\nscalability of the model. Addressing this, scMVP[43], employs a non-symmetric\nframework that enables the construction of a unified latent space for scRNA-\nseq and scATAC-seq data. This is achieved via a clustering consistency-enforced\nmulti-view VAE, which is further enhanced by multi-head self-attention mecha-\nnisms and a cycle-GAN module, thereby increasing the robustness across both\nmodalities. However, it again requires simultaneous multi-modality measure-\nments with individual cells to function effectively.\nTo address the challenge of information loss when integrating data across\ndifferent modalities, GLUE[44] employs a modality-specific graph VAE to refine\nthe feature transformation process by modeling regulatory relationships between\nchromatin regions and genes. It learns not only local but also global informa-\ntion. With a scalable adversarial alignment, GLUE also enables the integration\nof three modalities such as gene expression, chromatin accessibility, and DNA\nmethylations.\nBiolord[45] is a deep generative method designed to predict cellular responses\nto unseen drugs and genetic perturbations. It uses an autoencoder to separately\nencode multiple attributes of cellular identity, along with a single encoding for\nunknown attributes. This setup defines a decomposed latent space, serving as\nthe input for the generative module to provide measurement predictions. The"}, {"title": "", "content": "authors claim this design disentangles the representation with respect to known\nattributes. However, further exploration of the representation of unknown at-\ntributes would enhance the model's generalizability.\nHetzel et al. introduced ChemCPA[46] a model that incorporates knowledge\nabout compound structures and transfers bulk RNA-seq data into both identical\nand different gene sets between source (bulk) and target (single-cell) datasets.\nIt uses an encoder-decoder architecture with adversarial training, allowing the\nmodel to disentangle representations of various attributes and study the effects\non specific sources. Although the model was evaluated on unseen compounds,\nit would be more interesting if it could also work on unseen cell lines."}, {"title": "Transformer", "content": "In research areas such as natural language processing (NLP) and computer vi-\nsion (CV), Transformer as highlighted by the attention mechanism has gained\nsignificant attention in recent years, as evidenced by its successful deployment\nin foundation models. Pioneering models such as BERT [71], GPT[72, 73], PaLM[74, 75], and LLaMA[76] have set benchmarks in NLP as well as DALL-E[77] in CV have made significant contributions to various downstream tasks.\nIn a biological context, similar to how words construct a sentence, genes con-\nstruct cells. Analogous to how natural language acts as a foundational layer for\ninterpreting human behavior, the transcriptome similarly serves as a fundamen-\ntal layer for unraveling the intricacies of gene regulatory mechanisms in biology.\nStudies have utilized single-cell transcriptomic data to construct pre-trained\nfoundation models, such as scGPT[47], Genefomer[78] and scFoundation[79].\nThe representative work scGPT constructed the first foundation model through\npretraining on over 10 million cells with a 12-layered transformer architecture.\nIt also supports multiple omics data integration from paired data sources. The\nutilization of the self-attention approach over genes enables the encoding of gene-\ngene interaction, and the cell conditional tokenization also allows the model to\nlearn cell-specific information, such as different batches and sequencing modali-\nties. However, this technique is constrained by paired data, and exhibits limited\nreliability in zero-shot settings [80].\nWhile foundation models have achieved notable successes in a variety of\ndownstream tasks, their potential has not yet been leveraged for cross-species\ndata integration. However, the conserved nature of gene regulatory mechanisms\nacross different species presents an outstanding opportunity to delve into the\ncomplexities of gene regulation through such integrative analysis. Bridging the\ncross-species analytical gap, GeneCompass [14] emerges as an innovative founda-\ntion model, extensively pre-trained on a vast dataset comprising over 120 million\nsingle-cell transcriptomes from human and mouse origins. It integrates gene IDs,\nexpression values, and prior knowledge together as gene tokens, implementing\na 12-layer transformer model for encoding encoding. It also facilitates a variety\nof downstream tasks through supervised learning, encompassing gene regula-\ntory network elucidation, predictions of drug effects, gene dosage implications,\nand cellular responses to perturbations. However, GeneCompass is limited to"}, {"title": "Other techniques (contrastive learning etc.)", "content": "SATURN[48] stands out as the first model that combines protein embeddings,\ngenerated using large protein language model ESM2[81], with gene expression\nfrom scRNA-seq datasets. Overcoming the challenges of absent direct one-to-\none orthologs, it couples protein embeddings with gene expression, employing\nsoft clustering to form 'macrogene' groups. This approach allows the model to\nlearn universal cell embeddings that bridge differences between individual single-\ncell experiments even when they have different genes. It combines training with\nconditional autoencoders with ZINB loss inspired by Lopez et al. [38], and other\nlearning metrics by forcing the different cells within the same dataset far apart\nusing weakly supervised learning and similar cells across the dataset closer to\neach other in an unsupervised manner. But it requires paired information.\nscCLIP [49] introduces a novel application of transformers to scATAC-seq\ndata, drawing inspiration from the contrastive learning principles of CLIP [82],\nit trains a pair of transformer-based encoders on multimodal single-cell data,\nutilizing a contrastive loss function for optimization. The result is scCLIP's\nadeptness at integrating multimodal data into a singular, unified embedding\nspace, with the scalability to accommodate extensive tissue and organismal\ndata from large-scale atlas projects.\nRecent applications of optimal transport (OT) in single-cell data analysis\nhave enabled the identification of cellular dynamics and the alignment of multi-\nomics datasets. MatchCLOT[50] leverages these advancements by training two\nmodality-specific encoders to project single-cell multimodal measurements onto\na unified latent space. A novel OT algorithm is then employed for the soft-\nmatching of cells between modalities, using batch labels to narrow the search\nspace and mitigate distribution shifts."}, {"title": "Supervised learning", "content": ""}, {"title": "Multi-modal supervised learning", "content": "Yang et al. [51] propose a method using autoencoder across different modalities\nto achieve integration, each modality is encoded using a local network, such as a\nconvolutional network for image data, fully connected network for sequence data\n(RNA-seq and ATAC-seq), graph convolutional network for Hi-C. The joint rep-\nresentations are learned from the shared latent space, facilitating the translation\nbetween different modalities via a combination of encoders and decoders.\nFaisal et al. [52] adopt a deep learning-based multimodal fusion algorithm\nto integrate H&E whole slide images (WSIs) and molecular profile features,\nincluding Copy-Number of Variation (CNV), RNA-seq, and Mutation Status\n(MUT). Their method is particularly rigorous for its comprehensive application\nin survival prediction and patient risk stratification, enhanced by a focus on in-\nterpretability through the analysis of feature importance and gene attributions."}, {"title": "", "content": "Deep Subspace Integration Representation (DSIR) [53] represents another\ntechnique for multi-modality integration, utilizing deep subspace learning to\nsimultaneously learn the local and global structures. By constructing a consen-\nsus similarity matrix, DSIR finetunes its model for cancer subtype identification\nthrough spectral clustering.\nSimilarly, DLSF[54] also obtains the self-representation coefficient matrix for\ndisease subtype identification, what it differs from DSIR is the exploration of the\nshared global similarity structure, because DLSF uses cycle autoencoders with\na shared self-expressive layer to adaptively extract a consistent sample manifold\na multi-omics level.\nMoreover, A geometrical approach Module-based Omics Data Integration\nMOMA [55] vectorizes genes and modules, using the vector sum of genes within\na module to represent it. The incorporation of an attention mechanism as a\nmediator allows the model to identify the most related modules among multiple\nomics data types, by training with various tasks of predicting phenotypes.\nFor all the multi-modal techniques mentioned above, despite their poten-\ntial for cross-modal integration, those approaches require paired data from the\nvarious modalities and are tailored to individual cancer types, limiting their\ngeneralizability."}, {"title": "Knowledge graph and other techniques", "content": "Graph (network) representation has been widely applied in systems biology to\nrepresent biological organizations and interactions [83]. It is successful in inte-\ngrating diverse types of biological and chemical data for representing genotype-\nenvironment-phenotype relationships [84]. Compared with multi-modal super-\nvised learning, graph learning directly encodes complex interactions between\nentities and captures semantic relationships underlying data. This allows for\nthe seamless integration of information from diverse sources, the deduction of\nnew information based on existing knowledge, and a deeper understanding of\ncontext and interconnections between entities.\nLee et al. [56] propose a machine learning model to predict cancer response\nto immune checkpoint inhibitors (ICIs). The network is constructed on cell-\ncell communication with cell types as nodes and communication strength as\nedges, which is deconvoluted from the patient's bulk tumor transcriptomics data.\nThe model can also identify key communication pathways that are consistent\nwith single-cell level information. However, the graph is shallowly designed and\nmore sophisticated deep learning models could be utilized to reveal complex\nrelationships.\nBioBridge [57] is representative of the integration of multimodal foundation\nmodels. To overcome the singularity of foundation models by applying knowl-\nedge graphs to learn the transformation between one unimodal foundation model\nand another, and only the bridge module needs training while all the base foun-\ndation models are kept fixed, resulting in great computational efficiency. A\nvarious range of prediction tasks can be performed via BioBridge including\ncross-modality retrieval tasks, semantic similarity inference, protein-protein in-"}, {"title": "", "content": "teraction, and cross-species protein-phenotype matching. But it lacks quantita-\ntive evidence for molecular generation tasks.\nThe OFA [58] approach suggests using text-attributed graphs to represent the\ndiverse cross-domain attributes and connections in a graph to combine various\ntypes of graph data. This method involves converting these descriptions into fea-\nture vectors in the same embedding space using language models, regardless of\ntheir original domain. Additionally, the method introduces \"nodes-of-interest\"\nto standardize how we approach different graph-related tasks using a single\ntask. OFA also uses a unique method called graph prompting by adding special\nstructures to the graph that act like prompts, allowing the model to perform\na wide range of tasks without fine-tuning. The model is designed to handle\nvarious fields, such as citation networks, molecular structures, and knowledge\nbases. Despite the strengths of this method, the performance for individual\ntasks seems suboptimal.\nIntegrating deep learning with a knowledge graph of gene-gene interactions,\nGEARS[59] predicts transcriptional responses to both single and multigene per-\nturbations using single-cell RNA sequencing data from perturbational screens.\nIt employs a Graph Neural Network (GNN) to study genetic relationships and\nperturbational expression changes, enabling predictions for gene combinations\nnot experimentally perturbed. However, the model is limited to the same cell\ntype or experimental condition, and its reliance on combinatorial perturbational\ndata introduces confounding factors that need further addressing."}, {"title": "Challenges in machine learning techniques", "content": "Despite significant progress in applying machine learning to the integration of\nmulti-omics data and predictive modeling of genotype-environment-phenotype\nrelationships, several challenges persist. These include the need for biologically\ninformed representation learning, scarcity and ambiguity of labeled data, in-\nability to generalize out-of-distribution, and dealing with incomplete and noisy\ngraphs."}, {"title": "Need for biologically informed representation learning", "content": "A fundamental hurdle arises from the multi-level hierarchical organization of\nbiological systems, as discussed in the Introduction section. On one hand, mul-\ntiple statistically insignificant variations at a lower level can collectively result\nin significant changes at a higher level (e.g., gene expression)[85]. Hence, a net-\nwork biology approach is imperative to enhance biological signals [86]. On the\nother hand, many genotypes exert a pleiotropic effect on complex diseases and\ntraits[87]. Consequently, a higher-level endophenotype demonstrates greater dis-\ncriminatory power concerning the organismal phenotype than a lower-level one.\nTherefore, a cross-level modeling approach is necessary to simulate the asym-\nmetrical information transmission process between genotype and phenotype[88]."}, {"title": "", "content": "This, in turn, will enhance model interpretability and facilitate the elucidation\nof molecular underpinnings of phenotypes [89, 90]."}, {"title": "Scarcity and ambiguity of labeled data", "content": "The scarcity of labeled data significantly hinders the application of machine\nlearning in the predictive modeling of genotype-environment-phenotype rela-\ntionships through multi-omics data. Current multi-modal learning often neces-\nsitates paired omics data with shared labels, a challenge exacerbated by the\ninfrequent availability of such labeled data in many instances. For example,\ntranscriptomics and proteomics data from the brain tissues of Alzheimer's dis-\nease patients can only be obtained from post-mortem persons. Consequently,\nconstructing a practical machine learning model for living patients relies on\ngenomics or brain imaging data, despite transcriptomics and proteomics data\nexhibiting stronger predictive power for phenotypic responses to drug treatments\nand other environmental influences than genomics and brain imaging data.\nThe issue of phenotype label ambiguity is a concern that has not received\nsufficient attention in machine learning. Recent efforts, including the Pheno-\ntype and Trait Ontology (PATO) [91], pave the way to address this problem.\nPATO provides a standardized vocabulary for describing phenotypic qualities\nin a manner that can be consistently applied across different species. However,\nadditional efforts are needed to incorporate ontologies into machine learning\nmodels."}, {"title": "Inability to generalize out-of-distribution", "content": "A more pressing data issue emerges with an out-of-distribution (OOD) scenario,\nwhere new unseen cases differ significantly from the data used to train the\nmodel[92]. Technological limitations and human biases have illuminated only a\nfraction of the vast biological and chemical universe. For instance, among over\n20,000 human genes, only proteins encoded by hundreds of genes have known\nsmall molecule ligands, without accounting for isoforms, protein complexes,\nmutation states, and conformations. Despite an estimated 1060 small organic\nmolecules in the chemical space, only approximately 108 have known bioactiv-\nities. Single-cell profiling techniques have generated omics data for numerous\ncell types, but only around 100 of them have controlled perturbations and func-\ntional genomics readouts. The combined space of chemicals, biomolecules, and\nendo- and organismal phenotypes is staggeringly vast [93].\nAnother significant issue arises due to a notable distribution shift from in\nvitro to in vivo settings. This shift often results in disease models failing to ac-\ncurately reflect the efficacy and toxicity of drugs in humans. There is a critical\nneed for a computational approach that can effectively disentangle confounding\nfactors while preserving unique features. Existing methods that fail to ade-\nquately address confounding factors often overlook their connection to clinical\noutcomes. A more systematic approach is required to address this challenge."}, {"title": "", "content": "To address the OOD problem, it becomes imperative to quantify the predic-\ntion uncertainty of new cases [94, 95]. Uncertainty quantification is particularly\ncritical in high-stakes applications like drug discovery and precision medicine.\nGiven the resource-intensive nature of drug discovery, uncertainty quantification\naids in decision-making by offering insights into the confidence levels associated\nwith predictions. In precision medicine, where erroneous predictions about drug\nefficacy or safety can have severe consequences, uncertainty quantification is es-\nsential for assessing the risks associated with model predictions."}, {"title": "Incomplete and noisy graphs", "content": "In the realm of predictive modeling for genotype-environment-phenotype rela-\ntionships, two key issues within graph learning remain inadequately addressed:\nthe incorporation of novel nodes lacking previously recognized connections in\nan established graph model and the identification of dubious or conflicting re-\nlationships.\nThe construction of a high-quality graph model for a biological system is a\nlabor-intensive, domain-specific task that often demands manual data curation.\nFurthermore, the graph model may fall short in capturing implicit knowledge\nand intricate patterns not explicitly represented in the data, restricting its abil-\nity to unveil novel discoveries. This limitation is particularly critical in biology,\nwhere a vast number of biological and chemical entities remain uncharted, lack-\ning any annotations. These unannotated nodes become isolated in the graph\nmodel, impeding inference for them. For instance, a drug-like chemical com-\npound lacking significant structural similarity to existing drugs and without\nknown protein targets becomes an isolated node in a drug-gene-disease graph.\nIt becomes impractical and unreliable to infer its associations with diseases.\nVarious machine learning-based automatic processes have been developed to\nenhance graph models, such as predicting gene-disease associations through Nat-\nural Language Processing [96, 47, 48, 14], and drug-target interaction predictions[97,\n98, 99]. However, these predicted relationships may be inaccurate, resulting the\nintroduction of false positives and conflicting relationships. Few attention have\nbeen paid to addressing the issue of dubious relationships in the knowledge\ngraph, especially when it is generated from biomedical publications many of\nwhich cannot be reproduced [100, 101, 102]."}, {"title": "AI-powered knowledge-enriched multi-scale genotype-\nenvironment-phenotype predictive modeling", "content": "Recent advances in deep learning, coupled with the growing accessibility of\nmulti-omics data, have opened avenues for predicting emergent phenotypes\nthrough novel perturbations under diverse genotypes. Leveraging these develop-\nments, we propose two complementary approaches and their combinations: (1)\nbiology-inspired end-to-end multi-modal multi-task deep learning, (2) physics-\ninformed context-specific multi-scale knowledge graphs."}, {"title": "Biology-inspired end-to-end multi-modal multi-task deep\nlearning", "content": "Compared to classical machine learning, one of the unique features of deep\nneural networks is their capacity for end-to-end learning. End-to-end learning\ntackles a complex task from inception to completion, as opposed to dividing the\ntask into smaller sub-tasks and addressing them independently. In the context\nof predictive modeling for genotype-environment-phenotype relationships, an\nend-to-end deep neural network explicitly models asymmetric information flows\nfrom DNAs to RNAs to proteins to metabolites and ultimately to the organismal\nphenotype, following the central dogma of molecular biology, as illustrated in\nFigure 2. A foundation model for each data modality can be pre-trained and\nfine-tuned using modality-specific unlabeled and labeled data. When paired\ndata across two biological levels is available, the models from different levels can\nbe connected through contrastive learning [88", "learning[103": "or other\ntechniques[104"}]}