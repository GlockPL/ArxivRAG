{"title": "Exploring the Impact of Generative Artificial Intelligence in Education: A Thematic Analysis", "authors": ["Abhishek Kaushika", "Sargam Yadav", "Andrew Browne", "David Lillis", "David Williams", "Jack Mc Donnell", "Peadar Grant", "Siobhan Connolly Kernan", "Shubham Sharma", "Mansi Arora"], "abstract": "The recent advancements in Generative Artificial intelligence (GenAI) technology have been transformative for the field of education. Large Language Models (LLMs) such as ChatGPT and Bard can be leveraged to automate boilerplate tasks, create content for personalised teaching, and handle repetitive tasks to allow more time for creative thinking. However, it is important to develop guidelines, policies, and assessment methods in the education sector to ensure the responsible integration of these tools. In this article, thematic analysis has been performed on seven essays obtained from professionals in the education sector to understand the advantages and pitfalls of using GenAI models such as ChatGPT and Bard in education. Exploratory Data Analysis (EDA) has been performed on the essays to extract further insights from the text. The study found several themes which highlight benefits and drawbacks of GenAI tools, as well as suggestions to overcome these limitations and ensure that students are using these tools in a responsible and ethical manner.", "sections": [{"title": "1. Introduction", "content": "The accelerated advancements in Artificial Intelligence (AI) over the past decade have disrupted several fields such as education [1], healthcare [2] [3], finance [4], and law [5]. Natural Language Processing (NLP) is a subfield of AI responsible for understanding, synthesizing, and generating human language [6]. Examples of applications of NLP include sentiment analysis in various languages [7] [8], hate speech detection [9] [10], machine translation [11], and question answering [12].NLP systems have evolved from early rule-based chatbots, such as ALICE [13] and ELIZA [14], to the advanced transformer-based systems [15] such as Bidirectional Encoder Representations from Transformers (BERT) [16] and A Robustly Optimized BERT Pre-training Approach (RoBERTa) [17], which have found numerous applications [18] [19].These models are pre-trained on large amounts of data and consist of parameters in the millions or billions, enabling them to capture the context of the conversation and other linguistic complexities [20] [16]. They have gained popularity due to their ability to enhance human productivity, boost creativity [21], and support personalized and continuous learning [22].\nGenerative AI (GenAI) refers to AI systems capable of creating text, audio, and images, in response to user prompts [23]. In recent years, the outstanding capabilities of GenAI tools and LLMs such as ChatGPT [24], Bing-AI [25], and Bard [26] have highlighted the potential of this technology in education [27]. The ability of ChatGPT to carry out natural sounding conversations and respond in the style requested by the user can be harnessed to develop engaging teaching aids that suit the needs of the students [28] [29]. For software development, students can use AI-assisted coding tools to generate boilerplate templates [30], perform troubleshooting and debugging [31], and generate documentation [32]. GenAI tools can function as a personalized tutor for students, encouraging an adaptive learning environment, and reducing their dependence on educators [1] [33]. OpenAI's website has provided a student's guide to writing with ChatGPT, which suggests use cases such as formatting citations, providing foundational knowledge on a new topic, providing relevant research sources, providing answers to specific questions, providing tailored and iterative feedback, and suggesting counter-arguments for a thesis [34]. However, there are several pitfalls associated with GenAI technology that can lead to concerns about academic integrity,"}, {"title": "2. Motivation", "content": "The impressive capabilities of GenAI tools such as their ability to carry out natural conversations about a wide array of topics [40], perform analysis on multimodal data [24], and generate personalized content [41], come with several risks. Although these tools can be greatly beneficial by serving functions such as automating repetitive tasks [42], and providing personal tutoring [43], they pose significant ethical concerns and can be detrimental to the learning process and development of problem-solving skills [44]. The motivation behind conducting this study is to gain insight from educator opinions about the use of GenAI in the field of education. The individual perspectives of the educators can be a helpful tool in understanding the potential advantages and challenges of this transformative technology. This can help in the effective and ethical integration of GenAI tools in educational practices to harness their potential, while avoiding potential misuse and the limitations presented by the technology."}, {"title": "2.1. Hypothesis and Research Questions", "content": "The hypothesis for this study is as follows:\nHypothesis: Educators perceive both advantages and challenges in the integration of GenAI in education.\nThe research questions formulated to explore the hypothesis are as follows:\n1. RQ1: What potential advantages of GenAI in education are uncovered through thematic analysis of educator opinions?\n2. RQ2: What potential limitations and challenges of GenAI in education are uncovered through thematic analysis of educator opinions?\n3. RQ3: What are the findings of exploratory data analysis on opinion essays?"}, {"title": "3. Methodology", "content": "In this section, the methodology used to perform thematic analysis and exploratory data analysis has been discussed."}, {"title": "3.1. Thematic Analysis", "content": "Thematic analysis is a technique to find patterns and themes within qualitative data to uncover underlying topics and ideas [45]. Figure 1 displays the steps involved in performing thematic analysis as detailed by Braun and Clarke [46]. It consists of the following steps: Familiarize yourself with the data, generate initial codes from the data, search for themes, review themes, define themes, and complete the write-up."}, {"title": "3.2. Exploratory Data Analysis", "content": "In order to perform EDA on the opinion essays, pre-processing has been performed by converting the text to lowercase, removing all stopwords, and lemmatizing the tokens. All the references, images, and headings were removed from the essays. The most common words and bigrams and extracted from the text."}, {"title": "4. Educator Opinions", "content": "In the following subsections, the opinions essays provided by the educators have been included."}, {"title": "4.1. Educator 1", "content": "Students should understand that AI chatbots are tools/resources that can help them but cannot do everything. For example, an MSc student was interested in studying a topic but did not have an appropriate dataset. They asked ChatGPT to simulate data for them. The dataset that ChatGPT created was nonsensical and highly inappropriate to answer the questions they wanted to examine. AI chatbots are not able to create simulated data without clear and explicit instructions. A possible exercise in data management and study design would be to ask AI chatbots to simulate data. Writing specific instructions to create data with an appropriate structure could be a useful exercise. Asking chatbots the right questions is the skill that needs to be learned. Concerns related to plagiarism and academic misconduct are valid in my opinion. Even though third level institutions are putting policies in place to deter students from claiming the work of AI chatbots is their own, use is still prevalent, and often difficult to detect or to prove. Several of my colleagues teaching mathematics at third level have noted that many students do not have the patience to learn mathematics. They are used to instant answers from online calculators and AI chatbots. The art of taking time to figure out a problem has been lost. This is worrying as one of the main attributes of maths graduates is problem-solving skills. Universities also need to work with primary and secondary schools so that students are not dependent on AI chatbots when they start third level education.\nIt is important that students are taught about possible biases in AI-generated content. In many cases, the methodology for producing content is not transparent or easily accessed and the relevance or accuracy of the information must be questioned. It has also been shown that there are concerns around copyright issues when using AI chatbots [47]. Students need to be educated about the potential dangers of this. A module or course on AI chatbots could be a mandatory part of every third-level degree as part of core skills to make sure students are informed about the use of such tools.\nI am teaching programming to a group studying for a master's degree in data analytics. The lectures are lab-based with a focus on solving practical problems in class. Almost all the students immediately open AI chatbots to help them with the exercises. This can help with minor fixes, but when it is used to write full functions it removes the learning to independently solve problems. It is often the case that the chatbot has written code close to correct, but students do not question the output, and without developing the skills to write functions themselves they are unable to correct and improve the chatbot generated code. Possible exercises and assignments could involve taking human or AI generated code that is partially correct and adapting it. Universities and students should be careful about adopting the use of AI-driven tools. Students could be frustrated if lecturers use chatbots, but they are not allowed to. It is important to educate students on the weaknesses of ChatGPT. For example, it regularly miscalculates simple arithmetic operations. AI chatbots are excellent at relaying facts and writing text but reduce the possibility for creativity from the learner. There is an inherent struggle when writing an essay or code that I think is a necessary struggle. It is necessary to learn techniques and problem-solving skills and it is necessary to write creatively and to grapple with new concepts. People say it is like when the calculator was introduced it will become normalised and an accepted part of education. However, as someone with over ten years of experience as an educator at third level, I have seen a very poor standard of mental maths and an over-reliance on calculators. Students could do with having better arithmetic skills in my opinion. Students with better abilities of estimation are better equipped to identify when an answer is clearly wrong and not blindly accept the calculator's answer. Similarly, an over-reliance on AI chatbots will reduce students' ability to write clearly and think independently. They will be less able to critique the output from AI chatbots which is by no means perfect."}, {"title": "4.2. Educator 2", "content": "Artificial Intelligence was consigned by many to either an academic or science fiction curiosity. Although the founding of the MIT AI lab predates the internet's inception, Artificial Intelligence has remained largely a niche research pursuit even inside academia. This changed in 2023 when Generative AI and particularly Open Al's Generative Pre-trained Transformer (GPT) Large Language Models (LLMs) attracted significant interest, popularity and familiarity amongst the general public. The conversational interface of ChatGPT introduced many to constructing prompts and refining output for the first time. It was clear that students were ahead in uptake of ChatGPT in particular than their educators! The archetypical computer science education centres on programming. Assistance was largely confined to initial code template generation and basic refactoring tools, mainly centred around languages such as Java and C# that structurally suited them. Just as Google is supplemented by domain-specific search tools, ChatGPT's generality has now been augmented by tools such as GitHub CoPilot for programming. These are now integrated into modern code authoring tools, and even traditional text editors such as emacs have interface packages available. As well as programming languages, the computing ecosystem houses a multitude of text-based information: configuration files, Infrastructure-as-code and system administration scripts. I have found that students in diverse fields such as cloud computing, data storage technologies and data architecture have been able to leverage generative AI to produce boilerplate templates. More usefully they can generate minimal working examples from which to develop and integrate their own solutions, reducing the barrier to entry of many tools, and increasing the breadth of their skillset. Early internet search engines included many operators to fine-tune searches, and whilst Google still supports them, very few users actively take advantage of them. The usefulness of output from GPT models is highly correlated to the quality of the prompts given. Learners will benefit significantly if prompt construction is integrated into information search and retrieval tutorials at an early stage. More specifically, computing students need to see appropriate use of generative AI in coding contexts by their instructors, just as they would encounter the use of refactoring tools by example. Optimal ways to use revolutionary new tools, and knowing when not to use them, is best achieved by experiential practice, not avoidance! Educators are grappling with the impact that generative AI has had on assessment, particularly highlighted by academic integrity concerns. Many essay-type assessments are at risk of being largely the work of LLMs rather than the student, including perhaps some assessments that were not fit-for-purpose in any event. Practical skill demonstration under examination conditions will probably need to form an increased part of the assessment for many applied subjects, with prohibition or explicit limits on the use of generative AI and other tooling."}, {"title": "4.3. Educator 3", "content": "After seeing first hand the impact ChatGPT can have on a student that is struggling with getting code to work in a project, ChatGPT was freely available there to fix any bugs the student was struggling with and allowed them to move on to the next part of the project without having to ask for assistance from a supervisor/lecturer. This is an invaluable resource that allows the student more independence in their learning when it should be independent learning. However this only works well when the student has already achieved the foundational learning needed in the area and is now trying to do apply more advanced techniques. The student then has enough knowledge to understand when the prompts it has given ChatGPT has actually lead to a coherent and correct answer.\nAcademic integrity has been an issue since for over a century and will continue to be an issue with the current education and research structures [48]. During the pandemic and since the pandemic, learning has moved to a more blended online learning environment. Universities were already needing to update the policies and procedures to take into account this more fluid learning environment whilst maintaining the integrity of the grades being achieved without the formal onsite externally invigilated exams. They use of these more freely available AI tools has just accelerated this need even more so than the pandemic whether the learning is primarily in class room or online.\nThe need to be more inventive with the forms of assessment are needed that even if a student is to use an AI tool, despite explicated prohibited, that you can assess whether the learning has been achieved. This might take place in many different ways whether it be; Q&A sessions with the students on a topic/project, screencasts where the student explains the work, students have to critique the work of AI tools, etc. But it does mean what has worked in the past to assess this module may not still work now and needs a lot of thought from individual lecturers and programme teams to understand what will work for their courses, ideally guided by updated institutional academic integrity policies. Formal onsite exams still have a place in this new age of learning, and it might seem like an easy solution to assessing the learning from a student without the use of AI tools. Although for many courses, in particular ICT sector of education, formal onsite exams have long been replaced with various continuous assessment strategies and formal onsite exams should not be brought back in light of these AI challenges after it was argued that is not appropriate way to measure the student's learning in the area previously. The need for a diverse set of assessment strategies are the best way to assess the students abilities [49].\nDifficult thing to do as pandemic has hindered the learning for a lot of students so given the timeframe currently I think this needs to be looked at but when the pandemic can be isolated out of the data."}, {"title": "4.4. Educator 4", "content": "The adoption of any new automation technology is fraught with potential for pitfalls, misunderstandings and misapplications. Before turning attention"}, {"title": "4.4.1. Originality Detection", "content": "Even the least tech-savvy of students and educators have some grasp of how originality detectors such as Turnitin operate. On a high level, the system has access to a vast database of text samples (both those gathered online and those submitted to the system in the past) and newly-submitted work is compared against this. Text passages that match items in the database are identified and a \u201csimilarity score\" is output. Even in this relatively straightforward scenario, misinterpretation and misapplication abounds. Firstly, tools of this type are often deceptively described as \u201cplagiarism detection\u201d [50], leading to an over-reliance on a single tool as an arbiter of what constitutes plagiarism. As noted by Meo and Talha [50], plagiarism comes in many forms and plagiarism detection is an academic judgment. \u201cWord-for-word plagiarism\u201d (which originality checkers can effectively discover) is only one aspect. Students who are compelled to submit their work through such systems often come to conflate \u201csimilarity score\" with \u201cplagiarism score\". Particularly in situations where students can see these scores and resubmit their work, a perception can grow that rephrasing the offending matching sections is sufficient to avoid plagiarism. Where reworded ideas have been taken from other sources, without attribution, a heavily-plagiarised document can yield a low similarity score. Conversely, a relatively high similarity score does not necessarily constitute plagiarism either, and it is incumbent on educators to bear this in mind. There are myriad reasons why sections may match text from a database, particularly quotations and bibliographies. A submitted work that is overreliant on lengthy quotations without commentary may be of low quality, but if cited correctly it does not constitute plagiarism. Originality checkers should only be used as a tool to identify potential cases of a specific form of plagiarism, with a human investigation necessary to verify whether or not this is the case.\nIn summary, even an understandable tool of this type can directly contribute to students misunderstanding the concepts of plagiarism, and overzealous educators making accusations of academic misconduct based on a misinterpretation of the significance of the evidence to hand."}, {"title": "4.4.2. Large Language Models", "content": "The role and capabilities of LLMs such as ChatGPT and Bard are much more difficult to understand, and as such the challenges of dealing with them in an educational setting are even more pronounced. Firstly, we should endeavour to understand, even on a basic level, how a LLM operates. In essence, it learns patterns and relationships between words, sentences and paragraphs in text, having been exposed to enormous quantities of human-created text to learn from. Then, given a \u201cprompt\u201d from a user, it generates text in response, beginning by matching the context of the prompt against its text store. As it generates the text, it uses a probabilistic approach to choose words one at a time. Based on the text it has generated thus far, it tries to predict what the next word should be. However, to avoid generating the same text in response to the same prompt each time, an element of randomness is introduced so as not to always choose the most likely word. Finally, it has a stopping mechanism that will cause the generation to end as appropriate [51]. One other aspect is that ChatGPT is also trained on actual chat logs between humans, and so it exhibits elements of personality. It is polite to a fault, apologises for perceived mistakes and appears eager to please. This leads to another observation, relating to the language that people use to describe their characteristics, and indeed their shortcomings. Because of the human-like nature of the generated text, people seem to be happy to attribute human-like explanations. It has been widely observed that ChatGPT will generate plausible-looking, incorrect references when asked to provide a bibliography [52]. Other types of referencing errors have also been observed (e.g. in law [53]). Such errors are typically described as \u201challucinations\u201d, giving them a distinctly human characteristic that implies real intelligence. Contrast this with a hypothetical AI image classifier that, presented with a photograph of a cat, predicts that it is a spaceship. In the latter situation, users are more likely to dismiss the tool's effectiveness as being simply wrong.\nThe human-like characteristic of ChatGPT ultimately means that users are more likely to trust that its output is correct. An additional issue is that ChatGPT is innumerate. Although it can recognise where a numeric value would be appropriate in the text, the specific value often bears no resemblance to the correct answer. When challenged, it will attempt to \u201ccorrect\u201d the answer (even for relatively straightforward calculations) and offer an alternative. It is notable that when GPT-4 recognises that a numeric value is required (at present, the free version of ChatGPT is based on the earlier"}, {"title": "4.4.3. Detection of LLM-Generated Content", "content": "Educators are understandably concerned at the rise in the use of ChatGPT among students to write essays and assignments. This has led to the launch of a number of products that claim to be able to differentiate AI-generated content from human-generated text. Examples include GPTZero [35] and ZeroGPT. To be fair to the creators of these products, their websites are open about the role their tools are intended to play, and give some detail about how they are created. For example, GPTZero's website states the following: 'We test our models on a never-before-seen set of human and AI articles from a section of our large-scale dataset, in addition to a smaller set of challenging articles that are outside its training distribution.' ZeroGPT's website states the following: \u2018Finally, we employ a comprehensive deep learning methodology, trained on extensive text collections from the internet, educational datasets, and our proprietary synthetic AI datasets produced using various language models.' Both therefore claim strong accuracy in differentiating between text that is 100% AI-generated and text that is 100% human-generated. However, as with the originality detection software discussed above, it is imperative that educators understand what these tools are designed to do and what they are not designed to do. Only the laziest of students will directly submit a 100% AI-generated piece of work. These tools have not been trained on any dataset that includes proactive efforts to fool them. In some cases, even the addition of a single space can cause a ChatGPT detection tool to be fooled [54]. Similarly, since AI-generated text does not contain spelling or grammatical errors, some trivial manipulations can cause the detection software to fail. This serves to emphasise some inherent challenges in dealing with the problem of students using LLMs to complete their assignments. Certainly, no LLM detector should be relied upon as definitive evidence of wrongdoing, nor can it definitively exonerate a suspected student. It remains an open question as to whether a reliable AI-detection tool is even possible. At best, an educator may use these in a similar way to originality checkers: a first pass to find suspicious cases that may merit further investigation. However, human judgment and old-fashioned mechanisms like oral examinations should remain part of the process."}, {"title": "4.5. Educator 5", "content": "ChatGPT is a specific software application built on top of Generative AI technology, particularly large language models (LLMs). Generative AI is a broad term that refers to any type of artificial intelligence that can create new content. This can include text, images, music, code, and more. Among these, Large Language Models (LLMs) stand out as a specialized subset of Generative AI, specifically engineered for text generation. LLMs represent a class of artificial intelligence proficient in both text generation and comprehension. They undergo extensive training on extensive datasets containing text and code, enabling them to grasp the intricacies of human language patterns. LLMs find application across a diverse range of tasks, including [55] :\n\u2022 Text generation: LLMs can generate text, such as news articles, poems, code, scripts, musical pieces, email, letters, etc.\n\u2022 Translation: LLMs can translate languages from one language to another.\n\u2022 Question answering: LLMs can answer questions in a comprehensive and informative way, even if they are open ended, challenging, or strange.\n\u2022 Summarization: LLMs can summarize long pieces of text into shorter, more concise pieces.\n\u2022 Code generation: LLMs can generate code in a variety of programming languages.\nThis has given rise to Ethical and Privacy Concerns around AI generated content in education. Central to understanding the impact past the hype phase is promoting a broader understanding of what these models really are, and how they are designed. Bard, ChatGPT, and Bing AI are all examples of publicly available large language models (LLMs) that can generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way. While large language models open up many possibilities, there is still much to learn about how people will interact with them [56]. While Bard, Bing and ChatGPT all aim to give human-like answers to questions, each performs differently. Bing starts with the same GPT-4 tech as ChatGPT but goes beyond text and can generate images. Bard uses Google's own model, called LaMDA, often giving less text-heavy responses [57] [58]. Bard is trained on a dataset of text and code that is specifically designed to improve its dialogue and coding abilities. ChatGPT is trained on a dataset of text that is more general in nature. This means that Bard is better at understanding and responding to natural language, while ChatGPT is better at generating creative text formats.\nConsideration must be given to alignment with educational values. This should ensure AI tools align with educational goals and values, such as critical thinking, creativity, and ethical decision-making. The presence of AI-generated content presents new and unique ethical considerations. Firstly, the very notion of authorship blurs, as AI lacks the capacity for genuine creative ownership. Assigning sole credit to authors who merely provide prompts for AI outputs is equally disingenuous. Therefore, establishing transparent attribution guidelines becomes essential. Secondly, the specter of bias is evident throughout AI research, as AI algorithms can unwittingly mirror societal prejudices present in their training data. Mitigating this necessitates employing diverse datasets and vigilantly monitoring outputs for discriminatory content. Thirdly, the potential for manipulating or fabricating information through AI-generated content, exemplified by deepfakes, poses a significant threat. Safeguards emphasizing factual accuracy and transparency are essential to combat this. Finally, the emotional impact of AI content cannot be ignored. Educators must carefully consider the potential psychological effects, particularly on vulnerable populations within educa-"}, {"title": "4.6. Educator 6", "content": "Artificial Intelligence (AI), has been increasingly used these days as the prime disposition to take decision, solve problems, write reports and so on and so forth claiming to replace human intelligence in future. Since, it is typically performance based, executing the commands generously without any perceptions or misconceptions of its abilities, it is being increasingly demanded. But another facet to pointed is that, it is only a function of the human command programmed to function with a set pattern or methods and will deliver similar results, sometimes overlapping with the same methodical approach. The future of Artificial Intelligence in such light seems crippled without human intelligence. The future of decision-making, problem-solving lies with a careful concoction of number crunching, big data analysis, research tools and interdisciplinary research which requires correct amount of Human intelligence at every stage, leading to formation of Augmented Intelligence. It is an amalgamation of reckoning the correct ingredients or combination with intuitive abilities of human judgement when equipped with the methodical skill set of Artificial intelligence [60]. It is also known as Intelligence Augmentation (IA) or Cognitive augmentation is a new age marriage between man and machine. AI and IA together have a plan to pen down the future differently when used with a collaborative approach. While AI has been increasingly posing a threat to replace humans, but when it comes to the judgment and the reckoning aspect, we see human stepping in for an informed disposition of intelligence. Instead of avoiding or making attempts to accept this inevitable change, it is now time to look at the aspect as a JV between Humans and Computer. The IA approach shall bring together advances, modernisation and speed in the work approach across business enterprise, Institution, organisation, students, workers and media communities. The idea is to make the most of it by equipping and training the human intelligence with its correct and appropriate use. The tasks which are tedious for humans or repetitive in nature and has redundant value can be done by the AI bots, thus removing the human errors and biases. While the tasks which require interpretations, visionary approach holistic mind set and decree can be done by humans with larger efficiency due to save time at hand.\nThe statistics have shown that IA leads to 99% accuracy in decision making, leading to enhanced productivity. Alexa or other similar bots help you to take commands, recognize voices and eliminate the trouble of remembering and in some cases doing of mundane tasks. Students have although been using it as convenient tool to plagiarize their creativity lowering the scope of thinking. The University experts have now started to incorporate the Chatbot as the assignment providers to the students, where students are the ones evaluating the assignments created by bots [61]. The method is a clever precautionary approach rather than being a cure to the plagiarism. Unlike straight automation, IA shall enhance cognitive abilities. It's the IA technology who has to evolve with the open human mind set creating and consuming content with the help of AI, leaving no room for error and creating a powerful and strengthened approach. It uses the strengths of both man and machine while mitigating the risks and threats. The data has repeatedly shown that in organisation, where AI was kept as the sole leader, the human participation was ultimately asked in 30% of cases [62]. In the times of the uncertainty of the VUCA world, this only seems to rise. If your process has continuous human input, the change management in terms of adopting AI as a peer or colleague to work along will become smooth function of any organisation, While the students community need to be evaluators to understand deprivation from the AI approaches, so that they use it like an equipment rather an a subordinate. The IA can redefine the landscape of Human performance with harmonious function of partnership between man and machine building a realm of AI powered humans, who increase effectiveness at workplace by opening new horizons of ideas, backed by rationale and vision."}, {"title": "4.7. Educator 7", "content": "Assuring the veracity of student outputs has always been of concern, but recent developments in Generative AI (Gen AI) have thrown a curve ball at the processes already in place. Lecturers and administrators across our college have been challenged with the double concern of how to embed Gen AI into our teaching as a tool but also assure that it is not misused in producing outputs at the assessment level. The usage of these tools by students was at first met with apprehension but then excitement as it was seen as another important tool within the modern student's arsenal; it has become increasingly apparent that these tools will be and are being used across industry [63] so we have noticed that we would be seriously disadvantaging students by not including their usage in the teaching programmes. Early trials are in place for using Gen AI as a part of module teaching and assessment in some modules. But we also need to put in place mechanisms to help prevent their misuse in outputs at assessment level. The Exams Office along with Programme Coordinators have developed changes to overall assessment that reflect the need to be aware of the misuse of AI through more authentic forms of assessment. This discussion deals with some of the early ideas and mechanisms proposed and developed around both of these issues as we both battle and welcome A\u0399.\nMany scholars are exploring the ethical usage of Gen AI in the classroom. Some of this research finds high intention by students to use these tools [64]. But the perceived usefulness of these tools is questioned in university settings contrasting other research in the area [65] which the authors say may be due to a lack of understanding of these tools. Within our own organization we are going to extreme attempts to show students and staff the usefulness of these tools in the classroom as well as their coursework. One such method has involved staff CPD to instill effective usage as well as guidance from our corporate headquarters (Kaplan Inc.). We have also been developing guidance at the Quality Assurance Level for staff and students while some staff members are actively including Gen AI tools in their teaching..\nAnother interesting study looks at Gen AI adoption across the generations. [65] found that Generation Z students showed an interest in using Gen AI as a tool in their educational pursuits while Generation X and Y teachers showed optimism towards the tool while expressing concerns about its application. One could indeed map the rise of Gen AI on many other tools that over the years would have seemed to be cheapening the learning experience (the computer to the page, the page to rhetoric...). We have found this mixture of interest and apprehension across our own staff as we learn to deal with this interesting new tool.\nThe elephant in the room though, is plagiarism or academic impropriety (the other AI). Having experience working adjunct in two other universities has allowed this researcher multiple viewpoints into the issue as it has arisen. Working in different departments (Humanities and Social Sciences) has also highlighted interesting and varied approaches. The first observation was that Humanities departments, heavily reliant on the the essay form such as Literature Studies, initially showed an aggressive zero-tolerance approach to its usage in coursework while the Social Sciences such as Communications Studies, showed a more balanced approach, recognising it as a tool but still leaning strongly towards penalizing students for its usage as opposed to actively incorporating its usage. It was in our Business College where we found a more balanced approach and this may be due to the prevalence of project-type work which facilitates the ethical usage of Gen AI but also makes its misuse less easy to apply. The nature of project work is a more authentic type of assessment that involves more interaction between the lecturer and student, which makes Gen AI content more obvious in final productions.\nThe answer to the negative aspects of Gen AI that leads to academic impropriety is to embrace more authentic forms of assessment like the above. To move away from the essay from and towards more regulated and monitored project-type work that also encourages the use of Gen AI as a tool in that process. At the HECA Research Conference 2023, Gen AI and authentic assessment was the centre of many interesting discussions. Indeed, the conference ended with Danielle Logan Fleming of Griffith University, Australia: A message of HOPE: Generative AI and Authentic Interactive Oral Assessment."}, {"title": "5. Thematic Analysis", "content": "In this section, the results of the thematic analysis approach by Braun and Clarke [46] have been discussed. The framework helped in the identification of 11 themes, which have been discussed in the following subsections. The themes identified were:\u2018Academic Integrity and Challenges in Assessment', 'Limitations and Misuse of Generative AI' \u2018The Importance of Prompt Construction', \u2018Critical Thinking and Problem-Solving Skills', \u2018Bias, Transparency, and Ethical Concerns', 'Responsible use of GenAI', 'GenAI for Programming', \u2018Technical Details of AI Tools', \u2018Advantages of GenAI', 'Challenges of GenAI', and \u2018Miscellaneous'."}, {"title": "5.1. Academic Integrity and Challenges in Assessment", "content": "'Academic Integrity and Challenges in Assessment' is the most commonly discussed theme, mentioned by 5 out of the 7 educators."}, {"title": "5.2. Limitations and Misuse of Generative AI", "content": "The theme \u2018Limitations and Misuse of Generative AI' includes codes that discuss general limitations and the potential misuses of these tools, which could not be aggregated into a single theme. Educator 4 discusses how ChatGPT hallucinates plausible sounding references [52] and creates other referencing errors [53]. ChatGPT also struggles with basic arithmetic [69]."}, {"title": "5.3. The Importance of Prompt Construction", "content": "The theme 'Importance of Prompt Construction' consists of codes that discuss the importance of constructing high-quality and precise prompts to obtain relevant and accurate responses from a GenAI tool.  Educators 1 and 2 suggest supplying GenAI chatbots with precise prompts will provide optimal results [70], and tutorials for prompt construction should be included in the curriculum [1]."}, {"title": "5.4. Critical Thinking and Problem-Solving Skills", "content": "The theme 'Critical Thinking and Problem-Solving Skills' consists of codes which discuss the impact of GenAI technology on the critical thinking skills of students. GenAI tools can both promote and hinder the development of these skills [44]. Educator 1 mentions particular concerns such as decline in creativity and independent thinking due to over-reliance on GenAI tools [71]."}, {"title": "5.5. Bias, Transparency, and Ethical Concerns", "content": "The theme \u2018Bias, Transparency, and Ethical Concerns' consists of codes that touch on biases in AI-generated content [72], copyright concerns with AI generated content [73], and authorship debates around such content [58]. The lack of transparency in the development and deployment of these tools is also a significant barrier in their integration in the educational curriculum [37]. Educator 5 has also expressed concerns regarding the proliferation of AI-generated fake content, which can have a detrimental impact on misinformation in politics and journalism [74] [75]. The potential psychological impact that AI generated content can have on the students, which can be positive or negative, must also be kept in mind [33]."}, {"title": "5.6. Responsible use of GenAI", "content": "In the theme \u2018Responsible use of GenAI', suggestions for ethical and responsible use of GenAI have been highlighted. Educator 1 suggests possible changes that can be made to class assignments that are given to students. Educators 1 and 2 suggest that the proper use of GenAI tools must be taught as part of the curriculum. Educator 3 highlights the importance of studying user interaction with LLMs [56]. Educator 6 highlights the importance of human oversight in utilizing GenAI."}]}