{"title": "DL-Polycube: Deep learning enhanced polycube method for high-quality hexahedral mesh generation and volumetric spline construction", "authors": ["Yuxuan Yu", "Yuzhuo Fang", "Hua Tong", "Yongjie Jessica Zhang"], "abstract": "In this paper, we present a novel algorithm that integrates deep learning with the polycube method (DL-Polycube) to generate high-quality hexahedral (hex) meshes, which are then used to construct volumetric splines for isogeometric analysis. Our DL-Polycube algorithm begins by establishing a connection between surface triangular meshes and polycube structures. We employ deep neural network to classify surface triangular meshes into their corresponding polycube structures. Following this, we combine the acquired polycube structural information with unsupervised learning to perform surface segmentation of triangular meshes. This step addresses the issue of segmentation not corresponding to a polycube while reducing manual intervention. Quality hex meshes are then generated from the polycube structures, with employing octree subdivision, parametric mapping and quality improvement techniques. The incorporation of deep learning for creating polycube structures, combined with unsupervised learning for segmentation of surface triangular meshes, substantially accelerates hex mesh generation. Finally, truncated hierarchical B-splines are constructed on the generated hex meshes. We extract trivariate B\u00e9zier elements from these splines and apply them directly in isogeometric analysis. We offer several examples to demonstrate the robustness of our DL-Polycube algorithm.", "sections": [{"title": "1 Introduction", "content": "Isogeometric analysis (IGA) is an analysis method designed to unify finite element analysis (FEA) and computer-aided design (CAD) by using the same basis functions for both geometrical and simulation representation [1]. Introduced by T.J.R. Hughes in 2005 [2], IGA has evolved significantly over the past two decades. Despite these advancements, constructing volumetric parameterization from surfaces remains a challenging task. Most CAD software represents geometry using boundary representation (B-Rep) models, typically expressed mathematically through NURBS (Non-Uniform Rational B-Splines). These B-Rep models are composed of multiple B-spline or NURBS patches. Consequently, IGA initially focused on B-Rep models [2]. In 2003, T.W. Sederberg introduced T-splines [3], which allow for T-junctions in quadrilateral control meshes, enabling local refinement. However, traditional T-splines lack linear independence and partition of unity properties, making them unsuitable for IGA and design. Recent research has developed analysis-suitable T-splines for IGA [4], particularly for shell structures [5]. Although B-Rep model parameterization is often used in IGA, three-dimensional (3D) solid models often have advantages over B-Rep models which discard internal geometric information. IGA often requires volumetric representation to account for internal material structures and densities. Therefore, constructing volumetric spline parameterization models suitable for IGA has been a persistent challenge in applying IGA to 3D solid models.\nResearch on constructing volumetric parameterization for IGA can be categorized into two main approaches based on the input: constructive solid geometry (CSG) [6] and B-Rep [7, 8]. However, CSG-based models pose difficulties for IGA due to the presence of trimming surfaces. B-Rep models require generating control meshes and constructing volumetric spline basis functions. In FEA, B-Rep models can be discretized into tetrahedral or hexahedral (hex) meshes. While tetrahedral mesh generation has multiple automatic strategies and is widely used in industry, hex meshes are preferred for their advantages: fewer elements for the same accuracy [9], avoidance of tetrahedral locking [10], and better suitability for tensor-product spline construction.\nDespite ongoing research in hex mesh generation [11-13], generating high-quality hex meshes for complex B-Rep models remains challenging. Methods like indirect methods [14], sweeping methods [15, 16], grid-based methods [17-19], polycube methods [20-24], and vector field-based methods [25, 26] have been explored. However, not all these methods are suitable for IGA. Hex meshes often involve extraordinary points (an extraordinary point has other than four faces adjacent to it) or extraordinary edges (an extraordinary edge is an interior edge shared by other than four hex elements), which can complicate spline construction and parameterization. When extraordinary points or extraordinary edges are involved, achieving optimal convergence rates is an challenging problem in IGA, even smooth basis functions are defined around them. To minimize the number of extraordinary points and extraordinary edges, sweeping and polycube methods are preferred for generating hex control meshes for IGA. Sweeping methods produce high-quality meshes by scanning from source to target surfaces, but their applicability is limited to specific models where the source and target surfaces have similar topology. Polycube methods use polycubes as parameter spaces to generate hex meshes through parametric mapping. The concept of polycubes was first"}, {"title": "2 Overview of the pipeline", "content": "We integrate deep learning with the polycube method to convert CAD geometries into volumetric spline models. As shown in Fig. 1, our DL-Polycube pipeline begins with the conversion of the CAD geometry into a triangular mesh. Subsequently, a pretrained deep learning model is used to generate a polycube structure. This structure serves as the foundation for generating all-hex meshes through parametric mapping [37] and octree subdivision techniques [8]. To ensure the all-hex mesh meets the quality requirements necessary for IGA, we evaluate the all-hex mesh and employ several mesh quality improvement techniques-pillowing [38], smoothing, and optimization [17, 39]- as needed. Upon achieving a good quality hex mesh, the volumetric spline model is constructed from the hex mesh using TH-spline3D with local refinement. Then the B\u00e9zier information is extracted to perform IGA in ANSYS-DYNA."}, {"title": "2.2 DL-Polycube algorithm", "content": "The DL-Polycube algorithm includes three steps, which are training dataset generation and curation, graph convolutional network polycube (GCN-polycube) recognition, and K-means surface segmentation (see Fig. 2). This DL-Polycube method leverages the efficiency of machine learning to handle a wide range of CAD geometries, replacing the manual surface segmentation and polycube construction [22] with intelligent, automated methods. The success of this algorithm is based on the following assumption: although there are inconsistencies in the geometry models, the underlying polycube structure may remain topologically consistent. By utilizing a pretrained machine learning model, the algorithm can identify the most suitable polycube for unfamiliar geometries, thereby automating and optimizing the process. Consequently, this leads to a powerful tool for generating high-quality hex meshes and constructing volumetric splines from CAD geometry.\nIn the dataset generation and curation step, we create a corresponding cage around the target mesh that requires deformation (e.g., a cube). The deformation of the cage influences the inner mesh. Deformations are performed by randomly selecting points on the cage, stretching them to lengths that follow a normal distribution. The entire process is conducted in Blender, a free and open-source 3D creation suite, producing effects similar to classical free-form deformation [40, 41]. This method enables the generation of a diverse set of models with random transformations and deformations.\nIn the GCN-Polycube step, GCN-Polycube classification is used for polycube structure recognition. DL-Polycube employs multilayer perceptron (MLP)-based GCN-Polycube models, where MLPs serve as nonlinear regressors. The use of ReLU activation functions within these MLPs enhances the network's nonlinear capabilities to fit complex patterns. This approach not only enables DL-Polycube to automatically"}, {"title": "3 Implementation details of DL-Polycube", "content": "In the initial phase of our pipeline (see Fig. 1), we employ a pretrained model to convert CAD geometries into their corresponding polycube structures. Then, with the generated polycube structures and CAD models, we segment them into patches that have a one-to-one correspondence between the surface of the CAD and polycube structures. This process involves three key steps. Firstly, we generate \"pseudo-random data\" to establish a foundational relationship that links random surface triangular meshes with their corresponding polycube structures. Following this, a deep learning GCN-Polycube model architecture, is trained using the pseudo-random data and their corresponding polycube structures from the first step. This step learns the mapping between triangular meshes and polycube structures. Finally, we use the K-means clustering method, which is based on spatial attributes such as normal vectors and centroids obtained based on the polycube structures. This method segments the"}, {"title": "3.1 Dataset generation and curation", "content": "We use the 3D graphics software Blender, along with its built-in Python and BMesh libraries, to create polycube structures and a wide range of derivative geometries resulting from their transformations and deformations. These derivative geometries and their corresponding polycube structures are used as inputs and outputs for our deep learning model system. This procedural geometric model employs a multi-step strategy to compute the polycube structures and their derivative geometries. The first step involves using Boolean operations to generate polycube structure, as illustrated in Fig. 3. The second step involves surface subdivision using the Catmull-Clark algorithm, followed by triangulation of the generated polycube structures. The third step involves free-form deformation. This procedural geometric modeling process is configured to produce polycube structures and subsequent derivative geometries. Starting with a polycube structure in the first step, the second and third steps generate 900 derivative geometries corresponding to each initial polycube structure. Thus, the entire procedural geometric modeling process generates the input and output data for training.\nFinally, we employ procedural geometric modeling to obtain eleven types of polycube structures and their derivative geometries. These polycube structures correspond to configurations of a single cube, a genus-one cube, and combinations of these two primitive geometries. For each type of polycube structure, we generate 900 corresponding derivative geometries. Note that we only generate eleven polycube structures as a proof of concept. One can generate more polycube structures to make the pipeline work for other types of geometries."}, {"title": "3.1.2 Data generation", "content": "We employ a parametric script to create various polycube designs, often starting with basic shapes like cuboids. This script begins by using Boolean operation to combine basic shapes into a polycube structure and then alters its transformation and deformation behaviors through procedural geometric modeling, as mentioned in the previous section. Consequently, the resulting geometry exhibits diverse shapes and transformation and deformation behaviors while maintaining topological consistency. It is important to note that the variability of the design parameters constrains the generalizability of the machine learning model. If the geometry model encounters design parameters outside its trained range, it is likely to yield less accurate results. Therefore, these factors must be considered and integrated throughout the entire pipeline when developing a model for automatically generating hex meshes.\nWe use a cuboid primitive with a hole (genus-1) as an example to illustrate our process (see Fig. 3). Firstly, we create the cuboid primitive with a hole using Boolean operation. Then, we refine it through surface subdivision using the Catmull-Clark"}, {"title": "3.1.3 Feature extraction", "content": "The deformed geometries derived from the initial polycube structures are used for feature extraction to create the training dataset. Given an input surface triangular mesh T from the derivative geometry, the geometry can be represented as an abstract graph G = (A, N), where the adjacency matrix A = {Aij}i=1...Nn,j=1...Nn defines the connectivity between triangular elements, with Aij = 1 indicating that two triangular elements are adjacent. The node feature vectors N = {Ni}i=1...Nm encode the characteristics of each triangular element. Each node feature vector includes details of the triangular element, such as the vertices that form it and 3D position p of each vertex Vi E V:\n$P_i := p (v_i) = \\begin{bmatrix} x (v_i) \\\\ y (v_i) \\\\ z (v_i) \\end{bmatrix} \\in \\mathbb{R}^3.$\nBesides the physical information, the node feature vectors N = {Ni}i=1...Nn also include additional attributes such as the normal vector of each face. This dataset,"}, {"title": "3.2 Machine learning model", "content": "The DL-Polycube algorithm aims to automatically generate polycube structures and ensure a one-to-one correspondence between the surface of CAD geometry and polycube structures. To achieve this, we will first use GCN-Polycube to extract the polycube structure of the CAD geometry. Based on the algorithm, the possible corresponding polycube structures will be given. Then, we will use K-means segmentation to perform surface segmentation."}, {"title": "3.2.1 GCN-Polycube model architecture", "content": "Fig. 5 provides a hierarchical overview of the GCN-Polycube model architecture. The architecture is composed of multiple layers designed to capture and process the spatial relationships and features of the deformed geometries derived from the initial polycube structures. The initial layer takes the graphical representation of the CAD geometry as input, transforming it into a feature-enhanced representation through convolutional operations that consider both node features and their connections. Subsequent layers in the GCN-Polycube further refine these features by aggregating information from neighboring nodes, capturing the local and global geometric structures. This hierarchical processing allows the model to understand complex spatial dependencies and interactions within the CAD geometry. The output of the GCN-Polycube is then used to suggest possible corresponding polycube structures, ensuring a one-to-one correspondence between the surface of the CAD and polycube models. A layer of a GCN-Polycube can be described by the following formula [44]:\n$F^{(l+1)} = H (\\~{D}^{-1/2}\\~{A}\\~{D}^{-1/2}F^{(l)}W^{(l)})$, (2)\nwhere $F^{(l)}$ represents the feature matrix at layer l, $\\~{A} = A + I$ is the adjacency matrix of the graph with added self-loops, $\\~{D}$ is the degree matrix of $\\~{A}$, $W^{(l)}$ is the trainable weight matrix of layer l, and H is the activation function ReLU. Our neural network consists of those four GCN-Polycube layers followed by a global average pooling,"}, {"title": "Loss function in GCN-Polycube", "content": "The loss function quantifies the difference between the predicted polycube structures and the true polycube structures (initial polycube structures in Sec. 3.1.1). For GCN-Polycube, we use the cross-entropy (CE) loss, which measures the performance of our GCN-Polycube model. The CE loss is defined as:\n$L_{CE} = - \\frac{1}{N} \\sum_{i=1}^N \\sum_{c=1}^C Y_{i,c} \\log(\\hat{y}_{i,c}) + \\lambda \\sum ||W^l||^2 ,$ (3)\nwhere N is the number of training data, C is the number of types of polycube structure considered in this paper, $Y_{i,c}$ is the binary indicator indicating whether the true polycube structure c is the correct classification for training data i, and $\\hat{y}_{i,c}$ is the predicted probability that training data i belongs to true polycube structure c. L2 regularization is adopted to prevent overfitting. Here $\\lambda$ is a regularization parameter that controls the trade-off between fitting the data and keeping the model weights small, and $W^{(l)}$ are the weights of the l-th layer shown in Equation (2)."}, {"title": "3.2.2 K-means model architecture", "content": "Step 3 in Fig. 2 provides a hierarchical overview of the model architecture for K-means surface segmentation using polycube structure information. By using a trained GCN-Polycube model from the previous step, we can obtain the predicted polycube structure of the CAD geometry. Subsequently, we use the K-means algorithm to segment the CAD geometry into k clusters in an unsupervised manner. Traditionally, the number of clusters k in K-means is a hyperparameter. However, in this context, k is known because it corresponds to the k faces of the predicted polycube structure. The k initial centroids are not chosen randomly; instead, they are calculated by taking the mean of the normal vectors corresponding to the predicted polycube structure. We first select k initial centroids based on the predicted polycube structure. Each normal vector of a face of predicted polycube structure is used as an initial centroid. Given an input surface triangular mesh T from CAD geometry, let the dataset X = {$X_{T(i)}$}=1"}, {"title": "4 ML-Polycube based segmentation and path optimization", "content": "This section introduces the pipeline of integrating polycube structure information with K-means segmentation and path optimization to produce high-quality surface segmentation to match the polycube structure. In the K-means step from the previous section, a significant challenge arises from the need to segment not only based on the normal space but also based on 3D Euclidean space. It is common for two regions on the polycube structure to lie on the same plane (see Fig. 7(b)). To accurately segment these regions, especially when they are co-planar, it is important to determine the approximate location of each cluster. This requires K-means segmentation to be performed in both the normal space and a space formed by the centroids of the triangular elements. A secondary GCN model (GCN-centroid) is employed to predict the centroids when regions lie on the same plane but are separated in the polycube structure. After segmentation based on the polycube structure is introduced, the next challenge is the zigzag issue, as illustrated in Fig. 7(c). To address this problem, we use a polycube-based Dijkstra's shortest path algorithm. The final outcome is a one-to-one correspondence between the segmented surface and the surface of the polycube structure."}, {"title": "4.1 GCN-based centroid prediction for surface segmentation", "content": "In the K-means step, the predicted polycube structure is used to determine the number of clusters for the K-means algorithm. To segment the surface more accurately, especially when two regions lie on the same plane and cannot be distinguished using only the normal space, we use a space formed by the centroids of the triangular elements. A GCN-centroid model is then employed to predict these centroids. The GCN-centroid is trained to recognize and predict the centroids based on the polycube structure, enabling the K-means algorithm to determine the approximate location of each cluster according to the polycube structure.\nSimilar to the GCN-Polycube used in polycube structure recognition, we first perform feature extraction. Here, we calculate the centroid of a triangular element based on its 3D position vector p of each vertex vi \u2208 V. Then we use the centroid of a triangular element as the node feature vector. The layers of the GCN-centroid can be described by Equation (2), where F(l) represents the feature matrix corresponding to the centroid of a triangular element.\nThe model architecture includes four GCN-centroid layers that capture and refine node features, which are the centroids, followed by global max pooling to aggregate these features. Subsequent linear layers further process the pooled features to predict the centroids. We train the GCN-centroid model using batch gradient descent. Although both the Adam and RMSprop optimizers are suitable for this task, we choose to use the RMSprop optimizer.\nThe predicted centroids are then used for K-means surface segmentation based on 3D Euclidean space. These segmentation used in conjunction with the K-means algorithm based on the normal space to segment the surface into k clusters, corresponding to the polycube structure. The initial centroids for K-means are selected based on the"}, {"title": "4.2 Dijkstra's algorithm for zigzag path optimization", "content": "After segmenting the mesh using K-means, we often encounter zigzag issues in the generated segments. To address this, we use Dijkstra's shortest path algorithm to optimize the paths. The algorithm considers the geometric properties of the edges, such as length and angles, to ensure smooth and accurate paths. By minimizing the cumulative edge weights, the algorithm finds the shortest path in a graph. Let g = (v, e) be a graph with vertices v and edges e, and let w(e) be the weight of edge e. The shortest path from vertex vi to vertex vj is determined by:\n$\\text{dist}(v_i, v_j) = \\min_{\\text{paths } v_{ij}} \\sum_{e \\in v_{ij}} w(e).$ (7)\nThe path finding process involves edge weight adjustment. This adjustment ensures that the paths found not only minimize distance but also conform to the desired geometric constraints, such as the sharp features in the original geometry. Here, the edge weight is adjusted as follows. For an edge e between vertices vi and vj, the weight w(e) is calculated as:\n$w(e) = \\frac{1}{ ||v_i - v_j|| } + \\lambda_1 o + \\lambda_2 \\phi,$ (8)\nwhere ||vi - vj || is the Euclidean distance. The coefficient $\\lambda_o$ depends on whether the edge is a sharp feature or not. This adjustment allows the influence of sharp features to be incorporated based on the edge length. The second term $\\lambda_e$ considers the direction of the current edge relative to the previous edge. The third term $\\phi$ controls the direction of the selected edge so that it does not deviate from the overall direction from the origin to the destination node. The coefficients $ \\lambda_1$ and $\\lambda_2$ are penalty coefficients. This optimization step ensures that the final segments align well with the polycube structure and thus eliminates the zigzag problem."}, {"title": "5 High-quality hex mesh generation and volumetric spline construction", "content": "Upon the polycube is predicted by the GCN-Polycube algorithm and the surface is segmented by the K-means, we need to build a bijective mapping between the input triangular mesh and the boundary surface of the polycube structure. Our implementation adopts the strategy proposed in [42], utilizing an union of unit cubes as the parametric domain for the polycube structure (see Fig. 9). The integration of the segmented surface mesh (provided by K-means) and the polycube structure (provided by GCN-Polycube) yield a parametric domain to perform the following octree subdivision and parametric mapping; see the pseudocode provided in the Parametric mapping algorithm [24]."}, {"title": "5.3 Hex2Spline: volumetric spline construction", "content": "Upon acquiring the hex mesh of satisfactory quality, the subsequent step involves constructing the volumetric spline, specifically the TH-spline3D, on these unstructured hex meshes. This process consists of two steps: the construction of TH-spline3D on hex meshes and the extraction of B\u00e9zier elements for IGA simulation in ANSYS-DYNA. Our previous software, Hex2Spline, uses a generated hex mesh as the input control mesh to facilitate the construction of a TH-spline3D over CAD geometry. This robust portion of the system has been made publicly accessible via GitHub (https://github.com/CMU-CBML/HexGen_Hex2Spline.git), complete with comprehensive documentation and reference [24, 31] for an in-depth understanding. Capable of defining spline functions over arbitrarily unstructured hex meshes, Hex2spline supports sharp feature preservation, and global refinement (see Fig. 10(a)), Hex2spline also incorporates adaptive IGA with its local refinement capabilities (see Fig. 10(b)). Hex2Spline can output the B\u00e9zier information of constructed volumetric splines for IGA simulation in ANSYS-DYNA or alternative IGA platforms."}, {"title": "6 Results", "content": "In this section, we demonstrate the effectiveness and robustness of the DL-Polycube algorithm through various test cases. We evaluate the performance of our approach on a range of CAD geometries with varying complexities and topologies. The results are analyzed in terms of polycube structure prediction accuracy, and the overall quality of the generated hex meshes and IGA results."}, {"title": "6.1 Dataset of deep learning models", "content": "The training process for the deep learning models is conducted using a large dataset of generated geometric models. The dataset includes a wide variety of polycube structures and their corresponding deformed geometries, ensuring diverse training examples. The dataset was generated using Blender and its built-in Python and BMesh libraries. We created 11 types of polycube structures, each with 900 derivative geometries, resulting in a total of 9,900 training examples. Fig. 11 displays the dataset, including the polycube structure and their derivative geometries, with two randomly chosen examples."}, {"title": "6.2 Polycube structure prediction", "content": "We tested the DL-Polycube algorithm on a set of 16 CAD models, including mechanical parts and free-form geometries. We applied deep learning to classify the polycube structures of these 16 models in order to determine the most likely polycube structure. The accuracy of polycube structure prediction was evaluated by comparing the predicted structures with the constructed ground truth polycube structures. The probability distributions output by the model are shown in Table 1. To clarify, we have named Type-1 as the P1 column, Type-2 as the P2 column, Type-3 as the P3 column, and so on. The order of types corresponds to Fig. 11. The probability distribution represents the model's confidence in how well the predicted polycube structure matches each type of the ground truth. Specifically, for the rod model, the probability for P3 (Type-3) is 100.00%, which indicates that the model believes the predicted structure most likely belongs to Type-3. The surface triangle meshes with predicted polycube structures for these models are shown in Figs. 12, 13, 14, and 15. Interestingly, the probability distribution of predicted polycube structures shows that some models can potentially match multiple polycube structures. In such cases, we select the polycube structure corresponding to the highest probability. For example, in the case of the dice model, it has a 65.13% probability for P1 (Type-1), but also a 34.6% probability for P6 (Type-6). Here, we choose the structure with the highest probability, which is Type-1."}, {"title": "6.3 Hex mesh generation and volumetric spline construction", "content": "The Polycube structure prediction and surface segmentation are performed using the DL-Polycube program. The DL-Polycube algorithms are implemented in Python using the PyG library [47]. The software is open-source and available at the following GitHub repository: https://github.com/CMU-CBML/DL-polycube. The hex mesh generation and volumetric spline construction are done with the help of two software packages: Hex2Gen and Hex2Spline. These packages are open-source and available at the following GitHub repository: https://github.com/CMU-CBML/HexGen_Hex2Spline. The hex mesh generation and volumetric spline construction algorithms are implemented in C++, utilizing the Eigen library [48] and Intel MKL [49] for matrix and vector operations and numerical linear algebra.\nWe have applied GCN, K-means, and two software packages to various models in a fully automated process. The results were computed on a PC equipped with a 3.1 GHz Intel Xeon w5-2445 CPU, 64 GB of RAM, a 16 GB GPU, and 32 GB of shared"}, {"title": "7 Conclusions and future work", "content": "In this paper, we present a novel approach called DL-Polycube, which integrates deep learning with the polycube method to automate the generation of high-quality hex meshes and volumetric splines. By incorporating deep learning, we significantly reduce the manual effort required for surface segmentation and polycube construction in our previously developed software packages [24] and improve correction procedures to address the issue where not every labeling permits a corresponding polycube, as mentioned in [11]. Since the labeling is automatically generated from the predicted polycube structure, these labelings naturally correspond to a polycube. Our approach leverages machine learning to automate the construction of polycube structures from\nCAD geometries and the subsequent surface segmentation. The surfaces of the pre- dicted polycube structures and the segmented CAD geometry maintain a one-to-one correspondence. This algorithm not only automates the conversion of CAD geometries into high-quality hex meshes but also reduces the learning curve for users, allow- ing them to quickly become familiar with in generating hex meshes and constructing volumetric splines. The robustness and efficiency of the DL-Polycube algorithm are demonstrated through several examples.\nWhile the DL-Polycube algorithm represents a significant advancement in our early work on hex mesh generation and volumetric spline construction, there are several areas for future improvement. First, it is important to note that the variability of the design parameters and topologies within the dataset constrains the generalizability of the machine learning model. If the geometry model encounters design parameters and topologies outside its trained range, it may not predict an ideal polycube structure, leading to poor-quality hex mesh. Therefore, we plan to include a wider variety of design parameters and topologies in our dataset to cover more geometric configura- tions. A geometric library based on more polycubes can be established to facilitate this. Second, this paper focuses on genus-0 and genus-1 geometries. For high-genus geome- tries and complex genus-0 and genus-1 geometries, generative models can be employed to automatically separate them into multiple simpler genus-0 and genus-1 geometries, each simpler genus-0 or genus-1 geometry can then be processed using the methods described in this paper. This approach will enable the generation of hex meshes and the construction of splines for high-genus and complex geometries, which is an area of interest for us. Third, although our focus has been on hex meshes, extending the DL- Polycube algorithm to generate other types of meshes, such as hex-dominant meshes, could broaden its applicability.\nIn conclusion, the DL-Polycube algorithm represents a significant step forward in automating the hex mesh generation and volumetric spline construction. By addressing the future work, we aim to further enhance the capabilities and applicability of our approach, ultimately contributing to the advancement of hex mesh generation and IGA."}]}