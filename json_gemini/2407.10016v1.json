{"title": "Characterizing Disparity Between Edge Models and High-Accuracy Base Models for Vision Tasks", "authors": ["Zhenyu Wang", "Shahriar Nirjon"], "abstract": "Edge devices, with their widely varying capabilities, support a diverse range of edge AI models. This raises the question: how does an edge model differ from a high-accuracy (base) model for the same task? We introduce XDELTA, a novel explainable AI tool that explains differences between a high-accuracy base model and a computationally efficient but lower-accuracy edge model. To achieve this, we propose a learning-based approach to characterize the model difference, named the DELTA network, which complements the feature representation capability of the edge network in a compact form. To construct DELTA, we propose a sparsity optimization framework that extracts the essence of the base model to ensure compactness and sufficient feature representation capability of DELTA, and implement a negative correlation learning approach to ensure it complements the edge model. We conduct a comprehensive evaluation to test XDELTA's ability to explain model discrepancies, using over 1.2 million images and 24 models, and assessing real-world deployments with six participants. XDELTA excels in explaining differences between base and edge models (arbitrary pairs as well as compressed base models) through geometric and concept-level analysis, proving effective in real-world applications.", "sections": [{"title": "1 INTRODUCTION", "content": "Recent literature has proposed numerous neural network models for edge devices that aim to solve the same learning task, e.g., image classification and object detection. These models exhibit variations in the number of parameters, computational costs, learning capabilities, and overheads-due to the diverse range of edge platforms they run on [52, 59]. While some of these models are developed from scratch [12, 32], many are derived from large and complex models [5, 49] through various compression and transformation techniques [33, 34] to satisfy the resource limitations of edge devices. Even after deployments, these models continue to evolve as they are trained on new data [18, 42], and/or when their architectures are modified [4, 38]. With so many model variants, it becomes crucial [37] to understand the differences between their decision-making processes, which offers more insight than mere comparison of accuracy numbers.\nUnfortunately, existing explainable AI techniques that are primarily developed for standalone models [6, 45] are inadequate for comparing and contrasting the capabilities and differences between a high-accuracy base model and a computationally efficient but lower-accuracy edge model. Firstly, they do not provide any relative explanations. Their focus is solely on explaining individual model behavior on specific inputs, which does not provide interpretable relative differences between a pair of models. Secondly, they do not provide generalizable explanations. Their outcome is too specific to the given input, which does not generalize across many examples and multiple datasets. Recent works on model similarity analysis enable architectural-wise segment equivalence measurement and distance-based similarity metric comparison [11, 16, 24]. However, these techniques fall short in effectively explaining the fine-grained specifics of differences in instance-based decision-making processes among various base and edge models. Hence, devising a new technique that characterizes the generatlized relative difference between a base and an edge model has remained an open problem.\nIn this paper, we propose XDELTA, a new kind of explainable AI technique that categorizes and summarizes the explanations behind an edge model's relatively poor performance compared to a base model. It performs both geometric and semantic explanation analysis of the disparities between the feature maps of two models and provides a breakdown of cases where the edge model fails to correctly classify but the base model succeeds. The development of XDELTA involves two major tasks: (1) construction of a difference or DELTA model that represents the relative difference between base model and edge model, and (2) the generation and summarization of explainable differences between the model pair. The DELTA model plays a critical role in XDELTA. Figure 1 illustrates how the DELTA model behaves in XDELTA. Given a high-accuracy base model and a relatively lower-accuracy edge model, we construct a DELTA model that is compact in its size and complexity, and is complementary in its ability to enhance and rectify the feature representation of the edge model, as such, when the edge model and the DELTA model are fused, their combined performance is akin to the base model. We note that the goal of DELTA is not to approximate the base model; rather, it aims to approximate the difference between the base and the edge model. This is illustrated by the activation maps in Figure 1.\nThe construction of DELTA is a challenging feat. First, since the DELTA model complements the edge model, it primarily needs to capture the essence of the base model in a compact network architecture with reduced model complexity and high efficiency (adhering to Occam's Razor principle). We formulate this as a subgraph extraction problem, where the objective of the subgraph is to preserve the base model's partial feature-representation capabilities, rather than to maintain the accuracy of the base model in its entirety-since the edge model also contributes its features when DELTA is fused with it. Second, the DELTA model needs to extract those features from the input that complement the edge model's feature representations. This requires a different kind of algorithmic design that not only considers the overall representation capability of the fused model but also carefully make the contributions of the edge and DELTA models complementary.\nTo address these challenges, we devise a new structured subgraph extraction algorithm that is well-suited to DELTA models and a new objective function that considers both the feature representation quality of the fused model while keeping the feature maps of the DELTA and the edge models negatively correlated (i.e., complementary) to each other. Once the DELTA model is obtained, it is applied to the test dataset, which may include previously unseen images, to infer and analyze the semantic concepts missed by the edge model but captured by the base model. This helps understand the reasons behind the edge model's subpar performance at the human-understandable semantic level.\nWe extensively evaluate XDELTA's efficacy and algorithmic aspects across various scales and configurations. We leverage four popular image datasets containing over 1.2 million images and 24 models derived from 11 image classifiers. Additionally, 6 participants assess explanations in a real-world indoor scene recognition deployment. We demonstrate that XDELTA excels at explaining differences between base and edge models from multiple perspectives. It employs high-level geometric categorization to quantify activation region patterns, revealing deficiencies in the edge model. Furthermore, XDELTA provides fine-grained concept-level explanations, identifying missing semantic concepts during edge model decision-making and explaining misclassifications. Notably, XDELTA performs well with both arbitrary model pairs and compressed models (edge versions of base models). Finally, the real-world deployment demonstrates XDELTA's ability to explain differences between edge and base models across eight environment categories, using a total of 421 mobile phone images."}, {"title": "2 MOTIVATION", "content": "A wide variety of neural networks with different parameter sizes, computational costs, learning capabilities, and overheads exist that solve the same learning task. In Figure 2, for example, we plot 20 popular CNNs for the image classification task. Models in the lower-left rectangle have lower parameter sizes and computational costs (FLOPS) compared to those in the upper-right rectangle. These smaller, computationally efficient models, aka the edge models, are generally suitable for resource-constrained edge devices but usually exhibit lower accuracy than state-of-the-art base models designed for high-end machines. We aim at understanding the reasons behind this accuracy gap between an edge model and a high-accuracy base model."}, {"title": "3 OVERVIEW OF XDELTA", "content": "XDELTA is an explainable AI technique that categorizes and summarizes the explanations behind a computationally efficient but relatively lower-accuracy edge model's relatively poor performance compared to a high-accuracy base model\u00b9. The development of XDELTA involves two major tasks: (1) the construction of a model that characterizes the difference between the model pair, and (2) the generation and summarization of explainable semantic differences between the model pair. In this paper, we limit our scope to CNNs for image classification tasks considering their prevalence in recent embedded AI literature [35, 39]. For other types of"}, {"title": "3.1 DELTA Network Construction", "content": "Given a compatible model pair, we define DELTA as a network that models the shortcomings in the edge model's data representation ability, relative to the base model's ability to do the same. A DELTA network has two salient properties:\n\u2022 The DELTA model should complement the edge model's feature representation such that when the two models are fused together, the accuracy of the fused model is as high as the base model's accuracy.\n\u2022 The DELTA network should be minimal in size and execution cost (FLOPS) to adhere to the Occam's Razor principle. As such, the combined size as well as the execution cost of the DELTA and the edge model should be lower than the base model's size and execution cost, respectively.\nTwo major challenges lie ahead in constructing DELTA network: (1) devising a network that preserves partial knowledge from base model, such that it complements features of edge model; (2) ensuring the compactness and efficiency of DELTA model while retaining the capability of capturing the features missed by edge model."}, {"title": "3.2 Differential Explainable AI", "content": "Given a constructed DELTA network, several steps are required to clearly illustrate the differences between the corresponding model pair. We employ an existing explainable AI tool to generate a class activation map for the input, specifically highlighting areas captured by the base model but missed by the edge model. This map is then fed into the Large Language Model (LLM) layer to generate detailed and readable explanations, illustrating the differences. Additionally, we provide a geometric and semantic categorization summary outlining the behavior of the DELTA model, which emphasizes differences between the base model and various types of edge models (either directly derived from the base model or completely different ones)."}, {"title": "4 DELTA NETWORK CONSTRUCTION", "content": "A DELTA model enhances the data representation capability of an edge network in a compact and complimentary manner as such when it's fused with the edge network, their combined data representation capability becomes as close as possible to the base model's. To achieve this, we propose a network architecture for DELTA that resembles the English letter Y where the two branches capture the essence of the base and the edge model, respectively, and information flowing through these two branches are fused by the remaining part of the network to construct a representation of the input that we call the DELTA feature. During inference, DELTA features are used in conjunction with features extracted by the edge network to classify the input.\nThe architecture of a DELTA network along with the corresponding base and the edge network architectures is shown in Figure 6. The construction of DELTA has three steps:\n\u2022 Step 1 - Extracting structured subgraph from the base network to construct a portion of the DELTA that brings the base network's data representation capability into it.\n\u2022 Step 2 - Constructing the DELTA feature extractor that adapts and concatenates features extracted by the edge model and the subgraph of the base model.\n\u2022 Step 3 - Training the DELTA network by explicitly ensuring that the DELTA network is complementary to the edge network's ability to classify input data."}, {"title": "4.2 Step 1 - Structured Subgraph Extraction", "content": "In this step, a major part of the DELTA network is constructed by extracting the structured subgraph from the base network. The goal of subgraph extraction is not to have a smaller model that performs as accurately as the base model, but to extract feature representation capability from the base model, which when combined with the edge model's feature representation capability, the combined model performs as accurately as the base model. We describe the fundamentals and rationale behind developing a new subgraph extraction technique, followed by an optimization framework to obtain the parameters for the extraction process, and finally, the structured subgraph extraction steps.\nFundamentals and Rationale. Structured subgraph extraction entails application of binary masks to network weight matrices in order to reduce their size and execution cost:\n$W_{sparse} = M(\\varsigma) \\otimes W_{dense}$ (1)\nwhere, $W$ and $M(s)$ are the weight and the mask matrices; \u00e7 denotes the sparsity of the mask (i.e., number of zero elements divided by total number of elements); $\u00ae$ is the element-wise product operation.\nA large body of recent works are dedicated to finding optimal sparsity rates for different network constructs [26, 49]. A fundamental limitation of these works, however, is that the search space being too large, they get stuck in a bad local minima and perform sub-optimally. We observe that instead of directly searching for sparsity rates, if we redefine sparsity as a convex combination of n candidate sparsity rates {{$i}} with the corresponding sparsity coefficients {{$pi$}}, the search converges fast and becomes resilient to getting stuck in a bad local minima:\n$S = [\\gamma_1 \\gamma_2 ... \\gamma_n] \\times [\\varsigma_1 \\varsigma_2 ... \\varsigma_n]^T$ (2)\nThe mathematical insight behind the above observation is that when the loss function $L(W)$ reaches a local minima for weight $W_o$, $L(W)$ is convex with respect to $W \u2208 [W_o-\u20ac, W_o+e]$, where e is a small perturbation. Hence, when a mask $M(s)$ is applied, the loss function $L(W \u00ae M(s))$ becomes convex with respect to M(s) given a frozen W. To solve this convex optimization problem, we assume $M(\\varsigma) \u2208 [0,1]^n$ is continuous (and discretize afterwards without violating correctness). Using Jensen's inequality:\n$L(W \\otimes M(\\varsigma)) \\leq \\sum_{i=1}^n \\gamma_i L(W \\otimes M(\\varsigma_i))$ (3)\nBased on the above, we can always find a subset {M(sj)} for which the following holds:\n$L(W \\otimes \\sum_{i=1}^n \\gamma_i M(\\varsigma_i)) \\leq min \\sum_i L(W \\otimes M(\\varsigma_i))$ (4)\nIn other words, Equation (4) shows that a mask formed by weighted averaging keeps the loss at a relatively lower value. Since the loss remains closer to the local minima, the search process takes less time to converge and accuracy preservation becomes easier.\nOptimization Framework. Given the new definition of sparsity, a new challenge is to find the optimal sparsity coefficients [Y1 Y2 Yn] for each layer that is processed. These coefficients are used to generate masks that are applied to corresponding layers for subgraph extraction. The optimization goal is to minimize the loss of essential feature representation capability as well as the execution cost of the extracted subgraph. The entire framework runs on high-end server to expedite the optimization process.\nTo achieve this, an extended version of the base network that explicitly incorporates sparsity coefficients is constructed. For each convolutional and linear layer Li, K copies are created, and for each copy Li,j, a sparsity rate \u015ei,j \u2208 {$1,\u2026\u2026\u2026, $n} and a learnable weight yij is assigned. A larger K allows finer search space exploration for optimal solutions but is limited by the server's computational capacity."}, {"title": "4.3 Step 2 - Constructing DELTA Feature", "content": "In this step, features from the edge and the subgraph extracted from base networks are fine-tuned and combined to form the DELTA features.\nFine-Tuning Features. In order to improve the representational capability of the base network's subgraph, a squeeze-and-excitation [14] block with skip connection [12] is added to obtain the interdependencies between feature channels. These are further passed through a global average pooling layer [25] to ensure that the number of elements in the feature vector is the same as the channel size of the input feature map. Finally, the features are reshaped and linearly transformed to a lower dimension using a fully-connected layer. The edge model is unchanged, and the features from the edge network is only down-scaled by a pooling layer to incorporate enough information that helps speedup the convergence of DELTA feature construction process.\nCombining Features. The fine-tuned features are concatenated to form an extended feature vector - which is fed to a two-layer perceptron (MLP) network that acts as a feature resizer. This resizer is essential for merging features with different dimensions. It ensures the combined feature after resizing can be averaged with the down-scaled features from the edge model and then fed to the base model's classifier (i.e., layers after the feature extractor) for comparable accuracy."}, {"title": "4.4 Step 3 \u2013 Training DELTA Network", "content": "In this step, the DELTA network is trained while the edge and the base models remain frozen. Considering the fused feature quality, complementary nature, and efficiency, the loss function includes three terms mean squared error (LMSE), feature-wise negative correlation (LFNC), and sparsity regularization (LSR). The hyperparamters AFNC and ASR control the relative strength of corresponding terms.\n$L = L_{MSE} + \\lambda_{FNC} \\times L_{FNC} + \\lambda_{SR} \\times L_{SR}$ (6)\nMean Squared Error (MSE). This term ensures that when the DELTA features are fused with the edge model, their combined accuracy is on par with the base model's accuracy.\n$L_{MSE} = \\frac{1}{N} \\sum_{i=1}^N || F_\\delta^{(i)} - F_B^{(i)} ||^2$ (7)\nwhere $F_\\delta^{(i)}$ and $F_B^{(i)}$ are feature representations of the fused model and the base model for the i-th (1 \u2264 i \u2264 N) training example.\nFeature-wise Negative Correlation (FNC). This term ensures that DELTA is complementary to the edge model as such their features are negatively correlated to each other. It forces DELTA to learn different regions on the activation map than what the edge model attends to while the fused feature representation is as close to the base model's as possible. Unlike traditional negative correlation learning approaches [30] that penalize two models at the instance level, we introduce a feature-wise correlation loss designed for DELTA models:\n$L_{FNC} = \\frac{2\\lambda}{N} \\sum_{i=1}^N ((F_\\delta^{(i)} - \\overline{F_\\delta}) (F_{FE}^{(i)} - \\overline{F_{FE}})) + \\frac{1}{2N} \\sum_{i=1}^N (\\frac{||(F_\\delta^{(i)} - \\overline{F_\\delta})||^2}{||F_\\delta^{(i)}||^2} + \\frac{||(F_{FE}^{(i)} - \\overline{F_{FE}})||^2}{||F_{FE}^{(i)}||^2}) + (\\frac{||(F_{FE}^{(i)} - \\overline{F_{FE}})^2||^2}{||F_{FE}^{(i)}||^2})  \\frac{||(F_{B}^{(i)} - \\overline{F_{B}})^2||^2}{||F_{B}^{(i)}||^2}))^2$ (8)\nwhere $F_\\delta^{(i)}$ and $F_{FE}^{(i)}$ denote the DELTA feature and resized edge feature for the i-th (1 \u2264 i \u2264 N) training example, respectively, and a is a hyperparameter that adjusts the strength of the correlation penalty.\nSparsity Regularization (SR). The sparsity of the DELTA network is regularized by penalizing the absolute magnitude of its weights so that the model retains only the relevant features.\n$L_{SR} = \\sum_{l=1}^{\\#layers} (\\sum_{\\{f\\}} ||W^l_f||_1 + \\sum_{\\{c\\}} ||W^l_c||_1)$ (9)\nwhere $||W^l_f||_1$ and $||W^l_c||_1$ denote the group lasso [53] for filter- and channel-wise weights for l-th convolutional layer."}, {"title": "5 DIFFERENTIAL EXPLAINABLE AI", "content": "XDELTA analyzes the class activation map of the DELTA network to generate a summary of the edge model's shortcomings that is generalizable across multiple datasets. It leverages the DELTA model to summarize cases where an edge model underperforms compared to a base model on a given dataset. There are three simple steps:\n\u2022 Step 1 - Initialization: An existing explainable AI tool, e.g., GradCAM++ [6] is used to obtain the activation map of the DELTA network for each image in the dataset. These activation maps are segmented (by applying a threshold on activation values) to obtain one or more disjoint activation regions. This process is repeated for the edge model.\n\u2022 Step 2 Geometric Categorization: For each image, activation regions from the edge and the DELTA are geometrically compared and categorized into one of seven predefined categories. A summary statistics is produced by counting the occurrences for each category. Figure 8 shows an example.\n\u2022 Step 3 - Semantic Categorization: This step applies when the input dataset contains fine-grained semantic labels for different segments inside each image. The activation regions of the DELTA model inherit those semantic labels depending on their overlaps with the labeled segments. In cases where ground truth semantic labels are unavailable, we employ the GPT-40 LLM to generate the labels. A summary is produced by counting the occurrences of each semantic label. Figure 9 shows an example."}, {"title": "6 DATASET-DRIVEN EVALUATION", "content": "We conduct experiments on four image datasets: ImageNet-1K [43], CIFAR10 [19], MIT Indoor Scenes [40], COCO [28]. For each dataset, we choose a representative pair of models whose input dimensions are compatible with the dataset, as shown in Table 1. We report geometric summaries for the first three datasets and a semantic summary for the last one. To study the effect of compression on lost semantics, we use ResNet56 [12] as the base model pre-trained [1] on CIFAR10 dataset. A fine-tuning dataset is constructed using the ImageNet samples based on the records of the enlarged CINIC10 [7]. This fine-tuning dataset contains similar categories as CIFAR10 dataset while preserving higher resolution and more details. We use a randomly generated mask with controlled global sparsity to perform structured pruning on the ResNet56 using 12-norm as pruning criteria. As a result, we obtain four models: a base model and three edge models edge0, edge1 and edge2, as shown in Table 2."}, {"title": "6.2 Geometric Categorization", "content": "Activation regions of the edge and the DELTA models show different degrees of overlap \u2013 having different impacts on the edge model. Disjoint regions complement the edge model by bringing missing information. Overlapping regions enhance the edge model by suppressing noise. Often complementing and enhancing regions appear in a mix. These regions may be located on or near local segments of the target object, or spread out globally on other parts of the image.\nFigure 8 (a) explains the incorrect predictions by the edge models by categorizing the reasons into seven different categories. For the VGG16-AlexNetS pair on CIFAR10, local complementary regions explain the majority of its misprecitions since AlexNetS misses a large number of important regions on the target object. For the ResNet50-ShuffleNetV2 pair on ImageNet-1K, the local enhancement explains the majority of its mispredictions since ShuffleNetV2 attends to many noisy regions which are suppressed by the DELTA model. For the ResNet18-SqueezeNet pair on MIT Indoor Scenes dataset, both global spatial features and local object features are complemented by the DELTA model to correct most of the mispredictions by the SqueezeNet. We also quantify"}, {"title": "6.3 Semantic Categorization", "content": "Figure 9 (a) shows the top 10 most frequently missed semantic concepts that the DELTA model brings in to correct ShuffleNetV2's (edge model) mispredictions. Notably, about a third of the mispredictions are explained by the model's inability to recognize animal body parts such as eyes, nose, and facial features. Some example images are shown in Figure 9 (b) with activation regions that DELTA captures."}, {"title": "6.4 Lost Semantics in Model Compression", "content": "We conduct an experiment to understand the semantic loss in a model due to various degrees of model compression. We construct the DELTA model for each pair of base model and edge models from Table 2. The keywords are extracted from LLM layer to understand the frequency of the missed semantic concepts that corresponds to the loss of accuracy and feature representation capability. Figure 10 shows an example image of a horse correctly predicted by the base model but misclassified by the edge model. The text output of each model pair explains the difference between the edge and base models at various levels of detail, which highlights model disparity change after increasing the sparsity rate.\nFor an aggregate analysis, we identify the top-5 frequently missed concepts for each model pair and create a union list shown in Figure 11 for comparison. As the compression ratio increases, the models lose their ability to capture features in categories like felines, ships, and trucks. However, feature loss for bovidae (mammal with unbranched horns) is less affected due to their distinct recognition features. For complex structures like automobiles, higher compression ratios significantly impact the model's feature capture."}, {"title": "7 DEPLOYMENT EXPERIMENT", "content": "In order to evaluate the performance of XDELTA in real-world scenarios, we conduct a study involving six participants who contribute a total of 421 pictures of their living and working environments from four different environments. Objects in these images are classified locally on the user's phone using edge and DELTA models, and remotely using base model, listed in Table 3. XDELTA is applied to summarize the shortcomings of the edge model - geometrically as well as semantically. We implement XDELTA for Google Pixel 2XL using pytorch 1.12, which includes edge and DELTA models. The base and edge models are pre-trained on MIT Indoor Scenes dataset of 67 categories. The DELTA model is created and evaluated on the user-contributed data containing eight different categories of images. All images are resized to 256x256 before feeding into the networks."}, {"title": "7.1 Geometric Categorization", "content": "Figure 12 (a) summarizes the cause of incorrect predictions by SqueezeNet (the edge model) by geometrically categorizing the explanations. In about 57.3% cases, DELTA brings complementary information from local objects (e.g., sofa seat and table surface) and from spatial contexts (e.g., kitchen area and stairs) as such the edge model may focus on certain salient parts with less noisy regions \u2013 which is consistent with the dataset-driven experiment for the same pair of models. Figure 12 (b) shows example images (with marked activation regions for both DELTA and edge models) for the top two geometrically categorized explanations behind SqeezeNet's poor performance on user-contributed data. As expected, the enhancement category yields higher overlapping scores, while the complement category results in lower scores."}, {"title": "7.2 Semantic Categorization", "content": "Figure 13 (a) shows the top 10 most frequently missed semantic concepts that the DELTA model brings in to correct SqueezeNet's (edge model) mispredictions. For instance, most of the mispredictions are explained by the network's inability to recognize small parts of a larger object such as chair arms and table legs. Some example images (with marked activation regions of DELTA) are shown in Figure 13 (b)."}, {"title": "8 COMPONENT ANALYSIS AND ABLATION STUDIES", "content": "We conduct a series of experiments to evaluate the effect of individual algorithmic components of the whole framework."}, {"title": "8.1 Experimental Setup", "content": "Datasets and Models. We conduct experiments on two image datasets: CIFAR10 [19] and ImageNet-1K [43]. We use three high-accuracy models (VGG16 [46], ResNet56 [12] and ResNet50 [12]) as the base models, which are also used for subgraph extraction method evaluation based on their popularity in the literature. We use seven popular and relatively low-accuracy models as the edge models.\nTable 4 lists the datasets and models used in this section. We use publicly available pre-trained models [1, 3] whenever possible and train four networks on CIFAR10 by ourselves: VGG8 [46], ResNet8 [12], AlexNetS [20] and MobileNetV2S [44] for 100 epochs with an exponentially decaying learning rate of 0.01. AlexNetS and MobileNetV2S are down-scaled AlexNet [20] and MobileNetV2 [44] to match the CIFAR10 dataset, respectively; Batch normalization layer is not included in VGG8; MobileNetV2S uses multiplier parameter of 0.35; ShuffleNetV2 [32] has 0.5\u00d7 output channels; SqueezeNet [15] is the 1.0 version. AlexNetS and AlexNet are defined as edge models due to their low computational cost and small feature extractor size. All the FLOPS of each model is measured using [2]\nConfigurations. The subgraphs of VGG16 and ResNet56 are extracted on an NVIDIA Tesla K80 GPU. ResNet50 required 16 NVIDIA Tesla V100-SXM2 GPUs due to large-sized model and dataset. The subgraphs are extracted under the magnitude criterion and fine-tuned for 300 epochs. A stochastic gradient descent optimizer with exponential decay and 0.001 learning rate is used in sparsity optimization, \u03b1 = 10-5, and \u03b2 = 10-7. We set \u03bb = 0.5 and \u03bb\u2081 = 1.0 in the loss terms. The predefined sparsity rates are {$i} \u2286 {0.125 \u00d7 k | k = 1,2,..., 7} for convolutional layers, and {$i} \u2286 {0.2 \u00d7 k | k = 1, 2, 3, 4} for fully connected layers."}, {"title": "8.2 Compactness of DELTA", "content": "Baselines and Metric. We use structured pruning algorithms that are related to our structured subgraph extraction technique as baselines including several state-of-the-art approaches: l\u2081-norm [22], ABCPruner [26], APRS [49], EZCrop [27], PFEC-KESI [21], ResRep [8], Random Pruning [23], TMI-GKP [57]. We compare the size and FLOPS of the extracted subgraph, and corresponding inference accuracy with our approach. The values shown in Figure 14 are directly reported from their original published papers. The retention of the last few layers in the subgraph is to ensure a fair comparison with other baselines.\nParameter and FLOPS Reduction. Figure 14 (a) shows that our subgraph extraction method achieves the highest accuracy of 94.61% after removing 13.74M parameters and reducing 0.226G FLOPS from original VGG16 model. When a more aggressive subgraph extraction is performed on VGG16 that removes 15.05M parameters, our method still achieves 91.35% accuracy. Figure 14 (b) shows similar results. Our method subtracts 0.45M parameters and reduces 0.07G FLOPS from ResNet56, yet achieves the highest accuracy of 94.61%. To further verify our subgraph extraction method, we use a large-scale dataset \u2013 ImageNet-1K that contains over 1.4 million images. Figure 14 (c) shows that ResNet50 reaches the highest accuracy of 75.364% after 15.07M parameters and 2.76G FLOPS reduction.\nConvergence. One of the advantages of our structured subgraph extraction technique is its ability to converge faster. To demonstrate this, we extract structured subgraph from VGG16 using our method as well as by a baseline strategy that generates and applies random masks from pre-configured sparsity rates for different layers. We use 10 different mask settings. For our method, a single mask is created using averaged sparsity and then applied to a layer. For the baseline, each mask is individually applied to get 10 different sets of results whose mean and variance are used for comparison. Figure 15 shows the cross-entropy loss of both techniques as the model is trained (fine-tuned) on CIFAR10 dataset. We use the same training configurations for fair comparison. We observe that our method not only converges fast but also keeps the loss relatively lower, which ensures its accuracy preservation ability during fine-tuning."}, {"title": "8.3 Complementary Capability of DELTA", "content": "Models and Metric. We take all nine compatible pairs of base and edge models from Table 4, and generate DELTA models under different parameter and FLOPS constraints. We use the following expressions to express parameter ratio and FLOPS ratio between two models:\n$P_{D/M} = \\frac{param(D)}{param(M)}, F_{D/M} = \\frac{flops(D)}{flops(M)}, M \u2208 {E, B}$ (6)\nwhere, D, E, and B denote DELTA, edge, and base models, respectively; param() and flops() denote parameter size and FLOPS of the input model. The parameter size and FLOPS of DELTA also include the corresponding values from Feature Resizing Module and Finetuning Module.\nFeature Representation Capability (Intra-family). Table 5 (a) and Table 5 (b) show the feature representation improvement reflected by improved accuracy due to DELTA for VGG16-VGG8 and ResNet56-ResNet8 pairs, respectively. For each pair, three DELTA models D0, D1, D2 are generated by enforcing three different parameter and FLOPS constraints. By extracting less than 2.6%-4.3% parameters from VGG16, DELTA models increase the accuracy of VGG8 by 8.65%-9.74% which is within 0.65%-1.74% of VGG16's accuracy of 94.16%. Although the inclusion of DELTA adds 8.8%-14.8% parameters and 58%-74% FLOPS when compared to the edge (VGG8) model, the combined size and FLOPS of edge (VGG8) and DELTA model is still 66.57%-68.32% and 62.22%-65.62% less than those of the VGG16 model. We observe a similar trend for the ResNet56-ResNet8 pair. The constraints for the three DELTA models are slightly relaxed considering the large accuracy gap between ResNet56 and ResNet8.\nFeature Representation Capability (Inter-family). Table 6 (a) and Table 6 (b) show the feature representation improvement reflected by improved accuracy, attributed to DELTA for four model pairs on CIFAR10 and three model pairs on ImageNet-1K, respectively, for different parameter and FLOPS constraints. We observe that by extracting less than 2.47%-32.35% parameters from base models on CIFAR10, DELTA models increase the accuracy of edge models by 7.61%-17.37% which is within 1.32%-4.50% of ResNet56's accuracy of 94.37% (the highest accuracy). The combined size and FLOPS of edge and DELTA model is 21.29%-93.55% and 55.96%-83.17% less than those of the base models. We observe a similar trend for the three pairs on ImageNet-1K. In this case, however, the constraints for the DELTA models have been relaxed considering the large accuracy gap between the base and the edge networks.\nNegative Correlation Evaluation. We calculate the correlation score [31] between DELTA and edge model of the given model pair to evaluate their relationship, which is computed using the samples that are misclassified by edge model but correctly predicted by base model. The results are shown in Table 7 for each model pair on a representative dataset (CIFAR10). The negative sign denotes a negative correlation between the edge model and DELTA, with the correlation score magnitude reflecting the disparity in their feature representation capabilities. Additionally, higher architectural similarity between the edge model and DELTA corresponds to a lower correlation score magnitude, indicating reduced complementarity in their represented features.\nKnowledge Distillation (KD) Comparison. We evaluate the feature representation capability of the edge model independently of the DELTA. To maximize the potential representation capability of the edge model, we employ the base model as a teacher to transfer distilled knowledge. In Table 8, knowledge distillation improves the edge model's accuracy by 2.55%-6.94%, while integrating the DELTA component yields a greater improvement (9.74%-17.37%)."}, {"title": "9 RELATED WORK", "content": "Model Dissimilarity/Similarity Explanation. Various approaches [6, 48, 56] of explaining single CNN model's decision making behavior using class activation map [6, 58] or other saliency-map based techniques [48, 56] are proposed in literature, which lacks the capability to understand the model difference. Recent model similarity comparison analysis studies [11, 16, 24] perform measurements across from model functional equivalence to feature-wise distance comparison. However, they fall short of straightforwardly explaining the fine-grained concept-level details of differences between multiple models' decision-making process.\nStructured Pruning. Structured pruning methods based on property importance [27, 54] limit model compression ratio and accuracy. Adaptive importance based approaches [10, 29] require specific design to monitor the filter importance and carefully tuned hyperparameters. Automatic sparsity search, as presented in the literature [26, 49], faces challenges in finding the optimal substructure due to the extensive search space and the trade-off between searching efficiency and accuracy. Our method utilizes a more compact search space to find the optimal subnetwork without special ranking technique to achieve state-of-the-art performance."}, {"title": "10 CONCLUSION", "content": "This paper presents XDELTA, a differential explainable AI tool designed to elucidate the distinctions between a lower-accuracy edge model and a higher-accuracy base model across multiple levels of detail. Central to this approach is the introduction of DELTA, a neural network architecture that captures the differences between model pairs. By augmenting the feature representation capabilities of the edge model, DELTA enables the combined system to achieve a feature representation on par with the base model. Utilizing the complementarity of DELTA, XDELTA offers explanations at various levels, ranging from high-level geometric insights to fine-grained, human-understandable details."}]}