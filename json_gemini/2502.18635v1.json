{"title": "FASTER, CHEAPER, BETTER: MULTI-OBJECTIVE\nHYPERPARAMETER OPTIMIZATION FOR LLM AND\nRAG SYSTEMS", "authors": ["Matthew Barker", "Andrew Bell", "Evan Thomas", "James Carr", "Thomas Andrews", "Umang Bhatt"], "abstract": "While Retrieval Augmented Generation (RAG) has emerged as a popular tech-\nnique for improving Large Language Model (LLM) systems, it introduces a large\nnumber of choices, parameters and hyperparameters that must be made or tuned.\nThis includes the LLM, embedding, and ranker models themselves, as well as hy-\nperparameters governing individual RAG components. Yet, collectively optimiz-\ning the entire configuration in a RAG or LLM system remains under-explored-\nespecially in multi-objective settings due to intractably large solution spaces,\nnoisy objective evaluations, and the high cost of evaluations.\nIn this work, we introduce the first approach for multi-objective parameter opti-\nmization of cost, latency, safety and alignment over entire LLM and RAG systems.\nWe find that Bayesian optimization methods significantly outperform baseline ap-\nproaches, obtaining a superior Pareto front on two new RAG benchmark tasks.\nWe conclude our work with important considerations for practitioners who are de-\nsigning multi-objective RAG systems, highlighting nuances such as how optimal\nconfigurations may not generalize across tasks and objectives.", "sections": [{"title": "INTRODUCTION", "content": "Retrieval Augmented Generation (RAG) has emerged as a popular technique for improving the per-\nformance of Large Language Models (LLMs) on question-answering tasks over specific datasets.\nA benefit of using RAG pipelines is that they can often achieve high performance on specific tasks\nwithout the need for extensive alignment and fine-tuning (Gupta et al., 2024), a costly and time-\nconsuming process. However, the end-to-end pipeline of a RAG system is dependent on many\nparameters that span different components (or modules) of the system, such as the choice of LLM,\nthe embedding model used in retrieval, the number of chunks retrieved and hyperparameters govern-\ning a reranking model. Examples of choices, parameters, and hyperparameters that are often made\nor tuned when implementing a RAG pipeline are listed in Table 1. Importantly, the performance of\na RAG pipeline is dependent on these choices (Fu et al., 2024), many of which can be difficult to\ntune manually. While those building RAG pipelines might avoid fine-tuning costs, they often spend\ntime and resources on hyperparameter optimization (HO).\nDespite this, there is little research exploring methods for collectively optimizing all the hyperpa-\nrameters in a given LLM and RAG pipeline (Fu et al., 2024). Further, to the best of our knowledge,\nthere is no work that addresses this challenge in multi-objective settings, where the RAG pipeline\nmust achieve high performance across a range of objectives, like minimizing a system's inference\ntime while maximizing its helpfulness. In this work, we aim to fill this gap by introducing an ap-\nproach for collectively optimizing the hyperparameters of a RAG system in a multi-objective setting.\nThe authors of this paper are from a mixture of both academia and industry, and this work was\nmotivated by real-world challenges faced by industry practitioners. Use of RAG pipelines within\nindustry often requires balancing multiple requirements which are in competition with one another.\nFor example, at one financial services firm developing an in-house Q&A chatbot to support internal\nworkflows, practitioners aimed to both maximize accuracy and minimize the time taken to generate\na response. However, there is a tension in these two objectives: a RAG system utilizing larger\nmodels may yield more accurate responses, but consequently requires longer computation time. As\nanother example, a large bank developing an external insurance policy Q&A chatbot was primarily\nconcerned with the alignment of generated responses to policies and regulations. Objectives that\nwe have observed practitioners frequently consider when building RAG pipelines include: cost,\nresponse latency, safety (hallucination risk), and alignment (response helpfulness).\nMulti-objective HO over a RAG pipeline is particularly challenging for several reasons. First, RAG\npipelines naturally have a high number of parameters, leading to a large solution space. We identify\nat least 15 example choices, parameters, and hyperparameters in Table 1. Even if one has just a\nhandful of possible values for each choice, the parameter space becomes intractably large for simple\nalgorithms like grid search. Second, evaluating a RAG pipeline during the HO process is costly,\nwith respect to both compute resources and time: it requires running the RAG system over multiple\nqueries (where each iteration is bounded by the per-token inference time of the LLM), and then\nevaluating each output. Third, the objective evaluations can be noisy. The true characteristic of a\nRAG system cannot be computed directly, and requires sampling the evaluations from many queries.\nRelatedly, since in most cases LLMs are non-deterministic, combinations of hyperparameters need\nto be tested over multiple seeds.\nContributions. In this work, we make four main contributions:\n(1) We introduce an approach for multi-objective optimization over a unique set of hyper-\nparameters of a RAG pipeline, including choices for the LLM and embedding models\nthemselves. Our approach implements a single composite objective value called the hy-\npervolume improvement (Guerreiro et al., 2021), and uses Bayesian optimization with\nan acquisition function that allows for an arbitrary number of noisy objective functions\n(qLogNEHVI) (Daulton et al., 2021; Ament et al., 2023) to find the best RAG pipeline\nconfiguration.\n(2) We empirically show the effectiveness of our approach to identify optimal RAG pipeline\nconfigurations across two tasks (one related to financial services Q&A, and another related\nto medical Q&A) using a train-test paradigm, as compared to random parameter choices\nand other baseline optimization approaches.\n(3) We publicly release two novel benchmarks for evaluating RAG systems called\nFinancialQA and MedicalQA. Importantly, these benchmarks more closely mimic\nindustry RAG use-cases than currently available benchmarks, since the context must be\nretrieved at runtime from an available document, rather than being given in the dataset.\n(4) We frame our discussion (Section 7) as guidance to practitioners who seek to improve\ntheir own RAG systems. We highlight two important considerations: the first is what we\ncall \"task dependence\u201d, meaning that an optimal configuration for a RAG pipeline on a\ntask in a specific setting may not generalize to another setting. The second is \u201cobjective\ndependence\", where objective evaluations follow different trends (or have no trend) across\ndifferent configurations. Task and objective dependence can also compound, highlighting\nthe challenge of collectively optimizing the parameters of a RAG system."}, {"title": "RELATED WORK", "content": "There has been a mixture of work separately addressing multi-objective optimization and hyperpa-\nrameter optimization in LLM and RAG systems, which we summarize here. We provide further\ncomparison with fine-tuning and model-merging approaches in Appendix A.\nHyperparameter optimization (HO). As many pieces of LLM and RAG pipelines have hyper-\nparameters that must be tuned before deployment, there is a large body of work testing the efficacy\nof using HO to tune these systems.\nWang et al. (2023) propose a cost-based pruning strategy to hyperparameter tune LLM systems\nunder budget constraints. They focus on hyperparameters like the type of model (e.g., text-davinci-\n003, gpt-3.5-turbo, or gpt-4), the maximum number of tokens that can be generated in a response,\nthe model temperature, and the model top-p. They use a search method called BlendSearch (Wang\net al., 2021), which combines Bayesian optimization and local search (Wu et al., 2021), to find the\noptimal combinations of parameters, and measure performance on the tasks APPS (Hendrycks et al.,\n2021), XSum (Narayan et al., 2018), MATH (Hendrycks et al., 2021), and HumanEval Chen et al.\n(2021). In comparison with our work, Wang et al. (2023) do not consider a RAG system.\nMost related to our work, Kim et al. (2024) proposed AutoRAG, an open-source framework de-\nsigned for RAG experimentation and hyperparameter optimization. They use a a greedy algorithm\nfor selecting the hyperparameters governing RAG modules like query expansion, retrieval, passage\naugmentation, passage re-ranking, prompt making, and generating (the LLM). In concurrent work,\nFu et al. (2024) proposed AutoRAG-HP, which frames hyperparameter selection as an online multi-\narmed bandit (MAB) problem. To carry out HO, they introduce a novel two-level Hierarchical MAB\n(Hier-MAB) method, where a high-level MAB guides the optimization of modules, and several low-\nlevel MABs search for optimal settings within each module. Significantly, our work is distinct from\nboth Kim et al. (2024) and Fu et al. (2024) in that they do not consider multi-objective settings.\nMulti-objective alignment. Several researchers have proposed methods for incorporating multi-\nple objectives directly into the LLM fine-tuning and alignment processes. Li et al. (2020) devel-\noped an approach for multi-objective alignment from human feedback using scalar linearization.\nMukherjee et al. (2024) expanded on that approach by developing an algorithm that finds a diverse\nset of Pareto-optimal solutions that maximize the hypervolume, given a set of objectives. Zhou et al.\n(2024) proposed a reward-function free extension called Multi-Objective Direct Preference Opti-\nmization (MODPO). The latter showed that MODPO can effectively find a Pareto-optimal frontier\nof fine-tuned models, trading off objectives like \u201chelpfulness\u201d and \u201charmlessness\". While these\""}, {"title": "PRELIMINARIES AND PROBLEM FORMULATION", "content": "Multi-Objective Optimization (MOO). The goal of MOO is to find a solution \\(x \\in X\\) that maxi-\nmizes (or minimizes) a set of objective functions, where \\(x = [x_1,x_2, . . . x_1]\\) corresponds to a series\nof input values, and \\(X\\) is said to be the solution space. We then define each objective as \\(f : X \\rightarrow R\\)\nand use \\(f: X \\rightarrow R^k\\) to represent \\(k\\) objective functions. Using these definitions, we aim to solve the\nfollowing optimization problem:\n\\[\\max_{x \\in X} f(x) := \\max_{x \\in X} [f_1(x), f_2(x), ... f_k(x)]\\]\nRather than identifying a single solution, MOO algorithms identify a set of non-dominated solu-\ntions (Deb et al., 2016). We use \\(f(x^*) \\succ f(x)\\) to signify that \\(f(x^*)\\) dominates \\(f(x)\\):\n\\[\\forall i\\in \\{1,...,k\\}, f_i(x) \\leq f_i(x^*), and \\exists j s.t. f_j(x) < f_j(x^*)\\]\nHence, and following Daulton et al. (2021), we define the Pareto set as \\(P^* = \\{f(x^*) | x^* \\in\nX,\\nexists x \\in X s.t. f(x) \\succ f(x^*)\\}\\), and the corresponding Pareto optimal solutions as \\(X^* = \\{x^* |\nf(x^*) \\in P^*\\}\\). In practice, the Pareto optimal set often consists of an infinite set of points. Given a\nset of observed solutions from \\(X\\), we aim to identify an approximate Pareto optimal set, \\(\\hat{P} \\subset R^k\\),\nand its associated Pareto optimal solutions, \\(\\hat{X}\\). We then use the hypervolume (HV) indicator, \\(HV\\), to\nevaluate the quality of \\(\\hat{P}\\) given a reference point \\(r \\in R^k\\). Our optimization problem then becomes:\n\\[\\max_{\\hat{P}} HV(\\hat{P}|r)\\]\nIn this work, we seek to find the Pareto-optimal combinations of parameters of a RAG system (those\nindicated in Table 1). We represent a configuration of a RAG system as a solution vector \\(x \\in X\\,"}, {"title": "METHODOLOGY", "content": "Our approach works by defining a solution space (over the configurations of a RAG pipeline), objec-\ntives, and a train-test paradigm, then using BO to find the optimal configuration. BO is well-suited\nto exploit patterns in objective evaluations, for example the tendency for latency to increase with\nchunk size. We allow that the solution space has a mixture of continuous variables (e.g., tempera-\nture of LLM) and categorical variables (e.g., choice of LLM). In addition, we allow for constraints\non the inputs, such as asserting that the chunk overlap must be less than the chunk size.\nWe make use of two state-of-the-art algorithms that implement and extend BO. The first,\nqLogEHVI, takes advantage of recent advances in programming models and hardware acceleration\nto parallelize multi-objective BO using the LogEI variant (Ament et al., 2023) of expected hyper-\nvolume improvement to guide the acquisition of new candidate solutions (Daulton et al., 2020). The\nsecond is qLogNEHVI, which extends qLogEHVI by using a novel acquisition function that was\ntheoretically motivated and empirically demonstrated to outperform benchmark methods in settings\nwith noisy objective evaluations (Daulton et al., 2021). The noisy variant is particularly useful since\nthe probabilistic nature of LLMs can cause noisy objective function evaluations. BO is also well-\nsuited to exploit patterns in objective evaluations, for example the tendency for latency to increase\nwith chunk size. Following Daulton et al. (2021), we initialize both BO algorithms with \\(N_{init}\\) points\nfrom a scrambled Sobol sequence.\nWe outline our proposed methodology in Algorithm 1, and provide implementation details in Sec-\ntion 5. We also provide a method of approximating each objective function in Appendix B."}, {"title": "GENERATING TRAIN-TEST QUERIES", "content": "A frequent challenge encountered by the authors in industry is a lack of existing queries for RAG\nQ&A tasks. To this end, we use LLMs to help generate queries from the data, which may be PDF\ndocuments or large documents of text. LLMs are a reasonable choice for this approach because\nthey have been shown to be effective at generating synthetic data (Long et al., 2024). For our\nFinancialQA dataset described in Section 5.1, we generate train and test queries using an LLM\n(GPT-40). We publicly release the synthetic questions as part of our datasets, and provide the prompt\nused to generate the questions in Appendix D."}, {"title": "OBJECTIVES", "content": "Motivated by experiences in industry, we consider four objectives that practitioners commonly con-\nsider important: safety, alignment, cost and latency.\nSafety. In this work, we use the term \"safety\" to refer to hallucination risks, or the risk that a RAG\npipeline will return false information to the user. Hallucinations can cause significant downstream\nharm, particularly in high-stakes domains such as healthcare. In our experiments, we evaluate safety\nusing the faithfulness metric defined in the Trustwise API. Like previous work (Min et al., 2023;\nEs et al., 2023), faithfulness detects hallucinations by evaluating whether or not the response from\na RAG system is supported by the context. The response is split into individual, \u201catomic\" claims\nthat are verified with respect to the context. Scores of these verifications are then aggregated into a\nsingle faithfulness score between 0 and 100 for each response, where 100 represents a completely\n\"safe\" response with no hallucinations.\nAlignment. While hallucination risks are an immediate concern, the alignment of a response is\noften just as important in enterprise use-cases. To evaluate alignment, we follow the definition of\nhelpfulness popularized by Anthropic (Bai et al., 2022). We measure alignment using the helpfulness\nmetric as implemented in the Trustwise API which judges how useful, detailed and unambiguous a\nresponse is. This metric assigns a score between 0 and 100 for each response, where a higher score\nindicates a more helpful response.\nCost. To calculate the cost of an evaluation, we consider all the components of a RAG pipeline,\nincluding the query embedding cost, reranker embedding cost, LLM input token cost and LLM\noutput token cost. Importantly, the cost of a RAG pipeline is a function of its configuration:\n\\[\\begin{aligned}\ncost = &\\text{ number of query tokens } \\times \\text{ cost per embedding token } \\\\\n& + \\text{ number of context tokens } \\times \\text{ cost per reranker token } \\\\\n& + \\text{ number of prompt input tokens } \\times \\text{ cost per LLM input token } \\\\\n& + \\text{ number of output tokens } \\times \\text{ cost per LLM output token }\n\\end{aligned}\\]\nThe embedding cost per query token, reranker token cost, LLM input token cost, and LLM output to-\nken cost are based on the specific choices of those models, as well as the hardware being used to run\nthe RAG pipeline. In enterprise use-cases, these costs may also include overhead and maintenance.\nLatency. We define latency as the time it takes for a complete end-to-end run of the RAG pipeline,\nfrom the moment an initial query is sent to the system to the moment a full response is returned to\nthe user. As with cost, we can calculate the latency of a system as a function of its configuration:\n\\[\\text{latency} = \\text{embedding latency} + \\text{reranker latency} + \\text{LLM response latency} + \\text{evaluation latency }\\]\nWe note that response evaluations can take as long as, or longer than, response generation and thus\nthe end-to-latency is vital to consider in enterprise settings where evaluations are a requirement."}, {"title": "EXPERIMENTS", "content": "We tested our optimization approaches on two RAG tasks from different industries. We use a stan-\ndard RAG setup with retrieval using vector embeddings, a reranker to filter out unnecessary context\nchunks, and an LLM prompted to generate a response using the context. The exact configuration\nsolution space we use is given in Appendix C.\nWe optimize for the four objectives of cost, latency, safety and alignment. We run BO using the\ntrain question set, and then report results on a held out test set. We use Ax (Bakshy et al., 2018) and\nBoTorch (Balandat et al., 2020) to run and manage experiments. For all algorithms we use 50 total\niterations, and for BO methods, the first 20 iterations are chosen using Sobol sampling. In MOO,\na reference point is used to calculate the HV improvement, and represents the minimum acceptable\nsolution. Based on our industry experience, we use a reference point with cost of $2000 per million\nqueries, latency of 20s per query, safety of 50 and alignment of 50. This choice of reference point\nprevents degenerate solutions (e.g., a degenerate RAG system which does not retrieve any chunks)\nfrom contributing to the HV improvement.\nThroughout this work, we report the cost in USD per million queries ($/ million queries) and latency\nin seconds (s). Safety and alignment scores are dimensionless and range from 0 to 100. Cost and\nlatency are objectives to minimize, while safety and alignment are objectives to be maximized."}, {"title": "DATASETS", "content": "Existing datasets for Q&A tasks generally exist in the form of (question, context, answer) triplets.\nHowever, in industry RAG use-cases, the context is often retrieved at runtime from a set of docu-\nments. As such, we want to include the retrieval of the context as part of of our evaluation. To this\nend, we adapt two known tasks to fit the needs of our experimental setup7:\nFinancialQA. This task uses a publicly available document covering revenue recognition from a\nleading global accounting firm. The document includes more than 1000 pages of text, representing\na significant Q&A context retrieval challenge. Since the document does not come with a set of\nquestions, we synthetically generate 50 questions by prompting GPT-40, using the method described\nin Section 4.1. We then randomly split this set into 30 train and 20 test questions."}, {"title": "BASELINES", "content": "For our tasks, we lack access to a \"ground truth\" set of Pareto optimal configurations because we can-\nnot evaluate the objective functions directly, and grid search is computationally unfeasible. Hence\nwe use three baseline approaches that are applicable in MOO settings. The first is uniform sampling,\nwhich generates configurations independently, where each configuration from the solution space is\nequally probable. The second is Sobol sampling. Like latent hypercube sampling (Loh, 1996), this\nmethod generates configurations that guarantee good high-dimensional uniformity. It is commonly\nused to initialize optimization algorithms, including BO, and represents a sensible alternative to\ngrid-search. Finally, we use qLogEHVI BO, the noiseless variant of our chosen acquisition func-\ntion (Daulton et al., 2020)."}, {"title": "RESULTS", "content": "We report the HV improvement on the train and test splits of both datasets, across five random seeds\nin Figure 2. We find that BO methods significantly outperform other baseline approaches on both"}, {"title": "DISCUSSION", "content": "We frame our discussion as takeaways for industry practitioners that aim to optimize configurations\nof a RAG pipeline in a multi-objective setting. The first consideration is what we call objective\nrelationships. In our experiments, we found that safety and alignment are often positively correlated\nwith each other, and similarly for cost and latency. However, these two sets of objectives involve\nconflicting parameters, which makes it challenging to set a suitable trade-off between reliability\n(safety and alignment) and efficiency (cost and latency). Resolving conflicts between objectives is\ninherently challenging and remains an open question; we recommend that practitioners be thoughtful\nabout latent relationships between objectives when choosing which objectives to optimize over.\nThe second consideration is task dependence, meaning that an optimal configuration for a RAG\npipeline on a task in one setting may not generalize to another. While we observe configurations\nthat work well across both tasks with respect to certain objectives (e.g., high chunk size correlates\nwith higher safety and alignment), there is no optimal configuration that is shared across the two\ntasks. Practitioners should be aware that the optimal configuration will be highly dependent on\nthe task they are building for, including the way their system will be used, the domain, and the\nstakeholders.\nThe third consideration is objective dependence, where objective evaluations follow different trends\n(or have no trend) across different configurations. For example, we see high objective dependence"}, {"title": "Future Work", "content": "Our results demonstrate that end-to-end optimization of RAG systems is a promis-\ning avenue for research. We highlight two key areas for future exploration: first, improving the\nefficiency of Algorithm 1. A potential direction is \"decoupled evaluation\", where not all objectives\nare assessed at every iteration, towards a cost-aware optimization strategy. For instance, evaluating\nsafety and alignment is significantly more expensive than measuring cost and latency.\nSecond, improvements can be made to the framework itself. Our current approach does not account\nfor prompt engineering, despite its significant impact on response quality. Additionally, our safety\nand alignment metrics considered in this work remain limited in scope, excluding aspects such as\ntoxicity and data leakage. However, our framework is inherently flexible and can be extended with\nadapted objectives or additional parameters. Another open challenge is configuration selection from\nthe Pareto frontier. As Figure 3 illustrates, multiple configurations are Pareto-optimal, making the\nselection of the most suitable trade-off for a given application non-trivial."}, {"title": "APPROXIMATING OBJECTIVE FUNCTIONS", "content": "Equation 3 defines our proposed task as the maximization of the HV across multiple objectives.\nEach objective function evaluates a property of the RAG system for a given workload. We define\na workload as a probability distribution across all possible queries, \\(P(q)\\), where \\(q \\in Q\\) is a user\nquery for the RAG system. Further, we use \\(f_r: X, Q \\rightarrow R\\) to denote an evaluation function for an\nindividual query and objective m. Using these definitions, we can write down the objective function\nas the expectation across queries:\n\\[f_m(x) = \\sum_{q\\in Q} f_r(x, q)P(q)\\]\nAssuming we can sample queries from the workload, \\(q \\sim P(q)\\), we can use a Monte Carlo approx-\nimation for each objective function using a sample set \\(Q' \\subset Q\\):\n\\[f_m(x) \\approx \\frac{1}{|Q'|}\\sum_{q\\in Q'}f_r(x,q)\\]\nWe assume that generating data synthetically using an LLM (Section 4.1) is equivalent to sampling\nqueries \\(q \\sim P(q)\\) to obtain \\(Q'\\). Our algorithm uses Equation 7 as a tractable approximation of the\nobjective functions in Equation 1."}, {"title": "EXPERIMENTAL DETAILS", "content": "We use the following search space for hyperparameters:\n\u2022  \\(c_s \\in Z^+\\): Maximum number of tokens in each document chunk.\n\u2022  \\(c_n \\in Z^+\\): Number of chunks retrieved from the vector database for each query.\n\u2022 \\(o \\in Z^+\\): Number of tokens which overlap between adjacent chunks in a document.\n\u2022 \\(t \\in [0, 1.2]\\): Temperature of the LLM when generating responses.\n\u2022 \\(r \\in [0, 1]\\): Rerank threshold used to set the minimum similarity between the context chunk\nand query, as evaluated by the reranker14. Retrieved documents which are below this thresh-\nold are ignored and not passed to the LLM as context. If no chunks exceed this threshold,\nwe choose only the highest scoring chunk as context.\n\u2022 \\(l\\in \\{gpt-40, gpt-40-mini, llama-3.2-3B, llama-3.1-8B\\}\\): Choice of LLM used to generate\nthe response.\n\u2022 \\(e \\in \\{text-embedding-3-large, text-embedding-3-small\\}\\): Choice of embedding model\nwhen embedding the queries and document chunks."}, {"title": "LLM PROMPTS", "content": "We use the following prompt with GPT-40 to generate synthetic questions from the financial source\ndocument:\nYou are an expert synthetic data generation agent. Look at this PDF\ndocument containing information on accounting from a leading global\nfinancial services organization. Generate 50 questions which\naccountants might ask based only on the information provided in the\ndocument. Example questions are:\nAre there any specific disclosures required when transferring HTM\nsecurities to AFS?\nAre there any tax implications to consider when transferring securities\nbetween categories?\nWhat are the steps to recording a transfer of AFS securities to HTM?\nHow should Federal agencies implement the new Land standard?\nI have a client in bankruptcy, what is the presentation of financial\nstatements once they emerge from bankruptcy\nHow do you determine if a limited partnership is a VIE\ncan a debt being refinanced with a different lender result in\nmodification accounting?\nAre there specific criteria for capitalizing costs related to PP&E\nadditions?\nhow do you account for PP&E additions\nwhich examples in the debt and equity handbook illustrate the accounting\nfor preferred stock?\nAre there any examples of exit fees in investment company accounting?\nFor prompting the LLM during RAG, we use the following prompt from https://smith.\nlangchain.com/hub/rlm/rag-prompt:\nYou are an assistant for question-answering tasks. Use the following\npieces of retrieved context to answer the question. If you don't know\nthe answer, just say that you don't know. Use three sentences\nmaximum and keep the answer concise.\nQuestion: {question}\nContext: {context}\nAnswer:"}, {"title": "ADDITIONAL RESULTS", "content": ""}]}