{"title": "Graph-Structured Trajectory Extraction from Travelogues", "authors": ["Aitaro Yamamoto", "Hiroyuki Otomo", "Hiroki Ouchi", "Shohei Higashiyama", "Hiroki Teranishi", "Hiroyuki Shindo", "Taro Watanabe"], "abstract": "Previous studies on sequence-based extraction of human movement trajectories have an issue of inadequate trajectory representation. Specifically, a pair of locations may not be lined up in a sequence especially when one location includes the other geographically. In this study, we propose a graph representation that retains information on the geographic hierarchy as well as the temporal order of visited locations, and have constructed a benchmark dataset for graph-structured trajectory extraction. The experiments with our baselines have demonstrated that it is possible to accurately predict visited locations and the order among them, but it remains a challenge to predict the hierarchical relations.", "sections": [{"title": "Introduction", "content": "Travelogues are a significant source for analyzing human traveling behavior in various fields, including tourism informatics (Akehurst, 2009; Hao et al., 2010) and human geography (Cooper and Gregory, 2011; Caselli and Sprugnoli, 2021), because of their rich geographic and thematic content, which gives people, for example, a simulated experience of trip (Haris and Gan, 2021). In particular, human traveling trajectories play a central role in characterizing each travelogue, and thus, automatic trajectory extraction from travelogues is highly desired for tourism services, such as travel planning and recommendation (Pang et al., 2011).\nSome studies have addressed automatic trajectory extraction from text (Ishino et al., 2012; Wagner et al., 2023; Kori et al., 2006). However, these studies have two problematic issues: (i) inadequate trajectory representation and (ii) the scarcity of benchmark datasets.\nFirst, the previous studies treated each trajectory as a sequence of visited locations (Ishino et al.,"}, {"title": "Preliminaries for Data Construction", "content": "Our dataset, ATD-VSO, has been constructed on the basis of ATD-MCL (Higashiyama et al., 2023), which is a Japanese travelogue dataset annotated with geo-entity information, including mentions and their coreference relations, using a subset of the original travelogues, the Arukikata Travelogue"}, {"title": "Visit Status Prediction", "content": "In this section, we describe the task definition, annotation data construction, and our baseline system for Visit Status Prediction (VSP), which is the first step of trajectory extraction with given mentions and entities. The goal of VSP is to identify locations that the traveler visited by assigning a visit status for each location mentioned in the travelogue. For example, it is possible to judge that the traveler actually visited the station from the description of the real experience: \u201cArrived at Kintetsu Nara Station!\u201d In contrast, the following factual statement does not indicate whether the traveler visited these stations or not: \u201cJR Nara Station is a little far from Kintetsu Nara Station.\u201d"}, {"title": "Annotation Data Construction", "content": "We defined two types of visit status labels for entities and six types of visit status labels for mentions. The mention labels serve to distinguish detailed status for the mentioned locations based on the context, which typically corresponds to the sentence where the mention occurs. The entity labels serve to determine whether the traveler eventually visited the location, considering the context of the entire document.\nAs annotation work, native Japanese annotators at a data annotation company assigned visit status labels to each mention and entity in ATD-MCL travelogues using the brat annotation tool (Stenetorp et al., 2012), according to the label definitions and annotation guideline."}, {"title": "Task Definition", "content": "Entity-level and mention-level VSP are defined as follows: Given a set of entities $\\mathcal{E}$ in an input document, entity-level VSP requires a system to assign an appropriate visit status label $y \\in L_e$ for each entity $e_q \\in \\mathcal{E}$. Similarly, given an entity (or coreference cluster) $e_q = \\{m_1^{(q)}, ..., m_{e_q}^{(q)}\\}$, which consists of one or more mentions, mention-level VSP requires a system to assign an appropriate visit status label $y \\in L_m$ for each mention $m_i^{(q)} \\in e_q$."}, {"title": "Baseline System", "content": "As our baseline system, we employ a two-step method that first predicts mention labels and then predicts entity labels based on the mention labels. Specifically, we calculate the label probability distribution $P(y/m_i^{(q)})$ for each mention $m_i^{(q)} \\in e_q$, and select the most probable label $\\hat{y}_i^{(q)}$:\n$\\hat{y}_i^{(q)} = \\underset{y \\in L_m}{\\text{arg max}} P(y/m_i^{(q)})$.\nThen, we select a label for each entity $e_q$ according to the following mention label aggregation (MLA) rules.\n1.  If Visit or PlanToVisit has been assigned to at least one mention in $e_q$, then Visit is assigned to $e_q$.\n2.  Otherwise, Other is assigned to $e_q$."}, {"title": "Model Implementation", "content": "As the implementation of a model for mention label prediction, we used LukeForEntityClassification in Hugging Face Transformers with the inputs of the sentence containing the mention of interest and the position (character offsets) of the mention."}, {"title": "Visiting Order Prediction", "content": "In this section, we first define a visiting order graph, which is a key concept for our structured trajectory extraction. Then, we describe the task definition, annotation data construction, and our baseline system for Visiting Order Prediction (VOP), which involves prediction of geographic and temporal relations between visited locations."}, {"title": "Visiting Order Graph", "content": "We introduce a visiting order graph to represent non-linear relations of visited locations."}, {"title": "Annotation Data Construction", "content": "After the visit status annotation step, only entities with the Visit label were retained as the nodes of a visiting order graph and used as input for a successive relation annotation step. In this step, annotators assigned relations between the entities using an online whiteboard service, Miro, which can be served as an annotation tool with GUI."}, {"title": "Task Definition", "content": "The task of VOP involves two subtasks: Inclusion Relation Prediction (IRP) and Transition Relation Prediction (TRP)."}, {"title": "Inclusion Relation Prediction", "content": "Given a set of entities $\\mathcal{E}$ in a document, IRP requires a system to determine the parent entity for each entity $e_q \\in \\mathcal{E}$ from the set of candidate entities $P_{cand}^{(q)} = \\mathcal{E} \\setminus \\{e_q\\} \\cup \\{\\text{ROOT}\\}$. If $e \\in P_{cand}^{(q)}$ is predicted as the parent entity for $e_q$, it means that $e$ includes $e_q$. The pseudo parent node ROOT should be predicted when the entity of interest has no parent entities."}, {"title": "Transition Relation Prediction", "content": "Given a set of entities $\\mathcal{E}$ in a document, TRP requires a system to determine the entity subsequently visited for each entity $e_q \\in \\mathcal{E}$ from the candidate set $S_{cand}^{(q)}$ with the same parent as that of $e_q$: $S_{cand}^{(q)} = \\{e_k \\in \\mathcal{E} \\mid e_k \\neq e_q | Par(e_k) = Par(e_q)\\} \\cup \\{\\text{EOS}\\}$. Here, $Par(e)$ represents the parent entity of $e$, and the pseudo subsequent node EOS (End of Sequence) represents that the entity of interest has no subsequent entities."}, {"title": "Baseline System", "content": "The baseline systems adopt similar methods for the two subtasks. Specifically, for IRP and TRP, we select the most probable entity as the parent entity $\\hat{e}_p$ and the subsequent entity $\\hat{e}_s$ from the corresponding candidate set based on score functions $score_{par}$ and $score_{sub}$, respectively:"}, {"title": "Model Implementation", "content": "To implement models with the score functions for both IRP and TRP, we used LukeForEntityPairClassification (Yamada et al., 2020) in Hugging Face Transformers, which receives the input text and the positions (character offsets) of two mentions. The input text is constructed by concatenating the two sentences containing representative mentions for the target entity $e_q$ and a candidate entity $e'$ and all the sentences that occur between them, in the order of their occurrence."}, {"title": "Representative Mention Selection", "content": "For IRP, proper noun mentions are prioritized over others and selected as representative ones. For TRP, we define the priority for visit status labels, i.e., Visit > See > other labels, and select the mentions with higher priority as representative ones."}, {"title": "Sequence Sorting Decoding", "content": "For TRP, all sibling nodes sharing the same parent node should be arranged in a single sequence. However, na\u00efve decoding based on predicted pairwise scores (Equation 2) does not necessarily satisfy this requirement. To address this issue, we introduce sequence sorting decoding based on a greedy search strategy as follows.\n1.  Let $\\mathcal{P}$ a set of all possible pairs whose nodes have the same parent.\n2.  Select a pair $(e_a, e_b)$ with the highest score from $\\mathcal{P}$.\n3.  Exclude all pairs conflicting with $(e_a, e_b)$ from $\\mathcal{P}$, namely, $(e_b, e_a)$, $(*, e_b)$ and $(e_a, *)$. Here, \"*\" indicates an arbitrary node.\n4.  If transition relations among all the nodes have been determined, terminate the decoding. Otherwise, return to Step 2."}, {"title": "Experiments", "content": "We evaluated the performance of our baseline systems and basic rule-based systems for the visit status prediction (VSP) task (\u00a73.3) and the visiting order prediction subtasks: inclusion relation prediction (IRP) and transition relation prediction (TRP) (\u00a74.4)."}, {"title": "Experimental Settings", "content": "Data Split As shown in Table 2, we split the 100 documents in ATD-VSO into training, development, and test sets at a ratio of 7:1:2."}, {"title": "Results for Visit Status Prediction", "content": "Systems We evaluated a rule-based system (Majority Label) and baseline systems (LUKE and LUKE+MLA). The Majority Label rule always"}, {"title": "Directions for Improvement", "content": "The LUKE baselines take limited context as input. LUKE predicts a label for each mention based on the context within the sentence where the mention occurs, and the MLA rule predicts a label for the entity by merely aggregating the mention-level predictions. A possible direction to improve entity-level performance is to construct an end-to-end model that integrates information on all mentions for an entity with the wider context of the document."}, {"title": "Results for Inclusion Relation Prediction", "content": "Systems We evaluated two rule-based systems (Random and Flat) and a baseline system (LUKE). Random is a rule-based system that randomly selects the parent entity from the candidate set for each entity. Flat is the other rule-based system that always selects ROOT as the parent entity for an arbitrary entity. LUKE indicates the baseline system described in \u00a74.4."}, {"title": "Directions for Improvement", "content": "The current LUKE baseline has two limitations. First, the absolute overall performance (F1 of 0.355) has substantial room for improvement. Potential reasons for the limited performance are that (1) the pretrained LUKE model for general entity analysis tasks did not learn geographic relations among specific geo-entities, and (2) it was difficult to obtain generalized knowledge on geographic relations between entities from fine-tuning only with text-based features. Possible solutions include pretraining with geospatial information like GeoLM (Li et al., 2023), and fine-tuning a model with geocoding-based features, such as predicted coordinates and shapes of entities. Second, the performance is quite low for entities whose parent is ROOT. This is because the baseline predicts ROOT as the parent for an entity"}, {"title": "Results for Transition Relation Prediction", "content": "Systems We evaluated three rule-based systems (Random and two variants of OccOrder) and two variants of the LUKE baseline system. The Random rule randomly lines up candidate entities for each set of entities with the same parent entity. OccOrder arranges candidate entities in the order of occurrence of each representative mention in their document; whereas the \u201cearly mention\" strategy (OccOrder-EM) uses the earliest occurrence mention as the representative mention, the \u201cvisit status\u201d strategy (OccOrder-VS) prioritizes mentions based on visit status label similarly to LUKE (\u00a74.4). The LUKE variants correspond to the baseline system with na\u00efve score-based decoding and sequence sorting decoding (\u00a74.4)."}, {"title": "Directions for Improvement", "content": "The current LUKE baseline has two limitations. First, the vector representation of an entity is constructed from a single mention selected by the heuristic rule (\u00a74.4), which limits the context of the entity. This would be improved by extending the context to include all mentions for two entities of interest, although it is necessary to explore an effective method that can grasp complicated relations among many mentions. Second, the current baseline uniformly treats entity pairs without transition relation as negative instances. However, entity pairs with indirect transition relation, where one is visited before the other via one or more entities, can be exploited as positive instances for an auxiliary task, similarly to relative event time prediction (Wen and Ji, 2021)."}, {"title": "Error Analysis", "content": "We investigated tendencies of prediction errors of the current baseline systems: LUKE+MLA for VSP, LUKE for IRP, and LUKE with na\u00efve score decoding (\u00a76.3) or sequence sorting decoding (\u00a76.4) for TRP. The following subsections describe our error analysis in the settings of independent prediction for each task and integrated pipeline prediction for the three tasks."}, {"title": "Visit Status Prediction", "content": "As stated in \u00a75.2, the LUKE baselines often misclassified mentions with the UnkOrNotVisit label and entities with the Other label. Our analysis reveals two error tendencies. First, LUKE sometimes failed to distinguish factual statements from descriptions of traveler's visitation. For example,"}, {"title": "Inclusion Relation Prediction", "content": "The results shown in Table 5 (\u00a75.3) have indicated that IRP is a challenging task. Our analysis reveals that LUKE learned the tendency that prefectures and cities often become parents of some entities, but LUKE also sometimes made incorrect predictions, such as a prefecture/city being the parent of another prefecture/city. For example, LUKE predicted \u201cNagoya\u201d as the parent of \u201cIse,\u201d although both are cities (sentence 046 of document 20816 in Table 7). This suggests that the model lacks commonsensical geographic knowledge."}, {"title": "Transition Relation Prediction", "content": "The results shown in Table 6 (\u00a75.4) have indicated difficulty in predicting reverse-order entity pairs. An example reverse pair is in sentences 024 and 025 (document 20851) in Table 7. While \u201cDaiouji Temple\u201d precedes \u201cthe station,\u201d these sentences describe that the traveler moved from the station to the temple. Although LUKE tended to predict the correct order of reverse pairs when there were some clues, such as temporal expressions like \u201cbefore\u201d and \u201cafter,\u201d but the system made incorrect predictions for reverse pairs without salient clues, including the above example."}, {"title": "Pipeline Prediction", "content": "Figure 3 shows the gold visiting order graph and prediction from the baseline systems connected in the pipeline for document 00019.\nFor VSP, LUKE made correct predictions for 10 out of 13 entities. The three errors were caused by the predictions for three mentions in sentence 009 in Table 8; LUKE incorrectly predicted the mention label See, and then the MLA rule determined the entity label Other. LUKE failed to grasp the nuanced meaning of the sentence, which describes a photo of the facilities (\u201cfive-storied pagoda\u201d and \"Kofukuji Temple\") taken by the traveler and the nearby location (\u201cSarusawaike Pond\u201d).\nFor IRP, LUKE predicted correct parents for four out of seven entities with the predicted label Visit and incorrect parents for the remaining three entities. Two of the failed entities are written with"}, {"title": "Related Work", "content": "This study also relates to a number of studies on:\nVisit Status Prediction\nVisit status prediction can be regarded as a task in the field of human movement analysis for text, which includes a major stream of predicate-centric analysis and another location-centric analysis."}, {"title": "Predicate-Centric Analysis", "content": "Represented by SPACEBANK, a line of studies have sought to develop computational models that can recognize, generate and reason about spatial information, including place names, topological relations, and human movement (Pustejovsky et al., 2012; Pustejovsky and Yocum, 2013; Pustejovsky et al., 2015). These studies basically focused on verbs as expressions of movement. Similarly, previous event analysis studies from temporal or factuality perspectives treated verbs or predicates as a trigger of each event and specified attribute information on verbs, as represented by TIMEML (Pustejovsky et al., 2003) and FACTBANK (Saur\u00ed and Pustejovsky, 2009). In user-generated contents including travelogues, geographic movements are often expressed without predicates, for example, scene transition by changing paragraphs or posts. Thus, we focus on geo-entities and their mentions, in contrast to the above predicate-centric analysis studies."}, {"title": "Location-Centric Analysis", "content": "Some previous studies focused on \"mention-level\" visit status of location mentions in SNS posts (Li and Sun, 2014; Matsuda et al., 2018) and clinical documents (Peterson et al., 2021), which can be regarded as location-centric analysis. Long documents like travelogues often contain multiple mentions referring to the same location (i.e., geo-entity), and such different mentions can have different visit status labels. This necessitates a step of aggregating various visit status labels of mentions into the final visit status of the entity, which indicates whether the traveler eventually visited the location or not. Therefore, we additionally address \u201centity-level\u201d prediction."}, {"title": "Visiting Order Prediction", "content": "Compared to many existing studies on the extraction of geo-entity mentions or toponyms (Lieberman et al., 2010; Matsuda et al., 2017; Kamalloo and Rafiei, 2018; Wallgr\u00fcn et al., 2018; Weissenbacher et al., 2019; Gritta et al., 2020; Higashiyama et al., 2023), a few studies extracted some types of geographic trajectories from text (Ishino et al., 2012; Wagner et al., 2023; Kori et al., 2006).\nIshino et al. (2012) proposed a task and a method to extract transportation information, i.e., the origin and destination with a transportation method, from each disaster-related tweet. Such information can be regarded as part of a movement trajectory. Wagner et al. (2023) proposed a task to extract an entire trajectory from each transcription of testimony videos. Each testimony segment, which typically corresponds to one minute of the original video, was assigned a predefined location category, such as \"cities in Austria\" and \"ghettos in Hungary.\" That is, their trajectory is a transition sequence of a coarse-grained location mainly mentioned in each scene, not a detailed movement trajectory of specific locations. Kori et al. (2006) proposed a method to extract and summarize sequences of location mentions as visitors' representative trajectories in blogs. They determined the visiting order of locations based on the order that mentions occurred in blogs. In contrast to Kori et al. (2006), we aim to identify the faithful visiting order, which aligns with the written intentions. The crucial difference between these three studies and ours is the trajectory representation; we adopt not sequences but graphs as appropriate representations that retain geographic hierarchy as well as the temporal order of locations."}, {"title": "Conclusion", "content": "This study has proposed a visiting order graph to represent non-linear relations of visited locations and constructed an annotated travelogue dataset for graph-structured trajectory extraction. The experiments using the dataset have indicated the accuracy of baseline systems with some directions for performance improvement. The error analysis of actual examples has revealed notable tendencies of the prediction errors. One future direction is to develop sophisticated systems by addressing the issues we have raised for improvement. Another direction is to develop an integrated system for both trajectory extraction and grounding, which extracts an trajectory from each input document and associates its locations with points/areas of a map."}]}