{"title": "A Chinese Multi-label Affective Computing Dataset Based\non Social Media Network Users", "authors": ["Jingyi Zhou", "Senlin Luo", "Haofan Chen"], "abstract": "Emotion and personality are central elements in understanding human psychological states.\nEmotions reflect an individual's subjective experiences, while personality reveals relatively\nstable behavioral and cognitive patterns. Existing affective computing datasets often annotate\nemotion and personality traits separately, lacking fine-grained labeling of micro-emotions and\nemotion intensity in both single-label and multi-label classifications. Chinese emotion\ndatasets are extremely scarce, and datasets capturing Chinese users' personality traits are even\nmore limited. To address these gaps, this study collected data from the major social media\nplatform Weibo, screening 11,338 valid users from over 50,000 individuals with diverse\nMBTI personality labels and acquiring 566,900 posts along with the users' MBTI personality\ntags. Using the EQN method, we compiled a multi-label Chinese affective computing dataset\nthat integrates the same users' personality traits with six emotions and micro-emotions, each\nannotated with intensity levels. Validation results across multiple NLP classification models\ndemonstrate the dataset's strong utility. This dataset is designed to advance machine\nrecognition of complex human emotions and provide data support for research in psychology,\neducation, marketing, finance, and politics.", "sections": [{"title": "Background & Summary", "content": "Text serves as a crucial medium for human emotional expression, and the primary task of\ntext-based affective computing is to extract, analyze, understand, and generate subjective\ninformation from textual content. Over the past three years, text-based affective computing\nhas seen rapid advancementsand applications across numerous fields, including\npsychology 1,2,3, education, public welfare, marketing, finance, politics\u00b9\u00ba, creative text\ngeneration\u00b9\u00b9, robustness of large models12, and bias analysis\u00b9\u00b3. Emotion detection has also\nbecome a focal point in chatbot research, as seen with the release of Microsoft's empathetic\nsocial chatbot in 2020\u00b9\u00b9and Li's empathy-enabled chatbot with emotion causality\u00b95.\nMost emotion research relies on Ekman and Plutchik's emotion models\u00b96, where binary\nclassification denotes the presence or absence of specific emotions, and ternary classification\noften uses categories such as positive, neutral, and negative. Although these models are\nstraightforward and targeted, they struggle to capture the complexity of human emotions,\nfrequently failing to identify the nuanced and varied emotions embedded in text (termed\nmicro-emotions). A shift towards multi-category, fine-grained, and continuous annotation\nmodels has thus become an inevitable trend in text-based affective computing. The MuSe\n2022 Challenge\u00b9\" introduced humor and emotional stress as dimensions, extending emotion\nmodels with additional states for customized emotional representation. ChineseEmoBank18\nprovides fine-grained analysis of emotion intensity and is the first Chinese resource offering\nmulti-level granularity in affective dimensions. In 2020, Google's team launched\nGoEmotions\u00b9, a dataset containing 28 emotion categories with 58,009 manually annotated\ntext samples: single-label annotations account for 83%, double-label for 15%, triple-label for\n2%, and 4-5 labels for 0.2%. GoEmotions pioneered a highly detailed multi-category,\nmulti-label micro-emotion dataset; however, it offers limited multi-label annotations and lacks\nintensity differentiation among tags or personality traits.\nEmotion datasets primarily depend on manual annotation, which is costly and prone to\nsubjective bias, particularly in the lack of micro-emotion labeling with intensity levels,\nlimiting machine comprehension of subtle human emotions. Our previous\nresearch2 introduced a micro-emotion annotation framework with continuous intensity scores,\nand this paper applies that framework to annotate micro-emotion data, establishing the\nChinese Multi-label Affective Computing Dataset (CMACD) based on social media network\nusers.\nEmotion detection primarily focuses on the emotions conveyed in text, often overlooking the\nstable internal factors of the text creator, namely personality. Personality, an essential concept\nin psychology, encompasses enduring response patterns toward others, events, and oneself,\nshaping an individual's unique adaptive abilities in social contexts. It reflects aspects of\nintegrity, stability, uniqueness, and sociality within one's psychological makeup\u00b2\u00b9. Numerous\npsychological studies emphasize personality as a critical psychological indicator and extend\nits application from personality research to affective computing. For instance, Kashaniet al.22\nassessed the impact of personality on emotional states in video game communication, Kamran\net al.23 applied personality traits to explain emotions in short texts, and Kitkowska24\ninvestigated how emotions and personal traits influence interactions with privacy policies.\nPersonality-based affective computing has also garnered attention within large model\nresearch25. Since April 2022, the search index for the Myers-Briggs Type Indicator\u00ae (MBTI)\non Baidu has surged, and in 2023, it topped the most popular terms on Weibo, reflecting\nsustained public interest in MBTI-related topics. Widely regarded as one of the most popular\nand reliable personality prediction methods\u00b2, MBTI has inspired significant attention.\nHowever, a publicly available dataset that integrates personality traits and emotions remains\nabsent, and our CMACD dataset fills this gap. This dataset annotates each user's Weibo post\nwith both personality traits (MBTI) and emotions, along with emotion intensity values.\nCMACD is a Chinese dataset focusing on personality and emotion. A user with a unique\npersonality will express rich macro and micro emotions in their posts."}, {"title": "Methods", "content": "The CMACD dataset encompasses four key dimensions: users, user Weibo texts, MBTI\npersonality types, and six emotions with intensity scores, forming a large-scale Chinese\ndataset. The components of users, user Weibo texts, and MBTI personality types are drawn\nfrom publicly available personality information on Weibo, where users either discuss MBTI\nor self-identify with certain personality traits. This dataset has been carefully compiled in\nstrict compliance with user privacy protections. The six emotion labels with intensity levels\nare derived from an existing publicly annotated single-label Weibo emotion dataset\u00b9\u00b9 and are\nlabeled using the Extended Quantification Network (EQN) framework based on a BERT\nmodel.The workflow of our study is illustrated in Fig. 2.\nTraditional manually labeled datasets require significant human resources, and annotating\nMBTI personality traits necessitates substantial involvement from psychology professionals.\nTo ensure reliability in MBTI personality trait data, we selected users who had verified their\nMBTI traits through self-confirmation. To maintain dataset validity, we also established\nminimum posting requirements for users included in the dataset.\n(1) Large-Scale Search (Initial Screening). Through extensive manual searches, we identified\nWeibo users who publicly self-identify with an MBTI type. Using fuzzy search methods, we\ncollected data from 51,000 users by searching phrases like \u201cI am an INTJ\" for each of the 16\npersonality types, amassing over 5 million posts.\n(2) Manual Review (Detailed Screening). To accurately identify users with a specific\npersonality type, we conducted a manual review. For instance, when reviewing users with an\nISTJ personality, we included affirmative phrases like \u201cI am an ISTJ,\u201d \u201cISTJ certified,\u201d \u201cISTJ\ntype,\" \"as an ISTJ,\u201d \u201cwe ISTJs,\u201d\u201ctrue ISTJ,\u201d and \u201c100% ISTJ.\" Users employing such\nexpressions in their posts were selected for further personality verification to ensure the\naccuracy of MBTI labels.\n(3) Expanding Manual Filter Range (Further Detailed Screening). To capture more users with\nspecific personality traits, we compiled a list of popular colloquial expressions associated\nwith each MBTI personality type. Most of these terms are\nanthropomorphic labels provided by official MBTI testing sites and served as critical\nreference points in our manual screening process.\nExclusion of Bot Users. Weibo contains a significant number of bot-generated posts, which\nlack relevance to affective computing analysis. These bot users were removed from the\naggregated user list.\n(5) Manual Collection of Post Data by User ID.We created 16 personality folders named\naccording to each MBTI type. Posts collected from each user were stored in CSV files named\nby their user ID, with each row representing a Weibo post. These CSV files were placed in the\ncorresponding personality folder based on the user's self-identified MBTI type.", "subsections": [{"title": "2. Data Preprocessing", "content": "User activity levels on Weibo vary significantly, with some users posting thousands of tweets\nwithin a given timeframe, while others post only a few. Individual posts may range from\nthousands of characters to just a single word or emoji. Given that tweets often contain\nsubstantial emotional content, we implemented the following preprocessing steps to ensure\ndataset quality:\n(1) Removed all URLs from the dataset, as they offer no clear information about emotional\npolarity.\n(2) Deleted posts containing promotional or advertisement content.\n(3) Replaced any personal names in posts with the placeholder \u201c[name]\" and removed various\nnumeric identifiers to protect user privacy.\n(4) Deleted posts shorter than 30 characters or longer than 150 characters.\n(5) Excluded users with fewer than 50 posts following the above preprocessing steps.\nUltimately, we selected 11,338 users, randomly sampling 50 posts from each. Each post\nranged from 30 to 150 characters in length, resulting in a total of 566,900 posts, each\ncategorized under one of the 16 MBTI personality types."}, {"title": "3. Labeling Emotions with Intensity Scores Using the EQN Framework", "content": "We applied emotion labeling to the organized MBTI dataset. Currently, multi-label\nclassification datasets predominantly rely on manual annotations\u2014a time-consuming and\ncostly process. Furthermore, manual annotation is prone to subjectivity, which can lead to\nerrors or omissions in the labels. Human emotional expression varies in intensity, yet existing\nemotion labeling methods only categorize emotions without quantifying their strength,\nresulting in a lack of detail. However, machine learning techniques can capture more subtle\nfeatures, enhancing the model's ability to classify emotions and deepen the understanding of\nhuman emotions.\nTo address these issues, we implemented machine-driven multi-label emotion annotation with\nintensity scoring at the sentence or paragraph level. The implementation process is illustrated\nin Fig. 3."}]}, {"title": "4. MBTI Data Analysis", "content": "As shown in Fig.5, the distribution of users across the 16 MBTI personality types in the\nCMACD dataset is depicted. The number of users for each personality type is indicated above\nthe corresponding bars in the histogram. It can be observed that the number of users varies\nsignificantly across different personality types. Users of the INFP, ENFP, and INFJ types each\nexceed 1,000, while users of the ESTP, ESTJ, ESFJ, and ENTJ types number fewer than 300.\nAmong these, the number of INFP users is 12.46 times greater than that of ESTP users."}, {"title": "5. Quantitative Emotional Data Analysis", "content": "Using the previously developed EQN framework20, we fine-tuned a BERT pre-trained model\non a manually annotated dataset consisting of six emotion categories to train the annotation\nmodel42. This trained model provides multi-label emotional annotations and intensity scores\nfor each post in the dataset. (The trained annotation model and labeling code can be accessed\nat: https://github.com/yeaso/Expansion-Quantization-Network-EQN). The final dataset\nincludes 566,950 posts from 11,338 Weibo users, covering six emotions (anger, fear,\nhappiness, neutrality, sadness, and surprise) with quantitative multi-label annotations. Fig. 8\nillustrates an example of this quantified emotional data.Fig. 8.Quantitative annotation of sentiment labels. The emotional annotations in the dataset\nare assigned intensity levels ranging from 0 to 1 (where 0 indicates absence and 1 denotes\nmaximum intensity). Each post may contain multiple emotions. Our EQN annotation tool\nutilizes a full-label quantization method to effectively capture the correlations and\ndependencies between different labels. This allows us to annotate intensity scores that reflect\nboth macro and micro emotional aspects in the text. By setting a threshold, we define valid\nlabels scores above this threshold are considered valid annotations. In our experiment, this\nthreshold is set at 0.05; any emotional intensity below 0.05 is uniformly set to 0. Labels with\nan intensity of 0 indicate that the post does not exhibit that particular emotion."}, {"title": "6. MBTI and Emotion Data Analysis", "content": "For a more detailed analysis of the quantified emotional data, we provide a comparative\nanalysis with the MBTI data, identifying similarities and differences to better understand and\nanalyze the relationship between MBTI and emotional annotations. Please refer to the section\n\"MBTI and Emotion Data Analysis\" below.\nFor clarity, the following variables and formulas are defined:\nF(i): The intensity score of each post for each emotion category, with values ranging from (0,\n1).i= [angry, fear, happy, neutral, sad, surprise].\n$F(i) = \\begin{cases}\nF(i) & \\text{if } F(i) \\geq t \\\\\n0 & \\text{if } F(i) < t\n\\end{cases}$\nHere t is the threshold defined for the annotation label.\nPnum: Number of posts per personality type.\nPnum = \u03a3F(i)\nEnum(i): The number of energy level scores of each type of emotion for each type of\npersonality>= t. (This data set sets t=0.05).\nSume (i): Total energy. The sum of the energy level scores of each emotion type for each\npersonality type.\nSume(i) = \u03a3F\u1d62\nLAE(i): Local average energy. The average amount of energy a certain type of emotion\npossesses within each personality type.\nLAE(i) = Sume(i)/Enum(i)\nGAE(i): Global average energy.The average amount of emotion contained in posts by each\npersonality type.\nGAE(i) = Sume(i)/Pnum\nANL(i): The average number of labels. The probability of occurrence of each type of emotion\nfor each type of personality.\nANL(i) = Enum(i)/Pnum\nQEL(i):The quantity exceeding the local average energy.The number of posts for each\npersonality type with emotion levels exceeding LAE(i) for each emotion category.\nQEL(i) = Enum(i)/Pnum/Sume(i)/Enum(i)\nQEG(i):The quantity exceeding the global average energy.The number of posts for each\npersonality type with each emotion category exceedingGAE(i) levels.\nQEG(i) = Enum(i) - Sume(i)/Pnum\nLHEP(i):Local high expression probability.The local high-expression probability for each\nemotion within each personality type.\nLHEP(i) = QEL(i)/Pnum\nGHEP(i):Global high expression probability.The local high-expression probability for each\nemotion across posts within each personality type.\nGHEP(i) = QEG(i)/Pnum\nThe formulas (1)\u2013(5) compute the total and average emotional intensity for each emotion\nacross the 16 personality types, reflecting the strength of each type's emotional expression.\nFormulas (6)-(10) calculate the probability of users across the 16 personality types expressing\nthe six emotions. Using these definitions, we performed corresponding statistical analyses on\nour emotion dataset, with the results presented in Supplementary Table 1.\nTo facilitate observation and analysis, we have created several charts based on the data in\nSupplementary Table 1 to visually represent the various data categories.\nA key feature of our multi-label emotional dataset is that each annotated label is associated\nwith a specific intensity value. With these quantified data, we are able to analyze the\ndistribution of emotional intensity across different personality types, providing valuable\ninsights into the correlation between personality and emotion."}, {"title": "Data Records", "content": "The CMACD dataset comprises data from 11,338 Weibo users, with each user contributing 50\nposts. Each post is limited to 30\u2013150 characters, totaling 566,900 posts. The dataset includes\nusers' MBTI personality types along with a comprehensive affective computing dataset\ncontaining six emotion intensity values. The data records consist of the source of the dataset,\nthe dataset used for training the annotation model, and the format for data storage."}, {"title": "1. Source of Collected Dataset", "content": "The user Weibo corpus and MBTI personality characteristics used for this dataset were\ncollected from the Weibo platform, accessible at https://weibo.com/."}, {"title": "2. Training Dataset for Emotion Annotation", "content": "The emotion intensity annotations for this dataset were performed using the EQN emotion\nannotation framework. The training dataset used for the framework is the \"SMP2020 Weibo\nEmotion Classification Technical Evaluation General Weibo Dataset.\" This dataset contains\n27,768 Weibo posts, each annotated manually with one of six emotional categories, making it\na single-label dataset. The dataset can be downloaded at https://smp2020ewect.github.io."}, {"title": "3. Storage Structure of the CMACD Dataset", "content": "The CMACD dataset is organized in a hierarchical structure, with folders named according to\nthe 16 MBTI personality types. Each folder contains CSV files\ncorresponding to individual users classified under that personality type. In each user's CSV\nfile, 50 rows represent the user's posts, with columns containing the post content and scores\nfor the six emotional categories: anger, fear, happiness, neutrality, sadness, and surprise. This\nstructure enables efficient access to each user's personality and emotion data.\nFor example, in the ENFJ folder, CSV files for all CMACD users with the ENFJ personality\ntype are stored. The \"posts\" column records the content of each user's posts, with 50 rows\nrepresenting 50 Weibo posts per user. Other columns provide multi-label emotion annotations,\nwith each post assigned corresponding emotion scores."}, {"title": "Technical Validation", "content": "To validate the usability and effectiveness of the CMACD dataset, we conducted personality\nclassification and emotion classification tests using various classic algorithms and deep learning\nmodels. For the sake of experimental reproducibility, the algorithms or models employed\nstandard or basic parameter settings without any special optimization. Additionally, we\nperformed Pearson correlation analysis using the vector values corresponding to the four\ndimensions of the 16 personality labels to examine the interrelationships between the four\naspects (axes) of the MBTI personality types, thus assessing the rationality of the dataset\ndistribution. Furthermore, based on the annotated emotion intensity scores in the dataset, we\nperformed Pearson correlation analysis to explore the relationships between the six emotions,\nobserving whether the correlations between the emotions align with human cognitive\nunderstanding of emotional relationships."}, {"title": "1. Validation of MBTI Personality Types", "content": "The validation of MBTI personality types encompasses five key components: data preparation,\nselected algorithms and models, experimental protocols, experimental results, and testing the\ncorrelations across the four MBTI axes."}, {"title": "Data Preparation", "content": "To objectively validate the dataset, the following steps were undertaken:\n(1) Removal of Personality Keywords: To prevent the interference of MBTI personality keywords\nduring training, we excluded these terms from the dataset, including all uppercase and lowercase\nvariations. The 16 personality type keywords are as follows: ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ',\n'ENFJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ'].\n(2) Sentence Integrity: Unlike traditional machine semantic understanding, this project involves\nevaluating human language behavior that reflects individual personality traits. Therefore, we\nmaintained the integrity of each sentence used for training. Stopwords were not utilized in the\ndata processing.\n(3)Segmentation Tools: In this experiment, we employed the Chinese word segmentation tool\n\"jieba\" to process Chinese words and phrases into logical segments that align with the structure\nof the Chinese language. Unlike English, where word segmentation is typically achieved by spaces\nbetween words, Chinese segmentation is more complex. For example, \"apple\" in Chinese is \"\u82f9\u679c\n(p\u00edng gu\u01d2), and it is more intuitive to segment it as \"\u82f9\u679c\" rather than breaking it into the\ncharacters \"\u82f9\" and \"\u679c.\"\n(4) Generation of word embeddings or use of Tfidf to create the TFIDF matrix.\nTerm Frequency-Inverse Document Frequency (TF-IDF) is a classical and widely used\nmethod in natural language processing (NLP). The fundamental concept is as follows: if a\nword appears frequently in a document but infrequently across other documents, then the\nword is considered highly important for that specific document. TFIDF transforms textual\ncorpora into feature vectors represented by words. This process involves vectorizing the\ndatabase posts into a matrix of token counts for the model. In this experiment, we set the\nparameters 'max_df=0.97` (removing words that appear in more than 97% of the samples)\nand `min_df=0.03` (removing words that appear in less than 3% of the samples). The\nmaximum number of features was set to 'max_features=5000`."}, {"title": "Selected Algorithm Models", "content": "To validate the usability and adaptability of the dataset, this project employs a range of\nalgorithms based on the dataset. The following models are chosen for the classification and\nprediction of 16 personality types: Logistic Regression (Logit), AdaBoost, Gaussian Naive\nBayes (GNB), Random Forest, Decision Tree, Support Vector Machine (SVM), K-Nearest\nNeighbors (KNN), eXtreme Gradient Boosting (XGBoost), Naive Bayes, Multilayer\nPerceptron (MLP), Recurrent Neural Network (RNN), and Bidirectional Encoder\nRepresentations from Transformers (BERT42)."}, {"title": "Experimental Design", "content": "Based on the aforementioned models, the experimental design\nconsiders the different input methods for MBTI display, large models like BERT, and other\nmodels. The specific approach is as follows:\n(1) In accordance with the MBTI classification rules, the experiment transforms the 16-class\nclassification problem into four binary classification tasks, mapped as follows: {'I': 0, 'E': 1,\n'N': 0, 'S': 1, 'F': 0, 'T': 1, 'J': 0, 'P': 1}.\n(2) The BERT model utilizes word embeddings as input, while other models or methods use\nthe TF-IDF matrix as input."}, {"title": "Experimental Results", "content": "Based on the algorithms, models, and experimental design outlined\nabove, the personality type dataset is divided into training and test sets in a 7:3 ratio for\ntraining and validation. The final experimental results (Accuracy) are shown in Table 3.\nThe results indicate that classical algorithms, neural networks, and large language models\nexhibit varying classification capabilities on our dataset, thereby validating the effectiveness\nand adaptability of the dataset for personality classification. Notably, BERT demonstrated\nexceptional classification performance, highlighting the unique advantages of large language\nmodels. The results of the MBTI text classification model based on BERT can serve as a\nbenchmark for the classification performance of this dataset."}, {"title": "MBTI Axis Correlation Test", "content": "According to MBTI theory, the 16 personality labels are\ncomposed of four different letters, each representing one axis of the four-dimensional\nframework. Each of these axes has two polarities, which can be represented in binary form\n(for example, the I/E axis, where I is 1 and E is 0). Consequently, each label can be expressed\nas a 4-dimensional vector based on the polarities of the axes. For instance, the personality\ntype \"INFJ\" can be represented as the vector [1,1,0,1]. Using the vector values corresponding\nto the four axes of the MBTI labels in the dataset, we calculated the Pearson correlation\ncoefficient to analyze the relationships between the four axes."}, {"title": "Validation of Six Emotion Labels", "content": "To validate the quality of the six emotion annotations in the CMACD dataset, we employed\nthree methods to assess usability, accuracy, and the reasonableness of the overall label\ndistribution:"}, {"title": "(1) Multi-label Classification Experiment to Assess Dataset Usability", "content": "We trained and evaluated our emotion dataset using Support Vector Machine (SVM), FastText,\nTextCNN, TextRNN, and BERT models. To validate the usability and effectiveness of the\ndataset, the experiment was conducted using the standard or baseline parameter settings for\neach algorithm or model, without any special optimization. Two evaluation metrics were\nused:\nEl_Acc: Accuracy of the label with the highest energy score.\nEx_Acc: Accuracy of labels with non-maximum energy scores."}, {"title": "(2) Manual Spot Check to Assess the Accuracy of Emotion Annotations", "content": "To comprehensively evaluate the quality of the AI-based machine learning automatic\nannotations in the emotion dataset, a traditional manual spot check was conducted to assess\nthe quality of non-human-supervised annotations.\nManual Annotation Rules: Voting Method. A team of three annotators (each annotating posts\nwith a single label) determined the final label based on a voting principle.\nMethod: A random sample of 1,000 posts was selected from the dataset, and all labels\npreviously assigned by the annotation tool were removed. These 1,000 samples were then\nmanually annotated with single labels.\nResult Comparison: The manually annotated 1,000 samples (single-label) were compared\nwith the original multi-label results assigned by the annotation tool, which included energy\nscores. The hit rate for the top energy label (the label with the highest emotion energy score in\na sentence) was 83.1%, while the hit rate for the top two energy labels (the highest and the\nsecond-highest emotion energy labels in a sentence) was 92.3%. This result validates that our\nemotion dataset has a high level of accuracy, and it also demonstrates that the full-label\nmethod in EQN is beneficial for capturing micro-emotions."}, {"title": "(3) Evaluation of the Reasonableness of the Overall Distribution of Six Emotion Labels", "content": "To observe the correlations between the six annotated emotions, we used the Pearson\ncorrelation coefficient to calculate and analyze the relationships between the emotions based\non the quantified emotion data. This approach allows us to assess whether the overall\ndistribution of the labels is reasonable and provides an indication of the overall annotation\naccuracy within the dataset."}, {"title": "Usage Notes", "content": "Although this dataset has undergone privacy protection measures, it involves research on\nhuman personality and emotions. To ensure user safety, CMACD is made available free of\ncharge only to researchers with a legitimate need. Researchers wishing to use CMACD can\napply by emailing: annezjy94@163.com.\nTo demonstrate the features and application value of this dataset, and to facilitate basic testing\nand feedback, we have made a small sample of CMACD publicly available. The small sample\ndataset is now accessible at: https://github.com/yeaso/Chinese-Affective-Computing-Dataset"}, {"title": "Code Availability", "content": "To demonstrate the features and application value of this dataset, and to facilitate basic testing\nand feedback, we have made a small sample of CMACD publicly available. The small sample\ndataset is now accessible at: https://github.com/yeaso/Chinese-Affective-Computing-Dataset"}]}