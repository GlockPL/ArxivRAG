{"title": "ActPC-Chem:\nDiscrete Active Predictive Coding\nfor Goal-Guided Algorithmic Chemistry\nas a Potential Cognitive Kernel\nfor Hyperon & PRIMUS-Based AGI", "authors": ["Ben Goertzel"], "abstract": "This exploratory, speculative \"concept paper\" explores a novel paradigm\n(labeled ActPC-Chem) for biologically inspired, goal-guided artificial in-\ntelligence (AI) centered on a form of Discrete Active Predictive Coding\n(ActPC) operating within an algorithmic chemistry of rewrite rules.\nThe central thesis of the ActPC-Chem approach is that general-intelligence-\ncapable cognitive structures and dynamics can emerge in a system where\nboth data and models are represented as evolving patterns of metagraph\nrewrite rules, and where prediction errors, intrinsic and extrinsic rewards,\nand semantic constraints guide the continual reorganization and refine-\nment of these rules.\nIn contrast to backpropagation-based approaches to training large AI\nnetworks, ActPC-Chem makes it relatively straightforward to integrate\nsubsymbolic pattern recognition and behavior learning with symbolic and\ncausal reasoning in a unified framework.\nWe begin with a review of active predictive coding concepts and show\nhow they can be adapted to a discrete, rewrite-rule-based \"algorithmic\nchemistry\" that supports goal-driven reinforcement. To accelerate the\nevolution of discrete ActPC, we introduce the notion of discrete natural\ngradients grounded in optimal transport geometry.\nUsing a virtual \"robot bug\" thought experiment, we illustrate how\nsuch a system might self-organize to handle challenging tasks involving\ndelayed and context-dependent rewards, integrating causal rule inference\n(AIRIS) and probabilistic logical abstraction (PLN) to discover and ex-\nploit conceptual patterns and causal constraints.\nNext, we describe how continuous predictive coding neural networks,\nwhich excel at handling noisy sensory data and motor control signals, can", "sections": [{"title": "1 Introduction", "content": "These are unique times in the history of AI; AGI is finally taken seriously as a\nscientific and engineering pursuit, and significant resources are now being put\ninto the quest to create AGI and even superintelligence, but there is still nothing\nnear a consensus of which approaches are likely to get us there.\nLarge neural networks - trained with massive datasets via backpropagation\nhave achieved impressive successes across domains such as language modeling,\ncomputer vision, and game-playing. Yet from an GI perspective, these models\nremain limited (see [Goe23] for a detailed exposition on these limitations). They\nstruggle to exhibit robust causal reasoning, often produce logically inconsistent\n\"hallucinations\" and rely on a batch-mode, non-localized training methodology\nthat in many ways contradicts basic principles of adaptive cognition. More-\nover, working around these shortcomings via hybridizing these neural nets with\nother AI tools is highly challenging - the current paradigm makes it infeasible\nto seamlessly integrate symbolic knowledge, abstract reasoning or evolutionary\ncreativity with the neural learning process. These various issues are not in-\ntrinsic to the neural net paradigm generally speaking but have to do with the\nspecific (not very biologically realistic, as it happens) neural net architectures\nand training approaches currently in use.\nOn the other hand, purely symbolic or logic-based AI approaches have of-\nfered interpretability and direct representations of causality, but historically\nhave failed to scale up and adapt swiftly to the noisy complexity of real-world\ntasks. Symbolic evolutionary methods have demonstrated impressive creativity,\nbut also have not been scaled to the level needed for widespread practical utility.\nThe longstanding dichotomy between subsymbolic pattern-learning and sym-\nbolic abstraction is still with us today our large subsymbolic networks, while\nin some ways surprisingly good at reasoning, remain unable to extrapolate very\nfar beyond their training data; and our symbolic reasoning systems, while in\nsome cases very powerful, have not yet demonstrated the large-scale pattern\nrecognition and synthesis abilities of the best large neural networks.\nA key challenge, then, is to discover an architectural principle that natu-\nrally blends the various aspects of human-like general intelligence: subsymbolic\nadaptability, symbolic and causal reasoning, evolutionary creativity and robust\nexperiential learning.\nThe PRIMUS cognitive architecture [GBD+23], which partially motivated\nthe OpenCog Hyperon AGI infrastructure, provides a complex and coherent\nproposal regarding how to overcome these challenges and create a human-level\nAGI capable of self-modifying itself into an ASI. However, PRIMUS is a quite\nlarge and complicated design, with many aspects only partially specified, and\nin setting about specifying and implementing PRIMUS in practice there is no\nsingle clear best way to start.\nHere we propose a specific approach to experiential learning for AGI systems\ncalled ActPC-Chem, which makes sense on its own, but also constitutes a subset\nof the PRIMUS architecture. In a PRIMUS context, we suggest, ActPC-Chem\nmay be considered as one of multiple possible \"cognitive kernels\" - autonomous"}, {"title": "1.0.1 Plan of the Paper", "content": "We start by reviewing the concepts of active predictive coding and showing how\nthey can be adapted to discrete, rewrite-rule-based algorithmic chemistries that\nsupport goal-driven behavior and reinforcement signals. Next, to accelerate\nthe evolution of discrete ActPC, we discuss the use of discrete natural gra-\ndients derived from optimal transport geometry, providing a more stable and\ngeometry-aware update mechanism. Through a \"virtual robot bug\" thought\nexperiment, we demonstrate how the system might handle complex tasks in-\nvolving delayed and context-dependent rewards. Integrating causal rule infer-\nence (AIRIS) and probabilistic logical abstractions (PLN) enables the discovery\nof subtle conceptual patterns and causal constraints that guide the system's\nautopoietic creativity toward effective, adaptive solutions.\nWe then describe how continuous predictive coding neural networks can be\nmerged with this discrete substrate, creating a hierarchical architecture where\ncontinuous sensorimotor loops provide stable perceptions and actions at the\nbottom, and discrete symbolic reasoning handles abstraction and causality at\nthe top. This synergy allows prediction errors to propagate smoothly across\nlevels, yielding a coherent multimodal pipeline that can continuously refine both\nperceptual accuracy and strategic intelligence.\nFinally, we outline how these ideas could be extended to form a transformer-\nlike model that forgoes formal neurons and backprop in favor of weighted rewrite\nrules and ActPC-driven rule transformations. The resulting layered architecture\n-supplemented by AIRIS's causal logic, PLN's abstractions, and continuous\nPC's robust multimodal integration \u2013 appears well suited to produce structured,\ncontextually rich next-token predictions.\nSumming up in a general way: Beyond the various technical novelties, the\nbroader vision here is that by grounding AGI-capable cognitive processes in an\nautopoietic, algorithmic-chemistry-like substrate guided by predictive coding,\nwe achieve a system with intrinsic flexibility, adaptability, and inventive power\nat its core. This \"cognitive kernel\" may then serve as the base upon which\nfurther PRIMUS methods and other AI techniques can be layered, ultimately\npaving a plausible pathway toward human-level AGI and beyond."}, {"title": "1.1 Act PC-Chem as one more PRIMUS Probabilization", "content": "A more PRIMUS-related way to summarize these ideas and how they fit into the\nPRIMUS architecture might be: ActPC-Chem is the next in a series of \"prob-\nabilizations\" of AI methods that has been carried out in an effort to leverage\nprobabilistic semantics to more effectively connect diverse techniques with vary-\ning mathematical and conceptual underpinnings into a coherent and synergetic\nframework.\nPredecessors in this vein have been\n\u2022 PLN (Probabilistic Logic Networks), which makes highly general and ab-\nstract forms of logic probabilistic, in a way that helps connect them to\nobservational data\n\u2022 MOSES (Meta-Optimizing Semantic Evolutionary Search), which brings\n(probabilistic) Estimation of Distribution Algorithms (EDAs) to evolu-\ntionary program learning in a general and AGI-friendly way\n\u2022 ECAN (Economic Attention Allocation), which can be viewed as a vari-\nation of attractor neural networks in which (the analogue of) activations\nsum to 1, thus making them straightforwardly model-able as probabilities\nOrorbia's Predictive Coding approach has many interesting specificities to\nit, but at a high level, it also has the general aspect of making the learning\noperations within a neural network clearly probabilistically interpretable, much\nmore than is the case with backpropagation (prediction errors are measured via\nentropies which are transformed probabilities).\nAlgorithmic chemistry and related approaches have been discussed in a\nPRIMUS and OpenCog context for decades now, however ActPC-Chem is the\nfirst time they have been connected in a clear way with a probabilistic semantics.\nIt has been proposed previously to use PLN and MOSES to reason probabilis-\ntically about which patterns in algorithmic-chemistry networks seemed to be\nmore effective (part of the \"Cogistry\" proposal [Goe16]), but this is different\nthan using probabilistic methods as the core base-level method of \"training\" an\nalgorithmic chemistry network, which is what occurs in ActPC-Chem.\nThere are some echoes here of prior work combining the (algorithmic chem-\nistry like) AERA architecture with Pei Wang's NARS uncertain reasoning en-\ngine [R\u00f6r22]. However, the lack of probabilistic semantics in NARS (among\nother factors) meant that the math of algorithmic-chemistry-network learning\nand the math of probabilistic reasoning could not be as tightly connected within\nthat system, as what we believe can be achieved using a common probabilistic\nsemantics in an ActPC-Chem context."}, {"title": "1.1.1 Probabilistic Graph Structured Lambda Theory as Potential\nInitial Cognitive-Synergetic Glue", "content": "Having multiple components of a tightly-coupled hybrid cognitive architecture\n(like PRIMUS) all use probabilistic semantics is a good start toward having"}, {"title": "2 ActPC-Chem: Discrete Active Predictive Cod-\ning for Goal-Guided Algorithmic Chemistry", "content": "Let us review what ActPC is, and how it may be adapted to a discrete setting,\nand in particular a \"metagraph rewrite rule soup\" style algorithmic-chemistry\nsetting."}, {"title": "2.1 Brief Review of Active Predictive Coding", "content": "Active Predictive Coding (ActPC) [OK22] is a novel reinforcement learning (RL)\nparadigm grounded in predictive coding principles and implemented through\nNeural Generative Coding (NGC) circuits. Predictive coding, a biologically"}, {"title": "2.1.1 Neural Generative Coding (NGC) Framework:", "content": "Ororbia's NGC framework is a specific instantiation of the ActPC idea, with\nthe following key aspects:\n\u2022 Core Idea: NGC layers predict the activity of subsequent layers. The\ndifference between actual and predicted activity generates an error signal,\nwhich drives synaptic updates.\n\u2022 State Updates: Neuron states are iteratively updated based on error sig-\nnals and local connectivity. A layer's activity, $z^l$, is refined through a\ndynamic inference process where the error neurons $e^l = z^l - \\hat{z}^l$ guide\nadjustments.\n\u2022 Predictions: Predictions are generated from forward synaptic connec-\ntions and memory terms $m_t$, reflecting temporal context.\n\u2022 Hebbian-Like Updates: Synaptic weights W and error synapses E are\nadjusted locally using Hebbian-like rules that strengthen connections con-\ntributing to accurate predictions."}, {"title": "2.2 Toward Discrete ActPC: General Considerations", "content": "While the standard math of ActPC is continuous-variable, there is nothing in\nthe conceptual underpinnings of the method that especially favors continuous\nover discrete implementation. For applications more toward the cognitive than\nperception or actuation side, discrete versions of ActPC might have advantages,\nin terms of naturalness of handling symbolic and abstract knowledge. Discrete\nand continuous versions of ActPC would then have natural pathways for close\ncoordination due to their common foundation.\nTo make a discrete analogue of ActPC, one might adapt the underlying prin-\nciples of predictive coding and error-driven, local learning rules to a symbolic\ndomain where programs, rather than neural activations, serve as the generative\nmodels. This discrete framework would learn to produce or refine programs so\nthat their outputs match observed data or achieve desired goals. Instead of using\ncontinuous error neurons and Hebbian weight adjustments, this version would\nrely on the manipulation of discrete structures program instructions, rewrit-\ning rules, combinational logic - and measure error using information-theoretic\nquantities."}, {"title": "2.2.1 Moving Toward a Discrete Variation", "content": "One direction for cashing out this idea might be:\n\u2022 Programs as Generative Models: In the neural version of ActPC, each layer\npredicts the activity of downstream layers. In a discrete setting, imagine\na program (e.g. a functional program, a logic program, or a sequence of\ninstructions) attempting to generate or predict the observed data from\nan environment. Here, the program's output is compared to the actual\nobserved output (or target state) at each step. The program thus serves\nas a generative model, trying to \"explain\" the incoming data.\n\u2022 Measuring Error via Information Theory:. Instead of using the difference\nbetween predicted and actual neuron activations, we can measure the \"er-\nror\" as the discrepancy in information content. There are two clearly\npromising approaches here:\nShannon Information: Use measures like cross-entropy or Kullback-\nLeibler (KL) divergence between the predicted probability distribu-\ntion over possible outcomes and the actual observed outcome distri-\nbution. The closer the predicted distribution is to the actual one, the\nless \"surprise\" or \"error.\"\nAlgorithmic Information/Complexity: More ambitiously, one could\napproximate the algorithmic complexity (Kolmogorov complexity)\ndifference between the program's predicted output and the observed\noutput. For instance, if the observed data can be succinctly generated\nby the program's current form, the complexity is low, implying low\nerror. If the observed data is more complex relative to the program's\npredictions, the discrepancy is high, and so is the \"error.\""}, {"title": "2.2.2 Epistemic vs. Instrumental Signals in a Discrete Domain", "content": "In ActPC, learning is driven by two complementary signals: an epistemic (ex-\nploration) signal that rewards high prediction error (surprise), encouraging the\nmodel to seek new informative states, and an instrumental (goal-oriented) sig-\nnal that rewards states where the prediction error related to a desired goal is\nminimized.\nSimilarly, in a program-learning context, the epistemic signal can encourage\nthe system to explore programs that increase its ability to compress or predict\npreviously unpredictable data. High epistemic reward might come from discov-\nering shorter or more elegant programs that generate a good internal model\nof the environment. In an information-theoretic sense, this can be related to\nseeking out complexity that can later be compressed: the system is incentivized\nto explore patterns it cannot currently explain well, thereby gathering more\ninformation.\nThe instrumental reward can be tied to how closely the program's final\noutput matches a desired criterion (e.g., solving a puzzle, reaching a target\nstate, or producing a successful control sequence). Reducing this goal-related\ncomplexity difference (or prediction error) provides a strong incentive to refine\nthe program's logic so that it consistently produces the correct outcome.\nThe combined objective would blend these signals. The system tries to bal-\nance improving predictive coverage of the environment (epistemic) with achiev-\ning task success (instrumental)."}, {"title": "2.2.3 Incremental Learning for Discrete ActPC", "content": "Just as the neural ActPC avoids gradient based updates, this discrete analogue\nwould also be gradient-free. Instead of gradients, it uses local transformations\nguided by whether they reduce the chosen measure of error. This could be\nimplemented as a form of hill-climbing or stochastic search over a space of\nprograms, e.g.:\n\u2022 From a given program, propose local rewrites (akin to random mutations).\n\u2022 Evaluate the new program's predictive error (using Shannon or approxi-\nmate algorithmic measures).\n\u2022 Accept rewrites that reduce error and reject those that increase it, thus\nperforming a form of local, error-driven adaptation.\nHowever there are many ways to organize this kinds of search, which may have\nmajor influences on the efficiency and capability of the resultant framework."}, {"title": "2.2.4 Choices!", "content": "Summarizing based on the above conceptual considerations, there are many\nchoices to be made in crafting a discrete analogue of classical ActPC, e.g.\n\u2022 Choice of Information Measure:\nShannon-based measures (like KL divergence) are more tractable and\ncan be computed if you can model the environment's probability\ndistributions.\nApproximating algorithmic complexity requires compression-based\nmetrics or other heuristics, which may be computationally expensive\nbut could yield more fundamental insights.\n\u2022 Program Representation: Representing programs in a way that supports\nlocal, meaning-preserving transformations is crucial. Functional or logic\nprogramming languages, or graph-based intermediate representations, might\nlend themselves well to well-defined local rewrites.\n\u2022 Search and Optimization Methods:. Techniques like genetic programming,\nMarkov chain Monte Carlo (MCMC), or other search heuristics could be\nemployed to navigate the space of programs. The difference is that your\n\"fitness\" function (akin to negative error) now explicitly encodes predictive\npower and compressive capacity, rather than just a task-specific numerical\nreward."}, {"title": "2.3 Act PC-Chem: Discrete ActPC for Goal-Guided Al-\ngorithmic Chemistry", "content": "Now we will get more specific", "algorithmic chemistry\" of metagraph rewrit-\ning rules, where the entire AI system-its data, its models, and the rules used\nfor rewriting-are all encoded as subgraphs within a larger metagraph. This sort\nof system would be extremely natural to implement in the MeTTa language\n[MGWV23": "of the OpenCog Hyperon framework", "with": "n\u2022 Metagraph: A graph of graphs", "data\" (inputs, outputs, intermediate\nstates), while other parts correspond to \"code\" or \"rules\" (rewrite rules\nthat operate on the metagraph).\n\u2022 Rewrite Rules": "These are transformations that take a certain sub-metagraph\npattern (input pattern) and produce a new sub-metagraph pattern (out-\nput pattern). Each rewrite rule can be represented as a pair: a \"condition\npattern\" and a \"replacement pattern.\" Because rewrite rules themselves\nare sub-metagraphs", "Outputs": "Some nodes in the metagraph are designated as \"ex-\nternal inputs\" originating from the environment (e.g., sensor readings),\nand some nodes are designated as \"external outputs\" that affect the envi-\nronment (e.g., actuator commands). The system applies its rewrite rules\niteratively to propagate and transform input patterns into output pat-\nt"}]}