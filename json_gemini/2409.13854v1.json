{"title": "More Consideration to the Perceptron", "authors": ["Slimane LARABI"], "abstract": "In this paper, we introduce the gated perceptron, an enhancement of the conventional perceptron, which incorporates an additional input computed as the product of the existing inputs. This allows the perceptron to capture non-linear interactions between features, significantly improving its ability to classify and regress on complex datasets. We explore its application in both linear and non-linear regression tasks using the Iris dataset, as well as binary and multi-class classification problems, including the PIMA Indian dataset and Breast Cancer Wisconsin dataset. Our results demonstrate that the gated perceptron can generate more distinct decision regions compared to traditional perceptrons, enhancing its classification capabilities, particularly in handling non-linear data. Performance comparisons show that the gated perceptron competes with state-of-the-art classifiers while maintaining a simple architecture.", "sections": [{"title": "1. Introduction", "content": "The first artificial neuron was introduced by Warren McCulloch in 1943 [1]. In this model, without any training, the weighted sum of inputs is compared to a threshold to determine the neuron's output. In the 1950s, Frank Rosenblatt proposed a learning rule for training neural networks, introducing the concept of the perceptron [2]. However, the limitations of perceptrons, particularly their inability to handle non linearity, were highlighted by Marvin Minsky and Seymour Papert [3]. They demonstrated that perceptrons could not account for nonlinear relationships. Subsequently, the development of multilayer perceptrons and training algorithms like back propagation [6] enabled the processing of nonlinear problems.\nUsing only one neuron in a single-layer neural network for binary classification is equivalent to a simple linear classifier. This approach can work well if the data is linearly"}, {"title": "2. The Gated Perceptron and Proprieties", "content": "We define a gated perceptron as a conventional perceptron with inputs, activation function and output, and in addition a new input computed as the product of all inputs. Figure 1 shows a gated perceptron with two inputs, (X1) and (X2), a third input is generated from these two inputs equal to X1 * X2.\nSimilar to the conventional perceptron, to each input is assigned a weight, and the weighted sum is calculated as follows:\n$y = W1X1 + W2X2 + W3X1X2 + b$ (1)\nIn order to study the sum function y, we draw its boundary expressed by the following equation.\nX2(W2 + W3X1) + w1X1 + b = 0 (2)"}, {"title": "3. The Gated Perceptron for Computing Linear and non Linear Regression", "content": "This section explores the application of the gated perceptron in both linear and non-linear regression tasks. By utilizing gate mechanisms, the perceptron adapts to a wider range of data patterns, allowing it to compute non-linear relationships that traditional perceptrons struggle with. Through the appropriate choice of weights and gate configurations, the gated perceptron demonstrates its capacity to model complex, non-linear functions, as well as simpler, linear relationships.\nFor the computation of linear regression using a gated perceptron, we consider the Iris dataset [5], commonly used in classic regression tasks. This dataset includes four parameters defining the type of plants. To perform regression on this dataset with two classes ('Iris-setosa' and 'Iris-versicolor'), we employ a gated perceptron with two inputs (xi, xj), where (i, j = 0..3). Figure 6 displays the results obtained using one combination of these two parameters; similar results are observed with other combinations. In the figure, green dots represent instances of the first class ('Iris-setosa'), while red dots represent instances of the second class ('Iris-versicolor'). The figures also include regression results obtained using a simple perceptron for comparison.\nThe concept of computing the boundaries between three classes of data is based on the loss function (L) defined by equation 3, where (x1, x2) represent the ith input to the gated perceptron."}, {"title": "4. The Gated Perceptron for Classification", "content": "In this section, we examine the efficiency of the gated perceptron in solving classification problems. We begin by addressing binary classification, followed by an investigation into its application for multi-class classification."}, {"title": "4.1 Binary Classification", "content": null}, {"title": "4.1.1 Breast Cancer Wisconsin (Diagnostic) Dataset [8]", "content": "The binary classification model is applied to the Breast Cancer Wisconsin (Diagnostic) Dataset [8], utilizing a single-layer gated perceptron with one neuron. The inputs to the gated perceptron are n entries X\u2081, and the output y is computed as the sigmoid of the sum of weighted inputs (see Figure 6). Additionally, the product (X1, X2, ..., Xn), is"}, {"title": "4.1.2 Discussion", "content": "To understand the good results obtained with only one gated perceptron, we tracked the values of the weights associated with the added input (the gate) across all epochs. The weights remained stable, indicating that the gated perceptron performed computations similar to a traditional perceptron.\nWhen we replaced the gated perceptron with a conventional perceptron, we obtained the same results (see Table 2 and Figures 10, 11, 12). This suggests that the 30 fea-tures of the WDBC (Wisconsin Diagnostic Breast Cancer) dataset are effectively linear.\nThis finding is noteworthy because many researchers have developed various methods, including complex neural networks, without testing with a single perceptron, under the"}, {"title": "4.1.3 PIMA Indian Dataset [7]", "content": "We implemented a single-layer gated perceptron model to classify patients as diabetic or non-diabetic based on the PIMA Indian Dataset [7] using one gated perceptron.\nWe performed data preprocessing to ensure that missing values were handled appro-priately, and we normalized all features. The model was trained using gradient descent with sigmoid activation and binary cross-entropy loss, and validated on a separate test set using various performance metrics.\nThe same experiment has been conducted using a mode with one perceptron. The results are given by tables 4 and 5. Globally, both the gated and conventional perceptron achieve similar results. Note that the gated perceptron performs better overall considering the F1 Score and Recall while maintaining reasonable precision and overall performance"}, {"title": "4.2 Multi-Class Classification", "content": "We performed multi-class classification on the Iris dataset [11] using a single-layer gated perceptron model with softmax output for the three classes: Iris-setosa, Iris-versicolor, and Iris-virginica."}, {"title": "5. Conclusion", "content": "In this paper, we introduced the gated perceptron as an enhancement over the conven-tional perceptron, allowing it to handle non-linearity in data through the introduction of a new input that captures interactions between features. We demonstrated how the gated perceptron can generate more distinct regions in the input space, improving its ability to perform both linear and non-linear regression and classification tasks.\nOur experiments, conducted on both binary and multi-class classification problems, as well as regression tasks using common datasets like Iris and Breast Cancer Wisconsin,"}]}