{"title": "Generating Gender Alternatives in Machine Translation", "authors": ["Sarthak Garg", "Mozhdeh Gheini", "Clara Emmanuel", "Tatiana Likhomanenko", "Qin Gao", "Matthias Paulik"], "abstract": "Machine translation (MT) systems often translate terms with ambiguous gender (e.g., English term \"the nurse\") into the gendered form that is most prevalent in the systems' training data (e.g., \"enfermera\", the Spanish term for a female nurse). This often reflects and perpetuates harmful stereotypes present in society. With MT user interfaces in mind that allow for resolving gender ambiguity in a frictionless manner, we study the problem of generating all grammatically correct gendered translation alternatives. We open source train and test datasets for five language pairs and establish benchmarks for this task. Our key technical contribution is a novel semi-supervised solution for generating alternatives that integrates seamlessly with standard MT models and maintains high performance without requiring additional components or increasing inference overhead.", "sections": [{"title": "1 Introduction and Related Work", "content": "Gender\u00b9 biases present in train data are known to bleed into natural language processing (NLP) systems, resulting in dissemination and potential amplification of those biases (Sun et al., 2019). Such biases are often also the root cause of errors. A machine translation (MT) system might, for example, translate doctor to the Spanish term m\u00e9dico (masculine) instead of m\u00e9dica (feminine), given the input \u201cThe doctor asked the nurse to help her in the procedure\" (Stanovsky et al., 2019). To avoid prescribing wrong gender assignment, MT systems need to disambiguate gender through context. When the correct gender cannot be determined through context, providing multiple translation alternatives that cover all valid gender choices is a reasonable approach.\nNumerous prior works have focused on producing correctly gendered translations given contextual gender \"hints\", such as \u201cto help her\" in the example above (Stanovsky et al., 2019; Saunders and Byrne, 2020; Stafanovi\u010ds et al., 2020; Costa-juss\u00e0 et al., 2022; Saunders et al., 2022; Renduchintala et al., 2021; Bentivogli et al., 2020; Currey et al., 2022). In contrast, the problem of generating all valid and grammatically correct gendered translations has seen far less attention (Kuczmarski and Johnson, 2018; Johnson, 2020; S\u00e1nchez et al., 2023).\nConsider the example: \"The secretary was angry with the boss.\" The gender of both secretary and boss remain ambiguous in the absence of additional context: both entities can take either gender. However, and to the best of our knowledge, all existing approaches (Kuczmarski and Johnson, 2018; Johnson, 2020; S\u00e1nchez et al., 2023; Rarrick et al., 2023) for producing different gendered translations operate on \u201csentence-level\", instead of on \"entity-level\": they only allow two sentence-level alternatives to surface, in which both secretary and boss are either masculine or feminine:\nIn this work, we introduce a novel approach that operates on entity-level, i.e., it generates four alternatives corresponding to all grammatically valid combinations of gender choices for both entities:\nWhen integrated with a proper user interface, our approach provides users with the freedom to choose gender for each entity. We posit that any such system should meet the following practical quality criteria, making the problem challenging:"}, {"title": "2 Entity-Level Gender Alternatives", "content": "Our key insight for efficiently generating entity-level gender alternatives is to reduce the problem to generating a single translation with embedded gender structures and their gender alignments.\nConsider our previous example: \u201cThe secretary was angry with the boss.\u201d We want to generate the following entity-level alternatives:\nSince we constraint the alternatives to only differ in gender inflections, we can instead produce a single translation with gender-sensitive phrases grouped together as gender structures, shown in ():\nAll alternatives can be derived from this single translation by choosing either the masculine or feminine form in each gender structure. However, doing this naively can give us invalid alternatives that break gender agreement, for example:\n and  correspond to the same entity secretary and cannot have different gender choices. By having gender alignments between each gender structure in the translation and its corresponding gender-ambiguous entity in the source, we can deduce which gender structures are linked together and need to be consistent with each other.\nLet \\(x = x_1... x_n\\) be the source sentence containing n tokens and let \\(G_a \\subset \\{1...n\\}\\) represent the set of indices of gender-ambiguous entities in x. We aim to produce a translation \\(y_s\\):\n\\(y_S = y_1 ... (\\frac{M_i}{F_i}) ... y_m\\),\ncontaining a set of gender structures \\(S = \\{S_1... S_k\\}\\) where \\(S_i = (\\frac{M}{F})\\) is the ith gender structure. Translation \\(y_s\\) is a sequence of two types of elements: \\{y_1...y_m\\} = YS\\backslash S are regular tokens that do not change based on the gender of any entity in \\(G_a\\) and M/F are the masculine and feminine inflected forms of the phrases that do change based on the gender of an entity in \\(G_a\\). Gender alignments can then be formally defined as a one-to-many mapping from \\(G_a\\) to S. An ambiguous entity is aligned to a gender structure \\((\\frac{M}{F})\\) iff the correct inflection form (M or F) in the translation depends on the gender of the entity. In our example, secretary is aligned to \\((\\frac{El secretario}{La secretaria})\\), \\((\\frac{enojada}{enojado})\\), and boss is aligned to \\((\\frac{el jefe}{la jefa})\\). Given the translation with gender structures \\(y_s\\) and gender alignments, alternatives corresponding to any combination of gender assignments of ambiguous entities can be easily derived as follows: for all ambiguous entities with male gender assignment, choose the male form for their aligned gender structures. Similarly, for all entities with female assignments, choose the female form for their aligned gender structures."}, {"title": "3 Datasets", "content": "To build and evaluate systems producing alternatives, we prepare train and test sets containing gender structures and gender alignment annotations.\n3.1 Test data\nWe evaluate our models on a combination of two existing test sets that test complementary aspects:\n\u2022 GATE (Rarrick et al., 2023) has source sentences with at least 1 and at most 3 gender-ambiguous entities with their entity-level alternatives satisfying our quality criteria. It evaluates the system on cases where alternatives should be produced.\n\u2022 MT-GenEval (Currey et al., 2022) contains sentences with entities whose gender can be inferred from the sentence context and are not ambiguous. This set is helpful for evaluating cases where alternatives should not be produced.\nThese two test sets have different annotation formats and guidelines. In order to unify them, we ask annotators to review and post-edit existing annotations using the following guidelines:\n1. Marking gendered words: First, all words in the source referring to entities (people/animals) that can have masculine or feminine grammatical genders are marked.\n2. Gender ambiguity annotation: Next, if multiple words refer to the same entity, a head word is selected among them. We guided the annotators to pick the one that acts the most like the subject as the head word. For each head word, if its gender can be inferred from the grammatical context, such as co-referring male/female pronouns, it is marked as such. If no gender can be inferred, the gender is marked as ambiguous. We only rely on grammatical sentence context and not on external knowledge/common gender associations of names/proper nouns. Appendix B discusses how our annotation guidelines handle the problem of masculine generics (Piergentili et al., 2023a), where masculine nouns/pronouns can be used to refer to ambiguous or collective entities.\n3. Gender aware translation: Finally, we ask the annotators to translate the source sentence. Entities without any ambiguity must be translated into the correct gender. If the translation depends on the gender of the ambiguous entities in the source, gender structures and gender alignments are annotated.\nTable 1 explains the process with the help of an example annotation. We prepare this unified test set for 6 language pairs: English to German, French, Spanish, Portuguese, Russian, and Italian.4\n3.2 Train data\nWe open source train data containing samples in the same format as the test set to ensure reproducibility and to encourage development of supervised/semi-supervised systems for producing alternatives. In contrast to the test sets, which are created via human annotation, we rely on an automatic data augmentation approach (see Appendix C for details) to create train data at scale. The source sentences for the train sets are sampled from Europarl (Koehn, 2005), WikiTitles (Tiedemann, 2012), and WikiMatrix (Schwenk et al., 2021) corpora. The train data are partitioned into two different sets:\n\u2022 G-Tag contains source sentences with head words for all entities with their gender ambiguity label: Masc., Fem. or Ambiguous.\n\u2022 G-Trans contains gender-ambiguous entities in the source sentences, gender structures in the translations and gender alignments.\nTo the best of our knowledge, this is the first large-scale corpus that contains gender ambiguities and how they effect gendered forms in the translation. We release these sets for 5 language pairs: English to German, French, Spanish, Portuguese, and Russian. G-Tag contains ~ 12k sentences and"}, {"title": "4 Training MT Models to Generate Gender Structures and Alignments", "content": "We first present how to train MT models that produce gender structures and alignments, assuming parallel data enriched with gender structures and alignments (for example, G-Trans) is available. We then describe a novel data augmentation pipeline that can enrich any regular parallel corpora with gender structures and alignments.\nGiven a source sentence \\(x = \\{x_1... x_n\\}\\), translation \\(y_s\\) containing gender structures, and gender alignments A, we want to train the MT model to generate \\(y_s, A|x\\). Let's assume that \\(y_s\\) contains k gender structures and \\(A = \\{a_1 ... a_k\\}\\) where \\(a_i\\) represents the source token aligned to the ith gender structure. We serialize each gender structure in \\(y_s\\) into a sequence of tokens as follows:\n\\(( \\frac{M}{F} ) \\rightarrow BEG M MID F END\\)\nwhere BEG, MID, and END are special tokens. The model is then trained to produce gender structures in the form of this sequence.\nGarg et al. (2019) introduced a technique to train MT models to jointly generate translations and word-alignments. We use their approach to learn generation of gender alignments. Let \\(m_1 .. m_k\\) denote the positions of the MID tokens of the gender structures. A specific cross-attention head is chosen and supervised to learn gender alignments. Let n and m denote the lengths of the source and the serialized target respectively and let \\(P_{mxn}\\) denote the attention probability distribution computed by the selected head. We train the model with regular cross entropy and an additional alignment loss:\n\\(L = L_{cross-ent} - \\frac{\\lambda}{k} \\sum_{i=1}^k log(P_{m_i,a_i})\\)\nwhere \\(\\lambda\\) is a scaling factor. This added loss term encourages the attention head to place more probability mass on the aligned source token when generating the MID token belonging to that token's gender structure. During inference, the gender alignment for the ith gender structure can be computed as:\n\\(a_i = \\underset{s \\in \\{x_1...x_n\\}}{argmax} P_{m_i,s}\\)\nThis model can generate gender structures and alignments without any additional inference overhead. Then, using the procedure described in section 2, all entity-level alternatives can be easily derived from the model outputs."}, {"title": "5 Data Augmentation Pipeline", "content": "G-Trans dataset provides supervised data to train MT models in the above manner. However, this dataset is small (50k examples per language pair) and has a restrictive domain, limiting the quality of the trained models. We propose a data augmentation pipeline that can take any regular parallel corpora (containing high quality but potentially biased translations) and augment the translations with gender structures and alignments whenever there are ambiguities in the source."}, {"title": "5.1 Detecting gender-ambiguous entities", "content": "Traditionally, rule-based methods, which rely on dependency parsing and co-reference resolution, are used to detect gender-ambiguous entities in the source sentence (Rarrick et al., 2023; Habash et al., 2019). In contrast, we adopt a data-driven approach. G-Tag dataset contains English source sentences annotated with head-words, which refer to entities with their gender label derived from the grammatical sentence context: ambiguous, masculine, feminine. Following Alhafni et al. (2022), we fine-tune a (BERT-style) pre-trained language model (PLM) using this dataset to tag each source token with one of the four labels: ambiguous, masculine, feminine, or not a headword."}, {"title": "5.2 Generating all-masculine/feminine translations using fine-tuned MT models", "content": "If ambiguous entities are detected in the source sentence, then the next step is to transform the high-quality but potentially biased reference translation \\(y_\u00df\\) to all-masculine \\(y_M\\) and all-feminine \\(y_F\\) translations. \\(y_M\\) and \\(y_F\\) are equivalent to sentence-level alternatives corresponding to masculine and feminine assignments for all ambiguous entities, respectively. We explore two methods for this task: fine-tuning pre-trained MT models (this subsection) and using LLMs (subsection 5.3).\nWe fine-tune a pre-trained MT model M on a bi-text extracted from the G-Trans dataset. The source sentences of this bi-text contain ambiguous entities tagged as masculine or feminine using <M>/<F> tags, and the target translation has correct gender inflections given the gender tags. Table 2 explains this extraction process in detail using an example.\nThe fine-tuned model \\(M_{fine-tuned}\\) learns to generate translations with gender inflections in agreement with the gender assignments (<M>/<F>) in the source. We use Saunders and Byrne (2020)'s lattice rescoring approach to generate \\(y_M\\) and \\(y_F\\). Let \\(X_M\\) and \\(X_F\\) denote source sentences in which all ambiguous entities (\\(G_a\\)) have been tagged using <M> and <F> tags, respectively. Let I(\\(y_\u00df\\)) represent the search space consisting only of all possible gender inflection variants of \\(y_\u00df\\). \\(M_{fine-tuned}\\) is used to decode \\(y_M\\) and \\(y_F\\) over the constrained search space I(\\(y_\u00df\\)):\n\\(y_M = \\underset{y \\in I(y_\u00df)}{argmax} p_{M_{fine-tuned}} (y|X_M)\\)\n\\(y_F = \\underset{y \\in I(y_\u00df)}{argmax} p_{M_{fine-tuned}} (y|X_F)\\)\nThis can be done efficiently using constrained beam search. This procedure guarantees that \\(y_M\\), \\(y_F\\), and \\(y_\u00df\\) differ only in terms of gender inflections, and therefore, \\(y_M\\) and \\(y_F\\) possess the same general translation quality as the reference translation \\(y_\u00df\\)."}, {"title": "5.3 Generating all-masculine/feminine translations using LLMs", "content": "LLMs' ability to learn using in-context examples (Brown et al., 2020) provides us with an alternative approach for generating \\(y_M\\) and \\(y_F\\). We"}, {"title": "5.4 Aligning gender structures", "content": "\\(y_M\\) and \\(y_F\\) are combined together in Step 3 as described in Algorithm 1 to produce a single translation \\(y_s\\) containing gender structures. The final step is to align each gender structure in \\(y_s\\) to an ambiguous entity in the source. We model this as a tagging task and fine-tune a PLM using alignment annotations in the G-Trans dataset."}, {"title": "6 Evaluation Metrics", "content": "We evaluate our systems' performance using the following metrics:\n\u2022 Alternatives metrics: These metrics compute the overlap between the set of sentences that have alternatives in the test set and the set of sentences for which the system produces alternatives. This overlap is measured using precision and recall and gives a sense of how often the system produces alternatives and whether it produces them only when needed.\n\u2022 Structure metrics: These metrics are computed over the set of sentences for which both the test set and system output contain alternatives. They measure the quality of the generated alternatives by computing the overlap between the gender structures in the reference alternatives and the generated alternatives. The overlap is measured using precision and recall.\n\u2022 Alignment accuracy: This is measured as the % of gender structures that are aligned to the correct source entity and reflects the quality of gender agreement in the generated alternatives.\n\u2022 \u03b4-BLEU: Lastly, following Currey et al. (2022), to measure the degree of bias towards a gender, we compute \u03b4-BLEU as follows: We separate the masculine and feminine forms in gender structures (if any) for the reference and the system output, compute masculine and feminine BLEU scores (using sacrebleu (Post, 2018)), and measure the absolute difference between the two:\n\u03b4-BLEU = |BLEU(\u0177m, Ym) \u2013 BLEU(\u0177f, yf)|\nHigher \u03b4-BLEU indicates more bias. Mathematical definitions of alternatives and structure metrics can be found in Appendix K."}, {"title": "7 Experiments and Results", "content": "We will first describe the experimental details and results of our data augmentation pipeline in 7.1 and 7.2. We then present the training details of the MT model generating alternatives end-to-end and how it benefits from data augmentation in 7.3 and 7.4.\n7.1 Data augmentation pipeline details\nThe data augmentation pipeline consists of three components: detecting gender-ambiguous entities, generating all-masculine/feminine translations and aligning gender structures.\nWe build the ambiguous entity detector (\u00a75.1) by fine-tuning xlm-roberta-large (Conneau et al., 2020) using transformers (Wolf et al., 2020). We use the combined G-Tag dataset across all 5 language pairs for fine-tuning.\nTo generate all-masculine/feminine translations, we explore two approaches: fine-tuning pre-trained MT models (\u00a75.2), and using LLMs (\u00a75.3). For the first approach, we fine-tune the M2M 1.2B (Fan et al., 2021) model using fairseq (Ott et al., 2019). The model is fine-tuned jointly on bi-text"}, {"title": "7.2 Data augmentation pipeline results", "content": "The data augmentation pipeline takes source sentences and their reference translations (without gender structures, potentially biased) as inputs. For evaluating the data augmentation pipeline, we feed in the source sentences and their all-masculine reference translations from the test set as inputs. The pipeline returns these translations augmented with gender structures and alignments. We can then compute the evaluation metrics described in section 6 on the generated gender structures and alignments. Table 3 summarizes the results.\nBoth M2M and GPT perform mostly on par with the exception of English-Russian, where GPT achieves much lower alternatives recall (58.7 compared to 89.3). The quality of generated gender structures is better for GPT on English-German and English-Portuguese and better for M2M on English-Spanish and English-Russian, as can be seen from the structure metrics. Note that we don't have any G-Trans data for English-Italian, so the results of the M2M model and the alignment accuracy on English-Italian are purely due to zero-shot generalization of M2M and XLM models (Johnson et al., 2017). Overall, the zero-shot results are comparable to others in terms of alternatives metrics and alignment accuracy but fall behind on structure metrics. The alignment model performs well obtaining \u2265 91% accuracy on all language pairs.\n\u03b4-BLEU depends on both alternatives and structure metrics and can be used as a single metric to compare systems' performance. Overall, GPT wins in terms of not relying on any fine-tuning dataset and better performance on English to German, Spanish, and French. Fine-tuning M2M wins in terms of achieving better results on English to Portuguese and Russian and being much more efficient in terms of parameters and inference cost (M2M 1.2B can be fit on a single A100 GPU).\nFinally, Table 5 compares the performance of our data augmentation pipeline using M2M against GATE's sentence-level gender re-writer on their setup. We use our pipeline to re-write an all-masculine reference into an all-feminine form (M\u2192F) and vice-versa (F\u2192M). More details about"}, {"title": "7.3 End-to-end MT model details", "content": "We train a vanilla multilingual MT model on all 6 language pairs using parallel corpora from Europarl, WikiMatrix, WikiTitles, Multi-UN (Chen and Eisele, 2012), NewsCommentary (Barrault et al., 2019) and Tilde MODEL (Rozis and Skadi\u0146\u0161, 2017). We refer to this as vanilla bi-text. We evaluate the models on gender-related metrics using our gender test set. The details of data pre-processing, training, and model architecture can be found in Appendix J.\nA straightforward way to adapt this vanilla model to produce gender alternatives is to use domain adaptation methods towards the G-Trans dataset (which contains gender structures and alignments). To this end, we train another MT model with the vanilla bi-text plus the G-Trans dataset with a prefixed corpus tag <gender> using the loss and serialization described in section 4. Adding corpus tags when mixing corpora from different domains has proven to be quite effective (Kobus et al., 2017; Caswell et al., 2019; Costa-juss\u00e0 et al., 2022). During inference, this tag is used to decode gender alternatives. We treat this model as the supervised baseline.\nFinally, we train a third model, this time augmenting the entire vanilla bi-text with gender structures and alignments by passing it through our data augmentation pipeline (using M2M since running GPT at scale is cost-prohibitive).\nTo measure the impact of our approach on general domain translation performance, we evaluate the models on the FLoRes (Costa-juss\u00e0 et al., 2022) test set. Since FLoRes references don't contain gender structures, we also remove gender structures from the outputs of our models (if any are present) while evaluating against FLoRes. We do so by choosing the gender form which is more probable according to the model: concretely, for every gender structure BEG M MID F END, we choose either M or F depending on which phrase has a higher average token log probability."}, {"title": "7.4 End-to-end MT model results", "content": "Table 4 summarizes the results of these models.\nThe vanilla model cannot generate alternatives and shows a huge bias towards generating masculine forms (\u03b4-BLEU ranging from 5.3 to 12.5 points). This bias is greatly reduced by the supervised baseline. The model trained on augmented data further reduces the bias and obtains the best performance in terms of alternative metrics, alignment accuracy, and \u03b4-BLEU. This shows the effectiveness of the data augmentation pipeline. Augmented data also allows us to train a competitive system for English-Italian which lacks supervised data.\nResults on general domain translation quality (Column FLoRes BLEU from Table 4) show that compared to the vanilla baseline, the model trained on augmented data suffers no degradation on English to German and Spanish and some degradations (-0.3 to \u22120.7 BLEU) on Engish to French, Portuguese, Russian and Italian."}, {"title": "8 Conclusion and Future Work", "content": "In this work, we study the task of generating entity-level alternatives when translating a sentence with gender ambiguities into a language with grammatical gender. We open source first train datasets, encouraging future research towards this task, and develop a data augmentation pipeline that leverages pre-trained MT models and LLMs to generate even larger train sets. Finally, we demonstrate that this data can be used effectively to train deployment-friendly MT models that generate alternatives without any additional inference cost or model components.\nOur models and pipeline can enable new translation UIs that support fine-grained gender control and can also find applications in aiding human translators to automatically point out ambiguities and recommend alternative translations.\nFuture work includes exploring other genderless source languages apart from English (e.g., Chinese, Korean, and Japanese) and associated challenges, as well as extending the approach to non-binary and gender-neutral forms (Lardelli, 2023; Piergentili et al., 2023b; Savoldi et al., 2024)."}, {"title": "Bias Statement", "content": "This work focuses on the bias a machine translation system can manifest by solely generating one translation from multiple valid ones that exist with respect to grammatical gender when translating from English to a more gendered language, e.g., French. Singling out one translation as such without offering users the ability to modify the output to match the grammatical gender the user intends for each entity causes two categories of harm: representation harm and quality-of-service harm (Madaio et al., 2020; Blodgett et al., 2020). It causes representational harm by reflecting the potential stereotypes that lead to the default translation (e.g., between occupations and gender) and quality-of-service harm by failing the users who need the output in the target language to be in a grammatical gender case other than what is generated by default. Our work advocates and proposes a solution for enabling users to choose from all equally correct translation alternatives."}, {"title": "Limitations", "content": "All mentions of \"gender\" in this work refer to the grammatical gender present in many languages of the world that are not genderless. Grammatical gender in linguistics is distinct from social gender: while grammatical gender is essentially a noun class system, the discussion surrounding social gender (male, female, nonbinary) encompasses a much more complex set of concepts, e.g., social constructs, norms, roles, and gender identities. Building effective solutions that facilitate inclusive conversations on these topics is not only an open problem in NLP, but many fields.\nMoreover, the ambiguities in the linguistic grammatical gender are assumed to be, as in most of the gendered languages, binary: masculine and feminine. However, many languages have more grammatical genders (i.e., noun classes): e.g., Worrorra has masculine, feminine, terrestrial, celestial, and collective.\nAs such, our proposed resources, as presented so far, fall short of generating entity-level gender-neutral translations or disambiguation beyond the binary system of masculine/feminine. However, it's noteworthy that our pipeline, paired with suitable data resources, e.g., gender-neutral terms for lattice rescoring, forms a powerful instrument for addressing such more challenging settings."}]}