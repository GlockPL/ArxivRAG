{"title": "Generating Gender Alternatives in Machine Translation", "authors": ["Sarthak Garg", "Mozhdeh Gheini", "Clara Emmanuel", "Tatiana Likhomanenko", "Qin Gao", "Matthias Paulik"], "abstract": "Machine translation (MT) systems often translate terms with ambiguous gender (e.g., English term \"the nurse\") into the gendered form that is most prevalent in the systems' training data (e.g., \"enfermera\", the Spanish term for a female nurse). This often reflects and perpetuates harmful stereotypes present in society. With MT user interfaces in mind that allow for resolving gender ambiguity in a frictionless manner, we study the problem of generating all grammatically correct gendered translation alternatives. We open source train and test datasets for five language pairs and establish benchmarks for this task. Our key technical contribution is a novel semi-supervised solution for generating alternatives that integrates seamlessly with standard MT models and maintains high performance without requiring additional components or increasing inference overhead.", "sections": [{"title": "1 Introduction and Related Work", "content": "Gender\u00b9 biases present in train data are known to bleed into natural language processing (NLP) systems, resulting in dissemination and potential amplification of those biases (Sun et al., 2019). Such biases are often also the root cause of errors. A machine translation (MT) system might, for example, translate doctor to the Spanish term m\u00e9dico (masculine) instead of m\u00e9dica (feminine), given the input \u201cThe doctor asked the nurse to help her in the procedure\" (Stanovsky et al., 2019). To avoid prescribing wrong gender assignment, MT systems need to disambiguate gender through context. When the correct gender cannot be determined through context, providing multiple translation alternatives that cover all valid gender choices is a reasonable approach."}, {"title": "2 Entity-Level Gender Alternatives", "content": "Our key insight for efficiently generating entity-level gender alternatives is to reduce the problem to generating a single translation with embedded gender structures and their gender alignments.\nConsider our previous example: \u201cThe secretary was angry with the boss.\u201d We want to generate the following entity-level alternatives:\nSince we constraint the alternatives to only differ in gender inflections, we can instead produce a single translation with gender-sensitive phrases grouped together as gender structures, shown in ():\nAll alternatives can be derived from this single translation by choosing either the masculine or feminine form in each gender structure. However, doing this naively can give us invalid alternatives that break gender agreement, for example:\n(El secretario) and (enojada) correspond to the same\nentity secretary and cannot have different gender\nchoices. By having gender alignments between\neach gender structure in the translation and its cor-\nresponding gender-ambiguous entity in the source,\nwe can deduce which gender structures are linked\ntogether and need to be consistent with each other.\nLet $x = x_1...x_n$ be the source sentence con-\ntaining n tokens and let $G_a \\subset {1...n}$ represent\nthe set of indices of gender-ambiguous entities in x.\nWe aim to produce a translation $y_s$:\n$y_S = y_1 ... \\frac{M_i}{F_i} ... y_m, \\forall i = \\binom{M}{F}$,\ncontaining a set of gender structures $S = {S_1... S_k}$ where $S_i = \\binom{M}{F}$ is the ith gender\nstructure. Translation ys is a sequence of two types\nof elements: {$Y_1...Y_m$} = $Y_S \\setminus S$ are regular to-\nkens that do not change based on the gender of any\nentity in $G_a$ and $\\frac{M}{F}$ are the masculine and fem-\ninine inflected forms of the phrases that do change\nbased on the gender of an entity in $G_a$. Gender\nalignments can then be formally defined as a one-\nto-many mapping from $G_a$ to S. An ambiguous\nentity is aligned to a gender structure $\\binom{M}{F}$ iff the\ncorrect inflection form (M or F) in the translation\ndepends on the gender of the entity. In our example,\nsecretary is aligned to $\\binom{El secretario}{La secretaria}$, $\\binom{enojado}{enojada}$, and\nboss is aligned to $\\binom{el jefe}{la jefa}$. Given the translation\nwith gender structures ys and gender alignments,\nalternatives corresponding to any combination of\ngender assignments of ambiguous entities can be\neasily derived as follows: for all ambiguous enti-\nties with male gender assignment, choose the male\nform for their aligned gender structures. Similarly,\nfor all entities with female assignments, choose the\nfemale form for their aligned gender structures."}, {"title": "3 Datasets", "content": "To build and evaluate systems producing alternatives, we prepare train and test sets containing gender structures and gender alignment annotations."}, {"title": "3.1 Test data", "content": "We evaluate our models on a combination of two existing test sets that test complementary aspects:\nThese two test sets have different annotation formats and guidelines. In order to unify them, we ask annotators to review and post-edit existing annotations using the following guidelines:\n1. Marking gendered words: First, all words in the source referring to entities (people/animals) that can have masculine or feminine grammatical genders are marked.\n2. Gender ambiguity annotation: Next, if multiple words refer to the same entity, a head word is selected among them. We guided the annotators to pick the one that acts the most like the subject as the head word. For each head word, if its gender can be inferred from the grammatical context, such as co-referring male/female pronouns, it is marked as such. If no gender can be inferred, the gender is marked as ambiguous. We only rely on grammatical sentence context and not on external knowledge/common gender associations of names/proper nouns. Appendix B discusses how our annotation guidelines handle the problem of masculine generics (Piergentili et al., 2023a), where masculine nouns/pronouns can be used to refer to ambiguous or collective entities.\n3. Gender aware translation: Finally, we ask the annotators to translate the source sentence. Entities without any ambiguity must be translated into the correct gender. If the translation depends on the gender of the ambiguous entities in the source, gender structures and gender alignments are annotated."}, {"title": "3.2 Train data", "content": "We open source train data containing samples in the same format as the test set to ensure reproducibility and to encourage development of supervised/semi-supervised systems for producing alternatives. In contrast to the test sets, which are created via human annotation, we rely on an automatic data augmentation approach (see Appendix C for details) to create train data at scale. The source sentences for the train sets are sampled from Europarl (Koehn, 2005), WikiTitles (Tiedemann, 2012), and WikiMatrix (Schwenk et al., 2021) corpora. The train data are partitioned into two different sets:\n\\begin{itemize}\n    \\item G-Tag contains source sentences with head words for all entities with their gender ambiguity label: Masc., Fem. or Ambiguous.\n    \\item G-Trans contains gender-ambiguous entities in the source sentences, gender structures in the translations and gender alignments.\n\\end{itemize}\nTo the best of our knowledge, this is the first large-scale corpus that contains gender ambiguities and how they effect gendered forms in the translation. We release these sets for 5 language pairs: English to German, French, Spanish, Portuguese, and Russian. G-Tag contains ~ 12k sentences and"}, {"title": "4 Training MT Models to Generate Gender Structures and Alignments", "content": "We first present how to train MT models that produce gender structures and alignments, assuming parallel data enriched with gender structures and alignments (for example, G-Trans) is available. We then describe a novel data augmentation pipeline that can enrich any regular parallel corpora with gender structures and alignments.\nGiven a source sentence $x = {x_1... x_n}$, translation ys containing gender structures, and gender alignments A, we want to train the MT model to generate ys, Alx. Let's assume that ys contains k gender structures and $A = {a_1 ...a_k}$ where $a_i$ represents the source token aligned to the ith gender structure. We serialize each gender structure in ys into a sequence of tokens as follows:\n$\\binom{M}{F} \\rightarrow BEG M MID F END$\nwhere BEG, MID, and END are special tokens. The model is then trained to produce gender structures in the form of this sequence.\nGarg et al. (2019) introduced a technique to train MT models to jointly generate translations and word-alignments. We use their approach to learn generation of gender alignments. Let $m_1 .. m_k$ denote the positions of the MID tokens of the gender structures. A specific cross-attention head is chosen and supervised to learn gender alignments. Let n and m denote the lengths of the source and the serialized target respectively and let $P_{m \\times n}$ denote the attention probability distribution computed by the selected head. We train the model with regular cross entropy and an additional alignment loss:\n$L = L_{cross-ent} - \\frac{\\lambda}{k} \\sum_{i=1}^{k} log(P_{m_i,a_i})$\nwhere \u03bb is a scaling factor. This added loss term encourages the attention head to place more probability mass on the aligned source token when generating the MID token belonging to that token's gender structure. During inference, the gender alignment for the ith gender structure can be computed as:\n$A_i = \\underset{s \\in {x_1...x_n}}{argmax} P_{m_i,s}$ \nThis model can generate gender structures and alignments without any additional inference overhead. Then, using the procedure described in section 2, all entity-level alternatives can be easily derived from the model outputs."}, {"title": "5 Data Augmentation Pipeline", "content": "G-Trans dataset provides supervised data to train MT models in the above manner. However, this dataset is small (50k examples per language pair) and has a restrictive domain, limiting the quality of the trained models. We propose a data augmentation pipeline that can take any regular parallel corpora (containing high quality but potentially biased translations) and augment the translations with gender structures and alignments whenever there are ambiguities in the source.\nAlgorithm 1 gives an overview of the main components of the pipeline, which we describe in detail in the following subsections. It consists of first detecting gender-ambiguous entities in the source sentence (\u00a75.1), followed by transforming the reference translation into all-masculine/all-feminine translations (\u00a75.2, \u00a75.3), condensing those into single translation with gender structures, and finally aligning the gender structures (\u00a75.4)."}, {"title": "5.1 Detecting gender-ambiguous entities", "content": "Traditionally, rule-based methods, which rely on dependency parsing and co-reference resolution, are used to detect gender-ambiguous entities in the source sentence (Rarrick et al., 2023; Habash et al., 2019). In contrast, we adopt a data-driven approach. G-Tag dataset contains English source sentences annotated with head-words, which refer to entities with their gender label derived from the grammatical sentence context: ambiguous, masculine, feminine. Following Alhafni et al. (2022), we fine-tune a (BERT-style) pre-trained language model (PLM) using this dataset to tag each source token with one of the four labels: ambiguous, masculine, feminine, or not a headword."}, {"title": "5.2 Generating all-masculine/feminine translations using fine-tuned MT models", "content": "If ambiguous entities are detected in the source sentence, then the next step is to transform the high-quality but potentially biased reference translation $y_B$ to all-masculine $y_M$ and all-feminine $y_F$ translations. $Y_M$ and $Y_F$ are equivalent to sentence-level alternatives corresponding to masculine and feminine assignments for all ambiguous entities, respectively. We explore two methods for this task: fine-tuning pre-trained MT models (this subsection) and using LLMs (subsection 5.3).\nWe fine-tune a pre-trained MT model M on a bi-text extracted from the G-Trans dataset. The source sentences of this bi-text contain ambiguous entities tagged as masculine or feminine using <M>/<F> tags, and the target translation has correct gender inflections given the gender tags. explains this extraction process in detail using an example.\nThe fine-tuned model $M_{fine-tuned}$ learns to generate translations with gender inflections in agreement with the gender assignments (<M>/<F>) in the source. We use Saunders and Byrne (2020)'s lattice rescoring approach to generate $y_M$ and $y_F$. Let $X_M$ and $X_F$ denote source sentences in which all ambiguous entities ($G_a$) have been tagged using <M> and <F> tags, respectively. Let I($y_B$) represent the search space consisting only of all possible gender inflection variants of $y_B$. $M_{fine-tuned}$ is used to decode $y_M$ and $y_F$ over the constrained search space I($y_B$):\n$y_M = \\underset{y \\in I(y_B)}{argmax} p_{M_{fine-tuned}}(Y|X_M)$\n$y_F = \\underset{y \\in I(y_B)}{argmax} p_{M_{fine-tuned}}(Y|X_F)$\nThis can be done efficiently using constrained beam search. This procedure guarantees that $y_M$, $y_F$, and $y_B$ differ only in terms of gender inflections, and therefore, $y_M$ and $y_F$ possess the same general translation quality as the reference translation $y_B$."}, {"title": "5.3 Generating all-masculine/feminine translations using LLMs", "content": "LLMs' ability to learn using in-context examples (Brown et al., 2020) provides us with an alternative approach for generating $y_M$ and $y_F$. We"}, {"title": "5.4 Aligning gender structures", "content": "$Y_M$ and $y_F$ are combined together in Step 3 as described in Algorithm 1 to produce a single translation ys containing gender structures. The final step is to align each gender structure in ys to an ambiguous entity in the source. We model this as a tagging task and fine-tune a PLM using alignment annotations in the G-Trans dataset.\nAlgorithm 2 Alignment Algorithm\nEach gender structure is aligned one-by-one as described in Algorithm 2. To align the ith gender structure $S_i$, we take $y_M$ and enclose the phrase corresponding to $S_i$ by a special token | to get $y_A$. Then x and $y_A$ are concatenated together and fed to the PLM, which is fine-tuned to tag all the tokens in x as aligned/not-aligned to $S_i$. The gold aligned/not-aligned labels for fine-tuning are extracted from the G-Trans dataset."}, {"title": "6 Evaluation Metrics", "content": "We evaluate our systems' performance using the following metrics:\n\\begin{itemize}\n    \\item Alternatives metrics: These metrics compute the overlap between the set of sentences that have alternatives in the test set and the set of sentences for which the system produces alternatives. This overlap is measured using precision and recall and gives a sense of how often the system produces alternatives and whether it produces them only when needed.\n    \\item Structure metrics: These metrics are computed over the set of sentences for which both the test set and system output contain alternatives. They measure the quality of the generated alternatives by computing the overlap between the gender structures in the reference alternatives and the generated alternatives. The overlap is measured using precision and recall.\n    \\item Alignment accuracy: This is measured as the % of gender structures that are aligned to the correct source entity and reflects the quality of gender agreement in the generated alternatives.\n    \\item $\\delta$-BLEU: Lastly, following Currey et al. (2022), to measure the degree of bias towards a gender, we compute $\\delta$-BLEU as follows: We separate the masculine and feminine forms in gender structures (if any) for the reference and the system output, compute masculine and feminine BLEU scores (using sacrebleu (Post, 2018)), and measure the absolute difference between the two:\n    $\\delta$-BLEU = |BLEU($\\hat{y}_m, y_m$) \u2013 BLEU($\\hat{y}_f, y_f$)| \n\\end{itemize}\nHigher \u03b4-BLEU indicates more bias. Mathematical definitions of alternatives and structure metrics can be found in Appendix K."}, {"title": "7 Experiments and Results", "content": "We will first describe the experimental details and results of our data augmentation pipeline in 7.1 and 7.2. We then present the training details of the MT model generating alternatives end-to-end and how it benefits from data augmentation in 7.3 and 7.4."}, {"title": "7.1 Data augmentation pipeline details", "content": "The data augmentation pipeline consists of three components: detecting gender-ambiguous entities, generating all-masculine/feminine translations and aligning gender structures.\nWe build the ambiguous entity detector (\u00a75.1) by fine-tuning xlm-roberta-large (Conneau et al., 2020) using transformers (Wolf et al., 2020). We use the combined G-Tag dataset across all 5 language pairs for fine-tuning.\nTo generate all-masculine/feminine translations, we explore two approaches: fine-tuning pre-trained MT models (\u00a75.2), and using LLMs (\u00a75.3). For the first approach, we fine-tune the M2M 1.2B (Fan et al., 2021) model using fairseq (Ott et al., 2019). The model is fine-tuned jointly on bi-text"}, {"title": "7.4 End-to-end MT model results", "content": "Table 4 summarizes the results of these models. The vanilla model cannot generate alternatives and shows a huge bias towards generating masculine forms (\u03b4-BLEU ranging from 5.3 to 12.5 points). This bias is greatly reduced by the supervised baseline. The model trained on augmented data further reduces the bias and obtains the best performance in terms of alternative metrics, alignment accuracy, and \u03b4-BLEU. This shows the effectiveness of the data augmentation pipeline. Augmented data also allows us to train a competitive system for English-Italian which lacks supervised data.\nResults on general domain translation quality (Column FLoRes BLEU from Table 4) show that compared to the vanilla baseline, the model trained on augmented data suffers no degradation on English to German and Spanish and some degradations (-0.3 to \u22120.7 BLEU) on Engish to French, Portuguese, Russian and Italian."}, {"title": "8 Conclusion and Future Work", "content": "In this work, we study the task of generating entity-level alternatives when translating a sentence with gender ambiguities into a language with grammatical gender. We open source first train datasets, encouraging future research towards this task, and develop a data augmentation pipeline that leverages pre-trained MT models and LLMs to generate even larger train sets. Finally, we demonstrate that this data can be used effectively to train deployment-friendly MT models that generate alternatives without any additional inference cost or model components.\nOur models and pipeline can enable new translation UIs that support fine-grained gender control and can also find applications in aiding human translators to automatically point out ambiguities and recommend alternative translations.\nFuture work includes exploring other genderless source languages apart from English (e.g., Chinese, Korean, and Japanese) and associated challenges, as well as extending the approach to non-binary and gender-neutral forms (Lardelli, 2023; Piergentili et al., 2023b; Savoldi et al., 2024)."}, {"title": "Bias Statement", "content": "This work focuses on the bias a machine translation system can manifest by solely generating one translation from multiple valid ones that exist with respect to grammatical gender when translating from English to a more gendered language, e.g., French. Singling out one translation as such without offering users the ability to modify the output to match the grammatical gender the user intends for each entity causes two categories of harm: representation harm and quality-of-service harm (Madaio et al., 2020; Blodgett et al., 2020). It causes representational harm by reflecting the potential stereotypes that lead to the default translation (e.g., between occupations and gender) and quality-of-service harm by failing the users who need the output in the target language to be in a grammatical gender case other than what is generated by default. Our work advocates and proposes a solution for enabling users to choose from all equally correct translation alternatives."}, {"title": "Limitations", "content": "All mentions of \"gender\" in this work refer to the grammatical gender present in many languages of the world that are not genderless. Grammatical gender in linguistics is distinct from social gender: while grammatical gender is essentially a noun class system, the discussion surrounding social gender (male, female, nonbinary) encompasses a much more complex set of concepts, e.g., social constructs, norms, roles, and gender identities. Building effective solutions that facilitate inclusive conversations on these topics is not only an open problem in NLP, but many fields.\nMoreover, the ambiguities in the linguistic grammatical gender are assumed to be, as in most of the gendered languages, binary: masculine and feminine. However, many languages have more grammatical genders (i.e., noun classes): e.g., Worrorra has masculine, feminine, terrestrial, celestial, and collective.\nAs such, our proposed resources, as presented so far, fall short of generating entity-level gender-neutral translations or disambiguation beyond the binary system of masculine/feminine. However, it's noteworthy that our pipeline, paired with suitable data resources, e.g., gender-neutral terms for lattice rescoring, forms a powerful instrument for addressing such more challenging settings."}]}