{"title": "Hypergraph-Based Dynamic Graph Node Classification", "authors": ["Xiaoxu Ma", "Chen Zhao", "Minglai Shao", "Yujie Lin"], "abstract": "Node classification on static graphs has achieved significant success, but achieving accurate node classification on dynamic graphs where node topology, attributes, and labels change over time has not been well addressed. Existing methods based on RNNs and self-attention only aggregate features of the same node across different time slices, which cannot adequately address and capture the diverse dynamic changes in dynamic graphs. Therefore, we propose a novel model named Hypergraph-Based Multi-granularity Dynamic Graph Node Classification (HYDG). After obtaining basic node representations for each slice through a GNN backbone, HYDG models the representations of each node in the dynamic graph through two modules. The individual-level hypergraph captures the spatio-temporal node representations between individual nodes, while the group-level hypergraph captures the multi-granularity group temporal representations among nodes of the same class. Each hyperedge captures different temporal dependencies of varying lengths by connecting multiple nodes within specific time ranges. More accurate representations are obtained through weighted information propagation and aggregation by the hypergraph neural network. Extensive experiments on five real dynamic graph datasets using two GNN backbones demonstrate the superiority of our proposed framework.", "sections": [{"title": "I. INTRODUCTION", "content": "As a widely employed data structure, graph structures excel in representing intricate data and possess robust capabilities for storing and articulating node attributes and entity relationships. The current landscape of graph neural networks [1]\u2013[7] predominantly operates within the realm of static graph structures [8]. However, many real-world scenarios involve dynamic graph structures, such as recommender systems, social media analytics [9], transportation systems [10], citation networks [11]and epidemic modeling. Dynamic graphs can be broadly classified into discrete-time dynamic graphs and continuous-time dynamic graphs [12].In both forms of dynamic graphs, node features, node labels, and graph structures may evolve over time [13], posing a challenge for traditional static graph models in capturing the dynamic relationships among node features. Consequently, the effective capture and utilization of node relationships and features in dynamic networks have emerged as pivotal research questions.\nIn this paper, we focus on the task of node classification in discrete dynamic graphs, specifically predicting the node labels in unknown future graph snapshots given the graph information at previous time steps. As illustrated in Fig. 1, in social interest networks, a user's social connections and personal information may change significantly over time, leading to shifts in their interest labels. Current methods primarily fall into two categories [12], [14]: one uses RNNs [15]\u2013[18] to capture temporal relationships between nodes, while the other employs attention [13], [19] mechanisms to capture dynamic relationships between nodes. However, in diverse real-world dynamic networks, simply using RNNs or self-attention to link the representations of the same node across different time slices may fail to adequately capture the features of various node categories. In scenarios involving changes in node features, label shifts, node disappearance, or the addition of new nodes, traditional dynamic graph learning methods struggle to perform inductive learning effectively, thus failing to cope with the complex node dynamics within dynamic networks.\nTo address these challenges, we propose the Hypergraph-Based Multi-granularity Dynamic Graph Node Classification (HYDG) algorithm, which captures both individual and group-level node features using hypergraphs [20]-[23]. By connecting multiple nodes within specific time intervals through hyperedges, HYDG constructs multi-granularity features, enabling more accurate classifications via hypergraph neural networks. Compared to traditional methods, HYDG more effectively models high-order dependencies and enhances temporal information capture at both individual and group levels through weighted information propagation. Our contributions include:\n\u2022 We introduce a novel hypergraph-based algorithm for dynamic graph node classification that effectively captures"}, {"title": "II. METHODOLOGY", "content": "The primary focus of this paper is to address the problem of node classification on discrete dynamic graphs. Given the dynamic graph snapshots \\(G_p = \\{G_1, G_2,...,G_t\\}\\) up to time step t and the corresponding node labels \\(Y_p = \\{Y_1, Y_2, . . ., Y_t\\}\\), our goal is to classify all nodes in future graph snapshots \\(G_F = \\{G_{t+1},G_{t+2},...,G_T\\}\\), whose labels \\(Y_F = \\{Y_{t+1}, Y_{t+2},...,Y_T\\}\\) are unknown."}, {"title": "A. Dynamic Graph Feature Extraction", "content": "Static graph neural networks have been widely applied in graph representation learning tasks. Therefore, we first utilize a backbone GNN to perform feature extraction on each node of every temporal slice, as shown in Fig. 2(a). This process yields a feature representation for each node at each time step. For the t-th temporal slice of the dynamic graph \\(G^t\\), we can utilize it to obtain feature representations.\n\\(Z^t = GNN(A^t, X^t),\\)\nwhere \\(Z^t\\) represents the matrix of feature embeddings for the nodes in the graph snapshot \\(G^t\\) processed by the GNN, with \\(Z^t = [z_1^t,z_2^t,...,z_n^t]\\), where n is the number of nodes. \\(A^t\\) denotes the adjacency matrix of \\(G^t\\), and \\(X^t\\) refers to the initial feature matrix of the nodes in \\(G^t\\)."}, {"title": "B. Hypergraph Construction", "content": "In dynamic graphs, nodes possess both individual features and common features shared within their subgroups. To better capture the higher-order correlations of nodes within each time slice, we construct multi-scale hypergraphs by capturing individual-level and group-level dependencies, as shown in Fig. 2(b).\nIndividual-level hypergraph construction. We capture the individual high-order dependencies of each node in the dynamic graph by constructing a series of individual hyperedges, denoted as \\(G_{in} = (V_{in}, E_{in})\\). Here, \\(G_{in}\\) includes individual nodes \\(V_{in}\\) and the set of hyperedges \\(E_{in}\\). Specifically, for a given node \\(v_{it}\\), we identify K nodes from other time slices within a specified time range that are most close to the feature vector obtained from (1), excluding the current time slice. These K + 1 nodes are then connected via a hyperedge \\(e_{it}\\), as shown in (2).\n\\(e_{it} = \\{v_{it}, v_{jt'} \\in N_K(v_{it})\\}, s.t. |t - t'| \\leq \\tau,\\)\nwhere \\(N_k\\) represents the set of K nearest neighbors, which can be calculated using various distance metrics such as Euclidean distance, Chebyshev distance, cosine distance, etc. \\(|*|\\) denotes the temporal distance between nodes. \\(\\tau\\) represents the threshold value of the time range. We model the multi-scale temporal dependencies in the dynamic graph by setting three threshold ranges: short-term connection, mid-term connection, and long-term connection, respectively. We construct the individual hypergraph \\(G_{in}\\) using \\(V_{it}\\) and \\(e_{it}\\) obtained from all nodes in each time slice.\nGroup-level hypergraph construction. To better capture the multi-granularity group features of each category in dynamic graphs, we construct a series of group-level hypergraphs \\(G_{group}\\), where \\(G_{group} = (V_{group}, E_{group})\\), including group nodes \\(V_{group}\\) and group hyperedge sets \\(E_{group}\\). In summary, we first group the feature vectors \\(Z^t\\) according to the true labels \\(Y^t\\) of the nodes, followed by hierarchical clustering and aggregation of these groups within each time slice. This process yields spatio-temporal group representations, which are then used to construct hypergraphs for each node category, capturing both the features and their spatio-temporal dependencies in the dynamic network. The mathematical representation is as follows:\n\\(Z_{group} = \\{Agg(Cluster_M(\\{z^t_i | y^t_i = c\\}))\\},\\)\nwhere \\(y^t_i\\) denote the label of node v at time t. By grouping node embeddings with the same label, we obtain \\(O_{c,t} = \\{z^t_i | y^t_i = c\\}\\), where C represents the number of node categories. The function \\(Cluster_M(\\cdot)\\) performs clustering on the grouped embeddings. Applying \\(Cluster_M(O_{c,t})\\) yields the clusters \\(\\{O^1_{c,t}, O^2_{c,t}, ...,O^M_{c,t}\\}\\), where M denotes the number of clusters. The aggregation function \\(Agg(\\cdot)\\) is applied to aggregate the vectors within each cluster, which could be operations such as max(\\cdot), min(\\cdot), or avg(\\cdot). Finally, for each group, we obtain \\(Z^{c,t} \\in \\mathbb{R}^{M \\times T}\\). This process is formalized to capture diverse temporal characteristics of nodes within the same category across different clusters at various time steps.\nWe merge each time slice obtained from \\(Z_{group}\\) by (3) to obtain the grouped \\(Z_{group}\\). Following the construction method of individual-level hypergraph in (2), we construct hyperedges for \\(Z_{group}\\) separately to capture the spatio-temporal evolutionary relationships of various category group characteristics, resulting in \\(V_{group}\\) and \\(E_{group}\\). Hence, we obtain \\(G_{group} = \\{G_{group}\\}_{c \\in C}\\."}, {"title": "C. Hypergraph Propagation", "content": "After constructing individual-level hypergraph \\(G_{in}\\) and group-level hypergraph \\(G_{group}\\), We employ Hypergraph Neu-ral Networks (HGNN) [24] for node-weighted information propagation and feature updating to obtain spatio-temporal fusion features within hyperedges, as illustrated in Fig. 2(c). For a given hypergraph G, the incidence matrix H is defined based on the node set V and edge set E as:\n\\(H(v, e) = 1 \\text{ if } v \\in e, \\text{ else } 0, \\forall v \\in V, \\forall e \\in E.\\)\nBased on \\(G_{in}\\) and \\(G_{group}\\), we can derive the individual and group-level incidence matrices, \\(H_{in}\\) and \\(H_{group}\\), through (4). Following the approach of frequency-domain GCNs [1], we use Fourier transformation to shift spatial signals to the frequency domain for convolution, and then apply the inverse Fourier transformation [24], as formalized by the following equation:\n\\(Z^{(l+1)} = \\sigma (D^{-\\frac{1}{2}}HWD^{-1}H^TD^{-\\frac{1}{2}}Z^{(l)}),\\)\nwhere Z represents the feature matrix, H denotes the incidence matrix, \\( \\Theta \\) is the learnable hypergraph convolution kernel, W is the learnable weight matrix, and \\( \\sigma \\) is the non-linear activation function.\nMore specifically, for a given node \\(v_{it}\\), \\(H(v_{it})\\) represents all hyperedges connected to node \\(v_{it}\\), containing nodes with the highest relevance to \\(v_{it}\\). We aggregate the features of nodes from different time slices in the hyperedges, except for \\(v_{it}\\), using the corresponding weights \\(w_{it'}\\) in \\(H(v_{it})\\) to capture the temporal dependencies within the same hyperedge:\n\\(w_{it'} = \\frac{exp(-\\frac{d(z_{it}, z_{jt'})^2}{\\sigma^2})}{\\sum_{j \\neq i}exp(-\\frac{d(z_{it}, z_{jt'})^2}{\\sigma^2})}, \\, w_{it'} \\forall v_{jt'} \\in e_k\\)\n\\(w_{it'} \\, \\forall v_{it}, v_{jt'} \\in  H(v_{it}),\\)\n\\(v_{it}\\) and \\(v_{jt'}\\) represent a pair of nodes at different time slices within a hyperedge. \\(d(z_{it}, z_{jt'})\\) denotes the distance between \\(v_{it}\\) and \\(v_{jt'}\\). We can use various methods to compute the distance, such as Euclidean distance, cosine distance, etc. \\( \\sigma \\) can be set as the median of distances between all pairs of vertices, \\(z^{l-1}_{jt'}\\) represents the output of node \\(v_{jt'}\\) at layer l \u2013 1 in HGNN.\nAfter obtaining different hyperedge features for the dynamic graph node \\(v_{it}\\), we compute the weight by measuring the similarity between the hyperedge features and node features and normalize the weights using softmax function. Then, we perform edge-node level spatio-temporal dependency aggregation:\n\\(z_{it} = \\sum_{k} \\frac{exp(sim(z_{p_{it}}^{k-1}, z_{it}))}{\\sum_{k}exp(sim(z_{p_{it}}^{k-1}, z_{it}))}\\), where \\(z_{it}\\) denotes the node representations obtained from the above process, are passed through a non-linear function, yielding the integrated representation of node dependencies across time and space."}, {"title": "D. Model Learning", "content": "After the hypergraph information propagation, we obtain the individual and group hypergraph representation, \\(Z_{in}\\) and \\(Z_{group}\\). By applying the softmax function, for each time slice, we compute the predicted labels \\(\\hat{Y}_{in}\\) and \\(\\hat{Y}_{group}\\) for the nodes in \\(G_{in}\\) and \\(G_{group}\\), respectively. The true labels for the group-level hypergraph, \\(Z_{group}\\), are represented by c as follows:\n\\(\\mathcal{L}_{in}(\\mathbf{Y}, \\hat{\\mathbf{Y}}) = - \\sum_{i=1}^{N} y_i \\log(\\frac{e^{z_{in_i}}}{\\sum_{j=1}^{N}e^{z_{in_j}}}),\\)\n\\(\\mathcal{L}_{group}(\\mathbf{Y}, \\hat{\\mathbf{Y}}) = - \\sum_{c=1}^{C}\\sum_{i=1}^{M} y_i^c \\log(\\frac{e^{z_{group_{ic}}}}{\\sum_{j=1}^{M}e^{z_{group_{jc}}}}).\\)\nFor \\(\\mathcal{L}_{in}\\) and \\(\\mathcal{L}_{group}\\), we assign different weights, denoted as \\( \\alpha \\) and \\( \\beta \\), respectively, resulting in the overall loss function \\(L_{all}\\), which consists of the following two terms:\n\\(L_{all} = \\alpha \\cdot \\mathcal{L}_{in} + \\beta \\cdot \\mathcal{L}_{group}.\\)\nDuring training, we construct both individual and group-level hypergraphs to capture diverse node representations using hypergraph neural networks. During testing, without labels, we use only individual-level hypergraphs and the trained network for predictions. The group-level hypergraphs, used for data augmentation, capture evolving relationships within the same class, addressing variations in unseen test sets."}, {"title": "III. EXPERIMENTS", "content": ""}, {"title": "A. Experimental Settings", "content": "We conducted experiments using five real-world dynamic graph datasets, with detailed information provided in Table II. We selected seven baselines for comparison, including both static [1], [8] and dynamic graph neural networks [13], [16], [18], [19], [25]. The primary task is to predict the node labels in the test set at various time slices using the node features and label information from limited time slices in the training set. To better evaluate the model's performance, we used accuracy and Macro-AUC as evaluation metrics. Each method employs"}, {"title": "B. Overall Performance", "content": "As shown in Table I, we conduct experiments using both GCN and GraphSAGE backbones, with EvolveGCN and DySAT sharing experimental results across both sets. The results demonstrate that the HYDG model consistently outperforms baseline models in node classification tasks across five datasets. By constructing individual hypergraphs and multi-scale group-level hypergraphs while capturing spatio-temporal dependencies, HYDG achieves superior accuracy on the DBLP5, Reddit, Wiki, and ML-RATING datasets using both GCN and GraphSAGE backbones, and records the highest AUC scores on the DBLP3, Reddit, and ML-RATING datasets. Notably, HYDG shows a 2%-3% improvement in accuracy on the DBLP5 and Reddit datasets compared to the best-performing baselines, despite slightly trailing RNN-GCN in AUC on DBLP3. These results suggest that the ability of HYDG to capture spatio-temporal dependencies enables better learning of node representations and relationships in dynamic graphs, outperforming traditional methods based on self-attention mechanisms and RNNS."}, {"title": "C. Ablation Study", "content": "To better explore the roles of individual-level hypergraphs and group-level hypergraphs in capturing spatio-temporal dependencies in dynamic graphs, we conduct ablation experiments on these two modules separately, and the results are shown in Fig. 3. (i) Removal of individual-level hypergraphs. Utilizing only group-level hypergraphs yields poor accuracy and AUC results. This is because group-level hypergraphs capture features only within each slice, resulting in insufficient usable nodes and inadequate capture of features and dependencies across samples. (ii) Removal of group-level hypergraphs. Utilizing only individual-level hypergraphs achieves relatively high accuracy but results in lower AUC. This is because the individual hypergraph construction, which links hyperedges by identifying each node's nearest neighbors, may capture only single dynamic dependency patterns. Additionally, connections between nodes with different labels can lead to incomplete dynamic feature representations."}, {"title": "IV. CONCLUSION", "content": "This paper presents a dynamic graph node classification framework based on multi-granularity hypergraphs. By constructing individual-level hypergraphs across various time ranges and multi-granularity group-level hypergraphs, the framework effectively captures higher-order spatio-temporal dependencies in dynamic graph nodes. Hypergraph neural networks are employed for weighted information propagation, leading to more accurate and robust node representations. Extensive experiments on five real datasets using two backbones demonstrate that the proposed framework outperforms the optimal baseline models."}]}