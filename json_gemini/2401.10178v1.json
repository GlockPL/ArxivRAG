{"title": "Neural Echos: Depthwise Convolutional Filters Replicate Biological Receptive Fields", "authors": ["Zahra Babaiee", "Peyman M. Kiasari", "Daniela Rus", "Radu Grosu"], "abstract": "In this study, we present evidence suggesting that depthwise convolutional kernels are effectively replicating the structural intricacies of the biological receptive fields observed in the mammalian retina. We provide analytics of trained kernels from various state-of-the-art models substantiating this evidence. Inspired by this intriguing discovery, we propose an initialization scheme that draws inspiration from the biological receptive fields. Experimental analysis of the ImageNet dataset with multiple CNN architectures featuring depthwise convolutions reveals a marked enhancement in the accuracy of the learned model when initialized with biologically derived weights. This underlies the potential for biologically inspired computational models to further our understanding of vision processing systems and to improve the efficacy of convolutional networks.", "sections": [{"title": "1. Introduction", "content": "Convolutional Neural Networks (CNNs) [31], a mainstay of modern artificial intelligence (AI), owe their fundamental design principles to insights drawn from neuroscience (NS) [24], particularly our understanding of receptive fields. A receptive field is the specific region of sensory space eliciting a response from a neuron when stimulated [14, 24]. The concept is deeply ingrained in the architecture of the mammalian visual system, starting from the retina. CNNs mimic this structure through their use of 'kernels' capable of responding to a specific part of the image. This convolution process mirrors the hierarchal, spatially invariant nature of biological vision systems, underscoring the deep connections between the fields of NS and AI.\nThe realm of convolutional neural networks (CNNs) has witnessed remarkable evolutionary phases since its inception. Initial architectures, such as AlexNet [27], introduced in 2012, focused on varying kernel sizes to capture image features. As the field matured, architectures like VGG networks [38] and Residual Networks [18] standardized the use of 3x3 kernels, optimizing for efficiency and training speed. However, a pivotal shift emerged with the introduction and popularization of depthwise convolutions.\nDepthwise convolutions introduced a novel approach to feature extraction, where each input channel is individually convolved with its own filter, as opposed to standard convolutions that aggregate information across multiple channels. This technique, exemplified by architectures like MobileNet with its 3x3 depthwise convolutions, offers significant reductions in computational overhead without markedly sacrificing model accuracy. The advent of vision transformers and their patch-centric designs [8] further accentuated the exploration into depthwise convolution behaviors with larger kernel sizes, reinforcing their unique ability to manifest structured patterns.\nThe cornerstone of visual processing in numerous retinal cell types, including the intricate network of ganglion neurons, is the principle of center-surround antagonism, a mechanism established in the receptive field of neurons, as early as in the retina [9, 24, 29]. This mechanism stems from lateral inhibitory connections and is perpetuated by neurons in higher visual processing centers, namely the lateral geniculate nucleus and the visual cortex [22].\nThe center-surround antagonism plays a vital role in the primate visual system, assisting in complex tasks such as edge detection, figure-background segregation, depth, and object perception, that remain consistent across various visual cues. Importantly, this architecture has two key configurations: excitatory- and inhibitory-center receptive fields, respectively [37,44]. In the former configuration, ganglion cells are excited by light falling on the center of the receptive field and inhibited by light falling on the surrounding area. Conversely, in the latter configuration, cells are inhibited by light at the center and excited by light in the surrounding area. This design enhances contrast and aids in edge detection [9,24].\nClassical NS models frequently employ receptive fields featuring center-surround antagonism, typically realized through a Difference of Gaussians (DoG) function, which creates an excitatory peak at the receptive field's center counterbalanced by an inhibitory surround [10, 23].\nIn our investigations, we unearthed a remarkable parallel between the trained kernels of depthwise convolutions in various models and biological receptive fields: a significant quantity of them echoed the center-surround pattern seen in biological receptive fields. Intriguingly, such patterns were exclusively observed in depthwise convolutions, eluding their regular convolution counterparts. In Figure 1 we provide a comparative demonstration of the trained depthwise kernels and the NS-based model of center-surround kernels, highlighting their noteworthy similarities. This discovery underscores not only the computational advantages of depthwise convolutions but also their potential to mirror biologically-inspired patterns, reaffirming the value of rethinking standard convolution operations in modern deep-learning paradigms.\nTaking cues from these resemblances, we suggest a center-surround initialization procedure for depthwise convolutional kernels. Our experiments on ImageNet dataset with different models revealed that networks when initialized using our biologically-inspired methodology, display a marked increase in accuracy. Specifically, models initialized by our method gain up to more than two percent accuracy on the ImageNet dataset. Despite these notable improvements, the primary purpose of this paper is not solely to underscore performance enhancements. Rather, we aim to emphasize the intriguing discovery that artificial kernels emulate their biological counterparts without explicit supervision. Our results demonstrate the significant potential of biologically inspired computational models in enriching our comprehension of vision processing systems and enhancing the performance of artificial neural networks."}, {"title": "2. Related Work", "content": "Depth-wise Convolutions. The evolution of convolutional neural networks has been marked by the introduction and adaptation of diverse convolution operations. Notably, depthwise convolutions, where each input channel is convolved with its distinct filter, have gained traction. With the recent surge of modern enhanced CNN architectures, especially in the wake of the transformative impact of vision transformers, many models are now favoring depthwise convolutions with large kernels over traditional regular convolutions. Depthwise convolutions gained prominence with the introduction of the MobileNet architecture [20], which showcased their efficacy in crafting lightweight models tailored for mobile and embedded vision applications. With the resurgence of the modern CNN architectures after the introduction of vision transformers, many models use depthwise convolutions in their blocks [32, 35, 41, 42].\nBio-inspired Models. A considerable volume of research has aimed to incorporate insights from NS into computer vision systems [25,30,47]. Initial vision models were significantly influenced by NS and psychology. In recent times, there have been substantial advances in both NS and AI, especially in computer vision. However, the majority of contemporary networks, are only loosely based on the visual system, and cross-fertilization between the two fields is less frequent as in the early days of AI. This is in spite of the fact that NS continues to be a vital source of innovative ideas that fuel advancements in AI [4, 16].\nThe development of AI models that closely resemble their biological counterparts and that incorporate advances in NS offers two primary advantages. Firstly, NS can be a fertile source of inspiration for designing new models and enhancing existing ones. This holds true both in isolation and in tandem with the computational and mathematical advancements underpinning new models. Secondly, NS can offer validation for existing models and methodologies in the AI domain. An example of this is the residual connections found in pyramidal cells within the cerebral cortex. These connections enable input from layer I to reach cortical layer VI neurons, bypassing intermediary layers [16,40].\nCenter-Surround Receptive Fields. The Neocognitron model, proposed by Fukushima, holds a key position in the history of neural networks and machine learning, as one of the earliest examples of a CNN. Inspired by the pioneering work of Hubel and Wiesel on the visual cortex of cats [22], the Neocognitron model was designed to mimic the hierarchical structure of the visual system in mammals. It included a contrast-extracting preprocessing layer, reminiscent of the On-Off ganglion neurons, as well as inhibitory surround connections, mirroring the surround modulation observed in the visual cortex [10]. More recent studies have tried to incorporate center-surround receptive fields into CNNs by integrating convolutional layers equipped with fixed kernels into the input feature maps. Evidence indicates that this modification enhances the network's performance and resilience, particularly with respect to variations in lighting conditions and input noise [2, 15].\nInitialization Methods. Kernel initialization methods are crucial in training deep convolutional neural networks (CNNs) and have been the focus of significant research. The initialization of convolutional kernels directly impacts the convergence speed and the final performance of CNNs. Traditional initialization methods include Glorot and Bengio's uniform initialization [11], He et al.'s Kaiming initialization [17], and LeCun's Normal initialization. Mishkin and Matas introduced the LSUV initialization, optimized for deep architectures [33]. Hanin and Rolnick identified and addressed initialization failure modes in deep ReLU networks [12]. Arpit et al. proposed a robust initialization for weight normalized and ResNets, demonstrating enhanced generalization in deeper structures [1]. These methods usually generate weights from a Gaussian or uniform distribution with zero mean and a certain standard deviation. These initialization methods aim to maintain a reasonable activation variance across layers to avoid the issue of vanishing or exploding gradients.\nKaiming initialization, also known as He initialization [17], is a widely adopted technique for initializing weights in convolutional neural networks. Kaiming initialization addresses the vanishing/exploding gradients problem by initializing weights in a way that the variance of the outputs of each convolutional layer is approximately the same as the variance of its inputs. Specifically, the weights are initialized from a Gaussian distribution with a mean of zero and a standard deviation of $\\sqrt{2/n}$, where n is the number of inputs to the neuron. This technique has been shown to significantly improve the speed of convergence in deep neural networks and to stabilize the training process."}, {"title": "3. Methods", "content": "In the following section, we delve into the specifics of our proposed methodology. We begin by conducting a comprehensive analysis of the trained kernels of various state-of-the-art (SOTA) models on the ImageNet dataset. We provide detailed visual illustrations coupled with quantitative results, to validate the presence of the center-surround antagonism in a considerable portion of the kernels.\nNext, we move on to discuss the Difference of Gaussian (DoG) function. This function serves as a mathematical model of the center-surround receptive fields found in biological visual systems. This mathematical model provides us with a foundation for designing an initialization scheme that mimics these biological structures.\nFinally, we describe our novel kernel initialization approach, which leverages the DoG function. We detail the process of applying this function to generate kernel weights that resemble the center-surround antagonism of biological vision systems. The ultimate goal is to provide the model with a starting point that is already attuned to the kind of spatial feature mappings it would otherwise have to learn through many epochs of training."}, {"title": "3.1. Inspecting the Trained Kernels", "content": "In this section, we conduct a detailed exploration of the trained kernels of the regular and depthwise convolutions in different models. Specifically, we examine VGG16 [38], ResNet50 [18], DenseNet201 [21], MobilenetV3 [19], EfficientNet [39], ConvNext [32], ConvNeXtV2 [42], Hornet [35], and ConvMixer [41]. For our analysis, we utilized the pre-trained versions of these models, sourced directly from Pytorch or their respective official code repositories.\nIn order to visually inspect the learned patterns within these filters, we have included Figures 4 and 6 in our paper. Figure 4 provides a representative selection of randomly chosen samples from the trained kernels of each of the models utilizing depth-wise convolutions, and Figure 6 shows the same for models with regular convolutions. Upon inspection of these kernels, we can identify recurring patterns among the depthwise convolutions. We observed similar patterns in other variants of these models trained on ImageNet, too. However, kernels of regular convolutions do not show such observable patterns\nOne particularly notable pattern in depthwise kernels is the center-focused structure of many of them. Interestingly, these center-focused kernels can be broadly divided into two categories. The first category includes kernels with larger weight values concentrated in their center. Conversely, the second category consists of kernels with larger weight values populating their surround.\nThese discovered patterns bear striking resemblance to the well-studied \u2018center-surround antagonism' found in the mammalian visual system which we discussed previously. Nevertheless, it's worth noting that not all filters from our models exhibit this center-surround pattern. We observed other filters possessing different, non-center-surround patterns, but their occurrence was less frequent compared to the center-surround ones. This differential frequency points to the significance and prevalence of the center-surround pattern in the learned representations of depthwise kernels in these models.\nTo attain a more analytic comprehension of the varying kernel patterns, we leverage a straightforward clustering algorithm to group all the kernels. Our hypothesis suggests that the two center-surround groups are the most significant patterns, thus we set the number of clusters to three in the clustering algorithm. This choice is to discern whether the algorithm can effectively categorize the kernels into two distinct center-surround clusters, and a third cluster comprising the less common patterns.\nFor a successful execution of clustering, we took some preparatory steps. First, we normalized all kernels to have their weight values lie within the range of 0 and 1, utilizing min-max encoding. This step is essential to ensure the numerical stability and effectiveness of the clustering algorithm. Following normalization, we flattened each kernel into a vector, to fit the input requirement of the k-means algorithm. With the transformed data, we were finally able to run the k-means algorithm [13] with a k-value of 3.\nAfter clustering, we visually inspected the kernels belonging to each cluster, by presenting randomly selected samples in Figure 5. For each cluster, we also depict the average of all kernels belonging to it. This helps in better seeing the prominent pattern of each cluster. The first cluster predominantly contained kernels akin to the excitatory-center receptive fields, while the second cluster closely resembled inhibitory-center receptive fields. As for the third cluster, the kernels exhibited some degree of center-focused structures but lacked the precise characteristics of center-surround receptive fields. Examination of the average kernel within each cluster reveals a pronounced center-surround structure in the first two clusters, whereas the third cluster exhibits a more dispersed pattern. This observation further underscores that even an unbiased clustering approach distinctly recognizes the prominence of center-surround patterns relative to alternative patterns.\nFigures 7 and 8 show the discovered clusters of the models with 3 \u00d7 3 kernels with regular and depthwise convolutions, respectively. As one can see, the models with small depthwise kernels still have prominent center-surround clusters, in contrast to the ones with regular convolutions. Only in Resnet50, the average kernels of one cluster is similar to the center-surround pattern. However, once inspecting the kernels themselves, we can not distinguish the patterns (See Figure 6).\nThe distribution of the kernels across each cluster of ConvNeXt compared to ConvNeXtV2 variants is demonstrated by the histograms shown in Figure 9. The ConvNeXt model faced challenges with feature collapse, manifesting as redundant activations across channels. In response, the ConvNeXt V2 architecture introduces the Global Response Normalization (GRN) layer, promoting feature diversity. This enhancement, coupled with advanced self-supervised techniques, positions ConvNeXtV2 as a marked improvement over its predecessor in visual recognition tasks. We note a significant reduction in the number of kernels within the third cluster of the improved ConvNeXtV2 when contrasted with its predecessor, ConvNeXtV1. This is an interesting observation that underscores the pivotal role of center-surround in enhancing the model's performance.\nAs detailed in Figure 10, we observed a remarkable consistency in the proportions of filter clusters across various models, despite changes in model sizes, kernel sizes, and dataset sizes. This trend was evident in models such as ConvNeXt, ConvNeXtV2, and Hornet, where different model sizes were analyzed. For MobileNet and ConvMixer, we extended this analysis to include variations in kernel sizes. Additionally, the training of MobileNet on both ImageNet 1K and 21K datasets did not significantly alter the proportion of filter clusters. These findings suggest an inherent stability in the distribution of filter types within each model category, indicating that the architectural design of these models plays a more critical role in determining filter distribution than the scale of the model or the size of the dataset. This insight could have implications for understanding the scalability and adaptability of these models to different sizes and types of datasets."}, {"title": "3.2. Formulation of Center-Surround Kernels", "content": "The computation of center and surround weights can be accomplished using a difference of two Gaussian functions (DoG). Represented in Cartesian coordinates (CC), with the CC origin designated as the receptive field's center, the DoG can be formulated as presented in Rodieck's work [36]:\n$DoG(x, y) = K_1e^{-\\frac{x^2+y^2}{2\\sigma_1^2}} + K_2e^{-\\frac{x^2+y^2}{2\\sigma_2^2}}$\nwhere it holds true that $K_1$, $K_2$ and $\\sigma_2$, $\\sigma_1$ [3].\nWe use the DoG model proposed by Petkov and Kruizinga [28, 34], which defines the difference of Gaussians for the center and surround kernels. This model enables us to calculate the variances analytically, given the kernel size and the ratio of the center to surround [34]:\n$DoG_{\\sigma, \\gamma}(x, y) = A_ce^{-\\frac{x^2+y^2}{2 \\sigma^2}} + A_se^{-\\frac{x^2+y^2}{2(\\gamma \\sigma)^2}}$\nIn this formula, $\\gamma <1$ stipulates the ratio between the center radius r and the surround. The coefficients $A_c$ and $A_s$ are determined by requiring the sum of all positive values in Equation 2 to be equivalent to the negative values. These are then normalized such that their sum equals 0.5 and -0.5, respectively. While in the continuous infinite case, the coefficients $A_c$ and $A_s$ are equal, in the discrete finite case, the values of $A_c$ and $A_s$ remain remarkably similar.\nBy setting $DoG_{\\sigma, \\gamma}(x,y) = 0$, $\\sigma$ can be calculated immediately as shown in Equation 3 below, where k is the kernel size, for any arbitrary values of k and $\\gamma$:\n$\\sigma = \\sqrt{\\frac{k-1}{4-lny^2}}$\nIn Figure 2, we show the DoG functions used to model the center-surround receptive fields, with either excitatory or inhibitory centers, respectively."}, {"title": "3.3. Center-Surround Initialization", "content": "Observing the repetitive patterns exhibited in the depth-wise kernels trained on ImageNet, and noting their resemblance to center-surround receptive fields, we propose a novel methodology for kernel-weight initialization. Our hypothesis is based on the assumption that by offering the model kernels an initialization that aligns with patterns not only found in nature but also in fully-trained models, we can enhance the performance of these models. Additionally, this approach might streamline the convergence process during training. This method potentially serves as a bridge, linking biological vision models with their artificial counterparts, thereby enabling the latter to benefit from the intrinsic efficiency of the former.\nIn our approach, we begin by initializing the weights of the depth-wise convolution kernels in the model architectures with the weights derived from the previously discussed DoG function. This is a crucial step that enables us to effectively incorporate the center-surround receptive field structure into the model. To achieve a balanced representation of both inhibitory and excitatory centers, each kernel is assigned a center type \u2013 either inhibitory or excitatory \u2013 with an equal probability of 50%. This ensures that both types of centers are represented in approximately equal proportions across the kernels, thus maintaining a balanced interaction of these opposing neural behaviors in the model.\nAdditionally, we introduce variability in the ratio of the center to the surround for each kernel. To do this, we select the ratio from a uniform distribution. This introduces an element of randomness to the model, ensuring that a wide variety of center-to-surround ratios are represented in the kernels. Consequently, this design enables the model to accommodate and respond to a broad range of spatial scales in the input data and adds a wider variety of weight values to the initialization.\nFigure 3 shows the DoG kernels of size 9 with different ratios of the center to surround varying from 0.2 to 0.8. As the ratio increases, the center gets larger."}, {"title": "4. Experiments", "content": "Here, we detail our implementation, covering model selection and training. We then showcase results from testing our initialization on ConvNeXt, HorNet, and ConvMixer models using Cifar10 [26] and ImageNet [6]. Lastly, we provide an ablation study on our approach's facets."}, {"title": "4.1. Implementation Details", "content": "For the ImageNet evaluations, we employed ConvNeXt tiny, HorNet Tiny, and ConvMixer-512. ConvNext tiny and HorNet tiny contain 18 and 25 blocks respectively, each composed of one depthwise and two pointwise convolutions. The ConvMixer models incorporate 512 filters, within each depthwise convolutional layer and comprise mixer blocks composed of depthwise and pointwise convolutions. For each model, we used the training settings proposed in the original paper. Our training regimen included the use of a suite of data augmentation techniques, namely RandAugment [5], mixup [45], CutMix [43], and random erasing [46], in addition to gradient norm clipping. We employed the Adam optimizer [7] for the training process.\nAcross all experimental evaluations, we adhered to a balanced strategy for our kernel initialization, assigning half of the kernels with excitatory centers and the other half with inhibitory centers. Moreover, to determine the value of $\\gamma$, representing the ratio of center to surround, we utilized a uniform distribution inside [0,0.5]. This choice is motivated by our observations derived from the trained filters, which showed us that the centers are usually quite small."}, {"title": "4.2. Results", "content": "In the following, we describe our experimental results on ImageNet and Cifar10 datasets. We compare our results to the Kaiming initialization, which is the default initialization method used in most of the models.\nImageNet. In Table 1 we present the empirical results of our experiments on ImageNet. Across all configurations, our initialization consistently outperforms the Kaiming initialization, with improvements ranging from marginal to substantial. This was particularly evident in the improvement exceeding 2% for the ConvMixer-512 with kernel-size 9\u00d79.\nFirst, we present the performance metrics for the ConvNeXt tiny model, utilizing a 7 \u00d7 7 kernel size and trained over 50 epochs. Employing the conventional Kaiming initialization, the model achieved an accuracy of 76.17%. However, when initialized with our proposed method, the accuracy exhibited a slight enhancement, reaching 76.74%.\nThe subsequent row provides the results for the HorNet tiny model under analogous conditions: a kernel size of 7 \u00d7 7 and a training duration of 50 epochs. The performance with the Kaiming initialization stood at 76.06%. In contrast, our innovative initialization method yielded a superior result, registering an accuracy of 76.40%.\nFinally, we explored the effectiveness of our method with larger kernel sizes using the ConvMixer-512 model. Specifically, we employed a kernel size of 9 in the ConvMixer architecture. This approach resulted in a significant improvement, with an accuracy increase of 2.34%, thereby affirming even better efficacy of our method when applied to models with larger kernel configurations.\nCifar10. We evaluated our initialization on Cifar10 with models with kernel sizes of 5, 7, and 9. However, across different runs, we observed little to no improvements. This may be primarily attributed to the lack of discernible patterns in filters trained on Cifar10, in contrast to their ImageNet counterparts. This disparity is likely rooted in the significant size difference between the datasets, both in number of classes and image sizes. Clusters of kernels trained on Cifar10 are depicted in Figure 11."}, {"title": "4.3. Ablation Study", "content": "To assess our initialization's impact, we conducted an ablation study on the ConvMixer model, as this model exhibited the most significant improvement from our initialization method. The study, performed on the ImageNet dataset, is detailed in Table 2.\nOur baseline evaluation using Kaiming initialization achieved 64.00% accuracy. We applied our initialization, adjusting the DoG function parameters and the excitatory/inhibitory center arrangement. First, we sampled $\\gamma$ from a uniform distribution between (0,1) and used both On (excitatory) and Off (inhibitory) centers. This yielded an improved accuracy of 65.20%.\nNext, we narrowed the range of $\\gamma$ to (0,0.5), while only utilizing On centers. The resulting accuracy, though slightly lower at 64.78 percent, still exceeded the baseline Kaiming initialization. This suggests that the selection of $\\gamma$ and center types both play significant roles in the performance.\nFinally, maintaining $\\gamma$ in the (0,0.5) range, we reintroduced both On and Off centers into our model. This resulted in the highest observed accuracy of 66.34%. It is clear from this ablation study, that the selection of $\\gamma$ and the type of centers (On or Off) significantly influence the model performance."}, {"title": "5. Conclusions and Future Work", "content": "Conclusions. This paper has delved into an intriguing discovery of center-surround patterns in depthwise convolutional kernels, highlighting a fascinating interplay between artificial neural networks and natural vision systems. We capitalized on this finding by introducing a novel initialization strategy for depthwise kernels, incorporating the principles of the DoG method, typically utilized in bio-inspired vision models. This unique approach taps into the center-surround antagonism property of retinal ganglion cells, offering enhanced contrast sensitivity, mirroring the proficiency of biological vision systems.\nThe empirical evidence from our extensive experiments on ImageNet firmly backs the efficacy of our proposed method. Compared to the widely used Kaiming initialization, our technique demonstrated a notable improvement in the accuracy of the models. As illustrated in Figure 11, it is also interesting to observe that on the Cifar10 dataset, models do not seem to be able to learn biological kernels so effectively. In our opinion, this is a result of the small size of their images (32\u00d732 compared to 224x224 in ImageNet), and the very limited number of their classes (10 compared to 1000 in ImageNet).\nFuture Work. While the results obtained are promising, there's still scope for further exploration. A promising direction is to test our initialization method across a broader range of CNNs, potentially advancing a ubiquitous biology-inspired initialization approach.\nFurthermore, the primary aim of this paper was to highlight the resemblance between trained kernels and their biological counterparts. We have not yet embarked on any form of hyperparameter search to fine-tune the parameters of our initialization method. Parameters like the range for $\\gamma$, the proportion of excitatory and inhibitory kernels, initialization specific to each layer, and the balance of positive and negative values in the Difference of Gaussians function have been left unexplored. Potentially, these factors could be tweaked for optimal performance.\nFinally, this paper has not explored the patterns in the \"Others\" cluster of Figure 9. It is very likely that these patterns are linked to biological neural processing, too."}]}