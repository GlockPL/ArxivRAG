{"title": "Fuzzy Rule based Intelligent Cardiovascular Disease Prediction using Complex Event Processing", "authors": ["Shashi Shekhar Kumar", "Anurag Harsh", "Ritesh Chandra", "Sonali Agarwal"], "abstract": "Cardiovascular disease (CVDs) is a rapidly rising global concern due to unhealthy diets, lack of physical activity, and other factors. According to the World Health Organization (WHO), primary risk factors include elevated blood pressure, glucose, blood lipids, and obesity. Recent research has focused on accurate and timely disease prediction to reduce risk and fatalities, often relying on predictive models trained on large datasets, which require intensive training. An intelligent system for CVDs patients could greatly assist in making informed decisions by effectively analyzing health parameters. Complex Event Processing (CEP) has emerged as a valuable method for solving real-time challenges by aggregating patterns of interest and their causes and effects on end users. In this work, we propose a fuzzy rule-based system for monitoring clinical data to provide real-time decision support. We designed fuzzy rules based on clinical and WHO standards to ensure accurate predictions. Our integrated approach uses Apache Kafka and Spark for data streaming, and the Siddhi CEP engine for event processing. Additionally, we pass numerous cardiovascular disease-related parameters through CEP engines to ensure fast and reliable prediction decisions. To validate the effectiveness of our approach, we simulated real-time, unseen data to predict cardiovascular disease. Using synthetic data (1000 samples), we categorized it into \"Very Low Risk, Low Risk, Medium Risk, High Risk, and Very High Risk.\" Validation results showed that 20% of samples were categorized as very low risk, 15-45% as low risk, 35-65% as medium risk, 55-85% as high risk, and 75% as very high risk.", "sections": [{"title": "1 Introduction", "content": "Health is one of the most challenging issues for humans, necessitating immediate attention, precautionary measures, and expert consultation to mitigate the impact of any disease as well as reduce fatalities. CVDs is a major health issue that can be life-threatening if not treated properly within the timeline. However, adequate and timely measures of human parameters can reduce risk significantly.\nAccording to the WHO recent reports approximately 17.9 million people died from CVDs in 2019, representing 32% of all global deaths. Out of these casualties, 85% were due to heart attacks and strokes. In 2019, CVDs caused 38% of the 17 million premature deaths (under the age of 70) due to noncommunicable diseases.\nCVDs can be prevented by addressing behavioral risk factors such as usage of tobacco, unhealthy diet, obesity, physical inactivity, and the harmful use of alcohol. It is important to detect cardiovascular disease as early as possible so that precautionary measures can be provided to patients. Subsequently, the clinical data of human plays an important role in identifying the risk of CVDs.\nSimilarly, a report published by the ACC in the context of India suggests that the mortality rate from NCDs accounted for 65% of total deaths in India in 2019, of which more than 25% could be attributed to cardiovascular diseases and related risk factors, which is an alarming situation.\nAutomating the prediction of cardiovascular risk requires a lot of data to be analyzed and expert consultation is needed to timely diagnose the disease. On the contrary, delays in important parameter processing may increase risk further and may lead to serious health consequences [1]. Therefore it is essential to design such systems that work in real time with predefined set of rules to timely decision support for cardiovascular disease.\nIn developing such a framework, leveraging technological aspects becomes an important part, as it helps us make effective decisions for all. Exploring these tools to process large amounts of health parameters and detect a useful pattern, CEP [2] promises to be one of the most efficient methods for handling pattern-based events based on real-time data streams. Additionally, CEP[3] works with a predefined set of rules that are designed based on health parameters to aggregate and correlate to reach predictions.\nHowever, rule design is a challenging task as it requires domain knowledge as well as careful consideration of techniques for predicting cardiovascular risk from a data stream.\nBuilding on the proposed system, the following points outline the proposed work's main contribution.\nWe propose a real-time model approach for cardiovascular disease prediction using Apache Spark and Kafka, with various cardio parameters.\nWe develop a predefined set of rules using fuzzy logic and a certified standard parameters for cardiovascular disease monitoring and prediction through the Siddhi CEP engine.\nWe propose a structured alert system for cardiovascular disease for enhancing more accurate prediction.\nValidation of proposed method using synthetically generated data and how efficiently the disease can be diagnosed.\nAnalysis of event processing scenarios using time windows based intervals.\nA real-time dashboard for analyzing CVDs prediction and monitoring changing parameters.\nThe remaining section of the research work follows as:- Section II discusses the background analysis and related work. Section III presents the proposed system and its working"}, {"title": "2. Background analysis and related Work", "content": "In order to analyze the research gaps and how the proposed solution addresses them, it is important to discuss the existing work in the domain and its challenges before delving deeper into the sections."}, {"title": "2.1 Apache Spark and Kafka", "content": "Spark is one of the mostly used frameworks for simulating real time applications and supports a variety of workloads including batch processing, interactive queries, real-time streaming, and machine learning, all within a single framework. This eliminates the need for separate systems and simplifies development and maintenance. Its speed, ease of use, fault tolerance, and extensibility make it a popular choice for big data processing and analytics tasks. Spark can be directly integrated with Kafka for offset and processing data in real time[4][5].\nBoth Kafka and Spark support fault tolerance inherently by distributing data across multiple nodes and recovers in case of any failure.\nThe combination of Kafka and Spark Streaming is highly scalable. Kafka can handle large volumes of data by partitioning topics among multiple brokers in the cluster. Spark Streaming facilitates windowed computations, grouping data into intervals (e.g., every 10 seconds) and performing operations like aggregations on each window [6][7]."}, {"title": "2.2 Complex Event Processing", "content": "CEP is a method used for analyzing high volumes of data that processes and analyzes real-time event streams and triggers responses based on patterns in high-speed information systems. Applications that need to discover complex patterns across several event streams in milliseconds need this technology. Financial, telecommunications, health care, transportation, and security businesses use CEP to make real-time decisions [8]. In CEP, patterns in these streams indicate simple patterns, which include a single occurrence that fits requirements, while complex patterns have non-obvious links between several events. Systems can react instantly to new data as they process these events in real time or near real time. CEP systems define patterns using rules or queries. These rules allow extensive temporal logic and event linkages in specialized CEP languages [9][10]."}, {"title": "2.3 Fuzzy rules", "content": "Fuzzy logic systems use fuzzy rules as a key component to model approximate reasoning rather than fixed and exact reasoning. It is an extension of classical set theory; fuzzy logic introduces the concept of partial truth values between \"completely true\" and \"completely false.\"\nFuzzy rules provide flexible thinking and decision-making in complex systems with ambiguity and vagueness, where binary logic fails. Its help systems behave more like humans, handling complexities more intuitively and adaptably. Fuzzy logic allows for the representation of vague or subjective concepts by assigning membership degrees to different categories or conditions [11].\nIn the medical field, it is common to encounter knowledge gaps. often remains questionable and uncertain. Fuzzy logic is a variant of multi-valued logic that goes beyond binary values. The true/false paradigm involves assigning truth values to variables between 0 and 1. This methodology aims to tackle imprecision and uncertainty by providing a mathematical solution. The foundation of fuzzy logic lies in the idea that human decision-making often relies on imprecise and non-numeric data. Fuzzy models, or fuzzy sets, are mathematical tools for capturing information vagueness and imprecision."}, {"title": "2.4 Related work", "content": "Hsu et al. [12] proposed a methodology for cardiovascular disease-related event detection using recurrent neural networks. The research work was carried out using a 2-year observation and 5-year prediction window. The experimental result shows that the proposed model achieved an average precision of 0.425 and an AUROC of 0.805.\nRumsfeld et al. [13] explored the challenges related to cardiovascular disease in the context of big data applications and emphasized the role of big data in improving the prediction model's accuracy.\nRahmani et al. [14] proposed an event-driven model for intelligent healthcare monitoring using CEP. The model uses real-time healthcare data for monitoring and data analysis. Additionally, the model is cost-effective and reliable enough for real-time healthcare applications.\nTerrada et al. [22] proposed a fuzzy logic-based system designed to optimize patient diagnosis by integrating cardiovascular risk factors, organizing decision rules, and employing a fuzzification-defuzzification process to manage clinical data. The paper outlines the structure of this fuzzy cardiovascular diagnosis system and validates its performance using sensitivity and specificity measures, demonstrating the system's potential in improving diagnostic accuracy and minimizing errors.\nMa et al.[23] proposed a novel approach of prediction of coronary heart disease(CHD) for diabetic patients using an AI based model. They used statistics for the experiment to examine the distribution of four different types of features (basic demographic information, laboratory indicators, a medical exam, and a questionnaire) among comorbidities. Then, we tested how well three common machine learning methods could predict what would happen (extreme gradient boosting, random forest, and logistic regression)."}, {"title": "3. Materials and Methodologies", "content": "In this section, we introduce a layered model for intelligent cardiovascular disease prediction. The model integrates Apache Spark, Apache Kafka, and Siddhi framework, offering a comprehensive solution. We provide a detailed analysis of the proposed approach."}, {"title": "3.1 System Architecture of Fuzzy Rules based Intelligent Cardiovascular Disease Prediction", "content": "In IoT-based healthcare applications, rules are pivotal in identifying diseases based on early symptoms and recommending appropriate medical guidelines for treatment. However, managing such issues in real-time is complex due to changing parameters and the necessity of maintaining high standards for accurate disease prediction. Given this information, we propose an intelligent cardiovascular disease prediction system utilizing a fuzzy rule-based Complex Event Processing (CEP) approach. This system predicts diseases based on real-time healthcare parameters and designed rules. Figure 1 shows the architecture of the proposed system integrated with various frameworks.\nIn the proposed system, there are three components: Event producer, Event processing, and Event consumers. The Event producer serves as the initial stage of this architecture, responsible for collecting cardiovascular parameters from sources, repositories, or raw data obtained from health sensors.\nIn our case, data has been collected from the Kaggle repository, where it is available as open source. Event Processing is the second phase of this architecture, using frameworks such as Apache Spark for handling real-time data, Kafka for managing large numbers of events, and Siddhi CEP for analyzing and correlating cardiovascular parameters in real-time. Fuzzy logic aids in designing approximate reasoning rules based on these parameters. At its core is the concept of a membership function, which determines the extent to which an input value belongs to a specific set or category.\nFurthermore Siddhi CEP are used for correlating and analyzing the cardiovascular disease parameters from different sources based on fuzzy rules. The third component of the proposed architecture is an event consumer: a real-time dashboard developed to support the end user in better understanding and diagnosing CVDs."}, {"title": "3.2 Apache Spark and Kafka Integration", "content": "The integration of Kafka and Spark combines real-time data streaming and distributed processing. Kafka acts as a reliable data source, allowing Spark Streaming to consume data from Kafka topics. Spark processes the data using familiar APIs, and the results can be stored in various sinks. This powerful combination enables organizations to build robust, scalable, and real-time data pipelines for use cases like analytics and recommendations systems [16] [17] .\nFigure 2 illustrates the integrated approach of Kafka and Spark for stream processing."}, {"title": "3.3 Siddhi Architecture", "content": "Siddhi is an open-source, lightweight framework for real-time event processing. It handles large event volumes, extracting useful information from event streams. Commonly used for streaming analytics, rule-based decision-making, and adaptive systems, Siddhi supports query processing with user-defined rules. By correlating and analyzing events, it draws important conclusions that support decision-making for end-user applications[18]. In this work, the system takes cardiovascular parameters as input and predicts whether a patient has CVDs based on rules designed using medical standards and fuzzy logic. Figure 3 shows the working of Siddhi CEP engine with real time data streams."}, {"title": "3.4 Working of Fuzzy Terminology", "content": "The term \"fuzzy\" means ambiguity or lack of clarity. In the medical field, knowledge often remains uncertain. Fuzzy Logic, a variant of multi-valued logic, goes beyond the binary true/false paradigm by assigning truth values to variables as real numbers between 0 and 1. This methodology provides a mathematical framework for handling imprecision and uncertainty in decision-making processes, based on the premise that human decision-making often relies on imprecise and non-numeric data. Fuzzy models, or fuzzy sets, capture vagueness and imprecision in information[19][20][21].\nAt the core of Fuzzy Logic is the concept of a membership function, which determines the extent to which an input value belongs to a specific set or category. This function maps input values to membership degrees ranging from 0 to 1. Fuzzy Logic operates through Fuzzy Rules,"}, {"title": "3.4.1 Membership Function", "content": "The input variables mentioned above are represented using triangular membership functions. A triangular membership function is defined by three parameters: a, b, and c, such that (a < b < c). These parameters form the three vertices of the triangular membership function. The mathematical definition of the triangular membership function is shown below.\n$\\mu(x) = 0$, if x$\\leq$a\nx-a/b-a, if a $\\leq$x$\\leq$b\nc-x/c-b, if b $\\leq$x$\\leq$c\n0 if x $\\geq$ c\n(1)\nA membership function in fuzzy logic defines how each point in the input space is mapped to a degree of membership between 0 and 1. It determines the extent to which an input value belongs to a specific fuzzy set or category. Fuzzification converts crisp input values into fuzzy values using membership functions. For example, if the age is 45, then the fuzzification"}, {"title": "3.4.2 JFuzzy Logic", "content": "The fuzzy logic in our research has been implemented using a Java library named JFuzzy Logic It provides a framework for creating fuzzy logic systems and performing operations such as fuzzification, rule evaluation, and defuzzification. In JFuzzyLogic, FCL files are used to define fuzzy logic systems in a human-readable and easily understandable format. These files typically contain declarations of linguistic variables, membership functions, fuzzy rules, and other parameters necessary for fuzzy inference [29]. Figure 6 shows a sample of our FCL file where we have defined our membership functions and rule block."}, {"title": "3.5 Algorithm for rule development", "content": "Input : Blood Pressure, Weight, Glucose, Age, Systolic, Diastolic, Smoking, Gender, Alcohol intake\nOutput : Rule development for CEP based CVDs prediction.\nStep 1: Collect and preprocess data.\nStep 2 : Take parameters and construct if then rules using medical guidelines.\nStep 3: Modeling with the conventional fuzzy logic method.\nStep 4: Apply approximate reasoning to fuzzify each attribute.\nStep 5: Calculate membership functions to determine attribute values.\nStep 6: Apply the fuzzy rules on CEP engine for CVDs prediction."}, {"title": "3.5.1 Standard Guidelines for CVDS", "content": "The rule base is a crucial component of our system. It maps input or computed truth values to desired output truth values using predefined rules. These rules are derived from cardiovascular disease symptoms and clinical guidelines from authorized organizations. The"}, {"title": "3.5.2 Rule Designed using Clinical Guidelines.", "content": "Based on medical guidelines and fuzzy logic, we designed around 30 rules for filtering CVD parameters. Table 4 shows some of these rules for CEP-based cardiovascular disease prediction."}, {"title": "Experiment Details and Results", "content": "This section presents the experiment details and results obtained by rigorously filtering important parameters from the real-time data stream. To perform the experiment, we used a PC with 16.0 GB of RAM, a 64-bit OS, an x64 processor, Windows 10 Pro Edition, and version 21H2."}, {"title": "4.1 Dataset Description", "content": "We used an open-source cardiovascular disease dataset from the Kaggle repository, containing 70,000 samples and 11 cardio parameters. These include age, height, weight, gender, systolic blood pressure, diastolic blood pressure, cholesterol, glucose, smoking status, alcohol intake, physical activity, and the presence or absence of cardiovascular disease as the target value. The dataset contains no missing or null values, so data preprocessing is not required."}, {"title": "4.2 Time Window based Execution Analysis", "content": "Window interval-based event analysis was performed using a 5-second interval to analyze real-time event processing. Figure 7 demonstrates the model's efficient processing of cardiovascular parameters within small windows. As the window length increases, the number of events also increases, aiding in efficient disease diagnosis based on conditional rules. We have considered five rules at a time for processing cardio-based events."}, {"title": "4.3 Rule Deployment Time for CEP Engine", "content": "In this section we consider deploying CEP rules to CEP engines to determine how efficiently rules are being processed by a stream of events[31][32]. In this scenario we have considered different counts of rules. Figure 8 shows the time it takes to deploy a rule based on the number of events processed [33]. Additionally, the execution time increases with the number of rules and events, reaching up to 25 seconds at maximum load."}, {"title": "4.4 Average Number of Event Detection for Time Window Length", "content": "The average event detection window length significantly impacts accuracy. Shorter windows enhance sensitivity to rapid changes but may introduce noise. This analysis aims to detect changes in CVDs parameters and take prompt action based on specified rules. Figure 9 shows that the number of events increases with longer time windows."}, {"title": "4.5 Validation of Proposed Approach", "content": "To validate our approach, we used synthetic data to test the efficiency of our CEP-based model in predicting CVDs. We generated 1000 samples using Python's Numpy library, applying parameters to validate the model on unseen data. The model predicts the presence or absence of CVDs and, if present, the disease's severity using designed rules.\nFigure 10 shows that less than 20% of samples were categorized as very low risk, 15-45% as low risk, 35-65% as medium risk, 55-85% as high risk, and 75% as very high risk. This correct categorization demonstrates the effectiveness of the designed rules and model. Table 6 illustrates the categorization of the synthetic data into different levels of CVDs."}, {"title": "Conclusion and Future work", "content": "In this paper, we propose a fuzzy rule-based intelligent CVDs prediction model using CEP. Our real-time approach offers scalable and accurate predictions by employing rule-based parameters to simulate the model effectively. We integrated Apache Kafka and Apache Spark to handle large volumes of cardio parameter-based events in real-time scenarios. Additionally, we used a CEP engine to analyze these events, developing rules with fuzzy logic and standard medical guidelines for CVDs prediction. By processing a large number of events within specific time windows, we identified useful patterns and efficiently monitored input parameter fluctuations for accurate decision support.\nWe validated our model using synthetic data (1000 samples), categorizing each attribute into \"Very Low Risk, Low Risk, Medium Risk, High Risk, and Very High Risk.\" The validation results showed that 20% of samples were categorized as very low risk, 15\u201345% as low risk, 35-65% as medium risk, 55\u201385% as high risk, and 75% as very high risk.\nFor future studies, we aim to enhance our research by extending it to a distributed CEP environment for fault tolerance and efficient event timestamping in CVD prediction. We also plan to optimize fuzzy logic, include more medical parameters, and integrate Semantic Web technology to improve data interoperability and enable advanced semantic reasoning for more accurate predictions, while enhancing the correlation capabilities of the CEP system."}]}