{"title": "A Hybrid Quantum-Classical AI-Based Detection Strategy for Generative Adversarial\nNetwork-Based Deepfake Attacks on an Autonomous Vehicle Traffic Sign Classification\nSystem", "authors": ["M Sabbir Salek", "Shaozhi Li", "Mashrur Chowdhury"], "abstract": "The perception module in autonomous vehicles (AVs) relies heavily on deep learning-based models to\ndetect and identify various objects in their surrounding environment. An AV traffic sign classification\nsystem is integral to this module, which helps AVs recognize roadway traffic signs. However, adversarial\nattacks, in which an attacker modifies or alters the image captured for traffic sign recognition, could lead\nan AV to misrecognize the traffic signs and cause hazardous consequences. Deepfake presents itself as a\npromising technology to be used for such adversarial attacks, in which a deepfake traffic sign would\nreplace a real-world traffic sign image before the image is fed to the AV traffic sign classification system.\nIn this study, the authors present how a generative adversarial network-based deepfake attack can be\ncrafted to fool the AV traffic sign classification systems. The authors developed a deepfake traffic sign\nimage detection strategy leveraging hybrid quantum-classical neural networks (NNs). This hybrid\napproach utilizes amplitude encoding to represent the features of an input traffic sign image using\nquantum states, which substantially reduces the memory requirement compared to its classical\ncounterparts. The authors evaluated this hybrid deepfake detection approach along with several baseline\nclassical convolutional NNs on real-world and deepfake traffic sign images. The results indicate that the\nhybrid quantum-classical NNs for deepfake detection could achieve similar or higher performance than\nthe baseline classical convolutional NNs in most cases while requiring less than one-third of the memory\nrequired by the shallowest classical convolutional NN considered in this study.", "sections": [{"title": "INTRODUCTION", "content": "With worldwide leading industries, like Tesla, Waymo, General Motors, and Baidu, focusing\nheavily on autonomous vehicle (AV) development, the opportunity of riding a vehicle without ever\nneeding to drive it is getting more realistic. An AV depends on its perception module to perceive the\nsurrounding environment, to recognize different types of objects, such as other vehicles, pedestrians, and\nroad users, and to realize roadway regulations enforced by traffic signals and signs (1). This perception\nmodule leverages different onboard sensors like camera, radio detection and ranging (radar), and light\ndetection and ranging (lidar) to collect data from its surrounding environment. These data are processed\nand analyzed in the perception module to extract relevant information for autonomous driving.\nRecognizing traffic signs, either regulatory or warning, posted on the roadway is crucial for\ndriving safely through roadways. Failure to detect and identify these signs could lead to hazardous\nconsequences, especially for AVs. An AV's perception module includes object detection and\nclassification systems, such as a traffic sign recognition system, to carry out this task. However, recent\nstudies have indicated that such systems could be attacked by tampering with the captured images or the\nclassification models, causing the perception system to misrecognize the traffic signs (2). These attacks\nare commonly known as adversarial attacks and have been widely studied in recent years, where\nresearchers have introduced various adversarial attack models and their corresponding detection,\nmitigation, and resilient strategies.\nWith the recent advent of deep learning, producing realistic fake images and videos has become\ncommon. Deep learning-based techniques for manipulating existing images/videos are known as deepfake\n(3, 4). Anyone with a computer or a smartphone can manipulate or create realistic fake images or videos\nnowadays and cause the spread of misinformation. Although, to the authors' best knowledge, no existing\nstudies have considered a deepfake technique as a means to perform an adversarial attack on the AV\nperception module, it is quite feasible to conduct such attacks.\nIn this study, the authors explored how a deepfake technique can be utilized to perform an\nadversarial attack on an AV traffic sign classification system, leading the system to misrecognize any\ntraffic sign images. The authors used a generative adversarial network (GAN) based approach to perform\nthe deepfake attacks in this study. The deepfake attack was performed on real-world traffic sign images\nfrom two benchmark datasets. Furthermore, the authors introduced an amplitude encoding-based hybrid\nquantum-classical neural network (NN) supported strategy to detect the deepfake attack-generated fake\ntraffic sign images. Several classical deep learning models, ranging from a shallow two-layer\nconvolutional NN (CNN) to a six-layer deep CNN, were employed to serve as baseline models to\ncompare with the deepfake detection performance achieved by the hybrid quantum-classical NN-based\nstrategy. Our results indicated that the hybrid strategy could achieve a detection performance comparable\nto that of the classical strategy. However, due to quantum phenomena such as quantum superposition and\nentanglement and the adoption of amplitude encoding for transforming image data into representative\nquantum states, the memory requirement for the hybrid quantum-classical NN models was found to be\nmuch lower than the classical CNN models.\nThe contributions of this study are as follows: (i) the development of a GAN-based deepfake\nattack model to perform adversarial attacks on an AV traffic sign classification system, and (ii) the\ndevelopment of a hybrid quantum-classical NN-based deepfake detection strategy that can achieve similar\ndetection performance to classical CNN models with substantially lower memory requirement. The rest of\nthe paper is organized as follows: the second section summarizes some of the recent noteworthy studies\nconducted for deepfake detection; the third section presents the deepfake attack model and the detection\nstrategy developed in this study; the fourth section presents the dataset and the evaluation metrics used to\nevaluate the performance of the deepfake detection strategy introduced here, followed by the evaluation\nresults and related discussions; and finally the last section highlights the conclusions of this study."}, {"title": "LITERATURE REVIEW", "content": "In this section, the authors present a brief overview of the recent advances in deepfake detection\ntechnology. The existing research on deepfake technology primarily focuses on human images or videos."}, {"title": "DEEPFAKE ATTACK AND DETECTION METHOD", "content": "In this section, the authors introduce the deepfake attack model, which aims to fool an AV traffic\nsign recognition system and cause it to misrecognize the traffic signs it comes across on the roadway.\nNext, the authors present a deepfake detection strategy, including a classical CNN-based detection\nstrategy used as the baseline and a hybrid quantum-classical NN-based deepfake detection strategy with\nreduced memory requirements."}, {"title": "Deepfake Attack Model", "content": "An AV traffic sign recognition system receives roadway images captured by the onboard camera(s),\ndetects and then classifies the traffic signs in them to help the AV perceive its driving environment,\ncomply with roadway regulations, take actions based on warnings, and navigate safely through its desired\nroute. Similar to any other adversarial attacks, the authors assume that an attacker resides between the\nonboard camera-captured traffic sign image and the AV's traffic sign classification system and is capable\nof manupulating the image data as the attacker wishes (as shown in Figure 1). Upon receiving a traffic\nsign image, the attacker leverages a deepfake attack module to instantly generate a fake traffic sign image\nthat is different from the input traffic sign type and replaces the real image with the fake one.\nAs depicted in Figure 1, the deepfake module contains a pretrained generator that generates a\nfake traffic sign image for an input image x (i.e., a real traffic sign image). This is done by optimizing the\ninput latent vector z, which is the only input to the generator. The optimal input latent vector z* for\ngenerating the fake image that would replace the real one is obtained by solving the optimization problem\npresented in Equation 1 using a gradient descent-based iterative approach,\n$z^* = \\arg \\max_z ||G(z) - x||$\nwhere, G(z) presents the generated image for the input latent vector z. The optimization ensures that the\nfake image G(z*) that will replace the real one least resembles the input image x; therefore, it is most\nlikely that the fake image G(z*) would be of a different type of traffic sign from the input image x.\nBecause of the non-convex nature of the objective function in Equation 1 and to ensure that the attack is\nfeasible in real-time, the authors assume that the attacker utilizes a fixed number of random initializations\nof z.\nThe generator model is obtained through training a GAN model using the Wasserstein GAN with\ngradient penalty (WGAN-GP) approach introduced by Gulrajani et al. (20). Like any other GAN models,\nWGAN-GP includes a generator (to produce fake images) and a discriminator (to tell apart the generator-\nproduced fake images from the real ones) that are trained in tandem using a min-max loss function given\nby Equation 2 below.\n$\\min_D \\min_G \\max_{V_w} (D, G) = E_{x~P_r(x)} [log D(x)] \u2013 E_{z~P_f(z)} [log (D(G(z)))] + E_{x~P}[||\u2207D(x)||^2 - 1]^2$\nwhere, x and z are the input image and the input latent vector, respectively; G(\u00b7) and D(\u00b7) represent the\ngenerator and the discriminator, respectively; E(\u00b7) represents the expected value; Pr(\u00b7) and Pf (\u00b7) represent\nthe distributions of real and generated (fake) images, respectively; A is a constant, which is set to 10 (20);\nV is a differential operator with respect to \u00ee; and \u00e2 is sampled from x and G(x) using Equation 3 given\nbelow.\n$\\hat{x} = tG(x) + (1 - t)x$\nwhere, t is uniformly sampled between 0 and 1, i.e., 0 \u2264 t \u2264 1.\nThe neural network architectures used for the generator and the discriminator are based on the\ndeep convolutional GAN (DCGAN) (21) and WGAN (20), as shown in Figures 2 and 3, respectively. In\nFigures 2 and 3, each layer's output dimension is shown as C \u00d7 H \u00d7 W, where C, H, and W represent the\nnumber of feature maps, and the height and the width of each feature map, respectively."}, {"title": "Deepfake Detection Strategy", "content": "In this subsection, the authors present the deepfake detection strategy developed in this study. This\nstrategy employs two NNs, as shown in Figure 4. The first NN, a CNN (i.e., a traffic sign classifier), is\nresponsible for recognizing the traffic sign type of an input traffic sign image. The authors utilize a\nResNet9 (22) based architecture (as shown in Figure 5) to develop the traffic sign classifier. After the\ntraffic sign type is determined by the traffic sign classifier, the second NN (i.e., a deepfake detection\nmodel) determines whether the image is a real image or a fake image. The deepfake detection model is a\ntraffic sign type-specific model, i.e., this strategy requires a pretrained deepfake detection model for each\ntype of traffic sign. For developing the traffic sign type-specific deepfake detection models, the authors\ntake two approaches: (i) classical CNN-based deepfake detection and (ii) quantum-classical NN-based\ndeepfake detection; the following subsections present these approaches in detail."}, {"title": "Classical CNN-based Deepfake Detection", "content": "The authors consider five different classical CNN models to have a set of baseline classical deepfake\ndetection models. These models vary from a shallow two-layer CNN model to a deeper six-layer CNN\nmodel as follows: (i) Classical CNN-1 (includes one convolutional layer and one fully connected layer),\n(ii) Classical CNN-2 (includes two convolutional layers and one fully connected layer), (iii) Classical\nCNN-3 (includes three convolutional layers and one fully connected layer), (iv) Classical CNN-4\n(includes four convolutional layers and one fully connected layer), and (v) Classical CNN-1 (includes five\nconvolutional layers and one fully connected layer). Figure 6 presents the architectures for the first three\nclassical CNNs used in this study as examples. The remaining two classical CNNs, i.e., classical CNN-4\nand CNN-5, also follow the same architectures with one and two additional convolutional layers,\nrespectively. Note that the shape boxes in Figure 6 are not drawn to scale.\nAs observed from Figure 6, each convolutional layer in the classical CNNs includes a\nconvolutional step (denoted as Conv2D) with a 3 \u00d7 3 kernel and padding (padding size: 1) applied,\nfollowed by a batch normalization step (denoted as BatchNorm2D), a rectified linear unit-based activation\nstep (denoted as ReLU), and a max pooling step (denoted as MaxPool2D). For each of the classical\nCNNs, the output feature map from the last convolutional layer is flattened, and a 20% dropout of the\nneurons is applied as a regularization to reduce overfitting issues (23) before feeding the feature map to\nthe fully connected layer. The final output of the classical CNNs maps to two labels: real image (labeled\nas 0) and fake image (labeled as 1). The authors implemented the classical CNNs using the open-source\nPyTorch library (24) in Python."}, {"title": "Hybrid Quantum-Classical NN-based Deepfake Detection", "content": "The authors leverage a hybrid quantum-classical NN to detect fake images for each of the traffic sign\ntypes. The hybrid NN includes quantum NNs and two fully connected layers, as shown in Figure 7(a).\nThe authors utilized 32 quantum circuits to generate 32 neurons in the first hidden layer, which is\nconnected to the second hidden layer with 120 neurons. The activation function between the first and the\nsecond hidden layers is set as Tanh.\nWe transform the data of an input traffic sign image to a quantum state using amplitude encoding.\nTherefore, the initial quantum state is set as,\n$|\\psi_\u03bf) = \\frac{\\sum_i x_i}{|x|} |b_i)$\nwhere, xi denotes the color intensity at the i-th site in the image and b\u2081 is the basis, denoting the binary\nrepresentation of the number i. For a 3 \u00d7 32 \u00d7 32 image with 3,072 pixels, 12 qubits are used (it has 212\nbasis) to represent it. Compared to the frequently used angle-encoding method (25), amplitude encoding\ncan take advantage of the large Hilbert space and the powerful storage capability of quantum computers.\nAs shown in Figure 7(b), each quantum NN consists of one rotational layer, three quantum convolutional\nlayers, and three quantum pooling layers. The rotational layer is made of single qubit rotation operators\nRy(01) and R2(02). The two-gate operators in the quantum convolutional layer (denoted as U(p)) and\nthe quantum pooling layer (denoted as P(\u03c6)) are presented in Figures 7(c) and 7(d), respectively. The\noutput of the quantum circuit is the average value of 0 = <|\u039612|4), where |4) is the final quantum state\nand Z12 denotes the z-component of the Pauli matrix on the 12-th qubit.\nThe authors used the Adam optimizer to optimize parameters in the hybrid quantum-classical NN.\nIn principle, the gradient of O with respect to the rotation angle can be exactly evaluated using the\nparameter shift rule, which needs to simulate a quantum circuit three times. To reduce the computational\ncost, we evaluate this gradient using the finite difference method. The authors used the open-source"}, {"title": "EVALUATION", "content": "This section explains the evaluation approach considered in this study. First, the authors present\nthe details of the traffic sign dataset and the deepfake dataset used here. Second, the authors introduce the\nevaluation metrics considered for evaluating the performance of our classical and hybrid quantum-\nclassical deepfake detection models."}, {"title": "Dataset", "content": "The deepfake detection strategy presented in this study requires adversarial training. Therefore, the\ndataset used to train the deepfake detection models must have both real traffic sign images (captured\nduring driving in the real world) and fake traffic sign images (generated by the deepfake attack model\nintroduced in this study). In this section, the authors present the details of the dataset considered in this\nstudy."}, {"title": "Real-World Traffic Sign Image Dataset", "content": "Since the deepfake attack model developed in this study relies on a GAN-based framework, which\nrequires a lot of training data to produce realistic fake images, the authors reviewed the existing datasets\ncontaining US traffic sign images. Considering the unavailability of a single dataset containing enough\nimages for each of the US traffic sign types, the authors decided to combine data from two prominent\ntraffic sign image datasets, i.e., the LISA traffic sign dataset (27) and the Mapillary traffic sign dataset\n(28).\nThe LISA dataset comprises 49 US traffic signs types with 7,855 image annotations. These traffic\nsign images were extracted from video frames recorded by dashboard cameras of multiple vehicles\ntraveling around San Diego, California. On the other hand, the Mapillary dataset comprises 313 types of\nworldwide traffic signs (out of which the authors only considered the US traffic sign images) and includes\na total number of 82,724 traffic sign images. After combining the two datasets, the authors selected the\nten types of traffic signs with the maximum number of available images and manually cleaned the dataset\nto ensure the final dataset of real traffic sign images only includes those recognizable by humans."}, {"title": "Deepfake Traffic Sign Image Dataset", "content": "The real traffic sign image dataset was used to train a GAN model to generate realistic fake images. After\nthe GAN is trained, the authors used the images from the real traffic sign image dataset as inputs to the\ngenerator model to generate random fake traffic sign images based on the deepfake attack model\npresented in the earlier section. Even though the GAN model was adequately trained to generate realistic\nfake images, it still produces a few ambiguous images that do not fall under any particular type of traffic\nsign. This is due to the fixed number of iterations used in the deepfake attack model to generate a fake\ntraffic sign image in real time that most closely resembles a traffic sign type other than the type of the\ninput traffic sign image. These unrecognizable fake images were manually removed from the pool of\ndeepfake attack-generated images to obtain the final dataset of fake traffic sign images.\nThe real and the fake images from each of the traffic sign types were then combined by randomly\nundersampling the majority class between the real and the fake images. This ensured that for each type of\ntraffic sign, the numbers of real and fake images were balanced (i.e., 50% real images and 50% fake\nimages) in the dataset. The total number of images for each traffic sign type is as follows: STOP (154\nimages), SIGNAL AHEAD (250 images), PED XING (194 images), SPEED LIMIT 25 (192 images),\nSPEED LIMIT 30 (190 images), SPEED LIMIT 35 (250 images), SPEED LIMIT 45 (200 images),\nSPEED LIMIT 55 (146 images), and STOP AHEAD (202 images). Figure 8 presents a few examples of\nthe real and fake images of each traffic sign type. Images from each traffic sign type were then randomly"}, {"title": "Evaluation Metrics", "content": "Both two CNNs of the deepfake detection strategy introduced here, as previously shown in Figure 1, are\ntasked with classification problems. Therefore, the authors selected the four most popular evaluation\nmetrics for deep learning-based classification problems: (i) precision, (ii) recall, (iii) F1 score, and (iv)\naccuracy to evaluate the performance of the CNN models. Table 1 presents how these metrics were\ncalculated and what they represent."}, {"title": "Evaluation Results and Discussions", "content": "In this section, the authors present the evaluation results of the deepfake detection strategy\nintroduced in this study. As shown in Figure 1, the first CNN identifies the type of traffic sign present in\nan input image. The ResNet9-based traffic sign classifier, used as the first CNN in this study, achieved an\noverall precision, recall, F1 score, and accuracy of 0.97, 0.97, 0.97, and 0.97, respectively, on the\ncombined dataset of real and fake images of all traffic sign types. After the traffic sign type is identified,\nthe respective deepfake detection CNN model is invoked by the deepfake detection system to determine\nwhether the image is a real image or a fake image.\nFigures 9(a) through 9(d) present a comparison among the baseline classical CNN-based\ndeepfake detection models and the hybrid quantum-classical NN-based deepfake detection model in terms\nof precision, recall, F1 score, and accuracy, respectively. As observed in Figure 9, from the classical\nCNN-1 through CNN-5, the detection performance improved gradually for all the traffic sign types with a\nfew exceptions. This is expected as the additional convolutional layers help improve prediction\nperformance by extracting relevant features. The hybrid quantum-classical NN model outperformed, or at\nleast provided, similar performance to the classical CNN-1 through CNN-5 in most cases, including a few\nexceptions, such as for the PED XING and the SPEED LIMIT 45 signs.\nHowever, the advantage of the hybrid quantum-classical NN model over the classical CNN\nmodels becomes apparent when their memory requirements are compared. Table 2 presents the total\nnumber of parameters (based on Equation 5) and the required memory size in MB (estimated using\nEquation 6) for all these deepfake detection models. The hybrid quantum-classical NN model used in\nthis study requires only 5,425 parameters or 0.021 MB of memory, which is less than one-third of the\nparameters or memory needed for the shallowest baseline classical model used in this study, i.e., classical\nCNN-1. Except for the PED XING and the SPEED LIMIT 45 signs, the hybrid deepfake detection\napproach outperformed the classical approach for classical CNN-1 through 3 (as observed in Figure 9)\neven though the required number of parameters for the hybrid approach is substantially less than these\nthree classical CNN models."}, {"title": "CONCLUSIONS", "content": "AVs rely on their onboard computers for a wide range of tasks, such as perception, localization,\nmapping, path planning, and motion control (1), that require large storage and processing capacity.\nTherefore, reducing the memory requirement for different autonomous driving-related tasks is crucial. In\naddition, the rapid expansion of attack surfaces due to the increased connectivity and automation warrants\nAVs to incorporate various cyberattack detection, mitigation, and resilient strategies posing an additional\nhurdle to the already existing challenge of memory allocation for AV onboard computers. Keeping this in\nmind, the authors developed a hybrid quantum-classical NN-based strategy for deepfake detection in this\nstudy.\nAlthough deepfake-related security concerns have been explored extensively by researchers in\nrecent years, their applicability to the transportation domain has not received any attention. This study\nintroduced how this security threat affects our transportation systems by crafting a deepfake-based\nadversarial attack model aimed at fooling an AV perception module with fake traffic sign images. The\nhybrid quantum-classical NN-based deepfake detection strategy developed in this study could help detect\nsuch attacks effectively and efficiently without causing excessive load on the AV onboard computers.\nThis strategy, evaluated on a real-world traffic sign image dataset combined with a deepfake traffic sign\nimage dataset, obtained comparable deepfake detection performance to that of the baseline classical\nCNNs with a substantially low memory requirement for the model parameters.\nA limitation of this study is that the authors could not develop deepfake detection models for all\nthe US traffic sign types due to the limited availability of good-quality traffic sign images. In the future,\nthe authors aim to expand the deepfake detection strategy introduced in this study to include all US traffic\nsign types."}]}