{"title": "AutoSearch: Unlocking the Reasoning Potential of Large Models for Web-based Source Search", "authors": ["Zhengqiu Zhu", "Yatai Ji", "Jiaheng Huang", "Yong Zhao", "Sihang Qiu", "Rusheng Ju"], "abstract": "Web-based management systems have been widely used in risk control and industrial safety. However, effectively integrating source search capabilities into these systems, to enable decision-makers to locate and address the hazard (e.g., gas leak detection) remains a challenge. While prior efforts have explored using web crowdsourcing and AI algorithms for source search decision support, these approaches suffer from overheads in recruiting human participants and slow response times in time-sensitive situations. To address this, we introduce AutoS\u00b2earch, a novel framework leveraging large models for zero-shot source search in web applications. AutoSearch operates on a simplified visual environment projected through a web-based display, utilizing a chain-of-thought prompt designed to emulate human reasoning. The multi-modal large language model (MLLMs) dynamically converts visual observations into language descriptions, enabling the LLM to perform linguistic reasoning on four directional choices. Extensive experiments demonstrate that AutoSearch achieves performance nearly equivalent to human-AI collaborative source search while eliminating dependency on crowdsourced labor. Our work offers valuable insights in using web engineering to design such autonomous systems in other industrial applications.", "sections": [{"title": "1 Introduction", "content": "In today's rapidly evolving digital landscape, the transformative power of web technologies has redefined not only how services are delivered but also how complex tasks are approached. Web-based systems have become increasingly prevalent in risk control across various domains. This widespread adoption is due their accessibility, scalability, and ability to remotely connect various types of users. For example, these systems are used for process safety management in industry [14], safety risk early warning in urban construction [6], and safe monitoring of infrastructural systems [20]. Within these web-based risk management systems, the source search problem presents a huge challenge. Source search refers"}, {"title": "2 Background and Motivation", "content": "In this section, we review related works across three key areas and then outline the motivation behind this study."}, {"title": "2.1 Web Crowdsourcing and Human-AI Collaboration Empowerment", "content": "With the advancement of web technologies, crowdsourcing activities have increasingly migrated to web and mobile internet platforms, namely web crowdsourcing [7]. An exponential rise in its applications has witnessed, such as ride-hailing and software development. To tackle complex web-based tasks, scientists at Microsoft introduced human-AI interaction guidelines to assist researchers and practitioners in designing studies utilizing AI technologies [2]. Following this, numerous studies have integrated human intelligence with AI methods to address challenges such as conversational agent learning for intent detection and text classification [24,3]. A recent study, for example, engaged online users from crowdsourcing platforms and implemented advanced computer vision techniques to generate city maps [19]. Given the growing significance of AI-in-the-loop systems in human-intervened tasks, the concept and principles of human-AI decision-making within the context of web crowdsourcing were provided [8]."}, {"title": "2.2 Source Search and Crowd-powered Practices", "content": "Source search is a critical problem for both nature and mankind [13] focusing on determining the location of a source (of gas or signal) in the shortest possible time. Existing source search approaches can generally be classified into three categories: information-theoretic [10], biologically-inspired [1], and gradient-based methods [12]. Among these, information-theoretic algorithms, especially those grounded in the Bayesian framework [17], stand out for their distinct advantages. To further enhance the performance (i.e., success rate and efficiency) of a searching algorithm, multi-robot collaboration mechanisms [22] have been designed and adopted. However, when source search takes place in complex environments, the search process always encounters fatal problems, resulting in wrong outcomes. Thus, researchers started to explore effective ways leveraging human intelligence to improve AI-based search algorithms through web platforms [26]. However, this approach also entails substantial costs and imposes considerable burdens on human workers."}, {"title": "2.3 Large Models for Scene Understanding and Reasoning", "content": "MLLMs integrate multimodal encoders/decoders with traditional LLMs, enabling cross-modal understanding that overcomes text-only limitations. While these models demonstrate remarkable capabilities across diverse tasks including image-text understanding [16], video-text understanding [15], and even multi-modal generation [18], their effectiveness in handling complex tasks remains constrained by predominant single-step reasoning approaches. To this end, CoT prompts are utilized to enhance problem-solving abilities by guiding LLMs through structured multi-step reasoning. Recent work explores CoT adaptations for multimodal problems, for instance, Shikra [5] pioneers CoT application in visual grounding tasks, while SoM [23] introduces structural image annotations like segmentation maps and spatial grids to provide spatial reasoning anchors. However, CoT has not been comprehensively explored for fine-grain reasoning in source search tasks."}, {"title": "2.4 Motivation", "content": "Building on the demonstrated scene understanding and reasoning capabilities of large models across various tasks, as well as addressing the limitations of human-AI collaborative source search, our work seeks to explore concrete methods for leveraging large models in zero-shot source search tasks within a top-down view of web-based search environments."}, {"title": "3 System Design", "content": "To answer RQ1, we designed the AutoSearch framework based on web platforms. This involved migrating our previously developed crowd-powered source search prototype system [27] from a desktop application to a web platform. The primary goals of this implementation were to achieve cross-platform accessibility, real-time interaction, and dynamic visualization.\n(1) Back-End Implementation: we selected the lightweight and scalable Flask framework, and initialized the application using Flask and Socket.IO. The functions are handled by defining routes and Socket.IO events.\n(2) Real-Time Communication: Socket.IO was used to support WebSocket and polling to ensure low-latency communication. Data is sent to the front-end using 'socketio.emit', and on the front-end, events sent by the backend are received using 'socket.on'.\n(3) Map Drawing and Updating: we first determined the map drawing logic (initializing the map and updating it based on changes), and then converted the map data into a format recognizable by the front-end.\n(4) Front-End Rendering: we utilized HTML5's Canvas an ideal choice for dynamic map displays to achieve efficient graphic rendering. We defined the Canvas element and implemented the drawing logic using JavaScript. To facilitate user interaction, we added control buttons on the interface and bound"}, {"title": "4 Method", "content": "Previous studies have demonstrated the feasibility and effectiveness of human-AI collaborative source search in addressing fatal problems encountered in search problems (e.g., local optimum, dead end, infinite loop) [27,28]. However, this approach comes with significant costs and imposes considerable burdens on human workers. Therefore, to answer RQ2, we elaborate on the design of a large models-assisted source search method and explain how could it achieve human-like scene understanding and multi-step reasoning."}, {"title": "4.1 Method Overview", "content": "In this section, we show the design of AutoS\u00b2earch, and introduce how MLLM and LLM can be used during the search process to improve the effectiveness and efficiency of search algorithms. There are various ways to achieve this goal in search. Here, we designed a straightforward workflow where the MLLM dynamically interprets visual data from a web-based display interface, converting it into detailed language descriptions for the LLM's CoT reasoning. Notably, no changes are made inside the search algorithm. The overview of the method is shown in as Fig. 2. Similar to the workflow of human-AI collaborative search (Fig. 2(a)), AutoSearch follows three main steps: initialization, execution, and end. The main distinction lies in the execution phase, where AutoSearch incorporates four core components: machine-driven problem detection, machine-generated prompt explanations, problem description by the MLLM, and reasoning and acting by the LLM. Except for the problem detection mechanism, the subsequent steps are totally different with those in our previous work [28]. In this work, we leverage human rationale to carefully design prompts, eliminating the need for human intervention after the method is initiated, as the problem-solving process is entirely handled by large models. Our approach helps reduce labor costs and accelerates problem-solving response time."}, {"title": "4.2 The Workflow Design of AutoSearch", "content": "The prototype system was designed following the method outlined in Fig. 2(b), employing Infotaxis as the source searching algorithm. Infotaxis is one of the most popular cognitive search strategies, known for its effectiveness in solving source searching problems [21].\n(1) Problem Detection and Task Generation. Through discussions with experts on the question, \"what fatal problems could be happened during the search process\", we have already identified common problems found in source search"}, {"title": "5 Experiments", "content": "In this section, we introduce experimental setup, baseline algorithms, and evaluation metrics. The project code can be found here\u00b9."}, {"title": "5.1 Experimental Setup", "content": "The source search activities are performed by a virtual robot within a simulated 2D environment measuring 20m \u00d7 20m. The search area is divided into a 20 \u00d7 20 grid of cells. Each cell has a probability $P_o$ of containing an obstacle, with $P_o$ set to 0.75 to introduce a relatively high difficulty (more obstacles). This higher complexity is chosen because simpler environments (with fewer obstacles) do not require external assistance. In this study, we did not consider the specific types or shapes of obstacles. If a cell contains an obstacle, it is considered completely obstructed, meaning the robot cannot enter or traverse it."}, {"title": "5.2 Baseline Algorithms", "content": "As detailed in the published work [28] on human-collaborative source search, the baselines adopted in this study naturally follow from that setup. Baseline 1 employs the Infotaxis algorithm directly, while Baseline 2 incorporates our proposed automatic problem detection method, navigating the robot to a random location to escape problematic scenarios. For consistency, we adopt an aided control interaction model of human-AI collaboration in this comparative analysis. Furthermore, we introduce Baseline 3, where the robot navigates to a randomly chosen direction from four possible options (mentioned in Section 4.2) upon detecting a problem. It is worth noting that both Baseline 2 and Baseline 3 represent state-of-the-art improvements over traditional source search algorithms."}, {"title": "5.3 Evaluation Metrics", "content": "In this study, we evaluate the effectiveness and efficiency of the source search process and its outcomes. Effectiveness is measured by the success rate, defined as the robot successfully locating the source within 400 steps (where a step represents one iteration of updating search states). If the robot fails to find the source within 400 steps, regardless of whether large models are involved, the task is considered unsuccessful. Efficiency is assessed by the number of steps the robot takes to find the source, with failed attempts excluded from the calculation. Additionally, we measure the execution time of large models per task to see whether they hold an advantage over human workers in time-sensitive tasks."}, {"title": "6 Results", "content": "In this section, we present the results of (1) an illustrative run, (2) the comparison study, and (3) the ablation study."}, {"title": "6.1 Illustrative Run", "content": "We conducted an experiment using one scenario from a set of 20 benchmark scenarios to illustrate a successful search process. The illustrative run of AutoS\u00b2earch is shown in Fig. 4. The process includes the initiation of the search, the progression of the algorithm-driven search, the involvement of large models when a problem is detected, and ultimately resolving the issue to successfully locate the source. As we can see in Fig. 4(c), large models (both GPT-402) are activated at search step=151. Based on the current visual inputs and the provided prompt for MLLMs, the language description of this scene is presented as follows."}, {"title": "6.2 Comparative Study", "content": "In this subsection, we evaluated the effectiveness of large models-assisted source search over 20 benchmark scenarios (each scenario was run ten times) by measuring the effectiveness (success rate), the efficiency (the number of steps taken to find the source), the execution time of large models. The experimental results, averaged over Monte Carlo simulations across 20 scenarios, are presented in Table 1. Clearly, large models-assisted source search has proved to be effective, achieving a success rate of 97% in most cases. This represents an improvement of approximately 18.5% over Baseline 1, 9% over Baseline 2, and 7% over Baseline 3, while being only 3% lower than the success rate of human-AI collaborative search. Note that Baseline 2 and 3 are improvements based on the original algorithm (Baseline 1) since automatic problem detection and rule-based problem-solving strategies are used. Furthermore, we observe that the efficiency of AutoSearch (in terms of steps taken) is comparable to that of human-AI collaborative search, while the average execution time of large models is even shorter. For details on how human workers complete the crowdsourcing task, interested readers can refer to the previous work [27]."}, {"title": "6.3 Ablation Study", "content": "We further ablation studies to validate the importance of main elements designed in our framework: the Chain-of-Thought prompt for the LLM and the size of directional choices A, B, C, and D (which determine the number of candidate cells for each option). We designated the model without CoT reasoning as Our-A and the model with reduced block sizes as Our-B. The average results across 20 scenarios are presented in Table 3. As we can see, both the removal of CoT reasoning and the reduction in block sizes significantly decrease the success rate by approximately 6% and 7%, respectively. Notably, while removing CoT reasoning compromises the effectiveness performance, it does lead to improved efficiency and shorter execution time due to fewer reasoning steps."}, {"title": "7 Discussions", "content": "The source search results convey three main messages: (1) By incorporating carefully designed prompts that enable large language models with scene comprehension and multi-step reasoning capabilities, autonomous source search capabilities can be integrated into web-based systems to support decision-making in time-sensitive scenarios. (2) The large models-assisted method is effective and efficient for improving source search, approaching the performance of human-AI collaborative approaches while reducing execution time by approximately 25%. (3) Whether in scene element presentation, problem detection mechanisms, or CoT prompt design, each component reflects human intelligence, highlighting that complex task solving fundamentally relies on human-AI hybrid intelligence.\nDrawbacks. Despite the strengths, this work has several limitations. (1) Environmental Complexity Gap: The simplified 20 \u00d7 20 grid with static obstacles fail to capture real-world dynamics (e.g., moving obstructions, multi-source scenarios). The visual environment used here is insufficient to test whether large models truly possess robust scene understanding and multi-step reasoning capabilities in complex settings. (2) Limited Task Understanding: While simple scene elements were designed to help the large model understand tasks, the lack of domain-specific knowledge makes it difficult for the model to balance exploration and exploitation during the search, sometimes leading to hallucinations by selecting irrelevant areas. (3) Underutilization of MLLM Potential: In this work, MLLMS were mainly used to convert visual observations into textual descriptions, with large language models handling subsequent reasoning. This separation of visual understanding and language reasoning may limit the integrated capabilities MLLMs are designed to offer.\nPotential Avenues. To address these limitations, we propose to explore: (1) Dynamic Environment Adaptation: Design LLM-empowered search agent and develop online prompt tuning mechanisms where LLMs could adjust decision rules according to the environment variations. (2) Visual Thinking Augmentation: Integrate graph-based scene representations and reflection mechanisms to help MLLMs directly reason on the visual inputs without hallucinations. (3) Human-AI Value Alignment: Implement human-in-the-loop feedback mechanisms in complex and high-risk scenarios and ensure alignment of decision objectives between humans and AI.\nImplications. The implications of AutoS\u00b2earch extend far beyond the technical achievements in web-based autonomous systems. Its design reflects a broader trend in human-AI collaborative systems, where the goal is to harness the cognitive strengths of both entities in tandem. Moreover, it may redefine the role of humans in web crowdsourcing systems from task executors to validators of AI rationality in the future."}, {"title": "8 Conclusions", "content": "In this work, we present AutoSearch to address the issue of human dependency in web-based crowdsourcing systems for source search tasks. Through AutoSearch, we demonstrate that large models can effectively improve the performance of human-designed search algorithms in complex environments through visual-language translation and CoT reasoning. Our experimental validation shows AutoS\u00b2earch achieves 95-98% of human-AI collaborative source search algorithm effectiveness while eliminating labor costs and response time. This implies that modern large models can sufficiently replicate human scene reasoning for critical tasks like source search in complex environments. As global industries increasingly lean on such systems for effective management, our work establishes a solid foundation for web engineering in other industrial applications."}]}