{"title": "Revolutionizing Personalized Cancer Vaccines with NEO: Novel Epitope Optimization Using an Aggregated Feed Forward and Recurrent Neural Network with LSTM Architecture", "authors": ["Nishanth Basava"], "abstract": "As cancer cases continue to rise, with a 2023 study from Zhejiang and Harvard predicting a 31% increase in cases and a 21% increase in deaths by 2030, the need to find more effective treatments for cancer is greater than ever before. Traditional approaches to treating cancer, such as chemotherapy, often kill healthy cells because of their lack of targetability. On the contrary, personalized cancer vaccines can utilize neoepitopes - distinctive peptides on cancer cells that are often missed by the body's immune system - that have strong binding affinities to a patient's MHC to provide a more targeted treatment approach. The selection of the perfect neoepitopes that elicit an immune response is a time-consuming and costly process because of the required inputs of modern predictive methods. This project aims to facilitate faster, cheaper, and more accurate neoepitope binding predictions with the use of Feed Forward Neural Networks and Recurrent Neural Networks.\nThus, NEO was created. NEO requires next-generation sequencing data and utilizes the stacking ensemble method by calculating scores from state-of-the-art models (MHCFlurry1.6, NetMHCstabpan-1.0, and IEDB.) The model's architecture includes an FFNN and an RNN with LSTM layers with memory to analyze both sequential and non-sequential data. Both model's results are aggregated to produce predictions. Using this model, personalized cancer vaccines can be produced with improved results (0.9166 AUC, recall = 91.67%,).", "sections": [{"title": "1 Introduction", "content": "Cancer-the notorious, pathogenic disease that is estimated to have killed almost 10 million people and caused an estimated 19.3 million new cancer cases in 2020\u2014remains a significant global health challenge [20]. Even with improved treatment options, these values had a 26.3% and 20.9% increase from 2010 to 2019 respectively [15]. In the past, the lack of efficient sequencing techniques has limited the ability to develop personalized techniques that are tailored to a patient's tumor genome. More recently, however, with technological innovations making next-generation sequencing cheaper and more accessible, more direct patient specificity may be possible [13]. By performing next-generation sequencing on a patient's normal and tumor genome, tumor-specific antigens, commonly known as neoantigens, can be identified [3]. The issue with developing neoantigen vaccines is the difficulty in predicting whether the neoantigens would bind to the MHC-I and MHC-II of the antigen-presenting cells (APCs) and be recognized by the immune system. In vitro testing of neoantigen presentation in the immune system would be time-consuming as scientists would have to test the thousands of neoantigens present in the patient's tumor for binding to the patient's HLA. Through the usage of computational models, these predictions can be automated with a cheaper, less time-consuming, and more accurate methodology.\nOver time, newer machine learning models, such as neural networks, have been developed with increased predictive power by being able to recognize patterns and optimize parameters to achieve more accurate results [14]. Within the field of neural networks, there exist different types, each of which is able to handle different data types best and learn the patterns of the training data differently. For example, feed-forward neural networks (FFNNs) typically train best on non-sequential data whereas the more novel Long-Short Term Memory (LSTM)"}, {"title": "2 Background", "content": "Cancer is caused by a build of somatic mutations throughout the body cells that affect various cellular processes [1]. A key change has to do with the identity of the body's cells. On the surface of most human cells are peptides\u2014 sequences of amino acids \u2013called epitopes. Epitopes are a part of antigens, which are substances that trigger immune responses, that can be recognized by the immune system's b-cells or t-cells as either self or non-self. If the immune cells recognize the epitope as self, central immune tolerance causes the cell to not attack itself [15]. However, if the immune cells find an epitope that it does not recognize as self, otherwise known as a neoepitope (the part of a neoantigen that binds to the MHC), then the immune system will try to get rid of the cell with the neoepitope [15]. The key to recognizing the neoepitope lies in the binding of the neoepitope to the surface of the Major Histocompatibility Complex (MHC) molecules on the antigen-presenting cell (APC). In humans, the MHC is known as the human leukocyte antigen (HLA). The APCs then mature the cytotoxic T-cells, causing a cascade of tumor killing, or immunosurveillance, that results in the release of more neoepitopes and increased binding through a positive feedback mechanism [15]."}, {"title": "2.1 Neoepitopes", "content": "Cancer is caused by a build of somatic mutations throughout the body cells that affect various cellular processes [1]. A key change has to do with the identity of the body's cells. On the surface of most human cells are peptides\u2014 sequences of amino acids \u2013called epitopes. Epitopes are a part of antigens, which are substances that trigger immune responses, that can be recognized by the immune system's b-cells or t-cells as either self or non-self. If the immune cells recognize the epitope as self, central immune tolerance causes the cell to not attack itself [15]. However, if the immune cells find an epitope that it does not recognize as self, otherwise known as a neoepitope (the part of a neoantigen that binds to the MHC), then the immune system will try to get rid of the cell with the neoepitope [15]. The key to recognizing the neoepitope lies in the binding of the neoepitope to the surface of the Major Histocompatibility Complex (MHC) molecules on the antigen-presenting cell (APC). In humans, the MHC is known as the human leukocyte antigen (HLA). The APCs then mature the cytotoxic T-cells, causing a cascade of tumor killing, or immunosurveillance, that results in the release of more neoepitopes and increased binding through a positive feedback mechanism [15]."}, {"title": "2.2 Proposed Method of Treatment", "content": "As mentioned earlier, traditional approaches lack targetability, so why aren't oncologists using personalized cancer vaccines? The reason lies in the inefficiency of current methodologies of personalized cancer vaccine development. After next-generation sequencing and epitope identification, computational models can be utilized to determine which of those neoepitopes are effective at eliciting an immune response. Sequencing techniques such as high throughput detection have been developed, making acquiring genomic data cheaper, faster, and easier than ever before [2]. In fact, the recent SARS-CoV-2 vaccines were able to be developed so quickly largely due to this innovation [2]. Additionally, In vitro testing of each epitope is a very time-consuming process, and through the utilization of modern machine learning and deep learning techniques such as neural networks, these lengthy assays can be bypassed."}, {"title": "2.3 Current Models", "content": "State-of-the-art models for predicting neoepitope-MHC binding are very large (NetMHCPan-4.0 has 40 Feed Forward Neural Networks, each with 60-70 hidden layers) and require high computational power and time. They are also not commonly used in treatment due to their low relative accuracy on new testing data (NetMHCpan 4.0 - 90%, HLAthena - 85%, MHCFlurry - 81%) [13,16,17].\nThe majority of these models implement a feed-forward neural network architecture because of their proven ability to be better predictors in classification and regression problems than earlier models such as logistic regression or random forest [11]. Feed-Forward Neural Networks are often able to achieve strong predictive results when trained on non-sequential data [14]. Recurrent Neural Networks are a novel neural network framework and are able to capture and utilize memory in order the make more accurate predictions on sequential data. Since the sequence of the peptides is sequence data, it was hypothesized that a recurrent neural network architecture could be useful in making the neoepitope-MHC binding predictions.\nOnly two models currently exist that use RNNs in their architecture [12, 10]. Though their models had high predictive power, they may not be useful for the development of personalized cancer vaccines because of their lack of generalization between various HLA classes and binding peptide types. For this reason, NEO (Novel Epitope Optimization) was created."}, {"title": "3 Materials and Methods", "content": null}, {"title": "3.1 NCI Dataset", "content": "The data used in this project was sourced from a clinical trial approved by the institutional review board of the National Cancer Institute [7]. The 70 individuals chosen for the clinical trial had at least one tumor where whole-exome and whole-transcriptome sequencing was performed with at least one HLA class I-restricted epitope. The dataset had 2,433,281 unique epitopes consisting mainly of mutant residue and the 12 amino acids upstream and downstream of the mutation (resulting in sequences of 25 amino acids in length) [7]. The individual neoepitopes of base pair lengths of 8-12 amino acids from the tumors of the patients were also in the dataset. A subset of the 25 peptide sequences was screened and evaluated for immunoreactivity by co-culturing autologous antigen-presenting cells expressing both the 25 and 8-12 peptide sequences [7]. Since the epitope status was listed as either 0.0 or 1.0 (based on whether the epitope had bound to the MHC complex or not), the machine learning model would have to be created for binary classification. Binary classification involves a model that predicts which class, out of two classes, a sample best fits into based on the input features."}, {"title": "3.2 Model Architecture", "content": null}, {"title": "3.2.1 Feed Forward Neural Network", "content": "NEO's architecture was a two-branched, ensemble model with two neural networks. A feed-forward neural network was utilized to learn from patterns from the non-sequential data such as mutation present in RNA sequence, gene expression, and HLA type."}, {"title": "3.2.2 Recurrent Neural Network", "content": "An additional RNN model with an LSTM architecture was created and trained on wild-type and mutant peptide sequences in addition to the previous features. Through temporal segmentation, the sequences were broken up into individual amino acids so that they could be used as sequential data. The LSTM architecture was utilized to account for the memory aspect of the sequential peptide sequences [22]. The recurrent neural network had an input layer with all 35 features (the peptide sequences + the non-sequential features + HLA type), 2 Long-Short Term Memory (LSTM) layers with 32 neurons each, and an output layer with one neuron. The output of the model was again inputted into a sigmoid function and a threshold of 0.5 was used for the binary classification. Once again, an output of 1.0 represented binding and 0.0 represented no binding. Both models had a learning rate of 0.001.\nTo discuss how an RNN is able to utilize memory to learn from the sequential data, the structure of the LSTM layers must be analyzed. In an LSTM, the cell state (C) is what moves the information along. The module can add or remove information from the cell state, as regulated by the gates. In a standard LSTM, there are three gates. The first gate (f\u2081), is the forget gate. This gate determines how much of the previous data the neuron wants to forget. The input gate (i) records how much of the new input the neuron wants to replace the old information. The final gate is the output gate (o), which is where the actual adding and removing of information occurs. In this way of regulating how much to remember from previous inputs, the LSTM is able to retain sequential information and make informed predictions on new inputs.\nThe optimizer used was a combination of Adam (Adaptive Moment Estimation) and SGD (Stochastic Gradient Descent) [19]. A batch size of 100 was used to train the model due to the large dataset size. The loss function utilized was Binary Cross Entropy."}, {"title": "3.3 SMOTE", "content": "A big challenge with building an accurate machine learning model for this data set was the data imbalance. This dataset has only 139 positive samples but over 2 million negative samples for binding. For this reason, the original training data set was unable to provide the model with sufficient information to effectively predict the neoepitope-MHC binding.\nTo make up for the lack of positive samples in the dataset, the SMOTE technique was used. SMOTE, or Synthetic Minority Over-sampling Technique, is a technique used when there is a class imbalance problem with the training dataset of a machine learning model. The goal of SMOTE is to balance the class distribution so that the model is better able to learn the patterns of the minority class. SMOTE works by first identifying the minority class. Then, it randomly picks a sample from the minority class and identifies the k-nearest neighbors of the selected instance. Once the neighbors are identified, SMOTE creates synthetic samples by interpolating between the selected sample and its neighbors, a process that includes creating a random instance on the line segment between the two neighbors. The process is repeated until the desired balance between the two classes is achieved."}, {"title": "3.4 Model Aggregation", "content": "The aggregation technique for merging the results of the two models together was an ensemble with fixed weights (results were averaged together and the threshold of 0.5 was used to determine which classification the ensemble model would choose)."}, {"title": "4 Results", "content": null}, {"title": "4.1 Training Features", "content": "The features to be used were determined by running Layer-wise Relevance Propagation (LRP). LRP is a model-agnostic feature importance test that calculates the importance of each feature on the output of a layer. The outputs chosen were those of the FFNN between layer 1 and layer 2."}, {"title": "4.2 Testing Results", "content": "The final models were trained on ~480,000 samples after synthesizing positive samples with SMOTE. The FFNN was trained for 100 epochs and the RNN was trained for 5 epochs before aggregating the results. The model achieved a loss of 0.0017, an accuracy of 99.98%, a sensitivity of 0.833, a specificity of 0.9999, a precision of 76.92, an F1 score of 0.8, and an AUC score of 0.9166."}, {"title": "4.3 Performance Benchmarking", "content": "Through brief comparative metric analysis of the AUC scores (the ability of each model to correctly distinguish between positive and negative samples), NEO outperformed every state-of-the-art model."}, {"title": "5 Discussions and Conclusion", "content": "Overall, NEO can revolutionize personalized vaccine production by accurately predicting which neoepitopes should be used in the vaccines. NEO provides hope for the usage of Recurrent Neural Networks when developing predictive models with peptide sequence data, especially in cancer biology. NEO, unlike many state-of-the-art models, doesn't require specific data about the orientation of the neoepitopes. Using NEO, oncologists don't need to wait for days or even hours to get results from a computational model and vaccines can be developed with higher efficiency and efficacy.\nTo further this research, more relevant features could be extracted from the sequencing data and trained on, such as mutational signatures. Moreover, a larger dataset with more patient"}]}