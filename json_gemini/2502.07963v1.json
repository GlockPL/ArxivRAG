{"title": "Caught in the Web of Words:\nDo LLMs Fall for Spin in Medical Literature?", "authors": ["Hye Sun Yun", "Karen Y.C. Zhang", "Ramez Kouzy", "Iain J. Marshall", "Junyi Jessy Li", "Byron C. Wallace"], "abstract": "Medical research faces well-documented chal-\nlenges in translating novel treatments into clin-\nical practice. Publishing incentives encourage\nresearchers to present \"positive\" findings, even\nwhen empirical results are equivocal. Conse-\nquently, it is well-documented that authors of-\nten spin study results, especially in article ab-\nstracts. Such spin can influence clinician in-\nterpretation of evidence and may affect patient\ncare decisions. In this study, we ask whether the\ninterpretation of trial results offered by Large\nLanguage Models (LLMs) is similarly affected\nby spin. This is important since LLMs are in-\ncreasingly being used to trawl through and syn-\nthesize published medical evidence. We evalu-\nated 22 LLMs and found that they are across\nthe board more susceptible to spin than hu-\nmans. They might also propagate spin into\ntheir outputs: We find evidence, e.g., that\nLLMs implicitly incorporate spin into plain lan-\nguage summaries that they generate. We also\nfind, however, that LLMs are generally capable\nof recognizing spin, and can be prompted in a\nway to mitigate spin's impact on LLM outputs.", "sections": [{"title": "1. Introduction", "content": "Randomized controlled trials (RCTs) form the cor-\nnerstone of evidence-based medicine. Healthcare\nproviders often base clinical decisions on trial find-\nings, mostly as presented in article abstracts (Chris-\ntakis et al., 2000; Hopewell et al., 2008; Berwanger\net al., 2009; Marcelo et al., 2013). Unlike full texts,\nabstracts are concise and easily accessible, unlike full"}, {"title": "2. Experimental Setup", "content": "To empirically evaluate LLM susceptibility to spin in\nmedical abstracts, we ran three experiments measur-\ning how different LLM outputs are when given ab-\nstracts with and without spin. We base these analy-\nses on data manually collected in prior work on spin\nin oncology and its influence on medical experts such\nas clinicians and principal investigators in cancer re-\nsearch (Boutron et al. 2014; Section 2.1).\nIn the first experiment, we measured whether\nLLMs can spot spin in medical abstracts. The other\ntwo experiments examined downstream effects of any\nsusceptibility to spin: First, we assessed whether\nLLMs \"interpret\" results differently when the under-\nlying abstract has been spun, and then we measured\nif any such bias is propagated to automatically sim-\nplified abstracts."}, {"title": "2.1. Data", "content": "In all of our experiments we used a small, man-\nually curated dataset from Boutron et al. (2014).\nThis comprises 60 abstracts (both real and synthetic)\npaired to compare results reported with and without\nspin. The 30 source abstracts are from cancer-related\nRCTs that met two criteria: (1) reported statistically\nnonsignificant results for all primary outcomes of the\nstudied intervention, and (2) contained language in\ntheir results and conclusion sections that overstated\nthe benefit of the intervention. All of the underlying\ntrials comprised two arms (intervention and control)\nand included at least 100 patients.\nResearchers in this prior work (Boutron et al.,\n2014) manually edited each of these abstracts to re-\nmove spin, yielding 30 \"neutral\" matched abstracts.\nThis process controlled for length: \"neutralized\" ver-\nsions were constrained to be within 25 words of the\noriginal (spun) versions. Author names, references,\njournal names, registration numbers, trial names or\nacronyms, and article titles were removed from both\nversions of the abstracts. Further, treatment descrip-\ntions were systematically masked with generic terms\n(e.g., treatment A and comparator B) to avoid any\npre-existing bias individuals may have based on treat-\nment names."}, {"title": "2.2. Evaluation", "content": "Spin detection Using the abstracts from Boutron\net al. (2014), we prompted LLMs to answer whether\nor not a given abstract contains spin. This is a binary\nclassification problem with a balanced distribution,\nso we use accuracy as a metric. The exact prompt\nwe used is available in Appendix B.1.\nInterpretation of trial results for spun and un-\nspun abstracts For each abstract, we prompted\nLLMs to answer the following 5 questions individu-\nally on a scale of 0-10:"}, {"title": "2.3. Models", "content": "We include in our analysis a variety of LLMs (22\nin all), including both open and closed (proprietary)\nmodels. We also include both general and specialized\n(biomedical) LLMs, and models spanning a range of\nparameter counts.\n\u2022\n\u2022\n\u2022\nGeneralist closed-source/proprietary: An-\nthropic's Claude 3.5 Haiku and Sonnet, Google's\nGemini 1.5 Flash and Flash 8B (Team et al.,\n2024), OpenAI's GPT 3.5 175B (OpenAI, 2025),\nGPT40 (Hurst et al., 2024), GPT40 Mini (Ope-\nnAI, 2024).\nGeneralist open-weight: Llama2 7B, 13B,\nand 70B Chat (Touvron et al., 2023); Llama3\n8B and 70B Instruct (Meta, 2024); Mistral 7B\nInstruct v0.1 (Jiang et al., 2023); OLM02 7B and\n13B Instruct (OLMo et al., 2024).\nBiomedical open-weight: Alpacare 7B\n(Zhang et al., 2023), BioMedGPT 7B (Luo et al.,"}, {"title": "3. Results", "content": "Detecting spin in abstracts Figure 2 reports\nthe accuracies of all LLMs on the spin detection\ntask. The average accuracy across all models is 0.67.\nClaude 3.5 Sonnet achieved the highest accuracy\nscore (0.97), followed by GPT40 Mini (0.85). LLMs\nwith accuracy scores close to 0.50 predicted just one\nlabel (spin or no spin) for all abstracts. The mean ac-\ncuracy of generalist closed-source/proprietary LLMs\nwas 0.75. Generalist open-weight LLMs had an av-\nerage accuracy of 0.64, while specialist biomedical\nopen-weight LLMs were comparable (0.63). Over-\nall, these results indicate that LLMs are in general\nmoderately to strongly capable of detecting spin.\nInterpretation of (spun) trial results Does spin\nchange LLM interpretation of the reported results?\nThe mean differences of the 5 interpretation ques-\ntions asked to the LLMs are available in Figure 3.\nDifferences across all interpretation measures from\nLLMs were generally (much) higher than those ob-\nserved for human experts. This suggests that LLMs\nerroneously infer larger differences in results between\\spun and unspun abstracts than do human experts."}, {"title": "LLM k output score = Bok+\nB1k (presence or absence of spin)", "content": "Where Bok is an intercept (for LLM k), and \u1e9e1k is a\ncoefficient for LLM k."}, {"title": "4. Reducing the Effect of Spin", "content": "Our findings demonstrate that LLMs are susceptible\nto spin in medical articles when used without safe-\nguards. To address this vulnerability, we evaluated\nstrategies that might reduce LLMs' tendency to over-\nstate favorable trial results.\nWe used two approaches to spin mitigation. The\nfirst approach incorporated explicit spin labels into"}, {"title": "5. Related Work", "content": "Spin in medical literature Classification and\nprevalence of spin in medical literature has been stud-\nied extensively. In this literature, spin is commonly\ndefined in one or more of the following ways: (1) Dis-"}, {"title": "Appendix A. LLM Details & Compute", "content": "We used a total of 4 x NVIDIA A100 GPUs to con-\nduct our experiments.\nGeneralist\nclosed-source/proprietary: We\nused API interfaces provided by OpenAI, An-\nthropic, and Google to interact with their pro-\nprietary language models. For OpenAI mod-\nels, we used GPT-40 (gpt-40-2024-08-06),\nGPT-40-mini (gpt-40-mini), and GPT-3.5\n(gpt-3.5-turbo-0125).\nFor Anthropic's\nClaude models, we tested Claude 3.5 Haiku\n(claude-3-5-haiku-20241022) and Claude 3.5\nSonnet (claude-3-5-sonnet-20241022).\nFor\nGoogle's Gemini models, we used Gemini 1.5 Flash\n(gemini-1.5-flash) and Gemini 1.5 Flash 8B\n(gemini-1.5-flash-8b).\nAcross all models and\nexperiments, we set the temperature parameter to 0\nto ensure deterministic outputs.\nGeneralist open-weight: All the generalist open-\nweight models were downloaded from Hugging Face's\nModel Hub4. We set the parameter for do_sample\nas false for all experiments to ensure deterministic\noutputs.\nBiomedical open-weight: Similar to the general-\nist open-weight models, the biomedical models were\nalso downloaded via HuggingFace. The parameter for\ndo_sample was also set to false for all experiments."}, {"title": "Appendix B. Zero-Shot Prompts", "content": "B.1. Detection of Spin\nWe provide the exact prompt used in our study for\ndetecting spin below to ensure reproducibility. The\nprompt was designed to elicit a binary answer of a\ngiven abstract.\nSpin or misrepresentation of study\nfindings can be used to influence,\npositively, the interpretation of\nstatistically nonsignificant randomized\ncontrolled trials (RCTs), for example,\nby emphasizing the apparent benefit of\na secondary outcome or findings from a\nsubgroup of patients.\nDoes the following clinical trial abstract\ncontain spin (yes/no)?\nAnswer only with 'yes' or 'no'. Do not\nprovide any explanations.\nAbstract:\n{ABSTRACT}\nB.2. Interpretation of Trial Results\nBelow, we provide the exact prompt used to guide the\nLLM in interpreting the results of a given abstract.\nThis abstract describes a study evaluating\na treatment in the field of cancer\npublished in a peer-reviewed journal.\nWe appreciate that in clinical practice\nyou would need to read the full article to\nmake a final decision. However, the full\narticle is not always freely available and\npeople sometimes make decisions based on\nthe abstract.\nBased on the information reported in the\nabstract, please answer the following\nquestion about the treatment. Only output\na score between 0-10. Do not provide any\nexplanations.\nAbstract:\n{ABSTRACT}\nQuestion: {QUESTION}\nFor interpreting the trial results from the simplified\nabstracts, we used the following prompt:\nThis summary describes a study evaluating\na treatment in the field of cancer\npublished in a peer-reviewed journal."}, {"title": "Appendix C. Linear Regression\nModels", "content": "Figures 7, 8, 9, and 10 show the coefficients and 95%\nconfidence intervals from the linear regression models\nrun with an indicator for the presence of spin in an\nabstract as a predictor for study rigor, study impor-\ntance, interest to read the full-text, and interest to\nrun another trial."}, {"title": "Appendix D. Simplified Abstract\nExamples", "content": "Table 3 shows selected examples of simplified ab-\nstracts generated by LLMs. Further examples can\nbe found in our project GitHub repo."}]}