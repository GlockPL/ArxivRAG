{"title": "Thoughtful Adoption of NLP for Civic Participation: Understanding Differences Among Policymakers", "authors": ["JOSE A. GURIDI", "CRISTOBAL CHEYRE", "QIAN YANG"], "abstract": "Natural language processing (NLP) tools have the potential to boost civic participation and enhance democratic processes because they can significantly increase governments' capacity to gather and analyze citizen opinions. However, their adoption in government remains limited, and harnessing their benefits while preventing unintended consequences remains a challenge. While prior work has focused on improving NLP performance, this work examines how different internal government stakeholders influence NLP tools' thoughtful adoption. We interviewed seven politicians (politically appointed officials as heads of government institutions) and thirteen public servants (career government employees who design and administrate policy interventions), inquiring how they choose whether and how to use NLP tools to support civic participation processes. The interviews suggest that policymakers across both groups focused on their needs for career advancement and the need to showcase the legitimacy and fairness of their work when considering NLP tool adoption and use. Because these needs vary between politicians and public servants, their preferred NLP features and tool designs also differ. Interestingly, despite their differing needs and opinions, neither group clearly identifies who should advocate for NLP adoption to enhance civic participation or address the unintended consequences of a poorly considered adoption. This lack of clarity in responsibility might have caused the governments' low adoption of NLP tools. We discuss how these findings reveal new insights for future HCI research. They inform the design of NLP tools for increasing civic participation efficiency and capacity, the design of other tools and methods that ensure thoughtful adoption of AI tools in government, and the design of NLP tools for collaborative use among users with different incentives and needs.", "sections": [{"title": "INTRODUCTION", "content": "Natural language processing (NLP) systems can increase policymakers' ability to analyze citizens' comments on policy issues or drafts, a process known as civic participation in policymaking. In prior research, NLP systems have shown promising results in helping policymakers to organize and make sense of large volumes of citizen comments and opinions and even in helping policymakers to respond to constituents promptly [9, 23, 46, 47, 101, 102]. However, NLP tool adoption in government remains limited, perhaps because of the concerns that careless deployment of NLP tools can harm the democratic processes and erode public trust in government [17, 23, 29, 52, 115]. How can the design of NLP tools and their use protocols effectively enhance civic participation capacity and efficiency while mitigating potential risks and unintended consequences?\nCSCW research has long focused on how technology influences collaborative work [44] and how the design of new socio-technical systems can address conflicting stakeholder needs and enhance teamwork [e.g., 68, 82, 89, 103, 132, 140]. These complexities also apply to adopting and using NLP tools in government. Prior research has highlighted the sometimes conflicting interest among government's internal and external stakeholders [20, 21, 30, 38, 84, 110]. These organizational dynamics differ from those in the private sector because value within government is primarily associated with how citizens perceive and evaluate policy outcomes rather than corporate interest [19\u201321, 84, 105]. Interestingly, despite CSCW's increasing interest in civic tech and governments [8, 117], little research has studied the internal dynamics of governments around NLP tools' adoption and use.\nThis paper asks: How do politicians and public servants\u2014the two primary groups involved in policy-making within government-consider whether and how to use NLP tools to enhance civic participation? How do they consider possible ways to address potential risks and challenges? We focused on two Latin American countries-Chile and Uruguay-as our study sites. Latin America has a long-standing civic participatory tradition. As most countries transitioned to democracy in the last 30 years, it is a fertile ground for studying the use and innovation of technology for democratic processes [87]. Yet, the canon research literature-in HCI and beyond-has rarely studied these countries [87, 94, 134]. With HCI and CSCW communities increasingly advocating for the inclusion of the Global South in their research agendas [7, 94, 95, 121, 134], now is an opportune time to address this critical gap.\nWe conducted an interview study with seven politicians and thirteen public servants from five ministries in Chile and a public agency in Uruguay. Our findings suggest that policymakers across both groups focused on their needs for career advancement and the need to strengthen the legitimacy of their work when considering NLP tools' adoption and use. Because these needs vary between politicians and public servants, their preferred NLP features and tool designs also differ. Politicians' legitimacy was rooted in their constituents' trust and approval; therefore, they wanted NLP features that could showcase the fairness and capacity of their public participation processes and the use of cutting-edge technologies. Public servants, in contrast, were internally oriented. Their jobs' legitimacy came from the approval of their superiors; consequently, they looked for NLP features that could help them become both more efficient and more empathetic in analyzing citizen comments at the current volume. Interestingly, despite their differing needs and opinions, neither group clearly identified who should advocate for NLP adoption to enhance civic participation or address the unintended consequences of a poorly considered adoption. Instead, they blamed each other for NLP tools' low adoption in government.\nOur study makes two key contributions. First, it provides a rich description of how different policymakers in Latin America considered the adoption of NLP tools and their use in civic par-ticipation processes. It offers a valuable reference point for future research on similar topics in other government contexts and for innovating NLP tools for the public sector. Second, it challenges the common assumptions in HCI and AI literature that the adoption of AI tools in government is solely about algorithmic performance or fairness and that \"policymakers\" are a homogeneous group. By illuminating the complexities and differences among various types of policymakers, this work opens up new research and design opportunities for AI tools in the public sector."}, {"title": "RELATED WORK", "content": "In this paper, we use the term \u201ccivic participation\u201d to broadly refer to the processes by which individuals and organizations can influence the design and implementation of governmental policies [10, 15, 29, 48]. The level of empowerment and mode of engagement may vary based on the government and policy contexts [139].\nCivic participation in policy rule-making and implementation offers many important benefits. For citizens, it serves as a crucial component of civic education and engagement and increases trust in governmental processes [4, 60]. For policymakers, civic participation processes provide access to a broad range of experience-based knowledge at a low cost, enabling them to create better policy [4, 6, 9, 65, 85]. At a higher level, civic engagement enhances the inclusiveness, transparency, and accountability of democratic processes; it is a pillar of democracy itself [4, 9, 10].\nHowever, poorly implemented civic participation processes can cause more harm than good. For instance, when the participation process\u2014or the use of AI tools within it\u2014is unfair or opaque, it could inadvertently amplify the voices of powerful organizations or individuals, harming the less powerful citizens [10, 18, 29]. Over time, if citizens perceive the government as a passive listener that neither properly analyzes information nor responds and acts promptly, it could erode the public trust in both the participatory process and the government agency itself [5, 18, 23, 35, 74, 109, 114, 118]. In summary, the benefits of incorporating rich, diverse citizen input in policymaking must be balanced with the need to maintain transparency and fairness.\nThis dual requirement poses significant challenges to policymakers and public institutions, who often struggle to read or synthesize the large volume and wide variety of citizen inputs promptly [5, 9, 23, 52, 66, 70, 93, 112]. This issue is especially pronounced when dealing with unstructured citizen input, such as free texts [24, 39, 51]. To address these challenges, policymakers use heuristics to filter citizen inputs and prioritize those deemed more substantive. However, this approach has been criticized for potentially dismissing too many contributions, thereby biasing policy outcomes [23, 83, 98].\nWith the rapid advances in AI in recent years, NLP tools have become capable of assisting poli-cymakers in processing and synthesizing citizen inputs in many valuable ways [e.g., 46, 59, 101, 102, 112, 130]. Prior NLP research has demonstrated these tools' usefulness in pre-processing data (e.g., voice-to-text transcription, detecting duplicates, identifying spams), summarizing data (e.g., identifying topics and themes in citizen comments), and clustering data (e.g., grouping citizen comments with similar sentiments) within civic participation contexts [9, 23, 101, 102]. In recent years, Large Language Models (LLMs) have greatly improved NLP models' performances across various tasks, further increasing the potential of NLP tools to assist policymakers [62].\nHowever, adopting NLP tools in civic participation involves complexities beyond model perfor-mance or tool usefulness [122, 131]. To ensure public trust in the civic participation process, NLP tools need to ensure that they offer sufficient transparency to the public [32, 64, 92, 122, 128], treat diverse citizen comments fairly [50, 63, 122], and protect citizen privacy [63, 122, 131]. Even after these basic requirements are met, the decisions on whether governments should adopt NLP tools and how to use those tools in practice are contentious ones, highly dependent on different stake-holders' normative perspectives [104, 105, 107]. After all, the legitimacy of democratic governments fundamentally rests on the intrinsic right of citizens to be served by their representatives [105, 120]. Therefore, how citizens perceive NLP tool use and the outcomes of policymaking processes is paramount [19\u201321, 84, 105]."}, {"title": "METHOD", "content": "We wanted to understand how different stakeholders within government institutions consider whether and how to use NLP tools to enhance civic participation, as well as how they consider possible ways to address potential risks and challenges. We hope these insights will inform better NLP tool design and illuminate new social practices to ensure thoughtful adoption and use of these tools. To extend prior research that focused on public agencies, we chose to focus on the internal stakeholder dynamics within central government institutions. Instead of studying front-line workers, we focus on politicians and public servants\u2014the two primary groups involved in policymaking within government. Additionally, we focused on two Latin American countries-Chile and Uruguay-as our study sites.\nWe conducted IRB-approved semi-structured interviews with 20 politicians and policymakers. We recruited participants from five ministries in Chile and one agency in Uruguay. These institutions are all under the executive branch of government, which more often manages civic participation processes than other branches. The institutions vary in terms of legal mandate, the type of policies they develop, and how they conduct participation processes. Interviewees were initially recruited"}, {"title": "Interview Data Analysis", "content": "We analyzed the interview recordings using a two-phase coding technique and the qualitative data analysis software MaxQDA. The first phase of open coding contrasts the data and builds a broad set of codes, which are then connected in the second phase of axial coding [25]. The first author conducted the open coding stage, producing 73 codes with 735 coded sentences. All the authors discussed the findings and related work, and the first author refined the coding, classifying them into 24 second-level codes, which were grouped into four categories that are presented in the Findings section 4 in Tables 3, 4, 5, and 6."}, {"title": "FINDINGS", "content": "Our interviews revealed three major findings. The first two findings are interrelated. First, both groups of policymakers\u2014politicians and public servants-focused on their needs for career ad-vancement and the need to strengthen the legitimacy of their work when considering NLP tools' adoption and use. Second, because these needs varied between politicians and public servants, their preferred NLP features and tool designs also differed. Politicians' legitimacy was rooted in their constituents' trust and approval; therefore, they wanted NLP features that could showcase the fairness and capacity of their public participation process and the use of cutting-edge technologies. Public servants, in contrast, were internally oriented. Their jobs' legitimacy came from the approval of their superiors; consequently, they looked for NLP features that could help them become both more efficient and more empathetic in analyzing citizen comments at the current volume. Finally, despite their differing needs and opinions, neither group clearly identified who should advocate for NLP adoption to enhance civic participation or address the unintended consequences of a poorly considered adoption. Instead, they blamed each other for NLP tools' low adoption in government.\nWe compared politicians and public servants in different categories (e.g., general and institutional level, experience using NLP) but only found relevant differences at a general level (politicians-public servants) and some particular cases for experience using NLP, which we highlight. Below, we report our findings using textual quotes from the interviews translated from Spanish by the authors, paraphrasing multiple quotes, and summarizing exemplary cases narrated by the interviewees. When using quotes within paragraphs, fragments are selected without changing the original quote's intention, context, and meaning."}, {"title": "Differing Motivations of Using NLP Tools", "content": "Politicians and public servants differed in their incentives when deciding whether to use NLP to support participatory processes. Politicians focused on increasing legitimacy towards their constituents and managing power, while public servants were primarily interested in reducing their workload, increasing efficiency, and avoiding being replaced. 1 summarizes the percentage of interviewees in each group that discussed each motivation."}, {"title": "Politicians prioritized building legitimacy towards external stakeholders", "content": "Politicians highlighted that using NLP could increase objectivity and rigor, increasing their legitimacy by promoting con-stituents' trust. There was a shared belief among politicians that \u201cwhen there is human intervention concerning the comments and responses of those who participated, there is always manipulation stemming from who takes notes and then informs the authority\u201d (PT1). Using NLP tools, politicians could \u201cidentify the true conversations and the words people used to refer to the different topics without the filters and biases of who listened and systematized\u201d (PT4). Politicians tended to believe that NLP tools were \u201cnot interpreting, only processing data\u201d (PT1), which was essential to achieve their goal of \u201cestimating frequencies of converging responses to identify topics you can incorporate with more assurance of people adhering to them [...] to give the process a scientific approach through technology\u201d (PT3). PT5 summarized this idea well:\nAlthough some politicians recognized that \u201cNLP tools might have some bias\u201d (PT4), they believed Al's biases could be identified more precisely and efficiently than biases from people taking notes (PT4, PT5). Politicians considered machines superior to humans, so using them would increase their constituents' trust in the process. For example, PT4 explained that \u201cthere is no mechanism without bias [...], for example, how a topic modeling algorithm groups topics can be directed. However, eliminating the first intermediary, the policymaker, allows the raw data to be considered better when first processed by a machine\u201d (PT4).\nSome politicians argued that using NLP tools could increase their public approval through positive press: \u201cTechnology has good selling, and politicians like that. Authorities would implement technology to support participation because it will sell; it has a certain glamour and attractiveness\u201d (PT2). Politicians argued that although some citizens were afraid of AI, most people believed that using it would improve the quality of policymaking, especially since trust in governments in Latin America was shallow. One public servant mentioned that emphasizing the public image benefits of AI adoption might help convince authorities to implement technology: \u201cPoliticians would use AI because they think it is interesting. They would be able to say they are at the frontier, and that is something you can communicate. Authorities will always consider how they benefit from the method, so using technology can be an element of marketing\u201d (PS2)."}, {"title": "Politicians perceived NLP could help them manage power dynamics", "content": "Politicians thought NLP tools could help them manage power among stakeholders and align the processes to their political agendas by including new groups that could change power dynamics. The role of NLP tools here was dual. On the one hand, politicians saw NLP as a tool to identify trends in data, increase the salience of marginalized stakeholders, and build a case against stakeholders that are traditionally more vocal and visible to the public in traditional participatory processes. PT1 explained their needs: \u201cWe could identify trends from majorities that usually don't voice their demands or are not able to articulate as a group, that would give us more support for certain policies, distributing power\u201d (PT1). On the other hand, politicians saw NLP tools as capable of decreasing biases in participation processes, which suffer from self-selection. Politicians believed working with NLP could decrease barriers for underrepresented groups by enabling them to work with raw data and a larger pool of participants. The latter would dilute specific interest groups' power, making processes more objective and legitimate. PT4 described an example during the COVID-19 pandemic:\nPoliticians would only implement NLP tools if they considered it would not harm their legitimacy with relevant external stakeholders. For example, PS5 explained how NLP was discarded from a massive consultation in education because politicians considered that using AI would not be accepted by core stakeholders (i.e., teachers' unions) and thus reduce the process' legitimacy. PS5 argued that NLP tools could enable them to consult a broader set of stakeholders, but politicians preferred to reduce the number of participants and ask less specific questions while keeping the analysis manual."}, {"title": "Public servants prioritized efficiency to build their legitimacy towards their superiors", "content": "Public servants wanted NLP to alleviate their workload and make the processes more efficient by \u201cbroad-ening the reach while cutting down time demands\u201d (PS3). Public servants argued that analyzing participatory data manually was hard or impossible since it took too much time and they had to fulfill multiple roles in government (PS3, PS5, PS10, PS12). Public servants were usually asked to deliver quickly, which they argued to be incompatible with an in-depth analysis of qualitative information (PS3, PS4, PS5, PS8, PS9). Many times, public servants had to narrow down questions to collect less information to be able to analyze and respond to citizens promptly (PS5), which they believed could change using NLP tools (PS3, PS5).\nPublic servants believed NLP tools could support organizing, filtering, navigating, and summa-rizing information. Interviewees wanted NLP tools to efficiently identify the most frequent topics and core ideas (PS7, PS9, PS10, PS12), propose relationships between topics, build clusters, and extract the most relevant quotes (PS1, PS5, PS8) that they could connect to political priorities (PS8). Public servants approached the representation issue from an efficiency perspective: they needed more efficient strategies to engage with the right stakeholders and find missing minority groups in less time (PS7). Public servants needed support from NLP to \u201cidentify actors\u201d (PS5) and \u201cbe able to map stakeholders because the public is so broad that it is hard to identify which groups are relevant\u201d (PS10) or \u201cwhich institutions need to be involved\u201d (PS12). Additionally, public servants discussed the possibility of using AI tools to \u201chave more representative samples of participants or warn potential missing groups from alternative sources such as social media data\u201d (PS4). The latter was not necessarily related to NLP tools, but they did mention analyzing textual data to identify similar stakeholders within the data and compare it to textual data in other sources, such as social media."}, {"title": "Public servants' use of NLP was mediated by their perception of their role in the process", "content": "Public servants did not see NLP tools replacing their role in analyzing participatory data or policy design. Public servants wanted to have a tool that \u201ccould automate systematizing and summarizing the information, not to a final document, to something where we can explore the main ideas efficiently\u201d (PS4). Public servants envisioned NLP as \u201ca team member with better capacities to systematize and summarize the information and that then I can interrogate\u201d (PS1).\nPublic servants who did not have previous experience with NLP tools insisted that there were elements of the participatory process that machines should never perform. This group argued they had to use the data to \u201cbuild the public policy document that can be communicated, and that they would not trust an Al system to build the political narrative\u201d (PS2). They argued that NLP tools could never replace human analysis since humans were the ones who could provide theoretical explanations for correlations (PS7) and understand human sensitivities (PS11)."}, {"title": "Differing Considerations on How to Use NLP Tools", "content": "Politicians and public servants differed in how they perceived and approached risks from NLP, depending on their legitimacy-building orientation (i.e., from whom they draw legitimacy) and relationship with the NLP tools. Politicians' interaction with external stakeholders was more direct and core to their legitimacy, so their orientation was often external. However, politicians' interaction with the NLP tools was usually indirect, so they were less conscious of the risks. In contrast, public servants' legitimacy depended less on external stakeholders than on their superiors' opinions about their role, so their orientation was often internal. Moreover, public servants usually interacted more intensively with the NLP system, which put them at greater risk of being replaced and often made them more conscious of the risks. 4 summarizes the percentage of interviewees that discussed each risk, and table 5 summarizes the percentage of interviewees that discussed different mechanisms for a thoughtful adoption of NLP."}, {"title": "Politicians were less aware of risks than public servants", "content": "Relying on external validation and seeing themselves far from the tool, politicians were less aware of the risks of using NLP in participatory processes. In contrast, public servants saw themselves as key actors in implementing NLP tools, so they were more conscious and knowledgeable. Public servants identified risks and challenges such as errors in analysis (e.g., hallucinations, misclassification), lack of explainability, surveillance, biases, and privacy breaches. The only risk both groups were equally aware of was potential biases. However, politicians tended to think that although NLP tools could be biased, they would probably be less biased than humans (PT1 & PT4) and that reducing bias was just a technical problem (PT3).\nPoliticians tended to believe that \u201cAI could help since it provides an objective perspective\u201d (PT1), revealing an illusion of objectivity. Public servants recognized the risk that politicians could argue that the machine was objective because it is not human and use NLP systems to claim neutrality and manipulate citizens (intentionally or unintentionally). PS7 voiced this fear:\nPoliticians discussed the risks of political manipulation from a different perspective. For politi-cians, the risk was present if someone intentionally altered the code or tampered with the results, which could put democracy at risk and harm citizens (PT2, PT4, PT5). Politicians analyzed the risk, considering that it did not stem from the system's characteristics or use but from the users' direct intervention. The latter was consistent with their external orientation, which usually expected attacks from opposing political forces."}, {"title": "Politicians favored external-facing mechanisms towards responsible Al", "content": "Politicians built legiti-macy towards the public (external orientation), favoring external-facing mechanisms. Politicians considered providers' reputation and replicability as the most critical elements in thoughtfully adopting NLP. Politicians explained they needed information about providers' previous experi-ence and team composition to assess their reputation and fit to safely develop and implement an NLP (PT1, PT3, PT4). PT1 explained that providers had to \u201cprove neutrality and capacities before the project implementation\u201d (PT1).\nPoliticians highlighted the role of civil society and academia in replicating and challenging results, so data needed to be made available along with well-crafted documentation so that external reviewers could audit the processes and results (PT2, PT3, PT5, PT6). PT3 argued that involvement from academia could increase trust in the system: \u201cDespite academia not being a default honest broker, under certain conditions, it can be trustworthy and increase trust in the process and systems when involved\" (PT3).\nRegarding the system, politicians sought signals and information about the systems' trustworthi-ness in standards, certifications, and compliance with existing regulations (PT1, PT3, PT4, PT5). PT1, PT3, and PT4 mentioned how providing certifications such as ISO would help increase citizens' trust and reliance on AI. Moreover, certifications and standards could be linked to the legal process, such as procurements: \u201cWe have to incorporate technical requirements and certifications in the procurement process to support institutions with no technical capacities\u201d (PT6)."}, {"title": "Public servants favored human-in-the-loop internal-facing approaches towards responsible Al", "content": "Public servants built legitimacy within the organization (internal orientation) by validating their roles and capacities towards their superiors. Thus, they tended to favor internal-facing mechanisms where they played a relevant role: human validation, piloting periods, improving their knowledge to serve as internal counterparts, and using guidelines/standards.\nPublic servants favored internal controls through human involvement (humans-in-the-loop) to ensure thoughtful adoption processes by validating the algorithms throughout their life cycle. Public servants argued the need to \u201caccess the raw data and check if the analysis made sense and correct when it is wrong\u201d (PS7). Even in non-analytical tasks like transcriptions, they believed they should review the results: \u201cWhen there is too much jargon, we need to check the automated transcription and correct it\u201d (PS9).\nPublic servants discussed that NLP systems would not replace them but change their role into acting more as reviewers. Interviewees argued that the processes should have \u201cstages where the human has the role of revising, supervising, and ensuring the data quality and analysis is right\u201d (PS6). The associated challenge was that public servants had to be competent counterparts for third parties providing the NLP systems, which was not always the case. To this point, public servants believed they \u201cdid not need to understand the algorithm in-depth but to have some basic understanding and a critical approach\u201d (PS3) to work \u201chand in hand with the provider to understand all the decisions and results\u201d (PS8).\nPublic servants recognized the lack of knowledge and considered either bringing technical people to the team (PS7), using existing guidelines and standards (PS7 & PS12), or connecting to third parties (PS9 & PS12). Thus, external validation was an option when the expertise was unavailable, but public servants still required strong connections and involvement with the review board. Some mechanisms were discussed, such as having third parties \u201crandomly revising a sample of raw quotes\u201d (PS12), adapting \u201cuniversities ethics revision boards and revision processes [...] or creating ad honorem advisory boards\u201d (PS9).\nPublic servants emphasized that adoption processes should include piloting periods and strong collaborations with the providers (PS1 & PS12). To do so, public servants agreed they needed \u201cguidelines to know what to do when evaluating [NLP] projects\u201d (PS13) and \u201csectorial standards which lower the knowledge asymmetries [with providers] when implementing NLP systems\u201d (PS7)."}, {"title": "Politicians and public servants manifested different transparency and explainability needs", "content": "Transparency and explainability were operationalized differently depending on which stakeholder was relevant to the politician or public servant. Both groups agreed that data should be open when it was allowed by regulation and privacy was adequately protected. Moreover, most participants emphasized that traceability from results to the raw data should be easy and interactive. However, they disagreed on how, to whom, and how much data/code to open.\nPoliticians were prone to argue about opening data/code and making it explainable to the public or external reviewers. Politicians argued that tailored explanations were needed for citizens to understand, replicate, and audit the analysis (PT2, PT5): \u201cauthorities need to explain to citizens how they did the analysis, so they need a semi-technical explanation of the system they can understand to have a legitimate process\u201d (PT6). Thus, politicians' core goal was to increase trust in the process among external stakeholders.\nPublic servants usually discussed transparency and explainability when working with the system and explaining results to their superiors. Public servants prioritized explanations from providers to understand the process themselves in elements such as \u201chow the insights were extracted\u201d (PS1) and \u201chow the system filtered and classified information\u201d (PS4). Public servants argued that despite explanations to external stakeholders being needed, they would not completely open the code since it could increase costs and decrease providers, making the process less efficient (PS1, PS3, PS12). For example, PS12 argued that \u201cproviders will not open the code of their systems, and probably it is not viable nor desirable because that would increase costs and providers' availability\u201d (PS12)."}, {"title": "Who is Responsible for NLP Tool Adoption and Proper Use?", "content": "Politicians and public servants blamed each other on who was responsible for the lack of widespread thoughtful use of NLP for participation processes. Both groups highlighted bureaucracy and lack of knowledge about NLP as the main barriers to its use. However, there were subtleties related to how they interpreted the implications of these barriers. Politicians believed that lack of knowledge made public servants resist change, blaming them for not exploring and not being open to using new technology. Public servants countered, blaming politicians' lack of leadership for their lack of knowledge, infrastructure, and support. 6 summarizes the percentage of interviewees who discussed each barrier."}, {"title": "Politicians and public servants agreed bureaucracy was a relevant burden to adopt NLP tools", "content": "Public servants and politicians agreed that excessive or unfit bureaucracy and inadequate procure-ment processes were relevant barriers to adoption. Interviewees believed \u201cthe problem is institutional; it is bureaucracy\u201d (PT2) because in the public sector \u201cyou will always have a limitation which is that you need an enabling regulation\u201d (PS12). Procurement processes are not suited for technology, as one participant explained: \u201cwe were trying to hire a massive mailing service for over a year because paying a monthly license did not fit the procurement processes\u201d (PS1). Moreover, interviewees complained that many \u201cregulation frameworks are outdated; when they were created, technology had other business models. We have issues even for maintaining web pages\u201d (PS5)."}, {"title": "There was a lack of knowledge about NLP, but no clarity on who was responsible for it", "content": "The most relevant consensual barrier was the lack of knowledge within the government, but the two groups perceived it differently. Politicians argued that public servants resisted change because they lacked the technical knowledge about what NLP could do and how to implement it. Politicians highlighted the importance of fostering \u201can educational effort on understanding AI systems for public servants\" (PT3). PT2 explained:\nPublic servants agreed that the government lacked knowledge about NLP, but this was not necessarily a reason for resisting change. Public servants acknowledged that background hetero-geneity could create barriers (e.g., PS8 highlighted legal and procurement teams) or particular sectors that did not trust technology (e.g., interviewees exemplified education and culture public servants). Still, it was not usually the reason for stopping the adoption of NLP. Lack of knowledge was often a barrier because public servants did not know what NLP tools could do nor how to design and implement them (PS4, PS10, PS12). Moreover, governments usually did not have the required technological infrastructure regarding computation capacities or budget (PS7, PS8, PS10). Public servants said they did not necessarily resist; they did not know the available tools and had no time to explore.\nPublic servants argued that the lack of knowledge was partly due to politicians' lack of leadership, which made adoption harder. They believed that \u201ceducating people who will implement NLP tools depends on the head of the organization, but bosses often do not see the relevance of using them\u201d (PS2). Public servants contended that having the time and flexibility to explore methodologies and tools was critical to acquiring knowledge and successfully implementing new tools, but politicians often did not allow that. For example, PS1 explained that \u201cexploration is incredibly valuable to learn what new technologies could do, now I can tell because I could do it with my former supervisor, but now I have to fight too hard to be able to learn and try new tools\u201d (PS1). Public servants argued that resistance to change has to be managed by politicians, which does not always happens: \u201cChange and human management are critical, but they need the authority to be convinced. If the person in charge sees the value, they will bring the necessary people and resources to the team; if not, there is nothing to do, and change will be impossible\u201d (PS7)."}, {"title": "DISCUSSION", "content": "Our findings examined why NLP tools have failed to be widely adopted thoughtfully for civic participation processes by governments despite recent technical advancements [e.g., 9, 47, 100, 102]. Previous research in NLP for participation has focused on efficiency and technical limitations of offering consistent and reliable support to public servants [e.g., 9, 47, 101, 102]. Still, that body of work has little connection to research about the complexities of internal stakeholders when implementing technological tools in the public sector [54, 104, 105, 107] in combination with the complexities of designing human-AI interaction [135, 136]. While multiple value positions have been addressed in prior CSCW work [e.g., 43, 68, 132], it is not necessarily tailored and adequate to government contexts [54, 55, 104, 105] and might fail to inform thoughtful adoption of NLP tools in civic participation processes. We contribute to a nascent line of work within CSCW that analyzes the complexities of AI adoption in government, considering different internal stakeholder groups [54].\nOur findings inform how to approach the design and adoption of NLP tools for participation processes, considering the nuances of politicians and public servants within the public sector. We discuss research and design implications and opportunities around three areas: (1) Designing NLP tools for more than efficiency in participation processes, (2) Designing tools and methods for a thoughtful use of NLP in participation processes and (3) Designing tools and methods not for single-user but for collaborative use in government."}, {"title": "Designing NLP Tools for More Than Efficiency in Participation Processes", "content": "Our findings suggest that NLP tools for supporting participation processes should not focus only on efficiency, which has been the primary goal of most prior work [9, 23, 66, 102", "102": "might not be compelling to politicians.\nWe do not argue that increasing efficiency does not matter. Rather, our findings surface a potential tension between politicians and public servants regarding their motivations because they construct their legitimacy differently. Both motivations are not necessarily incompatible, but they can be misaligned. If politicians need to efficiently process the information and showcase the results, they will probably be aligned with public servants' needs as users. However, if politicians are not aware of public servants' needs, are only concerned with getting good press, and/or have relevant stakeholders resistant to AI, public servants probably will not be able to convince them to use NLP tools. As prior work in electronic participation initiatives has shown, failing to address the motivations of the most salient stakeholder (i.e., the one with the higher power, urgency, and legitimacy) can prevent adoption [120", "67": "infrastructural requirements [5, 58, 101, 130", "63": ".", "52": ".", "106": "since they see an intrinsic value in having humans supervising and translating data to policy. Our findings suggest convincing public servants to adopt NLP tools is more complex than just achieving better results and making algorithms more readily available through software [69, 102, 122, 131"}]}