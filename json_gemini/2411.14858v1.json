{"title": "Domain and Range Aware Synthetic Negatives Generation for Knowledge Graph Embedding Models", "authors": ["Alberto Bernardi", "Luca Costabello"], "abstract": "Knowledge Graph Embedding models, representing entities and edges in a low- dimensional space, have been extremely successful at solving tasks related to completing and exploring Knowledge Graphs (KGs). One of the key aspects of training most of these models is teaching to discriminate between true statements (positives) and false ones (negatives). However, the way in which negatives can be defined is not trivial, as facts missing from the KG are not necessarily false and a set of ground truth negatives is hardly ever given. This makes synthetic negative generation a necessity. Different generation strategies can heavily affect the quality of the embeddings, making it a primary aspect to consider. We revamp a strategy that generates corruptions during training respecting the domain and range of relations, we extend its capabilities and we show our methods bring substantial improvement (+10% MRR) for standard benchmark datasets and over +150% MRR for a larger ontology-backed dataset.", "sections": [{"title": "Introduction", "content": "Knowledge Graphs (KGs) are a flexible and scalable data representation paradigm to represent complex relationships between different concepts [1]. Their applicability to model information related to any domain made them reach a significant size, including millions or even billions of edges. This makes manual curation almost impossible and leaves them incomplete and error-prone [2].\nIn this context, a machine-based approach is necessary to infer missing links and assess the correctness of given links. Pioneer research efforts [3, 4] led to Knowledge Graph Embedding (KGE) models, that learn low-dimensional representations for entities and relations to perform a variety of tasks.\nAlthough some approaches rely uniquely on the true facts that make up a KG, the dominant training approach for KGE models teaches to discriminate between true statements (positives) and false ones (negatives). However, statements missing in a KG are not necessarily false, and rarely ground truth negatives are provided. This makes the generation of synthetic negatives, or Negative Sampling (NS), necessary and determinant during training. A lot of research was carried out, addressing the difficult challenge of coming up with effective and efficient strategies to sample true negatives [5, 6].\nOur work extends an existing NS strategy [7] that leverages schema-based information in order to enhance the quality of the negatives. Despite nailing the possibility of using entity type information to generate negatives that are semantically relevant, they neglect how, in case a class has few instances, the likelihood of resampling the same entity from the class increases, so we might end up generating non-diverse and (if the sampled entity coincides with the ground truth one) false negatives. Combining it with random uniform sampling [3], we mitigate this issue while also limiting the risk of generating trivial random negatives. The latter problem, indeed, affects the uniform random sampling applied on its own, especially in KGs where some node types are over-represented.\nAs an additional contribution, we validate our results on two popular benchmark datasets, where the classes of nodes are inferred based on relation types, and on a biological dataset for which classes are"}, {"title": "Related Work", "content": "Knowledge Graph Embedding Models. KGE models learn continuous representations of entities and relations in the KG from the graph topology and its soft regularities (symmetries and asymmetries, concept homophily, long-range relationships...) to solve a wide variety of tasks. We refer the interested reader to [10] for a comprehensive overview.\nNegative Sampling. A lot of methods addressed the challenge of generating negative samples from existing KGs. We can broadly categorize them in 4 groups. (i) Static NS methods consider a pool of possible negatives that does not change during training. Within this group we have: the preeminent random sampling, that corrupts either the tail or the head of a triple picking uniformly at random any entity in the KG [3], that might be extended to relations [11] or limited to entities within the mini-batch [12]; probabilistic negative sampling methods, that fix a probability to decide whether to corrupt the head or the tail of a triple [13\u201316] or to use random negatives or those sampled from a predetermined list [17]; methods that leverage a pre-trained external models (e.g., a pre-trained KGE [18] or Language Model [19]) to generate corruptions that are similar to the entity to corrupt; auxiliary data-based, that leverage type information [7], domain or range information [20, 21], or the semantics [22] of a KG to generate negatives. (ii) Self-Adversarial NS strategies use the KGE embeddings to model a probability distribution from which to sample a set of negatives. For example, [23] makes the distribution of negatives proportional to the score assigned from the KGE model to the negatives, so to guarantee that, as training progresses, the model is influenced more by more plausible negatives. However, this strategy comes with the risk of assigning higher relevance to false negatives. Other works along this line are [24-26]. (iii) Adversarial NS methods leverage an external model, trained in a framework that resembles Generative Adversarial Networks [27], to generate negatives. (iv) Dynamic negative sampling methods, finally, try to inform the generation of negatives by changing their distribution as training progresses to avoid trivial negatives. However, (iii) and (iv) introduce a significant computational overhead. For non-attributive graphs, [28] use a similarity score to sample harder negatives, but its efficient definition in KGs is complicated by their heterogeneity. For more details and negative sampling methods, refer to [5, 6]."}, {"title": "Methods", "content": "3.1 Background and Notation\nA Knowledge Graph $G = \\{(s, p, o)\\} \\subseteq E \\times R \\times E$ is a set of triples $t = (s, p, o)$, each including a subject (head) $s \\in E$, a predicate $p \\in R$, and an object (tail) $o \\in E$, where $E$ and $R$ are the sets of all entities and relation types, respectively. We refer to the task of predicting unseen triples in a KG as Link Prediction. It is formalised in literature as a learning to rank problem, where the objective is learning a scoring function $f : E\\times R\\times E \\rightarrow R$ that, given an input triple $t = (s, p, o)$, assigns a score $f(t) = f((s, p, o)) \\in R$ proportional to the likelihood that the fact $t$ is true. Predictions of true triples $t^+ \\in T^+$ are ranked against predictions for synthetic negatives $t^- \\in T^-$, to gauge how well the model discriminates true from false statements. Finally, we introduce the concept of class. If in KGs this concept is formally tied to the definition of a schema or an ontology, we will more broadly refer to it to also indicate the grouping of entities we can infer from the relation types in case the ontology is missing. In these cases, we are going to define two classes for every relation type $p\\in R$:\n$domain_p := \\{e \\in E | \\exists o \\in E s.t. (e,p, o) \\in G\\}$, $range_p := \\{e \\in E | \\exists s \\in E s.t. (s,p, e) \\in G\\}$.\n3.2 Ontology-based Negative Sampling\nThe dominant approach to NS while training a KGE model is, given a positive triple $t = (s, p, o)$, to corrupt either the subject or the object with \u03b7 entities sampled uniformly at random from E [3]. Formally, the set of negatives to sample from is defined as $T_{rand} = \\{t^- = (s', p, o) | s' \\in E\\} \\cup$"}, {"title": "Experiments", "content": "4.1 Experimental Settings\nDatasets. We evaluate our NS strategy on three KGs: FB15k-237 [29] and WN18RR [9] are two of the most widely used benchmarks for link prediction; Hetionet [30] is a network encoding biological data. Differently from the former two, Hetionet does not come with pre-defined train-test splits. Therefore, we create a test set of 10,000 triples and a validation set of 5,000 extracted at random from the training set so that no entity of the test and validation sets was not present in the training set.\nEvaluation. We evaluate our models in the filtered setting: for every target triple $t = (s, p, o)$, we separately corrupt the subject and the object with all the entities in the KG not generating a fact in the training, validation or test sets. We then rank test triples against all corruptions. The metrics used are the usual for link prediction: Mean Reciprocal Rank (MRR) and Hits at N (Hits @N).\nHyperparameter Search. We perform an extensive grid search to validate our results. For FB15k-237 and WN18RR, we explore embedding dimension k = [200,350], \u03b7 = [10,20,30], loss functions [self-adversarial, multi-class NLL]. As optimizer we use Adam [32] with learning rate lr = [1e-2, 1e-3, 1e-4, 1e-5] and LP-regularization coefficient \u03bb = [1e-2, 1e-3, 1e-4]. Finally, we test the proportion \u03bd of negatives sampled respecting domain and range constraints: \u03bd = [0.0 \u2013 1.0] with step 0.1. We run experiments for 1000 epochs on FB15k-237 and 4000 epochs on WN18RR, enabling early stopping monitoring MRR, with patience set to 10 and validation frequency of 25 epochs. For Hetionet we run experiments for 1000 epochs and explore k = [100, 200] and \u03b7 = [10, 20], while we keep the rest of the grid search unchanged.\nBaseline. We compare our NS strategy with KGE models trained following the random uniform NS [3] and the Type-Constrained approach [7] we have extended. For a fair comparison, we pick as the best baselines those that share the same (or smaller) embedding size and number of negatives of the best performing model trained with our own NS strategy. The KGE models we consider are TransE [3], DistMult [33], ComplEx-N3 [34, 35] and RotatE [23]. Despite some recent works (among the others [36, 37]) claim new state-of-the-art results, the gain is often marginal and inflated by expensive training protocols. Moreover, the impact of our strategy can be gauged independently on the models considered. We leave for future work the analysis of a wider set of models."}, {"title": "Main Results", "content": "The results of our experiments are reported in Table 1. Our NS method outperforms the random approach and the Type-Constrained one in all cases, with the only exceptions of TransE and DistMult on WN18RR. The improvement is substantial in FB15k-237: +10% MRR on the random baseline for ComplEx-N3 and +33% on the type-constrained baseline. Indeed, some of the classes inferred from relation types for FB15k-237 have extremely reduced cardinality (11 classes have just one node, 24 up to 3 nodes, 56 up to 10), thus making the generation of negatives entirely based on type-constraints harmful, as it leads to many false negatives. On the other hand, on Hetionet, our NS strategy leads to impressive gains of well over +150% MRR relative to the random sampling baseline. The definition of classes based on a proper ontology, indeed, allows for the generation of more significant and diverse negatives, not dominated by over-represented classes (e.g., Gene and Biological Process). At the same time, the proportion of random uniform negative samples helps increasing the diversity for classes that have few instances (e.g., Disease and Pharmacological Class), thus motivating the improvement over the T.C. baseline.\nAs a final remark, the optimal value of \u03b7 for TransE, DistMult and ComplEx-N3 on WN18RR is 30, while for all the other models is 10. The low (or null) improvement in the performance for the former three models suggests that our strategy impacts more models trained with few negative samples. Indeed, if the number grows, too many domain and range-based negatives can cause issues similar to those outlined for Type-Constrained NS. Random uniform sampling on its own, on the other hand, is enough to yield more meaningful negatives if \u03b7 grows significantly. This shows how our approach can hugely benefit efficiency, allowing for a reduced number of negative samples. Moreover, the overhead introduced by our strategy is minimal, as ComplEx-N3 run on Hetionet (over 2 million triples) took an average ~5ms per step extra overhead compared to the random uniform sampling."}, {"title": "Conclusion and Future Work", "content": "With this work, we have proposed a simple and effective NS strategy, that can significantly enhance the performance of KGE models and help improve the size, and thus the efficiency, of these models. We have validated results on two popular benchmark KGs and on a biological graph that, given an ontology, was affected the most by our method. The results obtained are extremely promising and, given the flexibility of the approach, we leave for further work its application to a broader set of KGE methods. In addition, we plan to extend the experiments to more datasets, to specifically gauge the impact of ontology-derived classes over relation-inferred ones."}, {"title": "Appendix", "content": "A.1 Ontology-based Negative Sampling Pseudo-Code\nWe provide the pseudo-code of our Negative Sampling strategy in Algorithm 1.\nAlgorithm 1 Ontology-based Negative Sampling\nRequire: t (s, p, 0), Trand, Tt.c., \u03bd\u2208 [0, 1], \u03b7 \u03b5\u039d.\nEnsure: S set of negatives for t such that |S| = \u03b7.\n$N_{rand} = \\lfloor\\eta\\cdot\\nu\\rfloor$ \u25b7 Number of negatives to sample uniformly at random\n$N_{t.c.} = \\lfloor\\eta\\cdot (1 - \\nu)\\rfloor$ \u25b7 Number of Ontology-based negatives to sample\n$S_{rand} \\leftarrow sample (T_{rand}, N_{rand})$\n$S_{t.c.} \\leftarrow sample (T_{t.c.}, N_{rand})$\nreturn $S\\leftarrow S_{rand} \\cup S_{t.c.}$\nA.2 Dataset Statistics\nStatistics of the three datasets are reported in Table 2.\nA.3 Implementation Details\nAll experiments are implemented with AmpliGraph library [38], using Tensorflow 2.9.0 and Python 3.8.10 in the backend. All our code was run under Ubuntu 20.04 on an Intel Xeon Gold 6226R, 256GB, equipped with Tesla A100 40GB GPUs.\nA.4 Optimal Hyperparameters\nIn Tables 3-4-5 we report the best hyperparameters obtained grid searching our models. k specifies the dimension of the KGE embeddings; \u03b7 the number of negatives generated for each training triple; Ir is the learning rate of the Adam optimizer used in our experiments; v specifies the proportion of the \u03b7 negatives that are sampled respecting the domain and range constraints.\nA.5 Impact of v on the Results\nAs an additional experiment, we report in Figure 1 the performance of the best models for the different scoring functions, modifying the value of v, the hyper-parameter specifying the proportion of ontology-based negatives to sample for each training triple.\nAt a first glance, we can notice how, for the same dataset, the impact of ontology-based sampling has a quite consistent behaviour across all the four models, hinting at its applicability to any other scoring function. Moreover, it looks like there is consistency in the behaviour of the same model across neighbouring values of v. FB15k-237, for example, favours low values of v, while Hetionet and WN18RR favour higher values. Importantly, this shows how v is an hyper-parameter easy to tune. Indeed, it will be enough to test a couple of extreme values and a central one to have a good estimate of what the impact of the strategy could be.\nAnother important observation is the difference even a very small v can make on the random baseline when there are entity types that are over-represented. It is the case of Hetionet. For this dataset, indeed, we can notice how, even the slightest increase of v makes the the performance spike. Indeed, as already mentioned in the main text in the paper, ontology-based negatives allows the generation of negatives more pertinent for each triple and not dominated by entities of the over-represented"}]}