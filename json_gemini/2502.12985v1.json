{"title": "PartSDF: Part-Based Implicit Neural Representation for Composite 3D Shape Parametrization and Optimization", "authors": ["Nicolas Talabot", "Olivier Clerc", "Arda Cinar Demirtas", "Doruk Oner", "Pascal Fua"], "abstract": "Accurate 3D shape representation is essential in engineering applications such as design, optimization, and simulation. In practice, engineering workflows require structured, part-aware representations, as objects are inherently designed as assemblies of distinct components. However, most existing methods either model shapes holistically or decompose them without predefined part structures, limiting their applicability in real-world design tasks. We propose PartSDF, a supervised implicit representation framework that explicitly models composite shapes with independent, controllable parts while maintaining shape consistency. Despite its simple single-decoder architecture, PartSDF outperforms both supervised and unsupervised baselines in reconstruction and generation tasks. We further demonstrate its effectiveness as a structured shape prior for engineering applications, enabling precise control over individual components while preserving overall coherence. Code available at https://github.com/cvlab-epfl/PartSDF.", "sections": [{"title": "1. Introduction", "content": "We live in a world full of manufactured objects of ever-increasing complexity that require clever engineering to be functional. These objects are inherently composite. Thus Computer Aided Design (CAD) tools used to design and optimize them must be able to handle them as assemblies of distinct parts from the outset. Each part must adhere to separate fabrication constraints, tolerances, and functional requirements, making part-based representations essential. Unlike in many publicly available 3D datasets where shapes are treated as holistic entities, real-world engineering applications therefore require structured, part-aware models to support tasks such as simulation, optimization, and interactive design refinement. For example, when optimizing"}, {"title": "2. Related Work", "content": "Over the last several decades, the evolution of traditional CAD systems has reflected a fundamental tension between simplicity and expressiveness. Early approaches relied on basic geometric primitives such as spheres, cylinders, and NURBS surfaces (Piegl, 1991), offering mathematical precision but limited representational power. Recent years have witnessed a shift toward more sophisticated primitives, from simple cuboids (Tulsiani et al., 2017; Niu et al., 2018; Sun et al., 2019; Kluger et al., 2021) to learned deep representation, which we briefly review here. We start with generic 3D shape representations learned from data and continue with more-flexible part-based approaches."}, {"title": "2.1. Learned 3D Shape Representation", "content": "Learning-based methods for 3D shape representation have evolved significantly, beginning with explicit approaches such as voxel grids, point clouds, and meshes. Voxel-based methods (Wu et al., 2015; 2016; Choy et al., 2016; Dai et al., 2017) partition 3D space into grids, but are memory-intensive at finer resolutions, which can be mitigated using octrees (Riegler et al., 2017; Tatarchenko et al., 2017), but only up to a point. Point clouds reduce memory costs by representing shapes as surface points but ignore connectivity, which can compromise topological consistency (Fan et al., 2017; Yang et al., 2018; Achlioptas et al., 2018; Peng et al., 2021; Zeng et al., 2022). Meshes, though well-suited for detailed surface representation, impose a rigid topology that is difficult to modify (Groueix et al., 2018; Kanazawa et al., 2018; Wang et al., 2018; Pan & Jia, 2019).\nImplicit Neural Representations (INRs) offer a flexible alternative, defining shapes as continuous functions of the 3D space that encode the surface implicitly (Park et al., 2019; Mescheder et al., 2019; Chen & Zhang, 2019; Xu et al., 2019). It can then be recovered explicitly using meshing algorithms (Lorensen & Cline, 1987; Lewiner et al., 2003; Ju et al., 2002). Even though these meshing algorithms may not be themselves differentiable, differentiability can be preserved by relying on the implicit function theorem (Guillard et al., 2024), enabling back-propagation from the explicit surface, for example when optimizing a shape to maximize its aerodynamic performance (Baqu\u00e9 et al., 2018). Extensions enable shape manipulation (Hao et al., 2020), point-cloud reconstruction (Peng et al., 2020), and training directly from point data (Atzmon & Lipman, 2020; Gropp et al., 2020). Newer works (Sitzmann et al., 2020; Takikawa et al., 2021) improve the accuracy further with new latent representations, such as irregular grids (Zhang et al., 2022) or unordered sets (Zhang et al., 2023)."}, {"title": "2.2. Part Based Models", "content": "As effective as they are, the INRs described above model 3D shapes as single entities, limiting their capacity to represent structured, part-based composite objects. This requires decomposing the shapes into their component parts, which can be done in a supervised or unsupervised manner.\nUnsupervised Part Decomposition. Early unsupervised approaches learn shape abstractions using local primitives such as cuboids (Tulsiani et al., 2017; Zou et al., 2017; Sun et al., 2019; Smirnov et al., 2020; Yang & Chen, 2021), superquadrics (Paschalidou et al., 2019; 2020), anisotropic Gaussians (Genova et al., 2019), or convexes (Deng et al., 2020), approximating complex shapes as combinations of simpler parts. More recently, complex objects are better rep-"}, {"title": "3. Method", "content": "We propose PartSDF, a modular, part-based representation for composite shapes, designed for flexibility across applications that require both structured part manipulation and optimization. Given a dataset of composite shapes with known part decompositions, our model learns to represent each one independently within a compact latent space, while being able to maintain consistency when deforming them.\nAs shown in Figure 2, our framework consists of two primary components. First, the core of our model is a composite shape decoder that outputs a signed distance function (SDF) for each part, parameterized by a latent vector and a pose (Section 3.1). It is trained in an auto-decoding fashion (Park et al., 2019) in which the latent vectors and the decoder's weights are learned simultaneously, with supervision applied at both the global and part levels (Section 3.2). Second, our architecture supports secondary models for part encoding or generation, allowing further adaptation of part latents and poses for tasks such as shape reconstruction or generation, while maintaining the same core part decoder for efficient inference and manipulation (Section 3.3)."}, {"title": "3.1. Composite Shape Decoder", "content": "In our composite shape representation, shown in Figure 2(a), each part is described by a latent vector $z_p \\in \\mathbb{R}^Z$ and a pose $P_p \\in \\mathbb{R}^{10}$, consisting of a rotation quaternion $q_p \\in \\mathbb{R}^4$,"}, {"title": "3.2. Training", "content": "Let us consider a dataset D where each shape S is decomposed in up to P parts, given as the segmentation of its surface. To establish initial poses for each part, we fit simple primitives\u2014cuboids or cylinders\u2014to the segmented"}, {"title": "3.3. Part Encoding and Generation", "content": "Once PartSDF's decoder is trained, it is frozen to be used for downstream tasks, optionally in conjunction with separate specialized networks. While this requires training two networks independently, it makes the training of each one easier. Furthermore, the decoder need only been trained once and used again and again for the different tasks.\nEncoding To reconstruct a shape from a given modality, e.g., point clouds or images, encoders can be trained to directly predict part latents and poses, to then be decoded with PartSDF: with input data I corresponding to the shape of our training data D, encoders are trained to map this new modality to the part latents and poses of our pre-trained decoder. As an example, we show how to reconstruct unseen shapes for which part decomposition is unknown in Section 4.1. We do this by training a point cloud encoder to predict part latents and poses, which are then refined in an auto-decoding strategy and part-agnostic manner.\nGeneration For shape generation with a coherent part set, generative models can be trained to map random noise to the parts parametrization. Generative Adversarial Networks (GAN) (Goodfellow et al., 2014) have been used to generate shape latents, often dubbed latentGANs in related work (Achlioptas et al., 2018; Chen & Zhang, 2019) such as PQ-NET (Wu et al., 2020). Recently, diffusion mod-"}, {"title": "4. Experiments", "content": "In this section, we demonstrate how our method can be applied to various tasks and compare it to several part-based baselines. Further experimental details and additional re-sults are available in Appendix B and F, respectively.\nDatasets Obtaining high-quality composite shape data is challenging as many detailed datasets tend to remain private. Public datasets, such as ShapeNet (Chang et al., 2015) and PartNet (Mo et al., 2019), often suffer from over-segmentation and inconsistencies in part definitions across samples, or provide only coarse semantic segmentations that lack the granularity needed for precise part manipulation. To remedy this, we use three curated datasets that offer consistent and well-defined part decompositions: (1) Car, a hand-processed subset of ShapeNet in which the wheels of the cars are separated from the main body; (2) Mixer, a set of liquid mixers made of a central helix within a tube and two attach points (Vasu et al., 2022); and (3) Chair, a cleaned subset of ShapeNet chairs, segmented with Part-Net's semantic labels and further divided into individual legs and arms. There are 1046, 1949, and 1332 shapes in each dataset with 5, 4, and 8 parts, respectively. We use 80% of the data for training and the remaining 20% as the unseen test set.\nBaselines. For part-based baselines, we have unfortunately found no publicly available code for modern architectures such as ProGRIP (Deng et al., 2022), SPAGHETTI (O. et al., 2022) and PASTA (Li et al., 2024). We therefore use DAE-NET (Chen et al., 2023) that learns deformable part template in an unsupervised manner, BAE-NET (Chen et al., 2019) that uses weak supervision with 8 labeled shapes, and PQ-NET (Wu et al., 2020), a fully-supervised approach that supports shape generation. As these part-based baselines are several years old, we also compare against the state-of-the-art 3DShape2VecSet, or 3DS2VS for short (Zhang et al., 2023). It is not ideal because, not being part-based, it is not suitable for engineering design. However, it gives an upper bound on the accuracy that can currently be obtained if one ignores the part decomposition, which typically allows for higher precision than when enforcing it.\nMetrics. Reconstruction accuracy is assessed using three different metrics: Chamfer-Distance (CD) for surface accu-"}, {"title": "4.1. Shape and Part Reconstruction", "content": "We evaluate the accuracy of shape and part reconstruction across all datasets and methods. To encode new test shapes at inference time, our model relies on auto-decoding: It remains frozen while reconstruction losses are minimized with respect to the latent vectors. We also report results for"}, {"title": "4.2. Shape Generation", "content": "We compare PartSDF's shape generation abilities against those of 3DShape2VecSet and PQ-NET. The former relies on a diffusion model and the latter on a latentGAN (Achlioptas et al., 2018) to yield latent vectors from which shape or parts are decoded. For PartSDF, we leverage SALAD (Koo et al., 2023), a cascaded diffusion model that first gener-ates part poses and then part latents conditioned on these poses. This also enables us to generate shapes fitting specified pose decompositions, something that PQ-NET cannot do with its single latent space. We report MMD and COV metrics in Table 2 and show generated examples in Figure 5. PartSDF achieves consistently better results than PQ-NET, with more detailed composite shapes. Our results are also better than, or on-par with, those 3DShape2VecSet, with the added bonus that our models are part-aware whereas those of 3DShape2VecSet are not, and therefore not usable for engineering design. Furthermore, it requires training different models for shape reconstruction and generation, while we use only one for both."}, {"title": "4.3. Part Manipulation", "content": "We evaluate our model's ability to perform part-specific shape manipulation by editing part latent vectors and poses in Figure 6. Both latents and poses can be edited conjointly in PartSDF, we do so separately here for visualization purposes. When modifying part latents, the appearance of the corresponding parts is changed but the shape's structure and parts layout remain fixed. On the other hand, when changing poses, the parts layout adapts and their general appearance is unchanged. In all cases, the resulting composite shape preserves its overall consistency while fitting the editions. These qualitative results emphasize the flexibility of our part-based representation, showing that our model can adapt individual parts independently while preserving overall shape integrity."}, {"title": "4.4. Part Optimization", "content": "To demonstrate the effectiveness of PartSDF as a part-aware shape prior for downstream tasks, we address a key engineering problem: Refining the shape of a car to reduce the drag induced by air flowing over its surface S, without editing the wheels. Drag can be computed as the surface integral of the air pressure\n$\\textrm{drag}_p(S) = \\int_{S} -n_x(x) \\cdot p(x) dS(x), \t\\textrm{(9)}$"}, {"title": "5. Limitations", "content": "The main limitation of PartSDF is its reliance on part labels during training. For our intended application, computer-aided design, this is not a major issue because the decomposition of shapes into parts is known a priori. Thus PartSDF is particularly relevant in scenarios where objects are naturally created with part-aware structures. While this limits PartSDF's applicability to datasets without predefined decompositions\u2014such as most of those available on-line-it better matches with practical engineering requirements. Nonetheless, if generalization to unlabeled data is desired, PartSDF could be combined with co-segmentation methods to generate pseudo-labels for its training."}, {"title": "6. Conclusion", "content": "In this work, we introduced PartSDF, a modular and supervised approach specifically designed for composite shape representation. PartSDF enables flexible, part-based shape modeling, supporting independent part manipulation and optimization while maintaining overall shape coherence. Our method leverages a simple architecture, achieving strong performance across tasks such as shape reconstruction, ma-nipulation and generation.\nExperimental results demonstrate that PartSDF consistently outperforms baseline methods in part-level accuracy, and can be adapted to a wide range of tasks, highlighting its effectiveness as a robust shape prior for composite structures. This flexibility makes PartSDF particularly suited for applications in fields like engineering design, where precise control over individual components is essential for customization and optimization.\nWhile PartSDF achieves promising results, future work will explore enhancing part interactions to further support appli-cations involving highly dynamic shapes or complex inter-part dependencies. Furthermore, developing more advanced topological supervision for each part should also be investi-gated to help prevent topologically inconsistent predictions, further improving its the robustness and applicability."}]}