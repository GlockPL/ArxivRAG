{"title": "Beyond Trend Following: Deep Learning for Market Trend Prediction", "authors": ["Fernando Berzal", "Alberto Garc\u00b4\u0131a"], "abstract": "Trend following and momentum investing are com mon strategies employed by asset managers. Even though they can be helpful in the proper situations, they are limited in the sense that they work just by looking at past, as if we were driving with our focus on the rearview mirror. In this paper, we advocate for the use of Artificial Intelligence and Machine Learning techniques to predict future market trends. These predictions, when done properly, can improve the performance of asset managers by increasing returns and reducing drawdowns.", "sections": [{"title": "I. INTRODUCTION", "content": "TREND following or trend trading is an investment strat egy based on the expectation of price movements to continue in the same direction: buy an asset when its price goes up, sell it when its price goes down. For its application, obviously, you need a particular criterion to detect when prices move in a particular direction over time. Since every investor uses his own criterion, a market trend is often just a perceived tendency within a financial market.\nTraditional trend following is usually done on futures. Just follow trends on a large, diversified set of futures markets, covering major asset classes. Diversification is key: with multiple assets with low or negative correlations, you can achieve higher returns at a lower risk.\nTrend following on stocks can easily yield negative returns in the short side (when prices go down). When we trade only on the long side, it does not always add any real value. Compared with a passive index ETF, trend following requires additional work and creates potential risks, yet it does not always yield actual benefits.\nCole Wilcox and Eric Crittenden [1] proposed the use of an all-time high as the entry criteria: buy on all time high and sell at a trailing stop set at 10 times the 40-day ATR [average true range], using a large stock universe. Trend following on single stocks, or a few of them, however, is not attractive for the risk you have to assume.\nStandard trend following is not expected to work with stocks, since their correlation is too high. But momentum investing does. When a stock price goes up for a while, the likelihood of rising higher is greater than the likelihood of falling. Likewise, a stock going up faster than other stocks is likely to keep going up faster than other stocks. This is the momentum effect, known at least since the 1960\u2019s [2].\nWhy does momentum investing work? According to aca demic studies [3], just because people overreact to information. One explanation is that people who buy past winners and sell past losers temporarily move prices. An alternative explanation is that the market underreacts to information on short-term prospects but overreacts to information on long-term prospects. In any case, choosing the top past performers can yield positive returns. Additional safeguards can also be employed, such as not investing in stocks during bear markets.\nFor instance, Andreas Clenow [4] employs the following trading rules on a weekly basis: rank stocks on volatility adjusted momentum (using an exponential 90-day regression, multiplied by its coefficient of determination), calculate posi tion sizes (targeting a daily move of 10 basis points), check the index filter (S&P 500 above its 200-day moving average), and build your portfolio. Individual stocks are disqualified when they are below their 100-day moving average or have experienced a gap over 15%. When, in the weekly portfolio rebalancing, a stock is no longer in the top 20% of the S&P 500 ranking or fails to meet the qualification criteria (moving average and gap), it is sold. It is replaced by other stocks only if the index is in a positive trend. Twice per month, position sizes are also rebalanced to control risk.\nWhat is the difference between trend following and mo mentum investing? Apart from the fact that both are valid investment strategies for different situations and asset classes, the key factor is that trend following just employs the asset\u2019s past returns, i.e., its time series momentum. In contrast, momentum investing compares an asset\u2019s momentum to the momentum of other assets. Whereas trend following is es sentially autoregressive, momentum investing takes (a limited) context into account.\nA common drawback of both trend following and momen tum investing is that they reap benefits after the current trend is already underway. Can we do better? Most investment professionals might say that no, you cannot reliably predict changes in market trends.\nThe ACCI\u00b7ON project started with the goal of using Artifi cial Intelligence techniques to predict trends in financial mar kets, including both equity markets and fixed-income markets."}, {"title": "II. INVESTMENT PHILOSOPHY", "content": "Instead of trying to design a fully-automated algorithmic trading decision, the goal of the ACCION project was, from its inception, the design of a tool to support the work of asset managers, not to replace them. Human asset managers are in charge of their assets under management [AuM] and they should feel fully responsible for their management decisions."}, {"title": "A. Risk Indicators", "content": "Deciding when to change the composition of a portfolio is one of the key decisions an asset manager has to make. Proper timing is important, yet it is really hard for a human being to determine when to buy/sell assets given the overabundance of signals and the deluge of information available at his fingertips. Hence, ACCI decided to base its investment strategy on risk indicators that help asset managers time buying/selling decisions.\nThe basic idea of a risk indicator in this context is that a single number summarizes the current market situation, indicating the probability of a severe drawdown in the market of interest (e.g. S&P 500, NASDAQ 100, investment-grade bonds, or high-yield bonds). When such an indicator surpasses a predefined threshold, the asset manager can take a more risk-seeking position in his portfolio. When the indicator falls below a given value, the asset manager should cover his positions and defensively switch to a more risk-averse portfolio.\nGiven the prior experience of ACCI managers, the risk indi- cators are real-valued numbers, between -1 and +1. When the risk indicator is negative, asset managers should be defensive with respect to risks in the market the indicator is designed for. When an indicator approaches -1, the probability of a severe drawdown in its market tends to one. When the risk indicator is positive, asset managers could take a more positive attitude towards the market trend. In the limit, when the risk indicator approaches +1, the probability of a severe drawdown tends to zero. Of course, risk indicator models are probabilistic and some uncertainty is always present.\nAs we mentioned before, asset managers are always in charge. They can modulate their risk exposure by establishing different thresholds for changing their portfolio composition. When their outlook is optimistic, they can set a lower threshold for their positive portfolio. When their outlook is pessimistic, they can set a higher threshold for abandoning their defensive portfolio."}, {"title": "B. The Limits of Linear Models", "content": "Some financial institutions and asset managers resort to lin- ear models when designing their own risk indicators. Billions of dollars in assets under management are allocated using strategies that rely on linear models.\nA linear model is of the form $\\hat{y} = \\sum w_i x_i$, where $\\hat{y}$ is the prediction (i.e. the risk indicator), the different $x_i$ are the variables, features, or factors taken into account to make the prediciton, and the weights $w_i$ model the importance of each feature. Those weights can be learnt using a standard linear regression model.\nFrom a formal point of view, a linear model is only able to separate between linearly-separable classes. In other words, the decision frontier of such a model is a hyperplane (the generalization of a three-dimensional plane and a straight line in a two-dimensional space). A linear model cannot differentiate between non-linearly-separable classes, no matter how it is learnt.\nGiven that the World is highly nonlinear, linear approxi- mations are not always suitable. They underfit data and this underfitting causes an error that cannot be suppressed because of the intrinsic limitations of linear models. In particular, given a linear model:\n*   A change $\\Delta x_i$ in one of the model variables provokes a change $\\Delta \\hat{y} = w_i \\Delta x_i$ in the model prediction.\n*   That change, $\\Delta \\hat{y}$ is always the same, no matter what the current context is. When $x_i$ has an associated positive weight ($w_i > 0$), the prediction always changes in the same direction of the change observed in the input vari- able $x_i$. Likewise, a negative weight ($w_i < 0$) makes input variable and prediction change in opposite directions.\n*   As a consequence of model linearity, changes in the model output are always proportional to changes in the model inputs. In extreme situations, model predictions are slow to change, given that input changes are often gradual."}, {"title": "C. On the Use of Risk Indicators by Fund Managers", "content": "Given the complexity of financial markets, asset managers face many challenges when deciding how to allocate assets and when to change their portfolio composition. A risk indicator can help alleviate some of their burden by providing a timely signal they can use to change their risk exposure.\nHow can asset managers use the information provided by a risk indicator? They can track its value to modulate their risk exposure according to the current market situation. Let us recall that a risk indicator for a given market predicts the probability of a severe drawdown (e.g. > 5% in equity markets, > 2% in bond markets).\nACCI provides risk indicators for different markets, includ- ing the S&P 500 stock index. In the following paragraphs, we illustrate the use of the ACCI S&P 500 risk indicator for different scenarios that might be suitable investment strategies for particular investors:\n*   Risk-on/risk-off strategy (e.g., XLK/XLP): The investor switches between two assets depending on the value of the risk indicator for the stock market. When the risk indicator is high (i.e., low drawdown probability), you invest into a procyclical sector, such as technology. In this case, we use the XLK ETF (Technology Select Sector SPDR Fund). When the risk indicator is low, i.e., below a predefined threshold (i.e., a higher drawdown probability), you opt for investing in a countercyclical sector, such as consumer staples (goods like foods and beverages, household goods, and hygiene products, as well as alcohol and tobacco, that people are unable -or unwilling to cut out of their budgets regardless of their financial situation). In this case, we use the XLP ETF (Consumer Staples Select Sector SPDR Fund).\n*   Cyclical strategy, with a more diversified portfolio: Using the same decision criteria we used in the risk- on/risk-off example, we switch between two predefined portfolios depending on the value of the risk indicator for the overall stock market. When the risk indicator is high, we use a 100% equity portfolio with a selection of procyclical sectors, which are expected to offer positive returns when the outlook is positive. When the risk indicator is low, we reduce our equity exposure to 30%, with a combination of countercyclical assets, suitable for more uncertain times."}, {"title": "III. MODEL TRAINING FOR MARKET TREND PREDICTION", "content": "In the previous section, we introduced the use of risk indicators in asset management. In this section, we delve into the details of how they can be designed for particular markets.\nAs described above, risk indicators are predictive models for drawdown periods. Drawdown, when talking about invest ments, is a measure of the decline from a previous historical peak in the cumulative return or current value of an investment strategy. In other words, we focus on the downside risk, the probability that an asset portfolio will fall in price. Given historical data, Machine Learning techniques can be used to model that probability."}, {"title": "A. Machine Learning", "content": "Machine Learning [ML] is a field within Artificial In telligence [AI] that studies the design and development of algorithms that can learn from data. Hopefully, the models learnt using ML, apart from working properly with the data they were trained on, should also generalize well to unseen data."}, {"title": "B. Machine Learning Techniques", "content": "We use Machine Learning techniques to design risk indica tors for financial markets, both fixed-income and equity mar kets. These risk indicators are predictive models for drawdown periods. Since they use labelled historical data to be trained on, they can be built using supervised ML techniques.\nIn supervised learning techniques, training data contains both input variables (e.g., a vector of predictor variables) and the desired model output. From input-output pairs, a model is learnt from the training dataset. Where do the outputs come from? Typically, an human expert has labelled each training set example with the desired output. Once the training set is prepared, it is the turn of the computer to learn from it and train a suitable model using a particular learning algorithm.\nA wide range of supervised learning algorithms are avail able, each one with its own strengths and weaknesses. In fact, a well-known theoretical result, the \u201cno free lunch theorem,\u201d asserts that there is no single learning algorithm that works best on all supervised learning problems [9], a result that also applies to optimization techniques [10].\nGiven that we cannot know beforehand which particular ML technique will work best for a particular problem (we might have some hints, yet they are never conclusive), we have tested multiple ML techniques in the ACCI\u00b7ON project to design ACCI risk indicators.\nTesting multiple ML algorithms lets us compare the differ ences among the ML models they train. Our comparison takes into account both quantitative and qualitative aspects. From a quantitative point of view, we are interested in model accuracy, precision, and recall, as well as in the episodic behavior of the risk indicator when market trends change. For us, the dynamic response of a risk indicator to a trend reversal is paramount, as we discussed when describing the limitations of linear models. From a qualitative point of view, model interpretability is desirable, yet not essential, but model behavior is crucial. Even when a binary output model might yield better quantitative results, a zero-one response does not help asset managers feel confident on the risk indicator value, as changes in the indicator seem to be unpredictable. A gradual response is often preferable, when daily changes in the risk indicator hint at current potential trends in the underlying market.\nIn the ACCI\u00b7ON project, a wide range of supervised ML techniques have been evaluated:\n*   Linear models, even when they exhibit some undesirable properties, such as their lack of responsiveness when a market trend is reversed, are still useful as a baseline. They provide a foundation on which we can build on to compare the effectiveness of more sophisticated learning algorithms. In our experiments, we tested linear regres sion for regression problems as well as logistic regression for classification problems.\n*   Support vector machines: A support vector machine, or SVM, in addition to linear classification, can efficiently perform a non-linear classification using what is called the kernel trick. Since linear approximations are not suitable for the non-linear world of financial markets, SVMs provide an interesting alternative, even though they are not truly scalable. SVMs represent data through pairwise similarity comparisons between original data observations. SVMs implicitly represent the original data in transformed coordinates within a higher dimensional space (actually, a potentially infinite-dimensional space) and identify the maximum-margin hyperplace in that space. Even though the decision frontier is still linear in the transformed coordinate space, it corresponds to a non linear frontier in the original space. SVMs can be used to solve both classification problems [11] and regression problems [12].\n*   Ensembles are popular for winning data mining competi tions. In ML, ensemble methods combine multiple learn ing algorithms. As musical ensembles combine multiple musical instruments to achieve a more harmonious result, ML ensembles obtain better predictive performance than any of the individual learning algorithms in the ensemble. For that to occur, the ensemble must be designed so that we can ensure that the individual algorithms within the esemble do not always make the same mistakes. From a quantitative point of view, they can achieve the best numerical results, hence their popularity in Kaggle competitions [13], even though they might be unsuitable from a qualitative point of view. Two of the best-known ensemble learning algorithms are random forests [14] and gradient boosting [15].\n    *   A random forest, proposed by Leo Breiman from the University of California, Berkeley, is an ensemble of decision trees. A decision tree is a symbolic model most economists are already familiar with.\n    *   Gradient boosting, proposed by Jerome Friedman from Stanford University, is based on boosting. Most boosting algorithms consist of iteratively learning weak classifiers and adding them to a final strong classifier. A weak classifier is only slightly correlated with the true classification (it can label examples better than random guessing). The resulting strong learner is a classifier that is arbitrarily well-correlated with the true classification. The predition model obtained by gradient boosting is an ensemble of weak prediction models. Gradient boosting algorithms are iterative functional gradient descent algorithms; that is, they optimize a cost function over function space by iteratively choosing a function (weak hypothesis) that points in the negative gradient direction.\n*   Deep learning models are based on artificial neural networks [16] [17] [18]. Artificial neural networks are connectionist models, formerly known as Parallel Dis tributed Processing (PDP) models.\nNeural networks consist of individual neurons, which are simple computational elements of the form\n$y = f(\\sum w_i x_i) = f(\\vec{w} \\cdot \\vec{x})$\nThe nonlinear function f is the neuron activation func tion, typically a sigmoidal function, such as the logistic function and the hyperbolic tangent, or a rectified linear function. In the former case, the neuron is said to be sigmoidal; in the latter, it is a ReLU [Rectified Linear Unit].\nMultiple neurons can be put in parallel to create a network layer with vector input $\\vec{x}$, vector output $\\vec{y}$, weight matrix W, and activation function f, to be applied element-wise:\n$\\vec{y} = f (W \\vec{x})$\nMultiple network layers can be stacked to create a feed forward neural network:\n$\\vec{y} = f (W_L f (W_{L-1} ...f (W_1\\vec{x})))$\nThe last layer, characterized by the weight matrix $W_L$, is the network output layer. The input vector $\\vec{x}$ is the input layer, which performs no computation, just provides the input to the network. Inner layers are called hidden layers. When the network has more than one hidden layer, the network is said to be a deep neural network, hence the term \u2018deep learning\u2019 to refer to the learning techniques that allow us to train deep neural networks.\nThe weights of an artificial neural network are typically trained by stochastic gradient descent with the help of a dynamic programming algorithm called backpropaga tion. Backpropagation is an efficient gradient estima tion method for neural network models, also known as the reverse mode of automatic differentiation or reverse accumulation. Backpropagation computes the gradient of a loss function with respect to the weights of the network for a single input-output example. It computes the gradient one layer at a time and iterates backward from the last layer to avoid redundant calculations of intermediate terms in the Leibniz chain rule that is applied to compute the gradient.\nIn contrast to symbolic models (e.g., decision trees) and statistical techniques (e.g. SVMs), neural networks were originally proposed as computational models to describe aspects of human perception, cognition, and behaviour, the learning processes underlying such behaviour, and the storage and retrieval of information from memory [19]. From a computational perspective, feed-forward neural networks can be interpreted as models that learn to extract hierarchical features from data. The first layers of a feed- forward network learn to extract relatively simple features directly from the input data. As we advance through a deep network, neurons learn to represent more complex features from the features extracted by previous network layers. Deep learning can, therefore, be viewed as hi- erarchical feature representation [20], hence the name of one of the major conferences in the area (ICLR, the International Conference on Learning Representations)."}, {"title": "C. Model Output", "content": "The first decision we must make when building a predictive model is the nature of our target variable, the value we are trying to predict, typically denoted by \u0177. If we choose to predict a categorical, discrete, or nominal variable, we build a classification model. If we opt for predicting a continuous real-valued variable, we are building a regression model.\nMarket trend prediction can be modeled either as a classi- fication problem or as a regression problem:\n*   Trend prediction as a classification problem: Our target variable will be a binary variable that indicates whether or not our market of interest is immersed in a drawdown period. The drawdown period covers from peak to trough, from a local maximum to the following local minimum.\n    How are local maxima and minima chosen? There are several alternatives:\n    *   We can choose the top-k drawdown periods accord- ing to their magnitude.\n    *   Alternatively, we can choose every drawdown period where our market of interest drops beyond a prede- fined threshold (in percentage points).\n    In both cases, we might establish a time horizon.\n    For classification problems, the cross-entropy, also known as logarithmic loss or log loss, is a suitable loss function for training a predictive model:\n$CE = -[y \\log \\hat{y} + (1 - y) \\log(1 \u2013 \\hat{y}) ]$\n    where y is the desired output and $\\hat{y}$ is our prediction.\n*   Trend prediction as a regression problem: We can also interpret our trend prediction goal as a regression problem.\n    In this case, we can try to predict:\n    *   The magnitude of the expected market drawdown at each time period.\n    *   The expected market return until the next market trend reversal.\n    *   The overall market return during the whole current market trend.\n    *   The overall market drawdown during a bear market.\n    As before, we might consider an unlimited time horizon (for bear markets) or set a predefined time horizon in accordance to the frequency of our particular trading strategy.\n    For regression problems, the mean squared error is a suitable loss function for training our predictive models:\n$MSE = \\frac{1}{N}\\sum_{i=1} (y_i - \\hat{y}_i)^2$\n    where y is the desired output and $\\hat{y}$ is our prediction.\nNo matter if we model our prediction as a classification or regression problem, we must also take into account that, for our prediction to be actionable, it must be of the form $\\hat{y}(t + 2) = f(x(t))$. Our prediction at the close of a trading session is a prediction valid not for the immediately-following trading session, but for the session after that. In other words, we must have the opportunity to trade today using yesterday's session data to prepare for tomorrow's trend."}, {"title": "D. Input Variables", "content": "Simple forecasting models are autoregressive. In statistics, econometrics, and signal processing, the output or target variable of an autoregressive model depends only on its own previous values. In time-series analysis, we predict the future values of a time series based on its past values. Autoregressive models are widely used in technical analysis to forecast future security prices.\nMore advanced forecasting models take additional context into account. That context can be provided by additional variables or time series. For instance, instead of predicting future S&P 500 values using only past S&P 500 values, we might also incorporate bond market data as an additional input to our predictive model.\nWith the initial support of Umberto M\u00e1rmol and other economists at ACCI Capital Partners, we analyzed a multitude of economic variables that might serve as leading indicators for predicting changes in market trends. It is essential that they are leading indicators because we are especially interested in detecting changing trends as soon as they happen. Many economic variables are either lagging indicators (they hint at trends after they have started) or are published with too much delay to be useful when we expect a quick response from our trend prediction model. These were finally discarded in our risk indicator models.\nOur final risk indicator models incorporate dozens of dif- ferent variables, sometimes hundreds. In broad terms, the variables we use as input can be grouped into the following six categories:\n*   Stock market indexes for main global and regional equity markets, including the S&P 500, the MSCI World, the NASDAQ 100, or the Russell 2000, as well as the S&P 500 Equal Weight Index and many other regional stock market indexes.\n*   Bond market data, including US Treasury bonds, their yield curve, government bonds from the major economies of the World, commercial paper interest rates, and cor- porate bonds (both investment-grade and high-yield).\n*   Currency exchange rates for the World major currencies and currency baskets such as the U.S. Dollar Index (DXY).\n*   Futures market data, including commodity indexes (GSCI and DJCI), commodity futures, energy (oil and natural gas), and precious metals (e.g., gold).\n*   Volatility indexes associated to different markets, includ- ing the well-known VIX and MOVE volatility indexes, as well as volatility measures for commodities, gold, currencies, stocks, and bonds.\n*   Macroeconomic variables including leading indexes (OECD and BBK), ISM data, freight indexes, advance retail sales, consumer sentiment data, monetary data, or weekly initial unemployment claims, among many others.\nA wide range of input variables were chosen for their ability to move the particular markets we were designing risk indicators for or just for their usefulness as leading indicators. Using scores, even hundreds, of input variables in a predictive model causes technical problems that are not always solvable using traditional techniques. Fortunately, deep learning models were up to the task and helped us improve the predictive power of our risk indicators."}, {"title": "E. Feature Engineering", "content": "Once input variables have been selected, they must be prepared to be used as the input to Machine Learning models. First of all, a proper encoding must be selected, often depend- ing on the particular ML technique to be used for training a predictive model.\nEven when no additional variables are included, apart from those of the time series we wish to model, we must decide whether we provide the time series values as they are acquired or we preprocess them to make it easier for the ML algorithm to learn a good model. For instance, when we are predicting the evolution of the S&P 500 stock index, using index values would hamper most ML algorithms, since the index is near its all-time high and current index values have never been observed in the past. It is much more reasonable to use percentage changes, always as model input and as model output in the case of regression models.\nBefore using some ML techniques, the scale of the input data must also be adjusted. Even when ML techniques are able to cope with different scales for different inputs, learning is easier if we do some preprocessing. It is usually a good idea to normalize or standardize all the model inputs before proceeding further. Scale changing transformations include the following:\n*   Feature scaling, unity-based normalization, or [0,1] nor- malization brings all values into the [0,1] unit interval:\n$X_{[0,1]} = \\frac{X - X_{min}}{X_{max} - X_{min}}$\n*   Min-max feature scaling or min-max normalization brings values into the [a,b] interval:\n$X_{[a,b]} = a + \\frac{X - X_{min}}{X_{max} - X_{min}}(b-a)$\n*   Robust normalization or robust standardization employs the median and interquartile range (IQR) to be more robust against outliers in data:\n$X_{robust} = \\frac{X - X_{median}}{X_{IQR}}$\n*   Standardization or z-score normalization is a more com- mon approach, using the mean \u00b5 and the standard devi- ation \u03c3:\n$Z = \\frac{X - \\mu}{\\sigma}$"}, {"title": "F. Model Hyperparameters", "content": "Each Machine Learning technique is designed for building a particular kind of model (e.g.", "case": "n*   Recurrent neural networks [RNNs]: In feed-forward neural networks", "38]": "n    $h_t = f(W x_t + U h_{t-1"}, "n    The output of hidden layers now depends on both their current input xt, through their weight matrix W, and their previous output $h_{t-1}$, through a second weight matrix U.\n    Training RNNs is performed by backpropagation through time, ot BPTT [39], which consists of unrolling or un- folding the recurrent network and performing backpropa- gation on the unrolled computational graph associated to the network.\n    Gated RNNs create paths through time whose derivatives do not vanish nor explode, a common problem with deep neural networks and Elman's RNNs.\n*   The long short-term memory [LSTM] model introduced self-loops to enable paths where the gradient can flow for long [40]. The behavior of a LSTM cell with a forget gate is defined by the following equations:\n    $f_t = \\sigma_g(W_f x_t + U_f h_{t-1}+b_f)$\n    $i_t = \\sigma_g(W_i x_t + U_i h_{t-1} + b_i)$\n    $O_t = \\sigma_g(W_o x_t + U_o h_{t-1} + b_o)$\n    $\\tilde{C}_t = \\sigma_c(W_c x_t + U_c h_{t-1} + b_c)$\n    $C_t = f_t C_{t-1} + i_t \\tilde{C}_t$\n    $h_t = O_t \\sigma_h (C_t)$\n    where, as in simple RNNs, the matrices W and U contain the weights for inputs and recurrent connections.\n    A LSTM cell contains an input gate i that decides which pieces of new information to store in the current state, an output gate o that controls which pieces of information in the current state to output, a forget gate f that decides what information to discard from a previous state b, a hidden state vector h (i.e., the output of the LSTM cell), and a cell state vector c.\n    Gated recurrent units [GRUs] [41] are like LSTMs, with a gating mechanism to input or forget certain features, but without a context vector or output gate, resulting in fewer parameters than LSTMs:\n    $z_t = \\sigma(W_z x_t + U_z h_{t-1} + b_z)$\n    $r_t = \\sigma(W_r x_t + U_r h_{t-1} + b_r)$\n    $\\hat{h}_t = \\phi(W_h x_t + U_h (r_t h_{t\u22121}) + b_h)$\n    $h_t = (1 - z_t) h_{t-1} + z_t \\odot \\hat{h}_t$\n    where $\\odot$ represents the Hadamard product (i.e., element- wise multiplication), z is the update gate, r is the reset gate, and h is the output vector.\n    The recurrent networks we have discussed have a causal structure, their state at time t only depends on data from the past, which is suitable for time series prediction. Other applications, however, employ bidirectional RNNs and their prediction depends on whole input sequences. Such architecture is suitable for dealing with coarticulation in speech recognition, optical character recognition for hand-written manuscripts, or word disambiguation in natural language processing.\n    RNNs have been the most common architecture for dealing with sequential data, at least until the appearance of transformers. In their gated version, i.e. LSTMs and GRUs, they have been used with some success in the implementation of trading systems [42] [43]. However, RNN training is problematic and limited when they have to deal with long-term dependencies.\n*   Convolutional neural networks [CNNs] are widely- used in signal processing applications, including speech recognition and computer vision (e.g., image classifica- tion, object detection and tracking...). They are based on the discrete convolution operation:\n    $y(t) = (x * w)(t) = \\sum_i x(i) w(t - i)$\n    whose first operator x is the input and whose second operator w is often referred to as the kernel or convolution mask. In neural networks, the kernel or mask w can be learnt using backpropagation.\n    In CNNs, there are no recurrent connections. A network topology with weight sharing substitutes for the recurrent connections of RNNs. Whereas RNNs receive their input sequentially (one value at a time), CNNs receive their input in parallel (the whole sequence at once).\n*   Time delay neural networks [TDNNs] [44] were proposed to classify patterns with shift-invariance (i.e. they do not require explicit segmentation prior to classification) and model context at each layer of the network. They perform a 1D convolution across time and they were originally proposed for speech recognition [45] [46], where the automatic determination of precise segments or feature boundaries was difficult or impossible.\n*   Attention mechanisms and transformers [51] also eliminate the recurrent connections in RNNs, without arbitrarily restricting connections between neurons in the nework as CNNs do.\n    Transformers convert their sequential input into a nu- merical representation, a sequence of token vectors. An embedding layer converts tokens and positions of the tokens into vector representations. At each transformer layer, tokens are contextualized within the scope of the context window with other tokens via a parallel multi- head attention mechanism that allows the signal for key tokens to be amplified and the signal for less important tokens to be attenuated.\n    Transformer layers carry out repeated transformations on the vector representations, extracting more and more information by alternating attention and feed-forward layers.\n    The components of the Transformer attention mechanism are two vectors of dimension dk, the query q and the key k, and a third vector of dimension du, the values v. The matrices Q, K, and V pack sets of queries, keys, and values. Three projection matrices $W^Q$, $W^K$, and $W^V$ generate different subspace representations of the query, key, and value matrices. Finally, the projection matrix Wo is used for the multi-head attention output. The output of the attention mechanism is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key. The scaled dot-product attention computes\n    $\\text{attention}(Q, K, V) = \\text{softmax} (\\frac{QK^T}{\\sqrt{d_k}}) V$\n    where each output of the softmax(```json\n{\n        \"title\": null,\n        \"authors\": null,\n        \"abstract\": null,\n        \"sections\": ["]}