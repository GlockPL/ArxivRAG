{"title": "Beyond Trend Following: Deep Learning for Market Trend Prediction", "authors": ["Fernando Berzal", "Alberto Garc\u00eda"], "abstract": "Trend following and momentum investing are common strategies employed by asset managers. Even though they can be helpful in the proper situations, they are limited in the sense that they work just by looking at past, as if we were driving with our focus on the rearview mirror. In this paper, we advocate for the use of Artificial Intelligence and Machine Learning techniques to predict future market trends. These predictions, when done properly, can improve the performance of asset managers by increasing returns and reducing drawdowns.", "sections": [{"title": "I. INTRODUCTION", "content": "Trend following or trend trading is an investment strategy based on the expectation of price movements to continue in the same direction: buy an asset when its price goes up, sell it when its price goes down. For its application, obviously, you need a particular criterion to detect when prices move in a particular direction over time. Since every investor uses his own criterion, a market trend is often just a perceived tendency within a financial market.\nTraditional trend following is usually done on futures. Just follow trends on a large, diversified set of futures markets, covering major asset classes. Diversification is key: with multiple assets with low or negative correlations, you can achieve higher returns at a lower risk.\nTrend following on stocks can easily yield negative returns in the short side (when prices go down). When we trade only on the long side, it does not always add any real value. Compared with a passive index ETF, trend following requires additional work and creates potential risks, yet it does not always yield actual benefits.\nCole Wilcox and Eric Crittenden [1] proposed the use of an all-time high as the entry criteria: buy on all time high and sell at a trailing stop set at 10 times the 40-day ATR [average true range], using a large stock universe. Trend following on single stocks, or a few of them, however, is not attractive for the risk you have to assume.\nStandard trend following is not expected to work with stocks, since their correlation is too high. But momentum investing does. When a stock price goes up for a while, the likelihood of rising higher is greater than the likelihood of falling. Likewise, a stock going up faster than other stocks is likely to keep going up faster than other stocks. This is the momentum effect, known at least since the 1960's [2].\nWhy does momentum investing work? According to academic studies [3], just because people overreact to information. One explanation is that people who buy past winners and sell past losers temporarily move prices. An alternative explanation is that the market underreacts to information on short-term prospects but overreacts to information on long-term prospects. In any case, choosing the top past performers can yield positive returns. Additional safeguards can also be employed, such as not investing in stocks during bear markets.\nFor instance, Andreas Clenow [4] employs the following trading rules on a weekly basis: rank stocks on volatility-adjusted momentum (using an exponential 90-day regression, multiplied by its coefficient of determination), calculate position sizes (targeting a daily move of 10 basis points), check the index filter (S&P 500 above its 200-day moving average), and build your portfolio. Individual stocks are disqualified when they are below their 100-day moving average or have experienced a gap over 15%. When, in the weekly portfolio rebalancing, a stock is no longer in the top 20% of the S&P 500 ranking or fails to meet the qualification criteria (moving average and gap), it is sold. It is replaced by other stocks only if the index is in a positive trend. Twice per month, position sizes are also rebalanced to control risk.\nWhat is the difference between trend following and momentum investing? Apart from the fact that both are valid investment strategies for different situations and asset classes, the key factor is that trend following just employs the asset's past returns, i.e., its time series momentum. In contrast, momentum investing compares an asset's momentum to the momentum of other assets. Whereas trend following is essentially autoregressive, momentum investing takes (a limited) context into account.\nA common drawback of both trend following and momentum investing is that they reap benefits after the current trend is already underway. Can we do better? Most investment professionals might say that no, you cannot reliably predict changes in market trends.\nThe ACCI-ON project started with the goal of using Artificial Intelligence techniques to predict trends in financial markets, including both equity markets and fixed-income markets."}, {"title": "II. INVESTMENT PHILOSOPHY", "content": "Instead of trying to design a fully-automated algorithmic trading decision, the goal of the ACCION project was, from its inception, the design of a tool to support the work of asset managers, not to replace them. Human asset managers are in charge of their assets under management [AuM] and they should feel fully responsible for their management decisions."}, {"title": "A. Risk Indicators", "content": "Deciding when to change the composition of a portfolio is one of the key decisions an asset manager has to make. Proper timing is important, yet it is really hard for a human being to determine when to buy/sell assets given the overabundance of signals and the deluge of information available at his fingertips. Hence, ACCI decided to base its investment strategy on risk indicators that help asset managers time buying/selling decisions.\nThe basic idea of a risk indicator in this context is that a single number summarizes the current market situation, indicating the probability of a severe drawdown in the market of interest (e.g. S&P 500, NASDAQ 100, investment-grade bonds, or high-yield bonds). When such an indicator surpasses a predefined threshold, the asset manager can take a more risk-seeking position in his portfolio. When the indicator falls below a given value, the asset manager should cover his positions and defensively switch to a more risk-averse portfolio.\nGiven the prior experience of ACCI managers, the risk indicators are real-valued numbers, between -1 and +1. When the risk indicator is negative, asset managers should be defensive with respect to risks in the market the indicator is designed for. When an indicator approaches -1, the probability of a severe drawdown in its market tends to one. When the risk indicator is positive, asset managers could take a more positive attitude towards the market trend. In the limit, when the risk indicator approaches +1, the probability of a severe drawdown tends to zero. Of course, risk indicator models are probabilistic and some uncertainty is always present.\nAs we mentioned before, asset managers are always in charge. They can modulate their risk exposure by establishing different thresholds for changing their portfolio composition. When their outlook is optimistic, they can set a lower threshold for their positive portfolio. When their outlook is pessimistic, they can set a higher threshold for abandoning their defensive portfolio."}, {"title": "B. The Limits of Linear Models", "content": "Some financial institutions and asset managers resort to linear models when designing their own risk indicators. Billions of dollars in assets under management are allocated using strategies that rely on linear models.\nA linear model is of the form $\\hat{y} = \\sum w_i x_i$, where $\\hat{y}$ is the prediction (i.e. the risk indicator), the different $x_i$ are the variables, features, or factors taken into account to make the prediciton, and the weights $w_i$ model the importance of each feature. Those weights can be learnt using a standard linear regression model.\nFrom a formal point of view, a linear model is only able to separate between linearly-separable classes. In other words, the decision frontier of such a model is a hyperplane (the generalization of a three-dimensional plane and a straight line in a two-dimensional space). A linear model cannot differentiate between non-linearly-separable classes, no matter how it is learnt.\nGiven that the World is highly nonlinear, linear approximations are not always suitable. They underfit data and this underfitting causes an error that cannot be suppressed because of the intrinsic limitations of linear models. In particular, given a linear model:\n\u2022\tA change $\\Delta x_i$ in one of the model variables provokes a change $\\Delta \\hat{y} = w_i \\Delta x_i$ in the model prediction.\n\u2022\tThat change, $\\Delta \\hat{y}$ is always the same, no matter what the current context is. When $x_i$ has an associated positive weight ($w_i > 0$), the prediction always changes in the same direction of the change observed in the input variable $x_i$. Likewise, a negative weight ($w_i < 0$) makes input variable and prediction change in opposite directions.\n\u2022\tAs a consequence of model linearity, changes in the model output are always proportional to changes in the model inputs. In extreme situations, model predictions are slow to change, given that input changes are often gradual."}, {"title": "C. On the Use of Risk Indicators by Fund Managers", "content": "Given the complexity of financial markets, asset managers face many challenges when deciding how to allocate assets and when to change their portfolio composition. A risk indicator can help alleviate some of their burden by providing a timely signal they can use to change their risk exposure.\nHow can asset managers use the information provided by a risk indicator? They can track its value to modulate their risk exposure according to the current market situation. Let us recall that a risk indicator for a given market predicts the probability of a severe drawdown (e.g. > 5% in equity markets, > 2% in bond markets).\nACCI provides risk indicators for different markets, including the S&P 500 stock index. In the following paragraphs, we illustrate the use of the ACCI S&P 500 risk indicator for different scenarios that might be suitable investment strategies for particular investors:\n\u2022\tRisk-on/risk-off strategy (e.g., XLK/XLP): The investor switches between two assets depending on the value of the risk indicator for the stock market. When the risk indicator is high (i.e., low drawdown probability), you invest into a procyclical sector, such as technology.\n\u2022\tCyclical strategy, with a more diversified portfolio:\nSystematic allocation strategy. As a third example, we include a complete strategy with 3 different base portfolios adjusted to different risk levels. These base portfolios cover a more diversified asset base and comply with the requirements of the UCITS [Undertakings for Collective Investment in Transferable Securities] regulatory framework in the European Union. The actual ACCI SA fund now employs a similar asset allocation strategy. For negative risk indicator values, we use a 30% equity defensive portfolio.\nAs shown above, risk indicators can serve as a guideline to configure different investment strategies. From switching between assets, as in our risk-on/risk-of example, to full-fledged portfolio allocation, as illustrated by our systematic allocation case study.\nThe use of risk indicators can be tailored to the preferences of a particular asset manager. He can just set a threshold to decide when to switch from a defensive portfolio to a positive one, or vice versa. Or he can adjust his risk exposure daily, according to the risk indicator value at the close of the previous"}, {"title": "III. MODEL TRAINING FOR MARKET TREND PREDICTION", "content": "In the previous section, we introduced the use of risk indicators in asset management. In this section, we delve into the details of how they can be designed for particular markets.\nAs described above, risk indicators are predictive models for drawdown periods. Drawdown, when talking about investments, is a measure of the decline from a previous historical peak in the cumulative return or current value of an investment strategy. In other words, we focus on the downside risk, the probability that an asset portfolio will fall in price. Given historical data, Machine Learning techniques can be used to model that probability."}, {"title": "A. Machine Learning", "content": "Machine Learning [ML] is a field within Artificial Intelligence [AI] that studies the design and development of algorithms that can learn from data. Hopefully, the models learnt using ML, apart from working properly with the data they were trained on, should also generalize well to unseen data.\nGiven a data set, known as training set, and a ML algorithm, the computer learns a model from the provided data. By means of an inductive process, which depends on the particular learning algorithm chosen, we build a model, whose properties also depend on the specifics of the ML algorithm. Formally, induction is making an inference based on an observation of a sample (i.e., the training set). Abduction is making a probable conclusion from what you know, so model building or training, as it is often called, is an example of abductive reasoning from a mathematical logic point of view. Model training, as abductive reasoning, seeks the simplest and most likely conclusion from a set of observations (those in the training set).\nOnce the model is trained, it can be applied on new data to make predictions. This application of the trained model to data is an example of deductive reasoning. The model is used to draw valid inferences that follow logically from their premises (i.e., those represented by the trained model). Hence, the use of ML models is often referred to as 'inference.'\nWhen evaluating ML models, a separate dataset is kept, distinct from the training dataset. This dataset, often called test set, is employed to evaluate the performance of ML models. Why? Because the results on the training dataset would be utterly optimistic and we need an unbiased estimation of the true performance of ML models before they are deployed. This is the role of the test set."}, {"title": "B. Machine Learning Techniques", "content": "We use Machine Learning techniques to design risk indicators for financial markets, both fixed-income and equity markets. These risk indicators are predictive models for drawdown periods. Since they use labelled historical data to be trained on, they can be built using supervised ML techniques.\nIn supervised learning techniques, training data contains both input variables (e.g., a vector of predictor variables) and the desired model output. From input-output pairs, a model is learnt from the training dataset. Where do the outputs come from? Typically, an human expert has labelled each training set example with the desired output. Once the training set is prepared, it is the turn of the computer to learn from it and train a suitable model using a particular learning algorithm.\nA wide range of supervised learning algorithms are available, each one with its own strengths and weaknesses. In fact, a well-known theoretical result, the \"no free lunch theorem,\" asserts that there is no single learning algorithm that works best on all supervised learning problems [9], a result that also applies to optimization techniques [10].\nGiven that we cannot know beforehand which particular ML technique will work best for a particular problem (we might have some hints, yet they are never conclusive), we have tested multiple ML techniques in the ACCION project to design ACCI risk indicators.\nTesting multiple ML algorithms lets us compare the differences among the ML models they train. Our comparison takes into account both quantitative and qualitative aspects. From a quantitative point of view, we are interested in model accuracy, precision, and recall, as well as in the episodic behavior of the risk indicator when market trends change. For us, the dynamic response of a risk indicator to a trend reversal is paramount, as"}, {"title": "\u2022", "content": "we discussed when describing the limitations of linear models. From a qualitative point of view, model interpretability is desirable, yet not essential, but model behavior is crucial. Even when a binary output model might yield better quantitative results, a zero-one response does not help asset managers feel confident on the risk indicator value, as changes in the indicator seem to be unpredictable. A gradual response is often preferable, when daily changes in the risk indicator hint at current potential trends in the underlying market.\nIn the ACCI-ON project, a wide range of supervised ML techniques have been evaluated:\nLinear models, even when they exhibit some undesirable properties, such as their lack of responsiveness when a market trend is reversed, are still useful as a baseline. They provide a foundation on which we can build on to compare the effectiveness of more sophisticated learning algorithms. In our experiments, we tested linear regression for regression problems as well as logistic regression for classification problems.\nSupport vector machines: A support vector machine, or SVM, in addition to linear classification, can efficiently perform a non-linear classification using what is called the kernel trick. Since linear approximations are not suitable for the non-linear world of financial markets, SVMs provide an interesting alternative, even though they are not truly scalable. SVMs represent data through pairwise similarity comparisons between original data observations. SVMs implicitly represent the original data in transformed coordinates within a higher dimensional space (actually, a potentially infinite-dimensional space) and identify the maximum-margin hyperplace in that space. Even though the decision frontier is still linear in the transformed coordinate space, it corresponds to a non-linear frontier in the original space. SVMs can be used to solve both classification problems [11] and regression problems [12].\nEnsembles are popular for winning data mining competitions. In ML, ensemble methods combine multiple learning algorithms. As musical ensembles combine multiple musical instruments to achieve a more harmonious result, ML ensembles obtain better predictive performance than any of the individual learning algorithms in the ensemble. For that to occur, the ensemble must be designed so that we can ensure that the individual algorithms within the esemble do not always make the same mistakes. From a quantitative point of view, they can achieve the best numerical results, hence their popularity in Kaggle competitions [13], even though they might be unsuitable from a qualitative point of view. Two of the best-known ensemble learning algorithms are random forests [14] and gradient boosting [15].\nA random forest, proposed by Leo Breiman from the University of California, Berkeley, is an ensemble of decision trees. A decision tree is a symbolic model most economists are already familiar with. Decision trees were very popular in Machine Learning and Data Mining at the turn of the century.\nGradient boosting, proposed by Jerome Friedman from Stanford University, is based on boosting. Most boosting algorithms consist of iteratively learning weak classifiers and adding them to a final strong classifier. A weak classifier is only slightly correlated with the true classification (it can label examples better than random guessing). The resulting strong learner is a classifier that is arbitrarily well-correlated with the true classification. The predition model obtained by gradient boosting is an ensemble of weak prediction models. Gradient boosting algorithms are iterative functional gradient descent algorithms; that is, they optimize a cost function over function space by iteratively choosing a function (weak hypothesis) that points in the negative gradient direction.\nDeep learning models are based on artificial neural networks [16] [17] [18]. Artificial neural networks are connectionist models, formerly known as Parallel Distributed Processing (PDP) models.\nNeural networks consist of individual neurons, which are simple computational elements of the form\n$y = f (\\sum w_ix_i) = f(\\vec{w} \\cdot \\vec{x})$\nThe nonlinear function $f$ is the neuron activation function, typically a sigmoidal function, such as the logistic function and the hyperbolic tangent, or a rectified linear function. In the former case, the neuron is said to be sigmoidal; in the latter, it is a ReLU [Rectified Linear Unit].\nMultiple neurons can be put in parallel to create a network layer with vector input $\\vec{x}$, vector output $\\vec{y}$, weight matrix $W$, and activation function $f$, to be applied element-wise:\n$\\vec{y} = f (W\\vec{x})$\nMultiple network layers can be stacked to create a feed-forward neural network:\n$\\vec{y} = f (W_Lf (W_{L-1}... f (W_1\\vec{x})))$"}, {"title": "\u2022", "content": "The last layer, characterized by the weight matrix $W_L$, is the network output layer. The input vector $\\vec{x}$ is the input layer, which performs no computation, just provides the input to the network. Inner layers are called hidden layers. When the network has more than one hidden layer, the network is said to be a deep neural network, hence the term 'deep learning' to refer to the learning techniques that allow us to train deep neural networks.\nThe weights of an artificial neural network are typically trained by stochastic gradient descent with the help of a dynamic programming algorithm called backpropagation. Backpropagation is an efficient gradient estimation method for neural network models, also known as the reverse mode of automatic differentiation or reverse accumulation. Backpropagation computes the gradient"}, {"title": "\u2022", "content": "of a loss function with respect to the weights of the network for a single input-output example. It computes the gradient one layer at a time and iterates backward from the last layer to avoid redundant calculations of intermediate terms in the Leibniz chain rule that is applied to compute the gradient.\nIn contrast to symbolic models (e.g., decision trees) and statistical techniques (e.g. SVMs), neural networks were originally proposed as computational models to describe aspects of human perception, cognition, and behaviour, the learning processes underlying such behaviour, and the storage and retrieval of information from memory [19].\nFrom a computational perspective, feed-forward neural networks can be interpreted as models that learn to extract hierarchical features from data. The first layers of a feed-forward network learn to extract relatively simple features directly from the input data. As we advance through a deep network, neurons learn to represent more complex features from the features extracted by previous network layers. Deep learning can, therefore, be viewed as hierarchical feature representation [20], hence the name of one of the major conferences in the area (ICLR, the International Conference on Learning Representations)."}, {"title": "C. Model Output", "content": "The first decision we must make when building a predictive model is the nature of our target variable, the value we are trying to predict, typically denoted by $\\hat{y}$. If we choose to predict a categorical, discrete, or nominal variable, we build a classification model. If we opt for predicting a continuous real-valued variable, we are building a regression model.\nMarket trend prediction can be modeled either as a classification problem or as a regression problem:\n\u2022\tTrend prediction as a classification problem:\nOur target variable will be a binary variable that indicates whether or not our market of interest is immersed in a drawdown period. The drawdown period covers from peak to trough, from a local maximum to the following local minimum.\nHow are local maxima and minima chosen? There are several alternatives:\n\u2022\tTrend prediction as a regression problem:\nWe can also interpret our trend prediction goal as a regression problem. In this case, we can try to predict:"}, {"title": "D. Input Variables", "content": "Simple forecasting models are autoregressive. In statistics, econometrics, and signal processing, the output or target variable of an autoregressive model depends only on its own previous values. In time-series analysis, we predict the future values of a time series based on its past values. Autoregressive models are widely used in technical analysis to forecast future security prices.\nMore advanced forecasting models take additional context into account. That context can be provided by additional variables or time series. For instance, instead of predicting future S&P 500 values using only past S&P 500 values, we might also incorporate bond market data as an additional input to our predictive model.\nWith the initial support of Umberto M\u00e1rmol and other economists at ACCI Capital Partners, we analyzed a multitude of economic variables that might serve as leading indicators for predicting changes in market trends. It is essential that they are leading indicators because we are especially interested in detecting changing trends as soon as they happen. Many economic variables are either lagging indicators (they hint at trends after they have started) or are published with too much delay to be useful when we expect a quick response from our trend prediction model. These were finally discarded in our risk indicator models.\nOur final risk indicator models incorporate dozens of different variables, sometimes hundreds. In broad terms, the variables we use as input can be grouped into the following six categories:\n\u2022\tStock market indexes for main global and regional equity markets, including the S&P 500, the MSCI World, the NASDAQ 100, or the Russell 2000, as well as the S&P 500 Equal Weight Index and many other regional stock market indexes.\n\u2022\tBond market data, including US Treasury bonds, their yield curve, government bonds from the major economies of the World, commercial paper interest rates, and corporate bonds (both investment-grade and high-yield).\n\u2022\tCurrency exchange rates for the World major currencies and currency baskets such as the U.S. Dollar Index (DXY).\n\u2022\tFutures market data, including commodity indexes (GSCI and DJCI), commodity futures, energy (oil and natural gas), and precious metals (e.g., gold).\n\u2022\tVolatility indexes associated to different markets, including the well-known VIX and MOVE volatility indexes, as well as volatility measures for commodities, gold, currencies, stocks, and bonds.\n\u2022\tMacroeconomic variables including leading indexes (OECD and BBK), ISM data, freight indexes, advance"}, {"title": "E. Feature Engineering", "content": "Once input variables have been selected, they must be prepared to be used as the input to Machine Learning models. First of all, a proper encoding must be selected, often depending on the particular ML technique to be used for training a predictive model.\nEven when no additional variables are included, apart from those of the time series we wish to model, we must decide whether we provide the time series values as they are acquired or we preprocess them to make it easier for the ML algorithm to learn a good model. For instance, when we are predicting the evolution of the S&P 500 stock index, using index values would hamper most ML algorithms, since the index is near its all-time high and current index values have never been observed in the past. It is much more reasonable to use percentage changes, always as model input and as model output in the case of regression models.\nBefore using some ML techniques, the scale of the input data must also be adjusted. Even when ML techniques are able to cope with different scales for different inputs, learning is easier if we do some preprocessing. It is usually a good idea to normalize or standardize all the model inputs before proceeding further. Scale changing transformations include the following:\n\u2022\tFeature scaling, unity-based normalization, or [0,1] normalization brings all values into the [0,1] unit interval:\n$x_{[0,1]} = \\frac{x - x_{min}}{x_{max} - x_{min}}$\n\u2022\tMin-max feature scaling or min-max normalization brings values into the [a,b] interval:\n$x_{[a,b]} = a + \\frac{x - x_{min}}{x_{max} - x_{min}} (b - a)$\n\u2022\tRobust normalization or robust standardization employs the median and interquartile range (IQR) to be more robust against outliers in data:\n$x_{robust} = \\frac{x - x_{median}}{x_{IQR}}$\n\u2022\tStandardization or z-score normalization is a more common approach, using the mean \u00b5 and the standard deviation \u03c3:\n$z = \\frac{x - \\mu}{\\sigma}$"}, {"title": "\u2022", "content": "The z-score, or standard score, measures the number of deviations by which the value of the raw score is above or below the mean value. It works well for data that is normally distributed, when large deviations from the mean are not frequent. In a normal distribution, 68.3% of the data lie in the [$\\mu - \\sigma, \\mu + \\sigma$] interval, 95.4% of the data lie in within two standard deviations (the [$\\mu \u2013 2\\sigma, \\mu + 2\\sigma$] interval), and 99.7% of the data lie in within three standard deviations (the [$\\mu \u2013 3\\sigma, \\mu + 3\\sigma$] interval). The six-sigma interval covers 99.9999998% of data (less than one value in 500 million falls outside this range).\nWhen you have a sample of data, the z-score computation of that sample yields the well-known t-statistic, used by Student's t-test for statistical hypothesis testing.\nWhen working with time series, not all ML techniques are able to use them directly as model inputs. Therefore, scalar features are often extracted from them. Autoregressive models are often limited to a small window in the time series past; i.e., they use just the previous time series values as input. Some deep learning models, fortunately, are able to process sequences in general and time series in particular.\nThe efficient market hypothesis [EMH] states that prices reflect all available information and consistent alpha generation is impossible. If it were true, beating the market would not be feasible. However, even simple autoregressive models can benefit from the design of input variables derived from the original time series we are modeling. For instance, Zura Kakushadze, from Quantigic Solutions LLC, Stamford, \u0421\u0422 [21], enumerates 101 'alphas' that have proven to be useful in algorithmic trading. An 'alpha' is an indicator that, when used in combination with historical data, can be useful for making predictions on the future price movements of financial instruments. In other words, 'alphas' provide some capability to beat the market. When used for predicting the S&P 500 stock index, for instance, they achieve a 54% accuracy rate [22], somewhat above the 50% accuracy expected by the EMH, an edge that is enough to obtain benefits if we used high frequency trading [HFT] strategies.\nHigh frequency trading, however, is not a suitable investment strategy for many investment funds. More traditional asset managers do not want to trade too often, so the quantitative models used in HFT do not match their expectations. They often want to minimize the number of trades in their portfolios (in order to reduce operational risks) and prefer a low portfolio rotation. Risk indicators, as described in this paper, are designed for them.\nThere is still a problem that must be solved. Daily market data is noisy. That noise might cause sudden temporary fluctuations in risk indicators, leading to unnecessary trades and flip-flop rotations. Depending on the particular ML technique employed to build the risk indicator, different noise reduction strategies might be used:\nSome ML algorithms, such as linear models, are not particularly robust to the presence of noise in data, so that noise must be filtered before it reaches the model"}, {"title": "\u2022", "content": "input. Input noise filtering, however, delays the input to the model when trend changes suddenly appear. This delay is added to the limited reactivity of linear models, hence compounding the problem and limiting the ability of linear risk indicators to react to trend reversals.\nOther ML algorithms, such as deep learning models, can be made robust against input noise without having to filter that noise beforehand. In fact, noise can act as as regularizer and help improve the performance of such models on unseen data. If brief fluctuations are observed in their output, that output can be filtered to reduce wiggling and provide more aesthetically pleasing risk indicators, with a more continuous appearance and without the loss of model responsiveness associated to input noise filtering.\nApart from data normalization/standardization, custom feature engineering, and noise reduction filters, automated feature extraction and dimensionality reduction techniques can also help improve the performance of trend prediction models. Some of alternatives available for mining complex data include the following:\n\u2022\tPrincipal component analysis [PCA] is the best-known feature extraction and dimensionality reduction tech-nique, developed by Pearson in 1901 [23] and Hotelling in 1933 [24]. Data is linearly transformed onto a new coordinate system so that that the new axes (i.e. the principal components) capture the largest variation in the data can be easily identified. In other words, the coordinate system is rotated to match the distribution of the input data and most of the variance in data is captured by the first few dimensions.\n\u2022\tCUR decomposition [25] [26] [27] approximately ex-"}, {"title": "\u2022", "content": "presses the original data in terms of a basis consisting of actual data elements and thus have a natural interpretation in terms of the processes generating the data. CUR decomposition is a scalable alternative to PCA, when data can be stored but is too large to practically perform superlinear polynomial time computations on it.\n\u2022\tDynamic Mode Decomposition [DMD] [28] [29], given time series data, computes a set of modes each of which is associated with a fixed oscillation frequency and decay/growth rate. Each mode can be physically meaningful because it is associated with a damped (or driven) sinusoidal behavior in time.\n\u2022\tWavelets, sometimes called brief oscillations, are wave-like oscillations with an amplitude that begins at zero, increases or decreases, and then returns to zero one or more times. Used for decades in digital signal processing, the first-known wavelet was the Haar wavelet (1909). Wavelet analysis is similar to Fourier analysis in that it allows a target function over an interval to be represented in terms of an orthonormal basis. A key difference is that wavelets capture both frequency and location information (i.e., location in time).\n\u2022\tKernel PCA [30] is is a nonlinear extension of principal component analysis (PCA) using kernel methods. The kernel trick is used to factor away much of the com-putation: a non-trivial, arbitrary function is 'chosen' that is never calculated explicitly, allowing the possibility to use very-high-dimensional functions, since we never have to actually evaluate the data in that space.\n\u2022\tStochastic Neighbor Embedding [SNE] [31] places objects, described by high-dimensional vectors or by pairwise dissimilarities, in a low-dimensional space in a way that preserves neighbor identities. Its more efficient t-distributed variant, t-SNE [32], runs in O(n\u00b2) time and requires O(n\u00b2) space.\n\u2022\tUniform manifold approximation and projection [UMAP] [33] is another nonlinear dimensionality reduc-tion technique. Visually, it is similar to t-SNE, but it assumes that the data is uniformly distributed on a locally connected Riemannian manifold.\n\u2022\tAutoencoders are deep learning models used to learn efficient codings of unlabeled data (i.e., for unsuper-vised learning). In fact, they were originally proposed as a nonlinear variant of PCA based on artificial neural networks [34]. An autoencoder learns two functions: an encoding function that transforms the input data, and a decoding function that recreates the input data from the encoded representation. Regularized autoencoders (sparse [35], denoising [36], and contractive [37]) are effective in learning representations for subsequent predictive tasks."}, {"title": "F. Model Hyperparameters", "content": "Each Machine Learning technique is designed for building a particular kind of model (e.g.", "case": "n\u2022\tRecurrent neural networks [RNNs", "SRNs": "are fully-recurrent neural networks that connect the output of all hidden units to their input for each hidden layer in the network [38"}]}