{"title": "Polynomial Threshold Functions of Bounded Tree-Width: Some Explainability and Complexity Aspects", "authors": ["Karine Chubarian", "Johnny Joyce", "Gy\u00f6rgy Tur\u00e1n"], "abstract": "The tree-width of a multivariate polynomial is the tree-width of the hypergraph with hyperedges corresponding to its terms. Multivariate polynomials of bounded tree-width have been studied by Makowsky and Meer as a new sparsity condition that allows for polynomial solvability of problems which are intractable in general. We consider a variation on this theme for Boolean variables. A representation of a Boolean function as the sign of a polynomial is called a polynomial threshold representation. We discuss Boolean functions representable as polynomial threshold functions of bounded tree-width and present two applications to Bayesian network classifiers, a probabilistic graphical model. Both applications are in Explainable Artificial Intelligence (XAI), the research area dealing with the black-box nature of many recent machine learning models. We also give a separation result between the representational power of positive and general polynomial threshold functions.", "sections": [{"title": "Introduction", "content": "The tree-width of a multivariate polynomial is the tree-width of the hypergraph with hyperedges corresponding to its terms. Multivariate polynomials of bounded tree-width have been studied by Makowsky\nand Meer [32, 33] as a new sparsity condition that allows for polynomial solvability of problems which\nare intractable in general. The paper is closely related to Courcelle, Makowsky and Rotics [7] and to\nFischer, Makowsky and Ravve [14]. The topics covered are polynomials, graphs, widths, counting and\nlogic. We discuss a variation on this theme, in the context of Boolean functions. Polynomials, graphs,\nwidths, counting and (propositional) logic all appear, although the context is different. The problems\nconsidered are from Explainable Artificial Intelligence (XAI) and complexity theory.\nBoolean functions f : {0,1} \u2192 {0,1} can be represented by multivariate polynomials exactly or\napproximately in a many different ways over GF (2) or the reals. In this paper we consider polynomials\nover the reals. As $x^2 = x$ for 0 and 1, polynomials can be assumed to be multilinear. Let\n$p(x_1,...,x_n) = \\sum_{I \\subseteq [n]} \\beta_I x_I$ (1)\nbe a multilinear polynomial, where $I$ is a family of subsets of $[n]$, $\\beta_I \\in \\mathbb{R}$ and $x_I = \\prod_{i \\in I} x_i$. The degree\nof the polynomial is the maximal number of variables in a term, and its size is the number of terms. One\ncan consider the Boolean function\n$sgn(p(x_1,...,x_n)) : {0,1}^n \\rightarrow {0,1}$,\nwhere sgn is the sign function (1 for nonnegative values and 0 otherwise). For example,\n$sgn(x_1 + x_2 + x_3 + x_4 - x_1x_2 - x_3x_4 - 2)$ (2)\nrepresents the 4-variable Boolean function which has value 1 iff $(x_1, x_2, x_3, x_4)$ contains at least three 1s,\nor both $(x_1,x_2)$ and $(x_3, x_4)$ contain exactly one 1.\nEvery Boolean function can be represented in this form, called a polynomial threshold function (PTF)\nrepresentation (see Sect. 2.1). The smallest degree and size of polynomials representing a Boolean function\nare important measures of its complexity. A Boolean function is a degree-d polynomial threshold function\nif it can be written as the sign of a degree-d polynomial. Linear threshold functions (LTF or perceptrons)\nplayed an important role since the beginning of machine learning.\nWe consider the minimal tree-width of polynomial sign-representations as a measure of complexity of\na Boolean functions. Consider a polynomial p as in (1). The term-hypergraph $H_p$ of polynomial p has\nvertex set $[n]$ and edge set $I$. The tree-width of polynomial p is the tree-width of its term-hypergraph $H_p$.\nA Boolean function is a tree-width-k polynomial threshold function if it can be written as the sign of a\ntree-width-k polynomial. Thus, for example, the Boolean function (2) has tree-width 1.\nPolynomial threshold representations are useful in many different areas. One of these is a probabilistic"}, {"title": "Explainability", "content": "graphical model, the Bayesian network classifier (BNC) [15], a generalization of the Naive Bayes classifier.\nA Bayesian network classifier can be represented by a polynomial threshold function, where the terms\nreflect the graphical structure of the network (see Sect. 3). Polynomials representing the Naive Bayes\nclassifier are linear. Tree Augmented Bayesian network classifiers (TAN) have additional edges forming a\nforest [15]. They correspond to quadratic polynomial threshold functions (QTF), where the quadratic\nterms correspond to the edges of the forest. Bayesian network classifiers with a bounded tree-width\nnetwork structure correspond to polynomials of bounded tree-width. Bounded tree-width Bayesian\nnetworks form a tractable subclass for several inference and learning problems [8, 24]. In this paper we\nconsider some aspects of Bayesian network classifiers related to their explainability.\nRecent machine learning models, in particular deep neural networks, are often black\nboxes in the sense that they do not provide an explanation for the output produced, and this hinders\nthe development of trustworthy AI. Standard examples are that a rejected loan applicant needs to know\nthe reason for the rejection, and a physician needs to know reasons for a suggested diagnosis. The need\nfor explanations has a long history in machine learning 2, but the recent developments amplified the\nthe relevance of this issue and brought about Explainable AI as a separate field of research [35].\nHow to define what is an explanation is a difficult question, which has a long history in the philosophy of\nscience. The type of explanation relevant in a particular machine learning application is context-dependent.\nA post-hoc explanation provides an explainable model 3 corresponding (exactly or approximately) to a\nblack-box model. Post-hoc explanations can be global or local, depending on whether the whole model is\nexplained or only its behavior on a specific input. Even if there is an agreed upon notion of explanation,\nit is usually not clear how to evaluate the explanations provided, one reason being the lack of ground\ntruth (e.g., what is the reason for classifying an image as a cat?).\nA neural network is usually considered non-explainable and a decision tree is usually considered\nexplainable (but see, for example, [28] for a discussion of this distinction). Probabilistic graphical models\nare somewhere in between, having both explainable and non-explainable features. A Bayesian network,\non one hand, gives explicit graphical information about conditional independencies. On the other hand,\nprobabilistic inference is hard, and usually not explainable for the user. This holds even for the Naive\nBayes classifier. Therefore, explaining Bayesian networks has been studied for a long time [27].\nExplaining Bayesian Network Classifiers by Approximate OBDD A post-hoc approach to\nglobal explanations for Naive Bayes classifiers, proposed by [5], is to compile them into Ordered Binary"}, {"title": "Preliminaries", "content": "Decision Diagrams (OBDD) [48]. This is an instance of knowledge compilation, transforming a knowledge\nrepresentation into another which is more suitable for a given application [10]. Explainability aspects of\nknowledge compilation are considered in [12].\nBesides being explainable in the local sense similarly to decision trees, OBDDs can also be considered\nas global explanations, as they provide a useful data structure for Boolean functions. There are efficient\nalgorithms for deciding their properties and performing operations on them that are relevant for proposi-\ntional reasoning about a model [31, 48, 9]. Thus, if a system has a component which computes a Boolean\nfunction, then having an OBDD representing this function can be useful for reasoning about how this\ncomponent works as part of the system. In this sense, OBDD is a \"reasonable\" representation.\nIt was shown in [21] that linear threshold functions require exponential size OBDDs in the worst case,\nso such compilation algorithms have to be exponential. Therefore, for efficient compilation approximations\nneed to be considered. As learned models are supposed to be approximations, this requirement seems\nnatural.\nIn [6] we gave an approximation scheme compiling Bayesian network classifiers of bounded tree-width\ninto OBDD. Bounded tree-width is well-known to be a useful parameterization for efficient computation.\nHere we consider its relevance for finding explanations efficiently, which is a different aspect. An outline of\nthe algorithm is given in Sect. 4. From the point of view of knowledge representation in AI, the result is an\nexample of approximate knowledge compilation. Negative results for approximate knowledge compilation\nare given in [13].\nThe algorithm is based on first translating the classifier into a PTF of bounded tree-width, and\nthen translating this PTF into an approximate OBDD. The second step generalizes the approximate\ndeterministic counting algorithm of [16] (an FPTAS, fully polynomial-time approximation scheme) for\nthe knapsack solution counting problem, corresponding to the LTF case. Error is measured with respect\nto the input distribution generated by the classifier, and not the uniform distribution.\nDeterministic approximation algorithm schemes for counting the number of satisfying truth assignments\nfor a class of Boolean functions work as follows. Given an e > 0 and a function f from the class, an\nestimate is computed for the probability $P(f(x) = 1)$, where x is uniformly distributed over {0,1}\".\nMultiplicative (resp., additive) approximation algorithms compute an estimate within a multiplicative\nerror 1 \u00b1\u20ac (resp., an additive error \u00b1\u20ac). If the satisfiability problem for the class (i.e., deciding whether\nthere is an x such that f(x) = 1) is NP-complete then, assuming $P \\neq NP$, polynomial time multiplicative\napproximation algorithms cannot exist, as those could be used to solve the satisfiability problem in\npolynomial time. Hence in such cases additive approximation has to be considered. In contrast to\nthe linear case, for degree at least 2 the PTF satisfiability problem is NP-complete, so only additive\napproximation algorithms can be hoped for (see [42], and [11] for the QTF case). Tree-width provides a\""}, {"title": "Bayesian Network Classifiers and Polynomial Threshold Functions", "content": "different parameterization.\nExplainability Evaluation for Generalized Additive Models with Interactions In Sect. 5 we\ndiscuss another application of polynomial threshold functions to explainability. A generalized additive\nmodel (GAM) is a generalization of logistic regression. It can be extended further to include interaction\nterms between the variables. InterpretML [36] contains an implementation of the GA2M algorithm of [30],\nwhich is applied, for example, in the medical domain [4]. Its accuracy is competitive with more complex\nmodels, and it is also explainable in the practical, informal sense that the interaction terms are often\nmeaningful for medical experts.\nWe discuss an experiment aimed at a qualitative evaluation of the explainability of the GA2M algorithm.\nBayesian network classifiers provide a class of instances with ground truth. The applicability of BNC in\nthis context is due to the connection between BNC and polynomial threshold functions mentioned above.\nThis connection implies that a BNC can be viewed as a generalized additive model with interactions, with\nthe structure of the network corresponding to interaction terms. The ground truth is structured in the\nsense that terms not included in the basic representation also have a probabilistic meaning in the network.\nThe basic setup of GA2M is to handle pairwise interactions, therefore so far we have only considered\nTAN in our experiments.\nWe present experimental results for a small synthetic example, using InterpretML [36]. BNC is a\ngenerative model, so one can train a GA2M on random examples generated from the input distribution\nof the BNC. The ground truth given by the polynomial threshold function representing the classifier can\nbe compared with the polynomial produced by the GA2M in different ways, perhaps the simplest being\ncomparing the terms in the ground truth and learned polynomials. Besides achieving almost optimal\naccuracy on the example, the learned terms show a good correspondence to the ground truth.\nPositive Polynomial Threshold Functions A main research direction of computational complexity\ntheory is to compare the computational power of various models of computation.\nA Boolean circuit computes a Boolean function using $ \\land, \\lor$ and $\\neg$ gates. The circuit is monotone if it\ncontains only $ \\land, \\lor$ gates and no negation. Such circuits can compute all monotone Boolean functions and\nonly those. Comparing the computational power of monotone and general circuits and other computational\nmodels has been studied in complexity theory for a long time [39]. The problem is also referred to as\n\"monotone versus positive\" ([1], where it is shown that Lyndon's theorem fails for finite models by a circuit\nlower bound). Superpolynomial separations between monotone and general circuits were given in [41, 40],\nstrengthened to exponential separation in [46]. A survey of results on monotone circuit complexity is\ngiven in [22].\nAs far as we know the related problems for PTF have not been considered before. A PTF is positive if"}, {"title": "Bayesian Network Classifiers and Polynomial Threshold Functions", "content": "In this section we formulate the representation of BNC as PTF, which is used in the next two sections. A\nunified presentation of work on this connection, going back to [34], is given in [47].\nProposition 1. Let N be a Bayesian network classifier with non-zero conditional probabilities. Then\nthere is a polynomial p such that\n$\\log \\frac{P_N(C = 1 | X = x)}{P_N(C = 0 | X = x)} = p(x)$,\nwhere p is of degree at most $d_N$ and every term is a subset of a family. Thus $f_N$ is a PTF of degree at\nmost $d_N$.\nProof. It holds that\n$P_N (X_i = x_i | X_{\\Pi_i} = x_{\\Pi_i}, C = c) = P_{(a_i,a_{\\Pi_i},c)} ; \\prod_{v_j \\in \\Pi_i} I_{a_j}(v_j)$.\nFrom (4) we get\n$P_N (X_1 = x_1,..., X_n = x_n, C = c) = p_c \\prod_{i=1}^n (P_{(a_i,a_{\\Pi_i},c)} \\prod_{v_j \\in \\Pi_i} I_{a_j}(v_j)) $\nThen for $x = (x_1,...,x_n)$ it holds that\n$\\frac{P_N(C = 1 | X = x)}{P_N(C = 0 | X = x)} = \\frac{p_1}{p_0}  \\prod_{i=1}^n (\\prod_{(a_i,a_{\\Pi_i}) \\in E_N} (\\frac{P_{(a_i,a_{\\Pi_i},1)}}{P_{(a_i,a_{\\Pi_i},0)}} )^{I_{a_i}(x_i) \\prod_{v_j \\in \\Pi_i} I_{a_j}(v_j)}$\nTaking logarithms\n$\\log \\frac{P_N(C = 1 | X = x)}{P_N(C = 0 | X = x)} = \\log  \\frac{p_1}{p_0} + \\sum_{i=1}^n (\\sum_{(a_i,a_{\\Pi_i}) \\in E_N} (\\log \\frac{P_{(a_i,a_{\\Pi_i},1)}}{P_{(a_i,a_{\\Pi_i},0)}} ) I_{a_i}(x_i) \\prod_{v_j \\in \\Pi_i} I_{a_j}(x_j)).$\nCorollary 2. For a TAN with non-zero conditional probabilities $f_N$ is a QTF of tree-width 1, with\nquadratic terms corresponding to $E_N$.\nCorollary 3. For BNC of tree-width k with non-zero conditional probabilities $f_N$ is a PTF of path-width\nO(klog n)."}, {"title": "Approximating Bayesian Network Classifiers with OBDD", "content": "Proof. For every edge of the primal graph of the term-hypergraph $H_p$ for the PTF constructed above\nthere is a family of N containing that edge, which then belongs to the moral graph of the classifier. The\nstatement then follows from the fact that $pw(G) = O(tw(G) log n)$ for undirected graphs [25].\nThe primal graph may be a proper subset of the moral graph due to cancellations.\nIn this section we show that Bayesian network classifiers of bounded tree-width can be approximated by\npolynomial size OBDD. We first introduce OBDD, then formulate the result and outline its proof.\nOrdered Binary Decision Diagrams\nAn ordered binary decision diagram (OBDD) over Boolean variables $x_1,...,x_n$ computes a Boolean\nfunction f. An OBDD is a DAG with two sinks labeled 0 and 1, and the other nodes labeled with"}, {"title": "Bayesian Network Classifiers for Evaluating the Explain- ability of Generalized Additive Models with Interactions", "content": "variables. The DAG is assumed here to be layered, with directed edges going from a layer to the next\nlayer, and sinks on the last layer. There are n + 1 layers and a permutation \u03c0(i) of [n] such that nodes\non the i'th layer are labeled with variable $x_{\\pi(i)}$. On the first layer there is a single start node labeled\n$x_{\\pi(1)}$. Every non-sink node has two outgoing edges, labeled with 0, resp., 1. For every truth assignment\na = $(a_1,...,a_n), f(a)$ is the label of the sink reached by following edge labels corresponding to the bits in\na, evaluated in the order given by the labels of the layers. The width of an OBDD is the maximal number\nof nodes in a layer 5.\nGiven an ordering of the variables, every Boolean function has a unique minimal layered OBDD,\nwhere every node of the i'th layer correspond to a subfunction obtained by fixing the variables above the\nlayer. This can further be simplified to the reduced OBDD, where edges can \"jump\" layers, by deleting\nnodes with both outgoing edges leading to the same successor node, and redirecting their incoming edges\nto the successor node. The left side of Fig. 1 shows the minimal layered OBDD of the function (2) and\nthe right side shows its reduced OBDD, with respect to the identity permutation.\nA generator OBDD (GOBDD) D generates a probability distribution over {0,1}\". It is similar to a\nlayered OBDD, except edges are also labeled with probabilities, and there is a single sink. A probability\npu is associated with every non-sink vertex u, and the 0-edge (resp. 1-edge) leaving u is labeled $p_u = p_u$\n(resp., $p_u^1 = 1 - p_u$). For every truth assignment a = $(a_1,...,a_n)$, the GOBDD determines a path from\nthe source to the sink, and $P_D(a)$ is the product of edge probabilities along the path. The width of a\nGOBDD is the width of the underlying OBDD. The width of a distribution is the minimal width of\nGOBDDs generating it. Product distributions have width one.\nResult and Proof Outline\nWe now state the result on approximating Bayesian network classifiers of bounded tree-width with OBDD\nover the input distribution of the classifier. As discussed in the introduction, the goal is to provide a\n\"small\" approximate representation of bounded tree-width Bayesian network classifiers which allows for\nefficient reasoning. Besides the parameters discussed earlier, the bounds also depend on the bit-precision\nq of the conditional probabilities.\nTheorem 4. [6] For every Bayesian network classifier of tree-width k having n Boolean variables and q-bit\nnon-zero conditional probabilities, and every \u025b > 0 there is an OBDD of size poly $(n^k, q, 1/\\epsilon)$ approximating\nthe classifier with multiplicative error at most \u025b with respect to the input distribution of the classifier. The\nOBDD can be constructed in time poly $(n^k, q, 1/\\epsilon)$.\nProof. Let N be a BNC with the properties given in the theorem. Consider the polynomial p provided by\""}, {"title": "Experimental Results on a Small Example", "content": "Logistic regression for Boolean variables is a probabilistic model of the form\n$\\log \\frac{P(C = 1 | X = x)}{P(C = 0 | X = x)} = a + \\sum_{i=1}^n B_i x_i$,\nwhere the coefficients are to be learned. A generalized additive model with interactions (GA2M) has the\nmore general form\n$g(P(C = 1| X = x)) = \\sum_{I \\in I} f_I(x^I)$,\nwhere g is a given function, I is a family of subsets of [n] and the functions $f_I$ are to be learned.\nBy Proposition 1 a BNC can be viewed as logistic regression model with interactions. In this case the\nfunctions $f_I$ are products. In particular, by Corollary 2, TAN can be written as\n$\\log \\frac{P_i}{P_0} = \\sum_{i root} (\\log \\frac{P_{10}^i}{P_{00}^i} x_i) - \\sum_{i non-root} (\\log \\frac{P_{10}^i}{P_{00}^i} x_i + (\\log \\frac{P_{01}}{P_{00}^i}) (1 - x_i) x_{f(i)}) $\n$+ (\\log \\frac{P_{011}}{P_{010}} (1 - X_i) X_{f(i)} + (\\log \\frac{P_{111}}{P_{110}} X_iX_{f(i)} )$.\nwhere the p's are the local conditional probabilities and f(i) is the parent of i.\nBNC is a generative model, so one can generate sets of random training and test examples from\nthe joint distribution starting at the classifier node and proceeding down the forests, choosing nodes\naccording to the local conditional probabilities. Using such samples, the GA2M algorithm can learn a\nlogistic regression model q(x) with pairwise interactions.\nThe accuracy of a (deterministic) classifier f over the whole domain is\n$Acc(f) = P_{(x,C)~P_N} (C' = f(X)) = \\sum_X P_N(x, f(x)).$ (5)\nBy its definition the polynomial p is an optimal classifier.\nA GA2M is considered to be an explainable model by analyzing the polynomial produced. For example,\none can consider the set of terms I and the functions $f_I$. In our case this corresponds to considering the\nterms and their coefficients. As there is a ground truth, one can consider the similarity of the target\npolynomial p and the learned polynomial q. The relevant notion of similarity is to be specified. Here we\nconsider what is perhaps the simplest possibility, the fraction of common interaction terms."}, {"title": "A Complexity Lower Bound for Positive Polynomial Thresh- old Representations", "content": "In this section we present a small synthetic example of a target TAN and some experimental results on\nevaluating its similarity to the learned models. This is a snapshot of ongoing experiments.\nThe TAN structure considered is shown in Fig. 2(a), and the conditional probabilities are listed\nin Fig. 2(b). Here, for each node $X_i$ that depends on nodes $X_j$ and C, each conditional probability\n$P(X_i = 1 | X_j = x_j, C = c)$ (for $x_j \\in {0,1}$ and for $c \\in {0,1}$) was selected uniformly at random from\nthe union of intervals $(\\frac{1}{8}, \\frac{3}{8}) \\cup (\\frac{5}{8}, \\frac{7}{8}) \\cup (\\frac{1}{16}, \\frac{15}{16})$. For nodes that depend only on C, $P(X_i = 1 | C = c)$ was\nselected in the same way. Finally, we set $P(C = 1) = \\frac{1}{2}$.\nWe use the InterpretML software package [36] Python implementation of GA\u00b2M, referred to as\nexplainable boosting machines (EBM) 6. The number of interaction terms is specified to be 12, the number\nof edges between the X-variables. All other settings were left as default. To ensure accurate arithmetic\nwith the TAN, particularly with repeated multiplication, all operations were performed with Python's\ndecimal module. Pgmpy [2] was used to build the graph structure of the TAN, and NetworkX [17] was\nused for visualization. Classifiers were trained on samples of sizes up to 2000 (out of 214 possible inputs),\nwith step size 5, using 5-fold cross validation. Accuracies are shown by the dashed curve.\nAccuracies over the whole domain (as in (5)) are also shown on the top part of Fig. 3. The accuracy\nof the target classifier p(x) is 0.9266, corresponding the top line. The accuracies of the learned classifiers\nq(x) (averaged over the 5 folds) are shown by the thick middle curve.\nThe explanation quality of the classifiers produced is measured by the fraction of interaction terms"}, {"title": "Experimental Results on a Small Example", "content": "In this section we give a separation result between the sizes of positive and general QTF representations\nof an explicitly defined monotone Boolean function. The weight of $x \\in {0,1}^n$ is $|x| = \\sum_{i=1}^n x_i$. If |x| = l\nthen x is on level l. The Boolean threshold function $Th_l(x)$ has value 1 iff $|x| \\geq l$.\nLet n = 2k and\n$f_n(x) = (Th_{k+1}(x) \\lor Th_{k}(x)) \\land (Th_{k}(x_1) \\lor \\neg x_1) $. (2)\nA PTF representation of the function f4(x) is given in (2).\nTheorem 8. The function fn\na) is a monotone Boolean function,\nb) is a QTF of size O(n) (and tree-width 1),"}]}