{"title": "Belief Roadmaps with Uncertain Landmark Evanescence", "authors": ["Erick Fuentes", "Jared Strader", "Ethan Fahnestock", "Nicholas Roy"], "abstract": "We would like a robot to navigate to a goal location while minimizing state uncertainty. To aid the robot in this endeavor, maps provide a prior belief over the location of objects and regions of interest. To localize itself within the map, a robot identifies mapped landmarks using its sensors. However, as the time between map creation and robot deployment increases, portions of the map can become stale, and landmarks, once believed to be permanent, may disappear. We refer to the propensity of a landmark to disappear as landmark evanescence. Reasoning about landmark evanescence during path planning, and the associated impact on localization accuracy, requires analyzing the presence or absence of each landmark, leading to an exponential number of possible outcomes of a given motion plan. To address this complexity, we develop BRULE, an extension of the Belief Roadmap. During planning, we replace the belief over future robot poses with a Gaussian mixture which is able to capture the effects of landmark evanescence. Furthermore, we show that belief updates can be made efficient, and that maintaining a random subset of mixture components is sufficient to find high quality solutions. We demonstrate performance in simulated and real-world experiments. Software is available at https://bit.ly/BRULE.", "sections": [{"title": "I. INTRODUCTION", "content": "To reliably reach a goal location, a robot must plan in real-time with imperfect knowledge of the robot and world states. A map, created from a previous deployment or another information source (e.g. overhead imagery), is often used as an aid in navigation. However, the fidelity of the map tends to degrade as the time between map creation and robot deployment increases. For example, in an urban environment, a parked car may be a useful landmark over a time span of minutes, but almost certainly ceases to be useful over days. To the robot, the landmark simply disappeared. We refer to the propensity of landmarks to disappear as landmark evanescence. The simultaneous localization and mapping (SLAM) community has studied landmark evanescence [1]- [3] and developed models of the behavior of these landmarks. While the use of maps is common, the incorporation of landmark evanescence probability distributions (LEPDs) into navigation models has not yet been yet been explored."}, {"title": "II. PROBLEM FORMULATION", "content": "Given a model of our robot dynamics and sensors, and a prior map, we wish to navigate from a start location to a goal location while maximizing the probability that we are near our goal. We assume access to a landmark evanescence probability distribution (LEPD) that describes how the world may have evolved since it was mapped. We formally describe each of these components in the following subsections."}, {"title": "A. World Model", "content": "Let a landmark be $l \\in \\mathbb{R}^d \\times I$, where $d$ is the dimensionality of the landmark locations and $I$ is a set of identifiers. Each landmark is uniquely labeled with one of the identifiers, so that landmarks and measurements may be associated. A map $M = \\{l_i\\}_{i=1}^{N_l}$ is a collection of landmarks. The set of binary strings of length $N_l$, $\\Omega = \\{0,1\\}^{N_l}$ can be used to represent the presence or absence of the mapped landmarks, or evanescence configuration, where the $i$th landmark in $\\omega \\in \\Omega = \\{\\omega_1,\\omega_2,...,\\omega_{N_l}\\}$ is present if $w_i = 1$. We define a probability measure $P(\\omega) : 2^{\\Omega} \\rightarrow [0, 1]$ that maps a set of configurations to a probability. We assume that if a landmark is observed (or noted absent), it will remain observable (or absent) throughout the deployment."}, {"title": "B. Robot Model", "content": "Let $X \\subset \\mathbb{R}^{d_x}$ be the $d_x$-dimensional robot state space and let $U \\subset \\mathbb{R}^{d_u}$ be the $d_u$-dimensional control space. If $x_t \\in X$ and $u_t \\in U$ are the state of the robot and control applied at time $t$, then the next state $x_{t+1}$ is distributed according to the transition distribution $P(x_{t+1} | x_t, u_t)$. Let $Z = (\\mathbb{R}^{d_z} \\cup \\{o\\}) \\times I$ be the observation space where $d_z$ is the dimension of a measurement, $o$ represents the absence of a measurement, and $I$ is the set of landmark identifiers. Concretely, for every landmark, the robot either receives a measurement $(z \\in \\mathbb{R}^{d_z})$ or notes a lack of a measurement $(z = o)$, with perfect data association of measurements to mapped landmarks. Let $\\omega \\in \\Omega$ be an evanescence configuration. The probability of receiving a measurement $z_{i,t} \\in Z$ of the $i$th landmark at time $t$ is given by $P(z_{i,t} | x_t, \\omega)$. During planning, we assume a perfect detector that produces range and bearing measurements when the distance to the landmark is less than $r_{max}$ and produces $o$ otherwise."}, {"title": "C. Bayesian Update of Belief", "content": "If we allow a Markov assumption to be made, then future states are independent of past states, controls, and observations given the current state and control, that is $P(x_{t+1} | x_{0:t}, u_{0:t}, z_{1:t}) = P(x_{t+1} | x_t, u_t)$. Additionally, the current observation is independent of previous states, con- trols, and observations given the current state and the evanescence configuration, that is $P(z_t | x_{0:t}, u_{0:t}, z_{1:t-1}, \\omega) = P(z_t | x_t, \\omega)$. Let $b_t = P(x_t, \\omega | u_{0:t-1}, z_{1:t})$ represent our belief of the robot state and evanescence configuration at time $t$. Then the belief at the next time step $b_{t+1}$ can be computed recursively using the Bayes filter [10] update:\n$b_{t+1}] = P(x_{t+1},\\omega | u_{0:t}, z_{1:t}) = $\n$\\frac{1}{\\eta}\\int_{x_t\\in X}P(x_{t+1}|x_t, u_t)b_tdx_t$ (1)\n$b_{t+1} = \\frac{1}{\\eta}P(z_{t+1} | x_{t+1},\\omega)b_{t+1|t}$ (2)\nwhere $\\eta$ is a normalization constant. Equations (1) and (2) are known as the process and measurement update respectively. Let the combined update be given by $b_{t+1} = \\tau(b_t, u_t, z_{t+1})$."}, {"title": "D. Trajectory Planning in Belief Space", "content": "The most common formulation of trajectory planning minimizes a cost $J: X^T \\times U^T \\rightarrow \\mathbb{R}$. In the presence of uncertainty, we might wish to minimize the expected cost. However, defining the cost explicitly as a function of the belief allows the use of both decision theoretic and information theoretic costs. Therefore, we wish to find a sequence of controls $u_{0:T-1}$ that minimizes an objective $J' : B^T \\times U^T \\rightarrow \\mathbb{R}$, where $B$ is the set of possible beliefs. Restricting to Markovian costs, the objective has the form:\n$J'(b_{0:T}, u_{0:T-1}) = c_T(b_T) + \\sum_{t=0}^{T-1} c_t(b_t, u_t)$. (3)\nwhere $c_t$ is a per timestep cost and $c_T$ is a terminal cost. We wish to solve the following optimization:\n$\\underset{u_{0:T-1}}{\\text{argmin}} J'(b_{0:T}, u_{0:T-1})$\ns.t. $b_0 = b_{[0]}$\n$b_{t+1} = \\tau(b_t, u_t, z_{t+1})$ (4)\nIn this work, we assume that we are only concerned with the uncertainty at the goal, and allow for potentially high uncertainty beliefs along the path, so long as the uncertainty can be resolved by the time the robot reaches the goal."}, {"title": "III. BELIEF ROADMAPS", "content": "POMDP solvers can be used for the problem posed in (4). However, the optimization quickly becomes intractable as the planning horizon increases [5], so we use the belief roadmap (BRM) [7] as our planning approach instead. The BRM navigates to a goal while minimizing uncertainty given a dynamics model, an observation model, and a map of the environment. In this section, we revisit the major compo- nents of the BRM and identify the challenges introduced by landmark evanescence.\nTo make the problem tractable, the BRM makes a num- ber of assumptions. First, the BRM restricts the possible trajectories to a graph where the nodes represent locations and the edges encode a trajectory between nodes, which has the effect of shortening the apparent planning horizon through the introduction of macro-actions, and enabling the reuse of computation. Next, the BRM assumes that the initial pose uncertainty is well modeled by a Gaussian and that the dynamic and observation models are linearizable. These assumptions simplify the process and measurement updates in (1) and (2) into those of an Extended Kalman Filter (EKF) [10]. The BRM determinizes the observations by assuming the maximum likelihood observation is always received. As a result, the innovation during the EKF measurement update is always zero, making the evolution of the state distribution deterministic. For our problem, the belief is no longer Gaussian. To remedy this shortcoming, we use a Gaussian mixture belief where each component captures the belief under a given evanescence configuration.\nThe BRM performs a breadth first search, starting with the initial belief and propagating the belief across an edge using the EKF updates for each node expansion. Since the EKF is a recursive filter, traversing an edge with different initial beliefs normally requires applying each update in turn. However, a key insight of [7] is that an appropriate factorization of the belief covariance allows for linear updates, which can be coalesced into a single step, greatly accelerating the search. For our problem, a different belief means the efficient updates are not applicable. We show that with additional bookkeeping, the efficient updates can be recovered.\nIf each node in the graph has a branching factor $b$, then the number of paths of length $l$ is $b^l$. The BRM employs a domi- nance check to prune branches of the search tree, reducing the number of paths under consideration. Specifically, if a path reaches a node that was traversed by another path with lower uncertainty, then the first path is pruned. In [7], the trace of the covariance matrix is used to compare two beliefs. For our problem, we must define how to compare two different Gaussian mixtures to enable pruning. We use the probability mass within a region to perform this comparison."}, {"title": "IV. BELIEF ROADMAPS WITH UNCERTAIN LANDMARK EVANESCENCE", "content": "In this section, we present two attempts at reconciling landmark evanescence with the assumptions of the BRM. The first, which we call Belief Roadmaps with Uncertain Landmark Evanescence (BRULE), replaces the belief used in the BRM with a Gaussian mixture. An alternative, which we call BRULE-Expected (BRULE-E), resolves the incon- sistencies by applying the BRM on configurations sampled from the LEPD and then evaluating the generated paths."}, {"title": "A. Gaussian Mixture Belief Representation", "content": "A Rao Blackwellized belief [11] is one where a subset of the variables are sampled and the remaining variables are described by a simple distribution conditioned on the sampled subset of variables. We note that conditioned on an evanes- cence configuration, the robot state belief is still Gaussian.\nThis suggests that a belief can be used where each evanes- cence configuration $\\omega$ has a particle belief $p_\\omega(x) = P(x | \\omega)$ with an associated particle weight $P(\\omega)$. The resulting state belief is a Gaussian mixture:\n$P(x) = \\sum_{\\omega \\in \\Omega}P(\\omega)\\mathcal{N}(x | \\mu_\\omega, \\Sigma_\\omega)$. (5)\nSince $\\Omega = 2^{|M|}$, the number of particles required to represent the belief exactly quickly becomes intractable, even in simple environments. However, there is an opportunity for efficiency gains. Initially, when no observations have been made, all particles will have the same particle belief. After the robot observes landmark $l_i$, the particles $P_0 = \\{p_\\omega | \\omega_i = 0\\}$ make one update and the particles $P_1 = \\{p_\\omega | \\omega_i = 1\\}$ make a different update. We refer to $P_0$ and $P_1$ as indistinguishable sets of particles. If $n$ landmarks have been observed, we ex- pect there to be $2^n$ indistinguishable sets. The particle weight is the total probability of the associated indistinguishable set. Since $n \\leq |M|$, significant savings can be realized by instead associating each indistinguishable set with a particle. However, the number of particles still grows exponentially, which we address in IV-D."}, {"title": "B. Belief Update with Landmark Evanescence", "content": "Next we tackle the propagation of the new belief across an edge. We start with the general process and measurement updates shown in (1) and (2) and show that closed form updates can be derived using the existing BRM assumptions. Starting with the process update, we incorporate the evanes- cence configuration $\\omega$:\n$b_{t+1|t} = \\int_{x_t \\in X} P(x_{t+1} | x_t, u_t) P(x_t, \\omega | u_{0:t-1}, z_{1:t}) dx_t$. (6)\nTaking advantage of independence relations and rearranging:\n$b_{t+1|t} = P(\\omega | u_{0:t-1}, z_{1:t}) \\int_{x_t} P(x_{t+1} | x_t, u_t)P(x_t | \\omega, u_{0:t-1}, z_{1:t})dx_t$. (7)\nWe see that each particle is updated by maintaining the particle weight and then performing the usual EKF process update to the associated particle belief.\nNow we define the measurement update. We take advan- tage of the law of total probability to split the observations of the landmark $l_i$ into two cases, one where a measurement is acquired $(z \\in \\mathbb{R}^{d_z})$ and one where it is not acquired $(z = o)$,\n$P(z | x_{t+1}, \\omega) = P(\\exists_{z=o} | x_{t+1}, \\omega)P(z | \\exists_{z=o}, x_{t+1}, \\omega) + P(\\exists_{z \\neq o} | x_{t+1}, \\omega)P(z | \\exists_{z \\neq o}, x_{t+1}, \\omega)$, (8)"}, {"title": null, "content": "where $\\mathbb{I}_{z=o}$ is the indicator function that equals one when $z = o$. The measurement update for $l_i$ then becomes:\n$b_{t+1} = \\frac{1}{\\eta} b_{t+1|t}P(z_{i,t+1} | x_{t+1},\\omega) = $\n$\\frac{1}{\\eta} [P(z_{i,t+1} = o | x_{t+1},\\omega)P(\\omega | u_{0:t}, z_{1:t}) \\int P(z_{i,t+1} | z_{i,t+1} = o, x_{t+1},\\omega)P(x_{t+1} | \\omega, u_{0:t}, z_{1:t})\n+\n P(z_{i,t+1} \\neq o | x_{t+1},\\omega)P(\\omega | u_{0:t}, z_{1:t}) \\int P(z_{i,t+1} | z_{i,t+1} \\neq o, x_{t+1}, \\omega)P(x_{t+1} | \\omega, u_{0:t}, z_{1:t})]$ (9)\nwhere terms $A$ and $C$ correspond to the updated particle weights depending on whether $l_i$ is observed or not, and terms $B$ and $D$ are the updated particle beliefs.\nLet us consider a few cases to gain a better understanding of the update. When $\\omega_i = 0$, then $\\forall x_{t+1} \\in X, P(z_{i,t+1} \\neq o | x_{t+1} \\omega) = 0$, so the term $CD = 0$, and only the term $AB$ remains. Since $P(z_{i,t+1}=o = 1 | x_{t+1},\\omega) = 1$, the particle weight remains unchanged. Additionally, $P(z_{i,t+1} = o | z_{i,t+1} = o, x_{t+1}, \\omega) = 1$ and the particle belief also remains unchanged. Therefore, if $l_i$ is known to be absent, the associated observation updates do not change the belief.\nMeasurement updates when $\\omega_i = 1$ require more care. Un- der the observation model in Sec. II-B, a lack of measurement $(z_{i,t+1} = o)$ implies that the true state must be at least $r_{max}$ away from $l_i$. Since the particle belief has infinite support, some portion of the belief will be within detection range and the rest will lie outside. Incorporating this non-Gaussian observation would break our Gaussian particle belief as- sumption. This non-Gaussian property greatly complicates the estimation problem, but in planning, we can choose to leverage the maximum likelihood observation assumption to condition the observations on the mean of the particle belief $\\mu_{t+1}$ instead of on $x_{t+1}$. Therefore, when $l_i$ is more than $r_{max}$ away from $\\mu_{t+1}$, we assume that no measurement is received and the particle belief is unchanged, as above. When $l_i$ is less that $r_{max}$ away from $\\mu_{t+1}$, the entire belief is updated with the received observation. In this case, we recognize $D$ as an EKF measurement update. We also note that all particle beliefs share the mean.\nUsing (7) and (10), we can efficiently predict future beliefs to help in solving (4). The Gaussian mixture belief combined with the maximum likelihood observation assumption means that we can propagate each particle using the efficient BRM updates developed in [7]."}, {"title": "C. BRM Pruning Heuristic with Gaussian Mixture Belief", "content": "The BRM uses a pruning heuristic to limit the number of paths under consideration. Specifically, if a path visits a node that was previously visited and the new path has higher uncertainty (as measured by the trace of the covariance) than the previous visit, then the new path is pruned. As the belief is now a Gaussian mixture, a new method of computing a scalar quantity of uncertainty is required, $||\\u00b7||_P : B \\rightarrow \\mathbb{R^+}$.\nIn this work, we use the probability mass within a region $R \\subset X$ around the mean state belief, although the effect of different norms could be interesting and is left for future work. Concretely, we define:\n$||b||_P = E_{\\omega \\sim P(\\omega)}[\\int_{x \\in R}P(x | \\omega) dx]$ (11)\nWith these modifications, we are now able to run the BRM with a Gaussian mixture belief. However, as was previously noted, the number of particles in a belief grows exponentially in the number of landmarks observed along a path. While this computational complexity may be manageable in environ- ments with sparse landmarks, it quickly becomes untenable in even modestly dense environments. We now show how to bound the number of particles."}, {"title": "D. Bounded Size of Belief", "content": "To determine the relative value of one path over another, BRULE only requires access to the belief through the size of the uncertainty $||b||_P$. We propose tracking an approximate belief $b^*$, which maintains a bounded number of particles, chosen in such a way that $||b|| \\approx ||b||_P$.\nLet $b$ be a belief with $N$ particles. The approximate belief $b^*$ with $n$ particles is constructed by sampling $I_n \\subset \\{1,...,N\\}$ where $|I_n| = n$ without replacement according to the particle weights. In [12], it is proved that estimates of expectations based on a particle filter converge almost surely with error governed by the central limit theorem. While this result was derived assuming sampling with replacement, in [13] and [14], it was shown that estimates when sampling without replacement have lower error.\nThe straightforward implementation of weighted sampling without replacement can be inordinately slow. The method proposed in [15] performs the sampling in $O(n \\log k)$ time where $n$ is the number of particles and $k$ is the number of desired samples. Since the particle beliefs are not required when sampling particles, significant time and space is saved by deferring the computation of edge transforms and updated beliefs until after sampling."}, {"title": "E. BRULE-Expected", "content": "An alternative approach to solving the optimization prob- lem in (4), is to sample paths and select the path that performs best in expectation. The performance of this method relies heavily on the ability to focus sampling on high qual- ity paths. We propose sampling evanescence configurations $\\{\\omega^i\\}_{i=1}^{N_\\omega}, \\omega^i \\sim P$ and then using the conventional BRM to find a path $p^i$ for each sampled configuration $\\omega^i$, and then using the path that performs best in expectation over all sampled configurations. The paths sampled are of high quality because each path is optimal for some configuration. However, even in the limit, the optimal path over all possible"}, {"title": "V. EVALUATION", "content": "To evaluate the proposed BRULE and BRULE-E algo- rithms, we perform a series of simulation and real-world experiments. The simulation experiments are aimed at un- derstanding the impact of the number of particles on the uncertainty reduction and computational cost. The real-world experiments are aimed at validating the problem formulation."}, {"title": "A. Simulation Experiments", "content": "To evaluate the proposed approach, we perform simulated experiments in a 100m \u00d7 100m region. We use a regular 8- connected grid with 10m spacing as the roadmap. For each experiment, an environment consisting of landmark locations and an LEPD are sampled. The roadmap, landmarks, and LEPD are used by each planner to create a plan. The expected probability mass near the goal is computed by rolling out each plan using 1000 evanescence configuration samples.\nAs a baseline, we consider the original BRM with an optimistic assumption that all previously mapped landmarks are present. For the BRULE and BRULE-E algorithms, we evaluate the performance as the number of particles maintained or paths sampled increases. As the difficulty of environments can vary dramatically, we compute the regret against a planner that has privileged information. Specifically, for each of the evaluation trials, we run the BRM with the sampled configuration. Note that the planner with privileged information may still perform worse since pruning performed during search may discard a lower uncertainty plan.\nWe explore two kinds of correlation structures, the mutex structure and the latent structure. In the mutex structure, exactly one landmark in each set of landmarks is present. In the latent structure, there is a latent variable $z \\sim Bern(p_z)$. If $z = 0$, then no landmarks are present. If $z = 1$, then each landmark is present with probability $p_l$, and is independent of every other landmark. Completely independent landmarks can be achieved by setting $p_z = 0$. We also explore two kinds of spatial landmark distributions, diffuse and clustered. Diffuse landmarks are sampled uniformly from the simulation region without any constraints. Clustered landmarks are sam- pled in a two step process. First, cluster centers are sampled uniformly. Next, landmarks are sampled uniformly from a 10m \u00d7 10m region around the cluster center. We sample environments by combining these correlation structures and spatial distributions. We explore the behavior of the different methods in 66 different environments which are described in Table I. We show examples of the environments in Fig. 2.\nThe results for the simulation experiments are shown in Fig. 3 with 13200 trials per planner. We see that even with 10 particles or samples, BRULE and BRULE-E outperform the optimistic BRM baseline. As the size of the planners increase, we see that they remain comparable with each other. However, at 1000 samples, BRULE has a runtime that is nearly an order of magnitude lower than BRULE-E."}, {"title": "B. Real-World Experiments", "content": "To validate our problem formulation, we perform a limited set of trials in MIT's Killian Court on a real robot. We manually place landmarks, prescribe an LEPD, define a roadmap, and ask the robot to navigate to the goal location while minimizing uncertainty (see left plot in Figure 4). We use the Boston Dynamics Spot as the robot platform, which provides 360\u00b0 camera coverage, odometry measurements, and a low level navigation stack that accepts body relative pose commands. All image processing, state estimation, and"}, {"title": null, "content": "planning is performed on an Nvidia Xavier NX. To create the landmarks, we place AprilTags [16] in the environment and use [17], [18] to get range and bearing measurements in the robot frame from the camera images. The odometry is fused with landmark range and bearing observations using an EKF SLAM filter [19] to maintain a belief over the landmark locations and robot pose. This belief, along with the specified LEPD and roadmap, serve as the inputs for planning.\nIn this experiment, we prescribe a mutex distribution over the landmarks near node 6 and node 9. The landmarks near the start are always present so the robot starts with a well known belief. All other landmarks are set to absent. At the start of a trial, an evanescence configuration is sampled from the LEPD and the estimator is told to ignore detections coming from absent landmarks.\nIn the right plot of Fig. 4, since BRULE-E only has sample access to the LEPD, we observe that it fails to correctly reason about the mutual exclusion of landmarks and plans a path that only visits one of the two potential landmarks. This leads to the higher crosstrack error seen in Fig. 5 as half of the trajectories do not observe any landmarks. In contrast, the Gaussian mixture belief maintained by BRULE allows the planner to produce a path that visits both landmarks, resulting in a smaller crosstrack error. BRULE achieves a mean position error of 55 cm and a standard deviation of 8 cm, while BRULE-E achieves a mean error of 69 cm and a standard deviation of 51 cm. We again note the tighter standard deviation of the BRULE trials as compared to the BRULE-E trials. The mean error for both is similar and includes error from odometry and mapping error."}, {"title": "VI. RELATED WORKS", "content": "Since the original publication of the Belief Roadmap in [7], there have been many avenues through which additional sources of uncertainty have been incorporated or other search strategies have been developed. The Robust BRM [8] con- siders the problem tackled by the BRM with the additional complexity that sensor observations are intermittently avail- able, for example ranging information from a radio beacon in the prescence of occluders. A key assumption is that absence or presence of a measurement is independent over time. In our problem, the absence or presence of a measurement is directly correlated with whether or not the landmark is present. Missiuro and Roy [9] consider the case where there is no uncertainty in robot position, but the uncertainty is in obstacle position. In [20], Indelman et al. relax several assumptions, including the need to discretize actions and the maximum likelihood observation assumptions, but they do not handle hybrid beliefs. In [21], Van den Berg et al. assumes knowledge of the LQR controller to compute beliefs using an LQG controller to find the best path among a set of candidates. However, as we have shown in this work, finding high quality paths often requires reasoning about the correlation structure of the LEPD. FIRM [22] use the belief stabilizing property of the LQG controller to create independence between edges. However, they assume that all states are observable at all times. Rosen et. al. [1] borrowed the concept of hazard functions from survival analysis to describe the evanescence of a landmark. Nobre et. al. [2] extends [1] to introduce correlations between landmarks and show how a LEPD can be used to improve data association."}, {"title": "VII. CONCLUSION", "content": "In this work, we introduced the problem of landmark evanescence. We have also shown that tracking the evolution of a richer Gaussian mixture belief can be made tractable by maintaining a subset of mixture components. We have shown through our experiments that the approach can scale to mod- erately complex environments and is efficient enough for use in a real-world robotic system. In the future, interesting av- enues may include incorporating other types of environment evolution, such as landmark drift, and incorporating noisy observation models that model phenomena like occlusion."}]}