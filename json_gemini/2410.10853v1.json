{"title": "MITIGATING HALLUCINATIONS USING ENSEMBLE OF KNOWLEDGE GRAPH AND VECTOR STORE IN LARGE\nLANGUAGE MODELS TO ENHANCE MENTAL HEALTH SUPPORT", "authors": ["Abdul Muqtadir", "Ayesha Yousaf", "Hafiz Syed Muhammad Bilal", "Hafiz Farooq Ahmed", "Jamil Hussain"], "abstract": "This research work delves into the manifestation of hallucination within Large Language Models\n(LLMs) and its consequential impacts on applications within the domain of mental health. The\nprimary objective is to discern effective strategies for curtailing hallucinatory occurrences, thereby\nbolstering the dependability and security of LLMs in facilitating mental health interventions such as\ntherapy, counseling, and the dissemination of pertinent information. Through rigorous investigation\nand analysis, this study seeks to elucidate the underlying mechanisms precipitating hallucinations in\nLLMs and subsequently propose targeted interventions to alleviate their occurrence. By addressing\nthis critical issue, the research endeavors to foster a more robust framework for the utilization of\nLLMs within mental health contexts, ensuring their efficacy and reliability in aiding therapeutic\nprocesses and delivering accurate information to individuals seeking mental health support.", "sections": [{"title": "Introduction", "content": "Mental health is an increasing concern in our fast-paced and digitally connected world [1]. However, mental health\nservices have traditionally been associated with accessibility, affordability, and stigma. Additionally, face-to-face\nmeetings with consultants are limited in time and space. As a result, many people refuse to seek help for these problems,\nputting their mental health at risk. As the need for mental health support continues to increase, there is an urgent\nneed for new developments to meet this need [2]. Virtual discussion techniques such as LLM's based digital twins are\nbeing increasingly used in psychological support to help clients and patients explore, gain insight, take action, and\nultimately self-heal without needing proper human support [3]. However, the current virtual counseling process tends to\nfocus on the counselor's opinions and often ignores the patient's behavior [4] [5]. This tendency leads to inappropriate\nor unnecessary argumentation strategies and collaborative interactions in discussion. Despite these advancements,\na shortcoming of Large Language Model (LLM) content generation is hallucination, i.e. including false positive\ninformation in the response. In the real world, it is very difficult to make judgments about hallucinations (errors of fact\nor opinion in the LLM). This is because the description of semantics in the real world is still an open problem. We define\nthe legal world of computing as a world where failure is clearly discussed. In this world, hallucinations occur in the\nLLM. We draw an important conclusion from this: hallucination is an inevitable part of any dynamic LLM regardless\nof the model, learning algorithm, method support, or knowledge. Since the formal world is part of the real world, the\nresults also apply to real-world LLMs [6] [7]. LLMs face the challenge of correctly interpreting words or concepts\nwhen the meaning is ambiguous and outside the knowledge domain of the model. This limitation poses significant\nchallenges, particularly in critical domains such as healthcare, where accuracy is paramount [8]. Additionally, training\nmaterials contain misinformation, biases, or inaccuracies. In that case, these flaws may be reflected or amplified in the\ncontent created by these standards link which leads to outputs that may look imaginable but are often irrelevant or out\nof context [8]. Solving the hallucination problem in such models is difficult due to the nature of the phenomenon of\nthese models. These models work probabilistic nature which means they may be prone to hallucinations or delusions,\ndue to this reason they tend to deviate from the real-world scenarios and possibilities. To effectively solve this problem,\nthere have been continuous research efforts in making knowledge bases and fine-tuning models [9]."}, {"title": "Related Work", "content": "There are about 40 different types of mental health chatbots, most of which are designed to treat depression or autism.\nCurrently, many chatbots available combine elements of cognitive behavioral therapy (CBT) with gaming tools to\nenhance the user experience, but very few chat-bots can help manage thoughts and sentiments through a fusion of tools\nand techniques such as Dialectical Behavior Therapy (DBT), evidence from CBT, and guided meditation. And they\nappear to be working: According to the results of a 2017 study by the Stanford University School of Medicine and the\ndevelopers of the software called Woebot, the robots are quite functional in reducing depression. After just two weeks\nof treatment, these digital mental health support tools seem to be humane among college students. [10]\nThe utilization of LLMs in mental health services is a growing area. Researchers have proposed models that can help\nemployees provide effective counseling or peer support. They have also created Emotional Support Conversations\n(ESCs) or conversations based on Hill's Helping Skills Theory [11] to create support to reduce daily stress. A major\nrisk posed by LLMs in the domain of mental health is hallucination [12].The traditional division of hallucination is the\ninternal-external dichotomy[13] [14]. Internal hallucinations occur when the LLM output is against the input. External\nhallucinations occur when the LLM output cannot identify the information in the input. Hallucinations are needed to be\neliminated from LLM responses especially in the healthcare field in order for them to be reliable and appropriate for the\none seeking their assistance and employing them instead of actual specialist. The area of large language model (LLM)\nhallucination mitigation has attracted a significant amount of interest lately [15]. Recent comprehensive surveys [8]\non the types and causes of hallucinations in natural language generation have been made available by previous works.\nThese surveys emphasize that the probabilistic nature of LLMs, a lack of training data, or the models' attempt to patch\nin knowledge gaps with erroneous but plausible-sounding information can all lead to hallucinations. However, there is\nstill room left for research on the production of integrated dialogue systems for cognitive health assistance [8]. To the\nbest of our knowledge, this is the early research that specifically focuses on critically reviewing methods for augmenting\nlarge language models (LLMs) using combination of structured knowledge from knowledge graphs and dense vector\nrepresentation from vector stores. In particular, we concentrate on addressing hallucinations in LLMs by integrating\nknowledge graphs and vector stores at the same time."}, {"title": "Methodology", "content": "Language modeling is an important task in natural language processing (NLP), which focuses on understanding\nlanguage patterns and generating text. It has gained importance in recent years. Specifically, in probabilistic neural\nlanguage models, the goal is to predict the probability of a sequence of words. It involves counting the probability of\neach coin in the sequence, including previous coins, using the chain rule to simplify the process. The introduction of\nthe Transformers architecture [16] effectively improves the probabilistic neural language model and makes it more\nefficient to match and identify distant areas of text. When combined with previous training such as remedial training\nand learning support with human language feedback (RLHF), these abstract language models have led to the formation\nof large-scale language models (LLMs), such as GPTLMs."}, {"title": "Ensemble Retriever Framework", "content": "The proposed solution combines the strengths of vector store retrieval and knowledge graph store retrieval to reduce\nhallucinations in large language models. The ensemble retriever [21] integrates these components to provide a more\naccurate and contextually relevant set of information to the LLM, enhancing its output quality."}, {"title": "System Architecture", "content": "The ensemble retriever system is designed with the following components:\n\u2022 Query Processor: The system parses user input to understand the intent of the query and identify key terms,\nconcepts, and entities. This may involve using techniques such as Named Entity Recognition (NER) and\ndependency parsing. The query is tokenized, and stop words are removed. Additional preprocessing may\ninclude lowercasing, stemming, and lemmatization to normalize the input.\n\u2022 Vector Store Retriever: The Vector Store Retrieval module is responsible for retrieving semantically relevant\ndocuments based on the vector representation of the query. All documents in the corpus are preprocessed and\ntransformed into dense vector representations using the same embedding model as the query. The dense vector"}, {"title": "Vector Store Retrieval", "content": "Vector Store Retrieval relies on embedding-based techniques to represent textual data as dense vectors in a high-\ndimensional space [23]. These vectors encode semantic meaning, allowing for effective matching and retrieval based on\nthe similarity of their embedding rather than just keyword overlap. Some of the use full features of vector store retrieval\nincludes semantic similarity which captures the meaning of text by embedding words, sentences, or documents into\nvectors that reflect their semantic content [24]. Contextual Matching uses these embedding to match user queries with\nrelevant passages, providing contextually appropriate information. Scalability which supports efficient retrieval from\nlarge datasets by leveraging vector-based indexing and search algorithms. The vector representation v of a text T can be\nformulated as:\n$v = f(T)$                                                                                                                                                                                                                                                                                                                                   (1)\nwhere f is the embedding function."}, {"title": "Embedding Generation", "content": "Sentence-Transformers [25], a pre-trained model recognized for producing better sentence embeddings has been used in\nthis research. Using the chosen model, every document in the corpus is transformed into a dense vector representation.\nEffective similarity searches have been seen feasible by the indexing of these vectors in the Chroma Vector Store, a\nhigh-dimensional vector store. A schema-less vector database created for artificial intelligence applications is called\nChroma Vector Store. With the ability to store, retrieve, and handle vector data (embeddings) necessary for LangChain\nand data propagation in chat applications, it is both lightweight and powerful. Using Chroma Vector Store, vector data\ncan be easily managed to improve the accuracy and performance of AI applications."}, {"title": "Retrieval Process", "content": "The user query is transformed into a dense vector using the same embedding model.The nearest neighbor search is\nconducted within the vector store to identify documents with the highest cosine similarity to the query vector. The\ntop-k documents are ranked based on their similarity scores and returned for further processing. Accurate retrieval of\nsemantically similar text can be achieved by comparing query vectors q with indexed vectors $v_i$ The similarity score s\nbetween query vector q and document vector $v_i$ is computed as:\n$s(q, v_i) = cos(q, v_i)$                                                                                                                                                                                                                                                                                                                               (2)"}, {"title": "Knowledge Graph Store Retrieval", "content": "The Knowledge Graph Store Retrieval [26] component utilizes the GENA (Graph for Enhanced Neuropsychiatric\nAnalysis) [22] knowledge graph to provide structured, authoritative information on psychiatric conditions. GENA\nsupports the ensemble retriever system by offering detailed, verifiable data that enhances the factual accuracy and"}, {"title": "Knowledge Graph Construction", "content": "Data Sources: Because of privacy concerns in cognitive health, most dialogue datasets for mental health support are\nsourced from public social platforms, crowdsourcing, and data synthesis. Dialogue datasets collected from public social\nplatforms include the Huggingface datasets. Crowdsourcing involves high costs and time, with the Huggingface dataset\nserving as a typical example. Data synthesis is an effective approach in the era of large language models, often yielding\na large-scale corpus.\nThe dataset used for building a knowledge graph based on the mental health domain is taken from the novel graph\nmodel named \"Graph of Mental-health and Nutrition Association\" usually referred to as 'GENA' [22]. It contained 676\nmental health terms with other domains related to medical health. Such a large amount of information collection lead to\nthe generation of 2,975,076 keyword pairs between Mental Health and the other groups that were used to search for\nrelevant healthcare abstracts.\nThe dataset includes documents that contain information about mental health. During the creation of knowledge this\ndocument data is also used to make use of entities from the text included in the document."}, {"title": "Graph Building Process", "content": "Determination and selection of entities such as conditions, treatments, symptoms, and genetic markers from source data.\nDetermining and extracting the connections between entities by using source data and context. Create a schema that\noutlines the relationship and entity types that are pertinent to psychiatric analysis. Combining information from several\nsources, foreseeing and catering disputes with certain accuracy. Verify the graph's accuracy and completeness by doing\nquality checks, such as cross-referencing with reliable sources and professional evaluations."}, {"title": "Query Processing", "content": "Query Translation:\n\u2022 Natural Language Understanding (NLU): Convert user queries into structured queries that can be executed\nagainst GENA, involving entity recognition, intent detection, and relationship identification.\n\u2022 Cypher Queries: Depending on the graph's underlying technology, GENA supports SPARQL (for RDF-based\ngraphs) or Cypher (for property graphs in systems like Neo4j). We have used Neo4j for our research and have\nrecreated the knowledge graph with all the entities. The retrieval from the knowledge graph can be represented\nas:\n$Results = KGQuery(G, query)$                                                                                                                                                                                                                                                                                                                                       (3)\nwhere G is the knowledge graph and query is the structured query.\nExample: For a query such as \"What genetic factors are linked to bipolar disorder?\", the system translates it into a\nCypher query to find genetic markers related to \"Bipolar Disorder\" in GENA."}, {"title": "Fusion Module", "content": "The Fusion Module plays a critical role in the ensemble retriever system by integrating and refining the results from\nthe vector store retriever and the knowledge graph store retriever. The primary objective is to combine the factual\nprecision of the knowledge graph with the semantic richness of the vector store thus enhancing the benefits of both\nretrieval techniques which eventually helps in eliminating hallucinations. This integration reduces the likelihood of\nhallucinations in large language models (LLMs) by generating responses that are factually accurate and contextually\nrelevant."}, {"title": "Result Integration", "content": "The fusion module integrates the results from the vector store and the knowledge graph store, aiming to produce a\ncomprehensive and accurate response. The aggregated result R is given by:\n$R = Aggregate(R_{vector}, R_{graph})$                                                                                                                                                                                                                                                                                                               (4)\nThe aggregation process involves:\n\u2022 Preliminary Filtering: Both the vector store and the knowledge graph store's initial findings are evaluated\nusing predetermined relevance and accuracy thresholds. This stage of the procedure eliminates findings that\nare irrelevant or of poor quality early on. This elimination ensures that the extra padding or information that\ncan be skipped without disturbing the context is only being presented.\n\u2022 Re-ranking: By combining similarity ratings from the vector store with accuracy metrics from the knowledge\ngraph, the results are reranked. The information that is most factually correct and contextually relevant is\ngiven priority crediting to the re-ranking procedure.\n\u2022 Ensemble Strategies:\n\u2022 Weighted Voting: A confidence score is assigned by each retriever (knowledge graph and vector storage)\nto the results it has retrieved. These scores are combined by the fusion module, which weights the\ninformation from each retriever according to its degree of confidence and contextual significance. High-\nconfidence results from both sources are provided to make a substantial contribution to the final ranking\nproving this strategy to be useful. The final score S can be computed as a weighted sum of individual\nscores:\n$S = w_1S_{vector} + w_2S_{vector} + w_3S_{vector}$                                                                                                                                                                                                                                                                                                                                                                      (5)\nwhere $w_1$, $w_2$, and $w_3$ are the weights for vector similarity, graph accuracy, and contextual relevance\nscores respectively.\n\u2022 Decision Fusion: The top results from each retriever are selected and cross-verified to ensure consistency\nand accuracy. The fusion module may choose to present results from both sources if they complement\neach other, or it may resolve discrepancies by preferring the more accurate or relevant information."}, {"title": "Contextual Disambiguation", "content": "\u2022 Entity Context Matching: In order to make sure the answer conatins the intended context, the user query is\ncross-referenced with entities from the knowledge graph and documents that have been retrieved from the\nvector store. if a query specifies the term \"panic attack\" in relation to a mental disorder. Results pertaining to\nthe term \"panic attack\" would be given precedence over those pertaining to other conditions, for example, if a\nquery specifies the term \"panic attack\" in relation to a mental disorder.\n\u2022 Fact-Checking: Verification is done between the information obtained from the vector store and the structured\ndata discovered in the knowledge graph. This stage assists in tracking down and eliminating contradictions,\nconfirming that the finished response is factually accurate as well as semantically relevant. The knowledge\ngraph, for instance, is used to verify the legitimacy of treatment choices for diseases that the vector store has\nretrieved."}, {"title": "Case Study", "content": "A series of medical queries were used to evaluate the system's performance, including:\n\u2022 \"What are the symptoms and treatment options for hypertension?\"\n\u2022 \"How metformin interacts with insulin in diabetes facilitation?\"\n\u2022 \"What are the potential problems arising baecause of taking atorvastatin?\u201d\nThese queries were chosen to cover a range of complexity and specificity, reflecting common patient and provider\ninformation needs. The ensemble retriever system showed a marked improvement in accuracy and relevance compared\nto the baseline LLM system. Increased from 78% to 92%. The inclusion of knowledge graph data significantly reduced\nthe rate of incorrect information. Enhanced contextual understanding was observed, with relevance scores improving\nfrom 70% to 88% as reviewed by medical experts.\nFor the query \"How does metformin interact with insulin in diabetes management?\", Regarding diabetic drugs, the initial\nsystem offered a generic response. The ensemble retriever, on the other hand, provided an extensive rationale of the\npharmacodynamics and particular interactive effects of insulin and metformin, based on clinical recommendations and\norganised medical data. With the ensemble retriever, the hallucination rate decreased from 22% in the baseline system to\n5%. The knowledge graph drastically decreased hallucinations through fact-checking and the distribution of organised,\nreliable material. Occasionally, the baseline system produced answers to the question \"What are the symptoms and\ntreatment options for hypertension?\" that contained inaccurate or out-of-date therapy suggestions. With the help of the\nknowledge graph's amended medical recommendations, the ensemble retriever regularly offered precise and up-to-date\nmedicinal properties. Patients' and healthcare professionals' feedback revealed a greater level of confidence in the\nsystem's ability to respond. On a 5-point rating, satisfaction scores increased from an average of 3.8 to 4.6. Users noted\nthat the responses were more in line with modern medical norms and practices, and they valued the increased accuracy\nand complexity of the material."}, {"title": "Performance and Evaluation:", "content": "For the evaluation of our Ensemble RAG, we have used a popular evaluator provided by HuggingFace named evaluator.\nOur evaluation shows that the responses generated by ensemble RAG are better than the ones generated without\nensemble evaluation either using vector-based RAG or Knowledge Graph-based RAG."}, {"title": "Discussion", "content": "The experimental results demonstrate that the proposed ensemble retriever system effectively mitigates hallucinations in\nlarge language models (LLMs). The integration of knowledge graphs significantly reduces the hallucination rate, as the\nstructured data provides a reliable basis for fact-checking and context validation. The approach accomplishes a notable\nimprovement in the precision and reliability of generated responses by fusing the factual precision of knowledge graph\nstore retrieval with the semantic characteristics of vector store retrieval. The research's conclusions have a number of\nsignificant ramifications for the creation and use of LLMs in real-world settings.The decreased probability of\nhallucinations depicts that ensemble retrievers can increase the reliability of LLMs for jobs that demand high factual\naccuracy, like automated summarisation, answering questions, and creating material for delicate industries like law and\nhealthcare. The technology increases user happiness and trust by producing responses that are more accurate and\nrelevant for the given context. This can be especially helpful in conversational AI systems and customer service, where\nusers depend on the accuracy of the information given. The methodology demonstrated that it is not only efficient but\nalso domain-adaptable to combine vector and knowledge graph storage. The system is robust as well as appropriate for\na variety of knowledge-driven applications due to the fact that it can integrate many kinds of data sources."}, {"title": "Conclusion, Limitations and Future Work", "content": "By utilising the mutually beneficial advantages of structured knowledge graph retrieval and sparse vector retrieval, this\nsystem architecture makes sure that the generated responses are factually correct and have a rich semantic\nrepresentation. The key to reducing hallucinations in LLMs is this dual retrieval strategy. Using both vector store\nretrieval and knowledge graph store retrieval in the suggested ensemble retriever architecture makes LLMs significantly\nmore accurate and reliable by minimising hallucinations, which is very useful in the mental health industry. This\ntechnique successfully blends the factual precision of knowledge graphs with the semantic richness of vector stores.\nThis results in responses that are more relevant for the context and correct in terms of facts. The evaluations give\nconfirmation of the advantages of this ensemble system contrasted to individual retrievers, including greater user\nconfidence, heightened precision, and higher performance in managing difficult problems. Furthermore, the system is a\nviable tool for AI-powered mental health support and other applications needing a high degree of comprehension\nbecause of its ability to adapt to different datasets and sectors. This framework provides a significant improvement in\nthe practical application of artificial intelligence (AI) by enhancing the trustworthiness of LLMs, particularly in delicate\nsectors like healthcare.\nDespite its positive aspects, the ensemble retriever structure has some drawbacks. Its effectiveness in sectors with\nscarce or defective structured data may be limited by the knowledge graph's comprehensiveness and effectiveness,\nwhich have a significant impact on its performance. Large datasets in vector storage can improve semantic retrieval, but\nthey can also introduce noise that might affect retrieval accuracy if it is not carefully regulated. Additionally, compared\nto independent systems which are based on a single retriever, the dual retrieval system has a greater computation cost,\nwhich leads to prolonged reaction times. This trade-off between increased accuracy and longer processing times\nrequires adaption based on specific application needs, particularly where efficiency is critical. To improve the system's\nscalability and adaptability throughout a wider range of applications and domains, these limits must be resolved."}]}