{"title": "MorphBPE: A Morpho-Aware Tokenizer Bridging Linguistic Complexity\nfor Efficient LLM Training Across Morphologies", "authors": ["Ehsaneddin Asgari", "Yassine El Kheir", "Mohammad Ali Sadraei Javaheri"], "abstract": "Tokenization is fundamental to Natural Lan-\nguage Processing (NLP), directly impacting\nmodel efficiency and linguistic fidelity. While\nByte Pair Encoding (BPE) is widely used in\nLarge Language Models (LLMs), it often dis-\nregards morpheme boundaries, leading to sub-\noptimal segmentation-particularly in morpho-\nlogically rich languages. We introduce Mor-\nphBPE, a morphology-aware extension of BPE\nthat integrates linguistic structure into subword\ntokenization while preserving statistical effi-\ncency. Additionally, we propose two mor-\nphology based evaluation metrics: (i) Morpho-\nlogical Consistency F1-Score, which quanti-\nfies the consistency between morpheme shar-\ning and token sharing, contributing to LLM\nconvergence, and (ii) Morphological Edit Dis-\ntance, which measures alignment between mor-\nphemes and token concerning interpretabil-\nity. Experiments on English, Russian, Hun-\ngarian, and Arabic across 300M and 1B param-\neter LLMs demonstrate that MorphBPE con-\nsistently reduces cross-entropy loss, acceler-\nates convergence, and improves morphological\nalignment scores. Fully compatible with ex-\nisting LLM pipelines, MorphBPE requires\nminimal modifications for integration. The\nMorphBPE codebase\u00b9 and tokenizer play-\nground\u00b2 will be available.", "sections": [{"title": "1 Introduction", "content": "Tokenization is a fundamental preprocessing step\nin NLP, converting raw text into structured units\nsuch as bytes (Gillick et al., 2016), characters (Al-\nRfou et al., 2019), subwords (Sennrich et al., 2016),\nwords, or multi-word expressions (Gee et al., 2023).\nIts effectiveness directly influences downstream\ntasks, as tokenization errors can propagate through\nthe pipeline, impacting overall model performance\n(Sajjad et al., 2017; Adel et al., 2018). Over\nthe years, tokenization has advanced from basic\nwhitespace-based segmentation to sophisticated sta-\ntistical and neural approaches (Smit et al., 2014;\nOtani et al., 2020). In Large Language Mod-\nels (LLMs), tokenization significantly affects ef-\nficiency, context length, and representational accu-\nracy (Dagan et al., 2024). Although tokenization-\nfree architectures have been investigated as poten-\ntial alternatives (Clark et al., 2022; Deiseroth et al.,\n2024), most state-of-the-art models-including\nGemma (Team et al., 2024), LLaMA (Touvron\net al., 2023), DeepSeek (Bi et al., 2024) and Ope-\nnAI's GPT series\u2014still rely on Byte Pair Encoding\n(BPE)-based tokenization for most languages, re-\ntaining both its benefits and inherent limitations.\nThe additive nature of Byte Pair Encoding (BPE)\nmakes it well-suited for concatenative morphol-\nogy, as seen in English, where morphemes are lin-\nearly appended. However, it struggles with non-\nconcatenative morphological systems, such as root-\nand-pattern morphology in Arabic and Hebrew,\nwhere meaning is encoded through non-linear in-\nfixation (Khaliq and Carroll, 2013). Similarly, ag-\nglutinative languages like Turkish, Hungarian, and\nKorean pose challenges, as their highly produc-\ntive affixation processes complicate adherence to\nmorpheme boundaries (Hakkani-T\u00fcr et al., 2000).\nThese languages require finer-grained tokeniza-\ntion to preserve linguistically meaningful subword\nstructures. Standard BPE and byte-level tokeniza-\ntion methods often struggle to represent these com-\nplex morphological patterns effectively, empha-\nsizing the necessity for morphology-sensitive to-\nkenization approaches that better align with the\ndiverse structural properties of different word for-\nmation processes (Marco and Fraser, 2024).\nAnalyzing BPE output across morphologically\nrich languages, we observe that its segmentation\noften disregards meaningful morpheme boundaries,\nintroducing ambiguity and disrupting semantic co-"}, {"title": null, "content": "herence. For instance, in Arabic, the word \u0627\u0644\u0631\u062d\u0645\u0646\n(Al-Rahman, \u201cThe Merciful\u201d) may be incorrectly\nsegmented into \u0645\u0646 )min, whom( \u0627\u0644 )al, \u201cthe\u201d( +\n\u0631\u062d )rah, an incomplete fragment). Here\n\u2022 Arabic: Templatic, high complexity\nMorphBPE achieves superior morphological\nalignment and consistency, enhancing model in-\nterpretability.\n(min), \na frequent token, is semantically unrelated to the\noriginal word, increasing the model's burden in re-\nconstructing meaningful representations. Similar\nchallenges arise in agglutinative and polysynthetic\nlanguages, where BPE's greedy merging strategy\noften fails to align with true morpheme boundaries.\nWhile purely morphology-based segmentation\ncould mitigate these issues, it has also shown\nlimitations in aligning with naturally occurring\nlinguistic patterns in corpus-based learning (Dur-\nrani et al., 2019; Marco and Fraser, 2024). Thus,\ndeveloping tokenization methods that balance\nmorphological integrity with statistical efficiency\nremains a critical challenge for multilingual NLP.\nContributions: We introduce MorphBPE, an\nextension of Byte Pair Encoding (BPE) that inte-\ngrates linguistic knowledge into subword tokeniza-\ntion. Our key contributions are:\n(i) A Morphology-Aware LLM Tokenizer:\nMorphBPE improves adherence to linguistic\nstructures while identifying frequent patterns, bal-\nancing token efficiency and interpretability, partic-\nularly in morphologically rich languages. It ex-\ntends BPE by incorporating morphological struc-\nture while remaining fully compatible with existing\nLLM training pipelines.\n(ii) Linguistically Informed Tokenizer Evalua-\ntion Metrics: We introduce morphology-aware\nevaluation metrics to assess tokenization quality:\n\u2022 Morph.-Edit Distance Score: Measures edit\ndistance at the morpheme level, quantifying\nsegmentation accuracy.\n\u2022 Morph.-Consistency F1-Score: Inspired by\n(Marco and Fraser, 2024), evaluates the seg-\nmentation consistency, offering a linguisti-\ncally grounded metric evaluating whether\nwords that share the same morphemes are also\nassigned the same tokens, and vice versa.\nFor benchmarking, we curate a dataset covering\ndiverse morphological typologies (Ge and Comrie,\n2022):\n\u2022 English: Fusional, low complexity\n\u2022 Russian: Fusional, moderate complexity\n\u2022 Hungarian: Agglutinative, high complexity"}, {"title": null, "content": "(iii) Empirical Evaluation on LLM Training: We\ncompare MorphBPE to vanilla BPE on 300M\nand 1B parameter LLMs across the four languages,\ndemonstrating:\n\u2022 Lower training loss, indicating improved lin-\nguistic representations.\n\u2022 Faster convergence, enhancing computa-\ntional efficiency.\nBy integrating linguistic principles with mod-\nern tokenization strategies, MorphBPE bridges\nthe gap between traditional morphological anal-\nsis and NLP, providing a computationally effi-\ncient and morphologically interpretable tokeniza-\ntion approach for language modeling, particularly\nin morphologically rich languages like Arabic. In\nline with this, MorphBPE3 has been developed\nand implemented in Fanar\u2074, an Arabic-centric lan-\nguage model, leading to significant improvements\nin model performance (FanarTeam et al., 2025).\n2 Related Work\nBPE, originally introduced as a text compression\nalgorithm (Shibata et al., 1999), was first adapted\nfor machine translation as a tokenization method in\n2016 (Sennrich et al., 2016). Since then, it has be-\ncome the de facto standard in NLP and Large Lan-\nguage Models (LLMs) due to its efficiency in man-\naging vocabulary size, handling out-of-vocabulary\nwords, and capturing frequent patterns, while offer-\ning partial improvements over morphology-based\ntokenizers (Sennrich et al., 2016).\nDespite its widespread adoption, vanilla BPE\nhas several notable limitations: its greedy merg-\ning strategy, inefficiencies in cross-lingual settings\nwhere similar words with different character varia-\ntions are not aligned, and inconsistent handling of\ncharacter-level information across languages. To\naddress these challenges, various extensions have\nbeen proposed, including BPE dropout (Provilkov\net al., 2020), which introduces stochasticity to im-\nprove generalization, sampling-based BPE (Asgari\net al., 2019, 2020), which enhances subword di-\nversity, byte-level adaptations (Wang et al., 2020),"}, {"title": null, "content": "which aim to improve robustness across scripts, and\nmultilingual BPE variants (Liang et al., 2023), de-\nsigned to optimize token sharing across languages.\nThe importance of morphology-aware tokeniza-\ntion for language models has been recognized in\nseveral recent studies (Park et al., 2021; Jabbar,\n2023; Marco and Fraser, 2024; Weller-Di Marco\nand Fraser, 2024). However, an integrated solution\nthat effectively balances morphological informa-\ntion with frequent pattern extraction while remain-\ning fully compatible with modern LLM training\npipelines has remained an open problem.\n3 Methods\nFigure 2 provides an overview of our approach. To\nsystematically evaluate MorphBPE, we select four\nlanguages with distinct morphological typologies,\nwhere morphological segmentation is available for\ntraining and evaluation at the word level. We de-\ntermine the vocabulary sizes for each language\nbased on optimal alignment with morphological\nboundaries. Then we evaluate the vanilla BPE and\nMorphBPE on the selected vocabulary size using\nintrinsic metrics detailed in \u00a73.3.\n3.1 Datasets\n3.1.1 Morphological Data\nOur dataset comprises morphologically segmented\nwords from four morphologically diverse lan-\nguages (Ge and Comrie, 2022): English, Russian,\nHungarian, and Arabic. The segmentation data\nfor English, Russian, and Hungarian is sourced\nfrom the SIGMORPHON 2022 Shared Task on\nMorpheme Segmentation (Batsuren et al., 2022),\nwhich provides high-quality morpheme segmen-\ntations. To incorporate a root-based (templatic)\nmorphological system, we include Arabic, where,\nwe utilize multiple sources: the Arabic Treebank\n(ATB) dataset (Taji et al., 2017), the Dialectal\nSegmentation Dataset (Darwish et al., 2018), and\nQuranic morphology data (Dukes and Habash,\n2010). Additionally, we enrich this set with 1M\nhigh-confidence segmentations of frequent Arabic\nsurfaceforms obtained using Farasa (Darwish and\nMubarak, 2016). All datasets were cleaned and\nstandardized. Manually annotated segmentations\nwere split into 80% training, 10% validation, and\n10% test sets."}, {"title": "3.1.2 LLM Training Data", "content": "For our study on Evaluating MorphBPE vs. BPE\nAcross Languages with Diverse Morphologies:\nHungarian, Arabic, Russian, and English, we re-\nquire a large-scale multilingual training dataset. We\nselected FineWeb2 (Penedo et al., 2024), a com-\nprehensive corpus covering over 1,000 languages,\nto ensure sufficient tokens for training, following\nthe Chinchilla scaling law (Hoffmann et al., 2022).\nThis choice enables a balanced token distribution\nacross the selected languages, ensuring fair and\nrobust evaluation of MorphBPE and BPE.\n3.2 MorphBPE approach\nMorphBPE is a simple yet effective extension of\nBPE that prevents frequent symbol pair merges\nfrom crossing morpheme boundaries while keeping\nthe rest of the algorithm unchanged (Algorithm 1).\nThis ensures compatibility with standard BPE infer-\nence, making MorphBPE easy to integrate into\nexisting pipelines without modifications."}, {"title": "3.3 Tokenization Evaluation", "content": "Tokenization evaluation can be conducted using\nintrinsic or extrinsic metrics. Extrinsic evaluation\nassesses tokenizers in the broader context of LLM\nperformance across diverse capabilities, requiring\nextensive pre/post training and high-level analysis,\nwhich is beyond the scope of this work (Cecchini\net al., 2024; Chia et al., 2024). Before evaluating\ntokenizers in downstream tasks, it is essential to\nfirst examine fundamental properties to ensure ef-\nficiency and consistency. Therefore, we focus on\nintrinsic evaluation metrics that provide insights\ninto the core characteristics of tokenization in large\nlanguage models (LLMs).\n(i) Fertility ($\\phi$): Fertility quantifies the number of\ntokens generated by a tokenizer relative to a base-\nline, typically a whitespace-based tokenizer (Rust\net al., 2021). A lower fertility score generally in-\ndicates a more efficient representation, enabling\nlonger contexts. However, this assumption is de-\nbatable, particularly for agglutinative languages\nsuch as Hungarian and Turkish, where capturing\nmorphological structure necessitates more tokens\nto provide adequate context for each surface form.\nAs shown in Table 1, languages vary in the aver-\nage number of morphemes per word. For instance,\nHungarian and Arabic require more tokenization\ncompared to English to accurately represent their\nlinguistic structures.\n(ii) Morph.-Edit Distance Score ($\\mu_e$): We intro-"}, {"title": null, "content": "duce a new intrinsic evaluation metric, the morpho-\nlogical edit distance, which assesses how well tok-\nenization aligns with the underlying morphological\nsegmentation of words. This metric is computed\nusing a pairwise alignment score based on dynamic\nprogramming, ensuring that the order of matching\ntokens with segmented morphemes is preserved.\nThis approach quantitatively evaluates how effec-\ntively a tokenizer respects the morphological struc-\nture of the language. We refer to this metric as the\nMorphology Edit Distance Score ($\\mu_e$), which eval-\nuates the interpretability of the tokenizer. While it\ncan be normalized by the number of morphemes\nin each word, we retain its raw form to provide a\nclearer indication of the average number of edits re-\nquired. (iii) Morph.-Consistency Scores (F1: $\\mu_c$):\nInspired by the discussion in (Marco and Fraser,\n2024), we propose a morphology consistency mea-\nsure, which is crucial for language model training.\nIt ensures that words sharing the same morphemes\nalso share tokens (recall score) and that words with\nshared tokens correspondingly share morphemes\n(precision score). This evaluation is conducted over\na dataset of segmented words, where shared mor-\npheme/token relationships can be treated as either\nbinary events or weighted counts. For simplicity,\nwe adopt a binary scheme, checking whether shared\nmorphemes correspond to shared tokens and vice\nversa. Since both precision and recall are essential\nfor avoiding unnecessary ambiguity and maintain-\ning a consistent representation of related words,"}, {"title": "3.4 Vocabulary Size Selection", "content": "Vocabulary size is a critical hyperparameter in\nLLM training, directly impacting model perfor-\nmance across languages. To determine the optimal\nvocabulary size in MorphBPE, for our four lan-\nguages, we employed a morphology distance score,\n$\\mu_e$, computed over the development set. We eval-\nuated vocabulary sizes from 8K to 96K in 8K in-\ncrements, selecting the smallest size beyond which\nfurther increases did not yield statistically signif-\nicant improvements in morphological alignment\n(measured via a t-test over the dev. vocabular-"}, {"title": null, "content": "ies). Through this approach, we determined opti-\nmal sizes of 24K for Hungarian and 64K for Rus-\nsian, where larger vocabularies showed diminish-\ning returns. For English and Arabic, morphology\ndistance continued improving with larger vocabu-\nlaries, leading us to select 96K.\nWe evaluated the selected tokenizers based on\n(i) fertility rate ($\\phi$), (ii) morphological edit distance\nscore ($\\mu_e$), and (iii) morphological consistency\nscore ($\\mu_c$) on the test sets of English, Russian, Hun-\ngarian, and Arabic. Since fertility rate is a relative\nmeasure, we compare both MorphBPE and BPE\nagainst a strong multilingual baseline\u2014Bloomz\n(256K) (Yong et al., 2023), which employs a large\nvocabulary to accommodate multiple languages. In\ncontrast, $\\mu_e$ and $\\mu_c$ are directly computed from\nthe test data to evaluate tokenization quality with\nrespect to linguistic structure.\n(iv) Cross Entropy Loss of Language Modeling\n(lc) Cross-entropy loss in language modeling mea-\nsures the divergence between predicted and ground\ntruth outputs. The trajectory of training cross-"}, {"title": null, "content": "entropy loss indicates how quickly a model con-\nverges and improves next-token prediction. This\nmetric is closely related to model perplexity, a stan-\ndard intrinsic evaluation measure for language mod-\nels. However, cross-entropy loss is only compara-\nble across models with identical vocabulary sizes,\nas vocabulary variations directly affect the model's\nbranching factor.\n3.5 Language Model Training\nTo assess the scalability of our approach, we\ntrained two model sizes-300M (small) and 1B\n(large) using decoder architectures within the\nLLaMA-Factory framework (Zheng et al., 2024).\nFor each language, we trained models with both\nvanilla BPE and MorphBPE of the same vocab-\nulary sizes, resulting in four models per language.\nTraining loss was monitored and compared across\nlanguages and tokenization methods to evaluate\ntheir impact on learning efficiency. We ensured\npassing \u2248 6B tokens to the small and \u2248 20B to-\nkens to the large model compatible with the Chin-\nchilla scaling law (Hoffmann et al., 2022).\n4 Results\n4.1 Morphological Metrics and Fertility\nThe results in Figure 1 and Table 2 show a clear\ntrend: MorphBPE consistently achieves lower mor-\nphological edit distance ($\\mu_e$) and higher morpho-\nlogical consistency ($\\mu_c$) compared to BPE, with a\nslight increase in fertility rate across all languages.\nThe extent of improvement varies based on the\nmorphological complexity of the language. The\ngap in $\\mu_e$ and $\\mu_c$ between MorphBPE and BPE is\nlarger for Hungarian and Arabic, which have more\ncomplex morphological structures. These results\nindicate that MorphBPE better preserves linguistic\nstructure, particularly in morphologically rich lan-\nguages, while BPE tends to over-fragment words\nbased on subword frequency rather than morpheme\nboundaries. Higher $\\mu_e$ of MorphBPE also reflects\nconsistent tokenization which morphology, which\ncan impact the convergence of language model\ntraining."}, {"title": "4.2 Training cross-entropy loss", "content": "The training cross-entropy loss for the four lan-\nguages, using the same vocabulary and comparing\nBPE and MorphBPE, is presented in Figure 3.\nThe results are shown over a training window of\n\u2248 14B tokens for both small and large models,"}, {"title": null, "content": "with the selected interval chosen for clarity, as the\noverall trend remains consistent throughout train-\ning. The results indicate that MorphBPE consis-\ntently improves cross-entropy loss across all lan-\nguages and model sizes, even for English language.\nThis improvement is particularly pronounced in\nmorphologically richer languages, where the reduc-\ntion in loss is more significant. The results demon-\nstrate lower training loss, indicating improved lin-\nguistic representations as well as faster conver-\ngence.\n5 Discussions and Conclusion\nIn this work, we introduced Morph BPE, \u0430\nmorphology-aware extension of BPE that integrates\nlinguistic knowledge into subword tokenization.\nThrough extensive empirical evaluation across En-\nglish, Russian, Hungarian, and Arabic, we demon-\nstrated that MorphBPE consistently enhances\nLLM training efficiency by reducing cross-entropy\nloss, improving morphological alignment, and ac-\ncelerating convergence across both 300M and 1B\nparameter models.\nAnother key contribution of this work is the in-\ntroduction of linguistically informed tokenizer eval-\nuation metrics, addressing a critical gap in current\ntokenization evaluation. The Morphological Con-\nsistency F1-Score provides a structured measure\nof segmentation stability, which is essential for en-\nsuring consistent morpheme-level representations\nduring LLM training. This stability directly con-\ntributes to better generalization and improved learn-\ning efficiency, particularly for morphologically rich\nlanguages. Meanwhile, the Morphological Align-\nment Score, based on edit distance at the morpheme\nlevel, serves as a linguistically grounded metric,\nthat can contribute to the interpretability of the tok-\nenizer.\nWe show that MorphBPE, despite having\nhigher fertility, results in a more interpretable\nand more consistent and more efficient tokenizer\nfor LLM training. This suggests that fertility\u2014a\ncommonly used metric in tokenization evalua-\ntion-may not be the most reliable indicator of\ntokenizer quality of an efficient LLM training.\nAn additional advantage of MorphBPE is its\nfull compatibility with existing LLM training and\ninference pipelines, requiring minimal modifica-\ntions to the tokenization process. This ensures\neasy integration without disrupting standard work-\nflows. Furthermore, an efficient implementation of"}, {"title": null, "content": "MorphBPE training and evaluation metrics will\nbe released with this work, enabling reproducibil-\nity and facilitating further research in morphology-\naware tokenization.\n6 Limitations\nWe\ndemonstrated\nof\nthe effectiveness\nMorphBPE across four languages with di-\nverse morphological typologies. However, future\nwork can extend this evaluation to additional lan-\nguages. One limitation is that MorphBPE relies\non the availability of morphological segmentation\ndata, which is not yet accessible for all languages.\nEfforts such as UniMorph (Kirov et al., 2018) and\nMorphyNet (Batsuren et al., 2021) are helping\nbridge this gap, but further development is needed.\nAdditionally, an important next step is the extrinsic\nevaluation of LLMs trained with MorphBPE,\nassessing their impact on higher-level capabilities."}]}