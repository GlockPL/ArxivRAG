{"title": "Trajectory Manifold Optimization for Fast and Adaptive Kinodynamic Motion Planning", "authors": ["Yonghyeon Lee"], "abstract": "Fast kinodynamic motion planning is crucial for systems to effectively adapt to dynamically changing environments. Despite some efforts, existing approaches still struggle with rapid planning in high-dimensional, complex problems. Not surprisingly, the primary challenge arises from the high-dimensionality of the search space, specifically the trajectory space. We address this issue with a two-step method: initially, we identify a lower-dimensional trajectory manifold offline, comprising diverse trajectories specifically relevant to the task at hand while meeting kinodynamic constraints. Subsequently, we search for solutions within this manifold online, significantly enhancing the planning speed. To encode and generate a manifold of continuous-time, differentiable trajectories, we propose a novel neural network model, Differentiable Motion Manifold Primitives (DMMP), along with a practical training strategy. Experiments with a 7-DoF robot arm tasked with dynamic throwing to arbitrary target positions demonstrate that our method surpasses existing approaches in planning speed, task success, and constraint satisfaction.", "sections": [{"title": "I. INTRODUCTION", "content": "Kinodynamic motion planning seeks to identify a trajectory that achieves a specified task while meeting various constraints such as joint, velocity, acceleration, torque limits, and avoiding self-collisions. Consider, for example, a 7-DoF robot arm tasked with throwing a ball into a target box. This requires the robot to accelerate and decelerate within these constraints to successfully throw the ball and then come to a stop within a set time frame. Now, suppose the target box unexpectedly moves after the robot has initiated its throwing motion. The robot must quickly adjust its trajectory to adapt to new task requirements while adhering to kinodynamic constraints. In such dynamically changing environments, fast kinodynamic motion planning is crucial for adaptation, which we aim to address in this paper.\nThe problem of kinodynamic planning has been explored through various methods including sampling, search, and optimization techniques [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16]. Despite progress, quickly finding solution trajectories that involve complex, nonlinear dynamics and constraints remains a significant challenge, primarily due to the high dimensionality of the search space. For example, when the planning problem is formulated as an optimization and solved using direct collocation methods [17], the dimensionality increases linearly with the number of discretized time grid points, often reaching thousands of dimensions.\nIn contrast, consider how humans achieve rapid kinody-namic planning. Rather than exploring an entire, large trajectory space, humans are more likely to search through a much smaller space informed by specific motor patterns ingrained, for instance, in muscle memory related to the throwing motion. Building on this concept, we propose identifying a trajectory manifold a lower-dimensional subspace consisting of task-relevant motions offline, and then quickly searching for solutions online within this manifold, as illustrated in Fig. 1.\nEncoding motions with mathematical models, commonly referred to as movement primitives, has been a key focus in the learning from demonstration literature [18], [19], [20], [21], where motions are typically obtained from human demonstrations. Recent advances in the Motion Manifold Primitives (MMP) framework are particularly relevant to our work, as they focus on encoding a manifold of trajectories that capture a diverse set of motions [22], [23], [24]. By incorporating kinodynamic planning algorithms to generate demonstration trajectory data unlike previous works that predominantly relied on human demonstration data - the MMP framework can be seamlessly adapted for our purposes.\nHowever, existing MMPs do not take into account kinodynamic constraints, leading to trajectories that severely violate them. A common solution in deep learning is to introduce an additional loss term during training to enforce constraint satisfaction. However, the discrete-time trajectory represen-"}, {"title": "II. RELATED WORKS", "content": "Kinodynamic planning combines the search for a collision-free path with the system's inherent dynamics, ensuring that the resulting trajectory is feasible [1]. Many sampling, search, and optimization-based methods have been developed [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], but it is still difficult to perform real-time kinodynamic planning for problems with highly nonlinear dynamics and constraints. Some recent efforts have focused on using deep neural networks for fast planning. Learning-based modules have been introduced to improve the planning speed of the popular sampling-based method, the kinodynamic RRT* [13], [14]. Meanwhile, end-to-end neural network planners have been developed [15], [16], though without considering dynamic constraints.\nOf particular relevance to our approach is the Con-strained Neural Motion Planning with B-splines (CNP-B), which generate continuous-time trajectories parametrized by B-splines [26]. The key difference is that our model, a type of generative model, can encode a manifold of continuous-time trajectories, enabling it to generate multiple trajectories for a given task, while CNP-B generates a single optimal trajectory."}, {"title": "B. Motion Manifold Primitives", "content": "Recently, task-conditioned generative models that can generate multiple trajectories for each task parameter have been explored. Given the high dimensionality of trajectory data often represented as a sequence of configurations \u2013, a common approach leverages the manifold hypothesis and employs an encoder-decoder framework to learn a lower-dimensional manifold of trajectories [22], [23], [24]. Initial methods used conditional autoencoder architectures, where decoders took both latent variables and task parameters as inputs [22], [23]. Later, Motion Manifold Flow Primitives (MMFP) demonstrated that first identifying lower-dimensional motion manifolds and then learning flow models within these latent spaces can more effectively capture complex conditional distributions [24].\nHowever, these existing approaches rely on discrete-time trajectory representations, which prevents the generated trajectories from being differentiated over time. This makes it challenging to design loss functions that enforce kinodynamic constraints. Recently, motion manifold primitives utilizing user-defined parametric curve models, which are continuous-time trajectory representations that enable time differentiation, have been introduced [27], focusing on simpler, uncondi-tioned trajectory modeling. In contrast, our approach learns a manifold of continuous-time, differentiable trajectories using more expressive neural network models, without relying on predefined parametric curve models."}, {"title": "III. PRELIMINARIES: MOTION MANIFOLD PRIMITIVES", "content": "This section reviews existing discrete-time MMP methods [22], [23], [24] to clarify their limitations. We begin this section with notations and common assumptions used in these works. Let $Q \\subset \\mathbb{R}^n$ be an n-dimensional configuration space and denote a configuration by $q$. A demonstration trajectory is given as a sequence of configurations $(q_1,...,q_L) \\in Q^L$. We denote a task parameter by $\\tau$ and its space by $T$, which is assumed to be compact. For example, [23] solved a water-pouring task where the position of the cup, the initial pose of the bottle, and the amount of water were considered as $\\tau$, while [24] treated a text embedding vector as $\\tau$ for a language-guided trajectory generation task.\nWe are given a dataset of task-trajectory pairs: for each task parameter $\\tau_i \\in T$, where $i = 1,...,M$, there are $N_i$ trajectories $\\{(q_{ij,1},..., q_{ij,L}) \\in Q^L\\}_{j=1}^{N_i}$. The goal is to learn a model that maps an input task parameter $\\tau \\in T$ to a set of trajectories that fit the distribution of demonstrated trajectories. One naive approach would be to fit a probability density model directly in the trajectory space; however, due to the high dimensionality and limited dataset size, the performance is often suboptimal. To address this issue, MMPs commonly adopt an autoencoder framework for dimensionality reduction."}, {"title": "IV. DIFFERENTIABLE MOTION MANIFOLD PRIMITIVES", "content": "We begin this section with assumptions, notations, and problem definitions. The same notations from section III are used for the configuration $q\\in Q$ and the task parameter $\\tau \\in T$. We consider a fixed terminal time $T$ and denote a smooth trajectory by $q(t)$ for $t \\in [0,T]$. Sometimes, an additional variable is needed to fully represent a motion. We denote this variable as $\\eta$. For example, in the throwing task, the throwing time $\\eta \\in (0,T)$ must be determined so that the object is thrown at $q(\\eta) \\in Q."}, {"title": "A. Data Collection via Trajectory Optimizations", "content": "The goal of this section is to collect multiple trajectories for each $\\tau$, which will be used in the subsequent motion manifold learning. Since it is infeasible to collect data for all $\\tau \\in T$, we first select a finite subset of $T$, denoted by $T_s = \\{\\tau_i\\}_{i=1}^M \\subset T$, that approximately covers $T$. For each $\\tau_i$, we solve the following optimization:\n$\\min_{q(t),\\eta} J(q(\\cdot), \\eta; \\tau_i)$\nsuch that $C(q(t), \\dot{q}(t), \\ddot{q}(t), \\dddot{q}(t)) \\leq 0$ for all $t \\in [0,T]$. Any optimization algorithm (or any planning algorithm) can be used; by employing different random seeds, initializations, or any inherent randomness in algorithms, we solve this problem multiple times to obtain diverse solution trajectories.\nIn this paper, adopting the via-point movement primitives [25], we use the following parametric curve model and perform the optimization in the parameter space:\n$q(t) = q_0 + (q_T - q_0)(3 - 2s)s^2 + s^2(s - 1)^2 \\Phi(s)w$,\nwhere $s = t/T$, $q_0, q_T \\in Q \\subset \\mathbb{R}^n$, $\\Phi(s) = [\\phi_1(s),...,\\phi_B(s)] \\in \\mathbb{R}^{1\\times B}$ where $\\phi_i(s) = exp(-B^2(s - \\frac{i-1}{B-1})^2)$ and $B$ is the number of basis functions , and $w \\in \\mathbb{R}^{B\\times n}$. We note that the coefficients are carefully chosen so that $q(0) = q_0$, $q(T) = q_T$, and $\\dot{q}(0) = \\dot{q}(T) = 0$. We consider $q_0$, $q_T$, $w$ as parameters for $q(t)$.\nTo collect diverse trajectories, we randomly initialize $q_0$, $q_T$ and solve (3). We iterate this process multiple times with different random seeds. As a result, for each $\\tau_i$, we have multiple motions $\\{(q_{ij}(t), \\eta_{ij})\\}_{j=1}^{N_i}$ where $q_{ij}(t)$ is given by (4) with $(q_0)_{ij}, (q_T)_{ij}$ and $w_{ij}$. At this stage, the speed of solving the optimization problem is not crucial, as it only needs to be done once offline to collect good data. During actual control, there is no need to solve this optimization problem again."}, {"title": "B. Learning Differentiable Motion Manifold", "content": "In this section, we propose a method to train a manifold of continuous-time, differentiable trajectories using the dataset $\\{(q_{ij}(t), \\eta_{ij})\\}_{j=1}^{N_i}$. The key idea is to design the decoder - which outputs a discretized trajectory in the discrete-time MMPs - to take time as an additional input and produce a configuration as a function of time. A similar technique can be found in 3D modeling, where 3D spatial coordinates are used as an additional input to the shape latent code [38].\nSpecifically, we consider two mappings, an encoder $g$ and decoder $f$, and an m-dimensional latent space $Z = \\mathbb{R}^m$. The encoder $g$ takes a discretized trajectory $(q_1,...,q_L) \\in Q^L$ and $\\eta$ as inputs and outputs a latent value $z \\in Z$, i.e., $g((q_1,...,q_L), \\eta) = z$. The decoder $f$ takes the latent value $z$ and time variable $t$ as inputs and outputs a configuration in Q"}, {"title": "C. Latent Flow Learning", "content": "This section introduces how to fit a task-conditioned density model $p(z|\\tau)$ in the latent space of the learned differentiable motion manifold, by adopting the latent flow learning from MMFP [24]. Let $z_{ij}$ denote a latent value of $(q_{ij}(t), \\eta_{ij})$ encoded by the trained encoder $g_\\alpha$ from the previous section. Then, we have a dataset of task-latent values $(\\tau_i, \\{z_{ij}\\}_{j=1}^{N_i})_{i=1}^M$. Our goal is to train a task-conditioned latent probability density model $p(z|\\tau)$ so that we can sample $z$ given $\\tau$ and then generate a motion by using the trained decoder, i.e., $z \\sim p(z|\\tau)$.\nThe distribution $p(z|\\tau)$ can be arbitrarily complex, e.g., it may have multiple modes and disconnected supports. Simple density models cannot fit $p(z|\\tau)$, therefore, we use a sufficiently expressive deep generative model, specifically a flow-based model [40], [37].\nIn the latent space Z, consider a neural network velocity field $v_\\gamma(s, \\tau, z)$ parametrized by $\\gamma$ conditioned on $s, \\tau$ for $s \\in [0, 1]$ and an Ordinary Differential Equation (ODE):\n$\\frac{dz}{ds} = v_\\gamma(s, \\tau, z)$.\nGiven a Gaussian prior distribution $p_0(z)$, we model $p_\\gamma(z|\\tau)$ as a pushforward of $p_0$ by the flow of $v_\\gamma$. For example, to sample from $p_\\gamma(z|\\tau)$, we first sample from $p_0$ and solve the ODE from $s = 0$ to $s = 1$. We use the flow matching [37] to train $v_\\gamma$, a simulation-free approach that is much more efficient than the conventional maximum log-likelihood method.\nConsequently, by sampling from $z \\sim p_1(z|\\tau)$ and using the differentiable decoder as $z \\rightarrow f(z)$, we can generate motions for $\\tau$. We call this Differentiable Motion Manifold Flow Primitives (DMMFP)."}, {"title": "D. Trajectory Manifold Optimization", "content": "Trajectories generated by DMMFP are not guaranteed to satisfy the kinodynamic constraints. Additionally, because the dataset only includes a finite set of task parameters $\\{\\tau_i\\}_{i=1}^M$, performance for unseen $\\tau \\in T$ is also not guaranteed. In this section, we propose a trajectory manifold optimization to fine-tune the manifold, ensuring that generated trajectories not only achieve the tasks for all $\\tau \\in T$ but also comply with kinodynamic constraints.\nSpecifically, let $g_\\alpha$, $f_\\beta$, and $p_\\gamma$ be pre-trained encoder, decoder, and latent flow. Our key strategy is to fine-tune the decoder parameter $\\beta$ while fixing the encoder and flow parameters $\\alpha, \\gamma$. One may reasonably ask why not fine-tune all the parameters $(\\alpha, \\beta, \\gamma)$ simultaneously. While this is possible, it requires gradient backpropagation through the latent values sampled via the flow. Consequently, the entire computation graph from the ODE simulation must be traversed, which is computationally very expensive and significantly prolongs the training process. We only fine-tune the decoder parameters, as this is both efficient and sufficient to modify the motion manifold.\nSpecifically, let $U(S)$ be a uniform distribution on a set S. We then define a task loss as follows:\n$\\mathcal{L}_{task}(\\beta) := \\mathbb{E}_{t,\\tau,z} [J(\\hat{q}_\\beta(z,\\cdot), \\eta_\\beta(z); \\tau) + w_T (ReLU(C(t, z, \\beta))^2)]$,"}, {"title": "V. CASE STUDY: DYNAMIC THROWING WITH A 7-DOF ROBOT ARM", "content": "In this section, we demonstrate the effectiveness of our algorithms for fast and adaptive kinodynamic planning with the dynamic throwing task using the 7-DoF Franka Panda robot arm. This involves solving a non-trivial kinodynamic op-timization problem with nonlinear objectives and constraints, where the limits must be fully utilized. The solution process is highly dependent on initial conditions and can be time-consuming, making it an ideal example to showcase the effectiveness of our method. This will become more evident as the problem description is introduced below.\nAs shown in Fig. 6, the position of the target box is consid-ered as the task parameter. We define $\\tau = (r \\cos \\theta, r \\sin \\theta, h) \\in \\mathbb{R}^3$. When training motion manifold primitives, we assume $\\theta = 0$, since if $\\theta \\neq 0$, we can simply rotate the first joint by $\\theta$ for the generated trajectories, leveraging the rotational symmetry. If the target box is too close to the robot, there is no need to throw an object. Therefore, the task parameter space is defined as $T := \\{(r, \\theta, h) | r \\in [1.1, 2.0], h \\in [0.0, 0.3]\\}$. The object is assumed to be released from the gripper immediately when the gripper opens, and thereafter, the object is assumed to be in free fall. The throwing time is considered as an additional variable $\\eta \\in [0, T]$ where the total time is $T = 5$. Thus, given a joint trajectory $q(t)$, the throwing phase \u2013 where the robot releases the object \u2013 is $(q(\\eta), \\dot{q}(\\eta))$.\nObjective function. We are assumed to be given kinematic and mass-inertial parameters of the robot arm and the relative position of the object to the gripper while holding it. Let $T_{sb}: Q \\rightarrow SE(3)$ be the forward kinematics of the robot's end-effector frame, where $T_{sb}(q) = (R_{sb}(q), t_{sb}(q)) \\in SO(3) \\times \\mathbb{R}^3$ is the end-effector frame described in the fixed frame $\\{s\\}$. Let $p_b \\in \\mathbb{R}^3$ be the relative position of the object described from the end-effector frame, then, when the robot is at a joint configuration $q$, the object position described in the fixed frame is given as\n$p_s(q) = R_{sb}(q)p_b + t_{sb}(q)$.\nLet $J_b: Q \\rightarrow \\mathbb{R}^{6\\times7}$ be the end-effector body Jacobian so that $(\\omega_b, v_b) = J_b(q)\\dot{q}$ is the body velocity. We note that"}, {"title": "C. Online Adaptation", "content": "In this section, we demonstrate the online adaptability of our model, thanks to its rapid planning speed, in dynamically changing environments. We consider a scenario where, given an initially planned throwing trajectory for a certain target box position and a robot following that trajectory, the target box position suddenly changes. We quickly replan a throwing trajectory, and the robot smoothly and naturally converges to and tracks the new trajectory.\nIn the replanning step, we first sample multiple throwing trajectories one hundred in our experiments denoted by $\\{(q_i(t), \\eta_i)\\}_{i=1}^{100}$, conditioned on the new target box position. Among these trajectories, we select the one that is closest to the current robot configuration $q_c$ - where closeness is measured by the shortest distance to the trajectory segment prior to the release of the object. Specifically, we find $(i^*,t^*) = arg \\min_{(i,t)} ||q_c- q_i(t)||$ such that $t < \\eta_i$. We then compute a transition trajectory that connects the current configuration $q_c$ to the nearest configuration $q_{i^*}(t^*)$, which occurs before the moment of throw, in the selected trajectory. The transition trajectory starts with the current robot phase $(q_c, \\dot{q}_c)$ and ends with the phase $(q_{i^*}(t^*), \\dot{q}_{i^*}(t^*))$ from the updated trajectory. We construct the transition trajectory with the following parametric curve model:\nq(t) =q_o + (q_T - q_o) (3 - 2s)s^2 \\\\\n+ \\dot{q}_os - (2\\dot{q}_o + \\dot{q}_T)s^2 + (\\dot{q}_o + \\dot{q}_T)s^3 \\\\\n+ s^2 (s - 1)^2\\Phi(s)w,,"}, {"title": "VI. CONCLUSIONS", "content": "We have proposed identifying a trajectory manifold consisting of diverse task-completing trajectories offline, and then performing fast kinodynamic motion planning by searching for a trajectory within the manifold online. We have proposed Differentiable Motion Manifold Primitives (DMMP), a manifold of continuous-time, differentiable trajectories, and a practical training strategy composed of four steps: (i) data collection via trajectory optimizations, (ii) differentiable motion manifold learning, (iii) latent flow learning, and (iv) trajectory manifold optimization. Using dynamic throwing tasks with a 7-DoF robot arm, we have confirmed our method can quickly generate diverse trajectories that satisfy task requirements and kinodynamic constraints.\nOne of the most important parts of DMMP training is the initial step: data collection via trajectory optimizations. The diversity of this dataset will determine the diversity of the resulting trajectory manifold, which in turn will impact the efficiency of the re-planning algorithm in online adaptation. For example, a manifold with more diverse trajectories is likely to lead to finding a trajectory closer to the robot's current phase, making it easier to identify a transition trajectory, and leading to reducing both the distance and the time the robot must travel during the transition. In our current implementa-tion, we have collected diverse trajectories through random initializations of the initial and final configurations. Future research directions include using more sophisticated methods to develop a trajectory manifold that spans a broader area.\nIn this paper, we have demonstrated examples of adaptation when a new task variable is introduced, but our trajectory manifold can also be utilized to adapt to a broader range of scenarios. For instance, in the throwing example, consider a case where additional obstacles, such as a wall, are present near the robot, restricting its workspace. If only a single trajectory had been encoded offline, and that trajectory collided with the additional obstacles, the robot would be unable to throw the object. However, since we have learned a trajectory manifold, we have diverse candidate trajectories, increasing the likelihood of finding a trajectory on the manifold that avoids collisions with the obstacles. As mentioned earlier, to achieve higher adaptability, it is important to learn a manifold that includes as many diverse trajectories as possible."}]}