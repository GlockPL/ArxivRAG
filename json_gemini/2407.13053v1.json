{"title": "E2Vec: Feature Embedding with Temporal Information\nfor Analyzing Student Actions in E-Book Systems", "authors": ["Yuma Miyazaki", "Valdemar \u0160v\u00e1bensk\u00fd", "Yuta Taniguchi", "Fumiya Okubo", "Tsubasa Minematsu", "Atsushi Shimada"], "abstract": "Digital textbook (e-book) systems record student interactions\nwith textbooks as a sequence of events called EventStream\ndata. In the past, researchers extracted meaningful features\nfrom EventStream, and utilized them as inputs for down-\nstream tasks such as grade prediction and modeling of student\nbehavior. Previous research evaluated models that mainly\nused statistical-based features derived from EventStream logs,\nsuch as the number of operation types or access frequencies.\nWhile these features are useful for providing certain insights,\nthey lack temporal information that captures fine-grained\ndifferences in learning behaviors among different students.\nThis study proposes E2Vec, a novel feature representation\nmethod based on word embeddings. The proposed method re-\ngards operation logs and their time intervals for each student\nas a string sequence of characters and generates a student\nvector of learning activity features that incorporates time\ninformation. We applied fastText to generate an embedding\nvector for each of 305 students in a dataset from two years\nof computer science courses. Then, we investigated the effec-\ntiveness of E2Vec in an at-risk detection task, demonstrating\npotential for generalizability and performance.", "sections": [{"title": "1. INTRODUCTION", "content": "Digital textbook systems are widely used in educational\ninstitutions and online educational services. They not only\nprovide learning materials to students but also collect logs of\nstudent actions, such as moving between pages and adding\nmarkers or memos, in the EventStream format. Various\nstudies have been conducted in the fields of Educational\nData Mining (EDM) and Learning Analytics (LA), ranging\nfrom basic learning activity analysis to a deeper evaluation\ntowards personalized learning support. In such analyses of\ne-book data, extracting useful features from EventStream\nis a crucial aspect since the features are used as inputs of\ndownstream machine learning (ML) tasks, such as prediction\nof grades or clustering of students based on their behavior.\nPrevious studies (see Section 2.1) used e-book EventStream\ndata to extract features consisting of the counts of various\nactions (operations) [16, 5, 1, 23]. However, these types of\nfeatures do not consider the sequential or temporal informa-\ntion of operations or the time intervals between operations.\nFlanagan et al. [8] used features that consider sequential\noperations, taking into account the order of operations, but\nnot the intervals between them. Therefore, it is not possible\nto capture in detail the differences between how students\nspent their time reading the learning materials.\nMinematsu et al. [12] proposed CRE (contrastive learning\nfor reading behavior embedding), a method of feature embed-\nding of EventStream data. They used operation tokens and\ntimestamps as inputs of the embedding model. Subsequently,\nstudent vectors generated with CRE yielded higher Fl-score\nthan count-based features in downstream tasks. This model\nis the basis for our proposed method; however, we introduce\na different unsupervised training model of embedding.\nOur research purpose is to evaluate a more fine-grained\nrepresentation of learning activities that considers not only\nthe operations' order, but also their intervals during student\nlearning. We propose a novel feature representation method\nfor EventStream based on word embedding. Our method\nconsiders a set of operations and intervals between operations\nas primitive symbols represented by individual characters. A\nshort learning activity, such as opening an e-book and reading\nseveral pages by flipping them at certain time intervals, is\nrepresented as a series of primitives, named unit. A sequence\nof units represents a learning activity, action, over time.\nA feature embedding model based on fastText [4], proposed\nfor effective word embedding, was trained using a large data-\nset of actions. Embedding features are then acquired using\nthe trained model. We call the embedding model \"E2Vec\"\nsince EventStream data are vectorized. The resulting em-\nbedding features are easy to use in various ML tasks.\nE2Vec aims to improve downstream tasks in education by pro-\nviding features that were not considered much in prior work.\nOur study empirically investigates whether features obtained\nby E2Vec are effective for downstream tasks, evaluating\nE2Vec on a task of predicting at-risk students. Specifically,\nwe explore three research questions:\nRQ1 Does E2Vec represent learning activities in an appropri-\nate way, meaning that (a) units similar to each other\nand (b) actions similar to each other are converted to\na similar vector embedding?\nRQ2 How well do features generated by E2Vec perform when\nused as inputs for downstream at-risk prediction tasks?\nRQ3 How well do features produced by E2Vec generalize for\napplications in different models?"}, {"title": "2. RELATED WORK", "content": "Past research employed EventStream data to extract features\ndescribing students' learning activities in various ways.\nOkubo et al. [16] proposed the Active Learner Point (ALP)\nas a feature representation of student activities in e-books\nand other learning management systems. In ALP, learning\nactivities, such as the number of markers and memos or\nattendance information, were scored in the range between 0\nand 5. The scores were used for training a recurrent neural\nnetwork (RNN) model for a grade prediction task.\nChen et al. [5] researched early prediction of student grades\nusing several ML classifiers. They focused on 14 kinds of\noperations in an e-book system, and extracted the number\nof each kind of operation. The result showed that operations\nwith e-book memos positively correlated with the students'\nacademic achievement.\nAk\u00e7ap\u0131nar et al. [1] used features such as the total number\nof events, total time spent in the e-book system, and the\nnumber of \"next page\" events. Additionally, they used the\nnumber of events longer than 3 seconds and shorter or equal\nto 3 seconds. These were the only considered features that\ninvolved time interval information between operations.\nFlanagan et al. [8] used sequential features. They created\n5-gram features from preprocessed logs and predicted the\nperformance in an open-book assessment. However, time\ninformation was only used to determine whether an opera-\ntion is recorded before or after starting the assessment, and\noperations with intervals of less than 3 seconds were removed\nin the preprocessing step.\nAnother possibility of using EventStream data is a pattern\nanalysis or clustering based on learning activities. Yin et\nal. [24] performed k-means clustering of students based on\nlearning activities and analyzed the characteristics of each\ncluster. Examples of features include total number of pages\nread and the frequency of page flipping.\nOverall, EventStream data can yield various features. A\ncommon issue among previous studies is that they did not\nfully exploit the potential of employing temporal information.\nThis study aims to address this gap in the literature."}, {"title": "2.2 Word Embedding", "content": "In Natural Language Processing (NLP), word embedding\nmodels are used to provide feature representations for words\nor documents. Word2vec [10] is one such well-known model,\nobtaining distributed representations of words in training\ntext data. GloVe [18] and fastText [4] were proposed for\nan improved representation. FastText can generate a vector\nof words that does not exist in the training data using sub-\nword information. (A subword is an n-gram of characters.)\nRecently, these models have been combined with other ML\nmodels for prediction and classification tasks see below.\nUmer et al. [22] proposed a 3-layer Convolutional Neural\nNetwork (CNN) with fastText embedding for text classifi-\ncation and marked higher accuracy than other models on\nfive datasets. Dharma et al. [7] compared the three word\nembedding models - Word2vec, Glove, and fastText using\ntext classification with CNN. Furthermore, Riza et al. [20]\nused a long short term memory network and fastText for\nemotion detection. Tiun et al [21] showed the effectiveness\nof fastText in classification of functional and non-functional\nrequirements in software engineering.\nWord embedding models were applied not only to NLP tasks\nbut also in other fields. An example is item2vec by Barkan\net al. [3]. This model learned distributed representations of\nitems that correspond to words in Word2vec. Moreover, in\nbioinformatics, Ng et al. [14] proposed dna2vec which is a\nmethod for feature generation using skip-gram.\nTo summarize, the value of feature embedding inspired by\nword embedding has been recognized in various studies. We\npropose a new feature embedding method based on the\nfastText model for EDM. Then, we verify its effectiveness\nfor student learning logs from e-books."}, {"title": "3. THE PROPOSED METHOD", "content": "This section explains how we generate distributed represen-\ntations of a student's learning activity using EventStream.\nFigure 1 illustrates our method. There are three main mod-\nules: Preprocessing, Embedding, and Aggregation. We call\nthe embedding by these series of processes \"E2Vec,\" and use\nfastText [4] to acquire an embedding model. The details of\neach module are explained in the following sections."}, {"title": "3.1 BookRoll: Reading Data Collection Tool", "content": "We used an e-book system called BookRoll [15, 9] to collect\nEventStream logs. Students access BookRoll to read a learn-\ning material via a web browser. There are various function\nbuttons whose usage is recorded, such as moving to the next\nor previous page or adding markers.\nTo identify frequently occurring operations, we recorded\n5,698,558 logs in BookRoll from 2021/04/01 to 2022/03/31 in\nvarious courses.  shows the frequently used operations;\noperations with less than 10,000 occurrences are grouped\nunder \"OTHERS\". The log data indicate when, by whom, and\non which material the operation was performed (see ).\nThe dataset used to determine these operations differs from\ndatasets in Section 4 used to evaluate our proposed method."}, {"title": "3.2 Preprocessing", "content": "During the preprocessing phase, EventStream is converted\ninto string representations. In NLP, a word is composed\nof several characters, a sentence consists of several words,\nand several sentences form documents. To apply fastText\nto EventStream data, we define primitive, unit and action\ncorresponding to \"character,\" \"word,\" and \"sentence,\" in NLP,\nrespectively. An action is a sequence of several units. Each\nunit consists of a series of several primitives. A primitive\ncorresponds to single character (a symbol) defined in .\n shows the definition and examples of primitve, unit\nand action. Preprocessing is done by the following rules:\n1. EventStream log is divided by the student ID and by the\ncontent ID. Therefore, a unit is made from operations\nof a student on a lecture material.\n2. Frequent operations (see ) are converted into the\ncorresponding primitive symbols (N, P, O, A, C, J, G \u2208\nP); other operations are all replaced by E EP.\n3. Insert s, m, 1 \u2208 P between two primitives, correspond-\ning to time interval between two operations. If the\ninterval between two operations is less than 1 second,\nnone of the interval symbols are inserted.\n4. A unit (u) is a sequence of primitives consisting of\nEventStream log up to 1 minute long.\n5. Maximal length of a unit is 15 primitives. If there are\n15 or more primitives within 1 minute, append '_' to\ntail of the unit and treat 15-th primitive as head of\nthe next unit. If 15-th primitive is s, m, 1 \u2208 P, treat\n16-th primitive as the head of the next unit.\n6. An action (a) is a sequence of several units.\n7. If time interval of two operations exceeds 5 minutes,\nthe actions are separated. That is, the preceding unit\nis the tail of the current action followed by the next\naction which begins with a new unit.\nTo acquire the embedding of learning activities in a short\ntime, we designed an unit to contain primitives for up to\n1 minute or 15 primitives. The maximum length setting\nprevents our preprocessing from generating too long units,\nas the percentage of units reaching max length (15) was\nincreased when using 3 or 5 minutes instead of 1 minute.\nTo characterize a learning activity sequence consisting of a\nseries of units, actions were separated when long intervals\nwere observed between two successive operations.\nBased on the preprocessing, EventStream of a lecture course\nwas converted into sequences of actions student by student.\nFor instance, the EventStream in  was converted into\nthe following action sequence $A_{sample}$.\n$A_{sample} = {\\{OsNmNNm, PsAl\\}, \\{N,...\\},...}$\n: unit\n: action\nThe first action consists of two units: OsNmNNm and\nPsAl. Then, a new action which begins with primitive \u201cN\u201d\nis generated as there is an interval longer than 5 minutes\nbetween the event of \"ADD MARKER\" and subsequent\n\"NEXT\" (see ). Note that the number of actions is\ndifferent among students. Some students have up to 400\nactions representing their learning activities."}, {"title": "3.3 Embedding", "content": "We used fastText, a well-known model for word embedding\nin NLP, to generate distributed representation of actions.\nFastText generates not only the embedding vectors of words\nlearned thus far but also unknown words. The advantage\nof using the fastText model is that it can generate similar\nvectors for two syntactically similar words. Although the fast-\nText model is widely used and many pretrained models are\npublicly available, our proposed action sequences have mean-\nings different from those of natural languages. Therefore, we\ntrained fastText with actions from EventStream."}, {"title": "3.3.1 Training fastText", "content": "We followed the training strategy of fastText model based on\nskipgram negative sampling [11]. Let $A = \\{a_1, a_2,..., a_n\\}$ be\na set of actions generated from EventStream in the training\ndataset. As explained earlier, an action consists of a sequence\nof units such that each unit is also an element in the set of A.\nAfter training the fastText model, distributed representations\nfor each unit in A are obtained. In our implementation, we\nset the number of dimensions of the embedding vectors to\n100. Regarding the other configurations, we followed the\ndefault settings in Meta Research Python module [19] except\nfor the minimal number of appearance parameter and epoch.\nWe set the parameter to 1, whereas the default setting was\n5, and epoch was set to 30."}, {"title": "3.3.2 Generating Action Vectors", "content": "The trained fastText model converts a given unit into its\nembedding representation. Let ui be an embedding vector\nof an unit. The action vector va is calculated by using\nEquation (1).\n$v_a = \\frac{1}{m} \\sum_{i=1}^{m} u_i$ (1)\nNote that va is generated student-by-student, and the num-\nber of dimensions is the same as that of ui. Therefore, we\ncan obtain an embedded representation corresponding to\neach student's learning activity, action."}, {"title": "3.4 Aggregation", "content": "Learning activities of a student over a specific period are\nrepresented by a set of actions. We introduce an idea of\n\"Bag of Words\" [25] to obtain a feature representation of the\nentire learning activity during the period, namely \"Bag of\nActions.\" This step consists of creating a CodeBook using\nthe data for training the fastText model."}, {"title": "3.4.1 Making a CodeBook", "content": "First, it is necessary to create a CodeBook using the dataset\n$A = \\{a_1, a_2, ..., a_n\\}$ used for training the fastText model.\n1. Remove duplicate actions in A and treat it as A'.\n2. Generate embedding vectors for all actions in A'.\n3. Perform k-means++ clustering [2] for the embedding\nvectors.\n4. Store the centroid of each cluster as a CodeWord, which\nbecomes an element of CodeBook.\nThe similarity between vectors was measured using cosine\nsimilarity."}, {"title": "3.4.2 Bag of Actions", "content": "This is the last step needed to generate student vectors by\nE2Vec. Inspired by the Bag-of-Visual-Words approach [6]\nused in computer vision research, the proposed approach\ngenerates a histogram representation of actions based on the\nCodeBook. Figure 2 shows the process to aggregate one\nstudent's action vectors as corresponding student vector.\nIn summary, a student vector represents the characteristics of\na student's learning activities as a histogram of actions over\ntime. Its elements reflect operational patterns in the learning\nmaterials. Note that, in the proposed method, temporal\ninformation is considered in action and unit. Therefore,\nwe can expect to obtain a more detailed representation of\nlearning activities than by simply aggregating the number of\nevents, as in previous studies."}, {"title": "4. DATASETS", "content": "We used EventStream logs of 6 courses that used BookRoll\nand students' grade information.  describes each\ncourse. The notations A and D represent the type of courses,\nand 2020, 2021, and 2022 represent the years in which the\ncourse was held. These courses were held for computer\nscience course students in Kyushu University.\nThe duration of each lecture session was 90 min. Course A is\nheld in two consecutive lectures in one day, thus we described\nthe lecture time of course A as 180 min. Logs recorded in and\nout of lecture time are used without distinction. ALL-2020\nis a concatenation of A-2020 and D-2020, which were used\nonly for training fastText and making the CodeBook, not for\npredicting grades of students in A-2020 and D-2020.\n shows the distribution of student grades in four\ncourses that were used as training or test data of at-risk\nprediction. Five grades are possible, from A to F. F means\nfailing a course, while others pass a course. In our study, we\ntreated grades A and B as no-risk, and C, D, F as at-risk."}, {"title": "5. UNIT VECTOR ANALYSIS (RQ1A)", "content": "In this study, we verify which units are similar to each\nother in the vector representation and find similarities and\ndifferences between the vectors of known and unknown units.\nTo generate unit vectors, we used fastText trained with\nAALL-2020. fastText learned 33963 units in AALL-2020."}, {"title": "5.1 Method", "content": "As an example demonstration, we calculated similarity be-\ntween Nm the most frequent unit generated from students'\nactivity and all the units in AALL-2020. For comparison,\nthe same calculation was performed for NNNNsNmNsNsPl\nunlike Nm, this unit was not trained by fastText. The\nformer unit is in AALL-2020 and AD-2022. The latter is not\nin AALL-2020, but is included in AD-2022.\nIn addition, we calculated cosine similarity between each of\ntwo units and all the units in AD-2022 and evaluated the\ndistribution of cosine similarities."}, {"title": "5.2 Result", "content": " shows the unit similarity results. E2Vec\ngenerated embedding vectors with high similarity (\u2265 0.7)\nwhen units had common subwords - i.e., high-similarity units\nhave common subwords (subword is a sequence of primitives).\nNm and its highly similar actions share the subword Nm. A\ncommon subword implies that two units are created for\nthe same order of operations and similar time intervals.\nIn addition, Figure 3 is a histogram of the similarity between\nthe two selected units and all 25076 units in D-2022. One\nunit has fewer similar units and many dissimilar units in the\ncourse activities of students on the learning materials. This\nshows that not only features with high similarity but also\nfeatures with low similarity were generated.\nOverall, these results suggest that the similarity between\nlearning activities in a short time is preserved in distributed\nrepresentations of units generated with fastText. Also, dis-\nsimilar activities converted into discriminative features. This\nis a property of a good feature generator, which should pro-\nduce highly similar features for similar inputs and highly\ndiscriminative features for those that are not."}, {"title": "6. ACTION VECTOR ANALYSIS (RQ1B)", "content": "A vector of an action a = 41, 42, , Um is generated\nfrom unit vectors {U1, U2, ..., Um}. In our method, the\nCodeBook is made to aggregate one student's actions to\nstudent vector. In the process of making the CodeBook,\nk-means++ clustering is performed with the set of action\nvectors. In this section, we describe the study of action\nvectors. We evaluated the result of clustering and sought to\nfind the features of action vectors."}, {"title": "6.1 Method", "content": "We used fastText, which was trained using AALL-2020. It\nhas 19979 actions, of which 14016 were unique. In this study,\nk-means++ clustering was performed using AALL-2020. The\nnumber of clusters k was set to 10.\nWe calculated the maximum, mean, and variance of the\nlength of actions in each cluster. The length of action a is, in\nother words, the number of units that constitute a. A long\nsequence of units indicates that students execute sequential\noperations on learning materials in BookRoll."}, {"title": "6.2 Result", "content": " shows the quantitative analysis of clusters. Cluster\nnumbers are sorted by max length of actions. From the\nactions length in each cluster, co and cl contains actions\nthat consist of small number of units. The maximum length\naction in this cluster had only 8 and 9 units. Other clusters\ninvolved actions, which consists of large number of units.\nHowever, the mean of the length of actions in each cluster\nwas less than 10. Also, It can be observed that the actions\nin the same cluster have similar unit and sequences of units.\nFor example, one cluster have sequences composed only of\nmultiple Ns. These sequences indicated that the student\nclicked the NEXT multiple times per second. On the other\nhand, some actions do not have similar units to other actions\nin the same cluster; and similar actions in different clusters."}, {"title": "7. AT-RISK PREDICTION (RQ2, RQ3)", "content": "In this study, we performed at-risk prediction as an appli-\ncation of student vectors generated by E2Vec. This is a\nbinary classification task. In our setting, classification mod-\nels trained with all the student vectors and their grades of\nCr, predicted all the students' grades of course cy from the\nstudent vectors of cy. The ground truth of this task is stu-\ndent's final grade of cy. At-risk are treated as positive and\nno-risk as negative classes. This evaluation aims to verify\nthe following hypotheses.\nh1: The student vectors generated by E2Vec are effective as\nan input of classification models for at-risk prediction.\nh2: fastText trained with logs from several courses is able\nto perform predictions for various courses.\nh3: Accurate predictions can be made regardless of the\ncombination of train and test lecture courses by using\nthe proposed method.\nh1 corresponds to RQ2. h2 and h3 are related to RQ3."}, {"title": "7.1 Method", "content": "We used four classification models: Random Forest Classifier\n(RFC), Support Vector Machine (SVM), Ada-Boost classifier\n(ADA), and k-Nearest Neighbor classifier (KNN), all from\nthe Scikit-learn library [17]. We aimed to verify that E2Vec\nfeatures are suitable as input of different classification models.\nTwo courses are selected from the four courses in .\nWe represent the training course as X and test course as\nY. The at-risk prediction process involves three steps: the\ngeneration of student vectors, training of the classification\nmodel, and prediction. This process is illustrated in Figure 4."}, {"title": "7.1.1 The Generation of Student Vectors", "content": "We used the proposed method and two comparison methods\nto generate vectors of all students in X and Y, and used\nthese vectors as input of classification models.\n1. E2Vec\nfastText trained with ALL-2020 was treated as basic\nmodel and compared models trained with A-2020 and\nD-2020 used to verify h2. The number of centroids k\nwas selected from [10, 100]. k was corresponds to the\nsize of CodeBook and student vector. The compared\nmodels' dimensions were set to 100.\n2. Operation Count Feature (OC)\nOne student vector was formed by counting the number\nof each operation in  and normalizing to norm 1.\nThus, the dimension of student vectors were 7."}, {"title": "7.1.2 Training Classification Model", "content": "To tune the hyperparameters of the classification model, we\nperformed a grid search with 3-fold cross validation with\ntraining data. This was implemented using the scikit-learn\nmodule GridSearchCV. Students in X were split into three\nsets, two of which were treated as training data, and the other\nas validation data. The score of the one-hyperparameter set\nmodel was the mean of 3 F1-scores in each validation. The\nparameter set with the highest score was selected. In the\nprediction, the selected model and the default parameter\nmodel were used. In our implementation, the random states\nof the models were fixed at 42 to ensure reproducibility."}, {"title": "7.1.3 Prediction", "content": "In this step, two trained classification models (the selected\nparameter set model and the default parameter model) pre-\ndicted all students in Y as at-risk or not with the student\nvector. The output of the classification model is a binary list\nof labels. Label 1 indicates that the student is predicted to be\nat-risk. For the evaluation, we calculated F1-score using the\npredicted labels and ground truth.  to 11 show only\nthe higher F1-score of each model's (tuned hyperparameters\nmodel and default hyperparameters model) evaluation."}, {"title": "7.2 Result", "content": " shows the result of prediction for A-2022, trained\non A-2021.  represents prediction results of D-2022,\nwith classifiers trained on D-2021. These are the cases when\nthe model was trained with past student information and\npredicted students on the same course in the following years.\nThis is a typical application of at-risk prediction."}, {"title": "8. DISCUSSION", "content": "For RQ1, the effectiveness of E2Vec was shown in Section 5\nand Section 6. The unit vectors preserve the similarity of\nstudent operations in a short time. Regardless of whether\nunit is involved in the vocabulary of fastText, the input unit\nand the similar units shared sequences of primitives. In\naddition, action vectors have similarities that correspond to\nthe sequences of operations. Based on the clustering, actions\nin the same cluster have similar units. Thus, the distributed\nrepresentations of units generated by E2Vec are effective\nrepresentations of student learning activities.\nFor RQ2, Section 7 showed that E2Vec can be used as a\nfeature expression method for at-risk prediction using several\nML models. We investigated a practical use case of using\npast course data for model training and the following year's\ndata for prediction. In typical cases, the Fl-scores using the\nfeatures generated by E2Vec were comparable or higher than\nthe traditional approach, so we conclude that the features\ncan be suitably utilized for downstream tasks.\nFor RQ3, F1-scores of using E2Veck100, in which mixed\ncourse data was used to train fastText, were comparable to\nthose of using single course data such as E2Veca or E2Vec D\n(see  and ). In general, using the same\ncourse data used in feature extraction and its prediction task\nled to successful results. On the other hand, our results\nsuggest that fastText model does not have to be trained by\nspecific course data. Once a fastText model is trained using\na mixed dataset from past courses, the model can extract\nrobust features that can be used universally. When we used\nE2Vec features for at-risk prediction, the training data used\nfor the classification model (not fastText model) exhibited\ndifferences of prediction quality. It implied that the same\nlearning activity has a different influence on the final grade\nin each course.\nThe limitation is that our study used data from six courses at\nour university. The number of students in one course ranged\nfrom 50 to 100, and the grade distributions differed. In addi-\ntion, if our method is used with other e-book EventStream,\nadditional preprocessing is required, because our implemen-\ntation only corresponds to BookRoll EventStream.\nprediction is higher than in most other cases. Whereas, when\nusing data of course D- for training and A-2021 or A-2022\nfor testing, E2Vec achieved much lower Fl-scores than OC."}, {"title": "9. CONCLUSION", "content": "We proposed E2Vec a method of feature expression from\ne-book EventStream. Our method uses fastText, a word\nembedding model, to learn the distributed representations\nof operations in a short time, called unit. Similar units have\nsimilar representations, and actions in the same cluster have\na common units or subword. We applied our method to\nat-risk prediction, which is a representative task in EDM.\nOur model recorded a higher F1-score than the operation\ncount features for at-risk prediction in typical cases.\nFuture work should apply E2Vec with deep learning models\nor other EDM tasks, such as early prediction of student\ndropout. Finally, the impact of changing intervals on the\nprediction performance needs to be evaluated."}]}