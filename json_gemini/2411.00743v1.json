{"title": "Decoding Dark Matter: Specialized Sparse Autoencoders for Interpreting\nRare Concepts in Foundation Models", "authors": ["Aashiq Muhamed", "Mona Diab", "Virginia Smith"], "abstract": "Understanding and mitigating the potential\nrisks associated with foundation models (FMs)\nhinges on developing effective interpretability\nmethods. Sparse Autoencoders (SAEs) have\nemerged as a promising tool for disentangling\nFM representations, but they struggle to\ncapture rare, yet crucial concepts in the data.\nWe introduce Specialized Sparse Autoencoders\n(SSAEs), designed to illuminate these elusive\ndark matter features by focusing on specific\nsubdomains. We present a practical recipe for\ntraining SSAEs, demonstrating the efficacy\nof dense retrieval for data selection and the\nbenefits of Tilted Empirical Risk Minimization\nas a training objective to improve concept\nrecall. Our evaluation of SSAEs on standard\nmetrics, such as downstream perplexity\nand Lo sparsity, show that they effectively\ncapture subdomain tail concepts, exceeding\nthe capabilities of general-purpose SAEs.\nWe showcase the practical utility of SSAEs\nin a case study on the Bias in Bios dataset,\nwhere SSAEs achieve a 12.5% increase in\nworst-group classification accuracy when\napplied to remove spurious gender information.\nSSAEs provide a powerful new lens for peering\ninto the inner workings of FMs in subdomains.", "sections": [{"title": "1 Introduction", "content": "Interpretability is crucial for ensuring the safety\nand reliability of foundation models (FMs) (Bom-\nmasani et al., 2021). A key challenge in inter-\npretability research is to scalably explain the myr-\niad unanticipated behaviors in FMs. Sparse Au-\ntoencoders (SAEs) have recently emerged as a\npromising tool for disentangling the complex, high-\ndimensional representations within FMs into mean-\ningful, human-interpretable features without super-\nvision (Cunningham et al., 2023; Gao et al., 2024;\nBraun et al., 2024; Bricken et al., 2023). However,\neven massively wide SAEs, trained on vast amounts\nof data, may only capture a fraction of the concepts\nembedded within these models (Templeton et al.,\n2024). A significant portion of rare or highly spe-\ncific concepts remain essentially invisible due to\ntheir infrequent activation. These elusive features,\nakin to dark matter in the universe of interpretabil-\nity, pose a significant challenge for understanding\nand mitigating potential risks associated with FMs.\nWhile larger SAEs did exhibit some features for\nrarer concepts, Templeton et al. (2024) found com-\npelling evidence suggesting a vast amount of dark\nmatter features were still being missed. For exam-\nple, they found features for some of San Francisco's\nneighborhoods, but their model still lacked features\nfor smaller entities like coffee shops or street inter-\nsections. They observed that if a concept is present\nonly once every billion tokens, we may need a\nbillion-feature SAE to capture it reliably. This\nraises a critical question: can we develop more\nefficient methods than simply scaling SAE width\nto capture the tail concepts we are interested in?\nThis paper introduces Specialized Sparse Au-\ntoencoders (SSAEs), a novel approach designed to\naddress this challenge. Instead of aiming to capture\nall concepts, as in current SAE practices, we pro-\npose SSAEs as an unsupervised targeted method\nfor efficiently extracting rare features related to\nspecific subdomains. By focusing on a particular\nsubdomain, we can train SSAEs to learn features\nrepresenting tail concepts without needing to scale\nto billions of features. Furthermore, instead of rely-\ning solely on scaling, we investigate whether Tilted\nEmpirical Risk Minimization (TERM), which\napproximates minimax risk at large tilt parameters,\ncan further improve the representation of tail\nconcepts within SSAEs. Our key contributions are:\n1. Specialized Sparse Autoencoders: An unsu-\npervised method for efficiently extracting rare,\nsubdomain-specific features. We demonstrate\nempirically that SSAEs capture a greater propor-\ntion of tail concepts than standard SAEs trained\non general-purpose data, achieving a 12.5%"}, {"title": "2 Methodology", "content": "2.1 Sparse Autoencoders (SAE)\nThe superposition hypothesis in FMs suggests\nthat a limited number of neurons encode a much\nlarger number of concepts, leading to complex and\noverlapping representations (Elhage et al., 2022b).\nSuperposition, while efficient, makes it challenging\nto interpret individual neuron representations or\ndirections in representation space. Sparse autoen-\ncoders (SAEs) offer a potential solution by learning\nto reconstruct FM representations at a layer using a\nsparse set of features in a higher-dimensional space,\npotentially disentangling superposed features\nand revealing more interpretable representations\n(Elhage et al., 2022a; Olshausen and Field, 1997).\nIn a well-trained SAE, individual features in the\nhidden dimension align with underlying sparse,\nsemantically meaningful features (Donoho, 2006).\nSAEs decompose a model's activation $x \\in \\mathbb{R}^{N}$\ninto a sparse, linear combination of feature di-\nrections: $x \\approx x_{o} + \\sum_{i=1}^{M} f_{i}(x)d_{i}$, where $d_{i}$ are\n$M$ latent unit-norm feature directions, and\nthe sparse coefficients $f_{i}(x) \\geq 0$ are the corre-\nsponding feature activations for x. The right-hand\nside of this equation has the structure of an au-\ntoencoder: an input activation x is encoded into\na (sparse) feature activations vector $f(x) \\in \\mathbb{R}^{M}$,\nwhich is then linearly decoded to reconstruct x.\nWe parameterize a single-layer autoencoder (f, x)\nas follows: $f(x) := ReLU(W_{enc}(x) + b_{enc})$ and\n$\\bar{x}(f) := W_{dec}f + b_{dec}$ where $W_{enc} \\in \\mathbb{R}^{M \\times n}$ and\n$W_{dec} \\in \\mathbb{R}^{n \\times M}$ are the encoding and decoding\nweight matrices, and $b_{enc} \\in \\mathbb{R}^{M}$ and $b_{dec} \\in \\mathbb{R}^{n}$ are\nthe bias vectors. The training objective combines a\nreconstruction loss and a sparsity penalty:\n$L(x) = ||x - \\bar{x}(f(x))||_{2} + \\lambda ||f(x)||_{1}$  (1)\nwhere $\\lambda > 0$ is a hyperparameter controlling\nthe trade-off between reconstruction fidelity and\nsparsity. We constrain the columns of $W_{dec}$ to have\nunit norm during training (Bricken et al., 2023).\nIn existing work, SAEs for FMs are trained on\nthe same large, general-purpose dataset used to\ntrain the underlying FM (Bricken et al., 2023; Cun-\nningham et al., 2023; Rajamanoharan et al., 2024;\nGao et al., 2024). This approach ensures that the\nSAE captures a wide array of concepts present in\nthe general language domain. However, this can\nresult in the SAE learning features that are frequent\nin the pretraining data but miss concepts within\nspecific domains of interest, especially those that\nare rare by frequency in the pretraining data.\n2.2 Specialized Sparse Autoencoders (SSAE)\nSpecialized Sparse Autoencoders are designed to\nlearn features representing rare concepts within spe-\ncific subdomains. Our approach begins with a small\nseed concept dataset, comprising either a specific"}, {"title": "2.3 Subdomain Data Selection Strategies", "content": "SSAE effectiveness depends on the quality and\nrelevance of the selected subdomain data used for\nfinetuning. We study several selection strategies\nto identify data points from a larger corpus (FM's\npretraining data) most relevant to the seed data:\nSparse Retrieval: Okapi BM25 (Robertson and\nZaragoza, 2009), a TF-IDF variant, ranks docu-\nments based on query relevance, considering term\nfrequency, inverse document frequency, and doc-\nment length. We use the seed dataset as query to\nretrieve relevant documents from the larger corpus.\nDense Retrieval: Contriever (Izacard et al.,\n2022), a dual-encoder dense retriever, generates se-\nmantically meaningful embeddings for queries and\ndocuments. We embed the seed dataset and candi-\ndate documents, using cosine similarity to retrieve\ndocuments most similar to the seed concepts.\nSAE TracIn: Training data Influence Score\n(TracIn) (Pruthi et al., 2020) quantifies training ex-\namples' influence on model predictions. We adapt\nTracIn to SAEs by calculating the dot product of the\nloss gradients with respect to the training data and\nseed data: $TracIn(z, z') = \\nabla L_{w}(z) \\cdot \\nabla L_{w}(z')$\nwhere z is a training data point, z' is the seed\ndataset, w are the pretrained SAE weights, and\n$L_{w}( \\cdot)$ is the SAE loss (Equation 1). We use a two-\nstage approach to identify influential data: Initial\nFiltering with Sparse/Dense retrieval, then TracIn\nReranking to select points for SSAE training."}, {"title": "2.4 Tilted Empirical Risk Minimization for\nEnhanced Detection", "content": "Finetuning with Empirical Risk Minimization\n(ERM) tends to prioritize learning features for the\nmost frequent head concepts in the subdomain data.\nHowever, for many applications such as safety,\ncapturing rare tail concepts is often crucial. These\nrare features may represent potential risks or safety\nviolations and are often overlooked by standard\nERM as it focuses on minimizing the average loss.\nThe objective then is not minimizing the average\nloss, but rather minimizing the maximum risk to\nensure that even the rarest, potentially dangerous\nfeatures are captured. Tilted Empirical Risk Min-\nimization (TERM) (Li et al., 2020; Beirami et al.,\n2018) provides a framework for approximating\nthis minimax risk, encouraging the model to learn\nfeatures that better represent these tail concepts.\nTERM modifies the standard ERM objective\nby introducing a tilt parameter (t) that controls the\nemphasis on different parts of the loss distribution:\n$L(t; w) = \\log (\\frac{1}{N} \\sum_{i=1}^{N} e^{t L_{w}(z_{i})})$ where\n$L_{w}(z_{i})$ is the standard SAE loss (Equation 1) for\ndata point $z_{i}$ in a minibatch with N points and\nSAE parameters w. TERM generalizes ERM as the\n0-tilted loss recovers the average loss, while it also\nrecovers other alternatives such as the max-loss\n(t\u2192 +\u221e) and min-loss (t \u2192 -\u221e). In this work\nwe use large tilt parameters (t \u226b 0) to effectively\nminimize the maximum loss, encouraging the\nmodel to learn features that better represent the tail\nof the data distribution, including rare concepts."}, {"title": "3 Experiments And Results", "content": "3.1 Specialized Sparse Autoencoders (SSAEs)\n3.1.1 Data Selection Strategies\nIn this section, we evaluate the effectiveness of var-\nious data selection strategies for training SSAEs.\nExperimental Setup We use the pretrained\nGemma-2b (Team et al., 2024) residual\nstream GSAE (gemma-2b-res-jb checkpoint\nat blocks.12.hook_resid_post layer) (Bloom, 2024).\nThese SAEs have feature width 16384 and were\npretrained on OpenWebText (OWT) (Gokaslan\net al., 2019). For the Pareto front, we sweep 8\nL1 penalty coefficients, selecting the best model\non validation for each L1 value, then evaluating\non the held-out test split. SAEs are trained using\nAdam (Kingma and Ba, 2015) with lr 5e-5, token\nbatch size 4096, data shuffled within a batch buffer\nof size 4, and linear Ir decay over the last 1000\nsteps. Experiments complete in under 12 hours\nusing 4 A6000 GPUs. We use SAELens (Bloom\nand Chanin, 2024) for training and analysis.\nSSAE for Physics We start with a seed concept\ndataset (Validation) consisting of 9.2K tokens sam-\npled from the arXiv Physics dataset (Anonymous,\n2024). Using BM25, Dense Retrieval, and SAE\nTracIn, we expand this to 13.9M tokens from OWT.\nThe SSAE is trained by finetuning the GSAE for\n1000 iterations on this expanded set. For SAE\nTracIn, we first reduce OWT to 1% using BM25\nor Dense retrieval, then rerank using TracIn scores\nand select 13.9M tokens. We call these methods\nBM25 TracIn and Dense TracIn, respectively.\nWe train an SSAE for each strategy and com-\npare its performance to a baseline SAE finetuned\non the full OWT dataset across various sparsity\ncoefficients (\u03bb). We evaluate the models on two\ntest splits: 4.8M tokens from arXiv Physics (in-\ndistribution) and 700K tokens from Physics in-\nstruction tuning (Group, 2024)(out-of-distribution).\nTesting on instruction data helps measure whether\nthe SAEs are overfitting to the specific template of\nthe text as opposed to identifying concepts. \n3.1.2 Probing Tail Concept Learning\nTo probe tail concept learning we use convergent\nvalidity (Campbell and Fiske, 1959) with the Logit\nLens (Joseph Bloom, 2024). \n3.1.3 Case study: Removing Spurious\nFeatures in Bias in Bios Classifier\nHaving shown the effectiveness of ERM-trained\nSSAEs in capturing tail concepts for finer\ncontrol, we apply them to the Spurious Human-"}, {"title": "3.2 Tilted ERM for Enhanced Detection", "content": "3.2.1 Motivating Example: TERM-trained\nGSAES on TinyStories\nERM-trained GSAEs prioritize learning frequent\nconcepts in the data. In this section, we study\nfeatures in TERM-trained GSAEs, showing that\nTERM improves feature recall at the expense of\nfeature control."}, {"title": "4 Conclusion and Future Work", "content": "This work introduces SSAEs for interpreting rare,\nsubdomain features in FMs. SSAEs trained with\nDense retrieval and TERM, outperform standard\nSAEs in capturing tail concepts and yield more\ninterpretable features. Future work could explore\ntheir application to targeted concept unlearning."}, {"title": "5 Acknowledgements", "content": "This research was supported by the Anthropic Re-\nsearcher Access Program through their generous\ngrant of model credits, and AI Safety Support. The\nproject originated during Aashiq's participation in\nthe ML Alignment and Theory Scholars (MATS)\nprogram. We are grateful to Jake Mendel, Lucius\nBushnaq, and Jacob Drori for their insightful dis-\ncussions on experimental design and valuable feed-\nback on earlier drafts of this manuscript."}, {"title": "Limitations", "content": "While our work demonstrates the effectiveness of\nSSAEs in enhancing interpretability and tail con-\ncept capture across diverse domains like Physics\nand Toxicity, there are several areas for further ex-\nploration:\nComputational Efficiency of TERM. Training\nSAEs with TERM, while effective in enhancing\nconcept recall and yielding more interpretable\nfeatures, can be computationally more demanding\nthan standard ERM. The TERM objective requires\ncomputing the exponent of the loss for each data\npoint, which is more computationally intensive\nthan in ERM. This can potentially lead to numeri-\ncal instability and slower convergence, particularly\nat high tilt values. The benefits of TERM in\nimproving interpretability and fairness encourage\nfurther research to reduce its computational cost\nfor broader adoption and scalability.\nDependence on Seed Data. The success of\nSSAEs relies on the quality and representativeness\nof the initial seed data used for retrieval. Low-\nquality or unrepresentative seed data could lead\nto SSAEs that fail to capture relevant subdomain\nconcepts or exhibit biases inherited from the\nseed data. Exploring methods for automatically\nselecting or generating high-quality seed data and\nanalyzing the sensitivity of SSAEs to different\nseed data selection strategies would be valuable\ndirections for future research.\nGeneralizability Across Domains and Appli-\ncations. Our experiments with the Physics,\nToxicity, Bias in Bios, and TinyStories datasets\ndemonstrate the effectiveness of SSAEs across di-\nverse domains. While we have no reason to believe\nour findings won't generalize, further empirical\nvalidation across an even broader range of tasks\nand datasets would strengthen our conclusions.\nWe are particularly interested in evaluating SSAES\nin settings where rare concepts play a crucial\nrole, such as AI safety, healthcare, and fairness.\nThese applications would further solidify SSAES\nas powerful and versatile tools for enhancing\ninterpretability and control in foundation models."}, {"title": "Ethical Considerations", "content": "The ability to interpret and analyze rare concepts\nwithin foundation models, particularly those related"}, {"title": "Potential for Misuse and Dual-Use Concerns.", "content": "The techniques presented in this work, while\nintended for enhancing interpretability, safety, and\nfairness, could be misused for malicious purposes.\nThe capability to identify and manipulate rare\nfeatures, especially those associated with sensitive\nattributes like gender, race, or political affiliation,\ncould be exploited to amplify existing biases,\ngenerate harmful or misleading content, or manip-\nulate model behavior in ways that perpetuate or\nexacerbate societal inequalities. Addressing these\ndual-use concerns requires proactive efforts to\ndevelop safeguards, promote responsible use guide-\nlines, and engage in open discussions about the\npotential risks associated with these powerful tools."}, {"title": "Bias Amplification.", "content": "While SSAEs aim to im-\nprove the representation of rare and potentially un-\nderrepresented concepts, they are not inherently im-\nmune to bias. Biases present in the underlying foun-\ndation model and its training data can be inherited\nand potentially amplified by SSAEs, even when tai-\nlored to focus on specific subdomains or sensitive\nattributes. Mitigating this risk requires careful at-\ntention to data curation, development of robust bias\ndetection and mitigation techniques during both\nFM and SSAE training, and ongoing monitoring\nand evaluation of SSAE features to ensure they do\nnot perpetuate or exacerbate existing biases."}, {"title": "Data Privacy and Responsible Use.", "content": "The\ndatasets used in this work (OWT, Pile, arXiv\nPhysics, Pile Toxicity, Bias in Bios, TinyStories)\nare publicly available and widely used within\nthe NLP research community (see Appendix O).\nThese datasets have undergone accepted privacy\npractices at their creation time. We have strictly\nadhered to the license terms of these datasets,\nensuring responsible and ethical handling. We\nalso acknowledge the contributions of the creators\nand maintainers of the artifacts used in this\nwork (Gemma-2b, Pythia-70M, SAELens, and the\ndictionary_learning library). We have utilized\nthese artifacts in accordance with their intended\nuse and licensing agreements."}, {"title": "Reproducibility", "content": "To ensure reproducibility and\nfacilitate further research, all our code, experi-\nments, and ablations are implemented within the\nSAELens framework and will be publicly released\nupon acceptance of this paper."}, {"title": "A Related Work", "content": "This work intersects with several research areas, in-\ncluding mechanistic interpretability, sparse coding,\nfeature disentanglement, and evaluation methods\nfor Sparse Autoencoders. We contextualize our\ncontributions within this broader landscape."}, {"title": "A.1 Mechanistic Interpretability", "content": "Mechanistic Interpretability (MI) aims to decipher\nthe internal workings of neural networks by reverse\nengineering their computational processes (Olah\net al., 2020; Elhage et al., 2021). This approach\nconceptualizes model computations as collections\nof circuits narrow, task-specific algorithms.\nRecent circuit analyses of Foundation Models\n(FMs) have focused on mapping these circuits to\nspecific model components like attention heads\nand MLP layers (Wang et al., 2022; Heimersheim\nand Janiak, 2023).\nBuilding upon this component-level understand-\ning, the linear representation hypothesis proposes\nthat component activations can be further decom-\nposed into (sparse) linear combinations of mean-\ningful feature vectors. This concept underpins our\nwork on SSAEs. Unlike previous research that\nsought to identify individual subspaces represent-\ning specific concepts (Geiger et al., 2023; Nanda\net al., 2023a; Tigges et al., 2023), SAEs aim to pro-\nvide a more complete picture by fully decomposing\nactivations into interpretable features.\nMI has shown promise in various downstream\ntasks, including modifying model behavior to re-\nmove toxic outputs (Li et al., 2023), altering en-\ncoded factual knowledge (Meng et al., 2022), im-\nproving truthfulness (Li et al., 2024), analyzing\ngender bias mechanisms (Vig et al., 2020), and mit-\nigating spurious correlations (Gandelsman et al.,\n2023). Our work with SSAEs seeks to advance\nthese applications by providing refined tools for\ndetecting, interpreting, and modifying model be-\nhavior, particularly concerning rare or underrepre-\nsented concepts."}, {"title": "A.2 Sparse Coding, Dictionary Learning, and\nSparse Autoencoders", "content": "Our work draws inspiration from the foundational\nconcepts of sparse coding with over-complete dic-\ntionaries (Mallat and Zhang, 1993) and unsuper-\nvised dictionary learning from data (Olshausen\nand Field, 1996). These ideas, impactful in im-\nage processing (Mairal et al., 2014), evolved into\nthe development of sparse autoencoders (SAEs)\nthrough their integration with autoencoder architec-\ntures (Hinton and Salakhutdinov, 2006; Lee et al.,\n2007; Le, 2013; Konda et al., 2014).\nRecently, SAEs have been applied to language\nmodels (Yun et al., 2021; Sharkey et al., 2023;\nBricken et al., 2023; Cunningham et al., 2023),\nwith successful implementations on smaller open-\nsource language models (Marks et al., 2024; Bloom\nand Chanin, 2024; Mossing et al., 2024). We build\nupon this research trajectory, addressing specific\nlimitations and extending the approach to capture\nrare, domain-specific features more effectively."}, {"title": "A.3 Challenges, Improvements, and\nEvaluation of Sparse Autoencoders", "content": "Despite their potential, SAEs face several chal-\nlenges. For example, Anders and Bloom (2024)\nobserved that SAE features trained on language\nmodels with specific context lengths fail to general-\nize to activations from longer contexts. Wright and\nSharkey (2024) and Jermyn et al. (2024) osberved\nfeature suppression, a phenomenon where SAE fea-\nture activations systematically underestimate true\nactivation values due to sparsity penalties.\nVarious solutions have been proposed to tackle\nthese challenges, including post-training finetun-\ning (Wright and Sharkey, 2024), alternative spar-\nsity penalties (Jermyn et al., 2024; Riggs and\nBrinkmann, 2024; Farrell, 2024), and architectural\nmodifications such as Gated SAEs (Rajamanoharan\net al., 2024). Our work focuses on overcoming the\nlimitations of SAEs in representing tail concepts\nand proposes SSAEs to ensure a more balanced\nrepresentation of both frequent and rare concepts.\nEvaluating SAE performance is further compli-\ncated by the absence of ground truth labels for\nthe features they learn. Existing research has em-\nployed diverse metrics, including comparison with\nground truth features in toy data, activation recon-\nstruction loss, L1 loss, number of alive dictionary\nelements, feature similarity across seeds and dictio-\nnary sizes (Sharkey et al., 2022), LO sparsity, KL\ndivergence upon causal interventions (Cunningham\net al., 2023), reconstructed negative log likelihood\n(Cunningham et al., 2023; Bricken et al., 2023),\nfeature interpretability (Bills et al., 2023), and task-\nspecific comparisons (Makelov et al., 2024).\nOur work utilizes a combination of these metrics,\nincluding LO sparsity, reconstruction error, down-\nstream perplexity, and automated interpretability\nevaluations. We also introduce new metrics specifi-"}, {"title": "A.4 Disentangled Representations", "content": "Our research also connects to the broader field of\ndisentanglement in representation learning (Bengio,\n2013). While traditional disentanglement meth-\nods often rely on enforcing priors on learned rep-\nresentations (Chen et al., 2018; Kim and Mnih,\n2018; Mathieu et al., 2019), SAEs aim to decom-\npose the representation space of a pretrained lan-\nguage model into a sparse linear combination of\nan overcomplete basis. This approach aligns with\nthe theory that language models implicitly learn\ndisentangled representations of data with specific\nstructures, which we seek to recover using sparse\nautoencoders."}, {"title": "B Evaluating SSAE for Physics on OOD\ndata", "content": "Figure 9 depicts Pareto curves for SSAE trained\nwith various data selection strategies as the sparsity\ncoefficient is varied on the OOD Physics instruction\ntest data. We find that both BM25 retrieval and\ntraining on the validation data generalize poorly\nwhen tested out of domain."}, {"title": "C Evaluating Data Selection Strategies\nfor Toxicity SSAES", "content": "We use a seed concept dataset of 4072 tokens from\nthe Pile Toxicity dataset (Korbak, 2024). We re-"}, {"title": "D Probing SSAE Tail Concept Learning\nfor Toxicity", "content": "Figure 11 shows the proportion of tokens with SAE\nfeatures vs. Token frequency in Toxicity data using\nthe Logit Lens approach. We leverage the unem-\nbedding matrix as a logit lens to analyze the top-10\ntoken logits associated with each SSAE feature.\nFor each frequency bucket in the Toxicity dataset,\nwe calculate the percentage of tokens that appear\namong the top-10 logits for at least one feature.\nThis analysis allows us to assess the extent to which\nSSAE features represent tokens across different fre-\nquency ranges. SSAE trained with dense retrieval\ncaptures more tail tokens (concepts) in its features\ncompared to the baseline."}, {"title": "E Pareto curves for Tilted ERM trained\nSSAE", "content": "Figure 12 evaluates SSAEs trained with Tilted\nERM on the Physics arXiv dataset, displaying\nPareto curves where the x-axis represents $L_0$\nand the y-axis shows downstream perplexity with\npatched-in SSAE. TERM-finetuned SSAEs achieve\ncompetitive performance with Dense retrieval\nalone within the $L_0$ range of 85-100.\nFigure 13 shows similar Pareto curves on the Pile\ntoxicity dataset where TERM-finetuned SSAES\nachieve competitive performance with Dense re-\ntrieval within the $L_0$ range of 100-140.\nOur experiments demonstrate that TERM-\ntrained SSAEs consistently maintain $L_0$ within this\ndesired range, ensuring both sparsity and accurate\nreconstruction of subdomain concepts."}, {"title": "Improving $L_0$ Control at Extreme Values", "content": "Adaptive penalty schemes are much better than"}, {"title": "FTERM-trained SSAE enhances Tail\nConcept Capture in Toxicity data", "content": "Figure 14 shows the cumulative proportion of to-\nkens with SAE features vs. cumulative percentage\nof tokens in Toxicity data, normalized per model\nso that the cumulative proportion of tokens with\nfeatures is 1 over the entire dataset. SSAE trained\nwith dense retrieval and larger tilt captures more\ntail tokens (concepts) in its features."}, {"title": "G Implementation Details for\nBias-in-Bios Classification Experiments", "content": "We follow the methodology in Marks et al. (2024)\nfor Spurious Human-interpretable Feature Trim-\nming (SHIFT), which we summarize here for com-\npleteness. All models can be trained on a single\nA100 in under a day."}, {"title": "G.1 Classifier Training", "content": "Here we describe our approach to training a clas-\nsifier on Pythia-70M for the Bias in Bios (BiB)\ntask. To mimic a realistic application setting, we\nconducted a hyperparameter search to train high-\nperforming baseline and oracle classifiers (using\nthe ambiguous and balanced datasets, respectively).\nHyperparameters were not selected with the aim of\nstrong SHIFT performance.\nThe inputs to our classifier are residual stream\nactivations from the penultimate layer of Pythia-\n70M. We apply mean-pooling over (non-padding)\ntokens from the context. In our initial experiments,\nwe found that extracting representations over only\nthe final token led to slightly worse baseline and\noracle performance. Similarly, using activations\nfrom Pythia-70M's final layer yielded slightly\npoorer results.\nWe then fit a linear probe to these representations\nusing logistic regression. For optimization, we em-\nploy AdamW (Loshchilov, 2017) with a learning\nrate of 0.01, training for a single epoch. When re-\ntraining after SHIFT, we finetune only this linear\nprobe, leaving the full model unchanged.\nLike Marks et al. (2024), we encountered diffi-\nculties when attempting to fit a probe with greater-\nthan-chance accuracy using logistic regression on\nfinal layer representations. This observation led us\nto opt for penultimate layer representations in our\nmain approach."}, {"title": "G.2 Implementation for Concept Bottleneck\nProbing", "content": "Our implementation of Concept Bottleneck Prob-\ning (CBP) draws from Yan et al. (2023). The pro-\ncess is as follows:\n1. First, we select N = 20 keywords related to\nthe intended prediction task. Our keyword set\nincludes: nurse, healthcare, hospital, patient,\nmedical, clinic, triage, medication, emergency,\nsurgery, professor, academia, research, univer-\nsity, tenure, faculty, dissertation, sabbatical, pub-\nlication, and grant.\n2. We obtain concept vectors C1, . . ., CN for each\nkeyword by extracting Pythia-70M's penultimate\nlayer representation over the final token of each\nkeyword, then subtracting the mean concept vec-\ntor. This normalization step proved crucial, as\nwe found that without it, concept vectors exhib-\nited very high pairwise cosine similarities.\n3. Given an input with representation x (obtained\nvia the mean-pooling procedure described ear-\nlier), we construct a concept bottleneck represen-\ntation z \u2208 RN by computing the cosine similar-\nity with each Ci.\n4. Finally, we train a linear probe on these con-\ncept bottleneck representations z using logistic\nregression, following the approach outlined in\nthe Classifier Training subsection.\nAs in Marks et al. (2024), we decided to normal-\nize concept vectors but not input representations,\nas this approach yielded stronger performance. We\nalso explored the alternative of computing cosine\nsimilarities before mean pooling."}, {"title": "H Sparse Feature Circuits for Bias in\nBios Classifer", "content": "In this section, we generate sparse feature circuits,\nwhich are computational sub-graphs that explain\nmodel behaviors in terms of SAE features and er-\nror terms, using the methodology in Marks et al.\n(2024). We begin by describing the process of gen-\nerating these circuits.\nGiven a language model M, SAEs for various\nsubmodules of M (e.g., attention outputs, MLP\noutputs, and residual stream vectors), a dataset D\nconsisting of either contrastive pairs ($X_{clean}, X_{patch}$)\nof inputs or single inputs x, and a metric m de-\npending on M's output when processing data from\nD, we can construct these circuits. The idea is to\ntreat SAE features as part of the model. By ap-\nplying the decomposition to various hidden states\nx in the LM, we can view the feature activations\n$f_i$ and SAE errors $\\varepsilon$ as integral parts of the LM's\ncomputation. This allows us to represent the model\nas a computation graph G where nodes correspond\nto feature activations or SAE errors at particular\ntoken positions.\nTo approximate the Indirect Effect (IE) of each\nnode, we compute IE(m; a; x) for each node a in\nG and input x ~ D, where IE is either $IE_{atp}$ or\n$IE_{ig}$. We then apply a node threshold $T_N$ to select\nnodes with a large (absolute) IE. Consistent with\nprior work (Nanda, 2023; Kram\u00e1r et al., 2024), we\nfind that $IE_{"}]}