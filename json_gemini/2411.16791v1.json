{"title": "What can LLM tell us about cities?", "authors": ["Zhuoheng Li", "Yaochen Wang", "Zhixue Song", "Yuqi Huang", "Rui Bao", "Guanjie Zheng", "Zhenhui Jessie Li"], "abstract": "This study explores the capabilities of large language models (LLMs) in providing knowledge about cities and regions on a global scale. We employ two methods: directly querying the LLM for target variable values and extracting explicit and implicit features from the LLM correlated with the target variable. Our experiments reveal that LLMs embed a broad but varying degree of knowledge across global cities, with ML models trained on LLM-derived features consistently leading to improved predictive accuracy. Additionally, we observe that LLMs demonstrate a certain level of knowledge across global cities on all continents, but it is evident when they lack knowledge, as they tend to generate generic or random outputs for unfamiliar tasks. These findings suggest that LLMS can offer new opportunities for data-driven decision-making in the study of cities.", "sections": [{"title": "Introduction", "content": "Cities are of significant importance, as more than half of the world's population now resides in cities. With the availability of rich city data, LLMs inherently encode extensive information about various aspects of our cities. LLMs could open new possibilities for city research, as illustrated in the following examples.\nExample 1. Region-level knowledge inside cities. Using NYC open data (New York City Taxi &Limousine Commission 2024), Figure 1 shows the 24-hour taxi pick-up and drop-off count for two zones in New York City (NYC). Since the 24-hour data are aggregated from raw pick-up and drop-off records, LLMs naturally do not have access to this specific information. When directly asked to generate a 24-hour curve, an LLM will either acknowledge that it lacks this data or produce random numbers. However, LLMs can provide insights into the functions of these zones within NYC, and the semantics of these functions often align well with our understanding of traffic patterns. For example, the LLM identifies the Garment District primarily as a commercial zone, exhibiting a drop-off peak in the morning and a pick-up peak in the evening. In contrast, the LLM classifies Arden Heights as a predominantly residential area, showing the opposite pattern. These functional characteristics can be leveraged as features to model traffic.\nThis example demonstrates that although LLMs may not have direct access to the target variable, they can identify features that could be used to model it. This implication is significant. If an LLM can estimate features for all cities and the correlation between these features and traffic patterns can be generalized, we could potentially derive traffic patterns for any city, even those that do not release traffic data as comprehensively as NYC does.\nExample 2. City-level knowledge across the globe. Public transportation is a core topic in city research. However, since different cities around the world release data in various formats, collecting public transportation data is a tremendous effort. For instance, a recent study (Verbavatz and Barthelemy 2020) compiles public transportation data from 85 cities in OECD (Organization for Economic Co-operation and Development) countries, spanning across 25 nations.  As seen, these countries use different languages, and some data sources include terms that may be well-known locally but unfamiliar to outsiders (e.g., SNCF, which stands for Soci\u00e9t\u00e9 nationale des chemins de fer fran\u00e7ais, is France's national state-owned railway company). Even within the same country, data sources can come from different agencies (e.g., PTV of Melbourne and TransLink of Brisbane, both in Australia). This example illustrates the significant challenges involved in collecting city data across global cities.\nMeanwhile, LLMs possess a broad understanding of cities across the globe. As shown in Figure 3, when asked to score public transportation for these 85 cities, the LLM's responses strongly correlate with the public transportation metric, People Near Transit (PNT), calculated in the dataset (Verbavatz and Barthelemy 2020). We do not intend to suggest that the effort of collecting raw data should be replaced by LLMs. However, we want to emphasize that LLMs can easily scale up studies to include global cities with minimal effort. In situations where no data is available, having some insight from an LLM is better than having none, especially when attempting to generalize a scientific study to a global scale. While we do not believe that data from LLMs should be directly trusted to derive rigorous scientific findings, we do think that this data can be valuable in helping to test some hypotheses.\nMotivated by the examples above, we conduct extensive experiments to explore what LLMs know about cities. Our experiments cover more than 40 tasks, each involving hundreds of cities on average. These tasks encompass various aspects of cities, including the environment, transportation, energy, crime, industry, and more. We also experiment with different ways to prompt the LLM and test various models.\nThrough these experiments, we discover many interesting findings, with our key insight being that LLMs know something about everywhere.\nIn summary, our contributions are as follows:\n\u2022 We systematically investigate the knowledge in LLMs about cities, providing a comprehensive analysis across a broad range of city-related tasks.\n\u2022 We demonstrate that LLMs can effectively identify and leverage latent features within both cities and regions, even in the absence of direct data, offering a novel approach to modeling urban and regional phenomena and generalizing insights across different areas. This suggests a scalable method for extending research to locations with limited or no data availability.\n\u2022 We provide valuable experimental results that pave the way for future studies on the application of LLMs in city research, opening new possibilities for understanding global cities."}, {"title": "Related Work", "content": "By pre-training large language models on vast amounts of data, they acquire a significant amount of knowledge. Since the advent of pre-trained language models, numerous studies have sought to quantify the extent of knowledge contained within these models (Roberts, Raffel, and Shazeer 2020). A common focus has been on evaluating how well these models respond to factual knowledge (Petroni et al. 2019; Jiang et al. 2020). Other areas of investigation include commonsense knowledge (Davison, Feldman, and Rush 2019), time-sensitive knowledge (Dhingra et al. 2022), biomedical knowledge (Sung et al. 2021), geospatial knowledge (Manvi et al. 2023), among others. Our work draws inspiration from GeoLLM (Manvi et al. 2023), which explores using LLMs to infer global geospatial knowledge such as population and education. However, we specifically focus on cities, examining how to extract city knowledge and exploring how this knowledge correlates with open city data."}, {"title": "Extracting Knowledge from LLM", "content": "LLMs are known to embed extensive knowledge, yet the challenge lies in effectively extracting this knowledge in a desired way. A common approach involves fine-tuning the LLM by adapting its pre-trained weights to a new data domain, thereby enabling its prediction capabilities in that area (Radford et al. 2018). Recent years have seen the development of efficient fine-tuning frameworks like LoRA (Hu et al. 2021), which optimizes the process by using low-rank matrices to approximate necessary adjustments instead of modifying entire weight matrices. Another group of research focuses on prompt tuning (Zhong, Friedman, and Chen 2021), which seeks to design prompts that effectively leverage the pre-trained model's knowledge in new domains. Crafting effective prompts is notoriously challenging (Qin and Eisner 2021); thus, strategies like chain-of-thought reasoning (Wei et al. 2022) and instruction templates (Longpre et al. 2023) have demonstrated more effective in guiding LLMs toward accurate responses. Rather than adapting the pre-trained model to a specific new field, we propose to investigate the extent of city knowledge that LLMs can reveal across various aspects. Our goal is to demonstrate that LLMs can achieve comparable accuracy to traditional feature engineering approaches but with significantly less effort."}, {"title": "LLM for City Tasks", "content": "Recent studies have been utilizing the large language model (LLM) to better tackle traffic-related tasks (Jin et al. 2024; Minaee et al. 2024). Generally, the utilization of LLM can be divided into three categories. (1) LLM as prediction model. Most of the current methods aim to use LLM as a predictor. Hence, the critical step is to convert the time series data into the space of LLM, by quantizing the time series into discrete tokens (Ansari et al. 2024) through methods like VQ-VAE or training a separate encoder to align the time series to LLM semantic space (Zhou et al. 2023). Thus, LLM can be used to make time series predictions (Gruver et al. 2024) like traffic prediction. (2) Fine-tuned LLM as a prediction model. Recent studies further explored utilizing the traffic time series data to fine-tune the pre-trained LLM model (Jin et al. 2023; Cao et al. 2023; Chang, Peng, and Chen 2023) to achieve better prediction results. Extra background information like date and hour can be extracted from the time series to help LLM better fine-tune (Guo et al. 2024). (3) LLM to enhance feature. Researchers also try to use LLM as a feature extractor (Xue and Salim 2023) to reveal more information from the time series data and use this information to further make predictions. (4) LLM to interpret instructions to run traffic models. Some studies also use the power of LLM to facilitate a front-end chatbot in which people can call several traffic analysis tools (Zhang et al. 2024a). In contrast, we are working on a completely different problem, in which we aim to use LLM to extract external long-tail knowledge and verify its effectiveness on various tasks, instead of one specific prediction task."}, {"title": "Problem and Method", "content": "Given a set of cities (or regions in a city) $C = \\{C_1, C_2,..., C_n\\}$, we are interested in obtaining the target variable values for all cities (or regions) in $C$. Let the target variable be denoted by $y$. The goal is to determine the values $y(c_i)$ for each city $c_i$ in the set $C$. Cities or regions in the cities are treated the same in the method. We will use cities for simplicity in the description of the method.\nWe conduct experiments in two categories:\n\u2022 Directly asking LLM. This method is to directly ask LLM about the values of the target value for the city of interest.\n\u2022 Extract features and train an ML model. This line of methods is to ask LLM about the features that potentially correlate with the target variable for the city of interest. Using these features retrieved for each city, we then train a machine learning model to predict the target variables across the set of cities.\nWe will describe the methods in detail in the rest of the section."}, {"title": "Directly Asking LLM", "content": "When directly asking LLM, the prompt includes both the city name and the target variable. The following is a template applicable to all tasks."}, {"title": "Implicit Feature Extraction", "content": "To extract the features for the target variable, we obtain the last hidden states from the LLM and then treat them as features. These features may not be human-understandable but they encapsulate knowledge relevant to the city and the target variable.\nWe use the same prompt as the one used in directly asking LLM. The last hidden layer is used to extract features. However, directly using the last layer is problematic due to its size. For example, the last hidden layer of Llama3.1-8B is the size of 37 \u00d7 4096. Since our data samples are usually in the scale of hundreds, the high dimensionality will cause the under-fitting of the machine learning models. It is necessary to conduct dimension reduction for the raw features from the last hidden layer.\nAs shown in Figure 4, to conduct dimension reduction, we first use a concatenated mean-max pooling technique, followed by a linear transformation, inspired by common practices in NLP (Lin et al. 2017) and computer vision (Kipf and Welling 2016). The dimension of features is 32 by default in experiments. A machine learning model is further trained on the extracted features and the target variable.\nWe could only conduct this experiment on the open-source LLMs. LLMs such as chatGPT only provide API access, limiting the access of the hidden layers. In the experiments, we use Llama3.1-8B-Instruct by default. We also conduct experiments using Llama3.1-70B-Instruct. The difference between these two models is marginal in our tasks."}, {"title": "Explicit Feature Extraction", "content": "Another method to extract features is to explicitly include the feature names in the prompt. Different from implicit feature extraction, such an explicit approach can extract features that are human-understandable. The following example is a template applicable to all tasks.\nThough explicit features are good for human understanding, it is tricky to design what features to be asked. Especially for the unfamiliar target variable, we may have little knowledge of which features might be relevant. Even for the target variable that we are familiar with, we may not be sure which wording we should use for features.\nWe find that instead of handcrafting features by humans, it is more effective to ask LLM about the features to use. LLM not only serves as feature extraction but also feature identification in this method. We design an interactive feature extraction framework as shown in Figure 5. In feature identification step, LLM provides the general knowledge related to the target variable. In feature extraction step, LLM provides specific knowledge about certain features for the city of interest. In this framework, the feature extraction is more coherent using the knowledge and the wording that LLM inherently encodes. The correlation with the target variable is often more significant for LLM-extracted features, leading to better model performance compared to manually selected features."}, {"title": "Experiment", "content": "We conduct experiments about 41 various tasks in 8 domains on two levels of data, region-level (each data point represents a census block, community area, or district) and city-level (each data point represents a city). For evaluation, we use the Root Mean Square Error (RMSE) as the primary metric.\nThe compared methods are listed below.\n\u2022 Exp-Feature: Given a task, explicitly ask LLM for related feature names and then ask LLM for feature values.\n\u2022 Imp-Feature: Ask LLM about the target variable and implicitly obtain the last hidden layer vector to represent the city/region.\n\u2022 Direct-Ask: Directly ask LLM for predictions on the target variable.\n\u2022 No-Feature: Use the average value of the target as the predicted value.\nNote that, the Exp-Feature and Imp-Feature are further fed into an ML model. A set of frequently used ML models are tried including Decision Tree, Random Forest, Gradient Boosting, XGBoost, AdaBoost, and Linear Regressor. The best results are reported. We use 5-fold cross-validation in the ML setting.\nRegarding computational resources, we use machines equipped with either four NVIDIA A30 GPUs or eight NVIDIA A100 GPUs. For the model, note that all references to Llama 3.1-8B in this paper refer specifically to Llama 3.1-8B-Instruct. Llama3.1-8B is locally deployed on A30 GPUs, while GPT-40 is accessed via API. Due to the limitations of the GPT-40 API, which does not allow access to hidden layers, the Imp-Feature method was implemented solely using the locally deployed Llama3.1-8B to extract the necessary hidden layers.\nTo illustrate, on the Carbon emission dataset (Nangini et al. 2019), which includes 343 global cities, the Exp-Feature and Direct-Ask experiments on GPT-40 each take approximately 50 minutes. Similarly, on Llama3.1-8B, these experiments also take around 50 minutes, while the Imp-Feature experiment requires only about 1 minute. The No-Feature experiment, which does not involve GPU computation, takes only a very short amount of time."}, {"title": "Overall Results", "content": "Table 1 shows the comprehensive results of 41 tasks. The key findings are as follows:\n\u2022 LLMs generally provide meaningful responses, enabling us to predict target values effectively, whether through Direct-Ask or feature-based methods. For popular datasets (i.e., datasets that might be public and easy-to-be-browsed online), Direct-Ask yields the smallest error. This means LLM directly knows the answer (like the PM2.5, PM10, COVID-19, and Home value cases).\n\u2022 For most of the cases, extracting features improves the performance over Direct-Ask and No-Feature. This means that even for target values that LLM does not directly know, LLM can help to extract useful features to assist the prediction.\n\u2022 In terms of different LLM models, GPT-4o performs better in general. This selection of various LLMs will be further illustrated later in the experiment.\n\u2022 It is interesting to see that Exp-Feature and Imp-Feature using Llama3.1-8B show a tie in their performance, indicating that explicitly extracting features is recommended in practice because not all LLMs provide the hidden layers as Llama does."}, {"title": "Q1: Can we determine when LLM knows or does not know the answer?", "content": "Although it can be fairly difficult to prove what LLM says is correct (without knowing the ground truth), there are some obvious flags when LLM does not know.\nDetecting consistent generic values. If the LLM frequently produces the same rounded number, such as 50, across various contexts, it suggests that the model may lack specific knowledge about the data in question. This behavior indicates a tendency to default to a generic or placeholder value rather than providing a contextually informed estimate. As shown in Figure 6, for the queries on values of Industry Output of Mining for 245 cities in China (Zhang et al. 2024b), LLM outputs certain placeholder values for most of the time ('5' for 54 times, and '50' for 176 times out of the 245 city queries). This is clearly suggesting suspicious generic outputs.\nDetecting inconsistent values among different rounds of generations. If the outputs of the LLM regarding the same query exhibit large variance, this suggests that the model may be uncertain about the information and is generating responses based on random guesses rather than a solid knowledge of the data. Such inconsistency indicates that the LLM may not be reliably estimating the information, instead oscillating between generic or uncertain predictions. As shown in Figure 7, we plot the re-scaled deviation of each sample in 100 queries for two datasets, COVID-19 (CDC 2023) and Mining. For a dataset that LLM has high confidence, COVID-19, its output is very stable. While for a dataset that LLM has no clear answer, Mining, its output has a much larger deviation. This aligns with the fact that LLM does a good job in the COVID-19 prediction while a poor job in the Mining prediction."}, {"title": "Q2: Can LLM tell the precise value of the features?", "content": "When asking LLM for feature values, it is observed that LLM may generate data with some randomness. Here, we ask LLM to generate features for PNT on a scale of 0.0-10.0 and 0.0-100.0. The extracted feature values on a scale of 0.0-10.0 are shown in Figure 8. A pattern emerges where the generated features tend to cluster around specific intervals (e.g., 5.0, 5.5, 6.0). When changing the feature scale to 0.0-100.0, the original feature values are basically amplified by 10 times. Averaging results across scales of 0.0-10.0 and 0.0-10.0 reveals that over 60% of standard deviations are less than 1.0, indicating consistent feature extraction by the LLM across different scales, with minor variation added.\nThus, it is easy to conclude that LLM is not outputting the precise value. Since LLM-generated features do help the prediction (as in Table 1), it can be inferred that LLM-generated features keep the relative order of samples compared with the ground truth samples. Here, we plot the ground truth nightlife POI data (Wang et al. 2016) and LLM-generated nightlife POI data for Chicago in Figure 9. We can observe that although the exact values in the two feature sets are different, the relative order among different regions is close."}, {"title": "Q3: Which LLM model performs the best?", "content": "While we have compared GPT-40 and Llama3.1-8B in Table 1, here we further compare several frequently-used LLM via API queries. These LLMs are asked to generate the Methane data (Du et al. 2024) of 347 cities in China using the Exp-Feature manner. It is obvious that GPT-40 achieves the best performance and all other three models hold an 8% - 19% larger error.\nWe further investigate the impact of model size by implicit feature Llama3.1-8B and Llama3.1-70B for the NYC 311 data (nyc opendata 2023) three times. The results in Table 3 show that the model size does not make too much difference."}, {"title": "Q4: Which language should be used to formulate the prompt?", "content": "We formulate the prompts in Chinese and English respectively and test the Direct-Ask performance on two datasets, Material stocks (Li et al. 2023) and PNT(1500m). Since Material stocks focus on Chinese cities while PNT(1500m) covers worldwide cities, we expect prompts in different languages to exhibit different performances. The results are shown in Table 4. For global cities, using English brings a better performance, while for Chinese cities, using Chinese can bring a similar performance as using English."}, {"title": "Conclusion", "content": "Our paper conducts extensive experiments to explore what LLM knows about cities. From experiments, there are three key takeaways. (1) LLM knows something about everywhere. Our experiments include global cities on all continents. All the experiments consistently show that LLM either directly knows the answer or contains related features that could be used to train ML models with 18% improvements over the No-Feature method. (2) It is obvious to know when LLM does not know. Most of our tasks are not common knowledge and LLM may have not seen such data before. In these cases, we commonly see that LLM generates generic or random answers. (3) Explicit feature extraction is often more effective and versatile, offering a structured approach to capturing information across both open-source and closed-source models. Though Exp-Feature and Imp-Feature with Llama 3.1-8B perform similarly, Exp-Feature is recommended since not all LLMs provide accessible hidden layers. Additionally, our method could offer valuable insights into how different models perform in city contexts. In conclusion, our work paves the way for future studies on the application of LLMs in city research, opening new possibilities for understanding global cities."}]}