{"title": "Mining Glitch Tokens in Large Language Models via Gradient-based Discrete Optimization", "authors": ["Zihui Wu", "Haichang Gao", "Ping Wang", "Shudong Zhang", "Zhaoxiang Liu", "Shiguo Lian"], "abstract": "Glitch tokens in Large Language Models (LLMs) can trigger unpredictable behaviors, compromising model reliability and safety. Existing detection methods often rely on manual observation to infer the prior distribution of glitch tokens, which is inefficient and lacks adaptability across diverse model architectures. To address these limitations, we introduce GlitchMiner, a gradient-based discrete optimization framework designed for efficient glitch token detection in LLMs. GlitchMiner leverages an entropy-based loss function to quantify the uncertainty in model predictions and integrates first-order Taylor approximation with a local search strategy to effectively explore the token space. Our evaluation across various mainstream LLM architectures demonstrates that GlitchMiner surpasses existing methods in both detection precision and adaptability. In comparison to the previous state-of-the-art, GlitchMiner achieves an average improvement of 19.07% in precision@1000 for glitch token detection. By enabling efficient detection of glitch tokens, GlitchMiner provides a valuable tool for assessing and mitigating potential vulnerabilities in LLMs, contributing to their overall security. Our code is available at https://github.com/wooozihui/GlitchMiner.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs), such as GPT-4 [2], have revolutionized natural language processing, enabling breakthroughs in critical fields, including code generation [13, 6, 18], medical research [10, 26], and education [25, 14]. Despite their strengths, these models harbor a subtle yet critical vulnerability: glitch tokens [9]. Glitch tokens are anomalous tokens that disrupt the model's ability to understand or generate accurate responses, leading to unpredictable behaviors such as inappropriate content, repetitive errors, hallucinated outputs, or offensive language [9, 16, 17, 15]. This issue stems from the tokenization process, potentially arising due to insufficient training or poorly embedded tokens within the model's vocabulary.\nFor instance, as shown in Figure 1, the Llama2-7B-chat-hf [23] model fails to recognize the token \u201coreferrer,\u201d treating it as an uncorrelated term. This oversight reveals deeper vulnerabilities in token handling, leading to unexpected outputs that can compromise the reliability of LLMs, especially in high-stakes applications. Mitigating these glitches is crucial to ensuring the trustworthiness and robustness of LLM-generated content.\nExisting methods for detecting glitch tokens primarily rely on manual observation to assume their prior distribution [16, 17, 15]. However, this approach is not only time-consuming and labor-intensive but also struggles to adapt to different model architectures and vocabularies. Moreover, it often overlooks glitch tokens that fall outside predefined distribution patterns, limiting the detection's coverage and accuracy.\nTo overcome these challenges, we propose GlitchMiner, a novel gradient-based discrete optimization framework for efficiently detecting glitch tokens in LLMs. Unlike previous methods that rely on manual observation of glitch tokens, GlitchMiner focuses on identifying tokens that deviate significantly from the normal token distribution\u2014where most tokens exhibit high certainty and predictable behavior. As illustrated in Figure 2, GlitchMiner leverages the uncertainty in token predictions to uncover potential glitches. It employs an entropy-based loss function to measure uncertainty and uses a local discrete optimization strategy, combining first-order Taylor approximation [21] with local search, to efficiently explore the token space. This adaptive approach enables GlitchMiner to surpass the limitations of earlier methods, providing more comprehensive detection without relying on predefined distribution assumptions.\nOur main contributions in this paper include:\n1. Entropy-based Loss Function: We propose using entropy as the optimization objective, effectively capturing the uncertainty in model predictions without relying on manually defined glitch token prior distributions.\n2. Local Search Strategy: We design a novel discrete optimization method that combines first-order Taylor approximation with local search, significantly improving the efficiency and accuracy of glitch token detection.\n3. Wide Applicability: Through experiments on multiple mainstream LLM architectures, we demonstrate the generalizability and effectiveness of GlitchMiner. Experimental results show that GlitchMiner improves the precision@1000 of glitch token detection by an average of 19.07% compared to previous state-of-the-art method.\n4. Efficient Detection: Our method can quickly locate potential glitch tokens in large-scale vocabularies, greatly improving detection efficiency and providing a powerful tool for assessing and improving the security of LLMs.\nThe structure of this paper is as follows: Section 2 reviews related work, including glitch token detection and gradient-based discrete optimization methods; Section 3 details the design and implementation of GlitchMiner; Section 4 presents experimental results and analysis; finally, Section 5 concludes the paper and discusses future research directions."}, {"title": "Related Work", "content": "2.1 Glitch Token Detection\nDetecting glitch tokens in LLMs has garnered increasing attention. Several methods have been proposed to address this issue, including Magikarp [15], GlitchHunter [17], and GlitchProber [28], each utilizing different strategies to identify glitch tokens.\nMagikarp [15] detects glitch tokens by analyzing token embeddings. It uses characteristic patterns, such as the l2 norm, in the embedding space to identify under-trained tokens and employs simple repetition tasks to test whether the model can accurately reproduce these tokens. This method focuses on quickly detecting problematic tokens through direct queries, making it fast and lightweight.\nGlitchHunter [17] adopts a clustering-based approach. It assumes that glitch tokens tend to cluster in the embedding space and constructs a Token Embedding Graph (TEG), where nodes represent tokens connected based on their embedding similarity. By applying the Leiden algorithm [24], GlitchHunter identifies potential glitch clusters. Hypothesis testing is then used to refine these clusters, iterating multiple times to ensure the accuracy of detection.\nGlitchProber [28] takes a different approach by analyzing the internal activations within transformer layers, such as attention heads and hidden states. It reduces the dimensionality of these activations using PCA [11] and applies SVM classifiers [7] to identify glitch tokens. Additionally, it integrates mitigation mechanisms by modifying neuron activations to minimize the impact of glitch tokens during inference.\nBoth Magikarp and GlitchHunter rely on manually observed prior distributions to sample token space for glitch token detection, performing well when their assumptions align with the actual glitch token distribution. However, their adaptability can be limited when real-world distributions deviate from these priors. GlitchProber aims to improve detection through automation, but it requires a large number of queries to collect sufficient training data. Additionally, the need for extra training introduces computational overhead, impacting efficiency in practice.\nOur method overcomes these limitations by using entropy-based loss functions to quantify uncertainty in predictions, without relying on priors or additional training.\n2.2 Gradient-based Discrete Optimization\nGradient-based discrete optimization methods [8, 20, 29] leverage gradient information to predict how individual tokens impact the loss function. These approaches typically treat the one-hot encoding of tokens or token embeddings as continuous vectors to compute gradients, guiding token replacements for optimization."}, {"title": "Method", "content": "3.1 Token Filter\nIn the initialization stage of GlitchMiner, we first filter all tokens to remove those that do not need to be detected. Similar to [15], we designed a token filter module that classifies tokens based on their characteristics and filters out those that are unnecessary for detection.\nThe core idea of the token filter module is to classify each token by decoding and then re-encoding it, ensuring it meets specific classification criteria. Specifically, we prepend a special prefix \u201c\u00ab\u201d to each token to maintain consistency during the encoding and decoding process. Then, we filter out tokens that fall into the following categories:\n\u2022 SPECIAL: Special tokens, such as [BOS], </s>, etc., which are enclosed in brackets or angle brackets and contain alphabetic characters.\n\u2022 UNDECODEABLE: Tokens that cannot be decoded, usually containing illegal characters.\n\u2022 UNREACHABLE: Tokens that cannot be restored to their original token ID through the decoding and re-encoding process.\nDuring the classification process, we first decode each token ID to obtain its corresponding string representation. If decoding fails, the token is classified as UNDECODEABLE. Next, we encode the decoded string and check if it can be restored to the original token ID. If it cannot, the token is classified as UNREACHABLE. If it meets the characteristics of a special token, it is classified as SPECIAL.\nBy filtering out these unnecessary tokens, we retain only the essential ones for subsequent mining, which improves the algorithm's efficiency and ensures the accuracy of the detection results.\n3.2 Glitch Token Verification\nTask Template. Previous research typically employed a repetition task to verify whether a token is a glitch token by checking if the model can repeat a given token. If the model fails to reproduce the token correctly, the token is labeled as a glitch token. However, we found that the prior task templates are not directly suitable for gradient-based discrete optimization. For instance, in Magikarp [15], the token being checked is repeated multiple times, forcing the model to output the current token, which can lead to unnecessary computational overhead and imprecise gradient calculations of the input token.\nTo address this issue, we designed a more straightforward task template as follows:\nUser: Please repeat the string: \"<<{token}\u00bb\"\nAssistant: Sure, the string is: \"\u00ab{token}\"\nIn this template, the blue text represents the prompt used to verify glitch tokens. The green text, {token}, corresponds to the input token being tested, while the red text, {token}, represents the model's predicted output. If the predicted token does not match the input token, the input token is classified as a glitch token.\nThe response from the assistant, starting with \"Sure, the string is:\u00ab\", is prefilled as part of the template, ensuring consistency in the model's response format. The token is wrapped in the \"\u00ab\" and \"\u00bb\" symbols, similar to the token filter, to prevent interference from other characters during token encoding.\n3.3 Token Selection\nEntropy as Loss Function. One of the key distinctions between our approach and previous work lies in our token selection strategy. Prior methods often rely on manually observed prior knowledge about the distribution of glitch tokens to select those most likely to be glitch tokens. However, this approach can overlook tokens that do not fit the prior assumptions but are still glitch tokens. Ultimately, the effectiveness of these methods depends on how closely the manually defined priors align with the actual distribution of glitch tokens.\nGiven that manual priors of glitch token distribution can be inaccurate, a more robust approach is to identify tokens that deviate significantly from the normal token distribution. To achieve this, we propose using entropy as the loss function in our optimization process. Entropy measures the uncertainty or randomness in a probability distribution. For normal tokens, we expect the model to predict the next token with high confidence, resulting in a low-entropy distribution. Maximizing entropy helps us find tokens that cause more uncertainty in the model's predictions, thereby identifying tokens that deviate from the expected behavior of normal tokens. This allows us to discover glitch tokens without depending on observed distribution patterns or manually defined assumptions about their characteristics.\nOptimization Objective. Based on the above ideas, we present the mathematical description of the optimization objective. In each iteration, the goal is to find a batch of tokens with the highest entropy from the set of unverified tokens. Let $\\mathbb{T}$o represent the current candidate set, defined as $\\mathbb{T} = \\mathbb{T} \\backslash (\\mathbb{T}^* \\cup \\mathbb{G})$.\nLet $h(t)$ represent the context embedding for a token $t$, and let $P(v | h(t))$ denote the probability distribution over the vocabulary $\\mathbb{V}$, predicted by the model for token $t$. The entropy $H(t)$ for token $t$ is defined as:\n$H(t) = - \\sum_{v \\in \\mathbb{V}} P(v | h(t)) \\log P(v | h(t))$\nIn each iteration, the optimization objective is to find a batch of tokens $\\mathbb{B}$ that maximizes the entropy $H(t)$, i.e.,\n$\\mathbb{B} = \\underset{\\mathbb{B} \\subset \\mathbb{T}c, |\\mathbb{B}|=B}{\\arg \\max} \\sum_{t \\in \\mathbb{B}} H(t)$\nLocal Search Strategy. To efficiently solve the aforementioned optimization problem, we propose a local search strategy based on AutoPrompt. This approach combines local search with first-order Taylor approximation to estimate the entropy of candidate tokens, enabling us to select the batch most likely to contain glitch tokens.\nOur strategy initiates by selecting an initial token $t_0$, computing its entropy $H(t_0)$, and the corresponding gradient $\\nabla_{e}H(t_0)$, where $\\nabla_{e}H(t_0)$ represents the partial derivative with respect to the embedding vector $e_{t_0}$. For each candidate token $t \\in \\mathbb{T}e$, we estimate its entropy using the first-order Taylor approximation:\n$H(t) \\approx H(t_0) + \\nabla_{e}H(t_0) (e_t - e_{t_0})$\nwhere $e_t$ and $e_{t_0}$ denote the embedding vectors of tokens $t$ and $t_0$, respectively. This approximation estimates the change in entropy for the candidate token $t$ based on the change in its embedding relative to $e_{t_0}$, guiding the selection of tokens with potentially higher entropy.\nTo improve the accuracy of the approximation, we introduce a local search strategy. We define $\\mathbb{N}_K(t_0)$ as the set of $K$ nearest neighbor tokens to $t_0$:\n$\\mathbb{N}_K(t_0) = \\{t \\in \\mathbb{T} : t \\text{ is one of the } K \\text{ nearest neighbors of } t_0\\}$\nWithin this local neighborhood $\\mathbb{N}_K(t_0)$, we select the batch $\\mathbb{B}$ of $B$ tokens with the highest approximated entropy:\n$\\mathbb{B} = \\underset{\\mathbb{B} \\subset \\mathbb{N}_K(t_0), |\\mathbb{B}|=B}{\\arg \\max} \\sum_{t \\in \\mathbb{B}} \\widehat{H}(t)$\nAfter selecting the batch $\\mathbb{B}$, we compute the actual entropy values $H(t)$ for each token in the batch and choose the token with the highest actual entropy as the starting point $t_0$ for the next iteration.\nThis ensures that each iteration is guided by the token with the most promising entropy, allowing the optimization process to converge more efficiently.\nThis local optimization strategy effectively mitigates the issue of inaccuracies in the Taylor approximation when applied globally while maintaining computational efficiency. By focusing on a local neighborhood in each iteration, we can more accurately estimate the entropy of candidate tokens, thereby enhancing the efficiency of glitch token detection. This approach strikes a balance between exploration of the token space and exploitation of local information, facilitating a more targeted and effective search for glitch tokens."}, {"title": "Experiments", "content": "4.1 Experimental Setup\nTarget LLM. We used a diverse set of LLMs from five different model families to evaluate the performance of our glitch token detection approach. The selected models include Meta's Llama series [23, 3], Alibaba's Qwen models [27, 5], Google's Gemma models [22], Microsoft's Phi-3 models [1], and Mistral models [12, 4].\n4.3 Ablation Study\nTo evaluate the contributions of key components in GlitchMiner, we conducted ablation studies focusing on the local search strategy, neighborhood size K, and batch size B.\nEffect of Local Search. The local search strategy plays a crucial role in enhancing GlitchMiner's ability to detect glitch tokens by improving the precision of the Taylor approximation. Without local search, detection accuracy drops significantly (Figure 3), as global search lacks the necessary granularity to maintain precise approximations within the token space.\nEffect of Neighborhood Size. In figure 4, we can see that as the neighborhood size K increases, there is a gradual decline in precision. However, if K is too small, the exploration is insufficient, which also reduces accuracy, as shown in the experiments with Llama-3.1-8B. Therefore, balancing K is crucial to ensure both broad enough exploration and sufficient approximation accuracy.\nEffect of Batch Size. As shown in figure 5, different models exhibit varying sensitivity to batch size B. For example, Llama-3.1-8B and Qwen2.5-7B perform best at B = 4, while Phi-3-mini peaks at B = 8. Gemma-2-2B, on the other hand, reaches its highest performance at B = 16 and maintains strong results at larger B values. This indicates that the optimal B value depends on the specific model architecture.\n4.4 Token Entropy Analysis\nTo further validate the effectiveness of our entropy-based approach in detecting glitch tokens, we conducted an entropy analysis comparing glitch tokens and normal tokens across different models."}, {"title": "Conclusion", "content": "In conclusion, we introduce GlitchMiner, a novel method for efficiently mining glitch tokens in large language models through gradient-based discrete optimization. By leveraging entropy as the loss function and integrating a local search strategy, GlitchMiner accurately identifies tokens that deviate from normal distributions without relying on manually defined priors. Extensive experimental results demonstrate that GlitchMiner outperforms existing state-of-the-art methods across various model architectures, showcasing higher precision and adaptability. Ablation studies further confirm the contributions of key components to the overall performance. The consistent results across different models emphasize the robustness and generalizability of GlitchMiner. Future work may explore applying this method to other high-dimensional tasks that require efficient discrete optimization."}]}