{"title": "GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models", "authors": ["Zike Yuan", "Ming Liu", "Hui Wang", "Bing Qin"], "abstract": "Evaluating the graph comprehension and reasoning abilities of Large Language Models (LLMs) is challenging and often incomplete. Existing benchmarks focus primarily on pure graph understanding, lacking a comprehensive evaluation across all graph types and detailed capability definitions. This paper presents GraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and reasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and test models on pure graph and heterogeneous graphs, subdividing capabilities into 10 distinct areas tested through 19 tasks. Our benchmark includes 11 datasets with 5,140 graphs of varying complexity. We evaluated three closed-source and seven open-source LLMs, conducting thorough analyses from both ability and task perspectives. Key findings reveal that semantic enrichment enhances reasoning performance, node ordering impacts task success, and the ability to process longer texts does not necessarily improve graph comprehension or reasoning. GraCoRe is open-sourced at https://github.com/ZIKEYUAN/GraCoRe.", "sections": [{"title": "1 Introduction", "content": "Graph understanding and complex reasoning are critical capabilities of Large Language Models (LLMs) due to their wide-ranging applications in fields such as social network analysis, drug discovery, recommendation systems, and spatiotemporal predictions. Thus, the ability to understand and reason about graph-structured data is particularly essential for advancing Artificial General Intelligence (AGI). Graph-structured data primarily includes homogeneous and heterogeneous graphs. Research on homogeneous graphs often focuses on graph-structure-specific issues, such as protein-protein interaction prediction. In contrast to homogeneous graphs, pure graphs are simpler and do not contain attribute information for nodes and edge, such as graph-theoretic problems. For heterogeneous graphs, tasks often rely on their rich semantic information, such as those related to knowledge graph reasoning. However, the use of LLMs for parsing, understanding, and reasoning about graph-structured data remains a challenging area of study. Firstly, the reasoning and comprehension capabilities of current large language models significantly deteriorate when handling complex graph-structured data with numerous nodes and edges. This degradation is partly due to the models' difficulty in processing long textual inputs, especially when graph-structured data is described through lengthy texts. Long texts not only increase the computational burden but also introduce noise and redundant information, further diminishing the models' ability to capture critical details. Secondly, textual descriptions of graph-structured data often involve complex entity relationships and abstract concepts, requiring models to both understand explicit information and infer implicit connections and relationships. Current research tends to rely on direct mappings from graph structure to answers, overlooking the potential to enhance the models' deeper reasoning capabilities. Given the lack of systematic definitions and evaluation standards for the capabilities of large language models in graph understanding and reasoning, it is imperative to design a benchmark that extensively tests these abilities based on the models' capabilities.\nIn previous research, several benchmarks have been proposed to evaluate the understanding and reasoning capabilities of LLMs on graphs. However, existing benchmarks for evaluating the graph understanding capabilities of LLMs exhibit several limitations. Firstly, there is the issue of limited generalization: current benchmarks predominantly test either pure graphs or heterogeneous graphs in isolation, failing to provide a unified and systematic evaluation across both graph structures. Additionally, there is a lack of clear definition regarding model capabilities: traditional benchmarks for LLMs on graphs are primarily task-driven, inadequately assessing the specific abilities of LLMs on graph data. Hence, there is a need to develop better benchmarks that evaluate LLMs' capabilities more comprehensively and from an ability-based perspective, specifically focusing on graph-structured data understanding and reasoning. Lastly, there is insufficient variety in model types and task categories: current benchmarks neither offer a clear classification of task types nor test a wide range of models.\nTo address these challenges, we propose the GraCoRe benchmark, as shown in Figure 1, which aims to explore and evaluate the understanding and reasoning capabilities of mainstream LLMs. We have designed a three-tier hierarchical ability taxonomy that includes both capability-based and dataset-based categories. This taxonomy meticulously defines the model's capabilities and ensures greater generalization in the testing range. Regarding model types and task divisions, our benchmark tests multiple existing closed-source and open-source models, and divides tasks into multiple dimensions based on model capabilities.\nFigure 2 illustrates the overall framework of our ability taxonomy. The first layer outlines two progressive overall capabilities: graph understanding and graph reasoning. Graph understanding is the most fundamental ability, reflecting the model's proficiency in comprehending the nodes, edges, and overall structure of the graph within the contextual data. Built upon this foundation, graph reasoning encompasses the model's ability to utilize graph-structured data to infer implicit information. The second layer categorizes the capabilities of LLMs into four types based on different data types. In the third layer, these four categories are further divided into 10 distinct capabilities, which are ultimately tested through 19 tasks. This taxonomy provides evaluation results across three levels, from general to detailed, allowing for the identification of deficiencies in models at varying levels of granularity. For each task, we meticulously design specific prompts and construct them based on predefined rules, ultimately textualizing the structural information. GraCoRe comprises a total of 11 datasets, consisting of 5,140 graphs. We control the complexity of these graphs by adjusting factors such as graph size and network sparsity.\nFinally, we conducted extensive experiments on GraCoRe to evaluate the graph understanding and reasoning abilities of large language models. We tested three closed-source LLMs and seven open-source LLMs. Our findings include the following:\n\u2022 We identified graph reasoning as a critical weakness in current LLMs. Most models cannot balance both graph understanding and reasoning, with GPT-4o being the most comprehensive model in both aspects.\n\u2022 LLMs perform better on graph reasoning tasks enriched with semantic information compared to tasks involving purely structural graph reasoning, indicating that textual information can enhance the graph reasoning abilities of LLMs.\n\u2022 Models exhibit high sensitivity to the ordering of nodes in textual graph data. An ordered naming of nodes can significantly improve model performance on graph tasks.\n\u2022 The capability of models to handle longer text inputs does not affect their performance in graph understanding and reasoning tasks, regardless of whether the graphs are complex with long textual descriptions or simple with short descriptions."}, {"title": "2 Related Work", "content": "LLMs for Graph Recent advancements in LLMs for graph tasks includes several notable contributions. (Li et al., 2023) categorizes these tasks into three types: Enhancer, Predictor, and Alignment. (Pan et al.) provides a forward-looking roadmap for the unification of LLMs and Knowledge Graphs (KGs). proposes an end-to-end method for solving graph-related problems. Furthermore, investigates methods to improve the zero-shot reasoning ability of LLMs over structured data in a unified manner. explores the graph generation capabilities of LLMs through systematic task designs and extensive experiments.\nBenchmarks for LLMs on Graph Most benchmarks for evaluating LLMs on graph tasks are based on task testing. introduced a simple test dataset for eight graph tasks, while GPT4Graph tested LLM capabilities on semantic tasks. assessed the capabilities of four LLMs in graph data analysis. proposed a method for describing graph data in text form. designed a hint method specifically for graph tasks. provided diverse processes and steps for graph data generation. proposed an evaluation method for heterogeneous graphs, and VisionGraph assessed the capabilities of LLMs on image graphs."}, {"title": "3 GraCoRe", "content": "This section begins by describing a three-tier hierarchical taxonomy for large language models (LLMs) on graph data. Next, we explain the methodology used to collect the dataset. Finally, we present an analysis of the dataset's statistics."}, {"title": "3.1 Hierarchical Ability Taxonomy", "content": "After analyzing evaluation of the LLMs in the multi-round dialogue task, we have developed a hierarchical taxonomy for classifying LLMs capabilities on graphs, essential for their evaluation. The taxonomy is structured into three levels, encompassing 19 tasks within 10 sub-capabilities. Table 1 summarizes each task with a brief description. This section elaborates on the three levels and their corresponding tasks, with detailed examples provided in the Appendix A."}, {"title": "3.1.1 Graph understanding", "content": "Understanding graph structure necessitates large language models capable of accurately answering questions about the graph's basic properties and reconstructing its structural information from extensive text descriptions. This involves two core capabilities:\nPure graph understanding: Pure graphs refer to graph data containing only structural information, representing the simplest form of graph data. The structural information of such graphs can be encapsulated in an adjacency matrix. Consequently, research on pure graphs often emphasizes the structural information. Assessing the ability of large language models to understand pure graphs should thus focus on their capacity to comprehend structural information. To this end, I have identified four sub-capabilities:\n\u2022 Pure Graph Attribute Understanding: The most intuitive measure of understanding graph structure information is the correct comprehension of its basic attributes, such as the number of nodes, average degree, and performance on several sub-tasks related to node connectivity.\n\u2022 Pure Graph Memory: This requires the large language model to reconstruct the input graph structure data, testing its memory capacity. This is specifically evaluated by the similarity score of the reconstructed matrix.\n\u2022 Pure Graph Recognition: For graph data with different structures, the model must be able to recognize and distinguish them. This study uses bipartite graphs and tree graphs to evaluate this capability.\n\u2022 Graph Traversal: Traversal is fundamental to solving many graph theory reasoning problems. The model's performance in reasoning tasks is influenced by its traversal capability. This study primarily tests whether the model can traverse a graph using Breadth-First Search (BFS)."}, {"title": "Heterogeneous graph understanding", "content": "Unlike pure graphs, heterogeneous graphs often contain rich semantic information, with much of the data collected from real-world scenarios. Consequently, understanding heterogeneous graphs typically involves grasping their semantic information, whereas understanding their structural information is less critical. We have refined this into two sub-capabilities:\n\u2022 Graph QA and Querying: Given the rich semantic information in heterogeneous graphs, the ability of large language models to perform question-answering and querying is crucial. This capability includes three sub-tasks: querying neighbor nodes, answering questions about node relationships, and querying the number of relationships.\n\u2022 Subgraph Extraction: This pertains to the overall understanding of relationships and nodes within heterogeneous graphs, assessing the model's ability to extract relevant subgraphs."}, {"title": "3.1.2 Graph reasoning", "content": "Based on the graph understanding capabilities of LLMs, their graph reasoning abilities are also worth exploring. This ability requires the model to infer hidden information from known graph data. It includes the following two core capabilities:\nGraph structure reasoning: Graph structural information reasoning requires large language models to understand the nodes, edges, and their connections to infer the overall structural characteristics of the graph or the structural patterns of specific subgraphs. For example, the model should be able to identify cycles, paths, tree structures, and hierarchical structures within the graph, and use these structural features for further reasoning. Tasks related to structural reasoning are primarily focused on graph theory problems. We classify the complexity of these problems into two categories: Simple Graph Theory Problems Reasoning and Complex Graph Theory Problems Reasoning. The classification criterion is the time complexity of the corresponding algorithms. Simple graph theory problems are solvable in polynomial time, while complex graph theory problems are NP-complete, requiring significantly more time to solve. This classification tests the model's capability in reasoning about graph theory problems. We have selected three representative problems for testing within each of these categories.\nGraph semantic reasoning: Unlike structure-based reasoning, semantic information reasoning in graphs requires large language models to deeply understand the semantic meanings of nodes and edges, and to reason based on this semantic information. This involves modeling and reasoning about entities, relationships, and their interactions within the graph. Based on these tasks, we subdivide the semantic reasoning capabilities of large language models into Node Entity Reasoning and Link Relationship Reasoning. Corresponding tasks include node classification and link prediction. Previous studies have primarily addressed these two problems using graph neural networks (GNNs) such as GCN and GraphSAGE. These methods typically require large structured graph data for training and cannot directly utilize graph data containing text information for inference. Consequently, investigating the use of large models for semantic reasoning is highly significant. This research will explore whether text enhancement impacts the performance of LLMs on these two tasks"}, {"title": "3.2 Data Collection", "content": "We first divide the dataset into pure graphs and heterogeneous graphs to test the capabilities of large language models on these two types of datasets. For pure graphs, we customize unique data generation prompts based on the specific characteristics of each task, generating corresponding graph structure data using manually set rules. The scale of the graph is defined by the number of nodes and the sparsity of the network, ensuring that the generated data meets the specific needs of each task. For heterogeneous graph data, we use the ACM and IMDB datasets, converting them into text-based graph data. These are constructed according to a manually specified graph structure description framework, and unique prompts are designed for each task to build the dataset.\nAfter generating the benchmark datasets, we also designed specific few-shot prompts for each task to test the model's capabilities. These prompt datasets will be included in the benchmark data to provide additional testing options. Finally, we will provide a standard answer for each task and filter out graph data that does not meet the corresponding task requirements."}, {"title": "3.3 Data Statistics", "content": "Table 2 shows several key statistics of our GraCoRe benchmark. We categorized the dataset based on graph structure into two main datasets: PureGra and HeterGra. Each main dataset contains multiple sub-datasets used for corresponding task testing. In total, there are 19 tasks with up to 5,140 graphs. Detailed statistics for each task can be found in the Appendix A.\nFor pure graph data, the datasets include graphs with 8 to 30 nodes, with 20 test graphs per dataset. This design is intended to assess the impact of graph complexity on the performance of large language models. For heterogeneous graph data, we divided them into IMDBText and ACMText datasets. The ACMText dataset is more complex and extensive, containing more semantic information than the IMDBText dataset. Therefore, the ACMText dataset is primarily used for complex reasoning tasks, including node classification and edge prediction.\nGraCoRe is the first benchmark specifically focused on the fine-grained understanding and reasoning capabilities of large language models on graph data."}, {"title": "3.4 Evaluation", "content": "This thesis evaluates the output of large language models (LLMs) using exact match accuracy. We focus on various output types, including boolean values (e.g., graph recognition tasks), integers (e.g., path lengths), floating-point numbers (e.g., similarity and average degree), and lists of nodes (e.g., paths). For tasks with multiple possible solutions (e.g., BFS), we verify whether the output constitutes a valid answer.\nSince the metrics of different GraCoRe tasks are incomparable and differently sensitive, less experienced audiences cannot easily compare and interpret results, which is also prevalent in recent LLM benchmarks like Kola. Therefore, we utilized standardized global scores to evaluate the performance of LLMs on each task.\nGiven a task set $T = \\{t_i\\}_{i=1}^{M_T}$ and an evaluated model set $M = \\{m_j\\}_{j=1}^{M_M}$, so $x_{ij}$ represents the performance of model $m_j$ on task $t_i$. Then the standardized score z can be calculated as:\n$z_{ij} = \\frac{x_{ij} - \\mu (x_{i1}, ..., x_{i|M|})}{\\sigma (x_{i1},..., x_{i|M|})}$,\nwhere $\\mu(\\cdot)$ and $\\sigma(\\cdot)$ denote the mean and standard deviation.Next, we use the Min-Max scaling method to adjust the scores to the range of 0-100, making it easier to observe and compare the results. The final scores are presented as:\n$s_{ij} = 100 \\cdot \\frac{z_{ij} - min(z)}{max(z) - min(z)}$,\nwhere the functions max (z) and min (z) correspond to the maximum and minimum of all $z_{ij}$ scores."}, {"title": "4 Experiments", "content": "Based on the GraCoRe benchmark, we aim to investigate whether language models can understand and reason about graph structures through textual descriptions of graph data. Additionally, we explore whether designed prompts can enhance the models' performance on graph-related tasks.\nModels and Settings We evaluated a total of eight popular models on the GraCoRe benchmark, including three closed-source models and five open-source models. The closed-source models are: GPT-4o, GPT-4, and GPT-3.5. The open-source models are: LLama3-ins-8b, LLama2-7b-chat, Chatglm3-6b, Chatglm2-32k-7b, Vicuna-v1.5-7b, Vicuna-v1.5-16k-7b and Qwen2-7b-ins. More details about these models can be found in the appendix."}, {"title": "4.2 Main Results", "content": "Task Dimensional Analysis Table 3 and Table 4 shows the performance of various large language models across 19 different tasks in our GraCoRe benchmark. Among all tasks, graph understanding tasks are generally less challenging for the models, while graph reasoning tasks are more difficult. This conclusion is reflected in the performance of each model. Additionally, closed-source models, such as those developed by OpenAI, consistently demonstrated superior performance. The GPT-4o model achieved the highest total score of 1419, ranking first. Among open-source models, Llama3-8b and Qwen2-7b-ins also performed exceptionally well, scoring 1054 and 1053 respectively, ranking fourth and fifth, just behind the OpenAI models. In contrast, Chatglm2-7b model performance was less satisfactory compared to other open-source models. Regarding task types, performance on reasoning tasks was not ideal, but this outcome was expected.\nAdditionally, the average z-scores indicate a significant gap between open-source models and commercial closed-source models. Only the Llama3-8b and Qwen2-7b-ins models have z-scores greater than 0, indicating performance above the average level. This suggests that the open-source community needs more collaboration to support and improve the latest open-source large language models. It is noteworthy that these two open-source models have graph understanding and reasoning capabilities approaching those of the GPT-3.5 model.\nAbility Dimensional Analysis We further analyze Table 3 and Table 4 to evaluate the overall performance of the models from a capability perspective. We use radar charts to present the second and third layers of the three-tier taxonomy in a more intuitive manner. Left part of Figure 3 shows the performance of LLMs across four different capability dimensions at the second layer, where each dimension's score is the average of its respective tasks. It can be observed that most models perform well in graph understanding and semantic reasoning but need improvement in structural reasoning tasks. For most open-source models, performance in heterogeneous graph understanding tasks is not very satisfactory.\nRight part of Figure 3 provides a more granular view of LLMs' performance across ten capability dimensions at the third layer. It is evident that the reasoning abilities of large language models in graph theory problems are not very strong, particularly in complex graph theory tasks. Furthermore, GPT-4 and GPT-4o exhibit robust and balanced graph processing capabilities, especially excelling in complex tasks. In contrast, other models show less balanced performance in graph processing. For instance, the Vicuna-v1.5-16k-7b model excels in understanding heterogeneous graph structures but performs poorly in other areas, suggesting that the rich semantic information may enhance the model's graph processing capabilities.\nLong-Text-Specific Models Since graph structure data described in text often consists of long texts, the ability of models to handle long texts is also worth noting. As shown in Table 3, models capable of processing long texts, such as Chatglm2-32k-7b and Vicuna-v1.5-16k-7b, performed poorly in graph processing tasks. Compared to other models, their performance was even lower. This suggests that despite being designed for long text input and output, these models still require further development and training to effectively enhance their graph processing capabilities."}, {"title": "4.3 Further Analysis", "content": "Effect of Graph Size Figure 4 illustrates the performance of the model across four tasks as the number of nodes increases. Specifically, we used two graph understanding tasks and two graph reasoning tasks to evaluate the model's performance. The results indicate that as the number of nodes increases, the performance on each task decreases. In the graph understanding tasks, the impact is particularly significant on the average degree task. We hypothesize that the increase in nodes leads to a substantial rise in computational demands, resulting in decreased accuracy. In the graph reasoning tasks, we observed that for the shortest path problem, the performance of GPT-3.5 diminishes with an increasing number of nodes. However, for the other three open-source models, the node size appears to have minimal impact. This may be because the added nodes do not affect the search for the original path, though further experiments are needed to confirm this hypothesis.\nEffect of Random Sort Since our data consists of randomly generated graphs with nodes named by numbers, the performance of node-related tasks may be affected by changes in node order. In this study, we examine the impact of text order on the understanding of graph structures by large language models by comparing random sorting with sequential sorting. The results in Table 5 indicate that the model's performance under sequential sorting is often superior to that under random sorting, particularly in graph path reasoning tasks, where the impact is significant. This suggests that renaming nodes and ordering them sequentially can enhance model performance in path reasoning problems. However, it also highlights the model's lack of training on graph data with random sorting.\nEffect of Text Enhancement Heterogeneous graphs often contain rich semantic information, which typically aids models in understanding and reasoning about graph text information. If enhanced text information, such as paper titles and abstracts in the ACMText data is removed, can large language models perform reasoning based solely on the remaining structural information? Figure 5 compares the performance of different large language models on the node classification problem. The results indicate that large language models can reason about graphs without enhanced text information, particularly the GPT-4 and GPT-4o models, which maintain strong node prediction capabilities even without text information. However, for the GPT-3.5 model, the absence of text information significantly impacts performance. For other open-source models, the presence or absence of text information appears to have minimal impact."}, {"title": "5 Conclusion", "content": "This paper introduces GraCoRe, a benchmark designed to evaluate the capability of large language models (LLMs) in understanding and reasoning with graph-structured data. We develop a detailed, multi-level classification system to assess model performance on graph-based tasks. Utilizing GraCoRe, we evaluate 10 prominent LLMs, revealing significant deficiencies in their graph reasoning abilities. Extensive experimental results demonstrate the effectiveness of our benchmark in measuring the performance of LLMs on graph tasks."}, {"title": "6 Limitations", "content": "As LLMs continue to develop, the volume of training data and their capacity to represent graphs are likely to increase. Our current evaluation may not encompass all their capabilities, and some models might incorporate our data for training, potentially influencing the final evaluation outcomes. In the future, we aim to continually refine and update the GraCoRe benchmark to more effectively assess the graph understanding and reasoning abilities of emerging LLMs."}]}