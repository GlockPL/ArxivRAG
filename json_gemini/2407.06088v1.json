{"title": "Qualitative Event Perception: Leveraging Spatiotemporal Episodic Memory for Learning Combat in a Strategy Game", "authors": ["Will Hancock", "Kenneth D. Forbus"], "abstract": "Event perception refers to people's ability to carve up continuous experience into meaningful discrete events. We speak of finishing our morning coffee, mowing the lawn, leaving work, etc. as singular occurrences that are localized in time and space. In this work, we analyze how spatiotemporal representations can be used to automatically segment continuous experience into structured episodes, and how these descriptions can be used for analogical learning. These representations are based on Hayes' notion of histories and build upon existing work on qualitative episodic memory. Our agent automatically generates event descriptions of military battles in a strategy game and improves its gameplay by learning from this experience. Episodes are segmented based on changing properties in the world and we show evidence that they facilitate learning because they capture event descriptions at a useful spatiotemporal grain size. This is evaluated through our agent's performance in the game. We also show empirical evidence that the perception of spatial extent of episodes affects both their temporal duration as well as the number of overall cases generated.", "sections": [{"title": "1. Introduction", "content": "People carve up the continuous world into discrete events. We talk about drinking a cup of coffee in the morning, emptying the trash, filling the dishwasher, etc. These events are localized, i.e. spatially bounded and temporally extended. In psychology research, the ongoing segmentation of continuous experience is known as event perception (Zacks, 2020).\nIn qualitative reasoning research, Hayes proposed the notion of histories (Hayes, 1989;1978) as a general framework for representing change in continuous domains. Whereas the situation calculus describes changes in terms of discrete events and provides no spatial constraints (leading to the infamous Frame Problem), histories represent change in terms of pieces of space-time, based on the objects involved in the changes.\nIn this paper, we show how history-based representations can be used to automatically carve up continuous experience into discrete episodes. We investigate the relationship between representational choices and temporal segmentation, and then show how this affects an agent's ability to learn from past experience. Our task is analogically learning qualitative states of defense for cities in the strategy game Freeciv\u00b9 , where our agent records traces of military battles and makes"}, {"title": "2. Background & Motivation", "content": "Our qualitative representation (QSTEM) is based on Hayes' notion of histories, i.e. bounded pieces of spacetime. Histories were developed around intuitive models of human thinking about space and time. They emerged in part as an ontological solution to difficulties in representing continuous entities. A canonical example involves liquids; pieces of lakes are not readily individuated, so it is more natural to reify them based on spatial location. Histories have been used extensively in qualitative reasoning research (Forbus, 2019) and so we hypothesize that they will be useful for learning with episodic memory.\nOne component of QSTEM is a qualitative representation of change. These descriptions reify changing attributes of spatially extended entities as qualitative temporal intervals. For example, we can describe the period of decreasing height of a falling object, of the buildup of troops in preparation for a siege, of the increase of a player's gold, etc.\nHere we aim to show how history-based representations can be used for event segmentation, and how the resulting episodes can be used for learning. The automatic spatial and temporal adaptation based on the entities that make up the descriptions means that these descriptions rely on general purpose encoding schemes, allowing the agent to adapt to new situations more easily."}, {"title": "2.1 Qualitative Spatiotemporal Episode Memory", "content": "Our qualitative representation (QSTEM) is based on Hayes' notion of histories, i.e. bounded pieces of spacetime. Histories were developed around intuitive models of human thinking about space and time. They emerged in part as an ontological solution to difficulties in representing continuous entities. A canonical example involves liquids; pieces of lakes are not readily individuated, so it is more natural to reify them based on spatial location. Histories have been used extensively in qualitative reasoning research (Forbus, 2019) and so we hypothesize that they will be useful for learning with episodic memory.\nOne component of QSTEM is a qualitative representation of change. These descriptions reify changing attributes of spatially extended entities as qualitative temporal intervals. For example, we can describe the period of decreasing height of a falling object, of the buildup of troops in preparation for a siege, of the increase of a player's gold, etc.\nHere we aim to show how history-based representations can be used for event segmentation, and how the resulting episodes can be used for learning. The automatic spatial and temporal adaptation based on the entities that make up the descriptions means that these descriptions rely on general purpose encoding schemes, allowing the agent to adapt to new situations more easily."}, {"title": "2.2 Analogical Learning", "content": "One goal of this research is to demonstrate how analogy can support spatiotemporal learning. To do this, we use the Structure Mapping Engine (SME) (Forbus et al. 2017) for comparison, the MAC/FAC retrieval system (Forbus et al., 1995), and the SAGE generalization system (McLure et al. 2015). These analogical mechanisms are tightly integrated in the underlying reasoning engine and provide the mechanisms for retrieval, comparison, and transfer. There is a growing body of evidence that human cognition and therefore commonsense reasoning depends on structured representations of the world. The perceptual world around us is highly structured, both temporally and spatially, and so we think that analogical processes play an important role in learning."}, {"title": "2.2.1 SME", "content": "The Structure Mapping Engine (SME) (Forbus et al., 2017) is a computational model of matching in Structure Mapping Theory (Gentner, 1983). SME provides a mechanism for determining similarity between two structured descriptions. It does this by generating a set of mappings between a base and target. A mapping aligns entities and expressions between the descriptions. A structural similarity score is computed for each mapping that prefers higher-order structure and entities that participate in systems of relations. SME additionally computes a set of candidate inferences, or surmises about the target made on the basis of common structure plus the base representation."}, {"title": "2.2.2 MAC/FAC", "content": "Analogical retrieval is performed by MAC/FAC (Forbus et al., 1995), which stands for \u201cMany are Called, Few are Chosen\u201d because it uses two stages of map/reduce for scalability. The inputs consist of a probe case and a case library. The MAC stage, in parallel, computes dot products over vectors that are automatically constructed from structured descriptions, such that each predicate, attribute, and logical function are dimensions in the vector and whose magnitude in each dimension reflects their relative prevalence in the original structured description. The best mapping, and up to two others, are passed to the FAC stage. FAC compares the best structured descriptions from the MAC stage to the input probe using SME. The best match plus up to two others, is then returned. The inexpensive nature of the MAC stage allows for scalability, while the FAC stage allows for sensitivity to structural similarity."}, {"title": "2.2.3 SAGE", "content": "SAGE, or the Sequential Analogical Generalization Engine (McLure et al., 2015) is an analogical generalizer. It utilizes MAC/FAC for retrieval, and therefore SME at its core. SAGE operates over generalization pools (aka gpools), each of which represents a concept. Each gpool consists of a set of generalizations and outlier examples. Given a new example and a gpool, MAC/FAC first finds the most similar generalization or outlier to the example. This retrieval results in a SME mapping, which aids in assimilation. Examples are only merged if their similarity score exceeds an assimilation threshold. Generalizations accumulate statistics over expressions and filter out low frequency expressions based on a probability cutoff. Unlike many ML algorithms, SAGE is an incremental learner, which eliminates the need for retraining a model. It is similar to k-means with outliers, but unlike k-means uses a human-normed similarity metric operating on structured representations. In addition, the number of generalizations falls out automatically (i.e. it does not need to be prespecified), allowing the flexible learning of disjunctive concepts. As part of the"}, {"title": "2.3 Freeciv", "content": "Freeciv is a complex turn-based strategy game based on the Civilization franchise. It involves playing as an emerging nation, vying against potentially hostile nations to either conquer the world or build a spaceship and found a new colony in space. Successfully achieving either outcome requires a player to manage their scientific progress, military, and economic growth all while conducting diplomatic relations.\nFreeciv is an excellent domain for AI research due to its complexity. A typical game board consists of 4,000 tiles with varying terrain. Games typically last for hundreds of turns, and each turn involves many decisions. Some decisions are global across the entire civilization, such as setting the tax rate, determining the next technology to research, and engaging in diplomacy. Workers must be kept busy modifying terrain. Military units must defend cities and conduct attacks on opponents when at war. By contrast, Go is played on a 19x19 grid with uniform, immutable spatial properties which are always visible from the start. In addition, each turn in Go only involves a decision to place one piece.\nFreeciv is especially useful for exploring histories because important behaviors happen at multiple grain sizes. Combat often evolves as the game progresses, where early engagements are typically quick and involve fewer participants, and later battles (and sieges) are more drawn out and involve more unit types. Describing military battles using histories should benefit learning because case descriptions adapt automatically based on entities that participate in the event."}, {"title": "3. Learning from Battles in Freeciv", "content": "We begin by motivating the relationship between event perception, i.e. determining the spatiotemporal bounds of an event, and learning from the resulting descriptions. Consider the scenario in Figure 1, where a group of opposing units are attacking a city. The hypothesis is that without histories, learning will be harder because localized events like battles cannot be adequately characterized. Specifically, spatial extension of an event directly affects temporal segmentation and thus event individuation. In Figure 1, assume that the archers (attacker1) nearest to the city (Praha)\nattack the city, that there is at least one defender inside Praha, and the archers (attacker1) lose the attack and are removed from the game. In Figure 2, this scenario is illustrated without extended spatial representations.\nWe can define quantity conditioned events (e.g. battles) in terms of perceptual entities (the event participants). That is, a battle is over when one side has been eliminated (its cardinality is zero). This definition then provides a notion of persistence for the event, i.e. the temporal extension lasts as long as two local opposing forces exist within some spatial context. Note the dependence on locality. For this work, we compare a baseline experimental condition that does not use extended spatial representations against the histories condition that does. For the baseline condition, the venue for the battle is represented by two locations (space in Freeciv is represented tiles), the coordinates of the attacker and defender. In Freeciv, the attack action primitive takes the form (doAttack ?attacker ?defender) where both <attacker> and <?defender> are singular entities.\nFor Figure 1, these locations are the coordinates of attacker1 and the city Praha. After the attack, since the city is the only remaining entity at either location, the battle is over for the baseline condition. On the other hand, Figure 3 depicts the same situation given extended spatial representations. Here, the battle persists after attacker1 has been removed. To determine this, a"}, {"title": "3.1.1 Case Construction", "content": "Case construction for this experiment generates a structured description of military battles. Generated cases are based on QSTEM, with two additions. First, QSTEM segmented time solely on the basis of qualitative representations of change, i.e. intrinsic properties of quantities, whereas in this work, episodes can be defined as events which can have more complex start and end conditions, e.g. battles. Second, this work reifies and learns statistics over quantities that are included in cases, and later we describe how these statistics are used for decision making.\nWe begin by describing how we define military battles, which are constructed from the viewpoint of a player's cities. Battles start when an enemy attacks a city, and end when either the city has been conquered or there are no more local enemy units. Figure 3 shows a battle with enemy units (e.g. attacker2) and a defending city region, which are all compound spatial entities. We call these entities footprints (Hancock et al., 2020), which are spatial regions that are constructed out of more primitive regions. For this work, we use three kinds of footprints:\n1. City footprints: Defined by the twenty-one tiles in a city's region\n2. Unit footprints: The region bounded by a unit's max movement in one turn\n3. Unit group footprints: The region defined by a set of spatially local unit footprints\nAll footprints are constructed by computing the convex hull over constituent entities. During an ongoing battle, participants consist of the defending city footprint and any spatially local (i.e. rcc2- connected) unit group footprint."}, {"title": "3.1.2 Persistence for Compound Entities", "content": "Footprints are reified so that their attributes can be described. For military battles, one might describe the size of opposing forces (i.e. an aggregate quantity over relevant constituent units). We could also describe these quantities in terms of change, i.e. the size is increasing or decreasing. Hancock and Forbus (2021) showed that using qualitative descriptions of change helps an agent learn production decisions in Freeciv from a human. To reify these kinds of descriptions of change, we must first specify how compound entities persist. In other words, what makes an entity the same from one time to another if it has lost or gained (possibly both) some of its parts? For this work, persistence is determined by set intersection of constituent entities of a footprint. This depends on being able to individuate those entities (i.e. they can be named)\u00b2. \nFigure 4 shows an example of persistence for two cases: a simple and complex case. In the simple case, the compound entity CE1 remains the same from t\u2099 to t\u2099\u208a\u2081 whereas in the complex case, the entity gains and loses parts. We still have not described how persistence is determined, e.g. in the complex case, CE2 at t\u2099 could persist as either of the two entities at t\u2099\u208a\u2081. For this work, we use a simple heuristic which states that the entity persists as the largest entity. Given this definition, we can now describe how compound entities change over time, e.g. CE2 remains the same size. In the next section, we describe how properties are recorded for entities over time, resulting in a series of fluents. These fluents are then used to construct qualitative descriptions of change."}, {"title": "3.1.3 Recording Fluents", "content": "Knowledge about entities and their changing attributes is recorded at each timestep. In this work, time is indexed by significant events that occur in the game. Examples are the start of a new Freeciv turn, when entities are created and destroyed, when units move, when resources are produced, etc. We declaratively define a set of quantities that are recorded. Figure 5 shows one definition for the number of enemy units local to a player's city. Each definition is a triple, where the second argument names the quantity and the third argument specifies the intension of the set, i.e. the set of entities that the quantity should be recorded for. This work uses the same quantities defined in (Hancock and Forbus, 2020) as well as Figure 5, which is new. These definitions are used to record a set of fluents at each timestep. For each quantity type, first, the set extension is determined. From Figure 5, the form (GenericInstanceFn ... ) is queried in the current Freeciv context to return a set of relevant entities, e.g. (FC-City-Chicago FC-City-Boston). For each of these entities, an additional query is generated using the defined quantity type. This would be (((MeasurableQuantityFn enemyUnitCardinality) FC-City-Chicago), ...). These forms are again queried against the current scenario context and call outsourced predicates that return the current"}, {"title": "3.1.4 Learning a Model", "content": "After each battle has ended, a case is constructed and added to a success or failure gpool, depending on the outcome. Learning is incremental, with cases being generalized in the order that they are experienced. The general process for learning a SAGE model proceeds as follows. Assume that an agent experiences a series of failures. For the first battle event, the case is added to the failure gpool as an outlier. For the next example, the case is compared against the existing outlier. If it is sufficiently similar to the first case (as determined by SME's similarity score being above the SAGE assimilation threshold), then the two cases are merged into a single generalization. Otherwise, the second case is also added as an outlier. Learning continues in this matter as each new case is generalized into the model. Each cluster of cases (generalizations) can be seen as a learned schema for some disjunctive conceptualization of the overall model. For the battle failure gpool, these clusters describe different states where battles have been lost, e.g. these might describe a city in the desert with no city walls and three defenders, and a city on a hill with no defenders.\nAs part of this learning process, statistics are accumulated for quantities that appear in the structured case descriptions. Recall that these quantities take the form (holdsIn  (valueOf  )). Here,  is a typed numerical statement, e.g. (FreecivUnitCountFn 3). SAGE automatically accumulates statistical knowledge for typed quantities that appear in structured descriptions. This process proceeds as follows. Assume that a new case describing a battle has been constructed, and that this case is being assimilated into a SAGE generalization. Figure 7 shows an example mapping, i.e. corresponding statements, from the case to the Gpool generalization. As part of this generalization process, mapped terms are replaced by logical functions called generalized entities that denote the lifted type for ground entities (GenEntFn ), here abbreviated as GEFn. These reified entities are associated with a history of their"}, {"title": "3.1.5 Decision Making", "content": "Decision making is driven by analogical comparison of the agent's current situation to past failures. The idea is to determine if the current spatiotemporal context for a city is similar to one in which a city lost the battle. If this is the case, then a decision is made to improve the city's military system. The agent divides games into phases based on qualitative properties. It starts out in a growth phase, where the number of cities is monotonically nondecreasing. The conquest phase starts when the number of invaders becomes greater than zero. Decision making for this experiment starts in the conquest phase, which allows time to grow one's empire before focusing on defense."}, {"title": "4. Experiment", "content": "In this experiment, the two conditions are baseline and histories. For the baseline condition, the agent learns from combat experience without histories, i.e. it does not leverage extended representations of space, which constrains how the resulting events persist. The histories condition leverages extended spatial representations (i.e. regions). Our main hypothesis is that gameplay performance will improve more for the histories condition because histories should be useful for event perception, i.e. they help scope events. We show this in two ways. The first is by comparing the agent's performance in the two conditions. Second, we examine the relationship between episodic learning and history-based representations by analyzing the episodes generated by each condition. We evaluate our agent's performance in the game using two metrics: overall civilization size measured by the number of cities, and the amount of gold in the treasury. Determining success in Freeciv is complicated; there are many factors that indicate success in the game. In general, a"}, {"title": "5. Related Work", "content": "Wintermute et al. (2007) used the SOAR cognitive architecture (Laird 2019) to develop a model (SORTS) that performed various tasks within a real-time strategy game engine. SORTS also leveraged perceptual spatial representations to guide decision making but focused on models of attention rather than episodic representation. Jones and Laird (2019) laid out a general framework for event cognition within the Common Model of Cognition, which is a theoretical proposal of the computational processes underlying cognition (Laird, Lebiere, and Rosenbloom 2017). This framework focused on architectural specifications within cognitive architectures, and not the specifics of event representation. Jones (2022) provides a comprehensive implementation of these ideas in the SOAR cognitive architecture but did not leverage extended spatiotemporal representations."}, {"title": "6. Discussion and Future Work", "content": "We have described an experiment in which our agent learns qualitative states of defense in a strategy game from recording spatiotemporal traces of military battles. Empirical evidence from this experiment shows how perception of space affects event individuation and temporal segmentation. We show that history-based representations improve learning because they segment episodes based on change in the environment, and capture knowledge at a useful spatiotemporal grain size.\nThe event representations developed in this work can be construed as a framework for grounding quantity-conditioned processes in perceptual phenomena. In general, the spatial perception of these events affects how they persist, and therefore their duration. This applies to many kinds of events that we encounter in our everyday lives, e.g. finishing my morning cup of coffee, of class being over, etc. Often the relevant spatial bounds can be defined by containers, i.e. mugs and classrooms. In these cases, incorrect perception of the container leads to degenerate conclusions. If instead one considers the coffee shop as the container, then it is likely that a whole day goes by without finishing a cup of coffee. Here, the quantity condition (no more liquid coffee) is not met, because there is likely always coffee somewhere in the cafe. Containers are not always so readily available, however, as in the instance of representation the spatial extent of military battles. In fact, Hayes, thought that there were likely many kinds of histories that aligned with out commonsense notions of the world (Hayes, 1995). For the same reason that unbounded representations of change are likely inadequate for certain kinds of phenomenon (hence the ontology for liquids), histories are useful for event perception for continuous entities. Spilled milk, oil spills, spreading butter, and swarms are all phenomena for which the kinds of representations used in the work might help with episodic learning."}]}