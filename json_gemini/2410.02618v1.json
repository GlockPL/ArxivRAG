{"title": "Achieving Fairness in Predictive Process Analytics via Adversarial Learning", "authors": ["Massimiliano de Leoni", "Alessandro Padella"], "abstract": "Predictive business process analytics has become important for organizations, offering real-time operational support for their processes. However, these algorithms often perform unfair predictions because they are based on biased variables (e.g., gender or nationality), namely variables embodying discrimination. This paper addresses the challenge of integrating a debiasing phase into predictive business process analytics to ensure that predictions are not influenced by biased variables. Our framework leverages on adversial debiasing is evaluated on four case studies, showing a significant reduction in the contribution of biased variables to the predicted value. The proposed technique is also compared with the state of the art in fairness in process mining, illustrating that our framework allows for a more enhanced level of fairness, while retaining a better prediction quality.", "sections": [{"title": "1 Introduction", "content": "Predictive process analytics aims to forecast the outcome of running process instances to identify those requiring specific attention, such as instances risking delays, excessive costs, or unsatisfactory outcomes. By proactively predicting process behavior and outcomes, predictive process analytics enables timely intervention and informed decision-making. Over the years, numerous approaches have been proposed in the literature to address the challenges associated with predictive process analytics (cf. Section 2). Predictive process analytics naturally needs to rely onto the characteristics of the process being monitored, and performs predictions on their basis. Being that said, this analytics become a problem when predictions are unfair because they are based on characteristics that discriminate in a form that is unacceptable from a legal and/or ethical point of view. For instance, in a loan-application process at a financial institute, one cannot build on the applicant's gender to predict the outcome, namely whether or not the loan is granted. Pohl et al. indicate monitoring, detecting and rectifying biased patterns to be the most significant challenge in Discrimination-Aware Process Mining [15]. Process characteristics are hereafter modelled as process variables. In accordance with the literature terminology [19], we use the term protected variable to indicate the variables on which prediction cannot be based. The choice of the set of variables to"}, {"title": "2 Related Works", "content": "The existing literature related to debiasing in process mining is relatively limited: Mannhardt in [10] offers a comprehensive examination of Responsible Process Mining, where algorithmic fairness is identified as one of the four topics in which Responsible process mining is divided. As mentioned in Section 1, Qafari et al. in [16] is the only framework for fairness in process mining prescriptive analytics. The proposed approach operates through a process of identifying and rectifying mislabeled instances within the train-"}, {"title": "3 Preliminaries", "content": "The starting point for a prediction system is an event log. An event log is a multiset of traces. Each trace describes the life-cycle of a particular process instance (i.e., a case) in terms of the activities executed and the process attributes that are manipulated.\nDefinition 1 (Events). Let A be the set of process activities and let V be the set of process attributes. Let $W_V$ be a function that assigns a domain $W_V(x)$ to each process attribute $x \\in V$. Let $W = \\bigcup_{x \\in V}W_V(x)$. An event is a pair $(a,v) \\in A \\times (V \\cup W)$ where a is the event activity and v is a partial function assigning values to process attributes with $v(x) \\in W_V(x)$.\nNote that the same event can potentially occur in different traces, namely attributes are given the same assignment in different traces. This means that potentially the entire same trace can appear multiple times. This motivates why an event log is to be defined as a multiset of traces.\nDefinition 2 (Traces & Event Logs). Let E be the universe of events. A trace $\\sigma$ is a sequence of events, i.e. $\\sigma \\in E^*$. An event-log L is a multiset of traces, i.e. $L \\in \\mathfrak{B}(E^*)^1$.\nGiven a set A, $\\mathfrak{B}(A)$ indicates the set of all multisets with the elements in A."}, {"title": "3.1 Predictive Process Analytics via Fully Connected Neural Networks", "content": "The training of FCNN models falls into the problem of supervised learning, which aims to estimate a Machine-Learning (ML) function $\\Phi : X_1 \\times ... \\times X_n \\rightarrow Y$ where y is the domain of variable to predict (a.k.a. dependent variable), and $X_1 ... X_n$ are the domains of some independent variables $V_1, ..., V_n$, respectively.\nTo tackle the prediction problem for an outcome function $K : E^* \\rightarrow O, Y = O$. The values of the independent variables are obtained from the event-log traces: each trace is encoded into a vector element of $X_1 \\times ... \\times X_n$, through a trace-to-instance encoding function $\\rho_C : E^* \\rightarrow X_1 \\times ... \\times X_n$. Note that the process prediction oracle is thus implemented as $\\Psi_K(\\sigma) = \\Phi(\\rho_C(\\sigma))$.\nSeveral alternatives exist to define encoding function $\\rho_C$ [2]: here, we use the most widespread (cf. survey by M\u00e1rquest-Chamorro et al. [12]). The encoded vectors are in the domain $X_{v1} \\times ... \\times X_{vm} \\times ... \\times X_{a1} \\times ... \\times X_{ap}$ such that there is a variable $X_{vi}$"}, {"title": "3.2 Assessment of the Variable Influence on Predictions", "content": "The evaluation leverages on computing the influence of each variable $V_1, ..., V_n$ on the predictions returned by the ML function $\\Phi : X_1 \\times ... \\times X_n \\rightarrow Y$ where $X_1,..., X_n$ are again the domains of the variables $V_1,..., V_n$, respectively. In particular, we will assess the influence of the protected variables on the predictions and show how this is reduced after employing our debiasing technique.\nFor evaluating the influence of a variable, we use the widely adopted technique of Shapley Values [9,13]. Shapley values are computed for each variable for each instance separately. Let $(x_1,..., x_n)$ be an instance defined over variables $V_1,..., V_n$, which is predicted to return $y = \\Phi((x_1,...,x_n))$. The Shapley value of any variable $V_i$ is the contribution of $V_i = x_i$ to the prediction, where the contribution measures how much $V_i = x_i$ makes prediction y deviate from the mean prediction value. It follows that larger deviations imply higher influence on the prediction.\nConsider the example presented in Figure 1, focusing on the prediction of the probability of \"Open Loan\" occurrence within a loan application process. Initially set at 0.8,"}, {"title": "4 An Adversarial Debiasing Framework for Predictive Process Analytics", "content": "The overall objective of this paper is to build a process prediction function $\\Psi$ whose output values are not influenced by the chosen protected variables.\nThe determination of the protected variable depends on the the specific case study under consideration (e.g., the gender or nationality of a loan applicant). It is crucial to note that certain variables may be designated as protected in one case study but not in another. For instance, the variable \"Gender\" might be designated as a protected variable in the context of a loan application process, but it may not hold the same status in the process of hospital discharge. By carefully selecting the protected variables, we aim to ensure that the predictions do not enforce a discrimination that is not ethically and/or morally acceptable.\nThe framework is visually depicted in Figure 2 where the core component is the prediction model that implements the oracle function $\\Psi$, capable to of forecasting the outcome of a running trace. Leveraging on neural networks, $\\Psi_K$ is obtained through the composition of the trace-to-instance encoding function $\\rho_L$ and an ML function $\\Phi: X_1 \\times ... \\times X_n \\rightarrow O$, namely for any trace $\\sigma \\Psi_K(\\sigma) = \\Phi(\\rho_L(\\sigma))$. The most left gray box in Figure 2 is the encoder $\\rho_L$, which converts the trace into a vector. The second gray box from left depicts the FCNN that implements $\\Phi$, along with the decoder represented through the red dot.\nLooking from the right in Figure 2, the first gray box depicts the adversarial FCNN, which tackle the debiasing problem to ensure fairness. In particular, let $\\mathbb{V} = {V_1, ..., V_p} \\subseteq {V_1,..., V_n}$ be the set of the protected variables, which are defined over the do-mains $\\mathbb{Z} = X_1, ..., X_p$, respectively. Let $N_1, ..., N_q$ are the domains of the output of the q nodes that constitute the last layer of the FCNN implementing $\\Phi$. The adversarial FCNN implements a function $\\Phi_Z: N_1 \\times ... \\times N_q \\rightarrow \\mathbb{Z}$, which aims to predict the values of the protected variables, using the output of the last layer as input.\nIn accordance with the literature on adversarial debiasing [19], if the neural net-work that implements $\\Phi$ - in our case a FCNN - does not build the prediction on the protected variables, then the adversarial network that implements $\\Phi_Z$ - in our case an-other FCNN - is unable to predict the protected-variables values from the output of the network implementing $\\Phi$."}, {"title": "5 Evaluation", "content": "The evaluation focuses on evaluating how our framework mitigates the influence of protected variables while still ensuring a good quality.\nThe framework evaluation was carrying out, as previously mentioned, by training two FCNNs that implement functions $\\Phi$ and $\\Phi_Z$. In particular, we carried out a grid search to tune the hyper-parameters related to the learning rate, layers shape, epochs, and weight decay, so as to prevent over- and under-fitting problems.\nOur debiasing framework was evaluated on four case studies, aiming to assess (i) the mitigated influence of the protected variables on the prediction, and (ii) the extent of the reduction of the prediction accuracy when our framework was employed. Note that a reduction in accuracy is expected when addressing the fairness problem: if the protected variables have some good predictive power, their exclusion has a natural neg-ative impact on the ML-model accuracy. The baseline of comparison is with the only existing framework by Qafari et al. [16].\nThe remainder of this section is organized as follows. Section 5.1 introduces the case studies and the train-test splitting of event logs, while Section 5.2 discusses the choice of the protected variables. Section 5.3 reports on the metrics used for the evaluation, while Section 5.4 details and analyses the results. In Section 5.5, training times and accuracies for both LSTM and FCNN models are presented, motivating the FCNN choice."}, {"title": "5.1 Introduction to Use Cases and Event-log Datasets", "content": "Our technique was assessed through three process for which we have identified four case studies. The first and the second case study are from Volvo Belgium and refer to a process that focuses on an incident and problem management system called VINST. Executions of this process are recorded in an event log with 7,456 completed traces and 64,975 events. The process consists of 13 different activities that can be accomplished by 649 resources. In the first case study, our aim is to predict the total time of an execution that is running, while in the second our aim is to predict whether or not the activity Awaiting Assignment will occur in the future for the same process instance. When that activity occurs, it means that the procedure has been assigned to the wrong division of the Volvo system, negatively affecting in terms of time and costs.\nThe third case study refers to the Hiring process provided by Pohl et al. in [14]. It deals with a multi-faced requirement procedure with diverse application pathways. Exe-cutions of this process are recorded in event log containing 10,000 completed traces and 69,528 events. There are 12 different activities that can be accomplished by 8 different resources. For this case study we aim to predict the total time a running execution.\nThe last case study is based on the Hospital process discussed by Pohl et al. [14]. It depicts a hospital treatment that starts with registration at an Emergency Room or Fam-ily Department and advances through stages of examination, diagnosis, and treatment. Executions of this process are recorded in 10,000 completed traces and 69,528 events. There are 10 different activities that can be accomplished by 7 different resources. For"}, {"title": "5.2 Selection of Protected Variables", "content": "Each case study clearly uses different protected variables, since their choice depend on process and is also related to specific fairness-preserving considerations. Table 1 summarizes the choices for the four case studies.\nFor the VINST process, we opted to protect variable resource country when the predicted outcome is the total process-instance execution time: that variable encodes the country of residence of the resource in the support team working on the case: en-suring fairness for this case study means that the prediction of the total case is not biased by the residence country of the resource that manages the request. For the same process, we also used organization country as alternative protected variable when the predicted outcome is whether or not the process-instance execution has observed Await-ing Assignment, an undesired activity linked to a downtime. The choice of a different protected variable is to illustrate that our technique also works when the protected vari-able or variables are altered. Variable organization country stores the location that takes ownership of the support team and the objective: ensuring fairness with respect to this variable means that the prediction whether or not the undesired activity occurrence is executed is not influenced by the country where the request is made.\nFor the Hiring and Hospital processes, we follow the indication given by Pohl et al. [14]. For the former we aim to protect variables Gender and Religious (i.e., whether or not the patient is religious); for the Hospital process, we protect two boolean vari-ables: Citizen (i.e., whether or not the patient is German) and german_speaking (i.e., whether the patient does or does not speak German)."}, {"title": "5.3 Evaluation Metrics", "content": "The evaluation's goal is twofold, as indicated at the beginning of the section, and aims to assess the mitigation influence of the protected variables on the prediction, and the extent of the reduction of the prediction accuracy when our framework was employed.\nFor the first and third case studies in which we aim to predict the total time of run-ning traces, i.e. a regression problem, the results are provided in terms of Absolute Percentage Accuracy (APA), which is defined as 100% minus Mean Absolute Per-centage Error, between the actual value and the predicted one. For the second and fourth"}, {"title": "5.5 Analysis of LSTM and FCNN accuracy and training times", "content": "We conclude this section by motivating the choice of FCNNs in place of LSTM models for operationalizing our framework. Specifically, we compared the prediction quality of the FCNN prediction models that implement $\\Psi_K$ (cf. Figure 2) for the four case studies, with that of equivalent models that leverage on a LSTM-network models. The LSTM-network models were trained via an implementation similar to [4,6]. We also measured the model training time to be able to assess the time amount necessary to build the prediction models. The results are reported in Table 6: the model-training times are significantly lower for FCNNs, while the prediction quality is very similar in every case study. This ultimately led us to conclude that FCNNs were preferable."}, {"title": "6 Conclusion", "content": "Considerable research efforts have been directed towards predictive process analytics. Section 2 has shown that the fairness problem has generally been overlooked in predic-tive process analytics. This means that predictions may potentially be discriminatory, unethical, and, e.g., targeting certain ethnics, nationalities and religions.\nThis paper puts forward a predictive framework that specializes those based on ad-versarial debiasing so as to allow sequences (i.e., traces) as input.\nExperiments were carried out on three processes and four case studies, and the re-sults show that our debasing framework minimizes the influence of the protected vari-ables onto the prediction. At the same time, we illustrates that the reduction of the prediction quality is limited and lower than what is achieved by an existing framework for fairness-preserving process predictive analytics by Qafari et al. [16].\nWe acknowledge that we have used a specific encoding in our FCNNs for event-log traces (cf. Section 3.1), but alternatives are possible [2]. While this encoding has enable FCNNs to outperform the state of the art (see previous paragraph), a potential direction of future work is to evaluate alternative encodings, which can lead to further improve-ments. So do we plan to extend our debiasing framework and move it from predictive to prescriptive analytics, in order to provide fair recommendations. A nice side effect on adding fairness to recommendations is that one can configure the system to give recommendations that are not biased on process' resources: this should ensure a fair assignment of recommended activities that do not cause overload of certain resources with respect to others."}]}