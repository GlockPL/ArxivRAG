{"title": "Monte Carlo Tree Search with Velocity Obstacles for safe and efficient motion planning in dynamic environments", "authors": ["Lorenzo Bonanni", "Daniele Meli", "Alberto Castellini", "Alessandro Farinelli"], "abstract": "Online motion planning is a challenging problem for intelligent robots moving in dense environments with dynamic obstacles, e.g., crowds. In this work, we propose a novel approach for optimal and safe online motion planning with minimal information about dynamic obstacles. Specifically, our approach requires only the current position of the obstacles and their maximum speed, but it does not need any information about their exact trajectories or dynamic model. The proposed methodology combines Monte Carlo Tree Search (MCTS), for online optimal planning via model simulations, with Velocity Obstacles (VO), for obstacle avoidance. We perform experiments in a cluttered simulated environment with walls, and up to 40 dynamic obstacles moving with random velocities and directions. With an ablation study, we show the key contribution of VO in scaling up the efficiency of MCTS, selecting the safest and most rewarding actions in the tree of simulations. Moreover, we show the superiority of our methodology with respect to state-of-the-art planners, including Non-linear Model Predictive Control (NMPC), in terms of improved collision rate, computational and task performance.", "sections": [{"title": "1 INTRODUCTION", "content": "Motion planning for mobile robots is an important and widely studied research area. When robots move in a (possibly uncertain) environment in the presence of dynamic obstacles, e.g., other agents or people, they must balance trajectory optimality towards the goal and risk of collision. Fast real-time trajectory computation is a key feature in dynamic environments to guarantee prompt response and adaptation to changes in the environment [37].\nReactive planning methods, e.g., Velocity Obstacles (VO) [19] and Artificial Potential Fields [50] consider a single motion command per time step, but they can get stuck in local minima when maps are complex [18]. On the other hand, look-ahead planning methods, as Non-linear Model Predictive Control (NMPC) [30] and tree-based search [44], are more robust since they optimize the trajectory over a time horizon. However, they are computationally demanding in dynamic environments, where re-planning is often needed. Furthermore, these methods often require precise knowledge about the trajectories of dynamic obstacles [48], which is often unavailable or uncertain in real-world domains, especially when dealing with agents exhibiting heterogeneous behaviors (e.g., humans [24]). Deep Reinforcement Learning (DRL) has recently become popular for motion planning in complex dynamic environments; however, it often struggles to generalize beyond the training scenario, offering no guarantee about safe collision avoidance. Additionally, its effective implementation requires extensive training data [1].\nIn this paper, we propose a novel approach to online robotic motion planning in dense, dynamic and partially unknown environments, combining look-ahead and reactive planning. Unlike other methods assuming partially known obstacle trajectories [29, 48], our approach only requires knowledge about the instantaneous obstacle locations, which can be obtained from standard sensors (e.g., LIDARs and cameras), and an upper bound on their maximum velocity (typically available, e.g., from social models [26] or other robots' specifications). We define the problem as a Markov Decision Process (MDP) and solve it using Monte Carlo Tree Search (MCTS), which performs online simulations over a time horizon to estimate the long-term expected value of actions and determine the next best action. MCTS often fails to scale to large action spaces [7, 10, 14], which limits its applicability to fine-control mobile robots' velocity. For this reason, we combine MCTS with the VO paradigm, which prunes unsafe actions (i.e., leading to collisions) from the search space during MCTS simulations, reducing the action search space. If the positions and maximum velocities of obstacles are known\u00b9, the integration of the two approaches guarantees that the agent always picks safe (i.e., not colliding) and optimal actions, considering a sufficiently small time-step Crucially, using the proposed approach, the number of simulations required by MCTS is significantly reduced,\n\u00b9In case of uncertainties, upper bounds can be used."}, {"title": "2 RELATED WORKS", "content": "The problem of motion planning for mobile robots has been extensively studied in scientific literature [3, 15]. Nonetheless, this is still an open research area, given the demonstrated intractability of the problem in generic dynamic environments [28]. We classify motion planning algorithms into three main categories: reactive planners, look-ahead planners, and learning-based planners.\nReactive planners compute only the next safe (i.e., collision-free) robot command, given the current configuration of the environmental map. Since they consider only the instantaneous situation, reactive planners are computationally efficient, hence the trajectory can be adapted at run time in the presence of dynamic obstacles and multiple moving agents. Main examples include Artificial Potential Fields (APF) [22, 23, 52] and Velocity Obstacles (VO) [19, 38]. A known issue with reactive planners, such as the APF method, is that they can get stuck in local minima [18] in case of specific configurations of obstacles and goals. This typically requires ad-hoc modifications of the standard reactive planning approach [39]. In the VO paradigm, a slight perturbation of the reactive planner may help escape local minima\u00b2; however, in cluttered environments this may badly affect the performance of the agent.\nIn complex maps, look-ahead planners are more suitable to find a feasible path towards the goal, since they optimize the trajectory\n\u00b2Example implementation available at https://gamma.cs.unc.edu/RVO2/"}, {"title": "3 BACKGROUND", "content": "We now introduce the fundamentals of the VO paradigm and Monte Carlo planning for MDPs, which are the base of the methodology described in this paper."}, {"title": "3.1 Velocity Obstacles (VO)", "content": "In the classical VO setting, a robot R must reach a target G in an environment with N obstacles. Without loss of generality, we assume that the robot and the obstacles are spherical\u00b3, with radii $r_r$ and $r_i, i = 1, ..., N$, respectively. At a given time step t, the robot is at (vector) location $p_r$, while the obstacles have positions $p_i$ and velocity (vector) $v_i$ (in our setting, the velocity of the obstacles is unknown). Given the set V of admissible velocities for robot R, the VO paradigm is used to compute the set of collision-free velocities $V_c \\subseteq V$. Specifically, for each i-th obstacle, we define a collision cone $CC_i$ as:\n$CC_i = { v \\in V | \\exists t > t_s s.t. p_r(t)+v_r(t-t) \\cap B(p_i, r_r+r_i) \\neq 0} $ (1)\nwhere $B(p_i, r_r + r_i)$ is the ball centered at $p_i$ with radius $r_r + r_i$, and $v_r = v - v_i$ is the relative velocity of the robot with respect to the obstacle. We then define $V_c = V \\setminus \\bigcup_{i=1}^{N} CC_i$, the latter being the union of cones for every obstacle. In Figure 1, we show the velocity space of the robot for a simple scenario with the collision cone for one obstacle.\n\u00b3 More complex shapes can be considered, e.g., square obstacles [49]."}, {"title": "3.2 Markov Decision Processes", "content": "A Markov Decision Process (MDP) [6, 41] is a tuple $M = (S, A, T, R, \\gamma)$, where S is a finite set of states (e.g., robot and obstacle positions in the VO setting), A is a finite set of actions - we represent each action with its index, i.e., $A = {1, . . ., |A|}$ (e.g., linear velocity and movement direction in the VO setting), $T : S \\times A \\rightarrow P(S)$ is a stochastic"}, {"title": "3.3 Monte Carlo Tree Search", "content": "MCTS [8, 12] is an online solver, namely, it computes the optimal policy only for the current state of the agent. In particular, given the current state of the agent, MCTS first generates, in a sample-efficient way, a Monte Carlo tree rooted in the current state of the agent. In this way, it estimates the Q-values (i.e., action val-ues) for that state. Then, it uses these estimates to select the best action. A certain number $m \\in N$ of simulations are performed us-ing, at each step, Upper Confidence Bound applied to Trees (UCT) [5, 27] (inside the tree) or a rollout policy (from a leaf to the end of the simulation) to select the action. The transition model (or an equivalent simulator) is used to perform the step from one state to the next. Simulations allow updating two node statistics, namely, the average discounted return Q(s, a) obtained by selecting ac-tion a from state s, and the number of times N(s, a) action a was selected from state s. UCT extends UCB1 [5] to sequential deci-sions and allows to balance exploration and exploitation in the simulation steps performed inside the tree, and to find the optimal action as m tends to infinity. Given the average return $Q_{a,T_a(t)}$ of each action a \u2208 A after t simulations, where $T_a(t)$ is the num-ber of times action a has been selected up to simulation t, UCT selects the action with the best upper confidence bound. In other words, the index of the action selected at the t-th visit of a node is $I_t = argmax_{a\\in{1,...,|A|}} Q_{a,T_a(t)} + 2C_p \\frac{\\sqrt{ln(t-1)}}{T_a(t-1)}$, with appropriate constant $C_p > 0$. When all m simulations are performed, the action a with maximum average return (i.e., Q-value) $Q_{a,T_a(m)}$ in the root is executed in the real environment."}, {"title": "4 METHODOLOGY", "content": "We consider a 2D motion planning scenario, where the robot has only access to the current position of obstacles, their maximum speed and radius, hence requiring no strict communication capa-bilities. It is crucial to note that no specific knowledge is available about obstacle behaviors. This replicates a realistic robotic setting"}, {"title": "4.1 Action space discretization", "content": "We express each velocity v \u2208 V as a tuple v = (\u03c5, \u03b1), where v is the module of the velocity and \u03b1 is the heading angle in radians. We assume that the physical constraints of the robot impose a maximum velocity module $v_{max}$ and a maximum angular velocity $\u03c9_{max}$. Thus, at each time step $t_s$, where the robot has heading angle $\u03b1_o$, the action space can be expressed as $A = { (\u03c5, \u03b1) | 0 \\leq \u03c5 \\leq v_{max}, \u03b1_0 - \u03c9_{max}t_s \\leq \u03b1 \\leq \u03b1_o + \u03c9_{max}t_s }$. We then obtain the action space for MCTS by discretizing v and \u03b1 within their respective ranges and considering all possible combinations of them. We also add actions in the form (0, \u03b1), to allow in-place rotation."}, {"title": "4.2 Integration of VO into MCTS", "content": "We introduce VO in two phases of MCTS, namely, Monte Carlo tree exploration, where UCT selects actions in simulation steps per-formed inside the Monte Carlo tree (in the following, this method will be called MCTS_VO_TREE) and rollout, where a random pol-icy selects actions in simulation steps performed out of the Monte Carlo tree (this method is called MCTS_VO_ROLLOUT in the fol-lowing). In both cases, we build collision cones as in Eq. (1), but"}, {"title": "4.2.1 VO in UCT", "content": "It concerns simulation steps taken inside the Monte Carlo tree, namely, the first steps performed near the robot's current position, to realize safe collision avoidance in the short term of the trajectory execution. Algorithm 2 shows the pseudo-code implementation of branch expansion in UCT based on VO7. Considering the maximum possible relative velocity between the agent and other robots/obstacles, at each step of UCT we compute the set $V_c$ of velocity vectors that do not lead to collisions (Line 2 in Algorithm 2, using Algorithm 1), i.e., the set of vectors such\n'For the full UCT algorithm, please refer to [9]."}, {"title": "4.2.2 VO in Rollout", "content": "The rollout phase of MCTS is known to be computationally demanding, hence it is important to design suitable heuristics to guide action selection [36, 42] and shield undesired or unsafe actions [35]. As a rollout policy (Algorithm 3), we use an heuristic to encourage the robot to move in the direction of the goal but also ensure convergence guarantees. Specifically, if the direction between the robot and the goal corresponds to angle $\u03b1_g$, we sample"}, {"title": "4.3 Assumptions for safe collision avoidance", "content": "Introducing VO in MCTS allows to prune colliding actions (veloc-ities), hence improving the planning efficiency and reducing the rate of collision with obstacles. In this paper, we assume minimal knowledge about the environment (i.e., only positions and max-imum possible velocities of obstacles) for the best adherence to real-world partially observable robotic settings, showing the signif-icant advantages of our methodology experimentally in the next section. However, the algorithm cannot always guarantee safe colli-sion avoidance because collisions also depend on the behavior of dynamic obstacles. We now discuss in more detail our assumptions and necessary modifications to them in order to achieve formal guarantees, showing their feasibility in realistic robotic settings."}, {"title": "4.3.1 Knowledge of $v_{max,o}, P_o$", "content": "Our methodology assumes that the positions and maximum velocities of obstacles are available to the agent at each step of MCTS computation. In general, ob-stacle positions can be estimated with standard robotic sensors, e.g., LIDARs, while estimating actual velocities is more challenging due to additional noise in the computation [47]. On the contrary, estimating the maximum possible velocities is easier, since they can be derived from available rough prior information (e.g., crowd models [26, 33] or other robots' specifications). Moreover, when computing safe velocities in Algorithm 1, we can enlarge $r_{1,2}$ (Lines 5-6) with safety bounds, in order to incorporate the level of confi-dence of sensors and uncertainties about $v_{max,o}$. Note that, in case of large uncertainty, $A_c = 0$ in Algorithm 1. In this case, our algo-rithm is still able to take a collision-free action, which is remaining stationary (Line 16)."}, {"title": "4.3.2 Unknown obstacle trajectories", "content": "Starting from a configuration where the center of the robot is outside the extended circumference"}, {"title": "4.3.3 Simulation time", "content": "In Algorithm 1, safe velocities are computed assuming that the obstacles move at $v_{max,o}$ during the simulation time step $t_s$. Hence, collision avoidance is only guaranteed if the planning time step (i.e., the time required by MCTS to compute the optimal action to be executed) is lower than $t_s$ (i.e., the step time in MCTS, needed to compute the action space A in Section 4.1). In our experiments, we will show that VO action pruning significantly increases the efficiency of MCTS, thus realizing this requirement for safe collision avoidance."}, {"title": "5 EXPERIMENTAL RESULTS", "content": "We evaluate each algorithm with a number of MCTS simulations ranging in [10, 400]9 and investigate the performance as descibed in Section 5.3 in terms of discounted return, collision rate, and compu-tational time per step. To account for the stochasticity of MCTS, we run 50 tests for each number of simulations. In the action space, we consider 60 actions, which combine 5 different velocity modules up to robot's $\u03c5_{max}$ and 12 different heading angles among the feasible ones. The discount factor for MDP is chosen empirically as \u03b3 = 0.7. In the rollout phase, we empirically set $\u03b5_0$ = 0.2 in Algorithm 3. The maximum number of allowed steps in simulation is set to 100 (i.e tree depth + rollout steps).\nAll experiments are run with Python 3.10 on a PC with Processor Intel(R) Core(TM) i5-13600KF CPU, 64GB Ram running Ubuntu 22.04.2 LTS. The code is available in the supplementary material."}, {"title": "5.1 Domain", "content": "We evaluated our methodology in the simulated map depicted in Figure 3a, consisting of a 10\u00d710m workspace containing 40 dynamic obstacles.\nFor dynamic obstacles modeling, we set all maximum veloci-ties in $v_{max,o}$ as $\u03c5_{max,o}$ = 0.2 m/s. At each time step, dynamic obstacles move towards randomly predefined goals on the map, with additive noise10. Specifically, at each time step the velocity"}, {"title": "5.2 Algorithms and Baselines", "content": "We assess the effectiveness of various look-ahead planners, operat-ing on the premise of lacking knowledge about obstacle trajectory and without the need for prior offline training. The algorithms evaluated in our experiments are listed in the following:\n\u2022 MCTS_VO_TREE: it is the algorithm introducing the VO con-straint inside MCTS only in the simulation steps performed inside the tree (see Section 4.2.1). This is the version of our approach showing the best tradeoff between performance and computational time (see Section 5.5);\n\u2022 MCTS_VO_ROLLOUT: it is the algorithm introducing the VO constraint inside MCTS only in the simulation steps performed during the rollout phase (see Section 4.2.2);\n\u2022 MCTS_VO_2: it is the algorithm introducing the VO con-straint both inside the Monte Carlo tree and in the rollout phase;"}, {"title": "5.3 Performance measures", "content": "To evaluate the performance of the algorithms, we use the three measures defined in the following:\n\u2022 Discounted Return (\u03c1): it is the discounted sum of all re-wards obtained during the course of a trajectory, i.e., $\u03c1 = \\sum_{k=1}^{H}\u03b3^{k-1}r_k$, where H is the total number of steps in the trajectory. It indicates the quality of the trajectory and the travel distance, since at each step the agent cumulates a small negative reward at each step. This measure must be maximized.\n\u2022 Collision rate (\u03b7): it is the ratio between the number of episodes in which the agent collides and the total number of episodes performed, i.e., $\u03b7 = \\frac{n_{collides}}{n_{exp}}$. This measure must be minimized, as it quantifies the reliability of the planner across different environment settings.\n\u2022 Planning time per step ($t_{plan}$): it is the average computational time taken by the planner to compute a planning step. It is useful to evaluate the applicability of each planning algo-rithm to real-world robotic setting, where the time available for deciding the next action is limited. This measure must be minimized and kept below $t_s$ (see Section 4.3.3)."}, {"title": "5.4 Comparison with baselines", "content": "We compare the performance of MCTS_VO_TREE (i.e., the best ver-sion among the proposed approaches) with that of NMPC, DWA12, VO_PLANNER and MCTS. Example GIFs showing the performance of different algorithms are available in the supplementary material. Curves for NMPC (grey lines), DWA (pink lines) and VO_PLANNER (yellow lines) do not change with the number of simulations, since they are independent on that. Hyperparameter tuning was con-ducted for NMPC, in order to find the best time horizon $\u03c4\u2208 [10,70]$ to balance between computational efficiency and task performance, resulting in \u03c4 = 70."}, {"title": "5.5 Ablation study", "content": "To better understand the effects of the introduction of VO in differ-ent points of the MCTS algorithm, we compare the performance of four variants of the proposed algorithm, namely, MCTS_VO_TREE, MCTS_VO_ROLLOUT, MCTS_VO2, and MCTS. The results are de-picted in Figure 5. Each line represents a different approach: blue for MCTS, orange for MCTS_VO2, red for MCTS_VO_ROLLOUT, and"}, {"title": "6 CONCLUSION AND FUTURE WORKS", "content": "We presented a novel algorithm for optimal online motion plan-ning with collision avoidance in unknown dynamic and cluttered environments, combining the benefits of a look-ahead planner as Monte Carlo Tree Search (MCTS), with the safety guarantees about collision avoidance provided by Velocity Obstacles (VO). As ev-idenced by our ablation study, VO in the UCT phase of MCTS allows to significantly reduce the computational cost of the planner, restricting the action space to only collision-free actions and dra-matically reducing the number of required online simulations (even with a large action space consisting of \u2248 60 velocities). Moreover, we thoroughly discussed the assumptions required to guarantee safe collision avoidance, showing their feasibility in most practical robotic use cases. Notably, our algorithm does not require any prior knowledge about the trajectories of other obstacles, but only their positions at the planning time and maximum velocities. Valida-tion in a 10 \u00d7 10m map with up to 40 static and randomly moving obstacles shows that our approach can compute high-quality tra-jectories with very few simulations per step in MCTS (less than 50), maintaining low variability in random scenarios (hence being"}]}