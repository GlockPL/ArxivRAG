{"title": "Unrealized Expectations: Comparing AI Methods vs Classical Algorithms for Maximum Independent Set", "authors": ["Yikai Wu", "Haoyu Zhao", "Sanjeev Arora"], "abstract": "AI methods, such as generative models and reinforcement learning, have recently been applied to combinatorial optimization (CO) problems, especially NP-hard ones. This paper compares such GPU-based methods with classical CPU-based methods on Maximum Independent Set (MIS). Experiments on standard graph families show that AI-based algorithms fail to outperform and, in many cases, to match the solution quality of the state-of-art classical solver KaMIS running on a single CPU. Some GPU-based methods even perform similarly to the simplest heuristic, degree-based greedy. Even with post-processing techniques like local search, AI-based methods still perform worse than CPU-based solvers.\nWe develop a new mode of analysis to reveal that non-backtracking AI methods, e.g. LTFT (which is based on GFlowNets), end up reasoning similarly to the simplest degree-based greedy approach, and thus worse than KaMIS. We also find that CPU-based algorithms, notably KaMIS, have strong performance on sparse random graphs, which appears to refute a well-known conjectured upper bound for efficient algorithms from Coja-Oghlan & Efthymiou (2015).", "sections": [{"title": "1. Introduction", "content": "Combinatorial optimization (CO) lies at the core of numerous scientific and engineering studies, encompassing applications in network design, resource allocation, healthcare, and supply chain (Du & Pardalos, 1998; Hoffman, 2000; Zhong & Tang, 2021). Combinatorial optimization usually involves selecting an optimal solution from a discrete but often exponentially large set of candidates. Many are NP-hard (meaning that if $P \\neq NP$ then there is no polynomial-time algorithm for solving them in the general cases (Papadimitriou & Steiglitz, 1998)). This makes it challenging to design algorithms with provable guarantees, but in practice solvers can find reasonable quality solutions (e.g., Gurobi (Gurobi Optimization, LLC, 2024)).\nRecent advances in artificial intelligence (AI) and GPU computing have motivated use of AI-inspired approaches, e.g., Graph Neural Networs (GNNs) and reinforcement learning, to learn problem-specific strategies for NP-hard optimization problems such as MIS (Li et al., 2018; Ahn et al., 2020) and TSP (Kool et al., 2018; Zhang et al., 2021). AI models can also be trained to predict search directions or refine heuristic rules (Li et al., 2018; d O Costa et al., 2020). These algorithms utilize advanced GPUs and often require shorter inference compared to CPU-based algorithms. Additionally, AI-inspired methods avoid the need to design heuristics for specific problems, allowing generalization to new instances and problems (Bengio et al., 2021b; Cappart et al., 2023).\nDespite the claimed benefits of AI-inspired methods, a few years ago Angelini & Ricci-Tersenghi (2023) showed that a Graph Neural Network based MIS algorithm (Schuetz et al., 2022) failed to surpass greedy algorithms. B\u00f6ther et al. (2022) showed that AI-inspired approaches fail to provide superior search directions compared to traditional heuristics in tree search algorithms for MIS. Gamarnik (2023) suggests that GNN has theoretical limits which may become obstacles for GNN-based MIS algorithms.\nHowever, in recent years many new AI-inspired CO algorithms, utilizing a variety of techniques, such as diffusion models (Sun & Yang, 2023; Sanokowski et al., 2024), GPU-accelerated sampling (Sun et al., 2023), and direct optimization (Alkhouri et al., 2024) have been developed and claimed to significant improve over the previous ones. Furthermore, GFlowNets (Bengio et al., 2021a), which have been proposed as general-purpose tools for tasks like scientific discovery and reinforcement learning (Bengio et al., 2023), has also been used to solve CO problems (Zhang et al., 2023). Since combinatorial optimization is an arena where humans have hand-designed algorithms for many decades, the following question is of great scientific interest:\nDo Al-inspired algorithms perform better than\nclassical heuristics for\ncombinatorial optimization?"}, {"title": "1.1. Our contributions", "content": "We explore the question in the context of Maximum Independent Set (MIS) problem: given a graph, aiming to find the largest subset of nodes with no edges present between any node pair. The simplicity of the problem attracted design of many heuristics to tackle the problem (Andrade et al., 2012; Lamm et al., 2015). In recent works, MIS is also a main target in efforts that design AI-inspired approaches such as non-convex optimization (Schuetz et al., 2022; Alkhouri et al., 2024), reinforcement learning (Ahn et al., 2020; Zhang et al., 2023), and diffusion models (Sun & Yang, 2023; Sanokowski et al., 2024).\nFor classical heuristics, we test degree-based greedy (Deg-Greedy, pick a node with smallest degree at each step), and the state-of-the-art MIS solver KAMIS (Lamm et al., 2017; Dahlum et al., 2016; Hespe et al., 2019). For AI-inspired algorithms, we test the newest algorithms from each \"category\" according to the techniques they use, including sampling algorithm iSCO (Sun et al., 2023), non-convex optimization algorithm PCQO (Alkhouri et al., 2024), reinforcement-learning related algorithms LWD (Ahn et al., 2020) and LTFT (Zhang et al., 2023) (based on GFlowNets (Bengio et al., 2021a)) and diffusion models DIFUSCO (Sun & Yang, 2023) and DiffUCO (Sanokowski et al., 2024).\nTesting on different graph types with different sizes and densities leads to the following empirical finding (Section 3).\nFinding 1: Current Al-inspired algorithms for MIS still don't outperform the best heuristic KaMIS, which runs on a single thread in a CPU, while AI-inspired methods often require significant computational resources.\nFinding 2: As the graph becomes larger or denser, KaMIS exhibits a notable superiority to AI-inspired algorithms.\nFinding 3: The simplest degree-based greedy algorithm (Deg-Greedy) serves as a very strong baseline. Some AI-inspired algorithms perform similarly to or worse than Deg-Greedy, especially for larger and denser graphs.\nSection 4 presents ablation studies to understand why some Al-inspired methods fail to improve over the simplest Deg-Greedy method. We introduce a new mode of analysis, serialization, that transforms the solution of any algorithm into a sequential list of choices leading to the final independent set. We compare sequential order with the"}, {"title": "2. Benchmarking MIS Algorithms", "content": "We focus the experiment setup for benchmarking different algorithms for Maximum Independent Set problems (MIS)."}, {"title": "2.1. Maximum Independent Set (MIS) problem", "content": "Given an undirected graph G(V, E) where V is the set of nodes and E is the set of edges, an independent set is a subset of vertices $I \\subset V$ such that no two nodes in I are adjacent, i.e., (u, v) \u2209 E for all u, v \u2208 I. The goal in MIS is to find the largest possible independent set, I*."}, {"title": "2.2. MIS algorithms", "content": "We classify the algorithms we test as: (1) classical heuristics, which includes Deg-Greedy and KaMIS (OnlineMIS and ReduMIS); (2) GPU-accelerated non-learning algorithms, which includes iSCO and PCQO; and (3) learning-based algorithms, which includes LWD, LTFT, DIFUSCO, and DiffUCO.\nDeg-Greedy (Degree-based greedy) Simplest heuristic: always picks a node with the smallest degree in the current graph, add to the current independent set, and delete that node and all of its neighbors from the graph. Most papers on AI-inspired methods do not compare with this baseline.\nOnlineMIS and ReduMIS are two variants of the MIS solver KAMIS, mainly consists of three alternating steps: greedy, local search, and graph reductions. OnlineMIS (Dahlum et al., 2016) only applies a simple reduction after local search, while ReduMIS (Lamm et al., 2017) applies many graph reduction techniques.\nisco\n(Sun et al., 2023) is a GPU-accelerated sampling-based method, incorporating gradient-based discrete MCMC and simulated annealing. The MCMC is designed based on the Metropolis-Hasting algorithm, which"}, {"title": "2.3. Graph types", "content": "Erd\u0151s-Reny\u00ed (ER) graph (Erd\u00f6s & R\u00e9nyi, 1959) are random graphs where edges are connected uniformly at random (with a given probability or a fixed number of edges). We vary 2 parameters for ER graphs, number of nodes n and average degree d, by fixing the number of edges at $nd$. Previous benchmark (B\u00f6ther et al., 2022) and algorithms (Ahn et al., 2020; Sun & Yang, 2023; Zhang et al., 2023; Alkhouri et al., 2024) used it as test graphs for MIS, though without varying parameters as we did."}, {"title": "2.4. More experiment details", "content": "For synthetic graphs, we test 8 graphs for each parameter (n, d) or (n, m). We test on 100 graphs for real-world datasets. For learning-based algorithms, we use 4000 training graphs generated using the same parameter (in case of random graphs) or drawn 4000 graphs from the same real-world dataset. For algorithms requiring hyperparameters, we use default hyperparameters in most cases (Details in Appendix B).\nWe set 24-hr time limit for KAMIS (OnlineMIS and ReduMIS) since it runs on a single CPU thread with 32GB memory, and our benchmark focuses on performance on solution quality. Note that AI-based methods run well only on relatively small graphs, and ReduMIS runs in less than one hour on small graphs ($n < 3000$). Given 24 hours ReduMIS can handle much larger graphs (up to $n \\approx 1e6$).\nFor iSCO and learning-based algorithms, we report results within our computational limit (generally a single 80GB A100 for 96hrs, details in Appendix B.) We test PCQO for $n \\leq 10000$ because the performance degrades quickly for large graphs using default hyperparameter search domain."}, {"title": "3. Experiment Results and Main Findings", "content": "In this section, we present our main experiment results. The performance of different algorithms on Erd\u0151s-R\u00e9ny\u00ed (ER) graphs, Barab\u00e1si\u2013Albert (BA) graphs, and real-world graphs are shown in Tables 1 to 3 respectively.\nAI-inspired algorithms don't outperform ReduMIS.\nOur first main finding is that, current AI-inspired algorithms do not outperform the best classical heuristics ReduMIS in terms of performance. As shown in Tables 1 to 3, ReduMIS consistently achieves superior results compared to all other methods, with the exception of iSCO sometimes perform"}, {"title": "4. AI-Inspired vs Deg-Greedy", "content": "Our results show that the state-of-the-art Al-inspired algorithms for MIS still do not outperform the best heuristic ReduMIS. The surprising finding was that they also often do not outperform the simplest classical heuristic, Deg-Greedy, especially on large and dense graphs. In this section, we delve deeper into this comparison (Sections 4.1 and 4.2). Furthermore, we explore the impact of augmenting various algorithms with a local search as a post hoc step to enhance solution quality (Section 4.3)."}, {"title": "4.1. Comparison between Deg-Greedy and LTFT", "content": "Deg-Greedy sequentially picks nodes for the independent set. At each step, it picks the node with the smallest degree in the residual graph (where the nodes in the independent set and their neighbors are removed). It does not reverse any decisions (ie once picked, the node stays in the independent set). As in Section 2.2 we call it a non-backtracking algorithm. LTFT is also a non-backtracking algorithm and it often perform similarly to Deg-Greedy in Tables 1 and 2. It uses a trained policy network GFlowNets (Bengio et al., 2021a) to pick a node for the independent set at each step. Thus, we can naturally compare LTFT with Deg-Greedy"}, {"title": "4.2. Serialization: allows comparing to Deg-Greedy", "content": "In the previous part, we demonstrate that LTFT employs a heuristic similar to Deg-Greedy, selecting the node with the smallest degree in the remaining graph in each round. However, other algorithms, such as ReduMIS, PCQO, and DIFUSCO, which does not select one node at a step without backtracking, cannot be analyzed based on the sequence of nodes picked. Thus, we introduce a method called degree-"}, {"title": "4.3. Incorporating local search to improve solution", "content": "In the previous sections, we show that solutions generated by AI-based algorithms generally differ from those produced by degree-based greedy methods, which may explain their inferior performance on MIS problems. A natural idea is to enhance these solutions with simple heuristics, such as local search. Local search post-processing has also been used for AI-algorithms in previous works (Ahn et al., 2020; B\u00f6ther et al., 2022).\nWe applied the 2-improvement local search (Andrade et al., 2012) (details in B.7), which is used in KaMIS, as a post-processing step to all algorithms (except OnlineMIS and ReduMIS since they already has local search), and the resulting performance improvements are presented in Table 4.\nAs shown in Table 4, algorithms like PCQO and DIFUSCO benefit significantly more from the local search post-processing compared to others, such as Deg-Greedy and LwD. This observation aligns with our earlier findings: If the solution after serialization exhibits a high percentage of smallest-degree node selections in the later stages, there is relatively little room for improvement through local search. Conversely, if the solution after serialization shows a low percentage of smallest-degree node selections, there is greater potential for improvement via local search.\nIn addition, although all algorithms except iSCO have improvements after local search, they still perform worse than ReduMIS in most cases.\nIn summary, our analysis highlights a promising direction for designing machine learning-based combinatorial optimization algorithms. Rather than relying solely on end-to-end methods like PCQO or DIFUSCO, incorporating classical heuristics, such as greedily selecting the smallest-degree node, into the overall algorithm may yield better results. One potential approach could involve using machine learning algorithms to identify a small subset of nodes, followed by a degree-based greedy method to complete the solution."}, {"title": "4.4. KaMIS refutes famous conjecture?", "content": "For theoretical analysis for MIS on ER graphs and regular graphs, see Coja-Oghlan & Efthymiou (2015); Wormald et al. (1999); Barbier et al. (2013); Gamarnik & Sudan (2014). In ER graphs with n nodes and average degree d, the MIS has size $\\frac{2n}{\\ln d}$ for asymptotically large n and d, and simplest random greedy achieves half-optimal at $\\frac{n}{d}$"}, {"title": "5. Related Works", "content": "Classical and heuristic methods for MIS Classical methods for MIS range from simple greedy algorithms to advanced solvers like KaMIS which involves a number of heuristics. There are various existing heuristics for MIS, such as reduction techniques (Butenko et al., 2002; Xiao & Nagamochi, 2013; Akiba & Iwata, 2016), local search (Andrade et al., 2012), and evolutionary algorithms (Back & Khuri, 1994; Borisovsky & Zavolovskaya, 2003; Lamm et al., 2015). KaMIS (Lamm et al., 2017; Dahlum et al., 2016; Hespe et al., 2019) was developed based on these heuristics. In addition, MIS can be formulated into a binary integer programming problem (Nemhauser & Trotter Jr, 1975), which can be solved by the state-of-art integer programming solver Gurobi (Gurobi Optimization, LLC, 2024).\nMachine learning for combinatorial optimization In recent years, various ML-based algorithms have been developed for the MIS problem and most of them are based on graph neural networks (GNNs). Some of them using"}, {"title": "6. Conclusion and Takeaways", "content": "Given the great interest in designing \u201cgeneral purpose AI reasoners\u201d, it is interesting to check how well recent AI-based methods have fared in combinatorial optimization, a field with a long history of ingenious hand-designed algorithms. Our careful empirical comparisons of such AI-inspired methods with classical methods on MIS problem showed that none of the new methods outperform ReduMIS, the best CPU-based MIS solver, which builds up the independent set iteratively, sometimes backtracking (i.e. delete a vertex from the current set). As the graphs get larger or denser, the superiority of ReduMIS becomes more evident, whereas several AI-inspired algorithms drop to performing no better than trivial classical algorithms such as Deg-Greedy.\nFurther analysis shows that the fact that AI-inspired algorithms like DIFUSCO and PCQO select the independent set in one shot may be handicapping themselves by foregoing the benefits of local search. Methods like Deg-Greedy and"}, {"title": "B. Detailed Experiment Setup", "content": ""}, {"title": "B.1. Algorithm Pseudo-code for degree-based serialization", "content": "Please refer to Algorithm 1 for the pseudo-code for degree-based serialization, mentioned in Section 4.2."}, {"title": "B.2. Datasets", "content": "For synthetic graphs, we test 8 graphs for each parameter (n, d) or (n, m). We test on 100 graphs for real-world datasets. For learning-based algorithms, we use 4000 training graphs generated using the same parameter (in case of random graphs) or drawn 4000 graphs from the same real-world dataset.\nErd\u0151s-Reny\u00ed (ER) graph ER graphs (Erd\u00f6s & R\u00e9nyi, 1959) have 2 parameters: the number of nodes n and the average degree d. For graphs with given (n, d) We generate them by choosing $M = \\frac{nd}{2}$ edges uniformly at random between n nodes. This is the Erd\u0151s-Reny\u00ed's G(n, M) model.\nThere is also G(n, p) model for ER graphs, which is also used widely. They behave similarly for many graph properties to G(n, M) models when $M = \\binom{n}{2}p$ and we expect the emipirical results for MIS problems will also be very similar.\nFor the main experiments, we use ER graphs with n = {100, 300, 1000, 3000, 10000}, d = {10, 30, 100, 300, 1000, 3000} with d < n as shown in Table 2. We also test on larger graphs with n = {30000,1 \u00d7 105,3 \u00d7 105, 1 \u00d7 106,3 \u00d7 106} as shown in Table 7. Due to computational and time limits, we could only obtain results from classical CPU-based algorithms for these large graph, and only sparse graphs for very large $n \\geq 1 \u00d7 106$.\nBarab\u00e1si-Albert (BA) graph BA graphs (Albert & Barab\u00e1si, 2002) also have 2 parameters: the number of nodes n and the generation parameter m, with n > m. For a given (n, m), the generation process initializes with m nodes, and then add 1 node at each step. When adding a new node, m neighbors of the new node are sampled from the existing nodes, with the probability of the current degree of the nodes. The average degree of BA graph with given (n, m) can be computed as $d=\\frac{2m}{n}$.\nFor the main experiments, similar to ER graphs, we also use n = {100, 300, 1000, 3000, 10000}. Since the average degree $d \\approx 2m$, we use m = {5, 15, 50, 150, 500, 1500} with 2m < n.\nReal-world graphs Since we need at least 4100 graphs to train and test our algorithms and the graphs should not be too small, it is difficult to find such datasets. Fortunately, Morris et al. (2020) provides a website w.graphlearning.io which includes many graph datasets prepared by them or collected from other works. Although most of the datasets are still too small or having too small graphs, we are able to find 2 datasets: REDDIT-MULTI-5K and COLLA, both from Yanardag & Vishwanathan (2015). REDDIT-MULTI-5K has 4999 graphs with average nodes 508.52 and average edges 594.87, so the graphs are generally very sparse. COLLA has 5000 graphs with average nodes 74.49 and 2457.78, so they are denser but smaller graphs.\nWe were not able to find real-world datasets with enough size of more larger and denser graphs, which are generally more difficult for MIS algorithms. The dataset DIMACS used in B\u00f6ther et al. (2022) contains such graphs but they only have 37"}, {"title": "B.3. Hardware configurations", "content": "The CPU we use is either Intel Xeon Processor E5-2680 v4 @ 2.40GHz or Intel Xeon Silver 4214 Processor @ 2.20GHz. The GPU we use is Nvidia Tesla A100 80GB when we refer to time limit or time cost. For small graphs when the GPU memory limit and time limit is not reached, we also use Nvidia RTX A6000 48GB and Nvidia RTX 2080Ti 11GB."}, {"title": "B.4. Classical CPU-based algorithms", "content": "Ran-Greedy and Deg-Greedy Deg-Greedy (Degree-based Greedy) is as follows: Starting from an empty set. Select a node with the lowest degree of the graph (if there exists several nodes of the lowest degree, we pick one uniformly at random) and add it to the set. Then remove the node and all its neighbors from the graph.\nRan-Greedy (Random Greedy) is as follows: Starting from an empty set. Select a node from the graph uniformly at random and add it into the set. Then remove the node and all its neighbors from the graph. The only difference between it and Deg-Greedy is that the choice of node is completely random.\nThey are both non-backtracking algorithms.\nWe did not include results of Ran-Greedy in the main paper because its performance is significantly lower than all other algorithms. It can be considered as a baseline and has theoretical significance, since it has provable guarantee for random graphs (Grimmett & McDiarmid, 1975).\nIn order to match the best-of-20 sampling we used for the learning-based-algorithms, we also ran Deg-Greedy for 20 times and report the best results in the main experiments (n < 10000).\nWe wrote the script in Python and ran it on a single CPU thread for each graph with a time limit of 24hrs, but it actually run less than 1hr on smaller graphs like n \u2264 3000. We gave 32GB memory for graphs with n < 10000 and 64GB memory for larger graphs. Since there are much more efficient implementations like C++, the efficiency of the greedy algorithms is not very relevant.\nKAMIS (OnlineMIS and ReduMIS) KaMIS (Karlsruhe Maximum Independent Sets) (Lamm et al., 2017) (https://karlsruhemis.github.io/) is the state-of-art heuristic solver for MIS and has been used as a baseline in many previous works. It provides 2 algorithms for the MIS problem: ReduMIS (Lamm et al., 2017) and OnlineMIS (Dahlum et al., 2016).\nWe can provide a time-limit for both algorithm. OnlineMIS will use up the time given while ReduMIS will end on its own when it finds appropriate. In general, ReduMIS provides better results when given enough time, where OnlineMIS is faster to reach a solution of reasonable quality for large and dense graphs.\nWe ran both algorithm on a single CPU thread for each graph with a time limit of 24hrs, because our benchmark focus on performance instead of efficiency. For relatively small graphs (n < 3000), ReduMIS often require less than 1hr and at most 1.25hrs, and OnlineMIS can also provide answer with the same quality when giving 1hr time limit. We gave 32GB memory for graphs with n < 10000 and 64GB memory for larger graphs."}, {"title": "B.5. GPU-accelerated non-learning algorithms", "content": "isco iSCO (improved Sampling for Combinatorial Optimization) (Sun et al., 2023) is a GPU-accelerated sampling-based method. It does not require learning. According to (Sun et al., 2023), the main benefit is that it can process a large batch of graphs in parallel thus improve efficiency. While processing a small number of graphs like in our case (8 test graphs), it still requires significant time, often longer than ReduMIS.\nWe use the code from the codebase of DISCS (Goshvadi et al., 2024), which is a follow-up paper for iSCO, as iSCO did not provide the codebase. We use 1 80GB A100 GPU to run iSCO with all test graphs together. The time limit is 96hrs, and the actual time it requires is shorter. It fail to run graphs of size (n = 3000, 1000), (n = 10000, d = 100), and larger because they require larger than 80GB memory. The code does not support multi-GPU."}, {"title": "B.6. Learning-based algorithms", "content": "We use 4000 training graphs for each datasets to train our models. Without otherwise noted, all the training are in-distribution, with respect to a single set of parameters (i.e. (n, d) for ER graphs, (n, m) for BA graphs) for synthetic graphs.\nLwD LWD (Learning what to Defer) (Ahn et al., 2020) is a reinforcement learning based algorithm which requires training data to learn the policy. It models the MIS problem as a Markov Decision Process (MDP), where in each step it selects some (possibly 0, 1, or multiple) nodes to add into the independent set. It is a non-backtracking algorithm as the added nodes are never taken out. B\u00f6ther et al. (2022) also included this algorithm in their benchmark.\nWe use the code from B\u00f6ther et al. (2022) since it provides better functionality than the original codebase. We use the default setting provided by B\u00f6ther et al. (2022) in their MIS Benchmark codebase (https://github.com/MaxiBoether/mis-benchmark-framework), but change the number of samples to 20 (default is 10) for test sampling, in order to match the best-of-20 sampling in our benchmark.\nWe use 1 80GB A100 GPU to train for each datasets and test with the same GPU. The training time limit is set to 96hrs. The default number of training steps (number of updates to the policy) is 20000. Since LwD stores checkpoints throughout the process, we still report the test results based on the newest checkpoints for unfinished experiments if we have the checkpoints which reports meaningful results (better than half of the results reported by Deg-Greedy). Those results are indicated by * in the tables. The number of steps taken by those datasets with unfinished experiments is in Table 5.\nLTFT LTFT (Let the Flows Tell) (Zhang et al., 2023) similar to LwD, also model the MIS problem as a MDP and non-backtracking. The difference is that it only choose 1 node at each step, making it more similar to Deg-Greedy. The node chosen at each step is chosen by a GFlowNet (Bengio et al., 2021a), which is trained by in-distribution training data.\nWe use the default setting provide by (Zhang et al., 2023) for training with 20 epochs. By default setting, it has best-of-20 sampling and report the best solution found.\nWe use 1 80GB A100 GPU to train for each datasets and test with the same GPU. The training time limit is set to 96hrs. It completes training for all graphs with n \u2264 3000, but larger graphs require larger GPU memory. The code does not support multi-GPU.\nDIFUSCO DIFUSCO (Diffusion Solvers for Combinatorial Optimization) (Sun & Yang, 2023) trains a diffusion model using supervised learning to produce a solution for the MIS. The diffusion model provides an entire solution so it is a one-shot algorithm.\nThe training data is 4000 graphs for each dataset (1 set of parameter for synthetic graphs). All training is in-distribution. The training data is labelled by ReduMIS with time limit of 1hr. For graphs we used for training (n < 3000), ReduMIS gives the same performance compared to a time limit of 24hrs.\nWe use the default setting in (Sun & Yang, 2023) except that we use 50 diffusion steps throughout training and testing, and 20 samples for testing to be aligned with best-of-20 sampling in other methods. We train the model for 50 epochs (default) for each dataset.\nWe use 1 80GB A100 GPU to train for each datasets and test with the same GPU. The training time limit is set to 96hrs. The code does not support multi-GPU. We report results where the training can be completed.\nAlthough Sun & Yang (2023) suggested that DIFUSCO has some generalization ability. We found the performance degrade significantly for out-of-distribution trained models (specifically trained on smaller graphs with the same average degree but test on larger graphs), we did not report the results of larger graphs where the in-distribution training cannot finish.\nDiffUCO DiffUCO (Diffusion for Unsupervised Combinatorial Optimization) (Sanokowski et al., 2024) is also a diffusion model based algorithm but unlike DIFUSCO it uses unsupervised learning. The diffusion model is trained to sample the solution of low energy state. It also provides an entire solution and is also a one-shot algorithm.\nWe use the default setting in Sanokowski et al. (2024) for RB-large MIS task (in their Appendix C.5). During testing, we use conditional expectation with 20 samples to align with best-of-20 sampling in other algorithms. The code supports multi-GPU. We use 4 80GB A100 GPU to train for each datasets with time limit 96hrs.\nThe training time is significantly longer than other learning-based algorithms for the same dataset and it can only complete training up to ER graphs with (n = 1000, d = 100) and BA graph with (n = 1000, d = 50). According to Sanokowski et al. (2024) it has reasonable generalization ability, and we also found that the performance drop is relatively small if we test larger graphs using models trained with smaller graphs with similar average degree. Therefore, we also report test results using out-of-distribution trained model. The parameters of those datasets and the datasets used to train corresponding models are reported in Table 6. Those results are labelled using \u2020 in tables."}, {"title": "B.7. Local search", "content": "Local search is a method to improve a given independent set. It can be used as a post-processing technique, or be used as sub-procedures in more complicated algorithms like KaMIS. Andrade et al. (2012) provides an efficient local search algorithm. Part of it is to find 2-improvement, which is the part used as sub-procedure in KaMIS (Lamm et al., 2017; Dahlum et al., 2016).\nThe local search algorithm for 2-improvement for a given independent set I is as follows. This algorithm process every vertex x \u2208 I in turn. First, it temporarily removes x from I, creating a new set S. We call a vertex a free vertex of S if there is no edge between it and any vertex in S. If S has less than two free vertices, stop: there is no 2-improvement involving x. Otherwise, for each neighbor v of x that is a free vertex for S, insert v into S and check if the new set (S') has a free vertex w. If it does, inserting w leads to a 2-improvement; if it does not, remove v from S' (thus restoring S) and process the next neighbor of x. If no improvement is found, reinsert x into S to turn it back to I. Every vertex is scanned O(1) times in this algorithm so it can find a 2-improvement (if there exists) in O(m) time according to Andrade et al. (2012).\nWe implemented this algorithm in Python and use it as a post-processing for the solutions produced by the algorithm we test."}, {"title": "C. More Experiment Results", "content": "In this section, we show more experiment results. Appendix C.1 shows more experiment results on much larger graphs, where the AI-inspired methods cannot handle. Appendix C.2 show the serialization results on more graphs. Appendix C.3 show a more detailed results between LwD and Deg-Greedy, which applies degree-based serialization as a subprocedure. Appendix C.4 shows the full results when adding local search as a post-processing procedure. Finally, Appendix C.5 discusses more results on the ratio of"}]}