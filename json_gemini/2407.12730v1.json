{"title": "RODE: Linear Rectified Mixture of Diverse Experts for Food Large Multi-Modal\nModels", "authors": ["Pengkun Jiao", "Xinlan Wu", "Bin Zhu", "Jingjing Chen", "Chong-Wah Ngo", "Yugang Jiang"], "abstract": "Large Multi-modal Models (LMMs) have significantly ad-\nvanced a variety of vision-language tasks. The scalability and\navailability of high-quality training data play a pivotal role in\nthe success of LMMs. In the realm of food, while comprehen-\nsive food datasets such as Recipe1M offer an abundance of\ningredient and recipe information, they often fall short of pro-\nviding ample data for nutritional analysis. The Recipe1M+\ndataset, despite offering a subset for nutritional evaluation,\nis limited in the scale and accuracy of nutrition informa-\ntion. To bridge this gap, we introduce Uni-Food, a unified\nfood dataset that comprises over 100,000 images with various\nfood labels, including categories, ingredients, recipes, and\ningredient-level nutritional information. To mitigate the con-\nflicts arising from multi-task supervision during fine-tuning\nof LMMs, we introduce a novel Linear Rectification Mix-\nture of Diverse Experts (RoDE) approach. RoDE utilizes a\ndiverse array of experts to address tasks of varying complex-\nity, thereby facilitating the coordination of trainable parame-\nters, i.e., it allocates more parameters for more complex tasks\nand, conversely, fewer parameters for simpler tasks. RoDE\nimplements linear rectification union to refine the router's\nfunctionality, thereby enhancing the efficiency of sparse task\nallocation. These design choices endow RoDE with features\nthat ensure GPU memory efficiency and ease of optimization.\nOur experimental results validate the effectiveness of our pro-\nposed approach in addressing the inherent challenges of food-\nrelated multitasking.", "sections": [{"title": "Introduction", "content": "Food occupies a central position in our daily lives, leading\nto the emergence of various food-related tasks, e.g., ingre-\ndient recognition, recipe generation, and nutritional estima-\ntion. These tasks have attracted considerable research inter-\nests over the years (Chen and Ngo 2016a; Zhu et al. 2019;\nPan et al. 2020; Chen et al. 2020; Min et al. 2023; Luo et al.\n2023). Building on the success of Large Language Models\n(LLMs) (Radford et al. 2018; Touvron et al. 2023), Large\nMulti-modal Models (Liu et al. 2023a; Luo et al. 2023) have\nbegun to make a significant impact in many specialized ar-\neas, including the food domain (Yin et al. 2023).\nThe success of LLMs and LMMs can be largely attributed\nto the availability of large-scale training data. In the food do-\nmain, while Recipe1M (Salvador et al. 2017) provides over"}, {"title": "Dataset Construction", "content": "In this paper, we construct a large-scale dataset called\nUni-Food. Different from other publicly available food\ndatasets (Bossard, Guillaumin, and Van Gool 2014; Marin\net al. 2019; Chen and Ngo 2016a; Thames et al. 2021), Uni-\nFood contains various attributes used in food-related tasks,\nincluding food category, ingredients, recipe and nutrition for\neach food image. To the best of our knowledge, this is the\nlargest dataset that provides all the attributes in one dataset."}, {"title": "Attribution", "content": "Our objective is to construct a unified and comprehensive\ndataset containing rich information relevant to food, en-\ncompassing the following key attribution for each image.\nCategory: Classifying each food item into specific cate-\ngories to facilitate organization and categorization within\nthe dataset. Ingredients Information: Providing a thorough\nbreakdown of the ingredients used in each dish, including\ntheir names and quantities. Cooking Instructions: Offering\nstep-by-step instructions on how to prepare each dish, en-\nsuring clarity and completeness for easy reproduction. Nu-\ntrition Information: Incorporating detailed nutritional data\nfor each dish, such as macronutrient content (e.g., carbohy-\ndrates, proteins, fats), micronutrients, and total calories. An\nintuitive sample demonstration of these attributions is shown\nin Figure 2. The distribution across various categories is vi-\nsualized in Figure 3"}, {"title": "Nutrition Labeling", "content": "As the ingredient and recipe information can be easily col-\nlected from Recipe1M+ (Marin et al. 2019), we proceed to"}, {"title": "Method", "content": "In this section, we first provide a preliminary overview of the\nproblem formulation for multi-task tuning of LMMs, as well\nas the commonly used techniques, i.e., Low-Rank Adapta-\ntion (LoRA) (Hu et al. 2021) and Mixture of Experts (MoE)\n(Dou et al. 2023) for addressing this problem. Subsequently,\nwe introduce our Linear Rectified Mixture of Diverse Ex-\nperts approach in detail."}, {"title": "Preliminary", "content": "Problem Formulation. A Large Multi-modal Model\n(LMM) can be constituted by a vision encoder and a Large\nLanguage Model (LLM), as shown in Figure 4. Normally,\nLMM is initially pre-trained with tremendous amounts of\ndata, and then fine-tuned to adapt to downstream tasks. The\nutilization of multi-modal documents for Supervised Fine-\nTuning (SFT) (Radford et al. 2018) is a common practice in\nthe fine-tuning of LMMs.\nLet us denote the set of multimodal documents as $D$,\nwhere $D = \\{(I_i, T_i)\\}_{i=1}^M$, where $I_i$ signifies the image,\nand $T_i$ represents the associated set of tasks with that im-\nage. $M$ stands for the total number of documents. Each task\nset $T_i$ encompasses sequence-specific tasks ${\\lbrace (q_j, a_j)\\rbrace}_{j=1}^{T_i}$,\nwhere $q_j, a_j$ is the question and answer for task $j$, and\n$T_i$ is the number of task types. The primary objective of\nSFT is to using $D$ to fine-tune the LMM so that it can\nprovide corresponding answers to given questions based on\nan image. More specifically, for an image $I_i$ and a ques-\ntion $q_j$, the training objective is to maximize the probability\n$p(a|I, q, \\theta)$, where $\\theta$ represents the trainable parameters\nof the large model.\nLow-Rank Adaptation (LoRA). Fully tuning large mod-\nels can be resource-intensive. Parameter-Efficient Fine-\nTuning (PEFT) (Ding et al. 2023) introduces additional\nadapters to effectively customize large models for down-\nstream tasks with minimal resource overhead. Let $W$ repre-\nsent the weight of a linear layer $L$ in the large-scale model,\nwhich is initially set as $W_0$ after pre-training. In PEFT,\n$W_0$ remains frozen in order to preserve the acquired world\nknowledge. To facilitate adaptation to downstream tasks, a\nlearnable branch linear adapter, denoted as $\\Delta W$, is intro-\nduced to modify the initial frozen linear weights $W_0$. Con-\nsequently, the output of the adapted linear layer $L$ can be\nexpressed as $W = W_0 + \\Delta W$. LORA (Hu et al. 2021) fur-\nther decomposes $\\Delta W$ into two matrices, $A$ and $B$, where\nthe connection rank is considerably smaller than that of $W_0$.\nLORA allows the model to adapt to downstream tasks while\nreducing the number of training parameters.\nMixture of Experts (MoE). The Mixture of Experts\n(MoE) (Dou et al. 2023) paradigm of LoRA is proposed to\nadapt large models to multiple downstream tasks by employ-\ning multiple LoRAs in the MLP layers. Each LoRA module\ncan be considered as an expert, wherein all experts receive\nthe same input and combine their outputs to improve overall\nperformance. Let $R = \\{A_i, B_i\\}_{i=0}^N$ denote a series of LoRA\nmodules, where $N$ signifies the number of LoRAs. We use\n$h(.)$ to denote the linear router, which takes the dimension\nof the input feature $x$ and outputs the allocation vector of $R$.\nThe output of layer $L$ incorporating the MoE module can be\nrepresented as:\n$x' = W_0 x + \\sum_{i=0}^{N} \\sigma(\\alpha h(x))_i B_i A_i x$. (1)\nHere, $\\sigma$ stands for the softmax operation, $\\alpha$ is a hyperparam-\neter, and $x'$ is the output feature."}, {"title": "Linear Rectified Mixture of Diverse Experts", "content": "Our proposed RoDE framework incorporates a variety of\nexperts, each with distinct capabilities, and a linear rectifi-\ncation router to integrate the contributions of these experts.\nThe overall structure of the framework is depicted in Fig-\nure 4. A comprehensive illustration of the framework is pro-\nvided in the subsequent sections.\nDiverse Capability Experts Typically, within the Mixture\nof Experts (MoE) framework, all experts share the same\narchitecture. In the case of LoRA, for example, each ex-\npert is assigned the same rank. However, this uniformity\nassumes equal capabilities across all experts. This implies\nthat for more complex tasks, each expert might need to pos-\nsess a large number of parameters to adapt effectively. How-\never, this could be prohibitively demanding in terms of GPU\nmemory requirements.\nTo mitigate the issue of GPU memory constraints, we con-\nceptualize the experts as fine-grained skill modules. The key\nidea is that a task may activate a combination of these mod-\nules, and these modules can be shared across various tasks.\nThis modular design intuitively leads us to develop LORA\nexperts with different capabilities tailored to tasks of varying\ncomplexity. Drawing inspiration from Low-Rank Adapta-\ntion (Hu et al. 2021), which suggests that a low-rank adapter\nmay be sufficient for certain tasks, we create LoRAs with\nvarying ranks. Consequently, the resulting skill space com-\nprises both high-rank and low-rank LoRA experts, providing\ngreater flexibility and efficiency in addressing a diverse set\nof tasks.\nTo construct such skill space, we configure a heteroge-\nneous set of experts, represented as $R = \\{A_i, B_i\\}_{i=0}^{N}$,\nwhere the rank $r_i$ of $i$ - th LoRA module may vary from the\nothers. Therefore, we can establish a skill space composed"}, {"title": "Linear Rectified Router", "content": "The router consolidates the con-\ntributions of each expert based on the demands of the spe-\ncific task. Previous research (Zhou et al. 2022) has shown\nthat the use of sparse mixtures of LoRA experts outper-\nforms dense experts in the context of large language models.\nLLaVA-MOLE (Chen, Jie, and Ma 2024) presents a top-1\nselection strategy, which ensures the sparsity of expert se-\nlection in LMM. While some methodologies in the Natural\nLanguage Processing (NLP) field adopt a 'soft' approach to\ncombine expert outputs for instance, (Dou et al. 2023) uti-\nlizes softmax and (Ponti et al. 2023) employs Gumbel soft-\nmax-these techniques are not as sparse and can be chal-"}, {"title": "lenging to optimize.", "content": "In contrast, our methodology adopts a novel approach by\nutilizing the Rectified Linear Unit (ReLU) (Nair and Hinton\n2010) to rectify the output of the routers, thereby encour-\naging the sparse learning of LoRA expert activations. A vi-\nsual illustration of our routing strategy is shown in Figure\n5. Leveraging the intrinsic properties of the Rectified Linear\nUnit (ReLU), our approach benefits from a simplified opti-\nmization landscape and fosters sparsity within the network,\nwhich enables our model to boost both efficiency and effi-\ncacy.\nLet $\\gamma$ represent the linear rectification operation, $\\gamma(x) =$\nmax(x, 0). We utilize ReLU to rectify the linear router, re-\nsulting in an adjusted linear output that can be expressed as\nfollows:\nx' = W_0 x + \\sum_{i=0}^{N} \\sigma(h(x))_i B_i A_i x, (2)\nwhere $(A_i, B_i)$ represents the operation performed by the\ni-th LoRA expert. The summed output from the RoDE mod-\nule is then added to the frozen linear output and forwarded\nto the next module.\nThis linear rectification mechanism, enhances the sparsity\nof skill selection, facilitating efficient utilization of expertise\nacross a broad spectrum of tasks. Overall, diverse LoRA ex-\nperts and linear rectified arrangement yield a fine-grained\ntask-skill arrangement space, contributing to the optimized\nallocation and utilization of resources within the model."}, {"title": "Optimization Objects and Inference", "content": "Following previous LMM-based methods (Liu et al. 2023a),\nthe input images are transformed into image tokens and con-\ncatenated with text tokens to send to LLM. The training pro-\ncess adheres to the autoregressive model, predicting the next\ntoken based on the input tokens. We employ the standard\ncross-entropy loss as the optimization objective to train our\nmodel.\nDuring inference, for each task, we input the image along\nwith the corresponding question into the model. The model's\noutput tokens are then converted into words to formulate the\nanswer."}, {"title": "Experiment", "content": "In this section, we first present our experimental setup. Then\nwe elaborate experimental results of multiple food tasks\nbased on multi-task learning. Following this, we perform an\nablation study to evaluate the impact and effectiveness of our\nmain components."}, {"title": "Experiment Setup", "content": "Our approach commenced by utilizing the pre-trained\nweights of the LLaVA-Lightning-7B-v1-1 (Liu et al. 2023a)\nmodel, subsequently applying SFT on the Uni-Food and Nu-\ntrition5k datasets (Thames et al. 2021). In our RoDE model,\nwe employ a heterogeneous array of experts with LoRA\nranks of [2, 4, 8, 16]. Our primary baseline is FoodLMM\n(Yin et al. 2023), which to our knowledge is the only ver-\nsatile LMM specialized in food-related tasks. Additionally,"}, {"title": "Performance Comparison", "content": "We perform a comparative analysis between our model and\ntwo versions of FoodLMM: a base version equipped with\nplane LoRA, and an enhanced version, FoodLMM+MoE,\nequipped with four 8-rank LoRA and a linear router with\nsoftmax. These methods are evaluated across three tasks:\ningredient recognition, recipe generation, and nutrition es-\ntimation. The results are summarized in Table 2. The ta-\nble clearly shows that the MoE design enhances the per-\nformance of FoodLMM. By adopting the traditional MoE\nparadigm, i.e., FoodLMM+MoE, there is an 8.6% improve-\nment in IoU for ingredients recognition, for recipe genera-\ntion, there is a 14.6% increase in SacreBLEU and a 1.1%\ngain in Rouge-L scores. However, there is a slight reduction\nof 1% in nutritional performance. Overall, the comparison\ndemonstrates the advantages of incorporating MoE.\nFurthermore, our model, RoDE, significantly outperforms\nthe traditional MoE design, achieving the highest scores\nacross all evaluated metrics. In the ingredient recognition\ntask, RoDE surpasses FoodLMM+MoE by a notable margin\nof 9.5%. For recipe generation, RoDE shows an 11% higher\nSacreBLEU score and a 4.2% improvement in Rouge-L\nscore compared to FoodLMM+MoE. In the area of nutri-\ntion estimation, RoDE nearly tops the charts for all nutrient\nelements and secures the leading position in terms of av-\nerage performance. These experimental results conclusively\naffirm the superiority of our proposed RODE approach in"}, {"title": "food multi-task learning.", "content": "Additionally, we conduct further experiments on Nutri-\ntion5k (Thames et al. 2021) dataset, adhering to the method-\nology established by FoodLMM, where only image infor-\nmation was utilized for training (without depth informa-\ntion). The outcomes, as presented in Table 3, unequivo-\ncally demonstrate that our methods consistently surpass both\nFoodLMM and traditional MoE variations in performance."}, {"title": "Ablation study", "content": "In this section, we perform an ablation study to evaluate the\ncontribution and efficacy of the core components within our\nframework. For simplicity, we omit the task names and tag\nonly the metrics.\nMoE vs. Larger LoRA rank As illustrated in Table 4, we\nfirst compare the standard LoRA (Var1) with its MoE vari-\nant (Var3). The results indicate a superior performance of\nthe MoE design. To ascertain whether this performance im-\nprovement can be attributed to an increase in the number of\ntrainable LORA parameters, we augment the LoRA rank of\nVarl to 32 to obtain Var2. A comparison between Var2 and\nVar4 reveals the superiority of the MoE design, even though\nthese two variants have an equivalent number of trainable\nLORA parameters. This finding suggests that the successful\nintegration of MoE is not simply a result of expanding the\nnumber of trainable parameters."}, {"title": "Routing Strategy", "content": "Then we examine the effects of the\nrouting strategy. Our experiment includes three routing\nstrategies: 1) similar to (Chen, Jie, and Ma 2024), the top-1\nexpert is selected, referred to as Top-1; 2) following the ap-\nproach in (Dou et al. 2023), we employ a softmax function to\nnormalize the router outputs, which is denoted as Softmax;\n3) we introduce our novel linear rectified router, which we\ndenote with the abbreviation LR. The results are summa-\nrized in Table 5 and visualized in Figure 7. As observed,\nwhile the Top-1 allocation MoE outperforms the standard\nLORA (Var1), it is surpassed by the \"soft\" allocation strate-\ngies (i.e., Var2 and Var3). This indicates the efficiency of\nemploying an ensemble of experts to address a single task.\nMoreover, the comparison between the LR and Softmax\nrouters (i.e., Var2 and Var3, Var4 and Var5) suggests that\nthe LR routing strategy is superior. These results further un-\nderscore the effectiveness of our linear rectification routing\nstrategy.\nIn addition, we visualize the heatmaps of router outputs\nfor both the Softmax and LR routing strategies across sev-\neral middle transformer blocks. Figure 6 illustrates this com-\nparative analysis, clearly indicating that our proposed Linear\nRectified Router achieves a higher degree of sparsity in task\nallocation."}, {"title": "Rank configuration of LoRA", "content": "We conduct an ablation\nstudy to evaluate the impact of different LoRA rank config-\nurations. The results, as presented in Table 6, span multiple\nexpert configurations, including: 1) Varl - Four LoRAs, each\nwith a uniform rank of 5. 2) Var2 - Four LoRAs, each with a\nuniform rank of 8. 3) Var3 - A heterogeneous set of four Lo-\nRAs with ranks of [2, 4, 6, 7]. 4) Var4 - Another diverse set\nof four LoRAs with a distinct rank composition from Var3,\nspecifically [2, 4, 8, 16]. The analysis of Varl and Var2 sug-\ngests that configurations with higher-ranked LoRA experts\nare more effective. However, despite having the same num-\nber of trainable parameters as Var1, Var3 demonstrates supe-\nrior performance, indicating that a mix of higher and lower-\nranked LoRA experts can also be effective. Moreover, Var3\nshows comparable performance to Var2, with only a slight"}, {"title": "reduction in SacreBLEU score (by 0.08) and Rouge-L score", "content": "(by 0.36), while having 32.5% fewer trainable parameters.\nThis finding supports the notion that not all LoRA experts\nrequire high capacity to contribute effectively.\nBy adjusting the ranks in Var3 to create Var4, we observe\nimproved performance which exceeds that of Var2, despite\nVar4 having 6.25% fewer trainable parameters. This out-\ncome implies that a strategic combination of LoRA expert\nsizes can effectively support the inclusion of some larger Lo-\nRAs, potentially enhancing their capability to handle com-\nplex tasks more efficiently."}, {"title": "Training Parameter Efficiency", "content": "We evaluate various rank settings by visualizing the corre-\nlation between the number of trainable LoRA parameters\nand their corresponding task performance on the Uni-Food\ndataset. Figure 8 illustrates this relationship, with the y-axis\nindicating task performance and the x-axis representing the\ntrainable LoRA parameter count. It is apparent that the MoE\narchitecture incorporates more trainable LoRA parameters,\nwhich substantially boosts performance across a range of\nmetrics, i.e., recipe SacreBLEU, recipe Rouge-L, and ingre-\ndient IoU. When comparing sets of homogeneous experts\nto those of heterogeneous experts (i.e., comparing rank sets\n[5,5,5,5] to [2,4,6,8]), the introduction of high rank LoRA\ncan enhance model performance despite when the number of\ntrainable LORA parameters is the same. These results sug-\ngest that not every expert requires an extensive parameter\nset; heterogeneous experts can effectively coordinate train-\nable parameters, resulting in better performance on multi-\ntask learning."}, {"title": "Conclusion", "content": "In this paper, we delve into the broader scope of tasks within\nthe realm of food studies. We introduce Uni-Food, a compre-\nhensive dataset comprising classification, ingredient recog-\nnition, recipe generation, and nutrition estimation. Uni-Food\nserves as a foundational resource empowering a wide spec-\ntrum of food-related research endeavors. The expansion of"}]}