{"title": "RODE: Linear Rectified Mixture of Diverse Experts for Food Large Multi-Modal\nModels", "authors": ["Pengkun Jiao", "Xinlan Wu", "Bin Zhu", "Jingjing Chen", "Chong-Wah Ngo", "Yugang Jiang"], "abstract": "Large Multi-modal Models (LMMs) have significantly ad-\nvanced a variety of vision-language tasks. The scalability and\navailability of high-quality training data play a pivotal role in\nthe success of LMMs. In the realm of food, while comprehen-\nsive food datasets such as Recipe1M offer an abundance of\ningredient and recipe information, they often fall short of pro-\nviding ample data for nutritional analysis. The Recipe1M+\ndataset, despite offering a subset for nutritional evaluation,\nis limited in the scale and accuracy of nutrition informa-\ntion. To bridge this gap, we introduce Uni-Food, a unified\nfood dataset that comprises over 100,000 images with various\nfood labels, including categories, ingredients, recipes, and\ningredient-level nutritional information. To mitigate the con-\nflicts arising from multi-task supervision during fine-tuning\nof LMMs, we introduce a novel Linear Rectification Mix-\nture of Diverse Experts (RoDE) approach. RoDE utilizes a\ndiverse array of experts to address tasks of varying complex-\nity, thereby facilitating the coordination of trainable parame-\nters, i.e., it allocates more parameters for more complex tasks\nand, conversely, fewer parameters for simpler tasks. RoDE\nimplements linear rectification union to refine the router's\nfunctionality, thereby enhancing the efficiency of sparse task\nallocation. These design choices endow RoDE with features\nthat ensure GPU memory efficiency and ease of optimization.\nOur experimental results validate the effectiveness of our pro-\nposed approach in addressing the inherent challenges of food-\nrelated multitasking.", "sections": [{"title": "Introduction", "content": "Food occupies a central position in our daily lives, leading\nto the emergence of various food-related tasks, e.g., ingre-\ndient recognition, recipe generation, and nutritional estima-\ntion. These tasks have attracted considerable research inter-\nests over the years (Chen and Ngo 2016a; Zhu et al. 2019;\nPan et al. 2020; Chen et al. 2020; Min et al. 2023; Luo et al.\n2023). Building on the success of Large Language Models\n(LLMs) (Radford et al. 2018; Touvron et al. 2023), Large\nMulti-modal Models (Liu et al. 2023a; Luo et al. 2023) have\nbegun to make a significant impact in many specialized ar-\neas, including the food domain (Yin et al. 2023).\nThe success of LLMs and LMMs can be largely attributed\nto the availability of large-scale training data. In the food do-\nmain, while Recipe1M (Salvador et al. 2017) provides over"}, {"title": "Dataset Construction", "content": "In this paper, we construct a large-scale dataset called\nUni-Food. Different from other publicly available food\ndatasets (Bossard, Guillaumin, and Van Gool 2014; Marin\net al. 2019; Chen and Ngo 2016a; Thames et al. 2021), Uni-\nFood contains various attributes used in food-related tasks,\nincluding food category, ingredients, recipe and nutrition for\neach food image. To the best of our knowledge, this is the\nlargest dataset that provides all the attributes in one dataset.\nOur objective is to construct a unified and comprehensive\ndataset containing rich information relevant to food, en-\ncompassing the following key attribution for each image.\nCategory: Classifying each food item into specific cate-\ngories to facilitate organization and categorization within\nthe dataset. Ingredients Information: Providing a thorough\nbreakdown of the ingredients used in each dish, including\ntheir names and quantities. Cooking Instructions: Offering\nstep-by-step instructions on how to prepare each dish, en-\nsuring clarity and completeness for easy reproduction. Nu-\ntrition Information: Incorporating detailed nutritional data\nfor each dish, such as macronutrient content (e.g., carbohy-\ndrates, proteins, fats), micronutrients, and total calories. An\nintuitive sample demonstration of these attributions is shown\nNutrition Labeling\nAs the ingredient and recipe information can be easily col-\nlected from Recipe1M+ (Marin et al. 2019), we proceed to"}, {"title": "Method", "content": "In this section, we first provide a preliminary overview of the\nproblem formulation for multi-task tuning of LMMs, as well\nas the commonly used techniques, i.e., Low-Rank Adapta-\ntion (LoRA) (Hu et al. 2021) and Mixture of Experts (MoE)\n(Dou et al. 2023) for addressing this problem. Subsequently,\nwe introduce our Linear Rectified Mixture of Diverse Ex-\nperts approach in detail."}, {"title": "Preliminary", "content": "Problem Formulation. A Large Multi-modal Model\n(LMM) can be constituted by a vision encoder and a Large\nLanguage Model (LLM), as shown in Figure 4. Normally,\nLMM is initially pre-trained with tremendous amounts of\ndata, and then fine-tuned to adapt to downstream tasks. The\nutilization of multi-modal documents for Supervised Fine-\nTuning (SFT) (Radford et al. 2018) is a common practice in\nthe fine-tuning of LMMs.\nLet us denote the set of multimodal documents as D,\nwhere $D = \\{(I_i, T_i)\\}_{i=1}^M$, where $I_i$ signifies the image,\nand $T_i$ represents the associated set of tasks with that im-\nage. M stands for the total number of documents. Each task\nset $T_i$ encompasses sequence-specific tasks $T_i = \\{(q_j, a_j)\\}_{j=1}^{T}$,\nwhere $q_j, a_j$ is the question and answer for task j, and\nT is the number of task types. The primary objective of\nSFT is to using D to fine-tune the LMM so that it can\nprovide corresponding answers to given questions based on\nan image. More specifically, for an image $I_i$ and a ques-\ntion $q_j$, the training objective is to maximize the probability\n$p(a|I, q, \\theta)$, where $\\theta$ represents the trainable parameters\nof the large model.\nLow-Rank Adaptation (LoRA). Fully tuning large mod-\nels can be resource-intensive. Parameter-Efficient Fine-\nTuning (PEFT) (Ding et al. 2023) introduces additional\nadapters to effectively customize large models for down-\nstream tasks with minimal resource overhead. Let W repre-\nsent the weight of a linear layer L in the large-scale model,\nwhich is initially set as $W_0$ after pre-training. In PEFT,\n$W_0$ remains frozen in order to preserve the acquired world\nknowledge. To facilitate adaptation to downstream tasks, a\nlearnable branch linear adapter, denoted as $\\Delta W$, is intro-\nduced to modify the initial frozen linear weights $W_0$. Con-\nsequently, the output of the adapted linear layer L can be\nexpressed as $W = W_0 + \\Delta W$. LORA (Hu et al. 2021) fur-\nther decomposes $\\Delta W$ into two matrices, A and B, where\nthe connection rank is considerably smaller than that of $W_0$.\nLORA allows the model to adapt to downstream tasks while\nreducing the number of training parameters.\nMixture of Experts (MoE). The Mixture of Experts\n(MoE) (Dou et al. 2023) paradigm of LoRA is proposed to\nadapt large models to multiple downstream tasks by employ-ing multiple LoRAs in the MLP layers. Each LoRA module\ncan be considered as an expert, wherein all experts receive\nthe same input and combine their outputs to improve overall\nperformance. Let $R = \\{A_i, B_i\\}_{i=0}^N$ denote a series of LoRA\nmodules, where N signifies the number of LoRAs. We use\nh(.) to denote the linear router, which takes the dimension\nof the input feature x and outputs the allocation vector of R.\nThe output of layer L incorporating the MoE module can be\nrepresented as:\n$x' = W_0x + \\sum_{i=0}^{N} \\sigma(h(x)_i)B_iA_ix$.\\nHere, $\\sigma$ stands for the softmax operation, $\\alpha$ is a hyperparam-eter, and $x'$ is the output feature."}, {"title": "Linear Rectified Mixture of Diverse Experts", "content": "Our proposed RoDE framework incorporates a variety of\nexperts, each with distinct capabilities, and a linear rectifi-\ncation router to integrate the contributions of these experts.\nThe overall structure of the framework is depicted in Fig-\nure 4. A comprehensive illustration of the framework is pro-\nvided in the subsequent sections.\nDiverse Capability Experts Typically, within the Mixture\nof Experts (MoE) framework, all experts share the same\narchitecture. In the case of LoRA, for example, each ex-\npert is assigned the same rank. However, this uniformity\nassumes equal capabilities across all experts. This implies\nthat for more complex tasks, each expert might need to pos-\nsess a large number of parameters to adapt effectively. How-\never, this could be prohibitively demanding in terms of GPU\nmemory requirements.\nTo mitigate the issue of GPU memory constraints, we con-\nceptualize the experts as fine-grained skill modules. The key\nidea is that a task may activate a combination of these mod-\nules, and these modules can be shared across various tasks.\nThis modular design intuitively leads us to develop LORA\nexperts with different capabilities tailored to tasks of varying\ncomplexity. Drawing inspiration from Low-Rank Adapta-\ntion (Hu et al. 2021), which suggests that a low-rank adapter\nmay be sufficient for certain tasks, we create LoRAs with\nvarying ranks. Consequently, the resulting skill space com-\nprises both high-rank and low-rank LoRA experts, providing\ngreater flexibility and efficiency in addressing a diverse set\nof tasks.\nTo construct such skill space, we configure a heteroge-\nneous set of experts, represented as $R = \\{A_i,B_i\\}_{i=0}^{N}$,\nwhere the rank $r_i$ of i - th LoRA module may vary from the\nothers. Therefore, we can establish a skill space composed\nof various LoRAs, each tailored to accommodate tasks of\ndifferent complexity levels.\nLinear Rectified Router The router consolidates the con-\ntributions of each expert based on the demands of the spe-\ncific task. Previous research (Zhou et al. 2022) has shown\nthat the use of sparse mixtures of LoRA experts outper-\nforms dense experts in the context of large language models.\nLLaVA-MOLE (Chen, Jie, and Ma 2024) presents a top-1\nselection strategy, which ensures the sparsity of expert se-\nlection in LMM. While some methodologies in the Natural\nLanguage Processing (NLP) field adopt a 'soft' approach to\ncombine expert outputs for instance, (Dou et al. 2023) uti-lizes softmax and (Ponti et al. 2023) employs Gumbel soft-max-these techniques are not as sparse and can be chal-lenging to optimize.\nIn contrast, our methodology adopts a novel approach by\nutilizing the Rectified Linear Unit (ReLU) (Nair and Hinton\n2010) to rectify the output of the routers, thereby encour-aging the sparse learning of LoRA expert activations. A vi-sual illustration of our routing strategy is shown in Figure\n5. Leveraging the intrinsic properties of the Rectified Linear\nUnit (ReLU), our approach benefits from a simplified opti-mization landscape and fosters sparsity within the network,\nwhich enables our model to boost both efficiency and effi-cacy.\nLet $\\gamma$ represent the linear rectification operation, $\\gamma(x) =max(x, 0)$. We utilize ReLU to rectify the linear router, re-sulting in an adjusted linear output that can be expressed asfollows:\n$x' = W_0x + \\sum_{i=0}^{N} \\sigma(h(x)_i) B_i A_i x,$\\nwhere $(A_i, B_i)^{r_i}$ represents the operation performed by thei-th LoRA expert. The summed output from the RoDE mod-ule is then added to the frozen linear output and forwardedto the next module.\nThis linear rectification mechanism, enhances the sparsityof skill selection, facilitating efficient utilization of expertiseacross a broad spectrum of tasks. Overall, diverse LoRA ex-perts and linear rectified arrangement yield a fine-grainedtask-skill arrangement space, contributing to the optimizedallocation and utilization of resources within the model.\nOptimization Objects and Inference\nFollowing previous LMM-based methods (Liu et al. 2023a),the input images are transformed into image tokens and con-catenated with text tokens to send to LLM. The training pro-cess adheres to the autoregressive model, predicting the nexttoken based on the input tokens. We employ the standardcross-entropy loss as the optimization objective to train ourmodel.\nDuring inference, for each task, we input the image alongwith the corresponding question into the model. The model'soutput tokens are then converted into words to formulate theanswer."}, {"title": "Experiment", "content": "In this section, we first present our experimental setup. Then\nwe elaborate experimental results of multiple food tasks\nbased on multi-task learning. Following this, we perform an\nablation study to evaluate the impact and effectiveness of our\nmain components.\nExperiment Setup\nOur approach commenced by utilizing the pre-trained\nweights of the LLaVA-Lightning-7B-v1-1 (Liu et al. 2023a)\nmodel, subsequently applying SFT on the Uni-Food and Nu-trition5k datasets (Thames et al. 2021). In our RoDE model,\nwe employ a heterogeneous array of experts with LoRA\nranks of [2, 4, 8, 16]. Our primary baseline is FoodLMM\n(Yin et al. 2023), which to our knowledge is the only ver-satile LMM specialized in food-related tasks. Additionally,"}, {"title": "Conclusion", "content": "In this paper, we delve into the broader scope of tasks within\nthe realm of food studies. We introduce Uni-Food, a compre-hensive dataset comprising classification, ingredient recog-nition, recipe generation, and nutrition estimation. Uni-Food\nserves as a foundational resource empowering a wide spec-trum of food-related research endeavors. The expansion of"}]}