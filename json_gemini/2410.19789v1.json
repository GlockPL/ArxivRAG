{"title": "Xeno-learning: knowledge transfer across species in deep learning-based spectral image analysis", "authors": ["Jan Sellner", "Alexander Studier-Fischer", "Ahmad Bin Qasim", "Silvia Seidlitz", "Nicholas Schreck", "Minu Tizabi", "Manuel Wiesenfarth", "Annette Kopp-Schneider", "Samuel Kn\u00f6dler", "Caelan Max Haney", "Gabriel Salg", "Berkin \u00d6zdemir", "Maximilian Dietrich", "Maurice Stephan Michel", "Felix Nickel", "Karl-Friedrich Kowalewski", "Lena Maier-Hein"], "abstract": "Novel optical imaging techniques, such as hyperspectral imaging (HSI) combined with machine learning-based (ML) analysis, have the potential to revolutionize clinical surgical imaging. However, these novel modalities face a shortage of large-scale, representative clinical data for training ML algorithms, while preclinical animal data is abundantly available through standardized experiments and allows for controlled induction of pathological tissue states, which is not ethically possible in patients. To leverage this situation, we propose a novel concept called \"xeno-learning\", a cross-species knowledge transfer paradigm inspired by xeno-transplantation, where organs from a donor species are transplanted into a recipient species. Using a total of 11,268 HSI images from humans as well as porcine and rat models, we show that although spectral signatures of organs differ across species, shared pathophysiological mechanisms manifest as comparable relative spectral changes across species. Such changes learnt in one species can thus be transferred to a new species via a novel \"physiology-based data augmentation\" method, enabling the large-scale secondary use of preclinical animal data for humans. The resulting ethical, monetary, and performance benefits of the proposed knowledge transfer paradigm promise a high impact of the methodology on future developments in the field.\nKeywords: hyperspectral imaging, surgical scene segmentation, tissue classification, domain generalization, deep learning", "sections": [{"title": "1 Main", "content": "Death within 30 days after surgery has been found to be the third-leading contributor to mortality worldwide [1]. One of the major challenges faced by surgeons is the visual discrimination of tissues, for example to distinguish between pathological and physiological tissue or spare critical intraoperative structures. Spectral imaging has been proposed as a means of overcoming the limitations of visual perception [2]. While conventional medical cameras (e.g., laparoscopic imaging systems) are limited by \"imitating\" the human eye and recording only red, green and blue colors, spectral cameras remove this arbitrary restriction and instead capture mul-tiple specific bands of light that allow for decoding relevant information on tissue type and function [3, 4].\nArtificial intelligence (AI) in general and machine learning (ML) in particular have evolved as key enabling techniques to convert the high-dimensional spectral data into clinically useful information [5-8]. However, a major bottleneck in converting this novel imaging technique's poten-tial into patient benefit lies in the lack of large annotated, high-quality datasets covering the wide range of pathologies that can occur in practice. In this context, preclinical animal data represents an untapped resource, offering not only more data but also the possibility of conducting various types of standardized experiments. This is in stark contrast to human data acquisition for which high ethi-cal standards and clinical workflow considerations render many experiments of high scientific inter-est infeasible such as the intentional induction of pathological tissue states e.g. fibrosis, inflammation or malperfusion.\nTo address the human data bottleneck, we therefore propose the new concept of \"xeno-learning\" (cf. Figure 1), a new AI paradigm to transfer knowledge across species. The term has been inspired by the concept of xeno-transplantation, which refers to the transplantation of living cells, tissues, or organs from one species to another. In this case, the shortage of transplantable human organs is addressed by using organs from other species; in analogy, our work aims to address the shortage of standardized data by transferring knowledge from one species (specifically porcine or rat models) to another (here: humans). Our specific contributions are:\n\u2022 Knowledge transfer bottleneck: We demonstrate that spectral signatures of organs differ across species, thus causing neural networks trained on one species (e.g., animals) to fail when classifying tissues of another species (e.g., human tissue).\n\u2022 New cross-species learning paradigm: We introduce the concept of xeno-learning as a new paradigm to boost the performance of neural networks applied to one species by making effi-cient use of data from another species. We further instantiate the concept on the specific challenge of perfusion shifts in spectral image analysis, which may lead to radical performance decrease in state-of-the-art tissue segmentation methods. Relative spectral changes are learnt in one species and transferred to a new species via a novel \"physiology-based data augmentation\" method (cf. Figure 2)."}, {"title": "2 Results", "content": "Both medicine in general and surgery in particular offer numerous examples where animal research has significantly informed clinical practice [12]. The success of animal experiments can largely be attributed to existing similarities between humans and certain species, such as rats and pigs. In the fol-lowing, we explore to which extent spectral images acquired from animals can be leveraged for human applications.\nAll of the presented results were obtained using the medical device-graded HSI system Tivita\u00ae Surgery (Diaspective Vision, Am Salzhaff, Ger-many) to collect 11,268 HSI images from three species including 230 patients from Heidelberg Uni-versity Hospital. For our analysis, we semantically annotated 2,445 images with 12 classes (11 organ classes and background)."}, {"title": "2.1 Organ spectra differ across species", "content": "While similarities do exist, spectral organ finger-prints were generally not consistent across species. Figure 3 shows spectral organ fingerprints for a total of 11 organs for three species, namely humans, pigs and rats. Some organs such as skin or omen-tum exhibited higher similarities in their spectra across species than other organs, such as colon or kidney."}, {"title": "2.2 Segmentation networks fail to generalize across species", "content": "To investigate the effect of the spectral differences on neural network performance, we trained net-works on physiological organ images of one species and evaluated their performance on physiological organ images of other species (Figure 4).\nSegmentation networks failed dramatically when applied to a new species, with perfor-mance decreases of -45% (pig2human) to -59% (rat2human). The metric values also varied highly between different classes: Whereas classes such as background or skin could still be detected cor-rectly in many cases, other classes such as pancreas exhibited high performance drops. Joint training of animal and human data (Figure 4: pig+rat+human network) did not help with the discrimination of human tissues.\nIt should be noticed that the intra-species performance values (Dice similarity coefficient (DSC): Figure 4; normalized surface Dice (NSD) Figure A2) are consistent with the state-of-the-art literature [9-11]. Overall the segmentation perfor-mance on human data was lower (0.78 (standard deviation (SD) 0.17)) than on animal data (0.90 (SD 0.09) and 0.90 (SD 0.09) for pig and rat, respectively)."}, {"title": "2.3 Extended data analysis provides reasons for neural network failure", "content": "To quantify the relevance of the species relative to other sources of variation, such as the subject or the specific imaging conditions, we performed a mixed effect model analysis. For both pigs and rats, we followed the standardized recording protocol defined in [13], according to which spectral images from multiple subjects are acquired for a prede-fined set of recording conditions. For each organ, the proportion of variation in observed reflectance was decomposed into (explained) variation by the factors species, subject, image, and angle, as well as residual or unexplained variation, as shown in Figure 5.\nTo facilitate knowledge transfer, a negligible species effect would be desired. However, this is not the case, with no consistent behavior to be observed for all organs. For several organs, the species is even the main source of variability for certain wavelengths. Across all organs, the angle factor and unexplained variation (residuals) only played a minor role.\nBesides the variability analysis of the spec-tra, we performed an analysis to examine the extent to which spectral values matched between organs. Figure 6 accordingly examines the high-dimensional neighborhood of the median spectra. When comparing organ spectra of one species to those of another, it could be observed that the nearest neighbor only rarely agreed in the organ class (low agreement on the diagonal). For exam-ple, porcine spectra of the pancreas were closer to human colon or small bowel spectra than human pancreas spectra. Noticeable exceptions were liver spectra and skin spectra, which were relatively close to each other for all species. In contrast, the nearest neighbors between different human subjects have a much higher agreement."}, {"title": "2.4 Perfusion changes lead to comparable spectral shifts across species", "content": "Our previous analyses clearly showed that the substantial absolute differences of spectral organ signatures across species render naive approaches of knowledge transfer infeasible. Consequently, we investigated whether relative changes in spectra resulting from pathologies exhibited similarities across species. To this end, we focused on tissue malperfusion - an essential aspect of real-world surgeries, which may result in poor tissue discrim-ination performance for neural networks trained primarily on well-perfused tissue (cf. Figure 8).\nThe underlying hypothesis was that the compa-rable pathophysiological mechanisms leading to malperfusion result in similar spectral changes in humans and animals.\nWe thus systematically compared physiologi-cal and malperfused organ spectra (Figure 7). To"}, {"title": "2.5 Xeno-learning addresses spectral perfusion shifts", "content": "To instantiate the concept of xeno-learning for the specific challenge of perfusion shift compen-sation, we developed a method (Figure 2) that learns relative spectral changes from standardized animal data sets and then transfers this knowl-edge to humans via data augmentation during neural network training. In analogy to physics-based data augmentation, we coin this method physiology-based data augmentation.\nAccording to experimental results obtained on independent test sets that were not used during method development, our proposed xeno-learning method is able to transfer relevant pathology-related knowledge encoded in preclinical animal data to humans (Figure 8). In general, malperfused tissues present a challenge to the segmentation"}, {"title": "3 Discussion", "content": "With this systematic, in-depth analysis of spectral organ differences across species, we are the first to demonstrate that spectral knowledge transfer across species is possible, as exemplified by the task of surgical scene segmentation and the transfer of different perfusion states. Based on to the best of our knowledge - the largest HSI database containing 11,268 images from 294 subjects in three species from which 2,445 images have been fully semantically annotated with 12 classes, we derived the following key findings:\n1. Inter-species differences of organ spectra are significant: Different organs across species do not display uniform spectral organ finger-print features. When considering the species, the subject, and imaging related factors as sources of spectral variability, the species is even the main source of variability for certain wave-lengths and organs. This heterogeneity causes state-of-the-art segmentation networks to fail when applied across species.\n2. Shared pathophysiological mechanisms manifest as comparable relative spectral changes across species: Substantial absolute differences of spectral organ signatures across species render naive approaches of knowledge transfer infeasible. However, our study revealed that relative changes in spectra resulting from pathologies exhibit similarities across species.\n3. Xeno-learning enables knowledge trans-fer across species: A proof-of-concept study revealed that the proposed paradigm of learning across species to compensate for quantitative and qualitative data shortage is feasible. From a methodological perspective, the enabling idea was to transfer relative spectral changes via a novel means of physiological data augmentation."}, {"title": "3.1 Strengths and limitations of method", "content": "One of our key observations is that organ dif-ferences are high between species and that seg-mentation networks struggle when applied to another species. Despite that fact, our proposed xeno-learning method is still able to improve the segmentation on malperfused spectra. A key to this success lies in the fact that our xeno-learning method is independent of the absolute organ differ-ences between the species as it captures the relative change from a physiological to a malperfused organ.\nIn this proof-of-concept study, we model rela-tive spectral changes resulting from malperfusion via a linear transformation which is applied sep-arately to each pixel in the image and which consists only of a manageable number of learnable parameters (100 \u00b7 100 + 100 = 10,100 per image pair). This restriction naturally reduces the risk of overfitting, as there is less freedom to account for unwanted side effects (e.g., from outliers in the data) during the optimization process of the transformation. Though simple by design, it has proven to be a powerful tool to model perfusion"}, {"title": "3.2 Strengths and limitations of the study", "content": "The fact that spectra differ across species is not surprising as the basis of spectral tissue properties is the biomolecular composition of the organ-ism, which is highly different between species [14]. The most widely studied and spectrally influen-tial protein is hemoglobin which is known to be built differently between species, hence exhibit-ing different spectral properties under varying environmental conditions and affecting the organs differently [15, 16]. Analogous principles apply for other chromophores such as melanin, myo-globin, or bilirubin [17]. At the same time, it is also known that there are shared pathophysiologi-cal mechanisms across species. This includes the characteristic changes on the absorbance curve of hemoglobin [18-20]. In this paper, we showed that such shared pathophysiological mechanisms mani-fest as comparable relative spectral changes across species, which can then be used for xeno-learning.\nWhile we extensively analyzed the spectral char-acteristics of 11 physiological organs, we restricted our xeno-learning approach to one exemplary scenario: correcting the segmentation of kidneys despite different perfusion states (physiological and malperfused). This decision was made due to two main reasons: (1) kidneys offer a very standardized and controlled setting for inducing pathological organ states through their singular hilar blood supply by clamping, and (2) this is a relevant clini-cal pathology regularly encountered during kidney tumor surgery or kidney transplantation. Addition-ally, kidney pathology been of interest in other studies for differentiating arterial ischemia and venous congestion [21], assessing kidney function in human kidney allotransplantation [22] or mon-itoring oxygen saturation during normothermic machine perfusion [23].\nGenerally, opportunities for systematic and standardized HSI data acquisition are highly lim-ited in humans for ethical and regulatory reasons. Furthermore, human data rarely captures perfu-sion changes in isolation without the influence of other pathologies (e.g., thrombosis), surgical inter-ventions (e.g., cauterization), or side effects from surgical procedures like kidney transplantations (e.g., medication or host-versus-graft reactions). Organ surfaces may also be less exposed than in animal experiments, such as in cases with adherent renal fat. All these factors make human data acqui-sition and processing especially challenging. This may also explain the generally lower segmentation performance of neural networks on human data shown in Figure 4. We address the human data acquisition issues with xeno-learning. The animal malperfusion states, induced with high standard-ization by hilar clamping and recordings, possess a high temporal resolution, as evidenced by the num-ber of image data points in Figure 8. Knowledge acquired through these systematic experiments have successfully been transferred to a human application."}, {"title": "3.3 Comparison to other (multi-species) studies", "content": "Previous studies which included multiple species focused purely on spectral analysis without the aim to transfer knowledge in the context of AI training. For instance, [24], [21] and [25] compared spectra from humans and pigs with a focus on the gastric conduit, kidney perfusion states, and on organs of the biliary system, respectively. [24] included gastric conduit data from 10 patients and found comparable StO2 values across species for the malperfusion subgroup. The kidney results of [21] from 17 patients indicate similarities in the malperfusion spectra in line with our results. The presented data partly overlaps our data. While only healthy organs of the biliary system from the seven patients were considered in [25], significant spectral differences between humans and pigs could be observed, further supporting our findings. It should be noted that these works, however, used significantly lower sample sizes in the range of 7 to"}, {"title": "3.4 Impact and future directions", "content": "While our xeno-learning paradigm primarily demonstrates the potential for enhanced general-izability across species, it also holds significant promise for the generalization of other variations. For instance, insights into disease models, various pathologies, or imaging conditions observed in one species can potentially be transferred to others. One prominent example of a use case is cancer, a disease marked by differences in perfusion and oxygenation between physiological and pathologi-cal tissue. Overall, the expansion of xeno-learning to different use cases will require users to iden-tify shared mechanisms across species and use that prior knowledge to enable the knowledge transfer for AI.\nSimilarly, while our proposed augmentation method is primarily utilized for xeno-learning, its application is by no means limited to cross-species learning. From the perspective of transfer learning in artificial intelligence systems, the method can be broadly employed to identify variations within a source data distribution and subsequently integrate these insights during training within a target data distribution. For instance, observed tissue necro-sis, tissue fibrosis or tissue inflammation in one population can be effectively applied to another population.\nNotably, our xeno-learning method employs a simple linear model to transform between two spectral states - in our case, physiological and malperfused. Due to its simplicity, this method could contribute to the understanding of such spectral changes, for example by analyzing the properties of our transformation matrices. This is especially crucial for human data, which is often confounded by therapy effects, comorbidities, or surgical procedures that are not present in animal experiments [29, 30].\nOur results can impact the planning of future animal studies and their potential to be applied to humans. For example, since rat liver is closer to human liver than pig liver, the rat model may be more appropriate for future studies targeting liver pathologies. In contrast, for other organs such as pancreas, neither the pig nor the rat model would be an appropriate candidate."}, {"title": "3.5 Conclusion", "content": "In summary, we pioneered a new concept of knowl-edge transfer in the general context of AI-based image analysis. Our study with HSI data from three species demonstrated the potential of large-scale secondary use of preclinical animal data"}, {"title": "4 Methods", "content": ""}, {"title": "4.1 Data Collection", "content": "The HSI animal data was collected at Heidelberg University Hospital following approval from the Committee on Animal Experimentation of the regional council Baden-W\u00fcrttemberg in Karlsruhe, Germany (G-161/18, G-262/19 and G-62/23). The animals were treated in accordance with Ger-man laws for animal use and care, as well as the directives of the European Community Council (2010/63/EU).\nThe HSI human data was obtained during the SPACE trial (SPectrAl Characterization of organs and tissues during surgery) at Heidel-berg University Hospital, with approval from the Ethics Committee of the Medical Faculty of Heidel-berg University, Germany (S-459/2020). The trial adhered to the ethical principles of the Declaration of Helsinki [31] and the principles of Good Clini-cal Practice [32]. The trial's reporting followed the recommendations of the Consolidated Standards of Reporting Trials (CONSORT) guideline [33]. The SPACE trial was registered with the Research Registry (researchregistry6281) on November 23, 2020."}, {"title": "4.2 Hyperspectral image acquisition", "content": "The HSI camera system Tivita\u00ae Tissue (Diaspec-tive Vision GmbH, Am Salzhaff, Germany) was utilized to collect the HSI data. This system captured hyperspectral images in a push-broom manner with a spectral resolution of approximately 5 nm, covering the spectral range from 500 nm to 1,000 nm. The resulting data cubes have dimen-sions of 640 \u00d7 480 \u00d7 100 (width \u00d7 height \u00d7 number of spectral channels). The camera system imaged an area of about 20 \u00d7 30 cm. An integrated dis-tance calibration system, consisting of two light marks that overlap when the distance is correct, ensured an imaging distance of around 50 cm. The image acquisition process took approximately seven seconds.\nIn addition to the HSI data cubes, the camera system computed functional parameters like StO2 [4]. Furthermore, RGB images were reconstructed from the HSI data by combining spectral channels that capture red, green, and blue light. More tech-nical details on the hardware and the performed calculations can be found in [34].\nTo prevent spectral distortion from stray light, all other light sources were turned off during image capture, and window blinds were closed. Motion artifacts were minimized by (1) mounting the cam-era on a swivel arm to keep it stationary during image capture, thus eliminating camera motion, and (2) capturing images from static scenes with no surgeon-induced object movements. Consequently, any motion artifacts would only be due to natural causes like respiration and heartbeat. The camera perspectives were chosen to provide a clear view of all organs of interest in the scene.\nFor the pig and rat species, standardized record-ings were carried out with a predefined image acquisition protocol which is described in [13]. This data is used in Figure 5.\nFor the acquisition of animal data, the organs were mobilized and prepared to enable the spectral recording of representative tissue surfaces. Renal malperfusion in pigs was induced by preparing the renal hilum and applying strong bulldog clamps. Renal malperfusion in rats was induced by prepar-ing the aorta and caval vein and applying Yasargil clamps."}, {"title": "4.3 Hyperspectral image annotation", "content": "From the 11,268 images, 2,445 have been fully-semantically annotated. For the remaining 8,823 images, polygon annotations have been carried out to annotate highly-representative areas of the organ. All annotations were done based on the reconstructed RGB image.\nThe process of the polygon annotations is the same as described in [3] and the standardized recordings for the pig species are publicly avail-able [13]. Polygon annotations are used in the mixed effects analysis of Figure 5 and for several malperfused tissue annotations.\nThe semantic physiological porcine annotations are the same as described in [9] where the semantic annotation process was carried out by two different medical experts. Conflicts were revised by the same"}, {"title": "4.4 Data preprocessing", "content": "To mitigate sensor noise and transition the acquired HSI data from radiance to reflectance, the raw HSI data cubes were automatically calibrated using pre-recorded white and dark calibration files by the camera system, as outlined in [4]. Cali-bration of the camera was performed before each surgery by taking a new white and dark image to compensate for various sources of signal distortion, such as attenuation effects of the light source [36].\nAfter exporting the HSI cubes from the camera system, each pixel in the HSI cube was L1-normalized across the spectral channels to account for multiplicative illumination changes, such as those caused by fluctuations in the measurement distance."}, {"title": "4.5 Data statistics", "content": "The hyperspectral imaging database used in this study is composed of 11,268 images from 294 sub-jects in three species. Annotation has been carried out for 12 classes (11 organs and background). These organs were selected as they were available for all three species due to anatomical, anesthesio-logical and technical considerations. Malperfused kidney tissue was captured on 511 pig images, 1,597 rat images, and 71 human images. An overview of the database is given in Figure A1."}, {"title": "4.6 Segmentation models", "content": "The employed segmentation networks are the same as described in [9] with the organ transplanta-tion extension proposed in [10, 11]. In short, the full HSI data cube is passed on to a U-Net with an efficientnet-b5 encoder pre-trained on the Ima-geNet dataset. Dice loss and cross-entropy (CE) loss are equally weighted and computed for all valid pixels inside a batch, i.e., every pixel which does not belong to one of the ignored classes.\nThe same hyperparameters were used for all models. Adam [37] was used as an optimization algorithm with an exponential learning rate scheme (initial learning rate: \u03b7 = 0.001, decay rate y = 0.99, Adam decay rates \u1e9e\u2081 = 0.9and B2 = 0.999). Training was carried out with a batch size of 8 for 100 epochs with each epoch consisting of 500 images. During the last 10 epochs, stochastic weight averaging was applied [38]. Underrepre-sented classes were oversampled to ensure an equal class distribution.\nDuring training, images were augmented to increase the size and the diversity of the train-ing data. First, the same affine transformations as described in [9] (shift, scale, rotate and flip oper-ations) were applied. Then, target tissues in the images (kidney in our study) were transformed with our proposed xeno-learning method. Finally, the organ transplantation method proposed in [10, 11] followed by a L1 re-normalization of the image was applied."}, {"title": "4.7 Training and validation setup", "content": "A similar training and validation setup was used for all networks. Validation was carried out based on a nested cross-validation scheme to provide a more robust performance estimation that is based on the entire dataset [39]. The number of outer folds was set to 3 and the number of inner folds was set to 5. The folds were generated based on iterative stratification for multi-labeled data [40] to ensure a similar label distribution across folds. Final predictions for an image were obtained by ensembling the softmax output from all available networks.\nDuring development of our method, only the pig species was considered to keep data from all other species as untouched test sets. The xeno-learning approach was developed based on a pig2pig valida-tion scheme where perfusion shifts were learned in one subject set and applied to a disjoint subject set.\nFollowing the recommendations in [41] and to overcome the limitations of individual metrics, we assessed the segmentation performance via the"}, {"title": "4.8 Linear mixed model analysis", "content": "Separate linear mixed models for each wavelength and organ were employed to analyze explained vari-ation in order to evaluate the relevance of factors contributing to changes in the observed spectrum (Figure 5). The proportion of explained variance was derived through the empirical decomposi-tion of explained variation based on the variance components version of the mixed model [42].\nMore precisely, linear mixed models were fitted for each organ and wavelength separately, with fixed effects for the factor angle and the factor species as well as random effects for the factor subject and the factor image:\nreflectanceijk = a + speciesijk. B + angleijk0 + di + Vij + Eijk, where \nreflectanceijk = a + speciesijk. B + angleijk0 + di + Vij + Eijk. (1)\nfor repetition k = 1,..., 3 of image j = 1, ..., ni of animal i = 1,..., 24 (11 pigs and 13 rats).\nThe number of images ni varied per animal and organ. Here, a denotes a fixed intercept, speciesijk is a row vector of length 2 indicating the species rat or pig with \u1e9e denoting the corresponding fixed effect. Similarly, @ is a vector of fixed effects corresponding to the camera angles (\"perpendicu-lar to tissue surface\", \"25 degree from one side\", \"25 degree from the opposite side\"). The random intercept di ~ N(0, 0) describes animal specific variation, and the random intercept Yij ~ N(0, \u03c3\u00b2) describes image specific variations. The residuals Eijk ~ N(0, 2) capture the variability between repeated recordings of the same image. Within the model, we assume that the random effects and the residuals are stochastically independent.\nAdditionally, 95% pointwise confidence inter-vals were obtained based on parametric bootstrap-ping with 500 replications for an indication of the uncertainty in the relevance estimates."}, {"title": "4.9 Xeno-learning", "content": "The driving insight of our concept is that shared common pathophysiological mechanisms manifest in comparable relative spectral changes. In our approach (cf. Figure 2), we leverage this insight to transfer knowledge across species through data aug-mentation, which has already been demonstrated to be a powerful tool for addressing other domain shifts in spectral imaging [10]. Specifically, we instantiate the concept for perfusion knowledge transfer by first modeling the knowledge in the source species and then applying this knowledge in the target species.\nLearning relative changes in the source species\nWe encode relative spectral changes in a transfor-mation matrix that can be applied to any species. For the specific case of perfusion, a set of linear transformations ti (sp) are learnt that transform physiological spectra sp to malperfused spectra Sm (the transformation is applied independently for each spectra). To cover a variety of different perfusion states, we learn a whole set of transforma-tions each of which represents the spectral change between physiological and malperfused kidneys. Each transformation is a linear model represented by two parameters: a weight matrix Wi \u2208 R100\u00d7100 and a bias vector bi \u2208 R100, in analogy of a multivariate linear regression model, so that the"}]}