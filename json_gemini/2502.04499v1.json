{"title": "Revisiting Intermediate-Layer Matching in Knowledge Distillation: Layer-Selection Strategy Doesn't Matter (Much)", "authors": ["Zony Yu", "Yuqiao Wen", "Lili Mou"], "abstract": "Knowledge distillation (KD) is a popular method of transferring knowledge from a large \"teacher\" model to a small \u201cstudent\u201d model. KD can be divided into two categories: prediction matching and intermediate-layer matching. We explore an intriguing phenomenon: layer-selection strategy does not matter (much) in intermediate-layer matching. In this paper, we show that seemingly nonsensical matching strategies such as matching the teacher's layers in reverse still result in surprisingly good student performance. We provide an interpretation for this phenomenon by examining the angles between teacher layers viewed from the student's perspective.", "sections": [{"title": "1 Introduction", "content": "Large language models have achieved impressive performance in various NLP tasks (Brown et al., 2020; Devlin et al., 2019). However, they need a large number of parameters, making the models cumbersome and difficult to run in resource-restricted scenarios. Knowledge distillation (KD; Hinton et al., 2015) is a widely adopted method to reduce model parameters by training a small \u201cstudent\" model from a large \u201cteacher.\" With KD, the student is often able to retain most of the teacher's performance while using a fraction of the its parameters (Sun et al., 2020).\nCommon KD approaches can be generally divided into two categories: prediction matching and intermediate-layer matching. Matching the prediction is usually mandatory, as it informs the student of the task to solve. This can be achieved by minimizing the divergence of predicted distributions (Hinton et al., 2015; Wen et al., 2023) or using reinforcement learning (Li et al., 2024).\nIntermediate-layer matching distills the teacher's hidden states (i.e., intermediate layers) to the student (Sun et al., 2019; Jiao et al., 2020; Wang et al., 2021). This approach often involves minimizing the distance between the student's and teacher's hidden states (usually with a linear mapping if the dimensions do not match). Since the student model is often shallower than the teacher, a layer-selection strategy is required to specify which teacher layer is matched to each student layer.\nRecently, researchers have explored various layer-selection strategies. Sun et al. (2019) match the student's layers to evenly spaced teacher layers; Passban et al. (2021) learn an attention mechanism over the teacher's layers; Haidar et al. (2022) match the student's layers to randomly selected layers from the teacher, in order; and Wang et al. (2021) matches the last student layer to a teacher layer close to the end. Overall, there lacks consensus on the best strategy for layer selection, and different strategies often result in unexpectedly similar performance. For example, Sun et al. (2019) reports roughly 0.5 points of difference in accuracy between different layer-selection strategies, and Jiao et al. (2020) reports roughly 1-2 points difference in accuracy\u00b9.\nIn this work, we observe an intriguing phenomenon that the layer-selection strategy does not affect intermediate-layer matching for KD (much). Surprisingly, even matching teacher layers to the student in reverse order yields similar performance to forward matching. However, we do see that intermediate-layer matching (regardless of the layer-selection strategy) helps KD, compared with no intermediate-layer matching."}, {"title": "2 Background and Related Work", "content": "Knowledge Distillation (KD) is a method of transferring rich knowledge contained in a teacher model to a student model. To inform the student of the task, it is essential to match the student's and teacher's predictions. For the teacher distribution p and student distribution qe, Hinton et al. (2015) suggest minimizing the Kullback-Leibler (KL) divergence between them:\n$\\mathcal{L}_{KL}(\\theta_s) = \\mathbb{E}_{y \\sim p(y|x)}[log \\frac{p(y|x)}{q_{\\theta_s}(y|x)}]$ (1)\nwhere x represents the input, and the output y (conditioned on x) is sampled from p. The student's parameters $\\theta_s$ are optimized, whereas the teacher's parameters are frozen.\nOther than minimizing KL, different prediction matching approaches have been proposed. When the teacher distribu-tion is diverse, for example, the reverse KL divergence (Tu et al., 2020; Gu et al., 2024) is used due to its mode-seeking behavior, i.e., the student only focuses on one of the high-probability regions in the teacher distribution (Bishop, 2006). Wen et al. (2023) propose an f-divergence KD framework, where symemtric divergences (such as Jensen-Shannon and total variation distance) provide a balance between mode averaging and mode seeking. Reinforcement learning can also be applied to KD (Hao et al., 2022; Li et al., 2024), which makes the student aware of its prefix and addresses the exposure bias problem (Bengio et al., 2015).\nRegarding intermediate-layer matching, it distills the teacher's hidden states, thus providing additional supervisory signals to the student (Sun et al., 2019). Let $M = \\{(s_i, T_i)\\}_{i}$ be the mapping between student and teacher layers, i.e., the $s_i$th layer of the student is mapped to the $T_i$th layer of the teacher. Intermediate-layer matching typically penalizes the distance between the matched layers, given by\n$L_{hid}(\\theta_s, \\{A_i\\}_i) = \\sum_i dist(A_i h_i^{(s)}, h_i^{(t)})$ (2)\nwhere dist is a distance metric (such as mean squared error). The trainable linear operator $A_i$ transformers the student's hidden state $h_i^{(s)}$ to the space of the teacher's hidden state $h_i^{(t)}$, when their dimensions do not match. Otherwise, $A_i$ may be an identity matrix.\nIntermediate-layer matching can be applied to different types of representations. Traditionally, this is achieved by matching the student's and teacher's activations (Sun et al., 2019; Sanh, 2019). Other studies match attention log-its (Jiao et al., 2020), attention's query-key-value relations (Wang et al., 2021), and cross-sample relations (Park et al., 2019; Huang et al., 2023). In our work, we focus on matching activations because it is the most fundamental approach in intermediate-layer matching.\nVarious layer-selection strategies have been proposed for matching a shallow student to a deep teacher. Sun et al. (2019) and Jiao et al. (2020) suggest mapping evenly spaced teacher layers to the student. Passban et al. (2021) match each student layer to a weighted combination of all teacher layers to retain more knowledge. Haidar et al. (2022) randomly reselect a sequence of teacher layers to match with the student after each epoch, so that the student is exposed to different teacher layers.\nOverall, different layer-selection strategies perform unexpectedly similarly (as mentioned in \u00a71), which inspires our work. We observe an intriguing phenomenon that the layer-selection strategy does not matter (much), even with unusual mappings such as reverse order; we also provide an interpretation for this phenomenon."}, {"title": "3 Approaches and Setups", "content": "In this section, we begin by outlining the layer-selection strategies. We then describe the experimental setups, including datasets, metrics, and neural network hyperparameters."}, {"title": "3.1 Layer-Selection Strategies", "content": "Intermediate-layer matching requires a strategy to select which teacher layers are matched with which student layers. In this study, we examine the following layer-selection strategies.\nForward Matching. In this variant, lower student layers are matched to lower teacher layers. In particular, we follow Sun et al. (2019) and select evenly spaced teacher layers for matching.\nAll-to-One Matching. In this variant, all student layers are matched to the middle teacher layer. While matching to one layer is inspired by previous studies (Wang et al., 2020, 2021), we slightly modify their approaches (i.e. matching all student layers instead of one), for fair comparison with the rest of our settings.\nReverse Matching. We propose a counterintuitive strategy, where matching is in reverse order (i.e., lower stu-dent layers matched to upper teacher layers). This seemingly nonsensical strategy sheds light on the mechanism of intermediate-layer matching.\nRandom Matching. We choose the same teacher layers as forward matching, then randomly shuffle the order. The order is maintained during distillation. We average the performance across five seeds to evaluate the effect of different random mappings.\nNote that the intermediate-layer matching loss is combined with the predictor's KL loss by $L = L_{KL} + \\lambda L_{hid}$, where $\\lambda$ is a hyperparameter to balance the losses. In addition, we compare the above strategies the No Matching baseline, which disables intermediate-layer matching. In other words, only KL loss is involved in the KD process."}, {"title": "3.2 Datasets and Models", "content": "We evaluate our layer-selection strategies on a variety of classification and generation tasks.\nGLUE. The General Language Understanding Evaluation (GLUE) benchmark is a popular suite for natural language classification. From GLUE, we chose MNLI (Williams et al., 2018), QQP2, QNLI (Rajpurkar et al., 2016), and SST-2 (Socher et al., 2013), as these tasks have large training sets and produce robust model performance. For each task, we finetuned the 12-layer BERTBase (Devlin et al., 2019) as the teacher. We adopt standard evaluation metrics, namely, accuracy for all tasks and F\u2081 as an additional metric for QQP.\nDART. The DART dataset (Nan et al., 2021) is a popular data-to-text generation task. We followed Nan et al. (2021) and finetuned BARTLarge (Lewis et al., 2020) with 12 encoder and 12 decoder layers, which is the teacher model in the experiment. We report BLEU scores measuring textual overlap (Papineni et al., 2002).\nWMT16 En-Ro. The WMT16 dataset (Bojar et al., 2016) provides parallel text between six different language pairs. For our experiments, we followed the setups in Wen et al. (2023), which chose the English\u2013Romanian translation direction and used 100K samples from the 614K total samples for efficiency considerations. We also followed Wen et al. (2023) and finetuned 12-layer T5Base (Raffel et al., 2020) as the teacher, which has the same number of layers as the DART experiment. We also report BLEU scores as the evaluation metric."}, {"title": "4 Results and Analysis", "content": "Main Results. In Table 1, we present the main results of our layer-selection experiments. As seen in Lines 1-2, our finetuned teacher models perform similarly to previous work (Devlin et al., 2019; Nan et al., 2021; Wen et al., 2023), showing that we have successfully set up the environment for KD experiments.\nWe examine the performance of different layer-selection strategies. As shown in Lines 4\u20137 and 9\u201312, the student model achieves similar results across different strategies, with only 2-3 points difference in accuracy for classification tasks and 1-2 points difference in BLEU for generation tasks. Notice that Reverse Matching and Random Matching appear nonsensical, when in fact they still achieve close performance to Forward Matching, often outperforming No Matching. The results show that layer-selection strategy has an unexpectedly small effect on student performance; this highlights the limitations of previous research on layer-selection strategies.\nIt should be emphasized that intermediate-layer matching indeed helps KD compared with No Matching\u00b3, even though the matching strategy does not play a significant role. On MNLI, for example, all strategies improve upon No Matching by ten points in the setting of random initialization and two points when the student weights are initialized from the teacher.\nNext, we take a closer look at how different layer-selection strategies behave under the two parameter initialization settings. To reiterate, copying the teacher's parameters for initialization is a simple and practical method to quickly transfer the teacher's knowledge to the student (Sanh, 2019; Shleifer and Rush, 2020). In our experiments, it is evident that parameter copying indeed leads to significant improvements compared to random initialization. Nonetheless, the general trend is consistent: intermediate-layer matching is important, while layer-selection methods do not matter (much).\nThe Angles of Matching Different Layers. A curious question arises from these observations: why does intermediate-layer matching help KD but different layer-selection strategies perform similarly? To answer this, we measure the angles between the teacher's layers, viewed from the student. Specifically, we measure the angles formed"}, {"title": "5 Conclusion", "content": "In this paper, we observe an intriguing phenomenon that although intermediate-layer matching helps knowledge dis-tillation, the layer-selection strategy does not matter (much); we also provide an interpretation based on the angles of teacher and student layers. Our work suggests potential limitations and oversights in previous work, where re-searchers present various heuristic layer matching methods when training their distilled systems, but their effect is not comprehensively studied."}, {"title": "6 Limitations", "content": "In our work, we have experimented with various setups, including six tasks (four classification and two generation), three model architectures, and two parameter initialization methods. Although the results are generally consistent, there is one exception that intermediate-layer matching does not help in the DART setup. Nevertheless, this is under-standable as empirical findings are usually not theoretically guaranteed.\nIt is also worth mentioning that our work does not suggest intermediate-layer matching is unhelpful for KD. Rather, we present an interesting phenomenon that the layer-selection strategy plays an insignificant role in the process. We argue that future studies on layer selection should have closer examination and more rigorous comparison on its effect."}, {"title": "A Analysis of Student Depths", "content": "We validate our intriguing phenomenon across students with different depths. Due to the limit of computing resources, we selected MNLI as the representative classification task, but include both DART and WMT16 En-Ro generation tasks. Specifically, we experimented with student models containing three, six, and nine layers, initialized by copying the teacher's weights. As seen in Table 2, different layer-selection strategies show similar performances, confirming that the layer-selection strategies do not matter (much) across student models with various depths."}]}