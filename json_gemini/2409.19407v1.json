{"title": "Brain-JEPA: Brain Dynamics Foundation Model\nwith Gradient Positioning and Spatiotemporal Masking", "authors": ["Zijian Dong", "Ruilin Li", "Yilei Wu", "Thuan Tinh Nguyen", "Joanna Su Xian Chong", "Fang Ji", "Nathanael Ren Jie Tong", "Christopher Li Hsian Chen", "Juan Helen Zhou"], "abstract": "We introduce Brain-JEPA, a brain dynamics foundation model with the Joint-\nEmbedding Predictive Architecture (JEPA). This pioneering model achieves\nstate-of-the-art performance in demographic prediction, disease diagnosis/prognosis,\nand trait prediction through fine-tuning. Furthermore, it excels in off-the-shelf\nevaluations (e.g., linear probing) and demonstrates superior generalizability across\ndifferent ethnic groups, surpassing the previous large model for brain activity\nsignificantly. Brain-JEPA incorporates two innovative techniques: Brain Gradient\nPositioning and Spatiotemporal Masking. Brain Gradient Positioning introduces\na functional coordinate system for brain functional parcellation, enhancing the\npositional encoding of different Regions of Interest (ROIs). Spatiotemporal Masking,\ntailored to the unique characteristics of fMRI data, addresses the challenge of het-\nerogeneous time-series patches. These methodologies enhance model performance\nand advance our understanding of the neural circuits underlying cognition. Overall,\nBrain-JEPA is paving the way to address pivotal questions of building brain func-\ntional coordinate system and masking brain activity at the AI-neuroscience interface,\nand setting a potentially new paradigm in brain activity analysis through downstream\nadaptation. Code is available at: https://github.com/Eric-LRL/Brain-JEPA.", "sections": [{"title": "1 Introduction", "content": "Understanding large-scale brain activity data is crucial for deciphering the complex mechanisms\nunderlying cognitive processes and human behavior. Functional magnetic resonance imaging (fMRI)\ncaptures blood-oxygen-level dependent (BOLD) signals that reflect regional brain activity. It emerges\nas an indispensable tool in neuroscience for identifying the neural bases of cognitive processes [1, 2, 3].\nDeep learning approaches have been developed for fMRI analysis, improving brain disease diagnosis\nand deepening insights into cognition and behavior [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]. Despite notable\nadvances, these task-specific models suffer from limited generalizability and adaptability to other\ntasks. In addition, they fail to leverage the vast amounts of unlabeled fMRI data available [14, 15].\nArtificial intelligence (AI) is experiencing a paradigm shift from task-specific training to building\nfoundation models that are trained on extensive data using self-supervision at scale [16]. Unlike the\nmodels with singular functions, foundation models can be adapted to a diverse array of downstream\ntasks. Large language models such as GPT [17] and LLaMA [18] have shown significant potential in\nnatural language processing, with expansive applications in healthcare, biomedicine, and beyond [16].\nTherefore, rather than focusing on the original brain activity time series, the inherent noise and\nsparse information density of fMRI lead us to explore the latent space of fMRI time series extracted\nfrom a strong encoder (e.g., Vision Transformer (ViT) [22]). It potentially offers a higher SNR\nafter \"compression\", achieving a greater level of abstraction that captures subtle yet crucial patterns\n[23]. Recently, Imaged-based Joint-Embedding Predictive Architecture (I-JEPA) has been proposed\nas a non-generative architecture for self-supervised learning from images [21]. It predicts the\nrepresentations of various target blocks rather than reconstructing the masked input like MAE during\npretraining. By predicting representations in the latent space, I-JEPA enhances the semantic quality\nof learned representations and boosts scalability and efficiency.\nTraining a brain dynamics foundation model using a JEPA-like architecture might offer advantages\nover the MAE approach. However, the distinct spatiotemporal characteristics of fMRI data make\ndirect application of the JEPA architecture suboptimal: \u25cf Positional embeddings in transformer play\na crucial role by incorporating information about the order or position of tokens in the input data (e.g.,\nthe order of different words in a sentence or the locations of pixels in an image) [24]. However, there\nis no such natural \"order\" for different ROIs across the 3D brain volume in fMRI. BrainLM utilizes\nanatomical positions to label each ROI [14], yet it does not account for brain functional parcellation,\nwhere nearby anatomical ROIs might exhibit rather different brain activation patterns represented\nby a lack of local coherence in fMRI data [25]. \u25cf I-JEPA employs a random multi-block selection\nof context and target. However, unlike images, fMRI presents complex patterns across both spatial\nand temporal domains. Given the smaller sample size and sparser information density in fMRI datasets\ncompared to datasets like ImageNet [26], learning in fMRI requires a stronger inductive bias. This\nwould enhance the efficiency of training models by better capturing the underlying patterns specific to\nbrain activity. Given the unique challenges presented by fMRI data, there is a pressing need to develop\na functinal coordinate system and a tailored masking strategy for large-scale pretraining on fMRI data.\nThese neglected yet crucial questions of developing a functional coordinate system and a masking\nstrategy for large-scale pretraining with fMRI data, lie at the intersection of AI and neuroscience,\nhighlighting important interdisciplinary challenges.\nTo address these gaps, here we introduce Brain-JEPA, a brain dynamics foundation model with the\nJoint-Embedding Predictive Architecture (JEPA). Instead of reconstructing masked inputs during\npretraining, Brain-JEPA predicts abstract representations of sampled targets from the observation.\nWe propose two innovative techniques to enhance model performance and address key questions in\nAl for neuroscience: First, Brain Gradient Positioning provides a brain functional coordinate system\nfor positional embedding of brain functional parcellation (Section 3.1). Second, Spatiotemporal\nMasking offers a tailored masking strategy for the heterogeneous time-series patches inherent in\nfMRI (Section 3.2). Moreover, in downstream experiments, our proposed Brain-JEPA achieves\nstate-of-the-art results in demographic prediction, disease diagnosis/prognosis, and trait prediction\nthrough fine-tuning. It also excels in off-the-shelf evaluations (e.g., linear probing), and shows superior\ngeneralizability across different ethnic groups. Brain-JEPA enhances brain activity analysis and\ndeepens our understanding of critical AI-neuroscience questions related to constructing functional\ncoordinate systems and developing spatiotemporal masking strategies."}, {"title": "2 Related Work", "content": "Task-specific Models for fMRI (state-of-the-art). SVR and MLP have been used in fMRI analysis,\nutilizing Pearson correlation matrices derived from fMRI time series as input [8, 9]. Deep learning\nmodels have substantially advanced fMRI analysis in recent years. BrainNetCNN [6] introduces a\nconvolutional neural network (CNN) with specialized convolutional filters tailored for brain network.\nBrainGNN [5] utilizes ROI-aware graph neural networks (GNNs) to effectively harness functional\nbrain network information, incorporating a pooling operator to highlight key ROIs. More recently,\nBrain network transformer (BNT) [4] employs transformer encoders to generate embeddings for ROIS\nbased on Pearson correlation matrices, alongside a readout layer designed to identify clusters within\nthe brain. Swift [27] applies Swin Transformer architecture [28] to process brain functional data. As\nnoted in Section 1, these task-specific models have limited generalizability and adaptability across\ndifferent tasks, and fail to utilize extensive unlabeled fMRI data.\nThe fMRI Foundation Model. BrainLM [14] stands out as the first fMRI foundation model,\nemploying MAE for self-supervised pretraining of fMRI data. In this approach, fMRI time series\nare treated as images and patchified. The training goal is to reconstruct the masked patches of the\ntime series. As outlined in Section 1, BrainLM exhibits several limitations: 1) Direct reconstruction\nof masked input may not be suitable for inherently noisy data with low information density, such\nas fMRI. It complicates the differentiation between noise and signal, making it difficult to capture\nunderlying patterns. 2) Generative architectures like MAE result in suboptimal performance in linear\nprobing, a critical method for evaluating learned representations. 3) The absence of comparisons with\nstate-of-the-art models and evaluations limited to Caucasian cohorts restricts its broader applicability.\nBrainMass [29], a concurrent work in large-scale self-supervised learning for neuroimaging, focuses\non brain network analysis rather than brain dynamics, distinguishing it from our research."}, {"title": "3 Method", "content": "In this section, we outline the methodology of Brain-JEPA. Instead of reconstructing masked patches of\nfMRI time series, Brain-JEPA operates in the latent space, as depicted in Figure 1. With the observation\nblock excluded, the input data is divided into three non-overlapping regions: Cross-Time (\u03b1), Cross-\nROI (\u03b2), and Double-Cross (\u03b3). This division forces the model to engage in forecasting time series,\ngeneralizing across unseen ROIs, and predicting time series for unseen ROIs. Section 3.1 details the\nBrain Gradient Positioning we proposed, which encodes the functional relationships among different\nROIs, serving as a brain functional coordinate system in the brain's functional organization. In Section\n3.2, we introduce Spatiotemporal Masking, which injects a strong inductive bias during the masking\nprocess, leading to faster convergence during pretraining and superior performance in downstream tasks."}, {"title": "3.1 Brain Gradient Positioning", "content": "We propose Brain Gradient Positioning,\nwhich provides a brain functional coordi-\nnates system based on the functional con-\nnectivity gradient. Positional embeddings\nare crucial in transformer architectures, as\nthey encode information about the posi-\ntions of tokens in a sequence. These em-\nbeddings can be implemented using fixed\nsine and cosine functions across various fre-\nquencies [24] or through learnable embed-\ndings that adapt during training [30]. How-\never, the integration of positional informa-\ntion into fMRI time series has long been ne-\nglected. fMRI data, incorporating complex\nspatiotemporal information, requires sepa-\nrate consideration of its temporal and spatial\ndomains. The temporal domain, represent-\ning timesteps during scanning, is well-suited for conventional sine and cosine positional embeddings,\nas the time series in each ROI is sequentially ordered by time. However, this method is not appropriate\nfor the spatial domain, where ROIs across brain volumes lack a simple, inherent order, making sine and\ncosine embeddings unsuitable for capturing spatial relationships. Anatomical locations of ROIs offer an\nalternative to sine and cosine functions [14] but fall short in capturing functional parcellation. Spatially\nadjacent ROIs can exhibit significantly different brain activation patterns, reflecting the inherent lack\nof local coherence in fMRI data [25].\nThe functional connectivity gradient is a continuous measure that captures the functional relations\namong different ROIs. Each attribute in the gradient represents an axis in the latent space of brain\nregions and networks. The relative distance between different ROIs indicates the similarity in their\nconnectivity (i.e., shorter distance means higher similarity in connectivity). The concept of a spatial\ngradient as conceptualized by Mesulam in 1998 entailed a synaptic hierarchy that supports cognitive\nprocesses [31]. Recent studies have built upon this concept, revealing that brain networks in adult\nhumans and macaques exhibit linear distributions across different gradient axes [32]. Using this\nmethodology, it has been shown that these gradients reflect the functional changes related to age\n[33, 34, 35, 36, 37], cognition [37, 38] and brain diseases [35, 39, 40]. These gradients together provide\na framework to assess the relationship between brain regions based on their relative positioning across\ndifferent gradient axes.\nBefore deriving the gradients, we first calculate a non-negative affinity matrix $A(i,j)$ (a graph Lapla-\ncian) as follows:\n$A(i,j)=1-\\frac{1}{\\pi} cos^{-1}(\\frac{c_i^T c_j}{|| C_i |||| C_j ||})$\nwhere $c_i$ and $c_j$ represents the features (functional connectivity) across the ROI $i$ and $j$, respectively.\nGradients are then derived using diffusion map [41, 42], a nonlinear dimension reduction method used\nto identify the underlying manifold structure of the data. We can obtain the diffusion matrix $L_8$ and the\ndiffusion operator $M_8$ from A as follows:"}, {"title": "3.2 Spatiotemporal Masking", "content": "Observation. Brain-JEPA aims to predict representations of multiple target blocks based on the\nrepresentation of a single observation block. For an input fMRI time series, the temporal signal for\neach parcel is divided into patches after shuffling ROIs, each containing p time points (dash boxes in\nFigure 1). The observation block \u00e6 is obtained by randomly sampling a block within the range {\u03b7\u03c1,\n\u03b7\u03b3}. \u03b7\u03c1 specifies the range ratio along the ROI dimension, and \u03b7\u03b3 pertains to the timestep patches\n(10 in total). Subsequently, \u00e6 is fed through the observation encoder fe, generating a corresponding\npatch-level representation sx:\n$Sx={Sxj}j\u2208Bx$\nwhere B represents the mask associated with the observation block \u00e6, sx\u2081 is the representation of the\njth patch.\nTargets. Given a single observation, the model is trained to predict other parts of the fMRI within\nthe latent space. Random sampling of targets like MAE [19] might allow the model to learn shortcuts\n(e.g., interpolation of time series) or rely heavily on simpler, more frequent patterns in the data, which\ncould limit its generalizability. It is crucial to recognize that patches in fMRI vary spatially depending\non the positions in their brain functional organization, and temporally regarding brain states and task\nconditions. The nonlinear relationship among brain networks further complicates the interactions\nbetween different brain patches.\nAs shown in Figure 1, we categorize the remaining parts (with the observation excluded) into three\ndistinct and non-overlapping regions: Cross-ROI (\u03b1), Cross-Time (\u03b2), and Double-Cross (\u03b3). For\ntargets in the \u03b1 and \u03b2 regions, the model should generalize the observation across different ROIS\nspatially or timesteps temporally. For targets in the \u03b3 regions, which are the most challenging, the\nmodel should generalize to unseen ROIs at unencountered timesteps. We randomly sample K blocks\nfrom each of the three types of regions as targets, forcing the model to handle a variety of prediction\ntasks with a stronger inductive bias. We denote the mask corresponding of the region r (r\u2208 {\u03b1,\u03b2,\u03b3})\nas $B_r$.\nOverlapped sampling. It has been shown in [21] that a sufficiently large dynamic range of masking\nratio could benefit pretraining. To effectively adjust the observation-to-input ratio during pretraining,\nwe implement an overlapped sampling strategy that allows for a flexible, rather than fixed, ratio. When\nsampling the target block s from region r, for r = \u03b1 or \u03b2, we sample the target from the union of the\nobservation mask and region r mask; while for r=\u03b3, we directly sample the target from the \u03b3 region\nmask. Formally, the overlapped sampling strategy is defined as:\n$s_{\\alpha}^{y}\\sim B_{\\alpha} \\cup B, s_{\\beta}^{y}\\sim B_{\\beta} \\cup B, s_{\\gamma}^{y}\\sim B_{\\gamma}^{y}$"}, {"title": "4 Experiments", "content": "We leveraged the large-scale public dataset - UK Biobank (UKB) [44] for the self-supervised pretraining\nof Brain-JEPA. It includes resting-state fMRI recordings with medical records from 40,162 participants\naged 44 to 83. Multi-site recordings were acquired with the temporal resolution of 0.735s. We allocated\n80% of this dataset for pretraining (of which we calculated the group-level gradients as well), with the\n20% held-out for downstream evaluation (internal tasks of age and sex prediction).\nWe used three datasets for external evaluation: HCP-Aging, as a segment of the public Human\nConnectome Project (HCP) [45], includes resting-state fMRI from 656 healthy elderly participants.\nIt was used to predict traits (Neuroticism and Flanker score) and demographics (age and sex). The\nAlzheimer's Disease Neuroimaging Initiative (ADNI) [46] was used for the early diagnosis and\nprognosis of neurodegenerative diseases, with fMRI from 189 participants for normal control (NC) v.s.\nmild cognitive impairment (MCI) classification, and 100 cognitively normal participants for amyloid\npositive v.s. negative classification. Moreover, to assess generalizability across different ethnic groups\nand real-world clinical applications, we included resting-state fMRI of Asian participants recruited by\nMemory, Ageing and Cognition Centre (MACC), with 539 participants for NC v.s. MCI classification.\nMore details of the downstream tasks performed can be found in the Appendix A.\nAll fMRI data was parcellated into n = 450 ROIs, using Schaefer-400 [47] for cortical regions and\nTian-Scale III [48] for subcortical regions. Robust scaling was implemented by subtracting the median\nand dividing by the interquartile range, calculated across participants for each ROI [14]. Our default\ninput size is 160 timesteps for each of the 450 ROIs (i.e., 450\u00d7160). UKB and HCP-Aging used multi-\nband acquisition with a high temporal resolution (TR \u22480.7 seconds), while ADNI and MACC used\nsingle-band acquisition with a lower resolution (TR \u22482 seconds). To ensure consistency across datasets,\nwe standardized the temporal resolution by downsampling the multi-band data using a temporal stride\nof 3, aligning the TR of all datasets to approximately 2 seconds. During the fine-tuning and linear\nprobing stage, all the downstream datasets were divided into a 6:2:2 ratio for training, validation, and\ntesting."}, {"title": "4.2 Implementation details", "content": "For Brain-JEPA pretraining, we utilized ViT architectures for the observation encoder, target encoder,\nand predictor. We employed FlashAttention [49, 50] in our self-attention implementation to improve\ncomputational efficiency and reduce memory usage. Balancing the trade-off between data quantity and\nthe model complexity, we experimented with ViT-Small (ViT-S) (22M), ViT-Base (ViT-B) (86M), and\nViT-Large (ViT-L) (307M) for the observation encoder. For predictor, it is designed as a lightweight\n(narrow) ViT. Specifically, the predictor has the same architecture as the corresponding observation\nencoder, differing only in embedding dimension and depth. For the ViT-S and ViT-B observation\nencoders, the predictor has a depth of 6 and embedding dimensions of 192 and 384, respectively. The\nViT-L observation encoder uses a predictor with a depth of 12 and an embedding dimension of 384.\nBrain-JEPA is pretrained without a [cls] token. For evaluation, we used the target encoder and average\npooled its output to generate a global fMRI representation. The main results in Section 4.3, along with\nthe analysis in Section 4.5, 4.6 and 4.7 were all based on ViT-B pre-trained for 300 epochs. Refer to\nAppendix B for optimization and masking details."}, {"title": "4.3 Main results", "content": "Table 1, 2, and 3 compare Brain-JEPA with the existing deep learning models for fMRI analysis and\nfoundation model BrainLM. We select the three deep learning baselines because they not only represent\nthe previous state-of-the-art in fMRI analysis but also exemplify diverse model types: convolutional\nneural network (CNN)-based BrainNetCNN [6], graph neural network (GNN)-based BrainGNN [5],\nand transformer-based BNT [4]. For a fair comparison, both Brain-JEPA and BrainLM utilized a ViT-B\nbackbone and were fine-tuned for downstream tasks (Section 4.4 will discuss performance scaling\nwith different model sizes, and Section 4.5 will examine linear probing comparisons between the two\nmodels). BrainLM utilized [cls] token for downstream evaluation.\nThe results show that Brain-JEPA achieves state-of-the-art performance in various downstream tasks\non both the unseen data from the same pretrained cohort and other independent datasets. Brain-JEPA\neffectively captures fundamental demographic information such as age and sex, cognitive/personality\nvariance (Neuroticism and Flanker), and disease-related patterns for neurodegenerative diseases.\nNotably, Brain-JEPA demonstrates superior performance in classifying NC/MCI in Asian ethnic\ngroups - one of the most challenging tasks for early diagnosis and prognosis of Alzheimer's Disease\n(AD) - even though it was trained exclusively on the Caucasian cohort. Please refer to C.1 for\nadditional results on more datasets and comparisons with more baselines."}, {"title": "4.4 Performance scaling", "content": "Figure 3 presents the performance of Brain-JEPA across various model sizes, using ViT-S, ViT-B, and\nViT-L as backbones. The results demonstrate that the larger model configuration consistently achieves\nbetter performance. Specifically, there is a clear trend of increasing accuracy/correlation with larger\nmodels, with Brain-JEPA using ViT-L consistently achieving the best performance. We also studies the\nscaling property with respect to dataset size, please refer to C.2 for additional results."}, {"title": "4.5 Linear probing", "content": "BrainLM initially showcases its performance improvements through fine-tuning, complemented by\nan attached MLP [14]. However, to effectively assess the representations learned during pretraining,\noff-the-shelf evaluations such as linear probing are essential. As depicted in Figure 4, Brain-JEPA\nconsistently outperforms BrainLM in linear probing and exhibits a smaller performance decline from\nfine-tuning to linear probing. This highlights the robustness and higher level of abstraction in the\nrepresentations learned by Brain-JEPA."}, {"title": "4.6 Ablation study", "content": "We first compared Brain-JEPA with its ablated ver-\nsions, employing sine and cosine functions [43] and\nanatomical locations [14] for ROI spatial positioning,\nas shown in Figure 5. Brain Gradient Positioning\ndemonstrates superior performance over these two\nbaseline methods. It indicates that Brain Gradient Po-\nsitioning facilitates natural and accurate placement of\nbrain functional parcellations, enhancing the learning\nof brain dynamics. Next, we assessed the effectiveness\nof our proposed Spatiotemporal Masking by compar-\ning Brain-JEPA, pretrained over various numbers of\nepochs, to its ablated counterpart that utilizes standardy\nmulti-block sampling of targets [21]. This compari-\nson, illustrated in Figure 6, highlights that not only does our proposed masking technique yield superior"}, {"title": "4.7 Interpretation", "content": "With the Schaefer functional atlas [47], the brain network is categorized into seven distinct sub-\nnetworks: the control network (CN), the default mode network (DMN), the dorsal attention network\n(DAN), the limbic network (LN), the salience ventral attention network (SAN), the somatomotor\nnetwork (SMN), and the visual network (VN). To assess whether Brain-JEPA has captured the brain\nfunctional organization, we calculate the network-level attention for NC/MCI classification. For each\nROI, we first average the self-attention across its 10 patches. Next, we average the values of the ROIs\nwithin each sub-network and normalize them to obtain the network-level attention distribution. As\nshown in Figure 7, we found consistent patterns across both Caucasian and Asian ethnic groups, with\nthe model highlighting the critical roles of the DMN, CN, SAN, and LN in cognitive impairment,\nconsistent with previous literature [51, 52, 53]."}, {"title": "5 Conclusion", "content": "In this study, we developed Brain-JEPA, a brain dynamics foundation model based on the Joint-\nEmbedding Predictive Architecture (JEPA). Brain-JEPA predicts abstract representations of sampled\ntargets from observations during the pretraining stage. Utilizing Brain Gradient Positioning, Brain-\nJEPA encodes brain functional organization more naturally and accurately. With Spatiotemporal\nMasking, it effectively handles heterogeneous patches in fMRI time series. Brain-JEPA fosters\ngeneralizable and highly abstract representations of fMRI, achieving state-of-the-art performance\nacross various tasks, including demographic prediction, trait prediction, and disease diagnosis and\nprognosis across different cohorts and ethnic groups. Our study provides new insights into applying\nlarge-scale self-supervised learning to brain activity modelling and contributes to addressing key\nquestions in AI for neuroscience."}, {"title": "6 Limitation and future work", "content": "We acknowledge several limitations in our study, which also serve as inspirations for future research: 1)\nLarger models: Due to limited computing resources, we have not tested larger models like ViT-H. We\nexpect that larger models could further improve performance. 2) More diverse datasets: A more diverse\nbrain recording dataset for pretraining, including different ethnicity cohorts collected from various\nsites, scanning protocols, behavioral tasks, and disease groups, could enhance the generalizability\nand robustness of the representations learned by the model. 3) Fine-grained interpretation: More\nthorough interpretation can be achieved through the attention mechanism, such as comparing cortical\nand subcortical regions, identifying salient ROIs and critical timesteps. This would enable more\nnuanced and complex spatiotemporal interpretations. 4) Multi-modal integration: Brain-JEPA sets\na potential foundation for integrating multimodal brain activity data such as MEG and EEG or even\nbrain structure data like T1-weighted MRI. The integration could enhance our understanding of brain\nstructure, function, and their links to human behavior and mental disorders. Please refer to Appendix D\nfor the broader impact of Brain-JEPA."}, {"title": "A Task Details", "content": "A.1 Neuroticism\nNeuroticism is a personality trait linked to negative emotions and is one of the Big Five personality traits.\nPeople who score high in neuroticism tend to experience negative feelings more frequently than others\n[54]. The HCP uses the 60-question version of the NEO-FFI Short Form (ages 16+) questionnaire,\nwhich provides a quick, reliable, and accurate assessment of the Big Five personality traits: neuroticism,\nextraversion, openness, agreeableness, and conscientiousness. More detailed information can be found\nin the Lifespan HCP 2.0 Data Release Appendix 2: Details and References for Behavioral & Clinical\nInstruments.\nA.2 Flanker\nThe Flanker task is designed to assess both attention and inhibitory control in participants [55]. It\ninvolves the participant focusing on a central stimulus while ignoring adjacent stimuli, which are either\nfish for ages 3-7 or arrows for ages 8-85. Sometimes the central stimulus points in the same direction as\nthe flanking stimuli (congruent) and sometimes in the opposite direction (incongruent). For participants\naged 8-85, the task consists of twenty trials and takes about three minutes to complete. More detailed\ninformation can be found in the Lifespan HCP 2.0 Data Release Appendix 2: Details and References\nfor Behavioral & Clinical Instruments.\nA.3 NC/MCI\nFor the ADNI dataset [46], the criteria for NC was as follows: 1) No subjective memory complaints, 2)\npreserved activities of daily living and cognitive function, 3) Mini-mental state examination (MMSE)\nscore of between 24 to 30 inclusive, 4) Clinical Dementia Rating (CDR) score of 0, and 5) education-\nadjusted score on delayed recall of one paragraph from Wechsler Memory Scale Logical Memory\nII of >=3 for 0-7 years of education, >= 5 for 8-15 years of education, and >= 9 for >=16 years of\neducation. The criteria for MCI was as follows: 1) significant subjective memory complaints reported\nby the participant, clinician or informant, 2) not significantly impaired in other cognitively domains, 3)\nessentially preserved activities of daily living and does not meet criteria for diagnosis of dementia, 4)\nMMSE score of between 24 to 30 inclusive, 5) CDR score of 0.5, and 6) education-adjusted score on\ndelayed recall of one paragraph from Wechsler Memory Scale Logical Memory II of 3-6 for 0-7 years\nof education, 5-9 for 8-15 years of education, and 9-11 for >=16 years of education [56].\nFor the Asian disease cohort, all participants completed a locally validated neuropsychological test\nbattery, which assessed seven domains: executive function, attention, language, visuomotor speed,\nverbal memory, and visual memory. Impairment in a particular domain was defined as failing at\nleast half of the individual tests in a domain, and failure in an individual test was determined using\neducation-adjusted cut-offs of 1.5 standard deviations below established normal means. NC was\ndefined as having no impairment in all cognitive domains on the neuropsychological test battery, while\nMCI was defined as having an impairment in at least one cognitive domain of the neuropsychological\ntest battery. Detailed descriptions of the neuropsychological assessments and diagnostic criteria are\ndescribed in previous work which will be added upon acceptance.\nA.4 Amyloid +/-\nParticipants from the ADNI cohort were also classified as amyloid positive or amyloid negative, using\na threshold of global [18F]-Florbetapir amyloid PET SUVR >= 1.11 to define amyloid positivity [56]."}, {"title": "B Additional Implementation Details", "content": "Optimization for pre-training. The default settings are detailed in Table 4. We initialized all\ntransformer blocks using the Xavier uniform method, as described in [19]. The pre-training process\nutilized four A100 GPUs, each with 40GB of memory.\nOptimization for downstream tasks. The default settings for end-to-end fine-tuning and linear\nprobing are detailed in Table 5. For fine-tuning, following [19], we applied layer-wise Ir decay [57]."}, {"title": "C Additional Results", "content": "C.1 Results on additional baselines and datasets\nWe incorporated more baseline results for downstream tasks on external datasets in Tables 7-8, including\ncommonly used SVM/SVR [61] and recent self-supervised learning methods. It is observed that Brain-\nJEPA outperforms these models on most tasks. We note that for the compared baselines, BrainMass"}, {"title": "D Broader Impact", "content": "The introduction of Brain-JEPA marks a significant advancement in the interdisciplinary field of AI\nand neuroscience, particularly in the brain activity analysis. An assessment of the broader impact of\nthis model has across various dimensions:\nD.1 Neuroscience and medical advancements\nBrain-JEPA's capabilities in demographic prediction, disease diagnosis, and prognosis could revolution-\nize how neurological disorders are diagnosed and treated. This may lead to earlier detection and more\npersonalized therapeutic interventions, potentially improving outcomes for patients with conditions\nlike AD, schizophrenia, or autism spectrum disorders. Furthermore, the model's innovative techniques,\nincluding Brain Gradient Positioning and Spatiotemporal Masking, offer new ways to understand the\nbrain's functional organization. This could lead to breakthroughs in identifying how various cognitive\nprocesses are mapped in the brain, aiding in both basic science and clinical applications. On the\nother hand, by effectively predicting various traits, Brain-JEPA can aid in the study of the genetic and\nenvironmental influences on behavior and cognitive functions. This can enhance our understanding of\nthe neural underpinnings of psychological traits and disorders.\nD.2 Technological impact\nBrain-JEPA sets a new standard in AI's application to complex brain activity data with a novel\nbrain functional coordinate system and masking strategy, which could spur further innovations and\napplications of AI across different sub-fields of neuroscience. Furthermore, the model's success in\nperforming well across different ethnic groups indicate potential for broad applications in diverse\nglobal settings, which is crucial for building inclusive and unbiased AI systems.\nD.3 Ethical and social considerations\nEnsuring the confidentiality and integrity of patient data while using such advanced AI systems is\nparamount. While Brain-JEPA has shown superior performance across different tasks, continuous\nmonitoring for potential biases is essential, especially as the model is scaled and deployed in varied\nclinical settings. Besides, the deployment of advanced technologies like Brain-JEPA could exacerbate\nexisting disparities in healthcare access unless carefully managed. Ensuring that these technologies\nbenefit all segments of the population equally is critical."}, {"title": "NeurIPS Paper Checklist", "content": "1. Claims\nQuestion: Do the main claims made in the abstract and introduction accurately reflect the\npaper's contributions and scope?\nAnswer: [Yes", "nJustification": "Refer to Section 1 for our contributions and scope.\nGuidelines:\n\u2022 The answer NA means that the abstract and introduction do not include the claims made\nin the paper.\n\u2022 The abstract and/or introduction should clearly state the claims made", "Limitations\nQuestion": "Does the paper discuss the limitations of the work performed by the authors?\nAnswer: [Yes"}, {"nJustification": "Refer to Section 6 for the discussion of limitation and future work.\nGuidelines:\n\u2022 The answer NA means that the paper has no limitation while the answer No means that\nthe paper has limitations, but those are not discussed in the paper.\n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.\n\u2022 The paper should point out any strong assumptions and how robust the results are to\nviolations of these assumptions (e.g., independence assumptions, noiseless settings,\nmodel well-specification, asymptotic approximations only holding locally). The authors\nshould reflect on how these assumptions might be violated in practice and what the\nimplications would be.\n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only\ntested on a few datasets or with a few runs. In general, empirical results often depend on\nimplicit assumptions, which should be articulated.\n\u2022 The authors should reflect on the factors that influence the performance of the approach.\nFor example, a facial recognition algorithm may perform poorly when image resolution\nis low or images are taken in low lighting. Or"}]}