{"title": "A Dynamic Systems Approach to Modelling Human-Machine Rhythm Interaction", "authors": ["Zhongju Yuan", "Wannes Van Ransbeeck", "Geraint Wiggins", "Dick Botteldooren"], "abstract": "In exploring the simulation of human rhythmic perception and synchronization capabilities, this study introduces a computational model inspired by the physical and biological processes underlying rhythm processing. Utilizing a reservoir computing framework that simulates the function of cerebellum, the model features a dual-neuron classification and incorporates parameters to modulate information transfer, reflecting biological neural network characteristics. Our findings demonstrate the model's ability to accurately perceive and adapt to rhythmic patterns within the human perceptible range, exhibiting behavior closely aligned with human rhythm interaction. By incorporating fine-tuning mechanisms and delay-feedback, the model enables continuous learning and precise rhythm prediction. The introduction of customized settings further enhances its capacity to stimulate diverse human rhythmic behaviors, underscoring the potential of this architecture in temporal cognitive task modeling and the study of rhythm synchronization and prediction in artificial and biological systems. Therefore, our model is capable of transparently modelling cognitive theories that elucidate the dynamic processes by which the brain generates rhythm-related behavior.", "sections": [{"title": "I. INTRODUCTION", "content": "THERE are a lot of works are working on the modelling cognitive tasks [1-3], specifically on the rhythmic perception task [4]. Rhythm is a time series that exhibits periodic patterns or cycles [5] over a certain time interval. The sounds that humans use for communication are temporally structured sequences of events, such as musical notes. Here, rhythm means the pattern of timing and stress in the amplitude envelope of an acoustic sequence [6], which has a basic beat, the tactus, in a specific frequency range. The meter is a perceived temporal structure that includes the tactus frequency [7, 8].\nIn humans and embodied systems, the act of striking a rhythm has to begin prior to the real beats to account for delays in the system. Hence, for synchronization with others [9], precise prediction is crucial [10, 11]. Humans are capable of rhythm and rhythm synchronization within a particular range of beat and meter frequencies, a characteristic that we want the model architecture to simulate. In accordance with the process of biological rhythm processing in music, we designed a reservoir containing a pool of resonators to fulfill a role similar to the cerebellum [12, 13]. Reservoir computing is commonly used for time series prediction tasks [14]. In the work by Rigotti et al. [15], the authors present a biological model of cognition where single-neuron activity in the human brain is tuned to combinations of multiple task-related aspects, resembling the nature of the reservoir readout layer.\nWe propose a physical inspired reservoir to model a predictive coding task [1, 15]. In the proposed reservoir structure, neurons are classified into two types: primary and intermediate. The primary neurons correspond to pressure in the inspirational physical system, while the intermediate neurons map to particle velocities. To modulate information transfer, we introduce two types of weights, c and k. In the equivalent physical system, they represent propagation speed and decay rate, respectively. This physical inspiration imposes certain constraints on the reservoir weight matrix, yet it also enables easy adjustments to the overall reservoir speed and activation level. Furthermore, distinct regions within the reservoir can be designated distinct roles (e.g., oscillation frequencies), allowing for targeted design of their dynamics.\nThe biological plausibility of the proposed architecture could also be examined. Traveling waves and oscillations play a crucial part in dynamically coordinating neural connectivity, allowing for the flexible organization of the timing and directionality of network interactions throughout the cortex, which is essential for supporting cognition and behavior [16]. The overall topology-preserving structure can also be observed in the auditory cortex, where specific areas exhibit greater responsiveness to sound modulated at various frequencies [17, 18]. At the level of individual biological neurons, the intermediate artificial neurons can be considered as (groups of) synapses with a temporal storage capacity. This temporary information storage capability enables the intermediate neurons to model delays, a crucial aspect of biological neural networks [19]. The response of the primary neurons is further modulated by a global parameter that may be analogous to neurotransmitter control. This combination of structures enables the generation of slow rhythms without compromising the biological constraints of individual biological neurons. Additionally, the double-parameter architecture can discriminate between low and high spontaneous activity neurons, which exhibit varying sensitivities [20].\nFor the basic task of rhythm perception, specifically the predictive coding task related to meter, this study conducted"}, {"title": "II. METHODS", "content": "The main objective of the current model is to predict the occurrence of rhythmic beats during interactions with human-like (im)precision in a biologically plausible way.\nThe proposed model uses reservoir computing to capture the temporal aspects of rhythms. Reservoirs typically exhibit multiple damped resonances. Because slow temporal behavior can be obtained based on interactions between neurons that are fast, this can be considered a biologically plausible backbone. Our innovation contains two steps. Firstly, we introduce a topology-preserving reservoir structure (Section II-B). During training it is combined with classical output weight training. Secondly, the new structure allows tuning the reservoir during the application phase by means of parameters with physically predictable impact that are biologically interpretable. Based on our specifically designed synchronization loss function and the Dynamical Selection (DS) mechanism, adjustments are made to the reservoir's connection matrix to fine-tune predictions.\nA typical task for our model is illustrated in Fig 1: beat a rhythm based on another aurally-presented rhythm with the same underlying meter. To instruct the model what rhythm it is required to beat, a priming phase is foreseen. As this will be done via visual stimulation in the human experiment we refer to it as the visual input in Fig 1, yet as far as the model is concerned it consists of a second periodic signal envelope. Computer models are inherently very fast and could simply follow, but for the system to be human-like and even implementable in a robot it needs to be predictive. Here we selected a 200 milliseconds forward prediction.\nTo create this predictive behavior, an oscillating system is needed. A reservoir of connected neurons is chosen as a complex resonating system containing thousands of degrees of freedom. To select the desired rhythm, the internal states of this system are combined using trainable output weights. Training is done during the priming phase and could represent the biological process of selecting the appropriate envelope following component from the disentangling of the rhythm by the auditory system.\nThe outcome of this training process is a generative model designed to simulate sequential human behavior in rhythmic cognitive tasks. Central to the generative model is a latent dynamical system characterized by state variables \\(h_t\\). The evolution of the latent state is governed by the following dynamics:\n\\[h_{t+1} = f_o(h_t, x_t, b_t, \\xi_t), \\tag{1}\\]\nwhere \\(x_t\\) represents the inputs (primer, auditory reference, feedback) at time t, \\(b_t\\) is the bias at time t, \\(\\xi_t\\) is the noise term at time t, and \\(f_o\\) denotes the dynamics function. Here, \\(f_o\\) is modelled as a highly expressive physical-inspired reservoir structure (Section II-B ).\nThe representation of the input employs a smooth pulse to accentuate the occurrence or lack of a beat at any given moment. The injection of zero-mean Gaussian noise \\(\\xi_t\\) at each time step is essential. From a physical perspective, the noise will trigger the oscillating system to exhibit \"natural\" metronomes. Additive noise is biologically plausible due to spontaneous emission of the (auditory) neurons.\nModel outputs, denoted by \\(y_t\\), are produced through a linear combination acting as a representation of mixed selectivity [15], derived from the activity of neurons within the reservoir. The motor behavior is not explicitly modelled yet it is assumed that this introduces a delay of \\(\\Delta t\\). Therefore, the model is trained to predict upcoming beats \\(\\Delta t\\) ahead of their occurrence. For training the output layer weights, we employ the Mean Squared Error (MSE) metric to ascertain the proximity of the model's predictions to the target behavior."}, {"title": "B. Reservoir weights", "content": "The proposed model is based on a reservoir computing (RC) method: the Echo State Network (ESN) [23, 24], a specific recurrent neural network [25-27]. Its hidden states change according to the current input and the hidden states from the previous time step, which follows the equations:\n\\[h_{t+1} = (1 - \\alpha)h_t \\\\\n+ \\alpha f(W_{in}x_t + Wh_t + \\xi_t), \\\\\n\\hat{y}_t = W_{out}h_t, \\tag{2}\\]\nwhere \\(W\\) is a sparse matrix defining the connectivity of the network, \\(W_{in}\\) is the input weight, and \\(W_{out}\\) is the output weight matrix, and \\(\\alpha\\) is the leakage rate of the model. \\(f(\\cdot)\\) is a non-linear function, for which \\(\\tanh(\\cdot)\\) is used in this paper. \\(x_t\\) is the input signal at time step \\(t\\), and \\(h_t\\) is the hidden state at time step \\(t\\), and \\(\\hat{y}_t\\) is the output of the model at time step \\(t\\), which is the prediction. The expected prediction should satisfy \\(\\hat{y}_t = x_{t+n}\\) where \\(n\\) is the number of time steps predicted ahead: \\(\\Delta t = n\\delta t\\) with \\(\\delta t\\) the simulation time step.\nConventionally, the weight matrix of the reservoir \\(W\\), the input weight matrix \\(W_{in}\\), and the bias matrix \\(b_t\\) are randomly generated at each time step. In this paper, \\(W_{bias}\\) includes the Gaussion noise \\(\\xi_t\\), regenerated every time step. The weight matrix \\(W\\) is usually adapted to keep all of its eigenvalues inside the unit circle [28] in the z-domain, thereby assuring stability of this dynamic system in the linear, low amplitude, regime.\nFor the problem at hand, predicting the occurrence of rhythmic beats in a human-like way, the poles in the z-domain of the \\(W\\) matrix and thus the resonances in the random reservoir are not optimally placed: (1) they span a frequency range that does not match human capabilities; (2) many of them are too much damped. To overcome this problem, we propose a novel reservoir structure designed following physical principles. To simplify the tuning of \\(W\\), we design it based on a 2D Finite-Difference Time-Domain (2D-FDTD) computational approximation of the linearized Euler equations [29] for wave propagation in a medium with randomly generated properties. Because this system results in local connections, it has a clear topology which allows crafting connections from input or outputs to areas showing specific dynamics. Starting from the wave equations Eq 3 where c is the wave speed and k is a damping (amplification if negative) factor, and p and o are proportional to pressure and velocity.\n\\[\\frac{\\partial p}{\\partial t} + c^2\\nabla o = 0 \\\\\n\\frac{\\partial o}{\\partial t} - ko + p = 0, \\tag{3}\\]\nThe simplest FDTD model, a staggered grid, central differ-ences, and an explicit time stepping approximation of these equations leads to their discretised form (Eq 4):\n\\[p_{i,j}(t + \\delta t) = p_{i,j}(t) + c^2\\delta t * (o_{x,i+1,j} - o_{x,i,j})/\\delta x \\\\\n+ c^2\\delta t * (o_{y,i,j+1} - o_{y,i,j})/\\delta y \\\\\no_{x,i,j}(t + \\delta t/2) = \\frac{1 - k_{i,j}\\delta t/2}{1 + k_{i,j}\\delta t/2} o_{x,i,j}(t - \\delta t/2) \\\\\n+ \\frac{c^2\\delta t}{\\delta x(1 + k_{i,j}\\delta t/2)} (p_{i,j} - p_{i-1,j}), \\tag{4}\\]\nwhere the indices, i and j refer to spatial locations and the time dependence has been omitted on the right hand side of the equation. A similar equation holds for \\(o_y\\). Stability is guaranteed by keeping the Courant number, which relates the \\(\\delta t\\) to \\(\\delta x\\) and \\(\\delta y\\), smaller than 1.\nThe two groups of unknowns could be interpreted as two types of artificial neurons in a reservoir as in Fig 1: one is the primary neuron denoted as \\(p_{i,j}\\), and the other is the intermediate neuron, labeled as \\(o_{x,i,j}\\) or \\(o_{y,i,j}\\). These can be grouped in a hidden state matrix x like in Eq 2. As p, o are coupled locally and sparsely the coupling matrix A derived from Eq 4 will also be sparse.\nThe weight matrix W of the reservoir is computed by:\n\\[W = (A - (1 - \\alpha) \\cdot I)/\\alpha, \\tag{5}\\]\nwhere I is the identity matrix. In this way the update equations of the reservoir Eq 1 become very similar to the FDTD update equations. It implies very strong symmetry constraints on the W matrix. The local value of c determines how strongly the p-neuron responds to inputs from surrounding o-neurons and together with the coupling to its neighbors this can result in local resonances, where the physics equivalent learns that small c correspond to low-frequency resonances."}, {"title": "C. Tuning for synchronization", "content": "In this study, we employ stochastic gradient descent (SGD) to minimize the Mean Squared Error (MSE) between the prediction \\(\\hat{y}\\) and target y signals during training that is based on a large number of rhythmic beats that could theoretically be encountered in music. Following training, the output layer can thus identify a suitable combination of correct oscillators, thereby providing an initial estimate of the target beat periodicity and timing.\nTo synchronize the prediction with the target beats more accurately, an adaptation phase is introduced. A prediction of an upcoming beat can fail in to ways: 'too early' or 'too late', hence the error is split in two parts. In both cases, there is usually an overlap between the sound envelopes corresponding to a beat in the prediction and target. If the data consists of discrete moments in time, the peak is artificially extended. Thus, the slope of the peaks is employed to calculate the error \\(I_{early}\\) and \\(I_{late}\\) of the prediction \\(\\hat{y}\\) and target y signals.\nIf the prediction is descending while the target is ascending, we consider the prediction to be too early. Otherwise, if the prediction is ascending while the target is descending, the prediction is too late. Both values, \\(I_{early}\\) and \\(I_{late}\\) until an update_step is reached and the reservoir weights are changed, and reinitialize to 0 when the interval ends, as shown in Algorithm 1. To ensure proximity in amplitude between the target and prediction within the same time window, a moving average and a softmax normalisation are first applied to both the target and prediction values:\n\\[y_{norm}(t) = \\frac{y_t - y_{mean}}{y_{softmax}(t)}, \\tag{6}\\]\n\\[\\hat{y}_{norm}(t) = \\frac{\\hat{y}_t - \\hat{y}_{mean}}{\\hat{y}_{softmax}(t)}, \\tag{7}\\]\nwhere\n\\[y_{softmax}(t) = \\int_{-\\infty}^t ln(e^{y(t')}) dt', \\tag{8}\\]\n\\[\\hat{y}_{softmax}(t) = \\int_{-\\infty}^t ln(e^{\\hat{y}(t')}) dt', \\tag{9}\\]\nwhere \\(\\tau\\) is an exponential averaging time constant spanning multiple interbeat intervals.\nBy weighted comparison of \\(I_{early}\\) and \\(I_{late}\\), the decision is made to increase or decrease the speed-up factor \\(\\delta c\\) by a fixed amount as shown in Algorithm 1. If the prediction is too early, we thus decrease all elements of c proportionally to their value; if it is too late, we increase c it. In this way, the whole reservoir slows down or speeds up.\nSecondly, a proposed method: Dynamical Selection (DS) mechanism, is used to control the damping of the oscillations in the reservoir. The poles of the \\(W\\) matrix are modified by identifying regions within the reservoir that are pivotal for accurately predicting beats and amplifying them by lowering k in these regions. Simultaneously, the oscillations that make minor contributions are damped. To this end, each neuron within the reservoir is masked, generating masked outputs, and computed their MSE in comparison to the target in every time window. The neurons that resulted in the most significant MSE reduction when masked are considered the ones contributing the most to accurate prediction. Conversely, those neurons leading to the least reduction were considered to have the smallest contribution. We modulated the activity of these neurons by adjusting the parameter k around their positions, either enhancing or diminishing their activity accordingly. As k changes only slowly it will introduce some focus even after the meter or rhythmic pattern change, this mechanism can be considered to focus attention on an area in the reservoir and thus also on a specific rhythmic behavior."}, {"title": "D. Fine-tuning and Continuation", "content": "Having completed the model training, a first approximation to the output \\(W_{out}\\) is obtained. However, predictions for task illustrated in Fig 1 involving two inputs, lack accuracy. In this study, distinct combinations of beat multiples under the same meter are regarded as separate tasks. During the fine tuning process, fast adaptation is applied to the model's output layer, enabling the model to learn new combinations of multiples at different meters swiftly.\nDue to the well-established initialization, the model, prior to fast adaptation, can accurately output beats at appropriate positions for tasks within the perceptible frequency range for humans. However, the amplitudes of these beats are inaccurately predicted, exhibiting significant errors compared to the target beats. Additionally, predictions sometimes include extra beats between two adjacent target beats, further contributing to discrepancies between predictions and targets.\nTo facilitate fast adaptation of the output weights to new tasks, we store the fixed time step predictions and targets [30]. We compute the Mean Squared Error (MSE) between them and perform a few steps of weight updates in the direction that minimizes the MSE. To account for the impact of the additional peak between adjacent target beats on the computed MSE, a penalty is applied. Since the beats between input signals consist entirely of zeros, the MSE penalizes all extra beats equally. Therefore, we replace the zero segments between two adjacent beats with the negative portion of a sine wave with a 0.5 phase, matching the amplitude of the input peak.\nDuring the fine-tuning phase, the adjustment formula for the model's output weights is:\n\\[W_{out} \\leftarrow W_{out} - lr * \\frac{\\partial MSE}{\\partial W_{out}}, \\tag{10}\\]\nwhere the lr is the defined learning rate.\nOnce the visual reference halts (Figure 1), fine-tuning ends. Subsequently, the model's prediction persists for an additional beat. Its detection initiates a feedback loop, and the prediction replaces the visual reference. Notably, there is no need to modify the input weight, as shown in Eq 11. Consequently, the closed-loop model acquires the capacity to learn from its own sound and sustain the acquired rhythm.\n\\[h_{t+1} = (1-\\alpha)h_t \\\\\n+ \\alpha f (W_{in}(x_t + \\hat{y}_{t-n}) + Wh_t + b_t + \\xi_t), \\tag{11}\\]\n\\[\\hat{y}_t = W_{out}h_t,\\]\nwhere \\(y(t-n)\\) denotes the feedback from the output, and \\(\\Delta t = n \\delta t\\) indicates that the model is predicting \\(\\Delta t\\) ms into the future."}, {"title": "E. Customization during human behavior simulation", "content": "When two humans interact musically, they can adopt different behaviors. In broad terms they can act as a follower or as a leader in the interaction. When comparing the proposed model with interaction experiments (Fig 3(b)), this is included by customizing the update learning rate. To this end, we utilize the Wasserstein distance \\(W(\\cdot, \\cdot)\\) between the inter-beat interval generated by Participant 1 (P1) and the primer interval, and between the inter-beat interval generated by P1 and participant 2 (P2).\nThe Wasserstein distance [31] measures the amount of 'work' required to move one set of timings to another set, effectively identifying the inter-beat interval distribution similarity. The equation is as follows:\n\\[\\Upsilon_{E\\Gamma}(P_{pred}, P_{target}) = \\min_{\\gamma \\in \\Gamma(P_{pred}, P_{target})} \\int c(d_{pred}, d_{target}) d\\gamma, \\tag{12}\\]\nwhere \\(P_{pred}\\) and \\(P_{target}\\) are the inter-beat interval distribution of human prediction and visual reference respectively, \\(d_{target}\\) represents the set of inter-beat intervals from the participant, \\(d_{pred}\\) denotes the set of inter-beat intervals from the refer-ence or another subject, \\(min_{\\gamma \\in F(P_{pred},P_{target})}\\) signifies the minimum over all joint distributions \\(\\gamma\\) with marginals \\(P_{pred}\\), \\(P_{target}\\), \\(c(d_{pred}, d_{target})\\) denotes the time difference between point \\(d_{pred}\\) and point \\(d_{target}\\), and \\(d\\gamma (d_{pred}, d_{target})\\) represents the joint distribution.\nThe update learning rates are defined as:\n\\[\\beta * \\frac{1}{W(P_{pred}, P_{target}) * exp(- \\frac{l}{ds} )}, \\tag{13}\\]\nwhere \\(\\beta = 0.001\\) is the learning rate, \\(ds = 6ms\\) is the downsample factor, and l is the sequence length."}, {"title": "III. RESULTS", "content": "In human perceptive beat, lower-level dynamics, such as the grouping of two or three beats, are processed by sensory tissues such as the cerebellum, which establishes the fundamental rhythm in interaction with the environment. Meanwhile, higher cognitive processes are responsible for selecting and refining complex tasks [12]. This allows humans to generate rhythms within a certain frequency range, and upon mastery, anticipate beats ahead of the actual timing. Slower rhythms will be subdivided into faster meters.\nTo assess the model's frequency perception range, the model is pre-trained on large dataset of artificially created plausible rhythms. Then, test are conducted using rhythms spanning inter-beat intervals from 400 to 3000 milliseconds with an intervals of 50 milliseconds. The time-step \\(\\delta t\\) was set to 6 milliseconds. The model was tested without fine-tuning and with and without tuning c and k for synchronisation.\nAs depicted in Fig 2, when the inter-beat interval is less than 2000 milliseconds, the model demonstrates accurate rhythm prediction, with minimal variance observed between predicted beats. However, as shown in Fig 2(a) left side, when the intervals increase, the model's predictions begin to incorporate subdivisions, notably aligning well with intervals of one half and one third of the target intervals. Such behavior would also be expected in humans as this inter-beat interval falls well beyond human capabilities for rhythmic prediction.\nFollowing the tuning of c and k for synchronisation (Fig 2(a) right side) the model becomes more precise but also generates more subdivisions. A common observation is that humans also tend to perform internal counts between consecutive beats.\nAt six specific inter-beat intervals, the time offset ratio between the model's outputs before and after adjustments is investigated in more detail. The examples of comparing the prediction and the target rhythmic signals' mean and variance of time offset ratio are shown in Fig 2(b). The figure"}, {"title": "IV. CONCLUSION", "content": "In this study, we developed a biologically inspired dynamic system to simulate human rhythmic cognition by integrating predictive coding, aligning it with human behavior. Unlike traditional data-intensive machine learning models, our approach employs a recurrent neural network (RNN) trained on basic rhythmic patterns, demonstrating the capability to learn new rhythmic combinations and interact similarly to humans.\nOur model, designed with a weight matrix inspired by wave equation discretization, can emulate human-like rhythmic behaviors. To improve learning capacity, we introduced fine tuning on the output weights, enhancing the selection of neuron activity and enabling rapid adaptation to new rhythmic combinations. Our model maintains learned rhythms by selectively outputting and delaying feedback as input. Interaction tests with and without customization revealed that our model generalizes well to most basic human rhythmic behaviors. Broadly, our framework can extend to other time-varying signals, offering a potential method for generating models that simulate the brain's dynamic functions and enable the emergence of rhythmic behavior."}]}