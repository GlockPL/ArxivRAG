{"title": "Disk2Planet: A Robust and Automated Machine Learning Tool for Parameter Inference in Disk-Planet Systems", "authors": ["SHUNYUAN MAO (\u6bdb\u987a\u5143)", "RUOBING DONG (\u8463\u82e5\u51b0)", "KWANG MOO YI", "LU LU", "SIFAN WANG", "PARIS PERDIKARISS"], "abstract": "We introduce Disk2Planet, a machine learning-based tool to infer key parameters in disk-planet systems from observed protoplanetary disk structures. Disk2Planet takes as input the disk structures in the form of two-dimensional density and velocity maps, and outputs disk and planet properties, that is, the Shakura-Sunyaev viscosity, the disk aspect ratio, the planet-star mass ratio, and the planet's radius and azimuth. We integrate the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), an evolutionary algorithm tailored for complex optimization problems, and the Protoplanetary Disk Operator Network (PPDONet), a neural network designed to predict solutions of disk-planet interactions. Our tool is fully automated and can retrieve parameters in one system in three minutes on an Nvidia A100 graphics processing unit. We empirically demonstrate that our tool achieves percent-level or higher accuracy, and is able to handle missing data and unknown levels of noise.", "sections": [{"title": "1. INTRODUCTION", "content": "Planets form in protoplanetary disks: flattened, gaseous disks surrounding newborn stars (Andrews 2020). To study planet formation in the outer disk beyond the snowline, a straightforward approach is to directly image the forming planets in these disks. Successful detections can provide critical information about the process, such as the mass and orbit of the forming planets. However, this approach is challenging with current observational techniques as the signals from the stars and disks overwhelm those from the planets. These factors severely limit our understanding of how planets form.\nTo detect young planets embedded in protoplanetary disks, an alternative method is to infer their presence and constrain their parameters from observations of large-scale disk structures produced by disk-planet interactions. The morphology of these structures, such as gaps, spiral arms, vortices, and kinematic perturbations, depends on the properties of the disk and the planets, such as the viscosity and aspect ratio of the disk, and the masses and orbits of the planets.\nDeriving planetary parameters from observed disk structures requires solving the inverse problem: deducing causes from observed effects. It involves fitting observations with parametrized disk-planet models predicted by a forward problem solver, a solver that calculates the effects from the causes. The process iteratively fine-tunes parameters to fit the observed data."}, {"title": "2. METHOD", "content": "The inputs for our inverse problem solver consist of one or a combination of 2D maps of surface density and velocity distributions in a steady-state disk with a planet on a stable circular orbit. The solver is designed to find the optimal set of five parameters-Shakura-Sunyaev viscosity (\u03b1), disk aspect ratio (ho), planet-star mass ratio (q), and planetary location (radius rp and azimuth \u03b8\u03c1) that results in the minimal differences between the predicted disk model and the input data. This is accomplished through an iterative process outlined in Fig. 2.\nIn each iteration, we use a 5D Gaussian distribution to represent our current knowledge of (\u03b1, ho, q, rp, \u03b8\u03c1). The mean of the Gaussian indicates the most probable parameter values. Initially, we sample 4,096 parameter sets uniformly in the parameter space of interest: 3 \u00d7 10-4 \u2264 \u03b1 \u2264 0.1, 0.05 \u2264 ho \u2264 0.1, 5 \u00d7 10-5 < q < 2 \u00d7 10-3, and rp and Op within the input data image's boundaries (50\u2013150 au for rp and 2 for op, or wherever the truncation due to cropping is; \u00a73.4). The mean of the Gaussian is initialized to the parameters with the lowest score (\u00a72.2) among the 4,096 parameter sets. The standard deviation of the Gaussian reflects the confidence in the estimate and is initially set to 0.01 1. Each iteration includes four steps:\n1.  Sample 128 sets of parameters from the Gaussian distribution;\n2.  Predict the disk model for each parameter set using the forward problem solver PPDONet (\u00a72.1);\n3.  Assign a score to each prediction to quantify how well it matches the input data (\u00a72.2);\n4.  Update the Gaussian distribution's mean and standard deviation based on the scores using the Covariance Matrix Adaptation Evolution Strategy (CMA-ES; \u00a72.3).\nThe iterative process is repeated until the score in step (3) can no longer be minimized, indicating that the best possible set of parameters has been found.\nFigure 2 illustrates how the tool works. The input data (panel (a)) contains a surface density map generated using the FARGO3D code with its true parameters listed on the side. The evolution of the score is shown in panel (b). The inferred (optimal) parameters are shown in panel (c), where we achieve sub-percentage level accuracy for all five parameters. Panel (c) also shows the surface density map corresponding to the inferred parameters, obtained using PPDONet, enabling visual inspection."}, {"title": "2.1. The PPDONet-based Forward Problem Solver", "content": "To infer parameters automatically and accurately, our method tests many sets of parameters per iteration (e.g., 128 sets in our experiments) instead of a single set as in traditional approaches. This necessitates a fast forward problem solver, as traditional simulations are too slow to frequently test parameter sets. We employ PPDONet, the only public fast forward problem solver at the time of writing.\nFor each set of (\u03b1, ho, q) sampled during iterations, PPDONet predicts surface density \u03a3, radial velocity vr, and azimuthal velocity ve maps, each computed in 0.01 second on an Nvidia A100 chip. Line-of-sight velocity maps VLOS = vr cos(\u03b8) - ve sin(\u03b8) can be synthesized in post-processing. These maps are then rotated and stretched according to the planet location (rp, \u03b8p) in the current sample. PPDONet is a publicly available machine learning tool that efficiently maps scalar parameters from partial differential equations to their solutions. As demonstrated in Mao et al. (2023, Fig. 2), the predicted disk maps are visually indistinguishable from FARGO3D simulations within the parameter space of interest defined earlier."}, {"title": "2.2. The Score for Data-Output Comparisons", "content": "The PPDONet-predicted disk map for each sampled parameter set is compared with the corresponding input data to generate a score quantifying their differences. We opt for the L2 error metric over the structural similarity index measure (SSIM) due to its simplicity. In addition, our tests show that using L2 and SSIM as the evaluation metric yield similar results.\nFor velocities, the score is the relative L2 error:\nL2(velocity) = ||pred-data||2/||data||2, (1)\nwhere || ||2 denotes the root mean square over all pixel values. For surface density, the score is the logarithmic relative L2 error (e.g. Zhang et al. 2022)\nL2(\u03a3) = || log10 pred \u2013 log10 data||2/|| log10 data||2. (2)\nThe score is designed to handle the data complications illustrated in Fig. 3. For noisy data (block A), L2 is directly computed between the noisy data and the noise-free predicted model. For data with missing parts (block B), the error calculation is confined to valid pixels only. If the data includes multiple components, such as \u03a3 and ULOS (block C), L2 for each component are averaged to produce a composite measure. The score is not designed to account for effects caused by disk inclination, which is often known for individual systems , enabling deprojection of the input data prior to parameter inferences when the observations probe the disk midplane (e.g., millimeter dust continuum emission)."}, {"title": "2.3. The Optimization Algorithm CMA-ES", "content": "We use an optimization algorithm to iterate parameter updates based on their corresponding scores. In optimization problems, there are two primary classes of algorithms: gradient-based and gradient-free. Gradient-based methods typically offer superior performance; however, they are unsuitable for our problem because the derivatives of scores with respect to parameters are unavailable. Consequently, we rely on a gradient-free technique: the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) CMA-ES is renowned for its superior performance on benchmark problems where the correlation between parameters and scores is complex and not well understood analytically.\nCMA-ES automatically updates the mean and covariance matrix of the Gaussian distribution to minimize the scores (\u00a72.2) of the parameters sampled from the Gaussian distribution over iterations. Each update in CMA-ES follows an adaptive strategy similar to that found in evolutionary biology: The algorithm ranks parameter sets by their scores, selecting the lowest half as \"parents\". It then blends these parent sets through recombination and mutation to calculate the mean and covariance matrix for the new Gaussian distribution. This new Gaussian reflects the most successful parameter combinations at that moment, guiding the search towards promising directions. The updated Gaussian is then employed to generate \"children\" parameter sets for the next iteration. This iterative process repeats until the score improvement plateaus, indicating that the optimal parameters have been effectively identified by the latest Gaussian distribution."}, {"title": "3. PERFORMANCE", "content": "In this section, we evaluate the parameter inference accuracy of Disk2Planet. We begin with the baseline case in which the input data contains a complete noise-free map of surface density (\u00a73.1). We then test cases in which the input data contains multiple physical quantities (\u00a73.2), noises (\u00a73.3), and missing parts (\u00a73.4)."}, {"title": "3.1. The baseline case input data with surface density only", "content": "Fig. 4 shows the inferred versus ground truth planet masses for 256 tests uniformly sampled from the parameter space specified in Mao et al. (2023, Table 1). Overall, the two agree well. The agreement can be quantitatively assessed using the r2-score:\nr2 = 1-SS(Minferred \u2013 Mtrue)/SS(Mtrue \u2013 Mtrue), (3)\nwhere SS denotes the sum of square of all cases and Mtrue is the mean of all ground truth values. An r2-score close to one indicates near-perfect agreement. Our tool achieves an r2-score of 0.9994. For comparison, Bayesian network-based parameter inference achieves r2-scores of 0.82 and CNN-based parameter inference typically achieves r2-scores of 0.97 to 0.98.\nAnother metric for assessing the tool's performance is the error distribution of each parameter, as done by Zhang et al. (2022) and Ruzza et al. (2024). In each test, we quantify the error in each inferred parameter as:\nErr(\u03b1) = log10(ainferred) \u2013 log10(atrue), (4a)\nErr(ho) = (hinferred \u2013 htrue)/htrue, (4b)\nErr(q) = log10(qinferred) \u2013 log10(qtrue), (4c)\nErr(rp) = (rinferred \u2013 true)/rtrue, (4d)\nErr(0p) = (inferred - true. (4e)\nThe errors for \u03b1 and q are calculated on a logarithmic scale due to their wide range across several orders of magnitude (Ruzza et al. 2024, Eq. 13). The errors for ho and rp are normalized. We then define the inference uncertainty \u03c3 as half the difference between the error distribution's 84th and 16th percentiles, and list them in the first column in Fig. 5: \u03c3(\u03b1) = 0.022, \u03c3(ho) = 0.0015, \u03c3(q) = 0.0073, \u03c3(rp) = 0.00047, \u03c3(\u03b8p) = 0.0018. In comparison, CNN-based parameter inference achieves \u03c3(q) = 0.16 and 0.13 , and \u03c3(\u03b1) = 0.23 .\nWe examine the error distributions and possible correlations in the multi-dimensional parameter space in Fig. 6a. The histograms on the diagonal show the distributions of individual parameters while the off-diagonal panels highlight pairwise correlations. Notably, all distributions are centered, indicating little systematic bias in the inferred parameters. Additionally, only two pairwise correlations (out of a total of C(5,2) = 10) are not isotropic: Err(\u03b1) vs Err(q) exhibits a positive correlation, echoing Zhang et al. (2022, Fig. 5), while Err(rp) is negatively correlated with Err(\u03b8p)."}, {"title": "3.2. Input data with multiple quantities", "content": "Disk2Planet can incorporate surface density \u03a3, radial velocity ur, and azimuthal velocity ve in any combination. For example, we can supply two maps, \u03a3 + ULOS, as illustrated in Fig. 5 (case (b)). This scenario mimics real situations where gas line emission observations provide these quantities. As the amount of information in the input data increases, the parameter inference accuracy improves, resulting in smaller errors. Compared to the baseline case (a), adding ULOS reduces uncertainties for the five inferred parameters by 3% to 47% in 256 tests. Additionally, supplying three maps, \u03a3 + vr + ve, as input data (case c) further reduces uncertainties since vr + ve provide more information than ULOS."}, {"title": "3.3. Input data with noise", "content": "Observational data often contain noise. Our inverse problem solver can handle noisy input data, as shown in cases (d) and (e) in Fig. 5. They are created by introducing random uniform noises in \u03a3 (case (d)) and \u03a3 + ULOS (case (e)). The noises have a spatial scale of 2.5 AU , added to the logarithmic pixel values with a standard deviation 0.6\u00d7 the average of the quantity. The resulting uncertainties for the five parameters in both cases are 2\u20134\u00d7 those in the corresponding noise-free inputs (cases (a) and (b)). The associated multi-dimensional error distributions are shown in Fig. 6b, with trends similar to those in the baseline case (Fig. 6a; \u00a73.1)."}, {"title": "3.4. Input data with missing parts", "content": "In observations, signals in certain regions may be missing or masked for various reasons, such as foreground extinction . Figure 5 illustrates two such cases: the \u2211 map is cropped radially beyond 1.1rp (f) and azimuthally in half (g; the planet is in the cropped region). In both scenarios, the tool performs parameter inference in all 256 tests, albeit with uncertainties 1 - 9x those in the baseline case with a full map (a). This is expected, as cropping reduces the amount of information in the input image.\nIn the radial cropping case, \u03c3(ho) and o(rp) have the largest increases (4.3\u00d7 and 6.0\u00d7, respectively), although their absolute values remain low (0.007 and 0.003, respectively). In the azimuthal cropping case, a 9-fold increase in \u03c3(\u03b8p) stands out among the five uncertainties, attributed to the loss of substructures near the planet, crucial for its accurate localization. The absolute value of \u03c3(\u03b8\u03c1), 0.016 (1\u00b0, or 1.6 AU for a planet at 100 AU), remains smaller than the typical resolution achieved in to-"}, {"title": "4. ADVANTAGES OVER EXISTING INVERSE PROBLEM SOLVERS", "content": "Disk2Planet is robust against noisy data (3.3). This is because our optimization focuses on large-scale disk morphology (e.g., spiral arms, gap), more than noises (usually small-scale). To demonstrate this, imagine a small error in the inferred disk scale height. This will cause noticeable differences in the spiral arm pitch angle , which is much more than the influence of the noise (\u00a72.2). Thus Disk2Planet is generally noise-robust. In contrast, CNN-based methods rely on local spatial patterns, thus are more prone to noises. They result in significantly larger errors when the signal-to-noise ratio is below ten (e.g., a planet mass error of 0.68 dex versus 0.13 dex; Ruzza et al. 2024, \u00a75.3).\nOur inverse problem solver can process incomplete images with missing parts in arbitrary shapes in a straightforward manner. As illustrated in Fig. 3 (Block B), the missing parts are ignored and do not contribute to the parameter inference. In contrast, CNN-based methods require completed images, as every pixel contributes to the convolution, which is key to CNNs in extracting information. In theory, CNNs can also be trained with datasets that have the same missing parts as the real observations. However, this is impractical in real-life applications, because it is often difficult to predict which parts of the image will be missing in real observations, and the missing parts can vary between observations.\nOur inverse problem solver works with input images of any spatial resolution since the entire procedure is resolution-independent. In contrast, CNN-based solvers are often trained on datasets with fixed resolutions. To minimize training costs, low resolutions are typically used, such as 64\u00d764 in Zhang et al. (2022) or 128\u00d7128 in Ruzza et al. (2024), which can degrade detailed disk substructures like spiral arms. Additionally, due to limitations in the training sets, CNN-based tools can only operate properly when the input images have the same resolution as the training sets; if not, regridding is needed, which may result in a loss of information.\nDisk2Planet locates planets by matching their induced substructures with those in the data. This contrasts with CNN-based approaches , which requires users to provide prior knowledge of the planet's location. Augmenting the training dataset in PPDONet to accommodate different planet locations is not needed neither, in contrast to CNN-based approach .\nDisk2Planet has an advantage over the more traditional CNN-based methods when dealing with input images with parameters outside the specified range. Our method leverages the fast forward solver, PPDONet, which generates a modelled image (Fig. 2, panel (c)) based on the inferred parameters at no additional computational cost. This feature enables users to visually compare the modelled image with the input image. When the input image parameters fall outside the"}, {"title": "5. CONCLUSIONS AND FUTURE PERSPECTIVES", "content": "We have developed a fast and fully automated inverse problem solver, Disk2Planet, capable of inferring five parameters the Shakura-Sunyaev viscosity (\u03b1), disk aspect ratio (ho), planet-star mass ratio (q), and the planet's radius and azimuth from 2D steady-state disk-planet systems. Inferring these parameters from surface density in one system takes three GPU minutes on an Nvidia A100 machine. Our solver requires minimal human intervention and is user-friendly for newcomers without prior experience in numerical simulations of disk-planet interactions.\nThe architecture of the solver and an example application are shown in Fig. 2. The solver is built on the machine learning tool PPDONet, which predicts the disk maps created by a planet . The solver employs the evolutionary optimization algorithm CMA-ES , which samples parameters from a 5D Gaussian distribution in each iteration and refines the distribution by minimizing the difference between the model and the input data.\nThe inputs to the solver consist of 2D maps of gas surface density and velocities in a disk. The solver can handle data with unknown noise levels, incomplete data with missing parts, and user-defined combinations of quantities (Fig. 5). It achieves percentage-level or smaller errors in the inferred parameters in the tests performed in this work (Fig. 4), representing at least an order of magnitude improvement over previous tools based on Convolutional Neural Networks. As expected, the errors decrease as more information is provided by the input data.\nThe current version of Disk2Planet may be improved in certain ways. First, it is designed to work with 2D maps of gas surface density and velocities derived from observations , rather than directly with observational data. To extend its functionality to disk observations directly, an updated PPDONet capable of directly predicting synthetic images is required. Training such a network would necessitate a dataset generated from gas+dust simulations and synthetic observations, and sampling additional parameters such as dust properties and planet masses and orbits for multi-planet systems. Once such a dataset is available, future work can readily adapt our approach to update the existing inverse problem solver. These modifications would require minimal changes to the existing PPDONet architecture and our inverse problem solver framework.\nSecond, unlike Auddy et al. (2022) and Ruzza et al. (2024), it does not produce uncertainties on the inferred parameters. However, the forward problem solver employed, PPDONet, provides the predicted disk maps corresponding to the inferred parameters (Fig. 2). These disk maps can be visually compared to data, offering users a straightforward way to evaluate the quality of the inferences.\nThe data and source code for this work will be available at upon publication."}]}