{"title": "GraphPrint: Extracting Features from 3D Protein Structure for Drug Target Affinity Prediction", "authors": ["Amritpal Singh"], "abstract": "Accurate drug target affinity prediction can improve drug candidate selection, accelerate the drug discovery process, and reduce drug production costs. Previous work focused on traditional fingerprints or used features extracted based on the amino acid sequence in the protein, ignoring its 3D structure which affects its binding affinity. In this work, we propose GraphPrint: a framework for incorporating 3D protein structure features for drug target affinity prediction. We generate graph representations for protein 3D structures using amino acid residue location coordinates and combine them with drug graph representation and traditional features to jointly learn drug target affinity. Our model achieves a mean square error of 0.1378 and a concordance index of 0.8929 on the KIBA dataset and improves over using traditional protein features alone. Our ablation study shows that the 3D protein structure-based features provide information complementary to traditional features.", "sections": [{"title": "Introduction", "content": "Predicting drug and target affinity (DTA) can improve drug candidate selection, accelerate drug discovery duration, and reduce drug production costs, repurposing existing drugs [1]. Different techniques such as molecular coupling [2, 3, 4], similarity-based methods, [6, 7], network-based methods [8], and deep learning-based methods. Deep learning methods have been used to perform DTA, and have gained popularity in recent times as they can have higher accuracy and lower prediction time. [9, 10, 11, 12, 17]\n\nExisting deep learning-based methods use amino acid residue sequences in protein to extract features directly or learn feature extractors. [9, 10, 11, 12, 17]. The amino acid sequence can be of primary, secondary, tertiary, and sometimes quaternary structure, as shown in figure 1. The primary structure consists of a sequence of amino acids, and the secondary structure represents the alpha-helical or beta-sheet structure. The tertiary structure consists of folding the chain itself, leading to a 3D structure. Proteins with more than one peptide sequence can have additional folding among each other, leading to a quaternary structure. These higher structures affect the bindings and docking sites of these proteins. Incorporating the 3D structure of a protein can help improve performance on tasks such as drug target affinity prediction. With the advent of accurate 3D protein structure prediction [5], it is now possible to predict the 3D structure of proteins based on amino acid sequence. With the growing size of the 3D protein structure database, incorporating 3D features to learn drug-related features can be a new direction to explore in the field of drug discovery.\n\nDTA has been framed as a binary classification and regression problem. In binary classification, binary labels 0 and 1 are predicted. In a regression problem, drug-target affinity is quantified as a"}, {"title": "Related works", "content": "Different techniques such as molecular coupling [2, 3, 4], similarity-based methods, [6, 7], network-based methods [8], and deep learning-based methods. Deep learning methods have increasingly been used for drug target affinity prediction. Table 1 shows some of the previous state-of-the-art models and their backbone architecture. DeepDTA[9] was one of the first deep learning-based architectures for DTA tasks. The authors used 1D convolution to embed the drug's SMILES representation and protein sequence separately, followed by concatenation and classifier training.\n\nTo improve feature extraction, graph neural network-based architectures have been proposed. GraphDTA[10] is one such earlier work, to use graph neural networks to learn a drug structure representation, combined with CNN for protein sequence. iEdgeDTA [] treats protein sequence as a 1d graph and uses graph convolutional layers to extract protein features, combined with edge-graph convolutional for drug embeddings. BiCompDTA use normalized compression distance and Smith-Waterman measures to generate protein embeddings, that is later used to train deep learning network. Table 1 summarizes the architecture and input data representations used in these methods.\n\nMost previous works treat protein as a sequence of amino acids to either extract hand-crafted features or learn embeddings using neural network-based architectures. This work ignores the secondary, tertiary, or quaternary structure of proteins. These higher structures affect the bindings and docking sites of these proteins. Incorporating the 3D structure of a protein can help improve performance on tasks such as drug target affinity prediction. With recent works like Alphafold [5], it is now possible to predict 3D structures of proteins using their aminoacid sequence."}, {"title": "Methods", "content": "In this section, we describe a framework for a graph representation of protein 3D structure and our architecture, followed by the data set details."}, {"title": "Architecture", "content": "We explore a multimodality approach by using a multi-head network to learn protein/drug embeddings directly from their structure as well as their extracted fingerprints. This allows the model to leverage the complementary information in these representations.\n\nWe create a multihead neural network consisting of four branches. We use a graph convolution-based network for graph representations of proteins/drugs. For fingerprints, we use 1D convolutional blocks to learn embeddings. Figure 2 shows a pictorial representation of the architecture used.\n\nMathematically, for any drug molecule \\(D_i\\) and protein sequence \\(P_i\\), we learn a model \\(F_c\\), as shown in equation 1, where \\(F_{PG}, F_{PF}, F_{DG}, F_{DF}\\) represent branches \\(P_G, P_F, D_G, D_F\\) of the architecture, respectively. The output from three branches is concatenated, before passing through the classifier \\(F_c\\), generating a final prediction of the affinity score \\(Y_i\\).\n\n\\(Y_i = F_c([concat(F_{PG}(P_i), F_{PF}(P_i), F_{DG}(D_i), F_{DF}(D_i))])\\) (1)\n\nBranch \\(P_G\\) and \\(D_G\\) consist of 5 graph blocks in series, followed by a global pool average and a linear block. This helps to extract graph-level feature embeddings from the drug molecule. We add bottlenecks in the architecture to improve the information transfer enforcing model to learn efficient information on embedding information on embedding and lower parameter size. The branches \\(P_F\\) and \\(D_F\\) consist of a 1D convolutional layer and a linear layer. Outputs from all branches are concatenated and passed through fully connected layers to generate the final affinity score."}, {"title": "Graph embeedings", "content": "To generate protein graph representations, we use Alphafold [5] to generate the 3D protein structure of each protein target. Using the 3D structure, we define each amino acid residue as a node. We use the residue's coordinates of the center of mass to represent amino acids. We add additional features, such as amino acid encoding, molecular weight, polarity, solubility, and pKa values, to each node feature. Figure 3 shows the creation of graph representation for protein structure. For drugs, we convert the SMILES string into a molecular graph representation using the open-source library RDKit[21]. Atoms are represented as nodes, and the bonds between them are represented as edges. For node embeddings, we use one-hot encodings of atom type, number of neighboring atoms, number of neighboring hydrogens (explicit and implicit), and implicit valence and aromaticity of molecule."}, {"title": "Fingerprint extraction", "content": "We extract traditional hand-designed features to augment the graph representation. We choose AAC, Conjoint triad fingerprint, and quasi-sequence fingerprint, as they only require the protein's amino acid sequence to acquire. AAC encodes k-mers of amino acids into an 8,420-length bit vector. It can contain sequence neighborhood (local) information. The conjoint triad fingerprint utilizes a hand-made 7-letter alphabet to encode a continuous frequency distribution of three amino acids. This transforms the protein into a homogeneous vector space of a 343-length vector. The quasi-sequence fingerprint contains a residue pair correlation within its 100-length vector. All three of these representations are concatenated before being passed to the network. We use the open-source library iFeature [20] to calculate protein representations.\n\nFor drug molecules, we extract Morgan and Daylight fingerprints using the drug SMILES sequence, generating output of size 1024 and 2048 respectively. Morgan's fingerprint encodes circular radius-2 substructures of a molecule with a 1024-length bit vector. This includes partially disambiguated atom identifiers. The daylight fingerprint encodes path-based substructures into a 2048-length bit vector. We use the Therapeutics Data Commons (TDC) open-source library [22] to calculate these features."}, {"title": "Datasets", "content": "In this work, we use the KIBA dataset for evaluation [19]. The KIBA dataset contains an affinity score that combines \\(K_a\\), an inhibitor constant (\\(K_i\\)), and the half maximum inhibition concentration (\\(IC_{50}\\)). For comparison with previous works, we use a similar dataset generated by filtering all the drug-protein combinations with fewer than 10 interactions. The final dataset contains a total of 2,111 drugs and 229 proteins. The KIBA score ranges from 0.0 to 17.2 and a larger score represents a weaker binding affinity."}, {"title": "Evaluation", "content": "After model training is complete, we freeze the architecture and measure the performance on the test set. We will use the following metrics: Mean Squared Error (MSE) as defined as \\(MSE = \\frac{1}{n}\\sum_{i=1}^{n}(P_i - Y_i)^2\\), where n is the number of data points, P are the predicted affinity values, and Y are the expected affinity values. Lower MSE is better. Concordance Index (CI): [9] compares the predicted order of the binding affinity values corresponding to drug-target interactions with ground truth. CI values greater than 0.8 indicate a strong model. It is defined as \\(CI = \\frac{1}{Z} \\sum_{y_i > y_j} h(p_i - p_j)\\), where \\(h(x) = \\begin{cases} 1 & x > 0\\\\ 0.5 & x = 0\\\\ 0 & x < 0 \\end{cases}\\). \\(r_m\\) metric: measures external prediction performance of Quantitative structure-activity relationship (QSAR) models. This metric is defined as \\(r_m = r \\sqrt{r^2 - r_0^2}\\), where \\(r^2\\) is the squared correlation coefficient with intercept, and \\(r_0^2\\) is without intercept. A value above 0.5 is good. Spearman correlation measures if two variables are monotonically related, as defined by Spearman \\(= 1 - \\frac{6\\Sigma(P - Y)^2}{n(n^2-1)}\\). Pearson Correlation: a measure of the linear correlation between two variables, as defined by: Pearson \\(= \\frac{cov(P,Y)}{\\sigma_P \\sigma_Y}\\).\n\nWe explore the ablation of branches to understand their contributions to the learning of our architecture. We remove one layer at a time and report the metrics of the modified architecture. We also explore errors contributed by individual drugs and proteins to the overall error, by plotting the sum of MAE error per drug or protein."}, {"title": "Results and Discussion", "content": "In this study, we evaluate our trained model on the test subset of the KIBA dataset and compare it to previously reported baselines. Table 2 shows a comparison of the performance metrics of our models with DeepDTa, GraphDTA, iEdgeDTA, and BiCompDTA. Our model achieved 0.3713 RMSE, 0.1378 MSE, 0.8929 CI, Spearman correlation of 0.8852, and Pearson correlation of 0.8920. Our model results are competitive against state-of-the-art models.\n\nWe look into the MAE error contribution of individual proteins and drugs to the overall model MAE error. Figure 4a plots the sum of errors for each protein and drug molecule. As shown in the figure, only a small number of protein and drug molecules are responsible for the majority of errors. Figure 5a, 5b, 5c show scatterplot for the sum of error contribution per drug vs a number of drugs atom counts, aromatic atoms and bonds respectively. We can see that there is a linear relation with increasing atom count making drug affinity prediction harder. The same goes for the number of aromatic and number of bonds."}, {"title": "Ablation study", "content": "We perform architecture ablations by removing one or more branches of the network. At each stage, the model receives one of the two embeddings for both protein and drug. Table 3 shows ablation results for our architecture. All the ablations have lower performance compared to our main architecture. Removing branch PG causes a dip in the concordance index and an increase in the MSE score. This supports our hypothesis that 3D structure provides complementary information to traditional hand-crafted fingerprints. Further, replacing simple architecture with a bottleneck architecture causes an increase of 1.3% in the concordance index."}, {"title": "Limitations and Future work", "content": "There are a few limitations to improve on. Since the generation of 3D structures is a computationally expensive process, we present our results only on the KIBA dataset. More evaluation on multiple datasets is required for a more comprehensive evaluation. In this work, we focus on integrating 3D protein structure representation, we do not perform extensively on graph neural architecture. Using more recent architecture with attention can provide further boost performance. In the future, this work can be further extended and directly implement an explainability layer, pointing to amino acid regions interacting with drugs. It would be worthwhile to quantify error-contributing correlations in protein structures, as understanding the reasoning behind this might also lead to the development of better model architectures."}, {"title": "Conclusion", "content": "In conclusion, our GraphPrint framework is a novel approach for drug target affinity prediction that leverages 3D protein structure features in addition to traditional protein and drug representations. We have demonstrated the potential of our model in improving drug candidate selection, accelerating drug discovery, and reducing production costs. By incorporating protein 3D structure information, our model achieved a mean square error of 0.1378 and a concordance index of 0.8929 on the KIBA dataset, surpassing the performance of models that rely solely on traditional protein features.\n\nWith the advent of accurate 3D protein structure prediction and increasing 3D protein databases, incorporating 3D protein structure for drug target affinity and other approaches can be a new direction to explore in the field of drug discovery and multimodal learning. This research not only enhances our understanding of drug-target interactions but also holds promise for more efficient and cost-effective drug development processes in the future. Further exploration and refinement of our model may pave the way for even more accurate predictions in this critical area of pharmaceutical research."}]}