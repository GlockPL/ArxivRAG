{"title": "Combating Semantic Contamination in Learning with Label Noise", "authors": ["Wenxiao Fan", "Kan Li"], "abstract": "Noisy labels can negatively impact the performance of deep neural networks. One common solution is label refurbishment, which involves reconstructing noisy labels through predictions and distributions. However, these methods may introduce problematic semantic associations, a phenomenon that we identify as Semantic Contamination. Through an analysis of Robust LR, a representative label refurbishment method, we found that utilizing the logits of views for refurbishment does not adequately balance the semantic information of individual classes. Conversely, using the logits of models fails to maintain consistent semantic relationships across models, which explains why label refurbishment methods frequently encounter issues related to Semantic Contamination. To address this issue, we propose a novel method called Collaborative Cross Learning, which utilizes semi-supervised learning on refurbished labels to extract appropriate semantic associations from embeddings across views and models. Experimental results show that our method outperforms existing approaches on both synthetic and real-world noisy datasets, effectively mitigating the impact of label noise and Semantic Contamination.", "sections": [{"title": "Introduction", "content": "In recent years, notable progress has been achieved in various fields through deep learning methodologies (Bochkovskiy, Wang, and Liao 2020; Marriott, Romdhani, and Chen 2021). The use of labeled datasets plays a pivotal role in achieving these notable outcomes. Nevertheless, as datasets continue to expand in size, the probability of encountering noisy labels also increases. Such corrupted knowledge can be assimilated by models, which consequently results in a noticeable decrease in their performance (Zhang et al. 2017; Arpit et al. 2017). This occurrence naturally prompts an urgent inquiry into how deep learning continues to succeed despite the presence of label noise.\nState-of-the-art methods in Learning with Noisy Labels (LwNL) have notably enhanced noise robustness through label refurbishment methods (Malach and Shalev-Shwartz 2017; Song, Kim, and Lee 2019; Chen et al. 2020, 2023). The core idea of label refurbishment methods is to transform problematic labels into new, informative labels for the model to learn. Previous researches (Tarvainen and Valpola 2017; Song, Kim, and Lee 2019; Chen et al. 2023) have shown that label refurbishment methods face self-reinforcing errors and confirmation bias, which can hinder performance.\nMeanwhile, we have also discovered that, in addition to the two previously mentioned drawbacks, label refurbishment methods face another significant issue that can be more detrimental to the model: Semantic Contamination (SC). This scenario pertains to the model's inability to comprehend reasonable semantic associations, leading to the failure to acquire robust and consistent representations. For instance, if a cat is mislabeled in an airplane, the similarity between a cat and a dog could be smaller than the similarity between a cat and an airplane, as illustrated in Fig. 1. For clean datasets, reasonable semantic information can be easily learned by the model. However, in LwNL, samples in the same class could be clustered into different categories, leading to inconsistent predictions. Hence, how to acquire the relevant semantic information remains an open question.\nThis study focuses on how label refurbishment methods can mitigate the impact of noisy labels and Semantic Contamination. We initially analyze why the label refurbishment methods are prone to experiencing Semantic Contamination and observe that directly aligning logits from different models, a common practice in label refurbishment, does not effectively align the embeddings. While aligning the logits of different views can cluster the embeddings, the unequal confidences for each class hinder the models from acquiring appropriate semantic information. Instead of relying solely on refurbishing with logits, we suggest mining latent relevancy in embeddings across views and models to learn semantic information and propose a novel method called Collaborative Cross Learning, which consists of two components: Cross-view learning and Cross-model learning. For Cross-view learning, we decouple the class label and the semantic concept and utilize self-supervised learning to prevent the incorporation of harmful semantic information. For Cross-model learning, we propose promoting the alignment of different models by using Collaborative Contrastive Learning Refurbished Labels (CCLRL) and theoretically establish that optimizing CCLRL enhances mutual information between the two models. The superiority of our method over state-of-the-art (SOTA) methods is demonstrated through validation on various synthetic and real-world benchmarks. Our contributions can be summarized as follows:\n\u2022 We introduce a new challenge called Semantic Contamination in LwNL and analyze the reason why label refurbishment methods may be susceptible to SC from the perspective of views and models.\n\u2022 We propose a novel method called Collaborative Cross Learning. By decoupling the semantic concept between views and mimicking the contrastive distributions between models, it successfully obtains robust and consistent representations while alleviating the damage of both Semantic Contamination and label noise.\n\u2022 Experimental results show that our method advances state-of-the-art results on CIFAR with synthetic label noise, as well as on real-world noisy datasets."}, {"title": "Related Work", "content": "Label Refurbishment in LwNL. For label refurbishment, mainstream methods estimate refurbished labels through three ways: 1) Models: Decouple (Malach and Shalev-Shwartz 2017) updates two models with only disagreed samples between models. SEAL (Chen et al. 2020) retrains the model with the average predictions of the teacher model as refurbished labels. 2) Models and Views: RoLR (Chen et al. 2023) refurbishes noisy labels by aligning the predictions between models and views. 3) Historical predictions: SELFIE (Song, Kim, and Lee 2019) only includes samples with consistent predictions in recent epochs for refurbishment. However, the process of refurbishing labels poses challenges in high-noise environments due to self-refining errors, which can impede the training of models.\nSemi-supervised Learning. The field of semi-supervised learning (SSL) has experienced significant advances through the application of consistency regularization, which aims to minimize the disparity in model predictions between two views of the same sample or two predictions of the same sample using different models. MixMatch (Berthelot et al. 2019) initially aligned outputs from different views and models, but the enhancement strategies for different views were consistent. In contrast, FixMatch (Sohn et al. 2020) utilized both strong and weak transformations, in addition to confidently pseudo-labeling, which led to favorable results. Currently, SSL is also implemented in LwNL, for instance, DivideMix (Li, Socher, and Hoi 2020) incorporates MixMatch in LwNL, while RankMatch (Zhang et al. 2023) partially adopts FixMatch. RoLR (Chen et al. 2023) also employs distinct SSL augmentation strategies. However, SSL is susceptible to confirmation bias, and our experimental results indicate that SSL is still influenced by SC, both of which can impact the model's performance."}, {"title": "Semantic Contamination in LwNL", "content": "As mentioned in the Introduction, Semantic Contamination refers to the phenomenon where, in the presence of latent semantic relationships among samples, a model fails to capture accurate semantic associations. The captured corrupted semantic information often corresponds to noisy labels. Such toxic information is commonly utilized in various label refurbishment methods as part of the pseudo-labels and can harm generalization and lead to poor robustness in LwNL. To address this issue, in this study, we first explore why label refurbishment methods are susceptible to Semantic Contamination. First, we take RoLR (Chen et al. 2023) as an example of label refurbishment methods and analyze the influence of different views and models through which RoLR may have learned potentially erroneous semantic information. We demonstrate that relying solely on views for refurbishing could lead to semantic imbalance among classes, ultimately impairing performance. Apart from that, we find that relying on models for refurbishing cannot even maintain the semantic consistency across models. Addressing these drawbacks is the focus of our method."}, {"title": "Methodology", "content": "The previous section concludes that refurbishments on logits are inadequate for accurate semantic information. To tackle this challenge, we propose a method, named Collaborative Cross Learning, that learns semantic relationships from embedding perspectives. Specifically, we propose two modules: Semantic-wise Decoupling with Confident Learning (SDCL), which can help in balancing the confidence among classes for Cross-view learning, and Embedding-based Interactive Alignment (EIA), which aids in aligning the models and maintaining semantic consistency across models for Cross-model learning. The overall pipeline is shown in Fig. 4 and the algorithm pseudocode is in Appendix.\nSemantic-wise Decoupling with Confident Learning. Similar to Eq. (3), Semantic-wise Decoupling decouples the prediction into the predicted class and the semantic concepts. To avoid the effect of noisy labels, instead of using the logits in Semantic smoothing term, we employ an Augmentation-wise Contrastive Learning approach on embeddings. Strong augmentations are used as anchors to align with weak augmentations to reduce training difficulty, as depicted in Eq. (5).\n$L_{ACL}(x, \\theta) = -log q_w$\n$= - log \\frac{exp(f_s^\\theta(x) \\cdot f_w^\\theta(x))}{\\sum_{j=1}^N exp(f_s^\\theta(x) \\cdot f_w^\\theta(x_j))}$\nwhere N is the batch number, $q_w$ is the contrastive distribution of the model $\\theta$ from strong augmentations s to weak augmentations w.\nIn addition to directly aligning the representations of different views, we also use KL divergence to align the latent relationships of samples between views, named as View-wise Mimicry:\n$L_{VM}(x, \\theta) = KL(q_{o\\rightarrow w}^{\\theta} || q_{w \\rightarrow s}^{\\theta})$\nFor Predicted Guidance term in Eq. (3), considering the influence of noise that the prediction may be corrupted, the sample should only be learned when it exhibits a high confidence in the prediction as Confident Learning:\n$L_{PG}(x, \\theta) = -\\mathbb{1}[y_{pred} \\geq c] \\cdot y_{pred} log p_\\theta^s$\nwhere c is the threshold for confidence and $\\mathbb{1}[.]$ is the characteristic function.\nThe loss of Cross-view Learning (CVL) can be calculated as follows:\n$L_{CVL} = L_{PG} + L_{ACL} + L_{VM}$\n$L_{PG}$ is related to the predicted class and $L_{ACL} + L_{VM}$ can acquire relevant semantic information, separately.\nEmbedding-based Interactive Alignment. In order to get semantic consistency across models, in addition to aligning the logits in Eq. (1), it is necessary to explore cross-model relationships in embeddings. To address this, we introduce a novel approach called Collaborative Contrastive Learning on Refurbished Labels (CCLRL) to fully exploit the information interaction among diverse peer models. Specifically, CCLRL considers same-class samples with strong transformations $f_{\\theta_m}^s(x)$ from $\\theta_m$ and weak transformations $f_{\\theta_{(1-m)}}^{w}(x)$ from $\\theta_{(1-m)}$ as positive sample pairs, while treating all other samples pairs as negative sample pairs, as shown in Eq. (9).\n$L_{CCLRL} (x, \\theta_m, \\theta_{(1-m)}) = -log q_m^{\\theta \\theta_{(1-m)}}$\n$=-\\log \\frac{\\sum_{j=1, Y_j=Y_{x_j}}^N exp(f_{\\theta_m}^s(x) \\cdot f_{\\theta_{(1-m)}}^w (T_j))}{\\sum_{k=1}^N exp(f_{\\theta_m}^s(x) \\cdot f_{\\theta_{(1-m)}}^w (X_k))}$\nGiven the presence of noisy labels, the identification of samples of the same class is based on refurbished collaborative labels $y'$. Furthermore, to avoid self-refining errors, the collaborative refurbished labels for the current model $\\theta_m$ are obtained from another model $\\theta_{(1-m)}$, as shown in Eq. (10).\n$y_{\\theta_m}' = w \\hat{y} + (1-w)P_{\\theta_{(1-m)}}$\nTheoretical Analysis. We attribute the effectiveness of minimizing Eq. (9) to maximizing the lower bound on the mutual information $I(f_{\\theta_m}(x), f_{\\theta_{(1-m)}}(x))$ between $\\theta_m$ and $\\theta_{(1-m)}$, which can be formulated as:\n$I(f_{\\theta_m}(x), f_{\\theta_{(1-m)}}(x)) \\geq log(N) - E[L_{CCLRL}(x, \\theta_m, \\theta_{(1-m)})]$\nModel-wise Mimicry aligns the contrastive distribution q of samples between models:\n$L_{MM}(x, \\theta_m, \\theta_{(1-m)}) = KL(q_{\\theta_m \\rightarrow \\theta_{(1-m)}}^s || q_{\\theta_{(1-m)} \\rightarrow \\theta_m}^w)$\nCombining with the model alignment with logits in Eq. (1), the loss for Cross-model learning (CML) can be formulated as:\n$L_{CML} = L_c(P_{\\theta_m}, P_{\\theta_{(1-m)}}) + L_{CCLRL} + L_{MM}$\nOverall Loss Function. Following (Li, Socher, and Hoi 2020; Chen et al. 2023; Zhang et al. 2023), we apply the regularization $L_{div}$ to increase the diversity of predictions:\n$L_{div} = - \\frac{1}{N} \\sum_{j=1}^N \\sum_{i=1}^C log(\\pi_{[i]})$\nwhere $\\pi_{[i]}$ is the i-th class of the prediction of the strong augmentation of sample $x_j$.\nThe overall loss function for model $\\theta_m$ optimization is as follows:\n$\\mathcal{L} = wL_c(P_{\\theta_m}, \\hat{y}) + \\frac{1-w}{2}(L_{CVL} + L_{CML}) + L_{div}$"}, {"title": "Experiments", "content": "Experimental Setup\nDatasets. To verify the effectiveness of our method, we perform our method on classification tasks with six benchmarks: CIFAR-10 (Krizhevsky, Hinton et al. 2009), CIFAR-100 (Krizhevsky, Hinton et al. 2009), CIFAR-10N (Wei et al. 2022), CIFAR-100N (Wei et al. 2022), Animal-10N (Song, Kim, and Lee 2019) and WebVision (Li et al. 2017). The last four benchmarks are real-world noisy datasets.\nSynthetic noise injection. Under such an assumption that the corruption process is conditionally independent of data features when the true label is given (Song et al. 2020; Zhang et al. 2017), we can construct the dataset containing noises by the noise transition matrix T (Song et al. 2020; Jiang et al. 2018; Malach and Shalev-Shwartz 2017; Song, Kim, and Lee 2019), where $T_{ij} = p(\\hat{y} = j|y = i)$ is the probability of the clean label i being corrupted into a noisy label j. T can model two types of noises: (1) symmetric noise (Sym): $\\forall i \\neq j, T_{ij} = \\frac{\\epsilon}{C-1}$ and (2) pair noise (Pair): $\\exists i \\neq j, T_{ij} = \\epsilon,  \\forall k \\neq i, k \\neq j, T_{ik} = 0$, which is also known as the asymmetric noise. To evaluate the performance on varying noise rates from light noises to heavy noises, we run our method and other methods on different noise rates $\\epsilon \\in \\{0.2, 0.4, 0.5, 0.8\\}$.\nWe have also conducted experiments with another type of noise: instance-dependent noise (Ins) (Chen et al. 2020). Unlike the above two types of noise, Ins allows the label noise to depend mandatorily on the samples, and optionally on the labels.\nWeak and strong augmentations in our paper are identical with (Chen et al. 2023). All the results from our runs are the average test accuracy over the last 10 epochs. We replicated experimental results that were missing from the corresponding papers. A detailed description of Comparison Methods"}, {"title": "Experimental Results", "content": "Results on CIFAR with synthetic noise. Tab. 1 illuminates our method outperforms the state-of-the-art models across all noisy levels on CIFAR-10/100 with different types of synthetic noise. Benefiting from the advanced semantic mining mechanism, our method can boost the averaged test accuracy of the last 10 epochs from 94.2% to 94.6% on CIFAR-10 and 66.2% to 70.3% on CIFAR-100 under the extreme case of 80% noise compared with RoLR (Chen et al. 2023). Compared with sample selection methods such as RankMatch (Zhang et al. 2023), our method can achieve around 3.1% (70.3% v.s. 67.2%) on CIFAR-100 with 80% noisy labels. We surpass DMLP (Tu et al. 2023), a recent semi-supervised learning-based method, under all noise ratios, especially on the more challenging CIFAR-100 dataset with extreme noise.\nResults on real-world datasets. Tab. 2, Tab. 3 and Tab. 4 demonstrate the results on CIFAR-N, Animal-10N and WebVision, respectively. Our method demonstrates superior performances compared to all other methods across various noisy real-world datasets. In particular, compared with RoLR, our method achieves 1.2% performance gains in Aniaml-10N. Besides, compared with UNICON (Karim et al. 2022), another hybrid method that combines the advantages of semi-supervised learning and contrastive learning, our method surpasses the SOTA by over 3% in top-1 accuracy on both mini-WebVision and ILSVRC12 validation sets, ensuring the SOTA top-5 accuracy on WebVision and ILSVRC12, demonstrating the effectiveness of our method.\nResults on Semi-supervised learning methods in LwNL. In addition to label refurbishment methods, recent research has widely adopted semi-supervised learning mechanisms like MixMatch (Berthelot et al. 2019), such as DivideMix (Li, Socher, and Hoi 2020), to overcome the impact of noise. However, these methods also face the challenge of Semantic Contamination. To address this issue, we integrate ($L_{CVL}$ and $L_{CML}$) into the existing loss function to further enhance the learning of better semantic information. From the results shown in Tab. 5, we can uncover the following empirical results: 1) Semi-supervised learning methods do not actually receive proper semantic information. By utilizing both ($L_{CVL}$ and $L_{CML}$), the model can acquire better semantic information, resulting in performance enhancement. 2) Ensuring semantic consistency between the two models ($L_{CML}$) can yield greater performance improvements compared to learning semantic information between views ($L_{CVL}$). This also implies the importance of addressing semantic inconsistencies between two models.\nResults for combating Semantic Contamination. To validate the effectiveness of our method in combating Semantic Contamination, we initially train our method and ROLR on CIFAR-100 with 80% symmetric noise. We pick up samples with accurate predictions but differing second-"}, {"title": "Conclusion", "content": "In this paper, we study the problem of Semantic Contamination together with label noise. We analyze the drawbacks of label refurbishment methods and explain why these methods cannot overcome Semantic Contamination. The conclusion motivates us to propose our method that can learn the more reasonable semantic information through Semantic Decoupling with Confident Learning and Emebdding-based Interactive Alignment. Experimental results illustrate that our method surpasses current methods in performance on synthetic and real-world noisy datasets, effectively reducing the influence of label noise and Semantic Contamination. In the future, we will further explore the theoretical foundation and generalization analysis of our method."}, {"title": "Appendix", "content": "Details of our method\nWarm-up. (Arpit et al. 2017) shows that the deep neural network tend to learn clean samples first. Therefore, we follow the process of recent work (Han et al. 2018; Song, Kim, and Lee 2019; Chen et al. 2023) that warms two models in the early stages. In the warm-up phase, the objective function is the vanilla cross-entropy without performing label refurbishment operations. For CIFAR-like datasets, we consider the first 30 epochs as warm-up. For ImageNet-like datasets, we consider the first 80 epochs as warm-up.\nConfidence estimation. Recent studies (Arpit et al. 2017; Han et al. 2018; Song, Kim, and Lee 2019; Chen et al. 2023) have demonstrated that models are inclined to present smaller losses on clean samples. Therefore, we can use the loss value to judge whether the sample is clean or not. Following the process in (Han et al. 2018; Song, Kim, and Lee 2019; Chen et al. 2023), we first calculate the cross-entropy loss per-sample between the noisy label and the prediction through the other model $\\theta_{(1-m)}$ and use a two-component one-dimensional GMM to separate the datasets for training the current model $\\theta_m$, as shwon in Eq. (16).\n$W = GMM(\\{L_i(\\hat{y}, P_{\\theta_{(1-m)}}^s)\\})$\nwhere $W = \\{w_i\\}$ is the label confidence which equals to the probability of each sample belonging to the GMM component with a smaller mean (Chen et al. 2023). The training of GMM follows the standard practice (Song, Kim, and Lee 2019).\nPesudo-code of our method. As shown in Algorithm 1, we perform the pesudo-code of our method.\nDetails of different augmentation strategies\nIn our method, we use two augmentation strategies for training. In particular, the weak augmentation consists of random crop and random horizontal flip. The strong transformation consists of RandAugment (Cubuk et al. 2020) and Cutout (Devries and Taylor 2017). RandAugment initially selects a specified number of operations randomly from a predetermined set of transformations, which includes geometric and photometric transformations like affine transformation and color adjustment. Subsequently, these operations are implemented with designated magnitudes. Cutout involves randomly masking square regions of images. These augmentations are then sequentially applied to the input images (Chen et al. 2023).\nProof of maximizing the lower bound of the mutual information\nFor the sake of simplicity in the proof, we exclusively focus on individual positive sample pairs, where the same sample is depicted by different models. Furthermore, based on t-SNE analysis, it is apparent that samples from distinct perspectives can be readily aligned, as illustrated in Fig. 2(a). Consequently, we do not factor in the distinctions between various views in this proof. So, in Eq. (9), given the anchor embedding $f_{\\theta_m}(x)$ from $\\Theta_m$ and contrastive embeddings $f_{\\theta_{(1-m)}}(x)$ from $\\Theta_{(1-m)}$, we formulate the $(f_{\\theta_m}(x), f_{\\theta_{(1-m)}}(x))$ as the positive pair and $\\{(f_{\\theta_m}(x), f_{\\theta_{(1-m)}}(X_j))\\}_{j=1}^{N-1}$ as negative pairs. To generalize, we set m = 0 in the proof. The the joint distribution is $\\mu(f_0, f_1)$ and the product of marginals is $\\mu(f_0)\\mu(f_1)$. The distribution q with an indicator variable K can represent whether a pair $(f_0, f_1)$ is drawn from the joint distribution (K = 1) or the product of marginals (K = 0):\nq($f_0$, $f_1$|K = 1) = $\\mu$($f_0$, $f_1$)\nq($f_0$, $f_1$ K = 0) = $\\mu$($f_0$)$\\mu$($f_1$)\nTherefore, K = 1 can also indicate the positive pair ($f_0$(x), $f_1$(x)) while K = 0 can indicate a negative pair from $\\{(f_0(x), f_1(x_j))\\}_{j=1}^{N-1}$. Based on our approach and the assumptions mentioned earlier, we have one positive pair for every N - 1 pairs. Therefore, the prior probabilities of the variable K are:\nq(K = 1) = $\\frac{1}{N}$\nq(K = 0) = $\\frac{N-1}{N}$\nWe use Bayes' rule to derive the class posterior of the pair ($f_0$, $f_1$) belonging to the positive case (K = 1).\nq(K = 1 | $f_0$, $f_1$) = $\\frac{q(f_0,f_1|K=1)q(K=1)}{q(f_0,f_1|K=1)q(K=1) + q(f_0,f_1|K=0)q(K=0)} = \\frac{\\mu(f_0,f_1)}{\\mu(f_0,f_1) + (N-1)\\mu(f_0)\\mu(f_1)}$\nThe log class posterior can be further represented as follows:\nlogq(K = 1|$f_0$, $f_1$) = log$\\frac{\\mu(f_0,f_1)}{\\mu(f_0,f_1) + (N-1)\\mu(f_0)\\mu(f_1)} = -log(1 + (N-1)\\frac{\\mu(f_0)\\mu(f_1)}{\\mu(f_0,f_1)}) <-log(N) + log\\frac{\\mu(f_0,f_1)}{\\mu(f_0)\\mu(f_1)}$\nBy calculating expectations over the log class posterior, we can establish a connection to the mutual information in the following manner:\n$E_{q(f_0,f_1|K=1)} logq(K=1|f_0,f_1) <-log(N) + E_{\\mu(f_0,f_1)}log(\\frac{\\mu(f_0,f_1)}{\\mu(f_0)\\mu(f_1)}) = -log(N) + I(f_0,f_1)$\nIn fact, CCLRL can be seen as the negative log class posterior of the positive pair:\n$L_{CCLRL} = -logq(K=1|f_0,f_1)$\nTherefore, we can connect $L_{CCLRL}$ to the mutual information I($f_0, f_1$) as follows:\n$E[L_{CCLRL}] >= log(N) - I(f_0, f_1)$\n$\\Rightarrow$ I($f_0, f_1$) >= log(N) - $E[L_{CCLRL}]$\nDetails of the experimental setup\nBrief introduction of the datasets. CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset, with 50000 training colour images and 10000 test colour images in 10 classes (100 classes). CIFAR-10N and CIFAR-100N equip CIFAR-10 and CIFAR-100 with human-annotated real-world noisy labels researchers collected from Amazon Mechanical Turk. They have various types of noise such as Aggregate, Random, Worst or Fine. Animal-10N (Song, Kim, and Lee 2019) is a noisy dataset from the real world, with a noise rate expected to be around 8% and 50000 training colour images and 5000 test colour images in 10 confusing classes. WebVision (Li et al. 2017) comprises web-crawled images with similar concepts as ImageNet ILSVRC12 (Deng et al. 2009). We follow the previous works (Chen et al. 2023; Zhang et al. 2023) and compare baselines on the first 50 classes of ImageNet ILSVRC12 dataset.\nBrief introduction of comparison methods.\n\u2022 Decoupling (Malach and Shalev-Shwartz 2017) sends samples from the two models with inconsistent outputs to each other for training.\n\u2022 Co-teaching (Han et al. 2018) trains the models using the selected clean samples and co-training mechanism(Blum and Mitchell 1998).\n\u2022 Co-teaching+ (Yu et al. 2019) further develops Co-teaching and only used disagreement samples in selected small-loss samples for training.\n\u2022 JoCoR (Wei et al. 2020) uses two networks together to get two different views of the dataset but binds them by an joint loss, making their prediction consistent.\n\u2022 APL (Ma et al. 2020) assemblages two robust loss functions that mutually boost each other.\n\u2022 Co-learning (Tan et al. 2021) aligns the knowledge from supervised and unsupervised learning in a cooperative way to ensure that the model learns clean knowledge.\n\u2022 Cycle-Consistency Reg. (Cheng et al. 2022) reduces the side-effects of the inaccurate noisy class posterior through a novel forward-backward cycle-consistency regularization.\n\u2022 SELC (Lu and He 2022) refines the model by gradually reducing supervision from noisy labels and increasing supervision from ensemble predictions to retain the reliable knowledge in early stage of training.\n\u2022 LC (Wei et al. 2023) clamps the norm of the logit vector to mitigate the overfitting to noisy samples.\n\u2022 RankMatch (Zhang et al. 2023) propose rank contrastive loss, which strengthens the consistency of similar samples regardless of their potential noisy labels and facilitates feature representation learning.\n\u2022 DMLP (Tu et al. 2023) decouples the label correction process into label-free representation learning and a simple meta label purifier and can be pluged into various LwNL methods.\nImplementation Details. For the classification task, we implement all methods with default parameters in Pytorch 1.8, and conduct all the experiments on NVIDIA 3090 GPU. We utilize ResNet-18(He et al. 2016) for CIFAR and CIFAR-N datasets. For Animal-10N and WebVision, we use ResNet-50 (He et al. 2016). For the fair comparison, we choose Adam optimizer (momentum=0.9) is with an initial learning rate of 0.001, and the batch size and the epoch are set to 128 and 500 for CIFAR-10, CIFAR-100, CIFAR-10N and CIFAR-100N. For the different comparison methods the hyperparameters have been set according to those given in the original paper. The warm-up epoch is 10 epochs for CIFAR-10 and 30 epochs for CIFAR-100, respectively. In our method, we set c = 0.95, T = 0.5 as the default value. We report the average performance of our method over 3 trials with different random seeds for generating noise and parameters initialization.\nMore Comprehensive Analysis on Semantic Contamination.\nWe have incorporated additional metrics and analyses to further elucidate the performance of our method. Specifically, we employ LCA metric (Shi et al. 2024), which quantifies the semantic distance between two classes using class taxonomy. A lower LCA score between the top-1 and top-2 logits indicates that the model has learned a closer semantic relationship, implying that the model experiences reduced levels of semantic contamination (SC). We applied this metric to the model's output to provide a quantitative assessment of our method's performance, as detailed in Tab. 8. The experimental results demonstrate that our method achieves better semantic relevance, providing an experimental basis for the analysis in Fig. 1.\nMore discussion on Computational Efficiency.\nThe computational complexity of our method is O(M \u00b7 N + 2 \u00b7 B \u00b7 N), where M and N represent the sizes of the models and dataset, respectively, and B denotes the batch size.\nComparison with more SOTA methods on Mini-Web dataset.\nNGC (Wu et al. 2021) and Sel-CL+ (Li et al. 2022) are two important baselines for comparison. We supplement the relevant results, as shown in Tab. 9. The experimental results show that our algorithm achieves better performance and enhances the robustness of the model."}]}