{"title": "Foundation Model for Composite Materials and Microstructural Analysis", "authors": ["Ting-Ju Wei", "Chuin-Shan Chen"], "abstract": "The rapid advancement of machine learning has unlocked numerous opportunities for materials science, particularly in accelerating the design and analysis of materials. However, a significant challenge lies in the scarcity and high cost of obtaining high-quality materials datasets. In other fields, such as natural language processing, foundation models pre-trained on large datasets have achieved exceptional success in transfer learning, effectively leveraging latent features to achieve high performance on tasks with limited data. Despite this progress, the concept of foundation models remains underexplored in materials science. Here, we present a foundation model specifically designed for composite materials. Our model is pre-trained on a dataset of short-fiber composites to learn robust latent features. During transfer learning, the MMAE accurately predicts homogenized stiffness, with an $R^2$ score reaching as high as 0.959 and consistently exceeding 0.91, even when trained on limited data. These findings validate the feasibility and effectiveness of foundation models in composite materials. We anticipate extending this approach to more complex three-dimensional composite materials, polycrystalline materials, and beyond. Moreover, this framework enables high-accuracy predictions even when experimental data are scarce, paving the way for more efficient and cost-effective materials design and analysis.", "sections": [{"title": "Introduction", "content": "The mechanical properties of composite materials are highly dependent on their microstructure. Understanding and predicting the effective properties of composites based on their microstructural configurations is crucial for designing and optimizing advanced materials. Machine learning (ML) models have emerged as valuable tools for rapidly predicting these properties, opening new avenues in materials science research [1-6]. For instance, Abueidda et al. [3] developed a convolutional neural network (CNN) to predict the mechanical properties of two-dimensional checkerboard composites. In addition to CNNs, other architectures have been employed to address different aspects of material property prediction. Mianroodi et al. [4] utilized a U-Net architecture to predict the stress fields in polycrystalline materials, demonstrating the ability of ML models to capture complex stress distributions. Graph neural networks (GNNs) have also been integrated with deep material networks to predict the mechanical responses of composites [5]. Furthermore, Zhongbo et al. [6] employed a pre-trained transformer model to predict the mechanical response of elastoplastic composite materials, illustrating the versatility of transformer architectures in materials modeling.\nWhile these models have achieved considerable success, they predominantly rely on supervised learning, which requires large, labeled datasets for training. The necessity of extensive datasets poses a significant challenge due to the scarcity and high cost of acquiring training data, whether through experiments or simulations. Moreover, many of these models are problem-specific and may not generalize to different tasks, limiting their broader applicability [7]. In contrast, self-supervised learning approaches have revolutionized fields such as natural language processing (NLP) and computer vision by reducing the dependence on labeled data. Notably, models like BERT (Bidirectional Encoder Representations from Transformers) [8, 9] have utilized masked language modeling to learn rich representations from unlabeled text data. The advent of foundation models has further centralized information from diverse data modalities, enabling a single model to be adapted for a wide range of downstream tasks [10, 11].\nThe concept of foundation models has also been successfully applied to computer vision. Masked autoencoders (MAEs), introduced by He et al. [12], employ a strategy analogous to BERT by masking portions of the input image and training the model to reconstruct the missing parts. In these MAEs, the encoder is replaced with vision transformers (ViTs) [13], and the decoder is a lightweight transformer designed for reconstruction. MAEs have demonstrated performance that, in some instances, outperforms state-of-the-art contrastive learning methods with ViTs, highlighting the efficacy of self-supervised learning in visual domains [14]. Despite these advancements, exploring foundation models within materials science remains limited. Applying self-supervised learning to materials offers the potential to overcome data scarcity and enhance model generalizability across different tasks and material systems. Therefore, in this work, we propose a foundation model specifically designed for composite materials, termed the material masked autoencoder (MMAE), to validate the feasibility of this approach.\nWe generated a dataset comprising 100,000 grayscale images of short-fiber composites to facilitate self-supervised learning. By pre-training the MMAE on this dataset,"}, {"title": "Results and Discussion", "content": "the model learns robust and representative embeddings of the composite microstructures without reliance on labeled data. We anticipate that these embeddings capture essential features of the microstructures, making them highly informative for downstream tasks. To evaluate the effectiveness of the pre-trained MMAE, we employed direct numerical simulation (DNS) to generate datasets of homogenized stiffness for two types of composites: short-fiber composites and circular inclusion composites. We then fine-tuned the pre-trained models on significantly smaller labeled datasets to predict the homogenized stiffness of composites. Our results demonstrate that the MMAE achieves high accuracy, with a coefficient of determination ($R^2$) reaching as high as 0.959 and consistently exceeding 0.91 even when trained on limited data. This performance highlights the potential of the MMAE as a foundation model for composite materials and paves the way for more efficient and cost-effective materials design and analysis."}, {"title": "Pre-trained MMAE reconstruction performance", "content": "To assess the pre-trained MMAE's ability to capture latent features of composite microstructures, we evaluated its reconstruction performance using a high masking ratio of 85%, leaving only 15% (29 out of 196) of image patches visible during training. This challenging setup tests the model's generalization capabilities on unseen data from downstream task datasets.\nAs shown in Fig. 1, the pre-trained MMAE accurately reconstructs composite microstructure instances, including both short-fiber and circular inclusion composites, despite the severe masking employed during training. Notably, although the circular inclusion composites were not included in the pre-training dataset, the MMAE could still reconstruct them effectively. These results demonstrate the MMAE's robustness in learning representative microstructural features and its capacity to generalize to unseen microstructures, indicating its potential for effective transfer learning in downstream tasks."}, {"title": "Transfer learning performance", "content": "To evaluate the effectiveness of the embeddings learned by the pre-trained MMAE, we conducted transfer learning experiments on three downstream regression tasks aimed at predicting the homogenized stiffness components ($C_{1111}, C_{2222}, C_{1212}$). We utilized two datasets for these tasks: the short-fiber composite dataset and the circular inclusion composite dataset."}, {"title": "Linear probing", "content": "To assess the utility of the latent features extracted by the MMAE, we performed linear probing by training a linear regression model on top of the fixed pre-trained embeddings to predict the homogenized stiffness components. We investigated the impact of the masking ratio used during pre-training on the linear probing performance for both the short-fiber and circular inclusion composite datasets."}, {"title": "End-to-end fine-tuning", "content": "To evaluate the model's potential to capture nonlinear relationships in the data, we performed end-to-end fine-tuning of the MMAE on the downstream tasks. Unlike linear probing, end-to-end fine-tuning updates all the parameters of the MMAE during training on the downstream tasks, allowing the model to adapt fully to the specific task.\nAs shown in Fig. 4, the end-to-end fine-tuning performance on the short-fiber composite dataset is relatively insensitive to the masking ratio used during pre-training. In"}, {"title": "Partial fine-tuning", "content": "We conducted partial fine-tuning experiments to explore the MMAE's behavior in the intermediate regime between linear probing and end-to-end fine-tuning. In partial fine-tuning, only the last few transformer blocks of the model are updated during training on the downstream task, while the earlier blocks remain frozen. This approach allows the model to adjust task-specific representations in the fine-tuned blocks while retaining the general feature representations learned during pre-training in the frozen blocks.\nFig. 6 illustrates the performance on the short-fiber composite dataset as a function of the number of blocks fine-tuned. Here, tuning 0 blocks corresponds to linear probing, and tuning all 12 blocks corresponds to end-to-end fine-tuning. The results show that the accuracy improves as more blocks are fine-tuned, indicating better predictive performance. Notably, the performance increases significantly when the last two blocks are fine-tuned and then begins to plateau, suggesting that fine-tuning even a tiny portion of the model's parameters can capture the necessary task-specific features.\nThis observation implies that the relationship between the pre-trained embeddings and the homogenized stiffness components exhibits mild nonlinearity. Fine-tuning just a couple of transformer blocks is sufficient to adapt the model to these nonlinear"}, {"title": "Model explainability", "content": "To explore the explainability of the MMAE during transfer learning, we utilized saliency maps to understand how the model focuses on different regions of the microstructure images when predicting the homogenized stiffness components. Saliency maps highlight the most critical regions of the input that influence the model's output, providing visual insights into the model's decision-making process.\nWe analyzed the saliency maps for both linear probing and end-to-end fine-tuning using the MMAE pre-trained with an 85% masking ratio. Four microstructure images were selected from the validation set of the short-fiber composite dataset for this analysis. For each image, we generated saliency maps corresponding to the predictions of the stiffness components $C_{1111}, C_{2222}, and C_{1212}$.\nAs shown in Fig 7, during linear probing, the saliency maps indicate that the model assigns higher importance predominantly to the matrix regions of the microstructures when predicting all stiffness components. This suggests that the model, constrained by linear regression and with frozen encoder weights, relies mainly on the matrix phase to infer the homogenized stiffness. The emphasis on the matrix implies that the model is not fully capturing the contributions of the fibers and their interactions with the matrix, which are critical to the composite's mechanical properties. This limitation potentially hinders the model's predictive accuracy.\nIn contrast, Fig 8 shows that after end-to-end fine-tuning, the saliency maps highlight the matrix-fiber interfaces more prominently. This shift in focus indicates that the fine-tuned model has learned to capture the nonlinear relationships and critical interactions at the interfaces that significantly influence the composite's overall stiffness. By paying attention to these regions, the model effectively accounts for factors such as fiber orientation and aspect ratio, essential for accurately predicting the homogenized stiffness components.\nThe change in saliency patterns from emphasizing the matrix regions in linear probing to focusing on the matrix-fiber interfaces after fine-tuning demonstrates how fine-tuning enables the model to adapt its learned representations to capture more complex and relevant microstructural features. This adaptation improves the model's ability to encode critical aspects of the microstructure, leading to enhanced performance in predicting the homogenized stiffness components compared to linear probing."}, {"title": "Impact of dataset size in transfer learning", "content": "To evaluate the influence of dataset size during transfer learning, we selected the MMAE pre-trained with a masking ratio of 85% and varied the number of instances in the fine-tuning dataset. As shown in Fig. 9, we observed that the model's average validation set $R^2$ score is relatively low when the dataset is very small. However, even with a dataset containing only 500 instances, the model achieves a validation"}, {"title": "Methods", "content": "Additionally, exploring downstream tasks involving more complex, nonlinear material behaviors could further demonstrate the versatility of the MMAE. For instance, integrating the microstructural features extracted by the MMAE with deep material networks [17] could enable more effective extrapolation and prediction of material nonlinearities. This approach would facilitate modeling phenomena such as plasticity, damage, and fracture, which are critical for designing materials with tailored mechanical responses. By advancing the capability of foundation models like the MMAE to encompass a broader range of material behaviors and structures, we can accelerate the discovery and optimization of advanced materials, ultimately contributing to significant advancements in computational materials science and engineering.\nIn conclusion, our study demonstrates that the MMAE effectively captures essential features of composite microstructures through self-supervised pre-training, enabling high accuracy in predicting homogenized stiffness components with minimal labeled data and computational resources. The combination of robust feature learning, adaptability through fine-tuning, and efficiency in data utilization positions the MMAE as a powerful foundation model for composite materials. These findings suggest that similar approaches could be extended to more complex material systems, further advancing the field of machine learning in materials science."}, {"title": "Masked autoencoders", "content": "The MMAE employed in this study was primarily based on the MAE architecture proposed by He et al. [12]. As depicted in Fig. 10, the MMAE consists of an encoder-decoder structure, where the encoder is a standard ViT [13] with 12 transformer blocks, and the decoder comprised 8 transformer blocks. Each composite image, originally of size 224 x 224 pixels, was partitioned into 196 non-overlapping patches through a process known as patchification. Each patch was of size 16 \u00d7 16 grayscale pixels. These patches were then flattened and embedded into tokens suitable for input into the transformer encoder.\nWe applied random masking to a specified proportion of the image patches to introduce the self-supervised learning objective. Specifically, a random subset of patches without replacement was selected to be masked according to a predetermined masking ratio. For example, with a masking ratio of 85%, only 15% (29 out of 196) of the patches remained visible.\nThe tokens corresponding to the visible patches were fed into the encoder, which processes them through its transformer blocks to produce latent feature representations. Accordingly, the decoder received the encoder's latent features and positional embeddings for visible and masked patches. It reconstructed the pixel values of the masked patches using its transformer blocks, integrating contextual information from the encoded features. By reconstructing the missing patches, the decoder helps the model learn to infer unseen parts of the microstructure from the available information.\nThe training objective was to minimize the mean squared error (MSE) between the reconstructed and original pixel values, computed only over the masked patches. By focusing the reconstruction loss solely on the masked patches, the MMAE was"}, {"title": "Transfer learning", "content": "To evaluate the effectiveness of the embeddings learned by the pre-trained MMAE for predicting homogenized material properties, we employed transfer learning techniques utilizing the [cls] token output from the encoder as a global representation of the input microstructure. We explored linear probing and fine-tuning approaches, as illustrated in Fig. 11."}, {"title": "Linear probing", "content": "We performed linear probing to assess the robustness of the latent features extracted by the MMAE. Specifically, we utilized the [cls] token output from the frozen MMAE encoder to represent each input microstructure image. The [cls] token is a unique token added to the sequence of patch embeddings during encoding, designed to capture a global representation of the entire input image. By freezing the encoder weights, we ensured that the learned features remained unchanged during this step."}, {"title": "Fine-tuning", "content": "We also used the [cls] token output from the MMAE encoder for fine-tuning as the input representation. However, unlike linear probing, we updated the encoder weights during training. We conducted two types of fine-tuning:\n1. End-to-end fine-tuning: In this approach, we allowed all the parameters of the MMAE encoder to be updated during training on the downstream regression tasks. This means the model could adjust its learned representations to better predict homogenized stiffness components. Again, we used the [cls] token to represent the input microstructure and trained a regression head on top of it.\n2. Partial fine-tuning: To investigate the impact of fine-tuning only a subset of the model parameters, we performed partial fine-tuning. Specifically, we fine-tuned only the last few transformer blocks of the encoder while keeping the earlier layers frozen. By doing so, we aimed to adjust task-specific representations in the fine-tuned blocks while retaining the general feature representations learned during pre-training in the frozen blocks. This approach allows us to explore a balance between computational efficiency and model performance. The [cls] token was used as the input to the regression head."}, {"title": "Dataset generation", "content": "The regression head consisted of a fully connected feedforward neural network optimized using the MSE loss function for both fine-tuning methods."}, {"title": "Generation of microtrsturce", "content": "We generated synthetic microstructures for pre-training the MMAE and downstream tasks using the random sequential adsorption (RSA) method [18]. RSA is a stochastic process wherein particles are randomly and sequentially placed into a domain without overlapping, allowing us to create composite microstructures with inclusions of varying quantities, shapes, sizes, and orientations. This method effectively simulates realistic materials systems by capturing the randomness inherent in composite microstructures.\nFor the short-fiber composites, we considered representative volume elements (RVES) containing elliptical inclusions (fibers) dispersed within a matrix. The microstructures were defined within a three-dimensional descriptor space characterized by:\n1. Number of Particles (Np): The number of fibers in each RVE, ranging from 15 to 35.\n2. Aspect Ratio (Ar): The ratio of the major to minor axes of the elliptical fibers, ranging from 1 to 4.\n3. Volume Fraction (vf): The fraction of the RVE volume occupied by the fibers, ranging from 10% to 40%.\nThe actual sizes of the fibers in the RVEs were determined based on Np and vf. The orientations of the fibers were assigned randomly during their placement within the RVEs to mimic the stochastic nature of natural materials.\nWe generated two datasets using Latin hypercube sampling [19] for the short-fiber composites. A large dataset comprising 100,000 grayscale images of short-fiber composite microstructures was used for self-supervised pre-training of the MMAE. This dataset captured various fiber arrangements, aspect ratios, and volume fractions, enabling the MMAE to learn robust and generalizable features from diverse microstructures. An additional dataset of 5,000 short-fiber composite microstructures was generated for the downstream regression tasks. DNS was performed on these microstructures to compute their homogenized stiffness components. The dataset was divided into training and validation sets for these tasks with an 80/20 split.\nFor the circular inclusion composites, we generated 5,000 microstructures by uniformly sampling the volume fraction of within the range of 10% to 40%. The inclusions were circular, and their sizes were fixed. The inclusions varied according to the specified volume fractions to maintain the desired vf. This dataset evaluated the MMAE's transfer learning performance on a different composite system with distinct microstructural characteristics."}, {"title": "Direct numerical simulation", "content": "To obtain the homogenized stiffness components of the generated microstructures, we performed DNS using the RVE module available in LS-DYNA [20]. The simulations"}, {"title": "Saliency map", "content": "were conducted under periodic boundary conditions to capture the effective mechanical response of the composites accurately.\nThe material properties assigned to the matrix and inclusions were as follows:\n\u2022 Matrix: Young's modulus $E = 100$ GPa, Poisson's ratio $v = 0.30$.\n\u2022 Short-fiber/Circular-inclusion: Young's modulus $E = 500$ GPa, Poisson's ratio $v = 0.19$.\nWe assumed linear elastic material behavior for both phases to compute the homogenized stiffness components. The focus was on predicting the homogenized stiffness components $C_{1111}, C_{2222}, and C_{1212}$, which are critical for characterizing the elastic properties of the composites.\nThe DNS computations provided the necessary labels (homogenized stiffness components) for training and validation during transfer learning. Using consistent material properties and simulation conditions, we ensured the datasets were suitable for assessing the MMAE's ability to learn and generalize effective material representations.\nWe utilized saliency maps to investigate the explainability of MMAE and pinpoint the regions of the microstructure images that have the most significant influence on the model predictions. Saliency maps highlight the input areas that impact the model's output most, offering visual insights into the model's decision-making process. They are widely used in various fields, such as image classification and object detection, to assess the relative importance of individual input features in model predictions [21-24].\nIn this study, since the task was a regression, the saliency map M was computed based on the gradient of the MSE loss between the predicted value y and the ground truth \u0177 with respect to the input features. The saliency map for a specific input instance $X_o$ is defined as:\n$M = \\frac{\\partial MSE(y, \\hat{y})}{\\partial X}|_{X_o}$ (1)\nwhere X represents the input features, and $X_o$ refers to a specific input instance. The absolute value of the gradients M captures the sensitivity of the MSE loss to variations in each input feature, reflecting how changes in the input influence the predicted output.\nLarger values in the saliency map M indicate input features that influence the model's output more. This is because higher gradient magnitudes imply that even small perturbations in these features can lead to significant changes in the MSE loss. By visualizing these saliency maps, we can pinpoint the most influential regions within the microstructure images for predicting the homogenized stiffness components."}]}