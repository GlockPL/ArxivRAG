{"title": "TASK ARITHMETIC IN TRUST REGION:\nA TRAINING-FREE MODEL MERGING APPROACH\n\u03a4\u039f NAVIGATE KNOWLEDGE CONFLICTS", "authors": ["Wenju Sun", "Qingyong Li", "Wen Wang", "Yangli-ao Geng", "Boyang Li"], "abstract": "Multi-task model merging offers an efficient solution for integrating knowledge\nfrom multiple fine-tuned models, mitigating the significant computational and\nstorage demands associated with multi-task training. As a key technique in this\nfield, Task Arithmetic (TA) defines task vectors by subtracting the pre-trained\nmodel (\\( \\Theta_{\\text{pre}} \\)) from the fine-tuned task models in parameter space, then adjusting the\nweight between these task vectors and \\( \\Theta_{\\text{pre}} \\) to balance task-generalized and task-\nspecific knowledge. Despite the promising performance of TA, conflicts can arise\namong the task vectors, particularly when different tasks require distinct model\nadaptations. In this paper, we formally define this issue as knowledge conflicts,\ncharacterized by the performance degradation of one task after merging with a\nmodel fine-tuned for another task. Through in-depth analysis, we show that these\nconflicts stem primarily from the components of task vectors that align with the\ngradient of task-specific losses at \\( \\Theta_{\\text{pre}} \\). To address this, we propose Task Arith-\nmetic in Trust Region (TATR), which defines the trust region as dimensions in\nthe model parameter space that cause only small changes (corresponding to the\ntask vector components with gradient orthogonal direction) in the task-specific\nlosses. Restricting parameter merging within this trust region, TATR can effec-\ntively alleviate knowledge conflicts. Moreover, TATR serves as both an indepen-\ndent approach and a plug-and-play module compatible with a wide range of TA-\nbased methods. Extensive empirical evaluations on eight distinct datasets robustly\ndemonstrate that TATR improves the multi-task performance of several TA-based\nmodel merging methods by an observable margin.", "sections": [{"title": "1 INTRODUCTION", "content": "The growing adoption of large foundation models is accompanied by significant practical challenges\nin terms of computational and storage demands (Kaplan et al., 2020). To address these challenges,\nmulti-task model merging (Matena & Raffel, 2022) has emerged as a promising solution. For ex-\nample, Task Arithmetic (Ilharco et al., 2023b) merges models by summing the task vectors from\nmultiple tasks and applying them to the pre-trained model. Here task vectors are the difference in\nmodel parameters between the pre-trained foundation model and its fine-tuned version on a specific\ntask. This approach builds a high-performance multi-task model by simple arithmetic operations in\nthe model parameter space, thereby reducing computational overheads associated with fine-tuning\non multiple tasks."}, {"title": "2 RELATED WORK", "content": ""}, {"title": "2.1 TRADITIONAL MULTI-TASK LEARNING", "content": "Multi-task learning (MTL) aims to improve performance by sharing knowledge across related tasks\n(Zhang & Yang, 2022). A significant challenge for MTL is negative transfer (Liu et al., 2017; Zhang\net al., 2023b), where joint training on conflicting tasks yields performance lower than training on the\ntasks individually. Various solutions to negative transfer have been proposed, such as modularization"}, {"title": "2.2 MULTI-TASK LEARNING THROUGH MODEL MERGING", "content": "Model merging techniques, which aim to integrate knowledge across models, have attracted in-\ncreasing attention in recent years. As a precursor, Stochastic Weight Averaging (SWA) (Izmailov\net al., 2018) averages model weights near the end of training. This concept was further advanced\nby approaches like SWAD (Cha et al., 2021) and Ensemble of Averages (EoA) (Arpit et al., 2022).\nEmpirical evidence from Ilharco et al. (2023a) demonstrates that parameter averaging effectively\nintegrates knowledge from models trained on diverse tasks. DLCPA (Sun et al., 2023) proposes\nto apply cumulative parameter averaging (CPA) to continually assimilate knowledge across dis-\ntinct tasks. Fisher-Merging (Matena & Raffel, 2022) leverages the Fisher information matrix Fisher\n(1925) to measure the importance of model parameters and merge models using weighted averaging.\nAdditionally, RegMean (Jin et al., 2023) formulates an optimal merging model by minimizing the\ndistance to each model in the parameter space.\nRecently, Task Arithmetic (TA) (Ilharco et al., 2023b) innovatively proposes the concept of \"task\nvector\", defined as the vector from a pre-trained model to its fine-tuned counterpart in the parameter\nspace. By weighting these task vectors and adding them back to the pre-trained model, TA strikes a\nharmonious balance between generalized knowledge from the pre-train model and the task-specific\nknowledge in the task vectors. Following this insight, Ties-Merging (Yadav et al., 2023) refines the\nfusion process by discarding parameters deemed insignificant or of low magnitude. PEFT (Zhang\net al., 2023a) and MoLE (Wu et al., 2024) further extend TA by integrating it with LoRA (Hu et al.,\n2022) modules. Furthermore, Ortiz-Jimenez et al. (2023) suggests fine-tuning models in the tangent\nspace, which can effectively mitigate conflict between task vectors.\nFurthermore, several approaches combine test-time adaptation techniques with TA, yielding superior\nMTL performance. These test-time adaptation-based methods typically allocate merging weights\nand fine-tune them during testing using unsupervised test data. For instance, AdaMerging (Yang\net al., 2024b) trains a set of merging coefficients for layers, while other methods fit lightweight\nadapter modules, such as representation surgery (Yang et al., 2024a) and MoE router (Tang et al.,\n2024)."}, {"title": "3 PRELIMINARIES", "content": ""}, {"title": "3.1 PROBLEM SETTING", "content": "Formally, let \\( \\Theta_{\\text{pre}} \\in \\mathbb{R}^{N} \\) denote the set of \\( N \\) parameters of a pre-trained model, which is initially\ntrained using a diverse, large-scale dataset to encapsulate generalized, task-agnostic knowledge.\nSubsequently, \\( \\Theta_{\\text{pre}} \\) undergoes fine-tuning for \\( K \\) distinct downstream tasks, yielding a set of fine-\ntuned parameters \\( {\\theta_{k}}_{k=1}^{K} \\), where each \\( \\theta_{k} \\) is tailored to a specific task \\( k \\).\nThe objective of model merging is to integrate these fine-tuned parameters from the task-specific\nmodels \\( {\\theta_{k}}_{k=1}^{K} \\) into a single model \\( \\Theta_{\\text{MTL}} \\). This merged model \\( \\Theta_{\\text{MTL}} \\) aims to achieve effective\ngeneralization across all \\( K \\) tasks without resorting to trivial solutions such as retraining from scratch\nor requiring full access to the training datasets of all tasks."}, {"title": "3.2 TASK ARITHMETIC", "content": "Task arithmetic (TA) (Ilharco et al., 2023b) is known as a competitive baseline for model merging\nby leveraging task vectors, which are defined as the differential parameters between the pre-trained\nmodel \\( \\Theta_{\\text{pre}} \\) and each fine-tuned model. Specifically, the task vector for task \\( k \\) is given by:\n\n\n\\( \\Delta_{k} = \\Theta_{k} - \\Theta_{\\text{pre}} \\) \\(1\\)\n\n\nTA posits that these task vectors encapsulate essential task-specific knowledge. The merged model\nis then constructed by adding the cumulative task vector from all tasks back to \\( \\Theta_{\\text{pre}} \\):\n\n\n\\( \\Theta_{\\text{TA}} = \\Theta_{\\text{pre}} + \\lambda \\sum_{k} \\Delta_{k}, \\) \\(2\\)\n\n\ntask-generalized\ntask-specific\nwhere \\( \\lambda > 0 \\) is a pre-defined hyper-parameter that governs the influence of task-specific adjust-\nments.\nThis method is favored over direct averaging of fine-tuned parameters as it seeks a balance between\ngeneralized and task-specific knowledge, contributing to its competitive advantage. Nevertheless,\ntask vectors can encode conflicting adaptations across different tasks, leading to potential knowledge\nconflicts that may result in information loss and diminished performance. This issue, termed as\n\"knowledge conflict\", will be dissected further in the subsequent section."}, {"title": "4 ANALYZING KNOWLEDGE CONFLICT", "content": "Knowledge conflict frequently arises when merging MTL models, as the expert models encapsulate\ndiverse, sometimes conflicting, knowledge. We formally define knowledge conflict as follows:\nDefinition 1 (Knowledge Conflict). Given a pre-trained model \\( \\Theta_{\\text{pre}} \\) and a set of fine-tuned, task-\nspecific models \\( {\\theta_{k}}_{k=1}^{K} \\), where \\( \\Theta_{k} \\) represents the parameters optimized for task \\( k \\), the knowledge\nconflict on task \\( j \\) caused by task \\( i \\) can be quantified by the change in performance of task \\( j \\) when\ntask \\( i \\) is included in the model merging process. Formally, the knowledge conflict is defined as\n\n\n\\( C_{j|i} := L_{j} (\\Theta_{\\text{MTL}}(\\{ \\theta_{k} \\}_{k=1}^{K})) - L_{j} (\\Theta_{\\text{MTL}}(\\{\\theta_{k}\\}_{k \\neq i})), \\)\n\n\nwhere \\( L_{j}(\\theta) \\) denotes the loss for task \\( j \\) with model parameters \\( \\theta \\), and \\( \\Theta_{\\text{MTL}}(\\{\\theta_{k}\\}_{k \\neq i}) \\) represents the\nmerged model parameters excluding the model fine-tuned for task \\( i \\). The overall knowledge conflict,\n\\( C \\), is computed as the sum of \\( C_{j|i} \\) across all task pairs \\( (i, j) \\):\n\n\n\\( C:= \\sum_{i \\neq j} C_{j|i} \\)\n\nA higher value of \\( C \\) indicates a greater degree of conflict, as it reflects a larger negative impact on\ntask \\( j \\)'s performance when task \\( i \\) is incorporated into the merging process.\nKnowledge conflict can be regarded as a special case of negative transfer, although these concepts\nemphasize different aspects. In traditional MTL, negative transfer typically refers to the dynamic\ninterference between tasks during joint training, where conflicting gradients impede the model from\nlearning effective representations (Zhang et al., 2023b). In contrast, the knowledge conflict defined\nhere highlights a static nature among the fine-tuned model parameters, where further training to\nresolve task interference is prohibited. Each fine-tuned model has already encoded task-specific\nknowledge, which may be inherently incompatible with that of other tasks. As a result, knowl-\nedge conflict in model merging presents a unique challenge, necessitating methods that can align or\nreconcile parameters without resorting to retraining.\nIn the context of TA, knowledge conflict can be further articulated through task vectors:\n\n\n\\( C_{\\text{TA}_{j|i}} = L_{j} (\\Theta_{\\text{pre}} + \\lambda \\sum_{k} \\Delta_{k}) - L_{j} (\\Theta_{\\text{pre}} + \\lambda \\sum_{k \\neq i} \\Delta_{k}). \\) \\(3\\)"}, {"title": "5 TASK ARITHMETIC IN THE TRUST REGION", "content": "The above observations are reasonable since neural network parameters, particularly those in pre-\ntrained foundation models, often exhibit high redundancy (Dalvi et al., 2020; Chen et al., 2022b).\nAdditionally, task-specific knowledge is often low-rank Hu et al. (2022), i.e., only a few parameter\ndirections are critical for learning the task. In order to identify a small set of critical parameters that\nshould not be altered during model merging and alleviate knowledge conflicts, we propose defining\nthe following trust region:\nDefinition 2 (Trust Region for Knowledge Conflict). Given a pre-trained model \\( \\Theta_{\\text{pre}} \\), the trust region\nspecific in the dimension space is defined as follows:\n\n\n\\( \\text{TR} := \\{ n | (\\frac{1}{K(K-1)} \\sum_{i \\neq j} |\\nabla_{\\theta} L_{j} (\\Theta_{\\text{pre}}) \\odot |\\Delta_{i}|)[n] < \\epsilon \\}, \\) \\(5\\)\n\n\nwhere \\( n \\leq N \\) indexes the dimensions of the parameter space, \\( \\epsilon \\) represents the sensitivity threshold,\nand any dimension exceeding this threshold will be excluded from the trust region and not permitted\nto merge.\nDimensions outside the trust region (corresponding components of task vector that are collinear\nwith the gradient direction, regardless of whether the directions are aligned or opposite) are likely to\ncause knowledge conflicts. Conversely, when \\( \\nabla_{\\theta} L_{j} (\\Theta_{\\text{pre}}) \\) and \\( \\Delta_{i} \\) are orthogonal, their projections\nminimally interfere with each other, thereby reducing knowledge conflict.\nWe are now ready to present the TATR method. TATR mitigates knowledge conflict by restricting\nmerging within the trust region, involving the following three key steps.\nCalculating task-specific gradients. The first step involves computing the gradient for each task.\nSince accessing the full training data for each task is often impractical, we approximate the gradient\nusing an exemplar set for each task, denoted as \\( \\{S_{1}, ..., S_{K}\\} \\). For each task, the absolute gradient\nof the loss function \\( L_{k}(.) \\) (cross-entropy loss in our experiments) is computed as follows:\n\n\n\\( |\\nabla_{\\theta} L_{k} (\\Theta_{\\text{pre}})| \\approx E_{x_{k} \\in S_{k}} |\\nabla_{\\theta} L_{k} (x_{k}; \\Theta_{\\text{pre}})|. \\) \\(6\\)\n\n\nNotably, we place the expectation outside the absolute value operation, drawing inspiration from the\nFisher Information Matrix (Wasserman, 2013). This design captures absolute gradients that reflect\nthe average variation of parameters, facilitating the measurement of knowledge conflict across every\nexemplar. Additionally, the exemplar size can be remarkably small. Our empirical results in Figure 3\n(a) show that even in a one-shot setting, we achieve a competitive average accuracy of 72.3%, which\nis close to the highest accuracy of 72.8% obtained with 16 samples. Similar results are observed\nwhen TATR is integrated into AdaMerging Yang et al. (2024b).\nWe also propose a zero-shot version, where the task vector is used to estimate the gradient. Although\nthere may be estimation errors, this approach still offers performance improvements for TA-based\nmethods in most scenarios:\n\n\n\\( |\\nabla_{\\theta} L_{k} (\\Theta_{\\text{pre}})| \\approx |\\Delta_{k}|. \\) \\(7\\)\n\n\nEstablishing the trust region. Next, we aim to identify the trust region with minimal knowledge\nconflict, with a key requirement being the determination of the sensitivity threshold \\( \\epsilon \\). However,\nmanually specifying the exact value of \\( \\epsilon \\) becomes complex and tedious. Therefore, we employ a\nranking method to infer \\( \\epsilon \\). To achieve this, we derive the sensitivity of each dimension that may\ncause knowledge conflict, based on Definition 2:"}, {"title": "Algorithm 1: The model merging process of TATR", "content": "Input: Pre-trained model \\( \\Theta_{\\text{pre}} \\); Task vectors \\( \\{\\Delta_{1},..., \\Delta_{K}\\} \\); Exemplar-set \\( \\{S_{1}, ..., S_{K}\\} \\)\nOutput: Merged model \\( \\Theta_{\\text{TATR}} \\)\n1 // Deriving gradients for each task\n2 for k = 1,..., K do\n3 \\( \\quad | G_{k} = E_{x_{k} \\in S_{k}} |\\nabla_{\\theta} L_{k} (x_{k}; \\Theta_{\\text{pre}})| \\)\n4 // Establishing the trust region\n5 \\( \\Omega_{\\text{Trust}} = \\sum_{i \\neq j} |G_{j}| \\odot |\\Delta_{i}| \\)\n6 \\( \\epsilon = \\text{proportion\\_selection}(\\Omega_{\\text{Trust}}, \\tau) \\)\n7 \\( \\text{TR} = \\{ n | \\Omega_{\\text{Trust}}[n] < \\epsilon \\} \\)\n8 // Merging\n9 \\( \\Theta_{\\text{TATR}} = \\Theta_{\\text{pre}} + \\lambda \\sum_{k} \\Delta_{k} \\odot \\mathbb{1}\\{n \\in \\text{TR}\\} \\)\n10 return \\( \\Theta_{\\text{TATR}} \\)\n\n\n\\( \\Omega_{\\text{Trust}} = \\sum_{i \\neq j} |\\nabla_{\\theta} L_{j} (\\Theta_{\\text{pre}})| \\odot |\\Delta_{i}| = \\sum_{i \\neq j} |\\nabla_{\\theta} L_{j} (\\Theta_{\\text{pre}})| \\odot |\\Delta_{i}| . \\) \\(8\\)\n\n\nNext, the sensitivity threshold \\( \\epsilon \\) of the trust region is determined through a proportional selection\noperation:\n\n\n\\( \\text{proportion\\_selection}(\\Omega_{\\text{Trust}}, \\tau). \\) \\(9\\)\n\n\nIn this process, \\( \\Omega_{\\text{Trust}} \\) is sorted in descending order, and the values corresponding to the predefined\nratio \\( \\tau \\) are selected as the sensitivity threshold \\( \\epsilon \\). Based on \\( \\epsilon \\), we are able to establish the trust region\n\\( \\text{TR} \\) according to Definition 2.\nMerging the task vectors. The final step involves merging the task vectors using TA, where the\nmerging occurs within the dimensions confined to the trust region:\n\n\n\\( \\Theta_{\\text{TATR}} = \\Theta_{\\text{pre}} + \\sum_{k} \\Delta_{k} \\odot \\mathbb{1}\\{n \\in \\text{TR}\\}, \\) \\(10\\)\n\n\nwhere \\( \\mathbb{1}\\{n \\in \\text{TR}\\} \\in \\mathbb{R}^{N} \\) is an indicator vector whose value is 1 at index \\( n \\) if \\( n \\) belongs to the trust\nregion and 0 otherwise. The detailed workings of TATR are outlined in Algorithm 1. The entire\nmerging process does not rely on any additional training process.\nMoreover, the techniques introduced in TATR selectively limit the merging process to a subset of\nmodel parameters, allowing it to function as a plug-and-play module that seamlessly integrates with\na wide range of TA-based approaches, such as:\n\u2022 Ties-Merging & TATR: Ties-Merging (Yadav et al., 2023) partially reduces knowledge\nconflicts by pruning low-magnitude parameters and aligning the signs of task vectors.\nHowever, this approach overlooks conflicts that may arise from high-magnitude param-\neters. This bias can lead to knowledge conflicts, where some tasks dominate the model's\nbehavior. The combination of TATR with Ties-Merging refines the process, as shown in\nthe following formula:\n\n\n\\( \\Theta_{\\text{Ties+TATR}} = \\Theta_{\\text{pre}} + \\sum_{k} \\Phi(\\Delta_{k}) \\odot \\mathbb{1}\\{n \\in \\text{TR}\\}, \\) \\(11\\)\n\n\nwhere \\( \\Phi(.) \\) indicates the TrIm, Elect Sign, and Merge operation of Ties-Merging.\n\u2022 AdaMerging & TATR: AdaMerging (Yang et al., 2024b) adaptively learns merging co-\nefficients but does not inherently resolve knowledge conflicts between task vectors. This\ncan lead to interference during coefficient learning, especially when tasks require oppos-\ning parameter adaptations. TATR addresses this by pre-filtering task vectors to retain only"}, {"title": "6 EXPERIMENTS", "content": ""}, {"title": "6.1 SETTINGS", "content": "Datasets. Following prior works (Ilharco et al., 2023b; Yadav et al., 2023; Yang et al., 2024b;a), we\nperform model merging on the following eight datasets: SUN397 (Xiao et al., 2016), Cars (Krause\net al., 2013), RESISC45 (Cheng et al., 2017), EuroSAT (Helber et al., 2019), SVHN (Netzer et al.,\n2011), GTSRB (Stallkamp et al., 2011), MNIST (LeCun & Cortes, 2010), DTD (Cimpoi et al.,\n2014).\nBaselines. We compare our approach against a diverse set of methods, categorized into basic base-\nline methods, test-time training-based model merging methods, and training-free model merging\nmethods. Basic baseline methods include the Pre-trained model, Individual task model, and the Tra-\nditional Multi-Task Learning model. For test-time training-based methods, we provide AdaMerg-\ning, AdaMerging++ (Yang et al., 2024b), and Surgery (Yang et al., 2024a). Among the training-free\nmethods, we consider the simple Weight Average, Fisher Merging (Matena & Raffel, 2022), Reg-\nMean (Jin et al., 2023), Task Arithmetic (Ilharco et al., 2023b), and Ties-Merging (Yadav et al.,\n2023).\nImplementation details. Our implementation strictly follows task arithmetic (Ilharco et al., 2023b)\nand AdaMerging (Yang et al., 2024b). We apply the ViT-B/32 and ViT-L/14 in CLIP (Radford et al.,\n2021) as the pre-trained model. Task vectors are derived from task arithmetic (Ilharco et al., 2023b)\nwhich is fine-tuned on each specific dataset. We report the accuracy of each task after merging the\nmodels, along with the average accuracy (i.e., Avg ACC). The hyper-parameter \\( \\tau \\) is tuned within the\nrange [0.1%, 0.2%, 0.5%, 1.0%, 2.0%, 5.0%], while the size of the exemplar set is fixed at 128."}, {"title": "6.2 PERFORMANCE COMPARISON", "content": "The performance of all baselines using the ViT-B/32 and ViT-L/14 architectures is presented in\nTable 1 and Table 2, respectively. We report the performance metrics for each task after merging, as\nwell as the overall average performance.\nAs illustrated in the tables, the pre-trained model exhibits the lowest performance across all methods,\ndue to the absence of task-specific supervision. In contrast, the Individual models achieve the highest\nperformance, as they are exclusively trained for each specific task, which thus represents the upper-\nbound performance for model merging. Traditional MTL encounters knowledge conflict issues,\nresulting in slightly lower performance compared to the Individual models.\nAmong the model merging methods, the simplest Weight Averaging suffers significant knowledge\nconflicts, resulting in a worse performance. Fisher Merging and RegMean improve Weight Averag-\ning by incorporating parameter importance weight into the averaging process. TA and its enhanced\nversion, Ties-merging, demonstrate substantial performance improvements by better balancing the\npre-trained and task-specific knowledge. Additionally, owing to the additional training process,\ntest-time training-based models (AdaMerging and Surgery) generally outperform the training-free\nmethods."}, {"title": "6.3 SENSITIVITY ANALYSIS OF HYPERPARAMETERS", "content": "This section presents an analysis of the model's sensitivity to two hyperparameters: the number\nof exemplar samples and the proportion \\( \\tau \\) in Eq. (9). As shown in Figure 3, the performance of\nTATR remains stable with respect to both hyperparameters. Furthermore, Figure 3 (a) demonstrates\nthat even in a one-shot setting, TATR achieves a competitive average accuracy of 72.3%, evidently\noutperforming Task Arithmetic (0 exemplars in Figure 3 (a)) and comparable to the highest accuracy\nof 72.8%. Similarly, experiments plugged into AdaMerging also support this phenomenon, where"}, {"title": "6.4 ANALYSIS OF SENSITIVITY \\( \\Omega^{\\text{TRUST}} \\) FOR KNOWLEDGE CONFLICT", "content": "Figure 4 illustrates the average sensitivity of each dataset to task vectors across different layers.\nThree key characteristics can be observed. Firstly, the shallow layers exhibit greater sensitivity than\nother layers. Shallow layers typically encode task-generalized knowledge, and the increased sensi-\ntivity highlights the importance of preserving this information in the TATR method. Secondly, the\nsensitivity exhibits periodic variations across layers, with bias layers generally exhibiting higher sen-\nsitivity than weight layers. This trend is reasonable, as bias layers have a more pronounced impact\non network outputs, making them more susceptible to knowledge conflicts. Lastly, datasets com-\nprising digit data (e.g., SVHN and MNIST) show relatively lower sensitivity to knowledge conflicts,\nwhich can be attributed to their significant domain differences from other real-world datasets."}, {"title": "7 CONCLUSION", "content": "In this paper, we delve deep into the critical challenge of knowledge conflict in multi-task model\nmerging with a focus on task arithmetic. We began by formalizing the concept of knowledge conflict\nas the degradation in model performance caused by the interference between task vectors. Our\nanalysis and empirical findings suggest that components of task vectors orthogonal to the gradient\ndirection exhibit minimal knowledge conflict. This insight motivates us to define a trust region based\non orthogonality and propose Task Arithmetic in the Trust Region (TATR). Extensive experiments\nacross eight diverse datasets demonstrate that TATR effectively mitigates the knowledge conflict,\nenhancing the overall multi-task performance of task arithmetic-based methods."}, {"title": "A EXPERIMENT DETAILS", "content": "This section provides details of experiments, including the description of the experimental environ-\nment, datasets, and baselines."}, {"title": "A.1 ENVIRONMENT", "content": "All experiments detailed in our manuscript and appendix were conducted on a workstation running\nUbuntu 16.04, equipped with 18 Intel Xeon 2.60GHz CPUs, 256 GB of memory, and 6 NVIDIA\nRTX3090 GPUs. Python 3.8 was used to implement all the methods."}, {"title": "A.2 DATASETS", "content": "Our experiments strictly follow Task Arithmetic (Ilharco et al., 2023b) and AdaMerging (Yang et al.,\n2024b), utilizing eight widely-used image classification datasets. The information of these datasets\nis described as follows:\n\u2022 SUN397 (Xiao et al., 2016): A scene classification dataset containing 108,754 images\nacross 397 classes. Each class includes at least 100 images.\n\u2022 Stanford Cars (Cars) (Krause et al., 2013): A car classification dataset featuring 16,185\nimages of 196 car categories. The dataset is evenly split between training and test sets.\n\u2022 RESISC45 (Cheng et al., 2017): A remote sensing image classification dataset comprising\n31,500 images across 45 scene categories, with approximately 700 images per class.\n\u2022 EuroSAT (Helber et al., 2019): A satellite image classification dataset consisting of 27,000\nlabeled and geo-referenced images distributed among 10 categories.\n\u2022 SVHN (Netzer et al., 2011): A real-world digit classification dataset derived from house\nnumbers in Google Street View images. It includes 10 classes, with a training set of 73,257\nimages, a test set of 26,032 images, and an additional 531,131 samples available for ex-\ntended training.\n\u2022 GTSRB (Stallkamp et al., 2011): A traffic sign classification dataset comprising more than\n50,000 images across 43 traffic sign categories.\n\u2022 MNIST (LeCun & Cortes, 2010): A well-known benchmark for handwritten digit classifi-\ncation, containing 60,000 training images and 10,000 test images, evenly distributed among\n10 classes of digit numbers.\n\u2022 DTD (Cimpoi et al., 2014): A texture classification dataset consisting of 5,640 images\ndistributed across 47 texture classes, with approximately 120 images per class."}, {"title": "A.3 BASELINES.", "content": "In our experiments, we compare our methods with several baseline approaches, which are grouped\ninto four categories: basic baseline methods, test-time training-based methods, training-free meth-\nods, and our proposed methods. The details of these methods are as follows:\ni) Basic baseline methods:\n\u2022 Pre-trained directly employs a pre-trained model to predict across multiple tasks. Since it\ndoes not incorporate any downstream task-specific information during model training, its\nperformance on downstream tasks is typically suboptimal.\n\u2022 Individual. In this approach, an independent fine-tuned model is used for each task. While\nit avoids interference between tasks, it cannot perform multiple tasks simultaneously. It\nserves as a reference upper bound for model merging approaches.\n\u2022 Traditional MTL aggregates the original training data from all tasks to train a single multi-\ntask model.\nii) Test-time training-based methods:"}, {"title": "B VISUALIZATION OF LOSS LANDSCAPE", "content": ""}, {"title": "B.1 METHODOLOGY FOR VISUALIZING THE LOSS LANDSCAPE", "content": "In this section, we outline the methodology for visualizing the loss landscape, which involves three\nkey steps:\nTask vector decomposition. To effectively visualize the loss landscape, we first decompose a task-\nspecific vector into three essential components: a positive component (aligned with the gradient\ndirection), a negative component (opposed to the gradient), and an orthogonal component (orthog-\nonal to the gradient). These components are derived by analyzing the relationship between the task\nvector and the gradient, as detailed in Section 5. This decomposition allows us to explore how dif-\nferent aspects of the task vector interact with the gradient, each contributing uniquely to the overall\noptimization behavior.\nConstructing the 2D plane. We arrange these three components in a 2D coordinate system, with\nthe positive component anchored at (0,1), the negative component at (0,0), and the orthogonal com-\nponent at (1,0). Additionally, we project the parameters of the pre-trained model onto this plane\nusing linear combinations of the three components. Although this projection is an approximation, as"}, {"title": "B.2 LosS LANDSCAPE FOR EACH INDIVIDUAL TASK", "content": "In this section, we present the loss landscape for each individual task, along with the components\nof task vectors from the other seven tasks within the landscape. From Figure 5, we observe the\nsame patterns as described in the manuscript. Specifically, the positive component tends to ascend\nalong the gradient direction, while the negative component, despite aligning with the gradient de-\nscent direction, often overshoots local optima, leading to performance degradation. The orthogonal\ncomponent, in general, shows little sensitivity to performance changes. These findings further sup-\nport the generality of our conclusions and provide additional evidence for the effectiveness of the\nTATR method."}, {"title": "B.3 LosS LANDSCAPE FOR ALL TASKS", "content": "Furthermore, we visualize the overall loss landscape across all tasks, including the components of\nthe task vectors. We present the loss landscape under different mask ratios. As shown in Fig-\nure 6, we observe similar patterns: both the positive and negative components negatively impact the\nmodel's overall multi-task performance, leading to knowledge conflicts. In contrast, the orthogonal\ncomponent contributes to improving the model's multi-task capability."}, {"title": "C ADDITIONAL EXPERIMENTS", "content": ""}, {"title": "C.1 COMPARISON ON VIT-B/16", "content": "Table 3 presents the results of various model merging methods using the ViT-B/16 architecture. As\nwe can see, TATR significantly improves the multi-task performance of Task Arithmetic, raising\nthe average performance from 73.8% to 77.0%. Additionally, the zero-shot version also provides a\ncertain degree of improvement, ultimately reaching 74.1%."}, {"title": "C.2 GENERALIZATION COMPARISON", "content": "This section explores the generalization ability of TATR. Specifically", "experi-\nments": "in the first, MNIST and EuroSAT are set as unseen tasks, while in the second, RESISC45 and\nSVHN are treated as unseen. The results in Table 4 show that TATR outperforms Task Arithmetic\non the unseen datasets, with an average performance improvement of 0.8% and 1.3%, respectively.\nThis improvement in generalization is attributed to TATR's ability to handle knowledge conflicts,\nensuring that model updates move toward"}]}