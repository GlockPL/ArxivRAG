{"title": "Algorithm Research of ELMo Word Embedding and Deep Learning Multimodal Transformer in Image Description", "authors": ["Xiaohan Cheng", "Taiyuan Mei", "Yun Zi", "Qi Wang", "Zijun Gao", "Haowei Yang"], "abstract": "Zero sample learning is an effective method for data deficiency. The existing embedded zero sample learning methods only use the known classes to construct the embedded space, so there is an overfitting of the known classes in the testing process. This project uses category semantic similarity measures to classify multiple tags. This enables it to incorporate unknown classes that have the same meaning as currently known classes into the vector space when it is built. At the same time, most of the existing zero sample learning algorithms directly use the depth features of medical images as input, and the feature extraction process does not consider semantic information. This project intends to take ELMo-MCT as the main task and obtain multiple visual features related to the original image through self-attention mechanism. In this paper, a large number of experiments are carried out on three zero-shot learning reference datasets, and the best harmonic average accuracy is obtained compared with the most advanced algorithms.", "sections": [{"title": "I. INTRODUCTION", "content": "Medical image recognition technology, based on deep learning, has achieved significant breakthroughs[1-3]. However, traditional medical image classification algorithms require a large number of labeled samples and struggle to identify novel categories [4]. As new categories emerge, distinguishing them necessitates collecting numerous labeled samples and developing a new model, which is time- consuming. Zero-shot learning, which can be categorized into conventional and generalized types, offers a solution [5]. In conventional zero-shot learning, only unseen categories are present during testing, while generalized zero-shot learning, a more practical and challenging approach, involves both known and unseen categories. Current research primarily explores prototype-based and embedding-based zero-shot learning methods.\nThe method maps the features and quasi-semantic information of medical images to a certain vector space to achieve alignment between the two modes [6]. During the experiment, the type of sample to be detected is determined by the nearest neighbor lookup between the data to be detected and the aligned space. However, under the generalized zero-shot condition, the mapping relationship is only established for the known categories, which is likely to lead to the overfitting of the unknown categories and the obvious deviation in the prediction of the unknown categories [7]. Therefore, the core problem of the embedded method is how to make the model can extract the most typical embedded expression from the sample, and have sufficient differentiation to distinguish other types of features.\nIn the past, the learning method based on convolutional neural network has occupied absolute advantages in many research directions. However, with its excellent performance in medical image recognition, the current mainstream research framework has shifted from the traditional framework based on convolutional neural network to the framework based on automatic attention network based on Transformer [8-10]. This paper first studies the semantic similarity-based multi-label"}, {"title": "II. MULTI-MODE IMAGE DESCRIPTION CONVERTER", "content": "The feature quantity is input to the encoder for self- attention learning, and the visual attention representation of the image is obtained. The next word is then predicted based on the previous work and the encoder's visual attention information [11]. The network architecture of the multimodal image description converter is shown in Figure 1"}, {"title": "A. Image feature encoder", "content": "Its core task is to extract image characteristics and use attention mechanism to establish attention matrix between image modes, so as to obtain the correlation between images [12-14]. The algorithm mainly includes two aspects: one is the image feature extraction algorithm, the other is the multi-channel transform encoder.\n1) Image feature extractor\nIn the part of image feature extraction, the characteristics of an image are expressed [15]. This project intends to adopt the image feature extraction method based on the bottom-up attention mechanism[16], use the existing visual gene sequencing Faster-RCNN to identify the object association region[17-18], and adopt the mean pooling method to obtain the features of each object, express the characteristics of each object as X\u2081, and express the overall image as U[19]. Finally, the obtained image feature U is fed into the neural network, and the image feature matrix U\u2070 is formed by adjusting the image feature dimension to make it consistent with the spatial scale of the encoder.\n2) Multi-Channel Converter\nThe converted image feature U\u2070 is then input to a multimode converter, which contains M attention modules {B, B2,..., B}. The m attention module BM receives the output Um-\u00b9 of the m\u22121 attention module and computes it to get the attention characteristic U\u2122 in the image mode after the attention weight. Here's the formula:\n\\(U^m = B_e(U^{m-1})\\)\nEach B\u2122 (Um-\u00b9) is divided into multiple concerns (MHA) and feedback forward (FFN). The multi-focus attention module consists of a single-focus attention module (Figure 2)."}, {"title": "B. Text decoder", "content": "The text is decoded according to the image characteristic matrix after encoder. The specific research contents include: (1) This paper extracts the attention matrix of the correlation between words from the word pattern based on the internal attention theory of pattern; (2) Establish the association between images and text based on inter-pattern attention, obtain the image-oriented attention weight matrix, and finally generate the corresponding feature description.\n1) Multi-mode lexical information hidden encoder\nThe primary task of a multimode word steganography encoder is to encode the input word and then construct the corresponding character [20]. The algorithm consists of two aspects (Figure 3 cited in Intelligent Systems with Applications, Volume 18, May 2023, 200221), namely, the standard word embedded encoder and the ELMO word embedded encoder."}, {"title": "C. Experimental results and analysis", "content": "First, this project intends to take image characteristics and short-term memory (LSTM) based on Bottom-UP attention mechanism as the baseline and compare them with MCT (MCT)[27]. Secondly, this paper will make use of ELMo lexically-embedded ELMO-MCT and compare it with the above two models. The test results are shown in Table 1. Compared with the CIDEr scores of MCT and ELMO-MCT modes, the CIDEr scores of MCT and ELMO-MCT modes increased by 2.8 and 4.9 percentage points respectively.\nHowever, among the measured items, CIDEr has the largest improvement, while BLUE and ROUGE-L have a more balanced improvement. For the meaning of exponent, BLEU and ROUGE-L both judge the result by the frequency of using N lattice or longest common subsequence in candidate statements, and there is no big difference between them. CIDEr gets the final score by measuring the similarity of words. Because ELMo is used in word vector coding, the semantic meaning of the words generated by ELMO is richer, and the CIDEr score is higher than the BLEU score. Secondly, the effectiveness of the neural network under different conditions is analyzed. Tables 2 and 3 show this. The results show that the effectiveness of the method decreases with the increase of the depth. This suggests that over time, certain information may be missing, reducing the validity of the predictions."}, {"title": "IV. CONCLUSION", "content": "Encoding it with languages such as Word2Vec and Glove resulted in the loss of a large amount of useful data. For this purpose, the image representation method of multi-mode converter is established, and the accuracy of the model is improved by joint modeling of the attention within and between modes. By introducing the method of combining ELMo and vector, the semantic expression level of the model is further improved. Overall, our findings demonstrate the potential of integrating semantic similarity measures with advanced feature extraction technologies to enhance the capabilities of zero-shot learning in medical image recognition. This strategy not only improves model performance but also reduces the dependency on extensive labeled datasets, offering a viable path forward in the development of more adaptable and efficient medical imaging technologies."}]}