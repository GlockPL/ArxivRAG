{"title": "Water quality polluted by total suspended solids classified within\nan Artificial Neural Network approach", "authors": ["I. Luviano Soto", "Y. Concha S\u00e1nchez", "A. Raya"], "abstract": "This study investigates the application of an artificial neural network\nframework for analysing water pollution caused by solids. Water\npollution by suspended solids poses significant environmental and\nhealth risks. Traditional methods for assessing and predicting pollution\nlevels are often time-consuming and resource-intensive. To address\nthese challenges, we developed a model that leverages a comprehensive\ndataset of water quality from total suspended solids. A convolutional\nneural network was trained under a transfer learning approach using\ndata corresponding to different total suspended solids concentrations,\nwith the goal of accurately predicting low, medium and high pollution\nlevels based on various input variables. Our model demonstrated high\npredictive accuracy, outperforming conventional statistical methods in\nterms of both speed and reliability. The results suggest that the artificial\nneural network framework can serve as an effective tool for real-time\nmonitoring and management of water pollution, facilitating proactive\ndecision-making and policy formulation. This approach not only\nenhances our understanding of pollution dynamics but also underscores\nthe potential of machine learning techniques in environmental science.", "sections": [{"title": "HIGHLIGHTS", "content": "Artificial neural networks are used to study water pollution by total\nsuspended solids.\nSamples are prepared with different concentrations of suspended solids\nand filmed to obtain images\nConvolutional neural network with a transfer learning strategy is trained\nand tested for performance.\nLow, medium and high concentrations of total suspended solids in water\ncan be identified with high accuracy and modest computer resources."}, {"title": "INTRODUCTION", "content": "Water pollution by solids, including suspended and dissolved particles, poses\ncritical challenges to environmental sustainability, public health, and economic\ndevelopment (Khan et al. 2022). Understanding and mitigating these impacts\nrequire accurate monitoring and prediction of pollution levels. For instance, in\nMexico, the Ministry of Environment and Natural Resources has proposed NOM-\n001-SEMARNAT-2021 (National Advisory Committee for Standardization of the\nEnvironment and Natural Resources of Mexico 2021) as the standard for setting\nparameters for contaminated water quality, including Total Suspended Solids\n(TSS). To make water quality information accessible to the public, the Ministry\nalso proposes a system for estimating water quality by measuring three\nindicative parameters that differentiate various water quality levels. TSS is\namong these parameters because elevated TSS levels diminish the ability of\nwater bodies to support diverse aquatic life. These parameters help to identify\nconditions ranging from nearly natural, unaffected by human activity, to water\nshowing clear signs of significant municipal and non-municipal wastewater\ndischarges and severe deforestation (Ministry of Environment and Natural\nResources Mexico 2011).\nTraditional methods to identify and classify solid pollutants in water\nsamples include Gooch crucible with 2.4 cm glass fibre filter, Buchner funnel,\nmembrane filter, Gooch crucible asbestos (Smith et al. 1963). While effective,\nthese methods often involve labour-intensive sampling and analysis processes\nthat can be both time-consuming and costly. This underscores the need for\ninnovative approaches to enhance the efficiency and accuracy of water quality\nassessment. An Artificial Neural Network (ANN) framework offers a promising\nsolution to these challenges. To mention a few features in which an ANN\nframework is a valuable tool, we should keep in mind that water quality data is\ninherently complex, with numerous interdependent variables such as turbidity,\nTSS, and chemical oxygen demand (COD) (Tchobanoglous et al. 1991), for which\nan ANN excel in managing and interpreting complex, non-linear relationships\nwithin large datasets, providing more accurate predictions than traditional\nlinear models. Such a framework is capable of learning from historical data to\npredict future pollution levels, which is crucial for proactive environmental\nmanagement (Schauser & Steinberg 2001). Furthermore, once trained, ANN\nmodels can rapidly process and analyse data, significantly reducing the time\nrequired for water quality assessment, a beneficial feature for real-time\nmonitoring and decision-making (Palani et al. 2008). ANN frameworks can be\neasily scaled to incorporate additional data sources and parameters, enhancing\ntheir applicability across different water bodies and pollution scenarios. These\nframeworks continuously improve their performance as more data becomes\navailable and thus remain relevant and accurate over time, adapting to changes\nin pollution patterns and environmental conditions. An additional benefit of the\nuse of ANNs is that these frameworks can be seamlessly integrated with Internet\nof Things (IoT) devices and remote sensing technologies. This integration\nenables continuous, automated monitoring of water quality, providing real-time\ndata that enhances the responsiveness and effectiveness of pollution control\nmeasures. By providing reliable and detailed insights into pollution dynamics,\nANN frameworks support informed decision-making by policymakers,\nenvironmental agencies, and stakeholders. This leads to better resource\nallocation, targeted pollution control strategies, and ultimately, more effective\nenvironmental protection.\nIn the field of water management, several ANN models have been\nprimarily used to characterise both the quantity and quality of water (Farmaki\net al. 2010). One of the most common applications of ANNs in water monitoring\nis through remote sensing (Wagle & Acharya 2020), where satellite images are\nused to predict different water levels and the evolution of contaminants\n(Agrawal & Peterson 2021). Another significant application is in predicting\nwastewater, particularly in Wastewater Treatment Plants (WWTPs), as well as in\nprocess control within these facilities (Hamed et al. 2004). Also, ANNs are widely\nutilised for predicting water quality parameters through various machine\nlearning methods (Haghiabi et al. 2018).\nIn this article, we present a novel approach to assess water quality by\ndeveloping a Convolutional Neural Network (CNN) capable of predicting high,\nmedium, and low pollution levels based on TSS. This method offers a cost-\neffective, rapid, and non-invasive alternative for water quality monitoring,\nenabling the determination of water quality categories ('high', 'medium' and\n'low') based on TSS concentration using a single image captured with a\nsmartphone camera. Early studies under similar conditions already point\ntoward the benefits of using CNN in classification of water contamination by TSS"}, {"title": "METHODS", "content": "(Lopez-Betancur et al. 2022). Our CNN, consisting of five layers, has been\ndesigned to detect TSS concentrations ranging from 40 to 6000 mg/L and\nprovides the corresponding classifications. The remaining of this research work\nis organised as follows: In the Methods Section, we present in detail the sample\npreparation, the experimental procedure, the CNN development for classifying\nwater quality based on solids, as well as its training and calibration phases. In\nthe Results Section we report the findings of our study based upon the followed\nmethodology. In the Discussion Section we summarise the findings of this work\nand its impact in environmental science. Finally, we present an outlook for\nfuture work in the Conclusions Section."}, {"title": "Samples", "content": "To carry out this research, 30 water samples were prepared with different\nlevels of solids as main pollutant, this samples were obtained by selection clays\nwith particle diameter size smaller than 60 micrometres since TSS are\nconsidered matter with particle diameter less than 62 micrometres (Bilotta &\nBrazier 2008). This process involved sieving the material through a 60-micron\nmesh sieve to achieve material homogenization. It is important to note that the\nselected clays are primarily composed of iron and aluminium, which are the\nmost common types of clays found in urban environments, aimed at mimicking\nnatural contamination in urban water sources (Perry & Taylor 2009). The water\nused for preparing the samples was distilled water, known for its purity,\nensuring that TSS were the primary pollutant in the samples. The concentration\nrange of the samples used was from 40 to 6000 mg/L, obtained by mixing pure\nwater with clays. The clays were weighed on an analytical balance with a\nprecision of 0.1 mg and divided into three categories of water polluted by solids:\nlow, medium, and high. For low quality water were considered samples with\nconcentrations from 40 to 70 mg/L. Water classified as medium quality by TSS\ncontaminants ranges from 80 to 400 mg/L, while high quality water\nencompasses concentrations from 500 to 6000 mg/L. The number of samples\nvaried across different classes: four samples for the low class, ten samples for\nthe medium class, and sixteen samples for the high class. This variation is due\nto the differing ranges of TSS concentrations within each class. The low class\nexhibited minimal variability in TSS concentrations, the medium class displayed\na broader range of concentrations, and the high class had the widest range of\nTSS concentrations."}, {"title": "Experimental procedure", "content": "To carry out the experimental part of this work, it was necessary to take\nphotographic records of each water sample containing solids. This record was\nmade by placing 100 mL of the sample in transparent cubic containers with a 5\ncm edge. Each sample was illuminated laterally using a white dispersed light\nsource, specifically an 18-inch Ring Light Edge-Lit LED, positioned 20 centimeters\nfrom the water sample. The light was placed laterally to avoid reflections on the\nwater container. Due to the particle size of the TSS, a magnetic stirrer was\nrequired to prevent sedimentation. The stirrer operated at 300 rpm, which was\nthe speed at which the solids remained in constant suspension, with a 1.5-inch\ndiameter hexagonal capsule placed at the center of the sample. The images\nwere captured through a 1.0-minute video recorded with an iPhone 12 with a 12\nMP camera and a resolution of 1920 x 1080 progressively displayed pixels, also\nknown as High Definition (HD), capable of 30 fps (frames per second) and a 2.5x\nzoom. The entire experimental setup was conducted on a levelled anti-vibration\noptical table, with the smartphone mounted statically on a tripod and positioned\n15 centimeters from the camera shutter, located in a booth with black curtains\nto prevent external light intrusion. The entire experimental setup was\ndocumented to ensure repeatability in video recording. The images used in the\ndevelopment of the CNN were extracted from videos captured at a rate of 4\nframes per second (fps). This process was implemented using Python, a versatile\nand accessible programming language (Thaker & Shukla 2020), with the MoviePy\npackage. A total of 240 images were generated per sample, resulting in 7200\nimages. Following individual analysis, 685 images were excluded due to blur"}, {"title": "CNN development", "content": "In the domain of Deep Learning (DL), various types of algorithms exist,\nwith Convolutional Neural Networks (CNNs) being among the most widely used\n(Baek et al. 2020). These models offer several advantages: (1) They reduce both\ntime and costs (e.g., material and labour costs), (2) They enable forecasting\nacross different system phases, (3) They simplify complex systems to enhance\ncomprehension, and (4) They predict target values even in situations where site\naccess is challenging (Barzegar et al. 2020). Therefore, in this study, we propose\nthe use of a CNN.\nThe primary task of a CNN is classification. Initially, it performs feature\nextraction from the input image. These features are then fed into a Neural\nNetwork (NN), producing output probabilities that indicate the classification of\nthe input image into a specific category (Ferentinos 2018). However, training a\nCNN from scratch requires two main conditions: (1) Access to a large dataset\nwith labelled data, and (2) Significant computational and memory resources\n(Morid et al. 2021).\nAn alternative to training CNNs from scratch is Transfer Learning (TL),\nwhich allows leveraging knowledge acquired from large datasets of non-\nenvironmental data to address specific environmental challenges, such as water\nquality analysis. Specifically, parameters from well-trained CNN models on non-\nenvironmental datasets, which contain diverse images (e.g., ImageNet models\nlike AlexNet (Yuan & Zhang 2016), VGGNet (Purwono et al. 2023), and ResNet\n(Wu et al. 2019.)), can be transferred to tailor a CNN model for analysing water\nquality.\nThe use of TL with AlexNet is well known, as it has been used in various\nareas. For example, it has been used in the detection of pathologies (Lu et al.\n2019), identification of alcoholism (Wang et al. 2019), multiple sclerosis (Zhang\net al. 2019), skin lesions (Hosny et al. 2020), and even facial emotions (Sekaran\net al. 2021). In the environmental area, AlexNet has also been used in the\nidentification of diseases in maize leaves (Lv et al. 2020), identification of crop\nwater stress (Chandel et al. 2019), sounds of marine mammals (Lu et al. 2021).\nHowever, in water quality classification, it has been little explored. In this study,\nwe use TL for the classification of TSS using the AlexNet network, which is based\non a CNN model that won the ImageNet Large Scale Visual Recognition\nChallenge 2012 (ILSVRC2012). This competition has served as a major\nbenchmark for image recognition since 2010 (Russakovsky et al. 2015). AlexNet\nleverages the ImageNet dataset, which contains over 15 million labelled images\n(Deng, et al. 2009). Its architecture includes eight learned layers: five\nconvolutional layers followed by Max-pooling layers to reduce data dimensions,\nutilising Rectified Linear Units (ReLu) as activation function, and three fully\nconnected layers (Krizhevsky et al. 2017).\nTo carry out the TL process used in our work, we make use of Python as\nthe programming language, because it has a large number of packages that\nfacilitate the use of Machine Learning (ML) algorithms (Raschka & Mirjalili, 2019),\nand it is also free to use. The entire procedure was conducted using the Jupyter\nnotebook environment within the Integrated Development Environment (IDE)\nVisual Studio Code. All the computations were performed on a computer\nequipped with an 8th-generation Intel i5 processor and 8 GB of RAM, which\nprovides relatively modest computational resources. The well-trained AlexNet\nmodel was obtained from the Torchvision package, which is a Python package\nthat includes several pre-trained network models. The modification of the\nAlexNet CNN involved removing the classifier, which initially had 1000 different\ntypes of classes, and we proposed a three-class water quality classifier based on\ndifferent concentrations of TSS: High (500 to 6000 mg/L), Medium (80 to 400\nmg/L), and Low (40 to 70 mg/L). Subsequently, the parameters obtained from\nthe pre-training of AlexNet were unfrozen to adjust the weights of the network\nmodel.\nIn the ML realm, one of the most important elements to define are the\nhyperparameters of the ANN. These consist of configurations of the network\nthat affect its structure, learning, and performance. Hyperparameters differ\nfrom parameters in that they are not automatically modified or adjusted during\ntraining; instead, they must be specified beforehand (Yu & Zhu 2020). The\nhyperparameters established in this work were: the optimization algorithm,\nlearning rate, batch size, and number of epochs. Below, we describe each of\nthese.\nThe optimization process in Artificial Intelligence (Al) involves identifying\noptimal parameters that improve the performance of a CNN model. One of the\nclassic methods for this process is the Stochastic Gradient Descent (SGD)\noptimization method (Newton et al. 2018). However, tuning the learning rate of\nSGD, as a hyperparameter, is often challenging because the magnitudes of\ndifferent parameters vary significantly and need to be adjusted throughout the\ntraining process (Zhang 2018). Therefore, in our study, we utilised the Adam\noptimizer, as it is an efficient stochastic optimization method that only requires\nfirst-order gradients and has low memory requirements. This method computes\nindividual adaptive learning rates for different parameters based on estimates\nof the first and second moments of gradients (Kingma & Ba 2014), and iteratively\nfinding values that minimise the error (loss).\nIn a deep NN, the weight parameters e are updated as\n$\\Ot = 0^{-1} - et \\frac{\\partial L}{\\partial \\theta}$  (1)\nwhere L represents the loss function and et the learning rate. Regarding the\nlatter, it is known that a low rate causes slow convergence of the training\nalgorithm, while a very high rate can lead to divergence (Smith 2017). Therefore,\nin this work, we chose to use a low learning rate to ensure model convergence,\nopting for a learning rate Lr=0.000005, at the expense of sacrificing some\ntraining convergence speed.\nOne of the crucial hyperparameters is the number of epochs used during\ntraining. An epoch entails presenting each sample in the training dataset with\nan opportunity to update the model internal parameters. Each epoch consists\nof one or more batches. As each sample or batch is processed through the\nnetwork, the error is computed, and the Back Propagation (BP) algorithm is\napplied to adjust the weights and biases of the network. During BP, the error is\npropagated backward through the network, gradients of the weights are\ncalculated with respect to the error, and these gradients are used to update the\nweights, aiming to minimise the error. This process facilitates model learning\nand performance enhancement. Although the number of epochs is typically\nlarge, our approach employs 50 epochs.\nConversely, the batch size determines the number of samples\npropagated through the CNN and used to update model parameters in each\niteration until training is complete. Larger batch sizes facilitate greater\ncomputational parallelism and can often enhance performance. However, they\nrequire more memory and can introduce latency during training. For the\ncreation of the CNN model, a total of 6,515 images with varying suspended\nsolids concentrations were used, with 5,862 images allocated for the training set\nand 653 images for validation. Consequently, given the total number of images\navailable, we opted for a batch size of 50 images.\nThe hyperparameters were chosen through numerous performance\nevaluations aimed at minimising error and maximising classification accuracy,\nspecifically tailored to our image dataset."}, {"title": "Validation Metrics", "content": "For evaluating the proposed CNN, the most common metrics are based\non the prediction of four possible outcomes: True Positives (TP), True Negatives\n(TN), False Positives (FP), and False Negatives (FN) (Seliya et al. 2009). In this\nstudy, we use Accuracy, Precision, Recall, F-measure, Receiver Operating\nCharacteristic (ROC), and Confusion Matrix as validation metrics. Below, we\ndescribe the function of each metric.\nAccuracy (ACR) represents the Classification Accuracy Rate at the decision,\nand is defined as\n$\\ACR = \\frac{TP+TN}{N}$ (2)\nwhere N represents the total number of instances in the dataset.\nPrecision, defined in terms of the Positive Predictive Value (PPV) is\nobtained as\n$\\PPV = \\frac{TP}{TP +FP}$  (3)\nSensitivity metric is represented by Recall, which indicates the true\npositive rate and measures the ability of the classifier to correctly identify\npositive instances. Sensitivity, or Recall, is defined as\n$\\Recall = \\frac{TP}{TP+FN}$ (4)\nF-measure (FM) or F-score metric is derived from two parameters, Recall\nand Precision (Witten et al. 2005). This measure, ranging from 0 to 1, peaks at 1\nfor a perfect classifier. F-measure is obtained as\n$\\F measure = \\frac{(1+\u1e9e\u00b2) \u00d7 Recall \u00d7 Precision}{Recall + Precision}$  (5)\nIn our study, \u03b2=1.\nThe ROC curve illustrates how a classifier balances between correctly\nidentifying TP and FP. It provides a comprehensive view of the classifier\neffectiveness, independent of class distribution or error costs (Davis & Goadrich\n2006). The Area Under the ROC Curve (AUC) represents the probability that a\nrandomly selected positive instance is ranked higher than a randomly selected\nnegative instance according to the model predictions. Generally, a classifier with\na larger AUC indicates better performance compared to one with a smaller AUC.\nThis curve is commonly used as a validation metric.\nFinally, a Confusion Matrix, a widely used tool in classification problems,\nis employed in this research. This tool provides detailed information about the\npredicted classifications (Deng et al. 2016). The Confusion Matrix is particularly\nbeneficial for evaluating the overall performance of the classification model,\nwhich is crucial for guiding subsequent improvements. It is structured such that\neach cell corresponds to a specific class assigned by the model, with rows\nrepresenting the actual classes and columns representing the predicted classes.\nIdeally, correctly classified instances align along the diagonal of the matrix, while\nmisclassified instances appear in the off-diagonal cells."}, {"title": "RESULTS", "content": "The development of the CNN training process and its validation results\nare depicted in Figure 5, which illustrates the accuracy and loss curves. Figure"}, {"title": "DISCUSSION", "content": "The issue of water pollution by TSS requires action from environmental\npolicymakers concerning the connection of individuals to the public sewer\nsystem, as well as monitoring the health of water bodies. In this context,\nmachine learning techniques offer valuable tools for decision-making based on\nphysical data obtained from simple water imaging. The CNN developed in this\nstudy exemplifies a tool that delivers excellent performance with modest\ncomputational resources.\nFigure 5, which depicts the learning curve of the proposed model, shows\nthat the CNN developed for water quality classification based on TSS\nconcentration demonstrates strong performance. This is evident from epoch 10\nonwards, with an accuracy exceeding 0.99, along with high precision, sensitivity,\nand F1-measure. However, fluctuations occur in subsequent training epochs.\nThese fluctuations are primarily due to images with low and medium solid\nconcentrations, where the solid content is so minimal that it becomes\nchallenging to identify within the sample, especially during constant agitation.\nWith an agitation speed of 300 rpm and a selected image crop area of 450 x 450\npixels out of a total of 1920 x 1080 pixels, some images may not adequately\ncapture the TSS concentration in the water sample. This crop area was chosen\nto avoid capturing water vortices and the magnetic stirrer used in the agitation\nprocess. The fluctuations in the learning process are likely due to difficulties in\ndistinguishing between the low and medium classes. This is supported by the\nConfusion Matrix, which shows one misclassified image between the low class\n(label 3) and the medium class (label 2) in terms of true labels and predictions\n(Figure 6b). However, this misclassification occurs in only one of the 653 images\nused for validation, resulting in an error rate of 1/653, equivalent to an error of\n0.0015. It is important to emphasise that overfitting can be ruled out based on\nthe learning curve analysis. The learning curve shows that as the number of\nepochs increases, the model accuracy continues to improve. Although there are\nfluctuations in accuracy and loss, these variations are relatively small, within a\nrange between 0.02 and 0.0004, especially when the accuracy reaches a high\nvalue of 0.99. This minor fluctuation indicates stability and high performance,\nsuggesting that the model is learning effectively and is unlikely to be overfitting.\nRegarding the \"high\" class in TSS concentration, it is evident that this class\nwas the most accurately classified by the network. With the highest number of\nimages used for this category, no misclassified labels were found, resulting in an\naccuracy of 1.0. This can be attributed to the higher TSS concentrations in these\nsamples and the abundance of training data, enabling the proposed CNN model\nto correctly associate high concentrations with this label.\nAs shown by the previously presented metrics (Table 3), despite the\npresence of one misclassified image out of 653 used for validation, the ROC\ncurve indicates that the classification probability is nearly 1.0 for all classes.\nSpecifically, the \"high\" class achieves a perfect identification probability of 1.0.\nFor the \"medium\" and \"low\" classes, the probability of correct identification is\n0.99999, which is rounded to 1.0000 in ROC (Figure 7a) for clarity due to decimal\nprecision. Additionally, the overall AUC for the model is 0.999996, also rounded\nto 1.0000 in ROC (Figure 7b), indicating a very high level of accuracy. These\nresults suggest that the developed network has a high probability of accurately\nclassifying TSS concentrations.\nRegarding the feature maps presented in Figure 8, these provide a\ndetailed view of how the network processes and classifies images, thereby\nvalidating its ability to detect relevant features. These feature maps reveal which\nfeatures are activated at each layer of the network, illustrating how the network\nprocesses the image\u2014from detecting simple edges and textures to identifying\ncomplex patterns. The review of these maps confirms that the CNN focuses on\ndifferences in suspended solids and effectively learns to identify relevant\npatterns, while ignoring factors such as optical distortions and unwanted\nradiation. Additionally, the dimensions of each feature map at the output of the\nlayers demonstrate that the model is correctly structured according to the\narchitecture used by AlexNet.\nAlthough the developed CNN model demonstrates a very high\nclassification probability, it is important to acknowledge its limitations. One such\nlimitation pertains to the high class, where the samples used reached a\nconcentration limit of 6000 mg/L, corresponding to sample 30. This value does\nnot represent the maximum possible concentration of TSS, as concentrations\nexceeding 20,000 mg/L have been recorded, potentially leading to saturation of\nthe water sample. In this study, only concentrations up to 6000 mg/L were\ncharacterised, thus limiting the CNN model to this concentration range. The\nlarger number of samples in the \"high\" class was due to the potential for high\nTSS concentrations, given the greater variability in TSS within this water quality\ncategory.\nAnother important consideration is the impact of different lighting\nconditions. In this study, data capture was conducted in a controlled\nenvironment with constant lighting. However, varying lighting sources and\ncapturing images from different angles could introduce classification errors in\nthe CNN. Therefore, to maintain high predictive accuracy, it is recommended to\ncontinue using the experimental procedure employed for image collection.\nAdditionally, the proposed model is currently limited to estimating water\nquality classes in terms of TSS for samples without dissolved solids (DS).\nDissolved solids can vary in nature\u2014colloidal, organic, inorganic, or soluble\nmaterials\u2014and may have different colorations, potentially causing classification\nerrors. Therefore, this CNN is designed to assess water quality in contexts where\nhigh levels of dissolved solids are absent. Consequently, the model is suitable"}, {"title": "CONCLUSIONS", "content": "for evaluating water quality in drinking water distribution systems, treated\nwastewater, or rainwater, where high concentrations of dissolved solids are\ngenerally not present. Despite this limitation, the CNN model effectively\ndistinguishes and classifies images of water with TSS concentrations,\ndemonstrating its potential for TSS water quality classification, especially in\nwaters with low levels of dissolved solids.\nAnother key feature of our CNN model is its reproducibility. To achieve\nthis, we optimised the model design to require low computational costs. This is\nreflected in the training time of the network, which, despite lasting 354 minutes\nand 13.4 seconds, was executed on a computer with modest specifications, as\nwe have already explained. The dataset used is relatively small compared to\nthose employed in models handling more complex images. Additionally, the\nclassifier has been specifically tuned to the characteristics of the image set and\nthe available computing power, ensuring a balance between accuracy and\nefficiency. This strategy not only facilitates the replication of the model in other\nenvironments but also reduces the resources needed for its implementation.\nCurrently, determining TSS as a water pollution parameter is performed\nin water quality laboratories, which is both costly and time-consuming.\nTherefore, this study proposes a novel alternative for classifying solids. This\napproach could become a valuable tool, particularly in the environmental\nmonitoring of water bodies, as it enables the evaluation of TSS in an easy, rapid,\nand efficient manner. By classifying TSS, it is possible to provide\nrecommendations on the use, destination, and disposal of water. For instance,\nin Mexico, the \"low\" classification aligns with the TSS concentrations allowed for\nthe discharge of treated wastewater into rivers, streams, canals, drains,\nreservoirs, lakes, and lagoons, and for irrigation of green areas. This class\ncorresponds to water of acceptable quality in terms of TSS, while the \u201cmedium\u201d\nclass is associated with concentrations characteristic of contaminated water,\nand the \u201chigh\u201d class with heavily contaminated water.\nIn this study, we developed a CNN framework utilising transfer learning to\nclassify three levels of TSS in water. The CNN was trained using visual records of\nwater samples with varying TSS concentrations. By employing TL, we were able\nto leverage pre-existing knowledge from large datasets, enabling our model to\nperform with near-perfect accuracy despite being trained on relatively small\ndatasets. This approach not only demonstrates the feasibility of using TL in\nenvironmental monitoring but also highlights its effectiveness in achieving\ncompetitive classification performance comparable to models trained on much\nlarger datasets. Our results suggest that TL can significantly reduce the need for\nextensive labelled data and computational resources, making it a promising tool\nfor practical applications in water quality analysis and other environmental\nmonitoring tasks.\nThe results archived from the validation of the proposed model\ndemonstrate an adequate performance in predicting water quality classification\nbased on the TSS parameter obtained from images. The main advantage of the\nmodel lies in the ease of acquiring these images, as they were captured with a\nsmartphone and a Ring Light Edge-Lit LED lamp, a common lighting source for\nvideo recordings that is economically available. Nevertheless, despite the\npromising metrics achieved during the training and validation phases, further\nrefinements are required to reach an accuracy of 1.0. With these enhancements\nand the appropriate model weights, the CNN has the potential to be effectively\ndeployed for evaluating water quality in the context of detecting suspended\nsolids. Achieving this level of performance will necessitate improvements to and\nexpansion of the dataset, as well as enhancements in image collection,\nparticularly for images with low concentrations of solids (low class). It can be\ntheorised that reducing the rpm during sample agitation may yield a better\ndataset for training the CNN. Another potential improvement is the optimization\nof the network hyperparameters; however, this would require increased\ncomputational costs. So, in future work, we plan to develop a new model that\nclassifies water into five quality levels: \"excellent\", \"good\", \"acceptable\",\n\"contaminated\", and \"heavily contaminated\", that is the classification used by\nthe Ministry of Environment and Natural Resources Mexico to classify water\nquality by suspended solids. This will enhance the distribution of solids\nconcentrations in the samples used in this study. Additionally, we aim to create\na hybrid model that combines the proposed CNN with an ANN using Multiple\nLinear Regression (MLR) to estimate both contamination classification and TSS\nconcentration in water samples. To achieve this, we will improve the current\nmodel by expanding the image dataset."}]}