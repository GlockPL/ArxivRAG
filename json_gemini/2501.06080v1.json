{"title": "Scale-up Unlearnable Examples Learning with High-Performance Computing", "authors": ["Yanfan Zhu", "Issac Lyngaas", "Murali Gopalakrishnan Meena", "Mary Ellen I. Koran", "Bradley Malin", "Daniel Moyer", "Shunxing Bao", "Anuj Kapadia", "Xiao Wang", "Bennett Landman", "Yuankai Huo"], "abstract": "Recent advancements in AI models, like ChatGPT, are structured to retain user interactions, which could inadvertently include sensitive healthcare data. In the healthcare field, particularly when radiologists use AI-driven diagnostic tools hosted on online platforms, there is a risk that medical imaging data may be repurposed for future AI training without explicit consent, spotlighting critical privacy and intellectual property concerns around healthcare data usage. Addressing these privacy challenges, a novel approach known as Unlearnable Examples (UEs) has been introduced, aiming to make data unlearnable to deep learning models. A prominent method within this area, called Unlearnable Clustering (UC), has shown improved UE performance with larger batch sizes but was previously limited by computational resources (e.g., a single workstation). To push the boundaries of UE performance with theoretically unlimited resources, we scaled up UC learning across various datasets using Distributed Data Parallel (DDP) training on the Summit supercomputer. Our goal was to examine UE efficacy at high-performance computing (HPC) levels to prevent unauthorized learning and enhance data security, particularly exploring the impact of batch size on UE's unlearnability. Utilizing the robust computational capabilities of the Summit, extensive experiments were conducted on diverse datasets such as Pets, MedM-Nist, Flowers, and Flowers102. Our findings reveal that both overly large and overly small batch sizes can lead to performance instability and affect accuracy. However, the relationship between batch size and unlearnability varied across datasets, highlighting the necessity for tailored batch size strategies to achieve optimal data protection. The use of Summit's high-performance GPUs, along with the efficiency of the DDP framework, facilitated rapid updates of model parameters and consistent training across nodes. Our results underscore the critical role of selecting appropriate batch sizes based on the specific characteristics of each dataset to prevent learning and ensure data security in deep learning applications. The source code is publicly available at https://github.com/hrlblab/UE_HPC.", "sections": [{"title": "INTRODUCTION", "content": "In the era of data security, the absence of rigorous human oversight during the process of data collection renders organizations susceptible to heightened security threats [1]. The protection of sensitive information against unauthorized access and inference attacks has become paramount. As machine learning and deep learning technologies continue to permeate various sectors, the inadvertent leakage of data through learned models poses privacy risks. Recent advancements in enhancing data privacy through machine learning and deep learning have led to the development of innovative strategies which aim to make data inherently resistant to unauthorized learning, are crucial in increasingly data-driven world. This has led to the development of Unlearnable Examples (UEs) [9], a technique designed to render data unlearnable (or unusable) by machine learning models and deep learning models.\nAs the development of data poisoning algorithms for machine learning, such as SVMs [5] and deep learning [2], continues to advance, these techniques can also be utilized to protect data characteristics from being learned by attackers. Data poisoning strategically alters the training dataset, thereby impairing the ability of unauthorized models to train effectively as a unlearnable method shown in Figurel. This not only disrupts malicious uses of data but also enhances the security of data attributes, safeguarding them against adversarial learning attempts.\nUnlearnable Cluster(UCs) [3], a notable example, introduces a label-agnostic method to create effective unlearnable examples(UEs) using cluster-wise perturbations. UC method, compared to other UEs generate methods, are more powerful to prevent attackers from learning and disclosing data content without depending on specific data labels. While existing studies have explored various aspects of making data unlearnable, there is a dearth of systematic investigations into how different optimization settings affect the efficacy of unlearnable clusters across various datasets. Understanding the optimal settings that maximizes unlearnability without compromising the computational efficiency is crucial, particularly in enviroments that require the processing of large volumes of data.\nInspired by insights from work [6] by Samuel et al., we find"}, {"title": "METHOD", "content": "DDP Packed UCs\nThe UCs model primarily consists of two components: a generator model and a surrogate model. The generator model transforms random noise into cluster-wise noise, while the surrogate model is employed. This training process ensures that the noise-infused images more closely align with the disrupted cluster labels in the feature space. During training, the model initiates by generating clusters using k-means [10] and shuffling their labels. Noise, created from these shuffled labels by the generator, is then added to images and trained in the surrogate model. This process aims to achieve high accuracy with the noise on the surrogate model, ensuring that the noise added to the network is"}, {"title": "Modified Surrogate Model for Synchronized Bias and Weights", "content": "The synchronization of model parameters including biases and weights is a pivotal aspect of ensuring uniform model performance across multiple GPUs or nodes. Traditional surrogate model of UCs method commonly encounter issues with parameter synchronization when hooks are used to extract the features within the full connection layer. This leads to discrepancies in learning updates. To en-counteract this challenges, we have developed the modified surrogate model, ResNetWithFeature, that is specifically engineered for use in DDP environments.\nThe ResNetWithFeature model adapts the standard ResNet architecture by modifying how features are extracted and processed across the network. Instead of employing traditional hooks in the forward process that can cause asynchronous updates, this model utilizes a tailored mechanism to capture intermediate features directly within the forward pass of the mdoel. By embeddomg feature extraction directly into the computational graph of the model, it ensures that all feature maps and corresponding parameters are inherently synchronized across all nodes during backpropagation. This adjustment not only prevents the potential misalignment of weights and biases but also maintains the efficiency and scalability of the DDP framework.\nThis synchronization reduces the risks associated with divergent behaviors among nodes. Futhermore, by ensuring that all parameters are update uniformly, the model leverages the full computational power of the Summit supercomputer, thereby improving overall training speed and performance. The modification made in the ResNetWithFeature demonstrate a practical solution to the challenges posed by traditional hook-based feature extractions in distributed training environments, can be reproduced on any other surrogate model chosen. A substantial number of batch job scripts can be submitted to the Summit supercomputer to handle training with varying batch size parameters. This process provides us with reliable data, essential for studying the impact of scaling up techniques on the performance of the network model."}, {"title": "DATA AND EXPERIMENTAL DESIGN", "content": "Data\nIn our evaluation, we utilize a range of datasets including Pets [7], Flowers [13], Flowers102 [11], as well as OrganMNist-A, BloodMNist, and PathMNist from MedMNist [12]. The first three datasets represent real-world objects, while the latter ones are medical imaging datasets. By conducting experiments across these diverse datasets, we assess the model's performance under various real-world and medical imaging scenarios.\nExperimental Design\nThe network is trained using the Adam optimizer with a specified learning rate, with a weight decay of 5e-4 applied. To manage the learning rate throughout the training process, a cosine annealing scheduler is implemented, gradually reducing the learn-"}, {"title": "RESULTS", "content": "Tablel illustrates the performance of models trained on different datasets with varying batch sizes with the same cluster perturbation parameters, comparing to the performance of models trained on the clean datasets and the performance of the baseline results from Zhang et al [3].\nThe Figure3 of accuracy across different batch sizes for six datasets (BloodMNist, PathMNist, OrganMNist, Pets, Flowers, and Flowers102) reveal distinct trends that underscore the dataset-specific nature of batch size effects on model performance and data unlearnability.\nBased on the accuracy for BloodMNist and PathMNist"}, {"title": "DISCUSSION", "content": "The results from all the experiments conducted reveals that the relationship between batch size and model performance is highly dataset-dependent, underscoring the need for dataset-specific configurations when training models to optimize unlearnability. While some datasets, like BloodMNist and Flowers102, benefit from larger batch sizes, others, such as OrganMNist and"}, {"title": "CONCLUSION", "content": "In conclusion, this study highlights the critical role of batch size in optimizing the performance of UCs for data security in deep learning models. By leveraging the Summit supercomputer's capabilities, we demonstrate that the relationship between batch"}]}