{"title": "Towards Interactive and Learnable Cooperative Driving Automation: a Large Language Model-Driven Decision-Making Framework", "authors": ["Shiyu Fang", "Jiaqi Liu", "Mingyu Ding", "Yiming Cui", "Chen Lv", "Peng Hang", "Jian Sun"], "abstract": "At present, Connected Autonomous Vehicles (CAVs) have begun to open road testing around the world, but their safety and efficiency performance in complex scenarios is still not satisfactory. Cooperative driving leverages the connectivity ability of CAVs to achieve synergies greater than the sum of their parts, making it a promising approach to improving CAV performance in complex scenarios. However, the lack of interaction and continuous learning ability limits current cooperative driving to single-scenario applications and specific Cooperative Driving Automation (CDA). To address these challenges, this paper proposes CoDrivingLLM, an interactive and learnable LLM-driven cooperative driving framework, to achieve all-scenario and all-CDA. First, since Large Language Models (LLMs) are not adept at handling mathematical calculations, an environment module is introduced to update vehicle positions based on semantic decisions, thus avoiding potential errors from direct LLM control of vehicle positions. Second, based on the four levels of CDA defined by the SAE J3216 standard, we propose a Chain-of-Thought (COT) based reasoning module that includes state perception, intent sharing, negotiation, and decision-making, enhancing the stability of LLMs in multi-step reasoning tasks. Centralized conflict resolution is then managed through a conflict coordinator in the reasoning process. Finally, by introducing a memory module and employing retrieval-augmented generation, CAVs are endowed with the ability to learn from their past experiences. We validate the proposed CoDrivingLLM through ablation experiments on the negotiation module, reasoning with different shots experience, and comparison with other cooperative driving methods. The results demonstrate that our method provides significant safety and efficiency advantages, as well as the ability to interact and learn effectively in complex environments. Our code is available at: https://github.com/FanGShiYuu/CoDrivingLLM.", "sections": [{"title": "I. INTRODUCTION", "content": "As autonomous driving technology continues to advance, we are entering an era where both Connected Autonomous Vehicles (CAVs) and Human-Driven Vehicles (HDVs) will coexist. While CAVs are considered to have great potential in improving traffic safety and efficiency, their current performance on open roads is far from satisfactory. According to California's Department of Motor Vehicles [1], 51% of disengagements were due to CAVs' decision-making failures. Additionally, the Beijing Autonomous Vehicle Road Test Report revealed that up to 91% of disengagements occurred during interactions with other vehicles, indicating that current autonomous driving technology is not yet adequate for complex interaction scenarios [2].\nTo ameliorate this issue, a promising approach is to leverage the cooperative driving capabilities of CAVs [3]. The SAE J3216 standard divides Cooperative Driving Automation (CDA) into four levels: Status-sharing, Intent-sharing, Agreement-seeking, and Prescriptive [4]. Federal Highway Administration has conducted the CARMA Program to develop and test CDA. However, the current validation of the program primarily focuses on single CDA under single scenarios, such as cooperative platooning at highway [5]. How to achieve all-scenario and all-CDA cooperative driving still remains to be tackled.\nVarious approaches have been proposed to address the problem of cooperative driving in different scenarios. The currently popular cooperative driving methods can be broadly categorized into optimization-based, rule-based, and machine learning-based approaches. Optimization-based methods aim to maximize or minimize an objective function to achieve specific goals. Due to the complexity of cooperation involving multiple participants and relationships, optimization-based research often introduces additional simplifications to balance computational time and performance. A common practice in intersection management is to divide the area into multiple zones, with each zone being occupied by only one vehicle at any given time[6, 7]. An alternative approach is to decompose the problem into two layers and optimize the upper and lower layers respectively to simplify the complexity of the problem [8]. However, optimization-based approaches often fail to explicitly consider regulations and social norms during driving, making their decision results difficult to understand. In contrast, the rule-based approach boasts simplicity in form and thus computational efficiency [9]. Nevertheless, despite the rule-based approaches that can be coupled with traffic regulations, pre-set rules often result in poor robustness. On the other hand, machine learning methods, such as deep learning and reinforcement learning, have gained increasing popularity in recent years. These methods have been successfully applied"}, {"title": "II. PROBLEM FORMULATION", "content": "With the increasing maturity of autonomous driving technology, manufacturers have shifted from focusing on early-stage technical competition to prioritizing commercial deployment. However, CAVs still exhibit various problems on open roads and even become the culprit of many congestion or accidents. In certain scenarios, the accident rate of CAVs even reached 5.25 times that of human drivers, which has failed to meet people's expectations for autonomous driving technology, and is gradually eroding people's trust in CAVs. The communication capabilities of CAVs enable connectivity and mutual assistance. Therefore, leveraging cooperative driving capabilities is a promising way to enhance CAV performance.\nAdditionally, the cooperative decision-making problem for multiple CAVs can be modeled as a partially observable Markov decision process (POMDP)[24]. We define the POMDP using the tuple $M_g = (V, S, [O_i], [A_i], P, [r_i])$, where $V$ represents the finite set of all controlled agents (CAVs), and $S$ denotes the state space encompassing all agents. $O_i$ represents the observation space for each agent $i \\in V$, $A_i$ denotes the action space, and $r_i$ is the reward associated with CAV $i$. The transition distribution is represented by $P$.\nAt any given time, each agent $i$ receives an individual observation $o_i : S \\rightarrow O_i$ and selects an action $a_i \\in A_i$"}, {"title": "III. INTERACTIVE AND LEARNABLE LLM-DRIVEN COOPERATIVE DRIVING FRAMEWORK", "content": "Leveraging the cooperative driving ability of CAV can significantly improve the safety and efficiency of traffic systems. However, the current research often focuses on single-scenario, single-function cooperation, leading to insufficient interaction capabilities and a lack of continuous learning capabilities. Utilizing the extensive world knowledge and strong reasoning capabilities of LLMs holds promise for addressing these challenges and achieving all-scenario and all-level cooperative automation, thereby fully unleashing the potential of CAVs to transform traffic systems. As a solution, we propose CoDrivingLLM: an interactive and learnable LLM-driven cooperative driving framework for all scenarios and all cooperative driving automation.\nCoDrivingLLM mainly contains three modules: the environment module, the reasoning module, and the memory module. In this section, we first introduce the overall framework of CoDrivingLLM and then provide detailed explanations of each module.\nA. Overall Architecture\nFig. 2 illustrates the main modules and their logical relationships within CoDrivingLLM, which consists of three primary modules: the environment module, the reasoning module, and the memory module. First, the environment module updates the current scene information, including the state of all vehicles such as position, speed, etc., based on the actions of both CAVs and HDVs from the previous time step. Next, we designed a centralized-distributed coupled LLM reasoning module. Based on the four levels of CDA defined by the SAE J3216 standard, we integrated four sub-functions into this reasoning module: state sharing, intent sharing, negotiation, and decision. By incorporating the Chain-of-Thought (COT) method, we sequentially connect each sub-function in the reasoning process to enhance the safety and reliability of decision-making. During this process, each CAV performs distributed high-level logical reasoning using LLMs, completing cooperative driving at different levels, and utilizes the conflict coordinator within the framework for centralized conflict resolution, further enhancing safety. Finally, the scenario description, conflict description, and final decisions from the reasoning process are stored in a memory database with a vectorized form. In the subsequent reasoning, the CAV can reference the most similar past memory as experience, enabling the designed CAV to continuously learn and improve its capabilities while driving.\nB. Environment Module\nThe environment module consists of two sub-modules: (1) the environmental dynamics simulation sub-module, which simulates real-world environmental dynamics to provide realistic background traffic flow and training feedback for the cooperative driving framework, and (2) the model-based control execution sub-module, which provides model-based vehicle control units for the LLM, enhancing the accuracy and success rate of action execution.\n1) Environmental Dynamics Simulation Sub-module: Real-world feedback is crucial for training a stable and reliable cooperative decision-making model. To ensure the realism and reliability of the simulation, we consider a mixed human-autonomous driving environment within the environmental dynamics module, introducing uncontrolled human-driven ve-"}, {"title": "C. Reasoning Module", "content": "In this subsection, we establish an integrated reasoning module that progresses from state sharing to intent sharing, negotiation, and finally, decision. This module operates in a chain of thought manner, ensuring a smooth transition for CAVs from environmental perception to interaction and negotiation, and ultimately to decision-making.\nThe reasoning module first extracts information about surrounding vehicles from the environment to create a scene description. It then organizes the states of the vehicles into conflict pairs, forming conflict descriptions. To ensure consistency in vehicle decision-making during conflicts and to avoid collisions, we developed an LLM-based conflict coordinator. This coordinator integrates the current conflict descriptions with traffic rules to determine the order of priority for each conflict group. Finally, each CAV makes its decisions based on the conflict coordinator's recommendations and its own scenario description.\n1) State-perception: The state-perception function is responsible for acquiring and processing information about the current environment of the CAV, including dynamic data such as lane information and vehicle information. The designed state-perception function aligns with the first level of CDA in the SAE J3216 standard, which is state sharing. CAVS are allowed to exchange information with others, therefore paving the way for subsequent higher levels of CDA. Through comprehensive analysis of the above information, the state-perception function can construct a complete and accurate driving environment recognition, which provides a reliable basis for subsequent reasoning.\nSpecifically, lane information is divided into three categories: the ego lane, adjacent lanes, and conflict lanes. The ego lane is the lane where the ego vehicle is currently driving in, adjacent lanes are the lanes on the left and right sides of the ego lane if they exist, and conflict lanes are the lanes that intersect with the ego lane. Similarly, vehicle information can be grouped based on their relationship with the ego vehicle into leading vehicles, rearing vehicles, surrounding vehicles, and conflict vehicles. During the state-perception process, lane information and vehicle information are combined to create an overview of the ego vehicle's surrounding environment. Since vehicles in different lanes can affect the ego vehicle differently, a three-level action safety assessment is designed to ensure safe driving, which will be detailed in the decision subsection.\n2) Intent-sharing: The intent-sharing function, which conveys the driving intentions of a vehicle to other CAVs, is a key advantage of cooperative driving. From macro to micro, driving intention mainly includes the sharing of expected lanes and expected speed. Through intent-sharing, other vehicles can better understand the ego vehicle's intentions, allowing them to make decisions while avoiding conflicts as much as possible.\nState perception and intent sharing are combined as the scene descriptions. This description is based on the lane and includes all objects that could affect the ego vehicle, such as adjacent vehicles and conflicting vehicles. Therefore, it can be migrated to multiple scenarios, like intersections, highways, and merging areas, significantly enhancing the versatility of the proposed cooperative driving framework.\n3) Negotiation: CAVs possess broader perception capabilities and more powerful computing capabilities, which theoretically enable faster and more accurate recognition of the intentions of other vehicles. However, according to California's Department of Motor Vehicles [25], over 31% of accidents are caused by CAV misjudging the intentions of other traffic participants, highlighting that traditional decision-making methods still have significant shortcomings in processing high-dimensional information such as intentions. Therefore, a conflict coordinator is designed to resolve conflicts and achieve level-3 CDA, which is known as agreement-seeking cooperation.\nThe conflict coordinator identifies all potential conflicts in the current environment and assesses the severity of each conflict based on the current state of both vehicles involved. To quantify the degree of conflict severity, the time difference to the conflict point as the surrogate indicator, defined as:\n$\\Delta TTCP = |TTCP_i - TTCP_j| = |\\frac{d_i}{v_i} - \\frac{d_j}{v_j}|$\nATTCP < 2s, Serious Danger\n2s < \u0394TTCP < 5s, General Danger\n5s < ATTCP < 8s, Slight Danger\n\u0394\u03a4\u03a4\u0395\u03a1 > 8s, No Danger\nwhere $TTCP$ is the time to conflict point based on the vehicle's current distance to conflict point $d$ and speed. Among them, when ATTCP is less than 2s, it signifies a serious conflict, requiring at least one of them must take an emergency brake. If ATTCP falls between 2s and 5s, it is considered that there is a general conflict between the two vehicles, and at least one vehicle should slow down and yield. When the ATTCP is"}, {"title": "D. Memory Module", "content": "Enhancing continuous learning capabilities in autonomous systems has always been a significant challenge. Novice drivers accumulate experience through continuous driving practice, evaluate the effects of different behaviors, and learn from them to improve their driving skills. Drawing on this mechanism, a memory module is introduced to enable CAVS to learn from past experiences and utilize this knowledge to future interactions. This process is also referred to as Retrieve-Augmented Generation (RAG).\nRAG endows LLMs with the ability to access specific knowledge databases within a domain or organization. This capability allows for economically efficient improvement of LLM outputs without requiring model retraining, ensuring relevance, accuracy, and practicality in addressing specific domain problems. Specifically, the designed memory module contains two primary functions: memory augment and memory retrieval.\n1) Memory augment: The memory augment function evaluates the impact of CAV actions from the previous scenario to determine whether these actions have exacerbated conflicts. If a CAV's behavior leads to increased danger, the system generates negative feedback, such as: \"Your action has intensified the conflict; similar actions should be avoided.\" This feedback mechanism establishes a connection between scenarios, actions, and results, storing these mappings in the memory databases for future reference. Before each invocation of the LLM for reasoning, the most relevant memories are retrieved from the memory databases to augment the prompts, thereby avoiding the repetition of past mistakes.\n2) Memory retrieval: As the number of interactions increases, the memory databases will accumulate numerous past experiences. Inputting all memories as prompts would lead to redundancy, making it difficult for the CAV to extract"}, {"title": "IV. EXPERIMENTS AND ANALYSIS", "content": "To verify whether the proposed CoDrivingLLM can effectively improve the interaction ability and learning ability of CAV, this section carries out verification from three aspects. Firstly, ablation experiments were conducted on the negotiation module in different scenarios. Second, we compared the performance of CoDrivingLLM in different scenarios under 0-shot, 2-shots and 5-shots experiences. Finally, we evaluated the safety and efficiency of CoDrivingLLM against other cooperative driving methods, including optimization-based, rule-based, and machine learning-based methods.\nA. Experiment Settings\nSimulation Environment. We develop our environment module based on the highway-env[26], an open-sourced and flexible simulation platform for autonomous driving. Three scenarios are designed to conduct experiments, as shown in Fig.4, including a four-way highway scenario, merge scenario, and single-lane unsignalized intersection. The settings of context traffic flow and HDVs follow the instructions of the environment module of our framework.\nImplementation details. The GPT-40 mini is utilized our base LLM model to conduct high-level logical thinking and judgment. Four CAVs are controlled in each simulated environment. Furthermore, all scenarios with different settings are repeated 20 times with different random seeds to attain the final results. The success rate is used as the indicator to evaluate the performance of all methods. In one case, if all CAVs finish their driving tasks safely and arrive at their destination, this case is successful. Success rate means the ratio of the number of successful cases to the total number of cases.\nB. Ablation Study on Negotiation\nLack of interaction ability is an important reason for the current CAV's struggle on the open road. Cooperative driving, through the sharing of states and intentions, can provide additional information to help conflicting parties align their decision-making. To achieve this, we introduce a negotiation module into the reasoning process. By establishing an LLM-driven conflict coordinator, the traffic rules and scenario description are integrated to produce a suggested traffic sequence to assist the final decision, thus improving the interaction"}, {"title": "C. Comparison with Memory Module", "content": "The memory module helps CAVs learn from past experiences to avoid repeating mistakes. To validate the effectiveness of the memory module, we compare the performance of our method in different scenarios under 0-shot, 2-shots, and 5-shots experiences. In this context, 0-shot means the memory module is not used, while 2-shots and 5-shots refer to the introduction of the two and five most similar past experiences to the current scenario as prompts before reasoning.\nAs shown in Fig.7, in the highway scenario, where vehicle conflicts and interaction challenges are minimal, a 100% safety rate is achieved even without the memory module, and this success rate remains consistent when 2-shots and 5-shots experiences are added. However, in the merge and intersection scenarios, increasing the memory module from 0-shot to 2-shots significantly improves the decision-making success rate, with the merge scenario rising from 78% to 90% and the intersection scenario from 75% to 85%.\nWe do note that when the memory module is further increased from 2-shots to 5-shots, there is a slight decline in performance in both scenarios. We believe this indicates that longer memory does not necessarily enhance LLM decision-making. An excess of repetitive or low-value memories may occupy too much of the LLM's context window, reducing its ability to focus on other relevant perceptual information and potentially leading to a degree of negative impact.\nWe also use an intersection scenario case to demonstrate the role of the memory module. Fig.8(a) shows a typical case of decision failure. In this instance, CoDrivingLLM is not equipped with the memory module. At 4 seconds, although the decision module, through the negotiation module, identifies a potential rear-end conflict between CAV7 and CAV4 and attempts to resolve it by adjusting actions, CAV4 accelerates while CAV7 decelerates. However, due to CAV7's high initial speed, it collides with CAV4 before it can fully decelerate. This case illustrates that in certain special scenarios, cooperative decision-making can still fail even with the negotiation module in place.\nIn contrast, Fig.8(b) demonstrates the decision-making performance of CoDrivingLLM after utilizing the memory mod-"}, {"title": "D. Comparison with Other Methods", "content": "Considering that not all cooperative driving methods are suitable for multiple scenario, and unsignalized intersections are often where accidents occur most frequently [27]. Therefore, we selected the three typical cooperative driving methods mentioned earlier to test our approach under unsignalized intersection scenario, including optimization-based method (iDFST)[9], rule-based method (Cooperitave game)[28], learning-based method (MADQN)[29].\n1) Overall Performance: Firstly, we summarized the success rate of each methods. According to the data presented in Table. I, CoDrivingLLM outperforms the other methods, achieving a success rate of 90%. The iDFST and Cooperative Game methods lag slightly behind, both achieving a success rate of 85%. In contrast, MADQN displays the poorest generalization and performance, with a success rate of merely 20%.\n2) Safety Evaluation: We have conducted a comprehensive safety analysis of various methods, utilizing the Post-Encroachment Time (PET) metric, a widely recognized safety parameter in traffic engineering. This metric effectively quantifies the safety and interaction intensity of vehicles in intricate traffic scenarios. According to the results presented in Fig. 9 and Table. I, both the iDFST approach and CoDrivingLLM exhibit commendable performance, with mean PET values of 15.1 seconds and 10.3 seconds, respectively. Conversely, MADQN and the Cooperative method demonstrate PET values of 5.7 seconds and 3.7 seconds, respectively, indicating a heightened risk in decision-making interactions within the traffic environment. In addition, a lower PET value signifies an"}, {"title": "V. CONCLUSION", "content": "Cooperative driving technology effectively enhances the quality of cooperative decision-making for CAVs. Leveraging"}, {"title": "1 Initialize the decision buffer of each CAV", "content": "1 Initialize the decision buffer of each CAV $D \\leftarrow []$;\n2 Initialize the scenario description buffer of each CAV $sce \\leftarrow []$;\n3 $foreach i \\in C do$\nGenerate the scenario description $sce_i$ of vehicle i based on current states $S_t$;\nAdd scenario description to buffer\n$sce \\leftarrow sce.Add(sce_i)$;\n6 end"}]}