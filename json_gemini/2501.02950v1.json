{"title": "Key-value memory in the brain", "authors": ["Samuel J. Gershman", "Ila Fiete", "Kazuki Irie"], "abstract": "Classical models of memory in psychology and neuroscience rely on similarity-based retrieval of stored patterns, where similarity is a function of retrieval cues and the stored patterns. While parsimonious, these models do not allow distinct representations for storage and retrieval, despite their distinct computational demands. Key-value memory systems, in contrast, distinguish representations used for storage (values) and those used for retrieval (keys). This allows key-value memory systems to optimize simultaneously for fidelity in storage and discriminability in retrieval. We review the computational foundations of key-value memory, its role in modern machine learning systems, related ideas from psychology and neuroscience, applications to a number of empirical puzzles, and possible biological implementations.", "sections": [{"title": "Introduction", "content": "Despite the apparent fragility of memory, there is no decisive evidence that information, once stored, is ever permanently lost. The storage capacity of the brain of course must be finite, but that does not seem to be the principal limiting factor on memory performance. Rather, it is the retrieval process that fundamentally limits performance: the relevant information may be there, but cannot always be found (Tulving, 1974; Crowder, 1976; Lewis, 1979; Miller, 2021). Some of the evidence supporting this view will be summarized below.\nA retrieval-oriented view of memory performance places the primary explanatory burden on how memories are addressed (i.e., how the retrieval system keeps track of storage locations), and how they are queried (i.e., how the retrieval system maps sensory cues to addresses). There is a long history of theorizing about these concepts in cognitive psychology and neuroscience (Kahana, 2012; Chaudhuri and Fiete, 2016). Recently, the field of machine learning has developed its own analysis of these concepts, which form the basis of high-performing systems like transformers and fast weight programmers (Vaswani et al., 2017; Schmidhuber, 1992). There is increasing recognition that a significant aspect of intelligence (in both natural and artificial systems) is effective information retrieval (Graves et al., 2016; Gershman and Daw, 2017; Geva et al., 2021; Irie et al., 2022; Allen-Zhu and Li, 2024).\nOur goal is to connect the dots between conceptualizations of memory retrieval in psychology, neuroscience, and machine learning. Central to this effort is the concept of key-value memory, which we formalize below. The basic idea is that inputs (memoranda) are transformed into two distinct representations\u2014keys and values\u2014which are both stored in memory. The keys represent memory addresses, while the values store memory content. Memories are accessed by first matching a query to each key, and then retrieving a combination of values weighted by their corresponding matches. Importantly, the mappings from inputs into keys and values can be optimized separately, allowing the system to distinguish between information useful for finding memories (stored in the keys) and information useful for answering the query (stored in the values). This distinction is familiar in human-designed information retrieval systems. For example, books often have alphabetically organized indices, which are helpful for finding particular subjects. The indices do not contain any information about the meaning of the subjects themselves; this information is stored in the book's text, retrieved by going to the page number associated with the index.\nWe will argue that memory in the brain follows similar principles. In particular, we posit a division of labor between a key storage system in the medial temporal lobe and a value storage system in the neocortex. As reviewed below, closely related ideas have already been proposed in psychology and neuroscience. By connecting these ideas to key-value memories, we can begin to understand what makes memory in the brain computationally powerful. To illustrate these points, we present simulations that recapitulate a number of empirical phenomena. Implications for the convergence of natural and artificial intelligence are discussed in the concluding section."}, {"title": "Computational foundations of key-value memory", "content": "In this section, we introduce the technical ideas underlying key-value memory, exposing the multitude of ways in which this idea has been conceptualized. We place key-value memory within a modern machine learning framework by discussing how the key and value representations can be learned, comparing an end-to-end learning approach with fixed (or partially fixed) \u201cscaffolds\" for key representations."}, {"title": "From correlations to kernels", "content": "One of the earliest formalizations of a key-value memory was Kohonen's correlation matrix memory model (Kohonen, 1972), which was subsequently used by Pike (1984) to explain a range of human memory phenomena. Here we slightly change the notation and terminology to bring this model into correspondence with more recent formalizations (Figure 1, left). Each input, indexed by n, consists of a key vector kn and a value vector vn (which we take to be row vectors). Intuitively, the keys encode information about memory addresses (hence we will refer to the set of possible keys as the address space), while the values encode information about memory content. These two representations are linked in memory by an \u201cassociator\u201d matrix M, which is initialized at 0 and incremented by the outer product of the key and value vectors after each input is presented:\n\\Delta M \\propto k_n v_n^T.\n(1)\nIt is easy to see that this is just simple Hebbian learning between key and value units encoding the vector elements. In neurobiology, the standard interpretation is that Mij is encoded by the synaptic strength between neurons representing value element j and key element i. The synaptic strength is increased when the two neurons fire coincidentally (Caporale and Dan, 2008). Needless to say, learning in the brain is more complicated than this, but for present purposes we will take for granted the biological plausibility of Eq. 1 (see also Limbacher and Legenstein, 2020, for a related, but more complex, learning rule).\nThe correlation matrix memory is heteroassociative because M stores information about the relationship between two different kinds of objects or object properties (see also Steinbuch and Piske, 1963, for one of the earliest such models). If we impose the constraint that keys and values are the same, we get an autoassociative memory (Willshaw et al., 1969; Anderson, 1970; Amari, 1972; Nakano, 1972). This idea is now most closely associated with the work of Hopfield (1982), and such models (when the inputs are binary) are typically referred to as Hopfield networks."}, {"title": "Representational structure", "content": "So far, our setup has assumed a memory system provided with keys, values, and queries\u2014where do these representations come from? In modern machine learning, they are derived as mappings from input vectors, {xn}. A typical assumption in transformers and fast weight programming is to parametrize the mappings with a set of linear functions:\nk_n = x_n W_k\n(7)\nv_n = x_n W_v\n(8)\nq_n = x_n W_q.\n(9)\nwhere {Wk, Wv, Wq} are learned weight matrices. The input vectors may themselves be learned embeddings of raw input data, harnessing the power of deep learning systems trained end-to-end.\nIn some systems, the key and query mappings are assumed to be fixed, either randomly or based on some regular structure. In these systems, the address space is conceived as a kind of \u201cscaffold\u201d for the indexing of information content. In the sparse distributed memory model (Kanerva, 1988), the scaffold is random, so that similar keys do not systematically index similar values. This mimics (approximately) the organization of random access memory in digital computers. A familiar example of a structured scaffold is the alphabetical index found at the end of books. In the Hopfield network (Hopfield, 1982) and related autoassociative memory models, the scaffold is identical to the value space. This property endows the models with content addressability (Kohonen, 1980): memory addresses are accessed by matching values directly to queries. Most psychological and neural models of memory share this property, though they implement it in different ways.\nSome models assume that the scaffold is randomly constructed in such a way that it carries a structural imprint. For example, if inputs are assigned to random addresses, but these addresses change slowly over time, then inputs experienced nearby in time will encoded as more \u201csimilar\u201d in the address space. Temporal autocorrelation, in the absence of additional structure, is able to account for many aspects of human (Landauer, 1975) and animal (Estes, 1955) memory."}, {"title": "The ubiquity of key-value memory", "content": "The work reviewed above focused on explicit constructions of key-value memory. It turns out that other models are sometimes implicitly equivalent. Irie et al. (2022) showed that linear layers trained by gradient descent (ubiquitous in many machine learning models) can also be expressed as key-value memories. Here we briefly review this theorem.\nLet xn be the input vector at time n, as in the previous section. The output of a linear layer is yn = xnW, where W is as weight matrix. The weight matrix is trained by gradient descent, yielding the following after N timesteps:\nW = W_0 + \\sum_{n=1}^N x_n e_n^T,\n(10)\nwhere Wo is the initial weight matrix, and en = -\\eta_n(\\nabla_y L)_n is the error signal with learning rate \\eta_n and loss function L. Generalizing a classic result on kernel machines (Aizerman et al., 1964), Irie et al. (2022) showed that this construction is equivalent (in the sense of producing the same output for a given input) to the following linear key-value memory:\ny = xW_0 + \\sum_{n=1}^N \\alpha_n v_n,\n(11)\nwhere (using our earlier notation) \\alpha = qK^T with vn = en, kn = xn, and q = x, given an arbitrary input x. Thus, linear layers effectively memorize their experienced error patterns, computing their outputs as linear functions of these memories. This interpretation is intriguing in light of the fact that errors are particularly salient in human memory (Green, 1956; Hirshman et al., 1989; Sakamoto and Love, 2004; Rouhani et al., 2018; Bein et al., 2021).\nThe linear layers retain information about all training inputs\u2014they never \u201cforget\u201d (Irie et al., 2022). However, retrieval access may be (transiently) lost. We discuss evidence for this idea from psychology and neuroscience below."}, {"title": "Neurobiological substrates", "content": "While key-value memories are loosely inspired by the brain, it remains an open question how to implement them in a biologically plausible manner. Eq. 1 is a (somewhat) biologically plausible rule for learning associations between keys and values, but we still need rules for storing the keys and values themselves. In the section on representation learning, we described the widely used approach of modeling keys, queries, and values as linear mappings from input vectors (which themselves could be learned). This implies additional learning rules for the linear mappings. One could posit that they are learned by backpropagating the errors from whatever objective function is being optimized for a downstream task (see, for example, Limbacher and Legenstein, 2020). This would require a biologically plausible approximation of the backpropagation algorithm (Lillicrap et al., 2020).\nAlternatively, Tyulmankov et al. (2021) have proposed a non-Hebbian learning rule for key learning. They view the key-value memory as a three-layer neural network, where the input x (first layer) is transformed into a pattern of attention \\alpha (hidden layer), which is finally transformed into retrieved values v (output layer); see the right panel of Figure 1. Each hidden layer unit represents a \u201cslot\u201d to which a single input (or possibly multiple inputs) gets assigned. In this view, the key matrix K corresponds to the input-hidden synaptic strengths, and the value matrix V (where row n corresponds to value vector vn) corresponds to the hidden-output synaptic strengths. The proposed learning rule for the synapse connecting input unit j to hidden unit i is (simplifying slightly, and dropping time indices):\n\\Delta K_{ij} \\propto \\mu \\gamma_i (x_j - K_{ij}),\n(12)\nwhere \\mu \\in {0, 1} is a global third factor (possibly a neuromodulator like acetylcholine or dopamine) and \\gamma_i \\in {0, 1} is a local third factor (possibly a dendritic spike). The factors are binary to promote sparsity in the hidden layer. The local third factor tags the least-recently-used hidden unit as eligible for plasticity. Tyulmankov et al. (2021) point out that the key learning rule resembles behavioral time scale plasticity (Bittner et al., 2017), which has been observed in the hippocampus. The possibility that key learning occurs in the hippocampus will be considered in detail below.\nFor value learning, Tyulmankov et al. (2021) clamp the output layer to the target value v and then update the synapse connecting hidden unit i to output unit m according to:\n\\Delta V_{mi} \\propto \\mu \\gamma_i a_i (v_m - V_{mi}).\n(13)\nThis is a Hebbian rule, because it depends on the co-activation of hidden and output units. It could potentially describe modification of the output projections from the hippocampal area CA1 to entorhinal cortex.\nKozachkov et al. (2023) have proposed a different kind of architecture based on the \u201ctripartite synapse\" consisting of pre-synaptic and post-synaptic neurons modulated by an astrocyte (a type of glial cell). In particular, they posit that this motif applies to the hidden-to-output synapses in the three-layer network implementation of key-value memory. The activation of each astrocyte process is modeled as a linear function of the hidden unit activations. Kozachkov et al. (2023) show how the astrocyte processes collectively compute the similarity function S(K, q), which then multiplicatively modulate the hidden-to-output weights so that the network as a whole implements the transformer self-attention described earlier.\""}, {"title": "Evidence from psychology and neuroscience", "content": "In this section, we review several lines of evidence suggestive of key-value memory in the brain. Our review is organized around the following claims central to the theory:\n1. Memories are stored indelibly but subject to retrieval interference.\n2. Memories are addressed by representations (keys) that are distinct from the representations of memory content (values). The representational structure of the keys is optimized for discriminability, whereas the representational structure of the values is optimized for fidelity.\n3. The information stored in keys is not available to conscious access (i.e., recall). In other words, the brain uses keys to recall values but cannot recall the keys themselves."}, {"title": "Retrieval interference, not erasure, is the principal limiting factor in memory performance", "content": "An important implication of key-value memory systems is that memory performance is constrained primarily by the ability to retrieve relevant information, not by storage capacity. In this section, we review some of the theoretical arguments and empirical evidence that this assumption can be plausibly applied to the brain.\nA number of attempts have been made to estimate the storage capacity of the human brain (summarized in Dudai, 1997). Depending on different assumptions about numbers of neurons and connectivity, estimates can range from 107 to 1015 bits. The total number of bits arriving from sensory systems with minimal compression are estimated to range from 1013 to 1017. These rough numbers suggest that with adequate compression, storage capacity may not be the strongest constraint on memory performance.\nPerhaps more persuasively than these theoretical arguments, we can make the case based on observations about behavior. If memory storage has reached its capacity limit, then it is impossible to store new information without removing some old information. This implies that old information should become permanently inacessible at some point. In contrast, studies of human memory demonstrate that memories can be stored over decades, despite being rarely rehearsed (Bahrick et al., 1975; Bahrick and Hall, 1991; Conway et al., 1991; Maxcey et al., 2021).\nOne might try to explain these findings by arguing that memory storage has not reached the capacity limit, but then it would be very challenging to explain forgetting over the much shorter intervals studied in experiments on list memory. When presented with a list of random words, the proportion of recalled words declines with list length (typically in the range of 5 to 20 items). If this was due to removal of items from memory, then one would expect catastrophic forgetting over intervals of decades. Furthermore, a series of experiments by Shiffrin (1970) demonstrated that, when presented with a sequence of lists and then asked to recall the list before the most recently presented list, performance depended not on the length of the most recent list but only on the length of the list being recalled. This suggests that forgetting is not due to displacement of old items by items from the last list. The limiting factor is retrieval interference from other items on the same list.\nUsing word-location pairs, Berens et al. (2020) separately estimated memory accessibility (whether or not a location is recalled at all given a word cue) and precision (the variance of angular errors). They found that accessibility, but not precision, declined as a function of the retention interval. Similar results have been reported using memory for real-world events (Diamond et al., 2020). Thus, memories do not melt into oblivion, but rather disappear from view. When they come back into view, they are as sharp as they were before they disappeared.\nSupposedly lost memories can be found when appropriate retrieval cues are used (Wagenaar, 1986), when the number of retrieval attempts increases (Buschke, 1974; Roediger and Thorpe, 1978), or even spontaneously after a sufficiently long delay (Payne, 1987). This holds not only for standard memory tasks in healthy subjects but also for retrograde amnesia induced experimentally or by neurological damage. Spontaneous \u201cshrinkage\u201d of amnesia is a common clinical observation following brain trauma (Kapur, 1999), presumably due to the restoration of memory access. In laboratory studies, amnesia can be induced experimentally in a range of ways, such as electroconvulsive shock, hypothermia, protein synthesis inhibition, and lesion or inactivation of the hippocampus, with recovery also induced in a range of ways (Lewis et al., 1968; Riccio and Richardson, 1984; Miller, 2021). For example, protein synthesis inhibition following classical conditioning typically eliminates conditioned responding on long-term memory tests. However, delayed testing sometimes reveals recovery of performance (Flexner et al., 1966; Serota, 1971; Squire and Barondes, 1972). It is even possible to restore performance using the amnestic agent itself (Bradley and Galal, 1988; Briggs and Olson, 2013; Gisquet-Verrier et al., 2015).\nThese observations about amnesia mirror well-known phenomena in classical conditioning. Extinction of a previously conditioned stimulus (i.e., presenting the stimulus in the absence of the unconditioned stimulus) causes a decline in conditioned responding, eventually reaching baseline levels. This decline is transient: conditioned responding can return spontaneously (Pavlov, 1927), or can be induced by a single \u201creminder\u201d of the unconditioned stimulus (Rescorla and Heth, 1975).\nIn summary, considerable evidence suggests that failures of remembering primarily arise from failures of retrieval, typically due to interference from other memories. Memories thought to be lost can later be found under the right conditions. We will explore this idea computationally when we discuss model simulations (Sec. 5.2)."}, {"title": "Distinct representations of keys and values", "content": "The influential \u201cComplementary Learning Systems\u201d framework holds that there is a division of labor between the hippocampus and neocortex (McClelland et al., 1995; O'Reilly and Norman, 2002), with the hippocampus specialized for episodic memory (remembering events that occurred in a specific spatiotemporal context) and a set of neocortical areas (sometimes referred to as \u201cassociation cortex\u201d) that are specialized for semantic memory (remembering regularities that generalize across episodes). This framework has also influenced the design of artificial intelligence systems (Kumaran et al., 2016). In this section, we will argue that this framework can be understood in terms of key-value memory.\nRather than thinking about the hippocampus as directly storing memory content, we can alternatively conceptualize it as storing keys and matching queries to keys, which address memory content stored in neocortex. This view emphasizes the point that episodic memories need to be bound to semantic content\u2014otherwise, they're essentially empty vessels, as in cases of semantic demantia, where degeneration of anterior temporal lobe and prefrontal areas produces profound semantic impairments despite relatively intact recognition memory for recent experiences (Graham et al., 1999).\nIf the hippocampus provides the keys necessary for activating neocortical values, then we would expect a causal interplay between the two. Indeed, there is empirical evidence for the following facts: (i) cortical encoding-related activity is reinstated at the time of memory retrieval; (ii) cortical reinstatement depends on the hippocampus; and (iii) the reinstatement is necessary for memory retrieval (Staresina et al., 2012; Bosch et al., 2014; Tanaka et al., 2014; Danker et al., 2017; Pacheco Estefan et al., 2019; Hebscher et al., 2021).\nAnother line of evidence comes from studies of generalization. In the absence of the hippocampus, neocortical values cannot be accessed in a targeted way, leading to overgeneralization. A study by Winocur et al. (2009) offers a good example. When trained to anticipate a shock in Context A, rats specifically freeze in Context A but not in Context B when tested a day later. When tested a week later, rats show a generalization effect (loss of context specificity), freezing in both contexts. This generalization might arise because of interference from memories acquired during the intervening time. Context specificity can be restored by \u201creminding", "engram cells": "n the hippocampus which are causally linked to specific memories (Liu et al., 2012; Ramirez et al., 2013). Goode et al. (2020) interpret hippocampal engrams as indices (in the sense of Teyler and DiScenna), linking together information stored in a distributed network of neocortical areas.\nSeveral brain-wide engram mapping studies in rodents have reported a collection of neocortical (as well as subcortical) areas that are active during both encoding and retrieval, and therefore qualify as engrams (Vetere et al., 2017; Roy et al., 2022). What makes the hippocampus special is its role as a hub region with high connectivity to neocortical regions (Battaglia et al., 2011). This allows the hippocampus to exert strong control over neocortical regions. In addition, hippocampal engrams are highly sparse (involving a small subset of hippocampal cells) and conjunctively tuned to multiple sensory and cognitive inputs; these features make hippocampal engrams particularly well-suited to encoding episodically unique memories. A recent study of food-caching birds (Chettih et al., 2024) provides a particularly dramatic demonstration: hippocampal ensembles encoded unique representations for over 100 cache sites (including multiple caches at the same location), which were reactivated upon memory retrieval.\nIf hippocampal representations are optimized for discriminating between distinct episodes in a cue-dependent manner, then we should expect changes in these representations under different retrieval demands. For example, overlapping routes in spatial navigation need to be discriminated in order to avoid confusion. Chanales et al. (2017) showed that this situation produces repulsion of hippocampal representations specifically for overlapping locations (see also Wanjia et al., 2021). The repulsion effect emerges gradually over the course of learning, ultimately reversing the objective similarity relations between locations. The strength of the repulsion effect also correlated with behaviorally measured discrimination accuracy.\nNote that optimization for discriminability is only part of the story, since the hippocampus receives noisy inputs which may activate the wrong keys. The hippocampus needs to do some error correction / pattern completion in order to \u201cclean up"}, {"title": "Values, but not keys, are available for recall", "content": "Keys store information which is never overtly recalled. Testing this hypothesis is challenging because it is possible that some information stored in keys is also stored in values. Clear support comes from evidence that there is information used to guide retrieval (putatively stored in keys) which nonetheless is not available for overt recall. More technically, we characterize \u201covert recall\" of a key as the ability to report some aspect of the key vector. The evidence presented below suggests that keys can be matched to queries without making the content of the keys available for report.\nMany of us are familiar with the experience of having a memory at the \u201ctip of the tongue\u201d\u2014stored in memory yet temporarily unrecallable (Brown and McNeill, 1966; Brown, 1991). Closely related is the \u201cfeeling of knowing\u201d\u2014a subjective judgment about the likelihood of subsequently recognizing items which are presently unrecallable. The typical study procedure is to present subjects with difficult general knowledge questions, elicit feelings of knowing for questions they cannot presently answer, and then subsequently test their ability to recognize correct answers to the questions. An important finding from this literature is that feelings of knowing predict (though not perfectly) subsequent recognition (Hart, 1965; Freedman and Landauer, 1966), indicating that people are able to judge whether some piece of information is stored in memory despite not being able to retrieve it. Similar results have been found with cued recall tests (Gruneberg and Monks, 1974). Another clue comes from studies examining response times: Reder (1987) found that people could report answerability for trivia questions faster than they could report the answers, again indicating that metamemory does not require retrieval of memory content. Furthermore, feelings of knowing (but not recall) can be spuriously increased by increasing cue familiarity (Reder and Ritter, 1992; Schwartz and Metcalfe, 1992), possibly due to increased key-query match without increased probability that the correct keys are matched.\nThese phenomena are broadly consistent with the hypothesis that key-query matching can be used to judge whether some information (e.g., the answer to a question) is stored in memory, without accessing the memory content (value) itself. This idea has appeared in the human long-term memory literature under various guises; for example, Koriat and Lieblich (1977) discuss the tip-of-the-tongue phenomenon in terms of \u201cpointers\u201d (cues that specify a memory address without specifying memory content), whereas Morton et al. (1985) use \u201cheadings\u201d to refer to essentially the same idea.\nA pointer system has also been invoked to understand short-term memory: rather than storing transient copies of long-term memories, short-term memory might store pointers which refer to information in long-term memory (Ruchkin et al., 2003; Norris, 2017). This may explain why people can detect changes even when they cannot report what exactly has changed (Ball and Busch, 2015), analogous to the \u201cbutcher on the bus\" phenomenon in long term memory (Mandler, 1980), where people can recognize familiar items without being able to recollect any details about them. Both change detection without identification and familiarity without recollection might be accomplished using keys (pointers) that are content addressable but do not obligatorily activate their associated values (Chandra et al., 2023).\nMany standard models of memory cannot check whether information is stored without retrieving that information at least partially. This is because most models base recognition memory judgments on the match between the cue and stored content; there is no separate representation of keys that can be used to check whether something is stored in memory. This makes it challenging for these models to explain why people can be knowledgeable about what is stored in memory without recalling it.\""}, {"title": "Illustrative simulations", "content": "In this section, we provide two simulations that illustrate some of the distinctive characteristics of key-value models highlighted above. Further implementation details can be found in our public code repository, available at https://github.com/kazuki-irie/kv-memory-brain."}, {"title": "Distinct representations for keys and values", "content": "As we discussed earlier, one of the essential properties of key-value memory is the separate representations allocated for keys and values, which can be optimized for their specific roles in retrieval and storage, respectively. Here we present a toy simulation that illustrates this property.\nWe consider a minimal key-value model whose trainable parameters are a set of pairs of key and value vectors (i.e., in this model, we skip the step of mapping inputs to keys and values, and directly examine the properties of key/value representations). We set both keys and values to be 2-dimensional (2D) vectors which can be easily visualized in the 2D space. The model can take an arbitrary 2D vector as an input which is treated as a query; the query is compared to all the keys through dot product to obtain a similarity score for each key (as in Eq. 5). The resulting scores are normalized by applying the softmax function (Eq. 6) to obtain the final \u201cattention\u201d scores. The output of the model is the weighted average of value vectors using these attention scores (Eq. 2).\nTo train the model, we randomly assign each key/value pair to a class; we test two settings using either two or three classes in total. Each class has a fixed feature vector (representing some specific object or event): in the two-class case, the feature vectors for Class '0' and '1' are vectors (0, 1) and (1,0) in the 2D space, respectively; in the three-class case, we additionally have a third class, Class \u20182\u2032 with (1, 1) as its feature vector. The task of the model is to output the correct class feature vector when one of the keys is fed to the model as input. We apply the sigmoid function to the value vectors to ensure their effective values are between 0 and 1. The key and value vectors are initialized with a uniform distribution between 0 and 1, and our goal is to examine what key and value representations emerge when this key-value model is optimized for this simple retrieval task. We use the mean squared error loss and the gradient descent algorithm, as is commonly used in modern deep learning.\nThe results are shown in Figure 2. We observe that key and value representations effectively exhibit different optimal configurations. The key configuration is optimized for softmax-based discrimination, facilitating effective retrieval: as we can see in Figure 2A, Top row (the two-class case), the two classes take two opposite quadrants (which are highly distinguishable through dot product and softmax). The trend is similar for the three-class case (Figure 2B, Top row). In contrast, the value representations are optimized to represent the class features (i.e., the memory content)."}, {"title": "Forgetting as retrieval failure, and recovery by memory reactivation", "content": "Another distinctive property of the key-value memory we highlighted in Sec. 4.1 is that", "0": "s. '1') and FashionMNIST (\u2018T-shirt' vs. \u2018Trouser')", "transformations": "input-to-hidden, and hidden-to-output mappings with a rectifier linear activation function in-between). The input images are grayscale and their dimension is 28\u00d728; they are flattened to yield a 784-dimensional vector accepted by the input layer. We set the hidden-layer dimension to 64, and the model output size is 4 (for two times two-way classification tasks). The model is trained on the cross-entropy loss using the gradient descent algorithm; by applying the dual formulation described in Sec. 2.3, each linear layer in the model can be formalized as a key-value system keeping memory traces of the entire learning experience by storing layer inputs as keys and error signals as values for every learning step.\nIn this sequential learning setting, we first train the model on Task 1 (MNIST) for 5 epochs, after which the model is trained for another 5 epochs on the training dataset of Task 2 (FashionMNIST) without having access to the Task 1 training data anymore. While such a training process produces a set of weight matrices for neural networks in their conventional form, in the key-value memory view, the final model consists of a sequence of key/value vectors; in this specific scenario of two-task sequential learning, each key/value pair belongs to either Task 1 (MNIST) or Task 2 (FashionMNIST) learning experiences.\nFigure 3A shows the evolution of model performance on the test set of the two tasks as a function of training epochs. We observe that the model achieves ~99% test accuracy on Task 1 (MNIST) in the first 5 epochs corresponding to Task 1 learning, but this performance drops to ~9% after learning Task 2 (FashionMNIST) until the model achieves ~95% test accuracy on Task 2 (we deliberately train the model long enough to observe forgetting). This amnesic phenomenon, reminiscent of catastrophic forgetting in neural networks (McCloskey and Cohen"}]}