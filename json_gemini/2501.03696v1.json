{"title": "Exploring Molecule Generation\nUsing Latent Space Graph Diffusion", "authors": ["Prashanth Pombala", "Gerrit Gro\u00dfmann", "Verena Wolf"], "abstract": "Generating molecular graphs is a challenging task due to their discrete nature\nand the competitive objectives involved. Diffusion models have emerged as\nSOTA approaches in data generation across various modalities. For molecular\ngraphs, graph neural networks (GNNs) as a diffusion backbone have achieved\nimpressive results. Latent space diffusion\u2014where diffusion occurs in a low-\ndimensional space via an autoencoder-has demonstrated computational effi-\nciency. However, the literature on latent space diffusion for molecular graphs\nis scarce, and no commonly accepted best practices exist. In this work, we\nexplore different approaches and hyperparameters, contrasting generative flow\nmodels (denoising diffusion, flow matching, heat dissipation) and architectures\n(GNNs and E(3)-equivariant GNNs). Our experiments reveal a high sensitiv-\nity to the choice of approach and design decisions. Code is made available at\ngithub.com/Prashanth-Pombala/Molecule-Generation-using-Latent-Space-Graph-Diffusion.", "sections": [{"title": "Introduction", "content": "Drug discovery involves identifying molecules capable of interacting with specific molecular targets in\nthe body to treat diseases. Generative AI methods are increasingly employed for molecule generation.\nRecently, the rapid growth in image diffusion models has inspired various approaches for molecule\ngeneration [13, 5]. Each method presents unique strengths and challenges, contributing to a rapidly\nevolving field. However, the growing diversity of techniques and parameters has made it increasingly\nchallenging and time-consuming to identify the most effective approach for a given application.\nWe propose that key factors significantly influencing molecule generation include the choice between\nlatent space and traditional graph diffusion methods, the dimensionality of the latent space, the\nselection of various diffusion processes, and the decision between using Graph Neural Networks\n(GNNs) [12] or E(3)-Equivariant Graph Neural Networks (EGNNs) [11], which maintain equivari-\nance for rotations, translations, and reflections in the Euclidean space. This means that we interpret\nthe input data effectively as a point cloud and process it using pair-wise distances. Additionally, we ex-\nplore alternative diffusion processes, such as heat equation-based diffusion [9] and flow matching [7]."}, {"title": "Related Work", "content": "Diffusion. Denoising Diffusion Probabilistic Models [4], represent a novel approach to generative\nmodeling that employs a diffusion process that gradually degrades the data and then learns to reverse\nthis degradation to generate new data samples. Beyond standard Gaussian diffusion [9] implements\ngenerative modeling using heat equation-based diffusion for images. The work of [7] proposes flow\nmatching for generative modeling of point clouds, showing promising results. This study explores the\npotential of these methods for graph generation tasks and implements them. Latent diffusion models\nperform diffusion in the latent space [10] and advance denoising diffusion models by showcasing\nimproved performance across various aspects of image generation.\nMolecule Generation. Molecule generation using diffusion models has gained significant attention\nin recent years, leading to a diverse array of approaches and methodologies. The seminal paper by [4]\ninspires adaptations of denoising diffusion models to various graph generation tasks. Recent work,\nsuch as [13], adapts latent diffusion models for molecule generation.\nGraph Autoencoding. In [6], the authors discuss graph autoencoders, which encode graph struc-\ntures into a latent space representation and then decode them to reconstruct the original graph. The"}, {"title": "Method", "content": "This section provides an overview of the method used in this work. Appendix A provides detailed\ninformation.\nMolecule Representation. We represent each molecule as a molecular graph, where nodes corre-\nspond to atoms and edges indicate the presence of a covalent bond between two atoms. We label each\nedge to indicate the bond type (single, double, triple, or ring). Additionally, we represent each node\n(atom) with a 4-dimensional vector encoding its element (C, O, N, F) using a one-hot scheme. We let\nn denote the number of nodes. Following standard practice, we do not include hydrogen atoms.\nAutoencoder. We use autoencoders to learn a latent representation of each molecule. The latent\nrepresentation of a molecule is a point cloud composed of the latent representations of its individual\natoms. The encoder learns to map each atom to its latent representation, given the entire molecule\nas context. The decoder then learns to reconstruct the molecular graph from this point cloud using\neither a classical GNN or an EGNN architecture. The encoder and decoder both use the PNA\narchitecture [2].\nEncoder. The encoder generates a z-dimensional latent space embedding for the input molecules\n(i.e., a position when interpreted as a point cloud in latent space; z ranges over 1, 2, 6) for each atom\nusing a 2-layer PNA architecture. The input molecules are represented as described above.\nGNN-Based Decoder. The GNN-based decoder consists of three steps. (1) We convert the point\ncloud of latent embeddings into a complete graph, where the node features depend on the atom\nembeddings (i.e., the locations). (2) We then feed this graph into a 2-layer PNA decoder, which\ntranslates the embeddings into 4-dimensional atom representations. (3) Next, we feed all pairs of atom\nembeddings into an edge prediction layer (a 2-layer MLP), which predicts the presence of an edge\nbetween them based on a threshold. Finally, we predict the bond type (single, double, triple, ring) by\ngiving as input the decoded molecular graph to a 2-layer graph convolutional network model followed\nby a 2-layer MLP. Note that the bond-type predictor deterministically selects a single possible bond\ntype, given the molecular graph and following valency rules.\nEGNN-Based Decoder. The EGNN-based decoder consists of three steps: (1) We construct a\ngraph by introducing dummy nodes to represent edges between each pair of point clouds in the latent\nspace, with features of the dummy nodes based on the pairwise L2 distances of the point cloud latent\nembeddings. (2) We feed this graph into a 2-layer PNA decoder, using the output features of the\ndummy nodes to infer the presence or absence of an edge between two nodes based on a threshold.\n(3) Finally, we predict the bond type using the same method as in the GNN-based decoder."}, {"title": "Flavors of Diffusion", "content": "This section outlines the diffusion processes used in our experiments, following the notation from [1].\nWe refer to the information removal process as degradation rather than noising (or forward process)\nand use restoration to describe the information-adding process via a neural network backbone, rather\nthan denoising (or reverse process). Figure 1 provides an overview of the training and generation\nprocedures.\nThe first process we applied is standard Gaussian-based diffusion [4]. The degradation process\niteratively adds Gaussian noise to the data, gradually pushing it toward an isotropic Gaussian centered\naround zero. In the restoration process, a GNN processes the degraded embeddings and their\ncorresponding timestep as input to predict the restored embeddings. Using these predictions, the\nmodel refines the data by progressively adjusting it toward the restored state. In the generation\nprocess, the model begins with fully noised embeddings sampled from a Gaussian distribution and\nrestores them step-by-step in 50 timesteps until it achieves the fully restored representation.\nFor EGNN diffusion, we used the restoration model defined by [13]. Starting from the fully degraded\nembeddings, the restoration model takes in the degraded embeddings, computes the pairwise distance\nbetween the embeddings, and uses this information to predict the restored embeddings. Using these\npredictions, the model refines the data by progressively moving it toward the restored state.\nThe second process we used is heat dissipation [9], which simulates heat dissipation and then\nreverses it to restore the original data. This method consists of two stages: a degradation process\nthat blurs information and a restoration process that reverses this blurring to recover the data. The\ndegradation process blurs embeddings using the heat equation. First, we transform the embeddings\ninto the frequency domain using the Discrete Cosine Transform. In this domain, we attenuate\nhigh-frequency components by applying a decaying exponential function, simulating the effect of\nheat dissipation. We then transform the blurred embeddings back into the spatial domain using the\nInverse Discrete Cosine Transform. In the restoration process, a GNN reverses the heat equation\nto restore the embeddings. At each timestep, the model takes the blurred embeddings and predicts\nthe difference needed to restore them to a less blurred state, similar to the embeddings from the\nprevious timestep. In the generation process, we start with blurred embeddings derived from the heat\ndissipation mechanism. Using the restoration model, we iteratively refine the embeddings. At each\nstep, we add Gaussian noise. This iterative process continues until the embeddings are fully restored.\nThe third approach, flow matching [7], includes a training phase and a generation phase. In\nthe training phase, we construct a vector field to represent the instantaneous velocity required to\ntransform points from a simple source distribution to a complex target distribution. We construct\nthe vector field by interpolating between the source and target embeddings to estimate the sample's\nposition at any given time. The vector field at each point captures the required velocity to align\nthe interpolated position with the target embedding. The GNN model processes node embeddings\nover a complete graph structure to predict the vector field, representing the instantaneous velocity\nof the transformation. The training objective reduces the discrepancy between the GNN-predicted\nvector field and the defined vector field. In the generation phase, the model maps samples from a\nstandard normal distribution and uses an ODE solver to transform them into the target distribution by\nintegrating the learned vector field."}, {"title": "Results", "content": "All models were trained on the QM9 dataset containing 133,885 molecules with up to nine heavy\n(i.e., non-hydrogen) atoms.\nDuring the sampling process, we generated molecules and calculated their validity, uniqueness,\nand novelty. Validity assesses whether the generated molecules adhere to fundamental chemical\nrules, such as valency and bond structure. Uniqueness measures the diversity within the set of\ngenerated valid molecules, defined as the proportion of distinct molecules relative to the total number\nof generated molecules. Novelty evaluates the number of generated molecules that are new, meaning\nthey do not appear in the training set.\nThe following sections detail the experiments and their results. We randomly selected the number of\nmolecules generated within the range of 100 to 500 and averaged the results for consistency.\nExperiments. In Experiment 1, we applied GNN-based latent space Gaussian graph diffusion,\nwith latent space dimensions of two and six. The model achieved strong validity with moderate\ntraining demands, though it exhibited lower uniqueness. In Experiment 2, we applied EGNN-based\nlatent space Gaussian graph diffusion, with latent space dimensions of two and six. The model\nachieved higher uniqueness but lower validity, requiring significantly more computational resources.\nIn Experiment 3, we used GNN-based Gaussian graph diffusion in the input space, with embedding\ndimensions of two and six. This model was the most resource-intensive. In Experiment 4, we applied\nheat equation-based diffusion in a 1D embedding space. This method produced the highest novelty at\na minimal computational cost but had the lowest uniqueness. In Experiment 5, we used GNN-based\nlatent space flow matching with latent space dimensions of two and six. This model demonstrated\nbalanced performance across all metrics."}, {"title": "Discussion", "content": "We applied the GNN-based latent space Gaussian graph diffusion model across 2D and 6D configu-\nrations. In the 2D configuration, the model achieved high validity, balanced novelty, and moderate\nuniqueness, while training times per epoch stayed relatively efficient. At 6D, validity decreased while\nuniqueness improved, with novelty remaining stable. The minimal increase in training time at this\ndimensionality suggests that higher dimensions introduced a manageable computational cost.\nThe EGNN-based latent space Gaussian graph diffusion model, using the EGNN autoencoder\ndescribed in Section 3 and the EGNN diffusion model described in Section 3.1, achieved high\nuniqueness and novelty but lower validity in the 2D configuration. This model required notably\nmore training time than the GNN-based model, making it more computationally intensive. At 6D,\nuniqueness and novelty remained high, but validity declined further, and training times increased\nconsiderably. This result shows that EGNN-based diffusion generates unique structures but requires\nsignificant computational resources, especially at higher dimensions. Our adaptation of the EGNN to\noperate on edge indices instead of coordinates likely reduced the validity of the generated molecules\ncompared to GNN-based methods.\nThe GNN-based Gaussian graph diffusion model in input space achieved high uniqueness and novelty\nbut lower validity in the 2D configuration, with a substantially longer training time per epoch.\nThis observation indicates that input-space diffusion is highly computationally intensive. In the\n6D configuration, validity improved slightly while uniqueness and novelty declined, with training\ndemands remaining high, underscoring this method's intensive computational requirements.\nThe 1D heat equation-based diffusion model achieved high validity but had lower uniqueness and high\nnovelty. Training time for this model stayed relatively efficient compared to other methods, making\nit computationally light. This approach may be advantageous in scenarios prioritizing validity over\ndiversity, as it generates highly valid but more repetitive molecular structures at a low computational\ncost. Heat equation-based models exhibit high validity because they start with real data, blur the\ndata in the degradation process, and deblur it in the restoration process to generate new molecules.\nStarting with a valid data point instead of random embeddings helps in generating chemically valid\noutputs and conforming to learned structures. However, this approach limits the model's ability to\nproduce highly unique or novel outputs.\nThe GNN-based latent space flow matching model demonstrated balanced performance across all\nmetrics in the 2D configuration, with manageable training times. In the 6D configuration, validity\ndecreased slightly while uniqueness and novelty stayed high, with only a moderate increase in\ncomputational demand. This method achieved a strong balance of structural accuracy and diversity\nwith moderate computational requirements.\nIncreasing latent space dimensions typically reduced validity because added complexity diluted\nthe model's ability to learn. Higher-dimensional spaces also correlated with increased training\ntime, particularly in EGNN and input-space GNN-based models, highlighting greater computational\ninefficiencies in these configurations. These findings suggest that it is feasible to adequately encode\nthe topology of small molecules within two dimensions. Another feature observed with GNN models\nwas that increasing the size of the generated molecules improved uniqueness while maintaining\nvalidity.\nThe observed trade-offs between validity, uniqueness, and novelty emphasize the importance of\nselecting a model based on specific application goals, such as prioritizing structural accuracy or\nmolecular diversity in generated outputs.\nThe work Geometric Latent Diffusion Models for 3D Molecule Generation (GeoLDM) [13] remains\na strong benchmark for assessing diffusion models, given its robust performance metrics. Specifically,\nGeoLDM reports a validity of 93.8% and a combined validity and uniqueness score of 92.7%,\ndemonstrating its ability to generate reliable and unique molecular structures. In comparison, our\nmodels did not achieve the level of combined validity and uniqueness shown by GeoLDM. GeoLDM\nuses atom coordinates as inputs, which provide the model with direct spatial information on the\nmolecular structure. In contrast, we used the edge index as input, which focuses on the connectivity\nproperties of the graph rather than precise spatial coordinates. This choice influences how the models\ninterpret and generate molecular structures. GeoLDM uses a variational autoencoder to encode data\ninto a latent space with built-in probabilistic variability. Our approach, on the other hand, relies"}, {"title": "Conclusion and Future Work", "content": "We identify several open directions for enhancing the molecule generation model and evaluation\nframework. Expanding the metrics beyond validity, uniqueness, and novelty allows for a more\ncomprehensive evaluation of generation quality. While these metrics capture general properties, they\nfail to fully account for factors such as molecular stability, synthetic feasibility, or specific functional\ngroup accuracy, which play a critical role in practical applications in drug discovery and material\nscience. For example, a molecule may be valid and novel but inherently unstable or difficult to\nsynthesize, limiting its real-world utility.\nAdditionally, future work may explore alternative diffusion methods and include them in comparative\nstudies. Future work may also design deeper autoencoder models that maintain low variance in\nembeddings. Another potential direction involves integrating the edge-type prediction process directly\nwithin the decoder rather than using a dedicated model for edge-type prediction. Future work may\nalso increase the dimensionality of our 1D heat equation-based model to assess how this change\nimpacts the results. Appendix A provides additional details about the experiments."}, {"title": "Appendix", "content": "A.1 Method Details\nA.1.1 Autoencoder\nThe autoencoder maps each atom of the input molecular graph into a lower-dimensional latent space,\nperforms diffusion there, and subsequently decodes it to reconstruct the molecule. In this work, we\nutilize a simple autoencoder instead of a variational autoencoder, which is the commonly adopted\napproach in related literature [13].\nThe encoder and decoder consist of 2 layers of PNA. On the decoder side, the PNA decoder takes\nthese latent embeddings and generates a set of features for each node, referred to here as the output\nfeatures. The output features are 4-dimensional.\nThe edge predictor layer then takes these output features and uses them to determine the presence or\nabsence of edges between node pairs. The edge predictor layer consists of a fully connected layer\nwith ReLU activation to predict the existence of bonds in a molecule. We compare the output of the\nedge predictor layer with the input graph to compute the MSE loss function and train the model.\nTo predict the type of bonds in a molecule, we propose a novel architecture that separates bond type\nprediction from edge prediction, resulting in more accurate molecule generation. The edge-type\nprediction model takes the generated molecular graph as input and predicts the bond types for edges\nin the generated molecule. The edge-type prediction model consists of two graph convolutional layers\nwith ReLU activation followed by a fully connected layer to predict the types of edges in a molecule.\nWhile the graph autoencoder encodes information about the graph structure, the atom-type autoen-\ncoder creates embeddings for the atom-type information of each node. The input to this autoencoder is\nthe atom type of all nodes in a molecule, provided in a one-hot encoded format. The encoder converts\nthis input into 2-dimensional atom-type embeddings. The decoder then takes these embeddings and\nreconstructs the one-hot encoded atom types as output. In latent space, the atom-type embeddings are\nconcatenated with the graph embeddings, and diffusion is applied to the combined set of embeddings."}, {"title": "A.1.2 Gaussian Diffusion", "content": "Standard Gaussian diffusion uses Gaussian noise for the degradation process. The degradation process\napplies a linear beta schedule, with start and end values of 0.0001 and 0.02, respectively. We define\nthe linear beta schedule to determine how the noise variance \\( \\beta_t \\) increases linearly over time. We\nalso define the corresponding \\( a_t \\) and its cumulative product \\( \\tilde{a}_t \\) as \\( a_t = 1 - \\beta_t \\) and \\( \\tilde{a}_t = \\prod_{i=1}^{t} a_i \\),\nrespectively. The forward diffusion process is expressed as \\( q(x_t|x_0) = N(x_t; \\sqrt{\\tilde{a}_t}x_0, (1 - \\tilde{a}_t)I) \\),\nwhere we sample the value for \\( x_t \\) as \\( x_t = \\sqrt{\\tilde{a}_t}x_0 + \\sqrt{1 - \\tilde{a}_t}\\epsilon \\), with \\( \\epsilon \\sim N(0, I) \\).\nWe use a 7-layer GNN model to restore the latent features. We use 50 steps to degrade the embeddings\nduring training. At each training step, we select a random timestep and degrade the combined\nembeddings according to the timestep information. The restoration process begins with the noisy data\n\\( x_t \\) and its associated timestep embedding \\( h_t \\). We concatenate these inputs to form the feature vector\n\\( s_t = concat(x_t, h_t) \\), which we pass through the GNN \\( f_\\theta \\). We create a complete graph-based edge\nindex for the embeddings and input it to the GNN/EGNN model to restore the embeddings. From\nthe GNN output, we compute the predicted noise \\( z_\\theta \\) as \\( z_\\theta = f_\\theta(s_t) \\). We compare this predicted\ninformation loss with the actual information loss to generate an MSE loss signal, guiding the model's\ntraining.\nDe Novo Generation. The generation process begins with fully noised embeddings, sampled from\na Gaussian prior distribution \\( x_T \\sim N(0, I) \\); these represent the latent representation at the final\ntimestep T. The model iteratively refines this noisy state, proceeding from \\( t = T \\) to \\( t = 0 \\). At each\ntimestep t, we concatenate the current data state \\( x_t \\) with a normalized timestep embedding \\( h_t = \\frac{t}{T} \\),\nwhich encodes time information. We then pass the resulting combined input to the restoration model.\nThe restoration model predicts the noise added at that stage, \\( z_t \\). Using this prediction, we calculate\nthe posterior mean, \\( \\mu_t \\), as [4]:\n\\( \\mu_t = \\frac{1}{\\sqrt{a_t}} (x_t - \\frac{\\beta_t z_t}{\\sqrt{1 - \\bar{a}_t}}) \\)\nwhere \\( a_t = 1 - \\beta_t \\), \\( \\beta_t \\) represents the noise variance for the current timestep, and \\( \\bar{a}_t = \\prod_{i=t}^T a_i \\) is\nthe cumulative product of \\( a_i \\) over all timesteps. The posterior mean \\( \\mu_t \\) provides the estimate of the\ndenoised data at timestep \\( t - 1 \\).\nWe compute the posterior variance \\( \\sigma_t^2 \\) as:\n\\( \\sigma_t^2 = \\frac{\\beta_t (1 - a_{t-1})}{1 - \\bar{a}_t} \\)\nWe sample the denoised data for the previous timestep as:\n\\( x_{t-1} = \\mu_t + \\sigma_t \\epsilon, \\epsilon \\sim N(0, I) \\).\nAfter the final timestep \\( t = 0 \\), we give the restored latent representation to the decoders of the\nautoencoder and atom autoencoder models, as well as the edge predictor model, to generate the\nmolecule graph."}, {"title": "A.1.3 Heat Dissipation", "content": "In the heat dissipation approach, the heat equation blurs the 1D embeddings after the encoder stage.\nWe first convert the embeddings to the frequency domain using the Discrete Cosine Transform\n(DCT), represented as \\( X = DCT(x) \\), where \\( X \\) contains the DCT coefficients of the embeddings\n\\( x \\). In the frequency domain, the DCT coefficients are attenuated using a decaying exponential\nfunction dependent on the blur's standard deviation \\( \\sigma \\): \\( X' = X \\cdot e^{-(\\frac{\\pi freqs}{\\sigma})^2} \\),\nwhere \\( freqs = \\frac{\\pi}{input\\_size} \\cdot [0, 1, 2, . . ., input\\_size - 1] \\) represents the normalized frequencies. This operation simulates\na blur by attenuating higher frequencies. We then transform the blurred embeddings back into the\nspatial domain using the Inverse Discrete Cosine Transform (IDCT): \\( x' = IDCT(X') \\).\nWe add Gaussian noise with a variance of \\( \\sigma^2 \\) to the blurred embeddings: \\( x_{noisy} = x' + \\epsilon \\), where\n\\( \\epsilon \\sim N(0, \\sigma^2) \\). We train a GNN model to reverse this heat equation-based blurring by predicting\nthe difference needed to restore the embeddings of the previous timestep. The GNN takes in\nthe noisy embeddings \\( x_{noisy} \\) and a complete graph edge index and predicts the difference \\( \\Delta x = f_\\theta (x_{noisy}, edge\\_index) \\), where \\( f_\\theta \\) is the GNN. We compute the restored embeddings as \\( x_{restored} = x_{noisy} + \\Delta x \\). During training, the model minimizes a Mean Squared Error loss by comparing\nthe restored embeddings \\( x_{restored} \\) with the actual embeddings from the previous timestep: \\( L = MSE(x_{less\\_blurred}, x_{restored}) \\). Additionally, since the parameters of the blurring framework are fixed,\nwe added an additional KL Divergence loss term to the standard MSE loss term.\nDe Novo Generation. The generation process begins with the encoding of node features using\na pre-trained autoencoder. The encoder maps the input features into a latent space representation,\nwhich is transformed using an exponential function to ensure positive values. We then blur the\nresulting embeddings using a heat dissipation mechanism described in Section A.1.3. The sample\ncorresponding to a high level of blur is selected as the starting point for the deblurring process.\nThe iterative deblurring phase begins with the blurred embeddings. At each step i, we generate a fully\nconnected graph with self-loops to capture the graph structure, and the current embeddings are passed\nthrough a deblurring model. This model predicts the mean \\( \\mu_{mean} \\) for the previous timestep. Gaussian\nnoise \\( \\epsilon \\sim N(0, I) \\) is added to the mean, and the embeddings are updated as \\( u_{i-1} = \\mu_{mean} + \\epsilon \\cdot \\eta \\),\nwhere \\( \\eta \\) is a small scaling factor that introduces controlled stochasticity. This iterative process\nremoves the blur from the embeddings, progressing toward the unblurred state. After completing\nthe deblurring steps, we give the generated embeddings to the decoders of the autoencoder and atom\nautoencoder models, as well as the edge predictor model, to generate the molecule graph."}, {"title": "A.1.4 Flow Matching", "content": "In the flow matching approach, the architecture leverages Optimal Transport conditional vector fields\nto align source and target distributions. The Optimal Transport framework identifies the most efficient\nway to transform one probability distribution into another by minimizing a transport cost. This\nprinciple is applied in the flow-matching architecture to define continuous flows that interpolate\nbetween the source and target distributions.\nFirstly, the framework constructs a velocity field to represent the instantaneous velocity required to\ntransform the source distribution into the target distribution. We define it as \\( v_t = x_1 - (1 - \\theta_{min}) x_0 \\),\nwhere \\( x_0 \\) is the source embedding, \\( x_1 \\) is the target embedding, and \\( \\theta_{min} \\) is a scaling parameter to\nensure numerical stability.\nNext, we define the interpolation function, referred to as the conditional flow \\( v_t \\), to describe\nthe evolution of points between the source and target embeddings at any time \\( t \\). It is defined\nas \\( v_t(x_0, x_1, t) = (1 - (1 - \\theta_{min})t) x_0 + t x_1 \\). This function smoothly transitions between \\( x_0 \\) and\n\\( x_1 \\) over time, capturing the trajectory of embeddings during the transformation. The interpolation\nfunction provides the path or trajectory for the transformation, while the velocity field \\( v_t \\) determines\nthe instantaneous velocity required to move a sample along this trajectory at any given time \\( t \\).\nA GNN-based model predicts the vector field \\( v_t \\). The GNN processes node embeddings over a\ndynamically created complete graph structure. It comprises an initial graph convolutional layer, 10\nhidden layers with ReLU activations, and an output layer. To capture temporal dynamics, sinusoidal\ntime encoding is incorporated into the model. Additionally, the GNN is augmented with a function"}, {"title": "A.2 Edge-Type Prediction", "content": "The edge-type prediction model takes the molecular graph as input and predicts the bond types\nin the molecular graph using a GNN architecture. The model takes as input the node feature and\nedge index matrix. The GNN processes the node features, producing updated embeddings for each\nnode by aggregating information from its neighbors. To predict bond types, the model constructs\nan edge-level representation for each edge by concatenating the updated embeddings of its two\nconnected nodes. Specifically, for an edge (i, j) in the graph, the edge representation is \\( [x_i || x_j] \\),\nwhere \\( x_i \\) and \\( x_j \\) are the embeddings of nodes i and j, respectively, and || denotes concatenation.\nThese edge representations are processed to produce output logits corresponding to bond types. We\ntrain the model using a cross-entropy loss, minimizing the difference between the predicted bond\ntypes and the ground truth labels."}, {"title": "A.3 Experimental Details", "content": "We trained the model in the Colab environment with an Intel Xeon CPU @ 2.20GHz, featuring 2\nlogical processors and 13 GB of RAM. We loaded the QM9 dataset and converted the SMILES to\ngraphs using the RDKit library. We implemented the autoencoder model with the help of the Python\ntorch geometric library. We trained all models for 20 epochs using an Adam optimizer with a learning\nrate of 0.001.\nWe use the MSE loss function to train the autoencoder and diffusion models. For the PNA encoder,\nwe use mean, minimum, maximum, and standard deviation aggregators. We can use up to four\nlayers of PNA for encoding to increase accuracy. Increasing the number of layers in the encoder\nalso produces embeddings that are very high in value and have high variance. Having embeddings\nwith high variance can be disadvantageous while training diffusion models; hence, we used only two\nlayers of the PNA encoder and decoder while training the autoencoder. The accuracy achieved by the\n2-layer PNA autoencoder was nearly identical to that of the four-layer PNA autoencoder.\nThe edge classifier in our model uses a neural network architecture. It consists of two fully connected\nlayers, with hidden dimensions of 32 and a ReLU activation function to introduce non-linearity. The\nedge-type prediction model comprises two graph convolutional layers and a multi-layer perceptron\nfor edge type classification."}]}