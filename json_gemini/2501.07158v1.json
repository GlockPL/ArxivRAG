{"title": "Eye Sclera for Fair Face Image Quality Assessment", "authors": ["Wassim Kabbani", "Kiran Raja", "Raghavendra Ramachandra", "Christoph Busch"], "abstract": "Fair operational systems are crucial in gaining and\nmaintaining society's trust in face recognition systems (FRS). FRS\nstart with capturing an image and assessing its quality before\nusing it further for enrollment or verification. Fair Face Image\nQuality Assessment (FIQA) schemes therefore become equally\nimportant in the context of fair FRS. This work examines the\nsclera as a quality assessment region for obtaining a fair FIQA.\nThe sclera region is agnostic to demographic variations and skin\ncolour for assessing the quality of a face image. We analyze\nthree skin tone related ISO/IEC face image quality assessment\nmeasures and assess the sclera region as an alternative area for\nassessing FIQ. Our analysis of the face dataset of individuals from\ndifferent demographic groups representing different skin tones\nindicates sclera as an alternative to measure dynamic range, over-\nand under-exposure of face using sclera region alone. The sclera\nregion being agnostic to skin tone, i.e., demographic factors,\nprovides equal utility as a fair FIQA as shown by our Error-\nvs-Discard Characteristic (EDC) curve analysis.", "sections": [{"title": "I. INTRODUCTION", "content": "The quality of face images presented to a face recognition\nsystem (FRS) heavily influences its performance [31]. Thus,\nit is important to control face image quality before enrolment\nof reference samples and before the verification attempt. Face\nImage Quality Assessment (FIQA) is a process that measures\nthe quality of a face image in terms of its utility for face\nrecognition. The NIST FRVT report [9] states \"With good\nquality portrait photos, the most accurate algorithms will find\nmatching entries, when present, in galleries containing 12\nmillion individuals, with rank one miss rates of approaching\n0.1%\". A face image quality score can be an overall unified\nquality score that does not necessarily depend on specific fea-\ntures of the image explicitly or individual quality components\nthat assess a particular aspect of the face image independently\nfrom others.\nA good FIQA is expected to be robust against multiple vari-\nations in the images they process including the consideration\nto demographic variations [16].\nFIQA algorithms depend on analyzing a face image to\nextract features and measure certain aspects of the image. They\nshould be robust to numerous variations in the input images,\nherein demographic variations. For instance, in a recent report\nby Amnesty International [14], it is reported that \"Facial\nrecognition systems misidentify Black faces at a high rate.\nFacial recognition is less accurate in identifying people with\ndarker skin tones-especially women\u201d. The ISO/IEC CD3\non 29794-5 standard [16] states that \"A face image quality\nassessment algorithm should be insensitive to demographic\nfactors such as age, skin-tone or ethnicity\". For instance,\ngiven the two subjects in Figure 1 with two different skin\ntones, we would expect a FIQA algorithm that is assessing\nthe illumination conditions, exposure, or natural color, to\ngive relatively similar results given the images were taken\nunder the same photo session setup made according to the\nICAO requirements formulated in ISO/IEC 39794-5 in Annex\nD.1 [15]. Thus, when developing facial biometric systems or\nFIQA methods, rigorous testing should be performed to make\nsure the algorithms are robust to demographic differences to\nuncover any major differences in performance.\nFace image quality component measures in ISO/IEC 39794-\n5 such as dynamic range, over- and under-exposure are mea-\nsured on the skin of the face. These measures should be\ncarefully designed to take into consideration variations in skin\ntones, and should not make assumptions about the true skin\ntone of the subject as estimating the true skin tone from\nan image is not a reliable process [13]. In 2021, Howard\net al. [13] presented a study that explores the relationship\nbetween measured skin tone estimates from face images,\nand ground-truth skin readings collected using a colormeter\ndevice specifically designed to measure human skin. The study\nestablished that skin tones estimated from different images of\nthe same subject varied significantly from the ground-truth\nskin tone values. The study also showed that estimated skin\ntone measures as part of a face recognition application lead\nto erroneous results depending on algorithms measuring some\nskin tone features across different skin tones, even for same\nsubject under different environmental conditions. The analysis\nsuggested that alternative methods that do not rely on the face\nskin should be used to avoid any noisy or biased results [13].\nOne part of the face that has consistent color across all de-\nmographic groups is the sclera of the eye, whose whitish color\nhas been shown to be a general characteristic of the human"}, {"title": "II. RELATED WORKS", "content": "The eye sclera has received attention in the literature pri-\nmarily as a biometric recognition modality, not as a mean for\nface image quality assessment modality. It has been shown that\nsclera recognition, as one of the ocular traits, has high recogni-\ntion accuracy and considerable user acceptance, and while iris\nrecognition is the primary technology in the ocular biometrics\ngroup, sclera recognition, and particularly the vasculature of\nthe sclera, has recently been considered as a complement or\na substitute to iris recognition [26]. The vascular structure in\nthe sclera region is unique for each individual and relatively\nstable over the subject's life time. Early in 2012, Zhou et al.\n[29] proposed to use sclera as a mean for uniquely identifying\nsubjects. They introduce a method for sclera segmentation,\nand design a Gabor wavelet-based sclera pattern enhancement\nmethod to emphasize and binarize the sclera vessel patterns\nwhich are often blurry or have low contrast due to the highly\nreflective nature of the sclera area. They also propose a\nmethod to do feature extraction based on converting the vessel\nstructure to a set of single-pixel wide lines, which are then\nused to create the subject's sclera template. These templates\nare later used for recognition. In 2021, Das et al. [6] propose\na lightweight deep learning model based on UNet architecture\nfor sclera segmentation, an unsupervised methods for vessel\nextraction as well as a gaze detection model. They introduce\nDeepR, a deep model for sclera recognition which compares\ntwo vessel-structure pairs and produces a boolean output on\nwhether they match or not. The proposed methods are trained\nand tested over the MASD dataset consisting of 164 subjects,\nand the best reported results achieve 0.97 Area under the curve\n(AUC) in recognition accuracy.\nFIQA measures are undergoing a standardization process\nin ISO/IEC 29794-5 standard [16], and a reference imple-\nmentation is under development in the Open Source Face\nImage Quality (OFIQ) project which will provide an open-\nsource framework than can be deployed in commercial and\ngovernment applications 2. A FIQA measure can be either an"}, {"title": "III. METHODS", "content": "In this section, we present the details on dataset, pre-\nprocessing and evaluation approaches. Dataset: The dataset\nused for the experiments is the Face Research Lab London\ndataset (FRLL) [7]. The dataset contains 1020 full color\nimages of 1350x1350 pixels for 102 subjects. It contains five\npose variations per subject (frontal, left profile, right profile,\nleft 3 quarter, right 3 quarter) and two expression variations\n(neutral and smiling). We use frontal images of each subject\nin this work to avoid an overlay of impact from strong pose\nvariations on the recognition performance. Further, segmenting\nthe sclera region of both eyes is not possible with the profile\nviews for our analysis.\nTo be able to analyze and evaluate the FIQA algorithms on\ndemographic groups with different skin tones separately, the\ndataset is divided into two subsets. The first subset contains\nsubjects of darker skin tone, we call it D-FRLL, and contains\nin total 17 subjects (9 males, 8 females). The second subset\ncontains subjects of lighter skin tone, we call it L-FRLL, and\ncontains in total 57 subjects (24 males, 33 females). The rest of\nthe subjects were excluded either because they do not strictly\nbelong to either of the groups, or because of the presence of a\nheavy beard for some male subjects. The subjects in each of\nthe subsets were selected based on manual visual inspection.\nThe FRLL is not a balanced dataset in terms of the number\nof subjects in each skin tone category, but it is a good choice\nfor our analysis because the photos are taken in exactly the\nsame photo session setup, with the same lighting, pose and\nexpression conditions, making skin tone the only factor of\nvariation.\nAugmentations: Evaluating the FIQA on D-FRLL and L-\nFRLL will not produce representative results for the algorithms\nas there is not enough variations in dynamic range or exposure.\nThus, to evaluate the FIQA algorithms and to examine differ-\nences in performance between using the face skin vs. using the\nsclera, the two subsets are created with additional images by\nintroducing systematic synthetic variations in dynamic range\nand exposure.\nPreprocessing and skin extraction: After augmentation, all\ndatasets are processed such that the face is detected, aligned,\nand the image is cropped to the face region only. Sample\nand Computation Redistribution for Efficient Face Detection\n(SCRFD) is used as a face detection method [11]. The face\nskin is extracted using the face parsing network 6 standardized"}, {"title": "IV. DYNAMIC RANGE", "content": "The ISO/IEC 39794-5 standard [15] specifies the following\nrequirement with regard to dynamic range. \"The dynamic\nrange of the image should have at least 50% of intensity\nvariation in the face region of the image\".\nThe dynamic range assessment algorithm in this work is\nadapted from ISO/IEC CD3 29794-5 [16] and illustrated in\nAlgorithm 1. Given face skin or sclera RGB data, it uses the\nthe luminance histogram of the input pixels, and computes its\nentropy to produce an assessment value which is then mapped\nto the range of [0-100] using a sigmoid function. Unlike the\nalgorithm described in the ISO/IEC CD3 29794-5 standard,\nwhich takes as input a face image including the eyes and the\neyebrows, and uses $12.5 * H$ as the mapping function, this\none takes as input either the sclera region or the face skin\nwithout eyes, eyebrows, lips, or teeth (if visible). It also uses\na sigmoid mapping function to obtain consistent output values\nacross different type of input."}, {"title": "V. UNDER AND OVER EXPOSURE", "content": "The ISO/IEC 39794-5 standard [15] specifies the following\nrequirement with regard to exposure. \"The face portrait shall"}, {"title": "VI. CONCLUSION AND FUTURE WORK", "content": "Face image quality assessment is important for obtaining\nhigh face recognition performance. Face recognition systems,\nas well as FIQA algorithms, should be fair, and perform\nconsistently across different demographic groups. This work\ninvestigated the use of the eye sclera as an alternative to face\nskin for assessing some quality components of a face image.\nIt examined closely three face image quality components,\nnamely, dynamic range, over- and under exposure, and im-\nplemented corresponding quality assessment algorithms. The\nalgorithms are adapted from ISO/IEC CD3 29394-5 and have\nbeen adjusted to work with the face skin and sclera data. The\nevaluation results show that the eye sclera has very similar\npredictive capacity in assessing the quality of a face image\nwith compared to the face skin. Thus, it can be used as a\nsupplementary or an alternative method for a fully skin tone\nagnostic mechanism for assessing these quality factors to make\nsure that no bias is present in the assessment.\nFuture work can look at extending this approach to other\nquality components and examine whether the eye sclera has\nthe same predictive capacity as the face skin with regard to\nother aspects of the face image."}]}