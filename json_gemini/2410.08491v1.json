{"title": "A Systematic Review of Edge Case Detection in Automated Driving:\nMethods, Challenges and Future Directions", "authors": ["Saeed Rahmani", "Sabine Rieder", "Erwin de Gelder", "Marcel Sonntag", "Jorge Lorente Mallada", "Sytze Kalisvaart", "Vahid Hashemi", "Simeon C. Calvert"], "abstract": "The rapid development of automated vehicles (AVs)\npromises to revolutionize transportation by enhancing safety and\nefficiency. However, ensuring their reliability in diverse real-\nworld conditions remains a significant challenge, particularly due\nto rare and unexpected situations known as edge cases. Although\nnumerous approaches exist for detecting edge cases, there is\na notable lack of a comprehensive survey that systematically\nreviews these techniques. This paper fills this gap by presenting\na practical, hierarchical review and systematic classification of edge\ncase detection and assessment methodologies. Our classification is\nstructured on two levels: first, categorizing detection approaches\naccording to AV modules, including perception-related and\ntrajectory-related edge cases; and second, based on underlying\nmethodologies and theories guiding these techniques. We extend\nthis taxonomy by introducing a new class called \"knowledge-\ndriven\" approaches, which is largely overlooked in the literature.\nAdditionally, we review the techniques and metrics for the evalu-\nation of edge case detection methods and identified edge cases. To\nour knowledge, this is the first survey to comprehensively cover\nedge case detection methods across all AV subsystems, discuss\nknowledge-driven edge cases, and explore evaluation techniques\nfor detection methods. This structured and multi-faceted analysis\naims to facilitate targeted research and modular testing of AVs.\nMoreover, by identifying the strengths and weaknesses of various\napproaches and discussing the challenges and future directions,\nthis survey intends to assist AV developers, researchers, and\npolicymakers in enhancing the safety and reliability of automated\ndriving (AD) systems through effective edge case detection.", "sections": [{"title": "I. INTRODUCTION", "content": "Automated vehicles (AVs) have seen significant progress\ntowards deployment readiness in recent years. Despite the\npromising potential, significant challenges, particularly those\nassociated with their rigorous testing and validation, have\nhindered their widespread adoption. The validation process for\nAV systems is complex, involving not only technical trials in\ncontrolled environments but also extensive on-road testing in\na wide variety of road and weather conditions. This includes\naddressing ethical and legal considerations, such as decision-\nmaking in critical and unexpected situations and liability in\nthe event of accidents [1], [2]. Given the countless scenarios\nthat AVs may encounter, it is impractical to conduct physical\ntests for every possible situation. This limitation highlights the\ncritical role of \"edge cases\" in AV development. Edge cases\nare unusual or extreme scenarios that significantly deviate from\nnormal driving conditions, which can potentially challenge au-\ntomated driving functions. While often rare, these cases occur\nfrequently enough to demand specific design attention [3].\nExamples include extreme weather events, unexpected object\nbehaviors, and sudden animal crossings.\nEdge cases are crucial in the development and testing of AVs\nfor several key reasons. First, they often represent the bound-\nary between routine operations and potential failure modes\nthat can lead to accidents or unsafe driving behavior. While\nAVs are trained on massive datasets, these trainings usually\nfocus on \"common\" driving situations as these scenarios are\nprevalent in the training datasets. Specifically testing for edge\ncases improves their ability to handle the full spectrum of real-\nworld driving conditions.\nSecond, regulatory bodies and standardization organizations\nare increasingly setting safety standards for AVs, requiring\nthem to demonstrate competence in handling diverse scenarios.\nTesting for edge cases helps developers comply with such\nregulations. ISO 21448, the safety of the intended functionality\n(SOTIF) [4], is one such standard focusing on safety assurance\nfor automated driving (AD) functions. It aims to reduce\nunknown hazardous scenarios by identifying \"triggering con-\nditions\" that can initiate hazardous behavior. Edge cases can\nbe regarded as examples of these triggering conditions, playing\na crucial role in achieving safe AD function behavior.\nThird, public acceptance of AVs heavily relies on their\nability to handle unforeseen circumstances. Demonstrating that\nthese vehicles can navigate complex and unexpected situations\nbuilds public trust in their capability, ultimately fostering wider\nadoption of AD technology.\nFinally, by constantly challenging AVs with new edge cases\nand challenging scenarios, developers push the boundaries of"}, {"title": "A. Related Surveys", "content": "In general, current surveys studying edge cases in automated\ndriving can be categorized into two main groups: those fo-\ncusing on perception-related edge cases and those aiming to\naddress safety-critical scenarios, which can be considered a\nsubset of trajectory-related edge cases.\nWithin the first group of surveys, Breitenstein et al. [5]\ncategorized perception-related edge cases based on their com-\nplexity, ranging from pixel-level issues (e.g., dead pixels or dirt\non the windshield) to scenario-level anomalies (e.g., unusual\nenvironmental conditions). In another work, Heidecker et al.\n[6] categorized the perception-related edge cases based on\nsensor types. While these studies provide valuable taxonomies,\nthey mainly focus on categorizing perception-related edge\ncases themselves, without comprehensively investigating their\ndetection and assessment methods. Moreover, they do not\ncover other types of edge cases than perception-related ones.\nShifting the focus to trajectory-related edge cases, Wang\net al. [8] reviewed safety surrogate measures and their ap-\nplications in evaluating AV safety. However, apart from their\nlimited focus on a specific type of edge cases, they did not\nexplicitly address detection methods or processes for identify-\ning related edge cases. Zhang et al. [9] discussed methods for\nidentifying safety-critical scenarios and provided an overview\nof verification and validation approaches. However, their study\nwas limited to safety-relevant cases, not covering all types of\nedge cases.\nThe only study that partially covers both perception-related\nand trajectory-related edge cases is the work of Bogdoll et\nal. [7]. They reviewed anomaly detection methods in the\nAV domain, categorizing anomalies into camera, lidar, radar,\nmultimodal, and object-level classes. They discussed methods\napplicable to these anomaly classes but the main focus of their\nsurvey was again on perception-related anomalies, with only\na brief review of some examples of trajectory-related cases.\nMoreover, their survey was limited to anomalies and did not\ncover other types of edge cases or their detection methods.\nTo summarize, previous studies have primarily focused on\nspecific types of edge cases, such as perception-related anoma-\nlies or trajectory-based critical scenarios. They also lack a\nconsistent mapping of detection methods to different types\nof edge cases and their assessment techniques and metrics.\nOur survey distinguishes itself by comprehensively reviewing\nand categorizing various classes of edge cases based on their"}, {"title": "II. PRELIMINARIES", "content": "In this section, an overview of important definitions and\npreliminaries for understanding the term \"edge case\" and\nrelated notions in the context of AD is presented."}, {"title": "A. Automated Driving", "content": "Automated driving (AD) refers to the technological capa-\nbilities that allow a vehicle to operate without direct human\ninput. These functions cover a wide spectrum, from basic\ndriving assistance features to fully autonomous driving [10].\nEach AD function is defined by its specific operational design\ndomain (ODD). An ODD refers to the specific conditions\nunder which a given AD system is designed to function.\nAlthough novel situations and edge cases can happen even\nwithin a well-specified ODD, the identification of such cases\nbecomes paramount when the aim is to extend the ODD of\nan AD system. This importance stems from the broadening\ndiversity of situations in which AD functions must operate\nand the increasing complexity and number of sensors and\nalgorithms in the vehicle. Therefore, it is important to consider\nthe ODD of AD systems, as well as their operating subsystems\nand modules when developing and adopting methods for\naddressing edge cases."}, {"title": "B. Definition of Edge Cases", "content": "The term edge case has been used in various fields, and\nthere have been different definitions for it in the literature [3].\nIn the context of AD, \"edge cases\" have been mainly used\nfor safety testing and validation, but there is no unified and\nconsistent definition for the term \"edge case.\u201d Koopman et al.\n[11] define an edge case as \u201ca rare situation that will occur only\noccasionally but still needs specific design attention to be dealt\nwith in a reasonable and safe way. The quantification of 'rare'\nis relative, and generally refers to situations or conditions\nthat will occur often enough in a full-scale deployed fleet to\nbe a problem but have not been captured in the design or\nrequirements process.\u201d Koopman et al. [11] acknowledge that\n\"the process of identifying and handling edge cases makes\nthem - by definition no longer edge cases. So in practice,\nthe term applies to situations that would not have otherwise\nbeen handled had special attempts not been made to identify\nthem during the design and validation process.\u201d\nVater et al. [3] took a systematic approach and reviewed dif-\nferent definitions of edge cases in the literature. They expanded\non the Koopman et al. [11]'s definition by introducing two key\nterms novel and boundary case:", "novel": "r\n'rare' situation that still needs specific design attention to be\ndealt with in a reasonable and safe way, as it is a 'boundary\ncase' of one parameter for the system. The quantification of\nrare is relative and generally refers to situations or conditions\nthat will occur often enough in a full-scale deployed fleet to\nbe a problem [3].\u201d\nThe term novel is added to account for new additions to\ndriving environments (which are not necessarily \u201crare\u201d). For\ninstance, the introduction of a new mobility mean (such as\ne-scooters) could be considered an edge case at the time of\nintroduction. The term boundary case is added to clearly\ndistinguish an edge case from a corner case. Vater et al.\n[3] propose that an edge case is a boundary case of one\nparameter, while corner cases refer to situations where the\ncombination of normal operational parameters may lead to a\nrare situation. Despite this distinction, this study encompasses\nresearch on both edge case and corner case detection due to\ntheir frequent interchangeable use in the literature and their\nshared importance in identifying challenging scenarios for\nautomated driving systems. It is worth noting that in some\nstudies, the term", "anomaly": "s used as an alternative word for", "case,": "ut this terminology is not accurate as anomalies\nare only a subset of edge cases and refer to instances or\noccurrences that deviate significantly from the expected values\nof a variable or parameter."}, {"title": "C. Taxonomies of Edge Cases and Identification Methods", "content": "The classification of edge cases and their detection methods\ncan be approached from multiple angles, reflecting the diverse\nnature of challenges faced in developing robust and reliable\nAD systems. This section delves into different classifications\nof edge cases and their detection methods, breaking them\ndown into fundamental categories, which is necessary for\nunderstanding edge case detection methods.\n1) Detection vs. Generation: Edge cases can be achieved\nor identified through two main approaches: detection and\ngeneration. The former method aims to identify the edge cases\nduring the analysis of existing datasets and usually represents\nunusual or infrequent patterns in the data. In contrast, gener-\nated edge cases are created through simulations or synthetic\ndata generation techniques to anticipate rare conditions not\npresent in the training data. This can be done either by\nusing expert knowledge or advanced generative and learning-\nbased methods. In this survey, we use the term edge case\n\"identification\" to cover both methods.\n2) Data-driven vs. Knowledge-driven: From another per-\nspective, edge cases can be classified as data-driven or\nknowledge-driven ones. Data-driven edge cases are identified\nthrough the analysis of large datasets, leveraging statistical\nmethods or machine learning algorithms to detect anomalies\nand unexpected patterns. Knowledge-driven edge cases are\nmanaged by integrating expert knowledge and predefined rules\ninto the system. This approach relies on the understanding and\nanticipation of potential problems based on domain expertise,\nhistorical precedents, and theoretical models. It emphasizes\na proactive stance where systems are equipped with the\nnecessary logic to handle known edge cases even before they\nare encountered. These two approaches offer a supplementary\nstrategy for tackling edge cases.\n3) Online vs. Offline Detection: Edge case detection and\nmanagement can be applied online or offline. Online methods\nare characterized by their real-time nature, constantly analyz-\ning the collected data and identifying edge cases as the system\nnavigates an environment. This allows for a swift detection\nand response to mitigate or address the edge cases before\nthey escalate into more severe issues. Additionally, online\nmethods can help avoid collecting large amounts of common\nscenario data, instead focusing on detecting and capturing only\ninteresting or unusual scenarios, thereby streamlining the data\ncollection process.\nIn contrast, offline methods involve the detection of edge\ncases from historical data, simulations, or controlled exper-\niments conducted outside of the system's live operational\ncontext. This approach allows for a more thorough and detailed\nexamination of the data, enabling the identification of subtler\npatterns or anomalies that might not be apparent in real-time\nanalysis. Offline methods provide the opportunity to refine and\noptimize algorithms more thoroughly based on comprehensive\ninsights gained from the data.\n4) Root Causes and System Effects: Edge cases can be\nstudied based on their roots in or their effects on different\nmodules of an AV, including perception, decision-making and\nplanning, and control (also referred to as sensing, thinking,\nand acting [12]). This perspective is important as addressing"}, {"title": "D. A Hierarchical Approach to Edge Case classification", "content": "The multi-faceted variety of perspectives on edge cases\nunderscores the complexity of identifying and addressing them\nand highlights the need for a systematic, yet practical, classi-\nfication of edge cases and their detection methods. To achieve\nthis, this work adopts a hierarchical approach to categorize\nthe edge cases and their corresponding detection methods. Our\nclassification system is structured on two primary levels.\nThe first level adopts a practical perspective by categorizing\nedge case detection methods according to different AV mod-\nules. We distinguish between perception-related edge cases\nand trajectory-related edge cases (encompassing planning,\ndecision-making, and control). These two classes of methods\nfall under the umbrella of data-driven methods. Next, we\nintroduce a new category of edge case detection methods\ncalled \"knowledge-driven\" methods, which primarily focus\non the identification process rather than the edge case type.\nUnlike data-driven approaches, these methods primarily lever-\nage expert insights, potentially complemented by data analysis\nwhen available. knowledge-driven approaches can complement\nand encompass both trajectory-related and perception-related\ncases, offering insights that may not be apparent from data-\ndriven methods alone, and potentially identifying edge cases\nthat have not yet been observed in collected data.\nIn the second level, we further classify the identification\nmethods based on their underlying methodological approaches,\nsuch as generative techniques, confidence scores, feature\nextraction, surrogate measures, probability estimation, and\nmachine learning approaches. This dual-level classification\nenables a more structured analysis and understanding of the\ndiverse nature of edge cases, facilitates targeted research and\ndevelopment efforts, and supports the development of modular\ntesting and validation frameworks. Furthermore, the classifica-\ntion of identification techniques based on their methodological\napproaches allows us to identify the strengths and weaknesses\nof applying certain methods to specific edge case types."}, {"title": "III. PERCEPTION-RELATED EDGE CASES", "content": "Perception is key to an AV's functionality, providing es-\nsential environmental understanding that guides its decision-\nmaking and planning. Perception systems process the data"}, {"title": "A. Reconstructive and Generative Methods", "content": "Reconstructive and generative methods have emerged as\npromising strategies for detecting edge cases in AV percep-\ntion systems. Reconstructive methods analyze and rebuild the\nsensor data or images to identify anomalies or unexpected\nscenarios that do not match the trained data. In other words,\nthe idea of reconstructive methods is that recreating an image\ncontaining an anomaly leads to a higher reconstruction error.\nThese methods often use techniques such as autoencoders to\nreconstruct inputs and measure deviations from the original\ndata [55", "56": "flagging significant differences as potential\nedge cases.\nGenerative methods, on the other hand, create new data\ninstances that mimic realistic yet previously unseen driving\nscenarios. These methods often involve generating new data\nand using a discriminator to evaluate deviations from expected\ndistributions, indicating potential edge cases [57", "5": ".", "16": "and Lis et al. [23", "20": "extended this concept\nby adding a synthesis network between the segmentation\nand anomaly prediction steps to improve anomaly detection\nwithout compromising segmentation accuracy.\nAutoencoders are another popular technique in reconstruc-\ntive approaches. Cai and Koutsoukos [17"}]}