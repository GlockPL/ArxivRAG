{"title": "SUGAR: Leveraging Contextual Confidence for Smarter Retrieval", "authors": ["Hanna Zubkova", "Ji-Hoon Park", "Seong-Whan Lee"], "abstract": "Bearing in mind the limited parametric knowledge of Large Language Models (LLMs), retrieval-augmented generation (RAG) which supplies them with the relevant external knowledge has served as an approach to mitigate the issue of hallucinations to a certain extent. However, uniformly retrieving supporting context makes response generation source-inefficient, as triggering the retriever is not always necessary, or even inaccurate, when a model gets distracted by noisy retrieved content and produces an unhelpful answer. Motivated by these issues, we introduce Semantic Uncertainty Guided Adaptive Retrieval (SUGAR), where we leverage context-based entropy to actively decide whether to retrieve and to further determine between single-step and multi-step retrieval. Our empirical results show that selective retrieval guided by semantic uncertainty estimation improves the performance across diverse question answering tasks, as well as achieves a more efficient inference.", "sections": [{"title": "I. INTRODUCTION", "content": "Despite showing impressive performance results [1]-[4], recent state-of-the-art Large Language Models (LLMs) still face challenges in tackling knowledge-intensive tasks like open-domain question answering (QA) [5]. Their generations solely depend on parametric memory of the models, and LLMs lack domain-specific and up-to-date world knowledge, which leads to factual errors in solving QA tasks. Recently, retrieval-augmented generation (RAG) has become a widely applied approach to address this issue, as it provides LLMs with relevant supporting context from an external source [6]-[9].\nEven though RAG clearly helps with mitigating hallucinations, it has some challenges of its own. Namely, it is obviously not necessary to conduct retrieval for every QA case at hand. RAG does help LLMs generate factually accurate outputs when they lack relevant knowledge, but a lot of simpler queries can be answered with just the parametric knowledge of the model, so naively retrieving for every iteration makes inference inefficient [10]. Moreover, the retrieved results sometimes contain documents that are irrelevant [11], factually incorrect [12] or even contain harmful information [13]. Recent studies have investigated the knowledge preference between parametric knowledge and external context presented in RAG [14].\nSome works [15]-[22] have shown that LLMs get easily distracted by noisy retrieved documents and generate seemingly plausible, but incorrect outputs, even though the parametric knowledge of the model would have been enough to accurately answer the question, had retrieval not been triggered.\nThe problem of achieving a harmonious synthesis of external and internal knowledge within LLMs has inspired a whole line of RAG research that focuses on the question \"when to retrieve?\". Adaptive RAG [10] dynamically decides whether to retrieve based on class labels that reflect question complexity, Self-RAG [23] uses self-reflection tokens which signal the need for retrieval or confirm the output relevance, support, or completeness. UniWeb [24] retrieves only in the case of small predictive entropy of the output distribution. FLARE [25] retrieves relevant documents if a prediction of the upcoming sentence contains any low-confidence tokens. For complex multi-hop questions, IRCoT [26] has been proposed to iteratively interact with the both LLM and the retriever. However, such uniform multi-step retrieval becomes very resource-intensive or heavily data-dependent, and calculating naive entropy has a major downside unique to the area of natural language processing \u2013 in language generation the same output can be produced in a variety of linguistic forms [27]. So, when calculating predictive entropy without accounting for meaning, different surface forms compete for probability mass, even if they represent the same idea [28]. As a result, models either get confused by variations of the same meaning or, vice versa, exhibit overconfidence when lacking relevant knowledge and generating semantically disperse answers.\nTo address these points, in contrast with previous works and inspired by Kuhn et al. [29], we propose using semantic entropy as the defining metric for whether to conduct retrieval or not. With Semantic Uncertainty Guided Adaptive Retrieval (SUGAR), our intuition is that accounting for linguistic invariances improves the knowledge boundary evaluation of LLMS in general. Therefore, we believe that if provided with external context when models are uncertain of generating their answers, semantic uncertainty would make retrieval more controllable. This would improve the overall quality of QA performance by triggering the retriever only when it is necessary.\nIn summary, our contributions are as follows: (1) We propose SUGAR, an adaptive RAG strategy based on semantic"}, {"title": "II. SUGAR: SEMANTIC UNCERTAINTY GUIDED ADAPTIVE RETRIEVAL", "content": "In this section, we first outline the overall Semantic Uncertainty Guided Adaptive Retrieval (SUGAR) framework in Section 2.1, and then introduce the proposed strategy in detail. Specifically, in Section 2.2, we explain the idea behind Semantic Uncertainty; we then advocate for its adaptation in adaptive retrieval-augmented generation in Section 2.3."}, {"title": "A. Framework overview", "content": "As presented in Figure 1, given a question q, we use semantic entropy to evaluate how uncertain the model is of generating an answer a with respect to q using just its parametric knowledge P. We set a confidence threshold \u03c4, and if the model is confident in its output, it simply proceeds with generating the answer a. However, in the case of exhibiting high semantic uncertainty, we call the retriever. External knowledge D is extracted and used as supporting context to generate the answer a. When conducting retrieval, we propose using the confidence threshold \u03c4 to dynamically decide between single-step and multiple-step retrieval."}, {"title": "B. Semantic Uncertainty", "content": "One of the challenges of using entropy for uncertainty estimation in free-form language generation is that, unlike in other machine learning problems, where outputs are mutually exclusive, in natural language generation we can express the same idea in a variety of syntactic and lexical forms. Regular predictive entropy does not account for this fact, as it is computed based on token-likelihoods. To address this, Kuhn et al. [29] instead propose using semantic entropy,\n\n$SE(x) \\sim -|C|^{-1} \\sum_{i=1}^{|C|}log p(C_i | x)$"}, {"title": "C. Adaptive Retrieval Augmented Generation", "content": "Adequate evaluation of knowledge boundaries in language models is crucial to make retrieval more controllable and efficient. In LLM uncertainty estimation, for black-box models, it has been common to prompt the model itself to judge its own ability [30], but it is infeasible to estimate how truthful and faithful LLMs are when answering questions like \u201cCan you answer this question? It this answer correct?\" On the other hand, logit-based uncertainty estimation methods, even though not applicable to black-box models, essentially seem more reliable as they can be quantified and measured. Such methods, like predictive entropy or semantic entropy, are being actively used in the line of research that focuses on detecting hallucinations in LLMs and eliciting abstention [31].\nIt is important, though, that a model might be highly uncertain between generating something like \u201cShakespeare wrote Romeo and Juliet\" or \"Romeo and Juliet was written by Shakespeare\" token-by-token and therefore exhibit high entropy, as these sequences differ in terms of form, but convey the same idea. Since in knowledge intensive tasks like QA we care about factual accuracy, the lexical form does not really matter as long as the answer is correct. Semantic entropy supports the generation process when the model is confused by subtle lexical variations, and is a clearer indicator of uncertainty when potential answers drastically vary in meaning.\nTo the best of our knowledge, semantic uncertainty estimation methods have not been implemented in the context of information retrieval, so we advocate for its application as a metric for selective retrieval. With SUGAR we aim to dynamically decide when and how often to retrieve based on semantic entropy thresholds. As computing semantic entropy can be applied to any QA dataset, our approach also suggests a broader generalization potential, compared to the previous methods, namely highly task-dependent reflection tokens in Self-RAG (authors intend to simply retrieve more often for all knowledge intensive tasks), and highly data-dependent complexity labels in Adaptive-RAG (there is no annotated data available to properly train a complexity classifier).\nTherefore, we propose to set semantic entropy thresholds that make three uncertainty level intervals with three corresponding retrieval scenarios 'no retrieval' for the lowest semantic entropy (the model is most certain, retrieval is likely unnecessary), 'single-step retrieval' for intermediate levels of semantic entropy (the model is somewhat uncertain, one round of retrieval would help with answer generation), and 'multi-step retrieval' for the highest entropy (the model is highly uncertain, multiple rounds of retrieval would be helpful)."}, {"title": "III. EXPERIMENTS AND RESULTS", "content": "We evaluate the proposed strategy on the classic single-hop open-domain QA datasets: SQuAD [32], Natural Questions [33] and TriviaQA [34]. To evaluate how the method performs on more complex questions, we also use the following multi-hop datasets: HotpotQA [35] and 2WikiMultiHopQA [36]. We use accuracy, F1, and EM to measure effectiveness, and the number of retrieval steps and answering time relative to single-step retrieval to measure efficiency."}, {"title": "B. Baselines", "content": "We use the off-the-shelf version of FLAN-T5-XL [37] for the No Retrieval setting, and the same model augmented with a retriever for Single-step retrieval. We also compare SUGAR to previously proposed Adaptive retrieval strategies: Adaptive Retrieval [5] based on entity popularity, Self-RAG [23] based on reflection tokens, and Adaptive-RAG [10] based on question complexity labels. Additionally, we consider IR-CoT [26], which accesses the retriever and the generator with interleaving Chain-of-Thought reasoning, as the Multi-hop Retrieval baseline. As analyzed in the Adaptive-RAG paper, their method performs well on multi-hop datasets primarily due to the direct integration of the IRCOT strategy, which neither our approach nor other baselines utilize. Thus, for fair comparison on the multi-hop datasets, we exclude Adaptive-RAG. We run our experiments in a one-shot manner with one task demonstration of the \u201cQ: <question> A:\" format."}, {"title": "C. Results", "content": "In SUGAR, we use Llama-2-chat (7B) [38] as the generator and off-the-shelf Contriever-MS MARCO [7] as the retriever. To set the semantic entropy thresholds, we first performed a case study on the datasets to see what levels of semantic entropy the model normally demonstrates when generating answers. We then used cross-validation to determine the thresholds that yield the best performance in terms of effectiveness metrics, we report the case study results in Figure 2."}, {"title": "D. Ablation Study and Analyses", "content": "To further validate the effect of semantic entropy, we additionally compared Llama-2-chat (7B) without retrieval, uniform single-step retrieval, adaptive retrieval based on regular predictive entropy, and adaptive retrieval based on semantic entropy (SUGAR). As mentioned before, datasets naturally vary in complexity, so we observed the average values of predictive and semantic entropy for each dataset we experimented on. Representatively, for TriviaQA, predictive entropy was consistently higher than semantic entropy, while the opposite was the case for SQUAD. To demonstrate both possible scenarios of entropy variations, for the following analysis we decided to compare the performance on these two datasets.\nIn this experiment we set the single-hop SUGAR thresholds to the average values for both datasets (7 = 0.4 for TriviaQA, T = 0.9 for SQuAD) And for fair comparison, for predictive entropy we set two possible thresholds \u2013 average predictive entropy values (\u03c4 = 0.55 for TriviaQA, \u03c4 = 0.7 for SQuAD), and thresholds equal to the ones used for SUGAR (\u03c4 = 0.4 for TriviaQA, \u03c4 = 0.9 for SQuAD). We compare answer accuracy for effectiveness, and for efficiency the number of retrieval steps is averaged over both datasets, we report the ablation study results in Table III.\nSemantic entropy being consistently higher than regular predictive entropy points out the variability in potential answers and suggests the model is being overconfident (lower predictive entropy combined with high lexical variance in potential answers leads to believe model predictions might not be as reliable). In the opposite case when semantic entropy is lower, while the model is less certain about specific outputs, these outputs are semantically consistent and convey the same idea. But notably, for both datasets, we can see that context-sensitive semantic entropy performs much better and stays more efficient than regular predictive entropy, which leads us to believe that not only does semantic entropy help mitigate overconfidence, it also supports robust performance when the model encounters slight lexical form variations."}, {"title": "IV. CONCLUSION", "content": "In this work we proposed Semantic Uncertainty Guided Adaptive Retrieval, which we refer to as SUGAR, to dynamically determine the necessity of retrieving external knowledge in open-domain QA. The main idea of SUGAR is to use semantic entropy to assess if the parametric knowledge is sufficient to answer a question, and retrieve supporting external context if it is not. Semantic entropy is fit for free-form language generation as it estimates LLMs uncertainty over meaning to evaluate its knowledge boundaries. Our results show that SUGAR improves overall accuracy on QA tasks and proves to be an efficient retrieval strategy which allows the combination of using parametric and external knowledge."}]}