{"title": "MULTI-GROUP PROPORTIONAL REPRESENTATION", "authors": ["Alex Oesterling", "Claudio Mayrink Verdun", "Carol Xuan Long", "Alex Glynn", "Lucas Monteiro Paes", "Sajani Vithana", "Martina Cardone", "Flavio P. Calmon"], "abstract": "Image search and retrieval tasks can perpetuate harmful stereotypes, erase cultural identities, and amplify social disparities. Current approaches to mitigate these representational harms balance the number of retrieved items across population groups defined by a small number of (often binary) attributes. However, most existing methods overlook intersectional groups determined by combinations of group attributes, such as gender, race, and ethnicity. We introduce Multi-Group Proportional Representation (MPR), a novel metric that measures representation across intersectional groups. We develop practical methods for estimating MPR, provide theoretical guarantees, and propose optimization algorithms to ensure MPR in retrieval. We demonstrate that existing methods optimizing for equal and proportional representation metrics may fail to promote MPR. Crucially, our work shows that optimizing MPR yields more proportional representation across multiple intersectional groups specified by a rich function class, often with minimal compromise in retrieval accuracy.", "sections": [{"title": "Introduction", "content": "A recognized objective in fair machine learning (ML) is discovering, reporting, and mitigating representational harms [1-3]. Representational harms arise when systems reinforce and perpetuate the marginalization of population groups based on characteristics such as race, socioeconomic status, cultural background, and gender [1, 4-6]. These harms often manifest through the biased portrayal or misrepresentation of these groups, stereotype reinforcement, and erasure of cultural identities [7, 8]. Representational harms have been widely documented in ML systems. For instance, many freely available datasets used in ML are not geo-diverse [9], and generative models can output images that under-represent demographic minorities across gender and racial identities [10-12].\nWe focus on representation in retrieval tasks. Representational harms in retrieval and ranking tasks arise when retrieved items do not accurately reflect the true diversity and proportions present in reality, perpetuating harmful stereotypes and biases [13]. For instance, Kay et al. [2] demonstrated that, in 2015, only 10% of the top 100 results for CEO in Google Image Search were women, despite 28% of CEOs in the US being women, and recent studies [14, 15] have demonstrated that this bias is still present in modern image search engines. Later, Otterbacher et al. [16] showed that the search engine Bing usually produced twice as many men as compared to women when queried with the word \u201cperson\u201d. Finally, [17] systematically studied gender biases in image representations by auditing the four most important image search engines: Google, Bing, Baidu, and Yandex. In particular, among other findings, this study showed that when a qualifier such as \u201cintelligent\u201d is added to the query \u201cperson\u201d, the engines still exhibit a huge gender discrepancy; see also [1, Chapter 7]. When retrieval is based on a search over vector embeddings of images and text, biases in embedding models can propagate to retrieved results, leading to disparate representation of people by demographic groups such as gender or race [18-20], as well as propagating spurious correlations from the dataset more broadly [21] or distorting results due to stereotypes present in the representation [22]. Though correlations between unrelated semantic concepts do not necessarily constitute representational harms, a wealth of research charts undesirable bias in embedding models, including publicly available joint vision-language foundational embedding models such as CLIP [23] used for retrieval."}, {"title": "", "content": "Bias in embeddings can lead to bias in retrieval [24-26]. In fact, recent work by Srinivasan et al. [27] argues that many image retrieval systems lack \u201csocial diversity\u201d as perceived by humans.\nSeveral interventions aim to control gross statistical deviations in group representations in retrieval. A common approach is ensuring equal representation of pre-defined population groups in retrieved items [28, 29]. An alternative goal is proportional representation (PR) [20, 30], where the representation of different groups is approximately equal to reference population statistics. Various interventions have been proposed to achieve equal or proportional representation, including optimizing for diversity in addition to the similarity in retrieval [27, 31], directly selecting the objects retrieved based on balancing known or predicted sensitive attributes [29] and, for vector databases, modifying embeddings directly to remove information about group-defining attributes [18, 20].\nAchieving proportional representation across multiple intersectional groups is challenging, as existing fairness interven-tions typically consider only a small number of pre-defined groups. Ensuring representation across individual groups (e.g., given by gender or race) does not guarantee representation across intersectional groups (e.g., given by gender and race), as demonstrated in Tables 1 and 3. The study of intersectionality and its consequences is rooted in work in law and the social sciences [32\u201334] and has been a well-discussed problem for several decades. In machine learning systems, lack of intersectional representation can contribute to the invisibility of historically marginalized groups determined by multiple axes of identity [35], or their mistreatment through \u201cfairness gerrymandering,\u201d where interventions on fairness for specific groups may harm fairness on intersectional subgroups [36]. However, as the number of group-denoting attributes increases, the number of intersectional groups grows exponentially, quickly surpassing the number of retrieved items and limiting the achievable proportional representation.\nWe propose a metric called Multi-group Proportional Representation (MPR) to quantify the representation of intersec-tional groups in retrieval tasks. MPR measures the worst-case deviation between the average values of a collection of representation statistics computed over retrieved items relative to a reference population whose representation we aim to match. The set of representation statistics is given by a function class $C$, where each function $c \\in C$ maps a retrieved item $x$ to a Real number. For instance, $c(x) \\in \\{-1,1\\}$ may denote binary group membership. In theory, $C$ can be given by bounded complexity function classes, such as linear functions or shallow decision trees. In practice, $C$ are functions defined over item attributes, such as vector embeddings or group-denoting labels, enabling MPR to measure proportional representation across complex, intersectional subgroups. Compared to naively counting the number of retrieved items across a (potentially exponential) number of pre-defined groups, MPR offers a more flexible, scalable, and theoretically grounded metric for multi-group representation in retrieval.\nIn addition to introducing and carefully motivating the MPR metric (Section 2), we make three contributions. First, we show how to compute MPR for several function classes in Section 3. Computing MPR relies on a curated dataset that represents the desired population whose proportional representation we aim to reflect in retrieved items. We derive sample complexity bounds for the size of this curated dataset based on the complexity of the function class $C$. We also demonstrate that MPR can be computed in closed form for certain function classes or with a regression oracle. Second, we propose MAPR, an algorithm that retrieves items from a vector database to maximize their average similarity to a query embedding while satisfying an MPR constraint relative to the curated dataset (Section 4). MAPR achieves this by iteratively calling an oracle that computes MPR violations, yielding both relevant and representative retrieved items. Third, we evaluate MAPR on retrieval tasks using datasets such as CelebA [37], the Occupations dataset [31], Fairface [38], and UTKFace [39]. Our results (Section 5) show that MAPR Pareto-dominates competing approaches in balancing retrieval similarity and MPR.\nRelated Work. Broadly speaking, existing work on fair and diverse retrieval with pretrained embeddings either: 1) modifies the embedding space to prioritize downstream fairness, or 2) provides retrieval algorithms optimizing for diversity or fairness.\nMitigating Bias in Embedding Space. Various approaches have been proposed to produce vector embeddings of text and images that target diversity or mitigate bias. These include modifying loss functions to encourage group fairness [40], adversarial training [41, 42], disentangling representations [43], and in-processing fair sampling methods for gender imbalance [18]. Many foundational embeddings models are not trained with such approaches, so post-processing methods for fairness have also been developed for multimodal models like CLIP [23], such as CLIP-clip [18], CLIP-debias [20], and FairCLIP [19]. The recent work PATHS [27], built upon the pretrained image-text model CoCa, leverages text-guided projections to extract an embedding that captures complex notions of diversity in people, enabling effective diverse retrieval methods. In our experiments, we report the MPR achieved by CLIP-clip and CLIP-debias in retrieval tasks. PATHS [27] is the recent work most similar to ours in that it also aims to promote intersectional representation in retrieval. Code for implementing and reproducing [27] was not available at the time of submission. We approximate its retrieval algorithm with vanilla CLIP embeddings. Unlike the aforementioned methods, MAPR is not based on modifying embeddings."}, {"title": "", "content": "Retrieval Algorithms with Diversity or Fairness. Instead of modifying embeddings, several methods aim to promote diversity, given possibly biased embeddings. For a fixed query, the baseline method for retrieval is k-Nearest-Neighbors (k-NN), where the k most similar items are retrieved [44]. Given an additional diversity constraint, a popular approach is Maximal Marginal Relevance (MMR) [45], where items are greedily retrieved in order to maximize a linear combination of similarity and diversity metrics. Celis et al. [30], Celis and Keswani [31] focus on diversity and fairness in image retrieval, using a reweighing method that combines similarity and MMR to select diverse yet relevant images. Alternatively, the Post-Hoc Bias Mitigation [29] method aims to achieve equal representation over a pre-defined attribute (such as gender) through calls to an oracle classifier and selecting a balanced group of images. We extend this prior work in two key ways: (i) we aim to achieve proportional representation across intersectional groups, going beyond the representation of two groups defined by binary attributes; (ii) MAPR explicitly balances MPR and retrieval similarity via an optimization that controls for both, offering a principled alternative to greedy MMR-based methods.\nDiversity Metrics. A traditional measure of diversity for a set is the pairwise similarity of the retrieved items [46]. However, the general visual (dis)similarity metric is insufficient in optimizing for people-related diversity such as skin tone or gender [30]. When the attribute (e.g., race) along which diversity is optimized is known, fairness definition-derived metrics such as proportional representation are used ([47], see also next section). For more complex notions of diversity that aim to capture intersectional or subtle sociocultural identities (e.g., cultural backgrounds, lifestyles, nationalities, religions), human annotators are employed to determine if the selected set of images is more diverse than the baseline (retrieval based on similarity to query only) [27]. MPR complements existing metrics by providing a rigorous approach to measuring representation across complex, intersectional groups defined by a rich class of functions. However, as with any fairness metric, MPR has limitations (see Section 6) and may not always align with human perceptions of representation. We underscore the importance of involving stakeholders in defining representation goals and auditing retrieval systems.\nMulti-Group Fairness. Our work is directly informed by the burgeoning literature on multi-group fairness in classification, particularly the work of H\u00e9bert-Johnson et al. [48], Kim et al. [49, 50] who proposed rigorous frameworks of multi-group fairness auditing and post-processing to ensure fair predictions across identifiable subgroups. Recent efforts in this field include [51\u201353], which analyze sample complexity aspects of measuring and reporting multi-group representation, and [54, 55] who develop stronger variants of multi-group fairness notions. Unlike prior work, we focus on multi-group representation in retrieval rather than multi-group fairness in classification and regression. Lastly, proportional representation strategies arose in the political sciences literature [56\u201360] we address this body of work in Appendix C."}, {"title": "A Multi-Group Proportional Representation Metric", "content": "Preliminaries. Consider a retrieval dataset of items from which we aim to retrieve relevant entries, denoted by $D_R = \\{x_1, ...,x_n\\}$. We assume that $x_i \\in R^d \\times G$, where $G$ is a set of additional labels for each item. For example, items $x_i$ can be $d$-dimensional embeddings of images, videos, or textual content, in which case $G = \\emptyset$. Alternatively, $x_i = (e_i, g_i)$, where $e_i \\in R^d$ is an embedding and $g_i$ is a vector of labels indicating group membership (e.g., gender, race, ethnicity).\nGiven a query embedding $q \\in R^d$, the goal of retrieval is to search and return the top-$k$ most similar items to $q$ in $D_R$. The similarity between an embedding of $q$ and items in $D_R$ is measured according to a metric $\\kappa : R^d \\times R^d \\rightarrow R$. Throughout the paper, we assume that $D_R$ is a vector database and $\\kappa$ is cosine similarity between embeddings, though this formulation can be generalized. To retrieve items from $D_R$, users prompt a query $q$ (e.g., \"Fortune 500 CEOs\") which is then embedded $R^d$. Ideally, the user receives $k$ retrieved items $R(q) = \\{x_1,...,x_k\\} \\subset D_R$ such that $\\kappa(q, x_i) \\geq \\kappa(q, x)$ for all $x \\notin R(q)$ and $i \\in [k]$.\nThe simplest setting for measuring representation is to consider only two population groups denoted by a binary variable - a setting commonly found in the fair retrieval and generation literature [18, 19]. In this case, group membership is determined by a group-denoting function $c : R^d \\times G \\rightarrow \\{-1,1\\}$. For an item $x$, $c(x)$ indicates membership to group -1 or 1 (e.g., male/female) based on its embedding $e_i$ and associated labels $g_i$. If the retrieval dataset $D_R$ contains annotations for group membership, $c(x)$ can simply return the relevant feature from $g_i$. However, when group labels are not present (i.e., $G = \\emptyset$), $c(x)$ can be implemented as a classifier that predicts group membership based on the item's embedding $e_i$.\nWith a group-denoting function $c(x)$ in hand, we can measure the representation of each group in a set of retrieved items $R(q)$. One popular constraint for representation is equal representation [2, 28], which aims to ensure that the number of retrieved items in each group is approximately the same, i.e., $\\Sigma_{x^i \\in R(q)} c(x^i) \\approx 0$. An alternative metric is proportional representation [20, 61], which quantifies the deviation of group membership from a reference distribution $Q$. Methods that promote proportional representation aim to ensure $\\Sigma_{x^i \\in R(q)} c(x^i) \\approx E_Q [c(X)]$"}, {"title": "", "content": "Here, the measure $Q$ captures the distribution of a reference population whose representation statistics we aim to match. For example, if $Q$ were the distribution of individuals in the United States, $E_Q [c(X)]$ could measure the proportion of men vs. women in the US and be approximated using Census data.\nProportional representation generalizes equal representation since different groups are rarely uniformly distributed over a given population. Naturally, the choice of distribution $Q$ is application and context-dependent \u2013 we revisit the choice of $Q$ below. Importantly, if $Q$ is biased, then biases will be propagated to the retrieved items.\nMulti-Group Proportional Representation. We aim to ensure that retrieved items represent individuals from diverse and intersectional population groups. Instead of measuring proportional representation in terms of the average of a single group-denoting function $c(x)$, we consider a class of Q-measurable functions, the representation statistics class, $C \\subset \\{c : R^d \\times G \\rightarrow R\\}$. This set $C$ may represent multiple, potentially uncountable overlapping groups. We formally define multi-group proportional representation next.\nDefinition 1. For a reference representation distribution $Q$, a set of Q-measurable set of representation statistics $C$, and a set of $k$ retrieved items $R$, we define the multi-group Proportional Representation (MPR) metric as\n$\\qquad MPR(C, R, Q) = \\sup_{c \\in C} {\\Bigg |} \\frac{1}{k} \\sum_{x^i \\in R} c(x^i) - E_Q[c(X)] {\\Bigg |}$.\n\nA set of items $R$ is $(C, \\rho)$-multi-group proportional representative of $Q$ if $MPR(C, R, Q) \\leq \\rho$.\nThe MPR metric quantifies the \u201crepresentativeness\u201d of a rich class of statistics, denoted by functions in $C$, within a set of retrieved items $R$. This generalization is crucial for capturing intersectional groups. For example, $C$ could contain functions that map items to demographic groups based on race, gender, age, or combinations thereof. Alternatively, when labels in $G$ contain such group-denoting attributes, $C$ can represent decision trees of a given depth over features (e.g., all combinations of pairs of race, gender, and age). The MPR metric compares the empirical average of each $c \\in C$ over the retrieved set $R$ to its expectation under the reference distribution $Q$. By defining $Q$ appropriately, we can flexibly specify different statistical representation goals, such as equal representation ($E_Q[c(X)] = 1/2$ for binary $c$) or proportional representation w.r.t. a target population. However, as $C$ grows in complexity, pre-specifying $E_Q[c(X)]$ for all $c \\in C$ becomes infeasible. Instead, MPR can be estimated using a carefully curated dataset, which we define in the next subsection.\nRemark 1. MPR is equivalent to the maximum mean discrepancy (MMD) of representation statistics in $C$ between the empirical distribution over retrieved items $R$ and the reference distribution $Q$. MMD-based metrics have a long history [62, 63] and are used in hypothesis testing for comparing distributions. MMD is a particular case of the Integral Probability Metric (IPM) [64, 65], allowing us to borrow from the rich literature on IPMs to measure and ensure MPR in practice.\nRemark 2. MPR can be viewed as the \u201crepresentation in retrieval\u201d counterpart of multi-group fairness metrics found in classification, such as multiaccuracy [49] and multicalibration [48]. Whereas multiaccuracy and multicalibration measure if classification error residuals are correlated with any group represented within a class $C$, MPR captures proportional representation of groups in $C$ within a set of retrieved items a fundamentally different problem. The idea of representing groups in terms of a \u201ccomputationally identifiable\u201d class of functions $C$ is directly inspired by the multi-group fairness in classification literature, and we adopt similar notation (i.e., $c$ and $C$).\nCurated Datasets for Proportional Representation. A key challenge in computing MPR is selecting the reference representation distribution $Q$ and measuring the expectation of functions in $C$ against this distribution. In the simple case where $C$ consists of a small number of functions indicating membership in individual groups, we could potentially set the proportional representation targets $E_Q[c(X)]$ for each group $c \\in C$ manually, e.g., by defining a target fraction of men/women or individuals from different ethnic backgrounds. This quickly becomes infeasible when there are many intersectional groups \u2013 and impossible if $C$ is uncountable. Moreover, in most practical settings, $Q$ will very likely not have a simple closed-form analytical expression.\nIn practice, i.i.d. samples drawn for $Q$ may be available. For instance, the retrieval dataset $D_R$ itself may be drawn from the target population for which we aim to preserve proportional representation in retrieved items. Alternatively, we may have access to a dataset that was carefully curated to be representative of a diverse population. Examples include the FairFace dataset [38], which was designed to be balanced across race, gender, and age groups, and the AVFS dataset [66]. More generally, we refer to datasets with samples drawn from the target population $Q$ as a curated dataset.\nDefinition 2 (Curated Dataset). Let $Q$ be a probability distribution over $R^d \\times G$ tailored to account for diversity and representation of stakeholders who query the retrieval dataset. The curated dataset with $m$ samples drawn the distribution $Q$ is denoted as $D_c \\approx \\{x_1,...,x_m\\}$. We denote the MPR of a set of retrieved items $R$ relative to the empirical distribution over $D_c$ as $MPR(C, R, D_c)$."}, {"title": "", "content": "The exact nature of the curated dataset $D_c$ is context-dependent and may vary based on the specific application and desired representation goals. We can also condition the curated dataset on a given query. Specifically, for a query $q$, we can retrieve relevant samples from both the curated dataset $D_c$ and the retrieval dataset $D_R$. The samples retrieved from $D_c$ can then serve as a \u201cconditional\u201d curated dataset, denoted as $D_{c|q}$, which captures the desired representation target specific to the query $q$. This approach allows for a more granular and context-aware proportional representation.\nIn the next two sections, we introduce theoretical guarantees and algorithms that are agnostic to the specific choice of $D_c$. In other words, our proposed methods for measuring and promoting MPR in retrieval are general and can be applied regardless of how the curated dataset is constructed. In our numerical experiments (Section 5), we use FairFace [38] as the curated dataset."}, {"title": "Computing Multi-Group Proportional Representation", "content": "Computing MPR in Defnition 1 requires approximating two quantities: the representation distribution $Q$ and the supremum $\\sup_{c \\in C}$. We first establish generalization bounds for approximating $Q$ using i.i.d. samples. We then show how to compute $\\sup_{c \\in C}$ for several classes of representation statistics $C$.\nError in approximation $Q$ via a curated dataset. Proposition 1, proved in Appendix A, bounds the deviation between the empirical MPR computed over the curated dataset $D_c$ drawn i.i.d. from reference distribution $Q$ and the true MPR measured over $Q$.\nProposition 1 (Generalization Gap of MPR). Let $R(q) = \\{x_i\\}_{i=1}^k$ be a set of $k$ retrieved samples, $D_c = \\{x_i\\}_{i=1}^m$ be a curated dataset comprised of $m$ i.i.d. samples from a target representation distribution $Q$, and $\\delta > 0$. If $C = \\{c : R^d \\times G \\rightarrow \\{-1,1\\}\\}$ with Rademacher complexity $R_m(C)$ then, with probability at least $1 - \\delta$,\n$|MPR(C, R, D_c) - MPR(C, R, Q)| \\leq R_m(C) + \\sqrt{\\frac{\\log (2/\\delta)}{8m}}.$\n\nWe can extend Proposition 1 to any set of bounded functions $C$ (see, e.g., bounds on empirical MMD estimates in [63]). Note that the guarantee in (2) only holds for a single set of retrieved items $R$ in response to a query. Proposition 2 provides a bound on the size $m$ of an i.i.d. curated dataset $D_c$ that ensures an $\\epsilon$-accurate estimate of MPR for a set of $M$ queries.\nProposition 2 (Query Budget Guarantee). Consider any set of $M$ queries $Q = \\{q_1, ..., q_M \\}$ where $M \\in \\mathbb{N}$. Let $VC(C)$ denote the VC-dimension of the class $C$ with range in $\\{-1,1\\}$. For $\\epsilon > 0$, if $D_c$ consists of $m$ i.i.d. samples drawn from $Q$ where $m$ satisfies\n$\\qquad m \\geq \\frac{32VC(C)}{\\epsilon^2} \\log(\\frac{2M}{\\delta}) + \\frac{2}{\\epsilon^2} \\log(\\frac{2}{\\delta})$\nthen, with probability at least $1 - \\delta$, $|MPR(C, R, D_c) - MPR(C, R, Q)| \\leq \\epsilon$.\nThe above results provide guidelines on the size of the curated dataset required to accurately estimate MPR relative to a true target representation distribution $Q$. If the class of representation statistics $C$ is very complex (in the VC-dimension sense), then the size $m$ of the curated dataset $D_c$ must be proportionally large to represent $Q$ accurately. Hence, the curation dataset should be designed having in mind (i) the number of diverse queries being asked and (ii) the complexity of the function class $C$. While Proposition 2 provides a conservative bound, as generalization bounds are often not tight [67], these results nevertheless offer insight into the relationship between the complexity of $C$ and the accuracy of MPR estimation.\nIn the remainder of the paper, we assume that MPR is computed against a fixed curated dataset $D_c$ of size $m$. We consider four specific instantiations of the set of representation statistics $C$: (i) $C$ is closed under scalar multiplication, i.e., if $c \\in C$, then $\\lambda c \\in C$ for any $\\lambda \\in R$, (ii) $C$ is a set of functions taking values in $\\{-1, 1\\}$; (iii) $C$ consists of linear functions; and (iv) $C$ consists of functions in a Reproducing Kernel Hilbert Space (RKHS). Next, we show that for cases (i) and (ii) MPR can be computed using calls to an oracle that performs regression over $C$ and, for linear functions (iii), MPR has a simple closed-form expression. Due to its technical nature, we defer the calculation of MPR for functions in an RKHS to Appendix B.2.\nComputing MPR via Mean Square Error (MSE) Minimization. When $C$ is closed under multiplication or consists of binary functions with values -1, 1, MPR can be expressed as an MSE minimization. This enables us to compute MPR by leveraging existing black-box oracles that perform regression under quadratic loss, such as regressors/classifiers implemented in ML libraries like scikit-learn [68]."}, {"title": "", "content": "The key observation for expressing MPR as an MSE minimization is that MPR can be formulated as a maximum correlation problem. Consider the (row-wise) concatenation of the retrieval dataset $D_R$ and the curated dataset $D_c$, given by $X \\approx [x_1, ..., x_n, x_1, ..., x_m]$, where $x_i$ is the $i$-th entry of $X$. For the remainder of this section, we consider a fixed set of retrieved items $R$. Let $a \\in \\{0,1\\}^{n}$ be a vector indicating items that are retrieved from $D_R$ for a given query, i.e., $a_i = 1 \\Leftrightarrow x_i \\in R$. Under this notation, where retrieved items are indicated by the vector $a$, MPR can be reformulated as\n$\\qquad MPR(C, R, D_c) = \\sup_{c \\in C} {\\Bigg |} \\frac{\\sum_{i=1}^n a_i c(x_i)}{k} - \\frac{\\sum_{i=1}^m c(x_i)}{m} {\\Bigg |} = \\sup_{c \\in C} {\\Bigg |} \\sum_{i=1}^{n+m} c(x_i)\\tilde a_i {\\Bigg |},\n\nwhere $\\tilde a \\in R^{n+m}$ has $i$-th entry given by $\\tilde a_i \\overset{\\triangle}{=} \\frac{1}{k} \\text{1}_{i \\leq n} - \\frac{1}{m} \\text{1}_{i>n} \\frac{mk}{m+k}$ and c(X) = [c(x1), ..., c(Xn+m)]. Then\n$\\qquad \\{0 \\leq MPR(C', R, D_c) \\leq 1,$"}, {"title": "Computing MPR for Bounded-Norm Linear Regression", "content": "Recall that each item in the retrieval or curated datasets is of the form $x_i = (e_i, g_i)$, where $e_i$ is an embedding and $g_i$ are labels. When $x_i \\in R^l$ (i.e., the labels have numerical values), we can consider $C$ as a linear set of functions over retrieved items. In this case, MPR enjoys a closed-form expression, as stated in the next proposition.\nProposition 4. Let items in the retrieval and curated datasets be vectors in $R^l$ for $l < m + n$ and $C = \\{x \\rightarrow w^T x \\mid w \\in R^k \\}$. Moreover, let $X \\in [R^{(m+n) \\times l}$ be the matrix formed by concatenating items in the retrieval and curated dataset $D_R$ and $D_c$, respectively. For $C'$ in Proposition 3, we have\n$\\qquad MPR(C', R, D_c) = \\frac{mk}{m+k} ||U_a||_2,$\n\nwhere $X = U\\Sigma V^T$ is the SVD of $X$ and $U_a \\in R^{(m+n) \\times l}$ are the left singular vectors in $U$ corresponding to the top-$l$ largest singular values.\nThe above proposition can be directly adapted to linear functions defined only over embeddings or a subset of features of retrieved items. The closed-form expression for MPR in (9) also allows MPR-constrained retrieval to be computed by a quadratic program, as discussed in Appendix B.1.\nFor analysis of functions in an RKHS, see Appendix B.2"}, {"title": "Promoting Multi-Group Proportional Representation in Retrieval Tasks", "content": "Next, we develop an optimization framework for retrieving the $k$ most similar items in a vector database to a given query $q$ while satisfying a target MPR threshold of $\\rho$. We formulate the retrieval goal as maximizing the average similarity between a query and retrieved items, given by $s_i = \\kappa(x, q)$ (recall Section 2 for notation), where $\\kappa(x, q)$ is given by cosine similarity in our experiments. The problem of maximizing utility in retrieval while satisfying an MPR constraint (expressed as Eq. (4)) can be formulated as the integer program:\n$\\qquad \\max_{a \\in \\{0,1\\}^n} \\sum_{i=1}^n a_i s_i \\qquad \\text{ subject to } \\sup_{c \\in C} {\\Bigg |} \\frac{1}{k} \\sum_{i=1}^n a_i c(x_i) - \\frac{1}{m} \\sum_{i=1}^m c(x_i) {\\Bigg |} \\leq \\rho, \\sum_{i=1}^n a_i = k.$\n\nWhen $C$ is given by normalized linear functions as in Proposition 4, the integer constraints can be relaxed to $a \\in [0, 1]^n$ and the optimization can be approximated via standard quadratic solvers; see Appendix B.1.\nMulti-Group Aware Retrieval. We approximate (10) via the Multi-Group Aware Proportional Retrieval Algorithm (MAPR), described in Algorithm 1. MAPR is essentially a cutting-plane method that aims to find a set of $k$ items that maximize utility while approximately satisfying an MPR constraint of $\\rho$. The algorithm iterates between (i) a call to an oracle that computes MPR and returns a function $c \\in C$ that achieves the supremum in (4) and (ii) a call to a linear program (LP) solver that approximates the top-$k$ most similar items to a query subject to linear constraints on the violation measured by $c$. Each oracle call adds an additional constraint to the LP solver which, in turn, approximates the top-$k$ items under an increasing set of constraints. The solution of the LP is rounded to satisfy the integer constraint $a \\in \\{0,1\\}^n$. In our implementation, we assume that MPR can be computed via MSE minimization (cf. Section 3) in which case we consider the normalized class $C'$. The oracle call consists of running a black-box quadratic loss minimization over $C$.\nInterestingly, we observe that, despite relaxing the integer constraints in each LP call, the solution to the relaxed problem is very sparse and (after rounding) approximates well the solution of the ideal integer program (10) for moderate values of $\\rho$. However, the method can fail to accurately approximate the IP solution when $\\rho$ is small. We present a more detailed analysis of MAPR in Appendix B, which discusses potential convergence issues with the cutting plane method as well as stopping conditions."}, {"title": "Numerical Experiments", "content": "In this section, we show that MAPR is effective in promoting more proportional representation across intersectional groups while preserving similarity between retrieved items and a given query. Notably, MAPR Pareto-dominates competing benchmarks in terms of achieved MPR gap and utility.\nDatasets. We conduct retrieval over three image datasets of faces: CelebA [37], which includes labels for gender, age, and various other attributes, UTKFace [39], which contains gender, age, and race attributes, and Occupations [2], which contains gender attributes. We compute MPR using FairFace [38] as the curated dataset $D_c$, since it is a carefully designed dataset of faces with subgroup attributes for race, gender, and age. In all cases, each dataset entry consists of an image (CLIP) embedding $e_i$ and a set of labels $g_i$.\nBenchmarks. We compare our method with four baselines. DebiasClip [20] modifies text queries with a prepended learned embedding for debiased retrieval but does not allow for tunable control of the representation-similarity trade-off,"}, {"title": "Concluding Remarks and Limitations", "content": "In this work, we introduced a novel retrieval metric called Multi-group Proportional Representation (MPR) and developed algorithms to ensure MPR in retrieval tasks. By measuring deviations in a set of representation statistics, MPR provides a scalable approach to quantifying and enforcing proportional representation for complex, intersectional groups. We analyzed the generalization properties and realizable regimes of MPR and, through experiments in image retrieval, demonstrated its favorable utility-fairness trade-off compared to existing fair retrieval algorithms."}, {"title": "Acknowledgements", "content": "The authors would like to thank the discussions with Filipe Goulart Cabral. This material is based upon work supported by the National Science Foundation under awards CAREER-1845852, CIF-1900750, CIF-2231707, and CIF-2312667, FAI-2040880, and also by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-2140743. The views expressed here are those of the authors and do not reflect the official policy or position of the funding agencies."}, {"title": "Experiment Notes", "content": "E.1 GPT Generated Queries.\nThe 10 queries used in experiments and generated by GPT are as follows: [programmer, nurse, architect, scientist, artist, chef, lawyer, teacher, engineer, doctor"}]}