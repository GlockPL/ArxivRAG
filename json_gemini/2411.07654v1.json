{"title": "Spike Talk in Power Electronic Grids - Leveraging Post Moore's Computing Laws", "authors": ["Yubo Song", "Subham Sahoo"], "abstract": "Emerging distributed generation demands highly reliable and resilient coordinating control in microgrids. To improve on these aspects, spiking neural network is leveraged, as a grid-edge intelligence tool to establish a talkative infrastructure, Spike Talk, expediting coordination in next-generation microgrids without the need of communication at all. This paper unravels the physics behind Spike Talk from the perspective of its distributed infrastructure, which aims to address the Von Neumann Bottleneck. Relying on inferring information via power flows in tie lines, Spike Talk allows adaptive and flexible control and coordination itself, and features in synaptic plasticity facilitating online and local training functionality. Preliminary case studies are demonstrated with results, while more extensive validations are to be included as future scopes of work.", "sections": [{"title": "I. INTRODUCTION", "content": "The energy consumption of data centers has become a major concern in modern society. As the distributed energy resources (DERs) are increasingly promoted, the carbon footprint is also becoming more critical in power grids where large amount of data are involved [1]. Meanwhile, distributed generation is escalating the demand for coordinating control in cyber-physical microgrids to ensure operational reliability. In turn, challenges persist thereupon, involving delays [2] and susceptibility to cyberattacks [3]. It is therefore of much value to study on a decentralized transition of the operation paradigm to address both challenges.\nUnder this scenario, Talkative Power has been accordingly developed, aiming to co-transfer power and information along transmission lines [4]. System resilience is effectively improved, while additional energy consumption on the transmission line is inevitable. besides, as Talkative Power relies on request-respond information exchange protocol, its scalability is limited when multiple agents are involved in information exchange simultaneously.\nIn contrast, we delve into the realm of a publish-subscribe protocol, where information is fetched locally as needed. Navigated by the biologically plausible neuron model [5], [6], spiking neural network (SNN) has emerged with great advantage in energy efficient computation due to its event-driven feature. Beyond the von-Neumann computing architecture activated by real numbers and perceptrons, SNN leverages a leaky-charge framework instead that are triggered by asynchronous spikes. Empowered by SNN, we formalize the Spike Talk tailored for microgrids, harnessing power flow dynamics to infer remote information locally. As spiking neurons and spiking neural networks have the features of synaptic plasticity and spike-timing-dependent plasticity (STDP), the neuromorphic infrastructure also shows potential in online learning and effectively reduces the data and energy requirements for training. Furthermore, the necessity for communication channels is eliminated, thus effectively addressing the resilience challenges in microgrids.\nThis article thus delineates the infrastructure of Spike Talk and explains it from the perspective of its decentralized and online learning features. The remaining parts of this article is organized as follows: Section II introduces the inspiration of neuromorphic infrastructure for power grids from the von Neumann bottleneck. Section III elaborates on the online learning potential of Spike Talk by investigating the training principles. Section IV presents a case study, and Section V concludes the entire article. By discussing its inherent advantages, more promising real-world applications are implied, which should be the future scope of our work."}, {"title": "II. POST-MOORE POWER ELECTRONIC GRIDS", "content": "The study on neuromorphic infrastructure originates from Moore's Law, which indicates that the total number of transistors on an integrated circuit (IC) should double approximately every two years. It is an empirical conclusion based on the observation of past techniques, while the implementation of computational algorithms had also been following this rule. However, the von Neumann bottleneck is observed in recent years [7], where the room of IC development is shrinking, and the cutting-edge artificial intelligence (AI) is on the contrary calling for more powerful hardware or processing units, as shown in Fig. 1 [8]. On the contrary, it is also preferred to develop more energy-efficient AI algorithms as part of the post-Moore's solutions. In power grids involving interactive agents and noticeable amount of data, Moore's Law for electronics provides similar inspirations and post-Moore solutions are also worth exploring to elevate system scalability and facilitate the processing of larger amount of data, eventually to address the concerns in energy usage and carbon emissions.\nThe basic idea is illustrated in Fig. 2 [9], [10]. In von Neumann architecture shown in Fig. 2(a), the data are stored and processed in separate units, namely the memory and CPU, and data flow through the data bus between CPU and memory. In this case, the time efficiency of computational tasks are constrained by the bandwidth of the data bus, and the issues escalate when dealing with large amount of data.\nThe neuromorphic architecture in Fig. 2(b) has been consequently emerging, where data are stored close to the corresponding CPU cores. The data flows do not need to be handled by the same bus, but are distributed all over the network, thus reducing the occurrence of data congestion. This architecture can effectively mitigate the bandwidth requirement on the buses when large amount of data are demanded simultaneously, enhancing higher computational capability from hardware and thus providing possibilities to facilitate the post Moore algorithms efficiently.\nThe case in Fig. 2(a) is similar in conventional cyber-physical infrastructure of power grids. As per the secondary control targets, the physical layer requires remote data from the cyber layer through information channel, which limits the functionality of the system and induces the vulnerabilities of cyber attacks. Inspired by the neuromorphic architecture, a new-generation infrastructure of power grids can be formalized, the principle of which is the distributed control. Also in Fig. 2(b), leveraging the physical interconnections among nodes, the data bus is interpreted as the physical layer, thus requiring the local detection of remote state variables. We thereby denote this paradigm as the semantic communication for power grids."}, {"title": "B. Spiking Neurons and SNN-Based Power Grids", "content": "In practice, the spiking neuron can be leveraged to implement the said semantic communication, which stems from the bio-neurons [11] and its firing paradigm dependent on the stimuli or events accumulated on the membrane, i.e., the event-driven paradigm [12], [13]. In computational neuroscience, this can be modeled into an RC dynamic in time domain:\n$I(t) = \\frac{V_{mem}(t) - V_r}{R} + C_{mem} \\frac{dV_{mem}}{dt}$ (1)\nas shown in Fig. 3(a) [11]. Here, $I(t)$ is the input current injected to the neuron, and $V_{mem}$ is the output membrane potential.\nThe spikes are generated when the threshold when the threshold $V_{th}$ is hit, and the membrane potential is reset, e.g., through a drop by the threshold $V_{th}$, as Fig. 3(b).\n$s(t) = H(V_{mem}(t) - V_{th})$ (2)\nwhere, $H()$ is the Heaviside step function:\n$H(x) = \\begin{cases} 1 & x > 0 \\\\ 0 & x < 0 \\end{cases}$ (3)\nConsidering the interconnection of spiking neurons, spike response model (SRM) has also been established for spiking neural networks (SNN) [5], as shown in Fig. 3(c). Each neuron $N_i$, establishes connections with its preceding neurons via synaptic weights $w_{j, l-1}, \\forall j \\in Layer (l \u2013 1)$. When a spike is received from the preceding neurons, the membrane potential $v_{i, t}^{(l)}$ will experience a momentary increase (stimuli) and subsequently leakage of charge, namely the leaky-integrate-and-fire (LIF) model. An output spike is thereby set off given that the input membrane potential surpasses the threshold $V_{th}$:\n$v_{i, t}^{(l)} = \\sum_{j=1}^{N^{(l-1)}} w_{j, l-1} \\cdot (\\alpha_{\\tau} * s_{j, t}^{(l-1)}) + \\beta_{t} * s_{i, t}^{(l-1)}$ (4a)\n$s_{i, t}^{(l)} = H(v_{i, t}^{(l)} - V_{th})$ (4b)"}, {"title": "C. Synaptic Plasticity for Neuromorphic Power Grids", "content": "Moreover, this neuron model and the stated interconnection scheme also enable the neuromorphic architecture with noticeable synaptic plasticity beyond the von Neumann computing architecture, as illustrated in Fig. 4. Conventional perceptrons are interconnected in layers, the training of which requires iterations for weight updates. In comparison, the spiking neurons are connected as a network, like the physical layer in power grids. The state of a neuron can be fully / partially charged or leaked, which are dependent on the spikes received from preceding neurons, enabling online learning and showing synaptic plasticity in practice.\nThis forms the theoretical basis of neuromorphic power grids. Exemplifying a DC microgrid consisting of distributed energy resources (DERs) interfaced by power electronics converters, we thereby outline the following features to describe this concept [15]:\n1) The entire system can be mapped into a neural network, with each converter being a single neuron. The RC dynamic in LIF model matches the impedance network dominated by resistances and capacitances.\n2) When the weights are set aligned with the system impedances / admittances, the neural network is essentially mirroring the behaviors of the system. This indicates the possibility of using only local sampling to detect the remote states for secondary controllers.\n3) With the synaptic plasticity, it is possible to update the weights locally by integrating the local sampling and control targets, which is the potential of online learning. In this way, each local neural network or each converter is \"learning\" from the inherent system dynamics."}, {"title": "III. SPIKE TALK FOR POWER ELECTRONIC GRIDS", "content": "In power electronic dominated grids, we justify the name of this paradigm as Spike Talk, as spike neurons are utilized to convey the system states [15]. If the aforementioned principles are followed, then the spiking neural networks are coupled through the system admittance matrix $[Y]_{n\\times n}$ (the physical layer), as depicted in Fig. 5. Though the neural networks are executed locally, the physical coupling can contribute to maintaining the consistency of weight changes during online learning as well as the convergence of gradients regarding the loss functions.\nWe inspect a simple scenario of a DC grid consisting of interconnected DC-DC converters and governed by droop relationships. The proposed Spike Talk is then compared in Fig. 6, with conventional the cyber-physical infrastructure and the semantic communication using basic artificial neural network (ANN) [12]:\n1) Cyber-physical infrastructure in Fig. 6(a) requires both local sampling and the detection of remote states, which embeds the vulnerability to cyber attacks. As the cyber layer is essential in this case for data transfer, the system controllability is also limited by the capacity of the data buses all the time, which accords with the disadvantages of the von Neumann architecture mentioned in Fig. 2.\n2) In semantic communications in Fig. 6(b), the cyber layer is dismissed, improving the system resilience against cyber attacks. However, the remote data is still required for initializing training of ANN, and the energy efficiency during both training and execution is high due to the large number of perceptrons connected in layers.\n3) Spike Talk in Fig. 6(c) further goes beyond the ANN-based semantic communications. The networked structure can not only mirror the physical layer and simplify the initialization, but also enable the online training for higher adaptability to, e.g., various potential fault scenarios in power grids. Besides, as the number of neurons accords with that of the nodes, the neural networks are significantly simplified, implying enhanced energy efficiency in practice."}, {"title": "B. Principles of Hebbian-Disciplined Spike Talk", "content": "Spiking neural networks can be trained by general back-propagation approaches, while we tend to emphasize its capability of Hebbian learning, or online learning as per the control targets. This feature extends the semantic communication among converters to the comprehension of the system dynamics, promoting the adaptability of decentralized control for power grids.\nSeveral training principles are shown in Fig. 7(a)-(c) [16]. For layered structure, the gradient back-propagation in (a) is the most basic training method, where the gradient of loss functions are leveraged to update the weights. Considering the feedback path provided by the physical layer, the perturbation learning in (b) is also an option. The gradient of back-propagation-based training can be calculated based on the following equation [16]:\n$\\frac{\\partial L}{\\partial W_{in}} = \\frac{\\partial L}{\\partial S_{out}} \\frac{\\partial S_{out}}{\\partial U} \\frac{\\partial U}{\\partial W_{in}}$ (6)\nwhere $L$ is the data-based loss function, $W_{in}$ is the input weight, $S_{out}$ is the output spike, and $U$ is the generated membrane potential. The first and third term can be directly calculated, while the second term should be approximated as surrogate gradient through:\n$\\frac{\\partial S}{\\partial U} = \\frac{1}{\\pi} \\frac{1}{1 + (\\frac{U}{\\pi})^2}$ (7)\nHowever, in these two cases, secondary control is normally generated from the remote states estimated by the neural network, thus remote data are still required for training.\nWhen the neurons are connected in networked structure, another method becomes possible utilizing local losses. Since in DC grids, droop control is essentially an additional damping resistance, the secondary control targets can be merged into the changing weights as control-disciplined local losses. For instance, the spike-timing-dependent plasticity (STDP) feature of SNN introduced in [11] can be leveraged to account for secondary control objectives. An example is given in [15], to implement both voltage regulation and power management by aligning the voltage and current spikes, as illustrated in Fig. 7(d). The modification of droop gain is federated by the secondary control objectives:\n1) Voltage follows the global average reference;\n2) Current follows the power sharing requirements;\n3) When voltage and current are coded through rate and latency coding, respectively, the control target is met when the cross entropy of both reaches minimum.\nThus, the droop gain can be calculated as:\n$R'_a = R_a - \\alpha \\Delta w(t)$ (8)\nwhere, $\\Delta w(t)$ is the variation of weights in the SNN."}, {"title": "C. Key Features of Spike Talk", "content": "Therefore, Spike Talk also shows the following features based on the aforementioned functionalities:\n1) Energy efficiency: As Spike Talk roots in the event-driven paradigm, the neurons only show an state change when there is an event or transient. Also, as the desired neural network is highly consistent with the physical layer, it is not necessary to sample large amount of data for training and execution. Hence, it can effectively address the issue in energy efficiency of the data centers in power electronics grids.\n2) Publish-subscribe paradigm: Spike Talk requires local controllers to learn from the inherent system dynamics, without requiring data from remote nodes, which can be recognized as the publish-subscribe paradigm of the aforementioned neuromorphic infrastructure, and different from the conventional request-receive paradigm relying on the cyber layer. This feature meets the requirement on distributed computation and turns out to be a favorable post-Moore solution for power grids."}, {"title": "IV. PERFORMANCE DEMONSTRATIONS", "content": "A case study has been conducted by simulation to demonstrate the features of Spike Talk. The studied system is shown in Fig. 8, which is a droop-based DC microgrid consisting of four nodes. The secondary controllers aim at regulate the average voltage and the power sharing, and the key parameters are listed in appendix.\nWe first test the event capturing for SNN in Fig. 9. We utilize rate coding, and the events are captured only when there is a transient. When DER3 is out at t = 4 s, the spikes of DER3 are no longer generated, or in other words, the neuron representing DER3 is no longer active. This justifies the basis for SNN to adapt fault scenarios in grids or time-dependent system architectures.\nWe further showcase the STDP feature specified in Section III-B, and the results are shown in Fig. 10. With the initial weights are assigned, the spikes for voltage and current are captured by rate coding and latency coding, respectively, and the change of droop coefficients is recorded. From the results, the spikes for voltage and current are generated based on different coding methods to implement STDP. With this, the droop gain can be adjusted adaptively, which is the main purpose of online learning. Nevertheless, the results only involve preliminary cases, and we plan to extend the demonstrations by online experiments as future scope of work."}, {"title": "V. CONCLUSIONS AND FUTURE PERSPECTIVES", "content": "This paper sheds light on Spike Talk, a novel concept by employing spiking neural network (SNN) for semantic communication in power electronics grids, from the perspective of its decentralized and online learning features. Leveraging STDP and the networked architecture of SNN, Spike Talk dismisses the reliance on physical information channels and shows the potential in enhancing system energy efficiencies. As the validation of this concept is still not comprehensive, we aim to showcase Spike Talk in more scenarios and performing online experimental tests, to further evaluate its potential advantages in piloting future applications."}]}