{"title": "TART: Boosting Clean Accuracy Through\nTangent Direction Guided Adversarial Training", "authors": ["Bongsoo Yi", "Rongjie Lai", "Yao Li"], "abstract": "Adversarial training has been shown to be successful\nin enhancing the robustness of deep neural networks against\nadversarial attacks. However, this robustness is accompanied by\na significant decline in accuracy on clean data. In this paper,\nwe propose a novel method, called Tangent Direction Guided\nAdversarial Training (TART), that leverages the tangent space of\nthe data manifold to ameliorate the existing adversarial defense\nalgorithms. We argue that training with adversarial examples\nhaving large normal components significantly alters the decision\nboundary and hurts accuracy. TART mitigates this issue by\nestimating the tangent direction of adversarial examples and\nallocating an adaptive perturbation limit according to the norm\nof their tangential component. To the best of our knowledge, our\npaper is the first work to consider the concept of tangent space\nand direction in the context of adversarial defense. We validate\nthe effectiveness of TART through extensive experiments on\nboth simulated and benchmark datasets. The results demonstrate\nthat TART consistently boosts clean accuracy while retaining a\nhigh level of robustness against adversarial attacks. Our findings\nsuggest that incorporating the geometric properties of data can\nlead to more effective and efficient adversarial training methods.", "sections": [{"title": "I. INTRODUCTION", "content": "Despite the phenomenal success of deep neural networks\n(DNNs) in various fields including computer vision [1]\u2013[3],\nnatural language processing [4], recommendation systems [5],\nand reinforcement learning [6], they are highly susceptible to\nadversarial examples generated by adding small adversarial\nperturbations to natural examples [7]\u2013[10]. Adversarial per-\nturbations are purposely chosen by the attacker to deceive the\nmodel into making incorrect predictions, but are small enough\nto be imperceptible to humans. As DNNs are used in numerous\nreal-world scenarios, this vulnerability leads to serious security\nissues, particularly in fields like autonomous driving [11], [12]\nand medical analysis [13]\u2013[15].\nTo address these issues, developing powerful defense tech-\nniques against such adversarial attacks has become an essential\nresearch field. One of the most popular defense methods\nagainst adversarial attacks is standard adversarial training\nproposed by Madry et al. [16]. It trains the model using\nadversarial samples generated via a method called the pro-\njected gradient descent. See [17], [18] for a summary of"}, {"title": "II. STANDARD ADVERSARIAL TRAINING", "content": "In this section, we provide an overview of standard adver-\nsarial training [16] and its implementation."}, {"title": "A. Notation", "content": "We focus on multiclass classification problems with c\nclasses. Denote D the data manifold and X the input feature\nspace. The training dataset {(xi, Yi)}=1 is sampled from D,\nwhere xi \u2208 X and yi \u2208 Y = {1,...,c}. Our discussion\nwill be mainly based on the metric space (X, ||\u00b7||p) when\nX = Rd. Let Bp(\u20ac) = {\u03b4 \u2208 X : ||8|| \u2264 \u20ac} be the\nclosed e-ball centered at the origin 0 \u2208 X. We consider the\nclassifier f(.; 0) : X \u2192 RC parametrized by 0, where the i-\nth element of the output is the score of the i-th class. The\ngoal of the classification problem is to train a classifier f that\nminimizes E(x,y)~D[l(f(x; 0), y)], where l : R\u00a3 \u00d7 Y \u2192 R is\nthe classification loss."}, {"title": "B. Learning Objective", "content": "Madry et al. [16] proposed a standard adversarial training\n(standard AT) that solves a min-max optimization problem\nwith the following objective function:\nmin \u03b8  1 n \u03a3 i=1 l(f(x; 0), Yi), (1)\nwhere\nx= x + arg max l(f(xi + \u03b4; 0), Yi) (2)\n\u03b4\u03b5\u03c2"}, {"title": "III. TANGENT DIRECTION GUIDED ADVERSARIAL\nTRAINING (TART)", "content": "In this section, we propose Tangent diRection guided ad-\nversarial Training (TART) and its realization. Standard AT\nuses a common adversarial set S = Bp(\u20ac) for all training\ndata, while TART provides a reasonable perturbation set\nutilizing information from the data manifold and tangent space.\nTART was motivated by the concern that training models on\nadversarial examples with large normal components can have"}, {"title": "A. Finding the Tangent Space", "content": "For datasets where the data manifold is known, the tangent\nspace can be obtained explicitly and it can be used immedi-\nately to proceed with TART. However, for benchmark or real-\nworld datasets, we often do not know the corresponding data\nmanifold and thus need to approximately estimate the tangent\nspace.\nSuppose that dataset {x} < Rd lies in a k-dimensional\nmanifold embedded in Rd, where k < d. Indeed, many stud-\nies have demonstrated that the intrinsic dimension of image"}, {"title": "B. Computing Tangential Component", "content": "Using the estimation of tangent space, we compute the\ntangential component of adversarial examples. Let A be a\ndxk matrix whose columns are the tangent vectors of a natural\ndata x \u2208 Rd. We note that the column space of A is the k-\ndimensional tangent space at \u00e6. Also, let x* be an adversarial\nexample generated by perturbing \u00e6 and denote the projection\nof x* -x onto the tangent space of x as w. Then the tangential\ncomponent of x* is defined as the norm of w. Here we employ\na well-known fact that \u03a0\u2081\u03c5 is the projection of a vector v\nonto the column space of A, where \u041f\u2081 := A(ATA)\u00af\u00b9AT. A\nconcise overview of the projection matrix \u041f\u0104 is provided in\nAppendix A. Therefore, the tangential component of x* can\nbe computed as follows:\n||w|| = ||\u03a0\u0391(x* - x) || (6)\n= ||A(ATA)-1AT (x* \u2013 x)||"}, {"title": "C. Selecting the Perturbation Bound e", "content": "The final step in realizing TART is to select a suitable\nperturbation bound e for each data during training. We first\ngenerate adversarial examples with a perturbation bound of\nEmax for each training data. Next, the tangential components\ncomputed in Section III-B are used as the criterion for choos-\ning the correct \u20ac. The fundamental idea is to assign larger\nor smaller e values to data with larger or smaller tangential\ncomponents. While several assignment methods exist, TART\nadopts a straightforward approach providing Emax to the upper\n50% and 0 to the lower 50%. The perturbation bound of i-th"}, {"title": "IV. EXPERIMENTS", "content": "In this section, we first demonstrate the superiority of our\nproposed training technique TART through a simulated exper-\niment using a transformed hemisphere dataset. In addition, we\nevaluate the performance of TART on CIFAR-10 and illustrate\nthat TART can be effectively combined with various other\nadversarial training methods."}, {"title": "A. Transformed Hemisphere", "content": "We conduct an experiment to compare the efficacy of train-\ning on adversarial examples with large normal components\nversus training on adversarial examples with large tangen-\ntial components. Consider a unit hemisphere in R\u00b3 whose\ntangent space can be computed without any approximation.\nThe hemisphere is evenly divided into c regions. The data are\nfirst sampled from the hemispherical surface and transformed\nto a high dimensional space Rd with a linear transformation\nT : R3 \u2192 Rd, where T = (V1,V2, V3) and V1, V2, V3 are\nthree orthonormal vectors in Rd. Let z \u2208 R\u00b3 be the point\nsampled from the unit hemisphere. Then x = T(z) is the\nsimulated data used for classification where the data class\nlabels are determined by which region z is located. Since\nz lies on a sphere, we can explicitly compute the tangent\nvectors U1, U2 of z. Next, the tangent vectors of \u00e6 can be\nobtained immediately by performing transformation of u\u2081 and\n\u0e192: W\u2081 = T(u\u2081) and w\u2082 = T(u2). Using the tangent vectors\nw\u2081 and w2, we may calculate the tangential component of\nadversarial examples and implement TART on the simulated\ndataset.\nThe goal of this experiment is to confirm the validity\nof our concepts and assess the effectiveness of TART. We\ncompare our idea (TART) to the opposite of our idea (Reverse-\nTART), i.e., provide smaller perturbation bounds to adversarial\nexamples with larger tangential components. To see a more\npronounced effect, we compute the tangential components at\neach epoch and use only half of the adversarial examples\ngenerated (examples with the largest 25% and the smallest"}, {"title": "B. Performance Evaluation on CIFAR", "content": "In this section, we assess the performance of TART on\nCIFAR-10 [40]. We also verify the versatility of TART by\nsuccessfully integrating it with other existing defense methods.\nSpecifically, we combine TART with the following defense\napproaches: (1) Standard AT [16], (2) TRADES [20], (3)\nMART [29], and (4) GAIRAT [27]."}, {"title": "V. CONCLUSION", "content": "In this paper, we proposed a new adversarial training method\ncalled Tangent Direction Guided Adversarial Training (TART),\nwhich leverages the tangent space to improve clean accuracy.\nOur motivation stemmed from the widely accepted observation\nthat data often exhibits lower-dimensional structures. We an-\nticipated that leveraging information about the data manifold\nfor adversarial training would enhance its effectiveness. TART\nallocates larger or smaller perturbation limits to adversarial\nexamples with larger or smaller tangential components, re-\nspectively. We experimentally demonstrated that TART can\neffectively improve clean accuracy with minimal or even no\nimpact on robustness. In the future, we aim to explore the\noptimal epsilon for each sample by theoretically investigating"}, {"title": "APPENDIX A\nPROJECTION MATRIX", "content": "For a matrix A of size nxk with full column rank, we\ndefine CA as the column space of A, which is a linear subspace\nin Rn spanned by the columns of A. The column space CA\ncan be represented as:\nCA = {\u03b2\u2081\u2081 + \u03b22u2 + \u00b7\u00b7\u00b7 \u03b2\u03ba\u03c5\u03ba: \u03b21, \u03b22,\u00b7\u00b7\u00b7,\u03b2k\u2208R} (8)\n= {A\u1e9e : \u03b2 \u2208 R*} (9)\nwhere u1, u2,\u2026, uk are the columns of A.\nA projection matrix Ia := A(ATA)\u00af\u00b9AT is an n\u00d7n\nsquare matrix associated with a linear operator that projects a\nvector in Rn onto a subspace CA. The projection matrix \u041f\u0410\ncan be derived using the property that for any vector v \u2208 R\",\nthe vector v \u03a0\u03b1\u03bd is orthogonal to the column space CA.\nAlso, there exists a vector \u03b2 \u2208 Rk such that \u03a0\u03bf\u03c5 = \u0391\u03b2\nsince \u03a0\u03bf\u03c5 lies in the column space of A. Therefore,\nv - \u03a0\u0391v = v \u2013 \u0391\u03b2 1 CA (10)\n\u21d4 \u0391\u0384 (\u03bd \u2013 \u0391\u03b2) = 0 (11)\n\u21d4 \u03b2 = (ATA)-1\u0391\u03c4\u03c5 (12)\n\u21d4 \u041f\u2081 = A(A\u00a8A)-1A\u0f0b. (13)\nIt is important to highlight that ATA is always invertible\nwhen A has a full column rank, ensuring the existence of\nthe projection matrix \u03a0\u0391.\""}, {"title": "APPENDIX B\nPROOF OF PROPOSITION III.1", "content": "Proposition III.1. For any function f,\n|Rp(f) \u2013 R2(f)| \u2264 4 TV(P, Q),\nwhere TV(P, Q) denotes the total variance distance between\nP and Q.\nProof. Let P ~ p and Q ~ q. Then,\n|R2(f) \u2013 Rp(f)|\n=/ L(f(x), )dx - / L(f(x), )dx\n\u2264 / L(f(x), ) p(x) - q(x) dx\n\u22642 ||PQ||\u2081 = 4TV(P, Q),\nwhere the last equality holds due to the relationship between\nthe L\u00b9 norm and the total variance distance ."}]}