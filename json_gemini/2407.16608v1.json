{"title": "Deep Bayesian segmentation for colon polyps: Well-calibrated predictions in medical imaging", "authors": ["Daniela L. Ramos", "Hector J. Hortua"], "abstract": "Colorectal polyps are generally benign alterations that, if not identified promptly and managed successfully, can progress to cancer and cause affectations on the colon mucosa, known as adenocarcinoma. Today advances in Deep Learning have demonstrated the ability to achieve significant performance in image classification and detection in medical diagnosis applications. Nevertheless, these models are prone to overfitting, and making decisions based only on point estimations may provide incorrect predictions. Thus, to obtain a more informed decision, we must consider point estimations along with their reliable uncertainty quantification. In this paper, we built different Bayesian neural network approaches based on the flexibility of posterior distribution to develop semantic segmentation of colorectal polyp images. We found that these models not only provide state-of-the-art performance on the segmentation of this medical dataset but also, yield accurate uncertainty estimates. We applied multiplicative normalized flows(MNF) and reparameterization trick on the UNET, FPN, and LINKNET architectures tested with multiple backbones in deterministic and Bayesian versions. We report that the FPN + EfficientnetB7 architecture with MNF is the most promising option given its IOU of 0.94 and Expected Calibration Error (ECE) of 0.004, combined with its superiority in identifying difficult-to-detect colorectal polyps, which is effective in clinical areas where early detection prevents the development of colon cancer.", "sections": [{"title": "1. Introduction", "content": "Colorectal cancer is the second leading cause of cancer deaths worldwide, both in terms of prevalence and mortality for both genders. In 2020, it caused 935,000 deaths, accounting for 10% of all cancer-related deaths. This highlights the importance of its study and early detection (Globocan, 2020). The 5-year survival rate for this type of cancer is around 65% for all stages of the disease combined (NCI, 2020), but if detected early, this survival rate increases to 90% (ACS, 2022). Colorectal polyps are known as direct precursors of this disease, if they are not treated adequately, effectively, and in time. The main tool to detect them is visually during the colonoscopy procedure, but this can lead to human errors during the diagnostic process, as studies have reported a rate of undetected polyps during the process, ranging from 6-28% (Lee et al., 2017). Given the aforementioned reports, the importance of the development of automatic detection systems (ADS) for the accurate identification of colon polyps is evident. Recently, there have been several studies and approaches to automatic systems for polyps. One of the first proposals included morphology as WM-DOVA, where the authors implemented it in the CVC-CLINICDB dataset, being an approach to determine the presence and location of polyps, but it is not designed to accurately detect them at the pixel level (Baena J., 2015). This was followed by an exploration of ADS based on convolutional neural networks at the semantic level using UNET-type (Tashk et al., 2019), and FCN architectures (Li et al., 2017). These works reported notable results in terms of overall accuracy (96%), but without the advantage of having uncertainties associated with the predictions. Finally, some works on segmentation using the CVC-CLINICDB database have reported the use of transformers like SegFormer (Wang et al., 2022b), Polyp-SAM (Li et al., 2023) and multiple CNN architectures, such as the double-UNET (Jha et al., 2020), FCN-8 + VGG16, SegNet (Wickstr\u00f8m et al., 2020), ResUNet++ (Jha et al., 2021), with acceptable results, but mostly report metrics such as IOU < 90% (Mei et al., 2024). On the other hand, quantification of uncertainties is a topic of great interest in Bayesian analysis. Bayesian methods offer probabilistic interpretations for predicted outcomes via a posterior distribution. Although exact Bayesian inference with deep neural networks is computationally infeasible, the authors in (Gal, 2016) demonstrated that typical optimization of neural networks using dropout layers and L2 regularization can be seen as equivalent to performing Bayesian variational inference of a specific variational distribution (Kwon et al., 2020). In the field of medical image semantic segmentation, uncertainty estimation methods can be broadly classified into Bayesian-based and Non-Bayesian-based methods, as reviewed by (Zou et al., 2023). Bayesian-based methods include several techniques for estimating uncertainty. These techniques involve using ensemble-based approaches that employ multiple models to capture different sources of variability. For example, MC dropout is a technique that introduces randomness by dropping out units from a neural network during inference, allowing for uncertainty estimation through repeated sampling. Other techniques are deterministic-based, aiming to develop algorithms that accurately estimate uncertainties (Wu et al., 2024). Particularly for colon polyps, the proposed method by (Gal, 2016), which utilizes Monte Carlo estimator and dropout samples as seen in previous works like (Wickstr\u00f8m et al., 2020), often produces inaccurate uncertainty estimates because deep neural networks trained with maximum likelihood estimation approaches do not provide precise confidence intervals. Although is not yet clear the cause of this miscalibration, (Guo et al., 2017) reported several experiments that present how the training and certain hyper-parameters impact the accuracy uncertainty estimates. The goal of this paper is to provide a road map to build accurate systems in terms of prediction performance and uncertainty estimates. We explore the use of different convolutional network structures with backbones and Bayesian approaches such as the multiplicative normalizing flows method and reparameterization trick to yield well-calibrated uncertainties. The manuscript is structured as follows, in section 2.1 to 5, we present models and methods, that include the introduction to concepts used to develop the work. Then, in section 6, we present experimental development and different architectures implemented. Next, in section 7, we present the main results and report the highest combination in terms of Bayesian approach and network architectures to predict polyps and their accurate uncertainties, Also, we employ feature importance methods to understanding the correct interpretation of the model predictions. Finally, section 8 presents conclusions along with appendix material."}, {"title": "2. Bayesian Neural Networks", "content": "In the following, we introduce theoretical foundations of variational inference for Bayesian neural networks. It also covers measurement of model calibration, the association of uncertainties to predictions, and definition of recommended loss functions for binary segmentation cases."}, {"title": "2.1. Variational Inference in Bayesian Neural Networks", "content": "In the following, we introduce theoretical foundations of variational inference for Bayesian neural networks. It also covers measurement of model calibration, the association of uncertainties to predictions, and definition of recommended loss functions for binary segmentation cases."}, {"title": "2.2. Variational Inference in Bayesian Neural Networks", "content": "Within DNN framework, let $D = \\{(x_i, y_i)\\}_{i=1}^N$ where N is size of the sample and $x_i \\in \\mathbb{R}^d$, $y_i = (y_i^{(1)},..., y_i^{(K)}) \\in \\{(0,1)\\}^K$, d is dimension of input variables, K is the number of different classes (output), $\\omega \\in \\Omega$ the vector of parameters for the network and $p(\\omega)$ a prior on weights w. Posterior distribution is given by:\n\n$p(\\omega|D) = \\frac{p(D|\\omega) p(\\omega)}{p(D)} = \\frac{\\prod_{i=1}^N P(y_i|x_i, \\omega) p(\\omega)}{p(D)}$\n\nPredictive distribution (for a new pair $x_*, y_*$) is written as:\n\n$p(y_*|x_*, D) = \\int P(y_*|x_*, \\omega) p(\\omega|D) d\\omega$"}, {"title": "2.3. Monte Carlo estimator", "content": "Considering that the integration to compute the predicted distribution must be done over the entire \u03a9 space, we consider a Monte Carlo estimator as follows:\n\n$P_{\\theta}(y_*|x_*) = \\frac{1}{T}\\sum_{i=1}^T P(y_*|x_*, w_{\\theta})$\n\nHere ${w_\\theta}_1^T$ is a set of weight vectors randomly drawn from optimized variational distribution $q_\\theta(w)$ with T number of samples. For a high value of T, it converges to the probability of $q_{\\theta}(y_*|x_*)$ shown in Eq.(5) for all $\\omega \\in \\Omega$. (Kwon et al., 2020)"}, {"title": "2.4. Reparameterization Trick", "content": "Part of the strategies for generating inference about posterior distribution and variance reduction is a sampling process during optimization, called reparameterization trick. Being w the weights of the network, they can be written in terms of an auxiliary variable \u0454:\n\n$\\omega \\sim q(\\omega|\\theta) = g(\\epsilon, \\theta)$\n\nFor e ~ p(e) where p is an independent distribution of parameter 0 that we want to optimize in network training process. We get an estimation of $q_\\theta$ with:\n\n$\\int_{\\Omega} q_{\\theta}(\\omega)p(\\omega)d\\omega \\approx \\frac{1}{K}\\sum_{k=1}^K f(g(\\epsilon, \\theta)_k)$"}, {"title": "2.5. Multiplicative Normalizing Flows", "content": "In the analysis of limit in Eq.(6), ideal variational distribution is when $KL\\{q||p\\}$ equals zero. However, achieving this with mean field approximation introduced in Eq. (4) is not feasible. For this purpose, we consider a more complex and flexible family of distributions that allows the true posterior distribution to be one of the possible solutions. By increasing the complexity, we expect significant performance enhancements because we can draw samples from a more reliable distribution that is closer to the true posterior. Multiplicative normalized flows (MNF), are a way to obtain mentioned distributions through a combination of auxiliary random variables with normalization flows Louizos and Welling (2017). By associating the parameter 0 with a family of distributions to be compared over the posterior, and introducing an auxiliary latent variable in the form of a vector $z \\sim q_{\\theta}(z) = q(z)^2$, the variational posterior can be represented mathematically as a blend of distributions\n\n$q_\\theta(w) = \\int q_{\\theta}(w|z)q_{\\theta}(z)dz$\n\nIf the equation Eq.4 is rewritten including local reparametrizations, then posterior for fully connected layers will be (Garc\u00eda-Farieta et al., 2023)\n\n$w \\sim q(w/z) = \\prod_{i,j} N(W; z_i\\mu_{ij}, \\sigma^2_{ij})$\n\nLet $f: R^n \\rightarrow R^n$, $f^{-1} = g$, and $g \\circ f(z) = z$. A ramdom variable z with distribution q(z) and $z' = f(z)$, satisfies\n\n$q(z') = q(z) \\left| \\frac{det \\frac{\\partial z}{\\partial z'}}{det \\frac{\\partial f}{\\partial z}} \\right| = q(z) \\left|det \\frac{\\partial f}{\\partial z} \\right|^{-1}$\n\nThen, having a composition $z_l = f_l(f_{l-1}(...f_1(z_0)))$, where $z_0 \\sim q(z_0)$ are factorized gaussians like in Eq. (4), for a sequence of l invertible transformations, we have:\n\n$log q(z) = log q(z_0) - \\sum_{l=1}^L log \\left| det \\frac{\\partial f_l}{\\partial z_l} \\right|$\n\nTo calculate the posterior, implementing Bayes theorem $q(z_l)q(w|z_l) = q(w)q(z_l|w)$ and making use of an auxiliary distribution in the form $s(z_l|w, \\phi)$ as in Louizos and Welling (2017), with $\\phi$ as parameter, we can get this auxiliary distribution as close as possible to this distribution with originals parameters $q(z_l|w)$, meaning KL divergence and its lower bound are given by:\n\n$-KL\\{q(w)|p(w)\\} \\geq E_{q(w,z_l)}[ -KL[q(w|z_l)||p(w)] +log q(z) + log s(z_l|w, \\phi)]$\n\nInitial term in right side can be determined analytically because its KL divergence calculated over two gaussians distributions. The second is determined by normalizing flow in Eq.(13) and given $z_0 = g^{-1}_1(g^{-1}_2(...g^{-1}_l(z_L)))$:\n\n$log s(z_l|w, \\phi) = log s(z_0, \\phi) - \\sum_{l=1}^L log \\left|det \\frac{\\partial g_l^{-1}}{\\partial z_l} \\right|$\n\nBy parameterizing the auxiliary posterior and transforming $g^{-1}_l$ into the form of a normalized flow Louizos and Welling (2017), we obtain\n\n$z_0 \\sim s(z_l|w, \\phi) = \\prod_{i} N(z_0; \\tilde{\\mu}_i(w, \\phi), \\tilde{\\sigma}^2_i(w, \\phi))$\n\nHere, we adopt parameterization of mean, represented as $\\tilde{\\mu}$, and variance, represented as $\\tilde{\\sigma}^2$, from masked real valued non volume preserving (real NVP) like in (Dinh et al., 2017) as option for normalizing flows."}, {"title": "3. Observing calibration", "content": "A perfectly calibrated model is defined as one where prediction P is a real probability in frequentist terms, i.e., it represents real probability that prediction is correct. This applies to a scenario with variables X and Y, where X \u2208 X, Y in Y = {0,1}. The joint distribution of X and Y is given by p(X, Y) = p(Y|X)p(X). Otherwise, we have a neural network with input h(X) and prediction (\u0176, P), being \u0176 inference about the class and its associated probability P.Therefore, we have a calibrated model if (Guo et al., 2017)\n\nP(\u0176 = Y|P = p) = p, \u2200p \u2208 [0, 1].\n\n3.1. Expected calibration error (ECE)\n\nSeveral metrics are available to measure a model calibration, one of the most common and recognized is the so-called Expected Calibration Error (ECE). This metric, naturally derived from Eq.(17) represents the difference between prediction confidence and accuracy (Wang et al., 2022a)\n\n$ECE = E_P [|E(\u0176 = Y|P = p) - p|]$\n\nwhich is obtained by computing the weighted average of accuracy acc($B_M$) by partitioning p-space of predictions into M bins, where confidences are denoted by conf ($B_M$), value n, and |$B_M$| the number of pixels that fall into a bin. In semantic segmentation scheme n represents the number of pixels\n\n$ECE = \\frac{1}{n}\\sum_{m=1}^M |B_M||acc(B_M) - conf(B_M)|$.\n\nA model is perfectly calibrated when its ECE is zero. The difference in each bin between accuracy and the confidences is represented visually by a gap in the reliability diagrams, a powerful tool for evaluating quality of uncertainty estimations (Wang et al., 2022a).\n\n3.1.1. ECE for semantic segmentation\n\nFor ECE estimation, we adopt the approach followed in (Wang et al., 2022a), where each pixel in an image is considered as a single sample, resulting in a total of NxNxI samples, where I is the total number of images to be evaluated and N is the size of the images. Then the ECE is calculated first in each image, and then later over all the images\n\n$ECE = \\frac{1}{I} \\sum_{i=1}^I ECE_i$\n\n3.2. Reliability diagrams\n\nReliability diagrams are a visual representation of ECE, or equivalently, how well a model is calibrated. These graphs illustrate correlation between the expected accuracy of a sample and model confidences, using a partitioning of the prediction space into M bins. If model is perfectly calibrated, i.e. if the condition Eq. (17) is satisfied then, the relationship should be represented by an identity function. Any deviation from a perfect diagonal indicates a lack of calibration, implying that uncertainties are either under- or over-estimated (Guo et al., 2017)."}, {"title": "4. Metrics and loss functions", "content": "4.1. Metrics\n\nTo evaluate the performance of the models, we considered IOU (Intersection over Union) since it measures the exact spatial similarity between areas segmented by the model and the masks. This metric, based on F-score, is particularly useful for evaluating accuracy of segmentation models in scenarios where high accuracy at edges of region of interest is critical (M\u00fcller et al., 2022).\n\n$IoU_c = \\frac{\\sum_i (y_i(c) \\wedge \\hat{y}_i(c))}{\\sum_i (y_i(c) \\vee \\hat{y}_i(c))},$\n\nhere, c is the class, $y_i$ is mask value (ground truth) for class c, $\\hat{y}_i$ is prediction, $ \\wedge$ denotes and operation, and $\\vee$ denotes or operation. As a supporting metric, recall is also implemented, although this is less sensitive in isolation compared to F-score based metrics when assessing and comparing models. However, inclusion of recall helps us to provide a more comprehensive evaluation, allowing for a more nuanced understanding of a model performance and its ability to accurately identify ROI (M\u00fcller et al., 2022)\n\n$Recall = \\frac{TP}{TP+FN}$\n\n4.2. Loss functions\n\nThe loss functions are crucial in training stage to produce accurate predictions, especially in semantic segmentation domain. Our work will employ Jaccard loss, Dice loss, binary cross entropy, and total loss from the python library Segmentation Models (Iakubovskii, 2019).\n\n4.2.1. Region based\n\n\u2022 Jaccard Loss: This loss function calculates intersection over union between region of interest (ROI) and region predicted by the model, to optimize the overlap between them\n\n$J(A, B) = 1 - \\frac{A\\cap B}{A\\cup B},$\n\nwhere A is region of interest in ground truth, and B is the region which is predicted by the model.\n\n\u2022 Dice Loss: Similar to Jaccard Loss, this loss function is also focused on calculating the intersection over union\n\n$D(A, B) = 1 - \\frac{2 A \\cap B}{|A| + |B|}$\n\nThis function is utilized to measure overlap or similarity between two sets and is commonly used in medical image segmentation tasks. The advantage of this loss function over Jaccard is that the overlap carries more weight in loss calculation, which is useful when proportion of pixels in one class, such as region of interest in an image, is significantly smaller than another. In other words, the goal is not only to maximize the proportion of overlapped region, but also to prioritize the exact level of overlap.(Azad et al., 2023).\n\n4.2.2. Distribution based\n\n\u2022 Binary cross-entropy: This is computed as the difference between actual distribution and the predicted distribution (Ma et al., 2021).\n\n$BCE(y, \\hat{y}) = \\frac{1}{N}\\sum_{i=1}^N y_i log(\\hat{y_i}) + (1 - y_i) log(1 - \\hat{y_i}),$\n\nhere, y is real value, $\\hat{y}$ is the prediction and N is number of samples.\n\n\u2022 Total loss: This function takes into account both the similarity beetween regions of interest and the focus on the minority class in cases of class imbalance in semantic segmentation task.\n\n$TL(y, \\hat{y}) = D(A, B) + (0.5 * BFL).$\n\nDice loss is denoted by D, and BFL is Binary Focal Loss function\n\n$BFL = -y \\cdot \\alpha \\cdot (1 - \\hat{y})^\\gamma \\cdot log(\\hat{y}) - (1 - y) \\cdot \\alpha \\cdot \\hat{y} \\cdot log(1 - \\hat{y}),$\n\nwhere y is real value, $\\hat{y}$ is the prediction, $\\alpha$ is a weight and $\\gamma$ are a modulating parameter. The binary focal loss function is an extension of cross entropy loss. It incorporates a gamma factor, known also as focusing parameter, which permits hard to classify pixels to have more severe penalties than those that are easier (Jadon, 2020)."}, {"title": "4.3. Neg-Log Likelihood", "content": "The Negative Log Likelihood (NLL) is a function used to measure how closely a model fits the actual data. It is calculated based on number of samples n and the distribution p(Y|X)\n\n$NLL = -\\frac{1}{n} \\sum_{i=1}^n log p((Y|x_i)).$\n\nIn our case we will use it as a loss function for BNN models, any loss that includes an NLL is equivalent to minimizing the divergence Kullback-Leibler in Eq.(3), or alternatively, it is a binary cross entropy computed between the distribution defined by training set and the probability distribution defined by model Goodfellow et al. (2016)."}, {"title": "5. Dataset", "content": "The CVC-CLINICDB database, which is a free and public database, will be used for this work. It was developed by (Baena J., 2015), and comprises 612 images extracted from colonoscopy videos and created for the study and development of automatic systems for detection and segmentation of colon polyps. Fig.(1) shows an preview of dataset. Images include ground truth and background (mucosa and lumen) and were obtained from 31 video sequences taken from 23 patients. The resolution of the images is 384 \u00d7 288."}, {"title": "6. Experimental Setup", "content": "6.1. Preprocessing\n\nUsing the database referenced in Fig.(1), a binary segmentation task was conducted, class 0 represents the background and class 1 represents the polyp. The dataset was divided into three parts: training, validation, and test, with 70%, 20%, and 10% respectively. All images were resized to 256x256 to eliminate black borders and facilitate network input. For the training images, preprocessing was performed in the following order\n\n1. Adjust brightness, saturation, and contrast of the image randomly.\n\n2. Randomly flip the image and mask to left or right.\n\n3. Flip image and mask randomly up or down.\n\n4. Normalization of pixels.\n\nThe infrastructure put in place by Google Cloud Platform uses an nvidia-tesla-t4 of 16 GB GDDR6 in an N1 machine series shared-core.\n\n6.2. Deterministic models\n\nAt training phase, models were optimized using Adam optimizer with a batch size equals to eight. Early stopping was implemented by monitoring loss value on the validation set with a patience of 3. Four loss functions were used, as defined in Sec.(4.2). The pipeline was built using Tensorflow v:2.15\u00b9 and Tensorflow-probability v:0.222. furthermore, we selected three architectures: Unet, Linknet, and FPN, using python library Segmentation Models\u00b3. This module offers several advantages, including ease of implementation, a choice of four model architectures have been proven to be effective for binary segmentation and 25 backbones with pre-trained weights to achieve efficient convergence (Iakubovskii, 2019). These architectures were tested with four loss functions mentioned in Sec. (4.2) and three backbones that have been suggested for use in medical image segmentation: Seresnet101, Densenet169, EfficienNetB7 (Abedalla et al., 2021). A total of 36 iterations of deterministic models were performed for all possible combinations, as shown in the tables Tab.B.3, Tab.B.4, Tab.B.5.\n\n6.3. Bayesian models\n\n6.3.1. Multiplicative Normalizing Flows (MNF)\n\nWe adapted deterministic architectures to a Bayesian approach using the module models from segmentation models. To carry out this task, we utilized MNFConv2D class from tf-mnf module, replacing some strategic Conv2D Tensorflow layers in this code. Moreover, we have modified output layer of these architectures by adding a layer Independent Bernoulli from Tensorflow-probability module. Three architectures with highest IOU metric in test Appendix B, Unet + EB7, FPN + EB7, and Linknet + EB7, were evaluated with three different configurations each, resulting in a total of nine models. The MNFConv2D layers were strategically placed in the networks. All models were trained using the defined NLL loss Eq.(28) function. The nine modified configurations are as follows:\n\n1. UNET: Backbone output - Fig.(2), all layers of the final block of the backbone, last layer of each decoder.\n\n2. FPN: Backbone output, all layers of the final block of the backbone - Fig.(3), output concatenate + output last pyramidal block.\n\n3. Linknet: Backbone output, all layers of the final block of the backbone, last layer of each decoder Fig.(4).\n\n6.3.2. Reparametrizaci\u00f3n Trick\n\nConsidering the best combination of backbone and layer location for each architecture mentioned in the previous section, we replaced light green layers shown in Fig.(2), Fig.(3) and Fig.(4) with Conv2DReparameterization layers from the Tensorflow-probability library. Results of iterations can be found in Tab.(2)."}, {"title": "7. Results", "content": "Considering results achieved in all architectures Unet, FPN and Linknet, and using IOU as the main metric, and secondly, recall, it was determined that EfficientNetB7 is best backbone in terms of performance in iterations of Tab.B.3, Tab.B.4, Tab.B.5. In particular, binary cross entropy loss function was found to be the most efficient for Unet and Linknet architectures. Conversely, for FPN, total loss function was the best alternative. The top-performing model in iterations was Linknet+EB7+BinaryCE, achieving an IOU of 0.941 in test. Otherwise, the model with worst performance was FPN+ Densenet169+ Total loss, with an IOU of 0.78 and recall 0.72 in test. Upon analyzing the tables in Appendix B, it is found that the best configuration for all iterations performed with Densenet169 backbone was FPN + BinaryCE, with IOU = 0.92. The results of the combinations performed with different architectures and loss functions in Densenet169 show the presence of many false negatives. This is evidenced by the recall, which is consistently below 0.8 in most combinations and lower on average than other iterated backbones. In particular, the combination Densenet169 + Total Loss does not work well in any of the architectures and therefore, is not recommended. Similarly, for Seresnet101, the best model was the combination given by FPN + BinaryCE, with an IOU of 0.92. During the deterministic iterations with this backbone, we observed that the IOU was higher than 0.82 in all iterations. A lower sensitivity to detection is seen when employing the Linknet architecture with this backbone, this is evidenced by a higher number of false negatives compared to Unet and FPN. Therefore, the use of the Linknet + Seresnet101 configuration is not recommended either. Furthermore, we could observe that the region-based loss functions Sec. (4.2.1) did not provide a real benefit in improving ROI detection in contrast to other loss functions. This might imply that the class imbalance between the polyp and the background would not be significantly affecting the performance of the models. Moreover, in iterations performed by introducing MNF layers Tab.(1), it was found that the best configurations are those in Fig.(2), Fig.(3) y Fig.(4). MNF model that performed the best was Linknet in Fig.(4) configuration, achieving an IOU of 0.94 in test.\n\n7.0.1. Transformers: Segformer\n\nRecent studies have shown that transformer-based architectures are effective for semantic segmentation, so it is important to consider the potential benefits of using SegFormers in this work. SegFormers use multi-scale overlapping windows and a hybrid attention mechanism to optimize both global and local features (Xie et al., 2021; Wu et al., 2024). This could improve the models ability to detect subtle variations in polyps characteristics. Based on the above, we conducted iterations with SegFormer B0 and SegFormer B5 architectures. However, the latters showed that the SegFormer models were not performing well. The primary metrics, IOU and recall, yielded results of less than 0.7, leading us to discontinue further iterations with these models for this case.\n\n7.1. Architecture\n\n7.1.1. Unet\n\nThe initial iterations for UNET produced results that are summarized in Tab.(B.3). The best results were obtained for the EfficientNetB7 backbone, with an IOU in test greater than 0.9. For the iterations performed with EB7 with four loss functions Sec.(4.2), binary cross entropy performed better in all metrics evaluated, in comparison to other functions. Focusing on iterations with Seresnet101 and Densenet169, it is clear that both models show a acceptable overall performance, with IOU results consistently, above 0.8. Tab.(B.3). In this case, model Unet + Densenet + Total Loss exhibits the lowest recall, of 0.69. Conversely, Unet + Seresnet + BCE model achieved a higher recall (0.89). Therefore, it can be inferred that the latter offers a more balanced performance. Regarding results of Bayesian iterations, we made a direct comparison between UNET + EB7 deterministic architecture Tab.(B.3) and the one with MNF layers Tab.(1). IOU metric and accuracy in test dataset remained unchanged, while recall increased from 0.9 to 0.94. However, accuracy decreased from 0.97 to 0.93, indicating that MNF model is more sensitive to regions classified as polyps, resulting in a higher number of false positives. If we contrast this result with implementation of reparameterization layers in this structure Tab.(2), the metrics decreased, particularly recall (from 0.94 to 0.89) and IOU (from 0.93 to 0.92), resulting in increased false negatives.\n\n7.1.2. Linknet\n\nIn deterministic Linknet iterations, the best result was achieved again with EB7. In regard to loss functions, binary cross entropy outperformed the other functions in all evaluated metrics. Based on the analysis, it can be concluded that both Linknet combined with Seresnet101 and Densenet169 produce acceptable IOU results, with a score above 0.8 Tab.(B.5). However, they show lower recall than EB7 and then, a higher number of false negatives. Despite decent IOU performances, these configurations would not be optimal as they might have issues with under-detection. For Linknet + EB7 contrasting deterministic with MNF method, test metrics remain unchanged, except for a slight increase in precision from 0.96 to 0.97, resulting in a decrease in false positives. In case of reparameterization, performance decreases, lowering IOU from 0.94 to 0.9 and precision, from 0.96 to 0.87. Recall enhances from 0.92 to 0.95, generating high sensitivity and the number of false positives.\n\n7.1.3. FPN\n\nFor FPN architecture in deterministic case, the best result was achieved with EB7. Its IOU and Recall in test were slightly higher than the others, with IOU > 0.9. Among loss functions, total loss was superior to others, achieving an IOU of 0.93 and a recall of 0.94. In contrast to others architectures, EB7+BCE was worst loss function with a IOU = 0.89 and recall = 0.86. Analysis of Tab.(B.4) indicates Densenet169 with FPN has an IOU of approximately 0.8, except for Binary CE where it performed well with an IOU and recall of 0.92. However, this combination has lower recall overall and increased false negatives, particularly when using Densenet169 with FPN and Total loss. On the other hand, Seresnet101 with FPN has similar IOU results at 0.9, except for Jaccard loss, which had an IOU of 0.82 and a significant increase in false negatives. Despite acceptable IOU performance, these combinations exhibit low recall, which may result in under-detection issues. In the Bayesian FPN+EB7 counterpart, IOU slightly enhanced from 0.93 to 0.937, while precision improved from 0.94 to 0.96. At the same time, recall decreased from 0.94 to 0.925, reducing the number of false positives and improving performance. When comparing results obtained through reparameterization trick, IOU drops from 0.93 to 0.91 and recall drops to 0.88, thereby increasing the number of pixels with false negatives.\n\n7.2. Reliable analysis\n\nFig.(5) illustrates a comparison between BNN models with MNF layers Fig.(5b) and their respective deterministic versions (Linknet+EB7+BinaryC\u0415, UNET+EB7+BinaryCE, FPN+EB7+Total Loss), Fig.(5a), can be appreciated. In all three cases, deterministic versions were unable to accurately detect smaller polyps present in the example image. To calculate the mask for BNN models, we take 50 predictions over the input image, average them, and then binarize the result.\n\nConcerning heat maps, we can see that models have a low uncertainty in their predictions, except at the edges of the polyps and in those cases where they are difficult to detect. In the example provided, FPN model is the most sensitive, particularly to small polyps and image reflections compared to other models. In contrast, Linknet exhibited a more balanced performance and showed moderate sensitivity to these challenging cases. On the other hand, UNET model```json\ns show efficiency of architectures tested for semantic segmentation of medical images. The architecture based on Linknet + EfficientnetB7 demonstrated good results in both, deterministic and its Bayesian configuration (MNF layers). It presented a good calibration as well as a balanced option in visual terms and with adequate sensitivity for detecting colorectal polyps. However, FPN architectures with Bayesian layers are noteworthy for their ability to detect polyps that are difficult to identify with naked eye. They performed better than other architectures due to better calibration and uncertainty maps with more contrast between background and polyp edge. According to this study, FPN+ EfficientnetB7 with MNF or reparameterization trick layers was found to be the most suitable option for this aspect. Linknet configuration is also considered a viable option, but caution should be employed in scenarios involving smaller or difficult-to-visualize polyps. Finally, Unet version with reparameterization layers outperformed its MNF counterpart by better handling false positives, resulting in a tighter calibration. However, reparameterization trick approach in Linknet showed lower performance in terms of calibration, leading to an increase in false positives and overestimation of uncertainties in heat maps. This configuration is less recommendable compared to the ones studied, particularly for clinical case of polyp detection where accuracy is critical. The scripts used for different experiments shown in this paper can be found in medical-interpretability-polyp-detection ."}, {"title": "Abbreviations list", "content": "The following is a list of abbreviations used throughout the document.\n\nACS American Cancer Society\n\nADS Automatic Detection Systems\n\nBNN Bayesian Neural Networks\n\nD169 DenseNet169\n\nDNN Deep Neural Networks\n\nEB7 Efficient NetB7\n\nECE Expected Calibration Error\n\nMNF Multiplicative Normalizing Flows\n\nMIS Medical Image Segmentation\n\nNCI National Cancer Institute\n\nNLL Negative Log-Likelihood\n\nRT Reparameterization Trick\n\nS101 SeresNet101\n\nWHO World Health Organization"}]}