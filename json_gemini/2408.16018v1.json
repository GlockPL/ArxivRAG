{"title": "SPICED: Syntactical Bug and Trojan Pattern Identification in A/MS Circuits using LLM-Enhanced Detection", "authors": ["Jayeeta Chaudhuri", "Dhruv Thapar", "Arjun Chaudhuri", "Farshad Firouzi", "Krishnendu Chakrabarty"], "abstract": "Analog and mixed-signal (A/MS) integrated circuits (ICs) are crucial in modern electronics, playing key roles in signal processing, amplification, sensing, and power management. Many IC companies outsource manufacturing to third-party foundries, creating security risks such as stealthy analog Trojans. Traditional detection methods, including embedding circuit watermarks or conducting hardware-based monitoring, often impose significant area and power overheads, and may not effectively identify all types of Trojans. To address these shortcomings, we propose SPICED, a Large Language Model (LLM)-based framework that operates within the software domain, eliminating the need for hardware modifications for Trojan detection and localization. This is the first work using LLM-aided techniques for detecting and localizing syntactical bugs and analog Trojans in circuit netlists, requiring no explicit training and incurring zero area overhead. Our framework employs chain-of-thought reasoning and few-shot examples to teach anomaly detection rules to LLMs. With the proposed method, we achieve an average Trojan coverage of 93.32% and an average true positive rate of 93.4% in identifying Trojan-impacted nodes for the evaluated analog benchmark circuits. These experimental results validate the effectiveness of LLMs in detecting and locating both syntactical bugs and Trojans within analog netlists.", "sections": [{"title": "I. INTRODUCTION", "content": "Analog and mixed-signal (A/MS) integrated circuits (ICs) play a critical role in signal processing, amplifiers, sensors, and power management systems. Many IC companies such as Intel, AMD, Qualcomm, and Texas Instruments opt to outsource the manufacturing and fabrication of their analog designs to third-party foundries to avoid expensive capital expenditures as well as substantial costs associated with investing in manufacturing infrastructure. The globalization of the semiconductor industry and the outsourcing of analog ICs to third-party vendors have introduced significant security threats. These threats notably compromise the integrity of ICs, making them vulnerable to analog Trojans [1] [2] [3]. A major risk arises from the possibility of embedding stealthy Trojans that evade detection under normal operating conditions [4] [5].\n\nTrojans occupy minimal area footprints, enabling their easy integration into larger, complex A/MS designs at the netlist level, which includes multiple paths and transistor components. These stealthy components are activated only during specific operating bias voltages and remain dormant otherwise. Prior work on analog Trojan detection utilizes current-sensing amplifiers to identify Trojan activation [6]. A recent study introduces a sensitivity analysis-based framework leveraging analog neural twins to detect stealthy analog Trojans [7]. This approach identifies the critical paths most vulnerable to Trojan insertion [8]. Next, circuit watermarks are embedded to monitor deviations in these paths, triggering an alert when a Trojan is activated. While these methods are effective in detecting Trojans, they do not address the challenge of locating Trojan-impacted nodes within the design netlist, a task that becomes increasingly difficult as circuit complexity grows.\n\nThe recent advancements in Large Language Models (LLMs) have showcased their significant capabilities across various tasks including code generation and optimization. Such advancements in the EDA domain naturally position LLMs as highly potent for novel applications in A/MS design. Traditional methods for Trojan detection, including embedding circuit watermarks or conducting hardware-based monitoring, frequently impose significant area and power overheads, especially in large analog designs. To address this issue, we propose SPICED, an LLM-based framework that operates within the software domain, thereby eliminating the need for any hardware modifications to the analog design for Trojan detection and localization. SPICED excels at intelligent parsing and analysis of large volumes of structured data such as SPICE netlists. In addition to Trojan localization, the proposed LLM-based framework provides comprehensive analysis and detailed diagnosis of the detected anomalies. By leveraging a deep understanding of the HSPICE language, simulation logs, and the topological structure of netlists, SPICED can not only distinguish between Trojan-free and Trojan-inserted netlists but also precisely identify the specific Trojan components and the nodes affected by the Trojan. The key contributions of this paper are as follows:\n\n\u2022 Introduction of SPICED: Presenting SPICED, the first LLM-based framework for Trojan detection in A/MS design that requires no hardware modifications.\n\n\u2022 Syntactical Bug Mitigation: Leveraging in-context learning and Chain-of-Thought (CoT) prompting to detect and mitigate syntactical bugs in SPICE netlists.\n\n\u2022 Precise Trojan Detection and Localization: Developing supervised learning rules for the LLM to identify Trojan circuits and the Trojan-affected nodes in an analog design.\n\nThe remainder of the paper is organized as follows. Section II provides a comprehensive overview of recent work on LLM-"}, {"title": "II. BACKGROUND AND MOTIVATION", "content": "A. Design Automation using LLMs\n\nLLMs have been integrated into multiple stages of EDA, enhancing processes from code generation and placement and routing to security measures, thereby streamlining and improving the overall design workflow. Recent work used LLM for Verilog code generation by fine-tuning existing LLM with Verilog datasets [9]. Fine-tuned open-source CodeGen LLM outperformed state-of-the-art commercial LLM in generating functionally correct designs [14]. [12] used LLM-based iterative flow to design an 8-bit accumulator-based microprocessor architecture. [11] proposed LLM for generating analog circuits with a feedback-enhanced flow to enable self-correcting design of analog circuits. The feedback allowed generation of circuits without any LLM training involved. Domain-Adaptive Pre-Training (DAPT) followed by Supervised Fine-Tuning (SFT) of foundation LLM models enabled an assistant chatbot for chip design [13]. [17], [18] proposed LLM-based script generation to facilitate the EDA design flow. In the context of security, LLM is shown to be effective in structural generation of digital Trojans [15] as well as fixing syntactical bugs in Verilog codes [16]. These works are focused mainly on code generation tasks and bug detection in the digital domain, as shown in Table I.\n\nB. Nature of Analog Trojans\n\nAn analog Trojan consists of two primary components: (1) Trigger circuit, which is conditionally gated with an AND or OR gate to activate the Trojan only upon specific toggling instructions; (2) Detector circuit, which detects the charge buildup of the capacitive component of the Trojan circuit, and when the capacitor voltage reaches a threshold, activates the payload. Recent work shows the impact of an analog Trojan, namely A2 [4] that can be stealthily inserted during the design and fabrication phases of an analog design. Due to its small footprint, it can be maliciously inserted in unused parts during design phase. The trigger for the A2 Trojan is software-controlled i.e., the trigger is activated when a rare instruction is executed. As an extension to the A2 Trojan, authors in [5] shows the implementation of the DELTA Trojan, which uses a glitch generator for the trigger circuit, and can be inserted in any net of a circuit irrespective of it being rarely activated. In [8], it has been demonstrated that A2 Trojans remain mostly dormant due to their insertion in the less sensitive paths of a circuit. Upon their activation, the primary output voltage behavior is impacted, leading to significant performance degradation. Therefore, it is necessary to detect and localize these malicious circuits within the analog design netlist before the netlist is sent to the fabrication stage.\n\nC. Prior Work on Analog Trojan Detection\n\nIn [6], a current sensing-based circuit is inserted in a digital design to detect analog Trojans such as A2 at run-time. A recent work [8] demonstrates the impact of analog Trojans (A2, DELTA, and large-delay Trojans) on A/MS designs as well. In [8], analog neural twins are employed to identify critical paths in an analog circuit netlist through sensitivity analysis. After identifying critical paths, circuit watermarks are inserted to make these paths observable at the circuit output. Sensitizing the least sensitive paths of a circuit makes the detection of stealthy Trojans easier. This ensures that even if the effects of the Trojans are not captured at the primary output of the circuit, they can still be detected through the altered behavior of the sensitized paths.\n\nAlthough [8] effectively identifies all the Trojan hotspots, there are two significant limitations: (1) the area overhead associated with added watermarks increases with the complexity of the analog design, and (2) the specific Trojan-inserted nodes are not identified, i.e., localization of the detected Trojans is not performed; this limitation makes it difficult to pinpoint the exact nodes affected by the Trojans, making targeted mitigation infeasible.\n\nThese limitations motivate the exploration of specialized techniques that leverage the contextual ability of LLMs. LLMs are vastly known for interpreting and generating texts, and are capable of interpreting contexts across various programming languages such as C, C++, and Python. A significant portion of the training data for LLMs is sourced from Github repositories. LLMs such as Llama-2 and Llama-3 are primarily trained on Python datasets [19]. In the realm of digital design, the availability of Verilog code in training datasets is relatively limited compared to other programming languages [11]. The scarcity is even more for analog design data, particularly for the SPICE language, which has less code available in open-source repositories. This poses a challenge for LLMs like Llama 2 and GPT-3.5 to understand SPICE syntax comprehensively. Despite these challenges, GPT-3.5 shows the capability of understanding basic SPICE syntax and type of circuit configuration being implemented in a SPICE netlist. Leveraging LLMs for design analysis offers several advantages.\n\n\u2022 Textual analysis capability: Aided by the right prompts, LLMs can effectively parse simulation log files without"}, {"title": "III. LLM FOR SYNTACTICAL BUG DETECTION", "content": "Fig. 1 illustrates the proposed flow of guiding the LLM to detect a wide range of syntactical bugs while reducing the likelihood of incorrectly flagging correct lines as syntax errors. Note that this method does not involve any LLM fine-tuning; instead, it focuses on improving the bug detection capability of LLM through refinement of SPICE syntax rules based on real-time feedback. The steps involved are as follows:\n\n1) Begin with an initial set of SPICE syntax rules and use them to construct the LLM prompt to identify and locate syntactical bugs within a SPICE netlist (shown in Fig. 2(a)).\n\n2) When the LLM identifies the bug correctly, it specifies the type of the detected bug and its location in the netlist (shown in Fig. 2(b)).\n\n3) A false positive occurs when the LLM incorrectly identifies a line as containing a bug. If the LLM incorrectly flags a line as buggy, this feedback is used to manually update and refine the syntax rules in the prompt (shown in Fig. 2(c)).\n\n4) After updating the rules, the refined prompt is applied to the same netlist. The process is repeated until the number of false positives is minimized.\n\nWe use the updated set of syntax rules for evaluation. Additionally, we prompt the LLM to generate a structured bug detection report. The report includes the following items:\n\n1) List of all syntactical bugs in the SPICE netlist: The bugs may include connection error (missing connections or floating nodes in the netlist), insertion error (unintended or intended insertion of additional transistor components), and incorrect specifications of parameters.\n\n2) Location of the bugs in the SPICE netlist: Lines in the SPICE netlist where the bug is located, including the component or connection names.\n\n3) Suggestions for correction: Provides a list of recommended actions to correct the bugs and generate a revised netlist."}, {"title": "IV. SUPERVISED LEARNING-BASED FRAMEWORK USING LLM FOR TROJAN DETECTION", "content": "While Section III focuses on identifying and correcting syntactical bugs in the SPICE netlist, this section addresses functional bug detection, particularly targeting analog Trojans. A Trojan-impacted node is defined as one of the circuit nodes where the Trojan is inserted or which is part of the trigger node. From prior work on analog Trojan detection [8] [6], the following observations are noted regarding the current and voltage behavior of Trojan-impacted nodes.\n\n1) Deviation in primary output voltage: As observed in [8], when a Trojan is inserted into one of the sensitive paths of an analog design, its impact is captured at the primary output voltage. Specifically, the output voltage exceeds the desired specifications when the Trojan is activated.\n\n2) Anomalous deviation in circuit intermediate nodes: Nodes impacted by the Trojan, or the neighboring nodes exhibit significant deviations in voltage behavior when the Trojan is activated. This deviation can serve as a critical indicator of the presence of a Trojan.\n\n3) Anomalous surge in MOSFET current: According to [6], upon Trojan activation, some MOSFETs within the analog design draw a substantially higher current. This current behavior deviates significantly from the normal current behavior observed when the Trojan circuit is dormant.\n\nFor identifying analog Trojans and the Trojan-impacted nodes, we used these observations to craft supervised-learning rules. We then created prompts based on these rules to teach the LLM to detect anomalies in the current and voltage simulation logs. The simulation logs are obtained by running HSPICE simulation on analog netlists. The procedure of teaching the supervised learning approach (shown in Fig. 3 (a)) to the LLM is shown in Fig. 3(b). We link each Trojan characteristic to a specific supervised learning rule as follows:\n\n1. Deviation in primary output voltage\n\n\u25a0 Supervised Learning Rule 1: We craft prompts that"}, {"title": "V. EXPERIMENTAL RESULTS", "content": "A. Experimental Setup\n\nFor both bug detection and Trojan detection experiments, we evaluate a wide variety of analog benchmark circuits that are selected from the OpenSource netlist dataset from AMSNet [10] and Github [20]. These circuits include differential amplifier, inverter, OPAMP, and bandpass filter, thus providing a comprehensive dataset for evaluating both syntactical bug and Trojan detection capabilities of the LLM. We have compiled a total of 18 syntactical bugs from [21]. We choose varying complexity of bugs to test the effectiveness of LLM in identifying bug-inserted SPICE netlists. The bug complexity is classified as: easy, medium, and difficult. The bug benchmark used for LLM evaluation is shown in Table II. The benchmark includes 4 easy, 6 medium, and 8 difficult syntactical bugs that can be present in a SPICE netlist.\n\nFor the Trojan-detection experiments, we evaluate the well-known analog Trojan explored in recent literature - A2 [4]. This type of Trojan occupies small footprint and hence, can be easily embedded in the netlist stage by an untrusted foundry. We embed A2 in the SPICE netlist of an analog benchmark circuit to generate a Trojan-inserted netlist. The Trojan is considered to be internally triggered by an intermediate node of the analog design, thus emulating a realistic attack scenario shown in [22]. For our experiments, we use the GPT-3.5-turbo API. The experiments are carried out on an NVIDIA A100 GPU. Table III lists the information available to the LLM for performing bug and Trojan detection tasks.\n\nB. Evaluation Metrics\n\nWe use the following metrics to evaluate the effectiveness of the LLM in syntactical bug and Trojan detection.\n\n\u2022 Bug coverage (in %): This metric represents the percentage of syntactical bugs detected by the LLM out of the total number of bugs embedded within a SPICE netlist.\n\n\u2022 Bug resolved (in %): It represents the percentage of detected syntactical bugs that are correctly fixed by LLM.\n\n\u2022 Trojan identified: It indicates whether the LLM has correctly detected at least one Trojan component in the netlist.\n\n\u2022 Trojan coverage (in %): This metric calculates the ratio of the number of malicious components (transistor, resistor, or capacitor) embedded in the SPICE netlist that are correctly identified by the LLM and the total number of Trojan-injected components in the netlist.\n\n\u2022 Precision (in %): It indicates the percentage of correctly predicted Trojan-impacted nodes out of all the predicted impacted nodes. It is denoted by $Precision = \\frac{TP}{TP+FP}$, where TP and FP indicate the true positive and false positive counts, respectively.\n\n\u2022 Recall (%): It is indicated by the percentage of correctly predicted Trojan-impacted nodes out of the actual number of Trojan-impacted nodes. It is denoted by: $Recall = \\frac{TP}{TP+FN}$, where TP and FN indicate the true positive and false negative counts, respectively.\n\nC. Performance Evaluation of GPT Model\n\n1) Syntactical Bug Detection\n\nThe bug detection results are shown in Table IV. We observe that GPT-3.5 demonstrates higher accuracy and broader bug coverage across all evaluated SPICE netlists. Additionally, the proposed instruction-following approach results in fewer false positives for the evaluated bugs compared to the scenario when instructions were not explicitly provided in the prompt.\n\n2) Functional Bug (Trojan) Detection\n\nTo test the inherent capability of LLM to analyze structured prompts and to further improve its accuracy through well-crafted prompts based on supervised-learning rules and few-shot examples, we evaluate the following four test cases:\n\n1) FS: We evaluate the LLM by providing only few-shot examples.\n\n2) R: We provide supervised-learning rules without any few-shot examples.\n\n3) RFS: We provide supervised-learning rules followed by few-shot examples such that LLM can correlate the examples with the established rules, and use these examples to determine the Trojan-impacted nodes for a new test netlist based on these rules.\n\n4) Rs: We incorporate Rule #2 instead of Rule #1 (see Supervised Learning Rule 2), keeping the other rules unchanged, followed by few-shot examples.\n\nTo increase the complexity for LLM evaluation, we scrambled the Trojan components and nodes within the netlist as well as changed the parameters, such as the width-to-length (W/L) ratios of transistors and the capacitor values. The Trojan-inserted netlists used for the experiments are labeled as 'netlist_troj_n', where netlist is the specific circuit chosen from the AMSNet repository [10] and n indicates the netlist node where the Trojan payload is activated. Evaluation results are shown in Table V. We observe that incorporating the supervised-learning rules lead to a higher precision as well as overall accuracy in identifying the Trojan-impacted nodes. Additionally, the combination of few-shot examples with these rules enables the LLM to successfully identify the Trojan circuit in the benchmark netlists. The proposed method shows superior Trojan coverage and accuracy of Trojan-impacted nodes compared to scenarios where only few-shot examples are used without providing the supervised-learning rules."}, {"title": "VI. CONCLUSION", "content": "We have explored both syntactical and functional bug detection capabilities of the LLM. The proposed instruction-following approach significantly reduces the number of false positives while achieving high bug coverage. Additionally, by curating prompts with few-shot examples and CoT, LLM efficiently localizes the Trojan-impacted nodes for a range of Trojan-insertion scenarios while incurring zero area and power overheads. By incorporating the supervised learning rules in the prompt, we achieve an average Trojan coverage of 93.32% and an average true positive rate of 93.4% in identifying Trojan-impacted nodes for the evaluated analog benchmark circuits. This opens up new directions for securing analog designs from threats arising anywhere between design and fabrication stages of the chip."}]}