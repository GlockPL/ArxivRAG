{"title": "Quantum-secure multiparty deep learning", "authors": ["Kfir Sulimany", "Sri Krishna Vadlamani", "Ryan Hamerly", "Prahlad Iyengar", "Dirk Englund"], "abstract": "Secure multiparty computation enables the joint evaluation of multivariate functions across distributed users while ensuring the privacy of their local inputs. This field has become increasingly urgent due to the exploding demand for computationally intensive deep learning inference. These computations are typically offloaded to cloud computing servers, leading to vulnerabilities that can compromise the security of the clients' data. To solve this problem, we introduce a linear algebra engine that leverages the quantum nature of light for information-theoretically secure multiparty computation using only conventional telecommunication components. We apply this linear algebra engine to deep learning and derive rigorous upper bounds on the information leakage of both the deep neural network weights and the client's data via the Holevo and the Cram\u00e9r-Rao bounds, respectively. Applied to the MNIST classification task, we obtain test accuracies exceeding 96% while leaking less than 0.1 bits per weight symbol and 0.01 bits per data symbol. This weight leakage is an order of magnitude below the minimum bit precision required for accurate deep learning using state-of-the-art quantization techniques. Our work lays the foundation for practical quantum-secure computation and unlocks secure cloud deep learning as a field.", "sections": [{"title": "Introduction", "content": "Although deep learning has revolutionized multiple domains [1-3], its applications are constrained by increasing computational demands on the hardware [4-6]. Given the high energy consumption required for state-of-the-art deep neural network (DNN) inference [7-9], it is common to delegate inference workloads from the edge to centralized server clusters. Unfortunately, this paradigm introduces vulnerabilities that compromise data security, which is crucial in applications such as business, finance, and healthcare [4]. This situation underscores the central challenge in secure computation, where multiple parties perform a joint evaluation of multivariate functions across distributed resources while preserving the privacy of their inputs [10] (Fig. 1(a)).\nModern secure computation schemes are built on homomorphic encryption, which allows universal computation on encrypted data and preserves the security of both the inputs and the outputs of the computation [11]. Recent developments have adapted state-of-the-art homomorphic encryption schemes for secure machine learning [12], but real-world applications are limited due to their massive computational overhead [6] and recently discovered security vulnerabilities [13]. Moreover, these encryption schemes typically depend on computational complexity and are not information-theoretically secure.\nIn this work, we introduce a linear algebra engine for information-theoretically secure computation. We apply our engine to multiparty deep learning and derive rigorous security analysis for all parties. Applied to the MNIST classification task, we obtain test accuracies of more than 96% while leaking less than 0.1 bits per weight symbol and 0.01 bits per data symbol. This weight leak-"}, {"title": "Coherent linear algebra engine", "content": "Our protocol is based on a coherent optical linear algebra engine utilized by two parties in a network: the \"server\", which possesses a matrix W of dimensions M \u00d7 N representing a DNN linear layer, and the \u201cclient\u201d, which holds the data vector x of length N. The matrix-vector product Wx is computed through M inner products Wix for i \u2208 {1, ..., M}, each of which involves three steps:\n1. The server transmits a logical weight vector Wi encoded into the complex amplitudes of coherent states w. The amplitudes of these physical"}, {"title": "Classification accuracy", "content": "In this section, we calculate the classification accuracy of a secure neural network that uses our coherent linear algebra engine on the standard MNIST classification task. To this end, we first trained a digital noiseless neural network on the MNIST dataset and got a classification accuracy of 98%. Then we fed the trained weights into a PyTorch model of our optical architecture to evaluate the test accuracy of our secure optical neural network, see Section 7.2 for more details.\nWe calculate the classification accuracy as a function of the average photon number occupation \u00b5 and the amplification gain G, see Section 7.2. We obtain more then 96% classification accuracy with an average photon number of less then \u03bc = 4 per weight and amplification gain of G = 3.\nIn contrast to previous studies in optical machine learning [30, 36], we do not measure all of the light sent to the client but only the portion corresponding to (w\u22c5x)2 and yet obtain similar high accuracies. This fundamentally follows from the fact that the SNR in the inner product is the similar whether one optically routes the inner product amplitude to one mode and measures it vs. measuring all the modes and calculating the inner product digitally."}, {"title": "Security analysis", "content": "In this section, we use the verification state pu returned to the server by the client to calculate an upper bound on the amount of information about w, in terms of number"}, {"title": "Weights leakage", "content": "of bits, that could be learned by an arbitrary dishonest client. A dishonest client tries to learn the weights using arbitrary operations other than the operations defined by our protocol.\nHere, we assume that the dishonest operations are independent and identically distributed on all the incoming modes of w; the client employs separable ancilla states that interact individually with each weight mode. The ancilla states are stored in a quantum memory until the end of the attack and subsequently measured independently from one another to reveal information about w. Our security analysis for the weight leakage relies on results for quantum encryption [44-48] and proceeds via the Holevo theorem [37]; see Section 7.3.1 for the complete analysis.\nWe present here the final mathematical result for the weight leakage. Representing the weight occupation by \u03bc and defining the quantities:\n$a := 2\\mu + 1$\n$b := 2\\mu + 1 + N_i$\n$c := \\sqrt{4\\mu^2 + 2\\mu + 1}$\n$z := \\sqrt{(a + b)^2 - 4c^2}$,\nthe weight leakage Iw; is bounded by the Holevo theorem:\n$I_{W_i} \\leq g(\\nu_1) + g(\\nu_2) - g(\\nu_3)$,\nwhere\n$g(\\nu) = \\frac{\\nu + 1}{2} \\log_2(\\frac{\\nu + 1}{2}) -  \\frac{\\nu - 1}{2} \\log_2(\\frac{\\nu - 1}{2})$\n$\\nu_{1,2} = \\frac{1}{2} (z \\pm [b - a])$\n$\\nu_3 = \\frac{c^2}{b + 1}$\nThis inequality is shown to be tight by analyzing the entangling cloner attack [46]. The derivation of Eq. (2),\nand more details, can be found in Section 7.3.1.\nThe leakage is calculated for one query, that is, a single exposure of the client to the weights. To prevent information leakage after multiple uses of the model, the server sends the client invariants of the DNN model under affine transformations consisting of different individual weights while parameterizing the same model function and, therefore, conserving the inference output; see 7.3.2."}, {"title": "Data leakage", "content": "To calculate the data leakage, we consider an honest client and a dishonest server. In this setting, the server sends a weight matrix W of shape M \u00d7 N to the client and aims to evaluate the client's data vector x of length N using M measurements of the verification state.\nWe recall from Section 2 that the mode i of the verification state U\u2020G(Ux) has the mean wi and variance (1 + ni SNU), Eq. (1). In other words, information about the client's data x is leaked to the server not through the mean of the verification state, but through its variance. The client may control this leakage by reducing the gain Gin its amplification-and-splitting step. We also note that since the client is honest, it announces the true gain G to the server."}, {"title": "Secure classification", "content": "Now that we have a mathematical handle on both the weight (Eq. 2) and the data leakage (Eq. 3), we can ask how they trade off against each other if one requires a constant test accuracy. For this purpose, we revisit the classification accuracy that we computed numerically as a function of the two hardware configuration parameters of the system, the server average photon occupation per weight and the client gain G (see Fig. 6 in the Methods section). Recalling that the weight leakage and the data leakage are both functions of the hardware configuration parameters, we perform a change of variables and replace the axes in Fig. 6 with weight and data leakage to obtain the tradeoff result in Fig. 2. Note that the data leakage is calculated for the quantum adversary (k = 2).\nThe figure depicts a clear tradeoff of the data leakage and weight leakage in order to maintain classifica-"}, {"title": "Discussion", "content": "Our current protocol forces a trade-off between security for classification accuracy; future generations could relax this trade-off by joint optimization of DNN model param-"}, {"title": "Methods", "content": ""}, {"title": "Optical implementation", "content": "The server consists of two modules, the transmitter and the receiver (see Fig. 4(a)). The transmitter module I/Q modulates the neural network weights onto a train of weak coherent states which are produced by attenuating a continuous wave laser to the few-photon limit. The receiver module measures the modulated quadratures of the incoming verification state using homodyne detection with a reference local oscillator. The optical power difference between the two output arms is proportional to either the I or the Q quadrature of the verification state, depending on the phase of the local oscillator.\nWe propose multiple optical implementations of the unitaries U and U\u2020 at the client. The client could operate via time domain encoding using optical loops [53] (see Fig. 4(b)). Equivalently, the client could operate by spatial domain encoding using a mesh of interferometers [54, 55] (see Fig. 4(c)) or free-space multi-plane light converters [56-58]. Time-domain implementations are promising for large-scale universal optical information processing because the number of elements does not scale with the number of optical modes [59-61]. Due to optical loss, however, both technologies are currently limited to a few dozen modes.\nIn the time domain design, optical modes are defined by temporally separate pulses. The first operation U is implemented by a Mach-Zehnder interferometer (MZI) and a fiber loop. This structure allows us to interfere successive pulses from the incoming pulse train w with a pulse in the loop that contains the running sum of the inner product, resulting in the final inner product w\u22c5x being written into the complex amplitude of the last output pulse. The light in this mode is then amplified by a factor of G using a phase-insensitive amplifier such as a standard erbium-doped fiber amplifier. Then a beam splitter divides the light with a splitting ratio of $1 - \\frac{1}{G} : \\frac{1}{G}$ for the transmitted and reflected ports. The transmitted"}, {"title": "Quantum description", "content": "Phase-insensitive amplifier\nWe use the quantum electromagnetic field ladder operators (or annihilation and creation operators), denoted by \u00e2 and a\u2020, respectively, to analyze the behavior of the system at the quantum level. The action of these operators on the photon number states |n\u27e9 is given by:\n$\\hat{a}|n\\rangle = \\sqrt{n}|n - 1\\rangle$ and $\\hat{a}^{\\dag}|n\\rangle = \\sqrt{n + 1}|n + 1\\rangle$\nThe input-output relationship of the ladder operators in the Heisenberg picture for a phase-insensitive amplifier with gain G is [62]:\n$\\hat{a}_{amp} = \\sqrt{G}\\hat{a}_{in} + \\sqrt{G - 1}\\hat{a}_v$\nwhere \u00e2in is the annihilation operator for the input mode, \u00e2amp is the annihilation operator for the amplified output mode, and \u00e2v is the annihilation operator for the auxiliary vacuum noise mode introduced during amplification.\nThe quadrature operators are defined as:\n$X = \\hat{a} + \\hat{a}^{\\dag},  P = \\frac{(\\hat{a} - \\hat{a}^{\\dag})}{i}$\nThe variance for an operator \u00d4 is given by:\n$\\langle(\\Delta\\hat{O})^2\\rangle = \\langle\\hat{O}^2\\rangle - \\langle\\hat{O}\\rangle^2$\nThen, the following is true for the input mode:\n$\\langle(\\Delta \\hat{X}_{in})^2\\rangle = 1,  \\langle(\\Delta \\hat{P}_{in})^2\\rangle = 1$\nFor the output mode of the phase-insensitive amplifier:\n$X_{amp} = \\hat{a}_{amp} + \\hat{a}_{amp}^{\\dag},  P_{amp} = \\frac{(\\hat{a}_{amp} - \\hat{a}_{amp}^{\\dag})}{i}$\nSubstituting the expression for \u00e2amp:\n$X_{amp} = \\sqrt{G}X_{in} + \\sqrt{G - 1}X_{v}$\n$P_{amp} = \\sqrt{G}P_{in} - \\sqrt{G - 1}P_{v}$\nThe variance of the quadratures after amplification is:\n$\\langle(\\Delta \\hat{X}_{amp})^2\\rangle = \\langle(\\sqrt{G}X_{in} + \\sqrt{G - 1}X_{v})^2\\rangle = 2G - 1$\n$\\langle(\\Delta \\hat{P}_{amp})^2\\rangle = 2G - 1$\nThis shows that the noise is amplified along with the signal, and for large G, the noise variance scales linearly with G.\nWeighted beamsplitter\nThe beam splitter has a splitting ratio of $(1 - \\frac{1}{G}: \\frac{1}{G})$. In the spatial domain picture, the input modes for the beam splitter are the amplified output \u00e2amp and a vacuum mode, labeled \u00e2vac. The weighted beamsplitter transform yields:\n$\\hat{a}_{out1} = \\sqrt{1 - \\frac{1}{G}}\\hat{a}_{amp} - \\frac{1}{\\sqrt{G}}\\hat{a}_{vac}$\n$\\hat{a}_{out2} = \\frac{1}{\\sqrt{G}}\\hat{a}_{amp} + \\sqrt{1 - \\frac{1}{G}}\\hat{a}_{vac}$"}, {"title": "Classification accuracy calculation", "content": "To analyze our protocol's performance for deep learning, we compute the classification accuracy for the standard MNIST classification task using PyTorch. To this end, we wrote custom neural network layers that implement our coherent linear algebra engine presented in section 2; several of these custom layers were strung together to form a secure neural network. The detected homodyne current in each custom layer is sampled from a unit Gaussian distribution N(0,1 SNU) to account for the quantum shot noise in each quadrature. The resultant noisy sample is then fed to the non-linear ReLU activation function before being passed on to the next custom layer.\nSeparately, we trained a digital model composed of standard PyTorch layers on preprocessed MNIST images. The preprocessing of the data set included the flattening of the 28 \u00d7 28 images to vectors of size 784, followed by centering and scaling of each vector to the range [-1, 1]. Then we trained a standard 2-layer network with 784 inputs, 784 hidden neurons, and 10 outputs, obtaining a classification accuracy of 98%. We then transferred these trained digital weights into the custom secure neural network and computed the accuracy achieved by the secure protocol as a function of the weight pulse energy. We found that the accuracy of the digital and analog models were in agreement up to variations caused by quantum shot noise.\nThe real operations required for standard deep learning tasks can be implemented on our complex-valued hardware by encoding the real input vector x(R) of length N and the real weight matrix W(R) of size M \u00d7 N into a complex input vector x(C) of length N/2 and a complex weight matrix W(C) of shape M \u00d7 N/2 using the following procedure:\n$W^{(C)}_{i,k} = W^{(R)}_{i,2k-1} - i W^{(R)}_{i,2k} \\hspace{0.5cm}  \\vec{x}^{(C)}_{k} = \\vec{x}^{(R)}_{2k-1} + i \\vec{x}^{(R)}_{2k}$\nThe hardware computes the real value of the product W(C)x(C), which is precisely the desired matrix-vector product W(R)x(R) required for the DNN computations.\nWe define the signal-to-noise ratio (SNR) at the homodyne detector at the neural network outputs as\n$SNR_i = \\frac{G(G - 1)}{2G^2 - 3G + 2} \\frac{\\mu}{\\sqrt{\\mu}} \\frac{|W_i \\cdot x|^2}{\\sqrt{\\mu}}$\nwhere The amplitudes of these physical states, wj, encode the logical weights as $w_j = \\sqrt{\\frac{W_{ij}}{\\|W\\|_{RMS}}}$, where ||W||RMS denotes the root mean square of the elements in W. Therfore we have:\n$SNR_i = \\frac{G(G - 1)}{2G^2 - 3G + 2}  \\frac{\\mu}{\\|W\\|_{RMS}} |W_i \\cdot x|^2$\nNote that in order to get the desired inner product, the client scales the result digitally by $\\frac{\\|x\\| \\|W\\|_{RMS}}{\\sqrt{\\mu}}$However, for the purpose of deep learning, the scaling step for the client is superfluous because the client normalizes between layers regardless. We define a \"physical scaling parameter\" F to capture the hardware-dependent prefactor in the SNR equation,\n$F := \\sqrt{\\frac{G(G - 1)}{2G^2 - 3G + 2}}$\nVarying F changes the SNR of the inner product outputs, thereby affecting the accuracy of the secure neural network. The purpose of defining this parameter is to enable the calculation of classification accuracy as a function of the gain G and average photon occupation \u03bcwithout directly executing the intensive numerical calculations in the two-dimensional space spanned by these two parameters. Instead, we calculate the classification accuracy within the space spanned by F. The dependency of the test accuracy achieved by the secure neural network on F is presented in Fig. 5. We further find that a logistic function faithfully fits the variation of the classification accuracy as a function of F:"}, {"title": "Detailed security analyses", "content": "We analyze the security of this protocol following the standard security analysis for continuous-variable quantum key distribution (CVQKD).\nFirst, we express the setting of our problem in the continuous-variable quantum key distribution (CVQKD) framework. In a standard CVQKD setting, two legitimate parties Alice and Bob wish to communicate a message under possible attack by a third-party eavesdropper Eve external to both of them. In the CVQKD protocol,"}, {"title": "Weights Leakage", "content": "From the perspective of a malicious client, the server prepares displaced coherent states with quadrature components q and p that are realizations of two i.i.d. random variables Q and P. These random variables are normally distributed as Q, P \u223c N(0, Vmod), where Vmod denotes the modulation variance.\nHere we analyze the security against individual attacks, defined above, on the incoming modes of w sent by the honest server.\nHolevo bound x for the information held by Eve's substate PE = TrAB(|\u03c8\u27e9 \u27e8\u03c8|) about the quantum state PAB shared between Alice and Bob is given by [46]:\n$\u03c7 = S_E - S_{E|A} = S_{AB} - S_{B|A}$\nwhere Sxy is the conditional von Neumann entropy of the density matrix px given the density matrix py.\nThe von Neumann entropy of a quantum state can be expressed in terms of the symplectic eigenvalues of that state's covariance matrix. The symplectic eigenvalues of a 2N \u00d7 2N matrix are defined as the absolute values of the ordinary eigenvalues of the matrix \u03a3 = \u03a9\u03a3 where \u03a9 is the 2N \u00d7 2N matrix given by the direct sum:\n$\\Omega = \\oplus_{i=1}^N \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}$\nIt follows that a Gaussian state with covariance matrix \u03a3 has a von Neumann entropy given by $S = \\sum_{i} g(\\nu_i)$, where\n$g(\\nu) = (\\frac{\\nu + 1}{2}) log_2(\\frac{\\nu + 1}{2}) - (\\frac{\\nu - 1}{2}) log_2(\\frac{\\nu - 1}{2})$\nand vi is the i-th symplectic eigenvalue of \u03a3 (see [46] for details).\nTo calculate SAB, we calculate the symplectic eigenvalues of \u03a3\u0391\u0392:\n$\\nu_{1,2} = \\frac{1}{2} (z \\pm [b - a])$\nwhere\na := V\nb := T(V \u2212 1) + 1 + \u03be\nc := \u221aT(V2 \u2212 1)\nz := \u221a(a + b)2 \u2212 4c2,\nThen, we have SAB = g(\u03bd1) + g(\u03bd2). Note that in Section 4 we presented these quantities using the occupation \u03bc = V and T = 1. We analyze the effect of optical loss where the transmission T < 1 in Section 5.\nWe calculate SB|A assuming that Bob implements homodyne detection. The covariance matrix \u03a3B|A is given by:\n$\\Sigma_{B|A} = \\Sigma_{B} - \\frac{1}{\\Sigma_{A}+1} \\Sigma_{C} \\sigma_z $\nwhere \u03a3B = b1, \u03a3C = c\u03c3z, Va = a, and a, b, and c are defined as above. Using these definitions, we obtain\n$\\Sigma_{B|A} = \\begin{pmatrix} b & 0 \\\\ 0 & b \\end{pmatrix} - \\frac{1}{a + 1} \\begin{pmatrix} c & 0 \\\\ 0 & -c \\end{pmatrix} = \\frac{1}{a + 1} \\begin{pmatrix} b_2-c_2 & 0 \\\\ 0 & b - c\\end{pmatrix}$\nIts symplectic eigenvalue is:\n$V3 = \\frac{b-c}{a+1}$\nThis gives us SBA = g(\u03bd3), which finally yields \u03c7 = g(\u03bd1) + g(\u03bd2) \u2212 g(\u03bd3)."}, {"title": "Weight leakage accumulation due to multiple queries", "content": "We previously showed that clients only gain limited information on the DNN weights through a single broadcast of the weights. We now discuss how to prevent this information from accumulating during multiple queries. Specifically, we propose to manipulate the weights of the model in every broadcast in a way that preserves the neural network function while drastically reducing the accumulation of weight information at the client' end. Although neural network functions are not invariant to general linear transformations (e.g. translation [63, 64]), there always exist isomorphisms between weight matrices that do not alter the neural network function.\nLet W1,W2 \u2208 RN\u00d7N (this procedure works equally well for rectangular matrices) be two weight matrices with \u03c3(\u00b7) implementing an elementwise nonlinearity, so W2\u03c3(W1) implements two successive layers of a neural network. We note that for any permutation matrix T and its inverse T\u22121: W2\u03c3(W1) = (W2\u03c4\u22121)\u03c3(\u03c4W1). Thus, there are N! different permutations possible that all return the same computation [65]. The server can send any of these \u03c4W matrices. This process can be repeated with W2 and the next matrix of the network W3 and so on. For the common case of \u03c3(x) = ReLU(x) = max(0,x), T may also include multiplication by a random scalar [66], or even multiplication by a random diagonal matrix, limiting the information in one measurement to the entropy of these random manipulations. By choosing a maximally entropic distribution over the transformation space, Alice can limit Eve's ability to infer weight information between broadcasts."}, {"title": "Data leakage", "content": "In this scenario, the client operates legitimately and the server acts maliciously. Under our eavesdropper model, we assume that the server can perform any arbitrary individual attack upon receiving the verification state pu. In particular, the server could be equipped to make quantum measurements, observe quantum correlations, and transmit non-Gaussian states.\nWe recall from Section 7.1.1 that the excess noise in the i-th mode in pu is:\n$N_i = (2-\\frac{2}{G}) \\frac{|x_i|^2}{\\sqrt{\\mu}}$\nIn the following classical leakage analysis, we characterize the leakage of each individual data element x (subscript i suppressed for convenience) under the possibility of an individual classical attack from a malicious server. Let R be a Gaussian random variable corresponding to the i-th mode of the verification state with mean w and variance \u03c3\u00b2, where\n$\\sigma^2 = 1+ (2-\\frac{2}{G})^2\\frac{|x|^2}{\\sqrt{\\mu}}$\nfor a known parameter G and an unknown parameter x."}, {"title": "Data Leakage under quantum operations", "content": "Although the analysis via classical Fisher information provides an upper bound for the data leakage by lowerbounding the variance of an unbiased estimator, a tighter result can be achieved by applying the quantum Cram\u00e9r-Rao bound (QCRB). To this end, we extend our data leakage analysis to adversarial servers equipped with quantum operations in this section.\nThe quantum version of the CRB mirrors the classical construction:\n$Var(x) \\geq \\frac{1}{M F_R[p_x]}$\nwhere FR[px] is the quantum Fisher information (QFI) about parameter x under observations of random variable R. The QFI of a Gaussian state is [67]:\n$F_R[p_x] = Tr \\bigg(\\Sigma^{-1}(\\frac{\\partial \\Sigma}{\\partial x}) \\Sigma^{-1}(\\frac{\\partial \\Sigma}{\\partial x})\\bigg)$ (6)\nwhere \u03a3 is the covariance matrix of px. In our case, the relevant covariance matrix is that of the quadratures of the i-th mode of the verification state px:\n$\\Sigma = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\sigma^2 \\end{pmatrix}$\nwhere $\u03c3\u00b2 = 1 + (2-\\frac{2}{G}) \\frac{|x|^2}{\\sqrt{\\mu}}$\nRecalling the computation of $\\frac{\\partial \\Sigma}{\\partial x}$, we find the following derivative of the covariance matrix with respect to the parameter x:\n$\\frac{\\partial \\Sigma}{\\partial x} = \\begin{pmatrix} 0 & 0 \\\\ 0 & \\frac{2 \\|x\\| (2- \\frac{2}{G})}{\\sqrt{\\mu}} \\end{pmatrix}$\nso we have the product:\n$\\Sigma^{-1}\\frac{\\partial \\Sigma}{\\partial x} = \\begin{pmatrix} 0 & 0 \\\\ 0 & \\frac{(2- \\frac{2}{G}) \\|x\\|}{\\sigma^2 \\sqrt{\\mu}} \\end{pmatrix}$\nSubstituting the expressions for \u03a3\u22121 and $\\frac{\\partial \\Sigma}{\\partial x}$ into (6) yields the QFI:\n$F_R[p_x] = \\frac{4 \\|x\\|^2(2-\\frac{2}{G})^2}{\\sigma^4}$ (7)\nwhich is twice the classical Fisher information. The QCRB then bounds the variance of the estimator as follows:\n$\\overline{Var(x)} \\geq \\frac{\\sigma^4}{4 M \\|x\\|^2(2-\\frac{2}{G})^2}$\nThe precision and number of bits of information leaked can be calculated similarly to Section 7.3.3. The final result is presented in Eq. 3.\nFinally, we consider the case where the server transmits non-Gaussian states. Non-Gaussian states are not fully characterized by their covariance matrices, i.e., the inter-mode correlations of non-Gaussian states are not restricted to their first and second order moments. In particular, the client's Gaussian operations on the server's"}]}