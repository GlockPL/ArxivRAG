{"title": "Addressing and Visualizing Misalignments in Human Task-Solving Trajectories", "authors": ["Sejin Kim", "Hosung Lee", "Sundong Kim"], "abstract": "The effectiveness of AI model training hinges on the quality of the trajectory data used, particularly in aligning the model's decision with human intentions. However, in the human task-solving trajectories, we observe significant misalignments between human intentions and the recorded trajectories, which can undermine AI model training. This paper addresses the challenges of these misalignments by proposing a visualization tool and a heuristic algorithm designed to detect and categorize discrepancies in trajectory data. Although the heuristic algorithm requires a set of predefined human intentions to function, which we currently cannot extract, the visualization tool offers valuable insights into the nature of these misalignments. We expect that eliminating these misalignments could significantly improve the utility of trajectory data for AI model training. We also propose that future work should focus on developing methods, such as Topic Modeling, to accurately extract human intentions from trajectory data, thereby enhancing the alignment between user actions and AI learning processes.", "sections": [{"title": "Introduction", "content": "The Abstraction and Reasoning Corpus (ARC) has emerged as a pivotal benchmark for evaluating AI systems' abilities in abstract reasoning and generalization (Chollet 2019). ARC challenges AI by requiring models to generalize from minimal examples and solve tasks based on abstract rules, mimicking human cognitive processes. Despite significant advancements in deep learning (DL) and reinforcement learning (RL), AI systems continue to struggle with ARC tasks, highlighting a substantial gap between current AI capabilities and human-like reasoning.\nTo bridge this gap, interactive web interfaces have been developed (Borsky 2021; Kim et al. 2022; Shim et al. 2024; Strandgaard 2024), which capture human task-solving strategies through trajectory data. These trajectories, composed of state-action sequences, provide valuable insights into human approaches to ARC tasks, potentially guiding AI development toward more human-like reasoning. Among these interfaces, O2ARC (Object-Oriented ARC) (Shim et al. 2024) is notable for its comprehensive trajectory collection, utilizing a rich set of tools and primitives. These trajectories have directly influenced the development of ARCLE(Lee et al. 2024), an RL environment, enabling the translation of human strategies into AI training data.\nHowever, the application of trajectory data collected from O2ARC to train Al models within ARCLE has revealed significant challenges. Despite the richness of the data, RL agents and other AI models have exhibited suboptimal performance on ARC tasks, suggesting that the current form of trajectory data may not be fully suitable for direct AI training. We hypothesize that this performance discrepancy arises from misalignments between human intentions and the recorded trajectories. Such misalignments manifest as discrepancies between the intended actions and those captured in the data, stemming from user errors, interface limitations, or the inherent difficulties of translating abstract reasoning into discrete actions.\nThis research aims to: 1) identify and categorize the misalignments between trajectory data and human intentions through comprehensive analyses, and 2) investigate the impact of these misalignments on AI model training and performance. By addressing these issues, we seek to enhance the robustness and generalizability of AI systems, ultimately improving their ability to tackle ARC's complex reasoning tasks and narrowing the gap between human and machine reasoning."}, {"title": "Related Work", "content": ""}, {"title": "ARC and Trajectory Data", "content": "The Abstraction and Reasoning Corpus (ARC) (Chollet 2019) has emerged as an important benchmark in the pursuit of Artificial General Intelligence (AGI). ARC is designed to evaluate an AI system's ability to perform abstract reasoning and generalization, skills that are considered fundamental for the development of AGI. The benchmark consists of tasks where the model must infer the goal of the task from pairs of input-output grids and then apply that understanding to solve new inputs. One of the key challenges of ARC is that each task has a different goal, making it impossible to succeed by simply learning patterns from the data. This requirement for true generalization highlights the complexity of the benchmark.\nDespite the difficulty for machines, humans typically achieve an 80-90% success rate on ARC tasks (Chollet 2019), demonstrating that the reasoning required is within human cognitive capabilities. However, AI models, including the most advanced large language models (LLMs), have so far only achieved less than 40% accuracy (Bober-Irizar and Banerjee 2024). This significant gap underscores the challenges AI faces in abstract reasoning and generalization, further reinforcing ARC's role as a benchmark for progress toward AGI. The diversity of task structures and the need for novel solutions in each case further underscore the intricacies involved in ARC, pushing AI systems beyond mere pattern recognition.\nGiven the difficulty that Al systems have in solving ARC tasks, researchers have increasingly focused on human problem-solving strategies for insights (Johnson et al. 2021; Park et al. 2023). Their key idea is that by analyzing or mimicking human-generated trajectories during ARC tasks, we can better understand the reasoning processes that lead to success. These human-generated trajectories provide critical insights into the reasoning processes that underlie successful task completion. However, the unsolved challenge lies in the accurate representation of abstract reasoning in the form of discrete actions, where even slight misalignments can significantly degrade model performance.\nRecent efforts to bridge the gap between human and machine performance on ARC tasks have explored the integration of human-generated trajectories and natural language explanations. By analyzing the problem-solving processes of humans, researchers aim to provide AI models with richer contextual information that can guide their reasoning processes. For instance, the use of natural language descriptions alongside program synthesis has been shown to enhance Al's ability to understand and replicate human strategies, leading to improved performance on complex tasks (Acquaviva et al. 2022). Additionally, benchmarks like ConceptARC (Moskvichev, Odouard, and Mitchell 2023) have been developed to specifically assess an Al model's ability to generalize concepts across different tasks. These approaches emphasize the importance of capturing human reasoning processes accurately and highlight the potential for Al systems to improve their abstract reasoning capabilities by learning from human examples."}, {"title": "Misalignment and Data Quality", "content": "In AI model training, the alignment between user intention and the behavior of systems or agents is critical for effective learning (Norman 1995). Such misalignments can arise not only between the user's intended strategy and the recorded trajectory but also between the user's goals and the actions taken by an Al agent or system. These discrepancies can significantly degrade model performance, leading to inaccurate predictions, suboptimal decisions, and a lack of trust in AI systems. This issue is particularly relevant in complex tasks that require nuanced understanding and collaboration, where achieving the desired outcomes depends on accurately interpreting and aligning with human intentions (Christian 2021).\nRecent research has highlighted the significant risks associated with misalignments between user intentions and AI system behavior. When an AI system's actions diverge from users' intended goals, it can lead to outcomes that are not only undesirable but potentially harmful (Zhuang and Hadfield-Menell 2020). In the context of human-robot interactions, addressing these misalignments is essential for ensuring that the robot's behavior aligns with human expectations and intentions. By incorporating real-time user feedback, AI systems can be adjusted dynamically to more closely align with desired outcomes, enhancing performance and data quality in the learning process (Yuan et al. 2022).\nMoreover, the importance of data quality extends beyond the detection of misalignments in trajectories. Ensuring that Al systems can consistently and reliably interpret user intentions is crucial for building robust models that generalize well to real-world applications (Yudkowsky 2016). Poor alignment between user intentions and system behavior can lead to biased models, reduced generalization capabilities (Taylor et al. 2016), and ultimately, lower performance on challenging benchmarks like ARC (Veldkamp et al. 2023). As such, there is a growing emphasis on developing methods that improve the alignment between user intentions and system actions, ultimately enhancing the effectiveness and trustworthiness of AI systems. These efforts are particularly critical when analyzing trajectory, where the recorded sequences of actions provide a window into understanding and mitigating misalignments at a granular level."}, {"title": "Misalignment in Trajectory Data", "content": "The trajectory data collected from O2ARC are crucial as they reflect the sequence of decisions and actions taken by users as they navigate through different states within a task. Each trajectory is structured by the state-action format defined by the ARC Learning Environment (ARCLE) (Lee et al. 2024), which serves as a framework for understanding how users interact with the task environment."}, {"title": "The Format of Trajectory Data", "content": "In more detail, a trajectory is represented as a sequence of states and actions, where each state corresponds to a particular configuration of the task grid, and each action represents a specific operation performed by the user. The relationship between states and actions within a trajectory can be expressed as:\n$s_0 \\xrightarrow{a_0} s_1 \\xrightarrow{a_1} ... \\xrightarrow{a_{n-1}} s_n$"}, {"title": "", "content": "In Equation 1, $s_i$ denotes a state, typically represented as a grid that shows the current configuration of the task at step i, while $a_i$ represents an action selected from the set of possible operations defined by O2ARC. The index i ranges from 0 to n, where n is the total number of actions taken in the trajectory. Each action $a_i$ is applied to the current state $s_i$, transforming it into a new state $s_{i+1}$. This sequential application of actions to states continues until the final state $s_n$ is reached, which represents the completion of the task according to the user's problem-solving strategy.\nThe trajectory formulation captures the dynamic process of task-solving, highlighting the transitions between various states as driven by user actions. It provides a structured way to analyze and interpret how users navigate through the task, offering a clear pathway to study their reasoning patterns, identify potential misalignments between intended and actual actions, and ultimately enhance AI models trained on such data."}, {"title": "The Characteristics of Trajectory Data", "content": "The trajectory data collected from O2ARC exhibits several unique characteristics that set it apart from traditional trajectory datasets typically used in reinforcement learning (RL). First, the trajectory lengths in O2ARC are relatively short, typically consisting of only 10 to 30 discrete actions. This brevity is a stark contrast to the more extended data sequences often found in other RL tasks, where trajectories can span hundreds or even thousands of actions. The shorter length of these trajectories can complicate the learning process, as models have less data per task to learn from, making it more challenging to capture the full scope of the user's problem-solving strategies.\nSecond, O2ARC trajectories exhibit a strong temporal dependency, where each state and action in a trajectory is heavily reliant on its preceding elements. This sequential dependency is crucial for understanding the progression of user actions, as each step in the trajectory is not isolated but rather builds on the previous one. This characteristic introduces complexities in modeling, as it requires algorithms that can effectively capture and utilize these dependencies to predict future actions or states accurately.\nThird, the O2ARC data is inherently multi-user and multi-task in nature. On average, each ARC task has around 25 trajectories, with contributions from multiple users. Each user typically provides trajectories across various tasks, adding layers of variability and richness to the dataset. This diversity presents both an opportunity and a challenge: while it allows for a broad range of strategies to be captured and analyzed, it also introduces variability that must be carefully managed to avoid diluting the insights drawn from the data.\nLastly, the actions within each trajectory are structured, comprising two components: an operation, which defines the type of action (e.g., rotate, paint, erase), and a selection, which specifies the part of the grid where the action is applied. This structured nature of the actions adds a level of complexity to the data, as it requires models to not only predict the correct operation but also the precise location on the grid where this operation should be executed. The interplay between these two components is critical for accurately replicating or predicting user behavior.\nThese unique characteristics of the O2ARC trajectory data introduce specific challenges for analysis and modeling. The short length of the trajectories, combined with strong temporal dependencies, demands sophisticated methods capable of capturing intricate patterns in user behavior. Furthermore, the multi-user and multi-task dimensions require approaches that can generalize across different users and tasks, while the structured nature of the actions necessitates models that can handle both the type and location of actions simultaneously. Addressing these challenges is essential for leveraging the O2ARC data effectively in Al model training."}, {"title": "Misalignments in Trajectory", "content": "Figure 3-6 all depict the user's intention and the corresponding trajectory performed to solve O2ARC Task-49 which is described in Figure 1. If there exists an action that aligns with the intention for this task, the task can be solved with a single intention, as shown in Figure 3, resulting in a trajectory length of 1. However, if there is a misalignment between the user's intention and the trajectory, different outcomes, as shown in the rest figures will be observed.\nHowever, in a real system, there may not be an action like \"crop\" that is optimized for this task. As seen in Figure 4, in such a situation, a user who is well-acquainted with the available actions of the system can devise the most efficient intention based on the provided actions. The new intention involves copying the smallest rectangular object, pasting it in the upper-left corner of the grid, and then resizing the grid to match the size of the rectangular object. To execute this intention, the user created a trajectory involving a total of three actions."}, {"title": "Misalignment Analysis", "content": "In this section, we explore the existence and impact of misalignments between the user's intention and the trajectories they generated during ARC tasks. Our analysis follows a three-step approach: we first developed a visualization tool to facilitate the identification of misalignments, then proposed a heuristic algorithm for misalignment detection. However, due to limitations in acquiring a user intention set, we conducted a qualitative analysis instead, with a detailed case study to illustrate the impact of these misalignments."}, {"title": "Visualization Tool for User Trajectories", "content": "To facilitate the analysis of misalignments, we implemented a visualization tool that graphically represents the user trajectories. Each node in the graph represents a distinct state, defined by the grid and selection combination, while the"}, {"title": "Misalignment Detection Algorithm", "content": "To systematically identify and categorize misalignments within user trajectories, we developed a heuristic algorithm. The primary goal of this algorithm is to detect discrepancies between a user's intended actions and the recorded sequence of actions during task completion. This algorithm plays an important role in our analysis by providing a structured approach to examine how and why these misalignments occur, which is critical for improving the quality of trajectory data used in AI training.\nAlgorithm 1 works by analyzing user trajectories to identify patterns indicative of misalignments. The algorithm begins by checking for cycles within the trajectory T, which may suggest cognitive dissonance, leading to unnecessary repetition of actions. Such cycles are removed from the sub-trajectory T to simplify the analysis (Line 2-8). Next, the algorithm identifies sub-trajectories T that correspond to specific human intentions, starting with a state $s_i$ (Line 12). It then examines cases where multiple actions are recorded within T, determining if these actions could have been simplified to a single, more efficient action. This step helps identify user unfamiliarity with tools (Line 19-23) or, alternatively, functional inadequacies in the tools themselves that force the user to take extra steps (Line 26\u201328). When the sub-trajectory T reaches the final state, the algorithm checks if the task is completed correctly, detecting any further cognitive dissonance or identifying new intentions that may have arisen during task execution (Line 31-39). The result of this analysis is a list of detected misalignments C, which categorizes the different types of misalignments and their causes (Line 44).\nHowever, despite the potential utility of this algorithm, its application is currently limited by a significant challenge: the absence of a well-defined Human Intention Set I. The algorithm relies on accurate knowledge of the user's intentions to identify misalignments. Without this information, it is difficult to determine whether the recorded actions truly reflect the user's strategy or if they deviate due to misunderstanding, tool limitations, or other factors. As a result, while the algorithm offers a valuable framework for analyzing trajectory data, it cannot be fully utilized until we develop reliable methods to extract or infer human intentions from the data. This limitation underscores the need for future research focused on intention recognition, which could significantly enhance the accuracy and effectiveness of our misalignment detection efforts."}, {"title": "Topic Modeling with LDA", "content": "To address the challenge of extracting human intention sets (I) necessary for our heuristic algorithm, we propose exploring Latent Dirichlet Allocation (LDA) for unsupervised learning. LDA can be applied to trajectory data to uncover latent topics, which in this context, would correspond to the user's underlying intentions. This method could enable the automated extraction of human intentions from trajectory data, providing a significant advantage for aligning trajectory data with the user's original goals (Jelodar et al. 2019; Chauhan and Shah 2021)."}, {"title": "Graph Entropy", "content": "Given that the trajectory data is visualized in the form of graphs, we can leverage graph entropy to quantify the diversity and complexity of the trajectories (Ekroot and Cover 1993; Kafsi, Grossglauser, and Thiran 2013). By calculating the entropy of these graphs, we can perform a quantitative analysis of the current trajectory data, helping to identify patterns and inconsistencies in user behavior. This method could provide a robust metric for evaluating the variability and predictability of trajectories, thus contributing to a deeper understanding of user strategies (Dehmer and Mowshowitz 2011)."}, {"title": "Reward Modeling", "content": "To address the challenges of aligning Al models with human intentions, various approaches have been explored in the field of reinforcement learning (RL). In particular, Inverse Reinforcement Learning (IRL) and Reward Learning from Human Preferences (RLHP) have been significant areas of research. These approaches focus on modeling human intentions or preferences to better align the behavior of RL agents with the desired outcomes. In IRL, the goal is to infer the underlying reward function that a human is optimizing, based on observed behavior. This inferred reward function can then be used to train RL agents, effectively capturing human intentions in the learning process (Arora and Doshi 2021). Similarly, RLHP involves learning a reward model from human feedback on agent behavior, allowing for dynamic adjustment and improvement of the agent's performance based on human preferences (Christiano et al. 2017). These methods have shown that accurately modeling human intentions can significantly enhance the performance and reliability of RL agents. In our study, we propose that by eliminating misalignments in the trajectory data collected from O2ARC, the data can become a more effective resource for training AI models, particularly RL agents. Just as IRL and RLHP have demonstrated the value of incorporating human intentions into the learning process, our future work will explore how Topic Modeling with LDA could be employed to extract and model human intentions from trajectory data, thereby improving the alignment between AI models and human problem-solving strategies."}, {"title": "Conclusion", "content": "In this study, we focused on the challenges of using trajectory data collected from O2ARC for training AI models. While such data should ideally provide valuable insights into human problem-solving strategies, the presence of misalignments between user intentions and recorded actions poses significant obstacles. We developed a visualization tool and proposed a heuristic algorithm to identify and categorize these misalignments. Although the heuristic algorithm could not be fully utilized due to the lack of a defined human intention set, our qualitative analysis with case studies confirmed the existence and impact of these misalignments.\nBy improving the alignment between user intentions and the trajectories, the data from O2ARC has the potential to greatly enhance the training of AI models. Future work should focus on developing methods to accurately infer human intentions from trajectories, possibly through techniques such as Topic Modeling, to refine the data further and reduce the impact of misalignments. These advancements will help in creating more reliable and effective AI systems that can better emulate human abstract reasoning and problem-solving capabilities.\nAdditionally, supplementary material accompanying this paper includes the visualization results for 400 tasks and additional case studies. These materials provide deeper insights and further validation of our findings."}]}