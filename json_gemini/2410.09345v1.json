{"title": "Contrastive Learning for Implicit Social Factors in Social Media Popularity Prediction", "authors": ["Zhizhen Zhang", "Ruihong Qiu", "Xiaohui Xie"], "abstract": "On social media sharing platforms, some posts are inherently destined for popularity. Therefore, understanding the reasons behind this phenomenon and predicting popularity before post publication holds significant practical value. The previous work predominantly focuses on enhancing post content extraction for better prediction results. However, certain factors introduced by social platforms also impact post popularity, which has not been extensively studied. For instance, users are more likely to engage with posts from individuals they follow, potentially influencing the popularity of these posts. We term these factors, unrelated to the explicit attractiveness of content, as implicit social factors. Through the analysis of users' post browsing behavior (also validated in public datasets), we propose three implicit social factors related to popularity, including content relevance, user influence similarity, and user identity. To model the proposed social factors, we introduce three supervised contrastive learning tasks. For different task objectives and data types, we assign them to different encoders and control their gradient flows to achieve joint optimization. We also design corresponding sampling and augmentation algorithms to improve the effectiveness of contrastive learning. Extensive experiments on the Social Media Popularity Dataset validate the superiority of our proposed method and also confirm the important role of implicit social factors in popularity prediction. We open source the code at https://github.com/Daisy-zzz/PPCL.git.", "sections": [{"title": "1\nINTRODUCTION", "content": "As social networks become increasingly popular, more and more users are joining these platforms. Especially on content sharing platforms, users interact extensively by creating various posts including images, titles, personalized tags, etc. An intriguing observation is that some posts are born to be popular, making predicting the popularity of these posts before their publication highly valuable in realms such as online advertising and recommendation [11, 16, 24]. Appealing content can contribute to the popularity of a post, such as engaging photos and interesting captions. Thus, previous studies have concentrated on enhancing the representation of the post content, e.g., images and captions [4, 18, 37]. Many of these approaches require manual extraction of a variety of image and text features, and the extensive feature engineering leads to increased complexity, time-consuming processes, and hinders the practical application of these methods [12, 13, 15, 18, 34, 37, 39]. Some recent methods have adopted pre-trained models to extract content features, subsequently fine-tuning them with downstream tasks to enhance the quality of post content representations in an end-to-end manner [3, 4, 21, 29, 31]. Additionally, some others utilize temporal models to aggregate historical post content sequences, aiming to improve the prediction of current post popularity [29, 32, 36, 43].\nWhile the appeal of the content holds significant importance in determining the popularity of a post, various other factors within social platforms contribute to popularity as well. Previous study on social marketing theories [27, 28] shows that the content format and platform directly affect users' passive and active engagement behavior. For instance, some users are more inclined to browse posts that are recommended to them, and some others prefer to click on posts from people they follow, rather than posts that are inherently appealing in content. We categorize these platform-induced elements as implicit social factors, which are distinct from the explicit attractiveness of the content. These factors will subtly affect the behavior patterns of users browsing posts, and thus affect the popularity of posts. According to the influence of the content and platform, we first conduct a qualitative analysis of affected users' viewing post behavior and propose the following hypothesis: (1) Users tend to browse posts that align with their content preferences. Thus, posts with similar content are likely to have overlapping audiences, leading to their correlated popularity. (2) Users also tend to browse posts published by users they follow. Therefore, for a particular publisher, the popularity of his posts is more relevant with a close fan base. (3) In the case of different publishers, the size of user influence can impact the exposure of their posts, i.e., the more followers a user has, the greater the chances of his posts being seen. Consequently, posts from users with similar influence might exhibit closer levels of popularity. We summarize the above factors as Content Relevance (CR), User Identity (UI), and User Influence Similarity (UIS).\nTo verify the rationality of the motivation, we perform a quantitative analysis of the widely used Social Media Popularity Dataset (SMPD) [35], which includes information about posts published on Flickr. In Figure 1a, we randomly select 20 Concepts and corresponding posts. Different Concept labels in SMPD denote different content categories of posts. Since Concept is categorical, we present box plots of the popularity distribution of each Concept, revealing obvious variations in the popularity of posts across different content categories and relative concentration of popularity within the same category, which validates factor CR. In Figure 1b, we choose the FollowerCount attribute to denote the user influence. Since the FollowerCount of different users is continuous real numbers varying greatly, we draw the 2D density plot where x-axis denotes log2(FollowerCount) and y-axis denotes popularity. As we can see, the density reveals a more narrow distribution along the y-axis, indicating that users with similar influence tend to have posts that are relatively close in popularity, which validates factor UIS. In Figure 1c, we randomly choose 20 users and their posts, the x-axis denotes the selected userID. It can be found that there are significant differences between the popularity distribution of posts by different users, and the high concentration of popularity among posts from the same user, which validates factor UI. These three observations effectively validate our hypothesis on the social factors that influence popularity. Note that this is a preliminary verification of motivation through quantitative analysis. We will later prove the effectiveness of the proposed social factors for popularity prediction through comprehensive experiments.\nNotice that some previous works have adopted network-based methods to study the factor like UIS [1, 19]. Their approach is based on cascade graphs of post retweets or relationship networks of users to find the relationship between connected users and posts. However, this explicit interaction information is not available in the scenarios we study. All we have access to is post content and static user data. Therefore, to incorporate social factors without explicit interactive information, we abstract them as the similarity of data in three dimensions: post content, user identity, and user influence. This enlightens us to think of them as contrastive signals, using contrastive learning in the feature space to bring the representations of samples that are similar in each dimension closer while pushing apart those of dissimilar samples. Specifically, we introduce an end-to-end framework PPCL, which consists of a base prediction architecture and additional contrastive learning modules. PPCL includes post and user encoders to encode post content and user information in a common space, alongside a popularity predictor that integrates all information for predictions. To incorporate implicit social factors, PPCL further adds three supervised contrastive learning tasks to jointly optimize different components of the model: (1) Content Relevance Discrimination task. Tailored for the post encoder, this task aims to differentiate between posts with diverse content. This enhances the model's ability to understand post content at a fine-grained level. (2) User Influence Similarity Discrimination task. This task is designed for the user encoder to distinguish users with varying levels of influence. It enables the model to generate user representations that are sensitive to different levels of the publisher's influence. (3) User Identity Discrimination task. Focused on the popularity predictor, this task facilitates consistent predictions for posts originating from the same user. By assigning the three contrastive learning tasks to different encoders and controlling their gradient flows, the representation capabilities of these encoders are improved. We also design a corresponding sampling process as well as an unsupervised sample augmentation method to further enhance the learning of these tasks acting on different data sources and encoders. Further experimental results reveal that the three proposed social factors can serve as inductive biases in the popularity prediction task, enabling the model to easily learn popularity patterns even from limited data.\nIn summary, our main contributions are as follows:\n\u2022 We introduce three implicit social factors, i.e., content relevance, user influence similarity, and user identity, which play roles in determining post popularity.\n\u2022 We design a comprehensive framework PPCL that consists of post and user encoders, along with a popularity predictor, jointly optimized through three supervised contrastive learning tasks targeting the proposed social factors.\n\u2022 We conduct extensive experiments on the Social Media Popularity Dataset under three different settings. The results show the superiority of our proposed method and validate the significant impact of social factors on popularity."}, {"title": "2 RELATED WORK", "content": "For the Social Media Popularity Prediction task, conventional works adopt multiple feature extractors to extract image and text features of posts, fusing them with other metadata (e.g. user information) and making predictions with regression models [2, 5, 13, 37, 39]. For example, Wu et al. [37] adopts CLIP, Nima, HyperIQA, and Place365 to extract image features and use BERT, the text branch of CLIP to extract text feature. Such kinds of methods require extracting features from several heavy pre-trained models for each new post, which is bulky and unpractical in real scenarios. Recently, some researchers have started to design models in an end-to-end manner. Chen et al. [3] build two-stream ViLT models for title-visual and tag-visual representations, and design title-tag contrastive learning for two streams to learn the differences between titles and tags. Tan et al. [29] perform visual and textual feature extraction respectively and then employ a multimodal transformer ALBEF to align visual and text features in semantic space. Chen et al. [4] pre-train the vision-and-language transformer by multi-task learning, finetuning two models with different training strategies, and ensemble their results. Wang et al. [31] adopt a two-stage fusion method to fuse intra-modality and inter-modality features, respectively. Liu et al. [21] extract the relationship between objects in the image, enhancing the understanding of the post content. There are also some works that adopt sequence modeling methods to utilize historical posts to improve the prediction of the current post. Wu et al. [36] analyze temporal characteristics of social media popularity, consider the posts as temporal sequences, and make a prediction with temporal coherence across multiple time scales. Tan et al. [29] adopt a time transformer to aggregate the user's historical post content sequence. Zhang et al. [43] use LSTM and attention mechanisms to aggregate content-related posts in a size-fixed time window to enhance the current post feature. Previous works commonly face a limitation as they heavily depend on post content extraction. They mine the impact of the content itself on popularity through extensive feature engineering or pre-training and fine-tuning of the pre-trained model. However, this approach makes it difficult to uncover implicit social factors in the data that are also important for popularity prediction.\nSome other work uses information cascades to study social media popularity [1, 14, 19]. They primarily utilize the cascade graph formed by post reposts or the users' connection networks to model the impact of users or propagation structures on the popularity of posts. In our scenario, we can only utilize post content and static user information, so we do not elaborate further on this aspect."}, {"title": "3 PROBLEM DEFINITION", "content": "Formally, given a new post p published by user u, the problem of predicting its popularity is to estimate how much attention it would receive after its release (e.g. views, clicks or likes etc.). In Social Media Popularity Dataset [35] which we use for the experiment, \"viewing count\" is used to compute the popularity label \u0177 as below:\n$\\hat{y} = log_2(\\frac{r}{d}+1)$ (1)\nwhere r is the viewing count, d is the number of days since the photo was posted. In this way, \u0177 denotes a normalized measure of a post's popularity that accounts for both the viewing count and the time since the post was made. It provides a more balanced view of how popular a post is relative to the amount of time it has been available, facilitating fairer comparisons between posts with different viewing durations.\nIn this paper, for any given post p, we use the image I and text T in that post and its publisher information U to predict its popularity. Our objective is to construct an end-to-end model M that can generate popularity predictions y given inputs I, T, U:\ny = M(I, T, U; \u0398)"}, {"title": "4 THE PROPOSED MODEL", "content": "We design our model in an end-to-end manner, as shown in Figure 2, incorporating (1) Post Encoder that encodes image and text information of the post and learns a multi-modal representation. (2) User Encoder that encodes category and numerical user attributes, and (3) Popularity Predictor that combines all the information to output popularity features and makes final predictions. To capture implicit social influences, we introduce three contrastive learning tasks, jointly optimizing different components. This section will first provide a detailed introduction to the base prediction architecture, the contrastive learning part will be elaborated later."}, {"title": "4.1 Post Encoder", "content": "A post on Flickr usually consists of an image and some text information, including a post title and several customized hashtags. The text information is a description of the image, so we aim to use multi-modal learning to extract consistent image-text features. Due to the success of pre-trained models in multi-modal learning, we adopt CLIP [26], a multi-modal model pre-trained on a variety of (image, text) pairs, to extract raw features. Given the image I of a target post, we construct corresponding text T as \"The title of the image is {title} and the tags are {hashtags}\". Then the (I, T) pair is input into CLIP:\n$f_I^r = CLIP-image(I)$ (2)\n$f_T^r = CLIP-text(T)$ (3)\nThe image and text branches of CLIP are used to extract the raw image and text features $f_I^r, f_T^r \\in R^{d_r}$, where $d_r$ is the output dimension of CLIP. To obtain more task-specific representations, we adopt a lightweight method to adapt raw features to the new dataset. For computational efficiency, we follow [9] to freeze the backbone of CLIP and use additional learnable bottleneck layers to learn new features:\n$f_I^o = ReLU(f_I^{rT} \\cdot W_I) \\cdot W_I^T$ (4)\n$f_T^o = ReLU(f_T^{rT} \\cdot W_T) \\cdot W_T^T$ (5)\nReLU is the activation function, $W_I \\in R^{d_r \\times d_b}$ is the parameters of bottleneck linear layers where $d_b < d_r$, $W_T \\in R^{d_b \\times d_h}$ where $d_h = d_r$ transform features into the common hidden space. Then we use a two-layer Multi-layer Perception (MLP) to capture the relationship between image and text features:\n$f_p = MLP([f_I^o, f_T^o])$ (6)\nwhere [,] is concatenation. After fusion, we get $f_p \\in R^{d_h}$ as the multi-modal representation of the post. Note that CLIP can be easily replaced by other lightweight pre-trained models without much performance loss, which we verify in Appendix C."}, {"title": "4.2 User Encoder", "content": "The inputs of user information are usually in two kinds of structures: numerical (dense) and categorial (sparse) features. We use D = [D1, D2, ..., DN] to denote dense features including N numerical fields and S = [S1, S2, ..., SM] to denote sparse features including M categorical fields. Since there can be higher-order relationships in user information, we use two approaches, feature crossing which has been widely validated in the domain of click-through rate (CTR) prediction [30, 40], and MLP to both explicitly and implicitly capture interactions between different input fields.\n4.2.1 Feature crossing. We first introduce the cross-layers, each of which performs explicit interactions between input features. Then the model captures the high-order relationships by stacking several cross-layers.\nCross-layer. Given $X_a, X_b \\in d_t$ as the input with feature structure t of the ith cross-layer, we adopt inner-product and linear transformations to perform the crossing process:\n$Cross_i(X_a, X_b) = X_a^T \\cdot X_b \\cdot W^i + b^i$ (7)\nwhere $W^i, b^i \\in R^{d_t}$ are the weight and bias parameters, respectively. We use different parameters to model diverse relationships between different structures of features (i.e., dense or sparse).\nDense feature crossing. Since each field of the dense feature D is a real number that indicates different user attributes, we denote the dimension of D as $d_N$ which equals the number of numerical fields N. Then we adopt l cross-layers to capture (1, 2, ..., l)-order relationships between each dimension of D:\n$O_D^i = Cross_i(D, O_D^{i-1}), i = 1, ...l$ (8)\nwhere $O_D^i \\in R^{d_N}$ are the output of each numerical cross-layers, when i = 1, $O_D^0$ is the original dense feature D. We concatenate outputs of l layers to combine different order relationships between dense features:\n$O_D^u = [O_D^0, O_D^1...O_D^l]$ (9)\nwhere $O_D^u \\in R^{(l+1)*d_N}$ is the output of numerical feature crossing.\nSparse feature crossing. As sparse features S are represented as vectors of one-hot encoding of high-dimensional spaces, we employ an embedding layer to transform these one-hot encoding vectors into dense vectors E as:\n$E = [E_1, E_2, ..., E_M]$\n$E_i = embed(S_i), i = 1, ..., M$ (10)\nwhere $S_i$ indicates the input sparse feature of categorical field i, $E_i \\in R^{d_M}$ indicates the feature embedding of field i with dimension $d_M$. We adopt M * (M \u2013 1) /2 cross-layers to extract relationships of each embedding pair of E:\n$O_{i,j}^c = Cross_{i,j}(E_i, E_j), i \\neq j$ (11)\nwhere $O_{i,j}^c$ is the crossed features between categorical fields i and j. We concatenate individual and crossed dense features as the output of sparse feature crossing:\n$O_S^u = [E_1, ..., E_M, O_{1,2}^c, ..., O_{M-1,M}^c]$ (12)\nThe dimension of $O_S^u$ is $[M * (M + 1)/2] * d_M$.\nCross feature combination. We use an extra cross-layer to extract interactions between different structures of user information:\n$O^u = Cross(O_D^u, O_S^u)$ (13)\nwhere $O^u = [O_D^u, O_S^u]$ is the concatenation of dense and sparse features. Finally, we concatenate Ou and Oh as Ou and then use a linear layer to combine them as the final cross feature:\n$f_u = (O^u)^T \\cdot W_u + b_u$ (14)"}, {"title": "4.2.2 Integrate MLP", "content": "Besides feature crossing, we also adopt a two-layer MLP to implicitly capture interactions between different feature fields, and then we integrate cross features and MLP features as the final user representation:\n$f_u' = MLP([D, E])$\n$f_u = [f_u, f_u']$ (15)\nwhere $f_u \\in R^{d_h}$ is in the common hidden space of visual and text features."}, {"title": "4.3 Popularity Predictor", "content": "After extracting post and user features, we combine them to learn the popularity representation by using the two-layer MLP as a popularity encoder, and a linear layer is adopted to make final regression:\n$f_{pop} = MLP([f_p, f_u])$\n$y = f_{pop}^T \\cdot W + b$ (17)\nwhere $f_{pop} \\in R^{d_h}, W \\in R^{d_h \\times 1}, b \\in R$. We use the Mean Square Error (MSE) as the loss function to supervise the regression process:\n$L_{reg} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$ (18)\nwhere n is the number of samples, yi is the predicted value of sample i and \u0177i is the corresponding ground-truth. With the supervised signal of popularity label, fpop as the output of the last hidden layer of the network can learn features most associated with popularity."}, {"title": "5 CONTRASTIVE LEARNING TASKS", "content": "So far, we have introduced the main architecture of our model. However, it still only encodes post and user information given by the dataset, ignoring implicit social factors that affect the popularity of posts. We have identified three potential social factors, i.e., content relevance, user influence similarity, and user identity, thereby we design three supervised contrastive learning tasks to inject these factors into the model. We begin with a brief description of the Supervised Contrastive Learning (SupCon) loss [17]."}, {"title": "5.1 Supervised Contrastive Learning", "content": "Given N paired samples and their corresponding labels in a mini-batch $D = {x_i; y_i}_{i=1}^{2N}$, 2k and $x_{2k+1}$ represent a positive pair obtained through augmentation, thus sharing the same label, i.e., $\\hat{y}_{2k} = \\hat{y}_{2k+1}$. We denote I = {1, ..., 2N} as the index of all samples, and j(i) be the index of a positive sample associated with $x_i$, (e.g., if i = 2k, then j(i) = 2k + 1), $A(i) = I \\{i\\}$ is all index except i, then $P(i) = {p \\in A(i)|\\hat{y}_p = \\hat{y}_i\\}$ indicate the samples which have the same label with $x_i$, i.e., all positive samples in a mini-batch, the other samples in the same batch are treated as negative samples. We can calculate the SupCon objective for all data in a mini-batch as follows:\n$L_{sup} = -\\frac{1}{|P(i)|} \\sum_{i\\in I} log \\frac{e^{sim(f_i,f_p)/\\tau}}{\\sum_{a\\in A(i)} e^{sim(f_i,f_a)/\\tau}}$ (19)"}, {"title": "5.2 Content Relevance Discrimination Task", "content": "Influenced by user preferences on social platforms, posts with correlated content are likely to have more similar audiences. Therefore, we propose the Content Relevance Discrimination (CRD) task for the Post Encoder (Encp) to pull representations of posts with correlated content closer while pushing posts with different content away. Therefore, we use category labels as the supervised signal to represent correlations of post content. The category labels can be hierarchical, e.g., animal-dog-hound to characterize the differences in post content at a granular level. We denote the number of hierarchical levels as L, and l\u2208 L is a level in the multi-label, then we adopt Hierarchial Multi-label Contrastive Learning loss [42], which extends Eq. 19 to the multi-label scenario, as the objective function. Similar to P(i), we denote $P_l(i) = {p \\in A(i)|\\hat{y}_p = \\hat{y}_i\\}$ as the samples which have the same category label at level l with xi. Then the training objective of the CRD task is:\n$L_{CRD} = - \\sum_{l \\in L} \\frac{\\lambda_l}{|P_l(i)|} \\sum_{p\\in P_l(i)} log \\frac{e^{sim(f_i,f_p)/\\tau}}{\\sum_{a\\in A(i)} e^{sim(f_i, f_a)/\\tau}}$ (20)\nThe parameter $\\lambda_l = F(l)$ functions as a penalty parameter, imposing a higher penalty on sample pairs at higher levels. This is because positive samples at lower levels may give rise to negative sample pairs at higher levels. Here, we use $\\lambda_l = 1/l^2$ as the penalty function. Since the hierarchical labels are used to describe the post, i.e. image and text, we use $f_i$, the final output through $Enc_p$ computed by Eq. 6, as the feature of the sample $x_i$ to compute $L_{CRD}$. Thus the gradient can be computed as $\\nabla_{Enc_p}L_{CRD} = \\frac{\\partial L_{CRD}}{\\partial Enc_p}$, which will flow through all the parameters of the Post Encoder, allowing it to discriminate between different categories of post content."}, {"title": "5.3 User Influence Similarity Discrimination Task", "content": "On social platforms, more influential users attract more attention. Therefore, we design the User Influence Similarity Discrimination (UISD) task to encourage the user encoder (Encu) to pull representations of users with similar influence closer, and vice versa to push them away. We use the FollowerCount attribute to represent the influence size of a user, since intuitively users with more followers will also have more influence. However, FollowerCount \u2208 R+ is difficult to use directly as a target feature for contrastive learning. To this end, we utilize a clustering algorithm to assign a label of discrete influence level to each user. Specifically, we adopt K-means to cluster all data samples into k clusters according to their FollowerCount attribute, then for the sample $x_i$ in the cluster cj, its label of user influence level is assigned as $\\hat{y} = j$. Then we can denote positive sample set of $x_i$ as $P_c(i) = {p \\in A(i)|\\hat{y}_p = \\hat{y} }$, and adopt Eq. 19 as the training objective of the UISD task:\n$L_{UISD} = - \\frac{1}{|P_c(i)|} \\sum_{i\\in I} \\sum_{p\\in P_c(i)} log \\frac{e^{sim(f_u^i, f_u^p)/\\tau}}{\\sum_{a\\in A(i)} e^{sim(f_u^i, f_u^a)/\\tau}}$ (21)\nwhere $f_u$ is the final output of the sample $x_i$ through Encu computed by Eq. 15. The gradient can be computed as $\\nabla_{Enc_u}L_{UISD} = \\frac{\\partial L_{UISD}}{\\partial Enc_u}$, which will flow through all the parameters of the User Encoder, allowing it to discriminate between posts published by users with different influence levels."}, {"title": "5.4 User Identity Discrimination Task", "content": "As a user's followers tend to consistently engage with nearly every post from that user, the popularity of a post created by that user should exhibit a higher correlation with the popularity of their other posts than with the posts made by different users. Therefore, we propose the User Identity Discrimination (UID) task to encourage the popularity encoder (Encpop) to discriminate the final popularity feature of posts from different users. For sample $x_i$, we use the UserId attributes which identify each individual user as the label y, then we denote positive sample set $P_u(i) = {p \\in A(i)|\\hat{y} = \\hat{y}\\}$ and utilize Eq. 19 as the training objective of the UID task:\n$L_{UID} = - \\frac{1}{|P_u(i)|} \\sum_{i\\in I} \\sum_{p\\in P_u(i)} log \\frac{e^{sim(f_{pop}^i, f_{pop}^p)/\\tau}}{\\sum_{a\\in A(i)} e^{sim(f_{pop}^i, f_{pop}^a)/\\tau}}$ (22)\nwhere $f_{pop}$ is the final output of $x_i$ through Encpop computed by Eq. 16. The gradient can be computed as $\\nabla_{Enc_{pop}}L_{UID} = \\frac{\\partial L_{UID}}{\\partial Enc_{pop}}$, which only flows through parameters of the MLP in Eq. 16 so that the UID task focuses on tuning the feature space of the final popularity features without interfering with the optimization process of the previous Post and User encoders."}, {"title": "5.5 Unsupervised Augmentation", "content": "Remember that for each sample $x_i$, there is a positive sample $x_{j(i)}$ which is the augmentation of $x_i$. The augmentation methods include masking, cropping, and reordering for images [6], and a similar approach is used for natural language [38]. However, in our model, the three contrastive learning tasks optimize three encoders using inputs from diverse data sources, including images, text, numerical, categorical data, and their combinations. Therefore, we want to use a unified augmentation approach to provide high semantic similarity for positive pairs under various data sources. Inspired by [10, 25], we adopt an unsupervised model-level augmentation method by Dropout masks in the model. Notice that all three encoders optimized by our contrastive learning tasks contain MLPs, so we can add Dropout modules after the linear layer of the MLP. By feeding the features twice with different Dropout masks in the forward-passing process, semantically similar but different outputs can be obtained:\n$\\hat{f_t^i} = Dropout(Enc_t(z); \\theta_1)$\n$\\hat{f_t^{j(i)}} = Dropout(Enc_t(z); \\theta_2)$ (24)\nwhere t denotes different types of encoders, i.e., Encp, Encu, and Encpop, z is the input value of Enct corresponding to sample $x_i$, $\\theta_1$ and $\\theta_2$ denote different Dropout masks of two feed-forward processes."}, {"title": "5.6 Batch Sampling Strategy", "content": "The importance of sampling for representation learning has been shown in [17, 23]. Due to the utilization of different labels in our three supervised contrastive learning tasks, it is not feasible to ensure that there are enough positive and negative samples for all tasks in a batch of data. Therefore, our sampling method is designed for the CRD task, as optimizing the hierarchical loss imposes the strictest requirements on sample pairs, demanding that each sample can form a positive pair with samples that share a common ancestry at all levels in the structure. Denote the batch size is B and the hierarchical levels are {1, ..., l}, then our method is to sample (l+1) blocks {bo, b1, ..., bl} that |bi| = B/(l+1). First, we randomly sample bo to ensure sample diversity for each label. Then we repeat this operation: randomly sample bi such that the label of each sample in bi is the same as the label of the corresponding sample in bo on level\u012f, but different on leveli+1, where i = {1, 2, ..., l}. After l iterations, we get a batch {bo, b1,..., bl} that ensures sufficient representation from all levels of the hierarchy for each anchor sample."}, {"title": "5.7 Joint Optimization", "content": "To jointly optimize the main popularity prediction task and three contrastive learning auxiliary tasks, we design a weighted loss function:\n$L = L_{reg} + (1 - \\lambda) (\\alpha_1L_{CRD} + \\alpha_2L_{UISD} + \\alpha_3L_{UID})$ (25)\nwhere \u03bb is the hyperparameter to control the rate of main and auxiliary tasks. Since three contrastive learning tasks aim to optimize different encoders with different data sources, we use \u03b11, \u03b12, \u03b13 to regulate their convergence rate."}, {"title": "6 EXPERIMENT", "content": "6.1 Setup\n6.1.1 Datasets. We use the Social Media Popularity Dataset\u00b9 [35] (SMPD) collected from Flickr, which is widely used by previous works, to evaluate the performance of our method. SMPD includes 305, 595 posts published by 38, 307 users. The posts were published between 2015-03 and 2016-03, and the viewing numbers of these posts were recorded in 2016-07. The hierarchical category information in SMPD is displayed in 3 levels, i.e., Category, Subcategory, and Concept, with the number of labels at each level being 11, 77, and 668, respectively. Following previous work, we also use user information provided by Hyfea [18], which complements the data from SMPD. Since the amount of data available varies in different application scenarios, we randomly sample the original SMPD dataset and obtain three datasets of sizes 100K, 200K, and 300K, to test the performance of models with different data volumes. Details of datasets are shown in Appendix A. Each dataset is naturally sorted by posting time and divided into training, validation, and test sets in a ratio of 8:1:1. The experimental results are reported on the test set."}, {"title": "6.1.2 Metrics", "content": "To evaluate the prediction performance, we use two precision metrics, Mean Absolute Error (MAE) and Mean Square Error (MSE), and a correlation metric Spearman Ranking Correlation (SRC) as in [21, 36]. Lower MAE and MSE / higher SRC refer to better performance."}, {"title": "6.1.3 Baselines", "content": "We use the following social media popularity prediction methods for comparisons:\n\u2022 DTCN [36] uses ResNet to extract image features, and adopts a time-aware attention method to aggregate publishing time-related posts.\n\u2022 Att-MLP [39] combines ResNet and Word2Vec for image and text features, adopting feature-level attention to dynamically aggregate different features.\n\u2022 Multiview [29] utilizes ALBEF to encode image and text, employing time transformers to aggregate users' historical posts.\n\u2022 TTC-VLT [3] uses ViLT and designs a title-tag contrastive learning task for better text representation.\n\u2022 DSN [43] utilizes CLIP and designs content-aware attention to aggregate content-related posts.\n\u2022 VisualR [21] combines Faster R-CNN and a pre-trained scene graph generator model to extract relationships between objects in the image.\n\u2022 DFT-MOVLT [4] conducts three multimodal pre-training tasks to enhance ALBEF and designs an extra classification task to improve the results of the regression.\nIn addition, we select a contrastive regression method, Rank-N-Contrast (RNC) [41] for comparison. RNC is a framework designed for regression tasks that learns continuous representations by contrasting samples against each other based on their rankings in the target space. Because the implementation of RNC is a contrastive loss orthogonal to any regression model, we incorporate it into our base architecture, replacing our three contrastive tasks, to compare the contrastive learning schemes we have devised. We provide details of all baseline implementations in Appendix B."}, {"title": "6.1.4 Implementation", "content": "For all three datasets, the training batch"}]}