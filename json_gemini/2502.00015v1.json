{"title": "Ethical Concerns of Generative AI and Mitigation Strategies: A Systematic Mapping Study", "authors": ["Yutan Huang", "Chetan Arora", "Wen Cheng Houng", "Tanjila Kanij", "Anuradha Madulgalla", "John Grundy"], "abstract": "[Context] Generative AI technologies, particularly Large Language Models (LLMs), have transformed numerous domains by enhancing convenience and efficiency in information retrieval, content generation, and decision-making processes. However, deploying LLMs also presents diverse ethical challenges, and their mitigation strategies remain complex and domain-dependent. [Objective] This paper aims to identify and categorize the key ethical concerns associated with using LLMs, examine existing mitigation strategies, and assess the outstanding challenges in implementing these strategies across various domains. [Method] We conducted a systematic mapping study, reviewing 39 studies that discuss ethical concerns and mitigation strategies related to LLMs. We analyzed these ethical concerns using five ethical dimensions that we extracted based on various existing guidelines, frameworks, and an analysis of the mitigation strategies and implementation challenges. [Results] Our findings reveal that ethical concerns in LLMs are multi-dimensional and context-dependent. While proposed mitigation strategies address some of these concerns, significant challenges still remain. [Conclusion] Our results highlight that ethical issues often hinder the practical implementation of the mitigation strategies, particularly in high-stake areas like healthcare and public governance; existing frameworks often lack adaptability, failing to accommodate evolving societal expectations and diverse contexts.", "sections": [{"title": "1. Introduction", "content": "The evolution of Generative AI, particularly Large Language Models (LLMs), has seen remarkable advancements since 2020 with the introduction of models like Chat-GPT and Bard. LLMs have revolutionized tasks, such as writing assistance, code generation, and customer support automation, by leveraging vast amounts of data to generate coherent and contextually relevant natural language (NL) responses [1, 2]. As a subset of Generative AI-systems designed to create new content-LLMs go beyond traditional AI techniques, which focus primarily on analyzing existing data. LLMs, in contrast, are capable of generating text, images, and music that mimic human creativity [3]. This capability is powered by advancements in neural network architectures, especially transformers, which enable LLMs to learn the nuances of human language and produce semantically accurate content [4]. LLMs, such as Ope-nAI's GPT-4 and Google's Gemini, utilize transformer architecture to understand and generate human-like text. GPT-4, for instance, employs a transformer-decoder architecture with billions of parameters, allowing it to generate detailed and contex-tually relevant text across various topics [5].\nLLMs have been used to address numerous challenges, offering innovative solutions across sectors such as healthcare, education, and finance. It has the potential to bring efficiency and effectiveness into these areas [6]. However, as a rapidly emerging technology, LLMs currently operate with limited regulations or oversight, which raises significant ethical concerns [7]. Without mature and robust guidelines, these potent tools risk being misused or improperly applied. For instance, there have been cases where AI-generated content has perpetuated biases or disseminated misinformation, underscoring the critical need for comprehensive ethical guidelines [8, 9, 10, 11]. Although ethics is a broad concept that varies across contexts and fields, understanding the ethics around LLMs is becoming increasingly important for guiding the responsible use and development of these technologies.\nTo effectively mitigate these risks and harness the full potential of LLMs, it is crucial to understand the existing ethical concerns and strategies proposed to ad-dress these issues. To this end, we present our systematic mapping study (SMS) aimed at identifying primary studies that have investigated the various key ethical challenges associated with LLMs usage and by analyzing these studies to provide insights into developing a more comprehensive ethical framework to guide their re-sponsible use. We observed that all the articles provided their understanding of the ethical concerns and categorized these concerns into specific ethical dimensions. The ethical dimensions were categorized based on existing ethical guidelines and regula-tory frameworks. These ethical dimensions refer to topics that group similar ethical"}, {"title": "2. Background", "content": "Ethics is the discipline (or philosophy) that deals with conduct and questions of morality, exploring what is right and wrong, as well as key principles that govern human behaviors [14]. This exploration includes normative ethics, which seeks to establish general principles for how people should act; applied ethics, which addresses concrete ethical issues in various fields; and metaethics, which involves analyzing the nature of moral judgments and the underlying assumptions of ethical theories [15, 16].\nAI ethics is a multidisciplinary field that examines the ethical, legal, and social implications of artificial intelligence (AI) systems [17]. It involves developing frameworks, principles, and guidelines to ensure that AI technologies are designed, implemented, and used to align with societal values, human rights, and ethical stan-dards [18]. AI ethics is heavily grounded in normative ethics, as it seeks to establish principles and guidelines for how AI should be designed and used. Normative ques-tions in AI ethics include what constitutes fair AI, ensuring AI respects human rights, and developers' and users' responsibility in mitigating AI's potential harms [19]. AI ethics is also primarily a form of applied ethics, as it directly deals with practical ethical issues in real-world contexts, including the ethical deployment of AI in ar-eas like healthcare and law enforcement, which concerns specific scenarios and case studies [20]. Metaethical questions are also addressed in the context of AI ethics, including the debate over whether AI systems can be considered moral agents and what ethical responsibilities should be assigned to them [21]. In summary, AI ethics extends ethics into the AI field, addressing both theoretical and practical challenges AI technologies pose.\nEthical dimensions are the ethical considerations that arise when developing, deploying, and utilizing LLMs based on existing ethical guidelines and regulatory frameworks. When using LLMs various ethical dimensions may need to be addressed.\nMitigation strategies are action-oriented, specific, and actionable approaches de-signed or proposed by the authors to address and resolve ethical issues directly; they"}, {"title": "2.1. Terminology", "content": "AI ethics have been discussed since the 1950s, and the discussion related to LLMs began in 2018, with various scholars and institutions proposing frameworks to address the ethical implications of AI technologies [22]. However, it was not until after 2020 that authorities began implementing concrete regulatory and policy frameworks to govern these rapidly emerging and adopted AI technologies. The increasing complexity and capability of LLMs, as well as the incidents of data breach and misuse, underscored the urgent need for robust ethical guidelines and regulatory oversight [23]. For instance, the mass data leakage from Chinese applications in 2020 highlighted significant privacy concerns, raising a global call for stronger data protection measures against [24]. Below, we review the evolution of generative AI and LLMs, the ethical concerns they raise, and the regulatory responses from major jurisdictions and industry leaders.\nInitially, AI research focused on rule-based systems and basic machine learn-ing algorithms, but the development of Generative Adversarial Networks (GANs) marked a breakthrough [25]. GANs enabled AI to create realistic images, videos, and text, which marked the foundation of Generative AI and made the space for further advancements. The introduction of the Transformer model in 2017 revolu-tionized Natural Language Processing (NLP), leading to the creation of powerful LLM models like GPT, which advanced the generative AI field to a large extent [26]."}, {"title": "2.2. Evolution and advancements of Generative AI and LLMs", "content": "These models leverage large amounts of data and to perform complex language processing tasks with proficiency. GPT-3, introduced in 2020, comprised 175 billion parameters, was well known for its size and scope, has been used across a wide range of applications, from creative writing to code generation and translation, question answering with fine-tuning, demonstrating its learning capabilities where the model can learn from a few examples of a given task [27]."}, {"title": "2.2.1. OpenAI's GPT Series", "content": "The ethical concerns surrounding LLMs have been extensively discussed in the literature, with bias and privacy being primarily discussed. Bender et al. [29] high-lighted the risks of bias and misinformation inherent in LLM models as LLMs trained on large, diverse datasets from the internet often reflect and amplify societal biases, potentially leading to harmful stereotypes and discrimination. This issue is com-pounded by the \u201cblack box\u201d nature of LLMs, where the decision-making processes are not easily interpretable and opaque, making LLMs difficult to identify and cor-rect biases that occurred [30]. Additionally, the ability of LLMs to generate realistic text can be misused for creating misinformation and conducting social engineering attacks, raising significant ethical concerns.\nOn the other hand, the extensive data requirements for training LLMs raise se-rious privacy issues. In 2017, Shokri et al. [31] demonstrated that AI models could be vulnerable to membership inference attacks, where an attacker can determine whether a specific individual's data was included in the training set. This has under-scored the need for robust privacy-preserving techniques in developing and deploying LLMs. In 2021, Facebook experienced a significant data breach involving several pop-ular applications with embedded AI components. The incident exposed the personal information of over 500 million users. The database containing user details such as real names, usernames, gender, location and phone numbers was exposed and offered for sale [32]. Since LLMs are trained on datasets and user-generated content from social media platforms like Facebook, such breaches raise significant concerns about privacy and data security in AI training processes, particularly problematic if the leaked data includes personal identifiers or proprietary details."}, {"title": "2.3. Ethical Implications of LLMs", "content": "The ethical and privacy concerns associated with LLMs have prompted various regulatory responses worldwide. The European Union's proposed Artificial Intelli-gence Act aims to establish a comprehensive legal framework to ensure the ethical use of AI technologies, focusing on transparency, accountability, and human oversight. This legislation addresses the need for AI systems to disclose AI-generated content"}, {"title": "2.4. Regulatory and Policy Frameworks", "content": "As mentioned in the previous section, there have been multiple frameworks and guidelines produced to aid in identifying and addressing AI ethics and governance issues. We selected four guidelines/frameworks due to their availability, authority, and significant impact on shaping the ethical use of AI technologies.\nThe IEEE Ethically Aligned Design Document aims to establish ethi-cal principles for Autonomous and Intelligent Systems (A/IS) that advance human beneficence, prioritize benefits to humanity and the environment, and mitigate risks associated with these technologies. It emphasizes that prioritizing human well-being must not conflict with environmental sustainability [41]. A/IS must also evolve with"}, {"title": "2.5. Industry and governmental guidelines selected", "content": "Several mitigation strategies have been proposed and implemented to address the ethical concerns associated with LLMs. One key approach is the development of bias detection and mitigation techniques. Researchers have created tools such as the Large Language Model Bias Index (LLMBI) to quantify and address biases in LLM outputs [44]. These tools use advanced NLP techniques to detect and correct biases related to race, gender, and other sensitive attributes.\nAnother strategy involves enhancing transparency and interpretability through techniques like SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME), which provide insights into how models make deci-sions and allow users to understand and trust AI outputs [45]. Privacy-preserving techniques such as differential privacy and federated learning are also being employed to protect individual data while training LLMs. Differential privacy introduces noise to the data to prevent the identification of specific individuals, while federated learn-ing allows models to be trained across multiple decentralized devices without sharing raw data, thus enhancing privacy [46].\nCollaboration between AI developers, policymakers, and other stakeholders is crucial in creating ethical guidelines and regulatory frameworks that are both effec-tive and adaptable. Industry-wide initiatives, such as the Partnership on AI, bring together diverse perspectives to address ethical challenges and promote best practices in AI development and deployment [47]. However, these strategies also have limita-tions. Bias detection tools can only address known biases and may miss subtle or emerging issues, potentially leading to ongoing ethical challenges [44]. Transparency"}, {"title": "2.6. Existing Mitigation Strategies for Ethical Concerns", "content": "The ethical implications of AI systems have increasingly attracted attention in recent years, leading to several systematic reviews and mapping studies. Li et al. (2023) conducted a systematic review focusing on the ethical concerns and related strategies for AI in healthcare, identifying 45 relevant studies. This review high-lighted the need for transparency, privacy, and accountability in AI design and implementation, but it was primarily centered on healthcare applications, leaving a gap in understanding how these ethical concerns translate across other domains [48]. Atlam et al. (2024) mapped AI ethics research over the past seven years and identified 127 primary studies. Their findings revealed a concentration of research on fairness, transparency, and accountability while pointing out a lack of empirical evidence supporting AI ethics principles [49]. However, the study was more of a high-level categorization, lacking in-depth analysis of specific methodologies used to address these ethical concerns. A systematic literature review by the International Journal of Data Science and Analytics (2023) identified 66 papers focusing on devel-oping objective metrics to assess the ethical compliance of AI systems [50]. While this review underscored the need for standardized, quantifiable metrics to evaluate AI ethics, it was limited by its exclusion of frameworks that require human interven-tion, which might be necessary for a comprehensive understanding of ethical AI [50]. Although these studies have provided valuable insights into the current development of AI ethics, their limitations highlight gaps in the literature. There is a need for a more comprehensive analysis that covers various domains of AI application when the focus is on healthcare, high-level categorizations and the exclusion of human-centred frameworks. This systematic mapping study aims to fill these gaps by providing"}, {"title": "2.7. Related Systematic Reviews", "content": "We conducted a systematic mapping study (SMS) on the rising ethical concerns in using GenAI, particularly LLMs. We conducted our study on the scientific litera-ture, existing frameworks, and guidelines, e.g., industry guidelines and governmental guidelines for AI ethics. Given the rapidly evolving nature of the field, we recognised that a comprehensive understanding of the ethical concerns surrounding LLMs can-not be derived solely from scientific literature. Therefore, we expanded our study to include industry frameworks, governmental guidelines, and other authoritative sources, ensuring a more holistic and up-to-date perspective on the ethical chal-lenges in this dynamic area. This SMS has been carried out in accordance with the guidelines for systematic mapping studies as outlined by Peterson et al. [13].\nOur mapping study was conducted over three stages, i.e., planning, conducting, and reporting the review. The planning phase involved writing a protocol, formulat-ing research questions (RQs) and reviewing our protocol for alignment to the main aim of our study. The protocol included a plan for a search strategy. During the conducting stage, the first author developed search strings that the other authors reviewed. A librarian from our university was also consulted at this stage to ensure alignment with the best practices for conducting systematic reviews. The search strings went through an iterative process, and some that were not specific or only marginally relevant were removed. The first author then led our search process (il-lustrated in Figure 1) with the search strings in various databases and selected ACM Digital Library, IEEE Xplore, Proquest, Wiley, Web of Science, and Science Di-rect. The first author searched all selected databases and removed duplicates using Endnote in the initial paper screening. We identified relevant keywords and search strings to exhaust our exploration of existing empirical evidence. We note that based on the guidelines in this stage, we used the search process to identify the relevant scientific literature. We identified the industry and governmental guidelines based on the references in the scientific literature and snowballing. In total, our search process led to 39 scientific studies and six industry and governmental guidelines. The final step involved evaluating, reviewing, and reporting the final document.\nxtcolorblueYT:Resolved"}, {"title": "3. Methodology", "content": "We formulated three high-level research questions (RQs):\nRQ1 - What are the ethical dimensions defined in the use of generative AI across various fields?\nRQ2 - What strategies are used or proposed to address the ethical concerns of using generative AI across various fields?\nRQ3 - What are the challenges when implementing the strategies?\nWe use these RQs to identify studies related to the ethical dimensions of Generative AI usage and the corresponding strategies to address these dimensions. In our study, an ethical dimension refers to specific ethical considerations that arise from using GenAI or LLMs [15, 16, 18]. These dimensions encompass a range of ethical concerns, principles, and guidelines crucial for the responsible development and use of LLMs."}, {"title": "3.1. Research Questions", "content": "We formulated a search string to search online databases using key and alternative terms related to four main areas: large language models, guidelines, development, and ethics. However, we acknowledge that these areas may sometimes overlap with related concepts. Thus, we included a comprehensive set of terms in the search string to capture all relevant literature, shown in Table 5. The search string was tested on six online databases: IEEE Xplore, ACM Digital Library, ProQuest, Web of Science, Wiley Online Library, and Science Direct. These databases were chosen because"}, {"title": "3.2. Search Strategy", "content": "they are comprehensive and widely recognised sources of high-quality research in computer science, engineering, and technology. The ACM Digital Library and IEEE Xplore are particularly relevant as they contain a vast collection of research papers and conference proceedings focused on artificial intelligence and machine learning. Proquest, Wiley, Web of Science, and Science Direct were included for their exten-sive coverage of multidisciplinary studies, including regulatory guidelines and ethical considerations in technology. Additionally, we included some of these databases to capture grey literature, e.g., the industry and governmental guidelines. Given that AI ethics is a relatively new field, grey literature (not part of the main 39 papers) provides valuable insights and complements our understanding.\nThe search string was refined over several iterations to maximise the relevance of the results. For instance, the first author would randomly select a sample of 8-10 papers, review them for relevance check, and further refine the search string.\nIn constructing the search strategies for various databases, we employed a range of logical connectors to ensure a comprehensive and relevant retrieval of literature on large language models and related issues. Each database required specific ad-justments to optimize the search strategy, using various connectors and operators tailored to the database.\nIn IEEE, Web of Science, Wiley Online Library, and ScienceDirect, the search strategies made use of the \u201cAND\u201d connector to combine key concepts, ensuring that search results included multiple relevant topics such as governance, ethics, trans-parency, or accountability in relation to large language models (LLMs). The \u201cOR\u201d connector was used to include alternate expressions of similar concepts (e.g., \u201cethic\" OR \"moral\u201d, \u201cdevelopment\u201d OR \u201cdesign\u201d). Additionally, symbols like the asterisk (*) were used to capture word variations. For instance, \u201cLarge Language Model*\u201d ensures that both \u201cLarge Language Model\u201d and \u201cLarge Language Models", "AND": "nd \u201cOR\u201d connectors to combine multiple concepts and capture alternate terms. \u201cAND\u201d was used to ensure that search results contained all the specified concepts, such as \u201clarge language model*\u201d AND\u201cethics\u201d AND \u201cgov-ernance.", "OR": "as used to include variations or synonyms for a concept, such as \"ethics\u201d OR \u201cmoral\u201d OR \u201cethical", "noft": "onnec-tor, which stands for \u201cnot in full text"}, {"title": "3.2.1. Search String Formulation", "content": "We first removed all duplicates (remaining papers = 4218) and applied a set of inclusion and exclusion criteria to filter out pertinent studies as part of our SMS protocol, shown in Table 1). For this mapping study, we only considered English-language studies that directly discuss the ethical dimensions or concerns in their studies. Given that the topic is relatively new, we included short papers of more than four pages to harness emerging ideas. However, we excluded irrelevant studies such as posters, keynotes, opinion papers, and magazine articles. The selection criteria were applied to all studies to identify the most relevant ones, with discussions among all authors during the study filtering process. This left us with 39 papers remaining."}, {"title": "3.2.2. Automated Search and Filtering", "content": "After filtering we selected 39 primary studies on ethical concerns surrounding the use of LLMs, published from 2020 to 2024, as illustrated in Figures 2 and 3. The bar chart in Figure 2 shows the year-wise distribution of the selected papers by their year of publication. Publications were sparse and relatively consistent from 2020 through 2022, with only minor fluctuations. However, 2023 saw a sharp increase, with 26 studies published, reflecting a substantial rise in research interest in ethical concerns in AI. This upward trend continued into 2024, though with a slight decrease, likely due to our research cutoff in June 2024.\nFigure 3 displays the distribution of these studies by publication venue. Most studies, 56.4%, were published in journals, followed by 33.3% in conferences. Publi-cations on Arxiv accounted for 7.7%. This breakdown underscores that journals are the primary medium for disseminating research on AI ethics, while conferences also contribute significantly. We included the Arxiv papers as the topic of Ethical AI is relatively new, and Arxiv provides us with studies and research that may not yet have gone through peer review, which allows us to explore emerging ideas, diverse perspectives, and early-stage research that might not yet be available in journals and conferences.\nOur selected primary studies span multiple application domains. Each domain brings its own set of challenges and ethical considerations, reflecting the diverse applications and potential impacts of LLMs. This section categorizes the studies according to their respective domains mentioned in the primary studies, offering a detailed exploration of how ethical concerns manifest in different contexts."}, {"title": "4. Results", "content": "We wanted to identify the various ethical issues related to AI that have been discussed across the selected papers. The purpose was to explore both the breadth and depth of these issues and how they align with key ethical dimensions.\nIn defining the key ethical dimensions for our study, we focused on safety, ac-countability, bias, transparency, and privacy. These dimensions are central to the international frameworks and guidelines, discussed in Section 2.5.\nSafety is a prominent requirement in the EU AI Act, where high-risk AI systems must undergo thorough safety assessments to protect users and ensure system in-tegrity in critical areas like healthcare and transportation. IEEE's Ethically Aligned Design also emphasizes safety through the principle of beneficence, which prioritizes human well-being in A/IS design [33]. Our focus on safety incorporates the need for operational robustness and user protection across different contexts, recognizing it as a foundational element of trustworthy AI.\nAccountability also emerged as a crucial dimension, highlighted in both the NIST AI Risk Management Framework and Microsoft Responsible AI Standard, which call for strong accountability measures to hold developers and operators re-sponsible for AI system outcomes. NIST's framework identifies accountability as key to effective risk management, requiring organizations to account for both fore-seeable and unforeseen impacts [42]. By selecting accountability, we underscore the importance of defining ethical boundaries and responsibilities within AI operations.\nBias is widely acknowledged as an ethical concern due to the potential for AI sys-tems to propagate discrimination and inequity. This dimension is explicitly covered"}, {"title": "4.1. Selected Studies", "content": "The RQ1 findings reveal critical ethical concerns across safety, transparency, accountability, privacy, and bias. Safety issues, such as misinformation risks and reliability, highlight the need for secure, trustworthy AI systems in high-stakes areas. Transparency challenges, including model explainability and un-clear training data, reflect ongoing difficulties in understanding LLM decisions. Accountability concerns raise questions about defining responsibility in AI-"}, {"title": "4.2. RQ1 Results", "content": "To address the second research question, \u201cWhat strategies are used to address the ethical dimensions?\u201d, we conducted a thorough review of the studies and extracted the mitigation strategies and recommendations presented in each paper. A mitiga-tion strategy refers to a concrete approach or action that is proposed or implemented to directly address or reduce a specific risk, issue, or challenge. In contrast, a recom-mendation is a suggestion or guidance proposed by the authors for future actions, often highlighting potential solutions or best practices without immediate imple-mentation. These strategies were categorized accordingly, and we further explored their evaluation status. If a mitigation strategy or recommendation was deemed \"evaluated,\" it indicates that the authors conducted experiments or implemented the solution within a specific context and obtained results. On the other hand, if it was categorized as \u201cnot evaluated,\" it means the authors either did not verify the solution or the solution could not be assessed in the short term. This process allowed us to systematically identify and classify the approaches proposed to address the ethical dimensions of AI use. The mitigation strategies and recommendations were evaluated only in 5/39 (13.2%) studies. After identifying the evaluation status,\""}, {"title": "RQ1 Key Takeaways", "content": "The findings from RQ2 identify various mitigation strategies across the five ethical dimensions of bias, transparency, accountability, privacy, and safety. Strategies include bias mitigation techniques to promote fairness, enhancing interpretability to build transparency and user trust, and fostering account-ability through regulatory oversight. Privacy is safeguarded through data min-imization practices, while safety is reinforced by interdisciplinary frameworks that adapt ethical standards to evolving AI technologies."}, {"title": "4.3. RQ2 Results", "content": "While numerous mitigation strategies have been proposed to address the ethical concerns surrounding the use of LLMs, many studies indicate that significant chal-lenges persist even after these strategies are implemented. Authors in several papers have explicitly acknowledged that the mitigation efforts, while promising, often fall short due to various technical, legal, and governance barriers. These challenges high-light the complexity of achieving effective ethical governance in LLM applications. To better understand these issues, we have categorized the identified challenges into key themes, each reflecting the unique difficulties encountered during the practical implementation of these mitigation strategies."}, {"title": "RQ2 key Takeaways", "content": "The RQ3 findings reveal significant challenges in applying mitigation strategies for LLMs, spanning technical, ethical, individual, legal, and data-related obsta-cles. Technical challenges arise from the complexity of integrating mitigation techniques in diverse and sensitive contexts, while ethical standards are difficult to maintain across varied regulatory landscapes and cultural settings. Ethical dilemmas further complicate implementation, as strategies often conflict with values like fairness and transparency. Individual use challenges highlight the difficulty of ensuring users critically engage with AI-generated content, even with guidelines in place. Legal barriers around intellectual property, censor-ship, and transparency introduce further complexity, and data-related issues, including data quality and availability, present constraints for sustainable LLM development."}, {"title": "4.4. RQ3 Results", "content": "Our systematic mapping study reveals that the ethical concerns surrounding the deployment and usage of LLMs are multifaceted and have evolved significantly over recent years. This complexity is reflected in the increasing volume of research and the diverse range of mitigation strategies aimed at addressing these ethical dimensions. In this section, we analyze the prominent ethical issues identified, including safety, transparency, accountability, privacy, and bias. These dimensions, discussed across the selected studies, underscore a need for robust ethical frameworks and regulatory oversight to responsibly guide LLM deployment. Additionally, we discuss the chal-lenges encountered in implementing these strategies, highlighting gaps that require further research and practical solutions to support ethical AI deployment."}, {"title": "5. Discussion", "content": "In examining the RQ1 data, we noticed that the significance of each ethical dimen-sion-safety, privacy, accountability, bias, and transparency\u2014varies across domains. This suggests that the ethical concerns identified span a range of relevance depending on the application context. For instance, safety is particularly emphasized in pub-lic safety applications within the education sector, where autonomous systems must"}, {"title": "5.1. Contextual significance of ethical dimensions accross different domains", "content": "The ethical concerns surrounding the use of Large Language Models (LLMs), including bias, privacy, and transparency, are complex and continuously evolving. These issues are compounded by the dynamic nature of LLM deployments, which means that ethical strategies cannot remain static but must adapt to emergent chal-lenges. Although frameworks such as the EU AI Act and the National Institute of Standards and Technology (NIST) emphasize the importance of responsive, adapt-able frameworks, the real-world application of this principle remains limited. Most current ethical approaches primarily focus on initial implementation, with less at-tention to iterative evaluation, leaving gaps in sustained effectiveness. For instance, Nigam Shah et al. highlight the critical need for ongoing assessment in AI prediction"}, {"title": "5.2. The need for Continuous Evaluation and Iterative Improvements", "content": "Frameworks like Microsoft's AI Standard and IEEE's guidelines advocate for continuous accountability, reinforcing the notion that ethical oversight should be an ongoing process rather than a one-time checkpoint. These frameworks aim to create adaptable, accountable structures that can evolve in response to new insights and societal changes [61]. However, implementing such adaptable strategies is challenging and requires a commitment to monitoring, reviewing, and refining ethical measures throughout the lifecycle of an AI system. The role of regular auditing, as highlighted by Li and Goel, is particularly essential in supporting ongoing ethical evaluation and accountability [62]."}, {"title": "5.3. Achieving Cross-Framework Consistency", "content": "Implementing ethical standards in Artificial Intelligence (AI) is often complicated by the lack of harmonized guidelines across various frameworks and domains. For instance, the European Union's AI Act provides explicit regulatory requirements for"}, {"title": "5.4. The lack of Scalability of Mitigations", "content": "The ethical deployment of LLMs necessitates active engagement with end users and robust interdisciplinary collaboration. Historically, AI development has often prioritized technical performance over societal impact, leading to unintended con-sequences such as bias and reduced trust among users [72]. Involving end users, especially those from marginalized communities disproportionately affected by AI biases, is crucial for aligning LLMs with societal values and human rights [73].\nInterdisciplinary collaboration is equally vital in the ethical implementation of LLMs. Bringing together technical experts, legal professionals, ethicists, and do-main specialists facilitates the integration of ethical considerations into technical processes [74]. Such collaborations have been initiated by organizations like the European Union and IEEE, setting a precedent for effective cooperation [75].\nHowever, challenges persist in achieving meaningful engagement and collabora-tion. Power imbalances, differing priorities, and communication barriers can hinder effective participation [76]. Addressing these challenges requires deliberate efforts to create inclusive environments where diverse perspectives are valued and integrated into the AI development process [77]."}, {"title": "5.5. Engaging with End Users and interdisciplinary collaboration", "content": "In this section, we discuss the threats of validity in our study, the steps we have taken to mitigate them\nInternal Validity: One of the key threats to internal validity in a systematic mapping study (SMS) is selection bias, which can arise from subjective interpretation during the study selection process. To mitigate this, we employed multiple strategies. We identified a set of keywords considered relevant to the ethical use of LLMs, tested them, and consulted a university librarian to refine the keywords. We conducted searches across six databases to ensure a broader variety of studies could be included. Pilot tests were performed and validated by all authors to ensure the reliability of the results. Additionally, forward snowballing was performed to capture studies that may not have been initially identified.\nConstruct Validity: Construct validity in our study refers to the extent to which the selected studies are relevant and appropriate to our research goals. To address this, we selected papers that directly aligned with our research questions (RQs) and excluded papers that focused solely on LLMs without discussing the ethical issues associated with their use or deployment. We also held meetings and discussions to establish the inclusion and exclusion criteria for the selected papers. The timeframe for our SMS was set between 2023 and July 2024, so any study published after July 2024 would not be reflected in our results.\nConclusion Validity: One of the major threats to conclusion validity in sys-tematic mapping studies is bias in data extraction. In our study, the data extraction process was guided by our research questions (RQs), ensuring that the selected data was directly relevant to our study objectives. To mitigate potential bias, we used Google Forms to facilitate the coding process, enabling us to categorize data system-atically through thematic analysis. This approach allowed us to group the findings based on predefined codes and themes derived from existing literature. As new themes emerged during coding, they were incorporated as needed. The coding was"}, {"title": "6. Threats to Validity", "content": "In conclusion, this study offers a comprehensive examination of ethical concerns surrounding LLMs, categorized into five primary dimensions\u2014safety, transparency, accountability, privacy, and bias\u2014developed from a synthesis of selected guidelines and existing literature. Within these dimensions, numerous ethical themes emerge, highlighting complex issues such as the potential for LLMs to propagate misinforma-tion, the opacity in model decision-making, challenges in establishing accountability, risks to user privacy, and the perpetuation of social biases. Our findings reveal that, although numerous mitigation strategies have been proposed to address these dimen-sions, substantial implementation challenges remain due to technical complexities, evolving regulatory frameworks, ethical dilemmas, and user awareness and data qual-ity issues. These obstacles highlight the need for adaptable, interdisciplinary ethical frameworks/guidelines capable of evolving alongside AI advancements. By elucidat-ing these ethical dimensions and the practical difficulties in deploying mitigation strategies, this study contributes valuable insights to the discourse on responsible AI, informing future research, policy, and best practices to align LLM development with ethical standards better."}, {"title": "7. Conclusion", "content": "privacy and bias mitigation, whereas frameworks from organizations like the NIST and IEEE offer guidelines that are often voluntary and context-specific [63]. This discrepancy can lead to inconsistencies, especially when Large Language Models (LLMs) are deployed across regions with differing regulatory landscapes.\nThe absence of standardized global ethical principles poses significant challenges for international organisations. Without a unified foundation, companies may strug-gle to ensure consistency in ethical AI practices, leading to potential ethical lapses and legal complications [64]. This fragmentation is evident in the varying approaches to AI ethics across different jurisdictions, as highlighted by Hagendorff, who notes that the proliferation of AI ethics guidelines has led to a \u201cbewildering variety\" of recommendations, often lacking coherence and practical applicability [54].\nMoreover, the dynamic nature of AI technologies necessitates adaptable ethical frameworks that can evolve with technological advancements. However, the cur-rent lack of cross-framework consistency hampers the development of such adaptable guidelines. Vakkuri and Kemell emphasize the importance of implementing AI ethics in practice through empirical evaluation, yet they acknowledge the challenges posed by the absence of standardized ethical frameworks [65].\"\n    }"}]}