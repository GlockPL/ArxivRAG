{"title": "Improving LLM Abilities in Idiomatic Translation", "authors": ["Sundesh Donthi", "Maximilian Spencer", "Om Patel", "Joon Doh"], "abstract": "For large language models (LLMs) like NLLB and GPT, translating idioms remains\na challenge. Our goal is to enhance translation fidelity by improving LLM process-\ning of idiomatic language while preserving the original linguistic style. This has a\nsignificant social impact, as it preserves cultural nuances and ensures translated\ntexts retain their intent and emotional resonance, fostering better cross-cultural\ncommunication. Previous work has utilized knowledge bases like IdiomKB by\nproviding the LLM with the meaning of an idiom to use in translation. Although\nthis method yielded better results than a direct translation, it is still limited in its\nability to preserve idiomatic writing style across languages. In this research, we ex-\npand upon the knowledge base to find corresponding idioms in the target language.\nOur research performs translations using two methods: The first method employs\nthe SentenceTransformers model to semantically generate cosine similarity scores\nbetween the meanings of the original and target language idioms, selecting the best\nidiom (Cosine Similarity method). The second method uses an LLM to find a cor-\nresponding idiom in the target language for use in the translation (LLM-generated\nidiom method). As a baseline, we performed a direct translation without providing\nadditional information. Human evaluations on the English -> Chinese, and Chinese\n-> English show the Cosine Similarity Lookup method outperformed others in all\nGPT40 translations. To further build upon IdiomKB, we developed a low-resource\nUrdu dataset containing Urdu idioms and their translations. Despite dataset limita-\ntions, the Cosine Similarity Lookup method shows promise, potentially overcoming\nlanguage barriers and enabling the exploration of diverse literary works in Chinese\nand Urdu. For access to the code and replication of our experiments, please visit\nthis GitHub.(https://github.com/ANON13222/ITR)", "sections": [{"title": "Introduction", "content": "The primary challenge faced is enabling large language models (LLMs) to capture the cultural and\nemotional essence of the original author's words-frequently lost in direct translations (Levin et al.,\n2014). Idioms particularly highlight this difficulty; they differ significantly across languages and are\ndeeply embedded in cultural contexts, requiring additional cultural knowledge for accurate translation\n(Fadaee et al., 2018). Previous work has made efforts to enhance LLMs like NLLB and GPT for\nidiomatic translation and has primarily relied on augmenting these models with knowledge bases\nsuch as IdiomKB (Li et al., 2023). These knowledge bases provide meanings to assist in translating\nidioms. However, current methods still face challenges in preserving the idiomatic style and cultural\nnuances of the original text (Levin et al., 2014). Despite advancements, existing methods often\nstruggle to maintain the idiomatic writing style in translated texts. The difficulty lies in accurately\ncapturing the cultural and emotional essence embedded in idiomatic expressions, which are highly\ncontext-dependent and vary across languages (Shao et al., 2017). This research addresses these\nchallenges by expanding upon existing knowledge bases to include idiomatic expressions from both\nsource and target languages. Specifically, we introduce a novel method termed Cosine Similarity\nLookup that utilizes a refined dataset of the chosen language of translation with corresponding idioms\nthat are inserted according to the direct translation from the previous language. This is optimized\nfor SentenceTransformer embeddings (Li et al., 2023). We introduced and benchmarked methods\nto ensure fidelity in translating idiomatic sentences across languages, validated through human\nevaluation metrics, alongside compiling a benchmark dataset of Urdu idioms indexed by their English\nmeanings."}, {"title": "Related Works", "content": null}, {"title": "Limitations in Translation Technology", "content": "From a literary standpoint, idioms are figurative, institutionalized expressions that enrich speech\nand writing, demonstrating mastery of a language. Language models must understand and interpret\nidioms, especially when translating from one language to another. Recent work has used IdiomKB\nas a knowledge base for translating idioms, achieving some success with language models (Li,\nShuang, et al. \u201cTranslate Meanings, Not Just Words: IdiomKB's Role in Optimizing Idiomatic\nTranslation with Language Models.\u201d ArXiv abs/2308.13961 (2023): n. pag.). This knowledge base\npairs idioms in a language with their meanings in English, Chinese, and Japanese. In their method,\nthey use this to provide the translation model with the figurative meaning of the idiom in the sentence.\nHowever, this technique fell short of consistently super accurate results. The knowledge base is also\nrelatively small, limited to only three languages, and it does not include any low-resource languages.\nBuilding on these techniques for idiomatic translation is the use of retrieval-augmented models\n(KNN-MT) and the upweighting of training loss on potentially idiomatic sentences (Liu, Emmy, et al.\n\"Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss\nWeighting.\" Conference on Empirical Methods in Natural Language Processing (2023)). This showed\nimprovements in translations for idiomatic sentences along with slight improvements in non-idiomatic\nsentences as well. However, limitations include the use of synthetic data, limited languages, and the\nheavy reliance on high-quality training data. Past research has focused on translating an idiom in\nthe original language to the figurative meaning in the target language. Although this may convey the\nmessage, it fails to be a true translation because the idiomatic sentence style is lost."}, {"title": "Next Steps to Build On IdiomKB", "content": "As evidenced by Li and Chen, the use of specialized knowledge bases such as IdiomKB has proven\nbeneficial. However, the limited scope of these resources, covering only a few languages, constrains\ntheir utility in broader linguistic contexts (Li, Shuang, et al. \u201cTranslate Meanings, Not Just Words:\nIdiomKB's Role in Optimizing Idiomatic Translation with Language Models.\" ArXiv abs/2308.13961\n(2023): n. pag.). This highlights the need to expand these databases to encompass a wider array\nof languages and idiomatic expressions. We also hope to build on the use of a knowledge base in\nidiomatic translation by using it to translate an idiom in one language to an idiom in another language.\nThis would better capture cultural nuances and help maintain the style of the idiomatic sentence\nacross languages.. The inherent complexity of idioms is underscored by research from Dankers\nand Lucas, who analyze the compositional challenges faced by Transformer models in handling"}, {"title": "Method", "content": null}, {"title": "Dataset construction", "content": "For the English-to-Chinese translation, we used the \u201cMWE-PIE\u201d (Zhjjn, 2021) dataset that had\n1,197 English idioms with around 5 sentences per idiom for a total of 5,170 sentences. For the\nChinese-to-English translation, we used the CCT \"cheng yu\" dataset (Jiang et al., 2018) which\nhad 108,987 Chinese sentences that contained 7,397 unique idioms. For future use with the cosine\nsimilarity method, we re-formatted the datasets so the English meaning was the key with the meanings\nand idioms from other languages as the values. We are indexing on the English meanings so that\nsemantically comparing the English meanings of idioms is made easier(Li et al., 2023). For the Urdu\ndataset construction, we found a dataset with 2,111 Urdu idioms(with repeats) (ul Hassan, 2024) and\ntheir English meanings/idioms. We then found matching English idioms when they existed from\nour English idiom dataset and, using GPT4o, generated English sentences for those that we did not\nalready have sentences that we flagged."}, {"title": "Translating idioms", "content": "We tested three translation methods: (1) Cosine similarity lookup, (2) LLM-Generated Idioms, and (3)\nDirect Translation. For the EN -> ZH and ZH -> EN we evaluated a random subset of 500 sentences\nand for the EN -> UR we evaluated on 216 sentences. The Urdu idiom dataset was limited because\nwe only translated the idiomatic sentences that had corresponding English and Urdu idioms. All\nmethods were translated with GPT-3.5-Turbo and GPT-40. For all translations, we set the temperature\nto 0.7."}, {"title": "Cosine Similarity Lookup Method", "content": "In the Cosine similarity lookup method, we extracted idioms\nfrom sentences and searched for their meanings in the data. Using SentenceTransformers paraphrase-\nMiniLM-L6-v2, we generated embeddings for English meanings and compared them with target\nlanguage idioms using cosine similarity with a threshold of 0.7 to find the best match. If no match\nwas found, we used the English meaning for translation. For the idioms that did find a match, we\nprompted GPT4o to choose/confirm an idiom if the lookup method found corresponding idioms in\nthe dataset. We then translate the sentence while providing the matching target language idiom."}, {"title": "LLM-Generated Idioms Method", "content": "For the LLM-Generated Idioms method we first use GPT 4o to\ngenerate corresponding idioms in the target language that match the idiom in the original language.\nWe give an option for the model to find up to 3 matches, specifically clarifying that it is acceptable\nto not find any match at all to minimize hallucinations. Then we prompt the model again to choose\nthe best match from the top 3. We do this in order to stay consistent with the GPT confirmation\nperformed in the Cosine Similarity Lookup method. Lastly, we prompt the model to use the top\nLLM-generated idiom when translating the sentence."}, {"title": "Direct Translation Method", "content": "The direct translation method simply prompts the model to translate the\nsentence without providing additional information about the idiom. This method is the baseline that\nwe compare the performance of the other two methods."}, {"title": "Evaluation method", "content": "To evaluate the translations, we compared the original sentence and the translated sentence. We\nused both GPT4 and GPT4o as well as human evaluations. The focus of the evaluation depended on\nwhether the model was instructed to use a specific idiom in the translation. If there was an idiom in\nthe translated sentence we instructed the model to focus on the idiom counterpart, but if there was not\nan idiom in the translated sentence we instructed the model to focus if the figurative meaning of the\nidiom was maintained. We did this to ensure that the evaluation prompt was fairly tailored for each\ntranslation. We also set the temperature to 0.1 for the evaluations so there is less randomness. Every\ntranslation received a score from 1-3 based on the scale outlined in the table below:"}, {"title": "Results", "content": "The evaluations presented below reveal the performance of different models for translating idiomatic\nexpressions from English to Chinese and from Chinese to English. The GPT-40 translations, expec-\ntantly, outperformed the GPT3.5-Turbo translations. Regarding the translation model, the GPT-40\nevaluations consistently score the translations lower than the GPT4 evaluations(Figure 2, Page 8);\nthe evaluation done by GPT-40 matched more closely with the human evaluations. Using a binary\ncorrelation we found that the GPT4o score matched the human evaluation score 65% of the time\nwhile the GPT4 score only matched 53% of the time. The superior GPT40 model was more critical\nof the idiom translations than GPT4 making it a more human-like evaluation. Although the LLM\nevaluations typically did not score the Cosine Similarity Lookup method the highest, the GPT-40\nCosine Similarity Lookup method scored the highest on the human evaluations( which were evaluated\nusing the same criteria as the LLM), making it a promising and viable method. For the EN->ZH\ntranslation, 238 idioms did not find a match, and 262 did. For ZH->EN, 386 idioms did not find a\nmatch and 114 did. Despite the dataset not being designed for idiom-to-idiom correlation, the method\nstill found success in translation. The translations that did not find an idiom scored better than the\ntranslations that did find an idiom in the LLM evaluations. However, the human evaluations show that\nthe translations that did find an idiom were mostly better translations. This suggests that the LLM is\nnot adequately equipped to assess the accuracy of translations that contain idioms as it prefers the\nusage of the figurative meaning in the translation over a corresponding idiom. This is likely why\nthe LLM evaluations also favored direct translation as it was better able to assess the accuracy of\nan idiom -> meaning translation rather than an idiom -> idiom translation. Occasionally the cosine\nsimilarity fell short when the meanings were semantically similar but not the same. For example,\n\"having extremely poor or no vision\" (\"blind as a bat\") was paired with \"having small and narrow\nvision; lacking in foresight (\"\u76ee\u5149\u5982\u8c46\"). These two idioms being considered semantically similar is\nreasonable but the differences in the meaning account for the poor idiomatic translation. The majority\nof Cosine Similarity Look-ups are successful such as pairing \"to remain silent or keep a secret\" (\"zip\none's lips\") with \"keep one's lips sealed, remain silent\" (\"\u7f04\u53e3\u4e0d\u8a00\"). The LLM-Generated Idiom\nmethod scored lower likely due to the model not producing good idiom translations in the first place\ncompared to the Cosine Similarity Look-up method. The outputted idioms were very sensitive to\nthe prompt as slight variations in the prompt led to varying idioms which could be a reason for the\nmethod's worse performance. The direct translation performed surprisingly well because for simple\nidioms such as \"quality time\" it was able to successfully translate it without additional information.\nFor the EN -> UR sentences, 48 sentences were found in the English sentences dataset while 168\nwere generated by GPT40. The low resource language results showed the Cosine Similarity Lookup\nunderperforming. We attribute this to the LLM evaluations previously favoring the usage of the\nfigurative meaning in the translation rather than a corresponding idiom, which is especially true here\nbecause, for the Urdu idioms dataset, we had a 1:1 correspondence for idioms. Following the trend of\nthe previous translations we hypothesize that human evaluations would show positive results for the\nCosine Similarity Lookup method."}, {"title": "Cosine similarity look-up results", "content": null}, {"title": "LLM-generated idioms evaluations", "content": null}, {"title": "Direct translation evaluations", "content": null}, {"title": "Limitations", "content": "Although the results of the Cosine Similarity look-up method have been promising thus far, there\nhave been limitations in our work that prevented the method from being an even bigger success.\nFinite amount of idioms As stated earlier in the LLM-generated idioms method, we could generate\na corresponding idiom in the target language for nearly every original idiom. This yielded a much\nhigher percentage of idioms that found a match, even if they were not all perfect matches. However,\nthe IdiomKB datasets, which were used in the Cosine Similarity look-up method, were composed of\nEnglish and Chinese idioms without a 1:1 correspondence. There were 8,643 Chinese idioms and\n3,990 English idioms. As a result, only about 1/2 of the idioms had a match in the Cosine Similarity\nlook-up method. Had there been a comprehensive dataset that had both the English idiom and its\ncorresponding Chinese idiom, the method would've been much more effective, which we leave to\nfuture work. Further, we leave the expansion of the knowledge base to more low-resource languages\nfor future work.\nInferior GPT evaluation GPT evaluation does not strongly mimic human evaluation, especially for\nUrdu translation, where we lacked access to an Urdu human evaluator."}, {"title": "Conclusion", "content": "In this paper, we presented advancements in translating idiomatic expressions using LLMs. We evalu-\nated two methods, Cosine Similarity Look-up, and LLM-generated idioms, using Direct Translation\nas a baseline. Our findings indicate that the Cosine Similarity Look-up method is particularly effective\nin preserving idiomatic integrity and achieving higher translation fidelity. Despite sometimes yielding\nworse results than other methods, the Cosine Similarity Look-up method proved to be an effective\nand viable option. LLM-generated idioms performed well but fell short compared to the Cosine\nSimilarity Look-up, while Direct Translation often missed idiomatic nuances. Human evaluations\nconfirmed the effectiveness of the Cosine Similarity Look-up method, emphasizing the need for\ncontext-aware translations. The impact of this technology can be proven significant when used to\nenhance communication through more accurate and culturally resonant translations of literary and ed-.\nucational materials. By making literary works more accessible, this research can help bridge cultural\ngaps and promote cross-cultural literacy and education globally. It profoundly impacts literary and\neducational communities by preserving the original tone and style of literary works, allowing readers\nworldwide to experience texts as intended. By enhancing LLMs to maintain the style and tone of\nmessages across languages, we acknowledge the crucial role idioms play in communication and how\nthey can express authors' intent in their work, something that is often lost with direct translation from\ntwo languages."}]}