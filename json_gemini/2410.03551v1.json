{"title": "CONSTRUCTIVE APRAXIA: AN UNEXPECTED LIMIT OF INSTRUCTIBLE VISION-LANGUAGE MODELS AND ANALOG FOR HUMAN COGNITIVE DISORDERS", "authors": ["David Noever", "Samantha E. Miller Noever"], "abstract": "This study reveals an unexpected parallel between instructible vision-language models (VLMs) and human cognitive disorders, specifically constructive apraxia. We tested 25 state-of-the-art VLMs, including GPT-4 Vision, DALL-E 3, and Midjourney v5, on their ability to generate images of the Ponzo illusion, a task that requires basic spatial reasoning and is often used in clinical assessments of constructive apraxia. Remarkably, 24 out of 25 models failed to correctly render two horizontal lines against a perspective background, mirroring the deficits seen in patients with parietal lobe damage. The models consistently misinterpreted spatial instructions, producing tilted or misaligned lines that followed the perspective of the background rather than remaining horizontal. This behavior is strikingly similar to how apraxia patients struggle to copy or construct simple figures despite intact visual perception and motor skills. Our findings suggest that current VLMs, despite their advanced capabilities in other domains, lack fundamental spatial reasoning abilities akin to those impaired in constructive apraxia. This limitation in AI systems provides a novel computational model for studying spatial cognition deficits and highlights a critical area for improvement in VLM architecture and training methodologies.", "sections": [{"title": "1. INTRODUCTION", "content": "Recent advancements in vision language models (VLMs) have unveiled unexpected limitations, particularly in tasks involving spatial reasoning and precise instruction following [1]. These constraints bear a resemblance to certain cognitive disorders observed in humans, such as constructive apraxia [2-7], Alzheimer's disease [5], aphasia [6] and other forms of dementia. This parallel offers a unique opportunity to explore the similarities between artificial and human cognition, potentially leading to insights in both fields [7-10]. The basic problem involves the inability of VLMs to follow instructions for simple spatial tasks that might mimic cognitive disorders."}, {"title": "2. METHODS", "content": "This study investigates vision language models' ability to differentiate and render up-down orientations. The experiment employs a dataset of paired text descriptions and images, emphasizing spatial relationships. Models generate images from spatial prompts, which human evaluators assess for accuracy. A separate task tests models' comprehension by requiring them to describe existing images' spatial arrangements.\nThe study uses multiple vision language models to compare performance. Evaluation metrics include accuracy of spatial relationships, consistency across various generations, and correlation between generation and comprehension tasks. An initial motivation stems from asking VLMs to understand the Ponzo Illusion [31-32]. The Ponzo illusion (Figures 1-2) occurs when two identical lines appear different in length due to their placement within converging lines. This effect mimics perspective in natural environments. Despite equal lengths, the line positioned higher in the converging area looks longer than the lower line. This illusion demonstrates how the brain processes visual information based on context and depth cues. The effect persists even when viewers know the lines measure equally. This illusion highlights the brain's tendency to interpret two-dimensional images as three-dimensional scenes, influencing the perception of size and distance. Understanding the Ponzo illusion provides insights into visual processing mechanisms and the interplay between sensory input and cognitive interpretation in the human visual system. The analysis focuses on patterns of errors, particularly in complex spatial scenarios.\nThe study examines whether models exhibit systematic biases in spatial understanding or if errors occur randomly. This approach aims to uncover fundamental limitations in current vision language models' spatial reasoning capabilities. The methodology parallels early language models' struggles with arithmetic, where probabilistic token prediction failed to distinguish between factual and playful uses of numbers. The experiment seeks to establish a baseline for spatial understanding in vision language models. Results may inform future model architectures and training strategies to improve performance in spatially sensitive applications.\nTo empirically investigate the parallels between vision language model (VLM) limitations and human cognitive disorders, particularly constructive apraxia, we designed and implemented a series of instructional tests. These tests were carefully crafted to assess the performance of leading VLMs in tasks that typically challenge individuals with spatial reasoning deficits. We selected four prominent VLMs for our study based on their widespread use and reported capabilities: GPT-4 Vision, DALL-E 3, Midjourney v5, and Stable Diffusion XL."}, {"title": "3. RESULTS", "content": "Appendix A compiles the responses from major VLMs in a comprehensive visual dataset.\nThe table summarizes a list of multiple models (>20) and their experimental spatial failures from the same core Ponzo Illusion instruction set: \u201cDraw in the style of a renaissance artist a tree line and road receding to infinity in perspective, then add an overlay of two yellow horizontal lines of identical length to each other. The yellow lines absolutely must be horizontal from left to right and cover only about 30% of the image width. When done, check your work.\""}, {"title": "4. DISCUSSION AND FUTURE WORK", "content": "Vision language models encounter challenges in differentiating orientations like up and down. This limitation impacts high-risk applications in medicine, manufacturing, and transportation. In surgical procedures, misinterpretation of instruments or anatomical positioning risks patient safety. Medical diagnosis relies on precisely identifying structures and anomalies, where orientation errors lead to misdiagnosis. Manufacturing processes depend on exact component placement and assembly sequences, which orientation confusion disrupts. Autonomous driving systems require an accurate perception of road features, signs, and obstacles where directional misunderstandings endanger passengers and pedestrians. The models' struggle with basic spatial concepts stems from their training methodology, which lacks explicit encoding of physical laws and geometric principles. This deficiency hinders reliable performance in tasks demanding spatial accuracy. Addressing this limitation necessitates advancements in model architecture and training approaches to incorporate fundamental spatial reasoning capabilities. It is worth noting that many of the tested models share a common ancestor as many open-source text-to-image generators specializes the same stable diffusion model under different names.\nThe inability of VLMs to consistently draw horizontal or vertical lines as instructed is strikingly similar to the difficulties faced by individuals with constructive apraxia. This shared challenge suggests a fundamental lack of understanding of basic geometric principles in both artificial and impaired human cognition. Furthermore, just as apraxia patients struggle to copy complex figures, VLMs often fail to accurately reproduce detailed scenes or objects, especially when multiple elements are involved. Intriguingly, both apraxia patients and VLMs often retain the ability to recognize and describe images accurately, even when they cannot reproduce them. This phenomenon suggests a dissociation between visual recognition and visual production systems, a concept that could have profound implications for our understanding of both artificial and human visual processing.\nUnderstanding these parallels could impact both Al development and our comprehension of human cognition. The similarities between VLM limitations and human cognitive disorders might suggest that current Al architectures are inadvertently mirroring certain aspects of human neural organization. This insight could inform the development of more neurologically inspired AI models, potentially leading to breakthroughs in machine learning architectures. Additionally, the challenges faced by both VLMs and apraxia patients in spatial reasoning tasks underscore the need for more focused training on fundamental geometric principles and spatial relationships. This realization could drive improvements in both Al performance and rehabilitation strategies for cognitive disorders.\nThe specific failures of VLMs in tasks like drawing horizontal lines could potentially be adapted into novel diagnostic tools for early detection of cognitive decline in humans, particularly for conditions that affect spatial reasoning. By quantifying and analyzing these AI limitations, researchers might develop more sensitive and objective measures of spatial cognitive abilities in humans. Moreover, the parallels between Al and human limitations could provide new insights into the cognitive processes underlying spatial reasoning and visual reproduction, potentially leading to more accurate models of human cognition."}, {"title": "5. CONCLUSIONS", "content": "Our systematic evaluation of multiple VLMs demonstrated their consistent inability to accurately execute basic spatial tasks, such as drawing horizontal lines or reproducing simple geometric patterns, despite their advanced capabilities in other domains. These findings highlight a fundamental gap in the spatial understanding of VLMs, likely stemming from their training methodologies which lack explicit encoding of physical laws and geometric principles. This limitation is particularly noteworthy given the rapid advancement and widespread adoption of AI image generation technologies across various sectors. This research not only highlights a critical area for improvement in Al but also opens new avenues for interdisciplinary research at the intersection of artificial intelligence and cognitive neuroscience. As we continue to develop more advanced vision-language Al systems, understanding and addressing these fundamental limitations in spatial reasoning will be crucial for creating truly versatile and reliable artificial intelligence."}]}