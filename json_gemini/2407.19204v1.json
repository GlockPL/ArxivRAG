{"title": "Towards the Terminator Economy: Assessing Job Exposure to AI through LLMs", "authors": ["Emilio Colombo", "Fabio Mercorio", "Mario Mezzanzanica", "Antonio Serino"], "abstract": "The spread and rapid development of AI-related technologies are influencing many aspects of our daily lives, from social to educational, including the labour market. Many researchers have been highlighting the key role AI and technologies play in reshaping jobs and their related tasks, either by automating or enhancing human capabilities in the workplace. Can we estimate if, and to what extent, jobs and related tasks are exposed to the risk of being automatized by state-of-the-art AI-related technologies? Our work tackles this question through a data-driven approach: (i) developing a reproducible framework that exploits a battery of open-source Large Language Models to assess current AI and robotics' capabilities in performing job-related tasks; (ii) formalising and computing an Al exposure measure by occupation, namely the TEAI (Task Exposure to AI) index. Our results show that about one-third of U.S. employment is highly exposed to AI, primarily in high-skill jobs (aka, white collars). This exposure correlates positively with employment and wage growth from 2019 to 2023, indicating a beneficial impact of AI on productivity. The source codes and results are publicly available, enabling the whole community to benchmark and track AI and technology capabilities over time.", "sections": [{"title": "Introduction", "content": "The 1984 famous movie \"The Terminator\" is set in a dystopian future where intelligent machines, created by a military defence system known as Skynet, become self-aware and perceive humanity as a threat, initiating a war to eliminate humans. Skynet creates advanced humanoid robots called Terminators to hunt down and kill human survivors. The Terminator possesses advanced learning algorithms that enable it to adapt to any environment, making it a formidable antagonist for humans. The debate and concerns about the impact of AI are often conducted against the backdrop of the film's setting. This paper takes these concerns seriously by developing an AI-centered assessment of the possible exposure of different occupations to artificial intelligence. Assessing the potential impacts of technology on the labour market is not easy, as there are several potential channels at work. As stressed by Acemoglu and Restrepo (2019) technology has three major effects on labour demand. The first is the productivity effects that operate through lower production costs brought about by new technologies. The second is the displacement effect of workers operated by machines and alike. These two effects operate in different directions and depend on whether technology substitutes or complements human labour. Economic jargon depends on the elasticity of substitution between tasks. Moreover, there is another third effect of technology: the creation of new tasks and activities where labour can be productively employed (reinstatement effect). Indeed, if we look at history, the reinstatement effect has been a central feature of all technological revolutions that continuously created new opportunities for labour. For the reinstatement effect to take hold, technology must have a wider impact than its narrow scope, with spillover effects in sectors/areas other than those for which it was designed. In other words, technology must have the features of a general purpose technology, which, according to Lipsey, Carlaw, and Bekar (2005), are pervasiveness across the economy, ability to generate complementary innovations, and improvement over time.\nAI, due to its broad applicability, potential productivity gains, and potential for driving further innovation, provides strong arguments for being considered a general-purpose technology. These features of AI, however, create a relevant measurement issue, as it is extremely difficult to identify all the channels through which it affects the economy. This paper contributes to this field by developing a methodology for assessing Al exposure using Large Language Models (LLMs), using a very granular approach that analyses exposure for each task that makes up each occupation.\nContribution. Our main contribution is twofold:\n1.  From a methodological point of view, we design and implement a reproducible framework to estimate to what extent existing AI and robotics technologies can perform job-related tasks relying on Large Language Models (LLMs). In a nutshell, instead of assessing AI exposure through external benchmarks such as expert judgment or AI patents and innovations data, we construct an internal assessment using LLM's own evaluation. To do so, we use O*NET as a reference taxonomy of about 1K"}, {"title": "Background and Related Works", "content": "AI and jobs. Since the seminal paper by Autor, Levy, and Murnane (2003), the task approach has proven to be very effective in analyzing the impact of technology and jobs. It divides work activities into tasks, each of which can be performed by humans or by machines. In this way, the distinction between capital and labour tasks is more precise, flexible, and able to shift over time. In fact, capital and machines can substitute for labour in the performance of a particular task while complementing it in the performance of others.\nThe task approach has been applied to analyse the effect of technology and trade (offshoring) Acemoglu and Autor (2011), to the long run effect of technology (Consoli et al. 2023) and to skill task interaction (Colombo, Mercorio, and Mezzanzanica 2019).\nThis approach has been used to measure occupational exposure to computers and robots recently. In a seminal paper Frey and Osborne (2017) estimated that up to 47% of jobs in the US are at risk of automation. Subsequently, other attempts focused on developing measures of exposure to machine learning and robotics Brynjolfsson and Mitchell (2017); Acemoglu and Restrepo (2020) and to AI Felten, Raj, and Seamans (2021); Webb (2023); Eloundou et al. (2023); Pizzinelli et al. (2023).\nOverall all these works find an extensive share of employment exposed to AI; the specific effect on occupations varies depending on the nuances that the different indicators capture about the effect of technology, i.e., whether they focus on aspects of technology that impact more routine-based activities (Frey and Osborne 2017) or more cognitive elements (Felten, Raj, and Seamans 2021). All these works share the attempt to quantify AI exposure through an external benchmark, which may be expert judgment or data analysis on patents and innovations. In contrast, our approach is based on an internal assessment, whereby LLM systems are asked to assess the suitability of tasks for AI. This approach has"}, {"title": "Building the AI Exposure Index", "content": "Our method can be summarised as follows: First, we obtain from O*NET the description of each task associated with each SOC occupation. Second, we apply LLMs to task descriptions to obtain a rating about how well AI technologies can accomplish each task. Third, we aggregate the rating at the occupation level to obtain an AI occupation score. Finally, we apply our score to US data to assess the extent of Al exposure in the US labour market and the effect of AI on employment and wages. Figure 1 provides a graphical representation of our approach."}, {"title": "Step 1: Compute the AI rate", "content": "To obtain the AI rate we propose a methodology driven by LLMs. To avoid the risk of being driven by the LLMs' well-known problem called \"hallucinations\u201d (Ji et al. 2023), we design a framework involving three different LLMs aiming to identify and limit the false information generated, creating a consensus system between them\nModel choice. To ensure the reproducibility of this work we use three of the best open source models, according to performance benchmarks, available on the open LLM leaderboard.4 To reduce the lack of computational complexity, we use 7 billion parameter models. The three selected models are Mistral 7B Instruct v 0.2 (Jiang et al. 2023),"}, {"title": "Prompt design.", "content": "The starting point is the O*NET taxonomy which identifies 19281 tasks for 923 SOC occupations. We formulate a five-shot prompt using the few-shot learning approach (Brown et al. 2020). We use each individual task description assigned to an occupation to ask the models how well, on a scale of 1 to 5,6 the combination of different AI technologies could perform the input task and a discursive motivation for the evaluation. As AI technologies, we consider i) LLMs for textual data understanding, ii) Image Processing Systems for elaboration and decision-making based on visual data analysis, and iii) Robotic systems for physical execution. At the end of the prompt, we provide the model with five examples of this task to obtain more contextual and accurate results.\nTo automate the methodology, the models are asked to return the result in a list format, with the rate as the first element and the motivation as the second element."}, {"title": "Consensus System.", "content": "We iterate this process for each task provided by O*NET and for each model chosen, ending up with three scores and natural language motivations provided by each model. Table 1 provides an example of the results after this stage for a selection of occupations and tasks.\nAs mentioned above, the choice to use three different models was made to avoid hallucinations. In order to construct a single indicator, we took a conservative approach by assigning to each task the value of the rating with the highest frequency among the three models; if the three rates were different, we selected the lowest.\nTo assess the agreement between the rates expressed by the LLMs, we compute a consensus metric (Tastle and Wierman 2007).\n$Cns(a_i) = 1 + \\sum_{k=1}^{m} p_k log_2(1 - \\frac{|LV_k - \\mu_{LV}|}{d_{LV}})$\n The equation 1 shows the consensus calculation in which $LV_k$ represents the observed rating value, $p_k$ its relative frequency, $\\mu_{LV}$ represents the weighted average of the LV ratings using $p_k$ probabilities as weights, and $d_{LV}$ represents the scale size of the ratings adopted. The logarithmic function calculates the impact of the normalised difference between each rating and the weighted average, moderated by the $d_{LV}$ dimension. The calculation uses a repeated summation for each k-th rate expressed for each individual task.\nSimilarly, to estimate the similarity between the motivations provided by the LLMs, we compute the centroid of semantic cosine similarity (Rahutomo et al. 2012), between the three motivations. The embedding vectors for the centroid computation is obtained using an open source Transformer model: as for the LLMs, we chose the Transformer model to be used in accordance with the Massive Text Embedding Benchmark (MTEB) Leaderboard.7 Having English-language motivations, the choice fell on the UAE-Large-V18, which represented an excellent compromise between effectiveness and efficiency, given its small size.\nNotably, as higher cosine similarity values reflect higher semantic similarities between the text of the LLM motivations, we expect a strong correlation between the consensus metric and the cosine similarity. On the one hand, this suggests coherence between LLM-generated rates and the associated motivations, on the other it adds robustness to our conservative approach in selecting the score among different models.\nThis process results in a single score TE that returns a metric from 1 to 5, measuring the extent to which AI can perform each specific task and a quantitative indicator of similarity between discursive motivation generated by models."}, {"title": "Step 2: Compute the AI exposure", "content": "To compute occupation exposure to AI, we aggregate the TE scores at the occupation level by weighting them by task relevance (R), importance (I) and frequency (F) as measured by O*NET. More specifically, for each task j and occupation i our AI exposure score is computed as follows\n$\u03a4\u0395\u0391\u0399_i = \\frac{\\sum_{j=1}^{n} TE_{ij} . R_{ij} I_{ij}. F_{ij}}{\\sum_{j=1}^{n} R_{ij} I_{ij}. F_{ij}}$\nwhere $TE_{ij}$ identifies the metric developed in step 1 at task level, n defines the number of tasks within each occupation. Each weight is scaled by its maximum to obtain equal weights. The O*NET model uses different scales for Relevance (scale 1-100), Importance (scale 1-5), and Frequency (scale 1-7). We normalised the indexes to ensure equal scale across weights. Finally, the score was normalised to ensure comparability with other similar scores."}, {"title": "Experimental Results", "content": "Benchmarking evaluation\nFirst, we compare our AI index with other existing measures in the literature. The pairwise correlation is always statistically significant at 5%. It is higher for the AIOE index, much lower for the AI Webb and the offshorability index, and negative for the Frey-Osborne index. This means our measure is broadly consistent with existing measures but captures different elements of the relationship between AI and the labour market. The negative correlation with the Frey and Osborne index can be explained by the latter being a measure of exposure to robotisation and computerisation and is more centred on routine tasks. At the same time, generative AI is more centred on cognitive/non-routine tasks.\nAI and skills\nNext we explore the relationship between our TEAI index and different skills. The graph shows the peculiar nature of AI technologies, which are positively correlated with cognitive analytical and interpersonal skills while negatively correlated with routine manual skills and non-routine manual skills that require physical adaptability. Surprisingly, the correlation with cognitive routine skills is only weekly positive, while it is positive for non-routine manual skills that require interpersonal adaptability. The results of the figure are purely descriptive, therefore we add a more robust analysis by extracting from O*NET the detailed skills associated with each occupation. We group skills into 4 classes: Cognitive, Social, Problem solving and management and Technical skills. We then develop a skill relevance index for each class at the occupation level by weighting each skill by its level and importance. The skill relevance index is constructed as follows:\n$SR_{ci} = \\frac{\\sum_{z=1}^{m} S_{zcj}L_{zcj}. I_{zcj}}{\\sum_{z=1}^{m} L_{zcj}. I_{zcj}}$\nwhere z denotes the m skills of class c in each occupation j; L and I denote, respectively, the level and importance of each skill in each occupation.\nWe therefore estimate the following regression:\n$TEAI_i = \u03b1_i + \u03b2S_i + \u03b3O_i + \u03b5_i$\nwhere each observation is a SOC occupation, $TEAI_i$ is our measure of AI exposure, S is a vector of skill relevance at the occupation level, and O defines occupation dummies. We saturate the model using more detailed dummies up to the fourth digit; therefore, the results are identified within group variation. Table 3 shows the results. The TEAI index is positively related to cognitive skills and problem-solving and management skills; on the contrary, as expected, it is negatively correlated with social skills. The relationship with technical skills is very weak and does not survive the inclusion of detailed SOC occupation dummies."}, {"title": "AI employment and wages", "content": "Finally, we explore the relationship between $TEAI$ and labour market outcomes. We start by analysing the size and the characteristics of workers exposed to AI technologies. First, we divide the distribution of $TEAI$ scores into three tertiles representing High, Medium and Low Al exposure. Subsequently, we computed the degree of exposure of the US population using BLS employment data. Finally, we distinguish between occupation groups and by skill groups within each tertile Over-all, in 2023, 34% of US employment is highly exposed to AI technologies, while medium and low exposure represents 32% and 34%, respectively. Our findings do not suggest a polarising effect of AI exposure as found by Frey and Osborne (2017); on the contrary, AI seems to have a more balanced impact on the labour market. This is because our indicator is able to capture recent advances in AI, such as LLMs, that have affected occupation groups such as management, business, administration, and finance, as well as ICT and science, which are intensive in non-routine cognitive tasks. For example, AI technologies are increasingly used to diagnose diseases, write reports, code, or brainstorm ideas in management and business. On the contrary, previous studies that focus more on the effect of AI on routine tasks find these tasks and occupations to be less exposed to AI.\nGrouping occupations by skill intensity shows that in the group highly exposed to AI, 88% of employment is in high-skill jobs; in the group with medium exposure 53% of employment is in medium-skill jobs while 40% in high-skill jobs. In the group with the lowest exposure 67% are medium-skill jobs and 25% low-skill jobs. Overall, AI exposure disproportionately affects high-skill jobs, characterised by the competencies most heavily affected by AI technologies.\nNext we analyse the relationship between Al exposure and workers' characteristics.\nFigure 5 shows that $TEAI$ exposure is higher for workers' with high level of education, in particular graduates and postgraduates. Age is slightly increasing in exposure to $TEAI$ albeit the variation in exposure is really limited above the age of 30. Males are more exposed than females at all age groups.\nFinally, we assess the relationship between Al exposure, employment, and wages. To compute the medium-term effect of AI in a flexible way, allowing for changes during the estimation period, we compute the log change in employment and wages over a 4-year rolling window from 2003 to 2019. Therefore, we run the following regression.\n$\\Delta y_{i,j} = \u03b1_i + \u03b2TEAI_i + \u03b3Z_{i,j} + \u03b4_i + \u03b7_j + \u03b5_{i,j}$\nwhere $\\Delta y_{i,j}$ denotes the 4 changes in log employment and log wages in sector j for occupation i. To control for possible endogeneity and omitted variable problems, we add the initial level of employment, the initial level of wage and wage squared. We also included detailed NAICS and SOC fixed effects in the regression, and we clustered errors at the NAICS level. Figure 6 demonstrates that exposure to artificial intelligence (AI) positively correlates with employment and wage growth. This suggests that AI technologies complement labour and enhance productivity, thereby increasing employment and wages in occupations with greater exposure to AI.\nThe presence of detailed controls at the industry and occupation level allows us to control for factors on the production side (changes in output across industries), on the demand side (changes in product demand across industries) and on the labour supply side (changes in employment across industries and occupations) that are unrelated to AI technologies and that could affect wages and employment. Moreover, the focus on a relatively short period of time isolates our results from long-term trends within industries and occupations.\nTherefore, the positive relationship between employment and wages and AI exposure should be interpreted as meaning that occupations more exposed to AI have stronger employment and wage growth within the occupation and sector. Our results contrast with those obtained by Acemoglu et al. (2022); Webb (2023), who find a negative relationship between employment and wages. The potential reconciliation between our findings and theirs lies, on the one hand, in our construction of a different measure of AI exposure, which emphasizes more recent advances in AI. On the other hand, our analysis concentrates on changes occurring in the last 20 years, whereas their analysis adopts a more long-term perspective, focusing on changes spanning several decades."}, {"title": "Conclusions, limitations and future extensions", "content": "This paper provides a comprehensive assessment of AI exposure for 19281 tasks for 923 SOC occupations identified by O*NET. We use the task description and perform the task assessment using LLMs own evaluation. We then aggregate task scores, obtaining an occupation-based score of AI exposure. Our methodology ensures the full reproducibility of results, allowing future assessment of potential performance improvements in new versions of LLMs. Our Al exposure index is positively related to cognitive, problem-solving and management skills, emphasising the role of recent advances in AI that heavily affect management and decision-making tasks; on the contrary, our measure is negatively correlated with social skills, a well-known area of weakness of AI.\nRegarding labour market outcomes, we find that AI exposure is positively associated with both employment and wage growth in the period 2003-2023, suggesting that AI has a positive effect on productivity. Therefore, at least in the medium run, Al has an overall positive impact on the labour market. However, our estimates show that high exposure to artificial intelligence affects about one-third of the American workforce, of which the largest part is composed of high-skill jobs. Whether for these workers, in the future, AI will turn out to be an opportunity or a threat will depend on whether AI will complement or substitute human labour. Our measure in this regard is relatively agnostic, as we cannot yet disentangle the substitutability from the complementarity effect. In other words, a high exposure metric does not necessarily imply full substitution of labour by technology, which, on the contrary, may fully complement human activities, leading to higher productivity without displacing labour. Future research will explore this important distinction."}]}