{"title": "Towards the Terminator Economy: Assessing Job Exposure to AI through LLMs", "authors": ["Emilio Colombo", "Fabio Mercorio", "Mario Mezzanzanica", "Antonio Serino"], "abstract": "The spread and rapid development of AI-related technologies are influencing many aspects of our daily lives, from social to educational, including the labour market. Many researchers have been highlighting the key role AI and technologies play in reshaping jobs and their related tasks, either by automating or enhancing human capabilities in the workplace. Can we estimate if, and to what extent, jobs and related tasks are exposed to the risk of being automatized by state-of-the-art AI-related technologies? Our work tackles this question through a data-driven approach: (i) developing a reproducible framework that exploits a battery of open-source Large Language Models to assess current AI and robotics' capabilities in performing job-related tasks; (ii) formalising and computing an Al exposure measure by occupation, namely the TEAI (Task Exposure to AI) index. Our results show that about one-third of U.S. employment is highly exposed to AI, primarily in high-skill jobs (aka, white collars). This exposure correlates positively with employment and wage growth from 2019 to 2023, indicating a beneficial impact of AI on productivity. The source codes and results are publicly available, enabling the whole community to benchmark and track AI and technology capabilities over time.", "sections": [{"title": "Introduction", "content": "The 1984 famous movie \"The Terminator\" is set in a dystopian future where intelligent machines, created by a military defence system known as Skynet, become self- aware and perceive humanity as a threat, initiating a war to eliminate humans. Skynet creates advanced humanoid robots called Terminators to hunt down and kill human sur- vivors. The Terminator possesses advanced learning algo- rithms that enable it to adapt to any environment, making it a formidable antagonist for humans. The debate and con- cerns about the impact of AI are often conducted against the backdrop of the film's setting. This paper takes these con- cerns seriously by developing an AI-centered assessment of the possible exposure of different occupations to artificial intelligence. Assessing the potential impacts of technology on the labour market is not easy, as there are several po- tential channels at work. As stressed by Acemoglu and Re- strepo (2019) technology has three major effects on labour demand. The first is the productivity effects that operate through lower production costs brought about by new tech- nologies. The second is the displacement effect of workers operated by machines and alike. These two effects operate in different directions and depend on whether technology sub- stitutes or complements human labour. Economic jargon de- pends on the elasticity of substitution between tasks. More- over, there is another third effect of technology: the creation of new tasks and activities where labour can be productively employed (reinstatement effect). Indeed, if we look at his- tory, the reinstatement effect has been a central feature of all technological revolutions that continuously created new opportunities for labour. For the reinstatement effect to take hold, technology must have a wider impact than its narrow scope, with spillover effects in sectors/areas other than those for which it was designed. In other words, technology must have the features of a general purpose technology, which, ac- cording to Lipsey, Carlaw, and Bekar (2005), are pervasive- ness across the economy, ability to generate complementary innovations, and improvement over time.\nAI, due to its broad applicability, potential productivity gains, and potential for driving further innovation, provides strong arguments for being considered a general-purpose technology. These features of AI, however, create a relevant measurement issue, as it is extremely difficult to identify all the channels through which it affects the economy. This pa- per contributes to this field by developing a methodology for assessing Al exposure using Large Language Models (LLMs), using a very granular approach that analyses ex- posure for each task that makes up each occupation.\nContribution. Our main contribution is twofold:\n1.  From a methodological point of view, we design and im- plement a reproducible framework to estimate to what extent existing AI and robotics technologies can per- form job-related tasks relying on Large Language Mod- els (LLMs). In a nutshell, instead of assessing AI expo- sure through external benchmarks such as expert judg- ment or AI patents and innovations data, we construct an internal assessment using LLM's own evaluation. To do so, we use O*NET as a reference taxonomy of about 1K"}, {"title": "", "content": "occupations and 19K+ job-related tasks.\n2.  From an economic perspective, we develop an AI expo- sure measure for individual tasks reaching a high level of granularity. Then, we show that in the US, approximately 1/3 of employment is highly exposed to AI technologies, the major being high-skill jobs. Finally, we show that AI exposure is positively associated with employment and wage growth in 2019-2023, suggesting a positive effect of AI technologies on productivity.\nTo allow the community to compare our results and estimate the advances of LLMs capabilities over time, both codes and the enriched O*NET have been made available on GitHub\u00b2. The remainder of the paper is structured as follows: sec- tion discusses the related literature, section describes the methodology and the construction of the AI index, section presents the results; finally section concludes."}, {"title": "Background and Related Works", "content": "AI and jobs. Since the seminal paper by Autor, Levy, and Murnane (2003), the task approach has proven to be very effective in analyzing the impact of technology and jobs. It divides work activities into tasks, each of which can be per- formed by humans or by machines. In this way, the distinc- tion between capital and labour tasks is more precise, flexi- ble, and able to shift over time. In fact, capital and machines can substitute for labour in the performance of a particular task while complementing it in the performance of others.\nThe task approach has been applied to analyse the effect of technology and trade (offshoring) Acemoglu and Autor (2011), to the long run effect of technology (Consoli et al. 2023) and to skill task interaction (Colombo, Mercorio, and Mezzanzanica 2019).\nThis approach has been used to measure occupational ex- posure to computers and robots recently. In a seminal pa- per Frey and Osborne (2017) estimated that up to 47% of jobs in the US are at risk of automation. Subsequently, other attempts focused on developing measures of exposure to machine learning and robotics Brynjolfsson and Mitchell (2017); Acemoglu and Restrepo (2020) and to AI Felten, Raj, and Seamans (2021); Webb (2023); Eloundou et al. (2023); Pizzinelli et al. (2023).\nOverall all these works find an extensive share of employ- ment exposed to AI; the specific effect on occupations varies depending on the nuances that the different indicators cap- ture about the effect of technology, i.e., whether they focus on aspects of technology that impact more routine-based ac- tivities (Frey and Osborne 2017) or more cognitive elements (Felten, Raj, and Seamans 2021). All these works share the attempt to quantify AI exposure through an external bench- mark, which may be expert judgment or data analysis on patents and innovations. In contrast, our approach is based on an internal assessment, whereby LLM systems are asked to assess the suitability of tasks for AI. This approach has"}, {"title": "", "content": "two major advantages. Firstly, it is fully transparent, with outcomes and results being fully disclosed. Secondly, the approach is entirely reproducible. This implies that when subsequent generations of LLM are available, they can be employed in our approach to measuring the change in task exposure that they imply.\nLarge Language Models. LLMs are powerful computa- tional models designed to understand and generate human- like text by leveraging vast amounts of textual data, have taken Natural Language Processing (NLP) by storm, achiev- ing state-of-the-art performance on many tasks (Min et al. 2023). Typically these models are based on Transformer architecture (Vaswani et al. 2017), powered by Attention mechanism (Luong, Pham, and Manning 2015; Bahdanau, Cho, and Bengio 2014) and are composed by decoder-only stack. These models are initially trained on Autoregressive task (Radford et al. 2018), where given a sequence of words S = (W1,W2, ..., Wn\u22121) the training objective is to maxi- mize the log-likelihood \u2211; log P(wi|w1, W2, ..., Wi\u22121; 0T) where 0T are the model parameters, in order to predict the next word in the sequence \u03a0-1 P(Wi | W1, ..., Wi\u22121). Af- ter being pre-trained, these models are fine-tuned for sev- eral tasks, providing examples of Natural Language Infer- ence (Radford et al. 2018). Thanks to their capability to learn from context, known as in-context learning (Radford et al. 2019), LLMs can accomplish specific tasks with high accuracy (Zhao et al. 2023), exploiting prompt engineering methodologies such as zero-shot (Wei et al. 2021) and few-shot learning (Brown et al. 2020).\nBuilding the AI Exposure Index\nOur method can be summarised as follows: First, we obtain from O*NET the description of each task associated with each SOC occupation. Second, we apply LLMs to task de- scriptions to obtain a rating about how well AI technologies can accomplish each task. Third, we aggregate the rating at the occupation level to obtain an AI occupation score. Fi- nally, we apply our score to US data to assess the extent of Al exposure in the US labour market and the effect of AI on employment and wages. Figure 1 provides a graphical rep- resentation of our approach.\nStep 1: Compute the AI rate\nTo obtain the AI rate we propose a methodology driven by LLMs. To avoid the risk of being driven by the LLMs' well- known problem called \"hallucinations\u201d (Ji et al. 2023), we design a framework involving three different LLMs aiming to identify and limit the false information generated, creating a consensus system between them\nModel choice. To ensure the reproducibility of this work we use three of the best open source models, according to performance benchmarks, available on the open LLM leaderboard.4 To reduce the lack of computational complex- ity, we use 7 billion parameter models. The three selected models are Mistral 7B Instruct v 0.2 (Jiang et al. 2023),\""}, {"title": "Prompt design.", "content": "The starting point is the O*NET taxon- omy which identifies 19281 tasks for 923 SOC occupa- tions. We formulate a five-shot prompt using the few-shot learning approach (Brown et al. 2020). We use each indi- vidual task description assigned to an occupation to ask the models how well, on a scale of 1 to 5,6 the combination of different AI technologies could perform the input task and a discursive motivation for the evaluation. As AI technolo- gies, we consider i) LLMs for textual data understanding, ii) Image Processing Systems for elaboration and decision- making based on visual data analysis, and iii) Robotic sys- tems for physical execution. At the end of the prompt, we provide the model with five examples of this task to obtain more contextual and accurate results.\nTo automate the methodology, the models are asked to return the result in a list format, with the rate as the first element and the motivation as the second element.\nConsensus System. We iterate this process for each task provided by O*NET and for each model chosen, ending up with three scores and natural language motivations provided by each model. Table 1 provides an example of the results after this stage for a selection of occupations and tasks.\nAs mentioned above, the choice to use three different models was made to avoid hallucinations. In order to con- struct a single indicator, we took a conservative approach by assigning to each task the value of the rating with the high- est frequency among the three models; if the three rates were different, we selected the lowest.\nTo assess the agreement between the rates expressed by the LLMs, we compute a consensus metric (Tastle and Wier- man 2007).\n$Cns(a_i) = 1 + \\sum_{k=1}^{m} p_k log_2(1 - \\frac{|LV_k - \\mu_{LV}|}{d_{LV} \\cdot \\mu_{LV}})$       (1)\nThe equation 1 shows the consensus calculation in which $LV_k$ represents the observed rating value, $p_k$ its relative fre- quency, $\\mu_{LV}$ represents the weighted average of the LV rat- ings using $p_k$ probabilities as weights, and $d_{LV}$ represents the scale size of the ratings adopted. The logarithmic func- tion calculates the impact of the normalised difference be- tween each rating and the weighted average, moderated by the $d_{LV}$ dimension. The calculation uses a repeated summa- tion for each k-th rate expressed for each individual task.\nSimilarly, to estimate the similarity between the moti- vations provided by the LLMs, we compute the centroid of semantic cosine similarity (Rahutomo et al. 2012), be- tween the three motivations. The embedding vectors for the centroid computation is obtained using an open source Transformer model: as for the LLMs, we chose the Trans- former model to be used in accordance with the Massive Text Embedding Benchmark (MTEB) Leaderboard.7 Hav- ing English-language motivations, the choice fell on the UAE-Large-V18, which represented an excellent compro- mise between effectiveness and efficiency, given its small size."}, {"title": "Step 2: Compute the AI exposure", "content": "To compute occupation exposure to AI, we aggregate the TE scores at the occupation level by weighting them by task rel- evance (R), importance (I) and frequency (F) as measured by O*NET. More specifically, for each task j and occupa- tion i our AI exposure score is computed as follows\n$TEAI_i = \\frac{\\sum_{j=1}^{n} TE_{ij} \\cdot R_{ij} I_{ij}. F_{ij}}{\\sum_{j=1}^{n} R_{ij} I_{ij}. F_{ij}}$        (2)\nwhere $TE_{ij}$ identifies the metric developed in step 1 at task level, n defines the number of tasks within each occupa- tion. Each weight is scaled by its maximum to obtain equal weights. The O*NET model uses different scales for Rele- vance (scale 1-100), Importance (scale 1-5), and Frequency (scale 1-7). We normalised the indexes to ensure equal scale across weights. Finally, the score was normalised to ensure comparability with other similar scores.\nExperimental Results\nBenchmarking evaluation\nFirst, we compare our AI index with other existing measures in the literature. Figure 3a shows the correlation between the $TEAI$ index and the well-known measure developed by Frey and Osborne (2017), the AI exposure index by Felten, Raj, and Seamans (2021) and by Webb (2023) and the off- shorability index developed by Acemoglu and Autor (2011). The pairwise correlation is always statistically significant at 5%. It is higher for the AIOE index, much lower for the AI Webb and the offshorability index, and negative for the Frey-Osborne index. This means our measure is broadly consis- tent with existing measures but captures different elements of the relationship between AI and the labour market. The negative correlation with the Frey and Osborne index can be explained by the latter being a measure of exposure to robo- tisation and computerisation and is more centred on routine tasks. At the same time, generative AI is more centred on cognitive/non-routine tasks.\nAI and skills\nNext we explore the relationship between our $TEAI$ index and different skills. In figure 3b, we plot scatterplots com- paring the $TEAI$ index with the intensity of different skill types at occupation level derived from Acemoglu and Autor (2011). The graph shows the peculiar nature of AI technolo- gies, which are positively correlated with cognitive analyti- cal and interpersonal skills while negatively correlated with routine manual skills and non-routine manual skills that re- quire physical adaptability. Surprisingly, the correlation with"}, {"title": "", "content": "cognitive routine skills is only weekly positive, while it is positive for non-routine manual skills that require interper- sonal adaptability. The results of the figure are purely de- scriptive, therefore we add a more robust analysis by extract- ing from O*NET the detailed skills associated with each oc- cupation. We group skills into 4 classes: Cognitive, Social, Problem solving and management and Technical skills. We then develop a skill relevance index for each class at the oc- cupation level by weighting each skill by its level and impor- tance. 10 The skill relevance index is constructed as follows:\n$SR_{ci} = \\frac{\\sum_{z=1}^{m} S_{zcj}L_{zcj}. I_{zcj}}{\\sum_{z=1}^{m} L_{zcj}. I_{zcj}}$        (3)\nwhere z denotes the m skills of class c in each occupation j; L and I denote, respectively, the level and importance of each skill in each occupation.\nWe therefore estimate the following regression:\n$TEAI_i = a_i + \\beta S_i + \\gamma O_i + \\epsilon_i$\nwhere each observation is a SOC occupation, $TEAI_i$ is our measure of AI exposure, S is a vector of skill relevance at the occupation level, and O defines occupation dummies. We saturate the model using more detailed dummies up to the fourth digit; therefore, the results are identified within group variation. Table 3 shows the results. The TEAI in- dex is positively related to cognitive skills and problem- solving and management skills; on the contrary, as expected, it is negatively correlated with social skills. The relationship with technical skills is very weak and does not survive the inclusion of detailed SOC occupation dummies."}, {"title": "AI employment and wages", "content": "Finally, we explore the relationship between $TEAI$ and labour market outcomes. We start by analysing the size and the characteristics of workers exposed to AI technologies. First, we divide the distribution of $TEAI$ scores into three tertiles representing High, Medium and Low Al exposure. Subsequently, we computed the degree of exposure of the US population using BLS employment data. Finally, we distinguish between occupation groups and by skill groups within each tertile. Figures 6a and 4b show the results. Over- all, in 2023, 34% of US employment is highly exposed to AI technologies, while medium and low exposure represents 32% and 34%, respectively. Our findings do not suggest a polarising effect of AI exposure as found by Frey and Os- borne (2017); on the contrary, AI seems to have a more bal- anced impact on the labour market. This is because our indi- cator is able to capture recent advances in AI, such as LLMs, that have affected occupation groups such as management, business, administration, and finance, as well as ICT and sci- ence, which are intensive in non-routine cognitive tasks. For example, AI technologies are increasingly used to diagnose diseases, write reports, code, or brainstorm ideas in man- agement and business. On the contrary, previous studies that focus more on the effect of AI on routine tasks find these tasks and occupations to be less exposed to AI.\nGrouping occupations by skill intensity shows that in the group highly exposed to AI, 88% of employment is in high-skill jobs; in the group with medium exposure 53% of employment is in medium-skill jobs while 40% in high-skill jobs. In the group with the lowest exposure 67% are medium-skill jobs and 25% low-skill jobs. Overall, AI expo- sure disproportionately affects high-skill jobs, characterised by the competencies most heavily affected by AI technolo- gies.\nNext we analyse the relationship between Al exposure and workers' characteristics.\nFigure 5 shows that $TEAI$ exposure is higher for work- ers' with high level of education, in particular graduates and postgraduates. Age is slightly increasing in exposure to $TEAI$ albeit the variation in exposure is really limited above the age of 30. Males are more exposed than females at all age groups.\nFinally, we assess the relationship between Al exposure, employment, and wages. To compute the medium-term ef- fect of AI in a flexible way, allowing for changes during the estimation period, we compute the log change in employ- ment and wages over a 4-year rolling window from 2003 to 2019. Therefore, we run the following regression.\n$\\Delta y_{i,j} = \\alpha_i + \\beta TEAI_i + \\gamma Z_{i,j} + d_i + N_j + \\epsilon_{i,j}$       (4)\nwhere $\\Delta y_{i,j}$ denotes the 4 changes in log employment and log wages in sector j for occupation i. To control for possible endogeneity and omitted variable problems, we add the initial level of employment, the initial level of wage and wage squared. We also included detailed NAICS and SOC fixed effects in the regression, and we clustered errors at the NAICS level. Figure 6 demonstrates that exposure to artifi- cial intelligence (AI) positively correlates with employment and wage growth. This suggests that AI technologies com- plement labour and enhance productivity, thereby increasing employment and wages in occupations with greater expo- sure to AI.\nThe presence of detailed controls at the industry and occu- pation level allows us to control for factors on the production side (changes in output across industries), on the demand side (changes in product demand across industries) and on the labour supply side (changes in employment across indus- tries and occupations) that are unrelated to AI technologies"}, {"title": "Conclusions, limitations and future extensions", "content": "This paper provides a comprehensive assessment of AI ex- posure for 19281 tasks for 923 SOC occupations identified by O*NET. We use the task description and perform the task assessment using LLMs own evaluation. We then aggregate task scores, obtaining an occupation-based score of AI ex- posure. Our methodology ensures the full reproducibility of results, allowing future assessment of potential performance improvements in new versions of LLMs. Our Al exposure index is positively related to cognitive, problem-solving and management skills, emphasising the role of recent advances in AI that heavily affect management and decision-making tasks; on the contrary, our measure is negatively correlated with social skills, a well-known area of weakness of AI.\nRegarding labour market outcomes, we find that AI ex- posure is positively associated with both employment and wage growth in the period 2003-2023, suggesting that AI has a positive effect on productivity. Therefore, at least in the medium run, Al has an overall positive impact on the labour market. However, our estimates show that high ex- posure to artificial intelligence affects about one-third of the American workforce, of which the largest part is composed of high-skill jobs. Whether for these workers, in the future, AI will turn out to be an opportunity or a threat will depend on whether AI will complement or substitute human labour. Our measure in this regard is relatively agnostic, as we can- not yet disentangle the substitutability from the complemen- tarity effect. In other words, a high exposure metric does not necessarily imply full substitution of labour by technol- ogy, which, on the contrary, may fully complement human activities, leading to higher productivity without displacing labour. Future research will explore this important distinc- tion."}]}