{"title": "Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention", "authors": ["Susung Hong"], "abstract": "Conditional diffusion models have shown remarkable success in visual content generation, producing high-quality samples across various domains, largely due to classifier-free guidance (CFG). Recent attempts to extend guidance to unconditional models have relied on heuristic techniques, resulting in suboptimal generation quality and unintended effects. In this work, we propose Smoothed Energy Guidance (SEG), a novel training- and condition-free approach that leverages the energy-based perspective of the self-attention mechanism to enhance image generation. By defining the energy of self-attention, we introduce a method to reduce the curvature of the energy landscape of attention and use the output as the unconditional prediction. Practically, we control the curvature of the energy landscape by adjusting the Gaussian kernel parameter while keeping the guidance scale parameter fixed. Additionally, we present a query blurring method that is equivalent to blurring the entire attention weights without incurring quadratic complexity in the number of tokens. In our experiments, SEG achieves a Pareto improvement in both quality and the reduction of side effects. The code is available at https://github.com/SusungHong/SEG-SDXL.", "sections": [{"title": "1 Introduction", "content": "Diffusion models [12, 45, 46] have emerged as a promising tool for visual content generation, producing high-quality and diverse samples across various domains, including image [38, 40, 42, 8, 13, 30, 2, 24, 9, 29, 34, 33, 4, 41, 5, 20, 22], video [11, 50, 23, 18, 15, 3, 19, 44], and 3D generation [36, 27, 6, 26, 49, 43, 48, 16]. The success of these models can be largely attributed to the use of classifier-free guidance (CFG) [14], which enables sampling from a sharper distribution, resulting in improved sample quality. However, CFG is not applicable to unconditional image generation, where no specific conditions are provided, creating a disparity between the capabilities of text-conditioned sampling and sampling without text. This disparity results in a restriction in application, e.g., synthesizing images with ControlNet[51] without a text prompt (see the last two columns of Fig. 1).\nRecent literature [17, 1] has attempted to decouple CFG and image quality by extending guidance to general diffusion models, leveraging their inherent representations [25, 32, 17]. Self-attention guidance (SAG) [17] proposes leveraging the intermediate self-attention map of diffusion models to blur the input pixels and provide guidance, while perturbed attention guidance (PAG) [1] perturbs the attention map itself by replacing it with an identity attention map. Despite these efforts, these methods rely on heuristics to make perturbed predictions, resulting in unintended effects such as smoothed-out details, saturation, color shifts, and significant changes in the image structure when given a large guidance scale. Notably, the mathematical underpinnings of these unconditional guidance approaches are not well elucidated.\nIn this work, we approach the objective from an energy-based perspective of the self-attention mechanism, which has been previously explored based on its close connection to the Hopfield energy [39, 31, 7]. Specifically, we start from the definition of the energy of self-attention, where"}, {"title": "2 Preliminaries", "content": ""}, {"title": "2.1 Diffusion models", "content": "Diffusion models [12, 45, 46] are a class of generative models that generate data through an iterative denoising process. The process of adding noise to an image x over time $t \\in [0, T]$ is governed by the forward stochastic differential equation (SDE):\n$dx = f(x,t)dt + g(t)dw,$\nwhere f and g are predefined functions that determine the manner in which the noise is added, and dw denotes a standard Wiener process.\nCorrespondingly, the denoising process can be described by the reverse SDE:\n$dx = [f(x, t) - g(t)^2\\nabla_x \\log p_t(x)]dt + g(t)dw,$\nwhere $\\nabla_x \\log p_t(x)$ represents the score of the noisy data distribution and dw denotes the standard Wiener process for the reversed time."}, {"title": "2.2 Energy-based view of attention mechanism", "content": "The attention mechanism [47], which has been widely adopted in diffusion models [12], has been interpreted through the lens of energy-based models (EBMs) [31, 39, 7], especially through its close connection with the Hopfield energy [7, 39]. In the modern (continuous) Hopfield network, the attention operation can be derived based on the concave-convex procedure (CCCP) from the following energy function [39]:\n$E(\\mathcal{X}) = -lse(X\\mathcal{X}^T) + \\frac{1}{\\gamma}\\mathcal{X}^T\\mathcal{X},$\nwhere $\\mathcal{X} \\in \\mathbb{R}^{1 \\times d}$, $X \\in \\mathbb{R}^{N \\times d}$, and lse stands for the log-sum-exp function, defined as $lse(v) := \\log (\\sum_i e^{v_i})$. The quadratic term acts as a regularizer to prevent $\\mathcal{X}$ from exploding [39], while $-lse(X\\mathcal{X}^T)$ penalizes misalignment between X and $\\mathcal{X}$.\nMathematically, it turns out that the attention mechanism is equivalent to the update rule of the modern Hopfield network [7, 39]. Specifically, inspired by the Hopfield energy in (4), and noticing that the first term depends on the attention weights, we propose the following energy function for entire self-attention weights in diffusion models:\nDefinition 2.1 (Energy Function for Self-Attention). Let $Q \\in \\mathbb{R}^{(HW) \\times d}$ be a matrix of query vectors and $K \\in \\mathbb{R}^{(HW) \\times d}$ be a matrix of key vectors, where H, W, and d represent the height, width, and dimension, respectively. Let $A \\in \\mathbb{R}^{(HW) \\times (HW)} := QK^T$. The energy function with respect to entire self-attention weights in diffusion models is defined as:\n$E(A) := \\sum_{i=1}^{HW}\\sum_{j=1}^{HW}E' (a_{(i,j)}), E' (a) := -lse (a) = -\\log (\\sum_{k=1}^{HW}\\sum_{l=1}^{HW}e^{a_{(k,l)}})$\nNote that to explicitly denote the spatial dimension, we use the subscript (x, y) to represent the index of a row or column of the matrices. Despite using the definition in (5) for the rest of the paper for simplicity, we additionally discuss the dual case, where we use the swapped indexing, in Appendix B.\nThis view leads us to an important intuition: the attention operation can be seen as a minimization step on the energy landscape, considering that the first derivative represents the softmax operation which also appears in the attention operation. Building upon this intuition, we argue that Gaussian blurring on the attention weights modulates the underlying landscape to have less curvature, and we demonstrate this in the following sections by analyzing the second derivatives."}, {"title": "3 Method", "content": "Our aim is to theoretically derive the effect of Gaussian blur applied on the attention weights, which in the end attenuates the curvature of the underlying energy function. Then, utilizing this fact, we develop attention-based drop-in diffusion guidance that enhances the quality of the generated samples, regardless of whether an explicit condition is given. In Section 3.1, we claim some useful properties of Gaussian blur: that it preserves mean, reduces variance, and thus decreases the lse value. In Section 3.2, we find that the curvature of the energy landscape is attenuated by the attention blur operation, leading naturally to a blunter prediction for guidance. And finally, in Section 3.3, built upon this fact, we define Smoothed Energy Guidance (SEG) and propose the equivalent query blurring method, which can perform attention blurring while avoiding quadratic complexity in the number of tokens."}, {"title": "3.1 Gaussian blur to attention weights", "content": "In this section, we derive some important properties of the Gaussian blur with the aim of figuring out the variation of the energy landscape. To this end, we start from some mathematical underpinnings on applying Gaussian blur to attention weights.\nA 2D Gaussian filter is a convolution kernel that uses a 2D Gaussian function to assign weights to neighboring pixels. The 2D Gaussian function is defined as:\n$G(x,y) = \\frac{1}{2\\pi\\sigma^2}e^{-\\frac{(x-\\mu_x)^2+(y-\\mu_y)^2}{2\\sigma^2}}$\nwhere $\\mu_x$ and $\\mu_y$ are the means in the x and y directions, and $\\sigma$ is the standard deviation. The 2D Gaussian filter possesses symmetry, i.e., $G(x,y) = G(-x,-y)$, and normalization, i.e., $\\int\\int G(x,y)dxdy = 1$. In practice, we use a discretized version of the Gaussian filter with a finite kernel size depending on $\\sigma$, normalized to sum to 1.\nLemma 3.1. Spatially applying a 2D Gaussian blur to the attention weights $a := Qk^T$ preserves the average $\\mathbb{E}_{i,j}[a_{(i,j)}]$. In addition, the variance monotonically decreases every time we apply the Gaussian blur.\nProof sketch. Applying a 2D Gaussian filter to the attention weights $a_{(i,j)}$ yields the blurred values $\\tilde{a}_{(i,j)}$:\n$\\tilde{a}_{(i,j)} = \\sum_{m=-k}^{k}\\sum_{n=-k}^{k} G(m,n) \\cdot a_{(i+m,j+n)}$\nwhere k is the filter size, G(m, n) is the Gaussian filter value at position (m, n), and $a_{(i+m,j+n)}$ is the attention weight at position (i + m, j + n). Since the Gaussian filter is symmetric and normalized, it can be shown that the mean of the blurred attention weights is equal to the mean of the original attention weights. Similarly, we can show that the variance monotonically decreases when we apply a 2D Gaussian filter. See Appendix A.1 for the complete proof.\nNote that this fact also implies that blurring with a Gaussian filter with a larger standard deviation causes a greater decrease in the variance of attention weights. This is because a Gaussian filter with a larger standard deviation can always be represented as a convolution of two filters with smaller standard deviations, due to the associativity of the convolution operation.\nFinally, we show that applying a 2D Gaussian blur to attention weights increases the lse value in (5), i.e., increases the energy in (5). This provides a bit of intuition about the underlying energy landscape, yet it is more prominently utilized in the claims in the following sections.\nLemma 3.2. Applying a 2D Gaussian blur to attention weights $a := Qk^T$ increases the lse term when we consider the second-order Taylor series approximation of the exponential function around the mean $\\mu := \\mathbb{E}_{i,j}[a_{(i,j)}]$. Consequently, the maximum is achieved when the attention is uniform, i.e., $a_{(i,j)} = a_{(k,l)} \\forall i,j,k,l$. This corresponds to the case when we apply the Gaussian blur with $\\sigma \\rightarrow \\infty$.\nProof sketch. Applying the second-order Taylor series approximation around the mean $\\mu$, and using Proposition 3.1, we show that the second-order approximation of lse(a) is larger than or equal to that of lse(a). Subsequently, we introduce Lagrange multipliers to find the maximum, which gives us the result, $a_{(i,j)} = a_{(k,l)} \\forall i, j, k, l$. We leave the full proof in Appendix A.2."}, {"title": "3.2 Analysis of the energy landscape", "content": "In this section, we demonstrate that applying a 2D Gaussian blur to the attention weights before the softmax operation results in computing the updated value with reduced curvature of the underlying energy function. To this end, we analyze the Gaussian curvature before and after blurring the attention weights. This is closely related to the Hessian of the energy function.\nTheorem 3.1. Let the attention weights be defined as $a := Qk^T$. Consider the energy function in (5). Then, applying a Gaussian blur to the attention weights a before the softmax operation results in the attenuation of the Gaussian curvature of the underlying energy function where gradient descent is performed."}, {"title": "3.3 Smoothed energy guidance for diffusion models", "content": "Based on the above observation that the Gaussian blur on attention weights attenuates the curvature of the energy function, we propose Smoothed Energy Guidance (SEG) in this section. For brevity, we redefine the unconditional score prediction as $s_\\theta(x, t)$, and the unconditional score prediction with the energy curvature reduced as $\\check{s}_\\theta(x, t)$. Specifically, $\\check{s}_\\theta(x, t)$ is the prediction with the attention weights blurred using a 2D Gaussian filter G with the standard deviation $\\sigma$. We formulate the process as:\n$(QK^T)_{seg} = G * (QK^T)$,\nwhere * denotes the 2D convolution operator. Then, we replace the original attention weights with $(QK^T)_{seg}$ and compute the final value as in ordinary self-attention.\nFor practical purposes when the number of tokens is large, we propose an efficient computation of (6) using the property of a linear map, since the convolution operation is linear. Concretely, blurring queries is exactly the same as blurring the entire attention weights, and we propose the following proposition to justify our claim.\nProposition 3.1. Let Q and K be the query and key matrices in self-attention, and let G be a 2D Gaussian filter. Blurring the attention weights with G is equivalent to blurring the query matrix Q with G and then computing the attention weights.\nProof. Since the convolution operation is linear, we can always find a Toeplitz matrix B such that:\n$G * (QK^T) = B(QK^T)$,\nwhere * denotes the 2D convolution operation. Using the properties of matrix multiplication, we can rewrite (7) as:\n$B(QK^T) = (BQ)K^T = (G* Q)K^T$.\nFinally, SEG is formulated as follows:\n$dx = [f(x, t) - g(t)^2(\\gamma_{seg}s_\\theta(x, t) - (\\gamma_{seg} - 1)\\check{s}_\\theta(x, t))]dt + g(t)dw,$\nwhere $\\gamma_{seg}$ denotes the guidance scale of SEG.\nIn a straightforward manner, as SEG does not rely on external conditions, it can be used for conditional sampling strategies such as CFG [14] and ControlNet [51]. For the combinatorial sampling with CFG, following [17], we simply extend (9) for improved conditional sampling with both SEG and CFG as follows:\n$dx = [f(x, t) - g(t)^2((1-\\gamma_{cfg} + \\gamma_{seg})s_\\theta(x, t) + \\gamma_{cfg}s_\\theta(x, t, c) - \\gamma_{seg}\\check{s}_\\theta(x, t))]dt+g(t)dw,$"}, {"title": "5 Experiments", "content": ""}, {"title": "5.1 Implementation details", "content": "We build upon the current open-source state-of-the-art diffusion model, Stable Diffusion XL (SDXL) [35], as our baseline, and do not change the configuration. To sample with SEG, we choose the same attention layers (mid-blocks) and guidance scale as PAG [1]. For SEG and PAG sampling, we use the Euler discrete scheduler [21], while for SAG [17], we instead use the DDIM scheduler [45] since the current implementation of SAG does not support the Euler discrete sampler. For SAG and PAG, we use the same configurations they used in the experiments with the previous version of Stable Diffusion, with guidance scales of 1.0 and 3.0, respectively. We set $\\gamma_{seg}$ to 3.0, except in the ablation study."}, {"title": "5.2 Metrics", "content": "We use various metrics to evaluate quality (FID [10] and CLIP score [37], calculated with 30k references from the MS-COCO 2014 validation set [28]) and to assess the extent of change due to"}, {"title": "5.3 Controlling image generation with the standard deviation", "content": "In this section, our aim is to demonstrate that with SEG, we can sample plausible images using vanilla SDXL [35] under various conditions and even without any conditions, as demonstrated in Fig. 1. Furthermore, without the risk of saturation, we can control the quality and plausibility of the samples. For the results, we use $\\sigma\\in \\{1,2,5,10\\}$. Additionally, as mentioned in Sec. 3.3, we present two extreme cases, $\\sigma \\rightarrow 0$ (vanilla SDXL) and $\\sigma \\rightarrow \\infty$ (uniform queries).\nUnconditional generation In this section, our aim is to demonstrate that with SEG, we can sample plausible images from the unconditional mode of the vanilla SDXL, which was originally trained on a large-scale text-to-image dataset. The results are presented in Fig. 1, Fig. 2, and Table 1. The results show a clear tendency to draw higher quality samples by utilizing the differences between the two energy landscapes with different curvatures derived from self-attention mechanisms.\nIn Fig. 2 and Fig. 12, we show the effectiveness of generating more plausible images, while vanilla SDXL is unable to generate high-quality images without any conditions. The results show a clear tendency to draw higher quality samples by utilizing the differences between the two energy landscapes"}, {"title": "5.4 Comparison with previous methods", "content": "Since the results are visually favorable when we use $\\sigma = 10$ and $\\sigma \\rightarrow \\infty$, and they are the best in terms of CLIP score and FID, respectively, we adopt those configurations for comparison of unconditional guidance methods. The results are presented in Figs. 5, 7, 8, and Table 1. Notably, our method achieves better image quality in terms of FID, while remaining similar to the original output of vanilla SDXL as measured by LPIPS, implying a Pareto improvement."}, {"title": "5.5 Ablation study", "content": "In this section, we address two parameters, $\\gamma_{seg}$ and $\\sigma$, and justify that fixing $\\gamma_{seg}$ is a reasonable choice. In Fig. 6, we present the results from our testing. The results reveal that increasing $\\gamma_{seg}$ does not generally lead to improved sample quality in terms of FID and CLIP score, due to various issues such as saturation. In contrast, increasing $\\sigma$ tends to improve sample quality and plausibility. This supports the claim that image quality should be controlled by $\\sigma$, instead of the guidance scale parameter. We sample 30k images for each combination to calculate the metrics."}, {"title": "6 Conclusion, limitations and societal impacts", "content": "Conclusion We introduce Smoothed Energy Guidance (SEG), a novel training- and condition-free guidance method for image generation with diffusion models. The key advantages of SEG lie in its flexibility and the theoretical foundation, allowing us to significantly enhance sample quality without side effects by adjusting the standard deviation of the Gaussian filter. We hope our method inspires further research on improving generative models, and extending the approach beyond image generation, for example, to video or natural language processing.\nLimitations and societal impacts The paper proposes guidance to enhance quality outcomes. Consequently, the attainable quality of our approach is contingent upon the baseline model employed. Furthermore, the application of SEG to temporal attention mechanisms in video or multi-view diffusion models is not addressed, remaining a promising avenue for future research. It is important to note that the improvements achieved through this method may potentially lead to unintended negative societal consequences by inadvertently amplifying existing stereotypes or harmful biases."}, {"title": "A Full proofs", "content": ""}, {"title": "A.1 Proof of Lemma 3.1", "content": "Let $a_{(i,j)}$ denote the original attention weights and $\\tilde{a}_{(i,j)}$ denote the blurred attention weights, as in the main paper. Assume that the original attention weights are properly padded to maintain consistent statistics. Then, the following shows that the mean of the blurred attention weights remains the same.\n$\\mathbb{E}_{i,j}[\\tilde{a}_{(i,j)}] = \\frac{1}{HW}\\sum_{i=1}^{HW}\\sum_{j=1}^{HW}\\tilde{a}_{(i,j)} = \\frac{1}{HW}\\sum_{i=1}^{HW}\\sum_{j=1}^{HW}\\sum_{m=-k}^{k}\\sum_{n=-k}^{k} G(m,n) \\cdot a_{(i+m.j+n)}$\n$= \\frac{1}{HW}\\sum_{m=-k}^{k}\\sum_{n=-k}^{k} G(m, n) \\cdot \\sum_{i=1}^{HW}\\sum_{j=1}^{HW} a_{(i+m,j+n)}$\n$= \\sum_{m=-k}^{k}\\sum_{n=-k}^{k} G(m, n) \\cdot \\frac{1}{HW} \\sum_{i=1}^{HW}\\sum_{j=1}^{HW} a_{(i+m,j+n)} = \\sum_{m=-k}^{k}\\sum_{n=-k}^{k} G(m, n) \\cdot \\mathbb{E}_{i,j} [a_{(i,j)}] = \\mathbb{E}_{i,j}[a_{(i,j)}]\\cdot \\sum_{m=-k}^{k}\\sum_{n=-k}^{k} G(m, n) = \\mathbb{E}_{i,j}[a_{(i,j)}]$\nIn addition, the variance of the blurred attention weights is smaller than or equal to the variance of the original attention weights.\n$Var_{i,j}[\\tilde{a}_{(i,j)}] = \\frac{1}{HW}\\sum_{i=1}^{HW}\\sum_{j=1}^{HW} ((\\tilde{a}_{(i,j)} - \\mathbb{E}_{i,j} [\\tilde{a}_{(i,j)}])^2$\n$= \\frac{1}{HW}\\sum_{i=1}^{HW}\\sum_{j=1}^{HW} (\\sum_{m=-k}^{k}\\sum_{n=-k}^{k} G(m,n) \\cdot a_{(i+m,j+n)} - \\mathbb{E}_{i,j} [a_{(i,j)}])^2$\n$= \\sum_{m=-k}^{k}\\sum_{n=-k}^{k}\\sum_{r=-k}^{k}\\sum_{s=-k}^{k} G(m, n) \\cdot G(r, s) \\cdot Cov[a_{(i+m,j+n)}, a_{(i+r,j+s)}]$\nUsing the Cauchy-Schwarz inequality and the normalization property of the 2D Gaussian filter, we can show that the variance monotonically decreases when we apply Gaussian blur.\n$Var_{i,j}[\\tilde{a}_{(i,j)}] \\leq \\sum_{m=-k}^{k}\\sum_{n=-k}^{k}\\sum_{r=-k}^{k}\\sum_{s=-k}^{k} G(m, n) \\cdot G(r, s) \\cdot \\sqrt{Var[a_{(i+m,j+n)}]} \\cdot \\sqrt{Var[a_{(i+r,j+s)}]}$\n$=(\\sum_{m=-k}^{k}\\sum_{n=-k}^{k} G(m, n) \\cdot \\sqrt{Var[a_{(i+m,j+n)}]})^2$\n$\\leq (\\sum_{m=-k}^{k}\\sum_{n=-k}^{k} G(m,n)) (\\sum_{m=-k}^{k}\\sum_{n=-k}^{k} G(m,n) \\cdot Var[a_{(i+m.j+n)}])$\n$= \\sum_{m=-k}^{k}\\sum_{n=-k}^{k} G(m, n) \\cdot Var[a_{(i+m,j+n)}]$\n$= Var_{i,j} [a_{(i,j)}]$"}, {"title": "A.2 Proof of Lemma 3.2", "content": "Applying the second-order Taylor series approximation of $e^x$ to our function f around the mean $\\mu$, we get:\n$\\sum_{i=1}^{HW}\\sum_{j=1}^{HW}e^{a_{(i,j)}} \\approx \\sum_{i=1}^{HW}\\sum_{j=1}^{HW}(e^\\mu + e^\\mu (a_{(i,j)} - \\mu) + \\frac{1}{2}e^\\mu (a_{(i,j)} - \\mu)^2)$\n$=HW \\cdot e^\\mu + \\frac{1}{2}e^\\mu \\sum_{i=1}^{HW}\\sum_{j=1}^{HW} (a_{(i,j)} - \\mu)^2$"}, {"title": "A.3 Proof of Theorem 3.1", "content": "Let a = ($a_1$,...,$a_n$) denote the attention values before the softmax operation, and let $\\tilde{a}$ = ($\\tilde{a}_1$,..., $\\tilde{a}_n$) denote the attention values after applying the 2D Gaussian blur. Let H denote the Hessian of the original energy, i.e., the derivative of the negative softmax, and H denote the Hessian of the underlying energy associated with the blurred weights.\nThe elements in the i-th row and j-th column of the Hessian matrices are given by:\n$h_{ij} = (\\xi(a)_i - \\delta_{ij})\\xi(a)_j,$\n$\\tilde{h}_{ij} = (\\xi(\\tilde{a})_i - \\delta_{ij})\\xi(\\tilde{a})_jb_{ij},$\nrespectively, where $b_{ij}$ are the elements of the Toeplitz matrix corresponding to the Gaussian blur kernel, and $\\delta_{ij}$ denotes the Kronecker delta.\nAssuming $\\xi(\\tilde{a})_i\\xi(\\tilde{a})_j \\approx 0$ and $\\xi(a)_i\\xi(a)_j \\approx 0$ for all i and j, which is a reasonable assumption when the number of token is large, the non-diagonal elements of the Hessians approximate to 0 and the diagonal elements dominate. Therefore, the determinants of the Hessian matrices are approximated as the product of the dominant terms:\n$| det(H)| \\approx \\prod_{i=1}^{n} \\xi(a)_i, | det(\\tilde{H})| \\approx \\prod_{i=1}^{n} \\xi(\\tilde{a})_ib_{ii}$"}, {"title": "B Dual definition", "content": "As we previously stated in Section 2.2, we have the dual definition regarding (5), where we use swapped indexing. Importantly, the swapped indices can be interpreted as altering the definition of attention weights to $A := KQ^T$.\nA similar conclusion can be drawn as in the main paper, except that query blurring becomes key blurring with this definition. To see this, Eq. 7 changes slightly with this definition, using the symmetry of the Toeplitz matrix B:\n$G * (KQ^T) = B(KQ^T)$\n$= ((KQ^T)^TBT)^T$\n$= (QKTBT)^T$\n$= (Q(BK)^T)^T$\n$= (Q(G* K)^T)^T$\n$= (G * K)QT,$\nwhere * denotes the 2D convolution operation. Empirically, this altered definition does not introduce a significant difference in the overall image quality, as shown in Fig. 11."}, {"title": "C Additional qualitative results", "content": "In this section, we present further qualitative results to demonstrate the effectiveness and versatility of our Smoothed Energy Guidance (SEG) method across various generation tasks and in comparison with other approaches.\nComparison with previous methods Figs. 7 and 8 provide a qualitative comparison of SEG against vanilla SDXL [35], Self-Attention Guidance (SAG) [17], and Perturbed Attention Guidance (PAG) [1]. These comparisons highlight the superior performance of SEG in terms of image quality, coherence, and adherence to the given prompts. SEG consistently produces sharper details, more realistic textures, and better overall composition compared to the other methods.\nConditional generation with ControlNet Figs. 9 and 10 showcase the application of SEG in conjunction with ControlNet [51] for conditional image generation. These results illustrate how SEG can enhance the quality and coherence of generated images while maintaining fidelity to the provided control signals. The images demonstrate improved detail, texture, and overall visual appeal compared to standard ControlNet outputs without prompts."}]}