{"title": "Premier d\u00e9cryptage du r\u00e8glement europ\u00e9en sur l'intelligence artificielle (AI Act) : Vers un standard mondial de l'IA de confiance ?", "authors": ["Marion Ho-Dac"], "abstract": "R\u00e9sum\u00e9 : Le r\u00e8glement sur l'intelligence artificielle (AI Act) est entr\u00e9 en vigueur le 1er ao\u00fbt 2024 dans l'Union europ\u00e9enne. Il s'agit d'un texte-cl\u00e9 tant pour les citoyens plac\u00e9s au c\u0153ur des technologies d'IA que pour l'industrie active dans le march\u00e9 int\u00e9rieur. L'AI Act impose une mise en conformit\u00e9 progressive pour les organisations \u2013 priv\u00e9es comme publiques \u2014, intervenant dans la chaine de valeur mondiale des syst\u00e8mes et mod\u00e8les d'IA mis sur le march\u00e9 et utilis\u00e9s dans l'Union. Alors que le texte est in\u00e9dit \u00e0 l'\u00e9chelle internationale de par son emprise r\u00e8glementaire horizontale et contraignante, sa force d'attraction mondiale au soutien de l'IA de confiance est l'un de ces enjeux majeurs.", "sections": [{"title": "I) Le champ d'application de l'AI Act", "content": "L'AI Act est dot\u00e9 d'un vaste champ d'application. D'une part, il retient une d\u00e9finition souple des syst\u00e8mes d'IA inspir\u00e9e de celle \u00e9labor\u00e9e dans l'enceinte internationale de l'OCDE\u00b9\u00b2. Il s'agit de tout \u00ab syst\u00e8me automatis\u00e9 [...] con\u00e7u pour fonctionner \u00e0 diff\u00e9rents niveaux d'autonomie et [pouvant] faire preuve d'une capacit\u00e9 d'adaptation apr\u00e8s son d\u00e9ploiement, et qui, pour des objectifs explicites ou implicites, d\u00e9duit, \u00e0 partir des entr\u00e9es qu'il re\u00e7oit, la mani\u00e8re de g\u00e9n\u00e9rer des sorties telles que des pr\u00e9dictions, du contenu, des recommandations ou des d\u00e9cisions qui peuvent influencer les environnements physiques ou virtuels \u00bb\u00b9\u00b3. D'autre part, il affirme sa dimension horizontale au sein du march\u00e9 europ\u00e9en des produits, associ\u00e9e au principe de lex specialia du fait de la particularit\u00e9 de son objet \u2013 les technologies avanc\u00e9es d'IA \u2013\u00b9\u2074. Al'examen cependant, quelques nuances s'imposent. Tant la taxonomie des syst\u00e8mes et mod\u00e8les d'IA \u00e9labor\u00e9e par l'AI Act (A) que le march\u00e9 qu'il entend couvrir (B) connaissent des limitations et des exceptions qui att\u00e9nuent la port\u00e9e englobante, \u00e0 vocation mondiale, du texte."}, {"title": "A) La taxonomie des syst\u00e8mes et mod\u00e8les d'IA", "content": "La taxonomie des syst\u00e8mes d'IA \u00e9labor\u00e9e par l'AI Act est complexe dans sa d\u00e9limitation fine\u00b9\u2075. A c\u00f4t\u00e9 des pratiques interdites car pr\u00e9sentant des risques inacceptables (1) et des syst\u00e8mes d'IA \u00e0 haut risque (2), une cat\u00e9gorie ad hoc pour les mod\u00e8les d'IA \u00e0 usage g\u00e9n\u00e9ral (ci-apr\u00e8s << mod\u00e8les d'IAUG \u00bb) (3) a \u00e9t\u00e9 ins\u00e9r\u00e9e en fin de n\u00e9gociations, sous la pression de la diffusion fulgurante de l'IA g\u00e9n\u00e9rative aupr\u00e8s du grand public. Il n'existe en revanche aucune trace lisible d'une cat\u00e9gorie de syst\u00e8mes d'IA \u00e0 risque mod\u00e9r\u00e9 qui figure g\u00e9n\u00e9ralement dans la pyramide des risques associ\u00e9e \u00e0 l'AI Act\u00b9\u2076."}, {"title": "1) Les pratiques d'IA interdites", "content": "L'article 5, \u00a71 de l'AI Act pr\u00e9voit une liste de huit cas d'usage donnant lieu \u00e0 une interdiction de plein droit, \u00e0 l'instar des syst\u00e8mes d'IA capables de sonder les \u00e9motions ou d'influencer le consentement humain, et des pratiques de scoring social, de pr\u00e9diction en mati\u00e8re d'infraction p\u00e9nale et de biom\u00e9trie. Ces interdictions sont fond\u00e9es sur la contrari\u00e9t\u00e9 de ces pratiques aux valeurs de l'Union \u00e0 commencer par le respect de la dignit\u00e9 humaine et de la libert\u00e9\u00b9\u2077. L'Union donne ainsi \u00e0 voir au reste du monde sa vision politique de la vie en soci\u00e9t\u00e9. Cependant, cette d\u00e9monstration \u00ab quasi-constitutionnelle \u00bb est mise \u00e0 mal. Ces interdictions sont toutes, et parfois tr\u00e8s largement, conditionn\u00e9es et souvent amput\u00e9es par des exceptions. Elles ne sont donc pas ais\u00e9ment pr\u00e9visibles alors m\u00eame que leur qualification est laiss\u00e9e \u00e0 l'appr\u00e9ciation des fournisseurs. Ainsi, par exemple, les \u00c9tats membres ont r\u00e9ussi \u00e0 maintenir une forte exception en mati\u00e8re r\u00e9pressive (\u00ab law enforcement \u00bb) afin de permettre l'utilisation de syst\u00e8mes biom\u00e9triques qui peuvent pourtant porter gravement atteinte \u00e0 l'int\u00e9grit\u00e9 humaine dans nombre de situations \u00b9\u2078."}, {"title": "2) Les syst\u00e8mes d'IA \u00e0 haut risque", "content": "L'article 6 de l'AI Act distingue deux cat\u00e9gories de syst\u00e8mes d'IA \u00e0 haut risque entendus limitativement comme ceux \u00ab [...] qui ont une incidence pr\u00e9judiciable substantielle sur la sant\u00e9, la s\u00e9curit\u00e9 et les droits fondamentaux des citoyens dans l'Union \u00bb\u00b9\u2079. La premi\u00e8re d\u00e9coule de l'article 6, \u00a71, lu en combinaison avec l'annexe I qui pr\u00e9voit une double liste (A et B) de l\u00e9gislations d'harmonisation de l'Union, la liste A \u00e9tant directement issue du NLF. Pour \u00eatre qualifi\u00e9 de syst\u00e8me \u00e0 haut risque, il faut que le produit ou le composant de s\u00e9curit\u00e9 d'un produit int\u00e9grant l'IA soit r\u00e9gi par l'une des l\u00e9gislations d'harmonisation de cette annexe I et soit soumis, selon cette l\u00e9gislation, \u00e0 un \u00ab module \u00bb de conformit\u00e9 exigeant l'\u00e9valuation par un tiers, c'est-\u00e0-dire par un organisme d'\u00e9valuation de conformit\u00e9.\nLa seconde cat\u00e9gorie de syst\u00e8me \u00e0 haut risque prend appui sur l'article 6, \u00a72 de l'AI Act, lu en combinaison avec l'annexe III qui pr\u00e9voit une liste de huit domaines, avec 25 cas d'usage pr\u00e9sentant des niveaux de granularit\u00e9 plus ou moins avanc\u00e9s, en mati\u00e8re de biom\u00e9trie, d'infrastructures critiques, de justice r\u00e9pressive, d'\u00e9ducation et d'emploi, de services essentiels, de migration et d'administration de la justice\u00b2\u2070. La cat\u00e9gorie est complexe car elle embrasse une grande diversit\u00e9 d'usage de l'IA, ayant chacun leur sp\u00e9cificit\u00e9, parfois en prolongement des pratiques interdites (reconnaissance des \u00e9motions ou biom\u00e9trie en particulier) et appelant donc \u00e0 une articulation avec celles-ci\u00b2\u00b9.\nDans le m\u00eame temps, l'article 6, \u00a73 de l'AI Act pr\u00e9voit une certaine flexibilit\u00e9 en faveur des fournisseurs quant \u00e0 la qualification de syst\u00e8me d'IA \u00e0 haut risque. Il introduit une sorte de r\u00e8gle de minimis permettant au fournisseur d'exclure un syst\u00e8me donn\u00e9 de la cat\u00e9gorie \u00ab haut risque \u00bb si ledit syst\u00e8me ne pr\u00e9sente pas de risque significatif. Il s'agit certes d'all\u00e9ger la charge r\u00e8glementaire des fournisseurs ; pour autant, fallait-il leur laisser une telle latitude ?"}, {"title": "3) Les mod\u00e8les d'IAUG", "content": "En tant que \u00ab nouveaux venus \u00bb dans le r\u00e8glement, les mod\u00e8les d'IAUG constituent une cat\u00e9gorie ad hoc soumise \u00e0 un r\u00e9gime propre, renforc\u00e9 en cas de \u00ab risques syst\u00e9miques \u00bb associ\u00e9s aux mod\u00e8les les plus puissants\u00b2\u00b2. L'AI Act opte pour une d\u00e9finition fonctionnelle de ces mod\u00e8les, \u00e0 l'aune de \u00ab [leur] g\u00e9n\u00e9ralit\u00e9 et [de leur] capacit\u00e9 [\u00e0] ex\u00e9cuter de mani\u00e8re comp\u00e9tente un large \u00e9ventail de t\u00e2ches distinctes \u00bb\u00b2\u00b3. Ils sont g\u00e9n\u00e9ralement commercialis\u00e9s au moyen de biblioth\u00e8ques, d'interfaces de programmation d'applications (API) ou de t\u00e9l\u00e9chargements ; ils sont modifiables et ont vocation \u00e0 \u00eatre int\u00e9gr\u00e9s dans un syst\u00e8me d'IA\u00b2\u2074. Ce sont les grands mod\u00e8les d'IA g\u00e9n\u00e9rative venus d'outre-Atlantique \u2013 \u00e0 l'instar de \u00ab GPT-3 \u00bb puis << -4 \u00bb de l'entreprise OpenAI, int\u00e9gr\u00e9 par le c\u00e9l\u00e8bre agent conversationnel Chat-GPT \u2013 qui constituent l'arri\u00e8re-fond embl\u00e9matique de cette cat\u00e9gorie. Ces mod\u00e8les peuvent pr\u00e9senter des risques syst\u00e9miques, c'est-\u00e0-dire susceptibles d'avoir une incidence significative et \u00e0 grande \u00e9chelle dans l'Union, \u00ab sur la soci\u00e9t\u00e9 dans son ensemble \u00bb, au-del\u00e0 d'une atteinte aux seuls droits individuels\u00b2\u2075.\nLe crit\u00e8re-cl\u00e9 de qualification d'un mod\u00e8le d'IAUG pr\u00e9sentant des risques syst\u00e9miques est celui de ses \u00ab capacit\u00e9s d'impact \u00e9lev\u00e9es \u00bb\u00b2\u2076. Ce crit\u00e8re, de nature technique, s'analyse \u00e0 partir d'\u00e9l\u00e9ments m\u00e9thodologiques et de r\u00e9f\u00e9rence list\u00e9s \u00e0 l'annexe XIII de l'AI Act ; il est pr\u00e9sum\u00e9 r\u00e9alis\u00e9 lorsque le volume de calcul utilis\u00e9 pour l'apprentissage du mod\u00e8le d\u00e9passe un certain"}, {"title": "B) Le march\u00e9 des syst\u00e8mes et mod\u00e8les d'I\u0391", "content": "La d\u00e9limitation mat\u00e9rielle (1) et spatiale (2) du march\u00e9 que l'AI Act entend r\u00e9guler est r\u00e9v\u00e9latrice de la port\u00e9e mondiale que l'Union ambitionne pour ce texte. Cela ressort distinctement des volets r\u00e8glementaires de conformit\u00e9 et de public enforcement du r\u00e8glement, \u00e0 l'exclusion de tout sch\u00e9ma transnational de private enforcement confi\u00e9 \u00e0 d'autres instruments l\u00e9gislatifs \u00b3\u2070."}, {"title": "1) Les contours mat\u00e9riels de l'AI Act", "content": "Tout d'abord, l'AI Act se compose de trois grands corpus normatifs\u00b3\u00b9. Le premier regroupe des \u00ab r\u00e8gles harmonis\u00e9es concernant la mise sur le march\u00e9, la mise en service et l'utilisation de syst\u00e8mes d'IA dans l'Union \u00bb\u00b3\u00b2 et inclut, \u00e0 un niveau de granularit\u00e9 sup\u00e9rieur, des dispositions interdisant certaines pratiques d'IA ainsi que des exigences sp\u00e9cifiques pour les syst\u00e8mes \u00e0 haut risque et les mod\u00e8les d'IA. Le second corpus est constitu\u00e9 d'un sch\u00e9ma assez dense de public enforcement comprenant, d'une part, les r\u00e8gles de surveillance de march\u00e9 propres au march\u00e9 europ\u00e9en des produits, renforc\u00e9es, d'autre part, par un cadre de gouvernance << f\u00e9d\u00e9rale \u00bb inspir\u00e9 d'autres instruments r\u00e8glementaires du march\u00e9 unique num\u00e9rique. Le troisi\u00e8me et dernier corpus pr\u00e9voit des mesures en faveur de l'innovation, prenant notamment la forme de bacs \u00e0 sable r\u00e8glementaires\u00b3\u00b3 et d'un accompagnement/all\u00e8gement r\u00e8glementaire pour les PME et les start-ups\u00b3\u2074.\nEnsuite, plusieurs exclusions mat\u00e9rielles sont pr\u00e9vues par le texte. Il en va ainsi, premi\u00e8rement, des syst\u00e8mes d'IA \u00e0 haut risque qui s'inscrivent dans les huit l\u00e9gislations d'harmonisation de l'annexe I, section B\u00b3\u2075. L'AI Act se limite \u00e0 amender ces textes sectoriels, afin qu'ils pr\u00e9voient la prise en compte des exigences essentielles de l'IA de confiance\u00b3\u2076, lorsque les produits concern\u00e9s int\u00e9greront un syst\u00e8me d\u2019IA \u00e0 haut risque, le plus souvent en tant que composant de s\u00e9curit\u00e9. Deuxi\u00e8mement, l'AI Act s'est clairement align\u00e9 sur la position d\u00e9fendue par le Conseil"}, {"title": "2) Les fronti\u00e8res spatiales de l'AI Act", "content": "Dans la droite ligne des textes NLF qui appr\u00e9hendent largement la cha\u00eene d'approvisionnement transnationale des produits mis sur le march\u00e9 europ\u00e9en, sous l'angle tant de la responsabilit\u00e9 des acteurs que de la surveillance de march\u00e9\u2074\u00b9, l'AI Act a une port\u00e9e extra-europ\u00e9enne assum\u00e9e. Les op\u00e9rateurs technologiques les plus puissants sont originaires d'\u00c9tats tiers \u00e0 l'Union. Aussi, l'AI Act se doit d'assurer un level playing field au sein de l'industrie de l'IA et de prot\u00e9ger les droits et libert\u00e9s des citoyens de l'Union. Partant, le r\u00e8glement s'applique, d'une part, aux fournisseurs et d\u00e9ployeurs \u00e9tablis ou situ\u00e9s dans l'Union et, d'autre part, aux fournisseurs \u00e9tablis ou situ\u00e9s hors de l'Union, lorsqu'ils mettent sur le march\u00e9 europ\u00e9en, y compris \u00e0 titre gratuit\u2074\u00b2, un syst\u00e8me d'IA ou un mod\u00e8le d'IAUG couvert par l'AI Act\u2074\u00b3. Les fournisseurs extra-europ\u00e9ens ont, par ailleurs, l'obligation de nommer un mandataire install\u00e9 dans l'Union\u2074\u2074.\nDe mani\u00e8re plus originale, l'AI Act pr\u00e9voit \u00e9galement que lorsque tant le fournisseur que le d\u00e9ployeur sont \u00e9tablis ou situ\u00e9s dans un pays tiers, mais que \u00ab les sorties produites par le syst\u00e8me d'IA sont utilis\u00e9es dans l'Union \u00bb, le cadre r\u00e8glementaire est applicable\u2074\u2075. Sont vis\u00e9s ici les syst\u00e8mes d\u2019IA de nature num\u00e9rique d\u00e9velopp\u00e9s et d\u00e9ploy\u00e9s hors de l'Union, notamment dans un sch\u00e9ma de sous-traitance organis\u00e9 par un op\u00e9rateur europ\u00e9en aupr\u00e8s d'un op\u00e9rateur"}, {"title": "II) Les r\u00e9gimes de conformit\u00e9 des syst\u00e8mes et mod\u00e8les d'IA", "content": "Le r\u00e9gime de conformit\u00e9 des syst\u00e8mes d'IA \u00e0 haut risque s'inscrit dans le sillage de la s\u00e9curit\u00e9 des produits (A). Par contraste, les autres syst\u00e8mes de la taxonomie, y compris les mod\u00e8les d'IAUG (B) ont des r\u00e9gimes tr\u00e8s parcellaires\u2074\u2077, cr\u00e9ant un sentiment de hiatus r\u00e8glementaire."}, {"title": "A) Le r\u00e9gime de conformit\u00e9 des syst\u00e8mes d'IA \u00e0 haut risque", "content": "La conformit\u00e9 des syst\u00e8mes d'IA \u00e0 haut risque prend appui sur le concept NLF d'exigences essentielles qui sont codifi\u00e9es dans la section 2 du chapitre III. Elles constituent le c\u0153ur du r\u00e8glement et certainement sa partie la plus connue. Elles sont tr\u00e8s largement inspir\u00e9es des caract\u00e9ristiques de l'IA de confiance d\u00e9gag\u00e9es, au titre de l'\u00e9thique de l'IA par le High Level Expert Group on Al\u2074\u2078, aux fins d'\u00eatre transcrites ici en droit contraignant. Il s'agit principalement des exigences de gouvernance des donn\u00e9es, de tra\u00e7abilit\u00e9, de transparence, de contr\u00f4le humain et des caract\u00e9ristiques techniques d'exactitude, de robustesse et de cybers\u00e9curit\u00e9\u2074\u2079. Elles sont compl\u00e9t\u00e9es par la dimension r\u00e8glementaire de la conformit\u00e9 ex ante assur\u00e9e par la mise en place, par le fournisseur, d'un syst\u00e8me de gestion des risques\u2075\u2070, d'une documentation technique\u2075\u00b9 et d'un syst\u00e8me de gestion de la qualit\u00e9\u2075\u00b2, en vue de l'\u00e9valuation de conformit\u00e9 et du marquage CE.\nL'ensemble de ces exigences essentielles a vocation \u00e0 \u00eatre traduit dans des normes techniques sous le format europ\u00e9en des \u00ab normes harmonis\u00e9es \u00bb\u2075\u00b3. Une question d\u00e9licate se pose quant aux int\u00e9r\u00eats publics que ces futures normes ont vocation \u00e0 assurer. De mani\u00e8re originale l'AI Act vise de mani\u00e8re r\u00e9currente, notamment en mati\u00e8re de gestion des risques, la protection des"}, {"title": "2) Les obligations des op\u00e9rateurs", "content": "L'AI Act fixe des obligations pour l'ensemble des op\u00e9rateurs dans la cha\u00eene de valeur d'un syst\u00e8me d'IA \u00e0 haut risque\u2075\u2079. Sont ainsi pr\u00e9vues, \u00e0 c\u00f4t\u00e9 des obligations du fournisseur et du d\u00e9ployeur, des obligations pour les mandataires des fournisseurs\u2076\u2070, pour les importateurs\u2076\u00b9 et pour les distributeurs\u2076\u00b2. L'\u00e9clatement transnational des op\u00e9rateurs intervenant dans le d\u00e9veloppement et le d\u00e9ploiement d'un syst\u00e8me ne doit pas conduire \u00e0 une dilution des responsabilit\u00e9s et \u00e0 un affaiblissement subs\u00e9quent du cadre r\u00e8glementaire\u2076\u00b3.\nS'agissant du fournisseur qui d\u00e9veloppe et commercialise le syst\u00e8me, il est soumis \u00e0 diverses obligations (classiques, \u00e0 l'aune du NLF) visant \u00e0 assurer la mise en conformit\u00e9 du syst\u00e8me d'IA tout au long de son cycle de vie. La focale principale est celle de l'att\u00e9nuation des risques que le syst\u00e8me pourrait g\u00e9n\u00e9rer\u2076\u2074, compl\u00e9t\u00e9e par la n\u00e9cessit\u00e9 de coop\u00e9ration avec les autorit\u00e9s de surveillance \u2076\u2075. L'AI Act instaure, par ailleurs, une obligation d'enregistrement des syst\u00e8mes \u00e0 haut risque par les fournisseurs sur une future base de donn\u00e9es europ\u00e9enne\u201c. Cette obligation doit \u00eatre salu\u00e9e en ce qu'elle favorisera la transparence et l'on peut regretter les d\u00e9rogations importantes en mati\u00e8re s\u00e9curitaire\u2076\u2077. Enfin, l'AI Act pr\u00e9voit deux modules d'\u00e9valuation de conformit\u00e9 : soit l'\u00e9valuation de conformit\u00e9 fond\u00e9e sur le contr\u00f4le interne\u2076\u2078, soit une proc\u00e9dure fond\u00e9e sur la gestion de la qualit\u00e9\u2076\u2079. En pratique, il ouvre largement la voie au contr\u00f4le interne par les fournisseurs qui respecteront les normes harmonis\u00e9es. Il place donc une grande confiance tant dans les industriels de l'IA que dans la normalisation technique. L'intervention des organismes notifi\u00e9s aurait, tout au moins, pu \u00eatre impos\u00e9e pour les syst\u00e8mes d'IA \u00e0 haut risque de l'annexe III d\u00e9ploy\u00e9s \u00e0 grande \u00e9chelle\u2077\u2070. Une autre fragilit\u00e9 ressort des d\u00e9rogations admises \u00e0 la proc\u00e9dure d'\u00e9valuation de conformit\u00e9 notamment pour des motifs de \u00ab s\u00e9curit\u00e9 publique \u00bb, y compris en mati\u00e8re r\u00e9pressive\u2077\u00b9.\nQuant au d\u00e9ployeur, on rel\u00e8vera d'embl\u00e9e qu'il est un destinataire essentiel du cadre r\u00e8glementaire de l'AI Act, aux c\u00f4t\u00e9s du fournisseur ; toutes les entit\u00e9s priv\u00e9es comme publiques - qui recourent \u00e0 l'IA doivent en avoir bien conscience. Ainsi, les d\u00e9ployeurs sont associ\u00e9s \u00e0 la mise en \u0153uvre (et donc au respect) de plusieurs exigences essentielles qui fondent le cadre de confiance des syst\u00e8mes d'IA \u00e0 haut risque : en mati\u00e8re de contr\u00f4le humain\u2077\u00b2, de qualit\u00e9 des donn\u00e9es\u2077\u00b3 ou encore de tra\u00e7abilit\u00e9\u2077\u2074 et de transparence sous la forme d'un devoir d'information des personnes concern\u00e9es lorsque le d\u00e9ploiement du syst\u00e8me \u00e0 haut risque est utilis\u00e9 pour une (aide \u00e0 la) prise de d\u00e9cision\u2077\u2075 ou sur le lieu de travail\u2077\u2076. En creux, il s'agit de prot\u00e9ger les citoyens contre les risques de discrimination, d'atteintes \u00e0 l'autod\u00e9termination informationnelle ou \u00e0 la vie. Dans le m\u00eame esprit, certains d\u00e9ployeurs devront conduire une \u00e9tude d'impact sur les droits fondamentaux pour certains syst\u00e8mes d'IA\u2077\u2077. Il faut se f\u00e9liciter de cette disposition, ins\u00e9r\u00e9e sous la pression du Parlement europ\u00e9en, m\u00eame si son champ d'action personnel a \u00e9t\u00e9 restreint aux seules administrations publiques, \u00e0 l'exception de certains cas d'usage particuli\u00e8rement sensibles dans le domaine des services financiers. Ces m\u00eames d\u00e9ployeurs \u00ab personnes publiques \u00bb sont \u00e9galement astreints \u00e0 un obligation d'enregistrement en s\u00e9lectionnant, sur la base de donn\u00e9es europ\u00e9enne pr\u00e9cit\u00e9e, les syst\u00e8mes d'IA \u00e0 haut risque enregistr\u00e9s pr\u00e9alablement par le fournisseur \u2013 qu'ils vont utiliser\u2077\u2078. Enfin, les d\u00e9ployeurs ont un r\u00f4le important sur le terrain du public enforcement, puisqu'ils sont associ\u00e9s au monitoring de la s\u00e9curit\u00e9 des syst\u00e8mes qu'ils d\u00e9ploient, en dialogue avec les fournisseurs et les autorit\u00e9s de surveillance\u2077\u2079. Le d\u00e9ployeur est, en outre, responsable de la bonne ex\u00e9cution du droit \u00e0 l'explication dont les utilisateurs finaux sont titulaires, \u00e0 certaines conditions plut\u00f4t resserr\u00e9es, en pr\u00e9sence d'une d\u00e9cision prise par ce dernier sur la base d'un syst\u00e8me \u00e0 haut risque\u2078\u2070."}, {"title": "B) Le r\u00e9gime de conformit\u00e9 des mod\u00e8les d'IAUG", "content": "Les mod\u00e8les d'IAUG font l'objet, en cas de mise sur le march\u00e9, d'un r\u00e9gime de conformit\u00e9 \u00e0 plusieurs niveaux selon, d'une part, qu'ils sont ou non diffus\u00e9s sous licence libre et, d'autre part, qu'ils pr\u00e9sentent ou non des risques syst\u00e9miques. Quel que soit son niveau, ce r\u00e9gime vient en principe s'ajouter au r\u00e9gime de conformit\u00e9 applicable au syst\u00e8me d'IA auquel le mod\u00e8le est int\u00e9gr\u00e9, que le fournisseur de ce syst\u00e8me et de ce mod\u00e8le soit, ou non, le m\u00eame op\u00e9rateur\u2078\u00b9; l'enjeu de ce cumul r\u00e8glementaire est central au stade de la mise sur le march\u00e9 d'un syst\u00e8me d'IA \u00e0 haut risque \u2013 qu'il soit ou non \u00e0 usage g\u00e9n\u00e9ral \u2013 ayant int\u00e9gr\u00e9 un tel mod\u00e8le, afin d'assurer la protection des droits des citoyens et de la soci\u00e9t\u00e9. A ce titre et aux fins d'assurer l'effectivit\u00e9 extra-europ\u00e9enne de cette protection, les fournisseurs non europ\u00e9ens de mod\u00e8les d'IAUG doivent, eux aussi, d\u00e9signer un mandataire \u00e9tabli dans l'Union\u2078\u00b2.\nS'agissant du premier niveau de conformit\u00e9 qui vise tous les mod\u00e8les d'IAUG, sauf ceux sous licence libre qui en sont exempt\u00e9s \u2078\u00b3, il prend la forme d'un r\u00e9gime de transparence principalement fond\u00e9 sur l'\u00e9laboration d'une documentation technique, \u00e0 destination tant des autorit\u00e9s de r\u00e9gulation en l'occurrence le \u00ab Bureau de l'\u0399\u0391 \u00bb que des fournisseurs de syst\u00e8mes d'IA qui envisagent d'int\u00e9grer un tel mod\u00e8le. L'annexe XI de l'AI Act fournit un canevas pour r\u00e9aliser la documentation technique du mod\u00e8le et l'annexe XII d\u00e9roule le contenu minimum de l'obligation d'information d\u00fb aux fournisseurs de syst\u00e8mes d'IA. Ces obligations devraient \u00eatre op\u00e9rationnalis\u00e9es, dans leur dimension technique, par de futures normes harmonis\u00e9es \u2078\u2074, compl\u00e9t\u00e9es par des actes d\u00e9l\u00e9gu\u00e9s de la Commission\u2078\u2075. Les fournisseurs de mod\u00e8les d'IAUG doivent \u00e9galement informer le public \u00ab du contenu utilis\u00e9 pour entra\u00eener le mod\u00e8le \u00bb sur la base d'un formulaire-type que le Bureau de l'IA devra \u00e9laborer. Enfin, ils sont invit\u00e9s \u00e0 mettre en place une politique de conformit\u00e9 \u00e0 l'aune des exigences europ\u00e9ennes du droit d'auteur.\nQuant au second niveau de conformit\u00e9, il vise les fournisseurs de mod\u00e8les d'IAUG pr\u00e9sentant un risque syst\u00e9mique. Ils ont une obligation de notification de leur mod\u00e8le aupr\u00e8s de la Commission europ\u00e9enne qui devra assurer la publication d'une liste de ces mod\u00e8les, dans le respect du secret des affaires\u2078\u2076. Ils doivent, en outre, mettre en place des politiques de gestion des risques, en \u00e9cho \u00e0 l'exigence de l'article 9 en mati\u00e8re de syst\u00e8mes \u00e0 haut risque. Il s'agit d'\u00e9valuer les mod\u00e8les suivant une m\u00e9thodologie d'\u00e9tude d'impact permettant d'identifier les"}, {"title": "III) La gouvernance multi-niveaux des syst\u00e8mes d'IA", "content": "Le cadre de public enforcement de l'AI Act est holistique. Le texte prend appui sur le sch\u00e9ma de surveillance du march\u00e9 au sens du r\u00e8glement (UE) 2019/1020 qui s'applique \u00ab dans son int\u00e9gralit\u00e9 \u00bb\u2078\u2078 mais va au-del\u00e0 en \u00e9tablissant une gouvernance multi-niveaux. Cela est justifi\u00e9 par la volont\u00e9 \u00abde renforcer les capacit\u00e9s au niveau de l'Union et d'int\u00e9grer les parties prenantes dans le domaine de l'IA \u00bb\u2078\u2079. Il y a ainsi une volont\u00e9 centralisatrice \u00e0 l'\u00e9chelle f\u00e9d\u00e9rale europ\u00e9enne, dans la lign\u00e9e d'autres grands textes et domaines strat\u00e9giques du march\u00e9 int\u00e9rieur. En appui de ce niveau d'ex\u00e9cution europ\u00e9en (B), le niveau national demeure central (A)."}, {"title": "A) La gouvernance nationale d\u00e9centralis\u00e9e fond\u00e9e sur la surveillance de march\u00e9", "content": "Pour ce qui, d'abord, de la dimension institutionnelle de la surveillance de march\u00e9, l'AI Act laisse aux \u00c9tats membres une marge de man\u0153uvre dans la d\u00e9signation des autorit\u00e9s nationales comp\u00e9tentes. Chaque \u00c9tat doit se doter, \u00ab au moins \u00bb, d'une autorit\u00e9 notifiante et d'une autorit\u00e9 de surveillance du march\u00e9, avec comme principes-cl\u00e9s d'exercice de leur comp\u00e9tence, l'ind\u00e9pendance et l'impartialit\u00e9\u2079\u2070. D'un c\u00f4t\u00e9, les autorit\u00e9s notifiantes ont pour mission d'\u00e9valuer, de d\u00e9signer, de notifier et de contr\u00f4ler les organismes en charge de l'\u00e9valuation de la conformit\u00e9 des syst\u00e8mes d'IA \u00e0 haut risque\u2079\u00b9. Ces organismes (pr\u00e9cit\u00e9s) sont au c\u0153ur du sch\u00e9ma de conformit\u00e9 ex ante des fournisseurs de syst\u00e8mes d'IA \u00e0 haut risque puisque ce sont eux qui doivent superviser le module de conformit\u00e9 fond\u00e9 sur l'\u00e9valuation du syst\u00e8me de gestion de la qualit\u00e9\u2079\u00b2. Leur r\u00e9gime est tr\u00e8s d\u00e9taill\u00e9 en vue de garantir leur haut niveau d'expertise et d'ind\u00e9pendance\u2079\u00b3. De l'autre c\u00f4t\u00e9, les autorit\u00e9s nationales de surveillance jouent le r\u00f4le de r\u00e9gulateur du march\u00e9 domestique au sein duquel les syst\u00e8mes d'IA sont mis \u00e0 disposition; cette mission pourra \u00eatre partag\u00e9e entre plusieurs entit\u00e9s nationales, selon les <<< besoins organisationnels \u00bb des \u00c9tats membres. Dans tous les cas, un \u00abpoint de contact unique \u00bb devra \u00eatre d\u00e9sign\u00e9, dans chaque \u00c9tat membre, afin de jouer le r\u00f4le d'interface avec le public et dans les relations avec l'Union et les autres \u00c9tats membres\u2079\u2074. En outre, l'AI Act impose (avec des d\u00e9rogations possibles), pour certains domaines \u00e0 haut risque, la d\u00e9signation d'autorit\u00e9s de contr\u00f4le pr\u00e9existantes ; c'est le cas, d'une part, dans le cadre des l\u00e9gislations"}, {"title": "B) Le cadre europ\u00e9en de gouvernance de l'IA", "content": "En surplomb de la surveillance nationale de march\u00e9, l'AI Act instaure une gouvernance europ\u00e9enne de l'IA compos\u00e9e de trois entit\u00e9s : une entit\u00e9 \u00ab verticale \u00bb, au sein de la Commission europ\u00e9enne et d\u00e9nomm\u00e9 \u00ab Bureau de l'IA \u00bb\u00b9\u2070\u2075; une entit\u00e9 \u00ab horizontale \u00bb sous le nom de \u00ab Comit\u00e9 europ\u00e9en de l'IA \u00bb\u00b9\u2070\u2076, compos\u00e9e des repr\u00e9sentants des r\u00e9gulateurs des \u00c9tats membres, du Bureau de l'IA (sans droit de vote) et de membres soit observateurs \u2013 \u00e0 l'instar du CEPD \u2013 soit invit\u00e9s ; et enfin, une entit\u00e9 \u00ab experte \u00bb compos\u00e9e d'un \u00ab Forum consultatif \u00bb\u00b9\u2070\u2077 r\u00e9unissant des repr\u00e9sentants des parties prenantes de l'\u00e9cosyst\u00e8me de l'IA en vue de conseiller le Comit\u00e9 europ\u00e9en de l'IA et la Commission, et d'un \u00ab Groupe scientifique \u00bb\u00b9\u2070\u2078 dont la mission est de soutenir la mise en \u0153uvre de l'AI Act, gr\u00e2ce \u00e0 des connaissances scientifiques de pointe, notamment en mati\u00e8re de mod\u00e8les d'IAUG.\nS'agissant du Bureau de l'IA, il est une \u00e9manation de la Commission avec une double fonction : d'une part, la surveillance des mod\u00e8les d'IA \u00e0 usage g\u00e9n\u00e9ral et, d'autre part, la gouvernance europ\u00e9enne de l'IA dans le contexte transnationale du march\u00e9 int\u00e9rieur de l'Union\u00b9\u2070\u2079. Sa fonction de superviseur des mod\u00e8les d'IA est largement calqu\u00e9e sur celle des autorit\u00e9s nationales de surveillance \u00e0 l'\u00e9gard des syst\u00e8mes d\u2019IA \u00e0 haut risque : adopter des mesures de contr\u00f4le et conduire des enqu\u00eates, donner suite aux alertes de risques syst\u00e9miques en conduisant une \u00e9valuation de conformit\u00e9 du mod\u00e8le, acc\u00e9der \u00e0 la documentation technique, solliciter des fournisseurs des mesures correctives notamment en cas de non-conformit\u00e9\u00b9\u00b9\u2070, mettre en place un syst\u00e8me de r\u00e9clamations pour les fournisseurs en aval\u00b9\u00b9\u00b9 et prononcer des sanctions sous forme d'amendes\u00b9\u00b9\u00b2. De mani\u00e8re plus sp\u00e9cifique, le Bureau de l'IA est en charge d'\u00e9tablir la m\u00e9thodologie de classification des mod\u00e8les d'IA \u00e0 usage g\u00e9n\u00e9ral \u00b9\u00b9\u00b3 et de l'\u00e9laboration des codes de bonne pratique qui doivent jouer comme base-relais de la mise en conformit\u00e9 dans l'attente des futures normes techniques en mati\u00e8re d'obligation de transparence des mod\u00e8les d'IA\u00b9\u00b9\u2074. Quant \u00e0 sa mission de gouvernance de haut niveau, elle est \u00e9clat\u00e9e \u00e0 travers diverses dispositions de l'AI Act. Elle consiste, d'une part, \u00e0 \u00e9laborer diff\u00e9rents documents de r\u00e9f\u00e9rence favorisant une mise en \u0153uvre harmonis\u00e9e et coh\u00e9rente du texte par les parties prenantes\u00b9\u00b9\u2075. D'autre part, le Bureau de l'IA se voit confier un r\u00f4le de coordinateur des diff\u00e9rents acteurs industriels comme institutionnels et de promotion de la coop\u00e9ration transfronti\u00e8re\u00b9\u00b9\u2076, y compris internationale. Ce dernier aspect est central dans le contexte d'institutionnalisation progressive d'une gouvernance mondiale de l'IA notamment dans sa"}]}