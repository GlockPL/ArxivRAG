{"title": "Separable Power of Classical and Quantum Learning Protocols Through the Lens of No-Free-Lunch Theorem", "authors": ["Xinbiao Wang", "Yuxuan Du", "Kecheng Liu", "Yong Luo", "Bo Du", "Dacheng Tao"], "abstract": "The No-Free-Lunch (NFL) theorem, which quantifies problem- and data-independent generalization errors regardless of the optimization process, provides a foundational framework for comprehending diverse learning protocols' potential. Despite its significance, the establishment of the NFL theorem for quantum machine learning models remains largely unexplored, thereby overlooking broader insights into the fundamental relationship between quantum and classical learning protocols. To address this gap, we categorize a diverse array of quantum learning algorithms into three learning protocols designed for learning quantum dynamics under a specified observable and establish their NFL theorem. The exploited protocols, namely Classical Learning Protocols (CLC-LPs), Restricted Quantum Learning Protocols (ReQu-LPs), and Quantum Learning Protocols (Qu-LPs), offer varying levels of access to quantum resources. Our derived NFL theorems demonstrate quadratic reductions in sample complexity across CLC-LPs, ReQu-LPs, and Qu-LPs, contingent upon the orthogonality of quantum states and the diagonality of observables. We attribute this performance discrepancy to the unique capacity of quantum-related learning protocols to indirectly utilize information concerning the global phases of non-orthogonal quantum states, a distinctive physical feature inherent in quantum mechanics. Our findings not only deepen our understanding of quantum learning protocols' capabilities but also provide practical insights for the development of advanced quantum learning algorithms.", "sections": [{"title": "I. Introduction", "content": "In the realm of artificial intelligence and machine learning, the utilization of vast datasets has become a cornerstone for advancing deep learning algorithms [1-5]. Recent breakthroughs in natural language processing and computer vision serve as compelling evidence of this trend [6-10]. Despite the numerous merits of large-volume data, the crucial determinant of deep learning success lies in the ability to effectively extract intricate patterns and knowledge from the information-rich landscapes of collected data [11-15]. To this end, various advanced learning strategies have been proposed to maximize information extraction. Concrete instances include contrastive learning for identifying the intrinsic invariance in image data [16-18], generative adversarial networks for extracting information by generating synthetic data samples that are remarkably similar to real data [19, 20], and transfer learning for recognizing patterns over different tasks [21-23]. However, deep learning models have encountered the issues of the scaling law [24-27], which indicates that the limited computational power of classical computers results in diminishing returns in performance improvement as the size of the training dataset grows. Therefore, alternative approaches that enable the efficient processing of large datasets and facilitate the development of advanced A\u0399 models are highly demanded.\nQuantum machine learning (QML), which utilizes quantum computers to construct learning models, is heralded as a potential game-changer for artificial intelligence [28-32]. A primary objective within QML is to effectively address problems that are intractable for classical algorithms, thereby delineating the boundaries between quantum and classical learning models in terms of learning performance. In this regard, the formulation of rigorous theoretical frameworks to deeply understand the capabilities of QML models is crucial for advancing this field. Existing literature has seen the emergence of sophisticated quantum learning algorithms with provable advantages for specific datasets and problems. For instance, quantum kernel methods have been shown to significantly lower the generalization error compared to their classical counterparts on synthetic datasets, as evidenced by studies of Ref. [33-35]. Furthermore, in the domain of quantum states learning, models exploiting quantum memory have demonstrated an exponential reduction in query complexity compared to that without employing quantum memory for learning some specific properties of unknown states [36, 37]. Despite the advancement, a broader question of a universal separation between classical and quantum learning approaches- -ones that do not rely on particular datasets or problems-remains less understood. To further unlock the potential of QML and harness its universal power, it is imperative to extend our exploration beyond narrowly defined scenarios and delve into the fundamental distinctions and capabilities that quantum learning algorithms offer over classical ones.\nA pivotal metric for assessing the universal capabilities of a model is through the lens of the No Free Lunch (NFL) theorem, which is a fundamental concept in artificial intelligence that characterizes the capabilities of learning models [38-40]. One interpretation of the theorem is that"}, {"title": "II. Preliminaries", "content": "In this section, we first review the essential foundations of quantum computing and variational quantum algorithms in Subsection II A and Subsection IIB, respectively. Subsequently, we introduce the related work of the NFL theorems in the context of QML and the established separation in classical and quantum learning protocols in Subsection II C. The frequently used notations and abbreviations throughout the whole manuscript are summarized in Table II."}, {"title": "A. Quantum computing", "content": "Quantum bit (qubit) and quantum states. A quantum bit or qubit is the basic unit of quantum information. Unlike a classical bit that can be in a state of 0 or 1, a qubit state refers to a two-dimensional vector defined as $|\\varphi\\rangle = a_0 |0\\rangle + a_1 |1\\rangle \\in \\mathbb{C}^2$ under Dirac notation, where $|0\\rangle = [1,0]$ and $|1\\rangle = [0,1]$ specify two unit bases, and the coefficients $a_0, a_1 \\in \\mathbb{C}$ satisfy $|a_0|^2 + |a_1|^2 = 1$. Similarly, an n-qubit state is denoted by $|\\psi\\rangle = \\sum_{i=1}^{2^n} a_i |e_i\\rangle \\in \\mathbb{C}^{2^n}$, where $|e_i\\rangle \\in \\mathbb{R}^{2^n}$ is the unit"}, {"title": "B. Variational quantum algorithms", "content": "Variational quantum algorithms (VQAs) [54] provide a general framework for implementing the task of unitary learning with various learning protocols. As shown in Fig. 2, a VQA can be divided into four elemental blocks: the preparation of the initial state $|\\psi\\rangle$, the implementation of a parameterized quantum circuit (PQC) $V(\\theta)$, the measurement $H$, and the construction of the cost function $\\mathcal{L}(\\theta)$.\nInitial state preparation. The input data in VQAs could be quantum states or classical vectors $x$. In the latter case, the classical data must first be embedded into quantum states to enable processing on quantum computers. Typical encoding manners include amplitude embedding and gate embedding. Amplitude embedding maps the $2^n$-dimension vector $x = (x_1,\\dots, x_{2^n})$ into the amplitude of an n-qubit quantum state $|x\\rangle = \\sum_i x_i|e_i\\rangle / ||X||_2$ with $|e_i\\rangle$ being the computational basis. For gate embedding, the entries of classical vectors are encoded into the n-qubit parameterized gates $W(x)$ acting on the basis state $|0\\rangle^n$, leading to the quantum state representation $|x\\rangle = W(x)|0\\rangle^n$. In the subsequent discussion, we refer to the input data as quantum states $|\\psi\\rangle$ assuming that all classical inputs have been encoded into quantum states.\nImplementations of PQCs. The PQCs $V(\\theta)$ consist of a sequence of parameterized gates with flexible structures, including hardware efficient ansatz, Hamiltonian variational ansatz, and tensor-network based ansatz [59-63]. The PQCs can be directly applied to the prepared initial state or integrated into the process of initial state preparation, aiming to obtain the feature state $|\\psi(\\theta)\\rangle$ which takes the form of $V(\\theta) |\\psi\\rangle$ for the former case and $\\prod_k V_k(\\theta) W_k(x) |0\\rangle^n$ for the latter case [64].\nCost function. The specific form of the cost function $\\mathcal{L}(\\cdot)$ varies with different learning tasks and learning algorithms. For example, in the classification task with training dataset $\\mathcal{D} = \\{|\\psi_j\\rangle, y_j\\}\\}_{j=1}^N$, the cost function refers to\n$\\mathcal{L}_\\mathcal{D}(\\theta) = \\frac{1}{N} \\sum_{j=1}^N |\\langle y_j | H | V(\\theta) |\\psi_j\\rangle \\langle \\psi_j | V^{\\dagger}(\\theta) | H | y_j\\rangle - y_j|^2$,\nwhere $y_j$ is the discrete label of $|\\psi_j\\rangle$ and $H$ refers to a predefined projective measurement.\nOptimization of VQAs. The optimization of VQA follows an iterative manner, where a classical optimizer utilizes the outputs from the quantum circuit to continuously update the trainable parameters $\\theta$ of the PQCs. This process aims to minimize the predefined objective function $\\mathcal{L}_\\mathcal{D}(\\theta)$ in Eqn. (2). At the t-th iteration, the updating rule is\n$\\theta^{(t+1)} = \\theta^{(t)} - \\eta \\nabla_{\\theta} \\mathcal{L}_\\mathcal{D} (\\theta^{(t)})$,\nwhere $\\eta$ is the learning rate. The updating continuously proceeds unless the loss $\\mathcal{L}_\\mathcal{D}$ is converged or the iteration"}, {"title": "C. Related work", "content": "In this subsection, we first review relevant literature pertaining to the NFL theorem in the context of quantum machine learning in Subsubsection IIC1. Subsequently, we discuss the differences in the achieved separation between classical and quantum learning protocols with that demonstrated in previous studies in Subsubsection II C 2."}, {"title": "1. Quantum NFL theorem", "content": "The No-Free-Lunch (NFL) theorem is a renowned result in learning theory, emphasizing the constraints on the ability to learn a function solely from a training dataset. Its significance in classical learning theory is extensively acknowledged [38-40, 67-69]. Ref. [41] pioneered the NFL theorem's application to quantum machine learning, where both inputs and outputs are quantum states. Subsequently, Ref. [42] refined the quantum NFL theorem for quantum-assisted learning protocols where the bipartite entangled states are prepared as the training states of learning models by introducing a reference quantum system. They highlighted that the use of such entangled data could offset the exponential training data size demands when learning unitaries with non-entangled data. Ref. [70] provides a unified information-theoretic reformulation of the quantum no-free-lunch theorem from the lens of representation space of quantum states, indicating the same power of mixed states [71] as entangled states. Furthering this discourse, Ref. [43] shifted the focus towards a pragmatic learning scenario-learning a target operator through finite measurement outcomes on quantum states, as opposed to learning directly from the quantum output states themselves. Their findings underlined that the degree of entanglement in quantum states presents a dual effect on the generalization performance of learning models contingent on the number of measurements.\nHowever, despite the promising results shown by entangled data in reducing the size of training datasets, the preparation of entangled data is highly resource-intensive and tends to introduce additional quantum noise, particularly in the early stages of quantum computing. The problem settings explored in this work lean towards a more realistic approach, focusing on learning the quantum unitaries using unentangled data."}, {"title": "2. Separation between classical and quantum learning models", "content": "As the aim of quantum machine learning is to harness the peculiarities of quantum mechanics to improve upon the capabilities of classical learning models, the separation in learning performance between classical and quantum learning models has been explored in various learning tasks under various metrics, including classification [47, 72] and quantum system learning [73].\nFor the classification tasks, Ref. [33] has demonstrated that for carefully sculpted synthetic data with quantum computers, quantum kernels could achieve a significant reduction in terms of the generalization error over the best classical kernel methods. Moreover, Ref. [34] has shown the power of quantum kernels on classical data of discrete logarithm problems which could not be efficiently addressed by classical algorithms in polynomial time.\nQuantum system learning aims to fully characterize the quantum states or quantum channels by measuring the outcomes of the quantum systems. A plethora of studies"}, {"title": "III. Problem setup for quantum dynamics learning", "content": "Quantum dynamics learning involves converting a black-box quantum evolution operator into a digital form that can be analyzed on the quantum or classical computer. As discussed in Section I, quantum dynamics learning is essential for understanding the behavior and evolution of quantum systems, enabling precise control and manipulation of quantum states for various applications. By studying the evolution of quantum states, researchers can develop efficient algorithms such as quantum Fourier transformation [58] and variational quantum eigensolver [77], optimize quantum circuits for quantum error correction [78], and tackle complex problems in fields like quantum information processing [79-81], quantum chemistry and material sciences [82-85], and particle physics [86, 87]. In other words, learning quantum dynamics is often a necessary step before executing algorithms on real quantum devices. Several companies have developed their own commercial quantum learning platforms to facilitate this process [88, 89].\nHere we consider the specific form of quantum dynamics learning-learning a quantum unitary U under a given observable O, where U could be the unknown dynamics of an experimental quantum system. Formally, the target function is given by\n$f_U(\\psi) = \\text{Tr}(OU |\\psi\\rangle \\langle \\psi|U^{\\dagger})$,\nwhere O is an arbitrary bounded Hermitian operator with $||O||_\\infty < \\infty$. Let $\\mathcal{D} = \\{\\langle |\\psi_j\\rangle, y_j\\}\\}_{j=1}^N$ be the training dataset of N examples, where $y_j$ could be quantum data"}, {"title": "A. Risk function and No-Free-Lunch theorem", "content": "The risk function (or prediction error) is a crucial measure in statistical learning theory to quantify how well the learned hypothesis function h performs in predicting the concept f. As discussed in Subsection II B, the risk function in the context of learning the target function of Eqn. (5) refers to\n$\\mathcal{R}_U (\\mathcal{V}_D) = \\int d\\psi (f_U(\\psi) - h_{\\mathcal{P}}(\\psi))^2$,\nwhere $h_{\\mathcal{P}}(\\psi_j) = \\text{Tr}(OV_D |\\psi_j\\rangle \\langle \\psi_j|V_D^{\\dagger})$ with $V_D$ referring to the trained unitary, and the integration is taken over the Haar states $|\\psi\\rangle$. In the following, the term risk function and prediction error will be used interchangeably to elucidate the theoretical and empirical results.\nIn traditional machine learning, the no-free-lunch (NFL) theorem aims at deriving the lower bound of the average risk function across all possible training datasets and target concepts, under the assumption of perfect training that is, the learned hypothesis achieves zero training error for a given loss function [38, 90]. In the context of learning n-qubit quantum dynamics, the possible concept refers to the unitary operator within the unitary group, i.e., $U \\in \\mathcal{U}(d)$ with $d = 2^n$ being the dimension of n-qubit quantum system. Moreover, the uniform distribution of the target concept corresponds to the Haar distribution of unitaries as introduced in Subsection II A. The type of training dataset $\\mathcal{D}$ depends on the employed learning protocol. In this regard, we formulate the problem considered by the NFL theorem for quantum dynamics learning as follows.\nProblem 1. Let $\\mathcal{D} = \\{\\langle |\\psi_j\\rangle, y_j\\}| |\\psi_j\\rangle \\in H_x,Y_j \\in H_y\\}_{j=1}^N$ be the training dataset and $\\mathcal{P} : H_x \\rightarrow H_y$ be the related learning protocol satisfying the perfect training assumption $\\mathcal{P}(|\\psi_j\\rangle) = Y_j$ for any $j \\in [N]$. Let $h_{\\mathcal{P}}(\\psi) = \\text{Tr}(OV_D) |\\psi\\rangle \\langle \\psi|)$ be the learned hypothesis and O an arbitrary observable. The NFL theorem for quantum dynamics learning considers the lower bound of the average risk function\n$\\mathbb{E}_\\mathcal{UE}\\mathcal{D}\\mathcal{R}_U (\\mathcal{V}_D) = \\mathbb{E}_\\mathcal{UE}\\mathcal{D} \\int dy (f_V(\\psi) - h_{\\mathcal{P}}(\\psi))^2$,\nwhere the expectation is taken over the Haar unitary and all possible training datasets in some specific types."}, {"title": "B. Classical learning protocols", "content": "The ClassiCal Learning Protocols (CLC-LPs) employ the states $|\\psi_j\\rangle$ as inputs and the measurement output of the fixed observable O on the evolved states $U|\\psi_j\\rangle$ as the response, as shown in Fig. 3(a). The input $|\\psi_j\\rangle$ could be quantum states obtained in experiments or classical states of bits, referring to the computational basis $|e_j\\rangle$. Denote the fixed observable O defined in Eqn. (5) as the spectral decomposition $O = \\sum_{q=1}^r o_q|o_q\\rangle \\langle o_q|$, where $|o_q\\rangle$ are the eigenvectors related to the eigenvalues $o_q$ of observable O. As the expectation value of the observable O could be obtained by measuring the output states with the projective measurement $\\{|o_1\\rangle \\langle o_1|,\\dots,|o_r\\rangle \\langle o_r\\}$, the training dataset of N examples takes the form\n$\\mathcal{D}_c = \\{\\langle |\\psi_j\\rangle,a_j\\}| |\\psi_j\\rangle \\in H_d, a_j = (a_{j1},\\dots, a_{jr})\\}_{j=1}^N,$\nwhere $a_{jq} = \\text{Tr}(U^{\\dagger} |o_q\\rangle \\langle o_q| U |\\psi_j\\rangle \\langle \\psi_j|U)$ refers to the expectation value of projective measurement $|o_q\\rangle \\langle o_q|$. In this regard, the loss function is given by\n$\\mathcal{L}_c(\\theta) = \\frac{1}{N} \\sum_{q=1}^r \\sum_{j=1}^N |a_{jq} - \\text{Tr}(V^{\\dagger}(\\theta) |o_q\\rangle \\langle o_q| V(\\theta) |\\psi_j\\rangle \\langle \\psi_j||^2$,\nwhere the tunable unitary $V(\\theta)$ is trained to learn the output of each projective measurement $|o_q\\rangle \\langle o_q|$. This leads to the form of perfect training assumption\n$\\text{Tr}(U^{\\dagger} |o_q\\rangle \\langle o_q| U |\\psi_j\\rangle \\langle \\psi_j|) = \\text{Tr}(V|o_q\\rangle \\langle o_q| V_c |\\psi_j\\rangle \\langle \\psi_j|]$,\nwhere $V_c$ is the well-trained unitary and $j\\in [N], q\\in [r]$.\nNotably, the trained unitary $V_c$ could be employed to predict the output of a class of observables with the form of $O_j = \\sum_{q=1}^r o_{jq}|o_q\\rangle \\langle o_q|$ for any $o_{jq} \\in \\mathbb{R}$ by post-processing the classical output of the projective measurement $|o_q\\rangle \\langle o_q|$.\nRemark. (i) This learning protocol resembles the classical shadow [75] where the outputs of random projective measurement are utilized to efficiently predict the expectation value of exponential diverse observables on a given quantum state, namely $\\text{Tr}(U^{\\dagger}OUp)$ for $O \\in \\{O_j\\}_{j=1}^\\infty$. However, we focus on the sample complexity of learning a random quantum unitary, while classical shadow considers the query complexity for predicting the properties of specific states. (ii) This learning protocol is also dubbed the incoherent learning protocol in Ref. [93]. We suggest the name 'classical learning protocols' because when the target unitary is generated by Clifford circuits, this learning protocol could be implemented completely on the classical computer without using any quantum resources by training on classical bitstrings, as Gottesman-Knill theorem [94] shows that the Clifford circuits can be efficiently simulated with classical computers."}, {"title": "C. Restricted quantum learning protocols", "content": "Restricted Quantum Learning Protocols (ReQu-LPs) allow coherent operations to act on the target quantum system U, meaning that the target unitary U and the tunable unitary V (\u03b8) could be implemented on the same quantum devices. Specifically, the output states $U |\\psi_j\\rangle$, derived from the given input state $|\\psi_j\\rangle$, can be preserved in quantum memory. This storage facilitates subsequent direct operations using a parameterized quantum circuit, as depicted in Fig. 3(b). In this end, the training data refers to the pair of input-output states $(\\langle |\\psi_j\\rangle, U |\\psi_j\\rangle)$ stored in quantum memory. This differs from the CLC-LPs in the responses where the latter employs the measurement outcomes on the output state $U |\\psi_j\\rangle$ for training. Given the training dataset with N examples, i.e.,\n$\\mathcal{D}_{RQ} = \\{\\langle |\\psi_j\\rangle, U|\\psi_j\\rangle\\}| |\\psi_j\\rangle \\in H_d\\}_{j=1}^N,$\nthe loss function takes the trace norm of the difference between the evolved states under the target unitary U and the tunable unitary V(\u03b8), which is given by\n$\\mathcal{L}_{RQ}(\\theta) = \\frac{1}{N} \\sum_{j=1}^N ||U |\\psi_j\\rangle \\langle \\psi_j| U^{\\dagger} -\nV(\\theta) |\\psi_j\\rangle \\langle \\psi_j| V^{\\dagger}(\\theta)||_1.$\nBy using the relation between the trace norm and fidelity [58], this loss function can be reformulated as the expression in terms of the average fidelity\n$\\mathcal{L}_{RQ}(\\theta) = 1 - \\frac{1}{N} \\sum_{j=1}^N |\\langle \\psi_j| U^{\\dagger}V(\\theta)|\\psi_j\\rangle|^2.$\nFor ReQu-LPs, optimizing the loss function needs to calculate the inner product between the output states $U |\\psi_j\\rangle$ and $V(\\theta) |\\psi_j\\rangle$, which could be efficiently computed employing the Loschmidt echo or swap test circuit as shown in Fig. 1(b). Moreover, given the training dataset $\\mathcal{D}_{RQ}$ in Eqn. (11), the assumption of perfect training refers to $|\\langle \\psi_j| U^{\\dagger}V_{RQ}|\\psi_j\\rangle|^2 = 1$ for any $j\\in [N]$, or equivalently\n$U |\\psi_j\\rangle = e^{i\\alpha_j} V_{RQ}|\\psi_j\\rangle,$\nwhere $V_{RQ}$ refers to the well-trained unitary on the training dataset $\\mathcal{D}_{RQ}$, $\\alpha_j$ refers to the inter-state relative phase between the output states and varies with different input states $|\\psi_j\\rangle$. Particularly, the phase $\\alpha_j$ could be arbitrary and is uniformly distributed over any period of the function $e^{\\alpha_j}$ in the context of NFL theorems considering the average case of all related ingredients."}, {"title": "D. Quantum learning protocols with access to $U^{\\dagger}$", "content": "While ReQu-LPs are restricted to access to the vanilla target quantum system U, Quantum Learning Protocols"}, {"title": "IV. NFL theorem for quantum dynamics learning", "content": "In this section, we first introduce how to reduce the problem regarding NFL theorems of deriving a lower bound as elucidated in Problem 1 to a simplified problem of deriving an upper bound in Subsection IV A. Then, we establish the NFL theorems for CLC-LPs, ReQu-LPs, and ReQu-Qu-LPs in Section IVB, Section IV C, and Section IV D, respectively. Finally, we discuss the separation in terms of sample complexity between various learning protocols and identify the quantum resource used in quantum-related learning protocols causing such separation in Section IV E."}, {"title": "A. NFL theorem for QML", "content": "Recall that the NFL theorem considers the lower bound of the average risk function as detailed in Problem 1. It is"}, {"title": "B. NFL theorem for classical learning protocols", "content": "We first consider the NFL theorem in the ClassiCal Learning Protocol (CLC-LP) introduced in Section III B. Under this learning protocol with perfect training assumption in Eqn. (10), the following NFL theorem gives the lower bound of the average risk function defined in Eqn. (7)."}, {"title": "C. NFL theorem for restricted quantum learning protocols", "content": "For the Restricted Quantum Learning Protocols (ReQu-LPs) introduced in Section IIIC, the NFL theorem is encapsulated in the following theorem, whose proof is deferred to Appendix E."}, {"title": "D. NFL theorem for quantum learning protocols", "content": "We now elucidate the NFL theorem for Quantum Learning Protocols (Qu-LPs) with access to $U^{\\dagger}$. Under the"}, {"title": "E. Separation in various learning protocols", "content": "In this subsection, we combine the established NFL theorems for various learning protocols in Theorems 1-3 to comprehend the separable ability between various learning protocols.\nSeparation between CLC-LPs and quantum-related learning protocols (ReQu-LPs and Qu-LPs). When the training states are linearly independent and non-orthogonal such that the phase alignment $1(\\alpha \\propto 1_N)$ or $1(\\beta \\propto 1_N)$ is satisfied, the sample complexity required to achieving the zero prediction error scales with $d^2$ for CLC-LPs (Theorem 1) and d for ReQu-LPs"}, {"title": "V. Experiments", "content": "We conduct numerical simulations to verify the separation in learning performance between various learning protocols discussed above, showing the significance of capturing the phase information during the training process. All numerical simulations are implemented by Pennylane frameworks [101]."}, {"title": "A. Datasets", "content": "The target unitary is an n-qubit Haar random unitary U with n \u2208 {4,5}. The training datasets corresponding to the CLC-LPs, ReQu-LPs, and Qu-LPs take the form of Eqn. (8), Eqn. (11), and Eqn. (15). Two types of states"}, {"title": "B. Model construction and evaluation metric", "content": "Circuit optimization: We take the same hardware efficient ansatz (HEA) V (\u03b8) as the parameterized quantum unitary towards achieving the perfect training in various learning protocols, as shown in Fig. 5. The HEA consists of single rotation gates and CNOT gates. The number of layers is set as L = 30 for n = 4 and L = 42 for n = 5. The ADAM optimizer is employed to update the parameters in the HEA V (\u03b8) with learning rate \u03b7 = 0.01. The maximal iteration step is set as T = 1000 for n = 4 and T = 500 for n = 5.\nEvaluation metric: To show the separation between the classical learning protocols and quantum learning protocols, we record the averaged prediction error and averaged"}, {"title": "C. Experimental results", "content": "Separation between the CLC-LPs, ReQu-LPs, and Qu-LPs. The simulation results for the observable O being projective measurement $(|0\\rangle \\langle 0|)^n$ are displayed in Fig. (4) (a)-(c). In particular, Fig. 4 (a) indicates that the Qu-LPs could achieve a significant reduction in the sample complexity for achieving the zero prediction error from N = 64 to N = 16, compared to CLC-LPs when the input states are sampled from Haar distribution. Moreover, when the input states are orthogonal, the prediction performance of the ReQu-LPs with access to U is the same as the CLC-LPs, while the Qu-LPs with access to the inverse of the target unitary $U^{\\dagger}$ retains the same prediction performance as the case of using Haar input states, achieving quantum advantages over the other two learning protocols. In particular, when the training dataset size is N = 16, the Qu-LPs with access to $U^{\\dagger}$ reach zero prediction error, and the CLC-LPs and ReQu-LPs only have a small reduction of the prediction error than that of N = 1 and get a prediction error higher than 0.8. The same phenomenon also happens in the case of n = 5, as shown in Table III. These numerical results echo with the theoretical results established in Section IV for the projective measurement.\nThe significance of phase alignment. Fig. 4(c) shows the consistency of the phase alignment and the learning performance shown in Fig. 4(a), which highlights the significance of learning phase information in incurring the separation in sample complexity between CLC-LPs and ReQu-LPs. In particular, when the ReQu-LPs perform"}, {"title": "VI. Conclusion", "content": "In this article, we rigorously explored the universal learning performance of three distinct learning protocols for learning a target unitary under a fixed observ-able\u2014namely, classical learning protocols (CLC-LPs), restricted quantum learning protocols (ReQu-LPs), and quantum learning protocols (Qu-LPs)\u2014each employing quantum resources in ascending order. By establishing no-free-lunch (NFL) theorems tailored to these protocols, our theoretical results reveal a quadratic separation in terms of sample complexity between CLC-LPs, ReQu-LPs, and Qu-LPs. Our analysis suggests that the separation between CLC-LPs and the two quantum-related learning protocols originates from their differing capabilities in capturing the inter-state relative phase-a feature that ReQu-LPs and Qu-LPs possess when training states are non-orthogonal, but which CLC-LPs lack regardless of the training states. The conducted numerical simulations accord with the theoretical result. The results achieved in this study not only deepen our understanding of the capabilities of quantum learning protocols from both problem-and data-dependent perspectives but also elucidate the inherent quantum mechanisms that enable these capabilities. This insight provides practical guidance for designing advanced quantum learning protocols."}]}