{"title": "Capturing Temporal Dynamics in Large-Scale Canopy Tree Height Estimation", "authors": ["Jan Pauls", "Max Zimmer", "Berkant Turan", "Sassan Saatchi", "Philippe Ciais", "Sebastian Pokutta", "Fabian Gieseke"], "abstract": "With the rise in global greenhouse gas emissions, accurate large-scale tree canopy height maps are essential for understanding forest structure, estimating above-ground biomass, and monitoring ecological disruptions. To this end, we present a novel approach to generate large-scale, high-resolution canopy height maps over time. Our model accurately predicts canopy height over multiple years given Sentinel 2 time series satellite data. Using GEDI LiDAR data as the ground truth for training the model, we present the first 10 m resolution temporal canopy height map of the European continent for the period 2019-2022. As part of this product, we also offer a detailed canopy height map for 2020, providing more precise estimates than previous studies. Our pipeline and the resulting temporal height map are publicly available, enabling comprehensive large-scale monitoring of forests and, hence, facilitating future research and ecological analyses.", "sections": [{"title": "1. Introduction", "content": "As global carbon emissions continue to rise, meeting the goals of the Paris Agreement\u00b9 requires a comprehensive understanding of all climate-related factors. This includes precise quantification and temporal monitoring of carbon sinks.\nHowever, despite decades of research and the development of numerous methods, this quantification remains insufficient for detailed and effective policymaking (Cook-Patton et al., 2020; Cuni-Sanchez et al., 2021). An essential part of this quantification is the monitoring of forest ecosystems, in turn allowing their management and conservation. To support climate adaptation and mitigation strategies, accurate and up-to-date information on forest health and carbon balance is critical to evaluate the current state of forests, to implement measures to prevent forest loss, and to improve management strategies (Friedlingstein et al., 2019).\nA key approach to assess forest conditions is based on measuring or estimating tree heights, which results in height values that are used to approximate wood volume, so-called above-ground biomass and, consequently, the carbon stored in trees (Schwartz et al., 2023). A traditional way to obtain corresponding measurements is to manually measure individual trees, resulting in so-called National Forest Inventories (NFI). Such inventories are essential for forest monitoring, but are very costly and also lack global reach. This issue is worsened by varying forest monitoring efforts and techniques across different nations with different financial resources (Sloan & Sayer, 2015). However, advances in Earth observation and machine learning now enable automated, comprehensive global forest assessments by leveraging satellite data, including optical, radar, and LiDAR measurements (Hu et al., 2020). The resulting high-resolution canopy height maps are essential for understanding forest dynamics and supporting climate change mitigation efforts.\nRecent studies have advanced canopy height prediction using classical machine learning methods (Potapov et al., 2021; Kacic et al., 2023) and deep learning approaches (Schwartz et al., 2024; Fayad et al., 2023; Lang et al., 2023; Pauls et al., 2024; Liu et al., 2023; Tolan et al., 2024), with the satellite-dependent resolution varying between 30 m (Landsat), 10m (Sentinel-1, -2), 3 m (Planet-Labs) and 60 cm (Maxar) with only the Sentinel and Landsat program being openly available. However, almost all studies focus on predicting canopy height for a single year, despite that being insufficient (Bevacqua et al., 2024). Temporal dynamics of forests are essential for identifying carbon sources and sinks and assessing forest responses to natural or human-induced stressors such as drought, diseases, or environmental changes, and potentially predicting future forest developments. Although some methods have explored temporal tree height mapping\u00b2 at local scales (Kacic et al., 2023) and Turubanova et al. (2023) produced a map for Europe, no approach has yet tackled this challenge at a resolution of 10 m and greater scale combined, which is vital for assessing forest structural details.\nIn this work, we introduce an approach for generating large-scale, temporal tree height maps from satellite imagery. Specifically, we use a custom deep learning approach that predicts tree canopy height from Sentinel image data, using the sparsely-distributed space-borne GEDI LiDAR data as a ground truth source for tree height.\nContributions. We address the task of estimating tree canopy heights given satellite time series data as input. The main contributions made in this work are as follows:\n1.  We provide a model capable of accurately tracking forest height changes at 10 m resolution across the entire European continent, enabling consistent detection of growth and decline from 2019-2022.\n2.  We present a canopy height map of Europe for the year 2020, providing more accurate measurements and finer spatial details than previous studies, both in quantitative and qualitative assessments.\n3.  We demonstrate that using a full 12-month time series of Sentinel-2 imagery, rather than using a single aggregated composite, yields substantial performance gains by allowing the model to capture seasonal patterns and leverage geolocation shifts.\nThe entire pipeline and model weights are publicly available on GitHub\u00b3 Further, the resulting canopy height maps are accessible through Google's Earth Engine (Gorelick et al., 2017), ensuring reproducibility and facilitating research on large-scale forest monitoring and above-ground biomass estimation. Our framework highlights the importance of using multi-temporal satellite data for forest monitoring, enabling precise, large-scale assessment of forest structure and dynamics."}, {"title": "2. Background", "content": "Tree canopy height estimation has advanced significantly through integrating satellite data from Sentinel (European Space Agency, 2024), Landsat (Williams et al., 2006), GEDI (Dubayah et al., 2020), ICESat (Abdalati et al., 2010), and Aerial Laser Scanning (ALS). The goal is to predict the tree height for each pixel in satellite images. However, ground truth data like GEDI measurements are limited and sparsely distributed across the globe. This section covers the fundamental challenges of creating such maps."}, {"title": "2.1. Satellite Imagery", "content": "Openly available satellite imagery for tree canopy height prediction is primarily sourced from three key missions: Landsat, Sentinel-1, and Sentinel-2. The Landsat program (Williams et al., 2006), run by NASA since 1972, offers optical multi-spectral imagery with a 30 m resolution and a 16-day revisit cycle, meaning that new data are collected for any region every 16 days. The Sentinel missions, operated by the European Space Agency (ESA) since 2014, include Sentinel-1 with Synthetic Aperture Radar (SAR) and Sentinel-2 with multispectral sensors. Both provide 10 m resolution images and a global revisit time of about 5 days, allowing more frequent forest monitoring. While airborne data can achieve higher resolutions of up to 10 cm, it is often limited to specific regions and not widely accessible, making spaceborne imagery the preferred choice for large-scale height mapping.\nWhile these satellite missions provide global-scale image data, single images are often not suitable for canopy height prediction. Radar satellites like Sentinel-1 can suffer from rain interference and noise, while multispectral sensors like Sentinel-2 and Landsat struggle with cloud and cirrus penetration. These images require preprocessing, such as cloud removal, color correction, and atmospheric correction, to convert from Top-of-the-Atmosphere (TOA) to Bottom-of-the-Atmosphere (BOA) images.\nTo further address these issues, temporal composites are used to aggregate images over time, employing techniques like per-pixel median calculation (Pauls et al., 2024;"}, {"title": "2.2. Tree Canopy Height Estimation", "content": "Tree canopy height mapping has evolved from classical machine learning (Kacic et al., 2023; Potapov et al., 2021) to advanced methods such as convolutional networks (Liu et al., 2023; Yan et al., 2018; Lang et al., 2023) and vision transformers (Fayad et al., 2023; Tolan et al., 2024).\nA key challenge in training models for temporal canopy height estimation is obtaining accurate ground-truth data. This data can come from national forest inventories or LiDAR measurements, either airborne or spaceborne. Airborne LiDAR provides high-resolution data but is limited to local areas. In contrast, NASA's GEDI mission offers broader geographic and temporal coverage with spaceborne LiDAR, though at a coarser spatial resolution and with occasional geolocation inaccuracies. GEDI measures canopy heights using laser shots with a 25 m footprint, but only about 4% of Earth's surface is covered during the satellite's operational period, and spatial alignment across different years is virtually non-existent. This inconsistency complicates the use of GEDI as a reliable temporal training dataset.\nIn consequence, most studies focus on estimating height for a single year, with few addressing multi-year time series (Dixon et al., 2025; Kacic et al., 2023; Turubanova et al., 2023). Mapping efforts over multiple years or seasons face significant computational and storage challenges and can result in fluctuating height estimates due to varying satellite conditions and model uncertainties. A common approach is to apply a single-year model to data from other years, but this fails to capture temporal patterns. Consequently, post-processing techniques like moving averages, trend detection, and cut-detection are used to smooth out year-to-year variations. Developing a robust, large-scale framework for temporal tree canopy height mapping remains a key research challenge in forest monitoring."}, {"title": "3. Approach", "content": "Our methodology integrates multi-source satellite imagery and GEDI LIDAR data to produce high-resolution, temporal canopy height maps for Europe. This section details the data sources, preprocessing steps, and the design of our deep learning framework."}, {"title": "3.1. Data", "content": "To construct our dataset, we integrate information from three key sources: Sentinel-1, Sentinel-2, and GEDI. Each dataset undergoes rigorous preprocessing to ensure compatibility and optimal quality. To keep the best projection accuracy, we use a tiling system following the Universal Transverse Mercator (UTM) system and process the data in these tiles.\nSentinel-1 and Sentinel-2. Sentinel-1 provides Synthetic Aperture Radar (SAR) measurements in two polarizations: VV (vertical-vertical) and VH (vertical-horizontal), acquired in the Interferometric Wide Swath (IW) mode. Images are collected from both ascending and descending orbits, resulting in four distinct channels per tile. Due to the high noise levels inherent in SAR data, we aggregate the measurements over temporal space by computing the per-pixel median across all acquisitions within a year, thereby mitigating noise and enhancing temporal consistency. The data is collected in the Sentinel UTM coordinate system, where each tile spans 100 km \u00d7 100 km.\nSentinel-2 multispectral imagery is a key part of our approach. We use the Level-2A surface reflectance product (BOA) available via the Copernicus AWS, selecting a single best image each month based on minimal cloud cover, thereby ensuring minimal contamination and consistent data quality. This yields a temporal sequence of 12 monthly images per tile and year (one per month), thereby preserving seasonal patterns important for vegetation monitoring.\nWe include all Sentinel-2 bands except B10 (cirrus). To prepare the training data, each band's reflectance values are normalized by a fixed factor (cf. Table 1), mapping values to [0, 1]. Rather than employing conventional min-max or zero-mean normalization techniques, which are substantially affected by the presence of clouds and cirrus, we identified value ranges for each band that contain \"valuable\" information, ensuring data quality is maintained for analysis. By retaining monthly variability instead of aggregating temporal data, our approach captures seasonal dynamics, such as transitions between leaf-on and leaf-off states, which are crucial for vegetation monitoring.\nGEDI. GEDI LiDAR data provides sparse height measurements that are essential for model supervision. We use the Level-2A product, transforming its geolocations to align with the Sentinel UTM grid. Several filters are applied to ensure data quality: valid quality flags, non-degraded shots, and a sensitivity threshold of 0.9. We consider only high-power beams (IDs 5\u20138) due to their superior signal-to-noise ratio. Height values are constrained to a plausible range of [0, 100 m] to exclude outliers. We utilize the rh_98 metric (relative height 98%), which corresponds to the height below which 98% of returned photons are recorded, providing a robust estimate of canopy height. We use data from the years 2019-2022, where we have full coverage."}, {"title": "3.2. Model Architecture", "content": "We adopt a three-dimensional (3D) U-Net inspired by \u00c7i\u00e7ek et al. (2016), originally proposed for volumetric segmentation tasks, and modify it to output a single-channel tree canopy height for each input pixel. Unlike prior approaches relying on static images or single composites (Schwartz et al., 2024; Pauls et al., 2024), our model processes a stack of 12 monthly Sentinel-2 images concatenated with an aggregated Sentinel-1 composite. This approach exploits temporal patterns (e.g., seasonal vegetation changes), and leverages geolocation offsets in Sentinel-2 imagery and enhances spatial resolution by incorporating information from neighboring pixels.\nThe architecture follows the standard encoder-decoder U-Net structure, employing 3D convolutions throughout to capture both spatial and temporal dependencies. We adapt the final output layer to generate a single-channel height map rather than a multi-class segmentation mask. In parallel, Sentinel-1 data \u2013 aggregated into a single median-based image over the year \u2013 is repeated across these time slices so that the model can exploit both radar and optical signals. The encoder path slowly reduces the temporal dimension from its initial size down to 1 at the bottleneck, and each skip connection likewise applies a 3D convolution with a kernel size matching the remaining temporal images, effectively collapsing the temporal dimension to a single slice."}, {"title": "3.3. Model Training", "content": "Our training strategy is designed to address the challenges of sparse ground truth data, geolocation inaccuracies, and the need for temporally consistent predictions. The final model, based on the 3D U-Net architecture, is trained to predict canopy heights across spatial and temporal scales using a modified Huber loss (Pauls et al., 2024).\nModified Huber Loss. Our final loss function is the Huber loss, as it effectively balances penalizing small errors while being less sensitive to outliers compared to L2 loss. This is especially important because GEDI geolocation data often contains outliers. Since GEDI's geolocation is not perfectly precise, we incorporate a shift mechanism (Pauls et al., 2024), to account for systematic geolocation offsets. This mechanism allows the model to adjust an entire flight path (referred to as a \"track\") by a predefined maximum offset, such as 10 m, to reduce errors caused by consistent misalignment. Additionally, because the labels in our dataset are sparse - meaning that many pixels lack corresponding label values we compute the loss only for labeled pixels and ignore unlabeled pixels during training.\nOptimization Setup. We train our models using Adam (Kingma, 2014) with an initial learning rate of 0.001, weight decay of 0.01, and gradient clipping at 1.0. We follow best practices and use a linear learning rate scheduler with a 10% warmup, training for 400,000 iterations with a batch size of 16 (corresponding to 8 epochs).\nDataset Size. Our dataset comprises 800,000 randomly selected patches, each measuring 2.56 km \u00d7 2.56 km, totaling 8 TB in size. To minimize computational load and data transfer, we use a 10% subset for training and hyper-parameter tuning for the different baselines, as outlined in Section 4.1. The final model is then trained on the entire dataset.\nPost-Processing. A problem of temporal height maps is fluctuating predictions due to uncertainties in the data, such as inconsistent color calibration and varying cloud cover. To mitigate this, we apply a quadratic smoothing spline to capture the underlying trend while reducing noise. We set the smoothing parameter to 5 to balance fidelity to the data with improved temporal consistency, ensuring a clear and more interpretable prediction visualization."}, {"title": "4. Results", "content": "This section presents the results of our temporal tree canopy height estimation model, including quantitative and qualitative evaluations. We focus on the accuracy of our predicted tree canopy height maps, comparisons with existing models, and generalization across diverse european forest regions.\nAll results in this section are based on 1,500 randomly selected validation points, see Figure 2 for the distribution. At each validation point, we select a 2.56 km \u00d7 2.56 km area to collect all available GEDI labels that match the same criteria as in Section 3.1. We compare with five existing canopy height maps (Liu et al., 2023; Tolan et al., 2024; Lang et al., 2023; Turubanova et al., 2023; Pauls et al., 2024), downloaded from Google Earth Engine, and resample all maps to 10 m in a global projection system (EPSG:4326)."}, {"title": "4.1. Establishing Baselines", "content": "We evaluate our approach by comparing various model configurations. None of these models use explicit time-stamp information (e.g., a separate channel for month or year). Instead, they differ in their treatment of satellite data (e.g., full monthly stacks vs. median composites) and the span of training data (single-year vs. multi-year). In all configurations, Sentinel-1 data \u2013 aggregated into a median composite is concatenated along the channel dimension.\nC1: Single-Year Models Applied to Multiple Years. In this configuration, a model is trained on data from a single reference year and used to predict canopy height in other years without any retraining. We focus on 2020 due to the availability of published models for this period (Lang et al., 2023; Tolan et al., 2024; Turubanova et al., 2023; Pauls et al., 2024), enabling direct comparisons. We explore the following three variants of this approach:\n2D-STACK-2020: A 2D U-Net trained on the full 12-month Sentinel-2 stack of 2020, where monthly channels are flattened into a single tensor of shape [B, H, W, 12\u00d7 Channels].\n2D-COMPOSITE-2020: A 2D U-Net trained on the median composite of the 12 monthly images, reducing each year's input to a single image of shape [B, H, W, Channels].\n3D-STACK-2020: A 3D U-Net (similar to our model) trained solely on the 2020 dataset, using the 12-months stack as a spatio-temporal volume [B, H, W, 12, Channels].\nAfter training on the 2020 dataset, we evaluate the 2D-STACK-2020, 2D-COMPOSITE-2020, and 3D-STACK-2020 models on 2019-2022 satellite imagery to assess their generalization without multi-year training.\nC2: Single-Year Models for Each Year. This configuration trains independent models for each target year. We develop three variants per year-2D-STACK-YEAR, 2D-COMPOSITE-YEAR, and 3D-STACK-YEAR-with each model trained and validated solely on data from its respective year. This approach evaluates how well specialized, single-year models capture inter-annual variability.\nC3: Multi-Year Models. To enhance generalizability across years, we train models on multi-year data (2019-2022). We use both stack-based (2D-STACK-MULTIYEAR, 3D-STACK-MULTIYEAR) and composite-based (2D-COMPOSITE-MULTIYEAR) approaches. While the 2D-STACK architectures process multi-month data by concatenating all months into a single input dimension, they do not explicitly exploit temporal relationships."}, {"title": "4.2. Quantitative Evaluation", "content": "We begin by comparing our different model configurations for the reference year 2020 across different metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE) and Root Mean Squared Error (RMSE). As the resulting map is targeted towards forest assessment, we compare it only against labels exceeding 7 m, to exclude labels over acres and grassland. Another key comparison is how the metrics vary across different years. The results demonstrate that 3D-STACK-MULTIYEAR significantly outperforms all other configurations, both in single-year and multi-year analyses. In contrast, 2D-COMPOSITE consistently shows the poorest performance, followed by 2D-STACK and 3D-STACK."}, {"title": "4.3. Method Comparison", "content": "As outlined in Section 3.3, all models were trained on a smaller dataset. After identifying the best performing configuration, we trained a new model, 3D-STACK-MULTIYEAR-L, on the full dataset, which we will refer to as Ours from this point forward. Unless stated otherwise, all values in this section are based on labels greater than 7 m to focus on forest-related data.\nQuantitative Evaluation. Despite the coarser resolution of Sentinel-1/2 (10 m) compared to Planet (3 m) or Maxar (60 cm), models utilizing Sentinel data achieve higher accuracy, likely due to the availability of near-infrared and shortwave-infrared bands. As shown in our model, 3D-STACK-MULTIYEAR-L, achieves the best performance across all metrics, with an MAE of 4.76 m\u2014representing a 13% improvement over the next-best model (Pauls et al., 2024). Similar improvements are observed for MSE and RMSE.\nTurubanova et al. (2023) offers the only other high-resolution, multi-year tree canopy height map trained at European scale, with predictions spanning 2001-2021. Our model consistently outperforms Turubanova et al. (2023) across all shared years, achieving MAE values less than half theirs (61% improvement). Although both models exhibit notable inter-annual variations, likely due to factors such as lighting conditions, forest dynamics, and differences in label distributions, the results demonstrate the superior accuracy and robustness of our model for European tree canopy height estimation.\nTree canopy height maps often suffer from reduced accuracy as tree height increases; a serious problem as tree canopy height maps are often used for above-ground biomass prediction, where biomass typically scales non-linearly with height following an allometric power-law relationship. The results demonstrate that the prediction is on average lower than the label. For smaller trees ranging from 10 m to 20 m, Lang et al. (2023) and our model perform reasonably well, whereas Tolan et al. (2024) and Turubanova et al. (2023) show mean errors around -10m, which worsen further for taller trees. Notably, from 20 m onward, our model outperforms all others, achieving a mean error of approximately -5 m between 35 m and 40 m, significantly reducing the error compared to the next best model by Lang et al., particularly for these ecologically critical tall trees. This substantial improvement highlights our model's ability to provide more reliable tree canopy height estimates for tall trees, which are key contributors to carbon storage. The plots reveal that our model exhibits the narrowest point cloud, with the highest density areas aligning closely with the perfect fit line, and achieves strong performance up to 40 m-45 m. Consequently, we improve R2 from 0.793 to 0.819, and for labels over 7 m (R), from 0.536 to 0.591."}, {"title": "Qualitative Evaluation", "content": "While quantitative evaluation is essential, visual quality is equally important for tree canopy height prediction. The first column shows a high-resolution satellite image from Google Maps (not necessarily from 2020) whereas all other columns show the height between 0m (black) and 35 m (light yellow). Despite its relatively modest metrics, the high resolution of Tolan et al. (2024)'s map makes it effective for canopy detection. Liu et al. (2023) identifies trees with higher resolution and does not suffer as much from saturation effects as Tolan et al. (2024) and Turubanova et al. (2023). While our model lacks the high resolution of Liu et al. (2023) and Tolan et al. (2024), it surpasses Pauls et al. (2024), Lang et al. (2023), and Turubanova et al. (2023). Unlike other maps that assign similar heights to all forest patches, our map is the only one that differentiates between various forest heights in smaller patches (lower part of the first image row).\nOne strong improvement of our model is the detection of forest patches with very high trees. Although Liu et al. (2023) and Pauls et al. (2024) detect that these trees are at a different height than their surrounding, they fail to correctly estimate the height. Our model is able to detect those patches and accurately predict its height.\nAs our model is applied to 2019-2022 data, we can observe temporal dynamics such as deforestation, identifying where trees have been cut down. However, mapping minor tree growth is challenging due to the short time frame and the slow natural growth rate of trees. In contrast, in forest plantation areas where fast-growing tree species are actively managed, significant growth can be observed easier because the acceleration in growth outweighs the uncertainty in predictions."}, {"title": "5. Conclusion", "content": "We presented a novel approach for generating high-resolution, large-scale temporal tree canopy height maps using a 3D U-Net model. By utilizing a full 12-month Sentinel-2 imagery time series, our approach avoids the information loss of median composites and captures essential seasonal variations and geolocation shifts. Trained on GEDI LiDAR data, our model produces a highly accurate 10m resolution tree canopy height map of Europe for the years 2019 to 2022. Our model outperforms existing state-of-the-art models, achieving significantly lower errors. Notably, it drastically improves accuracy for tall trees, essential for precise biomass estimation and carbon stock assessments. Our temporal maps capture forest dynamics, such as deforestation and growth patterns, offering valuable insights for forest monitoring and ecological analyses. The publicly released pipeline and tree canopy height maps will support further research and inform decision-making in forest management and conservation. Our work underscores the importance of multi-temporal satellite data in enhancing the accuracy and reliability of large-scale forest assessments."}, {"title": "Impact Statement", "content": "This study significantly advances forest monitoring by leveraging machine learning to incorporate temporal dynamics, resulting in the creation of tree canopy height maps over a four-year span (2019-2022) on a continental scale. Forests play a vital role in mitigating climate change by absorbing nearly half of human-generated carbon dioxide emissions. However, they are increasingly at risk due to climate change and human activities such as deforestation and land degradation. In support of global initiatives like the United Nations' Sustainable Development Goals (SDGs), the Bonn Challenge, and the Glasgow Declaration, effective forest management and conservation are crucial for climate adaptation and mitigation. Our approach significantly benefits the estimation of above-ground biomass, a critical component among the 55 essential climate variables (ECVs). A key improvement in this research is the enhanced detection of large trees, which is critical due to the power-law relationship between tree height and biomass. This advancement allows for more accurate biomass estimation, essential for assessing carbon stocks. Additionally, precise monitoring is crucial for validating carbon credit investments in the voluntary carbon market, ensuring the effectiveness and sustainability of forest growth projects while reducing potential leakage effects."}, {"title": "A. Data Handling Details", "content": "Handling big amounts of data is a challenge. To aid data handling and still having optimal projection accuracy, we downloaded, stored and preprocessed all data in the original Sentinel-2 tiling system. The tiling system is based on the UTM projections system but divides every UTM zone in 100 km \u00d7 100 km tiles. Each UTM zone has its own projection.\nSentinel-1 images are created with Google Earth Engine (GEE) directly in their corresponding projection and compressed with LZW (the standard compression in GEE). Sentinel-2 images are distributed via the Copernicus AWS via a .SAFE-archive format. We extract all needed bands in JPEG2000-format and build virtual raster files for combined access. JPEG2000 has the big advantage of being an extremely storage efficient, yet applies the compression on image-level, so windowed access is not possible.\nEach sample of the final dataset is stored in a zip-compressed archive to further save storage.\nWhen doing inference, directly loading the entire tile and doing inference is not feasible, as data loading takes a long time due to the need to be decompressed. As this would lead to long GPU idle times, we use a different approach. We seperate the workload onto CPU- and GPU-nodes, where CPU-nodes load the data from the slow storage, decompress it multi-threaded and save it in a binary format on fast-access storage. The GPU-node then loads the fast binary and does inference. For each GPU-worker we start multiple CPU-workers to remove GPU idle time."}]}