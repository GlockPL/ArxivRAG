{"title": "Exploring Fine-tuned Generative Models for Keyphrase Selection: A Case Study for Russian", "authors": ["Anna Glazkova", "Dmitry Morozov"], "abstract": "Keyphrase selection plays a pivotal role within the domain of scholarly texts, facilitating efficient information retrieval, summarization, and indexing. In this work, we explored how to apply fine-tuned generative transformer-based models to the specific task of keyphrase selection within Russian scientific texts. We experimented with four distinct generative models, such as ruT5, ruGPT, mT5, and mBART, and evaluated their performance in both in-domain and cross-domain settings. The experiments were conducted on the texts of Russian scientific abstracts from four domains: mathematics & computer science, history, medicine, and linguistics. The use of generative models, namely mBART, led to gains in in-domain performance (up to 4.9% in BERTScore, 9.0% in ROUGE-1, and 12.2% in Fl-score) over three keyphrase extraction baselines for the Russian language. Although the results for cross-domain usage were significantly lower, they still demonstrated the capability to surpass baseline performances in several cases, underscoring the promising potential for further exploration and refinement in this research field.", "sections": [{"title": "1 Introduction", "content": "Identifying and extracting keyphrases from a document is an essential task in natural language processing aimed at summarizing the crucial information presented in the source document. Keyphrases facilitate retrieval of documents from large text corpora and show their efficacy in various tasks, such as text summarization and content analysis [28,44]. The two main approaches to keyphrase selection are extracting keyphrases directly from the text and generating keyphrases based on the semantics of the text through its generalization and paraphrasing [23]. In the second case, the task of keyphrase selection is similar to the task of abstractive text summarization [5].\nThe majority of widely used approaches to keyphrase extraction are based on unsupervised identifying the most significant words and phrases from the text,"}, {"title": "2 Related Work", "content": "Most widely used approaches to keyphrase selection are based on identifying the most significant words and phrases that give meaning to text content using unsupervised learning principles. In this case, the task is commonly referred to as keyphrase extraction [30]. In particular, keyphrase extraction approaches cover statistic-based methods, such as RAKE [32] and YAKE! [3], and graph methods, such as TopicRank [2]. Some of the keyphrase extraction methods belong to supervised approaches, for example, KEA [46]), which is based on the Na\u00efve Bayes classifier.\nAnother possible problem statement of keyphrase selection is keyphrase generation. In contrast to keyphrase extraction, generative approaches can produce keyphrases that are absent in a source text [4]. The authors of [23] proposed the CopyRNN model that comprises an encoder, which forms a hidden representation of the source text, and a decoder, which produces keyphrases using that representation. Later, more powerful architectures were proposed [9,50]. The scholars also experimented with various training paradigms, including reinforcement learning [7] and adversarial training [42]."}, {"title": "2.2 Keyphrase Selection for Russian Texts", "content": "A number of studies have investigated the use of unsupervised algorithms for keyphrase extraction from Russian texts. In particular, the authors of [34,37] utilized the RAKE algorithm for analyzing Russian texts from various domains. The paper [24] provides a comparison of several algorithms, including TF-IDF, YAKE!, RAKE, KeyBERT, and others, on a set of heterogeneous documents containing news, scientific, and literary texts. The work [13] presents a large-scale comparison of keyphrase extraction approaches for Russian popular science texts. In [26], the dataset for keyphrase selection from Russian texts from mathematical and computer science domains is presented. The authors also compare several common unsupervised approaches for keyphrase extraction. In [45], the keyphrases for Russian scientific texts are determined using a Latent Dirichlet allocation topic model.\nTo date, some studies explored supervised approaches for selecting keyphrases for Russian texts. The papers [37,36] investigate the effectiveness of the KEA algorithm for Russian texts. The paper [15] proposes an approach combining traditional unsupervised algorithms and neural networks. The approach is evaluated on a multilingual corpus, including Russian-language texts. In [29], the authors present a neural model for keyphrase extraction that calculates features from traditional statistical metrics and new state-of-the-art sentence embeddings. The authors of [11] fine-tune a multilingual text-to-text transformer (mT5) [48] for generating keyphrases for scientific texts from mathematical and computer science domains. For some metrics, the fine-tuned model outperformed unsupervised baselines.\nA brief review of the related work has shown that pre-trained language models have great potential for the task of keyphrase selection. The majority of existing"}, {"title": "3 Method", "content": "To answer research questions, we collected scientific texts and keyphrases for four different domains. The texts were divided into train and test sets. We fine-tuned several transformer-based models for generating keyphrases using train sets. The results of generative models were compared with the results of common baselines for keyphrase extraction in terms of three evaluation metrics."}, {"title": "3.1 Data", "content": "We utilized the Math&CS dataset [25] that consists of abstracts and their corresponding keyphrases collected from the online resources MathNet and Cyberleninka and described in [26]. Math&CS contains texts from mathematical and computer science domains. To perform cross-domain evaluation, we collected 22500 pairs of abstracts and corresponding keyphrases from Cyberleninka for three domains, namely, historical, medical, and linguistic.\nThe characteristics of data are presented in Table 1. The average numbers of tokens and sentences are defined using the NLTK package [1]. The percentage of absent keyphrases means the proportion of keyphrases from the list of keyphrases that do not appear in the corresponding abstract text."}, {"title": "3.2 Models", "content": "We used four pre-trained transformer-based models. The list of the models and their parameters are given in Table 2."}, {"title": "3.3 Baselines", "content": "We compared the results of generative models with the results of the following baselines.\n\nRuTermExtract [35], a package that determines important terms within a given piece of content using PyMorphy2 [16] for morphological analysis.\nYAKE! [3], an unsupervised method leveraging statistical attributes of text to select the most relevant keyphrases. We used the implementation of YAKE! provided by keyphrases.mca.nsu.ru via API.\nKeyBERT [12], a method employing document and word embeddings generated by BERT [10], along with cosine similarity, to identify the sub-phrases within a document that closely resemble the document as a whole. For KeyBERT, we utilized ruBERT-base-cased [18] as a basic model."}, {"title": "3.4 Evaluation Metrics", "content": "To evaluate the results, we used the following metrics: BERTScore [49], ROUGE-1 [20], and the full-match F1-score. We have chosen several diverse metrics since"}, {"title": "4 Results and Discussion", "content": "To answer RQ1, we compared the results of baselines and generative models. The scores are given in Tables 3 and 4. For each baseline model, we calculated BERTScore, ROUGE-1, and Fl-score at the top 5, 10, and 15 keyphrases.\nAmong baselines, the best results for test data were demonstrated by RuTermExtract. The highest BERTScore and ROUGE-1 were obtained for Math&CS (75.97% and 26.49%). The highest F1-score was achieved for the medical domain (11.35%). Other scores are provided in Table 3. The best results for each domain are shown in bold.\nTable 4 demonstrates the in-domain results of generative models. In this case, the models were fine-tuned and tested on the same domain. The values that outperformed the corresponding scores achieved by baselines are shown in bold. The best results for each domain across all models are underlined. In most cases, generative models outperformed RuTermExtract in terms of BERTScore (+4.78% medical, +3.06% linguistic, +2.5% - Math&CS, +2.22% - historical). mBART showed the highest ROUGE-1 scores (8.96% - medical, 3.78% linguistic, 3.08% - Math&CS, +2.68% historical). Besides, ruGPT and mT5 outperformed RuTermExtract in terms of ROUGE-1 for the medical domain. In half of the cases, generative models showed a higher F1-score than RuTermExtract. But at the same time, mBART demonstrated superior F1-score for all domains (+12.16% in comparison with RuTermExtract \u2013 medical, +7.24% - linguistic, +5.83% - Math&CS, +4.85% - historical). In general, mBART achieved the best scores across all considered domains.\nTable 5 presents the main characteristics of generated keyphrases, namely, the average number of generated keyphrases per text and abstractness. Abstractness shows the proportion of generated keyphrases that do not appear in the corresponding source text.\nAs can be seen from the table, ruGPT and mBART more accurately preserved the average number of keyphrases per text from the train set (see Table"}, {"title": "5 Conclusion", "content": "In this work, we explored the effectiveness of fine-tuned generative transformer-based models in the task of keyphrase selection within Russian scientific texts. We described the results for generating lists of keyphrases and compared the performance of generative models with the performance of several unsupervised keyphrase extraction methods. In our experiments, generative models often demonstrated quality exceeding baselines. Moreover, the best results across all metrics and domains were achieved using the mBART model. The performance of generative models in cross-domain settings was expectedly lower. However, in several cases, cross-domain models also outperformed the baselines. The possible advantages of generating keyphrases using pre-trained language models is"}]}