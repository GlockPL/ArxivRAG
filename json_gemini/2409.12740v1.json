{"title": "HLLM: Enhancing Sequential Recommendations via Hierarchical Large Language Models for Item and User Modeling", "authors": ["Junyi Chen", "Lu Chi", "Bingyue Peng", "Zehuan Yuan"], "abstract": "Large Language Models (LLMs) have achieved remarkable success in various fields, prompting several studies to explore their potential in recommendation systems. However, these attempts have so far resulted in only modest improvements over traditional recommendation models. Moreover, three critical questions remain under-explored: firstly, the real value of LLMs' pre-trained weights, often considered to encapsulate world knowledge; secondly, the necessity of fine-tuning for recommendation tasks; lastly, whether LLMs can exhibit the same scalability benefits in recommendation systems as they do in other domains. In this paper, we propose a novel Hierarchical Large Language Model (HLLM) architecture designed to enhance sequential recommendation systems. Our approach employs a two-tier model: the first Item LLM extracts rich content features from the detailed text description of the item, while the second User LLM utilizes these features to predict users' future interests based on their interaction history. Extensive experiments demonstrate that our method effectively leverages the pre-trained capabilities of open-source LLMs, and further fine-tuning leads to significant performance boosts. Additionally, HLLM achieves excellent scalability, with the largest configuration utilizing 7B parameters for both item feature extraction and user interest modeling. Moreover, HLLM offers excellent training and serving efficiency, making it practical in real-world applications. Evaluations on two large-scale datasets, PixelRec and Amazon Reviews, show that HLLM achieves state-of-the-art results, outperforming traditional ID-based models by a wide margin. In online A/B testing, HLLM showcases notable gains, validating its practical impact in real-world recommendation scenarios.", "sections": [{"title": "Introduction", "content": "The recommendation algorithm is a classic yet complex problem that requires understanding user interests to predict future behaviors across various items. The key to effective recommendation lies in accurately modeling both item and user features. Currently, mainstream approaches are predominantly ID-based, converting items and users into IDs and creating corresponding embedding tables for encoding."}, {"title": "Related Work", "content": "Traditional Recommender Systems\nTraditional Recommender Systems predominantly rely on ID-based embeddings, and how to design feature interac-tions is an important topic. DeepFM models low-order feature interactions with FM and models high-order feature interactions with DNN. DCN can model higher-order interactions by explicitly applying feature crossing at each layer. Besides, some researchers make efforts to model user interests from their historical behavior. For instance, DIN and DIEN introduce attention mechanisms to capture user's diverse interests from historical behaviors. Inspired by transformer, SASRec applies self-attention mechanisms to sequential recommendation. CLUE and HSTU demonstrate that models with parameter counts within hundreds of millions adhere to the scaling law. Some works have also introduced content features into recommendation mod-els, showing certain advantages in generalization.\nRecommendation with Language Models\nThe success of LLMs has attracted many researchers to ex-plore their applications in recommendation systems. These explorations can be categorized into three types. Firstly, LLMs are used for summarizing or supplementing infor-mation about users or items. For example, RLMRec develops a user/item profiling paradigm em-powered by LLMs, and aligns the semantic space of LLMs with the representation space of collaborative relational sig-nals through a cross-view alignment framework. LLMs are also employed to generate augmented training signals for coldstart items. Secondly, some works"}, {"title": "Method", "content": "In this section, we first introduce the problem formula-tion, and then propose Hierarchical Large Language Model (HLLM) with a detailed explanation of how to adapt pre-trained large language models to recommendation systems, including item feature extraction and user interest modeling. Finally we discuss how to align HLLM with the objectives of recommendation systems, thereby significantly enhancing its performance on recommendation tasks."}, {"title": "Problem Formulation", "content": "We study the task of sequential recommendations, formu-lated as: Given a user $u \\in U$, a sequence of user $u$'s his-torical interactions $U = \\{I_1, I_2, . . ., I_n\\}$ in chronological order, predict the next item $I_{n+1}$, where $n$ is the length of $U$ and $I \\in I$. Each item $I$ has its corresponding ID and text information (e.g. title, tag, etc.), but the method proposed in this paper uses only the text information."}, {"title": "Hierarchical Large Language Model Architecture", "content": "Currently, a considerable number of LLM-based recommen-dation models flatten users' historical behaviors into plain text inputs for the LLM. This results in very long input sequences, and due to the self-attention module in LLMs, the complexity grows quadratically with the length of the input sequence. To reduce the burden of user sequence modeling, we adopt a hi-erarchical modeling approach called the Hierarchical Large Language Model (HLLM) that decouples item modeling from user modeling, as shown in Figure 1. Specifically, we first extract item features using the Item LLM, compressing the complex text descriptions into an embedding represen-tation. Then, we model the user profile based on these item features with the User LLM. Additionally, to ensure better compatibility with pre-trained LLMs and to enhance scala-bility, we introduce minimal structural changes and design simple yet efficient training objectives. The following is a detailed introduction to item and user modeling.\nItem LLM is proposed to extract item features. It takes as input the text description of an item and outputs an embedding representation. LLMs have demonstrated excel-lent performance in text comprehension, but their use has mostly been limited to text generation scenarios, with few works using them as feature extractors. Inspired by previ-ous works , a special token [ITEM] is added at the end of the item's text descrip-tion to extract features.\nSpecifically, as shown in Figure 1, for Item I we first flat-ten its corresponding textual attributes into the sentence T, and prepend it with a fixed prompt. After passing through the LLM tokenizer, we additionally append a special token [ITEM] at the end, thus the input token sequence for the Item LLM can be formulated as $\\{t_1, t_2,..., t_m,[\\text{ITEM}]\\}$ where m represents the length of text tokens. The hidden state from the last layer corresponding to the special token [ITEM] is considered as the item embedding.\nUser LLM is designed to model user interests which is another key aspect of recommendation systems. The origi-nal user history sequence $U = \\{I_1, I_2, . . ., I_n\\}$ can be trans-formed into a historical feature sequence $\\{E_1, E_2,..., E_n\\}$"}, {"title": "Training for Recommendation Objectives", "content": "Existing LLMs are all pre-trained using general natural lan-guage corpora. Although they possess a wealth of world knowledge and strong reasoning abilities, there remains a considerable gap between their capabilities and those re-quired by recommendation systems. Following the best practices of other works, we adopt supervised fine-tuning on top of the pre-trained LLM.\nRecommendation systems can be divided into two cate-gories, generative and discriminative recommendation. It is noteworthy that the proposed HLLM architecture is appli-cable to both types, requiring only appropriate adjustments to the training objectives. The following sections provide a detailed introduction to the training objectives for both cate-gories.\nGenerative Recommendation Recent work has provided a successful generative recommendation solution, including both retrieval and ranking. Our approach differs from it in two major ways: the model architecture is upgraded to large language models with pre-trained weights, and the input features are changed from IDs to text-input LLM features. The above differences have minimal impact on the training and serving strategies, therefore, we largely follow approaches proposed in .\nFor the training objective of generative recommendation, next item prediction is adopted, which aims to generate the embedding of the next item given the embeddings of the pre-vious items in the user's history. Specifically, the InfoNCE loss is used during training. For any prediction $\\hat{E}$ in the output sequence of the User LLM, the positive sample is $E_i$, and the negative samples are ran-domly sampled from the dataset excluding the current user sequence. The loss function can be formulated as:\n$L_{gen} = -\\sum_{j=1}^{b}\\sum_{i=2}^{n}log\\frac{e^{s(E_{j,i}, \\hat{E}_{j,i})}}{e^{s(E_{j,i}, \\hat{E}_{j,i})} + N e^{s(E_{j,i}, \\hat{E}_{j,i,k})}}$\nwhere $s$ is the similarity function with a learnable temper-ature parameter, $E_{j,i}$ denotes the i-th item embedding pro-duced by the Item LLM in the j-th user's history interaction and $\\hat{E}$ denotes the i-th item embedding predicted by the User LLM for the j-th user. N is the number of negative samples, $E_{j,i,k}$ represents the k-th negative embedding of $\\hat{E}$. b represents the total number of users within the batch, n is the length of user history interactions.\nDiscriminative Recommendation Since discriminative recommendation models still dominate in the industry, we also present an application scheme for HLLM under dis-criminative recommendation models. The optimization ob-jective of discriminative models is to judge, given a user se-quence U and a target item $I_{tgt}$, whether the user is interested in the target item (e.g., by clicking, liking, purchasing, etc.).\nAs shown in Figure 2, there are two User LLM variants for discriminative recommendation, while keeping the Item LLM unchanged. Early fusion appends the target item em-bedding $E_{tgt}$ to the end of the user's historical sequence, then produces a high-order cross feature through User LLM, and finally inputs this cross feature into the prediction head to generate the final logits. Late fusion, on the other hand, first uses the User LLM to extract user features, which are inde-pendent of the target item, in a manner similar to the Item LLM feature extraction. A special token [USER] is added to the end of the user sequence to extract user representa-tion. The user embedding and the target item embedding are then input together into the prediction head to predict the fi-nal logits. Early fusion, due to its deep integration of user interests and the target item, tends to perform better but is challenging to apply simultaneously across numerous candi-dates; conversely, late fusion is more efficient since different candidates share the same user features, but typically sees a performance decline.\nThe training objective of discriminative recommendation is usually a classification task, such as predicting whether a user will click, etc. For the binary classification example, the training loss is as follows:\n$L_{cls} = -(y \\cdot log(x) + (1 - y) \\cdot log(1 - x))$\nwhere y denotes the label of the training sample and x de-notes the predicted logit.\nEmpirically, next item prediction can also be used as an auxiliary loss in discriminative models to further enhance performance. Hence, the final loss can be formulated as fol-lows:\n$L_{dis} = \\lambda L_{gen} + L_{cls}$\nwhere $\\lambda$ controls the weight of the auxiliary loss."}, {"title": "Experiments", "content": "In this section, we first introduce the basic experimental set-tings, and then numerous experiments are conducted to ad-dress the following research questions:\nRQ1: Does the general pre-training of the LLM and the fine-tuning with recommendation objectives improve the fi-nal recommendation performance?\nRQ2: Does HLLM have good scalability?\nRQ3: Are the advantages of HLLM significant compared with other state-of-the-art models?\nRQ4: How does the training and serving efficiency com-pare with ID-based models?\nFinally, we demonstrate how to deploy HLLM in online scenarios and achieve real-world benefits.\nDatasets and Evaluation Setup\nFor offline experiments, we evaluate HLLM on two large-scale datasets: PixelRec (including three subsets: 200K, 1M,and 8M) , and Amazon Book Reviews(Books). Consistent with previousworks , we adopt thesame data preprocessing and evaluation protocols to ensurea fair comparison. A more detailed analysis of these datasetsafter preprocessing is presented in Table 1 and Figure 5.We utilize a leave-one-out approach to split the data intotraining, validation, and testing sets. Performance is mea-sured using the metrics Recall@K (R@K) and NDCG@K(N@K). All open-source datasets are employed solely fortraining and evaluating in offline experiments.\nBaselines and Training\nFor baselines, we use two ID-based sequential rec-ommenders SASRec , andHSTU . They are all aimed at industrialapplications and boast state-of-the-art performance.\nFor offline experiments, the generative recommendationis used to stay consistent with other methods. For the onlineA/B test, discriminative recommendation is used to betteralign with the online system1.\nIn HLLM-1B, we use TinyLlama-1.1B for both Item LLM and User LLM. Correspondingly,in HLLM-7B, we utilize Baichuan2-7B forboth. Due to resource constraints, HLLMs are trained only 5epochs on PixelRec and Amazon Reviews while other mod-els are trained 50 and 200 epochs, respectively. The learningrate is set to le-4. Each item's text length is truncated to amaximum of 256. On PixelRec, following PixelNet , we utilize a batch size of 512. The maximumsequence length is set to 10, and the ratio of positive to neg-ative samples is 1:5632. On Books, we utilize a batch size of128, set a maximum sequence length of 50, and the numberof negative samples is 512.\nFor a fair comparison, we also implemented SASRec-1B(replacing its network structure with TinyLlama-1.1B) andHSTU-1B, which uses the same hidden size and numberof layers as TinyLlama-1.1B but has only 462M parametersdue to the elimination of the traditional FFN.\nPre-training and Fine-tuning (RQ1)\nAs clearly seen from Table 2, pre-trained weights are bene-ficial for HLLM, including both item feature extraction anduser interest modeling. Furthermore, as shown in Table 3,the performance is positively correlated with the number ofpre-trained tokens, indicating that the quality of pre-trainedweights also impacts the recommendation task. However,supervised fine-tuning (SFT) on conversation data can resultin slight negative effects, probably because world knowl-edge is primarily acquired during the pre-training stage, andSFT mainly enhances instruction-following abilities, whichdo not aid in recommendation tasks .\n1 Experiments demonstrated that most conclusions drawn fromthe academic dataset still hold true on large-scale industrial bench-marks."}, {"title": "Conclusion", "content": "In this paper, we propose a novel Hierarchical Large Lan-guage Model (HLLM) architecture designed to enhance se-quential recommendations. HLLM leverages LLMs to ex-tract item features and model user interests, effectively in-tegrating pre-training knowledge into the recommendation system, and it is proved that fine-tuning with recommenda-tion objectives is essential. HLLM exhibited excellent scal-ability with larger model parameters. Experiments demon-strated that HLLM outperforms traditional ID-based mod-els, achieving state-of-the-art results on academic datasets. Real-world online A/B testing further validated HLLM's practical efficiency and applicability, marking a significant advancement in the field of recommendation systems."}, {"title": "A More Experiments on Academic Datasets", "content": "Textual Input Length and Richness of Item LLM\nBy default, we input all types of text information with a length of 256. Here, we conduct ablation experiments on text length and richness. Table 9 shows that the text con-tent has a significant impact on the final performance. Richer text content and longer text lengths allow the Item LLM to extract more detailed item features, better differentiate be-tween items, and more effectively aid the User LLM in mod-eling user interests.\nMethod of Item LLM Feature Extraction\nTo enable LLMs trained on next token prediction to have feature extraction capabilities, we add a special token [ITEM] at the end of the text input. Another feasible fea-ture extraction approach is to take the average of the hid-den states from the final layer of the LLM to represent the features of the entire sentence. Table 10 shows the compari-son results of these two methods. As can be seen, using the [ITEM] token is better than mean pooling.\nSequence Length of User LLM\nWe explore the impact of input sequence length of User LLM on HLLM's recommendation performance in Ta-ble 11. Similar to other sequential recommenders, HLLM can also benefit from expanding the length of the input se-quence. Although the table shows only modest performance gains with increasing sequence length, we suspect this is likely because user sequence lengths are generally quite short in the academic dataset as shown in Figure 5. As shown in Appendix B, in the real-world industrial systems, where"}, {"title": "Compatibility with ID-based Features", "content": "In the previous sections, we primarily modeled item and user features based on the textual descriptions of items. Most current recommendation systems, however, still rely on ID features, including not only Item IDs but also features like actions, timestamps, and item categories in ID form. Here, we present a compatibility solution for integrating HLLM with ID features, and demonstrate that complementary ID features, when combined with item descriptions, can indeed bring significant improvements to HLLM, further highlight-ing its application value in industrial environments.\nHere, we choose the raw item IDs and timestamps as ID features for validation. The item IDs are transformed into id embeddings through an embedding lookup table. The behav-ior's timestamp is first split into specific year, month, day, hour, minute, and second components, obtaining the times-tamp embedding as Algorithm 1. We perform sum pooling with the ID features and item LLM embeddings before in-putting them into the User LLM. The prediction target dur-ing training remains the item embedding extracted by the Item LLM, and the experimental results are shown in Ta-ble 12. The introduction of item IDs actually results in a slight decrease in performance, likely because the item IDs do not provide incremental information beyond what is al-ready captured by the textual descriptions, which compre-hensively describe the item's characteristics and are suffi-ciently extracted by the Item LLM. However, the improve-ment resulting from the introduction of timestamps is very pronounced, as timestamps complement the textual descrip-tions. This also demonstrates that our method can be com-patible with ID-based features."}, {"title": "B Scaling Up of HLLM on Industrial Dataset", "content": "More extensive experiments are conducted on a large-scale industrial dataset to evaluate the scalability of HLLM.\nDouyin has a vast number of users and recommendation candidates, with extensive records of user behavior. We con-struct a dataset comprising 30 million samples from the past 3 years' logs. Each sample includes only the user's histor-ical click sequence, the target item, and a label indicating whether the item was clicked or not. We validate the effec-tiveness of HLLM in a discriminative recommendation sys-tem, using AUC as the evaluation metric, and verifying scal-ability from two aspects: the sequence length of User LLM, and the parameters of both Item LLM and User LLM.\nSequence Length of User LLM\nThe length of user behavior sequences in the industrial dataset is shown in Figure 5. And table 13 shows the im-pact of user sequence length, with HLLM's performance steadily increasing as the sequence length grows. This illus-trates HLLM's substantial potential in modeling users with longer sequences.\nParameters of Item LLM and User LLM\nTable 14 illustrates the impact of the parameters of HLLM in industrial scenario. For both Item LLM and User LLM, AUC consistently increases with the growth in the number of parameters."}]}