{"title": "Unsupervised Attention-Based Multi-Source Domain Adaptation Framework for Drift Compensation in Electronic Nose Systems", "authors": ["Wenwen Zhang", "Shuhao Hu", "Zhengyuan Zhang", "Yuanjin Zheng", "Qi Jie Wang", "Zhiping Lin"], "abstract": "Continuous, long-term monitoring of hazardous, noxious, explosive, and flammable gases in industrial environments using electronic nose (E-nose) systems faces the significant challenge of reduced gas identification accuracy due to time-varying drift in gas sensors. To address this issue, we propose a novel unsupervised attention-based multi-source domain shared-private feature fusion adaptation (AMDS-PFFA) framework for gas identification with drift compensation in E-nose systems. The AMDS-PFFA model effectively leverages labeled data from multiple source domains collected during the initial stage to accurately identify gases in unlabeled gas sensor array drift signals from the target domain. To validate the model's effectiveness, extensive experimental evaluations were conducted using both the University of California, Irvine (UCI) standard drift gas dataset, collected over 36 months, and drift signal data from our self-developed E-nose system, spanning 30 months. Compared to recent drift compensation methods, the AMDS-PFFA model achieves the highest average gas recognition accuracy with strong convergence, attaining 83.20% on the UCI dataset and 93.96% on data from our self-developed E-nose system across all target domain batches. These results demonstrate the superior performance of the AMDS-PFFA model in gas identification with drift compensation, significantly outperforming existing methods.", "sections": [{"title": "I. INTRODUCTION", "content": "An electronic nose (E-nose) system mimics the mammalian olfactory system to identify components in mixed odors [1]\u2013[3]. However, gas sensor drift poses a significant challenge, undermining long-term identification accuracy [4]. Efforts to address this focus on developing advanced gas sensors with better resistance to aging, poisoning, and environmental changes [5]. Despite these advancements, implementing them in practical applications remains time-consuming and costly.\nThe prevailing practice at most industrial sites is to procure established commercial gas sensors directly for on-site monitoring. Consequently, more efforts are directed towards developing the novel gas identification models, incorporating drift compensation techniques to process signals from gas sensor arrays [6]. For instance, in light of the remarkable accomplishments of domain adaptation (DA) within the field of transfer learning, some researchers are now channeling their efforts into the development of novel DA models designed to effectively address the challenge posed by gas sensor drift. For example, to investigate the cross-domain learning capability of extreme learning machines (ELM), Zhang et al proposed the domain adaptation extreme learning machine (DAELM) method [7] to develop robust classifiers for compensating drift and identifying gases in E-nose systems. This is achieved by utilizing a limited quantity of labeled data from the target domain and a single source domain. However, in real-world scenarios, annotated gas sensor data can originate from multiple source domains. Moreover, the label for the target domain is frequently unspecified or unknown.\nResearchers have developed novel models that leverage labeled data from multiple source domains to address tasks such as classification and fault diagnosis with unlabeled target domain data [8]\u2013[10]. However, most existing multi-source domain models focus on extracting invariant features across domains [11], [12] while neglecting unique source-target domain features. To improve drift suppression in E-nose systems, our study introduces the unsupervised attention-based multi-source domain shared-private feature fusion adaptation (AMDS-PFFA) model. This model leverages labeled data from multiple source domains and utilizes shared-private feature fusion to effectively counteract gas sensor drift while minimizing discrepancies among classifiers.\nWe verified our approach using both the gas sensor array drift dataset from the Biocircuits Institute at the University of California, Irvine (UCI) [13] and data collected over 30 months with a customized E-nose system designed in our laboratory. The main contributions of our work are summarized as follows:\n1) Drawing inspiration from the shortcut architecture of Residual Networks (ResNet), our study presents a novel multi-source domain shared-private feature fusion framework that integrates unique private features from each source-target pair. This approach overcomes the common limitation of existing multi-source domain adaptation"}, {"title": "II. RELATED-WORKS", "content": "The unsupervised multi-source domain adaptation (MSDA) method addresses the challenge of learning a classifier for an unlabeled target domain by leveraging knowledge from multiple labeled source domains, Currently, a variety of MSDA models are being proposed to improve the target domain task identification accuacy [14]. For example, Chai et al. introduce a multisource-refined transfer network to address fault diagnosis issues under both domain and category inconsistencies [15]. Chen et al have devised a multi-source weighted deep transfer network for open-set fault diagnosis in rotary machinery [10]. This network leverages an open-set adversarial training module and an adaptive weighting learning module, collaboratively constructed to acquire domain-invariant features that are applicable to different machine health conditions."}, {"title": "B. Gas sensor drift compensation", "content": "From a data distribution perspective, drifted data is treated as the target domain, while un-drifted data is considered the source domain [16]\u2013[18]. Current research focuses on finding mappings that align the projections of both clusters in a common space, aiming for distribution consistency. For example, Zhang et al. proposed domain regularized component analysis (DRCA) to enhance distribution alignment and drift adaptation in principal component subspaces [19]. They also developed an unsupervised feature adaptation (UFA)-based transfer learning method to improve drift tolerance in E-noses [20]. Building on this, Yi et al. introduced local discriminant subspace projection (LDSP) [21], extending DRCA by using label information to better separate samples in the latent subspace. Yan et al. proposed domain correction latent subspace learning (DCLSL) [22], which aligns statistical distributions before and after drift while leveraging geometric structure and domain discriminative information. Wang et al. tackled baseline drift in optical E-noses using independent component analysis [23]. Unlike conventional subspace methods, Zhang et al. framed gas sensor drift as a cross-domain recognition problem and introduced cross-domain discriminative subspace learning (CDSL) [24] to address odor recognition challenges .\nYi et al. further advanced subspace learning with a novel discriminative domain adaptation neighborhood preserving (DANP) method [25], bypassing assumptions of specific data distributions like Gaussian. Some researchers have turned to deep learning models, such as Feng et al. introduced an augmented convolutional neural network (ACNN) [26] to continuously address gas sensor drift with high accuracy over extended periods."}, {"title": "III. UNSUPERVISED AMDS-PFFA MODEL FOR GAS IDENTIFICATION WITH DRIFT COMPENSATION", "content": "To effectively utilize labeled gas data from multiple source domains and enhance gas identification accuracy with drift compensation in unlabeled, drifted target domains, an unsupervised attention-based AMDS-PFFA gas identification model framework are proposed for drift counteraction in this work.\nThe overview of the proposed unsupervised AMDS-PFFA model framework for drift compensation is depicted in Fig. 1. It consists of three stages. The detailed description of the model framework and the specific implementation process are as follows:"}, {"title": "1) The first stage - feature extractors", "content": "as illustrated in Fig. 1, consider a set of n labeled source domains, denoted as {$(D_{sj},V_{sj})\\}_{j=1}^{N_s}$, where $N_s$ denotes the number of source domains, corresponding to the variable n as shown in Fig. 1. For each source domain $D_{s_j}$, we have gas sensor array signal features {${x_i}^{s_j}\\}_{i=1}^{|D_{s_j}|} \\in R^d$, and corresponding gas type labels $V_{s_j} = {y_i}^{s_j}\\in R^K$, where $y_i^{s_j}\\in R^K$ with K representing the number of gas types. Each source domain exhibits a distinct data distribution {$p_{s_j}\\}_{j=1}^{N_s}$. Additionally, there is a target domain with unlabeled gas data, denoted as $D_t$, where $D_t = {x_i^t\\}_{i=1}^{|D_t|}$. The data distribution of the target domain is $p_t$ and differs from the source domain distributions, i.e., $p_t \\neq {p_{s_j}\\}_{j=1}^{N_s}$. In the first stage, the model includes n external private feature extractors for each source-target domain pair and one common feature extractor. This common feature extractor is cascaded with n internal private feature extractors, one for each source-target domain pair. The external private feature extractors are denoted as $G_1, ..., G_n$, the common feature extractor as S, and the internal private feature extractors as $P_1, ..., P_n$.\n(a) Shared feature extractor cascaded with n internal private feature extractors: the shared feature extractor S maps all domains into a unified feature space to extract common features across them. Given gas sensor array signal features $x_i^{s_j}$ from the source domain ($D_{s_j}, V_{s_j}$) and $x_t$ from the target domain $D_t$, the cascaded internal private feature extractors process the common features $S(x_i^{s_j})$ and $S(x_t)$. Each of the n internal private feature extractors then maps its corresponding source-target domain pair into distinct private feature spaces. The final output features from the j-th internal private feature extractor are $F_{in}^{s_j} = P_j(S(D_{s_j}))$ and $F_{in}^t = P_j(S(D_t))$, respectively.\n(b) External private feature extractors: as illustrated in Fig. 1, there are n source-target domain pairs and n corresponding external private feature extractors, labeled $G_1, ..., G_n$. Unlike shared extractors, these do not share weights and are designed to directly capture the private features of each source-target domain pair. Given gas sensor array signal features $x_i^{s_j}$ from source domain ($D_{s_j}, V_{s_j}$) and $x_t$ from target domain $D_t$, the external private feature extractor $G_j$ extracts features $G_j(x_i^{s_j})$ and $G_j(x_t)$ for the source and target domains, respectively. The final output features from the external extractor are expressed as $F_{ex}^{s_j} = G_j(D_{s_j})$ and $F_{ex}^t = G_j(D_t)$.\n(c) Local maximum mean discrepancy LMMD loss: to capture fine-grained information for each gas type across corresponding groups in the source domain $D_{s_j}$ and the target domain $D_t$, we divide the gas data in the source domain into K distinct subdomains, denoted as $D_h$ (where k = 1, ..., K), with each subdomain representing one of the K gas types. Similarly, the target domain is segmented into K subdomains, denoted as $D_t^k$. To align the feature distributions of each gas type within these subdomains, we employ the local maximum mean discrepancy (LMMD) metric [27]. The LMMD between the j-th source domain $D_{s_j}$ and the target domain $D_t$ in the Reproducing Kernel Hilbert Space (RKHS) is estimated as follows:\n$D(P_{s_j},P_t) = \\sum_{k=1}^{K} ||\\frac{1}{M} \\sum_{x_m \\in D_{s_j}^k} \\phi(x_m) - \\frac{1}{N} \\sum_{x_n \\in D_t^k} \\phi(x_n)||^2_H$\nwhere $\\phi(\\cdot)$ denotes a feature mapping function that projects the original samples into the RKHS, while $\\lambda_{m}^{jk}$ and $\\lambda_{t_k}$ are the probability coefficients corresponding to the source domain sample $x_m$ and the target domain sample $x_t$, respectively, both of which belong to gas type k. These coefficients satisfy $\\sum_{m=1}^{M} \\lambda_{m}^{jk} = 1$ and $\\sum_{n=1}^{N} \\lambda_{tk} = 1$, where M and N denote the number of gas sensor array signal samples in the j-th source and target domains, respectively. The weighted sums for gas type k are expressed as $\\sum_{x_m \\in D_{s_j}} \\lambda_{m}^{jk} \\phi(x_m)$ and $\\sum_{x_n \\in D_t} \\lambda_{tk} \\phi(x_n)$. The coefficients $\\lambda_{m}^{jk}$ and $\\lambda_{tk}$ are computed as follows:\n$\\lambda_{m}^{jk} = \\frac{y_{mk}}{\\sum_{(x_n, y_n)\\in D_{s_j}} y_{nk}}$\n$\\lambda_{tk} = \\frac{y_{nk}}{\\sum_{(x_m, y_m)\\in D_t} y_{mk}}$\nfor the labeled samples in the source domain, the known label $y_m^{s_j}$ is directly utilized as a one-hot vector to calculate $\\lambda_{m}^{jk}$ where $y_{mk}$ denotes the k-th entry of $y_m$. Since the AMDS-PFFA framework is unsupervised, direct calculation of Eq. (1) for the unlabeled target domain $D_t$ is not feasible due to the unknown $y_{nk}$. Instead, we employ the output $\\bar{y} = f_j(x)$ from the j-th classifier $C_j$, which provides the probability of assigning x to each of the K classes. The soft prediction $y_{nk}$ is then utilized to calculate $\\lambda_{tk}$, where $f_j(\\cdot)$ is the mapping function of x to the gas type predicted by classifier $C_j$. This allows the utilize of Eq. (1) to calculate the LMMD value. To integrate this with the deep learning network in the AMDS-PFFA framework, the activations generated by gas sensor array signal samples at the l-th layer of the network are denoted {$b_{jl}^{s_j}\\}_{m=1}^M$ and {$b_{tl}^{s_j}\\}_{n=1}^N$ for the j-th source and target domains, respectively. Eq. (1) is then reformulated as:\n$D_i(P_a, P_t) = \\frac{1}{K} \\sum_{k=1}^{K} [(\\frac{1}{M} \\sum_{m=1}^{M} \\lambda_{m}^{jk}b_{jl}^{s_j} b_{jm}^{s_j} )+(\\frac{1}{N} \\sum_{n=1}^{N} \\lambda_{tk}b_{tl}^{s_j} b_{tn}^{s_j} ) \\- 2(\\frac{1}{M} \\sum_{m=1}^{M} \\frac{1}{N} \\sum_{n=1}^{N} \\lambda_{m}^{jk} \\lambda_{tk}(b_{jl}^{s_j}, b_{tl}^{s_j}) )]$\nwhere the kernel k is defined as $k(x_i^{s_j}, x_t) = (\\phi(x_i^{s_j}), \\phi(x_t))$, with $(\\cdot,\\cdot)$ denoting the inner product of vectors. $b_{jl}^{s_j}$ and $b_{tl}^{s_j}$ denote the m-th and n-th sensor array signal samples in the j-th source domain and the target domain, respectively, at the l-th layer of network activation. Eq. (3) is employed to describe the distributions of subdomains within the same category across both source and target domains. The LMMD loss for the $N_s$ external private feature extractors, denoted as $L_{lmmd_1}$, is expressed as follows:\n$L_{lmmd_1} = \\frac{1}{N_s} \\sum_{j=1}^{N_s} D_i(F_{ex}^{s_j}, F_{ex}^t)$\nwhere $F_{ex}^{s_j}$ and $F_{ex}^t$ denote the output features from the external private feature extractor for the source and target domains, respectively."}, {"title": "2) The second stage - feature fusion module", "content": "in the first stage, mapping all domains into a shared feature space may lead to the loss of important private features unique to each source-target domain pair. To address this, we draw inspiration from the shortcut connections in ResNet. In the second stage, we propose utilizing an attention-based feature fusion module to focus on preserving the private feature information specific to each source-target domain pair. This module effectively integrates the private feature outputs from both internal and external private feature extractors. The fused features of the j-th source domain, denoted as $D_{s_j}$, and the corresponding target domain, denoted as $D_{t_j}$, are formulated as follows:\n$D_{s_j} = F(F_{ex}^{s_j}, F_{in}^{s_j}), D_{t_j} = F(F_{ex}^t, F_{in}^t)$\nwhere $F(\\cdot,\\cdot)$ denotes the feature fusion function, while $F_{in}^{s_j}$ and $F_{in}^t$ denote the output features from the internal feature extractors for the source and target domains, respectively. The divergence in data distribution between the fused features of the source and target domains is further reduced through the minimization of the $L_{lmmd_2}$ loss, expressed as follows:\n$L_{immd_2} = \\frac{1}{N_s} \\sum_{j=1}^{N_s} D_i(D_{s_j}, D_{t_j})$"}, {"title": "3) The third stage - gas type classifiers", "content": "this stage comprises $N_s$ gas category classifiers, denoted as {$C_j\\}_{j=1}^{N_s}$. Each classifier $C_j$ is a softmax classifier that receives fused source domain features from the j-th external and internal private feature extractors in the second stage. Each gas classifier employs a cross-entropy loss function. The total cross-entropy loss across the $N_s$ gas category classifiers is defined as:\n$L_{cross} = \\sum_{j=1}^{N_s} E_{x \\sim D_{s_j}} J(C_j(F(P_j(S(x)), G_j(x))), y^{s_j})$\nwhere $J(\\cdot,\\cdot)$ denotes cross-entropy calculation function, and $E_{x \\sim D_{s_j}}$ denotes the expected value taken over samples x drawn from the j-th source domain $D_{s_j}$, reflecting the average cross-entropy loss for these samples, and $y^{s_j}$ denotes the true label for the sample x within the j-th source domain. Since the gas category classifiers are trained on different source domains, their predictions on target samples may yield varying gas identification results for the same target domain. To minimize this divergence, the difference in probability prediction outputs across all classifiers is used as the classifier difference loss. The classifier difference loss between all classifiers is expressed as follows:\n$L_{diff} = \\frac{2}{N_s(N_s-1)} \\sum_{i=1}^{N_s-1} \\sum_{j=i+1}^{N_s} \\sum E_{x \\sim D_{t}} [||C_i(F(P_i(S(x_k)), G_i(x_k))) \\- C_j(F(P_j(S(x_k)), G_j(x_k)))||]$\nwhere $E_{x \\sim D_t}$ denotes the expected value of the function calculated over samples x drawn from the target domain $D_t$, reflecting the average discrepancy between the predictions made by different classifiers for target domain samples. By minimizing Eq. (8), the probability outputs of all classifiers are encouraged to converge, ensuring consistency among their predictions. Ultimately, the predicted gas type for each target domain sample is determined by averaging the outputs of all gas classifiers.\nIn summary, the loss function of the proposed unsupervised AMDS-PFFA framework consists of four components: $L_{lmmd_1}$, $L_{lmmd_2}$, $L_{cross}$, and $L_{diff}$. Minimizing $L_{lmmd_1}$ and $L_{lmmd_2}$ aligns the distribution of gas features within their respective subdomains, enabling the learning of domain-invariant features and private features specific to each source-target domain pair. Minimizing $L_{cross}$ allows the classifier to accurately identify gas types within the source domain, while minimizing $L_{diff}$ ensures consistent convergence in the probability outputs across all classifiers. The total loss function, denoted as $L_{total}$, is therefore formulated as follows:\n$L_{total} = L_{cross} + \\lambda (L_{lmmd_1} + L_{lmmd_2} + \\alpha L_{diff})$\nwhere $\\lambda$ is a configurable coefficient defined as $\\lambda = \\frac{1}{1+e^{-a}}$, and $\\alpha$ can be adjusted based on the experimental data. The adjustment coefficient $\\alpha$ employed in our two real-world data scenarios is provided in Tables II and V, respectively. During model training, the total loss $L_{total}$ is minimized, as shown in Eq. (9), to facilitate gas identification"}, {"title": "B. The specific models and parameters employed in each submodule of the AMDS-PFFA Framework for Drift Compen-sation", "content": "In this work, we developed and implemented the architecture of each unit within the proposed AMDS-PFFA model framework, specifically designed for experimental validation under the condition of having two labeled source domains available at the initial stage of sensor array signal collection. The validation was performed in two real-world scenarios: the UCI drift gas experimental dataset, which covers a 36-month measurement period, and drift data from a gas sensor array collected using our self-developed E-nose systems over a 30-month period. The detailed architecture and parameters of each unit in the AMDS-PFFA framework are illustrated in Fig. 2. A comprehensive description of the architecture and parameters for each internal unit is provided below.\n1) The first stage - feature extractors: as illustrated in Fig. 2, the model parameters are shown in black for the UCI drift data and in blue for the drift experimental data collected by the self-developed E-nose system. The shared feature extractor S is composed of N cascaded multi-head self-attention modules, followed by a two-layer fully connected neural network. For the UCI drift signal data, the first layer has 128 neurons, and the second layer has 128 neurons, while for the self-developed E-nose drift signal data, the first layer has 40 neurons, and the second layer has 32 neurons. This module employs weight-sharing to map all domains into a shared feature space.\nThe internal private feature extractors, $P_1$ and $P_2$, cascaded with the shared feature extractor S, are composed of a 1D-convolutional neural network (1D-CNN). For the UCI drift data, the convolutional layer has a kernel length of 3, a stride of 1, 128 input channels, 64 output channels, and \"same\" padding, producing a feature map of 64@1\u00d71. For the E-nose system drift data, the convolutional layer is configured with a kernel length of 3, a stride of 1, 32 input channels, 16 output channels, \"same\" padding, and outputs a feature map of 16@1\u00d71.\nThe external private feature extractors, $G_1$ and $G_2$, are similarly structured, consisting of a multi-head self-attention transformer followed by a two-layer fully connected neural network. For the UCI drift signal data, the first layer has 128 neurons, and the second layer has 64 neurons, while for the self-developed E-nose system drift signal data, the first layer has 40 neurons, and the second layer has 16 neurons.\n2) The second stage - attentional feature fusion module: In the second phase, we employ an attention-based feature fusion method designed for the characteristics of gas sensor array signals, referred to as iterative attentional feature fusion (iAFF) [28]. This method effectively merges the private feature outputs from both the external and internal private feature extractors. The architecture of the iAFF module and the detailed structure of the multi-scale channel attention module (MS-CAM) it employs are shown in Fig. 3 (a) and (b), respectively. The MS-CAM module includes a channel attention mechanism for global features, denoted as G(\u00b7), and another for local features, denoted as L(\u00b7). The output $X'$ of this module is computed as follows:\n$X' = X \\otimes Q(X) = X \\otimes sig(L(X) + G(X))$\nwhere $Q(\\cdot)$ denotes the input-output mapping function of MS-CAM, $sig(\\cdot)$ refers to the sigmoid function, $\\otimes$ denotes element-wise multiplication, and $\\oplus$ denotes broadcasting addition. The computations for L(X) and G(X) are defined as:\n$L(X) = B (P_2 (B (P_1(X))))$\n$G(X) = B (P_2 (B (P_1 (avg(X)))))$\nwhere avg(.) denotes the global average pooling function, $P_1$ and $P_2$ denotes the first and second layers of point-wise convolution, respectively, and B denotes batch normalization operation. Thus, Formula (10) can be reformulated as:\n$X' = X \\otimes Q(X) = X \\otimes sig (B (P_2 (B (P_1(X)))) \\oplus B (P_2 (B (P_1 (avg(X))))))$\nusing the MS-CAM function $Q(\\cdot)$, the source domain fusion feature $D_{s_j}$, generated by the j-th external private feature $F_{ex}^{s_j}$ and the j-th internal private feature $F_{in}^{s_j}$ after passing through the iAFF module, is given by:\n$D_{s_j} = Q(X_1 + X_2) \\otimes F_{ex}^{s_j} + (1 - Q (X_1 \\oplus X_2)) \\otimes F_{in}^{s_j}$\nwhere The blue dashed arrowed line indicates 1\u2013$Q(X_1 + X_2)$, and the initial integration $X_1 \\oplus X_2$ in Eq. (14) is computed as:\n$X_1 \\oplus X_2=Q(F_{ex}^{s_j} + F_{in}^{s_j}) \\otimes F_{ex}^{s_j} + (1 - Q (F_{ex}^{s_j} + F_{in}^{s_j})) \\otimes F_{in}^{s_j}$\nSimilarly, the target domain fusion feature $D_{t_j}$, created by combining the j-th external private feature $F_{ex}^t$ and the j-th internal private feature $F_{in}^t$ after passing through the iAFF module, is given by:\n$D_{t_j} = Q (X_1 + X_2) \\otimes F_{ex}^t + (1 - Q (X_1 \\oplus X_2)) \\otimes F_{in}^t$\nthe expression for the initial integration $X_1 \\oplus X_2$ in Eq. (16) is:\n$X_1 \\oplus X_2=Q(F_{ex}^t + F_{in}^t) \\otimes F_{ex}^t + (1 - Q (F_{ex}^t + F_{in}^t)) \\otimes F_{in}^t$\nthe input pairs for the iAFF module, namely $F_{ex}^{s_j}$ and $F_{in}^{s_j}$, as well as $F_{ex}^t$ and $F_{in}^t$, and their corresponding fused outputs $D_{s_j}$ and $D_{t_j}$, all have the same data size of $C\\times H \\times W$. For the UCI drift data, this size is 64 \u00d7 1 \u00d7 1, while for our self-developed E-nose system, it is 16 \u00d7 1 \u00d7 1. The parameter r within the MS-CAM module is set to 1 in both cases.\n3) The third stage - gas type classifiers: the gas type classifiers $C_1$ and $C_2$ each comprise a three-layer fully connected neural network. The first layer has neurons corresponding to the number of fused features obtained during the second stage, set at 64 for the UCI drift signal data and 16 for the drift signal from the self-developed E-nose system. The intermediate layer contains 25 neurons for the UCI drift data and 10 neurons for the self-developed E-nose drift data. The output layer has a number of neurons equal to the number of distinct gas types, which is 6 for the UCI drift signal data and 3 for the self-developed E-nose system drift data."}, {"title": "IV. EXPERIMENTAL VALIDATION OF SENOSR SIGNAL DRIFT DATA FROM THE UCI CHEMOSIGNAL LAB", "content": "We first conducted a verification process using the gas sensor array drift dataset compiled by Alexander Vergara and Shankar Vembu from the ChemoSignals Laboratory at the Bio-Circuits Institute, University of California [13]. This dataset spans a 36-month period, from January 2007 to February 2011, and contains 13,910 measurements collected from 16 chemical sensor arrays. These sensors were employed to simulate drift compensation in a discrimination task involving six distinct gases, namely ethanol, ethylene, ammonia, acetaldehyde, acetone, and toluene, each present at varying concentrations. In each experiment, each sensor extracted 8 features that captured both the steady-state and dynamic response processes of the sensor signal. This resulted in a total of 128 features across all 16 sensors, denoted as X = {x}, where $x_i$ denotes an individual feature and |X| = 128 is the total number of features. The 36-month dataset is divided into 10 distinct batches, each corresponding to different time segments. A detailed overview of the gas sensor drift data is provided in Table I. Data labels are typically obtained during the initial stage of data collection. In this study, two labeled datasets from the initial stage, batches 1 and 2, are employed as source domains for experimental validation. These are referred to as source domain n (where n = 1, 2) in Fig. 2."}, {"title": "B. The exprimental settings and results", "content": "The experimental setup for validating the AMDS-PFFA model is as follows: batch 1 and batch 2 serve as source domains, while each batch k (where k = 3,4,...,10) is employed sequentially as the target domain. Performance is evaluated on each target domain, and the results are recorded accordingly.\nTo observe the variations in data distribution across 10 different batches, we utilized the t-distributed stochastic neighbor embedding (t-SNE) method. This technique preserves the local structure of high-dimensional data, ensuring that similar data points remain close after dimensionality reduction. The resulting 2D distributions, derived from reducing the original 128-dimensional data, are shown in Fig. 4 (a)-(j). From a global perspective, significant differences can be observed between the data distributions of source domains 1 and 2 and those of the target domains, with these differences becoming more pronounced over time. Locally, the distribution of different gas types varies notably across batches, with the data becoming increasingly dispersed as time progresses. This drifting behavior is both irregular and unpredictable, causing a substantial decline in the accuracy of the gas identifier trained on the initial labeled batch when applied to later drifted batches, often rendering it ineffective.\nThe key parameters of the AMDS-PFFA model employed in the experimental setup are described in Table II. The term \"layers of S, G1, and G2\" refers to the number of multi-head self-attention modules within the shared feature extractor S and the external private feature extractors G1 and G2. The experimental procedure is as follows: as shown in Fig. 2, batches 1 and 2 are utilized as source domains, while each"}, {"title": "C. Convergence study of the AMDS-PFFA model", "content": "To demonstrate the convergence of the proposed AMDS-PFFA model within a limited number of training epochs, we recorded the accuracy and loss curves for each experiment, monitoring their changes as the number of epochs increased. The accuracy and loss curves for target domains 3 through 10 are presented in Fig. 6 (a) through (h), respectively. Generally, the accuracy and loss curves for each target domain, with the exception of batch 8, consistently converge and reach a relatively stable state within approximately 200 epochs. Although the curves for target domain batch 8 exhibit minor oscillations before epoch 400, they ultimately stabilize after 420 epochs of training. Overall, the experimental results confirm the robust convergence of the AMDS-PFFA model."}, {"title": "V. EXPERIMENTAL VALIDATION OF SENSOR SIGNAL DRIFT DATA FROM A SELF-DEVELOPED E-NOSE SYSTEM", "content": "To further demonstrate the capability of the proposed unsupervised attention-based AMDS-PFFA model in mitigating drift and enhancing gas identification accuracy, we fabricated a custom E-nose system in our laboratory. The custom-designed E-nose system and the gas sensor array with a 8-channel 12-bit A/D signal acquisition board are illustrated in Fig. 7 (a) and (b), respectively. We selected toxic, harmful, flammable, and explosive gases, specifically CO, H2, and mixed gases of CO and H2, for target identification. In accordance with these target gas, we selected 8 distinct gas sensors including Figaro's tgs813, tgs2611, tgs2610, tgs2620, tgs2600 and tgs2602 and Winsen's mp503 and mq135 to compose the sensor array. The experiment employs the syringe static injection method. The entirety of the experimental gas distribution equipment and gas distribution chamber are illustrated in Fig. 7 (c) and (d), respectively. The signal acquisition frequency is set to 10 Hz. Detailed experimental procedures are provided in the supplementary material.\nDuring each experiment, a cumulative total of approximately 3500 \u00d78 sensor array signal points can be acquired. The signal response curves depicting the continuous recording of single 600 ppm H2, single 600 ppm CO, a gas mixture of 400 ppm H2 and 300 ppm CO, and single 300 ppm CO are illustrated in Fig. 8 (a). Details regarding the drift data of gas sensor array signals obtained from our self-developed E-nose system are described in Table IV. The comprehensive experiment extended over a duration of 30 months."}, {"title": "B. Experimental validation of the model using drift data from the self-developed E-nose system", "content": "Extracting features from the dynamic response signal", "follows": "n$V_{diff} = \\frac{1}{n-m+1} \\sum_{k=m}^{n} V[k"}]}