{"title": "Preictal Period Optimization for Deep Learning-Based Epileptic Seizure Prediction", "authors": ["Petros Koutsouvelis", "Bartlomiej Chybowski", "Alfredo Gonzalez-Sulser", "Shima Abdullateef", "Javier Escudero"], "abstract": "Accurate prediction of epileptic seizures could prove critical for improving patient safety and quality of life in drug-resistant epilepsy. Although deep learning-based approaches have shown promising seizure prediction performance using scalp electroencephalogram (EEG) signals, substantial limitations still impede their clinical adoption. Furthermore, identifying the optimal preictal period (OPP) for labeling EEG segments remains a challenge. Here, we not only develop a competitive deep learning model for seizure prediction but, more importantly, leverage it to demonstrate a methodology to comprehensively evaluate the predictive performance in the seizure prediction task. For this, we introduce a CNN-Transformer deep learning model to detect preictal spatiotemporal dynamics, alongside a novel Continuous Input-Output Performance Ratio (CIOPR) metric to determine the OPP. We trained and evaluated our model on 19 pediatric patients of the open-access CHB-MIT dataset in a subject-specific manner. Using the OPP of each patient, preictal and interictal segments were correctly identified with an average sensitivity of 99.31%, specificity of 95.34%, AUC of 99.35%, and F1-score of 97.46%, while prediction time averaged 76.8 minutes before onset. Notably, our novel CIOPR metric allowed outlining the impact of different preictal period definitions on prediction time, accuracy, output stability, and transition time between interictal and preictal states in a comprehensive and quantitative way and highlighted the importance of considering both inter- and intra-patient variability in seizure prediction.", "sections": [{"title": "I. INTRODUCTION", "content": "EPILEPSY stands as one of the most prevalent neurological conditions worldwide, impacting an estimated 65 million individuals. This disorder is defined by recurrent epileptic seizures unprovoked surges of electrical activity in the brain, leading to transient alterations in behavior or consciousness. Patients span diverse socio-demographic backgrounds, with a lifetime prevalence rate of 3%. Notably, an approximate of 30% of patients suffer from drug-resistant epilepsy [1].\nAn inherent risk factor contributing to mortality among epileptic patients is the unpredictable nature of seizure occurrences, leading to elevated levels of uncertainty, anxiety, social stigma, distress, and potentially hazardous situations among patients [2]. These challenges not only diminish their quality of life but also underscore the critical need for effective seizure management strategies.\nImprovements in predicting epileptic seizures would significantly reduce the burden of uncertainty for patients, enabling them, along with caregivers and clinicians, to take preparatory actions, prevent injuries, and perform timely interventions [3], [4]. Epileptic seizures could be predicted by identifying the preictal state, a period preceding seizure onset (ictal state) characterized by distinct morphological EEG differences from the interictal (normal) state. It can typically last from several minutes to a few hours, varying upon seizures and individuals [5]."}, {"title": "A. Deep learning for epileptic seizure prediction", "content": "Deep learning algorithms have gained increasing popularity in epileptic seizure prediction owing to their ability to learn complex features from data [4]. Convolutional Neural Networks (CNN) have demonstrated particular efficacy in automatically extracting underlying patterns of preictal activity from raw EEG signals [6], EEG wavelets [7], time-frequency data matrices [8], and connectivity-based measures [9]. Recurrent Neural Networks (RNN), including Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM), and Bi-Directional LSTM (BiLSTM), have been successfully employed to capture temporal dependencies in preictal EEG feature vectors [10], [11]. However, when applied to raw EEG input, RNNs exhibit inferior performance compared to CNNs [12]. Various studies [6], [12], [13] have proposed hybrid models combining the advantages of both architectures with superior overall performance. While direct comparison of reported performances across different studies is not straightforward due to differences in experimental setups, ablation studies within a given work can showcase performance improvements due to specific design choices. Authors in [6] demonstrated that adding a Bi-LSTM layer to a CNN model can improve the accuracy of a subject-specific classifier from 94.1% to 99.7%. Similarly, ablation analysis in a cross-patient setting [13] showed that adding CNN layers prior to a GRU classifier led to a 4% increase in accuracy, illustrating the superiority of hybrid models.\nAttention mechanisms, especially within transformer models, have improved the ability to learn data relationships irrespective of sequence distance, a significant limitation in traditional LSTM applications [14], [15]. Integrating CNNs with transformers has led to robust models that effectively predict seizures from both raw EEG [16], [17] and EEG connectivity maps [18], sometimes combined with additional GRU layers [12], [13]. Adding a self-attention layer to a CNN-GRU architecture boosted cross-patient classification accuracy from 75.6% to 82.9% [13]."}, {"title": "B. Determining the preictal period length", "content": "Despite these technological advances, accurately identifying the optimal preictal period (OPP) [5] for labeling EEG segments remains a formidable challenge. This difficulty stems from the gradual nature of the transition into the preictal state and the significant intra- and inter-patient variability in ictogenesis [19], [20]. Approaches to determining the OPP are typically categorized into pre-training and post-training. The former involves defining the preictal length for each seizure before model training through the analysis of EEG markers. Researchers in [5] defined the OPP as the point at which the discriminability of spectral features between the two classes was maximized. Works [19], [20] have computed the preictal length using clustering methods from non-linear, univariate, multivariate, and connectivity EEG measures. Results showed that the OPP varied from 5 to 173 minutes before the onset, while average values ranged from 25 to 48 minutes. As for the post-training approaches, the performance of models trained with varying preictal lengths - usually ranging from 5 to 120 minutes - is evaluated against predefined metrics, such as accuracy, sensitivity, specificity, and F1-score, with the most successful model being selected [7], [8], [10], [13], [21]. Most studies observed higher classification accuracy with shorter preictal lengths, ranging from 5 to 10 minutes.\nAlthough the aforementioned strategies have helped mitigate the uncertainty in defining the preictal period, they still exhibit considerable limitations. Pre-training approaches are constrained by the quality and relevance of the hand-crafted EEG markers, which may not accurately represent the underlying dynamics of preictal activity. They are also agnostic of the histopathology of specific epilepsy subtypes and the location of the epileptogenic zone. Post-training methods, though less sophisticated, demonstrate greater resilience to our incomplete understanding of pre-ictal state dynamics and align more directly with the targeted diagnostic task. Nonetheless, conventional metrics used for model comparison fail to provide a comprehensive assessment of system performance. Though indicative of the model's ability to distinguish preictal from interictal segments, they capture neither the classifier's behavior during the gradual transition to the preictal state nor the distribution of false positives and negatives, which are critical for evaluating the model's practical implementation. Few studies [22]\u2013[24] have employed continuous, long-term EEG to visualize the system's behavior, yet they still rely on standard metrics without introducing novel measures."}, {"title": "C. Contributions", "content": "Recognizing these gaps, this study introduces a novel methodology for evaluating epileptic seizure prediction models. By training a high-performing classifier, we aim to provide a comprehensive assessment that not only monitors the model's behavior but also facilitates the selection of an optimal preictal state definition. For this, the contributions of this work are:\n1) We present a CNN-Transformer model to classify spatiotemporal EEG dynamics of preictal versus interictal EEGs that shows high sensitivity, early prediction time, and consistent performance across subjects.\n2) We introduce an approach that allows nuance assessment of the deep learning model's performance by fitting a sigmoidal curve to the output of the classifier subject to continuous, long EEG input.\n3) We developed a novel Continuous Input-Output Performance Ratio (CIOPR) metric that provides a comprehensive assessment of the performance of a seizure prediction system in a realistic implementation setting by combining measures of prediction time, output stability, and transition time between interictal and preictal states.\n4) We demonstrate the large impact of different preictal state definitions in the system's performance as well as how the CIOPR metric can be utilized to determine the optimal preictal period for each patient (OPP)."}, {"title": "II. MATERIALS AND METHODS", "content": null}, {"title": "A. EEG data and participant selection", "content": "The proposed seizure prediction model was trained and evaluated on the CHB-MIT dataset [25]. It consists of scalp EEG recordings from 23 pediatric patients at the Children's Hospital Boston following an anti-seizure medication withdrawal period of seven days. Patients' ages ranged from 1.5 to 22 years, with individual epilepsy types not being mentioned. There were 198 recorded seizures in total, for which seizure start and end times were annotated by experts. Cases chb01 and chb21 came from the same subject, with the latter being recorded 1.5 years later. Subject information for case chb24 was not provided. Electrodes were placed according to the international 10-20 system with the number of channels for most of the patients ranging from 23 to 26. The sampling rate was set to 256 Hz with 16-bit resolution.\nData recorded up to 4 hours before and 1 hour after each annotated seizure were classified as interictal, to account for the uncertainty in the duration of preictal and postictal effects. Cases without the defined criteria for interictal data were deemed ineligible and excluded from the study, regardless of the number of recorded seizures. The maximum duration for the preictal period was set to 60 minutes. Similarly to the interictal class, data collected up to 1 hour after seizure termination were not considered preictal. Seizures yielding less than one minute of preictal data were excluded as ineligible. Additionally, cases with fewer than two eligible seizures were also excluded, regardless of the volume of available interictal data, since there should be at least one seizure for training and one for testing each subject-specific model. Based on the exclusion criteria mentioned above, cases chb08, chb12, chb13, chb15, and chb24 were excluded. Cases chb01 and chb21 were treated as separate subjects due to the long time difference between the recordings. In instances where electrode placement varied across recordings, the configuration yielding the greatest amount of data was selected. A summary of all patient data and eligible seizures, as well as their Patient ID, Seizure ID, and file name, are detailed in the Supplementary Material Tables 1 and 2, respectively."}, {"title": "B. Pre-processing", "content": "Pre-processing of the EEG signals was kept minimal and was performed on the files meeting the eligibility criteria in Section II-A. Firstly, EEG was re-referenced to common average, which has been shown to improve the Signal-to-Noise Ratio (SNR) [26]. A 0.5 to 45 Hz Finite Impulse Response (FIR) non-causal bandpass filter with Hamming window and order N = 1690 was designed in the time-domain to remove redundant frequency bands, using the MNE Python package. The high-pass cutoff at 0.5 Hz served to remove DC offset and low-frequency voltage drifts [27], while the low-pass cutoff at 45 Hz removed power line interference and additional scalp EEG artifacts present at higher frequencies. No channels were removed, resulting in 23 channels for each eligible patient. Pre-processed data were then segmented into 5-second non-overlapping epochs."}, {"title": "C. Training methodology", "content": "Four different preictal period lengths - 60, 45, 30, and 15 minutes - were then extracted from each seizure to explore their effect on model performance and determine the OPP for each subject separately. Data extraction was conducted as follows: for the 60-minute duration, all available preictal data were extracted for each seizure, regardless of the actual duration available (e.g., some seizures had only 20 minutes of data available). For the 45-minute duration, only segments from the 45 minutes immediately preceding the seizure onset were included; if a seizure had 60 minutes of preictal data available, the first 15 minutes were excluded. If, for example, only 20 minutes were available, none were excluded. This procedure was similarly applied to the 30-minute and 15-minute durations. A histogram of available preictal data per seizure (in minutes) can be found in the Supplementary Material, Figure 1.\nThe models were trained and evaluated in a subject-specific manner. For each definition of preictal length, the extracted preictal segments from all seizures were concatenated without shuffling. To mitigate class imbalance, the minority class (preictal) data were oversampled by a factor of 3 through the introduction of a 66% overlap. Similarly, interictal segments were randomly selected from the pool of interictal data to match the number of the augmented pre-ictal data instances. The training and testing sets were created using the Leave-One-Seizure-Out Cross-Validation (LOOCV) method. Specifically, preictal data of a different seizure each time were isolated, alongside an equal number of randomly selected interictal segments to form the testing set. The remaining samples were shuffled and divided into a 90% training and 10% validation split, forming the training set. This process was repeated four times to ensure consistency across different shuffling and random weight initializations. Ultimately, this resulted in $N \\times 4 \\times k \\times 4$ training and testing sets, where $N$ represents the number of eligible subjects, $k$ denotes the number of eligible seizures per patient, and the four iterations correspond to the different preictal lengths (60, 45, 30, and 15 minutes), as well as the number of different runs."}, {"title": "D. Deep learning model", "content": "A CNN-Transformer deep learning model was developed to classify preictal and interictal EEG segments, with the architecture illustrated in Figure 1. The raw pre-processed EEG epochs were first input to a three-layer Deep Convolutional Neural Network (DCNN) to extract relevant spatiotemporal features. Each convolutional layer, consisting of 32, 64, and 128 filters, respectively, applied a $3 \\times 3$ filter and was followed by a Max-Pooling operation that reduced dimensionality by a factor of two. The architecture also incorporated a Dropout layer with a probability of $p = 0.1$ before each Max-Pooling step to mitigate overfitting, complemented by Batch Normalization (BN) and a Rectified Linear Unit (ReLU) activation function.\nAfter the final convolutional layer, the output tensor was reshaped into a two-dimensional matrix, where rows corresponded to subsequent time points and columns to spatiotemporal features, including positional information resulting from integrating the channel and feature dimensions during the reshaping process. To capture long-term temporal dependencies among these features, a transformer architecture was utilized, with two multi-head attention layers [14]. The reshaped two-dimensional output was used for the creation of the query, key, and value matrices. The linear layers shrunk the dimension of the feature vectors to 64, while the number of attention heads was set to 8. Each attention layer was followed by a fully-connected (dense) layer of 64 neurons, ReLU activation and $p = 0.3$ dropout, to highlight the most relevant features, while maintaining the dimensionality of the feature vectors.\nThe resulting attention-weighted feature map was then flattened and processed through a single-neuron output layer with sigmoid activation for the classification stage. The output value was rounded to the nearest integer (0: interictal, 1: preictal) without further post-processing. The model was trained using the binary cross-entropy loss function [28], with weight updates performed via the Adam optimization algorithm. The learning rate was set to $l = 0.001$, and the AMSGrad [29] extension was enabled. The training utilized a mini-batch size of 64 and was limited to 100 epochs. To prevent overfitting, the early-stopping callback terminated training if the validation loss did not improve for 20 consecutive epochs. The model-checkpoint callback preserved the weights of the model iteration, achieving the lowest validation loss. The complete summary of the model can be found in the Supplementary Material."}, {"title": "E. Continuous Input-Output Performance Ratio (CIOPR)", "content": "We introduce a novel metric that facilitates direct comparison of classifier behaviors across prediction tasks. Traditional accuracy metrics, heavily reliant on class definitions, fail to capture the timing of predictions or model performance during state transitions. Addressing these limitations, our innovative metric, CIOPR enables a comprehensive evaluation of models using uninterrupted, unlabeled long-term EEG data as input, to establish objective comparisons independent of class definitions. We utilized it to compare the effect of different preictal state definitions and assumed that the ideal classifier would offer early prediction, minimal errors, high stability, and brief transition periods. When subjected to continuous EEG data spanning several hours before a seizure, an accurate classifier is anticipated to initially produce negative (interictal) predictions, transition through a mix of negative and positive predictions, and ultimately converge to the preictal state. Consequently, to quantitatively model the timing of these predictions, we propose to fit a sigmoidal curve to the classifier's continuous output, which has undergone smoothing with an 8-minute averaging window. In particular, a 4-Parameter Logistic curve (4PL) is used, given by Equation 1 [30], where parameters $a, b, c$, and $d$ represent the vertical and horizontal stretch, the point of inflection, and the vertical offset, respectively, as\n$f(x) = \\frac{a}{1+e^{-b(x-c)}} + d$.\n(1)\nUtilizing the fitted sigmoidal curve, we derive key performance measures. Specifically, the transition period (TP) between interictal and preictal states is quantified as the time interval between the 5th and 95th percentile thresholds of the sigmoid curve's amplitude. The negative duration (ND), the supposed interictal period, is calculated as the duration between the first output prediction and the beginning of the transition period. The remaining measures are directly computed from the output data, following average smoothing (1 output prediction every 8 minutes). The seizure prediction convergence (SPC) is the point in time where output predictions reached 99% of the maximum value, in minutes before seizure onset. It represents the period of highest incoming-seizure probability by the model and could reflect the prediction horizon in a realistic implementation setting. Both output and maximum values used for the computation of SPC refer to the mean of 3 consecutive predictions ($3 \\times 8$ minutes = 24 minutes). Figure 2 depicts the fitted sigmoid, the output predictions, and the aforementioned measures.\nThe average errors during the SPC (SPCerr) and interictal period (NDerr) are calculated using Equations 2 and 3, respectively. NSPC and NND refer to the number of output predictions in each of the two regions. Then, Equation 4 is developed to combine all the measures so that the classifier with the longest SPC, minimum SPCerr and NDerr, and shortest TP achieved the highest score. SPCeff and NDeff represent the effective values of SPC and ND taking into account the average errors, and defined as SPCeff = SPC(1 \u2013 SPCerr) and NDeff = ND(1 \u2013 NDerr).\n$SPC_{err} = \\frac{1}{N_{SPC}} \\sum_{i=1}^{N_{SPC}} |1 - Y_i|$\n(2)\n$ND_{err} = \\frac{1}{N_{ND}} \\sum_{i=1}^{N_{ND}} Y_i$\n(3)\n$CIOPC = SPC_{eff} + \\eta(ND_{eff} + Infl_{comp})$\n(4)\nOverall, Equation 4 computes the Continuous Input-Output Performance Coefficient (CIOPC) of a model by taking into account two terms. The SPCeff term rewards the model for early prediction (SPC), as well as high accuracy (SPCerr). As for the second term, NDeff rewards the model for short TP (longer ND when TP is short) and high accuracy (NDerr). A reduction in ND due to earlier prediction should not get penalized and is compensated by the Inflcomp term (NDe f f lost due to an earlier point of inflection). The scaling factor \u03b7 ensures that the second term will not have a greater weighting than SPCeff due to hours-long interictal EEG; hence, maintaining the focus on early and accurate seizure prediction.\nThe CIOPC value for each preictal state definition is normalized to the CIOPR metric using Equation 5, where CIOPCmax denotes the maximal CIOPC obtained across the examined preictal durations. This normalization facilitates a relative performance evaluation, where the highest-scoring model is assigned a CIOPR score of 1, thus enabling a comparative analysis of the impact of varying preictal period lengths. Detailed expressions for Inflcomp and n, as well as elucidation of the underlying intuition for CIOPR, are detailed in the Supplementary Material, Section 3.\n$CIOPR_k = \\frac{CIOPC_k}{CIOPC_{max}}, k \\in {60, 45, 30, 15}$\n(5)\nLastly, the Pearson correlation coefficient, pis calculated between the output predictions and the fitted curve to assess the method's reliability. It also serves as an indicator of output stability, since greater fluctuations are expected to decrease the correlation coefficient."}, {"title": "F. Additional metrics", "content": "Beyond the CIOPR, conventional performance metrics including segment-wise sensitivity (SEN), specificity (SPE), accuracy (ACC), and F1-score (F1) were employed for performance evaluation. These metrics were computed on the test set, the formulation of which is detailed in Section II-D. Given the equal representation of classes in the test set, the resulting accuracy is equivalent to the balanced accuracy."}, {"title": "G. Testing setup", "content": "For each eligible seizure of a qualifying participant (criteria detailed in Section II-A), the prediction performance was tested using the conventional metrics (SEN, SPE, ACC, and F1), for all preictal durations. Seizures with over 2.5 hours of uninterrupted continuous EEG data were further subjected to CIOPR evaluation for each preictal interval. A maximum of 10 hours of continuous EEG was utilized for CIOPR to reduce computation time and maintain consistency across patients."}, {"title": "H. OPP selection", "content": "A general OPP \u2013 60, 45, 30, or 15 minutes \u2013 was then selected for each participant. When at least one seizure was eligible for CIOPR testing, the OPP was assigned to the preictal definition yielding the highest CIOPR values, averaged across those seizures. Conversely, if no CIOPR results were available, the OPP was assigned to the preictal definition attaining the highest F1-score, averaged across all testing seizures. F1-score is preferred over balanced accuracy due to its capability to emphasize minimizing false negatives, which are considered more detrimental in epileptic seizure prediction [4]. Lastly, the model trained using the OPP was selected from each patient to evaluate both the subject-specific and aggregate performance of our proposed methodology. To further showcase performance, the False Alarm Rate (FAR) (h\u00af\u00b9) and the Area Under the Receiver Operating Characteristic (ROC) Curve (AUC) were reported only for the selected models. FAR was computed based on the EPOCH [31] method on the 5-second segment level."}, {"title": "I. Statistical analysis", "content": "To explore statistical differences in model behavior attributed to different preictal definitions, a related-samples Friedman's two-way ANOVA with Bonferroni correction for multiple comparisons was conducted for all the metrics used in the testing setup (SEN, SPE, ACC, F1-score, SPC, SPCerr, NDerr, inflection point, TP, Pearson correlation, CIOPR). The null hypothesis tested was that the distributions of scores for each metric across the preictal lengths of 60, 45, 30, and 15 minutes do not differ significantly (significance level a = 0.05 after correction)."}, {"title": "III. RESULTS", "content": null}, {"title": "A. Classifier Training", "content": "The models were trained using an A100 Tensor Core GPU in Google Colab. The average training duration was 8.1 minutes per model, converging at epoch 54 due to the early-stopping callback. The training duration was significantly longer for 60- and 45-minute preictal class definitions due to increased data volume. The convergence minima for both validation and training curves varied more across patients than across intra-patient seizures or different preictal state lengths."}, {"title": "B. Classification results", "content": "Table I details the segment-wise SEN, SPE, ACC, and F1-score of the subject-specific classifiers. The displayed values represent the weighted average across all runs and testing seizures for each patient. A preictal class duration of 60 minutes generally yielded the highest average F1-scores, although 45- and 30-minute definitions performed better in certain individuals. The percentage change in F1-scores across different preictal class definitions was relatively modest, with a maximum variation of 3.2% observed in case chb05. Sensitivity scores remained consistent across various preictal durations. Fluctuations in the F1-score were primarily attributable to reductions in specificity associated with shorter preictal states."}, {"title": "C. Continuous Input-Output Performance Ratio (CIOPR) Testing Results", "content": "The proposed CIOPR in Section II-E was performed on the thirteen patients that met the criteria described in Section II-G. The first step of the analysis involved fitting the sigmoidal curve to the smoothed output of the classifiers. The Pearson correlation coefficient between the model output and the fitted curve across all the tested patients was on average p > 0.9 for the 60, 45, and 30-minute preictal definitions, and p = 0.876 for the 15-minute one. The high correlation values show the effectiveness of the chosen curve in modeling the classifiers' output profile and indicate that the models generally exhibited the intended behaviour. Similar to the F1-score results, the correlation coefficients differed across patients, seizures and pre-ictal state lengths, with 60 minutes usually leading to higher values.\nThe fitted curves allowed the computation of the CIOPR values for each testing seizure per patient, preictal period length per patient for each metric. The 60-minute preictal length generally resulted in higher CIOPR scores, although the 45-minute one was optimal for some individuals, similar to findings in Section III-B. The results can then be categorized into two types: a) concordant, where the same preictal length yielded the highest performance in both metrics and b) discordant, where CIOPR and F1-score values suggested different optimal preictal periods (OPP).\nContrary to the F1-score results, the CIOPR values were more sensitive to varying preictal class definitions. In particular, a 25% change was observed on average across different preictal lengths, reaching > 40% in case chb14. Cases chb02, chb07, chb14, and chb16 all presented differences \u226510% between the two best-performing models based on the CIOPR metric. The CIOPR discrepancies can be attributed to the visually identifiable changes in the model's behavior, such as greater prediction horizon, shorter transition time, and reduced error. In this case, the results between the two metrics were concordant; increasing preictal class definition led to improved CIOPR and higher F1-scores.\nOn the other hand, cases chb06, chb07, and chb14 demonstrated similar CIOPR variations (\u226510%) across different preictal definitions, yet yielded discordant F1-score results. The differences in seizure prediction convergence and output stability resulting in significantly greater CIOPR. Conversely, the F1-scores did not follow the same trend, underscoring the inadequacy of conventional metrics"}, {"title": "D. OPP selection and overall performance", "content": "For seizures eligible for CIOPR assessment, the OPP was determined based on the highest CIOPR values from Table II, while for the rest, it was based on the highest F1-score from Table I, as outlined in Section II-G. Overall results are summarized in Table III, which includes the OPP for each patient and corresponding performance metrics. SEN, SPE, FAR, ACC, AUC, and F1-score were computed for the selected OPP using all testing seizures as in Table I, while SPC used only the ones subject to CIOPR testing. The criterion used to select the OPP (CIOPR or F1-score) is also displayed. On average, the subject-specific models achieved a sensitivity of 99.31%, specificity of 95.34%, classification accuracy of 97.32%, and F1-score of 97.46%. The classifiers' output converged at 76.8 minutes before seizure onset, with a standard deviation of 36.8 minutes, reflecting anticipated cross-patient heterogeneities."}, {"title": "E. Statistical analysis results", "content": "The null hypothesis formulated in Section II-I was rejected with Bonferroni-corrected p-values < 0.05 for all metrics apart from NDerr (p-value = 0.388), TP (p-value = 0.135), and sensitivity (p-value = 0.161). The comparison between the 60 and 15-minute preictal periods showed significant differences in 8 of the 11 metrics assessed, followed by the 45 to 15, and 60 to 30-minute comparisons. Conversely, the smallest number of significant differences were noted between adjacent preictal definitions (15 minutes apart), particularly for the 30 to 15-minute and 60 to 45-minute pairs. CIOPR and SPC metrics accounted for the highest number of significant comparisons (4 out of 6), followed by specificity (3 out of 6), accuracy (2 out of 6), and lastly by the F1-score (1 out of 6)."}, {"title": "IV. DISCUSSION", "content": "We trained subject-specific classifiers for 19 pediatric patients of the CHB-MIT dataset to predict epileptic seizures using raw scalp EEG signals. The proposed CNN-Transformer deep learning architecture achieved a balanced accuracy of 97.32%, enabling confident seizure predictions up to 76.8 minutes prior to seizure onset on average. By introducing the CIOPR metric, we illustrated the significant impact of preictal class definition on model behavior and demonstrated how these variations can be quantified to determine the optimal preictal duration to maximize the model's usability for each individual patient.\nData augmentation in the preictal state, along with a lack of external validation, could lead to model overfitting, where classifiers memorize rather than generalize training data [4]. Although the LOOCV approach prevents the model from encountering test seizures during training, the uniform data acquisition setting and the close temporal proximity of recordings might still result in high similarity between training and testing sets [43]. Conversely, interictal data, recorded throughout the whole day, exhibit greater variability from circadian rhythms and additional EEG patterns [44], complicating their classification. This greater variability might explain the consistently lower specificity and its significant reduction with shorter preictal durations, as these entail fewer training samples.\nSome cases in our study had significantly lower performance compared to others. For instance, case chb06 exhibited a sensitivity of 94.76%, and a specificity of 73.54%, > 20% below the average. Cases chb14 and chb22 also showed notably low specificity scores. Comparison with literature suggests that cases chb06 and chb14 exhibited on average the lowest balanced accuracy across state-of-the-art studies. The same pattern was observed when comparing the reported F1-scores The limited number of patients and the absence of detailed pathological data in the CHB-MIT dataset prevent further exploration of the effect of various epilepsy sub-types on seizure prediction performance. However, concordance with the literature results indicates that the aforementioned limitations are broadly applicable to the field and could inform future research directions."}, {"title": "A. Classification performance", "content": "The proposed architecture demonstrated consistent performance across multiple subjects and preictal lengths with particularly high sensitivity (> 99%). We used the balanced accuracy metric (average of sensitivity and specificity) for comparison with state-of-the-art literature [10], [32]\u2013[42] to account for variations in the preictal-interictal data ratio across studies. Our model achieved higher balanced accuracy than the aforementioned studies, by an average of 7%. While the authors in [10] reported the highest accuracy value, the absence of validation using LOOCV undermines the reported performance. To the best of our knowledge, Daoud et al. [6] have attained the highest LOOCV-validated accuracy of 99.66%. False alarms averaged 33.6 per hour on a segment-wise basis, since they were computed on the raw model output. However, the average specificity exceeded 95%, suggesting that the introduction of a post-processing scheme would significantly reduce FAR (h-\u00b9) in a clinical environment.\nAlthough extended preictal periods could be expected to increase the likelihood of mislabeling interictal data, and consequently the number of false positives, the results of our study indicate the opposite. Varying preictal definitions minimally impacted model sensitivity as shown in Section III-E, whereas specificity improved with longer preictal periods. This finding aligns with the results reported in literature [10]. Furthermore, at the 0.5 decision threshold, specificity was consistently lower than sensitivity, a pattern appearing also in other studies Higher sensitivity scores and consequent invariability to changing preictal state definitions may reflect one of the major limitations in ongoing epileptic seizure prediction research: insufficient data volume."}, {"title": "B. CIOPR alongside conventional metrics", "content": "The newly introduced CIOPR metric was used to comprehensively assess model performance and compare the effect of different preictal state definitions. Comparison with the F1-score results indicates that CIOPR is considerably more sensitive to varying preictal lengths, showing an average change of 9.2% per 15-minute decrease, compared to a 0.3% average change for the F1-score. This is also confirmed by the statistical analysis in Section III-E, where the CIOPR distributions varied significantly across four preictal length comparisons, compared to only one for the F1-score. Furthermore, in 7 out of the 13 cases that underwent CIOPR testing, there was a discordance in the best-performing preictal definition between the two metrics. This discrepancy occurred only in cases where F1-score variations were less than 1% between the two best-performing preictal definitions.\nWhile the Fl-score and other conventional metrics remain useful and can guide design choices, comparing high-performing classifiers necessitates more sophisticated and sensitive measures to capture subtle behavioral differences. How the individual measures used to calculate the CIOPR allow a comprehensive assessment of the model's behavior"}, {"title": "C. Preictal length definition and model behavior", "content": "Observing the CIOPR scores and individual measures across all patients enabled us to draw general conclusions about the model's behavior under different preictal state definitions. As discussed in Section IV-A", "predictions": "the point of inflection in the fitted sigmoidal curve occurred on average 143.1 minutes before onset for the 60-minute definition, compared to 125.3 minutes for the 15-minute definition. Statistical analysis showed that reducing the preictal length from 60 to 15 and from 6"}]}