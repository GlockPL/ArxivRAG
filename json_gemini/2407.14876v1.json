{"title": "Preictal Period Optimization for Deep Learning-Based Epileptic Seizure Prediction", "authors": ["Petros Koutsouvelis", "Bartlomiej Chybowski", "Alfredo Gonzalez-Sulser", "Shima Abdullateef", "Javier Escudero"], "abstract": "Accurate prediction of epileptic seizures could prove critical for improving patient safety and quality of life in drug-resistant epilepsy. Although deep learning-based approaches have shown promising seizure prediction performance using scalp electroencephalogram (EEG) signals, substantial limitations still impede their clinical adoption. Furthermore, identifying the optimal preictal period (OPP) for labeling EEG segments remains a challenge. Here, we not only develop a competitive deep learning model for seizure prediction but, more importantly, leverage it to demonstrate a methodology to comprehensively evaluate the predictive performance in the seizure prediction task. For this, we introduce a CNN-Transformer deep learning model to detect preictal spatiotemporal dynamics, alongside a novel Continuous Input-Output Performance Ratio (CIOPR) metric to determine the OPP. We trained and evaluated our model on 19 pediatric patients of the open-access CHB-MIT dataset in a subject-specific manner. Using the OPP of each patient, preictal and interictal segments were correctly identified with an average sensitivity of 99.31%, specificity of 95.34%, AUC of 99.35%, and F1-score of 97.46%, while prediction time averaged 76.8 minutes before onset. Notably, our novel CIOPR metric allowed outlining the impact of different preictal period definitions on prediction time, accuracy, output stability, and transition time between interictal and preictal states in a comprehensive and quantitative way and highlighted the importance of considering both inter- and intra-patient variability in seizure prediction.", "sections": [{"title": "I. INTRODUCTION", "content": "EPILEPSY stands as one of the most prevalent neurological conditions worldwide, impacting an estimated 65 million individuals. This disorder is defined by recurrent epileptic seizures unprovoked surges of electrical activity in the brain, leading to transient alterations in behavior or consciousness. Patients span diverse socio-demographic backgrounds, with a lifetime prevalence rate of 3%. Notably, an approximate of 30% of patients suffer from drug-resistant epilepsy [1].\nAn inherent risk factor contributing to mortality among epileptic patients is the unpredictable nature of seizure occurrences, leading to elevated levels of uncertainty, anxiety, social stigma, distress, and potentially hazardous situations among patients [2]. These challenges not only diminish their quality of life but also underscore the critical need for effective seizure management strategies.\nImprovements in predicting epileptic seizures would significantly reduce the burden of uncertainty for patients, enabling them, along with caregivers and clinicians, to take preparatory actions, prevent injuries, and perform timely interventions [3], [4]. Epileptic seizures could be predicted by identifying the preictal state, a period preceding seizure onset (ictal state) characterized by distinct morphological EEG differences from the interictal (normal) state. It can typically last from several minutes to a few hours, varying upon seizures and individuals [5]."}, {"title": "A. Deep learning for epileptic seizure prediction", "content": "Deep learning algorithms have gained increasing popularity in epileptic seizure prediction owing to their ability to learn complex features from data [4]. Convolutional Neural Networks (CNN) have demonstrated particular efficacy in automatically extracting underlying patterns of preictal activity from raw EEG signals [6], EEG wavelets [7], time-frequency data matrices [8], and connectivity-based measures [9]. Recurrent Neural Networks (RNN), including Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM), and Bi-Directional LSTM (BiLSTM), have been successfully employed to capture temporal dependencies in preictal EEG feature vectors [10], [11]. However, when applied to raw EEG input, RNNs exhibit inferior performance compared to CNNs [12]. Various studies [6], [12], [13] have proposed hybrid models combining the advantages of both architectures with superior overall performance. While direct comparison of reported performances across different studies is not straightforward due to differences in experimental setups, ablation studies within a given work can showcase performance improvements due to specific design choices. Authors in [6] demonstrated that adding a Bi-LSTM layer to a CNN model can improve the accuracy of a subject-specific classifier from 94.1% to 99.7%. Similarly, ablation analysis in a cross-patient setting [13] showed that adding CNN layers prior to a GRU classifier led to a 4% increase in accuracy, illustrating the superiority of hybrid models. Attention mechanisms, especially within transformer models, have improved the ability to learn data relationships irrespective of sequence distance, a significant limitation in traditional LSTM applications [14], [15]. Integrating CNNs with transformers has led to robust models that effectively predict seizures from both raw EEG [16], [17] and EEG connectivity maps [18], sometimes combined with additional GRU layers [12], [13]. Adding a self-attention layer to a CNN-GRU architecture boosted cross-patient classification accuracy from 75.6% to 82.9% [13]."}, {"title": "B. Determining the preictal period length", "content": "Despite these technological advances, accurately identifying the optimal preictal period (OPP) [5] for labeling EEG segments remains a formidable challenge. This difficulty stems from the gradual nature of the transition into the preictal state and the significant intra- and inter-patient variability in ictogenesis [19], [20]. Approaches to determining the OPP are typically categorized into pre-training and post-training. The former involves defining the preictal length for each seizure before model training through the analysis of EEG markers. Researchers in [5] defined the OPP as the point at which the discriminability of spectral features between the two classes was maximized. Works [19], [20] have computed the preictal length using clustering methods from non-linear, univariate, multivariate, and connectivity EEG measures. Results showed that the OPP varied from 5 to 173 minutes before the onset, while average values ranged from 25 to 48 minutes. As for the post-training approaches, the performance of models trained with varying preictal lengths - usually ranging from 5 to 120 minutes - is evaluated against predefined metrics, such as accuracy, sensitivity, specificity, and F1-score, with the most successful model being selected [7], [8], [10], [13], [21]. Most studies observed higher classification accuracy with shorter preictal lengths, ranging from 5 to 10 minutes.\nAlthough the aforementioned strategies have helped mitigate the uncertainty in defining the preictal period, they still exhibit considerable limitations. Pre-training approaches are constrained by the quality and relevance of the hand-crafted EEG markers, which may not accurately represent the underlying dynamics of preictal activity. They are also agnostic of the histopathology of specific epilepsy subtypes and the location of the epileptogenic zone. Post-training methods, though less sophisticated, demonstrate greater resilience to our incomplete understanding of pre-ictal state dynamics and align more directly with the targeted diagnostic task. Nonetheless, conventional metrics used for model comparison fail to provide a comprehensive assessment of system performance. Though indicative of the model's ability to distinguish preictal from interictal segments, they capture neither the classifier's behavior during the gradual transition to the preictal state nor the distribution of false positives and negatives, which are critical for evaluating the model's practical implementation. Few studies [22]\u2013[24] have employed continuous, long-term EEG to visualize the system's behavior, yet they still rely on standard metrics without introducing novel measures."}, {"title": "C. Contributions", "content": "Recognizing these gaps, this study introduces a novel methodology for evaluating epileptic seizure prediction models. By training a high-performing classifier, we aim to provide a comprehensive assessment that not only monitors the model's behavior but also facilitates the selection of an optimal preictal state definition. For this, the contributions of this work are:\n1) We present a CNN-Transformer model to classify spatiotemporal EEG dynamics of preictal versus interictal EEGs that shows high sensitivity, early prediction time, and consistent performance across subjects.\n2) We introduce an approach that allows nuance assessment of the deep learning model's performance by fitting a sigmoidal curve to the output of the classifier subject to continuous, long EEG input.\n3) We developed a novel Continuous Input-Output Performance Ratio (CIOPR) metric that provides a comprehensive assessment of the performance of a seizure prediction system in a realistic implementation setting by combining measures of prediction time, output stability, and transition time between interictal and preictal states.\n4) We demonstrate the large impact of different preictal state definitions in the system's performance as well as how the CIOPR metric can be utilized to determine the optimal preictal period for each patient (OPP)."}, {"title": "II. MATERIALS AND METHODS", "content": "The proposed seizure prediction model was trained and evaluated on the CHB-MIT dataset [25]. It consists of scalp EEG recordings from 23 pediatric patients at the Children's Hospital Boston following an anti-seizure medication withdrawal period of seven days. Patients' ages ranged from 1.5 to 22 years, with individual epilepsy types not being mentioned. There were 198 recorded seizures in total, for which seizure start and end times were annotated by experts. Cases chb01 and chb21 came from the same subject, with the latter being recorded 1.5 years later. Subject information for case chb24 was not provided. Electrodes were placed according to the international 10-20 system with the number of channels for most of the patients ranging from 23 to 26. The sampling rate was set to 256 Hz with 16-bit resolution.\nData recorded up to 4 hours before and 1 hour after each annotated seizure were classified as interictal, to account for the uncertainty in the duration of preictal and postictal effects. Cases without the defined criteria for interictal data were deemed ineligible and excluded from the study, regardless of the number of recorded seizures. The maximum duration for the preictal period was set to 60 minutes. Similarly to the interictal class, data collected up to 1 hour after seizure termination were not considered preictal. Seizures yielding less than one minute of preictal data were excluded as ineligible. Additionally, cases with fewer than two eligible seizures were also excluded, regardless of the volume of available interictal data, since there should be at least one seizure for training and one for testing each subject-specific model. Based on the exclusion criteria mentioned above, cases chb08, chb12, chb13, chb15, and chb24 were excluded. Cases chb01 and chb21 were treated as separate subjects due to the long time difference between the recordings. In instances where electrode placement varied across recordings, the configuration yielding the greatest amount of data was selected. A summary of all patient data and eligible seizures, as well as their Patient ID, Seizure ID, and file name, are detailed in the Supplementary Material Tables 1 and 2, respectively."}, {"title": "A. EEG data and participant selection", "content": "The proposed seizure prediction model was trained and evaluated on the CHB-MIT dataset [25]. It consists of scalp EEG recordings from 23 pediatric patients at the Children's Hospital Boston following an anti-seizure medication withdrawal period of seven days. Patients' ages ranged from 1.5 to 22 years, with individual epilepsy types not being mentioned. There were 198 recorded seizures in total, for which seizure start and end times were annotated by experts. Cases chb01 and chb21 came from the same subject, with the latter being recorded 1.5 years later. Subject information for case chb24 was not provided. Electrodes were placed according to the international 10-20 system with the number of channels for most of the patients ranging from 23 to 26. The sampling rate was set to 256 Hz with 16-bit resolution."}, {"title": "B. Pre-processing", "content": "Pre-processing of the EEG signals was kept minimal and was performed on the files meeting the eligibility criteria in Section II-A. Firstly, EEG was re-referenced to common average, which has been shown to improve the Signal-to-Noise Ratio (SNR) [26]. A 0.5 to 45 Hz Finite Impulse Response (FIR) non-causal bandpass filter with Hamming window and order N = 1690 was designed in the time-domain to remove redundant frequency bands, using the MNE Python package. The high-pass cutoff at 0.5 Hz served to remove DC offset and low-frequency voltage drifts [27], while the low-pass cutoff at 45 Hz removed power line interference and additional scalp EEG artifacts present at higher frequencies. No channels were removed, resulting in 23 channels for each eligible patient. Pre-processed data were then segmented into 5-second non-overlapping epochs."}, {"title": "C. Training methodology", "content": "Four different preictal period lengths - 60, 45, 30, and 15 minutes were then extracted from each seizure to explore their effect on model performance and determine the OPP for each subject separately. Data extraction was conducted as follows: for the 60-minute duration, all available preictal data were extracted for each seizure, regardless of the actual duration available (e.g., some seizures had only 20 minutes of data available). For the 45-minute duration, only segments from the 45 minutes immediately preceding the seizure onset were included; if a seizure had 60 minutes of preictal data available, the first 15 minutes were excluded. If, for example, only 20 minutes were available, none were excluded. This procedure was similarly applied to the 30-minute and 15-minute durations. A histogram of available preictal data per seizure (in minutes) can be found in the Supplementary Material, Figure 1.\nThe models were trained and evaluated in a subject-specific manner. For each definition of preictal length, the extracted preictal segments from all seizures were concatenated without shuffling. To mitigate class imbalance, the minority class (preictal) data were oversampled by a factor of 3 through the introduction of a 66% overlap. Similarly, interictal segments were randomly selected from the pool of interictal data to match the number of the augmented pre-ictal data instances. The training and testing sets were created using the Leave-One-Seizure-Out Cross-Validation (LOOCV) method. Specifically, preictal data of a different seizure each time were isolated, alongside an equal number of randomly selected interictal segments to form the testing set. The remaining samples were shuffled and divided into a 90% training and 10% validation split, forming the training set. This process was repeated four times to ensure consistency across different shuffling and random weight initializations. Ultimately, this resulted in $N \\times 4 \\times k \\times 4$ training and testing sets, where $N$ represents the number of eligible subjects, $k$ denotes the number of eligible seizures per patient, and the four iterations correspond to the different preictal lengths (60, 45, 30, and 15 minutes), as well as the number of different runs."}, {"title": "D. Deep learning model", "content": "A CNN-Transformer deep learning model was developed to classify preictal and interictal EEG segments, with the architecture illustrated in Figure 1. The raw pre-processed EEG epochs were first input to a three-layer Deep Convolutional Neural Network (DCNN) to extract relevant spatiotemporal features. Each convolutional layer, consisting of 32, 64, and 128 filters, respectively, applied a 3 \u00d7 3 filter and was followed by a Max-Pooling operation that reduced dimensionality by a factor of two. The architecture also incorporated a Dropout layer with a probability of $p = 0.1$ before each Max-Pooling step to mitigate overfitting, complemented by Batch Normalization (BN) and a Rectified Linear Unit (ReLU) activation function.\nAfter the final convolutional layer, the output tensor was reshaped into a two-dimensional matrix, where rows corresponded to subsequent time points and columns to spatiotemporal features, including positional information resulting from integrating the channel and feature dimensions during the reshaping process. To capture long-term temporal dependencies among these features, a transformer architecture was utilized, with two multi-head attention layers [14]. The reshaped two-dimensional output was used for the creation of the query, key, and value matrices. The linear layers shrunk the dimension of the feature vectors to 64, while the number of attention heads was set to 8. Each attention layer was followed by a fully-connected (dense) layer of 64 neurons, ReLU activation and $p = 0.3$ dropout, to highlight the most relevant features, while maintaining the dimensionality of the feature vectors.\nThe resulting attention-weighted feature map was then flattened and processed through a single-neuron output layer with sigmoid activation for the classification stage. The output value was rounded to the nearest integer (0: interictal, 1: preictal) without further post-processing. The model was trained using the binary cross-entropy loss function [28], with weight updates performed via the Adam optimization algorithm. The learning rate was set to $l = 0.001$, and the AMSGrad [29] extension was enabled. The training utilized a mini-batch size of 64 and was limited to 100 epochs. To prevent overfitting, the early-stopping callback terminated training if the validation loss did not improve for 20 consecutive epochs. The model-checkpoint callback preserved the weights of the model iteration, achieving the lowest validation loss. The complete summary of the model can be found in the Supplementary Material."}, {"title": "E. Continuous Input-Output Performance Ratio (CIOPR)", "content": "We introduce a novel metric that facilitates direct comparison of classifier behaviors across prediction tasks. Traditional accuracy metrics, heavily reliant on class definitions, fail to capture the timing of predictions or model performance during state transitions. Addressing these limitations, our innovative metric, CIOPR enables a comprehensive evaluation of models using uninterrupted, unlabeled long-term EEG data as input, to establish objective comparisons independent of class definitions. We utilized it to compare the effect of different preictal state definitions and assumed that the ideal classifier would offer early prediction, minimal errors, high stability, and brief transition periods. When subjected to continuous EEG data spanning several hours before a seizure, an accurate classifier is anticipated to initially produce negative (interictal) predictions, transition through a mix of negative and positive predictions, and ultimately converge to the preictal state. Consequently, to quantitatively model the timing of these predictions, we propose to fit a sigmoidal curve to the classifier's continuous output, which has undergone smoothing with an 8-minute averaging window. In particular, a 4-Parameter Logistic curve (4PL) is used, given by Equation 1 [30], where parameters $a$, $b$, $c$, and $d$ represent the vertical and horizontal stretch, the point of inflection, and the vertical offset, respectively, as\n$$f(x) = \\frac{a}{1+e^{-b(x-c)}}+d.$$\nUtilizing the fitted sigmoidal curve, we derive key performance measures. Specifically, the transition period (TP) between interictal and preictal states is quantified as the time interval between the 5th and 95th percentile thresholds of the sigmoid curve's amplitude. The negative duration (ND), the supposed interictal period, is calculated as the duration between the first output prediction and the beginning of the transition period. The remaining measures are directly computed from the output data, following average smoothing (1 output prediction every 8 minutes). The seizure prediction convergence (SPC) is the point in time where output predictions reached 99% of the maximum value, in minutes before seizure onset. It represents the period of highest incoming-seizure probability by the model and could reflect the prediction horizon in a realistic implementation setting. Both output and maximum values used for the computation of SPC refer to the mean of 3 consecutive predictions (3 \u00d7 8 minutes = 24 minutes). Figure 2 depicts the fitted sigmoid, the output predictions, and the aforementioned measures.\nThe average errors during the SPC (SPCerr) and interictal period (NDerr) are calculated using Equations 2 and 3, respectively. $N_{SPC}$ and $N_{ND}$ refer to the number of output predictions in each of the two regions. Then, Equation 4 is developed to combine all the measures so that the classifier with the longest SPC, minimum SPCerr and NDerr, and shortest TP achieved the highest score. SPCeff and NDeff represent the effective values of SPC and ND taking into account the average errors, and defined as SPCeff = SPC(1 \u2013 SPCerr) and NDeff = ND(1 \u2013 NDerr).\n$$\\begin{aligned}\nSPC_{err} &= \\frac{1}{N_{SPC}} \\sum_{i=1}^{N_{SPC}} |1 - Y_i|\\\\\nND_{err} &= \\frac{1}{N_{ND}} \\sum_{i=1}^{N_{ND}} Y_i\n\\end{aligned}$$\nCIOPC = SPCeff +\u03b7(NDeff + Inflcomp)"}, {"title": "F. Additional metrics", "content": "Beyond the CIOPR, conventional performance metrics including segment-wise sensitivity (SEN), specificity (SPE), accuracy (ACC), and F1-score (F1) were employed for performance evaluation. These metrics were computed on the test set, the formulation of which is detailed in Section II-D. Given the equal representation of classes in the test set, the resulting accuracy is equivalent to the balanced accuracy."}, {"title": "G. Testing setup", "content": "For each eligible seizure of a qualifying participant (criteria detailed in Section II-A), the prediction performance was tested using the conventional metrics (SEN, SPE, ACC, and F1), for all preictal durations. Seizures with over 2.5 hours of uninterrupted continuous EEG data were further subjected to CIOPR evaluation for each preictal interval. A maximum of 10 hours of continuous EEG was utilized for CIOPR to reduce computation time and maintain consistency across patients."}, {"title": "III. RESULTS", "content": "The models were trained using an A100 Tensor Core GPU in Google Colab. The average training duration was 8.1 minutes per model, converging at epoch 54 due to the early-stopping callback. The training duration was significantly longer for 60- and 45-minute preictal class definitions due to increased data volume. The convergence minima for both validation and training curves varied more across patients than across intra-patient seizures or different preictal state lengths.\nTable I details the segment-wise SEN, SPE, ACC, and F1-score of the subject-specific classifiers. The displayed values represent the weighted average across all runs and testing seizures for each patient. A preictal class duration of 60 minutes generally yielded the highest average F1-scores, although 45- and 30-minute definitions performed better in certain individuals. The percentage change in F1-scores across different preictal class definitions was relatively modest, with a maximum variation of 3.2% observed in case chb05. Sensitivity scores remained consistent across various preictal durations. Fluctuations in the F1-score were primarily attributable to reductions in specificity associated with shorter preictal states.\nThe proposed CIOPR in Section II-E was performed on the thirteen patients that met the criteria described in Section II-G. The first step of the analysis involved fitting the sigmoidal curve to the smoothed output of the classifiers. The Pearson correlation coefficient between the model output and the fitted curve across all the tested patients was on average $p > 0.9$ for the 60, 45, and 30-minute preictal definitions, and $p = 0.876$ for the 15-minute one. The high correlation values show the effectiveness of the chosen curve in modeling the classifiers' output profile and indicate that the models generally exhibited the intended behavior. Similar to the F1-score results, the correlation coefficients differed across patients, seizures and preictal state lengths, with 60 minutes usually leading to higher values.\nThe fitted curves allowed the computation of the CIOPR values for each testing seizure per patient,"}, {"title": "A. Classifier Training", "content": "The models were trained using an A100 Tensor Core GPU in Google Colab. The average training duration was 8.1 minutes per model, converging at epoch 54 due to the early-stopping callback. The training duration was significantly longer for 60- and 45-minute preictal class definitions due to increased data volume. The convergence minima for both validation and training curves varied more across patients than across intra-patient seizures or different preictal state lengths."}, {"title": "B. Classification results", "content": "Table I details the segment-wise SEN, SPE, ACC, and F1-score of the subject-specific classifiers. The displayed values represent the weighted average across all runs and testing seizures for each patient. A preictal class duration of 60 minutes generally yielded the highest average F1-scores, although 45- and 30-minute definitions performed better in certain individuals. The percentage change in F1-scores across different preictal class definitions was relatively modest, with a maximum variation of 3.2% observed in case chb05. Sensitivity scores remained consistent across various preictal durations. Fluctuations in the F1-score were primarily attributable to reductions in specificity associated with shorter preictal states."}, {"title": "C. Continuous Input-Output Performance Ratio (CIOPR) Testing Results", "content": "The proposed CIOPR in Section II-E was performed on the thirteen patients that met the criteria described in Section II-G. The first step of the analysis involved fitting the sigmoidal curve to the smoothed output of the classifiers. The Pearson correlation coefficient between the model output and the fitted curve across all the tested patients was on average $p > 0.9$ for the 60, 45, and 30-minute preictal definitions, and $p = 0.876$ for the 15-minute one. The high correlation values show the effectiveness of the chosen curve in modeling the classifiers' output profile and indicate that the models generally exhibited the intended behavior. Similar to the F1-score results, the correlation coefficients differed across patients, seizures and preictal state lengths, with 60 minutes usually leading to higher values.\nThe fitted curves allowed the computation of the CIOPR values for each testing seizure per patient,"}, {"title": "D. OPP selection and overall performance", "content": "For seizures eligible for CIOPR assessment, the OPP was determined based on the highest CIOPR values from Table II, while for the rest, it was based on the highest F1-score from Table I, as outlined in Section II-G. Overall results are summarized in Table III, which includes the OPP for each patient and corresponding performance metrics. SEN, SPE, FAR, ACC, AUC, and F1-score were computed for the selected OPP using all testing seizures as in Table I, while SPC used only the ones subject to CIOPR testing. The criterion used to select the OPP (CIOPR or F1-score) is also displayed. On average, the subject-specific models achieved a sensitivity of 99.31%, specificity of 95.34%, classification accuracy of 97.32%, and F1-score of 97.46%. The classifiers' output converged at 76.8 minutes before seizure onset,"}, {"title": "E. Statistical analysis results", "content": "The null hypothesis formulated in Section II-I was rejected with Bonferroni-corrected p-values < 0.05 for all metrics apart from NDerr (p-value = 0.388), TP (p-value = 0.135), and sensitivity (p-value = 0.161). The comparison between the 60 and 15-minute preictal periods showed significant differences in 8 of the 11 metrics assessed, followed by the 45 to 15, and 60 to 30-minute comparisons. Conversely, the smallest number of significant differences were noted between adjacent preictal definitions (15 minutes apart), particularly for the 30 to 15-minute and 60 to 45-minute pairs. CIOPR and SPC metrics accounted for the highest number of significant comparisons (4 out of 6), followed by specificity (3 out of 6), accuracy (2 out of 6), and lastly by the F1-score (1 out of 6). Detailed p-values across all the hypothesis tests performed can be found in the Supplementary Material, Table 5."}, {"title": "IV. DISCUSSION", "content": "We trained subject-specific classifiers for 19 pediatric patients of the CHB-MIT dataset to predict epileptic seizures using raw scalp EEG signals. The proposed CNN-Transformer deep learning architecture achieved a balanced accuracy of 97.32%, enabling confident seizure predictions up to 76.8 minutes prior to seizure onset on average. By introducing the CIOPR metric, we illustrated the significant impact of preictal class definition on model behavior and demonstrated how these variations can be quantified to determine the optimal preictal duration to maximize the model's usability for each individual patient.\nData augmentation in the preictal state, along with a lack of external validation, could lead to model overfitting, where classifiers memorize rather than generalize training data [4]. Although the LOOCV approach prevents the model from encountering test seizures during training, the uniform data acquisition setting and the close temporal proximity of recordings might still result in high similarity between training and testing sets [43]. Conversely, interictal data, recorded throughout the whole day, exhibit greater variability from circadian rhythms and additional EEG patterns [44], complicating their classification. This greater variability might explain the consistently lower specificity and its significant reduction with shorter preictal durations, as these entail fewer training samples.\nSome cases in our study had significantly lower performance compared to others. For instance, case chb06 exhibited a sensitivity of 94.76%, and a specificity of 73.54%, > 20% below the average. Cases chb14 and chb22 also showed notably low specificity scores. Comparison with literature suggests that cases chb06 and chb14 exhibited on average the lowest balanced accuracy across state-of-the-art studies. The same pattern was observed when comparing the reported F1-scores in [33], [34], [36], [38], [42], [45], [46]. The limited number of patients and the absence of detailed pathological data in the CHB-MIT dataset prevent further exploration of the effect of various epilepsy sub-types on seizure prediction performance. However, concordance with the literature results indicates that the aforementioned limitations are broadly applicable to the field and could inform future research directions."}, {"title": "A. Classification performance", "content": "The proposed architecture demonstrated consistent performance across multiple subjects and preictal lengths with particularly high sensitivity (> 99%). We used the balanced accuracy metric (average of sensitivity and specificity) for comparison with state-of-the-art literature [10], [32]\u2013[42] to account for variations in the preictal-interictal data ratio across studies. Our model achieved higher balanced accuracy than the aforementioned studies, by an average of 7%. While the authors in [10] reported the highest accuracy value, the absence of validation using LOOCV undermines the reported performance. To the best of our knowledge, Daoud et al. [6] have attained the highest LOOCV-validated accuracy of 99.66%. Detailed patient-level performance comparison with existing literature can be found in the Supplementary Material, Table 6. False alarms averaged 33.6 per hour on a segment-wise basis, since they were computed on the raw model output. However, the average specificity exceeded 95%, suggesting that the introduction of a post-processing scheme would significantly reduce FAR (h\u00af\u00b9) in a clinical environment.\nAlthough extended preictal periods could be expected to increase the likelihood of mislabeling interictal data, and consequently the number of false positives, the results of our study indicate the opposite. Varying preictal definitions minimally impacted model sensitivity as shown in Section III-E, whereas specificity improved with longer preictal periods. This finding aligns with the results reported in literature [10]. Furthermore, at the 0.5 decision threshold, specificity was consistently lower than sensitivity, a pattern appearing also in other studies [34], [36], [38], [40], [41].\nHigher sensitivity scores and consequent invariability to changing preictal state definitions may reflect one of the major limitations in ongoing epileptic seizure prediction research: insufficient data volume."}, {"title": "B. CIOPR alongside conventional metrics", "content": "The newly introduced CIOPR metric was used to comprehensively assess model performance and compare the effect of different preictal state definitions. Comparison with the F1-score results indicates that CIOPR is considerably more sensitive to varying preictal lengths, showing an average change of 9.2% per 15-minute decrease, compared to a 0.3% average change for the F1-score. This is also confirmed by the statistical analysis in Section III-E, where the CIOPR distributions varied significantly across four preictal length comparisons, compared to only one for the F1-score. Furthermore, in 7 out of the 13 cases that underwent CIOPR testing, there was a discordance in the best-performing preictal definition between the two metrics. This discrepancy occurred only in cases where F1-score variations were less than 1% between the two best-performing preictal definitions.\nWhile the F1-score and other conventional metrics remain useful and can guide design choices, comparing high-performing classifiers necessitates more sophisticated and sensitive measures to capture subtle behavioral differences. Figure 6 illustrates how the individual measures used to calculate the CIOPR allow a comprehensive assessment of the model's behavior for case chb16. The performance advantages of a 60-minute preictal definition \u2013 early prediction time, minimized positive and negative errors, short transition period, and alignment with the fitted sigmoidal curve representing ideal behavior \u2013 are visualized in an interpretable manner that conventional metrics lack."}, {"title": "C. Preictal length definition and model behavior", "content": "Observing the CIOPR scores and individual measures (detailed in the Supplementary Material, Table 4) across all patients enabled us to draw general conclusions about the model's behavior under different preictal state definitions. As discussed in Section IV-A, the rate of false positives increased with shorter preictal lengths, while sensitivity remained relatively constant. Conversely, CIOPR results showed that the error during negative predictions (NDerr, Section II-E) increased with longer preictal definitions. This can be explained by NDerr being measured up to 10 hours before onset, unlike specificity, which was calculated using all interictal data. However, due to the large percent variations in NDerr and the limited number of testing seizures, the effect of preictal definitions in the NDerr distributions was deemed not statistically significant.\nModels trained with longer preictal periods could detect preictal-like dynamics many hours before onset, leading to an earlier gradual increase in positive predictions: the point of inflection in the fitted sigmoidal curve occurred on average 143.1 minutes before onset for the 60-minute definition, compared to 125.3 minutes for the 15-minute definition. Statistical analysis showed that reducing the preictal length from 60 to 15 and from 60 to 30 minutes led to significantly different distributions for the point of inflection. Therefore, these early positive predictions also reflected by the increased NDerr could be related to the impending seizure. However, they could cause patient distress and be considered undesired in a clinical setting. Similarly, longer preictal definitions led to earlier convergence of the classifier output, averaging 73 minutes before onset. In combination with lower SPCerr values and higher correlation coefficients with the fitted curve, increasing the preictal length appeared to lead to more accurate predictions in the preictal state with reduced output fluctuations.\nAlthough the transition from interictal to preictal predictions occurred faster in the 45-minute model compared to the 60-minute model, this difference was not statistically significant. Longer preictal periods allow classifiers to learn spatiotemporal EEG features more distantly from the seizure onset, enhancing state transition clarity. However, the slightly faster transition observed in the 45-minute model suggests that features learned more than 45 minutes before onset might overlap with interictal features and lose relevance for prediction. Conversely, features learned within the last 30 minutes before onset achieve high prediction accuracy but may be insufficient for early identification of an impending seizure. This could lead to increased uncertainty during the transitionperiod and potentially contradictory outputs in a clinical implementation setting. This is further highlighted by the fact that among adjacent preictal definitions, the 45 to 30-minute comparison yielded the highest number of significant differences across all metrics.\nOverall, a 60-minute preictal duration achieved the highest CIOPR scores, primarily due to the tuning of the algorithm to positively reward early prediction times. However, the CIOPR metric's multi-faceted design also emphasizes reducing the prediction error, leading to an OPP of 45 minutes for cases chb01 and chb22, despite having shorter prediction times. At the OPP, seizures were accurately predicted on a patient-wise average of 76.8 minutes before the onset, which to the best of our knowledge, is the earliest reported in the literature"}, {"title": "D. Cross- and intra-patient heterogeneities", "content": "The CIOPR-related measures and their sensitivity to different preictal period lengths varied across testing seizures. This observation underscores the major challenge in epileptic seizure prediction research: inter-seizure heterogeneities, both across and within patients. These differences caused the optimal preictal period (OPP) to fluctuate between 60 and 45 minutes across patients, and in some cases (e.g., chb01, chb22) within seizures of the same patient. Cross-patient variations can be addressed by designing patient-specific models. Intra-patient variations can be managed by choosing the best average across seizures, as in our study, or selecting a different preictal length definition for each training seizure, as suggested by [5].\nThese approaches, though effective at improving the classification of interictal and preictal segments, cannot eliminate inconsistent values across measures comprising CIOPR, due to the unique electrophysiological signature of epileptic seizures. Among these measures, prediction time is of utmost importance as it directly influences alarm generation and provides a window for potential intervention. Keeping two variables among Patient ID, Seizure ID, Preictal Length fixed, and computing the mean standard deviation on the third showed that variations in prediction time could be primarily attributed to cross-patient heterogeneities (\u00b138.3 minutes), followed by intra-patient heterogeneities (\u00b117.7 minutes), and lastly, by the preictal period lengths used for training (\u00b113.2 minutes).\nThe clinical usefulness of a seizure prediction system would rely on meeting the patients' preferences in prediction time and sensitivity-specificity trade-off [3]. Researchers in [47] highlighted that patient satisfaction was maximized with short prediction times, allowing effective lifestyle changes. Long prediction times on the other hand could be more useful in a closed-loop system, allowing room for drug-delivery or stimulation [48]. However, the observed cross-patient variations suggest that prediction time is not merely a matter of preference but is intrinsically linked to the preictal characteristics of each patient. Additionally, intra-patient variations, although less pronounced, could significantly impact the effectiveness of seizure predictions. For instance, in case chb09, the SPC ranged from 63.9 to 125 minutes.\nA reliable system should predict seizures earlier than a minimum seizure prediction horizon (SPH) with fluctuations not exceeding the seizure occurrence period (SOP), such that prediction times range within the [SPH,SPH+SOP] interval [49]. SPH should be large enough to allow clinical intervention (e.g., 30 minutes in [49]), while SOP could be limited to the duration of the treatment; e.g., 30 minutes for some anti-epileptic drugs [49]. Cross-patient heterogeneities could enable setting a realistic SPH interval, informed by both the patient's preferences and the electrophysiological signature of the preictal state. Case chb04 for instance exhibited SPC values of 133.3 and 217.5 minutes before the onset. A 30-minute SPH selection would hence prove non-practical for this case, as it would require a SOP of at least 3 hours, leading to increased uncertainty for the patient. Similarly, understanding intra-patient heterogeneity patterns could allow providing realistic SOP intervals for each individual. For instance, at the OPP, case chb07 experienced considerably less variations in prediction time (\u00b14.7 minutes) than case chb09 (\u00b130.6 minutes)."}, {"title": "E. Limitations and future work", "content": "Besides the aforementioned risk of overfitting, performance results could be affected by data leakage, a prevalent issue in machine learning-related research [50]. In particular, the LOOCV approach might introduce temporal leakage, due to the inclusion of \"future\" data (i.e., seizures) in the training process. For example, a model trained on seizures No. 1, 3, 4, 5 and tested on seizure No. 2 had access to information that occurred both before and after the test seizure, potentially introducing temporal dependencies between the training and testing sets. This information would not be available in a realistic implementation setting and could inflate the observed performance.\nFurthermore, the classifiers' output behavior was not uniform across all subjects and seizures, introducing limitations in the generalizability of the CIOPR metric. Convergence did not always occur right before seizure onset (Figure 3b), while in several cases, persistent output fluctuations complicated the identification of the SPC start (Figure 3d). Additionally, the TP was directly computed from the fitted curve, making it dependent on the quality of the fitting. Figure 5 highlights the issue, where small variations in model behavior caused large differences in the stretch of the sigmoidal curve and consequently in the calculated TP. Lastly, the penalty introduced due to long transition periods was dependent on the interictal duration, ND, inhibiting direct comparisons across different seizures.\nFuture efforts should prioritize improving the quality of EEG datasets. Extended recording times and longitudinal acquisitions are necessary to assess algorithms' generalizability over time. Such a dataset could alleviate the need for the LOOCV approach and consequently mitigate data leakage issues. Reporting pathological information, such as the location of the seizure onset zone, clinical semiology, and epilepsy sub-type, would be crucial in drawing clinically relevant conclusions, including which seizure sub-types could be more challenging to predict. Additionally, it could enable an understanding of preictal state-related heterogeneities across seizures and patients. Unraveling those patterns could enable tailored identification of SPH and SOP intervals, that could be dynamically adjusted during the course of the day, depending on the individual and epilepsy pathology. This would ultimately lead to providing context-aware warnings and improving the clinical reliability of automated seizure prediction models.\nThe proposed solution would also benefit from developing a channel-selection algorithm at the input stage, as suggested by authors in [36]. Furthermore, implementing a post-processing scheme to filter out incorrect predictions and generate confident alarms would be useful. Clinically relevant metrics such as FAR (h\u00af\u00b9) should then be computed on the post-processed output and reported for a predefined SPH and SOP. While the CIOPR algorithm prioritizes prolonged prediction times, future improvements should tune it to emphasize convergence within the preferred [SPH,SPH+ SOP] range. Consistent EEG datasets will enable benchmarking on achieved CIOPC values by fixing the input signal duration and the contribution of each term"}, {"title": "V. CONCLUSIONS", "content": "We introduced a CNN-Transformer model for predicting epileptic seizures using scalp EEG signals and proposed the novel Continuous Input-Output Performance Ratio (CIOPR) metric. Using the CIOPR metric we established that varying preictal period lengths result in statistically significant differences in model behavior. Overall, increasing the preictal length led to earlier prediction times, sharper interictal-preictal transitions, and reduced output fluctuations in the preictal state, at the expense of an increased volume of positive predictions several hours before the onset. This finding highlights the need for careful selection of the OPP depending on the desired usability.\nTo the best of our knowledge, this is the first study that uses a fitting curve to model the output of a seizure prediction classifier. The newly introduced CIOPR metric provides interpretability on model performance that conventional metrics lack, by outlining how the distribution of positive predictions varies over time. With the increasing complexity and classification capabilities of deep learning architectures, more intuitive and sophisticated measures are required to capture subtle performance differences. Integrative measures like CIOPR, apart from being useful in selecting the most suitable deep learning model, they can provide meaningful clinical insights and shed light on future research directions."}]}