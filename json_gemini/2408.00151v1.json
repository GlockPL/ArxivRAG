{"title": "Moderating Group Conversation Dynamics with Social Robots", "authors": ["Lucrezia Grassi", "Carmine Tommaso Recchiuto", "Antonio Sgorbissa"], "abstract": "This research investigates the impact of social robot participation in group conversations and assesses the effectiveness of various addressing policies. The study involved 300 participants, divided into groups of four, interacting with a humanoid robot serving as the moderator. The robot utilized conversation data to determine the most appropriate speaker to address. The findings indicate that the robot's addressing policy significantly influenced conversation dynamics, resulting in more balanced attention to each participant and a reduction in subgroup formation.", "sections": [{"title": "I. INTRODUCTION", "content": "Social robotics focuses on creating and applying robots designed to engage with humans in social environments. The use of social robots in group interactions is attracting increasing interest due to the growing need for these robots to engage with multiple users simultaneously. This includes scenarios such as robots participating in discussions with several individuals [9], facilitating social interactions [20], and engaging in social games [14].\nRobots capable of engaging with multiple people can en- hance user experiences by making interactions more com- pelling and natural. This can lead to higher user satisfaction and improved accessibility and inclusivity, as highlighted by [21]. However, at present, few robots can engage with multiple users simultaneously. This is due to the many factors that need to be considered in these situations. A system described in [23] examines the tracking and fusion aspects of multi-party interactions but only monitors user entry and exit and can accurately identify only two users. A spoken dialogue system like the one in [13] can identify multiple users using data from a Kinect sensor, but its conversational abilities are limited, and it struggles with long, natural conversations involving multiple parties. Additionally, it can only engage one person at a time. Similar limitations are observed in the work of [12], which aims to develop a multi-user engagement policy for managing turn-taking using the robot's gaze, head movements, and verbal communication.\nWhenever the robot interacts with multiple people, the \"many minds problem\" arises [4]. As the number of par- ticipants increases, basic conversational mechanisms such as turn-taking, speaking time, and listener feedback become more complex. Although turn-taking is a fundamental aspect of communication, researchers continue to study how speakers signal the end of their turn and indicate who they are ad- dressing, as well as how listeners recognize when it is their turn to speak. This is accomplished through behaviors such as gaze, head orientation, and intonation, which have been studied by various scholars, including [5, 7, 18]. Speakers typically use gaze to select the next speaker, known as the \"addressee\" [3, 1, 22]. The selection of the addressee is a crucial issue in group conversations, requiring speakers to make quick decisions that consider the potential reactions of other participants.\nFurthermore, the robot needs to comprehend the participa- tion levels of the users it is interacting with. Dominance, a key concept in social interactions, plays a significant role in this understanding and has been extensively studied in social psychology [8, 2]. Dominance can pertain to an individual's traits or their hierarchical status within a group. Indicators of dominance are categorized into vocalic and kinesic types. Vocalic indicators include factors such as speaking time, word count, and speech loudness (or energy) [19]. Speaking activity, especially the duration of speech, is a strong predictor of dominance. Kinesic indicators involve body movement, posture, facial expressions, and eye gaze [6]. Dominant indi- viduals generally exhibit more movement and a broader range of motion than non-dominant individuals, and their gestures during speech are positively associated with dominance [2].\nThis paper presents a study that aims to investigate and regulate the dynamics of group conversations involving a so- cial robot. In such interactions, participants may have varying"}, {"title": "II. METHODOLOGY", "content": "roles and personalities, leading some individuals to dominate the conversation while others may feel excluded. Ensuring balanced participation is essential to make everyone feel included and engaged.\nTo manage the dynamics of the conversation, particularly when it is crucial for all participants to feel like part of a cohesive group, we implemented four different control policies that leverage the concepts of dominance and communities. To validate these policies, we tested them against a baseline policy. We conducted 75 experiments involving a total of 300 participants, where a humanoid robot engaged in conversations with groups of four individuals. Figure 1 depicts the robot interacting with the participants in one of the experiments. Throughout these experiments, the robot collected quantitative data to analyze participation levels, identify distinct subgroups (i.e., communities) of participants, and evaluate the overall conversation dynamics. This information allows the robot to act as a moderator, promoting active participation in the conversation.\nThe article is structured as follows. Section II provides an overview of the system architecture and the developed control policies. Section III describes the experimental setup and discusses the findings. Finally, Section IV presents the conclusions.\nA. System Architecture\nThe robot's ability to converse autonomously with multiple people is enabled by CAIR (Cloud Artificial Intelligence and Robotics), a cloud software architecture specifically designed for autonomous conversation [17, 10]. This system relies on a framework for knowledge representation, utilizing an ontology implemented in OWL2. Conversation topics and related sentence pieces are dynamically composed at runtime using the hierarchical structure of the knowledge base.\nThe CAIR server comprises a set of web services, as illustrated in Figure 2. The Dialogue Manager service manages the conversation and identifies the user's intent to discuss specific topics, while the Plan Manager service interprets the user's intent to direct the robot to perform particular actions. To generate appropriate responses and plans, the server uses an Ontology that includes all the topics, keywords, sentences, and plans used during interactions with users [16, 11]. An additional service called Hub handles all incoming requests by forwarding them to the Dialogue Manager and Plan Manager services. Information exchange between the CAIR client and server is facilitated through the dialogue state, which tracks the conversation's history and includes discussed topics, preferred topics based on user input, and previously spoken sentences to avoid repetition.\nTo enable multi-party interaction, the original architecture described in [10] has been enhanced with two new services: the Registration service and the Audio Recorder service. The Registration service is activated when a new user initiates registration, creating a new profile ID linked to the user's voice. The Audio Recorder service starts recording audio when", "B. Control Policies": "the Root Mean Square (RMS) of the noise exceeds a specific threshold, sending the audio to the Speech Recognition API for transcription and to the Speaker Recognition API to identify the speaker's profile ID.\nThe dialogue state has been expanded to support multi-party interaction, incorporating data related to the speakers along with dialogue statistics. These include a matrix tracking the number of times one speaker talked after another in successive turns, the total number of turns for each user, the average topic distance between speakers, the a priori probability that a speaker will talk, and a moving window that tracks the information related to speakers' turns. The moving window maintains the most recent conversation turns within a duration equal to M. For each turn, it records the speaker's ID, speaking time, and word count. When the total speaking time in the moving window exceeds M minutes, the earliest turn is removed, and the latest one is added (FIFO queue).\nB. Control Policies\nThe information contained in the moving window has been used to develop two policies aimed at controlling different aspects of group dynamics.\n1) Balancing Policy: The Balancing policy exploits the data from the moving window to determine which speaker to address. Its goal is to identify and engage with the user who is least active in the conversation (i.e., the submissive user). Conversation participation is quantified using a metric $D_i$, which considers both speaking time and word count, as these are the most significant indicators of dominance [19]. \u03a4\u03bf calculate $D_i$ for each speaker $S_i$, we measure the percentage of their speaking time ($T_i$) and word count ($W_i$) within the moving window. The metric $D_i$ is then computed as:\n$$D_i = \\gamma_1 T_i + \\gamma_2 W_i,$$ (1)\nwhere $\\gamma_1$ and $\\gamma_2$ are weights representing the relative im- portance of speaking time and word count in determining dominance. The speaker addressed by the Balancing policy is $S_m$, where:\n$$m = \\text{arg min}(D_i).$$ (2)"}, {"title": "III. EXPERIMENTS AND RESULTS", "content": "There are two versions of this policy: the \"hard\" version (BH) and the \"soft\" version (BS). In the hard version, if a user other than the intended one responds, the robot ignores the response and repeats the question to the intended user. In contrast, the soft version accepts responses from any user, replies accordingly, and then readdresses the intended user with the original question.\n2) Community Policy: The Community policy is based on the hypothesis that it is possible to identify sub-groups (i.e., communities) among participants in a conversation. To identify these communities, we use the probability that one speaker talks after another, assuming that members of the same community tend to speak consecutively. This probability is derived from the matrix in the dialogue state, which tracks the frequency with which each speaker follows another. This data is represented in a matrix and then converted into an undirected graph, where nodes represent speakers and edge weights represent probabilities. The Louvain algorithm is applied to this weighted graph to find the optimal partitioning of nodes into communities [15]. Once the best partition is identified, the policy uses this information to address a random speaker from a different community at each turn. The goal is to maintain a single cohesive conversation and prevent speakers from dividing into sub-groups. Similar to the Balancing policy, both a hard (CH) and a soft (CS) version have been developed for the Community policy.\nFinally, it is important to note that the policy to be used by the system can be selected before the start of the interaction.\nIII. EXPERIMENTS AND RESULTS\nThe experiments were conducted at the \"Parini Merello\" middle school in Genoa, where we brought the humanoid robot Pepper, equipped with the CAIR cloud client. Approval was obtained from the University of Genoa's ethical committee, and consent forms were signed by the parents of all partici- pating first and second-grade students. A total of 300 students participated, divided into 75 groups of four. Each group took part in an experiment where the robot used one of the five developed policies, resulting in five types of experiments with 15 groups per experiment.\nTo establish a baseline, 15 groups interacted with the robot using a Neutral policy (N). The remaining groups were equally split among the other four policies. Participants registered to CAIR using their voices and then interacted freely with the robot for 15 minutes. They were unaware of the specific policy in use and could respond at their discretion. This approach ensured spontaneous and natural interactions. Each experiment required approximately 5 minutes for registration and 15 minutes for interaction with the robot. To ensure the privacy of the participants, all their personal information, including name, gender, and biometric data related to their voice, was promptly deleted after each experiment.\nFor the control groups (N), no specific results are expected, as this baseline represents the robot not attempting to influence the conversation dynamics. In contrast, for the first and second experimental groups (BH and BS), we anticipate that the robot will successfully \u201cbalance\u201d participation, ensuring all participants are included equally in terms of speaking time and word count. For these experiments, we set the weights $\\gamma_1 = \\gamma_2 = 0.5$. The third and fourth experimental groups (CH and CS) introduce the concept of community, aiming to demonstrate the robot's ability to unify any emerging sub-groups among the participants."}, {"title": "IV. CONCLUSION", "content": "This paper explored the effective management of group conversations involving a social robot. Motivated by the need for systems that handle multi-party interactions, the proposed system recognizes users, engages them in dialogue, and applies policies to ensure balanced participation and foster a sense of community. This system has diverse applications in healthcare, entertainment, and education, where multi-person interaction can enhance user experience.\nWe implemented and tested four control policies: Balancing Hard (BH), Balancing Soft (BS), Community Hard (CH), and Community Soft (CS). These were evaluated against a baseline in 75 experiments with a humanoid robot and 300 participants grouped in sets of four. The robot moderated the conversations, applying policies to balance speaking time and word count and reduce subgroup formation. Results showed that the policies effectively managed group conversation dynamics as intended."}]}