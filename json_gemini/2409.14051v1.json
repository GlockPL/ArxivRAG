{"title": "GroupDebate: Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion", "authors": ["Tongxuan Liu", "Xingyu Wang", "Weizhe Huang", "Wenjiang Xu", "Yuting Zeng", "Lei Jiang", "Hailong Yang", "Jing Li"], "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse NLP tasks. Extensive research has explored how to enhance the logical reasoning abilities such as Chain-of-Thought, Chain-of-Thought with Self-Consistency, Tree-Of-Thoughts, and multi-agent debates. In the context of multi-agent debates, significant performance improvements can be achieved with an increasing number of agents and debate rounds. However, the escalation in the number of agents and debate rounds can drastically raise the tokens cost of debates, thereby limiting the scalability of the multi-agent debate technique. To better harness the advantages of multi-agent debates in logical reasoning tasks, this paper proposes a method to significantly reduce token cost in multi-agent debates. This approach involves dividing all agents into multiple debate groups, with agents engaging in debates within their respective groups and sharing interim debate results between groups. Comparative experiments across multiple datasets have demonstrated that this method can reduce the total tokens by up to 51.7% during debates and while potentially enhancing accuracy by as much as 25%. Our method significantly enhances the performance and efficiency of interactions in the multi-agent debate.", "sections": [{"title": "Introduction", "content": "Large language Models (LLMs) such as GPT [1, 4, 5, 25, 26], LLaMa [31, 32], and PaLM [2, 7] have demonstrated remarkable capabilities in various downstream tasks. These models can reach or even exceed human performance in a range of NLP tasks but their performance is still limited in complex mathematical and logical reasoning tasks [21]. To address these limitations, researchers have proposed Chain-of-Thought [17, 35, 23] that generates the reasoning process step by step. Subsequent research has introduced such as the Tree-of-Thoughts [38], Graph-of-Thoughts [3], and the use of Verification [20] to further enhance the ability to perform complex multi-step reasoning. Unfortunately, these single-agent methods are more likely to fall into random fabrication of facts or the generation of delusions, thus leading to erroneous outcomes in multi-step reasoning processes [5, 14, 15]. The multi-agent debate methods mitigate these issues by allowing different agents to express their arguments to each other and these approaches have demonstrated considerable potential and effectiveness across various types of tasks and datasets [6, 9, 19, 29, 33, 36, 37].\nHowever, as the number of agents and rounds increases, the token cost in multi-agent debate can escalate significantly. This issue results in monetary expenditure on tokens through LLM-based API or substantial computational overhead and power consumption, thereby severely hindering the scalability and broader application of multi-agent debate, especially in scenarios with limited computational resources [11]. As illustrated in the Figure 1, compared with a single LLM-based agent, employing a multi-agent debate with three agents in five rounds can potentially raise the accuracy from the initial 50% to 98%, but introduces 101x token cost in the Arithmetic [4] task. Similarly, in the GSM8K [8] task, five rounds of multi-agent debate involving four agents can raise the accuracy from 76% to 88%, but it results in 90x token cost. To address the issue of the rapidly increasing number of tokens in multi-agent debates, researchers have proposed various improved techniques. For instance, the multi-agent debate in [9] summarizes the output of other agents to serve as the input for the next round. [29] proposes a \"forgetfulness\" mode that only the output from the previous round is stored as input for the next round. However, only employing a \"forgetfulness\" mode or summary mechanism to reduce token cost is still limited due to their theoretical complexity and the issue of exacerbated token growth. Moreover, owing to their simplistic debating modes, they struggle to fully exploit the collaborative capabilities of multi-agent debates.\nIn human societies, when multiple individuals engage in a debate, the group discussion method is usually employed to enhance the efficiency of interaction while also preserving the diversity of viewpoints [18]. Inspired by this, in this paper, we propose a novel method GroupDebate (GD), which is based on group discussion to further reduce token cost in multi-agent debates. Specifically, Our method divides all participating agents into several debate groups, with each group conducting internal debates. Following the debates, the results are summarized and placed into a shared pool. After that, each group of agents retrieves the debate summaries of all groups from the pool, which serve as the input for the agents in the next round. Upon the conclusion of the debate, all agents reach a consensus or the final outcome is determined by majority vote. Furthermore, we conduct a theoretical analysis of the total token cost of the GroupDebate, thereby affirming the effectiveness of the method. In our experiments, we evaluate the effectiveness of GroupDebate in comparison to existing multi-agent debate methods and observe up to 45%/42.6%/50.6%/51.7% reduction in token cost in the Arithmetic/GSM8K/MMLU/MATH dataset, as well as up to 25%/11% improvement in accuracy in the MMLU/MATH dataset. Moreover, compared with methods such as CoT, Reflection, and CoT-SC, GroupDebate also significantly outperforms them in terms of accuracy.\nThe main contributions of this paper are as follows:\n1. We propose an innovative multi-agent debate strategy based on group discussion which can improve the efficiency and performance of multi-agent debates.\n2. We conduct a theoretical analysis of token cost based on our method, demonstrating its efficiency and effectiveness.\n3. Extensive experiments across four logical reasoning and mathematical datasets show that our method can not only significantly reduce token cost but also potentially enhance accuracy, validating the efficiency and superiority of our method."}, {"title": "Preliminaries", "content": "In the context of multi-agent debates (MAD), by integrating multiple LLMs (each treated as an individual agent) and using various collaboration strategies, agents can propose viewpoints, review, and respond to the results of other agents in multiple rounds of debates [6, 29, 30]. The process of MAD can be summarized as follows: (i) At the beginning, each agent is provided with a question and generates an individual response; (ii) These responses then form the new input context for each agent, and the agents generate new responses; (iii) This debate procedure is repeated over multiple rounds and the final answer is obtained through majority voting. Throughout multi-agent debate procedure, all agents can consistently improve their own responses based on the responses of other agents. In order to reduce input context length, [9] proposes that after collecting the responses from other agents, the responses should first be summarized and then used as the new input context for each agent. Figure 2 shows an example of two-round debates among three agents. In the first round, each agent independently responds to the input and their outputs are collected and summarized. In the second round, each agent's input includes summaries from the previous round, which are combined with a prompt to guide the output. Ultimately, all agents reach a consensus conclusion."}, {"title": "Token Cost Problem in Multi-agent Debate", "content": "In the Figure 1, we can observe that although an increase in the number of agents and rounds can significantly enhance accuracy, the sharply increasing token cost is still a serious challenge in multi-agent debate. We analyze this based on the Simultaneous-Talk interaction strategy [6]. In this strategy, each agent synchronizes their results with other agents in each round of the debate. We separately scrutinized the changes in token cost brought about by increases in the number of agents and the number of rounds. From Figure 3, it can be observed that under 4 rounds, as the number of agents increases from 1 to 8, the token cost in GSM8K/Arithmetic/MMLU has respectively grown by 36x/44x/49x. Similarly, under 4 agents, as the number of rounds increases from 1 to 4, the token cost in GSM8K/Arithmetic//MMLU has respectively increased by 17x/29x/19\u00d7. These findings reveal that as the number of agents and rounds increases, the token cost also significantly rises."}, {"title": "Methodology", "content": "In this section, we first introduce the overall framework of our GroupDebate. Subsequently, we provide mathematical analysis of the token cost for both MAD and our GroupDebate. Formally, assume there are M LLM-based agents, denoted as A = {A\u1d62 | i = 1, 2, ..., M}, participating in a multi-round debate, with the total number of debate rounds denoted as T. In each round t (t = 1, 2, ..., T), the output of each agent A\u1d62 is represented as Output\u1d62\u1d57. The tokens of the initial question prompt are denoted as Q. These notations will be used throughout this paper."}, {"title": "GroupDebate", "content": "We have M agents A = {A\u1d62 | i = 1, 2, \u2026\u2026, M}, which can be randomly divided into N groups G = {G\u2c7c | j = 1, 2, \u2026\u2026\u2026, N}, with average K agents in each group. The GroupDebate splits the total debate rounds into S stages, with each stage encompassing R rounds. Thus, the total number of rounds T can be calculated as T = S \u00d7 R. For the s-th stage's r-th round, GroupDebate selects one of the following processes:\n(1) Initial Thinking. If s = 1 and r = 1 (i.e., the first stage's first round), we input the initial question prompt Q to each agent.\n(2) Inta-group Debate. If r > 1, we utilize the outputs from other agents within the same group as the input for each agent.\n(3) Inter-group Debate. If s > 1 and r = 1, we merge the outputs from the last round in each group into a summary and input the summaries from other groups to each agent.\nMeanwhile, inspired by [29], we summary the responses from other groups and restrict each agent to receive the latest summary from the previous stage in the inter-group debate. After the S-th stage's R-th round, all agents vote, and the ultimate result is determined by the majority selection. The detailed GroupDebate process can be found in Appendix A. The Figure 4 illustrates an example of GroupDebate consisting of two stages and two groups. In the first stage, two agents in each group receive the initial question and exchange ideas within the group. In the second stage, agents share the summaries of their respective groups between groups and then discuss within their own groups again."}, {"title": "Token Cost Analysis", "content": "We implement the summary mechanism in MAD following [9], where we summarize the output of other agents as the input for each agent in the next round. The summary for agent A\u1d62 in round t is denoted as Summary\u1d62\u1d57. We define the token cost in the summary generation after each round t as Token\u02e2\u1d58\u1d50\u1d50\u1d43\u02b3\u02b8\u1d57. And token cost in each round t can be computed as follows:\n\\begin{equation}\nTokent = \\begin{cases}\n\\sum_{i=1}^{M}(Q+Output_i^t), & t=1 \\\\\nTokent^{-1} + \\sum_{i=1}^{M}(Summary_i^{t-1} + Output_i^t), & t>1\n\\end{cases}\n\\end{equation}\nFinally, the total token cost in MAD is Token\u1d39\u1d2c\u1d30 = O (MTQ + (M\u00b2T + MT\u00b2)C), where C represents the upper bound on the token number for each agent's response and the generated summary. More mathematical details are illustrated in Appendix B.1."}, {"title": "Token Cost in GroupDebate", "content": "In GroupDebate, we summary the outputs from other groups at the end of each stage. Here, we define the summary of group G\u2c7c at the end of stage s as Summary\u2c7c\u02e2. We define the token cost in the summary generation after each stage s as Token\u02e2\u1d58\u1d50\u1d50\u1d43\u02b3\u02b8\u02e2. And token cost in round t at stage s is\n\\begin{equation}\nToken_t^s = \\begin{cases}\nM \\times Q + \\sum_{i=1}^{M}Output_i^t, & t=1 \\\\\n\\sum_{j=1}^{N} \\sum_{i \\in G_j} (Q+Output_i^{t-1} + \\sum_{i' \\in G} Summary_i^{t-1} + Output_i^t), & t = (s - 1)R + 1 \\\\\n\\sum_{j=1}^{N} \\sum_{i \\in G_j} (Q+Output_i^{t} - Output_i^{t-1}), & (s-1)R + 1 < t <= min(sR,T)\n\\end{cases}\n\\end{equation}\nFinally, the total token cost of GroupDebate is Token\u1d33\u1d30 = O (MTQ + (M\u221aT + MSN)C), where C represents the upper bound on the token number for each agent's response and the generated summary. More calculation details are shown in Appendix B.2.\nFrom the overall token cost complexity perspective, GD and MAD exhibit the same level of complexity regarding the input token cost of the question prompt Q, suggesting an equal impact on both methods. In our GroupDebate, given fixed values for T and M, the number of groups N and the total number of stages S can be dynamically adjusted. When we set N \u2192 O (\u221aMT/S), theoretically, we can obtain Token\u1d33\u1d30 \u2192 O (MTQ + \u221aM\u00b3TSC). This complexity is significantly lower than that of MAD. If we consider setting S to a small positive integer, treating it as a constant, then Token \u1d33\u1d30 can further approach O (MTQ + \u221aM\u00b3TC). Moreover, in fact, N and S also influence the diversity in multi-agent debate, affecting the accuracy of the debate results, which will be further studied in Section 4.3."}, {"title": "Experiments", "content": "To demonstrate the accuracy and effectiveness of different methods, we adopt total token cost, accuracy (ACC) as evaluation metrics. Additionally, we select four representative tasks related to logical reasoning and mathematical tasks to evaluate our methods, namely Arithmetic [4], GSM8K [8], MMLU [12], and MATH [13]."}, {"title": "Experimental Setup", "content": "We conduct a comparison of the efficiency and accuracy between GroupDebate (GD) and the following methods: (1) Chain-of-Thought (CoT) [35]. (2) Reflection [27], with the trail number set to 3. (3) Self-Consistency with Chain-of-Thought (CoT-SC) [34], where CoT-SC(40) represents CoT-SC with 40 reasoning paths. (4) multi-agent debate (MAD) [19], to ensure fair comparisons, we also conduct the experiment of the MAD under various agent and round configurations. Both GD(5,3) and MAD(5,3) indicate the use of 5 agents and 3 rounds.\nWe set the number of rounds of intra-group debate to 2 in GD. Additionally, we only retain output from the last round or summary generated from the last stage. Our experiments are conducted using the GPT-3.5-turbo-0301 language model [24]. In order to prevent the input prompt token exceeding the GPT-3.5 limit, the MAD defaults to using the summary [9]. For all baselines and GD, we conduct ten sets of tests separately, calculate the average, and mark the range of variation. We evaluate these methods in a zero-shot setting, and the details about prompts are illustrated in Appendix D."}, {"title": "Main Results", "content": "In this section, we conduct a detailed comparison of GD with MAD as well as other single-agent methods including CoT, Reflection and CoT-SC(40). In the MATH dataset, MAD can not produce results in both (6,3) and (6,4) scenarios due to the prompt tokens exceeding the GPT-3.5 limit. The main observations are as follows:\nFirst, as illustrated in Figure 5, GD consistently reduces token cost under different agent and round settings, achieving up to 45%/42.6%/50.6%/51.7% reduction in token cost in the Arithmetic/GSM8K/MMLU/MATH datasets. This demonstrates that our method can effectively reduce token cost in multi-agent debate while being theoretically grounded."}, {"title": "Comparison Between GD and MAD.", "content": "Second, GD also improves accuracy in all different settings, achieving up to 25%/11% improvement in accuracy in the MMLU/MATH dataset, which suggests GD can enhance accuracy in multi-agent debate while reducing token cost."}, {"title": "Comparison Between GD and Other Single-Agent Methods.", "content": "As shown in Figure 6, GD(5,3) and MAD(5,3) can significantly enhance the accuracy across all four datasets. This is because using multi-agent debate allows multiple agents to exchange ideas with each other, ensuring diversity. Secondly, multi-agent debate methods generally incur higher token cost compared to single-agent methods, indicating a significant challenge in reducing token cost while maintaining superior accuracy in multi-agent debates. Our method takes a further step and achieves significant advantages in both token cost and accuracy compared to MAD(5,3) under the same settings. This highlights the superiority and effectiveness of our method in multi-agent debates."}, {"title": "In-Depth Analysis of Different GroupDebate Strategies", "content": "In order to investigate the impact of different group strategy on accuracy and token cost, a comparison was made under the conditions of 6 and 8 agents with 4 rounds in the MMLU dataset. As illustrated in the Figure 7, as the groups becomes more refined, the accuracys increase and token cost decreases. And the group strategy of (2,2,2,2) compared to the group strategy of (4,4) results in a total token decrease of 10% and an accuracy increase of 17%."}, {"title": "Group Strategy.", "content": "To explore the impact of the number of intra-group debate rounds, we conduct analysis under the condition of 4 agents and 4 rounds with varying numbers of intra-group debate rounds. As shown in Figure 8, best accuracy can be achieved when the number of intra-group debate rounds R is 2. This suggests that brief intra-group discussion can achieve better accuracy. Moreover, as R increases, the number of stages S decreases, resulting in lower token cost, which aligns with our derived complexity formula."}, {"title": "Scaling Study", "content": "In order to explore the influence of rounds and agents on accuracy under MAD and GD, we evaluate the changing trends of accuracy for MAD and GD under various rounds and agents. As shown in Figure 9, with the increase in rounds, there is a significant growth in accuracy, but when rounds exceeds 4, a decrease in accuracy is observed across different numbers of agents. This reflects the phenomenon that limited increase in rounds can enhance accuracy, but excessive debate rounds can lead to accuracy degradation. As the number of agents increases, there is a significant growth in accuracy, indicating that an increase in agents can notably enhance the accuracy for both MAD and GD. Concurrently, it should be noted that the rate of improvement in accuracy tends to gradually decelerate as the number of agents continues to rise. The experimental results indicate the importance of controlling the appropriate number of agents and rounds."}, {"title": "Agent and Round Scaling.", "content": "We assess the scaling trends of token cost and accuracy under both MAD and GD through increasing rounds or agents. First, as illustrated in Figure 10, with the increase in token cost, both MAD and GD exhibit an overall upward trend in accuracy. And initially the accuracy increases rapidly, but as the token cost becomes very large, the rate of accuracy growth slows down. Moreover, in comparison between MAD and GD, GD consistently outperforms MAD with scaling of tokens across all four datasets. While MAD's accuracy tends to converge as the token cost becomes exceedingly large, GD still potentially exhibits a growing trend. And we notice that GD has more sharply increasing points, which may be indicative of emergent intelligence in the token scaling in GD. It's an intriguing research point to explore scaling laws about accuracy and efficiency within multi-agent debate."}, {"title": "Token Scaling.", "content": "Numerous research have explored to enhance the logical reasoning capabilities of LLMs. Chain-of-Thought [35] is conducted in a manner that mirrors human thought processes when tackling complex issues, utilizing a step-by-step approach. Tree-of-Thoughts [38] allows LLMs to determine their next course of action by considering various reasoning paths and self-evaluation choices. Graph-of-Thoughts [3] represents the nonlinear task resolution process of LLMs as an arbitrary graph, where ideas are represented as vertices, and the dependencies between these ideas form the edges. Additionally, the use of verification [20] and feedback recording are used to enhancement reasoning capabilities. STaR [39] generates multiple chains of thought, from which effective ones are selected. [28] involves creating a pool of CoT candidates and selecting the optimal candidate based on certain conditions. [40] proposes a method for selecting the optimal prompt from the candidate set. Skeleton-of-Thought [22] firstly generates skeleton of answer, followed by the parallel complete of content for each point in the skeleton, thus accelerating answer generation. Table-of-Thoughts [16] enhances the accuracy of reasoning through the structured modeling of the reasoning process. Self-Consistency with CoT [34] samples a set of reasoning path and selects the most consistent answer."}, {"title": "Related Work", "content": "In multi-agent collaboration, the multi-agent debate approach has been demonstrated as an effective orthogonal enhancement in logical reasoning. [19] proposes a Multi-Agent Debate (MAD) framework that encourages divergent thinking in LLMs, where a judge manages the debate and obtain a final solution. [36] focuses on common sense reasoning and conduct the debate align with real-world scenarios. [9] utilizes debates among multiple agents to enhance accuracy, and investigates the impact of the number of agents and rounds of debate on accuracy. [37] proposes a multi-agent collaboration strategy that simulates the academic peer review process, allowing different models to correct each other. It demonstrates that feedback exchange is superior to simple solution sharing. [33] integrates a prior knowledge retrieval into the debate process, thereby enhancing reasoning capabilities. [10] employs autonomous enhancement of negotiation strategies using a multi-round negotiation game exploration model with two agents. [6] presents various communication strategies and evaluates the effects of these differing approaches. Corex [29] employs collaborative methods such as debate, review, and retrieve among multiple agents."}, {"title": "LLM Reasoning", "content": "Although GroupDebate can bring about notable accuracy improvements on the MMLU and MATH datasets, the first key limitation is that we have not delved into the underlying reasons and the optimal settings of N and S. We only theoretically analyze the constraints of N and S required to achieve optimal token cost complexity. However, determining the optimal values of N and S also requires considering accuracy to maximize it under the same token cost, which is very complex. It necessitates the integration of further evaluations and experiments to deduce the theoretical basis for the enhancement of accuracy and optimal settings in GroupDebate. Furthermore, although GroupDebate can significantly reduce token cost in muti-agent debates, its token cost is still higher than single-agent methods like CoT. It is necessary to explore more ways to further reduce token cost while ensuring high accuracy, which is crucial for their widespread application."}, {"title": "Multi-agent Debate", "content": "In this paper, we investigate the token cost issue in multi-agent debates, a critical challenge that limits the scalability of multi-agent debate. We propose a novel GroupDebate method, which leverages the group discussion to mitigate this issue while fostering a diverse range of viewpoints. Specifically, we divide all participating agents into several debate groups, where each agent can engage in both intra-group debates and inter-group exchanges of ideas. Experimental results across four logical reasoning datasets demonstrate GroupDebate can significantly reduce token cost as well as enhance accuracy in multi-agent debates. In the future, we will further explore the theorem of how group discussion can improve accuracy and theoretically determine the optimal settings in GroupDebate."}, {"title": "Limitations", "content": "In this section, we aim to provide a theoretical analysis of the token cost for both MAD and GD. As LLMs' outputs typically are not too long and we can actually control the token length of LLMs' outputs in prompts to some extent, we assume that the upper bound on the number of tokens output by each agent participating in debate is Output\u2098\u2090\u2093 and the upper bound on the number of tokens in the generated summary is Summary\u2098\u2090\u2093. We define C as the maximum of Output\u2098\u2090\u2093 and Summary\u2098\u2090\u2093."}, {"title": "Conclusion", "content": "Here, we implement the MAD method, which summarizes the responses from other agents and inputs all previous summaries for each agent in each round. The token cost includes both input and output cost, and in each round t, it can be divided into two parts: summary generation Token\u02e2\u1d58\u1d50\u1d50\u1d43\u02b3\u02b8\u1d57 and agents' responses Tokent. Thus, the total token cost Token\u1d39\u1d2c\u1d30 can be represented as:\n\\begin{equation}\nToken^{MAD} = \\sum_{t=2}^{T} Token^{t} + (Token^{summary} + Tokent)\n\\end{equation}\nSpecifically, we provide a detailed description of the token cost for each part. (1) summary generation: The token cost for each agent includes the output from other agents and output summary. (2) agents' responses: If t = 1, the token cost for each agent includes the initial question prompt and its own output. If t > 1, the token cost for each agent includes the current summary, its own output, and the total token cost of all its previous inputs and outputs. The detailed computation process of the token cost in MAD can be found in Algorithm 2."}, {"title": "Token Cost Analysis", "content": "Following the line 7 in Algorithm 2, with Output\u1d62\u1d57 < Output\u2098\u2090\u2093 and Summary\u1d62\u1d57 < Summary\u2098\u2090\u2093 for every t and i, we can infer the following:\n\\begin{equation}\nToken^{MAD} = MTQ + \\sum_{i=1}^{MT}Output_i^{1} + \\sum_{t=2}^{TM} \\sum_{i=1}^{MT} (Output_i^{t} + Summary_i^{t-1})\n\\end{equation}\n\\begin{equation}\n+\\sum_{t=2}^{i=1} \\sum_{i'=1}^{MT_{t-1}} (Output_i^{t} + Summary_i^{t})\n\\end{equation}\n\\begin{equation}\n<= MTQ +(\\frac{3}{2}M^{2}T -\\frac{3}{2}M^{2} + M) \\times Output_{max}\n\\end{equation}\n\\begin{equation}\n+ (\\frac{1}{2}M^{2}T + \\frac{3}{2} MT^{2} - M^{2} - MT + M) \\times Summary_{max}\n\\end{equation}\n< MTQ + 2M\u00b2T \u00d7 Output\u2098\u2090\u2093 + (M\u00b2T + MT\u00b2) \u00d7 Summary\u2098\u2090\u2093\nTherefore, we can obtain Token\u1d39\u1d2c\u1d30 = O (MTQ + (M\u00b2T + MT\u00b2)C)."}, {"title": "Token Cost in MAD", "content": "As mentioned in Section 3.1, our GroupDebate includes three types of processes and thus the total token cost Token\u1d33\u1d30 can be further dividied into:\n\\begin{equation}\nToken^{GD} = Token^{initial thinking} + (Token_{s=2}^{summary} + Token_{t=(s-1)R+1}) + \\sum_{s=1}^{S} \\sum_{t=(s-1)R+2}^{min(sR,T)} Token^{intra-group debate}\n\\end{equation}\nSpecifically, for initial thinking, the token cost of each agent includes the initial question prompt and its own output. For intra-group debate, the token cost of each agent includes all responses from other agents within the same group in the previous round and its output. For inter-group debate, the token cost of each agent includes the summary generation cost, which comprises the responses from other groups and the output summary, as well as its own output. The detailed computation process of the token cost in GroupDebate can be found in Algorithm 3."}, {"title": "Token Cost in GroupDebate.", "content": "Following Appendix B.1 and Eq. 5, we have:\n\\begin{equation}\nToken^{GD} = MQ + Output_{1} + \\sum_{i=1}^{M} [\\sum_{s=2}^{S} \\sum_{j=1}^{N}( \\sum_{i in G_j}Output_i^{t=-1}R + Summary_i^{t=-1})\n\\end{equation}\n\\begin{equation}\n+ \\sum_{i=1}^{M}(Q+Output_i^{t=-1}R+Summary_i^{t=-1} + Output_i^{(s-1)R+1})]\n\\end{equation}\n\\begin{equation}\n+ \\sum_{s=1}^{S} \\sum_{min(sR,T)} \\sum_{j=1}^{N}(Q+Output_i + \\sum_{i' in G_j} Output_i^{t=-1})\n\\end{equation}\n< MTQ + [3MS - 2M + (T - S)(K + 1)M] \\times Output_{max}\n\\begin{equation}\n+ (S - 1)(M + 1)N \\times Summary_{max}\n\\end{equation}\n< MTQ + \\frac{2M^{2}T}{N} \u00d7 Output_{max} + 2MSN \\times Summary_{max}\nO (MTQ + (\\frac{M^{2}T}{N} + MSN)C)\n\\end{equation}\nIt is worth noting that, when we set N \u2192 O (\u221aMT/S), theoretically, we can obtain Token^GD \u2192 O (MTQ + \u221aM\u00b3TSC). Furthermore, if we consider setting S to a very small positive integer,"}]}