{"title": "AI, Global Governance, and Digital Sovereignty", "authors": ["Swati Srivastava", "Justin Bullock"], "abstract": "This essay examines how Artificial Intelligence (AI) systems are becoming more integral to international affairs by affecting how global governors exert power and pursue digital sovereignty. We first introduce a taxonomy of multifaceted AI pay- offs for governments and corporations related to instrumental, structural, and dis- cursive power in the domains of violence, markets, and rights. We next leverage different institutional and practice perspectives on sovereignty to assess how digital sovereignty is variously implicated in AI-empowered global governance. States both seek sovereign control over AI infrastructures in the institutional approach, while es- tablishing sovereign competence through AI infrastructures in the practice approach. Overall, we present the digital sovereignty stakes of AI as related to entanglements of public and private power. Rather than foreseeing technology companies as re- placing states, we argue that Al systems will embed in global governance to create dueling dynamics of public/private cooperation and contestation. We conclude with sketching future directions for IR research on AI and global governance.", "sections": [{"title": "1 Introduction", "content": "This essay examines how Artificial Intelligence (AI) systems are becoming more integral to international affairs by affecting how global governors exert power and invoke digital sovereignty. AI implicates governing power in different ways. For states, AI is an \u201cenabling force\" (Horowitz, 2018, p.39) (Arsenault and Kreps, 2024, p. 960) with promises to improve capabilities and competitiveness (Bullock et al., 2024). In 2022, U.S. federal agencies \u201creported about 1,200 AI use cases\u2014specific challenges or opportunities that AI may solve\" (Government Accountability Office, 2023). In light of this perceived promise, states are racing to secure AI as a national asset before their rivals (Horowitz et al., 2024, p.924) and seeking to set the agenda in AI governance debates (Bradford, 2023; Canfil and Kania, 2024). Yet, states must also rely on globalized technology infrastructures of data, computing resources, and human talent that make zero-sum competition difficult (Ding, 2024, p. 882). Meanwhile, AI is core to the continued dominance of traditional Big Tech firms Alphabet, Meta, Amazon, and Microsoft (Zuboff, 2019; Srivastava, 2023). Newer players OpenAI and Anthropic have their foundation models integrated into everyday chatbots and AI assistants, while chip designer Nvidia and manufacturer TSMC have seen their fortunes soar. The centrality of private actors to AI advances have led to claims of an emerging \"technopolar\" order where \u201ctechnology companies wield the kind of power in the domains once reserved by nation-states\u201d (Bremmer and Suleyman, 2023, p. 28). In response, states have pursued schemes for \u201cdigital sovereignty\u201d (Bellanova et al., 2022; Broeders et al., 2023; Adler-Nissen and Eggeling, 2024).\nBut what is AI? Over the past 75 years, \u201cartificial intelligence\u201d has been used to de- scribe various machine architectures. Work began on AI shortly after the invention of mechanical computers during the 1940s (Dyson, 2012). Early approaches to AI included architectures of symbolic manipulation and statistical inference. Throughout the second half of the 20th century and the first decade of the 21st century, interest in and progress of AI systems waxed and waned with a series of \u201cAI summers\u201d followed by \u201cAI winters.\u201d During the same period, digitalization marched forward with the rise of personal computers and the world wide web (Dyson, 2012). These developments highlighted the governance challenges and opportunities from vast increases in computation and the global inter- connectedness of computation (DeNardis, 2020). Digital governance, for example, has become its own area of inquiry (Milakovich, 2012; Luna-Reyes, 2017; Manoharan et al., 2023). However, modern machine learning and neural network forms of AI became more capable in the early 2010s. The creation of \u201cfrontier\u201d large language models over the last decade has ushered in AI systems with enhanced capabilities in a wide array of areas, including reading comprehension, image and speech recognition, and predictive reasoning (Kiela et al., 2023). Human judgment in governance is by some accounts being both aug- mented and replaced by machine intelligence (Bullock, 2019; Young et al., 2019). At the same time, the ethical AI community warns about perpetuating \u201cAI hype\u201d centered on future risks (Bender et al., 2021) while ignoring current AI harms impacting marginalized groups (Eubanks, 2018; Noble, 2018; Benjamin, 2019). Ultimately, as a \"general purpose technology,\" frontier AI is unlike a specific tool or weapon and more like electricity in its transformative potential (Horowitz, 2018).\nWhat does the proliferation of frontier AI systems mean for global governance? In- ternational Relations (IR) has examined how control of data and computing resources entrenches state power (Farrell and Newman, 2023), grows private power (Atal, 2021; Srivastava, 2023), and raises new dilemmas for human rights (Wong, 2023), regulatory\nOur aim in this agenda-setting essay is (1) to map how frontier AI systems equip public and private global governors with new ways of exercising power and (2) to as- sess the resulting implications for the emergence of digital sovereignty. We argue that AI systems do not affect power or sovereignty in singular ways. Instead, we create a taxonomy of AI payoffs related to instrumental, structural, and discursive power (Lukes, 1974; Fuchs, 2013). The purpose of the taxonomy is to take stock of the variety of ways in which Al systems have been, or might be, used by public and private governors (on varieties of global governors, see (Avant et al., 2010). For public global governors such as states, we explore the development of powerful weapons with decreased human oversight (instrumental power), increases in internal control by supercharging surveillance capac- ity (structural power), and the ability to tailor propaganda to individual susceptibilities (discursive power). For private global governors such as corporations, we explore the inva- sive control of employees (instrumental power), concentration of computational resources (structural power), and alteration of the trust landscape (discursive power). We also discuss how autonomous AI models may express more agentic control over governance decision-making, including being in conflict with the goals of humans and organizations that create the AI systems. By including private governors and potential AI agents, our taxonomy moves beyond recent overviews of AI for international politics that are largely state-centric (Horowitz et al., 2024, p.929-930) or skeptical of AI's unforeseen transformative potential (Arsenault and Kreps, 2024, p.960).\nWe present the digital sovereignty stakes of AI as related to entanglements of public and private power. Policy experts lament that \"big technology firms have effectively be- come independent, sovereign actors in the digital realms they have created\" (Bremmer and Suleyman, 2023, p.28), echoing claims by some IR scholars that online platforms now exhibit \"virtual sovereignty\u201d (Kelton et al., 2022). Within this context, some states are pursuing \u201csovereign AI\u201d in their national strategies, as seen in India's assertion: \u201cWe are determined that we must have our own sovereign AI", "a nation's capabilities to produce artificial intelligence using its own infras- tructure, data, workforce and business networks\" ((Nvidia, 2024) emphasis added). The French government also explicitly connects AI and sovereignty, recently acknowledging \"our lag in the field of artificial intelligence undermines our sovereignty. Weak control of technology effectively implies a one-way dependence on other countries. In the privatized and ever-evolving field of AI, public power appears largely outmatched, limiting our col- lective ability to make choices aligned with our values and interests\" (Artificial Intelligence Commission, 2024, p.8). These efforts follow a broader resurgence of sovereignty talk in global discourse (Paris, 2020). In reality, digital sovereignty has multifaceted meanings that authorize a range of policy practices (Bellanova et al., 2022; Broeders et al., 2023; Adler-Nissen and Eggeling, 2024).\nWe build on this later work to discuss AI's implications for digital sovereignty in two ways. As an international institution, sovereignty is state-centric (Onuf, 1991) and relies on states keeping nonstate actors out of their exclusive club (Barkin, 2021). In the institutional perspective, the AI race creates opportunities for states to assert digital sovereignty over AI infrastructures and to be seen as taking on Big Tech as potential rivals. Recent European regulations such as the Digital Services Act, Digital Markets Act, and AI Act project Europe as an autonomous actor over private, particularly non-European, AI infrastructures. However, sovereignty is also an ongoing social practice (Wendt, 1992; Biersteker and Weber, 1996), where performing sovereign functions may require states working with nonstate actors (Srivastava, 2022a). In the practice perspec- tive, digital sovereignty is achieved through largely private AI infrastructures and depends on governments and companies co-developing capacity for AI innovation and regulation. Sticking with the European context, the Data Act and the Data Governance Act aim to monetize public data for European companies, while the Digital Services Act adopts a \"co-regulatory": "odel with tech platforms. Thus, AI's diverse power payoffs in global governance are likely to result in dual dynamics of states pursuing sovereignty over AI and sovereignty through AI.\nThe rest of the article proceeds as follows. The next section introduces the classic"}, {"title": "2 Three Faces of Power in Global Governance", "content": "Global governance scholars have identified varieties of power (Barnett and Duvall, 2005) beyond the standard reference to power as \u201cA compels B to do something B would not otherwise do\" (Dahl, 1957). One influential source is Steven Lukes' three faces of power 1974; 2005. Lukes discusses compulsory influence as the first face of decision-making power, then brings in agenda-setting as the second face of non-decision-making power (Bachrach and Baratz, 1962), and identifies the ability to shape interests as the third face of ideological power. For Lukes, the second and third faces are less visible than the first. In a policy context, one might see the first face of power when veto players decide which proposals win or lose, but be less attuned to the second face in agenda-setting that influences which proposals even come for a vote or the third face in ideological forces that shape interests and desires for certain policies.\nLukes' three faces of power have been operationalized in the global governance litera- ture as instrumental, structural, and discursive power (Fuchs, 2013). Instrumental power \u201canalyzes direct, observable relationships of power deriving from actor-specific material resources, while structural material and discursive approaches situate power and its use in material and ideational institutions and structures\" (Fuchs, 2013, p.80). Consider cor- porations, who exercise instrumental power through direct, observable interactions that result in influence over political decision-makers, for instance by lobbying through cam- paign finance contributions to influence politicians or public relations media strategies to influence consumers. Corporations also wield structural power through occupying struc-"}, {"title": "3 Taxonomy of AI Uses by Global Governors", "content": "Global governors may use AI as sources of instrumental, structural, and discursive power in the domains of violence, markets, and rights. We catalogue some illustrative examples in this section, summarized in Table 1, to highlight the variety of power payoffs of AI in global governance."}, {"title": "3.1 Public Authorities and Governance by AI", "content": "Governments have already used AI technologies to create autonomous weapons to en- hance their instrumental power. AI can autonomously and by augmentation of human capabilities increase the precision of weapons to harm targets and conduct attacks at a larger scale and from a further distance, all while reducing the likelihood of danger from\none's own forces by removing the need for them to be near the target (Canfil and Kania, 2024). Autonomous weapons are a continuation of earlier digital warfare tools. AI can also increase the ability of both offensive and defensive tools in cyberspace to subvert the capabilities of an adversary. Structural power may be reflected in AI empowering states' capacity for surveillance of their populations, making subjects more legible and hence governable (Scott 1998). In this way, states' structural position related to the governed is boosted by AI tools. Additionally, discursive power may be mobilized by the use of AI to shape citizen preferences to legitimate violence. For instance, governments may use AI models to generate highly personalized propaganda to distribute in information warfare campaigns (Horowitz et al., 2024, p.918). Similar to the use of radio and cable news by political operatives in major atrocities in Nazi Germany and Rwanda, generative AI can be deployed on a larger, more tailored scale to justify state-sanctioned violence.\nGovernments wield significant authority in setting and enforcing the rules by which market actors are expected to compete. In instrumental power, states can use AI tools to increase economic revenues through enhancing tax enforcement capabilities or identifying fraudulent behavior in welfare provision, as is already being done with Medicare claims in the US (Bullock et al., 2020). Governments may further privilege AI tools in financial governance infrastructures, for instance in determining interest rates or setting govern- ment loan terms, and use AI systems for government procurement of commercial services (Ahmadi and Bullock, 2023). In terms of structural power, states such as the U.S. can entrench their market dominance in AI against China through weaponizing economic interdependence by activating export controls in semiconductors and disincentivizing international academic collaboration through government grant allocation (Farrell and Newman, 2023). In these interactions, AI tools can help states monitor and enforce their punitive economic regulatory policies. Finally, governments may also use AI to enhance their discursive power to shape economic policy preferences. For instance, governments may advance neoliberal logics of privatization through contracting more service provi- sion to AI, such as welfare allocation, and normalizing these practices for the public.\nGovernments could also use the AI race to encourage the public to support domestic firms.\nGovernments also decide the scope of rights and determine how these rights will be protected and enforced. Governments can expand instrumental power in the rights do- main through using AI in law enforcement. Both judicial and policing agencies already make use of AI to augment and automate tasks such as evidence collection, evidence anal- ysis, and judicial recommendations (Angwin et al., 2016; Brayne, 2020; Cordelli, 2020). In terms of consolidating structural power against the governed, judicial and law enforce- ment agencies may also integrate AI tools within their organizational decision-making apparatus in ways that produce asymmetries for rightsholders, including embedding sys- temic practices like judicial case assignment and benchmarking judicial decisions against decisions made by AI (Taylor, 2023). Finally, in discursive power, AI may be used by governments to shape rights consciousness, that is citizens' perceptions of the rights and processes to which they are entitled to by law. For instance, the use of AI in law enforce- ment might require real-time facial recognition tools that violate privacy, but governments may minimize how important privacy should be as a right to citizens inhabiting AI infused societies or use AI metrics delivering enhanced \u201cpublic safety\u201d as an adequate tradeoff. In this way, the rights and processes of the governed may be further obfuscated."}, {"title": "3.2 Private Authorities and Governance by AI", "content": "While governments typically hold a monopoly on the legitimate use of violence, pri- vate actors such as organized criminal groups and security contractors also engage in violence. In traditional warfare, private military and security contractors may deploy au- tonomous weapons or AI surveillance tools with less accountability than there would be for government use (Srivastava, 2022b). Mexican drug cartels have used malware against journalists while the militia Hezbollah and terrorist group Boko Haram have used cyber strikes against states (Handler, 2022). Corporations also used AI tools to exert unequal structural power vis-\u00e0-vis the general public through the creation of for-profit predictive policing (Brayne, 2020) and spyware (Deibert, 2020) that are used jointly for commercial and governmental purposes, as seen with Palantir and NSO Group. Finally, AI can also be used to shape consumers' threat perceptions of violence through making more \u201cana- lytics\" available without context, such as Amazon Ring video doorbell's facial recognition system that identifies \u201cstrangers", "gold rush.\" For instance, the International Chamber of Commerce has launched an AI system to advise its members, who are typically lobbyists, on negoti- ating trade agreements and contracts (Arsenault and Kreps, 2024, p.963). Firms are also already using AI to increase their structural power over competitors through integration of AI tools throughout their business model (World Economic Forum, 2024), as seen for instance in the adoption of algorithmic trading by global finance. Businesses also use AI to reshape supply chain management, for instance optimizing warehouse efficiency and shipping routes, to claim a better structural position. Moreover, corporate investment in\nAI helps maintain structural market dominance as the best performing AI models require large amounts of data, tremendous computing power, and elite human talent, all of which favor Big Tech firms who can then charge monopoly rents. In terms of discursive power, corporations may encourage consumers to view AI integration as an accepted practice of business and consumption. For instance, Ring may make it seem normal to consis- tently surveil one's neighborhood to identify \u201cpotential threats.": "he tremendous public response to ChatGPT as a new way of seeking information has led to a race to develop other chatbots and integrate them in existing services, such as Bing and Google Search, even though these models are not yet fully tested for accuracy and bias.\nCorporations also play a large role in how individual rights are respected. For instance, firms may violate employees' privacy when AI tools are used for worker surveillance for instrumental purposes. Even innocuous-sounding wellness programs or social media apps lead to a \u201cquantified\u201d self (Ajunwa, 2023). AI also enables corporations to exert structural power through automation in labor markets. Automation may impact how firms hire, for instance using AI tools in hiring processes. Under Title VII of the Civil Rights Act of 1964, employers cannot discriminate against applicants on the basis of sex, race, religion, disability, pregnancy, national origin, age, or genetic information. But predictive algorithms used in hiring processes have been found to systematically rank applicants lower on the dimensions of sex and race (Chen, 2023). Integration of AI tools into organizational processes may then structurally advantage capital vis-a-vis labor as applicants lack knowledge about algorithmic bias and discrimination. Moreover, automation impacts whether firms hire at all by replacing humans with machines in software form such as tax preparation tools or hardware such as physical robots. Finally, AI advancements require data and corporations wield discursive power to alter the general perception of data rights in surveillance capitalism, where the proliferation of data-hungry platforms like Facebook, Google, Amazon, and Tencent seems like an inevitable trade-off (Zuboff, 2019)."}, {"title": "3.3 Governance by Autonomous AI Agents", "content": "Our discussion of AI's uses for global governance has so far assumed states and corpo- rations as the primary players. However, autonomous AI agents may also be seen as decision-makers themselves. Computer scientists are increasing the ability of AI systems to act like agents that pursue goals in diverse environments (Cheng et al., 2024; Du et al., 2024). The notion of AI as agents is related to other kinds of nonhuman agentic capacity. Both governments and corporations pursue goals, acquire resources, and perform actions in their environment even when these goals do not perfectly overlap with the humans that constitute them (Young et al., 2021). In this way, governments and corporations are said to be agentic. Machine learning (ML) also creates agents that pursue goals, acquire resources, and perform actions in their environment. Many ML systems now perform tasks and play certain games at human capability and in many cases surpassing even the very best humans. In global governance, agency has been attributed to international organizations (Barnett and Finnemore, 2004), non-governmental organizations (Keck and Sikkink, 1998), corporations (Strange, 1996; Hofferberth, 2019), and regime complexes (Alter and Raustiala, 2018) in addition to states. Thus, the claim of agentic AI should be viewed along the same lines as other nonhuman agents in global governance such as bureaucracies, market logics, and international organizations.\nAI autonomy is generally viewed on a continuum of humans-in-the-loop, humans-on-\nthe-loop, and humans-out-of-the-loop, with each type broadly corresponding to humans initiating and being in control of a task, humans largely delegating to AI systems but retaining control over stopping a task, and humans taking no active role in a task. Table 2 summarizes how autonomous AI agents in humans-out-of-the-loop systems might be used to advance instrumental, structural, and discursive power relative to humans."}, {"title": "4 Implications for Digital Sovereignty", "content": "This section suggests a few points of analysis for how the use of AI technologies by global governors implicates sovereignty. Sovereignty is a contested concept in IR theory, at once indispensable yet subject to persistent debate about its meaning (Wendt and Duvall, 2008, p.607), (Paris, 2020, p.455-456),(Srivastava, 2022b, p.12-15). Rather than offer one definition of sovereignty, we center our discussion around two prevailing interpretations: sovereignty as an institution and sovereignty as a practice."}, {"title": "4.1 Sovereignty as Institution", "content": "What separates states from other entities is the shared international understanding that only states represent legitimate political authority. That legitimacy, in turn, relies on claims about sovereign authority that are distinct from claims about other kinds of au- thority, such as religious authority. In traditional understanding, sovereignty is \u201cthe idea that there is a final and absolute political authority in the political community ... and no final and absolute authority existed elsewhere\u201d (Hinsley, 1986, p.365). Here, sovereignty is an idealized claim \u2013 i.e., \u201cthe idea that\u201d \u2013 not an accurate representation of reality. It is in this context that scholars observe, \u201cstate control has waxed and waned enormously over time, regions, and issue-areas while the state's claim to ultimate political authority has persisted for more than three centuries\u201d (Thomson, 1994, p.214). The purpose of making idealized claims about sovereignty is \"to express and realize the principles that make a state a particular state\u201d (Inayatullah and Blaney, 1995, p.13). Variously referred to as international legal sovereignty (Krasner, 1999) or de jure sovereignty, in this inter- pretation \u201cwhen states recognize each other's sovereignty as a right then we can speak of sovereignty not only as a property of individual states, but as an institution shared by many states\u201d (Wendt, 1992, p.280). In short, sovereignty as an institution constitutes states as states (Onuf, 1991, p.430-431).\nIn a \"sovereignty cartel\" (Barkin, 2021), states jealously guard and uphold the inter- national institution of sovereignty to keep out nonstate actors or quasi states, no matter how powerful. Big Tech firms, like oil companies before them, are wealthier than most states, but none can be a member of the United Nations or engage in sovereign lending or sign peace treaties. But the sovereignty cartel faces challenges. Early globalization debates centered partially on whether borderless corporations would result in disempow- ered states and the erosion of state sovereignty (Strange, 1996; Goldsmith and Wu, 2006). Similarly, scholars speak of \u201csovereignty costs\" to indicate the tradeoffs of accepting an- other's authority in place of or alongside one's own (Krasner, 1999). For instance, in the European Union, member states give up some of their individual authority claims to make monetary policy or control borders when pooling sovereign authority. As such, joining the EU may come with some sovereignty costs. But as a supranational organization, the EU is made up of other sovereign states. In that regard, the international institution of sovereignty is not necessarily degraded. Moreover, to the extent the EU boosts member state capacity that would not be possible absent joining the organization, it might end up being a \"sovereignty boon.\u201d As such, there are no straightforward ways to assess how sovereignty as an institution may be implicated by changes in global power dynamics. In the context of AI, state actors may use AI to further entrench their sovereign claims. There are two ways this may happen.\nFirst, states may use the threat of powerful private interests to assert more sovereign control over digital infrastructures vis-a-vis any corporate sovereign challengers (Bel- lanova et al., 2022). Modern frontier AI systems are expensive endeavors. To collect massive training data, procure superclusters of computation, and have the human tal- ent required to develop the requisite training and inferential algorithms requires large amounts of capital. Additionally, until the past few years, it was thought that these types of AI systems would be unable to outperform symbolic, knowledge-based models. Consequently, well-resourced private actors have created the new wave of generative AI systems. Thus, the current frontier models are created by private companies and are designed to be useful agents in the marketplace for which the companies can deploy at\""}, {"title": "4.2 Sovereignty as Practice", "content": "Sovereignty as an institution might represent a state-centric claim to supreme political authority, but sovereignty is messier in practice. States may not be functionally in charge of making sovereign decisions, thus lacking de facto (in fact) sovereignty. The functions we assign to sovereign powers may also evolve over time. While we traditionally expect sovereigns to collect taxes, fight wars, write laws, and defend rights, among other activ- ities, these roles evolve. For instance, trash collection was not a sovereign function in\nthe early or late modern era, but is widely seen as one today. Taking care of wounded soldiers went from nonexistent before the 19th century to an integral part of interna- tional humanitarian law in the 20th century. In this interpretation of sovereignty, \u201cthe sovereign state is an ongoing accomplishment of practice, not a once-and-for-all creation of norms that somehow exist apart from practice\u201d (Wendt, 1992, p.413). As such, the \u201c\u201ctraditional' meaning of sovereignty is not as foundational and timeless as is commonly assumed", "are interested in considering the variety of ways in which states are constantly negotiating their sovereignty\" (Biersteker and Weber, 1996, p.11).\nResearch that regards sovereignty as practice shows that a variety of nonstate enti- ties carry out functions associated with sovereign states (Lake, 2003; Slaughter, 2005; Doty, 2007; Cooley and Spruyt, 2009; Avant et al., 2010; Best and Gheciu, 2014; Phillips and Sharman, 2015; Srivastava, 2022b). Contractors fight wars, lobbyists conduct com- merce, and nongovernmental organizations deliver welfare. While nonstate expressions of sovereign power may invite discussions of sovereignty costs or public versus private, some view sovereign competence as a joint enterprise between public and private entities. For instance, a \u201cstates and markets": "erspective pushes back against the early globaliza- tion debates on \u201cstates versus markets", "hybrid sovereignty,": "tates do not become \u201cless\u201d sovereign by collaborating with private actors; instead, sovereign power itself changes to include both public and private sources (Srivastava, 2022a).\nAI's many roles in global governance implicates digital sovereignty as practice in two ways. First, public and private global governors may jointly pursue AI advances that affect their capacities. Governments who seek to be empowered by AI also need to rely on public/private collaborations. Consider that while one plank of EU's digital sovereignty approach targets American tech companies for regulation, another plank part- ners with them for establishing its \u201csovereign cloud", "performative discourse": "Adler-Nissen and Eggeling, 2024), meant to include a diverse range of policy practices. As European data protection laws dictate how digital data is treated around the world, the EU also passed new regulations that make it easier to access public data for commercial purposes. While government programs such as PRISM reveal the shadow links between American firms and intelligence agencies for mass surveillance, many public-private hybrid collab- orations occur in plain sight. Smart cities rely on public-private data infrastructures to direct traffic, pick up trash, or fix potholes. Many airports now feature facial recognition boarding tools. Contact tracing by health ministries during the early part of the Covid pandemic relied on Apple and Google's operating systems. Amazon Ring cameras feed into law enforcement systems for neighborhood surveillance. In this way, public attempts at digital sovereignty may not be practiced against private interests, but decidedly with them.\nSecond, AI systems may come to represent new ways of practicing sovereignty. We have already discussed the many ways in which AI systems may empower public and private governors organizing violence, markets, and rights. Through critical functional embeddedness, decision-making logics of AI systems could permeate how governors make decisions as well. For example, greater use of AI technologies in governance may create new incentives for speed and scale or reduce demands for privacy protection. In embracing", "AI,": "he Indian government recognizes:\nWe can take two options. One is to say, as long as there is an AI ecosystem in India"}, {"title": "5 Conclusion", "content": "This essay mapped AI's multifaceted role in global governance. As a general purpose technology, AI systems are used by both public and private governors to enhance their instrumental, structural, and discursive power in the domains of violence, markets, and rights. We provided a taxonomy of AI power payoffs using examples of relevance to global governance broadly. We also assessed how digital sovereignty is implicated in AI- empowered global governance efforts by presenting different analyses of states seeking\nsovereign control over AI infrastructures and establishing sovereign competence through AI infrastructures. Rather than foreseeing a technopolar order where technology compa- nies replace states, we argued that AI systems will embed in global governance to create dueling dynamics of public/private cooperation and contestation. These dynamics are not unique to AI, but AI offers a particularly fertile issue area for studying overlapping agency in global politics.\nMoving forward, one strand of IR research should explore what new cooperative and competitive strategies arise between public and private governors in sovereignty games as they acquire power and aim to secure or hold onto authority. This research could focus on whether and how private actors are accommodated, if at all, in AI regulation. Moreover, detailed studies on AI private governance (such as standard-setting) or comparative AI firm strategies, for instance between American and Chinese technology sectors, would also be valuable. Broadly, we also need to know more about how intergovernmental organizations such as the UN or civil society groups respond to AI advances in the private sector.\nAnother set of research inquiries concern geopolitical dynamics between states, where questions include how AI exacerbates or ameliorates inequalities between the global North and South. Al is sometimes considered a democratizing technology, where, for instance, more people have access to the powerful technologies of ChatGPT and the like than ever before. However, frontier AI development is still concentrated in a handful of states and companies. Moreover, many states have signaled interest in developing safe and trustworthy AI, for instance through endorsing OECD and UNESCO guidelines on ethical AI. But under what conditions do states regulate AI in rights-protecting ways? Relatedly, will state regulation of AI move towards cohesion or fragmentation?\nFinally, IR scholars should also pay attention to changing AI capabilities. We have discussed the possibility of AI agents exerting significant power over governance decision- making. Researchers should explore the ethical and political implications of AI agency, including the potential for autonomous AI to alter the power dynamics between states and corporations and even the meaning of governance altogether."}]}