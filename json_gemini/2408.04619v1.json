{"title": "TRANSFORMER Explainer: Interactive Learning of Text-Generative Models", "authors": ["Aeree Cho", "Grace C. Kim", "Alexander Karpekov", "Alec Helbling", "Zijie J. Wang", "Seongmin Lee", "Benjamin Hoover", "Duen Horng (Polo) Chau"], "abstract": "Transformers have revolutionized machine learning, yet their inner workings remain opaque to many. We present TRANSFORMER EX-PLAINER, an interactive visualization tool designed for non-experts to learn about Transformers through the GPT-2 model. Our tool helps users understand complex Transformer concepts by integrating a model overview and enabling smooth transitions across abstraction levels of mathematical operations and model structures. It runs a live GPT-2 instance locally in the user's browser, empowering users to experiment with their own input and observe in real-time how the internal components and parameters of the Transformer work together to predict the next tokens. Our tool requires no installation or special hardware, broadening the public's education access to modern generative AI techniques. Our open-sourced tool is available at https://poloclub.github.io/transformer-explainer/. A video demo is available at https://youtu.be/ECR40Awocjs.", "sections": [{"title": "1 INTRODUCTION", "content": "The Transformer [10] has gained popularity as a neural network architecture across numerous tasks, from text to vision. Despite its increasing widespread use, particularly in AI chatbots (e.g., Chat-GPT, Gemini), its inner workings often remain opaque, hindering understanding and engagement [12]. Demystifying this architecture is crucial for non-experts interested in learning about it. Existing resources, such as blog posts [2], video tutorials [1, 9], and 3D visu-alizations [4] often emphasize mathematical intricacies and model implementations, which can overwhelm beginners. Meanwhile, visu-alization tools designed for AI practitioners focus on interpretability at the neuron and layer levels, which can be challenging for non-experts to grasp [3]. To address this research gap, we contribute:\n1. TRANSFORMER EXPLAINER, an open-source, web-based in-teractive visualization tool designed for non-experts to learn about both the Transformer's high-level model structure and low-level mathematical operations (Fig. 1). Our tool explains the Transformer through its application in text generation, one of its most recognized uses. It adopts the Sankey diagram visual design, inspired by recent studies viewing the Transformer as a dynamic system [5], to emphasize how input data \"flows\" through the model's components [6]. The Sankey diagram effectively illus-trates how information moves through the model, showcasing how inputs undergo processing and transformations via Trans-former operations. TRANSFORMER EXPLAINER helps users gain a comprehensive understanding of the complex concepts within Transformers by tightly integrating a model overview that sum-marizes a Transformer's structure and enabling users to smoothly transition between multiple abstraction levels to visualize the interplay between low-level mathematical operations and high-level model structures (Fig. 1C) [11].\n2. Open-source, web-based implementation with real-time in-ference. Unlike many existing tools that require custom soft-ware installations or lack inference capabilities [3], TRANS-FORMER EXPLAINER integrates a live GPT-2 model that runs locally in the user's browser using modern front-end frameworks."}, {"title": "2 SYSTEM DESIGN AND IMPLEMENTATION", "content": "TRANSFORMER EXPLAINER visualizes how a trained Transformer-based GPT-2 model processes text input and predicts the next token. The frontend uses Svelte and D3 for interactive visualizations, while the backend uses ONNX runtime and HuggingFace's Transformers library to run the GPT-2 model in the browser. A major challenge in designing TRANSFORMER EXPLAINER is managing the complexity of the underlying architecture, which can be overwhelming if all details are presented simultaneously. To address this, we draw on two key design principles:\nReducing Complexity via Multi-Level Abstractions. We struc-tured the tool to present information at varying levels of abstrac-tion. This approach allows users to start with a high-level overview and drill down into details as needed, preventing information over-load [8, 11]. At the highest level, our tool illustrates the complete pipeline: from taking user-provided text as input (Fig. 1A), embed-ding it, processing it through multiple Transformer blocks, to using this transformed data to rank the most likely next token predictions. Intermediate operations, such as calculations for the attention matrix (Fig. 1C), are collapsed by default to visualize the significance of the computational result, with the option to expand to inspect its deriva-tion through animation sequences. We employed a consistent visual language, such as stacking Attention Heads and collapsing repeated Transformer Blocks, to help users recognize repeating patterns in the architecture, while maintaining the end-to-end flow of data.\nEnhancing Understanding and Engagement via Interactivity. The temperature parameter is crucial in controlling a Transformer's output probability distribution, affecting whether the next-token prediction will be more deterministic (at low temperature) or random (high temperature). Existing educational resources on Transformers often overlook this aspect [2]. Our tool enables users to adjust the temperature in real time (Fig. 1B) and visualize its critical role in controlling the prediction determinism (Fig. 2). Additionally, users can select from provided examples or enter their own input text (Fig. 1A). Supporting custom input text engages users, by allowing them to analyze the model's behavior under various conditions and interactively test their own hypotheses on diverse text inputs.\nUsage scenario. Professor Rousseau is modernizing the curricu-lum of a Natural Language Processing course to highlight recent advances in generative AI. She has observed that some students view Transformer-based models as \"magic,\" and some wish to learn how they work but are unsure where to start. To address this, she directs students to TRANSFORMER EXPLAINER, which provides an interactive overview of the Transformer (Fig. 1), encouraging active experimentation and learning. With over 300 students in her class, the ability of TRANSFORMER EXPLAINER to run entirely in students' browsers without software installation or special hardware is a significant advantage, eliminating concerns about managing software or hardware setup. The tool introduces students to complex mathematical operations, such as attention computation, through animations and interactive reversible abstractions (Fig. 1C). This approach helps students gain both a high-level understanding of the operations and lower-level details that produce the results. Professor Rousseau is also aware that the technical capabilities and limitations of Transformers are sometimes obscured by anthropomorphism (e.g., the temperature parameter being viewed as a \"creativity\" control). By encouraging students to experiment with the temperature slider (Fig. 1B), she demonstrates that temperature actually modifies the probability distribution of the next token (Fig. 2), controlling the randomness of the predictions and balancing between deterministic and more creative outputs. Additionally, as the system visualizes the token processing flow, students see there is no \u201cmagic\u201d involved - regardless of the input texts (Fig. 1A), the model follows a well-defined sequence of operations using the Transformer architecture, simply sampling one token at a time, before repeating the process."}, {"title": "3 ONGOING WORK", "content": "We are enhancing the tool's interactive explanations (e.g., layer nor-malization) to improve the learning experience. We are also boosting the inference speed with WebGPU and reducing model size through compression techniques (e.g., quantization, palettization) [7]. Fi-nally, we plan to conduct user studies to assess TRANSFORMER EXPLAINER's efficacy and usability, to observe how newcomers to AI, students, educators, and practitioners use the tool, and gather feedback on additional functionalities they wish to see supported."}]}