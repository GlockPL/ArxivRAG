{"title": "ESCAPE: Energy-based Selective Adaptive Correction for Out-of-distribution 3D Human Pose Estimation", "authors": ["Luke Bidulka", "Mohsen Gholami", "Jiannan Zheng", "Martin J. McKeown", "Z. Jane Wang"], "abstract": "Despite recent advances in human pose estimation (HPE), poor generalization to out-of-distribution (OOD) data remains a difficult problem. While previous works have proposed Test-Time Adaptation (TTA) to bridge the train-test domain gap by refining network parameters at inference, the absence of ground-truth annotations makes it highly challenging and existing methods typically increase inference times by one or more orders of magnitude. We observe that 1) not every test time sample is OOD, and 2) HPE errors are significantly larger on distal keypoints (wrist, ankle). To this end, we propose ESCAPE: a lightweight correction and selective adaptation framework which applies a fast, forward-pass correction on most data while reserving costly TTA for OOD data. The free energy function is introduced to separate OOD samples from incoming data and a correction network is trained to estimate the errors of pretrained backbone HPE predictions on the distal keypoints. For OOD samples, we propose a novel self-consistency adaptation loss to update the correction network by leveraging the constraining relationship between distal keypoints and proximal keypoints (shoulders, hips), via a second \u201creverse\u201d network. ESCAPE improves the distal MPJPE of five popular HPE models by up to 7% on unseen data, achieves state-of-the-art results on two popular HPE benchmarks, and is significantly faster than existing adaptation methods.", "sections": [{"title": "1. Introduction", "content": "3D Human Pose Estimation (HPE) from single-view images is a fundamental task in computer vision with applications in healthcare [1]; [2], VR/AR [3], human-robot-interaction [4], etc. Recent deep-learning-based HPE methods have achieved remarkable performance [5, 6, 7, 8] on public benchmarks. Due to the immense difficulty of labeling 3D human pose data, most HPE methods are trained using public datasets which do not accurately represent the wide variety inherent in in-the-wild poses. Therefore, the pre-trained models significantly under-perform when applied to out-of-distributions (OOD) samples [9, 10]. The performance of HPE models specifically degrades in estimating the 3D distal keypoints (e.g. wrist, ankle) [11, 12].\nRecently, test-time adaptation (TTA) methods have been shown to help bridge the train-test domain gap and improve prediction performance on OOD data by fine tuning models on test data [10, 11, 12, 13]. Most of the prior works leverage the ground-truth 2D poses of the test sample to optimize the pre-trained models via 2D projection. However, ground-truth 2D poses are not available in real case scenarios and replacing them with estimated 2D keypoints significantly degrades the accuracy of prior works [12]. More-"}, {"title": null, "content": "over, because existing SOTA test-time adaptation methods indiscriminately optimize network parameters for every test sample, they massively increase inference times and remain impractical (e.g. BOA [10] and DynBOA [14] increase inference times by over 50x).\nTo address the above issues, we propose ESCAPE: Energy-based Selective-adaptive Correction for out-of-distribution 3d humAn Pose Estimation. A fast, selective test time adaptation method which only performs costly test time adaptation on OOD samples, optimizes an external lightweight correction network instead of the pre-trained model, and requires no 2D or 3D annotations whatsoever. Fig. 1 shows the high-level overview of ESCAPE.\nESCAPE uses a Free Energy Function to classify the pre-trained model outputs as corresponding to OOD or in-distribution (ID) inputs for the pre-trained model. This energy function is a label-free OOD detection that has shown to be fast and robust [15]. We then apply an intensive test-time adaptation for OOD samples and a fast forward-pass correction for ID samples.\nOur proposed test-time adaptation method relies on two observations. 1) pre-trained models estimate the proximal keypoints (e.g. hip and shoulder) with higher confidence compared with distal keypoints (e.g. wrist and ankle). That is, the majority of 3D keypoint estimation errors are in the distal keypoints because they are often poorly captured in a given frame (blurry, occluded, etc) and are highly unconstrained. Conversely, the proximal key-points are generally predicted well by virtue of being relatively constrained usually quite visible. We hypothesize that with proper considerations, we can leverage the well-estimated proximal keypoints to help correct the estimated distal keypoints. 2) due to biomechanical human joint constraints, there exists a correlation between distal and proximal keypoints. Specifically, given a set of distal keypoints there is a small space of possible corresponding proximal keypoints. We qualitatively demonstrate the above two observations in the experiments.\nFollowing these observations, the Fast Correction (Fig. 1) simply estimates the errors of distal keypoints given the initial estimated pose from the pre-trained model. We show that for ID samples, we can learn a correction network (CNet) to estimate the distal keypoint errors and thereby effectively correct the poses. For OOD samples, we propose a novel Test-time Adaptation utilizing the learned CNet in tandem with a reverse correction network (RCNet) which estimates the errors of proximal keypoints given the CNet corrected pose. We pre-train RCNet with predictions from CNet and"}, {"title": null, "content": "use it to optimize CNet at test time via a Self-Consistency Loss comparing the RCNet-corrected proximal joints to the intially estimated proximal joints from the pre-trained backbone estimator (Fig. 2).\nIn contrast to prior work, our test-time correction and adaptation method does not optimize the pre-trained model and so can be added downstream of any pre-trained pose estimator to boost performance on both ID and OOD samples. Further, because the proposed method optimizes an external correction network instead of the pre-trained model, and only does so on OOD samples, it maintains practical and comparable model inference times and is many times faster than other methods.\nOur contributions are as follows:\n\u2022 We propose a novel approach for test-time adaptation methods in which expensive adaptation is reserved for difficult OOD samples and otherwise only a fast feed-forward correction is applied, and demonstrate that an Energy function can be effectively used to perform the OOD sample selection.\n\u2022 We propose a novel and lightweight method (CNet) for correcting pre-trained backbone pose estimator predictions and a novel test-time adaptation method for improving CNet via a learned self-consistency loss using only the backbone estimations, avoiding direct optimization of backbone model parameters.\n\u2022 We attain state-of-the-art results on three popular 3D pose estimation benchmark datasets, atop several pre-trained pose estimation models.\n\u2022 We provide an extensive set of experiments and ablation studies, demonstrating the benefits of our Energy based sample selection for existing TTA methods and verifying the robustness of our proposed method across environmental conditions."}, {"title": "2. Related Work", "content": "3D Human Pose Estimation There are two categories of 3D human pose estimation models: parametric and non-parametric methods. The parametric methods estimate human joint angles for a parametric human mesh model (SMPL) and use that to obtain human mesh and pose [7, 8, 5]. Non-parametric methods directly estimate 3D positions of human keypoints given"}, {"title": null, "content": "images [16, 17, 18]. Some of the non-parametric methods divide the problem into two stage, first estimating 2D poses from the image and then estimating 3D poses from 2D poses. Our test-time adaptation method is applicable to all of the above-mentioned categories since it merely requires estimated 3D keypoints output by the pre-trained model for its optimization.\nTraining-Time Adaptation. Recently, the generalizability of HPE models has gained attention. Prior work has proposed various solutions to address it at training time via synthetic data generation or modifying the architecture of the network. [19], [20], and [9], proposed synthetic data generation to mitigate the domain gap between train and test samples. They generate 2D-3D novel poses from novel viewpoints to cover unseen poses and viewpoints in the test dataset. Such methods are specifically effective when the ground truth 2D poses are available at the inference time and often struggle when estimated 2D keypoints are not accurate [9]. [21] addresses the poor generalizability of HPE models by splitting the human body into body parts. They argue that the splitting procedure helps in estimating poses that are not available in the training dataset since sub-body poses have been seen in the training data. [22] proposes estimating camera viewpoint along with 3D poses to address the generalizability of HPE models. All of the above-mentioned methods are training-time adaptation methods and are unable to dynamically adapt the HPE models.\nTest-Time Adaptation. In this section we discuss the prior works that optimize the pre-trained model at the inference stage to address the generalizability problem. ISO [13] proposes using geometric cycle consistency loss to update the pre-trained HPE model at the inference stage. The proposed loss is inspired by an unsupervised loss that learns 3D poses from 2D poses without any 3D supervision [23]. BOA [10] proposes a bilevel optimization method that relies on 2D keypoints and temporal information of the test samples. BOA optimizes the pre-trained models on each single frame to minimize the 2D projection loss. DynBOA further improves BOA by retrieving examples from the train data that can specifically help in inference on a test image. DAPA [11] proposes a domain-adaptive pose augmentation method that augments the estimated pose given a target image. Then, the body regression network is finetuned on both the real target images and their augmented counterparts. The above methods highly depend on the error of test sample 2D keypoints. When 2D keypoints are noisy the performance drops significantly [12]. CycleAdapt [12] mitigates the above problem by proposing a motion-denoising network that corrects the 3D estimated motions at the"}, {"title": "3. Method", "content": "We first give a general overview of the proposed selective test-time adaptation ESCAPE framework, then define the human pose correction problem setup (3.1) and describe the application of ESCAPE to this particular setting. A detailed overview of ESCAPE is shown in Fig. 2.\nOur proposed method begins with the output prediction of a pre-trained backbone model given its input data. The energy score (3.2) of this initial backbone prediction is compared against a predetermined threshold to classify the input data as out-of-distribution (OOD) or in-distribution (ID)"}, {"title": "3.1. Problem Formulation", "content": "Given an input image frame $I$ of a person, a pre-trained human pose estimator $P$ returns 3D human poses $X \\in \\mathbb{R}^{j \\times 3}$ where $j$ is the number of keypoints:\n$P(I) = X, \\quad X \\in \\mathbb{R}^{j \\times 3}$ (1)\nThe proximal and distal keypoints $X_p$ and $X_D$ are subsets of the full key-points $X$. The proximal keypoints $X_p$ are the keypoints at the base of each human limb: the right/left hips and the right/left shoulders. The distal keypoints $X_D$ are the keypoints at the end of each human limb: the right/left feet and the right/left hands. Estimating proximal joints is an easier task because of their greater bio-mechanical constraints, and human pose estimators have correspondingly lower estimation errors on proximal keypoints than on distal keypoints. We leverage this in the design of the reverse network test-time adaptation objective outlined in section 3.4."}, {"title": "3.2. Energy-based Sample Selection", "content": "To select hard samples from incoming data for inference time adaptation, we use the Energy Function, which has been shown to be effective in OOD"}, {"title": null, "content": "detection in prior work [15, 24, 25].\nGiven the estimated human pose, $X \\in \\mathbb{R}^{j \\times 3}$, we flatten the estimated pose to create a vector, $f$, with the length of $H = j \\times 3$.\nWe calculate the free energy over $f$ as follows:\n$E(I) = - \\log \\sum_{h}^{H} e^{f(h)}$ (2)\nwhere $I$ is the input image.\nWe define a threshold, $E_T$, to classify the input data $I$ as OOD or IND. That is, if $E(I) < E_T$, we consider $I$ to be OOD for the backbone model, otherwise IND."}, {"title": "3.3. Correction Network", "content": "To improve backbone HPE predictions on the highly uncertain distal key-points, we propose learning a simple correction network (CNet) $C$ to estimate the distal keypoint errors of input backbone pose predictions. The errors can then be directly applied to the distal keypoints of the backbone prediction to obtain a corrected estimation. That is, $C$ outputs estimated 3D errors for the $d$ distal keypoints $\\Delta X_D \\in \\mathbb{R}^{d \\times 3}$, given an input 3D human keypoint estimation $X$:\n$\\Delta X_D = C(X)$, (3)\nand $X$ is subsequently adjusted using the predicted errors $\\Delta X_D$ to get a corrected pose $X^C$. Note that $X^C$ is identical to $X$ except for the adjusted distal keypoints:\n$X^C = X - \\Delta X_D$ (4)\nWe train $C$ in a fully supervised manner, using the ground-truth 3D pose distal keypoints $Y_D$ from the training set of the backbone. The distal error is defined as $\\Delta X_D = Y_D - X_D$. The $L_2$ norm between estimated distal errors $\\Delta \\hat{X}_D$ and ground-truth distal errors $\\Delta X_D$ is then used to train $C$:\n$\\mathcal{L}_1 = || C(X), \\Delta X_D||_2$, (5)\nWhile straightforward, using only $\\mathcal{L}_1$ as supervision can overly encourage the network to address only scale issues in the initial backbone estimate."}, {"title": null, "content": "Since we equally want $C$ to correct orientation errors in the initial estimate, we define a second, closely related loss term $\\mathcal{L}_2$ wherein $C$ ingests the initial pose $X$ procrustes-aligned to the ground-truth pose $Y$, denoted by $X^{pa}$. The overall $\\mathcal{L}_2$ term between the resulting prediction and the ground-truth error $\\Delta \\hat{X}_D^{pa} = Y_D - X_D^{pa}$ is then defined as follows:\n$\\mathcal{L}_2 = || C(X^{pa}), \\Delta \\hat{X}_D^{pa} ||_2$. (6)\nBoth $\\mathcal{L}_1$ and $\\mathcal{L}_2$ are combined into the final training objective for $C$:\n$\\mathcal{L}_C = \\lambda_1 \\mathcal{L}_1 + \\lambda_2 \\mathcal{L}_2$, (7)\nwhere $\\lambda_1$ and $\\lambda_2$ are weights of the loss terms.\nAt inference time, the trained $C$ is used frozen on ID samples (in fast forward-pass correction) but is further tuned on OOD samples (in intensive adaptation)."}, {"title": "3.4. Test-Time Adaptation via Self-Consistency", "content": "To adapt CNet to harder, OOD samples during inference, we define a Self-Consistency loss which uses only the backbone pose sample $X$, requiring no inference time ground-truth keypoints. This loss relies on a reverse network (RCNet), $R$, which aims to learn the biomechanical reverse of the CNet task. $R$ takes the corrected 3D human keypoint estimation $X^C$ as input and outputs estimated 3D errors for each of the $p$ proximal keypoints $\\Delta X_p \\in \\mathbb{R}^{p \\times 3}$.\n$\\Delta X_p = R(X^C)$ (8)\nAt the training stage, we use ground truth 3D poses from proximal keypoints to train $R$. The proximal error is defined as $\\Delta \\hat{X}_P = Y_P - X_P$. The $L_2$ norm between estimated proximal errors $\\Delta X_p$ and ground-truth distal errors $\\Delta \\hat{X}_P$ is defined as:\n$\\mathcal{L}_R = || R(X), \\Delta \\hat{X}_D||_2$. (9)\n$R$ is trained to predict proximal corrections given the pose corrected by $C$, $X^C$. It only ever takes $X^C$ as input. Learning $R$ is easier than learning $C$ since the proximal keypoints are more constrained compared with distal keypoints and therefore, once trained, $R$ is kept frozen and used in TTA to adapt $C$."}, {"title": null, "content": "To perform TTA on CNet using RCNet, the initial prediction $X$ is corrected by CNet. Then, the corrected sample $X^C$ is input to $R$ resulting in a pose $X^R$ with both corrected distal joints from $C$ and corrected proximal joints from $R$. The $L_2$ distance between the $X^R$ proximal joints $X^R_P$ and the original backbone pose proximal joints $X_P$ is used as the TTA objective $\\mathcal{L}_{TT}$ to update $C$. Only $C$ is updated using $\\mathcal{L}_{TT}$ during adaptation, while $R$ remains frozen. More formally, we define the test time consistency loss as:\n$\\mathcal{L}_{TT} = || X_P^R, X_P||_2$. (10)\nIn Fig. 4, we empirically demonstrate that the proposed self-consistency loss is highly correlated with the ground-truth 3D mean squared error (MSE) by reporting the self-consistency loss and ground-truth MSE for every sample in the 3DPW test set [26] using CLIFF as the backbone network. Due to the large number of samples, we plot the binned average values in red. While individual samples may have a high degree of noise, the proposed TTA loss has a clear correlation with the ground-truth 3D objective.\nTo further understand the proposed loss intuitively, first consider a sample $X^{ind}$ which lies ID for the backbone network. Because $C$ is trained using the backbone training data predictions, $X^{ind}$ will also be ID for $C$. Similarly, it is ID for $R$ since $R$ is trained using trained $C$ predictions on the backbone training data. If $C$ and $R$ have been trained well, $C$'s correction to $X^{ind}$ and $R$'s subsequent correction will both be minor since the sample was already good. Thus the distance between the distal joints of $X^{ind}$ and the twice-corrected pose will be small.\nIn contrast, a sample OOD for the backbone network $X^{ood}$ will be OOD for $C$ and $R$. Because it is OOD for the backbone, $X^{ood}$ will have unusually large error, receive more aggressive corrections, and result in greater distance between the proximals of the twice-corrected pose $X^R$ and the uncorected pose $X$."}, {"title": "4. Experiments", "content": "In this section, we introduce the datasets, metrics and implementation details. We subsequently present a thorough evaluation of our proposed method, including experimental results, comparisons to state-of-the-art methods, and ablation studies on different parts of our framework."}, {"title": "4.1. Experimental Setup", "content": "Backbone Networks. To demonstrate the general applicability of ESCAPE, we perform separate experiments using five widely-used and representative backbone HPE models: HybrIK [6], SPIN [5], PARE [7], BMSE [27], and CLIFF [8]. Pose estimations from each backbone on the train and test data are produced and used to train and evaluate a separate pair of $C$ and $R$ for each backbone.\nImplementation Details. The architecture of the residual networks used for $C$ and $R$ are identical, and follow that proposed by [28], which is often used as a 3D pose estimation baseline. A diagram of this architecture is shown in Fig. 3. First, the flattened 3D skeleton keypoints are embedded via a linear layer followed by a batch norm layer, ReLU activation, and dropout layer. The embedding is passed through a series of residual blocks, then passed to a final linear layer to produce an output set of 4x 3D keypoint error vectors. We set all linear layer sizes = 512, use dropout=0.3, and use N=1 residual block. Our evaluation datasets use 17 keypoints in Human3.6M format, thus the network input shapes are both (B, 51)."}, {"title": null, "content": "Our training procedure for $C$ and $R$ for a given pretrained backbone model is as follows: 1) we perform inference on the training images with the backbone model, recording the predicted and corresponding GT poses, 2) $C$ is trained in a supervised manner using the predicted and GT poses with loss $\\mathcal{L}_C$ (eq. 7), 3) we perform inference on the training set of backbone predicted poses with the fully trained $C$, recording the resulting distal-corrected poses $X^C$, and finally 4) $R$ is trained in a supervised manner using the distal-corrected poses $X^C$ and GT poses with loss $\\mathcal{L}_R$ (eq. 9). Steps 1 and 2 can be easily combined, but we separated them in order to speed up the training of $C$ and $R$ by avoiding repeated backbone model inference on the same images over the course of our work. Both are trained using the Adam optimizer for 30 epochs with batch size = 4096 using lr = 1e-4, $\\lambda_1$ = 1.0, and $\\lambda_2$ = 0.5. For TTA we take 2 steps with lr = 5e-4.\nAt inference, we perform per-sample adaptation and use test batch sizes = 1. We set the energy threshold = 800, and apply it to poses in millimetre scale. Identical training and inference hyperparameters are used across all backbones and datasets. No advanced hyperparameter searching or tuning was performed. An NVIDIA TITAN RTX GPU is used to produce all backbone pose estimations and to train and evaluate our networks."}, {"title": "4.2. Datasets", "content": "To train $C$ and $R$, we use the training splits of the MPII [29] and 3DHP [30] dataset. We limit ourselves to these datasets to demonstrate that ESCAPE requires no data other than that used to train the backbone in the first place. To evaluate ESCAPE, we follow prior works and use the 3DPW [26], 3DHP, and SURREAL [31] dataset test splits.\n\u2022 3DHP consists of in-the-wild and in-the-lab data from 8 subjects from 8 camera viewpoints. Six subjects (10.5k frames) make up the training set, two (2.9k frames) make up the test set.\n\u2022 MPII consists of a very wide range of everyday in-the-wild and indoor human activities extracted from YouTube videos (16.4k frames). While it is usually only used as a 2D dataset, we use pseudo-GT 3D annotations of MPII as the 3D dataset.\n\u2022 3DPW is an in-the-wild dataset of subjects performing dynamic tasks including climbing, boxing, and playing basketball (35.5k frames). It"}, {"title": null, "content": "contains many severe occlusions and has more dynamic camera poses than 3DHP.\n\u2022 SURREAL is a large-scale (6.5M frames) and realistic synthetic human pose estimation dataset containing 145 subjects with a large variety of poses, body shapes, clothings, viewpoints and backgrounds. The test set contains 30 of the subjects (1.2M frames)."}, {"title": "4.3. Evaluation Metrics", "content": "Following previous works, we use the following metrics for evaluation: 1) mean per-joint position error (MPJPE) and 2) Procrustes-aligned mean per-joint position error (PA-MPJPE). Both metrics are measured in millimetres between the predicted and GT 3D coordinates, after root joint alignment."}, {"title": "4.4. Quantitative Results", "content": "3DPW Results. In Tab. 1, we compare the all-keypoint performance of ESCAPE against state-of-the-art methods on the 3DPW test set. We report the distal performance improvement in Tab. 5. On 3DPW, ESCAPE improves the distal predictions of existing methods by significant margins: up to 6.3% (Tab. 5), and improves the SOTA by up to 3.4% on all-keypoints (Tab. 1).\n3DHP Results. Tab. 2 presents results of ESCAPE and other state-of-the-art methods on the 3DHP test set. We again report the distal performance improvement in Tab. 5. ESCAPE improves distal predictions by up to 6.8% on 3DHP (Tab. 5), and improves the SOTA by up to to 1.4% over all-keypoints (Tab. 2).\nSURREAL Results. Tab. 3 presents results of ESCAPE and other state-of-the-art backbone methods on the SURREAL test set. We again report the distal performance improvement in Tab. 5. ESCAPE improves distal predictions by up to 4.0% on SURREAL (Tab. 5), and improves the SOTA by up to to 1.4% over all-keypoints (Tab. 3).\nInference Time. In Tab. 4 we show that ESCAPE takes the least computation time compared to existing test-time adaptation methods. We observe a 50x speedup over DynaBOA, 37x over BOA, 19x over DAPA, and 3x over the recent CycleAdapt, which is the fastest of the prior arts by an order of magnitude. Additionally, in practice where no ground-truth 2D poses are available, the inference times of existing methods"}, {"title": null, "content": "will be increased by needing to compute estimated 2D keypoints for supervision. ESCAPE uses no 2D pose supervision at all and so does not have this drawback. BOA [10] and DynaBOA [14] have massive inference times due to performing two network updates on every image. The inference time of DAPA [11] suffers from rendering an image of a synthetic 3D pose for every image. While CycleAdapt [12] and the other methods tune all parameters in the large pretrained backbone during adaptation to every encountered sample, ESCAPE only adapts to hard samples and only tunes the small correction network $C$ during adaptation, leaving the backbone frozen."}, {"title": "4.5. Qualitative Results", "content": "Fig. 5 presents a qualitative evaluation of corrections made to PARE backbone predictions on samples from 3DPW. Input images and the corresponding GT, initial backbone prediction, and distal-corrected predictions from ESCAPE are shown for each. Even though the backbone predictions are already quite good, ESCAPE is able to significantly correct their distal keypoints to be closer to those of the ground-truth pose.\nFailure Cases. While the proposed method shows promising results, there are instances in which it is unable to succesfully improve the backbone prediction. To investigate the failure modes of ESCAPE, we consider its worst performing samples (i.e., with the greatest increase in MPJPE/PA-MPJPE of corrected pose vs backbone estimation) and specifically noted two major categories of backbone estimation mistakes which ESCAPE has difficulty correcting: 1) major overall pose (torso) misalignment, and 2) major simultaneous distal and near-distal keypoint mistakes (elbows, knees). We present some examples of these backbone mistakes and the corresponding ESCAPE corrections in Fig. 6).\nOverall, we observe that despite the large variations in actions, camera position, and lighting, ESCAPE is able to noticeably improve the backbone predictions."}, {"title": null, "content": "6 we illustrate representative failure cases for ESCAPE, selected from the worst performing samples on PW3D using the PARE backbone. For each example, the input image (1st column) and corresponding GT, initial backbone prediction, and distal-corrected predictions from ESCAPE (the 2nd, 3rd, 4th columns) are shown.\nThe first category primarily affects the corrected pose MPJPE but may still result in improved PA-MPJPE. In this case, the estimated pose has a significant misalignment w.r.t the GT pose (most often via torso orientation error) so even if the estimated pose has generally correct inter-keypoint relationships, a well-trained ESCAPE will make corrections which are reasonable within the mistaken orientation but which increase the error relative to the GT orientation. The second category is more challenging since it generally causes an irrecoverable loss in information for the affected limb. Considering the second example in Fig. 6, if both the left knee and left ankle keypoints have major mistakes which changes a stair-climbing stride to a firmly planted crouch, ESCAPE can not successfully predict the real GT pose since it only has the estimated pose without any other context or input.\nWhile these mistakes highlight some of the drawbacks stemming from the low-dimensional keypoint input of ESCAPE, the advantages in simplicity and speed make it a worthwhile trade-off. Additionally, it should be noted that the proposed corrections maintain reasonable poses even in these most"}, {"title": "4.6. Ablation Studies", "content": "Effectiveness of energy threshold in selecting hard samples. We measure the average backbone prediction MPJPE over each full dataset (Tab. 6, column All) and over each corresponding subset of energy-selected samples (Tab. 6, column OOD). Additionally, we measure the fraction of the top 10% error samples remaining after energy thresholding. The results are summarized in Tab. 6. The same energy threshold is used across all datasets and backbones. For all datasets and backbones, we observe that the average MPJPE of the energy threshold selected samples is always higher than that of the full set of samples, indicating that the energy threshold effectively keeps hard (OOD) samples while rejecting easier (ID) samples. In the last column of Tab. 6 we observe that despite using the same E threshold value across all backbones and datasets, more than 60% of the top 10% samples pass the energy threshold on the 3DHP dataset. This is comparable with prior work using the energy function [15] which found that even in classification, roughly 40% of OOD and ID samples were overlapped."}, {"title": null, "content": "plied. These findings demonstrate the effectiveness of each component of the proposed framework.\nWe also show the number of test samples which are adapted to in the fourth column (TTA). The last column reports the average increase in inference time introduced on top of the inference time of the backbone model. Selecting OOD samples for test time adaptation significantly decreases the number of test samples that were used for adaptation (more than 50%) and lowers the inference time by about 60% while the improvements remain unchanged."}, {"title": "Alternative OOD selection method.", "content": "While we have proposed using the Energy function for OOD sample selection in our framework, other methods can easily be used in its place. Since the accuracy of the OOD sample selection method has a great impact on the effectiveness of ESCAPE, we investigate the use of a recent OOD detection method, NNGuide [33], in place of the Energy function; and compare the results for PW3D and HP3D are in Table 8. We report the MPJPE of the distal keypoints in the \"Distal MPJPE\u201d columns and the number of samples selected for intensive adaptation in the \u201c# TTA\" columns. An NNGuide OOD score threshold of 63 was empirically determined such that the number of selected samples is"}, {"title": null, "content": "comparable to the Energy function, and we use k = 100 since our training data is not too large. We note that the results are robust to the two studied OOD detection methods (as indicated by overall comparable performances), despite that NNGuide requires some learning from training samples.\nEnergy based sample selection with BOA. The use of the energy function to select hard samples for adaptation is not limited to our framework but can be used to make existing TTA methods more efficient and practical. By choosing hard, OOD samples to adapt to instead of adapting blindly to all incoming samples, the large computational overhead of TTA methods can be mitigated while retaining most of their improvement. To evaluate this claim, we investigate the effectiveness of using our energy method to select samples for adaptation with BOA.\nIn Tab. 9 we report the results of using BOA to adapt a pretrained HMR [34] network to 3DPW on all samples (+BOA), and by selecting samples for"}, {"title": null, "content": "adaptation using our proposed Energy-based method with different Energy threshold values (+E800, +E750, +E700). We also compare against a naive random baseline which selects incoming samples with probability equal to the fraction of samples selected by the Energy threshold. That is, such that its number of selected samples is comparable to that selected by the Energy threshold. We report results with Energy threshold values of 800, 750, and 700 and include corresponding random baselines for each threshold value (+Rand).\nThere are a few differences in our setup compared to the original BOA setup which should be noted. It is common for existing adaptation works, including BOA, to demonstrate the capabilities of their method in adapting a poorly trained model to 3DPW. Generally, this means pre-training the backbone pose estimator only on the H36M [35] dataset, resulting in an impractical network that suffers from unrealistically large domain shifts at inference. While this is a useful approach for demonstration, we aim to show the benefit of our Energy selection method in a realistic setting, where the backbone has been trained on a variety of common datasets and shows good generally performance, but would still benefit from closing the train-test distribution gap. Instead of just H36M, we pretrain the same HMR backbone on a more realistic collection of datasets: H36M, 3DHP [30], LSP [36], lspet [37], MPII [29], and COCO 2014 [38]. We use the implementation"}, {"title": null, "content": "provided by [39] for this.\nWe do not use BOA's temporal-wise losses since by selecting poses for adaptation according to the Energy threshold or random sampling, we no longer have a fixed interval between frames. Additionally, we found the original hyperparameters of BOA to be unsuitable for the realistically trained network and reduced the number of adaptation steps from 7 to 3, reduced the lower-level fast learning rate from 8e-6 to 4e-6, and reducedthe upper-level learning rate from 3e-6 to 1e-6.\nWe find that adapting to only a fraction of incoming samples can keep most of the improvement gained by adapting to all samples. Using an Energy threshold of 750 to select samples for adaptation with B\u041e\u0410 has a 7x faster average inference time than adapting to all samples, while keeping the majority of the improvement. Naively adapting to all incoming samples with BOA increases the inference time by 51x, while only adapting to selected hard samples results in far more modest 6x, 7x, and 12x increases for energy thresholds of 700, 750, and 800. As in ESC\u0410\u0420\u0415, applying intensive adaptation to all samples encountered provides the best performance but suffers the largest computational overhead. Importantly, the Energy-based selection strategy always performs better than the random baselines. We note that the results further suggest that adapting to all incoming samples, as BOA and other methods do, is highly inefficient, since randomly sampling incoming samples without any strategy is also surprisingly effective. Overall, these results support the validity of our assumptions and demonstrate the ability of the proposed Energy-based sample selection to improve the efficiency of existing test-time adaptation methods.\nImpact of Varying Conditions. In many real-world scenes, challenges such as occlusions and varying lighting can significantly degrade the performance of pose estimation models. To systemically investigate the impact of these variations on the proposed method, we compile a new evaluation dataset comprising of 1000 images randomly selected from all PW3D test-set samples on which ESCAPE performed reasonably well (where the CNet correction gives improvement in PA-MPJPE/MPJPE over the backbone prediction, and CNet after TTA also gives improvement in PA-MPJPE/MPJPE over the un-adapted CNet correction). We then introduce synthetic variations in lighting and occlusion to create seperate variations of the new dataset and evaluate the resulting performance of ESCAPE in order to understand their impact on the performance.\nTo simulate lighting variations, we simply blend the original image with"}, {"title": null, "content": "a fully black image, with ratios of original/black of 0.3 and 0.1. To simulate occlusions, we overlay randomly sized black rectangles at random locations in the ROI defined by the GT pose bounding box. We define a \u2018Mild' setting in which the random rectangle has width ranging from 0.4x and 0.7x the bounding box width and height ranging from 0.3x to 0.6x the bounding box height. We also define a 'Moderate' setting placing a rectangle with width ranging from 0.6x and 0.8x the bounding box width and with height ranging from 0.5x to 0.8x the bounding box height. Fig. 7 provides some examples of the raw images and corresponding variations.\nFig. 7 presents some examples of the raw and synthesized samples and we summarize the resulting performance of ESCAPE with PARE backbone on the raw images and the distorted images under 4 variation settings in Tab. 10. We report both the performance of the fast CNet correction on all samples (+CNet only) and also the performance of the full proposed method with TTA applied to samples selected by the energy function threshold (+ESCAPE). The table shows that, as expected, the performance of ESCAPE is good on the raw images and that the performance of the backbone (PARE) is degraded by both increasingly darkened and increasingly occluded images. On this dataset, we report the results averaged over N=100 trials to counteract stochasticity in the TTA update on a single sample.\nDespite the challenging settings, we find that CNet remains able to significantly improve the backbone predictions and the self-consistency \u0422\u0422\u0410 remains able to improve CNet to a similar degree, demonstrating the robustness of ESCAPE. However, we note that the improvements degrade along with the backbone predictions and that occlussions in particular become more challenging for both the backbone and ESCAPE, as they increase from Mild to Moderate. As discussed in section 4.5, we identify two different major categories of backbone mistakes which ESCAPE can have difficulty correcting, both of which often result from challenging distal occlusions: 1) major overall pose (torso) misalignment, and 2) major simultaneous distal and near-distal keypoint mistakes (elbows, knees). We present some examples of these backbone mistakes and the corresponding ESCAPE corrections in Fig. 6).\nOverall, we observe that despite the large variations in actions, camera position, and lighting, ESCAPE is able to noticeably improve the backbone predictions."}, {"title": null, "content": "Figure 8: Visualization of the backbone estimation energy score PDF's for each of the condition variations added to the PW3D subset. The energy scores shift slightly but remain robust to the severe alterations to the raw images.\nsignificantly improve the estimations. Further, we demonstrate the effectiveness of the energy function in separating out hard samples and demonstrate that applying the proposed sample selection strategy to an existing TTA method massively improves its inference time while maintaining the majority of its improvement. Our experiments indicate that energy based thresholding could be effectively used to mitigate compute time increases of future adaptation methods, and could help target samples of interest. Finally, we quantitatively and qualitatively show that ESCAPE significantly improves the performance of several popular HPE models, outperforming previous methods on two public benchmark datasets. However, there are improvements to be made in future works. ESCAPE only corrects the distal keypoints, while future works should propose methods which additionally correct errors in proximal keypoints. Moreover, one of the major limitations of the pre-trained HPE model is estimating the global orientation of 3D human pose. Future work should address this limitation while optimizing the network at the inference stage. In addition, a fixed energy function threshold was used across all backbones, but more robust or adaptive approaches to energy thresholding should be developed."}, {"title": "5. Conclusions and Future Work", "content": "This work has proposed a novel selective test-time adaptation framework for 3D human pose estimation. Our framework addresses the lack of 2D supervision available in practice by proposing a novel consistency supervision based on the predicted errors of distal and proximal keypoints. We also sidestep the prohibitively large computational overhead of existing \u0422\u0422\u0410 methods in two main ways. First, by consciously selecting only the difficult OOD samples for intensive adaptation and otherwise only performing a fast, forward-pass correction. Second, by using the backbone estimator in a frozen, black box manner and only tuning a lightweight external network when intensive adaptation is indeed performed. To separate OOD and ID data, we select samples according to the recently proposed energy function threshold. We show the correction network can be effectively trained with data already used for the backbone estimator training and yet still learn to"}]}