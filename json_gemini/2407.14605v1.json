{"title": "ESCAPE: Energy-based Selective Adaptive Correction for Out-of-distribution 3D Human Pose Estimation", "authors": ["Luke Bidulka", "Mohsen Gholami", "Jiannan Zheng", "Martin J. McKeown", "Z. Jane Wang"], "abstract": "Despite recent advances in human pose estimation (HPE), poor generalization to out-of-distribution (OOD) data remains a difficult problem. While previous works have proposed Test-Time Adaptation (TTA) to bridge the train-test domain gap by refining network parameters at inference, the absence of ground-truth annotations makes it highly challenging and existing methods typically increase inference times by one or more orders of magnitude. We observe that 1) not every test time sample is OOD, and 2) HPE errors are significantly larger on distal keypoints (wrist, ankle). To this end, we propose ESCAPE: a lightweight correction and selective adaptation framework which applies a fast, forward-pass correction on most data while reserving costly TTA for OOD data. The free energy function is introduced to separate OOD samples from incoming data and a correction network is trained to estimate the errors of pretrained backbone HPE predictions on the distal keypoints. For OOD samples, we propose a novel self-consistency adaptation loss to update the correction network by leveraging the constraining relationship between distal keypoints and proximal keypoints (shoulders, hips), via a second \u201creverse\u201d network. ESCAPE improves the distal MPJPE of five popular HPE models by up to 7% on unseen data, achieves state-of-the-art results on two popular HPE benchmarks, and is significantly faster than existing adaptation methods.", "sections": [{"title": "1. Introduction", "content": "3D Human Pose Estimation (HPE) from single-view images is a fundamental task in computer vision with applications in healthcare [1]; [2], VR/AR [3], human-robot-interaction [4], etc. Recent deep-learning-based HPE methods have achieved remarkable performance [5, 6, 7, 8] on public benchmarks. Due to the immense difficulty of labeling 3D human pose data, most HPE methods are trained using public datasets which do not accurately represent the wide variety inherent in in-the-wild poses. Therefore, the pre-trained models significantly under-perform when applied to out-of-distributions (OOD) samples [9, 10]. The performance of HPE models specifically degrades in estimating the 3D distal keypoints (e.g. wrist, ankle) [11, 12].\nRecently, test-time adaptation (TTA) methods have been shown to help bridge the train-test domain gap and improve prediction performance on OOD data by fine tuning models on test data [10, 11, 12, 13]. Most of the prior works leverage the ground-truth 2D poses of the test sample to optimize the pre-trained models via 2D projection. However, ground-truth 2D poses are not available in real case scenarios and replacing them with estimated 2D keypoints significantly degrades the accuracy of prior works [12]. More-"}, {"title": "2. Related Work", "content": "3D Human Pose Estimation There are two categories of 3D human pose estimation models: parametric and non-parametric methods. The parametric methods estimate human joint angles for a parametric human mesh model (SMPL) and use that to obtain human mesh and pose [7, 8, 5]. Non-parametric methods directly estimate 3D positions of human keypoints given"}, {"title": "3. Method", "content": "We first give a general overview of the proposed selective test-time adaptation ESCAPE framework, then define the human pose correction problem setup (3.1) and describe the application of ESCAPE to this particular setting. A detailed overview of ESCAPE is shown in Fig. 2.\nOur proposed method begins with the output prediction of a pre-trained backbone model given its input data. The energy score (3.2) of this initial backbone prediction is compared against a predetermined threshold to classify the input data as out-of-distribution (OOD) or in-distribution (ID)"}, {"title": "3.1. Problem Formulation", "content": "Given an input image frame I of a person, a pre-trained human pose estimator P returns 3D human poses X \u2208 \u211d^(j\u00d73) where jis the number of keypoints:\nP(I) = X, X \u2208 \u211d^(j\u00d73) (1)\nThe proximal and distal keypoints Xp and X\u0189 are subsets of the full keypoints X. The proximal keypoints Xp are the keypoints at the base of each human limb: the right/left hips and the right/left shoulders. The distal keypoints XD are the keypoints at the end of each human limb: the right/left feet and the right/left hands. Estimating proximal joints is an easier task because of their greater bio-mechanical constraints, and human pose estimators have correspondingly lower estimation errors on proximal keypoints than on distal keypoints. We leverage this in the design of the reverse network test-time adaptation objective outlined in section 3.4."}, {"title": "3.2. Energy-based Sample Selection", "content": "To select hard samples from incoming data for inference time adaptation, we use the Energy Function, which has been shown to be effective in OOD"}, {"title": "3.3. Correction Network", "content": "To improve backbone HPE predictions on the highly uncertain distal keypoints, we propose learning a simple correction network (CNet) C to estimate the distal keypoint errors of input backbone pose predictions. The errors can then be directly applied to the distal keypoints of the backbone prediction to obtain a corrected estimation. That is, C outputs estimated 3D errors for the d distal keypoints \u2206X\u0189 \u2208 \u211d^(d\u00d73), given an input 3D human keypoint estimation X:\nAXD = C(X), (3)\nand X is subsequently adjusted using the predicted errors AXD to get a corrected pose XC. Note that X is identical to X except for the adjusted distal keypoints:\nXC = X \u2013 AXD (4)\nWe train C in a fully supervised manner, using the ground-truth 3D pose distal keypoints YD from the training set of the backbone. The distal error is defined as \u2206XD = YD - XD. The L2 norm between estimated distal errors AXD and ground-truth distal errors AXD is then used to train C:\nL\u2081 = || C(X), AXD||2, (5)\nWhile straightforward, using only L\u2081 as supervision can overly encourage the network to address only scale issues in the initial backbone estimate."}, {"title": "3.4. Test-Time Adaptation via Self-Consistency", "content": "To adapt CNet to harder, OOD samples during inference, we define a Self-Consistency loss which uses only the backbone pose sample X, requiring no inference time ground-truth keypoints. This loss relies on a reverse network (RCNet), R, which aims to learn the biomechanical reverse of the CNet task. R takes the corrected 3D human keypoint estimation X as input and outputs estimated 3D errors for each of the p proximal keypoints AXP \u2208 Rp\u00d73.\nAXp = R(XC) (8)\nAt the training stage, we use ground truth 3D poses from proximal key-points to train R. The proximal error is defined as \u2206Xp = Yp \u2013 Xp. The L2 norm between estimated proximal errors \u2206Xp and ground-truth distal errors AXP is defined as:\nLR = || R(X), \u2206XD||2. (9)\nR is trained to predict proximal corrections given the pose corrected by C, XC. It only ever takes XC as input. Learning R is easier than learning C since the proximal keypoints are more constrained compared with distal keypoints and therefore, once trained, R is kept frozen and used in TTA to adapt C."}, {"title": "4. Experiments", "content": "In this section, we introduce the datasets, metrics and implementation details. We subsequently present a thorough evaluation of our proposed method, including experimental results, comparisons to state-of-the-art methods, and ablation studies on different parts of our framework."}, {"title": "4.1. Experimental Setup", "content": "Backbone Networks. To demonstrate the general applicability of ESCAPE, we perform separate experiments using five widely-used and representative backbone HPE models: HybrIK [6], SPIN [5], PARE [7], BMSE [27], and CLIFF [8]. Pose estimations from each backbone on the train and test data are produced and used to train and evaluate a separate pair of C and R for each backbone.\nImplementation Details. The architecture of the residual networks used for C and R are identical, and follow that proposed by [28], which is often used as a 3D pose estimation baseline. A diagram of this architecture is shown in Fig. 3. First, the flattened 3D skeleton keypoints are embedded via a linear layer followed by a batch norm layer, ReLU activation, and dropout layer. The embedding is passed through a series of residual blocks, then passed to a final linear layer to produce an output set of 4x 3D keypoint error vectors. We set all linear layer sizes = 512, use dropout=0.3, and use N=1 residual block. Our evaluation datasets use 17 keypoints in Human3.6M format, thus the network input shapes are both (B, 51)."}, {"title": "4.2. Datasets", "content": "To train C and R, we use the training splits of the MPII [29] and 3DHP [30] dataset. We limit ourselves to these datasets to demonstrate that ESCAPE requires no data other than that used to train the backbone in the first place. To evaluate ESCAPE, we follow prior works and use the 3DPW [26], 3DHP, and SURREAL [31] dataset test splits.\n\u2022 3DHP consists of in-the-wild and in-the-lab data from 8 subjects from 8 camera viewpoints. Six subjects (10.5k frames) make up the training set, two (2.9k frames) make up the test set.\n\u2022 MPII consists of a very wide range of everyday in-the-wild and indoor human activities extracted from YouTube videos (16.4k frames). While it is usually only used as a 2D dataset, we use pseudo-GT 3D annotations of MPII as the 3D dataset.\n\u2022 3DPW is an in-the-wild dataset of subjects performing dynamic tasks including climbing, boxing, and playing basketball (35.5k frames). It"}, {"title": "4.3. Evaluation Metrics", "content": "Following previous works, we use the following metrics for evaluation: 1) mean per-joint position error (MPJPE) and 2) Procrustes-aligned mean per-joint position error (PA-MPJPE). Both metrics are measured in millimetres between the predicted and GT 3D coordinates, after root joint alignment."}, {"title": "4.4. Quantitative Results", "content": "3DPW Results. In Tab. 1, we compare the all-keypoint performance of ESCAPE against state-of-the-art methods on the 3DPW test set. We report the distal performance improvement in Tab. 5. On 3DPW, ESCAPE improves the distal predictions of existing methods by significant margins: up to 6.3% (Tab. 5), and improves the SOTA by up to 3.4% on all-keypoints (Tab. 1).\n3DHP Results. Tab. 2 presents results of ESCAPE and other state-of-the-art methods on the 3DHP test set. We again report the distal performance improvement in Tab. 5. ESCAPE improves distal predictions by up to 6.8% on 3DHP (Tab. 5), and improves the SOTA by up to to 1.4% over all-keypoints (Tab. 2).\nSURREAL Results. Tab. 3 presents results of ESCAPE and other state-of-the-art backbone methods on the SURREAL test set. We again report the distal performance improvement in Tab. 5. ESCAPE improves distal predictions by up to 4.0% on SURREAL (Tab. 5), and improves the SOTA by up to to 1.4% over all-keypoints (Tab. 3).\nInference Time. In Tab. 4 we show that ESCAPE takes the least computation time compared to existing test-time adaptation methods. We observe a 50x speedup over DynaBOA, 37x over BOA, 19x over DAPA, and 3x over the recent CycleAdapt, which is the fastest of the prior arts by an order of magnitude. Additionally, in practice where no ground-truth 2D poses are available, the inference times of existing methods"}, {"title": "4.5. Qualitative Results", "content": "Fig. 5 presents a qualitative evaluation of corrections made to PARE backbone predictions on samples from 3DPW. Input images and the corresponding GT, initial backbone prediction, and distal-corrected predictions from ESCAPE are shown for each. Even though the backbone predictions are already quite good, ESCAPE is able to significantly correct their distal keypoints to be closer to those of the ground-truth pose.\nFailure Cases. While the proposed method shows promising results, there are instances in which it is unable to succesfully improve the backbone prediction. To investigate the failure modes of ESCAPE, we consider its worst performing samples (i.e., with the greatest increase in MPJPE/PA-MPJPE of corrected pose vs backbone estimation) and specifically noted two major categories of backbone estimation mistakes which ESCAPE has difficulty correcting: 1) major overall pose (torso) misalignment, and 2) major simultaneous distal and near-distal keypoint mistakes (elbows, knees), both of which are due to upstream mistakes made by the backbone model. In Fig."}, {"title": "4.6. Ablation Studies", "content": "Effectiveness of energy threshold in selecting hard samples. We measure the average backbone prediction MPJPE over each full dataset (Tab. 6, column All) and over each corresponding subset of energy-selected samples (Tab. 6, column OOD). Additionally, we measure the fraction of the top 10% error samples remaining after energy thresholding. The results are summarized in Tab. 6. The same energy threshold is used across all datasets and backbones. For all datasets and backbones, we observe that the average MPJPE of the energy threshold selected samples is always higher than that of the full set of samples, indicating that the energy threshold effectively keeps hard (OOD) samples while rejecting easier (ID) samples. In the last column of Tab. 6 we observe that despite using the same E threshold value across all backbones and datasets, more than 60% of the top 10% samples pass the energy threshold on the 3DHP dataset. This is comparable with prior work using the energy function [15] which found that even in classification, roughly 40% of OOD and ID samples were overlapped."}, {"title": "5. Conclusions and Future Work", "content": "This work has proposed a novel selective test-time adaptation framework for 3D human pose estimation. Our framework addresses the lack of 2D supervision available in practice by proposing a novel consistency supervision based on the predicted errors of distal and proximal keypoints. We also sidestep the prohibitively large computational overhead of existing TTA methods in two main ways. First, by consciously selecting only the difficult OOD samples for intensive adaptation and otherwise only performing a fast, forward-pass correction. Second, by using the backbone estimator in a frozen, black box manner and only tuning a lightweight external network when intensive adaptation is indeed performed. To separate OOD and ID data, we select samples according to the recently proposed energy function threshold. We show the correction network can be effectively trained with data already used for the backbone estimator training and yet still learn to"}]}