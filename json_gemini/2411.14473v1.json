{"title": "Large Language Model for Qualitative Research - A Systematic Mapping Study", "authors": ["Cau\u00e3 Ferreira Barros", "Bruna Borges Azevedo", "Valdemar Vicente Graciano Neto", "Mohamad Kassab", "Marcos Kalinowski", "Hugo Alexandre D. do Nascimento", "Michelle C.G.S.P. Bandeira"], "abstract": "The exponential growth of text-based data in domains such as healthcare, education, and social sciences has outpaced the capacity of traditional qualitative analysis methods, which are time-intensive and prone to subjectivity. Large Language Models (LLMs), powered by advanced generative AI, have emerged as transformative tools capable of automating and enhancing qualitative analysis. This study systematically maps the literature on the use of LLMs for qualitative research, exploring their application contexts, configurations, methodologies, and evaluation metrics. Findings reveal that LLMs are utilized across diverse fields, demonstrating the potential to automate processes traditionally requiring extensive human input. However, challenges such as reliance on prompt engineering, occasional inaccuracies, and contextual limitations remain significant barriers. This research highlights opportunities for integrating LLMs with human expertise, improving model robustness, and refining evaluation methodologies. By synthesizing trends and identifying research gaps, this study aims to guide future innovations in the application of LLMs for qualitative analysis.", "sections": [{"title": "I. INTRODUCTION", "content": "The presence of Artificial Intelligence (AI) has been intensifying in supporting various human activities. Generative Artificial Intelligence (Generative AI) creates new data from learned patterns, facilitating the automation of complex processes. A promising application of this technology is Large Language Models (LLMs), which have proven effective in analyzing large volumes of text, enabling the extraction and understanding of information [1] [2] [3].\nLLMs are specialized Generative AI models designed for text processing and generation. The term 'large' refers to the massive number of parameters and the extensive textual data used in their training, allowing these models to identify complex patterns in natural language. Based on these patterns, LLMs can perform various tasks, such as machine translation, summarization, text editing, chatbot assistance, and even code generation for software development. These capabilities arise from LLMs ability to understand context and adjust their responses to different demands, making them powerful tools for automating tasks that previously required human intervention [4] [5].\nOne of the prominent fields for applying LLMs is qualitative analysis. Qualitative analysis is a research approach aimed at exploring and interpreting collected data to identify, develop, and categorize concepts based on their properties and dimensions. This process involves segmenting the data into smaller parts, continuously comparing them, and assigning labels that accurately synthesize observed events. Through this method, raw data is transformed into abstract concepts, allowing the formation of broader categories that enable a deeper understanding of the phenomena being studied [6].\nIn software engineering, qualitative analysis using LLMs becomes a powerful tool by providing an analytical framework to organize large volumes of unstructured textual data. This facilitates the identification of underlying patterns and the development of categories that help in understanding complex problems. By avoiding biases and premature interpretations, researchers can uncover valuable insights that aid in the formulation of new theories and the enhancement of analytical processes, especially in contexts where the complexity of data requires a thorough and systematic approach to ensure effective and applicable results [6].\nLLMs can significantly reduce the effort and time required for qualitative analysis of large data volumes by automating steps that traditionally demand exhaustive human analysis.\nThe main contribution of this paper is to report the results of a systematic mapping aimed at analyzing the state of the art on the use of LLMs in qualitative analysis, with the goal of identifying trends, research gaps, and opportunities for future investigations. This study seeks to provide valuable insights for researchers looking to integrate LLMs into their qualitative analysis processes, guiding them toward works that offer detailed prompt data and information on their effectiveness."}, {"title": "II. BACKGROUND", "content": "While qualitative research methods, such as grounded theory or thematic analysis, provide valuable insights into complex phenomena, they face significant challenges. For instance, manual coding and categorization processes are notoriously labor-intensive, often requiring weeks or even months of effort to analyze large datasets effectively [6]. Additionally, these methods are prone to subjectivity, as researchers' biases can unconsciously influence coding decisions, impacting the reliability and validity of findings [8].\nMoreover, traditional methods struggle with scalability. For example, analyzing hundreds of interviews or millions of social media posts in real time is impractical for human analysts. These limitations hinder the efficiency and breadth of qualitative analysis, particularly in rapidly evolving fields like software engineering or healthcare.\nLLMs offer transformative solutions to many challenges faced by traditional qualitative research methods. LLMs, such as GPT-4, LLaMA, and ChatGPT, are generative AI systems trained on vast datasets, enabling them to understand and generate human-like text [4], [5]. By leveraging billions of parameters, these models excel in identifying patterns, performing thematic analysis, and automating coding processes.\nAutomation of Coding: LLMs can rapidly process and analyze text, performing open and axial coding in minutes. For example, ChatGPT has been employed to analyze qualitative survey responses, extracting key themes such as student satisfaction and resource accessibility in educational research [12], [11].\nReducing Subjectivity: While human coding is prone to inconsistency, LLMs provide consistent and reproducible outputs, especially when fine-tuned or used with standardized prompts [14]. This minimizes bias and ensures greater reliability in findings.\nScalability and Speed: Unlike human analysts, LLMs can handle vast amounts of unstructured data efficiently. For example, in healthcare studies, LLMs have been used to process patient feedback, identifying recurring themes in hours rather than weeks [17]."}, {"title": "C. Illustrative Examples", "content": "The following examples demonstrate the transformative potential of LLMs:\nHealthcare Case Study: In a study analyzing patient feedback, an open-source LLM was fine-tuned to perform inductive thematic analysis, identifying critical concerns like delays in care and communication breakdowns [17]. This process significantly reduced the time required for analysis while maintaining accuracy.\nEducation Use Case: ChatGPT was used to categorize open-ended survey responses from students, identifying patterns such as dissatisfaction with online learning platforms and preferences for in-person classes [12]. The automated approach streamlined analysis, allowing researchers to focus on interpreting results."}, {"title": "D. Motivation for This Study", "content": "Despite their potential, LLMs face limitations that must be addressed for optimal application in qualitative research. For example, they are highly dependent on well-structured prompts, which, if poorly designed, can lead to inaccurate or incomplete outputs [19], [17]. Additionally, LLMs can generate \u201challucinations\u201d-fabricated responses that lack basis in the data [13]. These challenges highlight the need for systematic studies to explore best practices, identify gaps, and refine methodologies for integrating LLMs into qualitative research.\nThis study aims to fill this gap by systematically mapping the current state of the art in LLM applications for qualitative research. By analyzing existing studies, this research identifies trends, challenges, and opportunities, providing a roadmap for researchers seeking to leverage LLMs effectively in their workflows."}, {"title": "III. SYSTEMATIC MAPPING STUDY (SMS)", "content": "The structure adopted in this systematic mapping study was developed in accordance with the guidelines proposed by Kitchenham and Charters [10]. The main stages carried out include planning, conducting and reporting.\nwas used as a support tool for planning, conducting, and reporting the systematic mapping study, enabling the documentation and execution of the protocol."}, {"title": "A. Planning", "content": "The objective of this systematic mapping study was to identify the state of the art regarding the relationship between LLMs and qualitative analysis. Thus, the studies of interest include those that assess the application of LLMs in conducting qualitative analyses. Consequently, research questions and the corresponding protocol were established.\nRQ1: What is the context in which LLMs have been applied to support qualitative analysis?\nRationale: This question aims to identify the application contexts of LLMs, which is crucial for mapping the study areas where these models have demonstrated the most effectiveness.\nRQ2: What model and LLM configuration were used, and which data sources were utilized?\nRationale: Focuses on the specific LLM models, their configurations, and the data sources used, given that different models and configurations can significantly influence the accuracy and effectiveness of qualitative analysis.\nRQ3: How was the LLM used to conduct qualitative analysis, and what techniques or methodologies were applied?\nRationale: Investigates how LLMs were utilized in conducting qualitative analyses, including the techniques and methodologies applied. This question is essential for understanding best practices and adapting existing methodologies to maximize the potential of LLMs in different analysis contexts.\nRQ4: How was the effectiveness of the LLM evaluated, and what were the main outcomes?\nRationale: Analyzes whether the effectiveness of LLMs was assessed and the key results obtained, which is essential for measuring the added value of this approach compared to traditional methods, ensuring the validation of its application in supporting qualitative research.\nRQ5: What limitations and future research directions were reported?\nRationale: Examines the identified limitations and future research directions, contributing to the definition of continuous improvement strategies and refinement of the technology, ensuring that the use of LLMs becomes robust, accurate, and accessible in future applications."}, {"title": "B. Search Strategy", "content": "A generic search string was developed using the keywords \"LLM\" and \"Qualitative Analysis\". These keywords were connected using the logical operator AND, while their synonyms were linked with the OR operator. The terms in the search string were selected to ensure broader coverage of relevant studies. The string was tested in various configurations on the Scopus database, and after a calibration process, the final version defined was:\n(\"LLM\" OR \"LLMs\" OR \"Large Language Model\" OR \"Large Language Models\") AND (\"Qualitative Analysis\" OR \"Qualitative Research\" OR \"Grounded Theory\")\nIn addition to Scopus, searches were also conducted in the ACM Digital Library, IEEExplore, Web of Science, and SBC Open Lib databases. Considering the recent nature of the topic and the possibility of studies still awaiting peer review, the Arxiv database was also consulted. The searches were carried out during the months of September and October 2024, using filters applied to titles, abstracts, and keywords. No restrictions were placed on the starting publication year. In total, 354 studies were retrieved."}, {"title": "C. Selection Criteria", "content": "Subsequently, selection criteria were established to support the proper identification of relevant studies for this systematic mapping. Titles, abstracts, and keywords were read and analyzed, with the selection criteria outlined in Table I (where IC refers to Inclusion Criteria, and EC refers to Exclusion Criteria)."}, {"title": "D. Data Extraction", "content": "A questionnaire was developed to guide the data extraction process. This extraction criterion (DE, which refers to data extraction) is designed to address the research questions (RQ) defined in the study. The questions in the extraction form contain pre-defined response options to ensure consistency in data collection. Table II presents the extraction criteria (DE) and maps each one to the corresponding research questions (RQ)."}, {"title": "E. Conducting", "content": "criteria (DE1 to DE16) were used to compose the prompt, and ChatGPT\u00ae was employed in the data extraction stage of the studies analyzed in this systematic mapping. Polak and Morgan [11] reported results close to 90% precision and recall for their proposed method, named ChatExtract, which leverages LLMs like GPT-4 in the data extraction process. Syriani, David, and Kumar [13] highlighted in their findings that the use of ChatGPT for automating the article screening process in systematic reviews shows promising potential, achieving an accuracy of 82%.\nRegarding data extraction DE7, open-ended responses were obtained, which involved manual content analysis, as well as consulting the full original text to clarify any potential doubts.\nFigure 1 illustrates the steps followed in the study selection process, starting from the execution of the search string across the databases. A total of 354 studies were retrieved, distributed as follows: 20 from the ACM Digital Library, 30 from IEEExplore, 78 from Web of Science, 32 from SBC Open Lib, 193 from Scopus, and 1 from Arxiv.\nSubsequently, a refinement process was conducted to select the final set of studies. First, duplicate studies were removed, resulting in 253 studies. Next, inclusion and exclusion criteria were applied based on the reading of titles and abstracts, reducing the total to 34 studies. In the following stage, only studies available for download were included, which further reduced the count to 21.\nIf a study did not fully meet the response for criterion DE1 (i.e., the response was \"no\" or \"partially\"), the remaining criteria were not evaluated, and the study was excluded. Additionally, if a study did not meet criterion DE11 (\"no\"), it was excluded for not describing the prompt engineering used, which is essential to ensure reproducibility.\nAt the end of this process, 7 studies remained, for which comprehensive data extraction was conducted."}, {"title": "F. Results", "content": "During the analysis of the studies, it was found that 5 out of the 7 included works (approximately 71.4%) were published in 2024, while the remaining 2 were published in 2023. These data highlight the recent nature of the topic related to the evaluation of the use of LLMs for qualitative analysis, while also reflecting the growing interest of the scientific community and the increase in the number of publications on the subject.\nRQ1: What is the context in which LLMs have been applied to support qualitative analysis?\nThe studies exploring the use of LLMs as a tool to support qualitative data analysis are concentrated in various fields, including healthcare [14] [17], education [13] [15] [19], cultural studies [18], and analysis of technological applications [16].\nRegarding the primary objective of the studies applying LLMs in qualitative analysis, three of them aimed to evaluate the capability and potential of LLMs for automating this type of analysis [13] [15] [19]. In studies [14] [18], the main focus was on automating the qualitative data analysis process. Meanwhile, the works by [16] [17] aimed to compare the results of qualitative analysis assisted by LLMs with those obtained through manual analysis.\nRQ2: What LLM model and configuration were used, and which data sources were utilized?\nRegarding the LLM models tested in the studies, the following were used: ChatGPT [14] [16] [19], LLaMA-2 [17], ATLAS.TI [13], BERT [15], and the Sabi\u00e1-2 medium model [18]. Approximately 57.1% of the studies (4 out of 7) reported making adjustments or adaptations to the LLM to carry out the analyses [13] [14] [15] [17].\nAs for the data sources used in the included studies, most employed data from interviews [13] [17] [19], followed by those that analyzed documents [14] [15], social media (user reviews of applications) [16], and song lyrics [18].\nRQ3: How was the LLM used to conduct qualitative analysis, and what techniques or methodologies were applied?\nAll included studies employed techniques and/or methodologies to support qualitative data analysis, also detailing the prompt engineering used. Two studies applied theme extraction combined with content analysis [13] [16]. In other studies, the techniques of open coding and theme extraction were used in conjunction with content analysis [17] [19]. Two studies combined categorization and theme extraction techniques; one integrated the Grounded Theory method [14], and the other used content analysis [15]. In study [18], three techniques were tested: categorization, theme extraction, and topic extraction.\nRegarding how LLMs were used to conduct the qualitative analysis process, the approaches varied. Three studies utilized prompt-based instruction for the LLM [16] [17] [19]. In study [18], the authors combined prompt-based instruction with automated extraction using the BERT model, while study [15] exclusively conducted automated extraction using the BERT model. The remaining studies employed automated extraction using ATLAS.TI, associated with a specific technique [13], or conducted model training [14].\nRQ4: How was the effectiveness of the LLM evaluated, and what were the main results?\nAll seven included studies conducted comparisons between qualitative analysis performed with the support of LLMs and traditional analysis methods. In some cases, such as in studies [13] [14] [15] [17] [19], the use of LLMs yielded results classified as equivalent to traditional methods. In study [18], the performance of the LLM surpassed that of traditional methods. Conversely, in study [16], the final result was considered inferior to that of traditional analysis, particularly when compared to human analysis.\nThe metrics used to evaluate performance included comparisons between LLM-assisted analysis and human analysis [13] [16] [17] [19], comparisons with human analysis and accuracy [15], and comparisons involving human analysis, accuracy, F1 Score, and precision [14] [18].\nRQ5: What limitations and future research directions were reported?\nAll the included studies reported specific limitations regarding the use of LLMs in performing qualitative analyses. One limitation mentioned was the dependence on well-structured prompts to achieve accurate and reliable results [17] [19]. Another limitation relates to the tendency of LLMs to generate \"hallucinations,\" meaning responses that lack a clear justification in the data [13] [19]. Additionally, the risk of inherent biases in the models was noted, especially when dealing with sensitive information [17]. Other limitations included difficulties in assigning topics to subjective expressions [18], limitations in context sensitivity and emotional nuances"}, {"title": "IV. SUMMARY OF CONTRIBUTIONS AND RESEARCH OPPORTUNITIES", "content": "This section summarizes the main results and contributions obtained in this study, as well as the research opportunities identified through this mapping. The key contributions of this paper include:\nMapping of the field: This study provides an overview of the use of LLMs for qualitative analysis, addressing various dimensions of the area, such as: (i) the contexts in which LLMs have been applied to support qualitative analysis, (ii) the LLM models used and the data sources employed, (iii) the techniques and methodologies adopted in conducting qualitative analysis with the help of LLMs, (iv) the metrics used to evaluate effectiveness, and (v) the limitations and research opportunities identified in the current state of the art.\nThis mapping focused on studies that reported the use of LLMs for qualitative analysis and detailed the prompt engineering employed, which is an essential requirement to ensure replicability. The results highlight the recent nature of exploration in this field, reflected by the relatively low number of included studies, most of which were published recently in 2023 and 2024.\nHowever, the findings allowed for the identification of several research opportunities. While LLMs demonstrate performance close to or even superior to traditional methods in some cases, there is a clear need for improvements. One aspect that requires further exploration is the limitations associated with the reliance on well-structured prompts. In this regard, it would be relevant to explore approaches that enhance LLMs' textual understanding, enabling greater flexibility in qualitative analyses.\nAdditionally, there are opportunities to investigate new architectures or techniques that could improve the capture of semantic and subjective nuances, thereby ensuring more accurate and robust analyses. Another opportunity lies in researching methods to reduce \"hallucinations\u201d and biases, for instance, through fine-tuning models or adopting techniques for validation and filtering of responses. Moreover, the development of interfaces that make these models more accessible to researchers who are not AI specialists is another area worth exploring. Finally, creating a standardized and robust evaluation metric capable of capturing the complexity of qualitative analysis performed by LLMs represents a promising line of investigation."}, {"title": "V. THREATS TO VALIDITY", "content": "A concern when using LLMs to automate the selection of studies is the potential loss of knowledge that would normally be acquired during a full reading of the articles. Manual reviews allow researchers to better understand the field of study, identifying nuances and contexts that may go unnoticed in an automated analysis. This acquired knowledge can positively influence the quality of the analysis. To mitigate this risk, we conducted additional checks through comprehensive readings of the articles to clarify any doubts, ensuring a more solid and well-founded understanding.\nAnother concern is the dichotomy in using LLMs both for data extraction and for investigating their effectiveness in qualitative research, which could create a potential conflict of interest. This may lead to confirmation bias, where the use of the LLM influences results in a way that favors its own application. To ensure the objectivity and integrity of the study, we took rigorous measures, relying on solid references from the analyzed articles to ensure that conclusions were based on evidence and not merely on the inferences generated by the model.\nOther factors that may have influenced the results presented in this systematic mapping include threats to data validity, as well as internal, external, and construct validity.\nData Validity: One concern related to data validity is that ChatGPT may exhibit a certain level of superficiality. While robust, it lacks the deep contextual understanding that a human researcher can achieve. This may result in information being extracted incompletely or without sufficient analytical depth. To mitigate this threat, we adopted a manual review approach. Whenever doubts arose regarding the accuracy of the information provided by the model, a full reading of the articles was conducted. This procedure aimed to ensure that critical information was not overlooked, thus providing a more accurate and contextualized analysis.\nInternal Validity: Since two researchers were involved in the article selection process, there is a risk that inclusion criteria might vary due to individual biases. Differences in interpretation could affect the consistency of study selection. To mitigate this threat, we established standardized selection criteria, requiring that articles specifically focus on the use of LLMs for qualitative analysis. In cases of uncertainty, the researchers held joint discussions to reach a consensus, ensuring greater uniformity in the selection process.\nExternal Validity: Generalizing the results is crucial to ensure that the conclusions of this study can be applied to different contexts and diverse populations. To address this concern, studies were selected from various fields, including healthcare, education, technology, and others. This selection aimed to assess whether the techniques used and the results obtained would be replicable across multiple domains. Through this approach, we sought to demonstrate that the conclusions presented have the potential to be generalized beyond the initial scope of the study, thereby enhancing their applicability and relevance in various contexts.\nConstruct Validity: A critical issue involves whether the tools and methods used truly capture the concepts under investigation. To ensure that the prompts used were aligned with the research objectives, we adopted an iterative prompt engineering process in which different versions were tested and refined. These versions were made available on Zenodo to promote greater transparency. Additionally, test articles with known responses were used to validate whether the model's outputs were consistent with expectations. This procedure provided greater confidence that ChatGPT correctly interpreted the questions and returned responses aligned with the study's objectives."}, {"title": "VI. CONCLUSION", "content": "This paper presented a SMS on the use of LLMs in qualitative analyses, aiming to explore the state of the art in this area. Overall, the analysis of the studies revealed that most publications are recent (2023-2024), indicating that the field is still in its early stages but showing growing interest.\nThis study provides an overview of the field, addressing various dimensions such as contexts, LLM models, data sources, techniques and methodologies, metrics, limitations, and opportunities. The applications span areas like healthcare, education, culture, and technology, with objectives ranging from automating qualitative analysis to comparing results with traditional methods. Several models were utilized, with a predominance of adjustments made to LLMs to enhance outcomes. The effectiveness of LLMs was mostly evaluated as equivalent to traditional methods, though some limitations were identified, such as the dependence on prompts and the risk of biases.\nAs future work, we plan to develop a method using LLMs to automate the qualitative analysis process, particularly focusing on the coding stages, by exploring new architectures applied in different tools. For this new method, we also aim to incorporate improvements in prompt engineering techniques to achieve greater accuracy and robustness.\nWith continued advancements in this field, it is expected that LLMs may, in the future, play an even more significant role in qualitative analysis, becoming an indispensable tool for researchers dealing with large volumes of textual data."}]}