{"title": "OPTDTALS: Approximate Logic Synthesis via Optimal Decision Trees Approach", "authors": ["Hao Hu", "Shaowei Cai"], "abstract": "The growing interest in Explainable Artificial Intelligence (XAI) motivates promising studies of computing optimal Interpretable Machine Learning models, especially decision trees. Such models generally provide optimality in compact size or empirical accuracy. Recent works focus on improving efficiency due to the natural scalability issue. The application of such models to practical problems is quite limited. As an emerging problem in circuit design, Approximate Logic Synthesis (ALS) aims to reduce circuit complexity by sacrificing correctness. Recently, multiple heuristic machine learning methods have been applied in ALS, which learns approximated circuits from samples of input-output pairs.\nIn this paper, we propose a new ALS methodology realizing the approximation via learning optimal decision trees in empirical accuracy. Compared to previous heuristic ALS methods, the guarantee of optimality achieves a more controllable trade-off between circuit complexity and accuracy. Experimental results show clear improvements in our methodology in the quality of approximated designs (circuit complexity and accuracy) compared to the state-of-the-art approaches.", "sections": [{"title": "Introduction", "content": "By providing structures that are inherently understandable by humans, as a classical interpretable machine learning (ML) model, decision trees obtain increasing concerns in explainable artificial intelligence (XAI) (Rudin 2019; Rudin et al. 2021). Compared to traditional greedy decision tree models inducing accurate but large trees (Breiman et al. 1984; Quinlan 1986), recent exact methods focus on finding optimal decision trees of a metric (Ignatiev et al. 2021; Costa and Pedreira 2023). There are mainly three different metrics to optimize: tree size, tree depth, and empirical accuracy. The exact methods optimizing tree size (respectively, tree depth) target to find decision trees of the smallest tree size (respectively, tree depth) with perfect empirical accuracy. Some typical methods include (Bessiere, Hebrard, and O'Sullivan 2009; Narodytska et al. 2018) (optimal tree size), (Avellaneda 2020; Janota and Morgado 2020; Alos, Ans\u00f3tegui, and Torres 2021; Schidler and Szeider 2021) (optimal tree depth). To optimize empirical accuracy, the exact methods aim to find topology-restricted decision trees with the highest empirical accuracy, where the restriction is mostly the tree depth (Nijssen and Fromont 2010; Bertsimas and Dunn 2017; Hu, Rudin, and Seltzer 2019; Verwer and Zhang 2019; Verhaeghe et al. 2020; Aglin, Nijssen, and Schaus 2020; Hu et al. 2020; Shati, Cohen, and McIlraith 2021; Demirovic et al. 2022; Hu, Huguet, and Siala 2022; Shati, Cohen, and McIlraith 2023; Demirovic, Hebrard, and Jean 2023; Huisman, van der Linden, and Demirovic 2024).\nAs an emerging paradigm in the modern Electronic Design Automation (EDA) process, Approximate Logic Synthesis (ALS) offers benefits in terms of circuit area, power, or latency, by relaxing the requirement of full accuracy. During the last decade, multiple ALS methods have been proposed (Scarabottolo et al. 2020), where most of them focus on functional approximation. That is, to simplify the function implemented by a circuit in the corresponding gate-level netlist. There are three major approaches corresponding to different abstract levels: netlist transformation, logic rewriting, and approximate high-level synthesis. The netlist transformation approach is realized by removing some electrical nodes or substituting some wires with others (Shin and Gupta 2011; Venkataramani, Roy, and Raghunathan 2013; Liu and Zhang 2017; Schlachter et al. 2017; Scarabottolo, Ansaloni, and Pozzi 2018). The logic rewriting approach acts on the function truth table, which modifies the values of outputs for a subset of inputs to achieve the approximation (Yang, Ciesielski, and Singhal 2000; Mishchenko, Chatterjee, and Brayton 2006; Venkataramani et al. 2012; Miao, Gerstlauer, and Orshansky 2013; Wu and Qian 2016; Hashemi, Tann, and Reda 2018; Hashemi and Reda 2019; Ma, Hashemi, and Reda 2022). The approximate high-level synthesis approach targets the behavioral level, which modifies a portion of behavioral operations (Nepal et al. 2014; Lee, John, and Gerstlauer 2017; Mrazek et al. 2019; Zeng, Davoodi, and Topaloglu 2021).\nDue to the close relationship between ML and ALS, recently, in the IWLS Contest 2020, multiple supervised ML methods have been explored to realize ALS (Rai et al. 2021). Those ML-based ALS methods learn unknown Boolean functions from the sampled input-output pairs of several circuits, which are classified as logic rewriting approaches. In brief, recent works in this field majorly apply heuristic decision trees for profiting from the convenience of converting the tree structures learned into sets of rules, where rules are suitable for generating the circuit (Zeng, Davoodi, and Topaloglu 2021; Abreu et al. 2021; Huang and Jiang 2023).\nInspired by the usage of heuristic decision trees in ALS, in this paper, we devise a new methodology called OPTtimal Decision Trees-based Approximate Logic Synthesis (OPTDTALS), that applies optimal decision trees in empirical accuracy to ALS. To our best knowledge, OPTDTALS is the first attempt at offering approximated circuit designs with the guarantee of optimality. Considering the restricted tree topology measures the circuit complexity, the optimality in accuracy provides a more controllable trade-off between accuracy and circuit complexity compared to previous ALS methods. To scale OPTDTALS to large circuits, we propose to first partition an input circuit into multiple manageable sub-circuits, then apply OPTDTALS to those sub-circuits. We introduce a design space exploration heuristic to replace the sub-circuits in the final approximated circuit iteratively. Our experimental results demonstrate clear improvements in the quality of approximated designs comparing the proposed method to the state-of-the-art ALS method.\nAs an NP-hard problem (Hyafil and Rivest 1976), computing optimal decision trees is time-consuming. We emphasize the significance of OPTDTALS, which provides more compact approximated circuits than existing ALS methods with the guarantee of optimality. Meanwhile, it is a novel applicable approach for optimal decision tree algorithms into the circuit design domain. The rest of this paper is organized as follows. We first introduce preliminaries, Then, we will overview some closely relevant previous works. Next, we present the framework of our novel methodology proposed. Finally, We provide comprehensive experimental results."}, {"title": "Technical Background", "content": "Multiple error metrics are used in the quality-of-result (QoR) phase to evaluate the quality of the approximated circuit. This paper considers monitoring the Average Relative Error. For a circuit with input space X, the Average Relative Error of the approximated Boolean function f comparing to the original Boolean function $\\bar{f}$ is defined as follows:\n$\\frac{1}{|X|} \\Sigma_{x \\in X} \\frac{d(f(x), \\bar{f}(x))}{\\|\\bar{f}(x)\\|}$\nwhere $d(f(x), \\bar{f}(x))$ indicates the difference between the exact and approximated outputs of the same input x. Generally, Hamming Distance is employed to measure the difference by counting the number of bit flips in $f(x)$ with respect to $\\bar{f}(x)$, which is defined as follows:\n$d(f(x), \\bar{f}(x)) = \\| f(x) - \\bar{f}(x)\\|$\nIn the rest of the paper, we use the QoR metric to represent the Average Relative Error."}, {"title": "Decision Trees", "content": "As a classical interpretable ML model, decision trees are commonly used to make classifications. A decision tree contains a root node, several branching nodes, and leaf nodes. For each branching node (or the root node), a feature is selected as the test for the judgment. Each outcoming edge of the branching node (or the root node) corresponds to the case of the feature selected. The leaf node corresponds to a class. Each path from the root node to a leaf node is associated with a series of judgments. To predict an unseen sample, find the corresponding path from the root node to a leaf node based on its values for the series of tests, the prediction is the class associated with the leaf node.\nFrom the view of ALS, a binary decision tree is employed to represent a Boolean function, where a binary feature corresponds to an input bit and the binary class relates to the output bit. The sampled input-output pairs are used as the training set. When all possible input-output pairs of the input space are sampled, it is evident that maximizing empirical accuracy of the decision tree is equivalent to minimizing the Average Relative Error metric of ALS."}, {"title": "Related Works", "content": "This section introduces further details for some classical logic rewriting ALS methods and some optimal decision tree approaches in empirical accuracy.\nAs a representative method using Boolean Optimization, SALSA (Venkataramani et al. 2012) constructs a QoR circuit of a single output by combining the original and approximated circuits. The positive output of the QoR circuit indicates the approximated circuit is acceptable for a maximum error bound. Therefore, the logic of the approximated circuit is free to simplify as long as the output of the QoR circuit stays as a tautology. SALSA computes the observability don't cares for each output of the approximated circuit to minimize the circuit. Another ALS method BLASYS (Hashemi, Tann, and Reda 2018; Ma, Hashemi, and Reda 2022) captures the truth table of the input circuit as a Boolean matrix A, then apply a Boolean Matrix Factorization (BMF) algorithm to decompose A into two matrices B and C, such that A \u2248 BC with minimum error. The approximated circuit is created by combining the circuits synthesizing for B and C. BLASYS applies heuristic ASSO BMF Algorithm (Miettinen and Vreeken 2011). Furthermore, (Yang, Ciesielski, and Singhal 2000) proposes to generate a binary decision diagram representing all potential approximations with a maximum error bound, then find the minimal cover with the smallest size as the final approximated design. Regarding the efficiency and relevance to our method, we consider BLASYS the state-of-the-art ALS method.\nThere are two strategies to compute optimal decision trees in empirical accuracy: one is to encode the ML problem into a standard declarative combinatorial optimization problem and then solve it via general solvers, like MaxSAT approaches (Hu et al. 2020; Shati, Cohen, and McIlraith 2021), CP approach (Verhaeghe et al. 2020), etc. The other is to extract solutions directly from the search space via the dynamic programming approach, like DL8, DL8.5 (Nijssen and Fromont 2010; Aglin, Nijssen, and Schaus 2020), MurTree (Demirovic et al. 2022), and Blossom (Demirovic, Hebrard, and Jean 2023). These algorithms scale well to large datasets by leveraging branch independence as the sub-trees can be optimized independently. Regarding time efficiency, we apply dynamic programming approaches to OPTDTALS, such as DL8.5 and Blossom."}, {"title": "Proposed Methodology", "content": "In our proposed approach, OPTDTALS, we consider the ALS process as an ML process of learning optimal decision trees in empirical accuracy. For instance, to handle a single-output logic circuit with k inputs, a dataset of size $2^k$ consisting of the pairs of all inputs of the input space and their corresponding output is first generated. Then, OPTDTALS learns an optimal decision tree for this dataset. The predictions for all inputs of the input space form the approximated outputs, which is used to be further synthesized into the gate-level circuit. OPTDTALS is easy to extend for a multi-output case by considering it as multiple independent single-output cases. In brief, for a general multi-output logic circuit of m outputs, OPTDTALS learns m optimal decision trees, each of them corresponding to a separate output bit.\nWith the guarantee of the optimality in empirical accuracy, for OPTDTALS, the maximum tree depth reflects the approximation level as it directly measures the approximated circuit complexity. In general, deeper optimal decision trees lead to better prediction performance but more complicated structures. \nWith the decrease of the maximum depth, OPTDTALS offers more aggressive approximated designs in reducing circuit area by sacrificing more accuracy. \nCompared to ALS methods proposed in the IWLS Contest 2020, our method can handle multi-output circuits, and consider the full input space instead of a subset sampled via Monte Carlo. Moreover, our method provides the guarantee of optimality in circuit accuracy. However, the main challenge of our approach is the scalability problem as the truth table grows exponentially with the increase of circuit inputs."}, {"title": "Scaling Up for Large Circuits", "content": "Learning optimal decision trees naturally suffers the scalability issue. Even the most time-efficient dynamic programming approaches are unable to handle training sets of size more than 20,000 examples. Therefore, OPTDTALS is acceptable for circuits of maximum 14 inputs, as $2^{14}$ = 16384.\nTo scale OPTDTALS to large circuits, similar to BLASYS, we propose first to partition a given circuit into several manageable sub-circuits, then approximate those sub-circuits via OPTDTALS. We apply KahyPar (Schlag et al. 2016) recursively until all sub-circuits have maximum k inputs and maximum m outputs. The number of k and m are preset parameters determined by the budget of the computing resource. In this paper, we apply k = 14 and m = 5. The selection of 5 outputs accounts for limiting the number of optimal decision trees.\nWe evaluate the QoR metric of the whole circuit instead of sub-circuits in isolation, as a small error in the sub-circuit can propagate leading to large errors. We use Cir($s_i$ \u2192 $SA_{s_i,md_i}$) to represent the approximated circuit by substituting the original sub-circuit $s_i$ with its corresponding approximation $SA_{s_i,md_i}$ generated by OPTDTALS, where $md_i$ is the maximum depth of the optimal decision tree. As it is infeasible to evaluate the entire approximated circuit with the full input space, we use Monte Carlo sampling to estimate the QoR metric. We mention that, for all sub-circuits, the full input space is sampled when applying OPTDTALS."}, {"title": "Experimental Results", "content": "In this section, we perform two evaluations for OPTDTALS in terms of the accuracy and complexity of approximated designs generated. The first evaluation is performed on the IWLS Contest 2020 benchmarks, where we compare OPTDTALS with the ML-based ALS method proposed in the contest. Another evaluation is performed on several classical combinatorial circuits from the ISCAS85 benchmarks (Hansen, Yalcin, and Hayes 1999) 3, where we compare OPTDTALS with the state-of-the-art ALS method (BLASYS). We ran all experiments on a cluster using AMD EPYC-7763 @2.45GHz CPU and 1TB memory running Ubuntu 20.04 LTS."}, {"title": "Conclusion", "content": "We propose a novel Approximate Logic Synthesis methodology named OPTDTALS via learning optimal decision trees in empirical accuracy. The guarantee of optimality in accuracy leads to a controllable trade-off between circuit complexity and accuracy via restricting the maximum depth for tree topology. Our experimental studies show clear benefits of the proposed framework in providing more compact approximated designs with competitive accuracy compared with state-of-the-art heuristic ALS methods.\nIn the future, it would be interesting to extending our framework by applying different optimal \u201cwhite-box\" interpretable ML models, like decision diagrams, decision lists, etc. Moreover, the effect of different partition algorithms applied for large circuits is also worth investigating. Additionally, improving the scalability of our methodology is another crucial and urgent work."}]}