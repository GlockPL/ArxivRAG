{"title": "OPTDTALS: Approximate Logic Synthesis via Optimal Decision Trees Approach", "authors": ["Hao Hu", "Shaowei Cai"], "abstract": "The growing interest in Explainable Artificial Intelligence (XAI) motivates promising studies of computing optimal Interpretable Machine Learning models, especially decision trees. Such models generally provide optimality in compact size or empirical accuracy. Recent works focus on improving efficiency due to the natural scalability issue. The application of such models to practical problems is quite limited. As an emerging problem in circuit design, Approximate Logic Synthesis (ALS) aims to reduce circuit complexity by sacrificing correctness. Recently, multiple heuristic machine learning methods have been applied in ALS, which learns approximated circuits from samples of input-output pairs.\nIn this paper, we propose a new ALS methodology realizing the approximation via learning optimal decision trees in empirical accuracy. Compared to previous heuristic ALS methods, the guarantee of optimality achieves a more controllable trade-off between circuit complexity and accuracy. Experimental results show clear improvements in our methodology in the quality of approximated designs (circuit complexity and accuracy) compared to the state-of-the-art approaches.", "sections": [{"title": "Introduction", "content": "By providing structures that are inherently understandable by humans, as a classical interpretable machine learning (ML) model, decision trees obtain increasing concerns in explainable artificial intelligence (XAI) (Rudin 2019; Rudin et al. 2021). Compared to traditional greedy decision tree models inducing accurate but large trees (Breiman et al. 1984; Quinlan 1986), recent exact methods focus on finding optimal decision trees of a metric (Ignatiev et al. 2021; Costa and Pedreira 2023). There are mainly three different metrics to optimize: tree size, tree depth, and empirical accuracy. The exact methods optimizing tree size (respectively, tree depth) target to find decision trees of the smallest tree size (respectively, tree depth) with perfect empirical accuracy. Some typical methods include (Bessiere, Hebrard, and O'Sullivan 2009; Narodytska et al. 2018) (optimal tree size), (Avellaneda 2020; Janota and Morgado 2020; Alos, Ans\u00f3tegui, and Torres 2021; Schidler and Szeider 2021) (optimal tree depth). To optimize empirical accuracy, the exact methods aim to find topology-restricted decision trees with the highest empirical accuracy, where the restriction is\nAs an emerging paradigm in the modern Electronic Design Automation (EDA) process, Approximate Logic Synthesis (ALS) offers benefits in terms of circuit area, power, or latency, by relaxing the requirement of full accuracy. During the last decade, multiple ALS methods have been proposed (Scarabottolo et al. 2020), where most of them focus on functional approximation. That is, to simplify the function implemented by a circuit in the corresponding gate-level netlist. There are three major approaches corresponding to different abstract levels: netlist transformation, logic rewriting, and approximate high-level synthesis. The netlist transformation approach is realized by removing some electrical nodes or substituting some wires with others (Shin and Gupta 2011; Venkataramani, Roy, and Raghunathan 2013; Liu and Zhang 2017; Schlachter et al. 2017; Scarabottolo, Ansaloni, and Pozzi 2018). The logic rewriting approach acts on the function truth table, which modifies the values of outputs for a subset of inputs to achieve the approximation (Yang, Ciesielski, and Singhal 2000; Mishchenko, Chatterjee, and Brayton 2006; Venkataramani et al. 2012; Miao, Gerstlauer, and Orshansky 2013; Wu and Qian 2016; Hashemi, Tann, and Reda 2018; Hashemi and Reda 2019; Ma, Hashemi, and Reda 2022). The approximate high-level synthesis approach targets the behavioral level, which modifies a portion of behavioral operations (Nepal et al. 2014; Lee, John, and Gerstlauer 2017; Mrazek et al. 2019; Zeng, Davoodi, and Topaloglu 2021).\nDue to the close relationship between ML and ALS, recently, in the IWLS Contest 2020, multiple supervised ML methods have been explored to realize ALS (Rai et al. 2021). Those ML-based ALS methods learn unknown Boolean functions from the sampled input-output pairs of several circuits, which are classified as logic rewriting approaches. In brief, recent works in this field majorly apply heuristic decision trees for profiting from the convenience of converting the tree structures learned into sets of rules, where rules are suitable for generating the circuit (Zeng, Davoodi, and"}, {"title": "Technical Background", "content": "Multiple error metrics are used in the quality-of-result (QoR) phase to evaluate the quality of the approximated circuit. This paper considers monitoring the Average Relative Error. For a circuit with input space X, the Average Relative Error of the approximated Boolean function $\\hat{f}$ comparing to the original Boolean function $f$ is defined as follows:\n$\\frac{1}{|X|} \\sum_{x \\in X} \\frac{d(f(x), \\hat{f}(x))}{\\|f(x)\\|}$\nwhere $d(f(x), \\hat{f}(x))$ indicates the difference between the exact and approximated outputs of the same input x. Generally, Hamming Distance is employed to measure the difference by counting the number of bit flips in $\\hat{f}(x)$ with respect to $f(x)$, which is defined as follows:\n$d(f(x), \\hat{f}(x)) = \\| \\hat{f}(x) - f(x)\\|$\nIn the rest of the paper, we use the QoR metric to represent the Average Relative Error."}, {"title": "Decision Trees", "content": "As a classical interpretable ML model, decision trees are commonly used to make classifications. A decision tree contains a root node, several branching nodes, and leaf nodes.\nFor each branching node (or the root node), a feature is selected as the test for the judgment. Each outcoming edge of the branching node (or the root node) corresponds to the case of the feature selected. The leaf node corresponds to a class. Each path from the root node to a leaf node is associated with a series of judgments. To predict an unseen sample, find the corresponding path from the root node to a leaf node based on its values for the series of tests, the prediction is the class associated with the leaf node.\nFrom the view of ALS, a binary decision tree is employed to represent a Boolean function, where a binary feature corresponds to an input bit and the binary class relates to the output bit. The sampled input-output pairs are used as the training set. When all possible input-output pairs of the input space are sampled, it is evident that maximizing empirical accuracy of the decision tree is equivalent to minimizing the Average Relative Error metric of ALS."}, {"title": "Related Works", "content": "This section introduces further details for some classical logic rewriting ALS methods and some optimal decision tree approaches in empirical accuracy.\nAs a representative method using Boolean Optimization, SALSA (Venkataramani et al. 2012) constructs a QoR circuit of a single output by combining the original and approximated circuits. The positive output of the QoR circuit indicates the approximated circuit is acceptable for a maximum error bound. Therefore, the logic of the approximated circuit is free to simplify as long as the output of the QoR circuit stays as a tautology. SALSA computes the observability don't cares for each output of the approximated circuit to minimize the circuit. Another ALS method BLASYS (Hashemi, Tann, and Reda 2018; Ma, Hashemi, and Reda 2022) captures the truth table of the input circuit as a Boolean matrix A, then apply a Boolean Matrix Factorization (BMF) algorithm to decompose A into two matrices B and C, such that $A \\approx BC$ with minimum error. The approximated circuit is created by combining the circuits synthesizing for B and C. BLASYS applies heuristic ASSO BMF Algorithm (Miettinen and Vreeken 2011). Furthermore, (Yang, Ciesielski, and Singhal 2000) proposes to generate a binary decision diagram representing all potential approximations with a maximum error bound, then find the minimal cover with the smallest size as the final approximated design. Regarding the efficiency and relevance to our method, we consider BLASYS the state-of-the-art ALS method.\nThere are two strategies to compute optimal decision trees in empirical accuracy: one is to encode the ML problem into a standard declarative combinatorial optimization problem and then solve it via general solvers, like MaxSAT approaches (Hu et al. 2020; Shati, Cohen, and McIlraith 2021), CP approach (Verhaeghe et al. 2020), etc. The other is to extract solutions directly from the search space via the dynamic programming approach, like DL8, DL8.5 (Nijssen and Fromont 2010; Aglin, Nijssen, and Schaus 2020), MurTree (Demirovic et al. 2022), and Blossom (Demirovic, Hebrard, and Jean 2023). These algorithms scale well to large datasets by leveraging branch independence as the subtrees can be optimized independently. Regarding time effi-"}, {"title": "Proposed Methodology", "content": "In our proposed approach, OPTDTALS, we consider the ALS process as an ML process of learning optimal decision trees in empirical accuracy. For instance, to handle a single-output logic circuit with k inputs, a dataset of size $2^k$ consisting of the pairs of all inputs of the input space and their corresponding output is first generated. Then, OPTDTALS learns an optimal decision tree for this dataset. The predictions for all inputs of the input space form the approximated outputs, which is used to be further synthesized into the gate-level circuit. OPTDTALS is easy to extend for a multi-output case by considering it as multiple independent single-output cases. In brief, for a general multi-output logic circuit of m outputs, OPTDTALS learns m optimal decision trees, each of them corresponding to a separate output bit.\nWith the guarantee of the optimality in empirical accuracy, for OPTDTALS, the maximum tree depth reflects the approximation level as it directly measures the approximated circuit complexity. In general, deeper optimal decision trees lead to better prediction performance but more complicated structures. Figure 1 shows an illustrative example of 4-input, 4-output arbitrary logic circuit. We present the truth table of the original circuit and the synthesized design with Yosys Tool (Wolf) using the open ssxlib013 Liberty. We then provide the approximated circuits generated by OPTDTALS using the DL8.5 algorithm with maximum depths from 1 to 3. The optimal decision trees of each output bit, their average relative error, and their corresponding synthesized circuits are shown in Figure. The wrong predictions are marked in red. Compared to the original design, the approximated design of the maximum depth 3 reduces 29.6% circuit area while compromising only 3.125% in circuit accuracy. Meanwhile, with the decrease of the maximum depth, OPTDTALS offers more aggressive approximated designs in reducing circuit area by sacrificing more accuracy. In this example, when the maximum depth is 1, we can reduce 94.4% circuit area while sacrificing 18.75% circuit accuracy.\nCompared to ALS methods proposed in the IWLS Contest 2020, our method can handle multi-output circuits, and consider the full input space instead of a subset sampled via Monte Carlo. Moreover, our method provides the guarantee of optimality in circuit accuracy. However, the main challenge of our approach is the scalability problem as the truth table grows exponentially with the increase of circuit inputs."}, {"title": "Scaling Up for Large Circuits", "content": "Learning optimal decision trees naturally suffers the scalability issue. Even the most time-efficient dynamic programming approaches are unable to handle training sets of size more than 20,000 examples. Therefore, OPTDTALS is acceptable for circuits of maximum 14 inputs, as $2^{14} = 16384$. To scale OPTDTALS to large circuits, similar to BLASYS, we propose first to partition a given circuit into several manageable sub-circuits, then approximate those sub-circuits via OPTDTALS. We apply KahyPar (Schlag et al. 2016) recursively until all sub-circuits have maximum k inputs and maximum m outputs. The number of k and m are preset parameters determined by the budget of the computing resource. In this paper, we apply k = 14 and m = 5. The selection of 5 outputs accounts for limiting the number of optimal decision trees.\nWe evaluate the QoR metric of the whole circuit instead of sub-circuits in isolation, as a small error in the sub-circuit can propagate leading to large errors. We use $Cir(s_i \\rightarrow S_{As_i,m_{d_i}})$ to represent the approximated circuit by substituting the original sub-circuit $s_i$ with its corresponding approximation $S_{As_i,m_{d_i}}$ generated by OPTDTALS, where $m_{d_i}$ is the maximum depth of the optimal decision tree. As it is infeasible to evaluate the entire approximated circuit with the full input space, we use Monte Carlo sampling to estimate the QoR metric. We mention that, for all sub-circuits, the full input space is sampled when applying OPTDTALS."}, {"title": "Experimental Results", "content": "In this section, we perform two evaluations for OPTDTALS in terms of the accuracy and complexity of approximated designs generated. The first evaluation is performed on the IWLS Contest 2020 benchmarks, where we compare OPTDTALS with the ML-based ALS method proposed in the contest. Another evaluation is performed on several classical combinatorial circuits from the ISCAS85 benchmarks (Hansen, Yalcin, and Hayes 1999), where we compare OPTDTALS with the state-of-the-art ALS method (BLASYS). We ran all experiments on a cluster using AMD EPYC-7763 @2.45GHz CPU and 1TB memory running Ubuntu 20.04 LTS."}, {"title": "Evaluation in the Combinatorial Circuits", "content": "This experiment aims to compare our methodology with the state-of-the-art logic rewriting ALS method (BLASYS) for classical combinatorial circuits. For small circuits, we generate the truth tables and then directly learn corresponding optimal decision trees. For the larger ones, we apply the scaling-up process proposed before. The combinatorial circuits evaluated (Table 3) contain classical 8-bit adder, 7-bit multiplier, and part of the ISACAS85 benchmarks (circuits starting with C). All are implemented in Verilog. For each large circuit, as it is impractical to enumerate all test vectors to evaluate the QoR metric, we generate a testbench containing 10,000 random test vectors. For small circuits, the testbench contains all possible test vectors.\nFigure 3 describes the tool-chain used in OPTDTALS. In detail, Yosys parses the input circuit and assesses its circuit area with a given liberty file. LSOracle (Neto et al. 2019) is used to partition the input circuit into multiple manageable sub-circuits with similar sizes. For each sub-circuit, Icarus Verilog (Williams 2006) generates its corresponding truth table, which is used to learn multiple optimal decision trees. After optimal decision trees for a sub-circuit are learned, we synthesize these models using the Verilog Case Statements. Thus, an approximated design of the input circuit can be generated by partly substituting some approximated sub-circuits. The approximated design's circuit area and QoR metric are used to iteratively optimize the max_depth stream as described in Algorithm 2. In this experiment, we apply the DL8.5 algorithm as its time-efficiency. All designs are synthesized by Yosys using the open ssxlib013 liberty.\nWe first evaluate OPTDTALS on the small C17 circuit. We consider different maximum depths for OPTDTALS-DL8.5 (md \u2208 [2, 4]) to generate different approximated designs. Meanwhile, as the C17 circuit has only two outputs, BLASYS can only provide one approximated design with the factorization degree fd as 1. Table 4 presents the results of designs generated via different methods. Compared to BLASYS, we observe that OPTDTALS can provide diverse approximated designs without the limit of the number"}, {"title": "Conclusion", "content": "We propose a novel Approximate Logic Synthesis methodology named OPTDTALS via learning optimal decision trees in empirical accuracy. The guarantee of optimality in accuracy leads to a controllable trade-off between circuit complexity and accuracy via restricting the maximum depth for tree topology. Our experimental studies show clear benefits of the proposed framework in providing more compact approximated designs with competitive accuracy compared with state-of-the-art heuristic ALS methods.\nIn the future, it would be interesting to extending our framework by applying different optimal \u201cwhite-box\" interpretable ML models, like decision diagrams, decision lists, etc. Moreover, the effect of different partition algorithms applied for large circuits is also worth investigating. Additionally, improving the scalability of our methodology is another crucial and urgent work.\"\n    }"}]}