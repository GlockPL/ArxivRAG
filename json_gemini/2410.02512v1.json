{"title": "SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation", "authors": ["Mucong Ding", "Bang An", "Yuancheng Xu", "Anirudh Satheesh", "Furong Huang"], "abstract": "Data augmentation, a cornerstone technique in deep learning, is crucial in enhancing model performance, especially with scarce labeled data. While traditional methods, such as hand-crafted augmentations, are effective but limited in scope, modern, adaptable techniques often come at the cost of computational complexity and are hard to fit into existing processes. In this work, we unveil an efficient approach that universally enhances existing data augmentation techniques by enabling their adaptation and refinement, thereby providing a significant and comprehensive improvement across all existing methods. We present SAflex (Self-Adaptive Augmentation via Feature Label Extrapolation), an approach that utilizes an efficient bilevel optimization to learn the sample weights and soft labels of augmented samples. This is applicable to augmentations from any source, seamlessly integrating with existing upstream augmentation pipelines. Remarkably, SAFLEX effectively reduces the noise and label errors of the upstream augmentation pipeline with a marginal computational cost. As a versatile module, SAFLEX excels across diverse datasets, including natural, medical images, and tabular data, showcasing its prowess in few-shot learning and out-of-distribution generalization. SAFLEX seamlessly integrates with common augmentation strategies like RandAug and CutMix, as well as augmentations from large pre-trained generative models like stable diffusion. It is also compatible with contrastive learning frameworks, such as fine-tuning CLIP. Our findings highlight the potential to adapt existing augmentation pipelines for new data types and tasks, signaling a move towards more adaptable and resilient training frameworks.", "sections": [{"title": "1 Introduction", "content": "Data augmentation is a cornerstone in improving machine learning models, especially when labeled data is scarce. It enhances model performance by introducing varied training samples. Though traditional methods like rotation and cropping are widely used, they operate under a one-size-fits-all assumption that often falls short in the complexity of real-world data. The key is not just to augment data, but to do it in a way that does not mislead the learning process.\nRecent work emphasizes the benefits of learned data augmentation, where techniques such as AutoAugment (Cubuk et al., 2019) and RandAugment (Cubuk et al., 2020) adapt to specific datasets and tasks. While promising, this area is still nascent and lacks a comprehensive framework to address diverse tasks and data nuances. Furthermore, selecting meaningful transformations remains a challenge, often relying on heuristics or domain expertise, which is especially problematic"}, {"title": "2 Proposed Method: SAflex", "content": "Our goal is to refine augmented samples from any upstream pipeline to enhance classifier general-ization. The proposed methodology is founded on two pivotal questions: (1) Which aspects of the augmented samples should be refined? (2) What approach should be taken to learn these refined samples? We start from these questions and defer the derivation of the algorithm to Section 3.\nLimitations of Augmentation Methods. Data augmentation is pivotal in enhancing model generalization. However, its limitations, particularly the unintentional introduction of noise, can sometimes outweigh its benefits. For instance, consider the widespread use of random cropping on natural images. Although largely effective, there are times when this approach inadvertently omits task-relevant information, leading to unintended outcomes like false positives. This inherent noise creates a trade-off: under-augmentation may yield insufficient challenging examples, whereas over-augmentation can flood the dataset with misleading samples. As shown in Fig. 2a, reducing the noise in augmentation is the key to resolving the dilemma.\nNoise in augmentation primarily arises from two fundamental challenges: (1) the deviation of augmented samples from the original data distribution and (2) the potential mislabeling of augmented samples. We shall envision augmentation as a method to harness prior knowledge in capturing the underlying data distribution. This distribution is encapsulated in the joint distribu-tion, Pxy(x, y), where x \u2208 X are features and y \u2208 {1, . . ., K} represents labels, with K indicating the number of classes. Breaking down this joint distribution: Pxy(x,y) = Px(x) \u2022 Py|x(y|x), we observe that the primary source of noise is associated with the feature distribution Px(x), while the secondary source is tied to the conditional distribution Py|x(y|x). Addressing these challenges, our methodology is designed to integrate seamlessly with any upstream augmentation process, amend-ing both types of errors post-augmentation, and considering the initial augmentation process as a separate, unchanged entity.\nFeature and Label Extrapolation. A key concern in data augmentation pertains to addressing these two types of errors. Some prior works on learning augmentation (e.g., (Yang et al., 2022a)) attempted to reduce noise by fine-tuning augmented features, using them as initializations. Specif-ically, the aim was to derive a modified feature x' that eliminates both error types. Yet, due to the"}, {"title": "3 Algorithm", "content": "We now develop an algorithm for the bilevel problem described in Eq. (2).\nThe Greedy Approach. Bilevel optimization is notoriously challenging, often necessitating nested loops, which introduces significant computational overhead. Upon inspecting Eq. (2), it becomes evident that an essential characteristic of the problem \u2014 the training dynamics of the model \u2014 has been understated. In standard practice, augmented samples are typically generated during model training for each minibatch across all iterations. Therefore, the actual problem de-viates from Eq. (2) in two ways: (1) different batches of augmentation may influence the learned parameters differently, and the model is not trained on a cumulative set of augmented samples, and conversely, (2) the learned parameters are affected differently by the refined augmented samples across batches, implying that augmentation should be optimized with respect to the corresponding model parameters.\nTo incorporate model optimization dynamics, we should reformulate the problem on a finer scale: Given the model parameter \u03b8t\u22121 at an intermediate training step, how can we determine the batch of refined augmented samples, Dbatch? Through a greedy approach, we posit that the granular objective is to minimize the validation loss after a single update, denoted as L(Dval, \u03b8t), where \u03b8t is the model parameter updated from \u03b8t\u22121.\n$min_{\\mathcal{D}_{aug}^{batch}, \\theta_t} L(\\mathcal{D}_{val}, \\theta_t) \\quad \\text{s.t.} \\quad \\theta_t = \\theta_{t-1} - \\alpha \\cdot \\nabla_{\\theta} L(\\mathcal{D}_{train}^{batch} \\cup \\mathcal{D}_{aug}^{batch}, \\theta_{t-1})$\nThis micro-perspective of Eq. (2) is represented in Eq. (3), where the batch of augmented samples $Dbatch = \\{(waug, raug, yaug),..., (wBaug, xBaug, yaug)\\}$ is parametrized by the set of sample weights $(w_1^{aug},..., w_B^{aug})$ and soft labels $(y_1^{aug},..., y_B^{aug})$.\nAs a direct consequence, if the inner loop uses a first-order optimizer like SGD (as assumed), this significantly eases the optimization task. The emergent problem is no longer bilevel. With the"}, {"title": "4 Related Works", "content": "Traditional data augmentation techniques such as random flipping and cropping (Krizhevsky et al., 2017; Simard et al., 2003; Shorten & Khoshgoftaar, 2019) are hand-crafted and static, unlike our adaptive SAFLEX method that tunes sample weights based on validation performance. Autonomous approaches like AutoAugment (Cubuk et al., 2019; Lim et al., 2019; Ho et al., 2019; Mounsaveng et al., 2021, 2023) learn transformations but are restricted in scope, primarily focusing on affine transformations. Generative methods employing GANs or diffusion models (Odena et al., 2017; Sankaranarayanan et al., 2018; Huang et al., 2018; He et al., 2022; Shipard et al., 2023; Dunlap et al., 2023; Trabucco et al., 2023) can inadvertently alter class-relevant features, which our method avoids by adaptively adjusting sample weights. Research on adversarial perturbations (Goodfellow et al., 2015; Yang et al., 2022a,b; Ho & Nvasconcelos, 2020) and noise-robust learning (Han et al., 2018; Lang et al., 2022; Thulasidasan et al., 2019; Konstantinov & Lampert, 2019; Gao et al., 2022; Ma et al., 2018; Kremer et al., 2018) address similar problems but often suffer from complexity and stability issues, which we mitigate by our principled approach to weight adjustment. Recently, Soft-Augmentation (Liu et al., 2023) also proposes to use soft labels and sample weights to train on augmented samples. However, it implements a specific formula to generate them based on the strength parameter of upstream augmentations. This limits the applicability of Soft-Augmentation mostly to crop augmentation on images. Wang et al. (2023) introduce self-adaptive augmentation within the meta-learning framework, MetaMix, which improves the corruption robustness of con-tinual learning models. Bhattarai et al. (2020) propose a progressive sampling strategy for GAN synthetic data, while Caramalau et al. (2021) introduce a sequential graph convolutional network for active learning. Our work extends these findings by developing a novel sampling and purifying method for augmented data that is specifically designed to improve the performance of downstream tasks.\nFor a more detailed discussion of related works, please refer to Appendix B."}, {"title": "5 Experiments", "content": "We validate the effectiveness of SAFLEX under four very different learning scenarios: (1) adapt-ing augmentations to medical images, (2) refining augmentations for tabular data, (3) purifying diffusion-model-generated augments, and (4) applying to contrastive fine-tuning. Experimental setups and implementation details are provided in Appendix C.\nAdapting Augmentations to Medical Images. Unlike natural images, medical images often carry quantitative information (e.g., encoded as color) and objects without a canonical orienta-tion. While we usually lack the domain knowledge to design effective heuristic augmentation transformations for these images, applying augmentation pipelines designed for natural images, such as RandAugment (Cubuk et al., 2020), can sometimes degrade performance in the medi-cal context (Yang et al., 2022a). Consequently, we investigate whether SAFLEX can adapt these augmentation pipelines for medical images.\nWe assess multi-class classification across eight medical image datasets from MedMNIST (Yang et al., 2023), with each dataset comprising 10K to 236K 28\u00d728 images and 4 to 11 classes. In line with (Yang et al., 2021), we train a ResNet-18 model (He et al., 2016) using the Adam op-timizer (Kingma & Ba, 2014) for 100 epochs. For upstream augmentation, we utilize the widely-"}, {"title": "6 Conclusions", "content": "Our study presents SAFLEX, a novel solution to current challenges in data augmentation. At its core, SAFLEX offers a paradigm shift from traditional, one-size-fits-all augmentation strategies to a more adaptive, data-driven approach. It allows for the learning of low-dimensional sample weights and soft labels for each augmented instance, thereby circumventing the complexities and limitations inherent in direct augmentation feature learning. Our method demonstrates universal compatibil-ity, underscoring its vast potential for diverse data types in learning scenarios. Extensive empirical evaluations confirm SAFLEX's prowess, proving its adaptability from medical imaging contexts to the nuances of tabular and natural image datasets. While SAFLEX demonstrates promising re-sults, there are certain factors to consider for optimal performance. A substantial and high-quality validation set is beneficial. A suboptimal set could limit its effectiveness. Additionally, the type of upstream augmentation methods selected plays a role, as it impacts the overall performance of SAFLEX. Our approach also entails some computational overhead due to frequent gradient evalu-ations. These considerations will be the focus of future studies to further refine the methodology.\nIn essence, SAFLEX stands as a testament to the advancements in learnable data augmentation, ushering in a more adaptive and customized era of data-centric AI."}, {"title": "A Method and Algorithm Details", "content": "In this appendix, we provide more details about the proposed method and algorithm. We first show the derivation details behind results in Theorem 1. Then, we provide more details about the SAFLEX algorithm on contrastive losses discussed at the end of Section 3.\nProof of Theorem 1: As outlined in Section 3, we start from approximating the validation loss up to first order around the current parameter \u03b8t-1. By the first-order approximation, we shall rewrite the optimization problem in Eq. (3) as follows:\n$\\max_{\\substack{(w_1,...,w_B), (\\mathbf{y}_1,..., \\mathbf{y}_B);\\\\ \\sum_{i=1}^B w_i=1, \\mathbf{y}_i \\in \\Delta^K,\\forall i\\in[B]}} \\langle \\nabla_{\\theta} L(\\mathcal{D}_{val}, \\theta_{t-1}), \\nabla_{\\theta} L(\\mathcal{D}_{train}^{batch} \\cup \\{(\\mathbf{x}_{1}^{aug}, \\mathbf{r}_{1}^{aug}, \\mathbf{y}_{1}^{aug}),...,(\\mathbf{w}_{B}^{aug}, \\mathbf{x}_{B}^{aug}, \\mathbf{y}_{B}^{aug})\\}_{1}^{B}, \\theta_{t-1})\\rangle$\nwhere we also explicitly write out the learnable parts in the augmented batch.\nClearly, the set of constraints, $\\sum_{i=1}^B w_i = 1$ and $\\sum_{k=1}[K\\mathbf{y}_i]_k = 1$ for $\\forall i \\in [B]$, are linear. To show that the objective function is also linear, we consider the form of cross-entropy loss:\n$L_{CE}(D, \\theta) = - \\sum_{i=1}^B \\log \\frac{\\exp [f (x_i)]_{\\mathbf{y}_i}}{\\sum_{k=1}^K \\exp [f (x_i)]_k}$\nSince $f (.): \\mathcal{X} \\to \\Delta^K$ is assumed to have the Softmax function applied on the outputs (see Section 2), we have $\\sum_{k=1}^K \\exp [f (x_i)]_k = 1$, and the cross-entropy loss can be rewritten as:\n$L_{CE}(D, \\theta) = - \\sum_{i=1}^B \\log[f (x_i)]_{\\mathbf{y}_i}$\nWhen sample weights and soft labels are introduced, the cross-entropy loss becomes:\n$L_{CE}(D, \\theta) = - \\sum_{i=1}^B w_i \\sum_{k=1}^K [\\mathbf{y}_i]_k \\log[f (x_i)]_k$\nFrom the above equation, we can see that the objective function $L(\\mathcal{D}_{train}\\, \\{\\,(wang, xaug, ya yag)}-1,0-1)$ in Eq. (4) is indeed linear with respect to sample weigths $(w_1,...,w_B)$ and soft labels $(\\mathbf{y}_1,..., \\mathbf{y}_B)$.\nGiven these, we conclude, the resulted optimizaiton task, Eq. (4), is a linear programming problem, which can be solved efficiently. Moreover, the set of linear constraints are independent, which means the solution for sample weight w and soft labels y for an augmented sample $x_{i}^{aug} \\in \\mathcal{D}_{aug}^{batch}$ are independent of other augmented samples and the training sample batch $Dbatch$. For an arbitrary augmented sample $x_{i}^{aug} \\in \\mathcal{D}_{aug}^{batch}$, replacing the gradient vector on the entire batch of training and augmented samples with the gradient vector on this single augmented sample,\n$L_{CE}\\,(\\,\\{,(w^{aug}, \\mathbf{x}^{aug}, \\mathbf{y}^{aug})\\},\\,\\theta\\,) = w^{aug}. \\sum_{k=1}^K [\\mathbf{y}^{aug}]_k \\log[f (\\mathbf{x}^{aug})]_k$\nit is not hard to see that if the gradient inner product is denoted by\n$\\Pi = \\nabla_{\\theta} f (\\mathbf{x}^{aug}) \\,|_{{\\theta = \\theta_{t-1}}} \\nabla_{\\theta} L(\\mathcal{D}_{val}, \\theta_{t-1})$"}, {"title": "B Related Work", "content": "In this section, we compare our approach with established augmentation methods, including tradi-tional heuristical transformations, autonomous data augmentation, and methods leveraging large pretrained models or adversarial perturbation. We then discuss our methodology's connections to"}, {"title": "C Experimental Setups and Implementation Details", "content": "In this section, we provide more details about the experimental setups and implementation details.\nThe experiments are conducted on 4 NVIDIA Tesla V100 GPUs with 32GB memory each.\nFor the hyperparameter setting of SAFLEX algorithm, we usually set the penalty coefficient \u03b2 = 0, and only set it \u03b2 = 1 for experiments on the tabular datasets. We often keep the tem-perature \u03c4 = 0.01, and only set it to be r = 0.1 on the CLIP finetuning experiment. We do not conduct hyperparameter search for the hyperparameters of SAFLEX algorithm, and we believe the performance can be further improved by hyperparameter search.\nWe then describe the infomation of datasets. The information about tabular datasets are listed below.\nThe specific subsets of iWILDCam and CUB datasets used in diffusion-generated augmentation experiments are adopted form (Dunlap et al., 2023).\nNext, we show some more experiment results. The performance of Soft-Augmentation (Liu et al., 2023) on MedMNIST datasets is listed below. Since the Soft-Augmentation paper focuses on improving crop augmentation and does not provide formulas to generate soft labels and sample weights for the upstream augmentations we considered, we test it with crop augmentation on the MedMNIST medical image datasets. We use the tuned hyperparameters for crop augmentation"}]}