{"title": "fabSAM: A Farmland Boundary Delineation Method Based on the Segment Anything Model", "authors": ["Yufeng Xie", "Hanzhi Wu", "Hongxiang Tong", "Lei Xiao", "Wenwen Zhou", "Ling Li", "Thomas Cherico Wanger"], "abstract": "Delineating farmland boundaries is essential for agricultural management such as crop monitoring and agricultural census. Traditional methods using remote sensing imagery have been efficient but limited in generalization. The Segment Anything Model (SAM), known for its impressive zero-shot performance, has been adapted for remote sensing tasks through prompt learning and fine-tuning. Here, we propose a SAM-based farmland boundary delineation framework (fabSAM) that combines a Deeplabv3+-based Prompter and SAM. Also, a fine-tuning strategy was introduced to enable SAM's decoder to improve the use of prompt information. Experimental results on the AI4Boundaries and AI4SmallFarms datasets have shown that fabSAM has a significant", "sections": [{"title": "1. Introduction", "content": "One of the fundamental and challenging tasks of smart and precision agriculture is obtaining the spatial distribution of agricultural parcels and extracting their accurate boundaries, which also are indispensable prerequisites for downstream tasks in agricultural management, such as crop monitoring and agricultural census. Compared with conventional methods such as field surveys, methods that utilize Remote Sensing (RS) imagery can be much more efficient and cost-effective, as there are a large amount of publicly available RS datasets with various spatial and temporal resolutions, and the imagery interpretation technique is rapidly developing [1, 2].\nDepending on the delineation methods used, existing studies extracting farmland boundaries from RS imagery can be roughly divided into two"}, {"title": null, "content": "categories: traditional computer vision-based [3, 4] and deep learning-based methods [5, 6]. The traditional ones can be further sub-categorized into edge-based [7] and region-based techniques [4, 8]. As deep learning-based methods have shown greater accuracy and stability than traditional ones, models based on Deep Convolutional Networks (DCN) such as FCN [9], UNet [10], Deeplab [11] and their variants [5, 12] and Vision Transformers (ViTs) [13] have become popular recently.\nHowever, the lack of training data in some countries and regions limits the generalization of these data-driven models [13]. To overcome this limitation, Visual Fundamental Models (VFMs) have been extended to RS imagery interpretation [14, 15, 16, 6], especially the Segment Anything Model (SAM) [17]. SAM has been trained and used on a dataset with over one billion masks and eleven million images for segmentation and therefore performs well on different kinds of tasks, including edge detection [17]. Also, SAM can be prompted by multiple forms of prompts, including points, bounding boxes, texts and masks, then allows it to be conveniently applied to specific downstream tasks [18].\nRecently, a hybrid architecture has gained prominence in the RS community [14]. It contains a DCN model designed for object detection tasks to output bounding boxes that pinpoint the region of interest (ROI) in the RS images. Then, these boxes can serve as prompts for the SAM's prompt encoder. Combining the Prompter, a SAM-based workflow that automatically processes RS images has been developed.\nConsidering the variety of spatial resolution of RS datasets and the expected outputs of farmland boundary delineation tasks, we identified two challenges in constructing this hybrid model based on SAM: (1) How to"}, {"title": null, "content": "generate the most effective prompts for SAM? (2) How can the SAM be fine-tuned to get more accurate outputs?\nTo address the aforementioned challenges, we released a SAM-based farmland boundary delineation hybrid framework (fabSAM). This framework contains a Deeplabv3+-based Prompter that generates low-resolution masks and points as prompts, and two SAM-based parts that can separately identify the regions and boundaries of farmland. We then introduced a fine-tuning strategy for different delineation tasks. At the end, we evaluated whether fabSAM can improve the performance of the original Prompter on the AI4Boundaries (AI4B) and AI4SmallFarms (AI4S) datasets [19, 20]. To the best of our knowledge, this work is the first to introduce a hybrid architecture including a mask-prompt generator and a SAM-based block for farmland boundary delineation.\nThe rest of this article is organized as follows: Section 2 offers a review of SAM's applications in RS tasks, especially the farmland boundary delineation. Section 3 introduces the proposed fabSAM in detail. Section 4 presents the experimental results of fabSAM on the AI4B and AI4S datasets.\nFinally, the conclusion is given in section 5."}, {"title": "2. Related works", "content": "Currently, there are mainly three kinds of methods that have been adopted to enhance SAM's performance on RS tasks: direct use of SAM, prompt learning skills, and fine-tuning techniques. In a case study from Bihar, India, SAM was employed directly for farmland boundary delineation in an unsupervised manner and successfully identified approximately 58% of the"}, {"title": null, "content": "boundaries [13]. Also, SAM was directly applied to improve the Cropland Data Layer of the United States Department of Agriculture by incorporating a pixel-based classifier [21]. Besides, serving as a plug-in-and-play module, SAM was included in a CocoaNet architecture (i.e. a consistency-constrained multi-class attention model), which was used to obtain image-level class labels for RS images [22].\nPrompt learning skills usually determine the performance of SAM through the quality of prompts, and how to automatically generate suitable taskoriented prompts has been systematically studied[16, 23]. A Python package for segmenting geospatial data with SAM was released, which allows users to prompt SAM with points, boxes and texts [24, 6]. Point and box prompts are the most widely adopted due to their flexibility, clarity and ease of acquisition. In a case study from Heilongjiang, China, a point prompter that focused on the ROI extracted by a simple machine learning-based classifier was added to SAM for crop field boundary delineation [18]. GeoSAM also proposed a CNN-based sparse prompter to generate point prompts for SAM to automatically segment mobility infrastructure [25]. Besides point prompts, a SAM-based model prompted by boxes that were generated from pseudo-labels was integrated into a CS-WSCDNet for the change detection task [26]. In addition, to take both point and box prompts into consideration, a SAM-based model for the local RS segmentation task was designed to be prompted by either center points of the ROI or bounding boxes that contain the ground-truth masks [15, 27]. As for text prompts, Text2Seg developed three basic methods to guide SAM for RS imagery segmentation: \"Grounding DINO + SAM\u201d, \u201dCLIP Surgery + SAM\u201d and \"SAM + CLIP\u201d [28]."}, {"title": null, "content": "There are few studies focusing on mask prompts, however, they still have great potential in efficiently guiding SAM for RS segmentation compared to sparse prompts (i.e., points and boxes). First, mask prompts can provide the most exact spatial information for objects of interest. For example, GeoSAM contained a CNN-based mask prompter that can provide dense prompts for SAM[25]. Second, SAM supports self-guided iterative predictions. To be more specific, SAM can take the masks it predicted as input and iteratively predict masks to extract maximal information, then get stable and exact predictions. Take the Few-shot Self-guided Large Vision Model (Few-shot SLVM) as an example, this framework introduced an automatic prompt learning technique using the SAM for rendering coarse pixel-wise prompts instead of heavy reliance on manual guidance [29].\nRecently, fine-tuning techniques have been proven to be necessary for extending SAM to downstream tasks [6, 30]. For example, several works have utilized a low-rank adaptation (LoRA) approach for crop-specific feature extraction and image encoder's fine-tuning [30, 31]. Also, there are some text-based one-shot learning approaches have been developed to retrain SAM [28]. Furthermore, a fine-tuning strategy of SAM's mask decoder was introduced to improve the performance of GeoSAM [25]. Despite all the efforts of integration and improvements of SAM in farmland boundary delineation, an integrated and fine-tuned approach of a mask Prompter and SAM-based block is underutilized."}, {"title": "3. Methodology", "content": "The overall framework of fabSAM is illustrated in Figure. 1. fabSAM involves two main blocks, including a Prompter and a SAM-based block. The RS images are first utilized by the Prompter to generate both mask and point"}, {"title": null, "content": "prompts for SAM to localize farmland region. Following this, in the SAMbased block, the frozen SAM-based image encoder is utilized to extract highquality semantic features from original RS images, and the prompt encoder is employed to obtain explicit positional knowledge from prompts generated by the Prompter. Then, two fine-tunable decoders are introduced for farmland identification and boundary delineation tasks. Finally, the region mask and boundary mask are generated by the corresponding decoder and postprocessed to generate farmland parcels with exact and closed boundaries. This section first gives an introduction to the Prompter and the SAM-based block, followed by a discussion of our training strategies."}, {"title": "3.1. Prompter", "content": "The Prompter is designed to determine whether the pixels in the RS images belong to the farmland or background and generate both masks and points as prompts for the SAM-based block. As the range of farmland area is large and the boundaries are irregular, we use Deeplabv3+ [32] here as Prompter to better capture the multi-scale semantic features for farmland identification.\nThe Prompter follows the standard design of Deeplabv3+, which is an encoder-decoder structure. The encoder consists of two blocks: a ResNet50based DCNN block [33] and an Atrous Spatial Pyramid Pooling (ASPP)based block. In the prompt decoder, the low-level features drawn from the ResNet50-based DCNN block and the multi-level features extracted from the ASPP-based block are both aggregated and fed into a 3 \u00d7 3 convolution layer. In the end, an upsampling layer is used to restore the input shape. It is worth mentioning that the depthwise separable convolutions are used in the ASPP-based block and the prompt decoder to reduce the computation complexity [32].\nFollowing this, we directly take the logits containing abundant location information output by the prompt decoder as the mask prompt, which follows the original design of SAM. Let $mp \u2208 R^{H\u00d7W}$ denote the mask prompts, where H and W represent the resolution of the input RS image. Then, we introduce a point prompt generator (Gen) to obtain point prompts. In Gen, a farmland probability map ($P\u2208 R^{H\u00d7W}$) is first produced by applying the"}, {"title": null, "content": "sigmoid function on mp. Several foreground and background points are randomly chosen as prompts according to the following rules: (1) probability of belonging to farmland $P_i$ of the foreground pixel i must be larger than 0.7 while $P_j$ of background pixel j must be less than 0.3 to ensure the accuracy (these two thresholds are selected based on the experiment results); (2) the larger the $P_i$ (the lower the $P_j$)", "as": "n$P = Sigmoid(mp)$", "equations": 1}]}