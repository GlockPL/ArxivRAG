{"title": "A Novel Multimodal System to Predict Agitation in People with Dementia Within Clinical Settings: A Proof of Concept", "authors": ["Abeer Badawi", "Somayya Elmoghazy", "Samira Choudhury", "Sara Elgazzar", "Khalid Elgazzar", "Amer Burhan"], "abstract": "Dementia is a neurodegenerative condition that combines several diseases and impacts millions around the world and those around them. Although cognitive impairment is profoundly disabling, it is the noncognitive features of dementia, referred to as Neuropsychiatric Symptoms (NPS), that are most closely associated with a diminished quality of life. Agitation and aggression (AA) in people living with dementia (PwD) contribute to distress and increased healthcare demands. Current assessment methods rely on caregiver intervention and reporting of incidents, introducing subjectivity and bias. Artificial Intelligence (AI) and predictive algorithms offer a potential solution for detecting AA episodes in PwD when utilized in real-time. We present a 5-year study system that integrates a multimodal approach, utilizing the EmbracePlus wristband and a video detection system to predict AA in severe dementia patients. We conducted a pilot study with three participants at the Ontario Shores Mental Health Institute to validate the functionality of the system. The system collects and processes raw and digital biomarkers from the EmbracePlus wristband to accurately predict AA. The system also detected pre-agitation patterns at least six minutes before the AA event, which was not previously discovered from the EmbracePlus wrist-band. Furthermore, the privacy-preserving video system uses a masking tool to hide the features of the people in frames and employs a deep learning model for AA detection. The video system also helps identify the actual start and end time of the agitation events for labeling. The promising results of the preliminary data analysis underscore the ability of the system to predict AA events. The ability of the proposed system to run autonomously in real-time and identify AA and pre-agitation symptoms without external assistance represents a significant milestone in this research field.", "sections": [{"title": "1 Introduction", "content": "Dementia is a neurodegenerative condition that leads to a progressive decline in cognition and is one of the leading causes of death, disability, and hospitalization in Canada and worldwide. Currently, dementia is the seventh cause of death worldwide [1]. Globally, over 55 million individuals are living with dementia; as the ratio of older people increases, this number will grow to 78 million by 2030 and 139 million by 2050, making dementia a major global health crisis [1]. In addition to cognitive and functional decline, people living with dementia (PwD) also experience non-cognitive neuropsychiatric symptoms (NPS) during their illness [2]. NPS commonly includes agitation, aggression, apathy, symptoms of psychosis, delusions, hallucinations, and disturbances of sleep and appetite. Among NPS, agitation and aggression (AA) occur frequently in severe cases and are a common source of distress for patients and caregivers [3]. They commonly occur during care and are believed to be manifestations of perceived or real unmet needs [3]. Behaviors of AA include pacing, rocking, gesturing, restlessness, shouting, scratching, throwing objects, and destroying property [4]. These symptoms are the leading"}, {"title": "2 Related Work", "content": "The growing number of PwD causes significant challenges for healthcare systems and caregivers. One of these challenges is to deal with symptoms of AA that increase with the severity of dementia. These symptoms can cause distress, decreased quality of life, and increased healthcare costs. In recent years,"}, {"title": "3 Methodology", "content": null}, {"title": "3.1 Study Design", "content": "This study collects participant data using an EmbracePlus wristband [24] and video cameras. The objective of the study is to recruit 20-25 participants in the future from the Geriatric Dementia Unit (GDU) and the Geriatric Transitional Unit (GTU) at the Ontario Shores Center for Mental Health Sciences. We installed a single AXIS M3077-PLVE Network Camera [40] in each unit and one AXIS P3225-VE Mk II [41] in the hallway of GDU. The Research Ethics Board (REB) committee approved this study, ensuring the protection of the participants' privacy and the adherence to the hospital guidelines. We recruit patients based on inclusion criteria such as age, 60 years or older, having a moderately and severe major neurocognitive disorder as defined by a Mini-Mental State Examination (MMSE) score [42], and being able to ambulate independently (i.e., without the assistance of another person) with or without a walking aid (e.g., walker, cane). We also ensured that the participant has moderately severe major neurocognitive disorder, as defined by a Functional Assessment Staging Tool (FAST) scale score between 6a-6e [43], has significant agitation or aggression, and meets criteria for agitation in dementia as defined using the 2014 consensus criteria produced by the Agitation Definition Working Group from the International Psychogeriatric Association [44].\nWe follow specific procedures with all patients recruited in this study. The patients enrolled in the study need to wear a wristband during data collection. We closely monitored for signs of discomfort when wearing the wristband. In case the patient refuses to wear the wristband, a nurse re-approaches and attempts to apply the wristband later. The participants wear the device for 24 to 72 hours on three separate occasions within the six-week study period. The EmbracePlus device collects participants' physiological parameters. We record the baseline measurements of vital signs during the initial visit as the referring data points. Clinical staff monitor participants, make notes of any episodes of AA, and include the start and end times of the events. As there can be a lag between the actual episode of AA and the time a nurse observes and records the episode, the CCTV cameras in the units record video footage of the participants. These cameras capture real-time footage of the participants' episodes of AA. We mask data collected by these cameras and any faces appearing in the video frames are blurred. The video detection system processes the data, classifies AA, and records the incident to be checked by the healthcare provider. The exact time of the AA incident and comprehensive incident details are documented in the camera footage. The physiological parameters from the three sources provided are analyzed to identify changes during and before episodes of AA in PwD. This study is currently ongoing at Ontario Shores Mental Health Institute [45]. We have successfully recruited three participants using the established procedures, and we present the preliminary results of this work. The system architecture of data collection is shown in Figure 1."}, {"title": "3.2 Addressing Issues Arising from the REB Approval", "content": "The research commenced in 2019, with an REB approval process that lasted about six months. A significant challenge was presented by the use of video cameras to document the behaviors and activities of patients, staff and visitors in the public spaces of hospital inpatient units. Consent was secured for these patients through substitute decision makers (SDM), in light of their advanced dementia condition. At admission, capacity assessments were performed and SDMs were approached for permission to involve patients in potential research. Following the receipt of ethics approval, the research team organized informational sessions within the inpatient unit and restricted video recording to only the common areas where patients usually gather during the day. Recording devices were intentionally not placed in private areas such as patient rooms, restrooms, staff meeting rooms, and nursing stations, and audio capture was turned off throughout the data collection period. To alleviate the concerns about the REB's privacy and confidentiality, stringent data protection measures were instituted, including encrypting and securing all data on hospital servers with password protection. Clinical staff were tasked with observing participants for any agitated actions (AA) as part of their regular duties."}, {"title": "3.3 Event Classification", "content": "The proposed system collects the biomarkers using the EmbracePlus wristband, which is considered the state-of-the-art wearable device for continuous health monitoring in the market today [24]. The device combines digital biomarkers, robust sensors, and a user-friendly design to continuously monitor participants with various health conditions. It collects Electrodermal (EDA) that detects slight changes in skin conductance from the skin surface, Photoplethysmogram (PPG) that calculates the pulse rate and pulse rate variability measurements, skin temperature, and raw accelerometry data for motion detection. The collected signals are sent to the cloud-based EmbracePlus Care platform [24] through a Bluetooth-connected gateway (e.g., a smartphone).\nThe first type of data we deal with is the raw data from the accelerometer, heart rate, temperature, and EDA signals. We follow several pre-processing steps to clean, filter, and apply one-minute window segmentation for the raw signals [30, 31]. We then extract features from the signals as shown in our previous work from the statistical, time domain, frequency domain, and time-frequency do-main with around 150 features [30, 31]. Lastly, we evaluate multiple classification techniques, namely Support Vector Machine (SVM), Random Forest, Extra Trees, and Gradient Boosting to classify AA events. The performance of each model is evaluated using standard classification metrics such as accuracy, precision, recall, AUC, and F1-score. Furthermore, we collect the digital biomarkers that are pre-processed data derived from Empatica's algorithms and calculated minute-by-minute. The second type is the digital biomarkers, which include Pulse Rate Variability, Respiratory Rate, Move-ment Intensity, Accelerometer Magnitude Standard Deviation, Steps, Skin Conductance Level (SCL), Wearing Detection, Temperature, and Sleep Detection as shown in Table 1. Digital biomarkers have the capability to effectively and accurately oversee human health from a distance, consistently, and without causing disruption. This applies across a spectrum of health conditions [24]. Figure 2 shows the classification workflow from the EmbracePlus wristband using raw data and digital biomarkers.\nThe proposed work focuses on investigating the data from PwD using machine learning, two of which were thoroughly investigated in our previous work [30, 31]. The results concluded the most important features for this problem after performing feature engineering and proved that personalized models on individual patients outperform generic models. In this work, we report the results of the personalized model on three different participants from the Ontario Shores Mental Health Institute.\nWe test our system in real-time once we determine the optimal classification system to predict AA events. In the real-time (online) detection phase, real-time raw data is transmitted from the wristband. Following this, features are extracted from each 1-minute window, and these specific features are fed into the customized model to classify whether the data is considered normal or indicative of AA. The"}, {"title": "3.4 Video-based Analysis", "content": "In addition to collecting data on physiological biomarkers, the study incorporates video analysis data for AA prediction. This approach utilizes an extra cooperative model, which improves our overall AA detection system and allows us to get the precise duration, including start and end times, of the collected AA episodes. Moreover, once an AA episode is detected, the cameras record a previously set pre-agitation, making it easier to observe any visual pre-agitation signs. We aim to provide real-time alerts to healthcare providers for timely intervention. The setup includes three CCTV cameras installed and a PC in the attending psychiatric office with access to this footage. Our system operates in two phases: the offline phase for manual labeling and model training, and the real-time stage for running the model. To protect the privacy of the participants and the staff present, we blur all faces and run OpenPose, a computer vision tool that extracts skeletal keypoints, to capture movement data [46, 47, 48, 49]. The model is trained on features extracted from keypose points instead of the raw video frames. This approach has been recently used by researchers for AA detection in PwD, and has proven to be as successful in detecting AA while preserving the privacy of the people present [19, 34].\nIn our research, we utilize OpenPose, which is an advanced real-time system for multi-person 2D pose estimation, to anonymize individuals in video frames. OpenPose utilizes Convolutional Neural Networks (CNN) to detect human body parts and map their skeletal structure onto the image or video frame. This allows for a detailed representation of movement data present in the collected frames. After this, we employ a preprocessing phase to enhance the generalizability of the model across var-ious environments and datasets. This phase involves the elimination of extraneous noise that could otherwise impede model performance. The model considers the variations in camera angles and sub-ject positioning within the frame, which can significantly influence the coordinate data. We calculate Euclidean distances and angle measurements between specific skeletal coordinates to determine move-ments. For example, the measured distance between the torso and feet is useful to identify potential kicking actions, which may indicate AA in certain contexts."}, {"title": "4 Preliminary Data Analysis and Evaluation", "content": "A pilot study was conducted to validate the effectiveness and feasibility of the proposed system at Ontario Shores Mental Health Hospital. This initial investigation aimed to provide valuable insights into the system's functionality, usability, and overall potential before the implementation on a larger population. Details of the enrolled participants and the data collected can be found in Table 3. Upon enrolment, the participants wore the EmbracePlus wristband on three different days. We turned on the cameras installed in the unit during the data collection days to record the participants' activities. Lastly, we assigned a nurse to observe the participant and provide a detailed report of behavior, AA events, and any abnormal behavior. During the three days, we collected six AA events ranging from two to twenty-three minutes per AA event with a total of 20-32 minutes of AA labels and 560-581 minutes of normal labels for each participants. The following sections will present the results in detail from the EmbracePlus wristband and video cameras."}, {"title": "4.1 Performance Evaluation", "content": null}, {"title": "4.1.1 The EmbracePlus Wristband Raw Data", "content": "This study utilize raw data obtained from the wristband four signals and used personalized models, which achieved superior accuracy in AA detection from PwD in previous research [30, 31]. Subse-quently, we conducted a comparative analysis of multiple machine learning algorithms for AA detec-tion, including Support Vector Machines (SVM), Random Forest, Extra Trees, and Gradient Boosting. We trained and tested a personalized model for every participant and reported the evaluation results in Table 4. The dataset for each participant was randomly split into 70% training and 30% for testing.\nThe Extra Trees model emerged as the top-performing algorithm for all three participants. For participant #1, the Extra Trees model achieved an accuracy of 98.67%, an AUC of 99.1%, a recall of 99.76%, and an F1-score of 98.70%. It achieved the highest accuracy and AUC for participant #2 of 90% and 98%, respectively. Similarly, for participant #3, it achieved the highest accuracy of 99%. These results underscore the efficacy of the chosen features, preprocessing methodologies, and up-sampling techniques. While acknowledging the potential concern of overfitting, collecting additional patient data over time is anticipated to solve this issue. All models were also tested on the three participants together. The Extra Trees model achieved a much lower accuracy of 69%. The XGBoost and Random forest achieved higher accuracies in comparison with 98% and 93%, respectively.\nThe Random Forest model, on the other hand, performed very poorly in other evaluation matrices with an F1-score of 51% and a recall of 37%. The XGBoost performed best on all the participants, which highlights the potential for a general model when enough data is collected. Furthermore, for participant #1, the top 10 features contributing to accurate AA classification using the Extra trees model revealed that five were from EDA, three from the accelerometer, one from heart rate, and one from temperature. Figure 4a shows a summary of the feature importance plot for this participant. Since the EDA tonic mean was the top feature to classify AA, we investigated in-depth the AA labels. Figure 5a shows the Tonic mean values of the first participant from the EDA signal during labeled AA events from the camera and nurse notes (highlighted in red). This event occurred during the second day and lasted for 23 minutes from 17:55 pm to 18:17 pm. This observation suggests that the patient's AA was related to the EDA signal connected to the emotions. We also observed an apparent change to the data before the actual AA occurred, which we manually marked as pre-agitation labels (highlighted in blue).\nFor participants #2 and #3, the feature importance plot changes as shown in figures 4b and 4c. These plots show that, for these two participants, the features related to acceleration and temperature were the most important in AA detection, respectively. For participant #2, the acceleration features"}, {"title": "4.1.2 The Wristband EmbracePlus Digital Biomarkers", "content": "We explored all the digital biomarkers offered by EmbracePlus and observed that pulse rate, activity counts, and activity class were the leading indicators for AA detection for all three participants. In Figure 6, the same AA events discussed in the previous subsection for the three participants are illustrated and the values during labeled AA events from the camera and nurse notes are highlighted in red. Additionally, we observed a noticeable change in the data before the onset of AA, manually designated as pre-agitation labels and highlighted in grey. The manual label of the pre-agitation was done after reviewing all the signals for the participants and noting the same change across multiple patterns.\nFigure 6a illustrates the activity class, for the participant #1, extracted from the accelerometer signal, revealing that the participant was in motion rather than stationary during AA and pre-agitation episodes, indicating body movement during these events. Figure 6b displays the total activity counts for participant #2 from the accelerometer signal. While the normal activity count for the participant ranged between 0-100 during AA and pre-agitation events, it surged to 50-140, signifying heightened activity levels during AA. Finally, Figure 6c presents the pulse rate derived from the heart rate signal for participant #3. Although the participant's average pulse rate ranged from 55-80 bpm, it increased to 90-110 bpm during AA and pre-agitation events. Across the raw and digital biomarkers data, we observed that the pre-agitation occurred from 15:20 to 15:27 pm. This indicates that signs of AA behavior occurred approximately seven minutes before the actual event, suggesting the potential to predict and prevent AA events."}, {"title": "4.2 Performance of Video-based Detection", "content": "We preprocessed our videos using OpenPose and performed feature extraction as described in the methodology section. Since AA behaviors are repetitive in nature, we selected recurrent neural network (RNN) models to capture the sequential patterns of these events. Features were extracted from 30-second windows. The window moves one second at a time to capture different variations of AA behaviors from the skeletal points. This resulted in 182,994 AA sequences and 184,786 non-agitation sequences. For the classification task, we tested three different network structures that are Long Short-Term Memory (LSTM) model and a Gated Recurrent Unit (GRU)."}, {"title": "5 Discussion and Future Directions", "content": "The successful implementation of the system within the hospital setting, considering privacy, and the positive feedback from patients and healthcare professionals, underscores the system's viability in a real-world clinical environment. The system employed in this study integrated physiological data from the EmbracePlus wristband and video footage from CCTV cameras, allowing for a comprehensive and Multimodal approach to AA detection. The EmbracePlus wristband system demonstrates promising results in detecting and classifying AA and pre-agitation events in individuals with severe dementia. The AA detection results are reflected in the video detection system, and the pre-agitation labels can be added to the system from EmbracePlus. The following discussion highlights key findings and their implications, followed by suggestions for future work.\nThe EmbracePlus wristband, leveraging both raw data and digital biomarkers, demonstrates its efficacy in discerning patterns associated with AA and pre-agitation. The personalized Extra Trees model emerged as the top-performing algorithm for the raw data, achieving high performance. We believe that the Extra Trees model randomness introduced during the creation of the trees often results in a more robust and accurate model. Extra Trees evaluates different features at each split, leading to a diverse set of decision trees. This diversity often enhances the model's ability to capture complex patterns in the data. Furthermore, features such as EDA tonic mean, accelerometer activity class, and pulse rate highlighted the significance of identifying AA patterns from raw data and digital biomarkers. Each participant had a different set of top features in AA identification. For participant #1, the EDA Tonic mean showed high coloration to identify AA values, which indicates a connection between the emotional state of the patient and the observed AA. This supports the hypothesis that EDA, as a measure of sympathetic nervous system activity, is sensitive to emotional arousal. The top features for the second and third participants were the ones related to temperature and acceleration. These features can also have a strong correlation with AA since excessive movements and anger can contribute to the noted AA event. We also found pre-agitation label patterns for all participants from different features, at least six minutes before the actual AA event. The identification of pre-agitation"}, {"title": "6 Conclusion", "content": "This study represents a notable step forward in developing an AA and pre-agitation detection sys-tem for individuals with severe dementia, employing a comprehensive approach integrating intelligent psychological biomarkers sensing and video detection systems. We conducted a pilot study recruiting three participants from the Ontario Shores Center for Mental Health Sciences Institute. We used the EmbracePlus wristband for continuous health monitoring and video footage from CCTV cameras for real-time observation of AA events. In the preliminary data analysis, the raw data of the EmbracePlus wristband demonstrated exceptional performance in detecting AA events, with the Extra Trees model emerging as the top-performing algorithm for all the personalized models. For the general model, XGBoost outperform the rest of the models achieving an accuracy of 98%. Exploring the digital biomarkers further strengthened the system's classification of AA, pre-agitation, and normal events. Pulse rate, activity class, and activity counts have emerged as critical indicators to detect AA. The study revealed the potential for detecting pre-agitation patterns, showcasing a six-minute lead time before actual AA events. This early detection capability holds promise for timely intervention and preventive measures.\nAside from the EmbracePlus wristband, the video-based detection demonstrated promising results in detecting AA using LSTM, achieving a 98% accuracy rate and a robust AUC of 99%. The reported short inference time, of almost half of the GRU's inference time, and the fast learning are indicators of this model's capability to run in real-time. The high recall rate is particularly noteworthy, mini-"}]}