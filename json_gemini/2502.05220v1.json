{"title": "Aero-LLM: A Distributed Framework for Secure UAV Communication and Intelligent Decision-Making", "authors": ["Balakrishnan Dharmalingam", "Rajdeep Mukherjee", "Brett Piggott", "Guohuan Feng", "Anyi Liu"], "abstract": "Increased utilization of unmanned aerial vehicles (UAVs) in critical operations necessitates secure and reliable communication with Ground Control Stations (GCS). This paper introduces Aero-LLM, a framework integrating multiple Large Language Models (LLMs) to enhance UAV mission security and operational efficiency. Unlike conventional singular LLMs, Aero-LLM leverages multiple specialized LLMs for various tasks, such as inferencing, anomaly detection, and forecasting, deployed across onboard systems, edge, and cloud servers. This dynamic, distributed architecture reduces performance bottleneck and increases security capabilities. Aero-LLM's evaluation demonstrates outstanding task-specific metrics and robust defense against cyber threats, significantly enhancing UAV decision-making and operational capabilities and security resilience against cyber attacks, setting a new standard for secure, intelligent UAV operations.", "sections": [{"title": "I. INTRODUCTION", "content": "With the increasing deployment of unmanned aerial vehicles (UAVs) in mission-critical operations, securing the communication channels between UAVs and Ground Control Stations (GCS) becomes paramount. The integrity and confidentiality of the transmitted data must be ensured. In the evolving landscape of artificial intelligence, integrating Large Language Models (LLMs) with system and software security transforms defense mechanisms against cyber threats. LLMs, with their advanced capabilities in language comprehension and generation, offer significant potential to enhance detection and defensive strategies against cyber adversaries [1]\u2013[6]. The data exchange between UAVs and GCS, particularly sensor data, involves time series with varying sampling rates and occasional data gaps, necessitating meticulous preprocessing to ensure the data's usability for fine-tuning LLMs.\nIn this paper, we present Aero-LLM, a novel framework that integrates different types of LLMs as a team for collaboration and information sharing for UAV flying missions. Specifically, different types of LLMs show capabilities in inferencing, anomaly detection, and forecasting. The LLMs team is strategically placed onboard, at the edge, or in the cloud to provide a robust and effective defense against various cyber exploits. Compared with the state-of-the-art (SOTA) foundation LLMs, such as Llama [7], Gemini [8], Mistral [9], and DBRX [10], Aero-LLM is not designed to outperform their benchmark capabilities. Instead, it fine-tuned specialized LLMs, which focus on particular tasks and data. The striking feature of Aero-LLM is two-fold. First, it leverages a team of LLMs, whose size might be considerably smaller than the versatile but all-in-one LLMs. Each LLM takes the cross-sectional or time-series data and accomplishes specific tasks accordingly. The distributed architecture also potentially introduces intelligent agents into the scene, which orchestrates and moderates the coordination among LLMs. Second, it allows the partial LLMs to be offloaded to the computing units on edge servers or cloud servers. Thus, some inference tasks can be performed by more powerful GPUs off-board. To train special-skilled LLMs, we collectively applied two fine-tuning technologies: 1) supervised fine-tuning (SFT); and 2) reinforcement learning from human feedback (RLHF)."}, {"title": "II. RELATED WORK", "content": "This section briefly reviews the related work in three research domains: 1) LLM application in IoT and embedded systems; 2) Smaller-scale LLM cohorts application; and 3) The application of SFT and RLHF.\nThe application of large language models (LLMs) in the Internet of Things (IoT) and embedded systems has gained significant attention in recent years. Qiu et al. [12] proposed EdgeFormer, an edge-based transformer model for on-device natural language processing tasks in IoT environments. Their work demonstrated the feasibility of deploying LLMs on resource-constrained edge devices. Similarly, Zhang et al. [13] introduced a deflating technique to compress pre-trained LLMs for efficient deployment on embedded systems while maintaining performance.\nSeveral works have explored the use of smaller-scale LLM cohorts for specific tasks. Su et al. [14] proposed GlobalPipeline, a framework that decomposes large LLMs into smaller experts and orchestrates their collaboration. Their approach showed improved efficiency and scalability compared to monolithic LLMs. Likewise, Dai et al. [15] introduced a knowledge distillation method to train smaller LLMs from larger ones, enabling efficient deployment on edge devices.\nFine-tuning pre-trained LLMs has proven effective for adapting them to specific tasks and domains. Supervised fine-tuning (SFT) has been widely used to fine-tune LLMs on labeled data [16], [17]. Reinforcement learning from human feedback (RLHF) has also been explored as a fine-tuning approach, where human feedback is used to refine the LLM's behavior [18], [19]."}, {"title": "III. THREAT MODEL", "content": "In this section, we describe the potential attack vectors that can be detected by the LLM-empowered sub-system and the computing requirements for deploying LLMs at various levels of the system architecture.\nAero-LLM framework aims to detect and forecast the following attack vectors: 1) network attacks that attempt to disrupt these channels through jamming, spoofing, or man-in-the-middle attacks; 2) sensor manipulation attacks that manipulate sensor data or inject false information to mislead the UAV's decision-making processes; 3) software vulnerabilities that can be exploited by adversaries to gain unauthorized access or control; and 4) insider threats that attempt to disrupt operations or steal sensitive data.\nA reliable and high-bandwidth network infrastructure is essential to enable real-time communication and data exchange between the UAV, edge servers, and cloud servers. For smaller LLMs deployed onboard the UAV, embedded GPUs or specialized AI accelerators with limited computational resources may be sufficient. At the edge and cloud level, more powerful GPU resources may be available, enabling the deployment of larger-scale LLMs for computationally intensive tasks, such as finetuning or inference with large context windows. By deploying LLMs at various levels of the system architecture, the Aero-LLM framework provides a robust and effective defense against various cyber threats targeting UAV systems."}, {"title": "IV. SYSTEM DESIGN", "content": "Areo-LLM uses a multi-tiered architecture with specialized LLMs deployed across onboard, edge, and cloud environments as follow: 1) On-board: Small models like OPT-350m and OPT-125m are used for real-time tasks such as anomaly detection and basic inferencing, chosen for their low computational requirements and minimal latency. 2) At the edge: Medium models, such as OPT-1.3B and OPT-6.7B, are deployed on edge servers with powerful GPUs for complex tasks like aggregated data analysis and intermediate anomaly detection, balancing computational power and latency. 3) In the cloud: Large models including Llama2-7B, Llama2-13B, TimesNet, and Time-LLM are deployed in the cloud for comprehensive data analysis and long-term forecasting, utilizing extensive computational resources. This setup suits non-time-sensitive tasks despite higher latency. The rationale of this design is that onboard LLMs offer lowest latency with limited power. Edge LLMs balance the latency and computational capacity, while cloud LLMs provide high computing power but suffer from the increased latency. This hierarchical design balances performance and optimizes resource utilization."}, {"title": "V. IMPLEMENTATION", "content": "Figure 1 illustrates the sequential phases of data collection, LLM fine-tuning, and deployment for UAV systems. The UAV data was collected from two sources: the digital twins and the actual UAVs connected with software-in-the-loop (SITL) and hardware-in-the-loop (HITL) environments, using PixHawk [20] and ArduPilot [21] to simulate and capture data, which is then fed into a central repository. This repository collects both simulated and real-world sensing data, vital for fine-tuning task-specific LLMs. The fine-tuning of LLMs occurs on the cloud server, using the training data to ensure the models are well-adapted to the operational context of UAVs. Once fine-tuned, these models are deployed on edge computing platforms, leveraging the edge server equipped with GPUs. This enables efficient and rapid processing of UAV data"}, {"title": "VI. IMPLEMENTATION", "content": "A. Preprocessing Data\n1) Network layer data: We take the following steps to process network packets. First, we single out TCP sessions from our System-in-the-Loop (SIL) simulation. Then, we convert the sessions into a sliding window dataset. Using the format shown in Figure 3, we use one message as the prompt, along with previous n messages serving as the context. Following this, we have packets labeled as 'chosen' and 'rejected. The 'chosen' packet is the ground truth, representing the valid data in following packets of that session, providing positive feedback. The 'rejected' packet is the perturbation of one of the six key-value pairs, providing negative feedback. We compose the fine-tuning data in the format as illustrated in Fig. 3. Each data entry includes three sections: #Previous_Packet, #Predicted_Packet, and #Context, which use the same #BLOCK section that specifies <key:value> pairs. We describe how to process various data in following subsections."}, {"title": "VII. EVALUATION", "content": "1) Anomaly Detection: To enrich our dataset with anomalous data, we employ several techniques to transform normal records. First, we designate every n-th record as anomalous. Additionally, we introduce irregularities by randomly altering select records. To simulate different degrees of deviation, we systematically vary the dataset's variance and generate corresponding datasets. Lastly, we apply a Poisson distribution to intersperse anomalous data throughout the dataset, ensuring a realistic distribution of anomalies for robust model training. \nThe following formulas are used for detecting anomalies. The loss is calculated as:\nloss = MSE(predicted_value \u2013 groundtruth_value) (1)\nThe anomaly threshold is calculated as:\nthreshold = Percentile(loss, 100 \u2013 anomaly_ratio) (2)\na) Every nth record is anomaly: We take the normal data from the sensor and manipulate every nth record to contain anomalous data. For the experiment, we choose n=5. The anomalous data thus generated is fed into the TimesNet model running on the Edge Server, and the loss is calculated as per formula 1. When the loss exceeds the thresholds as calculated in formula 2, the data is flagged as an anomaly."}, {"title": "VIII. CONCLUSION", "content": "In this paper, we present the Aero-LLM framework for UAVs, addressing the need for secure, efficient, and intelligent systems. Aero-LLM integrates Large Language Models (LLMs) to enhance UAV capabilities for complex missions, ensuring security and efficiency. Future research aims to extend Aero-LLM to support multiple UAVs with individual computational LLMs for autonomous decision-making, enabling collaboration in terrain mapping and mission execution. Integrating advanced sensors and real-time data processing will enhance operational accuracy and efficiency. Aero-LLM seeks to achieve higher mission success and reliability through a distributed network of intelligent UAVs. Comprehensive evaluation confirms Aero-LLM's high performance across key metrics such as accuracy, precision, recall, and F1 score, while maintaining a low memory footprint."}]}