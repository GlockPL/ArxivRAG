{"title": "One Stone, Four Birds: A Comprehensive Solution for QA System Using Supervised Contrastive Learning", "authors": ["BO WANG", "TSUNENORI MINE"], "abstract": "This paper presents a novel and comprehensive solution to enhance both the robustness and efficiency of question answering (QA) systems through supervised contrastive learning (SCL). Training a high-performance QA system has become straightforward with pre-trained language models, requiring only a small amount of data and simple fine-tuning. However, despite recent advances, existing QA systems still exhibit significant deficiencies in functionality and training efficiency. We address the functionality issue by defining four key tasks: user input intent classification, out-of-domain input detection, new intent discovery, and continual learning. We then leverage a unified SCL-based representation learning method to efficiently build an intra-class compact and inter-class scattered feature space, facilitating both known intent classification and unknown intent detection and discovery. Consequently, with minimal additional tuning on downstream tasks, our approach significantly improves model efficiency and achieves new state-of-the-art performance across all tasks.", "sections": [{"title": "I. INTRODUCTION", "content": "UESTION answering (QA) system is a well-established and important application widely used in areas such as healthcare [1], finance [2] and e-commerce [3]. Despite the world gradually moving into the era of large language models (LLMs), classic QA systems still maintain a strong presence due to their low cost, ease of deployment, and high accuracy in answering questions.\nA typical QA system mainly comprises two components: user intent classification and answer retrieval. The efficiency of the former is crucial, as a correct response often depends on accurately determining the user's intent. To achieve robust classification, it is essential to efficiently extract features from user input, providing intent-specific and discriminative text representations for classification. Initially, text features were extracted manually using techniques like term frequency-inverse document frequency (TF-IDF [4]) or bag-of-words (BoW [5]). With the advent of neural networks, feature extraction became an automated process [6], [7]. Today, the power of pre-trained Transformers like BERT [8] has made it much easier to extract features and build classification models, requiring only a small amount of data with Cross-Entropy (CE) loss fine-tuning [9], [10].\nIt seems that the current QA system building is simple and mature, with nearly nothing to be changed. However, from the perspective of building a comprehensive system, current QA systems still face unresolved issues at both internal and external levels, which have not been fully addressed yet:\n\u2022 Externally, or at the system level: Current QA systems typically adopt a \"training-as-complete\" policy, meaning that once the model has finished training, its knowledge is not updated. This approach leaves the system vulnerable to unseen, unknown inputs (as out-of-domain, OOD inputs [11]). To maintain the robustness and security of the model, there should be mechanisms to handle these inputs. Furthermore, even when new data is collected to upgrade the system, the common practice is to re-train a new model from scratch, leading to a waste of labor and resources.\n\u2022 Internally, or in training efficiency: Increasing studies indicate that the BERT+CE training combination still has efficiency problems. For BERT, the raw text feature distribution is anisotropic [12]. Additionally, when using CE as the fine-tuning loss, text features of different intents often remain mixed with unclear boundaries in the embedding space [13]. Both issues hinder training efficiency and model performance.\nIn this paper, aiming to build a more robust QA system, we propose a novel and comprehensive solution to address both issues. To tackle the systematic issue, including the basic intent classification function, we define four key tasks and design a workflow between them (as shown in Figure 1), enabling the system to be self-consistent and recurrently updatable. Specifically, the tasks are:\nT-1 User input intent classification: The fundamental task for a QA system.\nT-2 OOD input detection: Detect abnormal inputs to prevent misleading output. The detected OOD texts are saved as source data for Task 3.\nT-3 New intent discovery: Utilize detected OOD texts to discover new possible intents once they accumulate to a sufficient quantity.\nT-4 Continual learning: Use newly discovered and pseudo-labeled data to incrementally train the initial classification model, enhancing the system's capability to handle the latest inquiries.\nTo address the training efficiency problem, we leverage supervised contrastive learning (SCL, [14]) to replace CE fine-tuning as the unified text representation optimization method, which requires minimal tuning to achieve all four task objectives. We choose SCL because, in our previous research on OOD detection [15], it demonstrated excellent capability in upstream feature optimization, allowing an accurate OOD text detection using only a simple distance-based algorithm in downstream.\nMore specifically, the advantage of SCL over CE fine-tuning lies in its ability to enhance both learning efficiency and feature separation. As shown in Figure 2-b), SCL employs a simple but clear optimization target: pulling same-label text features together and pushing different ones further apart, resulting in an intra-class compact and inter-class"}, {"title": "II. RELATED WORKS", "content": "Early history of representation learning\nRepresentation learning (RepL), or feature learning, is a crucial process in building machine learning models. Good RepL methods capture the intrinsic patterns and structures of the data, thus providing a solid foundation for downstream tasks.\nInitially, RepL research focused on manually extracting meaningful features from raw data, with preliminary methods including TF-IDF [4] and BoW [5]. Subsequently, the development of word embeddings extracted via neural net-\nAs discussed above, RepL research has gradually shifted focus from feature extraction to feature optimization, with one of the most popular method series being the contrastive learning (ConL). The earliest ConL can be traced back to supervised metric learning (MeL) [19] used in image classification tasks, which established the fundamental strategy of"}, {"title": "III. PROBLEM AND TASK DEFINITION", "content": "As mentioned in Section I, we introduce four basic tasks to build a comprehensive and adaptive QA system (Figure 1). Here, before presenting the specific solutions, we formally define the problems and targets of each task.\nSuppose we initially have a set of known data \\(S_{known}=\\{x_i, y_i | y_i \\in C_{kn}\\}\\), where \\(x_i\\) is the i-th user inquiry text, \\(y_i\\) is the corresponding label, and \\(C_{kn}\\) is the label set of known intents. This data serves as the pre-training data, which is also referred as the In-Domain, IND examples, i.e., \\(\\{x_i, y_i | y_i \\in C_{kn}\\} \\in D_{IND}\\).\nWe also have a set of label-unknown data \\(S_{unlabeled} = \\{x_j, y_j | y_j \\in \\{C_{kn} + C_{uk}\\}\\\\}\\), which refers to the real, daily user inputs. Note that besides the known intents, there are also\nThe target of this task is to find an accurate mapping:\n\\(f_{cls}: ENC(x_i) \\rightarrow \\hat{y}_i \\qquad \\hat{y}_i \\in C_{kn}\\) (2)\nFor traditional methods like CE-fine-tuning, this is achieved by further adding a fully-connected layer to the end of ENC and training them together using CE loss. In the proposed method, the encoder is pre-trained using SCL (refer to Section IV-A for details) and the parameters are fixed in the following tasks T-1/2/3. \\(f_{cls}\\) is realized by a nearest neighbor algorithm (Section IV-B1).\nThe target of this task is to determine whether an example \\(x_j\\) from \\(S_{unlabeled}\\) belongs to \\(D_{IND}\\) or \\(D_{OOD}\\). This is usually realized by comparing the detection score sco given by a detection algorithm \\(f_{det}\\) with an empirically-set threshold \\(\\lambda\\):\n\\(scoj = f_{det}(ENC(x_j))\\) (3)\n\\(x_j \\in \\begin{cases} D_{OOD}, \\text{ if } scoj \\geq \\lambda \\\\ D_{IND}, \\text{ if } scoj < \\lambda \\end{cases}\\) (4)\nHere, the detected \\(x_{ood}\\) are saved for T-3 (new intent discovery), while the detected \\(x_{ind}\\) will be classified normally in T-1 and also saved for the final task, T-4 (continual learning).\nOnce the collected OOD texts \\(x_{ood}\\) reach a sufficient quantity, an algorithm \\(f_{nid}\\) is used to cluster and assign pseudo labels \\(\\hat{y}_{j'}\\) to them, as the \u201cnew IND intents\u201d in \\(C_{kn'}\\):\n\\(f_{nid}: ENC(x_{j'}^{ood}) \\rightarrow \\hat{y}_{j'} \\qquad \\hat{y}_{j'} \\in C_{kn'}\\) (5)"}, {"title": "IV. METHODOLOGY", "content": "In this section, we introduce the methodology of SCL as the RepL method in the pre-training stage, followed by the downstream solutions to each task.\nAs discussed in Section II, BERT+CE fine-tuning exhibits issues with local loose borders and a global anisotropic distribution in RepL, while SCL has the potential to solve both of these problems.\nSpecifically, as illustrated in Figure 2, for the local aspect, compared with CE fine-tuning, SCL applies a more straightforward yet effective target: pulling the representations of similar examples (positive examples) together and pushing dissimilar ones (negative examples) further apart. To tackle the global distribution problem, SCL further generates \u201cview\u201d augmentations as additional positive examples before the contrasting process, optimizing features in a boarder scale. Together, these strategies provide a better supervision signal to arrange text representations to form compact and distinct clusters, enhancing both the alignment and uniformity of feature space, and thus sharpening the distinctions between texts from various intents.\nThis well-organized embedding space (Figure 2-b) provides a strong foundation that benefits all downstream tasks:\nT-1: The clear separations between each intent cluster facilitate easy and accurate classification.\nT-2: The compact and distinct IND clusters highlight the differences between them and OOD texts, which do not belong to any known intents.\nT-3: Although not trained directly with OOD data, the two optimization directions of SCL still drive the aggregation of semantically similar features. This creates an environment conducive to intent discovery algorithms, making it easier to identify the clustered gathered data.\nT-4: The accurately discovered new intent data, pre-organized feature space, and SCL-based re-training, together ensure the high-performance of the updated system.\nAs discussed in the last subsection, the effective optimization of SCL is attributed to both the supervised positive-negative movement and the unsupervised \"view\" augmentation. This augmentation also serves as a precaution against the lack of positive examples in the mini-batch, especially when the data quantity is small compared with category numbers. For images, view generation can be achieved by simple transformations such as rotating and cropping. However, these techniques are not easily applicable to text \u201cview\u201d generation, as hasty word swaps or deletions can distort the original meaning. In our previous study [15], we found that encoding a sentence twice with different drop-out masks (Figure 2-left) is an effective way to generate high-quality, slightly different but main meaning preserved text embeddings. By using this generation method, SCL gave the best OOD detection results compared to no-view-generation [33] or more complex techniques like embedding-attack [53] (refer to Tables 3-5 of [15] for detailed results). Considering these advantages, we continue to use this technique as the augmentation method in this paper.\nHere we give the formal definition of an SCL procedure:\nBefore the learning process, two text embedding views are generated for each example in the known dataset \\(S_{known}=\\{x_i, y_i | y_i \\in C_{kn}\\}\\). This is achieved by enabling the dropout option in network training settings and inputting the same sentence twice:\n\\(h_{2i'} = ENC_{drop1}(x_i), h_{2i'+1} = ENC_{drop2}(x_i)\\) (7)\nHere, since the two view embeddings are derived from the same text, we assign them the same label as \\(x_i\\), that is: we get two views \\(\\{(h_{2i'}, y_{2i'}), (h_{2i'+1}, Y_{2i'+1})\\}\\), where \\(y_{2i'} = y_{2i'+1}=y_{i'}\\), \\(i'\\in\\{1, 2, ..., N\\}\\).\nThe SCL training loss is defined as follows:\n\\(L_{SCL} = \\sum_{i'=1}^{2N} \\frac{-1}{|Pos(i)|} \\sum_{p \\in Pos(i')} log \\frac{exp(h_{i'} \\cdot h_p / \\tau)}{\\sum_{q \\in Neg(i')} exp(h_{i'} \\cdot h_q / \\tau)}\\) (8)\nwhere \\(i' \\in \\{1, 2, ..., 2N\\}\\) is the index of current sample (the anchor text). \\(Pos(i')\\) is the index set of all positive examples to the anchor text in the mini-batch, i.e., \\(y_p = y_{i'}\\), and \\(Neg(i')\\) is the index set of all negative examples, i.e., \\(y_q \\neq y_{i'}\\). \\(\\tau\\) is the temperature factor to amplify the loss output. To calculate text similarity directly using dot product, we apply L2 normalization to all representations before training.\nWith a well-organized embedding space achieved through SCL, we can complete all the tasks with the least efforts.\nWe apply a Mahalanobis distance (MDist) - nearest neighbor (NN)-based method for IND intent classification, which does not require any additional training. We use MDist because, compared to Euclidean distance, MDist considers the distribution of each feature component, providing a more accurate measurement of text similarity. Additionally, to further"}, {"title": "V. EXPERIMENT", "content": "We apply the following latest and competitive methods as baselines for evaluation.\nDespite being the most common training method, CE-based fine-tuning remains one of the most powerful methods actively used among all tasks [16], [31], [41]. Thus this time we applied it as a baseline of RepL, and tested the effects throughout all four tasks. The downstream detection and clustering method are all the same as SCL.\nThis work proposed a Prefix Tuning-based OOD detection method, training a generative GPT-2 model on IND data and then using the likelihood as sco. It assumes that the unseen OOD text should let model output a lower likelihood. This method originally supports unsupervised learning, but for a fair comparison, we applied its supervised mode with IND labels available.\nThis paper addressed that pre-trained language models like BERT may over-rationalize the input. That is, even it is an OOD input, the last-layer embedding may tend to be more like IND. Based on this observation, it proposed to consider a decision of multiple layers after fine-tuning, and finally used local outlier factor (LOF) with a voting mechanism for final decision. In this paper, we simply averaged its best-four layer results as the final result.\nThe state-of-the-art NID method that first pre-trains the model with a Masked Language Modeling (MLM) target to obtain prior semantic knowledge, then performs KNN contrastive learning for better cluster aggregation. The downstream clustering method is KMeans.\nThis Decoupled Prototypical Network first initializes some prototypes for known and unknown intents and aligns them as a bipartite matching problem. Unaligned prototypes represent new intents, and all embeddings are further optimized using semantic-aware prototypical learning. The downstream method is also KMeans.\nWe evaluate the methods using three popular intent clas-sification datasets. To measure the performance of T-3 and T-4 quantitatively, we randomly select approximately 75% of"}, {"title": "VII. CONCLUSION", "content": "In this paper, we addressed the functionality and efficiency problems of current QA system, and proposed our solution to solve them and build a comprehensive system. We first defined four key tasks to complement the system's functionality shortcomings, and then applied SCL as the unified representation learning method with minimal additional tuning to achieve the task targets. The experiment results demonstrated that although being simple and straightforward, the proposed method still achieved leading results in each task.\nAs this complete solution is first proposed and is still a prototype, there are still many situations needed to be considered for real deployment in the future. For example, there may also be some noisy inputs appearing, which are hard to be categorized into any intents. In such cases, developing a filtering algorithm before the intent discovery process might be necessary. In addition, to show efficiency, this time the downstream methods were all chosen to be as simple as possible, while more advanced methods could potentially yield even better results when combined with SCL."}]}