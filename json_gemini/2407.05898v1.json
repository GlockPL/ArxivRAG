{"title": "Contrastive Learning of Preferences\nwith a Contextual InfoNCE Loss", "authors": ["Timo Bertram", "Johannes F\u00fcrnkranz", "Martin M\u00fcller"], "abstract": "A common problem in contextual preference ranking is\nthat a single preferred action is compared against several choices,\nthereby blowing up the complexity and skewing the preference dis-\ntribution. In this work, we show how one can solve this problem via\na suitable adaptation of the CLIP framework. This adaptation is not\nentirely straight-forward, because although the InfoNCE loss used by\nCLIP has achieved great success in computer vision and multi-modal\ndomains, its batch-construction technique requires the ability to com-\npare arbitrary items, and is not well-defined if one item has multiple\npositive associations in the same batch. We empirically demonstrate\nthe utility of our adapted version of the InfoNCE loss in the domain\nof collectable card games, where we aim to learn an embedding space\nthat captures the associations between single cards and whole card\npools based on human selections. Such selection data only exists for\nrestricted choices, thus generating concrete preferences of one item\nover a set of other items rather than a perfect fit between the card and\nthe pool.\nOur results show that vanilla CLIP does not perform well due\nto the aforementioned intuitive issues. However, by adapting CLIP\nto the problem, we receive a model outperforming previous work\ntrained with the triplet loss, while also alleviating problems associ-\nated with mining triplets.", "sections": [{"title": "1 Introduction", "content": "Preference Learning [6] is a machine learning framework, where the\ntask is to learn a function over a set of objects which indicates a\ndegree of preference for a given object o. One way of solving this\nproblem is to learn a numeric utility function u: O \u2192 R, where\nhigher values of u indicate a higher degree of preference, i.e.,\n$$u(o_1) > u(o_2) \\Leftrightarrow o_1 \\succ o_2$$\nIn many cases, such a function is learned from a training set D of bi-\nnary constraints of the form $$\\langle p_i \\succ n_i\\rangle$$, i = 1... |D|, where the i-th\nconstraint indicates that object p\u2081 is preferred over n\u2081. In the follow-\ning, we will often call p\u2081 the positive and n\u2081 the negative example of\nthe i-th preference.\nAs there are O(|O|^2) possible preference constraints over the set\nof objects O, it is difficult to manually label a sufficient number\nof training examples. However, in many cases, preferences can be\nobserved from behavioural traces. In particular, in decision-making\nprocesses, one can infer preferences from observations, in which"}, {"title": "2 Deckbuilding in Collectable Card Games", "content": "Collectable card games are a significant portion of the board game\nmarket and offer a large competitive scene. Games such as Hearth-\nstone or Magic: The Gathering possess player counts in the millions\nand Magic: The Gathering is currently evaluated at over $1 billion\u00b9.\nStill, game AI for those games is still in its infancy and outside of\nvastly simplified game versions [14], few models exist that are able\nto navigate aspects of them. In this work, we regard one subarea of\nconstructing sophisticated collectable card game agents; deckbuild-\ning."}, {"title": "2.1 Deckbuilding", "content": "Deckbuilding, i.e. selecting which cards to play the game with, is an\nintegral aspect of every collectable card game. The specific choice\nof cards crucially enables gameplay and meaningful selections are\nnecessary to compete against others. Still, they are also influenced\nby personal preference and card availability, allowing for much dis-\ncussion and uncertainty. So far, constructing well-versed models to\nbuild functional decks on a similar level as humans is still a work in\nprogress [15].\nIn most game versions, building a deck is separate from playing\nwith it, i.e. the deckbuilding process is not built into gameplay but\nrather occurs in advance. However, some game versions strongly re-\nstrict deckbuilding by integrating it into the gameplay and reducing\nthe pool of cards to choose from. Such game modes are called Lim-\nited games. We outline the process in detail in Section 2.2"}, {"title": "2.2 Limited deckbuilding", "content": "In Limited, players sequentially build their decks based on a limited\nselection of cards. This process is called drafting.\n\u2022 For every decision point, a player is offered a set of cards called a\npack. At the start of the process, it consists of 15 unique cards.\n\u2022 The player selects a single card and adds it to their pool. After\nselecting the card, the player passes all unchosen cards to a neigh-\nbouring opponent. Note that pool and deck are interchangeable\n\u00b9 https://investor.hasbro.com/magic-gathering\n\u2022 The player receives a separate pack from the opponent on the other\nside. As that opponent has previously picked a card, this pack\ncontains one less card. The player again selects a single card and\npasses the remaining.\n\u2022 After 15 selections, each with a decreasing number of options, all\nsteps above are repeated twice with two additional packs.\nAltogether, a player makes 42 selections, as for the last card in\neach of the three packs, no decision occurs. Disregarding the influ-\nence of one's own selections on the opponents and disregarding card\nduplicates, this leads to 3.15! > 10\u00b9\u00b2 separate decks a player can end\nup with. While this might not seem like a large number, packs contain\na semi-random distribution of roughly 250 unique cards. With this,\nthe quantity of unique drafts is enormous. To add to the difficulty\nof learning this process, evaluating the chosen cards depends on the\nactual gameplay with them, which is a large and unsolved problem\nin itself. Thus, currently no strong drafting or playing against for\nfull games of Magic: The Gathering exist. In this work, we aim to\nwork towards being able to generate drafting agents for this game by\nleveraging human data. Such agents could be used as opponents or\ntraining tools for less experienced players."}, {"title": "2.3 Data", "content": "For this work, we use a dataset collected by 17lands. 17lands is\na website focused on Limited gameplay of Magic: The Gathering\nand collects data on a large amount of experienced human players.\nThe dataset we use consists of human selections of cards through-\nout the drafting process. For every draft, we receive information on\nthe possible card choices (P) and which card was chosen (c*). As\ncard choices are highly situational and strongly depend on previous\ndecisions, we relate the given card choice to all cards a player has\npreviously chosen C. The following section explains how we train\nmodels with this data."}, {"title": "3 Contextual Preference Ranking", "content": "In this section, we introduce the main contribution of this paper.\nWe first review the previous use of pairwise constraints for training\na Siamese neural network for contextual preference ranking (Sec-\ntion 3.1), then briefly recapitulate CLIP and the InfoNCE loss (Sec-\ntion 3.2), and finally demonstrate how it can be adapted to our con-\ntextual ranking setting (Section 3.3)."}, {"title": "3.1 Siamese Neural Networks for Drafting", "content": "As shown by Bertram et al. [1], Siamese Neural Networks (SNNs) [4]\ncan effectively be used to predict human player's decisions. In their\ncontextual preference ranking (CPR) framework, several options\nare compared against each other in the context of a specific item.\nConcretely, CPR learns to predict a preference of one choice $c_j$\nover $c_k$ in the context of C, i.e.\n$$\\langle C, c_j \\succ c_k\\rangle$$\nIn practice, this is achieved by training an SNN with the triplet loss\n(Equation 3) to generate a latent embedding space of $c_j$, $c_k$, and C,\nin which d($c_j$, C) < d($c_k$, C) according to some distance metric d\n(e.g. the Euclidian distance).\n$$L_{triplet}(a, p, n) = \\max(d(a, p) \u2013 d(a, n) + m, 0)$$\nCrucially, while the network is solely trained on comparisons of\nsingle choices, distances in the embedding space are transitive and\nwe can thus compare an arbitrary amount of items, i.e.\n$$(c_j \\succ c_k | C) \\land (c_k \\succ c_i | C) \\Rightarrow (c_j \\succ c_i | C)$$\nThis enables ranking a whole set of items in a given context, thus\nallowing us to use the method for drafting (Section 2.2). While this is\nhighly related to using SNNs for image recognition [9], training the\nSNN is more restricted here.\nGiven a dataset of images D and a labelling function f: R^n \u2192\n[1, C] one can construct numerous valid triplets (a, p, n) by sam-\npling random tuples ($x_0, x_1, x_2$) from D where f($x_0$) = f($x_1$) & f($x_0$) \u2260 f($x_2$) & $x_0 \\neq x_1$. While not allowing for completely\narbitrary comparisons, e.g. if f($x_0$) \u2260 f($x_1$) \u2260 f($x_2$) one can con-\nstruct no triplet, a well-constructed dataset will provide plenty of pos-\nsible comparisons even when mining batches online, as a, p, and n\nare all simple images.\nFor our domain, only restricted comparisons apply. For given set\nof items P, the dataset is constructed by relating the human selection\nc* \u2208 P | C to all other $c_0,..., c_n$ \u2208 P. As opposed to the previous\ndomain, all $c_i & P$ can not be compared and thus do not provide\nvalid triplets. Thus, for our work, we sample decisions of the form\n(C, P) with the labelling function f : P \u00d7 C \u2192 [1, 15], from which\nwe can generate the triplets (C, P[f(P, C)], $c_i$) for all i = 1, ..., |P|.\nNote that f is not necessarily deterministic, i.e. separate records in\nthe dataset can choose different cards in the exact same situation."}, {"title": "3.2 InfoNCE Loss in CLIP", "content": "The recently popularised InfoNCE loss [10, 8] is a powerful tool for\ncontrastive learning. This representation learning technique is based\non matching pairs of different modalities, e.g. pairs of images with\nassociated captions in CLIP. For a batch of pairs, CLIP [8] aligns all\npossible combinations in a square matrix with the correct pairings on\nthe diagonal, training the text-encoder and image-encoder to max-\nimise the cosine similarity of the diagonal and minimising all others\n(see Figure 1). However, this only results in perfect pairings when\nassuming that no other items in the batch interfere with the pairs by\nbeing more similar. Given a batch of N pairs of images I with texts\nT, it is assumed that, for a given similarity measure sim:\n$$\\forall i \\in [0, N] \\quad \\nexists j \\in [0, N] : \\text{sim}(I_i, T_i) > \\text{sim}(I_i, T_j), i \\neq j$$\nHowever, for sufficiently large batches, it is not unlikely that mul-\ntiple images fit a text or vice versa. In practice, this inaccuracy is\nlikely mitigated by the large dataset, but using the same approach for\nsmaller datasets or ones with frequently reoccurring items might lead\nto performance degradation. Our domain is one such example where\nthere are only roughly 250 different cards, which frequently results\nin one batch containing the same items. Therefore, it is not possi-\nble to simply minimise the cross entropy loss in both dimensions of\nthe pair-matrix, as there will be correct pairings not on the diagonal,\nwhich means that one card can be associated with multiple decks.\nSome later adaptions of CLIP [16] are able to handle such settings\nby circumventing the softmax normalisation and cross-entropy com-\nputation by using a pairwise sigmoid loss, but we show in Section 4\nthat our domain possesses additional difficulties which do not allow\nthis simple change."}, {"title": "3.3 Contextual InfoNCE for Drafting", "content": "In order to use the InfoNCE loss for drafting we need to make\nseveral adaptions. When training our model, we sample decisions\nfrom the dataset of the form (C, P) and have access to the labelling\nfunction f, where f(P, C) = c*, i.e. we can identify the chosen card\nin the pack. We create a multi-modal embedding space which relates\ncard pools C to cards c\u2208 P by training a pool encoding network and\na card encoding network. In contrast to the embeddings created in\nmany other domains, where the space models the similarity of items,\nours represents player decisions. Thus, we still aim to maximise the\ncosine similarity of the pool and chosen cards while minimising the\ncosine similarity of the pools and unchosen cards."}, {"title": "4 Experiments", "content": "In this section, we compare our proposed method to previous re-\nsearch using the triplet loss and an unaltered version of CLIP. For\nthe triplet approach, we use the research Bertram et al. [1], CLIP-\nbased experiments were re-implemented by us. Although the spe-\ncific implementation details are not of high importance, as we aim to\nequalise hyperparameters, we briefly cover implementation details\nin Section 4.1. For all experiments, we use the datasets provided\nby 17 lands. These datasets provide turn-by-turn records of human\ncard selections when drafting. We regard these drafting decisions are\npreferences of one card over a set of other cards given that player's\npool. Thus, we can directly generate training samples, i.e. triplets of\nthe pool, chosen card and unchosen cards, from the dataset. While\nnumerous datasets with different cards are available, we arbitrarily\nchose a single one (NEO). This dataset consists of 5,693,460 sam-\nples which we split 80/20 into training and test data.\nAll outlined training approaches aim to model the contextual card\npreferences by learning an embedding space in which preferred cards\npossess embeddings with high cosine similarity, or small distance, to\nthe pool. The methods mainly differ by the loss function used and\nhow the training data is processed by the networks."}, {"title": "4.1 Architectures and Hyperparameters", "content": "While it is not possible to entirely equalise the hyperparameters\nacross settings, we aim to minimise the interference of parameter\nchoice on the results. In addition, we realise that computation speed\ncomparisons are hardware and implementation-specific. Still, we be-\nlieve that our results provide useful insights into the problem setting.\nFor many architectural choices, we modelled our experiments after\nthe previous work by Bertram et al. [1]."}, {"title": "4.1.1 Card representation", "content": "Magic: The Gathering cards possess numerous attributes which are\nhard to properly represent to enable meaningful feature extraction.\nCrucially, cards consist of a variety of categorical and numerical at-\ntributes (e.g. cost, power, colour), but also contain important natu-\nral language text. To represent a single card, we encode all numer-\nical and categorical features in a vector. We concatenate this with a\nBERT-generated [5] embedding of the card text and an autoencoder-\ngenerated latent representation of the full card visual. Altogether, this\nresults in a 2330-dimensional vector.\nCard pools, i.e. a list of individual cards, are represented as ma-\ntrices of 45 cards, as a pool can maximally be 45 elements long.\nRows of the matrix that belong to yet-unchosen cards are set to 0.\nSequence-based approaches, e.g. RNNs or transformers, might be\nsuitable here but we simply process each pool matrix with convolu-tions."}, {"title": "4.1.2 Neural Networks", "content": "Single cards and card pools differ in their representation which ne-\ncessitates different neural network structures to learn embeddings\n(see Figure 3). We call those specialised networks card encoder and\npool encoder, which ultimately serve to translate the two differently\nrepresented inputs to a shared embedding space. When using the\ntriplet loss, the encoding networks are smaller due to the following\nshared main block. For the InfoNCE variant, we do not use a Shared\nMain Block and rather train two larger card encoders and pool en-\ncoders. While not strictly necessary, we experimentally found that\nusing the card encoder in the forward pass of pools aids training, as\npools are simply lists of cards.\nCard encoders are fully connected networks with 5 or 10 lay-\ners with 1024 neurons each, connected by normalisation and ELU-\nactivations. Pool encoders are convolutional neural networks con-\nsisting of 3 or 5 layers with 128 filters, which are connected in the\nsame manner. For the triplet-based network, the main block consists\nof 5 additional fully connected layers, while for the InfoNCE net-\nwork, the card output is a single layer. Both networks are trained\nwith stochastic gradient descent on their respective loss function and\na learning rate of 0.0003."}, {"title": "4.2 Results", "content": "Finally, we experimentally compare the outlined approaches. All ex-\nperiments are run on a single Nvidia A100 80GB GPU. We decided\non the following different methods:\n1. Standard InfoNCE loss. This generates a cosine similarity matrix\nas seen in Figure 1(a) and computes the cross entropy loss in both\ndimensions of the matrix, which are summed to generate the over-all loss.\n2. InfoNCE loss with a paired Sigmoid loss on the cosine similarities\ninstead of using Softmax and the cross entropy loss [16]. This\nversion alleviates some of the previously mentioned issues with\nthe InfoNCE loss, e.g. multiple matching pairs, but still suffers\nfrom comparisons out of context."}, {"title": "5 Conclusion", "content": "In this research, we aim to provide a novel way to frame contextual\npreferences by utilising the InfoNCE loss function. For numerous\ndomains, preferences between items depend on specific situations,\nthus making it impossible to compare them in a vacuum. To alleviate\nthis, we adapt the batch construction technique from CLIP [8] to only\ntrain on preferences explicitly contained in the training data.\nWe experimentally show (Section 4.2) that this technique outper-\nforms both unaltered CLIP, CLIP with a sigmoid loss function, and\ntriplet loss-based models. The sigmoid-based version is the second\nbest in our experiments, as it also alleviates a subset of the problems\nof standard InfoNCE, but our proposed method results in better per-\nformance. Our method adds no relevant computation time compared\nto the other InfoNCE methods and is thus strictly better-versed for\nthe task at hand.\nTriplet loss-based methods had surprising differences in accuracy\ndepending on the triplet mining technique. Random mining, i.e. ran-\ndomly choosing one of the available negative examples, is unsurpris-\ningly fastest but also leads to the best accuracy. Hard mining was\nassumed to lead to higher accuracy but required additional computa-\ntion with a decreased accuracy. We speculate that a mix of both, e.g.\nfirst mining randomly and later in training switching to hard mining,\nmight lead to higher accuracy, but such additional experiments are\nleft for future work. Unsurprisingly, using all negative examples in\ndifferent triplets leads to poor results, as this greatly bloats training\ntime due to reductions in batch size. In addition, this led to a stark\nperformance degradation.\nWhile only regarding a single domain here, collectable card\ngames, our proposed adaptions translate to many domains. Prefer-\nences, or other metrics which be can be represented by an embed-\nding space, often occur in specific contexts, which hinders the gen-\neral capability of the InfoNCE loss. Altogether, this research forms a\nbaseline for future work on contextual preferences, a highly relevant\nresearch question."}, {"title": "6 Future Work", "content": "While we show in this work that the InfoNCE loss can be adapted to\nthe given problem with few changes, we speculate that overall more\npromising methods are possible. Masking invalid entries in the co-\nsine similarity matrix works from a computational perspective but\nleads to a large number of unnecessary items. Instead, we aim to\nwork towards an approach that explicitly adds the context of the pref-\nerence to the loss computation while keeping the advantages of the\nInfoNCE loss."}]}