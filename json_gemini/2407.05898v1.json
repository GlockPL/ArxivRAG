{"title": "Contrastive Learning of Preferences with a Contextual InfoNCE Loss", "authors": ["Timo Bertram", "Johannes F\u00fcrnkranz", "Martin M\u00fcller"], "abstract": "A common problem in contextual preference ranking is that a single preferred action is compared against several choices, thereby blowing up the complexity and skewing the preference distribution. In this work, we show how one can solve this problem via a suitable adaptation of the CLIP framework. This adaptation is not entirely straight-forward, because although the InfoNCE loss used by CLIP has achieved great success in computer vision and multi-modal domains, its batch-construction technique requires the ability to compare arbitrary items, and is not well-defined if one item has multiple positive associations in the same batch. We empirically demonstrate the utility of our adapted version of the InfoNCE loss in the domain of collectable card games, where we aim to learn an embedding space that captures the associations between single cards and whole card pools based on human selections. Such selection data only exists for restricted choices, thus generating concrete preferences of one item over a set of other items rather than a perfect fit between the card and the pool.\nOur results show that vanilla CLIP does not perform well due to the aforementioned intuitive issues. However, by adapting CLIP to the problem, we receive a model outperforming previous work trained with the triplet loss, while also alleviating problems associated with mining triplets.", "sections": [{"title": "1 Introduction", "content": "Preference Learning [6] is a machine learning framework, where the task is to learn a function over a set of objects which indicates a degree of preference for a given object o. One way of solving this problem is to learn a numeric utility function u: O \u2192 R, where higher values of u indicate a higher degree of preference, i.e.,\n$$u(o_1) > u(o_2) \\Leftrightarrow o_1 > o_2$$\nIn many cases, such a function is learned from a training set D of binary constraints of the form $(p_i \\succ n_i), i = 1... |D|$, where the i-th constraint indicates that object $p_i$ is preferred over $n_i$. In the following, we will often call $p_i$ the positive and $n_i$ the negative example of the i-th preference.\nAs there are $O(|O|^2)$ possible preference constraints over the set of objects O, it is difficult to manually label a sufficient number of training examples. However, in many cases, preferences can be observed from behavioural traces. In particular, in decision-making processes, one can infer preferences from observations, in which one action has been selected (and thus preferred) over all alternative actions. Attempts for formalizing such settings in the context of Markov decision processes can be found in the literature [12, 13].\nMoreover, in many cases, the observed preference depends on a given context. A classic example is that the wine preference may depend on the choice of the accompanying main dinner course. Reasoning with such contextual preferences have, e.g., been formalized in CP-nets [3]. A simple example for such a setting is label ranking [7, 11], where contexts are given in the form of training examples, for which preference constraints are defined over (some of) the possible labels. However, in general, the objects over which preferences are defined may also be more complex than simple labels. For example, in the application we are working on, we intend to learn preferences over playing cards in the context of the cards a player is already holding. This allows a player to select from an available, restricted set of cards, where the best selection is not necessarily the overall best card, but the one that is the best addition to the set of cards that the player is already holding - a property that is crucial for success in collectable card games. Similar problems exist in many domains, such as, e.g., team building (the best addition to a team may not necessarily be the best player available on the market), recommender systems (the best recommendation for a user will not be the most popular book but the book that best fits the set of books they have already bought), etc.\nA common problem in learning such a contextual preference function from behavioural traces is that one typically observes one preferred out of a larger set of possible actions. In our case, we can observe the card that a user has picked out of a set of dozens of cards they could have selected. This gives rise to a set of pairwise preferences where a single picked card is paired with r rejected cards. Not only could r be a very large number, but it may also result in a skewed sample distribution because the single positive example will appear with higher frequency than the r negative examples.\nIn this paper, we improve upon prior work [1, 2] that used contextual preference ranking in the context of the collectable card game Magic: The Gathering. Our key contribution is to demonstrate how the above-mentioned setting can be solved by converting r pairwise contextual preferences into a single comparison of over r objects. To this end, we adapt the well-known CLIP framework [8] to this task, showing that while a straight-forward adaption does not work as intended, a few minor modifications allow us to not only improve the predictive performance but also speed up the training process, while not needing to mine triplets online.\nWe start with a brief introduction to our application setting, card selection in a collectable card game, in Section 2. Section 3 intro-"}, {"title": "2 Deckbuilding in Collectable Card Games", "content": "Collectable card games are a significant portion of the board game market and offer a large competitive scene. Games such as Hearthstone or Magic: The Gathering possess player counts in the millions and Magic: The Gathering is currently evaluated at over $1 billion\u00b9. Still, game AI for those games is still in its infancy and outside of vastly simplified game versions [14], few models exist that are able to navigate aspects of them. In this work, we regard one subarea of constructing sophisticated collectable card game agents; deckbuilding.\n2.1 Deckbuilding\nDeckbuilding, i.e. selecting which cards to play the game with, is an integral aspect of every collectable card game. The specific choice of cards crucially enables gameplay and meaningful selections are necessary to compete against others. Still, they are also influenced by personal preference and card availability, allowing for much discussion and uncertainty. So far, constructing well-versed models to build functional decks on a similar level as humans is still a work in progress [15].\nIn most game versions, building a deck is separate from playing with it, i.e. the deckbuilding process is not built into gameplay but rather occurs in advance. However, some game versions strongly restrict deckbuilding by integrating it into the gameplay and reducing the pool of cards to choose from. Such game modes are called Limited games. We outline the process in detail in Section 2.2\n2.2 Limited deckbuilding\nIn Limited, players sequentially build their decks based on a limited selection of cards. This process is called drafting.\n\u2022 For every decision point, a player is offered a set of cards called a pack. At the start of the process, it consists of 15 unique cards.\n\u2022 The player selects a single card and adds it to their pool. After selecting the card, the player passes all unchosen cards to a neighboring opponent. Note that pool and deck are interchangeable-"}, {"title": "3 Contextual Preference Ranking", "content": "In this section, we introduce the main contribution of this paper. We first review the previous use of pairwise constraints for training a Siamese neural network for contextual preference ranking (Section 3.1), then briefly recapitulate CLIP and the InfoNCE loss (Section 3.2), and finally demonstrate how it can be adapted to our contextual ranking setting (Section 3.3).\n3.1 Siamese Neural Networks for Drafting\nAs shown by Bertram et al. [1], Siamese Neural Networks (SNNs) [4] can effectively be used to predict human player's decisions. In their contextual preference ranking (CPR) framework, several options are compared against each other in the context of a specific item. Concretely, CPR learns to predict a preference of one choice $c_j$ over $c_k$ in the context of C, i.e.\n$$(c_j \\succ c_k | C).$$\nIn practice, this is achieved by training an SNN with the triplet loss (Equation 3) to generate a latent embedding space of $c_j$, $c_k$, and C, in which $d(c_j, C) < d(c_k, C)$ according to some distance metric d (e.g. the Euclidian distance).\n$$L_{triplet}(a, p, n) = max(d(a, p) \u2013 d(a, n) + m, 0)$$\nCrucially, while the network is solely trained on comparisons of single choices, distances in the embedding space are transitive and we can thus compare an arbitrary amount of items, i.e.\n$$(c_j \\succ c_k | C) \\land (c_k \\succ c_l | C) \\Rightarrow (c_j \\succ c_l | C)$$\nThis enables ranking a whole set of items in a given context, thus allowing us to use the method for drafting (Section 2.2). While this is highly related to using SNNs for image recognition [9], training the SNN is more restricted here.\nGiven a dataset of images D and a labelling function $f: \\mathbb{R}^n \\rightarrow [1, C]$ one can construct numerous valid triplets $(a, p, n)$ by sampling random tuples $(x_0, x_1, x_2)$ from D where $f(x_0) = f(x_1) \\& f(x_0) \\neq f(x_2) \\& x_0 \\neq x_1$. While not allowing for completely arbitrary comparisons, e.g. if $f (x_0) \\neq f(x_1) \\neq f(x_2)$ one can construct no triplet, a well-constructed dataset will provide plenty of possible comparisons even when mining batches online, as a, p, and n are all simple images.\nFor our domain, only restricted comparisons apply. For given set of items P, the dataset is constructed by relating the human selection $c^* \\in P | C$ to all other $c_0,..., c_n \\in P$. As opposed to the previous domain, all $c_i \\& P$ can not be compared and thus do not provide valid triplets. Thus, for our work, we sample decisions of the form (C, P) with the labelling function $f : P \\times C \\rightarrow [1, 15]$, from which we can generate the triplets $(C, P[f(P, C)], c_i)$ for all $i = 1, ..., |P|$. Note that $f$ is not necessarily deterministic, i.e. separate records in the dataset can choose different cards in the exact same situation.\n3.2 InfoNCE Loss in CLIP\nThe recently popularised InfoNCE loss [10, 8] is a powerful tool for contrastive learning. This representation learning technique is based on matching pairs of different modalities, e.g. pairs of images with associated captions in CLIP. For a batch of pairs, CLIP [8] aligns all possible combinations in a square matrix with the correct pairings on the diagonal, training the text-encoder and image-encoder to maximise the cosine similarity of the diagonal and minimising all others (see Figure 1). However, this only results in perfect pairings when assuming that no other items in the batch interfere with the pairs by being more similar. Given a batch of N pairs of images I with texts T, it is assumed that, for a given similarity measure sim:\n$$\\forall i \\in [0, N] \\nexists j \\in [0, N] : sim(I_i, T_i) > sim(I_i, T_j), i \\neq j$$\nHowever, for sufficiently large batches, it is not unlikely that multiple images fit a text or vice versa. In practice, this inaccuracy is likely mitigated by the large dataset, but using the same approach for smaller datasets or ones with frequently reoccurring items might lead to performance degradation. Our domain is one such example where there are only roughly 250 different cards, which frequently results in one batch containing the same items. Therefore, it is not possible to simply minimise the cross entropy loss in both dimensions of the pair-matrix, as there will be correct pairings not on the diagonal, which means that one card can be associated with multiple decks. Some later adaptions of CLIP [16] are able to handle such settings by circumventing the softmax normalisation and cross-entropy computation by using a pairwise sigmoid loss, but we show in Section 4 that our domain possesses additional difficulties which do not allow this simple change.\n3.3 Contextual InfoNCE for Drafting"}, {"title": "4 Experiments", "content": "In this section, we compare our proposed method to previous research using the triplet loss and an unaltered version of CLIP. For the triplet approach, we use the research Bertram et al. [1], CLIP-based experiments were re-implemented by us. Although the specific implementation details are not of high importance, as we aim to equalise hyperparameters, we briefly cover implementation details in Section 4.1. For all experiments, we use the datasets provided by 17 lands. These datasets provide turn-by-turn records of human card selections when drafting. We regard these drafting decisions are preferences of one card over a set of other cards given that player's pool. Thus, we can directly generate training samples, i.e. triplets of the pool, chosen card and unchosen cards, from the dataset. While numerous datasets with different cards are available, we arbitrarily chose a single one (NEO). This dataset consists of 5,693,460 samples which we split 80/20 into training and test data.\nAll outlined training approaches aim to model the contextual card preferences by learning an embedding space in which preferred cards possess embeddings with high cosine similarity, or small distance, to the pool. The methods mainly differ by the loss function used and how the training data is processed by the networks.\n4.1 Architectures and Hyperparameters\nWhile it is not possible to entirely equalise the hyperparameters across settings, we aim to minimise the interference of parameter choice on the results. In addition, we realise that computation speed comparisons are hardware and implementation-specific. Still, we believe that our results provide useful insights into the problem setting."}, {"title": "5 Conclusion", "content": "In this research, we aim to provide a novel way to frame contextual preferences by utilising the InfoNCE loss function. For numerous domains, preferences between items depend on specific situations, thus making it impossible to compare them in a vacuum. To alleviate this, we adapt the batch construction technique from CLIP [8] to only train on preferences explicitly contained in the training data.\nWe experimentally show (Section 4.2) that this technique outperforms both unaltered CLIP, CLIP with a sigmoid loss function, and triplet loss-based models. The sigmoid-based version is the second best in our experiments, as it also alleviates a subset of the problems of standard InfoNCE, but our proposed method results in better performance. Our method adds no relevant computation time compared to the other InfoNCE methods and is thus strictly better-versed for the task at hand.\nTriplet loss-based methods had surprising differences in accuracy depending on the triplet mining technique. Random mining, i.e. randomly choosing one of the available negative examples, is unsurprisingly fastest but also leads to the best accuracy. Hard mining was assumed to lead to higher accuracy but required additional computation with a decreased accuracy. We speculate that a mix of both, e.g. first mining randomly and later in training switching to hard mining, might lead to higher accuracy, but such additional experiments are left for future work. Unsurprisingly, using all negative examples in different triplets leads to poor results, as this greatly bloats training time due to reductions in batch size. In addition, this led to a stark performance degradation.\nWhile only regarding a single domain here, collectable card games, our proposed adaptions translate to many domains. Preferences, or other metrics which be can be represented by an embedding space, often occur in specific contexts, which hinders the general capability of the InfoNCE loss. Altogether, this research forms a baseline for future work on contextual preferences, a highly relevant research question."}, {"title": "6 Future Work", "content": "While we show in this work that the InfoNCE loss can be adapted to the given problem with few changes, we speculate that overall more promising methods are possible. Masking invalid entries in the cosine similarity matrix works from a computational perspective but leads to a large number of unnecessary items. Instead, we aim to work towards an approach that explicitly adds the context of the preference to the loss computation while keeping the advantages of the InfoNCE loss."}]}