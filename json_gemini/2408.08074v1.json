{"title": "A Survey on Integrated Sensing, Communication, and Computation", "authors": ["Dingzhu Wen", "Yong Zhou", "Xiaoyang Li", "Yuanming Shi", "Kaibin Huang", "Khaled B. Letaief"], "abstract": "The forthcoming generation of wireless technology, 6G, promises a revolutionary leap beyond traditional data-centric services. It aims to usher in an era of ubiquitous intelligent services, where everything is interconnected and intelligent. This vision requires the seamless integration of three fundamental modules: Sensing for information acquisition, communication for information sharing, and computation for information process-ing and decision-making. These modules are intricately linked, especially in complex tasks such as edge learning and inference. However, the performance of these modules is interdependent, creating a resource competition for time, energy, and band-width. Existing techniques like integrated communication and computation (ICC), integrated sensing and computation (ISC), and integrated sensing and communication (ISAC) have made partial strides in addressing this challenge, but they fall short of meeting the extreme performance requirements. To overcome these limitations, it is essential to develop new techniques that comprehensively integrate sensing, communication, and compu-tation. This integrated approach, known as Integrated Sensing, Communication, and Computation (ISCC), offers a systematic perspective for enhancing task performance. This paper begins with a comprehensive survey of historic and related techniques such as ICC, ISC, and ISAC, highlighting their strengths and limitations. It then explores the state-of-the-art signal designs for ISCC, along with network resource management strategies specifically tailored for ISCC. Furthermore, this paper discusses the exciting research opportunities that lie ahead for implement-ing ISCC in future advanced networks. By embracing ISCC, we can unlock the full potential of intelligent connectivity, paving the way for groundbreaking applications and services.", "sections": [{"title": "I. INTRODUCTION", "content": "Across the boundaries of fifth-generation wireless technology (5G), the next generation of wireless communications, 6G, is expected to go far beyond conventional communications of connected people and things to connected intelligence or intel-ligence of everything [1], [2], [3], [4]. As announced by IMT-2030, three additional usage scenarios of integrated artificial intelligence (AI) and communications, integrated sensing and communication (ISAC), and ubiquitous connectivity, will be fostered in 6G, as well as three enhanced usage scenarios, i.e., immersive communication, massive communication, and hyper reliable and low-latency communication, which evolve from the scenarios of enhanced mobile broadband (eMBB), massive machine-type communication (mMTC), and ultra-reliable low-latency communication (URLLC) in 5G [5]. \u03a4\u03bf facilitate the implementation of these scenarios, higher key performance indicators (KPIs) are designed in 6G [4], [6]. For example, the user-experienced data rate should achieve 1 Gbit/s and the connection density should be 107 devices/km\u00b2.\nFig. 1 depicts the evolution of KPIs and usage scenarios.\nTo achieve these KPIs, novel theories and techniques such as electromagnetic information theory [7], semantic communications [8], edge AI [9], and near-field communications [10], are developed. Moreover, the realization of connected intelligence demands the implementation of massive intelligent applications at the network edge such as autonomous vehicles, smart cities, remote health care, and industrial automation [9]. These applications call for the fusion of physical, biological, and cyber worlds, which naturally involves three modules, including sensing the environment for obtaining information, communication between different entities for information shar-ing, and computation on devices and servers for processing the information and making intelligent decisions [11]. This gives rise to a brand-new research area called integrated sensing, communication, and computation (ISCC). In the sequel, the related partial integration technologies are first introduced, followed by the discussion of the motivations and challenges of ISCC."}, {"title": "A. Technologies of Partial Integration", "content": "1) Integrated Communication and Computation: Integrated communication and computation (ICC) refers to the joint design of communication and computation processes in tasks by allowing resource allocation between them to improve the system performance under a unified goal, such as energy/latency minimization and computation accuracy maximization. Since a dozen years ago, researchers in the wireless communication field have made efforts to develop ICC techniques at the network edge. Initially, mobile edge computing (MEC) is proposed, which aims at offloading partial or full on-device tasks to edge servers for enhancing the system performance e.g., energy efficiency and latency, via balancing the on-device communication and computation loads [12]. Building on MEC, edge AI has attracted considerable attention, which aims at conducting distributed model training and cooperative inference at the network edge to exploit the benefits of fast mobile data access, data privacy preservation, and so on [9].\nWith the rapid advancement of microchip technology (the number of computer chips doubles every 18 to 24 months according to Moore's Law), massive computing powers are deployed on cloud, edge, and devices in wireless networks. Accordingly, a new ICC paradigm called computing power networks is proposed for coordinating and scheduling the ubiquitous computing resources to accomplish computationally in-tensive tasks, such as distributed training of large models [13], [14]. Particularly, since the deployment of massive low-earth orbit (LEO) satellites is regarded as the solution for providing infrastructure-free areas with communication services [15], space computing power networks will be a promising research topic. Apart from the ICC schemes in the application layer, a physical layer technique called over-the-air computation (AirComp) has emerged in recent years [16]. It allows all transmitters to send their signals over the same wireless resource block and directly calculates a functional value of all signals at the receiver using the waveform superposition property, instead of decoding each transmitter's signal. As a result, the communication efficiency is significantly enhanced. Due to its merits, AirComp is widely adopted as an air interface technique for wireless sensory data aggregation [17], [18], [19], [20], federated edge learning [21], [22], [23], [24], and edge Al inference [25], [26], [27].\n2) Integrated Sensing and Computation: Integrated sensing and computation (ISC) refers to the joint design of sensing transceivers and the subsequent sensing echo signal processing algorithms. The development of ISC techniques is significant since the realization of connected intelligence calls for de-ploying massive sensors in the network to sense the environment [28]. In this paper, we categorize ISC technologies into three types. The first is wireless (radar) sensing, which was originally developed in the military field for detecting aircraft before World War II. By carefully designing a transmit wave-form, e.g., frequency modulation continuous wave (FMCW), and processing the corresponding echo signals with the algo-rithms of sampling, fast Fourier transform (FFT), correlation calculation, filtering, etc., the distance and velocity of the target can be detected [29]. Other waveforms such as orthog-onal frequency division multiplexing (OFDM) waves, novel techniques like multiple antennas, and new frequency bands such as millimeter wave bands, can be used for enhancing the detection performance [29]. In addition, the utilization of wireless sensory data to train AI models for supporting various intelligent tasks such as human motion recognition and natural scene analysis, has become a research trend [29]. However, a single modality of wireless sensing is not able to obtain sufficient information for complicated intelligent tasks [30]. To this end, multi-modal sensing (including radar, camera, microphone, etc.) technology is developed. Benefiting from the rapid development of AI, machine learning algorithms are generally used for multi-modal sensory data processing, including representation, translation, alignment, and fusion [31], [32]. Moreover, mobile devices equipped with several types of sensors such as accelerometers, GPS, cameras, and microphones, have experienced exponential growth in the last several decades. This leads to a new paradigm called mobile crowdsensing, which collects massive and multi-domain sen-sory data from mobile devices for providing intelligent and people-centric services [33].\n3) Integrated Sensing and Communication: ISAC jointly designs the sensing and communication modules in the system, which saves hardware space and improves resource utiliza-tion by sharing hardware (e.g., transceivers) and network resources (e.g., time, spectrum, and energy), as well as making sensing and communication serve as each other's supporting techniques to enhance their respective performance, so-called sensing for communication and communication for sensing."}, {"title": "B. Motivations and Challenges of ISCC", "content": "1) Motivations: Future wireless networks are expected to complete complicated tasks to provide intelligent services such as smart cities, auto-driving, virtual/augmented reality, and smart manufacturing [1], [2]. These tasks generally in-volve three modules, i.e., information perception (sensing), information transmission (communication), and information processing for intelligent decision-making (computation) [11], [39], [40]. Existing techniques, i.e., ISC, ICC, and ISAC as mentioned before, make efforts to support a part of intelligent tasks with loose performance requirements. However, they fail to achieve the extreme performance demands of real-time intelligent tasks, like ultra-high decision accuracy and ultra-low latency. Specifically, They have the following three shortages.\n\u2022 Low Resource Utilization: In existing designs, network resources are shared and coordinated between only two of the sensing, communication, and computation modules, leading to low resource utilization.\n\u2022 Mismatch between Goals of the Overall Task and Each Module: In existing designs, different modules are de-signed under separate design goals, e.g., sensing for obtaining high-quality sensory data, communication for throughput maximization, and computation for low en-ergy cost and low latency. However, enhancing these goals is not necessarily beneficial or sometimes even harmful to the overall goal of the task [41]. For example, the transmission of unimportant data, like gradient vectors with zero values in federated learning tasks [42] and uninformative samples in active learning tasks [43], [44], consumes system resources (e.g., time, bandwidth, and energy) but makes little contribution to the task.\n\u2022 Ignoring the Tight Coupling of Different Modules: The sensing, communication, and computation modules are highly coupled in many tasks. For example, an online federated learning task involves sensing for data sample acquisition, on-device computation for local updating, and communication for local model uploading. The three modules compete for network resources (e.g., time and energy) but the convergence performance depends on the number of and the signal-to-noise ratio (SNR) of sensory data samples, the on-device computation speed, and the communication capacity in each round. Existing techniques ignore this tight coupling and design opti-mization algorithms from a partial perspective, leading to performance degradation.\nTo overcome the above shortages, ISCC is demanded.\n2) Challenges: Although ISCC design can achieve a higher performance ceiling, it encounters new challenges, as elabo-rated in the following.\n\u2022 Inference Management: In the case of the coexistence of multiple waveforms (e.g., sensing, communication, and AirComp signals), interference should be carefully managed to guarantee the quality of each module.\n\u2022 High Signal Design Complexity: In the case of reusing one waveform to perform dual functional of sensing and communication (see, e.g., [45]) or triple functional of sensing, communication, and computation (see, e.g., [46]), low-complexity signal processing techniques are demanded.\n\u2022 Complicated Resource Management: The radio resource management (RRM) from a systematic view to jointly coordinate the sensing, communication, and computation modules is much more complicated, due to the tight coupling among them and the enlarged problem size [47].\n\u2022 Lack of Unified Design Criteria: Different from the existing communication systems with a common design goal (e.g., channel capacity and SNR), there is a lack of a unified design criterion for intelligent tasks with customized goals. For example, federated learning tasks aim to achieve several goals of high testing accuracy, minimum convergence latency, data privacy, least energy consumption on devices, etc. (see, e.g., [48], [49]). This task-oriented property leads to a new challenge of finding suitable mathematical expressions to model the ISCC problem.\nTo this end, this paper will present state-of-the-art ISCC techniques to address the above challenges."}, {"title": "C. Organization", "content": "The rest of the paper is organized as follows. We first conduct a comprehensive survey in terms of the partial integration technologies, i.e., ICC, ISC, and ISAC in Sections II, III, IV, respectively. Then, signal designs and RRM techniques for ISCC are discussed in Sections V and VI respectively. In Section VII, the research opportunities of implementing ISCC in future advanced networks, i.e., digital-twin-enabled networks, computing power networks, and space-air-ground integrated networks (SAGINs), are introduced. Finally, Section VIII concludes the paper. The detailed contents are listed below and are shown in Table I.\n\u2022 Section II conducts a detailed survey of two ICC technologies, i.e., MEC and AirComp.\n\u2022 Three kinds of ISC technologies, i.e., wireless (radar) sensing, multi-modal sensing, and mobile crowdsensing, are discussed in Section III.\n\u2022 In Section IV, a comprehensive investigation of ISAC is provided, including integrated wireless/multi-modal/crowd-sensing and communication techniques.\n\u2022 Section V introduces three types of signal designs for ISCC, i.e., single-/dual-/triple-functional signal designs. Particularly, triple-functional signal design refers to using one signal to perform three functions of sensing, commu-nication, and computation.\n\u2022 In Section VI, the network resource management paradigms for ISCC are discussed. One is joint RRM for task coexistence, which refers to resource allocation among different tasks of sensing, communication, and computation to achieve multiple goals simultaneously. The other is task-oriented ISCC resource allocation, which refers to allocating network resources among the sensing, communication, and computation modules of a task to achieve its customized goal.\n\u2022 The implementation of ISCC in future advanced networks is investigated in Section VII, including ISCC for digital twin enabled wireless networks, computing power net-works supported ISCC, SAGINs supported ISCC.\n\u2022 Section VIII concludes the paper."}, {"title": "II. INTEGRATED COMMUNICATION AND COMPUTATION", "content": "Emerging intelligent services over wireless networks often encompass both communication and computation processes. In conventional wireless networks, the communication and computation processes are separately designed. For instance, service tasks are typically executed at a central server with high computing and storage capabilities, where the central server first collects the data from geographically dispersed devices for task-related computation and then feeds back the computation results to corresponding devices for fulfilling the service requirements. With the proliferation of wirelessly connected devices, the communication burden of bandwidth-limited wireless networks significantly increases and the com-putation burden of the central server is also augmented due to massive volumes of data to be processed, making it inefficient to handle diverse service requirements in a centralized man-ner. Such a separate design ignores the inherent connection between the transmitted data and subsequent service tasks, leading to inefficient resource utilization and in turn degrading the system performance.\nBy treating the communication and computation processes as a unified module, ICC emerges as a promising technique to enhance the system performance, where the allocation of com-munication and computation resources are jointly optimized to achieve a common objective, e.g., energy/delay minimization and computation accuracy maximization, thereby making full use of limited resources to improve the system performance. In this section, we provide an overview of the existing studies on ICC, focusing on the efficient design of joint communica-tion and computation, which is illustrated by presenting two promising examples, e.g., MEC and AirComp, as shown in Fig. 2 and listed below.\n\u2022 Mobile Edge Computing: MEC intends to move the data transmission and processing operations to the network edge by exploiting the computing power and storage capabilities of edge servers and distributed devices, while the communication resources can be utilized to exchange for the computation resources via task offloading, thereby enabling ICC with joint communication and computation resource allocation.\n\u2022 Over-the-Air Computation: AirComp aims at efficiently computing a target function by exploiting the co-channel interference, where the simultaneously transmitted signals can be naturally added over the air to realize a function computation during the communication process, thereby achieving ICC by exploiting the waveform superposition of concurrently transmitted signals."}, {"title": "B. Mobile Edge Computing", "content": "In the past few years, computation tasks over wireless networks have been typically accomplished by resorting to cloud computing, which requires the large amount of data generated by devices to be collected and transmitted to a cen-tralized server with high storage and computing capabilities, so as to perform data analysis and computation for meeting various requirements of different devices. However, with the rapid development of Internet of Things (IoT), the number of connected devices dramatically increases, leading to a severe communication burden of the wireless network and high computing pressure of the central server. Therefore, due to limited radio resources, cloud computing is no longer suitable for latency-sensitive services with massive connectivities in future wireless networks. To address the above issues, MEC is emerging as a new computing paradigm thanks to the advancement of microchip computing power, which enables the edge server and mobile devices to execute computing tasks with their own computing and storage capabilities at the network edge [12].\nA typical MEC system consists of edge servers and mobile devices, where edge servers are generally co-located with access points (APs) and deployed in proximity to mobile devices. Herein, the mobile devices are allowed to offload the computational tasks to edge servers for executing the tasks with high computing pressure and low latency require-ments. To unleash the potential of MEC, numerous studies have explored task offloading design in MEC systems with single/multiple edge server(s) and multiple users. Specifically, the system design of MEC lies in the following aspects."}, {"title": "Joint Resource Allocation:", "content": "Even though the edge servers are capable of providing strong computing power to fulfill various service requirements for different devices, they still confront high computation and communication bur-dens when there are massive tasks from multiple devices that need to be accomplished due to the limited radio and computing resources of the MEC system. To overcome the above challenge, joint communication and compu-tation resource allocation is required to enhance the system performance in terms of different objectives, e.g., execution delay and energy consumption. For instance, the authors in [50] propose a task offloading framework for MEC in software-defined ultra-dense networks, where the task placement and resource allocation are jointly optimized to minimize the average task duration under the given battery energy capacity of each device. Besides, the authors in [92] develop a SAGIN-assisted MEC for computing offloading in remote areas lacking conven-tional edge/cloud infrastructure, where a learning-based joint resource allocation and task scheduling approach is proposed to reduce the execution delay. To mitigate the overhead for collecting the global information to enable centralized system design, the authors in [93] propose an efficient decentralized algorithm for the task offloading in a dense wireless network with selfish mobile devices. By using game-theoretical analysis, they prove the existence of pure strategy Nash equilibria and the computation costs, i.e., the weighted sum of delay and energy consumption, of different devices can be balanced."}, {"title": "Task Scheduling:", "content": "In real-world applications, tasks are not only delay-sensitive and computation-intensive but also dependent on each other, which demands sequential task processing. During such a procedure, the output of one task serves as the input for the next one, which is required to be continued until all associated tasks are completed, thereby finishing the entire task. Therefore, the above issue makes it critical to schedule the offloading of such interdependent tasks in MEC systems, so as to ensure efficient and effective application performance. To this end, the authors in [51] investigate the task offloading scheme for multiple interdependent computation tasks in MEC systems, where the interdependent tasks are mod-eled as a directed acyclic graph. They formulate a mixed-integer nonlinear programming problem, and propose the highest response ratio and optimization method to implement joint scheduling and offloading design, which effectively reduces the average completion time in MEC systems with interdependent tasks. Furthermore, instead of assuming all requested tasks can be completed, the authors in [94] explore the task scheduling by taking into account the impact of interdependency among different tasks on the system reliability, where a multi-priority task sequencing algorithm and a deep deterministic pol-icy gradient-based learning algorithm are developed to minimize the system deadline violation ratio."}, {"title": "Cooperative Computing:", "content": "The mobile devices in MEC systems generally offload their computation-intensive tasks to edge servers for low-latency task execution while reducing communication overhead. Nevertheless, edge servers may become unavailable due to factors such as limited coverage area and exhausted computing re-sources, resulting in new tasks offloaded by devices not being processed instantly or failing directly. To address the above challenge, multi-user cooperative computing emerges as a promising solution to enhance the reliability of MEC systems by alleviating edge server overload and exploiting computing resources distributed among mobile devices. For instance, the authors in [52] propose a device-to-device (D2D)-assisted co-offloading framework for industrial IoT, and an efficient learning-based algo-rithm is developed to minimize the weighted sum of task delay and migration cost without the need of complete offloading information. To minimize the average delay under time-varying idle resources and channel conditions, the authors in [95] develop an online joint optimization for the task partitioning and parallel scheduling in a D2D-enabled MEC system, which achieves near-optimal delay performance with low computational complexity while ensuring fairness across various system states. In addition, the authors in [96] introduce a distributed multi-hop task offloading decision model for Internet of Vehicles (IoV) networks, where the peripheral vehicles with idle computing resources can be exploited to improve the task execution efficiency in dynamic vehicular environments."}, {"title": "C. Over-the-Air Computation", "content": "In traditional communication protocols, the signals among different devices over the same channel are deemed as co-channel interference, thus each of them demands individual and accurate reception at the receiver before the subsequent processing. In the face of emerging intelligent services, achiev-ing functional computation of gathered data becomes the key to implementing the corresponding applications, e.g., environmental monitoring and autonomous driving, while the accuracy and timeliness of such computation determine the quality of service. In this sense, the conventional compute-after-communicate strategy may become inefficient in a large-scale network with scarce resources due to the separation of communication and computation. With this in mind, Air-Comp has attracted much attention to pursuing the fusion of communication and computation by harnessing the co-channel interference [97], [98], [99].\nSeeking to integrate communication and computation, Air-Comp regards the co-channel waveform superposition as a summation operation for synchronized concurrently trans-mitted signals, enabling compute-when-communicate manner that allows the target function to be computed during the transmission process without need for one-by-one decoding at the receiver. As all devices are required to occupy the same channel to enforce the computation for the target func-tion, the number of radio resources utilized by AirComp is unrelated to the number of participating devices, thereby yielding a much higher spectral efficiency than conventional orthogonal multiple-access (OMA) approaches that allocate separated channels to each device. Meanwhile, compared with the non-orthogonal multiple-access (NOMA) scheme counter-parts, AirComp avoids the complex design for interference cancellation and saves the time for recovering each signal in terms of the functional computation at the cost of acceptable computation errors.\nBy implementing appropriate pre- and post-processing on transmit and receive signals, respectively, AirComp enables the receiver to compute a class of functions, namely nomographic function [100], which is defined as \\(f(x_1,x_2,...,x_K) = \\psi(\\sum_{k=1}^{K}\\phi_k(x_k))\\), where \\(\\psi(\\cdot)\\) denotes the post-processing function at the receiver and \\(\\phi_k(\\cdot)\\) denotes the pre-processing function for data \\(x_k \\in \\mathbb{R}\\) at device k, \\(\\forall k \\in \\{1,2,..., K\\}\\). Following the expression given in the above, AirComp can be decomposed into three stages [16]: 1) transmit data pre-processing at each device; 2) summation of pre-processed data through the waveform superposition property of multiple-access channels; and 3) receive data post-processing at the access point (AP). Note that, although the signal superposition can only realize the operation of summation, AirComp is ca-pable of computing non-linear functions [101], e.g., geometric mean and Euclidean norm, and even computing any continuous function by assembling multiple nomographic computation results [100].\nDuring the wireless propagation, the synchronized signals are performed with a weighted summation with respect to the channel coefficients, which may lead to a non-desired computation result. Accordingly, the transceiver design is nec-essary for AirComp to induce an expected signal superposition over non-uniform fading channels. Recently, many efforts have been made to induce signal alignment under different objectives for AirComp.\n\u2022 Data Fusion: Data fusion is the fundamental objective of AirComp and much of the underlying research has been conducted from this aspect [102]. For instance, the authors in [19] reveal the optimal transceiver design for AirComp under peak power constraints to minimize the distortion of data fusion in single-input single-output (SISO) networks. Meanwhile, the optimal design under sum-power constraint is obtained in [103] with closed-form solutions. By exploiting multi-antenna techniques, the authors in [16], [104], [105] develop beamform-ing design for AirComp and validate the performance improvement that can be achieved via diversity gain and multiplexing gain of multi-antenna arrays to reduce fusion error [104] and realize multi-modal fusion [16], [105], respectively.\n\u2022 Distributed Consensus: Distributed consensus expects all devices in the network to reach a consensus on a certain message without the assistance of a central node, which can be accelerated by AirComp with its efficient data aggregation. For instance, the authors in [53] show that multiple simultaneous average operations achieved by AirComp can accelerate the convergence rate of gossip-based consensus. In addition, the authors in [106] pro-pose beamforming design for decentralized AirComp to accelerate the distributed consensus.\n\u2022 Model aggregation: Federated learning (FL) has attracted much attention in machine learning areas due to its distributed computing structure and privacy-preservation property [54]. Although transmitting model parameters reduce the communication overhead by a significant amount compared to transmitting raw data, scarce com-munication resources still limit the communication ef-ficiency in wireless FL systems, which motivates the emergence of AirComp-based FL [21], [22], [107], [108]. The authors in [21] demonstrate that AirComp-based FL achieves much lower communication latency than the OFDMA-based scheme. To ensure accurate model aggregation, the authors in [22], [21], [109] develop device scheduling methods. Moreover, compression and sparsification approaches are leveraged in [110] to fur-ther reduce the communication overhead in resource-constrained wireless networks."}, {"title": "III. INTEGRATED SENSING AND COMPUTATION", "content": "In this section, we provide a comprehensive survey about the technologies for both sensing signals acquisition and the corresponding processing methods for completing sensing tasks, giving its name ISC. As shown in Fig. 3, there are three ISC technologies. The first one is wireless sensing (also called radar sensing) technology, which senses a target by re-ceiving and processing the echo signal of a carefully designed waveform. Yet, information obtained from a single modality of sensing signals may not be sufficient for completing com-plicated tasks [111]. It is mathematically shown in [30] that collecting multi-modal sensory data can provide better sensing performance. Therefore, the second ISC technology of multi-modal sensing is developed. Moreover, although multi-modal sensing technology can enjoy many benefits of rich infor-mation, high robustness, cross-modality data transformation, it requires deploying dedicated sensors, which is expensive. To empower ubiquitous sensing in a large coverage with low cost, the third ISC technology called mobile crowdsensing, is proposed [33]. It utilizes built-in sensors of ubiquitous mobile devices for collecting sensory data in various domains. In the sequel, the above three ISC technologies are discussed."}, {"title": "B. Wireless Sensing Technology", "content": "Wireless sensing, which is also called radar sensing, emits modulated radio waves, receives and processes the correspond-ing echo signals to complete computation tasks such as object ranging and detection, and motion recognition. Its application can be traced back to the usage of radar in the early 20th century. Because of its significant military value, radar ushered tremendous development during World War II and turned to be a key technique for empowering many major and intelligent applications, including military surveillance, remote sensing in space, and auto-driving. Based on the original continuous-wave radar, new techniques in terms of wave-form design, signal processing, and system architecture are developed to enhance its abilities regarding velocity, distance, direction, and sensitivity toward motions. In this part, the development of radar system design and the corresponding signal processing are introduced.\n1) Radar Waveform Design and Signal Processing: Aiming at achieving higher accuracy of the ranging and detection results, one key advancement of radar techniques is the de-velopment of waveform design and the corresponding signal processing approaches [55]. In this part, we will introduce the evolution of the waveform design from the initial continuous wave to the state-of-the-art designs.\n\u2022 Traditional Continuous-wave Radar: As its name sug-gests, traditional continuous-wave radar continuously transmits a waveform with a stable frequency and re-ceives an echo signal from one or more targets. To detect the Doppler shift of the received echo signal, a conjugate mixing method is utilized. To be specific, both the transmit signal and the echo signal are sampled with a time interval T and then transformed into the frequency domain using fast Fourier transform (FFT). By calculating the cross-correlation of the two signals and applying a low-pass filter, the frequency difference of the two signals, i.e., the Doppler frequency shift (DFS), can be extracted. Based on the DFS, the velocity can be estimated. The resolution (or the detection error) of the velocity is proportional to the sampling rate \\(\\frac{1}{T}\\). However, the measurement of range information i.e., distance of the target which is decided by light speed and the round-trip delay, is not available with continuous waveform. The reason is that the round-trip delay is detected by the phase shift of the echo signal, which is ambiguous to the receiver due to the lack of phase basis. That's to say, we cannot distinguish the phase shifts \\(\\theta\\) and \\((\\theta + 2k\\pi)\\) with k being any integers.\n\u2022 Pulsed Wave Radar: To obtain the range information, the pulsed radar is developed, where the transmit waveform is generated by modulating a single-frequency signal by a periodic window signal with period T. That's to say, the transmitter periodically produces a brief pulse of radio signal and keeps silent to receive the echo signal of the detected object. The interval between two consecutive pulses is called the inter-pulse period (IPP). The range information is detected by processing the echo signal within one transmission period, called fast-time processing. Specifically, with the time basis of the transmit signal, the exact phase shift of the two signals can be detected using their correlation in the frequency domain. Subsequently, the round-trip delay is calculated and is further used to compute the distance. It should be emphasized that IPP should be larger than the round-trip delay to make sure the echo signal of one pulse can be correctly received. The resolution of rang information is proportional to the pulse transmission period T. The velocity is detected using multiple pulses, called slow-time processing. With a fixed velocity, the DFS of each signal in several consecutive pulse waveforms is a single-frequency signal. Hence, by calculating the correlation of the echo signal and the transmit signal over a long time scale (i.e., over multiple transmission periods) in the frequency domain, the DFS is detected and the corresponding velocity can be calculated. The resolution of the detected DFS or velocity is proportional to 1/T. Note that there is a tradeoff between the resolutions of range and velocity information.\n\u2022 Frequency Modulated Continuous Wave (FMCW) Radar: The time efficiency of pulsed wave radar is relatively low due to the intermittent transmission. To this end, an advanced FMCW radar is developed. The sensing signal is decomposed of multiple repeated snapshots. In each snapshot, a continuous waveform is transmitted with the frequency modulated as a linear function of time. Although transmitting and receiving work simultaneously, no interference is caused as they have different frequen-cies. Similar to pulsed radar, the range information is detected via fast-time processing, and the velocity is detected by slow-time processing using M snapshots, but the time efficiency of FMCW is higher compared to pulsed radar due to continuous transmission. The resolutions of range and velocity are proportional to the snapshot duration and the number of used snapshots M, respectively."}, {"title": "C. Multi-modal Sensing Technology", "content": "A sensory modality refers to the way one entity is ob-served or perceived", "30": ".", "31": "."}, {"31": ".", "111": "such as using a text to generate a high-resolution image. To enjoy the above advantages and based on the fact that data in the real world have multiple modalities"}, {"31": [111], "136": ".", "Learning": "As stated in [31", "32": "there are five key issues to be addressed in the area of multi-modal machine learning", "Representation": "Representation is the information dis-tilled from the data that intelligent systems can use [137"}, {"31": ".", "137": "feature detection [138", "139": ".", "66": "pointed out that a good multi-modal representation should satisfy the following novel requirements: 1) Similarity in representation should lead to the same similarity in the corresponding results; 2) Multi-modal representation should be readily obtained even in the absence of certain modalities; 3) Missing modalities can be generated using other observed ones. As a result"}, {"31": [32]}, {"31": ".", "67": [140], "141": "and probabilistic graphical models like deep Boltzmann machines are adopted to deal with the issue of missing modality via using their generative nature [66", "142": ".", "Translation": "Multi-modal translation refers to the ability of modality transfer i.e."}, {"31": ".", "approach": "In this approach, a dic-tionary is constructed using the training data sam-ples. For each entity, the source modality and target modality of one entity are stored in the dictionary with one-to-one correspondence [31"}]}