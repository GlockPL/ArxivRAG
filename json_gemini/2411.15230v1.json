{"title": "A No Free Lunch Theorem for Human-AI Collaboration", "authors": ["Kenny Peng", "Nikhil Garg", "Jon Kleinberg"], "abstract": "The gold standard in human-AI collaboration is complementarity when combined perfor-mance exceeds both the human and algorithm alone. We investigate this challenge in binaryclassification settings where the goal is to maximize 0-1 accuracy. Given two or more agents whocan make calibrated probabilistic predictions, we show a \"No Free Lunch\"-style result. Anydeterministic collaboration strategy (a function mapping calibrated probabilities into binaryclassifications) that does not essentially always defer to the same agent will sometimes performworse than the least accurate agent. In other words, complementarity cannot be achieved \"forfree.\" The result does suggest one model of collaboration with guarantees, where one agentidentifies \"obvious\" errors of the other agent. We also use the result to understand the neces-sary conditions enabling the success of other collaboration techniques, providing guidance tohuman-AI collaboration.", "sections": [{"title": "1 Introduction", "content": "Many important decisions depend-in large part on prediction. Doctors decide if a patient shouldundergo a procedure by predicting if the operation will succeed. Judges decide whether or not togrant bail by predicting if the defendant will reoffend. Loan officials decide whether or not to offera loan by predicting if the loan will be repaid. In all of these tasks, algorithmic predictions arenow commonly incorporated into the decision-making process. Still, humans remain a central partof each of these settings, and often have the final say. The hope of human-AI collaboration is thata human and an algorithm can leverage their unique strengths to make predictions that are moreaccurate than either alone. This standard has been called complementarity.\nThe present work investigates the conditions under which complementarity can be guaranteedwhen making binary classifications, where the goal is to maximize 0-1 accuracy (minimize the num-ber of misclassifications). We consider a setup in which two or more agents can make calibratedprobabilistic predictions on a shared task. These predictions may differ-for example, due to differ-ences in the information available to each agent. Each agent can use their probabilistic predictionsto make binary classifications, each achieving some level of accuracy. We ask: Is there a way tocombine each agent's calibrated predictions to produce binary classifications that are guaranteed tobe at least as accurate, and sometimes more accurate, than every individual agent? In other words,if agents are calibrated, can we achieve complementarity \"for free\"?"}, {"title": "2 A No Free Lunch Theorem", "content": "A binary classification problem can be represented as a distribution $\\mathcal{D}$ over $\\mathcal{X} \\times \\{0,1\\}$ where $\\mathcal{X}$ isthe input space. A classifier is a function $Y : \\mathcal{X} \\rightarrow \\{0,1\\}$. The 0-1 accuracy of a classifier isgiven by\n$\\mathbb{E}_{(\\mathcal{X},Y)\\sim \\mathcal{D}}[|Y(X) - Y|].$\n(1)"}, {"title": "3 Implications for Human-AI Collaboration", "content": "In this section, we use Theorem 1 to better understand the conditions that enable effective human-AI collaboration. We begin by discussing numerous settings in ML, human-AI collaboration, andbeyond, in which collaboration has been shown to be possible (often, with guarantees). We thenidentify two common features of these \"success stories\" -features which are not present in thesetup of Theorem 1. We then argue that common implementations of human-AI collaboration alsolack these features, and suggest a path forward. Like Wolpert and Macready's \"No Free LunchTheorem,\" a primary use of Theorem 1 is in clarifying the additional structure needed to ensuresuccessful prediction."}, {"title": "3.1 Successful Collaborations", "content": "There are many lines of work that are fundamentally about collaboration in classification tasks, eachof which unlike us obtain positive results. For example, the machine learning literature is ripewith such results. Combining expert predictions is a basic problem in online learning theory (seefor an overview). There, it has been shown, for example, that expert predictions canbe combined to perform better than the best linear combination of experts .The idea of mixing expert predictions is also seen in the literature on ensemble classifiers, includingboosting methods and random forests. Pivoting, Condorcet's jury theorem provides a collaboration-based view of voting theory: when individual jurors are biased towards thecorrect decision, the majority vote is more accurate than individual votes. Finally, recent work onhuman-AI collaboration has presented numerous approaches to achieving complementarity . Why do each these methods work, and whydo they have guarantees? We suggest two distinct features behind these successful collaborations."}, {"title": "Leveraging Independence: Condorcet's Jury Theorem, Wisdom of Crowds, RandomForests.", "content": "Condorcet's jury theorem states that when individual jurors arebiased towards the correct decision (i.e., vote in that direction independently with probability$p > \\frac{1}{2}$), the majority vote is more accurate than any individual vote. Indeed, the idea of aggregat-ing independent signals appears in a much broader literature studying information aggregation andthe \"wisdom of crowds.\" A key distinction between Theorem 1 and these settings is a lack of\"independence\" in our setting; agents need not make predictions \"independently\" in our setup.This also appears to be the key distinction between our setting and that of majority vote ensembleclassifiers in ML such as random forests, which rely on some amount of independence in howdecision trees are constructed . Independence cannot be guaranteed in human-AIcollaboration in this way."}, {"title": "Leveraging Learning: Experts, Boosting.", "content": "Theorem 1 contrasts with the longstanding ma-chine literature in machine learning that shows how multiple \"expert\" predictions can be effectivelycombined. In fact, the idea of combining expert advice has formed a fruitful baselineintuition for how to build effective ML algorithms more broadly, such as in boosting . A crucial aspect of these methods is the process of learning which experts to trust, and whenand how much to trust them. (Note that while both random forests and boosting are consideredensemble methods-methods that combine predictions-the former relies on independence of pre-dictions and the latter on learning joint behavior.) This learning process is absent in the setup ofTheorem 1. While agents have strong information about their own predictions (calibration), theydo not know direct information about joint behavior."}, {"title": "3.2Human-AI Collaboration", "content": "We have described two general approaches to ensuring effective collaboration: independence andlearning. Since we cannot generally ensure that a human and algorithm produce independentestimates, we focus on the potential of the latter approach.\nLearning enables collaboration by understanding the joint behavior of agents. Theorem 1 itselfillustrates this point in one setting: when an agent is entirely certain in their prediction. In sucha setting, the relevant \"joint\" information is fully understood: regardless of what the other agentspredict, it is safe to defer to the agent. This connects more generally to recent work showingthat complementarity is achievable exactly when there are subsets of the domain in which eachagent has an advantage. The approach of \"overriding only when an agentis certain\" can be viewed in this framing, in which there is a designated region in which one agenthas a clear advantage (due to their full certainty), but otherwise, the other agent is deferred to.However, as Theorem 1 implies, the regions in which each agent has an advantage cannot in generalbe determined a priori from only their predictions in each region (even if calibrated probabilitiesintuitively give a measure of effectiveness). Thus, implementations of such collaboration modelsmust reason more directly with whether or not one agent is more equipped to handle a given subsetof the feature space. One way in which to do this is by performing additional training using jointinformation. Indeed, idea has been taken up by \"learning to defer\" approaches (e.g., et al.. Similarly, introduce a method to identify subsets ofinputs that are indistinguishable to an agent, in which case signal from the prediction of the otheragent can then be leveraged to improve predictions overall. These approaches require data fromthe joint distribution of agent predictions and outcomes. Theorem 1 suggests that such data is"}, {"title": "4 Proof of Theorem 1", "content": "Before proceeding to the proof of Theorem 1, we begin by establishing some basic language andtools with which to analyze and construct collaboration settings."}, {"title": "4.1 Preliminaries", "content": "Correctness and Agreement. We first introduce basic language to describe the performanceof agents and collaboration strategies.\nDefinition 5. For a collaboration setting $(\\mathcal{D}, P_1,\\ldots, P_n)$ and $x \\in \\mathcal{X}$, we say that\n$\\mathbb{E}_{(\\mathcal{X},Y)\\sim \\mathcal{D}}[\\mathcal{P}r[Y = 1| X = x]]$ $\\mathbb{E}_{(\\mathcal{X},Y)\\sim \\mathcal{D}}[\\mathcal{P}r[Y = 1| X = x]]$\nY_i(x) \\neq \\hat{Y}_j(x).\nFor each of these statements, we can replace i or j with a collaboration strategy C.\nFor example, if $\\mathbb{P}r_{(\\mathcal{X},Y)\\sim \\mathcal{D}}[Y = 1|X = x] = 0.75$, then i is correct on x if and only if $\\hat{Y}_i(x) = 1$.(This is the correct classification to maximize 0-1 accuracy.) Using the language established inDefinition 5, we can make some simple observations about accuracies. For example, if i is correcton x whenever j is correct on x, this implies that acci(S) > accj(S). If there furthermore is somex for which i is correct but j is incorrect, and where $\\mathcal{P}r_{(\\mathcal{X},Y)\\sim \\mathcal{D}}[X = x] \\neq 0$, this implies thatacci(S) > accj(S).\nCombining collaboration settings. Having established some basic language with which todescribe and analyze the performance of experts and collaboration strategies on a collaborationsetting, we now establish a basic tool for constructing collaboration settings \"piece by piece.\"\nProposition 6. Linear combinations of settings. Consider l collaboration settings $S_1,\\ldots, S_\\ell$.Then for all $(\\lambda_1,\\cdots, \\lambda_\\ell) \\in \\Delta^\\ell$, there exists a collaboration setting S such that\n$\\text{acci}(S) = \\sum_{m=1}^\\ell \\lambda_m \\text{acci}(S_m)$\n(7)\n$\\text{accc} (S) = \\sum_{m=1}^\\ell \\lambda_m \\text{accc}(S_m)$\n(8)"}, {"title": "4.2 Main Proof", "content": "In the remainder of this section, we prove Theorem 1 in full. We first rewrite Theorem 1 in anequivalent formulation.\nTheorem 1. For a collaboration strategy C, accc(S) > mini\u2208[n] acci(S) for all collaboration settingsS if and only if there exists k \u2208 [n] and \u03b1 \u2208 {0,1} such that for all $(p_1,p_2,\\ldots,p_n) \\in (0,1)^n$:\n$\\text{C}(p_1, p_2,\\ldots,p_n) = \\alpha.$\n(17)\nProof. We first establish a collaboration setting $S_1 = (\\mathcal{D}, A_1, \\ldots, A_n)$ such that accc($S_1$) =acck($S_1$) and accc($S_1$) < acci($S_1$) for all $i \\neq k$. Set $\\mathcal{X} = \\{0,1\\}$ and choose $\\mathcal{D}$ where\n\n\nwhere $\\epsilon < \\frac{1}{6}$. Now set $A_k = \\{\\{0,1\\}\\}\\text{ and } A_i = \\{\\{0\\}, \\{1\\}\\}$ for all $i \\neq k$. Then $\\mathcal{P}_k(0) = \\mathcal{P}_k(1) = \\frac{1}{2}$,while $\\mathcal{P}_i(0) = \\epsilon \\text{ and } \\mathcal{P}_i(1) = 1 - \\epsilon \\text{ for } i \\neq k$. Then $\\hat{Y}_C(0) = \\hat{Y}_k(0) \\text{ and } \\hat{Y}_C(1) = \\hat{Y}_k(1) \\text{ since }((P_1(0), \\ldots, P_n(0)), (P_1(1),\\ldots, P_n(1)) \\in (0,1)^n\\text{ . Then observe that acck}(S_1) = \\text{ accc}(S_1) = \\frac{1}{2} $(since C always defers to agent k's classification) and $\\text{acci}(S_1) = 1 - \\epsilon$ for $i \\neq k$. For $\\epsilon < \\frac{1}{6}$,$\n$\\text{Then, for all }\\lambda < 1, \\text{ since acck}(S_1) = \\text{ accc}(S_1) \\text{ and acck} (S_2) > \\text{ accc}(S_2), \\text{ we have that acck}(S) >\\\\text{accc}(S). Now, since acci}(S_1) > \\text{accc}(S_1), \\text{ regardless of acci}(S_2), \\text{accc}(S_2), \\text{ by taking }\\lambda \\text{ sufficientlyclose to }1, \\text{ acci}(S) > \\text{accc}(S). \\text{ This provides the desired contradiction.}$$\nFinally, recall that Theorem 1 follows directly from sequentially applying Propositions 7 and 9."}, {"title": "5 Conclusion", "content": "In this paper, we proved a \"No Free Lunch\"-style result in human-AI collaboration. In particular,in a classification setting with multiple calibrated agents, we showed that any collaboration strategythat is guaranteed to perform no worse than the least accurate agent must essentially always deferto the same agent. The result does, however, imply one successful collaboration strategy: deferringto the same agent except when another agent is fully certain in their prediction. More broadly,Theorem 1 suggests that strong individual information (calibration) is not sufficient to enablecollaboration; rather, successful collaboration hinges on learning joint information across agents.\nOpen Problems. The present result suggests a number of problems for future work. In thebinary setting, it is not clear from the proof of Theorem 1 whether or not complementarity canbe achieved for loss functions beyond 0-1 accuracy. For example, the baseline of reliability can beguaranteed under 12 loss by simply predicting the average probability of agents. Moreover, thepresent result places no restrictions on the distribution over X \u00d7 {0,1}. In the spirit of the No FreeLunch Theorem, it would be interesting to consider what restrictions on this distribution enablecollaboration strategies (and what those collaboration strategies are). Finally, Theorem 1 does notobviously extend to multi-class classification problems. Multi-class problems further opens up thepossibility of collaboration strategies that succeed in set prediction"}]}