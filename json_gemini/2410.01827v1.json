{"title": "Analysis of Convolutional Neural Network-based Image Classifications: A Multi-Featured Application for Rice Leaf Disease Prediction and Recommendations for Farmers", "authors": ["Biplov Paneru", "Bishwash Paneru", "Krishna Bikram Shah"], "abstract": "This study presents a novel method for improving rice disease classification using 8 different convolutional neural network (CNN) algorithms, which will further the field of precision agriculture. A thorough investigation of deep learning methods is carried out using the UCI dataset in order to create a reliable and effective model that can correctly identify a range of rice diseases. The suggested transfer learning models perform better at identifying subtle features and complex patterns in the dataset, which results in extremely accurate disease classification. Moreover, the study goes beyond the creation of models by incorporating an intuitive Tkinter-based application that offers farmers a feature-rich interface. With the help of this cutting-edge application, farmers will be able to make timely and well-informed decisions by enabling real-time disease prediction and providing personalized recommendations. Together with the user-friendly Tkinter interface, the smooth integration of cutting-edge CNN transfer learning algorithms-based technology that include ResNet-50, InceptionV3, VGG16, and MobileNetv2 with the UCI dataset represents a major advancement toward modernizing agricultural practices and guaranteeing sustainable crop management. Remarkable outcomes include 75% accuracy for ResNet-50, 90% accuracy for DenseNet121, 84% accuracy for VGG16, 95.83% accuracy for MobileNetV2, 91.61% accuracy for DenseNet169, and 86% accuracy for InceptionV3. These results give a concise summary of the models' capabilities, assisting researchers in choosing appropriate strategies for precise and successful rice crop disease identification. A severe overfitting has been seen on VGG19 with 70% accuracy and Nasnet with 80.02% accuracy. On Renset101, only an accuracy of 54% could be achieved, along with only 33% on efficientNetB0. A MobileNetV2-trained model was successfully deployed on a TKinter GUI application to make predictions using image or real-time video capture.", "sections": [{"title": "I. INTRODUCTION", "content": "Rice is by far the most significant food crop for people in low- and lower-middle-income countries out of the three main crops: wheat, maize, and rice. Rice is a basic and typically indispensable food staple in many Asian nations, particularly for the impoverished [1]. Rice makes up approximately half of the food expenses and, on average, a fifth of the total household expenditures for the extreme poor of Asia, who survive on less than $1.25 per day. By purchasing power parity, this group alone spends $62 billion a year on rice. A lot of the world's impoverished people depend on rice for their food security. Because it grows well in a variety of environments and is high in proteins and carbohydrates, rice is the most widely grown crop in India. As a result, over 1.2 billion people in South Asia and an estimated 3.5 billion people globally use rice as their main meal [2]. Rice is the main source of energy for over half of the world's population [3]. Numerous farmers worldwide are impacted by illnesses associated with rice leaves, which can seriously jeopardize the sustainable production of rice [20]. To reduce yield losses, rice infections must be identified and treated as soon as possible. Plant disease identification has shown considerable promise for convolutional neural networks (CNNs). However, CNN training requires enormous datasets of annotated images, which can be costly and time-consuming [4]. Today's agricultural industry is poised for a technological revolution that will necessitate a paradigm change toward precision farming practices. The introduction of AI and machine learning into agriculture has the potential to bring about previously unattainable breakthroughs in yield optimization, disease detection, and crop management. Our work aims to make a substantial contribution to this revolutionary wave by concentrating on the use of transfer learning algorithms in the field of rice disease classification."}, {"title": "II. LITERATURE REVIEW", "content": "Given the similarities in appearance between some types of rice disease, an overall accuracy of 91% was obtained when six types of rice diseases were diagnosed using the Ensemble Model. This is regarded as reasonably good. Using the smartphone app, the client could easily and effectively diagnose rice leaf blast, false smut, neck blast, sheath blight, bacterial stripe disease, and brown spot in the field. The Ensemble Model was accessible on the web server via a network [1].\nPaddy crops must be protected, and early disease detection is essential. In the past, diagnosing a disease required observation or laboratory examination. Visual observations require expertise and can differ from person to person, making them prone to error. Laboratory testing also takes longer and may not yield results quickly. Machine learning techniques based on image processing were employed to identify and categorize the diseases in order to overcome this problem. Authors primarily addressed diseases of rice (Oryza sativa) [2].\nIn order to obtain the reduced data with significant features that are used as the input to the classification model, the feature extraction process is first applied to the data in this work. Following this, feature selection is also applied. Color, shape, position, and texture features are extracted from photos of infected rice plants for the rice disease datasets, and a rough set theory-based feature selection technique is applied to the feature selection task. In order to develop an efficient disease prediction model for the classification task, ensemble classification methods have been implemented within a map reduce framework. The effectiveness of the suggested model is demonstrated by the findings on the gathered disease data [3].\nUsing a dataset of 8883 and 1200 photos of diseased and healthy rice leaves, respectively, the suggested method was tested and found to achieve an accuracy of 94% using the 10-fold cross-validation process, which was significantly higher than other approaches. These simulation results demonstrate the viability and effectiveness of rice disease detection and provide an affordable, easily accessible means of identifying rice diseases early on. This is especially helpful in developing nations with limited resources and can make a substantial contribution to the production of sustainable food [4].\nThe three most common diseases that affect rice leaves are brown spot, leaf blast, and hispa. In order to address this problem, we have investigated a number of deep learning and machine learning techniques for identifying the diseases on their leaves. We have measured the effectiveness of these techniques by calculating their accuracy, recall, and precision. By identifying diseases in rice leaves, this study assists farmers in obtaining a healthy crop yield. When compared to machine learning techniques, the deep learning models exhibit superior performance. After examining every deep learning model, we discovered that the 5-layer convolution model performed the best, with an accuracy of 78.2%, while other models, like VGG16, performed worse, with an accuracy of 58.4% [5].\nAn automated diagnosis technique was created for this study and put into a smartphone app. Based on a sizable dataset of 33,026 photos of six different forms of rice diseases-leaf blast, false smut, neck blast, sheath blight, bacterial stripe disease, and brown spot-the technique was created using deep learning. According to the results, the top three submodels in terms of a number of characteristics, including learning rate, precision, recall, and accuracy in identifying diseases were DenseNet-121, SE-ResNet-50, and ResNeSt-50. An overall accuracy of 91% was obtained when six different types of rice illnesses were diagnosed using the Ensemble Model. The client was able to use the Ensemble Model on the web server over a network thanks to the smartphone app, which made it easy and effective for field diagnosing illnesses [6]."}, {"title": "III. METHODOLOGY", "content": "The proposed work consists of training a deep learning model with a UCI dataset for creating an accurate model for making predictions on 3 classes of data, which are 'bacteria': 0, 'brown': 1, and'smut': 2, that are used to make the prediction on those images, along with which real-time video capturing of the image helps to make predictions on the image. The model can make predictions on the model as shown in figure 2. and predict the disease the rice leaf has been reflecting and providing suggestions to farmers regarding the implementing methods to treat the disease."}, {"title": "ResNet-50", "content": "Microsoft Research announced ResNet-50, also known as Residual Network with 50 layers, a deep convolutional neural network. It is well known for using residual connections, which are layer-skipping shortcuts. With the help of this architecture, the vanishing gradient issue is lessened, enabling a much deeper network without sacrificing efficiency. Because they make it easier for gradients to move across the network, residual connections aid in the training of deeper networks. ResNet-50 performs well in many image identification tasks, but because of its propensity for overfitting, it can occasionally do less well in validation accuracy, especially in smaller or less diversified datasets."}, {"title": "DenseNet-121", "content": "DenseNet-121 is a DenseNet variation with dense connections between layers that was first presented by Cornell University. In a DenseNet, every layer passes its own feature maps to every other layer after receiving inputs from all layers that came before it. Because of its dense interconnectedness, features can be reused and fewer parameters are required, which frequently leads to increased efficiency and accuracy. DenseNet-121 performs exceptionally well in training and validation accuracy, suggesting robust feature learning and good generalization. It maintains great validation accuracy and nearly faultless training performance thanks to its thick connections."}, {"title": "VGG16", "content": "The Visual Geometry Group at the University of Oxford created VGG16, which is renowned for its consistent architecture and simplicity. There are three fully connected layers and thirteen convolutional layers among its sixteen weighted layers. The model is simple to use but highly effective for picture classification tasks because it makes use of deep networks and relatively small convolutional filters (3x3). Due to its tendency to overfit, VGG16 can have issues with validation accuracy even with reasonably high training accuracy, particularly on datasets with low size or diversity."}, {"title": "MobileNetV2", "content": "Google created MobileNetV2, a platform for effective model deployment on mobile and edge devices. In order to save computation time and number of parameters without sacrificing accuracy, depthwise separable convolutions are introduced. To improve efficiency and performance even more, MobileNetV2 additionally uses inverted residual structures and linear bottlenecks. The model is durable and effective at capturing characteristics while being computationally efficient, which makes it well-suited for real-time applications. This is demonstrated by the high training and validation accuracy of the model."}, {"title": "Inception V3.", "content": "Google's Inception V3 is a deep convolutional network that applies several filters in parallel at various scales by using Inception modules. This architecture enhances the model's ability to learn by enabling it to capture a variety of features. To increase performance and efficiency, Inception V3 includes a number of improvements, such as factorized convolutions and auxiliary classifiers. It may not always obtain the highest training accuracy in comparison to other models, but it shows strong validation accuracy, suggesting that it can generalize well to new data."}, {"title": "Efficicent Net B0", "content": "A convolutional neural network architecture called EfficientNetB0 is made to operate effectively on a variety of computing platforms. It was created by Google and uses a technique called compound scaling to balance the network's depth, width, and resolution. The depthwise separable convolutions used in the mobile Inverted Residual Bottleneck (MBConv) blocks, which lower computing costs, form the foundation of the architecture. EfficientNetB0 is a good fit for server and mobile applications because it maintains great accuracy at a reduced computational cost than other networks."}, {"title": "ResNet-101", "content": "Building upon the ResNet (Residual Network) architecture, ResNet-101 is a deep convolutional neural network with 101 layers. In order to mitigate the vanishing gradient issue, it adds residual blocks with skip connections that facilitate gradient flow through the network during training. The network can effectively train very deep models thanks to these skip links. Because ResNet-101 can learn complicated features without overfitting, it is widely utilized in computer vision applications and is well-known for its strong performance in image classification tasks."}, {"title": "VGG19", "content": "The deep convolutional neural network VGG19 is well-known for being easy to use and efficient when it comes to image recognition tasks. It was created by Oxford University's Visual Geometry Group (VGG) and has 19 layers total-16 convolutional layers and 3 fully connected layers. Small 3x3 convolutional filters are used throughout the architecture to help capture minute features in photos. VGG19's simple design and strong performance on massive datasets like ImageNet have made it a popular choice for benchmarking and transfer learning."}, {"title": "NasNet", "content": "A deep learning model called NASNet (Neural Architecture Search Network) was created utilizing neural architecture search methods. NASNet, a Google creation, uses an automated search procedure to find the best network designs for particular purposes. Its modular architecture allows for the customization of construction blocks to fit a range of sizes and levels of complexity. NASNet has proven to be able to find efficient network configurations using algorithmic search, resulting in state-of-the-art performance in applications like as object detection and image categorization."}, {"title": "DenseNet169", "content": "A DenseNet architecture variation recognized for its dense connectivity structure is DenseNet169. Its 169 layers and feed-forward connectivity between each layer and every other layer mitigate the vanishing gradient issue and encourage feature reuse. DenseNet169 uses dense blocks, which enable each layer to learn rich representations with less parameters by receiving additional inputs from all layers that come before it. This design retains computing efficiency while achieving great accuracy on picture classification applications."}, {"title": "A. DATASET COLLECTION AND PREPROCESSING", "content": "There are 120 JPG pictures of diseased rice leaves in this dataset. Depending on the type of disease, the images are divided into three classes. Every class contains forty images as shown in figure 3."}, {"title": "B. DEEP LEARNING APPROACH", "content": "Utilizing the Mobile Net V2, vGG16, RestNet50, and finally InceptionV3 models, the deep learning algorithm in the script is based on convolutional neural networks (CNNs). Finally, the InceptionV3 model showed the best results in the classification on the training and validation sets.\nSetting parameters like batch size and image size, as well as dividing the dataset into training and validation sets, are all part of the training process for an ImageDataGenerator. The layers of the pre-trained InceptionV3 model on ImageNet were frozen, and a custom top classification layer was added. Categorical cross-entropy loss and the Adam optimizer are used to compile the model. The model learns from the augmented training data and validates on the separate validation set during the training loop's predetermined number of epochs. Following training, the accuracy results are printed, and the model is assessed on the training and validation sets. These measures shed light on how well the model applies to fresh, untested data."}, {"title": "C. APPLICATION DEVELOPMENT", "content": "A feature-rich Tkinter GUI application is used in the study to improve the deep learning model's applicability and user-friendliness in the classification of rice diseases. This Tkinter-based interface provides a variety of functionalities to meet the various needs of farmers and agricultural practitioners, acting as a dynamic decision support system. With its user-centric design, the GUI application facilitates seamless interaction between users and the model by accommodating multiple input modalities. A noteworthy feature allows users to upload images of rice leaves for the purpose of classifying diseases. Even those with little experience with technology can utilize it because of its user-friendly design, which leads them through the process. The InceptionV3 model with a greater accuracy result was applied and integrated to the application for classifying the diseases from rice leaf images.\nMoreover, the program incorporates a real-time video capture feature, going beyond static image input. Using the camera on their device, users can record live footage of rice leaves and receive instantaneous predictions for dynamic crop health monitoring. For prompt interventions and proactive disease management, this real-time component is crucial. The Tkinter application uses the trained deep learning model to accurately predict the disease class of the rice leaves after processing the input. The forecasts are then converted into practical advice suited to the particular ailment found. These suggestions are a great tool for farmers, helping them to make well-informed choices about crop care and management techniques."}, {"title": "IV. RESULTS", "content": "Thus, the application was able to make correct predictions with the help of the deep learning architecture used in the script that is based on the Inception V3 model with transfer learning, augmented by additional layers including dropout and dense layers for rice disease classification."}, {"title": "A. MODEL ACCURACY", "content": "The model gained an impressive accuracy of approximately 96% on training and 87.50% on validation set with Inception V3 model and similarly, 100% and 87.50% accuracy on mobileNetV2 which was a excellent result to deploy model with the application. The result accuracies obtained is tabulated in table 2.\nThus, we integrated MobileNetv2 model by analyzing the model loss and training and validation accuracy results which were satisfying enough. Mass overfitting was seen on VGG19, NasNet and low performance on efficientNetB0 as seen in table 2.\nAs, shown in figure.5. the inception DenseNet121 model obtained excellent result on training and validation set with the approach."}, {"title": "B. PREDICTION TEST", "content": "The model could successfully predict the type of disease leaf is associated or affected with and GUI application was made in such a way to provide recommendations to the user on the type of disease affected and solutions to overcome them.\nThe figure 6 shows prediction of brown sport disease on a sample test image. The sort of disease affecting the rice leaves has been successfully predicted by integrating the trained model into the GUI application. Users can upload an image of a diseased rice leaf using the GUI's user-friendly interface, and the model quickly predicts the associated disease label. The remarkable precision of the forecasts enables farmers and users to promptly recognize possible problems impacting their crops.\nThe application's goal and theme are reinforced by the classification.jpg image, which acts as a standout logo at the top of the graphical user interface. The resized recycle.png image and the logo are two examples of the visual components that make up a visually appealing and well-designed user interface."}, {"title": "C. MODELS HYPERPARAMETERS", "content": "Deep learning models' training dynamics and performance are greatly influenced by their hyperparameters. During optimization, the number of steps taken to minimize the loss function is controlled by the learning rate. Selecting the right learning rate is essential; too high a rate could push the model toward an unsatisfactory solution too soon, while too low a rate could result in a delayed and possibly halted convergence. The amount of training samples needed to calculate each gradient update depends on the batch size. The various hyperparameters used are shown in table 3."}, {"title": "D. TKINTER APPLICATION", "content": "Finally, the GUI was able to integrate the ML model, and then correct predictions were made and classification of disease could be done successfully. The recommendations could be provided to the farmers successfully with the help of the application. An important step toward bridging the gap between cutting-edge technology and useful agricultural applications has been taken with the successful integration of the GUI with the machine learning model. Interaction between the user and the system's underlying intelligence is made possible by the interface's seamless integration with the deep learning model. This integration highlights the potential of technology to empower people in traditionally non-technical domains while also simplifying the user experience. Based on the MobileNetV2 model architecture [17], the deep learning model continuously processes the input data as the user works with the GUI, uploading photos or recording videos of rice leaves. By utilizing transfer learning, the model makes use of its prior knowledge from ImageNet to identify complex patterns and features that correspond to different rice diseases. The process's successful completion demonstrates the deep learning architecture's versatility and resilience in the context of classifying agricultural diseases [18], [19]. The transfer learning algorithm shows a great result for promoting rice leaf prediction with intelligent application [27]. The application GUI built is shown in figure 7."}, {"title": "V. DISCUSSION", "content": "The accurate diagnoses and detailed categorization of rice illnesses represent the culmination of this integration. The model's capacity to learn from and generalize from a variety of data is demonstrated by its accuracy in identifying and labeling diseases, which empowers it to make judgments about crop health [18]. For farmers looking for trustworthy information to direct their farming practices and lessen the impact of diseases on crop yield, this accuracy is crucial [19]. The result obtained from this research study has been compared with previous research works, as seen in Table 4.\nOne of major achievement of this research work is a remarkable accuracies of 90%+ on 3 different transfer learning models on such a small dataset comprising of 120 images. The GUI built with in tkinter goes beyond simply classifying diseases; it can also offer farmers helpful recommendations [26]. These suggestions are based on the model's forecasts and are made specifically to deal with the identified disease. With the help of this feature, the application becomes more than just a classification tool-rather, it becomes a dynamic decision support system that gives farmers useful insights for managing their crops. The fact that the recommendations were delivered successfully demonstrates how well sophisticated machine learning and approachable user interfaces can be combined to solve practical agricultural problems [7]. The work has several limitations like unsuitability for integrating to mobile devices, and application isnt suited for high end Pcomputer devices as well as mobile devices, in future we aim to minimize such issues. The data can be further enhanced in the future with more data collection and utilization for making more robust models and developing mobile application tools. Many works have been done in deep learning in the agriculture sector [15], along with transfer learning models [13], process models to have been used [14], along with federated learning processes [23]. AI and robotics have a great role in promoting sustainability with multidisciplinary approaches like waste management aid [30], [31], and disease classifications [22-29]. There is still a need for much technological advancement in the field of agriculture, and the development of these applications can be supportive to create great outcomes in agriculture productions [28]."}, {"title": "VI. CONCLUSIONS", "content": "The GUI's seamless integration with the machine learning model demonstrates the architecture's technological prowess and is a big step toward enabling farmers to use cutting-edge technologies. This development with analysis on 10 models shows how crop illnesses may be accurately diagnosed by deep learning and actionable advice can be given, leading to more productive and sustainable farming methods.\nWith an Al-integrated system, it can be used to scan rice leaves and predict (classify) the disease. In addition to offering a video classification feature for a range of agricultural applications, the GUI makes it simple for users to upload photos for classification. Farmers are empowered to make informed decisions about crop management due to accurate disease categorization, which is made possible by the smooth interface between the model and GUI."}]}