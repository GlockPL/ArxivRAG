{"title": "SelEx: Self-Expertise in Fine-Grained Generalized Category Discovery", "authors": ["Sarah Rastegar", "Mohammadreza Salehi", "Yuki M. Asano", "Hazel Doughty", "Cees G. M. Snoek"], "abstract": "In this paper, we address Generalized Category Discovery, aiming to simultaneously uncover novel categories and accurately classify known ones. Traditional methods, which lean heavily on self-supervision and contrastive learning, often fall short when distinguishing between fine-grained categories. To address this, we introduce a novel concept called 'self-expertise', which enhances the model's ability to recognize subtle differences and uncover unknown categories. Our approach combines unsupervised and supervised self-expertise strategies to refine the model's discernment and generalization. Initially, hierarchical pseudo-labeling is used to provide 'soft supervision', improving the effectiveness of self-expertise. Our supervised technique differs from traditional methods by utilizing more abstract positive and negative samples, aiding in the formation of clusters that can generalize to novel categories. Meanwhile, our unsupervised strategy encourages the model to sharpen its category distinctions by considering within-category examples as 'hard' negatives. Supported by theoretical insights, our empirical results showcase that our method outperforms existing state-of-the-art techniques in Generalized Category Discovery across several fine-grained datasets. Our code is available at: https://github.com/SarahRastegar/SelEx.", "sections": [{"title": "1 Introduction", "content": "Supervised learning has proven its effectiveness in classifying predefined image categories [31, 34, 44, 72, 73]. However, it struggles significantly when presented with unknown categories, hindering its real-world applicability [7,50, 68, 76, 101]. Generalized Category Discovery (GCD) addresses this limitation by automatically identifying both known and novel categories from unlabeled data [2, 8, 16, 29, 63, 77,78,83,95]. A key approach for handling unknown categories within GCD has been self-supervision through contrastive learning [8, 9, 15, 27, 36, 46, 48, 53, 93]. However, this method struggles with fragmented clustering and an increased false negative rate, particularly in fine-grained categorization where positive augmented samples may significantly differ from their negative counterparts from the same category, which leads to misclassification [9, 18, 35, 37]. Although supervised contrastive learning [38,77] improves discrimination among known categories, it struggles with unknown categories due to the absence of supervisory"}, {"title": "2 Related Works", "content": "Generalized Category Discovery was introduced concurrently by Vaze et al. [77] and Cao et al. [8]. It provides models with unlabeled data from both novel and known categories, placing it within the realm of semi-supervised learning [12, 54, 58, 65, 88]. The unique challenge in generalized category discovery is handling categories without any labeled instances alongside already seen categories. There are primarily two approaches to address this challenge. One employs a series of prototypes as reference points, e.g., [2,16,17,29,39,75,81,83,86,87,94]. The second leverages local similarity as weak pseudo-labels per sample by utilizing sample similarities to form local clusters [20, 23, 62, 63,95,98] or by utilizing mean-teacher networks to address the challenges posed by noisy pseudo-labels [78,80,83,95]. Nonetheless, the foundation of these approaches is contrastive learning, which has previously been shown to falter in fine-grained classification [18] due to strong augmentations in positives in comparison to nuanced visual differences between samples of the same category. To alleviate this, we introduce 'self-expertise' aimed at hierarchical learning of known and unknown categories. Our method is particularly effective in overcoming the limited availability of positive samples per category and enhancing the identification of subtle differences among negative samples, which we deem the biggest challenge in fine-grained classification.\nHierarchical Representation Learning. Different approaches benefit from hierarchical categories. Zhang et al. [96] use multiple label levels to enhance their representation through hierarchical contrastive learning. Guo et al. [25] extract pseudo labels for hierarchical contrastive learning, where signals are positive within the same cluster. We also use hierarchical pseudo-labels, but instead employ negative samples from the same cluster for generalized category discovery.\nOtholt et al. [57] and Banerjee et al. [4] proposed hierarchical approaches to address generalized category discovery. These works leverage neighborhood structures to delineate refined categories. Rastegar et al. [63] learn an implicit category tree, facilitating hierarchical self-coding of categories, which maintains category similarity across all hierarchy levels. Differing from these works, our method leverages weak supervision from samples within each level of the hierarchy, which reduces misclassification impact on lower levels. Additionally, our focus on hard negatives for unsupervised self-expertise enhances the model's ability to discern nuanced distinctions, leading to better fine-grained classification."}, {"title": "3 Theoretical Framework for Self-Expertise", "content": "Notations. We denote the number of total categories with K and the number of samples by N. For each random variable c, we indicate the number of associated samples by cl. We use 'ln' for the natural logarithm and \u2018lg' for log2. Problem\nDefinition. The challenge of generalized category discovery lies in classifying samples during inference as belonging to categories encountered during training or as entirely novel categories. To describe this formally, throughout the training"}, {"title": "4 Self-Expertise for Generalized Category Discovery", "content": "Our proposed method for fine-grained generalized category discovery has three components: hierarchical pseudo-label extraction, unsupervised self-expertise, and supervised self-expertise. As illustrated in Fig. 3, each phase synergistically contributes to achieving discriminative clustering, which is pivotal for the task."}, {"title": "5 Experiments", "content": "Datasets. We assess the efficacy of our approach on four fine-grained datasets: CUB-200 [79], FGVC-Aircraft [51], Stanford-Cars [42] and Oxford-IIIT Pet [61]. Additionally, we demonstrate the adaptability of our method to more coarse-grained datasets CIFAR10 [43], CIFAR100 [43] and ImageNet-100 [19], highlighting its broader applicability beyond fine-grained classification tasks. Finally, in the Appendix experiments section, we report on the challenging Herbarium-19 dataset [74], which is fine-grained and long-tailed, to show that our approach is effective even with non-uniform category distributions. Detailed statistics of the datasets along with their train/test splits are also provided in the Appendix.\nImplementation Details. In our experiments, we adhered to the dataset division proposed by Vaze et al. [77], where half of the categories in each dataset are designated as known, except for CIFAR100, where 80% are used as known categories. The labeled set consists of 50% of the samples from these known categories. The remainder of the known category data, along with all data from novel categories, comprise the unlabeled set. Following [77], we use ViT-B/16 as our backbone, which is either pre-trained by DINOv1 [11] on unlabelled ImageNet 1K [44], or pretrained by DINOv2 [56] on unlabelled ImageNet 22K. We use the batch size of 128 for training and set \u5165=0.35. For label smoothing, we use a=0.5 for fine-grained datasets and a=0.1 for coarse-grained datasets. Different from [77], we froze the first 10 blocks of ViT-B/16 and fine-tuned the last two blocks instead of only the last one to have more parameters given that for each level, only a fraction of the latent dimension is considered."}, {"title": "5.2 Comparison with State-of-the-Art", "content": "Fine-grained image classification. We evaluate our model's effectiveness across three fine-grained datasets in Tab. 1. The results demonstrate our method's capability in handling fine-grained categories, as it consistently outperforms others in both all and novel category classification within these datasets. The success can be attributed to the model's hierarchical approach to category analysis, which is pivotal in differentiating between closely related categories that demand acute attention to specific details. Additionally, as indicated in Table 2, our method also leads in performance for both all and novel categories in the Oxford Pet dataset. Despite its small size, which typically poses a risk of overfitting, our model's strong performance on this dataset further indicates its robustness."}, {"title": "5.3 Ablative studies", "content": "We evaluate the individual effects of method components in this section. All ablative experiments are performed on CUB with the DINOv1 backbone. We present additional ablations, time complexity, and failure cases in the Appendix.\nEffect of each component. Tab. 4 (a) examines the effect of our three key method components: Hierarchical Semi-Supervised K-means (HSSK), unsuper-"}, {"title": "6 Conclusion", "content": "This work presents self-expertise in identifying and categorizing known and previously unknown categories, focusing on fine-grained distinctions. We introduce a method that utilizes hierarchical structures to effectively bridge the gap between labeled data for known categories and unlabeled data for novel categories. This is achieved by generating hierarchical pseudo-labels, which guide both supervised and unsupervised learning phases of our self-expertise framework. The supervised phase is designed to incrementally increase the complexity of differentiation tasks, thereby accelerating the training process and enhancing the formation of distinct clusters for unknown categories. This strategy improves the model's ability to generalize to novel categories. In the unsupervised phase, we integrate a label-smoothing hyperparameter, compelling the model to concentrate on negative samples within a localized context and to make finer distinctions. This approach enhances the model's fine-grained categorization capabilities. Overall, our work demonstrates the effectiveness of self-expertise in handling unknown and fine-grained categorization tasks. In the Appendix section titled 'Discussions,' we outline the limitations of our work and propose directions for future research."}, {"title": "A Related Works", "content": "To provide a more in-depth analysis of the relevant literature, this appendix section delves into additional related works."}, {"title": "A.1 Self-Supervised Learning", "content": "Self-supervised learning has transformed the analysis of large-scale unlabeled data, learning rich representations. He et al. [30] introduced the concept of momentum contrast with MoCo, enhancing the quality of learned representations by utilizing two encoders and a contrastive loss to learn image features that distinguish between different views [30]. Following this, Chen et al. [15] simplified the self-supervised learning pipeline with SimCLR, by maximizing agreement between different augmented versions of the same image, using a contrastive loss function [15]. Caron et al. [10] introduced SwAV, which employs a clustering mechanism to enhance consistency between cluster assignments, thereby improving learning efficacy [10]. By employing a self-distillation with information noise injection, DINO [11] efficiently captures complex visual features without labeled data. DINOv2 [56] further refines this approach with key improvements, enhancing both feature quality and model adaptability."}, {"title": "A.2 Open-Set Recognition", "content": "The advent of open set recognition marked a significant milestone in the evolution of computational models, addressing the complexities of processing real-world data. This domain was first conceptualized by Scheirer et al. [70], who laid the foundational theory for models capable of discerning between known and unknown data categories, a principle further developed by subsequent research [5, 69]. The pioneering application of deep learning techniques to tackle open-set recognition challenges was introduced through the development of OpenMax [6]. The core objective within open-set recognition is the accurate identification of known categories while effectively filtering out novel category samples. Various methodologies have been proposed to emulate the concept of \"otherness\" essential for distinguishing unknown categories. These approaches range from identifying significant reconstruction errors [60,90], measuring the deviation from a set of predefined prototypes [13, 14, 71], to differentiating samples generated through adversarial processes [24, 41, 52, 92]. Despite its advances, a notable limitation of open-set recognition is its inclination to disregard all instances of novel classes, potentially omitting valuable information. This challenge underscores the ongoing quest for more sophisticated models capable of not only identifying the unknown but also accommodating the continuous expansion of the knowledge domain."}, {"title": "A.3 Novel Category Discovery", "content": "The foundation for this line of inquiry was laid by Han et al. [28], who adapted classification models to recognize novel categories based on knowledge from known categories. Initial strategies, as documented in several studies [26,32,33], typically"}, {"title": "A.4 Generalized Category Discovery", "content": "Generalized category discovery was introduced by Vaze et al. [77] and Cao et al. [8]. It provides models with unlabeled data from both novel and known categories, placing it within the realm of semi-supervised learning, a domain thoroughly investigated in the machine learning literature [12,54,58,65,88]. The unique challenge in generalized category discovery is handling categories without any labeled instances, which introduces additional complexity. There are primarily two approaches to address this challenge. The first employs a series of prototypes as reference points, e.g., [2,16,17,29,39,75,81,83,86,87,94]. The second approach leverages local similarity as weak pseudo-labels for each sample and utilizes sample similarities to form local clusters [4, 16, 20, 23, 29, 57, 62, 63, 95, 98]. Studies such as [78,80,83,95] employ mean-teacher networks to tackle the issues arising from noisy pseudo-labels. Additionally, other research efforts leverage cues from alternative modalities to identify categories in a multimodal fashion [1,59,99]. Our approach introduces 'self-expertise', a novel concept aimed at hierarchical learning of known and unknown categories. This technique emphasizes the focus on the samples from identical clusters at each level. This method is particularly effective in overcoming the limited availability of positive samples per category, while also enhancing the identification of subtle differences among negative samples."}, {"title": "A.5 Hierarchical Representation Learning", "content": "In the realm of leveraging hierarchical categories for enhanced representation learning, several approaches have been introduced. Zhang et al. [96] employ multiple label levels to augment their models' representational capacity through hierarchical contrastive learning. Similarly, Guo et al. [25] extract pseudo-labels to facilitate hierarchical contrastive learning, with a unique emphasis on ensuring signals remain positive within identical clusters. The hierarchical structure of categories has been explored in previous works such as [45,85], aiming to enhance the identification of novel categories within the context of open-set recognition. Additionally, Rastegar et al. [64] utilize a hierarchical structure for multimodal data to infer missing modalities, which can be categories. An alternative perspective"}, {"title": "B Theory", "content": "In this section, we motivate our approach\nof hierarchical contrastive learning and\nwhy it is particularly well-suited for cate-\ngory discovery in unseen data."}, {"title": "B.1 Notations and Definitions", "content": "Let's consider the simple Bayesian net-\nworks depicted in Fig. 8. Here, xi and xj\nare different samples or different views of\nthe same sample which are observed. Their\ncorresponding ground truth context vari-"}, {"title": "B.2 Problem Definition", "content": "For contrastive training, the goal is to estimate the true distribution of equality\nof the ground truth context variables. Hence, for samples i and j, the goal is to\napproximate the following true distribution,\n$$p(y=1|c_i, c_j) = \\mathbb{1}(c_i=c_j),$$\nin which $ \\mathbb{1}$ is the identity operator, which is one only when its inner condition holds\nand zero otherwise. Depending on the problem we aim to solve, in training, we\nhave no access to the ground truth context variables as in unsupervised contrastive\nlearning, or we have partial access as in supervised contrastive learning. In both\ncontrastive learning formulations, we aim to minimize the KL divergence between\nthe true distribution $p$ and our model distribution $ \\hat{p}$ which in case of unsupervised\ncontrastive learning will be,\n$$D_{KL} [p(y|c_i, c_j) \\mid\\mid \\hat{p}(y|x_i, x_j)],$$"}, {"title": "B.3 Supervised Contrastive Learning", "content": "Theorem 1. Consider two samples i and j from the Bayesian network Fig. 8.\nIf we have a total of N samples and K categories and the dataset is balanced, we\nwill have the following upper bound if only i's label $c_i$ is known:\n$$D_{KL} [p(y|c_i, c_j) \\mid\\mid \\hat{p}(y|c_i, x_j)] \\leq \\ln \\frac{N}{K}$$\nProof. According to the Bayesian network shown in Fig. 8, we have:\n$$\\hat{p}(y|c_i, x_j) = \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) \\hat{p}(y|c_i, z_j).$$\nNote that since $\\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j)=1$ and $p(y|c_i, c_j)$ is independent of $z_j^3$, we can\nconsider that\n$$p(y|c_i, c_j) = \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) p(y|c_i, c_j).$$\nAlso, since KL divergence is convex, we can have the following inequality:\n$$D_{KL}[\\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) p(y|c_i, c_j) \\mid\\mid \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) \\hat{p}(y|c_i, z_j)]$$\n$$\\leq \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) D_{KL}[p(y|c_i, c_j) \\mid\\mid \\hat{p}(y|c_i, z_j)].$$\nIf we use equations Eqs. (19) to (21) on the left-hand side of the inequality\nEq. (18), we will have the following:\n$$D_{KL}[p(y|c_i, c_j) \\mid\\mid \\hat{p}(y|c_i, x_j)] =D_{KL}[p(y|c_i, c_j) \\mid\\mid \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) \\hat{p}(y|c_i, z_j)]$$\n$$=D_{KL}[\\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) p(y|c_i, c_j) \\mid\\mid \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) \\hat{p}(y|c_i, z_j)]$$\n$$\\leq \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) D_{KL} [p(y|c_i, c_j) \\mid\\mid \\hat{p}(y|c_i, z_j)],$$"}, {"title": "B.4 Unsupervised Contrastive Learning", "content": "For the unsupervised scenario, both labels\nare unknown, this means that we only have\naccess to the inputs $x_i$ and $x_j$. This means\nthat for unlabelled samples they will follow\nthe Bayesian network shown in Fig. 10.\nWe can state a similar theorem for the\nunsupervised case as follows:\nTheorem 2. Consider two samples i and\nj from the Bayesian network Fig. 8. If we\nhave a total of N samples and K categories\nand the dataset is balanced, we will have\nthe following upper bound if neither of i\nand j labels is known:\n$$D_{KL} [p(y|c_i, c_j) \\mid\\mid \\hat{p}(y|x_i, x_j)] \\leq \\ln \\frac{N}{K}.$$\nProof. According to the Bayesian network shown in Fig. 10, we have:\n$$\\hat{p}(y|X_i, x_j) = \\sum_{z_i=1}^{K} \\hat{p}(z_i|x_i) \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) \\hat{p}(y/z_i, z_j).$$\nNote that since $\\sum_{z_i=1}^{K} \\hat{p}(z_i|x_i)=1$ and $\\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j)=1$ and $p(y|c_i, c_j)$ is inde-\npendent of $z_i$ and $z_j$, we can consider that\n$$p(y|c_i, c_j) = \\sum_{z_i=1}^{K} \\hat{p}(z_i|x_i) \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) p(y|c_i, c_j).$$\nAlso, since the KL divergence is convex, we can have the following inequality:\n$$D_{KL}[\\sum_{z_i=1}^{K} \\hat{p}(z_i|x_i) \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) p(y|c_i, c_j) \\mid\\mid \\sum_{z_i=1}^{K} \\hat{p}(z_i|x_i) \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) \\hat{p}(y|z_i, z_j)]$$\n$$\\leq \\sum_{z_i=1}^{K} \\hat{p}(z_i|x_i) \\sum_{z_j=1}^{K} \\hat{p}(z_j|x_j) D_{KL} [p(y|c_i, c_j) \\mid\\mid \\hat{p}(y|z_i, z_j)].$$"}, {"title": "B.5 Self-Expertise", "content": "In the paper, we introduced an upper bound for a dataset comprising N samples\nacross K categories, denoted as Sk. To further refine our understanding, we\npropose an alternative upper bound, $\\hat{S}_K$, which leverages the hierarchical structure\ninherent among the categories. This hierarchical framework can be conceptualized\nas a Markov chain, where each category's relevance is determined independently\nof the samples and hyper-labels, except for its immediate predecessor and its\nchildren in the hierarchy. Our objective is to delineate the conditions under\nwhich $\\hat{S}_K$ serves as an effective upper bound, taking into account the hierarchical\nrelationships among categories. This approach aims to capture the nuanced\ndependencies within the category structure, thereby providing a more granular\nand accurate upper limit for the distribution of samples among the categories.\n$$\\sum_{l=1}^{\\log K} D_{KL} [p(y|c_i^{l}, c_j^{l}) \\mid\\mid \\hat{p}(y|c_i^{l}, x_j, c_j^{l-1})] \\leq \\hat{S}K,$$\nlet I denote the hierarchy level. Consider that at level l, given K distinct categories,\neach cluster $c_j^{l-1}$ contains $\\frac{N}{K}$ samples, as opposed to the full $N$ samples without\nconsidering the hierarchy. Upon substituting these adjusted values for $K$ and $\\frac{N}{K}$\ninto the established upper bound in Eq. (18), we obtain the following:\n$$S_K=\\log K \\ln \\frac{N}{K^2},\\qquad\\qquad \\hat{S}=\\log K - 1 \\ln \\frac{4N}{K^2} \\Rightarrow \\hat{S}K \\leq S.$$\nEmploying analogous reasoning for the unsupervised self-expertise component,\nwe derive:\n$$\\hat{\\Pi}_K \\leq \\Pi_K.$$"}, {"title": "C Method", "content": "For a deeper understanding of the proposed methods, this appendix section\nprovides a detailed explanation and corresponding pseudocode for the algorithms\nbriefly introduced in the main text."}, {"title": "C.1 Balanced Semi-Superivsed K-means", "content": "Our algorithm consists of three key stages:\n1. Semi-Supervised K-means Centers Initialization,\n2. Updating novel categories while balancing clusters,\n3. Semi-supervised K-means for final assignment based on the refined centers."}, {"title": "C.2 Hierarchical Semi-Supervised K-means", "content": "In our methodology, the initial step involves the generation of pseudo-labels\nthrough the application of the Balanced Semi-Supervised K-means (BSSK) algo-"}, {"title": "C.3 Unsupervised Self-Expertise", "content": "In the main text, we outlined the development of an unsupervised self-expertise\ntarget matrix designed to prioritize the model's attention on the most challenging\nnegative samples. The pseudocode for extracting these hard negatives via a Label"}, {"title": "C.4 Supervised Self-Expertise", "content": "In alignment with the paradigm of unsupervised self-expertise, our approach ne-\ncessitated the construction of a target matrix specific to supervised self expertise,\ndesigned to encapsulate both weakly positive instances and strongly negative\nexamples. Figure 16 elucidates the stepwise development of this matrix across\nvarious strata of the category hierarchy.\nJustification of Latent Utilization. The rationale behind allocating the first\nhalf of the latent dimension to more abstract categories is twofold. Firstly, this\nallocation allows the model to make a rough categorization e.g. 'feline' or 'canine'.\nSubsequently, the differentiation between precise categories e.g. 'cat' and 'lion'\nis handled by the second half. Utilizing the full dimension to simultaneously\nrepel 'cat' and 'lion' samples, while attracting them at a higher abstraction level,\nimpedes the model's capacity to distinguish between these categories. This is\nprimarily because the dominance of 'feline' samples obscures the finer distinctions\nbetween 'cat' and 'lion'. By segregating 'cat' and 'feline' expertise, we ensure\nthat a segment of the latent dimension is exclusively dedicated to discerning\nbetween finer-grained categories."}, {"title": "D Experiments", "content": "In this work, we evaluate the performance of our proposed method\nacross several datasets to demonstrate its effectiveness and versatility. We conduct\nexperiments on four detailed datasets, namely Caltech-UCSD Birds-200-2011\n(CUB-200) [79], Fine-Grained Visual Classification of Aircraft (FGVC-Aircraft)\n[51], Stanford Cars [42], and Oxford-IIIT Pet [61], to assess its efficacy in fine-\ngrained image recognition tasks. These tasks require the identification of subtle\ndistinctions among highly similar categories, such as different bird species, aircraft\nmodels, car brands, and pet breeds, thereby posing significant challenges for image\nrecognition systems. Furthermore, we extend our evaluation to more general\ncoarse-grained datasets, including CIFAR10, CIFAR100 [43], and a subset of\nImageNet comprising 100 categories, referred to as ImageNet-100 [19]. This\nextension showcases the adaptability of our method to broader classification\nchallenges beyond fine-grained tasks. CIFAR10 and CIFAR100 feature coarse-\ngrained categories encompassing a wide range of objects, such as vehicles and\nanimals, while ImageNet-100 offers a diverse set of general categories from the\nlarger ImageNet dataset. To provide a comprehensive overview of our experiments,\nwe include a detailed summary of the datasets' characteristics, including their\nstatistical distribution and train/test splits, in Tab. 5.\nCUB-200 [79], or Caltech-UCSD Birds-200-2011, emphasizes the importance of\ndiscerning minute details across different bird species, underlining the complexity\nof fine-grained image recognition tasks.\nFGVC-Aircraft [51] challenges image recognition models with its focus on\naircraft, where variations in design significantly affect structural appearances,\nhighlighting the dataset's fine-grained nature."}, {"title": "D.1 Experimental Setup", "content": "Datasets. In this work, we evaluate the performance of our proposed method\nacross several datasets to demonstrate its effectiveness and versatility. We conduct\nexperiments on four detailed datasets, namely Caltech-UCSD Birds-200-2011\n(CUB-200) [79], Fine-Grained Visual Classification of Aircraft (FGVC-Aircraft)\n[51], Stanford Cars [42], and Oxford-IIIT Pet [61], to assess its efficacy in fine-\ngrained image recognition tasks. These tasks require the identification of subtle\ndistinctions among highly similar categories, such as different bird species, aircraft\nmodels, car brands, and pet breeds, thereby posing significant challenges for image\nrecognition systems. Furthermore, we extend our evaluation to more general\ncoarse-grained datasets, including CIFAR10, CIFAR100 [43], and a subset of\nImageNet comprising 100 categories, referred to as ImageNet-100 [19]. This\nextension showcases the adaptability of our method to broader classification\nchallenges beyond fine-grained tasks. CIFAR10 and CIFAR100 feature coarse-\ngrained categories encompassing a wide range of objects, such as vehicles and\nanimals, while ImageNet-100 offers a diverse set of general categories from the\nlarger ImageNet dataset. To provide a comprehensive overview of our experiments,\nwe include a detailed summary of the datasets' characteristics, including their\nstatistical distribution and train/test splits, in Tab. 5.\nCUB-200 [79], or Caltech-UCSD Birds-200-2011, emphasizes the importance of\ndiscerning minute details across different bird species, underlining the complexity\nof fine-grained image recognition tasks.\nFGVC-Aircraft [51] challenges image recognition models with its focus on\naircraft, where variations in design significantly affect structural appearances,\nhighlighting the dataset's fine-grained nature."}, {"title": "D.2 Additional Empirical Results.", "content": "Aggregated Performance on Different Kinds of Datasets. In this section,\nwe present a comparative analysis of our method against other approaches, as\n4 Our code is available at: https://github.com/SarahRastegar/SelEx"}, {"title": "D.3 Ablative Studies", "content": "Impact of varying labeled sample ratios for known categories. In this\nsection, we explore the impact of varying the proportion of labeled samples from\nknown categories during training on model performance. In the primary experi-\nments detailed in the main body of the text, labels were available for 50% of the\nsamples from known categories. As illustrated in Fig. 17, we investigate the conse-\nquences of altering the ratio of labeled samples, ranging from nearly 0%-which\nessentially positions the model as an unsupervised clustering approach to 100%,\nwhere the problem can be posed as novel class discovery. Notably, we observe\nan anticipated enhancement in performance for known categories as the volume\nof labeled samples increases. Intriguingly, the performance on novel categories\nremains robust, achieving a score of 68 with only a 20% labeling ratio, which is on\npar with the 50% ratio utilized in our main experiments. This finding indicates\nthat our model is capable of identifying novel categories effectively, even with a\nsignificantly reduced number of labeled samples for known categories.\nImpact of the Supervised and Unsupervised Mixing Hyperparameter\n\u03bb. In this section, we modulate the mix between supervised learning and unsu-\npervised self-expertise by varying the parameter A, assessing its impact on model\nperformance across different levels. The findings are summarized in Fig. 18. An\noverarching observation is that an increase in A generally enhances performance,\nparticularly in the context of novel category recognition. This improvement is\nattributed to our utilization of pseudo-labels for the supervision of novel cat-\negories, contrasting with the Generalized Category Discovery (GCD), which\nprioritizes optimization for known category classification, often at the expense of\noverall performance. The Self-Expertise (SelEx) approach, in contrast, leverages\npseudo-labels for novel category supervision, leading to superior performance"}, {"title": "E Discussion", "content": "A significant constraint of methodologies grounded in hierarchical structures lies\nin their inherent assumption of dataset hierarchies. In scenarios where the dataset\nlacks clear hierarchical organization, this presupposition could be detrimental.\nWhile our method, SelEx, endeavors to mitigate this limitation by dynamically\nallocating portions of the latent dimension to represent higher hierarchical levels,\nit does not completely circumvent the issue. Furthermore, SelEx presupposes a\nbalanced data distribution, a presumption that becomes particularly challenging\nin the context of datasets with a long-tailed distribution, such as the Herbarium\ndataset. This limitation highlights a critical area for further improvement and\nadaptation in our approach."}, {"title": "E.1 Limitations", "content": "A significant constraint of methodologies grounded in hierarchical structures lies\nin their inherent assumption of dataset hierarchies. In scenarios where the dataset\nlacks clear hierarchical organization, this presupposition could be detrimental.\nWhile our method, SelEx, endeavors to mitigate this limitation by dynamically\nallocating portions of the latent dimension to represent higher hierarchical levels,\nit does not completely circumvent the issue. Furthermore, SelEx presupposes a\nbalanced data distribution, a presumption that becomes particularly challenging\nin the context of datasets with a long-tailed distribution, such as the Herbarium\ndataset. This limitation highlights a critical area for further improvement and\nadaptation in our approach."}, {"title": "E.2 Future Works", "content": "Our work introduces SelEx as a"}]}