{"title": "Transformer-based Neuro-Animator for Qualitative Simulation of Soft Body Movement", "authors": ["Somnuk Phon-Amnuaisuk"], "abstract": "The human mind effortlessly simulates the movements of objects governed by the laws of physics, such as a fluttering, or a waving flag under wind force, without understanding the underlying physics. This suggests that human cognition can predict the unfolding of physical events using an intuitive prediction process. This process might result from memory recall, yielding a qualitatively believable mental image, though it may not be exactly according to real-world physics. Drawing inspiration from the intriguing human ability to qualitatively visualize and describe dynamic events from past experiences without explicitly engaging in mathematical computations, this paper investigates the application of recent transformer architectures as a neuro-animator model. The visual transformer model is trained to predict flag motions at the t+1 time step, given information of previous motions from t-n to t time steps. The results show that the visual transformer-based architecture successfully learns temporal embedding of flag motions and produces reasonable quality simulations of flag waving under different wind forces.", "sections": [{"title": "1 Introdcution", "content": "Human cognitive abilities, particularly in conceptualizing and predicting the dynamics of physical events through vivid mental simulations, present a captivating area of exploration. One notable aspect of this cognitive capability is the capacity to engage in complex visual simulations without relying on explicit mathematical computations, as one would in a physics class. This phenomenon raises the fundamental question of how the human mind achieves such imaginative feats, prompting researchers to seek alternative approaches t qualitatively simulate physical activities.\nIn the context of dynamic tasks, such as describing the motion of soft-body objects like cloth influenced by external forces or the trajectory of rigid-body objects like a bouncing ball, humans effortlessly generate mental simulations. Importantly, this mental imagery does not involve precise mathematical calculations, creating an apparent gap between mathematical computation and visual"}, {"title": "2 Background", "content": "The exploration of replicating human cognitive processes within the field of artificial intelligence (AI) has led to various research areas, with Qualitative Reasoning (QR) standing out prominently [1]. QR in AI involves reasoning about the continuous aspects of the physical world using qualitative values, such as high, low, stable, increment, and decrement, without delving into precise numerical values. This qualitative approach is valuable in scenarios where parameters required for evaluating quantitative values are not available, or in scenarios where swift responses are needed, and decision-making relies on approximate, qualitative aspects [2]."}, {"title": "2.1 Qualitative Simulation", "content": "One important aspect of QR is Qualitative Simulation (QSIM). QSIM operates on the premise of predicting outcomes from physical simulations without exact precision. Instead, QSIM provides an approximation of how outcomes might appear based on qualitative differential equations (QDEs) of the system, which express states of continuous mechanisms based on incomplete knowledge of the system [1]."}, {"title": "2.2 Mental Models", "content": "The concept that the brain constructs mental models was first articulated by Kenneth Craik in 1943 [5]. While human mental models can simulate complex physical systems for prediction, the nature and operational characteristics of these models remain poorly understood. Early work in AI explored both symbolic approaches, such as STRIPS [6], and sub-symbolic approaches, such as TD-Gammon [7], to construct models of observed environments.\nIn neuroscience and cognitive science, the term internal forward model refers to a computational framework that predicts the outcome of actions or movements based on the current state of the system and past experiences [8]. Various computational frameworks have been explored to develop these models. For instance, early work by Grzeszczuk et al. [9] introduced the neuro-animator, constructed from a shallow artificial neural network model. Casey et al. [10] proposed the animation transformer, which uses a transformer-based architecture to learn the spatial and visual relationships between segments across a sequence of images. Shannon et al. [11] developed a control model using process-description language and genetic programming. The explainability of these models remains elusive, prompting further investigation by many researchers. Phon-Amnuaisuk [12] investigated what was learned by a deep reinforcement learning model and suggested that trajectory of a ball (external physical mode) was captured in neural network weights when the agent was successfully trained to perform tasks. Battaglia and colleagues studied video game-based computer models and found that human physical reasoning aligns well with their computer model based on the Intuitive Physical Engine (IPE) framework [13]. The IPE introduces probabilistic variation to standard deterministic physics simulations, showing that human judgments closely match predictions from these simulations rather than the actual physical world. To further promote studies in this area, Bakhtin et al. proposed a benchmark for physical reasoning named PHYRE [14]."}, {"title": "2.3 Adapting Transformer Architecture for Movement Prediction Tasks", "content": "In the context of dynamic 3D-point arrays representing soft-body objects, the domain can be conceptualized as sequences of snapshots of the positions of points on a 2D flag. The desired mental model would accept sequences of snapshots and predict the next snapshot. Applying a visual transformer architecture to such dynamic sequences is a novel approach, adapting a technology initially designed for Natural Language Processing (NLP) tasks.\nAdapting the transformer architecture, originally designed to handle text sequences for NLP, to the domain of dynamic 3D-point arrays presents several novel challenges and considerations. These challenges include: (i) handling sequences of 2D vertex frames, (ii) enabling next-frame predictions within the transformer framework, and (iii) obtaining embedding tokens for dynamic 3D-point arrays."}, {"title": "Handling Sequences of Vertices Array", "content": "Unlike text sequences, where spatial information is inherently captured in the order of text tokens, sequences of vertices arrays representing soft-body movement through time encode both temporal and spatial dimensions, adding an extra layer of complexity. In visual transformers 1, 2D patches are assigned to each image frame, with each patch treated as a visual token, and spatial embeddings are applied to capture the contextual information within each patch. The same concept is extended to 3D vertices, where each patch along many frames forms a trajectory representing a 3D visual token. Extending 2D patches to 3D trajectories captures both temporal and spatial dependencies."}, {"title": "Next-Frame Prediction with Transformer Architecture", "content": "One of the primary objectives of our visual transformer model is to facilitate next-frame prediction, a task that inherently aligns with the dynamic nature of flag movement data. Achieving this within the transformer architecture requires careful consideration of how the model learns and represents temporal dependencies to predict the positions of vertices in a coherent and contextually relevant manner based on past movement."}, {"title": "Embedding Tokens for Visual Vocabulary", "content": "In the realm of NLP, a fixed vocabulary size can be predetermined due to the discrete nature of textual data. However, the visual domain poses a different challenge: how to effectively obtain embedding tokens for a visual vocabulary. Unlike text, visual content is inherently continuous and lacks a predefined set of discrete symbols. In visual transformers, embeddings from visual input are not constrained by a fixed vocabulary."}, {"title": "3 Problem Formulation", "content": "Given a rectangular piece of soft body object (i.e., here is a flag) with the flag dimensions i xj, where i denotes the number of particles per row and j the number of particles per column. The mechanical properties of the soft body object, such as stretching, shearing, and bending, can be effectively captured through a mass-spring model (see [16]). Within this framework, each particle located at position (x, y, z) and time t is denoted as Pt. The temporal evolution of the flag is observed by tracking the positions of particles over time, forming a trajectory of length n (see Fig. 1).\nA visual transformer architecture [15] can be employed to model the spatio-temporal patterns of particles representing flag motions. It is noteworthy that the transformer architecture, originally designed for the natural language domain, relies on fixed-size tokens for input and output vocabulary. However, the continuous nature of particle movements in a 3D space in our setup introduces an additional layer of complexity when abstracting non-fixed size tokens representing these motions in a 3D space.\nIn our formulation, we address this challenge by considering each particle's trajectory as a token. The transformer model then maps an array of these trajectories to the next time step, denoted as t + 1, based on observations from the previous n time steps. Mathematically, this can be expressed as:\nPij [P,...,PP \u2192 Pt+1 \n(1)\nIn this implementation, the flag is modeled as array of particles' positions oin 3D space with eleven rows and eleven columns, P11\u00d711\u00d73. Considering 64 time"}, {"title": "4 Transformer Regressor as a Neuro Animator", "content": "Input/Output Representation for the Transformer Model : When observing the flag's configuration over n discrete steps, the training data is constructed to predict the (n + 1)th step, here n = 64. The training pair (X, Y) is then formulated as X64\u00d711\u00d711\u00d73 = P,..., P and Y11\u00d711\u00d73 = Pt+1.\nHere, Pin,..., P; represents the historical positions of the corner point (i,j) up to n steps, and Put denotes the target position for the subsequent time step.\nThe tensor X was reshaped to a new tensor with size of (64, 121, 3). This forms 121 trajectories, each representing 64 time steps of a point in a flag in 3D space, allowing temporal information to be encoded in each trajectory. These"}, {"title": "Multi-Head Attention:", "content": "This implementation leverages the MultiHeadAttention layer from Keras. It takes three inputs, corresponding to Query, Key, and Value, (denoted as Q, K, and V, respectively). In this self attention case, all three inputs are set to the same input sequence. Eight multi-head attention mechanism were employed in this implementation, multiple attention heads enabled the model to attend to different parts of the input sequence simultaneously, allowing it to capture diverse patterns and relationships of the input sequence.\nhead; = Attention(QWQi, KWKi, VWvi)\nMultiHead(Q, K, V) = Concat(head1, ..., headh) Wo (2)\nwhere the input Q, K, and V are projected into different spaces for each attention head using the weight matrices WQi, Wki, and Wvi. The learned weight matrix Wo is used to project the concatenated outputs of all heads into the final output space."}, {"title": "Huber Loss:", "content": "In this implementation, the transformer regressor employed Huber loss. The Huber loss is a robust loss function that combines the best properties of mean squared error (MSE) and mean absolute error (MAE).\nLs(y, f(x)) = (y \u2212 f(x))\u00b2 if |y \u2212 f(x)| \u2264 d\n\u03b4 (y \u2212 f(x) - 8) otherwise (3)\nwhere y is the true target value, f(x) is the predicted value by your model, and d is a hyperparameter that determines the point at which the loss transitions from quadratic to linear."}, {"title": "5 Simulating Flag Motions by Prediction", "content": ""}, {"title": "5.1 Preparing Data Set", "content": "Let C be a piece of rectangular cloth (a soft body object representing a flag) with w \u00d7 h particles, where there are w particles per row and h particles per column. The soft body object can be modeled using a mass-spring model which captures the mechanical properties of stretching, shearing and bening of the frabic 2. In a mass-spring model, each particle p(i, j) where i,j is the particle index, has a certain mass, and is connected to another particle with a spring and"}, {"title": "5.2 Results and Discussion", "content": "Details of the transformer-based animator model, including the parameter settings and the overall process, are described in Algorithm 1 and Fig. 2. The model was built from scratch, leveraging Keras and the Transformer API. The Adam optimizer and Huber loss function were employed during training. The total number of trainable parameters was approximately 1.6 million after the model was compiled."}, {"title": "Qualitative Simulation as Prediction", "content": "With the configured model, training data were fed into the model, which learned to make predictions based on the input-target pairs and adjusted its internal parameters to minimize the defined loss function. The predictions are points in 3D space that are rendered back as flag motions.\nThe trained model is used as an auto-regressive prediction model, where the current prediction is used as the input in the next time step. Three sets of flag motions under the influence of three different wind strengths are shown in Fig. 3 (middle pane). The bottom pane of Fig. 3 shows 121 plots. The plots in the leftmost columns are particles next to the fixed pole, hence particles' position (x, y, z) are fixed. The plots in the rightmost columns are at the boundary and are much more active as expected.\nTo objectively quantify model performance, frame prediction errors calculated from summation of discrepancies between targets and predicted points |Pt+1 - Pt+1| are averaged over all test data (approximately 1000-1500 frames for each win strength) where Pi,j \u2208 [-1,1]. The mean \u00b5 and standard deviation \u03c3are as follows: (i) strong wind: \u03bc = 0.014, \u03c3 = 0.005; (ii) moderate wind: \u03bc = 0.025, \u03c3 = 0.007; and (iii) no wind: \u03bc = 0.018, \u03c3 = 0.004."}, {"title": "6 Conclusion", "content": "This study draws inspiration from the innate human ability to mentally visualize dynamic events. It proposes that animation can be simulated based on memory recall from past experiences. Consequently, the model developed here does not focus on modeling control parameters for animating the 3D flag model but instead predicts the positions of the 3D flag directly.\nWe leverage the transformer model to learn the continuous nature of flag movement. The flag's spatio-temporal embeddings are captured using trajectory-based self-attention mechanisms within the transformer architecture. This approach enables the transformer model to learn and represent visually engaging movements, akin to the human mind's ability to simulate dynamic scenarios without explicit computational models, such as those commonly found in physics textbooks. Visual evaluations indicate that the generated flag motions appear believable. However, there is considerable room for improvement in terms of the naturalness of the motions (i.e., avoiding the uncanny valley)."}]}