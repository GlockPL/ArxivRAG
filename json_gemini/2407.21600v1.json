{"title": "Robust Simultaneous Multislice MRI Reconstruction Using Deep Generative Priors", "authors": ["Shoujin Huang", "Guanxiong Luo", "Yuwan Wang", "Kexin Yang", "Lingyan Zhang", "Jingzhe Liu", "Hua Guo", "Min Wang", "Mengye Lyu"], "abstract": "Simultaneous multislice (SMS) imaging is a powerful technique for accelerating magnetic resonance imaging (MRI) acquisitions. However, SMS reconstruction remains challenging due to the complex signal interactions between and within the excited slices. This study presents a robust SMS MRI reconstruction method using deep generative priors. Starting from Gaussian noise, we leverage denoising diffusion probabilistic models (DDPM) to gradually recover the individual slices through reverse diffusion iterations while imposing data consistency from the measured k-space under readout concatenation framework. The posterior sampling procedure is designed such that the DDPM training can be performed on single-slice images without special adjustments for SMS tasks. Additionally, our method integrates a low-frequency enhancement (LFE) module to address a practical issue that SMS-accelerated fast spin echo (FSE) and echo-planar imaging (EPI) sequences cannot easily embed autocalibration signals. Extensive experiments demonstrate that our approach consistently outperforms existing methods and generalizes well to unseen datasets. The code is available at https://github.com/Solor-pikachu/ROGER after the review process.", "sections": [{"title": "I. INTRODUCTION", "content": "Accelerating magnetic resonance imaging (MRI) is important for capturing subtle spatial/temporal information, im-proving patient throughput, and minimizing motion artifacts. Simultaneous multislice (SMS) imaging [1]\u2013[4] addresses this by using multiband (MB) radio-frequency pulses to acquire multiple slices simultaneously, effectively reducing scan time and/or improving slice coverage. Unlike in-plane acceleration, which suffers from intrinsic signal-to-noise ratio (SNR) loss due to k-space undersampling, SMS acquisitions benefit from improved SNR efficiency due to Fourier averaging [4].\nDespite its advantages, SMS MRI presents considerable reconstruction challenges. The simultaneous acquisition of multiple slices results in inter-slice signal interactions and potential artifacts. Traditional SMS reconstruction methods [1], [3], [5]\u2013[7] are adapted from classical parallel imaging techniques, often suffering from noise amplification and residual aliasing artifacts. Improved iterative approaches [8]\u2013[12], introduce additional regularization to stabilize the reconstruction but still struggle with ill-conditioning at high acceleration settings.\nRecent advancements in deep learning have shown promise for improving MRI reconstruction quality [13]. Supervised learning methods [14]\u2013[16], have been successfully demonstrated on in-plane accelerated MRI, leveraging large datasets to learn the reconstruction mappings. These models may also be adapted to SMS reconstruction by training on SMS-accelerated and fully sampled k-space pairs [17] or in self-supervised manners [18]. However, supervised deep learning methods may not generalize well to unseen data, such as those with different acquisition parameters, aliasing patterns, and coil sensitivity distributions.\nRecently, the use of generative models has emerged as a potentially more robust approach for MRI reconstruction [19]\u2013[26]. Generative models can learn data distributions as priors in solving the inverse problem of MR reconstruction. This flexibility allows generative models to adapt to a variety of MRI reconstruction tasks. However, the application of generative models to SMS reconstruction has not been studied to the best of our knowledge, and this is not straightforward for the following reasons.\nFirstly, the forward model of SMS imaging is not conventional k-space subsampling. This process includes encoding multiple 2D slices by different coil sensitivity maps, phase cycling for Controlled Aliasing in Parallel Imaging Results in Higher Acceleration (CAIPI) shifts [1], and the summation of signals into a single 2D matrix. This complexity, combined with the variations in MB factors (number of simultaneously"}, {"title": "II. BACKGROUND", "content": "SMS MRI reconstruction can be approached using several different frameworks [2], [3], [5], [31]\u2013[33] for handling the complexities of SMS encoding and signal separation.\nClassical slice-SENSE method [32] utilizes known coil sensitivity profiles to separate signals from simultaneously acquired slices in pure image domain. GRAPPA-based methods [34] offer another approach to SMS reconstruction based on k-space interpolation. While SENSE-GRAPPA [5] extends the field of view (FOV) along phase encoding direction and applies traditional GRAPPA methods to solve for aliased signals, slice-GRAPPA [3] reconstructs the data directly into separated slices without needing to create an extended FOV. An improved implementation of slice-GRAPPA is split slice-GRAPPA (SPSG) [7], which trains kernels not only to reconstruct the target slice but also suppress erroneous mappings to other slices. This approach mitigates slice leakage issue and improves temporal signal-to-noise ratio (tSNR).\nSMS reconstruction can also be reformulated using the readout concatenation framework [2], [9], [35]\u2013[37], which transforms SMS encoding as a one-dimensional in-plane acceleration along the readout direction. In this approach, the slices to be reconstructed are viewed as spatially concatenated, forming a single 2D image with the FOV extended MB times along the readout direction. Consequently, SMS acceleration can be characterized as a uniform k-space subsampling in this extended readout direction, with optional in-plane undersampling incorporated in the phase encoding dimension. Thus, the forward model for ROC based SMS reconstruction is given by:"}, {"title": "A. Related Work and Problem Formulation", "content": "y = ARx_{ms} + \u03b7    (1)\nwhere x_{ms} = {x_1, x_2, x_3, ..., x_{MB} } are the slice images to be reconstructed, MB is the number of simultaneously acquired slices, \u03b7 is complex Gaussian noise, R represents the combined data reorder operations of ROC (readout concatenation) and CS (CAIPI shift), and A is SENSE encoding operator. A can be further breakdown to PFS where Fis two-dimensional Fourier transform, S coil sensitivity maps, and P k-space subsampling. We adopt this ROC framework for applying SMS data consistency terms in this study."}, {"title": "B. Denoising Diffusion Probabilistic Models", "content": "Diffusion models are probabilistic generative models that express image generation as a temporal Markov process. DDPM defines a T-step forward and reverse diffusion process [38]. The forward process adds random Gaussian noise to image, while the reverse process constructs desired data samples from the Gaussian noise.\n1) Forward Diffusion: The forward process yields the present state xt from the previous state xt-1. At step t, the relationship between t and t \u2212 1, along with the conditional distribution q(xt | xt-1), is specified as follows:\nq(x_t|x_{t-1}) = CN(x_t; \\sqrt{1 - \\beta_t}x_{t-1}, \\beta_t I)     (2)\nx_t = \\sqrt{1 - \\beta_t}x_{t-1} + \\sqrt{\\beta_t}z, z ~ CN(0, I),   (3)\nwhere \u03b2t follows a pre-defined schedule {\u03b20, \u03b21,..., \u03b2T} which is an increasing sequence of t. xt converges to isotropic Gaussian noise after a large number of forward steps. Following re-parameterization method [39], the two equations become:\nq(x_t|x_0) = CN(x_t; \\sqrt{\\bar{a}_t}x_0, (1 - \\bar{a}_t)I)    (4)\nx_t = \\sqrt{\\bar{a}_t}x_0 + \\sqrt{1 - \\bar{a}_t}z, z ~ CN(0, I),   (5)\nwith \\bar{a}_t := \\prod_{s=1}^{t} a_s, a_t := 1 \u2212 \u03b2t. Intuitively for every training step, DDPM randomly picks a clean image x0 from the high-quality dataset and samples a noise z ~ CN(0, I), then picks"}, {"title": "III. METHODOLOGY", "content": "Alike many diffusion model-based techniques, reconstruction is one of the samples from the posterior distribution which is formulated with two components: 1) the likelihood term to describe the data consistency; 2) the diffusion prior trained on image dataset.\nAs illustrated in Fig. 1, our proposed SMS reconstruction ROGER employs DDPM to provide slice-wise learned probability distributions [22], [41], and the data consistency terms are applied through ROC framework.\nGiven multi-coil measurements y which are acquired SMS data across all coils, our goal is to find proper xms that contains the slices {x1, x2,x3, ..., \u706dMB} satisfying Eq. 1.\nFrom Eq. 9, we initialize the xms from random noise z ~ CN(0, I), and the reverse diffusion process is"}, {"title": "A. SMS Reverse Diffusion Sampling", "content": "x^{ms}_{0|t} = \\frac{1}{\\sqrt{a_t}} (x^{ms}_t - \\sqrt{1 - \\bar{a}_t}  \\epsilon_{\\theta}(x^{ms}_t))    (11)\nFor MRI reconstruction and more general image restoration tasks, it is required to equip the iterations with data consistency (fidelity) guidance [19]\u2013[25], [42]\u2013[46]. This guidance is typically based on the gradient of a data consistency term. Hence, to finally yield xms satisfying ARxms = y, we enforce that xsatisfies the data consistency constraint  x^{ms}_t - (AR)^H(ARx^{ms}_t - y), and thus we have\nx^{ms}_t = x^{ms}_t - \\lambda (AR)^H(ARx^{ms}_t - y) (12)"}, {"title": "B. Low-Frequency Enhanced Module", "content": "In practice, SMS-accelerated FSE and EPI sequences cannot easily embed autocalibration signals (ACS). The absence of low-frequency renders reconstruction challenging as the information for object shape and tissue contrasts is not available. To address this issue, we propose a simple yet effective low-frequency enhancement (LFE) method that uses GRAPPA to interpolate in the central k-space of the ROC data. Specifically, we first estimate the GRAPPA kernels from a calibration scan.\n\\text{kernel} o^{GRAPPA} = R(\\text{calibrations})   (14)\nThe estimated kernelo are then utilized to predict the missing k-space points in the low-frequency region:\ny' = LFE_s(kernelo, y)   (15)\nwhere s is the LFE size, i.e., size of estimated low-frequency area. This hyperparameter is fixed to be 8 in this study. The mask in A will be updated to preserve both the LFE estimated and original data.\nIn summary, our reconstruction algorithm can be described with the pseudo code below."}, {"title": "IV. EXPERIMENTS", "content": "First, three raw k-space datasets were used with retrospective SMS acceleration to evaluate our method:\n1) The public fastMRI brain dataset [47]. In brief, this dataset includes brain anatomical imaging data acquired on 1.5T and 3T magnets. The official training set was used to train our model (see \"Method Comparison and Implementation Details\" for details). In the training set, the majority were T2-weighted scans (2678 volumes), with the rest being T1-weighted (1447 volumes) and fluid attenuated inversion recovery (FLAIR) scans (344 volumes). We randomly selected 16 scans of T2-weighted contrast from the official validation set for method evaluation. Note that for data de-identification, this dataset does not contain any slices more than 5mm below the orbital rim [47].\n2) An in-house clinical dataset (Longgang). It included T1-weighted and T2-FLAIR images from 8 subjects with white matter lesions, acquired using a 3T Siemens scanner equipped with a 20-channel head coil. The common scan parameters were FOV = 220 mm and slice thickness/gap = 5/1.5 mm. For T1-weighted scans, TR/TE = 250/2.49 ms, flip angle (FA) = 70\u00b0, and matrix size = 320\u00d7288. For FLAIR, TR/TE/TI = 8000/84/2370 ms, refocusing FA = 150\u00b0, and matrix size = 320\u00d7224.\n3) An in-house T2-FSE dataset (Huaxin) from 4 healthy volunteers using a 3T GE scanner equipped with a 21-channel head coil. This dataset has whole brain coverage including the cerebellum and brainstem. The scan parameters were TR/TE = 4784/100 ms, refocusing FA = 111\u00b0, matrix size = 256\u00d7256, FOV = 220 mm, slice thickness/gap = 3/0.3 mm, 48 slices.\nFor retrospective acceleration, we experimented with MB factors of 3 and 4, and in-plane acceleration R factors of 2 and 3, resulting in four acceleration combinations: MB3R2, MB3R3, MB4R2, and MB4R3. This notation, MBxRy, will be used in the following sections to denote the specific acceleration settings.\nAdditionally, two prospectively SMS-accelerated datasets were used to further validate our methods:\n1) Prospectively SMS-accelerated T2-FSE data from one healthy subject at MB3R3 and MB4R2 using a 3T Siemens scanner equipped with a 64-channel head coil. The scan parameters were TR/TE = 6000/100 ms, refocusing FA = 150\u00b0, matrix size = 320\u00d7320, FOV = 220 mm, slice thickness/gap = 2/0.4 mm, and 30 slices. The vendor-provided SMS sequence was used, which acquired separate coil calibration data for each slice (see supplementary material for visualization). Additionally, fully sampled T2-FSE data were acquired as a reference for desired image quality.\n2) Prospectively SMS-accelerated gradient echo single-shot EPI data from six healthy subjects at MB4R2, MB2R2, and MB1R1 (i.e., no acceleration), using a 3T GE scanner equipped with an 21-channel head coil. The vendor-provided SMS sequence was used and common scan parameters were matrix size = 128\u00d7128, FOV = 220 mm, slice thickness/gap = 3/0.3 mm, and 48 slices. For MB1R1, TR/TE = 4480/30 ms, FA = 90\u00b0; for MB2R2, TR/TE = 2240/30 ms, FA = 84\u00b0; for MB4R2, TR/TE = 1120/30 ms, FA = 71\u00b0."}, {"title": "A. Datasets", "content": "For all in-house datasets, subjects provided written informed consent, in accordance with the approval from the Institutional Review Board of Shenzhen Technology University (reference number: SZTULL012021005)."}, {"title": "B. Method Comparison and Implementation Details", "content": "We compared our method with k-space interpolation techniques (RO-GRAPPA [2] and SPSG [7]), traditional iterative methods (L1-wavelet SENSE [48] and ROCK [9]), and a supervised deep learning method, end-to-end variational network (VarNet) [16].\nFor RO-GRAPPA, SPSG, L1-wavelet, and ROCK, we used the central 64\u00d764 k-space region as the calibration signal. For L1-wavelet and ROCK, we estimated coil sensitivity maps (CSMs) using the ESPIRIT [48] method from the central 30\u00d730 k-space region.\nFor deep learning methods, VarNet and our method (ROGER), models were trained on the official fastMRI brain training set. We removed the last four noisy slices from each volume, resulting in approximately 52k slice images for training. The models were then used to infer on all other datasets without retraining, except for SMS EPI, where light fine-tuning was performed.\nFor VarNet, paired SMS data and fully sampled data were created under the ROC framework and used to train VarNet weights for 50 epochs with the official settings [47]. For ROGER, multi-coil images were coil-combined using ESPIRIT and then used to train the diffusion generative model. The complex-valued images were split into real and imaginary components, each serving as a separate channel. Guidance scaling factor A was set to 2 and the LFE size to 8. We adopted the UNet network with multi-resolution attention as the DDPM architecture, using code from guided diffusion [38], [49]. Training was conducted with forward/reverse step of 1000, learning rate of 1 \u00d7 10\u22124, batch size of 8, 2 \u00d7 105 iterations, and the Adam optimizer.\nFor the SMS EPI data, to address geometric distortion mismatch issue [27], [50], [51], MB1R1 data were used first to train GRAPPA kernels to reconstruct MB2R2 images, which were then to generate CSMs for MB4R2. This provides a better geometry match between the coil sensitivity maps and the SMS data due to the same in-plane acceleration factors."}, {"title": "C. Performance Evaluation", "content": "Peak signal-to-noise ratio (PSNR) and the structural similarity index (SSIM), were used to measure the reconstruction performance. Specifically, evaluations were performed between slices. The larger PSNR and SSIM, indicate a better reconstruction.\nFor prospective acceleration, no perfect ground truth is available due to potential subject motion, different geometry distortion and slightly different contrast. We visually evaluated the reconstructed image quality compared with fully sampled data and additionally calculated the tSNR maps for the EPI images using 50 frames."}, {"title": "V. RESULTS", "content": "This section presents both quantitative and qualitative reconstruction results. We first evaluate the methods on two retrospectively SMS-accelerated datasets. Next, we assess performance on unseen anatomical regions and prospectively SMS-accelerated FSE and EPI. Finally, the impact of EPI fine-tuning sample size and the effectiveness of the LFE module are analyzed."}, {"title": "A. Evaluation on Public and In-House Clinical Datasets", "content": "Table. I presents the quantitative reconstruction results for retrospective SMS acceleration on the fastMRI and Longgang datasets. Our method ROGER achieved the highest scores at all acceleration factors for both datasets.\nRepresentative reconstruction results are presented in Fig. 2. GRAPPA and SPSG exhibited noticeable reconstruction noise, while L1-wavelet SENSE and ROCK showed aliasing artifacts. The results of VarNet were satisfactory, with a higher signal-to-noise ratio and fewer aliasing artifacts than traditional methods. However, VarNet failed to reconstruct many fine details and erroneously presents some white matter lesions as fake structures. In contrast, our method demonstrated the highest reconstruction quality, clearly revealing anatomical structures and small white matter lesions."}, {"title": "B. Evaluation on Unseen Brain Regions", "content": "Since the fastMRI training data does not contain slices more than 5mm below the orbital rim [47], we used the retrospectively accelerated Huaxin dataset, covering the whole brain, including the cerebellum and brainstem, to evaluate our method on unseen anatomical regions. As indicated by the mean PSNR/SSIM values in Table II and the visualization in Fig. 2 at MB4R2 acceleration, our algorithm achieved the best results among all methods again, despite not being trained on the inferior brain regions. Slice-level analysis presented in Fig. 3 revealed that our algorithm maintained superior performance on all slices with stable PSNR/SSIM advantages."}, {"title": "C. Evaluation on Prospectively Accelerated SMS FSE", "content": "The results of prospective SMS FSE acceleration agree with the findings with retrospective acceleration. As presented in"}, {"title": "D. Evaluation on Prospectively Accelerated SMS EPI", "content": "EPI is an ultra-fast imaging sequence, and has very different tissue contrast, image phase distribution, geometry distortion, and matrix sizes to regular anatomical images such as T2-FSE [27]. Therefore, for SMS EPI reconstruction using deep learning methods (i.e., VarNet and ROGER), we randomly selected 3 out of the 6 subjects as the training samples to fine-tune the model from fastMRI weights. From each subject, only one frame of the MB1R1 images and one frame of the GRAPPA reconstructed MB2R2 images were used for fine-tuning after discarding the top and bottom three slices. Thus, in total, only 252 slice images were used for fine-tuning. We used a learning rate of 1 \u00d7 10-4, batch size of 8, iterations of 4 \u00d7 104, and Adam optimizer.\nThe MB4R2 EPI data from the remaining three subjects were used as test set. As shown in Fig. 6, our method ROGER resulted in remarkably higher SNR and fewer artifacts than other methods. Moreover, our reconstruction led to consistently high tSNR across all brain regions."}, {"title": "E. Impact of Sample Sizes on EPI Fine-Tuning", "content": "In addition, we studied the impact of fine-tuning sample size on SMS EPI reconstruction quality. Fig. 7 shows the reconstruction results of one subject without fine-tuning ROGER and with fine-tuning using data from one, three, and five subjects, respectively. Without fine-tuning, the fastMRI-trained model produced noticeable artifacts due to large differences between EPI and anatomical imaging. Fine-tuning with one subject immediately improved image quality. Fine-tuning with three subjects resulted in further improvements, with no noticeable artifacts, while using five subjects yielded similar quality as three subjects. These results indicate that our method has strong generalization ability and can be applied to different datasets with minimal training resources."}, {"title": "F. Effect of LFE Module", "content": "Fig. 8 records the PSNR and SSIM scores of fastMRI reconstruction with different LFE sizes (i.e., sizes of GRAPPA interpolated k-space). As the LFE size increased from 0 (not using LFE) to approximately 8 (the setting in this study), our method showed marked improvement. However, excessively increasing the LFE size is not advisable, as the model performance declined with LFE sizes larger than 12, likely due to the interpolation errors introduced by the LFE module. Such decline was more pronounced for higher acceleration (MB3R3 and MB4R3) than lower acceleration (MB3R2 and MB4R2). Nevertheless, a stable range for the LFE size existed between 4 and 12, across various acceleration factors, to consistently achieve high SNR and SSIM scores. This observation is also visualized in Fig. 9."}, {"title": "VI. DISCUSSION", "content": "Our study introduces a novel approach SMS MRI reconstruction by integrating readout concatenation (ROC) with deep generative priors using denoising diffusion probabilistic models (DDPM). Our method outperforms existing techniques, achieving higher PSNR and SSIM while preserving anatomical details and reducing artifacts under various conditions.\nOur method utilizes the ROC framework to apply data consistency terms, and reverses the ROC operation before applying the generative prior in each iteration. This approach ensures that data consistency terms are enforced properly while allowing the deep generative prior to be trained routinely on single-slice images without specific adjustments for SMS tasks. Without such decoupling, the prior would require complicated training on ROC images.\nAnother key innovation in our method is the low-frequency enhancement (LFE) module, which enhances reconstruction quality, especially at high acceleration factors. In principle, the LFE module can also be implemented with other methods [52]\u2013[54], and its optimization constitutes future studies.\nDeep learning has profoundly impacted MRI reconstruction, yet ensuring robustness across diverse scanning conditions remains a challenge. These variations include differences in scanner hardware, imaging sequences, and scanning parameters. Through validation on multiple datasets, our method is demonstrated highly robust against most of these factors without necessitating retraining. Even for challenging scenarios on EPI, minimal fine-tuning is sufficient. While our method provides a strong foundation, optimal performance in specialized applications might still benefit from tailored strategies [55]. The potential for broader applications, including cardiac [9], knee [29], and abdominal imaging [28], suggests exciting avenues for future research.\nOur method has a few limitations. It relies on coil sensitivity maps (CSMs) estimated using ESPIRIT [48], whose performance varies with calibration data quality. Additionally, the current setting of 1000 iterations incurs high computational loads for reconstruction (2-3 min/slice on an RTX 4090 GPU). Improving CSM estimation and reconstruction speed [56], [57] are crucial for future research."}, {"title": "VII. CONCLUSION", "content": "In this study, we proposed a robust image reconstruction method for SMS MRI. It offers superior image reconstruction quality and high generalization ability, potentially benefiting a wide range of applications."}]}