{"title": "TS-ACL: A TIME SERIES ANALYTIC CONTINUAL LEARNING FRAMEWORK FOR PRIVACY-PRESERVING AND CLASS-INCREMENTAL PATTERN RECOGNITION", "authors": ["Kejia Fan", "Jiaxu Li", "Songning Lai", "Linpu Lv", "Anfeng Liu", "Jianheng Tang", "Houbing Herbert Song", "Huiping Zhuang"], "abstract": "Class-incremental Learning (CIL) in Time Series Classification (TSC) aims to incrementally train models using the streaming time series data that arrives continuously. The main problem in this scenario is catastrophic forgetting, i.e., training models with new samples inevitably leads to the forgetting of previously learned knowledge. Among existing methods, the replay-based methods achieve satisfactory performance but compromise privacy, while exemplar-free methods protect privacy but suffer from low accuracy. However, more critically, owing to their reliance on gradient-based update techniques, these existing methods fundamentally cannot solve the catastrophic forgetting problem. In TSC scenarios with continuously arriving data and temporally shifting distributions, these methods become even less practical. In this paper, we propose a Time Series Analytic Continual Learning framework, called TS-ACL. Inspired by analytical learning, TS-ACL transforms neural network updates into gradient-free linear regression problems, thereby fundamentally mitigating catastrophic forgetting. Specifically, employing a pre-trained and frozen feature extraction encoder, TS-ACL only needs to update its analytic classifier recursively in a lightweight manner that is highly suitable for real-time applications and large-scale data processing. Additionally, we theoretically demonstrate that the model obtained recursively through the TS-ACL is exactly equivalent to a model trained on the complete dataset in a centralized manner, thereby establishing the property of absolute knowledge memory. Extensive experiments validate the superior performance of our TS-ACL.", "sections": [{"title": "1 Introduction", "content": "Time series classification (TSC) plays a pivotal role in various fields such as healthcare [1] and industry [2], attracting substantial research attention in recent years. Although deep learning methods for TSC have gained widespread popularity due to their superior performance, these methods are typically trained on offline static datasets that assume data to be independently and identically distributed (i.i.d.) [3]. In contrast, real-world scenarios involve sensors that continuously collect data, leading to an ever-increasing volume of time series information, where the i.i.d. assumption often does not hold [4]. Moreover, new data with previously unseen classes may emerge over time, further adding complexity to the dataset [4]. This dynamic environment necessitates the continual updating of models to learn new knowledge from incremental samples, which unfortunately suffers from the well-known problem of \u201ccatastrophic forgetting\", where models tend to forget previously learned information upon learning new samples [5, 6].\nIn response to this, numerous Class-incremental Learning (CIL) methods have been developed to alleviate the problem of catastrophic forgetting. Specifically, these methods can be categorized into two types: the replay-based methods [7, 8, 9] and the example-free methods [10, 11, 4]. The replay-based methods store the historical samples or use generative models to produce historical samples for training, thereby alleviating the problem of catastrophic forgetting [7, 8, 12]. Although some replay-based methods achieve commendable performance, their necessity of storing historical samples inevitably raises concerns regarding user privacy [13]. Additionally, the example-free methods attempt to protect previously learned knowledge by incorporating additional terms into the loss function or by explicitly designing and manipulating the optimization process [10, 6]. While these methods eliminate the need to store historical samples and safeguard user privacy, they often suffer from suboptimal performance, making it challenging to meet practical user requirements [14].\nHowever, more critically, owing to their reliance on gradient-based back-propagation update techniques, these methods fundamentally cannot solve the problem of catastrophic forgetting [5]. Specifically, the gradients computed from the current task's dataset may conflict with, or even directly oppose, those derived from historical data. As a result, updating the model based on these conflicting gradients inevitably leads to the forgetting of previously acquired knowledge. Furthermore, in the context of TSC, new data samples arrive continuously, necessitating the more frequent implementation of incremental learning [4, 3]. Traditional methods become even less practical in real-world applications due to the problem of catastrophic forgetting.\nTo tackle these limitations, we introduce a Time Series Analytic Continual Learning framework, named TS-ACL, to achieve absolute knowledge memory without forgetting. Specifically, TS-ACL leverages analytic learning, transforming the updating of neural networks into solving linear regression problems, thereby eliminating the need for gradient-based updates and fundamentally addressing the problem of catastrophic forgetting. In each task, TS-ACL requires only a few recursive analytic matrix operations, enabling lightweight and efficient model updates. Theoretical analysis and extensive experimental evaluations have verified the effectiveness of TS-ACL, demonstrating significant improvements over existing baseline methods.\nTo sum up, the main contributions of our work are as follows.\n1. We propose a novel TS-ACL mechanism, which innovatively incorporates analytic learning into the time series CIL scenario. This novel integration fundamentally addresses the problem of catastrophic forgetting, ensuring that previously acquired knowledge is preserved without degradation as new samples arrive.\n2. In each task, TS-ACL requires only a few recursive lightweight matrix operations, highly suitable for real-time applications and large-scale data processing.\n3. Theoretical analysis demonstrates that the model obtained recursively through the TS-ACL mechanism is exactly equivalent to the model trained on the complete dataset in a centralized manner. This result confirms the property of absolute knowledge memory inherent in our mechanism.\n4. Comprehensive experiments have been conducted to validate the state-of-the-art performance of the TS-ACL mechanism. The results show that TS-ACL significantly outperforms baseline models.\""}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Time Series Classification", "content": "TSC aims to assign categorical labels to time series data based on its patterns or characteristics, playing an increasingly important role in numerous domains [1, 2, 15]. In the early stages of research, most approaches to TSC relied on non-deep learning methods, primarily including distance-based methods [16, 17] and ensembling methods [18, 19]. The distance-based methods rely on different time series distance measurement techniques, such as dynamic time warping"}, {"title": "2.2 Class-incremental Learning", "content": "In recent years, numerous studies on CIL have emerged to alleviate the problem of catastrophic forgetting [6, 10, 9]. These studies can be broadly categorized into two main types: the replay-based methods [7, 8, 7] and the example-free methods [10, 11, 4]. The replay-based methods store a subset of historical samples and replay them during incremental training, thereby alleviating the problem of catastrophic forgetting [8, 12]. Meanwhile, the example-free methods attempt to preserve prior knowledge by incorporating additional terms into the loss function or by explicitly designing and manipulating the optimization process [11, 4].\nHowever, in practice, the example-free methods often struggle to effectively constrain the model's optimization process, as their performance generally falls short of that achieved by the replay-based methods [14]. Despite some replay-based methods achieving satisfactory results, they rely on the storage of historical data, which raises concerns about user data privacy [8, 9]. More critically, these methods depend on gradient-based updating techniques, which fundamentally do not solve the problem of catastrophic forgetting [5]. This limitation makes them unsuitable for scenarios that require frequent incremental updates in TSC contexts."}, {"title": "2.3 Analytic Learning", "content": "Analytic learning, as a distinct technical pathway from gradient-based methods, has attracted considerable research attention in recent years [23, 24]. Specifically, the main idea of analytic learning is to directly compute the parameters of neural networks using mathematical methods such as least squares, thereby eliminating the need for gradients [23, 13]. For example, the radial basis network [25] use least-squares estimation to train parameters after the kernel transformation in the first layer. The multilayer analytic learning [26] transforms nonlinear network learning into segments, and efficiently solves this problem using least-squares techniques in a single-epoch training process.\nWe particularly note that the gradient-free characteristic of analytic learning holds promise for fundamentally resolving the problem of catastrophic forgetting. In response, we need to meticulously design a set of recursive computational methods tailored to match the CIL scenario, thereby achieving absolute knowledge memory without forgetting."}, {"title": "3 METHOD", "content": ""}, {"title": "3.1 Preliminaries", "content": "Let the network be continually trained for T tasks where the training data of each task comes with different classes. Let $D_{train}^t \\sim \\{Z_{train}^t, Y_{train}^t\\}$ and $D_{test}^t \\sim \\{Z_{test}^t, Y_{test}^t\\}$ be the training and testing datasets at task t (t = 1,...,T). $Z_t \\in \\mathbb{R}^{N_t \\times c \\times l}$ (e.g., Nt time series with a shape of c \u00d7 l) and $Y_{train}^t \\in \\mathbb{R}^{N_t \\times d_{y_t}}$ (with task t including $d_{y_t}$ classes) are stacked input and label (one-hot) tensors.\nIn Class-Incremental Learning (CIL), the classes learned in different tasks are independent and non-overlapping. Specifically, for each task t, the network learns from the new datasets $D_{train}^t$ and $D_{test}^t$, where the classes of the data differ from those of previous tasks. In other words, in task t, the training and testing data labels $Y_{train}^t$ and $Y_{test}^t$ belong to a task-specific class set Ct, and these class sets are disjoint from the class sets of other tasks $C_{t'}$ (for t' \u2260 t). As a result, the data from different tasks exhibit distinct class distributions. In the task of continual learning for time series data, a deep neural network can be represented as a feature extractor encoder $f_{encoder}$ and a classifier head $\\Phi_{FNN}$, where the final prediction is given by $\\hat{Y} = \\Phi_{FNN} \\circ f_{encoder}(Z)$. For each task t, the training objective of the model is to leverage the network parameters from the previous task $\\Theta_{t-1}$ and the current dataset $D_{train}^t$ to learn new parameters \u0398t."}, {"title": "3.2 BP-based Training", "content": "First, we use the BP method to train a regular classification network on the basic training set, which usually includes multiple training epochs. Theoretically, it can be composed of any commonly used network structure with a regular classifier. After BP training, the output Y of the network can be expressed as:\n$Y = f_{softmax}(f_{flat}(f_{encoder}(Z, \\Theta_{encoder}))\\Phi_{FNN})$\nWhere $\\Theta_{encoder}$ and $\\Phi_{FNN}$ are the parameters representing the encoder network and the fully connected classifier, $f_{encoder}(Z, \\Theta_{encoder})$ represents the encoder output, $f_{softmax}$ and $f_{flat}$ are the softmax function and the flattening operator. After training, we save and freeze the encoder weights. In the subsequent steps, it will be used to retrain in conjunction with the analytic classifier."}, {"title": "3.3 AL-based Re-alignment", "content": "Upon completing BP-based training, we proceed with the CIL step using concatenated recursive least squares (C-RLS) in a recursive and analytical manner. This process is carried out by the analytic classifier as the core mechanism. Briefly, the procedure consists of three main steps:\nThe first step involves extracting the feature matrix (denoted as $Z_1^{(encoder)}$) by passing the input tensor $Z_{train}^{train}$ through the trained encoder network, followed by a flattening operation, i.e.,\n$Z_1^{(encoder)} = f_{flat}(f_{encoder}(Z_{train}^{train}, \\Theta_{encoder}))$\nwhere $Z_1^{(encoder)} \\in \\mathbb{R}^{N_1 \\times d_{encoder}}$. Next, instead of directly mapping the features to the classification output via a single fully neural network (FNN), we perform a feature growth (FG) process. This involves inserting an additional FNN"}, {"title": "3.4 AL-based Class Incremental Learning", "content": "After completing the AL-based Re-alignment, we proceed with the CIL process using concatenated recursive least squares (C-RLS) in a recursive and analytical manner. To demonstrate this, without loss of generality, assume we are given $D_{train}^{train}$, and let\n$Z_{1:t-1}^{(fg)} \\in \\mathbb{R}^{N_{1:t-1} \\times d_{fg}}$, $Y_{1:t-1} \\in \\mathbb{R}^{N_{1:t-1} \\times \\sum_{i=1}^{t-1} d_{y_i}}$\nrepresent the concatenated activation and label tensors, respectively, from task 1 to t \u2013 1, i.e.,\n$\\begin{bmatrix} Z_{1:t-1}^{(fg)} \\\\ Z_t^{(fg)} \\end{bmatrix} = \\begin{bmatrix} Z_1^{(fg)} & 0 & \\dots & 0 \\\\ & Z_2^{(fg)} & & \\\\ & & \\ddots & \\\\ & & & Z_{t-1}^{(fg)} \\\\ 0 & 0 & \\dots & Z_t^{(fg)} \\end{bmatrix}$, $\\begin{bmatrix} Y_{1:t-1} \\\\ Y_{train}^t \\end{bmatrix} = \\begin{bmatrix} Y_{train}^1 & 0 & \\dots & 0 \\\\ & Y_{train}^2 & & \\\\ & & \\ddots & \\\\ & & & Y_{train}^{t-1} \\\\ 0 & 0 & \\dots & Y_{train}^t \\end{bmatrix}$.\nHere, $N_{1:t-1}$ indicates the total number of data samples from task 1 to t \u2013 1. The sparse structure of $Y_{1:t-1}$ arises because the data classes across different tasks are mutually exclusive. The learning problem can then be formulated as follows:"}, {"title": "4 Experiment", "content": "Class-Incremental Learning Setting.We trained and evaluated all methods on five datasets using two types of configurations: short-range and long-range. Specifically, in the short-range setting, two classes were introduced for each task, while in the long-range setting, only one class was introduced for each task. For long-range setting results, please see the Appendix (which we will be upload in the later version).\nDatasets. Following[32] We continued previous research by selecting five balanced time series datasets, each containing samples with the same length and variables, which is shown in 1. These datasets have an equal number of samples per category. We divided the datasets into n tasks, where each task contains different classes. In short-range tasks, each task includes 2 classes, while in long-range tasks, each task has 1 class. Before dividing the dataset, we randomly shuffled the class order, ensuring it varied for each run. We used different random seeds and conducted five experiments in total, reporting the average result. We applied layer normalization for the UCI-HAR, DSA, and GRABMyo datasets, with instance normalization for the Uwave dataset and no normalization for the WISDM dataset.\nComparison Methods. Following [32], for example-fre methods, we selected LwF [10], MAS [11], and DT2W [4]. For replay-based methods, we chose ER [8], ICARL [7], DER [33], ASER [34], CLPOS [3], and FASTICARL [9].\nEvaluation Metrics.To quantitatively assess the performance of class incremental learning(CIL) methods, we utilize two widely adopted metrics: Average accuracy and Forgetting. Average accuracy is calculated by averaging the"}, {"title": "5 Results and Discussion", "content": "Plasticity.As shown in 2 and 2, TS-ACL demonstrates outstanding accuracy performance across five datasets. Compared to the strongest baseline model, TS-ACL shows accuracy differences on the final task of -3.95%, 9.15%, 1.07%, 0.56%, and 37.00% for BN, and -3.00%, 6.70%, 0.11%, -7.34%, and 13.86% for LN. These results highlight TS-ACL's performance advantage in terms of Plasticity.\nStability. As shown in 2, TS-ACL achieves the lowest forgetting rate across all datasets, both under BN and LN conditions. Specifically, under BN, it surpasses the strongest baseline model by 1.35%, 17.16%, 2.24%, 16.83%, and"}, {"title": "6 Conclusion", "content": "In this paper, we introduce the application of continuous analytical learning methods to time series tasks for the first time. Through extensive experiments, we demonstrate the strong capabilities of TS-ACL, including its resistance to forgetting, the robustness of normalization, and its robustness in class-order. The superior performance of TS-ACL can be attributed to its ability to achieve results in incremental learning that are on par with joint learning. This is both mathematically proven and experimentally validated."}]}