{"title": "CAD-PROMPTED GENERATIVE MODELS: A PATHWAY TO FEASIBLE AND NOVEL ENGINEERING DESIGNS", "authors": ["Leah Chong", "Jude Rayan", "Steven Dow", "Ioanna Lykourentzou", "Faez Ahmed"], "abstract": "Text-to-image generative models have increasingly been used\nto assist designers during concept generation in various creative\ndomains, such as graphic design, user interface design, and fash-\nion design. However, their applications in engineering design\nremain limited due to the models' challenges in generating im-\nages of feasible designs concepts. To address this issue, this\npaper introduces a method that improves the design feasibility\nby prompting the generation with feasible CAD images. In this\nwork, the usefulness of this method is investigated through a case\nstudy with a bike design task using an off-the-shelf text-to-image\nmodel, Stable Diffusion 2.1. A diverse set of bike designs are\nproduced in seven different generation settings with varying CAD\nimage prompting weights, and these designs are evaluated on\ntheir perceived feasibility and novelty. Results demonstrate that\nthe CAD image prompting successfully helps text-to-image mod-\nels like Stable Diffusion 2.1 create visibly more feasible design\nimages. While a general tradeoff is observed between feasibility\nand novelty, when the prompting weight is kept low around 0.35,\nthe design feasibility is significantly improved while its novelty\nremains on par with those generated by text prompts alone. The\ninsights from this case study offer some guidelines for selecting\nthe appropriate CAD image prompting weight for different stages\nof the engineering design process. When utilized effectively, our\nCAD image prompting method opens doors to a wider range of\napplications of text-to-image models in engineering design.", "sections": [{"title": "1. INTRODUCTION", "content": "Concept generation is one of the early stages of the engineer-\ning design process. During this stage, engineers and designers\ngenerate and explore various design concepts [1]. Typically fol-\nlowed by the selection of concept(s) to pursue for the rest of the\ndesign process, the concepts generated in this stage have been\nfound to have critical impact on the success of the final product.\nParticularly, the exploration of a wide range of potential concepts\nthrough divergent thinking has been encouraged, as it has been\nfound to exercise designers' creativity and enhance the novelty\nand quality of the final product [2-4]. In design research, vari-\nous approaches have been proposed to assist designers' divergent\nthinking, including problem reframing [5], analogies [6, 7], and\nIdeation Decks [8].\nRecently, text-to-image (T2I) generative models, such as\nDALL-E and Stable Diffusion [9-11], have shown promise in\naugmenting designers' concept generation process [12, 13]. They\nnot only enable designers to immediately create visual represen-\ntations of their ideas but also facilitate the exploration of diverse\ndesign concepts. Trained on a large pool of images, T2I models\noften produce images of design concepts that can inspire design-\ners beyond their own creative capacities [12, 14, 15]. Therefore,\nthey are increasingly being implemented in various visual art do-\nmains [16], such as graphic design [17], user interface design\n[18, 19], fashion design [20], and digital art [21].\nDespite their widespread reach, the application of T2I mod-\nels in engineering design remains limited. One reason is that\nthese models frequently generate images of obviously infeasible\ndesigns concepts [22-24]. Unlike the visual and textual art con-\ntexts, such as graphic design and digital art, engineering design\noften requires the images of generated concepts to eventually\nbe realized into functional physical products [25]. However, be-\ncause T2I models are trained on large datasets of texts and images\nwithout the understanding of physical constraints, they produce\nimages of creative yet highly infeasible design concepts that can-\nnot be utilized as anything beyond an inspiration [22-24]. For\nexample, T2I models often generate images of unrealistic wheels,\nsuch as those that are triangular and/or without any spokes."}, {"title": "2. METHODS", "content": "Multiple research efforts have been dedicated to improving\nthe T2I models' suitability for engineering design by enhancing\nthe feasibility of the generated design concepts. One approach\nis prompt engineering. Some studies have suggested extracting\nimages with three-dimensional (3D) qualities by prompting the\nT2I models with specific words, such as \"3D render\" or \"CGI\"\n[26, 27]. In addition, Liu, et al. propose 3DALL-E that combines\nDALL-E, GPT-3, and Contrastive Language\u2013Image Pre-training\n(CLIP) within a computer aided design (CAD) software called\nAutodesk Fusion 360 [25]. This method assists designers during\ntheir prompt creation process, helping them to streamline the\ndisconnect between the infeasible images and the following stages\nof the design process involving manufacturing considerations.\nGPT-3 and CLIP help designers craft multimodal inputs (text and\nimage) that will effectively prompt DALL-E to generate novel\n3D images that meet their design goals. Although 3DALL-E\nencourages designers to think through the manufacturability of a\ndesign, it does not directly address the inherent problem of low\nfeasibility of the generated design concepts. Furthermore, this\nmethod adds complexity to the generation process, demanding\nmore steps to be taken by the designers to produce feasible design\nconcepts.\nSome researchers have also been developing text-to-3D mod-\nels, such as DreamFusion and Point-E [28-30]. These models\nare specifically meant for engineering design applications to gen-\nerate feasible 3D models of designs rather than images. Despite\ntheir potential, these models currently present many shortcom-\nings. They are much more computationally demanding than the\nT2I models, requiring longer inference times [31]. They are also\nrestricted in their capability to generate diverse and novel de-\nsigns due to the smaller volume of accessible training datasets\n[25, 29, 30]. These inherent restrictions of text-to-3D models\ncompromise the opportunity to use generative artificial intelli-\ngence (AI) to quickly produce novel inspirations [32].\nIn this paper, we propose a CAD image prompting method\nto improve the feasibility of T2I models' generated design con-\ncepts for engineering design applications. Specifically, we work\nwith Stable Diffusion 2.1, exploiting its capability to accept mul-\ntimodal input, such as texts and images, to create images in a\nzero-shot manner [9]. Given a text prompt, our method first\nidentifies a CAD image of a feasible design. Then, both the text\nprompt and the identified CAD image are used as prompts for the\nimage generation. To explore the potential of this CAD image\nprompting method for engineering design, we conducted a case\nstudy with a bike design task and investigate the feasibility and\nnovelty of the designs generated by this method."}, {"title": "2.1 CAD Image Prompting for Text-to-Image\nGeneration", "content": "The workflow of our CAD image prompting method is shown\nin Fig. 1. The method relies on a dataset of CAD images (not in\nCAD file formats, such as dwg and dxf) of the product that is being\ndesigned. We use images rather than dwg/dxf files to harness the\ncreative advantage of T2I models and image prompting. For\nexample, if the task is to design a chair, the CAD image dataset\nwould consist of a diverse set of chair designs. Then, given a text\nprompt entered by a designer, OpenAI's Contrastive Language-\nImage Pre-Training (CLIP) model is utilized to identify the image\nthat is the most semantically similar to the text prompt from the\nCAD image dataset. The CLIP model is a neural network trained\non 400 million image and text pairs to learn visual concepts from\ntext. The selected CAD image is then used as an image prompt,\ntogether with the designer's initial text prompt, to guide the T2I\nmodel's image generation. The T2I model blends the text and\nimage prompts according to the prompt weights to produce new\nimages. More details about the prompt weights and the generation\nsettings can be found in Section 2.2.1.\nThe goal of the CAD image prompting is to generate designs\nthat are more visibly feasible than those that would be generated\nusing text prompts alone. Enabling the generation of more fea-\nsible designs can greatly increase the use of T2I models in more\nphysical product design domains like engineering design. While\nmany studies have proposed image guidance and prompting as a\nway to improve the generated image quality, this method is unique\nin its use of CAD images to improve the perceived design feasi-\nbility. Since the generated output are still images, the purpose of\nour CAD image prompting is not to achieve the actual feasibil-\nity of the designs, but the apparent, perceived feasibility of the\ndesign concepts represented by the images. However, this work\ncould serve as a step towards generating actually feasible designs.\nFurthermore, CAD images offer an advantage of giving designers\nmore flexibility and control to gear the image generation in their\ndesired direction. This is because CAD image datasets can easily\nbe forged using CAD softwares. Synthetic datasets of CAD im-\nages can be fabricated strategically to guide the image generation\nprocess toward designers' specific needs."}, {"title": "2.2 Bike Case Study", "content": "We explored the effectiveness of our proposed CAD image\nprompting method by conducting a case study with a bike design\ntask adopted from Chong, et al.'s study [33]. The task is to create\nfeasible, novel, and aesthetically-pleasing bike design(s) using an\noff-the-shelf T2I platform called Leonardo.AI [34], as follows:"}, {"title": "2.2.1 Image Generation", "content": "To examine how the bike de-\nsigns generated with and without CAD image prompting differ\nin their feasibility and novelty, the first step was to generate the\nimages. For this generation, we used the text prompts provided\nby the 15 participants in Chong, et al.'s human subject study [33].\nBecause most of these participants entered multiple text prompts,\nthe most comprehensive prompt from each participant (15 total)\nwas selected and revised (e.g., typos and missing words) for our\nimage generation. The 15 prompts are displayed in Table 1.\nUsing Leonardo.AI, the authors generated bike design im-\nages with Stable Diffusion 2.1 in seven different generation set-\ntings:\n1) Stable Diffusion 2.1 (SD),\n2) Stable Diffusion 2.1 and Prompt Magic (SD+PM),\n3) Stable Diffusion 2.1, Prompt Magic, and CAD image\nprompting of weight 0.35 (CIP(0.35)),\n4) Stable Diffusion 2.1, Prompt Magic, and CAD image\nprompting of weight 0.51 (CIP(0.51)),\n5) Stable Diffusion 2.1, Prompt Magic, and CAD image\nprompting of weight 0.67 (CIP(0.67)),\n6) Stable Diffusion 2.1, Prompt Magic, and CAD image\nprompting of weight 0.83 (CIP(0.83)), and\n7) Stable Diffusion 2.1, Prompt Magic, and CAD image\nprompting of weight 1 (CIP(1)).\nAcross the seven settings, the following Leonardo.AI features\nare kept identical: Number of Images = 4, Input Dimensions =\n1024X768, Guidance Scale = 7, Public Images = OFF, Photo-\nReal = OFF, and Alchemy = OFF. The Number of Images is the\nquantity of images generated per generation. This value is set to\n4 to account for the variation within the same generation. The\nInput Dimensions refer to the size of the generated images. The\nGuidance Scale controls how much the image generation process\nfollows the text prompt. We use Leonardo.AI's default value of\n7. The Public Images value simply determines whether the gen-\nerated images will be shared with the public or not. Finally, the\nPhotoReal and Alchemy options are exclusive features offered\nby Leonardo.AI that finetune the default T2I model (in our case,\nStable Diffusion 2.1) to produce more realistic and high quality\nimages, respectively. To enable our study to be generalizable\nto any T2I tools other than Leonardo.AI, we have these features\noff for all image generations. For more information about the\nfeatures on Leonardo.AI, please refer to their website [34].\nPrompt Magic is an exclusive feature on Leonardo.AI that\nenhances prompt conformity and image structure. Although this"}, {"title": "2.2.2 Design Evaluations", "content": "Having had generated the 420\nimages of bike designs with 15 text prompts and seven different\nsettings, we collected human evaluations of the perceived feasi-\nbility and novelty of each design concept. Since the generated\noutput are still images in this work, the purpose of our CAD image\nprompting is not to achieve the actual feasibility of the designs,\nbut the apparent, perceived feasibility of the design concepts rep-\nresented by the images. However, this work could serve as a\nstep towards generating actually feasible designs. The evaluation\nquestions for each design are illustrated in Fig. 2. The definitions\nof feasibility and novelty were provided at the top of the screen\nfor reference so that all participants have the same understand-\ning of the evaluation categories. The definitions were taken and\nmodified from the Oxford Languages. Participants were asked to\nindicate their degree of agreement or disagreement with the two\nfollowing statements: 1) \"The bike is feasible.\" and, 2) \"The bike\nis novel\", in a 7-point Likert scale from \"Strongly disagree\" to\n\"Strongly agree\".\nAfter a round of pilot study, it was determined that a par-\nticipant could evaluate about 28 images in 5 minutes, leading to\na decision to give each participant 140 bike designs to evaluate\nduring a 30-minute session. 32 participants were recruited and\ncompleted the evaluations, and the data from two of these partic-\nipants were discarded and replaced because they failed to follow\nthe instructions and/or completed the evaluations too quickly. The\nparticipants were recruited using the convenience, voluntary, and\nsnowball sampling methods with the only recruitment criterion\nbeing they are 18 or order. We did not require the participants\nto have any prior design experience (although some did) because\nthe goal was to collect common users' ratings on their perceived\nfeasibility and novelty, rather than objective ratings. Each partici-\npant received 140 images randomly selected from 420 images and\nevaluated them in a random order. Each image was assigned to 10\ndifferent participants to be able to obtain the average feasibility\nand novelty ratings per image."}, {"title": "3. RESULTS", "content": "In this section, the CLIP similarity scores between the im-\nages generated in the seven generation settings (listed in Section\n2.2.1) are presented first in Table 3. Each CLIP similarity score\nrepresents how similar the images generated in the column setting\nare to those generated in the row setting. The CLIP similarity\nscore between the images generated in two settings is calculated\nby averaging the similarity scores for all pairs of images. For\nexample, given a prompt, each setting generated four images. For\nthe two sets of four images produced by two settings, the CLIP\nsimilarity scores are calculated for every pairwise combination\nand are averaged. The scores range from -1 to 1, -1 meaning\nmaximum dissimilarity and 1 meaning maximum similarity. No-\ntice that the left diagonal values are not 1, even though they are\ncomparing between the same settings. This is because there are\nmultiple images generated in each setting, and the average of the\nsimilarity scores between these images are reported. The lowest\nsimilarity scores (mostly negative) are mainly observed for the SD\nsetting, confirming that the images generated without the CAD\nimage prompting are highly dissimilar to the rest of the images.\nTable 3 displays the results only for the generations with Text\nPrompt 1 from Table 2. However, similar trends are observed\nwith the other 14 text prompts.\nWe also present the human evaluation results for how the per-\nceived feasibility and novelty of the generated bike designs vary\namong the seven generation settings. These results bring insight\ninto the effectiveness the CAD image prompting method in pro-\nducing more visibly feasible designs compared to the T2I models\nwith only text prompts, as well as whether and how the novelty\nof the designs may be compromised. Figure 3 shows the over-\nall results from the human evaluations and the Spearman's rho\ncorrelation result between the weight of the CAD image prompt\nand the feasibility and novelty ratings of the generated bike de-\nsigns. Table 4 consists of the Mann-Whitney U test results to\nshow whether the feasibility and novelty ratings of the generated\ndesigns are different between various pairs of settings."}, {"title": "3.1 Perceived feasibility increases with CAD image\nprompting", "content": "Figure 3a and the first two columns of Table 4 display re-\nsults related to the feasibility of the generated images. First and\nforemost, the second and seventh rows in Table 4 demonstrate the\neffectiveness of our CAD image prompting method in improving\nthe perceived feasibility of generated designs. The feasibility rat-\ning is significantly higher in the CAD image prompting settings\nwith 0.35 weight (CIP(0.35)) than Stable Diffusion 2.1 (SD) and\nStable Diffusion 2.1 with Prompt Magic (SD+PM) settings (Z =\n-7.22 and -2.81, p < 0.01 and < 0.01, respectively). This result\nholds true with all the other CAD image prompting settings with\ndifferent weights, as demonstrated in rows three to six and rows\neight to 11 in Table 4.\nFor the Spearman's rho test, the SD+PM setting, rather than\nthe SD setting, is used as the no CAD image prompting (weight\n= 0) setting. This is because the images generated in the SD+PM\nsetting tend to be perceived as more feasible than those generated\nin the SD setting (Z = -5.09, p < 0.01). Overall, a positive\ncorrelation is found between the weight of the CAD image prompt\nand the perceived feasibility of the generated images of bike\ndesigns ($\\rho$ = 0.186, p < 0.01). This means that as we increase\nthe weight of the CAD image prompt, the generated bike designs\nbecome more visibly feasible. However, it is important to note\nthat the feasibility rating of the designs drop from the weight 0.83\nto 1. This suggests that at a certain weight above 0.83, the T2I\nmodel's ability to balance adherence to the CAD image with the\ntext prompt may be compromised."}, {"title": "3.2 Novelty is compromised with higher CAD image\nprompting weights", "content": "Having confirmed that our proposed method successfully im-\nproves the perceived feasibility of the generated designs, we heed\nto how their novelty is affected with the CAD image prompting.\nThe novelty related results are illustrated in Fig. 3b and the last\ntwo columns of Table 4.\nWith the implementation of CAD image prompting with the\nlowest weight (0.35), the novelty of the generated bike designs\nis lower compared to the SD+PM setting but not the SD setting\n(Z = 2.62 and 1.72, p < 0.01 and = 8.59E-2, respectively). This\nresult shows that the novelty performance of Stable Diffusion 2.1\nis not significantly affected by the CAD image prompt of weight\n0.35. However, as shown in Fig. 3b, when Stable Diffusion 2.1\nis augmented by the Prompt Magic feature in Leonardo.AI, the\nnovelty of the generated designs slightly increases (though not\nstatistically significant). Therefore, the SD+PM setting produces\nmore novel designs than the CIP(0.35) setting.\nWith CAD image prompt of a weight greater than 0.35 (more\naccurately a weight greater than a value between 0.35 and 0.51),\nthe novelty of the generated designs is compromised. This result\nis bolstered by rows three to six and rows eight to 11 in Table 4.\nThe novelty ratings in settings CIP(0.51), CIP(0.67), CIP(0.83),\nand CIP(1) are all significantly lower than those in settings SD"}, {"title": "4. DISCUSSION", "content": "and SD+PM.\nLike the feasibility analysis, the SD+PM setting, rather than\nthe SD setting, is used as the no CAD image prompting setting\n(CIP(0)) for the Spearman's rho test. A negative correlation is ob-\nserved between the weight of CAD image prompt and the novelty\nof the generated images of bike designs ($\\rho$ = -0.386, p < 0.01). This\nmeans that as we increase the weight of the CAD image\nprompt, the generated bike designs become less novel. There-\nfore, recalling the earlier result that the generated designs are\nperceived to be more feasible with a higher CAD image prompt-\ning weight, we find that there is a significant tradeoff between the\nfeasibility and novelty ($\\rho$ = -0.728, p < 0.01).\nIn engineering design, T2I models have mainly been used as\nan inspirational tool during concept generation [13-15]. How-\never, they are difficult to implement for any purpose beyond inspi-\nration because the generated images of design concepts are often\ninfeasible [22-24]. Not only does the perceived infeasibility of\nthe designs prevent generation of realistic concepts, but also hin-\nder the potential use of the T2I models during the other stages\nof the engineering design process. To address this issue, we\npropose in this paper a CAD image prompting method in which\nCAD images of feasible designs are used as prompts in the image\ngeneration process along with text prompts.\nA case study with a bike design task was conducted to ex-\nplore the effectiveness of this method. Results from the study\nshow that CAD image prompting successfully improves the per-\nceived feasibility of designs generated by Stable Diffusion 2.1\nwith text prompts alone. The perceived feasibility is also im-\nproved compared to the advanced version of Stable Diffusion 2.1\nwhich had been further trained by Leonardo.AI's Prompt Magic\nfeature. This result implies that our proposed method has the po-\ntential to expand the applicability of T2I models, so that they can\nplay a role in engineering design by creating more visibly feasible\ndesign concepts that are beyond mere inspiration. For instance,\nwhile designers currently need to independently produce models\nfor their design concepts after being inspired by the images gener-\nated by T2I models, this process can be significantly streamlined\nwhen the generated designs are more feasible. The designs rep-\nresented in the generated images will more likely be able to be\nrealized directly into a physical product, meaning that the images\nwill act as models. Furthermore, the improved feasibility of gen-\nerated images may increase the usefulness of T2I models in later\nstages of the engineering design process. Our method may be\nable to generate images of overall designs or even designs of spe-\ncific parts feasible enough to be directly used for the system-level\ndesign, detailed design, and refinement stages. Although this\nwork is a proof-of-concept of the CAD image prompting method\nand has only improved the perceived feasibility of the generated\ndesign concepts, future refinement of this method has the poten-\ntial to further increase the perceived feasibility and even increase\nthe actual feasibility of the designs.\nOur image prompting method utilizes CAD images rather\nthan real-world images, offering unique advantages in engineer-\ning design applications. First, it will be highly synergistic with\nimage-to-CAD or image-to-3D methods that aim to instantly\ntransform images into CAD/3D models [28-30, 36, 37]. The\nimages of design concepts generated by our method will likely\nhave characteristics similar to those of CAD images, and there-\nfore, they may more easily be transformed into CAD models.\nMerging image-to-CAD methods with our CAD image prompt-\ning method will engender a design tool that allows designers to\nshift between concept generation and design refinement anytime.\nIn the image mode, the tool can harness the creative potential\nfrom T2I models' large dataset, while in the CAD mode, the\ndesigners will be able to make detailed changes to the design.\nAdditionally, CAD image datasets can easily be fabricated using\nCAD software, giving designers more flexibility and control over\nthe image generation process. When using real-world images,\ndesigners need to communicate their design ideas through text\nif the ideas do not already exist in the world. With our method,\nthese design ideas can be communicated using CAD images. Not\nonly does this make our method extremely versatile, but it also\nenables better control over the dataset and image generation.\nWhile the potential of the CAD image prompting in engineer-\ning design is clear, our results also highlight the tradeoff between\nthe perceived feasibility and novelty, confirming the difficulty\nin creating both feasible and novel designs with generative AI\n[32, 38]. The generated designs tend to become less novel with\nhigher CAD image prompt weight. Hence, it is critical to select\nthe appropriate image prompting setting for a given design stage\nand scenario. Generally, designers engage in an iterative process\nwhile working with T2I models to figure out the right balance of\nsettings in order to attain a reliable final design [39]. The findings\nin this work regarding the CAD image prompting method drasti-\ncally reduce the need for multiple iterations to generate feasible\nbike designs. For example, if a designer is using a T2I model\nfor inspiration during concept generation, it is important for the\nimages to be novel rather than feasible. In this case, the SD+PM\nsetting would be the most ideal as it provides the most novel\ndesigns. In contrast, if a designer wants to explore alternative\ndesigns in the later stages of the design process, producing feasi-\nble images may be a priority over highly novel ones. Therefore,\nCIP(0.51), CIP(0.67), or CIP(0.83) settings may be suitable for\nthis scenario.\nBased on the results, we offer a few points of caution when\nselecting the appropriate setting for image generation. First, se-\nlecting a CAD image prompt weight higher than 0.83 is likely\ndisadvantageous. Past 0.83, the perceived feasibility of the gen-\nerated images begins to drop, perhaps because the T2I model's\nability to balance adherence to the CAD image with the text\nprompt is compromised. Secondly, the decrease in image novelty\nseems to plateau at the CAD image prompt weight of 0.67. This\nmeans that past 0.67, about 0.83 may always be the ideal setting as\nit provides the most visibly feasible designs within that range. It\nis important to note that the specific values of the image prompt\nweight mentioned in these suggestions may be model specific.\nTherefore, if a T2I model other than Stable Diffusion 2.1 is being\nused, the appropriate values for that model must be investigated.\nLastly, if no CAD image prompting is used, the SD+PM setting\nmay always be better than the SD setting in terms of feasibility\nand novelty. SD+PM produces designs that are significantly more\nfeasible yet similar in novelty."}, {"title": "4.1 Limitations and Future Work", "content": "This section describes the limitations of this work and their\ncorresponding future research directions. The first limitation is\nthat the performance of the method proposed in this paper may\nbe dependent on the dataset. The CAD images that guide image\ngeneration are selected from a dataset of CAD images. This\nmeans that the quality and the prompt conformity of the CAD\nimages are determined by the dataset. This issue may be resolved\nby exploring alternative methods to produce the CAD images for\nprompting, such as designers manually creating them using CAD\nsoftware.\nIn addition, there is an inherent trade-off between the T2I\nmodel's adherence to the text and image prompts. With a higher\nimage prompting weight, the T2I model is less faithful to the\ntext prompt requirements, and vice versa. For example, in 2, the\ngenerated bike images in the higher image prompt weight settings\ntend to exclude some required elements from the text prompts like\nwings and sofa chair. Investigating this tradeoff and its impact\non the designers and their design process can add more insights\ninto how our CAD image prompting method can be effectively\nutilized in engineering design.\nFurthermore, we present one case study in this paper that\nserves as an initial exploration and proof-of-concept of our pro-\nposed method. Further validation of the method is a valuable\ndirection for future research.\nFinally, other potential future works include assessing the\nperceived feasibility and novelty of the CAD images themselves\nas a benchmark for comparison with the other generation settings\nand empirically investigating the difficulties engineers and de-\nsigners currently face using T2I models and identifying how our\nCAD image prompting may help those challenges."}, {"title": "5. CONCLUSION", "content": "In engineering design, T2I models are difficult to be utilized\nas more than an inspirational tool during concept generation be-\ncause they produce infeasible designs. This paper proposes a\nCAD image prompting method that aims to improve the perceived\nfeasibility of designs generated by T2I models. The effectiveness\nof this method was explored through a case study with a bike\ndesign task, which showed that CAD image prompting success-\nfully leads to more visibly feasible designs. A feasibility-novelty\ntradeoff was also observed, suggesting that caution and strategy\nis needed when selecting the weight of the CAD image prompt.\nWhen utilized effectively, our method has the potential to expand\nthe range of applicability of T2I models in the engineering design\nprocess. Moreover, our CAD image prompting method possesses\nunique advantages due to its use of CAD images. Particularly,\nwhen combined with image-to-CAD methods, it can lead to the\ndevelopment of a computational design tool that supports multi-\nmodal design, enabling designers to easily switch back and forth\nbetween concept generation and design refinement."}]}