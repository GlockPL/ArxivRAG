{"title": "Towards Robust Stability Prediction in Smart Grids: GAN-based Approach under Data Constraints and Adversarial Challenges", "authors": ["Emad Efatinasab", "Alessandro Brighente", "Denis Donadel", "Mauro Conti", "Mirco Rampazzo"], "abstract": "Smart grids are critical for addressing the growing energy demand due to global population growth and urbanization. They enhance efficiency, reliability, and sustainability by integrating renewable energy. Ensuring their availability and safety requires advanced operational control and safety measures. Researchers employ AI and machine learning to assess grid stability, but challenges like the lack of datasets and cybersecurity threats, including adversarial attacks, persist. In particular, data scarcity is a key issue: obtaining grid instability instances is tough due to the need for significant expertise, resources, and time. However, they are essential to test novel research advancements and security mitigations. In this paper, we introduce a novel framework to detect instability in smart grids by employing only stable data. It relies on a Generative Adversarial Network (GAN) where the generator is trained to create instability data that are used along with stable data to train the discriminator. Moreover, we include a new adversarial training layer to improve robustness against adversarial attacks. Our solution, tested on a dataset composed of real-world stable and unstable samples, achieve accuracy up to 97.5% in predicting grid stability and up to 98.9% in detecting adversarial attacks. Moreover, we implemented our model in a single-board computer demonstrating efficient real-time decision-making with an average response time of less than 7ms. Our solution improves prediction accuracy and resilience while addressing data scarcity in smart grid management.", "sections": [{"title": "I. INTRODUCTION", "content": "The rapid global population growth, economic expansion, and urbanization are projected to significantly increase energy consumption, coinciding with the adoption of renewable energy. Traditionally, energy grids functioned with a unidirectional flow from production centers to consumers. However, the emergence of the so-called prosumers -entities that both consume and supply energy-requires a shift to bidirectional energy flow within grids [1]. In this context, smart grids represent a transformative solution, enhancing the efficiency, reliability, and sustainability of electrical grids through advanced technologies. They create a modern electricity distribution network characterized by improved dependability, effectiveness, sustainability, and bidirectional communication capabilities [2]. Smart grids leverage real-time data, communication networks, and intelligent control mechanisms to optimize electricity generation, distribution, and consumption, enabling a responsive energy ecosystem with a two-way flow of information between utilities and customers [2]. As the energy landscape evolves, smart grids are vital for integrating renewable resources like solar and wind, mitigating variability, and promoting overall sustainability. Their adaptability is crucial for incorporating new technologies and managing operational characteristics, such as power collection timing and delivery capacity [3].\nAccurately predicting renewable energy generation is critical for maintaining stable and efficient power system operations, especially when managing the inherent fluctuations of sustainable energy sources [4]. Similarly, robust forecasting techniques are essential to preempt disruptions in balancing electricity supply and demand. To address the challenges posed by fluctuating power grids, various smart grid strategies have been developed, with a key focus on balancing supply and demand. One of the central concepts in these strategies is the regulation of consumer demand, commonly referred to as the demand response strategy [5], [6]. Demand response involves adjustments in electricity consumption by customers in response to changes in electricity prices, diverging from their typical consumption patterns [7]. A promising innovation in this domain is Decentralized Smart Grid Control (DSGC), which integrates electricity prices with grid frequency, a parameter that can be measured by prosumers [8]. In this framework, frequency increases during power surpluses and decreases during shortages [9], enabling real-time pricing mechanisms that allow prosumers to dynamically adjust their demand. However, the effective implementation of DSGC requires overcoming several challenges, including maintaining grid stability amidst rapid price fluctuations, addressing varying price sensitivities among participants, and accommodating differences in their response times [10].\nGrid instability can cause major disruptions to electricity supply, impacting everyday activities and economic systems. When the power grid experiences instability, it may lead to outages, harm electrical equipment, and create safety risks. For example, variations in voltage can make lights flicker and potentially harm delicate devices [11]. In extreme situations, a localized outage caused by its instability, within the grid can trigger a cascading effect, resulting in extensive blackouts [3]. In the real world, a fault in an underground cable caused a near-total blackout in Puerto Rico, leaving approximately 1.3 million people without electricity [12].\nMachine Learning (ML) and Artificial Intelligence (AI)"}, {"title": "II. RELATED WORKS", "content": "In this section, we delve into the existing literature concerning stability prediction systems and their security implications. Specifically, we scrutinize established methodologies for stability prediction in Section II-A, while we assess the current landscape of attacks targeting these systems in Section II-B.\nA. Smart Grid Stability Prediction using AI\nThe rise of distributed and renewable energy sources presents significant challenges in ensuring the stability of power grids. While researchers have taken various approaches in the past [21], ML and AI are shown to be an efficient way to enhance smart grid functionality by facilitating intelligent decision-making and rapid responses to various dynamic scenarios [22]. Advanced AI techniques provide robust solutions for stability analysis and control in smart grids, gathering considerable interest and attention from both researchers and practitioners [23].\nFor instance, Aliyeva et al. [24] developed a hybrid DL model that combines Multilayer Perceptron (MLP) and Extreme Gradient Boosting (XGBoost) classifiers to forecast smart grid stability. Bashir et al. [25] employed various state-of-the-art ML algorithms, such as Support Vector Machines (SVM), K-Nearest Neighbor (KNN), Logistic Regression, Naive Bayes, Neural Networks, and Decision Tree classifiers, to predict smart grid stability. Gorza\u0142czany et al. [7] approach the issue of smart grid stability prediction by utilizing a knowledge-based data-mining technique, particularly focusing on a fuzzy rule-based classifier. Furthermore, there is a growing emphasis on the utilization of Recurrent Neural Networks (RNNs) such as Long Short-Term Memory Network (LSTM) and Gated Recurrent Unit (GRU) in the literature [13], [14]. Zhang et al. [13] introduce a power grid stability prediction model that relies on a Bi-directional LSTM with an attention mechanism. This model is capable of learning the function of various stability features and the interrelationships among these features.\nA novel Multidirectional LSTM technique has been introduced by [14] for predicting the stability of smart grid networks. Furthermore, Massaoudi et al. [15] propose a DL approach using bidirectional GRU for predicting smart grid stability. To automate the tuning process, this research utilizes the Simulated Annealing algorithm to optimize selected hyperparameters and improve the model's forecasting capability. Also, the utilization of Convolutional Neural Networks (CNNs) in stability prediction research within smart grids has been explored by various researchers [26], [27]. While all these represent viable solutions, model training is always employing stable data together with unstable samples. However, the assumption of having unstable data is not always achievable in real-world settings, thus creating the need for alternative systems that rely only on stable data.\nB. ML Adversarial Attacks\nRecent studies have highlighted the vulnerabilities of various ML methods to adversarial attacks, raising concerns about their impact on the security and reliability of power systems [28]. Nowadays, smart grids are employing AI for grid stability, and adversarial examples can significantly compromise the outcome of these systems. Additionally, findings from [29] demonstrate that during cyber-attacks, ML algorithms suffer a notable drop in performance, leading to a sharp decline in the accuracy of transient stability predictions compared to normal conditions. Furthermore, Chenet al. [30] aim to address security issues associated with ML applications in power systems. They emphasize that most ML algorithms proposed for power systems are susceptible to adversarial examples-inputs intentionally crafted with malicious intent. The paper by Tian et al. [31] investigates security concerns of neural network-based state estimation in smart grids, focusing on adversarial attacks and proposing an efficient method for executing these attacks. Sayghe et al. [32] investigate the impact of adversarial examples on the detection of False Data Injection Attacks (FDIAs) using DL algorithms. Their research examines the repercussions on MLP when exposed to two different adversarial attack strategies. Ahmadian et al. [33] introduced a FDIA using a GAN framework, where the attacker acts as the generative network and the Energy System Operator (ESO) serves as the discriminative network. The attacker generates deceptive data to evade detection by the power system state estimator through an optimization process. Li et al. [34] show that well-established ML models used in energy theft detection systems are susceptible to adversarial attacks. They develop a method to create adversarial measurements, allowing attackers to report significantly lower power consumption to utility companies and evade detection by ML-based systems. Despite various research works investigating adversarial attack effects in this context, no one ever considers mitigation techniques, especially merged with stability prediction."}, {"title": "III. SYSTEM AND THREAT MODEL", "content": "In this section, we introduce the system and threat model for our GAN-Stability framework.\nA. System Model\nIn an operational setting without active threats, a DSGC stability prediction system assesses whether the grid remains stable or unstable, particularly in a decentralized smart grid context where electricity prices are tied to grid frequency that carry all necessary information about the current power balance. In fact, the stability of electrical grids depends on the balance between electricity generation and demand [7], [10]. In the context of DSGC, stability is characterized by synchronized node frequencies (w) and steady power flows (Pjk) across the grid. Stability requires minimal angular frequency deviations and effective damping to suppress oscillations. Stability is evaluated by the system's ability to return to equilibrium after disturbances, as measured by mathematical models such as local stability (i.e., linear stability exploring dynamical stability around the steady-state operation of the grid) [10]. Instability arises when synchronization is lost, resulting in significant frequency deviations, amplified oscillations, and destabilized power flows. These effects can lead to cascading failures, particularly when delays, resonance effects, or insufficient damping prevent the grid from recovering.\nOur system leverages ML and AI algorithms to perform binary classification to categorize grid samples into stable or unstable classes using various input data that the control center collects from nodes on the grid. Examples of such data include the reaction time of each participant, which indicates how quickly consumers or systems respond to changes; the price elasticity coefficients which reflect how sensitive power consumption is to changes in electricity prices; and nominal power consumption and production features which represent the baseline levels of power used or generated by the system. As we discuss in Section V-A, in our system we employ 12 different features which are usually collected by cheap equipment by a particular prosumer and sent to a control center. Before deployment, the model is trained on clean, uncorrupted data to ensure reliable predictions. Stable grid instances are easy to obtain from operational data since represent the vast majority of operation time, while gathering instability data is more difficult. Instability instances require careful labeling by human experts, and acquiring a comprehensive dataset involves long-term observation and considerable resources.\nIn our system model, we adopt a pragmatic approach where we collect enough instances of stability from cheap equipment by particular prosumers [7]. These instances, all from the same stable label, serve as the sole data for training the stability prediction model. Therefore, to ensure the model's effectiveness, we should collect a sufficient amount of data that is both comprehensive and representative of the underlying distribution of stable grid conditions. By focusing solely on stability instances, we streamline the training process and alleviate the need for extensive data collection efforts associated with capturing instances of instability. To the best of our knowledge, all the models in the existing literature typically rely on access to both labels in the dataset to make accurate predictions [1], [3], [14], [35]\u2013[37]. Our approach challenges this conventional paradigm by demonstrating that accurate stability prediction can be achieved using only instances of stability for training.\nB. Threat Model\nThe attacker's objective is to stealthily insert fraudulent information into the grid's data stream, manipulating the classification decisions made by the stability model. This manipulation can result in misclassification in both directions -either causing stable grid conditions to be incorrectly classified as unstable or, more critically, unstable conditions to be classified as stable. In pursuit of this goal, the attacker may exploit either known vulnerabilities or discover new ones to gain remote access to the smart grid elements [38].We delineate two scenarios based on the attacker's familiarity with the data of the smart grid and the stability prediction model.\nWhite-box Scenario: In this scenario, the attacker possesses comprehensive access to both the data employed in testing the model and detailed information regarding the model's architecture and parameters. This advantageous position provides the attacker with ample opportunities to exploit vulnerabilities in the system. By leveraging this intelligence, the attacker can meticulously craft powerful adversarial samples aimed at deceiving the model. Such a scenario could occur if an attacker compromises the control center of a distributed smart grid, for example, through malware infiltration or physical attacks targeting power companies [39].\nGrey-box Scenario: In this scenario, the attacker has access to the testing data but lacks access to the architecture and parameters of the main model. Despite this limitation, the attacker can still conduct evasion attacks by employing a surrogate model \u2014an alternative model trained on the same dataset- with different architectures. The effectiveness of these attacks relies on transferability properties or the chosen architecture. This condition can exist if an attacker compromises enough prosumers or entities in the system, thus gaining access to several data but without knowledge of the actual employed model. IoT botnets are an example of how such scenarios could easily become a reality [40].\nTo generate adversarial samples, we utilize the LSTM model proposed in [3] as surrogate model. These adversarial samples will then be deployed against our primary stability prediction system (GAN-Stability). This setup simulates a real-world scenario where potential attackers have access to limited information about the system."}, {"title": "IV. REFERENCE ATTACKS", "content": "In the white-box scenario, an attacker can exploit various state-of-the-art adversarial attacks. While numerous attacks exist, most have been evaluated primarily in multi-classification tasks and are not specifically designed for binary classification tasks like ours. We concentrate on specific attacks recognized for their effectiveness in exposing weaknesses, particularly in the context of decision-making in smart grids, as supported by existing literature [3], [17].\nIn the grey-box scenario, the same adversarial attacks are employed; however, adversaries only have access to genuine data and a surrogate model. They utilize this surrogate model to generate adversarial data, which is then tested against the primary model. This method assesses the robustness of the primary model without granting direct access to it.\nA potential attacker's objective is to carry out the following attack:\n$\\max_{\\epsilon} L(f(x + \\epsilon), y) \\qquad s.t. ||\\epsilon||_p \\leq \\gamma.$\nThe equation maximizes the loss $L$ between the model's prediction $f(x + \\epsilon)$ and the true label $y$ while constraining the perturbation $\\epsilon$ within a specified norm limit $||\\epsilon||_p \\leq \\gamma$. The selected adversarial attacks for this study are as follows:\nFast Gradient Sign Method (FGSM): FGSM efficiently generates adversarial examples using the sign of the gradient of the loss function and is widely used to benchmark the robustness of ML models [41].\nBasic Iterative Method (BIM): BIM extends FGSM by iteratively applying small perturbations to input data. By gradually perturbing the input, BIM aims to enhance the potency of the attack and uncover vulnerabilities in ML models [41].\nRandomized Fast Gradient Sign Method (RFGSM): introduces randomness into FGSM iterations by incorporating random noise, enhancing attack diversity. Explores the impact of variability in adversarial perturbations, providing insights into model robustness against unpredictable attacks [42].\nProjected Gradient Descent (PGD): PGD uses an iterative optimization approach like BIM, adding a projection step to keep perturbations within a predefined constraint set. This ensures perturbed examples remain within acceptable bounds, making PGD effective at crafting strong adversarial examples [41]."}, {"title": "V. GAN-STABILITY: OUR PROPOSED STABILITY PREDICTION SYSTEM", "content": "In this section, we present our proposed stability prediction system, whose architecture is summarized in Figure 1. In particular, training of the discriminator is done employing stable data (1), synthetic unstable data created by the generator starting from noise (\u2461), and adversarial samples generated by applying attacks to stable data (3).\nA. Architecture\nIntroduced by Goodfellow et al. [43], GANs consist of two neural networks -a generator and a discriminator- engaged in an adversarial game. The generator's objective is to produce synthetic data samples that closely resemble real ones, while the discriminator is trained to distinguish between genuine and fabricated samples.\nOur architecture leverages a GAN model for smart grid stability prediction, where the generator creates synthetic data representing potential instances of instability, addressing the challenge of acquiring rare unstable data in real-world scenarios. The discriminator learns to differentiate between real (stable) data and synthetic (unstable) data, enhancing its ability to detect anomalies and predict stability accurately even when we do not have access to one label (unstable) in the training data. In this context, the generator does not have direct access to real data; its learning process relies solely on its interaction with the discriminator, which has access to both generated and real samples.\nThe generator model, deliberately simpler than the discriminator, consists of four fully connected layers, with the number of neurons ranging from 12 (representing the number of features) to 128. The discriminator, instead, comprises five fully connected layers, with the neuron count ranging from 12 to 512. The specific details of our GAN-based stability prediction system architecture can be seen in Table I.\nB. Training\nThe training process in GANs is governed by a value function, $V(G, D)$, which accounts for both the generator G and discriminator D. The training process involves solving\n$\\min_G \\max_D V (G, D), \n         (1)$\nwhere\n$V(G, D) = E_{p_{data}(x)} [log D(x)] + E_{p_g(x)} [log(1 \u2013 D(x))]. \n         (2)$\nThe first term, $E_{p_{data}(x)} [log D(x)]$, represents the expectation of the log-likelihood that the discriminator correctly identifies real data samples drawn from the distribution $p_{data}(x)$. The second term, $E_{p_g(x)} [log(1 \u2013 D(x))]$, corresponds to the expectation that the discriminator correctly identifies fake data samples generated by G from the generator's distribution $p_g(x)$. The generator seeks to minimize this function by producing samples that the discriminator finds difficult to classify as fake, while the discriminator aims to maximize it by improving its ability to distinguish between real and generated data. This min-max game drives the adversarial training process, leading to improved generation of realistic data by G as training progresses.\nDuring training, one model's parameter is updated while the others are kept fixed. Goodfellow et al. [43] demonstrate that when the generator is fixed, there exists a unique optimal discriminator $D^*(x)$ given by:\n$D^*(x) = \\frac{p_{data}(x)}{p_{data}(x) + p_g(x)},\n         (3)$\nwhich gives the probability that a sample x belongs to the real data distribution $p_{data}$ rather than belonging to the generator's distribution $p_g$. Additionally, they show that the generator G is optimal when $p_g(x) = p_{data}(x)$, meaning the discriminator cannot distinguish between real and generated samples and assigns a probability of 0.5 to all samples, whether real or generated [44]. In this standard formulation, the generator G aims to minimize the objective by producing data that maximizes the discriminator's uncertainty (i.e., making $D(x)$ close to 0.5), while the discriminator D aims to maximize its ability to correctly classify real versus generated data by minimizing this uncertainty.\nIn our approach, we utilize a specialized training procedure for GAN models. Here, the generator begins with random noise and attempts to deceive the discriminator by generating synthetic data samples that resemble genuine instances. Concurrently, the discriminator is trained on real data, which, in our case, comprises just stable instances of the dataset, as well as on the fake data generated by the generator. Over time, the discriminator learns to distinguish between genuine stable data and the synthetic data produced by the generator, which may represent potential instances of instability lying outside the distribution of stable labels.\nUnlike the traditional usage of GANs, where the goal is for the generator to eventually converge and produce data that closely resembles the real data such that $p_g(x) \u2248 p_{data}(x)$, we intentionally prevent the generator from reaching that stage of convergence. The optimization process for the generator is intentionally constrained to prevent it from reaching convergence. This modified min-max problem reflects our novel approach where the generator's role is not to reach the standard equilibrium, but to guide the discriminator into learning better classification boundaries for stable and unstable instances.\nTo encourage the generator to explore regions away from the stable distribution $P_{stable}$, we add a regularization term to the generator's loss function. This term is referred to as the repulsion loss and is defined as:\n$L_{repulsion} = E_{x \\sim p_g, s \\sim P_{stable}} [ReLU(m - ||x \u2212 s||)],\n         (4)$\nwhere:\nReLU(m - ||x \u2212 s||) = \n         \\begin{cases}\n         m - ||x - s||, & \\text{if } ||x - s|| < m, \\\\\n         0, & \\text{if } ||x - s|| \\geq m.\n         \\end{cases}\nThe generator minimizes the following objective:\n$L_G = -E_{z \\sim p_z} [log D(G(z))] +  E_{x \\sim p_g, s \\sim P_{stable}} [ReLU(m - ||x \u2212 s||)],$\nIn this context, x represents a batch of data generated by the generator, derived as $x = G(z)$, where z is drawn from the latent distribution $p_z$. The variable s denotes a batch of data from the stable distribution $P_{stable}$, which represents regions in the data space the generator should avoid. The parameter m is a margin that determines the distance threshold for the repulsion effect.\nThe choice of a margin $m = 4$ is justified based on the distribution of features in the dataset and their deviations. Specifically, the margin is selected to ensure that the generated samples $p_g$ maintain a safe distance from the stable class $P_{stable}$, avoiding overlap while still exploring plausible regions of the data space. By analyzing the scale and standard deviations of the feature values, a margin of 4 represents a sufficient threshold to distinguish generated samples from the stable class while not overly restricting the generator's ability to explore diverse, non-stable regions. The discriminator's ability to classify stability and instability does not rely on the generator producing perfectly unstable data. Instead, the generator serves as an adversarial tool that pushes the discriminator to refine its decision boundaries. By doing so, the discriminator learns to focus on feature combinations that determine stability or instability, regardless of whether the generator's outputs match real-world patterns.\nFurthermore, we adopt a targeted strategy to extend the generator's training phase while allowing the discriminator to gain a prolonged upper hand. This approach diverges from conventional GAN setups that seek equilibrium between the generator and discriminator. Instead, our method intentionally introduces a controlled imbalance, enhancing the discriminator's capacity to classify generated data as unstable.\nAs depicted in Figure 2, the generator's loss begins at a high value and initially decreases as the generator starts challenging the discriminator. This early improvement highlights the generator's growing ability to deceive a discriminator that is still in the very early stages of learning, having been trained for less than 50 epochs. During this phase, the repulsion loss (shown in Figure 3) starts with high values, reflecting the generator's proximity to the real data distribution. However, the repulsion loss subsequently becomes optimized, enforcing divergence from the stable data distribution. This process, coupled with the discriminator's growing advantage, results in a gradual increase in the generator's loss, eventually reaching values between 10 and 40. The increasing generator loss reflects the escalating difficulty of producing samples that can deceive the discriminator.\nInitially, the repulsion loss has higher values. However, as training progresses and the discriminator gains the upper hand, the repulsion loss is optimized to push the generator's output away from stable samples. This effect is evidenced by the decreasing repulsion loss values during later epochs, corresponding to the generator's divergence from stability.\nThe discriminator's architectural advantage, with its deeper network design, further reinforces this dynamic. Its capacity to learn complex representations allows it to maintain dominance throughout training, as seen by its relatively stable loss values in Figure 2. This structural superiority, coupled with prolonged training and repulsion loss, ensures the generator does not converge too closely to the stable data distribution. Instead, it generates data that is more representative of potential instabilities, providing a more effective adversarial challenge and enhancing the model's robustness.\nThrough the interplay of the repulsion term, extended training, and the discriminator's architecture, our approach fosters a dynamic adversarial process. This controlled imbalance ensures the generator continually adapts, producing harder-to-fool samples that represent potential instabilities more effectively."}, {"title": "VI. EVALUATION", "content": "We now present the evaluation of GAN-Stability. As metrics, we use accuracy and F1 score to evaluate the models, defined as:\nAccuracy = $\\frac{TP+TN}{TP+FP+TN + FN}$,\n         (5)\nF1 = $\\frac{2TP}{2TP + FP + FN}$,\n         (6)\nwhere TP indicates the true positive, TN the true negatives, FP the false positives, and FN the false negatives."}, {"title": "VII. CONCLUSION", "content": "Our paper presents a pioneering framework using a GAN model to predict smart grid stability, effectively addressing the challenge of limited data accessibility by focusing on stable instances from available datasets. This approach aligns with real-world constraints where instability data is scarce. Our model achieves a commendable accuracy of 0.975 in stability prediction, even without instability instances in the training data, using just 32.85% of the dataset. Additionally, by incorporating a novel adversarial training layer, our framework demonstrates robustness against state-of-the-art adversarial attacks in both whitebox and greybox scenarios, classifying these attacks as instances of instability. We benchmarked our model against state-of-the-art approaches and found that while it may not surpass current best performances, it still offers high accuracy and enhanced robustness, a feature not commonly found in existing literature. In summary, our study advances stability prediction for smart grids by offering high accuracy and resilience, addressing data scarcity challenges, and enhancing operational efficiency and reliability in evolving energy landscapes with emerging cybersecurity threats."}]}