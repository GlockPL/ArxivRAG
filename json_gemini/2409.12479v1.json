{"title": "Learning Multi-Manifold Embedding for Out-Of-Distribution Detection", "authors": ["Jeng-Lin Li", "Ming-Ching Chang", "Wei-Chao Chen"], "abstract": "Detecting out-of-distribution (OOD) samples is crucial for trustworthy AI in real-world applications. Leveraging recent advances in representation learning and latent embeddings, Various scoring algorithms estimate distributions beyond the training data. However, a single embedding space falls short in characterizing in-distribution data and defending against diverse OOD conditions. This paper introduces a novel Multi-Manifold Embedding Learning (MMEL) framework, optimizing hypersphere and hyperbolic spaces jointly for enhanced OOD detection. MMEL generates representative embeddings and employs a prototype-aware scoring function to differentiate OOD samples. It operates with very few OOD samples and requires no model retraining. Experiments on six open datasets demonstrate MMEL's significant reduction in FPR while maintaining a high AUC compared to state-of-the-art distance-based OOD detection methods. We analyze the effects of learning multiple manifolds and visualize OOD score distributions across datasets. Notably, enrolling ten OOD samples without retraining achieves comparable FPR and AUC to modern outlier exposure methods using 80 million outlier samples for model training.", "sections": [{"title": "1 Introduction", "content": "In data-driven machine learning (ML), out-of-distribution (OOD) samples refer to unseen instances outside the distribution the ML models were trained on. Deploying artificial intelligence (AI) models often encounter OOD challenges due to domain shifts in test data compared to the original training data. This shift can cause trained models to be over-confident in incorrect decisions, leading to issues of trustworthiness and reliability. Detecting OOD samples from in-distribution (ID) data is challenging due to the vast OOD sample space compared to the ID data. In standard image classification tasks, the training set is considered the ID dataset, while any images outside or significantly different from the training set are considered OOD samples.\nPast research on OOD detection has predominantly focused on designing scoring functions based on predicting probabilities [27, 37]. The evolution of the scoring function includes approaches such as maximum softmax probability [10] and energy-based"}, {"title": "2 Related Work and Preliminary", "content": "We review the hypersphere embedding, hyperbolic embedding, and multiple manifold learning within the context of a classification problem with the following notations. An input data sample, denoted as x \u2208 X, undergoes processing by a model f : X \u2192 Y to predict a label y \u2208 YID, where ID denotes in-distribution. The training set contains K classes, thus YID = {y1, y2, ..., yK}. Model f is trained using ID training data x sampled from the marginal distribution PVD and produces the latent embedding z."}, {"title": "2.1 Hypersphere Embedding", "content": "Hypersphere embedding stands out with remarkable success across various ML domains, including face verification [21], person re-identification [6], emotion recognition [18], and adversarial training [24]. It was first introduced in CIDER [22] as a learning method for OOD detection. Hypersphere embedding learning methods often convert the standard cross-entropy loss into the angular space by eliminating the bias term. The resulting loss function comprises a radius term and an angular term. Since the radius term merely affects the scale, the attention focuses on optimizing the angular term. This loss function thus shapes the relationships of latent embeddings on a hypersphere. The latent embedding u is associated with an angle \u03b8y to the weight W and the corresponding label y, leading to the reformulated generalized loss function [21]:\n\nLs = \u2212log(exp(||u||\u03c6(\u03b8y)) / exp(||u||\u03c6(\u03b8y)) + \u2211i\u2260y exp(||u||\u03b7(\u03b8i))),\n\nwhere \u03c6 and \u03b7 are the angular functions for the target class and the other classes, respectively. By absorbing the negative sign in the previous equation and reorganizing the term for inter-class angular function, we can derive an angular margin \u0394(\u03b8) = \u03b7(\u03b8y) \u2212 \u03c6(\u03b8) to enlarge the inter-class distance and suppress the intra-class variability:\n\nLs = log(1 + \u2211i\u2260y exp(||u|| (\u03b7(\u03b8i) \u2013 \u03c6(\u03b8y))))\n= log(1 + \u2211i\u2260y exp(||u|| (\u03b7(\u03b8i) \u2013 \u03b7(\u03b8y) + \u0394(\u03b8))))\n\nIntegrating with metric learning, cluster centers are denoted as prototypes to capture intra-class and inter-class relationships. Prototype-based losses leverage spherical properties through a mixture of von Mises-Fisher (vMF) distributions for OOD detection [22]."}, {"title": "2.2 Hyperbolic Embedding", "content": "Hyperbolic embedding has demonstrated notable success in image recognition and person re-identification tasks [14]. Its effectiveness stems from the unique properties of the hyperbolic space, particularly its ability to handle hierarchical data structures. While hyperbolic embedding is commonly used in natural language and graph applications,"}, {"title": "2.3 Multiple Manifold Learning", "content": "Manifold learning aims to capture the latent structure of a dataset, facilitating the discovery of a low-dimensional space that offers a compact and effective representation. The key objective is to preserve the relationships between neighboring data points within the learned embedding space. Recent endeavors have expanded to the exploration of learning multiple manifolds, recognizing the manifold heterogeneity inherent in datasets [11]. These studies incorporate well-designed optimization strategies to ensure model convergence while learning multiple manifolds.\nHowever, the aforementioned works primarily focus on exploring subspaces within Euclidean space. In contrast, another research direction delves into curved manifolds, defining mixed spaces that combine manifolds with different curvatures [9]. This method has demonstrated impressive performance in benchmarks related to data reconstruction and word embeddings in natural language processing.\nDespite the rapid advancements in hypersphere and hyperbolic embeddings, the exploration of hyperbolic space and joint spaces for OOD detection remains largely untapped. This presents an intriguing avenue for future research in this area."}, {"title": "3 Method", "content": "Figure 1 overviews the proposed MMEL framework for OOD detection, including the training and inference steps. The framework is constructed by integrating the hypersphere and hyperbolic branches through a multi-task joint loss optimization scheme. \u00a7 3.1 presents the multi-manifold embedding learning. OOD scores are computed using the learned embeddings in \u00a7 3.2. \u00a73.3 presents our novel test-time enrollment approach for effective OOD detection without the need for model retraining.\nWe follow the standard OOD detection setup as follows: (1) Train a model with ID training data and freeze model parameters. (2) Run the model on test data. (3) Calculate OOD scores and identify OOD samples using a threshold."}, {"title": "3.1 Learning Multiple Manifold Embedding", "content": "We next describe the hypersphere and hyperbolic embedding learning in the following section. Then, we describe the loss optimization using these learned embeddings.\nLearning hypersphere manifold We use CIDER [22] to optimize compactness and disparity losses for a hypersphere manifold, represented by the von Mises-Fisher (vMF) distribution with a unit vector zs \u2208 R in class k and the class prototype \u03bck:\n\nPd(zs; \u03bck) = \u03c4exp(\u03bckzs/T),"}, {"title": "4 Experiments", "content": "Dataset. We use CIFAR-10 and CIFAR-100 [16] as the ID dataset and examine the performance on six other datasets that are treated as OOD: SVHN [23], Place365 [39], LSUN [38], LSUN-Resize [38], iSUN [36], and Textures [3]. In another experiment, we follow the setup in [22] and adopt the ImageNet-100 dataset as ID data which subsampled 100 classes from ImageNet [25]. Here, the other datasets regarded as OOD include SUN [35], Place365 [39], Textures [3], and iNaturalist [30].\nEvaluation metric. All methods are evaluated using two common OOD detection metrics: (1) FPR95: False positive rate at true positive rate of 95%. (2) AUC: Area under the Receiver Operating Characteristic curve."}, {"title": "4.1 Out-of-distribution Detection Accuracy", "content": "We use the ResNet-18 backbone network for CIFAR-10 and ResNet-34 for CIFAR-100 to assess OOD performance. To gauge generalization to the ImageNet-100 dataset, we fine-tune the model trained on CIFAR-100 for experiments. We follow the parameter setting of CIDER [22] to ensure comparable results.\nThe model is optimized via stochastic gradient descent (SGD) with momentum 0.9, weight decay of 10-4, and an initial learning rate of 0.5. Batch size and total epochs are fixed at 512 and 500, respectively. The intermediate layer comprises a 128-dimensional projection head. For ImageNet-100 fine-tuning, we employ a learning rate of 0.01 for 10 epochs. The curvature c of hyperbolic geometry is chosen to be 0.01. PKNN is implemented using Faiss-GPU [13] with k = 300 and p = 3.\nWe compare MMEL against 10 popular OOD detection methods, including MaxSoftmax [10], Mahalanobis [17], ODIN [19], Energy [20], Entropy [2], ViM [31], KLMatching [1], MaxLogits [1], GODIN [12], and DICE [28]. We also compare with three embedding-based methods, namely SSD [26], KNN+ [29], and CIDER [22].\nTable 1 shows that our MMEL framework outperforms other OOD detection approaches in the average FPR95 across six datasets, specifically, 14.15% and 42.61% FPR95 when using CIFAR-10 and CIFAR-100 as ID datasets, respectively. The margin of FPR95 becomes obvious with a larger ID class numbers (CIFAR-100), showcasing MMEL improvements on reducing FPR95 by 9.74% and 7.11% over the best-performed distance-based and score-based methods from other OOD detection studies, respectively.\nThe last column of Table 1 shows that MMEL excels in large-scale OOD detection on ImageNet-100, achieving 24.05% FPR95 and 94.96% AUC. The fine-tuned results"}, {"title": "4.2 In-distribution Classification Accuracy", "content": "It is a trade-off between the OOD detection performance and the underlying model's classification accuracy, which requires dedicated balance in practice. We experimented on CIFAR-100 to examine the underlying model's classification accuracy of MMEL and compare it with CIDER. Our result shows that CIDER achieves classification accuracy of 75.35% with an OOD FPR95 of 52.35%. MMEL outperforms CIDER with 75.99% classification accuracy, and also with a lower 46.12% OOD FPR95. The ID accuracy of CIFAR-10 is 94.53%, 94.59%, and 94.61% for SSD, CIDER, and MMEL. Score-based algorithms (e.g., GODIN, DICE) obtain equal accuracy (94.52%). MMEL outperforms these score-based algorithms (74.60%) in CIFAR-100, without showing a tradeoff between ID and OOD performance. This outcome affirms that incorporating additional manifolds in MMEL improves OOD detection; meanwhile, it does not compromise ID classification accuracy."}, {"title": "4.3 Ablation Studies of Different Manifolds", "content": "In this ablation study, we examine single-manifold embedding learning approaches and various scoring functions. In addition, we broaden the comparison by incorporat"}, {"title": "4.4 Visualization of OOD Scores", "content": "The OOD score plays a pivotal role in determining OOD detection outcomes and provides insights into the underlying distribution of ID and OOD data. To visually present these distributions, Figure 3 plots the histogram of OOD detection scores for all test samples in each case, coloring ID samples in blue and OOD samples in green. Each row shows plots for each dataset, and each column shows plots for each algorithm. Greater separability in scores between ID and OOD histograms suggests better OOD detection performance."}, {"title": "4.5 Evaluation of Test-Time Sample Enrollment", "content": "We evaluate the OOD enrollment approach (in \u00a73.3) for various OOD detection scenarios. \u00a74.5 shows enhanced results using very few enrolled OOD samples compared to the best MMEL results in \u00a74.1. \u00a74.5 further investigates a scenario where the ID dataset is expanded with additional classes. We discuss the different scenarios for enrolling the new classes in either the ID or OOD set for evaluation.\nImprovement from enrolling a few OOD samples Figure 2 shows the results with varying values of Ne within the set {1, 2, 3, 5, 10} using CIFAR-100 as ID data. The averaged FPR95 across six OOD datasets decreases as Ne increases, plateauing after Ne suppresses three. Notably, incorporating enrolled samples leads to a 16.68% reduction in FPR95 compared to the scenario without any enrolled samples. Although the AUC metric sees only a marginal improvement, it follows a similar trend. It's worth noting that the decline of FPR95 is not homogeneous across all OOD datasets. For instance, the iSUN dataset sees a substantial drop from 61.46% to 34.57% of FPR95, with the enrollment of ten OOD samples. On the other hand, datasets like SVHN and LSUN, which already exhibit low FPR95 with our MMEL framework, show limited benefits from the enrollment approach. These findings indicate that a significant improvement is achievable in FPR95 by enrolling a small number of known OOD samples. Additionally, the results highlight the advantages of distance-based embedding learning methods, facilitating straightforward prototype estimation with new anchor samples.\nWe next compare experimental results against the outlier exposure method [34], which leverages an auxiliary dataset to learn the OOD space. Note that the selection strategy for this auxiliary dataset requires further investigation, and the inclusion of outlier training may compromise ID accuracy.\nTable 4 shows our OOD detection results comparing with ICE [34], the state-of-the-art outlier exposure method. ICE achieves 34.96% FPR95 and 90.90% AUC through training on an 80-million auxiliary OOD dataset. In comparison, our MMEL, utilizing only 10 samples for enrollment, yields comparable results of 30.48% FPR95 and"}, {"title": "5 Conclusion", "content": "The detection of out-of-distribution (OOD) instances is crucial for the safe and reliable deployment of AI in real-world scenarios. Traditional OOD detection research has ignored the data diversity in embedding learning and suffered the distortation risk in modeling the whole ID data in a single manifold structure. In this work, we introduce a novel multi-manifold embedding learning (MMEL) framework that incorporates hypersphere and hyperbolic embeddings, coupled with a prototype-aware KNN scoring function, to enhance the robustness of in-distribution (ID) representations. Our proposed framework demonstrates significant performance boost. With flexibility of modeling multi-manifold data, we put forth an OOD sample enrollment scenario to further diminish FPR for real-world applications. Further experiments highlight the potential to enroll either ID or OOD samples with minimal samples collected during test time.\nFor future work, exploring manifold optimization for ID data preservation and extending the MMEL for continual OOD detection with manifold adaptation can substantially enhance usability of OOD detection."}]}