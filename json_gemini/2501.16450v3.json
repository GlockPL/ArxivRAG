{"title": "360Brew: A Decoder-only Foundation Model for Personalized Ranking and Recommendation", "authors": ["Maziar Sanjabi", "Hamed Firooz"], "abstract": "Ranking and recommendation systems constitute the foundation for numerous online experiences, ranging from search results to personalized content delivery. These systems have evolved into complex, multilayered architectures that leverage vast datasets and often incorporate thousands of predictive models. The maintenance and enhancement of these models is a labor intensive process that requires extensive feature engineering. This approach not only exacerbates technical debt but also hampers innovation in extending these systems to emerging problem domains.\nIn this report, we present our research aimed at addressing these challenges by leveraging a large foundation model with a textual interface for ranking and recommendation tasks the LinkedIn platform\u00b9. We highlight several key advantages of our approach in contrast to mainstream methods, which are predominantly ID-based. Specifically, our approach: (1) a single model can manage multiple predictive tasks involved in ranking and recommendation within LinkedIn's services, (2) decoder models with textual interface due to their comprehension of reasoning capabilities, can generalize to new recommendation surfaces and out-of-domain ranking and retrieval tasks in a zero-shot manner through simple prompts, thereby enabling product designers to engage with and iterate on them with ease, and (3) by employing natural language interfaces for task definitions and verbalizing member behaviors and their social connections, we eliminate the need for feature engineering and the maintenance of complex directed acyclic graphs (DAGs) of model dependencies. We introduce our research on our pre-production model, 360Brew V1.0, developed by a small team of researchers and engineers over a 9-month period. 360Brew is a 150B parameter, decoder-only model that has been trained and fine-tuned on LinkedIn's primarily first-party data and tasks (from users outside European Union). This model is capable of solving over 30 predictive tasks across various segments of the LinkedIn platform, achieving performance levels comparable to or exceeding those of current production systems based on offline metrics, without task-specific fine-tuning. Notably, each of these tasks is conventionally addressed by dedicated models that have been developed and maintained over multiple years by teams of a similar or larger size than our own.\nThe primary objective of 360Brew is to enhance AI development productivity across LinkedIn by centralizing common modeling components into a foundational layer. This approach facilitates fundamental modifications, moderation, and governance at the foundational level, ensuring simultaneous benefits across all platforms. Additionally, developers are empowered to rapidly iterate on new objectives, data sources, and AI-driven search and recommendation products.", "sections": [{"title": "1 Introduction", "content": "Production-level Recommendation Systems (RS) are built to provide a better experience for Internet users by matching them with the content such as posts, jobs, people. These systems are at the heart of many internet applications, e.g., search, social networking, e-commerce, and many more [1, 2]. RS often consists of many layers and models. In Figure 1 we show a simplified version of such complex systems. On the one side are generally members whom the systems want to recommend jobs, posts,"}, {"title": "1.1 Status Quo of RS Models", "content": "The retrieval and ranking layers in RS typically rely on ID based features for members and items. Essentially, these are large embedding tables where each embedding represents a (few) member(s)/item(s).\nIn addition to the ID based features, manually engineered features such as member/item interactions and item attributes are employed for richer representation learning. However, this process demands a perpetual process of improving and maintaining these models by large engineering teams.\nIn the rest of this section we discuss the challenges and active areas of research in RS modeling. Interestingly these challenges are mostly a direct result of using ID based and hand-crafted features.\n\u2022 Cold-start: The RS models rely on currently available IDs and cannot generalize to new members and items without frequent re-training. This frequent and computationally heavy process is necessary for adapting to new items/members and varying member behaviors (see the following points). As a result, a large body of works have been dedicated to solving this issue through approaches such as content-based representations [6, 7].\n\u2022 Interactions: Older RS models were primitive and required most of the cross features between member(s) and item(s) to be hand-crafted. With the popularity of deep neural networks (DNNs), architectures, such as DCN [4], which would allow automatic crossing of the item and member features became popular. More recently, there have been many works proposing more advanced architectures, e.g. transformers, for this purpose [8, 9].\n\u2022 Domain generalization: Most of the RS models are super-specialized, through the use of ID based and specialized embedding features. Such models are trained on specific interactions from a specific domain and cannot generalize to new surfaces and tasks [10]. For example, they cannot go from feed recommendation to job recommendation (surface change), or start predicting member's interaction instead of member's ratings (task change).\nIn this work we introduce 360Brew which is LinkedIn's venture project to build RS models based on modern and powerful LLMs that can naturally address the above-mentioned drawbacks of traditional RS models."}, {"title": "2 360Brew", "content": ""}, {"title": "2.1 Overview", "content": "Foundation models have achieved an unprecedented level of generality by leveraging scale and attention-based architectures [11, 12]. Recent advancements in decoder-only model architectures that use language as an input interface have demonstrated their capabilities in understanding, reasoning, and solving a variety of tasks beyond natural language processing, including graph understanding [13, 14, 15], robotic planning [16], and knowledge base management [17, 18], among others.\nRecent research has explored the application of large pre-trained decoder-only models to member-item recommendation tasks [19, 10]. The emergent problem-solving and reasoning capabilities of these models allow them to process member and item information\u2014such as member profiles and job or post descriptions\u2014and assess their relevance with high accuracy. This capability enables the models to exhibit improved performance on cold-start problems without additional modifications.\nTraditional ranking models often rely on hundreds of thousands of handcrafted features and complex architectures to capture high-order interactions among these features [4]. In contrast, the deep, multi-layer transformer architecture of LLMs can extract the necessary features directly from contextual information that is provided in text to address the task at hand [20]. This approach eliminates the need for feature engineering at the item or member level, as all input is processed as text by the model. Furthermore, LLMs are adept at generalizing to different item types and interactions, enhancing their out-of-the-box ability to adapt to new items, surfaces and interaction patterns. This property supports broad generalizability in new contexts.\nIn many practical use cases, traditional RS utilize text and content understanding models solely as feature generators to enhance ID-based models [6, 7]. However, our approach goes a step further. Instead of merely using these models to produce embeddings or features for the system, we aim to replace the entire model with an LLM that employs a natural language interface. This approach"}, {"title": "2.2 Results", "content": "In this section, we present the results from developing the 360Brew V1.0 model. The 360Brew model V1.0 is built on top of Mixtral 8x22 pre-trained MoE [26] architecture\u00b3. We further train it using a combination of LinkedIn raw entity data such as member profiles, job descriptions, and LinkedIn posts and interaction data (including member job applications) across 5+ surfaces on LinkedIn. More details to come soon.\nFinally, we apply the model to 30+ tasks across 8+ surfaces. Notably, not all tasks are in-domain, as some surfaces and tasks are outside the training data that the model has seen. Specifically, we categorize the tasks as follows:\n\u2022 T1 (in-domain): Tasks where recommendation data from past periods is used in training the model. There is at least a one-month gap between the T1 data used in training and the benchmark dataset. This means the data is subject to distribution shift, which is very common in recommendation systems, but the model has seen member behavior in the past for these tasks.\n\u2022 T2 (out-of-domain): Tasks and surfaces that are not part of the training data. In these tasks, the model is evaluated on data from domains or recommendation use cases that it has not encountered during training, representing an out-of-domain distribution.\nOur model is flexible and can predict different type of outputs based on the prompt. However, for simplicity and ease of scaling, the majority of traditional large industry ranking models are framed as binary tasks, such as P(like). Therefore, we also adapt our prompts so that the model generates binary predictions when answering questions about whether a member likes a post, allowing for direct comparison with these models. We use the logits for these tokens to obtain scores and compute metrics such as AUC, etc."}, {"title": "2.3 Data Scaling", "content": "As mentioned earlier, one of the most compelling benefits of building foundation models for ranking is the reduced development time. The way that this goal is achieved is by training a single large model"}, {"title": "2.4 Model Scaling", "content": "Recent works have shown increasing the size of the LLMs improves their capabilities in understanding the context and performing tasks [11]. In Figure 3 we show that the same holds in RS use-cases and 360Brew models get better as we increase the size of the model (by using larger and more powerful pre-trained architectures). This shows that there is an added value in modeling more complex relationships or reasoning by using larger model architectures in RS use-cases."}, {"title": "2.5 History Scaling", "content": "As mentioned above, one advantage of 360Brew model is that it does not require manual feature engineering. In Figure 4, we show that 360Brew model's performance gets better as we increase the history by increasing the max context length. The take-home message here is that improving processed history (by using more compute) could be an effective way of improving the performance of the RS. It is worth noting that the story here is a bit more nuanced than other scaling laws since the performance of the model could be affected by the underlying model's limitation on its context length. For more details see More details to come soon. We believe that the technical and modeling limitations on the context length will be alleviated with more advances in pre-trained LLM architectures. Based on our results, such advancements could directly benefit the 360Brew model."}, {"title": "2.6 Generalization", "content": ""}, {"title": "2.6.1 Out of domain", "content": "In Figure 5 we show that the 360Brew model can generalize to out-of-domain tasks and surfaces, and achieves performance similar to or better than the production model."}, {"title": "2.6.2 Cold-start", "content": "In Figure 6 we show the gap between the 360Brew model and the production model as max number of historical data points decreases from 100 to 5. As shown in the plot, the performance gap between the two models is the largest when member has few available interactions, which shows that 360Brew model has a greater margin over the production model for members with fewer interactions. These are usually called cold start members since they do not have many interactions."}, {"title": "2.6.3 Temporal", "content": "One major downside of the current recommendation systems is that they do not generalize well over time, and the relationships that they have extracted might be irrelevant to the data distribution shifts. This results in frequent updating of the model which increases the maintenance cost, development time, and complexity of the systems. In Figure 7, we benchmark the performance of the 360Brew model on different test data that lie within different time frames (in the future) from the training data. We do the same with the baseline models and show that the performance of the 360Brew model is less affected by time. This means that using 360Brew could potentially lead to more developer efficiency and less maintenance and technical debt as we do not need to update the model so frequently. This is possible since 360Brew model can use ICL to adjust its answers based on the member behavior it sees in its context. More details to come soon."}]}