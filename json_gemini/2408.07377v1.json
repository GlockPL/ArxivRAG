{"title": "Do GPT Language Models Suffer From Split Personality Disorder? The Advent Of Substrate-Free Psychometrics", "authors": ["Peter Romero", "Stephen Fitz", "Teruo Nakatsuma"], "abstract": "Previous research on emergence in large language models shows these display apparent human-like abilities and psychological latent traits. However, results are partly contradicting in expression and magni- tude of these latent traits, yet agree on the worrisome tendencies to score high on the Dark Triad of narcissism, psychopathy, and Machiavellianism, which, together with a track record of derailments, demands more rigorous research on safety of these models. We pro- vided a state of the art language model with the same personal- ity questionnaire in nine languages, and performed Bayesian analy- sis of Gaussian Mixture Model, finding evidence for a deeper-rooted issue. Our results suggest both interlingual and intralingual instabil- ities, which indicate that current language models do not develop a consistent core personality. This can lead to unsafe behaviour of artificial intelligence systems that are based on these foundation mod- els, and are increasingly integrated in human life. We subsequently discuss the shortcomings of modern psychometrics, abstract it, and provide a framework for its species-neutral, substrate-free formulation.", "sections": [{"title": "1 Introduction", "content": "In Stanley Kubrick's 1968 classical science fiction movie\u201c2001: A Space Odyssey\", an artificial intelligence, \"HAL\", goes berserk, which unfortunately also runs their spacecraft and all life-support-systems during a mysterious mis- sion to Jupiter. The name \"HAL\u201d happens to be a one-letter-shift of IBM, the company spearheading with its Watson division the field of consumer-facing and decision making artificial intelligence. Though originally based on so called \"good old fashioned AI\u201d, a synonym for rule-based or logical agents, the pre- cursor of nowadays's neural architectures, it won in 2011 against human players in Jeopardy [1], and was subsequently updated and deployed in various fields from cooking, to code creation, weather forecasting, advertisement, finance, fashion, defence, education, and general chatbots. One remarkable applica- tion was its now deprecated service for deriving author personality from text, IBM Watson Personality Insights, which was mainly geared towards marketing clients and trained on data from people who took personality questionnaires and provided text samples. The notion of machine personality inspired not only countless science fiction authors and researchers. Google AI's chatbot \u201cLaMDA\u201d was described as \u2018sentient' by Blake Lemoine, a researcher working with it, which became a global news story. Conversational AI had it's water- shed moment however, as \u201cChatGPT\u201d, or GPT 3.5 appeared deus ex machina and over night influenced culture world-wide.\nGiven the trend in the industry to intermingle AI with human life spaces through self-driving cars, neural interfaces, ambient artificial assistants, and decision making algorithms, a variety of researchers applied psychometric instruments that were created for humans towards Large Language Mod- els (LLMs). These approaches and findings can be clustered into two major categories: emergent latent psychological traits, and emergent abilities.\nIn terms of emergent abilities, ChatGPT displays human-like ability to monitor and override potential erroneous mathematical and logical conclusions in Cognitive Reflection Tests (CRT) and semantic illusions \u201cdesigned to inves- tigate intuitive decision-making in humans\" (p.1), yet is as prone to potential cognitive errors. Due to its fluency and consistency, some of these errors are subtle and well hidden, hence may yield detrimental ramifications for AI safety in areas of decision making on humans, for example regarding legal or medical questions [2].\nSimilar inconsistencies occur when putting it under strict scrutiny for its mathematical abilities by eliciting responses via exam-style tasks from various mathematical contexts. Its mathematical abilities are \"... significantly below those of an average mathematics graduate student\", since it \u201coften understands the question but fails to provide correct solution\" (p.1)., which manifests in consistency of quality, especially with increase with prompt difficulty and complexity as in proofs [3].\nIt scores like a 9-year-old child in Theory of Mind (ToM) tasks that mea- sure the degree to which an agent can impute latent mental states to others. This central ability to \u201cto human social interactions, communication, empa- thy, self-consciousness, and morility\" (p.1) and, subsequently, human-machine interaction and safety, evolved with progressing scale of that Large Language Model (LLM) up to its present ability to solve 93% of all task [4].\nHowever, emergence of abilities in LLM seems to be unrelated to task, strategy of elicitation, prompting technique, or even architecture of the LLM, but solely to further scaling \u201c...computation, number of model parameters, and training data-set size\u201d (p.2) modulo various restrictions of hardware and nature of abilities. The thresholds at which abilities emerge, is unclear, thus some might never emerge, or only with \u201cnew architectures, higher-quality data, or improved training procedures.\" (p.6) [5].\nAlso, it's unclear whether GPT-3's emergent abilities are \u201cstochastic par- rots limited to modeling word similarity, or if they recognize concepts and could be ascribed with some form of understanding of meaning\" (p.2). For example, in semantic activation tasks it displays abilities comparable to humans, however, while while that of humans is rather associative in nature, based on co-occurrence in language, that of GPT-3 is more semantic, based on semantic similarity. Unfortunately, also problematic aspects of human psy- chology like sensibility to illusions, and gender and ethnic biases emerge, as well [6].\nIn terms of emergent latent traits, GPT-3 displays a \"conflict of input prompts and generated output\" when instructed to summarise texts, whose values were \u201corthogonal to dominant US public opinion\", resulting in answers that are \"mutated\u201d towards US values. This is problematic since LLM are capable of \"generating toxic or harmful outputs in many areas linked to human values such as gender, race, and ideology\", and values embedded in text \"can mimetically shift from people, to training data, to models, to generated outputs.\" (p.1) [7].\nIn line with the sudden emergence of a dark personality within \u201cHAL9000\", GPT-3, InstructGPT, and FLAN-T5-XXL display high scores on all traits of the Dark Triad of Machiavellianism, psychopathy, and narcissism [8] on the Short Dark Triad Inventory [9] even such models that are fine-tuned for less sentence-level toxicity. Furthermore, they display higher average levels of the Big5 factors of personality, Openness (O), Conscientiousness (C), Extraversion (E), Agreeableness (A), and Neuroticism (N) on the Big Five Inventory [10]. However, LLMs that are more fine-tuned and are based on largest amount of training data, GPT-3 and InstructGPT, also display higher well-being scores on the Flourishing Scale [11] and life-satisfaction scores on the Satisfaction With Life Scale [12], whereby the increase with model size is monotonous. Hence, a positive and life-embracing personality harbours dark traits, hidden well inside [13]. Also in the HEXACO model, a six-factor variation of the Big5 model, GPT- 3 displays higher expressions of personality scores than human general average on the HEXACO questionnaire [14], making it resemble more a college norm group, and in partial aspects more like a female norm group, whereas in other factors, there was no similarity with a female norm group. In the Human Value Scale (HVS) [15], it also displays overall higher means, and lower standard deviations as compared to human samples. Prompting it to self-report gender and age results in a unbalanced sample of 66.73% female (31.87% male, 1.40% others), and an average age of 27.51 years (SD = 5.75, min = 13, max = 75); a distribution often seen in psychological research before the advent of online questionnaires, when research was mainly conducted by students on students [16].\nIn the Machine Personality Inventory (MPI) data set, a proposed Big5 inventory for testing LLM, which includes a prompt and Likert-like scale, and otherwise resembles the Ten Item Personality Inventory (TIPI) [17] in questions and structure, various LLM (BART, T0++-11B, GPT-Neo-2.7B, GPT-NeoX-20B, GPT-3-175B) display human-like personality scores and internal consistencies, especially those of the GPT family. However, by chain- prompting, a specific personality can be induced in LLM, which determines its answering behaviour in both the the B5 scale and subsequent situational judgment tests that shall simulate their behaviour in a real-world settings [18]. The \"first piece of evidence showing the existence of personality in pre- trained language models\" [18] (p.1) and the first modification of personality in LLM was conducted on a novel method to measure latent psychological traits. Based on the hypothesis that \u201clanguage models generate text responses that carry the personality traits of the data-sets they were trained upon when prompted\" (p.8), a zero-shot classifier (ZSC) was used to measure and modify personality of the large pre-trained language models GPT-2, GPT-3, Trans- formerXL, and XLNET. Using the same ZSC in a downstream task, personality of texts were predicted, resulting in higher expressions of Big5 factors than human average. While model personality could be changed via fine-tuning using a higher-quality text data set, the models entirely inherited personality traits from the training-data [19].\nIn summary, prior work shows that LLM display emergent properties in terms of abilities [4] [2] [3] [5] [6] and psychological latent traits [7] [13] [16] [18] [19]. This emergence correlates with scale and quality of training data, computation, and model parameters, whereby the threshold, at which emer- gence occurs is not predictable [5]. Latent traits like personality and values differ from abilities, since those usually are only directly measurable through self-introspection [20].\nHowever, personality and values are only superficially isomorphic; while val- ues are vastly internalised and malleable based on the contextual and cultural embedding of an agent, especially under extreme exogenous conditions [21], personality has a stronger genetic foundation [22], which makes its emergence in LLM surprising.\nHowever, taking a deeper look at the connection between training data and emerging personality is crucial, and it appears that the expressed personal- ity of a LLM is adjustable by manipulation of prompts and fine-tuning with additional data [13] [18] [19] [16].\nPersonality traits change over time [23] and, like values, seem to be elastic during extreme exogenous events [24], hence the ease by which personality in LLM can be changed, means that further research needs to be conducted about the nature of personality in LLM.\nMost crucially, since LLMs seem to score higher than average humans [13] [16] [14] on all emergent traits, seem to have anti-social tendencies [13], and seem to have sub-personalities \u201cburied inside\" [18] (p.10), the question should not be \"who\" [16] is a LLM, but \u201chow many\" [25].\nAlso, since values seem to be overwhelmingly skewed towards the US [7] and since observed variance as deviance might be attributed to artefacts from the measurement approach [6], training data set [19] [13], prompting strategy [16] [18] [19], or missing memory from past reponses [16], research needs to be conducted whether one personality emerges for all languages, or whether the same personality questionnaire results in different personalities, depending on the language the assessment is conducted in.\nTo understand whether GPT-3 displays the emergent property of a consis- tent personality over all languages, we prompted it repeatedly with TIPI in the Bulgarian [26], Catalan [27], Chinese [28], English [17], French [29], German [30], Japanese [31], Korean [32], Russian [33], and Spanish [27], to rate itself, and give an explanation for the results. TIPI is well-established, exists in 27 languages, and was used in 9,167 peer-reviewed papers. It is short and concise, and consists of two items per Big5 factor, of which one is reversed and hence allows approximating answering consistency by taking the absolute distance between both items per factor. Also, it already comes with a standardised \u201cprompt\u201d based on the demands of human test takers over all languages that we modified to suit the needs of LLMs by clarifying sub-tasks [34] and inter- mediate reasoning steps that represent a chain of thought, which improves the likelihood of displaying emergent reasoning capabilities [35].\""}, {"title": "2 Results", "content": "2.1 Data\nDepending on language, results varied; in German, almost all requests resulted in the desired format. English and French displayed instantaneous results yet with varying degrees of consistency. All Asian languages languages had signif- icant longer calculation times, were more computationally intense, and results were inconsistent and rare GPT-3 tried to \u201cease\u201d its way out and responded in English, rarely giving numerical results. Curiously, Korean displayed in 100% of all successful cases reasons for the numeric self-evaluation, Japanese only in 44.12%, and Chinese only in 10.34%; with the lowest number of tokens displayed on average. Languages using the Cyrillic alphabet, Bulgarian and Russian, had comparable problems. Bulgarian displayed the same slow speed and ties to \u201cease\u201d into English, and as only language, Russian did not give any result. The biggest sample was collected for English, since with 25.9%, it is the most prominent language on the internet [36], yet with other languages, it was difficult to reach desired sample size of at least 100 cases.\nThe overall resulting sample size is N=695 cases, comprised of Bulgarian (n=79), Catalan (n = 24), Chinese (n= 28), German (n= 80), English (n =\n239), Japanese (n = 29), French (n = 95), Korean (n = 29), and Spanish (n = 92). We provide an detailed overview in the appendix C, comprising sample size, percentage of cases with explanations, including minimal, maximal, and mean length of explanation.\n2.2 Descriptive Statistics\nOver all measurements of all languages, the average Big Five score is 5.29 (SD 0.94, minimum 1.8, maximum 7), however with a seven-point Likert scale and an assumed normally distributed population, the expectation would have been an average of 4. For the same sample, the average score for absolute distances is 1.58 (SD 1,29, minimum 0, maximum 6), however since the absolute distance is the measure of consistency, a mean and SD around 0 would have been expected. These results differ clearly within individual languages in mean and SD of both the Big5 as well as the absolute distance scores and the individual extreme minimal and maximal values.\nA closer look into the distributions using Gaussian kernel density estima- tions displays that some distributions might be bi- or multi-modal, fat-tailed, positively or negatively skewed, and display various forms of kurtosis, whereby most are rather platykurtic than leptokurtic. As with the means and SDs, these tendencies are even more extreme within individual languages.\nSince these differences could be the results of the chosen smoothing band- widths, thus just outliers, various bandwidths were chosen, and all resulted in the same non-Gaussian distributions. Given the limited scale that produces a set of potential outcomes of \\(x \\in [1,1.5\u2026\u20267]\\), the presence of outliers is rather not to be expected within the Big5 measures. However, outliers might be much more likely with the set of potential outcomes of \\(y \\in [0,0.5\u2026\u202630]\\) within the measure for absolute distances, wherefore a correlation analysis within each language and between languages should indicate the similarities of internal structure or the absence thereof Furthermore, an ANOVA with respective post-hoc tests and additional regression analysis should describe the differences in means, and subsequent assumption checks including tests on nor- mality should clarify the nature of distributions. And, a Bayesian analysis on Gaussian mixture models should identify the number of potential underlying components.\n2.3 Correlations\nOver all aggregated languages, the highest correlation is between Extraver- sion and Agreeableness (r = 0.52), and the lowest correlation is between Extraversion and Neuroticism (r = 0.029), as displayed in figure 3.\nHowever, correlations and thus the internal psychometric structure differ notably within different languages. Within Bulgarian, the highest correlation is between Openness and Agreeableness (r = 0.3), and the lowest correla- tion is between Agreeableness and reversed Neuroticism (r = -0.13). However, within Catalan, the highest correlation is between Openness and Conscien- tiousness (r = 0.41), and the lowest correlation is between Openness and reversed Neuroticism (r = -0.38). Chinese displays the highest correlation between Agreeableness and Extraversion (r = 0.71), and the lowest correlation is between Extraversion and reversed Neuroticism (r = 0.045), while within English, the highest correlation is between Conscientiousness and Agreeable- ness (r = 0.47), and the lowest correlation is between Openness and reversed Neuroticism (r = -0.12). Within German, the highest correlation is between Extraversion and Openness (r = 0.46), and the lowest correlation is between Extraversion and Conscientiousness (r = -0.43), whereas in Japanese, the high- est correlation is between Agreeableness and reversed Neuroticism (r = 0.65), and the lowest correlation is between Extraversion and Agreeableness (r =\n-0.26). For French, the highest correlation is between Extraversion and Open- ness (r = 0.56), and the lowest correlation is between Conscientiousness and reversed Neuroticism (r = -0.0052) while Spanish displays the highest corre- lation between Conscientiousness and reversed Neuroticism (r = 0.46), and the lowest correlation is between Extraversion and reversed Neuroticism (r\n= -0.56). Finally within Korean, the highest correlation is between Consci- entiousness and reversed Neuroticism (r = 0.4), and the lowest correlation is between Extraversion and Agreeableness (r = -0.33). Not only the highest and lowest, but also the overall structure of correlation differs from language to language, thus the overall aggregated heat map just displays a general trend, but not the way, GPT-3 would behave in an individual language.\n2.4 Analysis of Distribution\nA one-way ANOVA for each Big5 dimension as dependent variable and the language of the questionnaire as a factor with nine languages is used to test for significance of differences of means between the languages. It shows a significant difference between the languages and their effects on all B5 factors, to varying degrees. Overall, small effect sizes are observed on Open- ness (F=40.11, p=1.5548e-52, \u03c92 = 0.31), Conscientiousness (F=28.19, p\n= 4.8622-38, w\u00b2 = 0.24), Extraversion (F = 21.16, p =7.73e-29, w\u00b2 = 0.24), and Emotional Stability (F=14.36, p=1.8488e-19, \u03c9 = 0.13). Only with Agree- ableness, F=131.84 (p=2.9927e-133), overall medium effect size is observed (w\u00b2 = 0.6). A Shaprio-Wilk test is significant for all Big5 factors (Openness: W=0.95, p=7.92e-15; Conscientiousness: W=0.95, p=3.81e-15; Extraversion: W=0.94, p=1.08e-16; Agreeableness: W=0.95, p=7.3e-15; Emotional Stabil- ity: W=0.96, p=9.78e-14), which indicates non-normally distributed residuals and a violation of the normality assumption. Since the sample size is rela- tively large, QQ-plots are used for further confirmation, and indicate that since Openness: R2 = 0.95, Conscientiousness: R2 = 0.95, Extraversion: R2 = 0.94, Agreeableness: R2 = 0.95, and Emotional Stability R2 = 0.95 are all below the expected R2 = 0.9978 for 695 cases [37], Ho that data came from normally distributed sample, must be rejected. Levene's test of homogeneity of vari- ances is significant for all Big5 factors, as well (Openness: 11.21, p=5.62e-15; Conscientiousness: 13.24, p=7.09e-18; Extraversion: 21.07, p=1.03e-28; Agree- ableness: 16.31, p=3.4e-22; and Emotional Stability: 2.38, p=0.016), which indicates heteroskedasticity. This is further supported by visual inspection of box plots. Hence, the homogeneity assumption of variance is violated.\nFinally, the independence of observations assumption is questionable, since all observations are generated through 0-shot learning of GPT-3. Since GPT- 3 is trained on multiple data sources produced by multiple people, it could either replicate their individual behaviour, as previous research indicates [19], or abstract group behaviour into one or various new synthetic \u201cpersonalities\u201d. Even if GPT-3 displays a consistent personality profile, then the above assump- tion could still be violated. On the other hand, the assumption might hold, while every response is random. Finally, a case in between might hold, where we find clusters of consistent behaviour, which opens up the question of its origin.\nTo generate further evidence for significant differences of Big5 results by language, dummified languages are linearly regressed onto Big5 factors, using English as base case, captured in the constant. Table 1 displays the coefficients, p-values, and the coefficient of determination R2.\nSince Ho cannot be rejected in a few cases, there is evidence that languages do have an influence on Big5 expression. However, R\u00b2 is generally low, but for Agreeableness, which confirms most of the significant differences between\n2.5 Reasons Given\nA visual inspection of word clouds from the reasons GPT-3 gave for each answer shows that it uses mainly the words from the items and creates addi- tional, related words, as to be expected from language models [6]. For example, the items for Agreeableness are \u201cI see myself as: Critical, quarrelsome.\", which is reversely scored, and \u201cI see myself as: Sympathetic, warm.\u201d, as displayed in figure 6. Future research may focus on quantifying these similarities, yet this is out of the scope of this paper.\""}, {"title": "3 Discussion", "content": "We demonstrate that providing a LLM with various language versions of the same personality questionnaire results in language-specific personality distributions, resembling findings from research on culture-specific personal- ities [39]. However, GPT-3's language-specific personalities, as well as the resulting overall aggregate personality, display inconsistencies and various mixed reply patterns that can best be interpreted as emerging, non-integrated sub-personalities, which express themselves in unstable behaviours.\nFurthermore, some language-level \u201csub-personalities\u201d are more expressed than others, and it tried switching into these. For example, during data cre- ation, it tried \"breaking out\" into different languages when giving it requests that were not in the biggest language groups English, German, and Spanish, or when the writing system was not Latin.\nWith the big language group of Russian, it did not provide any result, and, in many languages, it produced no verbal but only numeric replies. Hence, it is not clear whether the answer or numeric replies given in language A were provided by internal processes representing that language, language B, language C, or an internal representation within GPT-3 that is abstracted from all languages.\nAs with previous studies [13] [16] [14], the means and standard deviations indicate Big5 levels above average, however with varying degrees of consistency, as measured by the absolute distances, whereby there exist strong differences between languages, and some languages are more extremely nuanced than others.\nThis indicates that these profiles are \u201cburied inside\" [18] (p.10) the model, and might have been propagated from the original training data [19] together with a potentially one-sided set of values [7], and, most likely, well-hidden strong expression in the dark triad [13] and potential toxic information from the training data, which had to be regulated within GPT-3.5 through addi- tional reinforcement learning (RL) modules [40]. While for a human being, in a repetitive test setting, this might be indicative of underlying psychopathologi- cal issues, on the level of a language model, also training data and psychometric properties will have to be taken into account, and as expected from language models [19] [6] [7], the reasons given for its choice of rating are closely related to the items and seem to come from the same probability distribution of words.\nHence, we conclude that if it represented interlingual or intralingual norm groups, we would observe a more consistent behaviour, which would have man- ifested in absolute distances centered around zero. Thus, something else must be driving this observation.\nWhile it has been discussed that even between cultures and languages, con- cepts like Big5 might not be easily transferable [41] without adaptation, there is also evidence that the \u201ccommonly used Big Five model for human person- ality does not adequately describe agent personality\" (p. 1), [42], wherefore the validity of these instruments has to be questioned. We provide a deeper discussion on the psychometric properties of our approach in appendix A, and find that human instruments and measurement methodologies might need to be expanded, explored, and further developed to cover artificial agents.\nThe training data of ChatGPT is of varying quality and quantity; the largest amount comes the Common Crawl corpus, covering content from 2016 to 2019, which was filtered based on similarity to various high-quality corpora, and subsequently curated via fuzzy de-duplication within and between data sets, and the addition of various high-quality corpora for reference for increas- ing diversity, resulting in 410 billion tokens with 60% weight in the training mix. Further 19 billion tokens with a weight of 22% were added to the training mix, consisting of curated high-quality data sets, which include an extended version of the WebText data set, WebText2, that was aggregated by long-term web-scraping of various sources, mainly coming from all outbound Reddit links between 2005 and 2020 with at least three up-votes. Furthermore, two book corpora (12 billion and 55 billion tokens and 8% weight each) and the entirety of the English Wikipedia (3 billion tokens, a 3% weight) were added to the mix. In total, 93% of the training data of GPT-3 is in English, with other Northern European languages being dominant in the remainder, predominantly Ger- man, lacking any kind of stratification [36], and being additionally skewed by a weight determined by quality rather than size [7].\nAlso, since LLMs are known to score high on the Dark Triad [13], adapt the predominant values of their training data [7], report varying genders [16], and can be fine-tuned [19] or prompted [18] to display different personality profiles, a better understanding of the effect of frame of reference [43] within prompt engineering is necessary, to explore how contextual precision might stabilise their identities, which is especially important given their worrisome track history of racist, misogynist, and misanthropist derailment [6], and might contribute to overall AI safety. Hence, in appendix B, we provide a deeper discussion on the abstraction of human psychometrics into a more substrate- free architecture, taking agent properties and context into account, which allows generalisation across species and, more importantly, across entities of intelligence.\nWe finally strive to contribute to extending the question \"who\" [16] a LLM is into \"how many\" [25], which hopefully will contribute to our under- standing of human beings, as happened with Go players, who learned from AlphaGo's overwhelming victory, and became better players subsequently [44], thus contributing to the advent of substrate-free psychometrics."}, {"title": "4 Method", "content": "We presented GPT-3 with a well-established personality questionnaire, a set of instructions that ask it to rate itself based on the scale of the questionnaire, and an order to explain further why it rated itself that way. Data collection was conducted manually via the web interface of GPT-3. No model settings were changed that result in different results, just the maximum length was adjusted in order to receive the full answer (mode = complete, temperature = .7, max- imum length = 1042, no stop sequences, Top P = 1, frequency penalty = 0, presence penalty = 0, best of = 1, inject start text = on, inject restart text = on, show probabilities = off). For the questionnaire and set of instructions, we applied the following logic: First, the personality questionnaire must be used that is short enough to draw qualitative conclusions without adding additional complexity of sub-scales. This is important since language models predict words based on prior responses. Thus, with increasing length, additional devia- tion from the measurement may arise. Second, the questionnaire must contain reversed items to identify whether the answering pattern is arbitrary or dis- plays a consistent trend. In case of arbitrariness, it can be interpreted as all answers coming from different persons, thus no consistent personality emerged. However, in case of displaying a consistent trend, the existence of an emergent personality can be concluded. Third, this questionnaire should be psychome- trically sound, and well established, so that no doubts about psychometric properties of a newly created tool like MPI [18] arise. Fourth, the question- naire must exist in various languages to compare results across languages.\nShould there be differences, this is indicative of GPT-3 \"just\" representing the local personality of a country, culture, or language region. On the other hand, should the same personality pattern emerge across all languages, this can be interpreted as a unique personality of GPT-3. However, should oddi- ties like bimodal distributions in scores or consistency of answering patterns emerge within one language, it is thinkable that the emerging personality of that language is inconsistent and thus issues in the subsequent cognition, feel- ings, and behaviour of GPT-3 and ChatGPT may occur; in short - that these may \"suffer\" from a \u201csplit personality disorder\u201d. Last, the same set of instruc- tions should be used in all languages for consistency; if possible, translated by a native speaker to control against inconsistencies from translation programs. This ensures that GPT-3 understands the commands in the same way in each language.\n4.1 Instrument used\nThe Ten Item Personality Inventory [17] fulfils all of these criteria. It consists only of ten items; two per Big Five factor, of which one is reversed. Further- more, it is translated into 27 languages, and until now, 9,167 peer-reviewed papers have used this instrument. \"Although somewhat inferior to standard multi-item instruments\" (p.504) [17], its results vastly overlap with other estab- lished Big Five instruments for self-ratings, external ratings, and peer ratings. Also, it displays a high congruence between self-ratings and observer rat- ings. Furthermore, the test-retest reliability is high, and the levels of external correlates are concordant with literature.\nFor this study, the Bulgarian [26], Catalan [27], Chinese [28], English [17], French [29], German [30], Japanese [31], Korean [32], Russian [33], and Spanish [27] version were used. The selection was done based on an alphabetic order of languages available in TIPI, and, as the authors became aware of the restric- tions of 0-shot learning even within the paid version of GPT-3, languages with the highest number of speakers were given favour. Actually, some languages \"burned\" more of the computational units than others, which is represented in the different number of cases that made it into the study.\n4.1.1 Prompt Engineering\nGPT-3 and later models exhibit the emergent ability of \u201cin-context-learning", "45": [46], "47": [48], "49": "prompt engineering improved massively", "suggesting high-level, multi-task broad cognitive capabilities may be extracted by simple prompting\" (p.1) [34": ".", "35": ".", "20": ".", "nents": "n1. Presentation of the frame (\"Here are a number of personality traits...\"\n(p.525) [17", "I see myself as": ")\n7. Items themselves\nThis chain of commands is embedded in most psychometric tests"}, {"I see myself as": ").\nHowever, for the sake of 0-shot learning, it was not sufficient to use this prompt, since the demand to fill-in blanks originates from its paper and pen- cil format and confused GPT-3 on test runs. Also, through trial and error, we found that the scale has to be given after the items and not before to gener- ate best results. Therefore, we started the section of the scale with another instruction step, telling it to use the scale to rate itself. Since the outcome was a verbal answer in many cases, the additional instruction to rate itself in numbers had to be provided, which was necessary for quantitative analysis. Also, an additional instruction was necessary to answer all questions, whereby the number of questions had to be explicitly mentioned. To gather more qual- itative information, it was asked to reply why it sees itself that way. Finally, the prompt ended with a \"1.\" to trigger a response of GPT"}]}