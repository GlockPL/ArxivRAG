{"title": "WHICH PPML WOULD A USER CHOOSE? A STRUCTURED\nDECISION SUPPORT FRAMEWORK FOR DEVELOPERS TO RANK\nPPML TECHNIQUES BASED ON USER ACCEPTANCE CRITERIA", "authors": ["Sascha L\u00f6bner", "Sebastian Pape", "Vanessa Bracamonte", "Kittiphop Phalakarn"], "abstract": "Using Privacy-Enhancing Technologies (PETs) for machine learning often influences the characteris-\ntics of a machine learning approach, e.g., the needed computational power, timing of the answers or\nhow the data can be utilized. When designing a new service, the developer faces the problem that\nsome decisions require a trade-off. For example, the use of a PET may cause a delay in the responses\nor adding noise to the data to improve the users' privacy might have a negative impact on the accuracy\nof the machine learning approach. As of now, there is no structured way how the users' perception\nof a machine learning based service can contribute to the selection of Privacy Preserving Machine\nLearning (PPML) methods. This is especially a challenge since one cannot assume that users have a\ndeep technical understanding of these technologies. Therefore, they can only be asked about certain\nattributes that they can perceive when using the service and not directly which PPML they prefer.\nThis study introduces a decision support framework with the aim of supporting the selection of PPML\ntechnologies based on user preferences. Based on prior work analysing User Acceptance Criteria\n(UAC), we translate these criteria into differentiating characteristics for various PPML techniques.\nAs a final result, we achieve a technology ranking based on the User Acceptance Criteria while\nproviding technology insights for the developers. We demonstrate its application using the use case\nof classifying privacy-relevant information.\nOur contribution consists of the decision support framework which consists of a process to connect\nPPML technologies with UAC, a process for evaluating the characteristics that separate PPML\ntechniques, and a ranking method to evaluate the best PPML technique for the use case.", "sections": [{"title": "1 Introduction", "content": "Which Privacy Preserving Machine Learning (PPML) technique a user would prefer to be implemented in a specific use\ncase is a difficult question to assess from a developer's perspective. Since users lack fundamental knowledge about\nthese technologies it is difficult to obtain preferences for implementing a PPML technique in a certain application. But\nfor the actual use of an application by the user, meeting their needs is a crucial requirement for AI service providers.\nThis is on the one hand driven by the need to meet legal regulations such as the GDPR. On the other hand, privacy\ncan be used as a selling point when comparing to other competitors. Although the principles of privacy by design [18]\nclaim full functionality in a win-win approach, in practice this is not easy to achieve for Machine Learning (ML)\napplications. Almost always PPML techniques such as Differential Privacy (DP), Homomorphic Encryption (HE) or\nSecure Multiparty Computation (SMPC), come with different trade-offs in performance, accuracy and adaptability [45].\nMoreover, these techniques are often not dominating each other but come with individual trade-offs that influence\ndifferent aspects of an application. To address this research gap, we provide a structured decision support framework\nfor developers to support them in the selection of a PPML technology that best suits the users' preferences. The result"}, {"title": "2 Related Literature", "content": "There are several studies that provide classification and comparison of PPML techniques. Zheng et al. [81] classified\nPPML systems based on key technologies with a special focus on applying the PPML techniques to IoT. Thus, they\ncompared the techniques according to computation and communication overhead. They first considered whether the\nsystem is for training or for inference. For privacy-preserving training, they further divided into parameter transmission-\nbased techniques (e.g., federated learning) and data transmission-based techniques (e.g., anonymization and data\nobfuscation). From their classification, it is difficult to see which key technologies can be combined. Tanuwidjaja et al.\n[66] presented a similar classification of privacy-preserving deep learning on machine learning as a service. Boulemtafes\net al. [11] classified PPML systems based on the structures of the systems. They divided the system settings into four\nlayers: (1) learning, inference, or releasing a model, (2) collaborative learning (multiple participants are involved) or\nindividual learning (a single participant is involved), (3) server-based (most tasks are outsourced) or server-assisted\n(tasks are performed cooperatively between participants and the outsourcing servers), and (4) key technological concepts\n(e.g., encryption). Similar to [81], it is difficult to see from their classification which key technologies can be combined.\nFor comparison of PPML techniques, they considered effectiveness (e.g., accuracy), efficiency (e.g., running time), and\nprivacy.\nTran et al. [69] compare different approaches such as HE, DP, SMPC and FL for privacy preserving decentralized deep\nlearning and evaluate different artifacts such as existence of bottlenecks, privacy, utility reduction, training latency or\nperformance costs.\nXu et al. [77] provided a framework explaining at which level different PPML techniques can be combined. This work\nmay be considered as a combination of [81], [66], and [11]. For the first category, PPML systems are divided by phases:\ndata preparation, model training, and model serving (deployment and inference). For the second category, PPML\nsystems are divided according to privacy guarantee: object-oriented (data and models) and pipeline-oriented (boundary\nand trust assumption). For the last category, PPML systems are divided according to technical utility: data publishing"}, {"title": "3 Methodology", "content": "This section presents involved entities and the methodology addressing our research objectives."}, {"title": "3.1 Entities Involved", "content": "We build on the entities that were already introduced by L\u00f6bner et al. [45]. Therefore, we only provide a brief summary\nof our definitions.\nData entity: A natural person who is providing private data for training a PPML model. No computation results are\nprovided to the data entity.\nUser: A natural person using an AI service as a customer, providing private input data and receiving private results.\nUser and data entity are data subjects as defined in the GDPR [27].\nDeveloper: Commissioned by the AI service provider to create PPML models for users, using data from data entities\nand user. Developing a PPML model is not restricted to a single occurrence but can be done continuously. The required\ndata to train a model is taken (a) from the data entity to e.g. built a pre-trained model or (b) from the user input.\nAl service provider: Utilises the PPML model that is commissioned and build by the developer in a user relationship.\nThe Al service provider takes over all communication with user and data entity.\nExperts: Exhibit advanced background knowledge in PPML or user privacy and are important to keep the presented\nframework up to date."}, {"title": "3.2 Research Objectives", "content": "To support AI service providers and developers, we aim to identify which PPML technique a user would prefer to be\nimplemented for an ML service that requires the disclosure of personal data. Therefore, we focus in this line of research\non providing a process to evaluate different PPML techniques based on the user preferences elicited by L\u00f6bner et al.\n[45]. Because all PPML techniques can improve privacy but have different advantages and disadvantages a distinction is\nrequired by analysing technical differences. However, due to continuous technical improvement of PPML technologies\nwe focus on providing a process on how to build an overall evaluation of eligible techniques (see section 4). Thus our\nframework is robust against changes in technology in future. We showcase the framework's application in section 6\ntaking over the role of framework users, utilising existing research and prototypes on the PPML technologies eligible for\nthe use case. Finally, our approach aims to provide a structured decision support for developers and service providers to\nidentify the PPML techniques with good (expected) user acceptance. Thus, for this line in research we have split the\nranking process of PPML techniques into three research objectives (RO):\nRO1: Providing a process on how to connect PPML technologies with UAC We explain and showcase how UAC\npreference scores can be translated into PPML Characteristic scores. This is done by utilising the mapping provided in\nL\u00f6bner et al. [45]. This mapping contains already expert validated connections between UAC and PPML Characteristics.\nWhile the survey can also be conducted by the AI service provider, the translation into the PPML Characteristic scores\nshould happen within the AI developer to adjust the mapping to the use case, if necessary.\nRO2: Providing a process for evaluating the PPML characteristics that separate PPML techniques We provide\na process on how the PPML Characteristics that separate different PPML techniques can be evaluated, introducing\nPPML criteria and criteria weights. We also showcase how the PPML criteria can be set up. This fine-grained evaluation\nis expected to be performed within the AI service chain, e.g., as paid service of an experienced PPML developer or as\npaid consultancy.\nRO3: Providing a ranking method to evaluate the best PPML technique for the use case, based on RO1 and RO2\nPPML Characteristic preference scores (RO1) elicited from the user input and the weighted PPML Characteristics\n(RO2) are used to compute a PPML technology score that can be used for technology decision support. The unique\ncontribution of this score is that it takes user preferences into account. This task can also be performed as a service\nwithin the AI service chain because background knowledge in PPML from e.g. similar projects is likely to speed up this\nprocess and increase the accuracy of the evaluation."}, {"title": "3.3 Threat Model", "content": "To evaluate the level of protection of the PPML techniques, it is crucial to define an individual threat model for the\napplication in focus. Since the threat model relies heavily on the ML application, i. e. its data input and output and\nthe aim of the application, we cannot provide a specific threat model for each possible application. To still allow our\nframework to consider attacks, we build a somewhat generic threat model by considering a set of common attacks that\nare structured based on Li et al. [40] in local and global privacy. A model protected against third parties except members\nof the AI service chain is considered globally private, (resilience against attacks) and it is locally private if protected\nagainst all entities, including internal adversaries (purpose and access limitation). We assume that attackers who are not\npart of the AI service chain, do not possess any information about the data or the model and have no physical access to\nthe infrastructure. They can only interact with the target model by providing inputs and receiving a predicted result.\nWe assume that attackers inside the AI service chain, are able to collect information about the data and model over time\nif no protection mechanism prevents this. They might possess additional information about the user or data entity. The\nattacker has physical access to the infrastructure. The attackers have full access to the target model and its prediction if\nnot prevent by PPML."}, {"title": "4 Framework Description", "content": "In this section, we explain the calculation steps within our framework.  provides an overview of the different\nsteps and clarifies at which state input is required to the framework.\nFirst, the framework is set up by checking whether the mapping of UAC and PPML Characteristics is up to date and\napplicable to the application (see section 4.1). Second, User Input (see section 4.2) and Developer Input (see section\n4.3) are collected. The user input is collected by conducting a survey. We assume that the developer input is a paid\nservice by the PPML developer. It is assessed which PPML techniques for the application are eligible (see section\n4.3.1). For each PPML Characteristics, categories (see section4.3.2) with Intra-categorical weights (see section 4.3.3)\nare set by the developers and the PPML technologies are evaluated based on the categories (see section 4.3.4. The\nuser input is translated by applying the mapping of L\u00f6bner et al. [45] into PPML Characteristic scores (see section\n4.4). Finally, the PPML technique scores are calculated (see section 4.5). The sections of the description (section 4)\ncorrespond to the framework application (section 6). The AI service provider can now include the preference of the\nusers for the new service into the privacy by design decisions of the application development."}, {"title": "4.1 Expert Input and Framework Setup", "content": "In this step, we define the framework setup using the UAC PPML Characteristics mapping proposed by L\u00f6bner et al.\n(see table 1). Their definitions of UAC are presented for the sake of completeness in table 2. L\u00f6bner et al.\n[45], collected UAC and PPML Characteristics from existing models and grouped the attributes in several rounds of\ndiscussions with experts in privacy and machine learning. Moreover, experts validated the attributes and their influence\nonto each other in several feedback loops. Thus, we consider the framework setup as provided from previous work.\nHow the proposed framework is applied to calculate the best PPML is the contribution of this paper. Thus, to later map\nthe input of UAC to PPML Characteristics we define $F$ as a binary mask matrix. A connection in the framework is\nrepresented by $F_{ij} \\in \\{0, 1\\}$, where $F_{ij}$ denotes the connection of the $j$-th UAC and the $i$-th PPML Characteristic. The\nstarting point are 15 UAC and 14 PPML Characteristics. For easy iteration and identification in the mapping matrix we\ndefine index $j$ ($J = 14$) and index $i$ ($I = 13$)."}, {"title": "4.2 User Input", "content": "In this step, we describe the user input. The user input contains a score for every UAC. The higher the score the more\nimportant is the UAC. We define the user input $u$ as a vector of UAC preference scores with $u_j \\in [0, 1]$ as the preference\nscore for every UAC, where $\\Sigma_{j=0}^{2} u_j = 1$. To evaluate the preference scores $u_j$ a variety of possible methods exists\nand the choice for a method depends on the specific use case and thus cannot be part of this theoretical framework paper."}, {"title": "4.3 Developer Input", "content": "In this step, we explain how the developer's input is derived. We assume that this step is a paid service performed by\nframework users (developers) with expert knowledge in PPML."}, {"title": "4.3.1 Assessing eligible PPML techniques", "content": "To identify which PPML techniques are taken into consideration for implementation, a list of possible methods can\nbe found, e.g., in the international standard ISO/IEC 20889 [32]. This document already classifies different privacy"}, {"title": "4.3.2 Setting PPML categories for application", "content": "A crucial step is defining categories, denoted as $k$, for each PPML Characteristic. These categories should be selected to\neffectively distinguish between different PPML techniques. A PPML Characteristic can have any number of categories,\ndenoted as $k \\in [0,\\infty)$. Categories can take on various forms, e.g. nominal, ordinal, or metric.\nIf a PPML Characteristic has only one valid category for a specific use case, we define it as a hard criterion. In such\ncases, if the hard criterion is not fulfilled, the technique can be directly excluded.\nLet $X_i$ be the matrix for the $i$-th PPML Characteristic, with dimensions $(m, n)$, where $m$ represents the number\nof PPML Characteristics ($m = I$) and $n$ represents the number of PPML techniques ($n = T$). The matrix $X_{i,kt}$\ncorresponds to the $i$-th PPML Characteristic submatrix with $k$ categories and $t$ PPML techniques."}, {"title": "4.3.3 Setting weights for categories", "content": "To cover that categories can be nominal, ordinal or metric we need to weight the categories against each other. Thus we\nintroduce a weight vector $y_i$ as the $i$-th $y$ vector of matrix $X_i$. Thereby, $y_{i,k}$ is the $k$-th category weight for the $i$-th\nPPML Characteristic with $y_{i,k} \\in [0, 1]$. Consider the following case differentiation for $y_{i,k}$:\n$V_i: \\begin{cases}\n    \\Sigma_{k=0}^{K} y_{i,k} \\geq 1 & \\text{if exclusive,}\\\\\n    \\Sigma_{k=0}^{K} y_{i,k} = 1 & \\text{if not exclusive.}\n  \\end{cases}$"}, {"title": "4.3.4 Evaluating PPML categories", "content": "Once the categories and weights are set up, the categories can be evaluated. The evaluation is conducted by the\nframework users (developers) and is expected to be performed based on previous knowledge about the respective\ntechniques. If a technique is new, it will need to be assessed based on related literature.\nIf a PPML technique is assigned to a category we set $X_{i,kt} = 1$, otherwise 0. In general, a technique can be assigned to\nseveral categories, resulting in a higher score.\nIn the evaluation, trade-offs can be discovered. We indicate a trade-off between categories with a capital T. It is possible\nto set a different value below 1 making the matrix non-binary. This can be required because otherwise the result is"}, {"title": "4.4 Framework Mapping", "content": "In this step, we describe how the user input is translated into PPML Characteristics' scores. This is necessary because\nthe user has a significant knowledge gap about PPML Characteristics and cannot evaluate them directly [45]. Thus we\ndefine $c_i$ as the PPML Characteristic preference vector with index $i$. It can be interpreted as the translation of UAC\npreference scores into preference scores for PPML Characteristics. Currently we only have the binary mask matrix $F_{ij}$.\nNext, we calculate the PPML Characteristic scores $c_i$ that is the dot product of the binary mask matrix $F_{ij}$ and the UAC\npreference scores $u_j$.\n$c_i := \\Sigma_{j=0}^{J} F_{ij}u_j$\nTo have a better comparison of the the results, we normalise the vector $c$. This is also required for the next calculation\nbecause these user preference scores for PPML Characteristics are later used to weight and rank the PPML techniques.\nThus we calculate\n$\\forall_i: \\bar{c_i} := \\frac{c_i}{\\Sigma_{g=0}^G c_g}$"}, {"title": "4.5 Framework Results", "content": "In this step, we calculate the final ranking of PPML techniques. Once all inputs are ready, the evaluation vector $e$ can be\ncalculated. Each PPML technique will receive a score. If other criteria besides UAC and PPML Characteristics should\nbe included in the ranking, this has to be taken into account by the developers. In our framework, the PPML technique\nwith the highest score will meet the UAC preference score the best. We calculate the evaluation vector $e$ so that\n$\\forall_t: e_t := \\Sigma_{i=0}^{I=13} (X \\cdot Y_i)$"}, {"title": "5 Use Case: PSI Detection in texts", "content": "To exemplify the use of the proposed framework, we describe a simplified AI application that a provider could be\nplanning to develop. We will use the example of PSI detection."}, {"title": "5.1 Use Case description", "content": "The application's objective is to detect the disclosure of Privacy Sensitive Information (PSI) in social media posts. The\napplication should detect whether PSI was included in the text and classify the text accordingly. If the text was classified\nas including sensitive information, then the application would additionally detect the type of PSI contained in the text.\nDifferent PPML methods could be used to implement such a PSI detection application. PSI detection can be accom-\nplished using multi-class or multi-label classification approaches that would classify private data into different categories\n(e.g., tracking, financial or medical data) [46]. Users' privacy concerns towards this type of privacy-preserving appli-\ncation have been investigated by Bracamonte et al. [12], who found that users have privacy concerns with regard to\nperceived surveillance and perceived intrusion and secondary use, which motivates the need of PPML in this type of\napplication.  shows a possible interface of such a tool."}, {"title": "5.2 PSI detection requirements", "content": "Because of the stake of showcasing the framework, we have to set some implementation requirements and assumptions\nto narrow down the use case:\n\u2022 The user input that is a ranking of UAC is assumed to be already achieved by a survey. How the survey is\nconducted precisely is part of our future experiments.\n\u2022 For our example, we analyse a text reinforcement learning problem for PSI detection.\n\u2022 The data used for training contains private data that cannot be removed."}, {"title": "5.3 PPML for text classification", "content": "In this section, we collect examples of text classification tasks using PPML, also highlighting some limitations and\nadvantages. This is relevant to ensure that the PPML technique is applicable.\nFL is benchmarked by Lin et al. [41] who use the 20news dataset and 100 clients. They identify future potential for\nimproved performance. Moreover, incorrect or biased data might cause biased decisions. They evaluate the current\nstate of FedNLP as \u201crelatively immature\". Sidhpura et al. [63] and Thapa et al. [67] propose a SMS spam and ham\nclassification. This task is very similar to a binary PSI detection because the length of text is comparable. Liu et al. [42]\nanalyse FL for Natural Language Processing (NLP) and find relevant challenges for text classification, e.g. solving\ncommunication overhead from client updates using distillation methods. A benchmarking of FL with NLP is provided\nby Lin et al. [41] who analyse a combination of NLP with BERT and FL.\nFL+LDP is combined by L\u00f6bner et al. [44] to increase the privacy of users. For a noise multiplier of 0.99 and an $e$ of\n23 they achieve an F1-Score of 0.94 after 20 federated rounds for 10 clients. In this approach LDP is applied on the\ngradients of the users' local models and not on the text itself. The evaluation of the whole model took 144 min.\nDP for unstructured text data was investigated by Klymenko et al. [35]. They find that DP does not permit inference\nattacks themselves but creates uncertainty about the inferred data. Regarding unstructured text, this concept can run into\nlimitations when following the strict definition that any two texts have to be considered adjacent. Thus, the application\nof Metric Differential Privacy (MDP) was introduced by Chatzikokolakis et al. [19] for unstructured text data. Carvalho\net al. [17] apply MDP on the IMDB review data set, using a sentiment classification model. Xu et al. [79] present a\ndifferentially private Mahalanobis mechanism for text perturbation. Weggenmann and Kerschbaum [75] propose an\nautomated text anonymisation approach for text mining that fulfills DP and comes with a provable plausible deniability\nguarantee. Classifying text into news groups, they find that their model requires a large $e$ to achieve an acceptable utility"}, {"title": "6 Framework Application", "content": "In this section, we apply the framework as described in section 4 for the PSI detection use case as presented in section 5.\nIn the role of framework users, we will go through each step of the framework and calculate the PPML technology that\nmeets the user requirements the best."}, {"title": "6.1 PSI: Expert Input and Framework Setup", "content": "We do not implement any changes to the framework itself and consider all UAC and PPML Characteristics to be relevant\nfor the PPML use case. We do not include additional features. Experts should re-evaluate the framework at regular\nintervals based on technology changes."}, {"title": "6.2 PSI: User Input", "content": "For the ranking we have run an AHP with 55 participants. Due to the high number of UAC (15), the UAC were divided\ninto four groups (PC, UX, DP, PT) and the respective subgroups as provided in table 1. The AHP took each participant\naround 15 minutes and a tolerable [31] Consistency Ratio (CR) below 0.2 was achieved for 31-33 participants in each\nsubgroup. Participants above 0.2 were excluded. Between 18 and 21 participants achieved a CR score below 0.1. 27\nparticipants were male and 27 female, 1 participant was diverse. Four participants were in the age group 18-19, 42\nbetween 20-29, seven between 30-39, none between 40-49, one between 50-59 and one between 60-69. We aimed\nspecifically for a younger age to get people with high social media interaction. The usage and posting behavior is shown\nin table 3. Following [60] when using AHP for group decisions we expect a relative importance score for each feature\nbetween 1 and 0. All global feature preference values sum up to 1. We also follow the fundamental scale: {extremely\nimportant: 9, very strong important : 7, strong important 5, moderate important: 3, equal: 1 }. We have also included\nintermediate choices (2, 4, 6, 8). The global preference values are provided in figure 3."}, {"title": "6.3 PSI: Developer Input", "content": "In this section, we describe how we derived the developer input for the PSI detection application."}, {"title": "6.3.1 PSI: Assessing eligible PPML techniques", "content": "Techniques are selected based on related literature, ISO/IEC 20889 and our own experience. We assume that also\ndevelopers would choose techniques based on their own experiences and the techniques establishment. As shown in\nsection 5.3 all techniques chosen for showcasing are suitable for the PSI detection application:\n\u2022 Federated Learning (FL)\n\u2022 FL + Local Differential Privacy (FL+LDP)\n\u2022 Metric Differential Privacy (MDP)\n\u2022 Secure Multiparty Computation (SMPC)\n\u2022 Homomorphic Encryption (HE)\n\u2022 Central Trusted Execution Environment (TEE)"}, {"title": "6.3.2 PSI: Setting PPML categories for application", "content": "In this section, we elicit categories for the PPML Characteristics based on table 1. An initial definition of the PPML\nCharacteristics is already provided by L\u00f6bner et al. [45]. We have separated the PPML Characteristics into categorical\nattributes that do not have a logical order, but one category might be preferred by the users.\nFor a better overview and easier computation of the final recommendation, we start by defining hard requirements that\nwill lead to an exclusion of the PPML if not fulfilled. We do this for an improved efficiency of the evaluation process.\nThe following criteria of PPML Characteristics we define as a hard requirement.\nLocation of raw data storage: The location where raw user data is stored is for our PPML techniques in focus local\n(stored on a user's device), central (stored on a central server within the AI service chain) or distributed (stored across\nseveral entities). For our PSI application we set the requirement to only allow locally stored raw user data. We set this\nrestriction because survey participants clearly preferred raw data to be stored exclusively local."}, {"title": "6.3.3 PSI: Setting weights for categories", "content": "For each category matrix $X_i$ we have to set a weight vector $y_i$. The sake of these weights is to support framework users\nwith another dimension to formulate requirements. Again the sum of each weight vector if not exclusive has to add\nup to 1. Setting up the weight vector is a task that is performed in the AI service chain by the party who has the most\nknowledge about the PPML characteristics. To achieve an equal scaling, an AHP could be used again for each category.\nAll values for y are shown in table 5 where we also indicate whether a category is exclusive or not. If a category is not\nexclusive (\"No\"), then $\\Sigma y = 1$ holds. For the sake of showcasing, we will set the weight vectors exemplary based on\nauthors' experience (see table 6)"}, {"title": "6.3.4 PSI: Evaluating PPML categories", "content": "In this section we describe the evaluation of PPML technologies (FL, FL+LDP, MDP, SMPC, HE) by labelling them\ninto PPML categories from section 6.3.2. For the sake of showcasing, the authors take over the role of framework\nusers. To evaluate the technologies we use the first 50 papers in ACM, IEEE and Google Scholar that were identified by\nsearch terms that consist of the respective technology, PPML Characteristic respective PPML criteria. The results of the\nevaluation are presented in table 7."}, {"title": "6.4 Framework Mapping", "content": "In this section we describe how to map the importance scores of the PPML characteristics and the PPML category\nevaluation metrics. As mentioned in the assumptions we only take the user and not the data entity into account. The\ncomputed normalised $\\bar{c_i}$ values for each PPML characteristic are provided in figure 3 for User and Data entity. The\ntranslation of UAC preferences scores into PPML Characteristic preference scores is presented in figure 4."}, {"title": "6.5 PSI: Framework Results", "content": "In this section, we derive the technology ranking based on the previous table by calculating a score that reflects the\ntechnology evaluation from table 7 and the PPML importance scores from figure 4a.\nThe first step in this calculation is to translate table 7 that represents the values of X into numbers we can use for\ncalculation. E.g., for the PPML Characteristics sensitive attributes $X_2$ and $y_2$ are represented the following:\n$X_2 =\\begin{bmatrix}\n    0 & 0 & 0 & 0 & 0 \\\\\n    0 & 1 & 1 & 0 & 0 \\\\\n    0 & 0 & 0 & 1 & 1 \\\\\n    0 & 0 & 0 & 0 & 0 \\\\\n    1 & 1 & 1 & 0 & 0\n  \\end{bmatrix} y_2 = \\begin{bmatrix}\n    0.2 \\\\\n    0.3 \\\\\n    0.3 \\\\\n    1 \\\\\n    0.2\n  \\end{bmatrix}$\nThe hard requirements have to be fulfilled and a technology will be removed if it does not. In a later implementation\nwe plan to invoke a notification if a hard requirement is not fulfilled. Since we have only evaluated techniques that do\nfulfill the hard requirements we reduce I to 10. Regarding the trade-offs (see table 7) we have set $T = 1$ because the\ntrade-off was already considered when setting e.g. a lower expected accuracy for MDP. We first derive the dot product\nof X and y (see table 8). Now we can compute the score e using our formula that includes the user preference scores $\\bar{c_i}$,\nthe technology characteristic evaluations $X_i$ and the weight vectors $y_i$:"}, {"title": "7 Discussion", "content": "In this section we discuss our impact, lessons learned and future work."}, {"title": "7.1 Impact", "content": "With the rise of the AI Act, the need for PPML has been confirmed by the European Commission. Incumbents that are\nin charge to implement privacy for their AI application as well as new entering companies can utilise our framework\nto understand the needs of their customers and thus adjust the privacy strategies. We aim to strengthen the principles\nof privacy by design by providing clarification on which PPML technology will bring the highest user satisfaction.\nThis aims to ensure full functionality while providing a high privacy level. Regarding research we identified a gap\nin structured comparison of PPML technologies that take user preferences into account. We hope to encourage other\nresearchers to close that gap."}, {"title": "7.2 Empowering of user rights", "content": "With this work we empower the user of an AI service with the possibility to choose a technology that meets best their\npreferences. Although the users are by our approach technically empowered to choose the PPML with the best security\nand privacy, this does not necessarily mean that they do so. Nevertheless, optimizing efficiency of an application by\ntrading e.g. performance against privacy is an intended possible outcome of the framework. We follow the approach\nthat security and privacy in an application is only useful if the application still provides full functionality [18]."}, {"title": "7.3 Lessons learned", "content": "During the evaluation of the categories we noticed that dependencies between categories exist. E.g., for DP often a\ntrade-off between accuracy and privacy is reported. While we take this into account with a reduced weight for these\ndependencies, we will further investigate how to best implement trade-offs in an advanced version of the framework.\nTo implement user preferences for a PPML technology decision requires many steps and specific technological expertise.\nHow to improve the evaluation time is a topic we will address in future.\nSince we have experimented with a lot of different UAC rankings we noticed that small changes in the UAC preference\nscores can have a huge impact on the final result. Thus, robustness of the model should be investigates with further\nstudies in future.\nWhen analysing the different steps to derive the framework results we had several feedback loops to ensure that there is\nnotable impact of UAC preference scores on the final results. To get a good balance between technology and UAC\npreference score influence is not an easy task. In our future work, we want to dive deeper into the explainability and\ntracing of influences."}, {"title": "7.4 Limitations", "content": "While the framework is a first step towards the possibility to consider user preferences for the selection of a PPML\ntechnology, it requires parameters specific to each considered scenario. For example, some of the thresholds and weights\nfor PPML Characteristics (cf. Table 7) might be different for another scenario. Determining these parameters can take a\nconsiderable amount of effort and requires"}]}