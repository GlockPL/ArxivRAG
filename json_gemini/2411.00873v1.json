{"title": "Towards Robust and Generalized Parameter-Efficient Fine-Tuning for Noisy Label Learning", "authors": ["Yeachan Kim", "Junho Kim", "SangKeun Lee"], "abstract": "Parameter-efficient fine-tuning (PEFT) has enabled the efficient optimization of cumbersome language models in real-world settings. However, as datasets in such environments often contain noisy labels that adversely affect performance, PEFT methods are inevitably exposed to noisy labels. Despite this challenge, the adaptability of PEFT to noisy environments remains underexplored. To bridge this gap, we investigate various PEFT methods under noisy labels. Interestingly, our findings reveal that PEFT has difficulty in memorizing noisy labels due to its inherently limited capacity, resulting in robustness. However, we also find that such limited capacity simultaneously makes PEFT more vulnerable to interference of noisy labels, impeding the learning of clean samples. To address this issue, we propose Clean Routing (CleaR), a novel routing-based PEFT approach that adaptively activates PEFT modules. In CleaR, PEFT modules are preferentially exposed to clean data while bypassing the noisy ones, thereby minimizing the noisy influence. To verify the efficacy of CleaR, we perform extensive experiments on diverse configurations of noisy labels. The results convincingly demonstrate that Clear leads to substantially improved performance in noisy environments.", "sections": [{"title": "1 Introduction", "content": "The ever-growing size of pre-trained language models (PLMs) has presented significant challenges in adapting these models to desired tasks. In response to this practical limitation, parameter-efficient fine-tuning (PEFT) has emerged as a promising strategy for real-world environments. Instead of fine-tuning all weights, PEFT optimizes only a minimal set of parameters (e.g., biases (Zaken et al., 2022), adapters (Houlsby et al., 2019), prompts (Liu et al., 2022b), or low-rank matrices (Hu et al., 2022)), thereby drastically cutting down the computation and storage costs. Such efficiency has led PEFT methods to become the preferred standard approaches for applying PLMs in real-world contexts, such as federated learning (Kim et al., 2023; Liao et al., 2023) and continual learning (Ermis et al., 2022; Razdaibiedina et al., 2022).\nWhile PEFT enables the efficient optimization of PLMs in real-world settings, datasets in such environments often contain noisy labels (i.e., incorrectly-labeled samples) (Jia et al., 2019; Alt et al., 2020), which adversely affects the generalization capabilities of PLMs (Wu et al., 2022). Given such distinct characteristics of the practical environments, PEFT methods are inevitably exposed to noisy labels during the optimization phase. Despite this significant challenge, there is a lack of prior research on the general adaptability of PEFT methods to noisy label learning (NLL) scenarios.\nIn this work, we bridge this research gap by exploring PEFT under noisy environments. Our results reveal that PEFT struggles in memorizing noisy labels due to its inherently limited capacity, which interestingly provides robustness to noisy labels. However, we also find that such limited capacity simultaneously makes PEFT more susceptible to interference of noisy labels, which impedes learning ability for clean samples, potentially leading to sub-optimal performance. This characteristic markedly contrasts with the behaviors in full fine-tuning, presenting the necessity of PEFT that steers its limited learning capacity towards clean samples.\nIn response, we propose Clean Routing (CleaR), a novel routing-based PEFT approach that adaptively activates PEFT modules. Our main strategy is to preferentially expose PEFT modules to correctly-labeled samples, while bypassing PEFT"}, {"title": "2 Investigation of PEFT on Noisy Labels", "content": "In this section, we systematically investigate PEFT methods in the presence of noisy labels.\nNoisy environment Following the previous work (Wu et al., 2022), we simulate the noisy environment by randomly flipping the given labels. Specifically, we employ the SST-5 dataset with a symmetric noise rate of 60% (i.e., 60% of the training set contains incorrect labels). Note that the test set is not corrupted to confirm the generalization ability of the trained model. The detailed process is described in Appendix E.\nPEFT methods We analyze the three representative types of PEFT methods (Chen et al., 2022) with the full fine-tuning: LoRA (Hu et al., 2022) that adds trainable decomposition matrices; BitFit (Zaken et al., 2022) that trains only biases; Prompt Tuning (Liu et al., 2022b) that appends learnable embeddings to the input of each layer.\nObservations Figure 1 presents the evaluation results of the PEFT methods alongside the full fine-tuning. The accuracy results (first row in the figure) show that PEFT methods reveal superior robustness to the full fine-tuning, even though all methods suffer from performance degradation. To gain further insights into the behavior of each method, we include the training loss for both clean and noisy samples (second low in the figure), which enables to analyze the learning capacity on clean and noisy samples (Arazo et al., 2019). These results show that PEFT methods have difficulty in memorizing the noisy samples, which interestingly contributes"}, {"title": "3 CleaR: PEFT with Clean Routing", "content": "In this section, we elaborate Clean Routing (Clear) in detail. The core idea is to adaptively activate the PEFT modules to circumvent the detrimental effect from noisy labels. To achieve this, CleaR estimates the probability whether a given sample is correctly labeled, leveraging the distinct training dynamics between clean and noisy samples. With these probabilities, CleaR steers the potentially clean samples to route through PEFT modules, whereas the noisy ones are directed to bypass PEFT modules, thereby minimizing their influence on the PEFT. To improve the routing stability of CleaR, we also introduce consistency regularization for PEFT modules. Figure 2 illustrates the overall procedures of CleaR.\nWe start by defining PEFT modules in CleaR. Since CleaR is designed to be module-agnostic, diverse PEFT methods can be seamlessly integrated with CleaR method. To showcase such applicability, we consider four representative PEFT modules (i.e., Adapter, BitFit, Prompt-tuning, and LoRA), which are commonly employed within NLP community. While these PEFT modules have distinct characteristics, they can be succinctly represented as additional parameters \\( \\delta \\) added to the pre-trained weights \\( \\theta \\) of PLMs (Ding et al., 2023). More specifically, since PEFT modules are uniformly distributed across all layers, we represent these modules as a set of additional parameters \\( \\delta = \\{\\delta^{(1)}, \\delta^{(2)}, ..., \\delta^{(L)}\\} \\), where L is the number of layers. Let the prediction involving these PEFT modules be denoted as \\( f(x, \\delta + \\theta) \\), the objective with an arbitrary loss function L can be formulated as follows:\n\\(min_{\\delta} L(x) = L(f(x, \\delta + \\theta), y),\\) (1)\nwhere x and y denote the training sample and the given label, respectively. Note that the PEFT modules and the task-specific classifier are only updated during training."}, {"title": "3.2 Routing PEFT Modules", "content": "Building upon these PEFT modules, we introduce a clean routing scheme that adaptively activates modules according to the estimated probability that a given sample is correctly labeled.\nEstimating clean probability for routing To derive the clean probability for each sample, we leverage the distinct learning patterns when learning with clean and noisy samples: deep networks prefer to learn clean samples first before fitting noisy ones (Arazo et al., 2019). Namely, noisy samples tend to have a higher loss than clean samples in the early training stage. This enables to distinguish potentially clean samples from the datasets based on loss deviation (Jiang et al., 2018; Han et al., 2018). Taking advantage of such phenomena, we adopt the widely-used Gaussian Mixture Model (GMM) in noise label learning (Li et al., 2020; Qiao et al., 2022), in which the probability of samples being clean is estimated by the per-sample loss.\nBased on the estimated mixture models, we compute the clean probability p using the posterior probability, i.e., \\( p(g|l) \\) where l is the loss for the training sample, and g is the Gaussian component"}, {"title": "3.3 Consistency Regularization for CleaR", "content": "While the routing scheme effectively mitigates the influence of noisy labels, model predictions may end up being overly diverse due to varying activations with each forward pass, potentially resulting in training instability. To address this issue, we introduce a consistency regularization to minimize the model variability. Considering that guiding the model to adhere to past predictions can enhance the stability and consistency of training (Shen et al., 2022; Xu et al., 2023), we regulate the model by minimizing the distance between its current and previous predictions. Specifically, we make ensemble predictions from multiple forwards to reduce predictive variance and increase stability:\n\\(f_{ens}(x, \\delta + \\theta) = \\frac{1}{N} \\sum_{k=1}^{N} f(x, \\delta_{r,k} + \\theta),\\) (4)\nwhere N is the number of forwards, and \\( \\delta_{r,k} \\) represents activated PEFT modules in the k-th forward of the previously trained model. It is noteworthy that, for computational efficiency, we reuse the predictions, which were previously used for fitting GMM. With the derived predictions, the model with CleaR is optimized with the following loss:\n\\(min_{\\delta, \\rho} L(x) = L_{CE}(f(x, \\delta_{r} + \\theta), y) + \\lambda L_{CE}(f(x, \\delta_{r} + \\theta), f_{ens}(x, \\delta_{r} + \\theta)).\\) (5)\nwhere \\( L_{CE}(\\cdot) \\) indicates the cross-entropy loss, and \\( \\lambda \\) is a coefficient to control the strength of the regularization."}, {"title": "4 Experiments", "content": "We demonstrate the efficacy of CleaR across diverse configurations of noisy environments."}, {"title": "4.1 Configurations of Noisy Labels", "content": "To comprehensively assess our method diverse scenarios characterized by different noisy labels, we evaluate each baseline against three distinct types of noisy labels: symmetric, asymmetric, and instance-dependent. We provide detailed descriptions of each noisy label type and the methodology for constructing noisy label datasets in \u00a7E."}, {"title": "4.2 Baselines and Implementations", "content": "Following the previous works, we use the BERT-base and BERT-large model (Devlin et al., 2019). Building on this PLM, we mainly compare CleaR with the full fine-tuning and widely-used PEFT methods including Adapter (Houlsby et al., 2019), LORA (Hu et al., 2022), Prompt tuning (Liu et al., 2022b), and BitFit (Zaken et al., 2022). For a fair comparison, we utilize the same settings for PEFT modules (e.g., bottleneck dimension, prompt length) for baselines and our CleaR. The detailed implementations are represented in \u00a7F. Additionally, we compare CleaR with the existing NLL methods to confirm the competitiveness of the proposed method in \u00a75.3."}, {"title": "4.3 Evaluation Metric", "content": "Building upon previous work (Wu et al., 2022), we assess each baseline model using two metrics: the instantaneous peak accuracy and the average accuracy across the last few epochs. The former metric evaluates the model's generalization performance, while the latter reflects its stability. Consequently, a smaller gap between these two metrics indicates a more effective model to noisy labels. For all CleaR models, we report the average performance on 10 different seeds considering their stochasticity."}, {"title": "4.4 Sentiment Analysis", "content": "We first evaluate baselines in sentiment analysis due to the inherent subjectivity of this task, which often results in noisy labels. Following the previous work, we use the Standard Sentiment Treebank (SST-5) dataset (Socher et al., 2013). For the levels of noisy labels, we scale the symmetric noise from 20% to 60% and asymmetric noise from 10% to 40%, respectively."}, {"title": "4.5 Intent Detection", "content": "We further evaluate Clear on intent detection. Given that the task is typically employed in conversational systems, the query usually consists of only a few words (e.g., 6 to 12 words) (Casanueva et al., 2020). Such brevity can amplify ambiguity, potentially leading to noisy annotations. We utilize the BANKING77 (Casanueva et al., 2020) that encompasses 77 fine-grained intent categories. For the levels of noisy labels, we scale the symmetric noise from 20% to 60% and asymmetric noise from 10% to 40%, respectively."}, {"title": "5 Analysis", "content": "To make a more comprehensive analysis of our CleaR, we designed a series of fine-grained experiments aimed at addressing the following research questions (RQs):\n\u2022 RQ1. How does each component within CleaR contribute to its overall performance? (\u00a75.1)\n\u2022 RQ2. Can CleaR learn clean samples well while minimizing the influence of noisy ones? (\u00a75.2)\n\u2022 RQ3. Can CleaR be combined with other noisy label learning methods? (\u00a75.3)\n\u2022 RQ4. Does CleaR offer improvements under more realistic noisy label scenarios? (\u00a75.4)\n\u2022 RQ5. Can CleaR be generalized to the large-sized model? (\u00a7C)"}, {"title": "5.1 Ablation Studies on CleaR (RQ1)", "content": "We perform ablation studies to investigate the contributions of each component and routing strategy in Clear."}, {"title": "Routing and Regularization", "content": "As shown in the upper part of Table 3, omitting routing and consistency regularization largely affects both peak"}, {"title": "5.2 Memorization Effects (RQ2)", "content": "To confirm whether CleaR mitigates the underfitting problems of PEFT methods on clean samples, we compare the ratio of memorizing clean and noisy samples after fine-tuning."}, {"title": "5.3 Clear on Different NLL Methods (RQ3)", "content": "We compare CleaR with existing NLL methods to demonstrate its applicability. We consider three approaches: Co-teaching (Han et al., 2018), SELC"}, {"title": "5.4 Instance-dependent Label Noise (RQ4)", "content": "To investigate CleaR in more realistic settings, we evaluate CleaR in scenarios where noisy labels arise from input features."}, {"title": "6 Related Work", "content": ""}, {"title": "6.1 Robustness of PEFT Methods", "content": "The well-known beneficial properties of PEFT are its generalization capabilities in low-data environments (Liu et al., 2022a; Zaken et al., 2022) and stability (Houlsby et al., 2019; Sung et al., 2021). These studies have demonstrated that full fine-tuning suffers from overfitting on small datasets,"}, {"title": "6.2 Noisy Label Learning in NLP", "content": "Noisy labels are inevitably introduced on large-scale datasets (Jia et al., 2019; Wu et al., 2023). To mitigate the influence of noisy labels in text classification, Jindal et al. (2019) have proposed a noise transition matrix on top of the classifier, learning the transition distribution of noisy labels, and Wang et al. (2023) have tackled noisy labels in classification tasks with supplemental guidance from large language models (e.g., ChatGPT). In addition, Zhuang et al. (2023) have utilized the dynamics of features with generative models during training to learn the transition matrix for noisy labels. For named-entity recognition, Meng et al. (2021) have introduced a self-training method based on the contextualized augmentations, and Zhou and Chen (2021) have proposed a co-regularization in which multiple models teach each other to avoid negative memorization. In entity linking, Le and Titov (2019) have explored an interpretable method to identify clean samples on the premise that interpretable samples tend to be clean. Recently, Wu et al. (2022) have proposed a noise-robust optimization by introducing stochastic tailor-made gradient noise.\nWhile these works have achieved robustness to noisy labels, these works typically consider the scenarios that the entire parameters in PLMs are optimized during fine-tuning, which is challenging due to the huge number of parameters. To the best of our knowledge, we are the first to explore"}, {"title": "7 Conclusion", "content": "In this work, we have explored whether the PEFT methods can be generalized to noisy environments. Interestingly, we have found that, while the limited capacity of PEFT allows the robustness to noisy labels, it can also act as a double-edged sword that hinders learning even with clean samples. In response, we have proposed CleaR, a novel routing-based PEFT approach that adaptively activates the PEFT modules by considering the probability of samples being clean. Extensive experiments have convincingly demonstrated the efficacy of CleaR across diverse configurations of noisy labels. Moreover, our in-depth analysis has demonstrated that CleaR effectively mitigates the underfitting on clean samples of PEFT methods."}, {"title": "8 Limitation", "content": "While we have shown that CleaR successfully improves the effectiveness of PEFT on various NLL scenarios, there exists a few limitations."}, {"title": "Exploration on Different Architectures", "content": "Our efforts have been focused on improving the efficacy of PEFT for encoder models, aligning with previous studies (Wu et al., 2022). Therefore, the applicability of CleaR methods to different architectures (e.g., decoder, encoder-decoder models) remains under-explored in this work. Nevertheless, based on recent evidence suggesting that routing-based PEFT methods can be effectively generalized to various architectures beyond encoder models (Wang et al., 2022; Choi et al., 2023), we believe that CleaR is expected to work well within other architectures. We leave the exploration of this direction as promising future work."}, {"title": "Computational Overheads", "content": "The adaptive routing mechanism in CleaR could potentially introduce computational overhead in two main areas: (i) determining the probability of each sample, and (ii) executing the PEFT routing. However, the overhead for (i) can be mitigated by caching the samples' losses during the training phase, eliminating the need for separate procedures to compute the training loss. As for (ii), in comparison to other routing-based methods cited as (Choi et al., 2023) that employ parameterized routers, the additional computational costs in CleaR are negligible, as the router in CleaR is non-parametric, and decisions are made through sampling, which streamlines the process."}, {"title": "A PEFT Analysis on Different Dataset", "content": "We further conducted the same analysis on a different dataset to validate the generality of our observations. Specifically, we examined PEFT methods on the BANKING77 (Casanueva et al., 2020) dataset, which focuses on an intent detection task. The results are presented in Figure 5. Similar to our analysis of the SST-5 dataset, we observed a similar trend: (i) PEFT methods exhibit greater robustness than full fine-tuning, and (ii) its limited memorization on noisy label attributes to robustness, although they also inhibit memorization even on clean samples. These findings further support our observations and analysis regarding the robustness of PEFT methods to noisy labels."}, {"title": "B Experiments on Additional Datasets", "content": "To further demonstrate the broad applicability of our proposed method, we have evaluated the proposed methods on the TREC and 20Newsgroups datasets."}, {"title": "CCleaR on Larger Model", "content": "To evaluate how CleaR performs as the model evolves, we compare our CleaR with baselines on BERT-Large, which is 3\u00d7 larger than the base-sized model."}, {"title": "D Clear on PEFT methods", "content": "In this paper, we apply CleaR to the existing PEFT methods. Specifically, we select the widely-used and different types of PEFT methods, which include Adapter (Houlsby et al., 2019), Prompt Tuning (Li and Liang, 2021), BitFit (Zaken et al., 2022), and LoRA (Hu et al., 2022). For each PEFT method, we follow the commonly used setup,"}, {"title": "E Detailed Process for Generating Noisy Labels", "content": "We detail the process for generating noisy labels when the noise rate \\( \\rho \\) is given.\n\u2022 Symmetric noise: To generate this noise, we create the noise transition matrix \\( T \\in \\mathbb{R}^{C \\times C} \\) where C is the number of classes. We then set a value of \\( \\rho \\) to its diagonal elements and distribute the remaining probability \\( (1 - \\rho) \\) to other non-diagonal elements. Based on the probability in the matrix, we flip the labels in training samples.\n\u2022 Asymmetric noise: Similar to the symmetric noise, we create the noise transition matrix \\( T \\in \\mathbb{R}^{C \\times C} \\) where C is the number of classes. We then set a value of \\( \\rho \\) to its diagonal elements and assign the remaining probability \\( (1 - \\rho) \\) to the next element of the diagonal values to implement single-flip noise (Qiao et al., 2022). Based on the probability in the matrix, we flip the labels in training samples.\n\u2022 Instance-dependent noise: To generate instance-dependent noise, we first pre-train the classifier on the original dataset. We then select the two classes, which are the most confident u and the second most confident classes s, and calculate the distance of decision boundaries between the classes, i.e., \\( [f_u(x) - f_s(x)]^2 \\). Based on the distance, we define the noise function as \\( \\tau = -[f_u(x) - f_s(x)]^2 + 3 \\). A smaller distance between the classes results in a larger flipping probability to the second most confident class s. Lastly, to control the degree of noisy labels, we multiply \\( \\tau \\) by a certain constant factor such that the final proportion of noise matches the pre-defined noise probability."}, {"title": "F Implementation Details and Setups", "content": "In this section, we detail to implement the baselines and our CleaR on various tasks.\nPEFT implementation. We compare our CleaR with four strong baselines, which include Adapter (Houlsby et al., 2019), LoRA (Hu et al., 2022), BitFit (Zaken et al., 2022), and Prompt-tuning (Liu et al., 2022b). Specifically, we set the bottleneck dimension r for the Adapter and LoRA as 16 and 4, respectively. For LoRA, we only apply LoRA weights on query and value attention weights. Moreover, we fine-tune all bias parameters in transformer blocks for BitFit. For Prompt-tuning, we set the fixed length as 20 for prompts in each transformer layer, following P-tuning v2 (Liu et al., 2022b).\nHyper-parameters. For the hyper-parameters to fine-tune in CleaR, we select the best warmup epoch in [3, 10] and clean probability weights \\( \\gamma \\) in [0.5, 1] corresponding to each PEFT method and task. We also use the number of forward N = 5 for constructing ensemble predictions on consistency regularization. we use the consistency regularization coefficient \\( \\lambda = 1 \\) for all experiments. For other settings, we use Adam optimizer (Kingma and Ba, 2015) with \\( \\beta_1 = 0.9 \\) and \\( \\beta_2 = 0.999 \\). We also train all models using a batch size of 32 and sweep the learning rates in {1e-4, 2e-4, 3e-4, 4e-4, 5e-4} for PEFT methods. For full fine-tuning, we select the best learning rates in {1e-5, 2e-5, 3e-5, 4e-5, 5e-5}. All models are fine-tuned for 20 epochs.\nHardware Details. We train all our models using four RTX 3090 GPUs. We utilize mixed-precision training (Micikevicius et al., 2018) to expedite the training procedure. All the implementations are performed using the PyTorch framework."}, {"title": "G Details for other NLL Methods", "content": "We compare our CleaR with the following NLL methods:\nCo-teaching. Co-teaching (Han et al., 2018) trains two models simultaneously and lets each model select clean training samples (i.e., small-loss instances) for training each other model. Co-teaching framework gradually drops the noisy samples to prevent overfitting. To this end, they require an estimation of the noise level (\\( \\eta \\)), warm-up steps (Tk), and coefficient (c). We set the noise level \\( \\eta \\) as the ground truth noise ratio. We vary the warm-up steps Tk in {1500, 2000, 2500, 3000, 3500}, and select the best coefficient c from search range of [1, 2] for each fine-tuning method.\nSELC. SELC (Lu and He, 2022) trains the model using ensemble prediction based on historical model outputs to correct the noisy labels. Specifically, they first train their models with given labels until the turning point T, which represents the model would start overfitting on noisy levels. And then they combine the given labels with ensemble predictions with momentum \\( \\alpha \\) as the target. We estimate the turning point T by leveraging met"}]}