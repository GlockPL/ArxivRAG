{"title": "VQLTI: Long-Term Tropical Cyclone Intensity Forecasting with Physical Constraints", "authors": ["Xinyu Wang", "Lei Liu", "Kang Chen", "Tao Han", "Bin Li", "Lei Bai"], "abstract": "Tropical cyclone (TC) intensity forecasting is crucial for early disaster warning and emergency decision-making. Numerous researchers have explored deep-learning methods to address computational and post-processing issues in operational forecasting. Regrettably, they exhibit subpar long-term forecasting capabilities. We use two strategies to enhance long-term forecasting. (1) By enhancing the matching between TC intensity and spatial information, we can improve long-term forecasting performance. (2) Incorporating physical knowledge and physical constraints can help mitigate the accumulation of forecasting errors. To achieve the above strategies, we propose the VQLTI framework. VQLTI transfers the TC intensity information to a discrete latent space while retaining the spatial information differences, using large-scale spatial meteorological data as conditions. Furthermore, we leverage the forecast from the weather prediction model FengWu to provide additional physical knowledge for VQLTI. Additionally, we calculate the potential intensity (PI) to impose physical constraints on the latent variables. In the global long-term TC intensity forecasting, VQLTI achieves state-of-the-art results for the 24h to 120h, with the MSW (Maximum Sustained Wind) forecast error reduced by 35.65%-42.51% compared to ECMWF-IFS.", "sections": [{"title": "Introduction", "content": "Tropical cyclones (TCs), commonly known as typhoons or hurricanes, are cyclonic circulations that are stronger in the near-sea surface layer than in the upper layer (Emanuel 2003). These systems possess tremendous destructive potential, as evidenced by typhoon Mangkhut in 2018, which impacted 3.29 million people and resulted in USD 7.62 billion in direct economic losses (Yang et al. 2019). Consequently, accurate long-term forecasting of TC intensity is of critical importance for minimizing disaster-related damages and losses (Woodruff, Irish, and Camargo 2013; Zhang, Fang, and Yu 2023).\nTC intensity forecasting typically refers to forecasting the maximum sustained wind (MSW) and minimum sea level pressure (MSLP) of a TC. In current operational forecasting, these forecasting methods primarily rely on Numerical Weather Prediction models (NWP) (Buizza et al. 2018), such as the Global Forecast System of the China Meteorological Administration (CMA-GFS) (Shen et al. 2023), the Global Forecast System of the National Centers for Environmental Prediction (NCEP-GFS) (Zhou and Juang 2023), and the Integrated Forecasting System of the European Centre for Medium-Range Weather Forecasts (ECMWF-IFS) (Haiden et al. 2018). However, these models usually require the use of high-performance computing resources to solve a large number of partial differential equations, resulting in high computational costs (R\u00fcttgers et al. 2019). Therefore, the computationally less expensive deep learning (DL) methods have become a research hotspot. Deep learning has made pioneering progress in the field of meteorology, able to understand natural phenomena across temporal and spatial scales, thereby driving the advancement of natural sciences (Bi et al. 2023; Lam et al. 2023; Chen et al. 2023a,b). In recent years, many researchers have begun to apply deep learning algorithms to the forecasting of TC intensity.\nResearchers have conducted some work on deep learning methods for time series forecasting of TC intensity (Pan, Xu, and Shi 2019; Jiang et al. 2023; Huang et al. 2022). They use popular neural network structures like Transformer (Vaswani et al. 2017) and LSTM (Graves and Graves 2012), based on historical time series information to predict future intensity. However, these simple time series features are still not sufficient to fully represent the current state of the TC, so the forecasting performance is not ideal. More researchers (Zhang et al. 2022; Meng et al. 2023; Huang et al. 2023; Wang, Li, and Zheng 2024; Wang et al. 2024) have been trying to use multimodal data, such as the renowned fifth generation of ECMWF reanalysis data (ERA5) (Hersbach et al. 2020), to effectively extract the spatial features of the TC. This led to decent progress in short-term 24-hour (24h) forecasting. However, these methods generally suffer from significant error accumulation problems, resulting in poorer long-term forecasting performance.\nThe above methods have two problems. First, there is insufficient matching between TC intensity and spatial information. In the actual dataset, the same TC intensity can exhibit a variety of different spatial patterns. Some past methods (Vaswani et al. 2017; Huang et al. 2022) have neglected the impact of this spatial diversity, which is why relying solely on historical TC intensity performs poorly. Inspired by prior work demonstrating the benefits of data discretization for time series prediction (Rasul et al. 2022, 2024), we propose to represent the original intensity in a discrete space. By representing the TC intensity information using discrete latent variables, and transforming the original TC intensity forecasting task into forecasting of the corresponding latent variables, this approach enables better matching between the TC intensity information and its spatial patterns.\nSecondly, we believe that one important reason for the poor long-term forecasting performance of deep learning models is the insufficient learning of underlying physical knowledge. By harnessing the massive global ERA5 dataset, significant advancements have been achieved in machine learning-driven medium-range weather forecasting (Bi et al. 2023; Lam et al. 2023; Chen et al. 2023a,b; Han et al. 2024). Taking the FengWu model (Chen et al. 2023a) as an example, it has achieved a skillful 10.75-day forecast horizon for future atmospheric fields. Even more impressively, the TC track forecasting capabilities of FengWu rival or surpass those of the ECMWF-IFS, which is grounded in fluid dynamics equations (Hsu et al. 2024). Based on this observation, we believe that the forecast results of FengWu contain certain underlying physical knowledge. If we can effectively utilize this knowledge, it will significantly improve the performance of TC intensity forecasting. Additionally, since the ERA5 dataset itself underestimates TC intensity information (Bourdin et al. 2022; Malakar et al. 2020), the FengWu forecast field also underestimates this information. Supplementing this part of the information could also contribute to performance improvement. Potential intensity (PI) is a theoretical model that characterizes the upper limit of TC intensity under given environmental conditions and constraints (Emanuel 1986). We calculate the PI value based on the forecast field, using physical constraints to enhance the forecasting performance.\nTo address the aforementioned issues, we propose the Vector Quantized Long-term Tropical cyclone Intensity forecasting model (VQLTI). The entire model training involves two stages. In the first stage, with the ERA5 data as a condition, we map the intensity information to a discrete latent space using the Conditional Vector Quantized-Variational AutoEncoder (CVQ-VAE) (Van Den Oord, Vinyals et al. 2017) framework. In the second stage, after mapping the historical intensity information to the latent space, similar to LSTM (Graves and Graves 2012), we transfer the forecasting task to the latent space. By utilizing the FengWu forecast field to calculate the PI, we apply physical constraints to the forecasting of the latent variables. Then, using the FengWu forecast field as a condition, we decode the forecast latent variables into TC intensity, thereby realizing the forecasting. By adjusting the number of iterations in the latent space, we can achieve forecasts of any time step. The key contributions of this work are:\n\u2022 Proposing to map the TC intensity information to a discrete space, which enables better alignment with the TC spatial information.\n\u2022 Incorporating the FengWu forecast field information to achieve high-precision real-time long-term TC intensity forecasting.\n\u2022 By calculating the PI, the problem of the forecast field underestimating TC intensity is improved, and the long-term forecasting performance is enhanced.\n\u2022 The VQLTI model achieves state-of-the-art (SOTA) performance in global long-term TC intensity forecasting."}, {"title": "Preliminaries", "content": "VQLTI takes the past n-step TC intensity and ERA5 data, as well as the m-step FengWu forecast data as input, to predict the future m-step TC intensity. In this study, the \"USA_WIND\" (knots) and \u201cUSA_PRES\u201d (hPa) variables from the IBTRACS dataset (Knapp et al. 2010) are employed as the ground truth for TC intensity, with a temporal resolution of 6 hours, denoted as $I$.\nThe ERA5 data can be interpreted as the fitted data of the actual atmospheric conditions. The same 69 variables as the FengWu model are selected, including 13 levels (50, 100, 150, 200, 250, 300, 400, 500, 600, 700, 850, 925, and 1000 hPa) of 5 variables (geopotential (z), specific humidity (q), zonal component of wind (u), meridional component of wind (v), and temperature (t)) and 4 surface variables (10-meter u wind component (u10), 10-meter v wind component (v10), 2-meter temperature (t2m), and mean sea level pressure (msl)) (Chen et al. 2023a), and the region with a 10\u00b0 (longitude and latitude) (Zhang et al. 2022) around TC center is cropped. The spatial resolution of the data is 0.25\u00b0, and the temporal resolution is 6 hours, denoted as $E$."}, {"title": "Potential Intensity", "content": "The fundamental energy source for TCs is the release of latent heat from the condensation of water vapor. This process can be described using a Carnot heat engine model to characterize the energy cycle (Emanuel 1986, 1987). Specifically, the surrounding air enters the eyewall, absorbs heat from the ocean, then continuously rises and goes through the energy cycle, before finally flowing out to the outer walls and descending (Emanuel 2018). The incorporation of this theoretical model enables the formulation of TC's theoretical maximum intensity, known as the Potential Intensity (PI), which is typically expressed in terms of wind speed as:\n$\\Vmax^2 = \\frac{Ck}{CD}\\frac{Ts-To}{To}(ko-k),$"}, {"title": "Methodology", "content": "The VQLTI model consists of two training stages, as Figure 3 illustrates. In the first stage, the model employs the CVQ-VAE training framework to learn the mapping from TC intensity information to a discrete latent space. The second phase involves learning within the latent space, forecasting future latent variables, and then decoding those into predicted TC intensity."}, {"title": "Pre-training", "content": "The first stage of training is inspired by CVAE (Sohn, Lee, and Yan 2015), CVAE-GAN (Bao et al. 2017), and VQ-TR (Rasul et al. 2024), forming an encoder-decoder CVQ-VAE framework. The Feature pyramid network (FPN) (Lin et al. 2017) is used to extract multi-scale feature maps of size {40 \u00d7 40, 20 \u00d7 20, 10 \u00d7 10, 10 \u00d7 10} from the ERA5 data. Similar to the Vision Transformer (ViT) (Dosovitskiy et al. 2020), the feature maps are reshaped into a sequence of flattened 2D patches with 5 \u00d7 5 patch size, which are then concatenated to represent the spatial information of the TC as $Ep \u2208 R^{88\u00d7dp}$, where dp is the dimension of Ep. Conditioned on the TC spatial information Ep, the Encoder maps the TC intensity information to a latent representation. The TC intensity is then passed through a multi-layer perceptron (MLP) and performs cross-attention (Vaswani et al. 2017) computation with Ep. The overall encoding process can be expressed as:\n$h = fe(I | E) = CrossAttn(MLP(I)W_I,E_pW_E, E_pW_E),$ (5)\n$CrossAttn(Q, K,V) = softmax(\\frac{Q(K)^T}{\\sqrt{d_k}})V,$ (6)\nwhere $W_I$, $W_E$ and $W_E$ are learnable parameter matrices. Define a learnable discrete latent space {$e_1,\u2026\u2026,e_j$} with a size of J and a dimension of dz, commonly referred to as the codebook. The encoder output vector h is compared against the discrete vectors in the codebook, and the nearest match is selected as the quantized representation, which can be expressed as:\n$Z = e_q = VQ(h), where q = argmin_j ||h \u2013 e_j ||2 .$ (7)\nThe architectures of the decoder and encoder are analogous. Conditioning on the TC spatial information Ep, the decoder learns to reconstruct the quantized discrete latent variable Z back to the TC intensity, represented as:\n$\\hat{I} = f_D(Z | E) = MLP(CrossAttn(ZW_Z, E_pW_E, E_pW_E)).$ (8)\nBesides the reconstruction loss $L_{recon}$, the overall network also aims to minimize the codebook loss $L_{codebook}$ and the commitment loss $L_{commit}$ introduced by the VQ component. The reconstruction loss, using the mean absolute error (MAE) here, optimizes the encoder and decoder. The codebook loss encourages the encoder's output to align with the codebook vectors. The commitment loss ensures the encoder commits to the embeddings, preventing unbounded output growth and facilitating training convergence. The overall aim is to minimize the following loss function:\n$L = L_{recon} + L_{codebook} + \\beta L_{commit} = MAE(I, \\hat{I}) + ||sg [h] - e||^2_2 + \\beta ||h - sg[e]||^2_2.$ (9)\nNote that Equation (7) does not have a gradient, so the stop gradient (sg) operator is used in $L_{codebook}$ and $L_{commit}$. During the forward pass, it is defined as the identity function and has zero partial derivatives. In the actual implementation, the \"detach\" operator blocks the gradient from propagating back. \u03b2 is a hyperparameter."}, {"title": "Forecast", "content": "After the pre-training stage, we obtain discrete latent variables that capture the TC intensity information while preserving the associated spatial patterns. If we obtain the discrete latent variables corresponding to the future TC intensity, as well as the future ERA5 data, we can then realize accurate forecasting. Inspired by MSCAR (Wang et al. 2024) and LSTM (Graves and Graves 2012), forecasting in the latent space is feasible. The second stage of training will focus on forecasting the latent variables. Based on the pre-trained model, we freeze the encoding and codebook modules, unfreeze the decoding part, and use FengWu's forecasting data to approximate the future ERA5 data, to achieve real-time forecasting. The second stage training process is shown in Figure 3(b).\nThe historical TC intensity information is quantified into discrete latent variables window {$Z_(n-1),..., Z_0$}, which are then forecasted through a latent variable iteration model. As TC intensity is influenced by current and historical information, we perform cross-attention calculations on the relevant latent variables, concatenate all the results, and pass them through an MLP layer.\nHowever, this latent space iteration approach suffers from the problem of error accumulation. Additionally, the ERA5 data itself tends to underestimate TC intensity. To address this, we calculate the future PI based on the FengWu forecast data and perform cross-attention between this PI and the MLP output. This provides an upper bound on the possible future TC intensity, which is used to constrain the iterative latent variables physically.\nUsing a residual connection, we add the last latent variable from the historical window to the one-step latent variable forecast result. We then concatenate this forecast result with the historical window, move the sliding window forward by one step, extract the new latent variables, and repeat the above process to complete the latent space iterative forecasting. The full algorithm is described in Algorithm 1.\nFor the forecasting task, it's important to note that using future ERA5 data is impossible for real-time forecasting. Therefore, the final approach is to use the FengWu forecast as the conditioning input and decode all the forecast latent variables {$Z_1,..., Z_m$} back to the TC intensity."}, {"title": "Experiments", "content": "We test the 5-day long-term forecast of global TC intensity and achieve SOTA performance. To assess its practical applicability, we further conduct real-time forecasting experiments, taking into account the actual operating conditions. Finally, we carry out ablation studies to validate the rationality of our model design."}, {"title": "Experimental Settings", "content": "The experiment uses global TC-related data from the year 1980 to 2022. As mentioned earlier, the IBTRACS dataset (Knapp et al. 2010) is used as the ground truth for TC intensity, and 69 atmospheric variables are selected from the ERA5 data (Hersbach et al. 2020), with a 10\u00b0 diameter area around the TC center extracted. The data from 1980 to 2017 is used for training, 2018 for validation, and 2019 to 2020 for testing. For real-time forecasting, we require Feng Wu forecast data. To address storage constraints, we use FengWu to generate 5-day forecasts for the ERA5 data in 2021 and 2022 and extract the corresponding TC-related variables. The PI is computed through future field calculations, including two-dimensional variables. All variables are normalized, as illustrated in:\n$x = \\frac{(X \u2013 Xmean)}{X_std}$ (10)\nConsistent with most research, we use mean absolute error (MAE) as the performance evaluation metric, calculating the absolute error of I and \u00ce, with the formula:\n$MAE = \\frac{1}{N}\\sum_{i=1}^N |I_i - \\hat{I}_i|$ (11)\nMeanwhile, the unit of MSW is commonly expressed in m/s, and we convert the experimental results according to the conversion of 1 knot = 0.5144 m/s. Furthermore, when comparing the performance enhancement between different models, the forecast skill is often expressed as:\n$sf(%) = 100 \u00d7 \\frac{e_b - e_f}{e_b}$ (12)\nhere, $e_b$ represents the error of the baseline model, while $e_f$ denotes the error of the model currently under evaluation. The value of sf can be easily understood as the percentage reduction in forecast error compared to the baseline model.\nVQLTI is trained using the Py-Torch framework on an Nvidia A100 GPU. We employ the Adam optimization algorithm with a learning rate of 0.0001 and apply Exponential Moving Average (EMA) and L1 regularization with a coefficient of 0.00001. The batch size is set to 64, and the model is trained for 30 epochs.\nIn the first stage of training, the FPN extracts 256-dimensional feature maps with spatial scales of {40 \u00d7 40, 20 \u00d7 20, 10 \u00d7 10, 10 \u00d7 10} through convolutional networks (Krizhevsky, Sutskever, and Hinton 2012). These feature maps are then split into patches of size 5 and concatenated, followed by a linear layer to output a dimension of dp = 128. The codebook has a hidden space size J = 1024, a dimension $d_z$ = 128, and the hyperparameter \u03b2 is 0.25. The cross-attention computation uses 3 heads and a dropout of 0.1.\nIn the second stage of training, the input consists of historical information from the past (-18h, -12h, -6h, 0h), denoted by n = 4, and the forecast covers the next 2 days, denoted by m = 8. Thanks to the design of the VQLTI model, we can easily modify the value of m and the corresponding Feng Wu forecast data to achieve forecasting at any desired time step without additional training."}, {"title": "Long-term Forecast", "content": "As shown in Table 1, we compare our global TC forecasts from 2019 to 2020 with some recent deep learning-based methods, including TC-Pre (Zhang et al. 2022), MSCAR (Wang et al. 2024), and TCIF (Wang, Li, and Zheng 2024). We also compare with the well-known NWP models ECMWF-IFS (Bougeault et al. 2010)and NCEP-GFS (Bougeault et al. 2010). To ensure the model achieves effective forecasting, we also present the error of the ERA5 data itself. Note that ERA5 does not have any forecast results. The error here is calculated based on the input of the future ERA5. For MSLP, the minimum value of the msl in ERA5 is selected, and for MSW, the maximum value of $\u221a{(u10)^2 + (v10)^2}$ is used as an approximate substitute, although they are not entirely consistent. Meanwhile, in the Western North Pacific (WP) basin where TC activities are most active, we also make comparisons with the deep learning-based MMSTN (Huang et al. 2022) and MGTCF (Huang et al. 2023), as well as the operational forecasts of Joint Typhoon Warning Center (JTCW) (Chen et al. 2019). The deep learning-based methods mentioned mostly have fixed forecast horizons, so they are all set to a fixed 20-step forecast during training.\nIn the global long-term forecast comparison, VQLTI demonstrates SOTA performance in 24h to 120h forecasts. The forecast skill of VQLTI not only comprehensively outperforms other deep learning-based methods, but its error accumulation rate is also significantly lower than other deep learning-based methods. TC-Pre, MSCAR, and TCIF have very fast error accumulation rates in short and medium-term forecasts, with their 48h MSLP forecast errors increasing by 63.16%, 61.51%, and 69.77% respectively compared to the 24h errors, while VQLTI's error only increases by 16.01%. Relative to the NWP models ECWMF-IFS and NCEP-GFS, VQLTI reduces the 24h to 120h MSW forecast error by 35.65%-42.51% and 25.69%-39.38%. The forecast errors of the VQLTI model are all lower than those of ERA5, which demonstrates the effectiveness of the model's forecasts.\nIn the WP basin, we only perform comparisons in 2019 due to the unique data used by MMSTN and MGTCF (Huang et al. 2022, 2023). MMSTN and MGTCF employ deep learning-based ensemble forecasting methods, with the mean of multiple forecasts used as the final result for a fair comparison. The 120-hour MSW forecast error of the VQLTI model is reduced by 71.73% and 36.53% compared to MMSTN and MGTCF, respectively. Furthermore, VQLTI's forecast error is 42.53% lower than that of JTWC."}, {"title": "Real-time Forecast", "content": "Real-time forecasting needs to address two key issues. First, the ERA5 data requires data assimilation and correction, and cannot be obtained in real-time, so we use relatively available real-time analysis data to replace the historical ERA5 inputs. Second, future ERA5 fields are also unavailable, so we substitute them with FengWu's forecast results. We use 2021 data to fine-tune VQLTI and evaluate it in 2022, as presented in Table 2.\nVQLTI (real-time) continues to exhibit excellent performance in real-time forecasting. Its 24h forecast shows negligible changes compared to VQLTI and even experiences a slight improvement in 24h MSW forecasting. VQLTI (real-time)'s long-term forecasting does exhibit some performance degradation, with its 120h MSW forecast error increasing by 20.22% compared to VQLTI. We consider this error reasonable, as FengWu's forecasts have inherent discrepancies compared to ERA5 (as shown in Figure 2), and the errors in FengWu's long-term forecasts lead to deviations in the TC positions obtained by the ECMWF's TC tracker, resulting in misalignment of the extracted spatial information. Although VQLTI (real-time) long-term forecasting has declined to some extent, its forecasting skill remains superior to other deep learning-based methods. Compared to TC-Pre, MSCAR, and TCIF, its 120h MSW forecast error decreases by 37.80%, 43.91%, and 54.60% respectively. Compared to the NWP models ECMWF-IFS and NCEP-GFS, VQLTI (real-time)'s 120h MSW forecast error decreases by 35.85% and 14.26%. We have also calculated the error of the Feng Wu forecast data, and the VQLTI's forecast skill is significantly better than FengWu, which verifies the effectiveness of the fine-tuning."}, {"title": "Ablation Studies", "content": "This ablation study explores the design rationale of the VQLTI model. As shown in Table 3, it explores whether to use a codebook to quantify latent variables (VQ), whether to introduce FengWu forecast data (FengWu), and whether to introduce PI data (PI). The experimental results show that using codebook for quantization of latent variables is beneficial for long-term forecasting, reducing the MSLP forecasting error by 14.54% for the 120h forecast. FengWu's forecast field plays a huge role, and introducing the FengWu forecast field, the error in the 24h to 120h MSW forecast is reduced by 55.29%-70.56%. The constraint brought by PI also plays a significant role in improving the long-term forecast skill, reducing the MSLP and MSW forecast errors by 30.75% and 24.35% for the 120h forecast, respectively.\nFurthermore, we visualize the latent variables Z of VQLTI with and without codebook quantization during training using t-SNE (Van der Maaten and Hinton 2008), as shown in Figure 4. We use the same color to represent the same intensity, and we find that the latent variables quantized using codebook not only correctly represent the same intensity, but also maintain a certain intra-class distance. This is consistent with our original intention, where the codebook successfully transfers the TC intensity information to the discrete latent space while ensuring the difference caused by the difference in spatial information between the same intensities.\nIn summary, these results validate the rationality and effectiveness of the VQLTI model design."}, {"title": "Conclusion", "content": "This study presents VQLTI, a model that achieves highly accurate real-time global long-term tropical cyclone (TC) intensity forecasting. We transfer the TC intensity information into a discrete latent space and fully leverage the forecast fields of the machine learning-based weather prediction model FengWu as spatial information conditions to compensate for the lack of physical knowledge learning in the VQLTI model. Finally, we propose to compute the potential intensity (PI) to provide physical constraints, mitigating the underestimation of TC intensity by the forecast fields. To the best of our knowledge, this is the first real-time TC intensity forecasting model that utilizes the forecast fields of a machine learning-based weather prediction model, and it performs the forecasting in the discrete latent space, resulting in low inference cost and no need for post-processing by forecasters. The experimental results demonstrate the superior performance and the rationality of the design of VQLTI."}]}