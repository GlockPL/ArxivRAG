{"title": "AIGT: AI Generative Table Based on Prompt", "authors": ["Mingming Zhang", "Zhiqing Xiao", "Guoshan Lu", "Sai Wu", "Weiqiang Wang", "Xing Fu", "Can Yi", "Junbo Zhao"], "abstract": "Tabular data, which accounts for over 80% of enterprise data assets, is vital in various fields. With growing concerns about privacy protection and data-sharing restrictions, generating high-quality synthetic tabular data has become essential. Recent advancements show that large language models (LLMs) can effectively generate realistic tabular data by leveraging semantic information and overcoming the challenges of high-dimensional data that arise from one-hot encoding. However, current methods do not fully utilize the rich information available in tables. To address this, we introduce AI Generative Table (AIGT) based on prompt enhancement, a novel approach that utilizes metadata information, such as table descriptions and schemas, as prompts to generate ultra-high-quality synthetic data. To overcome the token limit constraints of LLMs, we propose long-token partitioning algorithms that enable AIGT to model tables of any scale. AIGT achieves state-of-the-art performance on 14 out of 20 public datasets and two real industry datasets within the Alipay risk control system.", "sections": [{"title": "Introduction", "content": "Given the prevalence of tabular data in practical applications, synthesizing high-quality tabular data is an essential task. It ensures privacy protection, enhances the generalization capabilities of machine learning models, and boosts performance in scenarios with limited samples. However, this task is fraught with unique challenges, including specificity, impurities, class imbalances, and privacy concerns.\nTraditional approaches to tabular data synthesis, such as generative models and statistical methods, often lose textual information and struggle with capturing complex feature relationships. Recent efforts have explored the use of language models to incorporate feature names for better contextual learning. For instance, GReaT made the pioneering attempt to generate tabular data using large language models (LLMs), achieving satisfactory synthetic data. TapTap further enhanced the quality of synthetic data through table pre-training and applied it to data augmentation in tabular data for improved performance in prediction tasks, achieving state-of-the-art (SOTA) results. However, these methods are constrained by token limits, limiting their ability to handle arbitrarily wide tables. Additionally, they fail to fully utilize crucial tabular elements such as headers and column names, resulting in incomplete information integration.\nRecently, Artificial Intelligence Generation and Creation (AIGC) technologies, including large-scale language models and automatic image generation techniques, are driving progress in Al's capabilities for content creation and data generation. Prompt Learning, as an innovative approach, aligns the pre-training of language models with specific downstream tasks. By using well-designed prompts, which include task descriptions, input data, background information and output indicators, create a template that directs the model's attention and thus improves the accuracy and relevance of the generated context.\nAIGC is more broadly applied to the generation of multimedia content, such as images, videos, and audio. Combined with Prompt Learning, AIGC systems can generate content more accurately according to user instructions or needs. However, The application of AIGC technology in the generation of tabular data is currently relatively limited. Although work on table generation based on large-scale language models has begun to explore, these efforts have mostly utilized only the cell values in the tables, without fully leveraging the more comprehensive information contained in the tabular data. We recognize that table metadata, such as headers and column names, provides valuable context often overlooked in analysis. Inspired by AIGC and Prompt learning, we propose a prompt-enhanced model that leverages this metadata to improve performance. Therefore, we propose AI Generative Table (AIGT) technique based on prompt enhancement, which leverages metadata to enhance the quality and relevance of table generation.\nMethods based on language models inherently face limitations in generating long sequences of tokens, which is why previous approaches like GReaT and TapTap struggled to model tables with a large number of columns-something very common in real-world industry data. To address this, we developed a long-token partitioning algorithm specifically adapted for AIGT. This approach allows AIGT to effectively handle data synthesis tasks for tables of any size, overcoming the token length constraints. We further demonstrate AIGT's effectiveness in real-world scenarios such as Alipay's risk control system for commercial credit and merchant fraud detection.\nOur key contributions are as follows: (1) A Prompt-Enhanced LM for Tabular Data Synthesis: We utilize the metadata of tables to construct prompt-enhanced language model and design a series of training techniques to enhance the capability of table generation. (2) Scalability: Our proposed partitioning algorithm enables LM-based generation methods to be scaled to tables of any size, overcoming the token limit constraints of LM methods. (3) Superior Performance: We achieve state-of-the-art results on 14 out of 20 academic datasets and two real-world industry datasets from Alipay."}, {"title": "Related Works", "content": "In this section, we provide a brief background on prompt engineering and tabular data synthesis approaches."}, {"title": "Prompt Engineering", "content": "Prompt engineering has recently garnered significant attention as a technique for enhancing the performance and usability of AI models, especially in natural language processing (NLP). As described by a \u201cprompt\" involves providing natural language instructions or commands to guide an AI model in task completion. This approach offers several benefits, including increased model effectiveness, reduced training time and costs, and improved interpretability and controllability. Notable works in this area include those by ."}, {"title": "Tabular Data Synthesis", "content": "Existing approaches for tabular data synthesis can be categorized into four main groups:\nProbabilistic Models. These models leverage probabilistic techniques to synthesize data. For instance, Gaussian copula models are effective for continuous variables but not for categorical ones. Conversely, Bayesian networks  are adept at handling categorical data but struggle with continuous variables.\nGenerative Adversarial Networks. Generative Adversarial Networks (GANs) have been widely used to generate tabular data. MedGAN and RGAN produce healthcare records but face challenges with mixed data types. TableGAN employs Convolutional Neural Networks (CNNs), demonstrating that synthetic data can perform comparably to real data. CTGAN and TVAE address multimodality with column-specific preprocessing and Variational Gaussian Mixture (VGM) models. Other notable works include (Xu et al., 2019b; Marti, 2020; Jordon et al., 2018; Che et al., 2017).\nDiffusion Models. These approaches utilize diffusion models for data synthesis. TabDDPM models both categorical and continuous values but encounters difficulties with correlations. SOS uses Score-based Generative Models (SGMs) to handle imbalanced data, though it lacks the ability to condition on both data types.\nLanguage Models. Self-attention models, which have revolutionized NLP (Vaswani et al., 2017), have also been adapted for tabular data synthesis. These include encoding models (Lan et al., 2020; Devlin et al., 2018), sequence-to-sequence models (Raffel et al., 2020), and auto-regressive models (Radford et al., 2019). Transformers have been applied to table classification and joint table-text representations. GReaT and TapTap gener-"}, {"title": "The Task of Tabular Data Synthesis", "content": "To find a data synthesizer G learnt from a table D and using G to generate a synthetic table $D_{syn}$. The objective of table generation is to produce data that is similar in distribution to the original data. We evaluate the generator G from multiple perspectives: (1) Machine Learning Efficiency: When we train a classifier or regressor on the generated dataset, can it achieve the accuracy achieved by training on the original dataset? (2) Data Augmentation: When we add synthetic data to the original data, will it enhance the classification/regression task? (3) The difference between the synthetic data and the original data. We hope that the synthetic data is not a copy of the original data."}, {"title": "Methods", "content": "This section introduces the AIGT method for generating tabular data using prompt-based enhancement. As illustrated in Figure 1, AIGT comprises five main stages: (1) Prompt Design: Construct a prompt based on the table's caption information and column names. (2) Textual Encoding: Convert table features and their values into sentences, concatenate these into prompts, and construct data suitable for model input. (3) Training Procedure: Utilize a pre-trained Large Language Model (LLM) on an extensive corpus, and then conduct specific fine-tuning for downstream tables. (4) Generation: Generate samples using the fine-tuned auto-regressive language model. To support tables of any size, unrestricted by the number of features, we proposed a Partitioning Algorithm for Long Tokens to enhance the scalability of our model."}, {"title": "Prompt Design", "content": "To enhance the understanding of table structures and semantics in language models, we utilize the metadata of tables to construct prompts. In our framework, the metadata of the table comprises information from two parts.\n\u2022 Caption information: the description of the dataset, including the purpose of the dataset, background information.\n\u2022 Feature information: the names of features, the target column for prediction, and the meanings associated with the features, especially the meanings of certain abbreviations.\nWe define the function prompt that can process metadata, which is implemented by calling the GPT3.51. The corresponding code is available in the appendix B."}, {"title": "Textual Encoding", "content": "Feature Serialization. The standard large language model expects text as input. Thus, AIGT transforms each row from the dataset into a text format. We follow the previous work by serializing each sample into a text sequence. By concatenating the feature names and values of the table into sentences, that is, \"[Feature] is [Value]\". Considering that tabular data follows"}, {"title": "Training Procedure", "content": "Pre-Training. We perform pre-training on a large-scale dataset upstream. Specifically, following the first two steps, we convert each row of table data into text to form the pre-training corpus T. Each sentence $t \\in T$ can be encoded into a sequence of tokens using $tokenize(t) = (w_1,..., w_n)$. In general, AIGT factorizes the probability of generating t in an auto-regressive manner as $p(t) = \\prod_{i=1}^{N} p(w_i|w_1, ..., w_{i-1})$. During pre-training, AIGT is optimized towards maximizing the probability $\\prod_{i=1}^{||T||} p(i)$ on the entire pre-training corpus. The pre-training process can initiate with an auto-regressive language model, thereby capitalizing on the extensive knowledge that these models have already acquired.\nFine-tuning. The fine-tuning of AIGT on downstream tables follows a similar process as pre-training. The only difference is that fine-tuning aims to target specific downstream tables."}, {"title": "Generation", "content": "Sampling. We have trained an auto-regressive model q through fine-tuning on the text training dataset. This model predicts the potential subsequent labels $W_1, ..., W_{k-1}$ for the classification output distribution $z = q(w_1, ...W_{k-1})$. Multiple sampling strategies can be utilized in this scenario. Typically, the next token w is selected through weighted sampling from the output z of the LLM, guided by a temperature parameter T > 0,\n$p(w|w_1, ..., W_{k-1}) = \\frac{e^{(z_w/T)}}{\\sum_{w' \\in w}e^{(z_{w'}/T)}}$\nFollowing GReaT , the model is initialized with specific conditions and LLM is tasked with sampling the remaining tokens to complete the feature vector in its textual representation. Although we fix the position of the label in the first place during training, it is possible to generate data according to a specific feature column; one simply needs to prepend the corresponding label. For example, the provided condition can be \"prompt [Label] is [Value]\". Here, the prompt is generated from the semantic information of the table metadata as Section 4.1.\nRe-Labeling. We observe that in TapTap , the re-labeling through the table pre-diction model effectively enhances the ability to"}, {"title": "Partitioning Algorithm for Long Tokens", "content": "In practical industrial scenarios, datasets are large with numerous features, leading to the number of tokens to exceed LLM input limits. To address this scalability challenge for LLM-based methods, we propose a long-token partitioning algorithm that integrates seamlessly with existing training and generation methods.\nPartition Training. As shown in the Figure 3, first, we partition the features to ensure that there are some overlapping columns between each region, and then perform mixed training to enable the large language model to learn the feature associations of different partitions. The function of the cover column is to alleviate to some extent the missing feature associations between different regions. In our industrial scenario experiment, the number of overlapping columns is set to 1, and due to the small number of features on academic datasets, partitioning algorithms are not required.\nPartition Generation. When generating, it is generated from the back to the front. After each partition is generated, the remaining partitions are generated using the cover part of the generated partition as the starting distribution column, and finally merge the partitions."}, {"title": "Experiments", "content": "In Section 5.1, we outline the datasets, the baseline methods utilized in our experiments. In Section 5.2, we conducted extensive experiments, encompassing the machine learning efficiency of generated data, Distance to Closest Record (DCR) distance, data augmentation, and the application of our partitioning algorithm across both public and industrial datasets. To further show the excellence of our approach, we include additional analysis in the appendix C, such as discriminative metrics and feature statistical similarity between generated and original data."}, {"title": "Experimental Setup", "content": "Datasets. The experimental dataset consists of three parts as following:\n(1) Upstream Large-scale Cross-table Pre-training Dataset. We collected approximately 1000 tables with their metadata, sourced primarily from OpenML 2, referred to as STABS. We have made STABS open-source in the hope of contributing to and advancing the community focused on pre-training tabular data. More information about STABS can be seen in the appendix A.1.\n(2) Downstream Open Public Dataset. For downstream tabular tasks, we utilize a diverse set of 20 public benchmark tabular datasets to test the efficacy of our model. These datasets, sourced from OpenML, UCI repository and Kaggle, contain both binary, multi-class classification and Regression tasks. Information regarding each dataset is provided in the Table 1.\n(3) Ailpay Dataset. Datasets in real-world industrial settings generally comprise a multitude of column names. To evaluate the efficiency and performance of long token partitioning, we utilized two industrial datasets from Alipay's risk control system. We show the details in Table 2.\nBaseline Methods. We evaluate AIGT alongside five other SOTA tabular data synthesis algorithms: CTGAN, TVAE, TabDDPM, GReaT and TapTap. CTGAN  based on generative adversarial networks for tabular data, allowing the generation process to be conditional only on a single discrete feature. The same author proposed TVAE"}, {"title": "Overall Performance", "content": "In this section, we will demonstrate the performance of the proposed AIGT method through multiple experiments. Additionally, we also present the effects of the partitioning algorithm on both public and industrial datasets."}, {"title": "Machine Learning Efficiency (MLE)", "content": "In this section, we compare AIGT to alternative generative models in terms of machine learning efficiency. Each dataset was split into two parts: 80% for training purposes and 20% reserved for testing. Initially, each generative algorithm is trained on the training data. Subsequently, the trained model is utilized to generate synthetic data of equivalent size. This synthetic data is then used to train a classification/regression model, which is then evaluated using the real test set. We expect that for high-quality synthetic data, models trained on this data will perform comparably to those trained on real data. To assess the effectiveness of the machine learning models, we apply the LightGBM model, a leading GBDT method, to evaluate their efficiency. We adopt the AUC score as the evaluation metric for classification tasks and employ $R^2$ score for regression tasks. For a fair comparison we use the the standard hyper-parameter tuning budget of 50 trials. Our full search space is provided in the Appendix D and all the experimental results are averaged over 10 different random seeds. The result was showed in Table 3, Note that we match or exceed state-of-the-art on 14 out of 20 datasets."}, {"title": "Distance to closest records histogram", "content": "To verify that the generated data is similar to the original sample, rather than an exact replica, this metric calculates the distance from the nearest record in the original training dataset $D_{train}$. For each synthesized record s, it is given by $DCR(s)=min{distance(s, s_i)|s_i \\in D_{train}}$. As a distance measure, we use the L1 norm for numerical features. For categorical features, we set the difference to 0, otherwise it is set to 1. Note that models such as CTGAN and TabDDPM have a fixed"}, {"title": "Data Augmentation", "content": "When dealing with datasets that are relatively small in sample size, our approach is to boost the performance of machine learning models by supplementing these datasets with synthetic data. We integrate the synthetic data with the original training data to create an augmented training set. Following this, we conduct model training on this enlarged training set and assess its performance on the test set. The results are presented in Table 4, which show that AIGT is able to perform better than all baseline methods on most datasets."}, {"title": "Effectiveness of Partition Generation Algorithm", "content": "To validate our partitioning algorithm, we selected datasets with more than 20 columns from public datasets and two Real-world industrial Ailpay datasets. We divided the academic datasets and the NonBD table into two partitions, and partitioned the SYH table into five segments. Utilizing the synthetic data generated through our partitioning algorithm, we evaluated the ML efficiency of the synthetic datasets and compared it with the generation methods that do not employ language models. The results of the partitioning algorithm are shown in Table 5. It can be seen that even with the partitioning algorithm, our method still outperforms models not using language models in efficiency."}, {"title": "Ablation Analysis", "content": "Effects Analysis of Training Strategy. We selected 8 datasets and tested ablation experiments under the following different conditions: (1) w.o. Metadata Prompt. This refers to AIGT without the metadata from tables serving as fixed prompts. (2) w.o. Label Prioritization. We consider labels as features, shuffling them with other features for use in the training and generation processes, rather than moving the label column to the first position during the serialization process. The experimental results are shown in Figure 5, we can see that the prompt-enhanced method indeed has a good gain, demonstrating the effectiveness of our method."}, {"title": "Performance Analysis of Partition Algorithm", "content": "We evaluate the impact of the number of partitions in our partitioning algorithm on the synthesis of data. Four public datasets are selected for this purpose. The results are shown in Figure 6."}, {"title": "Conclusion", "content": "In this paper, we introduce a novel data-synthesis method for language models called AIGT, enhanced with prompts. This method utilizes the metadata of tables, guiding the language model to generate data more effectively.\nExisting table generation methods based on language models are unable to tackle the issue of long tokens. To overcome this limitation, we've designed a long-token partitioning algorithm, can support the generation of tabular data at any scale. Our approach is more flexible, capable of handling tabular data with a larger number of feature columns."}, {"title": "Ethics Statement", "content": "In this paper, the STABS dataset we constructed is derived from publicly available datasets that have been openly shared on well-known machine learning platforms such as OpenML, ensuring that no private information is included. For the risk control data from Alipay that we used, since it is internal company data and has not been anonymized, we only present the algorithm's performance without disclosing the dataset to protect user privacy and comply with data security laws and regulations. Additionally, our use of the GPT-3.5 API is conducted through compliant intermediaries and utilized by the enterprise in accordance with regulatory requirements."}, {"title": "Prompt Templates", "content": "In our implementation, we use the gpt-3.5-turbo model via the OpenAI-API to construct the function prompt. Here we presented the code to call the GPT API in Listing 1:\nOur prompt input to gpt-3.5 is shown as Listing 2. We utilize the table's metadata M to construct prompt input. In our framework, we actively collect metadata from two sources:\n\u2022 The caption information (C): the description of the dataset, including the purpose of the dataset, background information.\n\u2022 Feature information(F): the name of columns and the meaning of columns."}, {"title": "Statistical similarity", "content": "To accurately assess the dependencies among columns in synthetic data, we calculate pair-wise correlation matrices separately for both real and synthetic datasets. We use the Pearson correlation coefficient to analyze continuous variables, which produces results within the range of [-1, +1]. For categorical features, we use the uncertainty coefficient for evaluation, yielding values within the range of [0, 1]. Additionally, we use the correlation ratio to investigate the relationship between categorical and continuous variables, which also yields values within [0, 1]. Subsequently, we compute the Frobenius norm between the pairwise correlation matrices of the real and synthetic datasets and refer to it as the Correlation Distance. It is worth noting that a lower Correlation Distance value signifies a higher quality of data synthesis. The mean Correlation distance of 20 datasets was presented in figure 7."}, {"title": "Discriminator Measure.", "content": "In order to verify whether the data we generated can be easily distinguished from the original data, we trained a LightGBM discriminator (with hyper-parameter tuning) on a combination of the generated training set (with a label of 0) and the original training set (with a label of 1). Following this, we reported the test accuracy on a test data set, which comprises equal portions of samples from both the generated test set and the real test set. The scores, which are displayed in Table 7, demonstrate the superior performance of AIGT."}, {"title": "Running Time", "content": "We analyze the running time of AIGT and baseline methods. The results of the Adult Income dataset are in Table 8. As can be seen from the results, the generation method based on language models requires more computational resources and time."}, {"title": "Hyperparameters Optimization", "content": "We employ Optuna for hyperparameter tuning of LightGBM. For each specific dataset and model, we initially tune the model's hyperparameters using the original data. The determined set of hyperparameters is then consistently applied across all experiments on the dataset for all methods, ensuring a fair comparison."}, {"title": "Acknowledgments", "content": "This work is supported by the Fundamental Research Funds for the Central Universities (226-2024-00049), the NSFC Grants (No.62206247) and the Pioneer R&D Program of Zhejiang (No.2024C01035). The authors from Ant Group are supported by the Leading Innovative and Entrepreneur Team Introduction Program of Hangzhou (Grant No.TD2022005)."}, {"title": "Limitations", "content": "A primary limitation of our method is its processing speed. While we leverage the powerful capabilities of LLMs, this also results in increased running time and GPU memory consumption compared to more lightweight approaches such as GANs. Detailed comparisons are provided in appendix C.3. Furthermore, our current method for handling numerical values treats numbers as characters, applying tokenization and transformation without additional processing. This approach is unable to capture the magnitude relationships of numerical values, focusing solely on semantic similarity during tokenization. Future work will aim to develop more advanced encoding techniques for numerical values to address this limitation."}]}