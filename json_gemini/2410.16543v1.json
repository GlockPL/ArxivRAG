{"title": "Large language models enabled multiagent ensemble method for efficient EHR data labeling", "authors": ["Jingwei Huang", "Kuroush Nezafati", "Ismael Villanueva-Miranda", "Zifan Gu", "Ann Marie Navar", "Tingyi Wanyan", "Qin Zhou", "Bo Yao", "Ruichen Rong", "Xiaowei Zhan", "Guanghua Xiao", "Eric D. Peterson", "Donghan M. Yang", "Yang Xie"], "abstract": "This study introduces a novel multiagent ensemble method powered by large language models (LLMs) to address a key challenge in machine learning data labeling, particularly in large-scale Electronic Health Record (EHR) datasets. Manual labeling of such datasets is labor-intensive, time-consuming, expensive, and error-prone; it is often requiring domain expertise. To overcome this bottleneck, we developed an ensemble LLMs method and demonstrated its effectiveness in two real-world healthcare tasks: (1) labeling a large-scale unlabeled electrocardiogram (ECG) dataset in the Medical Information Mart for Intensive Care (MIMIC)-IV; (2) identifying social determinants of health (SDOH) from the clinical notes of EHR. Trading off benefits and cost, we selected a pool of diverse open source LLMs with satisfactory performance. We treat each LLM's prediction as a vote and apply a mechanism of majority voting with minimal winning threshold for ensemble. We implemented an ensemble LLMs application for EHR data labeling tasks. By using the ensemble LLMs and natural language processing, we labeled MIMIC-IV ECG dataset of 623,566 ECG reports with an estimated accuracy of 98.2%. We applied the ensemble LLMs method to identify SDOH from the social history sections of 1,405 EHR clinical notes, also achieving competitive performance. Our experiments show that the ensemble LLMs can outperform individual LLM even the best commercial one, and the method reduces hallucination errors. From the research, we found that (1) the ensemble LLMs method significantly reduces the time and effort required for labeling large-scale EHR data, automating the process with high accuracy and quality; (2) the method generalizes well to other text data labeling tasks, as shown by its application to SDOH identification; (3) the ensemble of a group of diverse LLMs can outperform or match the performance of the best individual LLM; and (4) the ensemble method substantially reduces hallucination errors compared to individual LLMs. This approach provides a scalable and efficient solution to data-labeling challenges in healthcare.", "sections": [{"title": "Introduction", "content": "Data labeling remains a significant bottleneck in machine learning (ML), particularly in healthcare applications involving large EHR datasets. The manual labeling process is labor-intensive, time-consuming, expensive, and error-prone, and it often requires substantial domain knowledge. This lack of labeled data frequently constrains the potential of supervised ML algorithms, creating a barrier to the development and deployment of predictive models for clinical applications.\nRecent advancements in LLMs\u00b9-7 offer a promising avenue to address some of these challenges. Trained on vast quantities of textual data, LLMs can perform a range of natural language processing (NLP) tasks such as text classification, summarization, and information extraction. In the healthcare field, less data labeling was identified as one of six key criteria for developing and evaluating clinical LLMs and foundation models.8,9 In clinical settings, leveraging LLMs for automatic labeling has emerged as a scalable solution for handling large datasets. However, different LLMs may have widely varying performances, and issues such as labeling errors and hallucinations pose significant risks to the accuracy of the ML models trained on these labels.\nTo overcome these challenges, we propose a multiagent ensemble method powered by LLMs (\"ensemble LLMs method\", hereafter). This approach draws inspiration from ensemble learning, a technique rooted in systems thinking and epitomized by Aristotle's assertion that \u201cthe whole is greater than the sum of its parts.\u201d Since Breiman's seminal work10 on \"bagging predictors,\" ensemble methods have proven effective at improving prediction performance by aggregating the outputs of multiple models.11-13 By combining the outputs of diverse LLMs, our ensemble approach mitigates the weaknesses of individual models, reduces hallucination errors, and yields more reliable labeling outcomes.\nWe applied the ensemble LLMs method to two real-world healthcare applications: (1) labeling 623,566 electrocardiogram (ECG) reports from the Medical Information Mart for Intensive Care (MIMIC)-IV ECG dataset,14,15 and (2) identifying social determinants of health (SDOH) from the social history sections of 1,405 clinical notes taken from the MIMIC-SDBH dataset.16 In both applications, the ensemble method demonstrated competitive performance, highlighting its scalability and effectiveness in automating healthcare data labeling."}, {"title": "AFib/AFL diagnosis from ECG Reports", "content": "The ECG is a recording of the electrical forces during depolarization and repolarization of the heart.17 The standard 12-lead ECG is an inexpensive and widely used method to study the heart's function. ECG interpretation aims to determine whether the waves and intervals observed are normal or pathological. Traditionally, ECG interpretation is broken down individually, identifying features such as heart rate, rhythm, cardiac axis, intervals (PR, QRS, QT), the P-wave, QRS complex, ST segment, and T-wave. However, \u201cthe best way to interpret an ECG is to read it systematically.\u201d18 Specific electrical abnormalities identified in these features can suggest various cardiac conditions, including arrhythmias like atrial fibrillation (AF) and atrial flutter (AFL).\nAF, a common supraventricular tachyarrhythmia, can typically be confirmed by 12-lead ECG. AF diagnosis depends on identifying characteristic features, including irregular R-R intervals, absence of distinct repeating P waves, and irregular atrial activity. However, certain complexities arise in diagnosing AF due to potential artifacts and distortions during the ECG recording, which may lead to diagnostic difficulties. In some cases, a recording may exhibit multiple rhythms, further complicating diagnosis.19 Furthermore, diagnostic statements in ECG reports often come with qualifiers that reflect the level of certainty regarding the interpretation. These qualifiers, recommended by professional guidelines, help provide context in diagnostic conclusions. For example, phrases such as \"probable\" or \"possible\" are commonly used to indicate diagnostic uncertainty20. In our study, we addressed this challenge by categorizing ECG reports based on certainty modifiers, ranking them accordingly. High-certainty modifiers, equivalent to \"probable,\" were mapped to a positive AF label, while others were categorized as uncertain or non-AF. In light of these challenges, the AFib/AFL diagnosis problem remains a key area where automating the labeling process with large-scale datasets is critical."}, {"title": "Extract SDOH from clinical notes", "content": "SDOH, or sometime referred as SBDH (social and behavioral determinants of health), are the social, economic, and behavioral factors that shape health outcomes, such as socioeconomic status, education, employment, social support, and health behaviors like smoking and alcohol use.21-23 Clinical notes in EHR often contain valuable SDOH information, which play a critical role in disease management. However, extracting these data requires either laborious human abstraction and/or extensive NLP.24,25"}, {"title": "Methods", "content": "Overall, we take an approach of selecting a key real-world problem-solving as a motivating application26 to develop the proposed ensemble LLMs method. Motivating applications can help us identifying problem formulation and goals, developing and evaluating the method on the soil of real-world application. The first and the major motivating application is to provide an effective and efficient solution for the targeted large volume MIMIC-IV ECG data labeling problem. SDOH identification is the second application, which can be also treated as text data labeling problem. This section is organized as several key questions regarding the methods we used."}, {"title": "How do we formulate the problem and prompt LLMs?", "content": "Russell L. Ackoff, a pioneer of systems thinking, addressed that \u201cSuccessful problem solving requires finding the right solution to the right problem. We fail more often because we solve the wrong problem than because we get the wrong solution to the right problem.\u201d27 Although each specific problem typically has its own features, through sharing what we experienced in our motivating application, we hope to shed light on the importance of right problem formulation, which is essential for problem-solving, here particularly critical for prompt design.\nIn our initial experiments, the problem was formulated to answer the core question of the task directly -- does the given ECG report indicate the current ECG tracing being AF (atrial fibrillation or atrial flutter)? In experiment result analysis, we identified a significant number of ECG reports that do not have sufficient evidence to assert AF or non-AF. As a matter of fact, in the recommended interpretation of ECG,20 jointly issued by American Heart Association Electrocardiography and Arrhythmias Committee and other cardiology professional organizations, modifiers such as \u201cprobably\u201d, \u201cpossible\", and others were introduced to describe the uncertainty. Correspondingly, we adjusted our problem formulation to extend the binary representation of AF with the third value \u201cUncertain\u201d, which has the semantics that the current ECG tracing has high uncertainty between AF or non-AF.\nAnother critical aspect of problem formulating is about whose judgment about the ECG tracing. It is easy to be allured to formulate the problem as to let a LLM to infer whether it is an AF case based on a given ECG report. Our initial experiments found that that problem solving perspective frequently causes LLMs to hallucinate. While, what we really need to know is the assertion of the cardiologist, who is the professional that carefully examined ECG data and wrote the ECG report about current tracing. Therefore, the problem become to ask LLMs to find what the opinion of the cardiologist has and what are the supporting evidence in the ECG report.\nCorresponding to the problem formulation, the prompt we designed is presented in Fig. S1. The prompt consists of system message and instruction. Each ECG report is concatenated in the end of instruction. This prompt is the outcome of our prompt engineering with AF200 dataset."}, {"title": "How do we organize data flow?", "content": "The MIMIC-IV ECG dataset is a valuable source for the research of heart diseases, such as atrial fibrillation (AFib) and atrial flutter (AFL) identification, and for AI&ML research. However, this large set of ECG data are unlabeled, and the data-labeling is the first thing which needs to be conducted before they can be used as valuable assets for both disease diagnosis research and AI research.\nAs illustrated in Fig. 1, we selected the first 100,000 cases (named as ECG_P1) for the method research, then we applied the method studied to the rest of the dataset (named as ECG_P2), which contains 523,566 cases. For shorter notion, term \u201ccase\u201d is used for each ECG report summarizing the \u201ccurrent tracing\u201d in a sequence of ECG study. Our research found that all AF cases appear only under certain necessary conditions, such as using AF-related terms and lemmas.28 As a matter of fact, no cardiologist would diagnose a case as AF without mentioning \u201catrial fibrillation\u201d or \u201catrial flutter\u201d related terms in the ECG report. This finding triggered us to further screen the dataset to select data which are AF-relevant cases and exclude those irrelevant, by using logical filters29. The logical filters reflect necessary conditions for AF cases and are implemented with regular expressions.28 AF relevant terms may present in some forms of variants, including abbreviations, typos, and terms in French and Spanish. For example, \u201cfibrillation\u201d may appear as \u201cfibri.\u201d, \u201cfibrillacion\u201d, \u201cfabrillation\u201d, and so on. The logical filter for \"fibrillation\" and its variants can be defined with a regular expression as follows.\nr'\\b([fF][ia]br[ia]lla[tcs]ion|[fF]ibri\\.)\\b'\nWe manually verified 200 randomly selected AF-irrelevant cases, in which there are indeed no AF cases. From the 14703 AF-relevant cases in ECG_P1 (named as dataset ECG_P1_AFR), our cardiologists in the team manually labeled a subset of randomly selected 200 cases (named as dataset AF200). We used this sub-dataset for prompt engineering to develop the prompt for labeling. With this prompt, the ensemble LLMs method is applied to dataset ECG_P1_AFR, and the labeling results are evaluated with a randomly selected 500 cases (named as validation datset), which again were manually labelled by our cardiologists. Based on the positive results of performance evaluation, we further applied the ensemble LLMs method to label ECG_P2_AFR dataset, consisting of the 53462 AF-relevant cases in ECG_P2, and we evaluated the labeling results with a randomly selected and labelled 100 cases from ECG_P2_AFR. The performance on ECG_P2_AFR resembles the one on ECG_P1_AFR. Details about the performance is presented later in this section."}, {"title": "How do we select LLMs for the ensemble method?", "content": "In our exploration of LLMs for this project, we experimented a pool of diverse LLMs from different \u201cfamilies\u201d, including GPT models, Llama3, Llama2-based models, gemma models, and MoE models. Considering the diversity of LLMs and their \u201copinions\" and trading off performance and cost, we selected a pool of 7 open source LLMs with acceptable performance on the ECG data. Each agent is a LLM together with the prompt used for predicting whether an ECG report indicates the current tracing being \u201cAF\u201d, \u201cNotAF\u201d, or \u201cUncertain\" (meaning possibly being either \u201cAF\u201d or \u201cNotAF\u201d). The 7 open LLMs include: beluga (70b), gemma (7b), llama3 (70b-instruct), mistral-openorca (7b), openhermes (7b), qwen (72b), and qwen2 (72b). The prompt used is provided in Fig. S1 (in \u201cSupplementary Material\u201d ). The performance of 7 LLMs are presented in Fig. S2, a. on ECG data labeling; b. on SDOH employment status identification; and c. on housing."}, {"title": "How do we integrate LLMs' opinions together?", "content": "We treat each LLM agent's prediction as a vote. The final labeling of an ECG report is the voting result of a voting committee composed of the 7 selected LLMs. There could be many different voting mechanisms to decide the winning label. For simplicity and generality, we adopted a most straightforward ensemble labeling rule \u2013 the label with the largest number of votes wins, under the condition that the portion of the votes is not less than a threshold, e.g., 50%. In the scenario that there is no wining label, such as tie, or the maximum of votes lower than the threshold, the case will be labeled as \u201cReview\u201d, meaning the case needs to be reviewed by a human expert. Specifically for the ensemble labeling of ECG dataset, we set the threshold as 50%, that is, a label (one of \u2018AF\u2019, \u2018Not AF\u2019, and \u2018Uncertain') must win at least 4 votes among 7 voters, to be selected. Otherwise, human expert review is required. For example, assume that there are 3 LLM agents vote for \"AF\", 2 agents vote for \u201cUncertain\u201d, and 2 vote for \u201cNot AF\u201d; in this case, although \u201cAF\u201d has maximum of votes, but it is less than 50%, so the final label is \u201cReview\u201d.\nLet\n$V_o = \\{AF, NotAF, Uncertain, NA\\}$\n$V$ is the set of valid votes.\n$V = \\{AF, NotAF, Uncertain\\}$\nLet $v_i \\in V_o$ be the vote of agent $i$, $i = 1, 2, ..., n$.\nDefine a membership function to facilitate counting votes on a valid label as follows.\n$f(x, v) = \\{\n\\begin{array}{ll}\n1 & v=x \\land x \\in V;\\\\\n0 & otherwise.\n\\end{array}$\nwhich means if vote $v$ is label $x$ in $V$, $f(x, v)$ is 1, otherwise 0.\nDefine votes counting function as follows.\n$votes(x) = \\sum_{i=1}^{n} f(x, v_i)$\nThen, the set of winners (which possibly tie on votes) is"}, {"title": null, "content": "$Y = argmax_{x \\in V} votes(x)$\nFor simplicity and generality, we adopt simple and most common ensemble labeling rules as follows.\nEnsemble rule 1 (simple majority):\n$w = \\{\n\\begin{array}{ll}\ny & y \\in Y \\land |Y| = 1;\\\\\nReview & otherwise.\n\\end{array}$\nThat is, the only label received the largest number of votes wins.\nEnsemble rule 2 (majority with winning threshold):\n$w = \\{\n\\begin{array}{ll}\ny & y \\in Y \\land |Y| = 1 \\land \\frac{votes(y)}{\\sum_{x \\in V} votes(x)} > \\theta;\\\\\nReview & otherwise.\n\\end{array}$\nBy rule 2, the label received the largest number of votes wins, subject to the condition that the proportion of votes received must be not less than a threshold $\\theta$. The threshold to use is problem-specific, dependent on the trade-off of performance and the cost for data review. A typical selection is 50%, that is, the label received over 50% of votes from LLM agents will be selected as the final label. In the scenario that there is no wining label, such as tie, or the majority of votes lower than the threshold, the case will be labeled as \u201cReview\u201d, meaning the case needs to be reviewed by a human expert."}, {"title": "How do we implement the ensemble LLMs application?", "content": "Fig. 2 illustrates a high-level perspective of the architecture, workflow, and data flow of the ensemble LLMs application we developed and used for ECG data labeling and SDOH identification. A configuration yaml file is used to specify a group of LLMs to use, the framework to use for launching each LLM, the input data path, the prompt file path, the expected output JSON structure, the project path, and other parameters. Based on the configuration, an ensemble LLMs application object will be constructed, and then the object will create a group of specified LLM agents, each of which uses the specified framework to load and run a requested LLM. Currently, the framework options available include: (1) Ollama; (2) directly using transformers with HuggingFace hub, to access the open-source LLMs in HuggingFace model repository; (3) OpenAI API and (4) Azure OpenAI, to access GPT model family. We will extend the framework options to others. Ensemble LLMs application object first creates config.yaml for each individual LLM agent, then uses that configuration to create the LLM agent. Each agent will receive the same prompt and the same input data then produce JSON style text outputs in the assigned folder of the agent. The LLM agent can fix common JSON grammar errors in the LLM output, extract structured data from the JSON data, and output the data as a CSV file. The ensemble LLMs application aggregates the CSV files from every LLM agent together, uses ensemble rules to vote, calculates the ensembled computing result, and finally evaluate the result. For the ECG data labeling problem, we created the configuration yaml file for the ensemble LLMs application, developed a prompt (as shown in Fig. S1), provided a set of ECG reports as input data, then used the ensemble LLMs application to complete the computing work. For SDOH identification problem, a set of clinical note snippets on social history was fed as input data, a prompt was designed for SDOH prediction, and the other part of the workflow is similar. Of course, the automatically created LLM agents can be used just as a template and be adapted for problem-specific needs. The ensemble LLMs application is applicable generally to text data labeling."}, {"title": "Results", "content": "Ensemble LLMs Labeling of the ECG Dataset\nUsing the proposed ensemble LLMs method, we labelled whole MIMIC-IV ECG dataset of 623,566 ECG reports. Fig. S3 illustrates the final labeling of the ECG dataset and the label distribution over the dataset. Fig. S2a is the labeling of whole ECG dataset, which consists of two subsets: (1) 555,401 AF-irrelevant cases, which were labeled as Non-AF. (2) 68,165 AF-relevant cases, which were labeled by using the ensemble LLMs method. The labels include: \u201cAF\u201d (either \u201catrial fibrillation\u201d or \u201catrial flutter\u201d), \u201cNotAF\u201d (with the same meaning as Non-AF, but labeled by LLM agents), \u201cUncertain\u201d (no sufficient information to tell it is AF or non-AF), \"Review\" (high disagreement among the voting of LLM agents, thus need human experts to review). In practice, both labels of \u201cUncertain\u201d and \u201cReview\u201d are the cases that need review, due to different reasons. The distribution rate of each label over the whole ECG dataset is provided in the right panel. Fig. S3b provides the labeling result over ECG_P1_AFR, which we used to research the ensemble LLMs method. As we will see in the next subsection, the estimated accuracy of labeling through evaluating is 98.6%. The promising outcome encouraged us to apply the ensemble LLMs method to labeling the rest of the ECG dataset. Fig. S3c shows the label distribution over ECG_P2_AFR (53462 cases). This distribution is similar to the one over ECG_P1_AFR. The estimated accuracy of labeling of ECG_P2_AFR is 96%. The details of evaluation of the labeling will be presented in the next subsection."}, {"title": "Evaluation of ECG data labeling", "content": "Fig. 3 shows the performance of the labeling of ECG_P1_AFR through evaluating with a randomly selected and labeled 500 cases as validation dataset. Fig. 3a is the confusion matrix of the labeling requiring that all LLM labeling agents get consensus on voting, that is, the winning threshold is 100%. The semantics of label \u201cUncertain\u201d is the uncertainty between \u201cAF\u201d and \u201cNotAF\u201d, and the cases labeled as \u201cUncertain\u201d will also be reviewed by human experts. For this reason, the importance of the false predictions in the confusion matrixes is different. We highlight the three different levels of importance of the false predictions in the figure. To reflect this difference, we calculated precision score of AF, precision score of NotAF, and recall score of Uncertain in Fig. 3d. Fig. 3b is the confusion matrix of the labeling with wining threshold of 50%. In this specific scenario with 7 voters, the wining label needs at least 4 of 7 agents vote the same label. Fig. 3c is the confusion matrix of the labeling with threshold 3/7 (42.9%), i.e. at least 3 of 7 agents vote the same. All confusion matrixes have removed the cases labeled as \u201cReview\u201d from evaluation. Fig. 3d lists the performance of the labeling with winning threshold (noted as \"vote_rate_LB\") from 7/7 (100%, all agree) to 0/7 (0%, no threshold at all). The labeling with threshold of 7/7 (100%), whose confusion matrix is given in Fig. 3a, achieves the best accuracy of 99.1% but has 65 cases labeled as \u201cReview\u201d (the cases did not reach the full consensus, thus needing review). When the threshold drops to 4/7 (50%), the labeling achieves accuracy of 98.6% and has just one case labeled as \u201cReview\u201d. When the threshold further drops to 3/7 (42.9%) and below, the labeling has slightly lower accuracy of 98.4% but has no case labeled as \u201cReview\u201d. Generally, with the increase of wining threshold, the accuracy increases; however, the number of cases need review also increase significantly, particularly in high thresholds close to 100%. Fig. S4a illustrates the specific LLMs vote distribution over 435 AF cases in validation dataset. The x-axis is the number of cases, and y-axis is the number of LLMs vote on \u201cAF\u201d. Overall, from Fig. 3, we can see that for this problem, no matter the ensemble rule uses which winning threshold, the labeling achieved accuracy over 98%. This high accuracy gives us confidence to move further using this ensemble LLMs method to label the rest of all MIMIC-IV ECG Data.\nTo evaluate the accuracy of labeling for ECG_P2_AFR dataset (53462 cases), we randomly selected 100 cases and labeled by our cardiologists in team. The evaluation result is presented in Fig. 4. As expected, the ensemble labeling shows similar performance as in ECG_P1_AFR, the dataset for our research on the method. The accuracy of all labeling with any threshold achieved over 96% for this larger dataset. Fig. S4b shows the specific LLMs votes distribution over 85 AF cases in validation dataset.\nThe outcome of this research shows that ensemble LLMs method is able to largely automate data labeling in large scale with satisfied quality and significant reducing of human efforts and time. Further details are given in Discussion section."}, {"title": "Ensemble LLMs method for identifying social determinants of health", "content": "In the second application, we apply the ensemble LLMs method to identify social determinants of health by using a randomly selected subset of 1405 notes (20%) from a curated MIMIC-III dataset16 on Social Behavioral Determinants of Health. We selected two variables employment status (reflecting economic status) and housing status (reflecting living environment status) for this purpose. Both these two variables already have ground truth. We apply the proposed method to this dataset and verify the predicted labels against the ground truth. Given that high uncertainty exists in social behavioral determinants of health, the ground truth of the data naturally contains some indeterminate values, which is assigned as value \u201cUncertain\u201d.\nThe result on employment status identification is presented in the Fig. 5. Using simple majority rule (without minimal votes threshold, i.e. 0/7), the ensemble LLMs method achieved overall accuracy of 95%, and 95.4% on Jaccard score of critical value \u201cAdverse\u201d, with review rate of 0.4% (2 cases to review). The results are the same for applying different winning threshold up to 50% to this problem. With the increase of the threshold, the accuracy and Jaccard score of \u201cAdverse\u201d are increasing, at the cost of increasing number of cases to review. With winning threshold of 7/7 (requiring all LLM agents agree), the accuracy is up to 97.6% and Jaccard score of \u201cAdverse\u201d is up to 96.2% at the cost of review rate up to 39.4%; when the threshold is 6/7, the accuracy is 96.9% and Jaccard of \u201cAdverse\u201d is 96.8% at the cost of review rate 11%.\nThe result on housing status identification is presented in Fig. 6. Using simple majority rule (without minimal votes threshold, i.e. 0/7), the method achieved accuracy of 99.7% and Jaccard score of 81.2% with 0 review rate. When raising the winning threshold to 5/7 (71.4%), the accuracy increases to 99.9% and Jaccard score increases from 81.2% to 92.9%, at the cost of increased review rate from 0 to 1.5% (13 cases to review among 892 cases with determinate ground truth on housing status)."}, {"title": "The ensemble LLMs surpasses the best individual LLM", "content": "Our experiments show that the ensemble LLMs method outperforms the best individual LLM in the voting committee. Fig. S2a presents the ECG data labeling performance metrics of each individual LLM in the voting committee. Earlier, Fig. 3 shows the ensemble LLMs performance, which outperforms each individual LLM's performance. Fig. S2b presents SDOH employment status identification performance. Compared with Fig. 5, the ensemble LLMs method surpasses each individual LLM. Fig. S2c shows SDOH housing status identification performance. Compared with Fig. 6, the performance of the ensemble method outperforms or matches the best individual LLM.\nFurthermore, we compared the ensemble LLMs method (using the selected 7 open source LLMs) with GPT-40, a best commercial LLM at the time of this research. Fig. S5 shows the performance comparison on ECG data labeling and Fig. S6 shows the performance comparison on SDOH identification. From Fig. S5, we can see that the overall accuracy of the ensemble method is higher than GPT-40; Fig. S6 shows that the overall performance of the ensemble LLMs method is betterer than GPT-40 on SDOH identification regarding both employment status and housing status. In both applications, the ensemble LLMs method demonstrates competitive capabilities with performance better or matching GPT-40. A more significant advantage of the ensemble LLMs method is that it reduces hallucination errors."}, {"title": "Ensemble LLMs method reduces hallucination errors", "content": "A broadly concerned problem of LLMs is hallucination. A hallucination is the contents generated by a language model and the contents appear real or plausible but false. The proposed ensemble LLMs method demonstrated its advantage in reducing the chance of errors caused by hallucination. This strength comes from the very small chance that the hallucination error could occur only if the majority of LLM agents hallucinate and trigger the false prediction at the same time and the votes with hallucination errors are the majority and larger than the winning threshold if the threshold applies. An example of ensemble ECG data labeling eliminating hallucination error is provided in Fig. 7."}, {"title": "Discussion", "content": "We presented the proposed ensemble LLMs method and its applications in large scale ECG data labeling and in identifying SDOH. There have been a large body of research applying LLMs to healthcare from many perspectives. Currently, the development of LLMs capabilities for healthcare focus on healthcare foundation models, datasets and benchmarks,30-34 as well as various novel utilization of a selected specific language model for a specific task in healthcare.35-43 To our knowledge, this is the first work on ensemble multiagent method using a group of diverse LLMs for healthcare text data labeling.\nWe applied the ensemble LLMs method to an important real-world application - labeling a large volume of ECG reports from MIMIC-IV ECG dataset effectively and efficiently. MIMIC is a broadly used publicly accessible data source for digital health research. The ECG data in MIMIC IV is a rich source for the research of heart diseases, such as atrial fibrillation (AFib) and atrial flutter (AFL) identification, with the state-of-the-art AI&ML technologies. However, this large set of ECG data with 623,566 ECG reports are unlabeled, and the data-labeling is the first thing which needs to be conducted before they can be used as valuable assets for both AFib/AFL diagnosis research and AI research. We used logical filters to screen the AF-relevant and exclude the majority of AF-irrelevant cases, then labeled the AF-relevant ECG data with the ensemble LLMs method. The estimated overall accuracy is 98.2% (weighted accuracy of 98.6% and 96% in test datasets 1&2 respectively); the cost of time for the 7 LLMs to complete the labeling is about 2 weeks (346.69 hours) on a Nvidia 4xA100 node using just one of its four GPUs; the estimated time for our cardiologist in the team to manually label 800 ECG reports is about 3.2 days at speed of 200~300 reports per day. If let a human professional to label 68165 AF-relevant cases, it will take 272.66 days, which is about 8.8 month; if to manually label all ECG reports in MIMIC-IV ECG dataset, it will cost about 2494.26 days, which is about 6.83 years, without a single day off.\nOur second application applied the ensemble LLMs method for identifying social determinants of health and achieved promising performance. As presented in Fig. 5&6, on employment status identification, the ensemble method using simple majority rule (without minimal votes threshold, i.e. 0/7) achieved overall accuracy of 95%, and 95.4% on Jaccard score of critical value \u201cAdverse\u201d, with review rate of 0.4% (2 cases to review). When using minimal winning votes threshold of 6/7, the accuracy is 96.9% and Jaccard of \u201cAdverse\u201d is 96.8% at the cost of review rate 11%. The ensemble LLMs method achieved better performance on housing status identification. Without threshold (0/7), the accuracy is 99.7% and Jaccard of \u201cAdverse\u201d is 81.2%, with review rate of 0.2%. When using the threshold 5/7, the accuracy is 99.9%, and Jaccard of \u201cAdverse\u201d is 92.9%, with review rate of 1.5% (13 cases to review).\nAs revealed in earlier discussion and presented in Figures 3, 5&6, S2, S5&S6, the ensemble of a group of diverse LLMs can outperform or at least match the performance of the best individual LLM in the voting committee and GPT-40 (the best individual LLM at the time of this research) in both ECG data labeling and SDOH identification. This is a manifestation of the advantage of ensemble learning and systems thinking.\nFinally, hallucination is one of the major challenges LLMs face.42,44,45 Particularly in clinical medicine, the errors caused by hallucinations that appear real or plausible but false could be dangerous and lead to adverse effects even risks of life. Because the probability of that all LLMs in the voting committee are hallucinating is significantly small, especially for a pool of diverse LLMs from different \u201cfamilies\u201d, the ensemble LLMs method is an effective approach to overcome or at least reduce occurrence of the hallucination problem."}]}