{"title": "An Empirical Study on Capability of Large Language Models in Understanding Code Semantics", "authors": ["Thu-Trang Nguyen", "Thanh Trong Vu", "Hieu Dinh Vo", "Son Nguyen"], "abstract": "Large Language Models for Code (code LLMs) have demonstrated remarkable performance across various software engineering (SE) tasks, increasing the application of code LLMs in software development. Despite the success of code LLMs, there remain significant concerns about the actual capabilities and reliability of these models, \"whether these models really learn the semantics of code from the training data and leverage the learned knowledge to perform the SE tasks\". In this paper, we introduce EMPICA, a comprehensive framework designed to systematically and empirically evaluate the capabilities of code LLMs in understanding code semantics. Specifically, EMPICA systematically introduces controlled modifications/transformations into the input code and examines the models' responses. Generally, code LLMs must be robust to semantically equivalent code inputs and be sensitive to non-equivalent ones for all SE tasks. Specifically, for every SE task, given an input code snippet c and its semantic equivalent variants, code LLMs must robustly produce consistent/equivalent outputs while they are expected to generate different outputs for c and its semantic non-equivalent variants. Our experimental results on three representative code understanding tasks, including code summarization, method name prediction, and output prediction, reveal that the robustness and sensitivity of the state-of-the-art code LLMs to code transformations vary significantly across tasks and transformation operators. In addition, the code LLMs exhibit better robustness to the semantic preserving transformations than their sensitivity to the semantic non-preserving transformations. These results highlight a need to enhance the model's capabilities of understanding code semantics, especially the sensitivity property.", "sections": [{"title": "1. Introduction", "content": "Large Language Models (LLMs) for code have demon-strated remarkable performance on a variety of automatedprogramming tasks. Automating such tasks is inherentlycomplex, requiring the model to understand numerous con-cepts within the underlying code. However, despite thiseffectiveness on various code-related tasks, a fundamen-tal question remains: How deeply do these large languagemodels for code (code LLMs) truly understand the codethey interact with? Current evaluations usually assess theusefulness (e.g., pass@k metric) of programs generated bythese models based on the passed tests for the given tasksin several benchmarks such as HumanEval [1], MBPP [2],and CodeContests [3]. While these task-driven evaluationsmeasure end-to-end performance, they fail to reveal theLLMs' capabilities in understanding code semantics, whichcould be crucial for ensuring the reliability of code LLMs.Prior studies [4, 5, 6] have begun to explore the capa-bilities of LLMs in code understanding. However, a deeperunderstanding of the LLMs' capabilities to capture semanticaspects, including control dependence and data dependence,remains elusive. Wan et al. [4] prioritize syntactic cor-rectness over semantic understanding. Evaluation methodsmight assess if generated code compiles without truly grasp-ing its intended functionality. Hooda et al. [5] evaluateLLMs' capability in understanding code semantics througha single task, which is code completion. This restricts ourunderstanding of how broadly code LLMs can understandcode. Ma et al. [6] evaluate the code LLMs' capabilities inreconstructing code syntax and semantic structures by fine-tuning the LLMs to predict certain properties in code suchas nodes and edges in Abstract Syntax Tree (AST) or data/-control dependence. It is unclear how LLMs arrive at theiroutputs, making it difficult to assess their reasoning processand identify potential biases in semantic understanding.In this paper, we propose EMPICA, a novel framework forsystematically and empirically evaluating code LLMs'capabilities in understanding essential code semantic as-pects. Our approach involves analyzing the sensitivity androbustness of code LLMs to changes in code semantics.Within this framework, we focus on two fundamental seman-tic relations in the programming analysis: control depen-dence and data dependence [7, 8, 9]. To assess code LLMs'capabilities in understanding these dependencies, we defineeight code transformations. These transformations can becategorized as either semantic non-preserving (affecting thesemantic relations) or semantic preserving (not affecting thesemantic relations).We apply our framework to three critical software en-gineering tasks with varying levels of semantic complexity:code summarization, method name prediction, and outputprediction. We evaluate the models for each task withoutfine-tuning or additional training data to minimize potentialbiases. Ideally, models must recognize semantic changesintroduced by non-preserving transformations and adjusttheir outputs accordingly. Conversely, their outputs must"}, {"title": "2. Background and Related Work", "content": "2.1. Large Language Models for Code\nLarge Language Models for Code (code LLMs) arebecoming popular in the Software Engineering (SE) indus-try. Multiple code LLMs, such as Github Copilot\u00b9, Alpha-Code [14], and GPT-3.5 [13], have been employed to speedup the software development process. These models playa significantly important role in the automation of multiple SEtasks such as code completion [15], program repair [16], ortest generation [17], etc. As the sizes of these models andthe amount of training data have increased, code LLMs haveexhibited impressive performance in these tasks [15, 16, 17].Existing LLMs for code are constructed based on theTransformer [18] (encoder-decoder or decoder-only). Thesemodels are trained on extensive, unlabelled corpora of code-related data, enabling them to generate code in various pro-gramming languages. The training process typically involvesthe causal language modeling objective, where the modellerns to predict the next token in a sequence. The success ofLLMs in the SE task can be attributed to three main factors:Large Size, Premium Data, and Expert Tuning [19].Recent advancements in code LLMs demonstrate atrend towards larger model sizes, accompanied by superiorperformance [20, 21]. These studies show that increas-ing the number of model parameters can significantly en-hance model capabilities. For instance, early models such asCodeT5 [22] had limited success due to their relatively smallsize. In contrast, modern models like Codex, Code Llama,and DeepSeek achieve remarkable performance on variousbenchmarks with their massive number of parameters.Additionally, high-quality code corpora enable LLMs tolearn different programming languages and coding paradigmseffectively. To ensure the quality of the training corpus, it iscommon for LLMs to perform extensive data preprocessingon the large amount of data collected. One common strategyis removing likely auto-generated or unfinished code files.Additionally, specific rules are employed to filter out un-common code files. These rules include the repository starrating, file size, line length, and alphanumeric rate.Expert tuning is also essential for optimizing modelperformance. Common practices include using the Adamoptimizer or its variants and further training from the modelspre-trained on text. Key hyperparameters such as learningrate, batch size, window size, warmup steps, gradient ac-cumulation steps, and sampling temperature require experttuning. Specialized tokenizers, such as Byte-level Byte-Pair-Encoding and SentencePiece, are applied on code corpora tohandle programming syntax effectively.\n2.2. Evaluating Code LLMS\nSeveral benchmarks have been established to evaluatethe capabilities of code LLMs in various SE tasks. Forexample, Chen et al. [1] introduced HumanEval, a popularbenchmark designed to assess the functional correctnessof the generated code in multiple programming languages.Similarly, Austin et al. [2] proposed MBPP dataset, whichcontains solvable problems for entry-level programmers.This dataset is also widely used to evaluate the programsynthesis of code LLMs [23, 24, 25]. Another manuallycrafted benchmark ClassEval [26] focuses on evaluatingLLMs' performance on class-level code generation. Exper-imental results on these benchmarks have demonstrated theremarkable performance of code LLMs across various SEtasks, which significantly accelerates the software develop-ment process.In addition, many approaches [27, 21, 5] proposed tofurther thoroughly test code LLMs in various code gener-ation and code understanding tasks. Liu et al. [27] con-ducted comprehensive experiments on eight models using"}, {"title": "3. Motivation", "content": "Despite the success of code LLM in SE tasks, thereare multiple doubts about the performance of these mod-els [5, 6, 31], \"Whether code LLM really learn the syntaxand semantics of code from the training data and leveragethe learned knowledge to conduct SE tasks\u201d. Yang et al. [31]have conducted experiments to investigate the memorizationof LLMs for code with CodeParrot and CodeParrot-small.Their experimental results show that from 43% to 57%,outputs of these models contain memorized information.This raises a question about the reliability of the answersprovided by code LLM.Figure 1 shows a summary generated by Microsoft/phi-22 for a given code snippet. This given code detects andreturns true if, at any point, the account balance falls belowzero. The generated summary is \u201cIf the balance becomesnegative at any point, the function returns true.\u201d (Figure 1b).According to the explanation of SHAP [32], the modelcan accurately produce this summary statement, especiallythe token \u201cnegative\u201d, because it focuses on the conditionalstatement at line 6, if (balance < 0).In addition, without checking the negative value of bal-ance (e.g. if (balance < 0)), the code snippet in Figure 2a issemantically different from one in Figure 1a. However, thesummary (Figure 2b) generated by Microsoft/phi-2 is stillvery similar to the summary in Figure 1b. Specifically, thesummary for the code in Figure 2a is \u201cThe function belowtakes an ArrayList of longs and returns true if the sum ofthe operations is below zero. Otherwise, it returns false\u201d.The explanation produced by SHAP (Figure 2b) showsthat Microsoft/phi-2 mainly focused on several tokens likeboolean, operation, true, false, or especially the methodname belowZero to generate the summary. For example, themodel focused on the expression balance += operation andreturn true; in the input for producing token \u201cif\u201d in thesummary. Also, to generate token \u201czero\u201d in the summary,the model focused on the tokens like boolean, belowZero, andoperation in the code snippet. This example demonstratesthat LLM could heavily rely on general patterns of input codeto generate summaries without really comprehending them.The above analysis raises the question on the capabilityof code LLM in understanding code semantics: \u201cWhetherand how the code LLM can really understand code semanticsor just capture and rely on the general patterns from thedata for conducting downstream tasks\u201d. In this research, wepropose EMPICA, a framework for systematically evaluatingthe capability of code LLM in capturing code semantics,including control and data dependencies."}, {"title": "4. EMPICA: A Framework for Evaluating Code Semantic Understandability of LLMs", "content": "This work aims to evaluate code LLMs' capability incode semantic understanding in the two fundamental codesemantic relations: control dependence and data depen-dence. Figure 3 illustrates the overview of our framework,EMPICA, containing four main components: (1) ProgramGeneration, (2) Program Transformation, and (3) Code Un-derstanding, and (4) Robustness & Sensitivity Evaluation.First, for a code LLM M under evaluation, EMPICAemploys M to generate code. Then, EMPICA directly usesthe generated code to evaluate the capabilities of M inunderstanding code semantics. This is reasonable becauseevaluating M in understanding arbitrary code could hinderthe capability of M. Indeed, M could misunderstand anentirely new code snippet, especially if the code significantlydeviates from the patterns and distributions seen duringtraining (i.e., out-of-distribution) [33]. Therefore, EMPICAconducts the analysis on the code generated by the model it-self for a more impartial evaluation of the model's capabilityand to mitigate the potential risk of capability hindering dueto the unseen data.Next, EMPICA systematically introduces controlled mod-ifications/transformations into the input code and observeshow the model reacts in M's output for a specific code under-standing task. EMPICA applies a variety of transformationsdesigned to target both control and data dependencies in theinput code snippets. We employ both semantic-preservingtransformations and semantic-non-preserving transforma-tions to modify the code snippets. Specifically, given acode snippet, semantic-preserving transformations createvarious variants of the code while maintaining the origi-nal functionality of the snippet in its variants. In contrast,semantic-non-preserving transformations produce variantswhose functionality differs from the original ones.Ideally, if M is capable of understanding code semantics,M' predictions must be robust to the semantic-preserving(SP) transformations and sensitive to the semantic-non-preserving (SNP) ones. For a specific task, M must producethe equivalent responses to the original input code and itsvariants created by the SP transformations. In contrast, M'soutputs for the original input and its variants modified by theSNP transformations are expected to be different.For thorough evaluation, EMPICA selects three repre-sentative SE tasks that heavily require code understanding,including code summarization, method/function name pre-diction, and output prediction. These tasks are in differentcomplexity levels, encompassing both static and dynamicbehaviors, as well as varying degrees of program under-standing, ranging from coarse-grained to fine-grained. Codesummarization requires an understanding of the overall pur-pose of the code snippet to provide a concise summary.Method/Function name prediction demands exact compre-hension of code semantics and functionality to predict anappropriate name for a method/function. Output predictioninvolves precisely capturing the underlying logic of code andthe relationship between input-output to provide correct pre-diction. By incorporating these tasks in different natures andcomplexities, EMPICA enables a comprehensive assessmentof code LLMs in capturing code semantics.\n4.1. Semantic-aware Code Transformations\nGiven a code snippet $c \\in C$, a transformation operator$t : C \\rightarrow C$ is a function that maps $c$ from and to a space$C$ of all possible code snippets in the given programminglanguage. Let's assume we have an oracle function $\\gamma : C \\rightarrowS$, which maps from the space of code snippets $C$ tothe specification space $S$ which represents the code behaviors.A code transformation $t$ can be categorized into two groupsbased on its impact on $\\gamma(t(c))$, semantic-preserving (SP) andsemantic-non-preserving (SNP) transformations.\nDefinition 1. Semantic-preserving (SP) transformation.Given a code snippet $c \\in C$, a transformation $t_p$ is asemantic-preserving transformation if the modifications in-troduced by applying $t_p$ on $c$ do not affect its specifiedbehaviors, $\\forall c \\in C, \\gamma(c) = \\gamma(t_p(c))$.\nDefinition 2. Semantic-non-preserving (SNP) transfor-mation. Given a code snippet $c \\in C$, a transformation $t_n$is a semantic-non-preserving transformation if the modifi-cations introduced by applying $t_n$ on $c$ change its specifiedbehaviors, $\\forall c \\in C, \\gamma(c) \\neq \\gamma(t_n(c))$.\nEMPICA curated the transformation operators from theliterature [34, 35, 36]. To systematically investigate theunderstanding of code LLMs in control and data depen-dencies, we manage the transformations with respect tothese relationships. Table 6 introduces the details of thetransformation operators and the corresponding examples.\n4.2. Code Understanding: Subject Tasks\nIn this work, EMPICA conducts Counterfactual Anal-ysis in three representative SE tasks which require code"}, {"title": "4.2.1. Code Summarization", "content": "Code summarization (Ts) is the task of concisely de-scribing a code snippet's overall functionality, purpose, andbehavior in a natural language [37]. To accurately providea summary of a given code snippet, the model needs toprecisely capture the semantics of the code. Thus, we employcode summarization as a representative task for evaluatingcode LLMs' capability in understanding code semantics.Given a code snippet $c_i \\in D$, which is originallygenerated by code LLM $M$, and $c_i' = t(c_i)$ is the transformedversion of $c_i$ which generated by applying a transformationoperator $t$. If $t$ is a SP transformation, the functionality of$c_i'$ is semantically equivalent to $c_i$, and the summary of $c_i'$is expected to be similar/identical with that of $c_i$. Meanwhile, if$t$ is a SNP transformation, the functionality of $c_i'$ is differentfrom $c_i$, and their corresponding summaries are expected tobe semantically different from each other.Let $d_i$ and $d_i'$ be the summaries of the code snippets $c_i$and $c_i'$, both outputted by $M$. To measure the Robustness"}, {"title": "4.2.2. Method Name Prediction", "content": "Method name prediction (TN) is the task of suggestingan appropriate method/function name for a given code snip-pet [41]. Successful method name prediction requires a deepunderstanding of the underlying semantics and operationsof the code. Similar to code summarization, method nameis another form of summary of code functionality, yet it ismore succinct.Let $m_i$ and $m_i'$ be the method names predicted by CodeLLM $M$ for the code snippet $c_i$ and its transformed code$c_i'$, respectively. To measure the capability of $M$ in under-standing code semantics for this task, $T_N$, we compare thesimilarity of $m_i$ and $m_i'$ at token level (i.e., exactly match) andsub-token level (i.e., precision, recall, and f1-score).For token-level assessment, the similarity of $m_i$ and$m_i'$, $sim(m_i, m_i')$, is measured regarding whether they areexactly identical, $sim(m_i, m_i') = EM(m_i, m_i')$. Specifically,$EM(m_i, m_i')$ measures whether $m_i$ and $m_i'$ are exactly thesame, $EM(m_i, m_i') = 1$ if $m_i$ and $m_i'$ are identical, otherwise,$EM(m_i, m_i') = 0."}, {"title": "4.2.3. Output Prediction", "content": "The task of output prediction, (To), involves predictingthe output of a given code snippet when it is executedwith a specific input [28]. To achieve high performancein this task, code LLMs must comprehensively understandthe code's semantics, operation logic, and execution flow.For code summarization and method name prediction, thesetasks are only required to capture the program's static be-haviors. Meanwhile, output prediction needs to analyze notonly static but also dynamic behaviors of the given codesnippets. Thus, the correct prediction of the test output ismore complex than the previous two.Let $k$ be the number of test inputs of $c_i$ and its trans-formed code $c_i'$. Let $o_{ij}$ and $o_{ij}'$, $1 \\leq j \\leq k$ be the outputsof $c_i$ and $c_i'$ which predicted by code LLM $M$ with the $j^{th}$test. If $c_i'$ is created by a SP transformation, the behaviorsand functionality of $c_i$ and $c_i'$ are equivalent. They behavesimilarly with the same input, i.e., return equal outputs fora given input. On the other hand, if $c_i'$ is created by a SNPtransformation, the functionalities of $c_i$ and $c_i'$ are different.They could produce different outputs for a given input.Specifically, to assess the robustness and sensitivity of $M$ inthe output prediction task, $T_O$, Equation 1 is realized withthe similarity function expressed as follows:\n$sim(o_i, o_i') = \\begin{cases}1 & \\text{if } o_i = o_i'\\\\0 & \\text{otherwise}\\end{cases}$"}, {"title": "4.3. Prompt Design", "content": "In this work, EMPICA utilizes prompting to evaluate codeLLMs with the code understanding tasks. The design of theprompt can significantly impact the performance of the mod-els. Thus, we aim to design simple prompts to mitigate the"}, {"title": "5. Evaluation Design", "content": "To evaluate code LLMs' capability in understandingcode semantics, we seek to answer the following questions:\n\u2022 RQ1: Robustness and Sensitivity Analysis. How ro-bust are the state-of-the-art code LLMs [11, 10, 13,12] to the SP transformations in code understandingtasks? How sensitive are code LLMs to SNP transfor-mations in these tasks?\n\u2022 RQ2: Model Size Analysis. Does code LLMs' sizeaffect their capability to understand code semantics?\n\u2022 RQ3: Correctness Correlation Analysis. Is there anycorrelation between the code semantic understand-ability of code LLMs and the correctness of theirgenerated code?\n\u2022 RQ4: Semantic Inference Analysis. Can the codeLLMs correctly capture the code semantics and di-rectly infer the relations including control and datadependence?"}, {"title": "5.1. Experimental Procedure", "content": "To mitigate the risk of the out-of-distribution prob-lem [42], EMPICA utilizes the code generated by the modelunder evaluation to evaluate the model's capability of un-derstanding code semantics. In this work, we employ thepopular benchmark HumanEval [1], which is widely usedin code generation research [5, 21], as \u201cseeds\u201d for the modelto generate code snippets for our experiments. Specifically,this dataset contains 164 programming problems with unittests. Each problem has a problem description, a functionsignature, and several manually created test cases. On aver-age, there are about eight tests per problem to evaluatethe correctness of the generated code. For thorough evaluation,EMPICA queries the models to generate code in two popularprogramming languages, Java and Python, for each problem.Then, EMPICA examines how the model understands codesemantics in both languages."}, {"title": "6. Experimental Results", "content": "6.1. RQ1. Robustness and Sensitivity Analysis\n6.1.1. Code Summarization\nTable 3 presents the average Robustness and Sensitivityof code LLMs to the code transformations in the codesummarization task. Code LLMs perform robustly to both SPand SNP transformations. Particularly, regarding semanticsimilarity, the average Robustness of the models to the SPtransformations is about 0.9. The average Sensitivity of themodels to the SNP transformations is about 0.1. In otherwords, the similarities between the summaries of the originalcode and those of the semantic equivalent transformed codeare 0.9. Meanwhile, the differences between the summariesof the original code and those of the semantic non-equivalenttransformed code are only 0.1. This indicates that the codeLLMs produce similar summaries for the original codeand the transformed code regardless of the impact of thetransformations on the code semantics.Figure 4 shows an example about the summaries pro-duced by Code Llama for its generated code and for thecorresponding transformed code. The original generatedcode is to check if an input n is a prime number. As shown,the summary of the original code (Figure 4a) and that ofthe transformed code, which is created by negating theconditions at lines 2 and 6 (Figure 4b), are pretty similar.The transformations completely change the semantics ofthe original code. Specifically, the transformed code returnsfalse for all the numbers greater than or equal to 2. Thismeans that the transformed code (Figure 4b) no longerchecks for prime numbers. However, the general structureof the original code and the transformed one are quite simi-lar. As a result, Code Llama produces similar summaries forthese two methods regardless their functionality differences.In general, code LLMs are not explicitly trained to cap-ture the program dependencies, the underlying semantics, orthe operational logic of code. Instead, they are trained on alarge corpus of code in form of text data to implicitly learnthe patterns and relationships in the data. When generatingcode summaries, the models could rely on the overall struc-tures and the surrounding contexts rather than deeply under-standing the underlying semantics of each code statementin the given code snippets. Although the original code andthe transformed code could be different or similar regardingtheir semantics, their general structures are still similar.Therefore, the models could produce similar summaries forthem. For instance, the transformations in Figure 4b makethe behaviors of the program totally different from those ofthe original one (Figure 4a). However, the general patterns ofthese two code snippets are similar, which led Code Llama to"}, {"title": "6.1.2. Method Name Prediction", "content": "Compared to the task of code summarization, code LLMsare less robust and more sensitive to both kinds of transfor-mations in the task of method name prediction, see Table 4.For instance, the predicted method names of 62% SP trans-formed Java code and 48% SP transformed Python code areidentical to those of the original code snippets. Meanwhile,by SNP transformations, 54% of transformed Java code and59% of transformed Python code have the predicted namesdifferent from that of the original code. This could indicatethat in the method name prediction task, code LLMs aremore perceptive to modifications and respond differently tooriginal and transformed code.Figure 5 shows the method name predicted by Magic-Coder for its original generated code and the correspond-ing transformed code. As seen in Figure 5a, the codeoriginally generated by MagicCoder for problem of Hum-manEval_72_will_it_fly is correct, which correctly returnstrue if an array list q will fly. Specifically, q will fly if it isa palindromic array list and the sum of its elements is lessthan or equal to a weight w.For the original code in Figure 5a, MagicCoder sug-gested the method name isPalindromeAndSumLessThen, whichreasonably describes the functionality of the given code.However, after reordering the parameters (Figure 5b), Mag-icCoder suggests a completely different name, isSymmetriceven though this transformation does not impact the func-tionality of the code. This shows that MagicCoder is notrobust enough to preserve the recommended name for thesemantic equivalent transformed code.For the similarity at the sub-token level (F1-Score), codeLLMs show their high Robustness to the SP transformationsbut low Sensitivity to the SNP transformations. In partic-ular, the average Robustness in terms of F1-Score for Javacode is 0.80, and the corresponding figure for Python code is0.72. Meanwhile, the Sensitivity is about 0.31 and 0.34 forJava and Python, respectively. This indicates that code LLMscan generate similar method names for the original code andSP transformed code. However, for SNP transformed code,the predicted names are not considerably distinguishablefrom that of the original code. These results suggest that atsome degree, code LLMs can capture the code semantics andrealize the modifications affecting code meaning. However,the effects on the generated outputs (methods' names) arenot significant."}, {"title": "6.1.3. Output Prediction", "content": "Table 5 shows the average Robustness and Sensitivityof code LLMs for the task of output prediction. The resultsillustrate the significant differences between the outputspredicted for the original code and the transformed code.Specifically, only 64% of the cases are predicted to have"}, {"title": "6.4. RQ4. Semantic Inference Analysis", "content": "Table 7 shows the prediction performance of CodeLLMs in predicting pairs of statements (pairs for short)that have control/data dependence relationships in a givencode. Specifically, Precision specifies the ratio of pairs thatreally have a control/data dependence relationship among"}, {"title": "6.5. Threats to Validity", "content": "As for any empirical study, there are several threats tothe validity of our results and conclusions. First, a potentialthreat lies in the design of the prompts. To mitigate thisthreat, we carefully follow the prompt templates of thestudied models to design and optimize the prompts for eachcode understanding task. Second, there is a certain levelof randomness of the studied code LLMs in the generationprocedure, which could affect the models' performance.To reduce this threat, we set the temperate value to 0 tominimize the randomness. Another threat could lie in theselection code LLMs. To mitigate this threat, we chose di-verse and representative models, including both open-sourceand commercial ones. We also conducted experiments ondifferent model sizes. In addition, one threat could comefrom the evaluation procedure, i.e., different performance"}]}