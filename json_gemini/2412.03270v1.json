{"title": "Intent-driven In-context Learning for Few-shot Dialogue State Tracking", "authors": ["Zihao Yi", "Zhe Xu", "Ying Shen"], "abstract": "Dialogue state tracking (DST) plays an essential role in task-oriented dialogue systems. However, user's input may contain implicit information, posing significant challenges for DST tasks. Additionally, DST data includes complex information, which not only contains a large amount of noise unrelated to the current turn, but also makes constructing DST datasets expensive. To address these challenges, we introduce Intent-driven In-context Learning for Few-shot DST (IDIC-DST). By extracting user's intent, we propose an Intent-driven Dialogue Information Augmentation module to augment the dialogue information, which can track dialogue states more effectively. Moreover, we mask noisy information from DST data and rewrite user's input in the Intent-driven Examples Retrieval module, where we retrieve similar examples. We then utilize a pre-trained large language model to update the dialogue state using the augmented dialogue information and examples. Experimental results demonstrate that IDIC-DST achieves state-of-the-art performance in few-shot settings on MultiWOZ 2.1 and MultiWOZ 2.4 datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "Task-oriented dialogue (TOD) has become increasingly inte-gral to our daily lives, assisting users in tasks such as booking flights and planning trips. A typical TOD system consists of four modules [1]: (1) Natural Language Understanding (NLU); (2) Dialogue State Tracking (DST); (3) Policy Learning; and (4) Natural Language Generation. DST is the central component of TOD systems, where it tracks the user's intent using slot-value pairs to represent the dialogue state.\nConstruction DST datasets is both expensive and time-consuming [2]. But most DST methods [3]\u2013[5] require large amounts of data to achieve satisfactory performance. Although some methods [6], [7] have enhanced the model's generalization performance in unknown domains, these models still heavily rely on DST datasets. Therefore, it is crucial to research effective few-shot DST methods to mitigate the expenses associated with constructing DST datasets.\nRecently, more and more researchers focus on large lan-guage models (LLMs) since they demonstrate superior per-formance in few-shot scenario [8]. Kulkarni et al. [9] accomplishes the DST task by automatically generating context"}, {"title": "II. METHOD", "content": "DST task predicts the dialogue state at turn t, denoted as Bt = {(s\u2081, v\u2081), (s\u2082, v\u2082),...,(s\u2099, v\u2099)}, where (sn, vn) is a slot-value pair. For example, {(train-arriveat, 10:00), (train-leaveat, 7:00)}. The input of DST task is the dialogue information, denoted as Dt = {Ut, Ht\u22121, Bt\u22121, Ot}, where Ut represents the user's input, Ht-1 represents the dialogue history and Ot includes other information such as dialogue turn and dialogue domain. DST task can be formalized as:\nBt = DST(Ut, Ht\u22121, Bt\u22121, Ot).\nFigure 1 presents the architecture of the IDIC-DST frame-work, which is composed of two main modules: the Intent-driven Dialogue Information Augmentation module and the Intent-driven Examples Retrieval module.\nIn the Intent-driven Dialogue Information Augmentation module, we first extract the user's intent It from Ut using a fine-tuned T5 model [16]. It is then incorporated into Dt, resulting in the augmented dialogue information D\u1d57.\nFollowing this, in the Intent-driven Examples Retrieval module, specific tokens in D\u1d57 are masked, generating the masked dialogue information D\u1d57'. We then calculate the similarity between D\u1d57' and other dialogues within the dataset. The top k examples with the highest similarity scores are selected. These selected examples are subsequently concatenated with D\u1d57' and fed into a pre-trained LLM, which is then used to update Bt."}, {"title": "A. Intent-driven Dialogue Information Augmentation", "content": "NLU focuses on identifying user's intents and extracting dialogue domains from dialogues, enabling computers to understand and interpret natural language. Therefore, we enhance the performance of LLMs on DST tasks through NLU models. Specifically, we fine-tune a T5 model as a NLU model to extract It from Ut, which is then concatenated with Dt, producing the augmented dialogue information D\u1d57. The computation of D\u1d57 can be formalized as:\nD\u1d57 = Dt \u222a NLU(Ht\u22121, Bt\u22121, Ut, Ot).\nTo extract the user's intent, we employ a T5-small model, which is trained in a few-shot setting using TOD dataset. Specifically, we utilize dialogue context as input, with the user's intent It as the output. This training process results in a T5 model that is specifically fine-tuned for NLU tasks."}, {"title": "B. Intent-driven Examples Retrieval", "content": "We test the impact of different information from Dt on retrieval results and we find that:\n1) In-context examples retrieved based on It provide the most effective guidance for the model. This is likely due to examples that closely match the current user's intent offer more relevant information. The dialogue state Bt-1, which comprises slot-value pairs from previous turns, may introduce irrelevant information, diminishing the effectiveness of guidance. Thus, in-context examples retrieved solely based on the current turn's slot-values It outperforms those retrieved based on other information.\n2) In-context examples retrieved based on dialogue history show the lowest relevance to current turn. This is likely because the dialogue history contains the complete interaction between the user and the system, which includes a substantial amount of information irrelevant to the current user's intent. Therefore, the dialogue history may be unnecessary for Intent-driven Examples Retrieval.\nBased on above findings, we mask dialogue history, Bt and Bt\u22121 before retrieval to obtain the rewritten information D\u1d57:\nD\u1d57' = Mask(D\u1d57)\n= {turn, domain, [MASK], [MASK], It, [MASK]}.\nThen, we perform a simple rewrite of the user's input based on It to ensure that the user's input includes explicit dialogue"}, {"title": "C. Dialogue State Updating", "content": "Numerous prior studies [14], [15] have approached DST task by framing it as a code generation problem, where dialogue states are dynamically updated by generating code. Building on these approaches, we propose modeling the DST task as a text-to-SQL generation task, leveraging the SQL language to dynamically update dialogue states.\nOur method follows a specific set of rules:\n1) Each table in the SQL schema represents a domain, while each column in the table corresponds to a slot.\n2) The WHERE clause captures all changes in the dialogue state relevant to the current conversation.\n3) If the current dialogue involves n domains, each domain is represented by a unique alias d\u2081,..., dn.\nThe input prompt Pt for the LLM consists of a predefined SQL command, which initializes tables to define the dialogue domains and slot values. This fixed SQL command is then augmented with the top-k retrieved in-context examples and the augmented dialogue information D\u1d57'. The pre-trained LLM processes this DST prompt to generate a SQL query, which reflects the updates required for the current dialogue state. Subsequently, the specific changes in the dialogue state St are extracted from the generated SQL query. The process of updating Bt can be formalized as follows:\nSQLt = PLM(Pt),\nSt = sql(SQLt, Bt\u22121),\nwhere sql() is the SQL query extraction function."}, {"title": "III. EXPERIMENTS", "content": "We employ the MultiWOZ 2.1 and 2.4 [17], [18] datasets to experimentally evaluate our proposed IDIC-DST method. The MultiWOZ dataset is a dialogue dataset widely used in research on task-oriented multi-turn dialogues within the field of natural language processing. It contains 10,438 dialogues spanning 7 different domains, including restaurants, hotels, attractions, taxis, and transportation. Each dialogue covers 1 to 5 domains, with an average of 13.7 turns per dialogue, exhibiting substantial variation in length and complexity.\nWe use the Joint Goal Accuracy (JGA) [19] as the evaluation metric. For each turn in a dialogue, a dialogue state is considered correct only if it exactly matches the ground truth, meaning all slots and values are correctly predicted.\nAdditionally, we evaluate IDIC-DST in practical dialogue tasks using four other metrics: booking rate, representing the percentage of dialogues that result in successful bookings; F1 score, which balances precision and recall to assess dialogue state accuracy; completion rate, indicating the proportion of dialogues that finish within a restricted turn; and average turn, counting the average turn needed to complete dialogues."}, {"title": "B. Implementation Details", "content": "To validate the performance of IDIC-DST, we extracted 1% of the MultiWOZ dataset for training the NLU model and the retriever, which is also used as the retrieval sample pool.\nThe NLU model is initialized using the T5-small model [16], with a batch size of 128, a learning rate of 10-3, 10 epochs, and the Adafactor optimizer. The retriever is initialized using the SBERT all-mpnet-v2 model [20], with a batch size"}, {"title": "C. Main Results", "content": "Table II shows the results of IDIC-DST compared with baseline methods. It is evident that our model outperforms all baseline models with parameter sizes less than 100B. When compared to the SOTA DST method SM2-11B, which has over 10 B parameters, IDIC-DST demonstrates a 4.75% improvement in JGA on MultiWOZ 2.1 and an even more substantial 12.63% advantage in JGA on MultiWOZ 2.4. Even when compared with the IC-DST Codex, which utilizes Codex-Davinic model with 175B parameters, IDIC-DST achieves comparable performance on MultiWOZ 2.1 dataset and even demonstrates a 4.31% improvement on MultiWOZ 2.4.\nTo validate the performance of IDIC-DST in TOD tasks, we implemented a complete TOD system. The NLU module utilizes T5 NLU model [28], the policy learning module adopts a dynamic dialogue policy transformer [29] model, and the natural language understanding module employs a template-based generation method.\nAs shown in Table III, the results indicate that the TOD system based on IDIC-DST achieves superior performance in terms of all evaluation metrics. This demonstrates that IDIC-DST can more accurately extract user's intent, improving the accuracy and efficiency of TOD."}, {"title": "D. Ablation Study", "content": "As shown in table IV, we conducted ablation experiments based on IC-DST on MultiWOZ 2.4 dataset.\n1) Intent-driven Dialogue Information Augmentation: The introduction of Intent-driven Dialogue Information Augmentation module significantly improved the JGA score of IC-DST on MultiWOZ 2.4, which achieves an impressive 11.55% increase in 1% few-shot setting.\n2) Intent-driven Examples Retrieval: After integrating the Intent-driven Examples Retrieval module and the Intent-driven"}, {"title": "E. Case Study", "content": "As shown in table V, we conducted a case study to evaluate the performance of IDIC-DST and the SOTA method IC-DST in specific dialogue scenarios. The IC-DST method retrieves Bt-1 and dialogue history. However, it encounters difficulties in retrieval when the user's input lacks explicit domain information. In contrast, IDIC-DST not only retrieves It and rewrites the user's input based on it, thereby retrieving more suitable in-context examples, but also provide It as a reference output to the LLM, enabling it to perform well even when the user's input is implicit. This approach effectively guides LLMs to generate correct outputs."}, {"title": "IV. CONCLUSION", "content": "In this paper, we introduce Intent-driven In-context Learning for Few-shot DST (IDIC-DST) to address the challenges posed by implicit dialogue information and data complexity in TOD systems. By extracting user's intent, IDIC-DST enriches dialogue information while effectively masking noisy information, thereby improving the alignment between retrieved in-context examples and the current dialogue context. Experimental results on the MultiWOZ 2.1 and MultiWOZ 2.4 datasets demonstrate that IDIC-DST achieves SOTA performance in few-shot settings, highlighting its effectiveness in enhancing DST accuracy under challenging conditions."}]}