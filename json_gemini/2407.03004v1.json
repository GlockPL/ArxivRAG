{"title": "SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research", "authors": ["Meghal Dani", "Muthu Jeyanthi Prakash", "Zeynep Akata", "Stefanie Liebe"], "abstract": "Large Language Models have shown promising results in their ability to encode general medical knowledge in standard medical question-answering datasets. However, their potential application in clinical practice requires evaluation in domain-specific tasks, where benchmarks are largely missing. In this study semioLLM, we test the ability of state-of-the-art LLMs (GPT-3.5, GPT-4, Mixtral 8x7B, and Qwen-72chat) to leverage their internal knowledge and reasoning for epilepsy diagnosis. Specifically, we obtain likelihood estimates linking unstructured text descriptions of seizures to seizure-generating brain regions, using an annotated clinical database containing 1269 entries. We evaluate the LLM's performance, confidence, reasoning, and citation abilities in comparison to clinical evaluation. Models achieve above-chance classification performance with prompt engineering significantly improving their outcome, with some models achieving close-to-clinical performance and reasoning. However, our analyses also reveal significant pitfalls with several models being overly confident while showing poor performance, as well as exhibiting citation errors and hallucinations. In summary, our work provides the first extensive benchmark comparing current SOTA LLMs in the medical domain of epilepsy and highlights their ability to leverage unstructured texts from patients' medical history to aid diagnostic processes in health care.", "sections": [{"title": "1. Introduction", "content": "Epilepsy is a chronic neurological disorder currently affecting 70 million people worldwide (Thijs et al., 2019). It is characterized by a predisposition of the central nervous system to unpredictably generate seizures. About two thirds of patients suffer from focal epilepsies, which produce distinct seizure-related changes in sensation and behavior depending on the seizure onset zone (SOZ) in the brain (Beniczky et al., 2022; L\u00fcders et al., 2006). Patient reports on seizure symptoms - so-called seizure semiology - are therefore routinely recorded by clinicians and used as one crucial source of information for localization of the SOZ. This is particularly important for patients with drug-resistant epilepsies, for which surgical resection of the SOZ is the only potentially curable therapy option (Wiebe et al., 2001; Sisodiya & Goldstein, 2007). For these patients, the clinicians' task is to determine a confident and accurate estimate of the SOZ, as only then a recommendation for epilepsy surgery can be made.\nThe advent of Large Language Models (LLMs) has sparked interest in their potential to leverage medical knowledge (Singhal et al., 2023; Savage et al., 2024; Sarvari et al., 2024). However, there is a lack of systematic evaluation of LLMs' understanding of specific clinical domains. Addressing this requires large-scale annotated text-datasets, systematic investigation of prompt designs, exploration of in-context learning strategies - all in comparison to problem evaluation technique followed by healthcare professionals in real world. Here, we address several of these questions and show a first comprehensive investigation for benchmarking currently accessible LLMs in the domain of epilepsy. For this task, we leverage a large-scale annotated database Semio2Brain (Alim-Marvasti et al., 2022) linking unstructured text reports of seizure symptoms to seizure onset zones. We highlight the contributions and key insights of this paper as follows:\n\u2022 First, we measure the correctness of the SOZ localization outputs generated by the LLMs. Second, we approximate the confidence in their outputs using entropy. Third, we perform a human evaluation to assess the LLMs' understanding, reasoning, and source retrieval abilities specific to the epilepsy domain."}, {"title": "2. Related Work", "content": "LLMs in medicine: Recent advancements in large language models have led to impressive performances across a variety of tasks such as report summarization (Yu et al., 2023) or question answering (Singhal et al., 2023; Li\u00e9vin et al., 2023; Li et al., 2024; Brown et al., 2020; Bubeck et al., 2023; Achiam et al., 2023). Furthermore, recent advancements in prompting techniques (Brown et al., 2020; Dong et al., 2022; Wei et al., 2022; Wang et al., 2022) have shown promising results in utilizing existing LLMs without any weight updates. This opens up exciting possibilities for leveraging pre-trained LLMs to go beyond question-answering and analyze unstructured text obtained from medical histories to aid the diagnostic process in specific medical domains.\nNLP in epilepsy: The potential of Natural Language Processing (NLP) and LLMs in the field of epilepsy has only very recently been discussed (van Diessen et al., 2024; Bo\u00dfelmann et al., 2023), with only one study investigating basic knowledge on epilepsy in a question-answering scheme and comparing LLMs performance to experienced epileptologists (Kim et al., 2024). In our study, we go beyond this general approach and harvest seizure descriptions obtained from medical histories of epilepsy patients which provide a rich and unique source of information relevant for important diagnostic decisions. Moreover, we are able to test model performance not only against clinicians' performance, but also the ground-truth data obtained from the annotated dataset."}, {"title": "3. Database and data curation", "content": "We utilize the publicly available Semio2Brain (Alim-Marvasti et al., 2022) database, which maps seizure semiologies to brain regions based on a meta-analysis of seizure descriptions from 4,643 patients. Each entry in the database includes a description of a seizure symptom either a behavioral or sensational phenomenon that occurred during a seizure-and which is assigned seven potential major brain regions: temporal lobe, frontal lobe, cingulate gyrus, parietal lobe, occipital lobe, insula, and hypothalamus. The assignment of brain regions to seizure descriptions is based on two types of information:\n1. Post-operative Seizure Freedom: Knowledge about seizure freedom after resection of the brain region.\n2. Seizure Activity: Seizure patterns recorded from intracranial EEG located within the brain region.\nBoth types of information serve as potential ground truths linking seizure semiology to SOZ in clinical practice. For our task, we focused on cases based on post-operative seizure freedom, as this is considered the gold standard for post-hoc evaluation of successfully identifying the SOZ. Finally, we performed several data preprocessing steps, including expanding abbreviations in the semiology descriptions, correcting spelling errors, and removing uninformative words or keywords (for details see supplementary material). This refinement process resulted in a final dataset of 1,269 entries."}, {"title": "4. Methodology", "content": "4.1. Task Formulation\nThe LLM's task is to predict the next probable token T given the input prompt P consisting of persona P, the user query Q, and the instruction format I as shown in Fig. 1. The prediction is based on maximizing the likelihood of the next token. The likelihood function L can be defined as:\n$L(T|P, Q, I) = \\prod_{i=1}^{n} P(T_i|P, Q, I),$\nwhere $P(T_i|P, Q, I)$ is the probability of the token $T_i$ given the persona P, the user query Q, and the instruction format I.\nWe emulate a clinical task exactly how it occurs in practice, where epileptologists evaluate seizure semiologies in order to predict brain regions that are likely involved in producing the seizure symptoms. Importantly, there is no ground truth available for clinicians when making this judgement (as a potential resection has not occurred yet). Thus, for the clinician several brain regions might be possible as potential seizure onset zones, especially if seizure symptoms are complex. Hence, for the SOZ localization task, in the user query, we ask for the percentage likelihood of brain regions given a semiology behavior s. We consider 7 main brain regions(R) in our case such that R={\"Temporal Lobe\", \"Frontal Lobe\", \"Cingulate Gyrus\", \"Parietal Lobe\", \"Occipital Lobe\", \"Insula\", \"Hypothalamus\"}. The instruction for the output is to obtain a dictionary D where each key is a brain region $r \\in R$ and the value is the likelihood $l'(r|s)$ as shown in the equation below:\n$D = {r : l'(r|s)}, r \\in R.$\nWe obtain the clinical reasoning and supporting evidence from the LLM for the likelihood output it generates. Specifically, the LLM is expected to provide a detailed rationale and cite relevant medical literature or sources that it has leveraged to arrive at the predicted likelihoods for the potential SOZs.\n4.2. LLMs\nFor the localization task, we compare the performance of four popular LLMs: GPT-3.5 (specifically \u201cgpt-3.5-turbo-1106\"), GPT-4 (\"gpt-4-turbo-preview\u201d in our case), Mixtral-8x7B Mixture of Experts (MoE) instruct version and Qwen-72B chat model.\n4.3. Prompting Techniques\nThe task we undertake is challenging and requires rigorous prompt engineering to define our final prompt template. As shown in Fig.1, our base prompt template consists of three parts: (i) persona that the LLM should assume i.e. of an expert epileptologist, (ii) user query where we add the semiology we want to inquire about and the exact question, and (iii) the instruction which guides the model to output the response according to the required schema.\nZero-Shot prompting: This structured approach is particularly effective for zero-shot prompting, where the model is expected to perform tasks based solely on its pre-existing knowledge without any specific examples or prior training on the task.\nFew-shot prompting: We carefully curate a handful of examples guided by a clinician, which are added as prompt text in the input context. The key idea of this in-context learning is to demonstrate the input and output structure required to the model without any finetune or weight update (Brown et al., 2020; Dong et al., 2022). The context provided typically have K = 5 examples of queries and answers, and then one user query for which the model is expected to provide the response.\nChain-of-Thought(CoT) prompting: Chain-of-thought prompting is a technique to ask the model to think step-by-step and provide intermediate reasoning and sources used to get to the final answer. This technique mimics a human cognitive process, to break complex problems into small, manageable steps. It is helpful where a straightforward answer may not be trivial (Wei et al., 2022). To do this, we add two more keys to the schema of the base prompt namely, \"Reasoning\" and \"Sources\". We later assess the reasoning for correctness, completeness, and reliability of the sources cited.\""}, {"title": "5. Experiments and Results", "content": "5.1. Correctness Measure\nPerformance is assessed using a multi-class evaluation emulating the fact that the actual ground truth (post-surgical seizure freedom) can only be true for 1 of the 7 brain regions. The predicted SOZ is determined by selecting the class with the highest likelihood values. In certain cases when model assigns equal high probabilities to more than one brain region, we resolve the tie with a simple deterministic approach np.argmax(). Using these labels and the ground truth labels, we compute precision, recall, and F1 score for each class.To account for potential class imbalances, we calculate the weighted average precision, recall, and F1 score across all classes. The weighting is based on the support (number of instances) for each class. This approach ensures that classes with more instances contribute proportionally to the overall metric, mitigating the impact of class imbalance. To estimate a lower bound performance expected by chance, we compute the minimum precision and recall. We take the ratio of positive instances (class support) to the total number of instances (total support), assuming a naive baseline classifier that predicts all instances as positive. Using the support values, the weighted precision, recall, and F1 score for this naive baseline is 39.34%. (see Supplement for full calculation). Finally, we asked a clinician to provide their input, similar to how we query the LLMs, and compute the F1 score, which is 49.07%.\nTo estimate the variability and uncertainty associated with the F1 scores, we perform bootstrapping (Tibshirani & Efron, 1993), a resampling technique that provides robust estimates of the metric's distribution. Specifically, we resample 10% of the full dataset 999 times, and calculate the F1 score for each sub-sample. We report the mean and standard deviation for each model in the supplementary material. Similarly, we subsample the responses of the clinician in order to obtain variance estimate as shown in Fig. 2(B).\nWe report our localization results in Tab.1. For zero-shot prompting, only GPT4 shows significantly higher performance than the lower bound. With better prompting techniques, however, all models achieve substantially higher, and significantly better performance than expected by chance and is even comparable to clinical evaluation (see Fig. 2 (A)). For almost all prompting styles GPT-4.0 outperforms the other models and achieves the highest F1 score of 53.78% using the self-consistency prompt-style. For few-shot CoT Mixtral-8x7B shows the best performance with an F1 score of 52.72%. Importantly, the models' performance is competitive with the clinician's response. Since there is no benchmark to compare our results with, we further assess the significance of our model's F1 scores using a permu-"}, {"title": "5.2. Confidence measure / Uncertainty Estimate", "content": "The likelihood output from the LLMs is more informative than a single class prediction, as it allows for understanding which classes the model considers plausible, and to what degree, rather than just which class it considers the \"winner\". We leverage this feature to approximate a confidence/uncertainty measure. Specifically, we employ Shannon entropy for this purpose, which is a fundamental concept in information theory that quantifies the \u201cfuzziness\u201d or uncertainty of a system's state. Given a discrete random variable X with possible outcomes $X_1, X_2, ...., X_n$, each with probability $P(x_i)$, the Shannon entropy H(X) is defined as:\n$H(X) = - \\sum_{i=1}^{n} P(x_i) log_2 P(x_i)$\nThe minimum entropy value is 0, which occurs when the model assigns a likelihood of 100% to one brain region and 0% to all others. The maximum entropy value is achieved when the model assigns equal likelihood to all seven brain regions, i.e. = * 100 = 14.28. We normalize the H(X), which effectively \"calibrate\" the metric, enabling a fair assessment of the relative gain achieved by each model in comparison. We eventually report the loss entropy, defined as 1 - normalized entropy. If loss entropy trends towards 1, it means that the model is confident or less uncertain and vice versa if it shows a tendency towards 0."}, {"title": "5.3. Clinical Evaluation", "content": "In a rigorous clinical evaluation, we validate the reasoning, completeness, and source citation accuracy of our best-performing language models, GPT-4 and Mixtral8x7B. The clinician (disclosure: one author of this paper) specializes in epileptology and is presented with the models' responses to a diverse set of fifty eight queries. The task is to assess the correctness and completeness of the provided reasoning on a three-point scale (absolutely correct/complete, somewhat correct/complete, and not correct/complete) as shown in Fig. 6. Additionally, two authors of the paper verify whether the sources cited by the models are correct or not. We only consider the source to be accurate if the author list, and exact title match verbatim.\nGPT-4 cited sources correctly for 83.33% of the queries presented, while Mixtral8x7B achieves an average accuracy of 18.33% as the latter hallucinates its sources by combining authors and titles from multiple research works. We also computed Cohen's kappa to assess the consensus between the two evaluators. As shown in Fig. 4, for GPT-4 and Mixtral8x7B kappa values are 0.88 and 0.78 respectively. We also note that GPT-4 comes up with correct and complete reasoning for 55.15% and 63.79% of the examples respectively while Mixtral8x7B is somewhat correct for 44.82% of cases or complete in its reasoning for 36.20% of the examples given as query (Refer Fig. 5)."}, {"title": "6. Conclusion", "content": "Our study provides the first investigation of whether current SOTA LLMs leverage their internal knowledge for epilepsy diagnosis. Specifically, we focus on a human-centric approach by emulating a characteristic use case in clinical practice, where clinicians evaluate the relationship between seizure symptoms and the likely underlying seizure onset zone. Importantly, we utilize a large-scale ground-truth annotated dataset and provide a first benchmark in this domain. We could show, that foundation large language models are able to correctly identify the Seizure Onset Zone (SOZ) significantly above chance from unstructured text descriptions of seizure behavior. Importantly, prompt engineering leads to substantial improvements in performance, achieving close to clinical performance in some models. We further provide a method to approximate uncertainty from the models' response distributions, which can be used to evaluate their confidence. This is important as models are required to perform correctly - and be confident about it. Overall our results suggest, that models achieve the highest performance and certainty using the self-consistency prompting technique. Comparing models, GPT-4 and Mixtral8x7B perform best, while being more grounded in their responses. GPT3.5 and Qwen 72, however, are more confident in their responses despite not fairing well in performance, which is not desirable. Lastly, we also asked the clinicians to rate the reasoning and assessed citations from these models. In source citation, both evaluators had a high consensus in responses with an agreement that Mixtral8x7B show hallucination tendencies and gives only partially correct and incomplete reasonings in the majority of the cases.\nIn summary, our analyses provide evidence for the potential applicability of LLMs outside of the vastly used use case of standard medical QA datsets. In the domain of epilepsy, we show their potential contribution to improving the efficiency of diagnostic processes and treatment planning. Our approach can be extended to other domains, where unstructured text in medical history provides medical diagnostic information that can be verified using ground-truth datasets. Overall, our work contributes to the ongoing development and refinement of reliable and trustworthy language models for domain-specific applications, facilitating a comprehensive understanding of the models' performance and their potential for real-world use cases in the medical domain."}, {"title": "D. User Study and Reasoning Output", "content": "We introduce clinicians in the benchmarking pipeline using two online surveys. In the first survey, we ask clinicians to assign likelihood values for SOZ being localized to the 7 brain regions for 58 semiologies chosen from diverse semiological categories. The form consists of the semiology and sliders next to the seven brain regions for clinicians to choose from a continuous range (0-100%) of likelihood values (Fig). This layout ensures similarity with the model's output format. We utilize a threshold (50%) to obtain the clinician's prediction of SOZ for comparison with the ground truth. We assess the relative performance of clinicians and models providing insights about the reliability of using these models in a clinical setting. A major advantage of LLMs is their capacity to generate reasoning that leads to seizure foci predictions. We ask clinicians to evaluate the reasoning generated by the models in the second survey. The form consists of the semiology, reasoning and likelihood values from the best-performing models (GPT-4 and Mixtral8x7B), along with questions to score correctness and completeness across three levels (Fig. 6). This enables us to effectively quantify the utility of long-form reasoning generated by models in epilepsy diagnosis.\nOn the next page, in Tab. 7 we show snippets of the output obtained from GPT-4 model for few-shot CoT prompt strategy on two semiologies. Each output contains three results including 'Reasoning', 'Likelihood' and 'Source(s)'."}, {"title": "1. Semiology:", "content": "he had hypertony of all four limbs\nReasoning:\nThe symptom described as \"hypertony of all four limbs\" refers to increased muscle tone affecting the arms and legs. This increased muscle tone, or hypertonia, can be a feature of seizures originating in several different brain regions. However, the fact that all four limbs are involved suggests a more generalized seizure activity or a seizure onset that quickly involves bilateral motor pathways. The frontal lobe is a common site for seizures that result in tonic or clonic movements, as it contains the primary motor cortex which controls voluntary muscle movements. Seizures originating in the frontal lobe can lead to bilateral tonic posturing due to the spread of seizure activity through motor pathways. While other regions like the parietal lobe can be involved in sensory aspects of seizures, the motor manifestations such as hypertonia are more typically associated with frontal lobe seizures. Given the lack of specificity in the symptom description, the likelihood percentages are estimates based on common seizure semiologies associated with these regions.\nLikelihood values:\nTL: 0% FL:80% Cing:10% PL:5% OL:0% Insula: 5% Hyp: 0%\nSource(s):\nTatum, W. O. (2012). Ellen R. Grass Lecture: Extraordinary EEG. Neurodiagnostic Journal, 52(4), 333-353. doi: 10.1080/21646821.2012.11079899"}, {"title": "2. Semiology:", "content": "visuospatial manifestation: the patient reported her impairment as being able to know \u201cintellectually and visually\" when a person or object is near, but sensing otherwise. She said this created a tension between her sensation and cognition. She further detailed a gap in her left visual field that was \"constantly opening up\", forcing her to rationalize her position in space rather than rely on sensory input. Although uncertain for a while, the patient grew assured in the fact that this was not a visual issue because even with her eyes closed, she would struggle to locate her place in a room.\nReasoning:\nThe patient's description indicates a complex visuospatial impairment that involves both visual processing and spatial awareness. The ability to know intellectually and visuallysuggests that the patient's primary visual processing (i.e., the ability to see and recognize objects and people) is intact, but there is a disconnect with the spatial perception and sensation of proximity. The gap in her left visual fieldsuggests a problem with the right visual field representation, which is processed by the occipital lobe, particularly the right side, given the contralateral nature of visual field representation in the brain. The fact that the patient experiences difficulty in locating her position in space even with her eyes closed points towards a deficit in spatial awareness and proprioception, which is often associated with the parietal lobe, particularly the right parietal lobe for spatial attention and representation. The tension between sensation and cognition and the need to rationalize position in space may also implicate the involvement of the posterior parietal cortex, which integrates sensory information and is involved in spatial cognition and navigation. Given the bilateral nature of the symptoms and the involvement of spatial awareness, it is likely that the seizure onset zone could be in the right parietal lobe or at the junction of the parietal and occipital lobes, possibly affecting the right hemisphere more due to the left visual field deficit described.\nLikelihood values:\nTL: 0% FL:0% Cing:0% PL:70% OL:30% Insula: 0% Hyp: 0%\nSource(s):\nKolb, B., & Whishaw, I. Q. (1990). Fundamentals of human neuropsychology (3rd ed.). New York: W.H. Freeman and Company"}]}