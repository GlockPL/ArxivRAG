{"title": "Transfer Learning with Active Sampling for Rapid Training and Calibration in BCI-P300 Across Health States and Multi-centre Data", "authors": ["Christian Flores", "Marcelo Contreras", "Ichiro Macedo", "Javier Andreu-Perez"], "abstract": "Machine learning and deep learning advance- ments have boosted Brain-Computer Interface (BCI) per- formance, but their wide-scale applicability is limited due to factors like individual health, hardware variations, and cultural differences affecting neural data. Studies often fo- cus on uniform single-site experiments in uniform settings, leading to high performance that may not translate well to real-world diversity. Deep learning models aim to enhance BCI classification accuracy, and transfer learning has been suggested to adapt models to individual neural patterns using a base model trained on others' data. This approach promises better generalizability and reduced overfitting, yet challenges remain in handling diverse and imbalanced datasets from different equipment, subjects, multiple cen- tres in different countries, and both healthy and patient populations for effective model transfer and tuning. In a setting characterized by maximal heterogeneity, we proposed P300 wave detection in BCIs employing a convo- lutional neural network fitted with adaptive transfer learning based on Poison Sampling Disk (PDS) called Active Sam- pling (AS), which flexibly adjusts the transition from source data to the target domain. Our results reported for subject adaptive with 40% of adaptive fine-tuning that the averaged classification accuracy improved by 5.36% and standard deviation reduced by 12.22% using two distinct, interna- tionally replicated datasets. These results outperformed in classification accuracy, computational time, and training efficiency, mainly due to the proposed Active Sampling (AS) method for transfer learning.", "sections": [{"title": "I. INTRODUCTION", "content": "Brain-Computer Interface (BCI) decodes brain signals for communication between a human and their environ- ment [1]. EEG signals are preferred for being non-invasive and capable of recording specific brain activities like motor or mental tasks, thereby extracting important information [1]. They offer a balanced spatio-temporal resolution through a high-density electrode system, improving BCI performance [1]. The P300 BCI paradigm produces a P300 wave in EEG signals via the oddball method. This wave, an event-related potential (ERP), reacts to visual or auditory stimuli [1]. Deep Learning (DL) has been effective in the classifica- tion stage of BCIs, especially through Convolutional Neural Networks (CNNs) and their variants, due to their proficiency in extracting spatial and temporal features from EEG signals. For example, Yang et al. [2] achieved 86.41% accuracy in classifying the BCI Competition IV dataset using a multi- layer CNN. Vega et al. [3] developed EEG-TCFNet, com- bining EEGNet with temporal convolution layers and fuzzy blocks, reaching up to 98.6% accuracy for subject-dependent P300 wave classification. However, DL models require large, homogeneously distributed datasets for reliable accuracy and generalization, which is challenging given the laborious nature of EEG experiments. To address this, some studies have implemented under-sampling methods to balance datasets, enhancing classification accuracy [4], [5]. Transfer Learning (TL) schemes in DL models address data variations from different subjects, sessions, and devices, enhancing performance. TL involves pre-training DL networks on large datasets to create generalized models with high performance on new data [6]-[9]. For example, models like Residual Neural Network (ResNet) and VGG16 pre-trained on the ImageNet dataset have been used for mental task signal classification, reaching accuracies up to 86.85 The fine-tuning aspect of Transfer Learning from source to target domains presents challenges, including the risk of negative transfer, which is difficult to manage. This process necessitates a judicious selection to prevent irrelevant source data from affecting the target domain mapping. Adaptive Transfer Learning (ATL), as proposed in [10], addresses this by adaptively sampling the target domain for mapping. While ATL mitigates inter-subject variability and manages unbal- anced datasets, it incurs high computational costs and struggles with intra-subject variability. Optimizing Stochastic Gradient Descent (SGD) parameters is key to enhancing classification accuracy and convergence speed, primarily by reducing Stochastic Gradient Noise (SGN) for quicker convergence and larger learning rates. As noted in"}, {"title": "II. RELATED WORK", "content": "This section reviews studies relevant to our proposal. Pan et al. [12] proposed transfer learning to address the issue of learning with insufficient labeled data, primarily by leveraging knowledge from related domains. A sampling strategy based on distribution difference is developed to select the most valuable instances for label querying. Liu et al. [13] employed transfer learning and active sampling methods to tackle im- balanced data in classification. The proposed transfer learning model comprises three modules such: an active sampling mod- ule, a real-time data augmentation module, and a DenseNet module. Some studies focus on how Stochastic Gradient Noise (SGN) acts as a regularizer in deep learning and its role in improving generalization through Stochastic Gradient Descent (SGD) [14]. Key studies by Kulezka and Taskar [15]-[17] explore Determinantal Point Processes (DPP) in subset selec- tion for data diversification in machine learning applications. Zhdanov [18] proposed an algorithm for creating diverse mini-batches, emphasizing informativeness and sample spacing, and incorporating k-means for scalability. Additionally, Point Processes (PP), like DPP or Repulsive Point Processes (RPP), are used for uncorrelated feature sampling in mini-batches, enhancing accuracy and convergence speed [19], [20]. Zhang et al. [19] utilized DPP to lower the variance in SGD. They ap- plied a non-uniform DPP-based sampling method to eliminate redundant data in mini-batches, demonstrating faster DPP- SGD convergence compared to the standard SGD on CIFAR- 10 and Oxford-102 datasets. Similarly, Zhang et al. [20] pro- posed using an RPP, specifically Poison Disk Sampling (PDS), for mini-batch sampling to simplify the RPP's complexity. Their studies compared SGD baseline, DPP-SGD, and PDS- SGD, revealing a significant reduction in convergence time with PDS across various tests. As discussed, although several studies have approaches to classify the target action based on the P300 BCI, some issues need to improve: Reduce the calibration time of BCI operation to operate in real-life conditions. Improve the model decoding capabilities to enhance classification accuracy, reducing the computational costs during the calibration stage. These issues are notable hurdles to face, especially in scenarios where the diversity of electrophysiological signals across different individuals, experiments conducted at var- ied locations, and utilizing diverse materials. Thus, Active Sampling (AS) paves the way for better Adaptive Transfer Learning (ATL) performance to expedite the calibration time of BCI operation for new subjects, which is appropriate for implementing BCIs in real-world scenarios. The proposed method resulted in enhancements for both subject-dependent and subject-independent settings, covering both healthy indi- viduals and patients, and was applied across two experimental datasets."}, {"title": "III. BACKGROUND", "content": "This section summarizes the state-of-the-art of RPP and PDS as the chosen sampling method. In addition, we also de-lineated that RPP may reduce the variance of SGD. Therefore, in the present work, we included RPP to sample the data from P300 signals to reduce the calibration Process in P300 BCI."}, {"title": "A. Repulsive Point Processes (RPP)", "content": "In this section, we provide a formal definition of the RPP. Considering a point process P in Rd and the nth order product density o(n) is defined by:\n$p(x_1,...,x_n) = \u03c1^{(n)} (x_1, x_2, ...., x_n)dx_1....dx_n$ (1)\nwhere $p(x_1,...., x_n)$ is the joint probability of having a point of the Point Process P in each of the infinitesimal spheres B. For our analysis, we define the first 2 and second 3 order product density, which are commonly denoted by:\n$\u03bb(x) := \u03c1^{(1)}(x)$ (2)\n$\u03c1(x, y) := \u03c1^{(2)} (x, y)$ (3)\nFurthermore, to denote the gradient of the loss function, it can be expressed as g(x, 0) = \u221a(x, 0) and k = |B|, the mini-batch size. After mentioning the previous definition, we can define:"}, {"title": "Theorem 1.", "content": "The variance of the gradient varp(\u011c) estimate (G) in SGD for a general stochastic point process P is given by:\n$var_p(G) = \\frac{1}{k^2}  \\frac{\u03c1(x, y)}{\u03bb(x)\u03bb(y)} g(x, \u03b8)^T g(y, \u03b8)] dxdy$\n$+ \\frac{1}{k^2} \\frac{\u03c1(x, y)}{\u03bb(x)\u03bb(y)} \\int||g(x,\u03b8)||^2 \u03bb(x)dx$ (4)\nThereby, the RPP can make the first term in Eq. 4 negative and reduce the variance.\nProof: For repulsive point processes, the probability of sampling points that are close to each other is low. Hence, if x and y are close, then correlations $\\frac{\u03c1(x,y)}{\u03bb(x)\u03bb(y)}$ tend to zero, and as -1, negative. Furthermore, supposing that the loss function is sufficiently smooth in its data argument, the gradients are aligned for close points, i.e., $g(x, 0)^T, g(y, 0)$. Thus, close points provide a negative contribution to the first integral in Eq. 4, so the negative first term in this equation drives the process to variance reduction."}, {"title": "B. Poison Disk Sampling (PDS)", "content": "PDS is one type of RPP that reported stronger local repul- sion than DPP. A dart-throwing algorithm is used to implement a PDS and provides equivalent point arrangements to DPP but much more efficiently. [21]. This algorithm states that the smallest distance between each pair of sample points should be at least to the predefined distance (r). Thus, when the distance between two points is smaller than the disk radius ||xy|| \u2264 r, the second order product density p(x, y) for PDS is zero, and when the two points are far, the second order product density converges to p(x,y) = x(x)\u03bb(y). Moreover, the complexity of PDS is O(k\u00b2), much lower than DPP complexity O(Nk\u00b3) where N is the total amount of points. Additionally, its simple procedure allowed the proposal of numerous PDS variants and spread the sampling even more."}, {"title": "IV. METHODOLOGY", "content": "In this section, we detail EEG signal preprocessing and data sampling using PDS. We then describe the process of training a Deep4Net network for three scenarios: subject-dependent (SD), subject-independent (SI), and subject-adaptive (SA), applying ATL to the pre-trained model. This methodology was replicated in two different countries using distinct equipment but maintaining the same paradigm."}, {"title": "A. Datasets", "content": "We employed two datasets: the public 'Original Experimen- tal benchmark dataset clinical P300 dataset' (OE) and our own 'Multi-centre benchmark clinical P300 dataset' (ME), created in our lab. ME replicates OE's P300 recording protocol but differs in device use, subjects, patients, and locations. Detailed descriptions of each dataset will follow in subsequent subsections."}, {"title": "B. Data pre-processing", "content": "In order to eliminate artifacts and obtain a higher number of samples, the two datasets were preprocessed. As both followed the same steps, only one kind of preprocessing task was designed:"}, {"title": "C. Dense Poison Disk Sampling for Active Sampling", "content": "When dealing with highly structured data, there may be only a few data points near the decision boundary that are difficult to classify, such as waves labeled P300 and non-P300. To tackle this issue, we use one PDS variation, namely Dense PDS, which draws darts based on mingling indices instead of random selection. This allows us to specify a categorical distribution called \u03c0 to refine the decision boundary. The mingling index measures the ratio of points belonging to different class labels. For further information on the mingling index, see [20]."}, {"title": "D. Deep Network Architecture", "content": "We utilised Deep4Net CNN architecture as base architecture [24]. The accuracy classification and Cross entropy loss value were performed using AdamW optimizer, Batch Normaliza- tion, and Dropout. The training parameters comprehend a batch size of 16 samples, performing the stage for 200 epochs."}, {"title": "E. Classification scheme for Active Sampling", "content": "In this section, we perform the effect of Active Sampling (AS) on the two datasets in different classification schemes, such as the subject-dependent, independent, and adaptive clas- sification, using a Deep4Net [24]. The data for each subject is composed of four sessions; thus, we sampled each subject for both datasets using a Dense PDS described in the previous item."}, {"title": "V. RESULTS", "content": "We evaluated Active Sampling (AS) with Dense PDS on Deep4Net, aiming to reduce computational cost while main- taining or improving classification accuracy. Our deep neural network, trained and tested in Google Colab using Python, underwent a cross-validation process. We experimented with different Sampling Factor (SF) sizes to find the most effective one. This evaluation included cross-validation with distinct training, validation, and testing phases across three subject strategies: dependent, independent, and adaptive. In the adap- tive approach, we varied the percentages of data split from the target subject for model fine-tuning, seeking the optimal value for comparison."}, {"title": "A. Samples number selection (Sampling Factor)", "content": "To determine the best sample number, we use Active Sampling with the Dense PDS to calculate the best classifi- cation accuracy for subject-independent, varying the sampling number from 500 to 1200. We summarize the process for both datasets using a Dense PDS:\n 1) Calculate a subject-independent classification using a Leave- One-Subject-Out Cross-Validation (LOSOCV) for all subjects and both datasets (OE and ME) using different sample sizes.\n 2) The sample size increased from 500 to 1200 in steps of 100 and studied their performance improvements.\n 3) The best subject-independent classification accuracy test and its corresponding sample size were chosen.\n 4) Create a histogram to perform the distribution of the best sample size."}, {"title": "B. Sampling Factor effect over dataset", "content": "To create a comprehensive visualization comparison of the performance of Active Sampling (AS) using a Dense PDS over the data from each subject and dataset, we performed a t-distributed stochastic neighbour embedding (t-SNE) plot. The input data are all P300 and non-P300 samples after being pre-processed according to IV-B (P300-pre-processing). The aim is to compare the impact on the data before and after performing Active Sampling (AS). Thus, the experimental results are presented in Fig. 7, where subject 01 was chosen for complete visualization of the AS effect. More results can be found in Section S.I of the supplementary material. Hence, the first row of Fig 7 depicts the t-SNE of samples before applying AS, and the second shows a t-SNE of samples after using AS. Furthermore, orange and blue dots represent the P300 and non-P300 samples, respectively. For all figures, the Active Sampling (AS) demonstrated data reduction in 1200 samples, increasing the sampling diversity, thus eliminating redundant data for better Stochastic Gradient Descent (SGD) convergence and classification accuracy. For instance, subject 01, after applying Active Sampling (AS), demonstrated a profound reduction of non-P300 samples due to their high number and the decrease of P300 samples. It leads to maintaining the data structure and precise decision boundary."}, {"title": "C. Classification Accuracy from OE", "content": "This section summarizes the classification accuracy results for the OE experimental scheme, both with and without Active Sampling (AS). Tables IV and V present the average classification accuracies for all 8 subjects using OE w/o AS and OE w/ AS, respectively. Our findings indicate that OE w/ AS consistently surpasses OE w/o AS in subject-dependent, subject-independent, and subject-adaptive classifications, also"}, {"title": "D. Classification Accuracy from OE and M\u0395", "content": "This section showcases the classification accuracy outcomes from the experimental approach that combines data from the Original Experiment (OE) and the Multi-centre Experiment (ME). It highlights how Active Sampling (AS) excels in scaling both accuracy and training duration when handling two different datasets. Tables VI and VII tabulate the average classification accuracy to compare the performances across all 17 subjects using OE+ME w/o AS and OE+ME w/ AS, respectively. Our results reported that the average classification accuracy of OE+ME w/ AS outperformed OE+ME w/o AS for subject-independent and subject-adaptive except for subject- dependent. Therefore, subject-adaptive reduced the standard deviation after applying the AS for all adaptation rates. Our results reported that the average classification accuracy for a subject adaptive with 40% of the adaptation rate in OE+ME w/o AS outperformed OE+ME w/AS with 5.36% and a standard deviation reduction of 12.22%.\nWe created Figure 8 to display classification accuracy and variance among subjects for three classification schemes with and without AS. The OE +ME w/ AS results reported a lower standard deviation for subject-adaptive for all adaptation rates compared to OE+ME w/o AS using less computational time. The classification accuracy tendency for subject-adaptive in OE+ME w/o AS starts at 80.71% for 10% of the adaptation rate, decreasing until 78,13% for 40% of the adaptation rate after that, it reported a high pick value at 81,97% for 50%."}, {"title": "E. Computation time", "content": "Reducing samples with Active Sampling (AS) aims to sig- nificantly cut the CPU training time (in seconds) for Deep4net. Table VIII demonstrates this reduction by comparing average CPU training times with and without AS, using 1200 samples across both datasets (OE and IE). With AS, the average CPU time was 22896.44\u00b11292.02 s (Avg. \u00b1 SD), while without AS, it averaged 8889.75 \u00b1 419.14 s (Avg. \u00b1 SD), resulting in a substantial 61.17% reduction. Notably, the average CPU time did not follow a normal distribution. A nonparametric Wilcoxon signed-rank test was conducted to analyze the me- dian differences between w/o AS and w/ AS, yielding highly significant p-values (p < 0.01), specifically 1.526 \u00d7 10\u22125. Subject 14 achieved the minimum CPU training time without AS, while subject 8 had the best reduction, with a remarkable 64.46% reduction in CPU training time (in seconds) with AS."}, {"title": "F. Bitrates Analysis", "content": "In Fig. 12a, averaged classification accuracy and their corresponding bitrates are plotted against the time needed for the number of blocks to make a decision. To demonstrate the feasibility of Active Sampling (AS), we select subject 10, corresponding to the experimental scheme of OE+ME. If bitrate is used as a performance measure, differences between OE+ME w/ AS and OE+ME w/o AS can be observed. For instance, OE+ME w/ AS outperformed OE+ME w/o AS for the bitrate from the first block, where w/ AS reported roughly 80 bits/min. As we can see, there is a close link to maximum bitrate and high classification accuracy for small numbers of blocks."}, {"title": "VI. DISCUSSION", "content": "A key challenge in Brain-Computer Interface (BCI) research is achieving high classification accuracy with minimal calibra- tion data while ensuring maximum generalizability. Transfer learning has been a common approach to address this, but fine-tuning often leads to over-fitting of the target class and irrelevant feature emphasis, even if the original model is highly robust. The variability of EEG data across individuals and experiments further complicates this. Our study, unique in its multi-subject, multi-country, and multi-hardware scope, introduces a novel adaptation transfer method. A novel method of adaptation transfer called ATL using Active Sampling (AS), based on Dense PDS is proposed and evaluated in such a scenario. Despite the data diversity, our deep learning model showed enhanced classification accuracy and reduced CPU training time. As detailed in Section V, our approach and active sampling method achieved 85.22% accuracy in subject-independent, heterogeneous conditions, surpassing other meth- ods in real-world scenarios and demonstrating faster training times.\nThe stability of dense PDS was confirmed by conducting multiple repetitions of training and testing the model in Adaptive Transfer Learning (ATL) for subject-independent classification using the experimental scheme from OE+ME.  Therefore, to compare the performance of Dense PDS, we included additional Active Sampling (AS) techniques based on Vanilla PDS, Easy PDS, and Anneal PDS [20] in Adaptive Transfer Learning (ATL) methods using the raw data of each subject for subject-independent classification using the experimental scheme from OE+ME. The results show that PDS Dense is the best choice, achieving the highest classification accuracy. Furthermore, to compare the performance of Adaptive Transfer Learning (ATL) using Deep4Net, over the OE+ME with AS for subject-independent classification, we applied Instance-based Transfer Learning (ITL) using Weighted k-Nearest Neighbors (Weighted K-NN). The results demonstrate that the mean classification accuracy of Deep4Net outperformed Weighted K-NN, showcasing its superiority. Thus, this work offers new insights into achieving optimal generalization in P300-BCI systems."}, {"title": "VII. CONCLUSION", "content": "This study introduces an adaptive transfer methodology with sampling selection for P300-BCI, showing notable per- formance in subject-independent and multi-centre contexts. The methodology leverages a diverse dataset from various countries, times, and hardware, enhancing P300 detection robustness and minimizing overfitting. Notably, it significantly reduces training time, enabling quick BCI-P300 system cali- bration and reactivation within a minute. These findings ad- vance the generalizability of non-invasive P300 BCI systems. Future applications of these techniques to other BCI paradigms are planned, with the possibility of integrating adaptive trans- fer learning with generative models for improved accuracy. This later methodology, however, requires further meticulous exploration. In the future, we plan to explore integrations of this transfer methodology in other machine learning and deep learning techniques [26]-[31]."}]}