{"title": "Federated Learning for Data Market: Shapley-UCB for Seller Selection and Incentives", "authors": ["Kongyang Chen", "Zeming Xu"], "abstract": "In recent years, research on the data trading market has been continuously deepened. In the transaction process, there is an information asymmetry process between agents and sellers. For sellers, direct data delivery faces the risk of privacy leakage. At the same time, sellers are not willing to provide data. A reasonable compensation method is needed to encourage sellers to provide data resources. For agents, the quality of data provided by sellers needs to be examined and evaluated. Otherwise, agents may consume too much cost and resources by recruiting sellers with poor data quality. Therefore, it is necessary to build a complete delivery process for the interaction between sellers and agents in the trading market so that the needs of sellers and agents can be met. The federated learning architecture is widely used in the data market due to its good privacy protection. Therefore, in this work, in response to the above challenges, we propose a transaction framework based on the federated learning architecture, and design a seller selection algorithm and incentive compensation mechanism. Specifically, we use gradient similarity and Shapley algorithm to fairly and accurately evaluate the contribution of sellers, and use the modified UCB algorithm to select sellers. After the training, fair compensation is made according to the seller's participation in the training. In view of the above work, we designed reasonable experiments for demonstration and obtained results, proving the rationality and effectiveness of the framework.", "sections": [{"title": "1 INTRODUCTION", "content": ""}, {"title": "1.1 Background", "content": "In the classic federated learning architecture [1], the local client provides data for model training. After each round of global training, the client sends the model to the central server for model aggregation. The central server does not need to collect data, only a subset of clients are randomly sampled in each global training, so federated learning has good data privacy. In this assumption, the central server does not need to care about whether there are clients willing to provide data for training, nor does it need to participate in client selection and consider the client's training costs and returns. However, this is not practical in real situations, especially in the transaction market, the willingness of sellers to provide data largely depends on the degree of compensation that agents provide to sellers. In recent years, federated learning has received widespread attention due to its performance and better privacy. In federated learning scenarios, the problem of how agents recruit high-quality sellers to participate in task training and provide reasonable compensation has not been effectively solved. Under normal circumstances, it is difficult to collect data directly. The federated learning architecture can avoid directly obtaining data for model training, and use the model parameters obtained from local data training to up- load and update to obtain the final model. In this process, re- cruiting sellers is an information asymmetric process. First, the seller's data quality is invisible to the agent. Feedback can only be provided through the accuracy of the model and the corresponding evaluation algorithm during the training process. If a batch of data is recruited, Sellers with poor quality will lead to poor quality of the final model, which is not conducive to agents delivering models, and will also cause excessive consumption of training time and training resources. Second, even if there are high-quality sellers willing to provide data, how to select sellers is a complicated process. Due to the lag in the contribution eval- uation method, it is difficult for agents to accurately identify high-quality sellers at the beginning of training. Third, the rewards brought by the data provided by the seller are not reasonable. Essentially, after the training, the agent cannot make a reasonable evaluation based on the seller's contri- bution and provide reasonable compensation based on the contribution, resulting in the inability to motivate the seller to provide data resources., which is not conducive to the development of the data trading market environment. For one thing, it is important to design a reasonable contribution evaluation method. Many studies have provided methods to evaluate the value of data. For example, Song et al. [2] used the gradient generated by the client's local training of the temporary global model to reconstruct the new model, so as to calculate the shapley value of the client, effectively reducing the computing overhead. Jiang et al. [3] proposed to estimate the contribution of clients in gradient and data space. Specifically, they suggested the difference in gradient direction between clients in gradient space, and the use of auxiliary models to measure the prediction error of client data in data space. Regarding the second one, seller selec- tion is an information asymmetric process. The reason is that there is a lag in the seller's contribution assessment during the training process. As a result, the agent cannot estimate the contribution probability of each seller in ad-"}, {"title": "1.2 Contribution", "content": "In this paper, we focus on solving the above existing problems. We use existing research to design a reasonable contribution evaluation method, model seller selection as a MAB problem, redesign the reward function, and design a reasonable compensation function. Achieve reasonable com- pensation based on contribution. The main contributions of this work are as follows:\n1) We propose to evaluate the training value of the model based on gradient similarity and Shapley value, combine the two to form the contribution evaluation value of each round, and design it as an aggregate parameter weight.\n2) According to the unpredictability of the seller's performance during the training process, the seller selection problem is modeled as a MAB problem, and the ucb algorithm is used to use the contribu- tion value as an indicator to redesign the reward function and update the selection probability based on the seller's historical performance.\n3) Design a reasonable contribution aggregation func- tion to aggregate the seller's training process con- tribution and local data distribution, and derive a reasonable compensation value based on budget constraints, ensuring that agents pay low costs and sellers receive high returns under this strategy."}, {"title": "2 PRELIMINARY KNOWLEDGE", "content": "This chapter will introduce the work related to the research content of this work. Since this work is based on the federated learning architecture, it attempts to solve the demand problem between sellers and agents in the data trading market. Therefore, research on client contribu- tion, client selection and incentive mechanisms in federated learning is relevant to this work, so this chapter will give a general introduction to the research in these aspects."}, {"title": "2.1 Client Contribution Assessment", "content": "Client contribution evaluation research aims to provide client selection metrics for client selection and incentive mechanism design. In machine learning, the measurement method based on the Shapley value [8] is often used to evaluate the performance of the data pair model, based on the Shapley value The concept of Intermediate results are recorded and no additional model training is involved. Zhao et al. [9] use the similarity between the local local model and the global aggregate model to measure the degree of contribution, assuming that the local model with greater contribution is more similar to the global model. Chen et al. [10] measure the client's contribution by calculating the cross-entropy between each local model and the global aggregate model. In addition, Lyu et al. [11] designed a reputation-based contribution evaluation method for fair- ness issues. The agent will iteratively update the reputation of each client based on the reputation value calculated in each round and its historical reputation."}, {"title": "2.2 Client Selection", "content": "Research on client selection focuses on designing rea- sonable and efficient selection algorithms to select high- quality clients, usually accompanied by evaluation of clients for screening. Ma et al. [4] introduced a group-based client selection mechanism, dividing clients into different groups based on the group bulldozer distance (GEMD) as a metric to balance the local label distribution of the client. A smaller GEMD value means The client's local data is closer to the IID distribution. Ami et al. [5] modeled the client selection problem as a multi-armed bandit (MAB) problem based on the client's training delay as an indicator to minimize the training delay. Zhang et al. [12] proposed a selection method based on reputation and reverse auction theory. After the agent releases the task, the client with good data quality is selected through the client's bidding and reputation. Hu et al. [13] used game theory to model the utility maximization problem of servers and clients in federated learning as a two-stage Stackelberg game. This scheme derives the opti- mal strategies of servers and users by solving Stackelberg equilibrium, thereby selecting the most beneficial Clients"}, {"title": "2.3 Incentive Mechanism", "content": "The compensation design of the incentive mechanism usually chooses to compensate clients participating in train- ing based on the revenue distribution method. Different revenue distribution methods are conducive to motivating participants with high-quality data to continue to partic- ipate in federated learning. [15] proposed a hierarchical incentive mechanism that uses contract theory to establish an incentive mechanism between clients and agents. Zeng et al. [16] proposed an incentive mechanism based on a multi- dimensional procurement auction framework, using game theory to derive the client's optimal strategy, thereby mo- tivating more low-cost, high-quality clients to participate. Rehman et al. [17] proposed a reputation system based on blockchain, which aggregates, calculates and records the reputation of each participant in federated learning through smart contracts, and motivates participants to pro- duce honest and high-quality behaviors under reputation awareness. thereby promoting the healthy development of the federated learning process. In addition, Sarikaya et al. [18] analyzed the impact of heterogeneous data on the convergence speed of federated learning and proposed an incentive mechanism to balance the time delay of each iteration. Khan et al. [19] used the theory of game theory to study enabling federated learning in edge networks, and established a specific incentive mechanism through Stackel- berg game to motivate clients to participate in training."}, {"title": "3 SYSTEM MODEL", "content": "This chapter will introduce the system architecture of this work and the work content and technical applications involved in each step. The data transaction framework flow chart introduced in this article is shown in Figure 1. It is mainly divided into the following nine steps:\n1) The agent publishes training tasks and recruits clients that meet the task data type.\n2) Selecting a client is divided into two parts: Part One: In the first few rounds of training, clients are selected for training and all clients are evaluated once. Part 2: After the first part, the agent will select the top m clients with the highest probability based on the selection probabilities formed by the clients' past performance.\n3) Based on the selected set of clients, the agent sends the trained model to these clients.\n4) The client performs local model training.\n5) After each round of partial updates is completed, the client sends update parameters back to the agent.\n6) The agent performs aggregation and update of global model parameters.\n7) During the global model aggregation process, the agent will evaluate the client's performance in this round of training based on two aspects, including: Gradient direction information: Based on the cosine value of the local model gradient and the global model gradient, evaluate whether the local model can bring new direction information to the global model. Approximate Shapley value calcu- lation: Save the gradient information of the local model during the training process, load different gradient information through the Shapley algorithm for accuracy evaluation, and calculate the Shapley value that reflects the amount of local data. A nega- tive shapley value means that the local data quality is poor, and a positive shapley value means that the local data resources are better.\n8) After each round of global training, the agent uses the UCB algorithm to decide whether to reward the client based on the client's performance in this round, and updates the client's selection probability for the next round based on the reward probability and participation round.\n9) After the final model training is completed, the agent will provide reasonable compensation based on the training contribution of the recruited clients."}, {"title": "4 DETAILED DESIGN", "content": "This chapter introduces the detailed implementation of specific steps in the system architecture. Suppose the number of clients in reality is N, $D_N = {D_i}_{i=1}^N$ represents the amount of local data owned by the client, and $M_N = {M_i}_{i=1}^N$ represents the local training model of each client. The agent's task is to recruit suitable m clients for each round of global training. The total number of training rounds is T. After the training, the agent will make reasonable compensation based on the budget limit."}, {"title": "4.1 Contribution Evaluation Design", "content": "This section introduces two factors for evaluating the client's contribution in a single round of training, consider- ing the model gradient direction and the model's Shapley value respectively. We record the client's contribution eval- uation value at the end of each training by multiplying the two and use this value as the aggregation parameter."}, {"title": "4.1.1 Gradient Direction Information", "content": "Gradient similarity is used to calculate the degree of proximity between two gradient directions. For the gradient update of the federated learning training process, different directions represent the degree of information that the local model can provide. The following calculation method is used to represent the impact of the local model on the global model.\n$\\Gamma_{t,i}(cos) \\triangleq 1 - cos(\\nabla F_i(w_{t,i}), \\nabla F_i(\\overline{w_t}))$ (1)\nWhere $\\nabla F_i(w_{t,i})$ represents the gradient of the local model of client i in round t, and $\\nabla F_i(\\overline{w_t})$ represents the ag- gregated gradient of the global model composed of the remaining clients except client i in round t. The cosine value between the two is calculated. If the value is closer to 1, the value of $\\Gamma_{t,i} (cos)$ is closer to 0, which means that the"}, {"title": "4.1.2 Gradient Loading Approximation Shapley Algorithm", "content": "In federated learning, directly applying the Shapley algorithm will cause a huge computational burden. Since Shapley requires calculating all full permutations and eval- uating them, and in federated learning, different full permu- tations correspond to complete local models or aggregate models composed of local models. Therefore, each retrain- ing of the model will be seriously time-consuming and labor-intensive. In response to the above problems, some related articles have proposed to transform the original Shapley value to reduce the amount of calculation [2], [20], [21]. This paper adopts a gradient loading-based method in- stead of model reconstruction training to reduce the amount of calculation. The specific Shapley value of the client is calculated through multiple rounds of aggregation. First, in each round of global training, the server will retain the gradient update information uploaded by each local model in this round. According to different client combinations, the global model loads the corresponding gradient information to form the corresponding aggregate model, and calculates and saves the performance of the aggregate model. Next, according to different aggregate models, the cumulative marginal contribution of each local model in this round is calculated. Finally, the cumulative marginal contribution is averaged to obtain the Shapley value of client i in the tth round, as follows, where S represents a subset of $D_m$, and $D_m$ is the full set of m clients.\n$\\phi_i = \\frac{1}{C} \\sum_{S\\subset N\\{i\\}} \\frac{(|S|!)(|N| - |S| - 1)!}{(n - 1)!} [U(M_{S\\cup\\{i\\}}) - U(M_S)]$\n(2)"}, {"title": "4.1.3 Aggregation of Contributing Factors", "content": "In the classic federated learning algorithm FedAvg [1], when aggregating global models, the proportion of the local model's data set to the total data is used as the weight of the aggregation parameter. In our work, based on the two contribution evaluation factors introduced above, we redesign the weight to the normalized value of $\\theta$. The aggregation weight of a local model i in round t is defined as:\n$\\rho_i^t = \\frac{\\theta_i^t}{\\sum_{i=1}^m \\theta_i^t}$ (3)\nThen the global model aggregation parameters of round t are:\n$W_{t+1} \\leftarrow W_t - \\eta \\sum_{i=1}^m \\rho_i^t \\nabla F_i(W_{t,i})$ (4)"}, {"title": "4.2 Client Selection Design", "content": "Client selection is a problem worth studying. Different client selection algorithms are implemented based on differ-"}, {"title": "4.2.1 UCB Algorithm", "content": "The idea behind the upper confidence bound (UCB) algorithm selection is that the square root term is a measure of the uncertainty in the estimate of the contribution of the ith model. Therefore, the size of the maximum value is an upper limit on the possible true value of model i. Each time i is selected, the uncertainty may decrease, and since $n_i$ appears in the denominator of the uncertainty term, this term decreases as $n_i$ increases. On the other hand, each time a seller other than i is selected, n in the numerator increases, while $n_i$ does not change, so the uncertainty increases. The use of the natural logarithm means that the increase becomes smaller and smaller over time, but it is in- finite and all models will eventually be selected. Therefore, every seller has the opportunity to participate with a fair contribution, while ensuring that greedy seller selection will not occur, thereby avoiding the situation where the model generalization performance is poor.\n$prob = R_i + \\sqrt{\\frac{2 ln n}{N_i}}$ (5)"}, {"title": "4.2.2 Reward Function", "content": "In the ucb formula, $R_i$ represents the probability of reward, which is reflected in the probability of generating a reward each time a selection is made. In this work, the reward is reflected in whether a client performs well or makes a positive contribution in this round of training when a client is selected for this round of training. Based on the two methods of measuring performance mentioned above, we design a corresponding reward function, which is defined as: the closer $\\Gamma_{t,i}(cos)$ of local model i in the tth round is to 1 (less than the threshold k) and $\\phi_i^t$ is greater than the average $\\overline{\\phi_i^t}$ of the participating clients in the tth round and the value is positive. When the above conditions are met, the reward value is 1, otherwise it is considered that the performance in this round is not worth rewarding, and the reward value is 0. $n_i$ represents the cumulative number of rounds participated by client i, and n represents all training rounds. Among them, k is a pre-set threshold, and m is the number of clients participating in each round.\n$R_i = \\begin{cases}\n1, & \\text{if } [\\Gamma_{(t,i)}(cos) < k \\cup \\phi_i^t > 0 \\cup \\phi_i^t > \\sum_{i=1}^m \\overline{\\phi_i^t}] \\\\\n0, & \\text{if } [\\Gamma_{(t,i)}(cos) < k || \\phi_i^t > 0 || \\phi_i^t > \\sum_{i=1}^m \\overline{\\phi_i^t}]\n\\end{cases}$ (6)"}, {"title": "4.3 Compensation Design", "content": ""}, {"title": "4.3.1 Contribution Aggregate Function", "content": "When the global training round ends, in addition to obtaining the cumulative contribution evaluation value dur- ing the training process, it is still necessary to combine the client's local data distribution and the number of training times for investigation. Therefore, it is necessary to design a reasonable contribution aggregation function to obtain the final contribution value. This work will examine and measure from different aspects, including the participation round $P_i$, the cumulative value represented by $GS_i$, and the client's local data distribution $EMD_i$ and data volume $C_i$, among which q is the control function growth rate factor. The $EMD$ value is used to measure the similarity of two data distributions. In this work, this value is used to judge the degree to which the client's local data distribution deviates from the global data distribution. Therefore, a larger $EMD$ value represents a larger deviation of the client's local data distribution, so the difference of $1 - EMD_i$ is taken as the value of this parameter. Among these four parameters, $GS_i$ is the most important measurement standard. If $P_i$ is used as the main indicator for measurement, the client's participation round will not be proportional to the actual contribution under the greedy selection participation round strategy, resulting in unfair contribution evaluation. There- fore, the weight of $GS_i$ should be larger, and the influence of $P_i$ should be suppressed, so that when the $P_i$ value is large, the impact on the function value is also within a controllable range. The final contribution evaluation value of client i is:\n$P_i = \\begin{cases}\nPi + 1, & \\text{if } i \\subseteq m \\text{ and } t > 0 \\\\\n0, & \\text{if } t = 0\n\\end{cases}$ (7)\n$GS_i = \\sum_{t=1}^T \\theta_t$ (8)\n$C_i = \\frac{len(D_i)}{\\sum_{i=1}^N len(D_i)}$ (9)\n$CE_i = (1 + log (P_i \\cdot e^{GS_i}) \\cdot [C_i + (1 - EMD_i)]) / e^{-q}$ (10)"}, {"title": "4.3.2 Budget Constraint Compensation", "content": "After obtaining the client's contribution evaluation value, it is necessary to compensate the client fairly under the budget limit to ensure high income for the client. The contribution evaluation function ensures the fairness of the final contribution value. The final compensation value is calculated as follows:\n$CV_i = \\frac{Budget \\cdot CE_i}{\\sum_{i=1}^N CE_i}$ (11)"}, {"title": "5 PERFORMANCE EVALUATION", "content": "This chapter will design corresponding experiments to verify the research involved in this work. Five parts are designed for experiments and corresponding simulation results are provided to evaluate the effectiveness and ratio-"}, {"title": "5.1 Selection Strategy", "content": "We verified the effectiveness of client selection based on the ucb algorithm. As a comparison, we chose a random strategy method for comparison. Under different data dis- tribution conditions, 20 clients were used to perform 100 global trainings. Five clients were selected in each training round to participate in the training. Figures 2 and 3 show the client participation of the two selection strategies un- der Non-iid and iid distributions. Regardless of the data distribution, the Random strategy selects each client more evenly, which is not conducive to the participation of clients with greater contributions in training. UCB reflects the trend of more work and more pay. At the same time, it does not over-converge on some clients, which will help the model not to over-converge on some clients and improve the generalization ability of the model."}, {"title": "5.2 Contribution Method Assessment", "content": "To verify the effectiveness of the contribution evalua- tion method proposed in this work, we selected 50 clients to conduct 100 rounds of global training first, and obtained the contribution value of each client in this process. Then, we sorted the 50 clients in descending order by contribu- tion value, and selected the top 10 and bottom 10 clients respectively, that is, removed the clients ranked in the [10:50] and [1:40] intervals and re-trained them, and recorded the training accuracy of these three groups of clients. At the same time, to verify the universality of this method under different data sets, we selected 5 different data sets for experiments. As shown in Figure 4, there is a significant gap in accuracy between the top 10 clients and the bottom 10 clients. On the svhn and fmnist data sets, the training effect and smoothness of the top 10 clients are even better than when all clients participate. This shows that our method can effectively evaluate the contribution of clients, and the selected high-quality clients are representative."}, {"title": "5.3 Client Participation Performance", "content": "Based on the ucb strategy, we compared the perfor- mance of 20 clients under the Random strategy after 100 rounds of global training, including the client's contribu- tion value and reward probability-participation rounds. We normalized the participation rounds of each client, and the reward probability was obtained by dividing the reward value of each round in the reward function designed in this work by the total rounds, which represents the probability of selecting a client to make a positive contribution, as shown in Figure 5. The broken line in the figure represents the contribution value of the client, the light-colored part of the bar chart represents the reward probability of the client, and the dark-colored part represents the participation rounds of the client. Under the ucb strategy, the higher the reward probability, the more participation rounds the client gets, thereby obtaining a higher contribution value. When the contribution value of the client is negative, the client will participate in very few rounds, which shows the rationality of our reward function design, which can accurately reflect the client's performance, so that clients with positive contributions can get more participation op- portunities. Under the Random strategy, we also record the reward probability of each client. Even though the reward probability correctly reflects the client's performance, due to the average nature of random selection, each client can get a similar number of participation rounds regardless of its per- formance. This means that clients with good performance do not get more opportunities to participate, while clients with poor performance may get more opportunities, which affects the accuracy of the model and cannot guarantee good contribution fairness."}, {"title": "5.4 Model Accuracy Assessment", "content": "To verify the effectiveness of strategy selection, we com- pared the training accuracy of several strategy selections under five different data sets, including the ucb-based strat- egy proposed in this work, the random selection strategy random, the worst selection strategy worst: that is, always select the client with the worst performance under the ucb- based strategy, and the greedy strategy greedy: greedily select the client with the most rounds of participation. In each round of training, we choose 5 out of 20 clients for training. At the same time, we list the test accuracy after the training.\n\u2022\n\u2022\nAs shown in Table 1 and Figure 7, the training accuracy under different data distributions, it can be observed that the training accuracy based on the UCB strategy is better than other strategies in different data distributions and different data sets. The gap is more obvious on the more complex the data set, and the training accuracy curve of the worst strategy is always at the bottom, which also shows the effectiveness of our strategy selection. The greedy strategy is equivalent to the worst strategy in most cases and converges to low accuracy too early. This shows that the participation round cannot reflect the performance of the client. Greedy selection of clients with more participation rounds will make the model converge to some clients, resulting in low model accuracy.\nAs shown in Tables 2 and Figure 6, the test accuracy of the model trained based on the UCB strategy is better than other selection strategies on each differ- ent data set. On more complex data sets, such as CIFARR-10 and SVHN, the accuracy gap is more obvious, even exceeding 20 percentage points, which shows that our strategy selection method can per- form better when dealing with more complex tasks."}, {"title": "5.5 Evaluate contribution aggregation function", "content": "To verify the rationality of the contribution aggregation function and compensation design, we added the parame- ters of the function one by one and observed the impact of the retained parameters on the function value. As shown in Figure 8, when the CEMD parameter is retained, the data distribution between different clients is obviously reflected. When only this parameter is retained, there is no distinction under different strategies, which is not suitable for separate measurement. When the P parameter is retained, it will be affected by the selection strategy. For example, the average of the training rounds under the Random strategy leads to almost no difference in the function value dominated by P. Only when GS is retained or other parameters are combined with GS can the specific contribution of the client be better reflected, and the function design makes the function value approximately proportional to the GS value. When the three parameters are combined, the function value will be improved as a whole. At the same time, we calculated the budget compensation under different parameter combina- tions. As shown in the Figure 9. Under the ucb strategy, the budget compensation expenditures obtained by different parameters are lower than those of the Random strategy, thus achieving the purpose of low cost for agents. The com-"}, {"title": "6 CONCLUSION", "content": "In this paper, we analyze the needs between sellers and agents in the data trading market, propose a data trading framework based on the federated learning architecture, design a seller selection algorithm and a contribution eval- uation method as well as a compensation method. Through experimental simulation results, we prove the rationality and effectiveness of the framework. At the same time, we achieve the goal of low cost for agents and high income for sellers, which helps to solve the problems existing in the data trading market and promote the development of this field. In future work, considering the privacy and timeliness of data is an aspect worth studying."}]}