{"title": "Balanced Multi-Relational Graph Clustering", "authors": ["Zhixiang Shen", "Haolan He", "Zhao Kang"], "abstract": "Multi-relational graph clustering has demonstrated remarkable success in uncovering underlying patterns in complex networks. Representative methods manage to align different views motivated by advances in contrastive learning. Our empirical study finds the pervasive presence of imbalance in real-world graphs, which is in principle contradictory to the motivation of alignment. In this paper, we first propose a novel metric, the Aggregation Class Distance, to empirically quantify structural disparities among different graphs. To address the challenge of view imbalance, we propose Balanced Multi-Relational Graph Clustering (BMGC), comprising unsupervised dominant view mining and dual signals guided representation learning. It dynamically mines the dominant view throughout the training process, synergistically improving clustering performance with representation learning. Theoretical analysis ensures the effectiveness of dominant view mining. Extensive experiments and in-depth analysis on real-world and synthetic datasets showcase that BMGC achieves state-of-the-art performance, underscoring its superiority in addressing the view imbalance inherent in multi-relational graphs. The source code and datasets are available at https://github.com/zxlearningdeep/BMGC.", "sections": [{"title": "1 Introduction", "content": "Multi-relational graphs, which involve a set of nodes with multiple relations, are prevalent in the real world because of their extraordinary ability in characterizing complex systems [29]. Some typical instances are citation networks, social networks, and knowledge graphs [24, 38]. Recently, the unsupervised exploration of the inherent pattern in complex networks has attracted considerable attention, particularly in the context of multiview graph clustering (MVGC). Conventional MVGC techniques typically combine graph optimization with clustering techniques such as subspace clustering and spectral clustering [13, 22]. With the advancement of Graph Neural Networks (GNNs), a new wave of deep MVGC methods has been proposed, such as O2MAC [5], DMGI [25], HDMI [11], BTGF [28]. They have demonstrated significant efficacy.\nHowever, representative MVGC methods often align all views to seek consistent information with the aid of a contrastive learning mechanism [11, 20, 28, 36]. This approach often ignores the fact that different views in real-world data do not always carry equal significance, i.e., the imbalance phenomenon. Our empirical analysis of real-world multi-relational graphs confirms this intuition. As shown in Fig. 1, different relations exhibit a big gap in classification accuracy. Therefore, naively aligning different views could degrade the final performance.\nTo this end, we address the view imbalance problem in multi-relational graphs in this work. Unlike other multiview data, the view differences in multi-relational graphs are rooted in their topology structures. Thus, a natural question arises: (Q1) How can we quantify the structural disparities between views in multi-relational graphs? Previous studies in multimodal learning indicate the presence of a dominant view in view-imbalanced data [34]. Given the clustering tasks, another question appears: (Q2) How can we discover the dominant view without supervision to guide multi-relational graph clustering?\nIn addressing Q1, we propose a simple yet effective view evaluation metric: Aggregation Class Distance (ACD). Unlike previous methods that solely calculate graph homophily ratios at the edge or node level [23], ACD takes into account both the aggregation process and the distribution of node classes. Empirical studies conducted on real-world datasets demonstrate the efficacy of this novel metric in evaluating the quality of views in multi-relational graphs.\nFor Q2, we propose Balanced Multi-Relational Graph Clustering (BMGC), which incorporates unsupervised dominant view mining and dual signal guided representation learning. A dynamic method of unsupervised exploration of the dominant view is employed throughout the training process, taking advantage of view-specific representations and original node features. Theoretical analysis establishes the connection between this approach and ACD, ensuring the effectiveness of dominant view mining. Afterward, dual signals"}, {"title": "2 Related Work", "content": "Recently, there have been extensive explorations into multiview graph clustering. Typical shallow methods, such as MvAGC [13] and MCGC [22], combine graph filtering with self-expression learning to leverage attribute and structural information simultaneously.\nWith the progress in representation learning, several deep methods have emerged. Most of them start by unsupervised learning of node representations and then apply the k-means algorithm on these representations to obtain clustering results. O2MAC [5] is the first to employ GNN for MVGC, selecting the most informative view as input and reconstructing the graph structures of all views to capture shared information. Although O2MAC considers discrepancies in different graph structures, its encoding strategy, which retains only the best view, results in degradation into a single-view method. Moreover, it uniformly reconstructs the graph structures of all views, which in turn disregards the view imbalance, further leading to suboptimal results. DMGI [25] and HDMI [11] optimize embeddings by maximizing mutual information between local and global representations. MGCCN [15], MGDCR [20], and BTGF [28] incorporate various contrastive losses to achieve the alignment of the representation and prevent dimension collapse. DuaLGR [14] extracts supervised signals from node attributes and graph structures to guide the MVGC. CoCoMG [26] and DMG [21] approach multi-view representation learning from the perspectives of consistency and complementarity. Although numerous methods achieve representation learning through multiview alignment, most of them overlook the inherent performance disparities between different views. These alignment-based methods tend to treat all graphs equally, which compromises the quality of node representations and thereby deteriorates the clustering results.\nIn supervised or semi-supervised tasks, methods like HAN [35] and SSAMN [30] consider the varying importance of views. However, they require labeled information for training, which is unsuitable for unsupervised tasks. To our best knowledge, we are the first to address view imbalance in multiview graph clustering."}, {"title": "2.2 Imbalanced Multiview Learning", "content": "Numerous efforts have been dedicated to addressing the challenges of imbalanced multiview learning from diverse perspectives. Works such as [8, 16] tackle imbalanced views through decision-level fusion. Specifically, they initially cluster each view and then fuse the view-specific clustering results. Another distinct avenue involves leveraging similarity graphs. MDCR [40] constructs balanced view-specific inter-instance similarity graphs, utilizes embedding techniques to acquire latent representations, and concatenates them to form the final representation for clustering. In contrast, FMUGE [39] takes a different approach to model order, initially combining view-specific similarity matrix to create a common similarity graph, followed by learning a comprehensive multiview representation.\nHowever, all of these methods cannot handle graph structure data. Imbalanced multimodal learning has also attracted widespread attention. Recent theoretical advancements have demonstrated the potential of multimodal learning to surpass the upper limits of single-modal performance [10]. However, due to the varying confidence levels and noise across different modalities, the learning process is susceptible to inducing bias towards a dominant modality. To achieve a balanced multimodal classification, OGM [27] devises a modality-wise difference ratio to monitor the contribution discrepancy of each modality to the target, thus adaptively adjusting the gradients of each modality. Subsequently, PMR [6] proposes Prototypical Modality Rebalance, accelerating the slow-learning modality by enhancing its clustering towards prototypes. Despite the effectiveness of these methods, none have considered graph data. Therefore, methods to handle the view imbalance in the realm of unsupervised multiview graph learning are urgently needed."}, {"title": "3 Empirical Study", "content": "Notation. In this work, we define a multi-relational graph as \\(G = \\{V, \\mathcal{E}_1,\\cdots, \\mathcal{E}_v, \\cdots, \\mathcal{E}_V, X\\}\\), where V is the node set with N nodes and \\( \\mathcal{E}_v \\) is the edge set in the v-th view. V > 1 is the number of relational graphs. \\(X \\in \\mathbb{R}^{N \\times d_f}\\) is the feature matrix and \\(x_i \\in \\mathbb{R}^{N} \\) is a column of the feature matrix that represents a graph signal. \\( \\tilde{A}^v \\) denotes the original adjacency matrix of the v-th view.\n\\(D^v\\) represents the degree matrix. The normalized adjacency matrix of the v-th view is given by \\(A^v = (D^v)^{-1} \\tilde{A}^v (D^v)^{-1}\\). It is a well-known fact that the eigenvalues of \\(A^v\\) in each view are contained within [\u22121, 1]. \\(\\hat{A}^v = (D^v + I)^{-\\frac{1}{2}} (\\tilde{A}^v + I)(D^v + I)^{-\\frac{1}{2}}\\) represents the normalized adjacency matrix with a self-loop to each node, where I is an identity matrix. C is the number of node classes, and \\(y \\in \\mathbb{R}^N \\) denotes the label vector.\nIn a multi-relational graph, the imbalance between views stems from differences in graph structure: some graphs contain more task-relevant information, while others are less task-relevant. Previous research has analyzed the impact of the graph structure on GNN from the perspective of graph homophily, suggesting that structures with high homophily ratios often exhibit superior performance [3, 42]. Here, the edge-level homophily ratio (hr) is defined as \\(hr = \\frac{\\sum_{(i,j)\\in \\mathcal{E}} 1(y_i = y_j)}{\\sum_{(i,j)\\in \\mathcal{E}} 1}\\), where 1(\u00b7) is the indicator function that equals 1 if its argument is true and 0 otherwise. However, recent studies have shown that neighbors of different classes may not necessarily make the nodes indistinguishable [19]. Graph structure analysis should consider node neighborhood patterns and the aggregation process. To quantify structural disparities across different views, we propose a simple yet effective metric: Aggregation Class Distance (ACD). ACD evaluates structure quality based on aggregated feature distribution of node classes, adapting better to real-world complexity than assuming a direct correlation between homophily ratio and task performance. The theoretical analysis in Section 5 substantiates this assertion. We choose the Simple Graph Convolution (SGC) as the aggregation method [37], a widely used representative aggregation operation [3, 19]. The ACD is defined as follows.\nDefinition 1. The aggregation class distance for the v-th view, denoted as \\(dis^v\\), is calculated as:\n\\[\\begin{aligned}X_m^v = \\frac{1}{\\mathcal{N}_m}\\sum_{y_i=m} \\mathbf{X}_i^v \\\\dis^v = \\frac{1}{C^2-C} \\sum_{m=1}^{C} \\sum_{n=m+1}^{C} ||\\mathbf{X}_m^v - \\mathbf{X}_n^v||^2\\end{aligned}\\]\nwhere Nm is the number of nodes in class m and K denotes the radius of aggregation. The reciprocal of \\(\\frac{1}{C^2-C}\\) represents the computation count for pairwise inter-class distances.\n\\(\\mathbf{X}_m^v\\) represents the centroid of aggregated features for nodes with class m in the v-th view. The metric \\(dis^v\\) gauges the inter-class distance of aggregated features. A higher value indicates better discriminability among different classes.\nTo demonstrate the connection between ACD and view performance, we conduct empirical research on real-world datasets. We randomly select 30% of the nodes as the training set, leaving the remaining ones for the test set. The aggregation radius is set to 3, aligning with the common layer count of many GNN models [2]. A linear layer serves as the classifier. As shown in Fig. 1, the line represents the classification accuracy of each view, while the bar chart indicates the corresponding ACD. Different views yield different results, affirming the existence of view imbalance. In each dataset, the performance of one view significantly exceeds that of others, and we refer to it as the dominant view. Furthermore, views with higher ACD values exhibit better classification results,"}, {"title": "4 Methodology", "content": "In this section, we propose Balanced Multi-Relational Graph Clustering, as depicted in Fig. 2, to overcome inherent view imbalance.\nUnlike most GNN-based approaches [20, 21], we decouple graph propagation and dimensionality reduction to improve scalability. Initially, we perform propagation on the node features separately for each view, acquiring view-specific aggregated features. Similarly to the approximate personalized propagation in [4], we introduce the features of the original node as a teleport vector in each layer of the propagation process:\n\\[X^{v,0} = X, \\quad X^{v,k+1} = (1 - \\alpha)\\hat{A}^v X^{v,k} + \\alpha X\\]\nwhere X acts as both the starting matrix and the teleport set for each view. The hyper-parameter \\(\\alpha \\in [0, 1]\\) represents the teleport probability. \\(k \\in [0, K - 1]\\) and the aggregated features \\(X^v = X^{v,K}\\). These features are then fed into a shared encoder for dimensionality reduction:\n\\[Z^v = f_e(X^v)\\]\nwhere \\(Z^v \\in \\mathbb{R}^{N \\times d_r}\\) denotes node representations in the v-th view. This decoupled setup avoids the time-consuming graph convolution operations during training. Subsequently, the representations for each view are fed into a shared decoder for the reconstruction of view-specific aggregated features. Effective training of each view is ensured by optimizing the reconstruction cosine error:\n\\[\\tilde{X}^v = g_e(Z^v)\\]\n\\[\\mathcal{L}_{REC} = - \\frac{1}{\\mathcal{V}N} \\sum_{v=1}^{\\mathcal{V}} \\sum_{i=1}^{N} \\frac{\\langle X_i^v, \\tilde{X}_i^v \\rangle}{\\|X_i^v\\| \\|\\tilde{X}_i^v\\|}\\]\nwhere the encoder \\(f_e(\\cdot)\\) and the decoder \\(g_e(\\cdot)\\) are both implemented using a Multilayer Perceptron (MLP) in this study."}, {"title": "4.2 Unsupervised Dominant View Mining", "content": "Due to the absence of label information, we cannot directly utilize ACD for the assessment of view quality in multi-relational graph clustering. Therefore, grounded in the principle of invariance in the distribution of similarity between instances, we propose an unsupervised method for dominant view mining:\n\\[v^* = \\arg \\min_v ||XX^T - X^v(X^v)^T||\\]\nwhere v* denotes the dominant view. The above expression quantifies the discrepancy between the similarity matrices of original features and view-specific aggregated features, henceforth referred to as the \"unsupervised metric\". Therefore, the dominant view should optimally maintain instance similarities. In Section 5, we theoretically establish the effectiveness of our approach.\nConsidering potential noise in real-world data, we refrain from directly using aggregated features to gauge view quality and, instead, rely on node representations:\n\\[v^* = \\arg \\min_v ||XX^T - Z^v(Z^v)^T||\\]\nIn the training process, we initialize the dominant view using Equation (7) and recalculate it every t epochs using Equation (8). As training progresses, the quality of node representations improves, thereby bolstering the reliability of dominant view mining. Simultaneously, the dominant view would guide representation learning, as elaborated later. It constitutes a mutually reinforcing process."}, {"title": "4.3 Co-aligned Representation Learning", "content": "After determining the dominant view, we use it to improve the representation quality. We employ contrastive learning to align the representations of other views with the dominant view. The representations of each view are projected to a shared latent space using separate learnable MLPs for fair similarity measurement and loss calculation. The contrastive loss is defined as follows:\n\\[f(Z_i^v, Z_j^*) = -\\log \\frac{e^{\\text{sim}(\\tilde{Z}_i^v, \\tilde{Z}_j^*)/\\tau}}{\\sum_{j=1}^{N}e^{\\text{sim}(\\tilde{Z}_i^v, \\tilde{Z}_j^*)/\\tau}}\\]\nwhere \\(\\tilde{Z}^v\\) is the non-linear projection of \\(Z^v\\). sim(\u00b7) refers to the cosine similarity and \u03c4 is the temperature parameter. The loss for aligning with the dominant view is given by:\n\\[\\mathcal{L}_{ADV} = \\frac{2}{\\mathcal{V}(\\mathcal{V}-1)} \\sum_{v=1}^{\\mathcal{V}} \\sum_{i=1}^{N} (f(Z_i^v, Z_i^*) + f(Z_i^*, Z_i^v))\\]\nEach view, along with the supervision from the dominant view, should also preserve a consistent similarity distribution among the nodes. Hence, we introduce a loss to ensure alignment with the node features:\n\\[\\mathcal{L}_{ANF} = \\frac{1}{\\mathcal{V} N^2} \\sum_{v=1}^{\\mathcal{V}} ||XX^T - Z^v(Z^v)^T||\\]\nNote that the loss \\( \\mathcal{L}_{ANF} \\) shares a similar form with the unsupervised metric proposed in Section 4.2. This establishes a foundation for ensuring the reliability of our approach in continuously mining the dominant view during training. Ultimately, guided by dual signals from both the dominant view and node features, we accomplish the co-aligned representation learning:\n\\[\\mathcal{L}_{CAL} = \\mathcal{L}_{ADV} + \\mathcal{L}_{ANF}\\]"}, {"title": "4.4 Dominant Assignment Enhanced Clustering", "content": "Most deep clustering methods leverage target distribution and soft cluster assignment probability distributions to achieve a selftraining clustering scheme, with the cluster distribution typically obtained by applying k-means [17, 28, 31]. To improve the clustering performance, we substitute representation distributions in other views with cluster assignments derived from the dominant view. Specifically, we apply k-means to the representations of the dominant view to obtain the dominant assignment:\n\\[\\hat{y} = KMeans(\\{Z_{i^*}: i = 1, \\ldots, N\\})\\]\nThen, the soft assignment distribution \\(Q^v\\) in the v-th view can be formulated as:\n\\[Q_{ij}^v = \\frac{\\left(1 + \\|Z_i^v - \\mu_j\\|^2\\right)^{-1}}{\\sum_{l=1}^{C}\\left(1 + \\|Z_i^v - \\mu_l\\|^2\\right)^{-1}}, \\mu_j = \\frac{1}{\\sum_{\\hat{y}_i=j} 1} \\sum_{\\hat{y}_i=j} Z_i^*,\\]\nwhere \\(N_j\\) denotes the number of nodes with the cluster assignment j and qij is measured using Student's t-distribution to denote the similarity between representation \\(Z_i^v\\) and the clustering center \\(\\mu_j\\). The target distribution \\(P^v\\) is computed as:\n\\[p_{ij}^v = \\frac{\\left(Q_{ij}^v\\right)^2 / \\sum_{i=1}^N Q_{ij}^v}{\\sum_{j=1}^C \\left(\\left(Q_{ij}^v\\right)^2 / \\sum_{i=1}^N Q_{ij}^v\\right)}\\]\nWe minimize the KL divergence between the distributions \\(Q^v\\) and \\(P^v\\) for each view to enhance cluster cohesion. The final node representation Z = [Z\u00b9,\u2026\u2026,ZV] \u2208 RN\u00d7Vdr is obtained by concatenating representations from all views. We simultaneously minimize the KL divergence between the Q and P distributions of the final representation Z:\n\\[\\mathcal{L}_{CLU} = KL(P||Q) + \\sum_{v=1}^{\\mathcal{V}} KL(P^v ||Q^v)\\]\nThe overall objective of BMGC, which we aim to minimize through the gradient descent algorithm, consists of three loss terms:\n\\[\\mathcal{L} = \\mathcal{L}_{REC} + \\mathcal{L}_{CAL} + \\mathcal{L}_{CLU}\\]\nFor large-scale datasets, our method, which benefits from scalable graph encoding, eliminates the need for neighbor sampling during the training process. Consequently, we can directly perform mini-batch training, where all loss terms are computed solely from nodes within the batch."}, {"title": "5 Theoretical Analysis", "content": "In this section, we use a synthetic network to theoretically demonstrate the efficacy of BMGC in extracting the dominant view. For simplicity, we adopt SGC as the feature aggregation method.\nData Assumption. A multi-relational graph G has N nodes partitioned into 2 equally sized communities C\u2081 and C2. Let \\(c_1, c_2 \\in \\{0, 1\\}^N\\) be indicator vectors for membership in each community, that is, the jth entry of ci is 1 if the jth node is in C\u00a1 and 0 otherwise. G has V views, each is generated by SBM [1], with intra- and inter-community edge probabilities \\(p^v\\) and \\(q^v\\). G is such a graph model with a feature matrix \\(X = F + H \\in \\mathbb{R}^{N \\times d_f}\\), where each column of H follows a zero-centered, isotropic Gaussian noise distribution N(0, \u03c3\u00b2I) and these columns are mutually independent. The matrix F is defined as \\(F = c_1 \\mu_1^T + c_2 \\mu_2^T\\), where \\( \\mu_1, \\mu_2 \\in \\mathbb{R}^{N}\\) has the same Euclidean norm ||\u00b5||, representing the expected characteristic vector of each community. In addition, let \\(\\mu = \\frac{1}{2} (\\mu_1 + \\mu_2)\\) be the average of the feature vector means.\nLemma 1. Let X be the aggregated feature matrix of the v-th view by applying SGC, with the number of hops K, to the expected adjacency matrix \\( \\tilde{A}^v \\) and the feature matrix X. Then, \\(X^v = F^v + c_1 \\theta_1^v + c_2 \\theta_2^v\\), where \\(F^v = (\\lambda_2^v)^K F + (1 - (\\lambda_2^v)^K)(1 \\mu^T)\\), \\(\\theta_1^v\\) and \\(\\theta_2^v \\in \\mathbb{R}^{d_f}\\) are both distributed according to \\(N(0, \\frac{1}{(1 + (\\lambda_2^v)^{2K})} \\sigma^2 I)\\), and \\(\\lambda_2^v = \\frac{p-q}{p+q} \\in [-1,1]\\) is the second largest non-zero eigenvalue of the associated normalized adjacency matrix \\(A^v\\).\nTheorem 1. Let \\(X_1^v\\) and \\(X_2^v\\) denote the centroid of aggregated features for each community in the v-th view. Then, \\(E [X_1^v - X_2^v] = (\\lambda_2^v)^K (\\mu_1 - \\mu_2)\\) and \\(E [XX^T - X^v(X^v)^T] = \\frac{1 - (\\lambda_2^v)^{2K}}{N} (||\\mu||^2 - \\mu_1 \\mu_2) (c_1c_1^T + c_2c_2^T - c_1c_2^T - c_2c_1^T) + \\omega(\\sigma^2)\\), where \\( \\omega(\\sigma^2)\\) represents the sum of terms containing \\( \\sigma^2 \\) that are of negligible magnitude.\nWhen negligible terms are ignored, it becomes clear that the unsupervised identification of the dominant view essentially corresponds to the view with the maximum \\((1-\\lambda_2^v)^2\\). Additionally, under this data assumption, \\(dis^v = ||\\bar{X}_1^v - \\bar{X}_2^v||\\) indicates that a view with a larger \\((1-\\lambda_2^v)^2\\) is more likely to exhibit a larger ACD. Specifically, the consistent changes in both \\(dis^v\\) and \\(||XX^T - X^v(X^v)^T||\\) related to \\((1-\\lambda_2^v)^2\\) reveal that the identified dominant view is the one with the largest ACD value.\nThe theoretical findings are interpretable. A is influenced by the ratio of intra- to inter-community edge probabilities, essentially measuring the homophily level of the graph structure in the v-th view. It tends toward 1 for complete homophily and -1 for complete heterophily. In both cases where (12)2 approaches 1, there would be no confusion between nodes from different communities. For example, when 22 = \u22121, if K is odd, feature exchange occurs between the two communities after aggregation; if K is even, the features would remain unchanged. In such cases with pure graph structures, the view consistently demonstrates a larger ACD and a smaller unsupervised metric, while the homophily ratio would tend toward zero as 22 approaches \u22121. On the contrary, when nears 0, the graph structure becomes uninformative, resulting in the view with a smaller ACD and a larger unsupervised metric. In summary, we draw two conclusions: 1. ACD is more universally applicable than the traditional homophily ratio in assessing the relevance between graph structures and downstream tasks. 2. The dominant view, mined through our unsupervised method, essentially corresponds to the view with the maximum ACD value, which ensures the effectiveness of unsupervised dominant view mining."}, {"title": "6 Experiments", "content": "To evaluate the performance of our model, we compare BMGC with multiple baselines on five real-world datasets. For the supervised baseline HAN, we employ k-means on the node embeddings of the test set to yield clustering results. We conduct single-view clustering methods separately for each view and present the best results. Generally, BMGC consistently outperforms all compared methods regarding four metrics over all datasets. From Table 1, we have the following observations:\n\u2022 The advantages of BMGC become evident when compared to other methods. In particular, our model significantly outperforms existing methods, including the supervised baseline, on Amazon and ACM2 datasets. Regarding second-place results on Amazon, our model improves NMI and ARI by 42.9% and 32.7%, respectively.\n\u2022 In general, multiview graph methods outperform single-view methods like VGAE and DGI, demonstrating the superiority of multiview methods in graph clustering. However, in the Yelp dataset, most multiview baselines underperform compared to single-view methods, which may be attributed to the fact that these multiview methods overlook the imbalance among different views, leading to worse performance. Moreover, while the supervised baseline HAN surpasses the unsupervised baselines on most datasets, BMGC still outperforms it, underscoring the superiority of our method.\n\u2022 Our model outperforms O2MAC which considers information differences among views. O2MAC retains only the most informative view while discarding others, which to some extent degenerates into a single-view method with worse results. Our model uses all the views and achieves better results by aligning the other views with the dominant view."}, {"title": "6.4 Evaluation on Synthetic Datasets", "content": "To further compare BMGC with other methods in addressing the imbalanced problem, we introduce a new synthetic dataset based on cSBM [4], named multi-relational cSBM. The multi-relational cSBM initially generates three views, each possessing unique graph structures with uniform homophily ratios, and sharing a common feature matrix. All nodes are categorized into two classes. We randomly add noisy edges to two of these graphs to induce perturbations, where the perturbation ratio p controls the proportion of randomly added edges, simulating the imbalanced multi-relational graph. The undisturbed view is denoted as view 1, representing the dominant view, while the other two views are referred to as view 2 and view 3. Experiments are carried out for four p values: [20%, 50%, 100%, 150%].\nTo reveal the performance discrepancies of different views, we use SGC on each view to obtain view-specific aggregated features and then obtain clustering results through k-means. We select several representation learning-based approaches for comparison. The results, as shown in Table 2, indicate that a higher perturbation ratio leads to poorer performance for all methods. Our detailed observations are as follows.\nFirst, the majority of multiview graph clustering methods yield unsatisfactory results. As the perturbation ratio increases, their performance degrades to a lower level. Second, as the perturbation ratio reaches 150%, the performance of the comparative methods even drops below the SGC result in view 1, indicating that when there is extensive noise in certain views of the dataset, the performance of multiview methods may deteriorate compared to the single view methods. In our method, aligning with the dominant view prevents the result from being impaired by low-quality views with noise. Third, our model maintains relatively stable performance as the perturbation ratio increases, with a maximal variation range of 17.7%, 11%, and 2.6% for NMI, ARI, and ACC respectively, showcasing the robustness for noisy data."}, {"title": "6.5 Evaluation on Large-scale Dataset", "content": "To evaluate the efficiency of BMGC, we conduct experiments on a large-scale multi-relational graph MAG. We select some scalable representation learning-based methods as baselines, while the remaining models run out of memory. We set the representation"}, {"title": "6.6 Ablation Study", "content": "To validate the effectiveness of different components in our model, we compare the performance of BMGC with its three variants:\n\u2022 Employing BMGC without \\( \\mathcal{L}_{ADV} \\) to show the significance of alignment with the dominant view.\n\u2022 Employing BMGC without \\( \\mathcal{L}_{ANF} \\) to observe the impact of alignment with the node features.\n\u2022 Employing BMGC without \\( \\mathcal{L}_{CLU} \\) to reveal the influence of the dominant assignment on clustering performance.\nBased on Table 4, we can draw the following conclusions. First, the results of BMGC are better than all variants, indicating that"}, {"title": "6.7 Case Study", "content": "Effectiveness of Unsupervised Mining. We delve deep into examining the impact of the perturbation ratio on both the accuracy and the unsupervised metric (||XXT \u2013 X\u00ba(X\u00ba)\u00af ||\u00b2 / N) in View 3 of the synthetic dataset. As depicted in Fig. 3a, it is conspicuous that with the increase of the perturbation ratio from 0 to 150%, the accuracy consistently decreases, indicating a continuous decline in view quality. In parallel, the corresponding unsupervised metric indeed rises. This highlights the effectiveness of our unsupervised dominant view extraction method, aligning with the conclusions drawn in the theoretical analysis in Section 5.\nReliability of Dynamic Mining. To provide a detailed description of the process through which our model uncovers the dominant view, we demonstrate the evolution of the unsupervised metric (||XX\u2122 \u2013 Z\u00ba (Z\u00ba)\u2122 ||\u00b2 / N), used to mine the dominant view, for each view of the ACM dataset. As illustrated in Fig. 3b, the data points on the y-axis represent the aggregated node features used to initialize the dominant view. These points are connected by dashed lines to subsequent data points derived from node representations. Throughout the training, the metrics of both views decrease, and"}, {"title": "6.8 Hyper-parameters Study", "content": "We conduct a hyper-parameter analysis on the teleport probability a and the radius of graph propagation K on three datasets ACM, Yelp, and Amazon. The result is given in Fig. 4. From the figure on the left, we can observe that our model shows low sensitivity to the change of \u03b1. However, when \u03b1 is too low, the performance shows a noticeable decrease. This can be attributed to the fact that the lower value of \u03b1 leads to a decreased influence of the features of the original nodes in the propagation process. In the figure on the right, we can see that the performance is stable to the change of K. Notable performance can be achieved when K is small, improving the efficiency of the model in practical applications."}, {"title": "7 Conclusion", "content": "In this study, we thoroughly investigate the prevalent challenge of view imbalance in real-world multi-relational graphs. We introduce a novel metric, the Aggregation Class Distance, to empirically quantify structural disparities among different graphs. To tackle view imbalance, we propose Balanced Multi-Relational Graph Clustering, which dynamically mines the dominant view throughout the training process, collaborating with representation learning to enhance clustering performance. Theoretical analysis validates the efficacy of unsupervised dominant view mining. Extensive experiments and in-depth analysis on both real-world and synthetic datasets consistently demonstrate the superiority of our model over existing state-of-the-art methods."}, {"title": "A Algorithm", "content": "Input: Node features X, adjacency matrices \\( \\tilde{A}^1, \\tilde{A}^2, ..., \\tilde{A}^V \\) where V is the number of relations, the number of clusters C, initialized model parameters \u0398.\n1: Obtain view-specific aggregated features \\(X^v\\) by Eq. (3) before training;\n2: Initialize the dominant view by Eq. (7);\n3: while not reaching maximum epochs do\n4: if every t epochs then\n5: Recalculate the dominant view by Eq. (8);\n6: end if\n7: Obtain node representations \\(Z^v\\) with encoder \\(f_e\\);\n8: Obtain the reconstruction of view-specific aggregated features \\(X^v\\) with decoder \\(g_e\\);\n9: Calculate the reconstruction loss \\( \\mathcal{L}_{REC} \\) by Eq. (6);\n10: Calculate the co-aligned representation learning loss \\( \\mathcal{L}_{CAL} \\) by Eq. (9), Eq. (10), Eq. (11) and Eq. (12);\n11: Obtain the dominant assignment by applying k-means to the representations of the dominant view by Eq. (13);\n12: Compute the soft alignment distribution \\(Q^v\\) and the target distribution \\(P^v\\) for each view by Eq. (14) and Eq. (15);\n13: Obtain the final node representation \\(Z = [Z^1, ...., Z^V]\\) by concatenating representations from all views;\n14: Apply k-means on the final representation Z and compute Q and P distribution of Z;\n15: Calculate the self-training clustering loss \\( \\mathcal{L}_{CLU} \\) by Eq. (16);\n16: Compute the overall objective \\( \\mathcal{L} \\) by Eq. (17);\n17: Back-propagate \\( \\mathcal{L} \\) to update model weights;\n18: end while\n19: Apply k-means on the final node representation Z to obtain the clustering results;\nOutput: The final node representation Z and the clustering results."}, {"title": "B Detailed Proofs", "content": "Data Assumption. A multi-relational graph G has N nodes partitioned into 2 equally sized communities C\u2081 and C2. Let \\(c_1, c_2 \\in \\{0, 1\\}^N\\) be indicator vectors for membership in each community, that is, the jth entry of ci is 1 if the jth node is in C\u00a1 and 0 otherwise. G has V views, each is generated by SBM [1], with intra- and inter-community edge probabilities \\(p^v\\) and \\(q^v\\). G is such a graph model with a feature matrix \\(X = F + H \\in \\mathbb{R}^{N \\times d_f}\\), where each column of H follows a zero-centered, isotropic Gaussian noise distribution N(0, \u03c3\u00b2I) and these columnsare mutually independent. The matrix F is defined as \\(F = c_1 \\mu_1^T + c_2 \\mu_2^T\\), where \\( \\mu_1, \\mu_2 \\in \\mathbb{R}^{N}\\) has the same Euclidean norm ||\u00b5||, representing the expected characteristic vector of each community. In addition, let \\(\\mu = \\frac{1}{2} (\\mu_1 + \\mu_2)\\) be the average of the feature vector means.\nLemma 1. Let X be the aggregated feature matrix of the v-th view by applying SGC, with the number of hops K, to the expected adjacency matrix \\( \\tilde{A}^v \\) and the feature matrix X. Then, \\(X^v = F^v + c_1 \\theta_1^v + c_2 \\theta_2^v\\), where \\(F^v = (\\lambda_2^v)^K F + (1 - (\\lambda_2^v)^K)(1 \\mu^T)\\), \\(\\theta_1^v\\) and \\(\\theta_2^v \\in \\mathbb{R}^{d_f}\\) are both distributed according to \\(N(0, \\frac{1}{(1 + (\\lambda_2^v)^{2K})} \\sigma^2 I)\\), and \\(\\lambda_2^v = \\frac{p-q}{p+q} \\in [-1,1]\\) is the second largest non-zero eigenvalue of the associated normalized adjacency matrix \\(A^v\\).\nTheorem 1. Let \\(X_1^v\\) and \\(X_2^v\\) denote the centroid of aggregated features for each community in the v-th view. Then, \\(E [X_1^v - X_2^v] = (\\lambda_2^v)^K (\\mu_1 - \\mu_2)\\) and \\(E [XX^T - X^v(X^v)^T] = \\frac{1 - (\\lambda_2^v)^{2K}}{N} (||\\mu||^2 - \\mu_1 \\mu_2) (c_1c_1^T + c_2c_2^T - c_1c_2^T - c_2c_1^T) + \\omega(\\sigma^2)\\), where \\( \\omega(\\sigma^2)\\) represents the sum of terms containing \\( \\sigma^2 \\) that are of negligible magnitude.\nWe first prove Lemma 1. Since the proof process is identical for each view, we omit the superscript v of some view-related symbols for simplicity in the proof.\nProof of Lemma 1. In expectation, an entry Aij of the adjacency matrix of the graph is p if both i, j\u2208 C\u2081 or both i, j \u0454 \u04212, and it is q otherwise. The eigendecomposition Qdiag(\u03bb)QT of the associated normalized adjacency matrix A has two non-zero eigenvalues: \u03bb\u2081 = 1, with eigenvector \\(q_1 = \\frac{1}{\\sqrt{N}} 1 = \\frac{1}{\\sqrt{N}} (c_1 + c_2)\\), and \\(\\lambda_2 = \\frac{p-q}{p+q}\\), with \\(q_2 = \\frac{1}{\\sqrt{N}} (c_1 - c_2)\\).\nZero-centered, isotropic Gaussian distributions are invariant to rotation, which means QTH.,i ~ N(0, \u03c3\u00b2I) for any orthonormal matrix Q, so X can be expressed as follows:\nX = AK X\n= Qdiag(\u03bb)KQT (c\u2081\u03bc\u2081 + c2p2 + H)\n= q1q1T (c1\u03bc\u2081 + c2\u03bc2 + H) + q2q2T (c1\u03bc\u2081 + c2\u03bc2 + H)\n\\[\\begin{aligned}&=\\hat{q}_1 \\sqrt{\\lambda_1^K} \\hat{q}_1^T (c_1\\mu_1+c_2\\mu_2+\\mathcal{H})+\\hat{q}_2 \\sqrt{\\lambda_2^K} \\hat{q}_2^T (c_1\\mu_1+c_2\\mu_2+\\mathcal{H}) \\\\& = \\frac{(c_1+c_2)}{sqrt{N}}\\left(\\frac{\\mu_1+\\mu_2}{sqrt{N}} + \\frac{\\hat{h_1}+\\hat{h_2}}{sqrt{N}}\\right)+\\frac{(c_1-c_2)}{\\sqrt{N}}\\left(\\frac{\\mu_1-\\mu_2}{\\sqrt{N}} + \\frac{\\hat{h_1}-\\hat{h_2}}{\\sqrt{N}}\\right) \\\\& = (1 + c2 ) (\\frac{\\mu_1 + \\mu_2}{\\sqrt{N}} + \\frac{\\hat{h_1} + \\hat{h_2}}{\\sqrt{N}}) \\\\& = \\frac{1}{\\sqrt{N}}(1+\\lambda_2)\\left[c_1\\left(\\frac{\\mu_1 + \\mu_2+\\mu_1 -\\mu_2}{2sqrt{N}}\\right)+\\frac{\\mu_1 + \\mu_2-(\\mu_1 -\\mu_2)}{2sqrt{N}}}\\right]\\\\&=(c_1+\\lambda_2c_2)(\\frac{\\mu_1}{\\sqrt{N}})+\\left(-\\frac{1}{\\sqrt{N}}+\\frac{\\mu_2}{\\sqrt{N}}\\right)+ \\frac{1}{\\sqrt{N}} \\left[c_1\\left(\\frac{\\hat{h_1} + \\hat{h_2}}{\\sqrt{N}}+\\frac{\\hat{h_1} -\\hat{h_2}}{sqrt{N}}\\right) \\\\& = \\frac{1}{\\sqrt{N}}(c_1+\\lambda_2c_2)(\\frac{\\mu_1+\\mu_2}{\\sqrt{N}}) + \\frac{1}{\\sqrt{N}}(\\hat{h_1}(h_1+h_2)^T+\\lambda_2(\\hat{h_1}-(\\hat{h_1})_2T)+\\lambda_2(h_2(\\hat{h_2})_2T))\\\\& = F + (1 - 1)1\\mu^T + c_1\\theta_1 + c_2\\theta_2\\end{aligned}\\]\nProof of Theorem 1. Based on the Lemma 1, we can obtain the following.\n\\[\\begin{aligned}&E [\\bar{X_1^v} [X - \\bar{X_1^v}] X] = E [\\lambda^k(\\mu_1 + (1 -\\lambda) \\mu + \\theta_1]\\\\& - E [\\lambda^k(\\mu_2 + (1 -\\lambda) \\mu + \\theta_2]\\\\& = \\lambda^k (\\mu_1 - \\mu_2)\\end{aligned}\\]\nSimilarly, we can formulate the expression for \\(E [XX^T - X^v(X^v)^T]\\) as follows:\nMM '24, October 28-November 1, 2024, Melbourne, VIC, Australia."}, {"title": "C Synthetic Datasets", "content": "We propose the multi-relational cSBM to generate imbalanced multi-relational graphs. We first introduce the data generation process of cSBM. Here, N denotes the number of nodes, and all nodes are divided into two classes of equal size with node labels \\(y_i \\in \\{-1, +1\\}\\). Each node possesses a df-dimensional feature vector, obtained by random sampling from class-specific Gaussian distributions, as follows:\n\\[X_i = \\frac{\\mu}{\\sqrt{N}}\\sqrt{ \\frac{\\lambda}{\\lambda + \\mu}} Y_iu + \\sqrt{ \\frac{\\mu}{\\lambda + \\mu}} \\frac{H_i}{\\sqrt{d_f}}\\]\nwhere u ~ N(0,I/df) and Hi \u2208 Rdf has independent standard normal entries. The adjacency matrix A of the generated cSBM graph is defined as:\n\\[\\mathbb{P} [A_{ij} = 1] = \\begin{cases} \\frac{d + \\sqrt{d}}{N} & \\text{if } Y_iY_j > 0 \\\\ \\frac{d - \\sqrt{d}}{N} & \\text{otherwise.} \\end{cases}\\]\nwhere d is the average degree of the generated graph. Note that \u03bb and u are hyper-parameters to control the proportion of contributions from the graph structure and node features, respectively.\nIn cSBM, the parameter \\( \\phi = arctan(\\frac{\\lambda}{\\mu}) \\in [-1,1]\\) controls the degree of homophily, where \\(\\gamma = \\frac{\\lambda}{\\lambda + \\mu}\\) is a control factor. A larger |\u03d5| implies that the graph can provide stronger topological information, whereas when \u03d5 = 0, only the node features are informative. The parameters of cSBM should satisfy the constraint = 1 + \u03b5, \u03b5 > 0 to generate informative graphs. We follow [4] for cSBM parameter settings, using N = 5000, df = 2000, d = 5, \u03b5 = 3.25.\nTo generate multi-relational graphs, we first create a label indicator vector and feature matrix for nodes. We then use cSBM to generate V graphs with different structures but the same \u03d5 value (\u03d5 = 0.5). Uniform values of \u03d5 ensure that the initial graph structures of each view have the same homophily ratio (0.825), further providing an equal level of topological information. We choose V = 3 to enhance realism. To simulate view imbalance among different views, we randomly add noisy edges to two of these graphs to induce perturbations, as mentioned in the main text."}, {"title": "D Additional Experiments", "content": "We add an experiment to demonstrate the effectiveness of ACD and its superior reliability compared to the existing supervised metric, the homophily ratio. We use the cSBM generative model to produce a series of graphs sharing the same node features and achieve various structures solely by adjusting the value. 30% of the nodes are randomly selected as the training set, with the rest forming the testing set. A linear layer is used as the classifier for view-specific features.\nTable 5 clearly shows that ACD is positively correlated with classification accuracy, which empirically proves the effectiveness"}]}