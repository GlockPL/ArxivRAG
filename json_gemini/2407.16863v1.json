{"title": "Balanced Multi-Relational Graph Clustering", "authors": ["Zhixiang Shen", "Haolan He", "Zhao Kang"], "abstract": "Multi-relational graph clustering has demonstrated remarkable success in uncovering underlying patterns in complex networks. Representative methods manage to align different views motivated by advances in contrastive learning. Our empirical study finds the pervasive presence of imbalance in real-world graphs, which is in principle contradictory to the motivation of alignment. In this paper, we first propose a novel metric, the Aggregation Class Distance, to empirically quantify structural disparities among different graphs. To address the challenge of view imbalance, we propose Balanced Multi-Relational Graph Clustering (BMGC), comprising unsupervised dominant view mining and dual signals guided representation learning. It dynamically mines the dominant view throughout the training process, synergistically improving clustering performance with representation learning. Theoretical analysis ensures the effectiveness of dominant view mining. Extensive experiments and in-depth analysis on real-world and synthetic datasets showcase that BMGC achieves state-of-the-art performance, underscoring its superiority in addressing the view imbalance inherent in multi-relational graphs. The source code and datasets are available at https://github.com/zxlearningdeep/BMGC.", "sections": [{"title": "1 Introduction", "content": "Multi-relational graphs, which involve a set of nodes with multiple relations, are prevalent in the real world because of their extraordinary ability in characterizing complex systems [29]. Some typical instances are citation networks, social networks, and knowledge graphs [24, 38]. Recently, the unsupervised exploration of the inherent pattern in complex networks has attracted considerable attention, particularly in the context of multiview graph clustering (MVGC). Conventional MVGC techniques typically combine graph optimization with clustering techniques such as subspace clustering and spectral clustering [13, 22]. With the advancement of Graph Neural Networks (GNNs), a new wave of deep MVGC methods has been proposed, such as O2MAC [5], DMGI [25], HDMI [11], BTGF [28]. They have demonstrated significant efficacy.\nHowever, representative MVGC methods often align all views to seek consistent information with the aid of a contrastive learning mechanism [11, 20, 28, 36]. This approach often ignores the fact that different views in real-world data do not always carry equal significance, i.e., the imbalance phenomenon. Our empirical analysis of real-world multi-relational graphs confirms this intuition. As shown in Fig. 1, different relations exhibit a big gap in classification accuracy. Therefore, naively aligning different views could degrade the final performance.\nTo this end, we address the view imbalance problem in multirelational graphs in this work. Unlike other multiview data, the view differences in multi-relational graphs are rooted in their topology structures. Thus, a natural question arises: (Q1) How can we quantify the structural disparities between views in multirelational graphs? Previous studies in multimodal learning indicate the presence of a dominant view in view-imbalanced data [34]. Given the clustering tasks, another question appears: (Q2) How can we discover the dominant view without supervision to guide multi-relational graph clustering?\nIn addressing Q1, we propose a simple yet effective view evaluation metric: Aggregation Class Distance (ACD). Unlike previous methods that solely calculate graph homophily ratios at the edge or node level [23], ACD takes into account both the aggregation process and the distribution of node classes. Empirical studies conducted on real-world datasets demonstrate the efficacy of this novel metric in evaluating the quality of views in multi-relational graphs. For Q2, we propose Balanced Multi-Relational Graph Clustering (BMGC), which incorporates unsupervised dominant view mining and dual signal guided representation learning. A dynamic method of unsupervised exploration of the dominant view is employed throughout the training process, taking advantage of view-specific representations and original node features. Theoretical analysis establishes the connection between this approach and ACD, ensuring the effectiveness of dominant view mining. Afterward, dual signals"}, {"title": "2 Related Work", "content": "2.1 Multiview Graph Clustering\nRecently, there have been extensive explorations into multiview graph clustering. Typical shallow methods, such as MvAGC [13] and MCGC [22], combine graph filtering with self-expression learning to leverage attribute and structural information simultaneously.\nWith the progress in representation learning, several deep methods have emerged. Most of them start by unsupervised learning of node representations and then apply the k-means algorithm on these representations to obtain clustering results. O2MAC [5] is the first to employ GNN for MVGC, selecting the most informative view as input and reconstructing the graph structures of all views to capture shared information. Although O2MAC considers discrepancies in different graph structures, its encoding strategy, which retains only the best view, results in degradation into a single-view method. Moreover, it uniformly reconstructs the graph structures of all views, which in turn disregards the view imbalance, further leading to suboptimal results. DMGI [25] and HDMI [11] optimize embeddings by maximizing mutual information between local and global representations. MGCCN [15], MGDCR [20], and BTGF [28] incorporate various contrastive losses to achieve the alignment of the representation and prevent dimension collapse. DuaLGR [14] extracts supervised signals from node attributes and graph structures to guide the MVGC. CoCoMG [26] and DMG [21] approach multiview representation learning from the perspectives of consistency and complementarity. Although numerous methods achieve representation learning through multiview alignment, most of them overlook the inherent performance disparities between different views. These alignment-based methods tend to treat all graphs equally, which compromises the quality of node representations and thereby deteriorates the clustering results.\nIn supervised or semi-supervised tasks, methods like HAN [35] and SSAMN [30] consider the varying importance of views. However, they require labeled information for training, which is unsuitable for unsupervised tasks. To our best knowledge, we are the first to address view imbalance in multiview graph clustering.\n2.2 Imbalanced Multiview Learning\nNumerous efforts have been dedicated to addressing the challenges of imbalanced multiview learning from diverse perspectives. Works such as [8, 16] tackle imbalanced views through decision-level fusion. Specifically, they initially cluster each view and then fuse the view-specific clustering results. Another distinct avenue involves leveraging similarity graphs. MDCR [40] constructs balanced view-specific inter-instance similarity graphs, utilizes embedding techniques to acquire latent representations, and concatenates them to form the final representation for clustering. In contrast, FMUGE [39] takes a different approach to model order, initially combining view-specific similarity matrix to create a common similarity graph, followed by learning a comprehensive multiview representation. However, all of these methods cannot handle graph structure data.\nImbalanced multimodal learning has also attracted widespread attention. Recent theoretical advancements have demonstrated the potential of multimodal learning to surpass the upper limits of single-modal performance [10]. However, due to the varying confidence levels and noise across different modalities, the learning process is susceptible to inducing bias towards a dominant modality. To achieve a balanced multimodal classification, OGM [27] devises a modality-wise difference ratio to monitor the contribution discrepancy of each modality to the target, thus adaptively adjusting the gradients of each modality. Subsequently, PMR [6] proposes Prototypical Modality Rebalance, accelerating the slow-learning modality by enhancing its clustering towards prototypes. Despite the effectiveness of these methods, none have considered graph data. Therefore, methods to handle the view imbalance in the realm of unsupervised multiview graph learning are urgently needed."}, {"title": "3 Empirical Study", "content": "Notation. In this work, we define a multi-relational graph as G = {V, &1,\u00b7\u00b7\u00b7, \u0395\u03c5,\u00b7\u00b7\u00b7, &v, X}, where V is the node set with N nodes and E is the edge set in the v-th view. V > 1 is the number of relational graphs. X \u2208 RN\u00d7df_is the feature matrix and x \u2208 RN is a column of the feature matrix that represents a graph signal. \u00c3\u00ba denotes the original adjacency matrix of the v-th view."}, {"title": "4 Methodology", "content": "In this section, we propose Balanced Multi-Relational Graph Clustering, as depicted in Fig. 2, to overcome inherent view imbalance.\n4.1 Scalable Graph Encoding\nUnlike most GNN-based approaches [20, 21], we decouple graph propagation and dimensionality reduction to improve scalability. Initially, we perform propagation on the node features separately for each view, acquiring view-specific aggregated features. Similarly to the approximate personalized propagation in [4], we introduce the features of the original node as a teleport vector in each layer of the propagation process:\nX0,0 = X, Xu,k+1 = (1 \u2212 a)\u00c2\u00a9Xu,k + aX\n(3)\nwhere X acts as both the starting matrix and the teleport set for each view. The hyper-parameter a \u2208 [0, 1] represents the teleport probability. k \u2208 [0, K \u2212 1] and the aggregated features X\u00ba = X\u028a,K. These features are then fed into a shared encoder for dimensionality reduction:\nZ = f(X)\n(4)\nwhere Zu \u2208 RN\u00d7dr denotes node representations in the v-th view. This decoupled setup avoids the time-consuming graph convolution operations during training. Subsequently, the representations for each view are fed into a shared decoder for the reconstruction of view-specific aggregated features. Effective training of each view is ensured by optimizing the reconstruction cosine error:\n1\nNV\nX = go (Z)\n(X)\nVN\nv=1 i=1\n1\nLREC =\n(5)\n(6)\nwhere the encoder fe() and the decoder ge() are both implemented using a Multilayer Perceptron (MLP) in this study.\n4.2 Unsupervised Dominant View Mining\nDue to the absence of label information, we cannot directly utilize ACD for the assessment of view quality in multi-relational graph clustering. Therefore, grounded in the principle of invariance in the distribution of similarity between instances, we propose an unsupervised method for dominant view mining:\nv* = arg min ||XX\u2122 \u2013 X\u00ba(X\u00ba)\u00af||\n\u03c5\n(7)\nwhere v* denotes the dominant view. The above expression quantifies the discrepancy between the similarity matrices of original features and view-specific aggregated features, henceforth referred to as the \"unsupervised metric\". Therefore, the dominant view"}, {"title": "4.3 Co-aligned Representation Learning", "content": "After determining the dominant view, we use it to improve the representation quality. We employ contrastive learning to align the representations of other views with the dominant view. The representations of each view are projected to a shared latent space using separate learnable MLPs for fair similarity measurement and loss calculation. The contrastive loss is defined as follows:\nf(Z,Z) = -log\nesim(\u017d, Z)/\u03c4\n\u03a3Nesim(2, 2)/\u03c4\n(9)\nwhere Z is the non-linear projection of Z. sim() refers to the cosine similarity and t is the temperature parameter. The loss for aligning with the dominant view is given by:\nLADV =\n2(-1) (2)+(2,2)) (10)\nVN\n1\n0=1 i=1\nv\u22600*\nEach view, along with the supervision from the dominant view, should also preserve a consistent similarity distribution among the nodes. Hence, we introduce a loss to ensure alignment with the node features:\nV\n1\nLANF = N2v Xx - 2\u00ba (2\u00ba) T\nv=1\n(11)\nNote that the loss LANF shares a similar form with the unsupervised metric proposed in Section 4.2. This establishes a foundation for ensuring the reliability of our approach in continuously mining the dominant view during training. Ultimately, guided by dual signals from both the dominant view and node features, we accomplish the co-aligned representation learning:\nLCAL = LADV + LANF\n(12)"}, {"title": "4.4 Dominant Assignment Enhanced Clustering", "content": "Most deep clustering methods leverage target distribution and soft cluster assignment probability distributions to achieve a selftraining clustering scheme, with the cluster distribution typically obtained by applying k-means [17, 28, 31]. To improve the clustering performance, we substitute representation distributions in other views with cluster assignments derived from the dominant"}, {"title": "5 Theoretical Analysis", "content": "In this section, we use a synthetic network to theoretically demonstrate the efficacy of BMGC in extracting the dominant view. For simplicity, we adopt SGC as the feature aggregation method.\nData Assumption. A multi-relational graph G has N nodes partitioned into 2 equally sized communities C\u2081 and C2. Let C1, C2 E {0, 1} be indicator vectors for membership in each community, that is, the jth entry of ci is 1 if the jth node is in C\u00a1 and 0 otherwise. G has V views, each is generated by SBM [1], with intra- and intercommunity edge probabilities pu and q. G is such a graph model with a feature matrix X = F + H \u2208 RN\u00d7df, where each column of H follows a zero-centered, isotropic Gaussian noise distribution N(0, 021) and these columns are mutually independent. The matrix F is defined as F = c1p] + c2p2, where \u00b51, \u00b52 \u2208 RN has the same Euclidean norm ||\u00b5||, representing the expected characteristic vector of each community. In addition, let p = \u00bd (\u03bc\u2081 + \u03bc2) be the average of the feature vector means.\nDEFINITION 1. The aggregation class distance for the v-th view, denoted as dis, is calculated as:\nX = (A)KX, X = \u03a3\u03a7\nYi=m\nC\nC\ndis =\nC2-C\nm=1 n=m+1\n-X|2 (1)\n(2)\nwhere Nm is the number of nodes in class m and K denotes the radius of aggregation. The reciprocal of \u0109 represents the computation count for pairwise inter-class distances.\nXm represents the centroid of aggregated features for nodes with class m in the v-th view. The metric dis gauges the inter-class distance of aggregated features. A higher value indicates better discriminability among different classes.\nTo demonstrate the connection between ACD and view performance, we conduct empirical research on real-world datasets. We randomly select 30% of the nodes as the training set, leaving the remaining ones for the test set. The aggregation radius is set to 3, aligning with the common layer count of many GNN models [2]. A linear layer serves as the classifier. As shown in Fig. 1, the line represents the classification accuracy of each view, while the bar chart indicates the corresponding ACD. Different views yield different results, affirming the existence of view imbalance. In each dataset, the performance of one view significantly exceeds that of others, and we refer to it as the dominant view. Furthermore, views with higher ACD values exhibit better classification results,"}, {"title": "6 Experiments", "content": "6.1\nDatasets and Metrics\nDatasets. We employ five publicly available real-world benchmark datasets and a large-scale dataset. ACM [5], ACM2 [7], and DBLP [41] are citation networks. Yelp [18] and Amazon [9] are review networks. MAG [33] is a large-scale citation network, constituting the largest dataset in multi-relation graph clustering thus far.\nMetrics. We adopt four popular clustering metrics, including Accuracy (ACC), Normalized Mutual Information (NMI), F1 score, and Adjusted Rand Index (ARI). A higher value of them indicates a better performance."}, {"title": "6.2 Experimental Setup", "content": "Baselines. We compare BMGC with various baselines, including the supervised multiview graph method HAN [35], single-view graph clustering methods VGAE [12] and DGI [32], and multiview graph clustering methods O2MAC [5], DMGI [25], MvAGC [13], HDMI [11], MCGC [22], MGDCR [20], DuaLGR [14], DMG [21], and BTGF [28]. All other methods are unsupervised excluding HAN, which serves as the supervised baseline.\nParameter Setting. Our model is trained for 400 epochs using the Adam optimizer with a learning rate of 1e-2. The weight decay of the optimizer is set to 1e-4. The recalculation interval t for the dominant view is every 50 epochs. We set the representation dimension dy to 64 for ACM2 dataset and 10 for the other datasets. The temperature parameter t is fixed at 1. The radius of graph propagation, K, is fixed at 3 and the teleport probability a is tuned in [0, 0.3, 0.5]. All experiments are implemented on the PyTorch platform using an Intel(R) Xeon(R) Platinum 8352V CPU and a GeForce RTX 4090 24G GPU."}, {"title": "6.3 Evaluation on Real-world Datasets", "content": "To evaluate the performance of our model, we compare BMGC with multiple baselines on five real-world datasets. For the supervised baseline HAN, we employ k-means on the node embeddings of the test set to yield clustering results. We conduct single-view clustering methods separately for each view and present the best results. Generally, BMGC consistently outperforms all compared methods regarding four metrics over all datasets. From Table 1, we have the following observations:\n\u2022 The advantages of BMGC become evident when compared to other methods. In particular, our model significantly outperforms existing methods, including the supervised baseline, on Amazon and ACM2 datasets. Regarding second-place results on Amazon, our model improves NMI and ARI by 42.9% and 32.7%, respectively.\n\u2022 In general, multiview graph methods outperform single-view methods like VGAE and DGI, demonstrating the superiority of multiview methods in graph clustering. However, in the Yelp dataset, most multiview baselines underperform compared to single-view methods, which may be attributed to the fact that these multiview methods overlook the imbalance among different views, leading to worse performance. Moreover, while the supervised baseline HAN surpasses the unsupervised baselines on most datasets, BMGC still outperforms it, underscoring the superiority of our method.\n\u2022 Our model outperforms O2MAC which considers information differences among views. O2MAC retains only the most informative view while discarding others, which to some extent degenerates into a single-view method with worse results. Our model uses all the views and achieves better results by aligning the other views with the dominant view."}, {"title": "6.4 Evaluation on Synthetic Datasets", "content": "To further compare BMGC with other methods in addressing the imbalanced problem, we introduce a new synthetic dataset based on cSBM [4], named multi-relational cSBM. The multi-relational cSBM initially generates three views, each possessing unique graph structures with uniform homophily ratios, and sharing a common feature"}, {"title": "7 Conclusion", "content": "In this study, we thoroughly investigate the prevalent challenge of view imbalance in real-world multi-relational graphs. We introduce a novel metric, the Aggregation Class Distance, to empirically quantify structural disparities among different graphs. To tackle view imbalance, we propose Balanced Multi-Relational Graph Clustering, which dynamically mines the dominant view throughout the training process, collaborating with representation learning to enhance clustering performance. Theoretical analysis validates the efficacy of unsupervised dominant view mining. Extensive experiments and in-depth analysis on both real-world and synthetic datasets consistently demonstrate the superiority of our model over existing state-of-the-art methods."}, {"title": "4.4 Dominant Assignment Enhanced Clustering", "content": "Most deep clustering methods leverage target distribution and soft cluster assignment probability distributions to achieve a selftraining clustering scheme, with the cluster distribution typically obtained by applying k-means [17, 28, 31]. To improve the clustering performance, we substitute representation distributions in other views with cluster assignments derived from the dominant view. Specifically, we apply k-means to the representations of the dominant view to obtain the dominant assignment:\n\u0177 = KMeans({Z : i = 1, \u2026, N})\n(13)\nThen, the soft assignment distribution Q\u00ba in the v-th view can be formulated as:\n= \u03a3 \u03b1 =\n\u0177i=j\n(1 + || \u2013 ||\u00b2)-1\n\u03a3=1(1 + ||\u0396 \u2013 12)-1\n(14)\nwhere Nj denotes the number of nodes with the cluster assignment j and qij is measured using Student's t-distribution to denote the similarity between representation Z and the clustering center \u03c3. The target distribution Pu is computed as:\n2\n(9) / \u03a3 19\nPij =\n(15)\nWe minimize the KL divergence between the distributions Q and P\u00ba for each view to enhance cluster cohesion. The final node representation Z = [Z\u00b9,\u2026\u2026,ZV] \u2208 RN\u00d7Vdr is obtained by concatenating representations from all views. We simultaneously minimize the KL divergence between the Q and P distributions of the final representation Z:\nLCLU = KL(P||Q) +\nV\n\u03a3\nv=1\nKL(P ||Q)\n(16)\nThe overall objective of BMGC, which we aim to minimize through the gradient descent algorithm, consists of three loss terms:\nL = LREC + LCAL + LCLU\n(17)\nFor large-scale datasets, our method, which benefits from scalable graph encoding, eliminates the need for neighbor sampling during the training process. Consequently, we can directly perform mini-batch training, where all loss terms are computed solely from nodes within the batch.\n5 Theoretical Analysis\nIn this section, we use a synthetic network to theoretically demonstrate the efficacy of BMGC in extracting the dominant view. For simplicity, we adopt SGC as the feature aggregation method.\nData Assumption. A multi-relational graph G has N nodes partitioned into 2 equally sized communities C\u2081 and C2. Let C1, C2 E {0, 1} be indicator vectors for membership in each community, that is, the jth entry of ci is 1 if the jth node is in C\u00a1 and 0 otherwise. G has V views, each is generated by SBM [1], with intra- and intercommunity edge probabilities pu and q. G is such a graph model with a feature matrix X = F + H \u2208 RN\u00d7df, where each column of H follows a zero-centered, isotropic Gaussian noise distribution N(0, 021) and these columns are mutually independent. The matrix F is defined as F = c1p] + c2p2, where \u00b51, \u00b52 \u2208 RN has the same Euclidean norm ||\u00b5||, representing the expected characteristic vector of each community. In addition, let p = \u00bd (\u03bc\u2081 + \u03bc2) be the average of the feature vector means.\nLEMMA 1. Let X be the aggregated feature matrix of the v-th view by applying SGC, with the number of hops K, to the expected adjacency matrix \u00c3\u00ba and the feature matrix X. Then, X\u00ba = F\u00b0 +\nc1(0) + c2(02), where F\u00ba = (12)KF + (1 \u2212 (12)K)(1p), \u03b8\u00ba and\n09\u2208 Raf are both distributed according to N(0, (1 + (12)2K)\u03c32\u0399),\nand p-q\n=\n\u2208 [-1,1] is the second largest non-zero eigenvalue\np+q\nof the associated normalized adjacency matrix A\u00ba.\nTHEOREM 1. Let X and X denote the centroid of aggregated features for each community in the v-th view. Then, E [X - X] =\n(12)\u039a (\u03bc1 \u2212\u00b52) andE [XXT - X\u00ba (X\u00ba)] = 1-(0)2K (1||12 -\u03bc \u03bc2)\n(C1C + C2C-C1C \u2013 c2c\u2081) + \u03c9(\u03c3\u00b2), where w(\u03c3\u00b2) represents the\nsum of terms containing o\u00b2 that are of negligible magnitude.\nWe first prove Lemma 1. Since the proof process is identical for\neach view, we omit the superscript v of some view-related symbols\nfor simplicity in the proof.\nPROOF OF LEMMA 1. In expectation, an entry Aij of the adjacency matrix of the graph is p if both i, j\u2208 C\u2081 or both i, j \u0454 \u04212, and it is q otherwise. The eigendecomposition Qdiag(2)QT of the associated normalized adjacency matrix A has two non-zero eigenvalues: \u03bb\u2081 = 1, with eigenvector q1 = 1 = (C1 + c2), and 2 =\n+, with q2 = \u8d64(C1 - C2).\nZero-centered, isotropic Gaussian distributions are invariant to rotation, which means QTH.,i ~ N(0, \u03c3\u00b21) for any orthonormal matrix Q, so X can be expressed as follows:\nX = AK X\n= Qdiag(\u03bb)KQT (c\u2081\u03bc\u2081 + c2p2 + H)\n= q1q1 (c1] + c2p2 + H) + q2q2 (c\u2081\u03bc + 2\u03bc2 + H)\nT\nVN(+)+ 92 (+)++\ub9ac 92 (-)+=+=(1+2)+(1-(1-)+=+-(c1 + c2) (\u03bc\u2081 + \u03bc2)+2(h\u2081\u2082= F + (1 \u2212 1)1\u03bc\u00af + c10] + c202\n(18)\nPROOF OF THEOREM 1. Based on the Lemma 1, we can obtain the\nfollowing.\nE [\u00d1\u00ba [X - \u00d1\u00ba] X] = E \u314c [\u00b5\u2081 + (1 -\u03bb) \u03bc+01]\n- \u0395\u03bb\u03bc2 + (1-\u03bb) \u03bc+02]\n= \u03bb (\u03bc1 \u2212 \u03bc2)\n(19)\nSimilarly, we can formulate the expression for E [XX\u2122 \u2013 X\u00ba (X\u00ba)T]\nas follows:\nMM '24, October 28-November 1, 2024, Melbourne, VIC, Australia."}, {"title": "Algorithm", "content": "Algorithm 1 The pseudo-code of the proposed BMGC\nInput: Node features X, adjacency matrices \u00c3\u00b9, \u00c3\u00b2, ..., \u00c4V where V is the number of relations, the number of clusters C, initialized model parameters \u0398.\n1: Obtain view-specific aggregated features X by Eq. (3) before training;\n2: Initialize the dominant view by Eq. (7);\n3: while not reaching maximum epochs do\n4: if every t epochs then\n5: Recalculate the dominant view by Eq. (8);\n6: end if\n7: Obtain node representations Z with encoder fo;\n8: Obtain the reconstruction of view-specific aggregated features X with decoder ge;\n9: Calculate the reconstruction loss LREC by Eq. (6);\n10: Calculate the co-aligned representation learning loss LCAL by Eq. (9), Eq. (10), Eq. (11) and Eq. (12);\n11: Obtain the dominant assignment by applying k-means to the representations of the dominant view by Eq. (13);\n12: Compute the soft alignment distribution Qu and the target distribution PU for each view by Eq. (14) and Eq. (15);\n13: Obtain the final node representation Z = [Z\u00b9,\u2026\u2026\u2026, ZV] by concatenating representations from all views;\n14: Apply k-means on the final representation Z and compute Q and P distribution of Z;\n15: Calculate the self-training clustering loss LCLU by Eq. (16);\n16: Compute the overall objective L by Eq. (17);\n17: Back-propagate L to update model weights;\n18: end while\n19: Apply k-means on the final node representation Z to obtain the clustering results;\nOutput: The final node representation Z and the clustering results.\nB Detailed Proofs\nData Assumption. A multi-relational graph G has N nodes partitioned into 2 equally sized communities C\u2081 and C2. Let C1, C2 E {0, 1} be indicator vectors for membership in each community, that is, the jth entry of ci is 1 if the jth node is in C\u00a1 and 0 otherwise. G has V views, each is generated by SBM [1], with intra- and intercommunity edge probabilities pu and q. G is such a graph model with a feature matrix X = F + H \u2208 RN\u00d7df, where each column of H follows a zero-centered, isotropic Gaussian noise distribution N(0, 021) and these columns are mutually independent. The matrix F is defined as F = c1p] + c2p2, where \u00b51, \u00b52 \u2208 RN has the same Euclidean norm ||\u00b5||, representing the expected characteristic vector of each community. In addition, let p = \u00bd (\u03bc\u2081 + \u03bc2) be the average of the feature vector means.\nLemma 1. Let Xu be the aggregated feature matrix of the v-th view by applying SGC, with the number of hops K, to the expected adjacency matrix \u00c3\u00ba and the feature matrix X. Then, X\u00ba = F\u00b0 +"}, {"title": "5 Theoretical Analysis", "content": "LEMMA 1. Let X be the aggregated feature matrix of the v-th view by applying SGC, with the number of hops K, to the expected\nadjacency matrix \u00c3\u00ba and the feature matrix X. Then, X\u00ba = F\u00b0 +\nc1(0) + c2(02), where F\u00ba = (12)KF + (1 \u2212 (12)K)(1p), \u03b8\u00ba and\n09\u2208 Raf are both distributed according to N(0, (1 + (12)2K)\u03c32\u0399),\nand p-q\n=\n\u2208 [-1,1] is the second largest non-zero eigenvalue\np+q\nof the associated normalized adjacency matrix A\u00ba.\nTHEOREM 1. Let X and X denote the centroid of aggregated features for each community in the v-th view. Then, E [X - X] =\n(12)\u039a (\u03bc1 \u2212\u00b52) andE [XXT - X\u00ba (X\u00ba)] = 1-(0)2K (1||12 -\u03bc \u03bc2)\n(C1C + C2C-C1C \u2013 c2c\u2081) + \u03c9(\u03c3\u00b2), where w(\u03c3\u00b2) represents the\nsum of terms containing o\u00b2 that are of negligible magnitude.\nWe first prove Lemma 1. Since the proof process is identical for\neach view, we omit the superscript v of some view-related symbols\nfor simplicity in the proof.\nPROOF OF LEMMA 1. In expectation, an entry Aij of the adjacency matrix of the graph is p if both i, j\u2208 C\u2081 or both i, j \u0454 \u04212, and it is q otherwise. The eigendecomposition Qdiag(2)QT of the associated normalized adjacency matrix A has two non-zero eigenvalues: \u03bb\u2081 = 1, with eigenvector q1 = 1 = (C1 + c2), and 2 =\n+, with q2 = \u8d64(C1 - C2).\nZero-centered, isotropic Gaussian distributions are invariant to rotation, which means QTH.,i ~ N(0, \u03c3\u00b21) for any orthonormal matrix Q, so X can be expressed as follows:\nX = AK X\n= Qdiag(\u03bb)KQT (c\u2081\u03bc\u2081 + c2p2 + H)\n= q1q1 (c1] + c2p2 + H) + q2q2 (c\u2081\u03bc + 2\u03bc2 + H)\nT\nVN(+)+ 92 (+)++\ub9ac 92 (-)+=+=(1+2)+(1-(1-)+=+-(c1 + c2) (\u03bc\u2081 + \u03bc2)+2(h\u2081\u2082= F + (1 \u2212 1)1\u03bc\u00af + c10] + c202\n(18)\nPROOF OF THEOREM 1. Based on the Lemma 1, we can obtain the\nfollowing.\nE [\u00d1\u00ba [X - \u00d1\u00ba] X] = E \u314c [\u00b5\u2081 + (1 -\u03bb) \u03bc+01]\n- \u0395\u03bb\u03bc2 + (1-\u03bb) \u03bc+02]\n= \u03bb (\u03bc1 \u2212 \u03bc2)\n(19)\nSimilarly, we can formulate the expression for E [XX\u2122 \u2013 X\u00ba (X\u00ba)T]\nas follows:\nMM '24, October 28-November 1, 2024, Melbourne, VIC, Australia."}, {"title": "Synthetic Datasets", "content": "We propose the multi-relational cSBM to generate imbalanced multi-relational graphs. We first introduce the data generation process of cSBM. Here, N denotes the number of nodes, and all nodes are divided into two classes of equal size with node labels yi \u2208 {-1, +1}. Each node possesses a df-dimensional feature vector, obtained by random sampling from class-specific Gaussian distributions, as follows:\nX\u2081 =\n\u03bc\nYiu- +\nN\nHi\n\u221aaf\ndf\n(21)\nwhere u ~ N(0,I/df) and Hi \u2208 Rdf has independent standard normal entries. The adjacency matrix A of the generated cSBM graph is defined as:\nP [\u00c4ij = 1] =\nd+ \u221ad\nN\nd - \u221ad\nN\nif Yiyj > 0\n(22)\notherwise.\n2\narctan(AVE)\n\u03bc\nwhere d is the average degree of the generated graph. Note that \u03bb and u are hyper-parameters to control the proportion of contributions from the graph structure and node features, respectively. In cSBM, the parameter $ =\n\u2208 [-1,1] controls the\ndegree of homophily, where \u00a7 = }} is a control factor. A larger |6|\nimplies that the graph can provide stronger topological information, whereas when 4 = 0, only the node features are informative. The parameters of cSBM should satisfy the constraint ^\u00b2 x\u00b2+ + 4 = 1 +\u20ac, \u20ac > 0 to generate informative graphs. We follow [4] for cSBM parameter settings, using N = 5000, df = 2000, d = 5, \u20ac = 3.25.\nTo generate multi-relational graphs, we first create a label indicator vector and feature matrix for nodes. We then use cSBM to generate V graphs with different structures but the same & value ($ = 0.5). Uniform values of $ ensure that the initial graph structures of each view have the same homophily ratio (0.825), further providing an equal level of topological information. We choose V = 3 to enhance realism. To simulate view imbalance among different views, we randomly add noisy edges to two of these graphs to induce perturbations, as mentioned in the main text.\nD Additional Experiments\nWe add an experiment to demonstrate the effectiveness of ACD and its superior reliability compared to the existing supervised metric, the homophily ratio. We use the cSBM generative model to produce a series of graphs sharing the same node features and achieve various structures solely by adjusting the f value. 30% of the nodes are randomly selected as the training set, with the rest forming the testing set. A linear layer is used as the classifier for view-specific features.\nTable 5 clearly shows that ACD is positively correlated with classification accuracy, which empirically proves the effectiveness"}, {"title": "5 Real-world Datasets", "content": "We employ five publicly available real-world benchmark datasets and a large-scale dataset. ACM [5", "7": "and DBLP [41", "18": "and Amazon [9", "33": "is a large-scale citation network. The statistics of these datasets are presented in Table 6.\n\u2022 ACM contains 3,025 papers with graphs generated by two meta-paths (paper-subject-paper and paper-author-paper). The feature of each paper is a 1,870-dimensional bag-ofwords representation of its abstract. Papers are categorized into three classes, i.e., database, wireless communication, and data mining.\n\u2022 DBLP contains 4,057 papers with graphs generated by three meta-paths (author-paper-author"}]}