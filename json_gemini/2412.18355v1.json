{"title": "Addressing Spatial-Temporal Data Heterogeneity in Federated Continual Learning via Tail Anchor", "authors": ["Hao Yu", "Xin Yang", "Le Zhang", "Hanlin Gu", "Tianrui Li", "Qiang Yang", "Lixin Fan"], "abstract": "Federated continual learning (FCL) allows each client to continually update its knowledge from task streams, enhancing the applicability of federated learning in real-world scenarios. However, FCL needs to address not only spatial data heterogeneity between clients but also temporal data heterogeneity between tasks. In this paper, empirical experiments demonstrate that such input-level heterogeneity significantly affects the model's internal parameters and outputs, leading to severe spatial-temporal catastrophic forgetting of local and previous knowledge. To this end, we propose Federated Tail Anchor (FedTA) to mix trainable Tail Anchor with the frozen output features to adjust their position in the feature space, thereby overcoming parameter-forgetting and output-forgetting. Moreover, three novel components are also included in FedTA: Input Enhancement for improving the performance of pre-trained models on downstream tasks; Selective Input Knowledge Fusion for fusion of heterogeneous local knowledge on the server side; and Best Global Prototype Selection for finding the best anchor point for each class in the feature space. Extensive experiments demonstrate that FedTA not only outperforms existing FCL methods but also effectively preserves the relative positions of features, remaining unaffected by spatial and temporal changes.", "sections": [{"title": "1 Introduction", "content": "Data heterogeneity across different clients (Non-IID) is one of the most important challenges in traditional Federated Learning (FL), which greatly hinders the integration of knowledge, leading to the aggregated global model underperforming on local tasks. Many studies have attempted to address this issue and have made some progress [1-3]. However, they are based on an unrealistic static assumption that the training data of all clients will remain unchanged. Federated Continual Learning (FCL) breaks the static limits by allowing clients to continually accumulate knowledge from task sequences [4, 5]. While FCL expands the applicability of FL in real-world scenarios, it also introduces a more challenging issue, i.e., spatial-temporal data heterogeneity. Not only is the data heterogeneous across different clients (spatial), but also the data within different tasks of the same client is heterogeneous (temporal), as shown on the left side of Fig. 1."}, {"title": "2 Related Work", "content": "Spatial data heterogeneity, as known as the Non-IID problem, has attracted much attention [15, 16, 2, 17]. Existing methods tackle data heterogeneity by either incorporating more effective local training or devising more comprehensive aggregation mechanisms [18].\nAlthough these studies have made progress in overcoming spatial data heterogeneity, they are unable to cope with more realistic and dynamic scenarios where each client continually learns on their own task stream.\nFCL has indeed greatly enhanced the practical value of FL in real-world scenarios, especially on the edge computing side [19, 20]. It allows each client to rapidly learn knowledge from the current task without forgetting previously knowledge, thus avoiding the need to retrain from scratch and greatly saving computational resources.\nExisting FCL papers have achieved promising results. FedWeIT [4] decomposes parameters into local, global-based and task-adaptive parts to address both practical and pathological data heterogeneity in FCL. GLFC [21] utilizes a class-aware gradient compensation loss and a class-semantic relation distillation loss to mitigate forgetting, and a proxy server to alleviate data heterogeneity. TARGET [22] generates synthetic data on the server and adopts knowledge distillation to alleviate forgetting of previous tasks. MFCL [5] trains a generative model in a data-free manner on the server and generates synthetic data via this model to mitigate forgetting and preserve data privacy.\nIn a survey paper on FCL, the authors identified a key issue that existing FCL articles have overlooked: the interaction between spatial heterogeneity and temporal heterogeneity, which leads to a unique challenge: spatial-temporal catastrophic forgetting (ST-CF) [6]. It means that models not only forget previous knowledge due to continual learning but also forget local knowledge due to federated aggregation. Existing FCL methods do not realize that spatial heterogeneity can exacerbate the temporal forgetting, so when the spatial heterogeneity becomes stronger, the performance is not as expected. Besides, effective FCL methods currently heavily rely on replaying or generating pseudo data to mitigate the effects of spatial-temporal data heterogeneity [22, 5, 23-26]. However, this may pose certain privacy risks and incur high computational cost.\nOnly a very small portion of work has attempted to address data heterogeneity from time and space simultaneously now [27, 28]. However, none of them have delved into how this heterogeneity leads to forgetting, nor have they ensured sufficiently strong spatial-temporal heterogeneity in their experimental settings. To our best knowledge, we are the first to deeply analyze how the heterogeneity of inputs affects model parameters and outputs."}, {"title": "3 Spatial-Temporal Data Heterogeneity", "content": "The purpose of Spatial-Temporal Data Heterogeneity is to continually integrate knowledge from different clients and different time periods. We extend the traditional FL to FCL with strong spatial-temporal data heterogeneity.\nFor spatial heterogeneity, given a clients (denoted as $A = {A_1, A_2, . . ., A_a }$), and a central server S, each client's data is composed of private classes $C_p$ and public classes $C_p$, where private classes refer to the class of data that can only be seen by the client itself. We ensure that the data of $C_p$ is non-overlapping between clients. Further, we can set $|C_p| = 0$ to ensure extreme spatial heterogeneity. We run experiments with $|C_p| = 0$ on Imagenet-R dataset.\nFor temporal heterogeneity, the task sequence of client $A_i$ is denoted as $T_i = {T_i^1,T_i^2,\u2026\u2026\u2026,T_i^{n_i} }$, where $n_i$ represents the total number of tasks on client $A_i$. Each task consists of the same number but entirely different classes."}, {"title": "3.2 Negative Impact", "content": "Spatial-temporal data heterogeneity is a type of heterogeneity in model inputs. Due to the back- propagation mechanism, it would significantly affect the internal parameters of the model and the outputs [29]. It not only introduces differences between models of different clients but also causes the features output by the same sample to undergo significant changes, thereby causing spatial-temporal forgetting of previous knowledge and local knowledge.\nLet's delve even further into the effects of spatial-temporal data heterogeneity. For deep neural networks, changes at the input level directly affect model parameters and corresponding outputs, thereby causing continual variations of the feature space. For spatial data heterogeneity, the absence of a common feature space among clients makes it challenging to share heterogeneous knowledge. For temporal data heterogeneity, changes in the feature space over time lead to variations in the locations of features of the same samples. If we can address the issues mentioned above simultaneously, then spatial-temporal catastrophic forgetting will be resolved."}, {"title": "3.3 Motivation", "content": "Based on the above analysis, it is evident that spatial-temporal data heterogeneity leads to both parameter-forgetting and output-forgetting. Therefore, to effectively handle spatial-temporal data heterogeneity, methods need to possess the following three capabilities: (1) Ensure that the model extracts nearly identical features for the same sample; (2) Fix the positions of extracted features in the feature space. (3) Allow clients to have a common feature space to better utilize heterogeneous knowledge.\nHowever, due to the training method of deep networks and the large number of parameters involved, parameter updates are uncontrollable, making it nearly impossible to mitigate parameter-forgetting. Similarly, since ensuring consistency within the parameters is impossible, it is also hard to guarantee the invariance of outputs in the feature space.\nPre-trained large models have attracted considerable attention due to their powerful representation capabilities. There are already articles attempting to apply pre-trained ViT to the traditional continual learning to overcome forgetting [30, 31]. Inspired by this, we find that freezing the feature extractor of pre-trained ViT can effectively eliminate parameter-forgetting. In FCL, clients share the same pre- trained model, ensuring that they have the same knowledge/feature space, which makes knowledge transfer between clients easier. Furthermore, by mixing learnable parameters (referred to as \"tail anchor\" in this paper) with frozen features, we can effectively control their positions in the feature space, thus addressing output-forgetting. The server is responsible for selecting anchor points with the lowest similarity to other classes' anchor points, which will be used as the global anchor point of a class in the feature space. When training the tail anchor on the client side, it will converge towards the anchor point of each class. Therefore, we mitigate the performance degradation caused by parameter-forgetting and output-forgetting induced by spatial-temporal data heterogeneity."}, {"title": "4 Methodology: FedTA", "content": "To address the spatial-temporal catastrophic forgetting caused by the heterogeneity of spatial-temporal data heterogeneity, which includes parameter-forgetting in the feature extractor and output-forgetting in the feature space, we propose Federated Tail Anchor (FedTA). Its aim is to leverage a frozen pre-trained model and cross-mix learnable parameters after the output features, ensuring that the position of features in the feature space remains fixed and unaffected by spatial-temporal changes.\nSpecifically, each client has a ViT pre-trained on ImageNet-21K as the foundation model, with all parameters frozen, ensuring that the feature space across all clients remains entirely consistent and unchanged. On the client side, we design two components: Input Enhancement to enhance the performance of the pre-trained ViT on the chosen datasets (Sec. 4.1) and Tail Anchor to control the distance (i.e., similarity) between output features (Sec. 4.2). On the server side, we have two modules designed for aggregating knowledge extracted from client inputs and outputs, respectively. Selective Knowledge Fusion is used to merge the knowledge applied to inputs accordingly (Sec. 4.3). Best Global Prototype Selection iteratively chooses the prototype with the lowest average similarity from the class prototypes uploaded by clients as the global prototype. When the average similarity drops below a threshold, it is fixed and becomes an anchor point in the feature space (Sec. 4.4)."}, {"title": "4.1 Input Enhancement", "content": "Inspired by the cognitive processes of humans, knowledge transfer among humans is effective because there is a fundamental shared cognition, enabling the meaningful exchange of knowledge. Therefore, we assign each client with the same pre-trained ViT model as a foundational cognitive system. With ViT's parameters frozen, clients learn common knowledge that operate at the input level. The purpose is to extract knowledge into a common space through the same model and enhance ViT's performance.\nKnowledge Base. We devise a knowledge base for storing and selecting the input enhancement parameters. The knowledge base of client i is defined as\n$KB_i = {IE_1, IE_2, ..., IE_M },\\qquad(1)$\nwhere M is the base size and IE is a set of learnable parameters. Then, let x and E = fe(x) be the input and its corresponding embedding feature, respectively. Denoting ${i}$ be the indices of N\nsets, then we can modify the embedding feature as follows:\n$E' = [IE_{s_1},...,IE_{s_N}; E],1 \\leq N \\leq M,\\qquad(2)$\nwhere [;] represents concatenation along the token length dimension. Each set has a corresponding key, denoted as $K_{ie}$, to facilitate the selection of the parameter set based on the similarity of keys.\nOptimization for the input enhancement. Each client has a classification head used for training input enhancement parameters, denoted as H. At the beginning of training, it is necessary to load the pre-trained model with H to enable it to perform the classification task, and we denote the model with H_e as V_e. Overall, the training loss function is as follows:\n$\\min L(V_e(E'), y) + \\lambda_1 \\sum_{K_{ie}} dis(K_{ie}, K_{ie}^{*}),\\qquad(3)$\nwhere $\\lambda_1$ is a hyperparameter, $K_{ie}^{*}$ and $K_{ie}$ are used to find the best input enhancement parameter sets. The initial term comprises the softmax cross-entropy loss, while the subsequent term serves as a surrogate loss aimed at bringing selected keys closer to their corresponding query features. Cosine similarity is used as the distance function."}, {"title": "4.2 Tail Anchor", "content": "Query function. Once the input enhancement parameters are well trained, they will be frozen, including their corresponding keys, until the next task training. The enhanced input embedding would be processed by the frozen ViT again to get the features, denoted as F_out. Then it will be used as the key to find the corresponding tail anchor based on the cosine similarity. We associate each tail anchor with a learnable key, denoted as $TA = {(K_{ta}^{1}, TA_1), (K_{ta}^{2}, TA_2),..., (K_{ta}^{m}, TA_m)}$. TA is a parameter set with the same shape as F_out, so it can easily be mixed with F_out. Then, the query process can be summarized by the following expression:\n$K_{ta}^{*} = argmin dis(F_{out}, K_{ta}),\\qquad(4)$\n$K_{ta}$\nwhere $K_{ta}^{*}$ denotes the chosen tail anchor's key, and Kta represents the set of keys for all tail anchors. Notice that this querying method is also used to select the parameter sets for input enhancement.\nOptimization for the tail anchor. Once the tail anchor is chosen, it will be frozen and mixed with F_out to form a new feature FTA. If a client has global prototypes (i.e., not the first round), then contrastive learning is utilized to unify the features across clients through the following unified representation loss function:\n$L_{cons} (F_{TA}) = -log\\frac{exp (F_{TA} \\cdot G_{Y_t} / \\tau)}{\\sum_{y_a \\in Y_t} exp (F_{TA} \\cdot G_{Y_a} / \\tau)},\\qquad(5)$\nwhere $Y_t$ represents the global available classes up to task t and $G_y$ represents the global prototypes of class y. $\\tau$ denotes the temperature that controls the tolerance of difference between extracted features and the corresponding global prototype. The overall loss function to optimize the tail anchor can be formulated as follows:\n$L_{ta} = L_{CE}(F_{TA}) + \\lambda_2 L_{cons} (F_{TA}) + \\lambda_3 dis(F_{TA}, K_{ta}^{*}),\\qquad(6)$\nwhere $L_{CE}$ is the standard cross-entropy loss.\nLocal prototypes. Once the training process of the tail anchor is done, the tail anchors will be frozen and remain unchanged. The local prototype is obtained by averaging features with tail anchors belonging to the same class, computed through\n$\\frac{1}{|D^y|} \\sum_{(x,y) \\in D^y} F_{TA_i},\\qquad(7)$\nwhere $D^y$ denotes the subset of private dataset of client a of class y. Each client forms a local set of prototypes, which is then uploaded to the server. The server iteratively selects the prototype with the lowest average similarity as the global prototype for that class."}, {"title": "4.3 Selective Input Knowledge Fusion", "content": "To fuse the input enhancement knowledge more precisely, we devise a novel selective Input Knowl- edge Fusion mechanism that aggregates knowledge base from different clients through knowledge distillation, enhancing their generalization. To our knowledge, it is a novel approach to distill knowledge of input from different clients.\nWe follow a common setting, which allows the server to possess a small-scale surrogate dataset, denoted as $D_s$. {$X_s, Y_s$} are the samples and corresponding labels from $D_s$, for the distillation process. For the convenience of writing and understanding, we will only consider two input enhancement knowledge base here, denoted as $KB_i$ and $KB_j$. KB_i is chosen as the student pool. Initially, the input $x_s$ searches for the corresponding input enhancement within KB_i, and then concatenates to form an embedding $E'_i$. Similarly, $E'_j$ represents the embedding of the same input but concatenated with the input enhancement from KB_j. Therefore, the distillation loss can be formulated as follows:\n$L_{KD} = MSE (V(E_i'), V(E_j')),\\qquad(8)$\n$X_s \\in D_s$\nwhere $V(E_i')$ represents the feature of $E'_i$ though ViT."}, {"title": "4.4 Best Global Prototype Selection", "content": "When the server receives local prototype sets from different clients, it reorders them to form a new set $P_G$ according to the class. Specifically, when two clients both have prototypes related to class q, denoted as $P_i^q$ and $P_j^q$, they will be adjacent to each other in the reordered prototype set. Then, the server computes the similarity between each pair of sets in the collection, forming an adjacency matrix M. The element of M is computed through:\n$M_{ij} = dis(P_i^q, P_j^q), 0 < i \\leq j \\leq |P_G|.\\qquad(9)$\nNotice that if $P_i^q$ and $P_j^q$ belong to same class, then $M_{ij}$ = 1. In each round, the server selects the prototype with the lowest average similarity with all local prototypes as the global prototype for one class. The selection process of the global prototype G for class y can be expressed as follows:\n$G^y = P_o^y = \\underset{P_i^y \\in P_G}{argmin} \\frac{1}{Y_{high} - Y_{low} + 1}\\sum_{j=Y_{low}}^{Y_{high}} M_{ij}\\qquad(10)$\nwhere $Y_{low}$ and $Y_{high}$ are the start index and end index of the local prototypes of class y in $P_G$. $P_o^y$ is the local prototype who has lowest similarity for class y. If the average similarity M_i falls below the threshold Thr during the iteration process, then that prototype is fixed as the global prototype for its class and will not be altered further. As a result, this global prototype will serve as a fixed anchor point for that class in the feature space."}, {"title": "5 Experiments", "content": "To verify whether the method can effectively address the challenges brought by spatial-temporal data heterogeneity, we use two new metrics from [6] to evaluate the performance of mitigating forgetting.\nDefinition 1. (Temporal Knowledge Retention):\n$KR_t = \\frac{1}{a} \\sum_{i=1}^{a} \\frac{Acc(\\theta_i^r; T_i^0)}{Acc(\\theta_i^0; T_i^0)},\\qquad(11)$\nwhere $Acc(\\theta_i^r; T_i^0)$ denotes the test accuracy of client $A_i$'s local model at r-th round on the 0-th task and $Acc(\\theta_i^0; T_i^0)$ denotes the accuracy of client $A_i$'s local model at the initial round on the 0-th task."}, {"title": "5.2 Metrics", "content": "Definition 2. (Spatial Knowledge Retention):\n$KR_S = \\frac{1}{a} \\sum_{i=1}^{a} \\frac{Acc(\\Theta^r; T_i^r)}{Acc(\\theta_i^r; T_i^r)},\\qquad(12)$\nwhere $Acc(\\Theta^r; T_i^r)$ denotes the accuracy of the global model $\\Theta^r$ on the current local task $T_i^r$ at client $A_i$ and $Acc(\\theta_i^r; T_i^r)$ denotes the accuracy of the local model $\\theta_i^r$ on its current local task $T_i^r$."}, {"title": "5.3 Results & Ablation Study", "content": "Table 1 illustrates the average accuracy of the aggregated global model on local test sets. The performance of FedViT is acceptable because all the parameters of its feature extractor are frozen, and only the classification head is involved in training and aggregation. However, it still experiences a certain degree of forgetting. FedL2P and FedDualP, which introduce trainable parameters on the input side and within the model, perform very well on the local side, achieving around 90% accuracy. However, as we concluded in Sec. 3.2, almost all trainable parameters are directly affected by the data. Consequently, after aggregation, there is significant forgetting on the local test sets.\nSurprisingly, the performance of TARGET, FedLwF and MFCL, the three baseline methods that use replay data to mitigate forgetting, is extremely poor. We speculate that the large size of data (3\u00d7224x224) results in the low quality of replayed pseudo-samples. Moreover, replay-based methods pose a certain risk of privacy leakage in federated learning, limiting the further application of these methods in real-world scenarios. GLFC, the most representative baseline method in FCL, also suffers significant performance degradation when faced with severe spatial-temporal data heterogeneity. However, its performance in Table 1 remains the best among the baseline methods.\nFedTA demonstrates the superior performance in these two settings, indicating its successful mitigation of the impact of spatial data heterogeneity. Furthermore, ablation studies highlight the effectiveness of the proposed novel components, with the Tail Anchor contributing the most to the performance improvement. However, the selective input knowledge fusion at the server-side sometimes falls below the results of direct weighted averaging on ImageNet-R. We believe this is due to insufficient surrogate data, which prevents adequate selective knowledge fusion."}, {"title": "Visualization & Sensitivity Analysis", "content": "Fig. 5 illustrates that FedTA can effectively control the relative distances between features, ensuring that even after spatial-temporal changes, their positions in the feature space do not experience significant shifts."}, {"title": "5.4 Privacy & Efficiency Analysis", "content": "Computational Burden. During the local training phase, clients train both the Input Enhancement and Tail Anchor components while the ViT itself remains frozen. Therefore, the number of parameters in these two components, along with the classification head, determines the training overhead of FedTA. The size of Input Enhancement is determined by the number, length and embedding dimension, which are set to 10, 10, and 768 in our setting. The size of the Tail Anchor is set to 100\u00d7768. The total size of keys is (100+10)\u00d7768. Therefore, the total number of trainable parameters amounts to 253,440. Compared to a ResNet-18 with 11,306,804 parameters, FedTA is efficient.\nCommunication Cost. Each client only needs to submit its own input enhancement and local proto- types to the server, with sizes of 76,800 and 768\u00d72 per class, respectively. Such small communication cost makes FedTA highly efficient, and also makes FedTA scalable for multi-clients.\nPrivacy Protection. For Input Enhancement, on the one hand, ViT is frozen, and on the other hand, due to its minimal number of parameters, it contains extremely little information. Moreover, since this method does not use replay data to alleviate forgetting, privacy protection is further strengthened. However, the uploaded local prototypes are class-specific, and employing cross-mixing might easily reveal the original features, posing a certain degree of privacy risk. If we randomly mix Tail Anchor with features, this issue will be resolved."}, {"title": "6 Conclusion", "content": "This article extends the issue of data heterogeneity in static FL to the more realistic problem of spatial-temporal data heterogeneity in FCL. Empirical experiments are conducted to demonstrate that spatial-temporal data heterogeneity can cause parameter-forgetting and spatial forgetting. Based on this finding, FedTA utilizes a frozen pre-trained ViT to overcome parameter-forgetting and mixes Tail Anchors with the output features to adjust their positions in the feature space in order to address output-forgetting. Extensive experiments have verified the superiority of our method, and ablation studies demonstrate the effectiveness of each component, especially Tail Anchor. Finally, the visualized results demonstrate that our method effectively fixes the features' relative positions, preventing them from being affected by spatial-temporal changes."}]}