{"title": "What We Talk About When We Talk About LMs:\nImplicit Paradigm Shifts and the Ship of Language Models", "authors": ["Shengqi Zhu", "Jeffrey M. Rzeszotarski"], "abstract": "The term Language Models (LMs), as a time-\nspecific collection of models of interest, is con-\nstantly reinvented, with its referents updated\nmuch like the Ship of Theseus replaces its parts\nbut remains the same ship in essence. In this pa-\nper, we investigate this Ship of Language Mod-\nels problem, wherein scientific evolution takes\nthe form of continuous, implicit retrofits of key\nexisting terms. We seek to initiate a novel per-\nspective of scientific progress, in addition to\nthe more well-studied emergence of new terms.\nTo this end, we construct the data infrastructure\nbased on recent NLP publications. Then, we\nperform a series of text-based analyses toward\na detailed, quantitative understanding of the use\nof Language Models as a term of art. Our work\nhighlights how systems and theories influence\neach other in scientific discourse, and we call\nfor attention to the transformation of this Ship\nthat we all are contributing to.", "sections": [{"title": "1 Introduction", "content": "Scientific publications expand exponentially, with\nthe size of literature doubling every ~17 years (For-\ntunato et al., 2018; Bornmann et al., 2021). The\nfield of CL/NLP is no exception; in fact, the dou-\nbling only took 5 years: As of 2023, the number\nof papers documented in the ACL Anthology is\ntwice as much as the total by 2018 (Bollmann et al.,\n2023; Zhao et al., 2023). With the explosion of new\npublications, it is imperative but also increasingly\nchallenging to sort out the major contexts, progress,\nand future directions of the field.\nResearchers have sought to identify emergent\nkey terms and factors that led to disruptive shifts\nof paradigms (Uban et al., 2021; Pramanick et al.,\n2023; Kuhn et al., 2014). In this period of flux,\nhowever, an ever-evolving field like ours calls for\ndeeper analysis beyond identifying these elements,\nin order to understand various quantitative ques-\ntions regarding these rapid and disruptive shifts.\nFor instance, to what extent is the field transformed\nby any certain model, like ChatGPT (OpenAI,\n2022)? How does the popularity of the latest GPT\nmodels compare with, say, that of BERT (Devlin\net al., 2019) in 2020? From there, we might even be\ncurious about bigger questions like, \u201cHow unprece-\ndented really is ChatGPT?\u201d, where our empirical\nguesses can diverge drastically without sufficient\nquantitative evidence. While readers of this paper\nlikely come in with a tacit understanding of the ebb\nand flow of the field, it is hard to nail down such\nfactors that keep changing in publications.\nMore fundamentally, the narrative describing sci-\nentific progress as the emergence of new elements\ndoes not cover the more implicit paradigm shifts,\nwhich features the evolution instead of invention of\nterms. The (forms of) key terms may continue to\nbe broadly used, but are gradually overwritten with\nnew meanings in new contexts. Language Models\n(LMs), as a term of art, refers to no single, static\nthing. It is used referentially to index a collection\nof models deemed relevant and representative at\nthe time or in the context of a paper. As this is ever-\nchanging, we are faced with a Ship of Theseus sce-\nnario (Plutarch), wherein the same terminology is\nessentially re-invented and its referents are perhaps\nentirely replaced. As such, a subtle gap between\nthe durable collective term of \"LMs\" and the time-\nspecific referent models of the moment is widening\nas the field progresses, threatening its stability and\naccessibility to new researchers. These issues call\nfor new analyses of the subtle transformations that\nresult from these paradigm shifts.\nIn this paper, we seek a quantitative description\nof a field's continuous evolution. More specifi-\ncally, we inquire into the Ship of LMs paradox, i.e.,\nthe aforementioned reconstruction of the term Lan-\nguage Models. We decipher this evergreen term's\nrapidly changing referents, contexts, and usages\nacross time. We develop a semi-automatic, gen-\neralizable framework to extract and organize two"}, {"title": "2 Related Work", "content": "Diachronic Analysis of the Progress in NLP\nVarious studies review the history of NLP confer-\nences and the ACL Anthology (Hall et al., 2008;\nAnderson et al., 2012; Bollmann et al., 2023), as\nwell as the community that contributed to the field's\ntrajectory (Abdalla et al., 2023; Movva et al., 2023).\nOther works identified the field's transition points\nand themes. Hou et al. (2019) proposes an au-\ntomatic framework to extract key entities (tasks,\ndataset, etc.). Uban et al. (2021) explores a simi-\nlar goal via topic modeling, and Pramanick et al.\n(2023) further identified such entities that causally\nshaped the field's important stages. More recently,\nthere has also been a specific focus on the changes\nbrought by LLMs (Min et al., 2023; Fan et al.,\n2023; Zhao et al., 2023) and the impact on the re-\nlated communities (Saphra et al., 2023; Liang et al.,\n2024). Aside from text-based analysis, interviews\nand surveys (Gururaja et al., 2023; Michael et al.,\n2023, etc.) have also provided valuable qualitative\ninsights for the disruptive shifts.\nParadigm Shifts and Scientific Trends have\nalso been core topics in the broader Science of Sci-\nence field (Fortunato et al., 2018) beyond CL/NLP.\nThe existing literature mostly centers on the emer-\ngence of new, trending ideas as well as their dynam-\nics across the author networks. For instance, Kuhn\net al. (2014) identified text snippets that are largely\ncited by future works, coined scientific memes, on\ncitation graphs; Cheng et al. (2023) explored the\ndiffusion process of new ideas under various social\nfactors; and Chu and Evans (2021) measured the\nrelation between the speed of producing new ideas\nand the size of a field. Citation/Author networks\nhave also been introduced by recent works (Mo-\nhammad, 2020; Wahle et al., 2023) as a method for\nthe more specific background of the NLP field.\nOur work provides a complement to these ongo-\ning threads. As discussed, we raise a novel scenario\nabout the transitions within a lasting concept (Ship\nof LMs), which to our knowledge has not been ex-\nplored. We examine the use of such terms as LMs,\nproviding quantitative interpretations of how (and\nhow much) our beliefs and common grounds have\nevolved. In some sense, our work can be also seen\nas a meta-analysis of the various works studying\ncertain elements (e.g. \"the era of LLM\", \"stages\nof statistical Machine Translation\u201d, \u201cChatGPT's\nimpact\", etc.) We integrate these valuable findings\nto highlight a new question about the procedures:\nhow exactly did we forge these of key elements into\npractice and eventually to our norms of language?\""}, {"title": "3 Methods", "content": "3.1 Dataset Construction\nFollowing common practice in prior work (Moham-\nmad, 2020; Pramanick et al., 2023), we utilize the\nofficial ACL Anthology as our data source. We\ncollect papers accepted to the main Proceedings\nof three major NLP conferences (ACL, EMNLP,\nNAACL) held annually. We first interact with the\nAPI to fetch metadata (e.g., Anthology ID, title,\nand abstract). Based on the index of a conference,\nwe obtain the paper PDFs from the formatted An-\nthology URLs, and scan the text with the pypdf2\ntools. For post-processing, we remove excessive\nformatting (e.g. conference names in the footers)\nand identify section titles with regular expressions.\nThe resulting dataset contains in total 7,650 pa-\npers from 10 conferences sequentially from ACL\n2020 to EMNLP 2023. Our analyses focus on this\nmost recent 4-year window where the advances\nregarding LMs have been especially pronounced,\nwhile our methodologies can similarly extend to a\nbroader range.\nDefault Setup We extract the body text by cutting\noff before the References section. This is marked\nas our default setup, and experiments are based on\nthe default unless otherwise noted."}, {"title": "3.2 Retrieving the Mentions of LMs", "content": "To investigate the Ship of LMs problem, we start\nby extracting and analyzing keywords and relevant\nentities, a common backbone method for analy-\nsis (Hou et al., 2019; Pramanick et al., 2023). For\na sample paper to be related to LMs, the writing\ncould utilize two types of mentions: (1) the collec-\ntive concept of \u201clanguage models\", implying the\ncontext as a generalizable discussion, and (2) the\nnames of specific models, indicating what models\nare exactly considered in a limited scope.\nOur goal is to maintain two keyword sets that cor-\nrespond to the two types. Thus, we can resolve the\nreferents of the generic language model mentions\nto the specific models used, by locating, linking,\nand comparing the keywords from both sets.\n3.2.1 Notations\nAs described, we seek to build two related collec-\ntions of key entities, one marking the mentions\nof LMs as a general term, and the other marking\nspecific model names. The two are respectively\ndenoted by L (from LMs) and M (from Models).\nIn practice, L converges to a small, well-\nrecognized set of terms. We define\n$\\L$ = {language model, LLM, PLM}\nsince \"language model\" is the substring of most\nof its subcategories, e.g., \u201clarge language models\",\n\"Korean language models\", or \"language model-\ning\", and searching for \u201clanguage model\" covers\nall such variations. We also include the most com-\nmon acronyms, \u201cLLM\u201d (Large Language Models)\nand \"PLM\u201d (Pre-trained Language Models). The\nconstruction of M is elaborated in \u00a73.2.2.\nWe use $m$ to represent a specific element from\n$M$ (e.g., $m =$ BERT). For a span of text, $s$, we\nhave $M(s)$ representing the subset of elements\nfrom $M$ that indeed appear in $s$. While $M(\u00b7)$\nis a function of the input text by definition, we omit\nthe input when $s$ is the entire body (default setup)\nfor simplicity, and write the subset as $M$. The\nomission applies similarly to the notations below.\nTo initiate our study on any individual paper and\nany model(s) of interest, we introduce a family of\ncounting functions. Given a model name $m$, we\ndefine $N_m(\u00b7)$ as the count of how many times $m$\nappears in the input text. The counting functions\nalso apply to sets of model names: For a set of\nmodels $\\mathcal{M} = \\{m_1, m_2, ..., m_k\\}$, we have\n$N_{\\mathcal{M}} = \\sum_{i=1}^{k} N_{m_i}$\nThus, $\\mathcal{M}$ can now be formally defined as\n$\\mathcal{M} = \\{m | N_m > 0, \\forall m \\in M\\}$\nAdditionally, given its importance, we mark the\ncount of all model names in a paper as\n$N := N_{\\mathcal{M}} = N_{\\mathrm{M}}$\nSimilarly for the other keyword set of general LM\nmentions, we denote the total count of all elements\nin $\\mathcal{L}$ as $N_\\mathcal{L}$. We mark $\\mathcal{L}$ as superscript for an ex-\nplicit distinction with the $N_m$ family. The total\ncounts $N_\\mathcal{L}$, $N$, and the $N_m$ family serve as essen-\ntial cornerstones of our approach since they are\ndirect indicators of how LMs are discussed and\nresolved. These patterns from independent works\nbecome the changing constituents of the Ship."}, {"title": "3.2.2 Constructing M from the text", "content": "To construct a comprehensive dictionary of specific\nmodel names, we established a human-AI workflow\nto extract and register model names at scale. We\ndesigned a detailed in-context prompt for a state-of-\nthe-art LLM to detect model names from the title\nand abstract of papers. All detected names from the\nfull dataset are collected and ranked by frequencies\nas candidates [m1, m2, ...]. Since the same type of\nmodel as referent can have various textual forms,\nwe aim to maintain and distinguish two attributes\n(as lists) for a model m:\n\u2022 Aliases: Different text patterns that all refer\nto m; e.g., both \u201cchatgpt\u201d and \u201cChatGPT\" are\nidentified separately but point to the same\nthing, and we need to count them together.\n\u2022 Variations: Refers to m, but is the exten-\nsion of an existing alias (i.e. having an alias\nas substring). This usually suggests a spe-\ncific variation of m, e.g., \u201cT5-3B"}, {"title": "4 Experiments and Findings", "content": "LMs have been steadily gaining more attention\nfrom the field. Zhao et al. (2023) reports that papers\ncontaining the key phrase \u201cLanguage Model\u201d have\nincreased from less than 400 pre-2019 to around\n10,000 in 2023. We observe a similar trend with a\nfiner-grained search and the focus on main confer-\nence publications in the NLP domain (Figure 2(a)).\nAt ACL 2020, 35% of the papers contain at least\none LM mention from $\\mathcal{L}$ (we refer to this portion as\nLM-related papers). Since then, this proportion\nhas had a smooth, continuous growth of approxi-\nmately 5% (additive) per conference, hitting 84%\njust three years later at EMNLP 2023.\n4.1 Wind in the Sails: Surging Mentions,\nSpeeding Conclusions\nWe begin by querying a fundamental aspect of LMs'\nincreasing popularity: Has our use of the term LM\nalso evolved per se, apart from the background in-\ncrease noted above? As one hypothesis, LMs' pop-\nularity might be attributed mainly to the increase of\nshare. The types of work we do and the context of\nLMs may have not changed significantly \u2013 it's just\nmore authors working on the topic, more resources\nput into it, or other external factors."}, {"title": "What about the actual models we use?", "content": "We consider the average $N_\\mathcal{L}$ of all papers at a\nconference ($N_\\mathcal{L}^C$). If the case above is true, $N_\\mathcal{L}$\nwould remain generally unchanged in both the LM-\nrelated and non-related groups. Thus, the ratio\nof LM-related papers determines $N_\\mathcal{L}^C$, and we can\ndraw an estimate from the scale of the first data\npoint ($N_\\mathcal{L}^C = 4.29$ for 35% at ACL 2020). For\ninstance, 54% of papers at EMNLP 2021 are LM-\nrelated, which is $1.54\\times$ that of ACL 2020 (35%).\nWe scale $N_\\mathcal{L}^C$ with the same ratio, $1.54 \\times 4.29 \\approx$\n6.56, as the estimate for EMNLP 2021.\nFig. 2(b) compares the actual $N_\\mathcal{L}$ and the value\nestimated in this way. This turns out to be a surpris-\ningly good fit for the first half of the data. Within\nthe first 5 conferences, the deviations between es-\ntimated and actual value are consistently less than\n10% and often close to 0, e.g., we estimated 6.56\nfor EMNLP 2021 where the actual value is 6.59.\nFor this period, LMs gained more attention as a\ntopic in this period, but language describing this\nterm remained similar. Metaphorically, the compo-\nsition of the Ship remains the same, but it has more\nwind in its sails.\nHowever, we see a strong deviation from the es-\ntimated growth starting 2022. $N_\\mathcal{L}$ has since been\non a super-exponential growth, eventually being\n80% higher than estimated at ACL 2023 and 168%\nhigher at EMNLP 2023 (where $N_\\mathcal{L}$ nearly dou-\nbled in just half a year). In other words, the Ship\nis not just sailing better (more papers), but it is\nalso undergoing reconstruction (referents of LM\nare changing). The distinct patterns pre- and post-\n2022 despite a similar background increase high-\nlight the necessity to study the Ship of LMs as a\ndynamic concept, as emergence of a term is not\nsufficient for mining the deeper nuances as such.\nThe super-linear increase of $N_\\mathcal{L}$ demands investiga-\ntion into its likely causes. Authors might seek to\ncover more models in more detail, and their writing\nadapts to the strengthened claims, leading to the\ngrowth observed. Alternatively, authors might be\nmore eager to employ trending terms even without\nsignificantly stronger evidence or fit to their work.\nTo this end, we compare how the distributions\nof $N_\\mathcal{L}$ and $N$ change over time in Figure 3. Each\nrow represents a conference and the columns list\nall conferences which occur after it. Grid cells\nare pairs of conferences in comparison. We apply\na Kolmogorov-Smirnov test (Massey Jr, 1951) to\neach pair to determine if there is a significant differ-"}, {"title": "4.2 Oak, Pine, or Cedar Planks: Which\nmodels are we talking about?", "content": "With the exploding usage of the term LMs comes\nwider variation in the use cases and context around\nthem. To go deeper, we must consider what writ-\ners refer to when they include LM in a paper (i.e.,\nwhat the Ship is like at a certain point and how\ndo they [re]build the ship, and not just whether it\nsails.) Based on all individual $N_m$ and the hierar-\nchy of components, we obtain the exact number of\nthe appearances of each model by matching their\naliases in the text. Thus, we put together the collec-\ntive compositions for each conference and visual-\nize them as Sunburst charts, where the component\nsizes correspond to their share. We show a repre-\nsentative comparison of EMNLP 2020 and 2023 in\nFigure 4, and display full results in Appendix B.\nIn 2020, the BERT model alone makes up 41%\nof $N$, and 55% with its dependents (We refer to\na model and all its dependents as a component\nto distinguish a group/family of models from the\nroot model itself.) Other significant components\ninclude RNN (20%), CNN (6%), and GPT (5%).\nAs for 2023, the GPT component (30%) takes the\nlead with the advent of the notable GPT-3 models\n(which formed 71% of all GPT mentions). BERT\nmodels are still the 2nd largest component despite\na reduction to 25%. The results seems to suggest a\nless unipolar composition; in fact, the share of the\nBERT component in 2020 is comparable to the top\ntwo in 2023 combined. We also notice the rise of\nmore recent components, including T5 (12%) and\nLLaMA (7%), while RNN (20% \u2192 2%) and CNN\n(6%\u21921%) saw the most significant decreases.\nHow much remains as the replacement of ear-\nlier components goes on? We calculate Jaccard\nsimilarity to quantify how much is shared between\nthe composition of conferences, shown in Figure 5.\nWe observe that Jaccard similarity between con-\nferences monotonically decreases for subsequent\nconferences, which matches the Ship of LMs case\nwhere constituent parts change over time. For two\nconsecutive conferences, the Jaccard similarity is\nusually only 71% to 85%; the index quickly drops"}, {"title": "One dominant model or many contributors?", "content": "all its specialties. In fact, we even see an opposite\ncase: conferences in 2022 and 2023 - the exact\ntime of the super-linear boosts of $N_\\mathcal{L}^C$ \u2013 contain\nsignificantly fewer model mentions than before. In\nother words, we arrive at the conclusions faster:\nthe information conveyed via specific models has\nnot increased, but more is drawn about LMs collec-\ntively. Possible reasons include more focus on the\nwhole concept of the Ship rather than maintaining\nits parts, or on specific planks than the wholesale\nrenovation of the vessel; more efforts would be\nneeded to understand the exact cause.\nWe have seen the presence of major component\nmodels so far, and readers likely have their own\ntacit understandings of the \"giants\" in the field\nat the moment. Here, we emphasize the vast im-\nplications of the dominant referents of LMs. For\nexample, if the supposedly abstract and inclusive\nconcept of LM is implicitly equated with a certain\nmodel, we might be assigning the random, quirky\ntraits of the model to the concept of LMs as a whole.\nThis could unwittingly hinder the diversity, gener-\nalizability, and future usefulness of work despite a\ngeneral veneer of neutrality among papers.\nTo portray how the giants shape our reported\nfindings, we drill down to investigate their presence\nin individual papers. We examine the existence\nof an absolute majority model component in each\npaper that appears more than all other components\ncombined, i.e., occupying more than $N/2$. One\nscenario, then, would be that a single or small set\nof giants actually underpin the notion of LMs in\npapers. On the other hand, if LM is truly a general\nterm of art, then we might also see some but not\nmost papers dominated by a model."}, {"title": "4.3 Lembos or Trireme: Factoring in context", "content": "Figure 6 displays the proportion of publications\nwith absolute majority components for the full data\n(left) and the top 25% with the highest $N_\\mathcal{L}^C$ (right).\nThe most notable components are marked with the\nsame color as in Fig. 4. Other models are shown\ncollectively as the grey bar (\"others\u201d), and the pro-\nportion with no single majority model is denoted\nwith a striped pattern. We observe that around\n80% of papers contain an absolute majority model.\nSpecifically, we get a glance at the astounding trac-\ntion of BERT before more recent paradigm shifts:\nit dominated up to 60.5% of all papers and 68.6%\nof the most LM-centered ones.\nInterestingly, more focus on the collective LM\nterms did not entail a more balanced composition.\nIn fact, they are often more biased: The percentage\nof papers with an absolute majority is higher in the\nmost LM-centered quartile than overall for all 7\nconferences before EMNLP 2022. There has also\nbeen a fresh wind, however. In the most recent 3\nconferences, we see fewer dominant components\nwhen a paper focuses heavily on the generalized\nLM terms. More importantly, the chance of an\nabsolute majority in both groups has been on a\ncontinuing decline and both reached an unprece-\ndentedly lower level: 70.5% for all papers and 67%\nfor the top quarter. We call to keep monitoring the\nheterogeneity (or lack thereof) in LM papers given\nthe (still) high presence of major components and\na visibly surging presence of the GPT component\nat the most recent EMNLP 2023.\nThe extent to which a paper focuses on LMs im-\nplies different use scenarios. For instance, a work\nmay utilize and mention them for data processing\nbut doesn't concern the science of LMs per se. This\nusually implies lower $N_\\mathcal{L}^C$ in contrast to another"}, {"title": "5 Concluding Remarks", "content": "Figure 6 displays the proportion of publications early conference (EMNLP 2020) versus a most re- with absolute majority components for the full data cent one (EMNLP 2023). We depict the change of (left) and the top 25% with the highest $N_\\mathcal{L}^C$ (right). 15 largest components in Figure 8. The findings The most notable components are marked with the are consistent: the most LM-centered group adapts same color as in Fig. 4. Other models are shown thoroughly to the latest models, while $Q_1^\u2212$ sees collectively as the grey bar (\"others\u201d), and the pro- a much more modest change, or even increased portion with no single majority model is denoted interest for models pre-2020 like BART (Lewis with a striped pattern. We observe that around et al., 2020) and COMET (Bosselut et al., 2019). 80% of papers contain an absolute majority model. Most notable is the contrast for BERT: For $Q_4^+$, Specifically, we get a glance at the astounding trac- the once-dominant component loses as much as tion of BERT before more recent paradigm shifts: 37% of $N$, going from 55.8% to 19%. However, it dominated up to 60.5% of all papers and 68.6% in $Q_1^\u2212$, the BERT component remains almost un- of the most LM-centered ones. touched; it still firmly takes up about 42% of $N Interestingly, more focus on the collective LM despite all the new models. This demonstrates that terms did not entail a more balanced composition. the trend in less LM-centered groups is not merely In fact, they are often more biased: The percentage a moderated or delayed version of that in the top of papers with an absolute majority is higher in the ones, but indeed represents a distinct interpretation most LM-centered quartile than overall for all 7 and resolution of LMs. conferences before EMNLP 2022. There has also The findings converge to an interesting division: been a fresh wind, however. In the most recent 3 the newest components or those with the latest ma- conferences, we see fewer dominant components jor models (GPT-3, ChatGPT, LlaMA, and Flan-T5, when a paper focuses heavily on the generalized inter alia; all of which are post-2022) instantly en- LM terms. More importantly, the chance of an ter the most LM-centered discourse, while the least absolute majority in both groups has been on a LM-centered ones persist to favor certain earlier continuing decline and both reached an unprece- models for a longer period. Thus, we should be dentedly lower level: 70.5% for all papers and 67% aware of the chasm between the co-occurring yet for the top quarter. We call to keep monitoring the distinct contexts that eventually map to different heterogeneity (or lack thereof) in LM papers given constructions of the same Ship. For instance, a the (still) high presence of major components and novel property found with 2023 models as default a visibly surging presence of the GPT component could be problematic if communicated to a BERT- at the most recent EMNLP 2023. centered subfield without regard, and further used to justify the use of LMs in a new stake despite wildly different ship drafts and capabilities. In In this work, we go over the past and present of return, the context difference may further hinder the enduring term of Language Model(s), based communications between groups representing the on an original dataset from the latest major confer- varied use and interpretations of LMs. ences. We sort out the subtle, continuous shifts in the practical meaning of LMs, and witness how the retrofits eventually accumulate to a brand new Ship of Language Models. We checked up the acceler- ated transmutation of our use of the term beyond the \"routine updates\" of the Ship, whereas actual referents did not sync with the pace. We quantify and visualize the drastic change in the planks and timber, emphasizing the shortened period of recon- struction and the presence of dominant components."}, {"title": "Finally, we highlight the snowballing context dif-ference between the LM-centered research and themore peripheral applications and its consequences.Our work seeks to delineate the shape of thedrifting concepts in the tide of time; yet, snapshotsat the galas still do not seem to catch up with thedifferentials as much originally as a decade's butnow within months or weeks. We have in fact seenmore interesting signs, standing at another epochalcrossroads of the ChatGPT era: the unprecedenteddissimilarity of compositions, or on the other hand,a more diverse, multipolar representation in modelchoices, to name a few. Perhaps, what is craftedfrom our hand signals the Age of Sail that we areyet to know \u2013 where it'd be too much for an epicArgo from the fanta-seas to explore.", "content": "4.3 Lembos or Trireme: Factoring in context"}]}