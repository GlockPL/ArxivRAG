{"title": "Diagnosis and Severity Assessment of Ulcerative\nColitis using Self Supervised Learning", "authors": ["Venkat Margapuri"], "abstract": "Abstract-Ulcerative Colitis (UC) is an incurable inflammatory\nbowel disease that leads to ulcers along the large intestine\nand rectum. The increase in the prevalence of UC coupled\nwith gastrointestinal physician shortages stresses the healthcare\nsystem and limits the care UC patients receive. A colonoscopy\nis performed to diagnose UC and assess its severity based on\nthe Mayo Endoscopic Score (MES). The MES ranges between\nzero and three, wherein zero indicates no inflammation and three\nindicates that the inflammation is markedly high. Artificial Intel-\nligence (AI)-based neural network models, such as convolutional\nneural networks (CNNs) are capable of analyzing colonoscopies\nto diagnose and determine the severity of UC by modeling\ncolonoscopy analysis as a multi-class classification problem. Prior\nresearch for AI-based UC diagnosis relies on supervised learning\napproaches that require large annotated datasets to train the\nCNNs. However, creating such datasets necessitates that domain\nexperts invest a significant amount of time, rendering the process\nexpensive and challenging. To address the challenge, this research\nemploys self-supervised learning (SSL) frameworks that can\nefficiently train on unannotated datasets to analyze colonoscopies\nand, aid in diagnosing UC and its severity. A comparative analysis\nwith supervised learning models shows that SSL frameworks,\nsuch as SwAV and SparK outperform supervised learning models\non the LIMUC dataset, the largest publicly available annotated\ndataset of colonoscopy images for UC.", "sections": [{"title": "I. INTRODUCTION", "content": "Inflammatory bowel disease (IBD) refers to the chronic\ninflammation of tissues in the digestive tract. Ulcerative\nColitis (UC) is a chronic IBD whose etiology remains\nunknown after decades of research [11] [29]. UC primarily\naffects the large intestine and is identified by the presence\nof ulcers in the large intestine and rectum [46]. A study\nconducted by the Crohn's and Colitis Foundation in 2023\nto estimate the incidence, prevalence, and ethnic distribution\nof physician-diagnosed IBD in the United States found that\none in 100 Americans has been diagnosed with IBD and\napproximately 56,000 new cases are diagnosed each year\n[27]. The uptick in IBD cases each year warrants a rise\nin gastrointestinal (GI) physicians. However, the United\nStates Health Resources and Services Administration (HRSA)\nprojects a shortage of 1,630 GI physicians by 2025 and\nexpects the shortage to rise in the next decade. One of the\nkey factors that lead to the shortage is the stress and burnout\nexperienced by the GI physicians on the job [17] [21]. As a\nconsequence, a multitude of patients do not receive timely\ncare for the chronic condition which has the potential to\ndevelop into colorectal cancer, if left untreated [24].\nUC is diagnosed with a colonoscopy, a test that captures\nimages of the gastrointestinal tract and enables the GI\nphysician to examine the intestinal lining for inflammation,\nsores, and ulcers. While multiple scoring systems [28] [18] to\nassess the severity of the disease exist, the Mayo Endoscopic\nScore (MES) [19] is widely accepted, wherein the severity\nis classified into one of four categories, Mayo 0 (normal or\ninactive disease), Mayo 1 (mild disease), Mayo 2 (moderate\ndisease), and Mayo 3 (a severe disease). Artificial Intelligence\n(AI)-based deep learning (DL) models have demonstrated an\nexcellent ability to perform classification tasks on medical\nimages for clinical diagnosis of UC [39] [40] [45]. In general,\nDL models help with the reduction in workload for physicians\nwho are faced with an ever-increasing number of medical\nimages to assess, and lower the risk of errors in diagnosis\n[48] [26]. The majority of DL models are supervised [47]\n[36], wherein the model is trained on a plethora of annotated\nimage samples. However, publicly available annotated image\ndata sets for colonoscopies are not abundant due to the\ndata confidentiality rules around medical data [1] [12].\nFurthermore, the development of annotated colonoscopy\nimage datasets is an endeavor that requires multiple medical\nexperts to dedicate extended amounts of time and energy,\nmaking the process tedious and expensive. Self-supervised\nlearning (SSL) is a methodology that develops DL models\nby learning representations from unlabeled datasets. SSL is\nproven to be effective for numerous tasks in the medical\ndomain [23] [37], and also in tasks where the data availability\nis limited. Furthermore, SSL is consistently able to deliver\nresults that are on par with supervised learning, albeit\nbeing trained on much smaller annotated datasets. While\nprevious work explores the use of supervised learning on DL\nmodels, such as convolutional neural networks (CNN) for"}, {"title": "II. RELATED WORK", "content": "Pretext tasks play a key role in training models using\nSSL. They refer to tasks wherein the neural network\nmodel is trained to learn features of the image dataset by\npredicting psuedo-labels obtained from applying different\ntransformations to the images. Pretext tasks may be common\nacross multiple downstream tasks. Commonly used pretext\ntasks include surrogate class prediction [9], relative position\nprediction [8], image transformation prediction, and solving\njigsaw puzzles [33]. In the realm of SSL, He et al. [14]\nproposed MoCo that builds a moving-average encoder by\nleveraging a dynamic dictionary with a queue to store feature\nvectors, ensuring that feature vectors are stored and not\ncomputed multiple times. Grill et al. [10] introduced the\nBYOL architecture that comprises online and target neural\nnetwork models, each with a different augmented view of\nan image. The online neural network is trained to predict\nthe target neural network representation of the image. The\ntarget neural network is updated with a slow-moving average\nof the online network. Caron et al. [7] proposed the SwAV\narchitecture, wherein the principle was to cluster different\naugmentations of the same image instead of performing pair-\nwise feature comparisons on the augmentations of the image,\ntypical of contrastive learning techniques. He et al.\n[13] proposed MAE to apply SSL techniques on vision\ntransformers. MAE masks a portion of the image and\napplies an encoder on the visible patches of the image to\ngenerate encoded tokens. The encoded and masked tokens are\nprocessed using a decoder to reconstruct the original image.\nThe critical works that inspired the choice of the dataset and\nframeworks for current work are highlighted next.\nTian et al. [42], proposed sparse masked modeling (SparK),\na hierarchical decoder to reconstruct images from multiscale\nencoded features. It can be used on any CNN without needing\nbackbone modifications. Validations on ResNet and ConvNext\nmodels demonstrated that it surpassed contrastive learning\ntechniques for CNNs.\nTuran and Durmus [43] explored the use of synthetic\nimages to train a classification model based on MES to assess\nUC from colonoscopy images. They developed UC-NfNet,\nan automated classification method, that outperformed other\nSOTA techniques such as convolutional vision transformers,\nswin transformer, InceptionV4, and ResNets. The use\nof synthetic image datasets to train the CNN is a key\ncontribution, considering the lack of publicly available\ndatasets for UC classification.\nPyatha, Xu, and Ali [35] performed vision transformer-\nbased SSL for UC grading using colonoscopy images on the\nLIMUC dataset. They used the combination of self-supervised\nMoCo with the Swin Transformer to develop a UC classifier\nbased on MES that outperformed ResNet-50, a supervised\nlearning technique.\nWolf et al. [48] demonstrated the feasibility of SSL\nfor the classification of computed tomography (CT) scan\nimages using the Lung Image Database Consortium and\nImage Database Resource Initiative (LIDC-IDRI) dataset that\nconsists of CT scans from 1,010 patients. The idea is to pre-\ntrain classification models using SSL techniques, such as\nMoCo and MAE, and leverage the model for the downstream\nclassification tasks of COVID-19, OrgMNIST, and brain\nhemorrhage.\nBhambhvani and Zamora [3] developed classification\nmodels for UC using different variants of ResNet, such\nas 50 and 101. The dataset used for the experiment is the\nHyper-Kvasir [4] dataset, and the images are classified based\non the MES.\nByrne et al. [6], compiled a dataset of colonoscopy\nimages by collecting colonoscopy videos of 134 UC\npatients comprising 1,550,030 frames at the Asian Institute\nof Gastroenterology (AIG). The images were used to\npredict the MES and Ulcerative Colitis Endoscopic\nIndex of Severity (UCEIS) score using the augmented"}, {"title": "III. SELF-SUPERVISED LEARNING", "content": "SSL refers to the technique of training neural network\nmodels to learn image features where the training data is not\nlabeled (annotated). The neural networks are provided with\npseudo labels that indicate the different image transformations\napplied to the images. In the absence of well-defined labels,\nthe neural network groups different images in the dataset based\non the similarity of pseudo labels associated with the images.\nFour different frameworks namely, BYOL, MoCo, SwAV, and\nSpark are used as part of the experiment to diagnose UC using\nSSL. Each of the architectures is described further."}, {"title": "A. BYOL", "content": "The basic principle of BYOL is to group augmented image\nsamples that are similar to each other. One of the key benefits\nof BYOL is that it avoids the collapsed representation problem.\nCollapsed representation is the state wherein a network trained\nonly on similar pairs of image samples learns a constant\nfunction that sets the loss to a constant value, such as zero. As\na result, no discriminative features are learned and the network\nremains unfit for fine-tuning on a different downstream task.\nThe working of BYOL is described as follows:\n1) Target and Online Networks: The architecture com-\nprises two image encoders, such as ResNet-50, with the\nsame architecture. One of them is the 'target' network\nthat is initialized with random parameters, and the other\nis the trainable 'online' network.\n2) Image Generation: An input image 'I' is run through\nan image augmentation pipeline to generate \u2018Il' and\n'12', two independent stochastically augmented versions\nof 'I'.\n3) Vector Encoding: The images 'Il' and '12' are pro-\ncessed using the 'target' and 'online' networks re-\nspectively to extract the vector encodings for each of\nthe augmented views of 'I'. The vector encodings are\nreduced to a low dimensional latent space, such as 256,\nif they are initially generated in a high dimensional\nvector space.\n4) Prediction: The 'online' vector representation is used to\npredict the 'target' vector representation by minimizing\nthe distance between the two vector encodings using the\nnormalized mean squared error loss function."}, {"title": "5) Updates", "content": "The 'target' network is updated at the end of\neach training step as the exponential moving average of\nthe parameters of the 'online' network."}, {"title": "B. MoCo", "content": "MoCo is a technique that is based on the principle of\nmatching queries to keys wherein key and query are vector\nencodings generated by passing augmented versions of the\nimage through two independent encoders, such as ResNet-50,\nthat are architecturally similar. MoCo constructs a dictionary,\nknown as the feature queue, which operates as a queue that\nkeeps a history of the encoded keys. The feature queue is used\nto create positive and negative pairs of images. A positive pair\nrefers to the instance where the query matches the key. All the\nkeys that don't correspond to the query are assumed to form\na negative pair with the query.\nThe key benefit of maintaining the dictionary as a queue is\nits flexible size, wherein the queue can hold multiple mini-\nbatches of keys at once. As a new mini-batch of keys is\nenqueued, the oldest mini-batch is dequeued. However, the\nkey pitfall of the feature queue-based encoder is that it isn't\nconducive to backpropagation owing to its large size. As a\nworkaround, the MoCo framework leaves the parameters of\nthe key encoder frozen during backpropagation, and updates\nonly backpropagates the gradient to the query encoder. A\nmomentum-based average of the query encoder is computed\nand used to update the parameters of the key encoder. It is\ncomputed as $\\theta_k \\leftarrow m \\theta_k + (1 - m) \\theta_q$ where $\\theta_k$ and $\\theta_q$ are the\nparameters of the key and query encoders respectively, and\n$m$ is the momentum whose value is maintained close to one.\nThe Contrastive Loss function which computes the similarity\nbetween the query and key is used to compute the loss\nduring training. It is formulated as $L_{self} = -log \\frac{exp(q \\cdot k^+/t)}{\\sum_{k}exp(q \\cdot k/t)}$\nwhere k, k\u207a, q, and t refer to key, positive key, query, and\ntemperature respectively. The lower the temperature, the higher\nthe confidence of the model, and vice versa."}, {"title": "C. SWAV", "content": "SwAV is an online clustering technique that works well with\nsmall and large batch sizes without the need for a momentum\nencoder or memory store. The standout feature of SwAV\nthat makes it unique from most SSL techniques is Multi-\nCrop Augmentation (MCA). Unlike other SSL techniques,\nsuch as MoCo and BYOL, that only create one augmented\nview of the original image, SwAV creates multiple augmented\nviews of the original image by applying different image\ntransformations. Since it is computationally expensive to create\nmultiple crops that are high resolution, SwAV creates a mix\nof high-resolution and low-resolution images to keep the\ncomputational cost reasonable. The augmented image views\nare passed in pairs through an encoder, such as ResNet-50,\nto generate high-dimensional encoded feature vectors. The\nfeature vectors are normalized by projecting them onto the unit\nsphere to ensure consistency. The normalized feature vectors\nare matched with prototype vectors that are characteristic of\nclustering algorithms. Prototype vectors define the space of\npossible distinction between the learnable feature space, and"}, {"title": "function that only computes errors on the masked areas\nof the images.", "content": "may also be understood as a low-dimensional projection of\nthe dataset. The mapping of feature vectors to the prototype\nvectors is done by computing the similarity between them\nresulting in a clustering assignment. The intuition behind\ncreating the clusters is that \u201cdifferent augmented views (crops)\ntaken from the same image should produce similar feature\nvectors.\u201d Therefore, the output vectors for the image crops\nare swapped, i.e. crop 1 is assigned output vector 2 and vice\nversa. The model is trained to predict the output vector of a\ndifferent augmented view as the target. The loss function used\nby SwAV is formulated as $L(Z_t, Z_s) = -(\\sum_k q_s(k)logP_{t}^{k} +\\sum_k q_t(k)logP_{s}^{k})$ where Zt and Zs refer to the feature vectors from\ndifferent augmentations of the same image, qs and qt refer to\nthe output vectors obtained after clustering, and Pt and Ps\nrefer to the probability obtained by taking the softmax of the\ndot product between the image feature vectors and prototype\nvectors."}, {"title": "D. SparK", "content": "Spark is a technique that is primarily based on MAE in\nthe natural language processing (NLP) space where models\nare pre-trained by dividing the image into patches, masking\nsome of the patches, and predicting the masked patch to\nreconstruct the original image. While MAEs work well for\nvision transformers, their performance on CNNs has been\nmoderate. Spark is an improvement over the current state of\nMAE, where it has been shown to outperform SOTA SSL\ntechniques for CNNs [42]. The architecture is explained as\nfollows:\n1) Image Curation: Given an image dataset $I = \\{I_1,\nI_2, I_3,... \\}$ each image is divided into multiple non-\noverlapping square patches. Each of the patches is\nmasked independently with a given probability known\nas \"mask ratio.\"\n2) Image Encoder: The model consists of an encoder,\nsuch as ResNet-50, to perform sparse convolutions\nwherein computations are performed only when the\ncenter element of the sliding window kernel is not\nempty. It ensures that computations are not performed\non masked regions and that feature vectors (encodings)\nare constructed only where the image is not masked.\n3) Image Decoder: The feature vectors from the en-\ncoder are passed in four different resolutions to a de-\ncoder whose architecture is similar to the U-Net [16]\ndesign, containing three blocks of upsampling layers.\nAny empty parts in the feature vectors are filled with\nlearnable mask embeddings M as they are input to\nthe decoder. Furthermore, a projection layer is added\nbetween the encoder and decoder for all computed\nresolutions in case they have different network widths.\n4) Image Reconstruction: The head module applied after\nthe decoder with two upsampling layers reconstructs the\nimage in the original resolution. Per-patch normalized\npixels are chosen as targets, with L2 being the loss"}, {"title": "IV. DATASET AND METHOD", "content": "The image dataset leveraged for the experiment is the\nLIMUC dataset which comprises 11,276 images from 564\npatients, and 1,043 colonoscopy procedures. While the size\nof the LIMUC dataset may not be considered large for\nexperiments in other domains, it is worth noting that medical\ndata is classified and the LIMUC dataset is considered large in\nthe medical domain. The images are compiled from patients\nwho underwent colonoscopy for UC between December 2011\nand July 2019 in the Department of Gastroenterology at\nMarmara University School of Medicine. The compilation of\nthe dataset includes two experienced gastroenterologists who\nblind-reviewed and classified all the images according to the\nMES. The images that lacked classification consensus are\ninspected independently by a third gastroenterologist, and the\nfinal label is assigned by majority voting."}, {"title": "B. Research Questions", "content": "The experiment described in the paper for UC diagnosis\nand severity assessment aims to answer the following research\nquestions (RQ):\nRQ-1: How do SSL techniques compare with supervised\nlearning techniques?\nRQ-2: How does each of the SSL techniques compare\nwith the others?\nRQ-3: How does the size of the dataset affect the perfor-\nmance of the supervised learning and SSL techniques?\nRQ-4: How does class imbalance within the dataset affect\nthe performance of the supervised learning and SSL\ntechniques?"}, {"title": "C. Experiment", "content": "The experiment to answer the RQ in IV-B involves con-\nducting experiments using the LIMUC dataset on supervised\nlearning and SSL models. The experiments are described as\nfollows:\nSupervised Learning: Google's InceptionV4, Microsoft's\nResNet-50, and Oxford's VGG-19 models are chosen\nfor the experiment due to their varied architectures, and\nsuccess in the field of medical imaging. The LIMUC\ndataset, shown in Table I, is split into Train, Validation,\nand Test datasets, each containing 60%, 20%, and 20% of\nthe data respectively. As a means to understand the impact\nof the size of the training dataset on the performance\nof the supervised models, they are independently trained\non 100%, 50%, and 25% of the data from the Train\ndataset. It is to be noted that using a part of the Train\ndataset still preserves images from each MES category\nat the same rate that they originally appear in the Train\ndataset. The supervised models are pre-trained on the\nImageNet dataset, and augmented to finetune on the\nTrain dataset. Three fully connected layers are added\nto the base architectures, followed by a softmax layer\nfor classification. All the pre-trained layers in the base\narchitectures are frozen, training only the three fully\nconnected layers.\nThe metrics of accuracy, precision, recall, and F1-score\nare used to evaluate the performance of the model.\nThey are briefly described as they relate to multi-class\nclassification, and expressed as percentages for better\nreadability wherever observed in the article.\nAccuracy: Accuracy is defined as the ratio of the\nnumber of correct predictions to the total number\nof predictions made on the dataset. It is computed as\n$\\frac{true\\ positives}{(true\\ positives+false\\ positives+true\\ negatives+false\\ negatives)}$\nPrecision: Precision for a class i is the ratio of\nthe correctly predicted positives for class i to the\ntotal number of predicted positives for class i. It is\ncomputed as$\\frac{true\\ positives}{true\\ positives + false\\ positives}$ \u00b7\nRecall: Recall for a class i is the ratio of the\ncorrectly predicted positives for class i to all the\ndata samples that belong to class i. It is computed\nas $\\frac{true\\ positives}{true\\ positives+false\\ positives}$ \u00b7\nF1-score: F1-score is given by the harmonic mean\nof precision and recall and is computed as $2 *\\frac{precision * recall}{precision + recall}$\nIn a nutshell, precision and recall provide insight into\nthe cost of false positives and false negatives affect-\ning the UC diagnoses. For instance, false positives\nmay lead to unnecessary treatments and false nega-\ntives may lead to missed diagnoses. Either scenario\nis a traumatic experience for the patients and needs\nto be avoided.\nNote: The standard/macro precision, recall, and F1-\nscore are reported as part of the experiment. While\nthe \"micro\" versions are deemed more robust to class\nimbalance, the experiment accounts for class imbal-\nance already, as described in the \u201cAddressing Class\nImbalance\" section below. In an attempt to ensure\nthat the metrics are not skewed by computation, the\n\"standard/macro\" version is reported.\nSelf-supervised Learning: The experiment using SSL\ncomprises two steps:\n1) Pre-training: The SSL frameworks described in\nsection III are initially trained on a majority of the\nimages from the LIMUC dataset without labels.\n2) Fine-tuning: The SSL model trained without labels\nis fine-tuned (trained) on a small portion of the\nimages from the LIMUC dataset with labels.\nIn order to train the SSL frameworks, the data from\nthe LIMUC dataset is split into three datasets, Pre-train,\nFine-tune, and Test. 50%, 30%, and 20% of the data\nare allocated to Pre-train, Fine-tune, and Test datasets\nrespectively."}, {"title": "D. Evaluation", "content": "The results from the experiment are used to answer the\nfour RQ mentioned in IV-B.\n1) How do SSL techniques compare with supervised\nlearning techniques?\nConsidering the class imbalance in the datasets that\nare employed on the supervised and SSL techniques,\nthe key metric that aids in the comparison of SSL\ntechniques with the supervised learning techniques\nis the F1-score [20]. Furthermore, it is worth noting\nthat F1-score considers the metrics of precision and\nrecall in its derivation. Among the supervised learning\nmodels (Table II), ResNet-50 performs the best with\nan F1-score of 70.9%, followed closely by VGG-19\nwith an F1-score of 67.4%. Among the SSL models\n(Table IV and Table V), the MAE-based technique of\nSpark performs the best with an F1-score of 73.1%\nfollowed by the contrastive learning technique of SwAV\nwith an F1-score of 70.4%. It is important to note\nthat the supervised and SSL models perform their best\nwhen trained on 100% of their respective datasets. The\nperformance metrics illustrate that SSL frameworks\noffer similar (or better) performance compared with the\nsupervised learning models. Furthermore, they don't\nrequire the same volume of labeled data, making them\nmore feasible for UC diagnosis and severity assessment.\n2) How does each of the SSL techniques compare with\nthe others?\nComparing the results of the SSL models with each\nother (Table IV and Table V), it is observed that the\nSSL models achieve their best accuracy and F1-score\nmetrics when trained on 100% of the Pretrain and Fine-\ntune datasets respectively. The MAE-based SparK\ntechnique, with an accuracy of 73.9% and F1-score of\n73.1%, outperforms the contrastive learning approaches\nof BYOL, MoCo, and SwAV. Among the contrastive\nlearning models, SwAV, with an F1-score of 70.4%\noutperforms both MoCo and BYOL with F1-scores\nof 66.9% and 66.5% respectively. The superior\nperformance of SwAV can be attributed to the MCA\nof SwAV wherein multiple augmentations at different\nresolutions are created, thereby enabling the framework\nto learn features at different scales. In contrast, the\ncontrastive learning techniques of BYOL and MoCo\nrely on only one augmented view of the original image.\nLike SwAV, the SparK technique comprises a decoder\nthat reconstructs images from multiscale encoded\nfeatures. Therefore, it is inferred that SSL frameworks\nthat consider multiple augmentations of the original\nimage at different resolutions perform better than those\nthat don't.\n3) How does the size of the dataset affect the performance\nof the supervised learning and SSL techniques?\nThe impact of dataset size is evident in the performance\nof both the supervised learning and SSL frameworks.\nFrom the results in Table II pertinent to the supervised\nlearning models, it is observed that each of the models\ndelivers the best metrics when trained on 100% of the\nTrain dataset, and the performance gets progressively\nworse as the size of the training dataset decreases.\nLikewise, from the results in Table IV and Table V,\nit is observed that the SSL frameworks perform best\nwhen pre-trained and fine-tuned with 100% of the Pre-\ntrain and Fine-tune datasets. Observing further, the\nperformance of the supervised models drops sharply\ncompared to the SSL models as the size of the dataset\ndecreases. For instance, the best-performing supervised\nlearning model, ResNet-50, exhibits Fl-scores of\n70.9%, 68.5%, and 65.6% at 100%, 50%, and 25%\nof training data respectively (Table II). A decrease of\n2.4% and 3.2% are observed for every 50% decrease in\ntraining data. On the other hand, the best-performing\nSSL framework, SparK, exhibits F1-scores of 73.1%,\n70.9%, and 70.2% when pre-trained on 100% of the\nPre-train dataset and fine-tuned on 100%, 50%, and\n25% of the Fine-Tune dataset respectively (Table IV).\nA decrease 2.2% and 0.7% are observed for every 50%\ndecrease in the finetuning data. Similar observations\nare made in reference to the other supervised and SSL\nmodels, effectively demonstrating the robustness of\nSSL frameworks compared with supervised models\nwhen trained on varying data sizes.\n4) How does class imbalance within the dataset affect\nthe performance of the supervised learning and SSL\ntechniques?\nFrom the results in Table VI, it is observed that class\nimbalance within the dataset has a notable impact on\nthe performance of both the supervised learning and\nSSL frameworks. The performance metrics of all the\nmodels, supervised and self supervised, have improved;\nResNet-50 and SparK continue to outperform the other\nsupervised learning and SSL models, respectively.\nUpon accounting for class imbalance, two of the SSL\nframeworks, SparK and SwAV with F1-scores of 77.5%\nand 75.5%, outperform the best supervised learning\nmodel, ResNet-50, with an F1-score of 72.5%. While\nit may appear that the increase in the F1-scores for\nsupervised learning and SSL frameworks is only about\n3% to 5% when accounted for class imbalance, it is\nimportant to note that such minor improvements in\nperformance are significant in the diagnosis of UC for\nthe following reasons backed by prior research.\nTrust and Adoption: Healthcare providers and\npatients are more likely to trust applications that\nimprove in performance over time [31].\nImpact on Unusual Conditions: For rare/unusual\nconditions, even a 1% increase in performance can\nsignificantly enhance the model's ability to detect\ncases that might otherwise be missed [44].\nImproved Generalization: An increase in model"}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "UC is an incurable autoimmune condition that gravely\naffects the quality of life of those afflicted. While AI systems\nare capable of diagnosing the severity of UC from colonoscopy\nimages, the majority of earlier research with tangible results\nfocuses on leveraging supervised learning frameworks that\nrequire large labeled datasets. The current work demonstrates\nthe feasibility of SSL frameworks which work efficiently\neven with small labeled datasets. Furthermore, it establishes\nbenchmarks for different SSL frameworks to diagnose the\nseverity of UC.\nIn the future, the feasibility of SSL frameworks on different\ncolonoscopy datasets will be investigated. Furthermore, the\ncurrent work does not focus on explainable AI techniques\nto interpret the model behavior. In the future, explainable AI\ntechniques, such as Gradient Class Activation Mapping, will\nbe applied to further improve the performance of the models."}]}