{"title": "Multimodal Ensemble with Conditional Feature Fusion for Dysgraphia Diagnosis in Children from Handwriting Samples", "authors": ["Jayakanth Kunhotha", "Somaya Al Maadeeda", "Moutaz Saleh", "Younes Akbari"], "abstract": "Developmental dysgraphia is a neurological disorder that hinders children's writing skills. The heterogeneous nature of dysgraphia symptoms and its frequent co-occurrence with other disorders complicate the identification process. In recent years, researchers have increasingly explored machine learning methods to support the diagnosis of dysgraphia based on offline and online handwriting. In most previous studies, the two types of handwriting have been analysed separately, which does not necessarily lead to promising results. In this way, the relationship between online and offline data cannot be explored. To address this limitation, we propose a novel multimodal machine learning approach utilizing both online and offline handwriting data. We created a new dataset by transforming an existing online handwritten dataset, generating corresponding offline handwriting images. We considered only different types of word data (simple word, pseudoword & difficult word) in our multimodal analysis. We trained SVM and XGBoost classifiers separately on online and offline features as well as implemented multimodal feature fusion and soft-voted ensemble. Furthermore, we proposed a novel ensemble with conditional feature fusion method which intelligently combines predictions from online and offline classifiers, selectively incorporating feature fusion when confidence scores fall below a threshold. Our novel approach achieves an accuracy of 88.8%, outperforming SVMs for single modalities by 12-14%, existing methods by 8-9%, and traditional multimodal approaches (soft-vote ensemble and feature fusion) by 3% and 5%, respectively. Our methodology contributes to the development of accurate and efficient dysgraphia diagnosis tools, requiring only a single instance of multimodal word/pseudoword data to determine the handwriting impairment. This work highlights the potential of multimodal learning in enhancing dysgraphia diagnosis, paving the way for accessible and practical diagnostic tools.", "sections": [{"title": "1. Introduction", "content": "Recent years have seen an increasing interest in exploring the relationship between neurological disorders, disabilities, and handwriting [1]. This interest has spurred research into using handwriting analysis as a diagnostic tool for various conditions and diseases. Handwriting deterioration, observable in several disorders and disabilities, makes it a promising biomarker. Parkinson's disease, a common neurodegenerative disorder, has been a focal point in handwriting analysis research [1, 2, 3, 4, 5], thanks to the availability of several datasets. Handwriting analysis has demonstrated diagnostic potential for mild cognitive impairment [6], Alzheimer's disease [7], and disorders within the schizophrenia spectrum and bipolar disorder [8]. Dysgraphia, a learning disability affecting writing expression, including spelling, grammar, and the organization of words and letters [9], is closely related to handwriting difficulties. Estimates suggest that 10% to 30% of children globally face handwriting challenges. Diagnosing dysgraphia accurately is complex, requiring consideration of various cues that change with age and developmental stage. These signs must persist for at least six months despite intervention efforts [10]. Dysgraphia can occur alone or with other disorders like autism spectrum disorder (ASD), developmental coordination disorder (DCD), or attention deficit hyperactivity disorder (ADHD), complicating the assessment [11]. Early diagnosis and intervention are crucial for effective treatment and reducing effort.\nHandwriting analysis data is generally divided into offline and online modes. Researchers examine online handwritten data, recorded in real-time with digitizing tablets, and offline data, comprising scanned or captured handwritten text images [12]. Online data features include dynamic parameters such as pen pressure, pen tilt, and pen-tip movement sequences, offering insights into fine motor control and pen dynamics during writing [3, 4, 13, 14, 15]. These features help assess detailed character and stroke formation. Advanced features have been introduced to capture more nuanced and condition-specific attributes [1, 2, 3, 7, 16, 17]. Offline data involves processing scanned handwritten text images to extract static features like character shape, size, slant, and spatial distribution on the page. Features related to character and stroke shape and curvature are also extracted to capture handwriting subtleties. Recent studies have focused on extracting CNN features from handwritten images [12, 18].\nDespite numerous studies addressing dysgraphia detection through handwriting analysis, most research has separately analyzed online and offline data. Current dysgraphia research in children has mainly emphasized online data analysis, with limited focus on offline data analysis [12]. With multimodal analy-"}, {"title": "2. Related works", "content": "The diagnosis of dysgraphia, a learning disability that primarily affects an individual's ability to express themselves through written communication, has been a subject of extensive research in recent years. Despite the inherent complexities involved, numerous studies have explored automated systems leveraging machine learning techniques to aid in the identification and analysis of dysgraphia [12]. In the following, we will first look at studies in connection with offline methods and then online methods.\nOne of the primary approaches has been the analysis of online handwritten data captured through digitizing tablets, aiming to distinguish between typical and dysgraphic handwriting patterns. Mekyska et al. [22] developed methods for classifying handwriting as either typical or dysgraphic by collecting data from school students using a Wacom Intuos tablet. They explored various characteristics such as kinematics, dynamics, and non-linear dynamics to differentiate between typically developing and dysgraphic writing. Their classifiers, based on Random Forest and linear discriminant algorithms, achieved an impressive handwriting classification sensitivity of 96%. Richard et al. [23] evaluated the performance of diverse machine learning algorithms, including Random Forest, logistic regression, and na\u00efve Bayes, in classifying online handwritten features for dysgraphia detection. Their study utilized features like pen tip pressure, letter and word characteristics, including shape and spacing. Asselborn et al. [24] introduced an automated dysgraphia diagnosis tool utilizing a consumer-level tablet and the Ductus software. With 54 extracted handwriting features, including static, kinematic, and dynamic characteristics, their Random Forest (RF) classifier demonstrated excellent accuracy in diagnosing dysgraphia among 298 primary school students, including 56 with dysgraphia. Drotar et al. [25] proposed a machine learning-based system that collected handwriting samples from 120 school students, including those with dysgraphia, using the WACOM Intuos Pro Large tablet. They captured data on pen movement, pressure, azimuth, and altitude during writing. Twenty-two types of spatiotemporal and kinematic features were extracted, and multiple machine learning algorithms were employed for classification, with the AdaBoost algorithm achieving the highest accuracy of 80%. Notably, features such as pressure and pen lifts showed high discriminatory potential. A different approach, presented by Dimauro et al. [26], introduced a software system designed to partially automate the evaluation of the Concise Evaluation Scale for Children's Handwriting (BHK) test. This test involves evaluating thirteen handwriting characteristics and assigning scores based on their quality. The proposed software system automatically generates scores for nine of the thirteen characteristics by modifying multiple document analysis algorithms. In methods based on online handwriting analysis for dysgraphia diagnosis"}, {"title": "3. Dataset", "content": "The dataset comprises handwriting samples collected from 57 children diagnosed with dysgraphia and 63 age- and sex-matched controls. The dysgraphic group's average age is 12.25 years (\u00b12.25), while the control group's average age is 11.78 years (\u00b12.09). Handwriting data were captured using a Wacom Intuos Pro Large tablet. Dysgraphic subjects' data were collected during diagnosis by trained professionals, with each subject becoming familiar with the environment and setup beforehand. Control subjects' data were collected in a classroom setting, with similar familiarization opportunities.\nThe dataset encompasses eight handwriting tasks, including writing the letter 'l' at typical and fast speeds, writing the syllable 'le' at typical and fast paces, and composing words like 'leto' (summer), 'lamoken' (pseudo-word), and the more challenging 'hra\u010dk'arstvo' (toy-store). The final task involved completing the sentence 'V lete bude teplo a sucho' (The weather in summer is hot and dry) [25]. Each sample was assessed by three independent trained professionals to determine its classification into the dysgraphic or healthy control group.\nIn this research, our approach focused on analyzing various word types ('leto', 'lamoken', 'hra\u010dk'arstvo') excluding letters, syllables, and sentences. This decision aligns with our research objectives, emphasizing the examination of different modalities of word writing data. This online data is converted into images to obtain an offline representation of the data. Each instance was considered as a unique sample for analysis, applied"}, {"title": "4. Methodology", "content": "This section outlines the methodology employed in constructing classifiers for diagnosing dysgraphia from handwriting samples. Figure 5 provides a visual summary of the process for developing a dysgraphia diagnosis system based on handwriting analysis, encompassing both online and offline handwritten data, and detailing the overall workflow.\nThe development of a machine learning-based dysgraphia diagnosis system involves several key stages. Initially, handwriting experiments are conducted to collect raw data, followed by extracting relevant features that characterize the dynamic, kinematic, temporal, and spatial attributes of the handwritten samples. With recent technological advancements, the digitized tablet can capture detailed information about the writing process, including the trajectory, time, and dynamics of the pen's movement.\nMoreover, this real-time handwritten data can be transformed into offline data by converting the x and y coordinates into a plot representation. In this study, both online and transformed offline data modalities are considered. Separate feature extraction techniques are applied to each data modality. The extracted features are then compiled into feature vectors that encapsulate the unique characteristics of each subject. These feature vectors are subsequently used to train machine learning algorithms. In this work we utilized SVM and XGboost algorithm to train and evaluate our proposed single modality and multimodality schemes."}, {"title": "4.1. Feature extraction", "content": "Feature extraction is crucial in developing decision-making systems that utilize traditional machine learning algorithms. In the context of handwriting tasks, each instance provides seven raw data values: x position, y position, time, pen position indicator, azimuth, altitude, and pressure.\nFor online handwriting data, feature extraction focuses on capturing dynamic aspects of handwriting. This process involves analyzing temporal characteristics, such as the sequence and timing of pen strokes, and spatial features related to the x and y coordinates. Additionally, it considers the pressure exerted by the pen tip and the angles of azimuth and altitude. Together, these elements create comprehensive feature vectors representing the online handwriting data.\nIn contrast, offline data, which exists in image form, requires a different approach. Feature extraction for offline data involves image processing and character recognition techniques."}, {"title": "4.1.1. Online handwritten features", "content": "From the online data, we have conducted feature extraction across four distinct categories, each serving as a fundamental aspect of handwriting analysis: kinematic, temporal, spatial, and dynamic features. These categories provide a comprehensive understanding of the handwriting process. We followed the same approach as our previous work to extract these features [32]. The kinematic features include the horizontal and vertical velocities of writing, which measure the rate of change of the stylus tip's position on the tablet surface in the horizontal and vertical directions with respect to time. The overall velocity of writing combines these components. Horizontal and vertical accelerations represent the rate of change of writing velocity in the respective directions, and the overall acceleration is calculated from these components. Horizontal and vertical jerks measure the rate of change of writing acceleration in the respective directions, with the overall jerk calculated similarly. Spatial features involve the length of the stroke, measured as the total length of the segment, horizontal length, and vertical length. Additionally, the width and height of the segment represent the maximum horizontal and vertical spans of the stroke, respectively. Temporal features include the duration of the segment, which is the time taken to complete a stroke. Dynamic features encompass various aspects, such as the pressure exerted by the stylus tip on the writing surface, the altitude (the angle of the stylus pen to the horizontal axis), and the azimuth (the angle of the stylus pen to the vertical axis). Other significant features include the difference between the y-positions of the first and last strokes, the variance of the y-positions of strokes, the number of pen lifts (the number of times the stylus pen tip is lifted from the tablet surface while writing), the count of velocity changes (the number of local extrema in velocity), the count of acceleration changes (the number of local extrema in acceleration), the total duration of writing, and the total length of writing. A total 141 online features were extracted from the online handwritten data."}, {"title": "4.1.2. Offline handwritten features", "content": "In the context of offline handwriting data analysis, a variety of image processing algorithms can be employed to extract meaningful features. In our approach, we utilized a technique known as \"transfer learning via feature extraction.\" This technique leverages a pre-trained neural network to extract valuable features from a new dataset. Subsequently, these extracted features serve as the foundation for developing a ma-"}, {"title": "4.2. Multi modal data fusion", "content": "Multimodal learning, a powerful approach in artificial intelligence, integrates information from various sources or modalities, such as text, images, and audio. This method's significant advantage lies in its ability to capture diverse and complementary features, leading to a more comprehensive understanding of the data. By combining different types of information, multimodal learning enhances the model's robustness and performance across a wide range of tasks, making it particularly beneficial in real-world applications. The implementation of multimodal learning involves extracting relevant features from each modality and merging them to form a unified representation.This can be achieved through methods such as feature concatenation, late fusion (classifier fusion), or early fusion. Effective feature extraction from each modality is essential to maintain the unique characteristics of different data types while ensuring a cohesive integration of information.\nIn the context of dysgraphia diagnosis, both online handwriting data (which captures dynamic aspects of writing) and offline/image data (which captures static features) are important. Multimodal learning is crucial in this setting because it combines the strengths of both data types, leading to a more accurate and comprehensive assessment of dysgraphia, thereby potentially enhancing diagnostic accuracy. In our research, we introduced both classifier fusion and feature fusion approaches for multimodal learning in dysgraphia diagnosis. An overview of the traditional classifier fusion approach (based on soft voting) and the feature fusion approach is illustrated in Figure 3."}, {"title": "4.2.1. Soft voting based ensembling", "content": "Soft voting-based fusion, including strategies like average voting and weighted voting, leverages the combined strengths of multiple classifiers to enhance prediction accuracy. Each classifier contributes its prediction, and these individual outputs are aggregated to form a final decision. Average voting entails averaging class probabilities or confidence scores from each classifier, whereas weighted voting involves assigning different weights to classifiers based on their performance or reliability before combining their probabilities/confidence scores.\nIn this work, we employed average voting for classifier fusion because the performance of the individual modality models (online modality classifier and offline modality classifier) was nearly identical across both datasets (word and pseudo-word)."}, {"title": "4.2.2. Feature fusion via concatenation", "content": "In this work, we employed feature fusion by concatenating features from online and offline handwritten data. This approach involves combining features extracted from both modalities into a single feature vector, which is then used to train a machine learning algorithm. During testing, features are similarly extracted from the test data, concatenated, and used for prediction.\nLet $X_{online}$ and $X_{offline}$ represent the feature sets extracted from the online and offline handwritten data, respectively. For a given sample, the feature vectors can be $X_{online} \\in R^m$ and $X_{offline} \\in R^n$, where $m$ and $n$ are the dimensions of the online and offline feature vectors, respectively. The feature fusion via concatenation is performed by linearly concatenating these feature vectors to form a single feature vector ($x_{fused} = [X_{online} | X_{offline}]$ where $x_{fused} \\in R^{m+n}$). This concatenated feature vector $x_{fused}$ is then used as input to a machine learning algorithm for training. Given a dataset $D = \\{(X^i_{online}, X^i_{offline},y^i)\\}_{i=1}^N$, where N is the number of samples, and $y^i \\in \\{TD, DYG\\}$ represents the class labels (TD for typically developing and DYG for dysgraphia), the concatenated feature vector for all samples is $X_{fused} = [x^1_{fused}, x^2_{fused}...x^N_{fused}]$ where $X_{fused} \\in R^{N\\times(m+n)}$. A machine learning algorithm is then trained on $X_{fused}$ and the corresponding labels $y = [y_1, y_2, ...,y_N]$.\nTesting Phase During testing, features are extracted from the test sample, concatenated in the same manner, and used for prediction. For a test sample, let $x^{test}_{online}$ and $x^{test}_{offline}$ be the extracted features. $X^{fused}_{test} = [x^{test}_{online}ext{ | } x^{test}_{offline}]$ is the fused test feature vector. This fused feature vector $x^{fused}_{test}$ is then passed to the trained machine learning model to obtain the final prediction."}, {"title": "4.2.3. Ensemble with conditional feature fusion", "content": "Ensemble with conditional feature fusion/classifier fusion with conditional feature fusion is a novel technique employed in our dysgraphia diagnosis framework to enhance the reliability of decision-making. It addresses situations where the confidence of the initial ensemble prediction falls below a predefined threshold, indicating uncertainty in the classification outcome. In such cases, instead of relying solely on the initial ensemble, we perform an additional round of ensemble voting. The workflow of proposed ensemble with conditional feature fusion approach is provided in Figure 4.\nIn our approach, we first train single-modality classifiers, $clf_{online}$ and $clf_{offline}$, on online and offline handwriting data, respectively. These classifiers provide probability distributions for dysgraphia and typically developing classes. Next, we employ average voting ensembling to combine the outputs of $clf_{online}$ and $clf_{offline}$, yielding an initial ensemble prediction.\nTo further leverage the complementary information captured by the two modalities, we introduce feature fusion by concatenating the online and offline modality features. This fusion process generates a combined feature vector, which is used to train another classifier, denoted as $clf_{fused}$. The intuition be-", "subsections": [{"title": "Algorithm 1: Multimodal Classifier Fusion with Conditional Feature Fusion", "content": "Require: Classifier trained on online features $Clf_{online}$, classifier trained on offline features $Clf_{offline}$, classifier trained on fused features $Clf_{fused}$, test data $D_{test}$ = [D(online), D(offline)], threshold \u03c4,\nEnsure: Final predicted label $\\hat{y}_{final}$\nClassifier prediction\nprocedure MULTIMODALCLASSIFIERFUSION($Clf_{online}$, $Clf_{offline}$, $Clf_{fused}$, $D_{test}$, T)\n// Predict probabilities for single modality\n$P_{online} \\leftarrow Clf_{online}(D(online)_{test})$\n$P_{offline} \\leftarrow Clf_{offline}(D(offline)_{test})$\n// Soft voting ensembling of single modality classifier\n$P_{ensemble} \\leftarrow SoftVote(P_{online}, P_{offline})$\nif max($P_{ensemble}$) < T then\n// Conditional Feature Fusion\n$P_{fusion} \\leftarrow Clf_{fused}(D(online)_{test} | D(offline)_{test})$\n// Perform another round of soft voting with individual classifiers\n$P_{soft\\_vote} \\leftarrow SoftVote (P_{online}, P_{offline}, P_{fusion})$\n$\\hat{y}_{final} \\leftarrow arg\\ max(P_{soft\\_vote})$\nelse\n$\\hat{y}_{final} \\leftarrow arg\\ max(P_{ensemble})$\nend if\nReturn $\\hat{y}_{final}$\nend procedure\nSoft voting\nprocedure SOFTVOTE(P)\n$P_{ensemble} \\leftarrow \\frac{1}{len(P)} \\sum_{i=1}^{len(P)}P_i$\nReturn $P_{ensemble}$\nend procedure\nAfter obtaining the initial ensemble prediction, we evaluate the confidence scores for dysgraphia and typically developing classes. If the confidence score for any class falls below a predefined threshold (e.g., 0.2), indicating uncertainty in the decision, we perform another round of soft voting ensemble. This time, we include the outputs of $Clf_{online}$, $Clf_{offline}$, and $Clf_{fused}$ in the ensemble. The final decision is made based on the combined ensemble output, thereby mitigating potential errors caused by low confidence scores. The importance of conditional feature fusion lies in its ability to mitigate potential errors caused by low confidence scores in the initial ensemble prediction. By incorporating this conditional mechanism, we ensure that the final decision is based on a more comprehensive assessment of the available information. This approach enhances the robustness and reliability of our dysgraphia diagnosis model, ultimately leading to improved diagnostic accuracy. In practical terms, conditional feature fusion provides a safety net against unreli-"}]}, {"title": "5. Evaluation and Results", "content": "Assessing and evaluating the efficacy of proposed methodologies is crucial for determining their ability to effectively tackle the problem at hand. In this research, a series of experiments were conducted to scrutinize and analyze the performance of the proposed techniques. All experimental procedures were implemented using the Python programming language. The training and evaluation phases were executed on a computing system equipped with an Intel(R) Core(TM) i7-7820HK CPU, operating at a frequency of 2.90 GHz (2901 MHz) with four processing cores, and an Nvidia GTX 1060 graphics processing unit (GPU). The well-established SciKit library was employed for the implementation of conventional machine learning algorithms, while the TensorFlow framework was utilized for the realization of feature extraction using a deep convolutional neural network (CNN).\nTo ensure a comprehensive performance analysis of the proposed methods, a diverse set of evaluation metrics were considered. The metrics employed in this study include accuracy, precision, and recall scores. While accuracy is a commonly used metric for classification tasks, precision, and recall are particularly effective for handling datasets with class imbalance.\nIn order to conduct a thorough investigation of classifier performance and mitigate the potential impact of random selection bias, a stratified group ten-fold cross-validation approach was employed for both training and evaluation. This methodology ensures that each cross-validation fold maintains a class label distribution that is consistent with the original dataset. Furthermore, hyperparameter tuning was performed using a grid search technique to identify the optimal hyperparameter configuration for each classifier. This approach allows for the exploration of a wide range of hyperparameter combinations, enabling the selection of the most suitable values for maximizing classifier performance."}, {"title": "5.1. Individual modality analysis", "content": "Table 2 presents a comparative analysis of the performance of two machine learning algorithms, SVM and XGboost, in diagnosing dysgraphia using online and offline modalities of handwritten data. The evaluation metrics used to assess the performance of these algorithms include accuracy, precision, and recall.\nIn the online modality, both SVM and XGboost demonstrate similar performance across different data types (Dword, Word,"}, {"title": "5.2. Multimodality analysis", "content": "Considering the poor performance of both algorithms in diagnosing dysgraphia using offline Dword data, we have decided to focus our multimodality analysis on Word and Pword data only. By concentrating on these data types, which yield better results in both online and offline modalities, we aim to leverage the complementary information provided by the two modalities to enhance the accuracy and reliability of dysgraphia diagnosis. Table 3 presents the performance of two multimodality fusion methods, feature fusion and soft voting ensemble, for diagnosing dysgraphia using SVM and XGboost classifiers. The evaluation metrics used are accuracy, precision, and recall. The analysis is conducted on two types of data: Word and Pword.\nIn the feature fusion method, the features from both modalities are concatenated and then used to train and test the classifiers. For Word data, XGboost achieves a higher accuracy (80.9%), precision (84.23%), and recall (80.5%) compared to SVM (accuracy: 77.9%, precision: 84.3%, recall: 73.1%). However, for Pword data, SVM outperforms XGboost with an accuracy of 83.4%, precision of 84.7%, and recall of 81.6%, while XGboost obtains an accuracy of 80.5%, precision of 84.1%, and recall of 75.6%.\nIn the soft voting ensemble method, each classifier is trained separately on the individual modalities, and the final prediction is made by averaging the confidence of the classifiers during testing. For Word data, XGboost shows slightly better performance than SVM, with an accuracy of 78.1%, precision of"}, {"title": "5.3. Comparison with state of the art methods", "content": "The proposed methods' effectiveness is highlighted by comparing their performance with state of the art dysgraphia diagnosis techniques evalauted on the same dataset. Table 5 illustrates this performance comparison, with the proposed methods emphasized in bold.\nThe Table 5 presents a comparison of the proposed multimodal methods with state-of-the-art techniques for dysgraphia diagnosis. The proposed methods, highlighted in bold, include SVM with feature fusion (FF), SVM with soft vote ensemble (SVE), and SVM with ensemble and conditional feature fusion (ECFF). These methods are compared against AdaBoost [25], AdaBoost [32], and CNN [37], which utilize only online"}, {"title": "6. Discussion", "content": "In this study, we have presented a novel approach for dysgraphia diagnosis using machine learning algorithms on a multimodal dataset. Our work addresses the limitations of existing research, which primarily focuses on single modality data, either online or offline handwriting, with a majority of studies concentrating on online data. To bridge this gap, we created a new dataset by transforming an existing online handwritten dataset through rasterization, generating corresponding offline handwriting images. This dataset encompasses various handwriting tasks, including letter writing, syllable writing, word writing, pseudoword writing, difficult word writing, and sentence writing. One of the key objectives of our work is to accurately detect dysgraphia from a single instance of a word, focusing on three word types: word, pseudoword, and difficult word. We trained SVM and XGBoost classifiers separately on online and offline features and analyzed the results. Our findings indicate that both classifiers demonstrate comparable performance across different word types in the online modality. However, their performance was relatively lower for difficult word data in the offline modality, with accuracies around 66%, highlighting the challenges in distinguishing between normal and dysgraphic handwriting in complex offline samples. This poor performance can be attributed to the visual similarity between normal and dysgraphic handwriting for difficult words, making it harder for the classifiers to capture discriminative features in the offline modality. To leverage the complementary information from both modalities, we implemented two multimodal approaches: feature fusion and soft-voted ensembling. These approaches yielded improved performance compared to the single modality experiments. The results varied depending on the word type and classifier used, with XGBoost generally outperforming SVM for word data and SVM surpassing XGBoost for pseudoword data in both fusion methods. Notably, the soft-voted ensembling approach with SVM achieved the highest accuracy of 85.6%, precision of 84.4%, and recall of 88.6% for pseudoword data among all combinations of fusion methods, data types, and classifiers. This represents a significant improvement of approximately 9-10% in accuracy compared to the single modality experiments. Furthermore, we proposed a novel approach called ensemble with conditional feature fusion, which intelligently combines the predictions from online and offline classifiers and selectively incorporates feature fusion when the confidence score difference between the positive and negative classes falls below a threshold. This approach aims to strike a balance between improving diagnosis performance and maintaining computational efficiency. Our results demonstrate that the proposed method is particularly effective for pseudoword data, where the SVM classifier achieves remarkably high accuracy of 88.8%, precision of 88.8%, and recall of 90.0%. This represents a substantial improvement of"}, {"title": "7. Conclusion", "content": "Dysgraphia is a learning disorder that affects an individual's ability to write legibly and efficiently, which can have a significant impact on their academic performance and overall quality of life. Early and accurate diagnosis of dysgraphia is crucial for providing timely interventions and support to those affected. In this study, we have tackled the challenge of dysgraphia diagnosis by proposing a novel multimodal approach that leverages machine learning algorithms and combines information from both online and offline handwriting data. Our research has made significant strides in advancing the field of dysgraphia diagnosis by addressing the limitations of previous studies that primarily focused on single modality data. By creating a new multimodal dataset from existing online dataset and exploring various fusion techniques, including feature fusion, soft-voted"}]}