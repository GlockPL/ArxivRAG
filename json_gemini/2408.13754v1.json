{"title": "Multimodal Ensemble with Conditional Feature Fusion for Dysgraphia Diagnosis in Children from Handwriting Samples", "authors": ["Jayakanth Kunhotha", "Somaya Al Maadeeda", "Moutaz Saleh", "Younes Akbari"], "abstract": "Developmental dysgraphia is a neurological disorder that hinders children's writing skills. The heterogeneous nature of dysgraphia symptoms and its frequent co-occurrence with other disorders complicate the identification process. In recent years, researchers have increasingly explored machine learning methods to support the diagnosis of dysgraphia based on offline and online handwriting. In most previous studies, the two types of handwriting have been analysed separately, which does not necessarily lead to promising results. In this way, the relationship between online and offline data cannot be explored. To address this limitation, we propose a novel multimodal machine learning approach utilizing both online and offline handwriting data. We created a new dataset by transforming an existing online handwritten dataset, generating corresponding offline handwriting images. We considered only different types of word data (simple word, pseudoword & difficult word) in our multimodal analysis. We trained SVM and XGBoost classifiers separately on online and offline features as well as implemented multimodal feature fusion and soft-voted ensemble. Furthermore, we proposed a novel ensemble with conditional feature fusion method which intelligently combines predictions from online and offline classifiers, selectively incorporating feature fusion when confidence scores fall below a threshold. Our novel approach achieves an accuracy of 88.8%, outperforming SVMs for single modalities by 12-14%, existing methods by 8- 9%, and traditional multimodal approaches (soft-vote ensemble and feature fusion) by 3% and 5%, respectively. Our methodology contributes to the development of accurate and efficient dysgraphia diagnosis tools, requiring only a single instance of multimodal word/pseudoword data to determine the handwriting impairment. This work highlights the potential of multimodal learning in enhancing dysgraphia diagnosis, paving the way for accessible and practical diagnostic tools.", "sections": [{"title": "1. Introduction", "content": "Recent years have seen an increasing interest in exploring the relationship between neurological disorders, disabilities, and handwriting [1]. This interest has spurred research into using handwriting analysis as a diagnostic tool for various conditions and diseases. Handwriting deterioration, observable in several disorders and disabilities, makes it a promising biomarker. Parkinson's disease, a common neurodegenerative disorder, has been a focal point in handwriting analysis research [1, 2, 3, 4, 5], thanks to the availability of several datasets. Handwriting analysis has demonstrated diagnostic potential for mild cognitive impairment [6], Alzheimer's disease [7], and disorders within the schizophrenia spectrum and bipolar disorder [8]. Dysgraphia, a learning disability affecting writing expression, including spelling, grammar, and the organization of words and letters [9], is closely related to handwriting difficulties. Estimates suggest that 10% to 30% of children globally face handwriting challenges. Diagnosing dysgraphia accurately is complex, requiring consideration of various cues that change with age and developmental stage. These signs must persist for at least six months despite intervention efforts [10]. Dysgraphia can occur alone or with other disorders like autism spectrum disorder (ASD), developmental coordination disorder (DCD), or attention deficit hyperactivity disorder (ADHD), complicating the assessment [11]. Early diagnosis and intervention are crucial for effective treatment and reducing effort.\nHandwriting analysis data is generally divided into offline and online modes. Researchers examine online handwritten data, recorded in real-time with digitizing tablets, and offline data, comprising scanned or captured handwritten text images [12]. Online data features include dynamic parameters such as pen pressure, pen tilt, and pen-tip movement sequences, offering insights into fine motor control and pen dynamics during writing [3, 4, 13, 14, 15]. These features help assess detailed character and stroke formation. Advanced features have been introduced to capture more nuanced and condition-specific attributes [1, 2, 3, 7, 16, 17]. Offline data involves processing scanned handwritten text images to extract static features like character shape, size, slant, and spatial distribution on the page. Features related to character and stroke shape and curvature are also extracted to capture handwriting subtleties. Recent studies have focused on extracting CNN features from handwritten images [12, 18].\nDespite numerous studies addressing dysgraphia detection through handwriting analysis, most research has separately analyzed online and offline data. Current dysgraphia research in children has mainly emphasized online data analysis, with limited focus on offline data analysis [12]. With multimodal analy-"}, {"title": "2. Related works", "content": "The diagnosis of dysgraphia, a learning disability that primarily affects an individual's ability to express themselves through written communication, has been a subject of extensive research in recent years. Despite the inherent complexities involved, numerous studies have explored automated systems leveraging machine learning techniques to aid in the identification and analysis of dysgraphia [12]. In the following, we will first look at studies in connection with offline methods and then online methods.\nOne of the primary approaches has been the analysis of online handwritten data captured through digitizing tablets, aiming to distinguish between typical and dysgraphic handwriting patterns. Mekyska et al. [22] developed methods for classifying handwriting as either typical or dysgraphic by collecting data from school students using a Wacom Intuos tablet. They explored various characteristics such as kinematics, dynamics, and non-linear dynamics to differentiate between typically developing and dysgraphic writing. Their classifiers, based on Random Forest and linear discriminant algorithms, achieved an impressive handwriting classification sensitivity of 96%. Richard et al. [23] evaluated the performance of diverse machine learning algorithms, including Random Forest, logistic regression, and na\u00efve Bayes, in classifying online handwritten features for dysgraphia detection. Their study utilized features like pen tip pressure, letter and word characteristics, including shape and spacing. Asselborn et al. [24] introduced an automated dysgraphia diagnosis tool utilizing a consumer-level tablet and the Ductus software. With 54 extracted handwriting features, including static, kinematic, and dynamic characteristics, their Random Forest (RF) classifier demonstrated excellent accuracy in diagnosing dysgraphia among 298 primary school students, including 56 with dysgraphia. Drotar et al. [25] proposed a machine learning-based system that collected handwriting samples from 120 school students, including those with dysgraphia, using the WACOM Intuos Pro Large tablet. They captured data on pen movement, pressure, azimuth, and altitude during writing. Twenty-two types of spatiotemporal and kinematic features were extracted, and multiple machine learning algorithms were employed for classification, with the AdaBoost algorithm achieving the highest accuracy of 80%. Notably, features such as pressure and pen lifts showed high discriminatory potential. A different approach, presented by Dimauro et al. [26], introduced a software system designed to partially automate the evaluation of the Concise Evaluation Scale for Children's Handwriting (BHK) test. This test involves evaluating thirteen handwriting characteristics and assigning scores based on their quality. The proposed software system automatically generates scores for nine of the thirteen characteristics by modifying multiple document analysis algorithms. In methods based on online handwriting analysis for dysgraphia diagnosis"}, {"title": "3. Dataset", "content": "The dataset comprises handwriting samples collected from 57 children diagnosed with dysgraphia and 63 age- and sex-matched controls. The dysgraphic group's average age is 12.25 years (\u00b12.25), while the control group's average age is 11.78 years (\u00b12.09). Handwriting data were captured using a Wacom Intuos Pro Large tablet. Dysgraphic subjects' data were collected during diagnosis by trained professionals, with each subject becoming familiar with the environment and setup beforehand. Control subjects' data were collected in a classroom setting, with similar familiarization opportunities.\nThe dataset encompasses eight handwriting tasks, including writing the letter 'l' at typical and fast speeds, writing the syllable 'le' at typical and fast paces, and composing words like 'leto' (summer), 'lamoken' (pseudo-word), and the more challenging 'hra\u010dk'arstvo' (toy-store). The final task involved completing the sentence 'V lete bude teplo a sucho' (The weather in summer is hot and dry) [25]. Each sample was assessed by three independent trained professionals to determine its classification into the dysgraphic or healthy control group.\nIn this research, our approach focused on analyzing various word types ('leto', 'lamoken', 'hra\u010dk'arstvo') excluding letters, syllables, and sentences. This decision aligns with our research objectives, emphasizing the examination of different modalities of word writing data. This online data is converted into images to obtain an offline representation of the data. Each instance was considered as a unique sample for analysis, applied"}, {"title": "4. Methodology", "content": "This section outlines the methodology employed in constructing classifiers for diagnosing dysgraphia from handwriting samples. Figure 5 provides a visual summary of the process for developing a dysgraphia diagnosis system based on handwriting analysis, encompassing both online and offline handwritten data, and detailing the overall workflow.\nThe development of a machine learning-based dysgraphia diagnosis system involves several key stages. Initially, handwriting experiments are conducted to collect raw data, followed by extracting relevant features that characterize the dynamic, kinematic, temporal, and spatial attributes of the handwritten samples. With recent technological advancements, the digitized tablet can capture detailed information about the writing process, including the trajectory, time, and dynamics of the pen's movement.\nMoreover, this real-time handwritten data can be transformed into offline data by converting the x and y coordinates into a plot representation. In this study, both online and transformed offline data modalities are considered. Separate feature extraction techniques are applied to each data modality. The extracted features are then compiled into feature vectors that encapsulate the unique characteristics of each subject. These feature vectors are subsequently used to train machine learning algorithms. In this work we utilized SVM and XGboost algorithm to train and evaluate our proposed single modality and multimodality schemes."}, {"title": "4.1. Feature extraction", "content": "Feature extraction is crucial in developing decision-making systems that utilize traditional machine learning algorithms. In the context of handwriting tasks, each instance provides seven raw data values: x position, y position, time, pen position indicator, azimuth, altitude, and pressure.\nFor online handwriting data, feature extraction focuses on capturing dynamic aspects of handwriting. This process involves analyzing temporal characteristics, such as the sequence and timing of pen strokes, and spatial features related to the x and y coordinates. Additionally, it considers the pressure exerted by the pen tip and the angles of azimuth and altitude. Together, these elements create comprehensive feature vectors representing the online handwriting data.\nIn contrast, offline data, which exists in image form, requires a different approach. Feature extraction for offline data involves image processing and character recognition techniques."}, {"title": "4.1.1. Online handwritten features", "content": "From the online data, we have conducted feature extraction across four distinct categories, each serving as a fundamental aspect of handwriting analysis: kinematic, temporal, spatial, and dynamic features. These categories provide a comprehensive understanding of the handwriting process. We followed the same approach as our previous work to extract these features [32]. The kinematic features include the horizontal and vertical velocities of writing, which measure the rate of change of the stylus tip's position on the tablet surface in the horizontal and vertical directions with respect to time. The overall velocity of writing combines these components. Horizontal and vertical accelerations represent the rate of change of writing velocity in the respective directions, and the overall acceleration is calculated from these components. Horizontal and vertical jerks measure the rate of change of writing acceleration in the respective directions, with the overall jerk calculated similarly. Spatial features involve the length of the stroke, measured as the total length of the segment, horizontal length, and vertical length. Additionally, the width and height of the segment represent the maximum horizontal and vertical spans of the stroke, respectively. Temporal features include the duration of the segment, which is the time taken to complete a stroke. Dynamic features encompass various aspects, such as the pressure exerted by the stylus tip on the writing surface, the altitude (the angle of the stylus pen to the horizontal axis), and the azimuth (the angle of the stylus pen to the vertical axis). Other significant features include the difference between the y-positions of the first and last strokes, the variance of the y-positions of strokes, the number of pen lifts (the number of times the stylus pen tip is lifted from the tablet surface while writing), the count of velocity changes (the number of local extrema in velocity), the count of acceleration changes (the number of local extrema in acceleration), the total duration of writing, and the total length of writing. A total 141 online features were extracted from the online handwritten data."}, {"title": "4.1.2. Offline handwritten features", "content": "In the context of offline handwriting data analysis, a variety of image processing algorithms can be employed to extract meaningful features. In our approach, we utilized a technique known as \"transfer learning via feature extraction.\" This technique leverages a pre-trained neural network to extract valuable features from a new dataset. Subsequently, these extracted features serve as the foundation for developing a machine learning model, which are then input into supervised learning algorithms such as SVM to facilitate the learning process. Specifically, for our work, we harnessed the power of EfficientNet-B7 [36], a convolutional neural network architecture known for its efficiency and accuracy as a feature extractor. EfficientNet-B7 is a part of the EfficientNet family, which scales up models in a more balanced way using a compound scaling method. This method uniformly scales the network's width, depth, and resolution using a set of fixed scaling coefficients. EfficientNet-B7 achieves state-of-the-art accuracy while being computationally efficient. It has been shown to perform exceptionally well on benchmark datasets like ImageNet. The architecture of EfficientNet-B7 consists of several key components, including MBConv blocks (Mobile Inverted Bottleneck Convolutional blocks), which are designed to optimize both accuracy and efficiency. The network is built with the following considerations:\n\u2022 Compound scaling: EfficientNet-B7 employs compound scaling to balance network depth, width, and resolution, enhancing performance while minimizing computational costs.\n\u2022 MBConv blocks: Each MBConv block includes depthwise separable convolutions, which split the convolution operation into two parts: depthwise convolution and pointwise convolution. This significantly reduces the number of parameters and computational complexity.\n\u2022 Squeeze-and-excitation (SE) blocks: EfficientNet-B7 integrates SE blocks to adaptively recalibrate channel-wise feature responses, further improving model performance.\nThe EfficientNet-B7 architecture includes several stages where the resolution of feature maps is progressively reduced while the number of channels increases, allowing the network to learn more abstract and high-level representations. This structure enhances feature reuse and promotes efficient information flow throughout the network. In traditional deep CNN models, layers primarily receive input from the immediate preceding layer. However, EfficientNet-B7's composite operations leverage a more advanced scaling method that ensures balanced growth across all dimensions of the network. This leads to robust feature extraction capabilities."}, {"title": "4.2. Multi modal data fusion", "content": "Multimodal learning, a powerful approach in artificial intelligence, integrates information from various sources or modalities, such as text, images, and audio. This method's significant advantage lies in its ability to capture diverse and complementary features, leading to a more comprehensive understanding of the data. By combining different types of information, multimodal learning enhances the model's robustness and performance across a wide range of tasks, making it particularly beneficial in real-world applications. The implementation of multimodal learning involves extracting relevant features from each modality and merging them to form a unified representation. This can be achieved through methods such as feature concatenation, late fusion (classifier fusion), or early fusion. Effective feature extraction from each modality is essential to maintain the unique characteristics of different data types while ensuring a cohesive integration of information.\nIn the context of dysgraphia diagnosis, both online handwriting data (which captures dynamic aspects of writing) and offline/image data (which captures static features) are important. Multimodal learning is crucial in this setting because it combines the strengths of both data types, leading to a more accurate and comprehensive assessment of dysgraphia, thereby potentially enhancing diagnostic accuracy. In our research, we introduced both classifier fusion and feature fusion approaches for multimodal learning in dysgraphia diagnosis. An overview of the traditional classifier fusion approach (based on soft voting) and the feature fusion approach is illustrated in Figure 3."}, {"title": "4.2.1. Soft voting based ensembling", "content": "Soft voting-based fusion, including strategies like average voting and weighted voting, leverages the combined strengths of multiple classifiers to enhance prediction accuracy. Each classifier contributes its prediction, and these individual outputs are aggregated to form a final decision. Average voting entails averaging class probabilities or confidence scores from each classifier, whereas weighted voting involves assigning different weights to classifiers based on their performance or reliability before combining their probabilities/confidence scores.\nIn this work, we employed average voting for classifier fusion because the performance of the individual modality models (online modality classifier and offline modality classifier) was nearly identical across both datasets (word and pseudo-word)."}, {"title": "4.2.2. Feature fusion via concatenation", "content": "In this work, we employed feature fusion by concatenating features from online and offline handwritten data. This approach involves combining features extracted from both modalities into a single feature vector, which is then used to train a machine learning algorithm. During testing, features are similarly extracted from the test data, concatenated, and used for prediction.\nLet $X_{online}$ and $X_{offline}$ represent the feature sets extracted from the online and offline handwritten data, respectively. For a given sample, the feature vectors can be $X_{online} \\in \\mathbb{R}^{m}$ and $X_{offline} \\in \\mathbb{R}^{n}$, where $m$ and $n$ are the dimensions of the online and offline feature vectors, respectively. The feature fusion via concatenation is performed by linearly concatenating these feature vectors to form a single feature vector ($x_{fused} = [X_{online} | X_{offline}]$ where $x_{fused} \\in \\mathbb{R}^{m+n}$). This concatenated feature vector $x_{fused}$ is then used as input to a machine learning algorithm for training. Given a dataset $D = \\{(X_{online}^{i}, X_{offline}^{i}, y^{i})\\}_{i=1}^{N}$, where $N$ is the number of samples, and $y^{i} \\in \\{TD, DYG\\}$ represents the class labels (TD for typically developing and DYG for dysgraphia), the concatenated feature vector for all samples is $X_{fused} = [x_{fused}^{1}, x_{fused}^{2}, ...,x_{fused}^{N}]$ where $X_{fused} \\in \\mathbb{R}^{N \\times (m+n)}$. A machine learning algorithm is then trained on $X_{fused}$ and the corresponding labels $y = [y^{1}, y^{2}, ..., y^{N}]$.\nDuring testing, features are extracted from the test sample, concatenated in the same manner, and used for prediction. For a test sample, let $x_{test online}$ and $x_{test offline}$ be the extracted features. $X_{fused test} = [x_{test online} x_{test offline}]$ is the fused test feature vector. This fused feature vector $x_{fused test}$ is then passed to the trained machine learning model to obtain the final prediction."}, {"title": "4.2.3. Ensemble with conditional feature fusion", "content": "Ensemble with conditional feature fusion/classifier fusion with conditional feature fusion is a novel technique employed in our dysgraphia diagnosis framework to enhance the reliability of decision-making. It addresses situations where the confidence of the initial ensemble prediction falls below a predefined threshold, indicating uncertainty in the classification outcome. In such cases, instead of relying solely on the initial ensemble, we perform an additional round of ensemble voting. The workflow of proposed ensemble with conditional feature fusion approach is provided in Figure 4.\nIn our approach, we first train single-modality classifiers, $Clf_{online}$ and $Clf_{offline}$, on online and offline handwriting data, respectively. These classifiers provide probability distributions for dysgraphia and typically developing classes. Next, we employ average voting ensembling to combine the outputs of $Clf_{online}$ and $Clf_{offline}$, yielding an initial ensemble prediction.\nTo further leverage the complementary information captured by the two modalities, we introduce feature fusion by concatenating the online and offline modality features. This fusion process generates a combined feature vector, which is used to train another classifier, denoted as $Clf_{fused}$. The intuition be-"}, {"title": "5. Evaluation and Results", "content": "Assessing and evaluating the efficacy of proposed methodologies is crucial for determining their ability to effectively tackle the problem at hand. In this research, a series of experiments were conducted to scrutinize and analyze the performance of the proposed techniques. All experimental procedures were implemented using the Python programming language. The training and evaluation phases were executed on a computing system equipped with an Intel(R) Core(TM) i7- 7820HK CPU, operating at a frequency of 2.90 GHz (2901 MHz) with four processing cores, and an Nvidia GTX 1060 graphics processing unit (GPU). The well-established SciKit library was employed for the implementation of conventional machine learning algorithms, while the TensorFlow framework was utilized for the realization of feature extraction using a deep convolutional neural network (CNN).\nTo ensure a comprehensive performance analysis of the proposed methods, a diverse set of evaluation metrics were considered. The metrics employed in this study include accuracy, precision, and recall scores. While accuracy is a commonly used metric for classification tasks, precision, and recall are particularly effective for handling datasets with class imbalance.\nIn order to conduct a thorough investigation of classifier performance and mitigate the potential impact of random selection bias, a stratified group ten-fold cross-validation approach was employed for both training and evaluation. This methodology ensures that each cross-validation fold maintains a class label distribution that is consistent with the original dataset. Furthermore, hyperparameter tuning was performed using a grid search technique to identify the optimal hyperparameter configuration for each classifier. This approach allows for the exploration of a wide range of hyperparameter combinations, enabling the selection of the most suitable values for maximizing classifier performance."}, {"title": "5.1. Individual modality analysis", "content": "Table 2 presents a comparative analysis of the performance of two machine learning algorithms, SVM and XGboost, in diagnosing dysgraphia using online and offline modalities of handwritten data. The evaluation metrics used to assess the performance of these algorithms include accuracy, precision, and recall.\nIn the online modality, both SVM and XGboost demonstrate similar performance across different data types (Dword, Word, and Pword). For Dword data, SVM achieves an accuracy of 72.1%, precision of 74.0%, and recall of 60.6%, while XGboost shows slightly better results with an accuracy of 72.6%, precision of 73.7%, and recall of 68.8%. For Word data, SVM and XGboost exhibit comparable accuracies of 72.6% and 72.8%, respectively. However, XGboost achieves higher precision (76.5%) compared to SVM (71.8%), while SVM has a higher recall (81.0%) compared to XGboost (69.7%). In the case of Pword data, SVM outperforms XGboost with an accuracy of 76.2%, precision of 79.0%, and recall of 70.0%, compared to XGboost's accuracy of 71.1%, precision of 74.3%, and recall of 65.2%.\nMoving to the offline modality, both algorithms show similar accuracies for Dword data (66.0%). However, SVM has slightly higher precision (64.3%) and recall (62.0%) compared to XGboost (precision: 62.7%, recall: 59.4%). For Word data, XGboost demonstrates better performance with an accuracy of 76.78%, precision of 80.86%, and recall of 76.6%, while SVM achieves an accuracy of 74.6%, precision of 81.7%, and recall of 70.0%. In the case of Pword data, SVM exhibits higher accuracy (76.3%), precision (79.3%), and recall (73.2%) compared to XGboost (accuracy: 72.9%, precision: 75.4%, recall: 69.6%). In the online modality, SVM demonstrates slightly better performance for Pword data, while XGboost shows marginally better results for Dword data. In the offline modality, XGboost outperforms SVM for Word data, while SVM exhibits better performance for pword data. It is important to note that the differences in performance between the two algorithms are relatively small.\nUpon further analysis of the results, it is evident that both SVM and XGboost demonstrate relatively low performance in diagnosing dysgraphia using Dword data, particularly in the offline modality. This can be attributed to the inherent difficulty in distinguishing between the handwriting patterns of typically developing individuals and those with dysgraphia when examining offline handwritten samples of difficult words.\nIn the offline modality, the accuracy for Dword data is 66.0% for both SVM and XGboost, which is considerably lower compared to the accuracies achieved for word and pword data. The precision and recall values for Dword data in the offline modality are also lower, with SVM achieving a precision of 64.3% and a recall of 62.0%, while XGboost shows a precision of 62.7% and a recall of 59.4%. These results highlight the challenges associated with accurately identifying dysgraphia based solely on offline handwriting samples of difficult words. The difficulty in distinguishing between typically developing handwriting and dysgraphic handwriting in offline Dword data can be attributed to several factors. Firstly, the static nature of offline handwriting samples limits the available information regarding the temporal and kinematic aspects of the writing process, which are crucial in detecting the subtle differences between normal and dysgraphic handwriting. Secondly, the complexity and variability of difficult words may obscure the characteristic features of dysgraphia, making it harder for the algorithms to capture the discriminative patterns. In contrast, the online modality provides additional temporal and kinematic information, such as stroke order, velocity, and pressure, which can aid in the identification of dysgraphic handwriting patterns. This is reflected in the relatively higher accuracies, precisions, and recalls achieved by both SVM and XGboost for Dword data in the online modality compared to the offline modality."}, {"title": "5.2. Multimodality analysis", "content": "Considering the poor performance of both algorithms in diagnosing dysgraphia using offline Dword data, we have decided to focus our multimodality analysis on Word and Pword data only. By concentrating on these data types, which yield better results in both online and offline modalities, we aim to leverage the complementary information provided by the two modalities to enhance the accuracy and reliability of dysgraphia diagnosis.\nTable 3 presents the performance of two multimodality fusion methods, feature fusion and soft voting ensemble, for diagnosing dysgraphia using SVM and XGboost classifiers. The evaluation metrics used are accuracy, precision, and recall. The analysis is conducted on two types of data: Word and Pword.\nIn the feature fusion method, the features from both modalities are concatenated and then used to train and test the classifiers. For Word data, XGboost achieves a higher accuracy (80.9%), precision (84.23%), and recall (80.5%) compared to SVM (accuracy: 77.9%, precision: 84.3%, recall: 73.1%). However, for Pword data, SVM outperforms XGboost with an accuracy of 83.4%, precision of 84.7%, and recall of 81.6%, while XGboost obtains an accuracy of 80.5%, precision of 84.1%, and recall of 75.6%.\nIn the soft voting ensemble method, each classifier is trained separately on the individual modalities, and the final prediction is made by averaging the confidence of the classifiers during testing. For Word data, XGboost shows slightly better performance than SVM, with an accuracy of 78.1%, precision of 80.05%, and recall of 77.9%, compared to SVM's accuracy of 77.4%, precision of 81.67%, and recall of 77.5%. However, for Pword data, SVM significantly outperforms XGboost, achieving an accuracy of 85.6%, precision of 84.4%, and recall of 88.6%, while XGboost obtains an accuracy of 76.6%, precision of 79.7%, and recall of 73.9%.\nOverall, the results suggest that the performance of the multimodality fusion methods varies depending on the type of data and the classifier used. For Word data, XGboost generally performs better than SVM in both feature fusion and soft voting ensemble methods. However, for Pword data, SVM consistently outperforms XGboost in both fusion methods.\nIt is worth noting that the soft voting ensemble method with SVM achieves the highest accuracy (85.6%), precision (84.4%), and recall (88.6%) for Pword data among all the combinations of fusion methods, data types, and classifiers. This indicates that the soft voting ensemble approach, which leverages the complementary information from multiple modalities by training classifiers separately and combining their predictions, can effectively improve the diagnosis of dysgraphia, particularly for Pword data. It is clearly evident from the results that the multimodal approach has significantly improved the performance of dysgraphia diagnosis compared to using single modalities. However, it is important to note that multimodal analysis comes with increased computational overhead due to the larger number of features and classifiers involved. To further enhance the diagnosis performance without significantly increasing the computational burden, we propose a novel approach called ensemble with conditional feature fusion.\nIn our proposed method, we initially perform soft voting between the online and offline classifiers. If the confidence score difference between the positive and negative classes is less than 0.2 in pseudoword data and 0.15 in word data (value is selected after expereimenting with set of threshold values), indicating a level of uncertainty in the prediction, we proceed to perform another round of soft voting. This additional voting includes classifiers trained on online features, offline features, and fused features, leveraging the complementary information from all available modalities. The results of our proposed ensemble with conditional feature fusion approach are presented in Table 4. This novel method aims to strike a balance between improving the diagnosis performance and maintaining computational efficiency by conditionally incorporating feature fusion based on the confidence of the initial soft voting prediction.\nFor Word data, the SVM classifier achieves an accuracy of 80%, precision of 84.6%, and recall of 77.3%. In comparison, the XGboost classifier obtains an accuracy of 78.8%, precision of 82.5%, and recall of 77.1%. The SVM classifier slightly outperforms XGboost in all three metrics for word data, indicating its effectiveness in capturing the discriminative patterns for dysgraphia diagnosis. Moving on to Pword data, the SVM classifier demonstrates exceptional performance with an accuracy of 88.8%, precision of 88.8%, and recall of 90.0%. This suggests that the proposed ensemble method is highly effective in correctly identifying individuals with dysgraphia based on their Pword handwriting samples. On the other hand, the XGboost classifier achieves an accuracy of 80.0%, precision of 83.0%, and recall of 78.0% for pword data, which is comparatively lower than SVM but still indicates a strong performance. The proposed ensemble method with conditional feature fusion leverages the strengths of both online and offline modalities by initially performing soft voting between their respective classifiers. In cases where the confidence score difference between the positive and negative classes is less than 0.2, indicating a level of uncertainty in the prediction, the method incorporates an additional round of soft voting that includes classifiers trained on fused features. This conditional feature fusion approach allows for the selective integration of complementary information from multiple modalities, enhancing the diagnosis performance without significantly increasing the computational overhead. The results demonstrate that the proposed method is particularly effective for pword data, where the SVM classifier achieves remarkably high accuracy, precision, and recall values. This suggests that the ensemble method successfully captures the subtle characteristics of dysgraphic handwriting in Pword samples, enabling accurate diagnosis. The performance on Word data is also commendable, with both SVM and XGboost classifiers achieving accuracy values close to 80% and precision values above 80%. One notable observation is the consistent superiority of the SVM classifier over XGboost in both Word and Pword data. This indicates that SVM's ability to find optimal decision boundaries in high-dimensional feature spaces is particularly suitable for the task of dysgraphia diagnosis using the proposed ensemble method.\nTo further analyze the impact of the confidence score threshold on the performance of the proposed ensemble method with conditional feature fusion, we conducted experiments with different threshold values. While the primary results presented in the study were based on a threshold of 0.2, it is essential to explore how varying this threshold affects the diagnosis accuracy, precision, and recall.\nWe selected a range of threshold values, including 0.1, 0.15,"}, {"title": "5.3. Comparison with state of the art methods", "content": "The proposed methods' effectiveness is highlighted by comparing their performance with state of the art dysgraphia diagnosis techniques evalauted on the same dataset. Table 5 illustrates this performance comparison, with the proposed methods emphasized in bold.\nThe Table 5 presents a comparison of the proposed multimodal methods with state-of-the-art techniques for dysgraphia diagnosis. The proposed methods, highlighted in bold, include SVM with feature fusion (FF), SVM with soft vote ensemble (SVE), and SVM with ensemble and conditional feature fusion (ECFF). These methods are compared against AdaBoost [25], AdaBoost [32], and CNN [37], which utilize only online data. The state-of-the-art methods using online data achieve accuracies ranging from 79.5% to 80.8%. AdaBoost [25] obtains an accuracy of 79.5%, while AdaBoost [32] slightly improves upon it with an accuracy of 80.8%. The CNN method [37] achieves an accuracy of 79.7%, which is comparable to the AdaBoost methods. In contrast, the proposed multimodal methods demonstrate superior performance. SVM with feature fusion achieves an accuracy of 83.4%, outperforming all the state-of-the-art methods that rely solely on online data. This indicates that the integration of features from both online and offline modalities enhances the discriminative power of the classifier, leading to improved diagnosis accuracy. Furthermore, SVM with soft vote ensemble (SVE) further improves the accuracy to 85.6%. This method leverages the complementary information from online and offline modalities by training separate classifiers and combining their predictions through soft voting. The increased accuracy suggests that the ensemble approach effectively captures the diverse characteristics of dysgraphia from multiple modalities, resulting in more reliable and accurate diagnosis. The most notable performance is achieved by SVM with ensemble and conditional feature fusion (ECFF), which obtains an accuracy of 88.8%. This method intelligently combines the predictions from online and offline classifiers and selectively incorporates feature fusion when the confidence score difference between the positive and negative classes is below a threshold. By conditionally integrating the fused features, ECFF strikes a balance between leveraging the complementary information from multiple modalities and maintaining computational efficiency. The high accuracy achieved by ECFF demonstrates its effectiveness in accurately diagnosing dysgraphia, even when analyzing a single instance of Pword data. It is important to highlight that the proposed multimodal methods, particularly SVM with ECFF, achieve state-of-the-art performance while analyzing only a single instance of pword data. This is in contrast to the other methods that utilize multiple instances or longer sequences of online data. The ability to accurately diagnose dysgraphia using a single pword sample showcases the efficiency and practicality of the proposed methods, as they require minimal data collection and processing overhead.\nIn conclusion, the comparison with state-of-the-art methods demonstrates the superiority of the proposed multimodal approaches for dysgraphia diagnosis. The integration of online and offline modalities through feature fusion, soft vote ensemble, and ensemble with conditional feature fusion significantly improves the accuracy of dysgraphia diagnosis. The SVM with ECFF method, in particular, achieves the highest accuracy of 88.8% while analyzing only a single instance of Pword data, outperforming the state-of-the-art methods that rely solely on online data."}, {"title": "6. Discussion", "content": "In this study, we have presented a novel approach for dysgraphia diagnosis using machine learning algorithms on a multimodal dataset. Our work addresses the limitations of existing research, which primarily focuses on single modality data, either online or offline handwriting, with a majority of studies concentrating on online data. To bridge this gap, we created a new dataset by transforming an existing online handwritten dataset through rasterization, generating corresponding offline handwriting images. This dataset encompasses various handwriting tasks, including letter writing, syllable writing, word writing, pseudoword writing, difficult word writing, and sentence writing. One of the key objectives of our work is to accurately detect dysgraphia from a single instance of a word, focusing"}]}