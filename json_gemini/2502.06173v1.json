{"title": "Uncertainty-Aware Adaptation of Large Language Models for\nProtein-Protein Interaction Analysis", "authors": ["Sanket Jantre", "Tianle Wang", "Gilchan Park", "Kriti Chopra", "Nicholas Jeon", "Xiaoning Qian", "Nathan M. Urban", "Byung-Jun Yoon"], "abstract": "Abstract\u2014Identification of protein-protein interactions (PPIs)\nhelps derive cellular mechanistic understanding, particularly in\nthe context of complex conditions such as neurodegenerative\ndisorders, metabolic syndromes, and cancer. Large Language\nModels (LLMs) have demonstrated remarkable potential in\npredicting protein structures and interactions via automated\nmining of vast biomedical literature; yet their inherent un-\ncertainty remains a key challenge for deriving reproducible\nfindings, critical for biomedical applications. In this study, we\npresent an uncertainty-aware adaptation of LLMs for PPI\nanalysis, leveraging fine-tuned LLaMA-3 and BioMedGPT\nmodels. To enhance prediction reliability, we integrate LORA\nensembles and Bayesian LoRA models for uncertainty quantifi-\ncation (UQ), ensuring confidence-calibrated insights into protein\nbehavior. Our approach achieves competitive performance\nin PPI identification across diverse disease contexts while\naddressing model uncertainty, thereby enhancing trustworthiness\nand reproducibility in computational biology. These findings\nunderscore the potential of uncertainty-aware LLM adaptation\nfor advancing precision medicine and biomedical research.", "sections": [{"title": "I. INTRODUCTION", "content": "Protein-protein interactions (PPIs) form the molecular\nfoundation of cellular function, orchestrating everything\nfrom gene regulation and signal transduction to metabolic\nprocesses and immune response. The intricate network of\nthese interactions, often termed the interactome, represents\none of the most complex and dynamic systems in biology [1].\nUnderstanding this complex PPI network is particularly\ncrucial in disease contexts, where aberrant protein inter-\nactions can lead to pathological states. Alterations in PPI\nnetworks have been implicated in numerous diseases, affecting\nfundamental cellular processes such as protein homeostasis,\ncell cycle regulation, and metabolic control. These disease-\nassociated changes in the interactome can manifest through\nvarious mechanisms, from disrupted protein complex forma-\ntion to altered signaling cascades, ultimately contributing to\ndisease progression and severity. Elucidating these interaction\nnetworks is therefore essential for understanding disease\nmechanisms and developing therapeutic strategies [2].\nTraditional experimental methods for identifying PPIs, such\nas yeast two-hybrid screening and co-immunoprecipitation,"}, {"title": "II. PRELIMINARIES", "content": "Throughout the paper, all vectors and matrices are denoted\nby bold lowercase (1) and uppercase letters (L) respectively.\n\nA. Low-Rank Adaptation\nTo adapt a pre-trained language model to downstream tasks,\nThe authors of [45] introduced LoRA, a parameter-efficient\nfine-tuning approach. Assuming that weight changes exhibit\na low intrinsic rank, LoRA optimizes rank decomposition\nmatrices while keeping the pre-trained weights frozen.\nSpecifically, given that the weight update has a low-rank\nstructure, the adapted forward pass is expressed as:\n$\n        h = (W + \\Delta W)a = (W_0 + BA)a.\n        $\nHere a and h represent the input and output vectors,\nrespectively, of a large frozen pre-trained weight matrix $W_0 \\in$\n$\\mathbb{R}^{d_1 \\times d_2}$. The matrices $B \\in \\mathbb{R}^{d_1 \\times r}$ and $A \\in \\mathbb{R}^{r \\times d_2}$ contain\ntrainable parameters, with $r <$ min($d_1$, $d_2$). This reduction\nin the number of parameters, allows LoRA to provide efficient\nfine-tuning with a decrease in storage requirements. We adopt\nthis model as a baseline in our experiments.\nB. Bayesian model formulation\nLet $D = \\{(x_i, y_i)\\}_{i=1,\\dots,n}$ be a training dataset with N\ni.i.d. samples, where x represents the input samples and y\nrepresents the output samples. Bayesian inference captures\nmodel uncertainty by inferring a probability distribution\nover model parameters, $\\theta = (\\theta_1,\\dots,\\theta_T) \\in \\mathbb{R}^T$, instead of\nlearning a single deterministic model-$p(y|x, \\theta)$. The posterior\ndistribution follows Bayes' rule: $p(\\theta|D) \\propto p(D|\\theta)p(\\theta)$,\nwhere $p(D|\\theta)$ is the model likelihood and $p(\\theta)$ is the\nprior distribution. To make predictions for a new input\n$x_{new}$, Bayesian model averaging (BMA) is applied using\nthe posterior distribution $p(\\theta|D)$ as follows:\n$\nP(y_{new}|x_{new}, D) = \\int p(y_{new}|x_{new}, \\theta) p(\\theta|D) d\\theta \\approx\\frac{1}{B}\\sum_{b=1}^{B} P(y_{new}|x_{new}, \\theta_b),~\\theta_b \\sim p(\\theta|D).\n$"}, {"title": "III. METHODOLOGY", "content": "A. LoRA Ensemble\nWe employ an ensemble of LoRA models \u2013 LoRA Ensemble\n[50], [51] as an efficient strategy for uncertainty quantification\nin LLMs. Traditional deep ensembles yield better predictive\nperformance and uncertainty estimation by training multiple\nmodels independently, but applying this directly to LLMS\nis often infeasible due to high memory and computational\ncosts.\nTo circumvent these issues, each LoRA Ensemble member\nfine-tunes the same pre-trained backbone $W_0$ with a low-\nrank trainable modification $W_m = B_mA_m$, where $B_m \\in$\n$\\mathbb{R}^{d_1 \\times r}$ and $A_m \\in \\mathbb{R}^{r \\times d_2}$ have significantly fewer parameters\nthan the full model, $r_m \\ll$ min($d_1$,$d_2$). These adapters\nare trained independently and in parallel, ensuring diverse\nsolutions-{$W_1$, $W_2$, ..., $W_M$}. The ensemble prediction is\ncomputed by averaging outputs across M ensemble members.\nFor a given input $x_{new}$, if $y_{new}^m$ represents the prediction\nfrom the m-th ensemble member, the final ensemble output\n(for continuous outcomes) is given by:\n$\n        P_{ens}(y_{new}|x_{new}) = \\frac{1}{M}\\sum_{m=1}^{M} P(y_{new}|x_{new}, W_m).\n        $\nThis approach retains the benefits of ensembling-improved\naccuracy, calibration, and robustness-while preserving effi-\nciency by reusing the frozen backbone and only training\nlightweight LoRA adapters.\nB. Bayesian Low-Rank Adaptation\nDespite the availability of scalable posterior inference\nmethods like variational inference [38], a fully Bayesian\ntreatment of LLMs remains computationally prohibitive.\nInstead, limiting Bayesian inference to LoRA parameters\noffers a more tractable means of capturing uncertainty in\nmodel predictions. However, even Markov chain Monte\nCarlo approaches can become excessively costly for inferring\nposteriors over the millions of LoRA parameters involved\nin large-scale models. As a practical compromise, Bayesian\nLORA [46] employs the Laplace approximation to estimate\nthe posterior over these low-rank parameters, centered around\ntheir maximum a posteriori (MAP) estimate together with\ncovariance equaling the Fisher information matrix [52].\nTo this end, let $\\theta$ denote the trainable LoRA parameters\nwith a prior distribution of $N(0, \\lambda^{-1}I)$. The Laplace approx-\nimation first calculates MAP estimate which is equivalent to\nmaximizing the log-joint, log P(y, X, $\\theta$)\n$\n        \\theta_{MAP} = argmax_{\\theta} log P(y, X, \\theta)\n        = argmax_{\\theta} log P(y|X, \\theta) + log P(\\theta)\n        = argmax_{\\theta} log P(y|X, \\theta) + \\frac{\\lambda}{2}|\\theta|^2 + const.\n        $\nwhere X represents the model inputs. The term associated\nwith log of the prior distribution provides us L2-regularization\non the trainable parameters. We can incorporate this in\nfrequentist model training via weight decay term with $\\lambda/2$\nstrength. As a result, parameters from any previously trained\nmodel that used a reasonable weight decay setting (for\nexample, via AdamW with its weight decay) can be directly\nreused.\nNext, to obtain an approximate posterior around $\\theta_{MAP}$,\nLaplace method proceeds with a second-order Taylor expan-\nsion of the log-joint $L(D, \\theta) =$ log $p(y, X, \\theta)$ around $\\theta_{MAP}$.\nHence, by ignoring the higher-order terms, this yields\n$\n        L(D, \\theta) \\approx L(D, \\theta_{MAP}) + \\frac{1}{2} (\\theta - \\theta_{MAP})^T H (\\theta - \\theta_{MAP}),\n        $\nwhere the first-order term zeros out due to the zero gradient\nat $\\theta_{MAP}$ and H is the Hessian of the log-joint at $\\theta_{MAP}$,\n$\\nabla^2 L(D, \\theta)|_{\\theta_{MAP}}$. Under this quadratic approximation,\n$\n        p(\\theta | D) \\approx N (\\theta|\\theta_{MAP}, H^{-1}).\n        $\nHence, Laplace approximation turns out to be post-hoc\nBayesian inference method which requires the additional\nstep of computing the $H^{-1}$ matrix at $\\theta_{MAP}$. In practice,\ncomputing the full Hessian H can be expensive, especially\nfor large models due to quadratic complexity with respect to\nthe number of model parameters. We use the positive semi-\ndefinite Fisher information matrix to circumvent the issue of\nthe potentially indefinite Hessian, which arises when local\nconvexity conditions fail to hold in large machine learning\nmodels. Accordingly, the Fisher information is defined by\n$\n        F(\\theta) = \\sum_{n=1}^{N}E_{\\hat{y} \\sim P(y|f_\\theta(x_n))} [GG^T]\n        $\nwhere $G = \\nabla_{\\theta}P(\\hat{y}|f_\\theta(x_n))$ represents the gradient and the\nexpectation above is over the model's output distribution.\nNext, in order to estimate the Fisher information in a\nmanner that is both tractable and memory-efficient, we\nemploy a Kronecker-Factored Approximate Curvature (K-\nFAC) approach similar to [46]. In K-FAC, we treat Fisher as\na block-diagonal matrix for each linear layer and factorize\neach block into two smaller matrices. For the 1-th linear layer,\nwe compute Fisher block $F_l$ using that layer's input activations\n$a_{l-1}$ and log-likelihood gradients with respect to layer's pre-\nactivation output $s_l$ denoted by $G_{s_l} = \\nabla_{s_l} log P(y|X, \\theta)$.\nHence the expression is\n$\n        F_l = \\sum_{n=1}^{N}E_{P(y|f_\\theta(x_n))} [a_{l-1}a_{l-1}^T] E_{P(y|f_\\theta(x_n))} [G_{s_l}G_{s_l}^T]\n        $\nThis approach avoids storing the full, dense Hessian, thereby\nreducing computational overhead. By applying K-FAC to the\nLORA parameters, we maintain a compact representation of\nuncertainty while keeping the overhead similar to standard\ntraining. However, in Equation (2), the first expectation grows\nwith the square of the layer's input width, while the second\ngrows with the square of the output width. Because LoRA\nadapters alternate between wide-input-narrow-output configu-\nration and vice versa, one of these expectations can become\nespecially large. To address this, we use an incremental SVD\nto factorize the large matrix into two new low-rank factors"}, {"title": null, "content": "thereby saving memory. Further mathematical details are\nprovided in Appendix E of [46].\nOnce we infer the approximate posterior which is Gaussian\nas per Equation 1, we can linearize the model predictions\naround the MAP estimate $\\theta_{MAP}$ [53]. For a test input $x_{new}$,\n$\n        f_{\\theta}(x_{new}) \\approx f_{\\theta_{MAP}}(x_{new}) + \\nabla_{\\theta}f_{\\theta}(x_{new})|_{\\theta_{MAP}} (\\theta - \\theta_{MAP}).\n        $\nBecause this expression is linear in $\\theta$, integrating out the\nGaussian posterior over $\\theta$ yields a Gaussian predictive\ndistribution for the logits:\n$\n        f_{\\theta}(x_{new}) \\sim N(y|f_{\\theta_{Map}} (x_{new}), \\Lambda),\n        $\nwhere $\\Lambda = \\nabla_{\\theta}f_{\\theta_{Map}} (x_{new})^T H^{-1} \\nabla_{\\theta}f_{\\theta_{Map}}(x_{new})$.\nFinally to efficiently sample from this predictive posterior,\nwe use the Cholesky decomposition of $\\Lambda = LL^T$. Then,\n$\n        \\hat{y} = f_{\\theta}(x_{new}) = f_{\\theta_{Map}}(x_{new}) + Lz, z \\sim N(0, I).\n        $\nThis linearized predictive step, combined with a Gaussian\napproximate posterior, yields efficient uncertainty estimates\nin Bayesian LoRA approach for downstream tasks."}, {"title": "IV. EXPERIMENTAL RESULTS", "content": "In this section, we assess the performance of two\nuncertainty-aware LoRA adaptations-LoRA Ensemble and\nBayesian LoRA-applied to LLaMA-3-8B and BioMedGPT-\nLM-7B models on publicly available protein-protein interac-\ntion datasets. As a baseline, we include a single LoRA model\ntrained in a deterministic manner. All LoRA-based approaches\nwere implemented using the PEFT library [54], with each\nconfiguration run three times using different random seeds.\nWe evaluate model performance and robustness by accuracy\n(Acc), negative log-likelihood (NLL), and expected calibration\nerror (ECE) on the test sets. Additional details on the NLL and\nECE metrics can be found in Appendix V-A. Furthermore, we\nreport Matthews Correlation Coefficient (MCC), specificity\n(Spec.), precision (Prec.), F1-score, and Area under Receiver\nOperating Characteristic curve (AUROC) over test sets for a\ncomprehensive view of predictive capabilities. Final metrics\nare summarized by the mean and standard deviation across\nthree independent runs.\nPPI Datasets. The datasets analyzed here explore PPIs related\nto various diseases, providing valuable insights into their\nunderlying mechanisms. The Neurodegenerative diseases PPI\n(ND-PPI) dataset, sourced from the study [55], focuses on\nneurodegenerative diseases and examines a network of 820\nproteins forming 11,762 interactions, evenly split between\npositive and negative pairs. The dataset is structured to\nassess whether specific protein pairs interact in the presence\nof neurodegenerative conditions. Similarly, the metabolic\ndisorders PPI (M-PPI) dataset, also from [55], investigates\nmetabolic disorders, encompassing 1,063 proteins and a\ntotal of 10,262 interactions. The cancer PPI (C-PPI) dataset,\nderived from the study [56], consisted of 933 positive and\n1,308 negative interactions. To ensure balanced representation,\nthis dataset was curated to create an equal-sized collection of\n1,866 total interactions. These datasets have been evaluated\nby prompting models to assess whether proteins interact\nin the corresponding conditions and collectively contribute\nto advancing computational models for predicting PPIs\nacross different disease contexts, enhancing our understanding\nof disease-specific interaction networks. These tasks are\nformalized into binary (True/False) classification problems\nas illustrated in Fig. 1. Furthermore, each dataset is divided\ninto 80% for training and 20% for testing, with all models\nevaluated on the fixed test set in each PPI prediction task. We\nrefer readers to [31], for additional details and exploratory\nanalyses of these datasets.\nImplementation Details. In all experiments, we construct\na LoRA ensemble using three individually fine-tuned LoRA\nlearners. The LoRA matrices B are initialized to zero, while\nthe entries of A follow a Kaiming Uniform initialization\n[57]. Optimization is performed using the AdamW optimizer\nwith a learning rate of 1 \u00d7 10-4, default hyperparameters,\nand a total of four training epochs. The batch size is set to\n4 for the ND-PPI and M-PPI cases and 16 for the C-PPI\ncase, following [31]. For Bayesian LoRA, the prior precision\n$\\lambda$ is fixed at 0.1. Lastly, LoRA is applied to the queries,\nvalues, and output layer across all methods, with specific\nhyperparameters set to r = 16, \u03b1 = 32, a dropout rate of\n0.05, and a maximum sequence length of 50.\nResults. The results for ND-PPI, M-PPI, and C-PPI tasks are\nsummarized in Tables I, II, and III, respectively.\nIn the ND-PPI prediction task (Table I), we demonstrate\nthat the LORA ensemble achieves the highest predictive\naccuracy among all models in both LLM settings and has the\nlowest NLL in the LLaMA-3 fine-tuning case. Conversely,\nBayesian LoRA demonstrates the best calibration in both\nscenarios, exhibiting the lowest ECE and achieving the lowest\nNLL in the BioMedGPT fine-tuning case. Lastly, the LoRA\nensemble reports the highest values for specificity, precision,\nF1-score, MCC, and AUROC among all models. In the M-PPI\nprediction task (Table II), we show that the LoRA ensemble\nachieves the highest predictive accuracy and lowest NLL in\nboth LLM scenarios, while also attaining the lowest ECE\nin the LLaMA-3 case. Conversely, Bayesian LoRA achieves\nthe best calibration in the BioMedGPT case and the highest\nspecificity in both scenarios. Finally, the LoRA ensemble\noutperforms all the models by achieving best precision, F1-\nscore, MCC, and AUROC values.\nIn the C-PPI prediction task (Table III), we demonstrate that\nthe LoRA ensemble once again achieves the highest predictive\naccuracy and lowest NLL in both settings, while also attaining\nthe lowest ECE in the BioMedGPT scenario. Bayesian LoRA\nmatches the best predictive accuracy in the BioMedGPT case\nand achieves the lowest ECE in the LLaMA-3 case. In the\nLLaMA-3 setting, the LoRA ensemble reports the highest\nvalues for specificity, precision, F1-score, MCC, and AUROC\namong all models. Additionally, it achieves the best specificity\nin the BioMedGPT case. Notably, both Bayesian LoRA and\nthe LoRA ensemble attain the best precision, F1-score, and\nMCC values in the BioMedGPT case. Lastly, all three models\nyield identical AUROC values in the BioMedGPT case."}, {"title": "V. CONCLUSION AND DISCUSSION", "content": "In this study, we presented a novel uncertainty-aware\nadaptation of LLMs approach for predicting protein-protein\ninteractions across multiple disease contexts. Leveraging\nfine-tuned LLaMA-3 and BioMedGPT models with LORA\nensemble and Bayesian LoRA, our approach consistently\nimproved prediction accuracy, reliability, and robustness, as\nconfirmed by comprehensive metrics such as negative log-"}]}