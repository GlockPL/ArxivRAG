{"title": "GDiffRetro: Retrosynthesis Prediction with Dual Graph Enhanced Molecular Representation and Diffusion Generation", "authors": ["Shengyin Sun", "Wenhao Yu", "Yuxiang Ren", "Weitao Du", "Liwei Liu", "Xuecang Zhang", "Ying Hu", "Chen Ma"], "abstract": "Retrosynthesis prediction focuses on identifying reactants capable of synthesizing a target product. Typically, the retrosynthesis prediction involves two phases: Reaction Center Identification and Reactant Generation. However, we argue that most existing methods suffer from two limitations in the two phases: (i) Existing models do not adequately capture the \"face\" information in molecular graphs for the reaction center identification. (ii) Current approaches for the reactant generation predominantly use sequence generation in a 2D space, which lacks versatility in generating reasonable distributions for completed reactive groups and overlooks molecules' inherent 3D properties. To overcome the above limitations, we propose GDiffRetro. For the reaction center identification, GDiffRetro uniquely integrates the original graph with its corresponding dual graph to represent molecular structures, which helps guide the model to focus more on the faces in the graph. For the reactant generation, GDiffRetro employs a conditional diffusion model in 3D to further transform the obtained synthon into a complete reactant. Our experimental findings reveal that GDiffRetro outperforms state-of-the-art semi-template models across various evaluative metrics.", "sections": [{"title": "1 Introduction", "content": "The retrosynthesis task aims to find a set of reactants capable of synthesizing a given product, which is a one-to-many problem. Even for experienced chemists, addressing such a one-to-many problem is still extremely challenging. Recently, benefitting from the rapid advancement of deep learning (DL), researchers have resorted to DL models to design efficient methods for retrosynthesis tasks. Existing DL-based methods (Somnath et al. 2021) can be divided into template-based, template-free, and semi-template methods. Template-based methods rely on predefined templates (extracted from a large-scale chemical database). For example, the GLN (Dai et al. 2019) treats chemical knowledge of reaction templates as logical rules, and then models the joint probability between rules and reactants. As template-based methods are constrained by predefined templates, template-free approaches are proposed. For example, Chemformer (Irwin et al. 2022) formulates the retrosynthesis prediction as a translation task, where the product SMILES (strings describing molecular compositions) and the set of reactant SMILES serve as the \u201csource language strings\" and \"target language strings\", respectively. Template-free methods typically generate reactant SMILES by sequentially outputting individual symbols, which makes their predictions limited in diversity.\nTo alleviate issues present in both template-based and template-free methods, the semi-template framework has recently been adopted, which does not utilize reaction templates and has good interpretability. It predicts the final reactants through the intermediates (synthons) in two steps: first identifying the reaction center to form synthons, then completing the synthons into reactants. For instance, G2Gs (Shi et al. 2020) first employs the Relational Graph Convolutional Network (RGCN) (Schlichtkrull et al. 2017) for reaction center identification, and then generates products through the variational graph translation.\nAlthough existing semi-template methods have achieved success in some scenarios, we argue that there are still avenues to improve. First, classical methods (Shi et al. 2020; Dai et al. 2019) solely focus on the nodes within the molecular graph, neglecting the features associated with faces (edges divide the entire plane into a set of regions, called faces) in the graph. The features of faces play a crucial role in the reaction center identification. For example, in a benzene ring, all carbon atoms reside on one face, and the bonds connecting these carbons exhibit high stability, making them less likely to serve as reaction centers. Secondly, existing methods generate reactants based on 2D graphs, ignoring the 3D structural information of molecules to some extent.\nTo address the above shortcomings, we propose the retrosynthesis prediction with dual graph-enhanced molecular representation and diffusion generation (GDiffRetro). We first introduce dual graphs to the reaction center identification."}, {"title": "2 Related Work", "content": "Retrosynthesis Prediction. Some significant template-based works include GLN (Dai et al. 2019), LocalRetro (Chen and Jung 2021), and Dual-TB (Sun et al. 2020). To overcome the constraints of external knowledge in template-based methods, template-free methods have been developed. Key examples in the template-free category include Chemformer (Irwin et al. 2022), RetroBridge (Igashov et al. 2024), and Dual-TF (Sun et al. 2020). Considering that template-free methods lack interpretability, semi-template methods have emerged. Notable works in the semi-template category include MEGAN (Sacha et al. 2021), G2Gs (Shi et al. 2020), and RetroDiff (Wang et al. 2023).\nMolecular Generation. The molecular generation is closely related to generative models (Zhang et al. 2024a; Guo et al. 2024; Zhang et al. 2024b). For example, You et al. modeled the molecular generation as a sequential decision process on graphs (You et al. 2018). Recent works introduced diffusion models to molecular data. GeoDiff (Xu et al. 2022) and ConfGF (Shi et al. 2021) condition the model on the adjacency matrix of the molecular, enabling them to optimize torsion angles between atoms. The equivariant diffusion model (Hoogeboom et al. 2022) generates 3D molecules from scratch, conditioned on predefined scalar properties. Another noteworthy work is DiffLinker (Igashov et al. 2022), an 3D diffusion model for designing linkers. Other models include LatentDiff (Cong et al. 2024) for protein design and AbX (Tian, Ren, and Zhang 2024) for antibody design."}, {"title": "3 Methodology", "content": "3.1 Graph-based Reaction Center Identification\nA molecule $M$ containing $n$ atoms and $q$ types of chemical bonds can be written as $M = {A, X}$, where $X \\in R^{n \\times d}$ is a d-dimensional node feature matrix and $A \\in R^{n \\times n \\times q}$ is an adjacency matrix ($A_{i,j,k} = 1$ if there exists a bond of type $k$ between atom $i$ and atom $j$). Based on the above formulation, a chemical reaction can be described as a pair of sets $(G^r, G^p)$, where $G^r = {M_i}_{i=1}^l$ is a set containing $l$ reactants and $G^p = {M_i}_{i=1}^m$ is a set containing $m$ products. Following previous work, we focus only on standard single-output chemical reactions, i.e., $|G^p| = 1$. For a single-output reaction (${M_i}_{i=1}^l, M^p)$, the goal of retrosynthesis is to predict the set of reactants ${M_i}_{i=1}^l$ corresponding to the given product $M^p$. The overview of our solution for the retrosynthesis task is shown in Fig. 1. We first conduct reaction center identification to partition the products into synthons (subgraphs of the product molecule, often not valid molecules). Then, we utilize a diffusion model to generate reactants based on the previously obtained synthons. Notations and chemical terms are summarized in Section A and Section B of the supplementary material, respectively. The supplementary material is in arXiv version of the paper.\nGiven embeddings of two atoms in the product, the prediction model for reaction center identification is required to output a score, i.e., the probability of a reaction center existing between these two atoms. The higher the probability, the more it indicates that the product needs to break the bond between these two atoms to generate synthons.\nConsidering the heterogeneity of the molecular graph, we use the RGCN to encode atoms in the given product $M^p = {A^p, X^p}$. The node $i$'s representation is updated as follows (starting with node $i$'s initial feature $h_i^0 = X^p[i, :])$:\n$\\begin{equation}\n    {h_i^l}_{l=1}^L = \\sigma(\\sum_{r \\in R} \\sum_{j \\in N_i^r} W_r h_j^{l-1} + W_o h_i^{l-1}),\n    (1)\n\\end{equation}$\nwhere $R$ is the set of all edge types (chemical bonds), $N_i^r$ is the set of neighbors of node $i$ under relation $r$ (can be obtained through $A^p[:, :, r]$), $\\sigma(\\cdot)$ is an activation function, $W_r$ is the learnable weight matrix corresponding to the edge type $r$, and $W_o$ is the learnable weight matrix for the self-loop edge. An RGCN with $L$ layers can only aggregate information from nodes within $L$ hops, while the reactivity of a reaction center may also be related to more distant nodes. Therefore, we also compute the graph-level embedding (by applying the $Readout()$ function proposed in (Velickovic et al. 2019)) to introduce the influence of remote atoms, i.e.,\n$\\begin{equation}\n    H^{M_p} = Readout(H^L),\n    (2)\n\\end{equation}$\nwhere $H^L$ is a node embedding matrix constructed from ${h_i^L}_{i=1}^n$.\n3.2 Dual Graph Enhanced Representation\nEncoding strategies in Section 3.1 is designed from the perspective of the nodes, while neglecting the faces in the molecular graph. Faces in the molecular graph are equally important. For example, carbon atoms in a benzene ring are all in one face, and the bonds between these carbons are very stable, making them unlikely to become reaction centers. To make up this shortcoming, we introduce the dual graph $D^p = {A^D, X^D}$ of $M^p$, which is constructed as follows:\n\u2022 Topological structure construction. Given an original planar graph $M^p$, the dual graph $D^p$ is a graph that has a"}, {"title": "3.3 Conditional Diffusion Reactant Generation", "content": "In Fig. 1, the conditional diffusion generation involves two processes: i) A forward process corrupts the structure and features of a synthon by adding Gaussian noise. ii) A reverse process learns the denoise process and outputs a reactant.\n\u2022 Forward process. An atom $s$ can be represented by a 3D coordinates $u^{(x)} \\in R^3$ and d-dimensional features $u^{(h)} \\in R^d$, i.e., $s = [u^{(x)}, u^{(h)}]$. Setting $z_0 = s$ as the initial state and parameterize a fixed noise process as:\n$q(z_t|z_0) = N(z_t; a_t z_0, \\sigma_t^2 I), t = 1, \\dots, T$, where $z_t$ is a latent noised representation, $N(\\cdot)$ denotes a Gaussian distribution, $I$ is an identity matrix, $a_t$ controls the proportion of the original input to be retained, and $\\sigma_t^2$ controls the intensity of added Gaussian noise. Inspired by (Song et al. 2021), we adopt a variance-preserving noise adding process, i.e., $a_t = \\sqrt{1 - \\sigma_t^2}$. In addition, a numerically stable polynomial noise schedule (Hoogeboom et al. 2022) is applied, i.e., $a_t = (1 - 2s)[1 - (\\frac{t}{T})^2]$, where $s$ is set to $10^{-5}$ to ensure numerical stability.\n\u2022 Reverse process. The reverse process takes $z_T$ as the starting point and attempts to learn a network with $\\theta$ as a trainable parameter for denoising, as follows:\n$\\begin{equation}\n    p_\\theta(z_{t-1}|z_t) = N(z_{t-1}; \\mu_\\theta(z_t, t), R_\\theta(z_t, t)),\n    (8)\n\\end{equation}$\nwhere $\\mu_\\theta(z_t, t)$ and $R_\\theta(z_t, t)$ are obtained from a network parameterized by $\\theta$.\n\u2022 Optimization process. To maximize the likelihood of observed data, we optimize the variational lower bound, i.e.,\n$- log p_\\theta(z_0) = - log \\int p_\\theta(z_{0:T}) dz_{1:T} < - \\mathbb{E}_{q(z_1|z_0)}[log p_\\theta(z_0|z_1)] + D_{KL}(q(z_T|z_0) || p(z_T)) - \\mathbb{E}_{q(z_{1}|z_0)}[D_{KL}(q(z_{t-1}|z_t, z_0) || p_\\theta(z_{t-1}|z_t))]  (9)$ where $p_\\theta(z_{0:T}) = p_\\theta(z_0, z_1, \\dots, z_T)$, $dz_{1:T} = dz_1 dz_2 \\dots dz_T$, and $D_{KL}(\\cdot)$ is the KL divergence. The $L_t$ encourages approximating the $q(z_{t-1}|z_t, z_0)$ through a distribution $p_\\theta(z_{t-1}|z_t)$ associated with a network. The closed form of $q(z_{t-1}|z_t, z_0)$ can be expressed as:\n$\\begin{equation}\n    q(z_{t-1}|z_t, z_0) = N(z_{t-1}; \\mu_q(z_t, z_0, t), \\sigma_t^2 I),\n    (10)\n\\end{equation}$\nwhere\n$\\begin{equation}\n    \\mu_q(z_t, z_0, t) = \\frac{\\alpha_t \\sigma_{t-1}^2}{\\alpha_{t-1} \\sigma_t^2}z_t + \\frac{\\alpha_{t-1} \\sigma_t^2 - \\alpha_t \\sigma_{t-1}^2}{\\alpha_{t-1} \\sigma_t^2}z_0,\n    (11)\n\\end{equation}$\nand $\\sigma(t)^2 = \\frac{\\sigma_{t-1}^2}{\\sigma_t^2}$. Substituting Eq. 8 and Eq. 10 into the diffusion loss at the time step t yields:\n$\\begin{equation}\n    L_t = \\mathbb{E}_{q(z_t|z_0)}[D_{KL}(q(z_{t-1}|z_t, z_0) || p_\\theta(z_{t-1}|z_t))] = \\mathbb{E}_{q(z_0, z_t)}[\\frac{1}{2R_\\theta(t)} || \\mu_\\theta(z_t, t) - \\mu_q(z_t, z_0, t) ||^2].\n    (12)\n\\end{equation}$\nwhere $\\mu_\\theta(z_t, t)$ can be expressed according to the Eq. 11:\n$\\begin{equation}\n    \\mu_\\theta(z_t, t) = \\frac{\\alpha_t \\sigma_{t-1}^2}{\\alpha_{t-1} \\sigma_t^2}z_t + \\frac{\\alpha_{t-1} \\sigma_t^2 - \\alpha_t \\sigma_{t-1}^2}{\\alpha_{t-1} \\sigma_t^2}z_\\theta(z_t, t),\n    (13)\n\\end{equation}$\nwith $z_\\theta(z_t, t)$ as the predicted initial state $z_0$ (output by a network). Plugging Eq. 11 and Eq. 13 into Eq. 12 results in\n$\\begin{equation}\n    L_t = \\mathbb{E}_{q(z_t|z_0)}[\\frac{1}{2R_\\theta(t)} (\\frac{\\alpha_{t-1} \\sigma_t^2 - \\alpha_t \\sigma_{t-1}^2}{\\alpha_{t-1} \\sigma_t^2})^2 || z_\\theta(z_t, t) - z_0 ||^2].\n    (14)\n\\end{equation}$\nConsidering that $z_t$ can be reparameterized as $z_t = a_t z_0 + \\sigma_t \\epsilon$, where $\\epsilon \\sim N(0, I)$, (Ho, Jain, and Abbeel 2020) suggests that using a network to predict $\\epsilon$ instead of $z_0$ will lead to a better result, i.e., $L_t$ can be simplifies to:\n$\\begin{equation}\n    L_t = \\mathbb{E}_{\\epsilon \\sim N(0,1)}[\\frac{1}{2R_\\theta(t)} (\\frac{\\alpha_{t-1} \\sigma_t^2 - \\alpha_t \\sigma_{t-1}^2}{\\alpha_{t-1} \\sigma_t^2})^2 || \\epsilon_\\theta(z_t, t) - \\epsilon ||^2].\n    (15)\n\\end{equation}$\nAccording to (Hoogeboom et al. 2022), both $L_p$ and $L_0$ are close to 0 (due to $a_T = 0$, $a_1 \\approx 1$, and $z_0$ is discrete). Furthermore, Ho et al. (Ho, Jain, and Abbeel 2020) found that removing the weight in Eq. 15 is conducive to improving sample quality. Therefore, an unweighted version of the final loss $L^{(2)}$ used in the reactant generation phase is:\n$\\begin{equation}\n    L^{(2)} = \\mathbb{E}_{\\epsilon \\sim N(0,1), t \\sim U(1,T)}[|| \\epsilon_\\theta(z_t, t) - \\epsilon ||^2].\n    (16)\n\\end{equation}$\n\u2022 Modeling of the $\\epsilon_\\theta$. During the reactant generation stage, each atom contains both a feature vector and 3D coordinates. To preserve equivariance of $\\epsilon_\\theta$ to coordinate rotations and translations (details about the equivariance are provided in Proposition 1), we utilize the EGNN (Satorras et al. 2021) to model $\\epsilon_\\theta$. Define the feature of atom i in the denoising time step t as $z_{i,t} = [z_i^{(h)}, z_i^{(x)}]$ and the final reactant $R$ containing $n$ atoms as $R = {V_i}_{i=1}^n = {S, Q}$, where $S = {v_i}_{i=1}^m$ is a set of $m$ atoms in the synthon (obtained from the first stage), $Q = {v_i}_{i=m+1}^n$ is a set of $n - m$ atoms need to be generated. The process of determining the number of atoms is detailed in Section G (supplementary material). Following the previous work (Hoogeboom et al. 2022), $\\epsilon_\\theta (Z_{i,t}, t)$ can be written as:\n$\\begin{equation}\n    \\epsilon_\\theta (Z_{i,t}, t) = \\phi_\\theta [e_{i,t}^{(x)}, e_{i,t}^{(h)}],\n    (17)\n\\end{equation}$\nwhere $[e_{i,t}^{(x)}, e_{i,t}^{(h)}]$ is the embedding of atom $i$ output by an L-layer EGNN (time t), and its computation process is:\n$\\begin{equation}\n    e_{i,t} = \\phi_\\theta(\\sum_{j \\neq i} m_{ij} d_e (e_{i,t}^{l-1}, e_{j,t}^{l-1}, ||d_{ij}^{l-1} ||)),\n\\end{equation}$\n$\\begin{equation}\n    e_{i,t}^{(h), l} = (1 - \\alpha_{ij}^{l-1}) e_{i,t}^{(h), l-1} + \\alpha_{ij}^{l-1} \\phi_e (\\sum_{j \\neq i} e_{i,t}^{l-1} \\frac{d_{ij}}{\\sqrt{1 + ||d_{ij}||^2}}), v_i \\in S,\n\\end{equation}$\n$\\begin{equation}\n    e_{i,t}^{(x), l} = (1 - \\alpha_{ij}^{l-1}) e_{i,t}^{(x), l-1} + \\alpha_{ij}^{l-1} \\phi_e (\\sum_{j \\neq i} d_{ij}^{l-1}), v_i \\notin S,\n\\end{equation}$\n$\\begin{equation}\n    d_{ij} = e_{i,t}^{(x), l-1} - e_{j,t}^{(x), l-1}.\n\\end{equation}$\n$\\begin{equation}\n    m_{ij} = \\frac{1}{\\sqrt{N}}, v_i \\in S,\n    (18)\n\\end{equation}"}, {"title": "4 Experiments", "content": "4.1 Experiment Setup\nWe utilize the USPTO-50k dataset (Lowe 2017), detailed in Section B of the supplementary material, to assess the proposed method. The split of the dataset follows previous work (Liu et al. 2017; Shi et al. 2020). Baselines are selected as follows: For Template-Based methods, we select MHNreact (Seidl et al. 2022), GLN (Dai et al. 2019), LocalRetro (Chen and Jung 2021), GraphRetro (Somnath et al. 2021), RetroComposer (Yan et al. 2022), and Dual-TB (Sun et al. 2020). For Template-Free methods, we select Transformer (Vaswani et al. 2017), SCROP (Zheng et al. 2020), Retroformer (Wan et al. 2022), GTA (Seo et al. 2021), Graph2SMILES (D-GCN) (Tu and Coley 2022), Transformer (Aug.) (Tetko et al. 2020), Dual-TF (Sun et al. 2020), Chemformer (Irwin et al. 2022), and RetroBridge (Igashov et al. 2024). For Semi-Template methods, we select MEGAN (Sacha et al. 2021), G2Gs (Shi et al. 2020), RetroXpert (Yan et al. 2020), G2Retro (Chen et al. 2023), RetroPrime (Wang et al. 2021), and RetroDiff (Wang et al. 2023). The definition of different types is given in Section 1. Following previous work (Liu et al. 2017), we employ the top-k exact match accuracy as evaluation metric. More implementation details can be seen in Section F (supplementary material). Code available at https://github.com/sunshy-1/GDiffRetro.\n4.2 Performance Comparison\nAs shown in Table 1, the top-1 result of GDiffRetro surpasses all template-free/semi-template based baselines, and most of the state-of-the-art template-based baselines. It's important to note that template-based methods rely heavily on external knowledge compared to template-free/semi-template based methods, making a direct comparison between template-based methods and template-free/semi-template based methods inherently unfair. To ensure fairness, we focus on performance gains within the category. Within the \"Semi-Template\" category, GDiffRetro achieves a relative improvement of 12.0% (unknown class) and 4.3% (known class, i.e. assuming the reaction class is known) in terms of the top-1 metric compared to the second-best method. This demonstrates that GDiffRetro can provide the most accurate retrosynthesis prediction with just a single attempt (this advantage is explained in the Proposition 2). In real-world applications, a relatively high single-attempt success rate (i.e., top-1 accuracy) is extremely important. This is because the reactants obtained a single retrosynthetic prediction usually not commercially available. Typically, we need to recursively conduct multiple retrosynthesis predictions to obtain the final synthesis route (akin to a search tree). Obviously, under this tree-like structure, a higher top-1 accuracy can greatly narrow the search space, thereby enhancing efficiency and reducing resource consumption. When examining the top-3 and top-5 metrics, GDiffRetro performs on par with all the template-free and semi-template baselines. Particularly, GDiffRetro almost outperforms all template-free/semi-template baselines in the top-3 and top-5 performances. It is worth noting that certain approaches, such as MEGAN, may exhibit significantly higher performance than GDiffRetro in terms of the top-5 result (known class). We attribute this difference to the limited number of sampling iterations in GDiffRetro, which may hinder its ability to generate an ample set of candidates. Mathematically, the diversity of results generated by a diffusion model is closely related to the sampling PDF's peakiness. In the conditional diffusion model, the peakiness depends on the mutual information between the condition and target. In our setting, the synthons (conditions) and reactants (targets) are similar, this leads to more concentrated sampling results, which in turn causes a decrease in the top-5 accuracy.\n4.3 Analysis and Visualization\nTo assess the proficiency of GDiffRetro in learning reaction templates, we visualize the end-to-end retrosynthesis prediction for two examples from the same reaction class in Fig. 3. For two products belonging to the \u201cprotections\" class, GDiffRetro accurately predicts the reaction centers. Then, it generates the reactants using two similar sets of synthons, formulating identical completed parts. These examples demonstrate that GDiffRetro's results are informed by\n4.4 Ablation Study\nTo verify the effectiveness of the dual graphs we introduced to the RGCNs, we compare two sets of ablation experiments (a. top-k accuracy of reaction center prediction, b. top-k accuracy of end-to-end retrosynthesis prediction), with and without dual graphs introduced in the inference process. The results are shown in Table 2a and Table 2b, respectively.\nIn Table 2a, it is evident that GDiffRetro achieves a significant improvement in top-1 accuracy when incorporating dual graphs. GDiffRetro with Dual-G also consistently surpasses its counterpart without Dual-G among all other metrics. A clear correlation between the performance of the end-to-end retrosynthesis prediction and the Dual-G configuration can be observed in Table 2b, following a similar trend to Table 2a. GDiffRetro with Dual-G outperforms the version without it, showing approximately a 6% increase in top-1 accuracy, and a slight improvement in top-3, top-5, and top-10 accuracy. The relatively modest improvement is attributed to the already high accuracy observed in these metrics.\nThe predictions for the reaction center of two test molecules, containing 1 and 3 rings, respectively, are depicted in Fig. 6. With enhanced information provided by the dual graphs, GDiffRetro with Dual-G can offer more precise predictions. More examples from 10 distinct reaction classes are illustrated in Section H (supplementary material)."}, {"title": "5 Conclusion", "content": "In this paper, we introduce GDiffRetro, a novel framework designed for retrosynthesis prediction. GDiffRetro notably incorporates a dual graph enhanced molecular representation for the reaction center identification, and introduces the 3D conditional diffusion model for reactant generation. Experimental results show that GDiffRetro not only surpasses current state-of-the-art models in top-1 accuracy, including those heavily reliant on templates, but also achieves competitive performance across top-3 and top-5 rankings. Through comprehensive ablation studies and detailed visualization, we confirm that the two key components proposed in GDiffRetro function independently and effectively."}, {"title": "A Notations", "content": "Vectors and matrices are denoted by bold lower case letters (e.g., a) and bold upper case letters (e.g., A), respectively. Calligraphic letters (e.g., Q) denote sets, and |\u00b7| represents the number of elements in the set (e.g., |Q|). Superscript (.)T stands for transpose. || denotes the concatenation operation. Rmon is real matrix space of dimension m \u00d7 n. E(\u00b7) represents the statistical expectation. N(\u03bc, R) denotes a Gaussian distribution with mean \u03bc and covariance matrix R. U(a, b) denotes a uniform distribution with noise range from a to b. I denotes an identity matrix. I(\u00b7) is an indicator function."}, {"title": "B Explanations of Chemical Terms", "content": "The chemical terms used in this paper and their corresponding explanations are summarized as follows:\n\u2022 Retrosynthesis Prediction. The retrosynthesis prediction problem is the inverse problem of the synthesis problem, that is, given a target molecule, we want to know which molecules it can be synthesized from.\n\u2022 Product. A product is a starting point of the retrosynthetic prediction, that is, the given target molecule.\n\u2022 Reactant. Reactants are the output of the retrosynthesis prediction. Reactants can be combined through chemical reactions to synthesize the product.\n\u2022 Synthon. A synthon is a subset of a reactant and the output of the reaction center identification. It is derived from the product by breaking the bond and may not be a legitimate molecule.\n\u2022 Atom, Bond, Molecule \u2192 Node, Edge, Graph. In this paper, we model the retrosynthesis prediction as a graph mining task. Specifically, we treat molecules as graphs, where each atom in the molecule is represented as a node in the graph, and the chemical bonds between atoms are represented as different types of edges between nodes."}, {"title": "C Dataset Details", "content": "The USPTO-50k dataset is a standard single-step retrosynthesis benchmark. The USPTO-50k dataset is obtained from the open soruce patent database (Lowe 2017), which includes approximately 50,000 chemical reactions divided into 10 classes (details of the classes are shown in Table 3). It should be noted that chemical reactions containing multiple products are split into multiple single product reactions, with each reaction preserving the reactants from the original reaction. Reactions involving trivial products, such as inorganic ions and solvent molecules, are eliminated. Among the whole reaction dataset, 13.61% of reaction centers are bonds within some ring, while 40.09% have exactly one node on rings. Only 0.448% of the graphs in the USPTO-50k and other molecular datasets are non-planar, making such cases relatively rare. Nevertheless, our model integrates both the original graph and a dual graph structure, enabling the GNN component to effectively handle non-planar graphs. Notably, all reported results are derived from the whole dataset, without excluding these special cases."}, {"title": "D Proofs of Propositions", "content": "Below, we offer proofs for several propositions that are not included in the main draft.\nD.1 Proof of Proposition 1\nNoting that U is an orthogonal matrix (UUT = I), we have ||Ux||2 = xTUTUx = ||x||2. Furthermore, we can deduce that the update of node features\n\u03a6h(ei(x),l\u22121+\u2211j\u2260i\u03a6h(ej(x),l\u22121)) is invariant to rotations and translations, and the update of the 3D coordinate attributes\n\u03a6h(ei(x),l\u22121+\u2211j\u2260i\u03a6h(ej(x),l\u22121)) is consistent with the change in input coordinates, where \u2161(\u00b7) is an indicator function.\nD.2 Proof of Proposition 2\nAccording to the Bayes\u2019 theorem, we havePo(zt\u22121|zt,c)=Po(zt\u22121|zt)expp(c|zt\u22121)\u2212logPo(c|zt)(21)Using a Taylor expansion around zt, the logpe(c|zt\u22121) can be further expressed as"}, {"title": "E More Information about Dual Graphs", "content": "The dual graph is a concept in graph theory, primarily used for geometric and topological analysis of graphs. The dual graph describes a graph from the perspective of its faces (faces naturally exist in the graph and do not need to be predefined). As show in Fig. 7, the original graph contains five nodes (A, B, C, D, and E) and six edges (AB, AC, BC, AD, AE, and DE). Additionally, the original graph divides the entire space S into three regions, i.e, the face ABC, the face ADE, and the face S \\ (ABC U ADE). In the dual graph of the original graph, the three nodes E, F, and G are located on the aforementioned three faces, respectively. The dual graph also contains six edges, i.e., FH1, FH2, FH3, GH1, GH2, and GH3. The type of each edge in the dual graph depends on the type of the edge it crosses in the original graph. For example, edge FH\u2081 and edge FH2 each cross over edge AB and edge BC respectively, and since edges AB and BC in the original graph are of the same type (marked in blue), edges FH\u2081 and FH2 in the dual graph are also of the same type (marked in red).\nIn chemistry, faces and chemical properties are closely related. For example, rings in molecules can influence the stability of connected bonds through i) Strain Transmission: Bond angles in rings deviate from ideal angles, resulting in strain within the ring. This strain can be transmitted to bonds connected to the ring, and change their bond lengths. ii) Electronic Inductive Effect: Electron groups on the ring change the electron density on the connected bonds. Through the calculation of bond dissociation energies (BDE, which are proportional to stability) for the bonds CCOC(=O)c1ccccc1 and O=C(OCc1ccco1)c1ccccc1, we observe that the introduction of the Tetrahydrofuran ring results in a significant increase in the BDE of the adjacent C-C bond (from 90.1 kcal/mol to 107.5 kcal/mol). Therefore, modeling \u201cfaces\u201d in the first stage is reasonable, as they are closely related to bond stability."}, {"title": "FImplementation Details", "content": "We leverage the open-source RDKit library to construct molecular graphs based on SMILES. During the \"Reaction Center Identification\", we adopt the widely-used machine learning tool, TorchDrug (Zhu et al. 2022), to facilitate the training and evaluation processes. To obtain the 3D conformation of a molecular graph from SMILES, we adopt the data processing method employed by DeLinker (Imrie et al"}]}