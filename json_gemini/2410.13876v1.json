{"title": "Deep Knowledge Tracing for Personalized Adaptive Learning at Historically Black Colleges and Universities", "authors": ["Ming-Mu Kuo", "Xiangfang Li", "Lijun Qian", "Pamela Obiomon", "Xishuang Dong"], "abstract": "Personalized adaptive learning (PAL) stands out by closely monitoring individual students' progress and tailoring their learning paths to their unique knowledge and needs. A crucial technique for effective PAL implementation is knowledge tracing, which models students' evolving knowledge to predict their future performance. Recent advancements in deep learning have significantly enhanced knowledge tracing through Deep Knowledge Tracing (DKT). However, there is limited research on DKT for Science, Technology, Engineering, and Math (STEM) education at Historically Black Colleges and Universities (HBCUs). This study builds a comprehensive dataset to investigate DKT for implementing PAL in STEM education at HBCUs, utilizing multiple state-of-the-art (SOTA) DKT models to examine knowledge tracing performance. The dataset includes 352, 148 learning records for 17,181 undergraduate students across eight colleges at Prairie View A&M University (PVAMU). The SOTA DKT models employed include DKT, DKT+, DKVMN, SAKT, and KQN. Experimental results demonstrate the effectiveness of DKT models in accurately predicting students' academic outcomes. Specifically, the SAKT and KQN models outperform others in terms of accuracy and AUC. These findings have significant implications for faculty members and academic advisors, providing valuable insights for identifying students at risk of academic underperformance before the end of the semester. Furthermore, this allows for proactive interventions to support students' academic progress, potentially enhancing student retention and graduation rates.", "sections": [{"title": "Introduction", "content": "In contemporary educational settings, personalized adaptive learning (PAL) has emerged as a dynamic approach to cater to the diverse needs and learning styles of students. This pedagogical framework tailors instructional content, pace, and learning experiences to the individual learner, leveraging technology and data analytics to facilitate targeted interventions (Bajaj and Sharma, 2018). In particular, PAL systems utilize artificial intelligence techniques to analyze student performance data, enabling educators to gain insights into each learner's strengths, weaknesses, and areas for improvement (Zine et al., 2019; Ya\u011fc\u0131, 2022; Waheed et al., 2020). By providing customized learning pathways and real-time feedback, these systems aim to optimize student engagement, comprehension, and overall academic achievement (Essa et al., 2023). Deep Knowledge Tracing (DKT) emerges as a crucial component for implementing PAL systems. It represents a paradigm shift from traditional assessment methods, offering a sophisticated approach to modeling and predicting students' mastery of specific concepts or skills over time (Piech et al., 2015). Unlike conventional methods that rely solely on grades or assessments, DKT leverages deep learning algorithms to analyze sequential student interactions with learning materials, including exercises, quizzes, and assignments. By capturing the dynamic and temporal aspects of learning, DKT predicts future learning outcomes, aiding educators in understanding and addressing students' individual progress and needs. This provides a more intricate comprehension of students' knowledge acquisition processes, facilitating timely interventions and personalized support (Liu et al., 2023). This nuanced understanding enables tailored support, fostering a more effective and responsive learning environment.\nDespite the advancements in DKT, there remains a gap in its investigation and application within specific educational contexts, particularly at Historically Black Colleges and Universities (HBCUs) (Pokrajac et al., 2016). These institutions play a vital role in fostering academic excellence and opportunity for underrepresented minority students, yet there is a lack of comprehensive research on the effectiveness and implementation of DKT within HBCU settings. Addressing this gap is crucial for advancing the understanding of knowledge tracing in diverse educational environments and ensuring equitable access to effective learning technologies.\nThis study builds a comprehensive dataset to investigate DKT for implementing PAL in STEM education at HBCUs. It utilizes multiple state-of-the-art (SOTA) DKT models, including DKT, DKT+, DKVMN, SAKT, and KQN, to examine knowledge tracing performance. The dataset comprises 352, 148 learning records for 17, 181 undergraduate students across eight colleges at Prairie View A&M University (PVAMU),"}, {"title": "Data collection and preparation", "content": "Educational institutions routinely maintain comprehensive electronic records of student information, encompassing diverse data types and volumes, ranging from demographic details to academic achievements. This study collected a real dataset of undergraduate students from the Student Information System (SIS) at PVAMU, one HBCU in Texas. The data spans four years, from fall 2020 to summer 2023. The collected data includes five essential elements: Academic Year, Universal ID, Course Subject, Course Level, and Pass/Fail grades. These features are strictly academic and relate to students' grades in their courses over the academic years."}, {"title": "Data Preparation", "content": "To prepare data for DKT, a few steps of data preprocessing are completed: 1) Data records lacking grades, incomplete courses, or non-gradable courses were excluded from the dataset; 2) The features comprise categorical data, which is incompatible with machine learning algorithms. Consequently, it is necessary to transform these categorical course data into a numerical format before inputting them into the machine learning model. In this research, we employed a technique known as label encoding to convert our categorical data into numerical values (Patil and Thorat, 2016). This method assigns an integer to each distinct nominal variable. Course subject and level features were transformed into integer numbers, representing the student's knowledge skill; 3) Courses sharing the same subject and level were treated as possessing the same knowledge skill. For example, courses like MATH 3201 and MATH 3800, both falling under the 3000-level math category, were considered part of the same skill set."}, {"title": "Statistical Analysis", "content": "Over the four-year period, the total university (UNIV) dataset comprises 352,148 records for undergraduate students."}, {"title": "Methodology", "content": "Deep Knowledge Tracing (DKT) has emerged as a powerful approach for modeling and predicting the knowledge mastery of learners in educational settings. Over time, several variants of DKT have been proposed, each introducing unique enhancements to address specific challenges. In this research, we delve into the methodologies of five prominent DKT models: DKT, DKT+, DKVMN, SAKT, and KQN to predict whether a student will pass or fail a course for HBUC education.\n\u2022 Deep Knowledge Tracing (DKT) (Piech et al., 2015) is the first work to apply neural networks for knowledge tracing tasks. It uses recurrent neural network (RNNs) to effectively capture the temporal dependencies inherent within a sequence of interactions comprising a student's questions and corresponding answers. This enables the model to predict a student's response to a new question based on their historical interactions.\nA fundamental representation of a simple RNN network for DKT is defined as follows:\n$h_t = tanh(W_{hx}x_t + W_{hh}h_{t-1} + b_h)$ (1)\n$Y_t = \u03c3(W_{yh}h_t + b_y)$ (2)\nwhere tanh is the activation function, $W_{hs}$ is the input weights, $W_{hh}$ is the recurrent weights, $W_{yt}$ is the readout weights, and $b_h$ and $b_y$ are the bias terms.\nWithin the DKT framework, the hidden state $h_t$ of the RNN is interpreted as the latent representation of the student's knowledge state. Moreover, $h_t$ is subjected to prediction through a Sigmoid-activated linear layer, denoted as $y_t$. This layer is of the same length as the number of exercises, with each element representing the model's predicted probability of the student correctly answering the corresponding exercise. The empirical findings indicated that DKT surpassed traditional KT models across multiple benchmark datasets. This underscores the promise of employing deep learning models to tackle the KT challenge. Since then, deep learning-based methods reached state of the art on knowledge tracing (Wang et al., 2023).\n\u2022 DKT model with regularization (DKT+) (Yeung and Yeung, 2018) presents a notable extension of the DKT framework. It introduces regularization terms that correspond to reconstruction and waviness to the loss function of the original DKT model to enhance the consistency in prediction. The initial loss function is expanded by integrating three regularization terms, resulting in the subsequent regularized loss function:\n$L' = L + \u03bb_rr + \u03bb_{\u03c91}\u03c9_1 + \u03bb_{\u03c92}\u03c9_2$ (3)\nwhere $\u03bb_r$, $\u03bb_{\u03c91}$, and $\u03bb_{w2}$ are regularization parameters.\nThis refinement was devised to mitigate inherent constraints observed in DKT, particularly in its proficiency to accurately reconstruct input responses and diminish incongruities in predicting answers for questions associated with similar KCs.\n\u2022 Dynamic Key-Value Memory Network (DKVMN) (Zhang et al., 2017) incorporates a key-value memory matrix, where each row represents an item or skill, and the columns correspond to key-value pairs associated with that item. The memory allows the model to store information about students' mastery of different skills and update this information as they interact with educational items. When a student responds to an item, the memory is updated to reflect their mastery of that item. The update process involves modifying the values associated with relevant keys in the memory, where the memory update for item i and key k is computed as:\n$Memory[i, k] = Memory[i, k] + update_k$ (4)\nwhere i is the index of the item, k represents the key associated with the item, and $update_k$ is the update value for key k, computed based on the student's response to the item.\n\u2022 Self-Attentive Knowledge Tracing (SAKT) (Pandey and Karypis, 2019) tried to handles with sparse data which students interact with few KCs. It adopts a transformer-based architecture, replacing Long Short-Term Memory (LSTMs) with self-attention mechanisms to capture the relevance between the KCs and the students' historical interactions. SAKT employs a novel architecture that allows for the dynamic weighting of input sequences, enabling the model to focus on the most relevant interactions within a student's learning history. The self-attention mechanism computes attention scores for each pair of elements in a sequence and then calculates a weighted sum of the values based on these scores. Here's the formula for computing the attention score for element i with respect to element j is computed as:\n$Attention(Q, K, V)_{i,j} = softmax(\\frac{Q_iK_j}{\\sqrt{d_k}})V_i$ (5)\nwhere is the query matrix, K is the key matrix, V is the value matrix, and $d_k$ is the dimensionality of the key vectors.\n\u2022 Knowledge Query Network (KQN) (Lee and Yeung, 2019) combines memory-augmented structures with attention mechanisms, encoding each student's current knowledge state as a query vector. The attention mechanisms enables KQN to retrieve pertinent information from its memory, prioritizing the most relevant items for each student. The attention weights are computed based on the similarity between each node and the current knowledge query, ensuring that the model prioritizes nodes most relevant to the student's current knowledge state. The attention weights $a_{ij}$ for each node j in the graph based on its similarity to the knowledge query $q_i$ are computed as:\n$a_{ij} = softmax(q_i.h_j)$ (6)\nwhere $h_j$ represents the node embedding for node j, $q_i$ is the knowledge query for student i. Furthermore, KQN introduces a novel concept called probabilistic skill similarity, which relates pairwise cosine and Euclidean distances between skill"}, {"title": "Experiments", "content": "It focuses on conducting a comparative evaluation of DKT models across different scales within the academic institution, specifically within the College of Engineering (COE) and at the university-wide level."}, {"title": "Dataset", "content": "We adhere to conventional practices by allocating dataset resources primarily for training purposes, typically dedicating 80% to 90% for this phase, while reserving the remaining portion for testing. Leveraging a four-year span of authentic data, we aim to predict student achievement in contemporary courses by analyzing historical academic performance. Specifically, the initial three years of data serve as the training dataset, while the fourth year is designated for testing."}, {"title": "Experiment Setup", "content": "In this study, we employed the default settings and configurations of DKT models sourced from the GitHub repository. The original PyTorch implementation of these DKT models can be accessed at https://github.com/hcnoh/knowledge-tracing-collection-pytorch.\n\u2022 Batch Size: The batch size denotes the number of instances processed in a single iteration during the training process. The default value is set to 256.\n\u2022 Number of Epochs: Epochs represent the number of complete passes through the entire training dataset. The default number of epochs utilized in this research is 100.\n\u2022 Learning Rate: This parameter governs the step size during the optimization process of the training algorithm. The default learning rate employed in this study is 0.001.\n\u2022 Optimizer: The optimizer determines the specific algorithm employed for optimizing the model parameters during the training process. The available optimizers include Stochastic Gradient Descent (SGD) and Adaptive Moment Estimation (Adam). For this research, the default optimizer chosen is Adam.\n\u2022 Sequence Length: The sequence length represents the number of time steps or elements considered in the dataset for each training instance. The default sequence length utilized in this research is 100.\nThese default settings serve as the foundational configuration for the DKT models applied throughout the experimental investigations conducted in this study. These DKT models were developed using PyTorch and trained on a workstation equipped with NVIDIA V-100 GPUs."}, {"title": "Evaluation Metrics", "content": "In the realm of knowledge tracing, numerous methodologies employ binary classification techniques to forecast students' academic performance, such as determining the accuracy of exercise completion (Song et al., 2022). This study aims to evaluate the effectiveness of various DKT models in predicting students' likelihood of success in a course, leveraging their historical subject grades as predictive features. All DKT models are subjected to a binary classification task that is to predict whether a student will pass or fail the course. The metrics used are accuracy, recall, precision, F1-score, and the Area Under the Receiver Operating Characteristic Curve (AUC).\n$Accuracy = \\frac{TP + TN}{TP + FP + TN + FN}$ (7)\nAccuracy, a commonly employed metric in classification tasks, measures the ratio of correctly classified instances, encompassing both true positives and true negatives, relative to the total instances evaluated, thereby providing a straightforward assessment of prediction accuracy.\n$Precision = \\frac{TP}{TP + FP}$ (8)\n$Recall = \\frac{TP}{TP + FN}$ (9)\n$F1 = 2 * \\frac{Precision * Recall}{Precision + Recall}$ (10)\nwhere True Positive (TP), False Positive (FP), True Negative (TN), and False Negative (FN) come from confusion matrix terminology.\n\u2022 TP: correct predictions of passing courses.\n\u2022 TN: correct predictions of failing courses.\n\u2022 FP: incorrect predictions of passing courses.\n\u2022 FN: incorrect predictions of failing courses."}, {"title": "Results and Discussion", "content": "The findings and discussions present the comprehensive prediction performance analysis of DKT models across various testing and training datasets, as delineated in Tables 6 through 13. These tables encapsulate the AUC and accuracy scores, providing insights into the model's efficacy. Recall, Precision, and F1 scores, further enriching our understanding of the model's capabilities under different training and testing conditions."}, {"title": "Knowledge tracing on departments within the COE when training on COE", "content": "Table 6 and Table 7 illustrate the performance of these models when tested on five engineering departments with training on the COE dataset. DKT and KQN models demonstrate superior performance compared to other models. Specifically, the DKT model achieves an average AUC of 0.6267, accuracy of 0.7604, and F1 score of 0.8567. The KQN model performs similarly well, with an AUC of 0.6255, accuracy of 0.7817, and F1 score of 0.8692. In contrast, the DKVMN and SAKT models exhibit moderate performance. The DKVMN model records an AUC of 0.5921, accuracy of 0.7892, and F1 score of 0.8779, while the SAKT model shows an AUC of 0.6099, accuracy of 0.7668, and F1 score of 0.8590. Among these models, the DKT+ model performs the least effectively, with an AUC of 0.5461, accuracy of 0.6277, and F1 score of 0.7469."}, {"title": "Knowledge tracing on departments within the COE when training on COE and COAS", "content": "Similarly, Table 8 and Table 9, testing the same engineering departments but with training on the COE + COAS dataset, indicates that the KQN models continue to deliver strong performance, with average metrics of AUC 0.6820, accuracy 0.8092, and F1 score 0.8884. The SAKT and DKVMN models show noticeable improvements compared to previous experiments and have surpassed the DKT model. Specifically, the SAKT model achieves an AUC of 0.6692, accuracy of 0.7903, and F1 score of 0.8750, while the DKVMN model reports an AUC of 0.6618, accuracy of 0.7949, and F1 score of 0.8805. In comparison, the DKT model has an average AUC of 0.6474, accuracy of 0.7897, and F1 score of 0.8768."}, {"title": "Knowledge tracing on departments within the COE when training on UNIV data", "content": "In Table 10 and Table 11, where testing is conducted on the same engineering departments but with training on the UNIV dataset, all models exhibit moderate to strong performance. The analysis reveals that the KQN model consistently delivers superior performance, with an average AUC of 0.6965, accuracy of 0.7996, and F1 score of 0.8834. The SAKT and DKVMN models also show competitive performance, reflecting their adaptability across various domains. Specifically, the SAKT model averages an AUC of 0.6764, accuracy of 0.8028, and F1 score of 0.8831, while the DKVMN model achieves an AUC of 0.6676, accuracy of 0.8066, and F1 score of 0.8889. Overall, the KQN model stands out for its robust performance across different testing and training datasets, establishing it as a reliable choice for educational prediction tasks. The SAKT and DKVMN models also demonstrate strong performance, suggesting their suitability for real-world educational prediction applications alongside KQN. In contrast, the DKT and DKT+ models show moderate performance and are generally surpassed by the KQN and SAKT models, underscoring the advantages of newer model architectures."}, {"title": "Knowledge tracing on COE and UNIV when training on UNIV data", "content": "Table 12 and Table 13 illustrate the performance of these models when tested on COE and UNIV with training on the UNIV dataset. For COE testing dataset, the analysis shows that the KQN model exhibits strong performance across datasets, with an average AUC of 0.6847, accuracy of 0.7963, and F1 score of 0.8805. The SAKT model also performs competitively, with an average AUC of 0.6845, accuracy of 0.7848, and F1 score of 0.8712. In contrast, the DKVMN and DKT models display moderate performance. The DKVMN model has an AUC of 0.6525, accuracy of 0.7987, and F1 score of 0.8837, while the DKT model shows an AUC of 0.6579, accuracy of 0.7779, and F1 score of 0.8672.\nFor the UNIV testing dataset, both the SAKT and KQN models maintain strong performance. The SAKT model averages an AUC of 0.6644, accuracy of 0.8094, and F1 score of 0.8892, while the KQN model achieves an AUC of 0.6639, accuracy of 0.8197, and F1 score of 0.8974. The DKVMN and DKT models continue to show moderate performance, with the DKVMN model having an AUC of 0.6326, accuracy of 0.8153, and F1 score of 0.8961, and the DKT model reporting an AUC of 0.6500, accuracy of 0.7917, and F1 score of 0.8791.\nWhen evaluating the models trained on the UNIV dataset, it is observed that testing on the smaller COE dataset yields better performance metrics than testing on the entire UNIV dataset. This discrepancy is largely due to the differences in testing and training ratios. The smaller COE testing dataset might have fewer examples but could present a more homogeneous and controlled environment, allowing the model to perform more effectively. In contrast, the larger UNIV dataset introduces greater variability and complexity, which can challenge the model's ability to generalize, potentially leading to lower performance metrics."}, {"title": "Conclusion and Future Work", "content": "PAL allows for monitoring individual students' progress and tailoring their learning paths to their unique knowledge and needs. DKT for PAL enhanced modeling students' evolving knowledge to predict their future performance. This study mitigates the gap in its investigation and application within specific educational contexts, particularly at HBCUs through building a comprehensive dataset from PVAMU and DKT model evaluation on this dataset. This study advocates for the utilization of DKT models to forecast the academic performance of undergraduate students, particularly in determining whether they will pass or fail a course based on their historical grade records. Through the utilization of diverse training datasets and various DKT models, the findings affirm the efficacy of DKT models in predicting students' academic outcomes for HBCUs. Furthermore, the adoption of DKT models in academic settings can serve as a valuable tool for enhancing student support mechanisms and promoting academic success for HBCUS.\nIn the future, it plans to explore the potential of adopting different DKT architectures not considered in this study such as large language models (LLMs) to develop more sophisticated models capable of capturing complex patterns in student learning data. Furthermore, there is a need to expand the way of knowledge skills are determined within the DKT models. While current research rely on course subject and course level, future research could explore incorporating additional course features to provide a more comprehensive understanding of student knowledge and learning trajectories. By incorporating these advancements, future DKT models have the potential to offer more accurate and personalized insights into student learning processes, ultimately leading to improved educational outcomes."}, {"title": "Related Work", "content": "Knowledge tracing involves modeling students' learning progress based on their activity sequences, making it a challenging task due to the need for accurate performance prediction and understanding of students' mastery levels. Researchers have tackled this challenge through various approaches. There are two most representative models: Bayesian Knowledge Tracking (BKT) and Deep Knowledge Tracing (DKT). Early efforts focused on BKT models (Corbett and Anderson, 1994), wherein each student's knowledge state is represented as a binary variable. These models employ probabilistic techniques like the Hidden Markov Model (HMM) to assess students' grasp of concepts (Awad and Khanna, 2015). It characterizes a student's progress in tackling problems associated with a specific concept by utilizing a binary indicator (either correct or"}]}